{
  "author": {
    "id": "itsmostafa",
    "display_name": "Mostafa",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/24395434?u=fc63e2baaea264df36ba590ccf3eabd6ed2bd54c&v=4",
    "url": "https://github.com/itsmostafa",
    "bio": "I build stuff",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 18,
      "total_stars": 979,
      "total_forks": 417
    }
  },
  "marketplaces": [
    {
      "name": "aws-agent-skills",
      "version": null,
      "description": "Claude skills for AWS cloud engineering tasks",
      "owner_info": {
        "name": "itsmostafa",
        "email": "mostafaxcodes@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "itsmostafa/aws-agent-skills",
      "repo_url": "https://github.com/itsmostafa/aws-agent-skills",
      "repo_description": "AWS Skills for Agents",
      "homepage": "",
      "signals": {
        "stars": 979,
        "forks": 417,
        "pushed_at": "2026-01-26T09:09:14Z",
        "created_at": "2019-05-18T19:38:59Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 991
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 4708
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/api-gateway",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/api-gateway/SKILL.md",
          "type": "blob",
          "size": 8947
        },
        {
          "path": "skills/api-gateway/integration-patterns.md",
          "type": "blob",
          "size": 9246
        },
        {
          "path": "skills/bedrock",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bedrock/SKILL.md",
          "type": "blob",
          "size": 10823
        },
        {
          "path": "skills/bedrock/model-invocation.md",
          "type": "blob",
          "size": 13261
        },
        {
          "path": "skills/cloudformation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cloudformation/SKILL.md",
          "type": "blob",
          "size": 9819
        },
        {
          "path": "skills/cloudformation/template-patterns.md",
          "type": "blob",
          "size": 8693
        },
        {
          "path": "skills/cloudwatch",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cloudwatch/SKILL.md",
          "type": "blob",
          "size": 10496
        },
        {
          "path": "skills/cloudwatch/alarms-metrics.md",
          "type": "blob",
          "size": 11278
        },
        {
          "path": "skills/cognito",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cognito/SKILL.md",
          "type": "blob",
          "size": 9223
        },
        {
          "path": "skills/cognito/auth-flows.md",
          "type": "blob",
          "size": 9131
        },
        {
          "path": "skills/dynamodb",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dynamodb/SKILL.md",
          "type": "blob",
          "size": 9890
        },
        {
          "path": "skills/dynamodb/query-patterns.md",
          "type": "blob",
          "size": 9266
        },
        {
          "path": "skills/ec2",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ec2/SKILL.md",
          "type": "blob",
          "size": 9452
        },
        {
          "path": "skills/ec2/instance-management.md",
          "type": "blob",
          "size": 9387
        },
        {
          "path": "skills/ecs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ecs/SKILL.md",
          "type": "blob",
          "size": 9410
        },
        {
          "path": "skills/ecs/task-definitions.md",
          "type": "blob",
          "size": 8770
        },
        {
          "path": "skills/eks",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/eks/SKILL.md",
          "type": "blob",
          "size": 9611
        },
        {
          "path": "skills/eks/cluster-setup.md",
          "type": "blob",
          "size": 8714
        },
        {
          "path": "skills/eventbridge",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/eventbridge/SKILL.md",
          "type": "blob",
          "size": 9306
        },
        {
          "path": "skills/eventbridge/event-patterns.md",
          "type": "blob",
          "size": 7573
        },
        {
          "path": "skills/iam",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/iam/SKILL.md",
          "type": "blob",
          "size": 7075
        },
        {
          "path": "skills/iam/best-practices.md",
          "type": "blob",
          "size": 7299
        },
        {
          "path": "skills/iam/policies.md",
          "type": "blob",
          "size": 6873
        },
        {
          "path": "skills/lambda",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/lambda/SKILL.md",
          "type": "blob",
          "size": 8617
        },
        {
          "path": "skills/lambda/debugging.md",
          "type": "blob",
          "size": 8731
        },
        {
          "path": "skills/lambda/deployment.md",
          "type": "blob",
          "size": 7300
        },
        {
          "path": "skills/rds",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/rds/SKILL.md",
          "type": "blob",
          "size": 9728
        },
        {
          "path": "skills/rds/administration.md",
          "type": "blob",
          "size": 8066
        },
        {
          "path": "skills/s3",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/s3/SKILL.md",
          "type": "blob",
          "size": 9316
        },
        {
          "path": "skills/s3/security.md",
          "type": "blob",
          "size": 7611
        },
        {
          "path": "skills/secrets-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/secrets-manager/SKILL.md",
          "type": "blob",
          "size": 9046
        },
        {
          "path": "skills/secrets-manager/rotation-strategies.md",
          "type": "blob",
          "size": 11139
        },
        {
          "path": "skills/sns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sns/SKILL.md",
          "type": "blob",
          "size": 9796
        },
        {
          "path": "skills/sns/notification-patterns.md",
          "type": "blob",
          "size": 7850
        },
        {
          "path": "skills/sqs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sqs/SKILL.md",
          "type": "blob",
          "size": 9040
        },
        {
          "path": "skills/sqs/messaging-patterns.md",
          "type": "blob",
          "size": 10738
        },
        {
          "path": "skills/step-functions",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/step-functions/SKILL.md",
          "type": "blob",
          "size": 9709
        },
        {
          "path": "skills/step-functions/workflow-patterns.md",
          "type": "blob",
          "size": 8970
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"aws-agent-skills\",\n  \"owner\": {\n    \"name\": \"itsmostafa\",\n    \"email\": \"mostafaxcodes@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude skills for AWS cloud engineering tasks\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"aws-agent-skills\",\n      \"description\": \"Collection of AWS engineering skills for IAM, Lambda, DynamoDB, S3, and 14 other core AWS services\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/iam\",\n        \"./skills/lambda\",\n        \"./skills/dynamodb\",\n        \"./skills/s3\",\n        \"./skills/api-gateway\",\n        \"./skills/ec2\",\n        \"./skills/ecs\",\n        \"./skills/eks\",\n        \"./skills/cloudformation\",\n        \"./skills/cloudwatch\",\n        \"./skills/rds\",\n        \"./skills/sqs\",\n        \"./skills/sns\",\n        \"./skills/cognito\",\n        \"./skills/step-functions\",\n        \"./skills/secrets-manager\",\n        \"./skills/eventbridge\",\n        \"./skills/bedrock\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# AWS Agent Skills\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Claude Code](https://img.shields.io/badge/Claude-Code-blueviolet)](https://claude.ai/code)\n![Last Commit](https://img.shields.io/github/last-commit/itsmostafa/aws-agent-skills)\n![GitHub Stars](https://img.shields.io/github/stars/itsmostafa/aws-agent-skills)\n\nSupercharge Claude Code with AWS cloud engineering skills across 18 core AWS services.\n\n## ðŸš€ Why AWS Agent Skills?\n\nDeveloping AWS solutions is complex spanning IAM, compute, storage, security, serverless, networking, and more.\n\nAWS Agent Skills equips Claude Code (and Codex) with deep expertise across 18 AWS domains, enabling automated cloud engineering support from IaC templates to debugging guidance and security best practices.\n\nAutomatically checks AWS documentation for updates on a weekly basis to ensure skills stay current with AWS service changes.\n\n### Why not just use an MCP?\n\nAWS MCP is great for live docs and API calls, but AWS Agent Skills is designed for reasoning first.\nIt gives AI Agents a curated, LLM-optimized AWS knowledge base with real-world patterns, edge cases, and best practices, without streaming large docs or schemas.\nBecause the skills are local and pre compressed, it is far more token efficient, keeps the context window small and predictable, and avoids MCP infrastructure, latency, and expanded credential exposure.\n\n## Installation\n\n### Claude Code\n\n#### From Marketplace\n\n```bash\n# Add the marketplace\n/plugin marketplace add itsmostafa/aws-agent-skills\n\n# Install the plugin\n/plugin install aws-agent-skills\n```\n\n#### From GitHub\n\n```bash\n/plugin install https://github.com/itsmostafa/aws-agent-skills\n```\n\n#### Local Development\n\n```bash\n/plugin install ./path/to/aws-agent-skills\n```\n\n### Codex CLI\n\n```bash\n$skill-installer install https://github.com/itsmostafa/aws-agent-skills/<skill-name>\n```\n\nFor example, to install the `rlhf` skill:\n\n```bash\n$skill-installer install https://github.com/itsmostafa/aws-agent-skills/rlhf\n```\n\n## Available Skills\n\n| Skill | Description |\n|-------|-------------|\n| **iam** | Identity and Access Management - users, roles, policies, permissions |\n| **lambda** | Serverless functions - deployment, triggers, debugging |\n| **dynamodb** | NoSQL database - table design, queries, indexes |\n| **s3** | Object storage - buckets, objects, security, lifecycle |\n| **api-gateway** | REST and HTTP APIs - integrations, authorization |\n| **ec2** | Virtual machines - instances, AMIs, networking |\n| **ecs** | Container orchestration - clusters, services, tasks |\n| **eks** | Kubernetes - clusters, node groups, IRSA |\n| **cloudformation** | Infrastructure as Code - templates, stacks, drift |\n| **cloudwatch** | Monitoring - logs, metrics, alarms, dashboards |\n| **rds** | Relational databases - instances, backups, replication |\n| **sqs** | Message queues - standard, FIFO, dead-letter queues |\n| **sns** | Notifications - topics, subscriptions, filtering |\n| **cognito** | User authentication - user pools, identity pools, OAuth |\n| **step-functions** | Workflow orchestration - state machines, error handling |\n| **secrets-manager** | Secret storage - rotation, versioning, RDS integration |\n| **eventbridge** | Event bus - rules, patterns, cross-account events |\n| **bedrock** | Foundation models - inference, RAG, custom models |\n\n## Usage Examples\n\n### IAM Policy Creation\nAsk Claude to help with IAM:\n- \"Create an IAM policy for Lambda to access DynamoDB\"\n- \"Set up cross-account access for S3\"\n- \"Debug this access denied error\"\n\n### Lambda Development\n- \"Create a Python Lambda function triggered by S3\"\n- \"Debug my Lambda timeout issues\"\n- \"Set up Lambda with VPC access\"\n\n### Infrastructure as Code\n- \"Write a CloudFormation template for a serverless API\"\n- \"Create an ECS Fargate service with load balancer\"\n- \"Set up EventBridge rules for scheduled tasks\"\n\n## Skill Structure\n\nEach skill contains:\n- `SKILL.md` - Core concepts, patterns, CLI reference, best practices, troubleshooting\n- Supplementary files - Deep dives into specific topics\n\nSkills include metadata showing when content was last updated, so you always know how current the information is.\n\n## Contributing\n\n1. Fork this repository\n2. Create a feature branch\n3. Add or update skills following the SKILL.md template\n4. Submit a pull request\n\n### SKILL.md Template\n\n```yaml\n---\nname: service-name\ndescription: Service description. Use when <trigger phrases>.\n---\n\n# AWS Service Name\n\n## Overview\n## Core Concepts\n## Common Patterns\n## CLI Reference\n## Best Practices\n## Troubleshooting\n## References\n```\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n",
        "skills/api-gateway/SKILL.md": "---\nname: api-gateway\ndescription: AWS API Gateway for REST and HTTP API management. Use when creating APIs, configuring integrations, setting up authorization, managing stages, implementing rate limiting, or troubleshooting API issues.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/apigateway/latest/developerguide/\n---\n\n# AWS API Gateway\n\nAmazon API Gateway is a fully managed service for creating, publishing, and securing APIs at any scale. Supports REST APIs, HTTP APIs, and WebSocket APIs.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### API Types\n\n| Type | Description | Use Case |\n|------|-------------|----------|\n| **HTTP API** | Low-latency, cost-effective | Simple APIs, Lambda proxy |\n| **REST API** | Full-featured, more control | Complex APIs, transformation |\n| **WebSocket API** | Bidirectional communication | Real-time apps, chat |\n\n### Key Components\n\n- **Resources**: URL paths (/users, /orders/{id})\n- **Methods**: HTTP verbs (GET, POST, PUT, DELETE)\n- **Integrations**: Backend connections (Lambda, HTTP, AWS services)\n- **Stages**: Deployment environments (dev, prod)\n\n### Integration Types\n\n| Type | Description |\n|------|-------------|\n| **Lambda Proxy** | Pass-through to Lambda (recommended) |\n| **Lambda Custom** | Transform request/response |\n| **HTTP Proxy** | Pass-through to HTTP endpoint |\n| **AWS Service** | Direct integration with AWS services |\n| **Mock** | Return static response |\n\n## Common Patterns\n\n### Create HTTP API with Lambda\n\n**AWS CLI:**\n\n```bash\n# Create HTTP API\naws apigatewayv2 create-api \\\n  --name my-api \\\n  --protocol-type HTTP \\\n  --target arn:aws:lambda:us-east-1:123456789012:function:MyFunction\n\n# Get API endpoint\naws apigatewayv2 get-api --api-id abc123 --query 'ApiEndpoint'\n```\n\n**SAM Template:**\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  MyApi:\n    Type: AWS::Serverless::HttpApi\n    Properties:\n      StageName: prod\n\n  MyFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.handler\n      Runtime: python3.12\n      Events:\n        ApiEvent:\n          Type: HttpApi\n          Properties:\n            ApiId: !Ref MyApi\n            Path: /items\n            Method: GET\n```\n\n### Create REST API with Lambda Proxy\n\n```bash\n# Create REST API\naws apigateway create-rest-api \\\n  --name my-rest-api \\\n  --endpoint-configuration types=REGIONAL\n\nAPI_ID=abc123\n\n# Get root resource ID\nROOT_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query 'items[0].id' --output text)\n\n# Create resource\naws apigateway create-resource \\\n  --rest-api-id $API_ID \\\n  --parent-id $ROOT_ID \\\n  --path-part items\n\nRESOURCE_ID=xyz789\n\n# Create method\naws apigateway put-method \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method GET \\\n  --authorization-type NONE\n\n# Create Lambda integration\naws apigateway put-integration \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method GET \\\n  --type AWS_PROXY \\\n  --integration-http-method POST \\\n  --uri arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/arn:aws:lambda:us-east-1:123456789012:function:MyFunction/invocations\n\n# Deploy to stage\naws apigateway create-deployment \\\n  --rest-api-id $API_ID \\\n  --stage-name prod\n```\n\n### Lambda Handler for API Gateway\n\n```python\nimport json\n\ndef handler(event, context):\n    # HTTP API event\n    http_method = event.get('requestContext', {}).get('http', {}).get('method')\n    path = event.get('rawPath', '')\n    query_params = event.get('queryStringParameters', {})\n    body = event.get('body', '')\n\n    if body and event.get('isBase64Encoded'):\n        import base64\n        body = base64.b64decode(body).decode('utf-8')\n\n    # Process request\n    response_body = {'message': 'Success', 'path': path}\n\n    return {\n        'statusCode': 200,\n        'headers': {\n            'Content-Type': 'application/json'\n        },\n        'body': json.dumps(response_body)\n    }\n```\n\n### Configure CORS\n\n**HTTP API:**\n\n```bash\naws apigatewayv2 update-api \\\n  --api-id abc123 \\\n  --cors-configuration '{\n    \"AllowOrigins\": [\"https://example.com\"],\n    \"AllowMethods\": [\"GET\", \"POST\", \"PUT\", \"DELETE\"],\n    \"AllowHeaders\": [\"Content-Type\", \"Authorization\"],\n    \"MaxAge\": 86400\n  }'\n```\n\n**REST API:**\n\n```bash\n# Enable CORS on resource\naws apigateway put-method \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method OPTIONS \\\n  --authorization-type NONE\n\naws apigateway put-integration \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method OPTIONS \\\n  --type MOCK \\\n  --request-templates '{\"application/json\": \"{\\\"statusCode\\\": 200}\"}'\n\naws apigateway put-method-response \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method OPTIONS \\\n  --status-code 200 \\\n  --response-parameters '{\n    \"method.response.header.Access-Control-Allow-Headers\": true,\n    \"method.response.header.Access-Control-Allow-Methods\": true,\n    \"method.response.header.Access-Control-Allow-Origin\": true\n  }'\n\naws apigateway put-integration-response \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method OPTIONS \\\n  --status-code 200 \\\n  --response-parameters '{\n    \"method.response.header.Access-Control-Allow-Headers\": \"'\\''Content-Type,Authorization'\\''\",\n    \"method.response.header.Access-Control-Allow-Methods\": \"'\\''GET,POST,PUT,DELETE,OPTIONS'\\''\",\n    \"method.response.header.Access-Control-Allow-Origin\": \"'\\''*'\\''\"\n  }'\n```\n\n### JWT Authorization (HTTP API)\n\n```bash\naws apigatewayv2 create-authorizer \\\n  --api-id abc123 \\\n  --name jwt-authorizer \\\n  --authorizer-type JWT \\\n  --identity-source '$request.header.Authorization' \\\n  --jwt-configuration '{\n    \"Issuer\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123\",\n    \"Audience\": [\"client-id\"]\n  }'\n```\n\n## CLI Reference\n\n### HTTP API (apigatewayv2)\n\n| Command | Description |\n|---------|-------------|\n| `aws apigatewayv2 create-api` | Create API |\n| `aws apigatewayv2 get-apis` | List APIs |\n| `aws apigatewayv2 create-route` | Create route |\n| `aws apigatewayv2 create-integration` | Create integration |\n| `aws apigatewayv2 create-stage` | Create stage |\n| `aws apigatewayv2 create-authorizer` | Create authorizer |\n\n### REST API (apigateway)\n\n| Command | Description |\n|---------|-------------|\n| `aws apigateway create-rest-api` | Create API |\n| `aws apigateway get-rest-apis` | List APIs |\n| `aws apigateway create-resource` | Create resource |\n| `aws apigateway put-method` | Create method |\n| `aws apigateway put-integration` | Create integration |\n| `aws apigateway create-deployment` | Deploy API |\n\n## Best Practices\n\n### Performance\n\n- **Use HTTP APIs** for simple use cases (70% cheaper, lower latency)\n- **Enable caching** for REST APIs\n- **Use regional endpoints** unless global distribution needed\n- **Implement pagination** for list endpoints\n\n### Security\n\n- **Use authorization** on all endpoints\n- **Enable WAF** for REST APIs\n- **Use API keys** for rate limiting (not authentication)\n- **Enable access logging**\n- **Use HTTPS only**\n\n### Reliability\n\n- **Set up throttling** to protect backends\n- **Configure timeout** appropriately\n- **Use canary deployments** for updates\n- **Monitor with CloudWatch**\n\n## Troubleshooting\n\n### 403 Forbidden\n\n**Causes:**\n- Missing authorization\n- Invalid API key\n- WAF blocking\n- Resource policy denying\n\n**Debug:**\n\n```bash\n# Check API key\naws apigateway get-api-key --api-key abc123 --include-value\n\n# Check authorizer\naws apigatewayv2 get-authorizer --api-id abc123 --authorizer-id xyz789\n```\n\n### 502 Bad Gateway\n\n**Causes:**\n- Lambda error\n- Integration timeout\n- Invalid response format\n\n**Lambda response format:**\n\n```python\n# Correct format\nreturn {\n    'statusCode': 200,\n    'headers': {'Content-Type': 'application/json'},\n    'body': json.dumps({'message': 'success'})\n}\n\n# Wrong - missing statusCode\nreturn {'message': 'success'}\n```\n\n### 504 Gateway Timeout\n\n**Causes:**\n- Backend timeout (Lambda max 29 seconds for REST API)\n- Integration timeout too short\n\n**Solutions:**\n- Increase Lambda timeout\n- Use async processing for long operations\n- Increase integration timeout (max 29s for REST, 30s for HTTP)\n\n### CORS Errors\n\n**Debug:**\n- Check OPTIONS method exists\n- Verify headers in response\n- Check origin matches allowed origins\n\n## References\n\n- [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/)\n- [API Gateway REST API Reference](https://docs.aws.amazon.com/apigateway/latest/api/)\n- [API Gateway CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/apigateway/)\n- [boto3 API Gateway](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/apigateway.html)\n",
        "skills/api-gateway/integration-patterns.md": "# API Gateway Integration Patterns\n\nAdvanced integration patterns and configurations.\n\n## Lambda Integrations\n\n### Proxy Integration (Recommended)\n\nPass entire request to Lambda:\n\n```yaml\n# SAM\nResources:\n  GetItemsFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.handler\n      Events:\n        GetItems:\n          Type: Api\n          Properties:\n            Path: /items\n            Method: GET\n```\n\nLambda receives:\n\n```json\n{\n  \"resource\": \"/items\",\n  \"path\": \"/items\",\n  \"httpMethod\": \"GET\",\n  \"headers\": {...},\n  \"queryStringParameters\": {...},\n  \"pathParameters\": {...},\n  \"body\": \"...\",\n  \"isBase64Encoded\": false\n}\n```\n\n### Custom Integration\n\nTransform request/response:\n\n```bash\n# Request template\naws apigateway put-integration \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method POST \\\n  --type AWS \\\n  --integration-http-method POST \\\n  --uri arn:aws:apigateway:us-east-1:lambda:path/... \\\n  --request-templates '{\n    \"application/json\": \"{\\\"action\\\": \\\"$input.params(\\\"action\\\")\\\", \\\"data\\\": $input.json(\\\"$.body\\\")}\"\n  }'\n\n# Response template\naws apigateway put-integration-response \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method POST \\\n  --status-code 200 \\\n  --response-templates '{\n    \"application/json\": \"{\\\"result\\\": $input.json(\\\"$.Payload\\\")}\"\n  }'\n```\n\n## AWS Service Integrations\n\n### Direct DynamoDB Integration\n\n```json\n{\n  \"type\": \"AWS\",\n  \"uri\": \"arn:aws:apigateway:us-east-1:dynamodb:action/GetItem\",\n  \"credentials\": \"arn:aws:iam::123456789012:role/apigw-dynamodb-role\",\n  \"requestTemplates\": {\n    \"application/json\": \"{\\\"TableName\\\": \\\"Users\\\", \\\"Key\\\": {\\\"id\\\": {\\\"S\\\": \\\"$input.params('id')\\\"}}}\"\n  },\n  \"responses\": {\n    \"default\": {\n      \"statusCode\": \"200\",\n      \"responseTemplates\": {\n        \"application/json\": \"#set($item = $input.path('$.Item'))\\n{\\\"id\\\": \\\"$item.id.S\\\", \\\"name\\\": \\\"$item.name.S\\\"}\"\n      }\n    }\n  }\n}\n```\n\n### Direct SQS Integration\n\n```json\n{\n  \"type\": \"AWS\",\n  \"uri\": \"arn:aws:apigateway:us-east-1:sqs:path/123456789012/my-queue\",\n  \"credentials\": \"arn:aws:iam::123456789012:role/apigw-sqs-role\",\n  \"requestParameters\": {\n    \"integration.request.header.Content-Type\": \"'application/x-www-form-urlencoded'\"\n  },\n  \"requestTemplates\": {\n    \"application/json\": \"Action=SendMessage&MessageBody=$util.urlEncode($input.body)\"\n  },\n  \"responses\": {\n    \"default\": {\n      \"statusCode\": \"200\",\n      \"responseTemplates\": {\n        \"application/json\": \"{\\\"messageId\\\": \\\"$input.path('$.SendMessageResponse.SendMessageResult.MessageId')\\\"}\"\n      }\n    }\n  }\n}\n```\n\n### Direct Step Functions Integration\n\n```json\n{\n  \"type\": \"AWS\",\n  \"uri\": \"arn:aws:apigateway:us-east-1:states:action/StartExecution\",\n  \"credentials\": \"arn:aws:iam::123456789012:role/apigw-stepfunctions-role\",\n  \"requestTemplates\": {\n    \"application/json\": \"{\\\"input\\\": \\\"$util.escapeJavaScript($input.json('$'))\\\", \\\"stateMachineArn\\\": \\\"arn:aws:states:us-east-1:123456789012:stateMachine:MyWorkflow\\\"}\"\n  }\n}\n```\n\n## HTTP Integrations\n\n### HTTP Proxy\n\n```bash\naws apigateway put-integration \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method GET \\\n  --type HTTP_PROXY \\\n  --integration-http-method GET \\\n  --uri https://api.example.com/items\n```\n\n### HTTP with VPC Link\n\n```bash\n# Create VPC Link\naws apigateway create-vpc-link \\\n  --name my-vpc-link \\\n  --target-arns arn:aws:elasticloadbalancing:us-east-1:123456789012:loadbalancer/net/my-nlb/abc123\n\n# Use VPC Link in integration\naws apigateway put-integration \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method GET \\\n  --type HTTP_PROXY \\\n  --connection-type VPC_LINK \\\n  --connection-id vpc-link-id \\\n  --uri http://my-nlb.internal:8080/items\n```\n\n## Request Validation\n\n### Enable Request Validation\n\n```bash\n# Create validator\naws apigateway create-request-validator \\\n  --rest-api-id $API_ID \\\n  --name body-validator \\\n  --validate-request-body \\\n  --validate-request-parameters\n\n# Create model\naws apigateway create-model \\\n  --rest-api-id $API_ID \\\n  --name CreateUserModel \\\n  --content-type application/json \\\n  --schema '{\n    \"type\": \"object\",\n    \"required\": [\"name\", \"email\"],\n    \"properties\": {\n      \"name\": {\"type\": \"string\", \"minLength\": 1},\n      \"email\": {\"type\": \"string\", \"format\": \"email\"}\n    }\n  }'\n\n# Apply to method\naws apigateway put-method \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method POST \\\n  --authorization-type NONE \\\n  --request-validator-id validator-id \\\n  --request-models '{\"application/json\": \"CreateUserModel\"}'\n```\n\n## Authorization\n\n### Cognito Authorizer (REST API)\n\n```bash\naws apigateway create-authorizer \\\n  --rest-api-id $API_ID \\\n  --name cognito-authorizer \\\n  --type COGNITO_USER_POOLS \\\n  --identity-source 'method.request.header.Authorization' \\\n  --provider-arns arn:aws:cognito-idp:us-east-1:123456789012:userpool/us-east-1_abc123\n```\n\n### Lambda Authorizer\n\n```bash\naws apigateway create-authorizer \\\n  --rest-api-id $API_ID \\\n  --name custom-authorizer \\\n  --type TOKEN \\\n  --authorizer-uri arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/arn:aws:lambda:us-east-1:123456789012:function:Authorizer/invocations \\\n  --identity-source 'method.request.header.Authorization' \\\n  --authorizer-result-ttl-in-seconds 300\n```\n\nLambda authorizer code:\n\n```python\ndef handler(event, context):\n    token = event['authorizationToken']\n    method_arn = event['methodArn']\n\n    # Validate token\n    if is_valid_token(token):\n        principal_id = get_user_id(token)\n        return generate_policy(principal_id, 'Allow', method_arn)\n    else:\n        raise Exception('Unauthorized')\n\ndef generate_policy(principal_id, effect, resource):\n    return {\n        'principalId': principal_id,\n        'policyDocument': {\n            'Version': '2012-10-17',\n            'Statement': [{\n                'Action': 'execute-api:Invoke',\n                'Effect': effect,\n                'Resource': resource\n            }]\n        },\n        'context': {\n            'userId': principal_id\n        }\n    }\n```\n\n## Rate Limiting\n\n### Usage Plans and API Keys\n\n```bash\n# Create API key\naws apigateway create-api-key \\\n  --name client-api-key \\\n  --enabled\n\n# Create usage plan\naws apigateway create-usage-plan \\\n  --name basic-plan \\\n  --throttle burstLimit=100,rateLimit=50 \\\n  --quota limit=10000,period=MONTH \\\n  --api-stages apiId=$API_ID,stage=prod\n\n# Associate key with plan\naws apigateway create-usage-plan-key \\\n  --usage-plan-id plan-id \\\n  --key-id key-id \\\n  --key-type API_KEY\n```\n\n### Method-Level Throttling\n\n```bash\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/~1items/GET/throttling/burstLimit\",\n    \"value\": \"50\"\n  }, {\n    \"op\": \"replace\",\n    \"path\": \"/~1items/GET/throttling/rateLimit\",\n    \"value\": \"100\"\n  }]'\n```\n\n## Caching (REST API)\n\n### Enable Caching\n\n```bash\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/cacheClusterEnabled\",\n    \"value\": \"true\"\n  }, {\n    \"op\": \"replace\",\n    \"path\": \"/cacheClusterSize\",\n    \"value\": \"0.5\"\n  }]'\n```\n\n### Cache Key Parameters\n\n```bash\naws apigateway update-method \\\n  --rest-api-id $API_ID \\\n  --resource-id $RESOURCE_ID \\\n  --http-method GET \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/requestParameters/method.request.querystring.category\",\n    \"value\": \"true\"\n  }]'\n```\n\n### Cache Invalidation\n\n```bash\n# From client with API key\ncurl -X GET \"https://api.example.com/prod/items\" \\\n  -H \"Cache-Control: max-age=0\"\n```\n\n## Logging and Monitoring\n\n### Access Logging\n\n```bash\n# Create log group\naws logs create-log-group --log-group-name API-Gateway-Access-Logs\n\n# Enable access logging\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/accessLogSettings/destinationArn\",\n    \"value\": \"arn:aws:logs:us-east-1:123456789012:log-group:API-Gateway-Access-Logs\"\n  }, {\n    \"op\": \"replace\",\n    \"path\": \"/accessLogSettings/format\",\n    \"value\": \"{\\\"requestId\\\":\\\"$context.requestId\\\",\\\"ip\\\":\\\"$context.identity.sourceIp\\\",\\\"method\\\":\\\"$context.httpMethod\\\",\\\"path\\\":\\\"$context.path\\\",\\\"status\\\":\\\"$context.status\\\",\\\"latency\\\":\\\"$context.responseLatency\\\"}\"\n  }]'\n```\n\n### Execution Logging\n\n```bash\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/*/*/logging/loglevel\",\n    \"value\": \"INFO\"\n  }, {\n    \"op\": \"replace\",\n    \"path\": \"/*/*/logging/dataTrace\",\n    \"value\": \"true\"\n  }]'\n```\n\n## Canary Deployments\n\n```bash\n# Create canary\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"replace\",\n    \"path\": \"/canarySettings/percentTraffic\",\n    \"value\": \"10\"\n  }, {\n    \"op\": \"replace\",\n    \"path\": \"/canarySettings/deploymentId\",\n    \"value\": \"new-deployment-id\"\n  }]'\n\n# Promote canary\naws apigateway update-stage \\\n  --rest-api-id $API_ID \\\n  --stage-name prod \\\n  --patch-operations '[{\n    \"op\": \"remove\",\n    \"path\": \"/canarySettings\"\n  }]'\n```\n",
        "skills/bedrock/SKILL.md": "---\nname: bedrock\ndescription: AWS Bedrock foundation models for generative AI. Use when invoking foundation models, building AI applications, creating embeddings, configuring model access, or implementing RAG patterns.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/bedrock/latest/userguide/\n---\n\n# AWS Bedrock\n\nAmazon Bedrock provides access to foundation models (FMs) from AI companies through a unified API. Build generative AI applications with text generation, embeddings, and image generation capabilities.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Foundation Models\n\nPre-trained models available through Bedrock:\n- **Claude** (Anthropic): Text generation, analysis, coding\n- **Titan** (Amazon): Text, embeddings, image generation\n- **Llama** (Meta): Open-weight text generation\n- **Mistral**: Efficient text generation\n- **Stable Diffusion** (Stability AI): Image generation\n\n### Model Access\n\nModels must be enabled in your account before use:\n- Request access in Bedrock console\n- Some models require acceptance of EULAs\n- Access is region-specific\n\n### Inference Types\n\n| Type | Use Case | Pricing |\n|------|----------|---------|\n| **On-Demand** | Variable workloads | Per token |\n| **Provisioned Throughput** | Consistent high-volume | Hourly commitment |\n| **Batch Inference** | Async large-scale | Discounted per token |\n\n## Common Patterns\n\n### Invoke Model (Text Generation)\n\n**AWS CLI:**\n\n```bash\n# Invoke Claude\naws bedrock-runtime invoke-model \\\n  --model-id anthropic.claude-3-sonnet-20240229-v1:0 \\\n  --content-type application/json \\\n  --accept application/json \\\n  --body '{\n    \"anthropic_version\": \"bedrock-2023-05-31\",\n    \"max_tokens\": 1024,\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain AWS Lambda in 3 sentences.\"}\n    ]\n  }' \\\n  response.json\n\ncat response.json | jq -r '.content[0].text'\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport json\n\nbedrock = boto3.client('bedrock-runtime')\n\ndef invoke_claude(prompt, max_tokens=1024):\n    response = bedrock.invoke_model(\n        modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'anthropic_version': 'bedrock-2023-05-31',\n            'max_tokens': max_tokens,\n            'messages': [\n                {'role': 'user', 'content': prompt}\n            ]\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['content'][0]['text']\n\n# Usage\nresponse = invoke_claude('What is Amazon S3?')\nprint(response)\n```\n\n### Streaming Response\n\n```python\nimport boto3\nimport json\n\nbedrock = boto3.client('bedrock-runtime')\n\ndef stream_claude(prompt):\n    response = bedrock.invoke_model_with_response_stream(\n        modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'anthropic_version': 'bedrock-2023-05-31',\n            'max_tokens': 1024,\n            'messages': [\n                {'role': 'user', 'content': prompt}\n            ]\n        })\n    )\n\n    for event in response['body']:\n        chunk = json.loads(event['chunk']['bytes'])\n        if chunk['type'] == 'content_block_delta':\n            yield chunk['delta'].get('text', '')\n\n# Usage\nfor text in stream_claude('Write a haiku about cloud computing.'):\n    print(text, end='', flush=True)\n```\n\n### Generate Embeddings\n\n```python\nimport boto3\nimport json\n\nbedrock = boto3.client('bedrock-runtime')\n\ndef get_embedding(text):\n    response = bedrock.invoke_model(\n        modelId='amazon.titan-embed-text-v2:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'inputText': text,\n            'dimensions': 1024,\n            'normalize': True\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['embedding']\n\n# Usage\nembedding = get_embedding('AWS Lambda is a serverless compute service.')\nprint(f'Embedding dimension: {len(embedding)}')\n```\n\n### Conversation with History\n\n```python\nimport boto3\nimport json\n\nbedrock = boto3.client('bedrock-runtime')\n\nclass Conversation:\n    def __init__(self, system_prompt=None):\n        self.messages = []\n        self.system = system_prompt\n\n    def chat(self, user_message):\n        self.messages.append({\n            'role': 'user',\n            'content': user_message\n        })\n\n        body = {\n            'anthropic_version': 'bedrock-2023-05-31',\n            'max_tokens': 1024,\n            'messages': self.messages\n        }\n\n        if self.system:\n            body['system'] = self.system\n\n        response = bedrock.invoke_model(\n            modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n            contentType='application/json',\n            accept='application/json',\n            body=json.dumps(body)\n        )\n\n        result = json.loads(response['body'].read())\n        assistant_message = result['content'][0]['text']\n\n        self.messages.append({\n            'role': 'assistant',\n            'content': assistant_message\n        })\n\n        return assistant_message\n\n# Usage\nconv = Conversation(system_prompt='You are an AWS solutions architect.')\nprint(conv.chat('What database should I use for a chat application?'))\nprint(conv.chat('What about for time-series data?'))\n```\n\n### List Available Models\n\n```bash\n# List all foundation models\naws bedrock list-foundation-models \\\n  --query 'modelSummaries[*].[modelId,modelName,providerName]' \\\n  --output table\n\n# Filter by provider\naws bedrock list-foundation-models \\\n  --by-provider anthropic \\\n  --query 'modelSummaries[*].modelId'\n\n# Get model details\naws bedrock get-foundation-model \\\n  --model-identifier anthropic.claude-3-sonnet-20240229-v1:0\n```\n\n### Request Model Access\n\n```bash\n# List model access status\naws bedrock list-foundation-model-agreement-offers \\\n  --model-id anthropic.claude-3-sonnet-20240229-v1:0\n```\n\n## CLI Reference\n\n### Bedrock (Control Plane)\n\n| Command | Description |\n|---------|-------------|\n| `aws bedrock list-foundation-models` | List available models |\n| `aws bedrock get-foundation-model` | Get model details |\n| `aws bedrock list-custom-models` | List fine-tuned models |\n| `aws bedrock create-model-customization-job` | Start fine-tuning |\n| `aws bedrock list-provisioned-model-throughputs` | List provisioned capacity |\n\n### Bedrock Runtime (Data Plane)\n\n| Command | Description |\n|---------|-------------|\n| `aws bedrock-runtime invoke-model` | Invoke model synchronously |\n| `aws bedrock-runtime invoke-model-with-response-stream` | Invoke with streaming |\n| `aws bedrock-runtime converse` | Multi-turn conversation API |\n| `aws bedrock-runtime converse-stream` | Streaming conversation |\n\n### Bedrock Agent Runtime\n\n| Command | Description |\n|---------|-------------|\n| `aws bedrock-agent-runtime invoke-agent` | Invoke a Bedrock agent |\n| `aws bedrock-agent-runtime retrieve` | Query knowledge base |\n| `aws bedrock-agent-runtime retrieve-and-generate` | RAG query |\n\n## Best Practices\n\n### Cost Optimization\n\n- **Use appropriate models**: Smaller models for simple tasks\n- **Set max_tokens**: Limit output length when possible\n- **Cache responses**: For repeated identical queries\n- **Batch when possible**: Use batch inference for bulk processing\n- **Monitor usage**: Set up CloudWatch alarms for cost\n\n### Performance\n\n- **Use streaming**: For better user experience with long outputs\n- **Connection pooling**: Reuse boto3 clients\n- **Regional deployment**: Use closest region to reduce latency\n- **Provisioned throughput**: For consistent high-volume workloads\n\n### Security\n\n- **Least privilege IAM**: Only grant needed model access\n- **VPC endpoints**: Keep traffic private\n- **Guardrails**: Implement content filtering\n- **Audit with CloudTrail**: Track model invocations\n\n### IAM Permissions\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"bedrock:InvokeModel\",\n        \"bedrock:InvokeModelWithResponseStream\"\n      ],\n      \"Resource\": [\n        \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\",\n        \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0\"\n      ]\n    }\n  ]\n}\n```\n\n## Troubleshooting\n\n### AccessDeniedException\n\n**Causes:**\n- Model access not enabled in console\n- IAM policy missing `bedrock:InvokeModel`\n- Wrong model ID or region\n\n**Debug:**\n\n```bash\n# Check model access status\naws bedrock list-foundation-models \\\n  --query 'modelSummaries[?modelId==`anthropic.claude-3-sonnet-20240229-v1:0`]'\n\n# Test IAM permissions\naws iam simulate-principal-policy \\\n  --policy-source-arn arn:aws:iam::123456789012:role/my-role \\\n  --action-names bedrock:InvokeModel \\\n  --resource-arns \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\"\n```\n\n### ModelNotReadyException\n\n**Cause:** Model is still being provisioned or temporarily unavailable.\n\n**Solution:** Implement retry with exponential backoff:\n\n```python\nimport time\nfrom botocore.exceptions import ClientError\n\ndef invoke_with_retry(bedrock, body, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return bedrock.invoke_model(\n                modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n                body=json.dumps(body)\n            )\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'ModelNotReadyException':\n                time.sleep(2 ** attempt)\n            else:\n                raise\n    raise Exception('Max retries exceeded')\n```\n\n### ThrottlingException\n\n**Causes:**\n- Exceeded on-demand quota\n- Too many concurrent requests\n\n**Solutions:**\n- Request quota increase\n- Implement exponential backoff\n- Consider provisioned throughput\n\n### ValidationException\n\n**Common issues:**\n- Invalid model ID\n- Malformed request body\n- max_tokens exceeds model limit\n\n**Debug:**\n\n```python\n# Check model-specific requirements\naws bedrock get-foundation-model \\\n  --model-identifier anthropic.claude-3-sonnet-20240229-v1:0 \\\n  --query 'modelDetails.inferenceTypesSupported'\n```\n\n## References\n\n- [Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/)\n- [Bedrock API Reference](https://docs.aws.amazon.com/bedrock/latest/APIReference/)\n- [Bedrock Runtime API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Operations_Amazon_Bedrock_Runtime.html)\n- [Model Parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html)\n- [Bedrock Pricing](https://aws.amazon.com/bedrock/pricing/)\n",
        "skills/bedrock/model-invocation.md": "# Bedrock Model Invocation Patterns\n\nAdvanced patterns for invoking foundation models.\n\n## Model-Specific Invocation\n\n### Claude (Anthropic)\n\n```python\nimport boto3\nimport json\n\nbedrock = boto3.client('bedrock-runtime')\n\ndef invoke_claude(messages, system=None, max_tokens=1024, temperature=1.0):\n    body = {\n        'anthropic_version': 'bedrock-2023-05-31',\n        'max_tokens': max_tokens,\n        'temperature': temperature,\n        'messages': messages\n    }\n\n    if system:\n        body['system'] = system\n\n    response = bedrock.invoke_model(\n        modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps(body)\n    )\n\n    return json.loads(response['body'].read())\n\n# Text generation\nresult = invoke_claude(\n    messages=[{'role': 'user', 'content': 'Explain microservices.'}],\n    system='You are a software architect. Be concise.',\n    temperature=0.7\n)\n\n# With image (Claude 3 vision)\nimport base64\n\nwith open('diagram.png', 'rb') as f:\n    image_data = base64.standard_b64encode(f.read()).decode()\n\nresult = invoke_claude(\n    messages=[{\n        'role': 'user',\n        'content': [\n            {\n                'type': 'image',\n                'source': {\n                    'type': 'base64',\n                    'media_type': 'image/png',\n                    'data': image_data\n                }\n            },\n            {\n                'type': 'text',\n                'text': 'Describe this architecture diagram.'\n            }\n        ]\n    }]\n)\n```\n\n### Titan Text (Amazon)\n\n```python\ndef invoke_titan_text(prompt, max_tokens=512, temperature=0.7):\n    response = bedrock.invoke_model(\n        modelId='amazon.titan-text-express-v1',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'inputText': prompt,\n            'textGenerationConfig': {\n                'maxTokenCount': max_tokens,\n                'temperature': temperature,\n                'topP': 0.9,\n                'stopSequences': []\n            }\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['results'][0]['outputText']\n```\n\n### Titan Embeddings (Amazon)\n\n```python\ndef invoke_titan_embeddings(text, dimensions=1024):\n    response = bedrock.invoke_model(\n        modelId='amazon.titan-embed-text-v2:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'inputText': text,\n            'dimensions': dimensions,\n            'normalize': True\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['embedding']\n\n# Batch embeddings\ndef batch_embeddings(texts, dimensions=1024):\n    embeddings = []\n    for text in texts:\n        embedding = invoke_titan_embeddings(text, dimensions)\n        embeddings.append(embedding)\n    return embeddings\n```\n\n### Llama (Meta)\n\n```python\ndef invoke_llama(prompt, max_tokens=512, temperature=0.7):\n    response = bedrock.invoke_model(\n        modelId='meta.llama3-70b-instruct-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'prompt': prompt,\n            'max_gen_len': max_tokens,\n            'temperature': temperature,\n            'top_p': 0.9\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['generation']\n\n# Format for instruction following\nprompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\nYou are a helpful assistant.<|eot_id|>\n<|start_header_id|>user<|end_header_id|>\nWhat is Amazon S3?<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n```\n\n### Mistral\n\n```python\ndef invoke_mistral(prompt, max_tokens=512, temperature=0.7):\n    response = bedrock.invoke_model(\n        modelId='mistral.mistral-large-2402-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'prompt': f'<s>[INST] {prompt} [/INST]',\n            'max_tokens': max_tokens,\n            'temperature': temperature,\n            'top_p': 0.9\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    return result['outputs'][0]['text']\n```\n\n### Stable Diffusion (Image Generation)\n\n```python\nimport base64\n\ndef generate_image(prompt, negative_prompt='', cfg_scale=7, seed=0):\n    response = bedrock.invoke_model(\n        modelId='stability.stable-diffusion-xl-v1',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'text_prompts': [\n                {'text': prompt, 'weight': 1.0},\n                {'text': negative_prompt, 'weight': -1.0}\n            ],\n            'cfg_scale': cfg_scale,\n            'seed': seed,\n            'steps': 50,\n            'width': 1024,\n            'height': 1024\n        })\n    )\n\n    result = json.loads(response['body'].read())\n    image_data = base64.b64decode(result['artifacts'][0]['base64'])\n\n    with open('output.png', 'wb') as f:\n        f.write(image_data)\n\n    return 'output.png'\n```\n\n## Converse API (Unified)\n\nThe Converse API provides a unified interface across models.\n\n```python\ndef converse(messages, model_id, system=None, max_tokens=1024):\n    params = {\n        'modelId': model_id,\n        'messages': messages,\n        'inferenceConfig': {\n            'maxTokens': max_tokens,\n            'temperature': 0.7\n        }\n    }\n\n    if system:\n        params['system'] = [{'text': system}]\n\n    response = bedrock.converse(**params)\n    return response['output']['message']['content'][0]['text']\n\n# Works with any supported model\nresult = converse(\n    messages=[\n        {'role': 'user', 'content': [{'text': 'What is Lambda?'}]}\n    ],\n    model_id='anthropic.claude-3-sonnet-20240229-v1:0',\n    system='Be concise.'\n)\n```\n\n### Converse with Tool Use\n\n```python\ndef converse_with_tools(messages, tools, model_id):\n    response = bedrock.converse(\n        modelId=model_id,\n        messages=messages,\n        toolConfig={\n            'tools': tools\n        }\n    )\n\n    output = response['output']['message']\n\n    # Check if model wants to use a tool\n    if response['stopReason'] == 'tool_use':\n        tool_use = next(\n            block for block in output['content']\n            if 'toolUse' in block\n        )\n        return {\n            'tool_name': tool_use['toolUse']['name'],\n            'tool_input': tool_use['toolUse']['input'],\n            'tool_use_id': tool_use['toolUse']['toolUseId']\n        }\n\n    return {'text': output['content'][0]['text']}\n\n# Define tools\ntools = [{\n    'toolSpec': {\n        'name': 'get_weather',\n        'description': 'Get current weather for a location',\n        'inputSchema': {\n            'json': {\n                'type': 'object',\n                'properties': {\n                    'location': {\n                        'type': 'string',\n                        'description': 'City name'\n                    }\n                },\n                'required': ['location']\n            }\n        }\n    }\n}]\n\n# Invoke\nresult = converse_with_tools(\n    messages=[\n        {'role': 'user', 'content': [{'text': 'What is the weather in Seattle?'}]}\n    ],\n    tools=tools,\n    model_id='anthropic.claude-3-sonnet-20240229-v1:0'\n)\n```\n\n## RAG with Knowledge Bases\n\n```python\nbedrock_agent = boto3.client('bedrock-agent-runtime')\n\ndef rag_query(query, knowledge_base_id, model_arn):\n    response = bedrock_agent.retrieve_and_generate(\n        input={'text': query},\n        retrieveAndGenerateConfiguration={\n            'type': 'KNOWLEDGE_BASE',\n            'knowledgeBaseConfiguration': {\n                'knowledgeBaseId': knowledge_base_id,\n                'modelArn': model_arn,\n                'retrievalConfiguration': {\n                    'vectorSearchConfiguration': {\n                        'numberOfResults': 5\n                    }\n                }\n            }\n        }\n    )\n\n    return {\n        'answer': response['output']['text'],\n        'citations': response.get('citations', [])\n    }\n\n# Usage\nresult = rag_query(\n    query='How do I configure S3 bucket policies?',\n    knowledge_base_id='KNOWLEDGE_BASE_ID',\n    model_arn='arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0'\n)\n```\n\n### Retrieve Only (No Generation)\n\n```python\ndef retrieve_context(query, knowledge_base_id, num_results=5):\n    response = bedrock_agent.retrieve(\n        knowledgeBaseId=knowledge_base_id,\n        retrievalQuery={'text': query},\n        retrievalConfiguration={\n            'vectorSearchConfiguration': {\n                'numberOfResults': num_results\n            }\n        }\n    )\n\n    return [\n        {\n            'text': result['content']['text'],\n            'score': result['score'],\n            'source': result['location']\n        }\n        for result in response['retrievalResults']\n    ]\n```\n\n## Guardrails\n\n```python\ndef invoke_with_guardrails(prompt, guardrail_id, guardrail_version):\n    response = bedrock.invoke_model(\n        modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n        contentType='application/json',\n        accept='application/json',\n        body=json.dumps({\n            'anthropic_version': 'bedrock-2023-05-31',\n            'max_tokens': 1024,\n            'messages': [{'role': 'user', 'content': prompt}]\n        }),\n        guardrailIdentifier=guardrail_id,\n        guardrailVersion=guardrail_version\n    )\n\n    result = json.loads(response['body'].read())\n\n    # Check if guardrail intervened\n    if 'amazon-bedrock-guardrailAction' in response['ResponseMetadata']['HTTPHeaders']:\n        return {\n            'blocked': True,\n            'reason': 'Content policy violation'\n        }\n\n    return {\n        'blocked': False,\n        'text': result['content'][0]['text']\n    }\n```\n\n## Batch Inference\n\n```python\nimport boto3\n\nbedrock = boto3.client('bedrock')\n\ndef create_batch_job(input_s3_uri, output_s3_uri, model_id, role_arn):\n    response = bedrock.create_model_invocation_job(\n        jobName=f'batch-job-{int(time.time())}',\n        modelId=model_id,\n        roleArn=role_arn,\n        inputDataConfig={\n            's3InputDataConfig': {\n                's3Uri': input_s3_uri\n            }\n        },\n        outputDataConfig={\n            's3OutputDataConfig': {\n                's3Uri': output_s3_uri\n            }\n        }\n    )\n\n    return response['jobArn']\n\n# Input format (JSONL file in S3)\n# {\"recordId\": \"1\", \"modelInput\": {\"anthropic_version\": \"...\", \"messages\": [...]}}\n# {\"recordId\": \"2\", \"modelInput\": {\"anthropic_version\": \"...\", \"messages\": [...]}}\n```\n\n## Error Handling\n\n```python\nfrom botocore.exceptions import ClientError\nimport time\n\nclass BedrockInvoker:\n    def __init__(self, model_id):\n        self.bedrock = boto3.client('bedrock-runtime')\n        self.model_id = model_id\n\n    def invoke(self, body, max_retries=3):\n        last_error = None\n\n        for attempt in range(max_retries):\n            try:\n                response = self.bedrock.invoke_model(\n                    modelId=self.model_id,\n                    contentType='application/json',\n                    accept='application/json',\n                    body=json.dumps(body)\n                )\n                return json.loads(response['body'].read())\n\n            except ClientError as e:\n                error_code = e.response['Error']['Code']\n                last_error = e\n\n                if error_code == 'ThrottlingException':\n                    wait_time = (2 ** attempt) + random.random()\n                    time.sleep(wait_time)\n                elif error_code == 'ModelNotReadyException':\n                    time.sleep(5)\n                elif error_code == 'ValidationException':\n                    raise  # Don't retry validation errors\n                else:\n                    raise\n\n        raise last_error\n```\n\n## Provisioned Throughput\n\n```bash\n# Create provisioned throughput\naws bedrock create-provisioned-model-throughput \\\n  --model-id anthropic.claude-3-sonnet-20240229-v1:0 \\\n  --provisioned-model-name my-claude-capacity \\\n  --model-units 1\n\n# Use provisioned model\naws bedrock-runtime invoke-model \\\n  --model-id arn:aws:bedrock:us-east-1:123456789012:provisioned-model/my-claude-capacity \\\n  --body '...' \\\n  response.json\n```\n\n```python\n# Invoke provisioned model\nresponse = bedrock.invoke_model(\n    modelId='arn:aws:bedrock:us-east-1:123456789012:provisioned-model/my-claude-capacity',\n    contentType='application/json',\n    accept='application/json',\n    body=json.dumps(body)\n)\n```\n\n## VPC Endpoint\n\n```yaml\n# CloudFormation for private Bedrock access\nResources:\n  BedrockEndpoint:\n    Type: AWS::EC2::VPCEndpoint\n    Properties:\n      VpcId: !Ref VPC\n      ServiceName: !Sub com.amazonaws.${AWS::Region}.bedrock-runtime\n      VpcEndpointType: Interface\n      SubnetIds:\n        - !Ref PrivateSubnet1\n        - !Ref PrivateSubnet2\n      SecurityGroupIds:\n        - !Ref BedrockSecurityGroup\n      PrivateDnsEnabled: true\n\n  BedrockSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      VpcId: !Ref VPC\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 443\n          ToPort: 443\n          SourceSecurityGroupId: !Ref AppSecurityGroup\n```\n",
        "skills/cloudformation/SKILL.md": "---\nname: cloudformation\ndescription: AWS CloudFormation infrastructure as code for stack management. Use when writing templates, deploying stacks, managing drift, troubleshooting deployments, or organizing infrastructure with nested stacks.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/\n---\n\n# AWS CloudFormation\n\nAWS CloudFormation provisions and manages AWS resources using templates. Define infrastructure as code, version control it, and deploy consistently across environments.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Templates\n\nJSON or YAML files defining AWS resources. Key sections:\n- **Parameters**: Input values\n- **Mappings**: Static lookup tables\n- **Conditions**: Conditional resource creation\n- **Resources**: AWS resources (required)\n- **Outputs**: Return values\n\n### Stacks\n\nCollection of resources managed as a single unit. Created from templates.\n\n### Change Sets\n\nPreview changes before executing updates.\n\n### Stack Sets\n\nDeploy stacks across multiple accounts and regions.\n\n## Common Patterns\n\n### Basic Template Structure\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: My infrastructure template\n\nParameters:\n  Environment:\n    Type: String\n    AllowedValues: [dev, staging, prod]\n    Default: dev\n\nMappings:\n  EnvironmentConfig:\n    dev:\n      InstanceType: t3.micro\n    prod:\n      InstanceType: t3.large\n\nConditions:\n  IsProd: !Equals [!Ref Environment, prod]\n\nResources:\n  MyBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: !Sub 'my-app-${Environment}-${AWS::AccountId}'\n      VersioningConfiguration:\n        Status: !If [IsProd, Enabled, Suspended]\n\nOutputs:\n  BucketName:\n    Description: S3 bucket name\n    Value: !Ref MyBucket\n    Export:\n      Name: !Sub '${AWS::StackName}-BucketName'\n```\n\n### Deploy a Stack\n\n**AWS CLI:**\n\n```bash\n# Create stack\naws cloudformation create-stack \\\n  --stack-name my-stack \\\n  --template-body file://template.yaml \\\n  --parameters ParameterKey=Environment,ParameterValue=prod \\\n  --capabilities CAPABILITY_IAM\n\n# Wait for completion\naws cloudformation wait stack-create-complete --stack-name my-stack\n\n# Update stack\naws cloudformation update-stack \\\n  --stack-name my-stack \\\n  --template-body file://template.yaml \\\n  --parameters ParameterKey=Environment,ParameterValue=prod\n\n# Delete stack\naws cloudformation delete-stack --stack-name my-stack\n```\n\n### Use Change Sets\n\n```bash\n# Create change set\naws cloudformation create-change-set \\\n  --stack-name my-stack \\\n  --change-set-name my-changes \\\n  --template-body file://template.yaml \\\n  --parameters ParameterKey=Environment,ParameterValue=prod\n\n# Describe changes\naws cloudformation describe-change-set \\\n  --stack-name my-stack \\\n  --change-set-name my-changes\n\n# Execute change set\naws cloudformation execute-change-set \\\n  --stack-name my-stack \\\n  --change-set-name my-changes\n```\n\n### Lambda Function\n\n```yaml\nResources:\n  LambdaFunction:\n    Type: AWS::Lambda::Function\n    Properties:\n      FunctionName: !Sub '${AWS::StackName}-function'\n      Runtime: python3.12\n      Handler: index.handler\n      Role: !GetAtt LambdaRole.Arn\n      Code:\n        ZipFile: |\n          def handler(event, context):\n              return {'statusCode': 200, 'body': 'Hello'}\n      Environment:\n        Variables:\n          ENVIRONMENT: !Ref Environment\n\n  LambdaRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: '2012-10-17'\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action: sts:AssumeRole\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n```\n\n### VPC with Subnets\n\n```yaml\nResources:\n  VPC:\n    Type: AWS::EC2::VPC\n    Properties:\n      CidrBlock: 10.0.0.0/16\n      EnableDnsHostnames: true\n      Tags:\n        - Key: Name\n          Value: !Sub '${AWS::StackName}-vpc'\n\n  PublicSubnet1:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref VPC\n      AvailabilityZone: !Select [0, !GetAZs '']\n      CidrBlock: 10.0.1.0/24\n      MapPublicIpOnLaunch: true\n\n  PrivateSubnet1:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref VPC\n      AvailabilityZone: !Select [0, !GetAZs '']\n      CidrBlock: 10.0.10.0/24\n\n  InternetGateway:\n    Type: AWS::EC2::InternetGateway\n\n  AttachGateway:\n    Type: AWS::EC2::VPCGatewayAttachment\n    Properties:\n      VpcId: !Ref VPC\n      InternetGatewayId: !Ref InternetGateway\n\n  PublicRouteTable:\n    Type: AWS::EC2::RouteTable\n    Properties:\n      VpcId: !Ref VPC\n\n  PublicRoute:\n    Type: AWS::EC2::Route\n    DependsOn: AttachGateway\n    Properties:\n      RouteTableId: !Ref PublicRouteTable\n      DestinationCidrBlock: 0.0.0.0/0\n      GatewayId: !Ref InternetGateway\n\n  PublicSubnet1RouteTableAssociation:\n    Type: AWS::EC2::SubnetRouteTableAssociation\n    Properties:\n      SubnetId: !Ref PublicSubnet1\n      RouteTableId: !Ref PublicRouteTable\n```\n\n### DynamoDB Table\n\n```yaml\nResources:\n  OrdersTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: !Sub '${AWS::StackName}-orders'\n      AttributeDefinitions:\n        - AttributeName: PK\n          AttributeType: S\n        - AttributeName: SK\n          AttributeType: S\n        - AttributeName: GSI1PK\n          AttributeType: S\n        - AttributeName: GSI1SK\n          AttributeType: S\n      KeySchema:\n        - AttributeName: PK\n          KeyType: HASH\n        - AttributeName: SK\n          KeyType: RANGE\n      GlobalSecondaryIndexes:\n        - IndexName: GSI1\n          KeySchema:\n            - AttributeName: GSI1PK\n              KeyType: HASH\n            - AttributeName: GSI1SK\n              KeyType: RANGE\n          Projection:\n            ProjectionType: ALL\n      BillingMode: PAY_PER_REQUEST\n      PointInTimeRecoverySpecification:\n        PointInTimeRecoveryEnabled: true\n```\n\n## CLI Reference\n\n### Stack Operations\n\n| Command | Description |\n|---------|-------------|\n| `aws cloudformation create-stack` | Create stack |\n| `aws cloudformation update-stack` | Update stack |\n| `aws cloudformation delete-stack` | Delete stack |\n| `aws cloudformation describe-stacks` | Get stack info |\n| `aws cloudformation list-stacks` | List stacks |\n| `aws cloudformation describe-stack-events` | Get events |\n| `aws cloudformation describe-stack-resources` | Get resources |\n\n### Change Sets\n\n| Command | Description |\n|---------|-------------|\n| `aws cloudformation create-change-set` | Create change set |\n| `aws cloudformation describe-change-set` | View changes |\n| `aws cloudformation execute-change-set` | Apply changes |\n| `aws cloudformation delete-change-set` | Delete change set |\n\n### Template\n\n| Command | Description |\n|---------|-------------|\n| `aws cloudformation validate-template` | Validate template |\n| `aws cloudformation get-template` | Get stack template |\n| `aws cloudformation get-template-summary` | Get template info |\n\n## Best Practices\n\n### Template Design\n\n- **Use parameters** for environment-specific values\n- **Use mappings** for static lookup tables\n- **Use conditions** for optional resources\n- **Export outputs** for cross-stack references\n- **Add descriptions** to parameters and outputs\n\n### Security\n\n- **Use IAM roles** instead of access keys\n- **Enable termination protection** for production\n- **Use stack policies** to protect resources\n- **Never hardcode secrets** â€” use Secrets Manager\n\n```bash\n# Enable termination protection\naws cloudformation update-termination-protection \\\n  --stack-name my-stack \\\n  --enable-termination-protection\n```\n\n### Organization\n\n- **Use nested stacks** for complex infrastructure\n- **Create reusable modules**\n- **Version control templates**\n- **Use consistent naming conventions**\n\n### Reliability\n\n- **Use DependsOn** for explicit dependencies\n- **Configure creation policies** for instances\n- **Use update policies** for Auto Scaling groups\n- **Implement rollback triggers**\n\n## Troubleshooting\n\n### Stack Creation Failed\n\n```bash\n# Get failure reason\naws cloudformation describe-stack-events \\\n  --stack-name my-stack \\\n  --query 'StackEvents[?ResourceStatus==`CREATE_FAILED`]'\n\n# Common causes:\n# - IAM permissions\n# - Resource limits\n# - Invalid property values\n# - Dependency failures\n```\n\n### Stack Stuck in DELETE_FAILED\n\n```bash\n# Identify resources that couldn't be deleted\naws cloudformation describe-stack-resources \\\n  --stack-name my-stack \\\n  --query 'StackResources[?ResourceStatus==`DELETE_FAILED`]'\n\n# Retry with resources to skip\naws cloudformation delete-stack \\\n  --stack-name my-stack \\\n  --retain-resources ResourceLogicalId1 ResourceLogicalId2\n```\n\n### Drift Detection\n\n```bash\n# Detect drift\naws cloudformation detect-stack-drift --stack-name my-stack\n\n# Check drift status\naws cloudformation describe-stack-drift-detection-status \\\n  --stack-drift-detection-id abc123\n\n# View drifted resources\naws cloudformation describe-stack-resource-drifts \\\n  --stack-name my-stack\n```\n\n### Rollback Failed\n\n```bash\n# Continue update rollback\naws cloudformation continue-update-rollback \\\n  --stack-name my-stack \\\n  --resources-to-skip ResourceLogicalId1\n```\n\n## References\n\n- [CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/)\n- [CloudFormation API Reference](https://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/)\n- [CloudFormation CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/cloudformation/)\n- [Resource and Property Reference](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html)\n",
        "skills/cloudformation/template-patterns.md": "# CloudFormation Template Patterns\n\nAdvanced template patterns and techniques.\n\n## Intrinsic Functions\n\n### Reference Functions\n\n```yaml\n# Reference a resource or parameter\n!Ref MyResource\n\n# Get attribute from resource\n!GetAtt MyLambda.Arn\n!GetAtt MyBucket.DomainName\n!GetAtt MyBucket.RegionalDomainName\n\n# Import from another stack\n!ImportValue other-stack-BucketName\n```\n\n### String Functions\n\n```yaml\n# Substitution\n!Sub 'arn:aws:s3:::${BucketName}/*'\n!Sub\n  - 'arn:aws:s3:::${Bucket}/*'\n  - Bucket: !Ref MyBucket\n\n# Join\n!Join\n  - ','\n  - - !Ref Subnet1\n    - !Ref Subnet2\n\n# Split\n!Split [',', !Ref SubnetList]\n\n# Select\n!Select [0, !GetAZs '']\n!Select [1, !Split [',', !Ref SubnetList]]\n```\n\n### Conditional Functions\n\n```yaml\nConditions:\n  IsProd: !Equals [!Ref Environment, prod]\n  HasBucket: !Not [!Equals [!Ref BucketName, '']]\n  IsProdAndHasBucket: !And [!Condition IsProd, !Condition HasBucket]\n  IsDevOrStaging: !Or\n    - !Equals [!Ref Environment, dev]\n    - !Equals [!Ref Environment, staging]\n\nResources:\n  MyResource:\n    Type: AWS::S3::Bucket\n    Condition: IsProd\n    Properties:\n      BucketName: !If\n        - IsProd\n        - !Sub 'prod-${AWS::StackName}'\n        - !Sub 'dev-${AWS::StackName}'\n```\n\n### Transform Functions\n\n```yaml\n# Include from S3\n!Transform\n  Name: AWS::Include\n  Parameters:\n    Location: s3://my-bucket/snippet.yaml\n\n# Use macros\nTransform: AWS::Serverless-2016-10-31\n```\n\n## Parameters\n\n### Comprehensive Parameter Types\n\n```yaml\nParameters:\n  # String with validation\n  ProjectName:\n    Type: String\n    MinLength: 3\n    MaxLength: 20\n    AllowedPattern: ^[a-z][a-z0-9-]*$\n    ConstraintDescription: Must start with letter, lowercase alphanumeric and hyphens\n\n  # Constrained values\n  Environment:\n    Type: String\n    AllowedValues: [dev, staging, prod]\n    Default: dev\n\n  # Number with range\n  InstanceCount:\n    Type: Number\n    MinValue: 1\n    MaxValue: 10\n    Default: 2\n\n  # AWS-specific types\n  VpcId:\n    Type: AWS::EC2::VPC::Id\n  SubnetIds:\n    Type: List<AWS::EC2::Subnet::Id>\n  KeyPair:\n    Type: AWS::EC2::KeyPair::KeyName\n  AMI:\n    Type: AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>\n    Default: /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2\n\n  # Secrets (NoEcho)\n  DatabasePassword:\n    Type: String\n    NoEcho: true\n    MinLength: 8\n```\n\n## Mappings\n\n```yaml\nMappings:\n  RegionAMI:\n    us-east-1:\n      HVM64: ami-0123456789abcdef0\n      HVM32: ami-0987654321fedcba0\n    us-west-2:\n      HVM64: ami-abcdef01234567890\n      HVM32: ami-fedcba0987654321\n\n  EnvironmentConfig:\n    dev:\n      InstanceType: t3.micro\n      MinSize: 1\n      MaxSize: 2\n    prod:\n      InstanceType: t3.large\n      MinSize: 2\n      MaxSize: 10\n\nResources:\n  Instance:\n    Type: AWS::EC2::Instance\n    Properties:\n      ImageId: !FindInMap [RegionAMI, !Ref 'AWS::Region', HVM64]\n      InstanceType: !FindInMap [EnvironmentConfig, !Ref Environment, InstanceType]\n```\n\n## Cross-Stack References\n\n### Stack A (Exporter)\n\n```yaml\nResources:\n  VPC:\n    Type: AWS::EC2::VPC\n    Properties:\n      CidrBlock: 10.0.0.0/16\n\nOutputs:\n  VpcId:\n    Value: !Ref VPC\n    Export:\n      Name: !Sub '${AWS::StackName}-VpcId'\n\n  VpcCidr:\n    Value: !GetAtt VPC.CidrBlock\n    Export:\n      Name: !Sub '${AWS::StackName}-VpcCidr'\n```\n\n### Stack B (Importer)\n\n```yaml\nParameters:\n  NetworkStackName:\n    Type: String\n    Default: network-stack\n\nResources:\n  SecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      VpcId: !ImportValue\n        Fn::Sub: '${NetworkStackName}-VpcId'\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 443\n          ToPort: 443\n          CidrIp: !ImportValue\n            Fn::Sub: '${NetworkStackName}-VpcCidr'\n```\n\n## Nested Stacks\n\n### Parent Stack\n\n```yaml\nResources:\n  NetworkStack:\n    Type: AWS::CloudFormation::Stack\n    Properties:\n      TemplateURL: https://s3.amazonaws.com/my-bucket/network.yaml\n      Parameters:\n        Environment: !Ref Environment\n\n  ComputeStack:\n    Type: AWS::CloudFormation::Stack\n    DependsOn: NetworkStack\n    Properties:\n      TemplateURL: https://s3.amazonaws.com/my-bucket/compute.yaml\n      Parameters:\n        VpcId: !GetAtt NetworkStack.Outputs.VpcId\n        SubnetIds: !GetAtt NetworkStack.Outputs.SubnetIds\n```\n\n## Resource Policies\n\n### Creation Policy\n\n```yaml\nResources:\n  AutoScalingGroup:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    CreationPolicy:\n      ResourceSignal:\n        Count: !Ref DesiredCapacity\n        Timeout: PT15M\n    Properties:\n      # ...\n\n  LaunchTemplate:\n    Type: AWS::EC2::LaunchTemplate\n    Properties:\n      LaunchTemplateData:\n        UserData:\n          Fn::Base64: !Sub |\n            #!/bin/bash\n            # ... setup ...\n            /opt/aws/bin/cfn-signal -e $? \\\n              --stack ${AWS::StackName} \\\n              --resource AutoScalingGroup \\\n              --region ${AWS::Region}\n```\n\n### Update Policy\n\n```yaml\nResources:\n  AutoScalingGroup:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    UpdatePolicy:\n      AutoScalingRollingUpdate:\n        MinInstancesInService: 1\n        MaxBatchSize: 1\n        PauseTime: PT10M\n        WaitOnResourceSignals: true\n      AutoScalingScheduledAction:\n        IgnoreUnmodifiedGroupSizeProperties: true\n```\n\n### Deletion Policy\n\n```yaml\nResources:\n  Database:\n    Type: AWS::RDS::DBInstance\n    DeletionPolicy: Snapshot\n    UpdateReplacePolicy: Snapshot\n    Properties:\n      # ...\n\n  LogBucket:\n    Type: AWS::S3::Bucket\n    DeletionPolicy: Retain\n    Properties:\n      # ...\n```\n\n## Custom Resources\n\n### Lambda-Backed Custom Resource\n\n```yaml\nResources:\n  CustomResourceLambda:\n    Type: AWS::Lambda::Function\n    Properties:\n      Runtime: python3.12\n      Handler: index.handler\n      Role: !GetAtt CustomResourceRole.Arn\n      Timeout: 300\n      Code:\n        ZipFile: |\n          import cfnresponse\n          import boto3\n\n          def handler(event, context):\n              try:\n                  if event['RequestType'] == 'Create':\n                      # Create logic\n                      response_data = {'Result': 'Created'}\n                  elif event['RequestType'] == 'Update':\n                      # Update logic\n                      response_data = {'Result': 'Updated'}\n                  elif event['RequestType'] == 'Delete':\n                      # Delete logic\n                      response_data = {'Result': 'Deleted'}\n\n                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)\n              except Exception as e:\n                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e)})\n\n  MyCustomResource:\n    Type: Custom::MyResource\n    Properties:\n      ServiceToken: !GetAtt CustomResourceLambda.Arn\n      Parameter1: !Ref SomeParameter\n```\n\n## Stack Policies\n\n### Prevent Updates to Critical Resources\n\n```json\n{\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"Update:*\",\n      \"Principal\": \"*\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"Update:Replace\",\n      \"Principal\": \"*\",\n      \"Resource\": \"LogicalResourceId/ProductionDatabase\"\n    },\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"Update:Delete\",\n      \"Principal\": \"*\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"ResourceType\": [\"AWS::RDS::DBInstance\"]\n        }\n      }\n    }\n  ]\n}\n```\n\nApply stack policy:\n\n```bash\naws cloudformation set-stack-policy \\\n  --stack-name my-stack \\\n  --stack-policy-body file://stack-policy.json\n```\n\n## Rollback Configuration\n\n```bash\naws cloudformation create-stack \\\n  --stack-name my-stack \\\n  --template-body file://template.yaml \\\n  --rollback-configuration '{\n    \"RollbackTriggers\": [\n      {\n        \"Arn\": \"arn:aws:cloudwatch:us-east-1:123456789012:alarm:HighErrorRate\",\n        \"Type\": \"AWS::CloudWatch::Alarm\"\n      }\n    ],\n    \"MonitoringTimeInMinutes\": 10\n  }'\n```\n\n## Transform Macros\n\n### Using AWS::Serverless\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nGlobals:\n  Function:\n    Runtime: python3.12\n    Timeout: 30\n\nResources:\n  MyFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.handler\n      CodeUri: ./src\n      Events:\n        Api:\n          Type: Api\n          Properties:\n            Path: /items\n            Method: GET\n```\n\n### Using AWS::LanguageExtensions\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::LanguageExtensions\n\nResources:\n  # Use Fn::ForEach\n  Fn::ForEach::Buckets:\n    - BucketName\n    - [logs, data, backup]\n    - '${BucketName}Bucket':\n        Type: AWS::S3::Bucket\n        Properties:\n          BucketName: !Sub 'my-app-${BucketName}-${AWS::AccountId}'\n```\n",
        "skills/cloudwatch/SKILL.md": "---\nname: cloudwatch\ndescription: AWS CloudWatch monitoring for logs, metrics, alarms, and dashboards. Use when setting up monitoring, creating alarms, querying logs with Insights, configuring metric filters, building dashboards, or troubleshooting application issues.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/\n---\n\n# AWS CloudWatch\n\nAmazon CloudWatch provides monitoring and observability for AWS resources and applications. It collects metrics, logs, and events, enabling you to monitor, troubleshoot, and optimize your AWS environment.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Metrics\n\nTime-ordered data points published to CloudWatch. Key components:\n- **Namespace**: Container for metrics (e.g., `AWS/Lambda`)\n- **Metric name**: Name of the measurement (e.g., `Invocations`)\n- **Dimensions**: Name-value pairs for filtering (e.g., `FunctionName=MyFunc`)\n- **Statistics**: Aggregations (Sum, Average, Min, Max, SampleCount, pN)\n\n### Logs\n\nLog data from AWS services and applications:\n- **Log groups**: Collections of log streams\n- **Log streams**: Sequences of log events from same source\n- **Log events**: Individual log entries with timestamp and message\n\n### Alarms\n\nAutomated actions based on metric thresholds:\n- **States**: OK, ALARM, INSUFFICIENT_DATA\n- **Actions**: SNS notifications, Auto Scaling, EC2 actions\n\n## Common Patterns\n\n### Create a Metric Alarm\n\n**AWS CLI:**\n\n```bash\n# CPU utilization alarm for EC2\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighCPU-i-1234567890abcdef0\" \\\n  --metric-name CPUUtilization \\\n  --namespace AWS/EC2 \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=InstanceId,Value=i-1234567890abcdef0 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts \\\n  --ok-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n**boto3:**\n\n```python\nimport boto3\n\ncloudwatch = boto3.client('cloudwatch')\n\ncloudwatch.put_metric_alarm(\n    AlarmName='HighCPU-i-1234567890abcdef0',\n    MetricName='CPUUtilization',\n    Namespace='AWS/EC2',\n    Statistic='Average',\n    Period=300,\n    Threshold=80.0,\n    ComparisonOperator='GreaterThanThreshold',\n    EvaluationPeriods=2,\n    Dimensions=[\n        {'Name': 'InstanceId', 'Value': 'i-1234567890abcdef0'}\n    ],\n    AlarmActions=['arn:aws:sns:us-east-1:123456789012:alerts'],\n    OKActions=['arn:aws:sns:us-east-1:123456789012:alerts']\n)\n```\n\n### Lambda Error Rate Alarm\n\n```bash\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"LambdaErrorRate-MyFunction\" \\\n  --metrics '[\n    {\n      \"Id\": \"errors\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/Lambda\",\n          \"MetricName\": \"Errors\",\n          \"Dimensions\": [{\"Name\": \"FunctionName\", \"Value\": \"MyFunction\"}]\n        },\n        \"Period\": 60,\n        \"Stat\": \"Sum\"\n      },\n      \"ReturnData\": false\n    },\n    {\n      \"Id\": \"invocations\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/Lambda\",\n          \"MetricName\": \"Invocations\",\n          \"Dimensions\": [{\"Name\": \"FunctionName\", \"Value\": \"MyFunction\"}]\n        },\n        \"Period\": 60,\n        \"Stat\": \"Sum\"\n      },\n      \"ReturnData\": false\n    },\n    {\n      \"Id\": \"errorRate\",\n      \"Expression\": \"errors/invocations*100\",\n      \"Label\": \"Error Rate\",\n      \"ReturnData\": true\n    }\n  ]' \\\n  --threshold 5 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 3 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Query Logs with Insights\n\n```bash\n# Find errors in Lambda logs\naws logs start-query \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --start-time $(date -d '1 hour ago' +%s) \\\n  --end-time $(date +%s) \\\n  --query-string '\n    fields @timestamp, @message\n    | filter @message like /ERROR/\n    | sort @timestamp desc\n    | limit 50\n  '\n\n# Get query results\naws logs get-query-results --query-id <query-id>\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport time\n\nlogs = boto3.client('logs')\n\n# Start query\nresponse = logs.start_query(\n    logGroupName='/aws/lambda/MyFunction',\n    startTime=int(time.time()) - 3600,\n    endTime=int(time.time()),\n    queryString='''\n        fields @timestamp, @message\n        | filter @message like /ERROR/\n        | sort @timestamp desc\n        | limit 50\n    '''\n)\n\nquery_id = response['queryId']\n\n# Wait for results\nwhile True:\n    result = logs.get_query_results(queryId=query_id)\n    if result['status'] == 'Complete':\n        break\n    time.sleep(1)\n\nfor row in result['results']:\n    print(row)\n```\n\n### Create Metric Filter\n\nExtract metrics from log patterns:\n\n```bash\n# Create metric filter for error count\naws logs put-metric-filter \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --filter-name ErrorCount \\\n  --filter-pattern \"ERROR\" \\\n  --metric-transformations \\\n    metricName=ErrorCount,metricNamespace=MyApp,metricValue=1,defaultValue=0\n```\n\n### Publish Custom Metrics\n\n```python\nimport boto3\n\ncloudwatch = boto3.client('cloudwatch')\n\ncloudwatch.put_metric_data(\n    Namespace='MyApp',\n    MetricData=[\n        {\n            'MetricName': 'OrdersProcessed',\n            'Value': 1,\n            'Unit': 'Count',\n            'Dimensions': [\n                {'Name': 'Environment', 'Value': 'Production'},\n                {'Name': 'OrderType', 'Value': 'Standard'}\n            ]\n        }\n    ]\n)\n```\n\n### Create Dashboard\n\n```bash\ncat > dashboard.json << 'EOF'\n{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"x\": 0, \"y\": 0, \"width\": 12, \"height\": 6,\n      \"properties\": {\n        \"title\": \"Lambda Invocations\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Invocations\", \"FunctionName\", \"MyFunction\"]\n        ],\n        \"period\": 60,\n        \"stat\": \"Sum\",\n        \"region\": \"us-east-1\"\n      }\n    },\n    {\n      \"type\": \"log\",\n      \"x\": 12, \"y\": 0, \"width\": 12, \"height\": 6,\n      \"properties\": {\n        \"title\": \"Recent Errors\",\n        \"query\": \"SOURCE '/aws/lambda/MyFunction' | filter @message like /ERROR/ | limit 20\",\n        \"region\": \"us-east-1\"\n      }\n    }\n  ]\n}\nEOF\n\naws cloudwatch put-dashboard \\\n  --dashboard-name MyAppDashboard \\\n  --dashboard-body file://dashboard.json\n```\n\n## CLI Reference\n\n### Metrics Commands\n\n| Command | Description |\n|---------|-------------|\n| `aws cloudwatch put-metric-data` | Publish custom metrics |\n| `aws cloudwatch get-metric-data` | Retrieve metric values |\n| `aws cloudwatch get-metric-statistics` | Get aggregated statistics |\n| `aws cloudwatch list-metrics` | List available metrics |\n\n### Alarms Commands\n\n| Command | Description |\n|---------|-------------|\n| `aws cloudwatch put-metric-alarm` | Create or update alarm |\n| `aws cloudwatch describe-alarms` | List alarms |\n| `aws cloudwatch set-alarm-state` | Manually set alarm state |\n| `aws cloudwatch delete-alarms` | Delete alarms |\n\n### Logs Commands\n\n| Command | Description |\n|---------|-------------|\n| `aws logs create-log-group` | Create log group |\n| `aws logs put-log-events` | Write log events |\n| `aws logs filter-log-events` | Search log events |\n| `aws logs start-query` | Start Insights query |\n| `aws logs put-metric-filter` | Create metric filter |\n| `aws logs put-retention-policy` | Set log retention |\n\n## Best Practices\n\n### Metrics\n\n- **Use dimensions wisely** â€” too many creates metric explosion\n- **Aggregate before publishing** â€” batch custom metrics\n- **Use high-resolution metrics** (1-second) only when needed\n- **Set meaningful units** for custom metrics\n\n### Alarms\n\n- **Use composite alarms** for complex conditions\n- **Set appropriate evaluation periods** to avoid flapping\n- **Include OK actions** to track recovery\n- **Use anomaly detection** for dynamic thresholds\n\n### Logs\n\n- **Set retention policies** â€” don't keep logs forever\n- **Use structured logging** (JSON) for better querying\n- **Create metric filters** for key events\n- **Use Contributor Insights** for top-N analysis\n\n### Cost Optimization\n\n- **Delete unused dashboards**\n- **Reduce log retention** for non-critical logs\n- **Avoid high-resolution metrics** unless necessary\n- **Use log subscription filters** instead of polling\n\n## Troubleshooting\n\n### Missing Metrics\n\n**Causes:**\n- Service not publishing yet (wait 1-5 minutes)\n- Wrong namespace/dimensions\n- Detailed monitoring not enabled (EC2)\n\n**Debug:**\n\n```bash\n# List metrics for a namespace\naws cloudwatch list-metrics \\\n  --namespace AWS/Lambda \\\n  --dimensions Name=FunctionName,Value=MyFunction\n```\n\n### Alarm Stuck in INSUFFICIENT_DATA\n\n**Causes:**\n- Metric not being published\n- Dimensions mismatch\n- Evaluation period too short\n\n**Debug:**\n\n```bash\n# Check if metric has data\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Invocations \\\n  --dimensions Name=FunctionName,Value=MyFunction \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\n```\n\n### Log Events Not Appearing\n\n**Causes:**\n- IAM permissions missing\n- CloudWatch Logs agent not running\n- Log group doesn't exist\n\n**Debug:**\n\n```bash\n# Check log streams\naws logs describe-log-streams \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --order-by LastEventTime \\\n  --descending \\\n  --limit 5\n```\n\n### High CloudWatch Costs\n\n**Check usage:**\n\n```bash\n# Get PutLogEvents usage\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Logs \\\n  --metric-name IncomingBytes \\\n  --dimensions Name=LogGroupName,Value=/aws/lambda/MyFunction \\\n  --start-time $(date -d '7 days ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 86400 \\\n  --statistics Sum\n```\n\n## References\n\n- [CloudWatch User Guide](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/)\n- [CloudWatch Logs User Guide](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/)\n- [CloudWatch API Reference](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/)\n- [CloudWatch CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/cloudwatch/)\n- [Logs Insights Query Syntax](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html)\n- [boto3 CloudWatch](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/cloudwatch.html)\n",
        "skills/cloudwatch/alarms-metrics.md": "# CloudWatch Alarms and Metrics\n\nDetailed patterns for CloudWatch alarms and custom metrics.\n\n## Alarm Types\n\n### Standard Metric Alarm\n\nTriggers based on a single metric threshold:\n\n```bash\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighCPUUtilization\" \\\n  --metric-name CPUUtilization \\\n  --namespace AWS/EC2 \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=InstanceId,Value=i-1234567890abcdef0 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Metric Math Alarm\n\nCombines multiple metrics with expressions:\n\n```bash\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighErrorRate\" \\\n  --metrics '[\n    {\n      \"Id\": \"e1\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/ApplicationELB\",\n          \"MetricName\": \"HTTPCode_ELB_5XX_Count\",\n          \"Dimensions\": [{\"Name\": \"LoadBalancer\", \"Value\": \"app/my-lb/1234567890123456\"}]\n        },\n        \"Period\": 60,\n        \"Stat\": \"Sum\"\n      },\n      \"ReturnData\": false\n    },\n    {\n      \"Id\": \"e2\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/ApplicationELB\",\n          \"MetricName\": \"RequestCount\",\n          \"Dimensions\": [{\"Name\": \"LoadBalancer\", \"Value\": \"app/my-lb/1234567890123456\"}]\n        },\n        \"Period\": 60,\n        \"Stat\": \"Sum\"\n      },\n      \"ReturnData\": false\n    },\n    {\n      \"Id\": \"e3\",\n      \"Expression\": \"IF(e2>0, e1/e2*100, 0)\",\n      \"Label\": \"Error Rate %\",\n      \"ReturnData\": true\n    }\n  ]' \\\n  --threshold 5 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 3 \\\n  --datapoints-to-alarm 2 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Anomaly Detection Alarm\n\nUses machine learning to detect anomalies:\n\n```bash\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"AnomalousLatency\" \\\n  --metrics '[\n    {\n      \"Id\": \"m1\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/Lambda\",\n          \"MetricName\": \"Duration\",\n          \"Dimensions\": [{\"Name\": \"FunctionName\", \"Value\": \"MyFunction\"}]\n        },\n        \"Period\": 60,\n        \"Stat\": \"Average\"\n      },\n      \"ReturnData\": true\n    },\n    {\n      \"Id\": \"ad1\",\n      \"Expression\": \"ANOMALY_DETECTION_BAND(m1, 2)\",\n      \"Label\": \"AnomalyDetectionBand\",\n      \"ReturnData\": true\n    }\n  ]' \\\n  --threshold-metric-id ad1 \\\n  --comparison-operator LessThanLowerOrGreaterThanUpperThreshold \\\n  --evaluation-periods 3 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Composite Alarm\n\nCombines multiple alarms with boolean logic:\n\n```bash\n# Create component alarms first\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighCPU\" \\\n  --metric-name CPUUtilization \\\n  --namespace AWS/EC2 \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=InstanceId,Value=i-1234567890abcdef0\n\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighMemory\" \\\n  --metric-name MemoryUtilization \\\n  --namespace CWAgent \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=InstanceId,Value=i-1234567890abcdef0\n\n# Create composite alarm\naws cloudwatch put-composite-alarm \\\n  --alarm-name \"InstanceUnhealthy\" \\\n  --alarm-rule \"ALARM(HighCPU) AND ALARM(HighMemory)\" \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n## Common Alarm Patterns\n\n### Lambda Function Health\n\n```bash\n# Errors alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"Lambda-MyFunction-Errors\" \\\n  --metric-name Errors \\\n  --namespace AWS/Lambda \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 5 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --dimensions Name=FunctionName,Value=MyFunction \\\n  --treat-missing-data notBreaching \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Throttles alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"Lambda-MyFunction-Throttles\" \\\n  --metric-name Throttles \\\n  --namespace AWS/Lambda \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --dimensions Name=FunctionName,Value=MyFunction \\\n  --treat-missing-data notBreaching \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Duration alarm (approaching timeout)\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"Lambda-MyFunction-Duration\" \\\n  --metric-name Duration \\\n  --namespace AWS/Lambda \\\n  --extended-statistic p99 \\\n  --period 300 \\\n  --threshold 25000 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=FunctionName,Value=MyFunction \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### DynamoDB Table Health\n\n```bash\n# Consumed capacity alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"DynamoDB-MyTable-HighReadCapacity\" \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --namespace AWS/DynamoDB \\\n  --statistic Average \\\n  --period 60 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 5 \\\n  --dimensions Name=TableName,Value=MyTable \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Throttled requests\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"DynamoDB-MyTable-Throttled\" \\\n  --metric-name ThrottledRequests \\\n  --namespace AWS/DynamoDB \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --dimensions Name=TableName,Value=MyTable \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### API Gateway Health\n\n```bash\n# 5XX errors\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"APIGW-MyAPI-5XXErrors\" \\\n  --metric-name 5XXError \\\n  --namespace AWS/ApiGateway \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 10 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=ApiName,Value=MyAPI \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Latency P99\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"APIGW-MyAPI-HighLatency\" \\\n  --metric-name Latency \\\n  --namespace AWS/ApiGateway \\\n  --extended-statistic p99 \\\n  --period 300 \\\n  --threshold 5000 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 3 \\\n  --dimensions Name=ApiName,Value=MyAPI \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### SQS Queue Health\n\n```bash\n# Messages in queue (backlog)\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SQS-MyQueue-Backlog\" \\\n  --metric-name ApproximateNumberOfMessagesVisible \\\n  --namespace AWS/SQS \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 1000 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 3 \\\n  --dimensions Name=QueueName,Value=MyQueue \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Age of oldest message\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SQS-MyQueue-OldMessages\" \\\n  --metric-name ApproximateAgeOfOldestMessage \\\n  --namespace AWS/SQS \\\n  --statistic Maximum \\\n  --period 300 \\\n  --threshold 3600 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --dimensions Name=QueueName,Value=MyQueue \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n## Custom Metrics\n\n### High-Resolution Metrics\n\nPublish metrics with 1-second resolution:\n\n```python\nimport boto3\n\ncloudwatch = boto3.client('cloudwatch')\n\ncloudwatch.put_metric_data(\n    Namespace='MyApp',\n    MetricData=[\n        {\n            'MetricName': 'RequestLatency',\n            'Value': 125.5,\n            'Unit': 'Milliseconds',\n            'StorageResolution': 1,  # 1 second resolution\n            'Dimensions': [\n                {'Name': 'Endpoint', 'Value': '/api/orders'}\n            ]\n        }\n    ]\n)\n```\n\n### Batched Metric Publishing\n\n```python\nimport boto3\nfrom datetime import datetime\n\ncloudwatch = boto3.client('cloudwatch')\n\n# Collect metrics\nmetric_data = [\n    {\n        'MetricName': 'OrdersProcessed',\n        'Value': 42,\n        'Unit': 'Count',\n        'Timestamp': datetime.utcnow(),\n        'Dimensions': [\n            {'Name': 'Environment', 'Value': 'Production'}\n        ]\n    },\n    {\n        'MetricName': 'ProcessingTime',\n        'Value': 250.5,\n        'Unit': 'Milliseconds',\n        'Timestamp': datetime.utcnow(),\n        'Dimensions': [\n            {'Name': 'Environment', 'Value': 'Production'}\n        ]\n    }\n]\n\n# Publish in batch (max 1000 per call)\ncloudwatch.put_metric_data(\n    Namespace='MyApp',\n    MetricData=metric_data\n)\n```\n\n### Embedded Metric Format (EMF)\n\nPublish metrics directly from Lambda logs:\n\n```python\nimport json\n\ndef handler(event, context):\n    # Process request\n    processing_time = 125.5\n\n    # Emit EMF log\n    print(json.dumps({\n        \"_aws\": {\n            \"Timestamp\": int(time.time() * 1000),\n            \"CloudWatchMetrics\": [{\n                \"Namespace\": \"MyApp\",\n                \"Dimensions\": [[\"Environment\", \"Endpoint\"]],\n                \"Metrics\": [\n                    {\"Name\": \"RequestLatency\", \"Unit\": \"Milliseconds\"},\n                    {\"Name\": \"RequestCount\", \"Unit\": \"Count\"}\n                ]\n            }]\n        },\n        \"Environment\": \"Production\",\n        \"Endpoint\": \"/api/orders\",\n        \"RequestLatency\": processing_time,\n        \"RequestCount\": 1\n    }))\n\n    return {\"statusCode\": 200}\n```\n\n## Metric Math Functions\n\n| Function | Description | Example |\n|----------|-------------|---------|\n| `SUM` | Sum of metrics | `SUM([m1, m2, m3])` |\n| `AVG` | Average | `AVG([m1, m2])` |\n| `MIN`, `MAX` | Minimum/Maximum | `MAX([m1, m2])` |\n| `RATE` | Per-second rate of change | `RATE(m1)` |\n| `PERIOD` | Current period in seconds | `m1 / PERIOD(m1)` |\n| `FILL` | Replace missing data | `FILL(m1, 0)` |\n| `IF` | Conditional | `IF(m1 > 100, m1, 0)` |\n| `ANOMALY_DETECTION_BAND` | ML-based band | `ANOMALY_DETECTION_BAND(m1, 2)` |\n| `SEARCH` | Dynamic metrics | `SEARCH('{AWS/EC2,InstanceId} MetricName=\"CPUUtilization\"', 'Average', 300)` |\n\n### Example: Percentage Calculation\n\n```\ne1 = errors metric\ne2 = requests metric\nerrorRate = IF(e2 > 0, (e1 / e2) * 100, 0)\n```\n\n### Example: Aggregate Across Dimensions\n\n```\nSEARCH('{AWS/Lambda,FunctionName} MetricName=\"Errors\"', 'Sum', 60)\n```\n\n## Alarm Actions\n\n### SNS Notification\n\n```bash\n--alarm-actions arn:aws:sns:us-east-1:123456789012:my-topic\n```\n\n### Auto Scaling\n\n```bash\n--alarm-actions arn:aws:autoscaling:us-east-1:123456789012:scalingPolicy:12345678-1234-1234-1234-123456789012:autoScalingGroupName/my-asg:policyName/scale-out\n```\n\n### EC2 Actions\n\n```bash\n# Stop instance\n--alarm-actions arn:aws:automate:us-east-1:ec2:stop\n\n# Terminate instance\n--alarm-actions arn:aws:automate:us-east-1:ec2:terminate\n\n# Recover instance\n--alarm-actions arn:aws:automate:us-east-1:ec2:recover\n```\n\n### Lambda Trigger\n\nUse SNS as intermediary:\n\n```bash\n# Subscribe Lambda to SNS topic\naws sns subscribe \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:alerts \\\n  --protocol lambda \\\n  --notification-endpoint arn:aws:lambda:us-east-1:123456789012:function:HandleAlarm\n```\n",
        "skills/cognito/SKILL.md": "---\nname: cognito\ndescription: AWS Cognito user authentication and authorization service. Use when setting up user pools, configuring identity pools, implementing OAuth flows, managing user attributes, or integrating with social identity providers.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/cognito/latest/developerguide/\n---\n\n# AWS Cognito\n\nAmazon Cognito provides authentication, authorization, and user management for web and mobile applications. Users can sign in directly or through federated identity providers.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### User Pools\n\nUser directory for sign-up and sign-in. Provides:\n- User registration and authentication\n- OAuth 2.0 / OpenID Connect tokens\n- MFA and password policies\n- Customizable UI and flows\n\n### Identity Pools (Federated Identities)\n\nProvide temporary AWS credentials to access AWS services. Users can be:\n- Cognito User Pool users\n- Social identity (Google, Facebook, Apple)\n- SAML/OIDC enterprise identity\n- Anonymous guests\n\n### Tokens\n\n| Token | Purpose | Lifetime |\n|-------|---------|----------|\n| **ID Token** | User identity claims | 1 hour |\n| **Access Token** | API authorization | 1 hour |\n| **Refresh Token** | Get new ID/Access tokens | 30 days (configurable) |\n\n## Common Patterns\n\n### Create User Pool\n\n**AWS CLI:**\n\n```bash\naws cognito-idp create-user-pool \\\n  --pool-name my-app-users \\\n  --policies '{\n    \"PasswordPolicy\": {\n      \"MinimumLength\": 12,\n      \"RequireUppercase\": true,\n      \"RequireLowercase\": true,\n      \"RequireNumbers\": true,\n      \"RequireSymbols\": true\n    }\n  }' \\\n  --auto-verified-attributes email \\\n  --username-attributes email \\\n  --mfa-configuration OPTIONAL \\\n  --user-attribute-update-settings '{\n    \"AttributesRequireVerificationBeforeUpdate\": [\"email\"]\n  }'\n```\n\n### Create App Client\n\n```bash\naws cognito-idp create-user-pool-client \\\n  --user-pool-id us-east-1_abc123 \\\n  --client-name my-web-app \\\n  --generate-secret \\\n  --explicit-auth-flows ALLOW_USER_SRP_AUTH ALLOW_REFRESH_TOKEN_AUTH \\\n  --supported-identity-providers COGNITO \\\n  --callback-urls https://myapp.com/callback \\\n  --logout-urls https://myapp.com/logout \\\n  --allowed-o-auth-flows code \\\n  --allowed-o-auth-scopes openid email profile \\\n  --allowed-o-auth-flows-user-pool-client \\\n  --access-token-validity 60 \\\n  --id-token-validity 60 \\\n  --refresh-token-validity 30 \\\n  --token-validity-units '{\n    \"AccessToken\": \"minutes\",\n    \"IdToken\": \"minutes\",\n    \"RefreshToken\": \"days\"\n  }'\n```\n\n### Sign Up User\n\n```python\nimport boto3\nimport hmac\nimport hashlib\nimport base64\n\ncognito = boto3.client('cognito-idp')\n\ndef get_secret_hash(username, client_id, client_secret):\n    message = username + client_id\n    dig = hmac.new(\n        client_secret.encode('utf-8'),\n        message.encode('utf-8'),\n        digestmod=hashlib.sha256\n    ).digest()\n    return base64.b64encode(dig).decode()\n\nresponse = cognito.sign_up(\n    ClientId='client-id',\n    SecretHash=get_secret_hash('user@example.com', 'client-id', 'client-secret'),\n    Username='user@example.com',\n    Password='SecurePassword123!',\n    UserAttributes=[\n        {'Name': 'email', 'Value': 'user@example.com'},\n        {'Name': 'name', 'Value': 'John Doe'}\n    ]\n)\n```\n\n### Confirm Sign Up\n\n```python\ncognito.confirm_sign_up(\n    ClientId='client-id',\n    SecretHash=get_secret_hash('user@example.com', 'client-id', 'client-secret'),\n    Username='user@example.com',\n    ConfirmationCode='123456'\n)\n```\n\n### Authenticate User\n\n```python\nresponse = cognito.initiate_auth(\n    ClientId='client-id',\n    AuthFlow='USER_SRP_AUTH',\n    AuthParameters={\n        'USERNAME': 'user@example.com',\n        'SECRET_HASH': get_secret_hash('user@example.com', 'client-id', 'client-secret'),\n        'SRP_A': srp_a  # From SRP library\n    }\n)\n\n# For simple password auth (not recommended for production)\nresponse = cognito.admin_initiate_auth(\n    UserPoolId='us-east-1_abc123',\n    ClientId='client-id',\n    AuthFlow='ADMIN_USER_PASSWORD_AUTH',\n    AuthParameters={\n        'USERNAME': 'user@example.com',\n        'PASSWORD': 'password',\n        'SECRET_HASH': get_secret_hash('user@example.com', 'client-id', 'client-secret')\n    }\n)\n\ntokens = response['AuthenticationResult']\nid_token = tokens['IdToken']\naccess_token = tokens['AccessToken']\nrefresh_token = tokens['RefreshToken']\n```\n\n### Refresh Tokens\n\n```python\nresponse = cognito.initiate_auth(\n    ClientId='client-id',\n    AuthFlow='REFRESH_TOKEN_AUTH',\n    AuthParameters={\n        'REFRESH_TOKEN': refresh_token,\n        'SECRET_HASH': get_secret_hash('user@example.com', 'client-id', 'client-secret')\n    }\n)\n```\n\n### Create Identity Pool\n\n```bash\naws cognito-identity create-identity-pool \\\n  --identity-pool-name my-app-identities \\\n  --allow-unauthenticated-identities \\\n  --cognito-identity-providers \\\n    ProviderName=cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123,\\\nClientId=client-id,\\\nServerSideTokenCheck=true\n```\n\n### Get AWS Credentials\n\n```python\nimport boto3\n\ncognito_identity = boto3.client('cognito-identity')\n\n# Get identity ID\nresponse = cognito_identity.get_id(\n    IdentityPoolId='us-east-1:12345678-1234-1234-1234-123456789012',\n    Logins={\n        'cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123': id_token\n    }\n)\nidentity_id = response['IdentityId']\n\n# Get credentials\nresponse = cognito_identity.get_credentials_for_identity(\n    IdentityId=identity_id,\n    Logins={\n        'cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123': id_token\n    }\n)\n\ncredentials = response['Credentials']\n# Use credentials['AccessKeyId'], credentials['SecretKey'], credentials['SessionToken']\n```\n\n## CLI Reference\n\n### User Pool\n\n| Command | Description |\n|---------|-------------|\n| `aws cognito-idp create-user-pool` | Create user pool |\n| `aws cognito-idp describe-user-pool` | Get pool details |\n| `aws cognito-idp update-user-pool` | Update pool settings |\n| `aws cognito-idp delete-user-pool` | Delete pool |\n| `aws cognito-idp list-user-pools` | List pools |\n\n### Users\n\n| Command | Description |\n|---------|-------------|\n| `aws cognito-idp admin-create-user` | Create user (admin) |\n| `aws cognito-idp admin-delete-user` | Delete user |\n| `aws cognito-idp admin-get-user` | Get user details |\n| `aws cognito-idp list-users` | List users |\n| `aws cognito-idp admin-set-user-password` | Set password |\n| `aws cognito-idp admin-disable-user` | Disable user |\n\n### Authentication\n\n| Command | Description |\n|---------|-------------|\n| `aws cognito-idp initiate-auth` | Start authentication |\n| `aws cognito-idp respond-to-auth-challenge` | Respond to MFA |\n| `aws cognito-idp admin-initiate-auth` | Admin authentication |\n\n## Best Practices\n\n### Security\n\n- **Enable MFA** for all users (at least optional)\n- **Use strong password policies**\n- **Enable advanced security features** (adaptive auth)\n- **Verify email/phone** before allowing sign-in\n- **Use short token lifetimes** for sensitive apps\n- **Never expose client secrets** in frontend code\n\n### User Experience\n\n- **Use hosted UI** for quick implementation\n- **Customize UI** with CSS\n- **Implement proper error handling**\n- **Provide clear password requirements**\n\n### Architecture\n\n- **Use identity pools** for AWS resource access\n- **Use access tokens** for API Gateway\n- **Store refresh tokens securely**\n- **Implement token refresh** before expiry\n\n## Troubleshooting\n\n### User Cannot Sign In\n\n**Causes:**\n- User not confirmed\n- Password incorrect\n- User disabled\n- Account locked (too many attempts)\n\n**Debug:**\n\n```bash\naws cognito-idp admin-get-user \\\n  --user-pool-id us-east-1_abc123 \\\n  --username user@example.com\n```\n\n### Token Validation Failed\n\n**Causes:**\n- Token expired\n- Wrong user pool/client ID\n- Token signature invalid\n\n**Validate JWT:**\n\n```python\nimport jwt\nimport requests\n\n# Get JWKS\njwks_url = f'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123/.well-known/jwks.json'\njwks = requests.get(jwks_url).json()\n\n# Decode and verify (use python-jose or similar)\nfrom jose import jwt\n\nclaims = jwt.decode(\n    token,\n    jwks,\n    algorithms=['RS256'],\n    audience='client-id',\n    issuer='https://cognito-idp.us-east-1.amazonaws.com/us-east-1_abc123'\n)\n```\n\n### Hosted UI Not Working\n\n**Check:**\n- Callback URLs configured correctly\n- Domain configured for user pool\n- OAuth settings enabled\n\n```bash\n# Check domain\naws cognito-idp describe-user-pool \\\n  --user-pool-id us-east-1_abc123 \\\n  --query 'UserPool.Domain'\n```\n\n### Rate Limiting\n\n**Symptom:** `TooManyRequestsException`\n\n**Solutions:**\n- Implement exponential backoff\n- Request quota increase\n- Cache tokens appropriately\n\n## References\n\n- [Cognito Developer Guide](https://docs.aws.amazon.com/cognito/latest/developerguide/)\n- [Cognito User Pools API](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/)\n- [Cognito Identity API](https://docs.aws.amazon.com/cognitoidentity/latest/APIReference/)\n- [Cognito CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/cognito-idp/)\n",
        "skills/cognito/auth-flows.md": "# Cognito Authentication Flows\n\nDetailed authentication flows and OAuth configurations.\n\n## Authentication Flows\n\n### USER_SRP_AUTH (Recommended)\n\nSecure Remote Password protocol - password never sent over network.\n\n```python\nimport boto3\nfrom warrant.aws_srp import AWSSRP\n\ncognito = boto3.client('cognito-idp')\n\n# Use warrant library for SRP\naws_srp = AWSSRP(\n    username='user@example.com',\n    password='password',\n    pool_id='us-east-1_abc123',\n    client_id='client-id',\n    client_secret='client-secret'\n)\n\ntokens = aws_srp.authenticate_user()\n```\n\n### USER_PASSWORD_AUTH\n\nDirect username/password (requires enabling in client settings).\n\n```python\nresponse = cognito.initiate_auth(\n    ClientId='client-id',\n    AuthFlow='USER_PASSWORD_AUTH',\n    AuthParameters={\n        'USERNAME': 'user@example.com',\n        'PASSWORD': 'password',\n        'SECRET_HASH': get_secret_hash(...)\n    }\n)\n```\n\n### CUSTOM_AUTH\n\nCustom authentication flow with Lambda triggers.\n\n```python\n# Step 1: Initiate\nresponse = cognito.initiate_auth(\n    ClientId='client-id',\n    AuthFlow='CUSTOM_AUTH',\n    AuthParameters={\n        'USERNAME': 'user@example.com'\n    }\n)\n\n# Step 2: Respond to challenge\nresponse = cognito.respond_to_auth_challenge(\n    ClientId='client-id',\n    ChallengeName='CUSTOM_CHALLENGE',\n    Session=response['Session'],\n    ChallengeResponses={\n        'USERNAME': 'user@example.com',\n        'ANSWER': 'custom-answer'\n    }\n)\n```\n\n## OAuth 2.0 Flows\n\n### Authorization Code Flow (Recommended for web)\n\n```\n1. Redirect to authorize endpoint:\n   https://my-domain.auth.us-east-1.amazoncognito.com/oauth2/authorize?\n   response_type=code&\n   client_id=CLIENT_ID&\n   redirect_uri=https://myapp.com/callback&\n   scope=openid+email+profile\n\n2. User authenticates, redirected back with code:\n   https://myapp.com/callback?code=AUTHORIZATION_CODE\n\n3. Exchange code for tokens:\n```\n\n```python\nimport requests\n\nresponse = requests.post(\n    'https://my-domain.auth.us-east-1.amazoncognito.com/oauth2/token',\n    data={\n        'grant_type': 'authorization_code',\n        'client_id': 'CLIENT_ID',\n        'client_secret': 'CLIENT_SECRET',\n        'code': 'AUTHORIZATION_CODE',\n        'redirect_uri': 'https://myapp.com/callback'\n    },\n    headers={'Content-Type': 'application/x-www-form-urlencoded'}\n)\n\ntokens = response.json()\n```\n\n### Authorization Code Flow with PKCE (Mobile/SPA)\n\n```python\nimport secrets\nimport hashlib\nimport base64\n\n# Generate PKCE values\ncode_verifier = secrets.token_urlsafe(64)\ncode_challenge = base64.urlsafe_b64encode(\n    hashlib.sha256(code_verifier.encode()).digest()\n).decode().rstrip('=')\n\n# Step 1: Authorization URL with PKCE\nauth_url = (\n    f'https://my-domain.auth.us-east-1.amazoncognito.com/oauth2/authorize?'\n    f'response_type=code&'\n    f'client_id={client_id}&'\n    f'redirect_uri={redirect_uri}&'\n    f'scope=openid+email&'\n    f'code_challenge={code_challenge}&'\n    f'code_challenge_method=S256'\n)\n\n# Step 2: Exchange code with verifier\nresponse = requests.post(\n    'https://my-domain.auth.us-east-1.amazoncognito.com/oauth2/token',\n    data={\n        'grant_type': 'authorization_code',\n        'client_id': client_id,\n        'code': authorization_code,\n        'redirect_uri': redirect_uri,\n        'code_verifier': code_verifier\n    }\n)\n```\n\n### Implicit Flow (Legacy, not recommended)\n\n```\nhttps://my-domain.auth.us-east-1.amazoncognito.com/oauth2/authorize?\nresponse_type=token&\nclient_id=CLIENT_ID&\nredirect_uri=https://myapp.com/callback&\nscope=openid+email\n\nCallback: https://myapp.com/callback#id_token=TOKEN&access_token=TOKEN\n```\n\n### Client Credentials Flow (Machine-to-Machine)\n\n```bash\n# Create resource server\naws cognito-idp create-resource-server \\\n  --user-pool-id us-east-1_abc123 \\\n  --identifier api.myapp.com \\\n  --name \"My API\" \\\n  --scopes ScopeName=read,ScopeDescription=\"Read access\" \\\n          ScopeName=write,ScopeDescription=\"Write access\"\n\n# Create client for M2M\naws cognito-idp create-user-pool-client \\\n  --user-pool-id us-east-1_abc123 \\\n  --client-name service-client \\\n  --generate-secret \\\n  --allowed-o-auth-flows client_credentials \\\n  --allowed-o-auth-scopes api.myapp.com/read api.myapp.com/write \\\n  --allowed-o-auth-flows-user-pool-client\n```\n\n```python\nimport requests\nimport base64\n\ncredentials = base64.b64encode(f'{client_id}:{client_secret}'.encode()).decode()\n\nresponse = requests.post(\n    'https://my-domain.auth.us-east-1.amazoncognito.com/oauth2/token',\n    data={\n        'grant_type': 'client_credentials',\n        'scope': 'api.myapp.com/read api.myapp.com/write'\n    },\n    headers={\n        'Content-Type': 'application/x-www-form-urlencoded',\n        'Authorization': f'Basic {credentials}'\n    }\n)\n```\n\n## MFA Flows\n\n### SMS MFA\n\n```python\n# After initial auth, if MFA required:\nif response.get('ChallengeName') == 'SMS_MFA':\n    response = cognito.respond_to_auth_challenge(\n        ClientId='client-id',\n        ChallengeName='SMS_MFA',\n        Session=response['Session'],\n        ChallengeResponses={\n            'USERNAME': 'user@example.com',\n            'SMS_MFA_CODE': '123456',\n            'SECRET_HASH': get_secret_hash(...)\n        }\n    )\n```\n\n### TOTP MFA\n\n```python\n# Associate TOTP\nresponse = cognito.associate_software_token(\n    AccessToken=access_token\n)\nsecret_code = response['SecretCode']\n\n# Verify TOTP\ncognito.verify_software_token(\n    AccessToken=access_token,\n    UserCode='123456',\n    FriendlyDeviceName='My Phone'\n)\n\n# Set as preferred\ncognito.set_user_mfa_preference(\n    AccessToken=access_token,\n    SoftwareTokenMfaSettings={\n        'Enabled': True,\n        'PreferredMfa': True\n    }\n)\n```\n\n## Lambda Triggers\n\n### Pre Sign-up\n\n```python\ndef handler(event, context):\n    # Auto-confirm users from specific domains\n    email = event['request']['userAttributes'].get('email', '')\n    if email.endswith('@mycompany.com'):\n        event['response']['autoConfirmUser'] = True\n        event['response']['autoVerifyEmail'] = True\n\n    return event\n```\n\n### Pre Authentication\n\n```python\ndef handler(event, context):\n    # Block specific users\n    username = event['userName']\n    if is_blocked(username):\n        raise Exception('User is blocked')\n\n    return event\n```\n\n### Post Confirmation\n\n```python\ndef handler(event, context):\n    # Add user to group after confirmation\n    cognito = boto3.client('cognito-idp')\n\n    cognito.admin_add_user_to_group(\n        UserPoolId=event['userPoolId'],\n        Username=event['userName'],\n        GroupName='Users'\n    )\n\n    return event\n```\n\n### Custom Message\n\n```python\ndef handler(event, context):\n    if event['triggerSource'] == 'CustomMessage_SignUp':\n        event['response']['emailSubject'] = 'Welcome to MyApp!'\n        event['response']['emailMessage'] = f'''\n            Hi {event['request']['userAttributes']['name']},\n            Your verification code is {event['request']['codeParameter']}\n        '''\n\n    return event\n```\n\n### Define Auth Challenge\n\n```python\ndef handler(event, context):\n    if len(event['request']['session']) == 0:\n        # First challenge\n        event['response']['challengeName'] = 'CUSTOM_CHALLENGE'\n        event['response']['issueTokens'] = False\n        event['response']['failAuthentication'] = False\n    elif event['request']['session'][-1]['challengeResult']:\n        # Challenge passed\n        event['response']['issueTokens'] = True\n        event['response']['failAuthentication'] = False\n\n    return event\n```\n\n## Social Identity Providers\n\n### Configure Google\n\n```bash\naws cognito-idp create-identity-provider \\\n  --user-pool-id us-east-1_abc123 \\\n  --provider-name Google \\\n  --provider-type Google \\\n  --provider-details '{\n    \"client_id\": \"google-client-id\",\n    \"client_secret\": \"google-client-secret\",\n    \"authorize_scopes\": \"profile email openid\"\n  }' \\\n  --attribute-mapping '{\n    \"email\": \"email\",\n    \"name\": \"name\",\n    \"picture\": \"picture\"\n  }'\n```\n\n### Configure SAML\n\n```bash\naws cognito-idp create-identity-provider \\\n  --user-pool-id us-east-1_abc123 \\\n  --provider-name MySAML \\\n  --provider-type SAML \\\n  --provider-details '{\n    \"MetadataFile\": \"<SAML metadata XML>\",\n    \"IDPSignout\": \"true\"\n  }' \\\n  --attribute-mapping '{\n    \"email\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress\"\n  }'\n```\n\n## Token Management\n\n### Verify Token\n\n```python\nimport jwt\nfrom jwt import PyJWKClient\n\ndef verify_cognito_token(token, user_pool_id, client_id, region='us-east-1'):\n    jwks_url = f'https://cognito-idp.{region}.amazonaws.com/{user_pool_id}/.well-known/jwks.json'\n    issuer = f'https://cognito-idp.{region}.amazonaws.com/{user_pool_id}'\n\n    jwk_client = PyJWKClient(jwks_url)\n    signing_key = jwk_client.get_signing_key_from_jwt(token)\n\n    claims = jwt.decode(\n        token,\n        signing_key.key,\n        algorithms=['RS256'],\n        audience=client_id,\n        issuer=issuer\n    )\n\n    return claims\n```\n\n### Revoke Tokens\n\n```python\ncognito.revoke_token(\n    Token=refresh_token,\n    ClientId='client-id',\n    ClientSecret='client-secret'\n)\n```\n\n### Global Sign Out\n\n```python\ncognito.global_sign_out(\n    AccessToken=access_token\n)\n```\n",
        "skills/dynamodb/SKILL.md": "---\nname: dynamodb\ndescription: AWS DynamoDB NoSQL database for scalable data storage. Use when designing table schemas, writing queries, configuring indexes, managing capacity, implementing single-table design, or troubleshooting performance issues.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/\n---\n\n# AWS DynamoDB\n\nAmazon DynamoDB is a fully managed NoSQL database service providing fast, predictable performance at any scale. It supports key-value and document data structures.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Keys\n\n| Key Type | Description |\n|----------|-------------|\n| **Partition Key (PK)** | Required. Determines data distribution |\n| **Sort Key (SK)** | Optional. Enables range queries within partition |\n| **Composite Key** | PK + SK combination |\n\n### Secondary Indexes\n\n| Index Type | Description |\n|------------|-------------|\n| **GSI (Global Secondary Index)** | Different PK/SK, separate throughput, eventually consistent |\n| **LSI (Local Secondary Index)** | Same PK, different SK, shares table throughput, strongly consistent option |\n\n### Capacity Modes\n\n| Mode | Use Case |\n|------|----------|\n| **On-Demand** | Unpredictable traffic, pay-per-request |\n| **Provisioned** | Predictable traffic, lower cost, can use auto-scaling |\n\n## Common Patterns\n\n### Create a Table\n\n**AWS CLI:**\n\n```bash\naws dynamodb create-table \\\n  --table-name Users \\\n  --attribute-definitions \\\n    AttributeName=PK,AttributeType=S \\\n    AttributeName=SK,AttributeType=S \\\n  --key-schema \\\n    AttributeName=PK,KeyType=HASH \\\n    AttributeName=SK,KeyType=RANGE \\\n  --billing-mode PAY_PER_REQUEST\n```\n\n**boto3:**\n\n```python\nimport boto3\n\ndynamodb = boto3.resource('dynamodb')\n\ntable = dynamodb.create_table(\n    TableName='Users',\n    KeySchema=[\n        {'AttributeName': 'PK', 'KeyType': 'HASH'},\n        {'AttributeName': 'SK', 'KeyType': 'RANGE'}\n    ],\n    AttributeDefinitions=[\n        {'AttributeName': 'PK', 'AttributeType': 'S'},\n        {'AttributeName': 'SK', 'AttributeType': 'S'}\n    ],\n    BillingMode='PAY_PER_REQUEST'\n)\n\ntable.wait_until_exists()\n```\n\n### Basic CRUD Operations\n\n```python\nimport boto3\nfrom boto3.dynamodb.conditions import Key, Attr\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('Users')\n\n# Put item\ntable.put_item(\n    Item={\n        'PK': 'USER#123',\n        'SK': 'PROFILE',\n        'name': 'John Doe',\n        'email': 'john@example.com',\n        'created_at': '2024-01-15T10:30:00Z'\n    }\n)\n\n# Get item\nresponse = table.get_item(\n    Key={'PK': 'USER#123', 'SK': 'PROFILE'}\n)\nitem = response.get('Item')\n\n# Update item\ntable.update_item(\n    Key={'PK': 'USER#123', 'SK': 'PROFILE'},\n    UpdateExpression='SET #name = :name, updated_at = :updated',\n    ExpressionAttributeNames={'#name': 'name'},\n    ExpressionAttributeValues={\n        ':name': 'John Smith',\n        ':updated': '2024-01-16T10:30:00Z'\n    }\n)\n\n# Delete item\ntable.delete_item(\n    Key={'PK': 'USER#123', 'SK': 'PROFILE'}\n)\n```\n\n### Query Operations\n\n```python\n# Query by partition key\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123')\n)\n\n# Query with sort key condition\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123') & Key('SK').begins_with('ORDER#')\n)\n\n# Query with filter\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123'),\n    FilterExpression=Attr('status').eq('active')\n)\n\n# Query with projection\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123'),\n    ProjectionExpression='PK, SK, #name, email',\n    ExpressionAttributeNames={'#name': 'name'}\n)\n\n# Paginated query\npaginator = dynamodb.meta.client.get_paginator('query')\nfor page in paginator.paginate(\n    TableName='Users',\n    KeyConditionExpression='PK = :pk',\n    ExpressionAttributeValues={':pk': {'S': 'USER#123'}}\n):\n    for item in page['Items']:\n        print(item)\n```\n\n### Batch Operations\n\n```python\n# Batch write (up to 25 items)\nwith table.batch_writer() as batch:\n    for i in range(100):\n        batch.put_item(Item={\n            'PK': f'USER#{i}',\n            'SK': 'PROFILE',\n            'name': f'User {i}'\n        })\n\n# Batch get (up to 100 items)\ndynamodb = boto3.resource('dynamodb')\nresponse = dynamodb.batch_get_item(\n    RequestItems={\n        'Users': {\n            'Keys': [\n                {'PK': 'USER#1', 'SK': 'PROFILE'},\n                {'PK': 'USER#2', 'SK': 'PROFILE'}\n            ]\n        }\n    }\n)\n```\n\n### Create GSI\n\n```bash\naws dynamodb update-table \\\n  --table-name Users \\\n  --attribute-definitions AttributeName=email,AttributeType=S \\\n  --global-secondary-index-updates '[\n    {\n      \"Create\": {\n        \"IndexName\": \"email-index\",\n        \"KeySchema\": [{\"AttributeName\": \"email\", \"KeyType\": \"HASH\"}],\n        \"Projection\": {\"ProjectionType\": \"ALL\"}\n      }\n    }\n  ]'\n```\n\n### Conditional Writes\n\n```python\nfrom botocore.exceptions import ClientError\n\n# Only put if item doesn't exist\ntry:\n    table.put_item(\n        Item={'PK': 'USER#123', 'SK': 'PROFILE', 'name': 'John'},\n        ConditionExpression='attribute_not_exists(PK)'\n    )\nexcept ClientError as e:\n    if e.response['Error']['Code'] == 'ConditionalCheckFailedException':\n        print(\"Item already exists\")\n\n# Optimistic locking with version\ntable.update_item(\n    Key={'PK': 'USER#123', 'SK': 'PROFILE'},\n    UpdateExpression='SET #name = :name, version = version + :inc',\n    ConditionExpression='version = :current_version',\n    ExpressionAttributeNames={'#name': 'name'},\n    ExpressionAttributeValues={\n        ':name': 'New Name',\n        ':inc': 1,\n        ':current_version': 5\n    }\n)\n```\n\n## CLI Reference\n\n### Table Operations\n\n| Command | Description |\n|---------|-------------|\n| `aws dynamodb create-table` | Create table |\n| `aws dynamodb describe-table` | Get table info |\n| `aws dynamodb update-table` | Modify table/indexes |\n| `aws dynamodb delete-table` | Delete table |\n| `aws dynamodb list-tables` | List all tables |\n\n### Item Operations\n\n| Command | Description |\n|---------|-------------|\n| `aws dynamodb put-item` | Create/replace item |\n| `aws dynamodb get-item` | Read single item |\n| `aws dynamodb update-item` | Update item attributes |\n| `aws dynamodb delete-item` | Delete item |\n| `aws dynamodb query` | Query by key |\n| `aws dynamodb scan` | Full table scan |\n\n### Batch Operations\n\n| Command | Description |\n|---------|-------------|\n| `aws dynamodb batch-write-item` | Batch write (25 max) |\n| `aws dynamodb batch-get-item` | Batch read (100 max) |\n| `aws dynamodb transact-write-items` | Transaction write |\n| `aws dynamodb transact-get-items` | Transaction read |\n\n## Best Practices\n\n### Data Modeling\n\n- **Design for access patterns** â€” know your queries before designing\n- **Use composite keys** â€” PK for grouping, SK for sorting/filtering\n- **Prefer query over scan** â€” scans are expensive\n- **Use sparse indexes** â€” only items with index attributes are indexed\n- **Consider single-table design** for related entities\n\n### Performance\n\n- **Distribute partition keys evenly** â€” avoid hot partitions\n- **Use batch operations** to reduce API calls\n- **Enable DAX** for read-heavy workloads\n- **Use projections** to reduce data transfer\n\n### Cost Optimization\n\n- **Use on-demand** for variable workloads\n- **Use provisioned + auto-scaling** for predictable workloads\n- **Set TTL** for expiring data\n- **Archive to S3** for cold data\n\n## Troubleshooting\n\n### Throttling\n\n**Symptom:** `ProvisionedThroughputExceededException`\n\n**Causes:**\n- Hot partition (uneven key distribution)\n- Burst traffic exceeding capacity\n- GSI throttling affecting base table\n\n**Solutions:**\n\n```python\n# Use exponential backoff\nimport time\nfrom botocore.config import Config\n\nconfig = Config(\n    retries={\n        'max_attempts': 10,\n        'mode': 'adaptive'\n    }\n)\ndynamodb = boto3.resource('dynamodb', config=config)\n```\n\n### Hot Partitions\n\n**Debug:**\n\n```bash\n# Check consumed capacity by partition\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=Users \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\n```\n\n**Solutions:**\n- Add randomness to partition keys\n- Use write sharding\n- Distribute access across partitions\n\n### Query Returns No Items\n\n**Debug checklist:**\n1. Verify key values exactly match (case-sensitive)\n2. Check key types (S, N, B)\n3. Confirm table/index name\n4. Review filter expressions (they apply AFTER read)\n\n### Scan Performance\n\n**Issue:** Scans are slow and expensive\n\n**Solutions:**\n- Use parallel scan for large tables\n- Create GSI for the access pattern\n- Use filter expressions to reduce returned data\n\n```python\n# Parallel scan\nimport concurrent.futures\n\ndef scan_segment(segment, total_segments):\n    return table.scan(\n        Segment=segment,\n        TotalSegments=total_segments\n    )\n\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    results = list(executor.map(\n        lambda s: scan_segment(s, 4),\n        range(4)\n    ))\n```\n\n## References\n\n- [DynamoDB Developer Guide](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/)\n- [DynamoDB API Reference](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/)\n- [DynamoDB CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/dynamodb/)\n- [boto3 DynamoDB](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html)\n- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)\n",
        "skills/dynamodb/query-patterns.md": "# DynamoDB Query Patterns\n\nAdvanced query patterns and single-table design strategies.\n\n## Single-Table Design\n\n### Entity Modeling\n\nStore multiple entity types in one table using composite keys:\n\n```\nPK                  SK                  Data\nUSER#123            PROFILE             {name, email, ...}\nUSER#123            ORDER#2024-001      {total, status, ...}\nUSER#123            ORDER#2024-002      {total, status, ...}\nORDER#2024-001      ITEM#1              {product, qty, ...}\nORDER#2024-001      ITEM#2              {product, qty, ...}\nPRODUCT#ABC         METADATA            {name, price, ...}\nPRODUCT#ABC         REVIEW#user-456     {rating, comment, ...}\n```\n\n### Access Patterns\n\n| Pattern | Query |\n|---------|-------|\n| Get user profile | `PK = USER#123, SK = PROFILE` |\n| Get user's orders | `PK = USER#123, SK begins_with ORDER#` |\n| Get order items | `PK = ORDER#2024-001, SK begins_with ITEM#` |\n| Get product reviews | `PK = PRODUCT#ABC, SK begins_with REVIEW#` |\n\n## Query Examples\n\n### Range Queries with Sort Key\n\n```python\nfrom boto3.dynamodb.conditions import Key\n\n# Orders in date range\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123') &\n        Key('SK').between('ORDER#2024-01', 'ORDER#2024-12')\n)\n\n# Latest 10 orders (descending)\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123') &\n        Key('SK').begins_with('ORDER#'),\n    ScanIndexForward=False,\n    Limit=10\n)\n```\n\n### Querying GSI\n\n```python\n# GSI: email-index (email as PK)\nresponse = table.query(\n    IndexName='email-index',\n    KeyConditionExpression=Key('email').eq('john@example.com')\n)\n\n# GSI: status-created-index (status as PK, created_at as SK)\nresponse = table.query(\n    IndexName='status-created-index',\n    KeyConditionExpression=Key('status').eq('pending') &\n        Key('created_at').gt('2024-01-01')\n)\n```\n\n### Filter Expressions\n\nFilters apply AFTER read, so they don't reduce consumed capacity:\n\n```python\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123'),\n    FilterExpression=Attr('status').eq('active') &\n        Attr('amount').gt(100)\n)\n```\n\n### Projection Expressions\n\nReduce data transfer by selecting specific attributes:\n\n```python\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('USER#123'),\n    ProjectionExpression='PK, SK, #name, email',\n    ExpressionAttributeNames={'#name': 'name'}  # 'name' is reserved word\n)\n```\n\n## Advanced Patterns\n\n### Hierarchical Data\n\nModel parent-child relationships:\n\n```\nPK                  SK                          Data\nORG#acme            METADATA                    {name, ...}\nORG#acme            DEPT#engineering            {name, head, ...}\nORG#acme            DEPT#engineering#TEAM#api   {name, lead, ...}\nORG#acme            DEPT#sales                  {name, head, ...}\n```\n\nQuery patterns:\n```python\n# All departments\ntable.query(\n    KeyConditionExpression=Key('PK').eq('ORG#acme') &\n        Key('SK').begins_with('DEPT#')\n)\n\n# Teams in engineering\ntable.query(\n    KeyConditionExpression=Key('PK').eq('ORG#acme') &\n        Key('SK').begins_with('DEPT#engineering#TEAM#')\n)\n```\n\n### Inverted Index (GSI)\n\nEnable reverse lookups:\n\n```\nTable:\nPK          SK              GSI1PK      GSI1SK\nUSER#123    FOLLOWS#456     USER#456    FOLLOWER#123\nUSER#123    FOLLOWS#789     USER#789    FOLLOWER#123\n```\n\n```python\n# Who does user 123 follow?\ntable.query(\n    KeyConditionExpression=Key('PK').eq('USER#123') &\n        Key('SK').begins_with('FOLLOWS#')\n)\n\n# Who follows user 456?\ntable.query(\n    IndexName='GSI1',\n    KeyConditionExpression=Key('GSI1PK').eq('USER#456') &\n        Key('GSI1SK').begins_with('FOLLOWER#')\n)\n```\n\n### Sparse Indexes\n\nOnly items with the GSI key are indexed:\n\n```python\n# Table: all items\n# GSI: only items with 'featured' attribute\n\n# Add item to GSI by setting the attribute\ntable.put_item(\n    Item={\n        'PK': 'PRODUCT#123',\n        'SK': 'METADATA',\n        'name': 'Widget',\n        'featured': 'FEATURED'  # This enables GSI inclusion\n    }\n)\n\n# Query featured products only\ntable.query(\n    IndexName='featured-index',\n    KeyConditionExpression=Key('featured').eq('FEATURED')\n)\n```\n\n### Time-Based Data\n\nUse sort key for time-series:\n\n```python\n# Store with ISO timestamp\ntable.put_item(\n    Item={\n        'PK': 'SENSOR#temp-001',\n        'SK': '2024-01-15T10:30:00Z',\n        'value': 23.5\n    }\n)\n\n# Query time range\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('SENSOR#temp-001') &\n        Key('SK').between('2024-01-15T00:00:00Z', '2024-01-15T23:59:59Z')\n)\n\n# Latest reading\nresponse = table.query(\n    KeyConditionExpression=Key('PK').eq('SENSOR#temp-001'),\n    ScanIndexForward=False,\n    Limit=1\n)\n```\n\n### Write Sharding\n\nDistribute writes across partitions:\n\n```python\nimport random\n\n# Write with shard suffix\nshard = random.randint(0, 9)\ntable.put_item(\n    Item={\n        'PK': f'COUNTER#daily#{shard}',\n        'SK': '2024-01-15',\n        'count': 1\n    }\n)\n\n# Read aggregates all shards\ntotal = 0\nfor shard in range(10):\n    response = table.get_item(\n        Key={\n            'PK': f'COUNTER#daily#{shard}',\n            'SK': '2024-01-15'\n        }\n    )\n    if 'Item' in response:\n        total += response['Item']['count']\n```\n\n## Transactions\n\n### TransactWriteItems\n\n```python\ndynamodb = boto3.client('dynamodb')\n\ndynamodb.transact_write_items(\n    TransactItems=[\n        {\n            'Put': {\n                'TableName': 'Users',\n                'Item': {\n                    'PK': {'S': 'ORDER#2024-001'},\n                    'SK': {'S': 'METADATA'},\n                    'total': {'N': '150.00'}\n                }\n            }\n        },\n        {\n            'Update': {\n                'TableName': 'Users',\n                'Key': {\n                    'PK': {'S': 'USER#123'},\n                    'SK': {'S': 'PROFILE'}\n                },\n                'UpdateExpression': 'SET order_count = order_count + :inc',\n                'ExpressionAttributeValues': {':inc': {'N': '1'}}\n            }\n        },\n        {\n            'Update': {\n                'TableName': 'Users',\n                'Key': {\n                    'PK': {'S': 'PRODUCT#ABC'},\n                    'SK': {'S': 'INVENTORY'}\n                },\n                'UpdateExpression': 'SET stock = stock - :qty',\n                'ConditionExpression': 'stock >= :qty',\n                'ExpressionAttributeValues': {':qty': {'N': '2'}}\n            }\n        }\n    ]\n)\n```\n\n### TransactGetItems\n\n```python\nresponse = dynamodb.transact_get_items(\n    TransactItems=[\n        {\n            'Get': {\n                'TableName': 'Users',\n                'Key': {\n                    'PK': {'S': 'USER#123'},\n                    'SK': {'S': 'PROFILE'}\n                }\n            }\n        },\n        {\n            'Get': {\n                'TableName': 'Users',\n                'Key': {\n                    'PK': {'S': 'USER#123'},\n                    'SK': {'S': 'SETTINGS'}\n                }\n            }\n        }\n    ]\n)\n```\n\n## Pagination\n\n### Manual Pagination\n\n```python\nitems = []\nlast_key = None\n\nwhile True:\n    params = {\n        'KeyConditionExpression': Key('PK').eq('USER#123'),\n        'Limit': 100\n    }\n    if last_key:\n        params['ExclusiveStartKey'] = last_key\n\n    response = table.query(**params)\n    items.extend(response['Items'])\n\n    last_key = response.get('LastEvaluatedKey')\n    if not last_key:\n        break\n```\n\n### Paginator\n\n```python\npaginator = dynamodb.meta.client.get_paginator('query')\n\nfor page in paginator.paginate(\n    TableName='Users',\n    KeyConditionExpression='PK = :pk',\n    ExpressionAttributeValues={':pk': {'S': 'USER#123'}},\n    PaginationConfig={'PageSize': 100}\n):\n    for item in page['Items']:\n        process(item)\n```\n\n## TTL (Time To Live)\n\n### Enable TTL\n\n```bash\naws dynamodb update-time-to-live \\\n  --table-name Sessions \\\n  --time-to-live-specification \"Enabled=true, AttributeName=expires_at\"\n```\n\n### Use TTL\n\n```python\nimport time\n\n# Set expiration (Unix timestamp)\ntable.put_item(\n    Item={\n        'PK': 'SESSION#abc123',\n        'SK': 'DATA',\n        'user_id': 'user-456',\n        'expires_at': int(time.time()) + 3600  # 1 hour from now\n    }\n)\n```\n\n## Expression Reference\n\n### Comparison Operators\n\n| Operator | Usage |\n|----------|-------|\n| `=` | `attribute = :value` |\n| `<>` | `attribute <> :value` |\n| `<`, `<=`, `>`, `>=` | `attribute >= :value` |\n| `BETWEEN` | `attribute BETWEEN :low AND :high` |\n| `IN` | `attribute IN (:v1, :v2, :v3)` |\n\n### Functions\n\n| Function | Usage |\n|----------|-------|\n| `attribute_exists` | `attribute_exists(attr)` |\n| `attribute_not_exists` | `attribute_not_exists(attr)` |\n| `attribute_type` | `attribute_type(attr, :type)` |\n| `begins_with` | `begins_with(attr, :prefix)` |\n| `contains` | `contains(attr, :value)` |\n| `size` | `size(attr) > :size` |\n\n### Update Operations\n\n| Operation | Expression |\n|-----------|------------|\n| SET | `SET attr = :value` |\n| REMOVE | `REMOVE attr` |\n| ADD | `ADD attr :value` (numbers, sets) |\n| DELETE | `DELETE attr :value` (sets only) |\n| List append | `SET list = list_append(list, :item)` |\n| Increment | `SET counter = counter + :inc` |\n| If not exists | `SET attr = if_not_exists(attr, :default)` |\n",
        "skills/ec2/SKILL.md": "---\nname: ec2\ndescription: AWS EC2 virtual machine management for instances, AMIs, and networking. Use when launching instances, configuring security groups, managing key pairs, troubleshooting connectivity, or automating instance lifecycle.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/\n---\n\n# AWS EC2\n\nAmazon Elastic Compute Cloud (EC2) provides resizable compute capacity in the cloud. Launch virtual servers, configure networking and security, and manage storage.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Instance Types\n\n| Category | Example | Use Case |\n|----------|---------|----------|\n| General Purpose | t3, m6i | Web servers, dev environments |\n| Compute Optimized | c6i | Batch processing, gaming |\n| Memory Optimized | r6i | Databases, caching |\n| Storage Optimized | i3, d3 | Data warehousing |\n| Accelerated | p4d, g5 | ML, graphics |\n\n### Purchasing Options\n\n| Option | Description |\n|--------|-------------|\n| On-Demand | Pay by the hour/second |\n| Reserved | 1-3 year commitment, up to 72% discount |\n| Spot | Unused capacity, up to 90% discount |\n| Savings Plans | Flexible commitment-based discount |\n\n### AMI (Amazon Machine Image)\n\nTemplate containing OS, software, and configuration for launching instances.\n\n### Security Groups\n\nVirtual firewalls controlling inbound and outbound traffic.\n\n## Common Patterns\n\n### Launch an Instance\n\n**AWS CLI:**\n\n```bash\n# Create key pair\naws ec2 create-key-pair \\\n  --key-name my-key \\\n  --query 'KeyMaterial' \\\n  --output text > my-key.pem\nchmod 400 my-key.pem\n\n# Create security group\naws ec2 create-security-group \\\n  --group-name web-server-sg \\\n  --description \"Web server security group\" \\\n  --vpc-id vpc-12345678\n\n# Allow SSH and HTTP\naws ec2 authorize-security-group-ingress \\\n  --group-id sg-12345678 \\\n  --protocol tcp \\\n  --port 22 \\\n  --cidr 10.0.0.0/8\n\naws ec2 authorize-security-group-ingress \\\n  --group-id sg-12345678 \\\n  --protocol tcp \\\n  --port 80 \\\n  --cidr 0.0.0.0/0\n\n# Launch instance\naws ec2 run-instances \\\n  --image-id ami-0123456789abcdef0 \\\n  --instance-type t3.micro \\\n  --key-name my-key \\\n  --security-group-ids sg-12345678 \\\n  --subnet-id subnet-12345678 \\\n  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=web-server}]'\n```\n\n**boto3:**\n\n```python\nimport boto3\n\nec2 = boto3.resource('ec2')\n\ninstances = ec2.create_instances(\n    ImageId='ami-0123456789abcdef0',\n    InstanceType='t3.micro',\n    KeyName='my-key',\n    SecurityGroupIds=['sg-12345678'],\n    SubnetId='subnet-12345678',\n    MinCount=1,\n    MaxCount=1,\n    TagSpecifications=[{\n        'ResourceType': 'instance',\n        'Tags': [{'Key': 'Name', 'Value': 'web-server'}]\n    }]\n)\n\ninstance = instances[0]\ninstance.wait_until_running()\ninstance.reload()\nprint(f\"Instance ID: {instance.id}\")\nprint(f\"Public IP: {instance.public_ip_address}\")\n```\n\n### User Data Script\n\n```bash\naws ec2 run-instances \\\n  --image-id ami-0123456789abcdef0 \\\n  --instance-type t3.micro \\\n  --key-name my-key \\\n  --security-group-ids sg-12345678 \\\n  --subnet-id subnet-12345678 \\\n  --user-data '#!/bin/bash\n    yum update -y\n    yum install -y httpd\n    systemctl start httpd\n    systemctl enable httpd\n    echo \"<h1>Hello from $(hostname)</h1>\" > /var/www/html/index.html\n  '\n```\n\n### Attach IAM Role\n\n```bash\n# Create instance profile\naws iam create-instance-profile \\\n  --instance-profile-name web-server-profile\n\naws iam add-role-to-instance-profile \\\n  --instance-profile-name web-server-profile \\\n  --role-name web-server-role\n\n# Launch with profile\naws ec2 run-instances \\\n  --image-id ami-0123456789abcdef0 \\\n  --instance-type t3.micro \\\n  --iam-instance-profile Name=web-server-profile \\\n  ...\n```\n\n### Create AMI from Instance\n\n```bash\naws ec2 create-image \\\n  --instance-id i-1234567890abcdef0 \\\n  --name \"my-custom-ami-$(date +%Y%m%d)\" \\\n  --description \"Custom AMI with web server\" \\\n  --no-reboot\n```\n\n### Spot Instance Request\n\n```bash\naws ec2 request-spot-instances \\\n  --instance-count 1 \\\n  --type \"one-time\" \\\n  --launch-specification '{\n    \"ImageId\": \"ami-0123456789abcdef0\",\n    \"InstanceType\": \"c5.large\",\n    \"KeyName\": \"my-key\",\n    \"SecurityGroupIds\": [\"sg-12345678\"],\n    \"SubnetId\": \"subnet-12345678\"\n  }' \\\n  --spot-price \"0.05\"\n```\n\n### EBS Volume Management\n\n```bash\n# Create volume\naws ec2 create-volume \\\n  --availability-zone us-east-1a \\\n  --size 100 \\\n  --volume-type gp3 \\\n  --iops 3000 \\\n  --throughput 125 \\\n  --encrypted\n\n# Attach to instance\naws ec2 attach-volume \\\n  --volume-id vol-12345678 \\\n  --instance-id i-1234567890abcdef0 \\\n  --device /dev/sdf\n\n# Create snapshot\naws ec2 create-snapshot \\\n  --volume-id vol-12345678 \\\n  --description \"Daily backup\"\n```\n\n## CLI Reference\n\n### Instance Management\n\n| Command | Description |\n|---------|-------------|\n| `aws ec2 run-instances` | Launch instances |\n| `aws ec2 describe-instances` | List instances |\n| `aws ec2 start-instances` | Start stopped instances |\n| `aws ec2 stop-instances` | Stop running instances |\n| `aws ec2 reboot-instances` | Reboot instances |\n| `aws ec2 terminate-instances` | Terminate instances |\n| `aws ec2 modify-instance-attribute` | Modify instance settings |\n\n### Security Groups\n\n| Command | Description |\n|---------|-------------|\n| `aws ec2 create-security-group` | Create security group |\n| `aws ec2 describe-security-groups` | List security groups |\n| `aws ec2 authorize-security-group-ingress` | Add inbound rule |\n| `aws ec2 revoke-security-group-ingress` | Remove inbound rule |\n| `aws ec2 authorize-security-group-egress` | Add outbound rule |\n\n### AMIs\n\n| Command | Description |\n|---------|-------------|\n| `aws ec2 describe-images` | List AMIs |\n| `aws ec2 create-image` | Create AMI from instance |\n| `aws ec2 copy-image` | Copy AMI to another region |\n| `aws ec2 deregister-image` | Delete AMI |\n\n### EBS Volumes\n\n| Command | Description |\n|---------|-------------|\n| `aws ec2 create-volume` | Create EBS volume |\n| `aws ec2 attach-volume` | Attach to instance |\n| `aws ec2 detach-volume` | Detach from instance |\n| `aws ec2 create-snapshot` | Create snapshot |\n| `aws ec2 modify-volume` | Resize/modify volume |\n\n## Best Practices\n\n### Security\n\n- **Use IAM roles** instead of access keys on instances\n- **Restrict security groups** â€” principle of least privilege\n- **Use private subnets** for backend instances\n- **Enable IMDSv2** to prevent SSRF attacks\n- **Encrypt EBS volumes** at rest\n\n```bash\n# Require IMDSv2\naws ec2 modify-instance-metadata-options \\\n  --instance-id i-1234567890abcdef0 \\\n  --http-tokens required \\\n  --http-endpoint enabled\n```\n\n### Performance\n\n- **Right-size instances** â€” monitor and adjust\n- **Use EBS-optimized instances**\n- **Choose appropriate EBS volume type**\n- **Use placement groups** for low-latency networking\n\n### Cost Optimization\n\n- **Use Spot Instances** for fault-tolerant workloads\n- **Stop/terminate unused instances**\n- **Use Reserved Instances** for steady-state workloads\n- **Delete unused EBS volumes and snapshots**\n\n### Reliability\n\n- **Use Auto Scaling Groups** for high availability\n- **Deploy across multiple AZs**\n- **Use Elastic Load Balancer** for traffic distribution\n- **Implement health checks**\n\n## Troubleshooting\n\n### Cannot SSH to Instance\n\n**Checklist:**\n\n1. Security group allows SSH (port 22) from your IP\n2. Instance has public IP or use bastion/SSM\n3. Key pair matches instance\n4. Instance is running\n5. Network ACL allows traffic\n\n```bash\n# Check security group\naws ec2 describe-security-groups --group-ids sg-12345678\n\n# Check instance state\naws ec2 describe-instances \\\n  --instance-ids i-1234567890abcdef0 \\\n  --query \"Reservations[].Instances[].{State:State.Name,PublicIP:PublicIpAddress}\"\n```\n\n**Use Session Manager instead:**\n\n```bash\naws ssm start-session --target i-1234567890abcdef0\n```\n\n### Instance Won't Start\n\n**Causes:**\n- Reached instance limits\n- Insufficient capacity in AZ\n- EBS volume issue\n- Invalid AMI\n\n```bash\n# Check instance state reason\naws ec2 describe-instances \\\n  --instance-ids i-1234567890abcdef0 \\\n  --query \"Reservations[].Instances[].StateReason\"\n```\n\n### Instance Unreachable\n\n**Debug:**\n\n```bash\n# Check instance status\naws ec2 describe-instance-status \\\n  --instance-ids i-1234567890abcdef0\n\n# Get console output\naws ec2 get-console-output \\\n  --instance-id i-1234567890abcdef0\n\n# Get screenshot (for Windows/GUI issues)\naws ec2 get-console-screenshot \\\n  --instance-id i-1234567890abcdef0\n```\n\n### High CPU/Memory\n\n```bash\n# Enable detailed monitoring\naws ec2 monitor-instances \\\n  --instance-ids i-1234567890abcdef0\n\n# Check CloudWatch metrics\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/EC2 \\\n  --metric-name CPUUtilization \\\n  --dimensions Name=InstanceId,Value=i-1234567890abcdef0 \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Average\n```\n\n## References\n\n- [EC2 User Guide](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/)\n- [EC2 API Reference](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/)\n- [EC2 CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/ec2/)\n- [boto3 EC2](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html)\n",
        "skills/ec2/instance-management.md": "# EC2 Instance Management\n\nAdvanced instance lifecycle and management patterns.\n\n## Instance Lifecycle\n\n### States\n\n```\npending â†’ running â†’ stopping â†’ stopped\n                â†“\n           shutting-down â†’ terminated\n```\n\n### Start/Stop Automation\n\n```python\nimport boto3\n\nec2 = boto3.client('ec2')\n\ndef stop_instances_by_tag(tag_key, tag_value):\n    \"\"\"Stop all instances with specific tag.\"\"\"\n    response = ec2.describe_instances(\n        Filters=[\n            {'Name': f'tag:{tag_key}', 'Values': [tag_value]},\n            {'Name': 'instance-state-name', 'Values': ['running']}\n        ]\n    )\n\n    instance_ids = []\n    for reservation in response['Reservations']:\n        for instance in reservation['Instances']:\n            instance_ids.append(instance['InstanceId'])\n\n    if instance_ids:\n        ec2.stop_instances(InstanceIds=instance_ids)\n        print(f\"Stopped: {instance_ids}\")\n\n# Stop all dev instances\nstop_instances_by_tag('Environment', 'dev')\n```\n\n### Scheduled Start/Stop with EventBridge\n\n```bash\n# Create Lambda function for start/stop\n# Then create EventBridge rules\n\n# Stop at 7 PM\naws events put-rule \\\n  --name \"stop-dev-instances\" \\\n  --schedule-expression \"cron(0 19 ? * MON-FRI *)\"\n\naws events put-targets \\\n  --rule \"stop-dev-instances\" \\\n  --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:us-east-1:123456789012:function:StopInstances\"\n\n# Start at 7 AM\naws events put-rule \\\n  --name \"start-dev-instances\" \\\n  --schedule-expression \"cron(0 7 ? * MON-FRI *)\"\n\naws events put-targets \\\n  --rule \"start-dev-instances\" \\\n  --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:us-east-1:123456789012:function:StartInstances\"\n```\n\n## Auto Scaling\n\n### Create Launch Template\n\n```bash\naws ec2 create-launch-template \\\n  --launch-template-name web-server-template \\\n  --version-description \"v1\" \\\n  --launch-template-data '{\n    \"ImageId\": \"ami-0123456789abcdef0\",\n    \"InstanceType\": \"t3.micro\",\n    \"KeyName\": \"my-key\",\n    \"SecurityGroupIds\": [\"sg-12345678\"],\n    \"IamInstanceProfile\": {\"Name\": \"web-server-profile\"},\n    \"UserData\": \"IyEvYmluL2Jhc2gKeXVtIHVwZGF0ZSAteQo=\",\n    \"TagSpecifications\": [{\n      \"ResourceType\": \"instance\",\n      \"Tags\": [{\"Key\": \"Name\", \"Value\": \"web-server\"}]\n    }],\n    \"MetadataOptions\": {\n      \"HttpTokens\": \"required\",\n      \"HttpEndpoint\": \"enabled\"\n    }\n  }'\n```\n\n### Create Auto Scaling Group\n\n```bash\naws autoscaling create-auto-scaling-group \\\n  --auto-scaling-group-name web-asg \\\n  --launch-template LaunchTemplateName=web-server-template,Version='$Latest' \\\n  --min-size 2 \\\n  --max-size 10 \\\n  --desired-capacity 2 \\\n  --vpc-zone-identifier \"subnet-12345678,subnet-87654321\" \\\n  --target-group-arns arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/web-tg/1234567890123456 \\\n  --health-check-type ELB \\\n  --health-check-grace-period 300 \\\n  --tags \"Key=Environment,Value=production,PropagateAtLaunch=true\"\n```\n\n### Scaling Policies\n\n```bash\n# Target tracking (CPU)\naws autoscaling put-scaling-policy \\\n  --auto-scaling-group-name web-asg \\\n  --policy-name cpu-target-tracking \\\n  --policy-type TargetTrackingScaling \\\n  --target-tracking-configuration '{\n    \"PredefinedMetricSpecification\": {\n      \"PredefinedMetricType\": \"ASGAverageCPUUtilization\"\n    },\n    \"TargetValue\": 70.0,\n    \"ScaleOutCooldown\": 300,\n    \"ScaleInCooldown\": 300\n  }'\n\n# Step scaling\naws autoscaling put-scaling-policy \\\n  --auto-scaling-group-name web-asg \\\n  --policy-name scale-out-policy \\\n  --policy-type StepScaling \\\n  --adjustment-type ChangeInCapacity \\\n  --step-adjustments '[\n    {\"MetricIntervalLowerBound\": 0, \"MetricIntervalUpperBound\": 20, \"ScalingAdjustment\": 1},\n    {\"MetricIntervalLowerBound\": 20, \"ScalingAdjustment\": 2}\n  ]'\n```\n\n### Scheduled Scaling\n\n```bash\n# Scale up for peak hours\naws autoscaling put-scheduled-update-group-action \\\n  --auto-scaling-group-name web-asg \\\n  --scheduled-action-name scale-up-morning \\\n  --recurrence \"0 8 * * MON-FRI\" \\\n  --min-size 5 \\\n  --max-size 20 \\\n  --desired-capacity 10\n\n# Scale down at night\naws autoscaling put-scheduled-update-group-action \\\n  --auto-scaling-group-name web-asg \\\n  --scheduled-action-name scale-down-night \\\n  --recurrence \"0 20 * * *\" \\\n  --min-size 2 \\\n  --max-size 5 \\\n  --desired-capacity 2\n```\n\n## Instance Connect and Session Manager\n\n### EC2 Instance Connect\n\n```bash\n# Push SSH key temporarily\naws ec2-instance-connect send-ssh-public-key \\\n  --instance-id i-1234567890abcdef0 \\\n  --instance-os-user ec2-user \\\n  --ssh-public-key file://~/.ssh/id_rsa.pub\n\n# Connect via browser or CLI\naws ec2-instance-connect ssh --instance-id i-1234567890abcdef0\n```\n\n### Session Manager\n\nNo SSH keys or open ports required:\n\n```bash\n# Install Session Manager plugin first\n# https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html\n\n# Start session\naws ssm start-session --target i-1234567890abcdef0\n\n# Port forwarding\naws ssm start-session \\\n  --target i-1234567890abcdef0 \\\n  --document-name AWS-StartPortForwardingSession \\\n  --parameters '{\"portNumber\":[\"3306\"],\"localPortNumber\":[\"3306\"]}'\n```\n\n### Enable Session Manager\n\n```bash\n# Instance needs SSM agent (pre-installed on Amazon Linux 2, Windows)\n# Instance needs IAM role with AmazonSSMManagedInstanceCore policy\n\n# Verify SSM agent is running\naws ssm describe-instance-information \\\n  --filters \"Key=InstanceIds,Values=i-1234567890abcdef0\"\n```\n\n## Instance Metadata Service (IMDS)\n\n### IMDSv2 (Recommended)\n\n```bash\n# Get token\nTOKEN=$(curl -X PUT \"http://169.254.169.254/latest/api/token\" \\\n  -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n\n# Use token to get metadata\ncurl -H \"X-aws-ec2-metadata-token: $TOKEN\" \\\n  http://169.254.169.254/latest/meta-data/instance-id\n\ncurl -H \"X-aws-ec2-metadata-token: $TOKEN\" \\\n  http://169.254.169.254/latest/meta-data/iam/security-credentials/my-role\n```\n\n### Enforce IMDSv2\n\n```bash\n# New instances\naws ec2 run-instances \\\n  --metadata-options \"HttpTokens=required,HttpEndpoint=enabled\" \\\n  ...\n\n# Existing instances\naws ec2 modify-instance-metadata-options \\\n  --instance-id i-1234567890abcdef0 \\\n  --http-tokens required \\\n  --http-endpoint enabled\n```\n\n## Placement Groups\n\n### Cluster (Low Latency)\n\n```bash\naws ec2 create-placement-group \\\n  --group-name hpc-cluster \\\n  --strategy cluster\n\naws ec2 run-instances \\\n  --placement \"GroupName=hpc-cluster\" \\\n  ...\n```\n\n### Spread (High Availability)\n\n```bash\naws ec2 create-placement-group \\\n  --group-name ha-spread \\\n  --strategy spread\n\n# Max 7 instances per AZ\naws ec2 run-instances \\\n  --placement \"GroupName=ha-spread\" \\\n  ...\n```\n\n### Partition (Large Distributed)\n\n```bash\naws ec2 create-placement-group \\\n  --group-name hadoop-cluster \\\n  --strategy partition \\\n  --partition-count 7\n\naws ec2 run-instances \\\n  --placement \"GroupName=hadoop-cluster,PartitionNumber=1\" \\\n  ...\n```\n\n## Spot Instances\n\n### Spot Fleet\n\n```bash\naws ec2 request-spot-fleet \\\n  --spot-fleet-request-config '{\n    \"IamFleetRole\": \"arn:aws:iam::123456789012:role/spot-fleet-role\",\n    \"TargetCapacity\": 10,\n    \"SpotPrice\": \"0.10\",\n    \"AllocationStrategy\": \"diversified\",\n    \"LaunchSpecifications\": [\n      {\n        \"ImageId\": \"ami-0123456789abcdef0\",\n        \"InstanceType\": \"c5.large\",\n        \"SubnetId\": \"subnet-12345678\",\n        \"SecurityGroups\": [{\"GroupId\": \"sg-12345678\"}]\n      },\n      {\n        \"ImageId\": \"ami-0123456789abcdef0\",\n        \"InstanceType\": \"c5.xlarge\",\n        \"SubnetId\": \"subnet-12345678\",\n        \"SecurityGroups\": [{\"GroupId\": \"sg-12345678\"}]\n      }\n    ]\n  }'\n```\n\n### Handle Spot Interruption\n\n```python\nimport requests\nimport time\n\ndef check_spot_interruption():\n    \"\"\"Check for spot interruption notice (2-minute warning).\"\"\"\n    try:\n        # IMDSv2\n        token = requests.put(\n            'http://169.254.169.254/latest/api/token',\n            headers={'X-aws-ec2-metadata-token-ttl-seconds': '21600'},\n            timeout=1\n        ).text\n\n        response = requests.get(\n            'http://169.254.169.254/latest/meta-data/spot/termination-time',\n            headers={'X-aws-ec2-metadata-token': token},\n            timeout=1\n        )\n\n        if response.status_code == 200:\n            return response.text  # Termination time\n        return None\n    except:\n        return None\n\n# Check periodically\nwhile True:\n    termination_time = check_spot_interruption()\n    if termination_time:\n        print(f\"Spot interruption! Terminating at {termination_time}\")\n        # Graceful shutdown, save state, deregister from LB\n        graceful_shutdown()\n        break\n    time.sleep(5)\n```\n\n## Instance Tags\n\n### Bulk Tagging\n\n```bash\n# Tag multiple resources\naws ec2 create-tags \\\n  --resources i-1234567890abcdef0 vol-12345678 \\\n  --tags Key=Project,Value=WebApp Key=Environment,Value=production\n\n# Tag based on filter\naws ec2 describe-instances \\\n  --filters \"Name=instance-state-name,Values=running\" \\\n  --query \"Reservations[].Instances[].InstanceId\" \\\n  --output text | xargs -n 1 aws ec2 create-tags --tags Key=Status,Value=active --resources\n```\n\n### Enforce Tagging\n\nUse Service Control Policies (SCPs) or IAM policies:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"ec2:RunInstances\",\n      \"Resource\": \"arn:aws:ec2:*:*:instance/*\",\n      \"Condition\": {\n        \"Null\": {\n          \"aws:RequestTag/Environment\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n",
        "skills/ecs/SKILL.md": "---\nname: ecs\ndescription: AWS ECS container orchestration for running Docker containers. Use when deploying containerized applications, configuring task definitions, setting up services, managing clusters, or troubleshooting container issues.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/\n---\n\n# AWS ECS\n\nAmazon Elastic Container Service (ECS) is a fully managed container orchestration service. Run containers on AWS Fargate (serverless) or EC2 instances.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Cluster\n\nLogical grouping of tasks or services. Can contain Fargate tasks, EC2 instances, or both.\n\n### Task Definition\n\nBlueprint for your application. Defines containers, resources, networking, and IAM roles.\n\n### Task\n\nRunning instance of a task definition. Can run standalone or as part of a service.\n\n### Service\n\nMaintains desired count of tasks. Handles deployments, load balancing, and auto scaling.\n\n### Launch Types\n\n| Type | Description | Use Case |\n|------|-------------|----------|\n| **Fargate** | Serverless, pay per task | Most workloads |\n| **EC2** | Self-managed instances | GPU, Windows, specific requirements |\n\n## Common Patterns\n\n### Create a Fargate Cluster\n\n**AWS CLI:**\n\n```bash\n# Create cluster\naws ecs create-cluster --cluster-name my-cluster\n\n# With capacity providers\naws ecs create-cluster \\\n  --cluster-name my-cluster \\\n  --capacity-providers FARGATE FARGATE_SPOT \\\n  --default-capacity-provider-strategy \\\n    capacityProvider=FARGATE,weight=1 \\\n    capacityProvider=FARGATE_SPOT,weight=1\n```\n\n### Register Task Definition\n\n```bash\ncat > task-definition.json << 'EOF'\n{\n  \"family\": \"web-app\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"256\",\n  \"memory\": \"512\",\n  \"executionRoleArn\": \"arn:aws:iam::123456789012:role/ecsTaskExecutionRole\",\n  \"taskRoleArn\": \"arn:aws:iam::123456789012:role/ecsTaskRole\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"web\",\n      \"image\": \"123456789012.dkr.ecr.us-east-1.amazonaws.com/my-app:latest\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8080,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\"name\": \"NODE_ENV\", \"value\": \"production\"}\n      ],\n      \"secrets\": [\n        {\n          \"name\": \"DB_PASSWORD\",\n          \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:db-password\"\n        }\n      ],\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/web-app\",\n          \"awslogs-region\": \"us-east-1\",\n          \"awslogs-stream-prefix\": \"ecs\"\n        }\n      },\n      \"healthCheck\": {\n        \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8080/health || exit 1\"],\n        \"interval\": 30,\n        \"timeout\": 5,\n        \"retries\": 3,\n        \"startPeriod\": 60\n      }\n    }\n  ]\n}\nEOF\n\naws ecs register-task-definition --cli-input-json file://task-definition.json\n```\n\n### Create Service with Load Balancer\n\n```bash\naws ecs create-service \\\n  --cluster my-cluster \\\n  --service-name web-service \\\n  --task-definition web-app:1 \\\n  --desired-count 2 \\\n  --launch-type FARGATE \\\n  --network-configuration \"awsvpcConfiguration={\n    subnets=[subnet-12345678,subnet-87654321],\n    securityGroups=[sg-12345678],\n    assignPublicIp=DISABLED\n  }\" \\\n  --load-balancers \"targetGroupArn=arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/web-tg/1234567890123456,containerName=web,containerPort=8080\" \\\n  --health-check-grace-period-seconds 60\n```\n\n### Run Standalone Task\n\n```bash\naws ecs run-task \\\n  --cluster my-cluster \\\n  --task-definition my-batch-job:1 \\\n  --launch-type FARGATE \\\n  --network-configuration \"awsvpcConfiguration={\n    subnets=[subnet-12345678],\n    securityGroups=[sg-12345678],\n    assignPublicIp=ENABLED\n  }\"\n```\n\n### Update Service (Deploy New Image)\n\n```bash\n# Register new task definition with updated image\naws ecs register-task-definition --cli-input-json file://task-definition.json\n\n# Update service to use new version\naws ecs update-service \\\n  --cluster my-cluster \\\n  --service web-service \\\n  --task-definition web-app:2 \\\n  --force-new-deployment\n```\n\n### Auto Scaling\n\n```bash\n# Register scalable target\naws application-autoscaling register-scalable-target \\\n  --service-namespace ecs \\\n  --resource-id service/my-cluster/web-service \\\n  --scalable-dimension ecs:service:DesiredCount \\\n  --min-capacity 2 \\\n  --max-capacity 10\n\n# Target tracking policy\naws application-autoscaling put-scaling-policy \\\n  --service-namespace ecs \\\n  --resource-id service/my-cluster/web-service \\\n  --scalable-dimension ecs:service:DesiredCount \\\n  --policy-name cpu-target-tracking \\\n  --policy-type TargetTrackingScaling \\\n  --target-tracking-scaling-policy-configuration '{\n    \"TargetValue\": 70.0,\n    \"PredefinedMetricSpecification\": {\n      \"PredefinedMetricType\": \"ECSServiceAverageCPUUtilization\"\n    },\n    \"ScaleOutCooldown\": 60,\n    \"ScaleInCooldown\": 120\n  }'\n```\n\n## CLI Reference\n\n### Cluster Management\n\n| Command | Description |\n|---------|-------------|\n| `aws ecs create-cluster` | Create cluster |\n| `aws ecs describe-clusters` | Get cluster details |\n| `aws ecs list-clusters` | List clusters |\n| `aws ecs delete-cluster` | Delete cluster |\n\n### Task Definitions\n\n| Command | Description |\n|---------|-------------|\n| `aws ecs register-task-definition` | Create task definition |\n| `aws ecs describe-task-definition` | Get task definition |\n| `aws ecs list-task-definitions` | List task definitions |\n| `aws ecs deregister-task-definition` | Deregister version |\n\n### Services\n\n| Command | Description |\n|---------|-------------|\n| `aws ecs create-service` | Create service |\n| `aws ecs update-service` | Update service |\n| `aws ecs describe-services` | Get service details |\n| `aws ecs delete-service` | Delete service |\n\n### Tasks\n\n| Command | Description |\n|---------|-------------|\n| `aws ecs run-task` | Run standalone task |\n| `aws ecs stop-task` | Stop running task |\n| `aws ecs describe-tasks` | Get task details |\n| `aws ecs list-tasks` | List tasks |\n\n## Best Practices\n\n### Security\n\n- **Use task roles** for AWS API access (not access keys)\n- **Use execution roles** for ECR/Secrets access\n- **Store secrets in Secrets Manager** or Parameter Store\n- **Use private subnets** with NAT gateway\n- **Enable CloudTrail** for API auditing\n\n### Performance\n\n- **Right-size CPU/memory** â€” monitor and adjust\n- **Use Fargate Spot** for fault-tolerant workloads (70% savings)\n- **Enable container insights** for monitoring\n- **Use service discovery** for internal communication\n\n### Reliability\n\n- **Deploy across multiple AZs**\n- **Configure health checks** properly\n- **Set appropriate deregistration delay**\n- **Use circuit breaker** for deployments\n\n```bash\naws ecs update-service \\\n  --cluster my-cluster \\\n  --service web-service \\\n  --deployment-configuration '{\n    \"deploymentCircuitBreaker\": {\n      \"enable\": true,\n      \"rollback\": true\n    }\n  }'\n```\n\n### Cost Optimization\n\n- **Use Fargate Spot** for batch workloads\n- **Right-size task resources**\n- **Scale to zero** when not needed\n- **Use capacity providers** for mixed Fargate/Spot\n\n## Troubleshooting\n\n### Task Fails to Start\n\n**Check:**\n\n```bash\n# View stopped tasks\naws ecs describe-tasks \\\n  --cluster my-cluster \\\n  --tasks $(aws ecs list-tasks --cluster my-cluster --desired-status STOPPED --query 'taskArns[0]' --output text)\n```\n\n**Common causes:**\n- Image not found (ECR permissions)\n- Secrets access denied\n- Network configuration (subnets, security groups)\n- Resource limits exceeded\n\n### Container Keeps Restarting\n\n**Debug:**\n\n```bash\n# Check CloudWatch logs\naws logs get-log-events \\\n  --log-group-name /ecs/web-app \\\n  --log-stream-name \"ecs/web/abc123\"\n\n# Check task details\naws ecs describe-tasks \\\n  --cluster my-cluster \\\n  --tasks task-arn \\\n  --query 'tasks[0].containers[0].{reason:reason,exitCode:exitCode}'\n```\n\n**Causes:**\n- Health check failing\n- Application crashing\n- Out of memory\n\n### Service Stuck Deploying\n\n```bash\n# Check deployment status\naws ecs describe-services \\\n  --cluster my-cluster \\\n  --services web-service \\\n  --query 'services[0].deployments'\n\n# Check events\naws ecs describe-services \\\n  --cluster my-cluster \\\n  --services web-service \\\n  --query 'services[0].events[:5]'\n```\n\n**Causes:**\n- Health check failing on new tasks\n- Not enough capacity\n- Target group health checks failing\n\n### Cannot Pull Image from ECR\n\n**Check execution role has:**\n\n```json\n{\n  \"Effect\": \"Allow\",\n  \"Action\": [\n    \"ecr:GetAuthorizationToken\",\n    \"ecr:BatchCheckLayerAvailability\",\n    \"ecr:GetDownloadUrlForLayer\",\n    \"ecr:BatchGetImage\"\n  ],\n  \"Resource\": \"*\"\n}\n```\n\n**Also check:**\n- VPC endpoint for ECR (if private subnet)\n- NAT gateway (if private subnet)\n- Security group allows HTTPS outbound\n\n## References\n\n- [ECS Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/)\n- [ECS API Reference](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/)\n- [ECS CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/ecs/)\n- [boto3 ECS](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html)\n",
        "skills/ecs/task-definitions.md": "# ECS Task Definitions\n\nDetailed patterns for ECS task definitions.\n\n## Task Definition Structure\n\n```json\n{\n  \"family\": \"my-app\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"256\",\n  \"memory\": \"512\",\n  \"executionRoleArn\": \"arn:aws:iam::123456789012:role/ecsTaskExecutionRole\",\n  \"taskRoleArn\": \"arn:aws:iam::123456789012:role/ecsTaskRole\",\n  \"containerDefinitions\": [...],\n  \"volumes\": [...],\n  \"runtimePlatform\": {\n    \"cpuArchitecture\": \"ARM64\",\n    \"operatingSystemFamily\": \"LINUX\"\n  }\n}\n```\n\n## CPU and Memory Combinations (Fargate)\n\n| CPU | Memory Options |\n|-----|----------------|\n| 256 (.25 vCPU) | 512 MB, 1 GB, 2 GB |\n| 512 (.5 vCPU) | 1-4 GB (1 GB increments) |\n| 1024 (1 vCPU) | 2-8 GB (1 GB increments) |\n| 2048 (2 vCPU) | 4-16 GB (1 GB increments) |\n| 4096 (4 vCPU) | 8-30 GB (1 GB increments) |\n| 8192 (8 vCPU) | 16-60 GB (4 GB increments) |\n| 16384 (16 vCPU) | 32-120 GB (8 GB increments) |\n\n## Container Definition Examples\n\n### Web Application\n\n```json\n{\n  \"name\": \"web\",\n  \"image\": \"123456789012.dkr.ecr.us-east-1.amazonaws.com/my-app:latest\",\n  \"essential\": true,\n  \"portMappings\": [\n    {\n      \"containerPort\": 8080,\n      \"protocol\": \"tcp\",\n      \"appProtocol\": \"http\"\n    }\n  ],\n  \"environment\": [\n    {\"name\": \"NODE_ENV\", \"value\": \"production\"},\n    {\"name\": \"PORT\", \"value\": \"8080\"}\n  ],\n  \"secrets\": [\n    {\n      \"name\": \"DB_PASSWORD\",\n      \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:db-password:password::\"\n    },\n    {\n      \"name\": \"API_KEY\",\n      \"valueFrom\": \"arn:aws:ssm:us-east-1:123456789012:parameter/my-app/api-key\"\n    }\n  ],\n  \"logConfiguration\": {\n    \"logDriver\": \"awslogs\",\n    \"options\": {\n      \"awslogs-group\": \"/ecs/my-app\",\n      \"awslogs-region\": \"us-east-1\",\n      \"awslogs-stream-prefix\": \"web\"\n    }\n  },\n  \"healthCheck\": {\n    \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8080/health || exit 1\"],\n    \"interval\": 30,\n    \"timeout\": 5,\n    \"retries\": 3,\n    \"startPeriod\": 60\n  }\n}\n```\n\n### Sidecar Pattern\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"name\": \"app\",\n      \"image\": \"my-app:latest\",\n      \"essential\": true,\n      \"portMappings\": [{\"containerPort\": 8080}],\n      \"dependsOn\": [\n        {\"containerName\": \"envoy\", \"condition\": \"HEALTHY\"}\n      ]\n    },\n    {\n      \"name\": \"envoy\",\n      \"image\": \"envoyproxy/envoy:v1.28.0\",\n      \"essential\": true,\n      \"portMappings\": [{\"containerPort\": 9901}],\n      \"healthCheck\": {\n        \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:9901/ready || exit 1\"],\n        \"interval\": 5,\n        \"timeout\": 2,\n        \"retries\": 3,\n        \"startPeriod\": 10\n      }\n    },\n    {\n      \"name\": \"xray-daemon\",\n      \"image\": \"amazon/aws-xray-daemon\",\n      \"essential\": false,\n      \"portMappings\": [{\"containerPort\": 2000, \"protocol\": \"udp\"}],\n      \"memory\": 256\n    }\n  ]\n}\n```\n\n### Init Container Pattern\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"name\": \"init-db\",\n      \"image\": \"my-migrations:latest\",\n      \"essential\": false,\n      \"command\": [\"./run-migrations.sh\"],\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/my-app\",\n          \"awslogs-stream-prefix\": \"init\"\n        }\n      }\n    },\n    {\n      \"name\": \"app\",\n      \"image\": \"my-app:latest\",\n      \"essential\": true,\n      \"dependsOn\": [\n        {\"containerName\": \"init-db\", \"condition\": \"SUCCESS\"}\n      ]\n    }\n  ]\n}\n```\n\n## Secrets Management\n\n### From Secrets Manager\n\n```json\n{\n  \"secrets\": [\n    {\n      \"name\": \"FULL_SECRET\",\n      \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:my-secret\"\n    },\n    {\n      \"name\": \"SPECIFIC_KEY\",\n      \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:my-secret:username::\"\n    },\n    {\n      \"name\": \"SPECIFIC_VERSION\",\n      \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:my-secret:password::abc123\"\n    }\n  ]\n}\n```\n\n### From Parameter Store\n\n```json\n{\n  \"secrets\": [\n    {\n      \"name\": \"API_KEY\",\n      \"valueFrom\": \"arn:aws:ssm:us-east-1:123456789012:parameter/my-app/api-key\"\n    },\n    {\n      \"name\": \"DB_HOST\",\n      \"valueFrom\": \"arn:aws:ssm:us-east-1:123456789012:parameter/my-app/db-host\"\n    }\n  ]\n}\n```\n\n### Execution Role Permissions\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\"\n      ],\n      \"Resource\": [\n        \"arn:aws:secretsmanager:us-east-1:123456789012:secret:my-app/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ssm:GetParameters\"\n      ],\n      \"Resource\": [\n        \"arn:aws:ssm:us-east-1:123456789012:parameter/my-app/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"kms:Decrypt\"\n      ],\n      \"Resource\": [\n        \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n      ]\n    }\n  ]\n}\n```\n\n## Logging Configurations\n\n### CloudWatch Logs\n\n```json\n{\n  \"logConfiguration\": {\n    \"logDriver\": \"awslogs\",\n    \"options\": {\n      \"awslogs-group\": \"/ecs/my-app\",\n      \"awslogs-region\": \"us-east-1\",\n      \"awslogs-stream-prefix\": \"ecs\",\n      \"awslogs-create-group\": \"true\",\n      \"mode\": \"non-blocking\",\n      \"max-buffer-size\": \"4m\"\n    }\n  }\n}\n```\n\n### FireLens (Fluent Bit)\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"name\": \"log-router\",\n      \"image\": \"amazon/aws-for-fluent-bit:latest\",\n      \"essential\": true,\n      \"firelensConfiguration\": {\n        \"type\": \"fluentbit\",\n        \"options\": {\n          \"enable-ecs-log-metadata\": \"true\"\n        }\n      }\n    },\n    {\n      \"name\": \"app\",\n      \"image\": \"my-app:latest\",\n      \"logConfiguration\": {\n        \"logDriver\": \"awsfirelens\",\n        \"options\": {\n          \"Name\": \"cloudwatch\",\n          \"region\": \"us-east-1\",\n          \"log_group_name\": \"/ecs/my-app\",\n          \"log_stream_prefix\": \"app-\",\n          \"auto_create_group\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## Volume Mounts\n\n### EFS Volume\n\n```json\n{\n  \"volumes\": [\n    {\n      \"name\": \"shared-data\",\n      \"efsVolumeConfiguration\": {\n        \"fileSystemId\": \"fs-12345678\",\n        \"rootDirectory\": \"/\",\n        \"transitEncryption\": \"ENABLED\",\n        \"authorizationConfig\": {\n          \"accessPointId\": \"fsap-12345678\",\n          \"iam\": \"ENABLED\"\n        }\n      }\n    }\n  ],\n  \"containerDefinitions\": [\n    {\n      \"name\": \"app\",\n      \"mountPoints\": [\n        {\n          \"sourceVolume\": \"shared-data\",\n          \"containerPath\": \"/data\",\n          \"readOnly\": false\n        }\n      ]\n    }\n  ]\n}\n```\n\n### Bind Mount (Fargate)\n\n```json\n{\n  \"volumes\": [\n    {\n      \"name\": \"scratch\"\n    }\n  ],\n  \"containerDefinitions\": [\n    {\n      \"name\": \"app\",\n      \"mountPoints\": [\n        {\n          \"sourceVolume\": \"scratch\",\n          \"containerPath\": \"/tmp/scratch\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Resource Limits\n\n### Per-Container Limits\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"name\": \"app\",\n      \"cpu\": 512,\n      \"memory\": 1024,\n      \"memoryReservation\": 512\n    },\n    {\n      \"name\": \"sidecar\",\n      \"cpu\": 256,\n      \"memory\": 512\n    }\n  ]\n}\n```\n\n### GPU (EC2 Launch Type)\n\n```json\n{\n  \"requiresCompatibilities\": [\"EC2\"],\n  \"containerDefinitions\": [\n    {\n      \"name\": \"ml-training\",\n      \"image\": \"my-ml-image:latest\",\n      \"resourceRequirements\": [\n        {\n          \"type\": \"GPU\",\n          \"value\": \"1\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Health Checks\n\n### HTTP Health Check\n\n```json\n{\n  \"healthCheck\": {\n    \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8080/health || exit 1\"],\n    \"interval\": 30,\n    \"timeout\": 5,\n    \"retries\": 3,\n    \"startPeriod\": 60\n  }\n}\n```\n\n### TCP Health Check\n\n```json\n{\n  \"healthCheck\": {\n    \"command\": [\"CMD-SHELL\", \"nc -z localhost 8080 || exit 1\"],\n    \"interval\": 30,\n    \"timeout\": 5,\n    \"retries\": 3\n  }\n}\n```\n\n### Script-Based Health Check\n\n```json\n{\n  \"healthCheck\": {\n    \"command\": [\"CMD\", \"/app/healthcheck.sh\"],\n    \"interval\": 30,\n    \"timeout\": 10,\n    \"retries\": 3,\n    \"startPeriod\": 120\n  }\n}\n```\n\n## Container Dependencies\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"name\": \"database\",\n      \"essential\": true,\n      \"healthCheck\": {...}\n    },\n    {\n      \"name\": \"cache\",\n      \"essential\": false,\n      \"dependsOn\": [\n        {\"containerName\": \"database\", \"condition\": \"HEALTHY\"}\n      ]\n    },\n    {\n      \"name\": \"app\",\n      \"essential\": true,\n      \"dependsOn\": [\n        {\"containerName\": \"database\", \"condition\": \"HEALTHY\"},\n        {\"containerName\": \"cache\", \"condition\": \"START\"}\n      ]\n    }\n  ]\n}\n```\n\nConditions:\n- `START`: Container has started\n- `COMPLETE`: Container ran and exited with code 0\n- `SUCCESS`: Container completed successfully\n- `HEALTHY`: Container health check passed\n",
        "skills/eks/SKILL.md": "---\nname: eks\ndescription: AWS EKS Kubernetes management for clusters, node groups, and workloads. Use when creating clusters, configuring IRSA, managing node groups, deploying applications, or integrating with AWS services.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/eks/latest/userguide/\n---\n\n# AWS EKS\n\nAmazon Elastic Kubernetes Service (EKS) runs Kubernetes without installing and operating your own control plane. EKS manages the control plane and integrates with AWS services.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Control Plane\n\nManaged by AWS. Runs Kubernetes API server, etcd, and controllers across multiple AZs.\n\n### Node Groups\n\n| Type | Description |\n|------|-------------|\n| **Managed** | AWS manages provisioning, updates |\n| **Self-managed** | You manage EC2 instances |\n| **Fargate** | Serverless, per-pod compute |\n\n### IRSA (IAM Roles for Service Accounts)\n\nAssociates Kubernetes service accounts with IAM roles for fine-grained AWS permissions.\n\n### Add-ons\n\nOperational software: CoreDNS, kube-proxy, VPC CNI, EBS CSI driver.\n\n## Common Patterns\n\n### Create a Cluster\n\n**AWS CLI:**\n\n```bash\n# Create cluster role\naws iam create-role \\\n  --role-name eks-cluster-role \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"eks.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }]\n  }'\n\naws iam attach-role-policy \\\n  --role-name eks-cluster-role \\\n  --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\n\n# Create cluster\naws eks create-cluster \\\n  --name my-cluster \\\n  --role-arn arn:aws:iam::123456789012:role/eks-cluster-role \\\n  --resources-vpc-config subnetIds=subnet-12345678,subnet-87654321,securityGroupIds=sg-12345678\n\n# Wait for cluster\naws eks wait cluster-active --name my-cluster\n\n# Update kubeconfig\naws eks update-kubeconfig --name my-cluster --region us-east-1\n```\n\n**eksctl (Recommended):**\n\n```bash\n# Create cluster with managed node group\neksctl create cluster \\\n  --name my-cluster \\\n  --region us-east-1 \\\n  --version 1.29 \\\n  --nodegroup-name standard-workers \\\n  --node-type t3.medium \\\n  --nodes 3 \\\n  --nodes-min 1 \\\n  --nodes-max 5 \\\n  --managed\n```\n\n### Add Managed Node Group\n\n```bash\n# Create node role\naws iam create-role \\\n  --role-name eks-node-role \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"ec2.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }]\n  }'\n\naws iam attach-role-policy --role-name eks-node-role --policy-arn arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\naws iam attach-role-policy --role-name eks-node-role --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\naws iam attach-role-policy --role-name eks-node-role --policy-arn arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\n\n# Create node group\naws eks create-nodegroup \\\n  --cluster-name my-cluster \\\n  --nodegroup-name standard-workers \\\n  --node-role arn:aws:iam::123456789012:role/eks-node-role \\\n  --subnets subnet-12345678 subnet-87654321 \\\n  --instance-types t3.medium \\\n  --scaling-config minSize=1,maxSize=5,desiredSize=3 \\\n  --ami-type AL2_x86_64\n```\n\n### Configure IRSA\n\n```bash\n# Enable OIDC provider\neksctl utils associate-iam-oidc-provider \\\n  --cluster my-cluster \\\n  --approve\n\n# Create IAM role for service account\neksctl create iamserviceaccount \\\n  --cluster my-cluster \\\n  --namespace default \\\n  --name my-app-sa \\\n  --attach-policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess \\\n  --approve\n```\n\n**Manual IRSA setup:**\n\n```bash\n# Get OIDC issuer\nOIDC_ISSUER=$(aws eks describe-cluster --name my-cluster --query \"cluster.identity.oidc.issuer\" --output text)\nOIDC_ID=${OIDC_ISSUER##*/}\n\n# Create trust policy\ncat > trust-policy.json << EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Principal\": {\n      \"Federated\": \"arn:aws:iam::123456789012:oidc-provider/oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}\"\n    },\n    \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n    \"Condition\": {\n      \"StringEquals\": {\n        \"oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}:sub\": \"system:serviceaccount:default:my-app-sa\",\n        \"oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}:aud\": \"sts.amazonaws.com\"\n      }\n    }\n  }]\n}\nEOF\n\naws iam create-role --role-name my-app-role --assume-role-policy-document file://trust-policy.json\n```\n\n### Kubernetes Service Account\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: my-app-sa\n  namespace: default\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/my-app-role\n```\n\n### Install Add-ons\n\n```bash\n# CoreDNS\naws eks create-addon \\\n  --cluster-name my-cluster \\\n  --addon-name coredns \\\n  --addon-version v1.11.1-eksbuild.4\n\n# VPC CNI\naws eks create-addon \\\n  --cluster-name my-cluster \\\n  --addon-name vpc-cni \\\n  --addon-version v1.16.0-eksbuild.1\n\n# kube-proxy\naws eks create-addon \\\n  --cluster-name my-cluster \\\n  --addon-name kube-proxy \\\n  --addon-version v1.29.0-eksbuild.1\n\n# EBS CSI Driver\naws eks create-addon \\\n  --cluster-name my-cluster \\\n  --addon-name aws-ebs-csi-driver \\\n  --addon-version v1.27.0-eksbuild.1 \\\n  --service-account-role-arn arn:aws:iam::123456789012:role/ebs-csi-role\n```\n\n### Deploy Application\n\n```yaml\n# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      serviceAccountName: my-app-sa\n      containers:\n      - name: app\n        image: 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-app:latest\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: nlb\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: my-app\n```\n\n## CLI Reference\n\n### Cluster Management\n\n| Command | Description |\n|---------|-------------|\n| `aws eks create-cluster` | Create cluster |\n| `aws eks describe-cluster` | Get cluster details |\n| `aws eks update-cluster-config` | Update cluster settings |\n| `aws eks delete-cluster` | Delete cluster |\n| `aws eks update-kubeconfig` | Configure kubectl |\n\n### Node Groups\n\n| Command | Description |\n|---------|-------------|\n| `aws eks create-nodegroup` | Create node group |\n| `aws eks describe-nodegroup` | Get node group details |\n| `aws eks update-nodegroup-config` | Update node group |\n| `aws eks delete-nodegroup` | Delete node group |\n\n### Add-ons\n\n| Command | Description |\n|---------|-------------|\n| `aws eks create-addon` | Install add-on |\n| `aws eks describe-addon` | Get add-on details |\n| `aws eks update-addon` | Update add-on |\n| `aws eks delete-addon` | Remove add-on |\n\n## Best Practices\n\n### Security\n\n- **Use IRSA** for pod-level AWS permissions\n- **Enable cluster encryption** with KMS\n- **Use private endpoint** for API server\n- **Enable audit logging** to CloudWatch\n- **Use security groups for pods**\n- **Implement network policies**\n\n```bash\n# Enable secrets encryption\naws eks create-cluster \\\n  --name my-cluster \\\n  --encryption-config '[{\n    \"provider\": {\"keyArn\": \"arn:aws:kms:us-east-1:123456789012:key/...\"},\n    \"resources\": [\"secrets\"]\n  }]' \\\n  ...\n```\n\n### High Availability\n\n- **Deploy across multiple AZs**\n- **Use managed node groups**\n- **Set pod disruption budgets**\n- **Configure horizontal pod autoscaling**\n\n### Cost Optimization\n\n- **Use Spot instances** for non-critical workloads\n- **Right-size nodes and pods**\n- **Use Fargate** for variable workloads\n- **Implement cluster autoscaler**\n- **Use Karpenter** for efficient scaling\n\n## Troubleshooting\n\n### Cannot Connect to Cluster\n\n```bash\n# Verify kubeconfig\naws eks update-kubeconfig --name my-cluster --region us-east-1\n\n# Check IAM identity\naws sts get-caller-identity\n\n# Verify cluster status\naws eks describe-cluster --name my-cluster --query 'cluster.status'\n```\n\n### Nodes Not Joining\n\n**Check:**\n- Node IAM role has required policies\n- Security groups allow node-to-control-plane communication\n- Nodes have network access to API server\n\n```bash\n# Check node status\nkubectl get nodes\n\n# Check aws-auth ConfigMap\nkubectl describe configmap aws-auth -n kube-system\n\n# Check node logs (SSH to node)\njournalctl -u kubelet\n```\n\n### Pod Cannot Access AWS Services\n\n```bash\n# Verify IRSA setup\nkubectl describe sa my-app-sa\n\n# Check pod environment\nkubectl exec my-pod -- env | grep AWS\n\n# Test credentials\nkubectl exec my-pod -- aws sts get-caller-identity\n```\n\n### DNS Issues\n\n```bash\n# Check CoreDNS pods\nkubectl get pods -n kube-system -l k8s-app=kube-dns\n\n# Test DNS resolution\nkubectl run test --image=busybox:1.28 --rm -it -- nslookup kubernetes\n\n# Check CoreDNS logs\nkubectl logs -n kube-system -l k8s-app=kube-dns\n```\n\n## References\n\n- [EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/)\n- [EKS API Reference](https://docs.aws.amazon.com/eks/latest/APIReference/)\n- [EKS CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/eks/)\n- [eksctl](https://eksctl.io/)\n- [EKS Best Practices Guide](https://aws.github.io/aws-eks-best-practices/)\n",
        "skills/eks/cluster-setup.md": "# EKS Cluster Setup\n\nComprehensive cluster configuration and setup patterns.\n\n## Cluster Architecture Options\n\n### Public Cluster\n\nAPI server accessible from internet, nodes in public subnets.\n\n```bash\neksctl create cluster \\\n  --name my-cluster \\\n  --region us-east-1 \\\n  --nodegroup-name standard-workers \\\n  --node-type t3.medium \\\n  --nodes 3\n```\n\n### Private Cluster\n\nAPI server only accessible from VPC.\n\n```bash\neksctl create cluster \\\n  --name my-cluster \\\n  --region us-east-1 \\\n  --nodegroup-name standard-workers \\\n  --node-type t3.medium \\\n  --nodes 3 \\\n  --node-private-networking \\\n  --vpc-private-subnets subnet-private1,subnet-private2\n```\n\n### Fully Private Cluster\n\nNo public access at all, requires VPN/Direct Connect.\n\n```bash\naws eks create-cluster \\\n  --name my-cluster \\\n  --role-arn arn:aws:iam::123456789012:role/eks-cluster-role \\\n  --resources-vpc-config \\\n    subnetIds=subnet-private1,subnet-private2,\\\n    endpointPublicAccess=false,\\\n    endpointPrivateAccess=true\n```\n\n## VPC Configuration\n\n### Required Subnets\n\n- **Control plane**: Needs subnets in at least 2 AZs\n- **Worker nodes**: Can be public or private\n- **Load balancers**: Need subnets tagged appropriately\n\n### Subnet Tags\n\n```bash\n# Public subnets (for public load balancers)\naws ec2 create-tags \\\n  --resources subnet-12345678 \\\n  --tags Key=kubernetes.io/role/elb,Value=1\n\n# Private subnets (for internal load balancers)\naws ec2 create-tags \\\n  --resources subnet-87654321 \\\n  --tags Key=kubernetes.io/role/internal-elb,Value=1\n\n# Cluster ownership (required for all subnets)\naws ec2 create-tags \\\n  --resources subnet-12345678 subnet-87654321 \\\n  --tags Key=kubernetes.io/cluster/my-cluster,Value=shared\n```\n\n### VPC CNI Configuration\n\n```bash\n# Enable prefix delegation for more IPs per node\nkubectl set env daemonset aws-node \\\n  -n kube-system \\\n  ENABLE_PREFIX_DELEGATION=true\n\n# Configure custom networking (pods in different subnets)\nkubectl set env daemonset aws-node \\\n  -n kube-system \\\n  AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true\n```\n\n## Node Groups\n\n### Managed Node Group with Launch Template\n\n```bash\n# Create launch template\naws ec2 create-launch-template \\\n  --launch-template-name eks-node-template \\\n  --launch-template-data '{\n    \"BlockDeviceMappings\": [{\n      \"DeviceName\": \"/dev/xvda\",\n      \"Ebs\": {\"VolumeSize\": 100, \"VolumeType\": \"gp3\", \"Encrypted\": true}\n    }],\n    \"MetadataOptions\": {\n      \"HttpTokens\": \"required\",\n      \"HttpEndpoint\": \"enabled\"\n    }\n  }'\n\n# Create node group with launch template\naws eks create-nodegroup \\\n  --cluster-name my-cluster \\\n  --nodegroup-name custom-workers \\\n  --node-role arn:aws:iam::123456789012:role/eks-node-role \\\n  --subnets subnet-12345678 subnet-87654321 \\\n  --launch-template name=eks-node-template,version=1 \\\n  --scaling-config minSize=1,maxSize=10,desiredSize=3\n```\n\n### Spot Instances\n\n```bash\neksctl create nodegroup \\\n  --cluster my-cluster \\\n  --name spot-workers \\\n  --node-type t3.medium,t3.large,t3a.medium,t3a.large \\\n  --nodes 3 \\\n  --spot\n```\n\n### ARM64 (Graviton)\n\n```bash\naws eks create-nodegroup \\\n  --cluster-name my-cluster \\\n  --nodegroup-name graviton-workers \\\n  --node-role arn:aws:iam::123456789012:role/eks-node-role \\\n  --subnets subnet-12345678 \\\n  --ami-type AL2_ARM_64 \\\n  --instance-types t4g.medium m6g.medium\n```\n\n### GPU Nodes\n\n```bash\naws eks create-nodegroup \\\n  --cluster-name my-cluster \\\n  --nodegroup-name gpu-workers \\\n  --node-role arn:aws:iam::123456789012:role/eks-node-role \\\n  --subnets subnet-12345678 \\\n  --ami-type AL2_x86_64_GPU \\\n  --instance-types p3.2xlarge g4dn.xlarge \\\n  --scaling-config minSize=0,maxSize=5,desiredSize=0\n```\n\n## Fargate\n\n### Create Fargate Profile\n\n```bash\n# Create pod execution role\naws iam create-role \\\n  --role-name eks-fargate-role \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"eks-fargate-pods.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }]\n  }'\n\naws iam attach-role-policy \\\n  --role-name eks-fargate-role \\\n  --policy-arn arn:aws:iam::aws:policy/AmazonEKSFargatePodExecutionRolePolicy\n\n# Create Fargate profile\naws eks create-fargate-profile \\\n  --cluster-name my-cluster \\\n  --fargate-profile-name default-fargate \\\n  --pod-execution-role-arn arn:aws:iam::123456789012:role/eks-fargate-role \\\n  --subnets subnet-private1 subnet-private2 \\\n  --selectors namespace=default,labels={compute=fargate}\n```\n\n### Deploy to Fargate\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: fargate-pod\n  labels:\n    compute: fargate  # Matches Fargate profile selector\nspec:\n  containers:\n  - name: app\n    image: nginx\n```\n\n## Cluster Autoscaler\n\n```bash\n# Create IRSA for cluster autoscaler\neksctl create iamserviceaccount \\\n  --cluster my-cluster \\\n  --namespace kube-system \\\n  --name cluster-autoscaler \\\n  --attach-policy-arn arn:aws:iam::123456789012:policy/ClusterAutoscalerPolicy \\\n  --approve\n\n# Deploy cluster autoscaler\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml\n\n# Configure for cluster\nkubectl -n kube-system annotate deployment cluster-autoscaler \\\n  cluster-autoscaler.kubernetes.io/safe-to-evict=\"false\"\n\nkubectl -n kube-system set env deployment cluster-autoscaler \\\n  AWS_REGION=us-east-1 \\\n  CLUSTER_NAME=my-cluster\n```\n\n## Karpenter (Recommended)\n\n```bash\n# Install Karpenter\nhelm install karpenter oci://public.ecr.aws/karpenter/karpenter \\\n  --namespace karpenter --create-namespace \\\n  --set settings.clusterName=my-cluster \\\n  --set settings.clusterEndpoint=$(aws eks describe-cluster --name my-cluster --query \"cluster.endpoint\" --output text) \\\n  --set serviceAccount.annotations.\"eks\\.amazonaws\\.com/role-arn\"=arn:aws:iam::123456789012:role/karpenter-role\n\n# Create NodePool\ncat <<EOF | kubectl apply -f -\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  template:\n    spec:\n      requirements:\n        - key: kubernetes.io/arch\n          operator: In\n          values: [\"amd64\", \"arm64\"]\n        - key: karpenter.sh/capacity-type\n          operator: In\n          values: [\"spot\", \"on-demand\"]\n      nodeClassRef:\n        name: default\n  limits:\n    cpu: 1000\n  disruption:\n    consolidationPolicy: WhenUnderutilized\nEOF\n```\n\n## Load Balancer Controller\n\n```bash\n# Create IRSA\neksctl create iamserviceaccount \\\n  --cluster my-cluster \\\n  --namespace kube-system \\\n  --name aws-load-balancer-controller \\\n  --attach-policy-arn arn:aws:iam::123456789012:policy/AWSLoadBalancerControllerIAMPolicy \\\n  --approve\n\n# Install controller\nhelm install aws-load-balancer-controller \\\n  eks/aws-load-balancer-controller \\\n  -n kube-system \\\n  --set clusterName=my-cluster \\\n  --set serviceAccount.create=false \\\n  --set serviceAccount.name=aws-load-balancer-controller\n```\n\n### Ingress Example\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-service\n            port:\n              number: 80\n```\n\n## Logging and Monitoring\n\n### Enable Control Plane Logging\n\n```bash\naws eks update-cluster-config \\\n  --name my-cluster \\\n  --logging '{\n    \"clusterLogging\": [{\n      \"types\": [\"api\", \"audit\", \"authenticator\", \"controllerManager\", \"scheduler\"],\n      \"enabled\": true\n    }]\n  }'\n```\n\n### Container Insights\n\n```bash\n# Install CloudWatch agent and Fluent Bit\ncurl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | \\\n  sed \"s/{{cluster_name}}/my-cluster/g; s/{{region_name}}/us-east-1/g\" | \\\n  kubectl apply -f -\n```\n\n## Security\n\n### Secrets Encryption\n\n```bash\n# Create KMS key\naws kms create-key --description \"EKS secrets encryption\"\n\n# Enable encryption\naws eks create-cluster \\\n  --name my-cluster \\\n  --encryption-config '[{\n    \"provider\": {\"keyArn\": \"arn:aws:kms:us-east-1:123456789012:key/...\"},\n    \"resources\": [\"secrets\"]\n  }]' \\\n  ...\n```\n\n### Security Groups for Pods\n\n```bash\n# Enable security groups for pods\naws eks update-cluster-config \\\n  --name my-cluster \\\n  --resources-vpc-config \\\n    endpointPublicAccess=true,\\\n    endpointPrivateAccess=true,\\\n    securityGroupIds=sg-12345678\n\n# Annotate node group\nkubectl annotate node <node> \\\n  vpc.amazonaws.com/pod-eni=enabled\n```\n",
        "skills/eventbridge/SKILL.md": "---\nname: eventbridge\ndescription: AWS EventBridge serverless event bus for event-driven architectures. Use when creating rules, configuring event patterns, setting up scheduled events, integrating with SaaS, or building cross-account event routing.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/eventbridge/latest/userguide/\n---\n\n# AWS EventBridge\n\nAmazon EventBridge is a serverless event bus that connects applications using events. Route events from AWS services, custom applications, and SaaS partners.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Event Bus\n\nChannel that receives events. Types:\n- **Default**: Receives AWS service events\n- **Custom**: Your application events\n- **Partner**: SaaS application events\n\n### Rules\n\nMatch incoming events and route to targets. Each rule can have up to 5 targets.\n\n### Event Patterns\n\nJSON patterns that define which events match a rule.\n\n### Targets\n\nAWS services that receive matched events (Lambda, SQS, SNS, Step Functions, etc.).\n\n### Scheduler\n\nSchedule one-time or recurring events to invoke targets.\n\n## Common Patterns\n\n### Create Custom Event Bus and Rule\n\n**AWS CLI:**\n\n```bash\n# Create custom event bus\naws events create-event-bus --name my-app-events\n\n# Create rule\naws events put-rule \\\n  --name order-created-rule \\\n  --event-bus-name my-app-events \\\n  --event-pattern '{\n    \"source\": [\"my-app.orders\"],\n    \"detail-type\": [\"Order Created\"]\n  }'\n\n# Add Lambda target\naws events put-targets \\\n  --rule order-created-rule \\\n  --event-bus-name my-app-events \\\n  --targets '[{\n    \"Id\": \"process-order\",\n    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder\"\n  }]'\n\n# Add Lambda permission\naws lambda add-permission \\\n  --function-name ProcessOrder \\\n  --statement-id eventbridge-order-created \\\n  --action lambda:InvokeFunction \\\n  --principal events.amazonaws.com \\\n  --source-arn arn:aws:events:us-east-1:123456789012:rule/my-app-events/order-created-rule\n```\n\n**boto3:**\n\n```python\nimport boto3\n\nevents = boto3.client('events')\n\n# Create event bus\nevents.create_event_bus(Name='my-app-events')\n\n# Create rule\nevents.put_rule(\n    Name='order-created-rule',\n    EventBusName='my-app-events',\n    EventPattern=json.dumps({\n        'source': ['my-app.orders'],\n        'detail-type': ['Order Created']\n    }),\n    State='ENABLED'\n)\n\n# Add target\nevents.put_targets(\n    Rule='order-created-rule',\n    EventBusName='my-app-events',\n    Targets=[{\n        'Id': 'process-order',\n        'Arn': 'arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder'\n    }]\n)\n```\n\n### Publish Custom Events\n\n```python\nimport boto3\nimport json\n\nevents = boto3.client('events')\n\nevents.put_events(\n    Entries=[\n        {\n            'Source': 'my-app.orders',\n            'DetailType': 'Order Created',\n            'Detail': json.dumps({\n                'order_id': '12345',\n                'customer_id': 'cust-789',\n                'total': 99.99,\n                'items': [\n                    {'product_id': 'prod-1', 'quantity': 2}\n                ]\n            }),\n            'EventBusName': 'my-app-events'\n        }\n    ]\n)\n```\n\n### Scheduled Events\n\n```bash\n# Run every 5 minutes\naws events put-rule \\\n  --name every-5-minutes \\\n  --schedule-expression \"rate(5 minutes)\"\n\n# Run at specific times (cron)\naws events put-rule \\\n  --name daily-cleanup \\\n  --schedule-expression \"cron(0 2 * * ? *)\"\n\n# Add target\naws events put-targets \\\n  --rule every-5-minutes \\\n  --targets '[{\n    \"Id\": \"cleanup-function\",\n    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:Cleanup\"\n  }]'\n```\n\n### EventBridge Scheduler (One-Time and Flexible)\n\n```bash\n# One-time schedule\naws scheduler create-schedule \\\n  --name send-reminder \\\n  --schedule-expression \"at(2024-12-25T09:00:00)\" \\\n  --target '{\n    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:SendReminder\",\n    \"RoleArn\": \"arn:aws:iam::123456789012:role/scheduler-role\",\n    \"Input\": \"{\\\"message\\\": \\\"Merry Christmas!\\\"}\"\n  }' \\\n  --flexible-time-window '{\"Mode\": \"OFF\"}'\n\n# Recurring with flexible window\naws scheduler create-schedule \\\n  --name hourly-sync \\\n  --schedule-expression \"rate(1 hour)\" \\\n  --target '{\n    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:SyncData\",\n    \"RoleArn\": \"arn:aws:iam::123456789012:role/scheduler-role\"\n  }' \\\n  --flexible-time-window '{\"Mode\": \"FLEXIBLE\", \"MaximumWindowInMinutes\": 15}'\n```\n\n### AWS Service Events\n\n```bash\n# EC2 state changes\naws events put-rule \\\n  --name ec2-state-change \\\n  --event-pattern '{\n    \"source\": [\"aws.ec2\"],\n    \"detail-type\": [\"EC2 Instance State-change Notification\"],\n    \"detail\": {\n      \"state\": [\"stopped\", \"terminated\"]\n    }\n  }'\n\n# S3 object created\naws events put-rule \\\n  --name s3-upload \\\n  --event-pattern '{\n    \"source\": [\"aws.s3\"],\n    \"detail-type\": [\"Object Created\"],\n    \"detail\": {\n      \"bucket\": {\"name\": [\"my-bucket\"]},\n      \"object\": {\"key\": [{\"prefix\": \"uploads/\"}]}\n    }\n  }'\n```\n\n## CLI Reference\n\n### Event Buses\n\n| Command | Description |\n|---------|-------------|\n| `aws events create-event-bus` | Create event bus |\n| `aws events delete-event-bus` | Delete event bus |\n| `aws events list-event-buses` | List event buses |\n| `aws events describe-event-bus` | Get event bus details |\n\n### Rules\n\n| Command | Description |\n|---------|-------------|\n| `aws events put-rule` | Create or update rule |\n| `aws events delete-rule` | Delete rule |\n| `aws events list-rules` | List rules |\n| `aws events describe-rule` | Get rule details |\n| `aws events enable-rule` | Enable rule |\n| `aws events disable-rule` | Disable rule |\n\n### Targets\n\n| Command | Description |\n|---------|-------------|\n| `aws events put-targets` | Add targets to rule |\n| `aws events remove-targets` | Remove targets |\n| `aws events list-targets-by-rule` | List rule targets |\n\n### Events\n\n| Command | Description |\n|---------|-------------|\n| `aws events put-events` | Publish events |\n\n## Best Practices\n\n### Event Design\n\n- **Use meaningful source names** â€” `company.service.component`\n- **Use descriptive detail-types** â€” `Order Created`, `User Signed Up`\n- **Include correlation IDs** for tracing\n- **Keep events small** (< 256 KB)\n- **Use versioning** for event schemas\n\n```python\n# Good event structure\n{\n    'Source': 'mycompany.orders.api',\n    'DetailType': 'Order Created',\n    'Detail': json.dumps({\n        'version': '1.0',\n        'correlation_id': 'req-abc-123',\n        'timestamp': '2024-01-15T10:30:00Z',\n        'order_id': '12345',\n        'data': {...}\n    })\n}\n```\n\n### Reliability\n\n- **Use DLQs** for failed deliveries\n- **Implement idempotency** in consumers\n- **Monitor failed invocations**\n- **Use archive and replay** for recovery\n\n### Security\n\n- **Use resource policies** to control access\n- **Enable encryption** with KMS\n- **Use IAM roles** for targets\n\n### Cost Optimization\n\n- **Use specific event patterns** to reduce matches\n- **Batch events** when publishing (up to 10 per call)\n- **Archive selectively** â€” not all events\n\n## Troubleshooting\n\n### Rule Not Triggering\n\n**Debug:**\n\n```bash\n# Check rule status\naws events describe-rule --name my-rule\n\n# Check targets\naws events list-targets-by-rule --rule my-rule\n\n# Test event pattern\naws events test-event-pattern \\\n  --event-pattern '{\"source\": [\"my-app\"]}' \\\n  --event '{\"source\": \"my-app\", \"detail-type\": \"Test\"}'\n```\n\n**Common causes:**\n- Rule disabled\n- Event pattern doesn't match\n- Target permissions missing\n\n### Lambda Not Invoked\n\n**Check Lambda permissions:**\n\n```bash\naws lambda get-policy --function-name MyFunction\n```\n\n**Required permission:**\n\n```json\n{\n  \"Principal\": \"events.amazonaws.com\",\n  \"Action\": \"lambda:InvokeFunction\",\n  \"Resource\": \"function-arn\",\n  \"Condition\": {\n    \"ArnLike\": {\n      \"AWS:SourceArn\": \"rule-arn\"\n    }\n  }\n}\n```\n\n### Events Not Reaching Custom Bus\n\n**Check:**\n- Publishing to correct bus name\n- Event format is valid JSON\n- Put events has proper permissions\n\n```bash\n# Test publish\naws events put-events \\\n  --entries '[{\n    \"Source\": \"test\",\n    \"DetailType\": \"Test Event\",\n    \"Detail\": \"{}\",\n    \"EventBusName\": \"my-app-events\"\n  }]'\n```\n\n### Viewing Failed Events\n\n```bash\n# Enable CloudWatch metrics\naws events put-rule \\\n  --name my-rule \\\n  --event-pattern '...' \\\n  --state ENABLED\n\n# Check FailedInvocations metric\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Events \\\n  --metric-name FailedInvocations \\\n  --dimensions Name=RuleName,Value=my-rule \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n```\n\n## References\n\n- [EventBridge User Guide](https://docs.aws.amazon.com/eventbridge/latest/userguide/)\n- [EventBridge API Reference](https://docs.aws.amazon.com/eventbridge/latest/APIReference/)\n- [EventBridge CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/events/)\n- [boto3 EventBridge](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/events.html)\n- [Event Pattern Reference](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html)\n",
        "skills/eventbridge/event-patterns.md": "# EventBridge Event Patterns\n\nComprehensive guide to event pattern matching.\n\n## Pattern Syntax\n\n### Exact Match\n\n```json\n{\n  \"source\": [\"my-app.orders\"]\n}\n```\n\n### Multiple Values (OR)\n\n```json\n{\n  \"source\": [\"my-app.orders\", \"my-app.inventory\"]\n}\n```\n\n### Nested Fields\n\n```json\n{\n  \"detail\": {\n    \"order\": {\n      \"status\": [\"completed\", \"cancelled\"]\n    }\n  }\n}\n```\n\n### Prefix Match\n\n```json\n{\n  \"source\": [{\"prefix\": \"my-app.\"}]\n}\n```\n\n### Suffix Match\n\n```json\n{\n  \"detail\": {\n    \"filename\": [{\"suffix\": \".pdf\"}]\n  }\n}\n```\n\n### Anything-But\n\n```json\n{\n  \"detail\": {\n    \"status\": [{\"anything-but\": [\"test\", \"draft\"]}]\n  }\n}\n```\n\n### Numeric Matching\n\n```json\n{\n  \"detail\": {\n    \"price\": [{\"numeric\": [\">=\", 100]}],\n    \"quantity\": [{\"numeric\": [\">\", 0, \"<=\", 100]}]\n  }\n}\n```\n\n### Exists\n\n```json\n{\n  \"detail\": {\n    \"customer_id\": [{\"exists\": true}],\n    \"discount_code\": [{\"exists\": false}]\n  }\n}\n```\n\n### IP Address Matching\n\n```json\n{\n  \"detail\": {\n    \"source_ip\": [{\"cidr\": \"10.0.0.0/8\"}]\n  }\n}\n```\n\n### Empty Array/String\n\n```json\n{\n  \"detail\": {\n    \"tags\": [{\"equals-ignore-case\": \"\"}]\n  }\n}\n```\n\n### Case-Insensitive\n\n```json\n{\n  \"detail\": {\n    \"action\": [{\"equals-ignore-case\": \"CREATE\"}]\n  }\n}\n```\n\n### Wildcard\n\n```json\n{\n  \"detail\": {\n    \"key\": [{\"wildcard\": \"prod-*-us-east-1\"}]\n  }\n}\n```\n\n## AWS Service Event Patterns\n\n### EC2 State Changes\n\n```json\n{\n  \"source\": [\"aws.ec2\"],\n  \"detail-type\": [\"EC2 Instance State-change Notification\"],\n  \"detail\": {\n    \"state\": [\"running\", \"stopped\", \"terminated\"]\n  }\n}\n```\n\n### S3 Object Events\n\n```json\n{\n  \"source\": [\"aws.s3\"],\n  \"detail-type\": [\"Object Created\"],\n  \"detail\": {\n    \"bucket\": {\n      \"name\": [\"my-bucket\"]\n    },\n    \"object\": {\n      \"key\": [{\"prefix\": \"uploads/\"}]\n    }\n  }\n}\n```\n\n### CodePipeline State Changes\n\n```json\n{\n  \"source\": [\"aws.codepipeline\"],\n  \"detail-type\": [\"CodePipeline Pipeline Execution State Change\"],\n  \"detail\": {\n    \"state\": [\"FAILED\", \"SUCCEEDED\"],\n    \"pipeline\": [\"my-pipeline\"]\n  }\n}\n```\n\n### ECS Task State Changes\n\n```json\n{\n  \"source\": [\"aws.ecs\"],\n  \"detail-type\": [\"ECS Task State Change\"],\n  \"detail\": {\n    \"clusterArn\": [{\"suffix\": \"/my-cluster\"}],\n    \"lastStatus\": [\"RUNNING\", \"STOPPED\"]\n  }\n}\n```\n\n### CloudWatch Alarm State Changes\n\n```json\n{\n  \"source\": [\"aws.cloudwatch\"],\n  \"detail-type\": [\"CloudWatch Alarm State Change\"],\n  \"detail\": {\n    \"state\": {\n      \"value\": [\"ALARM\"]\n    }\n  }\n}\n```\n\n### RDS Events\n\n```json\n{\n  \"source\": [\"aws.rds\"],\n  \"detail-type\": [\"RDS DB Instance Event\"],\n  \"detail\": {\n    \"EventCategories\": [\"failover\", \"failure\"]\n  }\n}\n```\n\n### Lambda Function Events\n\n```json\n{\n  \"source\": [\"aws.lambda\"],\n  \"detail-type\": [\"Lambda Function Invocation Result - Failure\"]\n}\n```\n\n### Secrets Manager Rotation\n\n```json\n{\n  \"source\": [\"aws.secretsmanager\"],\n  \"detail-type\": [\"AWS API Call via CloudTrail\"],\n  \"detail\": {\n    \"eventSource\": [\"secretsmanager.amazonaws.com\"],\n    \"eventName\": [\"RotateSecret\"]\n  }\n}\n```\n\n## Complex Patterns\n\n### Combined Conditions\n\n```json\n{\n  \"source\": [\"my-app.orders\"],\n  \"detail-type\": [\"Order Created\"],\n  \"detail\": {\n    \"order\": {\n      \"total\": [{\"numeric\": [\">=\", 100]}],\n      \"region\": [\"us-east-1\", \"us-west-2\"],\n      \"priority\": [{\"anything-but\": [\"low\"]}],\n      \"expedited\": [{\"exists\": true}]\n    }\n  }\n}\n```\n\n### Content-Based Routing\n\n```json\n// Route high-value orders\n{\n  \"source\": [\"ecommerce.orders\"],\n  \"detail-type\": [\"Order Placed\"],\n  \"detail\": {\n    \"total\": [{\"numeric\": [\">=\", 1000]}],\n    \"customer_tier\": [\"premium\", \"enterprise\"]\n  }\n}\n\n// Route standard orders\n{\n  \"source\": [\"ecommerce.orders\"],\n  \"detail-type\": [\"Order Placed\"],\n  \"detail\": {\n    \"total\": [{\"numeric\": [\"<\", 1000]}]\n  }\n}\n```\n\n## Event Structure\n\n### Standard Event Format\n\n```json\n{\n  \"version\": \"0\",\n  \"id\": \"12345678-1234-1234-1234-123456789012\",\n  \"detail-type\": \"Order Created\",\n  \"source\": \"my-app.orders\",\n  \"account\": \"123456789012\",\n  \"time\": \"2024-01-15T10:30:00Z\",\n  \"region\": \"us-east-1\",\n  \"resources\": [\n    \"arn:aws:dynamodb:us-east-1:123456789012:table/Orders\"\n  ],\n  \"detail\": {\n    \"order_id\": \"12345\",\n    \"customer_id\": \"cust-789\",\n    \"items\": [...],\n    \"total\": 99.99\n  }\n}\n```\n\n### Custom Event with Metadata\n\n```python\nimport boto3\nimport json\nfrom datetime import datetime\n\nevents = boto3.client('events')\n\nevents.put_events(\n    Entries=[{\n        'Source': 'mycompany.orders.api',\n        'DetailType': 'Order Created',\n        'Time': datetime.utcnow(),\n        'Resources': [\n            f'arn:aws:dynamodb:us-east-1:123456789012:table/Orders/item/{order_id}'\n        ],\n        'Detail': json.dumps({\n            'version': '1.0',\n            'metadata': {\n                'correlation_id': correlation_id,\n                'trace_id': trace_id,\n                'user_agent': user_agent\n            },\n            'data': {\n                'order_id': order_id,\n                'customer_id': customer_id,\n                'items': items,\n                'total': total\n            }\n        }),\n        'EventBusName': 'orders-bus'\n    }]\n)\n```\n\n## Input Transformation\n\n### Transform Event for Target\n\n```bash\naws events put-targets \\\n  --rule my-rule \\\n  --targets '[{\n    \"Id\": \"1\",\n    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder\",\n    \"InputTransformer\": {\n      \"InputPathsMap\": {\n        \"orderId\": \"$.detail.order_id\",\n        \"customerId\": \"$.detail.customer_id\",\n        \"total\": \"$.detail.total\"\n      },\n      \"InputTemplate\": \"{\\\"order\\\": {\\\"id\\\": <orderId>, \\\"customer\\\": <customerId>, \\\"amount\\\": <total>}}\"\n    }\n  }]'\n```\n\n### Pass Static Input\n\n```json\n{\n  \"Id\": \"1\",\n  \"Arn\": \"arn:aws:lambda:...\",\n  \"Input\": \"{\\\"action\\\": \\\"process\\\", \\\"source\\\": \\\"eventbridge\\\"}\"\n}\n```\n\n### Pass Matched Event\n\n```json\n{\n  \"Id\": \"1\",\n  \"Arn\": \"arn:aws:lambda:...\",\n  \"InputPath\": \"$.detail\"\n}\n```\n\n## Cross-Account Events\n\n### Send Events to Another Account\n\n```bash\n# In source account: create rule to forward\naws events put-rule \\\n  --name forward-to-central \\\n  --event-pattern '{\"source\": [\"my-app\"]}' \\\n  --event-bus-name default\n\naws events put-targets \\\n  --rule forward-to-central \\\n  --targets '[{\n    \"Id\": \"central-bus\",\n    \"Arn\": \"arn:aws:events:us-east-1:222222222222:event-bus/central-events\",\n    \"RoleArn\": \"arn:aws:iam::111111111111:role/EventBridgeCrossAccountRole\"\n  }]'\n\n# In target account: allow source account\naws events put-permission \\\n  --event-bus-name central-events \\\n  --action events:PutEvents \\\n  --principal 111111111111 \\\n  --statement-id allow-source-account\n```\n\n## Archive and Replay\n\n### Create Archive\n\n```bash\naws events create-archive \\\n  --archive-name order-events-archive \\\n  --event-source-arn arn:aws:events:us-east-1:123456789012:event-bus/orders-bus \\\n  --event-pattern '{\"source\": [\"my-app.orders\"]}' \\\n  --retention-days 30\n```\n\n### Replay Events\n\n```bash\naws events start-replay \\\n  --replay-name replay-jan-15 \\\n  --event-source-arn arn:aws:events:us-east-1:123456789012:event-bus/orders-bus \\\n  --destination '{\n    \"Arn\": \"arn:aws:events:us-east-1:123456789012:event-bus/orders-bus\"\n  }' \\\n  --event-start-time 2024-01-15T00:00:00Z \\\n  --event-end-time 2024-01-15T23:59:59Z\n```\n\n## Testing Patterns\n\n### Test Event Pattern Match\n\n```bash\naws events test-event-pattern \\\n  --event-pattern '{\n    \"source\": [\"my-app.orders\"],\n    \"detail\": {\n      \"total\": [{\"numeric\": [\">=\", 100]}]\n    }\n  }' \\\n  --event '{\n    \"source\": \"my-app.orders\",\n    \"detail-type\": \"Order Created\",\n    \"detail\": {\"order_id\": \"123\", \"total\": 150}\n  }'\n```\n\nReturns `true` if pattern matches.\n",
        "skills/iam/SKILL.md": "---\nname: iam\ndescription: AWS Identity and Access Management for users, roles, policies, and permissions. Use when creating IAM policies, configuring cross-account access, setting up service roles, troubleshooting permission errors, or managing access control.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/IAM/latest/UserGuide/\n---\n\n# AWS IAM\n\nAWS Identity and Access Management (IAM) enables secure access control to AWS services and resources. IAM is foundational to AWS securityâ€”every AWS API call is authenticated and authorized through IAM.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Principals\n\nEntities that can make requests to AWS: IAM users, roles, federated users, and applications.\n\n### Policies\n\nJSON documents defining permissions. Types:\n- **Identity-based**: Attached to users, groups, or roles\n- **Resource-based**: Attached to resources (S3 buckets, SQS queues)\n- **Permission boundaries**: Maximum permissions an identity can have\n- **Service control policies (SCPs)**: Organization-wide limits\n\n### Roles\n\nIdentities with permissions that can be assumed by trusted entities. No permanent credentialsâ€”uses temporary security tokens.\n\n### Trust Relationships\n\nDefine which principals can assume a role. Configured via the role's trust policy.\n\n## Common Patterns\n\n### Create a Service Role for Lambda\n\n**AWS CLI:**\n\n```bash\n# Create the trust policy\ncat > trust-policy.json << 'EOF'\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": { \"Service\": \"lambda.amazonaws.com\" },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n# Create the role\naws iam create-role \\\n  --role-name MyLambdaRole \\\n  --assume-role-policy-document file://trust-policy.json\n\n# Attach a managed policy\naws iam attach-role-policy \\\n  --role-name MyLambdaRole \\\n  --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport json\n\niam = boto3.client('iam')\n\ntrust_policy = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n\n# Create role\niam.create_role(\n    RoleName='MyLambdaRole',\n    AssumeRolePolicyDocument=json.dumps(trust_policy)\n)\n\n# Attach managed policy\niam.attach_role_policy(\n    RoleName='MyLambdaRole',\n    PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n)\n```\n\n### Create Custom Policy with Least Privilege\n\n```bash\ncat > policy.json << 'EOF'\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"dynamodb:GetItem\",\n        \"dynamodb:PutItem\",\n        \"dynamodb:Query\"\n      ],\n      \"Resource\": \"arn:aws:dynamodb:us-east-1:123456789012:table/MyTable\"\n    }\n  ]\n}\nEOF\n\naws iam create-policy \\\n  --policy-name MyDynamoDBPolicy \\\n  --policy-document file://policy.json\n```\n\n### Cross-Account Role Assumption\n\n```bash\n# In Account B (trusted account), create role with trust for Account A\ncat > cross-account-trust.json << 'EOF'\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": { \"AWS\": \"arn:aws:iam::111111111111:root\" },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": { \"sts:ExternalId\": \"unique-external-id\" }\n      }\n    }\n  ]\n}\nEOF\n\n# From Account A, assume the role\naws sts assume-role \\\n  --role-arn arn:aws:iam::222222222222:role/CrossAccountRole \\\n  --role-session-name MySession \\\n  --external-id unique-external-id\n```\n\n## CLI Reference\n\n### Essential Commands\n\n| Command | Description |\n|---------|-------------|\n| `aws iam create-role` | Create a new IAM role |\n| `aws iam create-policy` | Create a customer managed policy |\n| `aws iam attach-role-policy` | Attach a managed policy to a role |\n| `aws iam put-role-policy` | Add an inline policy to a role |\n| `aws iam get-role` | Get role details |\n| `aws iam list-roles` | List all roles |\n| `aws iam simulate-principal-policy` | Test policy permissions |\n| `aws sts assume-role` | Assume a role and get temporary credentials |\n| `aws sts get-caller-identity` | Get current identity |\n\n### Useful Flags\n\n- `--query`: Filter output with JMESPath\n- `--output table`: Human-readable output\n- `--no-cli-pager`: Disable pager for scripting\n\n## Best Practices\n\n### Security\n\n- **Never use root account** for daily tasks\n- **Enable MFA** for all human users\n- **Use roles** instead of long-term access keys\n- **Apply least privilege** â€” grant only required permissions\n- **Use conditions** to restrict access by IP, time, or MFA\n- **Rotate credentials** regularly\n- **Use permission boundaries** for delegated administration\n\n### Policy Design\n\n- Start with AWS managed policies, customize as needed\n- Use policy variables (`${aws:username}`) for dynamic policies\n- Prefer explicit denies for sensitive actions\n- Group related permissions logically\n\n### Monitoring\n\n- Enable **CloudTrail** for API auditing\n- Use **IAM Access Analyzer** to identify overly permissive policies\n- Review **credential reports** regularly\n- Set up alerts for root account usage\n\n## Troubleshooting\n\n### Access Denied Errors\n\n**Symptom:** `AccessDeniedException` or `UnauthorizedAccess`\n\n**Debug steps:**\n1. Verify identity: `aws sts get-caller-identity`\n2. Check attached policies: `aws iam list-attached-role-policies --role-name MyRole`\n3. Simulate the action:\n   ```bash\n   aws iam simulate-principal-policy \\\n     --policy-source-arn arn:aws:iam::123456789012:role/MyRole \\\n     --action-names dynamodb:GetItem \\\n     --resource-arns arn:aws:dynamodb:us-east-1:123456789012:table/MyTable\n   ```\n4. Check for explicit denies in SCPs or permission boundaries\n5. Verify resource-based policies allow the principal\n\n### Role Cannot Be Assumed\n\n**Symptom:** `AccessDenied` when calling `AssumeRole`\n\n**Causes:**\n- Trust policy doesn't include the calling principal\n- Missing `sts:AssumeRole` permission on the caller\n- ExternalId mismatch (for cross-account roles)\n- Session duration exceeds maximum\n\n**Fix:** Review and update the role's trust relationship.\n\n### Policy Size Limits\n\n- Managed policy: 6,144 characters\n- Inline policy: 2,048 characters (user), 10,240 characters (role/group)\n- Trust policy: 2,048 characters\n\n**Solution:** Use multiple policies, reference resources by prefix/wildcard, or use tags-based access control.\n\n## References\n\n- [IAM User Guide](https://docs.aws.amazon.com/IAM/latest/UserGuide/)\n- [IAM API Reference](https://docs.aws.amazon.com/IAM/latest/APIReference/)\n- [IAM CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/iam/)\n- [Policy Reference](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html)\n- [boto3 IAM](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/iam.html)\n",
        "skills/iam/best-practices.md": "# IAM Security Best Practices\n\nComprehensive security best practices for AWS IAM.\n\n## Foundational Security\n\n### Root Account Protection\n\n1. **Never use root for daily operations**\n2. **Enable MFA** on root account (hardware key preferred)\n3. **Delete root access keys** if they exist\n4. **Set up CloudWatch alarms** for root account usage:\n\n```bash\n# Create metric filter for root login\naws logs put-metric-filter \\\n  --log-group-name CloudTrail/DefaultLogGroup \\\n  --filter-name RootAccountUsage \\\n  --filter-pattern '{ $.userIdentity.type = \"Root\" }' \\\n  --metric-transformations \\\n    metricName=RootAccountUsageCount,metricNamespace=CloudTrailMetrics,metricValue=1\n\n# Create alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name RootAccountUsage \\\n  --metric-name RootAccountUsageCount \\\n  --namespace CloudTrailMetrics \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:security-alerts\n```\n\n### User Management\n\n1. **Use IAM Identity Center (SSO)** for human access\n2. **Enforce MFA** for all console users\n3. **Set password policies**:\n\n```bash\naws iam update-account-password-policy \\\n  --minimum-password-length 14 \\\n  --require-symbols \\\n  --require-numbers \\\n  --require-uppercase-characters \\\n  --require-lowercase-characters \\\n  --max-password-age 90 \\\n  --password-reuse-prevention 24\n```\n\n4. **Review and remove unused credentials**:\n\n```bash\n# Generate credential report\naws iam generate-credential-report\n\n# Get the report\naws iam get-credential-report --query Content --output text | base64 -d\n```\n\n## Least Privilege Implementation\n\n### Principles\n\n1. **Start with zero permissions**, add as needed\n2. **Use AWS managed policies** as starting points\n3. **Scope resources explicitly** â€” avoid `*` where possible\n4. **Use conditions** to further restrict access\n5. **Separate duties** â€” different roles for different functions\n\n### Implementing Least Privilege\n\n**Step 1: Analyze required permissions**\n\nUse CloudTrail to see what actions are actually used:\n\n```bash\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=Username,AttributeValue=developer-user \\\n  --start-time 2024-01-01 \\\n  --end-time 2024-01-31\n```\n\n**Step 2: Use IAM Access Analyzer**\n\n```bash\n# Create analyzer\naws accessanalyzer create-analyzer \\\n  --analyzer-name MyAnalyzer \\\n  --type ACCOUNT\n\n# Generate policy from CloudTrail activity\naws accessanalyzer start-policy-generation \\\n  --policy-generation-details '{\n    \"principalArn\": \"arn:aws:iam::123456789012:role/MyRole\",\n    \"cloudTrailDetails\": {\n      \"trailArn\": \"arn:aws:cloudtrail:us-east-1:123456789012:trail/MyTrail\",\n      \"startTime\": \"2024-01-01T00:00:00Z\",\n      \"endTime\": \"2024-01-31T23:59:59Z\"\n    }\n  }'\n```\n\n**Step 3: Validate policies**\n\n```bash\naws iam simulate-principal-policy \\\n  --policy-source-arn arn:aws:iam::123456789012:role/MyRole \\\n  --action-names s3:GetObject s3:PutObject \\\n  --resource-arns arn:aws:s3:::my-bucket/*\n```\n\n## Attribute-Based Access Control (ABAC)\n\nUse tags for dynamic, scalable access control.\n\n### Tag-Based Policy Example\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:StartInstances\",\n        \"ec2:StopInstances\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:ResourceTag/Project\": \"${aws:PrincipalTag/Project}\",\n          \"aws:ResourceTag/Environment\": \"${aws:PrincipalTag/Environment}\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Benefits of ABAC\n\n- **Scales automatically** â€” new resources inherit tags\n- **Reduces policy management** â€” fewer policies needed\n- **Enables self-service** â€” users manage tagged resources\n- **Audit-friendly** â€” clear relationship between principal and resource\n\n## Role-Based Best Practices\n\n### Service Roles\n\n1. **One role per function** â€” Lambda function A gets RoleA\n2. **Use service-linked roles** when available\n3. **Scope trust policies tightly**:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:SourceAccount\": \"123456789012\"\n        },\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"arn:aws:lambda:us-east-1:123456789012:function:my-*\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Cross-Account Roles\n\n1. **Always use External ID** for third-party access\n2. **Limit session duration** appropriately\n3. **Restrict source accounts explicitly**\n4. **Monitor assumeRole events** via CloudTrail\n\n## Monitoring and Auditing\n\n### Enable CloudTrail\n\n```bash\naws cloudtrail create-trail \\\n  --name ManagementEventsTrail \\\n  --s3-bucket-name my-cloudtrail-bucket \\\n  --is-multi-region-trail \\\n  --enable-log-file-validation\n```\n\n### Key Events to Monitor\n\n| Event | Description |\n|-------|-------------|\n| `CreateUser` | New IAM user created |\n| `CreateAccessKey` | New access key generated |\n| `AttachUserPolicy` | Policy attached to user |\n| `CreateRole` | New role created |\n| `UpdateAssumeRolePolicy` | Trust policy modified |\n| `ConsoleLogin` | Console access |\n| `AssumeRole` | Role assumption |\n\n### IAM Access Analyzer\n\nContinuously analyzes policies to identify unintended access:\n\n```bash\n# List findings\naws accessanalyzer list-findings \\\n  --analyzer-arn arn:aws:access-analyzer:us-east-1:123456789012:analyzer/MyAnalyzer\n\n# Archive resolved findings\naws accessanalyzer update-findings \\\n  --analyzer-arn arn:aws:access-analyzer:us-east-1:123456789012:analyzer/MyAnalyzer \\\n  --status ARCHIVED \\\n  --ids finding-id-1 finding-id-2\n```\n\n## Credential Rotation\n\n### Access Key Rotation\n\n```python\nimport boto3\nfrom datetime import datetime, timedelta\n\niam = boto3.client('iam')\n\n# List access keys\nresponse = iam.list_access_keys(UserName='my-user')\n\nfor key in response['AccessKeyMetadata']:\n    age = datetime.now(key['CreateDate'].tzinfo) - key['CreateDate']\n    if age > timedelta(days=90):\n        print(f\"Key {key['AccessKeyId']} is {age.days} days old - rotate it!\")\n\n        # Create new key\n        new_key = iam.create_access_key(UserName='my-user')\n\n        # Deactivate old key (after updating applications)\n        iam.update_access_key(\n            UserName='my-user',\n            AccessKeyId=key['AccessKeyId'],\n            Status='Inactive'\n        )\n```\n\n### Automation with AWS Config\n\n```yaml\n# Config rule for access key rotation\nType: AWS::Config::ConfigRule\nProperties:\n  ConfigRuleName: access-keys-rotated\n  Source:\n    Owner: AWS\n    SourceIdentifier: ACCESS_KEYS_ROTATED\n  InputParameters:\n    maxAccessKeyAge: 90\n```\n\n## Security Checklist\n\n- [ ] Root account MFA enabled\n- [ ] Root access keys deleted\n- [ ] IAM users have MFA\n- [ ] Password policy enforced\n- [ ] Unused credentials removed\n- [ ] Access keys rotated < 90 days\n- [ ] CloudTrail enabled\n- [ ] IAM Access Analyzer active\n- [ ] Permission boundaries in use\n- [ ] Service control policies defined (Organizations)\n- [ ] Roles used instead of users for applications\n- [ ] Cross-account access uses External ID\n- [ ] Policies follow least privilege\n- [ ] Credential report reviewed monthly\n",
        "skills/iam/policies.md": "# IAM Policy Patterns\n\nDetailed patterns and examples for IAM policies.\n\n## Policy Structure\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DescriptiveStatementId\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\"service:Action\"],\n      \"Resource\": [\"arn:aws:service:region:account:resource\"],\n      \"Condition\": {\n        \"ConditionOperator\": {\n          \"ConditionKey\": \"value\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## Common Policy Patterns\n\n### S3 Bucket Access\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"ListBucket\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"s3:ListBucket\",\n      \"Resource\": \"arn:aws:s3:::my-bucket\",\n      \"Condition\": {\n        \"StringLike\": {\n          \"s3:prefix\": [\"${aws:username}/*\"]\n        }\n      }\n    },\n    {\n      \"Sid\": \"ReadWriteObjects\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:GetObject\", \"s3:PutObject\", \"s3:DeleteObject\"],\n      \"Resource\": \"arn:aws:s3:::my-bucket/${aws:username}/*\"\n    }\n  ]\n}\n```\n\n### DynamoDB Table Access\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"dynamodb:GetItem\",\n        \"dynamodb:PutItem\",\n        \"dynamodb:UpdateItem\",\n        \"dynamodb:DeleteItem\",\n        \"dynamodb:Query\"\n      ],\n      \"Resource\": [\n        \"arn:aws:dynamodb:us-east-1:123456789012:table/MyTable\",\n        \"arn:aws:dynamodb:us-east-1:123456789012:table/MyTable/index/*\"\n      ]\n    }\n  ]\n}\n```\n\n### Lambda Execution with Logging\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:*:*:log-group:/aws/lambda/*\"\n    }\n  ]\n}\n```\n\n### Secrets Manager Access\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\"\n      ],\n      \"Resource\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:prod/*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"secretsmanager:ResourceTag/Environment\": \"production\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### EC2 Instance Management with Tags\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:StartInstances\",\n        \"ec2:StopInstances\",\n        \"ec2:RebootInstances\"\n      ],\n      \"Resource\": \"arn:aws:ec2:*:*:instance/*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:ResourceTag/Team\": \"${aws:PrincipalTag/Team}\"\n        }\n      }\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:DescribeInstances\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n## Condition Keys\n\n### Common Global Condition Keys\n\n| Key | Description | Example |\n|-----|-------------|---------|\n| `aws:SourceIp` | Request IP address | Restrict to office IPs |\n| `aws:CurrentTime` | Current date/time | Allow only during business hours |\n| `aws:MultiFactorAuthPresent` | MFA used | Require MFA for sensitive actions |\n| `aws:PrincipalTag/key` | Tag on the principal | ABAC patterns |\n| `aws:ResourceTag/key` | Tag on the resource | ABAC patterns |\n| `aws:RequestedRegion` | Target region | Restrict to specific regions |\n\n### MFA Enforcement\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"*\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"BoolIfExists\": {\n          \"aws:MultiFactorAuthPresent\": \"false\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### IP Restriction\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"*\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"NotIpAddress\": {\n          \"aws:SourceIp\": [\"192.0.2.0/24\", \"203.0.113.0/24\"]\n        }\n      }\n    }\n  ]\n}\n```\n\n### Region Restriction\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": \"*\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringNotEquals\": {\n          \"aws:RequestedRegion\": [\"us-east-1\", \"us-west-2\"]\n        }\n      }\n    }\n  ]\n}\n```\n\n## Trust Policy Patterns\n\n### Lambda Service Trust\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\n```\n\n### Cross-Account with External ID\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::111111111111:root\"\n      },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"sts:ExternalId\": \"unique-secret-id\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Federated Identity (OIDC)\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"arn:aws:iam::123456789012:oidc-provider/token.actions.githubusercontent.com\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\"\n        },\n        \"StringLike\": {\n          \"token.actions.githubusercontent.com:sub\": \"repo:my-org/my-repo:*\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## Resource-Based Policy Patterns\n\n### S3 Bucket Policy\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"AllowCrossAccountAccess\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::111111111111:role/CrossAccountRole\"\n      },\n      \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"],\n      \"Resource\": [\n        \"arn:aws:s3:::my-bucket\",\n        \"arn:aws:s3:::my-bucket/*\"\n      ]\n    }\n  ]\n}\n```\n\n### SQS Queue Policy\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"sns.amazonaws.com\"\n      },\n      \"Action\": \"sqs:SendMessage\",\n      \"Resource\": \"arn:aws:sqs:us-east-1:123456789012:my-queue\",\n      \"Condition\": {\n        \"ArnEquals\": {\n          \"aws:SourceArn\": \"arn:aws:sns:us-east-1:123456789012:my-topic\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## Permission Boundaries\n\nPermission boundaries limit the maximum permissions a role can have:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:*\",\n        \"dynamodb:*\",\n        \"lambda:*\",\n        \"logs:*\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": [\n        \"iam:*\",\n        \"organizations:*\",\n        \"account:*\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\nApply to a role:\n\n```bash\naws iam put-role-permissions-boundary \\\n  --role-name DeveloperRole \\\n  --permissions-boundary arn:aws:iam::123456789012:policy/DeveloperBoundary\n```\n",
        "skills/lambda/SKILL.md": "---\nname: lambda\ndescription: AWS Lambda serverless functions for event-driven compute. Use when creating functions, configuring triggers, debugging invocations, optimizing cold starts, setting up event source mappings, or managing layers.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/lambda/latest/dg/\n---\n\n# AWS Lambda\n\nAWS Lambda runs code without provisioning servers. You pay only for compute time consumed. Lambda automatically scales from a few requests per day to thousands per second.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Function\n\nYour code packaged with configuration. Includes runtime, handler, memory, timeout, and IAM role.\n\n### Invocation Types\n\n| Type | Description | Use Case |\n|------|-------------|----------|\n| **Synchronous** | Caller waits for response | API Gateway, direct invoke |\n| **Asynchronous** | Fire and forget | S3, SNS, EventBridge |\n| **Poll-based** | Lambda polls source | SQS, Kinesis, DynamoDB Streams |\n\n### Execution Environment\n\nLambda creates execution environments to run your function. Components:\n- **Cold start**: New environment initialization\n- **Warm start**: Reusing existing environment\n- **Handler**: Entry point function\n- **Context**: Runtime information\n\n### Layers\n\nReusable packages of libraries, dependencies, or custom runtimes (up to 5 per function).\n\n## Common Patterns\n\n### Create a Python Function\n\n**AWS CLI:**\n\n```bash\n# Create deployment package\nzip function.zip lambda_function.py\n\n# Create function\naws lambda create-function \\\n  --function-name MyFunction \\\n  --runtime python3.12 \\\n  --role arn:aws:iam::123456789012:role/lambda-role \\\n  --handler lambda_function.handler \\\n  --zip-file fileb://function.zip \\\n  --timeout 30 \\\n  --memory-size 256\n\n# Update function code\naws lambda update-function-code \\\n  --function-name MyFunction \\\n  --zip-file fileb://function.zip\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport zipfile\nimport io\n\nlambda_client = boto3.client('lambda')\n\n# Create zip in memory\nzip_buffer = io.BytesIO()\nwith zipfile.ZipFile(zip_buffer, 'w') as zf:\n    zf.writestr('lambda_function.py', '''\ndef handler(event, context):\n    return {\"statusCode\": 200, \"body\": \"Hello\"}\n''')\nzip_buffer.seek(0)\n\n# Create function\nlambda_client.create_function(\n    FunctionName='MyFunction',\n    Runtime='python3.12',\n    Role='arn:aws:iam::123456789012:role/lambda-role',\n    Handler='lambda_function.handler',\n    Code={'ZipFile': zip_buffer.read()},\n    Timeout=30,\n    MemorySize=256\n)\n```\n\n### Add S3 Trigger\n\n```bash\n# Add permission for S3 to invoke Lambda\naws lambda add-permission \\\n  --function-name MyFunction \\\n  --statement-id s3-trigger \\\n  --action lambda:InvokeFunction \\\n  --principal s3.amazonaws.com \\\n  --source-arn arn:aws:s3:::my-bucket \\\n  --source-account 123456789012\n\n# Configure S3 notification (see S3 skill)\n```\n\n### Add SQS Event Source\n\n```bash\naws lambda create-event-source-mapping \\\n  --function-name MyFunction \\\n  --event-source-arn arn:aws:sqs:us-east-1:123456789012:my-queue \\\n  --batch-size 10 \\\n  --maximum-batching-window-in-seconds 5\n```\n\n### Environment Variables\n\n```bash\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --environment \"Variables={DB_HOST=mydb.cluster-xyz.us-east-1.rds.amazonaws.com,LOG_LEVEL=INFO}\"\n```\n\n### Create and Attach Layer\n\n```bash\n# Create layer\nzip -r layer.zip python/\n\naws lambda publish-layer-version \\\n  --layer-name my-dependencies \\\n  --compatible-runtimes python3.12 \\\n  --zip-file fileb://layer.zip\n\n# Attach to function\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --layers arn:aws:lambda:us-east-1:123456789012:layer:my-dependencies:1\n```\n\n### Invoke Function\n\n```bash\n# Synchronous invoke\naws lambda invoke \\\n  --function-name MyFunction \\\n  --payload '{\"key\": \"value\"}' \\\n  response.json\n\n# Asynchronous invoke\naws lambda invoke \\\n  --function-name MyFunction \\\n  --invocation-type Event \\\n  --payload '{\"key\": \"value\"}' \\\n  response.json\n```\n\n## CLI Reference\n\n### Function Management\n\n| Command | Description |\n|---------|-------------|\n| `aws lambda create-function` | Create new function |\n| `aws lambda update-function-code` | Update function code |\n| `aws lambda update-function-configuration` | Update settings |\n| `aws lambda delete-function` | Delete function |\n| `aws lambda list-functions` | List all functions |\n| `aws lambda get-function` | Get function details |\n\n### Invocation\n\n| Command | Description |\n|---------|-------------|\n| `aws lambda invoke` | Invoke function |\n| `aws lambda invoke-async` | Async invoke (deprecated) |\n\n### Event Sources\n\n| Command | Description |\n|---------|-------------|\n| `aws lambda create-event-source-mapping` | Add event source |\n| `aws lambda list-event-source-mappings` | List mappings |\n| `aws lambda update-event-source-mapping` | Update mapping |\n| `aws lambda delete-event-source-mapping` | Remove mapping |\n\n### Permissions\n\n| Command | Description |\n|---------|-------------|\n| `aws lambda add-permission` | Add resource-based policy |\n| `aws lambda remove-permission` | Remove permission |\n| `aws lambda get-policy` | View resource policy |\n\n## Best Practices\n\n### Performance\n\n- **Right-size memory**: More memory = more CPU = faster execution\n- **Minimize cold starts**: Keep functions warm, use Provisioned Concurrency\n- **Optimize package size**: Smaller packages deploy faster\n- **Use layers** for shared dependencies\n- **Initialize outside handler**: Reuse connections across invocations\n\n```python\n# GOOD: Initialize outside handler\nimport boto3\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('MyTable')\n\ndef handler(event, context):\n    # Reuses existing connection\n    return table.get_item(Key={'id': event['id']})\n```\n\n### Security\n\n- **Least privilege IAM roles** â€” only grant needed permissions\n- **Use Secrets Manager** for sensitive data\n- **Enable VPC** only if needed (adds latency)\n- **Encrypt environment variables** with KMS\n\n### Cost Optimization\n\n- **Set appropriate timeout** â€” don't use max 15 minutes unnecessarily\n- **Use ARM architecture** (Graviton2) for 34% better price/performance\n- **Batch process** where possible\n- **Use Reserved Concurrency** to limit costs\n\n### Reliability\n\n- **Configure DLQ** for async invocations\n- **Handle retries** â€” async events retry twice\n- **Make handlers idempotent**\n- **Use structured logging**\n\n## Troubleshooting\n\n### Timeout Errors\n\n**Symptom:** `Task timed out after X seconds`\n\n**Causes:**\n- Function takes longer than timeout\n- Network call to unreachable resource\n- VPC configuration issues\n\n**Debug:**\n\n```bash\n# Check function configuration\naws lambda get-function-configuration \\\n  --function-name MyFunction \\\n  --query \"Timeout\"\n\n# Increase timeout\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --timeout 60\n```\n\n### Out of Memory\n\n**Symptom:** Function crashes with memory error\n\n**Fix:**\n\n```bash\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --memory-size 512\n```\n\n### Cold Start Latency\n\n**Causes:**\n- Large deployment package\n- VPC configuration\n- Many dependencies to load\n\n**Solutions:**\n- Use Provisioned Concurrency\n- Reduce package size\n- Use layers for dependencies\n- Consider Graviton2 (ARM)\n\n```bash\n# Enable Provisioned Concurrency\naws lambda put-provisioned-concurrency-config \\\n  --function-name MyFunction \\\n  --qualifier LIVE \\\n  --provisioned-concurrent-executions 5\n```\n\n### Permission Denied\n\n**Symptom:** `AccessDeniedException`\n\n**Debug:**\n\n```bash\n# Check execution role\naws lambda get-function-configuration \\\n  --function-name MyFunction \\\n  --query \"Role\"\n\n# Check role policies\naws iam list-attached-role-policies \\\n  --role-name lambda-role\n```\n\n### VPC Connectivity Issues\n\n**Symptom:** Cannot reach internet or AWS services\n\n**Causes:**\n- No NAT Gateway for internet access\n- Missing VPC endpoint for AWS services\n- Security group blocking outbound\n\n**Solutions:**\n- Add NAT Gateway for internet\n- Add VPC endpoints for AWS services\n- Check security group rules\n\n## References\n\n- [Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/)\n- [Lambda API Reference](https://docs.aws.amazon.com/lambda/latest/api/)\n- [Lambda CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/lambda/)\n- [boto3 Lambda](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/lambda.html)\n",
        "skills/lambda/debugging.md": "# Lambda Debugging Guide\n\nTechniques for debugging and troubleshooting Lambda functions.\n\n## CloudWatch Logs\n\n### View Logs\n\n```bash\n# Get log group\naws logs describe-log-groups \\\n  --log-group-name-prefix /aws/lambda/MyFunction\n\n# Get recent log streams\naws logs describe-log-streams \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --order-by LastEventTime \\\n  --descending \\\n  --limit 5\n\n# View log events\naws logs get-log-events \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --log-stream-name '2024/01/15/[$LATEST]abc123' \\\n  --limit 100\n```\n\n### Filter Logs\n\n```bash\n# Find errors\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --filter-pattern \"ERROR\" \\\n  --start-time $(date -d '1 hour ago' +%s000)\n\n# Find specific request\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --filter-pattern \"request-id-12345\"\n```\n\n### CloudWatch Logs Insights\n\n```bash\n# Query for errors with context\naws logs start-query \\\n  --log-group-name /aws/lambda/MyFunction \\\n  --start-time $(date -d '1 hour ago' +%s) \\\n  --end-time $(date +%s) \\\n  --query-string '\n    fields @timestamp, @message, @requestId\n    | filter @message like /ERROR/\n    | sort @timestamp desc\n    | limit 50\n  '\n```\n\nCommon queries:\n\n```sql\n-- Cold starts\nfields @timestamp, @duration, @billedDuration\n| filter @type = \"REPORT\"\n| filter @initDuration > 0\n| sort @timestamp desc\n| limit 50\n\n-- Slow invocations\nfields @timestamp, @requestId, @duration\n| filter @type = \"REPORT\"\n| filter @duration > 1000\n| sort @duration desc\n| limit 20\n\n-- Memory usage\nfields @timestamp, @requestId, @maxMemoryUsed, @memorySize\n| filter @type = \"REPORT\"\n| stats avg(@maxMemoryUsed), max(@maxMemoryUsed), avg(@memorySize) by bin(1h)\n\n-- Error rate\nfields @timestamp\n| filter @type = \"REPORT\"\n| stats count(*) as total,\n        sum(strcontains(@message, \"Error\")) as errors,\n        sum(strcontains(@message, \"Error\")) * 100.0 / count(*) as errorRate\n  by bin(5m)\n```\n\n## X-Ray Tracing\n\n### Enable X-Ray\n\n```bash\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --tracing-config Mode=Active\n```\n\n### Instrument Code\n\n```python\nfrom aws_xray_sdk.core import xray_recorder\nfrom aws_xray_sdk.core import patch_all\n\n# Patch AWS SDK calls\npatch_all()\n\ndef handler(event, context):\n    # Create custom subsegment\n    with xray_recorder.in_subsegment('process_data') as subsegment:\n        subsegment.put_annotation('user_id', event.get('user_id'))\n        result = process_data(event)\n\n    return result\n```\n\n### Query Traces\n\n```bash\n# Get trace summaries\naws xray get-trace-summaries \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --filter-expression 'service(id(name: \"MyFunction\")) AND responsetime > 1'\n```\n\n## Local Testing\n\n### SAM Local\n\n```bash\n# Invoke locally\nsam local invoke MyFunction --event event.json\n\n# Start local API\nsam local start-api\n\n# Debug with IDE\nsam local invoke MyFunction --event event.json --debug-port 5678\n```\n\n### Docker Lambda Runtime\n\n```bash\n# Run function locally\ndocker run --rm \\\n  -v $(pwd):/var/task \\\n  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n  public.ecr.aws/lambda/python:3.12 \\\n  lambda_function.handler '{\"key\": \"value\"}'\n```\n\n### Unit Testing\n\n```python\nimport json\nimport pytest\nfrom unittest.mock import patch, MagicMock\n\n# Import handler\nfrom lambda_function import handler\n\nclass TestHandler:\n    def test_successful_request(self):\n        event = {\"body\": json.dumps({\"name\": \"test\"})}\n        context = MagicMock()\n\n        result = handler(event, context)\n\n        assert result[\"statusCode\"] == 200\n\n    @patch('lambda_function.dynamodb')\n    def test_dynamo_error(self, mock_dynamo):\n        mock_dynamo.Table.return_value.get_item.side_effect = Exception(\"DB Error\")\n\n        event = {\"id\": \"123\"}\n        context = MagicMock()\n\n        result = handler(event, context)\n\n        assert result[\"statusCode\"] == 500\n```\n\n## Common Issues\n\n### Timeout Debugging\n\n```python\nimport time\nimport logging\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ndef handler(event, context):\n    start = time.time()\n\n    # Log remaining time periodically\n    def check_time(operation):\n        elapsed = time.time() - start\n        remaining = context.get_remaining_time_in_millis() / 1000\n        logger.info(f\"{operation}: elapsed={elapsed:.2f}s, remaining={remaining:.2f}s\")\n\n    check_time(\"start\")\n\n    result1 = step1()\n    check_time(\"after step1\")\n\n    result2 = step2()\n    check_time(\"after step2\")\n\n    return {\"statusCode\": 200}\n```\n\n### Memory Issues\n\n```python\nimport sys\nimport tracemalloc\n\ndef handler(event, context):\n    tracemalloc.start()\n\n    # Your code here\n    result = process(event)\n\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Current memory: {current / 1024 / 1024:.2f} MB\")\n    print(f\"Peak memory: {peak / 1024 / 1024:.2f} MB\")\n    tracemalloc.stop()\n\n    return result\n```\n\n### Connection Issues\n\n```python\nimport socket\nimport urllib.request\n\ndef handler(event, context):\n    # Test DNS resolution\n    try:\n        ip = socket.gethostbyname('example.com')\n        print(f\"DNS resolved: example.com -> {ip}\")\n    except socket.gaierror as e:\n        print(f\"DNS failed: {e}\")\n\n    # Test HTTP connectivity\n    try:\n        response = urllib.request.urlopen('https://example.com', timeout=5)\n        print(f\"HTTP status: {response.status}\")\n    except Exception as e:\n        print(f\"HTTP failed: {e}\")\n\n    return {\"statusCode\": 200}\n```\n\n## Structured Logging\n\n### AWS Lambda Powertools\n\n```python\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"my-service\")\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\ndef handler(event, context):\n    logger.info(\"Processing request\", extra={\n        \"user_id\": event.get(\"user_id\"),\n        \"action\": \"process\"\n    })\n\n    try:\n        result = process(event)\n        logger.info(\"Success\", extra={\"result\": result})\n        return {\"statusCode\": 200, \"body\": json.dumps(result)}\n    except Exception as e:\n        logger.exception(\"Failed to process\")\n        return {\"statusCode\": 500}\n```\n\n### JSON Logging\n\n```python\nimport json\nimport logging\n\nclass JsonFormatter(logging.Formatter):\n    def format(self, record):\n        log_data = {\n            \"timestamp\": self.formatTime(record),\n            \"level\": record.levelname,\n            \"message\": record.getMessage(),\n            \"function\": record.funcName,\n        }\n        if hasattr(record, 'request_id'):\n            log_data['request_id'] = record.request_id\n        if record.exc_info:\n            log_data['exception'] = self.formatException(record.exc_info)\n        return json.dumps(log_data)\n\nlogger = logging.getLogger()\nhandler = logging.StreamHandler()\nhandler.setFormatter(JsonFormatter())\nlogger.addHandler(handler)\nlogger.setLevel(logging.INFO)\n```\n\n## Debugging Event Sources\n\n### SQS Events\n\n```python\ndef handler(event, context):\n    for record in event['Records']:\n        message_id = record['messageId']\n        body = record['body']\n\n        print(f\"Processing message {message_id}\")\n        print(f\"Body: {body}\")\n        print(f\"Attributes: {record.get('messageAttributes', {})}\")\n\n        try:\n            process_message(body)\n        except Exception as e:\n            print(f\"Failed to process {message_id}: {e}\")\n            raise  # Message goes to DLQ\n```\n\n### API Gateway Events\n\n```python\ndef handler(event, context):\n    print(f\"HTTP Method: {event['httpMethod']}\")\n    print(f\"Path: {event['path']}\")\n    print(f\"Headers: {json.dumps(event.get('headers', {}))}\")\n    print(f\"Query: {json.dumps(event.get('queryStringParameters', {}))}\")\n    print(f\"Body: {event.get('body', '')}\")\n\n    return {\n        \"statusCode\": 200,\n        \"body\": json.dumps({\"message\": \"Debug info logged\"})\n    }\n```\n\n## Error Handling\n\n```python\nimport json\nfrom aws_lambda_powertools import Logger\n\nlogger = Logger()\n\nclass ProcessingError(Exception):\n    \"\"\"Custom application error\"\"\"\n    pass\n\ndef handler(event, context):\n    try:\n        result = process(event)\n        return {\n            \"statusCode\": 200,\n            \"body\": json.dumps(result)\n        }\n    except ProcessingError as e:\n        logger.warning(f\"Processing error: {e}\")\n        return {\n            \"statusCode\": 400,\n            \"body\": json.dumps({\"error\": str(e)})\n        }\n    except Exception as e:\n        logger.exception(\"Unexpected error\")\n        return {\n            \"statusCode\": 500,\n            \"body\": json.dumps({\"error\": \"Internal server error\"})\n        }\n```\n",
        "skills/lambda/deployment.md": "# Lambda Deployment Patterns\n\nStrategies and patterns for deploying Lambda functions.\n\n## Deployment Methods\n\n### Direct Zip Upload\n\nBest for small functions (< 50 MB):\n\n```bash\n# Package and deploy\nzip -r function.zip . -x \"*.git*\"\n\naws lambda update-function-code \\\n  --function-name MyFunction \\\n  --zip-file fileb://function.zip\n```\n\n### S3 Deployment\n\nRequired for packages > 50 MB (up to 250 MB unzipped):\n\n```bash\n# Upload to S3\naws s3 cp function.zip s3://my-deployment-bucket/function.zip\n\n# Deploy from S3\naws lambda update-function-code \\\n  --function-name MyFunction \\\n  --s3-bucket my-deployment-bucket \\\n  --s3-key function.zip\n```\n\n### Container Image Deployment\n\nFor packages up to 10 GB:\n\n```dockerfile\nFROM public.ecr.aws/lambda/python:3.12\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY app.py .\n\nCMD [\"app.handler\"]\n```\n\n```bash\n# Build and push\ndocker build -t my-lambda .\naws ecr get-login-password | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\ndocker tag my-lambda:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-lambda:latest\ndocker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-lambda:latest\n\n# Deploy\naws lambda update-function-code \\\n  --function-name MyFunction \\\n  --image-uri 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-lambda:latest\n```\n\n## AWS SAM Deployment\n\n### Template Example\n\n```yaml\n# template.yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nGlobals:\n  Function:\n    Runtime: python3.12\n    Timeout: 30\n    MemorySize: 256\n\nResources:\n  MyFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: MyFunction\n      Handler: app.handler\n      CodeUri: ./src\n      Environment:\n        Variables:\n          TABLE_NAME: !Ref MyTable\n      Events:\n        Api:\n          Type: Api\n          Properties:\n            Path: /items\n            Method: GET\n      Policies:\n        - DynamoDBReadPolicy:\n            TableName: !Ref MyTable\n\n  MyTable:\n    Type: AWS::Serverless::SimpleTable\n```\n\n### SAM Commands\n\n```bash\n# Build\nsam build\n\n# Local testing\nsam local invoke MyFunction --event event.json\nsam local start-api\n\n# Deploy\nsam deploy --guided  # First time\nsam deploy           # Subsequent deploys\n\n# View logs\nsam logs -n MyFunction --tail\n```\n\n## Versioning and Aliases\n\n### Publish Version\n\n```bash\n# Publish immutable version\naws lambda publish-version \\\n  --function-name MyFunction \\\n  --description \"v1.0.0 - Initial release\"\n```\n\n### Create Alias\n\n```bash\n# Create PROD alias pointing to version 1\naws lambda create-alias \\\n  --function-name MyFunction \\\n  --name PROD \\\n  --function-version 1\n\n# Create DEV alias pointing to $LATEST\naws lambda create-alias \\\n  --function-name MyFunction \\\n  --name DEV \\\n  --function-version '$LATEST'\n```\n\n### Weighted Alias (Canary Deployment)\n\n```bash\n# Route 90% to v1, 10% to v2\naws lambda update-alias \\\n  --function-name MyFunction \\\n  --name PROD \\\n  --function-version 2 \\\n  --routing-config AdditionalVersionWeights={1=0.9}\n```\n\n### Blue/Green with Aliases\n\n```bash\n# Current state: PROD -> v1\n\n# Deploy new version\naws lambda update-function-code \\\n  --function-name MyFunction \\\n  --zip-file fileb://function.zip\n\naws lambda publish-version \\\n  --function-name MyFunction \\\n  --description \"v2.0.0\"\n\n# Canary: 10% to v2\naws lambda update-alias \\\n  --function-name MyFunction \\\n  --name PROD \\\n  --function-version 2 \\\n  --routing-config AdditionalVersionWeights={1=0.9}\n\n# Full rollout\naws lambda update-alias \\\n  --function-name MyFunction \\\n  --name PROD \\\n  --function-version 2 \\\n  --routing-config AdditionalVersionWeights={}\n\n# Rollback if needed\naws lambda update-alias \\\n  --function-name MyFunction \\\n  --name PROD \\\n  --function-version 1\n```\n\n## Layers\n\n### Create a Layer\n\nPython dependencies:\n\n```bash\n# Structure: python/lib/python3.12/site-packages/\nmkdir -p python\npip install -t python/ requests boto3\n\nzip -r layer.zip python/\n\naws lambda publish-layer-version \\\n  --layer-name my-python-deps \\\n  --compatible-runtimes python3.12 \\\n  --compatible-architectures x86_64 arm64 \\\n  --zip-file fileb://layer.zip\n```\n\n### Use AWS-Provided Layers\n\n```bash\n# AWS Parameters and Secrets Layer\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --layers arn:aws:lambda:us-east-1:177933569100:layer:AWS-Parameters-and-Secrets-Lambda-Extension:11\n```\n\n### Layer Best Practices\n\n- Keep layers under 50 MB\n- Version layers properly\n- Test compatibility with function runtime\n- Use separate layers for different purposes\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Deploy Lambda\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: arn:aws:iam::123456789012:role/github-actions-role\n          aws-region: us-east-1\n\n      - name: Deploy\n        run: |\n          zip -r function.zip .\n          aws lambda update-function-code \\\n            --function-name MyFunction \\\n            --zip-file fileb://function.zip\n\n          aws lambda publish-version \\\n            --function-name MyFunction \\\n            --description \"${{ github.sha }}\"\n```\n\n### SAM Pipeline\n\n```bash\n# Initialize pipeline\nsam pipeline init --bootstrap\n\n# Creates:\n# - IAM roles for CI/CD\n# - S3 bucket for artifacts\n# - CloudFormation for infrastructure\n# - Pipeline configuration file\n```\n\n## Environment Management\n\n### Environment Variables\n\n```bash\n# Set environment variables\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --environment \"Variables={\n    STAGE=production,\n    DB_HOST=prod-db.example.com,\n    LOG_LEVEL=INFO\n  }\"\n```\n\n### KMS Encryption\n\n```bash\naws lambda update-function-configuration \\\n  --function-name MyFunction \\\n  --kms-key-arn arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012 \\\n  --environment \"Variables={\n    DB_PASSWORD=encrypted-value\n  }\"\n```\n\n### Using Secrets Manager\n\n```python\nimport boto3\nimport json\n\nsecrets = boto3.client('secretsmanager')\n\n# Cache secret outside handler for reuse\n_secret = None\n\ndef get_secret():\n    global _secret\n    if _secret is None:\n        response = secrets.get_secret_value(SecretId='my-secret')\n        _secret = json.loads(response['SecretString'])\n    return _secret\n\ndef handler(event, context):\n    secret = get_secret()\n    db_password = secret['password']\n    # Use secret...\n```\n\n## Package Size Optimization\n\n### Reduce Package Size\n\n```bash\n# Remove unnecessary files\nzip -r function.zip . \\\n  -x \"*.git*\" \\\n  -x \"*__pycache__*\" \\\n  -x \"*.pyc\" \\\n  -x \"tests/*\" \\\n  -x \"*.md\" \\\n  -x \"*.txt\"\n\n# Use zip with compression\nzip -9 -r function.zip .\n```\n\n### Lambda Powertools (Recommended)\n\n```python\n# Use AWS Lambda Powertools for structured logging, tracing, etc.\nfrom aws_lambda_powertools import Logger, Tracer, Metrics\n\nlogger = Logger()\ntracer = Tracer()\nmetrics = Metrics()\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@metrics.log_metrics\ndef handler(event, context):\n    logger.info(\"Processing request\", extra={\"event\": event})\n    return {\"statusCode\": 200}\n```\n",
        "skills/rds/SKILL.md": "---\nname: rds\ndescription: AWS RDS relational database service for managed databases. Use when provisioning databases, configuring backups, managing replicas, troubleshooting connectivity, or optimizing performance.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/\n---\n\n# AWS RDS\n\nAmazon Relational Database Service (RDS) provides managed relational databases including MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, and Aurora. RDS handles provisioning, patching, backups, and failover.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### DB Instance Classes\n\n| Category | Example | Use Case |\n|----------|---------|----------|\n| Standard | db.m6g.large | General purpose |\n| Memory Optimized | db.r6g.large | High memory workloads |\n| Burstable | db.t3.medium | Variable workloads, dev/test |\n\n### Storage Types\n\n| Type | IOPS | Use Case |\n|------|------|----------|\n| gp3 | 3,000-16,000 | Most workloads |\n| io1/io2 | Up to 256,000 | High-performance OLTP |\n| magnetic | N/A | Legacy, avoid |\n\n### Multi-AZ Deployments\n\n- **Multi-AZ Instance**: Synchronous standby in different AZ\n- **Multi-AZ Cluster**: One writer, two reader instances (Aurora-like)\n\n### Read Replicas\n\nAsynchronous copies for read scaling. Can be cross-region.\n\n## Common Patterns\n\n### Create a PostgreSQL Instance\n\n**AWS CLI:**\n\n```bash\n# Create DB subnet group\naws rds create-db-subnet-group \\\n  --db-subnet-group-name my-db-subnet-group \\\n  --db-subnet-group-description \"Private subnets for RDS\" \\\n  --subnet-ids subnet-12345678 subnet-87654321\n\n# Create security group (allow PostgreSQL from app)\naws ec2 create-security-group \\\n  --group-name rds-postgres-sg \\\n  --description \"RDS PostgreSQL access\" \\\n  --vpc-id vpc-12345678\n\naws ec2 authorize-security-group-ingress \\\n  --group-id sg-rds12345 \\\n  --protocol tcp \\\n  --port 5432 \\\n  --source-group sg-app12345\n\n# Create RDS instance\naws rds create-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --db-instance-class db.t3.medium \\\n  --engine postgres \\\n  --engine-version 16.1 \\\n  --master-username admin \\\n  --master-user-password 'SecurePassword123!' \\\n  --allocated-storage 100 \\\n  --storage-type gp3 \\\n  --db-subnet-group-name my-db-subnet-group \\\n  --vpc-security-group-ids sg-rds12345 \\\n  --multi-az \\\n  --backup-retention-period 7 \\\n  --storage-encrypted \\\n  --no-publicly-accessible\n```\n\n**boto3:**\n\n```python\nimport boto3\n\nrds = boto3.client('rds')\n\nresponse = rds.create_db_instance(\n    DBInstanceIdentifier='my-postgres',\n    DBInstanceClass='db.t3.medium',\n    Engine='postgres',\n    EngineVersion='16.1',\n    MasterUsername='admin',\n    MasterUserPassword='SecurePassword123!',\n    AllocatedStorage=100,\n    StorageType='gp3',\n    DBSubnetGroupName='my-db-subnet-group',\n    VpcSecurityGroupIds=['sg-rds12345'],\n    MultiAZ=True,\n    BackupRetentionPeriod=7,\n    StorageEncrypted=True,\n    PubliclyAccessible=False\n)\n```\n\n### Create Read Replica\n\n```bash\naws rds create-db-instance-read-replica \\\n  --db-instance-identifier my-postgres-replica \\\n  --source-db-instance-identifier my-postgres \\\n  --db-instance-class db.t3.medium \\\n  --availability-zone us-east-1b\n```\n\n### Take a Snapshot\n\n```bash\naws rds create-db-snapshot \\\n  --db-snapshot-identifier my-postgres-snapshot-2024-01-15 \\\n  --db-instance-identifier my-postgres\n```\n\n### Restore from Snapshot\n\n```bash\naws rds restore-db-instance-from-db-snapshot \\\n  --db-instance-identifier my-postgres-restored \\\n  --db-snapshot-identifier my-postgres-snapshot-2024-01-15 \\\n  --db-instance-class db.t3.medium \\\n  --db-subnet-group-name my-db-subnet-group \\\n  --vpc-security-group-ids sg-rds12345\n```\n\n### Point-in-Time Recovery\n\n```bash\naws rds restore-db-instance-to-point-in-time \\\n  --source-db-instance-identifier my-postgres \\\n  --target-db-instance-identifier my-postgres-pitr \\\n  --restore-time 2024-01-15T10:30:00Z \\\n  --db-instance-class db.t3.medium\n```\n\n### Modify Instance\n\n```bash\n# Change instance class (with downtime)\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --db-instance-class db.m6g.large \\\n  --apply-immediately\n\n# Scale storage (no downtime)\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --allocated-storage 200 \\\n  --apply-immediately\n```\n\n### Connect with IAM Authentication\n\n```python\nimport boto3\nimport psycopg2\n\nrds = boto3.client('rds')\n\n# Generate auth token\ntoken = rds.generate_db_auth_token(\n    DBHostname='my-postgres.abc123.us-east-1.rds.amazonaws.com',\n    Port=5432,\n    DBUsername='iam_user',\n    Region='us-east-1'\n)\n\n# Connect\nconn = psycopg2.connect(\n    host='my-postgres.abc123.us-east-1.rds.amazonaws.com',\n    port=5432,\n    database='mydb',\n    user='iam_user',\n    password=token,\n    sslmode='require'\n)\n```\n\n## CLI Reference\n\n### Instance Management\n\n| Command | Description |\n|---------|-------------|\n| `aws rds create-db-instance` | Create instance |\n| `aws rds describe-db-instances` | List instances |\n| `aws rds modify-db-instance` | Modify settings |\n| `aws rds delete-db-instance` | Delete instance |\n| `aws rds reboot-db-instance` | Reboot instance |\n| `aws rds start-db-instance` | Start stopped instance |\n| `aws rds stop-db-instance` | Stop instance |\n\n### Backups\n\n| Command | Description |\n|---------|-------------|\n| `aws rds create-db-snapshot` | Manual snapshot |\n| `aws rds describe-db-snapshots` | List snapshots |\n| `aws rds restore-db-instance-from-db-snapshot` | Restore from snapshot |\n| `aws rds restore-db-instance-to-point-in-time` | Point-in-time restore |\n| `aws rds copy-db-snapshot` | Copy snapshot |\n\n### Replicas\n\n| Command | Description |\n|---------|-------------|\n| `aws rds create-db-instance-read-replica` | Create read replica |\n| `aws rds promote-read-replica` | Promote to standalone |\n\n## Best Practices\n\n### Security\n\n- **Never make publicly accessible** â€” use VPC and security groups\n- **Enable encryption** at rest (KMS) and in transit (SSL)\n- **Use IAM authentication** for application access\n- **Store credentials in Secrets Manager** with rotation\n- **Use parameter groups** to enforce SSL\n\n```bash\n# Enforce SSL in PostgreSQL\naws rds modify-db-parameter-group \\\n  --db-parameter-group-name my-pg-params \\\n  --parameters \"ParameterName=rds.force_ssl,ParameterValue=1,ApplyMethod=pending-reboot\"\n```\n\n### Performance\n\n- **Right-size instances** â€” monitor CPU, memory, IOPS\n- **Use gp3** for cost-effective performance\n- **Enable Performance Insights** for query analysis\n- **Use read replicas** for read scaling\n- **Optimize queries** â€” check slow query log\n\n### High Availability\n\n- **Enable Multi-AZ** for production\n- **Use Aurora** for mission-critical workloads\n- **Configure appropriate backup retention**\n- **Test failover** periodically\n- **Monitor replication lag** for replicas\n\n### Cost Optimization\n\n- **Use Reserved Instances** for steady-state workloads\n- **Stop dev/test instances** when not in use\n- **Delete old snapshots** regularly\n- **Right-size instance classes**\n\n## Troubleshooting\n\n### Cannot Connect\n\n**Causes:**\n1. Security group not allowing access\n2. Instance not in VPC subnet\n3. SSL required but not used\n4. Wrong endpoint/port\n\n**Debug:**\n\n```bash\n# Check security group\naws ec2 describe-security-groups --group-ids sg-rds12345\n\n# Check instance status\naws rds describe-db-instances \\\n  --db-instance-identifier my-postgres \\\n  --query \"DBInstances[0].{Status:DBInstanceStatus,Endpoint:Endpoint}\"\n\n# Test connectivity from EC2\nnc -zv my-postgres.abc123.us-east-1.rds.amazonaws.com 5432\n```\n\n### High CPU/Memory\n\n**Debug:**\n\n```bash\n# Enable Enhanced Monitoring\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --monitoring-interval 60 \\\n  --monitoring-role-arn arn:aws:iam::123456789012:role/rds-monitoring-role\n\n# Enable Performance Insights\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --enable-performance-insights \\\n  --performance-insights-retention-period 7\n```\n\n**Solutions:**\n- Scale up instance class\n- Optimize slow queries\n- Add read replicas\n- Check for locking/blocking\n\n### Storage Full\n\n**Symptom:** Instance becomes unavailable\n\n**Prevention:**\n\n```bash\n# Enable storage autoscaling\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --max-allocated-storage 500\n\n# Set CloudWatch alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"RDS-Storage-Low\" \\\n  --metric-name FreeStorageSpace \\\n  --namespace AWS/RDS \\\n  --dimensions Name=DBInstanceIdentifier,Value=my-postgres \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 10000000000 \\\n  --comparison-operator LessThanThreshold \\\n  --evaluation-periods 2 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Replication Lag\n\n**Monitor:**\n\n```bash\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/RDS \\\n  --metric-name ReplicaLag \\\n  --dimensions Name=DBInstanceIdentifier,Value=my-postgres-replica \\\n  --start-time $(date -d '1 hour ago' -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Average\n```\n\n**Causes:**\n- Replica instance too small\n- Heavy write load\n- Network issues\n- Long-running queries on replica\n\n## References\n\n- [RDS User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/)\n- [RDS API Reference](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/)\n- [RDS CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/rds/)\n- [boto3 RDS](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rds.html)\n",
        "skills/rds/administration.md": "# RDS Administration\n\nDatabase administration tasks for RDS.\n\n## Parameter Groups\n\n### Create Parameter Group\n\n```bash\naws rds create-db-parameter-group \\\n  --db-parameter-group-name my-postgres-params \\\n  --db-parameter-group-family postgres16 \\\n  --description \"Custom PostgreSQL parameters\"\n```\n\n### Common PostgreSQL Parameters\n\n```bash\n# Set parameters\naws rds modify-db-parameter-group \\\n  --db-parameter-group-name my-postgres-params \\\n  --parameters \\\n    \"ParameterName=max_connections,ParameterValue=200,ApplyMethod=pending-reboot\" \\\n    \"ParameterName=shared_buffers,ParameterValue={DBInstanceClassMemory/4},ApplyMethod=pending-reboot\" \\\n    \"ParameterName=work_mem,ParameterValue=65536,ApplyMethod=immediate\" \\\n    \"ParameterName=maintenance_work_mem,ParameterValue=524288,ApplyMethod=immediate\" \\\n    \"ParameterName=log_statement,ParameterValue=ddl,ApplyMethod=immediate\" \\\n    \"ParameterName=log_min_duration_statement,ParameterValue=1000,ApplyMethod=immediate\"\n```\n\n### Common MySQL Parameters\n\n```bash\naws rds modify-db-parameter-group \\\n  --db-parameter-group-name my-mysql-params \\\n  --parameters \\\n    \"ParameterName=max_connections,ParameterValue=200,ApplyMethod=pending-reboot\" \\\n    \"ParameterName=innodb_buffer_pool_size,ParameterValue={DBInstanceClassMemory*3/4},ApplyMethod=pending-reboot\" \\\n    \"ParameterName=slow_query_log,ParameterValue=1,ApplyMethod=immediate\" \\\n    \"ParameterName=long_query_time,ParameterValue=1,ApplyMethod=immediate\" \\\n    \"ParameterName=log_queries_not_using_indexes,ParameterValue=1,ApplyMethod=immediate\"\n```\n\n### Apply Parameter Group\n\n```bash\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --db-parameter-group-name my-postgres-params \\\n  --apply-immediately\n```\n\n## Option Groups\n\n### Create Option Group (SQL Server, Oracle, MySQL)\n\n```bash\naws rds create-option-group \\\n  --option-group-name my-mysql-options \\\n  --engine-name mysql \\\n  --major-engine-version 8.0 \\\n  --option-group-description \"MySQL options\"\n```\n\n### Add Options\n\n```bash\n# Add MySQL memcached\naws rds add-option-to-option-group \\\n  --option-group-name my-mysql-options \\\n  --options OptionName=MEMCACHED\n\n# Add SQL Server TDE\naws rds add-option-to-option-group \\\n  --option-group-name my-sqlserver-options \\\n  --options OptionName=TDE\n```\n\n## Backup Management\n\n### Automated Backups\n\n```bash\n# Configure backup window\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --backup-retention-period 14 \\\n  --preferred-backup-window \"03:00-04:00\"\n```\n\n### Manual Snapshots\n\n```bash\n# Create snapshot\naws rds create-db-snapshot \\\n  --db-snapshot-identifier my-postgres-$(date +%Y%m%d) \\\n  --db-instance-identifier my-postgres\n\n# Wait for completion\naws rds wait db-snapshot-available \\\n  --db-snapshot-identifier my-postgres-20240115\n```\n\n### Copy Snapshot Cross-Region\n\n```bash\naws rds copy-db-snapshot \\\n  --source-db-snapshot-identifier arn:aws:rds:us-east-1:123456789012:snapshot:my-postgres-20240115 \\\n  --target-db-snapshot-identifier my-postgres-20240115 \\\n  --source-region us-east-1 \\\n  --region us-west-2 \\\n  --kms-key-id alias/aws/rds\n```\n\n### Share Snapshot\n\n```bash\naws rds modify-db-snapshot-attribute \\\n  --db-snapshot-identifier my-postgres-20240115 \\\n  --attribute-name restore \\\n  --values-to-add 111111111111\n```\n\n### Export to S3\n\n```bash\naws rds start-export-task \\\n  --export-task-identifier my-export-2024 \\\n  --source-arn arn:aws:rds:us-east-1:123456789012:snapshot:my-postgres-20240115 \\\n  --s3-bucket-name my-rds-exports \\\n  --iam-role-arn arn:aws:iam::123456789012:role/rds-s3-export-role \\\n  --kms-key-id alias/aws/rds\n```\n\n## Maintenance\n\n### Maintenance Window\n\n```bash\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --preferred-maintenance-window \"sun:04:00-sun:05:00\"\n```\n\n### Pending Maintenance\n\n```bash\n# View pending maintenance\naws rds describe-pending-maintenance-actions\n\n# Apply immediately\naws rds apply-pending-maintenance-action \\\n  --resource-identifier arn:aws:rds:us-east-1:123456789012:db:my-postgres \\\n  --apply-action system-update \\\n  --opt-in-type immediate\n```\n\n### Engine Upgrades\n\n```bash\n# Check available versions\naws rds describe-db-engine-versions \\\n  --engine postgres \\\n  --engine-version 15.4 \\\n  --query \"DBEngineVersions[].ValidUpgradeTarget\"\n\n# Upgrade (causes downtime)\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --engine-version 16.1 \\\n  --allow-major-version-upgrade \\\n  --apply-immediately\n```\n\n## Monitoring\n\n### CloudWatch Metrics\n\nKey metrics to monitor:\n\n| Metric | Description | Alarm Threshold |\n|--------|-------------|-----------------|\n| CPUUtilization | CPU usage % | > 80% |\n| DatabaseConnections | Active connections | > 80% of max_connections |\n| FreeableMemory | Available RAM | < 256 MB |\n| FreeStorageSpace | Available storage | < 20% |\n| ReadIOPS, WriteIOPS | I/O operations | Near provisioned IOPS |\n| ReadLatency, WriteLatency | I/O latency | > 20ms |\n| DiskQueueDepth | Pending I/O requests | > 5 |\n| ReplicaLag | Replication delay | > 60 seconds |\n\n### Enhanced Monitoring\n\n```bash\n# Create IAM role for enhanced monitoring\naws iam create-role \\\n  --role-name rds-monitoring-role \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"monitoring.rds.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }]\n  }'\n\naws iam attach-role-policy \\\n  --role-name rds-monitoring-role \\\n  --policy-arn arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\n\n# Enable on instance\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --monitoring-interval 60 \\\n  --monitoring-role-arn arn:aws:iam::123456789012:role/rds-monitoring-role\n```\n\n### Performance Insights\n\n```bash\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --enable-performance-insights \\\n  --performance-insights-retention-period 7 \\\n  --performance-insights-kms-key-id alias/aws/rds\n```\n\n### CloudWatch Logs\n\n```bash\n# Enable PostgreSQL logs\naws rds modify-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --cloudwatch-logs-export-configuration '{\n    \"EnableLogTypes\": [\"postgresql\", \"upgrade\"]\n  }'\n\n# Enable MySQL logs\naws rds modify-db-instance \\\n  --db-instance-identifier my-mysql \\\n  --cloudwatch-logs-export-configuration '{\n    \"EnableLogTypes\": [\"audit\", \"error\", \"general\", \"slowquery\"]\n  }'\n```\n\n## Secrets Manager Integration\n\n### Create Secret with Rotation\n\n```bash\n# Create secret\naws secretsmanager create-secret \\\n  --name rds/my-postgres/admin \\\n  --secret-string '{\"username\":\"admin\",\"password\":\"InitialPassword123!\"}'\n\n# Enable rotation\naws secretsmanager rotate-secret \\\n  --secret-id rds/my-postgres/admin \\\n  --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:SecretsManagerRDSPostgreSQLRotation \\\n  --rotation-rules AutomaticallyAfterDays=30\n```\n\n### Use Secret in Application\n\n```python\nimport boto3\nimport json\nimport psycopg2\n\nsecrets = boto3.client('secretsmanager')\n\ndef get_connection():\n    secret = secrets.get_secret_value(SecretId='rds/my-postgres/admin')\n    creds = json.loads(secret['SecretString'])\n\n    return psycopg2.connect(\n        host=creds['host'],\n        port=creds['port'],\n        database=creds['dbname'],\n        user=creds['username'],\n        password=creds['password']\n    )\n```\n\n## Failover and Recovery\n\n### Manual Failover (Multi-AZ)\n\n```bash\naws rds reboot-db-instance \\\n  --db-instance-identifier my-postgres \\\n  --force-failover\n```\n\n### Promote Read Replica\n\n```bash\naws rds promote-read-replica \\\n  --db-instance-identifier my-postgres-replica \\\n  --backup-retention-period 7\n```\n\n### Blue-Green Deployment\n\n```bash\n# Create blue-green deployment\naws rds create-blue-green-deployment \\\n  --blue-green-deployment-name my-bg-deployment \\\n  --source arn:aws:rds:us-east-1:123456789012:db:my-postgres \\\n  --target-engine-version 16.1\n\n# Switchover (after testing green)\naws rds switchover-blue-green-deployment \\\n  --blue-green-deployment-identifier bgd-abc123\n```\n",
        "skills/s3/SKILL.md": "---\nname: s3\ndescription: AWS S3 object storage for bucket management, object operations, and access control. Use when creating buckets, uploading files, configuring lifecycle policies, setting up static websites, managing permissions, or implementing cross-region replication.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AmazonS3/latest/userguide/\n---\n\n# AWS S3\n\nAmazon Simple Storage Service (S3) provides scalable object storage with industry-leading durability (99.999999999%). S3 is fundamental to AWSâ€”used for data lakes, backups, static websites, and as storage for many other AWS services.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Buckets\n\nContainers for objects. Bucket names are globally unique across all AWS accounts.\n\n### Objects\n\nFiles stored in S3, consisting of data, metadata, and a unique key (path). Maximum size: 5 TB.\n\n### Storage Classes\n\n| Class | Use Case | Durability | Availability |\n|-------|----------|------------|--------------|\n| Standard | Frequently accessed | 99.999999999% | 99.99% |\n| Intelligent-Tiering | Unknown access patterns | 99.999999999% | 99.9% |\n| Standard-IA | Infrequent access | 99.999999999% | 99.9% |\n| Glacier Instant | Archive with instant retrieval | 99.999999999% | 99.9% |\n| Glacier Flexible | Archive (minutes to hours) | 99.999999999% | 99.99% |\n| Glacier Deep Archive | Long-term archive | 99.999999999% | 99.99% |\n\n### Versioning\n\nKeeps multiple versions of an object. Essential for data protection and recovery.\n\n## Common Patterns\n\n### Create a Bucket with Best Practices\n\n**AWS CLI:**\n\n```bash\n# Create bucket (us-east-1 doesn't need LocationConstraint)\naws s3api create-bucket \\\n  --bucket my-secure-bucket-12345 \\\n  --region us-west-2 \\\n  --create-bucket-configuration LocationConstraint=us-west-2\n\n# Enable versioning\naws s3api put-bucket-versioning \\\n  --bucket my-secure-bucket-12345 \\\n  --versioning-configuration Status=Enabled\n\n# Block public access\naws s3api put-public-access-block \\\n  --bucket my-secure-bucket-12345 \\\n  --public-access-block-configuration \\\n    BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\n\n# Enable encryption\naws s3api put-bucket-encryption \\\n  --bucket my-secure-bucket-12345 \\\n  --server-side-encryption-configuration '{\n    \"Rules\": [{\"ApplyServerSideEncryptionByDefault\": {\"SSEAlgorithm\": \"AES256\"}}]\n  }'\n```\n\n**boto3:**\n\n```python\nimport boto3\n\ns3 = boto3.client('s3', region_name='us-west-2')\n\n# Create bucket\ns3.create_bucket(\n    Bucket='my-secure-bucket-12345',\n    CreateBucketConfiguration={'LocationConstraint': 'us-west-2'}\n)\n\n# Enable versioning\ns3.put_bucket_versioning(\n    Bucket='my-secure-bucket-12345',\n    VersioningConfiguration={'Status': 'Enabled'}\n)\n\n# Block public access\ns3.put_public_access_block(\n    Bucket='my-secure-bucket-12345',\n    PublicAccessBlockConfiguration={\n        'BlockPublicAcls': True,\n        'IgnorePublicAcls': True,\n        'BlockPublicPolicy': True,\n        'RestrictPublicBuckets': True\n    }\n)\n```\n\n### Upload and Download Objects\n\n```bash\n# Upload a single file\naws s3 cp myfile.txt s3://my-bucket/path/myfile.txt\n\n# Upload with metadata\naws s3 cp myfile.txt s3://my-bucket/path/myfile.txt \\\n  --metadata \"environment=production,version=1.0\"\n\n# Download a file\naws s3 cp s3://my-bucket/path/myfile.txt ./myfile.txt\n\n# Sync a directory\naws s3 sync ./local-folder s3://my-bucket/prefix/ --delete\n\n# Copy between buckets\naws s3 cp s3://source-bucket/file.txt s3://dest-bucket/file.txt\n```\n\n### Generate Presigned URL\n\n```python\nimport boto3\nfrom botocore.config import Config\n\ns3 = boto3.client('s3', config=Config(signature_version='s3v4'))\n\n# Generate presigned URL for download (GET)\nurl = s3.generate_presigned_url(\n    'get_object',\n    Params={'Bucket': 'my-bucket', 'Key': 'path/to/file.txt'},\n    ExpiresIn=3600  # URL valid for 1 hour\n)\n\n# Generate presigned URL for upload (PUT)\nupload_url = s3.generate_presigned_url(\n    'put_object',\n    Params={\n        'Bucket': 'my-bucket',\n        'Key': 'uploads/newfile.txt',\n        'ContentType': 'text/plain'\n    },\n    ExpiresIn=3600\n)\n```\n\n### Configure Lifecycle Policy\n\n```bash\ncat > lifecycle.json << 'EOF'\n{\n  \"Rules\": [\n    {\n      \"ID\": \"MoveToGlacierAfter90Days\",\n      \"Status\": \"Enabled\",\n      \"Filter\": {\"Prefix\": \"logs/\"},\n      \"Transitions\": [\n        {\"Days\": 90, \"StorageClass\": \"GLACIER\"}\n      ],\n      \"Expiration\": {\"Days\": 365}\n    },\n    {\n      \"ID\": \"DeleteOldVersions\",\n      \"Status\": \"Enabled\",\n      \"Filter\": {},\n      \"NoncurrentVersionExpiration\": {\"NoncurrentDays\": 30}\n    }\n  ]\n}\nEOF\n\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket my-bucket \\\n  --lifecycle-configuration file://lifecycle.json\n```\n\n### Event Notifications to Lambda\n\n```bash\naws s3api put-bucket-notification-configuration \\\n  --bucket my-bucket \\\n  --notification-configuration '{\n    \"LambdaFunctionConfigurations\": [\n      {\n        \"LambdaFunctionArn\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessS3Upload\",\n        \"Events\": [\"s3:ObjectCreated:*\"],\n        \"Filter\": {\n          \"Key\": {\n            \"FilterRules\": [\n              {\"Name\": \"prefix\", \"Value\": \"uploads/\"},\n              {\"Name\": \"suffix\", \"Value\": \".jpg\"}\n            ]\n          }\n        }\n      }\n    ]\n  }'\n```\n\n## CLI Reference\n\n### High-Level Commands (aws s3)\n\n| Command | Description |\n|---------|-------------|\n| `aws s3 ls` | List buckets or objects |\n| `aws s3 cp` | Copy files |\n| `aws s3 mv` | Move files |\n| `aws s3 rm` | Delete files |\n| `aws s3 sync` | Sync directories |\n| `aws s3 mb` | Make bucket |\n| `aws s3 rb` | Remove bucket |\n\n### Low-Level Commands (aws s3api)\n\n| Command | Description |\n|---------|-------------|\n| `aws s3api create-bucket` | Create bucket with options |\n| `aws s3api put-object` | Upload with full control |\n| `aws s3api get-object` | Download with options |\n| `aws s3api delete-object` | Delete single object |\n| `aws s3api put-bucket-policy` | Set bucket policy |\n| `aws s3api put-bucket-versioning` | Enable versioning |\n| `aws s3api list-object-versions` | List all versions |\n\n### Useful Flags\n\n- `--recursive`: Process all objects in prefix\n- `--exclude/--include`: Filter objects\n- `--dryrun`: Preview changes\n- `--storage-class`: Set storage class\n- `--acl`: Set access control (prefer policies instead)\n\n## Best Practices\n\n### Security\n\n- **Block public access** at account and bucket level\n- **Enable versioning** for data protection\n- **Use bucket policies** over ACLs\n- **Enable encryption** (SSE-S3 or SSE-KMS)\n- **Enable access logging** for audit\n- **Use VPC endpoints** for private access\n- **Enable MFA Delete** for critical buckets\n\n### Performance\n\n- **Use Transfer Acceleration** for distant uploads\n- **Use multipart upload** for files > 100 MB\n- **Randomize key prefixes** for high-throughput (less relevant with 2024 improvements)\n- **Use byte-range fetches** for large file downloads\n\n### Cost Optimization\n\n- **Use lifecycle policies** to transition to cheaper storage\n- **Enable Intelligent-Tiering** for unpredictable access\n- **Delete incomplete multipart uploads**:\n  ```json\n  {\n    \"Rules\": [{\n      \"ID\": \"AbortIncompleteMultipartUpload\",\n      \"Status\": \"Enabled\",\n      \"Filter\": {},\n      \"AbortIncompleteMultipartUpload\": {\"DaysAfterInitiation\": 7}\n    }]\n  }\n  ```\n- **Use S3 Storage Lens** to analyze storage patterns\n\n## Troubleshooting\n\n### Access Denied Errors\n\n**Causes:**\n1. Bucket policy denies access\n2. IAM policy missing permissions\n3. Public access block preventing access\n4. Object owned by different account\n5. VPC endpoint policy blocking\n\n**Debug steps:**\n\n```bash\n# Check your identity\naws sts get-caller-identity\n\n# Check bucket policy\naws s3api get-bucket-policy --bucket my-bucket\n\n# Check public access block\naws s3api get-public-access-block --bucket my-bucket\n\n# Check object ownership\naws s3api get-object-attributes \\\n  --bucket my-bucket \\\n  --key myfile.txt \\\n  --object-attributes ObjectOwner\n```\n\n### CORS Errors\n\n**Symptom:** Browser blocks cross-origin request\n\n**Fix:**\n\n```bash\naws s3api put-bucket-cors --bucket my-bucket --cors-configuration '{\n  \"CORSRules\": [{\n    \"AllowedOrigins\": [\"https://myapp.com\"],\n    \"AllowedMethods\": [\"GET\", \"PUT\", \"POST\"],\n    \"AllowedHeaders\": [\"*\"],\n    \"ExposeHeaders\": [\"ETag\"],\n    \"MaxAgeSeconds\": 3600\n  }]\n}'\n```\n\n### Slow Uploads\n\n**Solutions:**\n- Use multipart upload for large files\n- Enable Transfer Acceleration\n- Use `aws s3 cp` with `--expected-size` for large files\n- Check network throughput to the region\n\n### 403 on Presigned URL\n\n**Causes:**\n- URL expired\n- Signer lacks permissions\n- Bucket policy blocks access\n- Region mismatch (v4 signatures are region-specific)\n\n**Fix:** Ensure signer has permissions and use correct region.\n\n## References\n\n- [S3 User Guide](https://docs.aws.amazon.com/AmazonS3/latest/userguide/)\n- [S3 API Reference](https://docs.aws.amazon.com/AmazonS3/latest/API/)\n- [S3 CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/s3/)\n- [boto3 S3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html)\n",
        "skills/s3/security.md": "# S3 Security Configuration\n\nComprehensive security configurations for S3 buckets.\n\n## Access Control Hierarchy\n\nS3 access is evaluated in this order:\n\n1. **Account-level public access block** (strongest)\n2. **Bucket-level public access block**\n3. **Bucket policy**\n4. **IAM policies**\n5. **ACLs** (legacy, avoid using)\n\n## Block Public Access\n\n### Account-Level Block\n\n```bash\naws s3control put-public-access-block \\\n  --account-id 123456789012 \\\n  --public-access-block-configuration \\\n    BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\n```\n\n### Bucket-Level Block\n\n```bash\naws s3api put-public-access-block \\\n  --bucket my-bucket \\\n  --public-access-block-configuration '{\n    \"BlockPublicAcls\": true,\n    \"IgnorePublicAcls\": true,\n    \"BlockPublicPolicy\": true,\n    \"RestrictPublicBuckets\": true\n  }'\n```\n\n### Setting Explanations\n\n| Setting | Effect |\n|---------|--------|\n| `BlockPublicAcls` | Rejects PUT requests with public ACLs |\n| `IgnorePublicAcls` | Ignores existing public ACLs |\n| `BlockPublicPolicy` | Rejects bucket policies that grant public access |\n| `RestrictPublicBuckets` | Restricts access to AWS principals only |\n\n## Bucket Policies\n\n### Deny Unencrypted Uploads\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyUnencryptedUploads\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:PutObject\",\n      \"Resource\": \"arn:aws:s3:::my-bucket/*\",\n      \"Condition\": {\n        \"Null\": {\n          \"s3:x-amz-server-side-encryption\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Enforce HTTPS Only\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyHTTP\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:*\",\n      \"Resource\": [\n        \"arn:aws:s3:::my-bucket\",\n        \"arn:aws:s3:::my-bucket/*\"\n      ],\n      \"Condition\": {\n        \"Bool\": {\n          \"aws:SecureTransport\": \"false\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Restrict to VPC Endpoint\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"RestrictToVPCEndpoint\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:*\",\n      \"Resource\": [\n        \"arn:aws:s3:::my-bucket\",\n        \"arn:aws:s3:::my-bucket/*\"\n      ],\n      \"Condition\": {\n        \"StringNotEquals\": {\n          \"aws:SourceVpce\": \"vpce-1234567890abcdef0\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Cross-Account Access\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"CrossAccountAccess\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::111111111111:role/CrossAccountRole\"\n      },\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::my-bucket\",\n        \"arn:aws:s3:::my-bucket/*\"\n      ]\n    }\n  ]\n}\n```\n\n### Restrict to Specific IP Ranges\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"RestrictToOfficeIPs\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:*\",\n      \"Resource\": [\n        \"arn:aws:s3:::my-bucket\",\n        \"arn:aws:s3:::my-bucket/*\"\n      ],\n      \"Condition\": {\n        \"NotIpAddress\": {\n          \"aws:SourceIp\": [\"192.0.2.0/24\", \"203.0.113.0/24\"]\n        },\n        \"Null\": {\n          \"aws:SourceVpc\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## Encryption\n\n### Server-Side Encryption (SSE-S3)\n\n```bash\n# Set default encryption\naws s3api put-bucket-encryption \\\n  --bucket my-bucket \\\n  --server-side-encryption-configuration '{\n    \"Rules\": [{\n      \"ApplyServerSideEncryptionByDefault\": {\n        \"SSEAlgorithm\": \"AES256\"\n      },\n      \"BucketKeyEnabled\": true\n    }]\n  }'\n```\n\n### SSE-KMS (Customer Managed Key)\n\n```bash\naws s3api put-bucket-encryption \\\n  --bucket my-bucket \\\n  --server-side-encryption-configuration '{\n    \"Rules\": [{\n      \"ApplyServerSideEncryptionByDefault\": {\n        \"SSEAlgorithm\": \"aws:kms\",\n        \"KMSMasterKeyID\": \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n      },\n      \"BucketKeyEnabled\": true\n    }]\n  }'\n```\n\n### Bucket Key\n\nEnable Bucket Key to reduce KMS API calls and costs:\n\n```bash\naws s3api put-bucket-encryption \\\n  --bucket my-bucket \\\n  --server-side-encryption-configuration '{\n    \"Rules\": [{\n      \"ApplyServerSideEncryptionByDefault\": {\n        \"SSEAlgorithm\": \"aws:kms\",\n        \"KMSMasterKeyID\": \"alias/my-key\"\n      },\n      \"BucketKeyEnabled\": true\n    }]\n  }'\n```\n\n## Versioning and MFA Delete\n\n### Enable Versioning\n\n```bash\naws s3api put-bucket-versioning \\\n  --bucket my-bucket \\\n  --versioning-configuration Status=Enabled\n```\n\n### Enable MFA Delete\n\nRequires using root credentials:\n\n```bash\naws s3api put-bucket-versioning \\\n  --bucket my-bucket \\\n  --versioning-configuration Status=Enabled,MFADelete=Enabled \\\n  --mfa \"arn:aws:iam::123456789012:mfa/root-account-mfa-device 123456\"\n```\n\n## Access Logging\n\n```bash\n# Create logging bucket\naws s3api create-bucket --bucket my-bucket-logs --region us-east-1\n\n# Set ACL for S3 log delivery\naws s3api put-bucket-acl \\\n  --bucket my-bucket-logs \\\n  --grant-write URI=http://acs.amazonaws.com/groups/s3/LogDelivery \\\n  --grant-read-acp URI=http://acs.amazonaws.com/groups/s3/LogDelivery\n\n# Enable logging on source bucket\naws s3api put-bucket-logging \\\n  --bucket my-bucket \\\n  --bucket-logging-status '{\n    \"LoggingEnabled\": {\n      \"TargetBucket\": \"my-bucket-logs\",\n      \"TargetPrefix\": \"access-logs/\"\n    }\n  }'\n```\n\n## Object Lock (WORM)\n\n### Enable Object Lock on New Bucket\n\n```bash\naws s3api create-bucket \\\n  --bucket my-worm-bucket \\\n  --object-lock-enabled-for-bucket \\\n  --region us-east-1\n```\n\n### Set Default Retention\n\n```bash\naws s3api put-object-lock-configuration \\\n  --bucket my-worm-bucket \\\n  --object-lock-configuration '{\n    \"ObjectLockEnabled\": \"Enabled\",\n    \"Rule\": {\n      \"DefaultRetention\": {\n        \"Mode\": \"GOVERNANCE\",\n        \"Days\": 365\n      }\n    }\n  }'\n```\n\n### Retention Modes\n\n| Mode | Description |\n|------|-------------|\n| **Governance** | Users with special permissions can delete |\n| **Compliance** | No one can delete until retention expires |\n\n## VPC Endpoint Access\n\n### Create Gateway Endpoint\n\n```bash\naws ec2 create-vpc-endpoint \\\n  --vpc-id vpc-12345678 \\\n  --service-name com.amazonaws.us-east-1.s3 \\\n  --route-table-ids rtb-12345678\n```\n\n### Endpoint Policy\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": [\"s3:GetObject\", \"s3:PutObject\"],\n      \"Resource\": \"arn:aws:s3:::my-bucket/*\"\n    }\n  ]\n}\n```\n\n## Security Monitoring\n\n### S3 Access Analyzer\n\n```bash\n# Check for public or shared buckets\naws accessanalyzer list-analyzed-resources \\\n  --analyzer-arn arn:aws:access-analyzer:us-east-1:123456789012:analyzer/MyAnalyzer \\\n  --resource-type AWS::S3::Bucket\n```\n\n### CloudTrail Data Events\n\n```bash\naws cloudtrail put-event-selectors \\\n  --trail-name MyTrail \\\n  --event-selectors '[{\n    \"ReadWriteType\": \"All\",\n    \"IncludeManagementEvents\": true,\n    \"DataResources\": [{\n      \"Type\": \"AWS::S3::Object\",\n      \"Values\": [\"arn:aws:s3:::my-bucket/\"]\n    }]\n  }]'\n```\n\n## Security Checklist\n\n- [ ] Public access blocked at account level\n- [ ] Public access blocked at bucket level\n- [ ] Bucket policy enforces HTTPS\n- [ ] Server-side encryption enabled\n- [ ] Versioning enabled\n- [ ] MFA Delete enabled (critical buckets)\n- [ ] Access logging enabled\n- [ ] CloudTrail data events enabled\n- [ ] VPC endpoint for private access\n- [ ] Object Lock for compliance (if needed)\n- [ ] Regular access reviews with Access Analyzer\n",
        "skills/secrets-manager/SKILL.md": "---\nname: secrets-manager\ndescription: AWS Secrets Manager for secure secret storage and rotation. Use when storing credentials, configuring automatic rotation, managing secret versions, retrieving secrets in applications, or integrating with RDS.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/secretsmanager/latest/userguide/\n---\n\n# AWS Secrets Manager\n\nAWS Secrets Manager helps protect access to applications, services, and IT resources. Store, retrieve, and automatically rotate credentials, API keys, and other secrets.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Secrets\n\nEncrypted data stored in Secrets Manager. Can contain:\n- Database credentials\n- API keys\n- OAuth tokens\n- Any key-value pairs (up to 64 KB)\n\n### Versions\n\nEach secret can have multiple versions:\n- **AWSCURRENT**: Current active version\n- **AWSPENDING**: Version being rotated to\n- **AWSPREVIOUS**: Previous version\n\n### Rotation\n\nAutomatic credential rotation using Lambda functions. Built-in support for:\n- Amazon RDS\n- Amazon Redshift\n- Amazon DocumentDB\n- Custom secrets\n\n## Common Patterns\n\n### Create a Secret\n\n**AWS CLI:**\n\n```bash\n# Create secret with JSON\naws secretsmanager create-secret \\\n  --name prod/myapp/database \\\n  --description \"Production database credentials\" \\\n  --secret-string '{\"username\":\"admin\",\"password\":\"MySecurePassword123!\",\"host\":\"mydb.cluster-xyz.us-east-1.rds.amazonaws.com\",\"port\":5432,\"database\":\"myapp\"}'\n\n# Create secret with binary data\naws secretsmanager create-secret \\\n  --name prod/myapp/certificate \\\n  --secret-binary fileb://certificate.pem\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport json\n\nsecrets = boto3.client('secretsmanager')\n\nresponse = secrets.create_secret(\n    Name='prod/myapp/database',\n    Description='Production database credentials',\n    SecretString=json.dumps({\n        'username': 'admin',\n        'password': 'MySecurePassword123!',\n        'host': 'mydb.cluster-xyz.us-east-1.rds.amazonaws.com',\n        'port': 5432,\n        'database': 'myapp'\n    }),\n    Tags=[\n        {'Key': 'Environment', 'Value': 'production'},\n        {'Key': 'Application', 'Value': 'myapp'}\n    ]\n)\n```\n\n### Retrieve a Secret\n\n```python\nimport boto3\nimport json\n\nsecrets = boto3.client('secretsmanager')\n\ndef get_secret(secret_name):\n    response = secrets.get_secret_value(SecretId=secret_name)\n\n    if 'SecretString' in response:\n        return json.loads(response['SecretString'])\n    else:\n        import base64\n        return base64.b64decode(response['SecretBinary'])\n\n# Usage\ncredentials = get_secret('prod/myapp/database')\ndb_password = credentials['password']\n```\n\n### Caching Secrets\n\n```python\nfrom aws_secretsmanager_caching import SecretCache, SecretCacheConfig\n\n# Configure cache\ncache_config = SecretCacheConfig(\n    max_cache_size=100,\n    secret_refresh_interval=3600,\n    secret_version_stage_refresh_interval=3600\n)\n\ncache = SecretCache(config=cache_config)\n\ndef get_cached_secret(secret_name):\n    secret = cache.get_secret_string(secret_name)\n    return json.loads(secret)\n```\n\n### Update a Secret\n\n```bash\n# Update secret value\naws secretsmanager update-secret \\\n  --secret-id prod/myapp/database \\\n  --secret-string '{\"username\":\"admin\",\"password\":\"NewPassword456!\"}'\n\n# Put new version with staging labels\naws secretsmanager put-secret-value \\\n  --secret-id prod/myapp/database \\\n  --secret-string '{\"username\":\"admin\",\"password\":\"NewPassword456!\"}' \\\n  --version-stages AWSCURRENT\n```\n\n### Enable Rotation for RDS\n\n```bash\naws secretsmanager rotate-secret \\\n  --secret-id prod/myapp/database \\\n  --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:SecretsManagerRDSPostgreSQLRotation \\\n  --rotation-rules AutomaticallyAfterDays=30\n```\n\n### Create Secret with Rotation\n\n```bash\n# Use CloudFormation for RDS secret with rotation\naws cloudformation deploy \\\n  --template-file rds-secret.yaml \\\n  --stack-name rds-secret\n```\n\n```yaml\n# rds-secret.yaml\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  DBSecret:\n    Type: AWS::SecretsManager::Secret\n    Properties:\n      Name: prod/myapp/database\n      GenerateSecretString:\n        SecretStringTemplate: '{\"username\": \"admin\"}'\n        GenerateStringKey: password\n        PasswordLength: 32\n        ExcludeCharacters: '\"@/\\'\n\n  DBSecretRotation:\n    Type: AWS::SecretsManager::RotationSchedule\n    Properties:\n      SecretId: !Ref DBSecret\n      RotationLambdaARN: !GetAtt RotationLambda.Arn\n      RotationRules:\n        AutomaticallyAfterDays: 30\n```\n\n### Use in Lambda with Extension\n\n```python\nimport json\nimport urllib.request\n\ndef handler(event, context):\n    # Use AWS Parameters and Secrets Lambda Extension\n    secrets_port = 2773\n    secret_name = 'prod/myapp/database'\n\n    url = f'http://localhost:{secrets_port}/secretsmanager/get?secretId={secret_name}'\n    headers = {'X-Aws-Parameters-Secrets-Token': os.environ['AWS_SESSION_TOKEN']}\n\n    request = urllib.request.Request(url, headers=headers)\n    response = urllib.request.urlopen(request)\n    secret = json.loads(response.read())['SecretString']\n\n    credentials = json.loads(secret)\n    return credentials\n```\n\n## CLI Reference\n\n### Secret Management\n\n| Command | Description |\n|---------|-------------|\n| `aws secretsmanager create-secret` | Create secret |\n| `aws secretsmanager describe-secret` | Get secret metadata |\n| `aws secretsmanager get-secret-value` | Retrieve secret value |\n| `aws secretsmanager update-secret` | Update secret |\n| `aws secretsmanager delete-secret` | Delete secret |\n| `aws secretsmanager restore-secret` | Restore deleted secret |\n| `aws secretsmanager list-secrets` | List secrets |\n\n### Versions\n\n| Command | Description |\n|---------|-------------|\n| `aws secretsmanager put-secret-value` | Add new version |\n| `aws secretsmanager list-secret-version-ids` | List versions |\n| `aws secretsmanager update-secret-version-stage` | Move staging labels |\n\n### Rotation\n\n| Command | Description |\n|---------|-------------|\n| `aws secretsmanager rotate-secret` | Configure/trigger rotation |\n| `aws secretsmanager cancel-rotate-secret` | Cancel rotation |\n\n## Best Practices\n\n### Secret Organization\n\n- **Use hierarchical names**: `environment/application/secret-type`\n- **Tag secrets** for organization and cost allocation\n- **Separate by environment** (dev, staging, prod)\n\n### Security\n\n- **Use resource policies** to control access\n- **Enable encryption** with customer-managed KMS keys\n- **Rotate secrets** regularly (30-90 days)\n- **Audit access** with CloudTrail\n- **Use VPC endpoints** for private access\n\n### Access Control\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\"\n      ],\n      \"Resource\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:prod/*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"secretsmanager:ResourceTag/Environment\": \"production\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Application Integration\n\n- **Cache secrets** to reduce API calls\n- **Handle rotation** gracefully (retry with new credentials)\n- **Use Lambda extension** for faster access\n- **Never log secrets**\n\n## Troubleshooting\n\n### AccessDeniedException\n\n**Causes:**\n- IAM policy missing `secretsmanager:GetSecretValue`\n- Resource policy denying access\n- KMS key policy missing permissions\n\n**Debug:**\n\n```bash\n# Check secret resource policy\naws secretsmanager get-resource-policy --secret-id my-secret\n\n# Check IAM permissions\naws iam simulate-principal-policy \\\n  --policy-source-arn arn:aws:iam::123456789012:role/my-role \\\n  --action-names secretsmanager:GetSecretValue \\\n  --resource-arns arn:aws:secretsmanager:us-east-1:123456789012:secret:my-secret\n```\n\n### Rotation Failed\n\n**Debug:**\n\n```bash\n# Check rotation status\naws secretsmanager describe-secret --secret-id my-secret\n\n# Check Lambda logs\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/SecretsManagerRotation \\\n  --filter-pattern \"ERROR\"\n```\n\n**Common causes:**\n- Lambda timeout (increase to 30+ seconds)\n- Network connectivity (VPC configuration)\n- Database connection issues\n- Wrong secret format\n\n### Secret Not Found\n\n```bash\n# List secrets to find correct name\naws secretsmanager list-secrets \\\n  --filters Key=name,Values=myapp\n\n# Check if deleted (within recovery window)\naws secretsmanager list-secrets \\\n  --include-planned-deletion\n```\n\n## References\n\n- [Secrets Manager User Guide](https://docs.aws.amazon.com/secretsmanager/latest/userguide/)\n- [Secrets Manager API Reference](https://docs.aws.amazon.com/secretsmanager/latest/apireference/)\n- [Secrets Manager CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/secretsmanager/)\n- [boto3 Secrets Manager](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager.html)\n",
        "skills/secrets-manager/rotation-strategies.md": "# Secrets Manager Rotation Strategies\n\nSecret rotation patterns and Lambda rotation functions.\n\n## Rotation Strategies\n\n### Single User Rotation\n\nOne user, password changes in place. Brief connection interruption during rotation.\n\n```\n1. AWSCURRENT has current password\n2. Lambda creates new password â†’ AWSPENDING\n3. Lambda updates database with new password\n4. Lambda tests AWSPENDING credentials\n5. Lambda moves AWSPENDING â†’ AWSCURRENT\n```\n\n### Alternating Users Rotation\n\nTwo users alternate, zero downtime.\n\n```\nUser A (AWSCURRENT) â†’ User B (AWSPENDING)\n1. Lambda creates new password for User B\n2. Lambda updates User B in database\n3. Lambda tests User B credentials\n4. Lambda moves User B â†’ AWSCURRENT\n5. Next rotation: User A becomes AWSPENDING\n```\n\n## Built-in Rotation Functions\n\n### RDS PostgreSQL\n\n```bash\n# Use AWS-provided rotation Lambda\naws secretsmanager rotate-secret \\\n  --secret-id prod/myapp/database \\\n  --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:SecretsManagerRDSPostgreSQLRotationSingleUser \\\n  --rotation-rules AutomaticallyAfterDays=30\n```\n\n### RDS MySQL\n\n```bash\naws secretsmanager rotate-secret \\\n  --secret-id prod/myapp/database \\\n  --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:SecretsManagerRDSMySQLRotationSingleUser \\\n  --rotation-rules AutomaticallyAfterDays=30\n```\n\n### Deploy Rotation Lambda\n\n```bash\n# Use SAR to deploy rotation function\naws serverlessrepo create-cloud-formation-change-set \\\n  --application-id arn:aws:serverlessrepo:us-east-1:297356227824:applications/SecretsManagerRDSPostgreSQLRotationSingleUser \\\n  --stack-name rds-rotation-lambda \\\n  --capabilities CAPABILITY_IAM \\\n  --parameter-overrides \\\n    Name=endpoint,Value=mydb.cluster-xyz.us-east-1.rds.amazonaws.com \\\n    Name=functionName,Value=SecretsManagerRDSPostgreSQLRotation\n```\n\n## Custom Rotation Lambda\n\n### Lambda Structure\n\n```python\nimport boto3\nimport json\nimport logging\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\nsecrets = boto3.client('secretsmanager')\n\ndef handler(event, context):\n    secret_id = event['SecretId']\n    token = event['ClientRequestToken']\n    step = event['Step']\n\n    if step == 'createSecret':\n        create_secret(secret_id, token)\n    elif step == 'setSecret':\n        set_secret(secret_id, token)\n    elif step == 'testSecret':\n        test_secret(secret_id, token)\n    elif step == 'finishSecret':\n        finish_secret(secret_id, token)\n    else:\n        raise ValueError(f'Unknown step: {step}')\n\ndef create_secret(secret_id, token):\n    \"\"\"Create new secret version with AWSPENDING label.\"\"\"\n    # Check if already exists\n    try:\n        secrets.get_secret_value(\n            SecretId=secret_id,\n            VersionId=token,\n            VersionStage='AWSPENDING'\n        )\n        logger.info('AWSPENDING already exists')\n        return\n    except secrets.exceptions.ResourceNotFoundException:\n        pass\n\n    # Get current secret\n    current = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionStage='AWSCURRENT'\n    )\n    current_secret = json.loads(current['SecretString'])\n\n    # Generate new password\n    new_password = secrets.get_random_password(\n        PasswordLength=32,\n        ExcludeCharacters='\"@/\\\\'\n    )['RandomPassword']\n\n    # Create new version\n    new_secret = current_secret.copy()\n    new_secret['password'] = new_password\n\n    secrets.put_secret_value(\n        SecretId=secret_id,\n        ClientRequestToken=token,\n        SecretString=json.dumps(new_secret),\n        VersionStages=['AWSPENDING']\n    )\n\ndef set_secret(secret_id, token):\n    \"\"\"Update the resource with the new credentials.\"\"\"\n    pending = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionId=token,\n        VersionStage='AWSPENDING'\n    )\n    pending_secret = json.loads(pending['SecretString'])\n\n    # Update the actual resource (e.g., API key in external service)\n    # This is where you'd call your service's API to update the credential\n    update_resource_credential(pending_secret)\n\ndef test_secret(secret_id, token):\n    \"\"\"Test that the new credentials work.\"\"\"\n    pending = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionId=token,\n        VersionStage='AWSPENDING'\n    )\n    pending_secret = json.loads(pending['SecretString'])\n\n    # Test the credentials\n    if not verify_credentials_work(pending_secret):\n        raise ValueError('New credentials failed validation')\n\ndef finish_secret(secret_id, token):\n    \"\"\"Finalize rotation by moving labels.\"\"\"\n    # Get current version\n    metadata = secrets.describe_secret(SecretId=secret_id)\n\n    current_version = None\n    for version_id, stages in metadata['VersionIdsToStages'].items():\n        if 'AWSCURRENT' in stages:\n            current_version = version_id\n            break\n\n    # Move AWSCURRENT to new version\n    secrets.update_secret_version_stage(\n        SecretId=secret_id,\n        VersionStage='AWSCURRENT',\n        MoveToVersionId=token,\n        RemoveFromVersionId=current_version\n    )\n```\n\n### API Key Rotation Example\n\n```python\nimport boto3\nimport json\nimport requests\n\nsecrets = boto3.client('secretsmanager')\n\ndef set_secret(secret_id, token):\n    \"\"\"Rotate API key in external service.\"\"\"\n    # Get pending secret\n    pending = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionId=token,\n        VersionStage='AWSPENDING'\n    )\n    pending_secret = json.loads(pending['SecretString'])\n\n    # Get current secret (for authentication)\n    current = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionStage='AWSCURRENT'\n    )\n    current_secret = json.loads(current['SecretString'])\n\n    # Call external API to create new key\n    response = requests.post(\n        'https://api.example.com/v1/api-keys/rotate',\n        headers={'Authorization': f'Bearer {current_secret[\"api_key\"]}'},\n        json={'new_key': pending_secret['api_key']}\n    )\n\n    if response.status_code != 200:\n        raise Exception(f'Failed to rotate API key: {response.text}')\n\ndef test_secret(secret_id, token):\n    \"\"\"Test new API key works.\"\"\"\n    pending = secrets.get_secret_value(\n        SecretId=secret_id,\n        VersionId=token,\n        VersionStage='AWSPENDING'\n    )\n    pending_secret = json.loads(pending['SecretString'])\n\n    response = requests.get(\n        'https://api.example.com/v1/me',\n        headers={'Authorization': f'Bearer {pending_secret[\"api_key\"]}'}\n    )\n\n    if response.status_code != 200:\n        raise Exception('New API key validation failed')\n```\n\n## VPC Configuration\n\nFor RDS rotation, Lambda needs VPC access:\n\n```yaml\nResources:\n  RotationLambda:\n    Type: AWS::Lambda::Function\n    Properties:\n      VpcConfig:\n        SecurityGroupIds:\n          - !Ref LambdaSecurityGroup\n        SubnetIds:\n          - !Ref PrivateSubnet1\n          - !Ref PrivateSubnet2\n\n  LambdaSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      VpcId: !Ref VPC\n      SecurityGroupEgress:\n        - IpProtocol: tcp\n          FromPort: 443\n          ToPort: 443\n          CidrIp: 0.0.0.0/0  # For Secrets Manager API\n        - IpProtocol: tcp\n          FromPort: 5432\n          ToPort: 5432\n          DestinationSecurityGroupId: !Ref DBSecurityGroup\n\n  # VPC Endpoint for Secrets Manager\n  SecretsManagerEndpoint:\n    Type: AWS::EC2::VPCEndpoint\n    Properties:\n      VpcId: !Ref VPC\n      ServiceName: !Sub com.amazonaws.${AWS::Region}.secretsmanager\n      VpcEndpointType: Interface\n      SubnetIds:\n        - !Ref PrivateSubnet1\n        - !Ref PrivateSubnet2\n      SecurityGroupIds:\n        - !Ref EndpointSecurityGroup\n```\n\n## Rotation Permissions\n\n### Lambda Execution Role\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\",\n        \"secretsmanager:PutSecretValue\",\n        \"secretsmanager:UpdateSecretVersionStage\"\n      ],\n      \"Resource\": \"arn:aws:secretsmanager:us-east-1:123456789012:secret:prod/*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"secretsmanager:GetRandomPassword\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"kms:Decrypt\",\n        \"kms:GenerateDataKey\"\n      ],\n      \"Resource\": \"arn:aws:kms:us-east-1:123456789012:key/...\"\n    }\n  ]\n}\n```\n\n### Secret Resource Policy\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::123456789012:role/rotation-lambda-role\"\n      },\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:PutSecretValue\",\n        \"secretsmanager:UpdateSecretVersionStage\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"secretsmanager:VersionStage\": [\"AWSCURRENT\", \"AWSPENDING\"]\n        }\n      }\n    }\n  ]\n}\n```\n\n## Handling Rotation in Applications\n\n### Retry with New Credentials\n\n```python\nimport boto3\nimport json\nimport psycopg2\nfrom functools import wraps\n\nsecrets = boto3.client('secretsmanager')\n_cached_secret = None\n_secret_version = None\n\ndef get_db_credentials():\n    global _cached_secret, _secret_version\n\n    response = secrets.get_secret_value(SecretId='prod/myapp/database')\n\n    if response['VersionId'] != _secret_version:\n        _cached_secret = json.loads(response['SecretString'])\n        _secret_version = response['VersionId']\n\n    return _cached_secret\n\ndef with_credential_refresh(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except psycopg2.OperationalError as e:\n            if 'authentication failed' in str(e).lower():\n                # Force refresh and retry\n                global _cached_secret, _secret_version\n                _cached_secret = None\n                _secret_version = None\n                return func(*args, **kwargs)\n            raise\n    return wrapper\n\n@with_credential_refresh\ndef query_database():\n    creds = get_db_credentials()\n    conn = psycopg2.connect(\n        host=creds['host'],\n        port=creds['port'],\n        database=creds['database'],\n        user=creds['username'],\n        password=creds['password']\n    )\n    # Execute query...\n```\n\n## Monitoring Rotation\n\n### CloudWatch Alarms\n\n```bash\n# Alarm for rotation failures\naws cloudwatch put-metric-alarm \\\n  --alarm-name SecretsRotationFailed \\\n  --metric-name RotationFailure \\\n  --namespace AWS/SecretsManager \\\n  --statistic Sum \\\n  --period 86400 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Alarm for secrets not rotated\naws cloudwatch put-metric-alarm \\\n  --alarm-name SecretsNotRotated \\\n  --metric-name DaysSinceLastRotation \\\n  --namespace AWS/SecretsManager \\\n  --dimensions Name=SecretName,Value=prod/myapp/database \\\n  --statistic Maximum \\\n  --period 86400 \\\n  --threshold 45 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n",
        "skills/sns/SKILL.md": "---\nname: sns\ndescription: AWS SNS notification service for pub/sub messaging. Use when creating topics, managing subscriptions, configuring message filtering, sending notifications, or setting up mobile push.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/sns/latest/dg/\n---\n\n# AWS SNS\n\nAmazon Simple Notification Service (SNS) is a fully managed pub/sub messaging service for application-to-application (A2A) and application-to-person (A2P) communication.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Topics\n\nNamed channels for publishing messages. Publishers send to topics, subscribers receive from topics.\n\n### Topic Types\n\n| Type | Description | Use Case |\n|------|-------------|----------|\n| **Standard** | Best-effort ordering, at-least-once | Most use cases |\n| **FIFO** | Strict ordering, exactly-once | Order-sensitive |\n\n### Subscription Protocols\n\n| Protocol | Description |\n|----------|-------------|\n| **Lambda** | Invoke Lambda function |\n| **SQS** | Send to SQS queue |\n| **HTTP/HTTPS** | POST to endpoint |\n| **Email** | Send email |\n| **SMS** | Send text message |\n| **Application** | Mobile push notification |\n\n### Message Filtering\n\nRoute messages to specific subscribers based on message attributes.\n\n## Common Patterns\n\n### Create Topic and Subscribe\n\n**AWS CLI:**\n\n```bash\n# Create standard topic\naws sns create-topic --name my-topic\n\n# Create FIFO topic\naws sns create-topic \\\n  --name my-topic.fifo \\\n  --attributes FifoTopic=true\n\n# Subscribe Lambda\naws sns subscribe \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --protocol lambda \\\n  --notification-endpoint arn:aws:lambda:us-east-1:123456789012:function:my-function\n\n# Subscribe SQS\naws sns subscribe \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --protocol sqs \\\n  --notification-endpoint arn:aws:sqs:us-east-1:123456789012:my-queue\n\n# Subscribe email\naws sns subscribe \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --protocol email \\\n  --notification-endpoint user@example.com\n```\n\n**boto3:**\n\n```python\nimport boto3\n\nsns = boto3.client('sns')\n\n# Create topic\nresponse = sns.create_topic(Name='my-topic')\ntopic_arn = response['TopicArn']\n\n# Subscribe Lambda\nsns.subscribe(\n    TopicArn=topic_arn,\n    Protocol='lambda',\n    Endpoint='arn:aws:lambda:us-east-1:123456789012:function:my-function'\n)\n\n# Subscribe SQS with filter\nsns.subscribe(\n    TopicArn=topic_arn,\n    Protocol='sqs',\n    Endpoint='arn:aws:sqs:us-east-1:123456789012:order-queue',\n    Attributes={\n        'FilterPolicy': '{\"event_type\": [\"order_created\", \"order_updated\"]}'\n    }\n)\n```\n\n### Publish Messages\n\n```python\nimport boto3\nimport json\n\nsns = boto3.client('sns')\ntopic_arn = 'arn:aws:sns:us-east-1:123456789012:my-topic'\n\n# Simple publish\nsns.publish(\n    TopicArn=topic_arn,\n    Message='Hello, World!',\n    Subject='Notification'\n)\n\n# Publish with attributes (for filtering)\nsns.publish(\n    TopicArn=topic_arn,\n    Message=json.dumps({'order_id': '12345', 'status': 'created'}),\n    MessageAttributes={\n        'event_type': {\n            'DataType': 'String',\n            'StringValue': 'order_created'\n        },\n        'priority': {\n            'DataType': 'Number',\n            'StringValue': '1'\n        }\n    }\n)\n\n# Publish to FIFO topic\nsns.publish(\n    TopicArn='arn:aws:sns:us-east-1:123456789012:my-topic.fifo',\n    Message=json.dumps({'order_id': '12345'}),\n    MessageGroupId='order-12345',\n    MessageDeduplicationId='unique-id'\n)\n```\n\n### Message Filtering\n\n```bash\n# Add filter policy to subscription\naws sns set-subscription-attributes \\\n  --subscription-arn arn:aws:sns:us-east-1:123456789012:my-topic:abc123 \\\n  --attribute-name FilterPolicy \\\n  --attribute-value '{\n    \"event_type\": [\"order_created\"],\n    \"priority\": [{\"numeric\": [\">=\", 1]}]\n  }'\n```\n\nFilter policy examples:\n\n```json\n// Exact match\n{\"event_type\": [\"order_created\", \"order_updated\"]}\n\n// Prefix match\n{\"customer_id\": [{\"prefix\": \"PREMIUM-\"}]}\n\n// Numeric comparison\n{\"price\": [{\"numeric\": [\">=\", 100, \"<=\", 500]}]}\n\n// Exists check\n{\"customer_id\": [{\"exists\": true}]}\n\n// Anything but\n{\"event_type\": [{\"anything-but\": [\"deleted\"]}]}\n\n// Combined\n{\n  \"event_type\": [\"order_created\"],\n  \"region\": [\"us-east\", \"us-west\"],\n  \"priority\": [{\"numeric\": [\">=\", 1]}]\n}\n```\n\n### Fan-Out Pattern (SNS to Multiple SQS)\n\n```python\nimport boto3\nimport json\n\nsns = boto3.client('sns')\nsqs = boto3.client('sqs')\n\n# Create topic\ntopic = sns.create_topic(Name='orders-topic')\ntopic_arn = topic['TopicArn']\n\n# Create queues for different processors\nqueues = {\n    'analytics': sqs.create_queue(QueueName='order-analytics')['QueueUrl'],\n    'fulfillment': sqs.create_queue(QueueName='order-fulfillment')['QueueUrl'],\n    'notification': sqs.create_queue(QueueName='order-notification')['QueueUrl']\n}\n\n# Subscribe each queue\nfor name, queue_url in queues.items():\n    queue_arn = sqs.get_queue_attributes(\n        QueueUrl=queue_url,\n        AttributeNames=['QueueArn']\n    )['Attributes']['QueueArn']\n\n    sns.subscribe(\n        TopicArn=topic_arn,\n        Protocol='sqs',\n        Endpoint=queue_arn\n    )\n\n# One publish reaches all queues\nsns.publish(\n    TopicArn=topic_arn,\n    Message=json.dumps({'order_id': '12345', 'total': 99.99})\n)\n```\n\n### Lambda Permission for SNS\n\n```bash\naws lambda add-permission \\\n  --function-name my-function \\\n  --statement-id sns-trigger \\\n  --action lambda:InvokeFunction \\\n  --principal sns.amazonaws.com \\\n  --source-arn arn:aws:sns:us-east-1:123456789012:my-topic\n```\n\n## CLI Reference\n\n### Topic Management\n\n| Command | Description |\n|---------|-------------|\n| `aws sns create-topic` | Create topic |\n| `aws sns delete-topic` | Delete topic |\n| `aws sns list-topics` | List topics |\n| `aws sns get-topic-attributes` | Get topic settings |\n| `aws sns set-topic-attributes` | Update topic settings |\n\n### Subscriptions\n\n| Command | Description |\n|---------|-------------|\n| `aws sns subscribe` | Create subscription |\n| `aws sns unsubscribe` | Remove subscription |\n| `aws sns list-subscriptions` | List all subscriptions |\n| `aws sns list-subscriptions-by-topic` | List topic subscriptions |\n| `aws sns confirm-subscription` | Confirm pending subscription |\n\n### Publishing\n\n| Command | Description |\n|---------|-------------|\n| `aws sns publish` | Publish message |\n\n## Best Practices\n\n### Reliability\n\n- **Use SQS for durability** â€” SNS is push-based, SQS queues messages\n- **Implement retries** for HTTP/HTTPS endpoints\n- **Configure DLQ** for failed deliveries\n- **Use FIFO topics** for ordering requirements\n\n### Security\n\n- **Use topic policies** to control access\n- **Enable encryption** with SSE\n- **Use VPC endpoints** for private access\n\n```bash\n# Enable SSE\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name KmsMasterKeyId \\\n  --attribute-value alias/my-key\n```\n\n### Cost Optimization\n\n- **Use message filtering** to reduce unnecessary deliveries\n- **Batch operations** where possible\n- **Monitor and clean up** unused topics/subscriptions\n\n### Message Design\n\n- **Keep messages small** (256 KB limit)\n- **Use message attributes** for routing\n- **Include correlation IDs** for tracing\n\n## Troubleshooting\n\n### Subscription Not Receiving Messages\n\n**Check:**\n1. Subscription is confirmed (not pending)\n2. Filter policy matches message attributes\n3. Target permissions (Lambda, SQS)\n\n```bash\n# Check subscription status\naws sns list-subscriptions-by-topic \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic\n\n# Check subscription attributes\naws sns get-subscription-attributes \\\n  --subscription-arn arn:aws:sns:us-east-1:123456789012:my-topic:abc123\n```\n\n### HTTP Endpoint Not Working\n\n**Debug:**\n\n```bash\n# Check delivery status logging\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name DeliveryPolicy \\\n  --attribute-value '{\n    \"http\": {\n      \"defaultHealthyRetryPolicy\": {\n        \"minDelayTarget\": 20,\n        \"maxDelayTarget\": 20,\n        \"numRetries\": 3,\n        \"numMaxDelayRetries\": 0,\n        \"numNoDelayRetries\": 0,\n        \"numMinDelayRetries\": 0,\n        \"backoffFunction\": \"linear\"\n      }\n    }\n  }'\n```\n\n### Messages Not Matching Filter\n\n**Verify:**\n- Message attributes are set (not in body)\n- Attribute types match (String vs Number)\n- Filter policy syntax is correct\n\n```python\n# Correct: attributes must be message attributes\nsns.publish(\n    TopicArn=topic_arn,\n    Message='body content',\n    MessageAttributes={\n        'event_type': {\n            'DataType': 'String',\n            'StringValue': 'order_created'  # This is filtered\n        }\n    }\n)\n\n# Wrong: this won't be filtered\nsns.publish(\n    TopicArn=topic_arn,\n    Message=json.dumps({'event_type': 'order_created'})  # Not filtered\n)\n```\n\n### SQS Not Receiving from SNS\n\n**Check SQS queue policy:**\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"sns.amazonaws.com\"},\n      \"Action\": \"sqs:SendMessage\",\n      \"Resource\": \"arn:aws:sqs:us-east-1:123456789012:my-queue\",\n      \"Condition\": {\n        \"ArnEquals\": {\n          \"aws:SourceArn\": \"arn:aws:sns:us-east-1:123456789012:my-topic\"\n        }\n      }\n    }\n  ]\n}\n```\n\n## References\n\n- [SNS Developer Guide](https://docs.aws.amazon.com/sns/latest/dg/)\n- [SNS API Reference](https://docs.aws.amazon.com/sns/latest/api/)\n- [SNS CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/sns/)\n- [boto3 SNS](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sns.html)\n",
        "skills/sns/notification-patterns.md": "# SNS Notification Patterns\n\nAdvanced notification patterns and configurations.\n\n## Topic Policies\n\n### Allow Cross-Account Publishing\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::111111111111:root\"\n      },\n      \"Action\": \"sns:Publish\",\n      \"Resource\": \"arn:aws:sns:us-east-1:123456789012:my-topic\"\n    }\n  ]\n}\n```\n\n### Allow S3 Events\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"s3.amazonaws.com\"\n      },\n      \"Action\": \"sns:Publish\",\n      \"Resource\": \"arn:aws:sns:us-east-1:123456789012:my-topic\",\n      \"Condition\": {\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"arn:aws:s3:::my-bucket\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Allow CloudWatch Alarms\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"cloudwatch.amazonaws.com\"\n      },\n      \"Action\": \"sns:Publish\",\n      \"Resource\": \"arn:aws:sns:us-east-1:123456789012:alerts-topic\"\n    }\n  ]\n}\n```\n\n## Delivery Policies\n\n### HTTP/HTTPS Retry Policy\n\n```json\n{\n  \"http\": {\n    \"defaultHealthyRetryPolicy\": {\n      \"minDelayTarget\": 1,\n      \"maxDelayTarget\": 60,\n      \"numRetries\": 50,\n      \"numMaxDelayRetries\": 0,\n      \"numNoDelayRetries\": 3,\n      \"numMinDelayRetries\": 2,\n      \"backoffFunction\": \"exponential\"\n    },\n    \"disableSubscriptionOverrides\": false,\n    \"defaultThrottlePolicy\": {\n      \"maxReceivesPerSecond\": 10\n    }\n  }\n}\n```\n\n### Configure Delivery Policy\n\n```bash\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name DeliveryPolicy \\\n  --attribute-value file://delivery-policy.json\n```\n\n## Dead-Letter Queues\n\n### Configure DLQ for Subscription\n\n```bash\n# Create DLQ\naws sqs create-queue --queue-name sns-dlq\n\n# Get DLQ ARN\nDLQ_ARN=$(aws sqs get-queue-attributes \\\n  --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/sns-dlq \\\n  --attribute-names QueueArn --query 'Attributes.QueueArn' --output text)\n\n# Set DLQ on subscription\naws sns set-subscription-attributes \\\n  --subscription-arn arn:aws:sns:us-east-1:123456789012:my-topic:abc123 \\\n  --attribute-name RedrivePolicy \\\n  --attribute-value \"{\\\"deadLetterTargetArn\\\":\\\"${DLQ_ARN}\\\"}\"\n```\n\n## SMS Notifications\n\n### Send SMS\n\n```python\nimport boto3\n\nsns = boto3.client('sns')\n\n# Direct publish to phone number\nsns.publish(\n    PhoneNumber='+12025551234',\n    Message='Your verification code is 123456',\n    MessageAttributes={\n        'AWS.SNS.SMS.SMSType': {\n            'DataType': 'String',\n            'StringValue': 'Transactional'  # or 'Promotional'\n        },\n        'AWS.SNS.SMS.SenderID': {\n            'DataType': 'String',\n            'StringValue': 'MyApp'\n        }\n    }\n)\n```\n\n### SMS Preferences\n\n```bash\naws sns set-sms-attributes \\\n  --attributes '{\n    \"DefaultSMSType\": \"Transactional\",\n    \"DefaultSenderID\": \"MyApp\",\n    \"MonthlySpendLimit\": \"100\"\n  }'\n```\n\n### Check SMS Status\n\n```bash\n# Check spending\naws sns get-sms-attributes \\\n  --attributes MonthlySpendLimit\n```\n\n## Mobile Push Notifications\n\n### Create Platform Application\n\n```bash\n# For iOS (APNS)\naws sns create-platform-application \\\n  --name MyApp-iOS \\\n  --platform APNS \\\n  --attributes '{\n    \"PlatformCredential\": \"<private-key>\",\n    \"PlatformPrincipal\": \"<certificate>\"\n  }'\n\n# For Android (FCM)\naws sns create-platform-application \\\n  --name MyApp-Android \\\n  --platform GCM \\\n  --attributes '{\n    \"PlatformCredential\": \"<server-key>\"\n  }'\n```\n\n### Register Device Endpoint\n\n```python\nimport boto3\n\nsns = boto3.client('sns')\n\n# Register device\nresponse = sns.create_platform_endpoint(\n    PlatformApplicationArn='arn:aws:sns:us-east-1:123456789012:app/GCM/MyApp-Android',\n    Token='device-token-from-fcm'\n)\nendpoint_arn = response['EndpointArn']\n```\n\n### Send Push Notification\n\n```python\nimport boto3\nimport json\n\nsns = boto3.client('sns')\n\n# Direct to device\nsns.publish(\n    TargetArn=endpoint_arn,\n    Message=json.dumps({\n        'default': 'Default message',\n        'GCM': json.dumps({\n            'notification': {\n                'title': 'New Message',\n                'body': 'You have a new message'\n            },\n            'data': {\n                'message_id': '12345'\n            }\n        })\n    }),\n    MessageStructure='json'\n)\n```\n\n## Multi-Protocol Messages\n\n### Protocol-Specific Messages\n\n```python\nimport boto3\nimport json\n\nsns = boto3.client('sns')\n\nsns.publish(\n    TopicArn='arn:aws:sns:us-east-1:123456789012:my-topic',\n    Message=json.dumps({\n        'default': 'Default message for all protocols',\n        'email': 'Detailed email message with formatting',\n        'sms': 'Short SMS msg',\n        'lambda': json.dumps({'action': 'process', 'data': {...}}),\n        'sqs': json.dumps({'queue_message': {...}}),\n        'http': json.dumps({'webhook_payload': {...}})\n    }),\n    MessageStructure='json',\n    Subject='Email Subject Line'\n)\n```\n\n## Raw Message Delivery\n\n### Enable Raw Delivery for SQS\n\nBy default, SNS wraps messages. Raw delivery sends just the message body.\n\n```bash\naws sns set-subscription-attributes \\\n  --subscription-arn arn:aws:sns:us-east-1:123456789012:my-topic:abc123 \\\n  --attribute-name RawMessageDelivery \\\n  --attribute-value true\n```\n\n### Message Format Comparison\n\n**Without raw delivery (wrapped):**\n```json\n{\n  \"Type\": \"Notification\",\n  \"MessageId\": \"...\",\n  \"TopicArn\": \"arn:aws:sns:...\",\n  \"Subject\": \"...\",\n  \"Message\": \"{\\\"actual\\\":\\\"content\\\"}\",\n  \"Timestamp\": \"...\",\n  \"SignatureVersion\": \"1\",\n  \"Signature\": \"...\",\n  \"SigningCertURL\": \"...\",\n  \"UnsubscribeURL\": \"...\"\n}\n```\n\n**With raw delivery:**\n```json\n{\"actual\": \"content\"}\n```\n\n## FIFO Topics\n\n### Create FIFO Topic\n\n```bash\naws sns create-topic \\\n  --name orders.fifo \\\n  --attributes FifoTopic=true,ContentBasedDeduplication=true\n```\n\n### Subscribe FIFO Queue to FIFO Topic\n\n```bash\n# Create FIFO queue\naws sqs create-queue \\\n  --queue-name order-processing.fifo \\\n  --attributes FifoQueue=true\n\n# Subscribe\naws sns subscribe \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:orders.fifo \\\n  --protocol sqs \\\n  --notification-endpoint arn:aws:sqs:us-east-1:123456789012:order-processing.fifo\n```\n\n### Publish to FIFO Topic\n\n```python\nsns.publish(\n    TopicArn='arn:aws:sns:us-east-1:123456789012:orders.fifo',\n    Message=json.dumps({'order_id': '12345'}),\n    MessageGroupId='customer-abc',\n    MessageDeduplicationId='order-12345-v1'\n)\n```\n\n## Monitoring\n\n### CloudWatch Metrics\n\nKey metrics:\n- `NumberOfMessagesPublished`\n- `NumberOfNotificationsDelivered`\n- `NumberOfNotificationsFailed`\n- `PublishSize`\n\n### Enable Delivery Status Logging\n\n```bash\n# Create IAM role for logging\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name LambdaSuccessFeedbackRoleArn \\\n  --attribute-value arn:aws:iam::123456789012:role/sns-delivery-status-role\n\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name LambdaFailureFeedbackRoleArn \\\n  --attribute-value arn:aws:iam::123456789012:role/sns-delivery-status-role\n\n# Sample percentage (0-100)\naws sns set-topic-attributes \\\n  --topic-arn arn:aws:sns:us-east-1:123456789012:my-topic \\\n  --attribute-name LambdaSuccessFeedbackSampleRate \\\n  --attribute-value 100\n```\n\n### Alarm for Failed Deliveries\n\n```bash\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SNS-DeliveryFailures\" \\\n  --metric-name NumberOfNotificationsFailed \\\n  --namespace AWS/SNS \\\n  --dimensions Name=TopicName,Value=my-topic \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts-topic\n```\n",
        "skills/sqs/SKILL.md": "---\nname: sqs\ndescription: AWS SQS message queue service for decoupled architectures. Use when creating queues, configuring dead-letter queues, managing visibility timeouts, implementing FIFO ordering, or integrating with Lambda.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/\n---\n\n# AWS SQS\n\nAmazon Simple Queue Service (SQS) is a fully managed message queuing service for decoupling and scaling microservices, distributed systems, and serverless applications.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Queue Types\n\n| Type | Description | Use Case |\n|------|-------------|----------|\n| **Standard** | At-least-once, best-effort ordering | High throughput |\n| **FIFO** | Exactly-once, strict ordering | Order-sensitive processing |\n\n### Key Settings\n\n| Setting | Description | Default |\n|---------|-------------|---------|\n| **Visibility Timeout** | Time message is hidden after receive | 30 seconds |\n| **Message Retention** | How long messages are kept | 4 days (max 14) |\n| **Delay Seconds** | Delay before message is available | 0 |\n| **Max Message Size** | Maximum message size | 256 KB |\n\n### Dead-Letter Queue (DLQ)\n\nQueue for messages that failed processing after maxReceiveCount attempts.\n\n## Common Patterns\n\n### Create a Standard Queue\n\n**AWS CLI:**\n\n```bash\naws sqs create-queue \\\n  --queue-name my-queue \\\n  --attributes '{\n    \"VisibilityTimeout\": \"60\",\n    \"MessageRetentionPeriod\": \"604800\",\n    \"ReceiveMessageWaitTimeSeconds\": \"20\"\n  }'\n```\n\n**boto3:**\n\n```python\nimport boto3\n\nsqs = boto3.client('sqs')\n\nresponse = sqs.create_queue(\n    QueueName='my-queue',\n    Attributes={\n        'VisibilityTimeout': '60',\n        'MessageRetentionPeriod': '604800',\n        'ReceiveMessageWaitTimeSeconds': '20'  # Long polling\n    }\n)\nqueue_url = response['QueueUrl']\n```\n\n### Create FIFO Queue\n\n```bash\naws sqs create-queue \\\n  --queue-name my-queue.fifo \\\n  --attributes '{\n    \"FifoQueue\": \"true\",\n    \"ContentBasedDeduplication\": \"true\"\n  }'\n```\n\n### Configure Dead-Letter Queue\n\n```bash\n# Create DLQ\naws sqs create-queue --queue-name my-queue-dlq\n\n# Get DLQ ARN\nDLQ_ARN=$(aws sqs get-queue-attributes \\\n  --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/my-queue-dlq \\\n  --attribute-names QueueArn \\\n  --query 'Attributes.QueueArn' --output text)\n\n# Set redrive policy on main queue\naws sqs set-queue-attributes \\\n  --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/my-queue \\\n  --attributes \"{\n    \\\"RedrivePolicy\\\": \\\"{\\\\\\\"deadLetterTargetArn\\\\\\\":\\\\\\\"${DLQ_ARN}\\\\\\\",\\\\\\\"maxReceiveCount\\\\\\\":\\\\\\\"3\\\\\\\"}\\\"\n  }\"\n```\n\n### Send Messages\n\n```python\nimport boto3\nimport json\n\nsqs = boto3.client('sqs')\nqueue_url = 'https://sqs.us-east-1.amazonaws.com/123456789012/my-queue'\n\n# Send single message\nsqs.send_message(\n    QueueUrl=queue_url,\n    MessageBody=json.dumps({'order_id': '12345', 'action': 'process'}),\n    MessageAttributes={\n        'MessageType': {\n            'DataType': 'String',\n            'StringValue': 'Order'\n        }\n    }\n)\n\n# Send to FIFO queue\nsqs.send_message(\n    QueueUrl='https://sqs.us-east-1.amazonaws.com/123456789012/my-queue.fifo',\n    MessageBody=json.dumps({'order_id': '12345'}),\n    MessageGroupId='order-12345',\n    MessageDeduplicationId='unique-id-12345'\n)\n\n# Batch send (up to 10 messages)\nsqs.send_message_batch(\n    QueueUrl=queue_url,\n    Entries=[\n        {'Id': '1', 'MessageBody': json.dumps({'id': 1})},\n        {'Id': '2', 'MessageBody': json.dumps({'id': 2})},\n        {'Id': '3', 'MessageBody': json.dumps({'id': 3})}\n    ]\n)\n```\n\n### Receive and Process Messages\n\n```python\nimport boto3\nimport json\n\nsqs = boto3.client('sqs')\nqueue_url = 'https://sqs.us-east-1.amazonaws.com/123456789012/my-queue'\n\nwhile True:\n    # Long polling (wait up to 20 seconds)\n    response = sqs.receive_message(\n        QueueUrl=queue_url,\n        MaxNumberOfMessages=10,\n        WaitTimeSeconds=20,\n        MessageAttributeNames=['All'],\n        AttributeNames=['All']\n    )\n\n    messages = response.get('Messages', [])\n\n    for message in messages:\n        try:\n            body = json.loads(message['Body'])\n            print(f\"Processing: {body}\")\n\n            # Process message...\n\n            # Delete on success\n            sqs.delete_message(\n                QueueUrl=queue_url,\n                ReceiptHandle=message['ReceiptHandle']\n            )\n        except Exception as e:\n            print(f\"Error processing message: {e}\")\n            # Message will become visible again after visibility timeout\n```\n\n### Lambda Integration\n\n```bash\n# Create event source mapping\naws lambda create-event-source-mapping \\\n  --function-name my-function \\\n  --event-source-arn arn:aws:sqs:us-east-1:123456789012:my-queue \\\n  --batch-size 10 \\\n  --maximum-batching-window-in-seconds 5\n```\n\nLambda handler:\n\n```python\ndef handler(event, context):\n    for record in event['Records']:\n        body = json.loads(record['body'])\n        message_id = record['messageId']\n\n        try:\n            process_message(body)\n        except Exception as e:\n            # Raise to put message back in queue\n            raise\n\n    return {'batchItemFailures': []}\n```\n\n## CLI Reference\n\n### Queue Management\n\n| Command | Description |\n|---------|-------------|\n| `aws sqs create-queue` | Create queue |\n| `aws sqs delete-queue` | Delete queue |\n| `aws sqs list-queues` | List queues |\n| `aws sqs get-queue-url` | Get queue URL by name |\n| `aws sqs get-queue-attributes` | Get queue settings |\n| `aws sqs set-queue-attributes` | Update queue settings |\n\n### Messaging\n\n| Command | Description |\n|---------|-------------|\n| `aws sqs send-message` | Send single message |\n| `aws sqs send-message-batch` | Send up to 10 messages |\n| `aws sqs receive-message` | Receive messages |\n| `aws sqs delete-message` | Delete message |\n| `aws sqs delete-message-batch` | Delete up to 10 messages |\n| `aws sqs purge-queue` | Delete all messages |\n\n### Visibility\n\n| Command | Description |\n|---------|-------------|\n| `aws sqs change-message-visibility` | Change timeout |\n| `aws sqs change-message-visibility-batch` | Batch change |\n\n## Best Practices\n\n### Message Processing\n\n- **Use long polling** (WaitTimeSeconds=20) to reduce API calls\n- **Delete messages promptly** after successful processing\n- **Configure appropriate visibility timeout** (> processing time)\n- **Implement idempotent consumers** for at-least-once delivery\n\n### Dead-Letter Queues\n\n- **Always configure DLQ** for production queues\n- **Set appropriate maxReceiveCount** (usually 3-5)\n- **Monitor DLQ depth** with CloudWatch alarms\n- **Process DLQ messages** manually or with automation\n\n### FIFO Queues\n\n- **Use message group IDs** to partition ordering\n- **Enable content-based deduplication** or provide dedup IDs\n- **Throughput**: 300 msgs/sec without batching, 3000 with\n\n### Security\n\n- **Use queue policies** to control access\n- **Enable encryption** with SSE-SQS or SSE-KMS\n- **Use VPC endpoints** for private access\n\n## Troubleshooting\n\n### Messages Not Being Received\n\n**Causes:**\n- Short polling returning empty\n- All messages in flight (visibility timeout)\n- Messages delayed (DelaySeconds)\n\n**Debug:**\n\n```bash\n# Check queue attributes\naws sqs get-queue-attributes \\\n  --queue-url $QUEUE_URL \\\n  --attribute-names All\n\n# Check approximate message counts\naws sqs get-queue-attributes \\\n  --queue-url $QUEUE_URL \\\n  --attribute-names \\\n    ApproximateNumberOfMessages,\\\n    ApproximateNumberOfMessagesNotVisible,\\\n    ApproximateNumberOfMessagesDelayed\n```\n\n### Messages Going to DLQ\n\n**Causes:**\n- Processing errors\n- Visibility timeout too short\n- Consumer not deleting messages\n\n**Redrive from DLQ:**\n\n```bash\n# Enable redrive allow policy on source queue\naws sqs set-queue-attributes \\\n  --queue-url $MAIN_QUEUE_URL \\\n  --attributes '{\"RedriveAllowPolicy\": \"{\\\"redrivePermission\\\":\\\"allowAll\\\"}\"}'\n\n# Start redrive\naws sqs start-message-move-task \\\n  --source-arn arn:aws:sqs:us-east-1:123456789012:my-queue-dlq \\\n  --destination-arn arn:aws:sqs:us-east-1:123456789012:my-queue\n```\n\n### Duplicate Processing\n\n**Solutions:**\n- Use FIFO queues for exactly-once\n- Implement idempotency in consumer\n- Track processed message IDs in database\n\n### Lambda Not Processing\n\n```bash\n# Check event source mapping\naws lambda list-event-source-mappings \\\n  --function-name my-function\n\n# Check for errors\naws lambda get-event-source-mapping \\\n  --uuid <mapping-uuid>\n```\n\n## References\n\n- [SQS Developer Guide](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/)\n- [SQS API Reference](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/)\n- [SQS CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/sqs/)\n- [boto3 SQS](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs.html)\n",
        "skills/sqs/messaging-patterns.md": "# SQS Messaging Patterns\n\nAdvanced messaging patterns and configurations.\n\n## Queue Policies\n\n### Allow SNS to Send Messages\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"sns.amazonaws.com\"\n      },\n      \"Action\": \"sqs:SendMessage\",\n      \"Resource\": \"arn:aws:sqs:us-east-1:123456789012:my-queue\",\n      \"Condition\": {\n        \"ArnEquals\": {\n          \"aws:SourceArn\": \"arn:aws:sns:us-east-1:123456789012:my-topic\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Allow S3 to Send Messages\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"s3.amazonaws.com\"\n      },\n      \"Action\": \"sqs:SendMessage\",\n      \"Resource\": \"arn:aws:sqs:us-east-1:123456789012:my-queue\",\n      \"Condition\": {\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"arn:aws:s3:::my-bucket\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Cross-Account Access\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::111111111111:root\"\n      },\n      \"Action\": [\n        \"sqs:SendMessage\",\n        \"sqs:ReceiveMessage\",\n        \"sqs:DeleteMessage\"\n      ],\n      \"Resource\": \"arn:aws:sqs:us-east-1:123456789012:my-queue\"\n    }\n  ]\n}\n```\n\n## Encryption\n\n### Server-Side Encryption (SSE-SQS)\n\n```bash\naws sqs create-queue \\\n  --queue-name my-queue \\\n  --attributes '{\n    \"SqsManagedSseEnabled\": \"true\"\n  }'\n```\n\n### SSE with KMS\n\n```bash\naws sqs create-queue \\\n  --queue-name my-queue \\\n  --attributes '{\n    \"KmsMasterKeyId\": \"alias/my-key\",\n    \"KmsDataKeyReusePeriodSeconds\": \"300\"\n  }'\n```\n\n## FIFO Queue Patterns\n\n### Message Groups for Parallel Processing\n\n```python\nimport boto3\nimport json\n\nsqs = boto3.client('sqs')\nqueue_url = 'https://sqs.us-east-1.amazonaws.com/123456789012/orders.fifo'\n\n# Different customers can be processed in parallel\n# Same customer maintains order\norders = [\n    {'customer_id': 'A', 'order_id': '1'},\n    {'customer_id': 'B', 'order_id': '2'},\n    {'customer_id': 'A', 'order_id': '3'},  # After order 1\n]\n\nfor order in orders:\n    sqs.send_message(\n        QueueUrl=queue_url,\n        MessageBody=json.dumps(order),\n        MessageGroupId=order['customer_id'],  # Group by customer\n        MessageDeduplicationId=f\"{order['customer_id']}-{order['order_id']}\"\n    )\n```\n\n### High Throughput FIFO\n\n```bash\naws sqs create-queue \\\n  --queue-name my-queue.fifo \\\n  --attributes '{\n    \"FifoQueue\": \"true\",\n    \"ContentBasedDeduplication\": \"true\",\n    \"DeduplicationScope\": \"messageGroup\",\n    \"FifoThroughputLimit\": \"perMessageGroupId\"\n  }'\n```\n\n## Batch Processing with Lambda\n\n### Partial Batch Failure\n\n```python\ndef handler(event, context):\n    batch_item_failures = []\n\n    for record in event['Records']:\n        try:\n            body = json.loads(record['body'])\n            process_message(body)\n        except Exception as e:\n            # Report this specific message as failed\n            batch_item_failures.append({\n                'itemIdentifier': record['messageId']\n            })\n\n    return {'batchItemFailures': batch_item_failures}\n```\n\n### Configure Lambda for Partial Failures\n\n```bash\naws lambda update-event-source-mapping \\\n  --uuid <mapping-uuid> \\\n  --function-response-types ReportBatchItemFailures\n```\n\n## Visibility Timeout Management\n\n### Extend Visibility During Processing\n\n```python\nimport boto3\nimport time\nimport threading\n\nsqs = boto3.client('sqs')\n\ndef extend_visibility(queue_url, receipt_handle, stop_event):\n    \"\"\"Background thread to extend visibility.\"\"\"\n    while not stop_event.wait(timeout=30):\n        try:\n            sqs.change_message_visibility(\n                QueueUrl=queue_url,\n                ReceiptHandle=receipt_handle,\n                VisibilityTimeout=60\n            )\n        except Exception:\n            break\n\ndef process_long_running_message(queue_url, message):\n    stop_event = threading.Event()\n\n    # Start background visibility extender\n    extender = threading.Thread(\n        target=extend_visibility,\n        args=(queue_url, message['ReceiptHandle'], stop_event)\n    )\n    extender.start()\n\n    try:\n        # Long processing...\n        do_long_processing(message['Body'])\n\n        # Delete on success\n        sqs.delete_message(\n            QueueUrl=queue_url,\n            ReceiptHandle=message['ReceiptHandle']\n        )\n    finally:\n        stop_event.set()\n        extender.join()\n```\n\n## Message Delay Patterns\n\n### Per-Message Delay\n\n```python\n# Delay individual message up to 15 minutes\nsqs.send_message(\n    QueueUrl=queue_url,\n    MessageBody=json.dumps({'action': 'reminder'}),\n    DelaySeconds=900  # 15 minutes\n)\n```\n\n### Scheduled Processing\n\n```python\nimport time\n\ndef schedule_message(queue_url, body, execute_at):\n    \"\"\"Schedule message for future processing.\"\"\"\n    delay = int(execute_at - time.time())\n\n    if delay <= 0:\n        delay = 0\n    elif delay > 900:\n        # For delays > 15 min, use message attribute\n        # and filter on receive\n        sqs.send_message(\n            QueueUrl=queue_url,\n            MessageBody=json.dumps({\n                **body,\n                '_execute_at': execute_at\n            }),\n            DelaySeconds=900  # Maximum delay\n        )\n        return\n\n    sqs.send_message(\n        QueueUrl=queue_url,\n        MessageBody=json.dumps(body),\n        DelaySeconds=delay\n    )\n```\n\n## Monitoring\n\n### CloudWatch Alarms\n\n```bash\n# DLQ depth alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SQS-DLQ-NotEmpty\" \\\n  --metric-name ApproximateNumberOfMessagesVisible \\\n  --namespace AWS/SQS \\\n  --dimensions Name=QueueName,Value=my-queue-dlq \\\n  --statistic Sum \\\n  --period 60 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Queue backlog alarm\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SQS-Queue-Backlog\" \\\n  --metric-name ApproximateNumberOfMessagesVisible \\\n  --namespace AWS/SQS \\\n  --dimensions Name=QueueName,Value=my-queue \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 1000 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 3 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Age of oldest message\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"SQS-Old-Messages\" \\\n  --metric-name ApproximateAgeOfOldestMessage \\\n  --namespace AWS/SQS \\\n  --dimensions Name=QueueName,Value=my-queue \\\n  --statistic Maximum \\\n  --period 300 \\\n  --threshold 3600 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n```\n\n### Custom Metrics\n\n```python\nimport boto3\n\ncloudwatch = boto3.client('cloudwatch')\n\ndef publish_processing_metrics(queue_name, processing_time, success):\n    cloudwatch.put_metric_data(\n        Namespace='MyApp/SQS',\n        MetricData=[\n            {\n                'MetricName': 'ProcessingTime',\n                'Value': processing_time,\n                'Unit': 'Milliseconds',\n                'Dimensions': [\n                    {'Name': 'QueueName', 'Value': queue_name}\n                ]\n            },\n            {\n                'MetricName': 'ProcessingSuccess' if success else 'ProcessingFailure',\n                'Value': 1,\n                'Unit': 'Count',\n                'Dimensions': [\n                    {'Name': 'QueueName', 'Value': queue_name}\n                ]\n            }\n        ]\n    )\n```\n\n## Request-Response Pattern\n\n### Temporary Response Queue\n\n```python\nimport boto3\nimport json\nimport uuid\n\nsqs = boto3.client('sqs')\n\ndef send_request_with_response(request_queue_url, payload):\n    # Create temporary response queue\n    correlation_id = str(uuid.uuid4())\n    response_queue = sqs.create_queue(\n        QueueName=f'response-{correlation_id}',\n        Attributes={'MessageRetentionPeriod': '300'}\n    )\n    response_queue_url = response_queue['QueueUrl']\n\n    try:\n        # Send request with reply-to\n        sqs.send_message(\n            QueueUrl=request_queue_url,\n            MessageBody=json.dumps(payload),\n            MessageAttributes={\n                'ReplyTo': {\n                    'DataType': 'String',\n                    'StringValue': response_queue_url\n                },\n                'CorrelationId': {\n                    'DataType': 'String',\n                    'StringValue': correlation_id\n                }\n            }\n        )\n\n        # Wait for response\n        response = sqs.receive_message(\n            QueueUrl=response_queue_url,\n            WaitTimeSeconds=20,\n            MaxNumberOfMessages=1\n        )\n\n        if response.get('Messages'):\n            return json.loads(response['Messages'][0]['Body'])\n\n        return None\n    finally:\n        sqs.delete_queue(QueueUrl=response_queue_url)\n```\n\n## Large Message Pattern\n\n### Using S3 for Large Payloads\n\n```python\nimport boto3\nimport json\nimport uuid\n\ns3 = boto3.client('s3')\nsqs = boto3.client('sqs')\n\ndef send_large_message(queue_url, bucket, payload):\n    \"\"\"Send message > 256KB using S3.\"\"\"\n    payload_str = json.dumps(payload)\n\n    if len(payload_str) > 200000:  # Use S3 for large payloads\n        key = f'sqs-payloads/{uuid.uuid4()}.json'\n        s3.put_object(Bucket=bucket, Key=key, Body=payload_str)\n\n        sqs.send_message(\n            QueueUrl=queue_url,\n            MessageBody=json.dumps({\n                's3_bucket': bucket,\n                's3_key': key\n            }),\n            MessageAttributes={\n                'PayloadLocation': {\n                    'DataType': 'String',\n                    'StringValue': 's3'\n                }\n            }\n        )\n    else:\n        sqs.send_message(\n            QueueUrl=queue_url,\n            MessageBody=payload_str\n        )\n\ndef receive_large_message(queue_url, bucket):\n    \"\"\"Receive message, fetch from S3 if needed.\"\"\"\n    response = sqs.receive_message(\n        QueueUrl=queue_url,\n        MessageAttributeNames=['PayloadLocation'],\n        MaxNumberOfMessages=1\n    )\n\n    if not response.get('Messages'):\n        return None\n\n    message = response['Messages'][0]\n    attrs = message.get('MessageAttributes', {})\n\n    if attrs.get('PayloadLocation', {}).get('StringValue') == 's3':\n        pointer = json.loads(message['Body'])\n        response = s3.get_object(\n            Bucket=pointer['s3_bucket'],\n            Key=pointer['s3_key']\n        )\n        body = json.loads(response['Body'].read())\n\n        # Clean up S3 object\n        s3.delete_object(Bucket=pointer['s3_bucket'], Key=pointer['s3_key'])\n    else:\n        body = json.loads(message['Body'])\n\n    return body, message['ReceiptHandle']\n```\n",
        "skills/step-functions/SKILL.md": "---\nname: step-functions\ndescription: AWS Step Functions workflow orchestration with state machines. Use when designing workflows, implementing error handling, configuring parallel execution, integrating with AWS services, or debugging executions.\nlast_updated: \"2026-01-07\"\ndoc_source: https://docs.aws.amazon.com/step-functions/latest/dg/\n---\n\n# AWS Step Functions\n\nAWS Step Functions is a serverless orchestration service that lets you build and run workflows using state machines. Coordinate multiple AWS services into business-critical applications.\n\n## Table of Contents\n\n- [Core Concepts](#core-concepts)\n- [Common Patterns](#common-patterns)\n- [CLI Reference](#cli-reference)\n- [Best Practices](#best-practices)\n- [Troubleshooting](#troubleshooting)\n- [References](#references)\n\n## Core Concepts\n\n### Workflow Types\n\n| Type | Description | Pricing |\n|------|-------------|---------|\n| **Standard** | Long-running, durable, exactly-once | Per state transition |\n| **Express** | High-volume, short-duration | Per execution (time + memory) |\n\n### State Types\n\n| State | Description |\n|-------|-------------|\n| **Task** | Execute work (Lambda, API call) |\n| **Choice** | Conditional branching |\n| **Parallel** | Execute branches concurrently |\n| **Map** | Iterate over array |\n| **Wait** | Delay execution |\n| **Pass** | Pass input to output |\n| **Succeed** | End successfully |\n| **Fail** | End with failure |\n\n### Amazon States Language (ASL)\n\nJSON-based language for defining state machines.\n\n## Common Patterns\n\n### Simple Lambda Workflow\n\n```json\n{\n  \"Comment\": \"Process order workflow\",\n  \"StartAt\": \"ValidateOrder\",\n  \"States\": {\n    \"ValidateOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:us-east-1:123456789012:function:ValidateOrder\",\n      \"Next\": \"ProcessPayment\"\n    },\n    \"ProcessPayment\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessPayment\",\n      \"Next\": \"FulfillOrder\"\n    },\n    \"FulfillOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:us-east-1:123456789012:function:FulfillOrder\",\n      \"End\": true\n    }\n  }\n}\n```\n\n### Create State Machine\n\n**AWS CLI:**\n\n```bash\naws stepfunctions create-state-machine \\\n  --name OrderWorkflow \\\n  --definition file://workflow.json \\\n  --role-arn arn:aws:iam::123456789012:role/StepFunctionsRole \\\n  --type STANDARD\n```\n\n**boto3:**\n\n```python\nimport boto3\nimport json\n\nsfn = boto3.client('stepfunctions')\n\ndefinition = {\n    \"Comment\": \"Order workflow\",\n    \"StartAt\": \"ProcessOrder\",\n    \"States\": {\n        \"ProcessOrder\": {\n            \"Type\": \"Task\",\n            \"Resource\": \"arn:aws:lambda:...\",\n            \"End\": True\n        }\n    }\n}\n\nresponse = sfn.create_state_machine(\n    name='OrderWorkflow',\n    definition=json.dumps(definition),\n    roleArn='arn:aws:iam::123456789012:role/StepFunctionsRole',\n    type='STANDARD'\n)\n```\n\n### Start Execution\n\n```python\nimport boto3\nimport json\n\nsfn = boto3.client('stepfunctions')\n\nresponse = sfn.start_execution(\n    stateMachineArn='arn:aws:states:us-east-1:123456789012:stateMachine:OrderWorkflow',\n    name='order-12345',\n    input=json.dumps({\n        'order_id': '12345',\n        'customer_id': 'cust-789',\n        'items': [{'product_id': 'prod-1', 'quantity': 2}]\n    })\n)\n\nexecution_arn = response['executionArn']\n```\n\n### Choice State (Conditional Logic)\n\n```json\n{\n  \"StartAt\": \"CheckOrderValue\",\n  \"States\": {\n    \"CheckOrderValue\": {\n      \"Type\": \"Choice\",\n      \"Choices\": [\n        {\n          \"Variable\": \"$.total\",\n          \"NumericGreaterThan\": 1000,\n          \"Next\": \"HighValueOrder\"\n        },\n        {\n          \"Variable\": \"$.priority\",\n          \"StringEquals\": \"rush\",\n          \"Next\": \"RushOrder\"\n        }\n      ],\n      \"Default\": \"StandardOrder\"\n    },\n    \"HighValueOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ProcessHighValue\",\n      \"End\": true\n    },\n    \"RushOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ProcessRush\",\n      \"End\": true\n    },\n    \"StandardOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ProcessStandard\",\n      \"End\": true\n    }\n  }\n}\n```\n\n### Parallel Execution\n\n```json\n{\n  \"StartAt\": \"ProcessInParallel\",\n  \"States\": {\n    \"ProcessInParallel\": {\n      \"Type\": \"Parallel\",\n      \"Branches\": [\n        {\n          \"StartAt\": \"UpdateInventory\",\n          \"States\": {\n            \"UpdateInventory\": {\n              \"Type\": \"Task\",\n              \"Resource\": \"arn:aws:lambda:...:function:UpdateInventory\",\n              \"End\": true\n            }\n          }\n        },\n        {\n          \"StartAt\": \"SendNotification\",\n          \"States\": {\n            \"SendNotification\": {\n              \"Type\": \"Task\",\n              \"Resource\": \"arn:aws:lambda:...:function:SendNotification\",\n              \"End\": true\n            }\n          }\n        },\n        {\n          \"StartAt\": \"UpdateAnalytics\",\n          \"States\": {\n            \"UpdateAnalytics\": {\n              \"Type\": \"Task\",\n              \"Resource\": \"arn:aws:lambda:...:function:UpdateAnalytics\",\n              \"End\": true\n            }\n          }\n        }\n      ],\n      \"Next\": \"Complete\"\n    },\n    \"Complete\": {\n      \"Type\": \"Succeed\"\n    }\n  }\n}\n```\n\n### Map State (Iteration)\n\n```json\n{\n  \"StartAt\": \"ProcessItems\",\n  \"States\": {\n    \"ProcessItems\": {\n      \"Type\": \"Map\",\n      \"ItemsPath\": \"$.items\",\n      \"MaxConcurrency\": 10,\n      \"Iterator\": {\n        \"StartAt\": \"ProcessItem\",\n        \"States\": {\n          \"ProcessItem\": {\n            \"Type\": \"Task\",\n            \"Resource\": \"arn:aws:lambda:...:function:ProcessItem\",\n            \"End\": true\n          }\n        }\n      },\n      \"ResultPath\": \"$.processedItems\",\n      \"End\": true\n    }\n  }\n}\n```\n\n### Error Handling\n\n```json\n{\n  \"StartAt\": \"ProcessWithRetry\",\n  \"States\": {\n    \"ProcessWithRetry\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:Process\",\n      \"Retry\": [\n        {\n          \"ErrorEquals\": [\"Lambda.ServiceException\", \"Lambda.TooManyRequestsException\"],\n          \"IntervalSeconds\": 2,\n          \"MaxAttempts\": 6,\n          \"BackoffRate\": 2\n        },\n        {\n          \"ErrorEquals\": [\"States.Timeout\"],\n          \"IntervalSeconds\": 5,\n          \"MaxAttempts\": 3,\n          \"BackoffRate\": 1.5\n        }\n      ],\n      \"Catch\": [\n        {\n          \"ErrorEquals\": [\"CustomError\"],\n          \"ResultPath\": \"$.error\",\n          \"Next\": \"HandleCustomError\"\n        },\n        {\n          \"ErrorEquals\": [\"States.ALL\"],\n          \"ResultPath\": \"$.error\",\n          \"Next\": \"HandleAllErrors\"\n        }\n      ],\n      \"End\": true\n    },\n    \"HandleCustomError\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:HandleCustom\",\n      \"End\": true\n    },\n    \"HandleAllErrors\": {\n      \"Type\": \"Fail\",\n      \"Error\": \"ProcessingFailed\",\n      \"Cause\": \"An error occurred during processing\"\n    }\n  }\n}\n```\n\n## CLI Reference\n\n### State Machine Management\n\n| Command | Description |\n|---------|-------------|\n| `aws stepfunctions create-state-machine` | Create state machine |\n| `aws stepfunctions update-state-machine` | Update definition |\n| `aws stepfunctions delete-state-machine` | Delete state machine |\n| `aws stepfunctions list-state-machines` | List state machines |\n| `aws stepfunctions describe-state-machine` | Get details |\n\n### Executions\n\n| Command | Description |\n|---------|-------------|\n| `aws stepfunctions start-execution` | Start execution |\n| `aws stepfunctions stop-execution` | Stop execution |\n| `aws stepfunctions describe-execution` | Get execution details |\n| `aws stepfunctions list-executions` | List executions |\n| `aws stepfunctions get-execution-history` | Get execution history |\n\n## Best Practices\n\n### Design\n\n- **Keep states focused** â€” one purpose per state\n- **Use meaningful state names**\n- **Implement comprehensive error handling**\n- **Use Parallel for independent tasks**\n- **Use Map for batch processing**\n\n### Performance\n\n- **Use Express workflows** for high-volume, short tasks\n- **Set appropriate timeouts**\n- **Limit Map concurrency** to avoid throttling\n- **Use SDK integrations** when possible (avoid Lambda wrapper)\n\n### Reliability\n\n- **Retry transient errors**\n- **Catch and handle specific errors**\n- **Use idempotent operations**\n- **Enable X-Ray tracing**\n\n### Cost Optimization\n\n- **Use Express for short workflows** (< 5 minutes)\n- **Combine related operations** to reduce transitions\n- **Use Wait states** instead of Lambda delays\n\n## Troubleshooting\n\n### Execution Failed\n\n```bash\n# Get execution history\naws stepfunctions get-execution-history \\\n  --execution-arn arn:aws:states:us-east-1:123456789012:execution:MyWorkflow:exec-123 \\\n  --query 'events[?type==`TaskFailed` || type==`ExecutionFailed`]'\n```\n\n### Lambda Timeout\n\n**Causes:**\n- Lambda running too long\n- Task timeout too short\n\n**Fix:**\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:lambda:...\",\n  \"TimeoutSeconds\": 300,\n  \"HeartbeatSeconds\": 60\n}\n```\n\n### State Stuck\n\n**Check:**\n- Task state waiting for callback\n- Wait state not yet elapsed\n- Activity worker not responding\n\n### Invalid State Machine\n\n```bash\n# Validate definition\naws stepfunctions validate-state-machine-definition \\\n  --definition file://workflow.json\n```\n\n## References\n\n- [Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/)\n- [Step Functions API Reference](https://docs.aws.amazon.com/step-functions/latest/apireference/)\n- [Step Functions CLI Reference](https://docs.aws.amazon.com/cli/latest/reference/stepfunctions/)\n- [Amazon States Language](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html)\n",
        "skills/step-functions/workflow-patterns.md": "# Step Functions Workflow Patterns\n\nAdvanced workflow patterns and SDK integrations.\n\n## SDK Integrations\n\n### Lambda (Optimized)\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::lambda:invoke\",\n  \"Parameters\": {\n    \"FunctionName\": \"arn:aws:lambda:us-east-1:123456789012:function:MyFunction\",\n    \"Payload.$\": \"$\"\n  },\n  \"OutputPath\": \"$.Payload\",\n  \"End\": true\n}\n```\n\n### DynamoDB GetItem\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::dynamodb:getItem\",\n  \"Parameters\": {\n    \"TableName\": \"Orders\",\n    \"Key\": {\n      \"order_id\": {\"S.$\": \"$.order_id\"}\n    }\n  },\n  \"ResultPath\": \"$.order\",\n  \"Next\": \"ProcessOrder\"\n}\n```\n\n### DynamoDB PutItem\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::dynamodb:putItem\",\n  \"Parameters\": {\n    \"TableName\": \"Orders\",\n    \"Item\": {\n      \"order_id\": {\"S.$\": \"$.order_id\"},\n      \"status\": {\"S\": \"processed\"},\n      \"processed_at\": {\"S.$\": \"$$.State.EnteredTime\"}\n    }\n  },\n  \"End\": true\n}\n```\n\n### SQS SendMessage\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::sqs:sendMessage\",\n  \"Parameters\": {\n    \"QueueUrl\": \"https://sqs.us-east-1.amazonaws.com/123456789012/my-queue\",\n    \"MessageBody.$\": \"States.JsonToString($)\"\n  },\n  \"End\": true\n}\n```\n\n### SNS Publish\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::sns:publish\",\n  \"Parameters\": {\n    \"TopicArn\": \"arn:aws:sns:us-east-1:123456789012:my-topic\",\n    \"Message.$\": \"$.message\",\n    \"Subject\": \"Order Notification\"\n  },\n  \"End\": true\n}\n```\n\n### Step Functions (Nested)\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::states:startExecution.sync:2\",\n  \"Parameters\": {\n    \"StateMachineArn\": \"arn:aws:states:us-east-1:123456789012:stateMachine:ChildWorkflow\",\n    \"Input.$\": \"$\"\n  },\n  \"End\": true\n}\n```\n\n### ECS RunTask\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::ecs:runTask.sync\",\n  \"Parameters\": {\n    \"LaunchType\": \"FARGATE\",\n    \"Cluster\": \"arn:aws:ecs:us-east-1:123456789012:cluster/my-cluster\",\n    \"TaskDefinition\": \"my-task:1\",\n    \"NetworkConfiguration\": {\n      \"AwsvpcConfiguration\": {\n        \"Subnets\": [\"subnet-12345678\"],\n        \"SecurityGroups\": [\"sg-12345678\"],\n        \"AssignPublicIp\": \"ENABLED\"\n      }\n    },\n    \"Overrides\": {\n      \"ContainerOverrides\": [{\n        \"Name\": \"my-container\",\n        \"Environment\": [\n          {\"Name\": \"INPUT\", \"Value.$\": \"States.JsonToString($)\"}\n        ]\n      }]\n    }\n  },\n  \"End\": true\n}\n```\n\n### EventBridge PutEvents\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::events:putEvents\",\n  \"Parameters\": {\n    \"Entries\": [\n      {\n        \"Source\": \"my-app.orders\",\n        \"DetailType\": \"Order Completed\",\n        \"Detail.$\": \"States.JsonToString($)\",\n        \"EventBusName\": \"my-event-bus\"\n      }\n    ]\n  },\n  \"End\": true\n}\n```\n\n## Callback Pattern\n\n### Wait for External Process\n\n```json\n{\n  \"Type\": \"Task\",\n  \"Resource\": \"arn:aws:states:::sqs:sendMessage.waitForTaskToken\",\n  \"Parameters\": {\n    \"QueueUrl\": \"https://sqs.us-east-1.amazonaws.com/123456789012/approval-queue\",\n    \"MessageBody\": {\n      \"token.$\": \"$$.Task.Token\",\n      \"order_id.$\": \"$.order_id\",\n      \"action\": \"approve_order\"\n    }\n  },\n  \"TimeoutSeconds\": 86400,\n  \"Next\": \"ProcessApproval\"\n}\n```\n\n### Complete Callback (from external process)\n\n```python\nimport boto3\n\nsfn = boto3.client('stepfunctions')\n\n# On success\nsfn.send_task_success(\n    taskToken=task_token,\n    output='{\"approved\": true, \"approver\": \"user@example.com\"}'\n)\n\n# On failure\nsfn.send_task_failure(\n    taskToken=task_token,\n    error='RejectedError',\n    cause='Order rejected by approver'\n)\n\n# Heartbeat (for long-running tasks)\nsfn.send_task_heartbeat(taskToken=task_token)\n```\n\n## Distributed Map\n\n### Process Large Dataset\n\n```json\n{\n  \"Type\": \"Map\",\n  \"ItemProcessor\": {\n    \"ProcessorConfig\": {\n      \"Mode\": \"DISTRIBUTED\",\n      \"ExecutionType\": \"STANDARD\"\n    },\n    \"StartAt\": \"ProcessItem\",\n    \"States\": {\n      \"ProcessItem\": {\n        \"Type\": \"Task\",\n        \"Resource\": \"arn:aws:lambda:...:function:ProcessItem\",\n        \"End\": true\n      }\n    }\n  },\n  \"ItemReader\": {\n    \"Resource\": \"arn:aws:states:::s3:getObject\",\n    \"ReaderConfig\": {\n      \"InputType\": \"JSON\"\n    },\n    \"Parameters\": {\n      \"Bucket\": \"my-bucket\",\n      \"Key\": \"input/data.json\"\n    }\n  },\n  \"ResultWriter\": {\n    \"Resource\": \"arn:aws:states:::s3:putObject\",\n    \"Parameters\": {\n      \"Bucket\": \"my-bucket\",\n      \"Prefix\": \"output\"\n    }\n  },\n  \"MaxConcurrency\": 1000,\n  \"End\": true\n}\n```\n\n## Intrinsic Functions\n\n### String Operations\n\n```json\n{\n  \"Type\": \"Pass\",\n  \"Parameters\": {\n    \"concatenated.$\": \"States.Format('Order {} for customer {}', $.order_id, $.customer_id)\",\n    \"split.$\": \"States.StringSplit($.tags, ',')\",\n    \"uuid.$\": \"States.UUID()\"\n  }\n}\n```\n\n### Array Operations\n\n```json\n{\n  \"Type\": \"Pass\",\n  \"Parameters\": {\n    \"arrayLength.$\": \"States.ArrayLength($.items)\",\n    \"firstItem.$\": \"States.ArrayGetItem($.items, 0)\",\n    \"range.$\": \"States.ArrayRange(1, 10, 2)\",\n    \"partition.$\": \"States.ArrayPartition($.items, 10)\",\n    \"unique.$\": \"States.ArrayUnique($.items)\"\n  }\n}\n```\n\n### JSON Operations\n\n```json\n{\n  \"Type\": \"Pass\",\n  \"Parameters\": {\n    \"stringified.$\": \"States.JsonToString($.data)\",\n    \"parsed.$\": \"States.StringToJson($.jsonString)\",\n    \"merged.$\": \"States.JsonMerge($.base, $.override, false)\"\n  }\n}\n```\n\n### Math Operations\n\n```json\n{\n  \"Type\": \"Pass\",\n  \"Parameters\": {\n    \"sum.$\": \"States.MathAdd($.a, $.b)\",\n    \"random.$\": \"States.MathRandom(1, 100)\"\n  }\n}\n```\n\n## Common Patterns\n\n### Saga Pattern (Compensation)\n\n```json\n{\n  \"StartAt\": \"ReserveInventory\",\n  \"States\": {\n    \"ReserveInventory\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ReserveInventory\",\n      \"Catch\": [{\n        \"ErrorEquals\": [\"States.ALL\"],\n        \"Next\": \"FailOrder\"\n      }],\n      \"Next\": \"ProcessPayment\"\n    },\n    \"ProcessPayment\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ProcessPayment\",\n      \"Catch\": [{\n        \"ErrorEquals\": [\"States.ALL\"],\n        \"ResultPath\": \"$.error\",\n        \"Next\": \"ReleaseInventory\"\n      }],\n      \"Next\": \"ShipOrder\"\n    },\n    \"ShipOrder\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ShipOrder\",\n      \"Catch\": [{\n        \"ErrorEquals\": [\"States.ALL\"],\n        \"ResultPath\": \"$.error\",\n        \"Next\": \"RefundPayment\"\n      }],\n      \"End\": true\n    },\n    \"ReleaseInventory\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:ReleaseInventory\",\n      \"Next\": \"FailOrder\"\n    },\n    \"RefundPayment\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:RefundPayment\",\n      \"Next\": \"ReleaseInventory\"\n    },\n    \"FailOrder\": {\n      \"Type\": \"Fail\",\n      \"Error\": \"OrderFailed\",\n      \"Cause\": \"Order processing failed\"\n    }\n  }\n}\n```\n\n### Human Approval\n\n```json\n{\n  \"StartAt\": \"SubmitRequest\",\n  \"States\": {\n    \"SubmitRequest\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::lambda:invoke\",\n      \"Parameters\": {\n        \"FunctionName\": \"CreateApprovalRequest\",\n        \"Payload.$\": \"$\"\n      },\n      \"Next\": \"WaitForApproval\"\n    },\n    \"WaitForApproval\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::lambda:invoke.waitForTaskToken\",\n      \"Parameters\": {\n        \"FunctionName\": \"SendApprovalEmail\",\n        \"Payload\": {\n          \"token.$\": \"$$.Task.Token\",\n          \"request.$\": \"$\"\n        }\n      },\n      \"TimeoutSeconds\": 604800,\n      \"Catch\": [{\n        \"ErrorEquals\": [\"States.Timeout\"],\n        \"Next\": \"RequestExpired\"\n      }],\n      \"Next\": \"CheckApproval\"\n    },\n    \"CheckApproval\": {\n      \"Type\": \"Choice\",\n      \"Choices\": [{\n        \"Variable\": \"$.approved\",\n        \"BooleanEquals\": true,\n        \"Next\": \"ProcessApproved\"\n      }],\n      \"Default\": \"ProcessRejected\"\n    },\n    \"ProcessApproved\": {\n      \"Type\": \"Succeed\"\n    },\n    \"ProcessRejected\": {\n      \"Type\": \"Fail\",\n      \"Error\": \"Rejected\"\n    },\n    \"RequestExpired\": {\n      \"Type\": \"Fail\",\n      \"Error\": \"Expired\"\n    }\n  }\n}\n```\n\n### Polling Pattern\n\n```json\n{\n  \"StartAt\": \"SubmitJob\",\n  \"States\": {\n    \"SubmitJob\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:SubmitJob\",\n      \"Next\": \"Wait\"\n    },\n    \"Wait\": {\n      \"Type\": \"Wait\",\n      \"Seconds\": 30,\n      \"Next\": \"CheckStatus\"\n    },\n    \"CheckStatus\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:CheckJobStatus\",\n      \"Next\": \"IsComplete\"\n    },\n    \"IsComplete\": {\n      \"Type\": \"Choice\",\n      \"Choices\": [{\n        \"Variable\": \"$.status\",\n        \"StringEquals\": \"COMPLETED\",\n        \"Next\": \"GetResults\"\n      }, {\n        \"Variable\": \"$.status\",\n        \"StringEquals\": \"FAILED\",\n        \"Next\": \"JobFailed\"\n      }],\n      \"Default\": \"Wait\"\n    },\n    \"GetResults\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:...:function:GetResults\",\n      \"End\": true\n    },\n    \"JobFailed\": {\n      \"Type\": \"Fail\"\n    }\n  }\n}\n```\n"
      },
      "plugins": [
        {
          "name": "aws-agent-skills",
          "description": "Collection of AWS engineering skills for IAM, Lambda, DynamoDB, S3, and 14 other core AWS services",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/iam",
            "./skills/lambda",
            "./skills/dynamodb",
            "./skills/s3",
            "./skills/api-gateway",
            "./skills/ec2",
            "./skills/ecs",
            "./skills/eks",
            "./skills/cloudformation",
            "./skills/cloudwatch",
            "./skills/rds",
            "./skills/sqs",
            "./skills/sns",
            "./skills/cognito",
            "./skills/step-functions",
            "./skills/secrets-manager",
            "./skills/eventbridge",
            "./skills/bedrock"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add itsmostafa/aws-agent-skills",
            "/plugin install aws-agent-skills@aws-agent-skills"
          ]
        }
      ]
    }
  ]
}