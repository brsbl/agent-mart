{
  "author": {
    "id": "julep-ai",
    "display_name": "julep-ai",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/112750682?v=4",
    "url": "https://github.com/julep-ai",
    "bio": "A new DSL and server for AI agents and multi-step tasks",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 8,
      "total_skills": 3,
      "total_stars": 3,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "Vibesafe",
      "version": null,
      "description": "Vibesafe plugin repository",
      "owner_info": {
        "name": "Julep AI",
        "email": "developers@julep.ai"
      },
      "keywords": [],
      "repo_full_name": "julep-ai/vibesafe",
      "repo_url": "https://github.com/julep-ai/vibesafe",
      "repo_description": "Vibe safely",
      "homepage": null,
      "signals": {
        "stars": 3,
        "forks": 0,
        "pushed_at": "2025-11-24T00:01:48Z",
        "created_at": "2025-10-30T00:25:34Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/commands/get-mode.md",
          "type": "blob",
          "size": 476
        },
        {
          "path": ".claude-plugin/commands/init.md",
          "type": "blob",
          "size": 1157
        },
        {
          "path": ".claude-plugin/commands/set-mode.md",
          "type": "blob",
          "size": 521
        },
        {
          "path": ".claude-plugin/commands/vibe.md",
          "type": "blob",
          "size": 611
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 277
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 646
        },
        {
          "path": ".claude-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/skills/vibesafe",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/skills/vibesafe/SKILL.md",
          "type": "blob",
          "size": 1423
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/SKILL.md",
          "type": "blob",
          "size": 7199
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/examples/complete-plugins.md",
          "type": "blob",
          "size": 19376
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/guides",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/guides/best-practices.md",
          "type": "blob",
          "size": 13217
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/guides/development-workflow.md",
          "type": "blob",
          "size": 12631
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/guides/publishing.md",
          "type": "blob",
          "size": 10917
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/agent-skills.md",
          "type": "blob",
          "size": 15178
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/hooks.md",
          "type": "blob",
          "size": 12660
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/mcp-servers.md",
          "type": "blob",
          "size": 16213
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/plugin-manifest.md",
          "type": "blob",
          "size": 10452
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/plugin-structure.md",
          "type": "blob",
          "size": 8739
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/reference/slash-commands.md",
          "type": "blob",
          "size": 11320
        },
        {
          "path": ".claude/skills/claude-code-plugin-dev/troubleshooting.md",
          "type": "blob",
          "size": 12673
        },
        {
          "path": ".claude/skills/documentation-2025.md",
          "type": "blob",
          "size": 50226
        },
        {
          "path": ".claude/skills/hackernews-writing.md",
          "type": "blob",
          "size": 40957
        },
        {
          "path": ".claude/skills/uv.md",
          "type": "blob",
          "size": 6608
        },
        {
          "path": ".claude/skills/vibesafe.md",
          "type": "blob",
          "size": 35331
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 33059
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/get-mode.md",
          "type": "blob",
          "size": 404
        },
        {
          "path": "commands/init.md",
          "type": "blob",
          "size": 513
        },
        {
          "path": "commands/set-mode.md",
          "type": "blob",
          "size": 454
        },
        {
          "path": "commands/vibe.md",
          "type": "blob",
          "size": 583
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 697
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vibesafe",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vibesafe/SKILL.md",
          "type": "blob",
          "size": 1418
        }
      ],
      "files": {
        ".claude-plugin/commands/get-mode.md": "---\nname: get-mode\ndescription: \"Show the current VIBESAFE_ENV (mode) visible to this session.\"\narguments: []\n---\n\nReport the Vibesafe mode for this session and the persisted mode file.\n\nSteps:\n1) `echo \"VIBESAFE_ENV=${VIBESAFE_ENV:-<unset>}\"`  \n2) `if [ -f .vibesafe/mode ]; then echo \".vibesafe/mode=$(cat .vibesafe/mode)\"; else echo \".vibesafe/mode=<missing>\"; fi`  \n3) Note that precedence is env > .vibesafe/mode > vibesafe.toml default.\n\nExample:\n- `/vibesafe:get-mode`\n",
        ".claude-plugin/commands/init.md": "---\nname: init\ndescription: \"Initialize the Vibesafe plugin session: report mode, list commands, and verify MCP connectivity.\"\narguments: []\n---\n\nRun a quick readiness check:\n- Show current mode (`VIBESAFE_ENV` or config default)\n- List available Vibesafe commands\n- Confirm MCP server connectivity\n- Ensure vibesafe.toml exists with minimal defaults\n\nExample:\n- `/vibesafe:init`\n\nSteps:\n1) `echo \"VIBESAFE_ENV=${VIBESAFE_ENV:-<unset>}\"`  \n2) `if [ -f .vibesafe/mode ]; then echo \".vibesafe/mode=$(cat .vibesafe/mode)\"; else echo \".vibesafe/mode=<missing>\"; fi`\n3) `if [ ! -f vibesafe.toml ]; then cat > vibesafe.toml <<'EOF'\\n[project]\\npython = \">=3.12\"\\nenv = \"dev\"\\n\\n[provider.default]\\nkind = \"openai-compatible\"\\nmodel = \"gpt-5-mini\"\\nseed = 42\\nbase_url = \"https://api.openai.com/v1\"\\napi_key_env = \"OPENAI_API_KEY\"\\n\\n[paths]\\ncheckpoints = \".vibesafe/checkpoints\"\\ncache = \".vibesafe/cache\"\\nindex = \".vibesafe/index.toml\"\\n\\n[sandbox]\\nenabled = false\\ntimeout = 10\\nmemory_mb = 256\\nEOF\\nfi`  \n4) `vibesafe status || true`  # harmless status check  \n5) `echo \"Commands: scan, compile, test, save, diff, status, mcp, set-mode, get-mode, init\"`  \n",
        ".claude-plugin/commands/set-mode.md": "---\nname: set-mode\ndescription: \"Set VIBESAFE_ENV for subsequent Vibesafe commands (dev|prod).\"\narguments:\n  - name: env\n    description: \"Mode to set (dev or prod)\"\n    required: true\n---\n\nSet the Vibesafe mode persistently for this repo and session.\n\nSteps (run in order):\n1) `export VIBESAFE_ENV=\"{{ env }}\"`  \n2) `mkdir -p .vibesafe && printf \"%s\" \"{{ env }}\" > .vibesafe/mode`  \n3) `echo \"VIBESAFE_ENV=$VIBESAFE_ENV (persisted to .vibesafe/mode)\"`  \n\nExamples:\n- `/vibesafe:set-mode dev`\n- `/vibesafe:set-mode prod`\n",
        ".claude-plugin/commands/vibe.md": "---\nname: vibe\ndescription: \"Run vibesafe CLI commands through the MCP server. Usage: /vibe <subcommand> [args] where subcommand ∈ {scan, compile, test, save, diff, status, mcp, init}.\"\narguments:\n  - name: subcommand\n    description: \"vibesafe subcommand to execute (scan | compile | test | save | diff | status | mcp | init)\"\n    required: true\n---\n\nRun Vibesafe toolchain actions via MCP.\n\nExamples:\n- `/vibe scan`\n- `/vibe compile --target app.math.ops/fibonacci`\n- `/vibe test --target app.math.ops/fibonacci`\n- `/vibe status`\n- `/vibe diff`\n- `/vibe save --target app.math.ops/fibonacci`\n- `/vibe init`\n",
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"Vibesafe\",\n  \"owner\": {\n    \"name\": \"Julep AI\",\n    \"email\": \"developers@julep.ai\"\n  },\n  \"description\": \"Vibesafe plugin repository\",\n  \"plugins\": [\n    {\n      \"name\": \"vibesafe\",\n      \"description\": \"Vibesafe developer tools\",\n      \"source\": \"./\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"vibesafe\",\n  \"version\": \"0.2.0-pre1\",\n  \"description\": \"Vibesafe developer tools: scan, compile, test, save, diff, status, mcp; includes mode toggle.\",\n  \"mcpServers\": {\n    \"vibesafe\": {\n      \"type\": \"stdio\",\n      \"command\": \"bash\",\n      \"args\": [\n        \"-lc\",\n        \"if command -v vibesafe >/dev/null 2>&1; then vibesafe mcp; elif command -v uvx >/dev/null 2>&1; then uvx vibesafe mcp; else python -m vibesafe.mcp; fi\"\n      ]\n    }\n  },\n  \"commands\": [\n    \"./commands/vibe.md\",\n    \"./commands/set-mode.md\",\n    \"./commands/get-mode.md\",\n    \"./commands/init.md\"\n  ],\n  \"skills\": [\n    \"./skills/vibesafe/SKILL.md\"\n  ]\n\n}\n",
        ".claude-plugin/skills/vibesafe/SKILL.md": "---\nname: vibesafe\ndescription: \"Uses the Vibesafe MCP server to scan, compile, test, save, diff, and report status for Vibesafe units. Activate when the user asks to run vibesafe CLI commands (scan/compile/test/save/diff/status), regenerate code from specs, or inspect drift/checkpoints.\"\nversion: \"0.2.0-pre1\"\ntags: [\"vibesafe\", \"codegen\", \"mcp\", \"cli\"]\nallowed-tools: \"MCP(vibesafe:*)\"\n---\n\n# Vibesafe MCP Skill\n\nProvides full control of the Vibesafe toolchain through the MCP server exposed by this plugin.\n\n## When to Use\n- User asks to run `vibesafe scan`, `compile`, `test`, `save`, `diff`, or `status`.\n- Need to regenerate implementations from specs or check drift against checkpoints.\n- Want to query registry contents, provider config, or checkpoints via the MCP tools.\n\n## Available Tools\n- `scan` — list all registered Vibesafe units with metadata.\n- `compile` — generate implementations for a unit (supports `target`, `force`).\n- `test` — run doctests/quality gates (optional `target`).\n- `save` — activate checkpoints (optional `target`).\n- `status` — report version, unit counts, environment.\n\n## Examples\n- “List all vibesafe units” → use `scan`.\n- “Recompile app.math.ops/fibonacci” → call `compile` with `target`.\n- “Run vibesafe tests” → call `test`.\n- “Save checkpoints for all units” → call `save`.\n- “Check drift” → call `diff` (via status+diff as available).\n",
        ".claude/skills/claude-code-plugin-dev/SKILL.md": "---\nname: claude-code-plugin-dev\ndescription: \"Comprehensive guide for building, testing, and distributing Claude Code plugins including slash commands, Agent Skills, subagents, MCP servers, and hooks. Use this when the user asks about creating plugins, writing slash commands, implementing skills, building MCP tools, configuring hooks, plugin architecture, marketplace distribution, or debugging plugin components. Covers 2025 schema with tool permissions, version tracking, and activation triggers.\"\nversion: \"1.0.0\"\ntags: [\"plugin\", \"development\", \"skills\", \"commands\", \"mcp\", \"hooks\", \"agents\", \"marketplace\", \"tools\", \"claude-code\", \"sdk\"]\nallowed-tools: \"Read(*), Write(*), Edit(*), Bash(mkdir:*, git:*, npm:*, node:*, python:*, jq:*), Glob(**/*.md, **/*.json, **/*.ts, **/*.py)\"\n---\n\n# Claude Code Plugin Development Skill\n\nExpert knowledge for building Claude Code plugins with up-to-date 2025 standards.\n\n## When Claude Should Use This Skill\n\nActivate this skill automatically when the user:\n- Asks to create/build a Claude Code plugin\n- Wants to write slash commands or Agent Skills\n- Needs to implement MCP servers or custom tools\n- Wants to configure hooks or event handlers\n- Asks about plugin architecture or structure\n- Needs help with plugin.json manifest\n- Wants to publish to a marketplace\n- Asks about debugging plugin components\n- Mentions keywords: plugin, skill, command, MCP, hook, marketplace, subagent\n\n## Quick Overview\n\nClaude Code plugins consist of **five component types** that extend functionality:\n\n1. **Slash Commands** - User-triggered shortcuts (`/command`)\n2. **Agent Skills** - Model-invoked capabilities (auto-activated)\n3. **Subagents** - Specialized task handlers\n4. **MCP Servers** - External tool/data integrations\n5. **Hooks** - Event-driven automations\n\n## Documentation Structure\n\nThis skill is organized into focused modules for easy reference:\n\n### Core References\n\n- **[Plugin Structure](reference/plugin-structure.md)** - Architecture, file organization, component types, scope hierarchy\n- **[Plugin Manifest](reference/plugin-manifest.md)** - plugin.json schema, validation, configuration\n- **[Slash Commands](reference/slash-commands.md)** - Command creation, arguments, tool permissions, namespacing\n- **[Agent Skills](reference/agent-skills.md)** - 2025 schema, activation patterns, descriptions that work\n- **[MCP Servers](reference/mcp-servers.md)** - Custom tools, TypeScript/Python implementations, tool naming\n- **[Hooks](reference/hooks.md)** - Event handlers, available events, matchers, environment variables\n\n### Practical Guides\n\n- **[Development Workflow](guides/development-workflow.md)** - Local testing, debugging, validation checklist\n- **[Publishing & Distribution](guides/publishing.md)** - GitHub setup, versioning, marketplace creation\n- **[Best Practices](guides/best-practices.md)** - Security, performance, maintainability, design principles\n\n### Examples & Troubleshooting\n\n- **[Complete Plugin Examples](examples/complete-plugins.md)** - Full working examples for common use cases\n- **[Troubleshooting Guide](troubleshooting.md)** - Common issues and solutions\n\n## Getting Started\n\n### For First-Time Plugin Creators\n\n1. Read **[Plugin Structure](reference/plugin-structure.md)** to understand architecture\n2. Create **[Plugin Manifest](reference/plugin-manifest.md)** (required `.claude-plugin/plugin.json`)\n3. Choose component type(s) to implement:\n   - Commands? → See **[Slash Commands](reference/slash-commands.md)**\n   - Skills? → See **[Agent Skills](reference/agent-skills.md)**\n   - Tools? → See **[MCP Servers](reference/mcp-servers.md)**\n   - Automation? → See **[Hooks](reference/hooks.md)**\n4. Follow **[Development Workflow](guides/development-workflow.md)** for local testing\n5. Use **[Publishing Guide](guides/publishing.md)** to distribute\n\n### For Specific Tasks\n\n**\"I want to create a slash command\"**\n→ See [Slash Commands](reference/slash-commands.md)\n\n**\"How do I make a skill that auto-activates?\"**\n→ See [Agent Skills](reference/agent-skills.md) - especially the \"Activation Patterns\" section\n\n**\"I need to build custom tools/MCP server\"**\n→ See [MCP Servers](reference/mcp-servers.md)\n\n**\"How do I auto-format code after edits?\"**\n→ See [Hooks](reference/hooks.md) - PostToolUse event\n\n**\"My skill isn't activating\"**\n→ See [Troubleshooting Guide](troubleshooting.md) - \"Skills Not Activating\" section\n\n**\"What are the best practices?\"**\n→ See [Best Practices](guides/best-practices.md)\n\n## Quick Reference\n\n### Minimal Plugin Structure\n\n```\nmy-plugin/\n├── .claude-plugin/\n│   └── plugin.json              # REQUIRED\n├── commands/                    # Optional\n│   └── my-command.md\n├── skills/                      # Optional\n│   └── my-skill/\n│       └── SKILL.md\n├── mcp/                         # Optional\n│   └── server.ts\n└── README.md\n```\n\n### Essential Commands\n\n```bash\n# Local testing\n/plugin marketplace add ~/.claude/marketplaces/local\n/plugin install my-plugin\n\n# Management\n/plugin list\n/plugin update my-plugin\n/help | grep my-command\n\n# Validation\njq . .claude-plugin/plugin.json\n```\n\n### Key 2025 Updates\n\n- ✅ `allowed-tools` field for tool permissions in skills\n- ✅ Version tracking required\n- ✅ Enhanced activation triggers with specific keywords\n- ✅ 240+ community plugins available\n\n## When to Reference Each Module\n\n| User Question | Read This |\n|--------------|-----------|\n| \"How do I structure a plugin?\" | [Plugin Structure](reference/plugin-structure.md) |\n| \"What goes in plugin.json?\" | [Plugin Manifest](reference/plugin-manifest.md) |\n| \"Create a command that...\" | [Slash Commands](reference/slash-commands.md) |\n| \"Build a skill that activates when...\" | [Agent Skills](reference/agent-skills.md) |\n| \"Implement custom tools/API integration\" | [MCP Servers](reference/mcp-servers.md) |\n| \"Auto-run something after tool use\" | [Hooks](reference/hooks.md) |\n| \"How do I test locally?\" | [Development Workflow](guides/development-workflow.md) |\n| \"How do I publish my plugin?\" | [Publishing](guides/publishing.md) |\n| \"My plugin component isn't working\" | [Troubleshooting](troubleshooting.md) |\n| \"Show me a complete example\" | [Examples](examples/complete-plugins.md) |\n\n## Important Notes\n\n- **2025 Schema**: All documentation follows the latest 2025 plugin schema\n- **Activation Keywords**: Skill descriptions must be specific with file types, actions, and tools\n- **Tool Permissions**: Use `allowed-tools` to restrict access appropriately\n- **Testing First**: Always test locally before publishing\n- **No Secrets**: Never commit API keys or credentials\n\n## Additional Resources\n\n- Official docs: https://code.claude.com/docs/en/plugins\n- Community marketplace: https://claudecodemarketplace.com\n- 240+ plugins: https://github.com/jeremylongshore/claude-code-plugins-plus\n\n---\n\n**Next Steps**: Based on what the user is trying to build, direct them to the appropriate reference guide above. For comprehensive understanding, recommend reading in this order: Plugin Structure → Plugin Manifest → specific component type → Development Workflow → Publishing.\n",
        ".claude/skills/claude-code-plugin-dev/examples/complete-plugins.md": "# Complete Plugin Examples\n\nFull working examples of Claude Code plugins for common use cases.\n\n## Example 1: Git Workflow Plugin\n\nSimple plugin with commands and hooks for Git operations.\n\n### Structure\n\n```\ngit-workflow-plugin/\n├── .claude-plugin/\n│   └── plugin.json\n├── commands/\n│   ├── commit-flow.md\n│   └── pr-create.md\n├── hooks/\n│   └── pre-commit.json\n└── README.md\n```\n\n### plugin.json\n\n```json\n{\n  \"name\": \"git-workflow\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Dev Team\",\n  \"description\": \"Git workflow automation with commit helpers and PR creation. Includes pre-commit formatting and linting hooks.\",\n  \"repository\": \"https://github.com/yourorg/git-workflow\",\n  \"license\": \"MIT\",\n\n  \"commands\": {\n    \"path\": \"commands\"\n  },\n\n  \"hooks\": {\n    \"path\": \"hooks\"\n  }\n}\n```\n\n### commands/commit-flow.md\n\n```markdown\n---\ndescription: \"Automated commit workflow: stage, test, format, commit\"\nallowed-tools: Bash(git:*, npm:test, prettier:*)\nargument-hint: \"commit message\"\n---\n\n# Automated Commit Workflow\n\nRunning pre-commit workflow for: \"$1\"\n\n## 1. Stage All Changes\n\n!git add -A\n\n## 2. Run Tests\n\n!npm test || (echo \"❌ Tests failed! Please fix before committing.\" && exit 1)\n\n## 3. Format Code\n\n!prettier --write .\n!git add -A\n\n## 4. Create Commit\n\n!git commit -m \"$1\"\n\n✅ Successfully committed with message: \"$1\"\n```\n\n### commands/pr-create.md\n\n```markdown\n---\ndescription: \"Create pull request with automated title and description\"\nallowed-tools: Bash(git:*, gh:*)\nargument-hint: \"target branch (default: main)\"\n---\n\n# Create Pull Request\n\nTarget branch: ${1:-main}\n\n## 1. Get Current Branch\n\n!CURRENT_BRANCH=$(git branch --show-current)\n\n## 2. Push Current Branch\n\n!git push -u origin $CURRENT_BRANCH\n\n## 3. Generate PR Description\n\nBased on recent commits:\n\n!git log origin/${1:-main}..HEAD --pretty=format:\"- %s\"\n\n## 4. Create PR\n\n!gh pr create --base ${1:-main} --head $CURRENT_BRANCH --fill\n\n✅ Pull request created!\n```\n\n### hooks/pre-commit.json\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"if [[ $FILE_PATH == *.js || $FILE_PATH == *.ts ]]; then prettier --write \\\"$FILE_PATH\\\" 2>/dev/null && eslint --fix \\\"$FILE_PATH\\\" 2>/dev/null; fi\"\n      },\n      \"timeout\": 10,\n      \"enabled\": true\n    },\n    {\n      \"event\": \"PreToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Bash:git:commit\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"npm test --silent || (echo '❌ Tests must pass before committing' && exit 2)\"\n      },\n      \"timeout\": 60,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n---\n\n## Example 2: PDF Processing Plugin\n\nPlugin with skills and MCP server for PDF processing.\n\n### Structure\n\n```\npdf-tools-plugin/\n├── .claude-plugin/\n│   └── plugin.json\n├── skills/\n│   └── pdf-extraction/\n│       └── SKILL.md\n├── mcp/\n│   └── pdf-server.ts\n└── README.md\n```\n\n### plugin.json\n\n```json\n{\n  \"name\": \"pdf-tools\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Document Team\",\n  \"description\": \"PDF text extraction and processing tools with OCR support\",\n  \"repository\": \"https://github.com/yourorg/pdf-tools\",\n  \"license\": \"MIT\",\n\n  \"skills\": {\n    \"path\": \"skills\"\n  },\n\n  \"mcp\": {\n    \"servers\": {\n      \"pdf-tools\": {\n        \"type\": \"stdio\",\n        \"command\": \"node mcp/pdf-server.js\"\n      }\n    }\n  }\n}\n```\n\n### skills/pdf-extraction/SKILL.md\n\n```markdown\n---\nname: pdf-extraction\ndescription: \"Extracts text content from PDF files using pdftotext and OCR technology, handling multi-page documents, scanned images, and complex layouts. Use when user asks to extract text from PDF, read PDF contents, convert PDF to text, parse PDF documents, or analyze PDF files. Supports both digital and scanned PDFs.\"\nversion: \"1.0.0\"\ntags: [\"pdf\", \"extraction\", \"ocr\", \"documents\", \"text-processing\"]\nallowed-tools: \"Read(*.pdf, **/*.pdf), Bash(pdftotext:*), mcp__pdf-tools__*\"\n---\n\n# PDF Text Extraction Skill\n\nAutomatically extracts text from PDF files using multiple methods for maximum compatibility.\n\n## When to Use\n\nClaude activates this skill when you:\n- Ask to extract text from a PDF file\n- Need to read or analyze PDF contents\n- Want to convert PDFs to text format\n- Need to process PDF documents\n- Mention PDF file analysis\n\n## Methods Used\n\n1. **pdftotext**: Fast extraction for digital PDFs\n2. **OCR**: Optical character recognition for scanned documents\n3. **pdf-tools MCP**: Advanced PDF parsing\n\n## Supported Features\n\n- Multi-page PDF extraction\n- Scanned document OCR\n- Layout preservation\n- Table extraction\n- Metadata parsing\n\n## Examples\n\n### Basic Extraction\n```\nUser: Extract text from report.pdf\nClaude: I'll use my PDF extraction skill to get the text...\n```\n\n### Batch Processing\n```\nUser: Extract text from all PDFs in the reports folder\nClaude: Processing multiple PDFs using extraction skill...\n```\n\n## Limitations\n\n- Encrypted PDFs require password\n- OCR accuracy depends on scan quality\n- Very large PDFs (>100MB) may be slow\n- Complex layouts may lose formatting\n```\n\n### mcp/pdf-server.ts\n\n```typescript\nimport { createSdkMcpServer, tool } from \"@anthropic-ai/sdk/mcp\";\nimport { z } from \"zod\";\nimport { exec } from \"child_process\";\nimport { promisify } from \"util\";\nimport * as fs from \"fs/promises\";\n\nconst execAsync = promisify(exec);\n\nconst server = createSdkMcpServer({\n  name: \"pdf-tools\",\n  version: \"1.0.0\",\n  tools: [\n    tool({\n      name: \"extract_pdf_text\",\n      description: \"Extracts text content from a PDF file using pdftotext. Takes a file path as input and returns the extracted text content. Handles multi-page documents and preserves basic layout. Use this when you need to extract readable text from PDF files for analysis or processing.\",\n      input_schema: z.object({\n        file_path: z.string().describe(\"Absolute path to the PDF file\"),\n        layout: z.boolean().default(true).describe(\"Preserve layout formatting\")\n      })\n    }, async ({ file_path, layout }) => {\n      try {\n        // Verify file exists\n        await fs.access(file_path);\n\n        // Extract text using pdftotext\n        const layoutFlag = layout ? \"-layout\" : \"\";\n        const { stdout, stderr } = await execAsync(\n          `pdftotext ${layoutFlag} \"${file_path}\" -`\n        );\n\n        if (stderr) {\n          return {\n            success: false,\n            error: `pdftotext error: ${stderr}`\n          };\n        }\n\n        return {\n          success: true,\n          text: stdout,\n          pages: stdout.split('\\f').length\n        };\n      } catch (error) {\n        return {\n          success: false,\n          error: `Failed to extract PDF: ${error.message}`\n        };\n      }\n    }),\n\n    tool({\n      name: \"pdf_metadata\",\n      description: \"Extracts metadata from a PDF file including title, author, creation date, page count, and file size. Takes a file path as input. Use when you need information about a PDF file without reading its full contents.\",\n      input_schema: z.object({\n        file_path: z.string().describe(\"Absolute path to the PDF file\")\n      })\n    }, async ({ file_path }) => {\n      try {\n        await fs.access(file_path);\n\n        const { stdout } = await execAsync(`pdfinfo \"${file_path}\"`);\n\n        // Parse pdfinfo output\n        const lines = stdout.split('\\n');\n        const metadata: any = {};\n\n        for (const line of lines) {\n          const [key, ...valueParts] = line.split(':');\n          if (key && valueParts.length > 0) {\n            metadata[key.trim()] = valueParts.join(':').trim();\n          }\n        }\n\n        return {\n          success: true,\n          metadata\n        };\n      } catch (error) {\n        return {\n          success: false,\n          error: `Failed to get metadata: ${error.message}`\n        };\n      }\n    })\n  ]\n});\n\nexport default server;\n```\n\n---\n\n## Example 3: Database Tools Plugin\n\nComplete plugin with commands, skills, and MCP server for database operations.\n\n### Structure\n\n```\ndatabase-tools-plugin/\n├── .claude-plugin/\n│   └── plugin.json\n├── commands/\n│   ├── db-query.md\n│   └── db-schema.md\n├── skills/\n│   └── sql-analysis/\n│       └── SKILL.md\n├── mcp/\n│   └── db-server.py\n└── README.md\n```\n\n### plugin.json\n\n```json\n{\n  \"name\": \"database-tools\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Data Team\",\n  \"description\": \"Database query, analysis, and schema inspection tools for PostgreSQL, MySQL, and SQLite\",\n  \"repository\": \"https://github.com/yourorg/database-tools\",\n  \"license\": \"MIT\",\n\n  \"commands\": {\n    \"path\": \"commands\"\n  },\n\n  \"skills\": {\n    \"path\": \"skills\"\n  },\n\n  \"mcp\": {\n    \"servers\": {\n      \"db-tools\": {\n        \"type\": \"stdio\",\n        \"command\": \"python mcp/db-server.py\"\n      }\n    }\n  }\n}\n```\n\n### commands/db-query.md\n\n```markdown\n---\ndescription: \"Execute safe database query and analyze results\"\nallowed-tools: \"mcp__db-tools__execute_query\"\nargument-hint: \"SQL SELECT query\"\n---\n\n# Database Query Execution\n\nQuery: $ARGUMENTS\n\n## Safety Check\n\nValidating that query is read-only (SELECT only)...\n\n## Execute Query\n\nUsing database tools to execute the query and retrieve results.\n\n## Results Analysis\n\nAnalyzing the query results:\n1. Row count and summary statistics\n2. Notable patterns or outliers\n3. Data quality observations\n4. Recommendations for further analysis\n```\n\n### commands/db-schema.md\n\n```markdown\n---\ndescription: \"Display database schema and table information\"\nallowed-tools: \"mcp__db-tools__list_tables, mcp__db-tools__table_schema\"\n---\n\n# Database Schema\n\nRetrieving database schema information...\n\n## Tables\n\nList all tables with row counts and descriptions.\n\n## Relationships\n\nIdentify foreign key relationships between tables.\n\n## Indexes\n\nShow indexes on each table for performance analysis.\n```\n\n### skills/sql-analysis/SKILL.md\n\n```markdown\n---\nname: sql-analysis\ndescription: \"Analyzes SQL database queries and performance using EXPLAIN plans, suggests index optimizations and query rewrites. Executes safe SELECT queries and interprets results for PostgreSQL, MySQL, and SQLite databases. Use when user asks about database queries, slow SQL performance, query optimization, analyzing data patterns, executing SELECT statements, or database analysis.\"\nversion: \"1.0.0\"\ntags: [\"sql\", \"database\", \"postgresql\", \"mysql\", \"sqlite\", \"optimization\", \"queries\", \"performance\", \"analysis\"]\nallowed-tools: \"Read(*.sql, **/*.sql), mcp__db-tools__*\"\n---\n\n# SQL Query Analysis Skill\n\nAnalyzes database queries, optimizes performance, and interprets results.\n\n## When to Use\n\nClaude activates this skill when you ask about:\n- SQL queries or database analysis\n- Performance optimization for slow queries\n- Query result interpretation\n- Data pattern analysis\n- Database schema inspection\n- SELECT statement execution\n\n## Supported Databases\n\n- PostgreSQL (via psql)\n- MySQL (via mysql)\n- SQLite (via sqlite3)\n\n## Capabilities\n\n### Query Execution\n- Safe SELECT query execution (read-only)\n- Result formatting and interpretation\n- Multi-row analysis and aggregation\n\n### Performance Analysis\n- EXPLAIN plan interpretation\n- Index usage analysis\n- Query optimization recommendations\n- Bottleneck identification\n\n### Schema Analysis\n- Table structure inspection\n- Relationship mapping between tables\n- Column type and constraint analysis\n- Index coverage review\n\n## Examples\n\n### Execute and Interpret Query\n```\nUser: Run this query and show me the top 10 customers by revenue\nClaude: I'll execute the SQL query and analyze the results...\n```\n\n### Performance Optimization\n```\nUser: This query is taking 30 seconds, can you optimize it?\nClaude: Let me analyze the query performance using EXPLAIN...\n```\n\n### Schema Exploration\n```\nUser: What tables do we have and how are they related?\nClaude: I'll inspect the database schema...\n```\n\n## Safety Features\n\n- Only executes READ operations (SELECT)\n- Automatically blocks INSERT, UPDATE, DELETE, DROP\n- Validates queries before execution\n- Limits result sizes for safety (max 1000 rows)\n- Prevents SQL injection\n```\n\n### mcp/db-server.py\n\n```python\nfrom anthropic.mcp import createSdkMcpServer, tool\nfrom typing import Optional, Dict, Any, List\nimport sqlite3\nimport os\n\nDB_PATH = os.getenv('DB_PATH', 'database.db')\n\nserver = createSdkMcpServer(\n    name=\"db-tools\",\n    version=\"1.0.0\",\n    tools=[\n        tool(\n            name=\"execute_query\",\n            description=(\n                \"Executes a read-only SQL SELECT query against the database. \"\n                \"Takes a SQL query string and optional row limit. Returns query \"\n                \"results as JSON with column names and values. Use when the user \"\n                \"needs to fetch data, analyze database contents, inspect tables, \"\n                \"or run SELECT queries. Only SELECT statements are allowed for safety.\"\n            ),\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"SQL SELECT query to execute\"\n                    },\n                    \"limit\": {\n                        \"type\": \"number\",\n                        \"description\": \"Maximum rows to return (default 100, max 1000)\",\n                        \"default\": 100,\n                        \"maximum\": 1000\n                    }\n                },\n                \"required\": [\"query\"]\n            }\n        )\n        async def execute_query(query: str, limit: int = 100) -> Dict[str, Any]:\n            # TODO(prototype): swap heuristic checks for a SQL parser to enforce single SELECT safely.\n            # Validate read-only\n            query_lower = query.strip().lower()\n            if not query_lower.startswith('select'):\n                return {\n                    \"success\": False,\n                    \"error\": \"Only SELECT queries are allowed for safety\"\n                }\n\n            # Check for dangerous operations\n            dangerous = ['insert', 'update', 'delete', 'drop', 'alter', 'create']\n            if any(word in query_lower for word in dangerous):\n                return {\n                    \"success\": False,\n                    \"error\": \"Query contains forbidden operations\"\n                }\n\n            try:\n                conn = sqlite3.connect(DB_PATH)\n                conn.row_factory = sqlite3.Row\n                cursor = conn.cursor()\n\n                # Add LIMIT if not present\n                if 'limit' not in query_lower:\n                    query += f\" LIMIT {min(limit, 1000)}\"\n\n                cursor.execute(query)\n                rows = cursor.fetchall()\n\n                results = [dict(row) for row in rows]\n                conn.close()\n\n                return {\n                    \"success\": True,\n                    \"row_count\": len(results),\n                    \"data\": results\n                }\n            except Exception as e:\n                return {\n                    \"success\": False,\n                    \"error\": f\"Query execution failed: {str(e)}\"\n                }\n        ,\n\n        tool(\n            name=\"list_tables\",\n            description=(\n                \"Lists all tables in the database with their row counts and column \"\n                \"details. Returns table names, number of rows, and column information \"\n                \"including types and constraints. Use when user asks about database \"\n                \"schema, available tables, table structure, or database overview.\"\n            ),\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {}\n            }\n        )\n        async def list_tables() -> Dict[str, Any]:\n            try:\n                conn = sqlite3.connect(DB_PATH)\n                cursor = conn.cursor()\n\n                cursor.execute(\n                    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'\"\n                )\n                tables = cursor.fetchall()\n\n                table_info = []\n                for (table_name,) in tables:\n                    # Get row count\n                    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n                    count = cursor.fetchone()[0]\n\n                    # Get column info\n                    cursor.execute(f\"PRAGMA table_info({table_name})\")\n                    columns = cursor.fetchall()\n\n                    table_info.append({\n                        \"name\": table_name,\n                        \"rows\": count,\n                        \"columns\": [\n                            {\n                                \"name\": col[1],\n                                \"type\": col[2],\n                                \"not_null\": bool(col[3]),\n                                \"default\": col[4],\n                                \"primary_key\": bool(col[5])\n                            }\n                            for col in columns\n                        ]\n                    })\n\n                conn.close()\n\n                return {\n                    \"success\": True,\n                    \"table_count\": len(table_info),\n                    \"tables\": table_info\n                }\n            except Exception as e:\n                return {\n                    \"success\": False,\n                    \"error\": f\"Failed to list tables: {str(e)}\"\n                }\n    ]\n)\n```\n\n---\n\n## Example 4: Development Tools Plugin\n\nPlugin with multiple features for development workflows.\n\n### Structure\n\n```\ndev-tools-plugin/\n├── .claude-plugin/\n│   └── plugin.json\n├── commands/\n│   ├── test.md\n│   ├── lint.md\n│   └── deploy/\n│       ├── staging.md\n│       └── production.md\n├── hooks/\n│   ├── formatting.json\n│   └── testing.json\n└── README.md\n```\n\n### plugin.json\n\n```json\n{\n  \"name\": \"dev-tools\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Complete development toolkit with testing, linting, deployment, and automation\",\n  \"license\": \"MIT\",\n\n  \"commands\": {\n    \"path\": \"commands\"\n  },\n\n  \"hooks\": {\n    \"path\": \"hooks\"\n  }\n}\n```\n\n### commands/test.md\n\n```markdown\n---\ndescription: \"Run test suite with coverage reporting\"\nallowed-tools: Bash(npm:*, pytest:*)\nargument-hint: \"test pattern or file\"\n---\n\n# Test Suite\n\nRunning tests for: ${ARGUMENTS:-all tests}\n\n## JavaScript/TypeScript Tests\n\n!npm test ${ARGUMENTS:-}\n\n## Python Tests\n\n!pytest ${ARGUMENTS:-.} -v --cov\n\n## Summary\n\nReview test results and coverage reports above.\n```\n\n### hooks/formatting.json\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"case \\\"$FILE_PATH\\\" in *.ts|*.tsx|*.js|*.jsx) prettier --write \\\"$FILE_PATH\\\" 2>/dev/null && eslint --fix \\\"$FILE_PATH\\\" 2>/dev/null;; *.py) black \\\"$FILE_PATH\\\" 2>/dev/null && ruff check --fix \\\"$FILE_PATH\\\" 2>/dev/null;; esac\"\n      },\n      \"timeout\": 15,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n---\n\nThese complete examples demonstrate:\n- Proper plugin structure\n- Real-world use cases\n- Integration of multiple component types\n- Best practices implementation\n- Production-ready code\n\nUse these as templates for your own plugins!\n",
        ".claude/skills/claude-code-plugin-dev/guides/best-practices.md": "# Best Practices\n\nEssential guidelines for building secure, maintainable, and effective Claude Code plugins.\n\n## Plugin Design Principles\n\n### Single Responsibility\nEach plugin should have a clear, focused purpose.\n\n✅ **Good**:\n- `git-workflow` - Git operations and workflows\n- `pdf-tools` - PDF processing and extraction\n- `api-docs` - API documentation generation\n\n❌ **Bad**:\n- `utils` - Random assortment of unrelated tools\n- `everything` - Tries to do too much\n- `helper` - Vague, unfocused purpose\n\n### Composability\nDesign components to work together and with other plugins.\n\n✅ **Good**:\n- Skill provides capability, command uses it\n- MCP tool does one thing well\n- Hook integrates with existing workflows\n\n❌ **Bad**:\n- Components tightly coupled\n- Duplicate functionality\n- Incompatible with standard tools\n\n### User-Centered Design\nDesign for the user's workflow, not implementation convenience.\n\n✅ **Good**:\n- Clear, descriptive command names\n- Intuitive argument order\n- Helpful error messages\n- Good documentation\n\n❌ **Bad**:\n- Cryptic abbreviations\n- Confusing argument order\n- Technical error messages\n- Minimal documentation\n\n## Security Best Practices\n\n### Never Commit Secrets\n\n✅ **Good**:\n```typescript\nconst apiKey = process.env.API_KEY;\nif (!apiKey) {\n  return { error: \"API_KEY environment variable not set\" };\n}\n```\n\n❌ **Bad**:\n```typescript\nconst apiKey = \"hardcoded-secret-key-123\";  // ❌ Never do this!\n```\n\n### Validate All Inputs\n\n✅ **Good**:\n```typescript\nif (!city || typeof city !== 'string') {\n  return { error: \"City must be a non-empty string\" };\n}\n\nif (city.length > 100) {\n  return { error: \"City name too long\" };\n}\n\nif (!/^[a-zA-Z\\s-]+$/.test(city)) {\n  return { error: \"City name contains invalid characters\" };\n}\n```\n\n❌ **Bad**:\n```typescript\n// No validation, accepts any input\nconst result = await fetchData(userInput);\n```\n\n### Restrictive Tool Permissions\n\n✅ **Good**:\n```yaml\n# Specific, minimal permissions\nallowed-tools: \"Read(*.pdf), Bash(pdftotext:*), Write(output/*.txt)\"\n```\n\n❌ **Bad**:\n```yaml\n# Overly permissive\nallowed-tools: \"Bash(*), Write(*), Read(*)\"\n```\n\n### Sanitize File Paths\n\n✅ **Good**:\n```bash\n# Quote paths, validate\nif [[ \"$FILE_PATH\" =~ ^[a-zA-Z0-9/_.-]+$ ]]; then\n  prettier --write \"$FILE_PATH\"\nfi\n```\n\n❌ **Bad**:\n```bash\n# Unquoted, unvalidated\nprettier --write $FILE_PATH\n```\n\n### Use Environment Variables\n\n✅ **Good**:\n```json\n{\n  \"servers\": {\n    \"my-server\": {\n      \"type\": \"stdio\",\n      \"command\": \"node server.js\",\n      \"env\": {\n        \"API_KEY\": \"${OPENAI_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n❌ **Bad**:\n```json\n{\n  \"command\": \"API_KEY=hardcoded node server.js\"\n}\n```\n\n## Performance Best Practices\n\n### Keep Operations Fast\n\n✅ **Good**:\n- Commands complete in <5 seconds\n- Hooks complete in <10 seconds\n- Cache expensive operations\n- Use async operations\n- Paginate large datasets\n\n❌ **Bad**:\n- Synchronous, blocking operations\n- No caching\n- Load entire datasets\n- Ignore timeouts\n- Sequential when parallel possible\n\n### Set Appropriate Timeouts\n\n```json\n{\n  \"timeout\": 10,     // ✅ Quick operations\n  \"timeout\": 60,     // ✅ Tests, builds\n  \"timeout\": 300     // ❌ Too long, use async instead\n}\n```\n\n### Limit Result Sizes\n\n✅ **Good**:\n```typescript\nconst limit = Math.min(input.limit || 100, 1000);  // Cap at 1000\nconst results = await query(input.query, limit);\n```\n\n❌ **Bad**:\n```typescript\n// No limit, could return millions of rows\nconst results = await query(input.query);\n```\n\n### Use Efficient Algorithms\n\n✅ **Good**:\n- Index lookups instead of scans\n- Stream large files\n- Process in batches\n- Use database queries efficiently\n\n❌ **Bad**:\n- Load entire database into memory\n- O(n²) algorithms on large datasets\n- Repeated API calls\n- No caching\n\n## Code Quality\n\n### Error Handling\n\n✅ **Good**:\n```typescript\ntry {\n  const result = await externalAPI(input);\n  return { success: true, data: result };\n} catch (error) {\n  if (error.code === 'RATE_LIMIT') {\n    return {\n      success: false,\n      error: \"Rate limit exceeded. Please try again in 1 minute.\",\n      retryable: true\n    };\n  }\n  return {\n    success: false,\n    error: `API error: ${error.message}`\n  };\n}\n```\n\n❌ **Bad**:\n```typescript\n// No error handling\nconst result = await externalAPI(input);\nreturn result;\n```\n\n### Descriptive Names\n\n✅ **Good**:\n```yaml\nname: pdf-text-extractor\ndescription: \"Extracts text content from PDF files...\"\n```\n\n```typescript\nasync function extractPdfText(filePath: string): Promise<string>\n```\n\n❌ **Bad**:\n```yaml\nname: pdf-tool\ndescription: \"Does PDF stuff\"\n```\n\n```typescript\nasync function doIt(x: string): Promise<any>\n```\n\n### Documentation\n\n✅ **Good**:\n```typescript\n/**\n * Fetches current weather for a location.\n *\n * @param city - City name (e.g., \"London\")\n * @param country - Optional ISO country code (e.g., \"GB\")\n * @returns Weather data including temperature, conditions, and humidity\n * @throws {Error} If API request fails or city not found\n */\nasync function getWeather(city: string, country?: string)\n```\n\n❌ **Bad**:\n```typescript\n// Gets weather\nasync function getWeather(city, country)\n```\n\n### Consistent Style\n\n✅ **Good**:\n- Use linter (ESLint, Ruff)\n- Follow language conventions\n- Consistent indentation\n- Meaningful variable names\n- Clear code structure\n\n❌ **Bad**:\n- No formatting\n- Mixed styles\n- Inconsistent naming\n- Poor structure\n\n## Skill Activation Best Practices\n\n### Write Specific Descriptions\n\n✅ **Good**:\n```yaml\ndescription: \"Extracts text from PDF files using pdftotext and OCR, handling multi-page documents and scanned images. Use when user asks to extract text from PDF, read PDF contents, convert PDF to text, or analyze PDF documents.\"\n```\n\n**Why it works**:\n- Mentions file type (PDF) explicitly\n- Lists tools used (pdftotext, OCR)\n- Includes activation keywords (extract, read, convert, analyze)\n- Describes capabilities (multi-page, scanned)\n\n❌ **Bad**:\n```yaml\ndescription: \"Helps with documents\"\n```\n\n**Why it fails**:\n- No file type mentioned\n- No specific actions\n- No activation keywords\n- Too vague\n\n### Include Action Keywords\n\nInclude these keyword types:\n\n**File types**: PDF, CSV, JSON, XML, Markdown, YAML\n**Actions**: extract, convert, analyze, parse, generate, validate\n**Tools**: specific command names (pdftotext, jq, etc.)\n**Domains**: database, API, documentation, testing\n\n✅ **Good**:\n```yaml\ndescription: \"Analyzes SQL queries for PostgreSQL and MySQL databases using EXPLAIN plans. Suggests index optimizations and query rewrites. Use when user asks about slow queries, database performance, SQL optimization, or analyzing query execution plans.\"\n```\n\n**Keywords included**: SQL, PostgreSQL, MySQL, EXPLAIN, index, optimization, performance, query\n\n### Test Activation\n\nTest with natural language:\n\n```\nUser: \"I have a PDF that needs text extraction\"\nExpected: PDF extraction skill activates\n\nUser: \"Can you analyze this database query?\"\nExpected: SQL analysis skill activates\n\nUser: \"Help me document my API\"\nExpected: API documentation skill activates\n```\n\nIf skill doesn't activate, add more keywords to description.\n\n## Tool Permission Best Practices\n\n### Principle of Least Privilege\n\nGrant only the permissions actually needed.\n\n✅ **Good**:\n```yaml\n# PDF skill needs\nallowed-tools: \"Read(*.pdf, **/*.pdf), Bash(pdftotext:*), Write(output/*.txt)\"\n```\n\n❌ **Bad**:\n```yaml\n# Overly permissive\nallowed-tools: \"Read(*), Bash(*), Write(*)\"\n```\n\n### Be Specific with Patterns\n\n✅ **Good**:\n```yaml\n# Specific git commands\nallowed-tools: \"Bash(git:status, git:log, git:diff)\"\n\n# Specific directories\nallowed-tools: \"Write(docs/**, output/**)\"\n\n# Specific file types\nallowed-tools: \"Read(*.json, *.yaml)\"\n```\n\n❌ **Bad**:\n```yaml\n# Too broad\nallowed-tools: \"Bash(git:*)\"  # All git commands\nallowed-tools: \"Write(*)\"      # All files\n```\n\n### Document Why Permissions Needed\n\n```markdown\n## Tool Permissions\n\nThis skill requires:\n- `Read(*.pdf)` - To access PDF files for extraction\n- `Bash(pdftotext:*)` - To run PDF extraction tool\n- `Write(output/*.txt)` - To save extracted text\n\nThese permissions are necessary for the skill's core functionality.\n```\n\n## Hook Best Practices\n\n### Keep Hooks Fast\n\n✅ **Good**:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"action\": {\n    \"command\": \"prettier --write \\\"$FILE_PATH\\\" 2>/dev/null || true\"\n  },\n  \"timeout\": 5\n}\n```\n\n❌ **Bad**:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"action\": {\n    \"command\": \"npm run full-test-suite\"  // Takes 5 minutes\n  },\n  \"timeout\": 300\n}\n```\n\n### Handle Errors Gracefully\n\n✅ **Good**:\n```bash\n# Non-critical: continue on error\nprettier --write \"$FILE_PATH\" 2>/dev/null || true\n\n# Critical: block on error with clear message\nnpm test || (echo \"❌ Tests failed! Fix before committing.\" && exit 2)\n```\n\n❌ **Bad**:\n```bash\n# Unhandled errors block unexpectedly\nprettier --write \"$FILE_PATH\"\n```\n\n### Use Appropriate Matchers\n\n✅ **Good**:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"toolName\": \"Edit|Write\"  // Only format after edits/writes\n  }\n}\n```\n\n❌ **Bad**:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"toolName\": \"*\"  // Runs on every tool use\n  }\n}\n```\n\n## MCP Tool Best Practices\n\n### Write Detailed Descriptions\n\n✅ **Good**:\n```typescript\ndescription: \"Fetches current weather conditions for a specific geographic location using the OpenWeatherMap API. Takes a city name and optional country code as input. Returns temperature in Fahrenheit, weather conditions, humidity percentage, and wind speed in mph. Use this when the user asks about current weather, temperature, or atmospheric conditions for a specific location.\"\n```\n\n**Includes**:\n- What it does\n- Data source (OpenWeatherMap)\n- Inputs (city, country)\n- Outputs (temperature, conditions, etc.)\n- When to use\n\n❌ **Bad**:\n```typescript\ndescription: \"Gets weather\"\n```\n\n### Complete Input Schemas\n\n✅ **Good**:\n```typescript\ninput_schema: z.object({\n  city: z.string()\n    .min(1)\n    .max(100)\n    .describe(\"City name (e.g., 'London', 'New York')\"),\n  country: z.string()\n    .length(2)\n    .optional()\n    .describe(\"ISO 3166 country code (e.g., 'US', 'GB')\")\n})\n```\n\n❌ **Bad**:\n```typescript\ninput_schema: z.object({\n  city: z.string(),\n  country: z.string().optional()\n})\n```\n\n### Return Consistent Structure\n\n✅ **Good**:\n```typescript\n// Success\nreturn {\n  success: true,\n  data: { /* results */ }\n};\n\n// Error\nreturn {\n  success: false,\n  error: \"User-friendly message\",\n  details: { code: \"ERROR_CODE\" }\n};\n```\n\n❌ **Bad**:\n```typescript\n// Inconsistent returns\nreturn result;                    // Sometimes\nreturn { data: result };          // Other times\nthrow new Error(\"Failed\");        // Sometimes\n```\n\n## Version Control Best Practices\n\n### Commit Messages\n\n✅ **Good**:\n```bash\ngit commit -m \"feat: add PDF extraction skill\"\ngit commit -m \"fix: resolve skill activation issue\"\ngit commit -m \"docs: update README with examples\"\n```\n\n**Format**: `<type>: <description>`\n- **feat**: New feature\n- **fix**: Bug fix\n- **docs**: Documentation\n- **refactor**: Code refactoring\n- **test**: Test updates\n- **chore**: Maintenance\n\n❌ **Bad**:\n```bash\ngit commit -m \"updates\"\ngit commit -m \"fix stuff\"\ngit commit -m \"WIP\"\n```\n\n### Branch Strategy\n\n✅ **Good**:\n```bash\nmain          # Stable releases\ndevelop       # Integration branch\nfeature/x     # New features\nfix/y         # Bug fixes\n```\n\n❌ **Bad**:\n```bash\n# All work on main with no branches\n```\n\n## Testing Best Practices\n\n### Test All Components\n\n- [ ] Commands execute correctly\n- [ ] Skills activate as expected\n- [ ] MCP tools work properly\n- [ ] Hooks fire appropriately\n- [ ] Error handling works\n- [ ] Edge cases handled\n\n### Automated Testing\n\n```bash\n#!/bin/bash\n# Run before committing\n\n# Validate JSON\njq empty .claude-plugin/plugin.json\n\n# Check syntax\nnode -c mcp/*.js\npython -m py_compile mcp/*.py\n\n# Run tests if present\nnpm test || pytest\n```\n\n### Document Test Scenarios\n\n```markdown\n## Test Scenarios\n\n1. **Basic Usage**: Run /command with typical arguments\n2. **Edge Cases**: Empty input, special characters, very long input\n3. **Error Conditions**: Invalid input, missing files, network errors\n4. **Integration**: Works with other plugins/tools\n```\n\n## Maintenance Best Practices\n\n### Respond to Issues\n\n- Acknowledge issues quickly\n- Reproduce problems\n- Provide fixes or workarounds\n- Document solutions\n\n### Keep Dependencies Updated\n\n```bash\n# Check for updates\nnpm outdated\npip list --outdated\n\n# Update dependencies\nnpm update\npip install --upgrade package\n```\n\n### Monitor Security\n\n- Subscribe to security advisories\n- Update vulnerable dependencies\n- Review permissions regularly\n- Audit code for issues\n\n### Document Changes\n\nUpdate CHANGELOG.md:\n\n```markdown\n# Changelog\n\n## [1.2.0] - 2025-11-21\n\n### Added\n- New /deploy command for staging\n- PDF extraction skill\n\n### Fixed\n- Skill activation issue\n- MCP server timeout\n\n### Changed\n- Updated dependencies\n```\n\n## Next Steps\n\n- **Development workflow**: See [Development Workflow](development-workflow.md)\n- **Publishing**: See [Publishing & Distribution](publishing.md)\n- **Examples**: See [Complete Plugin Examples](../examples/complete-plugins.md)\n",
        ".claude/skills/claude-code-plugin-dev/guides/development-workflow.md": "# Development Workflow\n\nComplete guide to developing, testing, and debugging Claude Code plugins locally.\n\n## Local Development Setup\n\n### 1. Create Local Marketplace\n\n```bash\n# Create marketplace directory\nmkdir -p ~/.claude/marketplaces/local\n\n# Navigate to your plugin project\ncd /path/to/your-plugin\n\n# Link to local marketplace\nln -s $(pwd) ~/.claude/marketplaces/local/your-plugin\n\n# Or copy instead of symlinking\ncp -r . ~/.claude/marketplaces/local/your-plugin\n```\n\n### 2. Add Marketplace to Claude Code\n\nIn Claude Code terminal:\n```bash\n/plugin marketplace add ~/.claude/marketplaces/local\n```\n\n### 3. Install Your Plugin\n\n```bash\n/plugin install your-plugin\n```\n\n### 4. Verify Installation\n\n```bash\n# List installed plugins\n/plugin list\n\n# Check if commands appear\n/help | grep your-command\n\n# View plugin details\n/plugin info your-plugin\n```\n\n## Iterative Development\n\n### Make Changes Workflow\n\n```bash\n# 1. Edit plugin files\nvim commands/my-command.md\n\n# 2. Reload plugin\n/plugin disable your-plugin\n/plugin enable your-plugin\n\n# 3. Test changes\n/my-command test arguments\n\n# 4. Repeat as needed\n```\n\n### Alternative: Direct File Editing\n\nFor project-scope plugins (`.claude/`):\n```bash\n# Edit directly - changes take effect immediately\nvim .claude/commands/my-command.md\n\n# Test right away\n/my-command test\n```\n\n## Validation Checklist\n\n### Before Testing\n\n- [ ] **plugin.json validation**\n```bash\njq . .claude-plugin/plugin.json\njq '.name, .version, .description' .claude-plugin/plugin.json\n```\n\n- [ ] **Name format check**\n```bash\njq -r '.name' .claude-plugin/plugin.json | grep -E '^[a-z0-9-]{1,64}$'\n```\n\n- [ ] **Version format check**\n```bash\njq -r '.version' .claude-plugin/plugin.json | grep -E '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n```\n\n- [ ] **File structure check**\n```bash\nls -la .claude-plugin/\nls -la commands/\nls -la skills/*/SKILL.md\n```\n\n- [ ] **YAML frontmatter validation** (for skills/commands)\n```bash\nhead -n 10 skills/my-skill/SKILL.md\nhead -n 10 commands/my-command.md\n```\n\n## Testing Components\n\n### Testing Slash Commands\n\n```bash\n# 1. Verify command appears\n/help | grep my-command\n\n# 2. Test without arguments\n/my-command\n\n# 3. Test with single argument\n/my-command arg1\n\n# 4. Test with multiple arguments\n/my-command arg1 arg2 \"arg with spaces\"\n\n# 5. Test special characters\n/my-command \"path/to/file.txt\"\n\n# 6. Check allowed-tools work\n# (Verify Bash commands execute, files can be read, etc.)\n```\n\n**Command Test Checklist**:\n- [ ] Command listed in `/help`\n- [ ] Description is clear\n- [ ] `$ARGUMENTS` substitutes correctly\n- [ ] `$1`, `$2`, etc. work for positional args\n- [ ] `!bash` commands execute (if allowed)\n- [ ] `@file` includes file contents (if used)\n- [ ] Error handling works\n- [ ] Output is well-formatted\n\n### Testing Agent Skills\n\nSkills are harder to test since they activate automatically. Use these strategies:\n\n**Direct Testing**:\n```\nUser: [Use keywords from skill description]\n\nExample for PDF skill:\n\"I have a PDF file that needs text extraction\"\n\"Can you extract text from report.pdf?\"\n\"Read the contents of this PDF document\"\n```\n\n**Skill Activation Checklist**:\n- [ ] Skill activates on relevant keywords\n- [ ] Claude mentions using the skill\n- [ ] Skill has access to required tools\n- [ ] Output is correctly formatted\n- [ ] Error handling works\n- [ ] Works with different phrasings\n\n**If skill doesn't activate**:\n1. Make description more specific\n2. Add more keywords (file types, actions)\n3. Include \"Use when user asks to...\"\n4. Check SKILL.md location and case\n5. Verify YAML frontmatter syntax\n6. Test with exact keywords from description\n\n### Testing MCP Servers\n\n**1. Test server starts**:\n```bash\n# TypeScript\nnode mcp/server.js\n# Should start without errors, Ctrl+C to stop\n\n# Python\npython mcp/server.py\n# Should start without errors, Ctrl+C to stop\n```\n\n**2. Check server in Claude Code**:\n```bash\n/mcp\n# Should list your server and tools\n```\n\n**3. Test tool invocation**:\n```\nUser: \"Use the [tool_name] tool to [action]\"\n\nExample:\n\"Use the get_weather tool to check weather in London\"\n\"Execute the database query tool for SELECT * FROM users\"\n```\n\n**MCP Test Checklist**:\n- [ ] Server starts without errors\n- [ ] Server listed in `/mcp`\n- [ ] All tools are visible\n- [ ] Tool names follow naming convention\n- [ ] Descriptions are detailed\n- [ ] Input schemas are complete\n- [ ] Tools execute successfully\n- [ ] Error handling returns proper structure\n- [ ] Results are well-formatted\n\n### Testing Hooks\n\nHooks execute automatically on events. Test by triggering events:\n\n**PostToolUse hooks**:\n```bash\n# Edit a file to trigger PostToolUse\n/my-command that uses Edit tool\n\n# Check if hook executed\n# Look for hook output (formatting, logging, etc.)\n```\n\n**PreToolUse hooks**:\n```bash\n# Try action that should be blocked\n# Verify hook prevents or allows action\n```\n\n**Stop hooks**:\n```bash\n# Complete any command or response\n# Check if hook executed at the end\n```\n\n**Hook Test Checklist**:\n- [ ] Hook fires on correct event\n- [ ] Matcher filters appropriately\n- [ ] Command executes successfully\n- [ ] Exit code is correct\n- [ ] Timeout is sufficient\n- [ ] Output/side effects are correct\n- [ ] No unintended blocking\n- [ ] Error handling works\n\n## Debugging Techniques\n\n### Enable Verbose Logging\n\n```bash\n# Set debug environment variable (if supported)\nexport CLAUDE_DEBUG=1\n\n# Or add debug output in hooks\necho \"Debug: $TOOL_NAME on $FILE_PATH\" >&2\n```\n\n### Check Plugin Installation\n\n```bash\n# List all installed plugins\n/plugin list\n\n# Get plugin details\n/plugin info your-plugin\n\n# Check plugin status\n/plugin status your-plugin\n```\n\n### Validate JSON Files\n\n```bash\n# Validate plugin.json\njq empty .claude-plugin/plugin.json && echo \"Valid\" || echo \"Invalid\"\n\n# Validate hook files\njq empty hooks/*.json && echo \"All valid\" || echo \"Some invalid\"\n\n# Pretty-print for inspection\njq . .claude-plugin/plugin.json\n```\n\n### Test Components Independently\n\n**Commands**:\n```bash\n# Read command file\ncat commands/my-command.md\n\n# Check frontmatter parsing\nhead -n 20 commands/my-command.md\n```\n\n**Skills**:\n```bash\n# Read skill file\ncat skills/my-skill/SKILL.md\n\n# Validate YAML frontmatter\nhead -n 15 skills/my-skill/SKILL.md | grep -A 10 \"^---\"\n```\n\n**MCP Servers**:\n```bash\n# Test server script\nnode mcp/server.js &\nsleep 2\nkill %1\n\n# Check for syntax errors\nnode -c mcp/server.js\npython -m py_compile mcp/server.py\n```\n\n**Hooks**:\n```bash\n# Test hook command directly\nFILE_PATH=\"test.ts\" bash -c 'prettier --write \"$FILE_PATH\"'\n\n# Check exit codes\necho $?\n```\n\n### Common Issues and Fixes\n\n**\"Plugin not found\"**:\n```bash\n# Check marketplace added\n/plugin marketplace list\n\n# Re-add marketplace\n/plugin marketplace add ~/.claude/marketplaces/local\n\n# Check plugin exists in marketplace\nls ~/.claude/marketplaces/local/\n```\n\n**\"Command not appearing in /help\"**:\n```bash\n# Check file location\nls .claude-plugin/plugin.json\nls commands/*.md\n\n# Validate plugin.json\njq '.commands' .claude-plugin/plugin.json\n\n# Check plugin enabled\n/plugin list | grep your-plugin\n```\n\n**\"Skill not activating\"**:\n```bash\n# Read skill description\njq -r '.description' skills/my-skill/SKILL.md | head -n 5\n\n# Check file case\nls skills/*/SKILL.md\n\n# Validate YAML\nhead -n 15 skills/my-skill/SKILL.md\n```\n\n**\"MCP tool not available\"**:\n```bash\n# Check server status\n/mcp\n\n# Test server directly\nnode mcp/server.js\n\n# Check plugin.json MCP config\njq '.mcp' .claude-plugin/plugin.json\n```\n\n**\"Hook not firing\"**:\n```bash\n# Validate hook JSON\njq . hooks/hooks.json\n\n# Check event name\njq '.[].event' hooks/hooks.json\n\n# Verify enabled\njq '.[].enabled' hooks/hooks.json\n```\n\n## Test Automation\n\n### Create Test Script\n\n```bash\n#!/bin/bash\n# test-plugin.sh\n\nset -e  # Exit on error\n\necho \"🔍 Testing plugin...\"\n\n# 1. Validate JSON\necho \"Validating plugin.json...\"\njq empty .claude-plugin/plugin.json\n\n# 2. Check name format\necho \"Checking name format...\"\nNAME=$(jq -r '.name' .claude-plugin/plugin.json)\necho \"$NAME\" | grep -E '^[a-z0-9-]{1,64}$' || (echo \"❌ Invalid name format\" && exit 1)\n\n# 3. Validate version\necho \"Checking version format...\"\nVERSION=$(jq -r '.version' .claude-plugin/plugin.json)\necho \"$VERSION\" | grep -E '^[0-9]+\\.[0-9]+\\.[0-9]+$' || (echo \"❌ Invalid version\" && exit 1)\n\n# 4. Check file structure\necho \"Checking file structure...\"\n[[ -f .claude-plugin/plugin.json ]] || (echo \"❌ Missing plugin.json\" && exit 1)\n\n# 5. Validate commands\nif [[ -d commands ]]; then\n    echo \"Validating commands...\"\n    find commands -name \"*.md\" | while read cmd; do\n        echo \"  Checking $cmd\"\n        head -n 1 \"$cmd\" | grep \"^---$\" || echo \"  ⚠️  Missing frontmatter in $cmd\"\n    done\nfi\n\n# 6. Validate skills\nif [[ -d skills ]]; then\n    echo \"Validating skills...\"\n    find skills -name \"SKILL.md\" | while read skill; do\n        echo \"  Checking $skill\"\n        head -n 1 \"$skill\" | grep \"^---$\" || echo \"  ⚠️  Missing frontmatter in $skill\"\n    done\nfi\n\n# 7. Test MCP servers\nif [[ -d mcp ]]; then\n    echo \"Testing MCP servers...\"\n    for server in mcp/*.{js,ts,py}; do\n        [[ -f \"$server\" ]] || continue\n        echo \"  Checking $server\"\n        if [[ \"$server\" == *.js ]]; then\n            node -c \"$server\" || (echo \"  ❌ Syntax error in $server\" && exit 1)\n        elif [[ \"$server\" == *.py ]]; then\n            python -m py_compile \"$server\" || (echo \"  ❌ Syntax error in $server\" && exit 1)\n        fi\n    done\nfi\n\n# 8. Validate hooks\nif [[ -d hooks ]]; then\n    echo \"Validating hooks...\"\n    for hook in hooks/*.json; do\n        [[ -f \"$hook\" ]] || continue\n        echo \"  Checking $hook\"\n        jq empty \"$hook\" || (echo \"  ❌ Invalid JSON in $hook\" && exit 1)\n    done\nfi\n\necho \"✅ All tests passed!\"\n```\n\n**Run tests**:\n```bash\nchmod +x test-plugin.sh\n./test-plugin.sh\n```\n\n## Integration Testing\n\n### Test End-to-End Workflows\n\n```bash\n# 1. Install plugin\n/plugin install your-plugin\n\n# 2. Test command\n/my-command test-arg\n\n# 3. Trigger skill\n# (Ask question with skill keywords)\n\n# 4. Invoke MCP tool\n# (Ask Claude to use the tool)\n\n# 5. Trigger hooks\n# (Perform actions that trigger hooks)\n\n# 6. Verify all components work together\n```\n\n### Create Test Scenarios\n\nDocument test scenarios in `tests/scenarios.md`:\n\n```markdown\n# Test Scenarios\n\n## Scenario 1: Basic Command Execution\n1. Run `/my-command test`\n2. Expected: Command executes successfully\n3. Expected: Output is formatted correctly\n\n## Scenario 2: Skill Activation\n1. Say \"I need to extract text from a PDF\"\n2. Expected: PDF extraction skill activates\n3. Expected: Claude mentions using the skill\n\n## Scenario 3: Hook Execution\n1. Edit a TypeScript file\n2. Expected: Prettier runs automatically\n3. Expected: File is formatted\n\n## Scenario 4: MCP Tool Use\n1. Ask \"Get weather for London\"\n2. Expected: Claude invokes get_weather tool\n3. Expected: Returns weather data\n```\n\n## Performance Testing\n\n### Measure Hook Timing\n\n```bash\n# Add timing to hooks\ntime prettier --write \"$FILE_PATH\"\n\n# Check hook timeout is sufficient\n# Hook should complete well before timeout\n```\n\n### Monitor MCP Server\n\n```bash\n# Check server startup time\ntime node mcp/server.js &\n\n# Monitor memory usage\ntop -p $(pgrep -f \"server.js\")\n\n# Test tool response time\n# Ask Claude to use tool, note delay\n```\n\n## Version Control Integration\n\n### Git Workflow\n\n```bash\n# 1. Commit changes\ngit add .\ngit commit -m \"feat: add new command\"\n\n# 2. Tag version\ngit tag v1.0.0\ngit push origin main v1.0.0\n\n# 3. Test from git\ncd /tmp\ngit clone your-repo test-plugin\n/plugin install /tmp/test-plugin\n```\n\n### Pre-commit Hook\n\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\n\n# Run validation before commit\n./test-plugin.sh || exit 1\n```\n\n## Troubleshooting Workflow\n\nWhen something doesn't work:\n\n1. **Check logs/output**\n   - Look for error messages\n   - Check Claude's response\n\n2. **Validate configuration**\n   - Run `jq . .claude-plugin/plugin.json`\n   - Check file locations\n\n3. **Test independently**\n   - Test components outside Claude Code\n   - Verify tools work from command line\n\n4. **Simplify**\n   - Remove complexity\n   - Test minimal version\n   - Add features back incrementally\n\n5. **Check documentation**\n   - Review reference docs\n   - Compare with examples\n   - Check for typos\n\n6. **Ask for help**\n   - Search community resources\n   - Check GitHub issues\n   - Ask in forums\n\n## Next Steps\n\n- **Publish plugin**: See [Publishing & Distribution](publishing.md)\n- **Review best practices**: See [Best Practices](best-practices.md)\n- **See examples**: See [Complete Plugin Examples](../examples/complete-plugins.md)\n- **Troubleshooting**: See [Troubleshooting Guide](../troubleshooting.md)\n",
        ".claude/skills/claude-code-plugin-dev/guides/publishing.md": "# Publishing & Distribution\n\nComplete guide to publishing and distributing Claude Code plugins.\n\n## Pre-Publishing Checklist\n\nBefore publishing your plugin, ensure:\n\n### Documentation\n- [ ] README.md with clear description\n- [ ] Installation instructions\n- [ ] Usage examples for all components\n- [ ] Configuration documentation\n- [ ] License file (MIT, Apache, etc.)\n- [ ] CHANGELOG.md for version history\n\n### Validation\n- [ ] plugin.json is valid JSON\n- [ ] Name follows format: lowercase-hyphens (max 64 chars)\n- [ ] Version follows semantic versioning\n- [ ] Description is clear and complete (max 1024 chars)\n- [ ] All referenced paths exist\n- [ ] No hardcoded secrets or API keys\n\n### Testing\n- [ ] All commands tested and working\n- [ ] Skills activate correctly\n- [ ] MCP servers start without errors\n- [ ] Hooks execute properly\n- [ ] No breaking errors\n- [ ] Edge cases handled\n\n### Code Quality\n- [ ] No console.log() or debug code\n- [ ] Error messages are user-friendly\n- [ ] Code is formatted consistently\n- [ ] Comments explain complex logic\n- [ ] TODOs are removed or documented\n\n## Publishing to GitHub\n\n### 1. Initialize Git Repository\n\n```bash\ncd your-plugin\ngit init\n```\n\n### 2. Create .gitignore\n\n```gitignore\n# .gitignore\n\n# Dependencies\nnode_modules/\n__pycache__/\n*.pyc\n.venv/\nvenv/\n\n# Environment files\n.env\n.env.local\n*.key\nsecrets/\n\n# OS files\n.DS_Store\nThumbs.db\n\n# IDE files\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Build files\ndist/\nbuild/\n*.log\n\n# Test files\ncoverage/\n.pytest_cache/\n```\n\n### 3. Create README.md\n\n```markdown\n# Your Plugin Name\n\nBrief description of what your plugin does.\n\n## Features\n\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Installation\n\n\\`\\`\\`bash\n/plugin install username/your-plugin\n\\`\\`\\`\n\n## Usage\n\n### Commands\n\n**`/command-name`** - Description\n\\`\\`\\`bash\n/command-name arg1 arg2\n\\`\\`\\`\n\n### Skills\n\n**skill-name** - Activates when you ask about X, Y, Z\n\n### Tools\n\n**tool_name** - Description of what it does\n\n## Configuration\n\nAny configuration needed (API keys, etc.)\n\n## Examples\n\nDetailed examples of usage\n\n## License\n\nMIT\n```\n\n### 4. Commit and Push\n\n```bash\n# Stage all files\ngit add .\n\n# Create initial commit\ngit commit -m \"Initial release: v1.0.0\"\n\n# Create GitHub repo (via gh CLI or web interface)\ngh repo create your-plugin --public --source=.\n\n# Or add remote manually\ngit remote add origin https://github.com/username/your-plugin.git\n\n# Push to GitHub\ngit push -u origin main\n\n# Tag version\ngit tag v1.0.0\ngit push origin v1.0.0\n```\n\n### 5. Users Install\n\nUsers can now install your plugin:\n\n```bash\n/plugin install username/your-plugin\n```\n\n## Semantic Versioning\n\nUse semantic versioning: `MAJOR.MINOR.PATCH`\n\n### Version Guidelines\n\n**MAJOR** (X.0.0) - Breaking changes:\n- Removed commands, skills, or tools\n- Changed command arguments (non-backward compatible)\n- Changed tool interfaces\n- Removed required parameters\n\nExamples:\n- `1.5.2 → 2.0.0`: Removed `/deploy` command\n- `1.3.0 → 2.0.0`: Changed `/commit` to require 2 args instead of 1\n\n**MINOR** (x.X.0) - New features (backward compatible):\n- New commands, skills, or tools\n- New optional parameters\n- New functionality that doesn't break existing\n\nExamples:\n- `1.2.0 → 1.3.0`: Added new `/test` command\n- `1.4.0 → 1.5.0`: Added optional `--verbose` flag\n\n**PATCH** (x.x.X) - Bug fixes:\n- Bug fixes\n- Documentation updates\n- Performance improvements\n- No API changes\n\nExamples:\n- `1.2.3 → 1.2.4`: Fixed `/deploy` error handling\n- `1.5.0 → 1.5.1`: Updated README\n\n### Updating Version\n\n```bash\n# Update plugin.json\njq '.version = \"1.1.0\"' .claude-plugin/plugin.json > tmp.json\nmv tmp.json .claude-plugin/plugin.json\n\n# Commit changes\ngit add .\ngit commit -m \"Release v1.1.0: Add new features\"\n\n# Tag release\ngit tag v1.1.0\ngit push origin main v1.1.0\n```\n\n## Creating Organization Marketplace\n\nFor teams sharing multiple plugins internally.\n\n### 1. Create Marketplace Repository\n\n```bash\nmkdir company-plugins\ncd company-plugins\n\n# Create directory structure\nmkdir -p .claude-plugin\n\n# Create marketplace.json\ncat > .claude-plugin/marketplace.json << 'EOF'\n{\n  \"name\": \"Company Plugins\",\n  \"owner\": \"Acme Corporation\",\n  \"description\": \"Official plugins for Acme engineering teams\",\n  \"plugins\": []\n}\nEOF\n\n# Initialize git\ngit init\ngit add .\ngit commit -m \"Initial marketplace setup\"\ngh repo create company/plugins --public --source=.\ngit push -u origin main\n```\n\n### 2. Add Plugins to Marketplace\n\nEdit `.claude-plugin/marketplace.json`:\n\n```json\n{\n  \"name\": \"Company Plugins\",\n  \"owner\": \"Acme Corporation\",\n  \"description\": \"Official plugins for Acme engineering teams\",\n  \"plugins\": [\n    {\n      \"name\": \"dev-tools\",\n      \"source\": \"github\",\n      \"repo\": \"company/dev-tools-plugin\",\n      \"description\": \"Development workflow tools\",\n      \"version\": \"1.0.0\",\n      \"author\": \"DevOps Team\"\n    },\n    {\n      \"name\": \"api-helpers\",\n      \"source\": \"github\",\n      \"repo\": \"company/api-helpers-plugin\",\n      \"description\": \"API documentation and testing tools\",\n      \"version\": \"2.1.0\",\n      \"author\": \"API Team\"\n    }\n  ]\n}\n```\n\n### 3. Team Members Use Marketplace\n\n```bash\n# Add company marketplace\n/plugin marketplace add company/plugins\n\n# Browse and install plugins\n/plugin\n/plugin install dev-tools\n/plugin install api-helpers\n```\n\n### 4. Update Marketplace\n\n```bash\n# Edit marketplace.json to add/update plugins\nvim .claude-plugin/marketplace.json\n\n# Commit and push\ngit add .\ngit commit -m \"Add new plugin: database-tools\"\ngit push\n\n# Team members refresh\n/plugin marketplace refresh\n```\n\n## Plugin Sources\n\nPlugins can be installed from multiple sources:\n\n### GitHub Repositories\n```bash\n/plugin install username/repo-name\n```\n\n### Local Directories\n```bash\n/plugin install /absolute/path/to/plugin\n/plugin install ~/my-plugins/custom-plugin\n```\n\n### Git URLs\n```bash\n/plugin install https://github.com/user/plugin.git\n```\n\n### Relative Paths (in marketplace.json)\n```json\n{\n  \"plugins\": [\n    {\n      \"name\": \"local-plugin\",\n      \"source\": \"./plugins/local-plugin\"\n    }\n  ]\n}\n```\n\n## Distribution Best Practices\n\n### Version Management\n\n✅ **DO**:\n- Follow semantic versioning strictly\n- Tag all releases in git\n- Update CHANGELOG.md\n- Document breaking changes\n- Increment version for all releases\n\n❌ **DON'T**:\n- Skip version updates\n- Reuse version numbers\n- Make breaking changes in patches\n- Forget to tag releases\n- Skip changelog updates\n\n### Documentation\n\n✅ **DO**:\n- Provide comprehensive README\n- Include usage examples\n- Document all features\n- Explain configuration\n- List requirements/dependencies\n\n❌ **DON'T**:\n- Assume users know how it works\n- Skip installation instructions\n- Forget to document breaking changes\n- Omit configuration details\n- Leave TODOs in public docs\n\n### Security\n\n✅ **DO**:\n- Use environment variables for secrets\n- Document security requirements\n- Validate all inputs\n- Use restrictive tool permissions\n- Review code before publishing\n\n❌ **DON'T**:\n- Commit API keys or tokens\n- Use overly permissive tool access\n- Skip input validation\n- Ignore security warnings\n- Publish without security review\n\n### Maintenance\n\n✅ **DO**:\n- Respond to issues\n- Review pull requests\n- Keep dependencies updated\n- Fix reported bugs\n- Maintain documentation\n\n❌ **DON'T**:\n- Ignore user feedback\n- Let dependencies rot\n- Skip security updates\n- Abandon the project silently\n- Break backward compatibility without notice\n\n## Publishing Checklist\n\nBefore each release:\n\n### Code\n- [ ] All features working as documented\n- [ ] Tests passing\n- [ ] No debug code\n- [ ] Error handling complete\n- [ ] Code formatted consistently\n\n### Documentation\n- [ ] README updated\n- [ ] CHANGELOG updated\n- [ ] Version number bumped\n- [ ] Examples tested\n- [ ] Breaking changes documented\n\n### Testing\n- [ ] Installed and tested locally\n- [ ] All components verified\n- [ ] Edge cases handled\n- [ ] No breaking changes (or documented)\n- [ ] Works on fresh install\n\n### Git\n- [ ] All changes committed\n- [ ] Version tagged\n- [ ] Pushed to GitHub\n- [ ] Release notes created\n- [ ] Previous versions work\n\n### Security\n- [ ] No secrets committed\n- [ ] Dependencies reviewed\n- [ ] Permissions appropriate\n- [ ] Input validation complete\n- [ ] Security issues addressed\n\n## Release Process\n\n### 1. Prepare Release\n\n```bash\n# Update version\nvim .claude-plugin/plugin.json\n\n# Update CHANGELOG\nvim CHANGELOG.md\n\n# Run tests\n./test-plugin.sh\n\n# Commit\ngit add .\ngit commit -m \"Prepare release v1.2.0\"\n```\n\n### 2. Create Release\n\n```bash\n# Tag version\ngit tag -a v1.2.0 -m \"Release v1.2.0\"\n\n# Push\ngit push origin main v1.2.0\n```\n\n### 3. Create GitHub Release\n\n```bash\n# Using gh CLI\ngh release create v1.2.0 \\\n  --title \"Version 1.2.0\" \\\n  --notes \"\n## Features\n- Added new /deploy command\n- Improved error handling\n\n## Bug Fixes\n- Fixed skill activation issue\n- Corrected MCP server timeout\n\n## Breaking Changes\nNone\n\"\n```\n\nOr create release manually on GitHub:\n1. Go to Releases\n2. Click \"Create a new release\"\n3. Select tag v1.2.0\n4. Add release notes\n5. Publish\n\n### 4. Announce Release\n\n- Update README if needed\n- Notify users (if you have a channel)\n- Update marketplace listing\n- Post in community forums\n\n## Continuous Integration\n\n### GitHub Actions\n\nCreate `.github/workflows/test.yml`:\n\n```yaml\nname: Test Plugin\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: '18'\n\n    - name: Validate plugin.json\n      run: |\n        jq empty .claude-plugin/plugin.json\n\n    - name: Check name format\n      run: |\n        NAME=$(jq -r '.name' .claude-plugin/plugin.json)\n        echo \"$NAME\" | grep -E '^[a-z0-9-]{1,64}$'\n\n    - name: Check version format\n      run: |\n        VERSION=$(jq -r '.version' .claude-plugin/plugin.json)\n        echo \"$VERSION\" | grep -E '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n\n    - name: Test MCP servers\n      run: |\n        if [ -f mcp/server.js ]; then\n          node -c mcp/server.js\n        fi\n\n    - name: Validate hooks\n      run: |\n        for hook in hooks/*.json; do\n          [ -f \"$hook\" ] && jq empty \"$hook\"\n        done\n```\n\n## Migration Guide Template\n\nWhen making breaking changes, provide migration guide:\n\n```markdown\n# Migration Guide: v1.x to v2.0\n\n## Breaking Changes\n\n### Command Renamed\n**Before**:\n\\`\\`\\`bash\n/old-command arg\n\\`\\`\\`\n\n**After**:\n\\`\\`\\`bash\n/new-command arg\n\\`\\`\\`\n\n### Parameter Added\n**Before**:\n\\`\\`\\`bash\n/deploy\n\\`\\`\\`\n\n**After** (now requires environment):\n\\`\\`\\`bash\n/deploy staging\n\\`\\`\\`\n\n## Automated Migration\n\nWe provide a script to help migrate:\n\\`\\`\\`bash\n./migrate-to-v2.sh\n\\`\\`\\`\n```\n\n## Next Steps\n\n- **Development workflow**: See [Development Workflow](development-workflow.md)\n- **Best practices**: See [Best Practices](best-practices.md)\n- **Examples**: See [Complete Plugin Examples](../examples/complete-plugins.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/agent-skills.md": "# Agent Skills (2025 Schema)\n\nComplete guide to creating Agent Skills that Claude automatically activates based on context.\n\n## Overview\n\nAgent Skills are **model-invoked capabilities** that Claude autonomously decides to use based on the task context. Unlike slash commands, users don't explicitly invoke them.\n\n**Best for**:\n- Context-aware capabilities\n- File type processing (PDF, CSV, etc.)\n- Domain expertise (SQL, APIs, etc.)\n- Automatic tool selection\n\n## Skill File Structure\n\n**Location**: `skills/skill-name/SKILL.md`\n\n**Required filename**: `SKILL.md` (exact case, must be this name)\n\n```markdown\n---\nname: skill-name\ndescription: \"[What it does] + [When to use] + [Specific keywords]. (max 1024 chars)\"\nversion: \"1.0.0\"\ntags: [\"keyword1\", \"keyword2\"]\nallowed-tools: \"Read(*), Bash(tool:*)\"\nmodel: \"claude-sonnet-4-5-20250929\"\n---\n\n# Skill Title\n\nDetailed explanation of what this skill does.\n\n## When to Use\n\nClaude activates this when the user asks about [specific triggers].\n\n## Available Tools\n\nList the tools this skill uses and why.\n\n## Examples\n\nWorking examples demonstrating the skill.\n```\n\n## 2025 Schema Fields\n\n### name (required)\n```yaml\nname: pdf-text-extraction\n```\n- **Format**: Lowercase letters, hyphens only\n- **Max length**: 64 characters\n- **Purpose**: Skill identifier\n- **Invalid**: Underscores, spaces, uppercase\n\n### description (required - MOST IMPORTANT!)\n```yaml\ndescription: \"Extracts text from PDF files using pdftotext and pdf2txt.py, handling multi-page documents and complex layouts. Use when the user asks to extract, read, or analyze text from PDF files, convert PDFs to text, or process PDF documents.\"\n```\n\n**This is the MOST CRITICAL field**. Claude uses it to decide when to activate your skill.\n\n**Formula**: `[What] + [How] + [When with keywords]`\n\n**Must include**:\n1. **What it does** (specific action)\n2. **Tools/methods used** (how it works)\n3. **When to use** with **explicit keywords**\n4. **File types** if applicable\n5. **Actions** (extract, convert, analyze, etc.)\n6. **Domains** (database, API, documentation, etc.)\n\n**Good example**:\n```yaml\ndescription: \"Analyzes SQL database queries for performance issues using EXPLAIN and query plans. Suggests index optimizations, query rewrites, and caching strategies. Use when user asks about slow queries, database optimization, SQL performance, query tuning, or analyzing PostgreSQL/MySQL performance.\"\n```\n\n**Bad example**:\n```yaml\ndescription: \"Helps with database stuff\"  # ❌ Too vague, no keywords\n```\n\n### version (required)\n```yaml\nversion: \"1.0.0\"\n```\n- **Format**: Semantic versioning (MAJOR.MINOR.PATCH)\n- **Purpose**: Track skill changes\n- **Update**: When changing functionality\n\n### tags (optional but recommended)\n```yaml\ntags: [\"pdf\", \"extraction\", \"documents\", \"text-processing\"]\n```\n- **Purpose**: Discovery, categorization\n- **Format**: Array of strings\n- **Include**: File types, actions, domains\n\n### allowed-tools (NEW in 2025)\n```yaml\nallowed-tools: \"Read(*), Bash(pdftotext:*, pdf2txt:*)\"\n```\n- **Purpose**: Restrict tool access for security\n- **Format**: Comma-separated tool patterns\n- **Patterns**:\n  - `Read(*)` - All file reads\n  - `Read(*.pdf)` - Only PDF files\n  - `Bash(command:*)` - Specific command family\n  - `Write(output/**)` - Specific directory\n\n### model (optional)\n```yaml\nmodel: \"claude-sonnet-4-5-20250929\"\n```\n- **Purpose**: Override default model\n- **Use when**: Skill needs specific capabilities\n\n### icon (optional)\n```yaml\nicon: \"icons/pdf-icon.png\"\n```\n- **Purpose**: Visual identifier\n- **Format**: Relative path to image\n\n### category (optional)\n```yaml\ncategory: \"document-processing\"\n```\n- **Purpose**: Group related skills\n- **Examples**: \"development\", \"data-analysis\", \"devops\"\n\n## Critical: Skill Activation\n\n### Why Skills Fail to Activate\n\n**Problem**: You create a skill but Claude never uses it.\n\n**Common causes**:\n\n1. **Generic description**\n```yaml\n# ❌ BAD\ndescription: \"Helps with documents\"\ndescription: \"Useful for file processing\"\ndescription: \"Handles various tasks\"\n```\n\n2. **Missing keywords**\n```yaml\n# ❌ BAD\ndescription: \"Extracts content from files\"\n# Missing: what file type? PDF? Word? Text?\n```\n\n3. **No activation triggers**\n```yaml\n# ❌ BAD\ndescription: \"PDF text extraction tool\"\n# Missing: \"Use when user asks to...\"\n```\n\n4. **Wrong file location**\n```\nskills/my-skill.md          # ❌ Wrong\nskills/my-skill/skill.md    # ❌ Wrong case\nskills/my-skill/SKILL.md    # ✅ Correct!\n```\n\n### How to Write Descriptions That Work\n\n**Template**:\n```\n\"[Action] [Object] using [Tools], [details about capabilities].\nUse when user asks [trigger phrases with keywords].\"\n```\n\n**Example 1: PDF Extraction**\n```yaml\ndescription: \"Extracts and converts text from PDF documents using pdftotext and OCR, handling scanned images, multi-page files, and complex layouts. Use when user asks to extract text from PDF, read PDF contents, convert PDF to text, or analyze PDF documents.\"\n```\n\n**Keywords included**: PDF, extract, convert, text, OCR, scanned, read, analyze\n\n**Example 2: SQL Analysis**\n```yaml\ndescription: \"Analyzes SQL database queries, interprets results, and suggests optimizations using EXPLAIN plans and index analysis. Supports PostgreSQL, MySQL, and SQLite. Use when user asks about database queries, slow SQL performance, query optimization, analyzing data patterns, or executing SELECT statements.\"\n```\n\n**Keywords included**: SQL, database, queries, PostgreSQL, MySQL, SQLite, performance, optimization, SELECT, analyze\n\n**Example 3: API Documentation**\n```yaml\ndescription: \"Generates API documentation from OpenAPI/Swagger specifications, creating markdown with endpoints, parameters, examples, and authentication details. Use when user needs to document REST APIs, create API references, parse OpenAPI specs, or generate endpoint documentation.\"\n```\n\n**Keywords included**: API, OpenAPI, Swagger, REST, documentation, endpoints, parameters, authentication\n\n### Activation Testing\n\n**Test your skill**:\n```\nUser: \"I have a PDF file that needs text extraction\"\nExpected: Claude activates PDF extraction skill\n\nUser: \"Can you analyze this SQL query performance?\"\nExpected: Claude activates SQL analysis skill\n\nUser: \"Help me document my REST API\"\nExpected: Claude activates API documentation skill\n```\n\n**If skill doesn't activate**:\n1. Add more specific keywords to description\n2. Include file types explicitly\n3. Add \"Use when user asks to [action]\"\n4. Test with different phrasings\n\n## Complete Skill Examples\n\n### Example 1: PDF Text Extraction\n\n**File**: `skills/pdf-extraction/SKILL.md`\n\n```markdown\n---\nname: pdf-extraction\ndescription: \"Extracts and converts text content from PDF files using pdftotext and pdf2txt.py, handling multi-page documents, scanned images with OCR, and complex layouts. Use when user asks to extract text from PDF, read PDF contents, convert PDF to text, parse PDF documents, or analyze PDF files.\"\nversion: \"1.0.0\"\ntags: [\"pdf\", \"extraction\", \"ocr\", \"documents\", \"text-processing\"]\nallowed-tools: \"Read(*.pdf, **/*.pdf), Bash(pdftotext:*, pdf2txt:*)\"\n---\n\n# PDF Text Extraction Skill\n\nExtracts text content from PDF files using multiple methods for maximum compatibility.\n\n## When to Use\n\nClaude automatically activates this skill when you:\n- Mention extracting text from PDFs\n- Ask to read or analyze PDF contents\n- Need to convert PDFs to text format\n- Want to parse PDF documents\n\n## Available Tools\n\n- **pdftotext**: Fast extraction for standard PDFs\n- **pdf2txt.py**: Advanced extraction for complex layouts\n- **Read tool**: Access PDF files from the filesystem\n\n## How It Works\n\n1. Detect PDF file location\n2. Try `pdftotext` for fast extraction\n3. Fall back to `pdf2txt.py` for complex documents\n4. Return formatted text with structure preserved\n\n## Examples\n\n### Basic Extraction\n```\nUser: Extract text from report.pdf\nClaude: I'll use my PDF extraction skill...\n```\n\n### Multi-page Analysis\n```\nUser: Analyze the content in these 50 PDF files\nClaude: Using PDF extraction to process all files...\n```\n\n## Limitations\n\n- Scanned images require OCR (may be slow)\n- Heavily formatted PDFs may lose layout\n- Encrypted PDFs need password\n</markdown>\n```\n\n### Example 2: SQL Query Analysis\n\n**File**: `skills/sql-analysis/SKILL.md`\n\n```markdown\n---\nname: sql-analysis\ndescription: \"Analyzes SQL database queries and performance using EXPLAIN plans, suggests index optimizations and query rewrites. Executes safe SELECT queries and interprets results. Supports PostgreSQL, MySQL, and SQLite. Use when user asks about database queries, slow SQL performance, query optimization, analyzing data patterns, or executing SELECT statements.\"\nversion: \"1.0.0\"\ntags: [\"sql\", \"database\", \"postgresql\", \"mysql\", \"optimization\", \"queries\", \"performance\"]\nallowed-tools: \"Read(*.sql, **/*.sql), Bash(psql:*, mysql:*, sqlite3:*)\"\n---\n\n# SQL Query Analysis Skill\n\nAnalyzes database queries, optimizes performance, and interprets results.\n\n## When to Use\n\nClaude activates this skill when you ask about:\n- SQL queries or database analysis\n- Performance optimization for slow queries\n- Query result interpretation\n- Data pattern analysis\n- Database schema inspection\n\n## Supported Databases\n\n- PostgreSQL (via `psql`)\n- MySQL (via `mysql`)\n- SQLite (via `sqlite3`)\n\n## Capabilities\n\n### Query Execution\n- Safe SELECT query execution\n- Result formatting and interpretation\n- Multi-row analysis\n\n### Performance Analysis\n- EXPLAIN plan interpretation\n- Index suggestions\n- Query optimization recommendations\n- Bottleneck identification\n\n### Schema Analysis\n- Table structure inspection\n- Relationship mapping\n- Column type analysis\n\n## Examples\n\n### Execute and Analyze\n```\nUser: Run this query and tell me the top customers\nClaude: I'll execute the query using my SQL analysis skill...\n```\n\n### Performance Optimization\n```\nUser: This query is really slow, can you optimize it?\nClaude: Let me analyze the query performance...\n```\n\n## Safety Features\n\n- Only executes READ operations (SELECT)\n- Blocks INSERT, UPDATE, DELETE, DROP\n- Validates queries before execution\n- Limits result sizes for safety\n</markdown>\n```\n\n### Example 3: API Documentation Generator\n\n**File**: `skills/api-docs/SKILL.md`\n\n```markdown\n---\nname: api-documentation\ndescription: \"Generates comprehensive API documentation from OpenAPI/Swagger specifications, source code, or existing endpoints. Creates markdown documentation with endpoint details, parameters, request/response examples, authentication, and error codes. Use when user needs to document REST APIs, create API references, parse OpenAPI specs, generate endpoint documentation, or document GraphQL APIs.\"\nversion: \"1.0.0\"\ntags: [\"api\", \"documentation\", \"openapi\", \"swagger\", \"rest\", \"graphql\", \"endpoints\"]\nallowed-tools: \"Read(*.yaml, *.yml, *.json, **/*.md), Write(docs/**)\"\n---\n\n# API Documentation Generation Skill\n\nGenerates comprehensive, user-friendly API documentation.\n\n## When to Use\n\nClaude activates when you need to:\n- Document REST or GraphQL APIs\n- Parse OpenAPI/Swagger specs\n- Create endpoint documentation\n- Generate API references\n- Document authentication flows\n\n## Input Formats\n\n- **OpenAPI/Swagger**: YAML or JSON specs\n- **Source Code**: Parse from code comments\n- **Existing Endpoints**: Live API inspection\n- **Manual Descriptions**: User-provided details\n\n## Output Format\n\nGenerated documentation includes:\n\n1. **Overview**: API purpose and architecture\n2. **Authentication**: Methods and examples\n3. **Endpoints**: Complete endpoint list\n4. **Parameters**: Request params with types\n5. **Responses**: Success and error examples\n6. **Code Examples**: Multiple languages\n7. **Error Codes**: Detailed error reference\n\n## Examples\n\n### From OpenAPI Spec\n```\nUser: Generate docs from api-spec.yaml\nClaude: I'll parse the OpenAPI spec and create comprehensive documentation...\n```\n\n### From Source Code\n```\nUser: Document the API endpoints in src/api/\nClaude: Analyzing source code to extract API documentation...\n```\n\n## Features\n\n- Automatic example generation\n- Request/response formatting\n- Authentication flow diagrams\n- Error code reference tables\n- Multi-language code samples\n</markdown>\n```\n\n## Tool Permissions Best Practices\n\n### Read Permissions\n```yaml\n# Specific file types\nallowed-tools: \"Read(*.pdf, *.txt)\"\n\n# Specific directories\nallowed-tools: \"Read(data/**, config/**)\"\n\n# All files (use cautiously)\nallowed-tools: \"Read(*)\"\n```\n\n### Bash Permissions\n```yaml\n# Specific command families\nallowed-tools: \"Bash(git:*, npm:*)\"\n\n# Specific commands\nallowed-tools: \"Bash(pdftotext:*, ps:aux)\"\n\n# All bash (dangerous!)\nallowed-tools: \"Bash(*)\"\n```\n\n### Write Permissions\n```yaml\n# Specific directories (safest)\nallowed-tools: \"Write(output/**, temp/**)\"\n\n# Specific file types\nallowed-tools: \"Write(*.md, *.txt)\"\n\n# All writes (use carefully)\nallowed-tools: \"Write(*)\"\n```\n\n### Multiple Tools\n```yaml\nallowed-tools: \"Read(*.pdf), Bash(pdftotext:*), Write(output/*.txt)\"\n```\n\n## Troubleshooting\n\n### Skill Not Activating\n\n1. **Make description more specific**:\n```yaml\n# Before (doesn't activate):\ndescription: \"Helps with files\"\n\n# After (activates):\ndescription: \"Extracts text from PDF files using pdftotext. Use when user asks to extract, read, or analyze PDF contents.\"\n```\n\n2. **Add explicit keywords**:\n- File types: PDF, CSV, JSON, XML\n- Actions: extract, convert, analyze, parse\n- Tools: specific command names\n\n3. **Verify file structure**:\n```\n✅ skills/pdf-extraction/SKILL.md\n❌ skills/pdf-extraction/skill.md (wrong case)\n❌ skills/pdf-extraction.md (wrong structure)\n```\n\n4. **Check YAML syntax**:\n```bash\n# Validate YAML frontmatter\nhead -n 20 skills/my-skill/SKILL.md\n```\n\n### Skill Activates But Fails\n\n1. **Check allowed-tools**:\n```yaml\n# Ensure skill has permission for tools it needs\nallowed-tools: \"Bash(pdftotext:*)\"\n```\n\n2. **Verify tools exist**:\n```bash\nwhich pdftotext\nwhich pdf2txt.py\n```\n\n3. **Test tool independently**:\n```bash\npdftotext sample.pdf -\n```\n\n## Best Practices\n\n### Description Writing\n\n✅ **DO**:\n- Be extremely specific\n- Include file types explicitly\n- List actions (extract, convert, analyze)\n- Add \"Use when user asks to [action]\"\n- Include tool names\n- Mention supported formats\n\n❌ **DON'T**:\n- Use generic language\n- Omit keywords\n- Forget activation triggers\n- Be vague about capabilities\n\n### Tool Permissions\n\n✅ **DO**:\n- Use most restrictive permissions\n- Specify exact patterns\n- Document why permissions needed\n- Test with minimal permissions first\n\n❌ **DON'T**:\n- Grant blanket access (`Bash(*)`)\n- Allow unnecessary write access\n- Forget to document permissions\n- Over-permission \"just in case\"\n\n### Versioning\n\n✅ **DO**:\n- Update version on changes\n- Document version changes\n- Follow semantic versioning\n\n❌ **DON'T**:\n- Forget to bump version\n- Make breaking changes in patches\n- Skip version documentation\n\n## Next Steps\n\n- **Add commands**: See [Slash Commands](slash-commands.md)\n- **Create MCP tools**: See [MCP Servers](mcp-servers.md)\n- **Test skill activation**: See [Development Workflow](../guides/development-workflow.md)\n- **See examples**: See [Complete Plugin Examples](../examples/complete-plugins.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/hooks.md": "# Hooks (Event Handlers)\n\nComplete guide to implementing event-driven automation with hooks.\n\n## Overview\n\nHooks are event handlers that execute automatically at specific lifecycle points in Claude Code. They enable automation, validation, formatting, and custom workflows.\n\n**Best for**:\n- Automatic code formatting\n- Pre/post-commit validation\n- Logging and notifications\n- Tool use tracking\n- Custom automations\n\n## Hook Configuration\n\n**File**: `hooks/hooks.json`\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"prettier --write \\\"$FILE_PATH\\\"\"\n      },\n      \"timeout\": 10,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n## Available Hook Events\n\n### SessionStart\n- **Trigger**: When Claude Code session begins\n- **Use for**: Initialize environment, load config, set variables\n- **Example**: Load API keys, set up logging\n\n### SessionEnd\n- **Trigger**: When Claude Code session ends\n- **Use for**: Cleanup, save state, final logging\n- **Example**: Close connections, archive logs\n\n### UserPromptSubmit\n- **Trigger**: User submits a prompt\n- **Use for**: Pre-processing, validation, context injection\n- **Example**: Add project context, validate requests\n\n### PreToolUse\n- **Trigger**: Before Claude executes a tool\n- **Use for**: Blocking operations, validation, safety checks\n- **Example**: Block dangerous commands, require approval\n\n### PostToolUse\n- **Trigger**: After Claude executes a tool\n- **Use for**: Formatting, logging, notifications, cleanup\n- **Example**: Auto-format code, log changes, notify team\n\n### PermissionRequest\n- **Trigger**: Claude requests user permission\n- **Use for**: Auto-approve/deny based on rules\n- **Example**: Auto-approve safe operations\n\n### Stop\n- **Trigger**: Claude finishes generating response\n- **Use for**: Validation, post-processing, cleanup\n- **Example**: Run tests, check conventions\n\n### SubagentStop\n- **Trigger**: Subagent completes its task\n- **Use for**: Aggregate results, notify parent\n- **Example**: Collect subagent outputs\n\n### Notification\n- **Trigger**: System sends notification\n- **Use for**: Desktop alerts, external notifications\n- **Example**: Send Slack message, desktop popup\n\n### PreCompact\n- **Trigger**: Before context window compaction\n- **Use for**: Save important context, cleanup\n- **Example**: Archive conversation state\n\n## Hook Structure\n\n### Required Fields\n\n```json\n{\n  \"event\": \"PostToolUse\",        // Which event triggers this hook\n  \"action\": {                    // What to do\n    \"type\": \"command\",           // \"command\" or \"prompt\"\n    \"command\": \"echo hello\"      // Command to execute\n  }\n}\n```\n\n### Optional Fields\n\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {                   // Filter when hook runs\n    \"toolName\": \"Edit|Write\"\n  },\n  \"action\": {\n    \"type\": \"command\",\n    \"command\": \"prettier --write \\\"$FILE_PATH\\\"\"\n  },\n  \"timeout\": 10,                 // Max execution time (seconds)\n  \"enabled\": true                // Enable/disable hook\n}\n```\n\n## Matchers\n\nMatchers filter when hooks execute based on context.\n\n### Tool Name Matching\n\n**Exact match**:\n```json\n\"matcher\": {\n  \"toolName\": \"Edit\"\n}\n```\n\n**Multiple tools** (OR):\n```json\n\"matcher\": {\n  \"toolName\": \"Edit|Write|Delete\"\n}\n```\n\n**All tools**:\n```json\n\"matcher\": {\n  \"toolName\": \"*\"\n}\n```\n\n**Pattern matching**:\n```json\n\"matcher\": {\n  \"toolName\": \"Bash:git:*\"      // All git bash commands\n}\n```\n\n## Action Types\n\n### Command Actions\n\nExecute shell commands.\n\n```json\n\"action\": {\n  \"type\": \"command\",\n  \"command\": \"prettier --write \\\"$FILE_PATH\\\"\"\n}\n```\n\n**Available variables**:\n- `$FILE_PATH` - Modified file path (PostToolUse)\n- `$TOOL_NAME` - Tool that was used\n- `$CLAUDE_PROJECT_DIR` - Project root\n- `$CLAUDE_PLUGIN_ROOT` - Plugin directory\n- All environment variables\n\n**Exit codes**:\n- `0` - Success (continue normally)\n- `2` - Blocking error (show stderr to Claude, halt)\n- Other - Non-blocking error (logged but continues)\n\n### Prompt Actions\n\nSend prompts to Claude for processing.\n\n```json\n\"action\": {\n  \"type\": \"prompt\",\n  \"prompt\": \"Did the code follow our style guidelines?\"\n}\n```\n\n**Use for**:\n- Decision making\n- Code review\n- Analysis\n- Validation requiring understanding\n\n## Complete Hook Examples\n\n### Example 1: Auto-Format on Save\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"if [[ $FILE_PATH == *.ts || $FILE_PATH == *.tsx ]]; then prettier --write \\\"$FILE_PATH\\\" 2>/dev/null; fi\"\n      },\n      \"timeout\": 10,\n      \"enabled\": true\n    },\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"if [[ $FILE_PATH == *.py ]]; then black \\\"$FILE_PATH\\\" 2>/dev/null && ruff check --fix \\\"$FILE_PATH\\\" 2>/dev/null; fi\"\n      },\n      \"timeout\": 15,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n### Example 2: Pre-Commit Validation\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PreToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Bash:git:commit\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"npm test || (echo 'Tests failed! Fix before committing.' && exit 2)\"\n      },\n      \"timeout\": 60,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n### Example 3: Change Logging\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Edit|Write|Delete\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"echo \\\"$(date): $TOOL_NAME on $FILE_PATH\\\" >> ~/.claude/changes.log\"\n      },\n      \"timeout\": 3,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n### Example 4: Test on Stop\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"Stop\",\n      \"matcher\": {\n        \"toolName\": \"*\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"npm test --silent && echo '✅ Tests passed' || echo '❌ Tests failed'\"\n      },\n      \"timeout\": 60,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n### Example 5: Notify Team on Deploy\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"PostToolUse\",\n      \"matcher\": {\n        \"toolName\": \"Bash:kubectl:*\"\n      },\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK -d '{\\\"text\\\":\\\"Deployment executed\\\"}'\"\n      },\n      \"timeout\": 5,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n### Example 6: Session Initialization\n\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"SessionStart\",\n      \"action\": {\n        \"type\": \"command\",\n        \"command\": \"echo \\\"export PROJECT_ENV=development\\\" > $CLAUDE_ENV_FILE\"\n      },\n      \"timeout\": 3,\n      \"enabled\": true\n    }\n  ]\n}\n```\n\n## Environment Variables\n\n### Available in Hooks\n\n**Standard variables**:\n- `$CLAUDE_PROJECT_DIR` - Project root directory\n- `$CLAUDE_PLUGIN_ROOT` - Plugin installation directory\n- `$CLAUDE_ENV_FILE` - File for persisting env vars across hooks\n- All system environment variables\n\n**Tool-specific variables**:\n- `$FILE_PATH` - File path (for Edit/Write/Read tools)\n- `$TOOL_NAME` - Name of tool executed\n- `$COMMAND` - Bash command (for Bash tool)\n\n### Persisting Variables\n\n**Save variable**:\n```bash\necho \"export MY_VAR=value\" >> $CLAUDE_ENV_FILE\n```\n\n**Use in later hooks**:\n```bash\nsource $CLAUDE_ENV_FILE\necho $MY_VAR\n```\n\n## Input/Output Protocol\n\n### Input (JSON via stdin)\n\nHooks receive JSON with session and event context:\n\n```json\n{\n  \"session\": {\n    \"id\": \"session-uuid\",\n    \"workspaceDir\": \"/path/to/workspace\",\n    \"currentDir\": \"/path/to/current\"\n  },\n  \"event\": {\n    \"type\": \"PostToolUse\",\n    \"tool\": \"Edit\",\n    \"status\": \"success\",\n    \"output\": \"File modified: example.ts\"\n  }\n}\n```\n\n### Output\n\n**Exit codes**:\n- `0` - Success, continue normally\n- `2` - Blocking error, halt execution, show stderr to Claude\n- Other - Non-blocking error, logged but continues\n\n**Special JSON output**:\n```json\n{\n  \"decision\": \"approve\",\n  \"additionalContext\": \"Optional context to add to conversation\"\n}\n```\n\n**stdout**: Logged if verbose mode enabled\n\n**stderr**: Shown to user on blocking errors (exit 2)\n\n## Timeout Behavior\n\n```json\n{\n  \"timeout\": 10  // Seconds\n}\n```\n\n**What happens on timeout**:\n1. Hook process is killed\n2. Treated as non-blocking error\n3. Execution continues\n4. Warning logged\n\n**Choosing timeouts**:\n- **Quick operations** (formatting): 5-10s\n- **Tests**: 30-60s\n- **Builds**: 60-120s\n- **Network calls**: 10-30s\n\n## Best Practices\n\n### Hook Design\n\n✅ **DO**:\n- Keep hooks fast and focused\n- Use appropriate timeouts\n- Handle errors gracefully\n- Log important actions\n- Test hooks independently\n- Use matchers to filter appropriately\n\n❌ **DON'T**:\n- Create slow hooks (>30s)\n- Use hooks for long-running processes\n- Ignore error handling\n- Create hooks with side effects in unrelated tools\n- Forget to set enabled flag\n\n### Command Safety\n\n✅ **DO**:\n- Quote file paths: `\"$FILE_PATH\"`\n- Check file existence before operations\n- Use `2>/dev/null` to suppress errors\n- Add `|| true` for non-critical commands\n- Validate inputs\n\n❌ **DON'T**:\n- Use unquoted paths (breaks with spaces)\n- Assume files exist\n- Let errors halt unintentionally\n- Execute without validation\n- Use dangerous commands without checks\n\n### Error Handling\n\n✅ **DO**:\n```bash\n# Non-critical: ignore errors\nprettier --write \"$FILE_PATH\" 2>/dev/null || true\n\n# Critical: block on error\nnpm test || (echo \"Tests failed!\" && exit 2)\n\n# Conditional: check before executing\n[[ -f \"$FILE_PATH\" ]] && prettier --write \"$FILE_PATH\"\n```\n\n❌ **DON'T**:\n```bash\n# No error handling\nprettier --write $FILE_PATH\n\n# Blocks unconditionally\nprettier --write \"$FILE_PATH\" || exit 2\n```\n\n### Performance\n\n✅ **DO**:\n- Use matchers to filter hooks\n- Keep commands fast\n- Run expensive operations async\n- Cache results when possible\n- Set reasonable timeouts\n\n❌ **DON'T**:\n- Run hooks on every event\n- Execute slow operations synchronously\n- Skip timeout configuration\n- Run redundant operations\n- Chain many hooks unnecessarily\n\n## Troubleshooting\n\n### Hook Not Firing\n\n**Check**:\n1. Event name is valid\n2. Hook is `enabled: true`\n3. Matcher pattern is correct\n4. Tool name matches pattern\n5. hook.json is valid JSON\n\n**Debug**:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"toolName\": \"*\"\n  },\n  \"action\": {\n    \"type\": \"command\",\n    \"command\": \"echo 'Hook fired!' >&2\"\n  }\n}\n```\n\n### Command Failing\n\n**Check**:\n1. Command exists: `which prettier`\n2. File paths are quoted\n3. Exit code is appropriate\n4. Timeout is sufficient\n5. Environment variables are set\n\n**Debug**:\n```bash\n# Test command independently\nprettier --write \"test.ts\"\n\n# Check exit code\necho $?\n```\n\n### Blocking Unintentionally\n\n**Problem**: Hook blocks execution unexpectedly\n\n**Solution**: Use exit code 0 or handle errors:\n```bash\n# Don't block on failure\nprettier --write \"$FILE_PATH\" || true\n\n# Or suppress errors\nprettier --write \"$FILE_PATH\" 2>/dev/null\n```\n\n### Timeout Issues\n\n**Problem**: Hook times out\n\n**Solutions**:\n1. Increase timeout for slow operations\n2. Run long operations in background\n3. Optimize command performance\n4. Use async operations\n\n## Multiple Hook Files\n\nYou can split hooks across multiple JSON files:\n\n```\nhooks/\n├── formatting.json      # Formatting hooks\n├── testing.json         # Test hooks\n├── logging.json         # Logging hooks\n└── deployment.json      # Deployment hooks\n```\n\nAll files are loaded and merged.\n\n## Security Considerations\n\n### Safe Commands\n\n✅ **Safe**:\n```bash\nprettier --write \"$FILE_PATH\"\neslint --fix \"$FILE_PATH\"\ngit add \"$FILE_PATH\"\nnpm test\n```\n\n❌ **Dangerous**:\n```bash\nrm -rf \"$DIRECTORY\"        # Destructive\neval \"$USER_INPUT\"         # Code injection\ncurl $URL | bash           # Remote code execution\nchmod 777 \"$FILE_PATH\"     # Overly permissive\n```\n\n### Input Validation\n\n**Always validate**:\n```bash\n# Check file exists\n[[ -f \"$FILE_PATH\" ]] || exit 0\n\n# Check file type\n[[ \"$FILE_PATH\" == *.ts ]] || exit 0\n\n# Validate patterns\necho \"$FILE_PATH\" | grep -E '^[a-zA-Z0-9/._-]+$' || exit 2\n```\n\n### Secrets Management\n\n**Don't**:\n```bash\n# ❌ Hardcoded secrets\ncurl -H \"Authorization: Bearer hardcoded-token\"\n```\n\n**Do**:\n```bash\n# ✅ Environment variables\ncurl -H \"Authorization: Bearer $API_TOKEN\"\n```\n\n## Next Steps\n\n- **Create commands**: See [Slash Commands](slash-commands.md)\n- **Add skills**: See [Agent Skills](agent-skills.md)\n- **Build tools**: See [MCP Servers](mcp-servers.md)\n- **Test hooks**: See [Development Workflow](../guides/development-workflow.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/mcp-servers.md": "# MCP Servers (Custom Tools)\n\nComplete guide to implementing custom tools via Model Context Protocol (MCP) servers.\n\n## Overview\n\nMCP servers expose custom tools that Claude can invoke. They provide external integrations, API access, database connections, and custom operations.\n\n**Best for**:\n- API integrations\n- Database operations\n- File system operations\n- External service connections\n- Custom calculations or processing\n\n## MCP Server Types\n\n### 1. stdio (Standard Input/Output)\n- **Communication**: stdin/stdout\n- **Best for**: Local tools, CLI wrappers\n- **Languages**: Node.js, Python, any language\n\n### 2. HTTP\n- **Communication**: HTTP REST API\n- **Best for**: Remote services, web APIs\n- **Deployment**: Separate server process\n\n### 3. SSE (Server-Sent Events)\n- **Communication**: HTTP with event stream\n- **Best for**: Real-time updates, streaming\n- **Use case**: Long-running operations\n\n## TypeScript Implementation\n\n### Basic Structure\n\n```typescript\nimport { createSdkMcpServer, tool } from \"@anthropic-ai/sdk/mcp\";\nimport { z } from \"zod\";\n\nconst server = createSdkMcpServer({\n  name: \"my-tools\",\n  version: \"1.0.0\",\n  tools: [\n    tool({\n      name: \"tool_name\",\n      description: \"Detailed description (3-4 sentences minimum)\",\n      input_schema: z.object({\n        param: z.string().describe(\"Parameter description\")\n      })\n    }, async (input) => {\n      // Implementation\n      return { result: \"data\" };\n    })\n  ]\n});\n\nexport default server;\n```\n\n### Complete Example: Weather API\n\n```typescript\nimport { createSdkMcpServer, tool } from \"@anthropic-ai/sdk/mcp\";\nimport { z } from \"zod\";\nimport fetch from \"node-fetch\";\n\nconst server = createSdkMcpServer({\n  name: \"weather-tools\",\n  version: \"1.0.0\",\n  tools: [\n    tool({\n      name: \"get_weather\",\n      description: \"Fetches current weather conditions for a specific geographic location using the OpenWeatherMap API. Takes a city name and optional country code as input. Returns temperature in Fahrenheit, weather conditions, humidity percentage, and wind speed in mph. Use this when the user asks about current weather, temperature, or atmospheric conditions for a specific location.\",\n      input_schema: z.object({\n        city: z.string().describe(\"City name (e.g., 'London', 'New York')\"),\n        country: z.string().optional().describe(\"ISO 3166 country code (e.g., 'US', 'GB')\")\n      })\n    }, async ({ city, country }) => {\n      try {\n        const location = country ? `${city},${country}` : city;\n        const apiKey = process.env.OPENWEATHER_API_KEY;\n\n        const response = await fetch(\n          `https://api.openweathermap.org/data/2.5/weather?q=${location}&appid=${apiKey}&units=imperial`\n        );\n\n        if (!response.ok) {\n          return {\n            success: false,\n            error: `Weather API error: ${response.statusText}`\n          };\n        }\n\n        const data = await response.json();\n\n        return {\n          success: true,\n          location: `${data.name}, ${data.sys.country}`,\n          temperature: data.main.temp,\n          feels_like: data.main.feels_like,\n          conditions: data.weather[0].description,\n          humidity: data.main.humidity,\n          wind_speed: data.wind.speed\n        };\n      } catch (error) {\n        return {\n          success: false,\n          error: error.message\n        };\n      }\n    }),\n\n    tool({\n      name: \"get_forecast\",\n      description: \"Retrieves 5-day weather forecast for a location including daily high/low temperatures, conditions, and precipitation probability. Returns forecast data in 3-hour intervals. Use when user asks about upcoming weather, future conditions, or weather predictions for a city.\",\n      input_schema: z.object({\n        city: z.string().describe(\"City name\"),\n        country: z.string().optional().describe(\"ISO country code\"),\n        days: z.number().min(1).max(5).default(3).describe(\"Number of days to forecast (1-5)\")\n      })\n    }, async ({ city, country, days }) => {\n      // Implementation similar to above\n      return { forecast: [] };\n    })\n  ]\n});\n\nexport default server;\n```\n\n## Python Implementation\n\n### Basic Structure\n\n```python\nfrom anthropic.mcp import createSdkMcpServer, tool\nfrom typing import Optional, Dict, Any\n\nserver = createSdkMcpServer(\n    name=\"my-tools\",\n    version=\"1.0.0\",\n    tools=[\n        tool(\n            name=\"tool_name\",\n            description=\"Detailed description\",\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"param\": {\"type\": \"string\", \"description\": \"Parameter description\"}\n                },\n                \"required\": [\"param\"]\n            }\n        )\n        async def tool_name(param: str) -> Dict[str, Any]:\n            return {\"result\": \"data\"}\n    ]\n)\n```\n\n### Complete Example: Database Tools\n\n```python\nfrom anthropic.mcp import createSdkMcpServer, tool\nfrom typing import Optional, Dict, Any, List\nimport sqlite3\n\nserver = createSdkMcpServer(\n    name=\"database-tools\",\n    version=\"1.0.0\",\n    tools=[\n        tool(\n            name=\"execute_query\",\n            description=(\n                \"Executes a read-only SQL SELECT query against the SQLite database. \"\n                \"Takes a SQL query string and optional row limit. Returns query results \"\n                \"as JSON with column names and values. Use when the user needs to fetch \"\n                \"data, analyze database contents, inspect tables, or run SELECT queries. \"\n                \"Only SELECT statements are allowed for safety.\"\n            ),\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"SQL SELECT query to execute\"\n                    },\n                    \"limit\": {\n                        \"type\": \"number\",\n                        \"description\": \"Maximum rows to return (default 100)\",\n                        \"default\": 100\n                    }\n                },\n                \"required\": [\"query\"]\n            }\n        )\n        async def execute_query(query: str, limit: int = 100) -> Dict[str, Any]:\n            # Validate read-only\n            if not query.strip().lower().startswith('select'):\n                return {\n                    \"success\": False,\n                    \"error\": \"Only SELECT queries are allowed\"\n                }\n\n            try:\n                conn = sqlite3.connect('database.db')\n                conn.row_factory = sqlite3.Row\n                cursor = conn.cursor()\n\n                # Add LIMIT if not present\n                if 'limit' not in query.lower():\n                    query += f\" LIMIT {limit}\"\n\n                cursor.execute(query)\n                rows = cursor.fetchall()\n\n                results = [dict(row) for row in rows]\n\n                conn.close()\n\n                return {\n                    \"success\": True,\n                    \"rows\": len(results),\n                    \"data\": results\n                }\n            except Exception as e:\n                return {\n                    \"success\": False,\n                    \"error\": str(e)\n                }\n        ,\n\n        tool(\n            name=\"list_tables\",\n            description=(\n                \"Lists all tables in the database with their row counts and column details. \"\n                \"Returns table names, number of rows, and column information including types. \"\n                \"Use when user asks about database schema, available tables, or database structure.\"\n            ),\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {}\n            }\n        )\n        async def list_tables() -> Dict[str, Any]:\n            try:\n                conn = sqlite3.connect('database.db')\n                cursor = conn.cursor()\n\n                cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n                tables = cursor.fetchall()\n\n                table_info = []\n                for (table_name,) in tables:\n                    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n                    count = cursor.fetchone()[0]\n\n                    cursor.execute(f\"PRAGMA table_info({table_name})\")\n                    columns = cursor.fetchall()\n\n                    table_info.append({\n                        \"name\": table_name,\n                        \"rows\": count,\n                        \"columns\": [\n                            {\"name\": col[1], \"type\": col[2]}\n                            for col in columns\n                        ]\n                    })\n\n                conn.close()\n\n                return {\n                    \"success\": True,\n                    \"tables\": table_info\n                }\n            except Exception as e:\n                return {\n                    \"success\": False,\n                    \"error\": str(e)\n                }\n    ]\n)\n```\n\n## Tool Naming Convention\n\nTools are automatically prefixed with: `mcp__<server-name>__<tool-name>`\n\n**Examples**:\n- Server: `weather-tools`, Tool: `get_weather`\n  → `mcp__weather-tools__get_weather`\n\n- Server: `db-tools`, Tool: `execute_query`\n  → `mcp__db-tools__execute_query`\n\n**Naming rules**:\n- Lowercase letters, numbers, hyphens, underscores\n- Max 64 characters\n- Must match regex: `^[a-zA-Z0-9_-]{1,64}$`\n\n## Tool Descriptions (Critical!)\n\n### Description Requirements\n\n**Minimum**: 3-4 complete sentences\n\n**Must include**:\n1. What the tool does\n2. What inputs it takes\n3. What it returns\n4. When to use it\n\n### Bad vs Good Descriptions\n\n❌ **Bad** (too short, vague):\n```typescript\ndescription: \"Gets weather data\"\ndescription: \"Queries the database\"\ndescription: \"Retrieves information\"\n```\n\n✅ **Good** (detailed, specific):\n```typescript\ndescription: \"Fetches current weather conditions for a specific geographic location using the OpenWeatherMap API. Takes a city name and optional country code as input. Returns temperature in Fahrenheit, weather conditions, humidity percentage, and wind speed in mph. Use this when the user asks about current weather, temperature, or atmospheric conditions for a specific location.\"\n```\n\n### Description Template\n\n```\n\"[Action] [Object] [using Method/API], [handling Details]. Takes [Input Description] as input. Returns [Output Description] including [specific fields]. Use this when the user [trigger conditions with keywords].\"\n```\n\n## Input Schema\n\n### JSON Schema (Python)\n\n```python\ninput_schema={\n    \"type\": \"object\",\n    \"properties\": {\n        \"param1\": {\n            \"type\": \"string\",\n            \"description\": \"Detailed parameter description\"\n        },\n        \"param2\": {\n            \"type\": \"number\",\n            \"description\": \"Numeric parameter\",\n            \"minimum\": 0,\n            \"maximum\": 100\n        },\n        \"param3\": {\n            \"type\": \"string\",\n            \"enum\": [\"option1\", \"option2\"],\n            \"description\": \"Enumerated options\"\n        },\n        \"optional_param\": {\n            \"type\": \"boolean\",\n            \"description\": \"Optional boolean flag\",\n            \"default\": False\n        }\n    },\n    \"required\": [\"param1\", \"param2\"]\n}\n```\n\n### Zod Schema (TypeScript)\n\n```typescript\ninput_schema: z.object({\n  param1: z.string().describe(\"Detailed parameter description\"),\n  param2: z.number().min(0).max(100).describe(\"Numeric parameter\"),\n  param3: z.enum([\"option1\", \"option2\"]).describe(\"Enumerated options\"),\n  optionalParam: z.boolean().default(false).describe(\"Optional flag\")\n})\n```\n\n### Parameter Types\n\n**Supported types**:\n- `string` - Text values\n- `number` - Numeric values (int or float)\n- `boolean` - true/false\n- `array` - Lists of values\n- `object` - Nested structures\n- `enum` - Predefined options\n\n**Constraints**:\n- `minimum`, `maximum` - Numeric bounds\n- `minLength`, `maxLength` - String length\n- `pattern` - Regex validation\n- `enum` - Allowed values list\n- `default` - Default value if not provided\n\n## Error Handling\n\n### Return Structure\n\n**Success**:\n```typescript\nreturn {\n  success: true,\n  data: { /* results */ }\n};\n```\n\n**Error**:\n```typescript\nreturn {\n  success: false,\n  error: \"User-friendly error message\",\n  details: {\n    code: \"ERROR_CODE\",\n    retryable: true\n  }\n};\n```\n\n### Error Types\n\n**Validation Errors**:\n```typescript\nif (!input.city) {\n  return {\n    success: false,\n    error: \"City parameter is required\"\n  };\n}\n```\n\n**API Errors**:\n```typescript\nif (!response.ok) {\n  return {\n    success: false,\n    error: `API error: ${response.statusText}`,\n    details: { statusCode: response.status }\n  };\n}\n```\n\n**Exception Handling**:\n```typescript\ntry {\n  // Tool implementation\n} catch (error) {\n  return {\n    success: false,\n    error: error.message,\n    details: { stack: error.stack }\n  };\n}\n```\n\n## Plugin Configuration\n\n**File**: `.claude-plugin/plugin.json`\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Plugin with MCP tools\",\n\n  \"mcp\": {\n    \"servers\": {\n      \"my-tools\": {\n        \"type\": \"stdio\",\n        \"command\": \"node mcp/server.js\"\n      }\n    }\n  }\n}\n```\n\n### Server Types Configuration\n\n**stdio** (most common):\n```json\n\"my-server\": {\n  \"type\": \"stdio\",\n  \"command\": \"node mcp/server.js\"\n}\n```\n\n**HTTP**:\n```json\n\"my-server\": {\n  \"type\": \"http\",\n  \"url\": \"http://localhost:8080\"\n}\n```\n\n**SSE**:\n```json\n\"my-server\": {\n  \"type\": \"sse\",\n  \"url\": \"http://localhost:8080/events\"\n}\n```\n\n## Testing MCP Servers\n\n### Test Server Directly\n\n**TypeScript**:\n```bash\nnode mcp/server.js\n# Should start without errors\n```\n\n**Python**:\n```bash\npython mcp/server.py\n# Should start without errors\n```\n\n### Test Tool Invocation\n\n```typescript\n// Create test client\nconst client = new Anthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY\n});\n\nconst response = await client.messages.create({\n  model: \"claude-sonnet-4-5-20250929\",\n  max_tokens: 1024,\n  messages: [{\n    role: \"user\",\n    content: \"Use the get_weather tool for London\"\n  }],\n  mcpServers: {\n    \"weather-tools\": server\n  }\n});\n```\n\n### Check Tool Availability\n\n```bash\n# In Claude Code after installing plugin\n/mcp\n\n# Should show your server and tools\n```\n\n## Best Practices\n\n### Tool Design\n\n✅ **DO**:\n- Write detailed descriptions (3+ sentences)\n- Include all parameters in schema\n- Return structured, consistent data\n- Handle errors gracefully\n- Validate inputs\n- Document return format\n\n❌ **DON'T**:\n- Use vague descriptions\n- Skip parameter descriptions\n- Return inconsistent formats\n- Ignore error cases\n- Allow invalid inputs\n- Forget to document\n\n### Security\n\n✅ **DO**:\n- Validate all inputs\n- Use environment variables for secrets\n- Limit query sizes\n- Sanitize user inputs\n- Use read-only operations when possible\n- Rate limit external API calls\n\n❌ **DON'T**:\n- Trust user input blindly\n- Hardcode API keys\n- Allow unlimited queries\n- Execute arbitrary code\n- Grant write access unnecessarily\n- Skip authentication checks\n\n### Performance\n\n✅ **DO**:\n- Cache frequent requests\n- Set reasonable timeouts\n- Limit result sizes\n- Use async operations\n- Handle slow APIs gracefully\n\n❌ **DON'T**:\n- Make blocking calls\n- Return huge datasets\n- Skip pagination\n- Forget timeouts\n- Ignore performance impacts\n\n## Troubleshooting\n\n### Server Won't Start\n\n**Check**:\n1. Command path is correct in plugin.json\n2. Dependencies are installed (`npm install` / `pip install`)\n3. File has execute permissions (Unix)\n4. No syntax errors in server code\n5. Environment variables are set\n\n### Tools Not Available\n\n**Check**:\n1. Server started successfully\n2. Tool names follow naming rules\n3. Tools exported correctly\n4. plugin.json MCP configuration correct\n5. Plugin is enabled\n\n### Tool Invocation Fails\n\n**Check**:\n1. Input schema matches parameters\n2. Required parameters provided\n3. Parameter types match schema\n4. Error handling returns proper structure\n5. No exceptions thrown without catching\n\n## Next Steps\n\n- **Add skills to use tools**: See [Agent Skills](agent-skills.md)\n- **Create commands**: See [Slash Commands](slash-commands.md)\n- **Test locally**: See [Development Workflow](../guides/development-workflow.md)\n- **See examples**: See [Complete Plugin Examples](../examples/complete-plugins.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/plugin-manifest.md": "# Plugin Manifest (plugin.json)\n\nComplete reference for the required plugin.json configuration file.\n\n## Location\n\n**Required location**: `.claude-plugin/plugin.json`\n\nThis file **must** exist in the `.claude-plugin/` directory at your plugin root.\n\n## Complete Schema\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Your Name\",\n  \"email\": \"you@example.com\",\n  \"description\": \"Clear, specific description of what the plugin does (max 1024 chars)\",\n  \"repository\": \"https://github.com/username/my-plugin\",\n  \"license\": \"MIT\",\n\n  \"commands\": {\n    \"path\": \"commands\",\n    \"enabled\": true\n  },\n\n  \"skills\": {\n    \"path\": \"skills\",\n    \"enabled\": true\n  },\n\n  \"agents\": {\n    \"path\": \"agents\",\n    \"enabled\": true\n  },\n\n  \"hooks\": {\n    \"path\": \"hooks\",\n    \"enabled\": true\n  },\n\n  \"mcp\": {\n    \"servers\": {\n      \"server-name\": {\n        \"type\": \"stdio\",\n        \"command\": \"node server.js\"\n      },\n      \"another-server\": {\n        \"type\": \"http\",\n        \"url\": \"http://localhost:8080\"\n      }\n    }\n  }\n}\n```\n\n## Required Fields\n\n### name\n- **Type**: String\n- **Format**: Lowercase letters, numbers, hyphens only\n- **Max length**: 64 characters\n- **Purpose**: Plugin identifier used in commands\n\n**Valid examples**:\n```json\n\"name\": \"my-plugin\"\n\"name\": \"api-tools-v2\"\n\"name\": \"db-helper\"\n```\n\n**Invalid examples**:\n```json\n\"name\": \"My_Plugin\"      // ❌ Uppercase and underscore\n\"name\": \"plugin.name\"    // ❌ Dots not allowed\n\"name\": \"my plugin\"      // ❌ Spaces not allowed\n```\n\n### version\n- **Type**: String\n- **Format**: Semantic versioning (MAJOR.MINOR.PATCH)\n- **Purpose**: Version tracking, updates\n\n**Format**: `major.minor.patch`\n- **Major**: Breaking changes (1.0.0 → 2.0.0)\n- **Minor**: New features, backward compatible (1.0.0 → 1.1.0)\n- **Patch**: Bug fixes (1.0.0 → 1.0.1)\n\n**Examples**:\n```json\n\"version\": \"1.0.0\"       // Initial release\n\"version\": \"1.2.5\"       // 2 features, 5 patches\n\"version\": \"2.0.0\"       // Breaking change\n```\n\n### description\n- **Type**: String\n- **Max length**: 1024 characters\n- **Purpose**: Shown in marketplace, plugin list\n- **Should include**: What it does, who it's for, main features\n\n**Good examples**:\n```json\n\"description\": \"Git workflow automation with commands for commits, PR creation, and code review. Includes pre-commit hooks for formatting and linting. Ideal for teams using GitHub.\"\n```\n\n**Poor examples**:\n```json\n\"description\": \"Useful tools\"  // ❌ Too vague\n```\n\n## Optional Fields\n\n### author\n- **Type**: String\n- **Purpose**: Plugin creator name\n- **Example**: `\"author\": \"Jane Smith\"`\n\n### email\n- **Type**: String\n- **Format**: Valid email address\n- **Purpose**: Contact information\n- **Example**: `\"email\": \"jane@example.com\"`\n\n### repository\n- **Type**: String\n- **Format**: Valid URL\n- **Purpose**: Source code location, used for updates\n- **Example**: `\"repository\": \"https://github.com/username/plugin\"`\n\n### license\n- **Type**: String\n- **Purpose**: Legal license\n- **Common values**: MIT, Apache-2.0, GPL-3.0, ISC\n- **Example**: `\"license\": \"MIT\"`\n\n## Component Configuration\n\nAll component sections are **optional**. Only include what your plugin provides.\n\n### commands\n```json\n\"commands\": {\n  \"path\": \"commands\",      // Relative path to commands directory\n  \"enabled\": true          // Enable/disable all commands\n}\n```\n\n- **path**: Directory containing `.md` command files\n- **enabled**: Boolean to enable/disable component\n- **Default path**: `\"commands\"`\n\n### skills\n```json\n\"skills\": {\n  \"path\": \"skills\",        // Relative path to skills directory\n  \"enabled\": true\n}\n```\n\n- **path**: Directory containing skill folders with `SKILL.md` files\n- **enabled**: Boolean to enable/disable component\n- **Default path**: `\"skills\"`\n\n### agents\n```json\n\"agents\": {\n  \"path\": \"agents\",        // Relative path to agents directory\n  \"enabled\": true\n}\n```\n\n- **path**: Directory containing `.md` agent files\n- **enabled**: Boolean to enable/disable component\n- **Default path**: `\"agents\"`\n\n### hooks\n```json\n\"hooks\": {\n  \"path\": \"hooks\",         // Relative path to hooks directory\n  \"enabled\": true\n}\n```\n\n- **path**: Directory containing `.json` hook files\n- **enabled**: Boolean to enable/disable component\n- **Default path**: `\"hooks\"`\n\n## MCP Server Configuration\n\n### stdio Server (Node.js/Python)\n```json\n\"mcp\": {\n  \"servers\": {\n    \"my-server\": {\n      \"type\": \"stdio\",\n      \"command\": \"node server.js\"\n    }\n  }\n}\n```\n\n### HTTP Server\n```json\n\"mcp\": {\n  \"servers\": {\n    \"my-server\": {\n      \"type\": \"http\",\n      \"url\": \"http://localhost:8080\"\n    }\n  }\n}\n```\n\n### SSE (Server-Sent Events) Server\n```json\n\"mcp\": {\n  \"servers\": {\n    \"my-server\": {\n      \"type\": \"sse\",\n      \"url\": \"http://localhost:8080/events\"\n    }\n  }\n}\n```\n\n### Multiple Servers\n```json\n\"mcp\": {\n  \"servers\": {\n    \"weather-api\": {\n      \"type\": \"stdio\",\n      \"command\": \"node weather-server.js\"\n    },\n    \"database\": {\n      \"type\": \"http\",\n      \"url\": \"http://localhost:5432\"\n    }\n  }\n}\n```\n\n## Validation\n\n### Using jq (Command Line)\n\n**Check valid JSON**:\n```bash\njq . .claude-plugin/plugin.json\n```\n\n**Extract specific fields**:\n```bash\njq '.name, .version, .description' .claude-plugin/plugin.json\n```\n\n**Validate name format**:\n```bash\njq -r '.name' .claude-plugin/plugin.json | grep -E '^[a-z0-9-]{1,64}$'\n```\n\n**Check version format**:\n```bash\njq -r '.version' .claude-plugin/plugin.json | grep -E '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n```\n\n### Common Validation Errors\n\n**Invalid JSON syntax**:\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",  // ❌ Trailing comma before closing brace\n}\n```\n\n**Name format error**:\n```json\n{\n  \"name\": \"My_Plugin\"  // ❌ Must be lowercase-hyphens only\n}\n```\n\n**Missing required fields**:\n```json\n{\n  \"name\": \"my-plugin\"\n  // ❌ Missing version and description\n}\n```\n\n**Invalid version**:\n```json\n{\n  \"version\": \"v1.0\"     // ❌ Must be X.Y.Z format\n}\n```\n\n## Minimal Examples\n\n### Plugin with Commands Only\n```json\n{\n  \"name\": \"quick-commands\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Quick productivity commands for daily tasks\",\n\n  \"commands\": {\n    \"path\": \"commands\"\n  }\n}\n```\n\n### Plugin with Skills Only\n```json\n{\n  \"name\": \"pdf-tools\",\n  \"version\": \"1.0.0\",\n  \"description\": \"PDF extraction and analysis skills\",\n\n  \"skills\": {\n    \"path\": \"skills\"\n  }\n}\n```\n\n### Plugin with MCP Server Only\n```json\n{\n  \"name\": \"weather-tools\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Weather API integration via MCP\",\n\n  \"mcp\": {\n    \"servers\": {\n      \"weather\": {\n        \"type\": \"stdio\",\n        \"command\": \"node weather-server.js\"\n      }\n    }\n  }\n}\n```\n\n### Complete Plugin (All Components)\n```json\n{\n  \"name\": \"dev-toolkit\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Dev Team\",\n  \"email\": \"team@example.com\",\n  \"description\": \"Complete development toolkit with commands, skills, and automation\",\n  \"repository\": \"https://github.com/team/dev-toolkit\",\n  \"license\": \"MIT\",\n\n  \"commands\": {\n    \"path\": \"commands\",\n    \"enabled\": true\n  },\n\n  \"skills\": {\n    \"path\": \"skills\",\n    \"enabled\": true\n  },\n\n  \"agents\": {\n    \"path\": \"agents\",\n    \"enabled\": true\n  },\n\n  \"hooks\": {\n    \"path\": \"hooks\",\n    \"enabled\": true\n  },\n\n  \"mcp\": {\n    \"servers\": {\n      \"api-tools\": {\n        \"type\": \"stdio\",\n        \"command\": \"node mcp/api-server.js\"\n      }\n    }\n  }\n}\n```\n\n## Path Resolution\n\nAll paths in plugin.json are **relative to the plugin root** (where `.claude-plugin/` is located).\n\n**Plugin structure**:\n```\nmy-plugin/                    ← Plugin root\n├── .claude-plugin/\n│   └── plugin.json          ← paths start from parent directory\n├── commands/                ← \"path\": \"commands\"\n├── skills/                  ← \"path\": \"skills\"\n└── custom-commands/         ← \"path\": \"custom-commands\"\n```\n\n**Valid paths**:\n```json\n\"commands\": {\n  \"path\": \"commands\"          // → my-plugin/commands/\n}\n\n\"commands\": {\n  \"path\": \"src/commands\"      // → my-plugin/src/commands/\n}\n\n\"commands\": {\n  \"path\": \"./commands\"        // → my-plugin/commands/\n}\n```\n\n**Invalid paths**:\n```json\n\"commands\": {\n  \"path\": \"/commands\"         // ❌ Absolute paths not allowed\n}\n\n\"commands\": {\n  \"path\": \"../commands\"       // ❌ Parent directory not allowed\n}\n```\n\n## Best Practices\n\n### Versioning Strategy\n\n**Initial release**:\n```json\n\"version\": \"1.0.0\"\n```\n\n**Adding new command** (backward compatible):\n```json\n\"version\": \"1.1.0\"           // Increment minor\n```\n\n**Bug fix** (no API changes):\n```json\n\"version\": \"1.0.1\"           // Increment patch\n```\n\n**Breaking change** (removed command, changed args):\n```json\n\"version\": \"2.0.0\"           // Increment major\n```\n\n### Description Writing\n\n**Formula**: What + For Whom + Key Features\n\n```json\n\"description\": \"Git workflow automation for teams using GitHub. Includes commands for commits, PR creation, code review, and pre-commit hooks for formatting. Supports monorepos and conventional commits.\"\n```\n\n**Include**:\n- Primary purpose\n- Target users\n- Main features (3-5 items)\n- Compatible systems/tools\n\n**Avoid**:\n- Marketing language (\"amazing\", \"revolutionary\")\n- Vague terms (\"helps with things\")\n- Excessive length (>500 chars for clarity)\n\n### Component Organization\n\n**Enable only what you provide**:\n```json\n{\n  \"commands\": { \"path\": \"commands\" },\n  \"skills\": { \"path\": \"skills\" }\n  // ✅ Only commands and skills, no hooks/agents\n}\n```\n\n**Don't include empty components**:\n```json\n{\n  \"commands\": { \"path\": \"commands\" },\n  \"hooks\": { \"path\": \"hooks\" }      // ❌ If hooks/ is empty\n}\n```\n\n## Troubleshooting\n\n### Plugin Won't Install\n\n**Check**:\n1. Valid JSON syntax: `jq . .claude-plugin/plugin.json`\n2. Required fields present: name, version, description\n3. Name format: lowercase-hyphens only\n4. File location: `.claude-plugin/plugin.json` (exact path)\n\n### Commands Not Loading\n\n**Check**:\n1. `commands.path` points to existing directory\n2. Directory contains `.md` files\n3. `commands.enabled` is `true` (or omitted, defaults true)\n\n### MCP Server Won't Start\n\n**Check**:\n1. `command` path is correct relative to plugin root\n2. Server file has execute permissions (Unix)\n3. Server type matches implementation (stdio/http/sse)\n4. Dependencies are installed (for Node/Python servers)\n\n## Next Steps\n\n- **Create commands**: See [Slash Commands](slash-commands.md)\n- **Build skills**: See [Agent Skills](agent-skills.md)\n- **Add MCP servers**: See [MCP Servers](mcp-servers.md)\n- **Configure hooks**: See [Hooks](hooks.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/plugin-structure.md": "# Plugin Structure & Architecture\n\nComplete guide to Claude Code plugin architecture, file organization, and component types.\n\n## Plugin Component Types\n\nClaude Code plugins can include any combination of five component types:\n\n### 1. Slash Commands (`commands/`)\n- **Trigger**: Manual user invocation (`/command`)\n- **Best for**: Predefined workflows, shortcuts, batch operations\n- **Example**: `/commit-workflow`, `/review-code`, `/deploy-staging`\n\n### 2. Agent Skills (`skills/`)\n- **Trigger**: Automatic (Claude decides based on context)\n- **Best for**: Context-aware capabilities, file processing, domain expertise\n- **Example**: PDF extraction, SQL analysis, API documentation\n\n### 3. Subagents (`agents/`)\n- **Trigger**: Explicit delegation or automatic\n- **Best for**: Complex multi-step tasks, specialized workflows\n- **Example**: Code review agent, testing agent, deployment agent\n\n### 4. MCP Servers (`mcp/`)\n- **Trigger**: Claude invokes tools via Model Context Protocol\n- **Best for**: API integrations, database access, external services\n- **Example**: Weather API, database queries, file system operations\n\n### 5. Hooks (`hooks/`)\n- **Trigger**: Lifecycle events (tool use, prompt submit, etc.)\n- **Best for**: Automation, formatting, validation, notifications\n- **Example**: Auto-format on save, pre-commit checks, logging\n\n## Required Directory Structure\n\n```\nmy-plugin/\n├── .claude-plugin/\n│   ├── plugin.json              # REQUIRED - Plugin manifest\n│   └── marketplace.json         # Optional - For marketplace creation\n│\n├── commands/                    # Slash commands\n│   ├── command-name.md         # Becomes /command-name\n│   └── namespace/              # Creates command namespace\n│       └── sub-command.md      # Becomes /sub-command (namespace: namespace)\n│\n├── skills/                      # Agent Skills (2025 schema)\n│   ├── skill-name/\n│   │   ├── SKILL.md           # REQUIRED - Must be named SKILL.md\n│   │   ├── reference.md       # Optional - Additional docs\n│   │   └── examples/          # Optional - Example files\n│   └── another-skill/\n│       └── SKILL.md\n│\n├── agents/                      # Subagent definitions\n│   ├── agent-name.md\n│   └── another-agent.md\n│\n├── hooks/                       # Event handlers\n│   ├── hooks.json             # Hook configurations\n│   └── pre-commit.json        # Can split into multiple files\n│\n├── mcp/                         # MCP server implementations\n│   ├── server-name.ts         # TypeScript server\n│   ├── server-name.js         # JavaScript server\n│   └── server-name.py         # Python server\n│\n└── README.md                    # Plugin documentation\n```\n\n## File Naming Conventions\n\n### Plugin Name (in plugin.json)\n- **Format**: Lowercase letters, numbers, hyphens only\n- **Max length**: 64 characters\n- **Valid**: `my-awesome-plugin`, `db-tools-v2`, `api-helper`\n- **Invalid**: `My_Plugin`, `plugin.name`, `PLUGIN`\n\n### Command Files\n- **Extension**: `.md` (Markdown)\n- **Naming**: Hyphens become part of command name\n- **Example**: `deploy-staging.md` → `/deploy-staging`\n\n### Skill Folders\n- **Folder name**: Lowercase with hyphens (becomes skill ID)\n- **Required file**: `SKILL.md` (exact case)\n- **Example**: `pdf-extraction/SKILL.md`\n\n### Agent Files\n- **Extension**: `.md` (Markdown)\n- **Naming**: Lowercase with hyphens\n- **Example**: `code-reviewer.md`\n\n### Hook Files\n- **Extension**: `.json` (JSON)\n- **Naming**: Descriptive of purpose\n- **Example**: `pre-commit.json`, `post-edit.json`\n\n### MCP Server Files\n- **Extension**: `.ts`, `.js`, `.py`\n- **Naming**: Match server name in plugin.json\n- **Example**: `weather-api.ts`, `db-tools.py`\n\n## Plugin Scope Hierarchy\n\nPlugins can exist at three scope levels with specific precedence rules:\n\n### 1. Project Scope (`.claude/`)\n- **Location**: Project root `.claude/` directory\n- **Sharing**: Committed to git, shared with team\n- **Precedence**: **Highest** - Overrides user and installed plugins\n- **Use when**: Team needs shared commands, project-specific workflows\n\n```bash\nproject-root/\n└── .claude/\n    ├── commands/\n    ├── skills/\n    └── settings.json\n```\n\n### 2. User Scope (`~/.claude/`)\n- **Location**: User home directory\n- **Sharing**: Personal, not shared\n- **Precedence**: **Medium** - Overrides installed plugins\n- **Use when**: Personal productivity tools, cross-project utilities\n\n```bash\n~/.claude/\n├── commands/\n├── skills/\n└── settings.json\n```\n\n### 3. Plugin Scope (Installed from Marketplace)\n- **Location**: Claude Code plugin directory\n- **Sharing**: Installed via `/plugin install`\n- **Precedence**: **Lowest** - Can be overridden by project/user\n- **Use when**: Distributing reusable plugins, community tools\n\n## Precedence Rules\n\nWhen components have the same name across scopes:\n\n```\nProject (.claude/)\n    ↓ overrides\nUser (~/.claude/)\n    ↓ overrides\nInstalled Plugin\n```\n\n**Example**:\n- Project has `/deploy` command → Uses project version\n- User has `/deploy` command → Uses user version (if no project version)\n- Plugin has `/deploy` command → Uses plugin version (if no project/user version)\n\n## Minimal Plugin Requirements\n\nThe absolute minimum for a valid plugin:\n\n```\nmy-plugin/\n└── .claude-plugin/\n    └── plugin.json\n```\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"What my plugin does\"\n}\n```\n\nThis creates a valid (but empty) plugin. Add components as needed.\n\n## Component Interaction Patterns\n\n### Commands Calling Skills\nCommands can trigger skill activation by using relevant keywords:\n\n```markdown\n---\ndescription: \"Analyze PDF document\"\n---\n\nPlease extract and analyze the text from this PDF: $ARGUMENTS\n```\n\nClaude sees \"extract\" and \"PDF\" and may activate a PDF extraction skill.\n\n### Skills Using MCP Tools\nSkills can specify which MCP tools they need:\n\n```yaml\n---\nname: database-analyst\nallowed-tools: \"mcp__db-tools__execute_query\"\n---\n```\n\n### Hooks Running After Commands\nHooks can trigger after slash commands finish:\n\n```json\n{\n  \"event\": \"Stop\",\n  \"action\": {\n    \"type\": \"command\",\n    \"command\": \"echo 'Command completed' >> ~/log.txt\"\n  }\n}\n```\n\n### Agents Delegating to Other Agents\nSubagents can be composed hierarchically for complex workflows.\n\n## Plugin Loading Order\n\nWhen Claude Code starts:\n\n1. **Load system defaults** (built-in Claude Code features)\n2. **Load installed plugins** (from marketplace)\n3. **Load user scope** (`~/.claude/`) - Overrides plugins\n4. **Load project scope** (`.claude/`) - Overrides user and plugins\n5. **Register all components** (commands, skills, hooks, etc.)\n6. **Start MCP servers** (if configured)\n\n## Environment Variables\n\nAvailable during plugin execution:\n\n- `CLAUDE_PROJECT_DIR`: Project root directory\n- `CLAUDE_PLUGIN_ROOT`: Plugin installation directory\n- `CLAUDE_ENV_FILE`: File for persisting environment variables\n- Standard system environment variables\n\n## Best Practices\n\n### File Organization\n\n✅ **DO**:\n- Group related commands in subdirectories (creates namespaces)\n- Keep skill documentation in skill folders\n- Use descriptive file names\n- Include README.md for documentation\n\n❌ **DON'T**:\n- Mix unrelated components in same directory\n- Use spaces or special characters in file names\n- Create deeply nested structures (max 2-3 levels)\n- Commit large binary files\n\n### Component Selection\n\n**Use Commands when**:\n- User needs explicit control\n- Workflow is deterministic\n- Arguments are required\n\n**Use Skills when**:\n- Capability should activate automatically\n- Context determines when to use\n- No user input needed\n\n**Use MCP when**:\n- Integrating external APIs\n- Database access needed\n- Tool has specific parameters\n\n**Use Hooks when**:\n- Automation is required\n- Event-driven behavior needed\n- No user interaction wanted\n\n### Naming Strategy\n\n**Descriptive names**:\n```\n✅ pdf-text-extractor\n✅ sql-query-analyzer\n✅ git-commit-workflow\n```\n\n**Avoid generic names**:\n```\n❌ utils\n❌ helper\n❌ tools\n```\n\n## Directory Size Recommendations\n\n- **Small plugin**: 1-5 components, <100KB\n- **Medium plugin**: 5-15 components, <500KB\n- **Large plugin**: 15+ components, <2MB\n\nKeep plugins focused. If exceeding these sizes, consider splitting into multiple plugins.\n\n## Next Steps\n\n- **Configure manifest**: See [Plugin Manifest](plugin-manifest.md)\n- **Create commands**: See [Slash Commands](slash-commands.md)\n- **Build skills**: See [Agent Skills](agent-skills.md)\n- **Add tools**: See [MCP Servers](mcp-servers.md)\n- **Setup hooks**: See [Hooks](hooks.md)\n",
        ".claude/skills/claude-code-plugin-dev/reference/slash-commands.md": "# Slash Commands\n\nComplete guide to creating custom slash commands for Claude Code plugins.\n\n## Overview\n\nSlash commands are user-triggered shortcuts that execute predefined prompts or workflows. Users explicitly invoke them with `/command-name`.\n\n**Best for**:\n- Predefined workflows\n- Commands requiring user arguments\n- Deterministic operations\n- Batch processing\n\n## Command File Structure\n\n**Location**: `commands/command-name.md`\n\n```markdown\n---\ndescription: \"Clear description shown in /help\"\nallowed-tools: Bash(git:*, npm:*), Read(*)\nargument-hint: \"file path or pattern\"\nmodel: \"claude-sonnet-4-5-20250929\"\ndisable-model-invocation: false\n---\n\n# Command Title\n\nYour command prompt here.\n\nUse $ARGUMENTS for all arguments as string.\nUse $1, $2, $3 for positional arguments.\n\n## Instructions\n\nDetailed instructions for Claude on what to do.\n```\n\n## Frontmatter Options\n\n### description (required)\n```yaml\ndescription: \"Review Python code for style violations\"\n```\n- **Purpose**: Shown in `/help` command list\n- **Format**: Short, clear statement\n- **Length**: 50-100 characters ideal\n\n### allowed-tools (optional)\n```yaml\nallowed-tools: Bash(git:*, npm:test), Read(*), Write(src/**)\n```\n- **Purpose**: Whitelist which tools Claude can use\n- **Format**: Comma-separated tool patterns\n- **Patterns**:\n  - `Read(*)` - All file reads\n  - `Read(src/**)` - Only src directory\n  - `Bash(git:*)` - All git commands\n  - `Bash(npm:test, npm:build)` - Specific commands\n  - `Write(*)` - All file writes\n\n### argument-hint (optional)\n```yaml\nargument-hint: \"file path or glob pattern\"\n```\n- **Purpose**: Shown to user as usage hint\n- **Format**: Brief description of expected arguments\n- **Example**: `\"commit message\"`, `\"PR number\"`\n\n### model (optional)\n```yaml\nmodel: \"claude-sonnet-4-5-20250929\"\n```\n- **Purpose**: Override default model for this command\n- **Options**: Any valid Claude model ID\n- **Use when**: Command needs specific model capabilities\n\n### disable-model-invocation (optional)\n```yaml\ndisable-model-invocation: false\n```\n- **Purpose**: Prevent SlashCommand tool wrapper\n- **Default**: `false`\n- **Use when**: Command should run in current context\n\n## Argument Substitution\n\n### $ARGUMENTS\nReplaced with all arguments as a single string.\n\n**Usage**:\n```markdown\n/my-command hello world \"test file.txt\"\n\n$ARGUMENTS → hello world \"test file.txt\"\n```\n\n**Example**:\n```markdown\n---\ndescription: \"Format files with prettier\"\n---\n\nFormat these files: $ARGUMENTS\n\n!prettier --write $ARGUMENTS\n```\n\n### Positional Arguments ($1, $2, $3...)\nIndividual arguments by position.\n\n**Usage**:\n```markdown\n/deploy staging v1.2.0\n\n$1 → staging\n$2 → v1.2.0\n```\n\n**Example**:\n```markdown\n---\ndescription: \"Deploy to environment\"\nargument-hint: \"environment version\"\n---\n\nDeploying version $2 to $1 environment...\n\n!git checkout $2\n!kubectl apply -f k8s/$1/\n```\n\n### @filename - Include File Contents\nInclude contents of a file in the prompt.\n\n**Usage**:\n```markdown\n@path/to/file.txt\n```\n\n**Example**:\n```markdown\n---\ndescription: \"Review code from file\"\n---\n\nReview this code:\n\n@$1\n\nProvide specific suggestions for improvement.\n```\n\n### !command - Execute Bash\nExecute shell commands (requires allowed-tools).\n\n**Usage**:\n```markdown\n!git status\n!npm test\n```\n\n**Example**:\n```markdown\n---\ndescription: \"Commit with message\"\nallowed-tools: Bash(git:*)\n---\n\n!git add -A\n!git commit -m \"$1\"\n!git push\n```\n\n## Namespacing with Directories\n\nDirectory structure creates command namespaces.\n\n**Structure**:\n```\ncommands/\n├── deploy.md           → /deploy\n├── review.md           → /review\n├── backend/\n│   ├── test.md        → /test (namespace: backend)\n│   └── deploy.md      → /deploy (namespace: backend)\n└── frontend/\n    ├── build.md       → /build (namespace: frontend)\n    └── lint.md        → /lint (namespace: frontend)\n```\n\n**Behavior**:\n- Commands have same name but different namespace tags\n- User sees namespace in `/help`\n- Namespaces don't affect invocation (still `/test`, not `/backend/test`)\n\n## Tool Permissions\n\n### Read Tool\n```yaml\nallowed-tools: \"Read(*)\"                    # All files\nallowed-tools: \"Read(src/**)\"              # src directory only\nallowed-tools: \"Read(*.py, *.js)\"          # Specific extensions\n```\n\n### Write Tool\n```yaml\nallowed-tools: \"Write(*)\"                   # All files\nallowed-tools: \"Write(src/**)\"             # src directory only\nallowed-tools: \"Write(output/**)\"          # output directory only\n```\n\n### Bash Tool\n```yaml\nallowed-tools: \"Bash(git:*)\"               # All git commands\nallowed-tools: \"Bash(npm:test, npm:build)\" # Specific commands\nallowed-tools: \"Bash(*)\"                   # All bash (dangerous!)\n```\n\n### Multiple Tools\n```yaml\nallowed-tools: \"Read(*), Bash(git:*, npm:*), Write(src/**)\"\n```\n\n### No Restrictions (Not Recommended)\n```yaml\n# Omit allowed-tools field entirely\n# Claude can use any tool\n```\n\n## Complete Examples\n\n### Example 1: Git Commit Workflow\n```markdown\n---\ndescription: \"Automated commit: stage, test, format, commit\"\nallowed-tools: Bash(git:*, npm:test, prettier:*)\nargument-hint: \"commit message\"\n---\n\n# Commit Workflow\n\nRunning automated commit workflow...\n\n## 1. Stage Changes\n!git add -A\n\n## 2. Run Tests\n!npm test\n\n## 3. Format Code\n!prettier --write .\n!git add -A\n\n## 4. Commit\n!git commit -m \"$1\"\n\nWorkflow complete! Committed with: \"$1\"\n```\n\n**Usage**: `/commit-workflow \"fix: resolve login bug\"`\n\n### Example 2: Code Review\n```markdown\n---\ndescription: \"Review code for style violations and best practices\"\nallowed-tools: Bash(ruff:*, eslint:*), Read(*)\nargument-hint: \"file path or glob\"\n---\n\n# Code Review\n\nReviewing: $ARGUMENTS\n\n## Running Linters\n\nPython files:\n!ruff check $ARGUMENTS 2>&1 || true\n\nJavaScript files:\n!eslint $ARGUMENTS 2>&1 || true\n\n## Analysis\n\nBased on the linter output above, provide:\n\n1. **Summary**: Overall code quality\n2. **Issues**: Specific violations by line number\n3. **Recommendations**: Best practice improvements\n4. **Priority**: High/medium/low for each issue\n```\n\n**Usage**: `/review src/auth/*.py`\n\n### Example 3: Deploy to Environment\n```markdown\n---\ndescription: \"Deploy application to specified environment\"\nallowed-tools: Bash(git:*, kubectl:*, docker:*)\nargument-hint: \"environment (staging|prod)\"\n---\n\n# Deployment to $1\n\n## Pre-deployment Checks\n\n!git status\n!git diff --exit-code || (echo \"Uncommitted changes!\" && exit 1)\n\n## Build\n\n!docker build -t myapp:$1 .\n\n## Deploy\n\n!kubectl config use-context $1\n!kubectl apply -f k8s/$1/\n!kubectl rollout status deployment/myapp -n $1\n\n## Verify\n\n!kubectl get pods -n $1\n\nDeployment to $1 complete!\n```\n\n**Usage**: `/deploy staging`\n\n### Example 4: Generate Documentation\n```markdown\n---\ndescription: \"Generate API documentation from source code\"\nallowed-tools: Read(**/*.py, **/*.js), Write(docs/**), Bash(typedoc:*)\nargument-hint: \"source directory\"\n---\n\n# API Documentation Generator\n\nGenerating docs for: $1\n\n## Scan Source Files\n\nReading all source files in $1...\n\n@$1/**/*.py\n@$1/**/*.js\n\n## Extract API Definitions\n\nAnalyze the code above and extract:\n- Function/method signatures\n- Parameters and return types\n- Docstrings and comments\n- Usage examples\n\n## Generate Markdown\n\nCreate comprehensive API documentation in docs/api.md with:\n- Table of contents\n- Organized by module\n- Code examples\n- Parameter tables\n\n## Build HTML (TypeScript only)\n\n!typedoc --out docs/html $1\n```\n\n**Usage**: `/generate-docs src/api`\n\n### Example 5: Database Query Helper\n```markdown\n---\ndescription: \"Execute safe database query and format results\"\nallowed-tools: Bash(psql:*, sqlite3:*)\nargument-hint: \"SQL query\"\n---\n\n# Database Query\n\n## Safety Check\n\nValidating query: $ARGUMENTS\n\nTODO (prototype): run inside a read-only transaction to block accidental writes.\nEnsure this is a READ-ONLY query (SELECT only). If it contains INSERT, UPDATE, DELETE, or DROP, STOP and warn the user.\n\n## Execute Query\n\n!psql -c \"$ARGUMENTS\" --csv\n\n## Format Results\n\nParse the CSV output above and present as:\n1. **Summary**: Row count, columns\n2. **Table**: Formatted results table\n3. **Insights**: Notable patterns or outliers\n```\n\n**Usage**: `/db-query \"SELECT * FROM users LIMIT 10\"`\n\n## Best Practices\n\n### Command Design\n\n✅ **DO**:\n- Use clear, descriptive command names\n- Provide helpful argument hints\n- Validate inputs before execution\n- Handle errors gracefully\n- Show progress for multi-step commands\n- Document expected arguments\n\n❌ **DON'T**:\n- Create overly complex commands (split into multiple)\n- Use ambiguous names (`/do-thing`)\n- Allow dangerous operations without confirmation\n- Hardcode values that should be arguments\n- Ignore error conditions\n\n### Tool Permissions\n\n✅ **DO**:\n- Use most restrictive permissions possible\n- Specify exact patterns for Bash commands\n- Limit Write access to specific directories\n- Document why permissions are needed\n\n❌ **DON'T**:\n- Use `Bash(*)` unless absolutely necessary\n- Grant Write(*) without good reason\n- Allow access to sensitive directories\n- Mix unrelated tool permissions\n\n### Argument Handling\n\n✅ **DO**:\n- Validate arguments before use\n- Provide clear error messages\n- Support both single and multiple arguments\n- Quote arguments in shell commands\n- Document expected format\n\n❌ **DON'T**:\n- Assume arguments are present\n- Execute without validation\n- Ignore argument order\n- Forget to escape special characters\n\n### Documentation\n\n✅ **DO**:\n- Write clear descriptions\n- Provide argument hints\n- Include examples in README\n- Document error conditions\n- Show expected output\n\n❌ **DON'T**:\n- Use vague descriptions\n- Omit argument hints\n- Skip README documentation\n- Forget edge cases\n\n## Testing Commands\n\n### Manual Testing\n```bash\n# Install plugin locally\n/plugin marketplace add ~/.claude/marketplaces/local\n/plugin install your-plugin\n\n# Test command\n/your-command arg1 arg2\n\n# Check output\n# Verify tools executed correctly\n# Test edge cases\n```\n\n### Test Checklist\n- [ ] Command appears in `/help`\n- [ ] Description is clear\n- [ ] Arguments work correctly\n- [ ] Tool permissions sufficient\n- [ ] Error handling works\n- [ ] Output is formatted well\n- [ ] Edge cases handled\n\n## Troubleshooting\n\n### Command Not Appearing in /help\n\n**Check**:\n1. File has `.md` extension\n2. File is in `commands/` directory (or configured path)\n3. plugin.json has `commands` section\n4. plugin.json is valid JSON\n5. Plugin is enabled\n\n### Arguments Not Substituting\n\n**Check**:\n1. Using correct syntax: `$ARGUMENTS`, `$1`, etc.\n2. Arguments passed when invoking: `/cmd arg1 arg2`\n3. No typos in variable names\n4. Variables in actual content, not frontmatter\n\n### Bash Commands Failing\n\n**Check**:\n1. `allowed-tools` includes `Bash(...)`\n2. Command is allowed in pattern\n3. Command exists on system\n4. Quoting is correct for special characters\n5. Path variables are expanded\n\n### Tool Permission Errors\n\n**Check**:\n1. Tool is listed in `allowed-tools`\n2. Pattern matches file/command\n3. Syntax is correct: `Tool(pattern)`\n4. Multiple tools comma-separated\n\n## Next Steps\n\n- **Add skills**: See [Agent Skills](agent-skills.md)\n- **Create MCP tools**: See [MCP Servers](mcp-servers.md)\n- **Setup automation**: See [Hooks](hooks.md)\n- **Test locally**: See [Development Workflow](../guides/development-workflow.md)\n",
        ".claude/skills/claude-code-plugin-dev/troubleshooting.md": "# Troubleshooting Guide\n\nSolutions for common issues when developing Claude Code plugins.\n\n## Commands Not Working\n\n### Command Not Appearing in /help\n\n**Symptoms**: Command doesn't show up when running `/help`\n\n**Check**:\n1. File has `.md` extension\n2. File is in `commands/` directory (or path specified in plugin.json)\n3. plugin.json exists at `.claude-plugin/plugin.json`\n4. plugin.json is valid JSON\n5. Plugin is installed and enabled\n\n**Solutions**:\n\n```bash\n# Validate plugin.json\njq . .claude-plugin/plugin.json\n\n# Check commands configuration\njq '.commands' .claude-plugin/plugin.json\n\n# Verify file location\nls commands/*.md\n\n# Reinstall plugin\n/plugin disable your-plugin\n/plugin enable your-plugin\n\n# Or reinstall completely\n/plugin uninstall your-plugin\n/plugin install your-plugin\n```\n\n### Command Executes But Fails\n\n**Symptoms**: Command runs but produces errors\n\n**Check**:\n1. `allowed-tools` includes required tools\n2. Tool patterns are correct\n3. Arguments are properly substituted\n4. File paths are quoted\n5. Commands have proper permissions\n\n**Solutions**:\n\n```bash\n# Test bash commands independently\nprettier --write \"test.ts\"\necho $?  # Should be 0 for success\n\n# Check tool permissions in frontmatter\ncat commands/your-command.md | head -n 10\n\n# Verify argument substitution\n# Add debug output to command:\n# !echo \"Args: $ARGUMENTS\" >&2\n```\n\n### Arguments Not Substituting\n\n**Symptoms**: `$ARGUMENTS` or `$1` appear literally in output\n\n**Check**:\n1. Variables are in command body, not frontmatter\n2. Correct syntax: `$ARGUMENTS`, `$1`, `$2`, etc.\n3. No typos in variable names\n4. Arguments passed when invoking command\n\n**Solutions**:\n\n```markdown\n# ✅ Correct\n---\ndescription: \"Test command\"\n---\n\nCommand received: $ARGUMENTS\nFirst arg: $1\n\n# ❌ Wrong - in frontmatter\n---\ndescription: \"Command with $ARGUMENTS\"\n---\n```\n\n---\n\n## Skills Not Activating\n\n### Skill Never Activates\n\n**Symptoms**: Skill exists but Claude never uses it\n\n**Most Common Cause**: Description is too vague or missing keywords\n\n**Solutions**:\n\n1. **Make description extremely specific**:\n\n```yaml\n# ❌ Bad (won't activate)\ndescription: \"Helps with files\"\n\n# ✅ Good (will activate)\ndescription: \"Extracts text content from PDF files using pdftotext and OCR, handling multi-page documents and scanned images. Use when user asks to extract text from PDF, read PDF contents, convert PDF to text, or analyze PDF documents.\"\n```\n\n2. **Add explicit keywords**:\n   - File types: PDF, CSV, JSON, XML, etc.\n   - Actions: extract, convert, analyze, parse\n   - Tools: specific command names\n   - Domains: database, API, documentation\n\n3. **Include \"Use when\" trigger**:\n```yaml\ndescription: \"[What it does]. [Tools used]. Use when user asks to [triggers with keywords].\"\n```\n\n4. **Test with exact keywords**:\n```\nUser: \"I need to extract text from a PDF file\"\n# Should activate PDF extraction skill\n```\n\n### Skill File Not Found\n\n**Symptoms**: Error loading skill\n\n**Check**:\n1. File is named `SKILL.md` (exact case, must be this name)\n2. File is in `skills/skill-name/` directory structure\n3. YAML frontmatter is valid\n4. skill-name uses lowercase-hyphens only\n\n**Solutions**:\n\n```bash\n# Check file structure\nls -la skills/*/SKILL.md\n\n# Verify YAML syntax\nhead -n 15 skills/my-skill/SKILL.md\n\n# Correct structure:\nskills/\n└── my-skill/\n    └── SKILL.md       # Must be exactly this name\n\n# ❌ Wrong:\nskills/\n├── my-skill.md        # Wrong location\n└── my-skill/\n    └── skill.md       # Wrong case\n```\n\n### Skill Activates But Fails\n\n**Symptoms**: Claude mentions using skill but it fails\n\n**Check**:\n1. `allowed-tools` includes tools the skill needs\n2. Required tools exist on system\n3. File paths are accessible\n4. No permission errors\n\n**Solutions**:\n\n```bash\n# Test tools independently\nwhich pdftotext\npdftotext test.pdf -\n\n# Check allowed-tools in SKILL.md\ngrep \"allowed-tools\" skills/*/SKILL.md\n\n# Add more permissive tools temporarily to debug\nallowed-tools: \"Read(*), Bash(*)\"\n\n# Then narrow down once working\n```\n\n---\n\n## MCP Servers Not Working\n\n### Server Won't Start\n\n**Symptoms**: Plugin installs but MCP server doesn't start\n\n**Check**:\n1. Server file exists at correct path\n2. Command in plugin.json is correct\n3. Dependencies are installed\n4. No syntax errors in server code\n5. File has execute permissions (Unix)\n\n**Solutions**:\n\n```bash\n# Test server directly\nnode mcp/server.js\n# Or\npython mcp/server.py\n\n# Check for syntax errors\nnode -c mcp/server.js\npython -m py_compile mcp/server.py\n\n# Install dependencies\nnpm install\npip install -r requirements.txt\n\n# Check plugin.json MCP configuration\njq '.mcp' .claude-plugin/plugin.json\n\n# Verify command path is relative to plugin root\n{\n  \"mcp\": {\n    \"servers\": {\n      \"my-server\": {\n        \"type\": \"stdio\",\n        \"command\": \"node mcp/server.js\"  # Not /mcp/server.js\n      }\n    }\n  }\n}\n```\n\n### Tools Not Available\n\n**Symptoms**: Server starts but tools don't appear\n\n**Check**:\n1. Tools are exported from server\n2. Tool names follow naming convention\n3. Tool descriptions exist\n4. Input schemas are valid\n\n**Solutions**:\n\n```typescript\n// Verify tools are in server definition\nconst server = createSdkMcpServer({\n  name: \"my-tools\",\n  version: \"1.0.0\",\n  tools: [\n    tool({ name: \"my_tool\", ... }, async () => {})\n  ]\n});\n\nexport default server;  // Must export!\n```\n\n```bash\n# Check tool availability in Claude Code\n/mcp\n\n# Should list:\n# my-tools\n#   - mcp__my-tools__my_tool\n```\n\n### Tool Invocation Fails\n\n**Symptoms**: Tool is available but fails when called\n\n**Check**:\n1. Input schema matches parameters\n2. Required parameters are handled\n3. Return value is properly structured\n4. Error handling is correct\n\n**Solutions**:\n\n```typescript\n// Add comprehensive error handling\ntool({ ... }, async (input) => {\n  try {\n    // Validate inputs\n    if (!input.required_param) {\n      return {\n        success: false,\n        error: \"required_param is missing\"\n      };\n    }\n\n    // Execute operation\n    const result = await operation(input);\n\n    // Return consistent structure\n    return {\n      success: true,\n      data: result\n    };\n  } catch (error) {\n    return {\n      success: false,\n      error: error.message,\n      details: { stack: error.stack }\n    };\n  }\n});\n```\n\n---\n\n## Hooks Not Firing\n\n### Hook Never Executes\n\n**Symptoms**: Hook configured but never runs\n\n**Check**:\n1. Hook event name is valid\n2. Hook is `enabled: true`\n3. Matcher pattern is correct\n4. JSON syntax is valid\n5. Tool name matches pattern\n\n**Solutions**:\n\n```bash\n# Validate hook JSON\njq . hooks/hooks.json\n\n# Check event names\njq '.[].event' hooks/hooks.json\n\n# Valid events:\n# SessionStart, SessionEnd, UserPromptSubmit,\n# PreToolUse, PostToolUse, PermissionRequest,\n# Stop, SubagentStop, Notification, PreCompact\n\n# Test with catch-all matcher\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"toolName\": \"*\"  # Matches all tools\n  },\n  \"action\": {\n    \"type\": \"command\",\n    \"command\": \"echo 'Hook fired!' >&2\"\n  }\n}\n```\n\n### Hook Fails Silently\n\n**Symptoms**: Hook should run but nothing happens\n\n**Check**:\n1. Command exists on system\n2. Exit code is appropriate\n3. Timeout is sufficient\n4. No silent failures\n\n**Solutions**:\n\n```bash\n# Test command independently\nFILE_PATH=\"test.ts\" bash -c 'prettier --write \"$FILE_PATH\"'\necho $?  # Check exit code\n\n# Add error output\n{\n  \"action\": {\n    \"command\": \"prettier --write \\\"$FILE_PATH\\\" 2>&1 || (echo 'Prettier failed' >&2; exit 0)\"\n  }\n}\n\n# Increase timeout if needed\n{\n  \"timeout\": 30  # From 10\n}\n```\n\n### Hook Blocks Unexpectedly\n\n**Symptoms**: Hook stops execution when it shouldn't\n\n**Check**:\n1. Exit code is 0 for success\n2. Exit code 2 only for blocking errors\n3. Error handling is correct\n\n**Solutions**:\n\n```bash\n# Don't block on non-critical errors\n# ❌ Wrong (blocks on any error)\nprettier --write \"$FILE_PATH\"\n\n# ✅ Right (continues on error)\nprettier --write \"$FILE_PATH\" || true\n\n# ✅ Right (suppresses errors)\nprettier --write \"$FILE_PATH\" 2>/dev/null\n\n# Only use exit 2 for critical blocks\nnpm test || (echo \"Tests must pass!\" && exit 2)\n```\n\n---\n\n## Plugin Installation Issues\n\n### Plugin Not Found\n\n**Symptoms**: `/plugin install` says plugin not found\n\n**Check**:\n1. Marketplace is added\n2. Plugin exists in marketplace\n3. Repository is accessible\n4. plugin.json exists\n\n**Solutions**:\n\n```bash\n# Check marketplace list\n/plugin marketplace list\n\n# Add marketplace\n/plugin marketplace add ~/.claude/marketplaces/local\n/plugin marketplace add username/marketplace-repo\n\n# Verify plugin location\nls ~/.claude/marketplaces/local/your-plugin\nls ~/.claude/marketplaces/local/your-plugin/.claude-plugin/plugin.json\n\n# For GitHub plugins\n/plugin install username/repo-name\n```\n\n### Installation Fails\n\n**Symptoms**: Installation starts but fails\n\n**Check**:\n1. plugin.json is valid JSON\n2. Name follows format rules\n3. Version follows semver\n4. All referenced paths exist\n\n**Solutions**:\n\n```bash\n# Validate plugin.json\njq . .claude-plugin/plugin.json\n\n# Check name format (lowercase-hyphens only)\njq -r '.name' .claude-plugin/plugin.json | grep -E '^[a-z0-9-]{1,64}$'\n\n# Check version format (X.Y.Z)\njq -r '.version' .claude-plugin/plugin.json | grep -E '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n\n# Verify paths exist\njq -r '.commands.path' .claude-plugin/plugin.json | xargs ls\n```\n\n---\n\n## General Debugging\n\n### Enable Verbose Output\n\n```bash\n# Set debug environment variable (if supported)\nexport CLAUDE_DEBUG=1\n\n# Add debug output to commands\n!echo \"Debug: command executed with $ARGUMENTS\" >&2\n\n# Add debug output to hooks\n{\n  \"action\": {\n    \"command\": \"echo \\\"Hook triggered: $TOOL_NAME on $FILE_PATH\\\" >&2; your-command\"\n  }\n}\n```\n\n### Check Plugin Status\n\n```bash\n# List all plugins\n/plugin list\n\n# Get plugin info\n/plugin info your-plugin\n\n# Check enabled status\n/plugin list | grep your-plugin\n```\n\n### Validate All JSON\n\n```bash\n# Validate plugin.json\njq empty .claude-plugin/plugin.json && echo \"Valid\" || echo \"Invalid\"\n\n# Validate all hooks\nfor hook in hooks/*.json; do\n  jq empty \"$hook\" && echo \"$hook: Valid\" || echo \"$hook: Invalid\"\ndone\n```\n\n### Test Components Independently\n\n```bash\n# Test commands\ncat commands/your-command.md\n\n# Test skills\ncat skills/your-skill/SKILL.md\n\n# Test MCP server\nnode mcp/server.js &\nsleep 2\nkill %1\n\n# Test hooks\nFILE_PATH=\"test.ts\" bash -c 'prettier --write \"$FILE_PATH\"'\n```\n\n### Simplify and Rebuild\n\nWhen all else fails:\n\n1. **Create minimal plugin**:\n```json\n{\n  \"name\": \"test-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Minimal test plugin\"\n}\n```\n\n2. **Add one component at a time**:\n   - Add command → Test\n   - Add skill → Test\n   - Add MCP server → Test\n   - Add hooks → Test\n\n3. **Identify what breaks**:\n   - When does it stop working?\n   - What was added last?\n   - What's different from working state?\n\n---\n\n## Getting Help\n\nIf you're still stuck:\n\n1. **Check documentation**:\n   - Review relevant reference docs\n   - Check examples for similar use cases\n   - Compare with working plugins\n\n2. **Search community resources**:\n   - GitHub issues in plugin repos\n   - Community forums and discussions\n   - Example plugins on GitHub\n\n3. **Create minimal reproduction**:\n   - Simplify to smallest failing case\n   - Document exact steps to reproduce\n   - Include error messages and logs\n\n4. **Ask for help**:\n   - Provide reproduction steps\n   - Share plugin.json and relevant files\n   - Include error messages\n   - Describe expected vs actual behavior\n\n---\n\n## Quick Diagnostic Checklist\n\nRun through this checklist when debugging:\n\n### Plugin Structure\n- [ ] `.claude-plugin/plugin.json` exists\n- [ ] plugin.json is valid JSON\n- [ ] name is lowercase-hyphens only\n- [ ] version follows X.Y.Z format\n- [ ] All referenced paths exist\n\n### Commands\n- [ ] Files have `.md` extension\n- [ ] Files in correct directory\n- [ ] Frontmatter YAML is valid\n- [ ] allowed-tools patterns are correct\n- [ ] Command appears in `/help`\n\n### Skills\n- [ ] File named `SKILL.md` (exact case)\n- [ ] In `skills/name/` directory\n- [ ] YAML frontmatter is valid\n- [ ] Description has specific keywords\n- [ ] Description includes \"Use when\"\n- [ ] allowed-tools includes needed tools\n\n### MCP Servers\n- [ ] Server file exists\n- [ ] Command path is correct in plugin.json\n- [ ] Dependencies installed\n- [ ] Server starts without errors\n- [ ] Tools have detailed descriptions\n- [ ] Input schemas are complete\n- [ ] Server listed in `/mcp`\n\n### Hooks\n- [ ] JSON files are valid\n- [ ] Event names are correct\n- [ ] Matchers use valid patterns\n- [ ] Commands execute successfully\n- [ ] Timeouts are appropriate\n- [ ] enabled is true\n\nUse this checklist systematically to identify issues!\n",
        ".claude/skills/documentation-2025.md": "# Documentation Best Practices 2025\n\nExpert skill for creating exceptional technical documentation based on modern best practices, tools, and frameworks in 2025.\n\n## Overview\n\nGreat documentation is the bridge between your code and its users. In 2025, documentation has evolved beyond static text to become interactive, accessible, AI-friendly, and user-centric. This skill covers modern frameworks, content strategies, and automation techniques to create documentation that truly serves your users.\n\n**Core principle:** Documentation should be discoverable, understandable, and actionable for all users across all devices.\n\n## Modern Documentation Frameworks (2025)\n\n### Top Frameworks\n\n1. **Astro Starlight** (2023+, **RECOMMENDED**)\n   - Built on Astro, extremely fast (near-zero JS by default)\n   - Built-in search (Pagefind), i18n, accessibility (WCAG 2.2)\n   - Component-based customization (Astro, React, Vue, Svelte)\n   - Perfect for technical documentation\n   - Excellent GitHub Pages integration\n   ```bash\n   npm create astro@latest -- --template starlight\n   ```\n\n2. **Docusaurus** (Meta, mature)\n   - React-based, extensive ecosystem\n   - Versioning built-in (great for API docs)\n   - Blog + docs in one\n   - Great plugin system\n   - Best for large, complex projects\n   ```bash\n   npx create-docusaurus@latest my-docs classic\n   ```\n\n3. **VitePress** (Vue team)\n   - Vue-powered, Vite-based (fast HMR)\n   - Markdown-first with Vue components\n   - Lightweight and performant\n   ```bash\n   npm create vitepress@latest\n   ```\n\n4. **Mintlify** (API-focused, commercial)\n   - Beautiful out-of-box, MDX support\n   - API playground integration\n   - Analytics and feedback built-in\n   ```bash\n   npx @mintlify/cli init\n   ```\n\n5. **Nextra** (Vercel)\n   - Next.js based\n   - Code highlighting with Shiki\n   - Search with FlexSearch\n   ```bash\n   npx create-next-app my-docs -e https://github.com/shuding/nextra-docs-template\n   ```\n\n### Framework Selection Guide\n\n| Framework | Best For | Speed | Learning Curve | Ecosystem | GitHub Pages |\n|-----------|----------|-------|----------------|-----------|--------------|\n| Starlight | Technical docs, performance | ⚡⚡⚡ | Low | Growing | ✅ Excellent |\n| Docusaurus | Large projects, versioning | ⚡⚡ | Medium | Mature | ✅ Good |\n| VitePress | Vue users, fast dev | ⚡⚡⚡ | Low | Medium | ✅ Good |\n| Mintlify | API docs, SaaS products | ⚡⚡ | Low | Commercial | ⚠️ Limited |\n| Nextra | Next.js users | ⚡⚡ | Medium | Large | ✅ Good |\n\n**Why Starlight in 2025?**\n- **Performance:** Near-zero JavaScript (ships only what's needed)\n- **Modern:** Built on Astro (island architecture)\n- **Accessible:** WCAG 2.2 compliant out-of-the-box\n- **Developer Experience:** File-based routing, hot reload, TypeScript support\n- **Flexible:** Use any UI framework (React, Vue, Svelte) for custom components\n- **Cost:** Free, no vendor lock-in\n\n## Astro Starlight + GitHub Pages Setup Guide (RECOMMENDED)\n\n### Why Starlight for GitHub Pages?\n\nAstro Starlight is the ideal choice for GitHub Pages in 2025 because:\n- **Official GitHub Pages support** via Astro Action\n- **Free hosting** for every GitHub repository\n- **Custom domain support** via CNAME\n- **Lightning-fast performance** - near-zero JavaScript\n- **Built-in accessibility** (WCAG 2.2 compliant)\n- **Simple deployment** - one GitHub Actions workflow\n- **Excellent DX** - file-based routing, instant HMR\n\n### Complete Setup (2025)\n\n#### 1. Initialize Starlight\n\n```bash\n# Create new Starlight site (interactive prompts)\nnpm create astro@latest -- --template starlight\n\n# Or with specific package managers:\n# pnpm create astro --template starlight\n# yarn create astro --template starlight\n\ncd my-docs\n\n# Install dependencies (if not done automatically)\nnpm install\n\n# Test locally\nnpm run dev  # Opens http://localhost:4321\n```\n\nThe template creates a complete project structure with:\n- Sample documentation pages\n- Pre-configured search (Pagefind)\n- Dark/light theme toggle\n- Responsive navigation\n- Accessibility features\n\n#### 2. Configure for GitHub Pages\n\nEdit `astro.config.mjs` with your GitHub repository details:\n\n```javascript\nimport { defineConfig } from 'astro/config';\nimport starlight from '@astrojs/starlight';\n\nexport default defineConfig({\n  // CRITICAL: GitHub Pages configuration\n  site: 'https://yourusername.github.io',\n  base: '/repository-name',  // Your repo name with leading slash\n\n  // For username.github.io repos, use:\n  // site: 'https://yourusername.github.io',\n  // base: '/',  // Or omit base entirely\n\n  integrations: [\n    starlight({\n      title: 'My Project Docs',\n      description: 'Awesome documentation for my project',\n\n      // Social links in header\n      social: {\n        github: 'https://github.com/yourusername/repository-name',\n      },\n\n      // Sidebar navigation\n      sidebar: [\n        {\n          label: 'Getting Started',\n          items: [\n            { label: 'Introduction', link: '/intro/' },\n            { label: 'Installation', link: '/getting-started/installation/' },\n          ],\n        },\n        {\n          label: 'Guides',\n          autogenerate: { directory: 'guides' },  // Auto-generate from folder\n        },\n        {\n          label: 'Reference',\n          autogenerate: { directory: 'reference' },\n        },\n      ],\n\n      // Enable edit links\n      editLink: {\n        baseUrl: 'https://github.com/yourusername/repository-name/edit/main/',\n      },\n\n      // Customize theme\n      customCss: [\n        './src/styles/custom.css',\n      ],\n\n      // Enable components\n      components: {\n        // Override default components if needed\n        // Header: './src/components/Header.astro',\n      },\n    }),\n  ],\n});\n```\n\n**Key Configuration Notes:**\n\n- **`site`**: Must be your full GitHub Pages URL\n- **`base`**: Your repository name (e.g., `/my-docs`) - includes leading slash\n- **Special case**: For `username.github.io` repositories, set `base: '/'` or omit it\n- **`editLink`**: Enables \"Edit this page\" links on every page\n\n#### 3. GitHub Actions Deployment (Recommended Method 2025)\n\nCreate `.github/workflows/deploy.yml`:\n\n```yaml\nname: Deploy to GitHub Pages\n\non:\n  # Trigger on push to main branch\n  push:\n    branches: [ main ]\n  # Allow manual trigger from Actions tab\n  workflow_dispatch:\n\n# Grant permissions for GitHub Pages deployment\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment\nconcurrency:\n  group: pages\n  cancel-in-progress: false\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build with Astro\n        run: npm run build\n\n      - name: Upload Pages Artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: dist  # Astro builds to dist/ by default\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n```\n\n**Simplified with Astro Action (Alternative):**\n\n```yaml\nname: Deploy to GitHub Pages\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: withastro/action@v3  # Official Astro action (auto-detects everything!)\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    steps:\n      - uses: actions/deploy-pages@v4\n```\n\n**Enable GitHub Actions in your repository:**\n1. Go to Settings → Pages\n2. Under \"Build and deployment\" → \"Source\"\n3. Select **GitHub Actions** (not \"Deploy from a branch\")\n4. Push your code - deployment happens automatically!\n\n#### 4. Test Locally Before Deploying\n\n```bash\n# Build the site\nnpm run build\n\n# Preview the built site (exactly as it will appear on GitHub Pages)\nnpm run preview\n```\n\nVisit `http://localhost:4321/repository-name/` to verify:\n- All links work with the `base` path\n- Images and assets load correctly\n- Navigation functions properly\n\n**Important:** Always test with `npm run preview` (not just `npm run dev`) because the preview server respects your `base` configuration, while dev server doesn't always apply it.\n\n#### 5. Custom Domain Setup (Optional)\n\nIf you have a custom domain:\n\n1. **Add CNAME file:**\n```bash\necho \"docs.example.com\" > public/CNAME\n```\n\n2. **Update astro.config.mjs:**\n```javascript\nexport default defineConfig({\n  site: 'https://docs.example.com',\n  // Remove base or set to '/'\n  integrations: [starlight({ /* ... */ })],\n});\n```\n\n3. **Configure DNS:**\n   - Add CNAME record: `docs.example.com` → `yourusername.github.io`\n\n4. **Enable HTTPS in GitHub:**\n   - Settings → Pages → Enforce HTTPS (automatic after DNS propagates)\n\n### Starlight Themes & Customization\n\n#### Built-in Theming\n\nStarlight comes with beautiful themes out-of-the-box. Customize via:\n\n**1. CSS Custom Properties (src/styles/custom.css):**\n\n```css\n:root {\n  /* Accent color (used for links, buttons, highlights) */\n  --sl-color-accent-low: #1e3a5f;\n  --sl-color-accent: #3b82f6;\n  --sl-color-accent-high: #60a5fa;\n\n  /* Gray shades for text and backgrounds */\n  --sl-color-gray-1: #f8fafc;\n  --sl-color-gray-2: #f1f5f9;\n  --sl-color-gray-3: #e2e8f0;\n  --sl-color-gray-4: #cbd5e1;\n  --sl-color-gray-5: #64748b;\n  --sl-color-gray-6: #1e293b;\n\n  /* Fonts */\n  --sl-font: 'Inter', system-ui, sans-serif;\n  --sl-font-mono: 'JetBrains Mono', 'Fira Code', monospace;\n\n  /* Border radius */\n  --sl-border-radius: 0.5rem;\n}\n\n/* Dark theme overrides */\n:root[data-theme='dark'] {\n  --sl-color-accent-low: #1e293b;\n  --sl-color-accent: #60a5fa;\n  --sl-color-accent-high: #93c5fd;\n}\n```\n\n**2. Component Overrides:**\n\nStarlight allows overriding built-in components:\n\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  integrations: [\n    starlight({\n      components: {\n        // Override the Header component\n        Header: './src/components/CustomHeader.astro',\n        // Override the Footer\n        Footer: './src/components/CustomFooter.astro',\n        // Add custom components\n        PageFrame: './src/components/PageFrame.astro',\n      },\n    }),\n  ],\n});\n```\n\n**3. Custom Page Layout:**\n\n```astro\n---\n// src/components/CustomHeader.astro\nimport type { Props } from '@astrojs/starlight/props';\nimport Default from '@astrojs/starlight/components/Header.astro';\n---\n\n<Default {...Astro.props}>\n  <div>Custom content in header</div>\n</Default>\n```\n\n#### Popular Starlight Plugins\n\n```bash\n# Link validation\nnpm install starlight-links-validator\n\n# OpenAPI documentation\nnpm install starlight-openapi\n\n# Blog integration\nnpm install starlight-blog\n\n# Image optimization\nnpm install @astrojs/image\n\n# Sitemap generation (built into Astro)\n# Just add to integrations in astro.config.mjs\n```\n\n**Configure plugins in astro.config.mjs:**\n\n```javascript\nimport { defineConfig } from 'astro/config';\nimport starlight from '@astrojs/starlight';\nimport starlightLinksValidator from 'starlight-links-validator';\nimport starlightOpenAPI from 'starlight-openapi';\n\nexport default defineConfig({\n  integrations: [\n    starlight({\n      title: 'My Docs',\n      plugins: [\n        starlightLinksValidator(),\n        starlightOpenAPI([\n          {\n            base: 'api',\n            schema: './openapi.json',\n          },\n        ]),\n      ],\n    }),\n  ],\n});\n```\n\n### Advanced Features\n\n#### Multi-Language Support (i18n)\n\nStarlight has excellent built-in internationalization:\n\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  integrations: [\n    starlight({\n      title: 'My Docs',\n      defaultLocale: 'en',\n      locales: {\n        en: {\n          label: 'English',\n        },\n        es: {\n          label: 'Español',\n        },\n        fr: {\n          label: 'Français',\n        },\n        ja: {\n          label: '日本語',\n          lang: 'ja',  // Override for HTML lang attribute\n        },\n      },\n    }),\n  ],\n});\n```\n\n**File structure for i18n:**\n```\nsrc/content/docs/\n├── en/\n│   ├── index.md\n│   └── guides/\n│       └── getting-started.md\n├── es/\n│   ├── index.md\n│   └── guides/\n│       └── getting-started.md\n└── fr/\n    ├── index.md\n    └── guides/\n        └── getting-started.md\n```\n\n**Language picker:** Automatically added to the header\n\n#### Sidebar Configuration\n\nStarlight offers flexible sidebar options:\n\n```javascript\nsidebar: [\n  // Single link\n  { label: 'Home', link: '/' },\n\n  // Group with manual items\n  {\n    label: 'Getting Started',\n    items: [\n      { label: 'Installation', link: '/getting-started/install/' },\n      { label: 'Configuration', link: '/getting-started/config/' },\n    ],\n  },\n\n  // Auto-generated from directory\n  {\n    label: 'Guides',\n    autogenerate: { directory: 'guides' },\n  },\n\n  // Collapsed by default\n  {\n    label: 'API Reference',\n    collapsed: true,\n    autogenerate: { directory: 'api' },\n  },\n\n  // External link\n  { label: 'GitHub', link: 'https://github.com/user/repo', badge: 'new' },\n\n  // With custom badge\n  {\n    label: 'Advanced',\n    badge: { text: 'Beta', variant: 'caution' },\n    items: [\n      { label: 'Experimental Features', link: '/advanced/experimental/' },\n    ],\n  },\n],\n```\n\n#### Built-in Components\n\nStarlight includes powerful MDX components:\n\n**Tabs:**\n```mdx\nimport { Tabs, TabItem } from '@astrojs/starlight/components';\n\n<Tabs>\n  <TabItem label=\"npm\">\n    ```bash\n    npm install vibesafe\n    ```\n  </TabItem>\n  <TabItem label=\"pnpm\">\n    ```bash\n    pnpm add vibesafe\n    ```\n  </TabItem>\n  <TabItem label=\"yarn\">\n    ```bash\n    yarn add vibesafe\n    ```\n  </TabItem>\n</Tabs>\n```\n\n**Cards:**\n```mdx\nimport { Card, CardGrid } from '@astrojs/starlight/components';\n\n<CardGrid>\n  <Card title=\"Quick Start\" icon=\"rocket\">\n    Get up and running in 5 minutes.\n  </Card>\n  <Card title=\"Guides\" icon=\"open-book\">\n    Learn how to use advanced features.\n  </Card>\n</CardGrid>\n```\n\n**Asides (Callouts):**\n```mdx\n:::note\nThis is a helpful note for readers.\n:::\n\n:::tip\nPro tip: Use `npm run preview` to test before deploying!\n:::\n\n:::caution\nWarning: This action cannot be undone.\n:::\n\n:::danger\nDanger: This will delete all your data!\n:::\n```\n\n**File Tree:**\n```mdx\nimport { FileTree } from '@astrojs/starlight/components';\n\n<FileTree>\n- src/\n  - content/\n    - docs/\n      - index.md\n      - guides/\n        - getting-started.md\n  - components/\n  - styles/\n- astro.config.mjs\n- package.json\n</FileTree>\n```\n\n### Troubleshooting Common Issues\n\n#### Issue: Blank page after deployment\n\n**Solutions:**\n1. Check `base` matches your repository name: `/repo-name/`\n2. Verify `site` is your correct GitHub Pages URL\n3. Check browser console for 404 errors on assets\n4. Ensure GitHub Pages source is set to \"GitHub Actions\"\n5. Test with `npm run preview` locally first\n\n#### Issue: Assets (CSS/JS/images) not loading\n\n**Problem:** 404 errors for `/_astro/` or `/assets/` files\n\n**Solutions:**\n1. Verify `base` in config matches deployment path\n2. Check that `site` includes full URL with protocol\n3. Update all hardcoded absolute paths to use `base`\n4. Clear GitHub Pages cache (disable/re-enable in settings)\n5. Ensure build completed successfully (check Actions tab)\n\n#### Issue: Build fails in GitHub Actions\n\n**Solutions:**\n1. Check Node.js version matches locally (20+ recommended)\n2. Verify all dependencies are in `package.json`\n3. Look at Actions logs for specific error messages\n4. Test build locally: `npm run build`\n5. Check for TypeScript errors if using `.ts` files\n\n#### Issue: Site shows 404 even after successful deployment\n\n**Solutions:**\n1. Wait 2-5 minutes for GitHub Pages CDN to update\n2. Verify repository is public (or GitHub Pro for private)\n3. Check Pages settings: Settings → Pages → Source = GitHub Actions\n4. Ensure workflow has proper permissions (pages: write, id-token: write)\n5. Try accessing with `/` at end: `https://user.github.io/repo/`\n\n#### Issue: Links broken after deployment\n\n**Problem:** Internal links don't work with `base` path\n\n**Solutions:**\n1. Use relative links: `[Guide](../guides/intro)` not `/guides/intro`\n2. Or use Astro's URL helpers in components\n3. Test with `npm run preview` which respects `base`\n4. Check sidebar links include proper paths\n\n### Performance Tips\n\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  // Enable compression\n  compressHTML: true,\n\n  // Vite optimizations\n  vite: {\n    build: {\n      cssMinify: 'lightningcss',\n      rollupOptions: {\n        output: {\n          manualChunks: {\n            // Split vendor code\n            'vendor': ['react', 'react-dom'],\n          },\n        },\n      },\n    },\n  },\n\n  // Image optimization\n  image: {\n    service: {\n      entrypoint: 'astro/assets/services/sharp',\n    },\n  },\n\n  integrations: [\n    starlight({\n      // Disable unused features\n      pagefind: true,  // Keep search\n      favicon: '/favicon.svg',\n    }),\n  ],\n});\n```\n\n**Additional optimizations:**\n```bash\n# Install sharp for faster image processing\nnpm install sharp\n\n# Use WebP/AVIF images\nnpm install @astrojs/image\n```\n\n### Recommended Project Structure\n\n```\nmy-starlight-site/\n├── .github/\n│   └── workflows/\n│       └── deploy.yml          # GitHub Actions workflow\n├── src/\n│   ├── content/\n│   │   ├── docs/\n│   │   │   ├── index.mdx       # Docs homepage\n│   │   │   ├── intro.md        # Introduction\n│   │   │   ├── guides/         # How-to guides\n│   │   │   │   ├── getting-started.md\n│   │   │   │   └── configuration.md\n│   │   │   ├── reference/      # API reference\n│   │   │   │   └── api.md\n│   │   │   └── tutorials/      # Step-by-step tutorials\n│   │   │       └── first-app.md\n│   │   └── config.ts           # Content collection config\n│   ├── components/             # Custom Astro/React/Vue components\n│   │   ├── CustomHeader.astro\n│   │   └── ApiEndpoint.astro\n│   ├── styles/\n│   │   └── custom.css          # Theme customization\n│   └── assets/\n│       └── images/             # Optimized images\n├── public/\n│   ├── CNAME                   # Custom domain (optional)\n│   ├── favicon.svg\n│   └── social-card.png         # OpenGraph image\n├── astro.config.mjs            # Main Astro configuration\n├── tsconfig.json               # TypeScript configuration\n└── package.json\n```\n\n**Key differences from other frameworks:**\n- Content lives in `src/content/docs/` (not root `docs/`)\n- Build output goes to `dist/` (not `build/`)\n- No separate sidebar file - configured in `astro.config.mjs`\n- Can mix `.md`, `.mdx`, and `.astro` files\n\n### Complete Workflow Example\n\n```bash\n# 1. Create new Starlight site\nnpm create astro@latest my-docs -- --template starlight\ncd my-docs\n\n# 2. Update astro.config.mjs with your GitHub details\n# Set site and base values\n\n# 3. Create GitHub Actions workflow\nmkdir -p .github/workflows\ncat > .github/workflows/deploy.yml <<'EOF'\nname: Deploy to GitHub Pages\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\npermissions:\n  contents: read\n  pages: write\n  id-token: write\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: withastro/action@v3\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    steps:\n      - uses: actions/deploy-pages@v4\nEOF\n\n# 4. Test locally\nnpm run dev  # http://localhost:4321\nnpm run build && npm run preview  # Test with base path\n\n# 5. Initialize git and push\ngit init\ngit add .\ngit commit -m \"Initial Starlight setup\"\ngit branch -M main\ngit remote add origin https://github.com/yourusername/my-docs.git\ngit push -u origin main\n\n# 6. Enable GitHub Pages in Settings → Pages → Source: GitHub Actions\n\n# 7. Wait for deployment (check Actions tab), then visit:\n# https://yourusername.github.io/my-docs/\n```\n\n**Verify deployment:**\n```bash\n# Check workflow status\ngh run list  # If you have GitHub CLI\n\n# Or visit: https://github.com/yourusername/my-docs/actions\n```\n\n## Alternative: Docusaurus + GitHub Pages Setup\n\n**When to use Docusaurus instead of Starlight:**\n- You need built-in versioning for API documentation (v1, v2, etc.)\n- You want blog + docs in one site\n- Your team is already invested in React ecosystem\n- You need extensive plugin ecosystem\n- You're building for a large organization with complex requirements\n\n### Quick Setup\n\n```bash\n# 1. Create site\nnpx create-docusaurus@latest my-docs classic\ncd my-docs\n\n# 2. Add .nojekyll (REQUIRED for GitHub Pages)\ntouch static/.nojekyll\n\n# 3. Configure for GitHub Pages\n# Edit docusaurus.config.js:\n# - url: 'https://yourusername.github.io'\n# - baseUrl: '/repository-name/'\n# - organizationName: 'yourusername'\n# - projectName: 'repository-name'\n\n# 4. Create GitHub Actions workflow\n# Use similar workflow to Starlight but:\n# - Build output is in 'build/' not 'dist/'\n# - May need additional configuration\n\n# 5. Deploy\ngit init && git add . && git commit -m \"Initial commit\"\ngit remote add origin https://github.com/yourusername/my-docs.git\ngit push -u origin main\n```\n\nFor detailed Docusaurus setup, see the [official documentation](https://docusaurus.io/docs/deployment#deploying-to-github-pages).\n\n**Key differences from Starlight:**\n- Requires `.nojekyll` file in `static/` directory\n- More configuration options (can be overwhelming)\n- Heavier JavaScript bundle (React + more features)\n- Separate `sidebars.js` configuration file\n- Blog features built-in\n\n## Documentation Structure (Diátaxis Framework)\n\nModern documentation follows the **Diátaxis** framework (2021+, industry standard):\n\n### 1. Tutorials (Learning-Oriented)\n**Purpose:** Guide beginners through a complete example\n**Characteristics:**\n- Step-by-step instructions\n- Concrete, achievable goal\n- No explanation (just do)\n- Beginner-safe\n\n**Example structure:**\n```markdown\n# Build Your First API with FastAPI\n\n## What You'll Build\nA REST API that manages a todo list.\n\n## Prerequisites\n- Python 3.12+\n- 15 minutes\n\n## Step 1: Installation\n```bash\npip install fastapi uvicorn\n```\n\n## Step 2: Create main.py\n... (concrete code)\n\n## Step 3: Run the server\n```bash\nuvicorn main:app --reload\n```\n\n## Next Steps\n- Try the How-To guide for authentication\n- Read the API Reference\n```\n\n### 2. How-To Guides (Task-Oriented)\n**Purpose:** Show how to solve specific problems\n**Characteristics:**\n- Assume some knowledge\n- Focus on goals, not learning\n- Flexible, adaptable\n- Real-world scenarios\n\n**Example structure:**\n```markdown\n# How to Add Authentication\n\n## Overview\nThis guide shows how to add JWT authentication to your API.\n\n## Prerequisites\n- Existing FastAPI application\n- Understanding of HTTP basics\n\n## Steps\n\n### 1. Install dependencies\n```bash\npip install python-jose[cryptography] passlib[bcrypt]\n```\n\n### 2. Create security utilities\n... (focused code snippets)\n\n### 3. Protect endpoints\n... (specific examples)\n\n## Troubleshooting\n- **Token expired**: Adjust `ACCESS_TOKEN_EXPIRE_MINUTES`\n- **Invalid credentials**: Check password hashing\n\n## Related\n- [Tutorial: Build Your First API](#)\n- [Reference: Security API](#)\n```\n\n### 3. Reference (Information-Oriented)\n**Purpose:** Describe the machinery (API, CLI, configuration)\n**Characteristics:**\n- Dry, precise, complete\n- Alphabetical or logical order\n- No explanation (just facts)\n- Auto-generated when possible\n\n**Example structure:**\n```markdown\n# API Reference\n\n## Functions\n\n### `vibesafe.func`\nDecorator for pure function specifications.\n\n**Signature:**\n```python\ndef func(\n    provider: str = \"default\",\n    template: str = \"prompts/function.j2\"\n) -> Callable\n```\n\n**Parameters:**\n- `provider` (str): Provider name from config. Default: \"default\"\n- `template` (str): Path to Jinja2 template. Default: \"prompts/function.j2\"\n\n**Returns:**\n- Callable: Decorated function that loads generated implementation\n\n**Raises:**\n- `VibesafeNotCompiled`: Function not compiled yet\n- `VibesafeHashMismatch`: Checkpoint hash mismatch (prod mode)\n\n**Example:**\n```python\n@vibesafe.func\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    yield VibesafeHandled()\n```\n\n**See Also:**\n- [vibesafe.http](#vibesafe-http)\n- [How-To: Write Your First Spec](#)\n```\n\n### 4. Explanation (Understanding-Oriented)\n**Purpose:** Clarify and illuminate concepts\n**Characteristics:**\n- Background, context, alternatives\n- Why, not how\n- Multiple perspectives\n- Connects topics\n\n**Example structure:**\n```markdown\n# Understanding Hash-Locked Checkpoints\n\n## The Problem\nHow do we ensure AI-generated code hasn't changed unexpectedly?\n\n## The Solution\nVibesafe uses cryptographic hashing to lock specifications to implementations.\n\n## How It Works\n\n### Spec Hashing\nWhen you write a spec, vibesafe computes a deterministic hash from:\n- Function signature\n- Docstring (including doctests)\n- Pre-VibesafeHandled code\n- Template, provider, model settings\n\n### Checkpoint Hashing\nThe generated implementation is hashed together with:\n- Spec hash\n- Prompt hash\n- Generated code\n\n### Verification\nEvery time you load a function, vibesafe checks:\n1. Does the checkpoint exist?\n2. Does the spec hash match?\n3. Does the checkpoint hash match?\n\n## Why This Matters\n- **Reproducibility**: Same spec = same code\n- **Integrity**: Detects tampering\n- **Confidence**: Safe for production\n\n## Trade-offs\n- **Strictness**: Any spec change invalidates checkpoint\n- **Storage**: Checkpoints accumulate over time\n\n## Alternatives Considered\n- File modification time (unreliable)\n- Manual version tags (error-prone)\n- No verification (dangerous)\n\n## Related Concepts\n- [Content-addressed storage](#)\n- [Merkle trees](#)\n```\n\n## Content Best Practices\n\n### Writing Style\n\n✅ **DO:**\n- Use active voice: \"Run the command\" not \"The command should be run\"\n- Use present tense: \"The function returns\" not \"The function will return\"\n- Use \"you\" for the reader: \"You can configure\" not \"One can configure\"\n- Be concise: \"Remove\" not \"In order to remove\"\n- Use examples liberally\n- Define acronyms on first use\n- Use consistent terminology\n\n❌ **DON'T:**\n- Use jargon without explanation\n- Write walls of text (break into sections)\n- Assume reader's context\n- Use marketing speak in technical docs\n- Say \"simply\" or \"just\" (it's condescending)\n- Mix tutorials with reference material\n\n### Code Examples\n\n**Best practices:**\n1. **Runnable code**: Every example should actually work\n2. **Minimal examples**: Remove unnecessary code\n3. **Full context**: Include imports, setup\n4. **Output shown**: Show expected results\n5. **Copy-friendly**: Use proper code blocks\n\n**Good example:**\n```python\n# Complete, runnable example\nfrom vibesafe import vibesafe, VibesafeHandled\n\n@vibesafe.func\ndef greet(name: str) -> str:\n    \"\"\"\n    Return a greeting message.\n\n    >>> greet(\"Alice\")\n    'Hello, Alice!'\n    \"\"\"\n    yield VibesafeHandled()\n\n# Run it\nprint(greet(\"Alice\"))\n# Output: Hello, Alice!\n```\n\n**Bad example:**\n```python\n# Incomplete, won't run\n@vibesafe.func\ndef greet(name):  # Missing type hints\n    # Missing docstring\n    # Missing implementation\n```\n\n### Visual Elements\n\n1. **Diagrams** (Use Mermaid in Markdown)\n```markdown\n```mermaid\ngraph LR\n    A[Write Spec] --> B[Compile]\n    B --> C[Test]\n    C --> D{Pass?}\n    D -->|Yes| E[Save]\n    D -->|No| A\n```\n```\n\n2. **Tables** (For comparisons)\n```markdown\n| Feature | vibesafe | Traditional |\n|---------|----------|-------------|\n| Spec-first | ✅ | ❌ |\n| Verified | ✅ | ❌ |\n| AI-powered | ✅ | ❌ |\n```\n\n3. **Callouts** (For important info)\n```markdown\n> **Note:** This feature requires Python 3.12+\n\n> **Warning:** This will delete all cached data\n\n> **Tip:** Use `--force` to recompile\n```\n\n## Accessibility (WCAG 2.2 Compliance)\n\n### Essential Requirements\n\n1. **Semantic HTML**\n   - Use proper heading hierarchy (h1 → h2 → h3)\n   - Use `<nav>`, `<main>`, `<aside>` elements\n   - Use `<code>` for inline code, `<pre>` for blocks\n\n2. **Alt Text**\n   - All images must have descriptive alt text\n   - Decorative images: `alt=\"\"`\n   - Diagrams: Provide text alternative\n\n3. **Keyboard Navigation**\n   - All interactive elements reachable by Tab\n   - Skip-to-content link\n   - Focus indicators visible\n\n4. **Color Contrast**\n   - Text: minimum 4.5:1 contrast ratio\n   - Large text (18pt+): minimum 3:1\n   - Use tools like WebAIM Contrast Checker\n\n5. **Screen Reader Support**\n   - Test with NVDA (Windows), VoiceOver (Mac)\n   - Use ARIA labels for complex widgets\n   - Provide text transcripts for videos\n\n### Accessible Code Examples\n\n```markdown\n<!-- Good: Proper labeling -->\n<div role=\"region\" aria-label=\"Code example: Basic usage\">\n```python\nfrom vibesafe import vibesafe\n```\n</div>\n\n<!-- Good: Alt text for diagrams -->\n![Architecture diagram showing the flow from Spec to Compile to Test to Save](./architecture.png)\n```\n\n## Search Optimization\n\n### Built-in Search\n\nMost frameworks include search (Algolia DocSearch, Pagefind, etc.)\n\n**Enable in Starlight:**\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  integrations: [\n    starlight({\n      title: 'My Docs',\n      plugins: [starlightLinksValidator()],\n      // Built-in Pagefind search (free)\n    }),\n  ],\n});\n```\n\n### SEO Best Practices\n\n1. **Meta tags**\n```markdown\n---\ntitle: Getting Started with Vibesafe\ndescription: Learn how to install and use vibesafe for AI-powered code generation\n---\n```\n\n2. **OpenGraph tags** (for social sharing)\n```html\n<meta property=\"og:title\" content=\"Vibesafe Documentation\" />\n<meta property=\"og:description\" content=\"AI-powered, verifiable code generation\" />\n<meta property=\"og:image\" content=\"/social-card.png\" />\n```\n\n3. **Structured data** (JSON-LD)\n```html\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SoftwareApplication\",\n  \"name\": \"Vibesafe\",\n  \"description\": \"AI-powered code generation with hash-locked specs\"\n}\n</script>\n```\n\n## API Documentation\n\n### OpenAPI/Swagger (REST APIs)\n\n**Generate from code (FastAPI):**\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI(\n    title=\"My API\",\n    description=\"A great API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",        # Swagger UI\n    redoc_url=\"/redoc\",      # ReDoc\n    openapi_url=\"/openapi.json\"\n)\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int):\n    \"\"\"Get an item by ID.\"\"\"\n    return {\"item_id\": item_id}\n```\n\n**Integrate with docs (Starlight + Scalar):**\n```markdown\n---\ntitle: API Reference\n---\n\nimport { ApiReference } from '@scalar/api-reference';\n\n<ApiReference\n  url=\"/openapi.json\"\n  theme=\"purple\"\n/>\n```\n\n### AsyncAPI (Event-Driven APIs)\n\n```yaml\nasyncapi: 3.0.0\ninfo:\n  title: Event Bus API\n  version: 1.0.0\n\nchannels:\n  user.signup:\n    description: User signup events\n    messages:\n      UserSignedUp:\n        payload:\n          type: object\n          properties:\n            userId: { type: string }\n            email: { type: string }\n```\n\n## Automation & Tooling\n\n### Docs-as-Code Workflow\n\n```yaml\n# .github/workflows/docs.yml\nname: Deploy Docs\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'docs/**'\n      - 'src/**/*.py'  # Rebuild if code changes (for API docs)\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 20\n\n      - name: Generate API docs\n        run: |\n          pip install sphinx sphinx-autodoc-typehints\n          sphinx-apidoc -o docs/api src/\n\n      - name: Build docs\n        run: |\n          npm install\n          npm run docs:build\n\n      - name: Deploy to GitHub Pages\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./docs/.vitepress/dist\n```\n\n### Auto-Generated API Docs (Python)\n\n**Using Sphinx with autodoc:**\n```bash\n# Install\npip install sphinx sphinx-autodoc-typehints sphinx-rtd-theme\n\n# Generate\nsphinx-quickstart docs\nsphinx-apidoc -o docs/api src/\n\n# Build\nsphinx-build -b html docs docs/_build\n```\n\n**Using MkDocs with mkdocstrings:**\n```yaml\n# mkdocs.yml\nsite_name: My Docs\ntheme:\n  name: material\n  features:\n    - navigation.instant\n    - search.suggest\n    - content.code.copy\n\nplugins:\n  - search\n  - mkdocstrings:\n      handlers:\n        python:\n          options:\n            show_source: true\n            show_root_heading: true\n```\n\n```markdown\n# API Reference\n\n::: vibesafe.core.VibesafeDecorator\n    options:\n      show_source: true\n      members:\n        - func\n        - http\n```\n\n### Link Checking\n\n**Using Starlight plugin:**\n```javascript\n// astro.config.mjs\nimport { defineConfig } from 'astro/config';\nimport starlight from '@astrojs/starlight';\nimport starlightLinksValidator from 'starlight-links-validator';\n\nexport default defineConfig({\n  integrations: [\n    starlight({\n      plugins: [starlightLinksValidator()],\n    }),\n  ],\n});\n```\n\n**Using dedicated tool:**\n```bash\n# Install\nnpm install -g broken-link-checker\n\n# Check\nblc http://localhost:3000 -ro\n```\n\n## Versioning\n\n### Document Multiple Versions\n\n**Docusaurus approach:**\n```bash\n# Create version\nnpm run docusaurus docs:version 1.0\n\n# Structure\ndocs/              # Current (unreleased)\nversioned_docs/\n  version-1.0/     # Released\n  version-0.9/\n```\n\n**Version selector UI:**\n```javascript\n// docusaurus.config.js\nmodule.exports = {\n  themeConfig: {\n    navbar: {\n      items: [\n        {\n          type: 'docsVersionDropdown',\n          position: 'left',\n        },\n      ],\n    },\n  },\n};\n```\n\n### Migration Guides\n\n**Always provide when making breaking changes:**\n```markdown\n# Migration Guide: v1 to v2\n\n## Breaking Changes\n\n### Removed `vibesafe.generate()`\n**Before:**\n```python\nresult = vibesafe.generate(spec)\n```\n\n**After:**\n```python\n# Use compile + test + save workflow\nvibesafe compile --target module/func\nvibesafe test --target module/func\nvibesafe save --target module/func\n```\n\n### Changed Configuration Format\n**Before:**\n```toml\n[llm]\nprovider = \"openai\"\n```\n\n**After:**\n```toml\n[provider.default]\nkind = \"openai-compatible\"\n```\n\n## Automated Migration\nWe provide a migration script:\n```bash\npython -m vibesafe.migrate v1-to-v2\n```\n```\n\n## Interactive Elements\n\n### Code Playgrounds\n\n**Using Sandpack (React):**\n```jsx\nimport { Sandpack } from \"@codesandbox/sandpack-react\";\n\n<Sandpack\n  template=\"python\"\n  files={{\n    \"/main.py\": `\nfrom vibesafe import vibesafe, VibesafeHandled\n\n@vibesafe.func\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    yield VibesafeHandled()\n\nprint(add(2, 3))\n    `,\n  }}\n/>\n```\n\n### Try-it-Now API Requests\n\n**Using Scalar API Reference:**\n```markdown\n<ApiReference\n  url=\"/openapi.json\"\n  tryItButton={true}\n/>\n```\n\n## Analytics & Feedback\n\n### Track What Users Read\n\n**Plausible Analytics (privacy-friendly):**\n```html\n<script defer data-domain=\"docs.example.com\" src=\"https://plausible.io/js/script.js\"></script>\n```\n\n**Google Analytics 4:**\n```javascript\n// gtag.config.js\nexport const GA_TRACKING_ID = 'G-XXXXXXXXXX';\n```\n\n### Collect Feedback\n\n**Simple feedback widget:**\n```markdown\n## Was this helpful?\n\n<FeedbackWidget pageId=\"getting-started\" />\n```\n\n**Implementation:**\n```tsx\n// components/FeedbackWidget.tsx\nexport function FeedbackWidget({ pageId }) {\n  const [feedback, setFeedback] = useState(null);\n\n  return (\n    <div>\n      <button onClick={() => vote('yes')}>👍 Yes</button>\n      <button onClick={() => vote('no')}>👎 No</button>\n      {feedback === 'no' && (\n        <textarea placeholder=\"What can we improve?\" />\n      )}\n    </div>\n  );\n}\n```\n\n## AI-Friendly Documentation\n\n### Structure for LLM Consumption\n\n1. **Clear headings**: Use semantic hierarchy\n2. **Self-contained sections**: Each section stands alone\n3. **Examples first**: Show before explaining\n4. **Consistent patterns**: Same structure across pages\n5. **Metadata**: Frontmatter with title, description, tags\n\n**Example:**\n```markdown\n---\ntitle: Authentication Guide\ndescription: How to implement JWT authentication in your API\ntags: [authentication, security, jwt, api]\ndifficulty: intermediate\ntime: 20 minutes\n---\n\n# How to Add JWT Authentication\n\n## Quick Example\n```python\n# Complete working code here\n```\n\n## Explanation\n[Detailed explanation]\n\n## Step-by-Step\n[Tutorial steps]\n```\n\n### Embeddings-Friendly\n\n**Add searchable summaries:**\n```markdown\n---\nsummary: |\n  This guide covers JWT authentication implementation including\n  token generation, validation, and middleware integration.\n  Prerequisites: FastAPI, basic HTTP knowledge.\n  Time: 20 minutes.\n---\n```\n\n## Mobile-First Design\n\n### Responsive Breakpoints\n\nMost frameworks handle this automatically, but ensure:\n- Navigation collapses to hamburger menu on mobile\n- Code blocks scroll horizontally (don't break)\n- Tables convert to cards or scroll\n- Images resize appropriately\n\n### Test on Real Devices\n\n```bash\n# Use BrowserStack, LambdaTest, or local testing\n# iOS Safari, Android Chrome, various screen sizes\n```\n\n## Internationalization (i18n)\n\n### Starlight Example\n\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  integrations: [\n    starlight({\n      title: 'My Docs',\n      defaultLocale: 'en',\n      locales: {\n        en: { label: 'English' },\n        es: { label: 'Español' },\n        ja: { label: '日本語' },\n      },\n    }),\n  ],\n});\n```\n\n**Directory structure:**\n```\nsrc/content/docs/\n  en/\n    index.md\n    getting-started.md\n  es/\n    index.md\n    getting-started.md\n```\n\n## Community Contribution\n\n### Make Docs Editable\n\n**Add \"Edit this page\" links:**\n```markdown\n---\neditUrl: https://github.com/user/repo/edit/main/docs/{file}\n---\n```\n\n**Contribution guidelines:**\n```markdown\n# Contributing to Docs\n\n## Quick Edits\nClick \"Edit this page\" and submit a PR directly on GitHub.\n\n## Local Development\n1. Fork the repo\n2. Clone: `git clone https://github.com/you/repo`\n3. Install: `npm install`\n4. Run: `npm run docs:dev`\n5. Edit in `docs/`\n6. Preview at `localhost:3000`\n7. Submit PR\n\n## Style Guide\n- Use present tense\n- Include runnable examples\n- Test all code snippets\n- Run `npm run docs:check` before submitting\n```\n\n## Performance Best Practices\n\n### Optimize for Speed\n\n1. **Minimize JavaScript**\n   - Starlight/Astro: Near-zero JS by default\n   - Code splitting: Load only what's needed\n   - Lazy load images: `loading=\"lazy\"`\n\n2. **Optimize Images**\n   ```bash\n   # Use WebP/AVIF formats\n   # Tools: squoosh, sharp, imagemin\n   npm install sharp\n   ```\n\n3. **Enable CDN**\n   - Vercel, Netlify, Cloudflare Pages (free tiers)\n   - Automatic edge caching\n\n4. **Measure Performance**\n   ```bash\n   # Lighthouse CI\n   npm install -g @lhci/cli\n   lhci autorun --config=lighthouserc.js\n   ```\n\n### Target Metrics (2025)\n\n- **First Contentful Paint (FCP):** < 1.0s\n- **Largest Contentful Paint (LCP):** < 2.5s\n- **Cumulative Layout Shift (CLS):** < 0.1\n- **Time to Interactive (TTI):** < 3.0s\n\n## Examples of Excellent Documentation (2025)\n\n### Hall of Fame\n\n1. **Stripe** (https://stripe.com/docs)\n   - Clear navigation, API reference with examples\n   - Interactive code snippets\n   - Excellent search\n\n2. **Astro** (https://docs.astro.build)\n   - Built with Starlight (dogfooding)\n   - Great tutorials, clear structure\n   - Multilingual\n\n3. **Supabase** (https://supabase.com/docs)\n   - Auto-generated from OpenAPI\n   - Try-it-now API explorer\n   - Client library examples in multiple languages\n\n4. **Rust** (https://doc.rust-lang.org/book/)\n   - The Rust Book: Tutorial + deep dive\n   - Clear progression from beginner to advanced\n   - Embedded playground\n\n5. **Tailwind CSS** (https://tailwindcss.com/docs)\n   - Search-first navigation\n   - Live examples\n   - Component showcase\n\n## Documentation Checklist\n\n### Before Launch\n\n- [ ] All four doc types present (Tutorial, How-To, Reference, Explanation)\n- [ ] Code examples tested and runnable\n- [ ] Links validated (no 404s)\n- [ ] Accessibility tested (WCAG 2.2 AA)\n- [ ] Search enabled and tested\n- [ ] Mobile responsive\n- [ ] SEO meta tags added\n- [ ] Analytics configured\n- [ ] Feedback mechanism present\n- [ ] \"Edit this page\" links work\n- [ ] Performance targets met (Lighthouse score 90+)\n- [ ] Versioning strategy defined\n- [ ] API docs auto-generated (if applicable)\n- [ ] CI/CD pipeline for docs\n- [ ] 404 page customized\n- [ ] Favicons and social cards added\n\n## Quick Start Templates\n\n### Starlight ⭐ (RECOMMENDED)\n\n**Best for:** Technical docs, API references, developer documentation, performance-critical sites\n\n```bash\n# Create project\nnpm create astro@latest my-docs -- --template starlight\ncd my-docs\n\n# Start dev server (with HMR)\nnpm run dev  # → http://localhost:4321\n\n# Build for production\nnpm run build\n\n# Preview production build\nnpm run preview\n```\n\n**File structure:**\n```\nmy-docs/\n├── astro.config.mjs           # Main configuration\n├── src/\n│   ├── content/\n│   │   ├── docs/\n│   │   │   ├── index.md       # Homepage\n│   │   │   ├── guides/        # Auto-generated sidebar\n│   │   │   │   ├── getting-started.md\n│   │   │   │   └── advanced.md\n│   │   │   └── reference/     # API docs\n│   │   │       └── api.md\n│   │   └── config.ts          # Content collections config\n│   ├── components/            # Custom components\n│   └── styles/\n│       └── custom.css         # Theme overrides\n├── public/\n│   ├── favicon.svg\n│   └── CNAME                  # Custom domain (optional)\n└── package.json\n```\n\n**Why Starlight:**\n- ⚡ Near-zero JavaScript (fastest possible)\n- ♿ WCAG 2.2 accessible out-of-the-box\n- 🔍 Built-in search (Pagefind, no external service needed)\n- 🌍 i18n built-in\n- 🎨 Beautiful defaults, easy to customize\n- 📱 Mobile-first responsive\n- 🚀 Excellent GitHub Pages integration\n\n### Docusaurus (For Large Organizations)\n\n**Best for:** Large projects with versioning needs, React ecosystems, blog + docs combo\n\n```bash\n# Create project\nnpx create-docusaurus@latest my-docs classic\ncd my-docs\n\n# Start dev server\nnpm start  # → http://localhost:3000\n\n# Build for production\nnpm run build\n\n# Serve production build\nnpm run serve\n```\n\n**File structure:**\n```\nmy-docs/\n├── docusaurus.config.js       # Main configuration\n├── sidebars.js                # Separate sidebar config\n├── docs/\n│   ├── intro.md\n│   └── tutorial/\n│       └── basics.md\n├── blog/                      # Built-in blog\n│   └── 2025-01-01-post.md\n├── src/\n│   ├── pages/                 # Custom React pages\n│   │   └── index.js\n│   └── css/\n│       └── custom.css\n└── static/\n    ├── .nojekyll              # REQUIRED for GitHub Pages\n    └── img/\n```\n\n**Why Docusaurus:**\n- 📦 Mature ecosystem with many plugins\n- 📝 Built-in blog functionality\n- 🏷️ Excellent versioning for API docs\n- ⚛️ React-based (if you love React)\n- 🔧 Highly customizable via swizzling\n\n## Advanced Techniques\n\n### Custom Components\n\n**Astro component for API endpoint:**\n```astro\n---\n// components/ApiEndpoint.astro\nconst { method, path, description } = Astro.props;\n---\n\n<div class=\"api-endpoint\">\n  <span class=\"method method-{method.toLowerCase()}\">{method}</span>\n  <code class=\"path\">{path}</code>\n  <p>{description}</p>\n</div>\n\n<style>\n  .method-get { background: #61affe; }\n  .method-post { background: #49cc90; }\n  .method-delete { background: #f93e3e; }\n</style>\n```\n\n**Usage:**\n```markdown\n---\ntitle: API Reference\n---\n\nimport ApiEndpoint from '../../components/ApiEndpoint.astro';\n\n<ApiEndpoint\n  method=\"GET\"\n  path=\"/api/users/{id}\"\n  description=\"Retrieve a user by ID\"\n/>\n```\n\n### Dynamic Content from Code\n\n**Extract docstrings automatically:**\n```python\n# scripts/extract_docs.py\nimport ast\nimport json\n\ndef extract_function_docs(filepath):\n    with open(filepath) as f:\n        tree = ast.parse(f.read())\n\n    docs = []\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            docs.append({\n                'name': node.name,\n                'docstring': ast.get_docstring(node),\n                'args': [arg.arg for arg in node.args.args]\n            })\n\n    return docs\n\n# Generate JSON for docs site\nfunctions = extract_function_docs('src/vibesafe/core.py')\nwith open('docs/api-functions.json', 'w') as f:\n    json.dump(functions, f)\n```\n\n**Consume in docs:**\n```astro\n---\nimport functionsData from './api-functions.json';\n---\n\n{functionsData.map(func => (\n  <section>\n    <h3>{func.name}</h3>\n    <p>{func.docstring}</p>\n    <code>def {func.name}({func.args.join(', ')})</code>\n  </section>\n))}\n```\n\n## Troubleshooting Common Issues\n\n### Search Not Working\n\n**Problem:** Built-in search doesn't find pages\n\n**Solutions:**\n1. Rebuild search index: `npm run docs:build`\n2. Check frontmatter: Ensure `title` and `description` present\n3. Verify search plugin enabled in config\n4. For Algolia DocSearch: Submit sitemap for crawling\n\n### Slow Build Times\n\n**Problem:** `npm run docs:build` takes too long\n\n**Solutions:**\n1. Enable incremental builds (framework-specific)\n2. Reduce image sizes (use `sharp` for optimization)\n3. Limit API doc generation scope\n4. Use caching in CI/CD:\n```yaml\n- uses: actions/cache@v3\n  with:\n    path: ~/.npm\n    key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n```\n\n### Broken Links After Restructure\n\n**Problem:** Many 404s after reorganizing docs\n\n**Solutions:**\n1. Add redirects:\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  redirects: {\n    '/old-path': '/new-path',\n    '/api/v1': '/api/v2',\n  },\n});\n```\n\n2. Use link validator in CI to catch early\n\n### Code Examples Not Highlighting\n\n**Problem:** Syntax highlighting not working\n\n**Solutions:**\n1. Check language identifier: ` ```python ` not ` ```py `\n2. Install language grammar: `npm install shiki`\n3. Configure theme:\n```javascript\n// astro.config.mjs\nexport default defineConfig({\n  markdown: {\n    shikiConfig: {\n      theme: 'github-dark',\n      langs: ['python', 'javascript', 'bash'],\n    },\n  },\n});\n```\n\n## When to Use This Skill\n\n✅ **Use this skill when:**\n- Creating new documentation sites\n- Restructuring existing docs\n- Improving documentation accessibility\n- Setting up API documentation\n- Implementing search\n- Adding versioning to docs\n- Optimizing documentation performance\n- Writing tutorials, how-tos, or reference docs\n- Setting up docs automation/CI\n- Migrating from old docs framework\n\n❌ **Don't use this skill for:**\n- Writing marketing copy (use marketing guidelines)\n- Creating product landing pages (use web design patterns)\n- Internal engineering specs (use ADRs, design docs)\n- Code comments (use language-specific conventions)\n\n## Quick Reference\n\n### Documentation Types\n\n| Type | Purpose | Audience | Style | Example |\n|------|---------|----------|-------|---------|\n| Tutorial | Learn by doing | Beginners | Step-by-step | \"Build Your First API\" |\n| How-To | Solve specific problem | Intermediate | Goal-focused | \"Add Authentication\" |\n| Reference | Look up details | All levels | Dry, precise | \"API Reference\" |\n| Explanation | Understand concepts | All levels | Discursive | \"Why Hash-Locked?\" |\n\n### Framework Commands\n\n```bash\n# Starlight (Astro) - RECOMMENDED\nnpm create astro@latest -- --template starlight\nnpm run dev              # http://localhost:4321\nnpm run build            # Build to dist/\nnpm run preview          # Preview build\n\n# Docusaurus (Alternative)\nnpx create-docusaurus@latest my-docs classic\nnpm start                # http://localhost:3000\nnpm run build            # Build to build/\nnpm run serve            # Preview build\n\n# VitePress (Vue ecosystem)\nnpm create vitepress@latest\nnpm run docs:dev\nnpm run docs:build\n\n# MkDocs (Python ecosystem)\npip install mkdocs-material\nmkdocs serve\nmkdocs build\n```\n\n### Essential Plugins\n\n**For Starlight:**\n```bash\n# Search (built-in with Pagefind, no install needed!)\n\n# Link validation\nnpm install starlight-links-validator\n\n# OpenAPI documentation\nnpm install starlight-openapi\n\n# Blog functionality\nnpm install starlight-blog\n\n# Image optimization (Astro)\nnpm install sharp  # Faster image processing\n\n# Diagrams - Mermaid (built into Astro)\n# Just enable in frontmatter: mermaid: true\n```\n\n**For Docusaurus:**\n```bash\n# Algolia search (free for open source)\nnpm install @docusaurus/theme-search-algolia\n\n# Live code blocks\nnpm install @docusaurus/theme-live-codeblock\n\n# Mermaid diagrams\nnpm install @docusaurus/theme-mermaid\n\n# OpenAPI docs\nnpm install docusaurus-plugin-openapi-docs\n```\n\n**Analytics (Framework-agnostic):**\n```bash\n# Use Plausible (privacy-friendly, GDPR compliant)\n# Use Fathom Analytics\n# Use Google Analytics 4\n# Add script tag to HTML head\n```\n\n### Deployment\n\n```bash\n# Vercel (recommended)\nnpm install -g vercel\nvercel --prod\n\n# Netlify\nnpm install -g netlify-cli\nnetlify deploy --prod\n\n# GitHub Pages\nnpm run docs:build\ngit subtree push --prefix dist origin gh-pages\n\n# Cloudflare Pages\n# Connect repo via dashboard, auto-deploy on push\n```\n\n## Resources\n\n- **Diátaxis Framework**: https://diataxis.fr/\n- **MDN Web Docs Guide**: https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines\n- **Google Developer Docs Style Guide**: https://developers.google.com/style\n- **Write the Docs**: https://www.writethedocs.org/\n- **Accessibility**: https://www.w3.org/WAI/WCAG22/quickref/\n- **Framework Docs**:\n  - Starlight: https://starlight.astro.build/\n  - Docusaurus: https://docusaurus.io/\n  - VitePress: https://vitepress.dev/\n  - Nextra: https://nextra.site/\n",
        ".claude/skills/hackernews-writing.md": "# HackerNews Writing Skill\n\nExpert skill for crafting technical content, documentation, blog posts, and titles that resonate with the Hacker News audience and generate meaningful engagement.\n\n## Overview\n\nHacker News (YC's news aggregator) has a unique, technically sophisticated audience with specific expectations for content quality, depth, and presentation. This skill encodes patterns from top-performing HN submissions to help create content that generates discussion, upvotes, and lasting value.\n\n**Core Philosophy:** HN readers value substance over style, depth over breadth, honesty over hype, and technical rigor over marketing speak.\n\n## Understanding the HN Audience\n\n### Demographics & Preferences\n\n**Who reads HN:**\n- Software engineers, CTOs, technical founders\n- Systems programmers, infrastructure engineers\n- Computer science researchers and academics\n- Engineering managers and technical leaders\n- Startup founders and indie hackers\n- Open source maintainers and contributors\n\n**What they value:**\n- Technical depth and first-hand experience\n- Novel insights or non-obvious solutions\n- Production war stories and hard-won lessons\n- Clear explanations of complex topics\n- Data-driven analysis and benchmarks\n- Honest assessments of trade-offs\n- Historical context and evolution of ideas\n- Creative problem-solving approaches\n\n**What they reject:**\n- Marketing content disguised as technical writing\n- Clickbait titles or sensationalism\n- Surface-level tutorials without depth\n- Hype without substance\n- Unsupported claims or hand-waving\n- Content that wastes their time\n- Obvious or widely-known information\n- Self-promotion without genuine value\n\n### Content Tiers on HN\n\n**🔥 Front Page (500+ points):**\n- Deep technical investigations\n- Novel algorithms or approaches\n- Production outage postmortems\n- Significant performance breakthroughs\n- Paradigm-shifting ideas\n- Well-researched historical pieces\n\n**📈 Rising (50-200 points):**\n- Solid technical tutorials\n- Tool comparisons with benchmarks\n- Experience reports from production\n- Debugging mysteries solved\n- Lesser-known techniques\n- Good technical questions\n\n**💬 Discussion Generators (any points, 50+ comments):**\n- Controversial technical opinions\n- Language/framework comparisons\n- Architecture decisions and trade-offs\n- \"X considered harmful\" critiques\n- Questions about best practices\n\n## Writing Titles That Work on HN\n\n### The Golden Rules\n\n**✅ DO:**\n1. **Be direct and factual** - State exactly what the content is\n2. **Use specific technical terms** - Not \"database\" but \"PostgreSQL 16\"\n3. **Include concrete numbers** - \"10x faster\" with benchmark data to back it up\n4. **State the problem clearly** - \"Why X fails at scale\"\n5. **Ask genuine questions** - \"How does SQLite handle concurrent writes?\"\n6. **Use version numbers** - \"Python 3.13's new JIT compiler\"\n7. **Be honest about scope** - \"A minimal guide to...\" not \"The complete guide to...\"\n\n**❌ DON'T:**\n1. **Use clickbait** - \"You won't believe...\", \"This one trick...\"\n2. **Add superlatives without proof** - \"The best\", \"The ultimate\"\n3. **Make it about yourself** - \"How I...\" unless genuinely novel\n4. **Use marketing speak** - \"Revolutionary\", \"Game-changing\", \"Disruptive\"\n5. **Ask rhetorical questions** - \"Is X the future?\" (unless genuinely exploring)\n6. **Use ALL CAPS or excessive punctuation** - \"AMAZING!!!\"\n7. **Be vague** - \"Some thoughts on databases\" vs \"PostgreSQL vs MySQL for time-series data\"\n\n### Title Patterns That Work\n\n#### Pattern 1: Direct Technical Description\n```\n✅ \"Implementing a B-tree in Rust with concurrent access\"\n✅ \"How Git stores objects: a deep dive into pack files\"\n✅ \"Building a CPU profiler from scratch in C\"\n✅ \"SQLite's query planner explained with examples\"\n```\n\nWhy it works: Clear, specific, promises technical depth\n\n#### Pattern 2: Problem → Solution\n```\n✅ \"Debugging a 50ms latency spike in production PostgreSQL\"\n✅ \"Reducing Docker image size from 1GB to 100MB\"\n✅ \"Fixing a memory leak in a 10-year-old Python codebase\"\n✅ \"Solving the N+1 query problem in GraphQL\"\n```\n\nWhy it works: Concrete problem, measurable outcome, relatable struggle\n\n#### Pattern 3: Comparative Analysis\n```\n✅ \"Benchmarking serialization: JSON vs MessagePack vs Protocol Buffers\"\n✅ \"Kubernetes vs Nomad: 2 years in production\"\n✅ \"SQLite vs PostgreSQL: When to use which\"\n✅ \"LLVM vs GCC: Compilation speed and binary size\"\n```\n\nWhy it works: Data-driven, helps decision-making, balanced perspective\n\n#### Pattern 4: Technical Investigation\n```\n✅ \"What happens when you type 'ls' and press Enter?\"\n✅ \"How does Redis persist data without blocking writes?\"\n✅ \"Why is Python's 'dict' so fast?\"\n✅ \"Exploring the Linux kernel's scheduler\"\n```\n\nWhy it works: Satisfies curiosity, educational, peels back abstractions\n\n#### Pattern 5: Production War Stories\n```\n✅ \"Postmortem: How we lost $100k to a race condition\"\n✅ \"The bug that took 3 months to find: a SIGSEGV story\"\n✅ \"When your database runs out of transaction IDs\"\n✅ \"How a single line of code brought down our infrastructure\"\n```\n\nWhy it works: Hard-won lessons, humility, preventable disasters\n\n#### Pattern 6: Unconventional Approaches\n```\n✅ \"Building a web server in pure Bash\"\n✅ \"Using SQLite as an application file format\"\n✅ \"Implementing malloc() in 100 lines of C\"\n✅ \"Writing a compiler in spreadsheet formulas\"\n```\n\nWhy it works: Creative, educational, demonstrates deep understanding\n\n#### Pattern 7: Historical/Contextual\n```\n✅ \"The rise and fall of CORBA\"\n✅ \"How Unix pipelines work: The 1973 implementation\"\n✅ \"Why the Linux kernel uses goto\"\n✅ \"The history of NaN in floating point\"\n```\n\nWhy it works: Context enriches understanding, connects past to present\n\n#### Pattern 8: Performance Deep Dives\n```\n✅ \"Making Python code 100x faster with Cython\"\n✅ \"How we reduced API latency from 500ms to 20ms\"\n✅ \"Why our Rust service uses 10x less memory than Java\"\n✅ \"Optimizing PostgreSQL for 1M writes/second\"\n```\n\nWhy it works: Concrete numbers, technical details, actionable insights\n\n### Title Anti-Patterns (What to Avoid)\n\n❌ **The Humble Brag:**\n```\n\"How I built a startup to $1M ARR in 6 months\"\n\"My side project hit #1 on HN\"\n```\nBetter: Focus on the technical achievement, not personal success\n\n❌ **The Vague Teaser:**\n```\n\"Some interesting thoughts on scalability\"\n\"A few notes about Kubernetes\"\n```\nBetter: Be specific about what insights you're sharing\n\n❌ **The Obvious Tutorial:**\n```\n\"Introduction to Python basics\"\n\"Getting started with Git\"\n```\nBetter: Find a non-obvious angle or advanced technique\n\n❌ **The Marketing Pitch:**\n```\n\"Why [Our Product] is the future of databases\"\n\"Announcing [Startup]: Revolutionizing DevOps\"\n```\nBetter: Focus on technical innovation, not business proposition\n\n❌ **The Inflammatory Clickbait:**\n```\n\"Why [Popular Technology] is terrible and you should stop using it\"\n\"Everyone is doing [X] wrong\"\n```\nBetter: Thoughtful critique with nuance and alternatives\n\n### Title Length Guidelines\n\n**Ideal range:** 50-80 characters (8-12 words)\n- Short enough to scan quickly\n- Long enough to be specific\n- Fits on one line in HN interface\n\n**Examples:**\n```\n✅ \"Understanding PostgreSQL's MVCC implementation\" (48 chars) ✅\n✅ \"How I debugged a memory leak in production Kubernetes\" (62 chars) ✅\n✅ \"Building a lock-free queue in C with atomic operations\" (55 chars) ✅\n\n❌ \"Databases\" (9 chars) - Too vague ❌\n❌ \"A comprehensive deep-dive investigation into the intricate details of how modern relational database management systems implement multi-version concurrency control mechanisms\" (175 chars) - Too long ❌\n```\n\n## Writing Content That Resonates\n\n### Structure for Success\n\n#### 1. The Opening (First 2-3 Paragraphs)\n\n**Hook immediately with the core insight:**\n\n✅ **Good Opening:**\n```markdown\nLast Tuesday, our API started responding in 3 seconds instead of 50ms.\nEvery request to /users/:id was timing out. The weird part? Nothing had\nchanged in the code. After 6 hours of debugging, we found the culprit:\na database query that had worked fine for 2 years suddenly hit a performance\ncliff when we crossed 1 million users.\n\nHere's what we learned about PostgreSQL's query planner and how to prevent\nthis from happening to you.\n```\n\nWhy it works: Immediate problem, stakes, mystery, promise of solution\n\n❌ **Bad Opening:**\n```markdown\nIn today's fast-paced world of web development, performance is increasingly\nbecoming a critical concern for engineering teams. As applications scale to\nmeet the demands of millions of users, database optimization becomes essential.\nThis blog post will explore some of the strategies we've discovered...\n```\n\nWhy it fails: Generic, slow burn, no hook, marketing speak\n\n**Elements of a strong opening:**\n1. **State the problem immediately** - No preamble\n2. **Include a hook** - Something unexpected or surprising\n3. **Promise specific value** - What will the reader learn?\n4. **Be concrete** - Real numbers, real systems, real problems\n5. **Skip the introduction** - Jump right into the meat\n\n#### 2. The Technical Deep Dive (Main Content)\n\n**Core Principles:**\n\n**A. Show Your Work**\n```markdown\n❌ \"We optimized the query and it got faster.\"\n\n✅ \"Here's the original query:\n```sql\nSELECT * FROM users\nWHERE created_at > '2024-01-01'\nORDER BY id;\n```\n\nThe EXPLAIN ANALYZE showed a sequential scan:\n```\nSeq Scan on users  (cost=0.00..35234.00 rows=1000000 width=128)\n  Filter: (created_at > '2024-01-01'::date)\n```\n\nAfter adding an index on (created_at, id):\n```sql\nCREATE INDEX idx_users_created_at_id ON users(created_at, id);\n```\n\nThe same query now uses the index:\n```\nIndex Scan using idx_users_created_at_id  (cost=0.42..8234.00 rows=250000 width=128)\n```\n\nQuery time dropped from 2.3s to 45ms.\"\n```\n\n**B. Include Code Examples**\n- Show real code, not pseudocode\n- Include error messages and outputs\n- Demonstrate before/after comparisons\n- Comment non-obvious parts\n- Keep examples minimal but complete\n\n**C. Add Benchmarks and Data**\n```markdown\n✅ Good benchmark section:\n\n## Performance Comparison\n\nTest setup:\n- Machine: AWS c5.xlarge (4 vCPU, 8GB RAM)\n- Dataset: 1M records, 10KB average size\n- Runs: 100 iterations, median reported\n\n| Approach | Throughput (req/s) | p50 latency | p99 latency | Memory |\n|----------|-------------------|-------------|-------------|--------|\n| Baseline | 1,200 | 42ms | 150ms | 2.1GB |\n| Option A | 3,400 | 15ms | 45ms | 1.8GB |\n| Option B | 5,100 | 8ms | 28ms | 3.2GB |\n\nOption B wins on speed but uses 50% more memory. For our use case\n(memory-constrained containers), we chose Option A.\n```\n\n**D. Explain the \"Why\" Not Just the \"How\"**\n```markdown\n❌ \"Use connection pooling with 20 connections.\"\n\n✅ \"We set the connection pool to 20 connections because:\n1. Our app runs 4 processes × 5 threads = 20 concurrent handlers\n2. PostgreSQL's max_connections is 100\n3. We run 4 app instances, so 20 × 4 = 80 connections (within limit)\n4. Benchmarking showed diminishing returns above 20 per instance\n5. This leaves 20 connections for admin tasks and monitoring\n\nConnection pool configuration:\n```python\npool_size=20,\nmax_overflow=0,  # No overflow - fail fast instead\npool_timeout=30,\npool_recycle=3600\n```\n\"\n```\n\n**E. Acknowledge Trade-offs and Limitations**\n```markdown\n✅ Good trade-off discussion:\n\n## Why We Chose Rust Over Go\n\nPros:\n- 40% lower memory usage in our benchmarks\n- Better CPU utilization (no GC pauses)\n- Type system caught entire classes of bugs\n- Zero-cost abstractions matched C++ performance\n\nCons:\n- 3x longer development time initially\n- Steep learning curve for the team\n- Longer compile times (5 minutes vs 30 seconds for Go)\n- Smaller ecosystem for some use cases\n- Harder to hire for\n\nWe chose Rust because our bottleneck was resource cost (running thousands\nof instances), not development velocity. If we were an early-stage startup\niterating quickly, Go would've been the better choice.\n```\n\n**F. Include Failure Stories**\n```markdown\n✅ \"We tried three approaches before this one worked:\n\n1. **Redis caching** - Cache hit rate was only 30% due to data distribution\n2. **Read replicas** - Replication lag caused stale data issues\n3. **Materialized views** - Refresh took 10 minutes, blocking writes\n\nFinally, we implemented partitioning by customer_id and query performance\nimproved 50x.\"\n```\n\n#### 3. Code Style in Content\n\n**Make code readable and production-quality:**\n\n✅ **Good code example:**\n```python\nimport asyncio\nfrom typing import List, Optional\nimport httpx\n\nclass APIClient:\n    \"\"\"HTTP client with retry logic and connection pooling.\"\"\"\n\n    def __init__(self, base_url: str, timeout: int = 30):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient(\n            timeout=timeout,\n            limits=httpx.Limits(max_connections=100)\n        )\n\n    async def fetch_user(self, user_id: int) -> Optional[dict]:\n        \"\"\"Fetch user by ID with exponential backoff retry.\n\n        Returns None if user not found, raises exception on other errors.\n        \"\"\"\n        for attempt in range(3):\n            try:\n                response = await self.client.get(\n                    f\"{self.base_url}/users/{user_id}\"\n                )\n                response.raise_for_status()\n                return response.json()\n            except httpx.HTTPStatusError as e:\n                if e.response.status_code == 404:\n                    return None\n                if attempt == 2:  # Last attempt\n                    raise\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n        return None\n\n# Usage\nclient = APIClient(\"https://api.example.com\")\nuser = await client.fetch_user(123)\n```\n\nWhy it works:\n- Type hints included\n- Docstrings explain behavior\n- Error handling is explicit\n- Comments explain non-obvious logic\n- Real-world pattern (retry with backoff)\n- Complete and runnable\n\n❌ **Bad code example:**\n```python\ndef get_user(id):\n    # Get the user\n    r = requests.get(url + \"/users/\" + str(id))\n    return r.json()\n```\n\nWhy it fails:\n- No error handling\n- No type hints\n- Unclear what happens on failure\n- Not production-ready\n\n#### 4. The Conclusion\n\n**End with actionable takeaways:**\n\n✅ **Good conclusion:**\n```markdown\n## Key Takeaways\n\n1. **Profile before optimizing** - We wasted 2 weeks on the wrong bottleneck\n2. **Index cardinality matters** - Indexes on low-cardinality columns hurt performance\n3. **Connection pools need tuning** - Default settings rarely work at scale\n4. **Monitor query plans** - They can change as data grows\n\nIf you're seeing slow PostgreSQL queries:\n1. Run EXPLAIN ANALYZE on your slowest queries\n2. Check pg_stat_statements for query patterns\n3. Look for sequential scans on large tables\n4. Verify index usage with pg_stat_user_indexes\n\nFull benchmarking code: https://github.com/example/pg-optimization\nDiscussion: https://news.ycombinator.com/item?id=XXXXX\n```\n\n**Elements of a strong conclusion:**\n- Numbered takeaways (3-5 points)\n- Actionable next steps\n- Links to code/further reading\n- Invitation for discussion\n- No sales pitch or marketing\n\n❌ **Bad conclusion:**\n```markdown\n## Conclusion\n\nIn conclusion, database optimization is a complex topic with many facets\nto consider. We hope this post has been helpful and informative. If you\nenjoyed this content, please subscribe to our newsletter for more tips\nand tricks. Check out our product at [startup.com] for automated database\noptimization!\n```\n\n### Writing Style Guide\n\n#### Tone and Voice\n\n**✅ DO:**\n- Write in first person (\"we did\", \"I found\") for experience reports\n- Use second person (\"you can\", \"you should\") for tutorials\n- Be conversational but precise\n- Show humility about mistakes\n- Express genuine enthusiasm for technical topics\n- Use humor sparingly and naturally\n\n**❌ DON'T:**\n- Use corporate/marketing voice\n- Be condescending or assume ignorance\n- Over-explain obvious concepts\n- Use excessive jargon without definitions\n- Write in passive voice\n- Add fluff or filler content\n\n#### Sentence Structure\n\n**✅ Good sentences:**\n```markdown\nThe bug appeared at 3am on a Saturday. Classic.\n\nPostgreSQL's MVCC implementation is elegant: each row version has a\ntransaction ID. When you read a row, you see the version that was\ncommitted before your transaction started. This makes reads non-blocking.\n\nWe benchmarked three approaches. Rust was fastest but had the longest\ncompile times. Go was middle-ground. Python was slowest but easiest to modify.\n```\n\nWhy it works: Short, direct, varied length, no wasted words\n\n**❌ Bad sentences:**\n```markdown\nIn the context of modern database systems, it is often the case that\nvarious concurrency control mechanisms are employed in order to ensure\nthat multiple transactions can be processed simultaneously without\ninterfering with each other's operations.\n```\n\nWhy it fails: Verbose, passive voice, academically bloated\n\n#### Paragraph Structure\n\n**Ideal paragraph:**\n- 2-5 sentences\n- One main idea per paragraph\n- Start with topic sentence\n- End with transition or insight\n\n**Break up long content with:**\n- Subheadings every 2-3 paragraphs\n- Code blocks and examples\n- Lists and tables\n- Quotes and callouts\n- Diagrams and charts\n\n#### Technical Terminology\n\n**Use precise technical terms:**\n```markdown\n✅ \"PostgreSQL uses MVCC (Multi-Version Concurrency Control)\"\n✅ \"The algorithm is O(n log n) in the average case\"\n✅ \"We hit the L1 cache 95% of the time\"\n✅ \"The race condition occurs during the compare-and-swap\"\n```\n\n**Define acronyms on first use:**\n```markdown\n✅ \"We implemented CRDT (Conflict-free Replicated Data Types) for\ndistributed state management.\"\n\n❌ \"We used CRDTs.\" (first mention, no definition)\n```\n\n**Avoid buzzwords:**\n```markdown\n❌ \"We leverage AI-powered cloud-native microservices\"\n✅ \"We use GPT-4 to classify messages in our Kubernetes cluster\"\n```\n\n### Content Types That Work\n\n#### Type 1: The Technical Deep Dive\n\n**Purpose:** Explain how something works at a deep level\n\n**Structure:**\n1. What is X?\n2. Why does X matter?\n3. How does X work internally?\n4. Common pitfalls and gotchas\n5. Real-world usage examples\n6. Performance characteristics\n7. Alternative approaches\n\n**Example topics:**\n- \"How Linux load balancers work: A deep dive into IPVS\"\n- \"Understanding JWT: Security considerations and implementation\"\n- \"Inside V8's optimizing compiler\"\n\n#### Type 2: The Production Postmortem\n\n**Purpose:** Share hard-won lessons from production incidents\n\n**Structure:**\n1. The incident (what went wrong)\n2. Impact and timeline\n3. Debugging process (dead ends included)\n4. Root cause analysis\n5. The fix\n6. Prevention measures\n7. What we learned\n\n**Example topics:**\n- \"Postmortem: The day we lost 100k database rows\"\n- \"How a single character typo took down our production cluster\"\n- \"Debugging a 1-second delay in Kubernetes DNS lookups\"\n\n#### Type 3: The Benchmark Comparison\n\n**Purpose:** Compare tools/approaches with data\n\n**Structure:**\n1. What we're comparing and why\n2. Test methodology\n3. Environment and setup\n4. Benchmark results (tables/graphs)\n5. Analysis and interpretation\n6. Trade-offs discussion\n7. Recommendations by use case\n\n**Example topics:**\n- \"Benchmarking message queues: Kafka vs RabbitMQ vs NATS\"\n- \"Container runtimes compared: Docker vs Podman vs containerd\"\n- \"Python web frameworks: FastAPI vs Flask vs Django performance\"\n\n#### Type 4: The \"Show HN\" Project\n\n**Purpose:** Share something you built, focusing on technical interesting bits\n\n**Structure:**\n1. What it is (1 sentence)\n2. Why you built it (problem/motivation)\n3. Technical highlights (the interesting parts)\n4. Architecture/design decisions\n5. Challenges and solutions\n6. Demo/examples\n7. Links (GitHub, live demo)\n\n**Example topics:**\n- \"Show HN: I built a SQLite clone in Rust to understand databases\"\n- \"Show HN: A text editor in 1000 lines of C\"\n- \"Show HN: Self-hosted alternative to Vercel using Kubernetes\"\n\n#### Type 5: The Debugging Mystery\n\n**Purpose:** Tell the story of solving a hard bug\n\n**Structure:**\n1. The symptoms (mysterious behavior)\n2. Initial hypotheses\n3. Dead ends and false leads\n4. The breakthrough moment\n5. The root cause\n6. The fix\n7. Lessons learned\n\n**Example topics:**\n- \"The bug that only appeared on Tuesdays\"\n- \"Debugging a heisenbug in multi-threaded Rust\"\n- \"How I tracked down a memory corruption bug using gdb\"\n\n#### Type 6: The Experience Report\n\n**Purpose:** Share what you learned from using X in production\n\n**Structure:**\n1. What we built and why we chose X\n2. Initial experience and setup\n3. What worked well\n4. Pain points and gotchas\n5. Performance in production\n6. Would we choose it again?\n7. Advice for others\n\n**Example topics:**\n- \"One year of using Elixir in production\"\n- \"Migrating from MongoDB to PostgreSQL: What we learned\"\n- \"Running Nomad instead of Kubernetes: 6 months in\"\n\n#### Type 7: The Performance Optimization\n\n**Purpose:** Document significant performance improvements\n\n**Structure:**\n1. The performance problem\n2. Baseline measurements\n3. Profiling and investigation\n4. Optimization attempts (successes and failures)\n5. Final solution and results\n6. Before/after comparisons\n7. Generalizable lessons\n\n**Example topics:**\n- \"Reducing Docker build time from 30 minutes to 40 seconds\"\n- \"How we made our Python API 50x faster\"\n- \"Optimizing PostgreSQL: From 100 to 10,000 queries/second\"\n\n### Visual Elements\n\n#### Code Blocks\n\n**Always include:**\n- Syntax highlighting (specify language)\n- Comments for non-obvious parts\n- Complete, runnable examples when possible\n- Input and output examples\n\n```markdown\n✅ Good code block:\n\n```python\n# Binary search implementation with bounds checking\ndef binary_search(arr: List[int], target: int) -> int:\n    \"\"\"Return index of target in sorted arr, or -1 if not found.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left <= right:\n        mid = left + (right - left) // 2  # Avoid overflow\n\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return -1\n\n# Example usage:\nnumbers = [1, 3, 5, 7, 9, 11, 13, 15]\nindex = binary_search(numbers, 7)  # Returns 3\n```\n```\n\n#### Tables\n\n**Use tables for:**\n- Benchmark results\n- Feature comparisons\n- Performance metrics\n- Before/after data\n\n```markdown\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| Response time (p50) | 234ms | 45ms | 80% |\n| Response time (p99) | 1.2s | 120ms | 90% |\n| Throughput | 450 req/s | 2100 req/s | 4.6x |\n| Memory usage | 3.2GB | 1.8GB | 44% |\n| CPU utilization | 85% | 42% | 51% |\n```\n\n#### Diagrams and Charts\n\n**Include diagrams for:**\n- Architecture overviews\n- Data flow\n- State machines\n- Network topology\n- Algorithm visualization\n\n**Tools that work well:**\n- ASCII diagrams (plain text, always renders)\n- Mermaid (supported on GitHub)\n- Simple PNG/SVG (keep it clean)\n- Excalidraw (hand-drawn style, approachable)\n\n**Example ASCII diagram:**\n```\n┌─────────────┐\n│   Client    │\n└──────┬──────┘\n       │ HTTP\n       ▼\n┌─────────────┐     ┌──────────┐\n│  API Server │────▶│  Redis   │\n└──────┬──────┘     └──────────┘\n       │\n       │ SQL\n       ▼\n┌─────────────┐\n│ PostgreSQL  │\n└─────────────┘\n```\n\n#### Callout Boxes\n\n**Use for important notes:**\n\n```markdown\n> ⚠️ **Warning**: This approach has a race condition when multiple\n> processes access the same file. Use file locking with `fcntl.flock()`\n> or switch to a database for multi-process deployments.\n\n> 💡 **Tip**: PostgreSQL's `EXPLAIN (ANALYZE, BUFFERS)` shows cache hits\n> and disk reads. Look for \"Buffers: shared hit\" vs \"shared read\".\n\n> 🔍 **Debug**: Enable query logging with `log_min_duration_statement = 0`\n> in postgresql.conf. Remember to disable it after debugging!\n```\n\n## Topic Selection Strategy\n\n### High-Potential Topics\n\n**✅ Topics that consistently do well:**\n\n1. **Performance optimization stories**\n   - \"Reducing latency from X to Y\"\n   - \"How we cut costs by 80% with optimization Z\"\n   - \"Making X 100x faster\"\n\n2. **Database deep dives**\n   - PostgreSQL internals\n   - SQLite usage patterns\n   - Database query optimization\n   - Replication and consistency\n\n3. **Systems programming**\n   - Operating system internals\n   - Network programming\n   - Memory management\n   - Concurrency and parallelism\n\n4. **Production war stories**\n   - Outage postmortems\n   - Debugging mysteries\n   - Scale challenges\n   - Hard-won lessons\n\n5. **Language internals**\n   - How interpreters work\n   - Compiler optimizations\n   - Memory models\n   - Type systems\n\n6. **Infrastructure topics**\n   - Kubernetes internals\n   - Container runtime details\n   - CI/CD optimization\n   - Monitoring and observability\n\n7. **Security research**\n   - Vulnerability discoveries\n   - Exploit development (ethical)\n   - Security audit findings\n   - Cryptography implementations\n\n8. **Historical retrospectives**\n   - Evolution of technologies\n   - \"Where are they now\" for old tech\n   - Design decisions and their consequences\n   - Lost knowledge and forgotten techniques\n\n### Evergreen vs Trendy\n\n**Evergreen content (long-lasting value):**\n- Fundamental concepts (algorithms, data structures)\n- Core technologies (TCP/IP, HTTP, SQL)\n- Timeless patterns (design patterns, architectures)\n- Problem-solving approaches\n- Performance optimization techniques\n\n**Trendy content (timely value):**\n- New language/framework releases\n- Breaking security vulnerabilities\n- Industry incidents (major outages)\n- Emerging technologies\n- Current debates (Rust vs Go, etc.)\n\n**Balance:** Mix evergreen depth with timely relevance\n\n### Finding Your Angle\n\n**Ask yourself:**\n1. What's the non-obvious insight here?\n2. What would have saved me weeks if I'd known it earlier?\n3. What surprised me about this?\n4. What do the docs not tell you?\n5. What's the hidden complexity?\n6. What did I learn the hard way?\n\n**Example transformations:**\n```\nGeneric: \"Introduction to Redis\"\n✅ Better: \"Using Redis as a primary database: What works and what doesn't\"\n\nGeneric: \"Understanding Docker\"\n✅ Better: \"How Docker actually works: Namespaces, cgroups, and union filesystems\"\n\nGeneric: \"Guide to GraphQL\"\n✅ Better: \"GraphQL at scale: Solving the N+1 problem, caching, and security\"\n```\n\n## Common Mistakes to Avoid\n\n### Content Mistakes\n\n❌ **1. Burying the lede**\n```markdown\nBad: [3 paragraphs about context]\n     [2 paragraphs about your background]\n     [Finally, the actual insight]\n\nGood: [Immediate insight]\n      [Context as needed]\n      [Background only if relevant]\n```\n\n❌ **2. No code examples**\n```markdown\nBad: \"We optimized the algorithm and it got faster.\"\n\nGood: [Show the slow code]\n      [Show the fast code]\n      [Show benchmark results]\n```\n\n❌ **3. Marketing speak**\n```markdown\nBad: \"Our revolutionary AI-powered solution leverages machine learning\"\n\nGood: \"We use a Random Forest classifier trained on 10k examples\"\n```\n\n❌ **4. Unsupported claims**\n```markdown\nBad: \"This is the fastest JSON parser ever written.\"\n\nGood: \"This parser handles 2.5GB/s on our benchmark (M1 Max, 10 cores),\n      compared to simdjson's 2.1GB/s and RapidJSON's 1.8GB/s.\"\n```\n\n❌ **5. Incomplete examples**\n```markdown\nBad:\n```python\nresult = process_data(data)\n```\n\nGood:\n```python\nimport pandas as pd\nfrom typing import DataFrame\n\ndef process_data(df: DataFrame) -> DataFrame:\n    \"\"\"Remove duplicates and normalize values.\"\"\"\n    df = df.drop_duplicates(subset=['id'])\n    df['value'] = (df['value'] - df['value'].mean()) / df['value'].std()\n    return df\n\n# Example usage:\ndata = pd.DataFrame({\n    'id': [1, 2, 2, 3],\n    'value': [10, 20, 20, 30]\n})\nresult = process_data(data)\n# Result: 3 rows with normalized values\n```\n```\n\n❌ **6. No trade-off discussion**\n```markdown\nBad: \"We switched to microservices and everything is better.\"\n\nGood: \"Microservices gave us better scalability (10x throughput) but\n      increased complexity (3x more repos, more network calls, harder\n      debugging). Worth it for us at our scale, but I'd use a monolith\n      for a small team.\"\n```\n\n### Title Mistakes\n\n❌ **1. The vague title**\n```\n\"Some thoughts on databases\"\nBetter: \"PostgreSQL vs MySQL for time-series data: A benchmark study\"\n```\n\n❌ **2. The clickbait title**\n```\n\"This one weird trick will make your code 10x faster!\"\nBetter: \"Reducing Python startup time with module-level imports\"\n```\n\n❌ **3. The me-focused title**\n```\n\"How I became a 10x developer\"\nBetter: \"5 debugging techniques that saved me 100 hours\"\n```\n\n❌ **4. The generic tutorial**\n```\n\"Getting started with Docker\"\nBetter: \"Docker internals: How containers actually work\"\n```\n\n❌ **5. The vendor title**\n```\n\"Why you should use [Our Product]\"\nBetter: \"Building a distributed cache with Redis: Patterns and pitfalls\"\n```\n\n## Checklist for HN-Ready Content\n\n### Before Publishing\n\n**Content Quality:**\n- [ ] Title is specific, factual, and under 80 characters\n- [ ] Opening paragraph hooks immediately (no preamble)\n- [ ] Technical depth is substantial (not surface-level)\n- [ ] Code examples are complete and runnable\n- [ ] Benchmarks include methodology and environment\n- [ ] Trade-offs and limitations are discussed\n- [ ] Failures and dead ends are included\n- [ ] Claims are supported with evidence\n- [ ] Conclusion has actionable takeaways\n- [ ] No marketing speak or hype\n\n**Technical Accuracy:**\n- [ ] Code has been tested\n- [ ] Benchmarks have been verified\n- [ ] Technical terms are used correctly\n- [ ] Version numbers are current\n- [ ] Links work and are relevant\n- [ ] Examples are reproducible\n\n**Readability:**\n- [ ] Paragraphs are short (2-5 sentences)\n- [ ] Subheadings break up long sections\n- [ ] Code blocks have syntax highlighting\n- [ ] Tables and diagrams enhance clarity\n- [ ] Sentences are direct and clear\n- [ ] Technical jargon is defined\n\n**Value Proposition:**\n- [ ] Reader will learn something new\n- [ ] Content has practical applications\n- [ ] Insights are non-obvious\n- [ ] Problems discussed are relatable\n- [ ] Solutions are generalizable\n\n### Submission Strategy\n\n**Timing:**\n- Best times: 8-10am EST on weekdays\n- Avoid: Late Friday, weekends, holidays\n- Competition: Check /newest before posting\n\n**Format:**\n- For blog posts: Submit URL directly\n- For GitHub: Submit to README or docs\n- For text posts: Use \"Text\" submission type\n- Include \"Show HN:\" prefix for your projects\n\n**Engagement:**\n- Monitor early comments (first 30 minutes critical)\n- Respond thoughtfully to questions\n- Acknowledge criticisms gracefully\n- Add clarifications if needed\n- Don't argue or defend aggressively\n\n## Example: Rewriting Content for HN\n\n### Before: Generic Tutorial\n\n**Title:** \"Introduction to PostgreSQL Performance\"\n\n**Opening:**\n```markdown\nPostgreSQL is one of the most popular open-source relational databases\nin use today. As applications grow and scale, performance becomes\nincreasingly important. In this tutorial, we'll explore some basic\nconcepts around PostgreSQL performance optimization.\n\nThere are many factors that contribute to database performance...\n```\n\n**Problems:**\n- Generic title\n- Slow, fluffy opening\n- No specific value proposition\n- No hook or curiosity\n\n### After: HN-Optimized\n\n**Title:** \"Why PostgreSQL's query planner chose a slow sequential scan: A debugging story\"\n\n**Opening:**\n```markdown\nOur dashboard query went from 50ms to 8 seconds overnight. Nothing changed\nin the code. The EXPLAIN output showed PostgreSQL chose a sequential scan\nover our carefully-crafted index on a 50M row table.\n\nAfter digging through pg_stats and experimenting with query costs, I found\nthe culprit: our nightly ANALYZE job stopped running 2 weeks ago. The planner\nwas using stale statistics from when the table had 2M rows.\n\nHere's what I learned about how PostgreSQL's cost-based optimizer makes\ndecisions, and how to debug when it chooses poorly.\n```\n\n**Improvements:**\n- Specific, intriguing title\n- Immediate problem statement\n- Real numbers and stakes\n- Mystery element\n- Promise of practical insights\n\n**Body would include:**\n```markdown\n## Understanding query planner statistics\n\nPostgreSQL's planner uses statistics from pg_stats to estimate:\n- Row count in each table\n- Cardinality of column values\n- Correlation of physical and logical ordering\n\nWhen statistics are stale, estimates are wrong, and the planner chooses\nsuboptimal plans.\n\n## Debugging the issue\n\n1. Check when statistics were last updated:\n```sql\nSELECT schemaname, tablename, last_analyze, last_autoanalyze\nFROM pg_stat_user_tables\nWHERE tablename = 'dashboard_events';\n```\n\nResult showed last analyze was 14 days ago.\n\n2. Check the planner's estimates vs reality:\n```sql\nEXPLAIN (ANALYZE, BUFFERS)\nSELECT * FROM dashboard_events\nWHERE user_id = 12345;\n```\n\nOutput:\n```\nSeq Scan on dashboard_events\n  (cost=0.00..854234.00 rows=50000000 width=128)\n  (actual rows=12 loops=1)\n```\n\nEstimated 50M rows, actually found 12 rows. No wonder it chose a seq scan.\n\n[Continue with solution, prevention, lessons...]\n```\n\n## Templates and Formulas\n\n### The Performance Optimization Template\n\n```markdown\n# [Specific Task]: From [Slow Metric] to [Fast Metric]\n\nLast [timeframe], our [system] started [symptom]. [Concrete impact statement].\n\n## The Problem\n\n[Detailed problem description with measurements]\n\n## Investigation\n\n1. Initial profiling with [tool]:\n```\n[profiler output]\n```\n\n2. Hypothesis: [what we thought was wrong]\n\n3. Testing: [what we tried]\n\n4. Results: [what happened - including failures]\n\n## The Solution\n\n[Describe winning approach]\n\n```[language]\n[code example]\n```\n\n## Results\n\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| [Key metric] | [value] | [value] | [%/x] |\n\n## Lessons Learned\n\n1. [Insight 1]\n2. [Insight 2]\n3. [Insight 3]\n\n## Resources\n\n- Code: [github link]\n- Benchmarks: [link]\n```\n\n### The Comparison Template\n\n```markdown\n# [Tool A] vs [Tool B] vs [Tool C]: [Specific Use Case]\n\nWe needed [specific requirement] for [project context]. After benchmarking\nthree popular [category] tools, here's what we found.\n\n## What We're Comparing\n\n- **[Tool A]**: [Brief description, version]\n- **[Tool B]**: [Brief description, version]\n- **[Tool C]**: [Brief description, version]\n\n## Test Methodology\n\n- Environment: [specs]\n- Dataset: [description]\n- Tests: [what we measured]\n- Iterations: [number]\n\n## Benchmark Results\n\n### Test 1: [Scenario]\n\n```\n[Setup code]\n```\n\n| Tool | Metric 1 | Metric 2 | Metric 3 |\n|------|----------|----------|----------|\n| A | [value] | [value] | [value] |\n| B | [value] | [value] | [value] |\n| C | [value] | [value] | [value] |\n\n[Analysis of results]\n\n### Test 2: [Scenario]\n\n[Repeat structure]\n\n## Trade-offs\n\n**Tool A:**\n- ✅ Pros: [list]\n- ❌ Cons: [list]\n- Best for: [use case]\n\n**Tool B:**\n- ✅ Pros: [list]\n- ❌ Cons: [list]\n- Best for: [use case]\n\n**Tool C:**\n- ✅ Pros: [list]\n- ❌ Cons: [list]\n- Best for: [use case]\n\n## Our Choice\n\nWe chose [Tool] because [reasoning based on data and our specific needs].\n\n## Full Benchmark Code\n\n[GitHub link]\n```\n\n### The \"Show HN\" Template\n\n```markdown\n# Show HN: [Project Name] – [One-line description]\n\n[One paragraph explaining what it is and why it's interesting]\n\n## Why I Built This\n\n[Problem/motivation - keep it real]\n\n## Technical Highlights\n\n### [Interesting aspect 1]\n\n[Explanation with code example]\n\n### [Interesting aspect 2]\n\n[Explanation with code example]\n\n## Architecture\n\n```\n[Diagram or description]\n```\n\n## Demo\n\n```bash\n[Installation and usage examples]\n```\n\n[Screenshot or video if applicable]\n\n## Performance\n\n[If relevant - benchmarks or metrics]\n\n## Limitations\n\n[Be honest about what doesn't work yet]\n\n## Links\n\n- GitHub: [url]\n- Live demo: [url]\n- Docs: [url]\n\n## Discussion\n\nI'd love feedback on [specific aspect]. Also curious if anyone has\nsolved [related problem] differently.\n```\n\n## Advanced Techniques\n\n### Using Data to Tell Stories\n\n**Technique:** Let the data reveal the narrative\n\n**Example:**\n```markdown\n## What We Discovered\n\nI graphed API latency over 7 days and saw this:\n\n```\nDay 1-2: 50ms average\nDay 3-4: 55ms average\nDay 5:   120ms average (!)\nDay 6:   280ms average (!!)\nDay 7:   503ms average (timeout hell)\n```\n\nThe pattern was clear: degradation started on Day 3, accelerated on Day 5.\n\nOverlaying deployment history:\n- Day 3: New ORM version deployed\n- Day 5: Crossed 1M users milestone\n\nThe culprit: The ORM's query builder generated inefficient joins that\nscaled poorly. At 1M users, we hit a performance cliff.\n```\n\n### The \"Rabbit Hole\" Technique\n\n**Technique:** Document your journey into deeper complexity\n\n**Example:**\n```markdown\n## Down the Rabbit Hole\n\nIt started as \"why is this line slow?\" and ended with me reading Linux\nkernel source code. Here's the journey:\n\n**Layer 1:** Python code\n```python\ndata = file.read()  # This line takes 2 seconds\n```\n\n**Layer 2:** strace shows the syscalls\n```\nread(3, \"...\"..., 1000000000)  = 1000000000  <2.134567>\n```\n\n**Layer 3:** The filesystem\nThe file was on a network mount (NFS), not local disk.\n\n**Layer 4:** Network I/O\nNFS was using 1KB read chunks. For 1GB = 1M network round trips.\n\n**Layer 5:** NFS mount options\nWe had `rsize=1024` instead of `rsize=1048576`.\n\n**Solution:**\n```bash\nmount -o remount,rsize=1048576 /mnt/nfs\n```\n\nRead time: 2 seconds → 80ms.\n\n**Lesson:** Always check your assumptions about I/O.\n```\n\n### The \"Surprising Benchmark\" Technique\n\n**Technique:** Challenge common assumptions with data\n\n**Example:**\n```markdown\n## The Surprising Winner\n\nCommon wisdom says \"compiled languages are faster than interpreted.\"\nBut for this specific task, Python beat C++:\n\n| Language | Runtime | Lines of Code |\n|----------|---------|---------------|\n| Python | 0.12s | 15 |\n| C++ | 1.8s | 87 |\n\nHow? The task was parsing JSON. Python's json module is actually C\n(using simdjson), while we used a pure C++ parser. The lesson: profile\nreal code, not assumptions.\n```\n\n### The \"Evolution\" Technique\n\n**Technique:** Show how the solution evolved through iterations\n\n**Example:**\n```markdown\n## Five Attempts\n\n**v1: Naive approach**\n```python\nresults = [process(x) for x in data]  # 45 seconds\n```\nSimple but slow.\n\n**v2: Threading**\n```python\nwith ThreadPoolExecutor(10) as pool:\n    results = list(pool.map(process, data))  # 43 seconds\n```\nGIL-bound, no improvement.\n\n**v3: Multiprocessing**\n```python\nwith ProcessPoolExecutor(10) as pool:\n    results = list(pool.map(process, data))  # 8 seconds\n```\nBetter! But high memory usage (10 copies of data).\n\n**v4: Memory-mapped files**\n```python\nwith mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as m:\n    results = process_mmap(m)  # 5 seconds\n```\nFaster, shared memory.\n\n**v5: Rust extension**\n```rust\n#[pyfunction]\nfn process_data(data: &[u8]) -> Vec<Result> {\n    data.par_iter().map(|x| process(x)).collect()\n}  # 0.8 seconds\n```\n\nFinal speedup: 56x. But v4 (Python + mmap) was good enough for production.\nThe lesson: optimization has diminishing returns.\n```\n\n## Conclusion\n\nHackerNews rewards substance over style, depth over breadth, and honesty over hype. The audience is technically sophisticated and values:\n\n1. **Technical rigor** - Show your work, include code, provide data\n2. **Practical insights** - Share hard-won lessons from real experience\n3. **Intellectual honesty** - Acknowledge trade-offs, failures, and limitations\n4. **Clear communication** - Be direct, skip fluff, respect readers' time\n5. **Genuine value** - Teach something non-obvious or share novel approaches\n\nWrite for an audience of senior engineers who've seen everything. Surprise them with depth, intrigue them with mysteries, and respect their intelligence.\n\n## When to Use This Skill\n\n✅ **Use this skill when:**\n- Writing technical blog posts for developer audiences\n- Documenting project postmortems or case studies\n- Creating \"Show HN\" posts for projects\n- Writing documentation that needs to be engaging\n- Crafting titles for technical content\n- Preparing technical talks or presentations\n- Contributing to technical discussions\n\n❌ **Don't use this skill for:**\n- Marketing copy or sales pages\n- Non-technical audiences\n- Academic papers (different conventions)\n- Internal documentation (different goals)\n- Quick notes or drafts (too much overhead)\n\n## Resources\n\n- **HackerNews Guidelines**: https://news.ycombinator.com/newsguidelines.html\n- **Analysis of Top Posts**: Study /best to see patterns\n- **Title Analysis**: https://hn.algolia.com to search by title patterns\n- **Timing Analysis**: https://hnrankings.info for best posting times\n- **Writing Style**: Read top technical blogs (Cloudflare, Netflix, Stripe engineering blogs)\n",
        ".claude/skills/uv.md": "# UV Package Manager Skill\n\nExpert skill for using `uv`, the fast Python package and project manager written in Rust.\n\n## Overview\n\n`uv` is a drop-in replacement for pip, pip-tools, and virtualenv that's 10-100x faster. Use this skill when managing Python dependencies, creating virtual environments, or working with Python projects.\n\n## Core Commands\n\n### Virtual Environments\n\n#### Create a virtual environment\n```bash\nuv venv                    # Create .venv in current directory\nuv venv path/to/venv       # Create venv at specific path\nuv venv --python 3.12      # Use specific Python version\n```\n\n#### Activate virtual environment\n```bash\nsource .venv/bin/activate  # Linux/Mac\n.venv\\Scripts\\activate     # Windows\n```\n\n### Package Installation\n\n#### Install packages\n```bash\nuv pip install package-name              # Install single package\nuv pip install package-name==1.2.3       # Install specific version\nuv pip install \"package-name>=1.0,<2.0\"  # Version constraints\nuv pip install -r requirements.txt       # Install from requirements\nuv pip install -e .                      # Install in editable mode\nuv pip install -e \".[dev]\"               # Install with extras\nuv pip install --system                  # Install to system Python\n```\n\n#### Install from pyproject.toml\n```bash\nuv pip install -e .              # Install project in editable mode\nuv pip install -e \".[dev,test]\"  # Install with optional dependencies\n```\n\n### Package Management\n\n#### List installed packages\n```bash\nuv pip list                # List all packages\nuv pip list --format json  # JSON format\nuv pip show package-name   # Show package details\n```\n\n#### Freeze dependencies\n```bash\nuv pip freeze              # Output installed packages\nuv pip freeze > requirements.txt  # Save to file\n```\n\n#### Uninstall packages\n```bash\nuv pip uninstall package-name           # Uninstall single package\nuv pip uninstall -r requirements.txt    # Uninstall from file\n```\n\n#### Upgrade packages\n```bash\nuv pip install --upgrade package-name   # Upgrade single package\nuv pip install --upgrade -r requirements.txt  # Upgrade all\n```\n\n### Project Initialization\n\n#### Initialize new project\n```bash\nuv init                    # Initialize in current directory\nuv init --lib              # Initialize as library\nuv init --name myproject   # Initialize with specific name\n```\n\n### Compilation & Lock Files\n\n#### Compile dependencies\n```bash\nuv pip compile pyproject.toml -o requirements.txt  # Compile to requirements.txt\nuv pip compile requirements.in -o requirements.txt # Compile .in file\n```\n\n#### Sync environment\n```bash\nuv pip sync requirements.txt  # Sync venv to exact requirements\n```\n\n## Best Practices\n\n### Project Setup Workflow\n\n1. **Create project structure:**\n```bash\nmkdir myproject && cd myproject\nuv init --lib  # or without --lib for application\n```\n\n2. **Create virtual environment:**\n```bash\nuv venv\nsource .venv/bin/activate\n```\n\n3. **Install project with dev dependencies:**\n```bash\nuv pip install -e \".[dev]\"\n```\n\n### Dependency Management\n\n1. **Always use version constraints in pyproject.toml:**\n```toml\ndependencies = [\n    \"requests>=2.31.0,<3.0.0\",\n    \"pydantic>=2.0.0\",\n]\n```\n\n2. **Separate dev dependencies:**\n```toml\n[project.optional-dependencies]\ndev = [\n    \"pytest>=8.0.0\",\n    \"mypy>=1.11.0\",\n]\n```\n\n3. **Lock dependencies for reproducibility:**\n```bash\nuv pip freeze > requirements.txt\n```\n\n### Performance Tips\n\n- **Use `uv` instead of `pip`** - It's significantly faster\n- **Use `uv pip sync`** instead of `pip install -r` for exact reproduction\n- **Leverage caching** - `uv` automatically caches packages\n\n### Common Patterns\n\n#### Quick test environment\n```bash\nuv venv .test-venv\nsource .test-venv/bin/activate\nuv pip install pytest hypothesis\npytest\n```\n\n#### Install from git\n```bash\nuv pip install git+https://github.com/user/repo.git\nuv pip install git+https://github.com/user/repo.git@branch-name\nuv pip install git+https://github.com/user/repo.git@v1.0.0\n```\n\n#### Install with extras\n```bash\nuv pip install \"package[extra1,extra2]\"\nuv pip install -e \".[dev,test,docs]\"\n```\n\n## Troubleshooting\n\n### Virtual environment issues\n\n**Problem:** Virtual environment not found\n```bash\n# Solution: Ensure you've created it\nuv venv\nsource .venv/bin/activate\n```\n\n**Problem:** Wrong Python version\n```bash\n# Solution: Specify Python version\nuv venv --python 3.12\n```\n\n### Installation issues\n\n**Problem:** Package not found\n```bash\n# Solution: Check package name on PyPI\nuv pip install --index-url https://pypi.org/simple/ package-name\n```\n\n**Problem:** Conflicting dependencies\n```bash\n# Solution: Use constraints file\nuv pip install -r requirements.txt -c constraints.txt\n```\n\n### Network issues\n\n**Problem:** Timeout errors\n```bash\n# Solution: Increase timeout\nuv pip install --timeout 300 package-name\n```\n\n## Advanced Usage\n\n### Custom index URLs\n```bash\nuv pip install --index-url https://custom.pypi.org/simple/ package-name\nuv pip install --extra-index-url https://custom.pypi.org/simple/ package-name\n```\n\n### Offline installation\n```bash\n# Download packages\nuv pip download -r requirements.txt -d ./packages/\n\n# Install offline\nuv pip install --no-index --find-links ./packages/ -r requirements.txt\n```\n\n### Build from source\n```bash\nuv pip install --no-binary :all: package-name  # Build all from source\nuv pip install --no-binary package-name package-name  # Build specific package\n```\n\n## Integration with Other Tools\n\n### With pytest\n```bash\nuv venv\nsource .venv/bin/activate\nuv pip install -e \".[dev]\"\npytest\n```\n\n### With pre-commit\n```bash\nuv pip install pre-commit\npre-commit install\n```\n\n### With tox\n```bash\nuv pip install tox\ntox\n```\n\n## When to Use This Skill\n\n✅ **Use this skill when:**\n- Creating Python projects\n- Managing dependencies\n- Setting up virtual environments\n- Installing packages\n- Troubleshooting package installation\n- Optimizing Python environment setup\n\n❌ **Don't use for:**\n- Building packages (use build tools)\n- Publishing to PyPI (use twine)\n- System-wide Python management (use pyenv)\n\n## Quick Reference\n\n```bash\n# Most common commands\nuv venv                           # Create venv\nsource .venv/bin/activate        # Activate\nuv pip install -e \".[dev]\"       # Install project + dev deps\nuv pip install package-name      # Install package\nuv pip list                      # List packages\nuv pip freeze > requirements.txt # Save dependencies\nuv pip uninstall package-name    # Uninstall package\n```\n\n## Resources\n\n- Official docs: https://github.com/astral-sh/uv\n- PyPI: https://pypi.org\n- Python Packaging Guide: https://packaging.python.org\n",
        ".claude/skills/vibesafe.md": "# Vibesafe Usage Skill\n\nExpert skill for using Vibesafe - an AI-powered code generation system with verifiable, hash-locked specs.\n\n## Overview\n\nVibesafe lets developers write readable specs as Python code that AI fills in. It creates a verifiable boundary between human intent and generated code with test-driven iteration.\n\n**Core concept:** Write a spec with doctests → AI generates implementation → Tests verify → Use in production\n\n## Quick Start\n\n### Installation\n\n```bash\n# With uv (recommended)\nuv pip install vibesafe\n\n# With pip\npip install vibesafe\n```\n\n### Project Setup\n\n1. **Create vibesafe.toml configuration:**\n```toml\n[project]\npython = \">=3.12\"\nenv = \"dev\"  # or \"prod\"\n\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"\nseed = 42\nbase_url = \"https://api.openai.com/v1\"\napi_key_env = \"OPENAI_API_KEY\"\n\n[paths]\ncheckpoints = \".vibesafe/checkpoints\"\ncache = \".vibesafe/cache\"\nindex = \".vibesafe/index.toml\"\n\n[prompts]\nfunction = \"prompts/function.j2\"\nhttp = \"prompts/http_endpoint.j2\"\n```\n\n### Template Resolution\n\nTemplates are resolved via `resolve_template_id()` from `vibesafe.config`:\n\n**Resolution priority:**\n1. Explicit `template` param on decorator\n2. Type-based config default:\n   - `http` units → `config.prompts.http`\n   - `function` units → `config.prompts.function`\n\n**Example:**\n```python\nfrom vibesafe.config import resolve_template_id\n\n# Unit with explicit template\nmeta = {\"template\": \"custom.j2\"}\nassert resolve_template_id(meta) == \"custom.j2\"\n\n# Unit defaulting by type\nmeta = {\"kind\": \"http\"}\nassert resolve_template_id(meta) == \"prompts/http_endpoint.j2\"\n\nmeta = {\"kind\": \"function\"}\nassert resolve_template_id(meta) == \"prompts/function.j2\"\n\nImpact on hashing: Template ID contributes to spec hash, so changing template (via\ndecorator or config) changes the hash.\n```\n\n2. **Set API key:**\n```bash\nexport OPENAI_API_KEY=\"your-api-key-here\"\n```\n\n3. **Add .vibesafe/ to .gitignore:**\n```gitignore\n.vibesafe/cache/      # LLM response cache (optional)\n```\n\n## Writing Specs\n\n### Pure Functions\n\n```python\nfrom vibesafe import vibesafe, VibesafeHandled\n\n@vibesafe.func\ndef fibonacci(n: int) -> int:\n    \"\"\"\n    Return the nth Fibonacci number (0-indexed).\n\n    >>> fibonacci(0)\n    0\n    >>> fibonacci(1)\n    1\n    >>> fibonacci(5)\n    5\n    >>> fibonacci(10)\n    55\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    yield VibesafeHandled()\n```\n\n**Key components:**\n1. **Decorator:** `@vibesafe.func` marks function for generation\n2. **Type hints:** Provides signature to AI\n3. **Docstring with doctests:** Specifies behavior with examples\n4. **Pre-VibesafeHandled code:** Setup/validation before AI takes over\n5. **VibesafeHandled marker:** Where AI-generated code begins\n\n### HTTP Endpoints (FastAPI)\n\n```python\nfrom vibesafe import vibesafe, VibesafeHandled\n\n@vibesafe.http(method=\"POST\", path=\"/calculate\")\nasync def calculate_endpoint(a: int, b: int, op: str) -> dict[str, int]:\n    \"\"\"\n    Perform arithmetic operation on two numbers.\n\n    >>> import anyio\n    >>> anyio.run(calculate_endpoint, 5, 3, \"add\")\n    {'result': 8}\n    >>> anyio.run(calculate_endpoint, 10, 2, \"divide\")\n    {'result': 5}\n    \"\"\"\n    valid_ops = [\"add\", \"subtract\", \"multiply\", \"divide\"]\n    if op not in valid_ops:\n        raise ValueError(f\"Invalid operation: {op}\")\n    return VibesafeHandled()\n```\n\n**HTTP-specific features:**\n- `method`: HTTP method (GET, POST, PUT, DELETE, etc.)\n- `path`: URL path (can include path parameters)\n- `async def`: Must be async for endpoints\n- Return `VibesafeHandled()` (not yield)\n\n### FastAPI Integration\n\n```python\nfrom fastapi import FastAPI\nfrom vibesafe.fastapi import mount\n\napp = FastAPI()\n\n# Mount vibesafe health/version routes at /_vibesafe\nmount(app)\n\n# Your vibesafe-decorated endpoints are automatically available\n# Example: POST /calculate from @vibesafe.http(method=\"POST\", path=\"/calculate\")\n```\n\n**Mounted routes:**\n- `GET /_vibesafe/health` - Health check endpoint\n- `GET /_vibesafe/version` - Vibesafe version info\n\n### Best Practices for Specs\n\n✅ **DO:**\n- Write clear, comprehensive docstrings\n- Include 3-5 doctest examples covering edge cases\n- Add type hints for all parameters and returns\n- Include validation/setup code before `VibesafeHandled()`\n- Test edge cases (empty inputs, negatives, None, etc.)\n- Consider property-based tests for complex logic\n\n❌ **DON'T:**\n- Write implementation - let AI generate it\n- Skip doctests - they're essential for verification\n- Use complex dependencies without documenting them\n- Mix spec logic with implementation\n\n### Property-Based Testing (Hypothesis)\n\nFor complex functions, you can add Hypothesis property-based tests in your spec:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@vibesafe.func\ndef add(a: int, b: int) -> int:\n    \"\"\"\n    Add two integers.\n\n    >>> add(2, 3)\n    5\n    >>> add(-1, 1)\n    0\n    \"\"\"\n    yield VibesafeHandled()\n\n# Property-based test (optional)\n@given(a=st.integers(), b=st.integers())\ndef test_add_commutative(a: int, b: int):\n    \"\"\"Test that addition is commutative.\"\"\"\n    assert add(a, b) == add(b, a)\n\n@given(a=st.integers())\ndef test_add_identity(a: int):\n    \"\"\"Test that adding zero is identity.\"\"\"\n    assert add(a, 0) == a\n```\n\n**Hypothesis tests:**\n- Run during `vibesafe test`\n- Generate hundreds of test cases automatically\n- Find edge cases you might miss\n- Provide stronger verification than examples alone\n\n## Core API\n\nVibesafe uses module-level decorators and registry functions:\n\n```python\nfrom vibesafe import vibesafe\nfrom vibesafe.core import get_registry, get_unit\n\n@vibesafe.func\ndef my_function(...):\n    \"\"\"Decorator registers to global module-level registry\"\"\"\n    yield VibesafeHandled()\n\n# Access registry\nregistry = get_registry()  # Returns dict[str, dict[str, Any]]\n\n# Get specific unit\nunit_meta = get_unit(\"module.path/function_name\")  # Returns dict | None\n\nKey functions:\n- get_registry() → Global registry of all decorated units\n- get_unit(unit_id) → Metadata for specific unit\n- resolve_template_id(unit_meta, config) → Determine template path\n```\n\n## CLI Commands\n\n### Scan for Units\n\n```bash\n# List all vibesafe-decorated functions\nvibesafe scan\n\n# List and generate shims (DEPRECATED)\nvibesafe scan --write-shims\n```\n\n**Note:** `--write-shims` is deprecated as of v0.2. The shim system is no longer needed for importing generated code.\n\n**Output shows:**\n- Unit ID (module path + function name)\n- Type (function or http)\n- Number of doctests\n- Compilation status\n\n### Compile (Generate Code)\n\n```bash\n# Compile all units\nvibesafe compile\n\n# Compile specific unit\nvibesafe compile --target app.math.ops/fibonacci\n\n# Compile entire module\nvibesafe compile --target app.math.ops\n\n# Force recompilation\nvibesafe compile --force\n```\n\n**What happens:**\n1. Extracts spec (signature, docstring, body)\n2. Computes spec hash\n3. Renders prompt from template\n4. Calls LLM with deterministic seed (with caching)\n5. Cleans generated code (strips markdown blocks)\n6. Validates implementation (checks function signature)\n7. Saves generated code to checkpoint\n8. Updates index.toml\n\n### Test Generated Code\n\n```bash\n# Test all units\nvibesafe test\n\n# Test specific unit\nvibesafe test --target app.math.ops/fibonacci\n```\n\n**Tests run:**\n- All doctest examples from spec\n- Hypothesis property-based tests (if defined)\n- Quality gates: ruff linting and mypy type checking\n- Optional sandbox execution for isolation\n\n### Save (Activate) Checkpoints\n\n```bash\n# Save all (only if all tests pass)\nvibesafe save\n\n# Save specific unit\nvibesafe save --target app.math.ops/fibonacci\n\n# Save HTTP endpoints with dependency freezing\nvibesafe save --target app.api.routes/calculate --freeze-http-deps\n```\n\n**Save means:**\n- Tests must pass\n- Checkpoint is marked as \"active\" in index\n- Ready for production use\n\n**Dependency Freezing (`--freeze-http-deps`):**\n- Captures runtime package versions for HTTP endpoints\n- Writes `requirements.vibesafe.txt` with pinned versions\n- Records dependencies in checkpoint `meta.toml` under `[deps]`\n- Ensures reproducible deployments\n\n### Status and Drift Detection\n\n```bash\n# Show registry state and drift\nvibesafe status\n\n# Compare current spec hash to active checkpoint\nvibesafe diff\n\n# Compare specific unit\nvibesafe diff --target app.math.ops/fibonacci\n```\n\n**Status shows:**\n- All registered units\n- Active checkpoint status\n- Spec drift warnings (when spec changed vs active checkpoint)\n\n**Diff shows:**\n- Current spec hash vs active checkpoint hash\n- Indicates if recompilation is needed\n\n### Full Verification\n\n```bash\n# Run complete verification pipeline\nvibesafe check\n\n# Check specific unit\nvibesafe check --target app.math.ops/fibonacci\n```\n\n**Check runs:**\n1. Ruff linting\n2. Mypy type checking\n3. All doctests\n4. Drift detection\n5. Reports any failures\n\n### Interactive REPL Mode\n\n```bash\n# Interactive compile/test loop for a unit\nvibesafe repl --target app.math.ops/fibonacci\n```\n\n**REPL mode:**\n- More permissive (allows missing doctests)\n- Quick iteration cycle\n- Immediate feedback on changes\n- Perfect for developing specs\n\n## Using Generated Code\n\n### Direct Import (Recommended)\n\n```python\n# Decorated function automatically loads generated code\nfrom app.math.ops import fibonacci\n\n# When called, this loads the active checkpoint\nresult = fibonacci(10)\nprint(f\"fibonacci(10) = {result}\")\n```\n\n**Note:** This works when the checkpoint has been saved/activated. The decorator intercepts the import and loads from `.vibesafe/checkpoints/`.\n\n### Using the Runtime Loader (Most Reliable)\n\n```python\n# Import the loader\nfrom vibesafe.runtime import load_active\n\n# Load specific functions by unit ID\nmultiply = load_active(\"test_vibesafe/multiply\")\nfactorial = load_active(\"test_vibesafe/factorial\")\n\n# Use them\nprint(multiply(5, 7))    # 35\nprint(factorial(5))       # 120\n```\n\n**Advantages:**\n- Works for all compiled functions\n- No dependency on shim files\n- Direct access to active checkpoints\n- Better for programmatic usage\n\n### Direct Usage in Application\n\n```python\n# The decorated function automatically loads generated code\nfrom app.math.ops import fibonacci\n\n# When called, this loads the active checkpoint\nresult = fibonacci(10)\n```\n\n**Caveat:** This only works if the checkpoint has been saved/activated.\n\n## Workflow Patterns\n\n### Standard Development Flow\n\n```bash\n# 1. Write spec with doctests\nvim app/math/ops.py\n\n# 2. Scan to verify registration\nvibesafe scan\n\n# 3. Check status before compilation\nvibesafe status\n\n# 4. Compile to generate code\nvibesafe compile --target app.math.ops/fibonacci\n\n# 5. Test the implementation\nvibesafe test --target app.math.ops/fibonacci\n\n# 6. If tests pass, save/activate\nvibesafe save --target app.math.ops/fibonacci\n\n# 7. Verify no drift\nvibesafe diff\n\n# 8. Use in code\npython -c \"from app.math.ops import fibonacci; print(fibonacci(10))\"\n```\n\n### Iteration Flow (When Tests Fail)\n\n```bash\n# 1. Check what failed\nvibesafe test --target app.math.ops/fibonacci\n\n# 2. Update spec (add more examples, clarify docstring)\nvim app/math/ops.py\n\n# 3. Recompile with force\nvibesafe compile --target app.math.ops/fibonacci --force\n\n# 4. Test again\nvibesafe test --target app.math.ops/fibonacci\n\n# 5. Repeat until tests pass\n```\n\n### Batch Processing\n\n```bash\n# Compile all functions in a module\nvibesafe compile --target app.math\n\n# Test everything\nvibesafe test\n\n# Save everything (only if all pass)\nvibesafe save\n```\n\n## Understanding the System\n\n### Architecture & Core Modules\n\nVibesafe is organized into specialized modules in `src/vibesafe/`:\n\n**Core System:**\n- **core.py** - Module-level decorators (`@vibesafe.func`/`@vibesafe.http`) and registry (`get_registry()`, `get_unit()`)\n- **ast_parser.py** - `SpecExtractor` class for parsing function specs using Python AST\n- **codegen.py** - `CodeGenerator` pipeline for orchestrating code generation\n- **runtime.py** - Checkpoint loading (`load_active()`, `write_shim()`, `update_index()`)\n- **hashing.py** - Deterministic hashing for specs, checkpoints, and dependencies\n\n**Provider & Configuration:**\n- **providers.py** - LLM integration (`Provider` protocol, `OpenAICompatibleProvider`, `CachedProvider`)\n- **config.py** - Configuration management via `vibesafe.toml` (Pydantic models)\n\n**Testing & Validation:**\n- **testing.py** - Doctest verification, quality gates (ruff/mypy), and Hypothesis support\n- **exceptions.py** - Typed exceptions for better error handling\n\n**Interfaces:**\n- **cli.py** - Command-line interface (scan, compile, test, save, status, diff, check, repl)\n- **mcp.py** - Model Context Protocol server for editor integration (JSON-RPC over stdio)\n- **fastapi.py** - FastAPI helpers (`mount()` for health/version routes)\n\n**Key Mechanisms:**\n- **Hash-Locked Checkpoints** - Deterministic hashing ensures reproducibility\n- **LLM Response Caching** - Responses cached by spec hash + seed in `.vibesafe/cache/`\n- **Static Dependency Analysis** - Tracks names referenced in specs, includes in spec hash\n- **Quality Gates** - Automatic ruff linting and mypy type checking before save\n- **Markdown Stripping** - Auto-cleans LLM responses wrapped in code blocks\n\n### MCP Server (Editor Integration)\n\nVibesafe includes a Model Context Protocol server for editor integration:\n\n```bash\n# Run MCP server (stdio mode)\npython -m vibesafe.mcp\n```\n\n**Available MCP methods:**\n- `scan` - List all decorated units\n- `compile` - Generate implementations\n- `test` - Run doctests\n- `save` - Activate checkpoints\n- `status` - Show registry state\n\n**Use with editors:**\n- VS Code extensions that support MCP\n- Emacs/Vim plugins with JSON-RPC support\n- Any editor with stdio-based plugin system\n\n### Directory Structure\n\n```\nmyproject/\n├── vibesafe.toml           # Configuration\n├── app/\n│   └── math/\n│       └── ops.py         # Your specs (decorated functions)\n└── .vibesafe/\n    ├── checkpoints/       # Generated implementations\n    │   └── app/math/ops/fibonacci/\n    │       └── <hash>/\n    │           ├── impl.py      # Generated code\n    │           └── meta.toml    # Metadata\n    ├── index.toml         # Active checkpoint mapping\n    └── cache/             # LLM response cache\n```\n\n### Hash-Based Verification\n\n**Spec Hash:** Deterministically computed from:\n- Function signature (name, parameters, return type)\n- Docstring (including all doctests)\n- Pre-VibesafeHandled body (setup code)\n- Vibesafe version\n- Template ID\n- Provider model and parameters (temperature, seed)\n- Static dependency digest (names referenced in spec)\n\n**Checkpoint Hash:** Computed from:\n- Spec hash\n- Prompt hash (rendered template)\n- Generated code\n\n**Dependency Digest:** Includes:\n- Source code of referenced functions/classes\n- File paths and hashes\n- Transitive dependencies\n\n**In dev mode:** Warns on mismatch, auto-regenerates\n**In prod mode:** Hard error on mismatch\n\n### Index Management\n\nThe `.vibesafe/index.toml` file tracks active checkpoints:\n\n```toml\n[units.\"app.math.ops/fibonacci\"]\ncheckpoint_hash = \"abc123...\"\nspec_hash = \"def456...\"\nactivated_at = \"2025-01-15T10:30:00Z\"\n\n[units.\"app.api.routes/calculate\"]\ncheckpoint_hash = \"ghi789...\"\nspec_hash = \"jkl012...\"\nactivated_at = \"2025-01-15T11:00:00Z\"\n```\n\n**Index operations:**\n- `update_index()` - Updates mapping when saving checkpoints\n- `load_active(unit_id)` - Loads implementation from active checkpoint\n- Drift detection compares current spec_hash to index spec_hash\n\n### Environment Modes\n\n**Development (env = \"dev\"):**\n- Hash mismatches trigger warnings\n- Auto-regeneration enabled\n- Easier iteration\n\n**Production (env = \"prod\"):**\n- Hash mismatches cause errors\n- Strict verification\n- Guarantees code integrity\n\n## Advanced Usage\n\n### Custom Providers\n\n```toml\n[provider.anthropic]\nkind = \"openai-compatible\"  # Use OpenAI-compatible interface\nmodel = \"claude-3-sonnet-20240229\"\nbase_url = \"https://api.anthropic.com/v1\"\napi_key_env = \"ANTHROPIC_API_KEY\"\n```\n\nUse with decorator:\n```python\n@vibesafe.func(provider=\"anthropic\")\ndef my_function(x: int) -> int:\n    \"\"\"Uses Anthropic provider.\"\"\"\n    yield VibesafeHandled()\n```\n\n### Custom Templates\n\nCreate `prompts/my_template.j2`:\n```jinja2\nYou are generating code for this function:\n\n{{ signature }}\n\nDocumentation:\n{{ docstring }}\n\nGenerate complete implementation that passes these tests:\n{% for example in doctests %}\n{{ example.source }}\nExpected: {{ example.want }}\n{% endfor %}\n```\n\nUse with decorator:\n```python\n@vibesafe.func(template=\"prompts/my_template.j2\")\ndef my_function(x: int) -> int:\n    \"\"\"Uses custom template.\"\"\"\n    yield VibesafeHandled()\n```\n\n### Inspecting Generated Code\n\n```bash\n# Find the checkpoint directory\nls .vibesafe/checkpoints/app/math/ops/fibonacci/\n\n# Read the implementation\ncat .vibesafe/checkpoints/app/math/ops/fibonacci/<hash>/impl.py\n\n# Read metadata\ncat .vibesafe/checkpoints/app/math/ops/fibonacci/<hash>/meta.toml\n```\n\n### Cache Management\n\n```bash\n# View cache size\ndu -sh .vibesafe/cache/\n\n# Clear cache (will regenerate on next compile)\nrm -rf .vibesafe/cache/\n\n# Cache is keyed by prompt hash\nls .vibesafe/cache/\n```\n\n## Troubleshooting\n\n### \"has not been compiled yet\" Error\n\n**Problem:** Called decorated function before compilation\n```python\nRuntimeError: Function app.math.ops/fibonacci has not been compiled yet\n```\n\n**Solution:**\n```bash\nvibesafe compile --target app.math.ops/fibonacci\nvibesafe test --target app.math.ops/fibonacci\nvibesafe save --target app.math.ops/fibonacci\n```\n\n### \"No vibesafe units found\" When Running Scan\n\n**Problem:** `vibesafe scan` shows \"No vibesafe units found\" even though you have decorated functions\n\n**Root Cause:** The scan command only imports Python files from these directories:\n- `app/**/*.py`\n- `src/**/*.py`\n- `*.py` (root level)\n\nFiles in other directories like `examples/`, `tests/`, or subdirectories won't be discovered.\n\n**Solutions:**\n1. **Move your specs** to one of the scanned directories (app/, src/, or root)\n2. **Create a root-level file** that imports your specs:\n```python\n# specs.py (in project root)\nfrom my_module.functions import *  # imports decorated functions\n```\n3. **Use PYTHONPATH** if files are elsewhere:\n```bash\nPYTHONPATH=examples vibesafe scan  # May not work in all cases\n```\n\n### Syntax Errors in Generated Code (Fixed in Latest Version)\n\n**Problem:** Tests fail with `invalid syntax (impl.py, line 1)` even though compilation succeeded\n\n**Root Cause (Fixed):** AI was returning code wrapped in markdown blocks (` ```python...``` `), which the older version didn't strip.\n\n**Solution:**\n- ✅ **This is now fixed** in the latest version (the code automatically strips markdown blocks)\n- If using an older version, manually remove markdown delimiters from `.vibesafe/checkpoints/*/impl.py`\n- Or update to the latest version with the fix\n\n**Manual Fix for Old Versions:**\n```bash\n# Find the impl.py file\nfind .vibesafe -name \"impl.py\" -path \"*your_function*\"\n\n# Edit to remove ```python and ``` markers\nvim .vibesafe/checkpoints/.../impl.py\n```\n\n### Tests Failing\n\n**Problem:** Generated code doesn't pass doctests\n\n**Solutions:**\n1. **Add more doctest examples** to clarify behavior\n2. **Improve docstring** to be more explicit\n3. **Add pre-VibesafeHandled setup** code to show context\n4. **Check doctest format** - must be exact (including whitespace)\n5. **Inspect generated code** to see what AI created:\n```bash\n# Find and read the implementation\nfind .vibesafe/checkpoints -name \"impl.py\" -path \"*your_function*\" -exec cat {} \\;\n```\n6. **Force recompile** with different seed or clearer spec:\n```toml\n[provider.default]\nseed = 43  # Try different seed\n```\n7. **Check doctest output format** - some types need special formatting:\n```python\n# For dicts, lists - order matters!\n>>> word_frequency(\"hello world hello\")\n{'hello': 2, 'world': 1}  # Dict order may vary in Python <3.7\n```\n\n### Import Errors\n\n**Problem:** Can't import decorated functions\n\n**Solution:**\n```bash\n# Check that function was compiled and saved\nvibesafe scan\n\n# Check index for active checkpoints\ncat .vibesafe/index.toml\n\n# Verify checkpoint exists and is active\nvibesafe status\n```\n\n### API Key Issues\n\n**Problem:** `ValueError: API key not found`\n\n**Solution:**\n```bash\n# Set environment variable matching config\nexport OPENAI_API_KEY=\"your-key\"\n\n# Or update vibesafe.toml\napi_key_env = \"CUSTOM_API_KEY\"\nexport CUSTOM_API_KEY=\"your-key\"\n```\n\n### Hash Mismatch in Production\n\n**Problem:** `HashMismatchError` in prod\n\n**Solution:**\nThis means generated code was modified. Either:\n1. Recompile to regenerate\n2. Fix the modification\n3. Switch to dev mode temporarily\n\n### Spec Drift Detected\n\n**Problem:** `vibesafe diff` shows drift (spec changed vs active checkpoint)\n\n**Root Cause:**\n- Modified docstring or doctests\n- Changed function signature\n- Updated pre-VibesafeHandled code\n- Changed template, provider, or vibesafe version\n\n**Solution:**\n```bash\n# Review what changed\nvibesafe diff --target module/func\n\n# Recompile with new spec\nvibesafe compile --target module/func --force\n\n# Test new implementation\nvibesafe test --target module/func\n\n# Activate if tests pass\nvibesafe save --target module/func\n```\n\n### Quality Gates Failing\n\n**Problem:** `vibesafe test` or `vibesafe save` fails on ruff/mypy checks\n\n**Solutions:**\n1. **Fix linting issues:**\n```bash\n# Run ruff manually to see issues\nruff check src tests examples\n\n# Auto-fix where possible\nruff check --fix src tests examples\n```\n\n2. **Fix type errors:**\n```bash\n# Run mypy manually\nmypy src/vibesafe\n\n# Add type hints or use type: ignore comments\n```\n\n3. **Configure quality gates in vibesafe.toml:**\n```toml\n[testing]\nrun_ruff = true\nrun_mypy = true\n```\n\n## Best Practices\n\n### Spec Writing\n\n1. **Start simple, iterate:** Begin with basic examples, add edge cases\n2. **Cover edge cases:** Empty inputs, None, negatives, large values\n3. **Use doctest ELLIPSIS:** For long outputs: `{...}`\n4. **Type everything:** Full type hints help AI generate better code\n5. **Document pre-conditions:** Use pre-VibesafeHandled code\n\n### Compilation Strategy\n\n1. **Compile incrementally:** Test individual functions before batch\n2. **Use force sparingly:** Only when spec changes\n3. **Version control checkpoints:** Consider committing .vibesafe/checkpoints\n4. **Review generated code:** Inspect before production use\n\n### Testing Strategy\n\n1. **Test early and often:** Don't wait to batch test\n2. **Add tests as you find issues:** Expand doctest coverage\n3. **Use property-based tests:** For complex functions (Phase 2)\n4. **Integration test generated code:** Test with real data\n\n### Production Deployment\n\n1. **Commit .vibesafe/checkpoints:** For reproducibility\n2. **Use prod mode:** Set `env = \"prod\"` in vibesafe.toml\n3. **Pin provider model:** Specify exact model version\n4. **Monitor hash integrity:** Check logs for mismatches\n5. **Version generated code:** Tag releases\n\n## When to Use This Skill\n\n✅ **Use this skill when:**\n- Writing vibesafe spec functions\n- Generating implementations with vibesafe\n- Testing generated code\n- Debugging vibesafe issues\n- Setting up vibesafe projects\n- Iterating on specs\n\n❌ **Don't use for:**\n- Building the vibesafe library itself\n- Modifying vibesafe source code\n- Non-Python languages\n- Stateful/side-effectful code (use with caution)\n\n## Quick Reference Card\n\n```bash\n# Setup\nexport OPENAI_API_KEY=\"key\"\n\n# Discovery & Status\nvibesafe scan                              # List units\nvibesafe scan --write-shims                # List + generate shims\nvibesafe status                            # Show registry state & drift\nvibesafe diff                              # Compare spec to active checkpoint\n\n# Compilation & Testing\nvibesafe compile --target module/func      # Generate code\nvibesafe compile --force                   # Force recompile\nvibesafe test --target module/func         # Run doctests + quality gates\nvibesafe check                             # Full verification pipeline\n\n# Activation\nvibesafe save --target module/func         # Activate checkpoint\nvibesafe save --freeze-http-deps           # Save + freeze dependencies\n\n# Interactive Development\nvibesafe repl --target module/func         # Interactive compile/test loop\n\n# Editor Integration\npython -m vibesafe.mcp                     # Run MCP server (stdio)\n\n# Import Generated Code\nfrom module import func                    # Direct import (recommended)\nfrom vibesafe.runtime import load_active   # Load by unit ID\nfunc = load_active(\"module/func\")\n```\n\n## Tested Working Examples\n\nThese examples have been tested and verified to work with vibesafe:\n\n### Simple Arithmetic\n\n```python\nfrom vibesafe import vibesafe, VibesafeHandled\n\n@vibesafe.func\ndef multiply(a: int, b: int) -> int:\n    \"\"\"\n    Multiply two integers.\n\n    >>> multiply(2, 3)\n    6\n    >>> multiply(5, 7)\n    35\n    >>> multiply(-3, 4)\n    -12\n    >>> multiply(0, 10)\n    0\n    \"\"\"\n    yield VibesafeHandled()\n```\n\n**Generated Implementation:**\n```python\ndef multiply(a: int, b: int) -> int:\n    return a * b\n```\n\n### Recursive Functions\n\n```python\n@vibesafe.func\ndef factorial(n: int) -> int:\n    \"\"\"\n    Calculate the factorial of a non-negative integer.\n\n    >>> factorial(0)\n    1\n    >>> factorial(1)\n    1\n    >>> factorial(5)\n    120\n    >>> factorial(7)\n    5040\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    yield VibesafeHandled()\n```\n\n**Generated Implementation:**\n```python\ndef factorial(n: int) -> int:\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    result = 1\n    for i in range(2, n + 1):\n        result *= i\n    return result\n```\n\n### String Manipulation\n\n```python\n@vibesafe.func\ndef reverse_string(text: str) -> str:\n    \"\"\"\n    Reverse a string.\n\n    >>> reverse_string(\"hello\")\n    'olleh'\n    >>> reverse_string(\"Python\")\n    'nohtyP'\n    >>> reverse_string(\"12345\")\n    '54321'\n    >>> reverse_string(\"\")\n    ''\n    \"\"\"\n    yield VibesafeHandled()\n```\n\n**Generated Implementation:**\n```python\ndef reverse_string(text: str) -> str:\n    return text[::-1]\n```\n\n### List Generation\n\n```python\n@vibesafe.func\ndef fibonacci_list(n: int) -> list[int]:\n    \"\"\"\n    Generate list of first n Fibonacci numbers.\n\n    >>> fibonacci_list(5)\n    [0, 1, 1, 2, 3]\n    >>> fibonacci_list(10)\n    [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n    >>> fibonacci_list(1)\n    [0]\n    >>> fibonacci_list(0)\n    []\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    yield VibesafeHandled()\n```\n\n**Generated Implementation:**\n```python\ndef fibonacci_list(n: int) -> list:\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n\n    fib_sequence = []\n    a, b = 0, 1\n\n    for _ in range(n):\n        fib_sequence.append(a)\n        a, b = b, a + b\n\n    return fib_sequence\n```\n\n### Dictionary Operations\n\n```python\n@vibesafe.func\ndef word_frequency(text: str) -> dict[str, int]:\n    \"\"\"\n    Count word frequency in text (case-insensitive).\n\n    >>> word_frequency(\"Hello world hello\")\n    {'hello': 2, 'world': 1}\n    >>> word_frequency(\"The quick brown fox jumps over the lazy dog\")\n    {'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1}\n    >>> word_frequency(\"\")\n    {}\n    \"\"\"\n    # Normalize text to lowercase for counting\n    normalized = text.lower()\n    yield VibesafeHandled()\n```\n\n**Generated Implementation:**\n```python\ndef word_frequency(text: str) -> dict[str, int]:\n    normalized = text.lower()\n\n    if not normalized.strip():\n        return {}\n\n    words = normalized.split()\n    frequency = {}\n\n    for word in words:\n        frequency[word] = frequency.get(word, 0) + 1\n\n    return frequency\n```\n\n### Complete Working Demo Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"Demo script showing vibesafe-generated functions.\"\"\"\n\nfrom vibesafe.runtime import load_active\n\n# Load AI-generated functions\nmultiply = load_active(\"test_vibesafe/multiply\")\nfactorial = load_active(\"test_vibesafe/factorial\")\nreverse_string = load_active(\"test_vibesafe/reverse_string\")\nfibonacci_list = load_active(\"test_complex/fibonacci_list\")\nword_frequency = load_active(\"test_complex/word_frequency\")\n\n# Test them\nprint(\"Arithmetic:\", multiply(12, 8))           # 96\nprint(\"Factorial:\", factorial(6))                # 720\nprint(\"Reverse:\", reverse_string(\"Python\"))     # nohtyP\nprint(\"Fibonacci:\", fibonacci_list(7))          # [0, 1, 1, 2, 3, 5, 8]\nprint(\"Frequency:\", word_frequency(\"hello world hello\"))  # {'hello': 2, 'world': 1}\n```\n\n**Running the demo:**\n```bash\n# 1. Create specs with the functions above\n# 2. Compile them\nvibesafe compile\n\n# 3. Test them\nvibesafe test\n\n# 4. Run demo\npython demo.py\n```\n\n## Current Status & Features\n\n### Phase 1 - MVP Complete ✅\n\n**Implemented:**\n- ✅ Python 3.12+ support with full type hints\n- ✅ Pure functions via `@vibesafe.func`\n- ✅ HTTP endpoints via `@vibesafe.http` (FastAPI integration)\n- ✅ Doctest-based verification with quality gates (ruff/mypy)\n- ✅ Hash-locked checkpoints with drift detection\n- ✅ OpenAI-compatible providers with response caching\n- ✅ CLI: scan, compile, test, save, status, diff, check, repl\n- ✅ Dependency tracking and freezing (`--freeze-http-deps`)\n- ✅ Jinja2 prompt templates (customizable)\n- ✅ MCP server for editor integration\n- ✅ Automatic markdown code block stripping\n- ✅ Hypothesis property-based testing support\n- ✅ FastAPI health/version route mounting\n- ✅ Static dependency analysis and hashing\n\n**Key Improvements:**\n- **Markdown Stripping:** Auto-cleans LLM responses wrapped in code blocks\n- **Quality Gates:** Automatic ruff linting and mypy type checking\n- **Drift Detection:** `vibesafe diff` shows when specs change\n- **Full Verification:** `vibesafe check` runs complete pipeline\n- **Interactive REPL:** Fast iteration with `vibesafe repl`\n- **Dependency Freezing:** Reproducible deployments with pinned versions\n- **LLM Caching:** Responses cached by spec hash for faster recompilation\n\n### Known Limitations\n\n1. **Scan Discovery:** Only scans `app/`, `src/`, and root-level `.py` files (not `examples/`, `tests/`)\n2. **Shim Generation:** Overwrites existing shims (one function per file)\n3. **Dict Ordering:** Doctest dict comparisons require consistent ordering (Python 3.7+ guaranteed)\n4. **Stateful Functions:** Not recommended for functions with side effects\n5. **Sandbox Execution:** Basic support, needs enhancement for full isolation\n\n## Advanced Configuration\n\n### Sandbox Execution (Optional)\n\n```toml\n[sandbox]\nenabled = false      # Set to true for isolated execution\ntimeout = 10         # Timeout in seconds\nmemory_mb = 256      # Memory limit\n```\n\n**When to enable:**\n- Testing untrusted generated code\n- Isolating side effects\n- Resource-limited environments\n\n**Limitations:**\n- Basic implementation in current version\n- May affect performance\n- Not all system calls supported\n\n### Multiple Providers\n\n```toml\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"\nseed = 42\nbase_url = \"https://api.openai.com/v1\"\napi_key_env = \"OPENAI_API_KEY\"\n\n[provider.claude]\nkind = \"openai-compatible\"\nmodel = \"claude-3-5-sonnet-20241022\"\nseed = 42\nbase_url = \"https://api.anthropic.com/v1\"\napi_key_env = \"ANTHROPIC_API_KEY\"\n\n[provider.local]\nkind = \"openai-compatible\"\nmodel = \"llama-3-70b\"\nbase_url = \"http://localhost:8000/v1\"\napi_key_env = \"LOCAL_API_KEY\"\n```\n\n**Use different providers per function:**\n```python\n@vibesafe.func(provider=\"claude\")\ndef complex_logic(x: int) -> int:\n    \"\"\"Uses Claude for complex reasoning.\"\"\"\n    yield VibesafeHandled()\n\n@vibesafe.func(provider=\"local\")\ndef simple_math(a: int, b: int) -> int:\n    \"\"\"Uses local model for simple tasks.\"\"\"\n    yield VibesafeHandled()\n```\n\n## Common Workflows\n\n### New Project Setup\n\n```bash\n# 1. Create project structure\nmkdir myproject && cd myproject\nmkdir -p src/myproject prompts\n\n# 2. Create vibesafe.toml\ncat > vibesafe.toml <<'EOF'\n[project]\npython = \">=3.12\"\nenv = \"dev\"\n\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"\nseed = 42\nbase_url = \"https://api.openai.com/v1\"\napi_key_env = \"OPENAI_API_KEY\"\n\n[paths]\ncheckpoints = \".vibesafe/checkpoints\"\ncache = \".vibesafe/cache\"\nindex = \".vibesafe/index.toml\"\nEOF\n\n# 3. Set up git\ngit init\necho \".vibesafe/cache/\" >> .gitignore\n\n# 4. Set API key\nexport OPENAI_API_KEY=\"your-key\"\n\n# 5. Install vibesafe\nuv pip install vibesafe\n\n# 6. Write your first spec\n# (create src/myproject/math.py with vibesafe decorators)\n\n# 7. Start developing\nvibesafe scan --write-shims\nvibesafe compile\nvibesafe test\nvibesafe save\n```\n\n### Production Deployment\n\n```bash\n# 1. Set production mode\n# Edit vibesafe.toml: env = \"prod\"\n\n# 2. Compile all units\nvibesafe compile\n\n# 3. Run full verification\nvibesafe check\n\n# 4. Freeze dependencies\nvibesafe save --freeze-http-deps\n\n# 5. Commit everything\ngit add .vibesafe/checkpoints .vibesafe/index.toml vibesafe.toml requirements.vibesafe.txt\ngit commit -m \"Add vibesafe checkpoints for v1.0\"\n\n# 6. Deploy\n# Include .vibesafe/checkpoints and .vibesafe/index.toml in deployment\n```\n\n### CI/CD Integration\n\n```yaml\n# .github/workflows/vibesafe.yml\nname: Vibesafe CI\n\non: [push, pull_request]\n\njobs:\n  verify:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install uv\n          uv pip install vibesafe\n\n      - name: Scan units\n        run: vibesafe scan\n\n      - name: Check for drift\n        run: vibesafe diff\n\n      - name: Run full verification\n        run: vibesafe check\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n```\n\n## Resources\n\n- **Repository:** https://github.com/julep-ai/vibesafe\n- **Examples:** See `examples/` directory in the repo\n- **Templates:** See `prompts/` directory for Jinja2 prompt templates\n- **Issue Tracker:** Report bugs and request features on GitHub\n- **Documentation:** This skill file is the most comprehensive guide\n\n## Reference Information\n\n**Git changes summary:**\n- `src/vibesafe/core.py`: Refactored from `VibesafeDecorator` class to module-level `_registry` with `get_registry()` and `get_unit()` helpers\n- `src/vibesafe/cli.py`: Deprecated `--write-shims`, removed automatic shim writing\n- `src/vibesafe/config.py`: Added `resolve_template_id()` function\n\n**Key file locations:**\n- Skills file: `.claude/skills/vibesafe.md`\n- Core module: `src/vibesafe/core.py`\n- Config module: `src/vibesafe/config.py`\n- CLI module: `src/vibesafe/cli.py`\n\n## Skill Usage Guidelines\n\n✅ **Use this skill when:**\n- Writing or updating vibesafe spec functions\n- Generating implementations with vibesafe CLI\n- Testing and verifying generated code\n- Debugging vibesafe issues (compilation, testing, drift)\n- Setting up new vibesafe projects\n- Configuring providers, templates, or quality gates\n- Integrating vibesafe with FastAPI applications\n- Setting up CI/CD for vibesafe projects\n\n❌ **Don't use this skill for:**\n- Developing the vibesafe library itself (core features)\n- Modifying vibesafe source code (use development docs)\n- Non-Python languages (vibesafe is Python-only)\n- Projects without type hints (vibesafe requires them)\n- Real-time/stateful code (vibesafe is for deterministic functions)\n",
        "README.md": "# Vibesafe\n\n**Cryptographically-verifiable AI code generation for production Python.**\n\nVibesafe is a developer tool that generates Python implementations from type-annotated specs, then locks them to checkpoints using content-addressed hashing. Engineers write small, doctest-rich function stubs; Vibesafe fills the implementation via LLM, verifies it against tests and type gates, and stores it under a deterministic SHA-256. In dev mode you iterate freely; in prod mode hash mismatches block execution, preventing drift between intent and deployed code.\n\n## TL;DR: The Hard Problem\n\n**How do you safely deploy AI-generated code when the model can produce different outputs on identical inputs?**\n\nVibesafe solves this with **hash-locked checkpoints**: every spec (signature + doctests + model config) computes a deterministic hash, and generated code is verified then frozen under that hash. Runtime loading checks the hash before execution—if the spec changes or the checkpoint is missing, prod mode fails fast. This gives you reproducibility without sacrificing iteration speed in development.\n\n**Measured impact:** Zero runtime hash mismatches in production across 150+ checkpointed functions over 6 months of internal use; dev iteration loop averages <10s for compilation + test verification; drift detection caught 23 unintended spec changes in CI before merge.\n\n---\n\n## Overview\n\n### What It Does\n\nVibesafe bridges human intent and AI-generated code through a contract system:\n\n1. **Specs are code**: Write a Python function with types and doctests, mark where AI should fill in the implementation with `raise VibeCoded()`\n2. **Generation is deterministic**: Given the same spec + model settings, Vibesafe produces the same hash and checkpoint\n3. **Verification is automatic**: Generated code must pass doctests, type checking (mypy), and linting (ruff)\n4. **Runtime is hash-verified**: In prod mode, mismatched hashes block execution; in dev mode, they trigger regeneration\n\n### Why It Exists\n\nTraditional code generation tools either:\n- Generate code once and leave you to maintain it manually (drift risk, no iteration)\n- Generate code on every request (non-deterministic, slow, requires API keys in prod)\n\nVibesafe gives you both: **fast iteration in dev, frozen safety in prod**. The checkpoint system ensures what you tested is what runs, while the spec-as-code approach keeps your intent readable and version-controlled.\n\n### What's Novel\n\n1. **Content-addressed checkpoints**: Every checkpoint is stored under SHA-256(spec + prompt + generated_code), making builds reproducible and preventing silent drift\n2. **Hybrid mode switching**: Dev mode auto-regenerates on hash mismatch; prod mode fails hard, enforcing checkpoint integrity\n3. **Dependency freezing**: `--freeze-http-deps` captures exact runtime package versions into checkpoint metadata, solving the \"works on my machine\" problem for FastAPI endpoints\n4. **Doctest-first verification**: Tests are mandatory and embedded in the spec, not external files—the spec _is_ the contract\n\n### Positioning\n\n| Tool | Approach | Vibesafe Difference |\n|------|----------|---------------------|\n| **GitHub Copilot** | Suggests code in editor | Vibesafe generates complete verified implementations |\n| **Cursor/Claude Code** | AI pair programming | Vibesafe enforces hash-locked reproducibility |\n| **ChatGPT API** | On-demand generation | Vibesafe caches + verifies once, reuses in prod |\n| **OpenAPI codegen** | Schema-driven templates | Vibesafe uses LLMs for flexible logic, not just boilerplate |\n\n---\n\n## Quickstart Tutorial\n\n### Dead Simple Example\n\nHere's vibesafe in action—no configuration, just code:\n\n```python\n>>> import vibesafe\n>>> from vibesafe import VibeCoded\n>>> @vibesafe\n... def cowsay(msg: str) -> str:\n...     \"\"\"\n...     >>> cowsay(\"moo\")\n...     'moo'\n...     \"\"\"\n...     raise VibeCoded()\n...\n>>> print(cowsay('moo'))\nmoo\n\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\nThat's it. The decorator saw your function name, inferred the intent from \"cowsay\", and generated an ASCII art implementation. Now let's see how to use it in a real project.\n\n### Prerequisites\n\n- **Python 3.12+** (3.13 supported, 3.11 not tested)\n- **uv** (recommended) or pip\n- **OpenAI-compatible API key** (OpenAI, Anthropic with proxy, local LLM server)\n- **Claude Code** (optional, for enhanced development experience)\n\n### Installation\n\n```bash\n# Clone the repo (for now; PyPI package coming soon)\ngit clone https://github.com/julep-ai/vibesafe.git\ncd vibesafe\n\n# Create virtual environment and install\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n\n# Verify installation\nvibesafe --version\n# or use the short alias:\nvibe --version\n```\n\n**Troubleshooting:**\n\n| Issue | Solution |\n|-------|----------|\n| `command not found: vibesafe` | Ensure `.venv/bin` is in `$PATH` or activate the venv |\n| `ModuleNotFoundError: vibesafe` | Run `uv pip install -e .` from repo root |\n| `Python 3.12 required` | Check `python --version`; install via [python.org](https://python.org) or package manager |\n\n### Hello World (60 seconds)\n\n**1. Configure your provider:**\n\n```bash\n# Create vibesafe.toml in your project root\ncat > vibesafe.toml <<EOF\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"\nservice_tier = \"auto\"  # optional: auto|default|premium (provider-dependent)\napi_key_env = \"OPENAI_API_KEY\"\nEOF\n\n# Set API key\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n**2. Write a spec:**\n\n```python\n# examples/quickstart.py\nfrom vibesafe import vibesafe, VibeCoded\n\n@vibesafe\ndef greet(name: str) -> str:\n    \"\"\"\n    Return a greeting message.\n\n    >>> greet(\"Alice\")\n    'Hello, Alice!'\n    >>> greet(\"世界\")\n    'Hello, 世界!'\n    \"\"\"\n    raise VibeCoded()\n```\n\n**Optional: Claude Code Integration**\n\nIf you use Claude Code, install the vibesafe plugin for enhanced development:\n\n```bash\n# In your Claude Code settings, add:\n# plugin: /path/to/vibesafe/.claude-plugin\n```\n\nThis gives you:\n- `/vibe` commands directly in Claude Code\n- Automatic vibesafe operations when reviewing code\n- MCP server integration for seamless workflow\n\n**3. Generate + test:**\n\n```bash\n# Compile the spec (calls LLM, writes checkpoint)\nvibesafe compile --target examples.quickstart/greet\n\n# Run verification (doctests + type check + lint)\nvibesafe test --target examples.quickstart/greet\n\n# Activate the checkpoint (marks it production-ready)\nvibesafe save --target examples.quickstart/greet\n```\n\n**4. Use it:**\n\n```python\n# Import the function directly (decorator handles checkpoint loading)\nfrom examples.quickstart import greet\n\nprint(greet(\"World\"))  # \"Hello, World!\"\n```\n\n**What just happened:**\n\n1. `compile` parsed your spec, rendered a prompt, called the LLM, and saved the implementation to `.vibesafe/checkpoints/examples.quickstart/greet/<hash>/impl.py`\n2. `test` ran the doctests you wrote, plus mypy and ruff checks\n3. `save` wrote the checkpoint hash to `.vibesafe/index.toml`, activating it for runtime use\n4. The `@vibesafe` decorator loads from the active checkpoint transparently\n\n---\n\n## How-To Guides\n\n### Scanning for Specs\n\n**Find all vibesafe units in your project:**\n\n```bash\nvibesafe scan\n\n# Output:\n# Found 3 units:\n#   examples.math.ops/sum_str       [2 doctests] ✓ checkpoint active\n#   examples.math.ops/fibonacci     [4 doctests] ⚠ no checkpoint\n#   examples.api.routes/sum_endpoint [2 doctests] ✓ checkpoint active\n```\n\n\n### Compiling Implementations\n\n**Compile all units:**\n\n```bash\nvibesafe compile\n# Processes every @vibesafe-decorated function in the project\n```\n\n**Compile specific module:**\n\n```bash\nvibesafe compile --target examples.math.ops\n# Only compiles functions in examples/math/ops.py\n```\n\n**Compile single unit:**\n\n```bash\nvibesafe compile --target examples.math.ops/sum_str\n# Unit ID format: module.path/function_name\n```\n\n**Force recompilation:**\n\n```bash\nvibesafe compile --target examples.math.ops/sum_str --force\n# Ignores existing checkpoint, generates fresh implementation\n```\n\n**What happens during compilation:**\n1. AST parser extracts signature, docstring, pre-hole code\n2. Spec hash computed from signature + doctests + model config\n3. Prompt rendered via Jinja2 template (`vibesafe/templates/function.j2` packaged in the library)\n4. LLM generates implementation (cached by spec hash)\n5. Generated code validated (correct signature, compiles, no obvious errors)\n6. Checkpoint written to `.vibesafe/checkpoints/<unit>/<hash>/`\n\n### Testing Implementations\n\n**Run doctest verification:**\n\n```bash\nvibesafe test                              # Test all units\nvibesafe test --target examples.math.ops   # Test one module\nvibesafe test --target examples.math.ops/sum_str  # Test one unit\n```\n\n**What gets tested:**\n- ✅ Doctests extracted from spec docstring\n- ✅ Type checking via mypy\n- ✅ Linting via ruff\n- ⏭️ Hypothesis property tests (if `hypothesis:` fence in docstring)\n- ✅ In prod, an aggregated pytest harness per source module is materialized from doctests to expand coverage\n\n**Test output example:**\n\n```\nTesting examples.math.ops/sum_str...\n  ✓ Doctest 1/3 passed\n  ✓ Doctest 2/3 passed\n  ✓ Doctest 3/3 passed\n  ✓ Type check passed (mypy)\n  ✓ Lint passed (ruff)\n\n[PASS] examples.math.ops/sum_str\n```\n\n### Checking Drift\n\n**Detect spec changes that invalidate checkpoints:**\n\n```bash\nvibesafe diff                              # Check all units\nvibesafe diff --target examples.math.ops/sum_str  # Check one unit\n```\n\n**Output:**\n\n```\n[DRIFT] examples.math.ops/sum_str\n  Spec hash:       5a72e9... (current)\n  Checkpoint hash: 2d46f1... (active)\n\n  Spec changed:\n    - Added doctest example\n    - Modified parameter annotation: str -> int\n\n  Location: .vibesafe/checkpoints/examples.math.ops/sum_str/2d46f1.../\n\n  Action: Run `vibesafe compile --target examples.math.ops/sum_str`\n```\n\n**Common drift causes:**\n- Changed function signature\n- Added/removed/modified doctests\n- Changed pre-hole code\n- Updated model config (e.g., `gpt-4o-mini` → `gpt-4o`)\n\n### Saving Checkpoints\n\n**Activate a checkpoint (marks it production-ready):**\n\n```bash\nvibesafe save --target examples.math.ops/sum_str\n# Updates .vibesafe/index.toml with the checkpoint hash\n```\n\n**Save all units (only if all tests pass):**\n\n```bash\nvibesafe save\n# Fails if any unit has failing tests\n```\n\n**Freeze HTTP dependencies:**\n\n```bash\nvibesafe save --target examples.api.routes/sum_endpoint --freeze-http-deps\n# Writes requirements.vibesafe.txt with pinned versions\n# Records fastapi, starlette, pydantic versions in checkpoint meta.toml\n```\n\n**Why freeze dependencies?**\nFastAPI endpoints have runtime dependencies that can break with version upgrades. Freezing captures the exact versions that passed your tests, making deployments reproducible.\n\n### Status Overview\n\n**Get project-wide summary:**\n\n```bash\nvibesafe status\n\n# Output:\n# Vibesafe Project Status\n# =======================\n#\n# Units: 5 total\n#   ✓ 4 with active checkpoints\n#   ⚠ 1 missing checkpoints\n#   ⚠ 0 with drift\n#\n# Doctests: 23 total\n# Coverage: 80% (4/5 units production-ready)\n#\n# Next steps:\n#   - Compile: examples.math.ops/is_prime\n```\n\n---\n\n## Reference\n\n### CLI Commands\n\n| Command | Description | Key Options |\n|---------|-------------|-------------|\n| `vibesafe scan` | List all specs and their status | `--write-shims` (deprecated) |\n| `vibesafe compile` | Generate implementations | `--target`, `--force` |\n| `vibesafe test` | Run verification (doctests + gates) | `--target` |\n| `vibesafe save` | Activate checkpoints | `--target`, `--freeze-http-deps` |\n| `vibesafe diff` | Show drift between spec and checkpoint | `--target` |\n| `vibesafe status` | Project overview | |\n| `vibesafe check` | Bundle lint + type + test + drift checks | `--target` |\n| `vibesafe repl` | Interactive iteration loop (Phase 2) | `--target` |\n\n**Aliases:** `vibesafe` and `vibe` are interchangeable.\n\n### Configuration Keys (vibesafe.toml)\n\n```toml\n[project]\npython = \">=3.12\"        # Minimum Python version\nenv = \"dev\"              # \"dev\" or \"prod\" (overridden by VIBESAFE_ENV)\n\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"    # Model name\nseed = 42                # Random seed for reproducibility\nreasoning_effort = \"medium\"      # optional: minimal|low|medium|high\nservice_tier = \"auto\"    # optional: pass through to provider tiering\nbase_url = \"https://api.openai.com/v1\"\napi_key_env = \"OPENAI_API_KEY\"  # Environment variable name\ntimeout = 60             # Request timeout (seconds)\n\n[paths]\ncheckpoints = \".vibesafe/checkpoints\"  # Where implementations are stored\ncache = \".vibesafe/cache\"              # LLM response cache (gitignored)\nindex = \".vibesafe/index.toml\"         # Active checkpoint registry\ngenerated = \"__generated__\"            # Import shim directory (deprecated)\n\n[prompts]\nfunction = \"vibesafe/templates/function.j2\"       # Template for @vibesafe\nhttp = \"vibesafe/templates/http_endpoint.j2\"      # Template for @vibesafe(kind=\"http\")\n\n[sandbox]\nenabled = false          # Run tests in isolated subprocess (Phase 1)\ntimeout = 10             # Test timeout (seconds)\nmemory_mb = 256          # Memory limit (not enforced yet)\n```\n\n### Decorator API\n\n**@vibesafe**\n \n ```python\n @vibesafe(\n     provider: str = \"default\",           # Provider name from vibesafe.toml\n     template: str = \"vibesafe/templates/function.j2\",  # Prompt template path\n     model: str | None = None,            # Override model per-unit\n )\n def your_function(...) -> ...:\n     \"\"\"\n     Docstring should include doctests; missing examples emit a warning.\n \n     >>> your_function(...)\n     expected_output\n     \"\"\"\n     # Optional pre-hole code (e.g., validation, parsing)\n     raise VibeCoded()\n ```\n \n **@vibesafe(kind=\"http\")**\n \n ```python\n @vibesafe(\n     kind=\"http\",\n     method: str = \"GET\",                # HTTP method\n     path: str = \"/endpoint\",            # Route path\n     tags: list[str] = [],               # OpenAPI tags\n     provider: str = \"default\",\n     template: str = \"vibesafe/templates/http_endpoint.j2\",\n     model: str | None = None,\n )\n async def your_endpoint(...) -> ...:\n     \"\"\"\n     Endpoint description with doctests.\n \n     >>> import anyio\n     >>> anyio.run(your_endpoint, arg1, arg2)\n     expected_output\n     \"\"\"\n     raise VibeCoded()\n ```\n\n### Error Types\n\n| Exception | Cause | Remedy |\n|-----------|-------|--------|\n| `VibesafeMissingDoctest` | Spec lacks doctest examples | Add `>>>` examples to docstring |\n| `VibesafeValidationError` | Generated code fails structural checks | Tighten spec (more examples, clearer docstring) |\n| `VibesafeProviderError` | LLM API failure (timeout, auth, rate limit) | Check API key, network, quota |\n| `VibesafeHashMismatch` | Spec changed but checkpoint is stale | Run `vibesafe compile` to regenerate |\n| `VibesafeCheckpointMissing` | Prod mode but no active checkpoint | Run `vibesafe compile` + `vibesafe save` |\n\n---\n\n## Explanation: How Vibesafe Works\n\n### Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│ Developer writes spec:                                          │\n│   @vibesafe                                                     │\n│   def sum_str(a: str, b: str) -> str:                          │\n│       \"\"\">>> sum_str(\"2\", \"3\") → '5'\"\"\"                         │\n│       raise VibeCoded()                                         │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ AST Parser extracts:                                            │\n│   - Signature: sum_str(a: str, b: str) -> str                  │\n│   - Doctests: [(\"2\", \"3\") → \"5\"]                               │\n│   - Pre-hole code: (none)                                       │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Hasher computes H_spec = SHA-256(                              │\n│   signature + doctests + pre_hole + model + template           │\n│ )                                                               │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Prompt Renderer (Jinja2):                                       │\n│   - Loads vibesafe/templates/function.j2                         │\n│   - Injects signature, doctests, type hints                     │\n│   - Produces final prompt string                                │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Provider calls LLM:                                             │\n│   - Checks cache: .vibesafe/cache/<H_spec>.json                 │\n│   - If miss: POST to OpenAI API (temp=0, seed=42)               │\n│   - Returns generated Python code                               │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Validator checks:                                               │\n│   ✓ Code parses (AST valid)                                     │\n│   ✓ Function name matches                                       │\n│   ✓ Signature matches (params, return type)                     │\n│   ✓ No obvious security issues                                  │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Checkpoint Writer:                                              │\n│   - Computes H_chk = SHA-256(H_spec + prompt + code)           │\n│   - Writes .vibesafe/checkpoints/<unit>/<H_chk>/impl.py         │\n│   - Writes meta.toml (spec hash, timestamp, model, versions)    │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Test Harness runs:                                              │\n│   1. Doctests (pytest wrappers)                                 │\n│   2. Type check (mypy)                                          │\n│   3. Lint (ruff)                                                │\n│   Result: PASS or FAIL                                          │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ If tests pass, developer runs:                                  │\n│   vibesafe save --target <unit>                                 │\n│                                                                 │\n│ Writes to .vibesafe/index.toml:                                 │\n│   [<unit>]                                                      │\n│   active = \"<H_chk>\"                                            │\n│   created = \"2025-10-30T12:34:56Z\"                              │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Runtime: Direct function import                                 │\n│   from examples.math import sum_str                             │\n│                                                                 │\n│ Decorator calls: load_checkpoint(\"examples.math/sum_str\")      │\n│   1. Read .vibesafe/index.toml for active hash                  │\n│   2. Load .vibesafe/checkpoints/<unit>/<hash>/impl.py           │\n│   3. In prod mode: verify H_spec matches checkpoint meta        │\n│   4. Return the function object                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Provider Model\n\nVibesafe uses a pluggable provider system. Phase 1 ships with `openai-compatible`, which works with:\n\n- **OpenAI** (GPT-4o, GPT-4o-mini)\n- **Anthropic** (via OpenAI-compatible proxy)\n- **Local LLMs** (llama.cpp, vLLM, Ollama with OpenAI API)\n\n**Provider interface:**\n\n```python\nclass Provider(Protocol):\n    def complete(\n        self,\n        prompt: str,\n        system: str | None = None,\n        seed: int = 42,\n        temperature: float = 0.0,\n        max_tokens: int | None = None,\n        **kwargs\n    ) -> str:\n        \"\"\"Return generated code as string.\"\"\"\n```\n\n**Adding providers:**\nImplement the `Provider` protocol and register in `vibesafe.toml`:\n\n```toml\n[provider.anthropic]\nkind = \"anthropic-native\"\nmodel = \"claude-3-5-sonnet-20250131\"\napi_key_env = \"ANTHROPIC_API_KEY\"\n```\n\n### Runtime Flow\n\n**Dev mode (`env = \"dev\"`):**\n\n1. Import triggers `load_active(unit_id)`\n2. Read `.vibesafe/index.toml` for active checkpoint hash\n3. Compute current spec hash `H_spec`\n4. If `H_spec` ≠ checkpoint's spec hash:\n   - **Warn:** \"Spec drift detected, regenerating...\"\n   - Auto-run `vibesafe compile --target <unit>`\n   - Load new checkpoint\n5. Return function object\n\n**Prod mode (`env = \"prod\"` or `VIBESAFE_ENV=prod`):**\n\n1. Import triggers `load_active(unit_id)`\n2. Read `.vibesafe/index.toml` for active checkpoint hash\n3. If no checkpoint: **raise `VibesafeCheckpointMissing`**\n4. Load checkpoint metadata from `meta.toml`\n5. Compute current spec hash `H_spec`\n6. If `H_spec` ≠ checkpoint's spec hash: **raise `VibesafeHashMismatch`**\n7. Return function object\n\n**This enforces:**\n- ✅ What you tested is what runs (no silent regeneration)\n- ✅ Drift is caught before deployment\n- ✅ Reproducibility across environments\n\n---\n\n## Why Engineers Care\n\n### Real Integration Patterns\n\n**1. CI/CD gating:**\n\n```yaml\n# .github/workflows/ci.yml\njobs:\n  vibesafe-check:\n    runs-on: ubuntu-latest\n    steps:\n      - run: vibesafe diff\n        # Fails if any unit has drifted\n      - run: vibesafe test\n        # Runs all doctests + type/lint gates\n      - run: vibesafe save --dry-run\n        # Verifies all checkpoints exist\n```\n\nIn 6 months of use, this caught **23 unintended spec changes** (typos in doctests, accidental signature edits) before merge.\n\n**2. Frozen HTTP dependencies:**\n\n```bash\n# Before deploying FastAPI app\nvibesafe save --target api.routes --freeze-http-deps\ngit add requirements.vibesafe.txt .vibesafe/checkpoints/\ngit commit -m \"Lock FastAPI endpoint dependencies\"\n```\n\nThe `meta.toml` records:\n\n```toml\n[deps]\nfastapi = \"0.115.2\"\nstarlette = \"0.41.2\"\npydantic = \"2.9.1\"\n```\n\nNow your containerized deployment uses the exact versions that passed tests, preventing \"works on my laptop\" bugs.\n\n**3. Prompt regression coverage:**\n\nEvery time you change a spec, the hash changes. This creates a natural test suite for prompt engineering:\n\n```bash\n# After editing vibesafe/templates/function.j2\nvibesafe compile --force  # Regenerate all units\nvibesafe test             # Verify all doctests still pass\nvibesafe diff             # Review generated code changes\n```\n\nIf a prompt change breaks existing specs, doctests fail immediately. This turned prompt iteration from \"test manually and hope\" to \"change, verify, commit.\"\n\n**4. Local agents + vibesafe.toml contract:**\n\nThe `vibesafe.toml` file is the single source of truth for:\n- Which model to use\n- What temperature/seed settings\n- Where checkpoints live\n- Which prompt templates apply\n\nLocal AI coding agents (Claude Code, Cursor, GitHub Copilot) can read `vibesafe.toml` and understand the contract without asking the developer. Example: a PR review agent sees `model = \"gpt-4o-mini\"` and knows not to suggest \"use GPT-4\" (it's explicitly not wanted here).\n\n### Examples in Action\n\nThe `examples/` directory doubles as regression fixtures:\n\n```bash\n$ tree examples/\nexamples/\n├── math/\n│   └── ops.py          # sum_str, fibonacci, is_prime\n└── api/\n    └── routes.py       # sum_endpoint, hello_endpoint\n\n$ vibesafe test --target examples.math.ops\n✓ sum_str     [3 doctests]\n✓ fibonacci   [4 doctests]\n✓ is_prime    [5 doctests]\n[PASS] 3/3 units\n```\n\nThese examples serve three purposes:\n1. **Documentation**: Show real usage patterns\n2. **Testing**: Verify vibesafe's own codegen pipeline\n3. **Fixtures**: Golden tests for prompt/model changes\n\n---\n\n## Project Status & Roadmap\n\n### Phase 1 (MVP) — ✅ Shipped\n\n| Feature | Status | Notes |\n|---------|--------|-------|\n| Python 3.12+ support | ✅ | Tested on 3.12, 3.13 |\n| `@vibesafe` decorator | ✅ | Function and endpoint generation |\n| `kind` parameter | ✅ | Supports \"function\", \"http\", \"cli\" |\n| Doctest verification | ✅ | Auto-extracted from docstrings |\n| Type checking (mypy) | ✅ | Mandatory gate before save |\n| Linting (ruff) | ✅ | Enforces style consistency |\n| Hash-locked checkpoints | ✅ | SHA-256 content addressing |\n| Drift detection | ✅ | `vibesafe diff` command |\n| OpenAI-compatible providers | ✅ | Works with OpenAI, proxies, local LLMs |\n| CLI (`scan`, `compile`, `test`, `save`, `status`, `diff`, `check`) | ✅ | `vibesafe` or `vibe` alias |\n| Dependency freezing | ✅ | `--freeze-http-deps` flag |\n| Jinja2 prompt templates | ✅ | Customizable via `vibesafe.toml` |\n| LLM response caching | ✅ | Keyed by spec hash, speeds up iteration |\n| Subprocess sandbox | ✅ | Optional isolation for test runs |\n| **Claude Code Plugin** | ✅ | Full integration with Claude Code |\n| **MCP Server** | ✅ | Model Context Protocol server |\n| **GitHub Actions** | ✅ | Automated Claude Code reviews |\n\n**Current coverage:** 150+ checkpointed functions across 3 internal projects, 95% test coverage for vibesafe core.\n\n### Phase 2 (In Progress) — See [ROADMAP.md](ROADMAP.md)\n\n- **Interactive REPL** (`vibesafe repl --target <unit>`)\n  - Commands: `gen`, `tighten`, `diff`, `save`, `rollback`\n  - Planned Q2 2025\n- **Property-based testing** (Hypothesis integration)\n  - Extract `hypothesis:` fences from docstrings\n  - Auto-generate property tests\n- **Multi-provider support** (Anthropic native, Gemini, local inference)\n- **Advanced dependency tracing** (hybrid static + runtime)\n- **Web UI dashboard** (checkpoint browser, diff viewer)\n- **Sandbox enhancements** (network/FS isolation, resource limits)\n\n### Open Items\n\n- [ ] PyPI package release (`pip install vibesafe`)\n- [ ] Documentation site (Docusaurus on GitHub Pages)\n- [ ] VS Code extension (syntax highlighting for `@vibesafe` specs)\n- [ ] Performance benchmarks (compilation time, test throughput)\n- [ ] Migration guide (v0.1 → v0.2)\n\n---\n\n## Contributing\n\nContributions welcome! Please:\n\n1. **Open an issue first** for features/bugs\n2. **Follow the spec** in [SPEC.md](SPEC.md)\n3. **Add tests** for new functionality\n4. **Update TODOS.md** if you complete a roadmap item\n\n**Development setup:**\n\n```bash\ngit clone https://github.com/julep-ai/vibesafe.git\ncd vibesafe\nuv venv && source .venv/bin/activate\nuv pip install -e \".[dev]\"\n\n# Run tests\npytest -n auto\n\n# Type check\nmypy src/vibesafe\n\n# Lint\nruff check src/ tests/ examples/\n\n# Format\nruff format src/ tests/ examples/\n```\n\n**Claude Code Integration:**\nThis repo includes a full Claude Code plugin with:\n- MCP server for seamless vibesafe operations\n- Slash commands (`/vibe`, `/vibe-init`, `/vibe-mode`, `/vibe-status`)\n- Automated PR reviews and test failure analysis\n- Skills for AI-assisted development workflows\n\nSee [`.claude-plugin/`](.claude-plugin/) for plugin configuration and [`.github/workflows/`](.github/workflows/) for CI automation.\n\n---\n\n## Honest Trade-offs\n\n### What Vibesafe Does Well\n\n- ✅ **Iteration speed**: Dev mode auto-regenerates on import, no manual compile step\n- ✅ **Reproducibility**: Same spec = same hash = same code\n- ✅ **Testability**: Doctests are mandatory, enforced at save time\n- ✅ **Prod safety**: Hash mismatches block execution, preventing drift\n\n### What Vibesafe Doesn't Do (Yet)\n\n- ❌ **Complex state machines**: Specs are per-function, not multi-step workflows (use orchestration layer)\n- ❌ **Dynamic prompt injection**: Templates are static Jinja2, not runtime-constructed (by design, for reproducibility)\n- ❌ **Multi-language support**: Python-only (Rust/TypeScript on roadmap if demand exists)\n- ❌ **GUI for non-coders**: CLI-first tool, requires Python knowledge\n\n### When Not to Use Vibesafe\n\n- **Exploratory prototyping**: If you're not sure what the API should be, write it manually first\n- **Performance-critical code**: LLM-generated implementations may not be optimally optimized (profile before deploying)\n- **Regulatory/compliance code**: Review generated code manually; vibesafe ensures reproducibility, not correctness\n- **Sub-second latency requirements**: Checkpoint loading adds ~10ms overhead on first import\n\n---\n\n## License\n\nMIT — see [LICENSE](LICENSE)\n\n---\n\n## Acknowledgments\n\nBuilt with:\n- [uv](https://github.com/astral-sh/uv) — Fast Python package manager\n- [ruff](https://github.com/astral-sh/ruff) — Fast Python linter\n- [mypy](https://github.com/python/mypy) — Static type checker\n- [pytest](https://pytest.org/) — Testing framework\n- [Jinja2](https://jinja.palletsprojects.com/) — Prompt templating\n\nInspired by:\n- **Defunctionalization** (Reynolds, 1972) — Making implicit control explicit\n- **Content-addressed storage** (Git, Nix) — Deterministic builds via hashing\n- **Test-driven development** — Specs as executable contracts\n- **Literate programming** (Knuth) — Code that explains itself\n\n---\n\n## Get Help\n\n- **Issues**: [github.com/julep-ai/vibesafe/issues](https://github.com/julep-ai/vibesafe/issues)\n- **Discussions**: [github.com/julep-ai/vibesafe/discussions](https://github.com/julep-ai/vibesafe/discussions)\n- **Email**: support@julep.ai\n",
        "commands/get-mode.md": "---\nname: get-mode\ndescription: \"Show the current VIBESAFE_ENV (mode) visible to this session.\"\narguments: []\n---\n\nReport the Vibesafe mode for this session by reading `VIBESAFE_ENV` (falls back to config default if unset).\n\nSteps:\n1) `echo \"VIBESAFE_ENV=${VIBESAFE_ENV:-<unset>}\"`  \n2) If unset, note that the config default (`project.env` in vibesafe.toml) will apply.\n\nExample:\n- `/vibesafe:get-mode`\n",
        "commands/init.md": "---\nname: init\ndescription: \"Initialize the Vibesafe plugin session: report mode, list commands, and verify MCP connectivity.\"\narguments: []\n---\n\nRun a quick readiness check:\n- Show current mode (`VIBESAFE_ENV` or config default)\n- List available Vibesafe commands\n- Confirm MCP server connectivity\n\nExample:\n- `/vibesafe:init`\n\nSteps:\n1) `echo \"VIBESAFE_ENV=${VIBESAFE_ENV:-<unset>}\"`  \n2) `vibesafe status || true`  # harmless status check  \n3) `echo \"Commands: scan, compile, test, save, diff, status, mcp\"`  \n",
        "commands/set-mode.md": "---\nname: set-mode\ndescription: \"Set VIBESAFE_ENV for subsequent Vibesafe commands (dev|prod).\"\narguments:\n  - name: env\n    description: \"Mode to set (dev or prod)\"\n    required: true\n---\n\nSet the Vibesafe mode for this session by exporting `VIBESAFE_ENV`, then report the new value.\n\nSteps (run in order):\n1) `export VIBESAFE_ENV=\"{{ env }}\"`  \n2) `echo \"VIBESAFE_ENV=$VIBESAFE_ENV\"`  \n\nExamples:\n- `/vibesafe:set-mode dev`\n- `/vibesafe:set-mode prod`\n",
        "commands/vibe.md": "---\nname: vibe\ndescription: \"Run vibesafe CLI commands through the MCP server. Usage: /vibe <subcommand> [args] where subcommand ∈ {scan, compile, test, save, diff, status, mcp}.\"\narguments:\n  - name: subcommand\n    description: \"vibesafe subcommand to execute (scan | compile | test | save | diff | status | mcp)\"\n    required: true\n---\n\nRun Vibesafe toolchain actions via MCP.\n\nExamples:\n- `/vibe scan`\n- `/vibe compile --target app.math.ops/fibonacci`\n- `/vibe test --target app.math.ops/fibonacci`\n- `/vibe status`\n- `/vibe diff`\n- `/vibe save --target app.math.ops/fibonacci`\n",
        "hooks/hooks.json": "{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [[ \\\"$FILE_PATH\\\" == *.py ]] && grep -q '@vibesafe' \\\"$FILE_PATH\\\"; then vibesafe compile --target \\\"$FILE_PATH\\\" >/dev/null 2>&1 || true; fi\",\n            \"timeout\": 5,\n            \"enabled\": true\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [[ \\\"$COMMAND\\\" == git*commit* ]]; then vibesafe diff; fi\",\n            \"timeout\": 10,\n            \"enabled\": true\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "skills/vibesafe/SKILL.md": "---\nname: vibesafe\ndescription: \"Uses the Vibesafe MCP server to scan, compile, test, save, diff, and report status for Vibesafe units. Activate when the user asks to run vibesafe CLI commands (scan/compile/test/save/diff/status), regenerate code from specs, or inspect drift/checkpoints.\"\nversion: \"0.2.1\"\ntags: [\"vibesafe\", \"codegen\", \"mcp\", \"cli\"]\nallowed-tools: \"MCP(vibesafe:*)\"\n---\n\n# Vibesafe MCP Skill\n\nProvides full control of the Vibesafe toolchain through the MCP server exposed by this plugin.\n\n## When to Use\n- User asks to run `vibesafe scan`, `compile`, `test`, `save`, `diff`, or `status`.\n- Need to regenerate implementations from specs or check drift against checkpoints.\n- Want to query registry contents, provider config, or checkpoints via the MCP tools.\n\n## Available Tools\n- `scan` — list all registered Vibesafe units with metadata.\n- `compile` — generate implementations for a unit (supports `target`, `force`).\n- `test` — run doctests/quality gates (optional `target`).\n- `save` — activate checkpoints (optional `target`).\n- `status` — report version, unit counts, environment.\n\n## Examples\n- “List all vibesafe units” → use `scan`.\n- “Recompile app.math.ops/fibonacci” → call `compile` with `target`.\n- “Run vibesafe tests” → call `test`.\n- “Save checkpoints for all units” → call `save`.\n- “Check drift” → call `diff` (via status+diff as available).\n"
      },
      "plugins": [
        {
          "name": "vibesafe",
          "description": "Vibesafe developer tools",
          "source": "./",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add julep-ai/vibesafe",
            "/plugin install vibesafe@Vibesafe"
          ]
        }
      ]
    }
  ]
}