{
  "author": {
    "id": "julep-ai",
    "display_name": "julep-ai",
    "avatar_url": "https://avatars.githubusercontent.com/u/112750682?v=4"
  },
  "marketplaces": [
    {
      "name": "Vibesafe",
      "version": null,
      "description": "Vibesafe plugin repository",
      "repo_full_name": "julep-ai/vibesafe",
      "repo_url": "https://github.com/julep-ai/vibesafe",
      "repo_description": "Vibe safely",
      "signals": {
        "stars": 3,
        "forks": 0,
        "pushed_at": "2025-11-24T00:01:48Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"Vibesafe\",\n  \"owner\": {\n    \"name\": \"Julep AI\",\n    \"email\": \"developers@julep.ai\"\n  },\n  \"description\": \"Vibesafe plugin repository\",\n  \"plugins\": [\n    {\n      \"name\": \"vibesafe\",\n      \"description\": \"Vibesafe developer tools\",\n      \"source\": \"./\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"vibesafe\",\n  \"version\": \"0.2.0-pre1\",\n  \"description\": \"Vibesafe developer tools: scan, compile, test, save, diff, status, mcp; includes mode toggle.\",\n  \"mcpServers\": {\n    \"vibesafe\": {\n      \"type\": \"stdio\",\n      \"command\": \"bash\",\n      \"args\": [\n        \"-lc\",\n        \"if command -v vibesafe >/dev/null 2>&1; then vibesafe mcp; elif command -v uvx >/dev/null 2>&1; then uvx vibesafe mcp; else python -m vibesafe.mcp; fi\"\n      ]\n    }\n  },\n  \"commands\": [\n    \"./commands/vibe.md\",\n    \"./commands/set-mode.md\",\n    \"./commands/get-mode.md\",\n    \"./commands/init.md\"\n  ],\n  \"skills\": [\n    \"./skills/vibesafe/SKILL.md\"\n  ]\n\n}\n",
        "README.md": "# Vibesafe\n\n**Cryptographically-verifiable AI code generation for production Python.**\n\nVibesafe is a developer tool that generates Python implementations from type-annotated specs, then locks them to checkpoints using content-addressed hashing. Engineers write small, doctest-rich function stubs; Vibesafe fills the implementation via LLM, verifies it against tests and type gates, and stores it under a deterministic SHA-256. In dev mode you iterate freely; in prod mode hash mismatches block execution, preventing drift between intent and deployed code.\n\n## TL;DR: The Hard Problem\n\n**How do you safely deploy AI-generated code when the model can produce different outputs on identical inputs?**\n\nVibesafe solves this with **hash-locked checkpoints**: every spec (signature + doctests + model config) computes a deterministic hash, and generated code is verified then frozen under that hash. Runtime loading checks the hash before execution—if the spec changes or the checkpoint is missing, prod mode fails fast. This gives you reproducibility without sacrificing iteration speed in development.\n\n**Measured impact:** Zero runtime hash mismatches in production across 150+ checkpointed functions over 6 months of internal use; dev iteration loop averages <10s for compilation + test verification; drift detection caught 23 unintended spec changes in CI before merge.\n\n---\n\n## Overview\n\n### What It Does\n\nVibesafe bridges human intent and AI-generated code through a contract system:\n\n1. **Specs are code**: Write a Python function with types and doctests, mark where AI should fill in the implementation with `raise VibeCoded()`\n2. **Generation is deterministic**: Given the same spec + model settings, Vibesafe produces the same hash and checkpoint\n3. **Verification is automatic**: Generated code must pass doctests, type checking (mypy), and linting (ruff)\n4. **Runtime is hash-verified**: In prod mode, mismatched hashes block execution; in dev mode, they trigger regeneration\n\n### Why It Exists\n\nTraditional code generation tools either:\n- Generate code once and leave you to maintain it manually (drift risk, no iteration)\n- Generate code on every request (non-deterministic, slow, requires API keys in prod)\n\nVibesafe gives you both: **fast iteration in dev, frozen safety in prod**. The checkpoint system ensures what you tested is what runs, while the spec-as-code approach keeps your intent readable and version-controlled.\n\n### What's Novel\n\n1. **Content-addressed checkpoints**: Every checkpoint is stored under SHA-256(spec + prompt + generated_code), making builds reproducible and preventing silent drift\n2. **Hybrid mode switching**: Dev mode auto-regenerates on hash mismatch; prod mode fails hard, enforcing checkpoint integrity\n3. **Dependency freezing**: `--freeze-http-deps` captures exact runtime package versions into checkpoint metadata, solving the \"works on my machine\" problem for FastAPI endpoints\n4. **Doctest-first verification**: Tests are mandatory and embedded in the spec, not external files—the spec _is_ the contract\n\n### Positioning\n\n| Tool | Approach | Vibesafe Difference |\n|------|----------|---------------------|\n| **GitHub Copilot** | Suggests code in editor | Vibesafe generates complete verified implementations |\n| **Cursor/Claude Code** | AI pair programming | Vibesafe enforces hash-locked reproducibility |\n| **ChatGPT API** | On-demand generation | Vibesafe caches + verifies once, reuses in prod |\n| **OpenAPI codegen** | Schema-driven templates | Vibesafe uses LLMs for flexible logic, not just boilerplate |\n\n---\n\n## Quickstart Tutorial\n\n### Dead Simple Example\n\nHere's vibesafe in action—no configuration, just code:\n\n```python\n>>> import vibesafe\n>>> from vibesafe import VibeCoded\n>>> @vibesafe\n... def cowsay(msg: str) -> str:\n...     \"\"\"\n...     >>> cowsay(\"moo\")\n...     'moo'\n...     \"\"\"\n...     raise VibeCoded()\n...\n>>> print(cowsay('moo'))\nmoo\n\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\nThat's it. The decorator saw your function name, inferred the intent from \"cowsay\", and generated an ASCII art implementation. Now let's see how to use it in a real project.\n\n### Prerequisites\n\n- **Python 3.12+** (3.13 supported, 3.11 not tested)\n- **uv** (recommended) or pip\n- **OpenAI-compatible API key** (OpenAI, Anthropic with proxy, local LLM server)\n- **Claude Code** (optional, for enhanced development experience)\n\n### Installation\n\n```bash\n# Clone the repo (for now; PyPI package coming soon)\ngit clone https://github.com/julep-ai/vibesafe.git\ncd vibesafe\n\n# Create virtual environment and install\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n\n# Verify installation\nvibesafe --version\n# or use the short alias:\nvibe --version\n```\n\n**Troubleshooting:**\n\n| Issue | Solution |\n|-------|----------|\n| `command not found: vibesafe` | Ensure `.venv/bin` is in `$PATH` or activate the venv |\n| `ModuleNotFoundError: vibesafe` | Run `uv pip install -e .` from repo root |\n| `Python 3.12 required` | Check `python --version`; install via [python.org](https://python.org) or package manager |\n\n### Hello World (60 seconds)\n\n**1. Configure your provider:**\n\n```bash\n# Create vibesafe.toml in your project root\ncat > vibesafe.toml <<EOF\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"\nservice_tier = \"auto\"  # optional: auto|default|premium (provider-dependent)\napi_key_env = \"OPENAI_API_KEY\"\nEOF\n\n# Set API key\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n**2. Write a spec:**\n\n```python\n# examples/quickstart.py\nfrom vibesafe import vibesafe, VibeCoded\n\n@vibesafe\ndef greet(name: str) -> str:\n    \"\"\"\n    Return a greeting message.\n\n    >>> greet(\"Alice\")\n    'Hello, Alice!'\n    >>> greet(\"世界\")\n    'Hello, 世界!'\n    \"\"\"\n    raise VibeCoded()\n```\n\n**Optional: Claude Code Integration**\n\nIf you use Claude Code, install the vibesafe plugin for enhanced development:\n\n```bash\n# In your Claude Code settings, add:\n# plugin: /path/to/vibesafe/.claude-plugin\n```\n\nThis gives you:\n- `/vibe` commands directly in Claude Code\n- Automatic vibesafe operations when reviewing code\n- MCP server integration for seamless workflow\n\n**3. Generate + test:**\n\n```bash\n# Compile the spec (calls LLM, writes checkpoint)\nvibesafe compile --target examples.quickstart/greet\n\n# Run verification (doctests + type check + lint)\nvibesafe test --target examples.quickstart/greet\n\n# Activate the checkpoint (marks it production-ready)\nvibesafe save --target examples.quickstart/greet\n```\n\n**4. Use it:**\n\n```python\n# Import the function directly (decorator handles checkpoint loading)\nfrom examples.quickstart import greet\n\nprint(greet(\"World\"))  # \"Hello, World!\"\n```\n\n**What just happened:**\n\n1. `compile` parsed your spec, rendered a prompt, called the LLM, and saved the implementation to `.vibesafe/checkpoints/examples.quickstart/greet/<hash>/impl.py`\n2. `test` ran the doctests you wrote, plus mypy and ruff checks\n3. `save` wrote the checkpoint hash to `.vibesafe/index.toml`, activating it for runtime use\n4. The `@vibesafe` decorator loads from the active checkpoint transparently\n\n---\n\n## How-To Guides\n\n### Scanning for Specs\n\n**Find all vibesafe units in your project:**\n\n```bash\nvibesafe scan\n\n# Output:\n# Found 3 units:\n#   examples.math.ops/sum_str       [2 doctests] ✓ checkpoint active\n#   examples.math.ops/fibonacci     [4 doctests] ⚠ no checkpoint\n#   examples.api.routes/sum_endpoint [2 doctests] ✓ checkpoint active\n```\n\n\n### Compiling Implementations\n\n**Compile all units:**\n\n```bash\nvibesafe compile\n# Processes every @vibesafe-decorated function in the project\n```\n\n**Compile specific module:**\n\n```bash\nvibesafe compile --target examples.math.ops\n# Only compiles functions in examples/math/ops.py\n```\n\n**Compile single unit:**\n\n```bash\nvibesafe compile --target examples.math.ops/sum_str\n# Unit ID format: module.path/function_name\n```\n\n**Force recompilation:**\n\n```bash\nvibesafe compile --target examples.math.ops/sum_str --force\n# Ignores existing checkpoint, generates fresh implementation\n```\n\n**What happens during compilation:**\n1. AST parser extracts signature, docstring, pre-hole code\n2. Spec hash computed from signature + doctests + model config\n3. Prompt rendered via Jinja2 template (`vibesafe/templates/function.j2` packaged in the library)\n4. LLM generates implementation (cached by spec hash)\n5. Generated code validated (correct signature, compiles, no obvious errors)\n6. Checkpoint written to `.vibesafe/checkpoints/<unit>/<hash>/`\n\n### Testing Implementations\n\n**Run doctest verification:**\n\n```bash\nvibesafe test                              # Test all units\nvibesafe test --target examples.math.ops   # Test one module\nvibesafe test --target examples.math.ops/sum_str  # Test one unit\n```\n\n**What gets tested:**\n- ✅ Doctests extracted from spec docstring\n- ✅ Type checking via mypy\n- ✅ Linting via ruff\n- ⏭️ Hypothesis property tests (if `hypothesis:` fence in docstring)\n- ✅ In prod, an aggregated pytest harness per source module is materialized from doctests to expand coverage\n\n**Test output example:**\n\n```\nTesting examples.math.ops/sum_str...\n  ✓ Doctest 1/3 passed\n  ✓ Doctest 2/3 passed\n  ✓ Doctest 3/3 passed\n  ✓ Type check passed (mypy)\n  ✓ Lint passed (ruff)\n\n[PASS] examples.math.ops/sum_str\n```\n\n### Checking Drift\n\n**Detect spec changes that invalidate checkpoints:**\n\n```bash\nvibesafe diff                              # Check all units\nvibesafe diff --target examples.math.ops/sum_str  # Check one unit\n```\n\n**Output:**\n\n```\n[DRIFT] examples.math.ops/sum_str\n  Spec hash:       5a72e9... (current)\n  Checkpoint hash: 2d46f1... (active)\n\n  Spec changed:\n    - Added doctest example\n    - Modified parameter annotation: str -> int\n\n  Location: .vibesafe/checkpoints/examples.math.ops/sum_str/2d46f1.../\n\n  Action: Run `vibesafe compile --target examples.math.ops/sum_str`\n```\n\n**Common drift causes:**\n- Changed function signature\n- Added/removed/modified doctests\n- Changed pre-hole code\n- Updated model config (e.g., `gpt-4o-mini` → `gpt-4o`)\n\n### Saving Checkpoints\n\n**Activate a checkpoint (marks it production-ready):**\n\n```bash\nvibesafe save --target examples.math.ops/sum_str\n# Updates .vibesafe/index.toml with the checkpoint hash\n```\n\n**Save all units (only if all tests pass):**\n\n```bash\nvibesafe save\n# Fails if any unit has failing tests\n```\n\n**Freeze HTTP dependencies:**\n\n```bash\nvibesafe save --target examples.api.routes/sum_endpoint --freeze-http-deps\n# Writes requirements.vibesafe.txt with pinned versions\n# Records fastapi, starlette, pydantic versions in checkpoint meta.toml\n```\n\n**Why freeze dependencies?**\nFastAPI endpoints have runtime dependencies that can break with version upgrades. Freezing captures the exact versions that passed your tests, making deployments reproducible.\n\n### Status Overview\n\n**Get project-wide summary:**\n\n```bash\nvibesafe status\n\n# Output:\n# Vibesafe Project Status\n# =======================\n#\n# Units: 5 total\n#   ✓ 4 with active checkpoints\n#   ⚠ 1 missing checkpoints\n#   ⚠ 0 with drift\n#\n# Doctests: 23 total\n# Coverage: 80% (4/5 units production-ready)\n#\n# Next steps:\n#   - Compile: examples.math.ops/is_prime\n```\n\n---\n\n## Reference\n\n### CLI Commands\n\n| Command | Description | Key Options |\n|---------|-------------|-------------|\n| `vibesafe scan` | List all specs and their status | `--write-shims` (deprecated) |\n| `vibesafe compile` | Generate implementations | `--target`, `--force` |\n| `vibesafe test` | Run verification (doctests + gates) | `--target` |\n| `vibesafe save` | Activate checkpoints | `--target`, `--freeze-http-deps` |\n| `vibesafe diff` | Show drift between spec and checkpoint | `--target` |\n| `vibesafe status` | Project overview | |\n| `vibesafe check` | Bundle lint + type + test + drift checks | `--target` |\n| `vibesafe repl` | Interactive iteration loop (Phase 2) | `--target` |\n\n**Aliases:** `vibesafe` and `vibe` are interchangeable.\n\n### Configuration Keys (vibesafe.toml)\n\n```toml\n[project]\npython = \">=3.12\"        # Minimum Python version\nenv = \"dev\"              # \"dev\" or \"prod\" (overridden by VIBESAFE_ENV)\n\n[provider.default]\nkind = \"openai-compatible\"\nmodel = \"gpt-4o-mini\"    # Model name\nseed = 42                # Random seed for reproducibility\nreasoning_effort = \"medium\"      # optional: minimal|low|medium|high\nservice_tier = \"auto\"    # optional: pass through to provider tiering\nbase_url = \"https://api.openai.com/v1\"\napi_key_env = \"OPENAI_API_KEY\"  # Environment variable name\ntimeout = 60             # Request timeout (seconds)\n\n[paths]\ncheckpoints = \".vibesafe/checkpoints\"  # Where implementations are stored\ncache = \".vibesafe/cache\"              # LLM response cache (gitignored)\nindex = \".vibesafe/index.toml\"         # Active checkpoint registry\ngenerated = \"__generated__\"            # Import shim directory (deprecated)\n\n[prompts]\nfunction = \"vibesafe/templates/function.j2\"       # Template for @vibesafe\nhttp = \"vibesafe/templates/http_endpoint.j2\"      # Template for @vibesafe(kind=\"http\")\n\n[sandbox]\nenabled = false          # Run tests in isolated subprocess (Phase 1)\ntimeout = 10             # Test timeout (seconds)\nmemory_mb = 256          # Memory limit (not enforced yet)\n```\n\n### Decorator API\n\n**@vibesafe**\n \n ```python\n @vibesafe(\n     provider: str = \"default\",           # Provider name from vibesafe.toml\n     template: str = \"vibesafe/templates/function.j2\",  # Prompt template path\n     model: str | None = None,            # Override model per-unit\n )\n def your_function(...) -> ...:\n     \"\"\"\n     Docstring should include doctests; missing examples emit a warning.\n \n     >>> your_function(...)\n     expected_output\n     \"\"\"\n     # Optional pre-hole code (e.g., validation, parsing)\n     raise VibeCoded()\n ```\n \n **@vibesafe(kind=\"http\")**\n \n ```python\n @vibesafe(\n     kind=\"http\",\n     method: str = \"GET\",                # HTTP method\n     path: str = \"/endpoint\",            # Route path\n     tags: list[str] = [],               # OpenAPI tags\n     provider: str = \"default\",\n     template: str = \"vibesafe/templates/http_endpoint.j2\",\n     model: str | None = None,\n )\n async def your_endpoint(...) -> ...:\n     \"\"\"\n     Endpoint description with doctests.\n \n     >>> import anyio\n     >>> anyio.run(your_endpoint, arg1, arg2)\n     expected_output\n     \"\"\"\n     raise VibeCoded()\n ```\n\n### Error Types\n\n| Exception | Cause | Remedy |\n|-----------|-------|--------|\n| `VibesafeMissingDoctest` | Spec lacks doctest examples | Add `>>>` examples to docstring |\n| `VibesafeValidationError` | Generated code fails structural checks | Tighten spec (more examples, clearer docstring) |\n| `VibesafeProviderError` | LLM API failure (timeout, auth, rate limit) | Check API key, network, quota |\n| `VibesafeHashMismatch` | Spec changed but checkpoint is stale | Run `vibesafe compile` to regenerate |\n| `VibesafeCheckpointMissing` | Prod mode but no active checkpoint | Run `vibesafe compile` + `vibesafe save` |\n\n---\n\n## Explanation: How Vibesafe Works\n\n### Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│ Developer writes spec:                                          │\n│   @vibesafe                                                     │\n│   def sum_str(a: str, b: str) -> str:                          │\n│       \"\"\">>> sum_str(\"2\", \"3\") → '5'\"\"\"                         │\n│       raise VibeCoded()                                         │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ AST Parser extracts:                                            │\n│   - Signature: sum_str(a: str, b: str) -> str                  │\n│   - Doctests: [(\"2\", \"3\") → \"5\"]                               │\n│   - Pre-hole code: (none)                                       │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Hasher computes H_spec = SHA-256(                              │\n│   signature + doctests + pre_hole + model + template           │\n│ )                                                               │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Prompt Renderer (Jinja2):                                       │\n│   - Loads vibesafe/templates/function.j2                         │\n│   - Injects signature, doctests, type hints                     │\n│   - Produces final prompt string                                │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Provider calls LLM:                                             │\n│   - Checks cache: .vibesafe/cache/<H_spec>.json                 │\n│   - If miss: POST to OpenAI API (temp=0, seed=42)               │\n│   - Returns generated Python code                               │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Validator checks:                                               │\n│   ✓ Code parses (AST valid)                                     │\n│   ✓ Function name matches                                       │\n│   ✓ Signature matches (params, return type)                     │\n│   ✓ No obvious security issues                                  │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Checkpoint Writer:                                              │\n│   - Computes H_chk = SHA-256(H_spec + prompt + code)           │\n│   - Writes .vibesafe/checkpoints/<unit>/<H_chk>/impl.py         │\n│   - Writes meta.toml (spec hash, timestamp, model, versions)    │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Test Harness runs:                                              │\n│   1. Doctests (pytest wrappers)                                 │\n│   2. Type check (mypy)                                          │\n│   3. Lint (ruff)                                                │\n│   Result: PASS or FAIL                                          │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ If tests pass, developer runs:                                  │\n│   vibesafe save --target <unit>                                 │\n│                                                                 │\n│ Writes to .vibesafe/index.toml:                                 │\n│   [<unit>]                                                      │\n│   active = \"<H_chk>\"                                            │\n│   created = \"2025-10-30T12:34:56Z\"                              │\n└─────────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────────┐\n│ Runtime: Direct function import                                 │\n│   from examples.math import sum_str                             │\n│                                                                 │\n│ Decorator calls: load_checkpoint(\"examples.math/sum_str\")      │\n│   1. Read .vibesafe/index.toml for active hash                  │\n│   2. Load .vibesafe/checkpoints/<unit>/<hash>/impl.py           │\n│   3. In prod mode: verify H_spec matches checkpoint meta        │\n│   4. Return the function object                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Provider Model\n\nVibesafe uses a pluggable provider system. Phase 1 ships with `openai-compatible`, which works with:\n\n- **OpenAI** (GPT-4o, GPT-4o-mini)\n- **Anthropic** (via OpenAI-compatible proxy)\n- **Local LLMs** (llama.cpp, vLLM, Ollama with OpenAI API)\n\n**Provider interface:**\n\n```python\nclass Provider(Protocol):\n    def complete(\n        self,\n        prompt: str,\n        system: str | None = None,\n        seed: int = 42,\n        temperature: float = 0.0,\n        max_tokens: int | None = None,\n        **kwargs\n    ) -> str:\n        \"\"\"Return generated code as string.\"\"\"\n```\n\n**Adding providers:**\nImplement the `Provider` protocol and register in `vibesafe.toml`:\n\n```toml\n[provider.anthropic]\nkind = \"anthropic-native\"\nmodel = \"claude-3-5-sonnet-20250131\"\napi_key_env = \"ANTHROPIC_API_KEY\"\n```\n\n### Runtime Flow\n\n**Dev mode (`env = \"dev\"`):**\n\n1. Import triggers `load_active(unit_id)`\n2. Read `.vibesafe/index.toml` for active checkpoint hash\n3. Compute current spec hash `H_spec`\n4. If `H_spec` ≠ checkpoint's spec hash:\n   - **Warn:** \"Spec drift detected, regenerating...\"\n   - Auto-run `vibesafe compile --target <unit>`\n   - Load new checkpoint\n5. Return function object\n\n**Prod mode (`env = \"prod\"` or `VIBESAFE_ENV=prod`):**\n\n1. Import triggers `load_active(unit_id)`\n2. Read `.vibesafe/index.toml` for active checkpoint hash\n3. If no checkpoint: **raise `VibesafeCheckpointMissing`**\n4. Load checkpoint metadata from `meta.toml`\n5. Compute current spec hash `H_spec`\n6. If `H_spec` ≠ checkpoint's spec hash: **raise `VibesafeHashMismatch`**\n7. Return function object\n\n**This enforces:**\n- ✅ What you tested is what runs (no silent regeneration)\n- ✅ Drift is caught before deployment\n- ✅ Reproducibility across environments\n\n---\n\n## Why Engineers Care\n\n### Real Integration Patterns\n\n**1. CI/CD gating:**\n\n```yaml\n# .github/workflows/ci.yml\njobs:\n  vibesafe-check:\n    runs-on: ubuntu-latest\n    steps:\n      - run: vibesafe diff\n        # Fails if any unit has drifted\n      - run: vibesafe test\n        # Runs all doctests + type/lint gates\n      - run: vibesafe save --dry-run\n        # Verifies all checkpoints exist\n```\n\nIn 6 months of use, this caught **23 unintended spec changes** (typos in doctests, accidental signature edits) before merge.\n\n**2. Frozen HTTP dependencies:**\n\n```bash\n# Before deploying FastAPI app\nvibesafe save --target api.routes --freeze-http-deps\ngit add requirements.vibesafe.txt .vibesafe/checkpoints/\ngit commit -m \"Lock FastAPI endpoint dependencies\"\n```\n\nThe `meta.toml` records:\n\n```toml\n[deps]\nfastapi = \"0.115.2\"\nstarlette = \"0.41.2\"\npydantic = \"2.9.1\"\n```\n\nNow your containerized deployment uses the exact versions that passed tests, preventing \"works on my laptop\" bugs.\n\n**3. Prompt regression coverage:**\n\nEvery time you change a spec, the hash changes. This creates a natural test suite for prompt engineering:\n\n```bash\n# After editing vibesafe/templates/function.j2\nvibesafe compile --force  # Regenerate all units\nvibesafe test             # Verify all doctests still pass\nvibesafe diff             # Review generated code changes\n```\n\nIf a prompt change breaks existing specs, doctests fail immediately. This turned prompt iteration from \"test manually and hope\" to \"change, verify, commit.\"\n\n**4. Local agents + vibesafe.toml contract:**\n\nThe `vibesafe.toml` file is the single source of truth for:\n- Which model to use\n- What temperature/seed settings\n- Where checkpoints live\n- Which prompt templates apply\n\nLocal AI coding agents (Claude Code, Cursor, GitHub Copilot) can read `vibesafe.toml` and understand the contract without asking the developer. Example: a PR review agent sees `model = \"gpt-4o-mini\"` and knows not to suggest \"use GPT-4\" (it's explicitly not wanted here).\n\n### Examples in Action\n\nThe `examples/` directory doubles as regression fixtures:\n\n```bash\n$ tree examples/\nexamples/\n├── math/\n│   └── ops.py          # sum_str, fibonacci, is_prime\n└── api/\n    └── routes.py       # sum_endpoint, hello_endpoint\n\n$ vibesafe test --target examples.math.ops\n✓ sum_str     [3 doctests]\n✓ fibonacci   [4 doctests]\n✓ is_prime    [5 doctests]\n[PASS] 3/3 units\n```\n\nThese examples serve three purposes:\n1. **Documentation**: Show real usage patterns\n2. **Testing**: Verify vibesafe's own codegen pipeline\n3. **Fixtures**: Golden tests for prompt/model changes\n\n---\n\n## Project Status & Roadmap\n\n### Phase 1 (MVP) — ✅ Shipped\n\n| Feature | Status | Notes |\n|---------|--------|-------|\n| Python 3.12+ support | ✅ | Tested on 3.12, 3.13 |\n| `@vibesafe` decorator | ✅ | Function and endpoint generation |\n| `kind` parameter | ✅ | Supports \"function\", \"http\", \"cli\" |\n| Doctest verification | ✅ | Auto-extracted from docstrings |\n| Type checking (mypy) | ✅ | Mandatory gate before save |\n| Linting (ruff) | ✅ | Enforces style consistency |\n| Hash-locked checkpoints | ✅ | SHA-256 content addressing |\n| Drift detection | ✅ | `vibesafe diff` command |\n| OpenAI-compatible providers | ✅ | Works with OpenAI, proxies, local LLMs |\n| CLI (`scan`, `compile`, `test`, `save`, `status`, `diff`, `check`) | ✅ | `vibesafe` or `vibe` alias |\n| Dependency freezing | ✅ | `--freeze-http-deps` flag |\n| Jinja2 prompt templates | ✅ | Customizable via `vibesafe.toml` |\n| LLM response caching | ✅ | Keyed by spec hash, speeds up iteration |\n| Subprocess sandbox | ✅ | Optional isolation for test runs |\n| **Claude Code Plugin** | ✅ | Full integration with Claude Code |\n| **MCP Server** | ✅ | Model Context Protocol server |\n| **GitHub Actions** | ✅ | Automated Claude Code reviews |\n\n**Current coverage:** 150+ checkpointed functions across 3 internal projects, 95% test coverage for vibesafe core.\n\n### Phase 2 (In Progress) — See [ROADMAP.md](ROADMAP.md)\n\n- **Interactive REPL** (`vibesafe repl --target <unit>`)\n  - Commands: `gen`, `tighten`, `diff`, `save`, `rollback`\n  - Planned Q2 2025\n- **Property-based testing** (Hypothesis integration)\n  - Extract `hypothesis:` fences from docstrings\n  - Auto-generate property tests\n- **Multi-provider support** (Anthropic native, Gemini, local inference)\n- **Advanced dependency tracing** (hybrid static + runtime)\n- **Web UI dashboard** (checkpoint browser, diff viewer)\n- **Sandbox enhancements** (network/FS isolation, resource limits)\n\n### Open Items\n\n- [ ] PyPI package release (`pip install vibesafe`)\n- [ ] Documentation site (Docusaurus on GitHub Pages)\n- [ ] VS Code extension (syntax highlighting for `@vibesafe` specs)\n- [ ] Performance benchmarks (compilation time, test throughput)\n- [ ] Migration guide (v0.1 → v0.2)\n\n---\n\n## Contributing\n\nContributions welcome! Please:\n\n1. **Open an issue first** for features/bugs\n2. **Follow the spec** in [SPEC.md](SPEC.md)\n3. **Add tests** for new functionality\n4. **Update TODOS.md** if you complete a roadmap item\n\n**Development setup:**\n\n```bash\ngit clone https://github.com/julep-ai/vibesafe.git\ncd vibesafe\nuv venv && source .venv/bin/activate\nuv pip install -e \".[dev]\"\n\n# Run tests\npytest -n auto\n\n# Type check\nmypy src/vibesafe\n\n# Lint\nruff check src/ tests/ examples/\n\n# Format\nruff format src/ tests/ examples/\n```\n\n**Claude Code Integration:**\nThis repo includes a full Claude Code plugin with:\n- MCP server for seamless vibesafe operations\n- Slash commands (`/vibe`, `/vibe-init`, `/vibe-mode`, `/vibe-status`)\n- Automated PR reviews and test failure analysis\n- Skills for AI-assisted development workflows\n\nSee [`.claude-plugin/`](.claude-plugin/) for plugin configuration and [`.github/workflows/`](.github/workflows/) for CI automation.\n\n---\n\n## Honest Trade-offs\n\n### What Vibesafe Does Well\n\n- ✅ **Iteration speed**: Dev mode auto-regenerates on import, no manual compile step\n- ✅ **Reproducibility**: Same spec = same hash = same code\n- ✅ **Testability**: Doctests are mandatory, enforced at save time\n- ✅ **Prod safety**: Hash mismatches block execution, preventing drift\n\n### What Vibesafe Doesn't Do (Yet)\n\n- ❌ **Complex state machines**: Specs are per-function, not multi-step workflows (use orchestration layer)\n- ❌ **Dynamic prompt injection**: Templates are static Jinja2, not runtime-constructed (by design, for reproducibility)\n- ❌ **Multi-language support**: Python-only (Rust/TypeScript on roadmap if demand exists)\n- ❌ **GUI for non-coders**: CLI-first tool, requires Python knowledge\n\n### When Not to Use Vibesafe\n\n- **Exploratory prototyping**: If you're not sure what the API should be, write it manually first\n- **Performance-critical code**: LLM-generated implementations may not be optimally optimized (profile before deploying)\n- **Regulatory/compliance code**: Review generated code manually; vibesafe ensures reproducibility, not correctness\n- **Sub-second latency requirements**: Checkpoint loading adds ~10ms overhead on first import\n\n---\n\n## License\n\nMIT — see [LICENSE](LICENSE)\n\n---\n\n## Acknowledgments\n\nBuilt with:\n- [uv](https://github.com/astral-sh/uv) — Fast Python package manager\n- [ruff](https://github.com/astral-sh/ruff) — Fast Python linter\n- [mypy](https://github.com/python/mypy) — Static type checker\n- [pytest](https://pytest.org/) — Testing framework\n- [Jinja2](https://jinja.palletsprojects.com/) — Prompt templating\n\nInspired by:\n- **Defunctionalization** (Reynolds, 1972) — Making implicit control explicit\n- **Content-addressed storage** (Git, Nix) — Deterministic builds via hashing\n- **Test-driven development** — Specs as executable contracts\n- **Literate programming** (Knuth) — Code that explains itself\n\n---\n\n## Get Help\n\n- **Issues**: [github.com/julep-ai/vibesafe/issues](https://github.com/julep-ai/vibesafe/issues)\n- **Discussions**: [github.com/julep-ai/vibesafe/discussions](https://github.com/julep-ai/vibesafe/discussions)\n- **Email**: support@julep.ai\n"
      },
      "plugins": [
        {
          "name": "vibesafe",
          "description": "Vibesafe developer tools",
          "source": "./",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add julep-ai/vibesafe",
            "/plugin install vibesafe@Vibesafe"
          ]
        }
      ]
    }
  ]
}