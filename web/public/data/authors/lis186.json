{
  "author": {
    "id": "lis186",
    "display_name": "Justin Lee",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/635405?v=4",
    "url": "https://github.com/lis186",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 28,
      "total_skills": 14,
      "total_stars": 26,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "lis186-SourceAtlas",
      "version": null,
      "description": "SourceAtlas - AI-powered codebase understanding tools for Claude Code",
      "owner_info": {
        "name": "Justin Lee"
      },
      "keywords": [],
      "repo_full_name": "lis186/SourceAtlas",
      "repo_url": "https://github.com/lis186/SourceAtlas",
      "repo_description": "A set of AI-powered slash commands for Claude Code and OpenSkills (support Cursor, Windsurf and Gemini CLI) that help you understand any codebase quickly",
      "homepage": "https://www.sourceatlas.io",
      "signals": {
        "stars": 26,
        "forks": 0,
        "pushed_at": "2026-01-14T03:48:43Z",
        "created_at": "2025-11-19T15:35:36Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 522
        },
        {
          "path": "plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 594
        },
        {
          "path": "plugin/README.md",
          "type": "blob",
          "size": 18637
        },
        {
          "path": "plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/clear",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/clear/SKILL.md",
          "type": "blob",
          "size": 2393
        },
        {
          "path": "plugin/commands/deps",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/deps/SKILL.md",
          "type": "blob",
          "size": 9198
        },
        {
          "path": "plugin/commands/deps/output-template.md",
          "type": "blob",
          "size": 9433
        },
        {
          "path": "plugin/commands/deps/reference.md",
          "type": "blob",
          "size": 10135
        },
        {
          "path": "plugin/commands/deps/verification-guide.md",
          "type": "blob",
          "size": 6478
        },
        {
          "path": "plugin/commands/deps/workflow.md",
          "type": "blob",
          "size": 4541
        },
        {
          "path": "plugin/commands/flow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/flow/SKILL.md",
          "type": "blob",
          "size": 7397
        },
        {
          "path": "plugin/commands/history",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/history/SKILL.md",
          "type": "blob",
          "size": 9943
        },
        {
          "path": "plugin/commands/history/output-template.md",
          "type": "blob",
          "size": 12328
        },
        {
          "path": "plugin/commands/history/reference.md",
          "type": "blob",
          "size": 11781
        },
        {
          "path": "plugin/commands/history/verification-guide.md",
          "type": "blob",
          "size": 9114
        },
        {
          "path": "plugin/commands/history/workflow.md",
          "type": "blob",
          "size": 10575
        },
        {
          "path": "plugin/commands/impact",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/impact/SKILL.md",
          "type": "blob",
          "size": 6380
        },
        {
          "path": "plugin/commands/impact/output-template.md",
          "type": "blob",
          "size": 6946
        },
        {
          "path": "plugin/commands/impact/reference.md",
          "type": "blob",
          "size": 6315
        },
        {
          "path": "plugin/commands/impact/verification-guide.md",
          "type": "blob",
          "size": 5685
        },
        {
          "path": "plugin/commands/impact/workflow.md",
          "type": "blob",
          "size": 10606
        },
        {
          "path": "plugin/commands/list",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/list/SKILL.md",
          "type": "blob",
          "size": 2858
        },
        {
          "path": "plugin/commands/overview",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/overview/SKILL.md",
          "type": "blob",
          "size": 10184
        },
        {
          "path": "plugin/commands/overview/output-template.md",
          "type": "blob",
          "size": 18076
        },
        {
          "path": "plugin/commands/overview/reference.md",
          "type": "blob",
          "size": 13543
        },
        {
          "path": "plugin/commands/overview/verification-guide.md",
          "type": "blob",
          "size": 11363
        },
        {
          "path": "plugin/commands/overview/workflow.md",
          "type": "blob",
          "size": 13778
        },
        {
          "path": "plugin/commands/pattern",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/pattern/SKILL.md",
          "type": "blob",
          "size": 9668
        },
        {
          "path": "plugin/commands/pattern/output-template.md",
          "type": "blob",
          "size": 12675
        },
        {
          "path": "plugin/commands/pattern/reference.md",
          "type": "blob",
          "size": 4315
        },
        {
          "path": "plugin/commands/pattern/verification-guide.md",
          "type": "blob",
          "size": 8717
        },
        {
          "path": "plugin/commands/pattern/workflow.md",
          "type": "blob",
          "size": 14190
        },
        {
          "path": "plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/code-flow-tracer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/code-flow-tracer/SKILL.md",
          "type": "blob",
          "size": 1465
        },
        {
          "path": "plugin/skills/codebase-overview",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/codebase-overview/SKILL.md",
          "type": "blob",
          "size": 1142
        },
        {
          "path": "plugin/skills/dependency-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/dependency-analyzer/SKILL.md",
          "type": "blob",
          "size": 1587
        },
        {
          "path": "plugin/skills/history-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/history-analyzer/SKILL.md",
          "type": "blob",
          "size": 1511
        },
        {
          "path": "plugin/skills/impact-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/impact-analyzer/SKILL.md",
          "type": "blob",
          "size": 1354
        },
        {
          "path": "plugin/skills/pattern-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/pattern-finder/SKILL.md",
          "type": "blob",
          "size": 1577
        },
        {
          "path": "plugin/skills/test-default-persistence.md",
          "type": "blob",
          "size": 1940
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"lis186-SourceAtlas\",\n  \"metadata\": {\n    \"description\": \"SourceAtlas - AI-powered codebase understanding tools for Claude Code\",\n    \"version\": \"1.0.0\"\n  },\n  \"owner\": {\n    \"name\": \"Justin Lee\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sourceatlas\",\n      \"source\": \"./plugin\",\n      \"description\": \"AI-powered codebase understanding assistant. Learn design patterns, analyze impact, trace code flows, and understand any codebase through information theory principles.\",\n      \"version\": \"2.11.0\"\n    }\n  ]\n}\n",
        "plugin/.claude-plugin/plugin.json": "{\n  \"name\": \"sourceatlas\",\n  \"description\": \"AI-powered codebase understanding assistant. Learn design patterns, analyze impact, trace code flows, and understand any codebase through information theory principles. Includes 6 Agent Skills for automatic analysis triggering.\",\n  \"version\": \"2.13.0\",\n  \"author\": {\n    \"name\": \"Justin Lee\"\n  },\n  \"repository\": \"https://github.com/lis186/SourceAtlas\",\n  \"keywords\": [\n    \"codebase-analysis\",\n    \"pattern-learning\",\n    \"impact-analysis\",\n    \"code-flow\",\n    \"git-history\",\n    \"code-understanding\",\n    \"architecture\"\n  ],\n  \"license\": \"MIT\"\n}\n",
        "plugin/README.md": "# SourceAtlas Plugin\n\n**AI-powered codebase understanding assistant for Claude Code**\n\nSourceAtlas helps developers quickly understand any codebase through pattern learning and impact analysis.\n\n## ‚ú® Features\n\n### Slash Commands (User-invoked)\n\n- **üîç Project Overview** (`/sourceatlas:overview`) - Quick project understanding (<5% file scan)\n- **üéØ Pattern Learning** (`/sourceatlas:pattern`) - Learn design patterns from existing code\n- **üìä Impact Analysis** (`/sourceatlas:impact`) - Analyze change impact with static dependency analysis\n- **üìà History Analysis** (`/sourceatlas:history`) - Git history temporal analysis (Hotspots, Coupling, Contributors)\n- **üîÑ Flow Analysis** (`/sourceatlas:flow`) - Trace code execution and data flow (11 analysis modes)\n- **üì¶ Dependency Analysis** (`/sourceatlas:deps`) - Library/framework upgrade analysis (iOS, Android, Python, React)\n\n### Agent Skills (Model-invoked)\n\nClaude automatically triggers the right analysis based on your questions:\n\n| You Ask | Claude Runs |\n|---------|-------------|\n| \"What's the architecture of this project?\" | `/sourceatlas:overview` |\n| \"How do I add an API endpoint?\" | `/sourceatlas:pattern \"api endpoint\"` |\n| \"What breaks if I change this file?\" | `/sourceatlas:impact` |\n| \"How does login work?\" | `/sourceatlas:flow \"login\"` |\n| \"Who knows this code best?\" | `/sourceatlas:history` |\n| \"How much work to upgrade to iOS 17?\" | `/sourceatlas:deps \"iOS 16 ‚Üí 17\"` |\n\nNo need to remember commands ‚Äî just ask naturally!\n\n## üöÄ Installation\n\n### Method 1: Via Claude Code Plugin (Recommended)\n\n```bash\n# Step 1: Add the SourceAtlas marketplace\n/plugin marketplace add lis186/SourceAtlas\n\n# Step 2: Install the plugin\n/plugin install sourceatlas@lis186-SourceAtlas\n\n# Step 3: Start using in any project\n/sourceatlas:overview\n/sourceatlas:pattern \"api endpoint\"\n```\n\n**Installation Scopes**:\n- **User scope** (default): Available across all your projects\n- **Project scope**: `--scope project` to share with collaborators\n\n> ‚ö†Ô∏è **Known Issue**: If you install with `--scope project` in one repo, you may get \"already installed\" errors in other repos. This is a [Claude Code bug](https://github.com/anthropics/claude-code/issues/14202). **Workaround**: Use default user scope (no `--scope` flag).\n\n### Method 2: Via OpenSkills (For Cursor, Gemini CLI, Aider, Windsurf)\n\nSourceAtlas works with non-Claude Code agents via [OpenSkills](https://github.com/numman-ali/openskills).\n\n#### Prerequisites\n\n- **Node.js 18+** installed\n- **An AI coding agent**: Cursor, Gemini CLI, Aider, or Windsurf\n- **A project directory** where you want to use SourceAtlas\n\n#### Quick Start (TL;DR)\n\n```bash\nnpm i -g openskills\ncd your-project\nopenskills install lis186/SourceAtlas\ntouch AGENTS.md && openskills sync -y\n```\n\nThen ask your AI agent: *\"Help me understand this codebase\"*\n\n#### Step-by-Step Installation\n\n**Step 1: Install OpenSkills CLI**\n\n```bash\nnpm i -g openskills\n```\n\nExpected output:\n```\nadded 50 packages in 9s\n```\n\n**Step 2: Install SourceAtlas skills in your project**\n\n```bash\ncd your-project\nopenskills install lis186/SourceAtlas\n```\n\nExpected output:\n```\nInstalling from: lis186/SourceAtlas\n‚úî Repository cloned\nFound 14 skill(s)\n\n? Select skills to install (Press <space> to select)\n‚ùØ ‚óâ overview   - Project architecture overview\n  ‚óâ pattern    - Learn design patterns from existing code\n  ‚óâ flow       - Trace code execution and data flow\n  ... (select the 8 SourceAtlas skills)\n\n‚úÖ Installation complete: 8 skill(s) installed\n```\n\n> **Tip**: Select only the 8 skills starting with common names (overview, pattern, flow, history, impact, deps, list, clear). Skip agent skills like \"codebase-overview\" to avoid duplicates.\n\n**Step 3: Generate AGENTS.md**\n\n```bash\ntouch AGENTS.md\nopenskills sync -y\n```\n\nExpected output:\n```\n‚úÖ Synced 8 skill(s) to AGENTS.md\n```\n\n**Step 4: Verify installation**\n\n```bash\nopenskills list | grep -E \"overview|pattern|flow\"\n```\n\nYou should see:\n```\n  overview    (project)   Get project overview...\n  pattern     (project)   Learn design patterns...\n  flow        (project)   Extract business logic flow...\n```\n\n**Step 5 (Optional): Commit to share with your team**\n\n```bash\ngit add AGENTS.md .claude/\ngit commit -m \"Add SourceAtlas skills for AI agents\"\n```\n\n#### Using with Cursor\n\nAfter installation, open Cursor and use the AI Chat (Cmd+L or Ctrl+L). Just ask naturally:\n\n| You Ask | What Happens |\n|---------|--------------|\n| \"Help me understand this codebase\" | Runs `openskills read overview` ‚Üí Project architecture analysis |\n| \"How do I add an API endpoint here?\" | Runs `openskills read pattern` ‚Üí Shows existing patterns to follow |\n| \"What files are affected if I change UserService?\" | Runs `openskills read impact` ‚Üí Dependency impact analysis |\n| \"Trace the login flow\" | Runs `openskills read flow` ‚Üí Execution path visualization |\n| \"Show me the hotspots in this repo\" | Runs `openskills read history` ‚Üí Git history analysis |\n| \"What's needed to upgrade to React 18?\" | Runs `openskills read deps` ‚Üí Migration checklist |\n\n> **Note**: If Cursor doesn't auto-detect skills, explicitly ask: *\"Use `openskills read overview` to analyze this project\"*\n\n#### Using with Gemini CLI\n\n```bash\ngemini\n```\n\nThen ask:\n```\n> Analyze this project's architecture using the overview skill\n```\n\nGemini will execute `openskills read overview` and provide analysis.\n\n#### Using with Aider\n\n```bash\naider\n```\n\nThen ask:\n```\n> What patterns does this codebase use for API endpoints? Use openskills read pattern\n```\n\n#### Available Skills Reference\n\n| Skill | Description | Use When |\n|-------|-------------|----------|\n| `overview` | Project architecture (<5% file scan) | Starting on a new codebase |\n| `pattern` | Learn design patterns | Implementing new features |\n| `impact` | Change impact analysis | Before refactoring |\n| `flow` | Code execution tracing | Understanding business logic |\n| `history` | Git history analysis | Finding hotspots & experts |\n| `deps` | Dependency analysis | Planning upgrades |\n| `list` | List cached results | Checking previous analyses |\n| `clear` | Clear cached results | Forcing fresh analysis |\n\n#### Troubleshooting\n\n**\"SKILL.md not found at plugin/commands\"**\n\nUse the repo root path (skills are discovered recursively):\n```bash\nopenskills install lis186/SourceAtlas\n```\n\n**Skills not appearing in your AI agent**\n\n1. Check AGENTS.md exists and contains `<available_skills>`:\n   ```bash\n   grep \"available_skills\" AGENTS.md\n   ```\n\n2. Re-sync if needed:\n   ```bash\n   openskills sync -y\n   ```\n\n**\"openskills: command not found\"**\n\nEnsure global npm bin is in PATH:\n```bash\nnpm bin -g  # Shows the path\nexport PATH=\"$PATH:$(npm bin -g)\"  # Add to PATH\n```\n\n#### v2.13.0 Testing Note (Progressive Disclosure Architecture)\n\n**What changed**: Starting from v2.13.0, SKILL.md files are now more concise with detailed steps in separate support files (workflow.md, output-template.md, etc.). This follows Claude Code's Progressive Disclosure Architecture best practice.\n\n**For OpenSkills users**:\n- ‚úÖ Core functionality should work normally - SKILL.md still contains all execution logic\n- ‚ö†Ô∏è If your AI agent cannot access support files, you may notice less detailed error handling instructions\n- üí¨ **We need your feedback!** Please test and report issues at: https://github.com/lis186/SourceAtlas/issues\n\n**Quick Test**:\n```bash\n# In your project with SourceAtlas installed:\ncd your-project\n\n# Ask your AI agent:\n\"Use openskills read overview to analyze this project\"\n\n# Expected: Analysis completes successfully with proper output format\n# If you see issues: Please report with your AI agent name (Cursor/Gemini/Aider/Windsurf)\n```\n\n### Method 3: Local Development/Testing\n\n```bash\n# Test plugin locally without installation\nclaude --plugin-dir ./plugin\n\n# Or add as local marketplace\n/plugin marketplace add ./path/to/SourceAtlas\n/plugin install sourceatlas@lis186-SourceAtlas\n```\n\n## üìñ Usage\n\n### `/sourceatlas:overview` - Project Overview\n\nGet a quick understanding of any codebase by scanning <5% of files.\n\n```bash\n# Analyze entire project\n/sourceatlas:overview\n\n# Analyze specific directory\n/sourceatlas:overview src/api\n```\n\n**What you get:**\n- Project fingerprint (type, scale, tech stack)\n- Architecture hypotheses with confidence levels\n- AI collaboration level detection (Level 0-4)\n- Recommended next steps\n\n### `/sourceatlas:pattern` - Learn Design Patterns\n\nLearn how the current codebase implements specific patterns.\n\n**Examples:**\n\n```bash\n# Learn API endpoint patterns\n/sourceatlas:pattern \"api endpoint\"\n\n# Learn background job patterns\n/sourceatlas:pattern \"background job\"\n\n# Learn file upload patterns\n/sourceatlas:pattern \"file upload\"\n\n# Learn authentication patterns\n/sourceatlas:pattern \"authentication\"\n\n# Learn database query patterns\n/sourceatlas:pattern \"database query\"\n```\n\n**What you get:**\n- üìÅ Best example files with line numbers\n- üéØ Standard implementation flow\n- üìê Key conventions to follow\n- ‚ö†Ô∏è Common pitfalls to avoid\n- üß™ Testing patterns\n- üìö Concrete implementation steps\n\n### `/sourceatlas:impact` - Impact Analysis\n\nAnalyze the impact scope of code changes using static dependency analysis.\n\n```bash\n# Analyze API change impact\n/sourceatlas:impact \"api /api/users/{id}\"\n\n# Analyze model change impact\n/sourceatlas:impact \"User model\"\n\n# Analyze component change impact\n/sourceatlas:impact \"authentication\"\n```\n\n**What you get:**\n- üìä Impact summary (backend, frontend, test files)\n- üî¥üü°üü¢ Risk level assessment\n- üìã Migration checklist\n- üß™ Test coverage gaps\n- ‚ö†Ô∏è Language-specific risks (Swift/ObjC interop for iOS)\n\n### `/sourceatlas:history` - History Analysis\n\nAnalyze git history to identify hotspots, temporal coupling, and knowledge distribution.\n\n```bash\n# Analyze entire repository\n/sourceatlas:history\n\n# Analyze specific directory\n/sourceatlas:history src/\n\n# Analyze last 6 months\n/sourceatlas:history . 6\n```\n\n**What you get:**\n- üî• Hotspots - Files with most changes (complexity indicators)\n- üîó Temporal Coupling - Files that change together (hidden dependencies)\n- üë• Recent Contributors - Knowledge distribution by area\n- ‚ö†Ô∏è Bus Factor Risk - Single-contributor files\n- üìä Risk Assessment - Priority actions for refactoring\n\n**Auto-features:**\n- Detects shallow clone and offers one-click fix\n- Auto-installs code-maat dependency if needed\n\n### `/sourceatlas:flow` - Flow Analysis\n\nTrace code execution flow and data flow with natural language queries.\n\n```bash\n# Trace user flow\n/sourceatlas:flow \"user login flow\"\n/sourceatlas:flow \"What happens when user clicks submit\"\n\n# Trace specific function\n/sourceatlas:flow \"handleSubmit\"\n/sourceatlas:flow \"trace processOrder function\"\n\n# Error path analysis\n/sourceatlas:flow \"API error handling\"\n\n# Data flow tracing\n/sourceatlas:flow \"where does userProfile data come from\"\n\n# Reverse tracing\n/sourceatlas:flow \"who calls validateToken\"\n```\n\n**What you get:**\n- üìä Call Graph visualization (ASCII tree format)\n- üåê Boundary detection (API, DB, LIB, CLOUD markers)\n- üîÑ Recursion and cycle detection\n- üìà Depth-controlled tracing\n- üéØ 11 analysis modes:\n  - Forward/Reverse tracing\n  - Error path analysis\n  - Data flow tracing\n  - State machine visualization\n  - Feature toggle detection\n  - Event/Message flow\n  - Transaction boundary\n  - Permission/Role check\n  - Cache flow analysis\n  - Comparison mode\n\n**For beginners (Newbie Mode auto-enabled):**\n- Terms explained with tooltips\n- Progressive disclosure (7¬±2 items per level)\n\n### `/sourceatlas:deps` - Dependency Analysis\n\nAnalyze library/framework dependencies for upgrade planning and migration.\n\n```bash\n# iOS SDK upgrade\n/sourceatlas:deps \"iOS 16 ‚Üí 17\"\n/sourceatlas:deps \"Upgrade minimum iOS to 17, use iOS 26 SDK\"\n\n# Android SDK upgrade\n/sourceatlas:deps \"Android API 35\"\n\n# Python library upgrade\n/sourceatlas:deps \"Flask 1.x ‚Üí 3.x\"\n/sourceatlas:deps \"Python 3.11 ‚Üí 3.12\"\n\n# React upgrade\n/sourceatlas:deps \"React 17 ‚Üí 18\"\n\n# Pure inventory (no upgrade)\n/sourceatlas:deps \"kotlinx.coroutines\"\n/sourceatlas:deps \"Check AFNetworking usage\"\n```\n\n**What you get:**\n- üìã **Phase 0 Rule Confirmation** - Preview upgrade rules before scanning\n- ‚úÖ **Required Changes** - Removable checks, deprecated APIs, breaking changes\n- üöÄ **Modernization Opportunities** - New features you can adopt\n- üìä **Usage Summary** - All API usage points with file:line references\n- üì¶ **Third-party Dependencies** - Compatibility checks\n- ‚úÖ **Migration Checklist** - Step-by-step upgrade plan with time estimates\n\n**Auto-features:**\n- **Built-in Rules**: iOS 16‚Üí17, React 17‚Üí18, Python 3.11‚Üí3.12\n- **WebSearch Integration**: Dynamically fetch latest migration guides\n- **Dual Modes**: Automatic detection of upgrade vs pure inventory\n- **Multi-module Support**: Handles Android multi-module projects\n- **Graceful Degradation**: Works even without requirements.txt or package.json\n- **Constitution v1.1 Compliant**: Full evidence with file:line references\n\n**Tested on:**\n- ‚úÖ iOS projects (2,108 files) - 100% accuracy\n- ‚úÖ Android multi-module (30 modules) - 100% accuracy\n- ‚úÖ Python projects (missing deps files) - 100% accuracy\n- ‚úÖ Kotlin workspaces (1,509 imports) - 100% accuracy\n\n## üß† Agent Skills (Auto-triggered)\n\nSourceAtlas includes 6 Agent Skills that let Claude automatically choose the right analysis tool based on your natural language questions.\n\n### Available Skills\n\n| Skill | Triggers When You Ask About |\n|-------|----------------------------|\n| `codebase-overview` | Project structure, architecture, tech stack, onboarding |\n| `pattern-finder` | How to implement features, code examples, conventions |\n| `impact-analyzer` | Change impact, dependencies, breaking changes, safety |\n| `code-flow-tracer` | How features work, execution paths, data flow |\n| `history-analyzer` | Hotspots, code ownership, bus factor, knowledge silos |\n| `dependency-analyzer` | Upgrades, migrations, deprecated APIs, version changes |\n\n### Example Conversations\n\n**You**: \"I just joined this project, can you help me understand it?\"\n**Claude**: *automatically runs `/sourceatlas:overview`*\n\n**You**: \"I need to add a new API endpoint, how does this project do it?\"\n**Claude**: *automatically runs `/sourceatlas:pattern \"api endpoint\"`*\n\n**You**: \"Is it safe to refactor UserService.ts?\"\n**Claude**: *automatically runs `/sourceatlas:impact \"UserService.ts\"`*\n\n### Skills Location\n\n```\nplugin/skills/\n‚îú‚îÄ‚îÄ codebase-overview/SKILL.md\n‚îú‚îÄ‚îÄ pattern-finder/SKILL.md\n‚îú‚îÄ‚îÄ impact-analyzer/SKILL.md\n‚îú‚îÄ‚îÄ code-flow-tracer/SKILL.md\n‚îú‚îÄ‚îÄ history-analyzer/SKILL.md\n‚îî‚îÄ‚îÄ dependency-analyzer/SKILL.md\n```\n\n---\n\n## üéì How It Works\n\nSourceAtlas uses **information theory principles** to understand codebases efficiently:\n\n1. **High-Entropy File Prioritization** - Scans <5% of files to achieve 70-80% understanding\n2. **Pattern Recognition** - Extracts reusable design patterns from existing code\n3. **Static Dependency Analysis** - Traces code dependencies without runtime execution\n4. **Actionable Guidance** - Provides concrete steps to follow existing conventions\n\n**Key Principles:**\n- ‚úÖ Scan <5% of files (targeted, not exhaustive)\n- ‚úÖ Focus on patterns, not implementation details\n- ‚úÖ Provide actionable, concrete guidance\n- ‚úÖ Always cite specific file locations\n\n## üß™ Example Output\n\nWhen you run `/sourceatlas:pattern \"api endpoint\"` in a Next.js project:\n\n```markdown\n# Pattern: REST API Endpoints (Next.js API Routes)\n\n## Overview\n\nThis project uses Next.js API routes with TypeScript, following a\nconsistent controller pattern with centralized error handling and\nZod validation.\n\n## Best Examples\n\n- **`src/pages/api/users/[id].ts:15`** - Complete CRUD endpoint example\n- **`src/pages/api/auth/login.ts:8`** - POST endpoint with validation\n- **`src/lib/api/errorHandler.ts:5`** - Centralized error handling\n\n## Key Conventions\n\n1. **Define route** in `src/pages/api/[route].ts`\n2. **Validate request** using Zod schema\n3. **Call service layer** for business logic\n4. **Return standardized response** (success/error format)\n5. **Handle errors** through centralized error handler\n\n... (and more)\n```\n\n## üõ†Ô∏è Development\n\n### Project Structure\n\n```\nsourceatlas-plugin/\n‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îî‚îÄ‚îÄ plugin.json          # Plugin metadata\n‚îú‚îÄ‚îÄ commands/                # Slash commands (user-invoked)\n‚îÇ   ‚îú‚îÄ‚îÄ overview/SKILL.md    # Project overview\n‚îÇ   ‚îú‚îÄ‚îÄ pattern/SKILL.md     # Pattern learning\n‚îÇ   ‚îú‚îÄ‚îÄ impact/SKILL.md      # Impact analysis\n‚îÇ   ‚îú‚îÄ‚îÄ history/SKILL.md     # Git history analysis\n‚îÇ   ‚îú‚îÄ‚îÄ flow/SKILL.md        # Code flow tracing\n‚îÇ   ‚îú‚îÄ‚îÄ deps/SKILL.md        # Dependency analysis\n‚îÇ   ‚îú‚îÄ‚îÄ list/SKILL.md        # List saved analyses\n‚îÇ   ‚îî‚îÄ‚îÄ clear/SKILL.md       # Clear saved analyses\n‚îú‚îÄ‚îÄ skills/                  # Agent Skills (model-invoked)\n‚îÇ   ‚îú‚îÄ‚îÄ codebase-overview/SKILL.md\n‚îÇ   ‚îú‚îÄ‚îÄ pattern-finder/SKILL.md\n‚îÇ   ‚îú‚îÄ‚îÄ impact-analyzer/SKILL.md\n‚îÇ   ‚îú‚îÄ‚îÄ code-flow-tracer/SKILL.md\n‚îÇ   ‚îú‚îÄ‚îÄ history-analyzer/SKILL.md\n‚îÇ   ‚îî‚îÄ‚îÄ dependency-analyzer/SKILL.md\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ CHANGELOG.md\n‚îú‚îÄ‚îÄ TESTING.md\n‚îî‚îÄ‚îÄ LICENSE\n```\n\n**Note**: Commands use `{name}/SKILL.md` format for OpenSkills compatibility.\n\n### Testing Locally\n\n```bash\n# Option 1: Direct plugin loading (fastest for development)\nclaude --plugin-dir ./plugin\n\n# Option 2: Local marketplace\n# From the SourceAtlas repository root:\n/plugin marketplace add ./\n/plugin install sourceatlas@lis186-SourceAtlas\n\n# Test in any project\ncd ~/your-project\n/sourceatlas:overview\n/sourceatlas:pattern \"api endpoint\"\n/sourceatlas:impact \"User model\"\n\n# After making changes to plugin/\n/plugin uninstall sourceatlas@lis186-SourceAtlas\n/plugin install sourceatlas@lis186-SourceAtlas\n```\n\n## ü§ù Contributing\n\nContributions welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch\n3. Test your changes locally\n4. Submit a pull request\n\n## üìÑ License\n\nMIT License - see [LICENSE](LICENSE) for details\n\n## üôè Acknowledgments\n\nBuilt on SourceAtlas methodology:\n- Three-stage analysis framework\n- Information theory principles\n- High-entropy file prioritization\n- Static dependency analysis\n\n## üìö Resources\n\n- [SourceAtlas Documentation](https://github.com/lis186/SourceAtlas)\n- [Claude Code Plugin Docs](https://code.claude.com/docs/en/plugins)\n\n---\n\n**SourceAtlas v2.13.0** - Understanding codebases at the speed of thought üöÄ\n",
        "plugin/commands/clear/SKILL.md": "---\nname: clear\ndescription: Clear saved SourceAtlas analysis results\nmodel: haiku\nallowed-tools: Bash, Read\nargument-hint: (optional) [target: overview|patterns|flows|history|impact|deps]\n---\n\n# SourceAtlas: Clear Saved Results\n\n## Context\n\n**Target**: $ARGUMENTS (default: all)\n\n## Your Task\n\nHelp user clear saved analysis results from `.sourceatlas/` directory.\n\n### Step 1: Check what exists\n\n```bash\nls -la .sourceatlas/ 2>/dev/null || echo \"No .sourceatlas/ directory found\"\n```\n\nAlso check subdirectories:\n\n```bash\n# Count files in each subdirectory\nfor dir in patterns flows impact deps; do\n    if [ -d \".sourceatlas/$dir\" ]; then\n        count=$(ls -1 \".sourceatlas/$dir\" 2>/dev/null | wc -l)\n        echo \"$dir/: $count files\"\n    fi\ndone\n```\n\n### Step 2: Report findings\n\nList what will be deleted based on target:\n- If no argument or \"all\": list everything\n- If specific target (e.g., \"patterns\"): list only that\n\nExample output:\n```\nFound the following saved analyses:\n- overview.yaml (2025-12-12)\n- patterns/ (3 files)\n- history.md (2025-12-11)\n\nAre you sure you want to delete?\n```\n\n### Step 3: Wait for confirmation\n\nAsk user to confirm. Do NOT proceed without explicit confirmation.\n\nAcceptable confirmations:\n- \"yes\"\n- \"ok\"\n- \"confirm\"\n- \"delete\"\n- \"sure\"\n- etc.\n\n### Step 4: Delete if confirmed\n\nBased on target:\n\n```bash\n# All (default, no argument)\nrm -rf .sourceatlas/*\n\n# Specific targets\nrm -f .sourceatlas/overview.yaml    # for \"overview\"\nrm -rf .sourceatlas/patterns/       # for \"patterns\"\nrm -rf .sourceatlas/flows/          # for \"flows\"\nrm -f .sourceatlas/history.md       # for \"history\"\nrm -rf .sourceatlas/impact/         # for \"impact\"\nrm -rf .sourceatlas/deps/           # for \"deps\"\n```\n\n### Step 5: Confirm deletion\n\n```\n‚úÖ Cleared [target or \".sourceatlas/\"]\n```\n\n---\n\n## If nothing to clear\n\n```\n.sourceatlas/ directory does not exist or is already empty\n```\n\n---\n\n## Target Reference\n\n| Target | Path | Description |\n|--------|------|-------------|\n| `overview` | `.sourceatlas/overview.yaml` | Project overview |\n| `patterns` | `.sourceatlas/patterns/` | Pattern analysis |\n| `flows` | `.sourceatlas/flows/` | Flow analysis |\n| `history` | `.sourceatlas/history.md` | Temporal analysis |\n| `impact` | `.sourceatlas/impact/` | Impact analysis |\n| `deps` | `.sourceatlas/deps/` | Dependency analysis |\n| (no argument) | `.sourceatlas/*` | Clear all |\n",
        "plugin/commands/deps/SKILL.md": "---\nname: deps\ndescription: Analyze dependency usage for library/framework/SDK upgrades\nmodel: sonnet\nallowed-tools: Bash, Glob, Grep, Read, Write, WebSearch, WebFetch\nargument-hint: [target, e.g., \"react 17 ‚Üí 18\", \"iOS 16\", \"lodash\"] [--force]\n---\n\n# SourceAtlas: Dependencies\n\n> **Constitution**: [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md) v1.1\n\n## Context\n\n**Target:** $ARGUMENTS (library name, version upgrade, or iOS minimum version)\n**Goal:** Analyze dependency usage and provide upgrade guidance\n**Time Limit:** 5-15 minutes\n\n## Quick Start\n\n1. **Check cache** (skip if `--force` flag present)\n2. **Detect version** from manifest files (package.json, Podfile, etc.)\n3. **Search for upgrade rules** using WebSearch (if version upgrade)\n4. **Find all usage points** using grep/Glob\n5. **Categorize usage** by API type\n6. **Generate YAML report** following [output-template.md](output-template.md)\n7. **Verify output** using [verification-guide.md](verification-guide.md)\n8. **Auto-save** to `.sourceatlas/deps/`\n\n## Your Task\n\nYou are analyzing dependency usage to help users understand:\n1. **Current state**: Which version is installed, where it's used\n2. **Upgrade impact**: What needs to change for version upgrades\n3. **Migration path**: Step-by-step upgrade checklist\n4. **Risk assessment**: How complex is the upgrade\n\n### Upgrade Types You Handle\n\n| Input Pattern | Type | Focus |\n|--------------|------|-------|\n| `iOS 17`, `iOS 16 ‚Üí 17` | iOS Minimum Version Upgrade | Removable `#available`, deprecated APIs, new opportunities |\n| `iOS SDK 26`, `Xcode 16` | SDK/Compiler Upgrade | Compilation warnings, Swift version, new syntax |\n| `react 17 ‚Üí 18`, `pandas 1.x ‚Üí 2.x` | Major Version Upgrade | Breaking changes, deprecated APIs, new patterns |\n| `react`, `pandas` (no version) | Usage Inventory | List usage points only |\n\n---\n\n## Core Workflow\n\nExecute these phases in order. See [workflow.md](workflow.md) for complete details.\n\n### Phase 0: Rule Confirmation (1-2 minutes)\n\n**Purpose:** Identify upgrade type and confirm analysis rules with user before proceeding.\n\n**Steps:**\n1. Detect upgrade type from `$ARGUMENTS`\n2. Generate rules preview (what to check, where to search)\n3. Use `AskUserQuestion` to confirm rules\n\n‚Üí See [workflow.md#phase-0](workflow.md#phase-0-rule-confirmation-1-2-minutes)\n\n### Phase 1: Detect Current Version (1 minute)\n\n**Purpose:** Find current dependency version from manifest files.\n\n**Manifest files by ecosystem:**\n- Node.js: `package.json`, `package-lock.json`\n- iOS: `Podfile`, `Package.swift`\n- Android: `build.gradle`, `build.gradle.kts`\n\n‚Üí See [workflow.md#phase-1](workflow.md#phase-1-detect-current-version-1-minute)\n\n### Phase 2: Search for Upgrade Guide (2-3 minutes)\n\n**Purpose:** Find official migration guide using WebSearch.\n\n**Search for:**\n1. Official migration guide\n2. Official changelog\n3. Community upgrade guides\n4. GitHub release notes\n\n‚Üí See [workflow.md#phase-2](workflow.md#phase-2-search-for-upgrade-guide-2-3-minutes)\n\n### Phase 3: Find All Usage Points (3-5 minutes)\n\n**Purpose:** Locate every place the dependency is used.\n\n**Search patterns:**\n- JavaScript/TypeScript: `import` statements, API calls\n- Swift/iOS: `import` statements, `#available` checks\n- Android/Kotlin: `import` statements, API level checks\n\n‚Üí See [workflow.md#phase-3](workflow.md#phase-3-find-all-usage-points-3-5-minutes)\n\n### Phase 4: Categorize API Usage (2-3 minutes)\n\n**Purpose:** Group usage by category and match against upgrade rules.\n\n**Categories:**\n- Hooks (React), Components, Utilities (JavaScript)\n- Frameworks, APIs (iOS/Android)\n- Availability checks (iOS)\n- Deprecated APIs (all platforms)\n\n‚Üí See [workflow.md#phase-4](workflow.md#phase-4-categorize-api-usage-2-3-minutes)\n\n### Phase 5: Generate Analysis Report\n\n**Purpose:** Output complete YAML analysis following template.\n\n‚Üí See [output-template.md](output-template.md) for complete format\n\n---\n\n## Output Format\n\nYour analysis should follow this YAML structure:\n\n```yaml\ndependency_analysis:\n  target: \"${ARGUMENTS}\"\n  type: \"[library|sdk|framework|runtime]\"\n  analysis_time: \"[ISO 8601 timestamp]\"\n  constitution_version: \"1.1\"\n\nversion_info:\n  current: \"[detected version]\"\n  source: \"[manifest file]\"\n  target: \"[target version if upgrade]\"\n\nrules_applied:\n  source: \"[built-in|web_search|user_provided]\"\n  rule_count: [number]\n\n# Required changes for upgrade\nrequired_changes:\n  removable_availability_checks: [...]\n  deprecated_api_usages: [...]\n  breaking_change_impacts: [...]\n\n# Optional modernization opportunities\nmodernization_opportunities:\n  items: [...]\n\n# Complete usage inventory\nusage_inventory:\n  total_files: [number]\n  total_usage_points: [number]\n  by_category: [...]\n\n# Step-by-step migration guide\nmigration_checklist:\n  estimated_effort: \"[low|medium|high]\"\n  recommended_approach: \"[description]\"\n  steps: [...]\n\n# Risk evaluation\nrisk_assessment:\n  overall_risk: \"[üü¢ low|üü° medium|üî¥ high]\"\n  factors: [...]\n  recommendations: [...]\n```\n\n‚Üí See [output-template.md](output-template.md) for complete specification and examples\n\n---\n\n## Critical Rules\n\n### 1. Rule Confirmation Required\n- **Always use `AskUserQuestion`** in Phase 0 to confirm rules before full analysis\n- Show user what you plan to check (availability patterns, deprecated APIs, etc.)\n- Get explicit approval before proceeding to Phase 1-5\n\n### 2. Version Detection Must Be Accurate\n- **Always grep manifest files** for current version\n- Use lock files (package-lock.json, Podfile.lock) for actual installed version\n- Never guess or estimate version numbers\n\n### 3. Evidence-Based Analysis Only\n- **Every usage point must have `file:line` reference**\n- All counts must be verifiable via grep\n- No assumptions about code you haven't seen\n\n### 4. Upgrade Guide Source Transparency\n```yaml\nrules_applied:\n  source: \"web_search\"  # Or \"built-in\" if no guide found\n  rule_count: 12\n```\n- Always disclose where upgrade rules came from\n- Prefer official docs over community guides\n- Note limitations if no official guide found\n\n### 5. Verification Required Before Output\n- Execute [verification-guide.md](verification-guide.md) after generating analysis\n- Verify version numbers, file paths, usage counts\n- Correct any discrepancies before final output\n\n### 6. Constitutional Compliance\nFollow [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md):\n- **Article I**: Evidence-based (all claims reference actual code)\n- **Article III**: Verification (run V1-V4 checks)\n- **Article V**: Transparency (show cache age, source, limitations)\n- **Article VII**: User Empowerment (actionable checklist, effort estimates)\n\n---\n\n## Self-Verification\n\nAfter generating your analysis, execute verification steps:\n\n### Step V1: Extract Verifiable Claims\nParse output for all quantifiable claims (counts, versions, file paths)\n\n### Step V2: Parallel Verification\n- Verify version detection\n- Verify API usage counts (¬±5% tolerance)\n- Verify file paths (sample 3-5 files)\n- Verify upgrade guide quality\n\n### Step V3: Handle Results\n- ‚úÖ All checks pass ‚Üí Proceed to output\n- ‚ö†Ô∏è Minor issues (1-2 checks) ‚Üí Correct and note\n- ‚ùå Major issues (3+ checks) ‚Üí Re-execute analysis\n\n### Step V4: Add Verification Summary\n```yaml\nverification_summary:\n  checks_performed: [...]\n  confidence_level: \"high\"  # high|medium|low\n  notes: [...]\n```\n\n‚Üí See [verification-guide.md](verification-guide.md) for complete checklist\n\n---\n\n## Advanced\n\n### Cache Behavior\n- **Default**: Use cache if exists and fresh\n- **Force flag**: Skip cache with `--force`\n- **Cache location**: `.sourceatlas/deps/${SANITIZED_TARGET}.md`\n\n‚Üí See [reference.md#cache-behavior](reference.md#cache-behavior)\n\n### Auto-Save Mechanism\nComplete YAML report auto-saves after verification:\n```\nüíæ Saved to .sourceatlas/deps/react-17-18.md\n```\n\n‚Üí See [reference.md#auto-save-behavior](reference.md#auto-save-behavior)\n\n### Handoffs to Next Commands\nAfter analysis, suggest appropriate next steps based on risk level.\n\n‚Üí See [reference.md#handoffs](reference.md#handoffs)\n\n### Language-Specific Tips\n- JavaScript/TypeScript: Include all variants (.js, .jsx, .ts, .tsx)\n- Swift/iOS: Exclude Pods directory, check `#available` patterns\n- Android/Kotlin: Check compileSdk, minSdk, targetSdk\n\n‚Üí See [reference.md#language-specific-best-practices](reference.md#language-specific-best-practices)\n\n---\n\n## Support Files\n\nDetailed documentation available in:\n\n- **[workflow.md](workflow.md)** - Complete Phase 0-5 execution guide with bash commands and examples\n- **[output-template.md](output-template.md)** - Full YAML structure, field descriptions, and examples\n- **[verification-guide.md](verification-guide.md)** - Self-verification steps V1-V4 with verification scripts\n- **[reference.md](reference.md)** - Cache behavior, auto-save, handoffs, language-specific tips\n\n---\n\n## Output Header\n\nStart your output with:\n\n```markdown\nüó∫Ô∏è SourceAtlas: Dependencies\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüì¶ [target] ‚îÇ [N] APIs found\n```\n\nThen output complete YAML following [output-template.md](output-template.md).\n",
        "plugin/commands/deps/output-template.md": "# Dependency Analysis Output Template\n\nComplete YAML format specification for dependency upgrade analysis.\n\n---\n\n## Header Format\n\n```markdown\nüó∫Ô∏è SourceAtlas: Dependencies\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüì¶ [target] ‚îÇ [N] APIs found\n```\n\n---\n\n## YAML Output Structure\n\n```yaml\ndependency_analysis:\n  target: \"${ARGUMENTS}\"\n  type: \"[library|sdk|framework|runtime]\"\n  analysis_time: \"[ISO 8601 timestamp]\"\n  constitution_version: \"1.1\"\n\nversion_info:\n  current: \"[detected version or 'unknown']\"\n  source: \"[package.json|Podfile|build.gradle|etc.]\"\n  target: \"[target version if upgrade]\"\n\nrules_applied:\n  source: \"[built-in|web_search|user_provided]\"\n  rule_count: [number]\n\n# ============================================\n# SECTION 1: Removable/Modifiable Code (Required for Upgrade)\n# ============================================\nrequired_changes:\n  removable_availability_checks:\n    description: \"Version checks that can be removed after upgrade\"\n    total: [number]\n    items:\n      - file: \"[path:line]\"\n        code: \"[#available(...)]\"\n        action: \"Can be removed\"\n\n  deprecated_api_usages:\n    description: \"Code using deprecated APIs\"\n    total: [number]\n    items:\n      - file: \"[path:line]\"\n        api: \"[deprecated API]\"\n        replacement: \"[new API]\"\n        migration_effort: \"[low|medium|high]\"\n\n  breaking_change_impacts:\n    description: \"Code affected by breaking changes\"\n    total: [number]\n    items:\n      - file: \"[path:line]\"\n        change: \"[breaking change description]\"\n        action: \"[required action]\"\n\n# ============================================\n# SECTION 2: Modernization Opportunities (Optional for Upgrade)\n# ============================================\nmodernization_opportunities:\n  description: \"New APIs/Patterns available after upgrade\"\n  items:\n    - category: \"[e.g., Observation Framework]\"\n      current_pattern: \"[e.g., ObservableObject + @Published]\"\n      new_pattern: \"[e.g., @Observable]\"\n      affected_files: [number]\n      benefit: \"[e.g., Reduce boilerplate code]\"\n      effort: \"[low|medium|high]\"\n      files:\n        - \"[path:line]\"\n\n# ============================================\n# SECTION 3: Usage Inventory\n# ============================================\nusage_inventory:\n  total_files: [number]\n  total_usage_points: [number]\n\n  by_category:\n    hooks:  # For React\n      - name: \"useState\"\n        count: [number]\n        files:\n          - \"[path:line]\"\n\n    components:  # For React/Vue\n      - name: \"Button\"\n        count: [number]\n        files:\n          - \"[path:line]\"\n\n    utilities:\n      - name: \"formatDate\"\n        count: [number]\n        files:\n          - \"[path:line]\"\n\n# ============================================\n# SECTION 4: Migration Checklist\n# ============================================\nmigration_checklist:\n  estimated_effort: \"[low|medium|high]\"\n  recommended_approach: \"[description]\"\n\n  steps:\n    - step: 1\n      action: \"[e.g., Update package.json]\"\n      command: \"[e.g., npm install react@18]\"\n\n    - step: 2\n      action: \"[e.g., Remove [N] availability checks]\"\n      files_affected: [number]\n\n    - step: 3\n      action: \"[e.g., Update [N] deprecated API usages]\"\n      files_affected: [number]\n\n    - step: 4\n      action: \"[e.g., Test all affected areas]\"\n      areas: [\"[area1]\", \"[area2]\"]\n\n# ============================================\n# SECTION 5: Risk Assessment\n# ============================================\nrisk_assessment:\n  overall_risk: \"[üü¢ low|üü° medium|üî¥ high]\"\n\n  factors:\n    breaking_changes: \"[none|minor|major]\"\n    usage_breadth: \"[isolated|moderate|widespread]\"\n    test_coverage: \"[good|partial|poor]\"\n    migration_guide_quality: \"[excellent|good|poor|missing]\"\n\n  recommendations:\n    - \"[Recommendation 1]\"\n    - \"[Recommendation 2]\"\n```\n\n---\n\n## Example: React Upgrade\n\n```yaml\ndependency_analysis:\n  target: \"react 17 ‚Üí 18\"\n  type: \"library\"\n  analysis_time: \"2026-01-13T15:30:00Z\"\n  constitution_version: \"1.1\"\n\nversion_info:\n  current: \"17.0.2\"\n  source: \"package.json\"\n  target: \"18.2.0\"\n\nrules_applied:\n  source: \"web_search\"\n  rule_count: 12\n\nrequired_changes:\n  deprecated_api_usages:\n    description: \"Code using deprecated APIs\"\n    total: 3\n    items:\n      - file: \"src/components/Header.tsx:45\"\n        api: \"ReactDOM.render()\"\n        replacement: \"ReactDOM.createRoot()\"\n        migration_effort: \"medium\"\n\n      - file: \"src/App.tsx:12\"\n        api: \"unstable_batchedUpdates\"\n        replacement: \"Automatic batching (remove)\"\n        migration_effort: \"low\"\n\nmodernization_opportunities:\n  items:\n    - category: \"Automatic Batching\"\n      current_pattern: \"Manual batching with unstable_batchedUpdates\"\n      new_pattern: \"Automatic batching (built-in)\"\n      affected_files: 8\n      benefit: \"Reduced boilerplate, better performance\"\n      effort: \"low\"\n      files:\n        - \"src/hooks/useAuth.ts:34\"\n        - \"src/utils/state.ts:67\"\n\nusage_inventory:\n  total_files: 145\n  total_usage_points: 487\n\n  by_category:\n    hooks:\n      - name: \"useState\"\n        count: 89\n        files:\n          - \"src/components/UserProfile.tsx:23\"\n          - \"src/hooks/useForm.ts:12\"\n\n    components:\n      - name: \"Suspense\"\n        count: 12\n        files:\n          - \"src/App.tsx:45\"\n\nmigration_checklist:\n  estimated_effort: \"medium\"\n  recommended_approach: \"Incremental migration - update root first, then components\"\n\n  steps:\n    - step: 1\n      action: \"Update package.json\"\n      command: \"npm install react@18 react-dom@18\"\n\n    - step: 2\n      action: \"Update root rendering\"\n      files_affected: 1\n\n    - step: 3\n      action: \"Remove 3 deprecated API usages\"\n      files_affected: 3\n\n    - step: 4\n      action: \"Test all components for automatic batching\"\n      areas: [\"forms\", \"auth\", \"data-fetching\"]\n\nrisk_assessment:\n  overall_risk: \"üü° medium\"\n\n  factors:\n    breaking_changes: \"minor\"\n    usage_breadth: \"widespread\"\n    test_coverage: \"good\"\n    migration_guide_quality: \"excellent\"\n\n  recommendations:\n    - \"Update tests to use createRoot API\"\n    - \"Review automatic batching behavior in forms\"\n    - \"Consider adopting new Suspense features\"\n```\n\n---\n\n## Example: iOS Minimum Version Upgrade\n\n```yaml\ndependency_analysis:\n  target: \"iOS 15 ‚Üí 17\"\n  type: \"runtime\"\n  analysis_time: \"2026-01-13T16:00:00Z\"\n  constitution_version: \"1.1\"\n\nversion_info:\n  current: \"iOS 15.0\"\n  source: \"Project.swift\"\n  target: \"iOS 17.0\"\n\nrequired_changes:\n  removable_availability_checks:\n    description: \"Version checks that can be removed\"\n    total: 23\n    items:\n      - file: \"Sources/UI/ProfileView.swift:45\"\n        code: \"if #available(iOS 15.0, *)\"\n        action: \"Can be removed - always true on iOS 17+\"\n\n      - file: \"Sources/UI/SettingsView.swift:89\"\n        code: \"if #available(iOS 16.0, *)\"\n        action: \"Can be removed - always true on iOS 17+\"\n\n  deprecated_api_usages:\n    total: 0\n    items: []\n\nmodernization_opportunities:\n  items:\n    - category: \"Observation Framework\"\n      current_pattern: \"ObservableObject + @Published\"\n      new_pattern: \"@Observable\"\n      affected_files: 34\n      benefit: \"Simpler syntax, better performance\"\n      effort: \"medium\"\n      files:\n        - \"Sources/ViewModels/UserViewModel.swift:12\"\n\nmigration_checklist:\n  estimated_effort: \"low\"\n  recommended_approach: \"Remove availability checks, consider modernization\"\n\n  steps:\n    - step: 1\n      action: \"Update minimum deployment target\"\n      command: \"Update Project.swift: deploymentTarget: .iOS('17.0')\"\n\n    - step: 2\n      action: \"Remove 23 availability checks\"\n      files_affected: 15\n\n    - step: 3\n      action: \"Test on iOS 17 simulator\"\n      areas: [\"all\"]\n\nrisk_assessment:\n  overall_risk: \"üü¢ low\"\n\n  factors:\n    breaking_changes: \"none\"\n    usage_breadth: \"moderate\"\n    test_coverage: \"good\"\n    migration_guide_quality: \"good\"\n\n  recommendations:\n    - \"Safe upgrade - mostly code cleanup\"\n    - \"Consider adopting @Observable for new code\"\n```\n\n---\n\n## Field Descriptions\n\n### dependency_analysis\n- **target**: Original ${ARGUMENTS} from user\n- **type**: library/sdk/framework/runtime\n- **analysis_time**: ISO 8601 timestamp\n- **constitution_version**: Current Constitution version\n\n### version_info\n- **current**: Detected from manifest file\n- **source**: Which file provided version info\n- **target**: Target version for upgrade\n\n### required_changes\nChanges that MUST be done for successful upgrade:\n- **removable_availability_checks**: Version checks that are now redundant\n- **deprecated_api_usages**: APIs that will be removed\n- **breaking_change_impacts**: Behavior changes\n\n### modernization_opportunities\nOptional improvements using new features:\n- **category**: Type of opportunity\n- **current_pattern**: How it's done now\n- **new_pattern**: Modern approach\n- **benefit**: Why it's better\n- **effort**: Migration complexity\n\n### usage_inventory\nComplete list of API usage:\n- **by_category**: Grouped by type (hooks, components, utilities)\n- Each entry includes count and file locations\n\n### migration_checklist\nStep-by-step upgrade guide:\n- **estimated_effort**: Overall complexity\n- **recommended_approach**: Strategy description\n- **steps**: Ordered actions with commands\n\n### risk_assessment\nRisk evaluation:\n- **overall_risk**: üü¢ low / üü° medium / üî¥ high\n- **factors**: Contributing risk elements\n- **recommendations**: Specific advice\n",
        "plugin/commands/deps/reference.md": "# Dependency Analysis Reference\n\nAdvanced features, caching behavior, and best practices.\n\n---\n\n## Cache Behavior\n\n### When Cache is Used\n\n```bash\n# Default: Use cache if exists and fresh\n/sourceatlas:deps \"react\"\n\n# Check logic:\nif [ -f \".sourceatlas/deps/${SANITIZED_TARGET}.md\" ]; then\n  age_days=$(calculate_age_in_days)\n  if [ $age_days -eq 0 ]; then\n    echo \"üìÅ Loading from cache (today)\"\n  elif [ $age_days -eq 1 ]; then\n    echo \"üìÅ Loading from cache (1 day ago)\"\n  else\n    echo \"üìÅ Loading from cache ($age_days days ago)\"\n  fi\n  # Output cached content\n  exit 0\nfi\n```\n\n### When Cache is Skipped\n\n```bash\n# Force flag: Always skip cache\n/sourceatlas:deps \"react\" --force\n# ‚Üí Executes full analysis even if cache exists\n\n# No cache: First time analysis\n# ‚Üí .sourceatlas/deps/ doesn't exist yet\n```\n\n### Cache File Naming\n\n```bash\n# Target sanitization rules:\n\"react 17 ‚Üí 18\"  ‚Üí \"react-17-18.md\"\n\"iOS 16\"         ‚Üí \"ios-16.md\"\n\"lodash\"         ‚Üí \"lodash.md\"\n\"@types/node\"    ‚Üí \"types-node.md\"\n\n# Pattern: lowercase, alphanumeric + hyphens only\nsanitized=$(echo \"$ARGUMENTS\" | tr '[:upper:]' '[:lower:]' | \\\n            sed 's/[^a-z0-9]/-/g' | sed 's/--*/-/g' | \\\n            sed 's/^-//' | sed 's/-$//')\n```\n\n---\n\n## Auto-Save Behavior\n\n### File Structure\n\n```\n.sourceatlas/deps/\n‚îú‚îÄ‚îÄ react-17-18.md           # Analysis for \"react 17 ‚Üí 18\"\n‚îú‚îÄ‚îÄ ios-16-17.md             # Analysis for \"iOS 16 ‚Üí 17\"\n‚îú‚îÄ‚îÄ lodash.md                # Analysis for \"lodash\"\n‚îî‚îÄ‚îÄ pandas-1x-2x.md          # Analysis for \"pandas 1.x ‚Üí 2.x\"\n```\n\n### Save Timing\n\nAuto-save occurs **immediately after Step V4 verification**:\n\n```yaml\n# After verification passes\nverification_summary:\n  confidence_level: \"high\"\n\n# Then auto-save\nüíæ Saved to .sourceatlas/deps/react-17-18.md\n```\n\n### What Gets Saved\n\nComplete YAML output including:\n- dependency_analysis header\n- version_info\n- rules_applied\n- required_changes (all items)\n- modernization_opportunities\n- usage_inventory (by_category)\n- migration_checklist\n- risk_assessment\n- verification_summary\n\n**Format:** Full YAML as specified in [output-template.md](output-template.md)\n\n---\n\n## Handoffs: When to Suggest Next Commands\n\n### After Usage Inventory (No Upgrade)\n\nIf user only asked for usage analysis without version upgrade:\n\n```yaml\nusage_inventory:\n  total_files: 45\n  total_usage_points: 123\n```\n\n**Suggest:**\n```\n‚ú® Next steps:\n- /sourceatlas:impact \"src/hooks/useAuth.ts\" - See impact of changing this hook\n- /sourceatlas:pattern \"react hooks\" - Learn project's hook patterns\n```\n\n### After Upgrade Analysis (Low Risk)\n\n```yaml\nrisk_assessment:\n  overall_risk: \"üü¢ low\"\n```\n\n**Suggest:**\n```\n‚ú® Next steps:\n- Update package.json and run tests\n- /sourceatlas:impact - Check impact after upgrade\n```\n\n### After Upgrade Analysis (Medium/High Risk)\n\n```yaml\nrisk_assessment:\n  overall_risk: \"üü° medium\"\n```\n\n**Suggest:**\n```\n‚ö†Ô∏è Recommended actions:\n1. Review all deprecated API usages carefully\n2. Create a feature branch for testing\n3. /sourceatlas:impact \"ComponentX\" - Analyze high-risk components first\n```\n\n### If WebSearch/WebFetch Failed\n\n```yaml\nrules_applied:\n  source: \"built-in\"  # Fallback to built-in rules\n```\n\n**Suggest:**\n```\n‚ö†Ô∏è Could not find official migration guide\nPlease manually review:\n- ${LIBRARY} official changelog\n- Breaking changes documentation\n```\n\n---\n\n## Language-Specific Best Practices\n\n### JavaScript/TypeScript (Node.js)\n\n**Manifest Files:**\n- `package.json` - Primary source\n- `package-lock.json` - Actual installed versions\n- `yarn.lock` or `pnpm-lock.yaml` - Alternative lock files\n\n**Search Tips:**\n```bash\n# Include all JS/TS variants\n--include=\"*.js\" --include=\"*.jsx\" --include=\"*.ts\" --include=\"*.tsx\"\n\n# Exclude common directories\ngrep -v \"node_modules\\|dist\\|build\\|.next\"\n\n# Monorepo: Check workspace packages\ngrep -r \"\\\"workspaces\\\"\" package.json\n```\n\n**Common Upgrade Patterns:**\n- Major versions (e.g., React 17 ‚Üí 18) ‚Üí Focus on breaking changes\n- Minor versions (e.g., Next.js 13.4 ‚Üí 13.5) ‚Üí Focus on new features\n- Patch versions ‚Üí Usually safe, check security fixes\n\n---\n\n### Swift/iOS\n\n**Manifest Files:**\n- `Podfile` - CocoaPods dependencies\n- `Package.swift` - Swift Package Manager\n- `Cartfile` - Carthage dependencies\n- Project settings (`.xcodeproj`) - iOS deployment target\n\n**Search Tips:**\n```bash\n# Availability checks\ngrep -rn \"#available(iOS\" --include=\"*.swift\" . | grep -v Pods\n\n# Framework imports\ngrep -rn \"^import UIKit\\|^import SwiftUI\" --include=\"*.swift\" .\n\n# Deprecated APIs\ngrep -rn \"@available(*, deprecated\" --include=\"*.swift\" .\n```\n\n**iOS Version Upgrades:**\n- iOS 15 ‚Üí 17: Focus on removable `#available` checks\n- iOS 17+: Consider new APIs like `@Observable`, `Observation`\n- Check Swift version compatibility\n\n---\n\n### Android/Kotlin\n\n**Manifest Files:**\n- `build.gradle` or `build.gradle.kts` - Main config\n- `settings.gradle` - Project structure\n- `gradle.properties` - SDK versions\n\n**Search Tips:**\n```bash\n# API level checks\ngrep -rn \"Build.VERSION.SDK_INT\" --include=\"*.kt\" --include=\"*.java\" .\n\n# Dependency versions\ngrep \"implementation\\|api\\|compileOnly\" build.gradle\n```\n\n---\n\n## WebSearch Strategy\n\n### Query Templates\n\nFor major version upgrades:\n```\n\"${LIBRARY} ${FROM_VERSION} to ${TO_VERSION} migration guide\"\n\"${LIBRARY} ${TO_VERSION} breaking changes\"\n\"${LIBRARY} changelog ${TO_VERSION}\"\n```\n\nFor iOS/Android SDK:\n```\n\"iOS ${TO_VERSION} migration guide\"\n\"Android API ${TO_VERSION} migration\"\n\"What's new in iOS ${TO_VERSION}\"\n```\n\n### Source Priority\n\n1. **Official docs** (highest priority)\n   - Library's official website\n   - GitHub releases page\n   - Official migration guides\n\n2. **Semi-official** (high priority)\n   - Framework maintainer blog posts\n   - Official YouTube channels\n   - Conference talks\n\n3. **Community** (medium priority)\n   - Dev.to, Medium articles by core contributors\n   - Stack Overflow highly-voted questions\n   - GitHub discussions\n\n4. **Avoid** (low priority)\n   - Random blogs without verification\n   - Outdated tutorials\n   - AI-generated content without sources\n\n---\n\n## Edge Cases\n\n### Case 1: Dependency Not Found in Manifest\n\n```yaml\nversion_info:\n  current: \"unknown\"\n  source: \"not found in manifest files\"\n```\n\n**Possible reasons:**\n1. Transitive dependency (not directly listed)\n2. Different package name\n3. Bundled in framework\n\n**Action:**\n- Search for import/require statements\n- Check lock files for transitive deps\n- Ask user to clarify package name\n\n---\n\n### Case 2: Multiple Versions Detected\n\n```bash\n# package.json shows 17.0.2\n# package-lock.json shows 17.0.1\n```\n\n**Action:**\n```yaml\nversion_info:\n  current: \"17.0.1\"  # Use lock file version\n  source: \"package-lock.json (installed)\"\n  note: \"package.json specifies ^17.0.2\"\n```\n\n---\n\n### Case 3: Monorepo with Multiple Packages\n\n```bash\n# Root package.json: \"react\": \"17.0.2\"\n# packages/app-a/package.json: \"react\": \"16.8.0\"\n```\n\n**Action:**\n1. Clarify scope with user:\n   ```\n   ‚ö†Ô∏è Multiple versions detected:\n   - Root: 17.0.2\n   - packages/app-a: 16.8.0\n\n   Analyzing root package by default.\n   Use `/sourceatlas:deps \"react\" --scope=app-a` to analyze specific package.\n   ```\n\n2. Analyze specified scope only\n\n---\n\n### Case 4: No Upgrade Guide Found\n\n```yaml\nrules_applied:\n  source: \"built-in\"\n  rule_count: 0\n```\n\n**Action:**\n1. Report usage statistics only\n2. Skip breaking changes analysis\n3. Recommend manual changelog review:\n\n```\n‚ö†Ô∏è Could not find migration guide for ${LIBRARY}\n\nProvided usage inventory only. Please manually review:\n- ${LIBRARY} official changelog\n- GitHub releases: https://github.com/${ORG}/${REPO}/releases\n```\n\n---\n\n## Performance Optimization\n\n### For Large Codebases\n\n```bash\n# Limit grep results to prevent timeout\ngrep -r \"pattern\" --include=\"*.js\" . | head -100\n\n# Use --max-count for early exit\ngrep -r --max-count=50 \"pattern\" .\n\n# Parallel search for multiple patterns\ngrep -r \"pattern1\" . & grep -r \"pattern2\" . & wait\n```\n\n### For Monorepos\n\n```bash\n# Skip non-source directories\ngrep -r \"pattern\" . \\\n  --exclude-dir=\"node_modules\" \\\n  --exclude-dir=\"dist\" \\\n  --exclude-dir=\"build\" \\\n  --exclude-dir=\".next\" \\\n  --exclude-dir=\"coverage\"\n```\n\n---\n\n## Troubleshooting\n\n### Issue: Version Detection Failed\n\n**Symptom:** `current: \"unknown\"`\n\n**Debug:**\n```bash\n# Check manifest file exists\nls -la package.json Podfile build.gradle\n\n# Verify file format\ncat package.json | python -m json.tool\n\n# Search more broadly\ngrep -i \"version\" package.json\n```\n\n---\n\n### Issue: No Usage Points Found\n\n**Symptom:** `total_usage_points: 0`\n\n**Debug:**\n```bash\n# Verify library name\necho \"Searching for: ${LIBRARY}\"\n\n# Try broader pattern\ngrep -r \"${LIBRARY}\" . | head -20\n\n# Check file extensions\nfind . -name \"*.js\" -o -name \"*.ts\" | head -10\n```\n\n---\n\n### Issue: WebSearch Returns Irrelevant Results\n\n**Symptom:** Migration guide for wrong version\n\n**Action:**\n1. Add version number to query: `\"react 18.0.0 migration\"` (not just \"react 18\")\n2. Add \"official\" keyword: `\"official react 18 migration guide\"`\n3. Use site-specific search: `\"site:reactjs.org migration guide\"`\n\n---\n\n## Constitutional Compliance\n\n### Article I: Evidence-Based Analysis\n- ‚úÖ Every claim must reference actual files\n- ‚úÖ Version numbers from manifest files only\n- ‚úÖ Usage counts from verified grep results\n\n### Article III: Verification Required\n- ‚úÖ Execute [verification-guide.md](verification-guide.md) before output\n- ‚úÖ Re-verify after corrections\n\n### Article V: Transparency\n- ‚úÖ Show cache age: \"Loading from cache (2 days ago)\"\n- ‚úÖ Disclose upgrade guide source: \"source: web_search\"\n- ‚úÖ Note any limitations: \"No official migration guide found\"\n\n### Article VII: User Empowerment\n- ‚úÖ Provide actionable migration checklist\n- ‚úÖ Estimate effort level\n- ‚úÖ Suggest next steps\n\n---\n\n## Related Commands\n\nAfter dependency analysis, consider:\n\n- **`/sourceatlas:impact \"Component\"`** - See change impact before upgrade\n- **`/sourceatlas:pattern \"api\"`** - Learn how project uses the library\n- **`/sourceatlas:history \"src/lib/\"`** - Check change frequency in affected areas\n",
        "plugin/commands/deps/verification-guide.md": "# Dependency Analysis Self-Verification Guide\n\nComplete verification checklist to ensure dependency analysis accuracy.\n\n---\n\n## When to Verify\n\nExecute after completing your dependency analysis, before outputting final results.\n\n---\n\n## Verification Steps\n\n### Step V1: Extract Verifiable Claims\n\nParse your analysis output to identify all **quantifiable claims**:\n\n```yaml\nverifiable_claims:\n  - \"Found [N] usage points\"\n  - \"Current version: [X.Y.Z]\"\n  - \"Detected in [file]\"\n  - \"[M] deprecated API usages\"\n  - \"[K] removable availability checks\"\n  - \"[P] new APIs available\"\n```\n\n**Extract these for verification:**\n- Version numbers (current/target)\n- File counts\n- API usage counts\n- Manifest file locations\n- Breaking change counts\n\n---\n\n### Step V2: Parallel Verification Execution\n\nRun verification commands in **parallel** for speed:\n\n#### V2.1: Verify Version Detection\n\n```bash\n# For Node.js/npm\ngrep '\"${LIBRARY}\"' package.json | head -5\n\n# For iOS/CocoaPods\ngrep \"platform :ios\" Podfile | head -5\n\n# For Android/Gradle\ngrep \"compileSdk\\|minSdk\\|targetSdk\" build.gradle build.gradle.kts | head -5\n```\n\n**Check:**\n- ‚úÖ Version numbers match manifest files\n- ‚úÖ Source file (package.json/Podfile) exists\n- ‚ö†Ô∏è If mismatch ‚Üí update analysis\n\n#### V2.2: Verify API Usage Counts\n\n```bash\n# Count import/require statements\ngrep -r \"import.*${LIBRARY}\\|require.*${LIBRARY}\" \\\n  --include=\"*.js\" --include=\"*.ts\" --include=\"*.tsx\" \\\n  . | grep -v node_modules | wc -l\n\n# Count specific API usage\ngrep -r \"\\.${API_NAME}\\|${API_NAME}(\" \\\n  --include=\"*.js\" --include=\"*.ts\" \\\n  . | grep -v node_modules | wc -l\n```\n\n**Check:**\n- ‚úÖ Usage count matches analysis (¬±5% tolerance)\n- ‚ö†Ô∏è If significant difference ‚Üí re-search with better patterns\n\n#### V2.3: Verify File Paths\n\nSample 3-5 file paths from your analysis:\n\n```bash\n# Check files exist\nfor file in \"${FILE_PATHS[@]}\"; do\n  if [ ! -f \"$file\" ]; then\n    echo \"‚ö†Ô∏è Not found: $file\"\n  fi\ndone\n\n# Verify line numbers\ngrep -n \"${PATTERN}\" \"${FILE_PATH}\" | head -3\n```\n\n**Check:**\n- ‚úÖ All sampled file paths exist\n- ‚úÖ Line numbers are accurate (¬±2 lines)\n- ‚ö†Ô∏è If file not found ‚Üí remove from analysis\n\n#### V2.4: Verify Upgrade Guide Source\n\nIf you used WebSearch/WebFetch:\n\n```bash\n# Verify URL accessibility (if applicable)\n# Check migration guide quality indicators\n```\n\n**Check:**\n- ‚úÖ URLs are official sources (not third-party blogs)\n- ‚úÖ Migration guide matches target version\n- ‚ö†Ô∏è If quality low ‚Üí note in risk_assessment\n\n---\n\n### Step V3: Handle Verification Results\n\nBased on verification outcomes:\n\n#### If All Checks Pass ‚úÖ\n\n```yaml\nverification_status:\n  verified: true\n  checks_passed: 4\n  confidence: high\n```\n\nProceed to output.\n\n#### If Minor Issues Found ‚ö†Ô∏è (1-2 checks failed)\n\n**Examples:**\n- File path off by 1-2 lines\n- Usage count difference <10%\n- Version detection from wrong source\n\n**Action:**\n1. Correct the specific claims\n2. Re-verify those claims\n3. Add note to output:\n\n```yaml\nverification_notes:\n  - \"Line numbers adjusted after verification\"\n  - \"Usage count corrected to [N] (was [M])\"\n```\n\n#### If Major Issues Found ‚ùå (3+ checks failed)\n\n**Examples:**\n- Claimed files don't exist\n- Usage count off by >50%\n- Version numbers completely wrong\n- Upgrade guide for wrong version\n\n**Action:**\n1. **STOP** - Do not output current analysis\n2. Re-execute Phase 1-5 from [workflow.md](workflow.md)\n3. Use better search patterns\n4. Verify each step before proceeding\n\n---\n\n### Step V4: Verification Summary\n\nAdd to final output:\n\n```yaml\nverification_summary:\n  timestamp: \"[ISO 8601]\"\n  checks_performed:\n    - \"Version detection: ‚úÖ\"\n    - \"API usage counts: ‚úÖ\"\n    - \"File path accuracy: ‚úÖ\"\n    - \"Upgrade guide quality: ‚úÖ\"\n\n  confidence_level: \"high\"  # high|medium|low\n  notes:\n    - \"[Any corrections made]\"\n```\n\n**Confidence Level Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **High** | All 4 checks passed, official sources, recent data |\n| **Medium** | 3/4 checks passed, or no official migration guide |\n| **Low** | <3 checks passed, or upgrade guide missing |\n\n---\n\n## Verification Examples\n\n### Example 1: React Upgrade\n\n**Claim:** \"Found 89 useState usages\"\n\n**Verification:**\n```bash\ngrep -r \"useState\" --include=\"*.ts\" --include=\"*.tsx\" . | \\\n  grep -v node_modules | grep -v \".test.\" | wc -l\n# Output: 87\n```\n\n**Result:** ‚ö†Ô∏è Minor difference (89 ‚Üí 87)\n\n**Action:**\n- Update analysis: `useState: 87 usages`\n- Note: \"Count verified and adjusted\"\n\n---\n\n### Example 2: iOS Version Upgrade\n\n**Claim:** \"23 removable availability checks\"\n\n**Verification:**\n```bash\ngrep -rn \"#available(iOS 1[0-6]\" --include=\"*.swift\" . | \\\n  grep -v Pods | wc -l\n# Output: 23\n```\n\n**Result:** ‚úÖ Exact match\n\n**Action:** Proceed with confidence\n\n---\n\n### Example 3: Version Detection\n\n**Claim:** \"Current version: 17.0.2\"\n\n**Verification:**\n```bash\ngrep '\"react\"' package.json\n# Output: \"react\": \"17.0.1\"\n```\n\n**Result:** ‚ùå Version mismatch\n\n**Action:**\n- Correct to 17.0.1\n- Re-check if this affects breaking changes analysis\n- Verify package-lock.json for actual installed version\n\n---\n\n## Error Recovery\n\n### If Verification Script Fails\n\n```bash\n# If grep returns no results\n# ‚Üí Pattern might be too specific, broaden search\n\n# If file not found\n# ‚Üí Use find command to locate similar files\n\n# If command times out\n# ‚Üí Add --max-count or | head -N to limit results\n```\n\n### If Count Discrepancy Large (>20%)\n\n**Likely causes:**\n1. Search pattern too narrow/broad\n2. Wrong file extensions\n3. Forgot to exclude test files\n4. Manifest file outdated\n\n**Action:**\n1. Review search pattern from [workflow.md#phase-3](workflow.md#phase-3)\n2. Check file extensions match project\n3. Verify .gitignore patterns\n4. Use Glob to list files first, then grep\n\n---\n\n## Best Practices\n\n1. **Always verify version numbers** - Most critical for upgrade analysis\n2. **Sample at least 3 file paths** - Ensures grep patterns worked\n3. **Check official sources first** - Community guides are secondary\n4. **Note all corrections** - Transparency builds trust\n5. **Re-verify after corrections** - Don't assume fix is correct\n\n---\n\n## Handoff to Next Steps\n\nAfter verification:\n- ‚úÖ If confidence HIGH ‚Üí Proceed to output\n- ‚ö†Ô∏è If confidence MEDIUM ‚Üí Warn user about limitations\n- ‚ùå If confidence LOW ‚Üí Re-execute analysis or ask user for help\n\nSee [reference.md#handoffs](reference.md#handoffs) for when to suggest next commands.\n",
        "plugin/commands/deps/workflow.md": "# Dependency Analysis Workflow\n\nComplete step-by-step guide for dependency upgrade analysis.\n\n---\n\n## Phase 0: Rule Confirmation (1-2 minutes)\n\n### Step 0.1: Identify Upgrade Type\n\nBased on `${ARGUMENTS}`:\n\n| Input Pattern | Type | Focus Areas |\n|---------------|------|-------------|\n| `iOS 17`, `iOS 16 ‚Üí 17` | iOS Minimum Version Upgrade | Removable #available, deprecated APIs, new opportunities |\n| `iOS SDK 26`, `Xcode 16` | SDK/Compiler Upgrade | Compilation warnings, Swift version, new syntax |\n| `react 17 ‚Üí 18`, `pandas 1.x ‚Üí 2.x` | Major Version Upgrade | Breaking changes, deprecated APIs, new patterns |\n| `react`, `pandas` (no version) | Usage Inventory | List usage points only |\n\n### Step 0.2: Generate Rules Preview\n\nOutput YAML for user confirmation:\n```yaml\nupgrade_rules_preview:\n  detected_upgrade_type: \"[type]\"\n  from_version: \"[current]\"\n  to_version: \"[target]\"\n\n  planned_checks:\n    removable_availability_checks:\n      patterns: [\"#available(iOS [version below target]\"]\n    deprecated_apis:\n      source: \"[built-in|web_search|migration_guide]\"\n```\n\n### Step 0.3: Confirm with User\n\nUse `AskUserQuestion` to confirm rules before proceeding.\n\n---\n\n## Phase 1: Detect Current Version (1 minute)\n\n### For Node.js/npm\n\n```bash\n# package.json\ngrep '\"${LIBRARY}\"' package.json\n```\n\n### For iOS/CocoaPods\n\n```bash\n# Podfile or Podfile.lock\ngrep \"${POD_NAME}\" Podfile Podfile.lock\n```\n\n### For Android/Gradle\n\n```bash\n# build.gradle or build.gradle.kts\ngrep \"${DEPENDENCY}\" build.gradle build.gradle.kts\n```\n\n---\n\n## Phase 2: Search for Upgrade Guide (2-3 minutes)\n\n### Use WebSearch\n\n```bash\n# Search for official migration guide\nWebSearch: \"${LIBRARY} ${FROM_VERSION} to ${TO_VERSION} migration guide\"\nWebSearch: \"${LIBRARY} breaking changes ${TO_VERSION}\"\n```\n\n### Priority Order\n\n1. Official migration guide\n2. Official changelog\n3. Community upgrade guides\n4. GitHub release notes\n\n---\n\n## Phase 3: Find All Usage Points (3-5 minutes)\n\n### For JavaScript/TypeScript\n\n```bash\n# Import statements\ngrep -rn \"^import.*${LIBRARY}\\|require.*${LIBRARY}\" --include=\"*.ts\" --include=\"*.tsx\" --include=\"*.js\" --include=\"*.jsx\" . | grep -v node_modules | head -100\n\n# Specific API usage\ngrep -rn \"\\.${API_NAME}\\|${API_NAME}(\" --include=\"*.ts\" --include=\"*.tsx\" . | grep -v node_modules | head -50\n```\n\n### For Swift/iOS\n\n```bash\n# Import statements\ngrep -rn \"^import ${FRAMEWORK}\" --include=\"*.swift\" . | grep -v Pods | head -100\n\n# Specific API usage (UIKit)\ngrep -rn \"UIView\\|UIViewController\\|UITableView\\|UICollectionView\" --include=\"*.swift\" . | grep -v Pods | head -30\n\n# Availability checks\ngrep -rn \"#available(iOS\" --include=\"*.swift\" . | grep -v Pods | head -50\n```\n\n### For Android/Kotlin\n\n```bash\n# Import statements\ngrep -rn \"^import.*${LIBRARY}\" --include=\"*.kt\" --include=\"*.java\" . | grep -v build | head -50\n```\n\n---\n\n## Phase 4: Categorize API Usage (2-3 minutes)\n\nFrom usage points found:\n\n1. **Count unique APIs** used\n2. **Group by category** (hooks, components, utilities, etc.)\n3. **Note frequency** for each API\n4. **Identify file:line** for each usage type\n5. **Match against Phase 0 rules** to flag deprecated/removable items\n\n---\n\n## Phase 5: Generate Analysis Report\n\nSee [output-template.md](output-template.md) for complete format.\n\n---\n\n## Language-Specific Tips\n\n### Swift/iOS\n\n**Find removable availability checks:**\n```bash\n# iOS version checks below target\ngrep -rn \"#available(iOS 14\" --include=\"*.swift\" . | grep -v Pods\ngrep -rn \"#available(iOS 15\" --include=\"*.swift\" . | grep -v Pods\n# If target is iOS 17, these can be removed\n```\n\n**Find deprecated APIs:**\n```bash\n# UIWebView (deprecated)\ngrep -rn \"UIWebView\" --include=\"*.swift\" . | grep -v Pods\n\n# @UIApplicationMain (use @main instead)\ngrep -rn \"@UIApplicationMain\" --include=\"*.swift\" . | grep -v Pods\n```\n\n### React/JavaScript\n\n**Find deprecated patterns:**\n```bash\n# Legacy lifecycle methods\ngrep -rn \"componentWillMount\\|componentWillReceiveProps\" --include=\"*.js\" --include=\"*.jsx\" .\n\n# String refs (deprecated)\ngrep -rn 'ref=\"' --include=\"*.js\" --include=\"*.jsx\" .\n```\n\n---\n\n## Error Handling\n\n**If upgrade guide not found:**\n- Search broader terms\n- Check library's official GitHub releases\n- Ask user if they have migration guide URL\n\n**If no usage found:**\n- Verify dependency actually installed\n- Check different file extensions\n- Suggest dependency might be unused\n\n**If breaking changes unclear:**\n- Report usage statistics only\n- Recommend manual review of changelog\n- Provide comparison script for major APIs\n",
        "plugin/commands/flow/SKILL.md": "---\nname: flow\ndescription: Extract business logic flow from code, trace execution path from entry point\nmodel: opus\nallowed-tools: Bash, Glob, Grep, Read, Write\nargument-hint: [flow description or entry point, e.g., \"user checkout\", \"from OrderService.create()\"] [--force]\n---\n\n# SourceAtlas: Flow Analysis\n\n**Target:** $ARGUMENTS\n\n---\n\n## STEP 0: Mode Detection (EXECUTE IMMEDIATELY)\n\n**IMPORTANT: Check these patterns FIRST before doing anything else.**\n\n### Check for Tier 2-3 Keywords (External Mode Required)\n\nScan `$ARGUMENTS` for these keywords. **If ANY match, load external file and STOP reading this document:**\n\n| If arguments contain... | Then execute this action |\n|------------------------|--------------------------|\n| \"dead code\" OR \"unreachable\" OR \"unused\" | `Read scripts/atlas/flow-modes/mode-13-dead-code.md` then follow its instructions |\n| \"async\" OR \"thread\" OR \"concurrent\" OR \"race\" | `Read scripts/atlas/flow-modes/mode-14-concurrency.md` then follow its instructions |\n| \"taint\" OR \"injection\" OR \"untrusted\" | `Read scripts/atlas/flow-modes/mode-12-taint-analysis.md` then follow its instructions |\n| \"state\" OR \"status\" OR \"lifecycle\" | `Read scripts/atlas/flow-modes/mode-04-state-machine.md` then follow its instructions |\n| \"transaction\" OR \"rollback\" OR \"commit\" | `Read scripts/atlas/flow-modes/mode-09-transaction.md` then follow its instructions |\n| \"log\" OR \"logging\" OR \"from logs\" | `Read scripts/atlas/flow-modes/mode-06-log-discovery.md` then follow its instructions |\n| \"compare\" OR \"diff\" OR \"vs\" | `Read scripts/atlas/flow-modes/mode-05-flow-comparison.md` then follow its instructions |\n| \"feature toggle\" OR \"feature flag\" | `Read scripts/atlas/flow-modes/mode-07-feature-toggle.md` then follow its instructions |\n| \"cache\" OR \"redis\" OR \"TTL\" | `Read scripts/atlas/flow-modes/mode-11-cache-flow.md` then follow its instructions |\n\n**If a keyword matched above**: Load the file NOW, then execute ONLY that mode's instructions. Do NOT continue reading this document.\n\n### Check for Tier 1 Keywords (Built-in Modes)\n\nIf none of the above matched, check for these Tier 1 patterns:\n\n| If arguments contain... | Mode to use |\n|------------------------|-------------|\n| \"who calls\" OR \"callers\" OR \"called by\" | Mode 1: Reverse Tracing (see below) |\n| \"error\" OR \"failure\" OR \"exception\" OR \"fail\" | Mode 2: Error Path (see below) |\n| \"data flow\" OR \"how is X calculated\" OR \"trace variable\" | Mode 3: Data Flow (see below) |\n| \"event\" OR \"message\" OR \"pub/sub\" OR \"listener\" | Mode 8: Event Tracing (see below) |\n| \"permission\" OR \"role\" OR \"auth\" OR \"access control\" | Mode 10: Permission Flow (see below) |\n| (none of the above) | Standard Flow Tracing (default) |\n\n---\n\n## STEP 1: Cache Check\n\nIf `--force` NOT in arguments:\n1. Convert flow name to filename: lowercase, spaces‚Üíhyphens, max 50 chars\n2. Check: `ls .sourceatlas/flows/{name}.md 2>/dev/null`\n3. If exists: Load and output cache, then STOP\n4. If not exists: Continue\n\n---\n\n## STEP 2: Find Entry Point\n\n**If explicit path given** (e.g., \"from OrderService.create()\"):\n‚Üí Start tracing immediately\n\n**If flow description only** (e.g., \"checkout flow\"):\n‚Üí Search for entry points:\n```bash\ngrep -rn \"{keyword}\" --include=\"*.ts\" --include=\"*.js\" --include=\"*.py\" src/ app/ lib/ 2>/dev/null | head -15\n```\n‚Üí Present options if multiple matches\n\n---\n\n## STEP 3: Trace Flow\n\nFrom entry point, trace each step:\n1. Read the function\n2. Identify what it calls\n3. Follow the chain (depth: 5 levels default)\n4. Stop at boundaries (DB, external API, third-party)\n\nFor each step capture:\n- Function name\n- File:line location\n- Business meaning\n- Notable patterns (üîí security, üíæ DB, üåê API, ‚ö° async, ‚ö†Ô∏è risk)\n\n---\n\n## STEP 4: Output Format\n\n```\n{Flow Name}\n===========\n\nEntry Point: {file}:{line}\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Step ‚îÇ Operation                    ‚îÇ Location              ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  1   ‚îÇ {description}                ‚îÇ {file}:{line}         ‚îÇ\n‚îÇ  2   ‚îÇ {description}                ‚îÇ {file}:{line}         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nFlow Diagram:\n{entry}() ‚Üí {step1}() ‚Üí {step2}() ‚Üí {step3}()\n\nNotable Patterns:\n‚îú‚îÄ‚îÄ üîí {pattern1}\n‚îú‚îÄ‚îÄ üíæ {pattern2}\n‚îî‚îÄ‚îÄ ‚ö†Ô∏è {pattern3}\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Mode: Standard | Confidence: ~85% | Depth: 5\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n```\n\n---\n\n## Tier 1 Mode: Reverse Tracing\n\n**Trigger**: \"who calls\", \"callers\", \"called by\"\n\nFind all callers of target function:\n```\nWho calls {function}?\n=====================\n\nCallers (N found):\n‚îú‚îÄ‚îÄ {Caller1}()  ‚Üí {description}\n‚îÇ   üìç {file}:{line}\n‚îú‚îÄ‚îÄ {Caller2}()  ‚Üí {description}\n‚îÇ   üìç {file}:{line}\n‚îî‚îÄ‚îÄ {Caller3}()  ‚Üí {description}\n    üìç {file}:{line}\n\nüí° Modifying {function} affects these {N} callers\n```\n\n---\n\n## Tier 1 Mode: Error Path\n\n**Trigger**: \"error\", \"failure\", \"exception\", \"fail\"\n\nTrace failure scenarios:\n```\n{Flow} Error Paths\n==================\n\n1. {Step}\n   üìç {file}:{line}\n   ‚ö†Ô∏è Failure ‚Üí {ErrorType}\n      ‚îî‚îÄ‚îÄ {what happens}\n\nüìå Risk: {identified risk}\n```\n\n---\n\n## Tier 1 Mode: Data Flow\n\n**Trigger**: \"data flow\", \"how is X calculated\", \"trace variable\"\n\nTrack data transformations:\n```\nData Flow: {variable}\n=====================\n\n[Input] {source}\n   ‚Üì\n1. {Transform}  ‚Üí {result}\n   üìç {file}:{line}\n   ‚Üì\n[Output] {final}\n```\n\n---\n\n## Tier 1 Mode: Event Tracing\n\n**Trigger**: \"event\", \"message\", \"pub/sub\", \"listener\"\n\n```\n{EVENT} Tracing\n===============\n\nüì§ Emission: {Publisher}() ‚Üí emit(\"{EVENT}\")\n   üìç {file}:{line}\n\nüì• Listeners:\n‚îú‚îÄ‚îÄ {Listener1}()  ‚Üí {action}\n‚îÇ   üìç {file}:{line}\n‚îî‚îÄ‚îÄ {Listener2}()  ‚Üí {action}\n    üìç {file}:{line}\n```\n\n---\n\n## Tier 1 Mode: Permission Flow\n\n**Trigger**: \"permission\", \"role\", \"auth\", \"access control\"\n\n```\n{Operation} by Role\n===================\n\n[ADMIN] ‚Üí Full access\n‚îú‚îÄ‚îÄ {check}  üîê @RequireRole(\"ADMIN\")\n‚îî‚îÄ‚îÄ üìç {file}:{line}\n\n[USER] ‚Üí Limited access\n‚îú‚îÄ‚îÄ {check}  üîê @CheckOwnership\n‚îî‚îÄ‚îÄ üìç {file}:{line}\n```\n\n---\n\n## Self-Verification\n\nBefore output, verify:\n1. File paths exist: `test -f {path}`\n2. Methods exist: `grep -q \"{method}\" {file}`\n\nAdd to footer: `‚úÖ Verified: [N] paths, [M] methods`\n\n---\n\n## Auto-Save (Default Behavior)\n\nAfter analysis completes, automatically:\n1. `mkdir -p .sourceatlas/flows`\n2. Save to `.sourceatlas/flows/{name}.md`\n3. Append: `üíæ Saved to .sourceatlas/flows/{name}.md`\n\n---\n\n## Deprecated: --save flag\n\nIf `--save` is in arguments:\n- Show: `‚ö†Ô∏è --save is deprecated, auto-save is now default`\n- Remove `--save` from arguments\n- Continue normal execution (still auto-saves)\n\n---\n\nüó∫Ô∏è SourceAtlas v3.0 ‚îÇ Tiered Architecture\n",
        "plugin/commands/history/SKILL.md": "---\nname: history\ndescription: Smart temporal analysis using git history - Hotspots, Coupling, and Recent Contributors\nmodel: sonnet\nallowed-tools: Bash, Glob, Grep, Read, Write, AskUserQuestion\nargument-hint: (optional) [path or scope, e.g., \"src/\", \"frontend\", \"last 6 months\"] [--force]\n---\n\n# SourceAtlas: Smart Temporal Analysis (Git History)\n\n> **Constitution**: [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md) v1.0\n\n## Context\n\n**Analysis Scope:** $ARGUMENTS (default: entire repository)\n**Goal:** Extract actionable insights from git history\n**Time Limit:** 5-10 minutes\n**Prerequisite:** code-maat (will ask permission to install if missing)\n\n## Quick Start\n\n1. **Check cache** (skip if `--force` flag present)\n2. **Check code-maat** installation (install if needed with permission)\n3. **Generate git log** (last 12 months, code-maat compatible)\n4. **Run analyses**: Hotspots, Coupling, Contributors\n5. **Risk assessment** combining all dimensions\n6. **Generate report** following [output-template.md](output-template.md)\n7. **Verify output** using [verification-guide.md](verification-guide.md)\n8. **Auto-save** to `.sourceatlas/history.md`\n\n## Your Task\n\nYou are analyzing git commit history to understand:\n1. **Hotspots** - Files changed most frequently (likely complex/risky)\n2. **Temporal Coupling** - Files that change together (hidden dependencies)\n3. **Recent Contributors** - Who has knowledge of which areas (bus factor)\n4. **Risk Areas** - Aggregate assessment for prioritization\n\n### What You'll Discover\n\n| Analysis Type | Insight | Business Value |\n|---------------|---------|----------------|\n| **Hotspots** | Complexity indicators | Refactoring priorities, technical debt |\n| **Coupling** | Hidden dependencies | Architecture review targets |\n| **Contributors** | Knowledge distribution | Bus factor risks, training needs |\n| **Risk** | Aggregate assessment | Resource allocation decisions |\n\n---\n\n## Core Workflow\n\nExecute these steps in order. See [workflow.md](workflow.md) for complete details.\n\n### Step 0: Check Prerequisites (30 seconds)\n\n**Purpose:** Ensure code-maat is installed and Java is available.\n\n**Check code-maat:**\n```bash\nif [ -f \"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\" ]; then\n  export CODEMAAT_JAR=\"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\"\nfi\n```\n\n**If not found, use AskUserQuestion:**\n- \"code-maat required for analysis. Install now? (requires Java 8+)\"\n- If yes ‚Üí run `./scripts/install-codemaat.sh`\n- If no ‚Üí show manual installation steps\n\n‚Üí See [workflow.md#step-0](workflow.md#step-0-check-prerequisites-30-seconds)\n\n### Step 1: Generate Git Log (1 minute)\n\n**Purpose:** Create code-maat compatible git log file.\n\n**Default: Last 12 months**\n```bash\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-12m +%Y-%m-%d)\" \\\n    > /tmp/git-history.log\n```\n\n**If scope specified:** Filter to directory (e.g., \"src/\")\n\n‚Üí See [workflow.md#step-1](workflow.md#step-1-generate-git-log-1-minute)\n\n### Step 2: Hotspot Analysis (2 minutes)\n\n**Purpose:** Identify frequently changed files.\n\n**Run code-maat revisions:**\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a revisions\n```\n\n**Calculate complexity scores:** LOC √ó Revisions\n\n**Identify top 10 hotspots** sorted by complexity\n\n‚Üí See [workflow.md#step-2](workflow.md#step-2-hotspot-analysis-2-minutes)\n\n### Step 3: Temporal Coupling Analysis (2 minutes)\n\n**Purpose:** Find files that change together.\n\n**Run code-maat coupling:**\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a coupling\n```\n\n**Filter significant couplings:** degree ‚â• 0.5\n\n**Categorize:** Expected vs Suspicious\n\n‚Üí See [workflow.md#step-3](workflow.md#step-3-temporal-coupling-analysis-2-minutes)\n\n### Step 4: Recent Contributors Analysis (2 minutes)\n\n**Purpose:** Map knowledge distribution across modules.\n\n**Run code-maat entity-ownership:**\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a entity-ownership\n```\n\n**Generate knowledge map** by area (src/api/, src/core/, etc.)\n\n**Identify bus factor risks:** Single-contributor modules\n\n‚Üí See [workflow.md#step-4](workflow.md#step-4-recent-contributors-analysis-2-minutes)\n\n### Step 5: Risk Assessment (1 minute)\n\n**Purpose:** Combine all dimensions into actionable priorities.\n\n**Calculate composite risk:** (Revisions √ó Coupling_Count) / Contributor_Count\n\n**Risk categories:**\n- Bus Factor Risk\n- Complexity Risk\n- Coupling Risk\n- Testing Gap Risk\n\n‚Üí See [workflow.md#step-5](workflow.md#step-5-risk-assessment-1-minute)\n\n---\n\n## Output Format\n\nYour analysis should follow this Markdown structure:\n\n```markdown\nüó∫Ô∏è SourceAtlas: History\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìú [repo name] ‚îÇ [N] months\n\n**Analysis Period**: [start] ‚Üí [end]\n**Commits Analyzed**: [count]\n**Files Analyzed**: [count]\n\n## 1. Hotspots (Top 10)\n[Table with Rank, File, Changes, LOC, Complexity Score]\n[Insights paragraph]\n\n## 2. Temporal Coupling (Significant Pairs)\n[Table with File A, File B, Coupling, Co-changes]\n[Expected vs Suspicious coupling analysis]\n\n## 3. Recent Contributors (Knowledge Map)\n[Per-area tables with Contributor, Commits, Last Active]\n[Bus Factor Risks section]\n\n## 4. Risk Summary\n[Risk aggregation table]\n[Priority Actions numbered list]\n\n## 5. Recommendations\n[Refactoring candidates, knowledge sharing, architecture review]\n\n## Recommended Next\n[Dynamic suggestions based on findings]\n```\n\n‚Üí See [output-template.md](output-template.md) for complete specification and examples\n\n---\n\n## Critical Rules\n\n### 1. Privacy Aware\n- Use \"Recent Contributors\" not \"Ownership %\"\n- Focus on knowledge distribution, not blame\n- Frame findings as opportunities, not criticisms\n\n### 2. Actionable Insights\n- Every finding must have recommended action\n- Reference specific commit counts and file paths\n- Provide concrete next steps (not vague suggestions)\n\n### 3. Evidence-Based\n- All hotspot files must exist (verify)\n- Commit counts must match git history (¬±20% tolerance)\n- Contributor names must be in git log\n\n### 4. Time-Bounded\n- Default: 12 months (good balance)\n- Minimum: 3 months (for meaningful patterns)\n- Maximum: 24 months (avoid ancient history)\n\n### 5. Verification Required\n- Execute [verification-guide.md](verification-guide.md) after analysis\n- Verify file paths, commit counts, contributors\n- Correct discrepancies before output\n\n### 6. Constitutional Compliance\nFollow [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md):\n- **Article I**: Evidence-based (all claims from git/code-maat)\n- **Article III**: Verification (run V1-V4 checks)\n- **Article IV**: Evidence format (file:line references)\n- **Article V**: Transparency (show analysis period, cache age)\n- **Article VII**: User Empowerment (actionable recommendations)\n\n---\n\n## Self-Verification\n\nAfter generating your analysis, execute verification steps:\n\n### Step V1: Extract Verifiable Claims\nParse output for all quantifiable claims:\n- File paths (hotspots, coupled files)\n- Commit counts (total, per file, per contributor)\n- Contributor names\n- Coupling pairs\n- Date ranges\n\n### Step V2: Parallel Verification\n- Verify hotspot files exist (sample 3-5)\n- Verify commit counts (¬±20% tolerance)\n- Verify contributors in git history\n- Verify coupling pairs (both files exist)\n- Verify date ranges within repository history\n\n### Step V3: Handle Results\n- ‚úÖ All checks pass ‚Üí Proceed to output\n- ‚ö†Ô∏è Minor issues (1-2 checks) ‚Üí Correct and note\n- ‚ùå Major issues (3+ checks) ‚Üí Re-execute analysis\n\n### Step V4: Add Verification Summary\n```yaml\nverification_summary:\n  checks_performed: [...]\n  confidence_level: \"high\"  # high|medium|low\n  notes: [...]\n```\n\n‚Üí See [verification-guide.md](verification-guide.md) for complete checklist\n\n---\n\n## Advanced\n\n### Cache Behavior\n- **Default**: Use cache if exists\n- **Force flag**: Skip cache with `--force`\n- **Cache location**: `.sourceatlas/history.md` (fixed path)\n- **Cache age warning**: If >30 days old\n\n‚Üí See [reference.md#cache-behavior](reference.md#cache-behavior)\n\n### Auto-Save Mechanism\nComplete Markdown report auto-saves after verification:\n```\nüíæ Saved to .sourceatlas/history.md\n```\n\n‚Üí See [reference.md#auto-save-behavior](reference.md#auto-save-behavior)\n\n### Handoffs to Next Commands\nBased on findings, suggest:\n- High-risk hotspot ‚Üí `/sourceatlas:impact \"[hotspot]\"`\n- Suspicious coupling ‚Üí `/sourceatlas:flow \"[entry point]\"`\n- Refactoring needed ‚Üí `/sourceatlas:pattern \"[pattern]\"`\n\n‚Üí See [reference.md#handoffs](reference.md#handoffs)\n\n### code-maat Installation\n- Default location: `~/.sourceatlas/bin/code-maat-1.0.4-standalone.jar`\n- Auto-install via: `./scripts/install-codemaat.sh`\n- Requires: Java 8+\n\n‚Üí See [reference.md#code-maat-installation](reference.md#code-maat-installation)\n\n### Interpretation Guidelines\n- Hotspots: Not always bad (core logic changes often)\n- Coupling: Expected (same domain) vs Suspicious (cross-module)\n- Contributors: Healthy = 2-3 per module, Risk = single contributor\n\n‚Üí See [reference.md#interpretation-guidelines](reference.md#interpretation-guidelines)\n\n---\n\n## Support Files\n\nDetailed documentation available in:\n\n- **[workflow.md](workflow.md)** - Complete Step 0-5 execution guide with bash commands\n- **[output-template.md](output-template.md)** - Full Markdown structure and examples\n- **[verification-guide.md](verification-guide.md)** - Self-verification steps V1-V4\n- **[reference.md](reference.md)** - Cache, code-maat, interpretation, troubleshooting\n\n---\n\n## Output Header\n\nStart your output with:\n\n```markdown\nüó∫Ô∏è SourceAtlas: History\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìú [repo name] ‚îÇ [N] months\n```\n\nThen follow complete structure in [output-template.md](output-template.md).\n",
        "plugin/commands/history/output-template.md": "# History Analysis Output Template\n\nComplete Markdown format specification for temporal analysis reports.\n\n---\n\n## Header Format\n\n```markdown\nüó∫Ô∏è SourceAtlas: History\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìú [repo name] ‚îÇ [N] months\n\n**Analysis Period**: [start date] ‚Üí [end date]\n**Commits Analyzed**: [count]\n**Files Analyzed**: [count]\n```\n\n---\n\n## Section 1: Hotspots (Top 10)\n\nFiles changed most frequently - likely complex or frequently enhanced.\n\n```markdown\n## 1. Hotspots (Top 10)\n\nFiles changed most frequently - likely complex or frequently enhanced:\n\n| Rank | File | Changes | LOC | Complexity Score |\n|------|------|---------|-----|------------------|\n| 1 | src/core/processor.ts | 45 | 892 | 40,140 |\n| 2 | src/api/handlers.ts | 38 | 456 | 17,328 |\n| 3 | config/settings.json | 32 | 123 | 3,936 |\n| 4 | src/models/user.ts | 28 | 345 | 9,660 |\n| 5 | src/utils/helpers.ts | 25 | 234 | 5,850 |\n| 6 | src/middleware/auth.ts | 23 | 189 | 4,347 |\n| 7 | tests/integration.spec.ts | 21 | 567 | 11,907 |\n| 8 | src/routes/index.ts | 19 | 156 | 2,964 |\n| 9 | src/services/payment.ts | 18 | 423 | 7,614 |\n| 10 | package.json | 17 | 78 | 1,326 |\n\n**Insights**:\n- **Hotspot #1**: `processor.ts` has been modified in 45 commits\n  - Complexity score of 40,140 indicates significant technical debt\n  - Consider refactoring into smaller modules (Strategy pattern)\n  - Review recent changes for code duplication\n\n- **Hotspot #2**: `handlers.ts` frequently updated (38 commits)\n  - API endpoint additions/modifications\n  - Ensure adequate test coverage for new endpoints\n\n- **Configuration hotspot**: `settings.json` (32 commits)\n  - Normal for configuration files\n  - Consider environment-specific configs to reduce churn\n\n- **Test file in hotspots**: `integration.spec.ts` (21 commits)\n  - Good sign - tests updated with production code\n  - Complexity score indicates comprehensive test suite\n```\n\n---\n\n## Section 2: Temporal Coupling (Significant Pairs)\n\nFiles that frequently change together - may indicate hidden dependencies.\n\n```markdown\n## 2. Temporal Coupling (Significant Pairs)\n\nFiles that frequently change together - may indicate hidden dependencies:\n\n| File A | File B | Coupling | Co-changes |\n|--------|--------|----------|------------|\n| src/user/model.ts | src/user/service.ts | 0.85 | 23 |\n| src/api/auth.ts | src/middleware/jwt.ts | 0.72 | 18 |\n| src/routes/user.ts | src/controllers/user.ts | 0.68 | 15 |\n| src/core/processor.ts | src/core/validator.ts | 0.63 | 12 |\n| src/models/order.ts | src/services/payment.ts | 0.58 | 10 |\n| config/database.json | src/db/connection.ts | 0.55 | 9 |\n\n**Insights**:\n\n### Expected Coupling ‚úÖ\n- **user/model.ts ‚Üî user/service.ts** (0.85, 23 co-changes)\n  - Same domain, expected coupling\n  - Model changes naturally require service updates\n\n- **auth.ts ‚Üî jwt.ts** (0.72, 18 co-changes)\n  - Authentication flow dependencies\n  - Normal for security-related code\n\n- **routes ‚Üî controllers** (0.68, 15 co-changes)\n  - MVC pattern, expected behavior\n\n### Suspicious Coupling ‚ö†Ô∏è\n- **order.ts ‚Üî payment.ts** (0.58, 10 co-changes)\n  - Cross-module coupling (orders ‚Üí payments)\n  - **Review**: Consider event-driven decoupling\n  - May indicate missing abstraction layer\n\n### Recommendations\n1. **High coupling (>0.8)**: Consider merging files if always changed together\n2. **Cross-module coupling**: Review for architectural improvements\n3. **Config ‚Üî Code coupling**: Normal, ensure version control best practices\n```\n\n---\n\n## Section 3: Recent Contributors (Knowledge Map)\n\nWho has recent knowledge of each area.\n\n```markdown\n## 3. Recent Contributors (Knowledge Map)\n\nWho has recent knowledge of each area:\n\n### src/api/\n| Contributor | Recent Commits | Last Active |\n|-------------|----------------|-------------|\n| Alice | 12 | 2025-11-28 |\n| Bob | 8 | 2025-11-25 |\n| Charlie | 3 | 2025-11-15 |\n\n**Coverage**: 3 contributors, good knowledge distribution\n\n---\n\n### src/core/\n| Contributor | Recent Commits | Last Active |\n|-------------|----------------|-------------|\n| Charlie | 15 | 2025-11-29 |\n| Alice | 3 | 2025-11-20 |\n\n**Coverage**: 2 contributors, Charlie is primary maintainer\n\n---\n\n### src/legacy/\n| Contributor | Recent Commits | Last Active |\n|-------------|----------------|-------------|\n| David | 2 | 2025-05-10 |\n\n**‚ö†Ô∏è Bus Factor Risk**: Only 1 contributor in last 6 months, no recent activity\n\n---\n\n### src/payments/\n| Contributor | Recent Commits | Last Active |\n|-------------|----------------|-------------|\n| Eve | 5 | 2025-08-15 |\n\n**‚ö†Ô∏è Knowledge Gap**: Primary contributor last active 3 months ago\n\n---\n\n### Bus Factor Risks\n\n| Area | Risk Level | Contributors | Last Activity | Recommendation |\n|------|------------|--------------|---------------|----------------|\n| src/legacy/* | üî¥ HIGH | 1 | 6 months ago | Document immediately, pair programming |\n| src/payments/ | üü° MEDIUM | 1 | 3 months ago | Knowledge transfer, cross-training |\n| src/core/ | üü¢ LOW | 2 | Recent | Maintain current distribution |\n```\n\n---\n\n## Section 4: Risk Summary\n\nAggregate risk assessment across all dimensions.\n\n```markdown\n## 4. Risk Summary\n\n| Risk Type | Count | Top Files | Severity |\n|-----------|-------|-----------|----------|\n| Bus Factor | 3 | legacy/*, payments/gateway.ts, utils/deprecated.ts | üî¥ HIGH |\n| High Complexity | 2 | core/processor.ts, api/handlers.ts | üü° MEDIUM |\n| Suspicious Coupling | 1 | orders/model.ts ‚Üî payments/service.ts | üü° MEDIUM |\n| Testing Gap | 1 | core/processor.ts (no corresponding test changes) | üü° MEDIUM |\n\n---\n\n### Priority Actions\n\n1. **URGENT - Document Legacy Code** üî¥\n   - `src/legacy/*` - Single contributor, 6 months inactive\n   - Action: Schedule knowledge transfer session this week\n   - Pair junior dev with Charlie to review legacy patterns\n\n2. **HIGH - Add Tests for Hotspots** üü°\n   - `core/processor.ts` - 45 changes but no test file activity\n   - Action: Add unit tests, aim for 80% coverage\n   - Review recent changes for edge cases\n\n3. **MEDIUM - Review Cross-Module Coupling** üü°\n   - `orders/model.ts ‚Üî payments/service.ts` coupling (0.58)\n   - Action: Investigate if event-driven architecture is appropriate\n   - Consider introducing domain events for decoupling\n\n4. **MEDIUM - Knowledge Transfer for Payments** üü°\n   - Primary contributor Eve last active 3 months ago\n   - Action: Cross-train another developer on payment flows\n   - Document critical payment integration logic\n\n---\n\n### Risk Metrics\n\n| Metric | Value | Threshold | Status |\n|--------|-------|-----------|--------|\n| Files with single contributor | 8 | <5 | ‚ö†Ô∏è Above threshold |\n| Average contributors per module | 2.3 | >2 | ‚úÖ Acceptable |\n| Hotspots without tests | 1 | 0 | ‚ö†Ô∏è Needs attention |\n| Suspicious couplings | 1 | <2 | ‚úÖ Acceptable |\n```\n\n---\n\n## Section 5: Recommendations\n\nActionable recommendations based on temporal patterns.\n\n```markdown\n## 5. Recommendations\n\nBased on temporal analysis:\n\n### 1. Refactoring Candidates\n\n**processor.ts** (Hotspot #1)\n- **Problem**: 45 changes in 12 months, complexity score 40,140\n- **Indicator**: High change frequency suggests unstable design\n- **Recommendation**:\n  - Extract into Strategy or Plugin pattern\n  - Separate concerns: validation, transformation, persistence\n  - Target: Reduce file LOC from 892 ‚Üí <500 per module\n\n**handlers.ts** (Hotspot #2)\n- **Problem**: 38 changes, grows with each new API endpoint\n- **Recommendation**:\n  - Consider breaking into feature-specific handler modules\n  - Use route grouping by domain (users/, orders/, payments/)\n\n---\n\n### 2. Knowledge Sharing\n\n**Schedule Knowledge Transfer Sessions**:\n- `src/legacy/*` - Pair David (if available) with 2 developers\n- `src/payments/` - Document Eve's integration patterns\n- `src/core/` - Charlie to share processor.ts refactoring plan\n\n**Cross-Training Matrix**:\n| Module | Primary | Backup | Learning |\n|--------|---------|--------|----------|\n| api/ | Alice | Bob | Charlie |\n| core/ | Charlie | Alice | Bob |\n| payments/ | Eve | (needed) | (assign) |\n| legacy/ | David | (needed) | (assign) |\n\n---\n\n### 3. Architecture Review\n\n**Investigate Cross-Module Coupling**:\n- **orders ‚Üî payments** (0.58 coupling)\n  - Current: Direct service calls\n  - Consider: Event-driven architecture\n  - Benefit: Reduce coupling, improve scalability\n  - Trade-off: Increased complexity, eventual consistency\n\n**Review Testing Strategy**:\n- Hotspots should have proportional test activity\n- `processor.ts`: 45 production changes, 0 test file changes\n- Action: Implement test coverage before next refactor\n\n---\n\n### 4. Process Improvements\n\n**Commit Practices**:\n- Large, infrequent commits may hide coupling patterns\n- Consider: Smaller, atomic commits with clear messages\n- Benefit: Better coupling detection, easier rollback\n\n**Code Review Focus**:\n- Flag changes to identified hotspots (processor.ts, handlers.ts)\n- Extra scrutiny for cross-module coupling\n- Require tests for hotspot modifications\n```\n\n---\n\n## Section 6: Recommended Next\n\nDynamic suggestions based on findings.\n\n```markdown\n## Recommended Next\n\nBased on analysis findings, dynamically suggest 1-2 most relevant follow-up commands:\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:impact \"src/core/processor.ts\"` | processor.ts changed 45 times, need to understand dependencies |\n| 2 | `/sourceatlas:pattern \"strategy pattern\"` | Hotspot involves complex processing, need to understand implementation conventions |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n```\n\n**Rules**:\n- Only show if there are clear findings (hotspots, coupling, risks)\n- Use actual discovered file names, not placeholders\n- Limit to 1-2 most actionable recommendations\n- Reference specific metrics in Purpose (change count, coupling degree)\n\n---\n\n## Footer Format\n\n```markdown\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.13.0 ‚îÇ Constitution v1.1\n\nüíæ Saved to .sourceatlas/history.md\n```\n\n---\n\n## Example: Complete Output\n\n```markdown\nüó∫Ô∏è SourceAtlas: History\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìú sourceatlas2 ‚îÇ 12 months\n\n**Analysis Period**: 2024-11-30 ‚Üí 2025-11-30\n**Commits Analyzed**: 487\n**Files Analyzed**: 234\n\n---\n\n## 1. Hotspots (Top 10)\n\n[... full hotspots table ...]\n\n**Insights**:\n[... specific insights ...]\n\n---\n\n## 2. Temporal Coupling (Significant Pairs)\n\n[... full coupling table ...]\n\n**Insights**:\n[... expected vs suspicious ...]\n\n---\n\n## 3. Recent Contributors (Knowledge Map)\n\n[... knowledge map by area ...]\n\n**Bus Factor Risks**:\n[... specific risks ...]\n\n---\n\n## 4. Risk Summary\n\n[... risk aggregation ...]\n\n**Priority Actions**:\n[... numbered action items ...]\n\n---\n\n## 5. Recommendations\n\n[... detailed recommendations ...]\n\n---\n\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:impact \"src/core/processor.ts\"` | processor.ts changed 45 times, need to understand dependencies |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.13.0 ‚îÇ Constitution v1.1\n\n‚úÖ Verified: 10 hotspot files, 5 contributors, commit counts\n\nüíæ Saved to .sourceatlas/history.md\n```\n\n---\n\n## Field Descriptions\n\n### Hotspots Table\n\n- **Rank**: 1-10, sorted by revision count descending\n- **File**: Relative path from repository root\n- **Changes**: Number of commits touching this file\n- **LOC**: Current lines of code (use `wc -l`)\n- **Complexity Score**: LOC √ó Changes (higher = more risk)\n\n### Coupling Table\n\n- **File A, File B**: The coupled file pair\n- **Coupling**: Degree 0.0-1.0 (percentage they change together)\n- **Co-changes**: Number of commits where both files changed\n\n### Contributors Table\n\n- **Contributor**: Git author name (use `git shortlog`)\n- **Recent Commits**: Commits in analysis period\n- **Last Active**: Date of most recent commit (YYYY-MM-DD)\n\n### Risk Summary\n\n- **Risk Type**: Bus Factor / High Complexity / Suspicious Coupling / Testing Gap\n- **Count**: Number of instances\n- **Top Files**: Most critical examples\n- **Severity**: üî¥ HIGH / üü° MEDIUM / üü¢ LOW\n",
        "plugin/commands/history/reference.md": "# History Analysis Reference\n\nAdvanced features, caching behavior, and best practices.\n\n---\n\n## Cache Behavior\n\n### When Cache is Used\n\n```bash\n# Default: Use cache if exists and fresh\n/sourceatlas:history\n\n# Check logic:\nif [ -f \".sourceatlas/history.md\" ]; then\n  age_days=$(calculate_age_in_days)\n  if [ $age_days -eq 0 ]; then\n    echo \"üìÅ Loading from cache (today)\"\n  elif [ $age_days -eq 1 ]; then\n    echo \"üìÅ Loading from cache (1 day ago)\"\n  else\n    echo \"üìÅ Loading from cache ($age_days days ago)\"\n  fi\n  # If >30 days, warn user\n  if [ $age_days -gt 30 ]; then\n    echo \"‚ö†Ô∏è Cache is older than 30 days, recommend re-analysis\"\n  fi\n  # Output cached content\n  exit 0\nfi\n```\n\n### When Cache is Skipped\n\n```bash\n# Force flag: Always skip cache\n/sourceatlas:history --force\n# ‚Üí Executes full analysis even if cache exists\n\n# No cache: First time analysis\n# ‚Üí .sourceatlas/history.md doesn't exist yet\n```\n\n### Cache File Naming\n\nUnlike other commands, history has **fixed cache path**:\n```bash\n# Always the same\n.sourceatlas/history.md\n```\n\n**Rationale:** History analysis is repository-wide, doesn't vary by target.\n\n---\n\n## Auto-Save Behavior\n\n### File Structure\n\n```\n.sourceatlas/\n‚îî‚îÄ‚îÄ history.md              # Fixed filename\n```\n\n### Save Timing\n\nAuto-save occurs **immediately after Step V4 verification**:\n\n```yaml\n# After verification passes\nverification_summary:\n  confidence_level: \"high\"\n\n# Then auto-save\nüíæ Saved to .sourceatlas/history.md\n```\n\n### What Gets Saved\n\nComplete Markdown output including:\n- Header with analysis period and counts\n- Hotspots table (top 10)\n- Temporal coupling table\n- Recent contributors knowledge map\n- Risk summary\n- Recommendations\n- Verification summary\n\n**Format:** Full Markdown as specified in [output-template.md](output-template.md)\n\n---\n\n## Handoffs: When to Suggest Next Commands\n\n### After Hotspot Identification\n\nIf high-risk hotspots found (complexity >10,000):\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:impact \"src/core/processor.ts\"` | processor.ts changed 45 times, need to understand dependencies |\n```\n\n### After Suspicious Coupling Found\n\nIf cross-module coupling detected (degree >0.6):\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:flow \"src/orders/checkout\"` | Suspicious coupling with payments, trace execution flow |\n```\n\n### After Bus Factor Risk Found\n\nIf single-contributor modules identified:\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"legacy patterns\"` | Bus factor risk in legacy/, need to understand patterns before knowledge transfer |\n```\n\n### When to Stop (No Recommendations)\n\n- **History too short**: <50 commits or <3 months\n- **No significant patterns**: All coupling <0.5, all hotspots <10 revisions\n- **Analysis depth sufficient**: User already ran 4+ commands\n\n**Output instead:**\n```\n‚ö†Ô∏è **Insufficient Data Warning**\n- Commits: 38 (recommend ‚â•50)\n- Period: 67 days (recommend ‚â•90 days)\n\nRecommend analyzing temporal patterns again in 3-6 months\n```\n\n---\n\n## code-maat Installation\n\n### Default Installation Location\n\n```bash\n$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\n```\n\n### Environment Variable\n\n```bash\nexport CODEMAAT_JAR=\"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\"\n```\n\n### Installation Script\n\n```bash\n./scripts/install-codemaat.sh\n```\n\n**What it does:**\n1. Creates `~/.sourceatlas/bin/`\n2. Downloads code-maat JAR from GitHub releases\n3. Sets executable permissions\n4. Verifies installation\n\n### Manual Installation\n\nIf automatic installation fails:\n\n```bash\n# 1. Download from GitHub\nwget https://github.com/adamtornhill/code-maat/releases/download/v1.0.4/code-maat-1.0.4-standalone.jar\n\n# 2. Create directory\nmkdir -p ~/.sourceatlas/bin/\n\n# 3. Move JAR\nmv code-maat-1.0.4-standalone.jar ~/.sourceatlas/bin/\n\n# 4. Set environment variable\nexport CODEMAAT_JAR=\"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\"\n```\n\n### Prerequisites\n\n**Java 8+** required:\n\n```bash\n# Check Java version\njava -version\n\n# Install if missing (macOS)\nbrew install openjdk@11\n\n# Install if missing (Ubuntu)\nsudo apt-get install openjdk-11-jdk\n```\n\n---\n\n## Analysis Parameters\n\n### Time Range\n\n**Default: Last 12 months**\n\n```bash\ngit log --after=\"$(date -v-12m +%Y-%m-%d)\" ...\n```\n\n**Custom time range:**\n\n```bash\n# Last 6 months\n/sourceatlas:history \"last 6 months\"\n\n# Last 18 months\n/sourceatlas:history \"last 18 months\"\n```\n\n**Parsing logic:**\n```bash\n# Extract number from arguments\nMONTHS=$(echo \"$ARGUMENTS\" | grep -o '[0-9]\\+')\nif [ -z \"$MONTHS\" ]; then\n  MONTHS=12  # Default\nfi\n```\n\n### Scope Filtering\n\n**Default: Entire repository**\n\n**Custom scope:**\n\n```bash\n# Specific directory\n/sourceatlas:history \"src/\"\n\n# Multiple directories (future enhancement)\n/sourceatlas:history \"src/ lib/\"\n```\n\n**Implementation:**\n```bash\nif [ -n \"$SCOPE\" ]; then\n  git log --all --numstat ... -- \"$SCOPE\" > /tmp/git-history.log\nelse\n  git log --all --numstat ... > /tmp/git-history.log\nfi\n```\n\n---\n\n## Interpretation Guidelines\n\n### Hotspots\n\n**Not always bad:**\n- Core logic files naturally change often\n- Configuration files updated for environments\n- Test files should mirror production changes\n\n**Red flags:**\n- High complexity score (>10,000)\n- Hotspot without corresponding test changes\n- Frequent changes without documentation updates\n\n### Temporal Coupling\n\n**Expected (normal):**\n- Model ‚Üî Service (same domain)\n- Route ‚Üî Controller (MVC pattern)\n- Component ‚Üî Component styles\n- Test ‚Üî Production code\n\n**Suspicious (review needed):**\n- Cross-layer: API ‚Üî Database\n- Cross-module: User ‚Üî Payment\n- Backend ‚Üî Frontend (if separated)\n\n### Contributors\n\n**Healthy distribution:**\n- 2-3 active contributors per module\n- Regular activity (monthly commits)\n- Knowledge overlap between contributors\n\n**Bus factor risks:**\n- Single contributor (especially if inactive >6 months)\n- Primary contributor left team\n- No knowledge overlap in critical modules\n\n---\n\n## Performance Optimization\n\n### For Large Repositories (>10K commits)\n\n```bash\n# Limit analysis to recent history\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-6m +%Y-%m-%d)\" \\\n    --max-count=1000 \\\n    > /tmp/git-history.log\n```\n\n### For Monorepos\n\n```bash\n# Analyze specific package only\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    -- \"packages/app/\" \\\n    > /tmp/git-history.log\n\n# Or analyze multiple related packages\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    -- \"packages/app/\" \"packages/shared/\" \\\n    > /tmp/git-history.log\n```\n\n### For Slow code-maat Execution\n\n```bash\n# Use faster analysis types\n# revisions: Fast (seconds)\n# coupling: Moderate (seconds to minutes)\n# entity-ownership: Slow (minutes)\n\n# Skip entity-ownership if too slow\n# Focus on revisions + coupling\n```\n\n---\n\n## Edge Cases\n\n### Case 1: No Git History\n\n```bash\n# Check if git repository\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n    echo \"‚ùå Not a git repository\"\n    echo \"History analysis requires git version control\"\n    exit 1\nfi\n```\n\n---\n\n### Case 2: Very Short History (<50 commits)\n\n```yaml\noutput:\n  message: |\n    ‚ö†Ô∏è Only 38 commits found in analysis period\n\n    Temporal analysis works best with >50 commits.\n\n    Consider:\n    - Extending time range (e.g., --after=\"2 years ago\")\n    - Analyzing entire repository history (omit --after)\n    - Waiting for more development activity\n```\n\n---\n\n### Case 3: Monolithic Commits\n\nIf commits are very large (>100 files per commit):\n\n```yaml\nwarning: |\n  Large, infrequent commits detected.\n\n  This may affect coupling analysis accuracy:\n  - Many files change together in single commit\n  - Hard to distinguish real vs coincidental coupling\n\n  Recommend:\n  - Smaller, atomic commits going forward\n  - Focus on hotspot analysis (more reliable)\n```\n\n---\n\n### Case 4: Multiple Contributors with Same Name\n\n```bash\n# If \"Alice\" appears as:\n# - Alice Smith <alice@company.com>\n# - Alice Johnson <alice@contractor.com>\n\n# code-maat uses author name only, may merge stats\n# Verify in git log:\ngit log --format='%aN <%aE>' | sort -u | grep -i alice\n```\n\n**Action:** If ambiguous, note in output:\n```\nNote: Multiple contributors with name \"Alice\" found.\nStats may be aggregated.\n```\n\n---\n\n## Constitutional Compliance\n\n### Article I: Evidence-Based Analysis\n- ‚úÖ Every hotspot must have actual revision count\n- ‚úÖ Coupling degrees from code-maat output\n- ‚úÖ Contributor names from git log\n\n### Article II: Directory Exclusions\n- ‚úÖ Git log naturally excludes untracked files\n- ‚úÖ code-maat processes committed files only\n\n### Article III: Verification Required\n- ‚úÖ Execute [verification-guide.md](verification-guide.md) before output\n- ‚úÖ Re-verify after corrections\n\n### Article IV: Evidence Format\n- ‚úÖ Use `file:line` for hotspots\n- ‚úÖ Reference commit hashes where relevant\n- ‚úÖ Include coupling degrees in output\n\n### Article V: Transparency\n- ‚úÖ Show cache age: \"Loading from cache (2 days ago)\"\n- ‚úÖ Show analysis period explicitly\n- ‚úÖ Note if history insufficient\n\n### Article VI: Scale Awareness\n- ‚úÖ Limit analysis to 12 months by default\n- ‚úÖ Cap hotspot list to top 10\n- ‚úÖ Filter coupling to degree ‚â•0.5\n\n### Article VII: User Empowerment\n- ‚úÖ Provide actionable recommendations\n- ‚úÖ Suggest next commands based on findings\n- ‚úÖ Include priority actions in risk summary\n\n---\n\n## Related Commands\n\nAfter history analysis, consider:\n\n- **`/sourceatlas:impact \"[hotspot]\"`** - Understand dependencies of frequently changed files\n- **`/sourceatlas:pattern \"[pattern]\"`** - Learn patterns used in hotspots before refactoring\n- **`/sourceatlas:flow \"[entry point]\"`** - Trace execution through coupled modules\n- **`/sourceatlas:overview`** - Get broader context if history reveals complexity\n\n---\n\n## Troubleshooting\n\n### Issue: code-maat Not Found\n\n**Symptom:** `CODEMAAT_JAR not set` or `file not found`\n\n**Debug:**\n```bash\n# Check environment\necho $CODEMAAT_JAR\n\n# Check default location\nls -la ~/.sourceatlas/bin/code-maat-*.jar\n\n# Verify Java\njava -version\n```\n\n**Fix:** Run installation script or set environment variable\n\n---\n\n### Issue: Empty Git Log\n\n**Symptom:** `0 commits found`\n\n**Debug:**\n```bash\n# Check git repository\ngit log --oneline | head -5\n\n# Check date filter\ndate -v-12m +%Y-%m-%d  # macOS\ndate -d '12 months ago' +%Y-%m-%d  # Linux\n```\n\n**Fix:** Adjust date range or check if repository has history\n\n---\n\n### Issue: code-maat Fails\n\n**Symptom:** `Exception in thread \"main\"` or Java errors\n\n**Debug:**\n```bash\n# Test code-maat directly\njava -jar \"$CODEMAAT_JAR\" -h\n\n# Check git log format\nhead -20 /tmp/git-history.log\n```\n\n**Fix:**\n- Verify Java version (need 8+)\n- Regenerate git log with correct format\n- Re-download code-maat JAR if corrupted\n\n---\n\n### Issue: No Significant Patterns\n\n**Symptom:** All couplings <0.3, all hotspots <5 revisions\n\n**Possible causes:**\n1. Very stable codebase (good!)\n2. Short history period\n3. Large, infrequent commits hiding patterns\n\n**Action:**\n```\n‚úÖ No significant temporal patterns detected.\n\nThis could mean:\n- Clean architecture with good separation\n- Young codebase with limited history\n- Stable, mature codebase\n\nConsider re-analyzing after more development activity.\n```\n\n---\n\n## Best Practices\n\n1. **Run quarterly** - Temporal patterns evolve over time\n2. **Compare with previous runs** - Track if hotspots are growing\n3. **Act on bus factor risks** - Document before knowledge is lost\n4. **Review coupling trends** - Monitor if architecture is degrading\n5. **Cross-reference with static analysis** - Combine history + impact for complete picture\n",
        "plugin/commands/history/verification-guide.md": "# History Analysis Self-Verification Guide\n\nComplete verification checklist to ensure temporal analysis accuracy.\n\n---\n\n## When to Verify\n\nExecute after completing your history analysis, before outputting final results.\n\n---\n\n## Verification Steps\n\n### Step V1: Extract Verifiable Claims\n\nParse your analysis output to identify all **quantifiable claims**:\n\n```yaml\nverifiable_claims:\n  - \"500 commits analyzed\"\n  - \"src/core/processor.ts changed 45 times\"\n  - \"Alice made 12 commits to src/api/\"\n  - \"Coupling degree 0.85\"\n  - \"Analysis period: 2024-11-30 ‚Üí 2025-11-30\"\n```\n\n**Extract these for verification:**\n- File paths (hotspots, coupled files)\n- Commit counts (total, per file, per contributor)\n- Contributor names\n- Date ranges\n- Coupling pairs (both files must exist)\n- LOC counts\n\n---\n\n### Step V2: Parallel Verification Execution\n\nRun verification commands in **parallel** for speed:\n\n#### V2.1: Verify Hotspot Files Exist\n\n```bash\n# Check top 10 hotspot files\nfor path in \"src/core/processor.ts\" \"src/api/handlers.ts\" \"config/settings.json\"; do\n    if [ ! -f \"$path\" ]; then\n        echo \"‚ùå FILE_NOT_FOUND: $path\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All sampled hotspot file paths exist\n- ‚ö†Ô∏è If file not found ‚Üí Remove from hotspots or find correct path\n\n#### V2.2: Verify Commit Counts\n\n```bash\n# Verify total commit count\nclaimed_total=500\nactual_total=$(git rev-list --count HEAD 2>/dev/null)\n\n# Allow ¬±20% tolerance (git log filters may vary)\nmin_expected=$((actual_total * 80 / 100))\nmax_expected=$((actual_total * 120 / 100))\n\nif [ $claimed_total -lt $min_expected ] || [ $claimed_total -gt $max_expected ]; then\n    echo \"‚ö†Ô∏è COMMIT_COUNT_CHECK: claimed $claimed_total, actual ~$actual_total\"\nfi\n\n# Verify specific file change count\nclaimed_revisions=45\nactual_revisions=$(git log --oneline -- \"src/core/processor.ts\" | wc -l)\n\nif [ $((actual_revisions * 80 / 100)) -gt $claimed_revisions ] || [ $((actual_revisions * 120 / 100)) -lt $claimed_revisions ]; then\n    echo \"‚ö†Ô∏è FILE_REVISION_MISMATCH: claimed $claimed_revisions, actual $actual_revisions\"\nfi\n```\n\n**Check:**\n- ‚úÖ Total commit count within ¬±20% (accounts for filtering differences)\n- ‚úÖ Per-file revision counts within ¬±20%\n- ‚ö†Ô∏è If significant difference ‚Üí Re-run code-maat analysis\n\n#### V2.3: Verify Contributors\n\n```bash\n# Verify top contributor exists\nclaimed_contributor=\"Alice\"\nif ! git shortlog -sn --all 2>/dev/null | grep -qi \"$claimed_contributor\"; then\n    echo \"‚ùå CONTRIBUTOR_NOT_FOUND: $claimed_contributor\"\nfi\n\n# Verify contributor commit count\nclaimed_commits=12\nactual_commits=$(git log --author=\"$claimed_contributor\" --oneline | wc -l)\n\nif [ $((actual_commits / 2)) -gt $claimed_commits ] || [ $((actual_commits * 2)) -lt $claimed_commits ]; then\n    echo \"‚ö†Ô∏è CONTRIBUTOR_COUNT_MISMATCH: claimed $claimed_commits, actual $actual_commits\"\nfi\n```\n\n**Check:**\n- ‚úÖ All mentioned contributors exist in git history\n- ‚úÖ Commit counts per contributor are reasonable\n- ‚ö†Ô∏è If contributor not found ‚Üí Check spelling or remove\n\n#### V2.4: Verify Coupling Pairs\n\n```bash\n# Verify both files in coupling pair exist\nfor pair in \"src/user/model.ts:src/user/service.ts\" \"src/api/auth.ts:src/middleware/jwt.ts\"; do\n    IFS=':' read -r f1 f2 <<< \"$pair\"\n    if [ ! -f \"$f1\" ]; then\n        echo \"‚ùå COUPLING_FILE1_NOT_FOUND: $f1\"\n    fi\n    if [ ! -f \"$f2\" ]; then\n        echo \"‚ùå COUPLING_FILE2_NOT_FOUND: $f2\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ Both files in each coupling pair exist\n- ‚ö†Ô∏è If either file not found ‚Üí Remove coupling pair\n\n#### V2.5: Verify Date Range\n\n```bash\n# Verify analysis period matches actual git history\nclaimed_start=\"2024-11-30\"\nclaimed_end=\"2025-11-30\"\n\nactual_start=$(git log --reverse --format=\"%ai\" | head -1 | cut -d' ' -f1)\nactual_end=$(git log --format=\"%ai\" | head -1 | cut -d' ' -f1)\n\necho \"Claimed: $claimed_start ‚Üí $claimed_end\"\necho \"Actual:  $actual_start ‚Üí $actual_end\"\n```\n\n**Check:**\n- ‚úÖ Start date is within repository history\n- ‚úÖ End date is recent (not in future)\n- ‚ö†Ô∏è If dates outside actual range ‚Üí Update analysis period\n\n---\n\n### Step V3: Handle Verification Results\n\nBased on verification outcomes:\n\n#### If All Checks Pass ‚úÖ\n\n```yaml\nverification_status:\n  verified: true\n  checks_passed: 5\n  confidence: high\n```\n\nProceed to output.\n\n#### If Minor Issues Found ‚ö†Ô∏è (1-2 checks failed)\n\n**Examples:**\n- File revision count off by <30%\n- Contributor commit count slightly different\n- Date range off by a few days\n\n**Action:**\n1. Correct the specific claims\n2. Re-verify those claims\n3. Add note to output:\n\n```yaml\nverification_notes:\n  - \"Commit counts adjusted after verification\"\n  - \"File revision count corrected to [N] (was [M])\"\n```\n\n#### If Major Issues Found ‚ùå (3+ checks failed)\n\n**Examples:**\n- Multiple hotspot files don't exist\n- Contributor names not in git history\n- Commit counts off by >50%\n- Coupling pairs with non-existent files\n\n**Action:**\n1. **STOP** - Do not output current analysis\n2. Re-execute Step 1-5 from [workflow.md](workflow.md)\n3. Check code-maat installation\n4. Verify git log generation\n5. Re-run all analyses\n\n---\n\n### Step V4: Verification Summary\n\nAdd to final output (before footer):\n\n```yaml\nverification_summary:\n  timestamp: \"[ISO 8601]\"\n  checks_performed:\n    - \"Hotspot files: ‚úÖ\"\n    - \"Commit counts: ‚úÖ\"\n    - \"Contributors: ‚úÖ\"\n    - \"Coupling pairs: ‚úÖ\"\n    - \"Date ranges: ‚úÖ\"\n\n  confidence_level: \"high\"  # high|medium|low\n  notes:\n    - \"[Any corrections made]\"\n```\n\n**Confidence Level Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **High** | All 5 checks passed, no corrections needed |\n| **Medium** | 4/5 checks passed, minor corrections made |\n| **Low** | <4 checks passed, significant corrections made |\n\n---\n\n## Verification Examples\n\n### Example 1: Hotspot File Verification\n\n**Claim:** \"processor.ts changed 45 times\"\n\n**Verification:**\n```bash\ngit log --oneline -- \"src/core/processor.ts\" | wc -l\n# Output: 43\n```\n\n**Result:** ‚ö†Ô∏è Minor difference (45 ‚Üí 43)\n\n**Action:**\n- Update analysis: `processor.ts changed 43 times`\n- Note: \"Revision count verified and adjusted\"\n\n---\n\n### Example 2: Contributor Verification\n\n**Claim:** \"Alice made 12 commits to src/api/\"\n\n**Verification:**\n```bash\ngit log --author=\"Alice\" --oneline -- \"src/api/\" | wc -l\n# Output: 11\n```\n\n**Result:** ‚ö†Ô∏è Minor difference (12 ‚Üí 11)\n\n**Action:**\n- Update analysis: \"Alice made 11 commits\"\n- Acceptable within ¬±1 commit tolerance\n\n---\n\n### Example 3: Coupling Pair Verification\n\n**Claim:** \"model.ts ‚Üî service.ts coupling 0.85\"\n\n**Verification:**\n```bash\ntest -f \"src/user/model.ts\" && echo \"‚úÖ File 1 exists\"\ntest -f \"src/user/service.ts\" && echo \"‚úÖ File 2 exists\"\n```\n\n**Result:** ‚úÖ Both files exist\n\n**Action:** No correction needed\n\n---\n\n### Example 4: Non-existent File\n\n**Claim:** \"legacy/old-auth.ts is a hotspot\"\n\n**Verification:**\n```bash\ntest -f \"legacy/old-auth.ts\"\n# Exit code: 1 (file not found)\n```\n\n**Result:** ‚ùå File doesn't exist\n\n**Action:**\n- Search for similar path: `find . -name \"*old-auth*\"`\n- If found at different path ‚Üí Update path\n- If deleted from codebase ‚Üí Remove from hotspots entirely\n- Note: \"File was deleted after analysis period\"\n\n---\n\n## Error Recovery\n\n### If Verification Script Fails\n\n```bash\n# If git command fails\n# ‚Üí Check if inside git repository\ngit status > /dev/null 2>&1 || echo \"Not a git repository\"\n\n# If file not found\n# ‚Üí Use find to locate\nfind . -name \"processor.ts\" 2>/dev/null\n\n# If contributor not found\n# ‚Üí List all contributors\ngit shortlog -sn | head -10\n```\n\n### If Commit Count Discrepancy Large (>30%)\n\n**Likely causes:**\n1. Git log time filter different from code-maat\n2. Branch filtering issues (--all vs single branch)\n3. Git history rewritten recently\n\n**Action:**\n1. Regenerate git log with explicit date range\n2. Verify code-maat ran successfully\n3. Check if repository had recent force push\n\n---\n\n## Best Practices\n\n1. **Always verify file paths** - Files may be renamed/deleted after analysis\n2. **Sample at least 3 hotspots** - Ensures code-maat output is accurate\n3. **Check contributor spelling** - Git author names may have variations\n4. **Verify coupling makes sense** - Both files should be in same repository\n5. **Note all corrections** - Transparency builds trust\n\n---\n\n## Verification Checklist\n\nBefore finalizing output, confirm:\n\n- [ ] All hotspot file paths verified to exist (sample 3-5)\n- [ ] Total commit count reasonable (within ¬±20% of git rev-list --count)\n- [ ] Top contributors verified against git shortlog\n- [ ] Coupling pairs verified (both files exist)\n- [ ] Date ranges within actual repository history\n- [ ] LOC counts match current file sizes (use wc -l)\n- [ ] No placeholder values like \"[N]\" or \"[file]\" in output\n\n---\n\n## Handoff to Next Steps\n\nAfter verification:\n- ‚úÖ If confidence HIGH ‚Üí Proceed to output\n- ‚ö†Ô∏è If confidence MEDIUM ‚Üí Include verification notes, warn user\n- ‚ùå If confidence LOW ‚Üí Re-execute entire analysis\n\nSee [reference.md#handoffs](reference.md#handoffs) for when to suggest next commands.\n",
        "plugin/commands/history/workflow.md": "# History Analysis Workflow\n\nComplete step-by-step guide for git temporal analysis using code-maat.\n\n---\n\n## Overview\n\nThis workflow uses code-maat to analyze git history and extract:\n1. **Hotspots** - Frequently changed files (complexity indicators)\n2. **Temporal Coupling** - Files that change together (hidden dependencies)\n3. **Recent Contributors** - Knowledge distribution (bus factor risks)\n\n**Time Budget**: 5-10 minutes total\n\n---\n\n## Step 0: Check Prerequisites (30 seconds)\n\n### Check code-maat Installation\n\n```bash\n# Check if CODEMAAT_JAR is set\nif [ -z \"$CODEMAAT_JAR\" ]; then\n    # Check default location\n    if [ -f \"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\" ]; then\n        export CODEMAAT_JAR=\"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\"\n        echo \"‚úÖ code-maat found at $CODEMAAT_JAR\"\n    else\n        echo \"‚ö†Ô∏è code-maat not found.\"\n    fi\nfi\n```\n\n### If code-maat Not Found\n\nUse **AskUserQuestion** tool:\n\n```yaml\nquestions:\n  - header: \"Install Tool\"\n    question: \"code-maat is required for git history analysis. Install now? (requires Java 8+)\"\n    multiSelect: false\n    options:\n      - label: \"Yes, install\"\n        description: \"Run installation script automatically\"\n      - label: \"No, skip\"\n        description: \"Show manual installation instructions\"\n```\n\n### If User Agrees to Install\n\n```bash\n# Run installation script\n./scripts/install-codemaat.sh\n\n# Verify installation\nif [ -f \"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\" ]; then\n    export CODEMAAT_JAR=\"$HOME/.sourceatlas/bin/code-maat-1.0.4-standalone.jar\"\n    echo \"‚úÖ code-maat installed successfully!\"\nelse\n    echo \"‚ùå Installation failed. Please check Java installation.\"\n    exit 1\nfi\n```\n\n### Verify code-maat Works\n\n```bash\njava -jar \"$CODEMAAT_JAR\" -h > /dev/null 2>&1\nif [ $? -ne 0 ]; then\n    echo \"‚ùå code-maat installation is broken. Please reinstall.\"\n    exit 1\nfi\n```\n\n### Check Java Installation\n\n```bash\njava -version 2>&1 | head -1\n```\n\n**If Java not found**, inform user:\n```\n‚ö†Ô∏è Java 8+ required for code-maat\nInstall: brew install openjdk@11\n```\n\n---\n\n## Step 1: Generate Git Log (1 minute)\n\n### Default: Last 12 Months\n\n```bash\n# Generate code-maat compatible git log\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-12m +%Y-%m-%d 2>/dev/null || date -d '12 months ago' +%Y-%m-%d)\" \\\n    > /tmp/git-history.log\n\n# Count commits and files\nCOMMIT_COUNT=$(grep -c \"^--\" /tmp/git-history.log)\nFILE_COUNT=$(awk 'NF==3 && $1 ~ /^[0-9]+$/' /tmp/git-history.log | cut -f3 | sort -u | wc -l)\n\necho \"üìä Analyzed: $COMMIT_COUNT commits, $FILE_COUNT unique files\"\n```\n\n### If Scope Specified\n\nIf user provides scope (e.g., \"src/\", \"frontend\"):\n\n```bash\n# Filter to specific directory\nSCOPE=\"src/\"\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-12m +%Y-%m-%d)\" \\\n    -- \"$SCOPE\" > /tmp/git-history.log\n```\n\n### Custom Time Range\n\nIf user specifies time range (e.g., \"last 6 months\"):\n\n```bash\n# Parse time range\nMONTHS=6\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-${MONTHS}m +%Y-%m-%d)\" \\\n    > /tmp/git-history.log\n```\n\n### Validate Log Size\n\n```bash\n# Check if history is sufficient\nif [ $COMMIT_COUNT -lt 50 ]; then\n    echo \"‚ö†Ô∏è Only $COMMIT_COUNT commits found\"\n    echo \"Temporal analysis works best with >50 commits\"\nfi\n```\n\n---\n\n## Step 2: Hotspot Analysis (2 minutes)\n\n### Run Revisions Analysis\n\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a revisions \\\n    2>/dev/null > /tmp/revisions.csv\n```\n\n**Output format:**\n```\nentity,n-revs\nsrc/core/processor.ts,45\nsrc/api/handlers.ts,38\n...\n```\n\n### Identify Top 10 Hotspots\n\n```bash\n# Sort by revision count descending\ncat /tmp/revisions.csv | tail -n +2 | sort -t, -k2 -nr | head -10 > /tmp/hotspots.csv\n```\n\n### Calculate Complexity Scores\n\nFor each hotspot, calculate: **LOC √ó Revisions**\n\n```bash\nwhile IFS=, read -r file revs; do\n    if [ -f \"$file\" ]; then\n        LOC=$(wc -l < \"$file\" 2>/dev/null || echo 0)\n        COMPLEXITY=$((LOC * revs))\n        echo \"$file,$revs,$LOC,$COMPLEXITY\"\n    fi\ndone < /tmp/hotspots.csv > /tmp/hotspots-with-loc.csv\n```\n\n### Interpret Hotspots\n\n**High complexity score (>10,000)**:\n- Indicates frequently changed, large files\n- Potential technical debt\n- Refactoring candidates\n\n**High revision count, low LOC**:\n- Configuration files (normal)\n- Small utility files (normal)\n\n**Low revision count, high LOC**:\n- Stable, mature code\n- May need modernization\n\n---\n\n## Step 3: Temporal Coupling Analysis (2 minutes)\n\n### Run Coupling Analysis\n\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a coupling \\\n    2>/dev/null > /tmp/coupling.csv\n```\n\n**Output format:**\n```\nentity,coupled,degree,average-revs\nsrc/user/model.ts,src/user/service.ts,0.85,23\nsrc/api/auth.ts,src/middleware/jwt.ts,0.72,18\n...\n```\n\n### Filter Significant Couplings\n\n```bash\n# Filter coupling degree >= 0.5\nawk -F, 'NR>1 && $3 >= 0.5' /tmp/coupling.csv | \\\n    sort -t, -k3 -nr | \\\n    head -20 > /tmp/significant-coupling.csv\n```\n\n### Categorize Couplings\n\n**Expected Couplings** (normal):\n- Model ‚Üî Service (same domain)\n- Test ‚Üî Production code\n- Component ‚Üî Component styles\n\n**Suspicious Couplings** (review needed):\n- Cross-layer: Controller ‚Üî View\n- Cross-module: User ‚Üî Payment\n- Backend ‚Üî Frontend\n\n### Interpret Coupling Degrees\n\n| Degree | Meaning | Action |\n|--------|---------|--------|\n| 0.9-1.0 | Always change together | Consider merging files |\n| 0.7-0.9 | Very strong coupling | Review dependency |\n| 0.5-0.7 | Moderate coupling | Monitor |\n| <0.5 | Weak coupling | Normal |\n\n---\n\n## Step 4: Recent Contributors Analysis (2 minutes)\n\n### Run Entity Ownership Analysis\n\n```bash\njava -jar \"$CODEMAAT_JAR\" -l /tmp/git-history.log -c git2 -a entity-ownership \\\n    2>/dev/null > /tmp/ownership.csv\n```\n\n**Output format:**\n```\nentity,author,added,deleted\nsrc/api/handlers.ts,Alice,234,45\nsrc/api/handlers.ts,Bob,89,12\n...\n```\n\n### Generate Knowledge Map by Area\n\n```bash\n# Most recent commits per area\nfor area in \"src/api/\" \"src/core/\" \"src/components/\"; do\n    echo \"=== $area ===\"\n    git log --pretty=format:'%an|%ad|%s' --date=short -- \"$area\" | head -5\ndone\n```\n\n### Identify Bus Factor Risks\n\n```bash\n# Files with single contributor in last 6 months\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-6m +%Y-%m-%d)\" \\\n    > /tmp/recent-6m.log\n\njava -jar \"$CODEMAAT_JAR\" -l /tmp/recent-6m.log -c git2 -a entity-ownership \\\n    2>/dev/null | awk -F, 'NR>1 {count[$1]++} END {for (f in count) if (count[f]==1) print f}'\n```\n\n**High bus factor risk**:\n- Only 1 contributor in last 6 months\n- Primary contributor no longer active\n- Critical files with concentrated knowledge\n\n---\n\n## Step 5: Risk Assessment (1 minute)\n\n### Calculate Composite Risk Scores\n\nCombine multiple dimensions:\n\n```bash\n# Risk = (Revisions √ó Coupling_Count) / Contributor_Count\n\n# Example: processor.ts\n# - 45 revisions\n# - Coupled with 3 other files\n# - 2 contributors\n# Risk = (45 √ó 3) / 2 = 67.5 (HIGH)\n```\n\n### Risk Categories\n\n**1. Bus Factor Risk**\n- Single contributor files\n- No recent activity (>6 months)\n- Critical path files\n\n**2. Complexity Risk**\n- High revision count (>30 in 12 months)\n- High LOC (>500 lines)\n- Complexity score >10,000\n\n**3. Coupling Risk**\n- Coupled with >5 files\n- Cross-module coupling (suspicious)\n- High coupling degree (>0.8)\n\n**4. Testing Gap Risk**\n- Hotspot without test file\n- Test file change frequency < 20% of production changes\n\n### Priority Ranking\n\n```\nüî¥ HIGH RISK:\n- Bus factor + Complexity + No tests\n\nüü° MEDIUM RISK:\n- Coupling risk + High revisions\n\nüü¢ LOW RISK:\n- High revisions but well-tested\n- Multiple contributors\n```\n\n---\n\n## Error Handling\n\n### Issue: Git History Too Short\n\n```bash\nif [ $COMMIT_COUNT -lt 50 ]; then\n    echo \"‚ö†Ô∏è Only $COMMIT_COUNT commits found\"\n    echo \"\"\n    echo \"Temporal analysis works best with >50 commits.\"\n    echo \"\"\n    echo \"Consider:\"\n    echo \"- Extending time range\"\n    echo \"- Analyzing entire repository history\"\n    exit 0\nfi\n```\n\n### Issue: No Significant Patterns\n\nIf all couplings < 0.5 and hotspots < 10 revisions:\n\n```\n‚úÖ No significant temporal patterns detected.\n\nThis could mean:\n- Clean architecture with good separation\n- Young codebase with limited history\n- Inconsistent commit practices (large commits)\n```\n\n### Issue: code-maat Fails\n\n```bash\nif ! java -jar \"$CODEMAAT_JAR\" -h > /dev/null 2>&1; then\n    echo \"‚ùå code-maat failed to run\"\n    echo \"\"\n    echo \"Possible causes:\"\n    echo \"1. Java not installed (brew install openjdk@11)\"\n    echo \"2. JAR file corrupted (re-run install script)\"\n    echo \"3. Incompatible Java version (need Java 8+)\"\n    exit 1\nfi\n```\n\n---\n\n## Output Generation Tips\n\n### Hotspot Table\n\n```markdown\n| Rank | File | Changes | LOC | Complexity Score |\n|------|------|---------|-----|------------------|\n| 1 | src/core/processor.ts | 45 | 892 | 40,140 |\n```\n\n**Insights**:\n- Reference specific complexity scores\n- Mention if file lacks tests\n- Suggest concrete actions (refactor, document, test)\n\n### Coupling Table\n\n```markdown\n| File A | File B | Coupling | Co-changes |\n|--------|--------|----------|------------|\n| src/user/model.ts | src/user/service.ts | 0.85 | 23 |\n```\n\n**Insights**:\n- Distinguish expected vs suspicious coupling\n- Reference architectural concerns\n- Note if cross-layer or cross-module\n\n### Knowledge Map\n\n```markdown\n### src/api/\n| Contributor | Recent Commits | Last Active |\n|-------------|----------------|-------------|\n| Alice | 12 | 2025-11-28 |\n```\n\n**Insights**:\n- Highlight bus factor risks\n- Note inactive contributors\n- Suggest knowledge transfer actions\n\n---\n\n## Performance Optimization\n\n### For Large Repositories\n\n```bash\n# Limit git log to avoid timeout\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    --after=\"$(date -v-6m +%Y-%m-%d)\" \\\n    --max-count=1000 \\\n    > /tmp/git-history.log\n```\n\n### For Monorepos\n\n```bash\n# Analyze specific module only\ngit log --all --numstat --date=short \\\n    --pretty=format:'--%h--%ad--%aN' \\\n    -- \"packages/app/\" \\\n    > /tmp/git-history.log\n```\n\n---\n\n## Integration with Other Commands\n\nAfter history analysis, suggest:\n- **High-risk hotspot found** ‚Üí `/sourceatlas:impact \"[hotspot]\"`\n- **Suspicious coupling** ‚Üí `/sourceatlas:flow \"[entry point]\"`\n- **Need refactoring guidance** ‚Üí `/sourceatlas:pattern \"[pattern]\"`\n",
        "plugin/commands/impact/SKILL.md": "---\nname: impact\ndescription: Analyze the impact scope of code changes using static dependency analysis\nmodel: sonnet\nallowed-tools: Bash, Glob, Grep, Read, Write\nargument-hint: [target, e.g., \"User model\", \"api /api/users/{id}\", \"authentication\"] [--force]\n---\n\n# SourceAtlas: Impact Analysis (Static Dependencies)\n\n> **Constitution**: This command operates under [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md) v1.0\n>\n> Key principles enforced:\n> - Article I: Structure over details (track dependencies, not implementation)\n> - Article II: Mandatory directory exclusion\n> - Article IV: Evidence format (file:line references)\n> - Article VI: Scale awareness (limit tracking depth for large projects)\n\n## Context\n\n**Analysis Target:** $ARGUMENTS\n\n**Goal:** Identify all code affected by changes to the target component through static dependency analysis.\n\n**Time Limit:** Complete in 5-10 minutes.\n\n---\n\n## Quick Start\n\n1. **Check cache** (if no `--force` flag) ‚Üí See [reference.md#cache-behavior](reference.md#cache-behavior)\n2. **Execute analysis** using [workflow.md](workflow.md)\n3. **Verify output** using [verification-guide.md](verification-guide.md)\n4. **Auto-save** to `.sourceatlas/impact/` ‚Üí See [reference.md#auto-save](reference.md#auto-save)\n\n---\n\n## Your Task\n\nYou are **SourceAtlas Impact Analyzer**, specialized in tracing static dependencies and identifying change impact.\n\nHelp the user understand:\n1. What code directly depends on the target\n2. What code indirectly depends on it (call chains)\n3. Which tests need updating\n4. Migration checklist and risk assessment\n\n---\n\n## Core Workflow\n\nFollow these high-level steps. For detailed instructions, see [workflow.md](workflow.md).\n\n### Step 1: Parse Target and Detect Type (1 minute)\n\nDetermine analysis type: **API**, **MODEL**, or **COMPONENT**\n\n‚Üí See [workflow.md#step-1](workflow.md#step-1-parse-target-and-detect-type-1-minute)\n\n### Step 2: Project Context Detection (1 minute)\n\nDetect project type and key directories to scan.\n\n‚Üí See [workflow.md#step-2](workflow.md#step-2-project-context-detection-1-minute)\n\n### Step 2.5: ast-grep Enhanced Search (Optional)\n\nUse ast-grep for precise dependency search with false positive elimination.\n\n‚Üí See [workflow.md#step-25](workflow.md#step-25-ast-grep-enhanced-search-optional-p1-enhancement)\n\n### Step 3: Execute Impact Analysis (3-5 minutes)\n\n**Type-specific analysis**:\n- **API**: Backend ‚Üí Type Definitions ‚Üí Frontend ‚Üí Hooks ‚Üí Components\n- **MODEL**: Model ‚Üí Dependencies ‚Üí Associations ‚Üí Business Logic\n- **COMPONENT**: Locate ‚Üí Imports ‚Üí Usage ‚Üí Categorization\n\n**CRITICAL**: Use exact counts (not estimates), mutually exclusive categories.\n\n‚Üí See [workflow.md#step-3](workflow.md#step-3-execute-impact-analysis-3-5-minutes)\n\n### Step 4: Test Impact Analysis (1-2 minutes)\n\nFind related tests and analyze coverage gaps.\n\n‚Üí See [workflow.md#step-4](workflow.md#step-4-test-impact-analysis-1-2-minutes)\n\n### Step 5: Language-Specific Deep Analysis (Optional)\n\nFor iOS/Swift projects: Run Swift/Objective-C interop analysis.\n\n‚Üí See [workflow.md#step-5](workflow.md#step-5-language-specific-deep-analysis-1-2-minutes-optional)\n\n### Step 6: Risk Assessment (1 minute)\n\nEvaluate impact level: üü¢ LOW / üü° MEDIUM / üî¥ HIGH\n\n**Risk Factors**:\n- Number of direct dependents (>10 = HIGH)\n- Presence in critical path (auth, payment = HIGH)\n- Test coverage (<50% = HIGH risk)\n- Type of change (breaking change = HIGH)\n\n‚Üí See [workflow.md#step-6](workflow.md#step-6-risk-assessment-1-minute)\n\n---\n\n## Output Format\n\nYour analysis should follow this structure:\n\n```\nüó∫Ô∏è SourceAtlas: Impact\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüí• $TARGET ‚îÇ [total dependents] dependents\n\nüìä Impact Summary\n1. Backend/Frontend/Model Layer\n2. Component Impact\n3. Field Usage Analysis (if applicable)\n4. Test Impact\n5. Migration Checklist\n6. Language-Specific Analysis (iOS only)\n7. Recommendations\n```\n\n‚Üí See [output-template.md](output-template.md) for complete template\n\n---\n\n## Critical Rules\n\n1. **Static Analysis Only**: Analyze code structure, not runtime behavior\n2. **Evidence-Based**: Every claim must reference file:line\n3. **Prioritize Impact**: Show high-priority dependencies first\n4. **Practical Output**: Focus on actionable migration steps\n5. **Risk Assessment**: Always provide risk level and reasoning\n6. **Test First**: Identify test gaps before changes\n7. **Time Limit**: Complete analysis in 5-10 minutes\n8. **Exact Counts**: Use actual grep results, not estimates\n9. **Verification Required**: Run [verification-guide.md](verification-guide.md) before output\n\n---\n\n## Error Handling\n\n**If target not found**:\n- Search with fuzzy matching\n- Suggest similar components\n- Ask user to clarify\n\n**If too many results** (>100):\n- Sample top 20-30 most relevant\n- Group by category (controllers, services, etc.)\n- Warn about incomplete analysis\n\n**If no dependencies found**:\n- Verify target exists\n- Check if it's a leaf component (no dependents)\n- Suggest dead code possibility\n\n‚Üí See [workflow.md#error-handling](workflow.md#error-handling) for details\n\n---\n\n## Self-Verification (REQUIRED)\n\nBefore outputting results, run verification checks:\n\n1. **Extract verifiable claims** (file paths, counts, imports)\n2. **Execute parallel verification** (bash script)\n3. **Handle failures** (fix or remove incorrect claims)\n4. **Append verification summary** to output\n\n‚Üí See [verification-guide.md](verification-guide.md) for complete checklist\n\n---\n\n## Advanced\n\n- **Cache behavior**: [reference.md#cache-behavior](reference.md#cache-behavior)\n- **Auto-save**: [reference.md#auto-save](reference.md#auto-save)\n- **Handoffs rules**: [reference.md#handoffs](reference.md#handoffs-recommended-next)\n- **Best practices**: [reference.md#best-practices](reference.md#best-practices)\n- **Large codebase tips**: [reference.md#tips-for-complex-projects](reference.md#tips-for-complex-projects)\n\n---\n\n## Support Files\n\n- **[workflow.md](workflow.md)** - Detailed step-by-step execution guide\n- **[output-template.md](output-template.md)** - Complete output format specification\n- **[verification-guide.md](verification-guide.md)** - Verification checklist and error handling\n- **[reference.md](reference.md)** - Cache, Auto-Save, Handoffs, best practices\n",
        "plugin/commands/impact/output-template.md": "# Impact Analysis Output Template\n\nComplete format specification for impact analysis reports.\n\n---\n\n## For API Impact\n\n```markdown\nüó∫Ô∏è SourceAtlas: Impact\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüí• $API_PATH ‚îÇ [total dependents] dependents\n\nüìä **Impact Summary**:\n- Backend files: [count]\n- Frontend files: [count]\n- Test files: [count]\n- **Risk Level**: üî¥/üü°/üü¢ [reason]\n\n---\n\n## 1. Backend Layer\n\n### API Definition\n- File: [path:line]\n- Handler: [function name]\n- Request/Response types: [types]\n\n### Response Structure\n```[language]\n// Current structure from types\ninterface UserResponse {\n  id: string\n  role: string  // ‚ö†Ô∏è If changing this\n  ...\n}\n```\n\n---\n\n## 2. Frontend Layer\n\n### API Client/Service\n- File: [path:line]\n- Wrapper function: [function name]\n\n### Custom Hooks (React)\n- `useUser` ([path:line])\n  - Used by [count] components\n  - Components: [list]\n\n### Direct API Calls\n- [component:line] - [usage description]\n\n---\n\n## 3. Component Impact\n\n**High Priority** (Directly affected):\n1. [Component A] ([path:line])\n   - Usage: [how it uses the API/field]\n   - Impact: [what breaks]\n\n2. [Component B] ([path:line])\n   - Usage: [description]\n\n**Medium Priority** (Indirectly affected):\n3. [Component C] - Uses Hook that wraps API\n\n---\n\n## 4. Field Usage Analysis\n\n**Field: `role`** (‚ö†Ô∏è Changing from string ‚Üí array)\n- Total occurrences: [count]\n- Locations:\n  1. [file:line] - `if (user.role === 'admin')`\n  2. [file:line] - `user.role.toUpperCase()`\n\n**Breaking Change Assessment**:\n- All usages assume string type\n- Migration required: Yes\n- Backward compatibility: Possible with adapter\n\n---\n\n## 5. Test Impact\n\n**Test Files to Update**:\n- `user.test.ts` - Mock data structure\n- `useUser.test.ts` - Hook logic\n- `UserBadge.test.tsx` - Component rendering\n- `e2e/user-profile.spec.ts` - E2E scenarios\n\n**Test Coverage Gaps**:\n- ‚ö†Ô∏è No tests for [Component X]\n- ‚ö†Ô∏è Missing integration tests for [Flow Y]\n\n---\n\n## 6. Migration Checklist\n\n- [ ] Update API response type definition\n- [ ] Update [N] API call sites\n- [ ] Update [N] components using the field\n- [ ] Add backward compatibility layer (if needed)\n- [ ] Update [N] test files\n- [ ] Test all affected pages manually\n- [ ] Update API documentation\n\n**Risk Level**: üî¥ HIGH | üü° MEDIUM | üü¢ LOW\n\nüí° **Note**: Time estimation depends on team velocity and complexity. Discuss with your team based on the checklist above.\n\n---\n\n## 7. Language-Specific Deep Analysis\n\n**‚ö†Ô∏è Swift/Objective-C Interop Risks** (iOS Projects Only)\n\n### Critical Issues üî¥\n\n**Nullability Coverage**: [X]% ([N] files missing NS_ASSUME_NONNULL)\n- **Impact**: Runtime crashes due to force unwrapping operator (!)\n- **Auto-fix**: Run provided sed script to add annotations\n- **Priority**: CRITICAL - Fix before making changes\n\n### Medium Risks üü°\n\n**@objc Exposure**: [N] classes + [M] @objcMembers\n- Classes exposing members to Objective-C\n- **Risk**: Renaming/removing will break ObjC callers\n- **Target file impact**: [Is/Is not] in interop boundary\n\n**Memory Management**: [N] unowned references detected\n- **Risk**: Crashes if referenced object is deallocated\n- **Recommendation**: Review and convert to `weak` where appropriate\n\n### Architecture Info ‚ÑπÔ∏è\n\n**UI Framework**: [SwiftUI|UIKit|Hybrid]\n- SwiftUI files: [N]\n- UIKit files: [M]\n- Integration points: [N] UIViewRepresentable, [M] UIHostingController\n\n**Bridging Headers**: [N] found\n- Largest imports: [N] headers\n- Circular dependencies: [None|Detected]\n\nüí° **Full Swift Analysis**: Run `/sourceatlas:impact [target].m` to see complete 7-section analysis\n\n---\n\n## 8. Recommendations\n\n1. [Recommendation 1]\n2. [Recommendation 2]\n3. [Recommendation 3]\n```\n\n---\n\n## For Model Impact\n\n```markdown\nüó∫Ô∏è SourceAtlas: Impact\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüí• $MODEL_NAME ‚îÇ [total dependents] dependents\n\nüìä **Impact Summary**:\n- Controllers: [count]\n- Services: [count]\n- Associated models: [count]\n- Test files: [count]\n- **Risk Level**: üî¥/üü°/üü¢ [reason]\n\n---\n\n## 1. Model Definition\n- File: [path]\n- Table: [table_name]\n- Key fields: [list]\n\n### Associations\n- `belongs_to :organization`\n- `has_many :orders`\n- `has_one :profile`\n\n### Validations\n- `validates :email, presence: true, uniqueness: true`\n- [other validations]\n\n---\n\n## 2. Direct Dependencies\n\n### Controllers ([count])\n1. `UsersController#create` ([path:line])\n   - Creates new User instances\n   - Validation-dependent\n\n2. `Admin::UsersController#update` ([path:line])\n   - Updates User attributes\n\n### Services ([count])\n1. `UserImportService` ([path:line])\n   - Bulk creates Users\n   - ‚ö†Ô∏è No validation error handling\n\n---\n\n## 3. Cascade Impact\n\n### Associated Models\n1. **Order model** ([path:line])\n   - `belongs_to :user, validates: true`\n   - **Impact**: Will fail if User validation fails\n\n2. **Notification model** ([path:line])\n   - Assumes `user.email` is always valid\n   - **Risk**: May send to invalid emails\n\n---\n\n## 4. Test Coverage\n\n**Existing Tests**:\n- `users_controller_spec.rb` - Basic CRUD\n- `user_spec.rb` - Model validations\n\n**Coverage Gaps**:\n- ‚ö†Ô∏è UserImportService has no validation failure tests\n- ‚ö†Ô∏è Order-User association not tested with invalid user\n\n---\n\n## 5. Migration Checklist\n\n- [ ] Review validation rules for edge cases\n- [ ] Add tests for validation failures\n- [ ] Update controllers to handle new validation errors\n- [ ] Check associated models for assumptions\n- [ ] Add integration tests for cascade effects\n- [ ] Update API documentation\n\n**Risk Level**: üî¥ HIGH | üü° MEDIUM | üü¢ LOW\n\nüí° **Note**: Time estimation depends on team velocity and complexity. Discuss with your team based on the checklist above.\n\n---\n\n## 6. Language-Specific Deep Analysis\n\n*(Same format as API Impact - include if iOS/Swift project)*\n```\n\n---\n\n## Field Descriptions\n\n### Impact Summary\n- **Backend/Frontend/Test files**: Count of impacted files by category\n- **Risk Level**: Overall assessment based on dependency count, criticality, and test coverage\n\n### Component Impact Sections\n- **High Priority**: Components directly using the target (will break immediately)\n- **Medium Priority**: Components indirectly using target (may break)\n\n### Field Usage Analysis\n- **Total occurrences**: Exact count from grep\n- **Locations**: File:line references with code snippet\n- **Breaking Change Assessment**: Migration complexity evaluation\n\n### Test Impact\n- **Test Files to Update**: Specific test files needing changes\n- **Coverage Gaps**: Missing tests that should be added\n\n### Migration Checklist\n- Concrete, actionable steps\n- Each item should be measurable\n- Include counts where known ([N] files)\n\n### Language-Specific Deep Analysis\n- Only include for iOS/Swift projects\n- Focus on interop risks and architecture\n- Provide actionable recommendations\n",
        "plugin/commands/impact/reference.md": "# Impact Analysis Reference\n\nAdvanced features and behaviors reference.\n\n---\n\n## Cache Behavior\n\n### Cache Check (Highest Priority)\n\n**If `--force` is not in arguments**, check cache first:\n\n1. Extract target name from `$ARGUMENTS` (remove `--force`)\n2. Convert to filename: spaces ‚Üí `-`, slashes ‚Üí `-`, lowercase, remove `{}`, **truncate to 50 characters**\n   - Example: `\"User model\"` ‚Üí `user-model.md`\n   - Example: `\"api /api/users/{id}\"` ‚Üí `api-users-id.md`\n3. Check cache:\n   ```bash\n   ls -la .sourceatlas/impact/{name}.md 2>/dev/null\n   ```\n\n4. **If cache exists**:\n   - Calculate days since creation\n   - Read cache content using Read tool\n   - Output:\n     ```\n     üìÅ Loading from cache: .sourceatlas/impact/{name}.md (N days ago)\n     üí° Use --force to reanalyze --force\n     ```\n   - **If over 30 days**, additionally display:\n     ```\n     ‚ö†Ô∏è Cache is over 30 days old, recommend reanalysis\n     ```\n   - Then output:\n     ```\n     ---\n     [Cache content]\n     ```\n   - **End, do not execute subsequent analysis**\n\n5. **If cache does not exist**: Continue with analysis below\n\n**If arguments contain `--force`**: Skip cache check, run analysis directly\n\n---\n\n## Auto-Save (Default Behavior)\n\nAfter analysis completes, automatically:\n\n### Step 1: Parse target name\n\nExtract target name from arguments (remove `--force`):\n- `\"User model\"` ‚Üí target name is `user-model`\n- `\"api /api/users/{id}\"` ‚Üí target name is `api-users-id`\n\nConvert to filename:\n- Spaces ‚Üí `-`\n- Slashes ‚Üí `-`\n- Remove `{`, `}`, special characters\n- Lowercase\n- Example: `\"User model\"` ‚Üí `user-model.md`\n\n### Step 2: Create directory\n\n```bash\nmkdir -p .sourceatlas/impact\n```\n\n### Step 3: Save output\n\nAfter generating the complete analysis, save the **entire output** (from `üó∫Ô∏è SourceAtlas: Impact` to the end) to `.sourceatlas/impact/{name}.md`\n\n### Step 4: Confirm\n\nAdd at the very end:\n```\nüíæ Saved to .sourceatlas/impact/{name}.md\n```\n\n---\n\n## Handoffs (Recommended Next)\n\n> Follows **Constitution Article VII: Handoffs Principles**\n\nAdd at the end of output:\n\n```markdown\n---\n\n## Recommended Next\n\n| # | Command | Purpose |\n|---|------|------|\n| 1 | `/sourceatlas:flow \"[entry point]\"` | Impact chain involves N-layer calls, need to trace complete flow |\n| 2 | `/sourceatlas:history \"[directory]\"` | This area changes frequently, need to understand historical patterns |\n\nüí° Enter number (e.g., `1`) or copy command to execute\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1\n```\n\n### End Conditions vs Recommendations (choose one, mutually exclusive)\n\n**‚ö†Ô∏è Important: The following two outputs are mutually exclusive, choose only one**\n\n**Situation A - End (omit Recommended Next)**:\nWhen any of the following conditions are met, **only output end message, do not output table**:\n- Impact scope is small: <5 dependencies, no further analysis needed\n- Findings too vague: Cannot provide with high confidence (>0.7) specific parameters\n- Analysis depth sufficient: Already executed 4+ commands\n\nOutput:\n```markdown\n‚úÖ **Impact analysis complete** - Can start modifications following the Migration Checklist\n```\n\n**Situation B - Recommend (output Recommended Next table)**:\nWhen impact scope is large or there are clear risks, **only output table, do not output end message**.\n\n### Recommendation Selection (applies to Situation B)\n\n| Finding | Recommended Command | Parameter Source |\n|------|---------|---------|\n| Involves specific pattern | `/sourceatlas:pattern` | pattern name |\n| Complex impact chain | `/sourceatlas:flow` | entry point file |\n| Need to understand change history | `/sourceatlas:history` | related directory |\n| Need broader context | `/sourceatlas:overview` | no parameters needed |\n\n### Output Format\n\nUse numbered table for quick selection.\n\n### Quality Requirements\n\n- **Specific parameters**: Use actual found file names or entry point\n- **Quantity limit**: 1-2 recommendations, not required to fill all\n- **Purpose column**: Reference specific findings (dependency count, risk level, issues)\n\n---\n\n## Best Practices\n\n### For Accurate Analysis\n\n1. **Use precise grep patterns**: Match import statements, not comments\n2. **Follow the call chain**: From definition ‚Üí usage ‚Üí components\n3. **Check test files separately**: Different directory structure\n4. **Consider indirect dependencies**: Hooks/Services wrapping the target\n\n### Language-Specific Search Patterns\n\n**TypeScript/JavaScript**:\n```bash\n# Imports\ngrep -r \"import { UserService } from\\|import UserService from\" --include=\"*.ts\"\n\n# Usage\ngrep -r \"UserService\\.\\|new UserService(\" --include=\"*.ts\"\n```\n\n**Ruby**:\n```bash\n# Requires\ngrep -r \"require.*user\\|require_relative.*user\" --include=\"*.rb\"\n\n# Usage\ngrep -r \"User\\.create\\|User\\.find\\|User\\.where\" --include=\"*.rb\"\n```\n\n**Go**:\n```bash\n# Imports\ngrep -r 'import.*\".*user\"' --include=\"*.go\"\n\n# Usage\ngrep -r \"user\\.\\|User{\" --include=\"*.go\"\n```\n\n**Python**:\n```bash\n# Imports\ngrep -r \"from.*user import\\|import user\" --include=\"*.py\"\n\n# Usage\ngrep -r \"User(\\|user\\.\" --include=\"*.py\"\n```\n\n---\n\n## Deprecated Features\n\n### --save flag\n\nIf `--save` is in arguments:\n- Show: `‚ö†Ô∏è --save is deprecated, auto-save is now default`\n- Remove `--save` from arguments\n- Continue normal execution (still auto-saves)\n\n---\n\n## Tips for Complex Projects\n\n### Large Codebases (>100 dependencies)\n\nWhen facing too many results:\n1. Sample top 20-30 most relevant\n2. Group by category (controllers, services, components)\n3. Provide statistical summary instead of full list\n4. Warn about incomplete analysis\n\nExample:\n```\nüìä **Impact Summary** (sampled from 156 total dependencies):\n- Controllers: 23 files\n- Services: 45 files\n- Components: 88 files\n\n‚ö†Ô∏è Showing top 20 high-priority dependencies. Run with specific filters for complete analysis.\n```\n\n### Monorepos\n\nSpecify scope to avoid false positives:\n```bash\n# Instead of searching entire repo\ngrep -r \"UserService\" .\n\n# Search specific packages\ngrep -r \"UserService\" packages/backend/ packages/api/\n```\n\n### False Positive Reduction\n\nExclude common noise:\n```bash\ngrep -r \"UserService\" . \\\n  | grep -v \"node_modules\" \\\n  | grep -v \".git\" \\\n  | grep -v \"coverage\" \\\n  | grep -v \"build\" \\\n  | grep -v \"dist\"\n```\n",
        "plugin/commands/impact/verification-guide.md": "# Impact Analysis Verification Guide\n\nPrevent hallucinated file paths, incorrect dependency counts, and fictional impact assessments.\n\n**When to Run**: After output generation, BEFORE save\n\n---\n\n## Step V1: Extract Verifiable Claims\n\nAfter generating the impact analysis output, extract all verifiable claims:\n\n### Claim Types to Extract\n\n| Type | Pattern | Verification Method |\n|------|---------|---------------------|\n| **File Path** | Impacted files, dependencies | `test -f path` |\n| **Dependency Count** | \"12 direct dependencies\" | Count actual imports/usages |\n| **Import Statement** | `import X from Y` | `grep -q \"import.*X\" file` |\n| **Function/Class Name** | `UserService`, `handleLogin` | `grep -q \"name\" file` |\n| **Line Number** | `:45`, `:120` | `sed -n 'Np' file` |\n\n---\n\n## Step V2: Parallel Verification Execution\n\nRun **ALL** verification checks in parallel:\n\n```bash\n# Execute all verifications in a single parallel block\n\n# 1. Verify target file exists\ntarget_file=\"src/services/UserService.ts\"\nif [ ! -f \"$target_file\" ]; then\n    echo \"‚ùå TARGET_NOT_FOUND: $target_file\"\nfi\n\n# 2. Verify impacted files exist\nfor path in \"src/api/auth.ts\" \"src/components/Login.tsx\"; do\n    if [ ! -f \"$path\" ]; then\n        echo \"‚ùå IMPACTED_FILE_NOT_FOUND: $path\"\n    fi\ndone\n\n# 3. Verify dependency count\nclaimed_deps=12\nactual_deps=$(grep -l \"UserService\" src/**/*.ts 2>/dev/null | wc -l | tr -d ' ')\nif [ \"$actual_deps\" != \"$claimed_deps\" ]; then\n    echo \"‚ö†Ô∏è DEP_COUNT_MISMATCH: claimed $claimed_deps, actual $actual_deps\"\nfi\n\n# 4. Verify import relationships\nif ! grep -q \"import.*UserService\" \"src/api/auth.ts\" 2>/dev/null; then\n    echo \"‚ùå IMPORT_NOT_FOUND: UserService in src/api/auth.ts\"\nfi\n\n# 5. Verify line number references\nclaimed_line=45\nfile_path=\"src/services/UserService.ts\"\nif [ -f \"$file_path\" ]; then\n    line_content=$(sed -n \"${claimed_line}p\" \"$file_path\")\n    if [ -z \"$line_content\" ]; then\n        echo \"‚ùå LINE_NOT_FOUND: line $claimed_line in $file_path\"\n    fi\nfi\n```\n\n---\n\n## Step V3: Handle Verification Results\n\n### If ALL checks pass\n\n- Continue to output/save\n\n### If ANY check fails\n\n1. **DO NOT output the uncorrected analysis**\n2. Fix each failed claim:\n   - `TARGET_NOT_FOUND` ‚Üí Search for correct target file path\n   - `IMPACTED_FILE_NOT_FOUND` ‚Üí Remove from impact list or find correct path\n   - `DEP_COUNT_MISMATCH` ‚Üí Update with actual dependency count\n   - `IMPORT_NOT_FOUND` ‚Üí Remove invalid dependency relationship\n   - `LINE_NOT_FOUND` ‚Üí Re-read file and find correct line\n3. Re-generate affected sections with corrected information\n4. Re-run verification on corrected sections\n\n---\n\n## Step V4: Verification Summary\n\nAdd to footer (before `üó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1`):\n\n### If all verifications passed\n\n```\n‚úÖ Verified: [N] file paths, [M] dependencies, [K] import relationships\n```\n\n### If corrections were made\n\n```\nüîß Self-corrected: [list specific corrections made]\n‚úÖ Verified: [N] file paths, [M] dependencies, [K] import relationships\n```\n\n---\n\n## Verification Checklist\n\nBefore finalizing output, confirm:\n\n- [ ] Target file verified to exist\n- [ ] All impacted file paths verified to exist\n- [ ] Dependency count verified against actual grep results\n- [ ] Import relationships verified via grep\n- [ ] Line number references verified (content is relevant)\n\n---\n\n## Common Verification Errors\n\n### Error: TARGET_NOT_FOUND\n\n**Cause**: Target file path doesn't exist\n\n**Fix**:\n```bash\n# Find the correct path\nfind . -name \"*UserService*\" -type f | grep -v node_modules | grep -v test\n# Update output with correct path\n```\n\n### Error: DEP_COUNT_MISMATCH\n\n**Cause**: Claimed count doesn't match actual grep results\n\n**Fix**:\n```bash\n# Recount dependencies\nactual_count=$(grep -rl \"UserService\" src/ | wc -l | tr -d ' ')\n# Update output with actual count\n```\n\n### Error: IMPORT_NOT_FOUND\n\n**Cause**: Claimed import statement doesn't exist in file\n\n**Fix**:\n```bash\n# Verify import exists\ngrep \"import.*UserService\" src/api/auth.ts\n# If not found, remove this dependency from report\n```\n\n### Error: LINE_NOT_FOUND\n\n**Cause**: Referenced line number doesn't exist or file is shorter\n\n**Fix**:\n```bash\n# Check actual file length\nwc -l src/services/UserService.ts\n# Re-read file and find correct line\n# Update line number in output\n```\n\n---\n\n## Verification Examples\n\n### Example 1: Verify dependency count\n\n```bash\n# Claim: \"12 direct dependencies on UserService\"\nclaimed=12\nactual=$(grep -rl \"import.*UserService\\|from.*UserService\" src/ | wc -l | tr -d ' ')\n\nif [ \"$actual\" != \"$claimed\" ]; then\n    echo \"‚ö†Ô∏è Count mismatch: claimed $claimed, actual $actual\"\n    # Update output with actual count\nfi\n```\n\n### Example 2: Verify file paths\n\n```bash\n# Claim: Impact analysis lists 5 files\nfiles=(\n    \"src/api/users.ts\"\n    \"src/components/UserBadge.tsx\"\n    \"src/hooks/useUser.ts\"\n    \"src/services/UserService.ts\"\n    \"src/types/user.d.ts\"\n)\n\nfor file in \"${files[@]}\"; do\n    if [ ! -f \"$file\" ]; then\n        echo \"‚ùå File not found: $file\"\n    fi\ndone\n```\n\n### Example 3: Verify import relationships\n\n```bash\n# Claim: \"UserBadge.tsx imports useUser hook\"\nif ! grep -q \"import.*useUser\\|from.*useUser\" \"src/components/UserBadge.tsx\"; then\n    echo \"‚ùå Import not found: useUser in UserBadge.tsx\"\n    # Remove this claim from output\nfi\n```\n\n---\n\n## Quality Assurance\n\n### High Confidence Required\n\nOnly include claims with >90% confidence:\n- File paths you've actually Read\n- Counts from actual grep results\n- Import statements you've verified\n\n### Exclude Low Confidence\n\nRemove claims based on:\n- Assumptions without verification\n- Estimated counts (use \"~\")\n- Speculative dependencies\n",
        "plugin/commands/impact/workflow.md": "# Impact Analysis Workflow\n\nComplete step-by-step guide for executing static dependency analysis.\n\n## Step 1: Parse Target and Detect Type (1 minute)\n\nAnalyze `$ARGUMENTS` to determine the analysis type:\n\n**Type Detection**:\n\n```bash\n# If contains \"api\" or starts with \"/\" -> API Impact\nif [[ \"$ARGUMENTS\" =~ api|^/ ]]; then\n    TYPE=\"API\"\n    # Extract API path, e.g., \"/api/users/{id}\"\nfi\n\n# If contains \"model\" or common model names\nif [[ \"$ARGUMENTS\" =~ model|Model|entity|Entity ]]; then\n    TYPE=\"MODEL\"\nfi\n\n# Otherwise -> General Component\nTYPE=\"COMPONENT\"\n```\n\n**Detected Type determines analysis strategy:**\n- **API**: Backend ‚Üí Frontend call chain\n- **MODEL**: Database layer ‚Üí Business logic ‚Üí Controllers\n- **COMPONENT**: General dependency search\n\n---\n\n## Step 2: Project Context Detection (1 minute)\n\nUnderstand the project structure:\n\n```bash\n# Detect project type (Swift BEFORE Ruby to avoid Gemfile misdetection)\nif [ -f \"Package.swift\" ] || [ -f \"Project.swift\" ] || [ -d \"Tuist\" ] || \\\n   ls *.xcodeproj >/dev/null 2>&1 || ls *.xcworkspace >/dev/null 2>&1; then\n    PROJECT_TYPE=\"iOS/Swift\"\n    NEEDS_SWIFT_ANALYSIS=true\nelif [ -f \"package.json\" ]; then\n    PROJECT_TYPE=\"Node.js/TypeScript\"\n    # Check if frontend (React/Next/Vue)\n    if grep -q \"react\\|next\\|vue\" package.json; then\n        HAS_FRONTEND=true\n    fi\nelif [ -f \"Gemfile\" ]; then\n    PROJECT_TYPE=\"Ruby/Rails\"\nelif [ -f \"go.mod\" ]; then\n    PROJECT_TYPE=\"Go\"\nfi\n```\n\n**Key Directories to Scan**:\n- Backend: `src/`, `app/`, `lib/`, `api/`\n- Frontend: `components/`, `pages/`, `app/`, `hooks/`, `utils/`\n- Tests: `__tests__/`, `spec/`, `test/`, `*.test.*`, `*.spec.*`\n- Types: `types/`, `*.d.ts`, `interfaces/`\n- iOS: `Sources/`, `**/Classes/`, `*.xcodeproj/`, `Tests/`\n\n---\n\n## Step 2.5: ast-grep Enhanced Search (Optional, P1 Enhancement)\n\n**When to use**: ast-grep provides more precise dependency search, excluding false positives in comments and strings.\n\n**Use unified script** (`ast-grep-search.sh`):\n\n```bash\n# Set script path (global first, local fallback)\nAST_SCRIPT=\"\"\nif [ -f ~/.claude/scripts/atlas/ast-grep-search.sh ]; then\n    AST_SCRIPT=~/.claude/scripts/atlas/ast-grep-search.sh\nelif [ -f scripts/atlas/ast-grep-search.sh ]; then\n    AST_SCRIPT=scripts/atlas/ast-grep-search.sh\nfi\n\n# Type reference search (MODEL/COMPONENT)\n$AST_SCRIPT type \"UserDto\" --path .\n$AST_SCRIPT type \"ViewModel\" --path .\n\n# Function call tracking (API)\n$AST_SCRIPT call \"fetchUser\" --path .\n\n# If ast-grep is not installed, get grep fallback command\n$AST_SCRIPT type \"UserDto\" --fallback\n```\n\n**Value**: According to integration tests, ast-grep achieves in dependency analysis:\n- Swift UserDto dependencies: 93% false positive elimination\n- TypeScript useState: 15% false positive elimination\n- Kotlin ViewModel: 92% false positive elimination\n\n**Graceful Degradation**: Script automatically handles ast-grep unavailability, using `--fallback` to get equivalent grep command.\n\n---\n\n## Step 3: Execute Impact Analysis (3-5 minutes)\n\n### For API Impact (Type: API)\n\n**Phase 1: Backend Definition**\n\n```bash\n# Find API endpoint definition\n# Look for: route definitions, controllers, handlers\ngrep -r \"$API_PATH\" --include=\"*.ts\" --include=\"*.js\" --include=\"*.rb\" --include=\"*.go\" \\\n  app/ src/ routes/ api/ controllers/ 2>/dev/null | head -20\n```\n\n**Phase 2: Type Definitions**\n\n```bash\n# Find response type definitions (critical for API changes)\ngrep -r \"Response\\|ResponseType\" --include=\"*.ts\" --include=\"*.d.ts\" \\\n  types/ src/types/ 2>/dev/null | head -10\n```\n\n**Phase 3: Frontend Usage**\n\n```bash\n# Find API calls in frontend\ngrep -r \"$API_PATH\\|fetch.*users\\|axios.*users\" \\\n  --include=\"*.ts\" --include=\"*.tsx\" --include=\"*.js\" --include=\"*.jsx\" \\\n  src/ components/ app/ pages/ hooks/ 2>/dev/null | head -30\n```\n\n**Phase 4: Hook/Service Layer**\n\n```bash\n# Find custom hooks or services wrapping the API\ngrep -r \"useUser\\|userService\\|UserAPI\" \\\n  --include=\"*.ts\" --include=\"*.tsx\" \\\n  hooks/ services/ lib/ 2>/dev/null | head -20\n```\n\n**Phase 5: Component Usage**\n\nFor each Hook/Service found, find which components use it:\n\n```bash\n# Example: Find all imports of useUser\ngrep -r \"import.*useUser\\|from.*useUser\" \\\n  --include=\"*.tsx\" --include=\"*.ts\" \\\n  components/ app/ pages/ 2>/dev/null\n```\n\n### For Model Impact (Type: MODEL)\n\n**Phase 1: Model Definition**\n\n```bash\n# Find the model file\nfind . -name \"*User*.rb\" -o -name \"*user*.py\" -o -name \"*User*.ts\" \\\n  2>/dev/null | grep -v node_modules | grep -v test\n```\n\n**Phase 2: Direct Dependencies**\n\n```bash\n# Who imports/requires this model?\nMODEL_FILE=\"app/models/user.rb\"\ngrep -r \"require.*user\\|import.*User\\|from.*user\" \\\n  --include=\"*.rb\" --include=\"*.py\" --include=\"*.ts\" \\\n  app/ src/ lib/ 2>/dev/null | head -30\n```\n\n**Phase 3: Associations**\n\nRead the model file and identify associations:\n- `belongs_to`, `has_many`, `has_one` (Rails)\n- Foreign keys and references\n- Validation rules\n\n**Phase 4: Business Logic Usage**\n\n```bash\n# Find controllers/services using the model\ngrep -r \"User\\.create\\|User\\.find\\|User\\.where\\|new User\" \\\n  --include=\"*.rb\" --include=\"*.ts\" \\\n  controllers/ services/ app/ 2>/dev/null | head -30\n```\n\n### For General Component (Type: COMPONENT)\n\n**Phase 1: Locate Component**\n\n```bash\n# Find files matching the component name\nCOMPONENT_NAME=\"authentication\"\nfind . -iname \"*${COMPONENT_NAME}*\" -type f \\\n  -not -path \"*/node_modules/*\" \\\n  -not -path \"*/.git/*\" \\\n  2>/dev/null | head -20\n```\n\n**Phase 2: Find Imports/References**\n\n```bash\n# Search for imports\ngrep -r \"import.*${COMPONENT_NAME}\\|require.*${COMPONENT_NAME}\\|from.*${COMPONENT_NAME}\" \\\n  --include=\"*.ts\" --include=\"*.js\" --include=\"*.rb\" \\\n  . 2>/dev/null | grep -v node_modules | head -30\n```\n\n**Phase 3: Find Usage**\n\n```bash\n# Search for function calls\ngrep -r \"${COMPONENT_NAME}\\.\\|${COMPONENT_NAME}(\" \\\n  --include=\"*.ts\" --include=\"*.js\" \\\n  . 2>/dev/null | grep -v node_modules | head -30\n```\n\n**Phase 4: Mutually Exclusive Categorization** ‚ö†Ô∏è REQUIRED\n\n```bash\n# IMPORTANT: Categories MUST be mutually exclusive to avoid double-counting\n# Save all dependent files first\ngrep -rl \"${COMPONENT_NAME}\" --include=\"*.swift\" . 2>/dev/null | grep -v Test | grep -v Mock | sort -u > /tmp/all_deps.txt\n\n# Count total (this is the authoritative number)\nTOTAL=$(wc -l < /tmp/all_deps.txt)\n\n# Categorize with exclusion chain (order matters!)\n# 1. Core module files (highest priority)\nCORE=$(grep \"${COMPONENT_NAME}\" /tmp/all_deps.txt | wc -l)\n\n# 2. Coordinators (exclude core)\nCOORDINATORS=$(grep -v \"${COMPONENT_NAME}\" /tmp/all_deps.txt | grep 'Coordinator' | wc -l)\n\n# 3. Frontend (exclude core and coordinators)\nFRONTEND=$(grep -v \"${COMPONENT_NAME}\" /tmp/all_deps.txt | grep -v 'Coordinator' | grep 'Frontend' | wc -l)\n\n# 4. Others (everything else)\nOTHERS=$(grep -v \"${COMPONENT_NAME}\" /tmp/all_deps.txt | grep -v 'Coordinator' | grep -v 'Frontend' | wc -l)\n\n# VERIFY: Sum must equal total\necho \"Verification: $CORE + $COORDINATORS + $FRONTEND + $OTHERS = $TOTAL\"\n```\n\n**Phase 5: Exact API Usage Counts** ‚ö†Ô∏è REQUIRED\n\n```bash\n# NEVER estimate - always run actual grep counts\n# For each key API/property, count exact occurrences\n\n# Example for Swift:\necho \"selectedTab: $(grep -rn '\\.selectedTab' --include='*.swift' . | grep -v Test | wc -l)\"\necho \"addDelegate: $(grep -rn 'addDelegate' --include='*.swift' . | grep -v Test | wc -l)\"\n\n# Report actual numbers, NOT estimates like \"~30\"\n```\n\n---\n\n## Step 4: Test Impact Analysis (1-2 minutes)\n\n**Find Related Tests**:\n\n```bash\n# Find test files by name pattern\nfind . -name \"*user*test*\" -o -name \"*user*spec*\" \\\n  2>/dev/null | grep -v node_modules\n\n# Find tests importing the target\ngrep -r \"import.*User\\|require.*user\" \\\n  --include=\"*.test.*\" --include=\"*.spec.*\" \\\n  __tests__/ spec/ test/ 2>/dev/null | head -20\n```\n\n**Analyze Test Coverage**:\n- Are there tests for the target component?\n- Are there integration tests?\n- Are there E2E tests covering the flow?\n\n---\n\n## Step 5: Language-Specific Deep Analysis (1-2 minutes, optional)\n\n**When to Run**: If `NEEDS_SWIFT_ANALYSIS=true` AND target file is `.swift`, `.m`, or `.h`\n\nExecute the Swift/Objective-C deep analyzer for additional insights:\n\n```bash\n# Check if this is an iOS project with Swift/ObjC target\nif [[ \"$TARGET_FILE\" =~ \\.(swift|m|h)$ ]] && [[ \"$PROJECT_TYPE\" == \"iOS/Swift\" ]]; then\n    echo \"Running Swift/Objective-C deep analysis...\"\n\n    # Execute analyzer (located at scripts/atlas/analyzers/swift-analyzer.sh)\n    SWIFT_ANALYSIS_OUTPUT=$(./scripts/atlas/analyzers/swift-analyzer.sh \"$TARGET_FILE\" \"$PROJECT_ROOT\" 2>&1)\n\n    # Parse key findings from the output\n    # - Nullability coverage percentage\n    # - @objc exposure count\n    # - Memory management warnings\n    # - UI framework architecture\nfi\n```\n\n**What This Provides**:\n- Nullability annotation coverage (CRITICAL for Swift interop)\n- @objc exposure detection (breaking change risks)\n- Memory management warnings (unowned, retain cycles)\n- Bridging header circular dependency checks\n- SwiftUI vs UIKit architecture detection\n\n**Integration**: Include key findings in the final report's \"Language-Specific Risks\" section\n\n---\n\n## Step 6: Risk Assessment (1 minute)\n\nEvaluate impact level based on findings:\n\n**Risk Factors**:\n- Number of direct dependents (>10 = HIGH)\n- Presence in critical path (auth, payment = HIGH)\n- Test coverage (<50% = HIGH risk)\n- Type of change (breaking change = HIGH)\n\n**Risk Levels**:\n- üü¢ **LOW**: 1-5 dependents, well-tested, non-critical\n- üü° **MEDIUM**: 5-15 dependents, partial tests, business logic\n- üî¥ **HIGH**: >15 dependents OR critical path OR breaking change\n\n---\n\n## Error Handling\n\n**If target not found**:\n- Search with fuzzy matching\n- Suggest similar components\n- Ask user to clarify\n\n**If too many results** (>100):\n- Sample top 20-30 most relevant\n- Group by category (controllers, services, etc.)\n- Warn about incomplete analysis\n\n**If no dependencies found**:\n- Verify target exists\n- Check if it's a leaf component (no dependents)\n- Suggest dead code possibility\n\n---\n\n## Tips for Accurate Analysis\n\n- **Use precise grep patterns**: Match import statements, not comments\n- **Follow the call chain**: From definition ‚Üí usage ‚Üí components\n- **Check test files separately**: Different directory structure\n- **Consider indirect dependencies**: Hooks/Services wrapping the target\n- **Language-specific patterns**:\n  - TypeScript: `import { X } from`, `X.method()`, type definitions\n  - Ruby: `require`, `include`, `Class.method`\n  - Go: `import`, package usage\n  - Python: `from X import`, `import X`\n",
        "plugin/commands/list/SKILL.md": "---\nname: list\ndescription: List saved SourceAtlas analysis results\nmodel: haiku\nallowed-tools: Bash\n---\n\n# SourceAtlas: List Saved Results\n\n## Your Task\n\nList all saved analysis results in the `.sourceatlas/` directory.\n\n### Step 1: Check directory exists\n\n```bash\nls -la .sourceatlas/ 2>/dev/null || echo \"NOT_FOUND\"\n```\n\nIf output contains `NOT_FOUND` or directory is empty:\n\n```\nüìÅ No saved analyses yet\n\nUse the `--save` parameter to save analysis results:\n- `/sourceatlas:overview --save`\n- `/sourceatlas:pattern \"api\" --save`\n- `/sourceatlas:history --save`\n```\n\nEnd.\n\n### Step 2: List all files with details\n\n```bash\nfind .sourceatlas -type f -exec ls -lh {} \\; 2>/dev/null | sort\n```\n\n### Step 3: Format output\n\nFormat results into a table, calculate days since modification, and mark expired status (>30 days):\n\n```\nüìÅ .sourceatlas/ saved analyses:\n\n| Type | File | Size | Modified | Status |\n|------|------|------|----------|--------|\n| overview | overview.yaml | 2.3 KB | 3 days ago | ‚úÖ |\n| pattern | patterns/api.md | 1.5 KB | 45 days ago | ‚ö†Ô∏è |\n| pattern | patterns/repository.md | 2.1 KB | 5 days ago | ‚úÖ |\n| history | history.md | 4.2 KB | 60 days ago | ‚ö†Ô∏è |\n| flow | flows/checkout.md | 3.1 KB | 2 days ago | ‚úÖ |\n| impact | impact/user-model.md | 1.8 KB | 4 days ago | ‚úÖ |\n| deps | deps/react.md | 2.5 KB | 6 days ago | ‚úÖ |\n\nüìä Stats: 7 cached, 2 expired (>30 days)\n\nüí° Tips:\n- Clear cache: `/sourceatlas:clear`\n- Clear specific type: `/sourceatlas:clear patterns`\n```\n\n### Step 4: List expired items with refresh commands\n\nIf there are expired items (>30 days), output copyable re-analysis commands:\n\n```\n‚ö†Ô∏è Expired items (recommend re-analysis):\n\n| File | Days | Re-analyze Command |\n|------|------|-------------------|\n| patterns/api.md | 45 days | `/sourceatlas:pattern \"api\" --force --save` |\n| history.md | 60 days | `/sourceatlas:history --force --save` |\n\nüí° Copy the commands above to re-analyze\n```\n\n**Command generation rules**:\n\n| Type | Command Format |\n|------|----------------|\n| overview | `/sourceatlas:overview --force --save` |\n| overview-{dir} | `/sourceatlas:overview {dir} --force --save` |\n| patterns/{name}.md | `/sourceatlas:pattern \"{name}\" --force --save` |\n| history.md | `/sourceatlas:history --force --save` |\n| flows/{name}.md | `/sourceatlas:flow \"{name}\" --force --save` |\n| impact/{name}.md | `/sourceatlas:impact \"{name}\" --force --save` |\n| deps/{name}.md | `/sourceatlas:deps \"{name}\" --force --save` |\n\n**Note**: Convert `-` in filenames back to spaces for parameters (e.g., `api-endpoint.md` ‚Üí `\"api endpoint\"`)\n\n---\n\n## Type Detection Rules\n\n| File Path | Type |\n|-----------|------|\n| `overview.yaml` or `overview-*.yaml` | overview |\n| `patterns/*.md` | pattern |\n| `flows/*.md` | flow |\n| `history.md` | history |\n| `impact/*.md` | impact |\n| `deps/*.md` | deps |\n",
        "plugin/commands/overview/SKILL.md": "---\nname: overview\ndescription: Get project overview - scan <5% of files to achieve 70-80% understanding\nmodel: sonnet\nallowed-tools: Bash, Glob, Grep, Read, Write\nargument-hint: \"[path] [--force] (e.g., 'src/api' or '. --force')\"\n---\n\n# SourceAtlas: Project Overview (Stage 0 Fingerprint)\n\n> **Constitution**: [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md) v1.0\n\n## Context\n\n**Arguments**: ${ARGUMENTS:-.}\n\n**Goal**: Generate project fingerprint by scanning <5% of files to achieve 70-80% understanding in 10-15 minutes.\n\n**Auto-Save**: Results automatically saved to `.sourceatlas/overview.yaml` (or subdirectory-specific path)\n\n**Time Limit**: 10-15 minutes (typically 0-5 minutes)\n\n---\n\n## Cache Check (Highest Priority)\n\n**If `--force` is NOT in arguments**, check cache first:\n\n1. Calculate cache path:\n   - No path argument or `.`: `.sourceatlas/overview.yaml`\n   - With path (e.g., `src/api`): `.sourceatlas/overview-src-api.yaml`\n\n2. Check if cache exists:\n   ```bash\n   ls -la .sourceatlas/overview.yaml 2>/dev/null\n   ```\n\n3. **If cache exists**:\n   - Calculate days since modification\n   - Use Read tool to read cache\n   - Output:\n     ```\n     üìÅ Loading cache: .sourceatlas/overview.yaml (N days ago)\n     üí° Add --force to re-analyze\n     ```\n   - **If over 30 days**: Show warning\n   - Output cache content\n   - **End, do not execute analysis**\n\n4. **If cache does not exist**: Continue with analysis\n\n**If `--force` is in arguments**: Skip cache, execute analysis\n\n---\n\n## Your Task\n\nExecute **Stage 0 Analysis Only** - generate project fingerprint using information theory principles.\n\n**Information Theory Approach:**\n- **High-entropy files** contain disproportionate information\n- Scan priority: Documentation ‚Üí Configuration ‚Üí Models ‚Üí Entry Points ‚Üí Tests\n- **Scale-aware**: TINY/SMALL/MEDIUM/LARGE/VERY_LARGE projects need different approaches\n\n---\n\n## Core Workflow\n\nExecute these phases in order. See [workflow.md](workflow.md) for complete details.\n\n### Phase 1: Project Detection & Scale-Aware Planning (2-3 minutes)\n\n**Purpose:** Detect project type, count files, determine scale, set scan limits.\n\n**Execute detection:**\n```bash\n# Try helper script first (recommended)\nif [ -f ~/.claude/scripts/atlas/detect-project.sh ]; then\n    bash ~/.claude/scripts/atlas/detect-project.sh ${ARGUMENTS:-.}\nelif [ -f scripts/atlas/detect-project.sh ]; then\n    bash scripts/atlas/detect-project.sh ${ARGUMENTS:-.}\nelse\n    echo \"Warning: detect-project.sh not found, using manual detection\"\nfi\n```\n\n**Scale-Aware Scan Limits:**\n- **TINY** (<5 files): 1-2 files (50% max)\n- **SMALL** (5-15 files): 2-3 files (10-20%)\n- **MEDIUM** (15-50 files): 4-6 files (8-12%)\n- **LARGE** (50-150 files): 6-10 files (4-7%)\n- **VERY_LARGE** (>150 files): 10-15 files (3-7%)\n\n‚Üí See [workflow.md#phase-1](workflow.md#phase-1-project-detection--scale-aware-planning-2-3-minutes) for manual fallback\n\n### Phase 2: High-Entropy File Prioritization (5-8 minutes)\n\n**Purpose:** Scan highest information-density files first.\n\n**Scan Priority Order:**\n1. **Documentation** (README.md, CLAUDE.md, docs/)\n2. **Configuration** (package.json, docker-compose.yml, etc.)\n3. **Core Models** (models/, entities/, domain/) - pick 2-3 only\n4. **Entry Points** (app.ts, routes/) - pick 1-2 examples\n5. **Tests** - pick 1-2 examples\n\n**Execute scanning:**\n```bash\n# Use helper script if available\nif [ -f ~/.claude/scripts/atlas/scan-entropy.sh ]; then\n    bash ~/.claude/scripts/atlas/scan-entropy.sh ${ARGUMENTS:-.}\nelse\n    echo \"Warning: scan-entropy.sh not found, scanning manually\"\nfi\n```\n\n**AI Tool Detection:**\n```bash\n# Detect AI collaboration level (Tier 1 + Tier 2)\nif [ -f ~/.claude/scripts/atlas/detect-ai-tools.sh ]; then\n    bash ~/.claude/scripts/atlas/detect-ai-tools.sh ${ARGUMENTS:-.}\nelse\n    # Fallback: manual checks\n    ls -la CLAUDE.md .cursorrules .windsurfrules CONVENTIONS.md AGENTS.md .aiignore 2>/dev/null\n    ls -la .claude/ .cursor/rules/ .windsurf/rules/ .clinerules/ .roo/ .continue/rules/ .ruler/ 2>/dev/null\nfi\n```\n\n‚Üí See [workflow.md#phase-2](workflow.md#phase-2-high-entropy-file-prioritization-5-8-minutes) for manual commands\n\n### Phase 3: Generate Hypotheses (3-5 minutes)\n\n**Purpose:** Generate scale-appropriate hypotheses with confidence levels and evidence.\n\n**Hypothesis Categories:**\n- **Technology Stack**: Languages, frameworks, databases, testing\n- **Architecture**: Patterns, structure, layering\n- **Development Practices**: Code quality, testing, documentation\n- **AI Collaboration**: Tool detection (Level 0-4)\n- **Business Domain**: Purpose, entities, features\n\n**Scale-Aware Targets:**\n- TINY: 5-8 hypotheses\n- SMALL: 7-10 hypotheses\n- MEDIUM: 10-15 hypotheses\n- LARGE: 12-18 hypotheses\n- VERY_LARGE: 15-20 hypotheses\n\n**Each hypothesis must include:**\n- hypothesis: Clear statement\n- confidence: 0.0-1.0 (aim for >0.7)\n- evidence: file:line references\n- validation_method: How to verify\n\n‚Üí See [workflow.md#phase-3](workflow.md#phase-3-generate-hypotheses-3-5-minutes) for detailed guidance\n\n---\n\n## Output Format\n\nGenerate output with **branded header**, then **YAML format**:\n\n```markdown\nüó∫Ô∏è SourceAtlas: Overview\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüî≠ [project_name] ‚îÇ [SCALE] ([file count] files)\n```\n\nThen YAML content with sections:\n- `metadata`: project_name, scan_time, total_files, scanned_files, scan_ratio, project_scale, context\n- `project_fingerprint`: project_type, scale, primary_language, framework, architecture\n- `tech_stack`: backend, frontend (optional), infrastructure (optional)\n- `hypotheses`: architecture, tech_stack, development, ai_collaboration, business\n- `scanned_files`: List with file, reason, key_insight\n- `summary`: understanding_depth, key_findings\n\n‚Üí See [output-template.md](output-template.md) for complete YAML structure and examples\n\n---\n\n## Critical Rules\n\n1. **Scale-Aware Scanning**: Follow recommended file limits from Phase 1\n2. **Exclude Common Bloat**: Never scan .venv/, node_modules/, vendor/, __pycache__, .git/\n3. **Time Limit**: Complete in 10-15 minutes (typically 0-5 minutes)\n4. **Hypothesis Quality**: Each must have confidence >0.7 and evidence\n5. **Scale-Aware Targets**: Use hypothesis targets appropriate for project scale\n6. **No Deep Diving**: Understand structure > implementation details\n7. **STOP after Stage 0**: Do not proceed to validation or git analysis\n\n---\n\n## Handoffs Decision Rules\n\n> Follow **Constitution Article VII: Handoffs Principles**\n\n**‚ö†Ô∏è Choose ONE output, NOT both:**\n\n**Case A - End (No Table):**\nWhen any condition is met:\n- Project too small: TINY (<10 files)\n- Findings too vague: Cannot provide high confidence (>0.7) parameters\n- Goal achieved: AI collaboration Level ‚â•3 and scale TINY/SMALL\n\nOutput:\n```markdown\n‚úÖ **Analysis sufficient** - Project is small, can read all files directly\n```\n\n**Case B - Suggestions (Table):**\nWhen project scale is large enough or clear next steps exist.\n\n| Finding | Command | Parameter |\n|---------|---------|-----------|\n| Clear patterns | `/sourceatlas:pattern` | Pattern name |\n| Complex architecture | `/sourceatlas:flow` | Entry point file |\n| Scale ‚â• LARGE | `/sourceatlas:history` | No parameters |\n| High risk areas | `/sourceatlas:impact` | Risk file/module |\n\nFormat:\n```markdown\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"repository\"` | Found Repository pattern in 15 files |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n```\n\n‚Üí See [reference.md#handoffs](reference.md#handoffs-decision-rules) for detailed logic\n\n---\n\n## Self-Verification Phase (REQUIRED)\n\n> **Purpose**: Prevent hallucinated file paths, incorrect counts, fictional configs.\n> Execute AFTER output generation, BEFORE save.\n\n**Verification Steps:**\n\n### Step V1: Extract Verifiable Claims\n\nExtract from generated YAML:\n- File paths (`scanned_files[].file`)\n- Config files (`tools_detected[].config_file`)\n- File count (`metadata.total_files`)\n- Git branch (`metadata.context.git_branch`)\n- Evidence references (`hypotheses.*.evidence`)\n\n### Step V2: Parallel Verification\n\nRun ALL checks in parallel:\n- Verify scanned files exist: `test -f path`\n- Verify AI tool configs exist: `test -f config`\n- Verify file count: ¬±10% tolerance\n- Verify git branch: `git branch --show-current`\n- Verify evidence files exist\n\n### Step V3: Handle Results\n\n- ‚úÖ All pass ‚Üí Continue to output/save\n- ‚ö†Ô∏è 1-2 fail ‚Üí Correct claims, note in summary\n- ‚ùå 3+ fail ‚Üí Re-execute analysis phases\n\n### Step V4: Verification Summary\n\nAdd to footer:\n\n**If all passed:**\n```\n‚úÖ Verified: [N] scanned files, [M] config paths, file count\n```\n\n**If corrected:**\n```\nüîß Self-corrected: [list corrections]\n‚úÖ Verified: [N] scanned files, [M] config paths, file count\n```\n\n‚Üí See [verification-guide.md](verification-guide.md) for complete checklist and examples\n\n---\n\n## Auto-Save (Default Behavior)\n\nAfter verification passes, automatically:\n\n1. Create directory: `mkdir -p .sourceatlas`\n2. Save YAML output to:\n   - Root: `.sourceatlas/overview.yaml`\n   - Subdirectory: `.sourceatlas/overview-[path].yaml`\n3. Confirm: `üíæ Saved to .sourceatlas/overview.yaml`\n\n‚Üí See [reference.md#auto-save](reference.md#auto-save-behavior) for details\n\n---\n\n## Advanced\n\n- **Scale-aware analysis**: [reference.md#scale-aware-analysis](reference.md#scale-aware-analysis)\n- **Helper scripts**: [reference.md#helper-scripts](reference.md#helper-scripts)\n- **Cache behavior**: [reference.md#cache-behavior](reference.md#cache-behavior)\n- **AI collaboration detection**: [reference.md#ai-collaboration-detection](reference.md#ai-collaboration-detection)\n- **Information theory**: [reference.md#information-theory-principles](reference.md#information-theory-principles)\n\n---\n\n## Output Header\n\nStart your output with:\n\n```markdown\nüó∫Ô∏è SourceAtlas: Overview\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüî≠ [project_name] ‚îÇ [SCALE] ([file count] files)\n```\n\nThen follow YAML structure in [output-template.md](output-template.md).\n",
        "plugin/commands/overview/output-template.md": "# Overview Output Template\n\nComplete YAML format specification for Stage 0 fingerprint analysis.\n\n---\n\n## Header Format\n\n```markdown\nüó∫Ô∏è SourceAtlas: Overview\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüî≠ [project_name] ‚îÇ [SCALE] ([file count] files)\n```\n\n**Example:**\n```markdown\nüó∫Ô∏è SourceAtlas: Overview\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüî≠ sourceatlas2 ‚îÇ LARGE (127 files)\n```\n\n---\n\n## YAML Structure\n\nComplete YAML output with all sections:\n\n```yaml\nmetadata:\n  project_name: \"[detected name]\"\n  scan_time: \"[ISO 8601 timestamp]\"\n  target_path: \"${ARGUMENTS:-.}\"\n  total_files: [actual count after exclusions]\n  scanned_files: [files read]\n  scan_ratio: \"[percentage]\"\n  project_scale: \"[TINY|SMALL|MEDIUM|LARGE|VERY_LARGE]\"\n  constitution_version: \"1.1\"\n  # Branch-Aware Context (v2.8.2)\n  context:\n    git_branch: \"[branch name or null]\"\n    relative_path: \"[path within repo or null]\"\n    package_name: \"[detected package name or null]\"\n\nproject_fingerprint:\n  project_type: \"[WEB_APP|CLI|LIBRARY|MOBILE_APP|MICROSERVICE|MONOREPO]\"\n  scale: \"[TINY|SMALL|MEDIUM|LARGE|VERY_LARGE]\"\n  # TINY: <500 LOC, SMALL: 500-2k, MEDIUM: 2k-10k, LARGE: 10k-50k, VERY_LARGE: >50k\n  primary_language: \"[language + version]\"\n  framework: \"[framework + version]\"\n  architecture: \"[pattern name]\"\n\ntech_stack:\n  backend:\n    language: \"[name + version]\"\n    framework: \"[name + version]\"\n    database: \"[name + version]\"\n\n  frontend:  # if applicable\n    language: \"[name]\"\n    framework: \"[name]\"\n\n  infrastructure:  # if applicable\n    containerization: \"[Docker/none]\"\n    orchestration: \"[K8s/none]\"\n\nhypotheses:\n  architecture:\n    - hypothesis: \"[architectural pattern description]\"\n      confidence: 0.0-1.0\n      evidence: \"[file:line references]\"\n      validation_method: \"[how to verify]\"\n\n  tech_stack:\n    - hypothesis: \"[technology decision]\"\n      confidence: 0.0-1.0\n      evidence: \"[file:line references]\"\n      validation_method: \"[how to verify]\"\n\n  development:\n    - hypothesis: \"[development practice]\"\n      confidence: 0.0-1.0\n      evidence: \"[file:line references]\"\n      validation_method: \"[how to verify]\"\n\n  ai_collaboration:\n    level: 0-4\n    confidence: 0.0-1.0\n    tools_detected:\n      - tool: \"[tool name]\"\n        config_file: \"[file path]\"\n        content_quality: \"[minimal|basic|comprehensive]\"\n    indicators:\n      - \"[indicator 1]\"\n      - \"[indicator 2]\"\n    # Level interpretation:\n    # 0: No AI (no config files, 5-8% comments)\n    # 1: Occasional (1 config, minimal content)\n    # 2: Frequent (1-2 configs + indirect indicators)\n    # 3: Systematic (complete config + high comments + consistent style)\n    # 4: Ecosystem (multiple tools/AGENTS.md + team standards)\n\n  business:\n    - hypothesis: \"[business domain insight]\"\n      confidence: 0.0-1.0\n      evidence: \"[file:line references]\"\n      validation_method: \"[how to verify]\"\n\nscanned_files:\n  - file: \"[path/to/file]\"\n    reason: \"[why scanned]\"\n    key_insight: \"[main learning]\"\n\nsummary:\n  understanding_depth: \"[70-80%]\"\n  key_findings:\n    - \"[finding 1]\"\n    - \"[finding 2]\"\n    - \"[finding 3]\"\n```\n\n---\n\n## Section Specifications\n\n### Section 1: metadata\n\n**Required Fields:**\n\n| Field | Type | Example | Notes |\n|-------|------|---------|-------|\n| project_name | string | \"sourceatlas2\" | From package.json, pyproject.toml, or directory name |\n| scan_time | ISO 8601 | \"2025-01-14T10:30:00Z\" | UTC timestamp |\n| target_path | string | \".\" or \"src/api\" | From $ARGUMENTS, default \".\" |\n| total_files | integer | 127 | After exclusions (no .venv, node_modules) |\n| scanned_files | integer | 8 | Actual files read |\n| scan_ratio | string | \"6.3%\" | (scanned_files / total_files * 100) |\n| project_scale | enum | \"LARGE\" | TINY/SMALL/MEDIUM/LARGE/VERY_LARGE |\n| constitution_version | string | \"1.1\" | Current version |\n\n**Context Subfields** (v2.8.2):\n\n| Field | Type | Example | Notes |\n|-------|------|---------|-------|\n| git_branch | string or null | \"main\" | Current branch, null if not git repo |\n| relative_path | string or null | \"packages/api\" | Path within monorepo, null if root |\n| package_name | string or null | \"@org/api\" | From package.json name field |\n\n**Example:**\n```yaml\nmetadata:\n  project_name: \"sourceatlas2\"\n  scan_time: \"2025-01-14T10:30:00Z\"\n  target_path: \".\"\n  total_files: 127\n  scanned_files: 8\n  scan_ratio: \"6.3%\"\n  project_scale: \"LARGE\"\n  constitution_version: \"1.1\"\n  context:\n    git_branch: \"main\"\n    relative_path: null\n    package_name: \"@sourceatlas/plugin\"\n```\n\n### Section 2: project_fingerprint\n\nHigh-level project classification.\n\n**Fields:**\n\n| Field | Type | Values | Example |\n|-------|------|--------|---------|\n| project_type | enum | WEB_APP, CLI, LIBRARY, MOBILE_APP, MICROSERVICE, MONOREPO | \"CLI\" |\n| scale | enum | TINY, SMALL, MEDIUM, LARGE, VERY_LARGE | \"LARGE\" |\n| primary_language | string | Include version | \"TypeScript 5.3\" |\n| framework | string | Include version | \"None (vanilla TS)\" |\n| architecture | string | Pattern name | \"Modular CLI with plugins\" |\n\n**Scale Definitions:**\n- **TINY**: <500 LOC\n- **SMALL**: 500-2k LOC\n- **MEDIUM**: 2k-10k LOC\n- **LARGE**: 10k-50k LOC\n- **VERY_LARGE**: >50k LOC\n\n**Example:**\n```yaml\nproject_fingerprint:\n  project_type: \"CLI\"\n  scale: \"LARGE\"\n  primary_language: \"TypeScript 5.3\"\n  framework: \"None (vanilla TS)\"\n  architecture: \"Modular CLI with plugins\"\n```\n\n### Section 3: tech_stack\n\nTechnology stack breakdown.\n\n**Structure:**\n- `backend`: Always present\n- `frontend`: Optional (web apps, mobile apps)\n- `infrastructure`: Optional (Docker, K8s)\n\n**Example (Backend-Only):**\n```yaml\ntech_stack:\n  backend:\n    language: \"Python 3.11\"\n    framework: \"FastAPI 0.104\"\n    database: \"PostgreSQL 15\"\n```\n\n**Example (Full Stack):**\n```yaml\ntech_stack:\n  backend:\n    language: \"Node.js 20\"\n    framework: \"Express 4.18\"\n    database: \"MongoDB 7.0\"\n\n  frontend:\n    language: \"TypeScript\"\n    framework: \"React 18.2\"\n\n  infrastructure:\n    containerization: \"Docker 24.0\"\n    orchestration: \"Kubernetes 1.28\"\n```\n\n### Section 4: hypotheses\n\nScale-appropriate hypotheses with evidence.\n\n**Subsections:**\n- `architecture`: 2-4 hypotheses\n- `tech_stack`: 2-4 hypotheses\n- `development`: 2-4 hypotheses\n- `ai_collaboration`: 1 hypothesis (special structure)\n- `business`: 1-3 hypotheses\n\n**Hypothesis Structure:**\n```yaml\n- hypothesis: \"[clear, specific statement]\"\n  confidence: 0.0-1.0  # aim for >0.7\n  evidence: \"[file:line references]\"\n  validation_method: \"[how to verify in Stage 1]\"\n```\n\n**Example (architecture):**\n```yaml\nhypotheses:\n  architecture:\n    - hypothesis: \"3-layer architecture: Controller ‚Üí Service ‚Üí Repository\"\n      confidence: 0.85\n      evidence: \"src/controllers/, src/services/, src/repositories/ directories exist\"\n      validation_method: \"trace UserController.ts flow to UserService.ts to UserRepository.ts\"\n\n    - hypothesis: \"Dependency injection via constructor parameters\"\n      confidence: 0.90\n      evidence: \"src/controllers/UserController.ts:15-20, src/services/UserService.ts:10-12\"\n      validation_method: \"grep 'constructor.*private' src/**/*.ts\"\n```\n\n**Example (tech_stack):**\n```yaml\n  tech_stack:\n    - hypothesis: \"Express.js 4.18 with TypeScript for REST API\"\n      confidence: 0.95\n      evidence: \"package.json:12, src/app.ts:1-5\"\n      validation_method: \"grep 'express' package.json; check tsconfig.json\"\n\n    - hypothesis: \"Sequelize ORM for PostgreSQL database access\"\n      confidence: 0.80\n      evidence: \"package.json:18, src/config/database.ts:5-10\"\n      validation_method: \"check models/ directory for Sequelize model definitions\"\n```\n\n**Example (development):**\n```yaml\n  development:\n    - hypothesis: \"Jest + Supertest for API integration testing\"\n      confidence: 0.85\n      evidence: \"package.json:25, tests/api/users.test.ts:1-20\"\n      validation_method: \"run npm test -- --coverage\"\n\n    - hypothesis: \"ESLint + Prettier for code quality enforcement\"\n      confidence: 0.90\n      evidence: \".eslintrc.json, .prettierrc.json exist\"\n      validation_method: \"run npm run lint\"\n```\n\n**Example (ai_collaboration - Special Structure):**\n```yaml\n  ai_collaboration:\n    level: 3\n    confidence: 0.90\n    tools_detected:\n      - tool: \"Claude Code\"\n        config_file: \"CLAUDE.md\"\n        content_quality: \"comprehensive\"\n      - tool: \"Cursor\"\n        config_file: \".cursorrules\"\n        content_quality: \"basic\"\n    indicators:\n      - \"High comment density (18% vs typical 5-8%)\"\n      - \"Consistent code style across all files\"\n      - \"Comprehensive inline documentation\"\n      - \"Conventional Commits with AI tool signatures\"\n```\n\n**AI Collaboration Levels:**\n- **Level 0**: No AI detection\n- **Level 1**: 1 tool config, minimal content\n- **Level 2**: 1-2 tool configs + some indirect indicators\n- **Level 3**: Complete AI config + high comment density + consistent style\n- **Level 4**: Multiple tools (Ruler/.ruler/) or AGENTS.md + team standards\n\n**Content Quality:**\n- **minimal**: <5 lines, basic instructions\n- **basic**: 5-50 lines, clear guidance\n- **comprehensive**: >50 lines, detailed guidelines, examples\n\n**Example (business):**\n```yaml\n  business:\n    - hypothesis: \"E-commerce platform with user, product, order management\"\n      confidence: 0.80\n      evidence: \"README.md:15-30, models/User.ts, models/Product.ts, models/Order.ts\"\n      validation_method: \"review core entity relationships in models/\"\n\n    - hypothesis: \"Multi-tenant SaaS with organization-level isolation\"\n      confidence: 0.70\n      evidence: \"models/Organization.ts:5-10, middleware/tenantIsolation.ts:15-30\"\n      validation_method: \"trace request flow through tenant middleware\"\n```\n\n### Section 5: scanned_files\n\nList of files scanned with reasons and insights.\n\n**Structure:**\n```yaml\nscanned_files:\n  - file: \"[path]\"\n    reason: \"[why scanned - entropy category]\"\n    key_insight: \"[main learning]\"\n```\n\n**Example:**\n```yaml\nscanned_files:\n  - file: \"README.md\"\n    reason: \"Documentation (highest entropy)\"\n    key_insight: \"CLI tool for codebase analysis using information theory\"\n\n  - file: \"package.json\"\n    reason: \"Configuration (project-level decisions)\"\n    key_insight: \"TypeScript project with 15 dependencies, targets Node.js 18+\"\n\n  - file: \"CLAUDE.md\"\n    reason: \"AI collaboration detection\"\n    key_insight: \"Comprehensive Claude Code configuration, Level 3 collaboration\"\n\n  - file: \"src/commands/overview/SKILL.md\"\n    reason: \"Core model (data structure)\"\n    key_insight: \"Stage 0 fingerprint command with scale-aware analysis\"\n\n  - file: \"src/app.ts\"\n    reason: \"Entry point (architecture pattern)\"\n    key_insight: \"Plugin-based architecture, modular command system\"\n\n  - file: \"tests/integration/overview.test.ts\"\n    reason: \"Testing (development practices)\"\n    key_insight: \"Jest integration tests with real project fixtures\"\n```\n\n### Section 6: summary\n\nHigh-level summary with key findings.\n\n**Fields:**\n\n| Field | Type | Example | Notes |\n|-------|------|---------|-------|\n| understanding_depth | string | \"75%\" | Target: 70-80% |\n| key_findings | array | [3-5 findings] | Most important discoveries |\n\n**Example:**\n```yaml\nsummary:\n  understanding_depth: \"75%\"\n  key_findings:\n    - \"TypeScript CLI tool for codebase analysis\"\n    - \"Modular plugin architecture with 5 analysis commands\"\n    - \"Information theory-based approach (scan <5% for 70-80% understanding)\"\n    - \"Level 3 AI collaboration with comprehensive CLAUDE.md\"\n    - \"Constitutional compliance v1.1 with mandatory exclusions\"\n```\n\n---\n\n## Recommended Next Section\n\n**Decision Logic:** Choose ONE of these outputs, NOT both.\n\n### Case A: End Condition (No Table)\n\nWhen any of these conditions are met:\n- Project too small: TINY (<10 files)\n- Findings too vague: Cannot provide high confidence (>0.7) parameters\n- Goal achieved: AI collaboration Level ‚â•3 and scale TINY/SMALL\n\n**Output:**\n```markdown\n‚úÖ **Analysis sufficient** - Project is small, can read all files directly to start development\n```\n\n### Case B: Suggestions (Table Output)\n\nWhen project scale is large enough or there are clear next steps:\n\n**Format:**\n```markdown\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"[pattern name]\"` | [reason based on findings] |\n| 2 | `/sourceatlas:flow \"[entry point]\"` | [reason based on findings] |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n```\n\n**Suggestion Rules:**\n\n| Finding | Suggested Command | Parameter Source |\n|---------|-------------------|------------------|\n| Clear design patterns | `/sourceatlas:pattern` | Discovered pattern name |\n| Complex architecture (multi-layer/microservices) | `/sourceatlas:flow` | Main entry point file |\n| Scale ‚â• LARGE | `/sourceatlas:history` | No parameters needed |\n| High risk areas | `/sourceatlas:impact` | Risk file/module name |\n\n**Requirements:**\n- **Specific parameters**: Use actual names from analysis (e.g., `\"repository\"` not `\"related pattern\"`)\n- **Quantity limit**: 1-2 suggestions, don't force fill\n- **Purpose column**: Reference specific findings (numbers, file names)\n\n**Example (Good):**\n```markdown\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"repository pattern\"` | Found Repository pattern used in 15 files |\n| 2 | `/sourceatlas:flow \"src/app.ts\"` | Trace 3-layer architecture execution flow |\n```\n\n**Example (Bad - Too Generic):**\n```markdown\n| 1 | `/sourceatlas:pattern \"some pattern\"` | Learn more patterns |\n```\n\n---\n\n## Footer Format\n\n```markdown\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1\n```\n\n---\n\n## Complete Example\n\n```markdown\nüó∫Ô∏è SourceAtlas: Overview\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüî≠ express-api ‚îÇ MEDIUM (42 files)\n\n```yaml\nmetadata:\n  project_name: \"express-api\"\n  scan_time: \"2025-01-14T10:30:00Z\"\n  target_path: \".\"\n  total_files: 42\n  scanned_files: 5\n  scan_ratio: \"11.9%\"\n  project_scale: \"MEDIUM\"\n  constitution_version: \"1.1\"\n  context:\n    git_branch: \"main\"\n    relative_path: null\n    package_name: \"@company/express-api\"\n\nproject_fingerprint:\n  project_type: \"WEB_APP\"\n  scale: \"MEDIUM\"\n  primary_language: \"TypeScript 5.3\"\n  framework: \"Express.js 4.18\"\n  architecture: \"3-layer MVC (Controller-Service-Repository)\"\n\ntech_stack:\n  backend:\n    language: \"TypeScript 5.3\"\n    framework: \"Express 4.18\"\n    database: \"PostgreSQL 15\"\n\n  infrastructure:\n    containerization: \"Docker 24.0\"\n    orchestration: \"none\"\n\nhypotheses:\n  architecture:\n    - hypothesis: \"3-layer architecture: Controller ‚Üí Service ‚Üí Repository\"\n      confidence: 0.85\n      evidence: \"src/controllers/, src/services/, src/repositories/ exist\"\n      validation_method: \"trace UserController.ts flow\"\n\n    - hypothesis: \"RESTful API design with route-based organization\"\n      confidence: 0.90\n      evidence: \"src/routes/users.ts:1-20, routes follow REST conventions\"\n      validation_method: \"check all routes/*.ts files\"\n\n  tech_stack:\n    - hypothesis: \"Express.js 4.18 with TypeScript for type safety\"\n      confidence: 0.95\n      evidence: \"package.json:12, tsconfig.json:5-10\"\n      validation_method: \"grep 'express' package.json\"\n\n    - hypothesis: \"Sequelize ORM for PostgreSQL access\"\n      confidence: 0.80\n      evidence: \"package.json:18, src/config/database.ts:5-10\"\n      validation_method: \"check models/ for Sequelize definitions\"\n\n  development:\n    - hypothesis: \"Jest + Supertest for API testing, likely >70% coverage\"\n      confidence: 0.75\n      evidence: \"package.json:25, tests/api/users.test.ts:1-20\"\n      validation_method: \"run npm test -- --coverage\"\n\n    - hypothesis: \"ESLint + Prettier enforce code quality\"\n      confidence: 0.90\n      evidence: \".eslintrc.json, .prettierrc.json exist\"\n      validation_method: \"run npm run lint\"\n\n  ai_collaboration:\n    level: 2\n    confidence: 0.80\n    tools_detected:\n      - tool: \"Claude Code\"\n        config_file: \"CLAUDE.md\"\n        content_quality: \"basic\"\n    indicators:\n      - \"High comment density (12% vs typical 5-8%)\"\n      - \"Consistent code style\"\n\n  business:\n    - hypothesis: \"User management API with authentication/authorization\"\n      confidence: 0.80\n      evidence: \"README.md:15-30, models/User.ts, routes/auth.ts\"\n      validation_method: \"review auth flow in middleware/auth.ts\"\n\nscanned_files:\n  - file: \"README.md\"\n    reason: \"Documentation (highest entropy)\"\n    key_insight: \"REST API for user management with JWT auth\"\n\n  - file: \"package.json\"\n    reason: \"Configuration (project-level decisions)\"\n    key_insight: \"Express + TypeScript + Sequelize stack\"\n\n  - file: \"CLAUDE.md\"\n    reason: \"AI collaboration detection\"\n    key_insight: \"Basic Claude Code config, Level 2 collaboration\"\n\n  - file: \"src/controllers/UserController.ts\"\n    reason: \"Entry point (architecture pattern)\"\n    key_insight: \"Controller calls UserService, follows 3-layer pattern\"\n\n  - file: \"tests/api/users.test.ts\"\n    reason: \"Testing (development practices)\"\n    key_insight: \"Jest + Supertest for API integration tests\"\n\nsummary:\n  understanding_depth: \"75%\"\n  key_findings:\n    - \"Express.js REST API with 3-layer architecture\"\n    - \"TypeScript + Sequelize for type-safe database access\"\n    - \"JWT-based authentication with role-based authorization\"\n    - \"Level 2 AI collaboration (Claude Code, basic config)\"\n    - \"Good test coverage with Jest + Supertest\"\n\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"repository pattern\"` | Found Repository pattern in 8 files |\n| 2 | `/sourceatlas:flow \"src/routes/users.ts\"` | Trace 3-layer flow from route to database |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1\n```\n",
        "plugin/commands/overview/reference.md": "# Overview Reference Guide\n\nAdvanced features, scale-aware analysis, helper scripts, and best practices.\n\n---\n\n## Scale-Aware Analysis\n\n### Scale Definitions\n\n| Scale | File Count | LOC Range | Scan Limit | Hypothesis Target |\n|-------|------------|-----------|------------|-------------------|\n| **TINY** | <5 | <500 | 1-2 files (50% max) | 5-8 hypotheses |\n| **SMALL** | 5-15 | 500-2K | 2-3 files (10-20%) | 7-10 hypotheses |\n| **MEDIUM** | 15-50 | 2K-10K | 4-6 files (8-12%) | 10-15 hypotheses |\n| **LARGE** | 50-150 | 10K-50K | 6-10 files (4-7%) | 12-18 hypotheses |\n| **VERY_LARGE** | >150 | >50K | 10-15 files (3-7%) | 15-20 hypotheses |\n\n### Why Scale-Aware?\n\n**Problem:** Fixed 5% scan ratio doesn't work for all sizes\n- TINY projects: 5% of 4 files = 0 files (unusable)\n- VERY_LARGE projects: 5% of 1000 files = 50 files (wasteful)\n\n**Solution:** Adaptive scan limits\n- TINY: Higher ratio (50%) because each file matters\n- VERY_LARGE: Lower ratio (3-7%) because diminishing returns\n\n### Scale Detection Logic\n\n```bash\n# Count code files (excluding dependencies)\nFILE_COUNT=$(find . -type f \\\n    \\( -name \"*.py\" -o -name \"*.js\" -o -name \"*.ts\" -o -name \"*.swift\" -o -name \"*.kt\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -not -path \"*/vendor/*\" \\\n    -not -path \"*/__pycache__/*\" \\\n    2>/dev/null | wc -l | tr -d ' ')\n\n# Determine scale\nif [ $FILE_COUNT -lt 5 ]; then\n    SCALE=\"TINY\"\n    SCAN_LIMIT=\"1-2 files\"\nelif [ $FILE_COUNT -lt 15 ]; then\n    SCALE=\"SMALL\"\n    SCAN_LIMIT=\"2-3 files\"\nelif [ $FILE_COUNT -lt 50 ]; then\n    SCALE=\"MEDIUM\"\n    SCAN_LIMIT=\"4-6 files\"\nelif [ $FILE_COUNT -lt 150 ]; then\n    SCALE=\"LARGE\"\n    SCAN_LIMIT=\"6-10 files\"\nelse\n    SCALE=\"VERY_LARGE\"\n    SCAN_LIMIT=\"10-15 files\"\nfi\n```\n\n---\n\n## Helper Scripts\n\n### detect-project.sh\n\n**Location:**\n- Global: `~/.claude/scripts/atlas/detect-project.sh`\n- Local: `scripts/atlas/detect-project.sh`\n\n**Purpose:** Comprehensive project detection and scale analysis\n\n**Output:**\n```\nProject Type: WEB_APP\nPrimary Language: TypeScript\nFramework: Express.js 4.18\nFile Count: 127 (after exclusions)\nScale: LARGE\nRecommended Scan: 6-10 files (4-7%)\nHypothesis Target: 12-18 hypotheses\n\nContext:\n- Git Branch: main\n- Package Name: @company/api\n- Relative Path: (root)\n```\n\n**Usage:**\n```bash\nbash ~/.claude/scripts/atlas/detect-project.sh .\nbash ~/.claude/scripts/atlas/detect-project.sh src/api  # subdirectory\n```\n\n---\n\n### scan-entropy.sh\n\n**Location:**\n- Global: `~/.claude/scripts/atlas/scan-entropy.sh`\n- Local: `scripts/atlas/scan-entropy.sh`\n\n**Purpose:** Execute high-entropy file prioritization\n\n**Output:**\n```\n=== High-Entropy Files (Priority Order) ===\n\n[1] Documentation:\n- README.md\n- CLAUDE.md\n- docs/architecture.md\n\n[2] Configuration:\n- package.json\n- tsconfig.json\n- docker-compose.yml\n\n[3] Models (top 3):\n- src/models/User.ts\n- src/models/Product.ts\n- src/models/Order.ts\n\n[4] Entry Points (top 2):\n- src/app.ts\n- src/routes/index.ts\n\n[5] Tests (top 2):\n- tests/integration/api.test.ts\n- tests/unit/services/user.test.ts\n```\n\n**Usage:**\n```bash\nbash ~/.claude/scripts/atlas/scan-entropy.sh .\n```\n\n---\n\n### detect-ai-tools.sh\n\n**Location:**\n- Global: `~/.claude/scripts/atlas/detect-ai-tools.sh`\n- Local: `scripts/atlas/detect-ai-tools.sh`\n\n**Purpose:** Detect AI tool configurations (Tier 1 + Tier 2)\n\n**Output:**\n```\n=== AI Tool Detection ===\n\nTier 1 (Tool-Specific Config Files):\n‚úÖ Claude Code: CLAUDE.md (+0.30)\n‚úÖ Cursor: .cursorrules (+0.25)\n‚ùå Windsurf: not found\n‚ùå GitHub Copilot: not found\n‚úÖ AGENTS.md: AGENTS.md (+0.20)\n\nTier 2 (Indirect Indicators):\n- Comment density: 18% (vs typical 5-8%) ‚úÖ\n- Code consistency: 95% (>98% threshold) ‚ùå\n- Conventional Commits: 100% ‚úÖ\n\nAI Collaboration Level: 3\nConfidence: 0.85\n```\n\n**Tier 1 Tools Detected:**\n\n| Tool | Config Files | Boost |\n|------|--------------|-------|\n| Claude Code | `CLAUDE.md`, `.claude/` | +0.30 |\n| Cursor | `.cursorrules`, `.cursor/rules/*.mdc` | +0.25 |\n| Windsurf | `.windsurfrules`, `.windsurf/rules/` | +0.25 |\n| GitHub Copilot | `.github/copilot-instructions.md`, `**/.instructions.md` | +0.20 |\n| Cline/Roo | `.clinerules`, `.clinerules/`, `.roo/` | +0.25 |\n| Aider | `CONVENTIONS.md`, `.aider.conf.yml`, `.aider.input.history` | +0.25 |\n| Continue.dev | `.continuerules`, `.continue/rules/` | +0.25 |\n| JetBrains AI | `.aiignore` | +0.20 |\n| AGENTS.md | `AGENTS.md` | +0.20 |\n| Sourcegraph Cody | `.vscode/cody.json` | +0.15 |\n| Replit | `replit.nix` + `.replit` | +0.15 |\n| Ruler | `.ruler/` | +0.20 |\n\n**Usage:**\n```bash\nbash ~/.claude/scripts/atlas/detect-ai-tools.sh .\n```\n\n---\n\n## Cache Behavior\n\n### Cache Location\n\n**Root analysis:**\n```\n.sourceatlas/overview.yaml\n```\n\n**Subdirectory analysis:**\n```\n# For: /sourceatlas:overview \"src/api\"\n.sourceatlas/overview-src-api.yaml\n\n# For: /sourceatlas:overview \"packages/backend\"\n.sourceatlas/overview-packages-backend.yaml\n```\n\n**Naming rule:** Replace `/` with `-`, lowercase\n\n### Cache Check Logic\n\n```bash\n# Parse arguments\nif echo \"$ARGUMENTS\" | grep -q \"\\-\\-force\"; then\n    echo \"‚ö†Ô∏è --force flag detected, skipping cache\"\n    # Skip cache, execute analysis\nelse\n    # Calculate cache file name\n    if [ \"$ARGUMENTS\" = \".\" ] || [ -z \"$ARGUMENTS\" ]; then\n        CACHE_FILE=\".sourceatlas/overview.yaml\"\n    else\n        # Convert path to cache name\n        CACHE_NAME=$(echo \"$ARGUMENTS\" | tr '/' '-' | tr '[:upper:]' '[:lower:]')\n        CACHE_FILE=\".sourceatlas/overview-${CACHE_NAME}.yaml\"\n    fi\n\n    # Check if cache exists\n    if [ -f \"$CACHE_FILE\" ]; then\n        # Get modification time\n        MTIME=$(stat -f \"%Sm\" -t \"%Y-%m-%d\" \"$CACHE_FILE\" 2>/dev/null || stat -c \"%y\" \"$CACHE_FILE\" 2>/dev/null | cut -d' ' -f1)\n\n        # Calculate age\n        AGE_DAYS=$(( ($(date +%s) - $(date -j -f \"%Y-%m-%d\" \"$MTIME\" +%s 2>/dev/null || date -d \"$MTIME\" +%s 2>/dev/null)) / 86400 ))\n\n        echo \"üìÅ Loading cache: $CACHE_FILE ($AGE_DAYS days ago)\"\n        echo \"üí° Add --force to re-analyze\"\n\n        if [ $AGE_DAYS -gt 30 ]; then\n            echo \"‚ö†Ô∏è Cache is over 30 days old, recommend re-analysis\"\n        fi\n\n        # Output cache content\n        cat \"$CACHE_FILE\"\n        exit 0\n    fi\nfi\n```\n\n### Cache Age Warning\n\n- **<30 days**: No warning\n- **>30 days**: Show warning\n- **>90 days**: Strong warning\n\n**Rationale:** Projects evolve, old fingerprints may be stale.\n\n---\n\n## Auto-Save Behavior\n\n### Save Timing\n\nAuto-save occurs **after V4 verification passes**:\n\n```\nPhase 1 ‚Üí Phase 2 ‚Üí Phase 3 ‚Üí Generate YAML ‚Üí V1-V4 Verification ‚Üí Auto-Save\n```\n\n### Save Location\n\n```bash\nmkdir -p .sourceatlas\n\n# Root analysis\nSAVE_PATH=\".sourceatlas/overview.yaml\"\n\n# Subdirectory analysis (e.g., \"src/api\")\nSAVE_PATH=\".sourceatlas/overview-src-api.yaml\"\n```\n\n### Confirmation Message\n\n```\nüíæ Saved to .sourceatlas/overview.yaml\n```\n\n---\n\n## Handoffs Decision Rules\n\n> Follow **Constitution Article VII: Handoffs Principles**\n\n### Decision Logic\n\n**Choose ONE of these outputs, NOT both:**\n\n#### Case A: End Condition (No Table)\n\nWhen **any** of these are true:\n- Project too small: TINY (<10 files) can be read directly\n- Findings too vague: Cannot provide high confidence (>0.7) specific parameters\n- Goal achieved: AI collaboration Level ‚â•3 and scale TINY/SMALL (can start development)\n\n**Output:**\n```markdown\n‚úÖ **Analysis sufficient** - Project is small, can read all files directly to start development\n```\n\n#### Case B: Suggestions (Table Output)\n\nWhen project scale is large enough or there are clear next steps.\n\n**Suggestion Selection:**\n\n| Finding | Command | Parameter Source |\n|---------|---------|------------------|\n| Clear design patterns | `/sourceatlas:pattern` | Discovered pattern name |\n| Complex architecture (multi-layer/microservices) | `/sourceatlas:flow` | Main entry point file |\n| Scale ‚â• LARGE | `/sourceatlas:history` | No parameters |\n| High risk areas | `/sourceatlas:impact` | Risk file/module name |\n\n**Output Format:**\n```markdown\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"repository pattern\"` | Found Repository pattern used in 15 files |\n| 2 | `/sourceatlas:flow \"src/app.ts\"` | Trace 3-layer architecture flow |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n```\n\n**Quality Requirements:**\n- **Specific parameters**: Use actual discovered names (e.g., `\"repository pattern\"` not `\"some pattern\"`)\n- **Quantity limit**: 1-2 suggestions max, don't force fill\n- **Purpose column**: Reference specific findings (numbers, file names)\n\n---\n\n## Information Theory Principles\n\n### High-Entropy Files\n\n**Entropy** = Information density = How much you learn per line read\n\n**Ranking (highest to lowest):**\n\n1. **Documentation** (README, ARCHITECTURE docs)\n   - Entropy: ~10 bits/line\n   - Why: Summarizes entire project purpose, architecture, usage\n\n2. **Configuration** (package.json, docker-compose.yml)\n   - Entropy: ~8 bits/line\n   - Why: Technology stack decisions in one place\n\n3. **Models/Entities** (User.ts, Product.ts)\n   - Entropy: ~6 bits/line\n   - Why: Data structure defines business domain\n\n4. **Entry Points** (app.ts, routes/index.ts)\n   - Entropy: ~5 bits/line\n   - Why: Architecture patterns visible\n\n5. **Tests** (user.test.ts)\n   - Entropy: ~4 bits/line\n   - Why: Development practices visible\n\n6. **Implementation** (services, controllers)\n   - Entropy: ~2 bits/line\n   - Why: Details, not structure\n\n**Strategy:** Read top 3 categories, sample categories 4-5.\n\n---\n\n## AI Collaboration Detection\n\n### Level Definitions\n\n| Level | Criteria | Examples |\n|-------|----------|----------|\n| **0: No AI** | No config files, 5-8% comments, inconsistent style | Manual development |\n| **1: Occasional** | 1 tool config with minimal content | Experimenting with AI |\n| **2: Frequent** | 1-2 tool configs + some indirect indicators | Regular AI usage |\n| **3: Systematic** | Complete AI config + high comments + consistent style | Mature AI workflow |\n| **4: Ecosystem** | Multiple tools (Ruler) or AGENTS.md + team standards | Organization-wide |\n\n### Content Quality Assessment\n\nWhen config file is found, assess quality:\n\n**Minimal (<5 lines):**\n```markdown\n# .cursorrules\nUse TypeScript\nFollow ESLint rules\n```\n\n**Basic (5-50 lines):**\n```markdown\n# CLAUDE.md\n## Project Overview\nThis is an Express API for user management.\n\n## Code Style\n- Use TypeScript\n- Follow 3-layer architecture\n- Write tests for all endpoints\n```\n\n**Comprehensive (>50 lines):**\n```markdown\n# CLAUDE.md (full structure)\n## What is this project\n[Detailed explanation]\n\n## Key Files\n[File-by-file breakdown]\n\n## Must Follow\n[Detailed guidelines]\n\n## Development Workflow\n[Step-by-step instructions]\n```\n\n**Scoring:**\n- minimal ‚Üí confidence: 0.5-0.6\n- basic ‚Üí confidence: 0.7-0.8\n- comprehensive ‚Üí confidence: 0.9-1.0\n\n---\n\n## Best Practices\n\n### For Different Project Sizes\n\n**TINY projects (<5 files):**\n- Read ALL files if possible\n- Focus on purpose and usage\n- Simple hypotheses (5-8)\n\n**SMALL projects (5-15 files):**\n- Read docs + config + 1-2 models\n- Focus on architecture pattern\n- Moderate hypotheses (7-10)\n\n**MEDIUM projects (15-50 files):**\n- Standard entropy-based scanning\n- Focus on patterns and conventions\n- Balanced hypotheses (10-15)\n\n**LARGE projects (50-150 files):**\n- Strict entropy prioritization\n- Focus on high-level architecture\n- Comprehensive hypotheses (12-18)\n\n**VERY_LARGE projects (>150 files):**\n- Maximum efficiency required\n- Focus on fingerprint only, not details\n- Extensive hypotheses (15-20)\n\n---\n\n## Integration with Other Commands\n\nAfter overview fingerprint, consider:\n\n| Finding | Next Command | Reason |\n|---------|--------------|--------|\n| Clear patterns mentioned | `/sourceatlas:pattern` | Learn implementation |\n| Complex architecture | `/sourceatlas:flow` | Trace execution |\n| Large codebase | `/sourceatlas:history` | Find hotspots |\n| High-risk areas identified | `/sourceatlas:impact` | Assess change impact |\n\n---\n\n## Deprecated Features\n\n### --save flag (v2.8.0)\n\nAuto-save is now default behavior.\n\n**If user provides `--save`:**\n```bash\nif echo \"$ARGUMENTS\" | grep -q \"\\-\\-save\"; then\n    echo \"‚ö†Ô∏è --save is deprecated, auto-save is now default\"\n    # Remove --save from arguments\n    ARGUMENTS=$(echo \"$ARGUMENTS\" | sed 's/--save//g')\n    # Continue normal execution (still auto-saves)\nfi\n```\n\n---\n\n## Troubleshooting\n\n### Issue 1: Helper Scripts Not Found\n\n**Symptom:** Scripts not in ~/.claude/scripts/atlas/ or scripts/atlas/\n\n**Solution:**\n- Use manual fallback commands provided in workflow.md\n- All core functionality works without scripts\n- Scripts are optimization only\n\n### Issue 2: File Count Varies\n\n**Symptom:** Different counts on different runs\n\n**Solution:**\n- Normal if files are created/deleted between runs\n- Use same exclusions in verification\n- ¬±10% variance acceptable\n\n### Issue 3: Git Commands Fail\n\n**Symptom:** Not a git repository\n\n**Solution:**\n- Set `context.git_branch: null`\n- Set `context.relative_path: null`\n- Continue analysis without git context\n\n### Issue 4: Too Many/Few Hypotheses\n\n**Symptom:** Generated hypotheses don't match scale targets\n\n**Solution:**\n- Use scale targets as guidelines, not strict limits\n- Quality > quantity\n- Each hypothesis must have >0.7 confidence\n\n---\n\n## Version History\n\n- **v2.12.0**: Current version with Constitution v1.1\n- **v2.8.2**: Added branch-aware context\n- **v2.8.0**: Auto-save default, deprecated --save flag\n- **v2.5.0**: Added scale-aware analysis\n- **v2.0.0**: YAML output format\n",
        "plugin/commands/overview/verification-guide.md": "# Overview Self-Verification Guide\n\nComplete verification checklist for Stage 0 fingerprint analysis.\n\n---\n\n## When to Verify\n\nExecute **after generating YAML output, before saving** to `.sourceatlas/overview.yaml`.\n\n---\n\n## Purpose\n\nPrevent hallucinated file paths, incorrect counts, and fictional configurations from appearing in output.\n\n---\n\n## Verification Steps\n\n### Step V1: Extract Verifiable Claims\n\nAfter generating the YAML output, extract all verifiable claims.\n\n**Claim Types to Extract:**\n\n| Type | YAML Path | Verification Method |\n|------|-----------|---------------------|\n| **File Path** | `scanned_files[].file` | `test -f path` |\n| **Directory** | Architecture mentions | `test -d path` |\n| **File Count** | `metadata.total_files`, `metadata.scanned_files` | `find . -type f \\| wc -l` |\n| **Config File** | `hypotheses.ai_collaboration.tools_detected[].config_file` | `test -f config_file` |\n| **Git Branch** | `metadata.context.git_branch` | `git branch --show-current` |\n| **Evidence** | `hypotheses.*.evidence` | Verify file:line exists |\n\n**Example extraction:**\n```yaml\n# From generated YAML:\nscanned_files:\n  - file: \"README.md\"  # ‚úÖ Verify\n  - file: \"package.json\"  # ‚úÖ Verify\n  - file: \"CLAUDE.md\"  # ‚úÖ Verify\n\nmetadata:\n  total_files: 127  # ‚úÖ Verify ¬±10%\n  scanned_files: 8  # ‚úÖ Verify exact\n  context:\n    git_branch: \"main\"  # ‚úÖ Verify\n\nhypotheses:\n  ai_collaboration:\n    tools_detected:\n      - config_file: \"CLAUDE.md\"  # ‚úÖ Verify\n      - config_file: \".cursorrules\"  # ‚úÖ Verify\n```\n\n---\n\n### Step V2: Parallel Verification Execution\n\nRun **ALL** verification checks in parallel for speed.\n\n#### V2.1: Verify Scanned Files\n\n```bash\n# Check all scanned_files entries exist\nfor path in \"README.md\" \"package.json\" \"CLAUDE.md\" \"src/app.ts\"; do\n    if [ ! -f \"$path\" ]; then\n        echo \"‚ùå FILE_NOT_FOUND: $path\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All `scanned_files[].file` entries exist\n- ‚ö†Ô∏è If file not found ‚Üí Remove from scanned_files or find correct path\n\n#### V2.2: Verify AI Tool Config Files\n\n```bash\n# Check all AI tool config files\nfor config in \"CLAUDE.md\" \".cursorrules\" \".github/copilot-instructions.md\"; do\n    if [ ! -f \"$config\" ] && [ ! -d \"$config\" ]; then\n        echo \"‚ùå CONFIG_NOT_FOUND: $config\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All `tools_detected[].config_file` entries exist\n- ‚ö†Ô∏è If config not found ‚Üí Remove from tools_detected\n\n#### V2.3: Verify File Count\n\n```bash\n# Verify total_files count is reasonable\nclaimed_count=127\nactual_count=$(find . -type f \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.git/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -not -path \"*/vendor/*\" \\\n    -not -path \"*/__pycache__/*\" \\\n    2>/dev/null | wc -l | tr -d ' ')\n\n# Allow 10% variance for dynamic counts\nlower_bound=$((actual_count * 90 / 100))\nupper_bound=$((actual_count * 110 / 100))\n\nif [ $claimed_count -lt $lower_bound ] || [ $claimed_count -gt $upper_bound ]; then\n    echo \"‚ö†Ô∏è COUNT_CHECK: claimed $claimed_count, actual $actual_count (¬±10% tolerance)\"\nfi\n```\n\n**Check:**\n- ‚úÖ `metadata.total_files` within ¬±10% of actual count\n- ‚ö†Ô∏è If significant difference ‚Üí Update with actual count\n\n#### V2.4: Verify Git Branch\n\n```bash\n# Verify git branch if claimed\nclaimed_branch=\"main\"\nactual_branch=$(git branch --show-current 2>/dev/null)\n\nif [ -n \"$claimed_branch\" ] && [ \"$actual_branch\" != \"$claimed_branch\" ]; then\n    echo \"‚ùå BRANCH_MISMATCH: claimed $claimed_branch, actual $actual_branch\"\nfi\n```\n\n**Check:**\n- ‚úÖ `metadata.context.git_branch` matches current branch\n- ‚ö†Ô∏è If mismatch ‚Üí Update with actual branch\n- ‚úÖ If not a git repo ‚Üí set to `null`\n\n#### V2.5: Verify Evidence References\n\n```bash\n# Verify evidence file:line references\nevidence_files=\"package.json README.md src/app.ts\"\n\nfor file in $evidence_files; do\n    if [ ! -f \"$file\" ]; then\n        echo \"‚ùå EVIDENCE_FILE_NOT_FOUND: $file\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All files mentioned in `hypotheses.*.evidence` exist\n- ‚ö†Ô∏è If file not found ‚Üí Update evidence or remove hypothesis\n\n#### V2.6: Verify Directories\n\n```bash\n# Verify directories mentioned in hypotheses\nfor dir in \"src/controllers\" \"src/services\" \"src/repositories\"; do\n    if [ ! -d \"$dir\" ]; then\n        echo \"‚ùå DIR_NOT_FOUND: $dir\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All directories mentioned in hypotheses exist\n- ‚ö†Ô∏è If directory not found ‚Üí Update hypothesis or remove claim\n\n---\n\n### Step V3: Handle Verification Results\n\nBased on verification outcomes:\n\n#### If All Checks Pass ‚úÖ\n\n```yaml\nverification_status:\n  verified: true\n  checks_passed: 6\n  confidence: high\n```\n\n**Action:**\n- Continue to output/save\n- Add verification summary to footer\n\n#### If Minor Issues Found ‚ö†Ô∏è (1-2 checks failed)\n\n**Examples:**\n- File count off by <10%\n- One config file path incorrect\n- Git branch name slightly different\n\n**Action:**\n1. **Correct the specific claims** without regenerating entire output\n2. Re-verify corrected claims\n3. Add note to verification summary:\n\n```yaml\nverification_notes:\n  - \"File count corrected to 134 (was 127)\"\n  - \"Git branch corrected to 'develop' (was 'main')\"\n```\n\n#### If Major Issues Found ‚ùå (3+ checks failed)\n\n**Examples:**\n- Multiple scanned files don't exist\n- AI tool configs not found\n- File count wildly different (>20% off)\n- Many evidence references invalid\n\n**Action:**\n1. **STOP** - Do not output current analysis\n2. Re-execute relevant phases:\n   - If scanned files wrong ‚Üí Re-run Phase 2 (High-Entropy Scanning)\n   - If AI tools wrong ‚Üí Re-run detect-ai-tools.sh\n   - If file count wrong ‚Üí Re-run detect-project.sh\n3. Regenerate affected YAML sections\n4. Re-run full verification\n\n---\n\n### Step V4: Verification Summary\n\nAdd to footer (before `üó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1`):\n\n#### If All Verifications Passed\n\n```markdown\n‚úÖ Verified: [N] scanned files, [M] config paths, file count\n```\n\n**Example:**\n```markdown\n‚úÖ Verified: 8 scanned files, 2 config paths, file count\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1\n```\n\n#### If Corrections Were Made\n\n```markdown\nüîß Self-corrected: [list specific corrections]\n‚úÖ Verified: [N] scanned files, [M] config paths, file count\n```\n\n**Example:**\n```markdown\nüîß Self-corrected: File count updated to 134 (was 127)\n‚úÖ Verified: 8 scanned files, 2 config paths, file count\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.11.0 ‚îÇ Constitution v1.1\n```\n\n---\n\n## Verification Checklist\n\nBefore finalizing output, confirm:\n\n- [ ] All `scanned_files[].file` entries verified to exist\n- [ ] All `tools_detected[].config_file` entries verified to exist\n- [ ] `metadata.total_files` verified against filesystem (¬±10%)\n- [ ] `metadata.scanned_files` count matches actual files read\n- [ ] `metadata.context.git_branch` verified against current branch\n- [ ] All evidence file references in hypotheses verified to exist\n- [ ] All directories mentioned in hypotheses verified to exist\n- [ ] No placeholder values like `\"[detected name]\"` in output\n\n---\n\n## Verification Examples\n\n### Example 1: File Path Verification\n\n**Claim:**\n```yaml\nscanned_files:\n  - file: \"README.md\"\n```\n\n**Verification:**\n```bash\ntest -f \"README.md\"\necho $?  # 0 = exists\n```\n\n**Result:** ‚úÖ File exists\n\n**Action:** No correction needed\n\n---\n\n### Example 2: Config File Verification\n\n**Claim:**\n```yaml\nhypotheses:\n  ai_collaboration:\n    tools_detected:\n      - tool: \"Claude Code\"\n        config_file: \"CLAUDE.md\"\n```\n\n**Verification:**\n```bash\ntest -f \"CLAUDE.md\"\necho $?  # 0 = exists\n```\n\n**Result:** ‚úÖ Config exists\n\n**Action:** No correction needed\n\n---\n\n### Example 3: File Count Verification\n\n**Claim:**\n```yaml\nmetadata:\n  total_files: 127\n```\n\n**Verification:**\n```bash\nactual=$(find . -type f \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.git/*\" \\\n    -not -path \"*/.venv/*\" \\\n    2>/dev/null | wc -l | tr -d ' ')\necho \"Claimed: 127, Actual: $actual\"\n# Output: Claimed: 127, Actual: 134\n```\n\n**Result:** ‚ö†Ô∏è Count off by 7 (5.5%), within tolerance but should update\n\n**Action:**\n- Update `metadata.total_files: 134`\n- Recalculate `scan_ratio: \"6.0%\"` (8/134)\n- Note: \"File count corrected to 134\"\n\n---\n\n### Example 4: Non-existent Config File\n\n**Claim:**\n```yaml\nhypotheses:\n  ai_collaboration:\n    tools_detected:\n      - tool: \"Cursor\"\n        config_file: \".cursorrules\"\n```\n\n**Verification:**\n```bash\ntest -f \".cursorrules\"\necho $?  # 1 = not found\n```\n\n**Result:** ‚ùå Config file doesn't exist\n\n**Action:**\n- Remove Cursor from `tools_detected`\n- Lower AI collaboration level if appropriate\n- Update confidence level\n- Note: \"Removed .cursorrules (file not found)\"\n\n---\n\n### Example 5: Wrong Git Branch\n\n**Claim:**\n```yaml\nmetadata:\n  context:\n    git_branch: \"main\"\n```\n\n**Verification:**\n```bash\ngit branch --show-current\n# Output: develop\n```\n\n**Result:** ‚ùå Branch mismatch\n\n**Action:**\n- Update `git_branch: \"develop\"`\n- Note: \"Git branch corrected to 'develop'\"\n\n---\n\n### Example 6: Directory Not Found\n\n**Claim:**\n```yaml\nhypotheses:\n  architecture:\n    - hypothesis: \"3-layer architecture: Controller ‚Üí Service ‚Üí Repository\"\n      evidence: \"src/controllers/, src/services/, src/repositories/ exist\"\n```\n\n**Verification:**\n```bash\ntest -d \"src/controllers\" && test -d \"src/services\" && test -d \"src/repositories\"\necho $?  # 1 = at least one doesn't exist\n\n# Check individually\ntest -d \"src/controllers\" && echo \"‚úÖ controllers\"\ntest -d \"src/services\" && echo \"‚úÖ services\"\ntest -d \"src/repositories\" || echo \"‚ùå repositories not found\"\n```\n\n**Result:** ‚ùå repositories directory doesn't exist\n\n**Action:**\n- Update hypothesis to reflect reality\n- Lower confidence level\n- Change evidence: \"src/controllers/, src/services/ exist (no repository layer)\"\n- Update hypothesis: \"2-layer architecture: Controller ‚Üí Service\"\n\n---\n\n## Error Recovery\n\n### If Verification Script Fails\n\n```bash\n# If file not found, search for similar\nfind . -name \"*README*\" -type f 2>/dev/null\n\n# If git command fails (not a git repo)\ngit branch 2>&1 | grep -q \"not a git repository\"\nif [ $? -eq 0 ]; then\n    echo \"Not a git repo, set git_branch to null\"\nfi\n\n# If find fails (permission issues)\nfind . -type f 2>&1 | grep -i \"permission denied\" && echo \"Permission issues detected\"\n```\n\n### If Many Files Don't Exist\n\n**Likely causes:**\n1. Analyzing wrong directory\n2. Files from different project\n3. Placeholder values not replaced\n\n**Action:**\n1. Verify current directory: `pwd`\n2. Check expected location: `ls -la`\n3. Re-run Phase 2 (High-Entropy Scanning)\n4. Only include files that currently exist\n\n---\n\n## Best Practices\n\n1. **Always verify file paths** - Don't assume files exist\n2. **Check AI tool configs** - Many similar filenames (.cursorrules vs .cursor/rules/)\n3. **Verify file counts** - Use same exclusions as analysis\n4. **Check git context** - Projects may not be git repos\n5. **Note all corrections** - Transparency in verification summary\n\n---\n\n## Handoff to Next Steps\n\nAfter verification:\n- ‚úÖ If confidence HIGH ‚Üí Proceed to save\n- ‚ö†Ô∏è If confidence MEDIUM ‚Üí Save with corrections noted\n- ‚ùå If confidence LOW ‚Üí Re-execute analysis phases\n\nSee [reference.md#auto-save](reference.md#auto-save) for save behavior.\n",
        "plugin/commands/overview/workflow.md": "# Overview Workflow Guide\n\nComplete step-by-step execution guide for Stage 0 fingerprint analysis.\n\n---\n\n## Overview\n\nThis workflow generates a project fingerprint by scanning <5% of files to achieve 70-80% understanding in 10-15 minutes using information theory principles.\n\n**Time Budget**: 10-15 minutes (typically 0-5 minutes)\n\n---\n\n## Phase 1: Project Detection & Scale-Aware Planning (2-3 minutes)\n\n### Purpose\n\nDetect project type, count files, determine scale, and set scan limits.\n\n### Step 1.1: Run Enhanced Detection Script\n\n**IMPORTANT**: Use the script for accurate file counts and recommendations.\n\n```bash\n# Try global install first, then local\nif [ -f ~/.claude/scripts/atlas/detect-project.sh ]; then\n    bash ~/.claude/scripts/atlas/detect-project.sh ${ARGUMENTS:-.}\nelif [ -f scripts/atlas/detect-project.sh ]; then\n    bash scripts/atlas/detect-project.sh ${ARGUMENTS:-.}\nelse\n    echo \"‚ö†Ô∏è Warning: detect-project.sh not found, using manual detection\"\nfi\n```\n\n**Script outputs:**\n- Project type and language\n- Actual code file count (excluding .venv, node_modules, vendor, etc.)\n- Project scale classification\n- Recommended file scan limits\n- Hypothesis targets\n- Context (git branch, monorepo subdirectory, package name)\n\n### Step 1.2: Manual Detection Fallback\n\nIf script not available, manually detect:\n\n```bash\n# Detect primary language\necho \"=== Language Detection ===\"\nfind . -type f \\( -name \"*.py\" -o -name \"*.js\" -o -name \"*.ts\" -o -name \"*.swift\" -o -name \"*.kt\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -not -path \"*/vendor/*\" \\\n    2>/dev/null | head -10\n\n# Count code files\necho \"=== File Count ===\"\nfind . -type f \\( -name \"*.py\" -o -name \"*.js\" -o -name \"*.ts\" -o -name \"*.swift\" -o -name \"*.kt\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -not -path \"*/vendor/*\" \\\n    2>/dev/null | wc -l | tr -d ' '\n\n# Detect project type\necho \"=== Project Type ===\"\nif [ -f \"package.json\" ]; then\n    echo \"Node.js project detected\"\n    cat package.json | grep -A 5 \"\\\"name\\\"\"\nelif [ -f \"requirements.txt\" ] || [ -f \"pyproject.toml\" ]; then\n    echo \"Python project detected\"\nelif [ -f \"Podfile\" ] || [ -f \"*.xcodeproj\" ]; then\n    echo \"iOS project detected\"\nelif [ -f \"build.gradle\" ] || [ -f \"build.gradle.kts\" ]; then\n    echo \"Android project detected\"\nfi\n\n# Detect git context\necho \"=== Git Context ===\"\ngit branch --show-current 2>/dev/null || echo \"Not a git repository\"\ngit rev-parse --show-toplevel 2>/dev/null\n```\n\n### Step 1.3: Determine Project Scale\n\nBased on file count:\n\n| Scale | File Count | Scan Limit | Hypothesis Target |\n|-------|------------|------------|-------------------|\n| **TINY** | <5 files | 1-2 files (50% max) | 5-8 hypotheses |\n| **SMALL** | 5-15 files | 2-3 files (10-20%) | 7-10 hypotheses |\n| **MEDIUM** | 15-50 files | 4-6 files (8-12%) | 10-15 hypotheses |\n| **LARGE** | 50-150 files | 6-10 files (4-7%) | 12-18 hypotheses |\n| **VERY_LARGE** | >150 files | 10-15 files (3-7%) | 15-20 hypotheses |\n\n**Example calculation:**\n- 120 files detected ‚Üí **LARGE**\n- Scan limit: 6-10 files (5-8%)\n- Hypothesis target: 12-18 hypotheses\n\n---\n\n## Phase 2: High-Entropy File Prioritization (5-8 minutes)\n\n### Purpose\n\nApply information theory - **high-entropy files contain disproportionate information**.\n\n### Step 2.1: Execute Helper Script (Recommended)\n\n```bash\n# Use helper script if available (try global first, then local)\nif [ -f ~/.claude/scripts/atlas/scan-entropy.sh ]; then\n    bash ~/.claude/scripts/atlas/scan-entropy.sh ${ARGUMENTS:-.}\nelif [ -f scripts/atlas/scan-entropy.sh ]; then\n    bash scripts/atlas/scan-entropy.sh ${ARGUMENTS:-.}\nelse\n    echo \"‚ö†Ô∏è Warning: scan-entropy.sh not found, scanning manually\"\nfi\n```\n\n### Step 2.2: Manual Scan Priority Order\n\nScan in this order, respecting scale limits from Phase 1:\n\n#### 2.2.1: Documentation (Highest Entropy)\n\n```bash\n# Scan README first (often contains 30-40% of understanding)\nfind . -maxdepth 2 -iname \"README*\" -type f 2>/dev/null | head -3\n\n# Other high-value docs\nfind . -maxdepth 2 \\( -name \"CLAUDE.md\" -o -name \"CONTRIBUTING.md\" -o -name \"ARCHITECTURE.md\" \\) -type f 2>/dev/null\n\n# Docs directory\nfind . -path \"*/docs/*\" -o -path \"*/documentation/*\" -type f 2>/dev/null | head -5\n```\n\n**Action**: Use Read tool on top 1-2 documentation files.\n\n#### 2.2.2: Configuration Files (Project-Level Decisions)\n\n```bash\n# Language-specific config\nfind . -maxdepth 2 \\( -name \"package.json\" -o -name \"composer.json\" -o -name \"Gemfile\" \\\n    -o -name \"requirements.txt\" -o -name \"pyproject.toml\" -o -name \"Podfile\" \\\n    -o -name \"build.gradle\" -o -name \"pom.xml\" \\) -type f 2>/dev/null\n\n# Docker\nfind . -maxdepth 2 \\( -name \"docker-compose.yml\" -o -name \"Dockerfile\" \\) -type f 2>/dev/null\n\n# Root configs\nfind . -maxdepth 1 -name \"*.json\" -o -name \"*.yaml\" -o -name \"*.toml\" -type f 2>/dev/null | head -5\n```\n\n**Action**: Use Read tool on 2-3 key config files.\n\n#### 2.2.3: Core Models (Data Structure - Scan 2-3 Only)\n\n```bash\n# Find model directories\nfind . -type d \\( -name \"models\" -o -name \"entities\" -o -name \"domain\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    2>/dev/null | head -3\n\n# Find model files\nfind . -path \"*/models/*\" -o -path \"*/entities/*\" -o -path \"*/domain/*\" -type f \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    2>/dev/null | head -10\n```\n\n**Action**: Use Read tool on 2-3 most important models only.\n\n#### 2.2.4: Entry Points (Architecture Patterns - Scan 1-2 Examples)\n\n```bash\n# Find entry point files\nfind . -maxdepth 3 \\( -name \"main.*\" -o -name \"index.*\" -o -name \"app.*\" -o -name \"server.*\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -type f 2>/dev/null\n\n# Find controller/route directories\nfind . -type d \\( -name \"controllers\" -o -name \"routes\" -o -name \"api\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    2>/dev/null | head -5\n\n# Sample controllers\nfind . -path \"*/controllers/*\" -o -path \"*/routes/*\" -type f \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    2>/dev/null | head -5\n```\n\n**Action**: Use Read tool on 1-2 example entry points/controllers.\n\n#### 2.2.5: Tests (Development Practices - Scan 1-2 Examples)\n\n```bash\n# Find test directories\nfind . -type d \\( -name \"test\" -o -name \"tests\" -o -name \"spec\" -o -name \"__tests__\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    2>/dev/null | head -5\n\n# Find test files\nfind . \\( -name \"*.test.*\" -o -name \"*.spec.*\" \\) -type f \\\n    -not -path \"*/node_modules/*\" \\\n    2>/dev/null | head -10\n```\n\n**Action**: Use Read tool on 1-2 example test files to understand testing approach.\n\n### Step 2.3: AI Tool Detection\n\nRun AI collaboration detection:\n\n```bash\n# Use helper script for comprehensive detection\nif [ -f ~/.claude/scripts/atlas/detect-ai-tools.sh ]; then\n    bash ~/.claude/scripts/atlas/detect-ai-tools.sh ${ARGUMENTS:-.}\nelif [ -f scripts/atlas/detect-ai-tools.sh ]; then\n    bash scripts/atlas/detect-ai-tools.sh ${ARGUMENTS:-.}\nelse\n    # Fallback: manual checks\n    echo \"=== AI Tool Detection ===\"\n\n    # Tier 1: Tool-specific config files\n    ls -la CLAUDE.md .cursorrules .windsurfrules CONVENTIONS.md AGENTS.md .aiignore 2>/dev/null\n    ls -la .claude/ .cursor/rules/ .windsurf/rules/ .clinerules/ .roo/ .continue/rules/ .ruler/ 2>/dev/null\n    ls -la .github/copilot-instructions.md .vscode/cody.json .aider.conf.yml .aider.input.history 2>/dev/null\n    ls -la replit.nix .replit 2>/dev/null\n\n    # If found, read key config files\n    [ -f \"CLAUDE.md\" ] && echo \"Found: CLAUDE.md\"\n    [ -f \".cursorrules\" ] && echo \"Found: .cursorrules\"\n    [ -f \"AGENTS.md\" ] && echo \"Found: AGENTS.md\"\nfi\n```\n\n**Tier 1 Indicators (High-Confidence)**:\n\n| Tool | Files | Confidence Boost |\n|------|-------|------------------|\n| Claude Code | `CLAUDE.md`, `.claude/` | +0.30 |\n| Cursor | `.cursorrules`, `.cursor/rules/*.mdc` | +0.25 |\n| Windsurf | `.windsurfrules`, `.windsurf/rules/` | +0.25 |\n| GitHub Copilot | `.github/copilot-instructions.md`, `**/.instructions.md` | +0.20 |\n| Cline/Roo | `.clinerules`, `.clinerules/`, `.roo/` | +0.25 |\n| Aider | `CONVENTIONS.md`, `.aider.conf.yml`, `.aider.input.history` | +0.25 |\n| Continue.dev | `.continuerules`, `.continue/rules/` | +0.25 |\n| JetBrains AI | `.aiignore` | +0.20 |\n| AGENTS.md | `AGENTS.md` (Linux Foundation standard, 60K+ projects) | +0.20 |\n| Sourcegraph Cody | `.vscode/cody.json` | +0.15 |\n| Replit | `replit.nix` + `.replit` | +0.15 |\n| Ruler | `.ruler/` (multi-tool manager) | +0.20 |\n\n**Tier 2 Indicators (Indirect)**:\n\n| Indicator | Threshold | Interpretation |\n|-----------|-----------|----------------|\n| Comment density | >15% | AI-generated code (vs 5-8% manual) |\n| Code consistency | >98% | Systematic AI assistance |\n| Conventional Commits | 100% | AI tool integration |\n| Docs-to-code ratio | >1:1 | AI documentation generation |\n\n---\n\n## Phase 3: Generate Hypotheses (3-5 minutes)\n\n### Purpose\n\nBased on scanned files, generate **scale-appropriate hypotheses** with confidence levels and evidence.\n\n### Step 3.1: Technology Stack Hypotheses\n\nBased on config files and imports:\n\n**Example hypothesis:**\n```yaml\ntech_stack:\n  - hypothesis: \"Primary framework is Express.js v4.18 with TypeScript\"\n    confidence: 0.95\n    evidence: \"package.json:12, src/app.ts:1-5\"\n    validation_method: \"grep 'express' package.json; check TypeScript config\"\n```\n\n**Categories:**\n- Primary language(s) and versions\n- Framework(s) and major dependencies\n- Database(s) and storage solutions\n- Testing frameworks\n\n### Step 3.2: Architecture Hypotheses\n\nBased on directory structure and entry points:\n\n**Example hypothesis:**\n```yaml\narchitecture:\n  - hypothesis: \"3-layer architecture: Controller ‚Üí Service ‚Üí Repository\"\n    confidence: 0.85\n    evidence: \"src/controllers/, src/services/, src/repositories/ exist\"\n    validation_method: \"trace UserController.ts flow\"\n```\n\n**Categories:**\n- Overall pattern (MVC, Clean Architecture, Microservices, etc.)\n- Directory structure conventions\n- Layering and separation of concerns\n- Design patterns used\n\n### Step 3.3: Development Practices Hypotheses\n\nBased on tests, docs, and code quality:\n\n**Example hypothesis:**\n```yaml\ndevelopment:\n  - hypothesis: \"Jest + Supertest for API testing, 80%+ coverage\"\n    confidence: 0.75\n    evidence: \"package.json:25, tests/api/users.test.ts:1-20\"\n    validation_method: \"run npm test -- --coverage\"\n```\n\n**Categories:**\n- Code quality indicators\n- Testing coverage and approach\n- Documentation depth\n- Git workflow patterns\n\n### Step 3.4: AI Collaboration Hypotheses\n\nBased on Tier 1 + Tier 2 indicators:\n\n**Level Definitions:**\n- **Level 0**: No AI - No config files, low comment density (5-8%), inconsistent style\n- **Level 1**: Occasional use - 1 tool config with minimal content\n- **Level 2**: Frequent use - 1-2 tool configs + some indirect indicators\n- **Level 3**: Systematic collaboration - Complete AI config + high comment density + consistent style\n- **Level 4**: Ecosystem-level - Multiple tool configs (Ruler/.ruler/) or AGENTS.md + team-wide standards\n\n**Example hypothesis:**\n```yaml\nai_collaboration:\n  level: 3\n  confidence: 0.90\n  tools_detected:\n    - tool: \"Claude Code\"\n      config_file: \"CLAUDE.md\"\n      content_quality: \"comprehensive\"\n    - tool: \"Cursor\"\n      config_file: \".cursorrules\"\n      content_quality: \"basic\"\n  indicators:\n    - \"High comment density (18% vs typical 5-8%)\"\n    - \"Consistent code style across all files\"\n    - \"Comprehensive inline documentation\"\n```\n\n### Step 3.5: Business Domain Hypotheses\n\nBased on README, models, and code:\n\n**Example hypothesis:**\n```yaml\nbusiness:\n  - hypothesis: \"E-commerce platform with user, product, order management\"\n    confidence: 0.80\n    evidence: \"README.md:15-30, models/User.ts, models/Product.ts, models/Order.ts\"\n    validation_method: \"review core entity relationships\"\n```\n\n**Categories:**\n- What does this project do?\n- Key entities and concepts\n- Main features\n\n### Step 3.6: Hypothesis Quality Requirements\n\nEach hypothesis MUST include:\n- **hypothesis**: Clear, specific statement\n- **confidence**: 0.0-1.0 (aim for >0.7)\n- **evidence**: Specific file:line references\n- **validation_method**: How to verify in Stage 1\n\n**Scale-Aware Targets** (from Phase 1):\n- TINY: 5-8 hypotheses\n- SMALL: 7-10 hypotheses\n- MEDIUM: 10-15 hypotheses\n- LARGE: 12-18 hypotheses\n- VERY_LARGE: 15-20 hypotheses\n\n---\n\n## Performance Tips\n\n### For Large Codebases\n\n```bash\n# Limit search depth\nfind . -maxdepth 3 -name \"*.py\" ...\n\n# Limit results\n... | head -20\n\n# Exclude large directories early\nfind . -path \"*/vendor\" -prune -o -path \"*/dist\" -prune -o ...\n```\n\n### For Monorepos\n\n```bash\n# Search specific package only\nfind packages/api -name \"*.ts\" ...\n\n# Or multiple related packages\nfind packages/{api,core} -name \"*.ts\" ...\n```\n\n---\n\n## Common Issues\n\n### Issue 1: Script Not Found\n\n**Symptom:** Helper scripts not available\n\n**Solution:**\n- Check global: `~/.claude/scripts/atlas/`\n- Check local: `scripts/atlas/`\n- Use manual fallback commands provided in each step\n\n### Issue 2: Too Many Files\n\n**Symptom:** Project scale is VERY_LARGE, overwhelming\n\n**Solution:**\n- Respect scan limits (10-15 files max)\n- Focus on highest entropy files only\n- Trust the 70-80% understanding goal\n\n### Issue 3: Git Not Available\n\n**Symptom:** `git branch` fails\n\n**Solution:**\n- Set `context.git_branch: null`\n- Continue analysis without git context\n\n---\n\n## Output Transition\n\nAfter Phase 3 completes:\n1. Compile all findings\n2. Structure as YAML (see [output-template.md](output-template.md))\n3. Execute verification (see [verification-guide.md](verification-guide.md))\n4. Save result (see [reference.md#auto-save](reference.md#auto-save))\n",
        "plugin/commands/pattern/SKILL.md": "---\nname: pattern\ndescription: Learn design patterns from the current codebase\nmodel: sonnet\nallowed-tools: Bash, Glob, Grep, Read, Write\nargument-hint: [pattern type, e.g., \"api endpoint\", \"background job\"] [--force] [--brief|--full]\n---\n\n# SourceAtlas: Pattern Learning Mode\n\n> **Constitution**: [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md) v1.0\n\n## Context\n\n**Pattern requested:** $ARGUMENTS\n**Goal:** Learn how THIS specific codebase implements the requested pattern\n**Time Limit:** 5-10 minutes maximum\n\n## Quick Start\n\n1. **Check cache** (skip if `--force` flag present)\n2. **Detect pattern** using `find-patterns.sh` script\n3. **Apply output mode** (--brief / --full / smart)\n4. **Analyze top 2-3 files** (high-entropy priority)\n5. **Extract conventions** and best practices\n6. **Generate implementation guide**\n7. **Verify output** using [verification-guide.md](verification-guide.md)\n8. **Auto-save** to `.sourceatlas/patterns/`\n\n## Your Task\n\nYou are analyzing how THIS codebase implements a specific pattern by:\n1. Finding 2-3 best example files\n2. Extracting design patterns and conventions\n3. Providing actionable implementation guidance\n\n### Output Modes\n\n| Parameter | Behavior | Use Case |\n|-----------|----------|----------|\n| `--brief` | List files only | Quick file browser |\n| `--full` | Analyze all files | Deep learning |\n| (default) | Smart: ‚â§5 files‚Üífull; >5‚Üíselection UI | Balanced |\n\n---\n\n## Core Workflow\n\nExecute these steps in order. See [workflow.md](workflow.md) for complete details.\n\n### Step 0: Parse Output Mode (10 seconds)\n\n**Purpose:** Determine how much analysis to perform.\n\nDetect flags:\n- `--brief` ‚Üí List files only, no analysis\n- `--full` ‚Üí Analyze all found files\n- No flag ‚Üí Smart mode (adapt based on file count)\n\n‚Üí See [workflow.md#step-0](workflow.md#step-0-parse-output-mode-10-seconds)\n\n### Step 1: Execute Pattern Detection (1-2 minutes)\n\n**Purpose:** Find relevant files using optimized search.\n\n**Use find-patterns.sh script first:**\n```bash\n# Locate script (global ‚Üí local)\nif [ -f ~/.claude/scripts/atlas/find-patterns.sh ]; then\n    SCRIPT_PATH=~/.claude/scripts/atlas/find-patterns.sh\nelif [ -f scripts/atlas/find-patterns.sh ]; then\n    SCRIPT_PATH=scripts/atlas/find-patterns.sh\nfi\n\nbash \"$SCRIPT_PATH\" \"$ARGUMENTS\"\n```\n\n**Supported patterns:**\n- api endpoint / api / endpoint\n- background job / job / queue\n- swiftui view / view\n- view controller / viewcontroller\n- authentication / auth / login\n- file upload / upload\n- database query / database\n- networking / network\n\n**If unsupported:** Fallback to manual Glob/Grep search\n\n‚Üí See [workflow.md#step-1](workflow.md#step-1-execute-pattern-detection-1-2-minutes)\n\n### Step 1.5: ast-grep Enhanced Search (Optional)\n\n**Purpose:** More precise search for content-based patterns.\n\n**Use ast-grep-search.sh for:**\n- async/await patterns\n- suspend functions (Kotlin)\n- custom hooks (React)\n- goroutines (Go)\n\n**Graceful degradation:** Script handles ast-grep unavailability\n\n‚Üí See [workflow.md#step-1-5](workflow.md#step-1-5-ast-grep-enhanced-search-optional)\n\n### Step 2: Apply Output Mode Logic (30 seconds)\n\n**Purpose:** Decide analysis depth based on file count.\n\n**Smart mode logic:**\n```\nFILE_COUNT = 0      ‚Üí \"No files found\"\nFILE_COUNT ‚â§ 5      ‚Üí Full analysis\nFILE_COUNT > 5      ‚Üí Selection interface\n```\n\n**Brief mode:** List files, end immediately\n\n**Full mode:** Analyze all files (warn if >10)\n\n‚Üí See [workflow.md#step-2](workflow.md#step-2-apply-output-mode-logic-30-seconds)\n\n### Step 3: Analyze Selected Files (3-5 minutes)\n\n**Purpose:** Extract patterns from 2-3 best examples.\n\n**High-entropy priority:**\n- ‚úÖ Main implementation files\n- ‚úÖ Complete examples (100-500 lines)\n- ‚úÖ Well-structured production code\n- ‚ùå NOT: Utilities, trivial code, generated files\n\n**Focus areas:**\n1. Overall structure\n2. Standard flow\n3. Naming conventions\n4. Dependencies\n5. Error handling\n6. Configuration\n\n‚Üí See [workflow.md#step-3](workflow.md#step-3-analyze-selected-files-3-5-minutes)\n\n### Step 4: Extract the Pattern (2 minutes)\n\n**Purpose:** Distill findings into reusable guidance.\n\n**Extract:**\n1. How this codebase handles it (2-3 sentences)\n2. Standard flow (numbered steps)\n3. Key conventions (bullet points)\n4. Testing patterns\n5. Common pitfalls\n\n‚Üí See [workflow.md#step-4](workflow.md#step-4-extract-the-pattern-2-minutes)\n\n### Step 5: Find Related Tests (1 minute, optional)\n\n**Purpose:** Understand how pattern is tested.\n\n```bash\nfind . \\( -path \"*/test/*\" -o -path \"*/tests/*\" -o -name \"*.test.*\" \\) \\\n    -type f -not -path \"*/node_modules/*\" | head -20\n```\n\n‚Üí See [workflow.md#step-5](workflow.md#step-5-find-related-tests-1-minute-optional)\n\n### Step 6: Generate Implementation Guide (1 minute)\n\n**Purpose:** Provide concrete steps to follow.\n\nCreate actionable, step-by-step guide with:\n- Specific file locations\n- Code structure templates\n- Configuration steps\n- Testing approach\n\n‚Üí See [workflow.md#step-6](workflow.md#step-6-generate-implementation-guide-1-minute)\n\n---\n\n## Output Format\n\nYour analysis should follow this Markdown structure:\n\n```markdown\nüó∫Ô∏è SourceAtlas: Pattern\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüß© [Pattern Name] ‚îÇ [N] files found\n\n## Overview\n[2-3 sentence summary]\n\n## Best Examples\n### 1. [File Path]:[line]\n[Purpose, Key Code, Key Points]\n\n### 2. [File Path]:[line]\n[Same structure]\n\n## Key Conventions\n- [Convention 1]\n- [Convention 2]\n- [Convention 3]\n\n## Testing Pattern\n[Test location, approach, examples]\n\n## Common Pitfalls to Avoid\n1. [Pitfall 1]\n2. [Pitfall 2]\n\n## Step-by-Step Implementation Guide\n1. [Step 1]\n2. [Step 2]\n...\n\n## Related Patterns (Optional)\n[If applicable]\n\n## Recommended Next (Optional)\n[Dynamic suggestions based on findings]\n```\n\n‚Üí See [output-template.md](output-template.md) for complete specification and examples\n\n---\n\n## Critical Rules\n\n### 1. Scan <5% of Files\n- Use script for targeted search\n- Read only top 2-3 files\n- High-entropy priority\n\n### 2. Focus on PATTERNS\n- Extract reusable approaches\n- Not line-by-line details\n- Actionable conventions\n\n### 3. Be Specific to THIS Codebase\n- Not generic internet advice\n- Actual code from this project\n- Real file paths and examples\n\n### 4. Provide Evidence\n- file:line references always\n- Code snippets from actual files\n- Directory paths must exist\n\n### 5. Time Limit: 5-10 Minutes\n- Be efficient\n- Don't read entire codebase\n- Progressive disclosure\n\n### 6. Verification Required\n- Execute [verification-guide.md](verification-guide.md) after analysis\n- Verify file paths, line numbers, code snippets\n- Correct discrepancies before output\n\n### 7. Constitutional Compliance\nFollow [ANALYSIS_CONSTITUTION.md](../../../ANALYSIS_CONSTITUTION.md):\n- **Article I**: High-entropy priority (scan 2-3 best examples)\n- **Article II**: Mandatory exclusions (node_modules, .venv, Pods)\n- **Article IV**: Evidence format (file:line references)\n\n---\n\n## Self-Verification\n\nAfter generating your analysis, execute verification steps:\n\n### Step V1: Extract Verifiable Claims\n- File paths (with line numbers)\n- Directory paths\n- Code snippets\n- File counts\n\n### Step V2: Parallel Verification\n- Verify file paths exist\n- Verify line numbers within bounds\n- Verify code snippets match files\n- Verify directories exist\n- Verify file counts (¬±2 tolerance)\n\n### Step V3: Handle Results\n- ‚úÖ All checks pass ‚Üí Proceed to output\n- ‚ö†Ô∏è Minor issues (1-2 checks) ‚Üí Correct and note\n- ‚ùå Major issues (3+ checks) ‚Üí Re-execute analysis\n\n### Step V4: Add Verification Summary\n```yaml\nverification_summary:\n  checks_performed: [...]\n  confidence_level: \"high\"  # high|medium|low\n  notes: [...]\n```\n\n‚Üí See [verification-guide.md](verification-guide.md) for complete checklist\n\n---\n\n## Advanced\n\n### Cache Behavior\n- **Default**: Use cache if exists\n- **Force flag**: Skip cache with `--force`\n- **Cache location**: `.sourceatlas/patterns/${PATTERN_NAME}.md`\n- **Cache age warning**: If >30 days old\n\n‚Üí See [reference.md#cache-behavior](reference.md#cache-behavior)\n\n### Auto-Save Mechanism\nComplete Markdown report auto-saves after verification:\n```\nüíæ Saved to .sourceatlas/patterns/[pattern-name].md\n```\n\n‚Üí See [reference.md#auto-save-behavior](reference.md#auto-save-behavior)\n\n### Handoffs to Next Commands\nBased on findings, suggest:\n- Complex flow ‚Üí `/sourceatlas:flow \"[entry point]\"`\n- Wide usage ‚Üí `/sourceatlas:impact \"[core file]\"`\n- Related pattern ‚Üí `/sourceatlas:pattern \"[related]\"`\n\n‚Üí See [reference.md#handoffs](reference.md#handoffs)\n\n### find-patterns.sh Script\n- Pre-tested patterns for common use cases\n- Optimized search (<20 seconds)\n- Relevance ranking (‚≠ê‚≠ê‚≠ê / ‚≠ê‚≠ê / ‚≠ê)\n- Graceful fallback to manual search\n\n### ast-grep Integration\n- Content-based pattern search\n- Higher precision for Type B patterns\n- 14-93% false positive reduction\n- Automatic fallback if unavailable\n\n---\n\n## Support Files\n\nDetailed documentation available in:\n\n- **[workflow.md](workflow.md)** - Complete Step 0-6 execution guide with bash commands\n- **[output-template.md](output-template.md)** - Full Markdown structure and examples\n- **[verification-guide.md](verification-guide.md)** - Self-verification steps V1-V4\n- **[reference.md](reference.md)** - Cache, scripts, handoffs\n\n---\n\n## Output Header\n\nStart your output with:\n\n```markdown\nüó∫Ô∏è SourceAtlas: Pattern\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüß© [Pattern Name] ‚îÇ [N] files found\n```\n\nThen follow complete structure in [output-template.md](output-template.md).\n",
        "plugin/commands/pattern/output-template.md": "# Pattern Learning Output Template\n\nComplete Markdown format specification for pattern analysis reports.\n\n---\n\n## Header Format\n\n```markdown\nüó∫Ô∏è SourceAtlas: Pattern\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüß© [Pattern Name] ‚îÇ [N] files found\n```\n\n---\n\n## Section 1: Overview\n\n2-3 sentence summary of how this codebase implements the pattern.\n\n```markdown\n## Overview\n\nThis codebase implements [pattern] using [approach/framework]. The pattern follows [architectural style] with [key characteristics]. [Additional context about why this approach was chosen or how it differs from standard implementations].\n```\n\n**Example:**\n```markdown\n## Overview\n\nThis codebase implements API endpoints using Express.js controllers with a 3-layer architecture: Controller ‚Üí Service ‚Üí Repository. All endpoints follow RESTful conventions and use middleware for auth, validation, and error handling. The pattern emphasizes separation of concerns with clear boundaries between HTTP handling, business logic, and data access.\n```\n\n---\n\n## Section 2: Best Examples\n\nShow 2-3 concrete examples from the codebase.\n\n```markdown\n## Best Examples\n\n### 1. [File Path]:[line]\n\n**Purpose**: [What this example demonstrates - 1 sentence]\n\n**Key Code**:\n```[language]\n[Relevant code snippet - 5-15 lines showing core pattern]\n```\n\n**Key Points**:\n- [Important observation 1]\n- [Important observation 2]\n- [Important observation 3]\n\n---\n\n### 2. [File Path]:[line]\n\n[Same structure as Example 1]\n\n---\n\n### 3. [File Path]:[line] (Optional)\n\n[Only include if it adds significant new insight]\n```\n\n**Example:**\n```markdown\n## Best Examples\n\n### 1. src/api/controllers/UserController.ts:45\n\n**Purpose**: Demonstrates RESTful endpoint with authentication middleware\n\n**Key Code**:\n```typescript\n@Controller('/api/users')\nexport class UserController extends BaseController {\n  constructor(private userService: UserService) {\n    super();\n  }\n\n  @Get('/:id')\n  @UseGuards(AuthGuard)\n  async getUser(@Param('id') id: string): Promise<UserResponse> {\n    const user = await this.userService.findById(id);\n    return this.formatResponse(user);\n  }\n}\n```\n\n**Key Points**:\n- Uses decorator-based routing (@Controller, @Get)\n- Extends BaseController for common functionality\n- Injects UserService via constructor\n- Auth guard applied via @UseGuards decorator\n- Async/await pattern for service calls\n```\n\n---\n\n## Section 3: Key Conventions\n\nObservable patterns extracted from examples.\n\n```markdown\n## Key Conventions\n\nBased on the examples above, this codebase follows these conventions:\n\n- **[Convention Category 1]** - [Specific rule/pattern]\n  - Location: [where to find examples]\n  - Example: [concrete example]\n\n- **[Convention Category 2]** - [Specific rule/pattern]\n  - Location: [where to find examples]\n  - Example: [concrete example]\n\n- **[Convention Category 3]** - [Specific rule/pattern]\n  - Location: [where to find examples]\n  - Example: [concrete example]\n```\n\n**Example:**\n```markdown\n## Key Conventions\n\nBased on the examples above, this codebase follows these conventions:\n\n- **File Structure** - Controllers ‚Üí Services ‚Üí Repositories pattern\n  - Location: src/api/controllers/, src/services/, src/repositories/\n  - Example: UserController calls UserService calls UserRepository\n\n- **Naming** - PascalCase for classes, camelCase for methods\n  - Location: All TypeScript files\n  - Example: UserController.getUser(), OrderService.createOrder()\n\n- **Dependency Injection** - Constructor injection with private properties\n  - Location: All service and controller classes\n  - Example: constructor(private userService: UserService)\n\n- **Error Handling** - Custom exception classes + global error handler\n  - Location: src/exceptions/, src/middleware/errorHandler.ts\n  - Example: throw new NotFoundException('User not found')\n```\n\n---\n\n## Section 4: Testing Pattern\n\nHow this pattern is tested in the codebase.\n\n```markdown\n## Testing Pattern\n\n**Test Location:** [path/to/tests/ or \"No tests found\"]\n\n**Testing Approach:**\n[Describe framework, structure, key testing strategies - 2-3 sentences]\n\n**Example Test File:** [path/to/example.test.ext] (if available)\n\n**Key Test Patterns:**\n- [Test pattern 1]\n- [Test pattern 2]\n- [Test pattern 3]\n```\n\n**Example:**\n```markdown\n## Testing Pattern\n\n**Test Location:** tests/integration/api/\n\n**Testing Approach:**\nUses Jest + Supertest for API integration tests. Tests follow Arrange-Act-Assert pattern with separate test database setup. Each test file mirrors the controller structure and tests both happy paths and error cases.\n\n**Example Test File:** tests/integration/api/users.test.ts\n\n**Key Test Patterns:**\n- Mock external services using jest.mock()\n- Test database seeded in beforeEach, cleaned in afterEach\n- Use supertest for HTTP request testing\n- Separate unit tests for services in tests/unit/services/\n```\n\n---\n\n## Section 5: Common Pitfalls to Avoid\n\nBased on code analysis and anti-patterns observed.\n\n```markdown\n## Common Pitfalls to Avoid\n\nBased on code analysis and observations:\n\n1. **[Pitfall 1]** - [What to avoid]\n   - Why: [Reason/consequence]\n   - Instead: [Correct approach]\n\n2. **[Pitfall 2]** - [What to avoid]\n   - Why: [Reason/consequence]\n   - Instead: [Correct approach]\n\n3. **[Pitfall 3]** - [What to avoid]\n   - Why: [Reason/consequence]\n   - Instead: [Correct approach]\n```\n\n**Example:**\n```markdown\n## Common Pitfalls to Avoid\n\nBased on code analysis and observations:\n\n1. **Don't put business logic in controllers**\n   - Why: Controllers should only handle HTTP concerns (request parsing, response formatting)\n   - Instead: Move all business logic to service layer (UserService, OrderService, etc.)\n\n2. **Don't call repositories directly from controllers**\n   - Why: Breaks the layered architecture and makes testing harder\n   - Instead: Always go through service layer: Controller ‚Üí Service ‚Üí Repository\n\n3. **Don't forget input validation**\n   - Why: API is public-facing, all user input must be validated\n   - Instead: Use class-validator decorators on DTOs or middleware validators\n```\n\n---\n\n## Section 6: Step-by-Step Implementation Guide\n\nConcrete steps to implement similar functionality.\n\n```markdown\n## Step-by-Step Implementation Guide\n\nTo implement [similar functionality] following this codebase's pattern:\n\n1. **[Step 1 Title]** - [Action with specifics]\n   - File: [where to create/modify]\n   - Code structure: [what to include]\n   - Example: [concrete code snippet or reference]\n\n2. **[Step 2 Title]** - [Action with specifics]\n   - File: [where to create/modify]\n   - Code structure: [what to include]\n   - Example: [concrete code snippet or reference]\n\n... (as many steps as needed, typically 4-7 steps)\n```\n\n**Example:**\n```markdown\n## Step-by-Step Implementation Guide\n\nTo implement a new API endpoint following this codebase's pattern:\n\n1. **Create Route Definition**\n   - File: src/routes/[resource].ts\n   - Code structure: Import controller, define routes\n   - Example:\n     ```typescript\n     import { ProductController } from '../controllers/ProductController';\n     router.get('/api/products', controller.list);\n     router.post('/api/products', controller.create);\n     ```\n\n2. **Create Controller Class**\n   - File: src/controllers/[Resource]Controller.ts\n   - Code structure: Extend BaseController, inject service\n   - Example:\n     ```typescript\n     @Controller('/api/products')\n     export class ProductController extends BaseController {\n       constructor(private productService: ProductService) {\n         super();\n       }\n     }\n     ```\n\n3. **Implement Controller Methods**\n   - File: Same as above\n   - Code structure: Use decorators, call service methods\n   - Example:\n     ```typescript\n     @Get('/')\n     @UseGuards(AuthGuard)\n     async list(): Promise<ProductResponse[]> {\n       const products = await this.productService.findAll();\n       return this.formatList(products);\n     }\n     ```\n\n4. **Create Service Class**\n   - File: src/services/[Resource]Service.ts\n   - Code structure: Business logic, inject repository\n   - Example:\n     ```typescript\n     export class ProductService {\n       constructor(private productRepo: ProductRepository) {}\n\n       async findAll(): Promise<Product[]> {\n         return this.productRepo.findAll({ active: true });\n       }\n     }\n     ```\n\n5. **Create Repository Class** (if database access needed)\n   - File: src/repositories/[Resource]Repository.ts\n   - Code structure: Extend BaseRepository, use ORM\n   - Example:\n     ```typescript\n     export class ProductRepository extends BaseRepository<Product> {\n       async findAll(filters: any): Promise<Product[]> {\n         return this.model.findAll({ where: filters });\n       }\n     }\n     ```\n\n6. **Add Integration Tests**\n   - File: tests/integration/api/[resource].test.ts\n   - Code structure: Test happy path + error cases\n   - Example:\n     ```typescript\n     describe('GET /api/products', () => {\n       it('returns list of products', async () => {\n         const response = await request(app).get('/api/products');\n         expect(response.status).toBe(200);\n         expect(response.body).toHaveLength(3);\n       });\n     });\n     ```\n```\n\n---\n\n## Section 7: Related Patterns (Optional)\n\nPatterns commonly used together.\n\n```markdown\n## Related Patterns\n\n[If applicable, mention related patterns in this codebase]\n\n- **[Related Pattern 1]** - [Brief explanation of relationship]\n- **[Related Pattern 2]** - [Brief explanation of relationship]\n```\n\n**Example:**\n```markdown\n## Related Patterns\n\nThese patterns are commonly used with API endpoints in this codebase:\n\n- **Middleware Pattern** - Auth, validation, and error handling middleware wrap all endpoints\n- **DTO Pattern** - Data Transfer Objects validate and transform request/response data\n- **Repository Pattern** - All database access abstracted behind repository interfaces\n```\n\n---\n\n## Section 8: Recommended Next (Optional)\n\nDynamic suggestions based on findings.\n\n```markdown\n## Recommended Next\n\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:[command] \"[parameter]\"` | [Reason based on specific findings] |\n| 2 | `/sourceatlas:[command] \"[parameter]\"` | [Reason based on specific findings] |\n\nüí° Enter a number (e.g., `1`) or copy the command to execute\n```\n\n**Rules:**\n- Only include if there are clear next steps\n- Use actual discovered information (file names, patterns found)\n- Limit to 1-2 suggestions\n- Reference specific findings in Purpose column\n\n---\n\n## Section 9: Additional Notes (Optional)\n\nProject-specific quirks or important context.\n\n```markdown\n## Additional Notes\n\n[Any project-specific quirks, gotchas, or important context that doesn't fit above]\n\n- [Note 1]\n- [Note 2]\n```\n\n---\n\n## Footer Format\n\n```markdown\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.12.0 ‚îÇ Constitution v1.0\n\n‚úÖ Verified: [N] file paths, [M] directories, [K] code snippets\n\nüíæ Saved to .sourceatlas/patterns/[pattern-name].md\n```\n\n---\n\n## Complete Example\n\n```markdown\nüó∫Ô∏è SourceAtlas: Pattern\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüß© API Endpoint ‚îÇ 12 files found\n\n## Overview\n\nThis codebase implements API endpoints using Express.js controllers with a 3-layer architecture: Controller ‚Üí Service ‚Üí Repository. All endpoints follow RESTful conventions and use middleware for auth, validation, and error handling. The pattern emphasizes separation of concerns with clear boundaries between HTTP handling, business logic, and data access.\n\n---\n\n## Best Examples\n\n### 1. src/api/controllers/UserController.ts:45\n\n**Purpose**: Demonstrates RESTful endpoint with authentication middleware\n\n**Key Code**:\n```typescript\n@Controller('/api/users')\nexport class UserController extends BaseController {\n  constructor(private userService: UserService) {\n    super();\n  }\n\n  @Get('/:id')\n  @UseGuards(AuthGuard)\n  async getUser(@Param('id') id: string): Promise<UserResponse> {\n    const user = await this.userService.findById(id);\n    return this.formatResponse(user);\n  }\n}\n```\n\n**Key Points**:\n- Uses decorator-based routing (@Controller, @Get)\n- Extends BaseController for common functionality\n- Injects UserService via constructor\n- Auth guard applied via @UseGuards decorator\n- Async/await pattern for service calls\n\n---\n\n[... rest of sections ...]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüó∫Ô∏è v2.12.0 ‚îÇ Constitution v1.0\n\n‚úÖ Verified: 3 file paths, 4 directories, 5 code snippets\n\nüíæ Saved to .sourceatlas/patterns/api-endpoint.md\n```\n",
        "plugin/commands/pattern/reference.md": "# Pattern Learning Reference\n\nAdvanced features, caching behavior, and best practices.\n\n---\n\n## Cache Behavior\n\n### When Cache is Used\n\n```bash\n# Default: Use cache if exists and fresh\n/sourceatlas:pattern \"api endpoint\"\n\n# Check logic:\npattern_name=\"api-endpoint\"  # sanitized from arguments\ncache_file=\".sourceatlas/patterns/${pattern_name}.md\"\n\nif [ -f \"$cache_file\" ]; then\n  age_days=$(calculate_age_in_days)\n  echo \"üìÅ Loading from cache ($age_days days ago)\"\n  if [ $age_days -gt 30 ]; then\n    echo \"‚ö†Ô∏è Cache over 30 days old, recommend re-analysis\"\n  fi\n  cat \"$cache_file\"\n  exit 0\nfi\n```\n\n### When Cache is Skipped\n\n```bash\n# Force flag: Always skip cache\n/sourceatlas:pattern \"api endpoint\" --force\n# ‚Üí Executes full analysis even if cache exists\n\n# No cache: First time analysis\n# ‚Üí .sourceatlas/patterns/api-endpoint.md doesn't exist yet\n```\n\n### Cache File Naming\n\n```bash\n# Pattern name sanitization\n\"API Endpoint\"     ‚Üí \"api-endpoint.md\"\n\"Background Job\"   ‚Üí \"background-job.md\"\n\"React Component\"  ‚Üí \"react-component.md\"\n\"Very Long Pattern Name...\" ‚Üí \"very-long-pattern-name-that-exceeds-limit.md\" (truncated to 50 chars)\n\n# Rules:\n# - Spaces ‚Üí hyphens\n# - Lowercase\n# - Remove special characters\n# - Truncate to 50 characters\n```\n\n---\n\n## Auto-Save Behavior\n\n### File Structure\n\n```\n.sourceatlas/patterns/\n‚îú‚îÄ‚îÄ api-endpoint.md\n‚îú‚îÄ‚îÄ background-job.md\n‚îú‚îÄ‚îÄ repository-pattern.md\n‚îî‚îÄ‚îÄ custom-hook.md\n```\n\n### Save Timing\n\nAuto-save occurs **immediately after Step V4 verification**:\n\n```yaml\n# After verification passes\nverification_summary:\n  confidence_level: \"high\"\n\n# Then auto-save\nüíæ Saved to .sourceatlas/patterns/api-endpoint.md\n```\n\n### What Gets Saved\n\nComplete Markdown output including:\n- Header with pattern name and file count\n- Overview summary\n- Best Examples (2-3 with code snippets)\n- Key Conventions\n- Testing Pattern\n- Common Pitfalls\n- Step-by-Step Guide\n- Verification summary\n\n**Format:** Full Markdown as specified in [output-template.md](output-template.md)\n\n---\n\n## Handoffs: When to Suggest Next Commands\n\n### After Pattern with Complex Flow\n\nIf pattern involves multi-step execution:\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:flow \"src/api/controllers/UserController.ts\"` | Pattern involves 3-layer architecture, trace full execution flow |\n```\n\n### After Pattern with Wide Usage\n\nIf pattern used in many files:\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:impact \"src/services/BaseService.ts\"` | Pattern used in 23 services, need to understand dependencies |\n```\n\n### After Finding Related Pattern\n\nIf analysis mentions related patterns:\n\n**Suggest:**\n```\n| # | Command | Purpose |\n|---|---------|---------|\n| 1 | `/sourceatlas:pattern \"repository pattern\"` | Controllers depend on repositories, need to understand that pattern next |\n```\n\n### When to Stop (No Recommendations)\n\n- **Pattern is simple**: Self-contained, no complex dependencies\n- **No clear next steps**: Analysis complete, ready to implement\n- **Analysis depth sufficient**: User already ran 4+ commands\n\n**Output instead:**\n```\n‚úÖ **Pattern analysis complete** - Can start implementation following the Step-by-Step Guide above\n```\n\n---\n\n## Common Verification Errors\n\n### Error 1: Hallucinated File Paths\n\n**Symptom:** File paths that sound plausible but don't exist\n\n**Prevention:**\n- Always use actual search results\n- Never guess file paths\n- Verify each path before including\n\n### Error 2: Outdated Code Snippets\n\n**Symptom:** Code snippet doesn't match current file\n\n**Recovery:**\n```bash\n# Re-read file\ncat \"path/to/file.ts\"\n\n# Extract fresh snippet\nsed -n '40,55p' \"path/to/file.ts\"\n```\n\n### Error 3: Wrong Line Numbers\n\n**Symptom:** Line number points to wrong content\n\n**Debug:**\n```bash\n# Check file length\nwc -l file.ts\n\n# View lines around claimed line\nsed -n '43,47p' file.ts  # Show 45 ¬±2 lines\n```\n\n**Fix:** Re-read file, find correct line number\n\n---\n\n## Integration with Other Commands\n\nAfter pattern verification, consider:\n- **Pattern involves complex flow** ‚Üí `/sourceatlas:flow \"[entry point]\"`\n- **Pattern used in many files** ‚Üí `/sourceatlas:impact \"[core file]\"`\n- **Related pattern found** ‚Üí `/sourceatlas:pattern \"[related pattern]\"`\n",
        "plugin/commands/pattern/verification-guide.md": "# Pattern Learning Self-Verification Guide\n\nComplete verification checklist to ensure pattern analysis accuracy.\n\n---\n\n## When to Verify\n\nExecute after completing your pattern analysis, before outputting final results.\n\n---\n\n## Verification Steps\n\n### Step V1: Extract Verifiable Claims\n\nParse your analysis output to identify all **quantifiable claims**:\n\n```yaml\nverifiable_claims:\n  - \"path/to/file.ts:45 contains pattern\"\n  - \"Found 12 files matching pattern\"\n  - \"Controllers placed in app/controllers/ directory\"\n  - \"Code snippet from UserController.ts\"\n```\n\n**Extract these for verification:**\n- File paths (with line numbers)\n- Directory paths\n- Code snippets (must match actual file content)\n- File counts (\"12 files found\")\n- Pattern-specific claims (naming conventions, structure)\n\n---\n\n### Step V2: Parallel Verification Execution\n\nRun verification commands in **parallel** for speed:\n\n#### V2.1: Verify File Paths\n\n```bash\n# Check all file paths in \"Best Examples\" section\nfor path in \"src/api/controllers/UserController.ts\" \"src/services/UserService.ts\"; do\n    if [ ! -f \"$path\" ]; then\n        echo \"‚ùå FILE_NOT_FOUND: $path\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All referenced file paths exist\n- ‚ö†Ô∏è If file not found ‚Üí Search for similar path or remove example\n\n#### V2.2: Verify Line Numbers\n\n```bash\n# Verify line number references\nfile=\"src/api/controllers/UserController.ts\"\nclaimed_line=45\n\n# Check if line exists\ntotal_lines=$(wc -l < \"$file\" 2>/dev/null)\nif [ $claimed_line -gt $total_lines ]; then\n    echo \"‚ö†Ô∏è LINE_OUT_OF_RANGE: $file:$claimed_line (file has $total_lines lines)\"\nfi\n\n# Spot-check content at that line\nsed -n \"${claimed_line}p\" \"$file\"\n```\n\n**Check:**\n- ‚úÖ Line numbers are within file bounds\n- ‚úÖ Content at line number matches description\n- ‚ö†Ô∏è If line mismatch ‚Üí Re-read file and find correct line\n\n#### V2.3: Verify Code Snippets\n\n```bash\n# Verify code snippet exists in file\nsnippet_key_line=\"async getUser\"\nfile=\"src/api/controllers/UserController.ts\"\n\nif ! grep -q \"$snippet_key_line\" \"$file\" 2>/dev/null; then\n    echo \"‚ùå CODE_NOT_FOUND: '$snippet_key_line' in $file\"\nfi\n```\n\n**Check:**\n- ‚úÖ Key lines from code snippets exist in claimed files\n- ‚úÖ Code syntax is valid (no typos in snippet)\n- ‚ö†Ô∏è If code not found ‚Üí Re-read file and extract correct snippet\n\n#### V2.4: Verify Directory Paths\n\n```bash\n# Verify directory paths in \"Key Conventions\"\nfor dir in \"app/controllers\" \"app/services\" \"app/repositories\"; do\n    if [ ! -d \"$dir\" ]; then\n        echo \"‚ùå DIR_NOT_FOUND: $dir\"\n    fi\ndone\n```\n\n**Check:**\n- ‚úÖ All mentioned directories exist\n- ‚ö†Ô∏è If directory not found ‚Üí Search for similar path or correct claim\n\n#### V2.5: Verify File Counts\n\n```bash\n# Verify \"Found N files\" claim\nclaimed_count=12\nactual_count=$(find . -path \"*/*Controller.ts\" -type f 2>/dev/null | wc -l | tr -d ' ')\n\nif [ \"$actual_count\" != \"$claimed_count\" ]; then\n    echo \"‚ö†Ô∏è COUNT_MISMATCH: claimed $claimed_count, actual $actual_count\"\nfi\n```\n\n**Check:**\n- ‚úÖ File count matches actual search results (¬±2 tolerance)\n- ‚ö†Ô∏è If significant difference ‚Üí Update count\n\n---\n\n### Step V3: Handle Verification Results\n\nBased on verification outcomes:\n\n#### If All Checks Pass ‚úÖ\n\n```yaml\nverification_status:\n  verified: true\n  checks_passed: 5\n  confidence: high\n```\n\nProceed to output.\n\n#### If Minor Issues Found ‚ö†Ô∏è (1-2 checks failed)\n\n**Examples:**\n- Line number off by 1-2 lines\n- File count slightly different (¬±2)\n- Directory path has different name\n\n**Action:**\n1. Correct the specific claims\n2. Re-verify those claims\n3. Add note to output:\n\n```yaml\nverification_notes:\n  - \"Line numbers adjusted after verification\"\n  - \"File count corrected to 14 (was 12)\"\n```\n\n#### If Major Issues Found ‚ùå (3+ checks failed)\n\n**Examples:**\n- Multiple file paths don't exist\n- Code snippets not found in claimed files\n- Directory structure completely different\n\n**Action:**\n1. **STOP** - Do not output current analysis\n2. Re-execute Step 1-4 from [workflow.md](workflow.md)\n3. Use better search patterns\n4. Verify each file before including in examples\n\n---\n\n### Step V4: Verification Summary\n\nAdd to final output (before footer):\n\n```yaml\nverification_summary:\n  timestamp: \"[ISO 8601]\"\n  checks_performed:\n    - \"File paths: ‚úÖ\"\n    - \"Line numbers: ‚úÖ\"\n    - \"Code snippets: ‚úÖ\"\n    - \"Directories: ‚úÖ\"\n    - \"File counts: ‚úÖ\"\n\n  confidence_level: \"high\"  # high|medium|low\n  notes:\n    - \"[Any corrections made]\"\n```\n\n**Confidence Level Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **High** | All 5 checks passed, no corrections |\n| **Medium** | 4/5 checks passed, minor corrections |\n| **Low** | <4 checks passed, major corrections |\n\n---\n\n## Verification Examples\n\n### Example 1: File Path Verification\n\n**Claim:** \"src/api/controllers/UserController.ts:45\"\n\n**Verification:**\n```bash\ntest -f \"src/api/controllers/UserController.ts\"\n# Exit code: 0 (exists)\n```\n\n**Result:** ‚úÖ File exists\n\n**Action:** No correction needed\n\n---\n\n### Example 2: Line Number Verification\n\n**Claim:** \"UserController.ts:45 - async getUser method\"\n\n**Verification:**\n```bash\nsed -n '45p' src/api/controllers/UserController.ts\n# Output: async getUser(@Param('id') id: string): Promise<User> {\n```\n\n**Result:** ‚úÖ Line matches description\n\n**Action:** No correction needed\n\n---\n\n### Example 3: Code Snippet Verification\n\n**Claim:** Code snippet shows `@UseGuards(AuthGuard)`\n\n**Verification:**\n```bash\ngrep -n \"@UseGuards(AuthGuard)\" src/api/controllers/UserController.ts\n# Output: 46:  @UseGuards(AuthGuard)\n```\n\n**Result:** ‚ö†Ô∏è Line number slightly off (46 vs 45)\n\n**Action:**\n- Update reference to line 46\n- Or expand snippet to show lines 45-46\n- Note: \"Line number adjusted\"\n\n---\n\n### Example 4: Non-existent File\n\n**Claim:** \"src/api/controllers/AdminController.ts example\"\n\n**Verification:**\n```bash\ntest -f \"src/api/controllers/AdminController.ts\"\n# Exit code: 1 (not found)\n\n# Search for similar\nfind . -name \"*Admin*Controller*\" 2>/dev/null\n# Output: src/admin/controllers/AdminController.ts\n```\n\n**Result:** ‚ùå File path incorrect\n\n**Action:**\n- Update path to correct location\n- Or remove example if file doesn't exist\n- Note: \"File path corrected\"\n\n---\n\n### Example 5: Directory Structure Claim\n\n**Claim:** \"Controllers placed in app/controllers/\"\n\n**Verification:**\n```bash\ntest -d \"app/controllers\"\n# Exit code: 1 (not found)\n\n# Search for controllers directory\nfind . -type d -name \"controllers\" 2>/dev/null | head -5\n# Output:\n# ./src/api/controllers\n# ./packages/backend/controllers\n```\n\n**Result:** ‚ùå Directory path incorrect\n\n**Action:**\n- Update claim: \"Controllers placed in src/api/controllers/\"\n- Note: \"Directory path corrected\"\n\n---\n\n## Error Recovery\n\n### If Verification Script Fails\n\n```bash\n# If file not found\n# ‚Üí Use find to search\nfind . -name \"UserController*\" 2>/dev/null\n\n# If grep fails\n# ‚Üí File might be binary or very large\nfile \"$filepath\"\n\n# If wc fails\n# ‚Üí File might not exist\ntest -f \"$filepath\" || echo \"File missing\"\n```\n\n### If Code Snippet Doesn't Match\n\n**Likely causes:**\n1. Line number off by a few lines\n2. Code was recently refactored\n3. Wrong file referenced\n\n**Action:**\n1. Re-read the entire file\n2. Search for key functions/patterns\n3. Extract fresh snippet with correct line numbers\n\n---\n\n### If Many Files Don't Exist\n\n**Likely causes:**\n1. Analyzing wrong directory\n2. Patterns were from different project\n3. Files were moved/deleted\n\n**Action:**\n1. Verify current directory: `pwd`\n2. Check git status: `git status`\n3. Re-run pattern search from Step 1\n4. Only include files that currently exist\n\n---\n\n## Best Practices\n\n1. **Always verify file paths** - Files may be moved/renamed\n2. **Sample at least 3 code snippets** - Ensures they're from actual code\n3. **Check line numbers** - Code changes, line numbers shift\n4. **Verify directory structure** - Projects reorganize over time\n5. **Note all corrections** - Transparency builds trust\n\n---\n\n## Verification Checklist\n\nBefore finalizing output, confirm:\n\n- [ ] All file paths in \"Best Examples\" verified to exist\n- [ ] All line number references checked (within file bounds)\n- [ ] All code snippets verified against actual files\n- [ ] All directory paths in \"Key Conventions\" verified\n- [ ] File counts verified (¬±2 tolerance acceptable)\n- [ ] No placeholder values like \"[file]\" or \"[path]\" in output\n\n---\n\n## Handoff to Next Steps\n\nAfter verification:\n- ‚úÖ If confidence HIGH ‚Üí Proceed to output\n- ‚ö†Ô∏è If confidence MEDIUM ‚Üí Include verification notes, warn user\n- ‚ùå If confidence LOW ‚Üí Re-execute entire analysis\n\nSee [reference.md#handoffs](reference.md#handoffs) for when to suggest next commands.\n",
        "plugin/commands/pattern/workflow.md": "# Pattern Learning Workflow\n\nComplete step-by-step guide for learning design patterns from the codebase.\n\n---\n\n## Overview\n\nThis workflow helps you understand how the current codebase implements specific patterns by:\n1. Finding 2-3 best example files (high-entropy priority)\n2. Analyzing implementation details\n3. Extracting conventions and best practices\n4. Providing actionable implementation guidance\n\n**Time Budget**: 5-10 minutes total\n\n---\n\n## Step 0: Parse Output Mode (10 seconds)\n\n### Detect Output Mode Parameter\n\nParse `$ARGUMENTS` for mode flags:\n\n```bash\n# Check for --brief\nif echo \"$ARGUMENTS\" | grep -q \"\\-\\-brief\"; then\n    OUTPUT_MODE=\"brief\"\n# Check for --full\nelif echo \"$ARGUMENTS\" | grep -q \"\\-\\-full\"; then\n    OUTPUT_MODE=\"full\"\nelse\n    OUTPUT_MODE=\"smart\"  # Default\nfi\n```\n\n### Mode Behaviors\n\n| Mode | Behavior | Use Case |\n|------|----------|----------|\n| **--brief** | List files only, no analysis | Quick file browser |\n| **--full** | Analyze all found files | Deep learning session |\n| **smart** (default) | ‚â§5 files ‚Üí full; >5 ‚Üí show selection UI | Balanced approach |\n\n---\n\n## Step 1: Execute Pattern Detection (1-2 minutes)\n\n### Use find-patterns.sh Script\n\n**Priority: Try script first** (tested, optimized, fast):\n\n```bash\n# Locate script (global ‚Üí local fallback)\nSCRIPT_PATH=\"\"\nif [ -f ~/.claude/scripts/atlas/find-patterns.sh ]; then\n    SCRIPT_PATH=~/.claude/scripts/atlas/find-patterns.sh\nelif [ -f scripts/atlas/find-patterns.sh ]; then\n    SCRIPT_PATH=scripts/atlas/find-patterns.sh\nfi\n\n# Execute if found\nif [ -n \"$SCRIPT_PATH\" ]; then\n    bash \"$SCRIPT_PATH\" \"$ARGUMENTS\"\nelse\n    echo \"‚ö†Ô∏è find-patterns.sh not found, falling back to manual search\"\nfi\n```\n\n### Script Output Format\n\n```\nsrc/api/controllers/user_controller.ts ‚≠ê‚≠ê‚≠ê\nsrc/api/controllers/order_controller.ts ‚≠ê‚≠ê‚≠ê\nsrc/api/controllers/payment_controller.ts ‚≠ê‚≠ê\n...\n```\n\n**Ranking criteria:**\n- ‚≠ê‚≠ê‚≠ê Exact filename match + relevant directory\n- ‚≠ê‚≠ê Filename match OR relevant directory\n- ‚≠ê Partial match\n\n### Supported Predefined Patterns\n\nThe script recognizes these patterns:\n\n**Backend patterns:**\n- api endpoint / api / endpoint\n- background job / job / queue\n- file upload / upload / file storage\n- database query / database / query\n- authentication / auth / login\n- middleware\n- service object\n- repository\n\n**Frontend patterns:**\n- react component / component\n- custom hook / hook\n- swiftui view / view\n- view controller / viewcontroller\n\n**Infrastructure:**\n- networking / network\n- caching / cache\n\n### Fallback: Manual Search\n\nIf script returns \"Unknown pattern\" or not found:\n\n```bash\n# Extract keywords from pattern\n# Example: \"video learning progress\" ‚Üí keywords: video, learning, progress\n\n# Search by filename\nfind . -type f \\( -name \"*video*\" -o -name \"*learning*\" -o -name \"*progress*\" \\) \\\n    -not -path \"*/node_modules/*\" \\\n    -not -path \"*/.venv/*\" \\\n    -not -path \"*/Pods/*\" \\\n    2>/dev/null | head -20\n\n# Search by content\ngrep -rl \"video.*progress\\|learning.*video\" --include=\"*.ts\" --include=\"*.swift\" --include=\"*.py\" . | \\\n    grep -v node_modules | head -20\n```\n\n---\n\n## Step 1.5: ast-grep Enhanced Search (Optional)\n\n### When to Use\n\nFor **Type B patterns** (content-based, not filename-based):\n\n| Pattern Type | Examples | Tool |\n|--------------|----------|------|\n| **Type A**: Filename is pattern | ViewModel, Service, Repository | grep/find sufficient |\n| **Type B**: Requires content analysis | async/await, suspend functions, decorators | ast-grep better |\n\n### Use ast-grep-search.sh Script\n\n```bash\n# Locate script\nAST_SCRIPT=\"\"\nif [ -f ~/.claude/scripts/atlas/ast-grep-search.sh ]; then\n    AST_SCRIPT=~/.claude/scripts/atlas/ast-grep-search.sh\nelif [ -f scripts/atlas/ast-grep-search.sh ]; then\n    AST_SCRIPT=scripts/atlas/ast-grep-search.sh\nfi\n\n# Examples for different languages\n\n# Swift async functions\n$AST_SCRIPT pattern \"async\" --lang swift --path .\n\n# Kotlin suspend functions\n$AST_SCRIPT pattern \"suspend\" --lang kotlin --path .\n\n# TypeScript custom hooks (use* prefix)\n$AST_SCRIPT pattern \"hook\" --lang tsx --path .\n\n# Go goroutines\n$AST_SCRIPT pattern \"goroutine\" --lang go --path .\n```\n\n### Performance Data\n\nBased on integration tests:\n\n| Pattern | False Positive Reduction |\n|---------|-------------------------|\n| TypeScript custom hooks | 93% |\n| Kotlin suspend functions | 51% |\n| Kotlin data classes | 15% |\n| Swift async functions | 14% |\n\n### Graceful Degradation\n\n```bash\n# If ast-grep not installed, get fallback command\n$AST_SCRIPT pattern \"async\" --fallback\n# Returns: grep equivalent command to use\n```\n\n---\n\n## Step 2: Apply Output Mode Logic (30 seconds)\n\n### Count Files Found\n\n```bash\nFILE_COUNT=$(wc -l < /tmp/pattern-results.txt | tr -d ' ')\n```\n\n### Smart Mode Decision\n\n```python\nif FILE_COUNT == 0:\n    ‚Üí Output \"No matching files found\"\n    ‚Üí Suggest alternative patterns\n    ‚Üí END\n\nelif FILE_COUNT <= 5:\n    ‚Üí Proceed to Step 3 (full analysis)\n\nelse:  # FILE_COUNT > 5\n    ‚Üí Show selection interface\n    ‚Üí Wait for user input\n```\n\n### Selection Interface\n\n```markdown\nFound {FILE_COUNT} related files, please select files to analyze:\n\n| # | File Path | Relevance |\n|---|-----------|-----------|\n| 1 | src/api/controllers/user_controller.ts | ‚≠ê‚≠ê‚≠ê |\n| 2 | src/api/controllers/order_controller.ts | ‚≠ê‚≠ê‚≠ê |\n| 3 | src/api/controllers/payment_controller.ts | ‚≠ê‚≠ê |\n...\n\n**Options:**\n- Enter numbers separated by commas (e.g., `1,2,3`)\n- Enter \"all\" to analyze all files\n- Enter \"top3\" to analyze top 3 only\n```\n\n### Brief Mode (--brief)\n\nIf `--brief` flag detected:\n\n```markdown\nFound {FILE_COUNT} files matching pattern:\n\n1. src/api/controllers/user_controller.ts ‚≠ê‚≠ê‚≠ê\n2. src/api/controllers/order_controller.ts ‚≠ê‚≠ê‚≠ê\n...\n\nUse `/sourceatlas:pattern \"{pattern}\" --full` to analyze all files\nOr specify file numbers: `/sourceatlas:pattern \"{pattern}\" 1,2,3`\n```\n\nThen **END** (no further analysis).\n\n### Full Mode (--full)\n\nIf `--full` flag detected:\n- Bypass selection interface\n- Proceed to analyze ALL found files\n- Warn if >10 files: \"Analyzing {N} files, this may take longer...\"\n\n---\n\n## Step 3: Analyze Selected Files (3-5 minutes)\n\n### High-Entropy File Priority\n\nRead files in relevance order (top-ranked first):\n\n**What to prioritize:**\n- ‚úÖ Main implementation files (controllers, services, handlers)\n- ‚úÖ Complete examples (100-500 lines ideal)\n- ‚úÖ Well-structured, production code\n- ‚ùå NOT: Helper utilities, trivial code, generated files\n\n### Reading Strategy\n\nFor each selected file:\n\n```bash\n# Read file\ncat \"path/to/file.ts\"\n\n# Focus on:\n# 1. Class/function structure\n# 2. Imports/dependencies\n# 3. Main execution flow\n# 4. Error handling patterns\n# 5. Configuration patterns\n```\n\n### Analysis Focus Areas\n\n**1. Overall Structure**\n- How is code organized? (classes, functions, modules)\n- What's the typical file length?\n- How are concerns separated?\n\n**2. Standard Flow**\n- What's the typical execution path?\n- How do components interact?\n- What's the lifecycle?\n\n**3. Naming Conventions**\n- Variable naming: camelCase, snake_case, PascalCase?\n- File naming: UserService.ts vs user_service.py?\n- Directory structure patterns?\n\n**4. Dependencies**\n- What libraries/frameworks are imported?\n- How are dependencies injected?\n- Configuration management approach?\n\n**5. Error Handling**\n- Try/catch patterns?\n- Error types/classes used?\n- Error propagation strategy?\n\n**6. Testing Patterns**\n- Where are tests located?\n- Testing framework used?\n- Coverage approach?\n\n---\n\n## Step 4: Extract the Pattern (2 minutes)\n\n### Pattern Summary (2-3 sentences)\n\nAnswer:\n- How does THIS codebase handle this pattern?\n- What makes it unique to this project?\n- What's the high-level approach?\n\nExample:\n```\nThis codebase implements API endpoints using Express.js controllers\nwith a 3-layer architecture: Controller ‚Üí Service ‚Üí Repository.\nAll endpoints follow RESTful conventions and use middleware for\nauth, validation, and error handling.\n```\n\n### Standard Flow (Numbered Steps)\n\nDocument the typical execution path:\n\n```\n1. Request hits route ‚Üí routes/users.ts\n2. Middleware stack executes (auth, validation)\n3. Controller method called ‚Üí controllers/UserController.ts\n4. Service layer handles business logic ‚Üí services/UserService.ts\n5. Repository accesses database ‚Üí repositories/UserRepository.ts\n6. Response formatted and returned\n```\n\n### Key Conventions (Bullet Points)\n\nList concrete, observable conventions:\n\n```\n- All controllers extend BaseController class\n- Service objects placed in app/services/ directory\n- Use constructor injection for dependencies\n- Error responses follow RFC 7807 format (Problem Details)\n- File naming: PascalCase for classes, camelCase for functions\n```\n\n### Testing Pattern\n\nDescribe how this pattern is tested:\n\n```\n**Test Location:** tests/integration/api/\n\n**Testing Approach:**\n- Supertest for API integration tests\n- Jest for unit testing controllers\n- Mocks for service layer using jest.mock()\n- Test database setup/teardown in beforeEach/afterEach\n\n**Example test:** tests/integration/api/users.test.ts\n```\n\n### Common Pitfalls\n\nIdentify from code observations:\n\n```\n1. Don't call services directly from routes - use controllers\n2. Don't put business logic in controllers - use services\n3. Don't forget to sanitize user input - use validators\n```\n\n---\n\n## Step 5: Find Related Tests (1 minute, optional)\n\n### Locate Test Files\n\n```bash\n# Find test directories\nfind . \\( -path \"*/test/*\" -o -path \"*/tests/*\" -o -path \"*/spec/*\" \\\n         -o -path \"*/__tests__/*\" \\) -type d \\\n    -not -path \"*/node_modules/*\" \\\n    2>/dev/null | head -10\n\n# Find test files by extension\nfind . \\( -name \"*.test.*\" -o -name \"*.spec.*\" \\) -type f \\\n    -not -path \"*/node_modules/*\" \\\n    2>/dev/null | head -20\n```\n\n### Search for Pattern-Related Tests\n\n```bash\n# Example: Search for \"UserController\" tests\ngrep -rn \"UserController\\|user.*controller\" \\\n    --include=\"*.test.*\" --include=\"*.spec.*\" \\\n    tests/ 2>/dev/null | head -10\n```\n\n---\n\n## Step 6: Generate Implementation Guide (1 minute)\n\n### Create Step-by-Step Guide\n\nBased on analysis, provide concrete steps:\n\n```\n## Step-by-Step Implementation Guide\n\nTo implement a new API endpoint following this codebase's pattern:\n\n1. **Create route definition**\n   - File: src/routes/[resource].ts\n   - Add route: router.get('/api/resource', controller.method)\n\n2. **Create controller**\n   - File: src/controllers/[Resource]Controller.ts\n   - Extend BaseController\n   - Implement method with request validation\n\n3. **Create service**\n   - File: src/services/[Resource]Service.ts\n   - Implement business logic\n   - Use dependency injection for repositories\n\n4. **Create repository** (if database access needed)\n   - File: src/repositories/[Resource]Repository.ts\n   - Use ORM (e.g., Sequelize)\n\n5. **Add tests**\n   - File: tests/integration/api/[resource].test.ts\n   - Test happy path and error cases\n```\n\n---\n\n## Error Handling\n\n### Issue: Pattern Not Recognized by Script\n\n**Symptom:** Script returns \"Unknown pattern\"\n\n**Action:**\n1. Inform user about unsupported pattern\n2. Suggest similar supported patterns\n3. Fall back to manual search using keywords\n4. Still provide analysis based on findings\n\n---\n\n### Issue: No Files Found\n\n**Symptom:** 0 results from search\n\n**Action:**\n```\n‚ö†Ô∏è No files found matching pattern: \"{pattern}\"\n\nPossible reasons:\n- Pattern doesn't exist in this codebase\n- Using different naming conventions\n- Pattern is in language we didn't search\n\nSuggestions:\n- Try related patterns: [list similar patterns]\n- Check documentation or ask team members\n- Use different keywords: [suggest alternatives]\n```\n\n---\n\n### Issue: Pattern Too Generic\n\n**Symptom:** >50 files found, too broad\n\n**Action:**\n```\n‚ö†Ô∏è Found {N} files for pattern \"{pattern}\" - too generic\n\nPlease specify a more specific pattern:\n- Instead of \"service\", try \"payment service\" or \"email service\"\n- Instead of \"component\", try \"react component\" or \"button component\"\n- Instead of \"controller\", try \"api controller\" or \"admin controller\"\n```\n\n---\n\n### Issue: Files Are Test Files\n\n**Symptom:** Top results are all test files\n\n**Action:**\n- Filter out test files from ranking\n- Look for production implementation files\n- Note: \"Found mostly test files, looking for production code...\"\n\n```bash\n# Exclude test files from search\ngrep -v \"\\.test\\.\" results.txt | grep -v \"\\.spec\\.\" | grep -v \"/test/\" | grep -v \"/tests/\"\n```\n\n---\n\n## Output Generation Tips\n\n### Best Examples Section\n\n```markdown\n### 1. src/api/controllers/UserController.ts:45\n\n**Purpose**: Demonstrates RESTful endpoint with auth middleware\n\n**Key Code**:\n```typescript\n@Get('/api/users/:id')\n@UseGuards(AuthGuard)\nasync getUser(@Param('id') id: string): Promise<User> {\n  return await this.userService.findById(id);\n}\n```\n\n**Key Points**:\n- Uses decorator-based routing\n- Auth guard applied via @UseGuards\n- Async/await for service calls\n- TypeScript types for request/response\n```\n\n### Key Conventions Section\n\nBe specific and observable:\n\n```markdown\n## Key Conventions\n\n- **All controllers extend BaseController** - provides common methods (found in: src/common/BaseController.ts)\n- **Service objects use constructor injection** - e.g., constructor(private userRepo: UserRepository)\n- **Error responses follow RFC 7807** - {type, title, status, detail, instance}\n- **File structure**: controllers/ ‚Üí services/ ‚Üí repositories/\n```\n\n---\n\n## Performance Optimization\n\n### For Large Codebases\n\n```bash\n# Limit search depth\nfind . -maxdepth 5 -name \"*controller*\" ...\n\n# Limit results\n... | head -20\n\n# Exclude large directories early\nfind . -path \"*/vendor\" -prune -o -path \"*/dist\" -prune -o ...\n```\n\n### For Monorepos\n\n```bash\n# Search specific package only\nfind packages/api -name \"*controller*\" ...\n\n# Or multiple related packages\nfind packages/{api,core} -name \"*controller*\" ...\n```\n\n---\n\n## Integration with Other Commands\n\nAfter pattern analysis, suggest:\n- **Complex flow found** ‚Üí `/sourceatlas:flow \"[entry point]\"`\n- **Pattern used widely** ‚Üí `/sourceatlas:impact \"[core file]\"`\n- **Related pattern mentioned** ‚Üí `/sourceatlas:pattern \"[related pattern]\"`\n",
        "plugin/skills/code-flow-tracer/SKILL.md": "---\nname: code-flow-tracer\ndescription: Trace code execution paths and data flow. Use when user asks \"how does X work\", \"what happens when X\", \"trace the flow of X\", \"where does data come from\", or needs to understand feature implementation.\n---\n\n# Code Flow Tracer\n\n## When to Use\n\nTrigger this skill when the user:\n- Wants to understand how a feature works end-to-end\n- Asks what happens when an action is triggered\n- Needs to trace data flow through the system\n- Asks \"how does X work\"\n- Asks \"what calls X\" or \"what does X call\"\n\n## Instructions\n\n1. Identify the feature, function, or flow the user wants to trace\n2. Run `/sourceatlas:flow \"<query>\"` with a natural language description\n3. Returns call graph, boundary detection, and flow visualization\n\n## Query Formats\n\n- Feature flow: `/sourceatlas:flow \"user login\"`\n- Function trace: `/sourceatlas:flow \"handleSubmit\"`\n- Error paths: `/sourceatlas:flow \"error handling flow\"`\n- Data origin: `/sourceatlas:flow \"where does userProfile come from\"`\n- Reverse trace: `/sourceatlas:flow \"who calls validateToken\"`\n\n## What User Gets\n\n- Call graph visualization (ASCII tree)\n- Boundary detection (API, DB, LIB, CLOUD markers)\n- Recursion and cycle detection\n- Entry points identification\n- 11 analysis modes available\n\n## Example Triggers\n\n- \"How does the login flow work?\"\n- \"What happens when user clicks submit?\"\n- \"Trace the checkout process\"\n- \"Where does this data come from?\"\n- \"Who calls this function?\"\n",
        "plugin/skills/codebase-overview/SKILL.md": "---\nname: codebase-overview\ndescription: Quickly understand a new codebase's architecture, tech stack, and patterns. Use when user asks \"what is this project\", \"project overview\", \"how is this codebase structured\", \"what tech stack\", or when onboarding to a new codebase.\n---\n\n# Codebase Overview\n\n## When to Use\n\nTrigger this skill when the user:\n- Asks about project structure or architecture\n- Is new to a codebase and needs orientation\n- Wants to understand tech stack or patterns used\n- Asks \"what is this project about\"\n- Asks \"how is this organized\"\n\n## Instructions\n\n1. Run `/sourceatlas:overview` to analyze the codebase\n2. This scans <5% of high-entropy files (configs, READMEs, models)\n3. Returns project fingerprint, architecture hypotheses, and AI collaboration level\n\n## What User Gets\n\n- Project type and scale\n- Tech stack identification\n- Architecture patterns with confidence levels\n- Code quality signals\n- Recommended next steps\n\n## Example Triggers\n\n- \"I just joined this project, where do I start?\"\n- \"What's the architecture of this codebase?\"\n- \"Give me an overview of this project\"\n- \"What tech stack does this use?\"\n",
        "plugin/skills/dependency-analyzer/SKILL.md": "---\nname: dependency-analyzer\ndescription: Analyze dependencies for upgrade planning and migration. Use when user asks \"upgrade to X\", \"migrate from X to Y\", \"what breaks if we upgrade\", \"iOS 17 migration\", \"React 18 upgrade\", or planning framework/SDK upgrades.\n---\n\n# Dependency Analyzer\n\n## When to Use\n\nTrigger this skill when the user:\n- Is planning a framework or SDK upgrade\n- Wants to know migration effort for version changes\n- Asks about deprecated APIs or breaking changes\n- Needs to audit usage of a specific library\n- Asks \"how much work to upgrade X\"\n\n## Instructions\n\n1. Identify the upgrade path or library to analyze\n2. Run `/sourceatlas:deps \"<upgrade>\"` with the migration description\n3. Returns deprecated APIs, breaking changes, and migration checklist\n\n## Command Formats\n\n- iOS upgrade: `/sourceatlas:deps \"iOS 16 ‚Üí 17\"`\n- Android: `/sourceatlas:deps \"Android API 35\"`\n- React: `/sourceatlas:deps \"React 17 ‚Üí 18\"`\n- Python: `/sourceatlas:deps \"Python 3.11 ‚Üí 3.12\"`\n- Library audit: `/sourceatlas:deps \"kotlinx.coroutines\"`\n\n## What User Gets\n\n- Phase 0 Rule Confirmation (preview before scanning)\n- Required Changes: Removable checks, deprecated APIs\n- Modernization Opportunities: New features available\n- Usage Summary: All API usage with file:line references\n- Third-party compatibility\n- Migration Checklist with effort estimates\n\n## Example Triggers\n\n- \"We need to upgrade to iOS 17, how much work?\"\n- \"What breaks if we upgrade React to 18?\"\n- \"Plan the Python 3.12 migration\"\n- \"Check our usage of AFNetworking\"\n- \"How hard is the Swift 6 migration?\"\n",
        "plugin/skills/history-analyzer/SKILL.md": "---\nname: history-analyzer\ndescription: Analyze git history for hotspots, coupling, and knowledge distribution. Use when user asks \"who knows this code\", \"what files change most\", \"hotspots\", \"bus factor\", \"knowledge silos\", or needs to understand code evolution.\n---\n\n# History Analyzer\n\n## When to Use\n\nTrigger this skill when the user:\n- Wants to find code hotspots (frequently changed files)\n- Needs to identify who knows specific code areas\n- Asks about bus factor or knowledge distribution\n- Wants to find hidden coupling between files\n- Asks \"who should I ask about X\"\n\n## Instructions\n\n1. Run `/sourceatlas:history` for the entire repo, or `/sourceatlas:history <path>` for specific directory\n2. Optionally specify time range: `/sourceatlas:history . 6` for last 6 months\n3. Returns hotspots, coupling analysis, and contributor distribution\n\n## Command Formats\n\n- Full repo: `/sourceatlas:history`\n- Specific directory: `/sourceatlas:history src/`\n- With time range: `/sourceatlas:history . 6` (last 6 months)\n\n## What User Gets\n\n- Hotspots: Files with most changes (complexity indicators)\n- Temporal Coupling: Files that always change together (hidden dependencies)\n- Recent Contributors: Who knows what areas\n- Bus Factor Risk: Single-contributor files\n- Priority actions for refactoring\n\n## Example Triggers\n\n- \"What are the hotspots in this codebase?\"\n- \"Who knows the payment module best?\"\n- \"What files always change together?\"\n- \"Is there any bus factor risk?\"\n- \"Show me knowledge distribution\"\n",
        "plugin/skills/impact-analyzer/SKILL.md": "---\nname: impact-analyzer\ndescription: Analyze what code will be affected by changes. Use when user asks \"what will break if I change X\", \"impact of changing X\", \"dependencies of X\", \"is it safe to modify X\", or before making significant code changes.\n---\n\n# Impact Analyzer\n\n## When to Use\n\nTrigger this skill when the user:\n- Is about to modify code and wants to know the impact\n- Asks what depends on a file or component\n- Wants to understand breaking change risks\n- Asks \"what will break if I change X\"\n- Asks \"is it safe to modify this\"\n\n## Instructions\n\n1. Identify the file, component, or API the user wants to change\n2. Run `/sourceatlas:impact \"<target>\"` with the target\n3. Returns dependency analysis, risk assessment, and migration checklist\n\n## Target Formats\n\n- File path: `/sourceatlas:impact \"src/api/users.ts\"`\n- API endpoint: `/sourceatlas:impact \"api /api/users/{id}\"`\n- Component: `/sourceatlas:impact \"UserService\"`\n- Model: `/sourceatlas:impact \"User model\"`\n\n## What User Gets\n\n- Impact summary (backend, frontend, test files affected)\n- Risk level assessment (red/yellow/green)\n- Breaking change risks\n- Migration checklist\n- Test coverage gaps\n\n## Example Triggers\n\n- \"What happens if I change this file?\"\n- \"What depends on UserService?\"\n- \"Is it safe to modify the authentication module?\"\n- \"Impact of changing the User model\"\n",
        "plugin/skills/pattern-finder/SKILL.md": "---\nname: pattern-finder\ndescription: Find implementation examples and design patterns in the codebase. Use when user asks \"how to implement X\", \"how does this project do X\", \"show me examples of X\", \"where is X implemented\", or needs to follow existing code conventions.\n---\n\n# Pattern Finder\n\n## When to Use\n\nTrigger this skill when the user:\n- Asks how to implement a specific feature\n- Wants to see existing implementation examples\n- Needs to follow project conventions\n- Asks \"how does this project do X\"\n- Asks \"show me examples of X\"\n\n## Instructions\n\n1. Identify what pattern the user is looking for\n2. Run `/sourceatlas:pattern \"<pattern>\"` with the relevant pattern name\n3. Returns best example files with line numbers and implementation guide\n\n## Common Patterns\n\n- API endpoints: `/sourceatlas:pattern \"api endpoint\"`\n- Authentication: `/sourceatlas:pattern \"authentication\"`\n- Database queries: `/sourceatlas:pattern \"database query\"`\n- Background jobs: `/sourceatlas:pattern \"background job\"`\n- File uploads: `/sourceatlas:pattern \"file upload\"`\n- Error handling: `/sourceatlas:pattern \"error handling\"`\n- Validation: `/sourceatlas:pattern \"validation\"`\n- Testing: `/sourceatlas:pattern \"unit test\"`\n\n## What User Gets\n\n- Best example files with exact line numbers\n- Standard implementation flow\n- Key conventions to follow\n- Common pitfalls to avoid\n- Testing patterns\n\n## Example Triggers\n\n- \"How do I add a new API endpoint?\"\n- \"Show me how authentication works here\"\n- \"Where can I find examples of database queries?\"\n- \"How does this project handle errors?\"\n",
        "plugin/skills/test-default-persistence.md": "---\ndescription: TDD Ê∏¨Ë©¶ÔºöÈªòË™çÂ≠òÂÑ≤ÂäüËÉΩ\n---\n\n# Ê∏¨Ë©¶ÔºöÈªòË™çÂ≠òÂÑ≤\n\nÂü∑Ë°åÊ≠§Ê∏¨Ë©¶‰æÜÈ©óË≠âÈªòË™çÂ≠òÂÑ≤ÂäüËÉΩÊòØÂê¶Ê≠£Â∏∏ÈÅã‰Ωú„ÄÇ\n\n## Ê∏¨Ë©¶Áí∞Â¢ÉÊ∫ñÂÇô\n\n1. Ê∏ÖÈô§Ëàä cache:\n```bash\nrm -rf .sourceatlas/\n```\n\n2. Ë®òÈåÑÊ∏¨Ë©¶ÈñãÂßãÊôÇÈñì:\n```bash\ndate +%s > /tmp/test-start-time\n```\n\n---\n\n## T1: overview Ëá™ÂãïÂ≠òÂÑ≤\n\nÂü∑Ë°å `/atlas.overview` ÂëΩ‰ª§ÔºàÁÑ° --save ÂèÉÊï∏Ôºâ„ÄÇ\n\nÂÆåÊàêÂæåÈ©óË≠â:\n```bash\nif [ -f .sourceatlas/overview.yaml ]; then\n    echo \"‚úÖ T1 PASS: overview.yaml Â∑≤Âª∫Á´ã\"\nelse\n    echo \"‚ùå T1 FAIL: overview.yaml ‰∏çÂ≠òÂú®\"\nfi\n```\n\n---\n\n## T2: --force Ë¶ÜËìã\n\nË®òÈåÑËàäÊôÇÈñìÊà≥:\n```bash\nstat -f %m .sourceatlas/overview.yaml > /tmp/old-mtime\nsleep 2\n```\n\nÂü∑Ë°å `/atlas.overview --force` ÂëΩ‰ª§„ÄÇ\n\nÈ©óË≠â:\n```bash\nnew_mtime=$(stat -f %m .sourceatlas/overview.yaml)\nold_mtime=$(cat /tmp/old-mtime)\nif [ \"$new_mtime\" -gt \"$old_mtime\" ]; then\n    echo \"‚úÖ T2 PASS: Ê™îÊ°àÂ∑≤Ë¶ÜËìã\"\nelse\n    echo \"‚ùå T2 FAIL: Ê™îÊ°àÊú™Êõ¥Êñ∞\"\nfi\n```\n\n---\n\n## T3: --save deprecation\n\nÂü∑Ë°å `/atlas.overview --save` ÂëΩ‰ª§„ÄÇ\n\nÈ©óË≠âËº∏Âá∫ÊòØÂê¶ÂåÖÂê´ deprecation ÊèêÁ§∫Ôºà‰∫∫Â∑•Á¢∫Ë™çÔºâ:\n- ÊáâÁúãÂà∞È°û‰ºº: `‚ö†Ô∏è --save Â∑≤Ê£ÑÁî®ÔºåÁèæÂú®ÈªòË™çÂ≠òÂÑ≤`\n\n---\n\n## T4: pattern Ëá™ÂãïÂ≠òÂÑ≤\n\nÂü∑Ë°å `/atlas.pattern \"api\"` ÂëΩ‰ª§„ÄÇ\n\nÈ©óË≠â:\n```bash\nif [ -f .sourceatlas/patterns/api.md ]; then\n    echo \"‚úÖ T4 PASS: patterns/api.md Â∑≤Âª∫Á´ã\"\nelse\n    echo \"‚ùå T4 FAIL: patterns/api.md ‰∏çÂ≠òÂú®\"\nfi\n```\n\n---\n\n## T5: cache ËºâÂÖ•\n\nÂü∑Ë°å `/atlas.overview` ÂëΩ‰ª§ÔºàÂ∑≤Êúâ cacheÔºâ„ÄÇ\n\nÈ©óË≠âËº∏Âá∫ÊòØÂê¶ÂåÖÂê´ \"Loading cache\"Ôºà‰∫∫Â∑•Á¢∫Ë™çÔºâ:\n- ÊáâÁúãÂà∞È°û‰ºº: `üìÅ Loading cache: .sourceatlas/overview.yaml`\n\n---\n\n## Ê∏¨Ë©¶ÁµêÊûúÂΩôÊï¥\n\nÂü∑Ë°åÂÆåÊâÄÊúâÊ∏¨Ë©¶ÂæåÔºåËº∏Âá∫:\n```bash\necho \"=== Ê∏¨Ë©¶ÁµêÊûú ===\"\necho \"T1: $([ -f .sourceatlas/overview.yaml ] && echo 'PASS' || echo 'FAIL')\"\necho \"T4: $([ -f .sourceatlas/patterns/api.md ] && echo 'PASS' || echo 'FAIL')\"\necho \"T2, T3, T5: Ë´ã‰∫∫Â∑•Á¢∫Ë™ç‰∏äËø∞Ëº∏Âá∫\"\n```\n"
      },
      "plugins": [
        {
          "name": "sourceatlas",
          "source": "./plugin",
          "description": "AI-powered codebase understanding assistant. Learn design patterns, analyze impact, trace code flows, and understand any codebase through information theory principles.",
          "version": "2.11.0",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add lis186/SourceAtlas",
            "/plugin install sourceatlas@lis186-SourceAtlas"
          ]
        }
      ]
    }
  ]
}