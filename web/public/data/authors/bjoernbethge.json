{
  "author": {
    "id": "bjoernbethge",
    "display_name": "_bj03rn_",
    "avatar_url": "https://avatars.githubusercontent.com/u/8515720?u=02ce4b53b4b7e6e48bcffa9049f4988f2342f708&v=4"
  },
  "marketplaces": [
    {
      "name": "mcp-code-execution-marketplace",
      "version": null,
      "description": "Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99%.",
      "repo_full_name": "bjoernbethge/mcp-code-execution",
      "repo_url": "https://github.com/bjoernbethge/mcp-code-execution",
      "repo_description": "Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99% through progressive tool disclosure and in-environment processing.",
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-18T13:27:35Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"mcp-code-execution-marketplace\",\n  \"metadata\": {\n    \"description\": \"Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99%.\"\n  },\n  \"owner\": {\n    \"name\": \"bjoernbethge\",\n    \"url\": \"https://github.com/bjoernbethge\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"mcp-code-execution\",\n      \"source\": \"./\",\n      \"description\": \"Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99% through progressive tool disclosure and in-environment processing.\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"mcp-code-execution\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99%.\",\n  \"author\": {\n    \"name\": \"bjoernbethge\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/bjoernbethge/mcp-code-execution\"\n}\n",
        "README.md": "# MCP Code Execution Plugin\n\nToken-efficient MCP server interaction through code execution. Reduces context usage by **95-99%** through progressive tool disclosure and in-environment processing.\n\n## üéØ The Problem\n\n**Traditional Approach (Direct Tool Calling):**\n```\n1. All tool definitions in context window (100k+ tokens)\n2. Large data through context (50k tokens)\n3. Repeated data in chained calls (100k+ tokens)\n```\n**Result:** Slow, expensive, context window limits\n\n**Code Execution Approach:**\n```\n1. Tool definitions on-demand from filesystem (500 tokens)\n2. Data processing in execution environment (0 tokens)  \n3. Only summary back to Claude (1k tokens)\n```\n**Result:** 95-99% token reduction, faster, more scalable\n\n## üìÅ File Structure\n\n```\nclaude_mcp_workspace/\n‚îú‚îÄ‚îÄ mcp_config.json           # MCP Server Configuration\n‚îú‚îÄ‚îÄ pyproject.toml            # Python Dependencies (uv)\n‚îú‚îÄ‚îÄ package.json              # TypeScript Dependencies (bun)\n‚îú‚îÄ‚îÄ tsconfig.json             # TypeScript Config\n‚îú‚îÄ‚îÄ setup_mcp.py              # Python Setup Script\n‚îú‚îÄ‚îÄ setup.ts                  # TypeScript Setup Script (bun)\n‚îú‚îÄ‚îÄ example_task.py           # Example Task with Pattern\n‚îú‚îÄ‚îÄ servers/                   # Auto-generated Server Wrappers\n‚îÇ   ‚îú‚îÄ‚îÄ python/               # Python Server Wrapper\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TEMPLATE.md\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_drive/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ get_document.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ salesforce/\n‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ update_record.py\n‚îÇ   ‚îî‚îÄ‚îÄ typescript/            # TypeScript Server Wrapper\n‚îÇ       ‚îú‚îÄ‚îÄ TEMPLATE.md\n‚îÇ       ‚îú‚îÄ‚îÄ googleDrive/\n‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ index.ts\n‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ getDocument.ts\n‚îÇ       ‚îî‚îÄ‚îÄ salesforce/\n‚îÇ           ‚îú‚îÄ‚îÄ index.ts\n‚îÇ           ‚îî‚îÄ‚îÄ updateRecord.ts\n‚îú‚îÄ‚îÄ skills/                    # Reusable Skills\n‚îÇ   ‚îú‚îÄ‚îÄ python/               # Python Skills\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ example_data_filter.py\n‚îÇ   ‚îî‚îÄ‚îÄ typescript/            # TypeScript Skills\n‚îÇ       ‚îî‚îÄ‚îÄ exampleDataFilter.ts\n‚îú‚îÄ‚îÄ client/                    # MCP Client Libraries\n‚îÇ   ‚îú‚îÄ‚îÄ python.py             # Python Client\n‚îÇ   ‚îî‚îÄ‚îÄ typescript.ts          # TypeScript Client\n‚îî‚îÄ‚îÄ workspace/                 # Working Directory\n    ‚îî‚îÄ‚îÄ .gitkeep\n```\n\n## üöÄ Setup\n\n### 1. Prerequisites\n\n```bash\n# uv for Python Package Management\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nuv --version  # >= 0.1.0\n\n# bun for TypeScript/JavaScript Runtime\ncurl -fsSL https://bun.sh/install | bash\nbun --version  # >= 1.0.0\n\n# Claude Code CLI (included in Claude Pro)\n# Install via: https://docs.claude.com/en/docs/claude-code\n\n# Python for Skills (managed by uv)\npython --version  # >= 3.10\n```\n\n### 2. Initialize Workspace\n\n```bash\n# Clone or create workspace\nmkdir claude_mcp_workspace\ncd claude_mcp_workspace\n\n# Run setup (uses both uv and bun)\npython setup_mcp.py\n\n# Or with bun:\nbun run setup.ts\n\n# Install dependencies\nuv sync          # Python dependencies\nbun install      # TypeScript dependencies\n```\n\n### 3. Configure MCP Servers\n\nEdit `mcp_config.json` for your servers:\n\n```json\n{\n  \"mcpServers\": {\n    \"google-drive\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-gdrive\"],\n      \"env\": {\n        \"GDRIVE_CLIENT_ID\": \"your-client-id.apps.googleusercontent.com\",\n        \"GDRIVE_CLIENT_SECRET\": \"your-secret\"\n      }\n    },\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"./workspace\"]\n    }\n  }\n}\n```\n\n**Available Community Servers:**\n- `@modelcontextprotocol/server-gdrive` - Google Drive\n- `@modelcontextprotocol/server-github` - GitHub\n- `@modelcontextprotocol/server-sqlite` - SQLite DB\n- `@modelcontextprotocol/server-postgres` - PostgreSQL\n- `@modelcontextprotocol/server-filesystem` - Local Files\n\nSee: https://github.com/modelcontextprotocol/servers\n\n### 4. Start Claude Code\n\n```bash\n# In workspace directory\nclaude-code --config mcp_config.json\n```\n\n### 5. Generate Server Wrappers\n\nIn Claude Code Chat:\n\n```\nSetup MCP server wrappers for all configured servers.\n\nFor each server:\n1. List available tools\n2. Generate Python modules in servers/python/{server_name}/\n3. Generate TypeScript modules in servers/typescript/{serverName}/\n4. Create __init__.py / index.ts with exports\n5. Add type hints and docstrings\n```\n\nClaude automatically generates for both languages:\n\n**Python:**\n```\nservers/python/\n‚îú‚îÄ‚îÄ google_drive/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ get_document.py\n‚îÇ   ‚îú‚îÄ‚îÄ list_files.py\n‚îÇ   ‚îî‚îÄ‚îÄ search.py\n‚îî‚îÄ‚îÄ filesystem/\n    ‚îú‚îÄ‚îÄ __init__.py\n    ‚îú‚îÄ‚îÄ read_file.py\n    ‚îî‚îÄ‚îÄ write_file.py\n```\n\n**TypeScript:**\n```\nservers/typescript/\n‚îú‚îÄ‚îÄ googleDrive/\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts\n‚îÇ   ‚îú‚îÄ‚îÄ getDocument.ts\n‚îÇ   ‚îú‚îÄ‚îÄ listFiles.ts\n‚îÇ   ‚îî‚îÄ‚îÄ search.ts\n‚îî‚îÄ‚îÄ filesystem/\n    ‚îú‚îÄ‚îÄ index.ts\n    ‚îú‚îÄ‚îÄ readFile.ts\n    ‚îî‚îÄ‚îÄ writeFile.ts\n```\n\n## üí° Usage\n\n### Example 1: Document Processing\n\n**Task:**\n```\nDownload my Q4 planning document from Google Drive (ID: abc123)\nand extract all action items that start with \"ACTION:\".\nCreate a summary and attach it to Salesforce lead 00Q5f000001xyz.\n```\n\n**Claude writes and executes (Python):**\n\n```python\n# task_document_processing.py\nimport asyncio\nfrom servers.python.google_drive import get_document\nfrom servers.python.salesforce import update_record\n\nasync def main():\n    # 1. Fetch document (stays in execution environment)\n    print(\"Fetching document...\")\n    doc = await get_document(document_id='abc123')\n    \n    # 2. Process data HERE (not through context window)\n    print(f\"Processing {len(doc['content'])} characters...\")\n    lines = doc['content'].split('\\n')\n    actions = [l for l in lines if l.strip().startswith('ACTION:')]\n    \n    summary = f\"\"\"\nQ4 Planning - Action Items ({len(actions)} total)\n\n{chr(10).join(actions[:10])}\n\nFull document: {doc.get('url', 'N/A')}\n    \"\"\".strip()\n    \n    print(f\"Extracted {len(actions)} action items\")\n    print(f\"Summary: {len(summary)} chars (from {len(doc['content'])} original)\")\n    \n    # 3. Update Salesforce with processed summary\n    print(\"Updating Salesforce...\")\n    result = await update_record(\n        object_type='Lead',\n        record_id='00Q5f000001xyz',\n        data={\n            'Notes': summary,\n            'LastActivityDate': '2025-11-06'\n        }\n    )\n    \n    print(\"‚úì Lead updated successfully\")\n    \n    # Token efficiency\n    original_tokens = len(doc['content']) // 4 * 2  # Would pass through twice\n    actual_tokens = len(summary) // 4\n    print(f\"\\nToken savings: {original_tokens:,} ‚Üí {actual_tokens:,} ({(1-actual_tokens/original_tokens)*100:.1f}%)\")\n\nasyncio.run(main())\n```\n\n**Output:**\n```\nFetching document...\nProcessing 47,532 characters...\nExtracted 23 action items\nSummary: 892 chars (from 47,532 original)\nUpdating Salesforce...\n‚úì Lead updated successfully\n\nToken savings: 23,766 ‚Üí 223 (99.1%)\n```\n\n### Example 2: Batch Data Processing\n\n**Task:**\n```\nQuery all leads from Salesforce, filter for high-value (>$50k) pending deals,\ncompute aggregate metrics, and export top 100 to Google Sheets.\n```\n\n**Claude writes (Python):**\n\n```python\n# task_batch_processing.py\nimport asyncio\nfrom servers.python.salesforce import query\nfrom servers.python.google_sheets import update_range\n\nasync def main():\n    # 1. Query all leads (could be 10k+ records)\n    print(\"Querying Salesforce...\")\n    leads = await query(\n        soql=\"SELECT Id, Name, Status, Amount FROM Lead WHERE Status IN ('New', 'Qualified')\"\n    )\n    print(f\"Retrieved {len(leads)} leads\")\n    \n    # 2. Filter and aggregate IN EXECUTION ENVIRONMENT\n    print(\"Processing data...\")\n    high_value = [l for l in leads if l.get('Amount', 0) > 50000]\n    high_value.sort(key=lambda x: x.get('Amount', 0), reverse=True)\n    \n    # Compute metrics\n    total = sum(l.get('Amount', 0) for l in high_value)\n    avg = total / len(high_value) if high_value else 0\n    \n    print(f\"High-value leads: {len(high_value)}\")\n    print(f\"Total value: ${total:,.0f}\")\n    print(f\"Average: ${avg:,.0f}\")\n    \n    # 3. Export top 100 only\n    print(\"Exporting to Google Sheets...\")\n    export_data = [\n        ['Name', 'Amount', 'Status']\n    ] + [\n        [l['Name'], l['Amount'], l['Status']]\n        for l in high_value[:100]\n    ]\n    \n    await update_range(\n        spreadsheet_id='your-sheet-id',\n        range='Sheet1!A1',\n        values=export_data\n    )\n    \n    print(\"‚úì Exported top 100 to sheets\")\n    \n    # Token comparison\n    all_data_size = len(str(leads))\n    exported_size = len(str(export_data))\n    print(f\"\\nData reduction: {all_data_size:,} ‚Üí {exported_size:,} bytes\")\n\nasyncio.run(main())\n```\n\n### Example 3: Skills Building\n\nAfter multiple similar tasks, Claude saves reusable patterns:\n\n```python\n# skills/python/extract_action_items.py\n\"\"\"\nSkill: Extract action items from meeting transcripts\n\nDeveloped through multiple successful executions of document processing tasks.\nProven pattern for filtering action items from various document formats.\n\"\"\"\n\ndef extract_action_items(text: str, prefixes: list[str] = None) -> list[str]:\n    \"\"\"\n    Extract action items from text based on common prefixes.\n    \n    Args:\n        text: Full text content to search\n        prefixes: List of prefixes to identify action items\n                 Default: ['ACTION:', 'TODO:', 'FOLLOW-UP:', '[ ]']\n    \n    Returns:\n        List of action item strings\n    \"\"\"\n    if prefixes is None:\n        prefixes = ['ACTION:', 'TODO:', 'FOLLOW-UP:', '[ ]']\n    \n    lines = text.split('\\n')\n    actions = []\n    \n    for line in lines:\n        stripped = line.strip()\n        if any(stripped.startswith(prefix) for prefix in prefixes):\n            actions.append(stripped)\n    \n    return actions\n```\n\n**Usage in future tasks:**\n\n**Python:**\n```python\nfrom skills.python.extract_action_items import extract_action_items\nfrom servers.python.google_drive import get_document\n\ndoc = await get_document('meeting_notes_xyz')\nactions = extract_action_items(doc['content'])\n```\n\n**TypeScript:**\n```typescript\nimport { extractActionItems } from './skills/typescript/extractActionItems.js';\nimport { getDocument } from './servers/typescript/googleDrive/index.js';\n\nconst doc = await getDocument({ documentId: 'meeting_notes_xyz' });\nconst actions = extractActionItems(doc.content);\n```\n\n## üìä Token Efficiency Comparison\n\n### Scenario: Large Document Processing\n\n**Direct Tool Calling (Traditional):**\n```\n1. Load all tool definitions: 150,000 tokens\n2. TOOL_CALL: get_document() ‚Üí 50,000 tokens in context\n3. TOOL_CALL: update_record(full_doc) ‚Üí 50,000 tokens again\nTotal: 250,000 tokens\nCost: ~$0.75 (Sonnet 4)\n```\n\n**Code Execution (This Approach):**\n```\n1. Read 2 tool definitions from filesystem: 500 tokens\n2. Execute code: Process doc in environment (0 context tokens)\n3. Return summary only: 1,000 tokens\nTotal: 1,500 tokens\nCost: ~$0.005 (Sonnet 4)\nSavings: 99.4%\n```\n\n### Real-World Measurements\n\n| Task Type | Traditional | Code Execution | Savings |\n|-----------|-------------|----------------|---------|\n| Document extraction | 250k tokens | 1.5k tokens | 99.4% |\n| Batch data filtering | 180k tokens | 2k tokens | 98.9% |\n| Multi-step workflow | 320k tokens | 3k tokens | 99.1% |\n| Large dataset analysis | 450k tokens | 5k tokens | 98.9% |\n\n## üèóÔ∏è How It Works\n\n### Progressive Disclosure\n\n**Problem:** Loading all tool definitions upfront overloads context\n**Solution:** Claude loads only what it needs\n\n```python\n# Claude explores filesystem:\n$ ls servers/python/\ngoogle_drive/  salesforce/  github/\n\n# Reads only needed tools:\n$ cat servers/python/google_drive/get_document.py\n# Only this definition is loaded (~250 tokens)\n\n# Import in task:\nfrom servers.python.google_drive import get_document\n```\n\n**TypeScript:**\n```typescript\n// Claude explores filesystem:\n$ ls servers/typescript/\ngoogleDrive/  salesforce/  github/\n\n// Reads only needed tools:\n$ cat servers/typescript/googleDrive/getDocument.ts\n// Only this definition is loaded (~250 tokens)\n\n// Import in task:\nimport { getDocument } from './servers/typescript/googleDrive/index.js';\n```\n\n### Context-Efficient Processing\n\n**Problem:** Large data flows multiple times through context\n**Solution:** Processing in execution environment\n\n```python\n# Data stays in environment:\ndoc = await get_document('huge_file')  # 100k characters\nfiltered = [line for line in doc.split('\\n') if 'ERROR' in line]  # Processing here\nprint(f\"Found {len(filtered)} errors\")  # Only summary to context\n```\n\n### Skills Persistence\n\n**Problem:** Successful patterns must be re-explained\n**Solution:** Claude saves proven implementations\n\n```python\n# After task success:\n\"Save this implementation as a skill for future document processing tasks\"\n\n# Claude creates:\nskills/python/process_meeting_notes.py\n\n# Future tasks:\nfrom skills.python.process_meeting_notes import extract_and_summarize\nresult = await extract_and_summarize(doc_id)  # Instant reuse\n```\n\n**TypeScript:**\n```typescript\n// After task success:\n\"Save this implementation as a skill for future document processing tasks\"\n\n// Claude creates:\nskills/typescript/processMeetingNotes.ts\n\n// Future tasks:\nimport { extractAndSummarize } from './skills/typescript/processMeetingNotes.js';\nconst result = await extractAndSummarize(docId);  // Instant reuse\n```\n\n## üîí Security & Privacy\n\n### Data Flow Control\n\n**Sensitive data stays in execution environment:**\n\n```python\n# PII processing without context exposure:\ncustomer_data = await crm.get_customer('sensitive_id')\n# customer_data stays in environment\n\n# Only aggregates back:\nsummary = {\n    'total_customers': len(customer_data),\n    'avg_value': sum(c['value'] for c in customer_data) / len(customer_data)\n}\nprint(summary)  # Only summary goes to Claude\n```\n\n### Execution Sandboxing\n\nClaude Code runs in a controlled environment:\n- Filesystem access only in workspace\n- Network calls only to configured MCP servers\n- Resource limits (CPU, Memory, Time)\n- No system-level operations\n\n## üéì Best Practices\n\n### 1. Design for Token Efficiency\n\n```python\n# ‚ùå Bad: Everything through context\nall_records = await db.query(\"SELECT * FROM huge_table\")\nfor record in all_records:\n    print(record)  # Each record goes through context\n\n# ‚úÖ Good: Filter and aggregate locally\nall_records = await db.query(\"SELECT * FROM huge_table\")\nfiltered = [r for r in all_records if r['status'] == 'pending']\nsummary = {\n    'total': len(all_records),\n    'pending': len(filtered),\n    'avg_value': sum(r['value'] for r in filtered) / len(filtered)\n}\nprint(summary)  # Only summary goes through context\n```\n\n### 2. Progressive Tool Loading\n\n```python\n# ‚ùå Bad: All imports upfront\nfrom servers.python.google_drive import *\nfrom servers.python.salesforce import *\nfrom servers.python.github import *\n\n# ‚úÖ Good: Import only what's needed\nfrom servers.python.google_drive import get_document\nfrom servers.python.salesforce import update_record\n```\n\n**TypeScript:**\n```typescript\n// ‚ùå Bad: All imports upfront\nimport * from './servers/typescript/googleDrive/index.js';\nimport * from './servers/typescript/salesforce/index.js';\n\n// ‚úÖ Good: Import only what's needed\nimport { getDocument } from './servers/typescript/googleDrive/index.js';\nimport { updateRecord } from './servers/typescript/salesforce/index.js';\n```\n\n### 3. Build Reusable Skills\n\n**Python:**\n```python\n# After successful task:\n# \"Save this data filtering pattern as a reusable skill\"\n\n# Claude creates:\n# skills/python/filter_high_priority.py\ndef filter_high_priority(items, threshold=1000):\n    return [i for i in items if i.get('priority', 0) > threshold]\n\n# Next task can use immediately:\nfrom skills.python.filter_high_priority import filter_high_priority\n```\n\n**TypeScript:**\n```typescript\n// After successful task:\n// \"Save this data filtering pattern as a reusable skill\"\n\n// Claude creates:\n// skills/typescript/filterHighPriority.ts\nexport function filterHighPriority(items: any[], threshold = 1000) {\n  return items.filter(i => (i.priority || 0) > threshold);\n}\n\n// Next task can use immediately:\nimport { filterHighPriority } from './skills/typescript/filterHighPriority.js';\n```\n\n### 4. Explicit Error Handling\n\n```python\n# Fail fast with clear messages:\ntry:\n    doc = await get_document(doc_id)\nexcept Exception as e:\n    print(f\"‚ùå Failed to fetch document {doc_id}: {e}\")\n    # Claude sees clear error, can react\n    return None\n```\n\n## üêõ Troubleshooting\n\n### MCP Server Won't Start\n\n```bash\n# Check Node.js\nnode --version\n\n# Test server manually\nnpx -y @modelcontextprotocol/server-gdrive\n\n# Check config\ncat mcp_config.json\n```\n\n### Import Errors in Tasks\n\n**Python:**\n```python\n# Make sure server wrapper exists:\nls servers/python/google_drive/\n\n# If not, generate:\n# \"Setup MCP server wrappers for google-drive\"\n```\n\n**TypeScript:**\n```bash\n# Make sure server wrapper exists:\nls servers/typescript/googleDrive/\n\n# If not, generate:\n# \"Setup MCP server wrappers for google-drive\"\n```\n\n### Token Usage Still High\n\n```python\n# Check: Are you loading too many tool definitions?\n# Only import what you need\n\n# Check: Are you printing large data?\nprint(large_data)  # ‚ùå Everything goes through context\nprint(f\"Processed {len(large_data)} items\")  # ‚úÖ Only summary\n```\n\n## üîß Hybrid Setup: Python (uv) + TypeScript (bun)\n\nThis project supports both languages for maximum flexibility:\n\n### Why Both?\n\n- **Python (uv)**: Ideal for data processing, ML integration, existing Python tools\n- **TypeScript (bun)**: Fast, modern syntax, perfect for web APIs, type safety\n\n### Usage\n\n**Python Tasks:**\n```python\nfrom servers.python.google_drive import get_document\nfrom skills.python.data_filter import filter_large_dataset\n\ndoc = await get_document('doc_id')\nfiltered = await filter_large_dataset(doc['rows'], 'status', 'active')\n```\n\n**TypeScript Tasks:**\n```typescript\nimport { getDocument } from './servers/typescript/googleDrive/index.js';\nimport { filterLargeDataset } from './skills/typescript/dataFilter.js';\n\nconst doc = await getDocument({ documentId: 'doc_id' });\nconst filtered = await filterLargeDataset(doc.rows, {\n  filterKey: 'status',\n  filterValue: 'active'\n});\n```\n\n### Dependencies Management\n\n```bash\n# Python dependencies (uv)\nuv sync                    # Install all Python packages\nuv add pytest             # Add new dependency\nuv run python script.py    # Run Python script\n\n# TypeScript dependencies (bun)\nbun install               # Install all TypeScript packages\nbun add @types/node       # Add new dependency\nbun run script.ts         # Run TypeScript script\n```\n\n## üìö Resources\n\n- [Anthropic Engineering Blog: Code Execution with MCP](https://www.anthropic.com/engineering/code-execution-with-mcp)\n- [MCP Documentation](https://modelcontextprotocol.io/)\n- [MCP Community Servers](https://github.com/modelcontextprotocol/servers)\n- [Claude Code Documentation](https://docs.claude.com/en/docs/claude-code)\n- [uv Documentation](https://github.com/astral-sh/uv)\n- [bun Documentation](https://bun.sh/docs)\n\n## ü§ù Contributing\n\nSkills and server templates can be shared:\n\n```bash\n# Your proven skills:\nskills/\n‚îú‚îÄ‚îÄ your_domain_skill.py\n‚îî‚îÄ‚îÄ SKILL.md  # Documentation\n\n# Community can use and improve\n```\n\n## üìÑ License\n\nMIT - Use freely, contribute back!\n\n---\n\n**Built with Claude Code + MCP** üöÄ\n\nFollowing Anthropic's patterns for token-efficient AI agent development.\n"
      },
      "plugins": [
        {
          "name": "mcp-code-execution",
          "source": "./",
          "description": "Token-efficient MCP server interaction through code execution. Reduces context usage by 95-99% through progressive tool disclosure and in-environment processing.",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add bjoernbethge/mcp-code-execution",
            "/plugin install mcp-code-execution@mcp-code-execution-marketplace"
          ]
        }
      ]
    }
  ]
}