{
  "author": {
    "id": "existential-birds",
    "display_name": "existential-birds",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/250915402?v=4",
    "url": "https://github.com/existential-birds",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 41,
      "total_skills": 66,
      "total_stars": 15,
      "total_forks": 2
    }
  },
  "marketplaces": [
    {
      "name": "existential-birds",
      "version": null,
      "description": "Beagle plugins and tools for Claude Code",
      "owner_info": {
        "name": "Existential Birds, LLC",
        "email": "tech@existentialbirds.com"
      },
      "keywords": [],
      "repo_full_name": "existential-birds/beagle",
      "repo_url": "https://github.com/existential-birds/beagle",
      "repo_description": "Claude Code plugin for code review skills and verification workflows. Python, Go, React, FastAPI, BubbleTea, and AI frameworks (Pydantic AI, LangGraph, Vercel AI SDK).",
      "homepage": "",
      "signals": {
        "stars": 15,
        "forks": 2,
        "pushed_at": "2026-01-24T16:34:11Z",
        "created_at": "2025-12-21T15:44:12Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 568
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 666
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/release-tag.md",
          "type": "blob",
          "size": 2861
        },
        {
          "path": ".claude/commands/release.md",
          "type": "blob",
          "size": 5307
        },
        {
          "path": ".cursor",
          "type": "tree",
          "size": null
        },
        {
          "path": ".cursor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".cursor/commands/12-factor-apps-analysis.md",
          "type": "blob",
          "size": 18281
        },
        {
          "path": ".cursor/commands/commit-push.md",
          "type": "blob",
          "size": 2805
        },
        {
          "path": ".cursor/commands/create-pr.md",
          "type": "blob",
          "size": 3968
        },
        {
          "path": ".cursor/commands/ensure-docs.md",
          "type": "blob",
          "size": 12670
        },
        {
          "path": ".cursor/commands/fetch-pr-feedback.md",
          "type": "blob",
          "size": 9450
        },
        {
          "path": ".cursor/commands/gen-release-notes.md",
          "type": "blob",
          "size": 5870
        },
        {
          "path": ".cursor/commands/prompt-improver.md",
          "type": "blob",
          "size": 4184
        },
        {
          "path": ".cursor/commands/receive-feedback.md",
          "type": "blob",
          "size": 9729
        },
        {
          "path": ".cursor/commands/respond-pr-feedback.md",
          "type": "blob",
          "size": 4404
        },
        {
          "path": ".cursor/commands/review-frontend.md",
          "type": "blob",
          "size": 24216
        },
        {
          "path": ".cursor/commands/review-go.md",
          "type": "blob",
          "size": 35960
        },
        {
          "path": ".cursor/commands/review-plan.md",
          "type": "blob",
          "size": 11174
        },
        {
          "path": ".cursor/commands/review-python.md",
          "type": "blob",
          "size": 44564
        },
        {
          "path": ".cursor/commands/review-tui.md",
          "type": "blob",
          "size": 20387
        },
        {
          "path": ".cursor/commands/skill-builder.md",
          "type": "blob",
          "size": 10527
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 4135
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/12-factor-apps-analysis.md",
          "type": "blob",
          "size": 2558
        },
        {
          "path": "commands/commit-push.md",
          "type": "blob",
          "size": 2876
        },
        {
          "path": "commands/create-pr.md",
          "type": "blob",
          "size": 4051
        },
        {
          "path": "commands/draft-docs.md",
          "type": "blob",
          "size": 7045
        },
        {
          "path": "commands/ensure-docs.md",
          "type": "blob",
          "size": 12762
        },
        {
          "path": "commands/fetch-pr-feedback.md",
          "type": "blob",
          "size": 2659
        },
        {
          "path": "commands/fix-llm-artifacts.md",
          "type": "blob",
          "size": 5603
        },
        {
          "path": "commands/gen-release-notes.md",
          "type": "blob",
          "size": 5945
        },
        {
          "path": "commands/gen-test-plan.md",
          "type": "blob",
          "size": 9226
        },
        {
          "path": "commands/improve-doc.md",
          "type": "blob",
          "size": 9841
        },
        {
          "path": "commands/llm-judge.md",
          "type": "blob",
          "size": 6943
        },
        {
          "path": "commands/prompt-improver.md",
          "type": "blob",
          "size": 4184
        },
        {
          "path": "commands/receive-feedback.md",
          "type": "blob",
          "size": 1198
        },
        {
          "path": "commands/respond-pr-feedback.md",
          "type": "blob",
          "size": 4492
        },
        {
          "path": "commands/review-frontend.md",
          "type": "blob",
          "size": 3339
        },
        {
          "path": "commands/review-go.md",
          "type": "blob",
          "size": 3472
        },
        {
          "path": "commands/review-ios.md",
          "type": "blob",
          "size": 5242
        },
        {
          "path": "commands/review-llm-artifacts.md",
          "type": "blob",
          "size": 7358
        },
        {
          "path": "commands/review-plan.md",
          "type": "blob",
          "size": 6201
        },
        {
          "path": "commands/review-python.md",
          "type": "blob",
          "size": 4711
        },
        {
          "path": "commands/review-tui.md",
          "type": "blob",
          "size": 4389
        },
        {
          "path": "commands/run-test-plan.md",
          "type": "blob",
          "size": 7248
        },
        {
          "path": "commands/skill-builder.md",
          "type": "blob",
          "size": 10621
        },
        {
          "path": "commands/write-adr.md",
          "type": "blob",
          "size": 7142
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/12-factor-apps",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/12-factor-apps/SKILL.md",
          "type": "blob",
          "size": 18096
        },
        {
          "path": "skills/adr-decision-extraction",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/adr-decision-extraction/SKILL.md",
          "type": "blob",
          "size": 4318
        },
        {
          "path": "skills/adr-writing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/adr-writing/SKILL.md",
          "type": "blob",
          "size": 5811
        },
        {
          "path": "skills/adr-writing/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/adr-writing/references/definition-of-done.md",
          "type": "blob",
          "size": 3564
        },
        {
          "path": "skills/adr-writing/references/madr-template.md",
          "type": "blob",
          "size": 4314
        },
        {
          "path": "skills/agent-architecture-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/agent-architecture-analysis/SKILL.md",
          "type": "blob",
          "size": 15929
        },
        {
          "path": "skills/ai-elements",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-elements/SKILL.md",
          "type": "blob",
          "size": 11225
        },
        {
          "path": "skills/ai-elements/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-elements/references/conversation.md",
          "type": "blob",
          "size": 12053
        },
        {
          "path": "skills/ai-elements/references/prompt-input.md",
          "type": "blob",
          "size": 16330
        },
        {
          "path": "skills/ai-elements/references/visualization.md",
          "type": "blob",
          "size": 12983
        },
        {
          "path": "skills/ai-elements/references/workflow.md",
          "type": "blob",
          "size": 18219
        },
        {
          "path": "skills/app-intents-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/app-intents-code-review/SKILL.md",
          "type": "blob",
          "size": 2288
        },
        {
          "path": "skills/app-intents-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/app-intents-code-review/references/entities.md",
          "type": "blob",
          "size": 5816
        },
        {
          "path": "skills/app-intents-code-review/references/intent-structure.md",
          "type": "blob",
          "size": 4055
        },
        {
          "path": "skills/app-intents-code-review/references/parameters.md",
          "type": "blob",
          "size": 5401
        },
        {
          "path": "skills/app-intents-code-review/references/shortcuts.md",
          "type": "blob",
          "size": 4741
        },
        {
          "path": "skills/bubbletea-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bubbletea-code-review/SKILL.md",
          "type": "blob",
          "size": 4982
        },
        {
          "path": "skills/bubbletea-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bubbletea-code-review/references/bubbles-components.md",
          "type": "blob",
          "size": 12333
        },
        {
          "path": "skills/bubbletea-code-review/references/composition.md",
          "type": "blob",
          "size": 10521
        },
        {
          "path": "skills/bubbletea-code-review/references/elm-architecture.md",
          "type": "blob",
          "size": 7603
        },
        {
          "path": "skills/bubbletea-code-review/references/model-update.md",
          "type": "blob",
          "size": 4634
        },
        {
          "path": "skills/bubbletea-code-review/references/view-styling.md",
          "type": "blob",
          "size": 5217
        },
        {
          "path": "skills/cloudkit-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cloudkit-code-review/SKILL.md",
          "type": "blob",
          "size": 2449
        },
        {
          "path": "skills/cloudkit-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cloudkit-code-review/references/container-setup.md",
          "type": "blob",
          "size": 3933
        },
        {
          "path": "skills/cloudkit-code-review/references/records.md",
          "type": "blob",
          "size": 4741
        },
        {
          "path": "skills/cloudkit-code-review/references/sharing.md",
          "type": "blob",
          "size": 5985
        },
        {
          "path": "skills/cloudkit-code-review/references/subscriptions.md",
          "type": "blob",
          "size": 5619
        },
        {
          "path": "skills/combine-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/combine-code-review/SKILL.md",
          "type": "blob",
          "size": 2074
        },
        {
          "path": "skills/combine-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/combine-code-review/references/error-handling.md",
          "type": "blob",
          "size": 4037
        },
        {
          "path": "skills/combine-code-review/references/memory.md",
          "type": "blob",
          "size": 3464
        },
        {
          "path": "skills/combine-code-review/references/operators.md",
          "type": "blob",
          "size": 3760
        },
        {
          "path": "skills/combine-code-review/references/publishers.md",
          "type": "blob",
          "size": 2904
        },
        {
          "path": "skills/dagre-react-flow",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dagre-react-flow/SKILL.md",
          "type": "blob",
          "size": 10764
        },
        {
          "path": "skills/dagre-react-flow/reference.md",
          "type": "blob",
          "size": 8176
        },
        {
          "path": "skills/deepagents-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/deepagents-architecture/SKILL.md",
          "type": "blob",
          "size": 7815
        },
        {
          "path": "skills/deepagents-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/deepagents-code-review/SKILL.md",
          "type": "blob",
          "size": 13181
        },
        {
          "path": "skills/deepagents-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/deepagents-implementation/SKILL.md",
          "type": "blob",
          "size": 12564
        },
        {
          "path": "skills/deepagents-implementation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/deepagents-implementation/references/patterns.md",
          "type": "blob",
          "size": 2570
        },
        {
          "path": "skills/deepagents-implementation/references/tools.md",
          "type": "blob",
          "size": 1200
        },
        {
          "path": "skills/docling",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/docling/SKILL.md",
          "type": "blob",
          "size": 10309
        },
        {
          "path": "skills/docling/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/docling/references/batch.md",
          "type": "blob",
          "size": 14562
        },
        {
          "path": "skills/docling/references/chunking.md",
          "type": "blob",
          "size": 16207
        },
        {
          "path": "skills/docling/references/output.md",
          "type": "blob",
          "size": 15116
        },
        {
          "path": "skills/docling/references/parsing.md",
          "type": "blob",
          "size": 13269
        },
        {
          "path": "skills/docs-style",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/docs-style/SKILL.md",
          "type": "blob",
          "size": 8245
        },
        {
          "path": "skills/explanation-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/explanation-docs/SKILL.md",
          "type": "blob",
          "size": 15362
        },
        {
          "path": "skills/fastapi-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/fastapi-code-review/SKILL.md",
          "type": "blob",
          "size": 3686
        },
        {
          "path": "skills/fastapi-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/fastapi-code-review/references/async.md",
          "type": "blob",
          "size": 6642
        },
        {
          "path": "skills/fastapi-code-review/references/dependencies.md",
          "type": "blob",
          "size": 5628
        },
        {
          "path": "skills/fastapi-code-review/references/routes.md",
          "type": "blob",
          "size": 4209
        },
        {
          "path": "skills/fastapi-code-review/references/validation.md",
          "type": "blob",
          "size": 5569
        },
        {
          "path": "skills/github-projects",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/github-projects/SKILL.md",
          "type": "blob",
          "size": 6404
        },
        {
          "path": "skills/github-projects/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/github-projects/references/fields.md",
          "type": "blob",
          "size": 6135
        },
        {
          "path": "skills/github-projects/references/items.md",
          "type": "blob",
          "size": 5727
        },
        {
          "path": "skills/go-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/go-code-review/SKILL.md",
          "type": "blob",
          "size": 3249
        },
        {
          "path": "skills/go-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/go-code-review/references/common-mistakes.md",
          "type": "blob",
          "size": 4711
        },
        {
          "path": "skills/go-code-review/references/concurrency.md",
          "type": "blob",
          "size": 4137
        },
        {
          "path": "skills/go-code-review/references/error-handling.md",
          "type": "blob",
          "size": 2722
        },
        {
          "path": "skills/go-code-review/references/interfaces.md",
          "type": "blob",
          "size": 4007
        },
        {
          "path": "skills/go-testing-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/go-testing-code-review/SKILL.md",
          "type": "blob",
          "size": 3740
        },
        {
          "path": "skills/go-testing-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/go-testing-code-review/references/mocking.md",
          "type": "blob",
          "size": 5866
        },
        {
          "path": "skills/go-testing-code-review/references/structure.md",
          "type": "blob",
          "size": 5433
        },
        {
          "path": "skills/healthkit-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/healthkit-code-review/SKILL.md",
          "type": "blob",
          "size": 2406
        },
        {
          "path": "skills/healthkit-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/healthkit-code-review/references/authorization.md",
          "type": "blob",
          "size": 4645
        },
        {
          "path": "skills/healthkit-code-review/references/background.md",
          "type": "blob",
          "size": 6363
        },
        {
          "path": "skills/healthkit-code-review/references/data-types.md",
          "type": "blob",
          "size": 7237
        },
        {
          "path": "skills/healthkit-code-review/references/queries.md",
          "type": "blob",
          "size": 6337
        },
        {
          "path": "skills/howto-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/howto-docs/SKILL.md",
          "type": "blob",
          "size": 8511
        },
        {
          "path": "skills/langgraph-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/langgraph-architecture/SKILL.md",
          "type": "blob",
          "size": 9428
        },
        {
          "path": "skills/langgraph-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/langgraph-code-review/SKILL.md",
          "type": "blob",
          "size": 8514
        },
        {
          "path": "skills/langgraph-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/langgraph-implementation/PATTERNS.md",
          "type": "blob",
          "size": 9169
        },
        {
          "path": "skills/langgraph-implementation/SKILL.md",
          "type": "blob",
          "size": 8648
        },
        {
          "path": "skills/llm-artifacts-detection",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/llm-artifacts-detection/SKILL.md",
          "type": "blob",
          "size": 5438
        },
        {
          "path": "skills/llm-artifacts-detection/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/llm-artifacts-detection/references/abstraction-criteria.md",
          "type": "blob",
          "size": 7717
        },
        {
          "path": "skills/llm-artifacts-detection/references/dead-code-criteria.md",
          "type": "blob",
          "size": 5450
        },
        {
          "path": "skills/llm-artifacts-detection/references/style-criteria.md",
          "type": "blob",
          "size": 6512
        },
        {
          "path": "skills/llm-artifacts-detection/references/tests-criteria.md",
          "type": "blob",
          "size": 5998
        },
        {
          "path": "skills/llm-judge",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/llm-judge/SKILL.md",
          "type": "blob",
          "size": 3185
        },
        {
          "path": "skills/llm-judge/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/llm-judge/references/fact-schema.md",
          "type": "blob",
          "size": 4393
        },
        {
          "path": "skills/llm-judge/references/judge-agents.md",
          "type": "blob",
          "size": 2801
        },
        {
          "path": "skills/llm-judge/references/repo-agent.md",
          "type": "blob",
          "size": 2942
        },
        {
          "path": "skills/llm-judge/references/scoring-rubrics.md",
          "type": "blob",
          "size": 4211
        },
        {
          "path": "skills/postgres-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/postgres-code-review/SKILL.md",
          "type": "blob",
          "size": 1961
        },
        {
          "path": "skills/postgres-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/postgres-code-review/references/connections.md",
          "type": "blob",
          "size": 8011
        },
        {
          "path": "skills/postgres-code-review/references/indexes.md",
          "type": "blob",
          "size": 4741
        },
        {
          "path": "skills/postgres-code-review/references/jsonb.md",
          "type": "blob",
          "size": 5726
        },
        {
          "path": "skills/postgres-code-review/references/transactions.md",
          "type": "blob",
          "size": 13376
        },
        {
          "path": "skills/prometheus-go-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/prometheus-go-code-review/SKILL.md",
          "type": "blob",
          "size": 4365
        },
        {
          "path": "skills/pydantic-ai-agent-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-agent-creation/SKILL.md",
          "type": "blob",
          "size": 3677
        },
        {
          "path": "skills/pydantic-ai-common-pitfalls",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-common-pitfalls/SKILL.md",
          "type": "blob",
          "size": 7261
        },
        {
          "path": "skills/pydantic-ai-dependency-injection",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-dependency-injection/SKILL.md",
          "type": "blob",
          "size": 4432
        },
        {
          "path": "skills/pydantic-ai-model-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-model-integration/SKILL.md",
          "type": "blob",
          "size": 5288
        },
        {
          "path": "skills/pydantic-ai-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-testing/SKILL.md",
          "type": "blob",
          "size": 6291
        },
        {
          "path": "skills/pydantic-ai-tool-system",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pydantic-ai-tool-system/SKILL.md",
          "type": "blob",
          "size": 4565
        },
        {
          "path": "skills/pytest-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pytest-code-review/SKILL.md",
          "type": "blob",
          "size": 1949
        },
        {
          "path": "skills/pytest-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pytest-code-review/references/async-testing.md",
          "type": "blob",
          "size": 5397
        },
        {
          "path": "skills/pytest-code-review/references/fixtures.md",
          "type": "blob",
          "size": 7082
        },
        {
          "path": "skills/pytest-code-review/references/mocking.md",
          "type": "blob",
          "size": 10209
        },
        {
          "path": "skills/pytest-code-review/references/parametrize.md",
          "type": "blob",
          "size": 9378
        },
        {
          "path": "skills/python-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/python-code-review/SKILL.md",
          "type": "blob",
          "size": 3757
        },
        {
          "path": "skills/python-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/python-code-review/references/async-patterns.md",
          "type": "blob",
          "size": 2422
        },
        {
          "path": "skills/python-code-review/references/common-mistakes.md",
          "type": "blob",
          "size": 2762
        },
        {
          "path": "skills/python-code-review/references/error-handling.md",
          "type": "blob",
          "size": 2448
        },
        {
          "path": "skills/python-code-review/references/pep8-style.md",
          "type": "blob",
          "size": 4055
        },
        {
          "path": "skills/python-code-review/references/type-safety.md",
          "type": "blob",
          "size": 1936
        },
        {
          "path": "skills/react-flow-advanced",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow-advanced/SKILL.md",
          "type": "blob",
          "size": 10836
        },
        {
          "path": "skills/react-flow-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow-architecture/SKILL.md",
          "type": "blob",
          "size": 6817
        },
        {
          "path": "skills/react-flow-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow-code-review/SKILL.md",
          "type": "blob",
          "size": 5290
        },
        {
          "path": "skills/react-flow-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow-implementation/ADDITIONAL_COMPONENTS.md",
          "type": "blob",
          "size": 2363
        },
        {
          "path": "skills/react-flow-implementation/EDGE_PATHS.md",
          "type": "blob",
          "size": 2420
        },
        {
          "path": "skills/react-flow-implementation/SKILL.md",
          "type": "blob",
          "size": 7132
        },
        {
          "path": "skills/react-flow",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow/SKILL.md",
          "type": "blob",
          "size": 11275
        },
        {
          "path": "skills/react-flow/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-flow/references/custom-edges.md",
          "type": "blob",
          "size": 9183
        },
        {
          "path": "skills/react-flow/references/custom-nodes.md",
          "type": "blob",
          "size": 7054
        },
        {
          "path": "skills/react-flow/references/events.md",
          "type": "blob",
          "size": 14867
        },
        {
          "path": "skills/react-flow/references/viewport.md",
          "type": "blob",
          "size": 10002
        },
        {
          "path": "skills/react-router-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-router-code-review/SKILL.md",
          "type": "blob",
          "size": 3398
        },
        {
          "path": "skills/react-router-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-router-code-review/references/data-loading.md",
          "type": "blob",
          "size": 7484
        },
        {
          "path": "skills/react-router-code-review/references/error-handling.md",
          "type": "blob",
          "size": 10375
        },
        {
          "path": "skills/react-router-code-review/references/mutations.md",
          "type": "blob",
          "size": 10865
        },
        {
          "path": "skills/react-router-code-review/references/navigation.md",
          "type": "blob",
          "size": 11228
        },
        {
          "path": "skills/react-router-v7",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-router-v7/ACTIONS.md",
          "type": "blob",
          "size": 4203
        },
        {
          "path": "skills/react-router-v7/ADVANCED.md",
          "type": "blob",
          "size": 4054
        },
        {
          "path": "skills/react-router-v7/LOADERS.md",
          "type": "blob",
          "size": 2181
        },
        {
          "path": "skills/react-router-v7/NAVIGATION.md",
          "type": "blob",
          "size": 2719
        },
        {
          "path": "skills/react-router-v7/SKILL.md",
          "type": "blob",
          "size": 2945
        },
        {
          "path": "skills/react-router-v7/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/react-router-v7/references/actions.md",
          "type": "blob",
          "size": 4664
        },
        {
          "path": "skills/react-router-v7/references/advanced.md",
          "type": "blob",
          "size": 5319
        },
        {
          "path": "skills/react-router-v7/references/loaders.md",
          "type": "blob",
          "size": 2486
        },
        {
          "path": "skills/react-router-v7/references/navigation.md",
          "type": "blob",
          "size": 3188
        },
        {
          "path": "skills/receive-feedback",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/receive-feedback/EVALUATION.md",
          "type": "blob",
          "size": 1593
        },
        {
          "path": "skills/receive-feedback/RESPONSE.md",
          "type": "blob",
          "size": 1476
        },
        {
          "path": "skills/receive-feedback/SKILL.md",
          "type": "blob",
          "size": 1753
        },
        {
          "path": "skills/receive-feedback/TRACKING.md",
          "type": "blob",
          "size": 1276
        },
        {
          "path": "skills/receive-feedback/VERIFICATION.md",
          "type": "blob",
          "size": 1712
        },
        {
          "path": "skills/receive-feedback/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/receive-feedback/references/skill-integration.md",
          "type": "blob",
          "size": 1710
        },
        {
          "path": "skills/reference-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/reference-docs/SKILL.md",
          "type": "blob",
          "size": 7742
        },
        {
          "path": "skills/review-feedback-schema",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/review-feedback-schema/SKILL.md",
          "type": "blob",
          "size": 8423
        },
        {
          "path": "skills/review-skill-improver",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/review-skill-improver/SKILL.md",
          "type": "blob",
          "size": 5208
        },
        {
          "path": "skills/review-verification-protocol",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/review-verification-protocol/SKILL.md",
          "type": "blob",
          "size": 7433
        },
        {
          "path": "skills/shadcn-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/shadcn-code-review/SKILL.md",
          "type": "blob",
          "size": 3634
        },
        {
          "path": "skills/shadcn-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/shadcn-code-review/references/accessibility.md",
          "type": "blob",
          "size": 7358
        },
        {
          "path": "skills/shadcn-code-review/references/composition.md",
          "type": "blob",
          "size": 6186
        },
        {
          "path": "skills/shadcn-code-review/references/cva-patterns.md",
          "type": "blob",
          "size": 5465
        },
        {
          "path": "skills/shadcn-code-review/references/data-slot.md",
          "type": "blob",
          "size": 7313
        },
        {
          "path": "skills/shadcn-ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/shadcn-ui/SKILL.md",
          "type": "blob",
          "size": 12478
        },
        {
          "path": "skills/shadcn-ui/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/shadcn-ui/references/components.md",
          "type": "blob",
          "size": 16188
        },
        {
          "path": "skills/shadcn-ui/references/cva.md",
          "type": "blob",
          "size": 9172
        },
        {
          "path": "skills/shadcn-ui/references/patterns.md",
          "type": "blob",
          "size": 15704
        },
        {
          "path": "skills/sqlalchemy-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sqlalchemy-code-review/SKILL.md",
          "type": "blob",
          "size": 1945
        },
        {
          "path": "skills/sqlalchemy-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sqlalchemy-code-review/references/migrations.md",
          "type": "blob",
          "size": 10891
        },
        {
          "path": "skills/sqlalchemy-code-review/references/queries.md",
          "type": "blob",
          "size": 12512
        },
        {
          "path": "skills/sqlalchemy-code-review/references/relationships.md",
          "type": "blob",
          "size": 10376
        },
        {
          "path": "skills/sqlalchemy-code-review/references/sessions.md",
          "type": "blob",
          "size": 7890
        },
        {
          "path": "skills/sqlite-vec",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sqlite-vec/SKILL.md",
          "type": "blob",
          "size": 10893
        },
        {
          "path": "skills/sqlite-vec/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sqlite-vec/references/operations.md",
          "type": "blob",
          "size": 8984
        },
        {
          "path": "skills/sqlite-vec/references/queries.md",
          "type": "blob",
          "size": 7852
        },
        {
          "path": "skills/sqlite-vec/references/setup.md",
          "type": "blob",
          "size": 4367
        },
        {
          "path": "skills/sqlite-vec/references/tables.md",
          "type": "blob",
          "size": 7418
        },
        {
          "path": "skills/swift-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swift-code-review/SKILL.md",
          "type": "blob",
          "size": 2064
        },
        {
          "path": "skills/swift-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swift-code-review/references/common-mistakes.md",
          "type": "blob",
          "size": 3774
        },
        {
          "path": "skills/swift-code-review/references/concurrency.md",
          "type": "blob",
          "size": 3831
        },
        {
          "path": "skills/swift-code-review/references/error-handling.md",
          "type": "blob",
          "size": 3703
        },
        {
          "path": "skills/swift-code-review/references/observable.md",
          "type": "blob",
          "size": 3821
        },
        {
          "path": "skills/swift-testing-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swift-testing-code-review/SKILL.md",
          "type": "blob",
          "size": 2282
        },
        {
          "path": "skills/swift-testing-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swift-testing-code-review/references/async-testing.md",
          "type": "blob",
          "size": 4701
        },
        {
          "path": "skills/swift-testing-code-review/references/expect-macro.md",
          "type": "blob",
          "size": 3394
        },
        {
          "path": "skills/swift-testing-code-review/references/organization.md",
          "type": "blob",
          "size": 4340
        },
        {
          "path": "skills/swift-testing-code-review/references/parameterized.md",
          "type": "blob",
          "size": 3861
        },
        {
          "path": "skills/swiftdata-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swiftdata-code-review/SKILL.md",
          "type": "blob",
          "size": 2069
        },
        {
          "path": "skills/swiftdata-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swiftdata-code-review/references/concurrency.md",
          "type": "blob",
          "size": 4369
        },
        {
          "path": "skills/swiftdata-code-review/references/migrations.md",
          "type": "blob",
          "size": 4875
        },
        {
          "path": "skills/swiftdata-code-review/references/model-design.md",
          "type": "blob",
          "size": 3406
        },
        {
          "path": "skills/swiftdata-code-review/references/queries.md",
          "type": "blob",
          "size": 3921
        },
        {
          "path": "skills/swiftui-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swiftui-code-review/SKILL.md",
          "type": "blob",
          "size": 2101
        },
        {
          "path": "skills/swiftui-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swiftui-code-review/references/accessibility.md",
          "type": "blob",
          "size": 3420
        },
        {
          "path": "skills/swiftui-code-review/references/performance.md",
          "type": "blob",
          "size": 3038
        },
        {
          "path": "skills/swiftui-code-review/references/state-management.md",
          "type": "blob",
          "size": 2788
        },
        {
          "path": "skills/swiftui-code-review/references/view-composition.md",
          "type": "blob",
          "size": 2220
        },
        {
          "path": "skills/tailwind-v4",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/tailwind-v4/SKILL.md",
          "type": "blob",
          "size": 5704
        },
        {
          "path": "skills/tailwind-v4/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/tailwind-v4/references/dark-mode.md",
          "type": "blob",
          "size": 10327
        },
        {
          "path": "skills/tailwind-v4/references/setup.md",
          "type": "blob",
          "size": 5155
        },
        {
          "path": "skills/tailwind-v4/references/theming.md",
          "type": "blob",
          "size": 11761
        },
        {
          "path": "skills/tutorial-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/tutorial-docs/SKILL.md",
          "type": "blob",
          "size": 9577
        },
        {
          "path": "skills/tutorial-docs/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/tutorial-docs/references/example-weather-api.md",
          "type": "blob",
          "size": 3832
        },
        {
          "path": "skills/urlsession-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/urlsession-code-review/SKILL.md",
          "type": "blob",
          "size": 1848
        },
        {
          "path": "skills/urlsession-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/urlsession-code-review/references/async-networking.md",
          "type": "blob",
          "size": 5989
        },
        {
          "path": "skills/urlsession-code-review/references/caching.md",
          "type": "blob",
          "size": 7243
        },
        {
          "path": "skills/urlsession-code-review/references/error-handling.md",
          "type": "blob",
          "size": 7185
        },
        {
          "path": "skills/urlsession-code-review/references/request-building.md",
          "type": "blob",
          "size": 6793
        },
        {
          "path": "skills/vercel-ai-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vercel-ai-sdk/SKILL.md",
          "type": "blob",
          "size": 7205
        },
        {
          "path": "skills/vercel-ai-sdk/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vercel-ai-sdk/references/messages.md",
          "type": "blob",
          "size": 13934
        },
        {
          "path": "skills/vercel-ai-sdk/references/streaming.md",
          "type": "blob",
          "size": 15804
        },
        {
          "path": "skills/vercel-ai-sdk/references/tools.md",
          "type": "blob",
          "size": 19608
        },
        {
          "path": "skills/vercel-ai-sdk/references/use-chat.md",
          "type": "blob",
          "size": 12083
        },
        {
          "path": "skills/vitest-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vitest-testing/CONFIG.md",
          "type": "blob",
          "size": 3178
        },
        {
          "path": "skills/vitest-testing/MOCKING.md",
          "type": "blob",
          "size": 2744
        },
        {
          "path": "skills/vitest-testing/PATTERNS.md",
          "type": "blob",
          "size": 3340
        },
        {
          "path": "skills/vitest-testing/SKILL.md",
          "type": "blob",
          "size": 2986
        },
        {
          "path": "skills/vitest-testing/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/vitest-testing/references/config.md",
          "type": "blob",
          "size": 3501
        },
        {
          "path": "skills/vitest-testing/references/mocking.md",
          "type": "blob",
          "size": 3302
        },
        {
          "path": "skills/vitest-testing/references/patterns.md",
          "type": "blob",
          "size": 3627
        },
        {
          "path": "skills/watchos-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/watchos-code-review/SKILL.md",
          "type": "blob",
          "size": 2595
        },
        {
          "path": "skills/watchos-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/watchos-code-review/references/complications.md",
          "type": "blob",
          "size": 5574
        },
        {
          "path": "skills/watchos-code-review/references/connectivity.md",
          "type": "blob",
          "size": 5187
        },
        {
          "path": "skills/watchos-code-review/references/lifecycle.md",
          "type": "blob",
          "size": 5335
        },
        {
          "path": "skills/watchos-code-review/references/performance.md",
          "type": "blob",
          "size": 5565
        },
        {
          "path": "skills/widgetkit-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/widgetkit-code-review/SKILL.md",
          "type": "blob",
          "size": 2213
        },
        {
          "path": "skills/widgetkit-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/widgetkit-code-review/references/intents.md",
          "type": "blob",
          "size": 4236
        },
        {
          "path": "skills/widgetkit-code-review/references/performance.md",
          "type": "blob",
          "size": 4625
        },
        {
          "path": "skills/widgetkit-code-review/references/timeline.md",
          "type": "blob",
          "size": 4283
        },
        {
          "path": "skills/widgetkit-code-review/references/views.md",
          "type": "blob",
          "size": 2940
        },
        {
          "path": "skills/wish-ssh-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/wish-ssh-code-review/SKILL.md",
          "type": "blob",
          "size": 2570
        },
        {
          "path": "skills/wish-ssh-code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/wish-ssh-code-review/references/server.md",
          "type": "blob",
          "size": 4975
        },
        {
          "path": "skills/wish-ssh-code-review/references/sessions.md",
          "type": "blob",
          "size": 5815
        },
        {
          "path": "skills/zustand-state",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/zustand-state/MIDDLEWARE.md",
          "type": "blob",
          "size": 3057
        },
        {
          "path": "skills/zustand-state/PATTERNS.md",
          "type": "blob",
          "size": 4700
        },
        {
          "path": "skills/zustand-state/SKILL.md",
          "type": "blob",
          "size": 3019
        },
        {
          "path": "skills/zustand-state/TYPESCRIPT.md",
          "type": "blob",
          "size": 3958
        },
        {
          "path": "skills/zustand-state/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/zustand-state/references/middleware.md",
          "type": "blob",
          "size": 3390
        },
        {
          "path": "skills/zustand-state/references/patterns.md",
          "type": "blob",
          "size": 5532
        },
        {
          "path": "skills/zustand-state/references/typescript.md",
          "type": "blob",
          "size": 4651
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"existential-birds\",\n  \"owner\": {\n    \"name\": \"Existential Birds, LLC\",\n    \"email\": \"tech@existentialbirds.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Beagle plugins and tools for Claude Code\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"beagle\",\n      \"source\": \"./\",\n      \"description\": \"Code review skills and verification workflows for Python, Go, React, and AI frameworks\",\n      \"version\": \"1.12.0\",\n      \"keywords\": [\"code-review\", \"python\", \"go\", \"react\", \"ai\", \"langgraph\", \"pydantic\", \"fastapi\", \"bubbletea\"]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"beagle\",\n  \"description\": \"Code review skills and verification workflows for Python, Go, React, and AI frameworks\",\n  \"version\": \"1.12.0\",\n  \"author\": {\n    \"name\": \"Existential Birds, LLC\",\n    \"email\": \"tech@existentialbirds.com\"\n  },\n  \"repository\": \"https://github.com/existential-birds/beagle\",\n  \"keywords\": [\n    \"react\",\n    \"python\",\n    \"go\",\n    \"typescript\",\n    \"fastapi\",\n    \"sqlalchemy\",\n    \"postgres\",\n    \"pytest\",\n    \"bubbletea\",\n    \"wish\",\n    \"prometheus\",\n    \"pydantic\",\n    \"langgraph\",\n    \"deepagents\",\n    \"tailwind\",\n    \"vitest\",\n    \"zustand\",\n    \"shadcn\",\n    \"react-flow\",\n    \"react-router\",\n    \"code-review\"\n  ]\n}\n",
        ".claude/commands/release-tag.md": "---\ndescription: tag and push a release after the release PR is merged\n---\n\n# Release Tag\n\nCreate and push a version tag after a release PR has been merged.\n\n**Input**: Version number (e.g., `1.9.0`) - the `v` prefix is optional\n\n```text\n$ARGUMENTS\n```\n\n---\n\n## Prerequisites\n\nVerify the release PR is merged and we're ready to tag:\n\n```bash\n# Ensure we're on main with latest changes\ngit checkout main\ngit pull\n\n# Extract version from input (strip 'v' prefix if present)\nVERSION=\"${ARGUMENTS#v}\"\n\n# Verify plugin.json version matches\necho \"Checking version consistency...\"\nPLUGIN_VERSION=$(grep '\"version\"' .claude-plugin/plugin.json | sed 's/.*\"\\([0-9.]*\\)\".*/\\1/')\nif [ \"$PLUGIN_VERSION\" != \"$VERSION\" ]; then\n  echo \"ERROR: plugin.json version ($PLUGIN_VERSION) doesn't match requested version ($VERSION)\"\n  echo \"Ensure the release PR was merged first.\"\n  exit 1\nfi\necho \"plugin.json version: $PLUGIN_VERSION - matches\"\n```\n\nIf the version doesn't match, the script aborts with an error. The release PR must be merged first.\n\n## Step 1: Verify CHANGELOG Entry\n\nConfirm the version has a changelog entry:\n\n```bash\ngrep \"## \\[${VERSION}\\]\" CHANGELOG.md\n```\n\nIf no entry exists, abort - the release PR may not have been merged.\n\n## Step 2: Check Tag Doesn't Exist\n\n```bash\ngit tag -l \"v${VERSION}\"\n```\n\nIf the tag already exists, inform the user and ask if they want to view the release instead.\n\n## Step 3: Create Annotated Tag\n\nGenerate a brief summary from the CHANGELOG for the tag message:\n\n```bash\n# Extract the first category and its first item from this version's section\nSUMMARY=$(sed -n \"/## \\[${VERSION}\\]/,/## \\[/p\" CHANGELOG.md | grep \"^- \" | head -1 | sed 's/^- //' | cut -c1-60)\necho \"Tag summary: ${SUMMARY}\"\n```\n\nCreate the tag:\n\n```bash\ngit tag -a \"v${VERSION}\" -m \"Release v${VERSION} - ${SUMMARY}\"\n```\n\n## Step 4: Push Tag\n\n```bash\ngit push origin \"v${VERSION}\"\n```\n\n## Step 5: Create GitHub Release\n\nCreate the GitHub release using the changelog content:\n\n```bash\n# Extract changelog section for this version\nNOTES=$(sed -n \"/## \\[${VERSION}\\]/,/## \\[/p\" CHANGELOG.md | sed '$ d')\n\n# Create GitHub release\ngh release create \"v${VERSION}\" --title \"v${VERSION}\" --notes \"$NOTES\"\n```\n\n## Step 6: Confirm Release\n\nProvide the release URL:\n\n```bash\n# Get repo URL\nREPO_URL=$(gh repo view --json url --jq '.url')\necho \"Release available at: ${REPO_URL}/releases/tag/v${VERSION}\"\n```\n\nOutput:\n\n```text\nTagged and pushed v${VERSION}\n\nRelease created at:\n  ${REPO_URL}/releases/tag/v${VERSION}\n\nTo view the release:\n  gh release view v${VERSION}\n```\n\n## Error Handling\n\n- If not on main: checkout main first\n- If version not in plugin.json: abort, suggest running /release first\n- If version not in CHANGELOG: abort, release PR may not be merged\n- If tag exists: show existing tag info, don't recreate\n- If push fails: provide manual push command\n",
        ".claude/commands/release.md": "---\ndescription: create a release PR (auto-detects previous tag)\n---\n\n# Release Automation\n\nAutomate the full release process: generate notes, update files, create branch, and open PR.\n\nNo arguments required - automatically detects the previous tag.\n\n---\n\n## Versioning Overview\n\nBeagle has three version locations:\n1. **plugin.json version** - Main version, matches repo tags\n2. **marketplace.json metadata.version** - Marketplace version (only update when marketplace structure changes)\n3. **marketplace.json plugins[].version** - Plugin version in marketplace (only update when marketplace structure changes)\n\nThis command updates **plugin.json only**. Marketplace versions are updated manually when the marketplace structure changes.\n\n## Prerequisites\n\nVerify we're on main and it's clean:\n\n```bash\ngit checkout main\ngit pull\ngit status --short\n```\n\nIf there are uncommitted changes, abort and ask the user to resolve them first.\n\nDetect the previous tag:\n\n```bash\nPREV_TAG=$(git describe --tags --abbrev=0 2>/dev/null)\nif [ -z \"$PREV_TAG\" ]; then\n  echo \"No previous tags found. This appears to be the first release.\"\n  PREV_TAG=\"HEAD~100\"  # Fallback to analyze recent history\nfi\necho \"Previous tag: $PREV_TAG\"\n```\n\n## Step 1: Check for CHANGELOG.md\n\nIf `CHANGELOG.md` does not exist, create it with the standard header:\n\n```markdown\n# Changelog\n\nAll notable changes to Beagle are documented here.\n\nFormat follows [Keep a Changelog](https://keepachangelog.com/en/1.1.0/). Versioning adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n```\n\n## Step 2: Verify Documentation Coverage\n\nBefore generating release notes, verify all commands and skills are documented in README.md.\n\n**Check commands coverage:**\n\n```bash\n# List actual commands (excluding llm-judge which may be experimental)\nCOMMANDS=$(ls -1 commands/*.md 2>/dev/null | xargs -I {} basename {} .md | sort)\necho \"Actual commands:\"\necho \"$COMMANDS\"\n\n# Commands documented in README\necho \"\"\necho \"Commands in README:\"\ngrep -E '^\\| `[a-z-]+' README.md | sed 's/| `\\([^`]*\\)`.*/\\1/' | sort\n```\n\n**Check skills coverage:**\n\n```bash\n# List actual skill directories\nSKILLS=$(ls -1d skills/*/SKILL.md 2>/dev/null | xargs -I {} dirname {} | xargs -I {} basename {} | sort)\necho \"Actual skills count: $(echo \"$SKILLS\" | wc -l | tr -d ' ')\"\n\n# Skills should be grouped in README by category, verify major categories exist\necho \"\"\necho \"Skills categories in README:\"\ngrep -E '^\\| \\*\\*' README.md | head -10\n```\n\nIf documentation is missing or significantly out of sync, stop and run `/beagle:ensure-docs` first, then restart the release process.\n\n## Step 3: Generate Release Notes\n\nRun `/beagle:gen-release-notes ${PREV_TAG}` to:\n1. Analyze commits since the previous tag\n2. Categorize changes (Added, Changed, Fixed, Security, etc.)\n3. Determine the next version number based on semantic versioning\n4. Update `CHANGELOG.md` with the new version section\n\n**Do not proceed** until CHANGELOG.md is updated with the new version.\n\n## Step 4: Update Plugin Version\n\nAfter determining the new version from the changelog analysis, update `.claude-plugin/plugin.json`:\n\n```bash\n# Extract the new version from CHANGELOG.md (first version entry after Unreleased)\nVERSION=$(grep -E '^\\#\\# \\[[0-9]+\\.[0-9]+\\.[0-9]+\\]' CHANGELOG.md | head -1 | sed 's/.*\\[\\(.*\\)\\].*/\\1/')\necho \"New version: $VERSION\"\n\n# Update plugin.json version\n# Use jq if available, otherwise sed\nif command -v jq &> /dev/null; then\n  jq --arg v \"$VERSION\" '.version = $v' .claude-plugin/plugin.json > .claude-plugin/plugin.json.tmp && mv .claude-plugin/plugin.json.tmp .claude-plugin/plugin.json\nelse\n  sed -i '' \"s/\\\"version\\\": \\\"[^\\\"]*\\\"/\\\"version\\\": \\\"$VERSION\\\"/\" .claude-plugin/plugin.json\nfi\n```\n\nVerify the update:\n\n```bash\ngrep '\"version\"' .claude-plugin/plugin.json\n```\n\n## Step 5: Create Release Branch\n\nAfter the files are updated:\n\n```bash\n# Create and checkout release branch\ngit checkout -b \"chore/release-${VERSION}\"\n```\n\n## Step 6: Commit Changes\n\nCommit all updated version files:\n\n```bash\ngit add CHANGELOG.md .claude-plugin/plugin.json\ngit commit -m \"chore(release): bump version to ${VERSION}\"\n```\n\n## Step 7: Push and Create PR\n\nPush the branch and create a pull request:\n\n```bash\ngit push -u origin \"chore/release-${VERSION}\"\n```\n\nCreate the PR with this structure:\n\n```bash\ngh pr create --title \"chore(release): ${VERSION}\" --body \"$(cat <<EOF\n## Summary\n\n- Bump version to ${VERSION}\n- Update CHANGELOG.md with changes since ${PREV_TAG}\n\n## Version Locations Updated\n\n- [x] \\`.claude-plugin/plugin.json\\` - Plugin version\n- [ ] \\`.claude-plugin/marketplace.json\\` - Not updated (only for marketplace structure changes)\n\n## Post-merge Steps\n\nAfter merging, run:\n\\`\\`\\`\n/release-tag ${VERSION}\n\\`\\`\\`\n\n---\n\nGenerated with [Claude Code](https://claude.com/claude-code)\nEOF\n)\"\n```\n\n## Step 8: Output Summary\n\nAfter creating the PR, provide:\n\n1. The PR URL\n2. The version number\n3. Post-merge instructions:\n\n```text\nRelease PR created: <URL>\n\nAfter the PR is merged, run:\n  /release-tag ${VERSION}\n```\n\n## Error Handling\n\n- If main has uncommitted changes: abort and notify user\n- If no tags exist: treat as first release, analyze recent commits\n- If no changes since tag: abort and notify user\n- If PR creation fails: provide manual steps\n",
        ".cursor/commands/12-factor-apps-analysis.md": "# 12-Factor App Compliance Analysis\n\nYou are performing a comprehensive compliance analysis against the [12-Factor App](https://12factor.net) methodology for building SaaS applications.\n\n## Target Codebase\n\n**Path:** $ARGUMENTS (default: current working directory)\n\n## Analysis Scope\n\nEvaluate all 12 factors:\n\n1. **Codebase** - One codebase tracked in revision control, many deploys\n2. **Dependencies** - Explicitly declare and isolate dependencies\n3. **Config** - Store config in the environment\n4. **Backing Services** - Treat backing services as attached resources\n5. **Build, Release, Run** - Strictly separate build and run stages\n6. **Processes** - Execute the app as one or more stateless processes\n7. **Port Binding** - Export services via port binding\n8. **Concurrency** - Scale out via the process model\n9. **Disposability** - Maximize robustness with fast startup and graceful shutdown\n10. **Dev/Prod Parity** - Keep development, staging, and production as similar as possible\n11. **Logs** - Treat logs as event streams\n12. **Admin Processes** - Run admin/management tasks as one-off processes\n\n---\n\n# 12-Factor App Compliance Analysis Guide\n\n> Reference: [The Twelve-Factor App](https://12factor.net)\n\n## Overview\n\nThe 12-Factor App methodology is a set of best practices for building Software-as-a-Service applications that are:\n- Portable across execution environments\n- Scalable without architectural changes\n- Suitable for continuous deployment\n- Maintainable with minimal friction\n\n## Analysis Framework\n\n### Factor I: Codebase\n\n**Principle:** One codebase tracked in revision control, many deploys.\n\n**Search Patterns:**\n```bash\n# Check for version control\nls -la .git 2>/dev/null || ls -la .hg 2>/dev/null\n\n# Check for multiple apps sharing codebase\nfind . -name \"package.json\" -o -name \"pyproject.toml\" -o -name \"setup.py\" | head -20\n\n# Check for environment-specific code branches\ngrep -r \"if.*production\\|if.*development\\|if.*staging\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `.git/`, `package.json`, `pyproject.toml`, deployment configs\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Single Git repo, same codebase for all environments, no env-specific code branches |\n| **Partial** | Single repo but some environment-specific code paths |\n| **Weak** | Multiple repos for same app or significant code duplication across environments |\n\n**Anti-patterns:**\n- Multiple Git repositories for the same application\n- Environment-specific code branches (`if production: ...`)\n- Different source files for dev vs prod\n- Shared code not extracted to libraries\n\n---\n\n### Factor II: Dependencies\n\n**Principle:** Explicitly declare and isolate dependencies.\n\n**Search Patterns:**\n```bash\n# Python dependency files\nfind . -name \"requirements.txt\" -o -name \"pyproject.toml\" -o -name \"setup.py\" -o -name \"Pipfile\" -o -name \"uv.lock\"\n\n# JavaScript/TypeScript dependency files\nfind . -name \"package.json\" -o -name \"package-lock.json\" -o -name \"yarn.lock\" -o -name \"pnpm-lock.yaml\"\n\n# Check for system tool assumptions\ngrep -r \"subprocess.*curl\\|subprocess.*wget\\|os.system.*ffmpeg\\|shutil.which\" --include=\"*.py\"\ngrep -r \"exec.*curl\\|child_process.*curl\" --include=\"*.js\" --include=\"*.ts\"\n\n# Docker/container isolation\nfind . -name \"Dockerfile\" -o -name \"docker-compose*.yml\"\n```\n\n**File Patterns:** `**/requirements*.txt`, `**/package.json`, `**/*.lock`, `**/Dockerfile`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Lock files present, dependency isolation (venv/Docker), no implicit system tools |\n| **Partial** | Dependencies declared but no lock files or isolation |\n| **Weak** | Dependencies in documentation only, relies on system-installed packages |\n\n**Anti-patterns:**\n- Missing lock files (non-deterministic builds)\n- Assuming system tools (curl, ImageMagick, ffmpeg) are available\n- Different dependency managers in dev vs production\n- No virtual environment or container isolation\n\n---\n\n### Factor III: Config\n\n**Principle:** Store config in the environment.\n\n**Search Patterns:**\n```bash\n# Environment variable usage\ngrep -r \"os.environ\\|os.getenv\\|process.env\\|ENV\\[\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" --include=\"*.rb\"\n\n# Hardcoded credentials (anti-pattern)\ngrep -r \"password.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\ngrep -r \"api_key.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\ngrep -r \"secret.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\n\n# Environment-specific config files (anti-pattern)\nfind . -name \"config.dev.*\" -o -name \"config.prod.*\" -o -name \"settings.development.*\" -o -name \"settings.production.*\"\n\n# Database URLs in code\ngrep -r \"postgresql://\\|mysql://\\|mongodb://\\|redis://\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \".env\\|test\\|example\"\n```\n\n**File Patterns:** `**/.env*`, `**/config/*.py`, `**/settings.py`, environment files\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All config via environment variables, no hardcoded secrets, could open-source without leaks |\n| **Partial** | Most config externalized but some hardcoded defaults |\n| **Weak** | Hardcoded credentials, environment-specific config files |\n\n**Anti-patterns:**\n- Hardcoded database URLs, API keys, passwords in source\n- Config files like `config/production.yml` vs `config/development.yml`\n- Environment grouping (`if ENV == 'production': ...`)\n- Secrets committed to version control\n\n---\n\n### Factor IV: Backing Services\n\n**Principle:** Treat backing services as attached resources.\n\n**Search Patterns:**\n```bash\n# Database connection via config\ngrep -r \"DATABASE_URL\\|DB_HOST\\|REDIS_URL\\|CACHE_URL\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Service initialization\ngrep -r \"create_engine\\|MongoClient\\|Redis\\|Celery\\|boto3\" --include=\"*.py\"\ngrep -r \"createPool\\|createClient\\|new Redis\\|S3Client\" --include=\"*.js\" --include=\"*.ts\"\n\n# Hardcoded service locations (anti-pattern)\ngrep -r \"localhost:5432\\|localhost:6379\\|localhost:27017\\|127.0.0.1\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\\|default\"\n```\n\n**File Patterns:** `**/database/*.py`, `**/services/*.py`, `**/db.py`, connection configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All services via URL/connection string in config, swappable without code changes |\n| **Partial** | Most services configurable but some hardcoded defaults |\n| **Weak** | Hardcoded service locations, different code paths per environment |\n\n**Anti-patterns:**\n- Hardcoded `localhost` for services in production code\n- Conditional logic for local vs cloud services (`if USE_S3: ... else: local_storage`)\n- Service-specific code paths based on environment\n- Different drivers for dev vs prod\n\n---\n\n### Factor V: Build, Release, Run\n\n**Principle:** Strictly separate build and run stages.\n\n**Search Patterns:**\n```bash\n# Build/deploy configuration\nfind . -name \"Dockerfile\" -o -name \"Makefile\" -o -name \"build.sh\" -o -name \"deploy.sh\"\nfind . -name \".github/workflows/*.yml\" -o -name \".gitlab-ci.yml\" -o -name \"Jenkinsfile\"\n\n# Build scripts in package.json\ngrep -A5 '\"scripts\"' package.json 2>/dev/null | grep -E \"build|start|deploy\"\n\n# Check for runtime compilation (anti-pattern)\ngrep -r \"compile\\|transpile\\|webpack\" --include=\"*.py\" | grep -v \"test\\|build\"\n```\n\n**File Patterns:** `**/Dockerfile`, `**/Makefile`, `**/.github/workflows/**`, CI/CD configs\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Immutable releases, clear build/release/run stages, unique release IDs |\n| **Partial** | Build and run separated but release not immutable |\n| **Weak** | Runtime code modifications, asset compilation at startup |\n\n**Anti-patterns:**\n- Runtime code modifications\n- Asset compilation during application startup\n- Configuration baked into build artifacts\n- No release versioning\n\n---\n\n### Factor VI: Processes\n\n**Principle:** Execute the app as one or more stateless processes.\n\n**Search Patterns:**\n```bash\n# Session storage patterns\ngrep -r \"session\\|Session\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n\n# In-process state (anti-pattern)\ngrep -r \"global.*cache\\|process_local\\|instance_cache\" --include=\"*.py\"\ngrep -r \"global\\..*=\\|module\\.exports\\.cache\" --include=\"*.js\" --include=\"*.ts\"\n\n# External session stores (good pattern)\ngrep -r \"redis.*session\\|memcached.*session\\|session.*redis\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Sticky session configuration (anti-pattern)\ngrep -r \"sticky.*session\\|session.*affinity\" --include=\"*.yml\" --include=\"*.yaml\" --include=\"*.json\"\n```\n\n**File Patterns:** `**/middleware/*.py`, `**/session/*.py`, server configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Stateless processes, all state in external datastores (Redis, DB) |\n| **Partial** | Mostly stateless but some in-process caching |\n| **Weak** | Sticky sessions, in-process session storage, shared memory state |\n\n**Anti-patterns:**\n- In-process session storage (`user_sessions = {}`)\n- Sticky sessions or session affinity\n- File-based caching between requests\n- Global mutable state shared across requests\n\n---\n\n### Factor VII: Port Binding\n\n**Principle:** Export services via port binding.\n\n**Search Patterns:**\n```bash\n# Self-contained port binding\ngrep -r \"app.run\\|server.listen\\|serve\\|uvicorn\" --include=\"*.py\"\ngrep -r \"app.listen\\|server.listen\\|createServer\" --include=\"*.js\" --include=\"*.ts\"\n\n# PORT environment variable\ngrep -r \"PORT\\|port\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -i \"environ\\|process.env\"\n\n# Webserver as dependency\ngrep -r \"uvicorn\\|gunicorn\\|flask\\|fastapi\\|express\\|koa\\|hapi\" package.json pyproject.toml requirements.txt 2>/dev/null\n```\n\n**File Patterns:** `**/main.py`, `**/server.py`, `**/app.py`, `**/index.js`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Self-contained app binds to PORT, webserver is a dependency |\n| **Partial** | Port binding but not configurable via environment |\n| **Weak** | Relies on external webserver container (Apache, Nginx) to provide HTTP |\n\n**Anti-patterns:**\n- Relying on Apache/Nginx/Tomcat to inject webserver functionality\n- Hardcoded port numbers\n- No PORT environment variable support\n- CGI scripts or server modules\n\n---\n\n### Factor VIII: Concurrency\n\n**Principle:** Scale out via the process model.\n\n**Search Patterns:**\n```bash\n# Process definitions\nfind . -name \"Procfile\" -o -name \"process.yml\" -o -name \".foreman\"\n\n# Multiple entry points\nfind . -name \"worker.py\" -o -name \"scheduler.py\" -o -name \"web.py\"\n\n# Background job systems\ngrep -r \"celery\\|rq\\|sidekiq\\|bull\\|agenda\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"Celery\\|Worker\\|BackgroundJob\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/Procfile`, `**/worker.py`, `**/scheduler.py`, queue configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Explicit process types (web, worker, scheduler), horizontal scaling |\n| **Partial** | Multiple process types but not easily scalable |\n| **Weak** | Single monolithic process, no separation of concerns |\n\n**Anti-patterns:**\n- Single process handling all workloads\n- Hard-coded worker counts in code\n- No separation between web and background processes\n- Vertical scaling only (bigger server, not more processes)\n\n---\n\n### Factor IX: Disposability\n\n**Principle:** Maximize robustness with fast startup and graceful shutdown.\n\n**Search Patterns:**\n```bash\n# Signal handlers\ngrep -r \"signal.signal\\|SIGTERM\\|SIGINT\\|atexit\" --include=\"*.py\"\ngrep -r \"process.on.*SIGTERM\\|process.on.*SIGINT\" --include=\"*.js\" --include=\"*.ts\"\n\n# Graceful shutdown\ngrep -r \"graceful.*shutdown\\|shutdown_handler\\|cleanup\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Startup time\ngrep -r \"startup\\|initialize\\|bootstrap\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n```\n\n**File Patterns:** `**/main.py`, `**/server.py`, lifecycle management code\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Fast startup (<10s), SIGTERM handling, graceful shutdown, jobs returnable to queue |\n| **Partial** | Graceful shutdown but slow startup |\n| **Weak** | No signal handling, jobs lost on process death, slow startup |\n\n**Anti-patterns:**\n- No SIGTERM/SIGINT handlers\n- Slow startup (>30 seconds)\n- Jobs lost if process crashes\n- No cleanup on shutdown\n\n---\n\n### Factor X: Dev/Prod Parity\n\n**Principle:** Keep development, staging, and production as similar as possible.\n\n**Search Patterns:**\n```bash\n# Different services per environment (anti-pattern)\ngrep -r \"if.*development.*sqlite\\|if.*production.*postgres\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"development.*SQLite\\|production.*PostgreSQL\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Docker for parity\nfind . -name \"docker-compose*.yml\" -o -name \"Dockerfile\"\n\n# Environment-specific backends\ngrep -r \"USE_LOCAL_\\|LOCAL_STORAGE\\|MOCK_\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/docker-compose*.yml`, environment configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Same services everywhere (PostgreSQL in dev and prod), containerized |\n| **Partial** | Mostly same but some lightweight dev alternatives |\n| **Weak** | SQLite in dev, PostgreSQL in prod; different backing services |\n\n**Anti-patterns:**\n- SQLite for development, PostgreSQL for production\n- In-memory cache in dev, Redis in prod\n- Different service versions across environments\n- \"It works on my machine\" issues\n\n---\n\n### Factor XI: Logs\n\n**Principle:** Treat logs as event streams.\n\n**Search Patterns:**\n```bash\n# Stdout logging\ngrep -r \"print(\\|logging.info\\|logger.info\\|console.log\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n\n# File-based logging (anti-pattern)\ngrep -r \"FileHandler\\|open.*\\.log\\|writeFile.*log\\|fs.appendFile.*log\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"/var/log\\|/tmp/.*\\.log\\|logs/\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|example\"\n\n# Structured logging\ngrep -r \"structlog\\|json_logger\\|pino\\|winston\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/logging.py`, `**/logger.py`, logging configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Unbuffered stdout only, structured logging (JSON), no file management |\n| **Partial** | Stdout logging but with some file handlers |\n| **Weak** | Application writes to log files, manages rotation |\n\n**Anti-patterns:**\n- Writing logs to files (`FileHandler`, `open('/var/log/app.log')`)\n- Log rotation logic in application code\n- Log archival managed by application\n- Buffered logging\n\n---\n\n### Factor XII: Admin Processes\n\n**Principle:** Run admin/management tasks as one-off processes.\n\n**Search Patterns:**\n```bash\n# Management commands\nfind . -name \"manage.py\" -o -name \"Rakefile\" -o -name \"artisan\"\ngrep -r \"@cli.command\\|@click.command\\|typer.command\" --include=\"*.py\"\n\n# Migration scripts\nfind . -name \"migrations\" -type d\nfind . -name \"*migration*.py\" -o -name \"*migrate*.py\"\n\n# Admin scripts with proper isolation\ngrep -r \"bundle exec\\|source.*venv\\|uv run\" --include=\"*.sh\" --include=\"Makefile\"\n```\n\n**File Patterns:** `**/manage.py`, `**/cli.py`, `**/migrations/**`, admin scripts\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Admin tasks use same dependencies/config, proper isolation, idempotent |\n| **Partial** | Admin tasks exist but different setup from app |\n| **Weak** | Manual database manipulation, scripts without isolation |\n\n**Anti-patterns:**\n- Admin scripts not using app's dependency manager\n- Direct SQL manipulation outside of migrations\n- Admin scripts with hardcoded credentials\n- Non-idempotent migrations\n\n---\n\n## Workflow\n\n1. **Run searches** - Use grep patterns from above for each factor\n2. **Evaluate compliance** - Strong/Partial/Weak per factor\n3. **Document evidence** - File:line references for findings\n4. **Identify gaps** - What's missing vs. 12-Factor ideal\n5. **Provide recommendations** - Actionable improvements\n\n## Output Format\n\n### Executive Summary\n\n| Factor | Status | Key Finding |\n|--------|--------|-------------|\n| I. Codebase | Strong/Partial/Weak | [Summary] |\n| II. Dependencies | Strong/Partial/Weak | [Summary] |\n| III. Config | Strong/Partial/Weak | [Summary] |\n| IV. Backing Services | Strong/Partial/Weak | [Summary] |\n| V. Build/Release/Run | Strong/Partial/Weak | [Summary] |\n| VI. Processes | Strong/Partial/Weak | [Summary] |\n| VII. Port Binding | Strong/Partial/Weak | [Summary] |\n| VIII. Concurrency | Strong/Partial/Weak | [Summary] |\n| IX. Disposability | Strong/Partial/Weak | [Summary] |\n| X. Dev/Prod Parity | Strong/Partial/Weak | [Summary] |\n| XI. Logs | Strong/Partial/Weak | [Summary] |\n| XII. Admin Processes | Strong/Partial/Weak | [Summary] |\n\n**Overall:** X Strong, Y Partial, Z Weak\n\n### Detailed Findings\n\nFor each factor with gaps:\n- **Current State:** What exists\n- **Evidence:** File:line references\n- **Gap:** What's missing\n- **Recommendation:** How to improve\n\n### Priority Recommendations\n\n1. **High Priority** - Critical gaps affecting scalability/reliability\n2. **Medium Priority** - Improvements for better compliance\n3. **Low Priority** - Nice-to-have optimizations\n\n## Rules\n\n- Use the search patterns systematically for each factor\n- Provide file:line evidence for all findings\n- Be honest about compliance levels (don't inflate)\n- Focus on actionable recommendations\n- Reference the official 12-Factor App methodology\n\n## Quick Reference: Compliance Scoring\n\n| Score | Meaning | Action |\n|-------|---------|--------|\n| **Strong** | Fully implements principle | Maintain, minor optimizations |\n| **Partial** | Some implementation, significant gaps | Planned improvements |\n| **Weak** | Minimal or no implementation | High priority for roadmap |\n",
        ".cursor/commands/commit-push.md": "# Commit and Push\n\nCommit all local changes following Conventional Commits format and push to remote.\n\n## Step 1: Gather Context\n\nRun these commands in parallel to understand the changes:\n\n```bash\n# See all untracked and modified files\ngit status\n\n# See staged and unstaged changes\ngit diff\ngit diff --cached\n\n# See recent commit messages for style reference\ngit log --oneline -10\n```\n\n## Step 2: Analyze Changes\n\nReview the changes and determine:\n- **Type**: What kind of change is this?\n  - `feat` - New feature or capability\n  - `fix` - Bug fix\n  - `docs` - Documentation only\n  - `refactor` - Code restructure without behavior change\n  - `test` - Adding or updating tests\n  - `chore` - Maintenance, dependency updates\n  - `perf` - Performance improvement\n  - `ci` - CI/CD changes\n\n- **Scope**: Which component is affected?\n  - Examine the changed files and determine the appropriate scope\n  - Use consistent scope names within the project (check `git log` for patterns)\n  - *(omit scope for cross-cutting changes)*\n\n- **Breaking**: Does this break backward compatibility? If yes, add **!** after scope.\n\n## Step 3: Write Commit Message\n\nFormat:\n```\ntype(scope): description\n\n[optional body explaining why, not what]\n\n[optional footer with issue references]\n```\n\nRules:\n- Use imperative mood: \"add feature\" not \"added feature\"\n- Keep first line under 72 characters\n- Focus on *why* in the body, the diff shows *what*\n- Reference issues: `Closes #123` or `Fixes #456`\n\n## Step 4: Stage, Commit, and Push\n\n```bash\n# Stage all changes (or selectively stage)\ngit add -A\n\n# Commit with message (use HEREDOC for multi-line)\ngit commit -m \"$(cat <<'EOF'\ntype(scope): description\n\nOptional body explaining the motivation.\n\nCloses #123\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n\n# Push to remote\ngit push\n```\n\n## Examples\n\n```bash\n# Simple feature\ngit commit -m \"feat(api): add pagination support to list endpoints\"\n\n# Bug fix with body\ngit commit -m \"$(cat <<'EOF'\nfix(auth): handle token expiration during long requests\n\nThe previous implementation did not account for tokens expiring\nduring the processing of long-running requests.\n\nFixes #42\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n\n# Breaking change\ngit commit -m \"$(cat <<'EOF'\nfeat!(api): change response format for user endpoints\n\nBREAKING CHANGE: The `status` field is now an object with `state` and\n`message` properties instead of a plain string.\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n```\n\n## Step 5: Verify\n\nAfter pushing, run `git status` to confirm the working tree is clean and the branch is up to date with remote.\n",
        ".cursor/commands/create-pr.md": "# Create Pull Request\n\nCreate a pull request with a well-structured description based on the branch changes.\n\n## Instructions\n\n### 1. Gather Context\n\nFirst, collect information about the changes:\n\n```bash\n# Get current branch and verify it's not main\ngit branch --show-current\n\n# Get commit history for this branch\ngit log --oneline main..HEAD\n\n# Get detailed commit messages for context\ngit log --format=\"### %s%n%n%b\" main..HEAD\n\n# Get file change statistics\ngit diff --stat main..HEAD\n\n# Get the actual diff for understanding changes\ngit diff main..HEAD\n```\n\n### 2. Analyze the Changes\n\nBased on the gathered information, determine:\n\n- **What changed**: Categorize changes (features, fixes, refactors, docs, tests)\n- **Why it changed**: Infer motivation from commit messages and code changes\n- **Impact**: Breaking changes, new dependencies, migrations needed\n- **Testing**: What tests were added/modified, how to verify manually\n\n### 3. Check for Related Issues\n\nLook for issue references:\n- In commit messages (e.g., \"fixes #123\", \"closes #456\")\n- In branch name (e.g., `fix/issue-123-description`)\n- In code comments or TODOs addressed\n\n### 4. Generate PR Description\n\nCreate the PR using this template structure:\n\n```bash\ngh pr create --title \"<type>(<scope>): <description>\" --body \"$(cat <<'EOF'\n## Summary\n\n<1-3 sentence overview of what this PR does and why>\n\n## Changes\n\n<Categorized bullet list of changes>\n\n### Added\n- <new features or capabilities>\n\n### Changed\n- <modifications to existing functionality>\n\n### Fixed\n- <bug fixes>\n\n### Removed\n- <deprecated or removed functionality>\n\n## Motivation\n\n<Why were these changes needed? What problem does this solve?>\n\n## Testing\n\n<How was this tested?>\n\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing performed\n\n### Manual Testing Steps\n\n<If applicable, steps to manually verify the changes>\n\n## Breaking Changes\n\n<If any, describe what breaks and migration path. Remove section if none.>\n\n## Related Issues\n\n<Link to related issues. Remove section if none.>\n\n- Closes #<issue_number>\n- Related to #<issue_number>\n\n## Checklist\n\n- [ ] Code follows project style guidelines\n- [ ] Self-review completed\n- [ ] Tests pass locally\n- [ ] Linting passes\n- [ ] Documentation updated (if needed)\n\n---\n\nGenerated with [Claude Code](https://claude.com/claude-code)\nEOF\n)\"\n```\n\n### 5. Title Format\n\nUse conventional commit format for the PR title:\n- `feat(scope): add new feature`\n- `fix(scope): correct bug behavior`\n- `refactor(scope): restructure without behavior change`\n- `docs(scope): update documentation`\n- `test(scope): add or modify tests`\n- `chore(scope): maintenance tasks`\n\n### 6. Apply Labels\n\nAfter creating the PR, apply appropriate labels based on the changes. Use `gh pr edit <number> --add-label <label>`.\n\nCheck the repository's available labels first:\n```bash\ngh label list\n```\n\n#### Common Type Labels\n\n| Label | When to Use |\n|-------|-------------|\n| `enhancement` | New features, capabilities, or improvements |\n| `bug` | Bug fixes |\n| `documentation` | Documentation-only changes |\n| `breaking-change` | **User-facing** breaking changes requiring migration |\n\n#### Breaking Change Criteria\n\nOnly apply `breaking-change` for **user-facing** changes that require users to modify their:\n- Configuration files\n- CLI invocations\n- API integrations\n\nDo NOT apply for internal refactors unless they affect external consumers.\n\n### 7. After Creation\n\nAfter creating the PR:\n1. Display the PR URL with applied labels\n2. Suggest adding reviewers if appropriate\n3. Note if any CI checks need to pass\n\n## Guidelines\n\n**DO:**\n- Be specific about what changed and why\n- Include testing evidence\n- Link related issues\n- Note breaking changes prominently\n- Remove empty optional sections\n\n**DON'T:**\n- Include irrelevant commits (keep PR focused)\n- Leave placeholder text in the description\n- Skip the testing section\n- Create PRs without running local checks first\n",
        ".cursor/commands/ensure-docs.md": "# Ensure Documentation Coverage\n\nVerify code documentation coverage across a codebase, report gaps, and interactively generate missing documentation using parallel language-specific agents.\n\n## Arguments\n\n- `Path`: Target directory (default: current working directory)\n- `--report-only`: Skip interactive generation, just output findings\n\n## Workflow Overview\n\n1. **Detect** languages present in the codebase\n2. **Spawn** parallel verification agents per language\n3. **Merge** and present consolidated findings\n4. **Offer** interactive generation choices\n5. **Generate** missing docs if requested\n6. **Verify** with language linters\n\n## Phase 1: Language Detection\n\nDetect which languages are present in the codebase:\n\n```bash\n# Python detection\nPYTHON_FILES=$(find . -type f -name \"*.py\" ! -path \"./.*\" ! -path \"./venv/*\" ! -path \"./.venv/*\" | head -100)\nPYTHON_COUNT=$(echo \"$PYTHON_FILES\" | grep -c . || echo 0)\n\n# TypeScript/JavaScript detection\nTS_FILES=$(find . -type f \\( -name \"*.ts\" -o -name \"*.tsx\" -o -name \"*.js\" -o -name \"*.jsx\" \\) ! -path \"./node_modules/*\" ! -path \"./.*\" | head -100)\nTS_COUNT=$(echo \"$TS_FILES\" | grep -c . || echo 0)\n\n# Go detection\nGO_FILES=$(find . -type f -name \"*.go\" ! -path \"./vendor/*\" ! -path \"./.*\" | head -100)\nGO_COUNT=$(echo \"$GO_FILES\" | grep -c . || echo 0)\n```\n\n### Framework Detection\n\n```bash\n# FastAPI detection (affects OpenAPI handling)\ngrep -r \"from fastapi\\|FastAPI\\|@app\\.\\|@router\\.\" --include=\"*.py\" -l 2>/dev/null | head -1\n\n# Check existing OpenAPI specs\nls -la openapi.yaml swagger.json api.yaml 2>/dev/null\n```\n\n### Detection Output\n\nReport detected languages:\n\n| Language | Files Found | Standard |\n|----------|-------------|----------|\n| Python | $PYTHON_COUNT | Google docstrings |\n| TypeScript/JS | $TS_COUNT | JSDoc |\n| Go | $GO_COUNT | GoDoc |\n\nProceed only with languages that have at least 1 file detected.\n\n## Language Standards\n\n### Python (Google Docstrings)\n\n**What to check:**\n- All public functions (not starting with `_`)\n- All classes\n- All modules (top-of-file docstring)\n\n**Required docstring elements:**\n- Description (first line, imperative mood)\n- Args: Parameter name, type, and description\n- Returns: Return type and description\n- Raises: Exception types and when raised\n\n**Example of compliant docstring:**\n\n```python\ndef process_request(data: dict, timeout: int = 30) -> Response:\n    \"\"\"Process an incoming API request.\n\n    Args:\n        data: The request payload as a dictionary.\n        timeout: Maximum seconds to wait for processing.\n\n    Returns:\n        Response object containing status and result.\n\n    Raises:\n        ValidationError: If data fails schema validation.\n        TimeoutError: If processing exceeds timeout.\n    \"\"\"\n```\n\n**Missing indicators:**\n- No docstring at all\n- Docstring with only description (missing Args/Returns)\n- Mismatched parameters (docstring doesn't match signature)\n\n### TypeScript/JavaScript (JSDoc)\n\n**What to check:**\n- All exported functions\n- All exported classes\n- All exported interfaces and types\n- All exported constants with complex types\n\n**Required JSDoc elements:**\n- @description or first line description\n- @param for each parameter with type and description\n- @returns with type and description\n- @throws for thrown exceptions\n\n**Example of compliant JSDoc:**\n\n```typescript\n/**\n * Process an incoming API request.\n * @param data - The request payload\n * @param timeout - Maximum seconds to wait\n * @returns Response containing status and result\n * @throws {ValidationError} If data fails validation\n */\nexport function processRequest(data: RequestData, timeout = 30): Response {\n```\n\n**Missing indicators:**\n- No JSDoc comment\n- JSDoc with only description (missing @param/@returns)\n- Mismatched parameters (JSDoc doesn't match signature)\n\n### Go (GoDoc)\n\n**What to check:**\n- All exported functions (capitalized names)\n- All exported types (structs, interfaces)\n- Package comment in one file per package\n\n**Required GoDoc elements:**\n- Comment starting with the symbol name\n- Description of purpose and behavior\n- For complex functions: describe parameters inline\n\n**Example of compliant GoDoc:**\n\n```go\n// ProcessRequest handles an incoming API request with the given data\n// and timeout. It returns a Response or an error if processing fails.\n// The timeout is specified in seconds; use 0 for no timeout.\nfunc ProcessRequest(data map[string]any, timeout int) (*Response, error) {\n```\n\n**Missing indicators:**\n- No comment above exported symbol\n- Comment doesn't start with symbol name\n- Comment is too terse (single generic sentence)\n\n## Phase 2: Parallel Verification\n\nSpawn verification agents in parallel for each detected language using the `Task` tool.\n\n### Agent Prompt Template\n\nFor each detected language, spawn an agent with:\n\n**Python Agent:**\n```\nYou are a Python documentation verifier. Check all Python files for Google docstring compliance.\n\nSTANDARD:\n[Embed Python standard from above]\n\nTASK:\n1. Find all .py files in the target directory (exclude venv, .venv, __pycache__, tests)\n2. For each file, identify public functions (not _prefixed) and classes\n3. Check each symbol for docstring presence and completeness\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"python\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"path/to/file.py\", \"line\": 15, \"symbol\": \"function_name\", \"type\": \"function\", \"issue\": \"missing_docstring\"},\n    {\"file\": \"path/to/file.py\", \"line\": 42, \"symbol\": \"ClassName\", \"type\": \"class\", \"issue\": \"incomplete_docstring\", \"missing\": [\"Args\", \"Returns\"]}\n  ]\n}\n```\n\n**TypeScript Agent:**\n```\nYou are a TypeScript/JavaScript documentation verifier. Check all TS/JS files for JSDoc compliance.\n\nSTANDARD:\n[Embed TypeScript standard from above]\n\nTASK:\n1. Find all .ts, .tsx, .js, .jsx files (exclude node_modules, dist, build)\n2. For each file, identify exported functions, classes, interfaces, and types\n3. Check each symbol for JSDoc presence and completeness\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"typescript\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"src/api.ts\", \"line\": 10, \"symbol\": \"processRequest\", \"type\": \"function\", \"issue\": \"missing_jsdoc\"},\n    {\"file\": \"src/types.ts\", \"line\": 5, \"symbol\": \"UserData\", \"type\": \"interface\", \"issue\": \"incomplete_jsdoc\", \"missing\": [\"description for userId property\"]}\n  ]\n}\n```\n\n**Go Agent:**\n```\nYou are a Go documentation verifier. Check all Go files for GoDoc compliance.\n\nSTANDARD:\n[Embed Go standard from above]\n\nTASK:\n1. Find all .go files (exclude vendor, _test.go for symbol docs)\n2. For each file, identify exported functions and types (Capitalized names)\n3. Check each symbol for comment presence and correct format\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"go\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"pkg/api/handler.go\", \"line\": 25, \"symbol\": \"ProcessRequest\", \"type\": \"function\", \"issue\": \"missing_comment\"},\n    {\"file\": \"pkg/models/user.go\", \"line\": 8, \"symbol\": \"User\", \"type\": \"struct\", \"issue\": \"wrong_format\", \"detail\": \"Comment doesn't start with 'User'\"}\n  ]\n}\n```\n\n### Spawning Agents\n\nUse the `Task` tool to spawn agents in parallel:\n\n1. For each detected language with files > 0\n2. Spawn agent with subagent_type=\"general-purpose\"\n3. Include the language-specific prompt and standard\n4. Set run_in_background=false to wait for results\n5. Collect JSON output from each agent\n\n## Phase 3: Consolidate Results\n\nAfter all agents complete, merge their findings.\n\n### Categorize by Severity\n\nGroup findings into:\n\n| Severity | Issue Types | Priority |\n|----------|-------------|----------|\n| **Missing** | `missing_docstring`, `missing_jsdoc`, `missing_comment` | High |\n| **Incomplete** | `incomplete_docstring`, `incomplete_jsdoc` (has doc but missing required elements) | Medium |\n| **Wrong Format** | `wrong_format` (comment exists but doesn't follow standard) | Low |\n\n### Summary Table\n\nGenerate a summary table:\n\n```markdown\n## Documentation Audit Results\n\n| Language   | Files | Missing | Incomplete | Format Issues |\n|------------|-------|---------|------------|---------------|\n| Python     | 42    | 12      | 5          | 2             |\n| TypeScript | 28    | 8       | 3          | 0             |\n| Go         | 15    | 4       | 1          | 1             |\n| **Total**  | 85    | 24      | 9          | 3             |\n```\n\n### Detailed Report Format\n\nIf `--report-only` flag is set OR user requests detailed report:\n\n```markdown\n## Detailed Findings\n\n### Python (12 missing, 5 incomplete, 2 format issues)\n\n#### Missing Documentation\n\n1. **[src/api.py:15]** `process_request(data: dict) -> Response`\n   - Type: function\n   - Visibility: public\n\n2. **[src/models.py:8]** `class User`\n   - Type: class\n   - Visibility: public\n\n#### Incomplete Documentation\n\n3. **[src/utils.py:42]** `validate_input(value, schema)`\n   - Has: Description\n   - Missing: Args, Returns, Raises\n\n#### Format Issues\n\n4. **[src/helpers.py:20]** `format_output(data)`\n   - Issue: Docstring uses reST format instead of Google format\n\n### TypeScript (8 missing, 3 incomplete)\n...\n\n### Go (4 missing, 1 incomplete, 1 format issue)\n...\n```\n\n## Phase 4: Interactive Generation\n\nIf `--report-only` is NOT set, offer generation choices.\n\n### User Choice\n\nUse `AskUserQuestion` with these options:\n\n**Question:** \"Found {total} documentation gaps. What would you like to do?\"\n\n**Options:**\n1. \"Generate all missing docs\" - Generate documentation for all findings\n2. \"Generate for specific language\" - Choose which language(s) to generate for\n3. \"Show detailed report first\" - Display full findings before deciding\n4. \"Skip generation\" - Exit with report only\n\n### Generation Agent Prompts\n\nFor each language needing generation, spawn a generation agent:\n\n**Python Generation Agent:**\n```\nYou are a Python documentation generator. Generate Google-format docstrings.\n\nSTANDARD:\n[Embed Python standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/class implementation\n2. Understand parameters, return values, and exceptions\n3. Generate a complete Google-format docstring\n4. Apply the edit using the Edit tool\n\nRULES:\n- Match existing code style\n- Use imperative mood for descriptions\n- Include all Args, Returns, Raises\n- Don't modify any code logic\n```\n\n**TypeScript Generation Agent:**\n```\nYou are a TypeScript documentation generator. Generate JSDoc comments.\n\nSTANDARD:\n[Embed TypeScript standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/class/interface implementation\n2. Understand parameters, return types, and exceptions\n3. Generate a complete JSDoc comment\n4. Apply the edit using the Edit tool\n\nRULES:\n- Match existing code style\n- Include @param, @returns, @throws as needed\n- Don't modify any code logic\n```\n\n**Go Generation Agent:**\n```\nYou are a Go documentation generator. Generate GoDoc comments.\n\nSTANDARD:\n[Embed Go standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/type implementation\n2. Understand purpose, parameters, and behavior\n3. Generate a comment starting with the symbol name\n4. Apply the edit using the Edit tool\n\nRULES:\n- Start comment with symbol name\n- Be concise but complete\n- Don't modify any code logic\n```\n\n## Phase 5: Post-Generation Verification\n\nAfter generating documentation, offer to run language linters to verify.\n\n### Verification Commands\n\n**Python:**\n```bash\n# Check docstring formatting with ruff (requires convention=\"google\" in pyproject.toml [tool.ruff.lint.pydocstyle])\nruff check . --select=D --output-format=concise\n\n# Alternative: pydocstyle\npydocstyle --convention=google .\n```\n\n**TypeScript:**\n```bash\n# Check JSDoc with eslint (requires eslint-plugin-jsdoc)\nnpx eslint . --rule 'jsdoc/require-jsdoc: error' --rule 'jsdoc/require-param: error' --rule 'jsdoc/require-returns: error'\n```\n\n**Go:**\n```bash\n# Check with staticcheck (golint is deprecated, use golangci-lint for comprehensive linting)\nstaticcheck -checks \"ST1000,ST1020,ST1021,ST1022\" ./...\n```\n\n### Verification Flow\n\n1. After generation completes, ask: \"Run documentation linters to verify?\"\n2. If yes, run appropriate linter(s) based on languages that were modified\n3. Report any remaining issues\n4. Offer to fix linter-reported issues\n\n## Rules\n\n- Always detect languages before spawning agents\n- Spawn agents in parallel for efficiency\n- Present clear summary before offering generation\n- Don't generate docs for test files (except test helpers)\n- Respect `--report-only` flag\n- Run verification after generation when linters are available\n",
        ".cursor/commands/fetch-pr-feedback.md": "# Fetch PR Feedback\n\nFetch review comments from a bot reviewer on the current PR, format them, and evaluate using the receive-feedback skill.\n\n## Usage\n\n```\n/beagle:fetch-pr-feedback [--bot <username>] [--pr <number>]\n```\n\n**Flags:**\n- `--bot <username>` - Bot/reviewer to fetch comments from (default: `coderabbitai[bot]`)\n- `--pr <number>` - PR number to target (default: current branch's PR)\n\n## Instructions\n\n### 1. Parse Arguments\n\nExtract flags from `$ARGUMENTS`:\n- `--bot <username>` or default to `coderabbitai[bot]`\n- `--pr <number>` or detect from current branch\n\n### 2. Get PR Context\n\n```bash\n# If --pr was specified, use that number directly\n# Otherwise, get PR for current branch:\ngh pr view --json number,headRefName,url\n\n# Get repo owner/name:\ngh repo view --json nameWithOwner --jq '.nameWithOwner'\n```\n\nIf no PR exists for current branch, fail with: \"No PR found for current branch. Use --pr to specify a PR number.\"\n\n### 3. Fetch Comments\n\nFetch both types of comments (use `--paginate` to get all):\n\n**Issue comments** (summary/walkthrough posts):\n```bash\ngh api --paginate \"repos/{owner}/{repo}/issues/{number}/comments\" \\\n  --jq '.[] | select(.user.login == \"{bot}\") | .body'\n```\n\n**Review comments** (line-specific):\n```bash\ngh api --paginate \"repos/{owner}/{repo}/pulls/{number}/comments\" \\\n  --jq '.[] | select(.user.login == \"{bot}\") | \"---\\nFile: \\(.path):\\(.line // .original_line)\\n\\(.body)\\n\"'\n```\n\n### 4. Format Feedback Document\n\nStrip noise from the content:\n- Remove `<details>` blocks containing \"Learnings\" or AI command hints\n- Remove excessive whitespace\n\nStructure the output:\n\n```markdown\n# PR Feedback from {bot}\n\n## Summary/Overview\n[All issue comments here - there may be multiple]\n\n## Line-Specific Comments\n[All review comments here, each prefixed with \"File: path:line\"]\n```\n\nIf no comments found, output: \"No comments from {bot} found on this PR.\"\n\n### 5. Evaluate with receive-feedback\n\nProcess the formatted feedback document using the receive-feedback workflow:\n\n## Receive Feedback Workflow\n\nProcess code review feedback with verification-first discipline. No performative agreement. Technical correctness over social comfort.\n\n### Core Principle\n\n**Verify before implementing. Ask before assuming.**\n\n### Workflow Overview\n\n```\n          \n   VERIFY         EVALUATE        EXECUTE   \n (tool-based)      (decision          (implement/ \n                    matrix)            reject/    \n            defer)     \n                                         \n```\n\nFor each feedback item:\n1. **Verify** - Use tools to check if feedback is technically valid\n2. **Evaluate** - Apply decision matrix to determine action\n3. **Execute** - Implement, reject with evidence, or defer\n\n### Verification Workflow\n\nDo not trust feedback. Verify it against the current codebase state.\n\n**Verification by Feedback Type:**\n\n| Feedback Type | Verification Method |\n|---------------|---------------------|\n| \"Unused code\" | `Grep` for usage across codebase |\n| \"Bug/Error\" | Reproduce with test or script |\n| \"Missing import\" | Check file, run linter |\n| \"Style/Convention\" | Check existing patterns in codebase |\n| \"Performance issue\" | Profile or benchmark if possible |\n| \"Security concern\" | Trace data flow, check sanitization |\n\n**Verification Steps:**\n\nFor EACH feedback item:\n\n1. **Locate**: Find the referenced code (`Read` tool)\n2. **Context**: Understand why it exists (`Grep` for usage, git blame)\n3. **Validate**: Test the claim (run tests, reproduce issue)\n4. **Document**: Note verification result before proceeding\n\n**Using Code-Review Skills for Verification:**\n\nWhen feedback relates to a specific domain, load the relevant skill:\n\n| Domain | Skill to Reference |\n|--------|-------------------|\n| Python quality | python-code-review |\n| FastAPI routes | fastapi-code-review |\n| SQLAlchemy ORM | sqlalchemy-code-review |\n| React components | shadcn-code-review |\n| Routing | react-router-code-review |\n| Database queries | postgres-code-review |\n| Tests | pytest-code-review, vitest-testing |\n\nThese skills contain the authoritative patterns for this codebase. If feedback conflicts with skill guidance, flag for discussion.\n\n**Example:**\n\nFeedback: \"Remove unused `validate_user` function\"\n\nVerification:\n1. `Grep` for \"validate_user\" across codebase\n2. Found: Called in `auth/middleware.py:45`\n3. Result: **Feedback incorrect** - function is used\n4. Action: Push back with evidence\n\n### Evaluation Rules\n\n**Decision Matrix:**\n\n| Condition | Action | Response |\n|-----------|--------|----------|\n| **Correct & In Scope** | Implement immediately | \"Fixed in [file:line]\" |\n| **Correct but Out of Scope** | Defer | \"Valid point. Out of scope; added to backlog.\" |\n| **Technically Incorrect** | Reject with evidence | \"Verified: [evidence]. Maintaining current implementation.\" |\n| **Ambiguous / Unclear** | STOP and ask | \"Clarification needed: [specific question]\" |\n| **Violates YAGNI** | Reject | \"Not currently used by any consumer. Skipping (YAGNI).\" |\n| **Conflicts with codebase patterns** | Flag for discussion | \"Conflicts with established pattern in [location]. Discuss?\" |\n\n**Evaluation Order:**\n\nProcess feedback items in this order:\n\n1. **Clarify** - Resolve all ambiguous items first\n2. **Critical** - Security issues, breaking bugs\n3. **Simple** - Typos, imports, formatting\n4. **Complex** - Refactoring, logic changes, architecture\n\n**When To Push Back:**\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Conflicts with established codebase patterns\n- Legacy/compatibility reasons exist\n\n**Anti-Patterns:**\n\n| Forbidden | Why | Instead |\n|-----------|-----|---------|\n| \"You're absolutely right!\" | Performative, adds no value | State the fix or push back |\n| \"Great catch!\" | Social noise | Just fix it |\n| Implementing without verifying | May introduce bugs | Verify first |\n| Batch implementing | Hard to isolate regressions | One at a time, test each |\n\n### Response Format\n\nAfter processing all feedback items, produce this summary:\n\n```markdown\n## Feedback Response\n\n### Implemented\n| # | Item | Location | Notes |\n|---|------|----------|-------|\n| 1 | Fixed null check | `src/auth.py:42` | Added validation |\n| 3 | Renamed variable | `src/utils.py:15` | `data`  `user_data` |\n\n### Rejected\n| # | Item | Reason | Evidence |\n|---|------|--------|----------|\n| 2 | Remove validate_user | Function is used | Called in `middleware.py:45` |\n| 5 | Add generator | Premature optimization | Processes <1KB once at startup |\n\n### Deferred\n| # | Item | Reason |\n|---|------|--------|\n| 4 | Add caching layer | Out of scope for this PR |\n\n### Needs Clarification\n| # | Item | Question |\n|---|------|----------|\n| 6 | \"Fix the auth flow\" | Which specific aspect? Token refresh? Session handling? |\n```\n\n**Response Guidelines:**\n\n- **Be terse** - No filler words, no apologies\n- **Be specific** - Include file:line references\n- **Be evidenced** - Rejections must cite verification results\n- **Be actionable** - Clarification questions should be specific\n\n**Single-Item Responses:**\n\nFor quick acknowledgments during implementation:\n\n| Outcome | Response Format |\n|---------|-----------------|\n| Implemented | \"Fixed in `file:line`\" |\n| Rejected | \"Verified: [evidence]. Keeping current implementation.\" |\n| Deferred | \"Valid. Out of scope for this task.\" |\n| Unclear | \"Need clarification: [specific question]\" |\n\n### Feedback Tracking\n\n**Purpose:**\n\nMaintain a log of processed feedback for:\n- Reference during follow-up discussions\n- Pattern recognition (recurring feedback types)\n- Accountability (what was decided and why)\n\n**Tracking Prompt:**\n\nAfter processing feedback, always ask:\n\n> \"Log this feedback session to `.feedback-log.csv`? (y/n)\"\n\nDo not assume. Do not auto-track. Always prompt.\n\n**Log Format:**\n\nAppend to `.feedback-log.csv` in project root:\n\n```csv\ndate,source,item_number,item_summary,disposition,location,evidence\n2025-01-15,PR #123 @reviewer,1,Fix null check,implemented,auth.py:42,\n2025-01-15,PR #123 @reviewer,2,Remove unused fn,rejected,validate_user,Used in middleware.py:45\n2025-01-15,PR #123 @reviewer,3,Add caching,deferred,,Out of scope\n```\n\n**CSV Columns:**\n\n| Column | Description |\n|--------|-------------|\n| date | ISO date (YYYY-MM-DD) |\n| source | Origin of feedback (PR #, reviewer, session) |\n| item_number | Feedback item number from source |\n| item_summary | Brief description of the item |\n| disposition | implemented / rejected / deferred / clarified |\n| location | File:line where change was made (if applicable) |\n| evidence | Reason for rejection/deferral (if applicable) |\n\n**Log Location:**\n\nDefault: `.feedback-log.csv` in project root (gitignored)\n\n## Example\n\n```bash\n# Fetch CodeRabbit comments on current branch's PR (default)\n/beagle:fetch-pr-feedback\n\n# Fetch from a different bot\n/beagle:fetch-pr-feedback --bot renovate[bot]\n\n# Fetch from a specific PR\n/beagle:fetch-pr-feedback --pr 123\n\n# Combined\n/beagle:fetch-pr-feedback --bot coderabbitai[bot] --pr 456\n```\n",
        ".cursor/commands/gen-release-notes.md": "# Release Notes Generator\n\nGenerate professional release notes following the Keep a Changelog standard.\n\n**Input**: Previous tag (e.g., `v0.0.1`)\n\n```\n$ARGUMENTS\n```\n\n---\n\nUse extended thinking to analyze the changes thoroughly before generating release notes.\n\n## Step 1: Gather Changes\n\nRun these commands to collect information about changes since the provided tag:\n\n```bash\n# Store the previous tag\nPREV_TAG=\"$ARGUMENTS\"\n\n# Verify the tag exists\ngit tag -l \"$PREV_TAG\"\n\n# Get the repo URL for PR links\ngit remote get-url origin\n\n# List commits since last tag\ngit log ${PREV_TAG}..HEAD --pretty=format:\"%h %s\" --no-merges\n\n# Get detailed diff stats\ngit diff ${PREV_TAG}..HEAD --stat\n\n# List changed files by directory\ngit diff ${PREV_TAG}..HEAD --name-only | sort | uniq\n```\n\nAlso gather PR information:\n\n```bash\n# Get merged PRs since the tag (requires gh CLI)\ngh pr list --state merged --search \"merged:>=$(git log -1 --format=%ci $PREV_TAG | cut -d' ' -f1)\" --json number,title,author,labels\n```\n\n## Step 2: Analyze and Categorize\n\nCategorize each change into exactly one of these groups (in this order):\n\n| Category | Include | Exclude |\n|----------|---------|---------|\n| **Added** | New features, new public APIs, new CLI commands | Internal utilities not exposed to users |\n| **Changed** | Modified behavior, performance improvements, updated dependencies with user impact | Refactors with no behavior change |\n| **Deprecated** | Features marked for future removal | - |\n| **Removed** | Deleted features, removed public APIs | Removed internal code |\n| **Fixed** | Bug fixes, error handling improvements | Test-only fixes |\n| **Security** | Vulnerability patches, security hardening | - |\n\n**Exclude entirely:**\n- CI/CD configuration changes (unless they affect users)\n- Documentation-only changes (unless they reveal new features)\n- Code style/formatting changes\n- Test-only changes\n- Internal refactors with no user-visible impact\n- Merge commits\n\n## Step 3: Determine Version Number\n\nBased on the changes, suggest the next version following Semantic Versioning:\n- **MAJOR** (X.0.0): Breaking changes to public API\n- **MINOR** (x.Y.0): New features, backward-compatible\n- **PATCH** (x.y.Z): Bug fixes only\n\nDetect the tag format from existing tags (with or without `v` prefix).\n\n## Step 4: Write Release Notes\n\nGenerate a `CHANGELOG.md` entry using this exact format:\n\n```markdown\n## [VERSION] - YYYY-MM-DD\n\n### Added\n\n- **scope:** Add new feature description ([#54](REPO_URL/pull/54))\n\n### Changed\n\n- **Breaking:** Rename `oldName()` to `newName()` for consistency ([#145](REPO_URL/pull/145))\n\n  **Migration:** Replace all calls to `oldName()` with `newName()`.\n\n### Deprecated\n\n- **scope:** Deprecate `legacy_function()` in favor of `new_function()` ([#143](REPO_URL/pull/143))\n\n### Removed\n\n- **Breaking:** Remove deprecated `old_function()` ([#141](REPO_URL/pull/141))\n\n### Fixed\n\n- **scope:** Fix race condition when multiple workers access shared state ([#139](REPO_URL/pull/139))\n\n### Security\n\n- **deps:** Update vulnerable package to patched version ([#49](REPO_URL/pull/49))\n```\n\n### Writing Rules\n\n**Format requirements:**\n- Start every entry with an imperative verb: Add, Fix, Remove, Update, Improve, Rename, Deprecate, Patch\n- Include scope prefix in bold when present: `**server:**`, `**cli:**`, `**api:**`\n- One line per change (except breaking changes which get migration notes)\n- Include PR/issue link at end of line\n- Sort entries within each category by importance (most impactful first)\n- Omit empty categories entirely\n\n**Breaking changes:**\n- Prefix with bold `**Breaking:**`\n- List first within their category\n- Add a `**Migration:**` block on the next line explaining exactly what users must change\n- Include before/after code examples for API signature changes\n\n**Tone:**\n- Write for library consumers, not maintainers\n- Focus on *what changed for users*, not *how it was implemented*\n- Be specificnever write \"various improvements\" or \"bug fixes\"\n- Each entry should be understandable without reading the PR\n\n**Bad examples to avoid:**\n```markdown\n# BAD - Too vague\n- Fixed bugs\n- Performance improvements\n- Updated dependencies\n\n# BAD - Implementation-focused\n- Refactored the internal state machine to use async/await\n\n# BAD - Missing context\n- Fixed #234\n```\n\n**Good examples to follow:**\n```markdown\n# GOOD - Specific and user-focused\n- **server:** Fix timeout errors when processing files larger than 100MB ([#234](URL))\n- **cli:** Add `--dry-run` flag to preview changes before execution ([#235](URL))\n- **api:** Improve cold-start latency from 2.3s to 0.8s by lazy-loading plugins ([#236](URL))\n```\n\n## Step 5: Update CHANGELOG.md\n\n1. If `CHANGELOG.md` exists:\n   - Insert new version after the `## [Unreleased]` section (or at top if no Unreleased)\n\n2. If `CHANGELOG.md` doesn't exist, create it with this header:\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n```\n\n3. Add version comparison links at the bottom of the file using the detected repo URL.\n\n## Step 6: Output Summary\n\nAfter updating the changelog, provide:\n1. The suggested version number with rationale\n2. Summary of categorized changes\n3. Any breaking changes that need special attention\n4. Confirmation that CHANGELOG.md was updated\n\n## Conventional Commits Mapping\n\nMap commit prefixes to changelog categories:\n\n| Commit Prefix | Changelog Category |\n|---------------|-------------------|\n| `feat(scope):` | Added |\n| `feat!(scope):` | Added (with Breaking prefix) |\n| `fix(scope):` | Fixed |\n| `perf(scope):` | Changed |\n| `security(scope):` | Security |\n| `docs:`, `chore:`, `ci:`, `test:`, `style:` | **Exclude** |\n",
        ".cursor/commands/prompt-improver.md": "---\ndescription: Optimize prompts for code-related tasks following Claude best practices. Use when refining prompts for implementation, debugging, refactoring, code review, or testing.\n---\n\n# Prompt Improver\n\nOptimize code-related prompts for clarity, investigation-first thinking, and verification.\n\n## Input\n\n```\n$ARGUMENTS\n```\n\n---\n\n## Step 1: Analyze the Prompt\n\nEvaluate the input prompt across these dimensions:\n\n| Dimension | What to check |\n|-----------|---------------|\n| Task Clarity | Is the task type clear? (implement, fix, refactor, review, test) Are boundaries defined? |\n| Investigation | Does it specify reading/understanding before acting? |\n| Verification | Are there appropriate checks? (run tests, build, lint) |\n| Context Anchoring | Does it reference specific files, functions, or patterns? |\n| Action Specificity | Is the desired outcome explicit? Quality expectations stated? |\n| Scope Control | Is it appropriately scoped? Clear stopping points? |\n\nIdentify which dimensions are weak or missing in the input prompt.\n\n## Step 2: Apply Transformation Rules\n\n### Task Clarity\n- Convert vague requests  specific task type + scope\n- Add \"implement\", \"fix\", \"refactor\", \"review\", or \"test\" when ambiguous\n- Specify affected files/components when inferable\n\n### Investigation-First\n- Add \"Read and understand [relevant files] before making changes\"\n- For bugs: \"Reproduce and understand the root cause first\"\n- For features: \"Check existing patterns in the codebase\"\n\n### Anti-Hallucination\n- \"Do not assume code structure you haven't read\"\n- \"Verify imports/dependencies exist before using them\"\n- \"Check for existing utilities before creating new ones\"\n\n### Verification Steps\n- For implementation: \"Run tests after changes\"\n- For refactoring: \"Ensure behavior is unchanged\"\n- For fixes: \"Verify the fix and check for regressions\"\n\n### Positive Framing\n- Convert \"don't break tests\"  \"ensure tests pass after changes\"\n- Convert \"don't over-engineer\"  \"implement the minimal solution\"\n\n### Scope Control\n- Add explicit boundaries when missing\n- Break multi-part requests into phases if needed\n\n## Examples\n\n### Bug Fix\n```\nOriginal: \"fix the login bug\"\n\nOptimized:\nFix the login bug. First, read the authentication-related files to understand\nthe current implementation. Reproduce the bug to confirm the issue. Identify\nthe root cause before making changes. Implement the fix and run existing tests\nto verify no regressions.\n```\n\n### Feature Implementation\n```\nOriginal: \"add dark mode\"\n\nOptimized:\nImplement dark mode for the application. First, check how theming/styling is\ncurrently handled in the codebase. Look for existing color variables or theme\npatterns. Implement the toggle and theme switching with minimal changes to\nexisting components. Run tests and verify the UI renders correctly in both modes.\n```\n\n### Refactoring\n```\nOriginal: \"clean up the user service\"\n\nOptimized:\nRefactor the user service for improved maintainability. Read the current\nimplementation and understand its responsibilities. Identify specific issues\n(duplication, unclear naming, tight coupling). Make incremental changes,\nrunning tests after each step to ensure behavior is unchanged.\n```\n\n## Task-Type Tips\n\n| Task Type | Tip |\n|-----------|-----|\n| Bug fixes | Include reproduction steps if known. Specify whether this is a quick fix or needs root cause analysis. |\n| Feature implementation | Reference similar features in the codebase. Specify if tests are expected. |\n| Refactoring | State the goal (readability, performance, testability). Emphasize incremental changes. |\n| Code review | Specify focus areas (security, performance, style). Mention what to ignore. |\n| Testing | Specify test type (unit, integration, e2e). Reference existing test patterns. |\n\n## Step 3: Generate Output\n\nProduce output in this exact format:\n\n### Analysis\n\n[2-3 sentences identifying the prompt type and which dimensions are weak]\n\n### Improvements Applied\n\n- [Bullet list of specific transformations applied]\n\n### Optimized Prompt\n\n```\n[The improved prompt, ready to copy and use]\n```\n\n### Tips for This Prompt Type\n\n[1-2 sentences of relevant tips from the Task-Type Tips table]\n",
        ".cursor/commands/receive-feedback.md": "# Receive Feedback Command\n\nProcess external code review feedback using verification-first discipline.\n\n## Usage\n\n```\n/receive-feedback path/to/feedback.md\n```\n\n## Workflow\n\n1. **Read** the feedback file at `$ARGUMENTS`\n2. **Parse** individual feedback items (numbered, bulleted, or freeform)\n3. **Process** each item through verify  evaluate  execute workflow\n4. **Produce** structured response summary\n5. **Prompt** whether to log to `.feedback-log.csv`\n\n## Expected Feedback File Format\n\nThe feedback file should contain numbered or bulleted items:\n\n```markdown\n1. Remove unused import on line 15\n2. Add error handling to the API call\n3. Consider using a generator for large datasets\n4. Fix typo in variable name: `usr`  `user`\n```\n\nOr freeform prose - extract actionable items from the text.\n\n## Example\n\n```\n/receive-feedback reviews/pr-123-feedback.md\n```\n\nReads the file, processes each item with technical verification,\nand outputs a structured response table.\n\n---\n\n# Processing Framework\n\n## Core Principle\n\n**Verify before implementing. Ask before assuming.**\n\nNo performative agreement. Technical correctness over social comfort.\n\n## Quick Reference\n\n```\n          \n   VERIFY         EVALUATE        EXECUTE   \n (tool-based)      (decision          (implement/ \n                    matrix)            reject/    \n            defer)     \n                                         \n```\n\n## When To Use\n\n- Receiving code review from another LLM session\n- Processing PR review comments\n- Evaluating CI/linter feedback\n- Handling suggestions from pair programming\n\n---\n\n# 1. Verification Workflow\n\n## Principle\n\nDo not trust feedback. Verify it against the current codebase state.\n\n## Verification by Feedback Type\n\n| Feedback Type | Verification Method |\n|---------------|---------------------|\n| \"Unused code\" | `Grep` for usage across codebase |\n| \"Bug/Error\" | Reproduce with test or script |\n| \"Missing import\" | Check file, run linter |\n| \"Style/Convention\" | Check existing patterns in codebase |\n| \"Performance issue\" | Profile or benchmark if possible |\n| \"Security concern\" | Trace data flow, check sanitization |\n\n## Verification Steps\n\nFor EACH feedback item:\n\n1. **Locate**: Find the referenced code (`Read` tool)\n2. **Context**: Understand why it exists (`Grep` for usage, git blame)\n3. **Validate**: Test the claim (run tests, reproduce issue)\n4. **Document**: Note verification result before proceeding\n\n## Using Code-Review Skills for Verification\n\nWhen feedback relates to a specific domain, load the relevant skill:\n\n| Domain | Skill to Reference |\n|--------|-------------------|\n| Python quality | python-code-review |\n| FastAPI routes | fastapi-code-review |\n| SQLAlchemy ORM | sqlalchemy-code-review |\n| React components | shadcn-code-review |\n| Routing | react-router-code-review |\n| Database queries | postgres-code-review |\n| Tests | pytest-code-review, vitest-testing |\n\nThese skills contain the authoritative patterns for this codebase.\nIf feedback conflicts with skill guidance, flag for discussion.\n\n## Example\n\nFeedback: \"Remove unused `validate_user` function\"\n\nVerification:\n1. `Grep` for \"validate_user\" across codebase\n2. Found: Called in `auth/middleware.py:45`\n3. Result: **Feedback incorrect** - function is used\n4. Action: Push back with evidence\n\n---\n\n# 2. Evaluation Rules\n\n## Decision Matrix\n\n| Condition | Action | Response |\n|-----------|--------|----------|\n| **Correct & In Scope** | Implement immediately | \"Fixed in [file:line]\" |\n| **Correct but Out of Scope** | Defer | \"Valid point. Out of scope; added to backlog.\" |\n| **Technically Incorrect** | Reject with evidence | \"Verified: [evidence]. Maintaining current implementation.\" |\n| **Ambiguous / Unclear** | STOP and ask | \"Clarification needed: [specific question]\" |\n| **Violates YAGNI** | Reject | \"Not currently used by any consumer. Skipping (YAGNI).\" |\n| **Conflicts with codebase patterns** | Flag for discussion | \"Conflicts with established pattern in [location]. Discuss?\" |\n\n## Evaluation Order\n\nProcess feedback items in this order:\n\n1. **Clarify** - Resolve all ambiguous items first\n2. **Critical** - Security issues, breaking bugs\n3. **Simple** - Typos, imports, formatting\n4. **Complex** - Refactoring, logic changes, architecture\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Conflicts with established codebase patterns\n- Legacy/compatibility reasons exist\n\n## Anti-Patterns\n\n| Forbidden | Why | Instead |\n|-----------|-----|---------|\n| \"You're absolutely right!\" | Performative, adds no value | State the fix or push back |\n| \"Great catch!\" | Social noise | Just fix it |\n| Implementing without verifying | May introduce bugs | Verify first |\n| Batch implementing | Hard to isolate regressions | One at a time, test each |\n\n---\n\n# 3. Response Format\n\n## Structured Output Template\n\nAfter processing all feedback items, produce this summary:\n\n```markdown\n## Feedback Response\n\n### Implemented\n| # | Item | Location | Notes |\n|---|------|----------|-------|\n| 1 | Fixed null check | `src/auth.py:42` | Added validation |\n| 3 | Renamed variable | `src/utils.py:15` | `data`  `user_data` |\n\n### Rejected\n| # | Item | Reason | Evidence |\n|---|------|--------|----------|\n| 2 | Remove validate_user | Function is used | Called in `middleware.py:45` |\n| 5 | Add generator | Premature optimization | Processes <1KB once at startup |\n\n### Deferred\n| # | Item | Reason |\n|---|------|--------|\n| 4 | Add caching layer | Out of scope for this PR |\n\n### Needs Clarification\n| # | Item | Question |\n|---|------|----------|\n| 6 | \"Fix the auth flow\" | Which specific aspect? Token refresh? Session handling? |\n```\n\n## Response Guidelines\n\n- **Be terse** - No filler words, no apologies\n- **Be specific** - Include file:line references\n- **Be evidenced** - Rejections must cite verification results\n- **Be actionable** - Clarification questions should be specific\n\n## Single-Item Responses\n\nFor quick acknowledgments during implementation:\n\n| Outcome | Response Format |\n|---------|-----------------|\n| Implemented | \"Fixed in `file:line`\" |\n| Rejected | \"Verified: [evidence]. Keeping current implementation.\" |\n| Deferred | \"Valid. Out of scope for this task.\" |\n| Unclear | \"Need clarification: [specific question]\" |\n\n---\n\n# 4. Feedback Tracking\n\n## Purpose\n\nMaintain a log of processed feedback for:\n- Reference during follow-up discussions\n- Pattern recognition (recurring feedback types)\n- Accountability (what was decided and why)\n\n## Tracking Prompt\n\nAfter processing feedback, always ask:\n\n> \"Log this feedback session to `.feedback-log.csv`? (y/n)\"\n\nDo not assume. Do not auto-track. Always prompt.\n\n## Log Format\n\nAppend to `.feedback-log.csv` in project root:\n\n```csv\ndate,source,item_number,item_summary,disposition,location,evidence\n2025-01-15,PR #123 @reviewer,1,Fix null check,implemented,auth.py:42,\n2025-01-15,PR #123 @reviewer,2,Remove unused fn,rejected,validate_user,Used in middleware.py:45\n2025-01-15,PR #123 @reviewer,3,Add caching,deferred,,Out of scope\n```\n\n## CSV Columns\n\n| Column | Description |\n|--------|-------------|\n| date | ISO date (YYYY-MM-DD) |\n| source | Origin of feedback (PR #, reviewer, session) |\n| item_number | Feedback item number from source |\n| item_summary | Brief description of the item |\n| disposition | implemented / rejected / deferred / clarified |\n| location | File:line where change was made (if applicable) |\n| evidence | Reason for rejection/deferral (if applicable) |\n\n## Log Location\n\nDefault: `.feedback-log.csv` in project root (gitignored)\n\n---\n\n# 5. Skill Integration\n\n## Using Code-Review Skills for Verification\n\nWhen feedback relates to a specific technology, load the relevant skill\nto verify against established codebase patterns.\n\n## Skill Lookup Table\n\n| Feedback Domain | Skill | Key Patterns to Check |\n|-----------------|-------|----------------------|\n| Python code quality | python-code-review | Type hints, error handling, naming |\n| FastAPI endpoints | fastapi-code-review | Dependency injection, response models |\n| SQLAlchemy models | sqlalchemy-code-review | Relationships, session handling |\n| Pytest tests | pytest-code-review | Fixtures, parametrization, mocking |\n| PostgreSQL queries | postgres-code-review | Indexes, joins, transactions |\n| React components | shadcn-code-review | Component composition, accessibility |\n| React Router | react-router-code-review | Loaders, actions, error boundaries |\n| Tailwind styling | tailwind-v4 | Utility classes, responsive design |\n| State management | zustand-state | Store structure, selectors |\n| Vitest tests | vitest-testing | Test structure, mocking |\n\n## Integration Workflow\n\n1. **Identify domain** - What technology does the feedback concern?\n2. **Load skill** - Use Skill tool to load relevant skill\n3. **Cross-reference** - Does feedback align with skill guidance?\n4. **Resolve conflicts** - If feedback contradicts skill, flag for discussion\n\n## Conflict Resolution\n\nIf reviewer feedback conflicts with skill guidance:\n\n```\nSkill says: [pattern from skill]\nReviewer says: [contradicting suggestion]\n\nFlag: \"Feedback conflicts with established pattern. Discuss before implementing.\"\n```\n\nCodebase patterns (captured in skills) take precedence over external opinions.\n",
        ".cursor/commands/respond-pr-feedback.md": "# Respond to PR Feedback\n\nPost replies to bot review comments after you've evaluated the feedback and made fixes.\n\n## Usage\n\n```\n/beagle:respond-pr-feedback [--bot <username>] [--pr <number>] [--as <username>]\n```\n\n**Flags:**\n- `--bot <username>` - Bot whose comments to respond to (default: `coderabbitai[bot]`)\n- `--pr <number>` - PR number to target (default: current branch's PR)\n- `--as <username>` - Filter already-replied based on this responder (default: current `gh` user)\n\n## Prerequisites\n\nRun `/beagle:fetch-pr-feedback` first to evaluate the feedback and make any necessary fixes.\n\n## Instructions\n\n### 1. Parse Arguments\n\nExtract flags from `$ARGUMENTS`:\n- `--bot <username>` or default to `coderabbitai[bot]`\n- `--pr <number>` or detect from current branch\n- `--as <username>` or detect from `gh api user`\n\n### 2. Get PR Context\n\n```bash\n# Get repo info\ngh repo view --json nameWithOwner --jq '.nameWithOwner'\n\n# Get PR number (if not specified)\ngh pr view --json number --jq '.number'\n\n# Get responder username (if --as not specified)\ngh api user --jq '.login'\n```\n\n### 3. Fetch Unreplied Comments\n\nThis query filters out already-replied comments and deduplicates (CodeRabbit reposts on each iteration):\n\n```bash\ngh api --paginate \"repos/{owner}/{repo}/pulls/{number}/comments\" | jq -s 'add |\n  # Get root comments from target bot (not replies to itself)\n  [.[] | select(.user.login == \"{bot}\" and .in_reply_to_id == null)] as $roots |\n  # Get IDs that responder has already replied to\n  [.[] | select(.user.login == \"{responder}\") | .in_reply_to_id] as $replied |\n  # Filter to unreplied comments only\n  $roots | map(select(. as $c | $replied | index($c.id) == null)) |\n  # Group by file:line and pick newest comment for each (handles duplicates)\n  group_by({p: .path, l: .line}) |\n  map(sort_by(.created_at) | last) |\n  # Output needed fields\n  map({id, path, line, body})\n'\n```\n\nIf no unreplied comments found, output: \"All {bot} comments have been addressed.\"\n\n### 4. Generate and Post Replies\n\nFor each unreplied comment, determine the appropriate response based on your evaluation:\n\n| Evaluation Outcome | Response |\n|-------------------|----------|\n| Feedback was incorrect/unfounded | Explain why the current code is correct |\n| Feedback lacked context | Explain the design decision |\n| Feedback was valid and fixed | \"Fixed in {commit}\" or brief description of change |\n| Feedback was valid but won't fix | Explain the tradeoff/decision |\n\nPost reply to each comment:\n\n```bash\ngh api \"repos/{owner}/{repo}/pulls/{number}/comments/{comment_id}/replies\" \\\n  -X POST --raw-field body=\"@{bot} {response}\"\n```\n\n### 5. Prompt to Resolve Threads\n\nAfter posting replies, ask the user:\n\n> Would you like to resolve these conversation threads?\n> 1. **Yes, all** - Resolve all threads that were just replied to\n> 2. **Select individually** - Choose which threads to resolve\n> 3. **No** - Leave threads open for further discussion\n\nTo resolve a thread, use the GraphQL API:\n\n```bash\ngh api graphql -f query='\n  mutation {\n    resolveReviewThread(input: {threadId: \"{thread_id}\"}) {\n      thread { isResolved }\n    }\n  }\n'\n```\n\nNote: To get the `thread_id`, you need to query review threads:\n```bash\ngh api graphql -f query='\n  query {\n    repository(owner: \"{owner}\", name: \"{repo}\") {\n      pullRequest(number: {number}) {\n        reviewThreads(first: 100) {\n          nodes {\n            id\n            isResolved\n            comments(first: 1) {\n              nodes { databaseId }\n            }\n          }\n        }\n      }\n    }\n  }\n'\n```\n\nMatch `databaseId` to your comment IDs to find the corresponding `thread_id`.\n\n### 6. Output Summary\n\nDisplay a summary table:\n\n| File:Line | Response Type | Thread Status |\n|-----------|---------------|---------------|\n| `src/foo.ts:42` | Fixed | Resolved |\n| `src/bar.ts:15` | Explained design | Open |\n\n## Response Guidelines\n\n- **Always tag the bot** at the start: `@coderabbitai ...`\n- Keep responses concise and technical\n- No performative agreement (\"Great point!\", \"You're right!\")\n- Reference specific code/design when explaining decisions\n- If fixed: state what changed, no gratitude\n\n## Example\n\n```bash\n# Respond to CodeRabbit on current PR\n/beagle:respond-pr-feedback\n\n# Respond on a specific PR\n/beagle:respond-pr-feedback --pr 123\n\n# Use different bot/responder\n/beagle:respond-pr-feedback --bot renovate[bot] --as my-bot[bot]\n```\n",
        ".cursor/commands/review-frontend.md": "# Frontend Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.(tsx?|css)$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect React Flow\ngrep -r \"@xyflow/react\\|ReactFlow\\|useNodesState\" --include=\"*.tsx\" -l | head -3\n\n# Detect Zustand\ngrep -r \"from 'zustand'\\|create\\(\\(\" --include=\"*.ts\" --include=\"*.tsx\" -l | head -3\n\n# Detect Tailwind v4\ngrep -r \"@theme\\|@layer theme\" --include=\"*.css\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.test\\.tsx?$'\n```\n\n## Step 3: Technology-Specific Review Guidelines\n\nThe following sections provide comprehensive review guidance for each technology area. Apply the relevant sections based on detected technologies:\n\n- **Always apply**: React Router, shadcn/ui\n- **Conditionally apply**: React Flow, Zustand, Tailwind v4, Vitest (based on detection results)\n\n---\n\n# React Router Code Review\n\n## Review Checklist\n\n- [ ] Data loaded via `loader` not `useEffect`\n- [ ] Route params accessed type-safely with validation\n- [ ] Using `defer()` for parallel data fetching when appropriate\n- [ ] Mutations use `<Form>` or `useFetcher` not manual fetch\n- [ ] Actions handle both success and error cases\n- [ ] Error boundaries with `errorElement` on routes\n- [ ] Using `isRouteErrorResponse()` to check error types\n- [ ] Navigation uses `<Link>` over `navigate()` where possible\n- [ ] Pending states shown via `useNavigation()` or `fetcher.state`\n- [ ] No navigation in render (only in effects or handlers)\n\n## Critical Issues to Flag\n\n### Data Loading Anti-Patterns\n\n**Using useEffect Instead of Loaders**\n- **Issue**: Race conditions, loading states, unnecessary client-side fetching\n- **Fix**: Use route loaders for data fetching\n- **Example**:\n```tsx\n// BAD - Loading data in useEffect\nfunction UserProfile() {\n  const [user, setUser] = useState(null);\n  const { userId } = useParams();\n  useEffect(() => {\n    fetch(`/api/users/${userId}`).then(r => r.json()).then(setUser);\n  }, [userId]);\n}\n\n// GOOD - Using loader\nconst loader = async ({ params }) => {\n  const response = await fetch(`/api/users/${params.userId}`);\n  if (!response.ok) throw new Response(\"Not Found\", { status: 404 });\n  return response.json();\n};\n```\n\n**Unsafe Route Params Access**\n- **Issue**: Runtime errors from missing or invalid params\n- **Fix**: Validate params before use, preferably with zod\n- **Example**:\n```tsx\n// GOOD - Validate params\nconst loader = async ({ params }) => {\n  const userId = params.userId;\n  if (!userId) throw new Response(\"User ID required\", { status: 400 });\n  return fetch(`/api/users/${userId}`);\n};\n```\n\n**Sequential Data Fetching**\n- **Issue**: Slow page loads when data can be fetched in parallel\n- **Fix**: Use `Promise.all()` or `defer()` for non-critical data\n- **Example**:\n```tsx\n// GOOD - Parallel fetching\nconst loader = async ({ params }) => {\n  const [user, posts, comments] = await Promise.all([\n    fetchUser(params.userId),\n    fetchPosts(params.userId),\n    fetchComments(params.userId),\n  ]);\n  return { user, posts, comments };\n};\n```\n\n### Error Handling Anti-Patterns\n\n**Missing Error Boundaries**\n- **Issue**: Entire app crashes on route errors\n- **Fix**: Add `errorElement` to routes\n- **Example**:\n```tsx\n// GOOD - Error boundaries at route level\n{\n  path: \"users/:userId\",\n  element: <UserProfile />,\n  errorElement: <UserErrorBoundary />,\n  loader: userLoader\n}\n```\n\n**Not Using isRouteErrorResponse**\n- **Issue**: Unsafe error access, runtime errors in error handlers\n- **Fix**: Always use `isRouteErrorResponse()` to check error types\n- **Example**:\n```tsx\n// GOOD - Type-safe error checking\nimport { isRouteErrorResponse } from 'react-router-dom';\n\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    return <div>Error {error.status}: {error.statusText}</div>;\n  }\n\n  if (error instanceof Error) {\n    return <div>Unexpected Error: {error.message}</div>;\n  }\n\n  return <div>An unknown error occurred</div>;\n}\n```\n\n**Throwing Raw Errors Instead of Responses**\n- **Issue**: Missing status codes, inconsistent error format\n- **Fix**: Throw Response objects with proper status codes\n- **Example**:\n```tsx\n// GOOD - Throwing Response objects\nconst loader = async ({ params }) => {\n  const user = await db.user.findUnique({ where: { id: params.userId } });\n\n  if (!user) {\n    throw new Response('User not found', { status: 404 });\n  }\n\n  return user;\n};\n```\n\n### Mutations Anti-Patterns\n\n**Manual Form Submission with fetch**\n- **Issue**: Missing navigation state, manual revalidation, no progressive enhancement\n- **Fix**: Use `<Form>` and route actions\n- **Example**:\n```tsx\n// GOOD - Using Form and action\nimport { Form, useNavigation, useActionData } from 'react-router-dom';\n\nfunction CreateUser() {\n  const navigation = useNavigation();\n  const actionData = useActionData();\n  const isSubmitting = navigation.state === 'submitting';\n\n  return (\n    <Form method=\"post\">\n      <input name=\"name\" />\n      {actionData?.error && <div>{actionData.error}</div>}\n      <button disabled={isSubmitting}>\n        {isSubmitting ? 'Creating...' : 'Create'}\n      </button>\n    </Form>\n  );\n}\n```\n\n**Using Form When useFetcher is Appropriate**\n- **Issue**: Unnecessary navigation, losing current page state\n- **Fix**: Use `useFetcher` for mutations that should stay on current page\n- **Example**:\n```tsx\n// GOOD - useFetcher stays on current page\nfunction TodoItem({ todo }) {\n  const fetcher = useFetcher();\n\n  const isComplete = fetcher.formData\n    ? fetcher.formData.get('complete') === 'true'\n    : todo.complete;\n\n  return (\n    <fetcher.Form method=\"post\" action={`/todos/${todo.id}/toggle`}>\n      <input type=\"hidden\" name=\"complete\" value={String(!isComplete)} />\n      <button disabled={fetcher.state !== 'idle'}>Toggle</button>\n    </fetcher.Form>\n  );\n}\n```\n\n**Missing Optimistic UI**\n- **Issue**: Slow perceived performance, no immediate feedback\n- **Fix**: Show optimistic state using `fetcher.formData`\n- **Example**:\n```tsx\n// GOOD - Optimistic UI\nfunction LikeButton({ postId, liked, likeCount }) {\n  const fetcher = useFetcher();\n\n  const optimisticLiked = fetcher.formData\n    ? fetcher.formData.get('liked') === 'true'\n    : liked;\n\n  const optimisticCount = fetcher.formData\n    ? optimisticLiked ? likeCount + 1 : likeCount - 1\n    : likeCount;\n\n  return (\n    <fetcher.Form method=\"post\">\n      <input type=\"hidden\" name=\"liked\" value={String(!optimisticLiked)} />\n      <button>{optimisticLiked ? '' : ''} {optimisticCount}</button>\n    </fetcher.Form>\n  );\n}\n```\n\n### Navigation Anti-Patterns\n\n**Using navigate() Instead of Link**\n- **Issue**: Missing accessibility, no progressive enhancement, can't open in new tab\n- **Fix**: Use `<Link>` for user-initiated navigation\n- **Example**:\n```tsx\n// GOOD - Use Link for navigation\nfunction UserCard({ userId }) {\n  return (\n    <Link to={`/users/${userId}`} className=\"user-card\">\n      <h3>User {userId}</h3>\n    </Link>\n  );\n}\n```\n\n**Missing Pending UI States**\n- **Issue**: No feedback during navigation, feels broken\n- **Fix**: Show loading state via `useNavigation()`\n- **Example**:\n```tsx\n// GOOD - Show loading state\nimport { useNavigation } from 'react-router-dom';\n\nfunction UserList() {\n  const users = useLoaderData();\n  const navigation = useNavigation();\n\n  return (\n    <div>\n      {navigation.state === 'loading' && <div className=\"loading-bar\" />}\n      <ul className={navigation.state === 'loading' ? 'opacity-50' : ''}>\n        {users.map(user => (\n          <li key={user.id}>\n            <Link to={`/users/${user.id}`}>{user.name}</Link>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n```\n\n**Not Using NavLink for Active Styles**\n- **Issue**: Manual active state management, inconsistent UI\n- **Fix**: Use `<NavLink>` with className function\n- **Example**:\n```tsx\n// GOOD - NavLink with className function\nimport { NavLink } from 'react-router-dom';\n\nfunction Navigation() {\n  return (\n    <nav>\n      <NavLink\n        to=\"/\"\n        end\n        className={({ isActive }) => isActive ? 'active' : ''}\n      >\n        Home\n      </NavLink>\n    </nav>\n  );\n}\n```\n\n---\n\n# shadcn/ui Code Review\n\n## Review Checklist\n\n- [ ] `cn()` receives className, not CVA variants\n- [ ] `VariantProps<typeof variants>` exported for consumers\n- [ ] Compound variants used for complex state combinations\n- [ ] `asChild` pattern uses `@radix-ui/react-slot`\n- [ ] Context used for component composition (Card, Accordion, etc.)\n- [ ] `focus-visible:` states, not just `:focus`\n- [ ] `aria-invalid`, `aria-disabled` for form states\n- [ ] `disabled:` variants for all interactive elements\n- [ ] `sr-only` for screen reader text\n- [ ] `data-slot` attributes for targetable composition parts\n- [ ] CSS uses `has()` selectors for state-based styling\n- [ ] No direct className overrides of variant styles\n\n## Critical Issues to Flag\n\n### CVA Patterns\n\n**className Passed to CVA Instead of cn()**\n- **Issue**: CVA variants cannot be overridden by consumers\n- **Fix**: Pass className to `cn()` after CVA, not as a CVA variant\n- **Example**:\n```tsx\n// GOOD - className in cn()\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nconst buttonVariants = cva(\"base-styles\", {\n  variants: {\n    variant: { default: \"bg-primary\", destructive: \"bg-destructive\" },\n    size: { sm: \"h-9\", lg: \"h-11\" },\n  },\n  defaultVariants: { variant: \"default\", size: \"default\" },\n})\n\nexport function Button({ variant, size, className, ...props }) {\n  return (\n    <button\n      className={cn(buttonVariants({ variant, size }), className)}\n      {...props}\n    />\n  );\n}\n```\n\n**Missing VariantProps Export**\n- **Issue**: Consumers cannot type-check variant props correctly\n- **Fix**: Export VariantProps for type safety\n- **Example**:\n```tsx\n// GOOD - export VariantProps\nconst buttonVariants = cva(...)\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {\n  asChild?: boolean\n}\n\nexport function Button({ variant, size, className, ...props }: ButtonProps) {\n  return <button className={cn(buttonVariants({ variant, size }), className)} {...props} />\n}\n```\n\n**Not Using Compound Variants**\n- **Issue**: Complex state combinations create verbose, repetitive variant definitions\n- **Fix**: Use `compoundVariants` for state combinations\n- **Example**:\n```tsx\n// GOOD - use compoundVariants\nconst buttonVariants = cva(\"rounded font-medium\", {\n  variants: {\n    variant: {\n      default: \"bg-primary text-primary-foreground\",\n      outline: \"border border-input bg-background\",\n    },\n    size: {\n      sm: \"h-9 px-3\",\n      lg: \"h-11 px-8\",\n    },\n  },\n  compoundVariants: [\n    {\n      variant: \"outline\",\n      size: \"sm\",\n      class: \"border-2\",\n    },\n  ],\n})\n```\n\n### Component Composition\n\n**asChild Without Slot**\n- **Issue**: The asChild pattern requires `@radix-ui/react-slot` to work correctly\n- **Fix**: Use Slot from @radix-ui/react-slot\n- **Example**:\n```tsx\n// GOOD - using Slot\nimport { Slot } from \"@radix-ui/react-slot\"\n\nexport function Button({ asChild, className, variant, ...props }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      className={cn(buttonVariants({ variant }), className)}\n      {...props}\n    />\n  );\n}\n```\n\n**Missing Context for Compound Components**\n- **Issue**: Component parts cannot communicate state without Context\n- **Fix**: Use React Context for state sharing\n- **Example**:\n```tsx\n// GOOD - using Context\nconst CardContext = React.createContext<{ variant?: string }>({})\n\nexport function Card({ variant = \"default\", children, ...props }) {\n  return (\n    <CardContext.Provider value={{ variant }}>\n      <div className={cn(cardVariants({ variant }))} {...props}>\n        {children}\n      </div>\n    </CardContext.Provider>\n  );\n}\n\nexport function CardHeader({ className, ...props }) {\n  const { variant } = React.useContext(CardContext)\n  return (\n    <div\n      className={cn(headerVariants({ variant }), className)}\n      {...props}\n    />\n  );\n}\n```\n\n**Not Forwarding Refs with asChild**\n- **Issue**: Refs break when using asChild without forwardRef\n- **Fix**: Use React.forwardRef\n- **Example**:\n```tsx\n// GOOD - forwardRef with asChild\nexport const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ asChild = false, className, variant, ...props }, ref) => {\n    const Comp = asChild ? Slot : \"button\"\n\n    return (\n      <Comp\n        className={cn(buttonVariants({ variant }), className)}\n        ref={ref}\n        {...props}\n      />\n    );\n  }\n)\nButton.displayName = \"Button\"\n```\n\n### Accessibility Patterns\n\n**Using :focus Instead of :focus-visible**\n- **Issue**: Visible focus rings on mouse clicks create poor UX\n- **Fix**: Use `focus-visible:` for keyboard-only focus\n- **Example**:\n```tsx\n// GOOD - :focus-visible shows ring only for keyboard\nconst buttonVariants = cva(\n  \"rounded focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring\"\n)\n```\n\n**Missing aria-invalid for Form States**\n- **Issue**: Screen readers cannot announce validation errors\n- **Fix**: Use `aria-invalid` with proper error announcement\n- **Example**:\n```tsx\n// GOOD - aria-invalid with proper error announcement\nexport function Input({ error, className, ...props }) {\n  const errorId = React.useId()\n\n  return (\n    <div>\n      <input\n        className={cn(\n          \"border rounded focus-visible:ring-2\",\n          error && \"border-destructive focus-visible:ring-destructive\",\n          className\n        )}\n        aria-invalid={error ? \"true\" : undefined}\n        aria-describedby={error ? errorId : undefined}\n        {...props}\n      />\n      {error && (\n        <p id={errorId} className=\"text-sm text-destructive mt-1\">\n          {error}\n        </p>\n      )}\n    </div>\n  );\n}\n```\n\n**Missing Screen Reader Text**\n- **Issue**: Icon-only buttons need sr-only text for screen readers\n- **Fix**: Add `sr-only` text or `aria-label`\n- **Example**:\n```tsx\n// GOOD - sr-only text for screen readers\nexport function CloseButton({ onClick }) {\n  return (\n    <button onClick={onClick} aria-label=\"Close\">\n      <X className=\"h-4 w-4\" />\n      <span className=\"sr-only\">Close</span>\n    </button>\n  );\n}\n```\n\n### data-slot Pattern\n\n**Missing data-slot Attributes**\n- **Issue**: Component parts cannot be targeted by consumers for custom styling\n- **Fix**: Add `data-slot` attributes to component parts\n- **Example**:\n```tsx\n// GOOD - data-slot for targetable parts\nexport function Card({ children, ...props }) {\n  return (\n    <div className=\"border rounded-lg\" data-slot=\"card\" {...props}>\n      {children}\n    </div>\n  );\n}\n\nexport function CardHeader({ children, ...props }) {\n  return (\n    <div className=\"p-6\" data-slot=\"card-header\" {...props}>\n      {children}\n    </div>\n  );\n}\n\n// Consumer can target with stable selector:\n// <Card className=\"[&_[data-slot=card-header]]:bg-red-500\">\n```\n\n**Not Using has() Selectors for State-Based Styling**\n- **Issue**: Parent styling based on child state requires manual prop threading\n- **Fix**: Use `has()` selector with `data-slot`\n- **Example**:\n```tsx\n// GOOD - has() selector with data-slot\nexport function Card({ children, ...props }) {\n  return (\n    <div\n      className=\"border has-[[data-slot=card-content][data-error]]:border-destructive\"\n      data-slot=\"card\"\n      {...props}\n    >\n      {children}\n    </div>\n  );\n}\n\nexport function CardContent({ error, children, ...props }) {\n  return (\n    <div data-slot=\"card-content\" data-error={error ? \"\" : undefined} {...props}>\n      {error && <p className=\"text-sm text-destructive\">{error}</p>}\n      {children}\n    </div>\n  );\n}\n```\n\n---\n\n# React Flow Code Review (if detected)\n\n## Critical Anti-Patterns\n\n### Defining nodeTypes/edgeTypes Inside Components\n- **Issue**: Causes all nodes to re-mount on every render\n- **Fix**: Define outside component or use `useMemo`\n- **Example**:\n```tsx\n// GOOD - defined outside component\nconst nodeTypes = { custom: CustomNode };\nfunction Flow() {\n  return <ReactFlow nodeTypes={nodeTypes} />;\n}\n\n// GOOD - useMemo if dynamic\nfunction Flow() {\n  const nodeTypes = useMemo(() => ({ custom: CustomNode }), []);\n  return <ReactFlow nodeTypes={nodeTypes} />;\n}\n```\n\n### Missing memo() on Custom Nodes/Edges\n- **Issue**: Custom components re-render on every parent update\n- **Fix**: Wrap in `memo()`\n- **Example**:\n```tsx\n// GOOD - wrapped in memo\nimport { memo } from 'react';\nconst CustomNode = memo(function CustomNode({ data }) {\n  return <div>{data.label}</div>;\n});\n```\n\n### Inline Callbacks Without useCallback\n- **Issue**: Creates new function references, breaking memoization\n- **Fix**: Wrap callbacks in `useCallback`\n- **Example**:\n```tsx\n// GOOD - memoized callback\nconst onNodesChange = useCallback(\n  (changes) => setNodes((nds) => applyNodeChanges(changes, nds)),\n  []\n);\n<ReactFlow onNodesChange={onNodesChange} />\n```\n\n### Using useReactFlow Outside Provider\n- **Issue**: Will throw error if not inside ReactFlowProvider\n- **Fix**: Wrap component tree in ReactFlowProvider\n- **Example**:\n```tsx\n// GOOD - wrap in provider\nfunction App() {\n  return (\n    <ReactFlowProvider>\n      <FlowContent />\n    </ReactFlowProvider>\n  );\n}\n```\n\n## Performance Checklist\n\n- [ ] Custom nodes wrapped in `memo()`\n- [ ] nodeTypes defined outside component or memoized\n- [ ] Heavy computations inside nodes use `useMemo`\n- [ ] Event handlers use `useCallback`\n- [ ] Using functional form of setState: `setNodes((nds) => ...)`\n- [ ] Using `updateNodeData` for data-only changes\n- [ ] Container has explicit height (flow won't render without it)\n- [ ] CSS import present: `import '@xyflow/react/dist/style.css'`\n- [ ] Interactive elements marked with `nodrag` class\n- [ ] Position constants used instead of string literals\n\n---\n\n# Zustand State Management (if detected)\n\n## Critical Issues to Flag\n\n### Selector Performance\n- **Issue**: Subscribing to entire store causes unnecessary rerenders\n- **Fix**: Use specific selectors\n- **Example**:\n```tsx\n// GOOD - subscribes only to bears\nconst bears = useBearStore((state) => state.bears)\n\n// BAD - rerenders on any change\nconst state = useBearStore()\n```\n\n### Multiple Values with useShallow\n- **Issue**: Multiple values cause rerenders with shallow comparison\n- **Fix**: Use `useShallow` from zustand/react/shallow\n- **Example**:\n```tsx\n// GOOD - prevents rerenders with shallow comparison\nimport { useShallow } from 'zustand/react/shallow'\n\nconst { bears, fish } = useBearStore(\n  useShallow((state) => ({ bears: state.bears, fish: state.fish }))\n)\n```\n\n### State Updates\n- **Issue**: Direct mutation of state\n- **Fix**: Use immutable updates\n- **Example**:\n```tsx\n// GOOD - immutable update\nset((state) => ({ bears: state.bears + 1 }))\n\n// BAD - mutation\nset((state) => {\n  state.bears += 1  // Mutation!\n  return state\n})\n```\n\n### Nested Objects\n- **Issue**: Zustand only auto-merges at one level\n- **Fix**: Manual spread for nested objects\n- **Example**:\n```tsx\n// GOOD - manual spread for nested\nset((state) => ({\n  nested: { ...state.nested, count: state.nested.count + 1 }\n}))\n```\n\n## Best Practices\n\n- Use single selector for one piece of state\n- Use `useShallow` for multiple values\n- Use `getState()` outside React or in event handlers\n- Use `subscribe()` for external systems\n- Don't mutate state directly (use immer middleware if needed)\n- Avoid fetching entire store in components\n\n---\n\n# Tailwind v4 Review (if detected)\n\n## Critical Issues to Flag\n\n### Using v3 Patterns\n- **Issue**: Using tailwind.config.js or postcss.config.js\n- **Fix**: Use @theme in CSS and @tailwindcss/vite plugin\n- **Example**:\n```css\n/* GOOD - v4 approach */\n@import 'tailwindcss';\n\n@theme {\n  --color-primary: oklch(60% 0.24 262);\n}\n```\n\n### Incorrect @theme Mode\n- **Issue**: Using wrong @theme mode for use case\n- **Fix**: Use `inline` for static values, `default` for CSS variables\n- **Example**:\n```css\n/* GOOD - inline for static values */\n@theme inline {\n  --color-brand: oklch(60% 0.24 262);\n}\n\n/* GOOD - default for runtime theming */\n@theme {\n  --color-primary: oklch(60% 0.24 262);\n}\n```\n\n### Not Using OKLCH\n- **Issue**: Using rgb() or hsl() instead of oklch()\n- **Fix**: Use oklch() for perceptually uniform colors\n- **Example**:\n```css\n/* GOOD - OKLCH colors */\n@theme {\n  --color-blue-600: oklch(54.6% 0.245 262.881);\n}\n```\n\n### Missing CSS Variable Naming Convention\n- **Issue**: Not following Tailwind v4 naming patterns\n- **Fix**: Use `--color-{name}-{shade}` pattern\n- **Example**:\n```css\n/* GOOD - follows convention */\n@theme {\n  --color-primary-500: oklch(60% 0.24 262);\n  --font-display: 'Inter Variable', system-ui;\n}\n```\n\n## Dark Mode\n\n### Class-Based Dark Mode Setup\n- **Issue**: Missing darkMode configuration for class-based approach\n- **Fix**: Add v3 config file with `darkMode: 'class'`\n- **Example**:\n```js\n// tailwind.config.js\nmodule.exports = {\n  darkMode: 'class',\n};\n```\n\n### FOUC Prevention\n- **Issue**: Flash of unstyled content on page load\n- **Fix**: Add inline script before any styled content\n- **Example**:\n```html\n<script>\n  (function() {\n    const theme = localStorage.getItem('theme') || 'system';\n    const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n    const effectiveTheme = theme === 'system' ? systemTheme : theme;\n    document.documentElement.classList.add(effectiveTheme);\n  })();\n</script>\n```\n\n---\n\n# Vitest Testing (if test files detected)\n\n## Critical Issues to Flag\n\n### Missing await on Async Expects\n- **Issue**: Creates false positives\n- **Fix**: Always await async expects\n- **Example**:\n```ts\n// GOOD - awaited\nawait expect(promise).resolves.toBe(value)\n\n// BAD - false positive!\nexpect(promise).resolves.toBe(value)\n```\n\n### Shared State Between Tests\n- **Issue**: Flaky tests, order-dependent failures\n- **Fix**: Use beforeEach for isolation\n- **Example**:\n```ts\n// GOOD - isolated state\nbeforeEach(() => {\n  state = createFreshState()\n})\n```\n\n### vi.mock Inside Tests\n- **Issue**: Hoisting issues, won't work\n- **Fix**: vi.mock at top level before imports\n- **Example**:\n```ts\n// GOOD - vi.mock at top level\nvi.mock('./module')\nimport { fn } from './module'\n```\n\n### Missing Mock Cleanup\n- **Issue**: Mocks leak between tests\n- **Fix**: Clear/reset mocks in beforeEach\n- **Example**:\n```ts\n// GOOD - cleanup in beforeEach\nbeforeEach(() => {\n  vi.clearAllMocks()\n})\n```\n\n## Best Practices\n\n- Always await async expects\n- Use beforeEach for test isolation\n- vi.mock at top level, not inside tests\n- Clear mocks between tests\n- Don't nest describes excessively\n- Test behavior, not implementation details\n\n---\n\n## Step 4: Review Execution\n\n**Sequential (default):**\n1. Apply React Router patterns to all components\n2. Apply shadcn/ui patterns to all components\n3. Apply conditionally detected technology patterns\n4. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one parallel review per technology area\n3. Wait for all reviews\n4. Consolidate findings\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, a11y, perf, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\nnpm run lint\nnpm run typecheck\nnpm run test\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Don't assume Next.js patterns (no \"use client\")\n- Run verification after fixes\n",
        ".cursor/commands/review-go.md": "# Go Backend Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.go$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect BubbleTea TUI\ngrep -r \"charmbracelet/bubbletea\\|tea\\.Model\\|tea\\.Cmd\" --include=\"*.go\" -l | head -3\n\n# Detect Wish SSH\ngrep -r \"charmbracelet/wish\\|ssh\\.Session\\|wish\\.Middleware\" --include=\"*.go\" -l | head -3\n\n# Detect Prometheus\ngrep -r \"prometheus/client_golang\\|promauto\\|prometheus\\.Counter\" --include=\"*.go\" -l | head -3\n\n# Detect ZeroLog\ngrep -r \"rs/zerolog\\|zerolog\\.Logger\" --include=\"*.go\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '_test\\.go$'\n```\n\n## Step 3: Review\n\n**Sequential (default):**\n1. Review Go quality issues first (error handling, concurrency, interfaces)\n2. Review detected technology areas\n3. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent loads its skill and reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, race condition, resource leak, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\ngo build ./...\ngo vet ./...\ngolangci-lint run\ngo test -v -race ./...\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Check for race conditions with `-race` flag\n- Run verification after fixes\n\n---\n\n# Technology Knowledge Base\n\n## Go Code Review\n\n### Review Checklist\n\n- [ ] All errors are checked (no `_ = err`)\n- [ ] Errors wrapped with context (`fmt.Errorf(\"...: %w\", err)`)\n- [ ] Resources closed with `defer` immediately after creation\n- [ ] No goroutine leaks (channels closed, contexts canceled)\n- [ ] Interfaces defined by consumers, not producers\n- [ ] Interface names end in `-er` (Reader, Writer, Handler)\n- [ ] Exported names have doc comments\n- [ ] No naked returns in functions > 5 lines\n- [ ] Context passed as first parameter\n- [ ] Mutexes protect shared state, not methods\n\n### Review Questions\n\n1. Are all error returns checked and wrapped?\n2. Are goroutines properly managed with context cancellation?\n3. Are resources (files, connections) closed with defer?\n4. Are interfaces minimal and defined where used?\n\n### Error Handling\n\n#### Critical Anti-Patterns\n\n**1. Ignoring Errors**\n\nProblem: Silent failures are impossible to debug.\n\n```go\n// BAD\nfile, _ := os.Open(\"config.json\")\ndata, _ := io.ReadAll(file)\n\n// GOOD\nfile, err := os.Open(\"config.json\")\nif err != nil {\n    return fmt.Errorf(\"opening config: %w\", err)\n}\ndefer file.Close()\n```\n\n**2. Unwrapped Errors**\n\nProblem: Loses context for debugging.\n\n```go\n// BAD - raw error\nif err != nil {\n    return err\n}\n\n// GOOD - wrapped with context\nif err != nil {\n    return fmt.Errorf(\"loading user %d: %w\", userID, err)\n}\n```\n\n**3. String Errors Instead of Wrapping**\n\nProblem: Breaks error inspection with `errors.Is/As`.\n\n```go\n// BAD\nreturn fmt.Errorf(\"failed: %s\", err.Error())\n\n// GOOD - preserves error chain\nreturn fmt.Errorf(\"failed: %w\", err)\n```\n\n**4. Panic for Recoverable Errors**\n\nProblem: Crashes the program unexpectedly.\n\n```go\n// BAD\nfunc GetConfig(path string) Config {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        panic(err)  // Never panic for expected errors\n    }\n    ...\n}\n\n// GOOD\nfunc GetConfig(path string) (Config, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return Config{}, fmt.Errorf(\"reading config: %w\", err)\n    }\n    ...\n}\n```\n\n**5. Checking Error String Instead of Type**\n\nProblem: Brittle, breaks with error message changes.\n\n```go\n// BAD\nif err.Error() == \"file not found\" {\n    ...\n}\n\n// GOOD\nif errors.Is(err, os.ErrNotExist) {\n    ...\n}\n\n// For custom errors\nvar ErrNotFound = errors.New(\"not found\")\nif errors.Is(err, ErrNotFound) {\n    ...\n}\n```\n\n**6. Returning Error and Valid Value**\n\nProblem: Confuses callers about error semantics.\n\n```go\n// BAD - what does partial result mean?\nfunc Parse(s string) (int, error) {\n    if s == \"\" {\n        return -1, errors.New(\"empty string\")  // -1 is valid integer\n    }\n    ...\n}\n\n// GOOD - zero value on error\nfunc Parse(s string) (int, error) {\n    if s == \"\" {\n        return 0, errors.New(\"empty string\")\n    }\n    ...\n}\n```\n\n#### Sentinel Errors Pattern\n\n```go\n// Define at package level\nvar (\n    ErrNotFound     = errors.New(\"not found\")\n    ErrUnauthorized = errors.New(\"unauthorized\")\n)\n\n// Usage\nfunc GetUser(id int) (*User, error) {\n    user := db.Find(id)\n    if user == nil {\n        return nil, ErrNotFound\n    }\n    return user, nil\n}\n\n// Caller checks\nif errors.Is(err, ErrNotFound) {\n    http.Error(w, \"User not found\", 404)\n}\n```\n\n### Concurrency\n\n#### Critical Anti-Patterns\n\n**1. Goroutine Leak**\n\nProblem: Goroutines block forever, consuming memory.\n\n```go\n// BAD - no way to stop the goroutine\nfunc startWorker() {\n    go func() {\n        for {\n            doWork()\n        }\n    }()\n}\n\n// GOOD - context cancellation\nfunc startWorker(ctx context.Context) {\n    go func() {\n        for {\n            select {\n            case <-ctx.Done():\n                return\n            default:\n                doWork()\n            }\n        }\n    }()\n}\n```\n\n**2. Unbounded Channel Send**\n\nProblem: Sender blocks forever if receiver dies.\n\n```go\n// BAD - blocks if nobody reads\nch <- result\n\n// GOOD - respect context\nselect {\ncase ch <- result:\ncase <-ctx.Done():\n    return ctx.Err()\n}\n```\n\n**3. Closing Channel Multiple Times**\n\nProblem: Panic at runtime.\n\n```go\n// BAD - potential double close\nclose(ch)\nclose(ch)  // panic!\n\n// GOOD - only sender closes, once\nfunc produce(ch chan<- int) {\n    defer close(ch)  // close happens exactly once\n    for i := 0; i < 10; i++ {\n        ch <- i\n    }\n}\n```\n\n**4. Race Condition on Shared State**\n\nProblem: Data corruption, undefined behavior.\n\n```go\n// BAD - concurrent map access\nvar cache = make(map[string]int)\nfunc Get(key string) int {\n    return cache[key]  // race!\n}\nfunc Set(key string, val int) {\n    cache[key] = val  // race!\n}\n\n// GOOD - mutex protection\nvar (\n    cache   = make(map[string]int)\n    cacheMu sync.RWMutex\n)\nfunc Get(key string) int {\n    cacheMu.RLock()\n    defer cacheMu.RUnlock()\n    return cache[key]\n}\nfunc Set(key string, val int) {\n    cacheMu.Lock()\n    defer cacheMu.Unlock()\n    cache[key] = val\n}\n\n// BETTER - sync.Map for simple cases\nvar cache sync.Map\nfunc Get(key string) (int, bool) {\n    v, ok := cache.Load(key)\n    if !ok {\n        return 0, false\n    }\n    return v.(int), true\n}\n```\n\n**5. Missing WaitGroup**\n\nProblem: Program exits before goroutines complete.\n\n```go\n// BAD - may exit before done\nfor _, item := range items {\n    go process(item)\n}\nreturn  // goroutines may not finish\n\n// GOOD\nvar wg sync.WaitGroup\nfor _, item := range items {\n    wg.Add(1)\n    go func(item Item) {\n        defer wg.Done()\n        process(item)\n    }(item)\n}\nwg.Wait()\n```\n\n**6. Loop Variable Capture**\n\nProblem: All goroutines see the same variable value.\n\n```go\n// BAD (pre-Go 1.22)\nfor _, item := range items {\n    go func() {\n        process(item)  // all see last item!\n    }()\n}\n\n// GOOD - capture in closure\nfor _, item := range items {\n    go func(item Item) {\n        process(item)\n    }(item)\n}\n\n// Note: Go 1.22+ fixes this by default\n```\n\n**7. Context Not Propagated**\n\nProblem: Can't cancel downstream operations.\n\n```go\n// BAD\nfunc Handler(ctx context.Context) error {\n    result := doWork()  // ignores ctx\n    return nil\n}\n\n// GOOD\nfunc Handler(ctx context.Context) error {\n    result, err := doWork(ctx)  // passes ctx\n    if err != nil {\n        return err\n    }\n    return nil\n}\n```\n\n#### Worker Pool Pattern\n\n```go\nfunc processItems(ctx context.Context, items []Item) error {\n    const workers = 5\n\n    jobs := make(chan Item)\n    errs := make(chan error, 1)\n\n    var wg sync.WaitGroup\n    for i := 0; i < workers; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for item := range jobs {\n                if err := process(ctx, item); err != nil {\n                    select {\n                    case errs <- err:\n                    default:\n                    }\n                    return\n                }\n            }\n        }()\n    }\n\n    go func() {\n        wg.Wait()\n        close(errs)\n    }()\n\n    for _, item := range items {\n        select {\n        case jobs <- item:\n        case err := <-errs:\n            return err\n        case <-ctx.Done():\n            return ctx.Err()\n        }\n    }\n    close(jobs)\n\n    return <-errs\n}\n```\n\n### Interfaces\n\n#### Critical Anti-Patterns\n\n**1. Premature Interface Definition**\n\nProblem: Interfaces defined before needed, creating abstraction overhead.\n\n```go\n// BAD - interface in producer package\npackage storage\n\ntype UserRepository interface {\n    Get(id int) (*User, error)\n    Save(user *User) error\n}\n\ntype PostgresUserRepository struct { ... }\n\n// GOOD - interface in consumer package\npackage service\n\ntype UserGetter interface {\n    Get(id int) (*User, error)\n}\n\nfunc NewUserService(users UserGetter) *UserService {\n    return &UserService{users: users}\n}\n```\n\n**2. Interface Pollution (Too Many Methods)**\n\nProblem: Hard to implement, hard to mock, violates ISP.\n\n```go\n// BAD - fat interface\ntype UserStore interface {\n    Get(id int) (*User, error)\n    GetAll() ([]*User, error)\n    Save(user *User) error\n    Delete(id int) error\n    Search(query string) ([]*User, error)\n    Count() (int, error)\n    // ... 10 more methods\n}\n\n// GOOD - focused interfaces\ntype UserGetter interface {\n    Get(id int) (*User, error)\n}\n\ntype UserSaver interface {\n    Save(user *User) error\n}\n\ntype UserStore interface {\n    UserGetter\n    UserSaver\n}\n```\n\n**3. Wrong Interface Names**\n\nProblem: Doesn't follow Go conventions, less readable.\n\n```go\n// BAD\ntype IUserService interface { ... }  // Java-style prefix\ntype UserServiceInterface { ... }    // redundant suffix\ntype UserManager interface { ... }   // vague noun\n\n// GOOD - verb forms ending in -er\ntype UserReader interface {\n    ReadUser(id int) (*User, error)\n}\n\ntype UserWriter interface {\n    WriteUser(user *User) error\n}\n```\n\n**4. Returning Interface Instead of Concrete Type**\n\nProblem: Hides implementation details unnecessarily.\n\n```go\n// BAD - returns interface\nfunc NewServer(addr string) Server {\n    return &httpServer{addr: addr}\n}\n\n// GOOD - returns concrete type\nfunc NewServer(addr string) *HTTPServer {\n    return &HTTPServer{addr: addr}\n}\n```\n\n**5. Empty Interface Overuse**\n\nProblem: Loses type safety, requires type assertions.\n\n```go\n// BAD\nfunc Process(data interface{}) interface{} {\n    switch v := data.(type) {\n    case string:\n        return strings.ToUpper(v)\n    case int:\n        return v * 2\n    }\n    return nil\n}\n\n// GOOD - use generics (Go 1.18+)\nfunc Process[T string | int](data T) T {\n    // type-safe processing\n}\n\n// Or use specific types\nfunc ProcessString(data string) string\nfunc ProcessInt(data int) int\n```\n\n**6. Interface for Single Implementation**\n\nProblem: Unnecessary abstraction with no benefit.\n\n```go\n// BAD - interface with only one implementation\ntype ConfigLoader interface {\n    Load() (*Config, error)\n}\n\ntype fileConfigLoader struct { ... }\n\n// GOOD - just use the concrete type\ntype ConfigLoader struct { ... }\n\nfunc (c *ConfigLoader) Load() (*Config, error) { ... }\n```\n\n#### Accept Interfaces, Return Structs\n\n```go\n// Function accepts interface (flexible)\nfunc WriteData(w io.Writer, data []byte) error {\n    _, err := w.Write(data)\n    return err\n}\n\n// Function returns concrete type (explicit)\nfunc NewBuffer() *bytes.Buffer {\n    return &bytes.Buffer{}\n}\n\n// Usage\nbuf := NewBuffer()\nWriteData(buf, []byte(\"hello\"))  // Buffer implements io.Writer\n```\n\n### Common Mistakes\n\n#### Resource Leaks\n\n**1. Missing defer for Close**\n\nProblem: Resources leaked on early return.\n\n```go\n// BAD\nfunc readFile(path string) ([]byte, error) {\n    f, err := os.Open(path)\n    if err != nil {\n        return nil, err\n    }\n    data, err := io.ReadAll(f)\n    if err != nil {\n        return nil, err  // file never closed!\n    }\n    f.Close()\n    return data, nil\n}\n\n// GOOD - defer immediately\nfunc readFile(path string) ([]byte, error) {\n    f, err := os.Open(path)\n    if err != nil {\n        return nil, err\n    }\n    defer f.Close()\n    return io.ReadAll(f)\n}\n```\n\n**2. Defer in Loop**\n\nProblem: Resources accumulate until function returns.\n\n```go\n// BAD - files stay open until loop ends\nfor _, path := range paths {\n    f, _ := os.Open(path)\n    defer f.Close()  // deferred until function returns\n    process(f)\n}\n\n// GOOD - close in each iteration or use closure\nfor _, path := range paths {\n    func() {\n        f, _ := os.Open(path)\n        defer f.Close()\n        process(f)\n    }()\n}\n```\n\n**3. HTTP Response Body Not Closed**\n\nProblem: Connection pool exhaustion.\n\n```go\n// BAD\nresp, err := http.Get(url)\nif err != nil {\n    return err\n}\n// body never closed!\ndata, _ := io.ReadAll(resp.Body)\n\n// GOOD\nresp, err := http.Get(url)\nif err != nil {\n    return err\n}\ndefer resp.Body.Close()\ndata, _ := io.ReadAll(resp.Body)\n```\n\n#### Naming and Style\n\n**4. Stuttering Names**\n\nProblem: Redundant when used with package name.\n\n```go\n// BAD\npackage user\ntype UserService struct { ... }  // user.UserService\n\n// GOOD\npackage user\ntype Service struct { ... }  // user.Service\n```\n\n**5. Missing Doc Comments on Exports**\n\nProblem: godoc can't generate documentation.\n\n```go\n// BAD\nfunc NewServer(addr string) *Server { ... }\n\n// GOOD\n// NewServer creates a new HTTP server listening on addr.\nfunc NewServer(addr string) *Server { ... }\n```\n\n**6. Naked Returns in Long Functions**\n\nProblem: Hard to track what's being returned.\n\n```go\n// BAD\nfunc process(data []byte) (result string, err error) {\n    // 50 lines of code...\n\n    return  // what's being returned?\n}\n\n// GOOD - explicit returns\nfunc process(data []byte) (string, error) {\n    // 50 lines of code...\n\n    return processedString, nil\n}\n```\n\n#### Initialization\n\n**7. Init Function Overuse**\n\nProblem: Hidden side effects, hard to test.\n\n```go\n// BAD - global state via init\nvar db *sql.DB\n\nfunc init() {\n    var err error\n    db, err = sql.Open(\"postgres\", os.Getenv(\"DATABASE_URL\"))\n    if err != nil {\n        log.Fatal(err)\n    }\n}\n\n// GOOD - explicit initialization\ntype App struct {\n    db *sql.DB\n}\n\nfunc NewApp(dbURL string) (*App, error) {\n    db, err := sql.Open(\"postgres\", dbURL)\n    if err != nil {\n        return nil, fmt.Errorf(\"opening db: %w\", err)\n    }\n    return &App{db: db}, nil\n}\n```\n\n**8. Global Mutable State**\n\nProblem: Race conditions, hard to test.\n\n```go\n// BAD\nvar config Config\n\nfunc GetConfig() Config {\n    return config\n}\n\n// GOOD - dependency injection\ntype Server struct {\n    config Config\n}\n\nfunc NewServer(cfg Config) *Server {\n    return &Server{config: cfg}\n}\n```\n\n#### Performance\n\n**9. String Concatenation in Loop**\n\nProblem: O(n) allocation overhead.\n\n```go\n// BAD\nvar result string\nfor _, s := range items {\n    result += s + \", \"\n}\n\n// GOOD\nvar b strings.Builder\nfor _, s := range items {\n    b.WriteString(s)\n    b.WriteString(\", \")\n}\nresult := b.String()\n```\n\n**10. Slice Preallocation**\n\nProblem: Repeated reallocations.\n\n```go\n// BAD - grows dynamically\nvar results []Result\nfor _, item := range items {\n    results = append(results, process(item))\n}\n\n// GOOD - preallocate known size\nresults := make([]Result, 0, len(items))\nfor _, item := range items {\n    results = append(results, process(item))\n}\n```\n\n---\n\n## Go Testing Code Review\n\n### Review Checklist\n\n- [ ] Tests are table-driven with clear case names\n- [ ] Subtests use t.Run for parallel execution\n- [ ] Test names describe behavior, not implementation\n- [ ] Errors include got/want with descriptive message\n- [ ] Cleanup registered with t.Cleanup\n- [ ] Parallel tests don't share mutable state\n- [ ] Mocks use interfaces defined in test file\n- [ ] Coverage includes edge cases and error paths\n\n### Critical Patterns\n\n#### Table-Driven Tests\n\n```go\n// BAD - repetitive\nfunc TestAdd(t *testing.T) {\n    if Add(1, 2) != 3 {\n        t.Error(\"wrong\")\n    }\n    if Add(0, 0) != 0 {\n        t.Error(\"wrong\")\n    }\n}\n\n// GOOD\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     int\n        want     int\n    }{\n        {\"positive numbers\", 1, 2, 3},\n        {\"zeros\", 0, 0, 0},\n        {\"negative\", -1, 1, 0},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := Add(tt.a, tt.b)\n            if got != tt.want {\n                t.Errorf(\"Add(%d, %d) = %d, want %d\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n```\n\n#### Error Messages\n\n```go\n// BAD\nif got != want {\n    t.Error(\"wrong result\")\n}\n\n// GOOD\nif got != want {\n    t.Errorf(\"GetUser(%d) = %v, want %v\", id, got, want)\n}\n\n// For complex types\nif diff := cmp.Diff(want, got); diff != \"\" {\n    t.Errorf(\"GetUser() mismatch (-want +got):\\n%s\", diff)\n}\n```\n\n#### Parallel Tests\n\n```go\nfunc TestFoo(t *testing.T) {\n    tests := []struct{...}\n\n    for _, tt := range tests {\n        tt := tt  // capture (not needed Go 1.22+)\n        t.Run(tt.name, func(t *testing.T) {\n            t.Parallel()\n            // test code\n        })\n    }\n}\n```\n\n#### Cleanup\n\n```go\n// BAD - manual cleanup, skipped on failure\nfunc TestWithTempFile(t *testing.T) {\n    f, _ := os.CreateTemp(\"\", \"test\")\n    defer os.Remove(f.Name())  // skipped if test panics\n}\n\n// GOOD\nfunc TestWithTempFile(t *testing.T) {\n    f, _ := os.CreateTemp(\"\", \"test\")\n    t.Cleanup(func() {\n        os.Remove(f.Name())\n    })\n}\n```\n\n### Anti-Patterns\n\n**1. Testing Internal Implementation**\n\n```go\n// BAD - tests private state\nfunc TestUser(t *testing.T) {\n    u := NewUser(\"alice\")\n    if u.id != 1 {  // testing internal field\n        t.Error(\"wrong id\")\n    }\n}\n\n// GOOD - tests behavior\nfunc TestUser(t *testing.T) {\n    u := NewUser(\"alice\")\n    if u.ID() != 1 {\n        t.Error(\"wrong ID\")\n    }\n}\n```\n\n**2. Shared Mutable State**\n\n```go\n// BAD - tests interfere with each other\nvar testDB = setupDB()\n\nfunc TestA(t *testing.T) {\n    t.Parallel()\n    testDB.Insert(...)  // race!\n}\n\n// GOOD - isolated per test\nfunc TestA(t *testing.T) {\n    db := setupTestDB(t)\n    t.Cleanup(func() { db.Close() })\n    db.Insert(...)\n}\n```\n\n**3. Assertions Without Context**\n\n```go\n// BAD\nassert.Equal(t, want, got)  // \"expected X got Y\" - which test?\n\n// GOOD\nassert.Equal(t, want, got, \"user name after update\")\n```\n\n### Test Structure\n\n#### File Organization\n\n```\npackage/\n user.go\n user_test.go       # same package tests\n user_internal_test.go  # internal tests if needed\n testdata/          # test fixtures\n     users.json\n```\n\n#### Helper Functions\n\n```go\n// Mark as helper for better stack traces\nfunc assertNoError(t *testing.T, err error) {\n    t.Helper()  // marks this as helper\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n}\n\nfunc createTestUser(t *testing.T, name string) *User {\n    t.Helper()\n    u, err := NewUser(name)\n    if err != nil {\n        t.Fatalf(\"creating test user: %v\", err)\n    }\n    return u\n}\n```\n\n### Mocking\n\n#### Interface-Based Mocking\n\n```go\n// service.go\ntype UserStore interface {\n    Get(id int) (*User, error)\n}\n\ntype UserService struct {\n    store UserStore\n}\n\nfunc (s *UserService) GetUser(id int) (*User, error) {\n    return s.store.Get(id)\n}\n\n// service_test.go\ntype mockUserStore struct {\n    users map[int]*User\n    err   error\n}\n\nfunc (m *mockUserStore) Get(id int) (*User, error) {\n    if m.err != nil {\n        return nil, m.err\n    }\n    user, ok := m.users[id]\n    if !ok {\n        return nil, ErrNotFound\n    }\n    return user, nil\n}\n\nfunc TestGetUser(t *testing.T) {\n    mock := &mockUserStore{\n        users: map[int]*User{\n            1: {ID: 1, Name: \"Alice\"},\n        },\n    }\n\n    svc := &UserService{store: mock}\n    user, err := svc.GetUser(1)\n\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    if user.Name != \"Alice\" {\n        t.Errorf(\"name = %s, want Alice\", user.Name)\n    }\n}\n```\n\n#### Testing HTTP Clients\n\n```go\nfunc TestFetchUser(t *testing.T) {\n    // Create test server\n    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        if r.URL.Path != \"/users/1\" {\n            t.Errorf(\"unexpected path: %s\", r.URL.Path)\n        }\n        w.Header().Set(\"Content-Type\", \"application/json\")\n        w.Write([]byte(`{\"id\": 1, \"name\": \"Alice\"}`))\n    }))\n    defer ts.Close()\n\n    // Use test server URL\n    client := NewClient(ts.URL)\n    user, err := client.FetchUser(1)\n\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    if user.Name != \"Alice\" {\n        t.Errorf(\"name = %s, want Alice\", user.Name)\n    }\n}\n```\n\n---\n\n## BubbleTea TUI Code Review\n\n### Review Checklist\n\n- [ ] Model is immutable (Update returns new model, not mutates)\n- [ ] Init returns proper initial command (or nil)\n- [ ] Update handles all expected message types\n- [ ] View is a pure function (no side effects)\n- [ ] tea.Quit used correctly for exit\n- [ ] Key bindings use key.Matches with help.KeyMap\n- [ ] Lipgloss styles are defined once, not in View\n- [ ] Commands are used for I/O, not direct calls\n- [ ] WindowSizeMsg handled for responsive layout\n- [ ] tea.Batch used for multiple commands\n\n### Critical Patterns\n\n#### Model Must Be Immutable\n\n```go\n// BAD - mutates model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    m.items = append(m.items, newItem)  // mutation!\n    return m, nil\n}\n\n// GOOD - returns new model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    newItems := make([]Item, len(m.items)+1)\n    copy(newItems, m.items)\n    newItems[len(m.items)] = newItem\n    m.items = newItems\n    return m, nil\n}\n```\n\n#### Commands for Async/IO\n\n```go\n// BAD - blocking in Update\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    data, _ := os.ReadFile(\"config.json\")  // blocks UI!\n    m.config = parse(data)\n    return m, nil\n}\n\n// GOOD - use commands\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    return m, loadConfigCmd()\n}\n\nfunc loadConfigCmd() tea.Cmd {\n    return func() tea.Msg {\n        data, err := os.ReadFile(\"config.json\")\n        if err != nil {\n            return errMsg{err}\n        }\n        return configLoadedMsg{parse(data)}\n    }\n}\n```\n\n#### Styles Defined Once\n\n```go\n// BAD - creates new style each render\nfunc (m Model) View() string {\n    style := lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n    return style.Render(\"Hello\")\n}\n\n// GOOD - define styles at package level or in model\nvar titleStyle = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n\nfunc (m Model) View() string {\n    return titleStyle.Render(\"Hello\")\n}\n```\n\n### Model & Update\n\n#### Model Design\n\n```go\ntype Model struct {\n    // State\n    items    []Item\n    cursor   int\n    selected map[int]struct{}\n\n    // Dimensions (for responsive layout)\n    width  int\n    height int\n\n    // Sub-components\n    list     list.Model\n    viewport viewport.Model\n\n    // Error state\n    err error\n}\n\n// Verify interface implementation\nvar _ tea.Model = (*Model)(nil)\n```\n\n#### Update Patterns\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        return m.handleKey(msg)\n    case tea.WindowSizeMsg:\n        m.width = msg.Width\n        m.height = msg.Height\n        return m, nil\n    case dataLoadedMsg:\n        m.items = msg.items\n        return m, nil\n    case errMsg:\n        m.err = msg.err\n        return m, nil\n    }\n    return m, nil\n}\n```\n\n#### Key Handling with key.Matches\n\n```go\n// BAD - string comparison\ncase tea.KeyMsg:\n    if msg.String() == \"q\" {\n        return m, tea.Quit\n    }\n\n// GOOD - use key bindings\ntype keyMap struct {\n    Quit key.Binding\n    Up   key.Binding\n    Down key.Binding\n}\n\nvar keys = keyMap{\n    Quit: key.NewBinding(\n        key.WithKeys(\"q\", \"ctrl+c\"),\n        key.WithHelp(\"q\", \"quit\"),\n    ),\n    Up: key.NewBinding(\n        key.WithKeys(\"up\", \"k\"),\n        key.WithHelp(\"/k\", \"up\"),\n    ),\n}\n\ncase tea.KeyMsg:\n    switch {\n    case key.Matches(msg, keys.Quit):\n        return m, tea.Quit\n    case key.Matches(msg, keys.Up):\n        m.cursor--\n    }\n```\n\n### View & Styling\n\n#### View Must Be Pure\n\n```go\n// BAD - side effects\nfunc (m Model) View() string {\n    m.lastRender = time.Now()  // mutation!\n    log.Println(\"rendering\")    // I/O!\n    return \"...\"\n}\n\n// GOOD - pure function\nfunc (m Model) View() string {\n    if m.loading {\n        return m.spinner.View() + \" Loading...\"\n    }\n    return m.renderContent()\n}\n```\n\n#### Lipgloss Color Palette\n\n```go\n// Define a consistent color palette\nvar (\n    colorPrimary   = lipgloss.Color(\"205\")  // magenta\n    colorSecondary = lipgloss.Color(\"241\")  // gray\n    colorSuccess   = lipgloss.Color(\"78\")   // green\n    colorError     = lipgloss.Color(\"196\")  // red\n)\n\nvar (\n    titleStyle = lipgloss.NewStyle().Foreground(colorPrimary)\n    errorStyle = lipgloss.NewStyle().Foreground(colorError)\n)\n```\n\n#### Adaptive Colors for Themes\n\n```go\nvar (\n    // Adaptive colors work with light and dark terminals\n    subtle    = lipgloss.AdaptiveColor{Light: \"#D9DCCF\", Dark: \"#383838\"}\n    highlight = lipgloss.AdaptiveColor{Light: \"#874BFD\", Dark: \"#7D56F4\"}\n)\n\nvar titleStyle = lipgloss.NewStyle().\n    Foreground(highlight).\n    Background(subtle)\n```\n\n### Component Composition\n\n#### Using Standard Bubbles\n\n```go\nimport (\n    \"github.com/charmbracelet/bubbles/list\"\n    \"github.com/charmbracelet/bubbles/textinput\"\n    \"github.com/charmbracelet/bubbles/viewport\"\n    \"github.com/charmbracelet/bubbles/spinner\"\n)\n\ntype Model struct {\n    list      list.Model\n    input     textinput.Model\n    viewport  viewport.Model\n    spinner   spinner.Model\n}\n```\n\n#### State Machine Pattern\n\n```go\ntype viewState int\n\nconst (\n    viewLoading viewState = iota\n    viewList\n    viewDetail\n    viewEdit\n)\n\ntype Model struct {\n    state viewState\n    // sub-components for each state\n    list   list.Model\n    detail detailModel\n    edit   editModel\n}\n\nfunc (m Model) View() string {\n    switch m.state {\n    case viewLoading:\n        return m.spinner.View() + \" Loading...\"\n    case viewList:\n        return m.list.View()\n    case viewDetail:\n        return m.detail.View()\n    case viewEdit:\n        return m.edit.View()\n    default:\n        return \"Unknown state\"\n    }\n}\n```\n\n---\n\n## Wish SSH Server Code Review\n\n### Review Checklist\n\n- [ ] Host keys are loaded from file or generated securely\n- [ ] Middleware order is correct (logging first, auth early)\n- [ ] Session context is used for per-connection state\n- [ ] Graceful shutdown handles active sessions\n- [ ] PTY requests are handled for terminal apps\n- [ ] Connection limits prevent resource exhaustion\n- [ ] Timeout middleware prevents hung connections\n- [ ] BubbleTea middleware correctly configured\n\n### Critical Patterns\n\n#### Server Setup\n\n```go\n// GOOD - complete server setup\ns, err := wish.NewServer(\n    wish.WithAddress(fmt.Sprintf(\"%s:%d\", host, port)),\n    wish.WithHostKeyPath(\".ssh/id_ed25519\"),\n    wish.WithMiddleware(\n        logging.Middleware(),       // first: log all connections\n        activeterm.Middleware(),    // handle terminal sizing\n        bubbletea.Middleware(teaHandler),\n    ),\n)\nif err != nil {\n    return fmt.Errorf(\"creating server: %w\", err)\n}\n```\n\n#### Graceful Shutdown\n\n```go\n// BAD - abrupt shutdown\nlog.Fatal(s.ListenAndServe())\n\n// GOOD - graceful shutdown\ndone := make(chan os.Signal, 1)\nsignal.Notify(done, os.Interrupt, syscall.SIGTERM)\n\ngo func() {\n    if err := s.ListenAndServe(); err != nil && !errors.Is(err, ssh.ErrServerClosed) {\n        log.Error(\"server error\", \"error\", err)\n    }\n}()\n\n<-done\nctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\ndefer cancel()\nif err := s.Shutdown(ctx); err != nil {\n    log.Error(\"shutdown error\", \"error\", err)\n}\n```\n\n#### BubbleTea Handler\n\n```go\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()\n\n    model := NewModel(pty.Window.Width, pty.Window.Height)\n\n    return model, []tea.ProgramOption{\n        tea.WithAltScreen(),\n        tea.WithMouseCellMotion(),\n    }\n}\n```\n\n### Server Setup Details\n\n#### Host Key Management\n\n```go\n// BAD - generates new key each start (fingerprint changes)\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    // no host key specified - generates random\n)\n\n// GOOD - load from file\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    wish.WithHostKeyPath(\"/data/ssh_host_ed25519_key\"),\n)\n```\n\n#### Middleware Configuration\n\n```go\n// Middleware executes in order - first added runs first\nwish.WithMiddleware(\n    // 1. Logging - see all connections\n    logging.Middleware(),\n\n    // 2. Timeout - prevent hung connections\n    wish.WithIdleTimeout(10*time.Minute),\n    wish.WithMaxTimeout(30*time.Minute),\n\n    // 3. Active terminal - handle PTY/window sizing\n    activeterm.Middleware(),\n\n    // 4. Your app handler - BubbleTea or custom\n    bubbletea.Middleware(teaHandler),\n)\n```\n\n### Sessions & Security\n\n#### Access Session Info\n\n```go\nfunc handler(s ssh.Session) {\n    // User info\n    user := s.User()\n    remoteAddr := s.RemoteAddr()\n\n    // Public key (if key auth)\n    key := s.PublicKey()\n\n    // Environment variables\n    env := s.Environ()\n\n    // Command (if not interactive)\n    cmd := s.Command()\n\n    // PTY info (if allocated)\n    pty, winCh, isPty := s.Pty()\n    if isPty {\n        width := pty.Window.Width\n        height := pty.Window.Height\n    }\n}\n```\n\n#### Authentication\n\n```go\n// Public key authentication\nwish.WithPublicKeyAuth(func(ctx ssh.Context, key ssh.PublicKey) bool {\n    // Check against authorized keys\n    authorized := loadAuthorizedKeys()\n    for _, authKey := range authorized {\n        if ssh.KeysEqual(key, authKey) {\n            return true\n        }\n    }\n    return false\n}),\n```\n\n#### Per-Session Styles\n\n```go\n// Each session needs its own renderer for correct color detection\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    renderer := bubbletea.MakeRenderer(s)\n\n    // Create styles with session's renderer\n    styles := NewStyles(renderer)\n\n    model := Model{\n        styles: styles,\n    }\n\n    return model, nil\n}\n\ntype Styles struct {\n    Title lipgloss.Style\n    Item  lipgloss.Style\n}\n\nfunc NewStyles(r *lipgloss.Renderer) Styles {\n    return Styles{\n        Title: r.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\")),\n        Item:  r.NewStyle().PaddingLeft(2),\n    }\n}\n```\n\n### Anti-Patterns\n\n**Ignoring PTY**\n\n```go\n// BAD - assumes PTY always exists\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()  // may be nil!\n    model := NewModel(pty.Window.Width, pty.Window.Height)  // panic!\n}\n\n// GOOD - handle non-PTY connections\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, hasPty := s.Pty()\n\n    width, height := 80, 24  // sensible defaults\n    if hasPty {\n        width = pty.Window.Width\n        height = pty.Window.Height\n    }\n\n    model := NewModel(width, height)\n    return model, nil\n}\n```\n\n---\n\n## Prometheus Instrumentation Code Review\n\n### Review Checklist\n\n- [ ] Metric types match measurement semantics (Counter/Gauge/Histogram)\n- [ ] Labels have low cardinality (no user IDs, timestamps, paths)\n- [ ] Metric names follow conventions (snake_case, unit suffix)\n- [ ] Histograms use appropriate bucket boundaries\n- [ ] Metrics registered once, not per-request\n- [ ] Collectors don't panic on race conditions\n- [ ] /metrics endpoint exposed and accessible\n\n### Metric Type Selection\n\n| Measurement | Type | Example |\n|-------------|------|---------|\n| Requests processed | Counter | `requests_total` |\n| Items in queue | Gauge | `queue_length` |\n| Request duration | Histogram | `request_duration_seconds` |\n| Concurrent connections | Gauge | `active_connections` |\n| Errors since start | Counter | `errors_total` |\n| Memory usage | Gauge | `memory_bytes` |\n\n### Critical Anti-Patterns\n\n**1. High Cardinality Labels**\n\n```go\n// BAD - unique per user/request\ncounter := promauto.NewCounterVec(\n    prometheus.CounterOpts{Name: \"requests_total\"},\n    []string{\"user_id\", \"path\"},  // millions of series!\n)\ncounter.WithLabelValues(userID, request.URL.Path).Inc()\n\n// GOOD - bounded label values\ncounter := promauto.NewCounterVec(\n    prometheus.CounterOpts{Name: \"requests_total\"},\n    []string{\"method\", \"status_code\"},  // <100 series\n)\ncounter.WithLabelValues(r.Method, statusCode).Inc()\n```\n\n**2. Wrong Metric Type**\n\n```go\n// BAD - using gauge for monotonic value\nrequestCount := promauto.NewGauge(prometheus.GaugeOpts{\n    Name: \"http_requests\",\n})\nrequestCount.Inc()  // should be Counter!\n\n// GOOD\nrequestCount := promauto.NewCounter(prometheus.CounterOpts{\n    Name: \"http_requests_total\",\n})\nrequestCount.Inc()\n```\n\n**3. Registering Per-Request**\n\n```go\n// BAD - new metric per request\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    counter := prometheus.NewCounter(...)  // creates new each time!\n    prometheus.MustRegister(counter)       // panics on duplicate!\n}\n\n// GOOD - register once\nvar requestCounter = promauto.NewCounter(prometheus.CounterOpts{\n    Name: \"http_requests_total\",\n})\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    requestCounter.Inc()\n}\n```\n\n**4. Missing Unit Suffix**\n\n```go\n// BAD\nduration := promauto.NewHistogram(prometheus.HistogramOpts{\n    Name: \"request_duration\",  // no unit!\n})\n\n// GOOD\nduration := promauto.NewHistogram(prometheus.HistogramOpts{\n    Name: \"request_duration_seconds\",  // unit in name\n})\n```\n\n### Good Patterns\n\n#### Metric Definition\n\n```go\nvar (\n    httpRequests = promauto.NewCounterVec(\n        prometheus.CounterOpts{\n            Namespace: \"myapp\",\n            Subsystem: \"http\",\n            Name:      \"requests_total\",\n            Help:      \"Total HTTP requests processed\",\n        },\n        []string{\"method\", \"status\"},\n    )\n\n    httpDuration = promauto.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Namespace: \"myapp\",\n            Subsystem: \"http\",\n            Name:      \"request_duration_seconds\",\n            Help:      \"HTTP request latencies\",\n            Buckets:   []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},\n        },\n        []string{\"method\"},\n    )\n)\n```\n\n#### Middleware Pattern\n\n```go\nfunc metricsMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        timer := prometheus.NewTimer(httpDuration.WithLabelValues(r.Method))\n        defer timer.ObserveDuration()\n\n        wrapped := &responseWriter{ResponseWriter: w, status: 200}\n        next.ServeHTTP(wrapped, r)\n\n        httpRequests.WithLabelValues(r.Method, strconv.Itoa(wrapped.status)).Inc()\n    })\n}\n```\n\n#### Exposing Metrics\n\n```go\nimport \"github.com/prometheus/client_golang/prometheus/promhttp\"\n\nfunc main() {\n    http.Handle(\"/metrics\", promhttp.Handler())\n    http.ListenAndServe(\":9090\", nil)\n}\n```\n",
        ".cursor/commands/review-plan.md": "# Review Plan\n\nReview implementation plans created by `superpowers:writing-plans` before execution.\n\n## Arguments\n\n- Path: Plan file to review (e.g., `docs/plans/2025-01-15-auth-feature.md`)\n\n## Step 1: Read and Parse Plan\n\nRead the plan file and extract:\n\n1. **Header fields:**\n   - `**Goal:**` - Feature description\n   - `**Architecture:**` - Approach summary\n   - `**Tech Stack:**` - Technologies used\n\n2. **Verify via file patterns:**\n   - `.py` files  Python\n   - `.ts`, `.tsx` files  TypeScript\n   - `.go` files  Go\n   - `pytest` commands  pytest\n   - `vitest`, `jest` commands  JavaScript/TypeScript testing\n   - `go test` commands  Go testing\n\n## Step 2: Load Skills\n\nBased on detected tech stack, load relevant skills:\n\n| Detected | Skill |\n|----------|-------|\n| Python | `python-code-review` |\n| FastAPI | `fastapi-code-review` |\n| SQLAlchemy | `sqlalchemy-code-review` |\n| PostgreSQL | `postgres-code-review` |\n| pytest | `pytest-code-review` |\n| React | `react-code-review` |\n| TypeScript | `typescript-code-review` |\n| Go | `go-code-review` |\n\n### Python Code Review Guidelines\n\nReviews Python code for type safety, async patterns, error handling, and common mistakes. Use when reviewing .py files, checking type hints, async/await usage, or exception handling.\n\n**Review Checklist:**\n- Type hints on all function parameters and return types\n- No `Any` unless necessary (with comment explaining why)\n- Proper `T | None` syntax (Python 3.10+)\n- No blocking calls (`time.sleep`, `requests`) in async functions\n- Proper `await` on all coroutines\n- No bare `except:` clauses\n- Specific exception types with context\n- `raise ... from` to preserve stack traces\n- No mutable default arguments\n- Using `logger` not `print()` for output\n- f-strings preferred over `.format()` or `%`\n\n**Review Questions:**\n1. Are all function signatures fully typed?\n2. Are async functions truly non-blocking?\n3. Do exceptions include meaningful context?\n4. Are there any mutable default arguments?\n\n### FastAPI Code Review Guidelines\n\nReviews FastAPI code for routing patterns, dependency injection, validation, and async handlers. Use when reviewing FastAPI apps, checking APIRouter setup, Depends() usage, or response models.\n\n**Review Checklist:**\n- APIRouter with proper prefix and tags\n- All routes specify `response_model` for type safety\n- Correct HTTP methods (GET, POST, PUT, DELETE, PATCH)\n- Proper status codes (200, 201, 204, 404, etc.)\n- Dependencies use `Depends()` not manual calls\n- Yield dependencies have proper cleanup\n- Request/Response models use Pydantic\n- HTTPException with status code and detail\n- All route handlers are `async def`\n- No blocking I/O (`requests`, `time.sleep`, `open()`)\n- Background tasks for non-blocking operations\n- No bare `except` in route handlers\n\n**Review Questions:**\n1. Do all routes have explicit response models and status codes?\n2. Are dependencies injected via Depends() with proper cleanup?\n3. Do all Pydantic models validate inputs correctly?\n4. Are all route handlers async and non-blocking?\n\n### SQLAlchemy Code Review Guidelines\n\nReviews SQLAlchemy code for session management, relationships, N+1 queries, and migration patterns. Use when reviewing SQLAlchemy 2.0 code, checking session lifecycle, relationship() usage, or Alembic migrations.\n\n**Review Checklist:**\n- Sessions use context managers (`with`, `async with`)\n- No session sharing across requests or threads\n- Sessions closed/cleaned up properly\n- `relationship()` uses appropriate `lazy` strategy\n- Explicit `joinedload`/`selectinload` to avoid N+1\n- No lazy loading in loops (N+1 queries)\n- Using SQLAlchemy 2.0 `select()` syntax, not legacy `query()`\n- Bulk operations use bulk_insert/bulk_update, not ORM loops\n- Async sessions use proper async context managers\n- Migrations are reversible with `downgrade()`\n- Data migrations use `op.execute()` not ORM models\n- Migration dependencies properly ordered\n\n**Review Questions:**\n1. Are all sessions properly managed with context managers?\n2. Are relationships configured to avoid N+1 queries?\n3. Are queries using SQLAlchemy 2.0 `select()` syntax?\n4. Are all migrations reversible and properly tested?\n\n### PostgreSQL Code Review Guidelines\n\nReviews PostgreSQL code for indexing strategies, JSONB operations, connection pooling, and transaction safety. Use when reviewing SQL queries, database schemas, JSONB usage, or connection management.\n\n**Review Checklist:**\n- WHERE/JOIN columns have appropriate indexes\n- Composite indexes match query patterns (column order matters)\n- JSONB columns use GIN indexes when queried\n- Using proper JSONB operators (`->`, `->>`, `@>`, `?`)\n- Connection pool configured with appropriate limits\n- Connections properly released (context managers, try/finally)\n- Appropriate transaction isolation level for use case\n- No long-running transactions holding locks\n- Advisory locks used for application-level coordination\n- Queries use parameterized statements (no SQL injection)\n\n**Review Questions:**\n1. Will this query use an index or perform a sequential scan?\n2. Are JSONB operations using appropriate operators and indexes?\n3. Are database connections properly managed and released?\n4. Is the transaction isolation level appropriate for this operation?\n5. Could this cause deadlocks or long-running locks?\n\n### Pytest Code Review Guidelines\n\nReviews pytest test code for async patterns, fixtures, parametrize, and mocking. Use when reviewing test_*.py files, checking async test functions, fixture usage, or mock patterns.\n\n**Review Checklist:**\n- Test functions are `async def test_*` for async code under test\n- AsyncMock used for async dependencies, not Mock\n- All async mocks and coroutines are awaited\n- Fixtures in conftest.py for shared setup\n- Fixture scope appropriate (function, class, module, session)\n- Yield fixtures have proper cleanup in finally block\n- @pytest.mark.parametrize for similar test cases\n- No duplicated test logic across multiple test functions\n- Mocks track calls properly (assert_called_once_with)\n- patch() targets correct location (where used, not defined)\n- No mocking of internals that should be tested\n- Test isolation (no shared mutable state between tests)\n\n**Review Questions:**\n1. Are all async functions tested with async def test_*?\n2. Are fixtures properly scoped with appropriate cleanup?\n3. Can similar test cases be parametrized to reduce duplication?\n4. Are mocks tracking calls and used at the right locations?\n\n## Step 3: Launch 5 Parallel Agents\n\nUse the `Task` tool to spawn 5 agents simultaneously. Each receives:\n- Full plan content\n- Detected tech stack\n- Relevant skill content from Step 2\n\n### Agent 1: Parallelization Analysis\n\n```\nAnalyze whether this implementation plan can be executed by parallel subagents.\n\nINVESTIGATE:\n1. Which tasks can run in parallel (no dependencies between them)?\n2. Which tasks must be sequential (Task B depends on Task A output)?\n3. Are there any circular dependencies or blocking issues?\n4. What is the critical path?\n\nReturn:\n- Recommended batch structure for parallel execution\n- Maximum concurrent agents\n- Any blocking issues that prevent parallelization\n```\n\n### Agent 2: TDD & Over-Engineering Check\n\n```\nVerify TDD discipline in this implementation plan.\n\nCHECK each task for:\n1. Tests written BEFORE implementation (RED phase)\n2. Step to run test and verify it fails\n3. Minimal implementation to make test pass (GREEN phase)\n4. Tests focus on behavior, not implementation details\n\nLOOK FOR over-engineering:\n- Excessive mocking (testing implementation vs behavior)\n- Too many abstraction layers\n- Defensive code for impossible scenarios\n- Premature optimization\n\nReturn: TDD adherence assessment and over-engineering concerns.\n```\n\n### Agent 3: Type & API Verification\n\n```\nVerify types and APIs in the plan match the actual codebase.\n\nSEARCH the codebase for:\n1. All types referenced in the plan's code blocks\n2. Existing type definitions\n3. API endpoint contracts (request/response shapes)\n4. Import paths\n\nVERIFY:\n1. All properties referenced exist in the types\n2. Enum values match between plan and codebase\n3. Import paths are correct\n4. No type mismatches\n\nReturn: List of mismatches with file:line references.\n```\n\n### Agent 4: Library Best Practices\n\n```\nVerify library usage in this plan follows best practices.\n\nFor each library referenced:\n1. Are function signatures correct for current versions?\n2. Are there deprecated APIs being used?\n3. Does usage follow library documentation?\n4. Are installation commands correct?\n\nCheck against loaded skills for technology-specific guidance.\n\nReturn: Incorrect API usage with recommendations.\n```\n\n### Agent 5: Security & Edge Cases\n\n```\nCheck for security gaps and missing error handling.\n\nVERIFY:\n1. Input validation at system boundaries\n2. Error handling in API/DB operations\n3. Auth/authz checks where needed\n4. Edge cases are handled\n\nReturn: Security gaps and missing error handling.\n```\n\n## Step 4: Synthesize Report\n\nAfter all agents complete, create consolidated report:\n\n```markdown\n## Plan Review: [Feature Name from plan]\n\n**Plan:** `[path to plan file]`\n**Tech Stack:** [Detected technologies]\n\n### Summary Table\n\n| Criterion | Status | Notes |\n|-----------|--------|-------|\n| Parallelization |  GOOD /  ISSUES | [Brief note] |\n| TDD Adherence |  GOOD /  ISSUES | [Brief note] |\n| Type/API Match |  GOOD /  ISSUES | [Brief note] |\n| Library Practices |  GOOD /  ISSUES | [Brief note] |\n| Security/Edge Cases |  GOOD /  ISSUES | [Brief note] |\n\n### Issues Found\n\n#### Critical (Must Fix Before Execution)\n\n1. [Task N, Step M] ISSUE_CODE\n   - Issue: What's wrong\n   - Why: Impact if not fixed\n   - Fix: Specific change\n   - Suggested edit:\n   ```\n   [replacement content]\n   ```\n\n#### Major (Should Fix)\n\n2. [Task N] ISSUE_CODE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n#### Minor (Nice to Have)\n\n3. [Task N] ISSUE_CODE\n   - Issue: ...\n   - Fix: ...\n\n### Verdict\n\n**Ready to execute?** Yes | With fixes (1-N) | No\n\n**Reasoning:** [1-2 sentence assessment]\n```\n\n## Step 5: Save Review and Prompt\n\n**Save review** to same directory as plan:\n- Plan: `docs/plans/2025-01-15-feature.md`\n- Review: `docs/plans/2025-01-15-feature-review.md`\n\n**Review file header:**\n\n```markdown\n# Plan Review: [Feature Name]\n\n> **To apply fixes:** Open new session, run:\n> `Read this file, then apply the suggested fixes to [plan path]`\n\n**Reviewed:** [Current date/time]\n**Verdict:** [Yes | With fixes (1-N) | No]\n\n---\n```\n\n**Prompt user:**\n\n```markdown\n---\n\n## Next Steps\n\n**Review saved to:** `[review file path]`\n\n**Options:**\n\n1. **Apply fixes now** - Edit the plan file to address issues\n2. **Save & fix later** - Open new session to apply fixes\n3. **Proceed anyway** - Execute plan despite issues (not recommended for Critical)\n\nWhich option?\n```\n\n## Rules\n\n- Load skills BEFORE launching agents\n- All 5 agents run in parallel via Task tool\n- Reference Task:Step for each issue\n- Provide copyable suggested edits for Critical/Major issues\n- Save review before prompting user\n- Never auto-execute plan; require user choice\n- Number issues sequentially (1, 2, 3...)\n",
        ".cursor/commands/review-python.md": "# Backend Code Review\n\nComprehensive Python/FastAPI backend code review with optional parallel agents.\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.py$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect Pydantic-AI\ngrep -r \"pydantic_ai\\|@agent\\.tool\\|RunContext\" --include=\"*.py\" -l | head -3\n\n# Detect SQLAlchemy\ngrep -r \"from sqlalchemy\\|Session\\|relationship\" --include=\"*.py\" -l | head -3\n\n# Detect Postgres-specific\ngrep -r \"psycopg\\|asyncpg\\|JSONB\\|GIN\" --include=\"*.py\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E 'test.*\\.py$'\n```\n\n## Step 3: Apply Technology-Specific Reviews\n\nReview code using the technology-specific guidelines below based on what was detected:\n\n- **Python**: Always apply Python code review guidelines\n- **FastAPI**: Always apply FastAPI code review guidelines\n- **Tests**: If test files detected, apply pytest guidelines\n- **Pydantic-AI**: If detected, apply Pydantic-AI pitfalls guide\n- **SQLAlchemy**: If detected, apply SQLAlchemy guidelines\n- **PostgreSQL**: If detected, apply PostgreSQL guidelines\n\n## Step 4: Review Process\n\n**Sequential (default):**\n1. Review Python quality issues first\n2. Review FastAPI patterns\n3. Review detected technology areas\n4. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, type safety, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\nruff check .\nmypy .\npytest\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Run verification after fixes\n\n---\n\n# Technology-Specific Review Guidelines\n\n## Python Code Review\n\n### Quick Reference\n\n| Issue Type | Review Focus |\n|------------|--------------|\n| Missing/wrong type hints, Any usage | Type safety |\n| Blocking calls in async, missing await | Async patterns |\n| Bare except, missing context, logging | Error handling |\n| Mutable defaults, print statements | Common mistakes |\n\n### Review Checklist\n\n- [ ] Type hints on all function parameters and return types\n- [ ] No `Any` unless necessary (with comment explaining why)\n- [ ] Proper `T | None` syntax (Python 3.10+)\n- [ ] No blocking calls (`time.sleep`, `requests`) in async functions\n- [ ] Proper `await` on all coroutines\n- [ ] No bare `except:` clauses\n- [ ] Specific exception types with context\n- [ ] `raise ... from` to preserve stack traces\n- [ ] No mutable default arguments\n- [ ] Using `logger` not `print()` for output\n- [ ] f-strings preferred over `.format()` or `%`\n\n### Review Questions\n\n1. Are all function signatures fully typed?\n2. Are async functions truly non-blocking?\n3. Do exceptions include meaningful context?\n4. Are there any mutable default arguments?\n\n---\n\n## Type Safety\n\n### Critical Anti-Patterns\n\n#### 1. Missing Return Type\n\n**Problem**: Callers don't know what to expect.\n\n```python\n# BAD\ndef get_user(id: int):\n    return User.query.get(id)\n\n# GOOD\ndef get_user(id: int) -> User | None:\n    return User.query.get(id)\n```\n\n#### 2. Using Any Without Justification\n\n**Problem**: Defeats the purpose of type checking.\n\n```python\n# BAD\ndef process(data: Any) -> Any:\n    return data\n\n# GOOD - with justification\ndef process(data: Any) -> dict:  # Any: accepts JSON from external API\n    return json.loads(data)\n\n# BETTER - use proper types\ndef process(data: str | bytes) -> dict:\n    return json.loads(data)\n```\n\n#### 3. Optional vs Union Syntax\n\n**Problem**: Inconsistent syntax, less readable.\n\n```python\n# OLD (pre-3.10)\nfrom typing import Optional, Union\ndef find(id: int) -> Optional[User]: ...\ndef parse(val: Union[str, int]) -> str: ...\n\n# GOOD (3.10+)\ndef find(id: int) -> User | None: ...\ndef parse(val: str | int) -> str: ...\n```\n\n#### 4. Missing Generic Types\n\n**Problem**: Loses type information in collections.\n\n```python\n# BAD\ndef get_items() -> list:\n    return [Item(...)]\n\n# GOOD\ndef get_items() -> list[Item]:\n    return [Item(...)]\n\n# BAD\ndef get_config() -> dict:\n    return {\"key\": \"value\"}\n\n# GOOD\ndef get_config() -> dict[str, str]:\n    return {\"key\": \"value\"}\n```\n\n#### 5. TypedDict for Structured Dicts\n\n**Problem**: Plain dict loses key/value type information.\n\n```python\n# BAD\ndef get_user_data() -> dict:\n    return {\"name\": \"Alice\", \"age\": 30}\n\n# GOOD\nfrom typing import TypedDict\n\nclass UserData(TypedDict):\n    name: str\n    age: int\n\ndef get_user_data() -> UserData:\n    return {\"name\": \"Alice\", \"age\": 30}\n```\n\n---\n\n## Async Patterns\n\n### Critical Anti-Patterns\n\n#### 1. Blocking Calls in Async Functions\n\n**Problem**: Blocks the event loop, defeats async benefits.\n\n```python\n# BAD - blocks event loop\nasync def fetch_data():\n    response = requests.get(url)  # BLOCKING!\n    time.sleep(1)  # BLOCKING!\n    return response.json()\n\n# GOOD - non-blocking\nasync def fetch_data():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n    await asyncio.sleep(1)\n    return response.json()\n```\n\n#### 2. Missing await on Coroutines\n\n**Problem**: Coroutine never executes.\n\n```python\n# BAD - coroutine created but never awaited\nasync def process():\n    fetch_data()  # Returns coroutine, doesn't execute!\n\n# GOOD\nasync def process():\n    await fetch_data()\n```\n\n#### 3. Sequential Instead of Concurrent\n\n**Problem**: Misses parallelization opportunity.\n\n```python\n# BAD - sequential (slow)\nasync def get_all():\n    user = await get_user()\n    posts = await get_posts()\n    comments = await get_comments()\n    return user, posts, comments\n\n# GOOD - concurrent (fast)\nasync def get_all():\n    user, posts, comments = await asyncio.gather(\n        get_user(),\n        get_posts(),\n        get_comments()\n    )\n    return user, posts, comments\n```\n\n#### 4. Missing async with for Async Context Managers\n\n**Problem**: Resource not properly managed.\n\n```python\n# BAD\nasync def query():\n    session = aiosqlite.connect(db)  # Not entered!\n    return await session.execute(sql)\n\n# GOOD\nasync def query():\n    async with aiosqlite.connect(db) as session:\n        return await session.execute(sql)\n```\n\n#### 5. Sync File I/O in Async Context\n\n**Problem**: File operations block event loop.\n\n```python\n# BAD - blocks event loop\nasync def read_config():\n    with open(\"config.json\") as f:\n        return json.load(f)\n\n# GOOD - use aiofiles\nimport aiofiles\n\nasync def read_config():\n    async with aiofiles.open(\"config.json\") as f:\n        content = await f.read()\n        return json.loads(content)\n\n# ACCEPTABLE - for small files, run in executor\nasync def read_config():\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(None, load_config_sync)\n```\n\n---\n\n## Error Handling\n\n### Critical Anti-Patterns\n\n#### 1. Bare Except Clause\n\n**Problem**: Catches everything including KeyboardInterrupt, SystemExit.\n\n```python\n# BAD\ntry:\n    process()\nexcept:\n    pass\n\n# GOOD - specific exception\ntry:\n    process()\nexcept ValueError as e:\n    logger.error(f\"Invalid value: {e}\")\n    raise\n\n# ACCEPTABLE - if you must catch all\ntry:\n    process()\nexcept Exception as e:  # Still allows KeyboardInterrupt\n    logger.error(f\"Unexpected error: {e}\")\n    raise\n```\n\n#### 2. Swallowing Exceptions\n\n**Problem**: Hides errors, makes debugging impossible.\n\n```python\n# BAD\ntry:\n    result = risky_operation()\nexcept Exception:\n    pass  # Error silently ignored!\n\n# GOOD - log and handle\ntry:\n    result = risky_operation()\nexcept OperationError as e:\n    logger.warning(f\"Operation failed: {e}\")\n    result = default_value\n```\n\n#### 3. Losing Exception Context\n\n**Problem**: Original stack trace lost.\n\n```python\n# BAD - loses original traceback\ntry:\n    parse_config()\nexcept ValueError:\n    raise ConfigError(\"Invalid config\")\n\n# GOOD - preserves chain\ntry:\n    parse_config()\nexcept ValueError as e:\n    raise ConfigError(\"Invalid config\") from e\n```\n\n#### 4. Missing Context in Error Messages\n\n**Problem**: Can't diagnose issue from logs.\n\n```python\n# BAD\nexcept KeyError:\n    raise ValueError(\"Missing key\")\n\n# GOOD - include context\nexcept KeyError as e:\n    raise ValueError(f\"Missing required key: {e.args[0]}\") from e\n```\n\n#### 5. Not Logging Before Re-raising\n\n**Problem**: Exception might be caught elsewhere without logging.\n\n```python\n# BAD - no record if caught upstream\ntry:\n    process(item)\nexcept ProcessError:\n    raise\n\n# GOOD - log before re-raising\ntry:\n    process(item)\nexcept ProcessError as e:\n    logger.error(f\"Failed to process item {item.id}: {e}\")\n    raise\n```\n\n### Logging Best Practices\n\n```python\nfrom loguru import logger\n\n# BAD\nprint(f\"Processing {item}\")\nprint(f\"Error: {e}\")\n\n# GOOD\nlogger.debug(f\"Processing item {item.id}\")\nlogger.info(f\"Completed batch of {count} items\")\nlogger.warning(f\"Retry {attempt}/3 for {operation}\")\nlogger.error(f\"Failed to process {item.id}: {e}\")\n\n# With exception info\nlogger.exception(f\"Unexpected error processing {item.id}\")\n```\n\n---\n\n## Common Mistakes\n\n### Critical Anti-Patterns\n\n#### 1. Mutable Default Arguments\n\n**Problem**: Default value is shared across all calls.\n\n```python\n# BAD - same list reused!\ndef add_item(item, items=[]):\n    items.append(item)\n    return items\n\nadd_item(\"a\")  # [\"a\"]\nadd_item(\"b\")  # [\"a\", \"b\"] - unexpected!\n\n# GOOD\ndef add_item(item, items=None):\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\n# BETTER - using dataclass\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass Container:\n    items: list = field(default_factory=list)\n```\n\n#### 2. Using print() for Logging\n\n**Problem**: No log levels, no timestamps, hard to filter.\n\n```python\n# BAD\nprint(f\"Processing {item}\")\nprint(f\"Error: {e}\")\n\n# GOOD\nfrom loguru import logger\n\nlogger.info(f\"Processing {item}\")\nlogger.error(f\"Error: {e}\")\n```\n\n#### 3. String Formatting Inconsistency\n\n**Problem**: Mixing formats reduces readability.\n\n```python\n# BAD - mixed formats\nmsg = \"Hello %s\" % name\nmsg = \"Hello {}\".format(name)\nmsg = f\"Hello {name}\"\n\n# GOOD - f-strings consistently\nmsg = f\"Hello {name}\"\ntotal = f\"Count: {count:,}\"  # with formatting\npath = f\"{base}/{sub}/{file}\"\n```\n\n#### 4. Unused Variables\n\n**Problem**: Dead code, confusing to readers.\n\n```python\n# BAD\nresult = process()  # never used\n\n# GOOD - use underscore for intentionally ignored\n_, second, _ = get_triple()\n\n# Or just don't assign\nprocess()  # if result not needed\n```\n\n#### 5. Import Order\n\n**Problem**: Hard to scan, may cause issues.\n\n```python\n# BAD - random order\nfrom myapp.utils import helper\nimport os\nfrom typing import Optional\nimport sys\nfrom myapp.models import User\n\n# GOOD - standard order\nimport os\nimport sys\nfrom typing import Optional\n\nfrom myapp.models import User\nfrom myapp.utils import helper\n```\n\n#### 6. Magic Numbers\n\n**Problem**: Unclear intent, hard to maintain.\n\n```python\n# BAD\nif len(items) > 100:\n    paginate()\ntime.sleep(3600)\n\n# GOOD\nMAX_PAGE_SIZE = 100\nCACHE_TTL_SECONDS = 3600\n\nif len(items) > MAX_PAGE_SIZE:\n    paginate()\ntime.sleep(CACHE_TTL_SECONDS)\n```\n\n#### 7. Nested Conditionals\n\n**Problem**: Hard to read and maintain.\n\n```python\n# BAD\ndef process(user):\n    if user:\n        if user.active:\n            if user.verified:\n                return do_work(user)\n    return None\n\n# GOOD - early returns\ndef process(user):\n    if not user:\n        return None\n    if not user.active:\n        return None\n    if not user.verified:\n        return None\n    return do_work(user)\n```\n\n---\n\n## FastAPI Code Review\n\n### Quick Reference\n\n| Issue Type | Review Focus |\n|------------|--------------|\n| APIRouter setup, response_model, status codes | Routes |\n| Depends(), yield deps, cleanup, shared deps | Dependencies |\n| Pydantic models, HTTPException, 422 handling | Validation |\n| Async handlers, blocking I/O, background tasks | Async |\n\n### Review Checklist\n\n- [ ] APIRouter with proper prefix and tags\n- [ ] All routes specify `response_model` for type safety\n- [ ] Correct HTTP methods (GET, POST, PUT, DELETE, PATCH)\n- [ ] Proper status codes (200, 201, 204, 404, etc.)\n- [ ] Dependencies use `Depends()` not manual calls\n- [ ] Yield dependencies have proper cleanup\n- [ ] Request/Response models use Pydantic\n- [ ] HTTPException with status code and detail\n- [ ] All route handlers are `async def`\n- [ ] No blocking I/O (`requests`, `time.sleep`, `open()`)\n- [ ] Background tasks for non-blocking operations\n- [ ] No bare `except` in route handlers\n\n### Review Questions\n\n1. Do all routes have explicit response models and status codes?\n2. Are dependencies injected via Depends() with proper cleanup?\n3. Do all Pydantic models validate inputs correctly?\n4. Are all route handlers async and non-blocking?\n\n---\n\n## Routes\n\n### Critical Anti-Patterns\n\n#### 1. Missing response_model\n\n**Problem**: No type safety, documentation unclear, response not validated.\n\n```python\n# BAD\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    return {\"id\": user_id, \"name\": \"Alice\"}\n\n# GOOD\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int):\n    return {\"id\": user_id, \"name\": \"Alice\"}\n```\n\n#### 2. No APIRouter Prefix/Tags\n\n**Problem**: Routes not organized, duplicated path prefixes, unclear docs.\n\n```python\n# BAD\n@app.get(\"/api/v1/users\")\nasync def list_users(): ...\n\n@app.get(\"/api/v1/users/{id}\")\nasync def get_user(id: int): ...\n\n# GOOD\nrouter = APIRouter(prefix=\"/api/v1/users\", tags=[\"users\"])\n\n@router.get(\"\")\nasync def list_users(): ...\n\n@router.get(\"/{id}\")\nasync def get_user(id: int): ...\n\napp.include_router(router)\n```\n\n#### 3. Wrong HTTP Methods\n\n**Problem**: Violates REST conventions, confusing semantics.\n\n```python\n# BAD - using GET for mutations\n@router.get(\"/users/{id}/delete\")\nasync def delete_user(id: int): ...\n\n# BAD - using POST for retrieval\n@router.post(\"/users/{id}\")\nasync def get_user(id: int): ...\n\n# GOOD\n@router.delete(\"/users/{id}\", status_code=204)\nasync def delete_user(id: int): ...\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int): ...\n```\n\n#### 4. Missing Status Codes\n\n**Problem**: Always returns 200, even for creates/deletes.\n\n```python\n# BAD - creates should return 201\n@router.post(\"/users\")\nasync def create_user(user: UserCreate):\n    return created_user\n\n# BAD - deletes should return 204\n@router.delete(\"/users/{id}\")\nasync def delete_user(id: int):\n    return {\"message\": \"deleted\"}\n\n# GOOD\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    return created_user\n\n@router.delete(\"/users/{id}\", status_code=204)\nasync def delete_user(id: int):\n    # 204 returns no content\n    return None\n```\n\n#### 5. Direct Exception Raising\n\n**Problem**: Returns generic 500 errors instead of proper HTTP status codes.\n\n```python\n# BAD\n@router.get(\"/users/{id}\")\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise ValueError(\"User not found\")\n    return user\n\n# GOOD\nfrom fastapi import HTTPException\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n```\n\n#### 6. Multiple Response Models\n\n**Problem**: Same endpoint returns different schemas.\n\n```python\n# BAD\n@router.get(\"/users/{id}\")\nasync def get_user(id: int, full: bool = False):\n    if full:\n        return UserDetailResponse(...)\n    return UserSummaryResponse(...)\n\n# GOOD - use separate endpoints\n@router.get(\"/users/{id}\", response_model=UserSummaryResponse)\nasync def get_user(id: int):\n    return UserSummaryResponse(...)\n\n@router.get(\"/users/{id}/full\", response_model=UserDetailResponse)\nasync def get_user_full(id: int):\n    return UserDetailResponse(...)\n\n# ALTERNATIVE - use response_model with Union\nfrom typing import Union\n\n@router.get(\"/users/{id}\", response_model=Union[UserSummaryResponse, UserDetailResponse])\nasync def get_user(id: int, full: bool = False):\n    if full:\n        return UserDetailResponse(...)\n    return UserSummaryResponse(...)\n```\n\n#### 7. Path Parameter Validation\n\n**Problem**: No validation on path parameters.\n\n```python\n# BAD\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    # What if user_id is negative or zero?\n    return await db.get_user(user_id)\n\n# GOOD\nfrom fastapi import Path\n\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int = Path(..., gt=0)):\n    return await db.get_user(user_id)\n```\n\n---\n\n## Dependencies\n\n### Critical Anti-Patterns\n\n#### 1. Manual Dependency Calls\n\n**Problem**: Bypasses FastAPI's injection system, no automatic cleanup.\n\n```python\n# BAD - manually calling dependency\nasync def get_db_session():\n    session = SessionLocal()\n    return session\n\n@router.get(\"/users\")\nasync def list_users():\n    db = await get_db_session()  # Manual call!\n    users = await db.query(User).all()\n    return users\n\n# GOOD - using Depends()\nfrom fastapi import Depends\n\nasync def get_db_session():\n    session = SessionLocal()\n    try:\n        yield session\n    finally:\n        await session.close()\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: Session = Depends(get_db_session)):\n    users = await db.query(User).all()\n    return users\n```\n\n#### 2. Missing Cleanup in Yield Dependencies\n\n**Problem**: Resources leak, connections not closed.\n\n```python\n# BAD - no cleanup\nasync def get_db():\n    db = DatabaseConnection()\n    yield db\n    # Connection never closed!\n\n# GOOD - proper cleanup\nasync def get_db():\n    db = DatabaseConnection()\n    try:\n        yield db\n    finally:\n        await db.close()\n```\n\n#### 3. Shared State Without Proper Scope\n\n**Problem**: Dependencies create shared mutable state across requests.\n\n```python\n# BAD - shared mutable state\ncache = {}  # Shared across all requests!\n\nasync def get_cache():\n    return cache\n\n@router.get(\"/items/{id}\")\nasync def get_item(id: int, cache: dict = Depends(get_cache)):\n    # Multiple requests share same dict - race conditions!\n    if id not in cache:\n        cache[id] = await fetch_item(id)\n    return cache[id]\n\n# GOOD - request-scoped state\nfrom contextvars import ContextVar\n\nrequest_cache: ContextVar[dict] = ContextVar('request_cache')\n\nasync def get_cache():\n    cache = {}\n    request_cache.set(cache)\n    return cache\n\n# BETTER - use proper caching library\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\nasync def get_item_cached(id: int):\n    return await fetch_item(id)\n```\n\n#### 4. Nested Depends Not Utilized\n\n**Problem**: Duplicate code, no composition of dependencies.\n\n```python\n# BAD - duplicated logic\nasync def get_current_user(token: str):\n    # Verify token, decode, fetch user\n    return user\n\nasync def get_admin_user(token: str):\n    # Same verification, then check admin\n    user = await verify_and_decode(token)\n    if not user.is_admin:\n        raise HTTPException(403)\n    return user\n\n# GOOD - compose dependencies\nasync def get_current_user(token: str = Depends(oauth2_scheme)):\n    user = await verify_token(token)\n    if not user:\n        raise HTTPException(401, detail=\"Invalid token\")\n    return user\n\nasync def get_admin_user(user: User = Depends(get_current_user)):\n    if not user.is_admin:\n        raise HTTPException(403, detail=\"Admin required\")\n    return user\n```\n\n#### 5. Dependencies with Side Effects\n\n**Problem**: Dependencies modify state instead of providing resources.\n\n```python\n# BAD - dependency has side effects\nasync def log_request(request: Request):\n    # Side effect: writes to database\n    await db.log_request(request)\n    return None\n\n@router.get(\"/users\")\nasync def list_users(_: None = Depends(log_request)):\n    return users\n\n# GOOD - use middleware for cross-cutting concerns\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass LoggingMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        await db.log_request(request)\n        response = await call_next(request)\n        return response\n\napp.add_middleware(LoggingMiddleware)\n\n# OR - dependency returns resource\nasync def get_logger(request: Request):\n    logger = RequestLogger(request)\n    return logger\n\n@router.get(\"/users\")\nasync def list_users(logger: RequestLogger = Depends(get_logger)):\n    logger.info(\"Listing users\")\n    return users\n```\n\n#### 6. Class-Based Dependencies Without Caching\n\n**Problem**: New instance created unnecessarily.\n\n```python\n# BAD - new instance every time\nclass DatabaseService:\n    def __init__(self):\n        self.connection_pool = create_pool()  # Expensive!\n\n@router.get(\"/users\")\nasync def list_users(db: DatabaseService = Depends(DatabaseService)):\n    return await db.query_users()\n\n# GOOD - use singleton or app state\nclass DatabaseService:\n    def __init__(self, pool):\n        self.pool = pool\n\nasync def get_db_service(\n    pool = Depends(lambda: app.state.db_pool)\n) -> DatabaseService:\n    return DatabaseService(pool)\n\n# OR - use dependency with cache\nasync def get_db_service() -> DatabaseService:\n    return app.state.db_service\n\n@router.get(\"/users\")\nasync def list_users(db: DatabaseService = Depends(get_db_service)):\n    return await db.query_users()\n```\n\n#### 7. Security Dependencies Not Applied Globally\n\n**Problem**: Easy to forget security on new routes.\n\n```python\n# BAD - must remember to add auth to every route\n@router.get(\"/users\", dependencies=[Depends(verify_token)])\nasync def list_users(): ...\n\n@router.get(\"/posts\")  # Forgot auth!\nasync def list_posts(): ...\n\n# GOOD - apply at router level\nrouter = APIRouter(\n    prefix=\"/api/v1\",\n    dependencies=[Depends(verify_token)]\n)\n\n@router.get(\"/users\")\nasync def list_users(): ...\n\n@router.get(\"/posts\")\nasync def list_posts(): ...\n```\n\n---\n\n## Validation\n\n### Critical Anti-Patterns\n\n#### 1. Manual Validation Instead of Pydantic\n\n**Problem**: Duplicate validation logic, inconsistent errors.\n\n```python\n# BAD - manual validation\n@router.post(\"/users\")\nasync def create_user(request: Request):\n    data = await request.json()\n    if \"email\" not in data:\n        raise HTTPException(400, \"Email required\")\n    if \"@\" not in data[\"email\"]:\n        raise HTTPException(400, \"Invalid email\")\n    return await db.create_user(data)\n\n# GOOD - Pydantic validation\nfrom pydantic import BaseModel, EmailStr\n\nclass UserCreate(BaseModel):\n    email: EmailStr\n    name: str\n    age: int | None = None\n\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    return await db.create_user(user)\n```\n\n#### 2. Missing Field Validators\n\n**Problem**: Invalid data passes through.\n\n```python\n# BAD - no validation on age\nclass UserCreate(BaseModel):\n    name: str\n    age: int  # Can be negative!\n\n# GOOD - field validation\nfrom pydantic import BaseModel, Field\n\nclass UserCreate(BaseModel):\n    name: str = Field(..., min_length=1, max_length=100)\n    age: int = Field(..., ge=0, le=150)\n    email: EmailStr\n```\n\n#### 3. Generic HTTPException Messages\n\n**Problem**: Users don't know what's wrong.\n\n```python\n# BAD - vague error\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    user = await db.get_user(user_id)\n    if not user:\n        raise HTTPException(404)  # No detail!\n    return user\n\n# GOOD - specific error\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int):\n    user = await db.get_user(user_id)\n    if not user:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"User {user_id} not found\"\n        )\n    return user\n```\n\n#### 4. Not Using Pydantic Config\n\n**Problem**: Models accept extra fields, expose internal fields.\n\n```python\n# BAD - accepts any extra fields\nclass UserCreate(BaseModel):\n    name: str\n    email: str\n    # {\"name\": \"Alice\", \"email\": \"a@b.com\", \"is_admin\": true} accepted!\n\n# GOOD - strict validation\nclass UserCreate(BaseModel):\n    name: str\n    email: EmailStr\n\n    class Config:\n        extra = \"forbid\"  # Reject unknown fields\n\n# GOOD - control ORM exposure\nclass UserResponse(BaseModel):\n    id: int\n    name: str\n    email: str\n    # Don't expose password_hash, created_at, etc.\n\n    class Config:\n        from_attributes = True  # Formerly orm_mode\n```\n\n#### 5. Missing Custom Validators\n\n**Problem**: Business rules not enforced.\n\n```python\n# BAD - no validation\nclass PasswordReset(BaseModel):\n    password: str\n    confirm_password: str\n    # Passwords might not match!\n\n# GOOD - custom validator\nfrom pydantic import BaseModel, model_validator\n\nclass PasswordReset(BaseModel):\n    password: str = Field(..., min_length=8)\n    confirm_password: str\n\n    @model_validator(mode='after')\n    def passwords_match(self):\n        if self.password != self.confirm_password:\n            raise ValueError('Passwords do not match')\n        return self\n```\n\n#### 6. Not Handling 422 Validation Errors\n\n**Problem**: Default 422 responses unclear to clients.\n\n```python\n# BAD - default 422 response is verbose and unclear\n# (No custom handler)\n\n# GOOD - custom 422 handler\nfrom fastapi import Request, status\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\n@app.exception_handler(RequestValidationError)\nasync def validation_exception_handler(\n    request: Request,\n    exc: RequestValidationError\n):\n    errors = []\n    for error in exc.errors():\n        errors.append({\n            \"field\": \".\".join(str(x) for x in error[\"loc\"][1:]),\n            \"message\": error[\"msg\"],\n            \"type\": error[\"type\"]\n        })\n\n    return JSONResponse(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        content={\"detail\": errors}\n    )\n```\n\n#### 7. Using Dict Instead of Models\n\n**Problem**: No validation, no type safety, unclear API.\n\n```python\n# BAD - dict responses\n@router.get(\"/users/{id}\")\nasync def get_user(id: int) -> dict:\n    return {\n        \"id\": id,\n        \"name\": \"Alice\",\n        \"extra_field\": \"oops\"  # Inconsistent!\n    }\n\n# GOOD - Pydantic response model\nclass UserResponse(BaseModel):\n    id: int\n    name: str\n    email: str\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise HTTPException(404, detail=\"User not found\")\n    return user  # Auto-validates and filters fields\n```\n\n#### 8. Missing Query Parameter Validation\n\n**Problem**: Invalid query parameters not validated.\n\n```python\n# BAD - no validation\n@router.get(\"/users\")\nasync def list_users(page: int = 1, size: int = 10):\n    # What if page is 0 or negative?\n    # What if size is 10000?\n    return await db.get_users(page, size)\n\n# GOOD - validated query params\nfrom fastapi import Query\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(\n    page: int = Query(1, ge=1),\n    size: int = Query(10, ge=1, le=100)\n):\n    return await db.get_users(page, size)\n```\n\n---\n\n## Async\n\n### Critical Anti-Patterns\n\n#### 1. Blocking I/O in Async Handlers\n\n**Problem**: Blocks the event loop, prevents concurrent request handling.\n\n```python\n# BAD - blocking HTTP client\nimport requests\n\n@router.get(\"/external\")\nasync def fetch_external():\n    response = requests.get(\"https://api.example.com\")  # BLOCKS!\n    return response.json()\n\n# GOOD - async HTTP client\nimport httpx\n\n@router.get(\"/external\")\nasync def fetch_external():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com\")\n    return response.json()\n```\n\n#### 2. Blocking Database Calls\n\n**Problem**: Synchronous DB driver blocks event loop.\n\n```python\n# BAD - sync SQLAlchemy\nfrom sqlalchemy.orm import Session\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: Session = Depends(get_db)):\n    users = db.query(User).all()  # BLOCKS!\n    return users\n\n# GOOD - async SQLAlchemy\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: AsyncSession = Depends(get_db)):\n    result = await db.execute(select(User))\n    users = result.scalars().all()\n    return users\n```\n\n#### 3. Using time.sleep Instead of asyncio.sleep\n\n**Problem**: Blocks event loop during sleep.\n\n```python\n# BAD - blocking sleep\nimport time\n\n@router.post(\"/jobs\")\nasync def create_job():\n    time.sleep(5)  # BLOCKS for 5 seconds!\n    return {\"status\": \"done\"}\n\n# GOOD - async sleep\nimport asyncio\n\n@router.post(\"/jobs\")\nasync def create_job():\n    await asyncio.sleep(5)  # Yields control\n    return {\"status\": \"done\"}\n\n# BETTER - use background tasks for long operations\nfrom fastapi import BackgroundTasks\n\nasync def process_job():\n    await asyncio.sleep(5)\n    # Do actual work\n\n@router.post(\"/jobs\")\nasync def create_job(background_tasks: BackgroundTasks):\n    background_tasks.add_task(process_job)\n    return {\"status\": \"processing\"}\n```\n\n#### 4. Sync File I/O in Async Handlers\n\n**Problem**: File operations block event loop.\n\n```python\n# BAD - blocking file I/O\n@router.get(\"/config\")\nasync def get_config():\n    with open(\"config.json\") as f:  # BLOCKS!\n        return json.load(f)\n\n# GOOD - async file I/O\nimport aiofiles\n\n@router.get(\"/config\")\nasync def get_config():\n    async with aiofiles.open(\"config.json\") as f:\n        content = await f.read()\n    return json.loads(content)\n\n# ACCEPTABLE - small files in executor\nimport asyncio\n\ndef read_config_sync():\n    with open(\"config.json\") as f:\n        return json.load(f)\n\n@router.get(\"/config\")\nasync def get_config():\n    loop = asyncio.get_event_loop()\n    config = await loop.run_in_executor(None, read_config_sync)\n    return config\n```\n\n#### 5. Not Using Background Tasks\n\n**Problem**: Long operations block response, timeout issues.\n\n```python\n# BAD - blocks response\n@router.post(\"/emails\")\nasync def send_email(email: EmailCreate):\n    await send_email_via_smtp(email)  # Takes 5 seconds!\n    await log_email_sent(email)  # Takes 1 second!\n    return {\"status\": \"sent\"}\n\n# GOOD - use background tasks\nfrom fastapi import BackgroundTasks\n\nasync def send_email_background(email: EmailCreate):\n    await send_email_via_smtp(email)\n    await log_email_sent(email)\n\n@router.post(\"/emails\", status_code=202)\nasync def send_email(\n    email: EmailCreate,\n    background_tasks: BackgroundTasks\n):\n    background_tasks.add_task(send_email_background, email)\n    return {\"status\": \"queued\"}\n```\n\n#### 6. Sequential Instead of Concurrent Calls\n\n**Problem**: Misses parallelization opportunity.\n\n```python\n# BAD - sequential (slow)\n@router.get(\"/dashboard\")\nasync def get_dashboard(user_id: int):\n    user = await get_user(user_id)\n    posts = await get_user_posts(user_id)\n    stats = await get_user_stats(user_id)\n    return {\"user\": user, \"posts\": posts, \"stats\": stats}\n\n# GOOD - concurrent (fast)\nimport asyncio\n\n@router.get(\"/dashboard\")\nasync def get_dashboard(user_id: int):\n    user, posts, stats = await asyncio.gather(\n        get_user(user_id),\n        get_user_posts(user_id),\n        get_user_stats(user_id)\n    )\n    return {\"user\": user, \"posts\": posts, \"stats\": stats}\n```\n\n#### 7. Mixing Sync and Async Route Handlers\n\n**Problem**: Inconsistent patterns, sync handlers block thread pool.\n\n```python\n# BAD - mixing sync and async\n@router.get(\"/sync-route\")\ndef sync_handler():  # Blocks thread pool\n    return db.query(User).all()\n\n@router.get(\"/async-route\")\nasync def async_handler():\n    return await db.query_async(User)\n\n# GOOD - all async\n@router.get(\"/route1\")\nasync def handler1():\n    result = await db.execute(select(User))\n    return result.scalars().all()\n\n@router.get(\"/route2\")\nasync def handler2():\n    result = await db.execute(select(Post))\n    return result.scalars().all()\n```\n\n#### 8. Not Awaiting Coroutines\n\n**Problem**: Coroutine never executes, silent failures.\n\n```python\n# BAD - missing await\n@router.post(\"/users\")\nasync def create_user(user: UserCreate):\n    db.create_user(user)  # Returns coroutine, doesn't execute!\n    return {\"status\": \"created\"}  # User not actually created!\n\n# GOOD - await coroutines\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    created_user = await db.create_user(user)\n    return created_user\n```\n\n#### 9. Blocking External API Calls\n\n**Problem**: Synchronous requests library blocks event loop.\n\n```python\n# BAD - requests blocks\nimport requests\n\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    response = requests.get(f\"https://api.weather.com/{city}\")  # BLOCKS!\n    return response.json()\n\n# GOOD - httpx async\nimport httpx\n\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.weather.com/{city}\")\n    return response.json()\n\n# GOOD - with timeout\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    async with httpx.AsyncClient(timeout=5.0) as client:\n        try:\n            response = await client.get(f\"https://api.weather.com/{city}\")\n            return response.json()\n        except httpx.TimeoutException:\n            raise HTTPException(504, detail=\"Weather API timeout\")\n```\n\n---\n\n## Pytest Code Review\n\n### Quick Reference\n\n| Issue Type | Review Focus |\n|------------|--------------|\n| async def test_*, AsyncMock, await patterns | Async testing |\n| conftest.py, factory fixtures, scope, cleanup | Fixtures |\n| @pytest.mark.parametrize, DRY patterns | Parametrize |\n| AsyncMock tracking, patch patterns, when to mock | Mocking |\n\n### Review Checklist\n\n- [ ] Test functions are `async def test_*` for async code under test\n- [ ] AsyncMock used for async dependencies, not Mock\n- [ ] All async mocks and coroutines are awaited\n- [ ] Fixtures in conftest.py for shared setup\n- [ ] Fixture scope appropriate (function, class, module, session)\n- [ ] Yield fixtures have proper cleanup in finally block\n- [ ] @pytest.mark.parametrize for similar test cases\n- [ ] No duplicated test logic across multiple test functions\n- [ ] Mocks track calls properly (assert_called_once_with)\n- [ ] patch() targets correct location (where used, not defined)\n- [ ] No mocking of internals that should be tested\n- [ ] Test isolation (no shared mutable state between tests)\n\n### Review Questions\n\n1. Are all async functions tested with async def test_*?\n2. Are fixtures properly scoped with appropriate cleanup?\n3. Can similar test cases be parametrized to reduce duplication?\n4. Are mocks tracking calls and used at the right locations?\n\n---\n\n*Note: Detailed pytest anti-patterns for async testing, fixtures, parametrize, and mocking are extensive. Apply these guidelines when reviewing test files.*\n\n---\n\n## SQLAlchemy Code Review\n\n### Quick Reference\n\n| Issue Type | Review Focus |\n|------------|--------------|\n| Session lifecycle, context managers, async sessions | Sessions |\n| relationship(), lazy loading, N+1, joinedload | Relationships |\n| select() vs query(), ORM overhead, bulk ops | Queries |\n| Alembic patterns, reversible migrations, data migrations | Migrations |\n\n### Review Checklist\n\n- [ ] Sessions use context managers (`with`, `async with`)\n- [ ] No session sharing across requests or threads\n- [ ] Sessions closed/cleaned up properly\n- [ ] `relationship()` uses appropriate `lazy` strategy\n- [ ] Explicit `joinedload`/`selectinload` to avoid N+1\n- [ ] No lazy loading in loops (N+1 queries)\n- [ ] Using SQLAlchemy 2.0 `select()` syntax, not legacy `query()`\n- [ ] Bulk operations use bulk_insert/bulk_update, not ORM loops\n- [ ] Async sessions use proper async context managers\n- [ ] Migrations are reversible with `downgrade()`\n- [ ] Data migrations use `op.execute()` not ORM models\n- [ ] Migration dependencies properly ordered\n\n### Review Questions\n\n1. Are all sessions properly managed with context managers?\n2. Are relationships configured to avoid N+1 queries?\n3. Are queries using SQLAlchemy 2.0 `select()` syntax?\n4. Are all migrations reversible and properly tested?\n\n---\n\n*Note: Detailed SQLAlchemy anti-patterns for sessions, relationships, queries, and migrations are extensive. Apply these guidelines when reviewing database code.*\n\n---\n\n## PostgreSQL Code Review\n\n### Quick Reference\n\n| Issue Type | Review Focus |\n|------------|--------------|\n| Missing indexes, wrong index type, query performance | Indexes |\n| JSONB queries, operators, GIN indexes | JSONB |\n| Connection leaks, pool configuration, timeouts | Connections |\n| Isolation levels, deadlocks, advisory locks | Transactions |\n\n### Review Checklist\n\n- [ ] WHERE/JOIN columns have appropriate indexes\n- [ ] Composite indexes match query patterns (column order matters)\n- [ ] JSONB columns use GIN indexes when queried\n- [ ] Using proper JSONB operators (`->`, `->>`, `@>`, `?`)\n- [ ] Connection pool configured with appropriate limits\n- [ ] Connections properly released (context managers, try/finally)\n- [ ] Appropriate transaction isolation level for use case\n- [ ] No long-running transactions holding locks\n- [ ] Advisory locks used for application-level coordination\n- [ ] Queries use parameterized statements (no SQL injection)\n\n### Review Questions\n\n1. Will this query use an index or perform a sequential scan?\n2. Are JSONB operations using appropriate operators and indexes?\n3. Are database connections properly managed and released?\n4. Is the transaction isolation level appropriate for this operation?\n5. Could this cause deadlocks or long-running locks?\n\n---\n\n*Note: Detailed PostgreSQL anti-patterns for indexes, JSONB, connections, and transactions are extensive. Apply these guidelines when reviewing database code.*\n\n---\n\n## Pydantic-AI Common Pitfalls\n\n### Tool Decorator Errors\n\n#### Wrong: RunContext in tool_plain\n\n```python\n# ERROR: RunContext not allowed in tool_plain\n@agent.tool_plain\nasync def bad_tool(ctx: RunContext[MyDeps]) -> str:\n    return \"oops\"\n# UserError: RunContext annotations can only be used with tools that take context\n```\n\n**Fix**: Use `@agent.tool` if you need context:\n```python\n@agent.tool\nasync def good_tool(ctx: RunContext[MyDeps]) -> str:\n    return \"works\"\n```\n\n#### Wrong: Missing RunContext in tool\n\n```python\n# ERROR: First param must be RunContext\n@agent.tool\ndef bad_tool(user_id: int) -> str:\n    return \"oops\"\n# UserError: First parameter of tools that take context must be annotated with RunContext[...]\n```\n\n**Fix**: Add RunContext as first parameter:\n```python\n@agent.tool\ndef good_tool(ctx: RunContext[MyDeps], user_id: int) -> str:\n    return \"works\"\n```\n\n#### Wrong: RunContext not first\n\n```python\n# ERROR: RunContext must be first parameter\n@agent.tool\ndef bad_tool(user_id: int, ctx: RunContext[MyDeps]) -> str:\n    return \"oops\"\n```\n\n**Fix**: RunContext must always be the first parameter.\n\n### Dependency Type Mismatches\n\n#### Wrong: Missing deps at runtime\n\n```python\nagent = Agent('openai:gpt-4o', deps_type=MyDeps)\n\n# ERROR: deps required but not provided\nresult = agent.run_sync('Hello')  # Missing deps!\n```\n\n**Fix**: Always provide deps when deps_type is set:\n```python\nresult = agent.run_sync('Hello', deps=MyDeps(...))\n```\n\n#### Wrong: Wrong deps type\n\n```python\n@dataclass\nclass AppDeps:\n    db: Database\n\n@dataclass\nclass WrongDeps:\n    api: ApiClient\n\nagent = Agent('openai:gpt-4o', deps_type=AppDeps)\n\n# Type error: WrongDeps != AppDeps\nresult = agent.run_sync('Hello', deps=WrongDeps(...))\n```\n\n### Output Type Issues\n\n#### Pydantic validation fails\n\n```python\nclass Response(BaseModel):\n    count: int\n    items: list[str]\n\nagent = Agent('openai:gpt-4o', output_type=Response)\nresult = agent.run_sync('List items')\n# May fail if LLM returns wrong structure\n```\n\n**Fix**: Increase retries or improve prompt:\n```python\nagent = Agent(\n    'openai:gpt-4o',\n    output_type=Response,\n    retries=3,  # More attempts\n    instructions='Return JSON with count (int) and items (list of strings).'\n)\n```\n\n#### Complex nested types\n\n```python\n# May cause schema issues with some models\nclass Complex(BaseModel):\n    nested: dict[str, list[tuple[int, str]]]\n```\n\n**Fix**: Simplify or use intermediate models:\n```python\nclass Item(BaseModel):\n    id: int\n    name: str\n\nclass Simple(BaseModel):\n    items: list[Item]\n```\n\n### Async vs Sync Mistakes\n\n#### Wrong: Calling async in sync context\n\n```python\n# ERROR: Can't await in sync function\ndef handler():\n    result = await agent.run('Hello')  # SyntaxError!\n```\n\n**Fix**: Use run_sync or make handler async:\n```python\ndef handler():\n    result = agent.run_sync('Hello')\n\n# Or\nasync def handler():\n    result = await agent.run('Hello')\n```\n\n#### Wrong: Blocking in async tools\n\n```python\n@agent.tool\nasync def slow_tool(ctx: RunContext[Deps]) -> str:\n    time.sleep(5)  # WRONG: Blocks event loop!\n    return \"done\"\n```\n\n**Fix**: Use async I/O:\n```python\n@agent.tool\nasync def slow_tool(ctx: RunContext[Deps]) -> str:\n    await asyncio.sleep(5)  # Correct\n    return \"done\"\n```\n\n### Model Configuration Errors\n\n#### Missing API key\n\n```python\n# ERROR: OPENAI_API_KEY not set\nagent = Agent('openai:gpt-4o')\nresult = agent.run_sync('Hello')\n# ModelAPIError: Authentication failed\n```\n\n**Fix**: Set environment variable or use defer_model_check:\n```python\n# For testing\nagent = Agent('openai:gpt-4o', defer_model_check=True)\nwith agent.override(model=TestModel()):\n    result = agent.run_sync('Hello')\n```\n\n#### Invalid model string\n\n```python\n# ERROR: Unknown provider\nagent = Agent('unknown:model')\n# ValueError: Unknown model provider\n```\n\n**Fix**: Use valid provider:model format.\n\n### Streaming Issues\n\n#### Wrong: Using result before stream completes\n\n```python\nasync with agent.run_stream('Hello') as response:\n    # DON'T access .output before streaming completes\n    print(response.output)  # May be incomplete!\n\n# Correct: access after context manager\nprint(response.output)  # Complete result\n```\n\n#### Wrong: Not iterating stream\n\n```python\nasync with agent.run_stream('Hello') as response:\n    pass  # Never consumed!\n\n# Stream was never read - output may be incomplete\n```\n\n**Fix**: Always consume the stream:\n```python\nasync with agent.run_stream('Hello') as response:\n    async for chunk in response.stream_output():\n        print(chunk, end='')\n```\n\n### Tool Return Issues\n\n#### Wrong: Returning non-serializable\n\n```python\n@agent.tool_plain\ndef bad_return() -> object:\n    return CustomObject()  # Can't serialize!\n```\n\n**Fix**: Return serializable types (str, dict, Pydantic model):\n```python\n@agent.tool_plain\ndef good_return() -> dict:\n    return {\"key\": \"value\"}\n```\n\n### Debugging Tips\n\n#### Enable tracing\n\n```python\nimport logfire\nlogfire.configure()\nlogfire.instrument_pydantic_ai()\n\n# Or per-agent\nagent = Agent('openai:gpt-4o', instrument=True)\n```\n\n#### Capture messages\n\n```python\nfrom pydantic_ai import capture_run_messages\n\nwith capture_run_messages() as messages:\n    result = agent.run_sync('Hello')\n\nfor msg in messages:\n    print(type(msg).__name__, msg)\n```\n\n#### Check model responses\n\n```python\nresult = agent.run_sync('Hello')\nprint(result.all_messages())  # Full message history\nprint(result.response)  # Last model response\nprint(result.usage())  # Token usage\n```\n\n### Common Error Messages\n\n| Error | Cause | Fix |\n|-------|-------|-----|\n| `First parameter... RunContext` | @agent.tool missing ctx | Add `ctx: RunContext[...]` |\n| `RunContext... only... context` | @agent.tool_plain has ctx | Remove ctx or use @agent.tool |\n| `Unknown model provider` | Invalid model string | Use valid `provider:model` |\n| `ModelAPIError` | API auth/quota | Check API key, limits |\n| `RetryPromptPart` in messages | Validation failed | Check output_type, increase retries |\n",
        ".cursor/commands/review-tui.md": "# TUI Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.go$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect BubbleTea (required for TUI review)\ngrep -r \"charmbracelet/bubbletea\" --include=\"*.go\" -l | head -3\n\n# Detect Lipgloss styling\ngrep -r \"charmbracelet/lipgloss\\|lipgloss\\.Style\" --include=\"*.go\" -l | head -3\n\n# Detect Bubbles components\ngrep -r \"charmbracelet/bubbles\\|list\\.Model\\|textinput\\.Model\\|viewport\\.Model\" --include=\"*.go\" -l | head -3\n\n# Detect Wish SSH server\ngrep -r \"charmbracelet/wish\\|ssh\\.Session\" --include=\"*.go\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '_test\\.go$'\n```\n\n## Step 3: Load Skills\n\n**Always load:**\n- `go-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| Test files changed | `go-testing-code-review` |\n| Wish SSH detected | `wish-ssh-code-review` |\n\n## Step 4: BubbleTea Review Guidelines\n\n### Model/Update/View (Elm Architecture)\n\n- [ ] Model is immutable (Update returns new model)\n- [ ] Init returns proper initial command\n- [ ] Update handles all message types\n- [ ] View is pure function (no side effects)\n- [ ] tea.Quit used correctly for exit\n\n### Lipgloss Styling\n\n- [ ] Styles defined once at package level\n- [ ] Styles not created in View function\n- [ ] Colors use AdaptiveColor for light/dark themes\n- [ ] Layout responds to WindowSizeMsg\n\n### Component Composition\n\n- [ ] Sub-component updates propagated\n- [ ] WindowSizeMsg passed to resizable components\n- [ ] Focus management for multiple components\n- [ ] Clear state machine for view transitions\n\n### SSH Server (if applicable)\n\n- [ ] Host keys persisted\n- [ ] Graceful shutdown implemented\n- [ ] PTY window size passed to TUI\n- [ ] Per-session Lipgloss renderer\n\n---\n\n## BubbleTea Code Review Knowledge Base\n\n### Critical Patterns\n\n#### 1. Model Must Be Immutable\n\n```go\n// BAD - mutates model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    m.items = append(m.items, newItem)  // mutation!\n    return m, nil\n}\n\n// GOOD - returns new model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    newItems := make([]Item, len(m.items)+1)\n    copy(newItems, m.items)\n    newItems[len(m.items)] = newItem\n    m.items = newItems\n    return m, nil\n}\n```\n\n#### 2. Commands for Async/IO\n\n```go\n// BAD - blocking in Update\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    data, _ := os.ReadFile(\"config.json\")  // blocks UI!\n    m.config = parse(data)\n    return m, nil\n}\n\n// GOOD - use commands\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    return m, loadConfigCmd()\n}\n\nfunc loadConfigCmd() tea.Cmd {\n    return func() tea.Msg {\n        data, err := os.ReadFile(\"config.json\")\n        if err != nil {\n            return errMsg{err}\n        }\n        return configLoadedMsg{parse(data)}\n    }\n}\n```\n\n#### 3. Styles Defined Once\n\n```go\n// BAD - creates new style each render\nfunc (m Model) View() string {\n    style := lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n    return style.Render(\"Hello\")\n}\n\n// GOOD - define styles at package level or in model\nvar titleStyle = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n\nfunc (m Model) View() string {\n    return titleStyle.Render(\"Hello\")\n}\n```\n\n### Model & Update Patterns\n\n#### Model Design\n\n```go\ntype Model struct {\n    // State\n    items    []Item\n    cursor   int\n    selected map[int]struct{}\n\n    // Dimensions (for responsive layout)\n    width  int\n    height int\n\n    // Sub-components\n    list     list.Model\n    viewport viewport.Model\n\n    // Error state\n    err error\n}\n\n// Verify interface implementation\nvar _ tea.Model = (*Model)(nil)\n```\n\n#### Init Returns Initial Command\n\n```go\n// BAD - blocking operation\nfunc (m Model) Init() tea.Cmd {\n    data := loadData()  // blocks!\n    return nil\n}\n\n// GOOD - async via command\nfunc (m Model) Init() tea.Cmd {\n    return tea.Batch(\n        loadDataCmd(),\n        tea.EnterAltScreen,\n    )\n}\n```\n\n#### Update Pattern: Switch on Message Type\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        return m.handleKey(msg)\n    case tea.WindowSizeMsg:\n        m.width = msg.Width\n        m.height = msg.Height\n        return m, nil\n    case dataLoadedMsg:\n        m.items = msg.items\n        return m, nil\n    case errMsg:\n        m.err = msg.err\n        return m, nil\n    }\n    return m, nil\n}\n```\n\n#### Always Handle WindowSizeMsg\n\n```go\n// BAD - ignores window size\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    // no WindowSizeMsg handling\n}\n\n// GOOD\ncase tea.WindowSizeMsg:\n    m.width = msg.Width\n    m.height = msg.Height\n    // Update sub-components\n    m.viewport.Width = msg.Width\n    m.viewport.Height = msg.Height - 4  // reserve for header/footer\n    return m, nil\n```\n\n#### Key Handling with key.Matches\n\n```go\n// BAD - string comparison\ncase tea.KeyMsg:\n    if msg.String() == \"q\" {\n        return m, tea.Quit\n    }\n\n// GOOD - use key bindings\ntype keyMap struct {\n    Quit key.Binding\n    Up   key.Binding\n    Down key.Binding\n}\n\nvar keys = keyMap{\n    Quit: key.NewBinding(\n        key.WithKeys(\"q\", \"ctrl+c\"),\n        key.WithHelp(\"q\", \"quit\"),\n    ),\n    Up: key.NewBinding(\n        key.WithKeys(\"up\", \"k\"),\n        key.WithHelp(\"/k\", \"up\"),\n    ),\n}\n\ncase tea.KeyMsg:\n    switch {\n    case key.Matches(msg, keys.Quit):\n        return m, tea.Quit\n    case key.Matches(msg, keys.Up):\n        m.cursor--\n    }\n```\n\n#### Sub-Component Updates\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmds []tea.Cmd\n\n    // Update sub-components\n    var cmd tea.Cmd\n    m.list, cmd = m.list.Update(msg)\n    cmds = append(cmds, cmd)\n\n    m.viewport, cmd = m.viewport.Update(msg)\n    cmds = append(cmds, cmd)\n\n    // Handle our own messages\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        // ...\n    }\n\n    return m, tea.Batch(cmds...)\n}\n```\n\n#### Commands Return Messages\n\n```go\n// Command that performs I/O\nfunc fetchItemsCmd(url string) tea.Cmd {\n    return func() tea.Msg {\n        resp, err := http.Get(url)\n        if err != nil {\n            return errMsg{err}\n        }\n        defer resp.Body.Close()\n\n        var items []Item\n        json.NewDecoder(resp.Body).Decode(&items)\n        return itemsFetchedMsg{items}\n    }\n}\n```\n\n#### Tick Commands for Animation\n\n```go\ntype tickMsg time.Time\n\nfunc tickCmd() tea.Cmd {\n    return tea.Tick(time.Millisecond*100, func(t time.Time) tea.Msg {\n        return tickMsg(t)\n    })\n}\n\ncase tickMsg:\n    m.frame++\n    return m, tickCmd()  // schedule next tick\n```\n\n#### Batch Multiple Commands\n\n```go\n// BAD - returns only last command\nfunc (m Model) Init() tea.Cmd {\n    loadConfig()\n    return loadData()  // loadConfig result lost!\n}\n\n// GOOD - batch them\nfunc (m Model) Init() tea.Cmd {\n    return tea.Batch(\n        loadConfigCmd(),\n        loadDataCmd(),\n        startSpinnerCmd(),\n    )\n}\n```\n\n### View & Styling Patterns\n\n#### View Must Be Pure\n\n```go\n// BAD - side effects\nfunc (m Model) View() string {\n    m.lastRender = time.Now()  // mutation!\n    log.Println(\"rendering\")    // I/O!\n    return \"...\"\n}\n\n// GOOD - pure function\nfunc (m Model) View() string {\n    if m.loading {\n        return m.spinner.View() + \" Loading...\"\n    }\n    return m.renderContent()\n}\n```\n\n#### Handle Loading/Error States\n\n```go\nfunc (m Model) View() string {\n    if m.err != nil {\n        return errorStyle.Render(fmt.Sprintf(\"Error: %v\", m.err))\n    }\n    if m.loading {\n        return m.spinner.View() + \" Loading...\"\n    }\n    return m.renderContent()\n}\n```\n\n#### Compose Views Cleanly\n\n```go\nfunc (m Model) View() string {\n    var b strings.Builder\n\n    b.WriteString(m.renderHeader())\n    b.WriteString(\"\\n\")\n    b.WriteString(m.renderContent())\n    b.WriteString(\"\\n\")\n    b.WriteString(m.renderFooter())\n\n    return b.String()\n}\n```\n\n#### Define Styles at Package Level\n\n```go\n// BAD - created every render\nfunc (m Model) View() string {\n    style := lipgloss.NewStyle().Bold(true)\n    return style.Render(\"Hello\")\n}\n\n// GOOD - defined once\nvar (\n    titleStyle = lipgloss.NewStyle().\n        Bold(true).\n        Foreground(lipgloss.Color(\"205\"))\n\n    itemStyle = lipgloss.NewStyle().\n        PaddingLeft(2)\n)\n\nfunc (m Model) View() string {\n    return titleStyle.Render(\"Hello\")\n}\n```\n\n#### Use Color Palette\n\n```go\n// Define a consistent color palette\nvar (\n    colorPrimary   = lipgloss.Color(\"205\")  // magenta\n    colorSecondary = lipgloss.Color(\"241\")  // gray\n    colorSuccess   = lipgloss.Color(\"78\")   // green\n    colorError     = lipgloss.Color(\"196\")  // red\n)\n\nvar (\n    titleStyle = lipgloss.NewStyle().Foreground(colorPrimary)\n    errorStyle = lipgloss.NewStyle().Foreground(colorError)\n)\n```\n\n#### Adaptive Colors for Themes\n\n```go\nvar (\n    // Adaptive colors work with light and dark terminals\n    subtle    = lipgloss.AdaptiveColor{Light: \"#D9DCCF\", Dark: \"#383838\"}\n    highlight = lipgloss.AdaptiveColor{Light: \"#874BFD\", Dark: \"#7D56F4\"}\n)\n\nvar titleStyle = lipgloss.NewStyle().\n    Foreground(highlight).\n    Background(subtle)\n```\n\n#### Responsive Width\n\n```go\nfunc (m Model) View() string {\n    // Adjust style based on window width\n    doc := lipgloss.NewStyle().\n        Width(m.width).\n        MaxWidth(m.width)\n\n    return doc.Render(m.content)\n}\n```\n\n#### Layout with Place and Join\n\n```go\nfunc (m Model) View() string {\n    // Horizontal join\n    row := lipgloss.JoinHorizontal(\n        lipgloss.Top,\n        leftPanel.Render(m.menu),\n        rightPanel.Render(m.content),\n    )\n\n    // Vertical join\n    return lipgloss.JoinVertical(\n        lipgloss.Left,\n        m.header(),\n        row,\n        m.footer(),\n    )\n}\n\n// Center content\nfunc (m Model) View() string {\n    return lipgloss.Place(\n        m.width, m.height,\n        lipgloss.Center, lipgloss.Center,\n        m.content,\n    )\n}\n```\n\n#### Borders and Padding\n\n```go\nvar boxStyle = lipgloss.NewStyle().\n    Border(lipgloss.RoundedBorder()).\n    BorderForeground(lipgloss.Color(\"63\")).\n    Padding(1, 2).\n    Margin(1)\n\nvar selectedStyle = lipgloss.NewStyle().\n    Border(lipgloss.DoubleBorder()).\n    BorderForeground(lipgloss.Color(\"205\"))\n```\n\n#### Selected Item Highlighting\n\n```go\nfunc (m Model) renderItems() string {\n    var b strings.Builder\n    for i, item := range m.items {\n        cursor := \"  \"\n        if i == m.cursor {\n            cursor = \" \"\n        }\n\n        style := itemStyle\n        if i == m.cursor {\n            style = selectedStyle\n        }\n\n        b.WriteString(style.Render(cursor + item.Title))\n        b.WriteString(\"\\n\")\n    }\n    return b.String()\n}\n```\n\n#### Help Footer\n\n```go\nfunc (m Model) helpView() string {\n    return helpStyle.Render(\"/: navigate  enter: select  q: quit\")\n}\n\n// Or use the help bubble\nimport \"github.com/charmbracelet/bubbles/help\"\n\nfunc (m Model) View() string {\n    return m.content + \"\\n\" + m.help.View(m.keys)\n}\n```\n\n#### Status Bar\n\n```go\nvar statusStyle = lipgloss.NewStyle().\n    Background(lipgloss.Color(\"235\")).\n    Foreground(lipgloss.Color(\"255\")).\n    Padding(0, 1)\n\nfunc (m Model) statusBar() string {\n    status := fmt.Sprintf(\"Items: %d | Selected: %d\", len(m.items), len(m.selected))\n    return statusStyle.Width(m.width).Render(status)\n}\n```\n\n### Component Composition Patterns\n\n#### Using Standard Bubbles\n\n```go\nimport (\n    \"github.com/charmbracelet/bubbles/list\"\n    \"github.com/charmbracelet/bubbles/textinput\"\n    \"github.com/charmbracelet/bubbles/viewport\"\n    \"github.com/charmbracelet/bubbles/spinner\"\n)\n\ntype Model struct {\n    list      list.Model\n    input     textinput.Model\n    viewport  viewport.Model\n    spinner   spinner.Model\n}\n```\n\n#### Initialize Sub-Components\n\n```go\nfunc NewModel() Model {\n    // List\n    items := []list.Item{...}\n    l := list.New(items, list.NewDefaultDelegate(), 0, 0)\n    l.Title = \"My List\"\n\n    // Text input\n    ti := textinput.New()\n    ti.Placeholder = \"Type here...\"\n    ti.Focus()\n\n    // Spinner\n    s := spinner.New()\n    s.Spinner = spinner.Dot\n\n    return Model{\n        list:    l,\n        input:   ti,\n        spinner: s,\n    }\n}\n```\n\n#### Update Sub-Components\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmds []tea.Cmd\n    var cmd tea.Cmd\n\n    // Always update active sub-components\n    switch m.state {\n    case stateList:\n        m.list, cmd = m.list.Update(msg)\n        cmds = append(cmds, cmd)\n    case stateInput:\n        m.input, cmd = m.input.Update(msg)\n        cmds = append(cmds, cmd)\n    }\n\n    // Handle window size for all components\n    if msg, ok := msg.(tea.WindowSizeMsg); ok {\n        m.list.SetSize(msg.Width, msg.Height-4)\n        m.viewport.Width = msg.Width\n        m.viewport.Height = msg.Height - 4\n    }\n\n    return m, tea.Batch(cmds...)\n}\n```\n\n#### Component Interface Pattern\n\n```go\n// Component interface for consistent sub-components\ntype Component interface {\n    Init() tea.Cmd\n    Update(tea.Msg) (Component, tea.Cmd)\n    View() string\n    SetSize(width, height int)\n}\n```\n\n#### Self-Contained Component\n\n```go\n// menu/menu.go\npackage menu\n\ntype Model struct {\n    items   []Item\n    cursor  int\n    width   int\n    height  int\n}\n\nfunc New(items []Item) Model {\n    return Model{items: items}\n}\n\nfunc (m Model) Init() tea.Cmd {\n    return nil\n}\n\nfunc (m Model) Update(msg tea.Msg) (Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        switch msg.String() {\n        case \"up\", \"k\":\n            if m.cursor > 0 {\n                m.cursor--\n            }\n        case \"down\", \"j\":\n            if m.cursor < len(m.items)-1 {\n                m.cursor++\n            }\n        }\n    }\n    return m, nil\n}\n\nfunc (m Model) View() string {\n    var b strings.Builder\n    for i, item := range m.items {\n        cursor := \"  \"\n        if i == m.cursor {\n            cursor = \"> \"\n        }\n        b.WriteString(cursor + item.Title + \"\\n\")\n    }\n    return b.String()\n}\n\nfunc (m *Model) SetSize(w, h int) {\n    m.width = w\n    m.height = h\n}\n\nfunc (m Model) Selected() Item {\n    return m.items[m.cursor]\n}\n```\n\n#### State Machine Pattern\n\n```go\ntype viewState int\n\nconst (\n    viewLoading viewState = iota\n    viewList\n    viewDetail\n    viewEdit\n)\n\ntype Model struct {\n    state viewState\n    // sub-components for each state\n    list   list.Model\n    detail detailModel\n    edit   editModel\n}\n```\n\n#### State Transitions\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    // Global key handling\n    if key, ok := msg.(tea.KeyMsg); ok {\n        switch key.String() {\n        case \"esc\":\n            // Go back based on current state\n            switch m.state {\n            case viewDetail:\n                m.state = viewList\n                return m, nil\n            case viewEdit:\n                m.state = viewDetail\n                return m, nil\n            }\n        }\n    }\n\n    // Delegate to current state's component\n    var cmd tea.Cmd\n    switch m.state {\n    case viewList:\n        m.list, cmd = m.list.Update(msg)\n        // Check for selection\n        if key, ok := msg.(tea.KeyMsg); ok && key.String() == \"enter\" {\n            m.state = viewDetail\n            m.detail = newDetailModel(m.list.SelectedItem())\n        }\n    case viewDetail:\n        m.detail, cmd = m.detail.Update(msg)\n    case viewEdit:\n        m.edit, cmd = m.edit.Update(msg)\n    }\n\n    return m, cmd\n}\n```\n\n#### View Routing\n\n```go\nfunc (m Model) View() string {\n    switch m.state {\n    case viewLoading:\n        return m.spinner.View() + \" Loading...\"\n    case viewList:\n        return m.list.View()\n    case viewDetail:\n        return m.detail.View()\n    case viewEdit:\n        return m.edit.View()\n    default:\n        return \"Unknown state\"\n    }\n}\n```\n\n#### Focus Management\n\n```go\ntype focusState int\n\nconst (\n    focusList focusState = iota\n    focusInput\n    focusButtons\n)\n\ntype Model struct {\n    focus focusState\n    list  list.Model\n    input textinput.Model\n}\n\nfunc (m *Model) nextFocus() {\n    m.focus = (m.focus + 1) % 3\n    m.updateFocus()\n}\n\nfunc (m *Model) updateFocus() {\n    switch m.focus {\n    case focusInput:\n        m.input.Focus()\n    default:\n        m.input.Blur()\n    }\n}\n```\n\n#### Tab Navigation\n\n```go\ncase tea.KeyMsg:\n    switch key.String() {\n    case \"tab\":\n        m.nextFocus()\n        return m, nil\n    case \"shift+tab\":\n        m.prevFocus()\n        return m, nil\n    }\n\n    // Only handle keys for focused component\n    switch m.focus {\n    case focusList:\n        m.list, cmd = m.list.Update(msg)\n    case focusInput:\n        m.input, cmd = m.input.Update(msg)\n    }\n```\n\n### Anti-Patterns to Avoid\n\n#### 1. Side Effects in View\n\n```go\n// BAD\nfunc (m Model) View() string {\n    log.Printf(\"rendering\")  // side effect!\n    m.renderCount++          // mutation!\n    return \"...\"\n}\n\n// GOOD - View is pure\nfunc (m Model) View() string {\n    return \"...\"\n}\n```\n\n#### 2. Blocking in Update\n\n```go\n// BAD\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    time.Sleep(2 * time.Second)  // freezes UI!\n    return m, nil\n}\n\n// GOOD - use commands for delays\nreturn m, tea.Tick(2*time.Second, func(t time.Time) tea.Msg {\n    return delayCompleteMsg{}\n})\n```\n\n#### 3. ANSI Codes Instead of Lipgloss\n\n```go\n// BAD - raw ANSI\nfunc (m Model) View() string {\n    return \"\\033[1;31mError\\033[0m\"\n}\n\n// GOOD - Lipgloss\nvar errorStyle = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"196\"))\nfunc (m Model) View() string {\n    return errorStyle.Render(\"Error\")\n}\n```\n\n#### 4. Hardcoded Dimensions\n\n```go\n// BAD - ignores terminal size\nvar boxStyle = lipgloss.NewStyle().Width(80)\n\n// GOOD - responsive\nfunc (m Model) renderBox() string {\n    return boxStyle.Width(m.width - 4).Render(m.content)\n}\n```\n\n#### 5. Not Propagating Updates\n\n```go\n// BAD - sub-component never updates\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        // only handles own keys, ignores sub-component\n    }\n    return m, nil\n}\n\n// GOOD - always update sub-components\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmd tea.Cmd\n    m.list, cmd = m.list.Update(msg)  // always propagate\n    return m, cmd\n}\n```\n\n#### 6. Nested Component Access\n\n```go\n// BAD - reaches into component internals\nfunc (m Model) View() string {\n    return m.list.items[m.list.cursor].Title  // breaks encapsulation\n}\n\n// GOOD - use component methods\nfunc (m Model) View() string {\n    return m.list.SelectedItem().(Item).Title\n}\n```\n\n---\n\n## Step 5: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review Go code quality\n3. Review BubbleTea patterns (Model/Update/View)\n4. Review Lipgloss styling\n5. Review component composition\n6. Review SSH server (if applicable)\n7. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn subagents for: Go quality, BubbleTea, SSH\n3. Wait for all agents\n4. Consolidate findings\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (UI freeze, crash, resource leak)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\ngo build ./...\ngo vet ./...\ngolangci-lint run\ngo test -v -race ./...\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Pay special attention to:\n  - Blocking operations in Update (freezes UI)\n  - Style creation in View (performance)\n  - Missing WindowSizeMsg handling (broken resize)\n- Run verification after fixes\n",
        ".cursor/commands/skill-builder.md": "# Skill Builder\n\nCreate, validate, and refine Claude Code skills following official best practices.\n\n## Workflow Overview\n\n```\n1. Gather Requirements  2. Design Structure  3. Write SKILL.md  4. Add Supporting Files  5. Validate  6. Test\n```\n\n## Instructions\n\n### Phase 1: Gather Requirements\n\nBefore writing any skill, collect this information from the user:\n\n**Required:**\n- What capability should the skill provide?\n- When should Claude invoke this skill (triggers)?\n- What domain knowledge is needed that Claude doesn't have?\n\n**Optional:**\n- Are there utility scripts needed?\n- Should tool access be restricted (`allowed-tools`)?\n- What files/references should be included?\n\nAsk clarifying questions if the scope is unclear. Skills should be focused on one capability.\n\n### Phase 2: Design the Structure\n\nDetermine the skill complexity:\n\n**Simple Skill (single file):**\n```\nskill-name/\n SKILL.md\n```\n\nUse when: Single capability, no scripts, under 200 lines of content.\n\n**Multi-file Skill (progressive disclosure):**\n```\nskill-name/\n SKILL.md           # Overview + navigation (under 500 lines)\n reference.md       # Detailed API/schema info\n examples.md        # Extended examples\n scripts/           # Utility scripts\n     helper.py\n     validate.py\n```\n\nUse when: Complex domain, multiple sub-capabilities, utility scripts needed.\n\n### Phase 3: Write SKILL.md\n\n#### Frontmatter Requirements\n\n```yaml\n---\nname: skill-name-here\ndescription: What it does and when to use it. Include trigger keywords.\nallowed-tools: Read, Grep, Glob  # Optional: restrict tool access\n---\n```\n\n**Name rules:**\n- Lowercase letters, numbers, hyphens only\n- Maximum 64 characters\n- Use gerund form preferred: `processing-pdfs`, `generating-commits`\n- No reserved words: \"anthropic\", \"claude\"\n\n**Description rules:**\n- Maximum 1024 characters\n- Write in third person: \"Processes X\" not \"I can process X\"\n- Include BOTH what it does AND when to use it\n- Include trigger keywords users would naturally say\n\n**Description pattern:**\n```\n<what it does>. <trigger conditions>.\n```\n\n**Good examples:**\n```yaml\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n\ndescription: Analyze Excel spreadsheets, create pivot tables, generate charts. Use when analyzing Excel files, spreadsheets, tabular data, or .xlsx files.\n\ndescription: Generate descriptive commit messages by analyzing git diffs. Use when the user asks for help writing commit messages or reviewing staged changes.\n```\n\n**Bad examples:**\n```yaml\ndescription: Helps with documents  # Too vague\ndescription: I can process data    # Wrong person, too vague\ndescription: Does stuff with files # Useless\n```\n\n#### Body Structure\n\nUse this template:\n\n```markdown\n# Skill Name\n\n## Quick Start\n\n<Minimal working example - 3-5 lines max>\n\n## Instructions\n\n<Step-by-step guidance - be specific about WHAT to do>\n\n## Workflows\n\n<For complex tasks, provide checklists Claude can track>\n\n## Examples\n\n<Input/output pairs showing desired style and output>\n\n## Advanced\n\n<Link to additional files if needed>\nFor detailed reference, see [reference.md](reference.md).\n```\n\n### Phase 4: Apply Best Practices\n\n#### Conciseness Principle\n\n**Default assumption:** Claude is already very smart.\n\nOnly add context Claude doesn't have. Challenge each piece of information:\n- \"Does Claude really need this explanation?\"\n- \"Can I assume Claude knows this?\"\n- \"Does this paragraph justify its token cost?\"\n\n**Bad (verbose):**\n```markdown\nPDF (Portable Document Format) files are a common file format that contains\ntext, images, and other content. To extract text from a PDF, you'll need to\nuse a library. There are many libraries available...\n```\n\n**Good (concise):**\n```markdown\nUse pdfplumber for text extraction:\n\\`\\`\\`python\nimport pdfplumber\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n\\`\\`\\`\n```\n\n#### Degrees of Freedom\n\nMatch specificity to task fragility:\n\n**High freedom** (text-based instructions) - when multiple approaches are valid:\n```markdown\n## Code review process\n1. Analyze the code structure and organization\n2. Check for potential bugs or edge cases\n3. Suggest improvements for readability\n```\n\n**Low freedom** (exact commands) - when operations are fragile:\n```markdown\n## Database migration\nRun exactly this script:\n\\`\\`\\`bash\npython scripts/migrate.py --verify --backup\n\\`\\`\\`\nDo not modify the command or add additional flags.\n```\n\n#### Feedback Loops\n\nFor quality-critical tasks, add validation steps:\n\n```markdown\n## Editing Process\n1. Make your edits\n2. **Validate immediately**: `python scripts/validate.py`\n3. If validation fails:\n   - Review the error message\n   - Fix the issues\n   - Run validation again\n4. **Only proceed when validation passes**\n```\n\n#### Checklists for Complex Workflows\n\nProvide copyable checklists:\n\n````markdown\n## Form Filling Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Analyze the form\n- [ ] Step 2: Create field mapping\n- [ ] Step 3: Validate mapping\n- [ ] Step 4: Fill the form\n- [ ] Step 5: Verify output\n```\n````\n\n#### Examples Pattern\n\nShow input/output pairs for style guidance:\n\n````markdown\n## Commit Message Format\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n````\n\n#### Progressive Disclosure\n\nReference additional files instead of including everything:\n\n```markdown\n## Advanced Features\n\n**Form filling**: See [FORMS.md](FORMS.md) for complete guide\n**API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n**Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\n**Critical:** Keep references one level deep from SKILL.md. Don't create chains of references.\n\n### Phase 5: Validation Checklist\n\nBefore finalizing, verify:\n\n**Core Quality:**\n- [ ] Description is specific and includes trigger keywords\n- [ ] Description includes both what it does AND when to use it\n- [ ] Description is written in third person\n- [ ] Name uses lowercase-hyphen format\n- [ ] SKILL.md body is under 500 lines\n- [ ] No time-sensitive information\n- [ ] Consistent terminology throughout\n- [ ] Examples are concrete, not abstract\n- [ ] File references are one level deep\n- [ ] Workflows have clear steps\n\n**Technical:**\n- [ ] Valid YAML frontmatter (no tabs, correct syntax)\n- [ ] No Windows-style paths (use forward slashes)\n- [ ] Required packages listed if applicable\n- [ ] Scripts have explicit error handling\n\n**If using `allowed-tools`:**\n- [ ] Only necessary tools are listed\n- [ ] Tool names are correct (Read, Grep, Glob, Edit, Write, Bash, etc.)\n\n### Phase 6: Test the Skill\n\nAfter creating the skill:\n\n1. **Place in correct location:**\n   - Personal: `~/.claude/skills/skill-name/SKILL.md`\n   - Project: `.claude/skills/skill-name/SKILL.md`\n\n2. **Restart Claude Code** to load the skill\n\n3. **Test with natural language** that matches your description triggers:\n   ```\n   User: \"Help me extract text from this PDF\"\n    Should invoke skill with \"PDF\" trigger\n   ```\n\n4. **Verify Claude navigates correctly** to reference files when needed\n\n5. **Iterate based on observation:**\n   - Does Claude find the right information?\n   - Does Claude apply rules correctly?\n   - Are there missing examples or edge cases?\n\n## Anti-Patterns to Avoid\n\n**DON'T:**\n- Use Windows-style paths (`scripts\\helper.py`)\n- Offer too many options without a default\n- Include time-sensitive information\n- Use inconsistent terminology\n- Create deeply nested file references\n- Assume tools are installed without documenting\n- Write overly verbose explanations Claude already knows\n- Use first or second person in descriptions\n\n**DO:**\n- Provide a single recommended approach with alternatives noted\n- Use consistent terminology throughout\n- Structure longer files with table of contents\n- Document package requirements explicitly\n- Trust Claude's existing knowledge\n- Write descriptions that help Claude select the right skill\n\n## Template: Simple Skill\n\n```yaml\n---\nname: your-skill-name\ndescription: <What it does>. Use when <trigger conditions>.\n---\n\n# Your Skill Name\n\n## Quick Start\n\n<Minimal example - get user productive immediately>\n\n## Instructions\n\n<Clear, numbered steps for common use cases>\n\n## Examples\n\n<2-3 input/output examples showing desired style>\n```\n\n## Template: Multi-File Skill\n\n**SKILL.md:**\n```yaml\n---\nname: your-skill-name\ndescription: <What it does>. Use when <trigger conditions>.\n---\n\n# Your Skill Name\n\n## Quick Start\n\n<Minimal example>\n\n## Common Tasks\n\n### Task A\n<Brief instructions>\n\n### Task B\n<Brief instructions>\n\n## Advanced\n\n- **Full reference**: See [reference.md](reference.md)\n- **Examples**: See [examples.md](examples.md)\n- **Utility scripts**: See [scripts/](scripts/)\n```\n\n**reference.md:**\n```markdown\n# Reference\n\n## Contents\n- Section A\n- Section B\n- Section C\n\n## Section A\n<Detailed content>\n...\n```\n\n## Example Output\n\nAfter gathering requirements for a \"code-review\" skill:\n\n```\nCreated skill: .claude/skills/reviewing-code/\n\nFiles:\n SKILL.md (245 lines) - Core instructions and checklists\n security-patterns.md - Common security issues to check\n examples.md - Example review outputs\n\nDescription: \"Reviews code changes for production readiness, checking code quality, architecture, testing, and security. Use when reviewing PRs, checking code before merge, or auditing code quality.\"\n\nNext steps:\n1. Review the generated files\n2. Restart Claude Code to load the skill\n3. Test with: \"Review the changes in my current branch\"\n```\n\n## Guidelines\n\n**When the user asks for a skill:**\n1. Ask clarifying questions about scope and triggers\n2. Propose the structure (simple vs multi-file)\n3. Write the SKILL.md following all patterns above\n4. Run through the validation checklist\n5. Explain how to test the skill\n\n**Iterative refinement:**\nIf the user reports the skill isn't working:\n1. Check if description triggers match user's natural language\n2. Verify YAML syntax is valid\n3. Ensure file paths are correct\n4. Review if instructions are clear enough for the task\n",
        "README.md": "# beagle\n\n![Apollo 10 astronaut Thomas P. Stafford pats the nose of a stuffed Snoopy](assets/Stafford_and_Snoopy.jpg)\n\n*Image: NASA, Public Domain. [Source](https://www.nasa.gov/multimedia/imagegallery/image_feature_572.html)*\n\nA Claude Code plugin for code review and verification workflows. Catch issues before you push with pre-commit reviews for Python, Go, React, iOS/Swift, and AI frameworks.\n\nPowers the agents in [Amelia](https://github.com/existential-birds/amelia).\n\n## Installation\n\n**Prerequisites:**\n- [Claude Code](https://claude.ai/code) CLI installed\n- [agent-browser](https://github.com/vercel-labs/agent-browser) for `run-test-plan` command (optional)\n\n```bash\nclaude plugin marketplace add https://github.com/existential-birds/beagle\nclaude plugin install beagle\n```\n\nVerify installation by running `/beagle:` in Claude Codeyou should see the command list.\n\nTo update: `claude plugin update beagle`\n\n**Troubleshooting:**\n- \"Marketplace file not found\": Remove stale entries from `~/.claude/plugins/known_marketplaces.json` and restart Claude Code.\n- Plugin not updating: Run `claude plugin marketplace update beagle` to refresh the marketplace, then `claude plugin update beagle`.\n\n### Other Agents\n\nUse the [skills CLI](https://skills.sh/docs/cli) to install beagle skills for other AI agents:\n\n```bash\nnpx skills add existential-birds/beagle\n```\n\nThis downloads the skills and configures them for your agent. Commands (`/beagle:*`) are Claude Code specific and not available through the skills CLI.\n\n## Skills\n\nAuto-loaded by Claude when relevant. See [Agent Skills](https://docs.claude.com/en/docs/agents-and-tools/agent-skills/overview).\n\n| Category | Skills |\n|----------|--------|\n| **Frontend** | react-flow-\\*, react-router-\\*, tailwind-v4, shadcn-\\*, zustand-state, dagre-react-flow, vitest-testing, ai-elements |\n| **Backend (Python)** | python-code-review, fastapi-code-review, sqlalchemy-code-review, postgres-code-review, pytest-code-review, docling, sqlite-vec |\n| **Backend (Go)** | go-code-review, go-testing-code-review, bubbletea-code-review, wish-ssh-code-review, prometheus-go-code-review |\n| **iOS/Swift** | swift-code-review, swiftui-code-review, swiftdata-code-review, combine-code-review, urlsession-code-review, healthkit-code-review, cloudkit-code-review, watchos-code-review, widgetkit-code-review, app-intents-code-review, swift-testing-code-review |\n| **AI Frameworks** | pydantic-ai-\\* (6), langgraph-\\* (3), vercel-ai-sdk, deepagents-\\* (3) |\n| **Documentation** | docs-style, tutorial-docs, howto-docs, reference-docs, explanation-docs |\n| **Workflow** | receive-feedback, review-feedback-schema, review-skill-improver, llm-artifacts-detection |\n| **Architecture** | 12-factor-apps, agent-architecture-analysis, adr-\\*, github-projects |\n\n## Commands\n\nRun with `/beagle:<command>`. See [Slash commands](https://docs.claude.com/en/docs/claude-code/slash-commands).\n\n| Command | Description |\n|---------|-------------|\n| `review-python` | Python/FastAPI code review |\n| `review-frontend` | React/TypeScript code review |\n| `review-go` | Go code review |\n| `review-tui` | BubbleTea TUI code review |\n| `review-ios` | iOS/SwiftUI code review |\n| `review-plan <path>` | Review implementation plans |\n| `review-llm-artifacts` | Detect LLM coding artifacts |\n| `fix-llm-artifacts` | Fix detected artifacts |\n| `gen-test-plan` | Generate YAML test plan from branch changes |\n| `run-test-plan` | Execute test plan, stop on first failure |\n| `commit-push` | Commit and push changes |\n| `create-pr` | Create PR with template |\n| `gen-release-notes <tag>` | Generate release notes |\n| `write-adr` | Generate ADRs from decisions |\n| `draft-docs <prompt>` | Generate documentation drafts |\n| `improve-doc <path>` | Improve docs using Ditaxis |\n| `12-factor-apps-analysis` | 12-Factor compliance check |\n| `receive-feedback <path>` | Process review feedback |\n| `fetch-pr-feedback` | Fetch bot comments from PR |\n| `respond-pr-feedback` | Reply to bot comments |\n| `ensure-docs` | Documentation coverage check |\n| `skill-builder` | Create new skills |\n| `prompt-improver` | Optimize prompts |\n\n",
        "commands/12-factor-apps-analysis.md": "---\ndescription: perform 12-Factor App compliance analysis on a codebase\n---\n# 12-Factor App Compliance Analysis\n\nYou are performing a comprehensive compliance analysis against the [12-Factor App](https://12factor.net) methodology for building SaaS applications.\n\n**Use the `12-factor-apps` skill to guide this analysis.**\n\n## Target Codebase\n\n**Path:** $ARGUMENTS (default: current working directory)\n\n## Analysis Scope\n\nEvaluate all 12 factors:\n\n1. **Codebase** - One codebase tracked in revision control, many deploys\n2. **Dependencies** - Explicitly declare and isolate dependencies\n3. **Config** - Store config in the environment\n4. **Backing Services** - Treat backing services as attached resources\n5. **Build, Release, Run** - Strictly separate build and run stages\n6. **Processes** - Execute the app as one or more stateless processes\n7. **Port Binding** - Export services via port binding\n8. **Concurrency** - Scale out via the process model\n9. **Disposability** - Maximize robustness with fast startup and graceful shutdown\n10. **Dev/Prod Parity** - Keep development, staging, and production as similar as possible\n11. **Logs** - Treat logs as event streams\n12. **Admin Processes** - Run admin/management tasks as one-off processes\n\n## Workflow\n\n1. **Use the skill** - Read the `12-factor-apps` skill for search patterns\n2. **Run searches** - Use grep patterns from the skill for each factor\n3. **Evaluate compliance** - Strong/Partial/Weak per factor\n4. **Document evidence** - File:line references for findings\n5. **Identify gaps** - What's missing vs. 12-Factor ideal\n6. **Provide recommendations** - Actionable improvements\n\n## Output Format\n\n### Executive Summary\n\n| Factor | Status | Key Finding |\n|--------|--------|-------------|\n| I. Codebase | Strong/Partial/Weak | [Summary] |\n| II. Dependencies | Strong/Partial/Weak | [Summary] |\n| ... | ... | ... |\n\n**Overall:** X Strong, Y Partial, Z Weak\n\n### Detailed Findings\n\nFor each factor with gaps:\n- **Current State:** What exists\n- **Evidence:** File:line references\n- **Gap:** What's missing\n- **Recommendation:** How to improve\n\n### Priority Recommendations\n\n1. **High Priority** - Critical gaps affecting scalability/reliability\n2. **Medium Priority** - Improvements for better compliance\n3. **Low Priority** - Nice-to-have optimizations\n\n## Rules\n\n- Use the skill's search patterns systematically\n- Provide file:line evidence for all findings\n- Be honest about compliance levels (don't inflate)\n- Focus on actionable recommendations\n- Reference the official 12-Factor App methodology\n",
        "commands/commit-push.md": "---\ndescription: commit and push all local changes to remote repo\n---\n\n# Commit and Push\n\nCommit all local changes following Conventional Commits format and push to remote.\n\n## Step 1: Gather Context\n\nRun these commands in parallel to understand the changes:\n\n```bash\n# See all untracked and modified files\ngit status\n\n# See staged and unstaged changes\ngit diff\ngit diff --cached\n\n# See recent commit messages for style reference\ngit log --oneline -10\n```\n\n## Step 2: Analyze Changes\n\nReview the changes and determine:\n- **Type**: What kind of change is this?\n  - `feat` - New feature or capability\n  - `fix` - Bug fix\n  - `docs` - Documentation only\n  - `refactor` - Code restructure without behavior change\n  - `test` - Adding or updating tests\n  - `chore` - Maintenance, dependency updates\n  - `perf` - Performance improvement\n  - `ci` - CI/CD changes\n\n- **Scope**: Which component is affected?\n  - Examine the changed files and determine the appropriate scope\n  - Use consistent scope names within the project (check `git log` for patterns)\n  - *(omit scope for cross-cutting changes)*\n\n- **Breaking**: Does this break backward compatibility? If yes, add **!** after scope.\n\n## Step 3: Write Commit Message\n\nFormat:\n```\ntype(scope): description\n\n[optional body explaining why, not what]\n\n[optional footer with issue references]\n```\n\nRules:\n- Use imperative mood: \"add feature\" not \"added feature\"\n- Keep first line under 72 characters\n- Focus on *why* in the body, the diff shows *what*\n- Reference issues: `Closes #123` or `Fixes #456`\n\n## Step 4: Stage, Commit, and Push\n\n```bash\n# Stage all changes (or selectively stage)\ngit add -A\n\n# Commit with message (use HEREDOC for multi-line)\ngit commit -m \"$(cat <<'EOF'\ntype(scope): description\n\nOptional body explaining the motivation.\n\nCloses #123\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n\n# Push to remote\ngit push\n```\n\n## Examples\n\n```bash\n# Simple feature\ngit commit -m \"feat(api): add pagination support to list endpoints\"\n\n# Bug fix with body\ngit commit -m \"$(cat <<'EOF'\nfix(auth): handle token expiration during long requests\n\nThe previous implementation did not account for tokens expiring\nduring the processing of long-running requests.\n\nFixes #42\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n\n# Breaking change\ngit commit -m \"$(cat <<'EOF'\nfeat!(api): change response format for user endpoints\n\nBREAKING CHANGE: The `status` field is now an object with `state` and\n`message` properties instead of a plain string.\n\nGenerated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n```\n\n## Step 5: Verify\n\nAfter pushing, run `git status` to confirm the working tree is clean and the branch is up to date with remote.\n",
        "commands/create-pr.md": "---\ndescription: create a pull request with standardized description template\n---\n\n# Create Pull Request\n\nCreate a pull request with a well-structured description based on the branch changes.\n\n## Instructions\n\n### 1. Gather Context\n\nFirst, collect information about the changes:\n\n```bash\n# Get current branch and verify it's not main\ngit branch --show-current\n\n# Get commit history for this branch\ngit log --oneline main..HEAD\n\n# Get detailed commit messages for context\ngit log --format=\"### %s%n%n%b\" main..HEAD\n\n# Get file change statistics\ngit diff --stat main..HEAD\n\n# Get the actual diff for understanding changes\ngit diff main..HEAD\n```\n\n### 2. Analyze the Changes\n\nBased on the gathered information, determine:\n\n- **What changed**: Categorize changes (features, fixes, refactors, docs, tests)\n- **Why it changed**: Infer motivation from commit messages and code changes\n- **Impact**: Breaking changes, new dependencies, migrations needed\n- **Testing**: What tests were added/modified, how to verify manually\n\n### 3. Check for Related Issues\n\nLook for issue references:\n- In commit messages (e.g., \"fixes #123\", \"closes #456\")\n- In branch name (e.g., `fix/issue-123-description`)\n- In code comments or TODOs addressed\n\n### 4. Generate PR Description\n\nCreate the PR using this template structure:\n\n```bash\ngh pr create --title \"<type>(<scope>): <description>\" --body \"$(cat <<'EOF'\n## Summary\n\n<1-3 sentence overview of what this PR does and why>\n\n## Changes\n\n<Categorized bullet list of changes>\n\n### Added\n- <new features or capabilities>\n\n### Changed\n- <modifications to existing functionality>\n\n### Fixed\n- <bug fixes>\n\n### Removed\n- <deprecated or removed functionality>\n\n## Motivation\n\n<Why were these changes needed? What problem does this solve?>\n\n## Testing\n\n<How was this tested?>\n\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing performed\n\n### Manual Testing Steps\n\n<If applicable, steps to manually verify the changes>\n\n## Breaking Changes\n\n<If any, describe what breaks and migration path. Remove section if none.>\n\n## Related Issues\n\n<Link to related issues. Remove section if none.>\n\n- Closes #<issue_number>\n- Related to #<issue_number>\n\n## Checklist\n\n- [ ] Code follows project style guidelines\n- [ ] Self-review completed\n- [ ] Tests pass locally\n- [ ] Linting passes\n- [ ] Documentation updated (if needed)\n\n---\n\nGenerated with [Claude Code](https://claude.com/claude-code)\nEOF\n)\"\n```\n\n### 5. Title Format\n\nUse conventional commit format for the PR title:\n- `feat(scope): add new feature`\n- `fix(scope): correct bug behavior`\n- `refactor(scope): restructure without behavior change`\n- `docs(scope): update documentation`\n- `test(scope): add or modify tests`\n- `chore(scope): maintenance tasks`\n\n### 6. Apply Labels\n\nAfter creating the PR, apply appropriate labels based on the changes. Use `gh pr edit <number> --add-label <label>`.\n\nCheck the repository's available labels first:\n```bash\ngh label list\n```\n\n#### Common Type Labels\n\n| Label | When to Use |\n|-------|-------------|\n| `enhancement` | New features, capabilities, or improvements |\n| `bug` | Bug fixes |\n| `documentation` | Documentation-only changes |\n| `breaking-change` | **User-facing** breaking changes requiring migration |\n\n#### Breaking Change Criteria\n\nOnly apply `breaking-change` for **user-facing** changes that require users to modify their:\n- Configuration files\n- CLI invocations\n- API integrations\n\nDo NOT apply for internal refactors unless they affect external consumers.\n\n### 7. After Creation\n\nAfter creating the PR:\n1. Display the PR URL with applied labels\n2. Suggest adding reviewers if appropriate\n3. Note if any CI checks need to pass\n\n## Guidelines\n\n**DO:**\n- Be specific about what changed and why\n- Include testing evidence\n- Link related issues\n- Note breaking changes prominently\n- Remove empty optional sections\n\n**DON'T:**\n- Include irrelevant commits (keep PR focused)\n- Leave placeholder text in the description\n- Skip the testing section\n- Create PRs without running local checks first\n",
        "commands/draft-docs.md": "---\ndescription: Generate first-draft technical documentation from code analysis\n---\n\n# Draft Docs\n\nGenerate Reference or How-To documentation drafts to `docs/drafts/` for review before publishing.\n\n## Arguments\n\n- **Topic prompt:** Description of what to document (e.g., \"Document the WebSocket API\")\n- **--publish [file]:** Move reviewed draft to final location and update navigation\n\n## Mode 1: Generate Draft\n\n```\n/beagle:draft-docs \"Document the authentication middleware\"\n```\n\n### Step 0: Gather Context\n\nBefore parsing input, gather project context:\n\n```bash\n# Check for existing docs structure\nls -la docs/ 2>/dev/null || echo \"No docs/ directory found\"\n\n# Identify documentation framework\nls docs/navigation.json docs/mint.json docs/docusaurus.config.js docs/mkdocs.yml 2>/dev/null | head -1\n\n# Check for existing drafts\nls docs/drafts/*.md 2>/dev/null || echo \"No existing drafts\"\n\n# Get recent code changes for context\ngit diff --name-only $(git merge-base HEAD main)..HEAD 2>/dev/null | head -20\n```\n\n**Capture:**\n- Docs structure: `docs/` subdirectories present\n- Navigation system: `navigation.json`, `mint.json`, or other config\n- Tech stack hints: from file extensions and imports in changed files\n- Existing drafts: to avoid duplicates\n\n### Step 1: Parse Input\n\nExtract from the prompt:\n\n1. **Topic:** What to document (e.g., \"authentication middleware\")\n2. **Content type:** Detect from keywords:\n\n| Keywords | Type | Skill |\n|----------|------|-------|\n| \"how to\", \"guide\", \"steps\", \"configure\", \"set up\" | How-To | `howto-docs` |\n| \"API\", \"reference\", \"parameters\", \"function\", \"endpoint\" | Reference | `reference-docs` |\n\nIf ambiguous, ask: \"Should this be a Reference doc (technical lookup) or How-To guide (task completion)?\"\n\n### Step 2: Load Skills\n\nAlways load both:\n\n1. `beagle:docs-style` - Core writing principles\n2. Detected type skill:\n   - `beagle:reference-docs` for Reference\n   - `beagle:howto-docs` for How-To\n\n### Step 3: Analyze Code\n\nSearch the codebase for relevant code:\n\n1. **Symbol search:** Find functions, classes, types matching the topic\n2. **File search:** Locate related files by name patterns\n3. **Reference search:** Find usage examples\n\nGather:\n- Function/method signatures\n- Type definitions\n- Existing comments/docstrings\n- Usage patterns in tests or examples\n\n### Step 4: Generate Draft\n\nApply the loaded skills to generate documentation:\n\n**For Reference docs:**\n- Follow `reference-docs` template structure\n- Document all parameters with types\n- Include complete, runnable examples from actual code\n- Add Related section linking to connected symbols\n\n**For How-To docs:**\n- Follow `howto-docs` template structure\n- Start title with \"How to\"\n- List concrete prerequisites\n- Break into single-action steps\n- Include verification section\n\n### Step 5: Write Draft\n\n1. **Create output path:**\n   - `docs/drafts/{slug}.md`\n   - Slug from topic: \"WebSocket API\"  `websocket-api.md`\n\n2. **Ensure directory exists:**\n   ```bash\n   mkdir -p docs/drafts\n   ```\n\n3. **Write the draft file**\n\n4. **Report to user:**\n   ```markdown\n   ## Draft Created\n\n   **File:** `docs/drafts/{slug}.md`\n   **Type:** Reference | How-To\n   **Based on:** [list of analyzed symbols/files]\n\n   ### Next Steps\n\n   1. Review the draft for accuracy\n   2. Add any missing context or examples\n   3. When ready, publish with:\n      ```\n      /beagle:draft-docs --publish docs/drafts/{slug}.md\n      ```\n   ```\n\n### Step 6: End-of-Run Verification\n\nVerify draft generation completed successfully:\n\n```bash\n# Confirm draft file exists\nls -la docs/drafts/{slug}.md\n\n# Validate frontmatter (YAML header)\nhead -10 docs/drafts/{slug}.md | grep -E \"^---$|^title:|^description:\"\n\n# Check markdown syntax (if markdownlint available)\nmarkdownlint docs/drafts/{slug}.md 2>/dev/null || echo \"markdownlint not available\"\n```\n\n**Verification Checklist:**\n- [ ] Draft file created at `docs/drafts/{slug}.md`\n- [ ] Frontmatter includes `title` and `description`\n- [ ] Content type matches detected type (Reference or How-To)\n- [ ] Code examples are complete and runnable\n- [ ] All analyzed symbols referenced in draft\n\nIf any verification fails, report the specific issue and offer to regenerate.\n\n## Mode 2: Publish Draft\n\n```\n/beagle:draft-docs --publish docs/drafts/websocket-api.md\n```\n\n### Step 1: Read Draft\n\nRead the draft file and extract:\n- Title\n- Content type (from frontmatter or structure)\n\n### Step 2: Determine Destination\n\nAsk user which section:\n\n```markdown\nWhere should this document go?\n\n1. **API Reference**  `docs/api/{slug}.md`\n2. **Guides**  `docs/guides/{slug}.md`\n3. **How-To**  `docs/how-to/{slug}.md`\n4. **Other**  Specify path\n```\n\n### Step 3: Move File\n\n```bash\nmv docs/drafts/{slug}.md {destination}/{slug}.md\n```\n\n### Step 4: Update Navigation\n\nCheck for `docs/navigation.json` and update navigation:\n\n1. **Read current navigation.json**\n2. **Find appropriate navigation group**\n3. **Add new page entry**\n4. **Write updated navigation.json**\n\nExample update:\n```json\n{\n  \"navigation\": [\n    {\n      \"group\": \"API Reference\",\n      \"pages\": [\n        \"api/existing-page\",\n        \"api/websocket-api\"\n      ]\n    }\n  ]\n}\n```\n\n### Step 5: Report\n\n```markdown\n## Published\n\n**From:** `docs/drafts/{slug}.md`\n**To:** `{destination}/{slug}.md`\n**Navigation:** Updated `docs/navigation.json`\n\nThe document is now live in your docs.\n```\n\n### Step 6: End-of-Run Verification\n\nVerify publish completed successfully:\n\n```bash\n# Confirm file moved to destination\nls -la {destination}/{slug}.md\n\n# Confirm draft removed\nls docs/drafts/{slug}.md 2>/dev/null && echo \"WARNING: Draft still exists\" || echo \"Draft cleaned up\"\n\n# Verify navigation updated\ngrep -q \"{slug}\" docs/navigation.json && echo \"Navigation includes new page\" || echo \"WARNING: Navigation may need manual update\"\n\n# Check markdown syntax at final location\nmarkdownlint {destination}/{slug}.md 2>/dev/null || echo \"markdownlint not available\"\n```\n\n**Verification Checklist:**\n- [ ] Document moved to `{destination}/{slug}.md`\n- [ ] Draft removed from `docs/drafts/`\n- [ ] Navigation file updated with new page entry\n- [ ] No broken links in navigation structure\n- [ ] Document accessible at expected URL path\n\nIf any verification fails, report the specific issue and offer remediation steps.\n\n## Content Type Detection\n\n### Reference Indicators\n\n- Prompt mentions: API, endpoint, function, method, class, type, parameters, returns\n- Target is a specific symbol or set of symbols\n- User wants technical specification\n\n### How-To Indicators\n\n- Prompt mentions: how to, guide, steps, configure, set up, integrate\n- Target is a task or workflow\n- User wants procedural instructions\n\n## Rules\n\n- Always load `docs-style` skill for every draft\n- Generate to `docs/drafts/` - never directly to final location\n- Include frontmatter with title and description\n- Use realistic examples from actual codebase\n- Reference analyzed symbols in draft metadata\n- Preserve existing navigation structure when publishing\n- Ask before overwriting existing files\n",
        "commands/ensure-docs.md": "---\ndescription: Verify documentation coverage and generate missing docs interactively\n---\n\n# Ensure Documentation Coverage\n\nVerify code documentation coverage across a codebase, report gaps, and interactively generate missing documentation using parallel language-specific agents.\n\n## Arguments\n\n- `Path`: Target directory (default: current working directory)\n- `--report-only`: Skip interactive generation, just output findings\n\n## Workflow Overview\n\n1. **Detect** languages present in the codebase\n2. **Spawn** parallel verification agents per language\n3. **Merge** and present consolidated findings\n4. **Offer** interactive generation choices\n5. **Generate** missing docs if requested\n6. **Verify** with language linters\n\n## Phase 1: Language Detection\n\nDetect which languages are present in the codebase:\n\n```bash\n# Python detection\nPYTHON_FILES=$(find . -type f -name \"*.py\" ! -path \"./.*\" ! -path \"./venv/*\" ! -path \"./.venv/*\" | head -100)\nPYTHON_COUNT=$(echo \"$PYTHON_FILES\" | grep -c . || echo 0)\n\n# TypeScript/JavaScript detection\nTS_FILES=$(find . -type f \\( -name \"*.ts\" -o -name \"*.tsx\" -o -name \"*.js\" -o -name \"*.jsx\" \\) ! -path \"./node_modules/*\" ! -path \"./.*\" | head -100)\nTS_COUNT=$(echo \"$TS_FILES\" | grep -c . || echo 0)\n\n# Go detection\nGO_FILES=$(find . -type f -name \"*.go\" ! -path \"./vendor/*\" ! -path \"./.*\" | head -100)\nGO_COUNT=$(echo \"$GO_FILES\" | grep -c . || echo 0)\n```\n\n### Framework Detection\n\n```bash\n# FastAPI detection (affects OpenAPI handling)\ngrep -r \"from fastapi\\|FastAPI\\|@app\\.\\|@router\\.\" --include=\"*.py\" -l 2>/dev/null | head -1\n\n# Check existing OpenAPI specs\nls -la openapi.yaml swagger.json api.yaml 2>/dev/null\n```\n\n### Detection Output\n\nReport detected languages:\n\n| Language | Files Found | Standard |\n|----------|-------------|----------|\n| Python | $PYTHON_COUNT | Google docstrings |\n| TypeScript/JS | $TS_COUNT | JSDoc |\n| Go | $GO_COUNT | GoDoc |\n\nProceed only with languages that have at least 1 file detected.\n\n## Language Standards\n\n### Python (Google Docstrings)\n\n**What to check:**\n- All public functions (not starting with `_`)\n- All classes\n- All modules (top-of-file docstring)\n\n**Required docstring elements:**\n- Description (first line, imperative mood)\n- Args: Parameter name, type, and description\n- Returns: Return type and description\n- Raises: Exception types and when raised\n\n**Example of compliant docstring:**\n\n```python\ndef process_request(data: dict, timeout: int = 30) -> Response:\n    \"\"\"Process an incoming API request.\n\n    Args:\n        data: The request payload as a dictionary.\n        timeout: Maximum seconds to wait for processing.\n\n    Returns:\n        Response object containing status and result.\n\n    Raises:\n        ValidationError: If data fails schema validation.\n        TimeoutError: If processing exceeds timeout.\n    \"\"\"\n```\n\n**Missing indicators:**\n- No docstring at all\n- Docstring with only description (missing Args/Returns)\n- Mismatched parameters (docstring doesn't match signature)\n\n### TypeScript/JavaScript (JSDoc)\n\n**What to check:**\n- All exported functions\n- All exported classes\n- All exported interfaces and types\n- All exported constants with complex types\n\n**Required JSDoc elements:**\n- @description or first line description\n- @param for each parameter with type and description\n- @returns with type and description\n- @throws for thrown exceptions\n\n**Example of compliant JSDoc:**\n\n```typescript\n/**\n * Process an incoming API request.\n * @param data - The request payload\n * @param timeout - Maximum seconds to wait\n * @returns Response containing status and result\n * @throws {ValidationError} If data fails validation\n */\nexport function processRequest(data: RequestData, timeout = 30): Response {\n```\n\n**Missing indicators:**\n- No JSDoc comment\n- JSDoc with only description (missing @param/@returns)\n- Mismatched parameters (JSDoc doesn't match signature)\n\n### Go (GoDoc)\n\n**What to check:**\n- All exported functions (capitalized names)\n- All exported types (structs, interfaces)\n- Package comment in one file per package\n\n**Required GoDoc elements:**\n- Comment starting with the symbol name\n- Description of purpose and behavior\n- For complex functions: describe parameters inline\n\n**Example of compliant GoDoc:**\n\n```go\n// ProcessRequest handles an incoming API request with the given data\n// and timeout. It returns a Response or an error if processing fails.\n// The timeout is specified in seconds; use 0 for no timeout.\nfunc ProcessRequest(data map[string]any, timeout int) (*Response, error) {\n```\n\n**Missing indicators:**\n- No comment above exported symbol\n- Comment doesn't start with symbol name\n- Comment is too terse (single generic sentence)\n\n## Phase 2: Parallel Verification\n\nSpawn verification agents in parallel for each detected language using the `Task` tool.\n\n### Agent Prompt Template\n\nFor each detected language, spawn an agent with:\n\n**Python Agent:**\n```\nYou are a Python documentation verifier. Check all Python files for Google docstring compliance.\n\nSTANDARD:\n[Embed Python standard from above]\n\nTASK:\n1. Find all .py files in the target directory (exclude venv, .venv, __pycache__, tests)\n2. For each file, identify public functions (not _prefixed) and classes\n3. Check each symbol for docstring presence and completeness\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"python\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"path/to/file.py\", \"line\": 15, \"symbol\": \"function_name\", \"type\": \"function\", \"issue\": \"missing_docstring\"},\n    {\"file\": \"path/to/file.py\", \"line\": 42, \"symbol\": \"ClassName\", \"type\": \"class\", \"issue\": \"incomplete_docstring\", \"missing\": [\"Args\", \"Returns\"]}\n  ]\n}\n```\n\n**TypeScript Agent:**\n```\nYou are a TypeScript/JavaScript documentation verifier. Check all TS/JS files for JSDoc compliance.\n\nSTANDARD:\n[Embed TypeScript standard from above]\n\nTASK:\n1. Find all .ts, .tsx, .js, .jsx files (exclude node_modules, dist, build)\n2. For each file, identify exported functions, classes, interfaces, and types\n3. Check each symbol for JSDoc presence and completeness\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"typescript\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"src/api.ts\", \"line\": 10, \"symbol\": \"processRequest\", \"type\": \"function\", \"issue\": \"missing_jsdoc\"},\n    {\"file\": \"src/types.ts\", \"line\": 5, \"symbol\": \"UserData\", \"type\": \"interface\", \"issue\": \"incomplete_jsdoc\", \"missing\": [\"description for userId property\"]}\n  ]\n}\n```\n\n**Go Agent:**\n```\nYou are a Go documentation verifier. Check all Go files for GoDoc compliance.\n\nSTANDARD:\n[Embed Go standard from above]\n\nTASK:\n1. Find all .go files (exclude vendor, _test.go for symbol docs)\n2. For each file, identify exported functions and types (Capitalized names)\n3. Check each symbol for comment presence and correct format\n4. Return findings as JSON\n\nOUTPUT FORMAT:\n{\n  \"language\": \"go\",\n  \"files_scanned\": <count>,\n  \"findings\": [\n    {\"file\": \"pkg/api/handler.go\", \"line\": 25, \"symbol\": \"ProcessRequest\", \"type\": \"function\", \"issue\": \"missing_comment\"},\n    {\"file\": \"pkg/models/user.go\", \"line\": 8, \"symbol\": \"User\", \"type\": \"struct\", \"issue\": \"wrong_format\", \"detail\": \"Comment doesn't start with 'User'\"}\n  ]\n}\n```\n\n### Spawning Agents\n\nUse the `Task` tool to spawn agents in parallel:\n\n1. For each detected language with files > 0\n2. Spawn agent with subagent_type=\"general-purpose\"\n3. Include the language-specific prompt and standard\n4. Set run_in_background=false to wait for results\n5. Collect JSON output from each agent\n\n## Phase 3: Consolidate Results\n\nAfter all agents complete, merge their findings.\n\n### Categorize by Severity\n\nGroup findings into:\n\n| Severity | Issue Types | Priority |\n|----------|-------------|----------|\n| **Missing** | `missing_docstring`, `missing_jsdoc`, `missing_comment` | High |\n| **Incomplete** | `incomplete_docstring`, `incomplete_jsdoc` (has doc but missing required elements) | Medium |\n| **Wrong Format** | `wrong_format` (comment exists but doesn't follow standard) | Low |\n\n### Summary Table\n\nGenerate a summary table:\n\n```markdown\n## Documentation Audit Results\n\n| Language   | Files | Missing | Incomplete | Format Issues |\n|------------|-------|---------|------------|---------------|\n| Python     | 42    | 12      | 5          | 2             |\n| TypeScript | 28    | 8       | 3          | 0             |\n| Go         | 15    | 4       | 1          | 1             |\n| **Total**  | 85    | 24      | 9          | 3             |\n```\n\n### Detailed Report Format\n\nIf `--report-only` flag is set OR user requests detailed report:\n\n```markdown\n## Detailed Findings\n\n### Python (12 missing, 5 incomplete, 2 format issues)\n\n#### Missing Documentation\n\n1. **[src/api.py:15]** `process_request(data: dict) -> Response`\n   - Type: function\n   - Visibility: public\n\n2. **[src/models.py:8]** `class User`\n   - Type: class\n   - Visibility: public\n\n#### Incomplete Documentation\n\n3. **[src/utils.py:42]** `validate_input(value, schema)`\n   - Has: Description\n   - Missing: Args, Returns, Raises\n\n#### Format Issues\n\n4. **[src/helpers.py:20]** `format_output(data)`\n   - Issue: Docstring uses reST format instead of Google format\n\n### TypeScript (8 missing, 3 incomplete)\n...\n\n### Go (4 missing, 1 incomplete, 1 format issue)\n...\n```\n\n## Phase 4: Interactive Generation\n\nIf `--report-only` is NOT set, offer generation choices.\n\n### User Choice\n\nUse `AskUserQuestion` with these options:\n\n**Question:** \"Found {total} documentation gaps. What would you like to do?\"\n\n**Options:**\n1. \"Generate all missing docs\" - Generate documentation for all findings\n2. \"Generate for specific language\" - Choose which language(s) to generate for\n3. \"Show detailed report first\" - Display full findings before deciding\n4. \"Skip generation\" - Exit with report only\n\n### Generation Agent Prompts\n\nFor each language needing generation, spawn a generation agent:\n\n**Python Generation Agent:**\n```\nYou are a Python documentation generator. Generate Google-format docstrings.\n\nSTANDARD:\n[Embed Python standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/class implementation\n2. Understand parameters, return values, and exceptions\n3. Generate a complete Google-format docstring\n4. Apply the edit using the Edit tool\n\nRULES:\n- Match existing code style\n- Use imperative mood for descriptions\n- Include all Args, Returns, Raises\n- Don't modify any code logic\n```\n\n**TypeScript Generation Agent:**\n```\nYou are a TypeScript documentation generator. Generate JSDoc comments.\n\nSTANDARD:\n[Embed TypeScript standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/class/interface implementation\n2. Understand parameters, return types, and exceptions\n3. Generate a complete JSDoc comment\n4. Apply the edit using the Edit tool\n\nRULES:\n- Match existing code style\n- Include @param, @returns, @throws as needed\n- Don't modify any code logic\n```\n\n**Go Generation Agent:**\n```\nYou are a Go documentation generator. Generate GoDoc comments.\n\nSTANDARD:\n[Embed Go standard]\n\nSYMBOLS TO DOCUMENT:\n[List of file:line:symbol from findings]\n\nFOR EACH SYMBOL:\n1. Read the function/type implementation\n2. Understand purpose, parameters, and behavior\n3. Generate a comment starting with the symbol name\n4. Apply the edit using the Edit tool\n\nRULES:\n- Start comment with symbol name\n- Be concise but complete\n- Don't modify any code logic\n```\n\n## Phase 5: Post-Generation Verification\n\nAfter generating documentation, offer to run language linters to verify.\n\n### Verification Commands\n\n**Python:**\n```bash\n# Check docstring formatting with ruff (requires convention=\"google\" in pyproject.toml [tool.ruff.lint.pydocstyle])\nruff check . --select=D --output-format=concise\n\n# Alternative: pydocstyle\npydocstyle --convention=google .\n```\n\n**TypeScript:**\n```bash\n# Check JSDoc with eslint (requires eslint-plugin-jsdoc)\nnpx eslint . --rule 'jsdoc/require-jsdoc: error' --rule 'jsdoc/require-param: error' --rule 'jsdoc/require-returns: error'\n```\n\n**Go:**\n```bash\n# Check with staticcheck (golint is deprecated, use golangci-lint for comprehensive linting)\nstaticcheck -checks \"ST1000,ST1020,ST1021,ST1022\" ./...\n```\n\n### Verification Flow\n\n1. After generation completes, ask: \"Run documentation linters to verify?\"\n2. If yes, run appropriate linter(s) based on languages that were modified\n3. Report any remaining issues\n4. Offer to fix linter-reported issues\n\n## Rules\n\n- Always detect languages before spawning agents\n- Spawn agents in parallel for efficiency\n- Present clear summary before offering generation\n- Don't generate docs for test files (except test helpers)\n- Respect `--report-only` flag\n- Run verification after generation when linters are available\n",
        "commands/fetch-pr-feedback.md": "---\ndescription: Fetch bot review comments from a PR and evaluate with receive-feedback skill\n---\n\n# Fetch PR Feedback\n\nFetch review comments from a bot reviewer on the current PR, format them, and evaluate using the receive-feedback skill.\n\n## Usage\n\n```\n/beagle:fetch-pr-feedback [--bot <username>] [--pr <number>]\n```\n\n**Flags:**\n- `--bot <username>` - Bot/reviewer to fetch comments from (default: `coderabbitai[bot]`)\n- `--pr <number>` - PR number to target (default: current branch's PR)\n\n## Instructions\n\n### 1. Parse Arguments\n\nExtract flags from `$ARGUMENTS`:\n- `--bot <username>` or default to `coderabbitai[bot]`\n- `--pr <number>` or detect from current branch\n\n### 2. Get PR Context\n\n```bash\n# If --pr was specified, use that number directly\n# Otherwise, get PR for current branch:\ngh pr view --json number,headRefName,url\n\n# Get repo owner/name:\ngh repo view --json nameWithOwner --jq '.nameWithOwner'\n```\n\nIf no PR exists for current branch, fail with: \"No PR found for current branch. Use --pr to specify a PR number.\"\n\n### 3. Fetch Comments\n\nFetch both types of comments (use `--paginate` to get all):\n\n**Issue comments** (summary/walkthrough posts):\n```bash\ngh api --paginate \"repos/{owner}/{repo}/issues/{number}/comments\" \\\n  --jq '.[] | select(.user.login == \"{bot}\") | .body'\n```\n\n**Review comments** (line-specific):\n```bash\ngh api --paginate \"repos/{owner}/{repo}/pulls/{number}/comments\" \\\n  --jq '.[] | select(.user.login == \"{bot}\") | \"---\\nFile: \\(.path):\\(.line // .original_line)\\n\\(.body)\\n\"'\n```\n\n### 4. Format Feedback Document\n\nStrip noise from the content:\n- Remove `<details>` blocks containing \"Learnings\" or AI command hints\n- Remove excessive whitespace\n\nStructure the output:\n\n```markdown\n# PR Feedback from {bot}\n\n## Summary/Overview\n[All issue comments here - there may be multiple]\n\n## Line-Specific Comments\n[All review comments here, each prefixed with \"File: path:line\"]\n```\n\nIf no comments found, output: \"No comments from {bot} found on this PR.\"\n\n### 5. Evaluate with receive-feedback\n\nUse the Skill tool to load the receive-feedback skill: `Skill(skill: \"beagle:receive-feedback\")`\n\nThen process the formatted feedback document:\n\n1. Parse each actionable item from the formatted document\n2. Process each item through verify  evaluate  execute\n3. Produce structured response summary\n\n## Example\n\n```bash\n# Fetch CodeRabbit comments on current branch's PR (default)\n/beagle:fetch-pr-feedback\n\n# Fetch from a different bot\n/beagle:fetch-pr-feedback --bot renovate[bot]\n\n# Fetch from a specific PR\n/beagle:fetch-pr-feedback --pr 123\n\n# Combined\n/beagle:fetch-pr-feedback --bot coderabbitai[bot] --pr 456\n```\n",
        "commands/fix-llm-artifacts.md": "---\ndescription: Applies fixes from a prior review-llm-artifacts run, with safe/risky classification\n---\n\n# Fix LLM Artifacts\n\nApply fixes from a previous `review-llm-artifacts` run with automatic safe/risky classification.\n\n## Usage\n\n```\n/beagle:fix-llm-artifacts [--dry-run] [--all] [--category <name>]\n```\n\n**Flags:**\n- `--dry-run` - Show what would be fixed without changing files\n- `--all` - Fix entire codebase (runs review with --all first)\n- `--category <name>` - Only fix specific category: `tests|dead-code|abstraction|style`\n\n## Instructions\n\n### 1. Parse Arguments\n\nExtract flags from `$ARGUMENTS`:\n- `--dry-run` - Preview mode only\n- `--all` - Full codebase scan\n- `--category <name>` - Filter to specific category\n\n### 2. Pre-flight Safety Checks\n\n```bash\n# Check for uncommitted changes\ngit status --porcelain\n```\n\nIf working directory is dirty, warn:\n```\nWarning: You have uncommitted changes. Creating a git stash before proceeding.\nRun `git stash pop` to restore if needed.\n```\n\nCreate stash if dirty:\n```bash\ngit stash push -m \"beagle: pre-fix-llm-artifacts backup\"\n```\n\n### 3. Load Review Results\n\nCheck for existing review file:\n```bash\ncat .beagle/llm-artifacts-review.json 2>/dev/null\n```\n\n**If file missing:**\n- If `--all` flag: Run `review-llm-artifacts --all --json` first\n- Otherwise: Fail with: \"No review results found. Run `/beagle:review-llm-artifacts` first.\"\n\n**If file exists, validate freshness:**\n```bash\n# Get stored git HEAD from JSON\nstored_head=$(jq -r '.git_head' .beagle/llm-artifacts-review.json)\ncurrent_head=$(git rev-parse HEAD)\n\nif [ \"$stored_head\" != \"$current_head\" ]; then\n  echo \"Warning: Review was run at commit $stored_head, but HEAD is now $current_head\"\nfi\n```\n\nIf stale, prompt: \"Review results are stale. Re-run review? (y/n)\"\n\n### 4. Partition Findings by Safety\n\nParse findings from JSON and classify by `fix_safety` field:\n\n**Safe Fixes** (auto-apply):\n- `unused_import` - Unused imports\n- `todo_comment` - Stale TODO/FIXME comments\n- `dead_code_obvious` - Obviously unreachable code\n- `verbose_comment` - Overly verbose LLM-style comments\n- `redundant_type` - Redundant type annotations\n\n**Risky Fixes** (require confirmation):\n- `test_refactor` - Test structure changes\n- `abstraction_change` - Class/function extraction\n- `code_removal` - Removing functional code\n- `mock_boundary` - Test mock scope changes\n- `logic_change` - Any behavioral modifications\n\n### 5. Apply Safe Fixes\n\nIf `--dry-run`:\n```markdown\n## Safe Fixes (would apply automatically)\n\n| File | Line | Type | Description |\n|------|------|------|-------------|\n| src/api.py | 15 | unused_import | Remove `from typing import List` |\n| src/models.py | 42 | verbose_comment | Remove 23-line docstring |\n...\n```\n\nOtherwise, spawn parallel agents per category with `Task` tool:\n\n```\nTask: Apply safe fixes for category \"{category}\"\nFiles: [list of files with findings in this category]\nInstructions: Apply each fix, preserving surrounding code. Report success/failure per fix.\n```\n\nCategories to parallelize:\n- `style` - Comments, formatting\n- `dead-code` - Imports, unreachable code\n- `tests` - Test-related safe fixes\n- `abstraction` - Safe refactors\n\n### 6. Handle Risky Fixes\n\nFor each risky fix, prompt interactively:\n\n```\n[src/services/auth.py:156] Remove seemingly unused authenticate_legacy() method?\nThis method has no callers in the codebase but may be used externally.\n(y)es / (n)o / (s)kip all risky:\n```\n\nTrack user choices:\n- `y` - Apply this fix\n- `n` - Skip this fix\n- `s` - Skip all remaining risky fixes\n\n### 7. Post-Fix Verification\n\nDetect project type and run appropriate linters:\n\n**Python:**\n```bash\n# Check if ruff config exists\nif [ -f \"pyproject.toml\" ] || [ -f \"ruff.toml\" ]; then\n    ruff check --fix .\n    ruff format .\nfi\n\n# Check if mypy config exists\nif [ -f \"pyproject.toml\" ] || [ -f \"mypy.ini\" ]; then\n    mypy .\nfi\n```\n\n**TypeScript/JavaScript:**\n```bash\n# Check for eslint\nif [ -f \"eslint.config.js\" ] || [ -f \".eslintrc.json\" ]; then\n    npx eslint --fix .\nfi\n\n# Check for TypeScript\nif [ -f \"tsconfig.json\" ]; then\n    npx tsc --noEmit\nfi\n```\n\n**Go:**\n```bash\nif [ -f \"go.mod\" ]; then\n    go vet ./...\n    go build ./...\nfi\n```\n\n### 8. Run Tests\n\n```bash\n# Python\nif [ -f \"pyproject.toml\" ] || [ -f \"pytest.ini\" ]; then\n    pytest\nfi\n\n# JavaScript/TypeScript\nif [ -f \"package.json\" ]; then\n    npm test 2>/dev/null || yarn test 2>/dev/null || true\nfi\n\n# Go\nif [ -f \"go.mod\" ]; then\n    go test ./...\nfi\n```\n\n### 9. Report Results\n\n```markdown\n## Fix Summary\n\n### Applied Fixes\n- [x] src/api.py:15 - Removed unused import `List`\n- [x] src/models.py:42-64 - Removed verbose docstring\n- [x] src/auth.py:156-189 - Removed dead method (user confirmed)\n\n### Skipped Fixes\n- [ ] src/services/cache.py:23 - User declined risky fix\n- [ ] tests/test_api.py:45 - Test refactor skipped\n\n### Verification Results\n- Linter: PASSED\n- Type check: PASSED\n- Tests: PASSED (42 passed, 0 failed)\n\n### Diff Summary\n```bash\ngit diff --stat\n```\n\n## Cleanup\n\nOn successful completion (all verifications pass):\n```bash\nrm .beagle/llm-artifacts-review.json\n```\n\nIf any verification fails, keep the file and report:\n```\nReview file preserved at .beagle/llm-artifacts-review.json\nFix issues and re-run, or restore with: git stash pop\n```\n\n## Example\n\n```bash\n# Preview all fixes without applying\n/beagle:fix-llm-artifacts --dry-run\n\n# Fix only dead code issues\n/beagle:fix-llm-artifacts --category dead-code\n\n# Full codebase scan and fix\n/beagle:fix-llm-artifacts --all\n\n# Fix style issues only, preview first\n/beagle:fix-llm-artifacts --category style --dry-run\n```\n",
        "commands/gen-release-notes.md": "---\ndescription: generate release notes for changes since a given tag\n---\n\n# Release Notes Generator\n\nGenerate professional release notes following the Keep a Changelog standard.\n\n**Input**: Previous tag (e.g., `v0.0.1`)\n\n```\n$ARGUMENTS\n```\n\n---\n\nUse extended thinking to analyze the changes thoroughly before generating release notes.\n\n## Step 1: Gather Changes\n\nRun these commands to collect information about changes since the provided tag:\n\n```bash\n# Store the previous tag\nPREV_TAG=\"$ARGUMENTS\"\n\n# Verify the tag exists\ngit tag -l \"$PREV_TAG\"\n\n# Get the repo URL for PR links\ngit remote get-url origin\n\n# List commits since last tag\ngit log ${PREV_TAG}..HEAD --pretty=format:\"%h %s\" --no-merges\n\n# Get detailed diff stats\ngit diff ${PREV_TAG}..HEAD --stat\n\n# List changed files by directory\ngit diff ${PREV_TAG}..HEAD --name-only | sort | uniq\n```\n\nAlso gather PR information:\n\n```bash\n# Get merged PRs since the tag (requires gh CLI)\ngh pr list --state merged --search \"merged:>=$(git log -1 --format=%ci $PREV_TAG | cut -d' ' -f1)\" --json number,title,author,labels\n```\n\n## Step 2: Analyze and Categorize\n\nCategorize each change into exactly one of these groups (in this order):\n\n| Category | Include | Exclude |\n|----------|---------|---------|\n| **Added** | New features, new public APIs, new CLI commands | Internal utilities not exposed to users |\n| **Changed** | Modified behavior, performance improvements, updated dependencies with user impact | Refactors with no behavior change |\n| **Deprecated** | Features marked for future removal | - |\n| **Removed** | Deleted features, removed public APIs | Removed internal code |\n| **Fixed** | Bug fixes, error handling improvements | Test-only fixes |\n| **Security** | Vulnerability patches, security hardening | - |\n\n**Exclude entirely:**\n- CI/CD configuration changes (unless they affect users)\n- Documentation-only changes (unless they reveal new features)\n- Code style/formatting changes\n- Test-only changes\n- Internal refactors with no user-visible impact\n- Merge commits\n\n## Step 3: Determine Version Number\n\nBased on the changes, suggest the next version following Semantic Versioning:\n- **MAJOR** (X.0.0): Breaking changes to public API\n- **MINOR** (x.Y.0): New features, backward-compatible\n- **PATCH** (x.y.Z): Bug fixes only\n\nDetect the tag format from existing tags (with or without `v` prefix).\n\n## Step 4: Write Release Notes\n\nGenerate a `CHANGELOG.md` entry using this exact format:\n\n```markdown\n## [VERSION] - YYYY-MM-DD\n\n### Added\n\n- **scope:** Add new feature description ([#54](REPO_URL/pull/54))\n\n### Changed\n\n- **Breaking:** Rename `oldName()` to `newName()` for consistency ([#145](REPO_URL/pull/145))\n\n  **Migration:** Replace all calls to `oldName()` with `newName()`.\n\n### Deprecated\n\n- **scope:** Deprecate `legacy_function()` in favor of `new_function()` ([#143](REPO_URL/pull/143))\n\n### Removed\n\n- **Breaking:** Remove deprecated `old_function()` ([#141](REPO_URL/pull/141))\n\n### Fixed\n\n- **scope:** Fix race condition when multiple workers access shared state ([#139](REPO_URL/pull/139))\n\n### Security\n\n- **deps:** Update vulnerable package to patched version ([#49](REPO_URL/pull/49))\n```\n\n### Writing Rules\n\n**Format requirements:**\n- Start every entry with an imperative verb: Add, Fix, Remove, Update, Improve, Rename, Deprecate, Patch\n- Include scope prefix in bold when present: `**server:**`, `**cli:**`, `**api:**`\n- One line per change (except breaking changes which get migration notes)\n- Include PR/issue link at end of line\n- Sort entries within each category by importance (most impactful first)\n- Omit empty categories entirely\n\n**Breaking changes:**\n- Prefix with bold `**Breaking:**`\n- List first within their category\n- Add a `**Migration:**` block on the next line explaining exactly what users must change\n- Include before/after code examples for API signature changes\n\n**Tone:**\n- Write for library consumers, not maintainers\n- Focus on *what changed for users*, not *how it was implemented*\n- Be specificnever write \"various improvements\" or \"bug fixes\"\n- Each entry should be understandable without reading the PR\n\n**Bad examples to avoid:**\n```markdown\n# BAD - Too vague\n- Fixed bugs\n- Performance improvements\n- Updated dependencies\n\n# BAD - Implementation-focused\n- Refactored the internal state machine to use async/await\n\n# BAD - Missing context\n- Fixed #234\n```\n\n**Good examples to follow:**\n```markdown\n# GOOD - Specific and user-focused\n- **server:** Fix timeout errors when processing files larger than 100MB ([#234](URL))\n- **cli:** Add `--dry-run` flag to preview changes before execution ([#235](URL))\n- **api:** Improve cold-start latency from 2.3s to 0.8s by lazy-loading plugins ([#236](URL))\n```\n\n## Step 5: Update CHANGELOG.md\n\n1. If `CHANGELOG.md` exists:\n   - Insert new version after the `## [Unreleased]` section (or at top if no Unreleased)\n\n2. If `CHANGELOG.md` doesn't exist, create it with this header:\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n```\n\n3. Add version comparison links at the bottom of the file using the detected repo URL.\n\n## Step 6: Output Summary\n\nAfter updating the changelog, provide:\n1. The suggested version number with rationale\n2. Summary of categorized changes\n3. Any breaking changes that need special attention\n4. Confirmation that CHANGELOG.md was updated\n\n## Conventional Commits Mapping\n\nMap commit prefixes to changelog categories:\n\n| Commit Prefix | Changelog Category |\n|---------------|-------------------|\n| `feat(scope):` | Added |\n| `feat!(scope):` | Added (with Breaking prefix) |\n| `fix(scope):` | Fixed |\n| `perf(scope):` | Changed |\n| `security(scope):` | Security |\n| `docs:`, `chore:`, `ci:`, `test:`, `style:` | **Exclude** |\n",
        "commands/gen-test-plan.md": "---\ndescription: Analyze repo, detect stack, trace changes to user-facing entry points, generate YAML test plan\n---\n\n# Generate Test Plan\n\nAnalyze the repository's tech stack, branch changes vs default, and generate an executable YAML test plan focused on user-facing impact.\n\n## Arguments\n\n- `--base <branch>`: Base branch to diff against (default: `main`)\n- Path: Target directory (default: current working directory)\n\n## Step 1: Gather Repository Context\n\n```bash\n# Get current branch\ngit rev-parse --abbrev-ref HEAD\n\n# Get default base branch (try origin/main, then origin/master)\ngit rev-parse --verify origin/main >/dev/null 2>&1 && echo \"main\" || echo \"master\"\n\n# Get changed files vs base\ngit diff --name-only $(git merge-base HEAD origin/main)..HEAD\n\n# Get commit messages for context\ngit log --oneline $(git merge-base HEAD origin/main)..HEAD\n```\n\n**Capture:**\n- `current_branch`: Branch name\n- `base_branch`: Default branch to compare against\n- `changed_files`: List of modified files\n- `commit_messages`: What the PR is about\n\n## Step 2: Detect Tech Stack\n\nScan for project configuration files to determine the stack:\n\n```bash\n# Node.js detection\nls package.json pnpm-lock.yaml package-lock.json yarn.lock 2>/dev/null\n\n# Python detection\nls pyproject.toml requirements.txt setup.py 2>/dev/null\nls uv.lock poetry.lock 2>/dev/null\n\n# Go detection\nls go.mod 2>/dev/null\n\n# Docker detection\nls docker-compose.yml docker-compose.yaml Dockerfile 2>/dev/null\n\n# Makefile detection\nls Makefile 2>/dev/null && grep -q \"dev:\" Makefile && echo \"has-dev-target\"\n```\n\n### Stack Detection Rules\n\n| Files Found | Stack | Setup Commands | Default Port |\n|-------------|-------|----------------|--------------|\n| `package.json` + `pnpm-lock.yaml` | Node.js (pnpm) | `pnpm install && pnpm run dev` | 5173, 3000 |\n| `package.json` + `package-lock.json` | Node.js (npm) | `npm install && npm run dev` | 5173, 3000 |\n| `package.json` + `yarn.lock` | Node.js (yarn) | `yarn install && yarn dev` | 5173, 3000 |\n| `pyproject.toml` + `uv.lock` | Python (uv) | `uv sync && uv run <entrypoint>` | 8000 |\n| `pyproject.toml` + `poetry.lock` | Python (poetry) | `poetry install && poetry run <entrypoint>` | 8000 |\n| `go.mod` | Go | `go run .` or `make dev` | 8080 |\n| `docker-compose.yml` | Docker | `docker-compose up -d` | Parse from compose |\n| `Makefile` with `dev:` target | Make-based | `make dev` | Infer from Makefile |\n\n### Entrypoint Discovery\n\n**Python:**\n```bash\n# Check pyproject.toml for scripts\ngrep -A5 '\\[project.scripts\\]' pyproject.toml 2>/dev/null\n\n# Look for common entrypoints\nls main.py app.py server.py api/main.py src/main.py 2>/dev/null\n\n# Check for uvicorn/gunicorn patterns\ngrep -r \"uvicorn\\|gunicorn\" pyproject.toml Makefile 2>/dev/null\n```\n\n**Node.js:**\n```bash\n# Check package.json scripts\ncat package.json | python3 -c \"import sys,json; print(json.load(sys.stdin).get('scripts', {}).get('dev', ''))\"\n\n# Check for monorepo structure\nls apps/ packages/ 2>/dev/null\n```\n\n### Port Discovery\n\n```bash\n# Check .env files\ngrep -E \"^PORT=\" .env .env.example .env.local 2>/dev/null\n\n# Check docker-compose port mappings\ngrep -A2 \"ports:\" docker-compose.yml 2>/dev/null\n\n# Check vite.config for custom port\ngrep -E \"port:\" vite.config.ts vite.config.js 2>/dev/null\n```\n\n## Step 3: Discover User-Facing Entry Points\n\nGrep for route definitions based on detected stack:\n\n**Python (FastAPI/Flask):**\n```bash\ngrep -rn \"@app\\.\\(get\\|post\\|put\\|delete\\|patch\\)\" --include=\"*.py\" | head -20\ngrep -rn \"@router\\.\\(get\\|post\\|put\\|delete\\|patch\\)\" --include=\"*.py\" | head -20\n```\n\n**Node.js (Express/Fastify):**\n```bash\ngrep -rn \"app\\.\\(get\\|post\\|put\\|delete\\)\" --include=\"*.ts\" --include=\"*.js\" | head -20\ngrep -rn \"router\\.\\(get\\|post\\|put\\|delete\\)\" --include=\"*.ts\" --include=\"*.js\" | head -20\n```\n\n**React Router:**\n```bash\ngrep -rn \"createBrowserRouter\\|<Route\\|path=\" --include=\"*.tsx\" --include=\"*.jsx\" | head -20\n```\n\n**Go (net/http, gin, chi):**\n```bash\ngrep -rn \"http.HandleFunc\\|r.GET\\|r.POST\\|router.Get\\|router.Post\" --include=\"*.go\" | head -20\n```\n\nBuild a map of:\n- API endpoints: method + path + file:line\n- UI routes: path + component + file:line\n\n## Step 4: Trace Changes to Entry Points\n\nFor each changed file, determine if it affects user-facing functionality:\n\n1. **Direct entry point change** - File contains route definitions\n2. **Import chain analysis** - Find what imports the changed file and trace up to entry points\n3. **Document the trace path** in test context\n\n```bash\n# For each changed file, find what imports it\ngrep -rn \"from.*<module>\\|import.*<module>\" --include=\"*.py\" --include=\"*.ts\" --include=\"*.tsx\"\n```\n\n**Output:**\nFor each affected entry point, document:\n- Which changed files affect it\n- The import/dependency chain\n- Why this entry point needs testing\n\n## Step 5: Generate Test Cases\n\nFor each affected entry point, create appropriate test cases:\n\n### API Endpoints (curl tests)\n\nFor endpoints affected by changes:\n```yaml\n- id: TC-XX\n  name: <Describe what user action this represents>\n  context: |\n    <Which files changed and why this endpoint is affected>\n  steps:\n    - action: curl\n      method: <GET|POST|PUT|DELETE>\n      url: http://localhost:<port>/<path>\n      headers:\n        Content-Type: application/json\n      body: <JSON body if needed>\n  expected: |\n    <Natural language description of expected behavior>\n```\n\n### UI Routes (agent-browser tests)\n\nFor UI routes affected by changes:\n```yaml\n- id: TC-XX\n  name: <Describe the user journey>\n  context: |\n    <Which files changed and why this route is affected>\n  steps:\n    - action: agent-browser open\n      url: http://localhost:<port>/<path>\n    - action: agent-browser snapshot\n    - action: agent-browser fill\n      ref: \"@<field-name>\"\n      value: \"<test value>\"\n    - action: agent-browser click\n      ref: \"@<button-name>\"\n    - action: agent-browser wait\n      type: url\n      value: \"<expected-path>\"\n    - action: agent-browser snapshot\n  expected: |\n    <Natural language description of expected behavior>\n  evidence:\n    screenshot: evidence/tc-XX.png\n```\n\n### Test Case Guidelines\n\n- At least one test per affected entry point\n- API tests for backend-only changes\n- Browser tests for UI changes\n- Both when full-stack changes\n- Include authentication steps if endpoints are protected\n- Use `${ENV_VAR}` syntax for secrets/tokens\n\n## Step 6: Write YAML Test Plan\n\nCreate the test plan file:\n\n```bash\nmkdir -p docs/testing\n```\n\nWrite to `docs/testing/test-plan.yaml`:\n\n```yaml\nversion: 1\nmetadata:\n  branch: <current_branch>\n  base: <base_branch>\n  generated: <ISO timestamp>\n  changes_summary: |\n    <Summary of what this PR changes based on commit messages and diff>\n\nsetup:\n  stack:\n    - type: <node|python|go|docker>\n      package_manager: <pnpm|npm|yarn|uv|poetry|none>\n  commands:\n    - <install command>\n    - <run command>\n  health_checks:\n    - url: http://localhost:<port>/health\n      timeout: 30\n    - url: http://localhost:<frontend_port>\n      timeout: 30\n\ntests:\n  - id: TC-01\n    name: <Test name>\n    context: |\n      <Why this test exists, which changes affect it>\n    steps:\n      - <action steps>\n    expected: |\n      <Expected behavior in natural language>\n    evidence:\n      screenshot: evidence/tc-01.png\n```\n\n## Step 7: Report Summary\n\nAfter generating the test plan:\n\n```markdown\n## Test Plan Generated\n\n**File:** `docs/testing/test-plan.yaml`\n**Branch:** <current_branch>  <base_branch>\n\n### Detected Stack\n\n| Component | Type | Port |\n|-----------|------|------|\n| <component> | <type> | <port> |\n\n### Tests Generated\n\n| ID | Name | Type | Affected By |\n|----|------|------|-------------|\n| TC-01 | <name> | curl/browser | <files> |\n\n### Entry Point Coverage\n\n- **Covered:** <N> entry points with tests\n- **Unchanged:** <M> entry points not affected by this PR\n\n### Next Steps\n\n1. Review the generated test plan at `docs/testing/test-plan.yaml`\n2. Adjust test values and expectations as needed\n3. Run tests with:\n   ```\n   /beagle:run-test-plan\n   ```\n```\n\n## Step 8: Verification\n\nBefore completing:\n\n```bash\n# Verify file was created\nls -la docs/testing/test-plan.yaml\n\n# Validate YAML syntax\npython3 -c \"import yaml; yaml.safe_load(open('docs/testing/test-plan.yaml'))\" && echo \"Valid YAML\"\n\n# Check required fields\ngrep -E \"^version:|^metadata:|^setup:|^tests:\" docs/testing/test-plan.yaml\n```\n\n**Verification Checklist:**\n- [ ] Test plan file created at `docs/testing/test-plan.yaml`\n- [ ] YAML is syntactically valid\n- [ ] At least one test case generated\n- [ ] Setup commands match detected stack\n- [ ] Health checks point to valid endpoints\n- [ ] Each test has id, name, steps, and expected fields\n\n## Rules\n\n- Always create `docs/testing/` directory if it doesn't exist\n- Generate at least one test per affected entry point\n- Include context explaining why each test matters (trace from changes)\n- Use natural language for `expected` field (agent will interpret)\n- Default to conservative port detection (8000 for API, 5173/3000 for frontend)\n- Include `agent-browser snapshot` after significant UI state changes\n- Use `${ENV_VAR}` syntax for secrets, never hardcode credentials\n- If no user-facing changes detected, explain why and suggest manual verification\n",
        "commands/improve-doc.md": "---\ndescription: Analyze and improve existing documentation using Diataxis principles\n---\n\n# Improve Doc\n\nAnalyze an existing markdown document, classify sections by Diataxis type, identify issues, and interactively refine each section.\n\n## Arguments\n\n- **Path:** Path to the markdown document to improve (required)\n\n## Workflow Overview\n\n```\n/beagle:improve-doc docs/guides/getting-started.md\n```\n\nThe command runs in two phases:\n\n1. **Analysis Phase:** Parse document, classify sections, identify issues\n2. **Refinement Phase:** Interactive loop to improve each section\n\n## Phase 1: Analysis\n\n### Step 1: Read Document\n\nRead the target markdown file and parse into sections based on headings:\n\n- Each `#`, `##`, `###` heading starts a new section\n- Capture heading level, title, and content\n- Preserve hierarchy for context\n\n### Step 2: Load Core Skill\n\nLoad `beagle:docs-style` for core writing principles that apply to all documentation types.\n\n### Step 3: Classify Each Section\n\nFor each section, determine the Diataxis type using these indicators:\n\n| Type | Indicators |\n|------|------------|\n| **Tutorial** | \"Let's\", \"we will\", step-by-step learning, builds toward a project, minimal explanation of why |\n| **How-To** | \"How to\" title, task-focused steps, assumes prior knowledge, goal-oriented |\n| **Reference** | Parameter tables, type signatures, API specs, factual descriptions, no narrative |\n| **Explanation** | \"Why\", \"because\", history, trade-offs, alternatives, conceptual discussion |\n\n**Classification rules:**\n\n1. Check title first - \"How to X\" is always How-To, \"Why X\" is always Explanation\n2. Look for structural patterns - tables with parameters/types suggest Reference\n3. Analyze language - learning-oriented (\"Let's learn\") vs task-oriented (\"To accomplish X\")\n4. Consider context - what comes before/after this section\n5. Mark as \"Mixed\" if section blends types (this is an issue to fix)\n\n### Step 4: Identify Issues\n\nFor each section, check for issues based on its detected type:\n\n**Tutorial issues:**\n- Explains \"why\" instead of just guiding the learner\n- Skips steps assuming prior knowledge\n- No clear learning outcome\n- Missing \"you will build/learn\" framing\n\n**How-To issues:**\n- Includes explanatory tangents\n- Missing prerequisites\n- Steps not atomic (multiple actions per step)\n- No verification that goal was achieved\n\n**Reference issues:**\n- Missing parameter types or return values\n- Narrative text instead of factual description\n- Incomplete coverage of options/parameters\n- No code examples\n\n**Explanation issues:**\n- Includes procedural steps\n- Missing context for \"why\"\n- No trade-offs or alternatives discussed\n- Reads like reference material\n\n**Cross-type issues (any section):**\n- Mixed Diataxis types in single section\n- Unclear who the audience is\n- Missing or vague heading\n- Wall of text without structure\n\n### Step 5: Present Analysis\n\nDisplay analysis summary to user:\n\n```markdown\n## Document Analysis\n\n**File:** `docs/guides/getting-started.md`\n**Sections found:** 8\n**Estimated time:** ~15 minutes to refine\n\n### Type Breakdown\n\n| Type | Sections | Health |\n|------|----------|--------|\n| Tutorial | 2 | 1 issue |\n| How-To | 3 | 4 issues |\n| Reference | 1 | Clean |\n| Explanation | 1 | 2 issues |\n| Mixed | 1 | Needs split |\n\n### Top Issues\n\n1. **Section \"Setting Up\"** (How-To): Contains explanatory tangent about architecture\n2. **Section \"Configuration Options\"** (Mixed): Blends reference table with tutorial steps\n3. **Section \"Authentication\"** (How-To): Missing prerequisites, steps not atomic\n4. **Section \"Why We Built This\"** (Explanation): Includes procedural steps\n\n### Ready to Refine?\n\nI'll go through each section with issues. For each one, you can:\n- **yes** - Accept the proposed improvement\n- **skip** - Keep original, move to next section\n- **modify** - Tell me what to change about the proposal\n\nType \"start\" to begin refinement, or \"abort\" to exit without changes.\n```\n\n## Phase 2: Interactive Refinement\n\n### Step 1: Load Type-Specific Skills\n\nAs you encounter each section type, load the relevant skill if not already loaded:\n\n- Tutorial sections: `beagle:tutorial-docs`\n- How-To sections: `beagle:howto-docs`\n- Reference sections: `beagle:reference-docs`\n- Explanation sections: `beagle:explanation-docs`\n\n### Step 2: Refinement Loop\n\nFor each section with issues, in document order:\n\n#### 2a: Show Current State\n\n```markdown\n---\n\n## Section 3 of 5: \"Setting Up\" (How-To)\n\n### Current Content\n\n> ## Setting Up\n>\n> Before we begin, it's important to understand why the architecture\n> works this way. The system uses a microservices pattern because...\n> [explanatory content]\n>\n> To set up the project:\n> 1. Clone the repo and install dependencies\n> 2. Configure the environment variables\n> 3. Start the server\n\n### Issues Found\n\n1. **Explanatory tangent** (lines 1-3): How-To should assume reader knows why; move explanation to dedicated Explanation section\n2. **Non-atomic steps** (step 1): \"Clone and install\" is two actions; split into separate steps\n3. **Missing verification**: No way to confirm setup succeeded\n\n```\n\n#### 2b: Ask Clarifying Question (if needed)\n\nIf the type classification is uncertain:\n\n```markdown\n### Quick Question\n\nThis section has characteristics of both How-To (task steps) and Explanation (why content). How would you like to handle it?\n\n1. **Split** - Create separate How-To and Explanation sections\n2. **How-To** - Remove explanation, keep as pure How-To\n3. **Explanation** - Remove steps, keep as pure Explanation\n```\n\n#### 2c: Propose Improvement\n\n```markdown\n### Proposed Improvement\n\n> ## Setting Up\n>\n> **Prerequisites:** Familiarity with microservices architecture\n>\n> ### Steps\n>\n> 1. Clone the repository\n>    ```bash\n>    git clone https://github.com/example/project.git\n>    ```\n>\n> 2. Install dependencies\n>    ```bash\n>    cd project && npm install\n>    ```\n>\n> 3. Configure environment variables\n>    ```bash\n>    cp .env.example .env\n>    ```\n>\n> 4. Start the server\n>    ```bash\n>    npm start\n>    ```\n>\n> ### Verify\n>\n> Open http://localhost:3000 - you should see the welcome page.\n\n**Changes made:**\n- Removed explanatory content (suggest creating \"Architecture Overview\" section)\n- Split \"clone and install\" into separate steps\n- Added verification step\n- Added prerequisites reference\n\n---\n\n**Your choice:** [yes / skip / modify]\n```\n\n#### 2d: Handle User Choice\n\n**yes** - Apply the proposed changes to the section, continue to next\n\n**skip** - Keep original content unchanged, continue to next\n\n**modify** - User provides feedback:\n\n```markdown\n> modify: Keep the explanation but move it to a collapsible \"Why?\" block\n\n### Revised Proposal\n\n> ## Setting Up\n>\n> <details>\n> <summary>Why this architecture?</summary>\n>\n> The system uses a microservices pattern because...\n>\n> </details>\n>\n> ### Steps\n> [same as before]\n\n**Your choice:** [yes / skip / modify]\n```\n\n### Step 3: Handle Mixed Sections\n\nFor sections classified as \"Mixed\":\n\n```markdown\n---\n\n## Section 5 of 5: \"Configuration Options\" (Mixed)\n\n### Current Content\n\n> ## Configuration Options\n>\n> Let's walk through configuring your application. First, you'll need\n> to understand the available options:\n>\n> | Option | Type | Default | Description |\n> |--------|------|---------|-------------|\n> | port | number | 3000 | Server port |\n> | debug | boolean | false | Enable debug mode |\n>\n> Now let's configure each one step by step...\n\n### Issues Found\n\n1. **Mixed types**: Tutorial framing (\"Let's walk through\") with Reference content (options table)\n\n### Recommendation\n\nSplit into two sections:\n\n1. **Reference section** - \"Configuration Reference\" with the options table\n2. **Tutorial section** - \"Configuring Your First App\" with learning-oriented walkthrough\n\nWould you like me to:\n1. **Split** - Create both sections\n2. **Reference only** - Keep just the table, remove tutorial framing\n3. **Tutorial only** - Expand into full tutorial, move table to appendix\n```\n\n### Step 4: Write Updated Document\n\nAfter all sections processed:\n\n1. **Build updated content** from accepted changes\n2. **Preserve unchanged sections** exactly as they were\n3. **Overwrite original file** with updated content\n\n### Step 5: Report Results\n\n```markdown\n## Refinement Complete\n\n**File:** `docs/guides/getting-started.md`\n\n### Changes Summary\n\n| Section | Action | Type |\n|---------|--------|------|\n| Setting Up | Improved | How-To |\n| Configuration Options | Split | Reference + Tutorial |\n| Authentication | Improved | How-To |\n| Why We Built This | Skipped | Explanation |\n\n### Sections Modified\n\n- **Setting Up**: Removed tangent, split steps, added verification\n- **Configuration Options**: Split into \"Configuration Reference\" and \"Configuring Your App\"\n- **Authentication**: Added prerequisites, made steps atomic\n\n### New Sections Created\n\n- **Configuration Reference** (Reference): Options table from split\n- **Configuring Your App** (Tutorial): Learning walkthrough from split\n\n### Recommendations\n\nConsider creating these additional documents:\n- `docs/explanation/architecture-overview.md` - For content removed from \"Setting Up\"\n\nThe original file has been updated.\n```\n\n## Rules\n\n- Always load `docs-style` skill before analysis\n- Load type-specific skills lazily as sections are encountered\n- Never modify the file until refinement phase completes\n- Preserve sections marked \"skip\" exactly as-is\n- When splitting sections, maintain logical reading order\n- Ask clarifying questions when type classification is ambiguous (confidence < 70%)\n- For \"Mixed\" sections, always offer split as the first option\n- Include specific line references when identifying issues\n- Show diff-style changes in proposals when helpful\n- Respect user's \"modify\" feedback - iterate until they say \"yes\" or \"skip\"\n- Create backup note in output if major restructuring occurred\n",
        "commands/llm-judge.md": "---\ndescription: Compare code implementations across 2+ repos using LLM-as-judge methodology with weighted scoring\n---\n\n# LLM Judge\n\nCompare code implementations across multiple repositories using structured LLM-as-judge evaluation.\n\n## Usage\n\n```bash\n/beagle:llm-judge <spec> <repo1> <repo2> [repo3...] [--labels=...] [--weights=...] [--branch=...]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `spec` | Yes | Path to spec/requirements document |\n| `repos` | Yes | 2+ paths to repositories to compare |\n| `--labels` | No | Comma-separated labels (default: directory names) |\n| `--weights` | No | Override weights, e.g., `functionality:40,security:30` |\n| `--branch` | No | Branch to compare against main (default: current) |\n\n## Examples\n\n```bash\n# Basic comparison\n/beagle:llm-judge ./spec.md /path/to/repo-a /path/to/repo-b\n\n# With custom labels\n/beagle:llm-judge ./spec.md /path/a /path/b /path/c --labels=\"Claude,GPT-4,Gemini\"\n\n# With custom weights\n/beagle:llm-judge ./spec.md /path/a /path/b --weights=\"functionality:40,security:35,tests:15,overengineering:5,dead_code:5\"\n```\n\n## Step 1: Parse Arguments\n\nParse `$ARGUMENTS` to extract:\n- `spec_path`: First positional argument\n- `repo_paths`: Remaining positional arguments (must be 2+)\n- `labels`: From `--labels` flag or derive from directory names\n- `weights`: From `--weights` flag or use defaults\n- `branch`: From `--branch` flag or use \"main\"\n\n**Default Weights:**\n```json\n{\n  \"functionality\": 30,\n  \"security\": 25,\n  \"tests\": 20,\n  \"overengineering\": 15,\n  \"dead_code\": 10\n}\n```\n\n## Step 2: Validate Inputs\n\n```bash\n# Check spec exists\n[ -f \"$SPEC_PATH\" ] || { echo \"Error: Spec file not found: $SPEC_PATH\"; exit 1; }\n\n# Check each repo exists and is a git repo\nfor repo in \"${REPO_PATHS[@]}\"; do\n  [ -d \"$repo/.git\" ] || { echo \"Error: Not a git repository: $repo\"; exit 1; }\ndone\n\n# Ensure at least 2 repos\n[ ${#REPO_PATHS[@]} -ge 2 ] || { echo \"Error: Need at least 2 repositories to compare\"; exit 1; }\n```\n\nValidation failures exit immediately with error message.\n\n## Step 3: Read Spec Document\n\n```bash\nSPEC_CONTENT=$(cat \"$SPEC_PATH\") || { echo \"Error: Failed to read spec file: $SPEC_PATH\"; exit 1; }\n[ -z \"$SPEC_CONTENT\" ] && { echo \"Error: Spec file is empty: $SPEC_PATH\"; exit 1; }\n```\n\n## Step 4: Load the Skill\n\nLoad the llm-judge skill: `Skill(skill: \"beagle:llm-judge\")`\n\n## Step 5: Phase 1 - Spawn Repo Agents\n\nSpawn N parallel agents (one per repo) using the `Task` tool:\n\n```\nFor each repo, spawn a Task with:\n\nprompt: |\n  You are a Phase 1 Repo Agent for the LLM Judge evaluation.\n\n  **Your Repo:** $LABEL at $REPO_PATH\n\n  **Spec Document:**\n  $SPEC_CONTENT\n\n  **Instructions:**\n  1. Load skill: Skill(skill: \"beagle:llm-judge\")\n  2. Read references/repo-agent.md for detailed instructions\n  3. Read references/fact-schema.md for the output format\n  4. Load Skill(skill: \"beagle:llm-artifacts-detection\") for analysis\n\n  Explore the repository and gather facts. Return ONLY valid JSON following the fact schema.\n\n  Do NOT score or judge. Only gather facts.\n\nsubagent_type: \"general-purpose\"\ndescription: \"Gather facts from $LABEL repo\"\n```\n\nWait for all agents to complete. Collect their JSON outputs into `ALL_FACTS` array.\n\n## Step 6: Validate Phase 1 Results\n\nFor each repo agent result:\n1. Verify it returned valid JSON\n2. Verify required fields are present\n3. If any agent failed, report error and abort\n\n```bash\n# Validate JSON (example check)\necho \"$FACTS\" | python3 -c \"import json,sys; json.load(sys.stdin)\" 2>/dev/null || echo \"Invalid JSON from $LABEL\"\n```\n\n## Step 7: Phase 2 - Spawn Judge Agents\n\nSpawn 5 parallel judge agents using the `Task` tool:\n\n```\nFor each dimension in [functionality, security, tests, overengineering, dead_code]:\n\nprompt: |\n  You are the $DIMENSION Judge for the LLM Judge evaluation.\n\n  **Spec Document:**\n  $SPEC_CONTENT\n\n  **Facts from all repos:**\n  $ALL_FACTS_JSON\n\n  **Instructions:**\n  1. Load skill: Skill(skill: \"beagle:llm-judge\")\n  2. Read references/judge-agents.md for detailed instructions\n  3. Read references/scoring-rubrics.md for the $DIMENSION rubric\n\n  Score each repo on $DIMENSION. Return ONLY valid JSON with scores and justifications.\n\nsubagent_type: \"general-purpose\"\ndescription: \"Judge $DIMENSION dimension\"\n```\n\nWait for all judges to complete. Collect their outputs.\n\n## Step 8: Aggregate Scores\n\nCombine all judge outputs:\n\n```python\n# Pseudocode for aggregation\nfor repo_label in labels:\n    scores[repo_label] = {}\n    for dimension in dimensions:\n        scores[repo_label][dimension] = judge_outputs[dimension]['scores'][repo_label]\n\n    # Compute weighted total\n    weighted_total = sum(\n        scores[repo_label][dim]['score'] * weights[dim] / 100\n        for dim in dimensions\n    )\n    scores[repo_label]['weighted_total'] = round(weighted_total, 2)\n\n# Rank by weighted total\nranking = sorted(labels, key=lambda l: scores[l]['weighted_total'], reverse=True)\n```\n\n## Step 9: Generate Verdict\n\nBased on the ranking and score differences, generate a verdict:\n\n```\nThe verdict should:\n1. Name the winner\n2. Explain WHY they won (which dimensions drove the result)\n3. Note any close calls or trade-offs\n```\n\n## Step 10: Write JSON Report\n\nCreate `.beagle` directory if needed:\n\n```bash\nmkdir -p .beagle\n```\n\nWrite to `.beagle/llm-judge-report.json`:\n\n```json\n{\n  \"version\": \"1.0.0\",\n  \"created_at\": \"ISO timestamp\",\n  \"spec_file\": \"$SPEC_PATH\",\n  \"repos\": [\n    { \"label\": \"...\", \"path\": \"...\", \"git_head\": \"...\" }\n  ],\n  \"weights\": { ... },\n  \"scores\": { ... },\n  \"ranking\": [ ... ],\n  \"verdict\": \"...\"\n}\n```\n\n## Step 11: Display Summary\n\n```markdown\n## LLM Judge Results\n\n**Spec:** $SPEC_PATH\n**Repos compared:** $LABELS\n\n### Scores\n\n| Dimension | Weight | $LABEL1 | $LABEL2 | ... |\n|-----------|--------|---------|---------|-----|\n| Functionality | 30% | X | Y | |\n| Security | 25% | X | Y | |\n| Tests | 20% | X | Y | |\n| Overengineering | 15% | X | Y | |\n| Dead Code | 10% | X | Y | |\n| **Weighted Total** | | **X.XX** | **Y.YY** | |\n\n### Ranking\n\n1. **$WINNER** (X.XX)\n2. $SECOND (Y.YY)\n...\n\n### Verdict\n\n$VERDICT\n\n### Detailed Justifications\n\n#### Functionality\n- **$LABEL1:** $JUSTIFICATION\n- **$LABEL2:** $JUSTIFICATION\n\n[Repeat for each dimension]\n\n---\n\nReport saved to `.beagle/llm-judge-report.json`\n```\n\n## Step 12: Verification\n\nBefore completing:\n\n1. Verify `.beagle/llm-judge-report.json` exists and is valid JSON\n2. Verify all repos have scores for all dimensions\n3. Verify weighted totals sum correctly\n\n```bash\n# Verify JSON\npython3 -c \"import json; json.load(open('.beagle/llm-judge-report.json'))\" && echo \"Valid report\"\n```\n\n## Rules\n\n- Always validate inputs before proceeding\n- Spawn Phase 1 agents in parallel (one per repo)\n- Wait for Phase 1 to complete before Phase 2\n- Spawn Phase 2 agents in parallel (one per dimension)\n- Every score must have a justification\n- Write JSON report before displaying summary\n",
        "commands/prompt-improver.md": "---\ndescription: Optimize prompts for code-related tasks following Claude best practices. Use when refining prompts for implementation, debugging, refactoring, code review, or testing.\n---\n\n# Prompt Improver\n\nOptimize code-related prompts for clarity, investigation-first thinking, and verification.\n\n## Input\n\n```\n$ARGUMENTS\n```\n\n---\n\n## Step 1: Analyze the Prompt\n\nEvaluate the input prompt across these dimensions:\n\n| Dimension | What to check |\n|-----------|---------------|\n| Task Clarity | Is the task type clear? (implement, fix, refactor, review, test) Are boundaries defined? |\n| Investigation | Does it specify reading/understanding before acting? |\n| Verification | Are there appropriate checks? (run tests, build, lint) |\n| Context Anchoring | Does it reference specific files, functions, or patterns? |\n| Action Specificity | Is the desired outcome explicit? Quality expectations stated? |\n| Scope Control | Is it appropriately scoped? Clear stopping points? |\n\nIdentify which dimensions are weak or missing in the input prompt.\n\n## Step 2: Apply Transformation Rules\n\n### Task Clarity\n- Convert vague requests  specific task type + scope\n- Add \"implement\", \"fix\", \"refactor\", \"review\", or \"test\" when ambiguous\n- Specify affected files/components when inferable\n\n### Investigation-First\n- Add \"Read and understand [relevant files] before making changes\"\n- For bugs: \"Reproduce and understand the root cause first\"\n- For features: \"Check existing patterns in the codebase\"\n\n### Anti-Hallucination\n- \"Do not assume code structure you haven't read\"\n- \"Verify imports/dependencies exist before using them\"\n- \"Check for existing utilities before creating new ones\"\n\n### Verification Steps\n- For implementation: \"Run tests after changes\"\n- For refactoring: \"Ensure behavior is unchanged\"\n- For fixes: \"Verify the fix and check for regressions\"\n\n### Positive Framing\n- Convert \"don't break tests\"  \"ensure tests pass after changes\"\n- Convert \"don't over-engineer\"  \"implement the minimal solution\"\n\n### Scope Control\n- Add explicit boundaries when missing\n- Break multi-part requests into phases if needed\n\n## Examples\n\n### Bug Fix\n```\nOriginal: \"fix the login bug\"\n\nOptimized:\nFix the login bug. First, read the authentication-related files to understand\nthe current implementation. Reproduce the bug to confirm the issue. Identify\nthe root cause before making changes. Implement the fix and run existing tests\nto verify no regressions.\n```\n\n### Feature Implementation\n```\nOriginal: \"add dark mode\"\n\nOptimized:\nImplement dark mode for the application. First, check how theming/styling is\ncurrently handled in the codebase. Look for existing color variables or theme\npatterns. Implement the toggle and theme switching with minimal changes to\nexisting components. Run tests and verify the UI renders correctly in both modes.\n```\n\n### Refactoring\n```\nOriginal: \"clean up the user service\"\n\nOptimized:\nRefactor the user service for improved maintainability. Read the current\nimplementation and understand its responsibilities. Identify specific issues\n(duplication, unclear naming, tight coupling). Make incremental changes,\nrunning tests after each step to ensure behavior is unchanged.\n```\n\n## Task-Type Tips\n\n| Task Type | Tip |\n|-----------|-----|\n| Bug fixes | Include reproduction steps if known. Specify whether this is a quick fix or needs root cause analysis. |\n| Feature implementation | Reference similar features in the codebase. Specify if tests are expected. |\n| Refactoring | State the goal (readability, performance, testability). Emphasize incremental changes. |\n| Code review | Specify focus areas (security, performance, style). Mention what to ignore. |\n| Testing | Specify test type (unit, integration, e2e). Reference existing test patterns. |\n\n## Step 3: Generate Output\n\nProduce output in this exact format:\n\n### Analysis\n\n[2-3 sentences identifying the prompt type and which dimensions are weak]\n\n### Improvements Applied\n\n- [Bullet list of specific transformations applied]\n\n### Optimized Prompt\n\n```\n[The improved prompt, ready to copy and use]\n```\n\n### Tips for This Prompt Type\n\n[1-2 sentences of relevant tips from the Task-Type Tips table]\n",
        "commands/receive-feedback.md": "---\ndescription: Process code review feedback from a file with verification-first discipline\n---\n\n# Receive Feedback Command\n\nProcess external code review feedback using the receive-feedback skill.\n\n## Usage\n\n```\n/receive-feedback path/to/feedback.md\n```\n\n## Workflow\n\n1. **Read** the feedback file at `$ARGUMENTS`\n2. **Parse** individual feedback items (numbered, bulleted, or freeform)\n3. **Load skill** using the Skill tool: `Skill(skill: \"beagle:receive-feedback\")`\n4. **Process** each item through verify  evaluate  execute (as defined in the skill)\n5. **Produce** structured response summary (per skill's RESPONSE.md)\n6. **Prompt** whether to log to `.feedback-log.csv`\n\n## Expected Feedback File Format\n\nThe feedback file should contain numbered or bulleted items:\n\n```markdown\n1. Remove unused import on line 15\n2. Add error handling to the API call\n3. Consider using a generator for large datasets\n4. Fix typo in variable name: `usr`  `user`\n```\n\nOr freeform prose - extract actionable items from the text.\n\n## Example\n\n```\n/receive-feedback reviews/pr-123-feedback.md\n```\n\nReads the file, processes each item with technical verification,\nand outputs a structured response table.\n",
        "commands/respond-pr-feedback.md": "---\ndescription: Respond to bot review comments on a PR after evaluation and fixes\n---\n\n# Respond to PR Feedback\n\nPost replies to bot review comments after you've evaluated the feedback and made fixes.\n\n## Usage\n\n```\n/beagle:respond-pr-feedback [--bot <username>] [--pr <number>] [--as <username>]\n```\n\n**Flags:**\n- `--bot <username>` - Bot whose comments to respond to (default: `coderabbitai[bot]`)\n- `--pr <number>` - PR number to target (default: current branch's PR)\n- `--as <username>` - Filter already-replied based on this responder (default: current `gh` user)\n\n## Prerequisites\n\nRun `/beagle:fetch-pr-feedback` first to evaluate the feedback and make any necessary fixes.\n\n## Instructions\n\n### 1. Parse Arguments\n\nExtract flags from `$ARGUMENTS`:\n- `--bot <username>` or default to `coderabbitai[bot]`\n- `--pr <number>` or detect from current branch\n- `--as <username>` or detect from `gh api user`\n\n### 2. Get PR Context\n\n```bash\n# Get repo info\ngh repo view --json nameWithOwner --jq '.nameWithOwner'\n\n# Get PR number (if not specified)\ngh pr view --json number --jq '.number'\n\n# Get responder username (if --as not specified)\ngh api user --jq '.login'\n```\n\n### 3. Fetch Unreplied Comments\n\nThis query filters out already-replied comments and deduplicates (CodeRabbit reposts on each iteration):\n\n```bash\ngh api --paginate \"repos/{owner}/{repo}/pulls/{number}/comments\" | jq -s 'add |\n  # Get root comments from target bot (not replies to itself)\n  [.[] | select(.user.login == \"{bot}\" and .in_reply_to_id == null)] as $roots |\n  # Get IDs that responder has already replied to\n  [.[] | select(.user.login == \"{responder}\") | .in_reply_to_id] as $replied |\n  # Filter to unreplied comments only\n  $roots | map(select(. as $c | $replied | index($c.id) == null)) |\n  # Group by file:line and pick newest comment for each (handles duplicates)\n  group_by({p: .path, l: .line}) |\n  map(sort_by(.created_at) | last) |\n  # Output needed fields\n  map({id, path, line, body})\n'\n```\n\nIf no unreplied comments found, output: \"All {bot} comments have been addressed.\"\n\n### 4. Generate and Post Replies\n\nFor each unreplied comment, determine the appropriate response based on your evaluation:\n\n| Evaluation Outcome | Response |\n|-------------------|----------|\n| Feedback was incorrect/unfounded | Explain why the current code is correct |\n| Feedback lacked context | Explain the design decision |\n| Feedback was valid and fixed | \"Fixed in {commit}\" or brief description of change |\n| Feedback was valid but won't fix | Explain the tradeoff/decision |\n\nPost reply to each comment:\n\n```bash\ngh api \"repos/{owner}/{repo}/pulls/{number}/comments/{comment_id}/replies\" \\\n  -X POST --raw-field body=\"@{bot} {response}\"\n```\n\n### 5. Prompt to Resolve Threads\n\nAfter posting replies, ask the user:\n\n> Would you like to resolve these conversation threads?\n> 1. **Yes, all** - Resolve all threads that were just replied to\n> 2. **Select individually** - Choose which threads to resolve\n> 3. **No** - Leave threads open for further discussion\n\nTo resolve a thread, use the GraphQL API:\n\n```bash\ngh api graphql -f query='\n  mutation {\n    resolveReviewThread(input: {threadId: \"{thread_id}\"}) {\n      thread { isResolved }\n    }\n  }\n'\n```\n\nNote: To get the `thread_id`, you need to query review threads:\n```bash\ngh api graphql -f query='\n  query {\n    repository(owner: \"{owner}\", name: \"{repo}\") {\n      pullRequest(number: {number}) {\n        reviewThreads(first: 100) {\n          nodes {\n            id\n            isResolved\n            comments(first: 1) {\n              nodes { databaseId }\n            }\n          }\n        }\n      }\n    }\n  }\n'\n```\n\nMatch `databaseId` to your comment IDs to find the corresponding `thread_id`.\n\n### 6. Output Summary\n\nDisplay a summary table:\n\n| File:Line | Response Type | Thread Status |\n|-----------|---------------|---------------|\n| `src/foo.ts:42` | Fixed | Resolved |\n| `src/bar.ts:15` | Explained design | Open |\n\n## Response Guidelines\n\n- **Always tag the bot** at the start: `@coderabbitai ...`\n- Keep responses concise and technical\n- No performative agreement (\"Great point!\", \"You're right!\")\n- Reference specific code/design when explaining decisions\n- If fixed: state what changed, no gratitude\n\n## Example\n\n```bash\n# Respond to CodeRabbit on current PR\n/beagle:respond-pr-feedback\n\n# Respond on a specific PR\n/beagle:respond-pr-feedback --pr 123\n\n# Use different bot/responder\n/beagle:respond-pr-feedback --bot renovate[bot] --as my-bot[bot]\n```\n",
        "commands/review-frontend.md": "---\ndescription: Comprehensive React/TypeScript frontend code review with optional parallel agents\n---\n\n# Frontend Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.(tsx?|css)$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect React Flow\ngrep -r \"@xyflow/react\\|ReactFlow\\|useNodesState\" --include=\"*.tsx\" -l | head -3\n\n# Detect Zustand\ngrep -r \"from 'zustand'\\|create\\(\\(\" --include=\"*.ts\" --include=\"*.tsx\" -l | head -3\n\n# Detect Tailwind v4\ngrep -r \"@theme\\|@layer theme\" --include=\"*.css\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.test\\.tsx?$'\n```\n\n## Step 3: Load Verification Protocol\n\nLoad `beagle:review-verification-protocol` skill and keep its checklist in mind throughout the review.\n\n## Step 4: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:react-router-code-review\")`).\n\n**Always load:**\n- `beagle:react-router-code-review`\n- `beagle:shadcn-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| @xyflow/react detected | `beagle:react-flow-code-review` |\n| Zustand detected | `beagle:zustand-state` |\n| Tailwind v4 detected | `beagle:tailwind-v4` |\n| Test files changed | `beagle:vitest-testing` |\n\n## Step 5: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review React Router patterns first\n3. Review shadcn/ui patterns\n4. Review detected technology areas\n5. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent loads its skill and reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n## Step 6: Verify Findings\n\nBefore reporting any issue:\n1. Re-read the actual code (not just diff context)\n2. For \"unused\" claims - did you search all references?\n3. For \"missing\" claims - did you check framework/parent handling?\n4. For syntax issues - did you verify against current version docs?\n5. Remove any findings that are style preferences, not actual issues\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, a11y, perf, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\nnpm run lint\nnpm run typecheck\nnpm run test\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Don't assume Next.js patterns (no \"use client\")\n- Run verification after fixes\n",
        "commands/review-go.md": "---\ndescription: Comprehensive Go backend code review with optional parallel agents\n---\n\n# Go Backend Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.go$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect BubbleTea TUI\ngrep -r \"charmbracelet/bubbletea\\|tea\\.Model\\|tea\\.Cmd\" --include=\"*.go\" -l | head -3\n\n# Detect Wish SSH\ngrep -r \"charmbracelet/wish\\|ssh\\.Session\\|wish\\.Middleware\" --include=\"*.go\" -l | head -3\n\n# Detect Prometheus\ngrep -r \"prometheus/client_golang\\|promauto\\|prometheus\\.Counter\" --include=\"*.go\" -l | head -3\n\n# Detect ZeroLog\ngrep -r \"rs/zerolog\\|zerolog\\.Logger\" --include=\"*.go\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '_test\\.go$'\n```\n\n## Step 3: Load Verification Protocol\n\nLoad `beagle:review-verification-protocol` skill and keep its checklist in mind throughout the review.\n\n## Step 4: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:go-code-review\")`).\n\n**Always load:**\n- `beagle:go-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| Test files changed | `beagle:go-testing-code-review` |\n| BubbleTea detected | `beagle:bubbletea-code-review` |\n| Wish SSH detected | `beagle:wish-ssh-code-review` |\n| Prometheus detected | `beagle:prometheus-go-code-review` |\n\n## Step 5: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review Go quality issues first (error handling, concurrency, interfaces)\n3. Review detected technology areas\n4. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent loads its skill and reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n## Step 6: Verify Findings\n\nBefore reporting any issue:\n1. Re-read the actual code (not just diff context)\n2. For \"unused\" claims - did you search all references?\n3. For \"missing\" claims - did you check framework/parent handling?\n4. For syntax issues - did you verify against current version docs?\n5. Remove any findings that are style preferences, not actual issues\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, race condition, resource leak, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\ngo build ./...\ngo vet ./...\ngolangci-lint run\ngo test -v -race ./...\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Check for race conditions with `-race` flag\n- Run verification after fixes\n",
        "commands/review-ios.md": "---\ndescription: Comprehensive iOS/SwiftUI code review with optional parallel agents\n---\n\n# iOS Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.swift$'\n```\n\n## Step 2: Verify Linter Status\n\n**CRITICAL**: Run SwiftLint BEFORE flagging any style issues.\n\n```bash\n# Check if SwiftLint config exists and run it\nif [ -f \".swiftlint.yml\" ] || [ -f \".swiftlint.yaml\" ]; then\n    swiftlint lint --quiet <changed_files>\nfi\n```\n\n**Rules:**\n- If SwiftLint passes for a specific rule, DO NOT flag that issue manually\n- SwiftLint configuration is authoritative for style rules\n- Only flag issues that linters cannot detect (semantic issues, architectural problems)\n\n## Step 3: Detect Technologies\n\n```bash\n# SwiftUI (always with swift files that import it)\ngrep -r \"import SwiftUI\" --include=\"*.swift\" -l | head -3\n\n# SwiftData\ngrep -r \"import SwiftData\\|@Model\\|@Query\" --include=\"*.swift\" -l | head -3\n\n# Swift Testing\ngrep -r \"import Testing\\|@Test\\|#expect\" --include=\"*.swift\" -l | head -3\n\n# Combine\ngrep -r \"import Combine\\|AnyPublisher\\|@Published\" --include=\"*.swift\" -l | head -3\n\n# URLSession (explicit async patterns)\ngrep -r \"URLSession\\.shared\\|\\.data(from:\\|\\.download(from:\" --include=\"*.swift\" -l | head -3\n\n# CloudKit\ngrep -r \"import CloudKit\\|CKContainer\\|CKRecord\" --include=\"*.swift\" -l | head -3\n\n# WidgetKit\ngrep -r \"import WidgetKit\\|TimelineProvider\\|WidgetFamily\" --include=\"*.swift\" -l | head -3\n\n# App Intents\ngrep -r \"import AppIntents\\|@AppIntent\\|AppEntity\" --include=\"*.swift\" -l | head -3\n\n# HealthKit\ngrep -r \"import HealthKit\\|HKHealthStore\\|HKQuery\" --include=\"*.swift\" -l | head -3\n\n# WatchKit\ngrep -r \"import WatchKit\\|WKExtension\\|WKInterfaceController\" --include=\"*.swift\" -l | head -3\n```\n\n## Step 4: Load Verification Protocol\n\nLoad `beagle:review-verification-protocol` skill and keep its checklist in mind throughout the review.\n\n## Step 5: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:swift-code-review\")`).\n\n**Always load:**\n- `beagle:swift-code-review`\n- `beagle:swiftui-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| SwiftData detected | `beagle:swiftdata-code-review` |\n| Swift Testing detected | `beagle:swift-testing-code-review` |\n| Combine detected | `beagle:combine-code-review` |\n| URLSession detected | `beagle:urlsession-code-review` |\n| CloudKit detected | `beagle:cloudkit-code-review` |\n| WidgetKit detected | `beagle:widgetkit-code-review` |\n| App Intents detected | `beagle:app-intents-code-review` |\n| HealthKit detected | `beagle:healthkit-code-review` |\n| WatchKit detected | `beagle:watchos-code-review` |\n\n## Step 6: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review Swift quality issues first (concurrency, memory, error handling)\n3. Review SwiftUI patterns (view composition, state management, accessibility)\n4. Review detected technology areas\n5. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent loads its skill and reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n### Before Flagging Issues\n\n1. **Check SwiftLint output** - don't duplicate linter findings\n2. **Check code comments** for intentional patterns (// MARK:, // NOTE:, etc.)\n3. **Consider Apple framework idioms** - what looks wrong generically may be correct for the framework\n4. **Trace async code paths** before claiming missing error handling or race conditions\n\n## Step 7: Verify Findings\n\nBefore reporting any issue:\n1. Re-read the actual code (not just diff context)\n2. For \"unused\" claims - did you search all references?\n3. For \"missing\" claims - did you check framework/parent handling?\n4. For syntax issues - did you verify against current version docs?\n5. Remove any findings that are style preferences, not actual issues\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (crash, data loss, security, race condition)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\n# Swift build and lint\nswift build\nswiftlint lint --quiet\n\n# Run tests if present\nswift test\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Check for Swift 6 strict concurrency issues\n- Run verification after fixes\n",
        "commands/review-llm-artifacts.md": "---\ndescription: Detects common LLM coding agent artifacts by spawning 4 parallel subagents\n---\n\n# LLM Artifacts Review\n\nDetect common artifacts left behind by LLM coding agents: over-abstraction, dead code, DRY violations in tests, verbose comments, and defensive overkill.\n\n## Arguments\n\n- `--all`: Scan entire codebase (default: changed files from main)\n- `--parallel`: Force parallel execution (default when 4+ files)\n- Path: Target directory (default: current working directory)\n\n## Step 1: Determine Scope\n\nParse `$ARGUMENTS` for flags and path:\n\n```bash\n# Default: changed files from main\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.(py|ts|tsx|js|jsx|go|rs|java|rb|swift|kt)$'\n\n# If --all flag: scan entire codebase\nfind . -type f \\( -name \"*.py\" -o -name \"*.ts\" -o -name \"*.tsx\" -o -name \"*.js\" -o -name \"*.jsx\" -o -name \"*.go\" -o -name \"*.rs\" -o -name \"*.java\" -o -name \"*.rb\" -o -name \"*.swift\" -o -name \"*.kt\" \\) ! -path \"*/node_modules/*\" ! -path \"*/.git/*\" ! -path \"*/vendor/*\" ! -path \"*/__pycache__/*\"\n```\n\nIf no files found, exit with: \"No files to scan. Check your branch has changes or use --all to scan the entire codebase.\"\n\n## Step 2: Detect Languages\n\nExtract unique file extensions from the file list:\n\n```bash\n# Get unique extensions\necho \"$FILES\" | sed 's/.*\\.//' | sort -u\n```\n\nMap extensions to language names for the report:\n- `.py` -> Python\n- `.ts`, `.tsx` -> TypeScript\n- `.js`, `.jsx` -> JavaScript\n- `.go` -> Go\n- `.rs` -> Rust\n- `.java` -> Java\n- `.rb` -> Ruby\n- `.swift` -> Swift\n- `.kt` -> Kotlin\n\n## Step 3: Spawn Parallel Subagents\n\nIf file count >= 4 OR `--parallel` flag is set, spawn 4 subagents via `Task` tool.\n\nEach subagent MUST:\n1. Load the skill: `Skill(skill: \"beagle:llm-artifacts-detection\")`\n2. Review only its assigned category\n3. Return findings in the structured format below\n\n### Subagent 1: Tests Agent\n\n**Focus:** Testing anti-patterns from LLM generation\n\n- DRY violations (repeated setup code, duplicate assertions)\n- Testing library/framework code instead of application logic\n- Wrong mock boundaries (mocking too much or too little)\n- Overly verbose test names that describe implementation\n- Tests that just mirror the implementation\n\n### Subagent 2: Dead Code Agent\n\n**Focus:** Unused or obsolete code\n\n- Unused imports, variables, functions, classes\n- TODO/FIXME comments that should have been resolved\n- Backwards compatibility code for removed features\n- Orphaned test files for deleted code\n- Commented-out code blocks\n- Feature flags that are always on/off\n\n### Subagent 3: Abstraction Agent\n\n**Focus:** Over-engineering patterns\n\n- Unnecessary abstraction layers (interfaces for single implementations)\n- Copy-paste drift (similar code that diverged slightly)\n- Over-configuration (configurable things that never change)\n- Premature generalization\n- Factory/Builder patterns for simple object creation\n- Deep inheritance hierarchies\n\n### Subagent 4: Style Agent\n\n**Focus:** Verbose or defensive patterns\n\n- Verbose comments explaining obvious code\n- Defensive overkill (null checks on non-nullable values)\n- Unnecessary type hints (dynamic languages with obvious types)\n- Overly explicit error messages\n- Redundant logging\n- Self-documenting code with documentation\n\n## Step 4: Consolidate Findings\n\nWait for all subagents to complete, then:\n\n1. Merge all findings into a single list\n2. Assign unique IDs (1, 2, 3...)\n3. Group by category for display\n\n## Step 5: Write JSON Report\n\nCreate `.beagle` directory if it doesn't exist:\n\n```bash\nmkdir -p .beagle\n```\n\nWrite findings to `.beagle/llm-artifacts-review.json`:\n\n```json\n{\n  \"version\": \"1.0.0\",\n  \"created_at\": \"2024-01-15T10:30:00Z\",\n  \"git_head\": \"abc1234\",\n  \"scope\": \"changed\" | \"all\",\n  \"files_scanned\": 42,\n  \"languages\": [\"Python\", \"TypeScript\", \"Go\"],\n  \"findings\": [\n    {\n      \"id\": 1,\n      \"category\": \"tests\" | \"dead_code\" | \"abstraction\" | \"style\",\n      \"type\": \"dry_violation\" | \"unused_import\" | \"over_abstraction\" | \"verbose_comment\" | ...,\n      \"file\": \"src/utils/helper.py\",\n      \"line\": 42,\n      \"description\": \"Repeated setup code in 5 test functions\",\n      \"suggestion\": \"Extract to a pytest fixture\",\n      \"risk\": \"Low\" | \"Medium\" | \"High\",\n      \"fix_safety\": \"Safe\" | \"Needs review\",\n      \"fix_action\": \"refactor\" | \"delete\" | \"simplify\" | \"extract\"\n    }\n  ],\n  \"summary\": {\n    \"total\": 15,\n    \"by_category\": {\n      \"tests\": 4,\n      \"dead_code\": 5,\n      \"abstraction\": 3,\n      \"style\": 3\n    },\n    \"by_risk\": {\n      \"High\": 2,\n      \"Medium\": 8,\n      \"Low\": 5\n    },\n    \"by_fix_safety\": {\n      \"Safe\": 10,\n      \"Needs review\": 5\n    }\n  }\n}\n```\n\n## Step 6: Display Summary\n\n```markdown\n## LLM Artifacts Review\n\n**Scope:** Changed files from main | Entire codebase\n**Files scanned:** 42\n**Languages:** Python, TypeScript, Go\n\n### Findings by Category\n\n#### Tests (4 issues)\n\n1. [src/tests/test_api.py:15] **DRY violation** (Medium, Safe)\n   - Repeated setup code in 5 test functions\n   - Suggestion: Extract to a pytest fixture\n\n2. [src/tests/test_utils.py:42] **Wrong mock boundary** (High, Needs review)\n   - Mocking internal implementation details\n   - Suggestion: Mock at the adapter boundary instead\n\n#### Dead Code (5 issues)\n\n3. [src/utils/legacy.py:1] **Unused module** (Low, Safe)\n   - Module imported nowhere in codebase\n   - Suggestion: Delete file\n\n...\n\n#### Abstraction (3 issues)\n...\n\n#### Style (3 issues)\n...\n\n### Summary Table\n\n| Category | Safe Fixes | Needs Review | Total |\n|----------|------------|--------------|-------|\n| Tests | 3 | 1 | 4 |\n| Dead Code | 4 | 1 | 5 |\n| Abstraction | 2 | 1 | 3 |\n| Style | 1 | 2 | 3 |\n| **Total** | **10** | **5** | **15** |\n\n### Next Steps\n\n- Run `/beagle:review-llm-artifacts --fix` to auto-fix Safe issues (coming soon)\n- Review the JSON report at `.beagle/llm-artifacts-review.json`\n```\n\n## Step 7: Verification\n\nBefore completing, verify the review executed correctly:\n\n1. **JSON validity:** Confirm `.beagle/llm-artifacts-review.json` exists and is parseable\n2. **Subagent success:** All 4 subagents completed without errors\n3. **Git HEAD captured:** The `git_head` field is non-empty in the report\n4. **Staleness check:** If a previous report exists, compare stored `git_head` to current HEAD and warn if different\n\n```bash\n# Verify JSON is valid\npython3 -c \"import json; json.load(open('.beagle/llm-artifacts-review.json'))\" 2>/dev/null && echo \" Valid JSON\" || echo \" Invalid JSON\"\n\n# Check for staleness (if previous report exists)\nSTORED_HEAD=$(jq -r '.git_head' .beagle/llm-artifacts-review.json 2>/dev/null)\nCURRENT_HEAD=$(git rev-parse --short HEAD)\nif [ \"$STORED_HEAD\" != \"$CURRENT_HEAD\" ]; then\n  echo \" Report was generated on $STORED_HEAD, current HEAD is $CURRENT_HEAD\"\nfi\n```\n\nIf any verification fails, report the error and do not proceed.\n\n## Output Format for Each Finding\n\n```text\n[FILE:LINE] **ISSUE_TYPE** (Risk, Fix Safety)\n- Description\n- Suggestion: Specific fix recommendation\n```\n\n## Rules\n\n- Always load the `beagle:llm-artifacts-detection` skill first\n- Use `Task` tool for parallel subagents when >= 4 files\n- Every finding MUST have file:line reference\n- Categorize risk honestly (don't inflate or deflate)\n- Mark fix safety as \"Safe\" only if change is mechanical and reversible\n- Create `.beagle` directory if needed\n- Write JSON report before displaying summary\n",
        "commands/review-plan.md": "---\ndescription: Review implementation plans for parallelization, TDD, types, libraries, and security before execution\n---\n\n# Review Plan\n\nReview implementation plans created by `superpowers:writing-plans` before execution.\n\n## Arguments\n\n- Path: Plan file to review (e.g., `docs/plans/2025-01-15-auth-feature.md`)\n\n## Step 1: Read and Parse Plan\n\nRead the plan file and extract:\n\n1. **Header fields:**\n   - `**Goal:**` - Feature description\n   - `**Architecture:**` - Approach summary\n   - `**Tech Stack:**` - Technologies used\n\n2. **Verify via file patterns:**\n   - `.py` files  Python\n   - `.ts`, `.tsx` files  TypeScript\n   - `.go` files  Go\n   - `pytest` commands  pytest\n   - `vitest`, `jest` commands  JavaScript/TypeScript testing\n   - `go test` commands  Go testing\n\n## Step 2: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:python-code-review\")`).\n\nBased on detected tech stack, load relevant skills:\n\n| Detected | Skill |\n|----------|-------|\n| Python | `beagle:python-code-review` |\n| FastAPI | `beagle:fastapi-code-review` |\n| SQLAlchemy | `beagle:sqlalchemy-code-review` |\n| PostgreSQL | `beagle:postgres-code-review` |\n| pytest | `beagle:pytest-code-review` |\n| React Router | `beagle:react-router-code-review` |\n| React Flow | `beagle:react-flow-code-review` |\n| shadcn/ui | `beagle:shadcn-code-review` |\n| vitest | `beagle:vitest-testing` |\n| Go | `beagle:go-code-review` |\n| BubbleTea | `beagle:bubbletea-code-review` |\n\n## Step 3: Launch 5 Parallel Agents\n\nUse the `Task` tool to spawn 5 agents simultaneously. Each receives:\n- Full plan content\n- Detected tech stack\n- Relevant skill content from Step 2\n\n### Agent 1: Parallelization Analysis\n\n```\nAnalyze whether this implementation plan can be executed by parallel subagents.\n\nINVESTIGATE:\n1. Which tasks can run in parallel (no dependencies between them)?\n2. Which tasks must be sequential (Task B depends on Task A output)?\n3. Are there any circular dependencies or blocking issues?\n4. What is the critical path?\n\nReturn:\n- Recommended batch structure for parallel execution\n- Maximum concurrent agents\n- Any blocking issues that prevent parallelization\n```\n\n### Agent 2: TDD & Over-Engineering Check\n\n```\nVerify TDD discipline in this implementation plan.\n\nCHECK each task for:\n1. Tests written BEFORE implementation (RED phase)\n2. Step to run test and verify it fails\n3. Minimal implementation to make test pass (GREEN phase)\n4. Tests focus on behavior, not implementation details\n\nLOOK FOR over-engineering:\n- Excessive mocking (testing implementation vs behavior)\n- Too many abstraction layers\n- Defensive code for impossible scenarios\n- Premature optimization\n\nReturn: TDD adherence assessment and over-engineering concerns.\n```\n\n### Agent 3: Type & API Verification\n\n```\nVerify types and APIs in the plan match the actual codebase.\n\nSEARCH the codebase for:\n1. All types referenced in the plan's code blocks\n2. Existing type definitions\n3. API endpoint contracts (request/response shapes)\n4. Import paths\n\nVERIFY:\n1. All properties referenced exist in the types\n2. Enum values match between plan and codebase\n3. Import paths are correct\n4. No type mismatches\n\nReturn: List of mismatches with file:line references.\n```\n\n### Agent 4: Library Best Practices\n\n```\nVerify library usage in this plan follows best practices.\n\nFor each library referenced:\n1. Are function signatures correct for current versions?\n2. Are there deprecated APIs being used?\n3. Does usage follow library documentation?\n4. Are installation commands correct?\n\nCheck against loaded skills for technology-specific guidance.\n\nReturn: Incorrect API usage with recommendations.\n```\n\n### Agent 5: Security & Edge Cases\n\n```\nCheck for security gaps and missing error handling.\n\nVERIFY:\n1. Input validation at system boundaries\n2. Error handling in API/DB operations\n3. Auth/authz checks where needed\n4. Edge cases are handled\n\nReturn: Security gaps and missing error handling.\n```\n\n## Step 4: Synthesize Report\n\nAfter all agents complete, create consolidated report:\n\n```markdown\n## Plan Review: [Feature Name from plan]\n\n**Plan:** `[path to plan file]`\n**Tech Stack:** [Detected technologies]\n\n### Summary Table\n\n| Criterion | Status | Notes |\n|-----------|--------|-------|\n| Parallelization |  GOOD /  ISSUES | [Brief note] |\n| TDD Adherence |  GOOD /  ISSUES | [Brief note] |\n| Type/API Match |  GOOD /  ISSUES | [Brief note] |\n| Library Practices |  GOOD /  ISSUES | [Brief note] |\n| Security/Edge Cases |  GOOD /  ISSUES | [Brief note] |\n\n### Issues Found\n\n#### Critical (Must Fix Before Execution)\n\n1. [Task N, Step M] ISSUE_CODE\n   - Issue: What's wrong\n   - Why: Impact if not fixed\n   - Fix: Specific change\n   - Suggested edit:\n   ```\n   [replacement content]\n   ```\n\n#### Major (Should Fix)\n\n2. [Task N] ISSUE_CODE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n#### Minor (Nice to Have)\n\n3. [Task N] ISSUE_CODE\n   - Issue: ...\n   - Fix: ...\n\n### Verdict\n\n**Ready to execute?** Yes | With fixes (1-N) | No\n\n**Reasoning:** [1-2 sentence assessment]\n```\n\n## Step 5: Save Review and Prompt\n\n**Save review** to same directory as plan:\n- Plan: `docs/plans/2025-01-15-feature.md`\n- Review: `docs/plans/2025-01-15-feature-review.md`\n\n**Review file header:**\n\n```markdown\n# Plan Review: [Feature Name]\n\n> **To apply fixes:** Open new session, run:\n> `Read this file, then apply the suggested fixes to [plan path]`\n\n**Reviewed:** [Current date/time]\n**Verdict:** [Yes | With fixes (1-N) | No]\n\n---\n```\n\n**Prompt user:**\n\n```markdown\n---\n\n## Next Steps\n\n**Review saved to:** `[review file path]`\n\n**Options:**\n\n1. **Apply fixes now** - Edit the plan file to address issues\n2. **Save & fix later** - Open new session to apply fixes\n3. **Proceed anyway** - Execute plan despite issues (not recommended for Critical)\n\nWhich option?\n```\n\n## Rules\n\n- Load skills BEFORE launching agents\n- All 5 agents run in parallel via Task tool\n- Reference Task:Step for each issue\n- Provide copyable suggested edits for Critical/Major issues\n- Save review before prompting user\n- Never auto-execute plan; require user choice\n- Number issues sequentially (1, 2, 3...)\n",
        "commands/review-python.md": "---\ndescription: Comprehensive Python/FastAPI backend code review with optional parallel agents\n---\n\n# Backend Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.py$'\n```\n\n## Step 2: Verify Linter Status\n\n**CRITICAL**: Run project linters BEFORE flagging any style or type issues.\n\n```bash\n# Check if ruff config exists and run it\nif [ -f \"pyproject.toml\" ] || [ -f \"ruff.toml\" ]; then\n    ruff check <changed_files>\nfi\n\n# Check if mypy config exists and run it\nif [ -f \"pyproject.toml\" ] || [ -f \"mypy.ini\" ]; then\n    mypy <changed_files>\nfi\n```\n\n**Rules:**\n- If a linter passes for a specific rule (e.g., line length), DO NOT flag that issue manually\n- Linter configuration is authoritative for style rules\n- Only flag issues that linters cannot detect (semantic issues, architectural problems)\n\n**Why:** Analysis of 24 review outcomes showed 4 false positives (17%) where reviewers flagged line-length violations that `ruff check` confirmed don't exist. The linter's configuration reflects intentional project decisions.\n\n## Step 3: Detect Technologies\n\n```bash\n# Detect Pydantic-AI\ngrep -r \"pydantic_ai\\|@agent\\.tool\\|RunContext\" --include=\"*.py\" -l | head -3\n\n# Detect SQLAlchemy\ngrep -r \"from sqlalchemy\\|Session\\|relationship\" --include=\"*.py\" -l | head -3\n\n# Detect Postgres-specific\ngrep -r \"psycopg\\|asyncpg\\|JSONB\\|GIN\" --include=\"*.py\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E 'test.*\\.py$'\n```\n\n## Step 4: Load Verification Protocol\n\nLoad `beagle:review-verification-protocol` skill and keep its checklist in mind throughout the review.\n\n## Step 5: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:python-code-review\")`).\n\n**Always load:**\n- `beagle:python-code-review`\n- `beagle:fastapi-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| Test files changed | `beagle:pytest-code-review` |\n| Pydantic-AI detected | `beagle:pydantic-ai-common-pitfalls` |\n| SQLAlchemy detected | `beagle:sqlalchemy-code-review` |\n| Postgres detected | `beagle:postgres-code-review` |\n\n## Step 6: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review Python quality issues first\n3. Review FastAPI patterns\n4. Review detected technology areas\n5. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn one subagent per technology area with `Task` tool\n3. Each agent loads its skill and reviews its domain\n4. Wait for all agents\n5. Consolidate findings\n\n### Before Flagging Optimization or Pattern Issues\n\n1. **Check CLAUDE.md** for documented intentional patterns\n2. **Check code comments** around the flagged area for \"intentional\", \"optimization\", or \"NOTE:\"\n3. **Trace the code path** before claiming missing coverage or inconsistent handling\n4. **Consider framework idioms** - what looks wrong generically may be correct for the framework\n\n**Why:** Analysis showed rejections where reviewers flagged \"inconsistent error handling\" that was intentional optimization, and \"missing test coverage\" for code paths that don't exist.\n\n## Step 7: Verify Findings\n\nBefore reporting any issue:\n1. Re-read the actual code (not just diff context)\n2. For \"unused\" claims - did you search all references?\n3. For \"missing\" claims - did you check framework/parent handling?\n4. For syntax issues - did you verify against current version docs?\n5. Remove any findings that are style preferences, not actual issues\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (bug, type safety, security)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\nruff check .\nmypy .\npytest\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Run verification after fixes\n",
        "commands/review-tui.md": "---\ndescription: Comprehensive BubbleTea TUI code review for terminal applications\n---\n\n# TUI Code Review\n\n## Arguments\n\n- `--parallel`: Spawn specialized subagents per technology area\n- Path: Target directory (default: current working directory)\n\n## Step 1: Identify Changed Files\n\n```bash\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '\\.go$'\n```\n\n## Step 2: Detect Technologies\n\n```bash\n# Detect BubbleTea (required for TUI review)\ngrep -r \"charmbracelet/bubbletea\" --include=\"*.go\" -l | head -3\n\n# Detect Lipgloss styling\ngrep -r \"charmbracelet/lipgloss\\|lipgloss\\.Style\" --include=\"*.go\" -l | head -3\n\n# Detect Bubbles components\ngrep -r \"charmbracelet/bubbles\\|list\\.Model\\|textinput\\.Model\\|viewport\\.Model\" --include=\"*.go\" -l | head -3\n\n# Detect Wish SSH server\ngrep -r \"charmbracelet/wish\\|ssh\\.Session\" --include=\"*.go\" -l | head -3\n\n# Check for test files\ngit diff --name-only $(git merge-base HEAD main)..HEAD | grep -E '_test\\.go$'\n```\n\n## Step 3: Load Verification Protocol\n\nLoad `beagle:review-verification-protocol` skill and keep its checklist in mind throughout the review.\n\n## Step 4: Load Skills\n\nUse the `Skill` tool to load each applicable skill (e.g., `Skill(skill: \"beagle:go-code-review\")`).\n\n**Always load:**\n- `beagle:go-code-review`\n- `beagle:bubbletea-code-review`\n\n**Conditionally load based on detection:**\n\n| Condition | Skill |\n|-----------|-------|\n| Test files changed | `beagle:go-testing-code-review` |\n| Wish SSH detected | `beagle:wish-ssh-code-review` |\n\n## Step 5: Review Focus Areas\n\n### Model/Update/View (Elm Architecture)\n\n- [ ] Model is immutable (Update returns new model)\n- [ ] Init returns proper initial command\n- [ ] Update handles all message types\n- [ ] View is pure function (no side effects)\n- [ ] tea.Quit used correctly for exit\n\n### Lipgloss Styling\n\n- [ ] Styles defined once at package level\n- [ ] Styles not created in View function\n- [ ] Colors use AdaptiveColor for light/dark themes\n- [ ] Layout responds to WindowSizeMsg\n\n### Component Composition\n\n- [ ] Sub-component updates propagated\n- [ ] WindowSizeMsg passed to resizable components\n- [ ] Focus management for multiple components\n- [ ] Clear state machine for view transitions\n\n### SSH Server (if applicable)\n\n- [ ] Host keys persisted\n- [ ] Graceful shutdown implemented\n- [ ] PTY window size passed to TUI\n- [ ] Per-session Lipgloss renderer\n\n## Step 6: Review\n\n**Sequential (default):**\n1. Load applicable skills\n2. Review Go code quality\n3. Review BubbleTea patterns (Model/Update/View)\n4. Review Lipgloss styling\n5. Review component composition\n6. Review SSH server (if applicable)\n7. Consolidate findings\n\n**Parallel (--parallel flag):**\n1. Detect all technologies upfront\n2. Spawn subagents for: Go quality, BubbleTea, SSH\n3. Wait for all agents\n4. Consolidate findings\n\n## Step 7: Verify Findings\n\nBefore reporting any issue:\n1. Re-read the actual code (not just diff context)\n2. For \"unused\" claims - did you search all references?\n3. For \"missing\" claims - did you check framework/parent handling?\n4. For syntax issues - did you verify against current version docs?\n5. Remove any findings that are style preferences, not actual issues\n\n## Output Format\n\n```markdown\n## Review Summary\n\n[1-2 sentence overview of findings]\n\n## Issues\n\n### Critical (Blocking)\n\n1. [FILE:LINE] ISSUE_TITLE\n   - Issue: Description of what's wrong\n   - Why: Why this matters (UI freeze, crash, resource leak)\n   - Fix: Specific recommended fix\n\n### Major (Should Fix)\n\n2. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n### Minor (Nice to Have)\n\nN. [FILE:LINE] ISSUE_TITLE\n   - Issue: ...\n   - Why: ...\n   - Fix: ...\n\n## Good Patterns\n\n- [FILE:LINE] Pattern description (preserve this)\n\n## Verdict\n\nReady: Yes | No | With fixes 1-N\nRationale: [1-2 sentences]\n```\n\n## Post-Fix Verification\n\nAfter fixes are applied, run:\n\n```bash\ngo build ./...\ngo vet ./...\ngolangci-lint run\ngo test -v -race ./...\n```\n\nAll checks must pass before approval.\n\n## Rules\n\n- Load skills BEFORE reviewing (not after)\n- Number every issue sequentially (1, 2, 3...)\n- Include FILE:LINE for each issue\n- Separate Issue/Why/Fix clearly\n- Categorize by actual severity\n- Pay special attention to:\n  - Blocking operations in Update (freezes UI)\n  - Style creation in View (performance)\n  - Missing WindowSizeMsg handling (broken resize)\n- Run verification after fixes\n",
        "commands/run-test-plan.md": "---\ndescription: Execute YAML test plan, stop on first failure, output rich debug prompt\n---\n\n# Run Test Plan\n\nExecute a YAML test plan, run setup commands, health checks, and each test sequentially. Stop on first failure with rich debug output.\n\n## Prerequisites\n\n- **agent-browser skill**: Browser tests require the `agent-browser:agent-browser` skill to be available\n\n## Arguments\n\n- `--plan <path>`: Path to test plan (default: `docs/testing/test-plan.yaml`)\n- `--skip-setup`: Skip setup commands and health checks (for re-running after failure)\n\n## Step 1: Parse Test Plan\n\nRead and validate the test plan:\n\n```bash\n# Check file exists\nls docs/testing/test-plan.yaml || { echo \"Error: Test plan not found\"; exit 1; }\n\n# Validate YAML\npython3 -c \"import yaml; yaml.safe_load(open('docs/testing/test-plan.yaml'))\" || { echo \"Error: Invalid YAML\"; exit 1; }\n```\n\nExtract from the YAML:\n- `setup.commands`: List of setup commands\n- `setup.health_checks`: List of URLs to poll\n- `tests`: Array of test cases\n\n## Step 2: Run Setup Commands (unless --skip-setup)\n\nExecute setup commands sequentially:\n\n```bash\n# For each command in setup.commands\n<command> || { echo \"Setup failed: <command>\"; exit 1; }\n```\n\nFor commands that start services (e.g., `pnpm run dev`, `docker-compose up -d`):\n- Run in background\n- Capture PID for cleanup\n- Continue to health checks\n\n```bash\n# Start dev servers in background\nnohup <dev_command> > .beagle/dev-server.log 2>&1 &\necho $! > .beagle/dev-server.pid\n```\n\n## Step 3: Run Health Checks\n\nPoll each health check URL until healthy or timeout:\n\n```bash\n# For each health_check\ntimeout=<health_check.timeout or 30>\nurl=<health_check.url>\nelapsed=0\n\nwhile [ $elapsed -lt $timeout ]; do\n  if curl -s -o /dev/null -w \"%{http_code}\" \"$url\" | grep -qE \"^(200|301|302)\"; then\n    echo \" Health check passed: $url\"\n    break\n  fi\n  sleep 2\n  elapsed=$((elapsed + 2))\ndone\n\nif [ $elapsed -ge $timeout ]; then\n  echo \" Health check timeout: $url\"\n  exit 1\nfi\n```\n\n## Step 4: Execute Tests Sequentially\n\nFor each test in the plan:\n\n### 4a. Log Test Start\n\n```markdown\n## Running: TC-XX - <test.name>\n\nContext: <test.context>\n```\n\n### 4b. Execute Steps\n\nFor each step in `test.steps`:\n\n**curl actions:**\n```bash\ncurl -X <method> \\\n  -H \"Content-Type: application/json\" \\\n  <additional headers> \\\n  -d '<body>' \\\n  \"<url>\" \\\n  -o response.json \\\n  -w \"%{http_code}\" > status_code.txt\n\n# Capture response for evaluation\ncat response.json\ncat status_code.txt\n```\n\n**agent-browser actions:**\n\nLoad the `agent-browser:agent-browser` skill and delegate browser actions:\n\n```\nSkill(skill: \"agent-browser:agent-browser\")\n```\n\nExecute browser actions according to the skill's capabilities:\n- `agent-browser open`: Navigate to URL\n- `agent-browser fill`: Fill form field by ref\n- `agent-browser click`: Click element by ref\n- `agent-browser wait`: Wait for condition (url, element, etc.)\n- `agent-browser snapshot`: Capture screenshot\n\nSave screenshots to `docs/testing/evidence/<test.id>.png`\n\n### 4c. Evaluate Result\n\nUsing agent reasoning, compare actual outcome against `test.expected`:\n\n- Read the expected behavior description\n- Compare with actual response/screenshot\n- Determine PASS or FAIL\n\n### 4d. On PASS\n\n```markdown\n TC-XX PASSED: <test.name>\n```\n\nContinue to next test.\n\n### 4e. On FAIL\n\nStop immediately. Go to Step 6.\n\n## Step 5: On All Tests Pass\n\n```markdown\n## Test Results: ALL PASSED\n\n| ID | Name | Result |\n|----|------|--------|\n| TC-01 | <name> |  PASS |\n| TC-02 | <name> |  PASS |\n| ... | ... | ... |\n\n**Total:** N/N tests passed\n\n### Evidence\n\nScreenshots saved to `docs/testing/evidence/`\n\n### Cleanup\n\nStopping background services...\n```\n\nClean up:\n```bash\n# Kill dev servers\nif [ -f .beagle/dev-server.pid ]; then\n  kill $(cat .beagle/dev-server.pid) 2>/dev/null\n  rm .beagle/dev-server.pid\nfi\n```\n\n## Step 6: On Failure - Generate Debug Prompt\n\nWhen a test fails, generate rich debug output:\n\n### 6a. Gather Context\n\n```bash\n# Get changed files relevant to the failure\ngit diff --name-only $(git merge-base HEAD origin/main)..HEAD\n\n# Get recent changes in files mentioned in test.context\ngit diff $(git merge-base HEAD origin/main)..HEAD -- <relevant_files>\n```\n\n### 6b. Output Debug Report\n\n```markdown\n## Test Failure: TC-XX - <test.name>\n\n### What Failed\n\n**Test:** <test.name>\n**Expected:**\n<test.expected>\n\n**Actual:**\n<Describe what actually happened - response code, error message, screenshot description>\n\n### Relevant Changes in This PR\n\n<For each file mentioned in test.context or related to the failure:>\n- `<file>` (lines X-Y) - <brief description of changes>\n\n### Evidence\n\n<If screenshot exists:>\n- Screenshot: `docs/testing/evidence/<test.id>.png`\n\n<If API response:>\n- Status code: <code>\n- Response body:\n```json\n<response>\n```\n\n### Error Details\n\n<If error message in response or logs:>\n```\n<error message>\n```\n\n### Suggested Investigation\n\n<Based on the error, suggest 2-3 specific things to check:>\n1. <First thing to check based on error type>\n2. <Second thing related to changed files>\n3. <Third thing about environment/setup>\n\n### Debug Session Prompt\n\nCopy this to start a new Claude session:\n\n---\nI'm debugging a test failure in branch `<branch>`.\n\n**Test:** <test.name>\n**Error:** <brief error description>\n\n<Summarize what the test was checking and what went wrong>\n\nRelevant files:\n<List changed files related to this test>\n\nHelp me investigate why <specific failure reason>.\n---\n```\n\n### 6c. Preserve Evidence\n\n```bash\n# Ensure evidence directory exists\nmkdir -p docs/testing/evidence\n\n# Save failure context\ncat > docs/testing/evidence/<test.id>-failure.md << 'EOF'\n# Failure Report: <test.id>\n\n<Full debug report content>\nEOF\n```\n\n### 6d. Cleanup and Exit\n\n```bash\n# Kill dev servers\nif [ -f .beagle/dev-server.pid ]; then\n  kill $(cat .beagle/dev-server.pid) 2>/dev/null\n  rm .beagle/dev-server.pid\nfi\n```\n\n## Test Results Summary Table\n\nAlways output a summary table showing progress:\n\n```markdown\n## Test Results\n\n| ID | Name | Result |\n|----|------|--------|\n| TC-01 | <name> |  PASS |\n| TC-02 | <name> |  FAIL |\n| TC-03 | <name> | - SKIP |\n\n**Passed:** 1/3\n**Failed:** TC-02\n```\n\nTests after a failure are marked as SKIP (not executed).\n\n## Verification\n\nBefore completing:\n\n```bash\n# Verify evidence directory exists\nls -la docs/testing/evidence/\n\n# List captured evidence\nls docs/testing/evidence/*.png docs/testing/evidence/*.md 2>/dev/null\n```\n\n**Verification Checklist:**\n- [ ] Setup commands executed successfully\n- [ ] Health checks passed before test execution\n- [ ] Each executed test has recorded result\n- [ ] Evidence captured in `docs/testing/evidence/`\n- [ ] On failure: debug prompt includes expected vs actual\n- [ ] On failure: relevant PR changes listed\n- [ ] Background processes cleaned up\n\n## Rules\n\n- Stop on first test failure (do not continue to other tests)\n- Always capture evidence (screenshots, responses)\n- Include file:line references in debug prompts when possible\n- Use `--skip-setup` flag to re-run after fixing issues\n- Never hardcode secrets - use environment variables\n- Clean up background processes even on failure\n- Preserve failure evidence for debugging\n- Make debug prompts copy-paste ready for new sessions\n",
        "commands/skill-builder.md": "---\ndescription: create claude code skills with comprehensive best practices and patterns\n---\n# Skill Builder\n\nCreate, validate, and refine Claude Code skills following official best practices.\n\n## Workflow Overview\n\n```\n1. Gather Requirements  2. Design Structure  3. Write SKILL.md  4. Add Supporting Files  5. Validate  6. Test\n```\n\n## Instructions\n\n### Phase 1: Gather Requirements\n\nBefore writing any skill, collect this information from the user:\n\n**Required:**\n- What capability should the skill provide?\n- When should Claude invoke this skill (triggers)?\n- What domain knowledge is needed that Claude doesn't have?\n\n**Optional:**\n- Are there utility scripts needed?\n- Should tool access be restricted (`allowed-tools`)?\n- What files/references should be included?\n\nAsk clarifying questions if the scope is unclear. Skills should be focused on one capability.\n\n### Phase 2: Design the Structure\n\nDetermine the skill complexity:\n\n**Simple Skill (single file):**\n```\nskill-name/\n SKILL.md\n```\n\nUse when: Single capability, no scripts, under 200 lines of content.\n\n**Multi-file Skill (progressive disclosure):**\n```\nskill-name/\n SKILL.md           # Overview + navigation (under 500 lines)\n reference.md       # Detailed API/schema info\n examples.md        # Extended examples\n scripts/           # Utility scripts\n     helper.py\n     validate.py\n```\n\nUse when: Complex domain, multiple sub-capabilities, utility scripts needed.\n\n### Phase 3: Write SKILL.md\n\n#### Frontmatter Requirements\n\n```yaml\n---\nname: skill-name-here\ndescription: What it does and when to use it. Include trigger keywords.\nallowed-tools: Read, Grep, Glob  # Optional: restrict tool access\n---\n```\n\n**Name rules:**\n- Lowercase letters, numbers, hyphens only\n- Maximum 64 characters\n- Use gerund form preferred: `processing-pdfs`, `generating-commits`\n- No reserved words: \"anthropic\", \"claude\"\n\n**Description rules:**\n- Maximum 1024 characters\n- Write in third person: \"Processes X\" not \"I can process X\"\n- Include BOTH what it does AND when to use it\n- Include trigger keywords users would naturally say\n\n**Description pattern:**\n```\n<what it does>. <trigger conditions>.\n```\n\n**Good examples:**\n```yaml\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n\ndescription: Analyze Excel spreadsheets, create pivot tables, generate charts. Use when analyzing Excel files, spreadsheets, tabular data, or .xlsx files.\n\ndescription: Generate descriptive commit messages by analyzing git diffs. Use when the user asks for help writing commit messages or reviewing staged changes.\n```\n\n**Bad examples:**\n```yaml\ndescription: Helps with documents  # Too vague\ndescription: I can process data    # Wrong person, too vague\ndescription: Does stuff with files # Useless\n```\n\n#### Body Structure\n\nUse this template:\n\n```markdown\n# Skill Name\n\n## Quick Start\n\n<Minimal working example - 3-5 lines max>\n\n## Instructions\n\n<Step-by-step guidance - be specific about WHAT to do>\n\n## Workflows\n\n<For complex tasks, provide checklists Claude can track>\n\n## Examples\n\n<Input/output pairs showing desired style and output>\n\n## Advanced\n\n<Link to additional files if needed>\nFor detailed reference, see [reference.md](reference.md).\n```\n\n### Phase 4: Apply Best Practices\n\n#### Conciseness Principle\n\n**Default assumption:** Claude is already very smart.\n\nOnly add context Claude doesn't have. Challenge each piece of information:\n- \"Does Claude really need this explanation?\"\n- \"Can I assume Claude knows this?\"\n- \"Does this paragraph justify its token cost?\"\n\n**Bad (verbose):**\n```markdown\nPDF (Portable Document Format) files are a common file format that contains\ntext, images, and other content. To extract text from a PDF, you'll need to\nuse a library. There are many libraries available...\n```\n\n**Good (concise):**\n```markdown\nUse pdfplumber for text extraction:\n\\`\\`\\`python\nimport pdfplumber\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n\\`\\`\\`\n```\n\n#### Degrees of Freedom\n\nMatch specificity to task fragility:\n\n**High freedom** (text-based instructions) - when multiple approaches are valid:\n```markdown\n## Code review process\n1. Analyze the code structure and organization\n2. Check for potential bugs or edge cases\n3. Suggest improvements for readability\n```\n\n**Low freedom** (exact commands) - when operations are fragile:\n```markdown\n## Database migration\nRun exactly this script:\n\\`\\`\\`bash\npython scripts/migrate.py --verify --backup\n\\`\\`\\`\nDo not modify the command or add additional flags.\n```\n\n#### Feedback Loops\n\nFor quality-critical tasks, add validation steps:\n\n```markdown\n## Editing Process\n1. Make your edits\n2. **Validate immediately**: `python scripts/validate.py`\n3. If validation fails:\n   - Review the error message\n   - Fix the issues\n   - Run validation again\n4. **Only proceed when validation passes**\n```\n\n#### Checklists for Complex Workflows\n\nProvide copyable checklists:\n\n````markdown\n## Form Filling Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Analyze the form\n- [ ] Step 2: Create field mapping\n- [ ] Step 3: Validate mapping\n- [ ] Step 4: Fill the form\n- [ ] Step 5: Verify output\n```\n````\n\n#### Examples Pattern\n\nShow input/output pairs for style guidance:\n\n````markdown\n## Commit Message Format\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n````\n\n#### Progressive Disclosure\n\nReference additional files instead of including everything:\n\n```markdown\n## Advanced Features\n\n**Form filling**: See [FORMS.md](FORMS.md) for complete guide\n**API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n**Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\n**Critical:** Keep references one level deep from SKILL.md. Don't create chains of references.\n\n### Phase 5: Validation Checklist\n\nBefore finalizing, verify:\n\n**Core Quality:**\n- [ ] Description is specific and includes trigger keywords\n- [ ] Description includes both what it does AND when to use it\n- [ ] Description is written in third person\n- [ ] Name uses lowercase-hyphen format\n- [ ] SKILL.md body is under 500 lines\n- [ ] No time-sensitive information\n- [ ] Consistent terminology throughout\n- [ ] Examples are concrete, not abstract\n- [ ] File references are one level deep\n- [ ] Workflows have clear steps\n\n**Technical:**\n- [ ] Valid YAML frontmatter (no tabs, correct syntax)\n- [ ] No Windows-style paths (use forward slashes)\n- [ ] Required packages listed if applicable\n- [ ] Scripts have explicit error handling\n\n**If using `allowed-tools`:**\n- [ ] Only necessary tools are listed\n- [ ] Tool names are correct (Read, Grep, Glob, Edit, Write, Bash, etc.)\n\n### Phase 6: Test the Skill\n\nAfter creating the skill:\n\n1. **Place in correct location:**\n   - Personal: `~/.claude/skills/skill-name/SKILL.md`\n   - Project: `.claude/skills/skill-name/SKILL.md`\n\n2. **Restart Claude Code** to load the skill\n\n3. **Test with natural language** that matches your description triggers:\n   ```\n   User: \"Help me extract text from this PDF\"\n    Should invoke skill with \"PDF\" trigger\n   ```\n\n4. **Verify Claude navigates correctly** to reference files when needed\n\n5. **Iterate based on observation:**\n   - Does Claude find the right information?\n   - Does Claude apply rules correctly?\n   - Are there missing examples or edge cases?\n\n## Anti-Patterns to Avoid\n\n**DON'T:**\n- Use Windows-style paths (`scripts\\helper.py`)\n- Offer too many options without a default\n- Include time-sensitive information\n- Use inconsistent terminology\n- Create deeply nested file references\n- Assume tools are installed without documenting\n- Write overly verbose explanations Claude already knows\n- Use first or second person in descriptions\n\n**DO:**\n- Provide a single recommended approach with alternatives noted\n- Use consistent terminology throughout\n- Structure longer files with table of contents\n- Document package requirements explicitly\n- Trust Claude's existing knowledge\n- Write descriptions that help Claude select the right skill\n\n## Template: Simple Skill\n\n```yaml\n---\nname: your-skill-name\ndescription: <What it does>. Use when <trigger conditions>.\n---\n\n# Your Skill Name\n\n## Quick Start\n\n<Minimal example - get user productive immediately>\n\n## Instructions\n\n<Clear, numbered steps for common use cases>\n\n## Examples\n\n<2-3 input/output examples showing desired style>\n```\n\n## Template: Multi-File Skill\n\n**SKILL.md:**\n```yaml\n---\nname: your-skill-name\ndescription: <What it does>. Use when <trigger conditions>.\n---\n\n# Your Skill Name\n\n## Quick Start\n\n<Minimal example>\n\n## Common Tasks\n\n### Task A\n<Brief instructions>\n\n### Task B\n<Brief instructions>\n\n## Advanced\n\n- **Full reference**: See [reference.md](reference.md)\n- **Examples**: See [examples.md](examples.md)\n- **Utility scripts**: See [scripts/](scripts/)\n```\n\n**reference.md:**\n```markdown\n# Reference\n\n## Contents\n- Section A\n- Section B\n- Section C\n\n## Section A\n<Detailed content>\n...\n```\n\n## Example Output\n\nAfter gathering requirements for a \"code-review\" skill:\n\n```\nCreated skill: .claude/skills/reviewing-code/\n\nFiles:\n SKILL.md (245 lines) - Core instructions and checklists\n security-patterns.md - Common security issues to check\n examples.md - Example review outputs\n\nDescription: \"Reviews code changes for production readiness, checking code quality, architecture, testing, and security. Use when reviewing PRs, checking code before merge, or auditing code quality.\"\n\nNext steps:\n1. Review the generated files\n2. Restart Claude Code to load the skill\n3. Test with: \"Review the changes in my current branch\"\n```\n\n## Guidelines\n\n**When the user asks for a skill:**\n1. Ask clarifying questions about scope and triggers\n2. Propose the structure (simple vs multi-file)\n3. Write the SKILL.md following all patterns above\n4. Run through the validation checklist\n5. Explain how to test the skill\n\n**Iterative refinement:**\nIf the user reports the skill isn't working:\n1. Check if description triggers match user's natural language\n2. Verify YAML syntax is valid\n3. Ensure file paths are correct\n4. Review if instructions are clear enough for the task\n",
        "commands/write-adr.md": "---\ndescription: Generate ADRs from decisions made in the current session. Extracts decisions, confirms with user, writes MADR-formatted documents.\n---\n\n# Write ADR\n\nGenerate Architecture Decision Records (ADRs) from decisions made during the current session.\n\n## Workflow Overview\n\n1. **Context** - Gather repository context and existing ADRs\n2. **Extract** - Analyze conversation for decisions using a subagent\n3. **Confirm** - Present decisions to user for selection\n4. **Write** - Generate ADRs in parallel using subagents\n5. **Report** - Summarize created files and status\n6. **Verify** - Validate generated ADRs against Definition of Done\n\n## Step 1: Gather Context\n\n```bash\n# Get current branch and recent commits\ngit branch --show-current\ngit log --oneline -5\n\n# Check for existing ADRs\nls docs/adrs/ 2>/dev/null || echo \"No ADR directory found\"\n\n# Count existing ADRs for numbering\nfind docs/adrs -name \"*.md\" 2>/dev/null | wc -l\n```\n\nThis context helps the ADR writer:\n- Reference related commits in the ADR\n- Avoid duplicate ADRs for already-documented decisions\n- Determine correct sequence numbering\n\n## Step 2: Extract Decisions\n\nLaunch a subagent to analyze the current conversation for architectural decisions:\n\n```text\nTask(\n  description: \"Analyze conversation and extract architectural decisions\",\n  model: \"sonnet\",\n  prompt: |\n    Load the skill: Skill(skill: \"beagle:adr-decision-extraction\")\n\n    Analyze the conversation for decisions that warrant ADRs:\n    - Technology choices, architecture patterns, design trade-offs\n    - Rejected alternatives, significant implementation approaches\n\n    Return JSON:\n    {\n      \"decisions\": [\n        {\n          \"id\": 1,\n          \"title\": \"Use PostgreSQL for primary datastore\",\n          \"context\": \"Brief context about why this came up\",\n          \"decision\": \"What was decided\",\n          \"alternatives\": [\"What was considered but rejected\"],\n          \"rationale\": \"Why this choice was made\"\n        }\n      ]\n    }\n)\n```\n\nIf the subagent returns an empty `decisions` array, skip to Step 5 with message: \"No architectural decisions detected in this session.\"\n\n## Step 3: Confirm with User\n\n**Display all extracted decisions with full details**, then ask user to select:\n\n```text\n## Detected Decisions\n\n### 1. Use PostgreSQL for primary datastore\n**Confidence:** high\n\n**Problem:** Need ACID transactions for financial records\n\n**Decision:** PostgreSQL for user data storage\n\n**Alternatives discussed:**\n- MongoDB\n- SQLite\n\n**Rationale:** ACID compliance, team familiarity, mature ecosystem\n\n**Source:** Discussion about database selection in planning phase\n\n---\n\n### 2. Implement event sourcing for audit trail\n**Confidence:** medium\n\n**Problem:** Compliance requires complete audit history\n\n**Decision:** Event sourcing pattern for state changes\n\n**Alternatives discussed:**\n- Database triggers\n- Application-level logging\n\n**Rationale:** Immutable audit trail, temporal queries, debugging capability\n\n**Source:** Compliance requirements discussion\n\n---\n\n## Selection\n\nWhich decisions should I write ADRs for?\n- Enter numbers (e.g., \"1,2\" or \"1-2\"), \"all\", or \"none\" to skip\n```\n\n**Important:** Always display the full decision details (problem, decision, alternatives, rationale) from the extraction output BEFORE asking for selection. Do not truncate to just title and context.\n\nParse user response:\n- `\"all\"` - Process all decisions\n- `\"none\"` or empty - Skip with message \"No ADRs will be created.\"\n- `\"1,2\"` or `\"1-2\"` - Process specified decisions\n\n## Step 4: Write ADRs (Parallel)\n\n**Pre-allocate ADR numbers before launching subagents** to prevent numbering conflicts:\n\n```bash\n# Pre-allocate numbers for all confirmed decisions\n# Example: If user selected 3 decisions\npython skills/adr-writing/scripts/next_adr_number.py --count 3\n# Output:\n# 0003\n# 0004\n# 0005\n```\n\n**Assign each pre-allocated number to its corresponding decision** before launching subagents.\n\nFor each confirmed decision, launch an ADR Writer subagent in background with its **pre-assigned number**:\n\n```text\nTask(\n  description: \"Write ADR for: {decision.title}\",\n  model: \"sonnet\",\n  run_in_background: true,\n  prompt: |\n    Load the skill: Skill(skill: \"beagle:adr-writing\")\n\n    Write an ADR for this decision:\n    ```json\n    {decision JSON}\n    ```\n\n    **IMPORTANT: Use this pre-assigned ADR number: {assigned_number}**\n\n    Instructions:\n    1. Explore codebase for additional context\n    2. Write MADR-formatted ADR to docs/adr/\n    3. Use the pre-assigned number {assigned_number} - DO NOT call next_adr_number.py\n    4. Filename format: {assigned_number}-slugified-title.md\n    5. Return created file path\n)\n```\n\n**Critical:** Pass the pre-allocated number to each subagent. Subagents must NOT call `next_adr_number.py` themselves - this causes duplicate numbers when running in parallel.\n\nAll subagents run in parallel. Wait for all to complete before proceeding.\n\n## Step 5: Report Results\n\nCollect outputs from all subagents and present summary:\n\n```markdown\n## ADR Generation Complete\n\n| File | Decision | Status |\n|------|----------|--------|\n| docs/adr/0003-use-postgresql.md | Use PostgreSQL for primary datastore | Draft |\n\n### Next Steps\n- Review generated ADRs for accuracy\n- Update status from \"proposed\" to \"accepted\" when finalized\n\n### Gaps Requiring Investigation\n- [List any decisions where subagent noted missing context]\n```\n\nIf no decisions were processed:\n```text\nNo ADRs were created. Run this command again after making architectural decisions.\n```\n\n## Step 6: Verify Generated ADRs\n\nFor each created ADR, validate against Definition of Done:\n\n```markdown\n## Verification Checklist\n\n| ADR | E | C | A | D | R | Status |\n|-----|---|---|---|---|---|--------|\n| 0003-use-postgresql.md |  |  |  |  |  | Incomplete |\n\nLegend: E=Evidence, C=Criteria, A=Agreement, D=Documentation, R=Realization\n```\n\n**Verification steps:**\n1. Open each generated ADR file\n2. Confirm filename follows `NNNN-slugified-title.md` pattern\n3. **Verify YAML frontmatter exists at file start:**\n   - File MUST begin with `---`\n   - Contains `status: draft` (or valid status)\n   - Contains `date: YYYY-MM-DD` (actual date)\n   - Ends with `---` before title\n   - If frontmatter is missing, add it immediately\n4. Review for `[INVESTIGATE]` prompts - these need follow-up\n5. Verify at least 2 alternatives are documented\n6. Confirm consequences section has both Good and Bad items\n\n**If gaps exist:**\n- Keep status as `draft` until gaps are resolved\n- Use `[INVESTIGATE]` prompts to guide follow-up session\n- Schedule review with stakeholders before changing to `accepted`\n\n## Output Location\n\nADRs are written to `docs/adr/`. If no ADR directory exists, create it with an initial `0000-use-madr.md` template record.\n\n## MADR Format Reference\n\n```markdown\n---\nstatus: draft\ndate: YYYY-MM-DD\n---\n\n# {TITLE}\n\n## Context and Problem Statement\n\n{What is the issue motivating this decision?}\n\n## Decision Drivers\n\n* {driver 1}\n* {driver 2}\n\n## Decision Outcome\n\nChosen option: \"{option}\", because {reason}.\n\n### Consequences\n\n* Good, because {positive}\n* Bad, because {negative}\n```\n",
        "skills/12-factor-apps/SKILL.md": "---\nname: 12-factor-apps\ndescription: Perform 12-Factor App compliance analysis on any codebase. Use when evaluating application architecture, auditing SaaS applications, or reviewing cloud-native applications against the original 12-Factor methodology.\n---\n\n# 12-Factor App Compliance Analysis\n\n> Reference: [The Twelve-Factor App](https://12factor.net)\n\n## Overview\n\nThe 12-Factor App methodology is a set of best practices for building Software-as-a-Service applications that are:\n- Portable across execution environments\n- Scalable without architectural changes\n- Suitable for continuous deployment\n- Maintainable with minimal friction\n\n## Input Parameters\n\n| Parameter | Description | Required |\n|-----------|-------------|----------|\n| `codebase_path` | Root path of the codebase to analyze | Required |\n\n## Analysis Framework\n\n### Factor I: Codebase\n\n**Principle:** One codebase tracked in revision control, many deploys.\n\n**Search Patterns:**\n```bash\n# Check for version control\nls -la .git 2>/dev/null || ls -la .hg 2>/dev/null\n\n# Check for multiple apps sharing codebase\nfind . -name \"package.json\" -o -name \"pyproject.toml\" -o -name \"setup.py\" | head -20\n\n# Check for environment-specific code branches\ngrep -r \"if.*production\\|if.*development\\|if.*staging\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `.git/`, `package.json`, `pyproject.toml`, deployment configs\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Single Git repo, same codebase for all environments, no env-specific code branches |\n| **Partial** | Single repo but some environment-specific code paths |\n| **Weak** | Multiple repos for same app or significant code duplication across environments |\n\n**Anti-patterns:**\n- Multiple Git repositories for the same application\n- Environment-specific code branches (`if production: ...`)\n- Different source files for dev vs prod\n- Shared code not extracted to libraries\n\n---\n\n### Factor II: Dependencies\n\n**Principle:** Explicitly declare and isolate dependencies.\n\n**Search Patterns:**\n```bash\n# Python dependency files\nfind . -name \"requirements.txt\" -o -name \"pyproject.toml\" -o -name \"setup.py\" -o -name \"Pipfile\" -o -name \"uv.lock\"\n\n# JavaScript/TypeScript dependency files\nfind . -name \"package.json\" -o -name \"package-lock.json\" -o -name \"yarn.lock\" -o -name \"pnpm-lock.yaml\"\n\n# Check for system tool assumptions\ngrep -r \"subprocess.*curl\\|subprocess.*wget\\|os.system.*ffmpeg\\|shutil.which\" --include=\"*.py\"\ngrep -r \"exec.*curl\\|child_process.*curl\" --include=\"*.js\" --include=\"*.ts\"\n\n# Docker/container isolation\nfind . -name \"Dockerfile\" -o -name \"docker-compose*.yml\"\n```\n\n**File Patterns:** `**/requirements*.txt`, `**/package.json`, `**/*.lock`, `**/Dockerfile`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Lock files present, dependency isolation (venv/Docker), no implicit system tools |\n| **Partial** | Dependencies declared but no lock files or isolation |\n| **Weak** | Dependencies in documentation only, relies on system-installed packages |\n\n**Anti-patterns:**\n- Missing lock files (non-deterministic builds)\n- Assuming system tools (curl, ImageMagick, ffmpeg) are available\n- Different dependency managers in dev vs production\n- No virtual environment or container isolation\n\n---\n\n### Factor III: Config\n\n**Principle:** Store config in the environment.\n\n**Search Patterns:**\n```bash\n# Environment variable usage\ngrep -r \"os.environ\\|os.getenv\\|process.env\\|ENV\\[\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" --include=\"*.rb\"\n\n# Hardcoded credentials (anti-pattern)\ngrep -r \"password.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\ngrep -r \"api_key.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\ngrep -r \"secret.*=.*['\\\"]\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\"\n\n# Environment-specific config files (anti-pattern)\nfind . -name \"config.dev.*\" -o -name \"config.prod.*\" -o -name \"settings.development.*\" -o -name \"settings.production.*\"\n\n# Database URLs in code\ngrep -r \"postgresql://\\|mysql://\\|mongodb://\\|redis://\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \".env\\|test\\|example\"\n```\n\n**File Patterns:** `**/.env*`, `**/config/*.py`, `**/settings.py`, environment files\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All config via environment variables, no hardcoded secrets, could open-source without leaks |\n| **Partial** | Most config externalized but some hardcoded defaults |\n| **Weak** | Hardcoded credentials, environment-specific config files |\n\n**Anti-patterns:**\n- Hardcoded database URLs, API keys, passwords in source\n- Config files like `config/production.yml` vs `config/development.yml`\n- Environment grouping (`if ENV == 'production': ...`)\n- Secrets committed to version control\n\n---\n\n### Factor IV: Backing Services\n\n**Principle:** Treat backing services as attached resources.\n\n**Search Patterns:**\n```bash\n# Database connection via config\ngrep -r \"DATABASE_URL\\|DB_HOST\\|REDIS_URL\\|CACHE_URL\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Service initialization\ngrep -r \"create_engine\\|MongoClient\\|Redis\\|Celery\\|boto3\" --include=\"*.py\"\ngrep -r \"createPool\\|createClient\\|new Redis\\|S3Client\" --include=\"*.js\" --include=\"*.ts\"\n\n# Hardcoded service locations (anti-pattern)\ngrep -r \"localhost:5432\\|localhost:6379\\|localhost:27017\\|127.0.0.1\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|spec\\|example\\|default\"\n```\n\n**File Patterns:** `**/database/*.py`, `**/services/*.py`, `**/db.py`, connection configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All services via URL/connection string in config, swappable without code changes |\n| **Partial** | Most services configurable but some hardcoded defaults |\n| **Weak** | Hardcoded service locations, different code paths per environment |\n\n**Anti-patterns:**\n- Hardcoded `localhost` for services in production code\n- Conditional logic for local vs cloud services (`if USE_S3: ... else: local_storage`)\n- Service-specific code paths based on environment\n- Different drivers for dev vs prod\n\n---\n\n### Factor V: Build, Release, Run\n\n**Principle:** Strictly separate build and run stages.\n\n**Search Patterns:**\n```bash\n# Build/deploy configuration\nfind . -name \"Dockerfile\" -o -name \"Makefile\" -o -name \"build.sh\" -o -name \"deploy.sh\"\nfind . -name \".github/workflows/*.yml\" -o -name \".gitlab-ci.yml\" -o -name \"Jenkinsfile\"\n\n# Build scripts in package.json\ngrep -A5 '\"scripts\"' package.json 2>/dev/null | grep -E \"build|start|deploy\"\n\n# Check for runtime compilation (anti-pattern)\ngrep -r \"compile\\|transpile\\|webpack\" --include=\"*.py\" | grep -v \"test\\|build\"\n```\n\n**File Patterns:** `**/Dockerfile`, `**/Makefile`, `**/.github/workflows/**`, CI/CD configs\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Immutable releases, clear build/release/run stages, unique release IDs |\n| **Partial** | Build and run separated but release not immutable |\n| **Weak** | Runtime code modifications, asset compilation at startup |\n\n**Anti-patterns:**\n- Runtime code modifications\n- Asset compilation during application startup\n- Configuration baked into build artifacts\n- No release versioning\n\n---\n\n### Factor VI: Processes\n\n**Principle:** Execute the app as one or more stateless processes.\n\n**Search Patterns:**\n```bash\n# Session storage patterns\ngrep -r \"session\\|Session\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n\n# In-process state (anti-pattern)\ngrep -r \"global.*cache\\|process_local\\|instance_cache\" --include=\"*.py\"\ngrep -r \"global\\..*=\\|module\\.exports\\.cache\" --include=\"*.js\" --include=\"*.ts\"\n\n# External session stores (good pattern)\ngrep -r \"redis.*session\\|memcached.*session\\|session.*redis\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Sticky session configuration (anti-pattern)\ngrep -r \"sticky.*session\\|session.*affinity\" --include=\"*.yml\" --include=\"*.yaml\" --include=\"*.json\"\n```\n\n**File Patterns:** `**/middleware/*.py`, `**/session/*.py`, server configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Stateless processes, all state in external datastores (Redis, DB) |\n| **Partial** | Mostly stateless but some in-process caching |\n| **Weak** | Sticky sessions, in-process session storage, shared memory state |\n\n**Anti-patterns:**\n- In-process session storage (`user_sessions = {}`)\n- Sticky sessions or session affinity\n- File-based caching between requests\n- Global mutable state shared across requests\n\n---\n\n### Factor VII: Port Binding\n\n**Principle:** Export services via port binding.\n\n**Search Patterns:**\n```bash\n# Self-contained port binding\ngrep -r \"app.run\\|server.listen\\|serve\\|uvicorn\" --include=\"*.py\"\ngrep -r \"app.listen\\|server.listen\\|createServer\" --include=\"*.js\" --include=\"*.ts\"\n\n# PORT environment variable\ngrep -r \"PORT\\|port\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -i \"environ\\|process.env\"\n\n# Webserver as dependency\ngrep -r \"uvicorn\\|gunicorn\\|flask\\|fastapi\\|express\\|koa\\|hapi\" package.json pyproject.toml requirements.txt 2>/dev/null\n```\n\n**File Patterns:** `**/main.py`, `**/server.py`, `**/app.py`, `**/index.js`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Self-contained app binds to PORT, webserver is a dependency |\n| **Partial** | Port binding but not configurable via environment |\n| **Weak** | Relies on external webserver container (Apache, Nginx) to provide HTTP |\n\n**Anti-patterns:**\n- Relying on Apache/Nginx/Tomcat to inject webserver functionality\n- Hardcoded port numbers\n- No PORT environment variable support\n- CGI scripts or server modules\n\n---\n\n### Factor VIII: Concurrency\n\n**Principle:** Scale out via the process model.\n\n**Search Patterns:**\n```bash\n# Process definitions\nfind . -name \"Procfile\" -o -name \"process.yml\" -o -name \".foreman\"\n\n# Multiple entry points\nfind . -name \"worker.py\" -o -name \"scheduler.py\" -o -name \"web.py\"\n\n# Background job systems\ngrep -r \"celery\\|rq\\|sidekiq\\|bull\\|agenda\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"Celery\\|Worker\\|BackgroundJob\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/Procfile`, `**/worker.py`, `**/scheduler.py`, queue configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Explicit process types (web, worker, scheduler), horizontal scaling |\n| **Partial** | Multiple process types but not easily scalable |\n| **Weak** | Single monolithic process, no separation of concerns |\n\n**Anti-patterns:**\n- Single process handling all workloads\n- Hard-coded worker counts in code\n- No separation between web and background processes\n- Vertical scaling only (bigger server, not more processes)\n\n---\n\n### Factor IX: Disposability\n\n**Principle:** Maximize robustness with fast startup and graceful shutdown.\n\n**Search Patterns:**\n```bash\n# Signal handlers\ngrep -r \"signal.signal\\|SIGTERM\\|SIGINT\\|atexit\" --include=\"*.py\"\ngrep -r \"process.on.*SIGTERM\\|process.on.*SIGINT\" --include=\"*.js\" --include=\"*.ts\"\n\n# Graceful shutdown\ngrep -r \"graceful.*shutdown\\|shutdown_handler\\|cleanup\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Startup time\ngrep -r \"startup\\|initialize\\|bootstrap\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n```\n\n**File Patterns:** `**/main.py`, `**/server.py`, lifecycle management code\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Fast startup (<10s), SIGTERM handling, graceful shutdown, jobs returnable to queue |\n| **Partial** | Graceful shutdown but slow startup |\n| **Weak** | No signal handling, jobs lost on process death, slow startup |\n\n**Anti-patterns:**\n- No SIGTERM/SIGINT handlers\n- Slow startup (>30 seconds)\n- Jobs lost if process crashes\n- No cleanup on shutdown\n\n---\n\n### Factor X: Dev/Prod Parity\n\n**Principle:** Keep development, staging, and production as similar as possible.\n\n**Search Patterns:**\n```bash\n# Different services per environment (anti-pattern)\ngrep -r \"if.*development.*sqlite\\|if.*production.*postgres\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"development.*SQLite\\|production.*PostgreSQL\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n\n# Docker for parity\nfind . -name \"docker-compose*.yml\" -o -name \"Dockerfile\"\n\n# Environment-specific backends\ngrep -r \"USE_LOCAL_\\|LOCAL_STORAGE\\|MOCK_\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/docker-compose*.yml`, environment configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Same services everywhere (PostgreSQL in dev and prod), containerized |\n| **Partial** | Mostly same but some lightweight dev alternatives |\n| **Weak** | SQLite in dev, PostgreSQL in prod; different backing services |\n\n**Anti-patterns:**\n- SQLite for development, PostgreSQL for production\n- In-memory cache in dev, Redis in prod\n- Different service versions across environments\n- \"It works on my machine\" issues\n\n---\n\n### Factor XI: Logs\n\n**Principle:** Treat logs as event streams.\n\n**Search Patterns:**\n```bash\n# Stdout logging\ngrep -r \"print(\\|logging.info\\|logger.info\\|console.log\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | head -20\n\n# File-based logging (anti-pattern)\ngrep -r \"FileHandler\\|open.*\\.log\\|writeFile.*log\\|fs.appendFile.*log\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\ngrep -r \"/var/log\\|/tmp/.*\\.log\\|logs/\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" | grep -v \"test\\|example\"\n\n# Structured logging\ngrep -r \"structlog\\|json_logger\\|pino\\|winston\" --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\"\n```\n\n**File Patterns:** `**/logging.py`, `**/logger.py`, logging configurations\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Unbuffered stdout only, structured logging (JSON), no file management |\n| **Partial** | Stdout logging but with some file handlers |\n| **Weak** | Application writes to log files, manages rotation |\n\n**Anti-patterns:**\n- Writing logs to files (`FileHandler`, `open('/var/log/app.log')`)\n- Log rotation logic in application code\n- Log archival managed by application\n- Buffered logging\n\n---\n\n### Factor XII: Admin Processes\n\n**Principle:** Run admin/management tasks as one-off processes.\n\n**Search Patterns:**\n```bash\n# Management commands\nfind . -name \"manage.py\" -o -name \"Rakefile\" -o -name \"artisan\"\ngrep -r \"@cli.command\\|@click.command\\|typer.command\" --include=\"*.py\"\n\n# Migration scripts\nfind . -name \"migrations\" -type d\nfind . -name \"*migration*.py\" -o -name \"*migrate*.py\"\n\n# Admin scripts with proper isolation\ngrep -r \"bundle exec\\|source.*venv\\|uv run\" --include=\"*.sh\" --include=\"Makefile\"\n```\n\n**File Patterns:** `**/manage.py`, `**/cli.py`, `**/migrations/**`, admin scripts\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Admin tasks use same dependencies/config, proper isolation, idempotent |\n| **Partial** | Admin tasks exist but different setup from app |\n| **Weak** | Manual database manipulation, scripts without isolation |\n\n**Anti-patterns:**\n- Admin scripts not using app's dependency manager\n- Direct SQL manipulation outside of migrations\n- Admin scripts with hardcoded credentials\n- Non-idempotent migrations\n\n---\n\n## Output Format\n\n### Executive Summary Table\n\n```markdown\n| Factor | Status | Notes |\n|--------|--------|-------|\n| I. Codebase | **Strong/Partial/Weak** | [Key finding] |\n| II. Dependencies | **Strong/Partial/Weak** | [Key finding] |\n| III. Config | **Strong/Partial/Weak** | [Key finding] |\n| IV. Backing Services | **Strong/Partial/Weak** | [Key finding] |\n| V. Build/Release/Run | **Strong/Partial/Weak** | [Key finding] |\n| VI. Processes | **Strong/Partial/Weak** | [Key finding] |\n| VII. Port Binding | **Strong/Partial/Weak** | [Key finding] |\n| VIII. Concurrency | **Strong/Partial/Weak** | [Key finding] |\n| IX. Disposability | **Strong/Partial/Weak** | [Key finding] |\n| X. Dev/Prod Parity | **Strong/Partial/Weak** | [Key finding] |\n| XI. Logs | **Strong/Partial/Weak** | [Key finding] |\n| XII. Admin Processes | **Strong/Partial/Weak** | [Key finding] |\n\n**Overall**: X Strong, Y Partial, Z Weak\n```\n\n### Per-Factor Analysis\n\nFor each factor, provide:\n\n1. **Current Implementation**\n   - Evidence with file:line references\n   - Code snippets showing patterns\n\n2. **Compliance Level**\n   - Strong/Partial/Weak with justification\n\n3. **Gaps**\n   - What's missing vs. 12-Factor ideal\n\n4. **Recommendations**\n   - Actionable improvements with code examples\n\n---\n\n## Analysis Workflow\n\n1. **Initial Scan**\n   - Run search patterns for all factors\n   - Identify key files for each factor\n   - Note any existing compliance documentation\n\n2. **Deep Dive** (per factor)\n   - Read identified files\n   - Evaluate against compliance criteria\n   - Document evidence with file paths\n\n3. **Gap Analysis**\n   - Compare current vs. 12-Factor ideal\n   - Identify anti-patterns present\n   - Prioritize by impact\n\n4. **Recommendations**\n   - Provide actionable improvements\n   - Include before/after code examples\n   - Reference best practices\n\n5. **Summary**\n   - Compile executive summary table\n   - Highlight strengths and critical gaps\n   - Suggest priority order for improvements\n\n---\n\n## Quick Reference: Compliance Scoring\n\n| Score | Meaning | Action |\n|-------|---------|--------|\n| **Strong** | Fully implements principle | Maintain, minor optimizations |\n| **Partial** | Some implementation, significant gaps | Planned improvements |\n| **Weak** | Minimal or no implementation | High priority for roadmap |\n\n## When to Use This Skill\n\n- Evaluating new SaaS applications\n- Reviewing cloud-native architecture decisions\n- Auditing production applications for scalability\n- Planning migration to cloud platforms\n- Comparing application architectures\n- Preparing for containerization/Kubernetes deployment\n",
        "skills/adr-decision-extraction/SKILL.md": "---\nname: adr-decision-extraction\ndescription: Extract architectural decisions from conversations. Identifies problem-solution pairs, trade-off discussions, and explicit choices. Use when analyzing session transcripts for ADR generation.\n---\n\n# ADR Decision Extraction\n\nExtract architectural decisions from conversation context for ADR generation.\n\n## Detection Signals\n\n| Signal Type | Examples |\n|-------------|----------|\n| Explicit markers | `[ADR]`, \"decided:\", \"the decision is\" |\n| Choice patterns | \"let's go with X\", \"we'll use Y\", \"choosing Z\" |\n| Trade-off discussions | \"X vs Y\", \"pros/cons\", \"considering alternatives\" |\n| Problem-solution pairs | \"the problem is... so we'll...\" |\n\n## Extraction Rules\n\n### Explicit Tags (Guaranteed Inclusion)\n\nText marked with `[ADR]` is always extracted:\n\n```\n[ADR] Using PostgreSQL for user data storage due to ACID requirements\n```\n\nThese receive `confidence: \"high\"` automatically.\n\n### AI-Detected Decisions\n\nPatterns detected without explicit tags require confidence assessment:\n\n| Confidence | Criteria |\n|------------|----------|\n| **high** | Clear statement of choice with rationale |\n| **medium** | Implied decision from action taken |\n| **low** | Contextual inference, may need verification |\n\n## Output Format\n\n```json\n{\n  \"decisions\": [\n    {\n      \"title\": \"Use PostgreSQL for user data\",\n      \"problem\": \"Need ACID transactions for financial records\",\n      \"chosen_option\": \"PostgreSQL\",\n      \"alternatives_discussed\": [\"MongoDB\", \"SQLite\"],\n      \"drivers\": [\"ACID compliance\", \"team familiarity\"],\n      \"confidence\": \"high\",\n      \"source_context\": \"Discussion about database selection in planning phase\"\n    }\n  ]\n}\n```\n\n### Field Definitions\n\n| Field | Required | Description |\n|-------|----------|-------------|\n| `title` | Yes | Concise decision summary |\n| `problem` | Yes | Problem or context driving the decision |\n| `chosen_option` | Yes | The selected solution or approach |\n| `alternatives_discussed` | No | Other options mentioned (empty array if none) |\n| `drivers` | No | Factors influencing the decision |\n| `confidence` | Yes | `high`, `medium`, or `low` |\n| `source_context` | No | Brief description of where decision appeared |\n\n## Extraction Workflow\n\n1. **Scan for explicit markers** - Find all `[ADR]` tagged content\n2. **Identify choice patterns** - Look for decision language\n3. **Extract trade-off discussions** - Capture alternatives and reasoning\n4. **Assess confidence** - Rate each non-explicit decision\n5. **Capture context** - Note surrounding discussion for ADR writer\n\n## Pattern Examples\n\n### High Confidence\n\n```\n\"We decided to use Redis for caching because of its sub-millisecond latency\nand native TTL support. Memcached was considered but lacks persistence.\"\n```\n\nExtracts:\n- Title: Use Redis for caching\n- Problem: Need fast caching with TTL\n- Chosen: Redis\n- Alternatives: Memcached\n- Drivers: sub-millisecond latency, native TTL, persistence\n- Confidence: high\n\n### Medium Confidence\n\n```\n\"Let's go with TypeScript for the frontend since we're already using it\nin the backend.\"\n```\n\nExtracts:\n- Title: Use TypeScript for frontend\n- Problem: Language choice for frontend\n- Chosen: TypeScript\n- Alternatives: (none stated)\n- Drivers: consistency with backend\n- Confidence: medium\n\n### Low Confidence\n\n```\n\"The API seems to be working well with REST endpoints.\"\n```\n\nExtracts:\n- Title: REST API architecture\n- Problem: API design approach\n- Chosen: REST\n- Alternatives: (none stated)\n- Drivers: (none stated)\n- Confidence: low\n\n## Best Practices\n\n### Context Capture\n\nAlways capture sufficient context for the ADR writer:\n- What was the discussion about?\n- Who was involved (if known)?\n- What prompted the decision?\n\n### Merge Related Decisions\n\nIf multiple statements relate to the same decision, consolidate them:\n- Combine alternatives from different mentions\n- Aggregate drivers\n- Use highest confidence level\n\n### Flag Ambiguity\n\nWhen decisions are unclear or contradictory:\n- Note the ambiguity in `source_context`\n- Set confidence to `low`\n- Include all interpretations if multiple exist\n\n## When to Use This Skill\n\n- Analyzing session transcripts for ADR generation\n- Reviewing conversation history for documentation\n- Extracting decisions from design discussions\n- Preparing input for ADR writing tools\n",
        "skills/adr-writing/SKILL.md": "---\nname: adr-writing\ndescription: Write Architectural Decision Records following MADR template. Applies Definition of Done criteria, marks gaps for later completion. Use when generating ADR documents from extracted decisions.\n---\n\n# ADR Writing\n\n## Overview\n\nGenerate Architectural Decision Records (ADRs) following the MADR template with systematic completeness checking.\n\n## Quick Reference\n\n```\n          \n  SEQUENCE        EXPLORE          FILL     \n  (get next         (context,          (template  \n   number)           ADRs)              sections) \n          \n                                               \n                                               \n                                        \n                                           VERIFY    \n                                          (DoD       \n          checklist)\n                                         \n```\n\n## When To Use\n\n- Documenting architectural decisions from extracted requirements\n- Converting meeting notes or discussions to formal ADRs\n- Recording technical choices from PR discussions\n- Creating decision records from design documents\n\n## Workflow\n\n### Step 1: Get Sequence Number\n\n**If a number was pre-assigned** (e.g., when called from `/beagle:write-adr` with parallel writes):\n- Use the pre-assigned number directly\n- Do NOT call the script - this prevents duplicate numbers in parallel execution\n\n**If no number was pre-assigned** (standalone use):\n```bash\npython scripts/next_adr_number.py\n```\n\nThis outputs the next available ADR number (e.g., `0003`).\n\nFor parallel allocation (used by parent commands):\n```bash\npython scripts/next_adr_number.py --count 3\n# Outputs: 0003, 0004, 0005 (one per line)\n```\n\n### Step 2: Explore Context\n\nBefore writing, gather additional context:\n\n1. **Related code** - Find implementations affected by this decision\n2. **Existing ADRs** - Check `docs/adrs/` for related or superseded decisions\n3. **Discussion sources** - PRs, issues, or documents referenced in decision\n\n### Step 3: Load Template\n\nLoad `references/madr-template.md` for the official MADR structure.\n\n### Step 4: Fill Sections\n\nPopulate each section from your decision data:\n\n| Section | Source |\n|---------|--------|\n| Title | Decision summary (imperative mood) |\n| Status | Always `draft` initially |\n| Context | Problem statement, constraints |\n| Decision Drivers | Prioritized requirements |\n| Considered Options | All viable alternatives |\n| Decision Outcome | Chosen option with rationale |\n| Consequences | Good, bad, neutral impacts |\n\n### Step 5: Apply Definition of Done\n\nLoad `references/definition-of-done.md` and verify E.C.A.D.R. criteria:\n\n- **E**xplicit problem statement\n- **C**omprehensive options analysis\n- **A**ctionable decision\n- **D**ocumented consequences\n- **R**eviewable by stakeholders\n\n### Step 6: Mark Gaps\n\nFor sections that cannot be filled from available data, insert investigation prompts:\n\n```markdown\n* [INVESTIGATE: Review PR #42 discussion for additional drivers]\n* [INVESTIGATE: Confirm with security team on compliance requirements]\n* [INVESTIGATE: Benchmark performance of Option 2 vs Option 3]\n```\n\nThese prompts signal incomplete sections for later follow-up.\n\n### Step 7: Write File\n\n**IMPORTANT: Every ADR MUST start with YAML frontmatter.**\n\nThe frontmatter block is REQUIRED and must include at minimum:\n```yaml\n---\nstatus: draft\ndate: YYYY-MM-DD\n---\n```\n\nFull frontmatter template:\n```yaml\n---\nstatus: draft\ndate: 2024-01-15\ndecision-makers: [alice, bob]\nconsulted: []\ninformed: []\n---\n```\n\n**Validation:** Before writing the file, verify the content starts with `---` followed by valid YAML frontmatter. If frontmatter is missing, add it before writing.\n\nSave to `docs/adrs/NNNN-slugified-title.md`:\n\n```\ndocs/adrs/0003-use-postgresql-for-user-data.md\ndocs/adrs/0004-adopt-event-sourcing-pattern.md\ndocs/adrs/0005-migrate-to-kubernetes.md\n```\n\n### Step 8: Verify Frontmatter\n\nAfter writing, confirm the file:\n1. Starts with `---` on the first line\n2. Contains `status: draft` (or other valid status)\n3. Contains `date: YYYY-MM-DD` with actual date\n4. Ends frontmatter with `---` before the title\n\n## File Naming Convention\n\nFormat: `NNNN-slugified-title.md`\n\n| Component | Rule |\n|-----------|------|\n| `NNNN` | Zero-padded sequence number from script |\n| `-` | Separator |\n| `slugified-title` | Lowercase, hyphens, no special characters |\n| `.md` | Markdown extension |\n\n## Reference Files\n\n- `references/madr-template.md` - Official MADR template structure\n- `references/definition-of-done.md` - E.C.A.D.R. quality criteria\n\n## Output Example\n\n```markdown\n---\nstatus: draft\ndate: 2024-01-15\ndecision-makers: [alice, bob]\n---\n\n# Use PostgreSQL for User Data Storage\n\n## Context and Problem Statement\n\nWe need a database for user account data...\n\n## Decision Drivers\n\n* Data integrity requirements\n* Query flexibility needs\n* [INVESTIGATE: Confirm scaling projections with infrastructure team]\n\n## Considered Options\n\n* PostgreSQL\n* MongoDB\n* CockroachDB\n\n## Decision Outcome\n\nChosen option: PostgreSQL, because...\n\n## Consequences\n\n### Good\n\n* ACID compliance ensures data integrity\n\n### Bad\n\n* Requires more upfront schema design\n\n### Neutral\n\n* Team has moderate PostgreSQL experience\n```\n",
        "skills/adr-writing/references/definition-of-done.md": "# Definition of Done: E.C.A.D.R. Criteria\n\nAn ADR is complete when it meets all five E.C.A.D.R. criteria.\n\n## E.C.A.D.R. Checklist\n\n### E - Explicit Problem Statement\n\n| Check | Criteria |\n|-------|----------|\n| [ ] | Context describes a real, specific problem |\n| [ ] | Problem is scoped (not too broad, not too narrow) |\n| [ ] | Constraints and requirements are stated |\n| [ ] | Reader understands WHY a decision is needed |\n\n**Anti-patterns:**\n- \"We need to choose a database\" (too vague)\n- Problem buried in decision outcome section\n- Missing business or technical context\n\n### C - Comprehensive Options Analysis\n\n| Check | Criteria |\n|-------|----------|\n| [ ] | At least 2 options considered |\n| [ ] | Options are genuinely viable (not strawmen) |\n| [ ] | Each option has pros AND cons listed |\n| [ ] | \"Do nothing\" considered if applicable |\n\n**Anti-patterns:**\n- Single option presented as foregone conclusion\n- Options listed without analysis\n- Missing obvious alternatives\n\n### A - Actionable Decision\n\n| Check | Criteria |\n|-------|----------|\n| [ ] | Chosen option is clearly stated |\n| [ ] | Decision is specific enough to implement |\n| [ ] | Rationale links to decision drivers |\n| [ ] | No ambiguity about what was decided |\n\n**Anti-patterns:**\n- \"We will use a modern approach\" (vague)\n- Decision contradicts stated constraints\n- Missing implementation guidance\n\n### D - Documented Consequences\n\n| Check | Criteria |\n|-------|----------|\n| [ ] | Good consequences listed |\n| [ ] | Bad consequences listed (honest tradeoffs) |\n| [ ] | Operational impacts considered |\n| [ ] | Future implications noted |\n\n**Anti-patterns:**\n- Only positive consequences (overselling)\n- Generic consequences that apply to any option\n- Missing security, performance, or cost impacts\n\n### R - Reviewable by Stakeholders\n\n| Check | Criteria |\n|-------|----------|\n| [ ] | Status is set appropriately |\n| [ ] | Decision-makers are identified |\n| [ ] | Language is accessible (not jargon-heavy) |\n| [ ] | Sufficient context for outsiders to understand |\n\n**Anti-patterns:**\n- Missing metadata (date, status, authors)\n- Assumes reader context not in document\n- Dense technical prose without summaries\n\n## Quality Rubric\n\n| Score | Criteria Met | Status |\n|-------|--------------|--------|\n| 5/5 | All E.C.A.D.R. criteria | Ready for `proposed` |\n| 4/5 | One minor gap | Add `[INVESTIGATE]` prompt |\n| 3/5 | Two gaps | Needs revision before proposing |\n| 2/5 | Major gaps | Incomplete draft |\n| 1/5 | Minimal content | Placeholder only |\n\n## Using [INVESTIGATE] Prompts\n\nWhen a criterion cannot be met from available information, insert an investigation prompt:\n\n```markdown\n## Decision Drivers\n\n* Performance under 100ms response time\n* [INVESTIGATE: Confirm budget constraints with finance team]\n* Compatibility with existing Python stack\n```\n\nThese prompts:\n1. Signal incomplete sections\n2. Document what information is missing\n3. Enable async follow-up\n4. Prevent premature status advancement\n\n## Status Progression\n\n```\ndraft  proposed  accepted\n            \n            \n         rejected\n  \n   [fix gaps, remove INVESTIGATE prompts]\n```\n\nDo not advance to `proposed` until all `[INVESTIGATE]` prompts are resolved.\n\n## Review Checklist\n\nFinal pass before marking `proposed`:\n\n- [ ] No `[INVESTIGATE]` prompts remain\n- [ ] All E.C.A.D.R. criteria checked\n- [ ] File named correctly (`NNNN-slugified-title.md`)\n- [ ] Frontmatter complete (status, date, decision-makers)\n- [ ] Links to related ADRs if superseding/related\n",
        "skills/adr-writing/references/madr-template.md": "# MADR Template\n\n> Markdown Any Decision Records (MADR) - https://adr.github.io/madr/\n\n## Template Structure\n\n```markdown\n---\nstatus: {draft | proposed | accepted | rejected | deprecated | superseded by [ADR-NNNN](NNNN-title.md)}\ndate: YYYY-MM-DD\ndecision-makers: [list of involved people]\nconsulted: [list of people whose opinions are sought]\ninformed: [list of people who are kept up-to-date]\n---\n\n# {Title: Short imperative statement of decision}\n\n## Context and Problem Statement\n\n{Describe the context and problem statement, e.g., in free form using two to three sentences or in the form of an illustrative story. You may want to articulate the problem in form of a question.}\n\n## Decision Drivers\n\n* {decision driver 1, e.g., a force, facing concern, ...}\n* {decision driver 2, e.g., a force, facing concern, ...}\n* ...\n\n## Considered Options\n\n* {title of option 1}\n* {title of option 2}\n* {title of option 3}\n* ...\n\n## Decision Outcome\n\nChosen option: \"{title of option 1}\", because {justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force {force} | ... | comes out best (see below)}.\n\n### Consequences\n\n* Good, because {positive consequence, e.g., improvement of one or more desired qualities, ...}\n* Bad, because {negative consequence, e.g., compromising one or more desired qualities, ...}\n* Neutral, because {neutral consequence, neither positive nor negative}\n\n### Confirmation\n\n{Describe how the implementation of/compliance with the ADR is confirmed. E.g., by a review or an ArchUnit test. Although we classify this element as optional, it is recommended to include it.}\n\n## Pros and Cons of the Options\n\n### {title of option 1}\n\n{example | description | pointer to more information | ...}\n\n* Good, because {argument a}\n* Good, because {argument b}\n* Neutral, because {argument c}\n* Bad, because {argument d}\n* ...\n\n### {title of option 2}\n\n{example | description | pointer to more information | ...}\n\n* Good, because {argument a}\n* Good, because {argument b}\n* Neutral, because {argument c}\n* Bad, because {argument d}\n* ...\n\n### {title of option 3}\n\n{example | description | pointer to more information | ...}\n\n* Good, because {argument a}\n* Good, because {argument b}\n* Neutral, because {argument c}\n* Bad, because {argument d}\n* ...\n\n## More Information\n\n{You might want to provide additional evidence/confidence for the decision outcome here and/or document the team agreement on the decision and/or define when this decision should be re-considered and/or links to other decisions and resources.}\n```\n\n## Section Guide\n\n### Status Values\n\n| Status | Meaning |\n|--------|---------|\n| `draft` | Initial creation, not yet reviewed |\n| `proposed` | Ready for team review |\n| `accepted` | Approved and active |\n| `rejected` | Considered but not adopted |\n| `deprecated` | No longer recommended |\n| `superseded by [ADR-NNNN]` | Replaced by newer decision |\n\n### Title\n\n- Use imperative mood (\"Use X\", \"Adopt Y\", \"Migrate to Z\")\n- Keep concise (5-10 words)\n- Start with verb\n\n### Context and Problem Statement\n\n- 2-4 sentences describing the situation\n- Can be phrased as a question\n- Include relevant constraints\n\n### Decision Drivers\n\n- List forces influencing the decision\n- Prioritize by importance\n- Include both technical and business drivers\n\n### Considered Options\n\n- Minimum 2 options (including chosen)\n- Include \"do nothing\" if viable\n- Brief titles, details in Pros/Cons section\n\n### Decision Outcome\n\n- State chosen option clearly\n- Explain why it was chosen\n- Reference decision drivers it satisfies\n\n### Consequences\n\n- Categorize as Good/Bad/Neutral\n- Be honest about tradeoffs\n- Include operational impacts\n\n## Optional Sections\n\nThese sections enhance completeness but may be omitted for simpler decisions:\n\n- **Confirmation** - How to verify compliance\n- **Pros and Cons of the Options** - Detailed option analysis\n- **More Information** - Links, references, caveats\n\n## Minimal Template\n\nFor quick decisions, use this shortened form:\n\n```markdown\n---\nstatus: draft\ndate: YYYY-MM-DD\n---\n\n# {Title}\n\n## Context and Problem Statement\n\n{description}\n\n## Decision Drivers\n\n* {driver 1}\n* {driver 2}\n\n## Decision Outcome\n\nChosen option: \"{option}\", because {reason}.\n\n### Consequences\n\n* Good, because {positive}\n* Bad, because {negative}\n```\n",
        "skills/agent-architecture-analysis/SKILL.md": "---\nname: agent-architecture-analysis\ndescription: Perform 12-Factor Agents compliance analysis on any codebase. Use when evaluating agent architecture, reviewing LLM-powered systems, or auditing agentic applications against the 12-Factor methodology.\n---\n\n# 12-Factor Agents Compliance Analysis\n\n> Reference: [12-Factor Agents](https://github.com/humanlayer/12-factor-agents)\n\n## Input Parameters\n\n| Parameter | Description | Required |\n|-----------|-------------|----------|\n| `docs_path` | Path to documentation directory (for existing analyses) | Optional |\n| `codebase_path` | Root path of the codebase to analyze | Required |\n\n## Analysis Framework\n\n### Factor 1: Natural Language to Tool Calls\n\n**Principle:** Convert natural language inputs into structured, deterministic tool calls using schema-validated outputs.\n\n**Search Patterns:**\n```bash\n# Look for Pydantic schemas\ngrep -r \"class.*BaseModel\" --include=\"*.py\"\ngrep -r \"TaskDAG\\|TaskResponse\\|ToolCall\" --include=\"*.py\"\n\n# Look for JSON schema generation\ngrep -r \"model_json_schema\\|json_schema\" --include=\"*.py\"\n\n# Look for structured output generation\ngrep -r \"output_type\\|response_model\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/agents/*.py`, `**/schemas/*.py`, `**/models/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All LLM outputs use Pydantic/dataclass schemas with validators |\n| **Partial** | Some outputs typed, but dict returns or unvalidated strings exist |\n| **Weak** | LLM returns raw strings parsed manually or with regex |\n\n**Anti-patterns:**\n- `json.loads(llm_response)` without schema validation\n- `output.split()` or regex parsing of LLM responses\n- `dict[str, Any]` return types from agents\n- No validation between LLM output and handler execution\n\n---\n\n### Factor 2: Own Your Prompts\n\n**Principle:** Treat prompts as first-class code you control, version, and iterate on.\n\n**Search Patterns:**\n```bash\n# Look for embedded prompts\ngrep -r \"SYSTEM_PROMPT\\|system_prompt\" --include=\"*.py\"\ngrep -r '\"\"\".*You are' --include=\"*.py\"\n\n# Look for template systems\ngrep -r \"jinja\\|Jinja\\|render_template\" --include=\"*.py\"\nfind . -name \"*.jinja2\" -o -name \"*.j2\"\n\n# Look for prompt directories\nfind . -type d -name \"prompts\"\n```\n\n**File Patterns:** `**/prompts/**`, `**/templates/**`, `**/agents/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Prompts in separate files, templated (Jinja2), versioned |\n| **Partial** | Prompts as module constants, some parameterization |\n| **Weak** | Prompts hardcoded inline in functions, f-strings only |\n\n**Anti-patterns:**\n- `f\"You are a {role}...\"` inline in agent methods\n- Prompts mixed with business logic\n- No way to iterate on prompts without code changes\n- No prompt versioning or A/B testing capability\n\n---\n\n### Factor 3: Own Your Context Window\n\n**Principle:** Control how history, state, and tool results are formatted for the LLM.\n\n**Search Patterns:**\n```bash\n# Look for context/message management\ngrep -r \"AgentMessage\\|ChatMessage\\|messages\" --include=\"*.py\"\ngrep -r \"context_window\\|context_compiler\" --include=\"*.py\"\n\n# Look for custom serialization\ngrep -r \"to_xml\\|to_context\\|serialize\" --include=\"*.py\"\n\n# Look for token management\ngrep -r \"token_count\\|max_tokens\\|truncate\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/context/*.py`, `**/state/*.py`, `**/core/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Custom context format, token optimization, typed events, compaction |\n| **Partial** | Basic message history with some structure |\n| **Weak** | Raw message accumulation, standard OpenAI format only |\n\n**Anti-patterns:**\n- Unbounded message accumulation\n- Large artifacts embedded inline (diffs, files)\n- No agent-specific context filtering\n- Same context for all agent types\n\n---\n\n### Factor 4: Tools Are Structured Outputs\n\n**Principle:** Tools produce schema-validated JSON that triggers deterministic code, not magic function calls.\n\n**Search Patterns:**\n```bash\n# Look for tool/response schemas\ngrep -r \"class.*Response.*BaseModel\" --include=\"*.py\"\ngrep -r \"ToolResult\\|ToolOutput\" --include=\"*.py\"\n\n# Look for deterministic handlers\ngrep -r \"def handle_\\|def execute_\" --include=\"*.py\"\n\n# Look for validation layer\ngrep -r \"model_validate\\|parse_obj\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/tools/*.py`, `**/handlers/*.py`, `**/agents/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | All tool outputs schema-validated, handlers type-safe |\n| **Partial** | Most tools typed, some loose dict returns |\n| **Weak** | Tools return arbitrary dicts, no validation layer |\n\n**Anti-patterns:**\n- Tool handlers that directly execute LLM output\n- `eval()` or `exec()` on LLM-generated code\n- No separation between decision (LLM) and execution (code)\n- Magic method dispatch based on string matching\n\n---\n\n### Factor 5: Unify Execution State\n\n**Principle:** Merge execution state (step, retries) with business state (messages, results).\n\n**Search Patterns:**\n```bash\n# Look for state models\ngrep -r \"ExecutionState\\|WorkflowState\\|Thread\" --include=\"*.py\"\n\n# Look for dual state systems\ngrep -r \"checkpoint\\|MemorySaver\" --include=\"*.py\"\ngrep -r \"sqlite\\|database\\|repository\" --include=\"*.py\"\n\n# Look for state reconstruction\ngrep -r \"load_state\\|restore\\|reconstruct\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/state/*.py`, `**/models/*.py`, `**/database/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Single serializable state object with all execution metadata |\n| **Partial** | State exists but split across systems (memory + DB) |\n| **Weak** | Execution state scattered, requires multiple queries to reconstruct |\n\n**Anti-patterns:**\n- Retry count stored separately from task state\n- Error history in logs but not in state\n- LangGraph checkpoints + separate database storage\n- No unified event thread\n\n---\n\n### Factor 6: Launch/Pause/Resume\n\n**Principle:** Agents support simple APIs for launching, pausing at any point, and resuming.\n\n**Search Patterns:**\n```bash\n# Look for REST endpoints\ngrep -r \"@router.post\\|@app.post\" --include=\"*.py\"\ngrep -r \"start_workflow\\|pause\\|resume\" --include=\"*.py\"\n\n# Look for interrupt mechanisms\ngrep -r \"interrupt_before\\|interrupt_after\" --include=\"*.py\"\n\n# Look for webhook handlers\ngrep -r \"webhook\\|callback\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/routes/*.py`, `**/api/*.py`, `**/orchestrator/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | REST API + webhook resume, pause at any point including mid-tool |\n| **Partial** | Launch/pause/resume exists but only at coarse-grained points |\n| **Weak** | CLI-only launch, no pause/resume capability |\n\n**Anti-patterns:**\n- Blocking `input()` or `confirm()` calls\n- No way to resume after process restart\n- Approval only at plan level, not per-tool\n- No webhook-based resume from external systems\n\n---\n\n### Factor 7: Contact Humans with Tools\n\n**Principle:** Human contact is a tool call with question, options, and urgency.\n\n**Search Patterns:**\n```bash\n# Look for human input mechanisms\ngrep -r \"typer.confirm\\|input(\\|prompt(\" --include=\"*.py\"\ngrep -r \"request_human_input\\|human_contact\" --include=\"*.py\"\n\n# Look for approval patterns\ngrep -r \"approval\\|approve\\|reject\" --include=\"*.py\"\n\n# Look for structured question formats\ngrep -r \"question.*options\\|HumanInputRequest\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/agents/*.py`, `**/tools/*.py`, `**/orchestrator/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | `request_human_input` tool with question/options/urgency/format |\n| **Partial** | Approval gates exist but hardcoded in graph structure |\n| **Weak** | Blocking CLI prompts, no tool-based human contact |\n\n**Anti-patterns:**\n- `typer.confirm()` in agent code\n- Human contact hardcoded at specific graph nodes\n- No way for agents to ask clarifying questions\n- Single response format (yes/no only)\n\n---\n\n### Factor 8: Own Your Control Flow\n\n**Principle:** Custom control flow, not framework defaults. Full control over routing, retries, compaction.\n\n**Search Patterns:**\n```bash\n# Look for routing logic\ngrep -r \"add_conditional_edges\\|route_\\|should_continue\" --include=\"*.py\"\n\n# Look for custom loops\ngrep -r \"while True\\|for.*in.*range\" --include=\"*.py\" | grep -v test\n\n# Look for execution mode control\ngrep -r \"execution_mode\\|agentic\\|structured\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/orchestrator/*.py`, `**/graph/*.py`, `**/core/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Custom routing functions, conditional edges, execution mode control |\n| **Partial** | Framework control flow with some customization |\n| **Weak** | Default framework loop with no custom routing |\n\n**Anti-patterns:**\n- Single path through graph with no branching\n- No distinction between tool types (all treated same)\n- Framework-default error handling only\n- No rate limiting or resource management\n\n---\n\n### Factor 9: Compact Errors into Context\n\n**Principle:** Errors in context enable self-healing. Track consecutive errors, escalate after threshold.\n\n**Search Patterns:**\n```bash\n# Look for error handling\ngrep -r \"except.*Exception\\|error_history\\|consecutive_errors\" --include=\"*.py\"\n\n# Look for retry logic\ngrep -r \"retry\\|backoff\\|max_attempts\" --include=\"*.py\"\n\n# Look for escalation\ngrep -r \"escalate\\|human_escalation\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/agents/*.py`, `**/orchestrator/*.py`, `**/core/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Errors in context, retry with threshold, automatic escalation |\n| **Partial** | Errors logged and returned, no automatic retry loop |\n| **Weak** | Errors logged only, not fed back to LLM, task fails immediately |\n\n**Anti-patterns:**\n- `logger.error()` without adding to context\n- No retry mechanism (fail immediately)\n- No consecutive error tracking\n- No escalation to humans after repeated failures\n\n---\n\n### Factor 10: Small, Focused Agents\n\n**Principle:** Each agent has narrow responsibility, 3-10 steps max.\n\n**Search Patterns:**\n```bash\n# Look for agent classes\ngrep -r \"class.*Agent\\|class.*Architect\\|class.*Developer\" --include=\"*.py\"\n\n# Look for step definitions\ngrep -r \"steps\\|tasks\" --include=\"*.py\" | head -20\n\n# Count methods per agent\ngrep -r \"async def\\|def \" agents/*.py 2>/dev/null | wc -l\n```\n\n**File Patterns:** `**/agents/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | 3+ specialized agents, each with single responsibility, step limits |\n| **Partial** | Multiple agents but some have broad scope |\n| **Weak** | Single \"god\" agent that handles everything |\n\n**Anti-patterns:**\n- Single agent with 20+ tools\n- Agent with unbounded step count\n- Mixed responsibilities (planning + execution + review)\n- No step or time limits on agent execution\n\n---\n\n### Factor 11: Trigger from Anywhere\n\n**Principle:** Workflows triggerable from CLI, REST, WebSocket, Slack, webhooks, etc.\n\n**Search Patterns:**\n```bash\n# Look for entry points\ngrep -r \"@cli.command\\|@router.post\\|@app.post\" --include=\"*.py\"\n\n# Look for WebSocket support\ngrep -r \"WebSocket\\|websocket\" --include=\"*.py\"\n\n# Look for external integrations\ngrep -r \"slack\\|discord\\|webhook\" --include=\"*.py\" -i\n```\n\n**File Patterns:** `**/routes/*.py`, `**/cli/*.py`, `**/main.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | CLI + REST + WebSocket + webhooks + chat integrations |\n| **Partial** | CLI + REST API available |\n| **Weak** | CLI only, no programmatic access |\n\n**Anti-patterns:**\n- Only `if __name__ == \"__main__\"` entry point\n- No REST API for external systems\n- No event streaming for real-time updates\n- Trigger logic tightly coupled to execution\n\n---\n\n### Factor 12: Stateless Reducer\n\n**Principle:** Agents as pure functions: (state, input) -> (state, output). No side effects in agent logic.\n\n**Search Patterns:**\n```bash\n# Look for state mutation patterns\ngrep -r \"\\.status = \\|\\.field = \" --include=\"*.py\"\n\n# Look for immutable updates\ngrep -r \"model_copy\\|\\.copy(\\|with_\" --include=\"*.py\"\n\n# Look for side effects in agents\ngrep -r \"write_file\\|subprocess\\|requests\\.\" agents/*.py 2>/dev/null\n```\n\n**File Patterns:** `**/agents/*.py`, `**/nodes/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Immutable state updates, side effects isolated to tools/handlers |\n| **Partial** | Mostly immutable, some in-place mutations |\n| **Weak** | State mutated in place, side effects mixed with agent logic |\n\n**Anti-patterns:**\n- `state.field = new_value` (mutation)\n- File writes inside agent methods\n- HTTP calls inside agent decision logic\n- Shared mutable state between agents\n\n---\n\n### Factor 13: Pre-fetch Context\n\n**Principle:** Fetch likely-needed data upfront rather than mid-workflow.\n\n**Search Patterns:**\n```bash\n# Look for context pre-fetching\ngrep -r \"pre_fetch\\|prefetch\\|fetch_context\" --include=\"*.py\"\n\n# Look for RAG/embedding systems\ngrep -r \"embedding\\|vector\\|semantic_search\" --include=\"*.py\"\n\n# Look for related file discovery\ngrep -r \"related_tests\\|similar_\\|find_relevant\" --include=\"*.py\"\n```\n\n**File Patterns:** `**/context/*.py`, `**/retrieval/*.py`, `**/rag/*.py`\n\n**Compliance Criteria:**\n\n| Level | Criteria |\n|-------|----------|\n| **Strong** | Automatic pre-fetch of related tests, files, docs before planning |\n| **Partial** | Manual context passing, design doc support |\n| **Weak** | No pre-fetching, LLM must request all context via tools |\n\n**Anti-patterns:**\n- Architect starts with issue only, no codebase context\n- No semantic search for similar past work\n- Related tests/files discovered only during execution\n- No RAG or document retrieval system\n\n---\n\n## Output Format\n\n### Executive Summary Table\n\n```markdown\n| Factor | Status | Notes |\n|--------|--------|-------|\n| 1. Natural Language -> Tool Calls | **Strong/Partial/Weak** | [Key finding] |\n| 2. Own Your Prompts | **Strong/Partial/Weak** | [Key finding] |\n| ... | ... | ... |\n| 13. Pre-fetch Context | **Strong/Partial/Weak** | [Key finding] |\n\n**Overall**: X Strong, Y Partial, Z Weak\n```\n\n### Per-Factor Analysis\n\nFor each factor, provide:\n\n1. **Current Implementation**\n   - Evidence with file:line references\n   - Code snippets showing patterns\n\n2. **Compliance Level**\n   - Strong/Partial/Weak with justification\n\n3. **Gaps**\n   - What's missing vs. 12-Factor ideal\n\n4. **Recommendations**\n   - Actionable improvements with code examples\n\n---\n\n## Analysis Workflow\n\n1. **Initial Scan**\n   - Run search patterns for all factors\n   - Identify key files for each factor\n   - Note any existing compliance documentation\n\n2. **Deep Dive** (per factor)\n   - Read identified files\n   - Evaluate against compliance criteria\n   - Document evidence with file paths\n\n3. **Gap Analysis**\n   - Compare current vs. 12-Factor ideal\n   - Identify anti-patterns present\n   - Prioritize by impact\n\n4. **Recommendations**\n   - Provide actionable improvements\n   - Include before/after code examples\n   - Reference roadmap if exists\n\n5. **Summary**\n   - Compile executive summary table\n   - Highlight strengths and critical gaps\n   - Suggest priority order for improvements\n\n---\n\n## Quick Reference: Compliance Scoring\n\n| Score | Meaning | Action |\n|-------|---------|--------|\n| **Strong** | Fully implements principle | Maintain, minor optimizations |\n| **Partial** | Some implementation, significant gaps | Planned improvements |\n| **Weak** | Minimal or no implementation | High priority for roadmap |\n\n## When to Use This Skill\n\n- Evaluating new LLM-powered systems\n- Reviewing agent architecture decisions\n- Auditing production agentic applications\n- Planning improvements to existing agents\n- Comparing frameworks or implementations\n",
        "skills/ai-elements/SKILL.md": "---\nname: ai-elements\ndescription: Vercel AI Elements for workflow UI components. Use when building chat interfaces, displaying tool execution, showing reasoning/thinking, or creating job queues. Triggers on ai-elements, Queue, Confirmation, Tool, Reasoning, Shimmer, Loader, Message, Conversation, PromptInput.\n---\n\n# AI Elements\n\nAI Elements is a comprehensive React component library for building AI-powered user interfaces. The library provides 30+ components specifically designed for chat interfaces, tool execution visualization, reasoning displays, and workflow management.\n\n## Installation\n\nInstall via shadcn registry:\n\n```bash\nnpx shadcn@latest add https://ai-elements.vercel.app/r/[component-name]\n```\n\n**Import Pattern**: Components are imported from individual files, not a barrel export:\n\n```tsx\n// Correct - import from specific files\nimport { Conversation } from \"@/components/ai-elements/conversation\";\nimport { Message } from \"@/components/ai-elements/message\";\nimport { PromptInput } from \"@/components/ai-elements/prompt-input\";\n\n// Incorrect - no barrel export\nimport { Conversation, Message } from \"@/components/ai-elements\";\n```\n\n## Component Categories\n\n### Conversation Components\nComponents for displaying chat-style interfaces with messages, attachments, and auto-scrolling behavior.\n\n- **Conversation**: Container with auto-scroll capabilities\n- **Message**: Individual message display with role-based styling\n- **MessageAttachment**: File and image attachments\n- **MessageBranch**: Alternative response navigation\n\nSee [references/conversation.md](references/conversation.md) for details.\n\n### Prompt Input Components\nAdvanced text input with file attachments, drag-and-drop, speech input, and state management.\n\n- **PromptInput**: Form container with file handling\n- **PromptInputTextarea**: Auto-expanding textarea\n- **PromptInputSubmit**: Status-aware submit button\n- **PromptInputAttachments**: File attachment display\n- **PromptInputProvider**: Global state management\n\nSee [references/prompt-input.md](references/prompt-input.md) for details.\n\n### Workflow Components\nComponents for displaying job queues, tool execution, and approval workflows.\n\n- **Queue**: Job queue container\n- **QueueItem**: Individual queue items with status\n- **Tool**: Tool execution display with collapsible states\n- **Confirmation**: Approval workflow component\n- **Reasoning**: Collapsible thinking/reasoning display\n\nSee [references/workflow.md](references/workflow.md) for details.\n\n### Visualization Components\nReactFlow-based components for workflow visualization and custom node types.\n\n- **Canvas**: ReactFlow wrapper with aviation-specific defaults\n- **Node**: Custom node component with handles\n- **Edge**: Temporary and Animated edge types\n- **Controls, Panel, Toolbar**: Navigation and control elements\n\nSee [references/visualization.md](references/visualization.md) for details.\n\n## Integration with shadcn/ui\n\nAI Elements is built on top of shadcn/ui and integrates seamlessly with its theming system:\n\n- Uses shadcn/ui's design tokens (colors, spacing, typography)\n- Respects light/dark mode via CSS variables\n- Compatible with shadcn/ui components (Button, Card, Collapsible, etc.)\n- Follows shadcn/ui's component composition patterns\n\n## Key Design Patterns\n\n### Component Composition\nAI Elements follows a composition-first approach where larger components are built from smaller primitives:\n\n```tsx\n<Tool>\n  <ToolHeader title=\"search\" type=\"tool-call-search\" state=\"output-available\" />\n  <ToolContent>\n    <ToolInput input={{ query: \"AI tools\" }} />\n    <ToolOutput output={results} errorText={undefined} />\n  </ToolContent>\n</Tool>\n```\n\n### Context-Based State\nMany components use React Context for state management:\n\n- `PromptInputProvider` for global input state\n- `MessageBranch` for alternative response navigation\n- `Confirmation` for approval workflow state\n- `Reasoning` for collapsible thinking state\n\n### Controlled vs Uncontrolled\nComponents support both controlled and uncontrolled patterns:\n\n```tsx\n// Uncontrolled (self-managed state)\n<PromptInput onSubmit={handleSubmit} />\n\n// Controlled (external state)\n<PromptInputProvider initialInput=\"\">\n  <PromptInput onSubmit={handleSubmit} />\n</PromptInputProvider>\n```\n\n## Tool State Machine\n\nThe Tool component follows the Vercel AI SDK's state machine:\n\n1. `input-streaming`: Parameters being received\n2. `input-available`: Ready to execute\n3. `approval-requested`: Awaiting user approval (SDK v6)\n4. `approval-responded`: User responded (SDK v6)\n5. `output-available`: Execution completed\n6. `output-error`: Execution failed\n7. `output-denied`: Approval denied\n\n## Queue Patterns\n\nQueue components support hierarchical organization:\n\n```tsx\n<Queue>\n  <QueueSection defaultOpen={true}>\n    <QueueSectionTrigger>\n      <QueueSectionLabel count={3} label=\"tasks\" icon={<Icon />} />\n    </QueueSectionTrigger>\n    <QueueSectionContent>\n      <QueueList>\n        <QueueItem>\n          <QueueItemIndicator completed={false} />\n          <QueueItemContent>Task description</QueueItemContent>\n        </QueueItem>\n      </QueueList>\n    </QueueSectionContent>\n  </QueueSection>\n</Queue>\n```\n\n## Auto-Scroll Behavior\n\nThe Conversation component uses the `use-stick-to-bottom` hook for intelligent auto-scrolling:\n\n- Automatically scrolls to bottom when new messages arrive\n- Pauses auto-scroll when user scrolls up\n- Provides scroll-to-bottom button when not at bottom\n- Supports smooth and instant scroll modes\n\n## File Attachment Handling\n\nPromptInput provides comprehensive file handling:\n\n- Drag-and-drop support (local or global)\n- Paste image/file support\n- File type validation (accept prop)\n- File size limits (maxFileSize prop)\n- Maximum file count (maxFiles prop)\n- Preview for images, icons for files\n- Automatic blob URL to data URL conversion on submit\n\n## Speech Input\n\nThe PromptInputSpeechButton uses the Web Speech API for voice input:\n\n- Browser-based speech recognition\n- Continuous recognition mode\n- Interim results support\n- Automatic text insertion into textarea\n- Visual feedback during recording\n\n## Reasoning Auto-Collapse\n\nThe Reasoning component provides auto-collapse behavior:\n\n- Opens automatically when streaming starts\n- Closes 1 second after streaming ends\n- Tracks thinking duration in seconds\n- Displays \"Thinking...\" with shimmer effect during streaming\n- Shows \"Thought for N seconds\" when complete\n\n## TypeScript Types\n\nAll components are fully typed with TypeScript:\n\n```typescript\nimport type { ToolUIPart, FileUIPart, UIMessage } from \"ai\";\n\ntype ToolProps = ComponentProps<typeof Collapsible>;\ntype QueueItemProps = ComponentProps<\"li\">;\ntype MessageAttachmentProps = HTMLAttributes<HTMLDivElement> & {\n  data: FileUIPart;\n  onRemove?: () => void;\n};\n```\n\n## Common Use Cases\n\n### Chat Interface\nCombine Conversation, Message, and PromptInput for a complete chat UI:\n\n```tsx\nimport { Conversation, ConversationContent, ConversationScrollButton } from \"@/components/ai-elements/conversation\";\nimport { Message, MessageContent, MessageResponse } from \"@/components/ai-elements/message\";\nimport {\n  PromptInput,\n  PromptInputTextarea,\n  PromptInputFooter,\n  PromptInputTools,\n  PromptInputButton,\n  PromptInputSubmit\n} from \"@/components/ai-elements/prompt-input\";\n\n<div className=\"flex flex-col h-screen\">\n  <Conversation>\n    <ConversationContent>\n      {messages.map(msg => (\n        <Message key={msg.id} from={msg.role}>\n          <MessageContent>\n            <MessageResponse>{msg.content}</MessageResponse>\n          </MessageContent>\n        </Message>\n      ))}\n    </ConversationContent>\n    <ConversationScrollButton />\n  </Conversation>\n\n  <PromptInput onSubmit={handleSubmit}>\n    <PromptInputTextarea />\n    <PromptInputFooter>\n      <PromptInputTools>\n        <PromptInputButton onClick={() => attachments.openFileDialog()}>\n          <PaperclipIcon />\n        </PromptInputButton>\n      </PromptInputTools>\n      <PromptInputSubmit status={chatStatus} />\n    </PromptInputFooter>\n  </PromptInput>\n</div>\n```\n\n### Tool Execution Display\nShow tool execution with expandable details:\n\n```tsx\nimport { Tool, ToolHeader, ToolContent, ToolInput, ToolOutput } from \"@/components/ai-elements/tool\";\n\n{toolInvocations.map(tool => (\n  <Tool key={tool.id}>\n    <ToolHeader\n      title={tool.toolName}\n      type={`tool-call-${tool.toolName}`}\n      state={tool.state}\n    />\n    <ToolContent>\n      <ToolInput input={tool.args} />\n      {tool.result && (\n        <ToolOutput output={tool.result} errorText={tool.error} />\n      )}\n    </ToolContent>\n  </Tool>\n))}\n```\n\n### Approval Workflow\nRequest user confirmation before executing actions:\n\n```tsx\nimport {\n  Confirmation,\n  ConfirmationTitle,\n  ConfirmationRequest,\n  ConfirmationActions,\n  ConfirmationAction,\n  ConfirmationAccepted,\n  ConfirmationRejected\n} from \"@/components/ai-elements/confirmation\";\n\n<Confirmation approval={tool.approval} state={tool.state}>\n  <ConfirmationTitle>\n    Approve deletion of {resource}?\n  </ConfirmationTitle>\n\n  <ConfirmationRequest>\n    <ConfirmationActions>\n      <ConfirmationAction onClick={approve} variant=\"default\">\n        Approve\n      </ConfirmationAction>\n      <ConfirmationAction onClick={reject} variant=\"outline\">\n        Reject\n      </ConfirmationAction>\n    </ConfirmationActions>\n  </ConfirmationRequest>\n\n  <ConfirmationAccepted>\n    Action approved and executed.\n  </ConfirmationAccepted>\n\n  <ConfirmationRejected>\n    Action rejected.\n  </ConfirmationRejected>\n</Confirmation>\n```\n\n### Job Queue Management\nDisplay task lists with completion status:\n\n```tsx\nimport {\n  Queue,\n  QueueSection,\n  QueueSectionTrigger,\n  QueueSectionLabel,\n  QueueSectionContent,\n  QueueList,\n  QueueItem,\n  QueueItemIndicator,\n  QueueItemContent,\n  QueueItemDescription\n} from \"@/components/ai-elements/queue\";\n\n<Queue>\n  <QueueSection>\n    <QueueSectionTrigger>\n      <QueueSectionLabel count={todos.length} label=\"todos\" />\n    </QueueSectionTrigger>\n    <QueueSectionContent>\n      <QueueList>\n        {todos.map(todo => (\n          <QueueItem key={todo.id}>\n            <QueueItemIndicator completed={todo.status === 'completed'} />\n            <QueueItemContent completed={todo.status === 'completed'}>\n              {todo.title}\n            </QueueItemContent>\n            {todo.description && (\n              <QueueItemDescription completed={todo.status === 'completed'}>\n                {todo.description}\n              </QueueItemDescription>\n            )}\n          </QueueItem>\n        ))}\n      </QueueList>\n    </QueueSectionContent>\n  </QueueSection>\n</Queue>\n```\n\n## Accessibility\n\nComponents include accessibility features:\n\n- ARIA labels and roles\n- Keyboard navigation support\n- Screen reader announcements\n- Focus management\n- Semantic HTML elements\n\n## Animation\n\nMany components use Framer Motion for smooth animations:\n\n- Shimmer effect for loading states\n- Collapsible content transitions\n- Edge animations in Canvas\n- Loader spinner rotation\n\n## References\n\n- [Conversation Components](references/conversation.md)\n- [Prompt Input Components](references/prompt-input.md)\n- [Workflow Components](references/workflow.md)\n- [Visualization Components](references/visualization.md)\n",
        "skills/ai-elements/references/conversation.md": "# Conversation Components\n\nComponents for building chat-style interfaces with messages, attachments, and intelligent auto-scrolling.\n\n## Core Components\n\n### Conversation\n\nContainer component that wraps the entire conversation area with auto-scroll functionality.\n\n```typescript\ntype ConversationProps = ComponentProps<typeof StickToBottom>;\n```\n\n**Props:**\n- `className?: string` - Additional CSS classes\n- `initial?: \"smooth\" | \"auto\"` - Initial scroll behavior (default: \"smooth\")\n- `resize?: \"smooth\" | \"auto\"` - Scroll behavior on resize (default: \"smooth\")\n\n**Usage:**\n\n```tsx\n<Conversation className=\"flex-1 overflow-y-hidden\">\n  <ConversationContent>\n    {/* Messages go here */}\n  </ConversationContent>\n  <ConversationScrollButton />\n</Conversation>\n```\n\n**Features:**\n- Uses `use-stick-to-bottom` for intelligent scrolling\n- Automatically scrolls to bottom when new messages arrive\n- Pauses auto-scroll when user scrolls up manually\n- Provides context for scroll state to child components\n- Sets `role=\"log\"` for accessibility\n\n### ConversationContent\n\nContent area for messages within the conversation.\n\n```typescript\ntype ConversationContentProps = ComponentProps<typeof StickToBottom.Content>;\n```\n\n**Usage:**\n\n```tsx\n<ConversationContent className=\"flex flex-col gap-8 p-4\">\n  {messages.map(message => (\n    <Message key={message.id} from={message.role}>\n      {/* Message content */}\n    </Message>\n  ))}\n</ConversationContent>\n```\n\n**Default Styling:**\n- Flexbox column layout with gap\n- Padding for content separation\n\n### ConversationEmptyState\n\nPlaceholder shown when there are no messages.\n\n```typescript\ntype ConversationEmptyStateProps = ComponentProps<\"div\"> & {\n  title?: string;\n  description?: string;\n  icon?: React.ReactNode;\n};\n```\n\n**Props:**\n- `title?: string` - Heading text (default: \"No messages yet\")\n- `description?: string` - Descriptive text (default: \"Start a conversation to see messages here\")\n- `icon?: React.ReactNode` - Icon to display above text\n- `children?: React.ReactNode` - Custom content (overrides default)\n\n**Usage:**\n\n```tsx\n{messages.length === 0 ? (\n  <ConversationEmptyState\n    title=\"Welcome!\"\n    description=\"Ask me anything to get started\"\n    icon={<MessageSquareIcon className=\"size-12\" />}\n  />\n) : (\n  <ConversationContent>\n    {/* Messages */}\n  </ConversationContent>\n)}\n```\n\n### ConversationScrollButton\n\nButton that appears when user is not at the bottom of the conversation, allowing quick navigation to latest messages.\n\n```typescript\ntype ConversationScrollButtonProps = ComponentProps<typeof Button>;\n```\n\n**Usage:**\n\n```tsx\n<Conversation>\n  <ConversationContent>\n    {/* Messages */}\n  </ConversationContent>\n  <ConversationScrollButton />\n</Conversation>\n```\n\n**Behavior:**\n- Only visible when `isAtBottom` is false\n- Positioned at bottom center of conversation\n- Calls `scrollToBottom()` on click\n- Uses `ArrowDownIcon` by default\n\n## Message Components\n\n### Message\n\nContainer for an individual message with role-based styling.\n\n```typescript\ntype MessageProps = HTMLAttributes<HTMLDivElement> & {\n  from: UIMessage[\"role\"]; // \"user\" | \"assistant\"\n};\n```\n\n**Props:**\n- `from: \"user\" | \"assistant\"` - Message sender role\n- `className?: string` - Additional CSS classes\n- Standard HTML div attributes\n\n**Usage:**\n\n```tsx\n<Message from=\"assistant\">\n  <MessageContent>\n    <MessageResponse>{content}</MessageResponse>\n  </MessageContent>\n  <MessageActions>\n    <MessageAction tooltip=\"Copy\" onClick={copyToClipboard}>\n      <CopyIcon />\n    </MessageAction>\n  </MessageActions>\n</Message>\n```\n\n**Styling:**\n- User messages: right-aligned, max-width 80%\n- Assistant messages: left-aligned, max-width 80%\n- Adds `is-user` or `is-assistant` class for context-specific styling\n\n### MessageContent\n\nContent area for message text and media.\n\n```typescript\ntype MessageContentProps = HTMLAttributes<HTMLDivElement>;\n```\n\n**Usage:**\n\n```tsx\n<MessageContent>\n  <MessageResponse>{text}</MessageResponse>\n</MessageContent>\n```\n\n**Styling:**\n- User messages: rounded background with secondary color\n- Assistant messages: plain text styling\n- Flexbox column layout for multiple content types\n\n### MessageResponse\n\nRenders markdown/text content with streaming support.\n\n```typescript\ntype MessageResponseProps = ComponentProps<typeof Streamdown>;\n```\n\n**Usage:**\n\n```tsx\n<MessageResponse>\n  {message.content}\n</MessageResponse>\n```\n\n**Features:**\n- Uses `Streamdown` for markdown rendering\n- Memoized to prevent unnecessary re-renders\n- Supports streaming text updates\n- Removes default margin from first/last children\n\n### MessageActions\n\nContainer for action buttons (copy, edit, regenerate, etc.).\n\n```typescript\ntype MessageActionsProps = ComponentProps<\"div\">;\n```\n\n**Usage:**\n\n```tsx\n<MessageActions>\n  <MessageAction tooltip=\"Copy\" onClick={handleCopy}>\n    <CopyIcon />\n  </MessageAction>\n  <MessageAction tooltip=\"Regenerate\" onClick={handleRegenerate}>\n    <RefreshIcon />\n  </MessageAction>\n</MessageActions>\n```\n\n### MessageAction\n\nIndividual action button with optional tooltip.\n\n```typescript\ntype MessageActionProps = ComponentProps<typeof Button> & {\n  tooltip?: string;\n  label?: string;\n};\n```\n\n**Props:**\n- `tooltip?: string` - Tooltip text shown on hover\n- `label?: string` - Accessible label (falls back to tooltip)\n- All Button component props\n\n**Usage:**\n\n```tsx\n<MessageAction\n  tooltip=\"Copy to clipboard\"\n  onClick={handleCopy}\n  variant=\"ghost\"\n  size=\"icon-sm\"\n>\n  <CopyIcon className=\"size-4\" />\n</MessageAction>\n```\n\n## Message Branching\n\n### MessageBranch\n\nContainer for managing alternative message responses with navigation.\n\n```typescript\ntype MessageBranchProps = HTMLAttributes<HTMLDivElement> & {\n  defaultBranch?: number;\n  onBranchChange?: (branchIndex: number) => void;\n};\n```\n\n**Props:**\n- `defaultBranch?: number` - Initial branch index (default: 0)\n- `onBranchChange?: (index: number) => void` - Callback when branch changes\n\n**Usage:**\n\n```tsx\n<MessageBranch defaultBranch={0} onBranchChange={handleBranchChange}>\n  <MessageBranchContent>\n    <MessageResponse key=\"1\">{response1}</MessageResponse>\n    <MessageResponse key=\"2\">{response2}</MessageResponse>\n    <MessageResponse key=\"3\">{response3}</MessageResponse>\n  </MessageBranchContent>\n  <MessageBranchSelector from=\"assistant\">\n    <MessageBranchPrevious />\n    <MessageBranchPage />\n    <MessageBranchNext />\n  </MessageBranchSelector>\n</MessageBranch>\n```\n\n**Context:**\nProvides context with:\n- `currentBranch: number` - Current branch index\n- `totalBranches: number` - Total number of branches\n- `goToPrevious: () => void` - Navigate to previous branch\n- `goToNext: () => void` - Navigate to next branch\n\n### MessageBranchContent\n\nDisplays the current branch content, hiding others.\n\n```typescript\ntype MessageBranchContentProps = HTMLAttributes<HTMLDivElement>;\n```\n\n**Behavior:**\n- Automatically manages branch visibility\n- Updates when children change\n- Preserves all branches in DOM (display: none for hidden)\n\n### MessageBranchSelector\n\nContainer for branch navigation controls.\n\n```typescript\ntype MessageBranchSelectorProps = HTMLAttributes<HTMLDivElement> & {\n  from: UIMessage[\"role\"];\n};\n```\n\n**Behavior:**\n- Only renders if `totalBranches > 1`\n- Uses ButtonGroup for grouped appearance\n\n### MessageBranchPrevious\n\nButton to navigate to previous branch.\n\n```typescript\ntype MessageBranchPreviousProps = ComponentProps<typeof Button>;\n```\n\n**Behavior:**\n- Wraps around (last branch  first branch)\n- Disabled if only one branch exists\n- Default icon: `ChevronLeftIcon`\n\n### MessageBranchNext\n\nButton to navigate to next branch.\n\n```typescript\ntype MessageBranchNextProps = ComponentProps<typeof Button>;\n```\n\n**Behavior:**\n- Wraps around (first branch  last branch)\n- Disabled if only one branch exists\n- Default icon: `ChevronRightIcon`\n\n### MessageBranchPage\n\nDisplays current branch number and total.\n\n```typescript\ntype MessageBranchPageProps = HTMLAttributes<HTMLSpanElement>;\n```\n\n**Display:**\nShows \"1 of 3\", \"2 of 3\", etc.\n\n## Attachment Components\n\n### MessageAttachment\n\nDisplays a file or image attachment with optional remove button.\n\n```typescript\ntype MessageAttachmentProps = HTMLAttributes<HTMLDivElement> & {\n  data: FileUIPart;\n  className?: string;\n  onRemove?: () => void;\n};\n```\n\n**Props:**\n- `data: FileUIPart` - Attachment data (url, filename, mediaType)\n- `onRemove?: () => void` - Callback to remove attachment\n\n**Usage:**\n\n```tsx\n<MessageAttachment\n  data={{\n    type: \"file\",\n    url: \"blob:...\",\n    filename: \"document.pdf\",\n    mediaType: \"application/pdf\"\n  }}\n  onRemove={() => removeAttachment(id)}\n/>\n```\n\n**Behavior:**\n- Images: Shows thumbnail preview\n- Files: Shows paperclip icon\n- Hover: Shows remove button (if onRemove provided)\n- Tooltip: Displays filename on non-image files\n\n### MessageAttachments\n\nContainer for multiple attachments.\n\n```typescript\ntype MessageAttachmentsProps = ComponentProps<\"div\">;\n```\n\n**Usage:**\n\n```tsx\n<MessageAttachments>\n  {attachments.map(attachment => (\n    <MessageAttachment key={attachment.id} data={attachment} />\n  ))}\n</MessageAttachments>\n```\n\n**Styling:**\n- Flexbox wrap layout\n- Right-aligned (ml-auto)\n- Gap between items\n\n## MessageToolbar\n\nContainer for toolbar elements below message content.\n\n```typescript\ntype MessageToolbarProps = ComponentProps<\"div\">;\n```\n\n**Usage:**\n\n```tsx\n<MessageToolbar>\n  <div className=\"flex items-center gap-2\">\n    <span className=\"text-xs text-muted-foreground\">{timestamp}</span>\n  </div>\n  <MessageActions>\n    {/* Action buttons */}\n  </MessageActions>\n</MessageToolbar>\n```\n\n## Complete Example\n\n```tsx\nimport {\n  Conversation,\n  ConversationContent,\n  ConversationEmptyState,\n  ConversationScrollButton,\n} from \"@/components/ai-elements/conversation\";\nimport {\n  Message,\n  MessageContent,\n  MessageResponse,\n  MessageActions,\n  MessageAction,\n  MessageAttachments,\n  MessageAttachment,\n  MessageBranch,\n  MessageBranchContent,\n  MessageBranchSelector,\n  MessageBranchPrevious,\n  MessageBranchNext,\n  MessageBranchPage,\n} from \"@/components/ai-elements/message\";\n\nfunction ChatInterface({ messages }: { messages: UIMessage[] }) {\n  return (\n    <Conversation className=\"flex-1\">\n      {messages.length === 0 ? (\n        <ConversationEmptyState\n          title=\"Start a conversation\"\n          description=\"Ask me anything!\"\n        />\n      ) : (\n        <ConversationContent className=\"p-4\">\n          {messages.map(message => (\n            <Message key={message.id} from={message.role}>\n              {message.attachments && (\n                <MessageAttachments>\n                  {message.attachments.map(att => (\n                    <MessageAttachment key={att.url} data={att} />\n                  ))}\n                </MessageAttachments>\n              )}\n\n              <MessageContent>\n                {message.branches ? (\n                  <MessageBranch>\n                    <MessageBranchContent>\n                      {message.branches.map((branch, idx) => (\n                        <MessageResponse key={idx}>{branch}</MessageResponse>\n                      ))}\n                    </MessageBranchContent>\n                    <MessageBranchSelector from={message.role}>\n                      <MessageBranchPrevious />\n                      <MessageBranchPage />\n                      <MessageBranchNext />\n                    </MessageBranchSelector>\n                  </MessageBranch>\n                ) : (\n                  <MessageResponse>{message.content}</MessageResponse>\n                )}\n              </MessageContent>\n\n              <MessageActions>\n                <MessageAction tooltip=\"Copy\" onClick={() => copy(message)}>\n                  <CopyIcon />\n                </MessageAction>\n                <MessageAction tooltip=\"Regenerate\" onClick={() => regenerate(message)}>\n                  <RefreshIcon />\n                </MessageAction>\n              </MessageActions>\n            </Message>\n          ))}\n        </ConversationContent>\n      )}\n      <ConversationScrollButton />\n    </Conversation>\n  );\n}\n```\n",
        "skills/ai-elements/references/prompt-input.md": "# Prompt Input Components\n\nAdvanced text input components with file attachments, drag-and-drop, speech input, and comprehensive state management.\n\n## Table of Contents\n\n- [Core Components](#core-components)\n- [State Management](#state-management)\n- [Attachment Handling](#attachment-handling)\n- [Action Menus](#action-menus)\n- [Submit Button](#submit-button)\n- [Speech Input](#speech-input)\n- [Advanced Features](#advanced-features)\n- [Complete Example](#complete-example)\n\n## Core Components\n\n### PromptInput\n\nMain form container that handles text input, file attachments, and submission.\n\n```typescript\ntype PromptInputProps = Omit<HTMLAttributes<HTMLFormElement>, \"onSubmit\" | \"onError\"> & {\n  accept?: string;\n  multiple?: boolean;\n  globalDrop?: boolean;\n  syncHiddenInput?: boolean;\n  maxFiles?: number;\n  maxFileSize?: number;\n  onError?: (err: { code: \"max_files\" | \"max_file_size\" | \"accept\"; message: string }) => void;\n  onSubmit: (message: PromptInputMessage, event: FormEvent<HTMLFormElement>) => void | Promise<void>;\n};\n\ntype PromptInputMessage = {\n  text: string;\n  files: FileUIPart[];\n};\n```\n\n**Props:**\n- `accept?: string` - File type filter (e.g., \"image/*\")\n- `multiple?: boolean` - Allow multiple file selection\n- `globalDrop?: boolean` - Accept drops anywhere on document (default: false)\n- `syncHiddenInput?: boolean` - Keep hidden input in sync (default: false)\n- `maxFiles?: number` - Maximum number of files\n- `maxFileSize?: number` - Maximum file size in bytes\n- `onError?: (err) => void` - Error handler for file validation\n- `onSubmit: (message, event) => void | Promise<void>` - Submit handler (required)\n\n**Usage:**\n\n```tsx\n<PromptInput\n  accept=\"image/*\"\n  multiple\n  maxFiles={5}\n  maxFileSize={10 * 1024 * 1024} // 10MB\n  onError={(err) => toast.error(err.message)}\n  onSubmit={async (message) => {\n    await sendMessage(message.text, message.files);\n  }}\n>\n  <PromptInputAttachments>\n    {(attachment) => <PromptInputAttachment data={attachment} />}\n  </PromptInputAttachments>\n\n  <PromptInputBody>\n    <PromptInputTextarea placeholder=\"Type a message...\" />\n  </PromptInputBody>\n\n  <PromptInputFooter>\n    <PromptInputTools>\n      <PromptInputButton onClick={() => attachments.openFileDialog()}>\n        <PaperclipIcon />\n      </PromptInputButton>\n    </PromptInputTools>\n    <PromptInputSubmit status={chatStatus} />\n  </PromptInputFooter>\n</PromptInput>\n```\n\n**Features:**\n- Dual-mode operation (controlled/uncontrolled)\n- Drag-and-drop file handling (local or global)\n- Paste image/file support\n- File validation (type, size, count)\n- Automatic blob URL to data URL conversion\n- Async/sync onSubmit support\n- Auto-reset on successful submission\n\n### PromptInputBody\n\nContainer for the main input area.\n\n```typescript\ntype PromptInputBodyProps = HTMLAttributes<HTMLDivElement>;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputBody>\n  <PromptInputTextarea />\n</PromptInputBody>\n```\n\n### PromptInputTextarea\n\nAuto-expanding textarea with keyboard shortcuts and paste handling.\n\n```typescript\ntype PromptInputTextareaProps = ComponentProps<typeof InputGroupTextarea>;\n```\n\n**Props:**\n- `placeholder?: string` - Placeholder text (default: \"What would you like to know?\")\n- Standard textarea props\n\n**Usage:**\n\n```tsx\n<PromptInputTextarea\n  placeholder=\"Ask me anything...\"\n  className=\"max-h-48 min-h-16\"\n/>\n```\n\n**Keyboard Shortcuts:**\n- `Enter` - Submit (without Shift)\n- `Shift+Enter` - New line\n- `Backspace` - Remove last attachment when textarea is empty\n\n**Features:**\n- Auto-expands with content (field-sizing-content)\n- Paste image/file support\n- Composition event handling (for IME)\n- Respects submit button disabled state\n- Controlled/uncontrolled dual-mode\n\n### PromptInputHeader\n\nHeader section for additional controls above the textarea.\n\n```typescript\ntype PromptInputHeaderProps = Omit<ComponentProps<typeof InputGroupAddon>, \"align\">;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputHeader>\n  <PromptInputSelect>\n    <PromptInputSelectTrigger>\n      <PromptInputSelectValue placeholder=\"Select model\" />\n    </PromptInputSelectTrigger>\n    <PromptInputSelectContent>\n      <PromptInputSelectItem value=\"gpt-4\">GPT-4</PromptInputSelectItem>\n      <PromptInputSelectItem value=\"claude\">Claude</PromptInputSelectItem>\n    </PromptInputSelectContent>\n  </PromptInputSelect>\n</PromptInputHeader>\n```\n\n### PromptInputFooter\n\nFooter section for tools and submit button.\n\n```typescript\ntype PromptInputFooterProps = Omit<ComponentProps<typeof InputGroupAddon>, \"align\">;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputFooter>\n  <PromptInputTools>\n    {/* Tool buttons */}\n  </PromptInputTools>\n  <PromptInputSubmit status=\"ready\" />\n</PromptInputFooter>\n```\n\n### PromptInputTools\n\nContainer for tool buttons in the footer.\n\n```typescript\ntype PromptInputToolsProps = HTMLAttributes<HTMLDivElement>;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputTools>\n  <PromptInputButton onClick={openFileDialog}>\n    <PaperclipIcon />\n  </PromptInputButton>\n  <PromptInputSpeechButton textareaRef={textareaRef} />\n</PromptInputTools>\n```\n\n### PromptInputButton\n\nGeneric button for actions and tools.\n\n```typescript\ntype PromptInputButtonProps = ComponentProps<typeof InputGroupButton>;\n```\n\n**Props:**\n- `variant?: ButtonVariant` - Button style (default: \"ghost\")\n- `size?: ButtonSize` - Button size (auto-determined based on children)\n\n**Usage:**\n\n```tsx\n<PromptInputButton onClick={handleAction}>\n  <IconComponent />\n</PromptInputButton>\n\n<PromptInputButton onClick={handleAction}>\n  <IconComponent />\n  Label\n</PromptInputButton>\n```\n\n## State Management\n\n### PromptInputProvider\n\nOptional global provider that lifts input and attachment state outside of PromptInput.\n\n```typescript\ntype PromptInputProviderProps = PropsWithChildren<{\n  initialInput?: string;\n}>;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputProvider initialInput=\"\">\n  {/* App content */}\n  <PromptInput onSubmit={handleSubmit}>\n    {/* Input content */}\n  </PromptInput>\n\n  {/* External components can access state */}\n  <ExternalComponent />\n</PromptInputProvider>\n```\n\n**Provides:**\n- `textInput: TextInputContext` - Text state and setters\n- `attachments: AttachmentsContext` - File state and methods\n- `__registerFileInput` - Internal registration method\n\n### usePromptInputController\n\nHook to access the provider state.\n\n```typescript\nconst usePromptInputController = () => {\n  const { textInput, attachments } = usePromptInputController();\n\n  return {\n    textInput: {\n      value: string;\n      setInput: (v: string) => void;\n      clear: () => void;\n    },\n    attachments: {\n      files: (FileUIPart & { id: string })[];\n      add: (files: File[] | FileList) => void;\n      remove: (id: string) => void;\n      clear: () => void;\n      openFileDialog: () => void;\n      fileInputRef: RefObject<HTMLInputElement | null>;\n    }\n  };\n};\n```\n\n**Usage:**\n\n```tsx\nfunction ExternalComponent() {\n  const { textInput, attachments } = usePromptInputController();\n\n  return (\n    <div>\n      <p>Current input: {textInput.value}</p>\n      <p>Attachments: {attachments.files.length}</p>\n      <Button onClick={() => textInput.clear()}>Clear</Button>\n    </div>\n  );\n}\n```\n\n### useProviderAttachments\n\nHook to access attachment state from provider.\n\n```typescript\nconst useProviderAttachments = () => AttachmentsContext;\n```\n\n### usePromptInputAttachments\n\nHook to access attachment state (dual-mode: provider or local).\n\n```typescript\nconst usePromptInputAttachments = () => AttachmentsContext;\n```\n\n## Attachment Handling\n\n### PromptInputAttachments\n\nContainer for rendering attachments.\n\n```typescript\ntype PromptInputAttachmentsProps = Omit<HTMLAttributes<HTMLDivElement>, \"children\"> & {\n  children: (attachment: FileUIPart & { id: string }) => ReactNode;\n};\n```\n\n**Usage:**\n\n```tsx\n<PromptInputAttachments>\n  {(attachment) => (\n    <PromptInputAttachment data={attachment} />\n  )}\n</PromptInputAttachments>\n```\n\n**Behavior:**\n- Only renders if attachments exist\n- Uses render prop pattern for flexibility\n\n### PromptInputAttachment\n\nIndividual attachment display with preview and remove button.\n\n```typescript\ntype PromptInputAttachmentProps = HTMLAttributes<HTMLDivElement> & {\n  data: FileUIPart & { id: string };\n  className?: string;\n};\n```\n\n**Usage:**\n\n```tsx\n<PromptInputAttachment\n  data={{\n    id: \"abc123\",\n    type: \"file\",\n    url: \"blob:...\",\n    filename: \"image.png\",\n    mediaType: \"image/png\"\n  }}\n/>\n```\n\n**Features:**\n- Image preview for image/* media types\n- Paperclip icon for other files\n- Hover to reveal remove button\n- Hover card with full preview\n- Truncated filename display\n\n### PromptInputHoverCard\n\nHover card for attachment preview.\n\n```typescript\ntype PromptInputHoverCardProps = ComponentProps<typeof HoverCard>;\n```\n\n**Default Delays:**\n- `openDelay: 0` - Instant open\n- `closeDelay: 0` - Instant close\n\n### PromptInputHoverCardContent\n\nContent area for hover card preview.\n\n```typescript\ntype PromptInputHoverCardContentProps = ComponentProps<typeof HoverCardContent>;\n```\n\n## Action Menus\n\n### PromptInputActionMenu\n\nDropdown menu for additional actions.\n\n```typescript\ntype PromptInputActionMenuProps = ComponentProps<typeof DropdownMenu>;\n```\n\n**Usage:**\n\n```tsx\n<PromptInputActionMenu>\n  <PromptInputActionMenuTrigger>\n    <PlusIcon />\n  </PromptInputActionMenuTrigger>\n  <PromptInputActionMenuContent>\n    <PromptInputActionAddAttachments label=\"Add files\" />\n    <PromptInputActionMenuItem>\n      <SettingsIcon className=\"mr-2 size-4\" />\n      Settings\n    </PromptInputActionMenuItem>\n  </PromptInputActionMenuContent>\n</PromptInputActionMenu>\n```\n\n### PromptInputActionMenuTrigger\n\nTrigger button for action menu.\n\n```typescript\ntype PromptInputActionMenuTriggerProps = PromptInputButtonProps;\n```\n\n**Default Icon:** `PlusIcon`\n\n### PromptInputActionMenuContent\n\nContent area for menu items.\n\n```typescript\ntype PromptInputActionMenuContentProps = ComponentProps<typeof DropdownMenuContent>;\n```\n\n**Default Alignment:** `align=\"start\"`\n\n### PromptInputActionMenuItem\n\nIndividual menu item.\n\n```typescript\ntype PromptInputActionMenuItemProps = ComponentProps<typeof DropdownMenuItem>;\n```\n\n### PromptInputActionAddAttachments\n\nPre-built menu item for adding attachments.\n\n```typescript\ntype PromptInputActionAddAttachmentsProps = ComponentProps<typeof DropdownMenuItem> & {\n  label?: string;\n};\n```\n\n**Props:**\n- `label?: string` - Button label (default: \"Add photos or files\")\n\n**Usage:**\n\n```tsx\n<PromptInputActionMenuContent>\n  <PromptInputActionAddAttachments label=\"Upload images\" />\n</PromptInputActionMenuContent>\n```\n\n## Submit Button\n\n### PromptInputSubmit\n\nStatus-aware submit button with dynamic icons.\n\n```typescript\ntype PromptInputSubmitProps = ComponentProps<typeof InputGroupButton> & {\n  status?: ChatStatus; // \"submitted\" | \"streaming\" | \"error\" | \"ready\"\n};\n```\n\n**Status Icons:**\n- `undefined` / `\"ready\"` - `CornerDownLeftIcon` (enter key)\n- `\"submitted\"` - `Loader2Icon` (spinning)\n- `\"streaming\"` - `SquareIcon` (stop)\n- `\"error\"` - `XIcon` (error)\n\n**Usage:**\n\n```tsx\n<PromptInputSubmit status={chatStatus} />\n```\n\n**Behavior:**\n- `type=\"submit\"` - Triggers form submission\n- `aria-label=\"Submit\"` - Accessible label\n\n## Speech Input\n\n### PromptInputSpeechButton\n\nVoice input button using Web Speech API.\n\n```typescript\ntype PromptInputSpeechButtonProps = ComponentProps<typeof PromptInputButton> & {\n  textareaRef?: RefObject<HTMLTextAreaElement | null>;\n  onTranscriptionChange?: (text: string) => void;\n};\n```\n\n**Props:**\n- `textareaRef?: RefObject` - Reference to textarea for text insertion\n- `onTranscriptionChange?: (text: string) => void` - Callback when text changes\n\n**Usage:**\n\n```tsx\nconst textareaRef = useRef<HTMLTextAreaElement>(null);\n\n<PromptInputTextarea ref={textareaRef} />\n<PromptInputSpeechButton\n  textareaRef={textareaRef}\n  onTranscriptionChange={(text) => console.log(\"Transcribed:\", text)}\n/>\n```\n\n**Features:**\n- Browser-based speech recognition\n- Continuous recording mode\n- Interim results support\n- Automatic text insertion\n- Visual feedback (pulse animation when listening)\n- Disabled if browser doesn't support Speech Recognition\n- Error handling\n\n## Advanced Features\n\n### Select Components\n\nFor model selection or other dropdowns.\n\n```tsx\n<PromptInputSelect value={model} onValueChange={setModel}>\n  <PromptInputSelectTrigger>\n    <PromptInputSelectValue placeholder=\"Select model\" />\n  </PromptInputSelectTrigger>\n  <PromptInputSelectContent>\n    <PromptInputSelectItem value=\"gpt-4\">GPT-4</PromptInputSelectItem>\n    <PromptInputSelectItem value=\"claude\">Claude</PromptInputSelectItem>\n  </PromptInputSelectContent>\n</PromptInputSelect>\n```\n\n### Command Components\n\nFor slash commands or autocomplete.\n\n```tsx\n<PromptInputCommand>\n  <PromptInputCommandInput placeholder=\"Search commands...\" />\n  <PromptInputCommandList>\n    <PromptInputCommandEmpty>No commands found</PromptInputCommandEmpty>\n    <PromptInputCommandGroup heading=\"Actions\">\n      <PromptInputCommandItem value=\"summarize\">\n        Summarize\n      </PromptInputCommandItem>\n      <PromptInputCommandItem value=\"translate\">\n        Translate\n      </PromptInputCommandItem>\n    </PromptInputCommandGroup>\n    <PromptInputCommandSeparator />\n    <PromptInputCommandGroup heading=\"Settings\">\n      <PromptInputCommandItem value=\"preferences\">\n        Preferences\n      </PromptInputCommandItem>\n    </PromptInputCommandGroup>\n  </PromptInputCommandList>\n</PromptInputCommand>\n```\n\n### Tab Components\n\nFor organizing input modes or templates.\n\n```tsx\n<PromptInputTabsList>\n  <PromptInputTab>\n    <PromptInputTabLabel>Templates</PromptInputTabLabel>\n    <PromptInputTabBody>\n      <PromptInputTabItem>Summarize article</PromptInputTabItem>\n      <PromptInputTabItem>Write email</PromptInputTabItem>\n    </PromptInputTabBody>\n  </PromptInputTab>\n</PromptInputTabsList>\n```\n\n## Complete Example\n\n```tsx\nimport { useRef, useState } from \"react\";\nimport {\n  PromptInput,\n  PromptInputProvider,\n  PromptInputAttachments,\n  PromptInputAttachment,\n  PromptInputBody,\n  PromptInputTextarea,\n  PromptInputFooter,\n  PromptInputTools,\n  PromptInputButton,\n  PromptInputSpeechButton,\n  PromptInputSubmit,\n  PromptInputActionMenu,\n  PromptInputActionMenuTrigger,\n  PromptInputActionMenuContent,\n  PromptInputActionAddAttachments,\n  usePromptInputAttachments,\n} from \"@/components/ai-elements/prompt-input\";\nimport { PaperclipIcon, PlusIcon } from \"lucide-react\";\n\nfunction ChatInput() {\n  const [status, setStatus] = useState<ChatStatus>(\"ready\");\n  const textareaRef = useRef<HTMLTextAreaElement>(null);\n  const attachments = usePromptInputAttachments();\n\n  const handleSubmit = async (message: PromptInputMessage) => {\n    setStatus(\"submitted\");\n    try {\n      await sendMessage(message.text, message.files);\n      setStatus(\"ready\");\n    } catch (error) {\n      setStatus(\"error\");\n    }\n  };\n\n  return (\n    <PromptInput\n      accept=\"image/*,.pdf,.doc,.docx\"\n      multiple\n      maxFiles={10}\n      maxFileSize={10 * 1024 * 1024}\n      onError={(err) => toast.error(err.message)}\n      onSubmit={handleSubmit}\n    >\n      <PromptInputAttachments>\n        {(attachment) => <PromptInputAttachment data={attachment} />}\n      </PromptInputAttachments>\n\n      <PromptInputBody>\n        <PromptInputTextarea\n          ref={textareaRef}\n          placeholder=\"Type a message...\"\n        />\n      </PromptInputBody>\n\n      <PromptInputFooter>\n        <PromptInputTools>\n          <PromptInputButton onClick={() => attachments.openFileDialog()}>\n            <PaperclipIcon className=\"size-4\" />\n          </PromptInputButton>\n\n          <PromptInputSpeechButton textareaRef={textareaRef} />\n\n          <PromptInputActionMenu>\n            <PromptInputActionMenuTrigger>\n              <PlusIcon className=\"size-4\" />\n            </PromptInputActionMenuTrigger>\n            <PromptInputActionMenuContent>\n              <PromptInputActionAddAttachments />\n              <PromptInputActionMenuItem>\n                Insert template\n              </PromptInputActionMenuItem>\n            </PromptInputActionMenuContent>\n          </PromptInputActionMenu>\n        </PromptInputTools>\n\n        <PromptInputSubmit status={status} />\n      </PromptInputFooter>\n    </PromptInput>\n  );\n}\n\n// With global provider\nfunction App() {\n  return (\n    <PromptInputProvider initialInput=\"\">\n      <ChatInput />\n    </PromptInputProvider>\n  );\n}\n```\n",
        "skills/ai-elements/references/visualization.md": "# Visualization Components\n\nReactFlow-based components for workflow visualization, custom nodes, and animated edges.\n\n## Core Components\n\n### Canvas\n\nReactFlow wrapper with aviation-specific defaults and background.\n\n```typescript\ntype CanvasProps = ReactFlowProps & {\n  children?: ReactNode;\n};\n```\n\n**Usage:**\n\n```tsx\nimport { Canvas } from \"@/components/ai-elements/canvas\";\nimport { Background, Controls, Panel } from \"@xyflow/react\";\nimport \"@xyflow/react/dist/style.css\";\n\n<Canvas\n  nodes={nodes}\n  edges={edges}\n  nodeTypes={nodeTypes}\n  edgeTypes={edgeTypes}\n  onNodesChange={onNodesChange}\n  onEdgesChange={onEdgesChange}\n>\n  <Background bgColor=\"var(--sidebar)\" />\n  <Controls />\n  <Panel position=\"top-left\">\n    <h3>Workflow</h3>\n  </Panel>\n</Canvas>\n```\n\n**Default Props:**\n- `deleteKeyCode: [\"Backspace\", \"Delete\"]` - Keys to delete selected elements\n- `fitView: true` - Automatically fit content in viewport\n- `panOnDrag: false` - Disable pan on drag (use selection instead)\n- `panOnScroll: true` - Enable pan on scroll\n- `selectionOnDrag: true` - Enable selection box on drag\n- `zoomOnDoubleClick: false` - Disable zoom on double click\n\n**Features:**\n- Includes Background component with sidebar color\n- Accepts all ReactFlow props\n- Optimized for workflow visualization\n\n## Node Components\n\nCustom node components built on shadcn/ui Card components.\n\n### Node\n\nMain node container with connection handles.\n\n```typescript\ntype NodeProps = ComponentProps<typeof Card> & {\n  handles: {\n    target: boolean;\n    source: boolean;\n  };\n};\n```\n\n**Props:**\n- `handles: { target: boolean; source: boolean }` - Which handles to show (required)\n- All Card component props\n\n**Usage:**\n\n```tsx\n<Node handles={{ target: true, source: true }}>\n  <NodeHeader>\n    <NodeTitle>Process Data</NodeTitle>\n    <NodeDescription>Transform input data</NodeDescription>\n  </NodeHeader>\n  <NodeContent>\n    {/* Node content */}\n  </NodeContent>\n  <NodeFooter>\n    Status: Running\n  </NodeFooter>\n</Node>\n```\n\n**Handle Positions:**\n- Target: Left side (incoming connections)\n- Source: Right side (outgoing connections)\n\n**Default Styling:**\n- Relative positioning for handles\n- Auto height\n- Fixed width (w-sm)\n- Rounded corners\n\n### NodeHeader\n\nHeader section with border bottom and secondary background.\n\n```typescript\ntype NodeHeaderProps = ComponentProps<typeof CardHeader>;\n```\n\n**Usage:**\n\n```tsx\n<NodeHeader>\n  <NodeTitle>Step 1</NodeTitle>\n  <NodeDescription>Initial processing</NodeDescription>\n  <NodeAction onClick={handleEdit}>\n    <EditIcon />\n  </NodeAction>\n</NodeHeader>\n```\n\n**Default Styling:**\n- Rounded top corners\n- Border bottom\n- Secondary background\n- Compact padding (p-3)\n\n### NodeTitle\n\nTitle text for node header.\n\n```typescript\ntype NodeTitleProps = ComponentProps<typeof CardTitle>;\n```\n\n**Usage:**\n\n```tsx\n<NodeTitle>Data Processing</NodeTitle>\n```\n\n### NodeDescription\n\nSecondary description text.\n\n```typescript\ntype NodeDescriptionProps = ComponentProps<typeof CardDescription>;\n```\n\n**Usage:**\n\n```tsx\n<NodeDescription>\n  Transform and validate input data\n</NodeDescription>\n```\n\n### NodeAction\n\nAction button in header (typically edit/delete).\n\n```typescript\ntype NodeActionProps = ComponentProps<typeof CardAction>;\n```\n\n**Usage:**\n\n```tsx\n<NodeAction onClick={handleEdit}>\n  <EditIcon className=\"size-4\" />\n</NodeAction>\n```\n\n### NodeContent\n\nMain content area of the node.\n\n```typescript\ntype NodeContentProps = ComponentProps<typeof CardContent>;\n```\n\n**Usage:**\n\n```tsx\n<NodeContent>\n  <div className=\"space-y-2\">\n    <Label>Input</Label>\n    <Input value={data.input} readOnly />\n    <Label>Output</Label>\n    <Input value={data.output} readOnly />\n  </div>\n</NodeContent>\n```\n\n**Default Styling:**\n- Compact padding (p-3)\n\n### NodeFooter\n\nFooter section with border top and secondary background.\n\n```typescript\ntype NodeFooterProps = ComponentProps<typeof CardFooter>;\n```\n\n**Usage:**\n\n```tsx\n<NodeFooter>\n  <Badge variant=\"success\">Completed</Badge>\n  <span className=\"text-xs text-muted-foreground\">\n    Duration: 1.2s\n  </span>\n</NodeFooter>\n```\n\n**Default Styling:**\n- Rounded bottom corners\n- Border top\n- Secondary background\n- Compact padding (p-3)\n\n## Edge Components\n\nCustom edge types for different connection styles.\n\n### Edge.Temporary\n\nDashed edge for temporary or preview connections.\n\n```typescript\ntype TemporaryEdgeProps = EdgeProps;\n```\n\n**Usage:**\n\n```tsx\nconst edgeTypes = {\n  temporary: Edge.Temporary,\n};\n\n<Canvas edges={edges} edgeTypes={edgeTypes} />\n```\n\n**Features:**\n- Simple Bezier curve\n- Dashed stroke (5, 5)\n- Ring color stroke\n- Stroke width: 1\n\n**Use Cases:**\n- Drag preview connections\n- Temporary workflow paths\n- Suggested connections\n\n### Edge.Animated\n\nAnimated edge with moving dot indicator.\n\n```typescript\ntype AnimatedEdgeProps = EdgeProps;\n```\n\n**Usage:**\n\n```tsx\nconst edgeTypes = {\n  animated: Edge.Animated,\n};\n\n<Canvas edges={edges} edgeTypes={edgeTypes} />\n```\n\n**Features:**\n- Bezier curve path\n- Animated circle following edge path\n- 2-second animation duration\n- Infinite repeat\n- Primary color dot (4px radius)\n\n**Use Cases:**\n- Active data flow\n- Processing pipelines\n- Real-time connections\n\n**Implementation Details:**\n- Uses `useInternalNode` to get node positions\n- Calculates handle coordinates based on position\n- Supports Left (target) and Right (source) handle positions\n- Uses `getBezierPath` for smooth curves\n\n## ReactFlow Integration\n\n### Controls\n\nStandard ReactFlow controls (zoom, fit view, etc.).\n\n```typescript\nimport { Controls } from \"@xyflow/react\";\n```\n\n**Usage:**\n\n```tsx\n<Canvas>\n  <Controls />\n</Canvas>\n```\n\n### Panel\n\nPanel for custom UI overlays.\n\n```typescript\nimport { Panel } from \"@xyflow/react\";\n```\n\n**Usage:**\n\n```tsx\n<Canvas>\n  <Panel position=\"top-left\">\n    <h3>Workflow Name</h3>\n    <p>Status: Running</p>\n  </Panel>\n  <Panel position=\"bottom-right\">\n    <Button onClick={handleSave}>Save</Button>\n  </Panel>\n</Canvas>\n```\n\n**Positions:**\n- `top-left`, `top-center`, `top-right`\n- `bottom-left`, `bottom-center`, `bottom-right`\n\n### Background\n\nBackground pattern for the canvas.\n\n```typescript\nimport { Background } from \"@xyflow/react\";\n```\n\n**Usage:**\n\n```tsx\n<Canvas>\n  <Background bgColor=\"var(--sidebar)\" />\n</Canvas>\n```\n\n## Custom Node Types\n\nExample of creating custom node types with aviation-specific styling.\n\n```tsx\nimport { Node, NodeHeader, NodeTitle, NodeContent, NodeFooter } from \"@/components/ai-elements/node\";\nimport type { NodeProps } from \"@xyflow/react\";\n\ntype ProcessNodeData = {\n  label: string;\n  status: \"pending\" | \"running\" | \"completed\" | \"failed\";\n  input?: string;\n  output?: string;\n};\n\nfunction ProcessNode({ data }: NodeProps<ProcessNodeData>) {\n  const statusColors = {\n    pending: \"bg-gray-500\",\n    running: \"bg-blue-500 animate-pulse\",\n    completed: \"bg-green-500\",\n    failed: \"bg-red-500\",\n  };\n\n  return (\n    <Node handles={{ target: true, source: true }}>\n      <NodeHeader>\n        <NodeTitle>{data.label}</NodeTitle>\n      </NodeHeader>\n\n      <NodeContent>\n        {data.input && (\n          <div className=\"space-y-1\">\n            <Label className=\"text-xs\">Input</Label>\n            <p className=\"text-xs text-muted-foreground\">{data.input}</p>\n          </div>\n        )}\n        {data.output && (\n          <div className=\"space-y-1\">\n            <Label className=\"text-xs\">Output</Label>\n            <p className=\"text-xs text-muted-foreground\">{data.output}</p>\n          </div>\n        )}\n      </NodeContent>\n\n      <NodeFooter>\n        <div className=\"flex items-center gap-2\">\n          <div className={cn(\"size-2 rounded-full\", statusColors[data.status])} />\n          <span className=\"text-xs capitalize\">{data.status}</span>\n        </div>\n      </NodeFooter>\n    </Node>\n  );\n}\n\n// Register custom node type\nconst nodeTypes = {\n  process: ProcessNode,\n};\n\n<Canvas nodeTypes={nodeTypes} />\n```\n\n## Complete Example\n\n```tsx\nimport { useState } from \"react\";\nimport { Canvas } from \"@/components/ai-elements/canvas\";\nimport {\n  Node,\n  NodeHeader,\n  NodeTitle,\n  NodeDescription,\n  NodeContent,\n  NodeFooter,\n} from \"@/components/ai-elements/node\";\nimport { Edge } from \"@/components/ai-elements/edge\";\nimport {\n  Background,\n  Controls,\n  Panel,\n  useNodesState,\n  useEdgesState,\n  addEdge,\n  type Connection,\n} from \"@xyflow/react\";\nimport \"@xyflow/react/dist/style.css\";\n\nconst initialNodes = [\n  {\n    id: \"1\",\n    type: \"custom\",\n    position: { x: 0, y: 0 },\n    data: { label: \"Start\", status: \"completed\" },\n  },\n  {\n    id: \"2\",\n    type: \"custom\",\n    position: { x: 250, y: 0 },\n    data: { label: \"Process\", status: \"running\" },\n  },\n  {\n    id: \"3\",\n    type: \"custom\",\n    position: { x: 500, y: 0 },\n    data: { label: \"End\", status: \"pending\" },\n  },\n];\n\nconst initialEdges = [\n  {\n    id: \"e1-2\",\n    source: \"1\",\n    target: \"2\",\n    type: \"animated\",\n  },\n  {\n    id: \"e2-3\",\n    source: \"2\",\n    target: \"3\",\n    type: \"temporary\",\n  },\n];\n\nfunction CustomNode({ data }) {\n  return (\n    <Node handles={{ target: true, source: true }}>\n      <NodeHeader>\n        <NodeTitle>{data.label}</NodeTitle>\n        <NodeDescription>Step in workflow</NodeDescription>\n      </NodeHeader>\n      <NodeContent>\n        <p className=\"text-sm\">Status: {data.status}</p>\n      </NodeContent>\n      <NodeFooter>\n        <Badge variant={data.status === \"completed\" ? \"success\" : \"default\"}>\n          {data.status}\n        </Badge>\n      </NodeFooter>\n    </Node>\n  );\n}\n\nconst nodeTypes = {\n  custom: CustomNode,\n};\n\nconst edgeTypes = {\n  temporary: Edge.Temporary,\n  animated: Edge.Animated,\n};\n\nfunction WorkflowCanvas() {\n  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);\n  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);\n\n  const onConnect = (connection: Connection) => {\n    setEdges((eds) => addEdge({ ...connection, type: \"animated\" }, eds));\n  };\n\n  return (\n    <div className=\"h-screen\">\n      <Canvas\n        nodes={nodes}\n        edges={edges}\n        nodeTypes={nodeTypes}\n        edgeTypes={edgeTypes}\n        onNodesChange={onNodesChange}\n        onEdgesChange={onEdgesChange}\n        onConnect={onConnect}\n      >\n        <Background bgColor=\"var(--sidebar)\" />\n        <Controls />\n        <Panel position=\"top-left\">\n          <div className=\"rounded-lg bg-background p-4 shadow-lg\">\n            <h3 className=\"font-semibold\">Workflow</h3>\n            <p className=\"text-sm text-muted-foreground\">\n              {nodes.length} nodes, {edges.length} edges\n            </p>\n          </div>\n        </Panel>\n      </Canvas>\n    </div>\n  );\n}\n```\n\n## Handle Positioning\n\nThe edge components use custom handle coordinate calculation:\n\n```typescript\nconst getHandleCoordsByPosition = (node, handlePosition) => {\n  const handleType = handlePosition === Position.Left ? \"target\" : \"source\";\n  const handle = node.internals.handleBounds?.[handleType]?.find(\n    (h) => h.position === handlePosition\n  );\n\n  // Calculate absolute coordinates\n  const offsetX = handlePosition === Position.Right ? handle.width : 0;\n  const offsetY = handlePosition === Position.Bottom ? handle.height : 0;\n\n  const x = node.internals.positionAbsolute.x + handle.x + offsetX;\n  const y = node.internals.positionAbsolute.y + handle.y + offsetY;\n\n  return [x, y];\n};\n```\n\nThis ensures edges connect properly to handle centers.\n\n## Styling Tips\n\n### Node Widths\n\nControl node width with Tailwind classes:\n\n```tsx\n<Node handles={handles} className=\"w-64\">\n  {/* wider node */}\n</Node>\n\n<Node handles={handles} className=\"w-96\">\n  {/* extra wide node */}\n</Node>\n```\n\n### Edge Colors\n\nCustomize edge colors via className:\n\n```tsx\n// In custom edge component\n<BaseEdge\n  className=\"stroke-2 stroke-primary\"\n  id={id}\n  path={edgePath}\n/>\n```\n\n### Node Status Indicators\n\nAdd visual status indicators:\n\n```tsx\n<NodeFooter>\n  <div className=\"flex items-center gap-2\">\n    <div className={cn(\n      \"size-2 rounded-full\",\n      status === \"running\" && \"bg-blue-500 animate-pulse\",\n      status === \"completed\" && \"bg-green-500\",\n      status === \"failed\" && \"bg-red-500\"\n    )} />\n    <span className=\"text-xs\">{status}</span>\n  </div>\n</NodeFooter>\n```\n\n## Integration with Aviation Nodes\n\nAI Elements Canvas integrates seamlessly with custom aviation-specific node types. The Node component provides a flexible base for domain-specific extensions:\n\n```tsx\n// Aviation-specific node\nfunction FlightPlanNode({ data }) {\n  return (\n    <Node handles={{ target: true, source: true }}>\n      <NodeHeader>\n        <NodeTitle>{data.flightNumber}</NodeTitle>\n        <NodeDescription>{data.route}</NodeDescription>\n      </NodeHeader>\n      <NodeContent>\n        <div className=\"space-y-2 text-xs\">\n          <div>Departure: {data.departure}</div>\n          <div>Arrival: {data.arrival}</div>\n          <div>Aircraft: {data.aircraft}</div>\n        </div>\n      </NodeContent>\n      <NodeFooter>\n        <Badge>{data.status}</Badge>\n      </NodeFooter>\n    </Node>\n  );\n}\n```\n",
        "skills/ai-elements/references/workflow.md": "# Workflow Components\n\nComponents for displaying job queues, tool execution, approval workflows, and reasoning displays.\n\n## Table of Contents\n\n- [Queue Components](#queue-components)\n- [Tool Components](#tool-components)\n- [Confirmation Components](#confirmation-components)\n- [Reasoning Components](#reasoning-components)\n- [Loading Components](#loading-components)\n\n## Queue Components\n\nComponents for displaying task lists, job queues, and progress tracking.\n\n### Queue\n\nMain container for queue items and sections.\n\n```typescript\ntype QueueProps = ComponentProps<\"div\">;\n```\n\n**Usage:**\n\n```tsx\n<Queue>\n  <QueueSection>\n    {/* Queue items */}\n  </QueueSection>\n</Queue>\n```\n\n**Default Styling:**\n- Bordered container with rounded corners\n- Background with shadow\n- Flexbox column layout with gap\n\n### QueueSection\n\nCollapsible section for organizing queue items.\n\n```typescript\ntype QueueSectionProps = ComponentProps<typeof Collapsible>;\n```\n\n**Props:**\n- `defaultOpen?: boolean` - Initial open state (default: true)\n\n**Usage:**\n\n```tsx\n<QueueSection defaultOpen={true}>\n  <QueueSectionTrigger>\n    <QueueSectionLabel count={5} label=\"pending tasks\" />\n  </QueueSectionTrigger>\n  <QueueSectionContent>\n    <QueueList>\n      {/* Queue items */}\n    </QueueList>\n  </QueueSectionContent>\n</QueueSection>\n```\n\n### QueueSectionTrigger\n\nClickable header to toggle section visibility.\n\n```typescript\ntype QueueSectionTriggerProps = ComponentProps<\"button\">;\n```\n\n**Default Styling:**\n- Full width button\n- Muted background with hover effect\n- Flexbox layout for content alignment\n\n### QueueSectionLabel\n\nLabel with icon, text, and count display.\n\n```typescript\ntype QueueSectionLabelProps = ComponentProps<\"span\"> & {\n  count?: number;\n  label: string;\n  icon?: React.ReactNode;\n};\n```\n\n**Props:**\n- `count?: number` - Item count to display\n- `label: string` - Section label (required)\n- `icon?: React.ReactNode` - Optional icon\n\n**Usage:**\n\n```tsx\n<QueueSectionLabel\n  count={todos.length}\n  label=\"todos\"\n  icon={<CheckSquareIcon className=\"size-4\" />}\n/>\n```\n\n**Display:**\nShows \"{count} {label}\" with chevron icon that rotates when expanded.\n\n### QueueSectionContent\n\nCollapsible content area for queue items.\n\n```typescript\ntype QueueSectionContentProps = ComponentProps<typeof CollapsibleContent>;\n```\n\n### QueueList\n\nScrollable container for queue items.\n\n```typescript\ntype QueueListProps = ComponentProps<typeof ScrollArea>;\n```\n\n**Default Styling:**\n- Max height of 40 (10rem)\n- Scrollable when content overflows\n- Padding for scroll area\n\n**Usage:**\n\n```tsx\n<QueueList>\n  {items.map(item => (\n    <QueueItem key={item.id}>\n      {/* Item content */}\n    </QueueItem>\n  ))}\n</QueueList>\n```\n\n### QueueItem\n\nIndividual queue item container.\n\n```typescript\ntype QueueItemProps = ComponentProps<\"li\">;\n```\n\n**Usage:**\n\n```tsx\n<QueueItem>\n  <QueueItemIndicator completed={todo.status === 'completed'} />\n  <QueueItemContent completed={todo.status === 'completed'}>\n    {todo.title}\n  </QueueItemContent>\n  {todo.description && (\n    <QueueItemDescription completed={todo.status === 'completed'}>\n      {todo.description}\n    </QueueItemDescription>\n  )}\n  <QueueItemActions>\n    <QueueItemAction onClick={handleEdit}>\n      <EditIcon />\n    </QueueItemAction>\n  </QueueItemActions>\n</QueueItem>\n```\n\n**Default Styling:**\n- Flexbox column layout\n- Hover background effect\n- Grouped item styling\n\n### QueueItemIndicator\n\nStatus indicator dot.\n\n```typescript\ntype QueueItemIndicatorProps = ComponentProps<\"span\"> & {\n  completed?: boolean;\n};\n```\n\n**Props:**\n- `completed?: boolean` - Whether item is completed (default: false)\n\n**Styling:**\n- Pending: Solid border\n- Completed: Muted border and background\n\n### QueueItemContent\n\nMain content text for queue item.\n\n```typescript\ntype QueueItemContentProps = ComponentProps<\"span\"> & {\n  completed?: boolean;\n};\n```\n\n**Props:**\n- `completed?: boolean` - Whether item is completed (default: false)\n\n**Styling:**\n- Pending: Normal text\n- Completed: Muted text with line-through\n\n### QueueItemDescription\n\nSecondary description text.\n\n```typescript\ntype QueueItemDescriptionProps = ComponentProps<\"div\"> & {\n  completed?: boolean;\n};\n```\n\n**Props:**\n- `completed?: boolean` - Whether item is completed (default: false)\n\n**Styling:**\n- Smaller text size\n- Indented under main content\n- Muted color (more muted if completed)\n\n### QueueItemActions\n\nContainer for action buttons.\n\n```typescript\ntype QueueItemActionsProps = ComponentProps<\"div\">;\n```\n\n**Usage:**\n\n```tsx\n<QueueItemActions>\n  <QueueItemAction onClick={handleEdit}>\n    <EditIcon />\n  </QueueItemAction>\n  <QueueItemAction onClick={handleDelete}>\n    <TrashIcon />\n  </QueueItemAction>\n</QueueItemActions>\n```\n\n### QueueItemAction\n\nIndividual action button.\n\n```typescript\ntype QueueItemActionProps = Omit<ComponentProps<typeof Button>, \"variant\" | \"size\">;\n```\n\n**Behavior:**\n- Hidden by default\n- Visible on item hover\n- Ghost variant\n- Icon size\n\n### QueueItemAttachment\n\nContainer for attached files/images.\n\n```typescript\ntype QueueItemAttachmentProps = ComponentProps<\"div\">;\n```\n\n### QueueItemImage\n\nImage preview thumbnail.\n\n```typescript\ntype QueueItemImageProps = ComponentProps<\"img\">;\n```\n\n**Default Size:** 32x32px\n\n### QueueItemFile\n\nFile attachment display with icon.\n\n```typescript\ntype QueueItemFileProps = ComponentProps<\"span\">;\n```\n\n**Features:**\n- Paperclip icon\n- Truncated filename (max 100px)\n- Border and background styling\n\n## Tool Components\n\nComponents for displaying tool execution with states, parameters, and results.\n\n### Tool\n\nMain container for tool execution display.\n\n```typescript\ntype ToolProps = ComponentProps<typeof Collapsible>;\n```\n\n**Usage:**\n\n```tsx\n<Tool>\n  <ToolHeader\n    title=\"search\"\n    type=\"tool-call-search\"\n    state=\"output-available\"\n  />\n  <ToolContent>\n    <ToolInput input={{ query: \"AI tools\" }} />\n    <ToolOutput output={results} errorText={undefined} />\n  </ToolContent>\n</Tool>\n```\n\n**Default Styling:**\n- Bordered container\n- Rounded corners\n- Not prose (for content formatting)\n\n### ToolHeader\n\nCollapsible trigger showing tool name and status.\n\n```typescript\ntype ToolHeaderProps = {\n  title?: string;\n  type: ToolUIPart[\"type\"];\n  state: ToolUIPart[\"state\"];\n  className?: string;\n};\n```\n\n**Props:**\n- `title?: string` - Display name (defaults to type without \"tool-call-\" prefix)\n- `type: string` - Tool type identifier\n- `state: ToolState` - Current execution state (required)\n\n**Tool States:**\n- `input-streaming` - Parameters being received (Pending badge)\n- `input-available` - Ready to execute (Running badge, pulsing)\n- `approval-requested` - Awaiting approval (Awaiting Approval badge, yellow)\n- `approval-responded` - User responded (Responded badge, blue)\n- `output-available` - Completed (Completed badge, green)\n- `output-error` - Failed (Error badge, red)\n- `output-denied` - Approval denied (Denied badge, orange)\n\n**Features:**\n- Wrench icon\n- Color-coded status badge\n- Chevron that rotates when expanded\n\n### ToolContent\n\nCollapsible content area for parameters and results.\n\n```typescript\ntype ToolContentProps = ComponentProps<typeof CollapsibleContent>;\n```\n\n**Animation:**\n- Slide in/out from top\n- Fade transition\n\n### ToolInput\n\nDisplays tool parameters/arguments.\n\n```typescript\ntype ToolInputProps = ComponentProps<\"div\"> & {\n  input: ToolUIPart[\"input\"];\n};\n```\n\n**Props:**\n- `input: unknown` - Tool parameters (any JSON-serializable value)\n\n**Usage:**\n\n```tsx\n<ToolInput\n  input={{\n    query: \"AI tools\",\n    limit: 10,\n    filters: [\"type:library\"]\n  }}\n/>\n```\n\n**Features:**\n- \"PARAMETERS\" heading\n- JSON syntax highlighting via CodeBlock\n- Automatic JSON.stringify with formatting\n\n### ToolOutput\n\nDisplays tool results or errors.\n\n```typescript\ntype ToolOutputProps = ComponentProps<\"div\"> & {\n  output: ToolUIPart[\"output\"];\n  errorText: ToolUIPart[\"errorText\"];\n};\n```\n\n**Props:**\n- `output: unknown` - Tool result (any value, React element, or JSON)\n- `errorText?: string` - Error message if execution failed\n\n**Usage:**\n\n```tsx\n<ToolOutput\n  output={{\n    results: [...],\n    count: 42\n  }}\n  errorText={undefined}\n/>\n```\n\n**Behavior:**\n- Shows \"RESULT\" heading for success\n- Shows \"ERROR\" heading for errors\n- Renders React elements directly\n- JSON stringifies objects\n- CodeBlock for strings\n- Destructive styling for errors\n\n## Confirmation Components\n\nComponents for approval workflows requiring user confirmation.\n\n### Confirmation\n\nContainer for confirmation UI with conditional rendering based on state.\n\n```typescript\ntype ConfirmationProps = ComponentProps<typeof Alert> & {\n  approval?: ToolUIPartApproval;\n  state: ToolUIPart[\"state\"];\n};\n\ntype ToolUIPartApproval =\n  | { id: string; approved?: never; reason?: never }\n  | { id: string; approved: boolean; reason?: string }\n  | undefined;\n```\n\n**Props:**\n- `approval?: ToolUIPartApproval` - Approval data\n- `state: ToolState` - Current state\n\n**Usage:**\n\n```tsx\n<Confirmation approval={tool.approval} state={tool.state}>\n  <ConfirmationTitle>\n    Delete {count} files?\n  </ConfirmationTitle>\n\n  <ConfirmationRequest>\n    <ConfirmationActions>\n      <ConfirmationAction onClick={handleApprove} variant=\"default\">\n        Approve\n      </ConfirmationAction>\n      <ConfirmationAction onClick={handleReject} variant=\"outline\">\n        Reject\n      </ConfirmationAction>\n    </ConfirmationActions>\n  </ConfirmationRequest>\n\n  <ConfirmationAccepted>\n    Action approved and executed.\n  </ConfirmationAccepted>\n\n  <ConfirmationRejected>\n    Action rejected.\n  </ConfirmationRejected>\n</Confirmation>\n```\n\n**Context:**\nProvides `{ approval, state }` to child components.\n\n### ConfirmationTitle\n\nTitle/description of the confirmation request.\n\n```typescript\ntype ConfirmationTitleProps = ComponentProps<typeof AlertDescription>;\n```\n\n### ConfirmationRequest\n\nContainer shown during approval-requested state.\n\n```typescript\ntype ConfirmationRequestProps = { children?: ReactNode };\n```\n\n**Visibility:**\nOnly shown when `state === \"approval-requested\"`\n\n### ConfirmationActions\n\nContainer for approve/reject buttons.\n\n```typescript\ntype ConfirmationActionsProps = ComponentProps<\"div\">;\n```\n\n**Visibility:**\nOnly shown when `state === \"approval-requested\"`\n\n### ConfirmationAction\n\nIndividual action button.\n\n```typescript\ntype ConfirmationActionProps = ComponentProps<typeof Button>;\n```\n\n**Default Styling:**\n- Small height (h-8)\n- Compact padding\n\n### ConfirmationAccepted\n\nContent shown when approval is accepted.\n\n```typescript\ntype ConfirmationAcceptedProps = { children?: ReactNode };\n```\n\n**Visibility:**\nOnly shown when `approval.approved === true` and state is response/output state.\n\n### ConfirmationRejected\n\nContent shown when approval is rejected.\n\n```typescript\ntype ConfirmationRejectedProps = { children?: ReactNode };\n```\n\n**Visibility:**\nOnly shown when `approval.approved === false` and state is response/output state.\n\n### useConfirmation\n\nHook to access confirmation context.\n\n```typescript\nconst useConfirmation = () => {\n  const { approval, state } = useConfirmation();\n  // ...\n};\n```\n\n## Reasoning Components\n\nComponents for displaying AI thinking/reasoning with auto-collapse behavior.\n\n### Reasoning\n\nCollapsible container for reasoning content with auto-collapse.\n\n```typescript\ntype ReasoningProps = ComponentProps<typeof Collapsible> & {\n  isStreaming?: boolean;\n  open?: boolean;\n  defaultOpen?: boolean;\n  onOpenChange?: (open: boolean) => void;\n  duration?: number;\n};\n```\n\n**Props:**\n- `isStreaming?: boolean` - Whether content is actively streaming (default: false)\n- `open?: boolean` - Controlled open state\n- `defaultOpen?: boolean` - Initial open state (default: true)\n- `onOpenChange?: (open: boolean) => void` - Callback when open state changes\n- `duration?: number` - Thinking duration in seconds\n\n**Usage:**\n\n```tsx\n<Reasoning isStreaming={isStreaming} defaultOpen={true}>\n  <ReasoningTrigger />\n  <ReasoningContent>\n    {reasoningText}\n  </ReasoningContent>\n</Reasoning>\n```\n\n**Auto-Collapse Behavior:**\n1. Opens automatically when streaming starts\n2. Tracks duration from start to end of streaming\n3. Closes 1 second after streaming ends\n4. Auto-close only happens once per component lifecycle\n\n**Context:**\nProvides `{ isStreaming, isOpen, setIsOpen, duration }` to children.\n\n### ReasoningTrigger\n\nTrigger button with status message and icon.\n\n```typescript\ntype ReasoningTriggerProps = ComponentProps<typeof CollapsibleTrigger> & {\n  getThinkingMessage?: (isStreaming: boolean, duration?: number) => ReactNode;\n};\n```\n\n**Props:**\n- `getThinkingMessage?: (isStreaming, duration) => ReactNode` - Custom message generator\n\n**Default Messages:**\n- Streaming: \"Thinking...\" with shimmer effect\n- Duration 0 or undefined: \"Thought for a few seconds\"\n- Duration N: \"Thought for N seconds\"\n\n**Usage:**\n\n```tsx\n<ReasoningTrigger />\n\n// Custom message\n<ReasoningTrigger\n  getThinkingMessage={(streaming, duration) =>\n    streaming ? <Shimmer>Processing...</Shimmer> : `Done in ${duration}s`\n  }\n/>\n```\n\n**Icons:**\n- Brain icon\n- Rotating chevron (down when closed, up when open)\n\n### ReasoningContent\n\nCollapsible content area with markdown rendering.\n\n```typescript\ntype ReasoningContentProps = ComponentProps<typeof CollapsibleContent> & {\n  children: string;\n};\n```\n\n**Props:**\n- `children: string` - Reasoning text (required, string only)\n\n**Features:**\n- Uses Streamdown for markdown rendering\n- Slide and fade animations\n- Muted text color\n\n### useReasoning\n\nHook to access reasoning context.\n\n```typescript\nconst useReasoning = () => {\n  const { isStreaming, isOpen, setIsOpen, duration } = useReasoning();\n  // ...\n};\n```\n\n## Loading Components\n\n### Shimmer\n\nAnimated shimmer effect for loading text.\n\n```typescript\ntype TextShimmerProps = {\n  children: string;\n  as?: ElementType;\n  className?: string;\n  duration?: number;\n  spread?: number;\n};\n```\n\n**Props:**\n- `children: string` - Text to shimmer (required)\n- `as?: ElementType` - HTML element type (default: \"p\")\n- `className?: string` - Additional classes\n- `duration?: number` - Animation duration in seconds (default: 2)\n- `spread?: number` - Shimmer spread multiplier (default: 2)\n\n**Usage:**\n\n```tsx\n<Shimmer duration={1.5}>Thinking...</Shimmer>\n<Shimmer as=\"span\" spread={3}>Loading data...</Shimmer>\n```\n\n**Features:**\n- Framer Motion animation\n- Gradient sweep effect\n- Dynamic spread based on text length\n- Infinite loop\n\n### Loader\n\nSpinning loader icon.\n\n```typescript\ntype LoaderProps = HTMLAttributes<HTMLDivElement> & {\n  size?: number;\n};\n```\n\n**Props:**\n- `size?: number` - Icon size in pixels (default: 16)\n\n**Usage:**\n\n```tsx\n<Loader size={24} />\n<Loader className=\"text-primary\" />\n```\n\n**Features:**\n- SVG-based spinner\n- CSS animation (spin)\n- Respects current color\n\n## Complete Example\n\n```tsx\nimport {\n  Queue,\n  QueueSection,\n  QueueSectionTrigger,\n  QueueSectionLabel,\n  QueueSectionContent,\n  QueueList,\n  QueueItem,\n  QueueItemIndicator,\n  QueueItemContent,\n  QueueItemDescription,\n} from \"@/components/ai-elements/queue\";\nimport {\n  Tool,\n  ToolHeader,\n  ToolContent,\n  ToolInput,\n  ToolOutput,\n} from \"@/components/ai-elements/tool\";\nimport {\n  Confirmation,\n  ConfirmationTitle,\n  ConfirmationRequest,\n  ConfirmationActions,\n  ConfirmationAction,\n  ConfirmationAccepted,\n  ConfirmationRejected,\n} from \"@/components/ai-elements/confirmation\";\nimport {\n  Reasoning,\n  ReasoningTrigger,\n  ReasoningContent,\n} from \"@/components/ai-elements/reasoning\";\n\nfunction WorkflowDisplay({ todos, tools, reasoning }) {\n  return (\n    <div className=\"space-y-4\">\n      {/* Queue */}\n      <Queue>\n        <QueueSection>\n          <QueueSectionTrigger>\n            <QueueSectionLabel count={todos.length} label=\"tasks\" />\n          </QueueSectionTrigger>\n          <QueueSectionContent>\n            <QueueList>\n              {todos.map(todo => (\n                <QueueItem key={todo.id}>\n                  <QueueItemIndicator completed={todo.completed} />\n                  <QueueItemContent completed={todo.completed}>\n                    {todo.title}\n                  </QueueItemContent>\n                  {todo.description && (\n                    <QueueItemDescription completed={todo.completed}>\n                      {todo.description}\n                    </QueueItemDescription>\n                  )}\n                </QueueItem>\n              ))}\n            </QueueList>\n          </QueueSectionContent>\n        </QueueSection>\n      </Queue>\n\n      {/* Reasoning */}\n      {reasoning && (\n        <Reasoning isStreaming={reasoning.isStreaming}>\n          <ReasoningTrigger />\n          <ReasoningContent>{reasoning.content}</ReasoningContent>\n        </Reasoning>\n      )}\n\n      {/* Tools */}\n      {tools.map(tool => (\n        <div key={tool.id}>\n          <Tool>\n            <ToolHeader\n              title={tool.name}\n              type={tool.type}\n              state={tool.state}\n            />\n            <ToolContent>\n              <ToolInput input={tool.args} />\n              <ToolOutput output={tool.result} errorText={tool.error} />\n            </ToolContent>\n          </Tool>\n\n          {tool.requiresApproval && (\n            <Confirmation approval={tool.approval} state={tool.state}>\n              <ConfirmationTitle>\n                Approve {tool.name}?\n              </ConfirmationTitle>\n\n              <ConfirmationRequest>\n                <ConfirmationActions>\n                  <ConfirmationAction\n                    onClick={() => approveTool(tool.id)}\n                    variant=\"default\"\n                  >\n                    Approve\n                  </ConfirmationAction>\n                  <ConfirmationAction\n                    onClick={() => rejectTool(tool.id)}\n                    variant=\"outline\"\n                  >\n                    Reject\n                  </ConfirmationAction>\n                </ConfirmationActions>\n              </ConfirmationRequest>\n\n              <ConfirmationAccepted>\n                Tool approved and executed.\n              </ConfirmationAccepted>\n\n              <ConfirmationRejected>\n                Tool execution rejected.\n              </ConfirmationRejected>\n            </Confirmation>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n```\n",
        "skills/app-intents-code-review/SKILL.md": "---\nname: app-intents-code-review\ndescription: Reviews App Intents code for intent structure, entities, shortcuts, and parameters. Use when reviewing code with import AppIntents, @AppIntent, AppEntity, AppShortcutsProvider, or @Parameter.\n---\n\n# App Intents Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| AppIntent protocol, perform(), return types | [references/intent-structure.md](references/intent-structure.md) |\n| AppEntity, EntityQuery, identifiers | [references/entities.md](references/entities.md) |\n| AppShortcutsProvider, phrases, discovery | [references/shortcuts.md](references/shortcuts.md) |\n| @Parameter, validation, dynamic options | [references/parameters.md](references/parameters.md) |\n\n## Review Checklist\n\n- [ ] `perform()` marked with `@MainActor` if accessing UI/main thread resources\n- [ ] `perform()` completes within 30-second timeout (no heavy downloads/processing)\n- [ ] Custom errors conform to `CustomLocalizedStringResourceConvertible`\n- [ ] `EntityQuery.entities(for:)` handles missing identifiers gracefully\n- [ ] `EntityStringQuery` used if Siri voice input needed (not plain `EntityQuery`)\n- [ ] `suggestedEntities()` returns reasonable defaults for disambiguation\n- [ ] `AppShortcut` phrases include `.applicationName` parameter\n- [ ] Non-optional `@Parameter` has sensible defaults or uses `requestValue()`\n- [ ] `@IntentParameterDependency` not used on iOS 16 targets (crashes)\n- [ ] Phrases localized in `AppShortcuts.strings`, not `Localizable.strings`\n- [ ] App Intents defined in app bundle, not Swift Package (pre-iOS 17)\n- [ ] `isDiscoverable = false` for internal/widget-only intents\n\n## When to Load References\n\n- AppIntent protocol implementation -> intent-structure.md\n- Entity queries, identifiers, Spotlight -> entities.md\n- App Shortcuts, phrases, discovery -> shortcuts.md\n- Parameter validation, dynamic options -> parameters.md\n\n## Review Questions\n\n1. Does `perform()` handle timeout limits for long-running operations?\n2. Are entity queries self-contained (no `@Dependency` injection in Siri context)?\n3. Do phrases read naturally and include the app name?\n4. Are SwiftData models passed by `persistentModelID`, not directly?\n5. Would migrating from SiriKit break existing user shortcuts?\n",
        "skills/app-intents-code-review/references/entities.md": "# Entities and Queries\n\n## AppEntity Protocol\n\nRepresents domain objects for use in App Intents:\n\n```swift\nstruct BookEntity: AppEntity, Identifiable {\n    var id: UUID  // Must be stable and persistent\n\n    @Property(title: \"Title\")\n    var title: String\n\n    @Property(title: \"Author\")\n    var author: String\n\n    var displayRepresentation: DisplayRepresentation {\n        DisplayRepresentation(title: \"\\(title)\", subtitle: \"\\(author)\")\n    }\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Book\"\n    static var defaultQuery = BookQuery()\n}\n```\n\n| Requirement | Purpose |\n|-------------|---------|\n| `id` | Stable identifier for persistence across sessions |\n| `displayRepresentation` | How entity appears in Siri/Shortcuts UI |\n| `typeDisplayRepresentation` | Human-readable type name (\"Book\", \"Task\") |\n| `defaultQuery` | Associated query for lookups |\n\n## EntityQuery Protocol\n\nBasic lookup by identifier:\n\n```swift\nstruct BookQuery: EntityQuery {\n    func entities(for identifiers: [UUID]) async throws -> [BookEntity] {\n        identifiers.compactMap { Database.shared.book(for: $0) }\n    }\n}\n```\n\n## EntityStringQuery Protocol\n\nRequired for Siri voice input with free-form search:\n\n```swift\nstruct BookQuery: EntityStringQuery {\n    func entities(for identifiers: [UUID]) async throws -> [BookEntity] {\n        identifiers.compactMap { Database.shared.book(for: $0) }\n    }\n\n    func suggestedEntities() async throws -> [BookEntity] {\n        Database.shared.recentBooks  // Shown in picker UI\n    }\n\n    func entities(matching string: String) async throws -> [BookEntity] {\n        Database.shared.books.filter { $0.title.localizedCaseInsensitiveContains(string) }\n    }\n}\n```\n\n**Critical**: Using plain `EntityQuery` with Siri causes infinite parameter request loops. Use `EntityStringQuery` for voice-driven disambiguation.\n\n## EnumerableEntityQuery Protocol (iOS 17+)\n\nFor small datasets, return all entities and let system filter:\n\n```swift\nstruct ShelfQuery: EnumerableEntityQuery {\n    func allEntities() async throws -> [ShelfEntity] {\n        Shelf.allCases.map { ShelfEntity($0) }\n    }\n}\n```\n\nBest for: Enums, small fixed sets (<100 items)\n\n## EntityPropertyQuery Protocol\n\nFor large datasets with property-based filtering:\n\n```swift\nstruct BookQuery: EntityPropertyQuery {\n    static var sortingOptions = SortingOptions {\n        SortableBy(\\BookEntity.$title)\n        SortableBy(\\BookEntity.$dateAdded)\n    }\n\n    static var properties = QueryProperties {\n        Property(\\BookEntity.$title) { EqualTo, Contains }\n        Property(\\BookEntity.$author) { EqualTo, Contains }\n    }\n\n    func entities(matching predicates: QueryPredicate<BookEntity>,\n                  mode: ComparatorMode,\n                  sortedBy: [EntitySortingOptions<BookEntity>],\n                  limit: Int?) async throws -> [BookEntity] {\n        // Build NSPredicate from QueryPredicate\n    }\n}\n```\n\n## iOS 18 Entity Features\n\n**IndexedEntity**: Spotlight semantic search\n```swift\nstruct BookEntity: AppEntity, IndexedEntity {\n    var attributeSet: CSSearchableItemAttributeSet {\n        let attrs = CSSearchableItemAttributeSet()\n        attrs.displayName = title\n        attrs.contentDescription = summary\n        return attrs\n    }\n}\n```\n\n**URLRepresentable**: Deep linking\n```swift\nstruct BookEntity: AppEntity, URLRepresentable {\n    static var urlRepresentation: URLRepresentation {\n        \"myapp://book/\\(.id)\"\n    }\n}\n```\n\n## SwiftData Integration\n\n```swift\n// BAD: Passing model directly (not Sendable)\nfunc perform() async throws -> some IntentResult {\n    let book = fetchBook()  // @Model type\n    processBook(book)  // Data race risk\n}\n\n// GOOD: Pass by ID, fetch in context\nfunc perform() async throws -> some IntentResult {\n    let bookID = persistentModelID\n    let context = ModelContext(container)\n    let book = context.model(for: bookID) as? Book\n}\n```\n\n## Dependency Injection Limitation\n\n`@Dependency` and `@AppDependency` **do not work** in Siri/Shortcuts context. Queries must be self-contained:\n\n```swift\n// BAD: Dependency injection in query\nstruct BookQuery: EntityQuery {\n    @Dependency var database: Database  // nil in Siri\n\n    func entities(for identifiers: [UUID]) async throws -> [BookEntity] {\n        database.books(for: identifiers)  // Crashes\n    }\n}\n\n// GOOD: Self-contained query\nstruct BookQuery: EntityQuery {\n    func entities(for identifiers: [UUID]) async throws -> [BookEntity] {\n        Database.shared.books(for: identifiers)  // Singleton access\n    }\n}\n```\n\n## Critical Anti-Patterns\n\n```swift\n// BAD: Plain EntityQuery with Siri voice input\nstruct BookQuery: EntityQuery { ... }  // Infinite prompt loop\n\n// GOOD: EntityStringQuery for voice input\nstruct BookQuery: EntityStringQuery {\n    func entities(matching string: String) async throws -> [BookEntity] { ... }\n}\n```\n\n```swift\n// BAD: Empty suggested entities\nfunc suggestedEntities() async throws -> [BookEntity] { [] }\n\n// GOOD: Provide reasonable defaults\nfunc suggestedEntities() async throws -> [BookEntity] {\n    Database.shared.recentBooks.prefix(10)\n}\n```\n\n```swift\n// BAD: Non-persistent ID\nstruct BookEntity: AppEntity {\n    var id = UUID()  // New ID each time!\n}\n\n// GOOD: Stable ID from data source\nstruct BookEntity: AppEntity {\n    let id: UUID  // From database record\n}\n```\n\n## Review Questions\n\n1. **Is `EntityStringQuery` used for Siri voice input?** Plain `EntityQuery` causes infinite loops.\n2. **Does `suggestedEntities()` return useful defaults?** Empty results break disambiguation.\n3. **Are entity IDs stable and persistent?** New IDs each instantiation break continuity.\n4. **Is the query self-contained?** `@Dependency` fails in Siri/Shortcuts context.\n5. **Is `EnumerableEntityQuery` used only for small sets?** Large sets should use `EntityPropertyQuery`.\n",
        "skills/app-intents-code-review/references/intent-structure.md": "# Intent Structure\n\n## AppIntent Protocol\n\nRequired conformance for all App Intents:\n\n```swift\nstruct OpenCurrentlyReading: AppIntent {\n    static var title: LocalizedStringResource = \"Open Currently Reading\"\n    static var openAppWhenRun: Bool = true  // Optional: default false\n\n    @MainActor\n    func perform() async throws -> some IntentResult {\n        Navigator.shared.openShelf(.currentlyReading)\n        return .result()\n    }\n}\n```\n\n| Property | Required | Default | Purpose |\n|----------|----------|---------|---------|\n| `title` | Yes | - | Localized display name |\n| `openAppWhenRun` | No | `false` | Launch app before execution |\n| `isDiscoverable` | No | `true` | Show in Shortcuts app (iOS 17+) |\n\n## Return Types\n\n`perform()` returns `some IntentResult` with optional protocol conformances:\n\n| Protocol | Purpose | Example |\n|----------|---------|---------|\n| `ReturnsValue<T>` | Pass data to next intent | `.result(value: book)` |\n| `ProvidesDialog` | Siri voice/text response | `.result(dialog: \"Done!\")` |\n| `ShowsSnippetView` | SwiftUI visual feedback | `.result(view: SuccessView())` |\n| `OpensIntent` | Chain to another intent | `.result(opensIntent: NextIntent())` |\n\n```swift\n// Combined return type\nfunc perform() async throws -> some IntentResult & ReturnsValue<BookEntity> & ProvidesDialog {\n    return .result(value: book, dialog: \"Added \\(book.title) to Library!\")\n}\n```\n\n## Threading\n\n- `perform()` runs on arbitrary background queue by default\n- Mark with `@MainActor` for UI operations or main thread access\n- Long operations must complete within ~30 seconds or time out\n\n## Error Handling\n\nCustom errors must provide localized messages:\n\n```swift\nenum BookIntentError: Error, CustomLocalizedStringResourceConvertible {\n    case notFound\n    case networkError(String)\n\n    var localizedStringResource: LocalizedStringResource {\n        switch self {\n        case .notFound: return \"Book not found\"\n        case .networkError(let msg): return \"Network error: \\(msg)\"\n        }\n    }\n}\n```\n\nUse `AppIntentError` for standard cases:\n- `.insufficientAccount` - Needs sign-in\n- `.entityNotFound` - Entity missing\n- `.needsValue` - Parameter required\n\n## iOS 17+ Protocols\n\n**ForegroundContinuableIntent**: Continue in app with custom UI\n```swift\nthrow needsToContinueInForegroundError()  // Stop and require user action\ntry await requestToContinueInForeground()  // Continue with user input\n```\n\n**ProgressReportingIntent**: Long-running operations\n```swift\nfunc perform() async throws -> some IntentResult {\n    progress.totalUnitCount = 100\n    for i in 0..<100 {\n        progress.completedUnitCount = Int64(i)\n        // ... work\n    }\n    return .result()\n}\n```\n\n## Critical Anti-Patterns\n\n```swift\n// BAD: Heavy work without timeout consideration\nfunc perform() async throws -> some IntentResult {\n    let data = try await downloadLargeFile()  // May exceed 30s limit\n    return .result()\n}\n\n// GOOD: Open app for long operations\nstatic var openAppWhenRun = true\nfunc perform() async throws -> some IntentResult {\n    // App handles long operation with proper UI\n}\n```\n\n```swift\n// BAD: Generic error without localization\nthrow NSError(domain: \"app\", code: 1, userInfo: nil)\n\n// GOOD: Localized error message\nthrow BookIntentError.notFound\n```\n\n```swift\n// BAD: UI work without @MainActor\nfunc perform() async throws -> some IntentResult {\n    UIApplication.shared.open(url)  // Crashes\n}\n\n// GOOD: Mark for main thread\n@MainActor\nfunc perform() async throws -> some IntentResult {\n    UIApplication.shared.open(url)\n}\n```\n\n## Review Questions\n\n1. **Does `perform()` complete within 30 seconds?** Long downloads/processing should open app.\n2. **Is `@MainActor` used for UI operations?** Intents run on background queues by default.\n3. **Do custom errors provide localized messages?** Raw `Error` gives poor Siri feedback.\n4. **Is `openAppWhenRun` set appropriately?** Background-capable intents should stay `false`.\n5. **Is `isDiscoverable = false` for internal intents?** Widget-only intents shouldn't clutter Shortcuts.\n",
        "skills/app-intents-code-review/references/parameters.md": "# Parameters\n\n## @Parameter Property Wrapper\n\nDeclares user-configurable inputs:\n\n```swift\nstruct OpenBook: AppIntent {\n    @Parameter(title: \"Book\")\n    var book: BookEntity\n\n    @Parameter(title: \"Page\", default: 1)\n    var page: Int\n\n    @Parameter(title: \"Read Aloud\")\n    var readAloud: Bool?  // Optional = not required\n}\n```\n\n| Option | Purpose |\n|--------|---------|\n| `title` | Localized display name (required) |\n| `default` | Default value for parameter |\n| `description` | Help text for parameter |\n| `requestValueDialog` | Prompt when requesting value |\n\n## Supported Types\n\n- **Primitives**: `Int`, `Double`, `Bool`, `String`, `Date`, `URL`\n- **Collections**: `[T]` where T is supported\n- **Enums**: Must conform to `AppEnum`\n- **Entities**: Must conform to `AppEntity`\n- **Files**: `IntentFile` for file handling\n\n## AppEnum for Fixed Values\n\n```swift\nenum Priority: String, AppEnum {\n    case low, medium, high\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Priority\"\n    static var caseDisplayRepresentations: [Priority: DisplayRepresentation] = [\n        .low: \"Low\",\n        .medium: \"Medium\",\n        .high: \"High\"\n    ]\n}\n```\n\n## ParameterSummary\n\nNatural language description with embedded parameters:\n\n```swift\nstatic var parameterSummary: some ParameterSummary {\n    Summary(\"Open \\(\\.$book) at page \\(\\.$page)\")\n}\n```\n\niOS 17+: Conditional summaries based on widget family:\n```swift\nstatic var parameterSummary: some ParameterSummary {\n    When(\\.$includeDetails, .equalTo, true) {\n        Summary(\"Show \\(\\.$book) with details\")\n    } otherwise: {\n        Summary(\"Show \\(\\.$book)\")\n    }\n}\n```\n\n## Dynamic Options\n\nProvide runtime-computed options:\n\n```swift\nstruct BookParameter: DynamicOptionsProvider {\n    func results() async throws -> [BookEntity] {\n        Database.shared.availableBooks\n    }\n\n    func defaultResult() async -> BookEntity? {\n        Database.shared.lastOpenedBook\n    }\n}\n\n@Parameter(title: \"Book\", optionsProvider: BookParameter())\nvar book: BookEntity\n```\n\n## @IntentParameterDependency (iOS 17+)\n\nAccess other parameters in options provider:\n\n```swift\nstruct ChapterParameter: DynamicOptionsProvider {\n    @IntentParameterDependency<OpenBook>(\\.book)\n    var bookDependency\n\n    func results() async throws -> [ChapterEntity] {\n        guard let book = bookDependency?.book else { return [] }\n        return book.chapters\n    }\n}\n```\n\n**Warning**: `@IntentParameterDependency` crashes on iOS 16. Guard with availability:\n```swift\nif #available(iOS 17, *) {\n    // Use dependency\n}\n```\n\n## User Interaction\n\nRequest values or disambiguation during `perform()`:\n\n```swift\nfunc perform() async throws -> some IntentResult {\n    // Request missing value\n    let book = try await $book.requestValue(\"Which book?\")\n\n    // Disambiguation from options\n    let chapter = try await $chapter.requestDisambiguation(\n        among: book.chapters,\n        dialog: \"Which chapter?\"\n    )\n\n    // Confirmation\n    let confirmed = try await $book.requestConfirmation(\n        for: book,\n        dialog: \"Open \\(book.title)?\"\n    )\n}\n```\n\n**Note**: User cancellation throws an error - handle gracefully.\n\n## Validation\n\nValidate parameters before use:\n\n```swift\nfunc perform() async throws -> some IntentResult {\n    guard page > 0 && page <= book.pageCount else {\n        throw BookIntentError.invalidPage\n    }\n    // ...\n}\n```\n\nFor complex validation, use `requestValue()` with specific prompts.\n\n## Critical Anti-Patterns\n\n```swift\n// BAD: Non-optional parameter without default\n@Parameter(title: \"Count\")\nvar count: Int  // Required with no default - user must always provide\n\n// GOOD: Optional or has default\n@Parameter(title: \"Count\", default: 10)\nvar count: Int\n```\n\n```swift\n// BAD: @IntentParameterDependency on iOS 16 target\n@IntentParameterDependency<MyIntent>(\\.param)\nvar dependency  // Crashes on iOS 16\n\n// GOOD: Guard with availability\n@available(iOS 17, *)\n@IntentParameterDependency<MyIntent>(\\.param)\nvar dependency\n```\n\n```swift\n// BAD: Ignoring requestConfirmation cancellation\nfunc perform() async throws -> some IntentResult {\n    try await $action.requestConfirmation(for: action)  // Throws on cancel\n    performAction()  // Runs even if canceled?\n}\n\n// GOOD: Handle cancellation\nfunc perform() async throws -> some IntentResult {\n    do {\n        try await $action.requestConfirmation(for: action)\n        performAction()\n    } catch {\n        // User canceled - graceful exit\n        return .result()\n    }\n}\n```\n\n```swift\n// BAD: Missing defaultResult in DynamicOptionsProvider\nstruct BookParameter: DynamicOptionsProvider {\n    func results() async throws -> [BookEntity] { ... }\n    // No defaultResult - non-optional params fail without explicit selection\n}\n\n// GOOD: Provide default\nstruct BookParameter: DynamicOptionsProvider {\n    func results() async throws -> [BookEntity] { ... }\n    func defaultResult() async -> BookEntity? {\n        Database.shared.lastOpenedBook\n    }\n}\n```\n\n## Review Questions\n\n1. **Do non-optional parameters have defaults or use `requestValue()`?**\n2. **Is `@IntentParameterDependency` guarded for iOS 17+?** Crashes on iOS 16.\n3. **Are user cancellations from `requestConfirmation` handled?** They throw errors.\n4. **Does `DynamicOptionsProvider` implement `defaultResult()`?** Required for non-optional params.\n5. **Are parameter summaries written as natural sentences?**\n",
        "skills/app-intents-code-review/references/shortcuts.md": "# Shortcuts Integration\n\n## AppShortcutsProvider\n\nRegisters intents for automatic discovery in Shortcuts app and Siri:\n\n```swift\nstruct LibraryAppShortcuts: AppShortcutsProvider {\n    static var appShortcuts: [AppShortcut] {\n        AppShortcut(\n            intent: OpenCurrentlyReading(),\n            phrases: [\n                \"Open Currently Reading in \\(.applicationName)\",\n                \"Show my reading list in \\(.applicationName)\"\n            ],\n            shortTitle: \"Open Reading List\",\n            systemImageName: \"books.vertical.fill\"\n        )\n    }\n}\n```\n\n| Property | Required | Purpose |\n|----------|----------|---------|\n| `intent` | Yes | The AppIntent instance to invoke |\n| `phrases` | Yes | Siri trigger phrases (must include app name) |\n| `shortTitle` | Yes | Brief description for UI |\n| `systemImageName` | Yes | SF Symbol for visual display |\n\n## Phrase Requirements\n\n**Critical**: Every phrase MUST include `.applicationName`:\n\n```swift\n// BAD: Missing app name\nphrases: [\"Open my books\", \"Show reading list\"]  // Won't be discoverable\n\n// GOOD: Includes app name\nphrases: [\n    \"Open my books in \\(.applicationName)\",\n    \"Show reading list with \\(.applicationName)\"\n]\n```\n\n**Limits**:\n- Maximum 1,000 total phrases per app (including parameter variations)\n- Use natural language that reads well when spoken\n\n## Localization\n\nPhrases must be in `AppShortcuts.strings` (or `AppShortcuts.xcstrings` for iOS 18+):\n\n```strings\n// AppShortcuts.strings\n\"Open Currently Reading in ${applicationName}\" = \"Open Currently Reading in ${applicationName}\";\n```\n\n**Critical**: Using `Localizable.strings` for phrases does NOT work.\n\n## Parameterized Phrases\n\nInclude parameters using `\\(.$parameterName)`:\n\n```swift\nAppShortcut(\n    intent: OpenBook(),\n    phrases: [\n        \"Open \\(\\.$book) in \\(.applicationName)\",\n        \"Read \\(\\.$book) with \\(.applicationName)\"\n    ],\n    shortTitle: \"Open Book\",\n    systemImageName: \"book\"\n)\n```\n\n**Warning**: Custom `AppEntity` parameters in phrases may prevent shortcuts from appearing. Test thoroughly.\n\n## iOS 17+ Extensions\n\nDefine `AppShortcutsProvider` in App Intents extensions (not main app) for faster startup:\n\n```swift\n// In App Intents Extension target\nstruct BookShortcuts: AppShortcutsProvider {\n    static var appShortcuts: [AppShortcut] { ... }\n}\n```\n\nExtensions skip UI, analytics, and non-critical initialization.\n\n## Discovery Issues\n\nCommon reasons shortcuts don't appear:\n\n| Issue | Solution |\n|-------|----------|\n| Missing in Shortcuts app | Check Project Target > General > Supported Intents |\n| Xcode version mismatch | Try Xcode beta or release; use `xcode-select` |\n| App Intents in Swift Package | Move to main app bundle (pre-iOS 17) |\n| Release build issues | Mark all App Intents as `public` |\n| Metadata processor failure | Simplify custom types; check build logs |\n\n## Migration from SiriKit\n\nWhen migrating from INIntent to AppIntent:\n\n```swift\nstruct OpenBookIntent: AppIntent {\n    // Conform for migration\n    static var intentClassName: String? = \"OpenBookIntent\"\n}\n```\n\n**Warning**: `CustomIntentMigratedAppIntent` conformance breaks iOS 16 even with availability annotations.\n\n## Multilingual Considerations\n\n- App names in different languages than Siri's language cause recognition failures\n- Test with Siri language matching app language settings\n- Consider region-specific phrase variations\n\n## Critical Anti-Patterns\n\n```swift\n// BAD: Phrase without app name\nAppShortcut(\n    intent: OpenBook(),\n    phrases: [\"Open my book\"],  // Not discoverable by Siri\n    ...\n)\n\n// GOOD: App name included\nAppShortcut(\n    intent: OpenBook(),\n    phrases: [\"Open my book in \\(.applicationName)\"],\n    ...\n)\n```\n\n```swift\n// BAD: Localization in wrong file\n// Localizable.strings - WRONG FILE\n\"Open book\" = \"Open book\";\n\n// GOOD: Use AppShortcuts.strings\n// AppShortcuts.strings - CORRECT FILE\n\"Open book in ${applicationName}\" = \"Open book in ${applicationName}\";\n```\n\n```swift\n// BAD: Complex entity parameter in phrase (may fail)\nAppShortcut(\n    intent: ProcessBook(),\n    phrases: [\"Process \\(\\.$complexEntity) in \\(.applicationName)\"],\n    ...\n)\n\n// GOOD: Simple parameters or none\nAppShortcut(\n    intent: ProcessBook(),\n    phrases: [\"Process current book in \\(.applicationName)\"],\n    ...\n)\n```\n\n## Review Questions\n\n1. **Do all phrases include `.applicationName`?** Required for Siri discovery.\n2. **Are phrases in `AppShortcuts.strings`?** `Localizable.strings` doesn't work.\n3. **Is the app bundle correct?** Swift Package intents won't appear (pre-iOS 17).\n4. **Are custom entity parameters tested in phrases?** Complex entities may break discovery.\n5. **Is migration handled carefully?** `CustomIntentMigratedAppIntent` breaks iOS 16.\n",
        "skills/bubbletea-code-review/SKILL.md": "---\nname: bubbletea-code-review\ndescription: Reviews BubbleTea TUI code for proper Elm architecture, model/update/view patterns, and Lipgloss styling. Use when reviewing terminal UI code using charmbracelet/bubbletea.\n---\n\n# BubbleTea Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Elm architecture, tea.Cmd as data | [references/elm-architecture.md](references/elm-architecture.md) |\n| Model state, message handling | [references/model-update.md](references/model-update.md) |\n| View rendering, Lipgloss styling | [references/view-styling.md](references/view-styling.md) |\n| Component composition, Huh forms | [references/composition.md](references/composition.md) |\n| Bubbles components (list, table, etc.) | [references/bubbles-components.md](references/bubbles-components.md) |\n\n## CRITICAL: Avoid False Positives\n\n**Read [elm-architecture.md](references/elm-architecture.md) first!** The most common review mistake is flagging correct patterns as bugs.\n\n### NOT Issues (Do NOT Flag These)\n\n| Pattern | Why It's Correct |\n|---------|------------------|\n| `return m, m.loadData()` | `tea.Cmd` is returned immediately; runtime executes async |\n| Value receiver on `Update()` | Standard BubbleTea pattern; model returned by value |\n| Nested `m.child, cmd = m.child.Update(msg)` | Normal component composition |\n| Helper functions returning `tea.Cmd` | Creates command descriptor, no I/O in Update |\n| `tea.Batch(cmd1, cmd2)` | Commands execute concurrently by runtime |\n\n### ACTUAL Issues (DO Flag These)\n\n| Pattern | Why It's Wrong |\n|---------|----------------|\n| `os.ReadFile()` in Update | Blocks UI thread |\n| `http.Get()` in Update | Network I/O blocks |\n| `time.Sleep()` in Update | Freezes UI |\n| `<-channel` in Update (blocking) | May block indefinitely |\n| `huh.Form.Run()` in Update | Blocking call |\n\n## Review Checklist\n\n### Architecture\n- [ ] **No blocking I/O in Update()** (file, network, sleep)\n- [ ] Helper functions returning `tea.Cmd` are NOT flagged as blocking\n- [ ] Commands used for all async operations\n\n### Model & Update\n- [ ] Model is immutable (Update returns new model, not mutates)\n- [ ] Init returns proper initial command (or nil)\n- [ ] Update handles all expected message types\n- [ ] WindowSizeMsg handled for responsive layout\n- [ ] tea.Batch used for multiple commands\n- [ ] tea.Quit used correctly for exit\n\n### View & Styling\n- [ ] View is a pure function (no side effects)\n- [ ] Lipgloss styles defined once, not in View\n- [ ] Key bindings use key.Matches with help.KeyMap\n\n### Components\n- [ ] Sub-component updates propagated correctly\n- [ ] Bubbles components initialized with dimensions\n- [ ] Huh forms embedded via Update loop (not Run())\n\n## Critical Patterns\n\n### Model Must Be Immutable\n\n```go\n// BAD - mutates model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    m.items = append(m.items, newItem)  // mutation!\n    return m, nil\n}\n\n// GOOD - returns new model\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    newItems := make([]Item, len(m.items)+1)\n    copy(newItems, m.items)\n    newItems[len(m.items)] = newItem\n    m.items = newItems\n    return m, nil\n}\n```\n\n### Commands for Async/IO\n\n```go\n// BAD - blocking in Update\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    data, _ := os.ReadFile(\"config.json\")  // blocks UI!\n    m.config = parse(data)\n    return m, nil\n}\n\n// GOOD - use commands\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    return m, loadConfigCmd()\n}\n\nfunc loadConfigCmd() tea.Cmd {\n    return func() tea.Msg {\n        data, err := os.ReadFile(\"config.json\")\n        if err != nil {\n            return errMsg{err}\n        }\n        return configLoadedMsg{parse(data)}\n    }\n}\n```\n\n### Styles Defined Once\n\n```go\n// BAD - creates new style each render\nfunc (m Model) View() string {\n    style := lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n    return style.Render(\"Hello\")\n}\n\n// GOOD - define styles at package level or in model\nvar titleStyle = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\"))\n\nfunc (m Model) View() string {\n    return titleStyle.Render(\"Hello\")\n}\n```\n\n## When to Load References\n\n- **First time reviewing BubbleTea**  [elm-architecture.md](references/elm-architecture.md) (prevents false positives)\n- Reviewing Update function logic  [model-update.md](references/model-update.md)\n- Reviewing View function, styling  [view-styling.md](references/view-styling.md)\n- Reviewing component hierarchy  [composition.md](references/composition.md)\n- Using Bubbles components  [bubbles-components.md](references/bubbles-components.md)\n\n## Review Questions\n\n1. Is Update() free of blocking I/O? (NOT: \"is the cmd helper blocking?\")\n2. Is the model immutable in Update?\n3. Are Lipgloss styles defined once, not in View?\n4. Is WindowSizeMsg handled for resizing?\n5. Are key bindings documented with help.KeyMap?\n6. Are Bubbles components sized correctly?\n",
        "skills/bubbletea-code-review/references/bubbles-components.md": "# Bubbles Component Reference\n\nComplete reference for all charmbracelet/bubbles components.\n\n## Component Overview\n\n| Component | Package | Purpose |\n|-----------|---------|---------|\n| list | `bubbles/list` | Scrollable list with filtering |\n| table | `bubbles/table` | Tabular data display |\n| viewport | `bubbles/viewport` | Scrollable content area |\n| textinput | `bubbles/textinput` | Single-line text input |\n| textarea | `bubbles/textarea` | Multi-line text input |\n| spinner | `bubbles/spinner` | Loading indicator |\n| progress | `bubbles/progress` | Progress bar |\n| paginator | `bubbles/paginator` | Page navigation |\n| filepicker | `bubbles/filepicker` | File/directory selection |\n| timer | `bubbles/timer` | Countdown timer |\n| stopwatch | `bubbles/stopwatch` | Elapsed time counter |\n| help | `bubbles/help` | Key binding help display |\n| key | `bubbles/key` | Key binding definitions |\n| cursor | `bubbles/cursor` | Text cursor management |\n\n---\n\n## List\n\nFull-featured list with filtering, pagination, and custom delegates.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/list\"\n\n// Items must implement list.Item\ntype item struct {\n    title, desc string\n}\n\nfunc (i item) Title() string       { return i.title }\nfunc (i item) Description() string { return i.desc }\nfunc (i item) FilterValue() string { return i.title }\n\n// Create list\nitems := []list.Item{\n    item{title: \"Raspberry Pi\", desc: \"A small computer\"},\n    item{title: \"Arduino\", desc: \"A microcontroller\"},\n}\n\nl := list.New(items, list.NewDefaultDelegate(), 0, 0)\nl.Title = \"My List\"\n```\n\n### Common Patterns\n\n```go\n// Update list size on window resize\ncase tea.WindowSizeMsg:\n    h, v := docStyle.GetFrameSize()\n    m.list.SetSize(msg.Width-h, msg.Height-v)\n\n// Get selected item\nif i, ok := m.list.SelectedItem().(item); ok {\n    return i.title\n}\n\n// Set items dynamically\nm.list.SetItems(newItems)\n\n// Custom delegate for styling\ndelegate := list.NewDefaultDelegate()\ndelegate.Styles.SelectedTitle = selectedTitleStyle\ndelegate.Styles.SelectedDesc = selectedDescStyle\n```\n\n### Anti-Patterns\n\n```go\n//  BAD - reaching into internals\nselected := m.list.Items()[m.list.Index()]\n\n//  GOOD - use provided methods\nselected := m.list.SelectedItem()\n```\n\n---\n\n## Table\n\nTabular data with column definitions and row selection.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/table\"\n\ncolumns := []table.Column{\n    {Title: \"Name\", Width: 20},\n    {Title: \"Email\", Width: 30},\n    {Title: \"Role\", Width: 15},\n}\n\nrows := []table.Row{\n    {\"Alice\", \"alice@example.com\", \"Admin\"},\n    {\"Bob\", \"bob@example.com\", \"User\"},\n}\n\nt := table.New(\n    table.WithColumns(columns),\n    table.WithRows(rows),\n    table.WithFocused(true),\n    table.WithHeight(10),\n)\n\n// Apply styles\ns := table.DefaultStyles()\ns.Header = s.Header.BorderStyle(lipgloss.NormalBorder())\ns.Selected = s.Selected.Foreground(lipgloss.Color(\"229\"))\nt.SetStyles(s)\n```\n\n### Common Patterns\n\n```go\n// Get selected row\nselectedRow := m.table.SelectedRow()\n\n// Update rows\nm.table.SetRows(newRows)\n\n// Handle selection\ncase tea.KeyMsg:\n    switch msg.String() {\n    case \"enter\":\n        row := m.table.SelectedRow()\n        return m, selectRowCmd(row)\n    }\n```\n\n---\n\n## Viewport\n\nScrollable content area for large text or rendered content.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/viewport\"\n\nvp := viewport.New(80, 20)\nvp.SetContent(longContent)\n\n// In Update\ncase tea.WindowSizeMsg:\n    vp.Width = msg.Width\n    vp.Height = msg.Height - headerHeight - footerHeight\n```\n\n### Common Patterns\n\n```go\n// Track scroll position\nfunc (m Model) footerView() string {\n    return fmt.Sprintf(\"%3.f%%\", m.viewport.ScrollPercent()*100)\n}\n\n// Programmatic scrolling\nm.viewport.GotoTop()\nm.viewport.GotoBottom()\nm.viewport.LineDown(5)\nm.viewport.LineUp(5)\n\n// Update content\nm.viewport.SetContent(newContent)\n```\n\n### Anti-Patterns\n\n```go\n//  BAD - setting content in View\nfunc (m Model) View() string {\n    m.viewport.SetContent(m.renderContent())  // Side effect!\n    return m.viewport.View()\n}\n\n//  GOOD - set content in Update\ncase contentLoadedMsg:\n    m.viewport.SetContent(msg.content)\n    return m, nil\n```\n\n---\n\n## TextInput\n\nSingle-line text input with placeholder and validation.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/textinput\"\n\nti := textinput.New()\nti.Placeholder = \"Enter username\"\nti.CharLimit = 32\nti.Width = 20\nti.Focus()\n```\n\n### Common Patterns\n\n```go\n// Password input\nti.EchoMode = textinput.EchoPassword\nti.EchoCharacter = '*'\n\n// Validation styling\nti.Validate = func(s string) error {\n    if len(s) < 3 {\n        return errors.New(\"too short\")\n    }\n    return nil\n}\n\n// Get value\nvalue := m.textinput.Value()\n\n// Clear input\nm.textinput.Reset()\n\n// Focus management\nm.textinput.Focus()\nm.textinput.Blur()\n```\n\n### Multiple Inputs\n\n```go\ntype Model struct {\n    inputs  []textinput.Model\n    focused int\n}\n\nfunc (m *Model) nextInput() {\n    m.inputs[m.focused].Blur()\n    m.focused = (m.focused + 1) % len(m.inputs)\n    m.inputs[m.focused].Focus()\n}\n```\n\n---\n\n## TextArea\n\nMulti-line text input with line wrapping.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/textarea\"\n\nta := textarea.New()\nta.Placeholder = \"Type your message...\"\nta.SetWidth(60)\nta.SetHeight(10)\nta.Focus()\n```\n\n### Common Patterns\n\n```go\n// Get/set value\ncontent := m.textarea.Value()\nm.textarea.SetValue(\"Initial content\")\n\n// Line count\nlines := m.textarea.LineCount()\n\n// Cursor position\nrow, col := m.textarea.Cursor()\n\n// Resize\ncase tea.WindowSizeMsg:\n    m.textarea.SetWidth(msg.Width - 4)\n    m.textarea.SetHeight(msg.Height - 6)\n```\n\n---\n\n## Spinner\n\nLoading indicator with multiple styles.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/spinner\"\n\ns := spinner.New()\ns.Spinner = spinner.Dot  // or Line, MiniDot, Jump, Pulse, Points, Globe, Moon, Monkey, Meter, Hamburger\n\n// In Init\nreturn s.Tick\n\n// In Update\ncase spinner.TickMsg:\n    m.spinner, cmd = m.spinner.Update(msg)\n    return m, cmd\n```\n\n### Spinner Styles\n\n```go\n// Available spinners\nspinner.Line      // |/-\\\nspinner.Dot       // \nspinner.MiniDot   // \nspinner.Jump      // \nspinner.Pulse     // \nspinner.Points    // \nspinner.Globe     // \nspinner.Moon      // \nspinner.Monkey    // \nspinner.Meter     // \nspinner.Hamburger // \n```\n\n---\n\n## Progress\n\nProgress bar with percentage and custom styling.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/progress\"\n\np := progress.New(progress.WithDefaultGradient())\n// or\np := progress.New(progress.WithScaledGradient(\"#FF7CCB\", \"#FDFF8C\"))\n\n// In View\nreturn p.ViewAs(0.5)  // 50%\n\n// Animated progress\nreturn p.View()  // uses internal percentage\n```\n\n### Common Patterns\n\n```go\n// Update progress\nm.progress.SetPercent(0.75)\n\n// Width adjustment\ncase tea.WindowSizeMsg:\n    m.progress.Width = msg.Width - padding\n\n// Animated increment\ncase progressMsg:\n    cmd := m.progress.SetPercent(msg.percent)\n    return m, cmd\n```\n\n---\n\n## Paginator\n\nPage navigation for paginated content.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/paginator\"\n\np := paginator.New()\np.Type = paginator.Dots  // or Arabic (1/10)\np.SetTotalPages(10)\np.PerPage = 5\n```\n\n### Common Patterns\n\n```go\n// Get current page items\nstart, end := m.paginator.GetSliceBounds(len(items))\npageItems := items[start:end]\n\n// Navigation\nif m.paginator.OnLastPage() {\n    // handle end\n}\n\n// In Update - paginator handles arrow keys\nm.paginator, cmd = m.paginator.Update(msg)\n```\n\n---\n\n## FilePicker\n\nFile and directory selection.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/filepicker\"\n\nfp := filepicker.New()\nfp.CurrentDirectory, _ = os.UserHomeDir()\nfp.AllowedTypes = []string{\".go\", \".md\", \".txt\"}\nfp.ShowHidden = false\n```\n\n### Common Patterns\n\n```go\n// Check for selection\ncase tea.KeyMsg:\n    m.filepicker, cmd = m.filepicker.Update(msg)\n\n    if didSelect, path := m.filepicker.DidSelectFile(msg); didSelect {\n        m.selectedFile = path\n        return m, fileSelectedCmd(path)\n    }\n\n    if didSelect, path := m.filepicker.DidSelectDisabledFile(msg); didSelect {\n        m.err = errors.New(\"file type not allowed\")\n    }\n```\n\n---\n\n## Timer\n\nCountdown timer with start/stop/reset.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/timer\"\n\nt := timer.NewWithInterval(5*time.Minute, time.Second)\n\n// In Init\nreturn t.Init()\n\n// In Update\ncase timer.TickMsg:\n    m.timer, cmd = m.timer.Update(msg)\n    return m, cmd\n\ncase timer.TimeoutMsg:\n    // Timer finished\n    return m, nil\n```\n\n### Control\n\n```go\n// Toggle\ncmd := m.timer.Toggle()\n\n// Stop\ncmd := m.timer.Stop()\n\n// Start\ncmd := m.timer.Start()\n```\n\n---\n\n## Stopwatch\n\nElapsed time counter.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/stopwatch\"\n\nsw := stopwatch.NewWithInterval(time.Millisecond * 100)\n\n// In Init\nreturn sw.Init()\n\n// In Update\ncase stopwatch.TickMsg:\n    m.stopwatch, cmd = m.stopwatch.Update(msg)\n    return m, cmd\n```\n\n---\n\n## Help\n\nDisplay key bindings to users.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/help\"\nimport \"github.com/charmbracelet/bubbles/key\"\n\ntype keyMap struct {\n    Up    key.Binding\n    Down  key.Binding\n    Quit  key.Binding\n}\n\nfunc (k keyMap) ShortHelp() []key.Binding {\n    return []key.Binding{k.Up, k.Down, k.Quit}\n}\n\nfunc (k keyMap) FullHelp() [][]key.Binding {\n    return [][]key.Binding{\n        {k.Up, k.Down},\n        {k.Quit},\n    }\n}\n\nvar keys = keyMap{\n    Up: key.NewBinding(\n        key.WithKeys(\"up\", \"k\"),\n        key.WithHelp(\"/k\", \"up\"),\n    ),\n    Down: key.NewBinding(\n        key.WithKeys(\"down\", \"j\"),\n        key.WithHelp(\"/j\", \"down\"),\n    ),\n    Quit: key.NewBinding(\n        key.WithKeys(\"q\", \"ctrl+c\"),\n        key.WithHelp(\"q\", \"quit\"),\n    ),\n}\n\nh := help.New()\n\n// In View\nreturn h.View(keys)\n```\n\n### Expand/Collapse\n\n```go\n// Toggle full help\ncase tea.KeyMsg:\n    if msg.String() == \"?\" {\n        m.help.ShowAll = !m.help.ShowAll\n    }\n```\n\n---\n\n## Key\n\nKey binding definitions for consistent input handling.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/key\"\n\nvar quitKey = key.NewBinding(\n    key.WithKeys(\"q\", \"ctrl+c\", \"esc\"),\n    key.WithHelp(\"q\", \"quit\"),\n)\n\n// In Update\ncase tea.KeyMsg:\n    if key.Matches(msg, quitKey) {\n        return m, tea.Quit\n    }\n```\n\n### Enable/Disable Bindings\n\n```go\n// Disable a binding\nquitKey.SetEnabled(false)\n\n// Check if enabled\nif quitKey.Enabled() {\n    // ...\n}\n```\n\n---\n\n## Cursor\n\nText cursor management for custom text inputs.\n\n### Basic Setup\n\n```go\nimport \"github.com/charmbracelet/bubbles/cursor\"\n\nc := cursor.New()\nc.SetMode(cursor.CursorBlink)\n\n// Modes\ncursor.CursorBlink\ncursor.CursorStatic\ncursor.CursorHide\n```\n\n---\n\n## Integration Patterns\n\n### Multiple Components\n\n```go\ntype Model struct {\n    list      list.Model\n    spinner   spinner.Model\n    help      help.Model\n    keys      keyMap\n    loading   bool\n}\n\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmds []tea.Cmd\n    var cmd tea.Cmd\n\n    // Always update spinner when loading\n    if m.loading {\n        m.spinner, cmd = m.spinner.Update(msg)\n        cmds = append(cmds, cmd)\n    }\n\n    // Update list when not loading\n    if !m.loading {\n        m.list, cmd = m.list.Update(msg)\n        cmds = append(cmds, cmd)\n    }\n\n    return m, tea.Batch(cmds...)\n}\n```\n\n### Component Communication\n\n```go\n// Custom message for cross-component communication\ntype itemSelectedMsg struct {\n    item Item\n}\n\n// Child component emits message\ncase tea.KeyMsg:\n    if msg.String() == \"enter\" {\n        return m, func() tea.Msg {\n            return itemSelectedMsg{m.list.SelectedItem().(Item)}\n        }\n    }\n\n// Parent handles message\ncase itemSelectedMsg:\n    m.selectedItem = msg.item\n    m.state = viewDetail\n```\n\n## Review Questions\n\n1. Are components initialized with proper dimensions?\n2. Are components updated on WindowSizeMsg?\n3. Is focus managed correctly between components?\n4. Are component methods used instead of reaching into internals?\n5. Are tick messages handled for animated components (spinner, timer)?\n",
        "skills/bubbletea-code-review/references/composition.md": "# Component Composition\n\n## Bubbles Integration\n\n### 1. Using Standard Bubbles\n\n```go\nimport (\n    \"github.com/charmbracelet/bubbles/list\"\n    \"github.com/charmbracelet/bubbles/textinput\"\n    \"github.com/charmbracelet/bubbles/viewport\"\n    \"github.com/charmbracelet/bubbles/spinner\"\n)\n\ntype Model struct {\n    list      list.Model\n    input     textinput.Model\n    viewport  viewport.Model\n    spinner   spinner.Model\n}\n```\n\n### 2. Initialize Sub-Components\n\n```go\nfunc NewModel() Model {\n    // List\n    items := []list.Item{...}\n    l := list.New(items, list.NewDefaultDelegate(), 0, 0)\n    l.Title = \"My List\"\n\n    // Text input\n    ti := textinput.New()\n    ti.Placeholder = \"Type here...\"\n    ti.Focus()\n\n    // Spinner\n    s := spinner.New()\n    s.Spinner = spinner.Dot\n\n    return Model{\n        list:    l,\n        input:   ti,\n        spinner: s,\n    }\n}\n```\n\n### 3. Update Sub-Components\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmds []tea.Cmd\n    var cmd tea.Cmd\n\n    // Always update active sub-components\n    switch m.state {\n    case stateList:\n        m.list, cmd = m.list.Update(msg)\n        cmds = append(cmds, cmd)\n    case stateInput:\n        m.input, cmd = m.input.Update(msg)\n        cmds = append(cmds, cmd)\n    }\n\n    // Handle window size for all components\n    if msg, ok := msg.(tea.WindowSizeMsg); ok {\n        m.list.SetSize(msg.Width, msg.Height-4)\n        m.viewport.Width = msg.Width\n        m.viewport.Height = msg.Height - 4\n    }\n\n    return m, tea.Batch(cmds...)\n}\n```\n\n## Custom Components\n\n### 1. Component Interface Pattern\n\n```go\n// Component interface for consistent sub-components\ntype Component interface {\n    Init() tea.Cmd\n    Update(tea.Msg) (Component, tea.Cmd)\n    View() string\n    SetSize(width, height int)\n}\n```\n\n### 2. Self-Contained Component\n\n```go\n// menu/menu.go\npackage menu\n\ntype Model struct {\n    items   []Item\n    cursor  int\n    width   int\n    height  int\n}\n\nfunc New(items []Item) Model {\n    return Model{items: items}\n}\n\nfunc (m Model) Init() tea.Cmd {\n    return nil\n}\n\nfunc (m Model) Update(msg tea.Msg) (Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        switch msg.String() {\n        case \"up\", \"k\":\n            if m.cursor > 0 {\n                m.cursor--\n            }\n        case \"down\", \"j\":\n            if m.cursor < len(m.items)-1 {\n                m.cursor++\n            }\n        }\n    }\n    return m, nil\n}\n\nfunc (m Model) View() string {\n    var b strings.Builder\n    for i, item := range m.items {\n        cursor := \"  \"\n        if i == m.cursor {\n            cursor = \"> \"\n        }\n        b.WriteString(cursor + item.Title + \"\\n\")\n    }\n    return b.String()\n}\n\nfunc (m *Model) SetSize(w, h int) {\n    m.width = w\n    m.height = h\n}\n\nfunc (m Model) Selected() Item {\n    return m.items[m.cursor]\n}\n```\n\n### 3. Using Custom Component\n\n```go\nimport \"myapp/menu\"\n\ntype Model struct {\n    menu menu.Model\n}\n\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmd tea.Cmd\n    m.menu, cmd = m.menu.Update(msg)\n\n    // React to menu selection\n    if key, ok := msg.(tea.KeyMsg); ok && key.String() == \"enter\" {\n        selected := m.menu.Selected()\n        // handle selection\n    }\n\n    return m, cmd\n}\n```\n\n## State Machine Pattern\n\n### 1. View States\n\n```go\ntype viewState int\n\nconst (\n    viewLoading viewState = iota\n    viewList\n    viewDetail\n    viewEdit\n)\n\ntype Model struct {\n    state viewState\n    // sub-components for each state\n    list   list.Model\n    detail detailModel\n    edit   editModel\n}\n```\n\n### 2. State Transitions\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    // Global key handling\n    if key, ok := msg.(tea.KeyMsg); ok {\n        switch key.String() {\n        case \"esc\":\n            // Go back based on current state\n            switch m.state {\n            case viewDetail:\n                m.state = viewList\n                return m, nil\n            case viewEdit:\n                m.state = viewDetail\n                return m, nil\n            }\n        }\n    }\n\n    // Delegate to current state's component\n    var cmd tea.Cmd\n    switch m.state {\n    case viewList:\n        m.list, cmd = m.list.Update(msg)\n        // Check for selection\n        if key, ok := msg.(tea.KeyMsg); ok && key.String() == \"enter\" {\n            m.state = viewDetail\n            m.detail = newDetailModel(m.list.SelectedItem())\n        }\n    case viewDetail:\n        m.detail, cmd = m.detail.Update(msg)\n    case viewEdit:\n        m.edit, cmd = m.edit.Update(msg)\n    }\n\n    return m, cmd\n}\n```\n\n### 3. View Routing\n\n```go\nfunc (m Model) View() string {\n    switch m.state {\n    case viewLoading:\n        return m.spinner.View() + \" Loading...\"\n    case viewList:\n        return m.list.View()\n    case viewDetail:\n        return m.detail.View()\n    case viewEdit:\n        return m.edit.View()\n    default:\n        return \"Unknown state\"\n    }\n}\n```\n\n## Focus Management\n\n### 1. Track Focus\n\n```go\ntype focusState int\n\nconst (\n    focusList focusState = iota\n    focusInput\n    focusButtons\n)\n\ntype Model struct {\n    focus focusState\n    list  list.Model\n    input textinput.Model\n}\n\nfunc (m *Model) nextFocus() {\n    m.focus = (m.focus + 1) % 3\n    m.updateFocus()\n}\n\nfunc (m *Model) updateFocus() {\n    switch m.focus {\n    case focusInput:\n        m.input.Focus()\n    default:\n        m.input.Blur()\n    }\n}\n```\n\n### 2. Tab Navigation\n\n```go\ncase tea.KeyMsg:\n    switch key.String() {\n    case \"tab\":\n        m.nextFocus()\n        return m, nil\n    case \"shift+tab\":\n        m.prevFocus()\n        return m, nil\n    }\n\n    // Only handle keys for focused component\n    switch m.focus {\n    case focusList:\n        m.list, cmd = m.list.Update(msg)\n    case focusInput:\n        m.input, cmd = m.input.Update(msg)\n    }\n```\n\n## Anti-Patterns\n\n### 1. Not Propagating Updates\n\n```go\n// BAD - sub-component never updates\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        // only handles own keys, ignores sub-component\n    }\n    return m, nil\n}\n\n// GOOD - always update sub-components\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmd tea.Cmd\n    m.list, cmd = m.list.Update(msg)  // always propagate\n    return m, cmd\n}\n```\n\n### 2. Nested Component Access\n\n```go\n// BAD - reaches into component internals\nfunc (m Model) View() string {\n    return m.list.items[m.list.cursor].Title  // breaks encapsulation\n}\n\n// GOOD - use component methods\nfunc (m Model) View() string {\n    return m.list.SelectedItem().(Item).Title\n}\n```\n\n## Huh Forms Integration\n\n[Huh](https://github.com/charmbracelet/huh) is a form library built on BubbleTea.\n\n### Basic Form\n\n```go\nimport \"github.com/charmbracelet/huh\"\n\nform := huh.NewForm(\n    huh.NewGroup(\n        huh.NewInput().\n            Key(\"name\").\n            Title(\"What's your name?\").\n            Validate(func(s string) error {\n                if s == \"\" {\n                    return errors.New(\"name required\")\n                }\n                return nil\n            }),\n\n        huh.NewSelect[string]().\n            Key(\"role\").\n            Title(\"Select role\").\n            Options(\n                huh.NewOption(\"Admin\", \"admin\"),\n                huh.NewOption(\"User\", \"user\"),\n            ),\n\n        huh.NewConfirm().\n            Key(\"confirm\").\n            Title(\"Continue?\"),\n    ),\n)\n\n// Run standalone (blocking)\nerr := form.Run()\n\n// Get values\nname := form.GetString(\"name\")\nrole := form.GetString(\"role\")\nconfirmed := form.GetBool(\"confirm\")\n```\n\n### Embedding in BubbleTea\n\n```go\ntype Model struct {\n    form *huh.Form\n    done bool\n}\n\nfunc NewModel() Model {\n    form := huh.NewForm(\n        huh.NewGroup(\n            huh.NewInput().Key(\"name\").Title(\"Name\"),\n        ),\n    ).WithTheme(huh.ThemeDracula())\n\n    return Model{form: form}\n}\n\nfunc (m Model) Init() tea.Cmd {\n    return m.form.Init()\n}\n\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    // Check completion first\n    if m.form.State == huh.StateCompleted {\n        m.done = true\n        return m, nil\n    }\n\n    // Update form\n    form, cmd := m.form.Update(msg)\n    if f, ok := form.(*huh.Form); ok {\n        m.form = f\n    }\n    return m, cmd\n}\n\nfunc (m Model) View() string {\n    if m.done {\n        return fmt.Sprintf(\"Hello, %s!\", m.form.GetString(\"name\"))\n    }\n    return m.form.View()\n}\n```\n\n### Field Types\n\n```go\n// Text input\nhuh.NewInput().Key(\"name\").Title(\"Name\").Placeholder(\"Enter name\")\n\n// Multi-line text\nhuh.NewText().Key(\"bio\").Title(\"Bio\").Lines(5)\n\n// Single select\nhuh.NewSelect[string]().Key(\"color\").Title(\"Color\").\n    Options(\n        huh.NewOption(\"Red\", \"red\"),\n        huh.NewOption(\"Blue\", \"blue\"),\n    )\n\n// Multi select\nhuh.NewMultiSelect[string]().Key(\"tags\").Title(\"Tags\").\n    Options(\n        huh.NewOption(\"Go\", \"go\"),\n        huh.NewOption(\"Rust\", \"rust\"),\n    )\n\n// Confirmation\nhuh.NewConfirm().Key(\"agree\").Title(\"Agree?\")\n\n// File picker\nhuh.NewFilePicker().Key(\"file\").Title(\"Select file\")\n```\n\n### Theming\n\n```go\nform := huh.NewForm(...).\n    WithTheme(huh.ThemeDracula()).      // Built-in themes\n    WithWidth(60).\n    WithShowHelp(true).\n    WithShowErrors(true)\n\n// Built-in themes\nhuh.ThemeBase()\nhuh.ThemeCharm()\nhuh.ThemeDracula()\nhuh.ThemeCatppuccin()\nhuh.ThemeBase16()\n```\n\n### Multi-Page Forms\n\n```go\nform := huh.NewForm(\n    // Page 1\n    huh.NewGroup(\n        huh.NewInput().Key(\"name\").Title(\"Name\"),\n        huh.NewInput().Key(\"email\").Title(\"Email\"),\n    ).Title(\"Personal Info\"),\n\n    // Page 2\n    huh.NewGroup(\n        huh.NewSelect[string]().Key(\"plan\").Title(\"Plan\").\n            Options(\n                huh.NewOption(\"Free\", \"free\"),\n                huh.NewOption(\"Pro\", \"pro\"),\n            ),\n    ).Title(\"Subscription\"),\n)\n```\n\n### Anti-Patterns\n\n```go\n//  BAD - calling Run() inside BubbleTea (blocks)\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    m.form.Run()  // BLOCKS THE UI!\n    return m, nil\n}\n\n//  GOOD - use Update loop\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    form, cmd := m.form.Update(msg)\n    m.form = form.(*huh.Form)\n    return m, cmd\n}\n```\n\n## Review Questions\n\n1. Are sub-components properly initialized?\n2. Are sub-component updates propagated?\n3. Is WindowSizeMsg passed to all components needing resize?\n4. Is there a clear state machine for view transitions?\n5. Is focus tracked and components blurred/focused correctly?\n6. Are Huh forms embedded correctly (not using blocking Run())?\n",
        "skills/bubbletea-code-review/references/elm-architecture.md": "# Understanding the Elm Architecture\n\n## The Core Principle: Commands Are Data\n\nThe most important concept in BubbleTea (and Elm) is that **commands describe effects, they don't execute them**.\n\n```go\n// tea.Cmd is just a function signature\ntype Cmd func() Msg\n```\n\nWhen you return a `tea.Cmd` from `Update()`, you're returning a *description* of work to do. The BubbleTea runtime executes it asynchronously after `Update()` returns.\n\n## Common False Positive: \"Synchronous Execution\"\n\n**This is NOT blocking:**\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case NavigateMsg:\n        return m, m.loadData()  //  NOT synchronous execution!\n    }\n    return m, nil\n}\n\nfunc (m *Model) loadData() tea.Cmd {\n    return func() tea.Msg {\n        // This closure is NOT executed during Update()\n        // The runtime schedules it for async execution\n        data, _ := http.Get(\"https://api.example.com/data\")\n        return DataLoadedMsg{data}\n    }\n}\n```\n\n**Why this is correct:**\n1. `m.loadData()` is called synchronously, but it only *creates* the command\n2. The `http.Get` inside the closure does NOT run during `Update()`\n3. `Update()` returns immediately with the command\n4. BubbleTea's runtime executes the command in a separate goroutine\n5. When complete, the runtime sends `DataLoadedMsg` back to `Update()`\n\n## The Execution Model\n\n```\n\n                        BubbleTea Runtime                         \n\n                                                                 \n   User Input                                                 \n                                                                \n              returns               \n   Msg    Update     Model, Cmd            \n             immediately            \n                                                                \n                                \n                                                                \n                                                    \n          Runtime    executes Cmd                             \n          executes   in background                            \n            Cmd      goroutine                                \n                                                    \n                                                                \n               sends Msg                                        \n                                                    \n   Msg    Update    cycle continues                         \n                                                    \n                                                                 \n\n```\n\n## NOT Issues (Avoid These False Positives)\n\n### 1. Helper Functions Returning tea.Cmd\n\n```go\n//  CORRECT - this is NOT blocking\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    return m, m.fetchItems()\n}\n\nfunc (m *Model) fetchItems() tea.Cmd {\n    return func() tea.Msg {\n        items, _ := api.GetItems()  // Runs LATER, by runtime\n        return ItemsMsg{items}\n    }\n}\n```\n\n**Why OK:** The helper creates and returns a command descriptor. No I/O happens in Update().\n\n### 2. Value Receivers on Update\n\n```go\n//  CORRECT - standard BubbleTea pattern\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    m.counter++\n    return m, nil\n}\n```\n\n**Why OK:** BubbleTea returns the model by value. The caller receives the modified copy.\n\n### 3. Nested Model Updates\n\n```go\n//  CORRECT - normal component composition\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmd tea.Cmd\n    m.child, cmd = m.child.Update(msg)  // Updates child synchronously\n    return m, cmd\n}\n```\n\n**Why OK:** Child's Update() is also non-blocking. Commands bubble up.\n\n### 4. Batch Commands\n\n```go\n//  CORRECT - commands execute concurrently\nreturn m, tea.Batch(\n    m.loadUser(),\n    m.loadPosts(),\n    m.loadSettings(),\n)\n```\n\n**Why OK:** All three commands run concurrently by the runtime.\n\n### 5. Immediate Message Return\n\n```go\n//  CORRECT - synchronous state transition\nfunc (m *Model) navigateToMenu() tea.Cmd {\n    return func() tea.Msg {\n        return ShowMenuMsg{}  // No I/O, just returns a message\n    }\n}\n```\n\n**Why OK:** Even though this returns immediately, it's still async from Update()'s perspective.\n\n## ACTUAL Issues to Flag\n\n### 1. Blocking I/O Directly in Update\n\n```go\n//  BAD - blocks the UI\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    data, _ := os.ReadFile(\"config.json\")  // BLOCKS!\n    m.config = parse(data)\n    return m, nil\n}\n```\n\n**Fix:** Move to a command:\n```go\nreturn m, loadConfigCmd()\n```\n\n### 2. Sleep in Update\n\n```go\n//  BAD - freezes UI for 2 seconds\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    time.Sleep(2 * time.Second)\n    return m, nil\n}\n```\n\n**Fix:** Use tea.Tick:\n```go\nreturn m, tea.Tick(2*time.Second, func(t time.Time) tea.Msg {\n    return DelayCompleteMsg{}\n})\n```\n\n### 3. HTTP Calls in Update\n\n```go\n//  BAD - network I/O in Update\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    resp, _ := http.Get(\"https://api.example.com\")\n    // ...\n}\n```\n\n**Fix:** Wrap in a command function.\n\n### 4. Channel Operations That Block\n\n```go\n//  BAD - may block indefinitely\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    data := <-m.dataChan  // Could block!\n    return m, nil\n}\n```\n\n**Fix:** Use non-blocking select or move to command.\n\n## Quick Reference: Is It Blocking?\n\n| Code Pattern | Blocking? | Why |\n|--------------|-----------|-----|\n| `return m, m.loadData()` | No | Returns cmd descriptor |\n| `data := fetchData()` (in Update) | **Yes** | Direct I/O call |\n| `return m, func() tea.Msg { ... }` | No | Closure runs later |\n| `time.Sleep(d)` (in Update) | **Yes** | Blocks goroutine |\n| `<-channel` (in Update) | **Maybe** | Blocks if empty |\n| `return m, tea.Tick(d, ...)` | No | Runtime handles delay |\n\n## Review Guidance\n\nWhen reviewing BubbleTea code:\n\n1. **Look for I/O in Update()** - file, network, database calls directly in Update are bugs\n2. **Ignore cmd helper patterns** - `return m, m.someHelper()` where helper returns `tea.Cmd` is correct\n3. **Check what's INSIDE commands** - the closure body is where blocking ops belong\n4. **Value receivers are fine** - BubbleTea's design expects this\n\nThe rule is simple: **Update() must return quickly. Commands do the slow work.**\n",
        "skills/bubbletea-code-review/references/model-update.md": "# Model & Update\n\n## Model Design\n\n### 1. Model Must Implement tea.Model\n\n```go\ntype Model struct {\n    // State\n    items    []Item\n    cursor   int\n    selected map[int]struct{}\n\n    // Dimensions (for responsive layout)\n    width  int\n    height int\n\n    // Sub-components\n    list     list.Model\n    viewport viewport.Model\n\n    // Error state\n    err error\n}\n\n// Verify interface implementation\nvar _ tea.Model = (*Model)(nil)\n```\n\n### 2. Init Returns Initial Command\n\n```go\n// BAD - blocking operation\nfunc (m Model) Init() tea.Cmd {\n    data := loadData()  // blocks!\n    return nil\n}\n\n// GOOD - async via command\nfunc (m Model) Init() tea.Cmd {\n    return tea.Batch(\n        loadDataCmd(),\n        tea.EnterAltScreen,\n    )\n}\n```\n\n## Update Patterns\n\n### 1. Switch on Message Type\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        return m.handleKey(msg)\n    case tea.WindowSizeMsg:\n        m.width = msg.Width\n        m.height = msg.Height\n        return m, nil\n    case dataLoadedMsg:\n        m.items = msg.items\n        return m, nil\n    case errMsg:\n        m.err = msg.err\n        return m, nil\n    }\n    return m, nil\n}\n```\n\n### 2. Always Handle WindowSizeMsg\n\n```go\n// BAD - ignores window size\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    // no WindowSizeMsg handling\n}\n\n// GOOD\ncase tea.WindowSizeMsg:\n    m.width = msg.Width\n    m.height = msg.Height\n    // Update sub-components\n    m.viewport.Width = msg.Width\n    m.viewport.Height = msg.Height - 4  // reserve for header/footer\n    return m, nil\n```\n\n### 3. Key Handling with key.Matches\n\n```go\n// BAD - string comparison\ncase tea.KeyMsg:\n    if msg.String() == \"q\" {\n        return m, tea.Quit\n    }\n\n// GOOD - use key bindings\ntype keyMap struct {\n    Quit key.Binding\n    Up   key.Binding\n    Down key.Binding\n}\n\nvar keys = keyMap{\n    Quit: key.NewBinding(\n        key.WithKeys(\"q\", \"ctrl+c\"),\n        key.WithHelp(\"q\", \"quit\"),\n    ),\n    Up: key.NewBinding(\n        key.WithKeys(\"up\", \"k\"),\n        key.WithHelp(\"/k\", \"up\"),\n    ),\n}\n\ncase tea.KeyMsg:\n    switch {\n    case key.Matches(msg, keys.Quit):\n        return m, tea.Quit\n    case key.Matches(msg, keys.Up):\n        m.cursor--\n    }\n```\n\n### 4. Sub-Component Updates\n\n```go\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    var cmds []tea.Cmd\n\n    // Update sub-components\n    var cmd tea.Cmd\n    m.list, cmd = m.list.Update(msg)\n    cmds = append(cmds, cmd)\n\n    m.viewport, cmd = m.viewport.Update(msg)\n    cmds = append(cmds, cmd)\n\n    // Handle our own messages\n    switch msg := msg.(type) {\n    case tea.KeyMsg:\n        // ...\n    }\n\n    return m, tea.Batch(cmds...)\n}\n```\n\n## Commands\n\n### 1. Commands Return Messages\n\n```go\n// Command that performs I/O\nfunc fetchItemsCmd(url string) tea.Cmd {\n    return func() tea.Msg {\n        resp, err := http.Get(url)\n        if err != nil {\n            return errMsg{err}\n        }\n        defer resp.Body.Close()\n\n        var items []Item\n        json.NewDecoder(resp.Body).Decode(&items)\n        return itemsFetchedMsg{items}\n    }\n}\n```\n\n### 2. Tick Commands for Animation\n\n```go\ntype tickMsg time.Time\n\nfunc tickCmd() tea.Cmd {\n    return tea.Tick(time.Millisecond*100, func(t time.Time) tea.Msg {\n        return tickMsg(t)\n    })\n}\n\ncase tickMsg:\n    m.frame++\n    return m, tickCmd()  // schedule next tick\n```\n\n### 3. Batch Multiple Commands\n\n```go\n// BAD - returns only last command\nfunc (m Model) Init() tea.Cmd {\n    loadConfig()\n    return loadData()  // loadConfig result lost!\n}\n\n// GOOD - batch them\nfunc (m Model) Init() tea.Cmd {\n    return tea.Batch(\n        loadConfigCmd(),\n        loadDataCmd(),\n        startSpinnerCmd(),\n    )\n}\n```\n\n## Anti-Patterns\n\n### 1. Side Effects in View\n\n```go\n// BAD\nfunc (m Model) View() string {\n    log.Printf(\"rendering\")  // side effect!\n    m.renderCount++          // mutation!\n    return \"...\"\n}\n\n// GOOD - View is pure\nfunc (m Model) View() string {\n    return \"...\"\n}\n```\n\n### 2. Blocking in Update\n\n```go\n// BAD\nfunc (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {\n    time.Sleep(2 * time.Second)  // freezes UI!\n    return m, nil\n}\n\n// GOOD - use commands for delays\nreturn m, tea.Tick(2*time.Second, func(t time.Time) tea.Msg {\n    return delayCompleteMsg{}\n})\n```\n\n## Review Questions\n\n1. Does Init return a command for initial I/O?\n2. Does Update handle all relevant message types?\n3. Is WindowSizeMsg handled for responsive layout?\n4. Are key bindings using key.Matches?\n5. Are sub-component updates propagated correctly?\n6. Are commands used for all async/I/O operations?\n",
        "skills/bubbletea-code-review/references/view-styling.md": "# View & Styling\n\n## View Function\n\n### 1. View Must Be Pure\n\n```go\n// BAD - side effects\nfunc (m Model) View() string {\n    m.lastRender = time.Now()  // mutation!\n    log.Println(\"rendering\")    // I/O!\n    return \"...\"\n}\n\n// GOOD - pure function\nfunc (m Model) View() string {\n    if m.loading {\n        return m.spinner.View() + \" Loading...\"\n    }\n    return m.renderContent()\n}\n```\n\n### 2. Handle Loading/Error States\n\n```go\nfunc (m Model) View() string {\n    if m.err != nil {\n        return errorStyle.Render(fmt.Sprintf(\"Error: %v\", m.err))\n    }\n    if m.loading {\n        return m.spinner.View() + \" Loading...\"\n    }\n    return m.renderContent()\n}\n```\n\n### 3. Compose Views Cleanly\n\n```go\nfunc (m Model) View() string {\n    var b strings.Builder\n\n    b.WriteString(m.renderHeader())\n    b.WriteString(\"\\n\")\n    b.WriteString(m.renderContent())\n    b.WriteString(\"\\n\")\n    b.WriteString(m.renderFooter())\n\n    return b.String()\n}\n```\n\n## Lipgloss Styling\n\n### 1. Define Styles at Package Level\n\n```go\n// BAD - created every render\nfunc (m Model) View() string {\n    style := lipgloss.NewStyle().Bold(true)\n    return style.Render(\"Hello\")\n}\n\n// GOOD - defined once\nvar (\n    titleStyle = lipgloss.NewStyle().\n        Bold(true).\n        Foreground(lipgloss.Color(\"205\"))\n\n    itemStyle = lipgloss.NewStyle().\n        PaddingLeft(2)\n)\n\nfunc (m Model) View() string {\n    return titleStyle.Render(\"Hello\")\n}\n```\n\n### 2. Use Color Palette\n\n```go\n// Define a consistent color palette\nvar (\n    colorPrimary   = lipgloss.Color(\"205\")  // magenta\n    colorSecondary = lipgloss.Color(\"241\")  // gray\n    colorSuccess   = lipgloss.Color(\"78\")   // green\n    colorError     = lipgloss.Color(\"196\")  // red\n)\n\nvar (\n    titleStyle = lipgloss.NewStyle().Foreground(colorPrimary)\n    errorStyle = lipgloss.NewStyle().Foreground(colorError)\n)\n```\n\n### 3. Adaptive Colors for Themes\n\n```go\nvar (\n    // Adaptive colors work with light and dark terminals\n    subtle    = lipgloss.AdaptiveColor{Light: \"#D9DCCF\", Dark: \"#383838\"}\n    highlight = lipgloss.AdaptiveColor{Light: \"#874BFD\", Dark: \"#7D56F4\"}\n)\n\nvar titleStyle = lipgloss.NewStyle().\n    Foreground(highlight).\n    Background(subtle)\n```\n\n### 4. Responsive Width\n\n```go\nfunc (m Model) View() string {\n    // Adjust style based on window width\n    doc := lipgloss.NewStyle().\n        Width(m.width).\n        MaxWidth(m.width)\n\n    return doc.Render(m.content)\n}\n```\n\n### 5. Layout with Place and Join\n\n```go\nfunc (m Model) View() string {\n    // Horizontal join\n    row := lipgloss.JoinHorizontal(\n        lipgloss.Top,\n        leftPanel.Render(m.menu),\n        rightPanel.Render(m.content),\n    )\n\n    // Vertical join\n    return lipgloss.JoinVertical(\n        lipgloss.Left,\n        m.header(),\n        row,\n        m.footer(),\n    )\n}\n\n// Center content\nfunc (m Model) View() string {\n    return lipgloss.Place(\n        m.width, m.height,\n        lipgloss.Center, lipgloss.Center,\n        m.content,\n    )\n}\n```\n\n### 6. Borders and Padding\n\n```go\nvar boxStyle = lipgloss.NewStyle().\n    Border(lipgloss.RoundedBorder()).\n    BorderForeground(lipgloss.Color(\"63\")).\n    Padding(1, 2).\n    Margin(1)\n\nvar selectedStyle = lipgloss.NewStyle().\n    Border(lipgloss.DoubleBorder()).\n    BorderForeground(lipgloss.Color(\"205\"))\n```\n\n## Common Patterns\n\n### Selected Item Highlighting\n\n```go\nfunc (m Model) renderItems() string {\n    var b strings.Builder\n    for i, item := range m.items {\n        cursor := \"  \"\n        if i == m.cursor {\n            cursor = \" \"\n        }\n\n        style := itemStyle\n        if i == m.cursor {\n            style = selectedStyle\n        }\n\n        b.WriteString(style.Render(cursor + item.Title))\n        b.WriteString(\"\\n\")\n    }\n    return b.String()\n}\n```\n\n### Help Footer\n\n```go\nfunc (m Model) helpView() string {\n    return helpStyle.Render(\"/: navigate  enter: select  q: quit\")\n}\n\n// Or use the help bubble\nimport \"github.com/charmbracelet/bubbles/help\"\n\nfunc (m Model) View() string {\n    return m.content + \"\\n\" + m.help.View(m.keys)\n}\n```\n\n### Status Bar\n\n```go\nvar statusStyle = lipgloss.NewStyle().\n    Background(lipgloss.Color(\"235\")).\n    Foreground(lipgloss.Color(\"255\")).\n    Padding(0, 1)\n\nfunc (m Model) statusBar() string {\n    status := fmt.Sprintf(\"Items: %d | Selected: %d\", len(m.items), len(m.selected))\n    return statusStyle.Width(m.width).Render(status)\n}\n```\n\n## Anti-Patterns\n\n### 1. ANSI Codes Instead of Lipgloss\n\n```go\n// BAD - raw ANSI\nfunc (m Model) View() string {\n    return \"\\033[1;31mError\\033[0m\"\n}\n\n// GOOD - Lipgloss\nvar errorStyle = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color(\"196\"))\nfunc (m Model) View() string {\n    return errorStyle.Render(\"Error\")\n}\n```\n\n### 2. Hardcoded Dimensions\n\n```go\n// BAD - ignores terminal size\nvar boxStyle = lipgloss.NewStyle().Width(80)\n\n// GOOD - responsive\nfunc (m Model) renderBox() string {\n    return boxStyle.Width(m.width - 4).Render(m.content)\n}\n```\n\n## Review Questions\n\n1. Is View a pure function with no side effects?\n2. Are styles defined once, not in View?\n3. Are colors using AdaptiveColor for light/dark themes?\n4. Is layout responsive to WindowSizeMsg?\n5. Are lipgloss.Join/Place used for layout composition?\n",
        "skills/cloudkit-code-review/SKILL.md": "---\nname: cloudkit-code-review\ndescription: Reviews CloudKit code for container setup, record handling, subscriptions, and sharing patterns. Use when reviewing code with import CloudKit, CKContainer, CKRecord, CKShare, or CKSubscription.\n---\n\n# CloudKit Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| CKContainer, databases, zones, entitlements | [references/container-setup.md](references/container-setup.md) |\n| CKRecord, references, assets, batch operations | [references/records.md](references/records.md) |\n| CKSubscription, push notifications, silent sync | [references/subscriptions.md](references/subscriptions.md) |\n| CKShare, participants, permissions, acceptance | [references/sharing.md](references/sharing.md) |\n\n## Review Checklist\n\n- [ ] Account status checked before private/shared database operations\n- [ ] Custom zones used (not default zone) for production data\n- [ ] All CloudKit errors handled with `retryAfterSeconds` respected\n- [ ] `serverRecordChanged` conflicts handled with proper merge logic\n- [ ] `CKErrorPartialFailure` parsed for individual record errors\n- [ ] Batch operations used (`CKModifyRecordsOperation`) not individual saves\n- [ ] Large binary data stored as `CKAsset` (records have 1MB limit)\n- [ ] Record keys type-safe (enums) not string literals\n- [ ] UI updates dispatched to main thread from callbacks\n- [ ] `CKAccountChangedNotification` observed for account switches\n- [ ] Subscriptions have unique IDs to prevent duplicates\n- [ ] CKShare uses custom zone (sharing requires custom zones)\n\n## When to Load References\n\n- Reviewing container/database setup or zones -> container-setup.md\n- Reviewing record CRUD or relationships -> records.md\n- Reviewing push notifications or sync triggers -> subscriptions.md\n- Reviewing sharing or collaboration features -> sharing.md\n\n## Output Format\n\nReport issues using: `[FILE:LINE] ISSUE_TITLE`\n\nExamples:\n- `[AppDelegate.swift:24] CKContainer not in custom zone`\n- `[SyncManager.swift:156] Unhandled CKErrorPartialFailure`\n- `[DataStore.swift:89] Missing retryAfterSeconds backoff`\n\n## Review Questions\n\n1. What happens when the user is signed out of iCloud?\n2. Does error handling respect rate limiting (`retryAfterSeconds`)?\n3. Are conflicts resolved or does data get overwritten silently?\n4. Is the schema deployed to production before App Store release?\n5. Are shared records in custom zones (required for CKShare)?\n",
        "skills/cloudkit-code-review/references/container-setup.md": "# CloudKit Container Setup\n\n## Container Architecture\n\n```swift\n// Default container (matches app's bundle identifier)\nlet container = CKContainer.default()\n\n// Custom container (explicit identifier - recommended)\nlet container = CKContainer(identifier: \"iCloud.com.company.appname\")\n```\n\n**Container identifiers cannot be deleted once created** - verify naming before creation.\n\n## Database Types\n\n| Database | Access | Custom Zones | Use Case |\n|----------|--------|--------------|----------|\n| **Private** | User-only (requires iCloud) | Yes | Personal data |\n| **Public** | Read: anyone; Write: signed-in | No (default only) | App-wide content |\n| **Shared** | Invited users only | Yes (one per sharer) | Collaboration |\n\n```swift\nlet privateDB = container.privateCloudDatabase\nlet publicDB = container.publicCloudDatabase\nlet sharedDB = container.sharedCloudDatabase\n```\n\n## Custom Zones\n\nCustom zones provide atomic operations, sharing, and change tokens. **Required for production apps.**\n\n```swift\nlet zoneID = CKRecordZone.ID(zoneName: \"MyZone\", ownerName: CKCurrentUserDefaultName)\nlet zone = CKRecordZone(zoneID: zoneID)\n\nlet operation = CKModifyRecordZonesOperation(recordZonesToSave: [zone], recordZoneIDsToDelete: nil)\nprivateDB.add(operation)\n```\n\n## Critical Anti-Patterns\n\n### 1. Using Default Zone for Production\n\n```swift\n// BAD: Default zone lacks atomic operations and sharing\nlet record = CKRecord(recordType: \"Note\")\nprivateDB.save(record) { _, _ in }\n\n// GOOD: Use custom zone\nlet zoneID = CKRecordZone.ID(zoneName: \"NotesZone\", ownerName: CKCurrentUserDefaultName)\nlet recordID = CKRecord.ID(recordName: UUID().uuidString, zoneID: zoneID)\nlet record = CKRecord(recordType: \"Note\", recordID: recordID)\n```\n\n### 2. Missing Account Status Check\n\n```swift\n// BAD: Assumes iCloud is available\nfunc saveUserData() {\n    container.privateCloudDatabase.save(record) { _, _ in }\n}\n\n// GOOD: Check account status first\ncontainer.accountStatus { status, error in\n    guard status == .available else {\n        // Handle: .noAccount, .restricted, .couldNotDetermine\n        return\n    }\n    self.container.privateCloudDatabase.save(record) { _, _ in }\n}\n```\n\n### 3. Not Observing Account Changes\n\n```swift\n// BAD: Assumes account persists\nclass DataManager {\n    let container = CKContainer.default()\n}\n\n// GOOD: Observe account changes\nNotificationCenter.default.addObserver(\n    forName: .CKAccountChanged,\n    object: nil,\n    queue: .main\n) { _ in\n    // Re-check account status, clear private data cache if user changed\n}\n```\n\n### 4. Missing NSPersistentCloudKitContainer Options\n\n```swift\n// BAD: Missing required options\nlet container = NSPersistentCloudKitContainer(name: \"Model\")\ncontainer.loadPersistentStores { _, _ in }\n\n// GOOD: Enable required tracking\nlet description = container.persistentStoreDescriptions.first!\ndescription.setOption(true as NSNumber, forKey: NSPersistentHistoryTrackingKey)\ndescription.setOption(true as NSNumber, forKey: NSPersistentStoreRemoteChangeNotificationPostOptionKey)\ndescription.cloudKitContainerOptions = NSPersistentCloudKitContainerOptions(\n    containerIdentifier: \"iCloud.com.company.app\"\n)\n```\n\n## Required Entitlements\n\n```xml\n<key>com.apple.developer.icloud-services</key>\n<array>\n    <string>CloudKit</string>\n</array>\n<key>com.apple.developer.icloud-container-identifiers</key>\n<array>\n    <string>iCloud.com.company.appname</string>\n</array>\n```\n\nFor production:\n```xml\n<key>com.apple.developer.icloud-container-environment</key>\n<string>Production</string>\n```\n\n## Review Questions\n\n1. Is the container identifier explicitly specified or relying on `.default()`?\n2. Is account status checked before accessing private/shared databases?\n3. Are custom zones used for production features?\n4. Is `CKAccountChanged` notification observed?\n5. Are entitlements configured for both app and extensions?\n6. Is the production environment entitlement set for release builds?\n",
        "skills/cloudkit-code-review/references/records.md": "# CloudKit Records\n\n## CKRecord Basics\n\n**Supported field types:**\n- `String`, `NSNumber`, `Data`, `Date`, `CLLocation`\n- `CKRecord.Reference` - links to other records\n- `CKAsset` - binary files (images, audio, documents)\n- Arrays of any above type (same-type elements only)\n\n**Size limits:**\n| Constraint | Limit |\n|------------|-------|\n| Single record (excluding assets) | 1 MB |\n| Single asset | 250 MB (native) |\n| Batch operations per request | ~400 records |\n\n## CKRecord.Reference\n\n```swift\n// Child points to parent with cascade delete\nlet parentRef = CKRecord.Reference(recordID: parentRecord.recordID, action: .deleteSelf)\nchildRecord[\"parentRef\"] = parentRef\n```\n\n**Actions:**\n- `.deleteSelf` - Child deleted when parent deleted\n- `.none` - Child becomes orphan when parent deleted\n\n## CKAsset\n\n```swift\nlet fileURL = getLocalFileURL()\nlet asset = CKAsset(fileURL: fileURL)\nrecord[\"attachment\"] = asset\n```\n\nAssets stored separately, don't count toward 1MB record limit.\n\n## Critical Anti-Patterns\n\n### 1. Storing Child Arrays in Parent\n\n```swift\n// BAD: Causes conflict resolution nightmares\nlet parentRecord = CKRecord(recordType: \"Album\")\nparentRecord[\"photoIDs\"] = photoIDs as CKRecordValue\n\n// GOOD: Child references parent\nlet photoRecord = CKRecord(recordType: \"Photo\")\nlet albumRef = CKRecord.Reference(recordID: albumRecord.recordID, action: .deleteSelf)\nphotoRecord[\"album\"] = albumRef\n```\n\n### 2. Ignoring Errors\n\n```swift\n// BAD\ndatabase.save(record) { _, error in\n    self.updateUI()  // Ignores error!\n}\n\n// GOOD\ndatabase.save(record) { _, error in\n    if let error = error as? CKError {\n        switch error.code {\n        case .serverRecordChanged:\n            self.resolveConflict(error: error)\n        case .networkUnavailable, .networkFailure:\n            if let retry = error.userInfo[CKErrorRetryAfterKey] as? Double {\n                DispatchQueue.main.asyncAfter(deadline: .now() + retry) {\n                    self.retrySave(record)\n                }\n            }\n        default:\n            self.handleError(error)\n        }\n        return\n    }\n    DispatchQueue.main.async { self.updateUI() }\n}\n```\n\n### 3. String Literals for Keys\n\n```swift\n// BAD: Typos won't be caught\nrecord[\"titel\"] = title\n\n// GOOD: Type-safe keys\nenum RecordKeys: String {\n    case title, createdAt, category\n}\nrecord[RecordKeys.title.rawValue] = title\n```\n\n### 4. Individual Saves Instead of Batch\n\n```swift\n// BAD: Separate network call for each record\nfor record in records {\n    database.save(record) { _, _ in }\n}\n\n// GOOD: Single batch operation\nlet operation = CKModifyRecordsOperation(recordsToSave: records, recordIDsToDelete: nil)\noperation.modifyRecordsResultBlock = { result in }\ndatabase.add(operation)\n```\n\n### 5. Exceeding Record Size\n\n```swift\n// BAD: May exceed 1MB limit\nrecord[\"imageData\"] = largeImageData as CKRecordValue\n\n// GOOD: Use CKAsset for binary data\nlet tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(\"temp.jpg\")\ntry imageData.write(to: tempURL)\nrecord[\"image\"] = CKAsset(fileURL: tempURL)\n```\n\n### 6. UI Updates on Background Thread\n\n```swift\n// BAD: CloudKit callbacks are on background thread\ndatabase.fetch(withRecordID: recordID) { record, error in\n    self.titleLabel.text = record?[\"title\"] as? String  // Crash!\n}\n\n// GOOD\ndatabase.fetch(withRecordID: recordID) { record, error in\n    DispatchQueue.main.async {\n        self.titleLabel.text = record?[\"title\"] as? String\n    }\n}\n```\n\n### 7. Downloading All Fields\n\n```swift\n// BAD: Downloads everything including large assets\nlet query = CKQuery(recordType: \"Photo\", predicate: predicate)\ndatabase.perform(query, inZoneWith: nil) { records, error in }\n\n// GOOD: Only fetch needed fields\nlet operation = CKQueryOperation(query: query)\noperation.desiredKeys = [\"title\", \"timestamp\"]\ndatabase.add(operation)\n```\n\n## Error Handling Table\n\n| Error Code | Common Mistake | Correct Handling |\n|------------|----------------|------------------|\n| `partialFailure` | Treat as complete failure | Parse `partialErrorsByItemID` |\n| `serverRecordChanged` | Retry with client record | Merge using server record from error |\n| `requestRateLimited` | Immediate retry | Use `retryAfterSeconds` |\n| `limitExceeded` | Fail operation | Split batch and retry |\n| `quotaExceeded` | Silent failure | Alert user |\n\n## Review Questions\n\n1. Are custom record IDs used that match local storage identifiers?\n2. Is record data under 1MB with large files as CKAssets?\n3. Are relationships using back-references (child->parent) not arrays?\n4. Is `.deleteSelf` used appropriately for cascade delete needs?\n5. Are all CloudKit callbacks dispatching UI updates to main thread?\n6. Is `desiredKeys` specified to avoid downloading unnecessary data?\n",
        "skills/cloudkit-code-review/references/sharing.md": "# CloudKit Sharing\n\n## Sharing Models\n\n| Model | Use Case | CKShare Creation |\n|-------|----------|------------------|\n| **Record Sharing** | Individual records with hierarchy | `CKShare(rootRecord: record)` |\n| **Zone Sharing** | All records in custom zone | `CKShare(recordZoneID: zone.zoneID)` |\n\n## Permission Levels\n\n| Permission | Description |\n|------------|-------------|\n| `.none` | No access (default for `publicPermission`) |\n| `.readOnly` | Can read shared records |\n| `.readWrite` | Can read and modify shared records |\n\n## Database Architecture\n\n```\nPrivate Database (Owner)\n Custom Zone (required!)\n     Root Record\n     Child Records (auto-shared)\n     CKShare Record\n\nShared Database (Participants)\n [View into owner's private database]\n```\n\n## Critical Anti-Patterns\n\n### 1. Using Default Zone for Sharing\n\n```swift\n// BAD: CKShare cannot be saved in Default Zone\nlet record = CKRecord(recordType: \"Item\")  // Uses default zone\nlet share = CKShare(rootRecord: record)\ntry await privateDatabase.save(share)  // ERROR!\n\n// GOOD: Use custom zone\nlet zoneID = CKRecordZone.ID(zoneName: \"SharedItems\", ownerName: CKCurrentUserDefaultName)\nlet recordID = CKRecord.ID(recordName: UUID().uuidString, zoneID: zoneID)\nlet record = CKRecord(recordType: \"Item\", recordID: recordID)\nlet share = CKShare(rootRecord: record)\ntry await privateDatabase.modifyRecords(saving: [record, share], deleting: [])\n```\n\n### 2. Saving CKShare Without Root Record\n\n```swift\n// BAD: Even if record exists, must save together\nlet share = CKShare(rootRecord: existingRecord)\ntry await privateDatabase.save(share)  // ERROR!\n\n// GOOD: Save both together\ntry await privateDatabase.modifyRecords(saving: [existingRecord, share], deleting: [])\n```\n\n### 3. Creating New Shares for Already-Shared Records\n\n```swift\n// BAD: Revokes existing share, removes all participants\nfunc shareContact(_ contact: CKRecord) async throws {\n    let share = CKShare(rootRecord: contact)  // Creates NEW share!\n    try await privateDatabase.modifyRecords(saving: [contact, share], deleting: [])\n}\n\n// GOOD: Check for existing share first\nfunc shareContact(_ contact: CKRecord) async throws -> CKShare {\n    if let existingShareRef = contact.share {\n        return try await privateDatabase.record(for: existingShareRef.recordID) as! CKShare\n    }\n    let share = CKShare(rootRecord: contact)\n    try await privateDatabase.modifyRecords(saving: [contact, share], deleting: [])\n    return share\n}\n```\n\n### 4. Not Verifying Permissions Before Modification\n\n```swift\n// BAD: Assumes write access\nfunc updateSharedRecord(_ record: CKRecord) async throws {\n    record[\"name\"] = \"Updated\"\n    try await sharedDatabase.save(record)  // Fails if readOnly!\n}\n\n// GOOD: Check permission first\nfunc canModify(share: CKShare) -> Bool {\n    guard let participant = share.currentUserParticipant else { return false }\n    return participant.permission == .readWrite || share.owner == participant\n}\n```\n\n### 5. Missing CKSharingSupported in Info.plist\n\n```xml\n<!-- Required for share acceptance callbacks -->\n<key>CKSharingSupported</key>\n<true/>\n```\n\nWithout this, `userDidAcceptCloudKitShareWith` is never called.\n\n### 6. Not Handling Share Acceptance\n\n```swift\n// BAD: Share links won't work\nclass SceneDelegate: UIResponder, UIWindowSceneDelegate {\n    // Missing implementation\n}\n\n// GOOD\nfunc windowScene(\n    _ windowScene: UIWindowScene,\n    userDidAcceptCloudKitShareWith metadata: CKShare.Metadata\n) {\n    let container = CKContainer(identifier: metadata.containerIdentifier)\n    Task {\n        do {\n            try await container.accept(metadata)\n        } catch {\n            // Handle error\n        }\n    }\n}\n```\n\n### 7. Not Setting Share Metadata\n\n```swift\n// BAD: Email invitations show no context\nlet share = CKShare(rootRecord: record)\n\n// GOOD: Set title for user-friendly invitations\nlet share = CKShare(rootRecord: record)\nshare[CKShare.SystemFieldKey.title] = \"Shopping List\"\nshare[CKShare.SystemFieldKey.shareType] = \"com.app.shoppinglist\"\nshare[CKShare.SystemFieldKey.thumbnailImageData] = thumbnailData\n```\n\n### 8. Multiple CKShare per Zone\n\n```swift\n// BAD: Only ONE CKShare allowed per zone\nlet share1 = CKShare(recordZoneID: zoneID)\ntry await privateDatabase.save(share1)\nlet share2 = CKShare(recordZoneID: zoneID)  // ERROR on save!\n\n// GOOD: Check for existing zone share\nfunc getOrCreateZoneShare(for zoneID: CKRecordZone.ID) async throws -> CKShare {\n    let shareID = CKRecord.ID(recordName: CKRecordNameZoneWideShare, zoneID: zoneID)\n    do {\n        return try await privateDatabase.record(for: shareID) as! CKShare\n    } catch {\n        let share = CKShare(recordZoneID: zoneID)\n        try await privateDatabase.save(share)\n        return share\n    }\n}\n```\n\n## UICloudSharingController Integration\n\n```swift\nfunc presentShareController(for share: CKShare, record: CKRecord) {\n    // Pre-fetch share before presenting\n    let controller = UICloudSharingController(share: share, container: container)\n    controller.delegate = self\n    present(controller, animated: true)\n}\n\n// Required delegate methods\nextension ViewController: UICloudSharingControllerDelegate {\n    func cloudSharingController(_ csc: UICloudSharingController, failedToSaveShareWithError error: Error) {\n        // Handle error\n    }\n\n    func itemTitle(for csc: UICloudSharingController) -> String? {\n        return \"Shared Item\"\n    }\n}\n```\n\n## Review Questions\n\n1. Is CKShare saved to a **custom zone** (not Default Zone)?\n2. Is root record saved **together** with CKShare in same operation?\n3. Does code check for **existing shares** before creating new ones?\n4. Is **CKSharingSupported** enabled in Info.plist?\n5. Is `userDidAcceptCloudKitShareWith` implemented?\n6. Are shared records accessed from **sharedDatabase** (not privateDatabase)?\n7. Does code verify **permissions** before attempting modifications?\n8. Is **share metadata** (title, type) set for user-friendly invitations?\n",
        "skills/cloudkit-code-review/references/subscriptions.md": "# CloudKit Subscriptions\n\n## Subscription Types\n\n| Type | Use Case | Database Support |\n|------|----------|------------------|\n| **CKQuerySubscription** | Records matching predicate | Public, Private (default zone) |\n| **CKRecordZoneSubscription** | All changes in custom zone | Private only |\n| **CKDatabaseSubscription** | All changes across database | Private, Shared |\n\n**Recommendation:** Start with `CKDatabaseSubscription` unless only using default zone.\n\n## Notification Configuration\n\n```swift\nlet info = CKSubscription.NotificationInfo()\n\n// Visible notification\ninfo.alertBody = \"New record available\"\ninfo.soundName = \"default\"\ninfo.shouldBadge = true\n\n// Silent notification (background sync)\ninfo.shouldSendContentAvailable = true\n// Leave alertBody, soundName, shouldBadge unset\n```\n\n## Critical Anti-Patterns\n\n### 1. Creating Duplicate Subscriptions\n\n```swift\n// BAD: Creates duplicate on every app launch\nfunc application(_ application: UIApplication, didFinishLaunchingWithOptions...) {\n    let subscription = CKQuerySubscription(recordType: \"Item\", predicate: predicate, options: .firesOnRecordCreation)\n    database.save(subscription) { _, _ in }\n}\n\n// GOOD: Check before creating, use consistent ID\nlet subscriptionID = \"item-creation-subscription\"\n\ndatabase.fetch(withSubscriptionID: subscriptionID) { subscription, error in\n    if subscription == nil {\n        let newSubscription = CKQuerySubscription(\n            recordType: \"Item\",\n            predicate: predicate,\n            subscriptionID: subscriptionID,\n            options: .firesOnRecordCreation\n        )\n        let info = CKSubscription.NotificationInfo()\n        info.shouldSendContentAvailable = true\n        newSubscription.notificationInfo = info\n        database.save(newSubscription) { _, _ in }\n    }\n}\n```\n\n### 2. Missing NotificationInfo\n\n```swift\n// BAD: Subscription will fail to save\nlet subscription = CKQuerySubscription(recordType: \"Item\", predicate: predicate, options: .firesOnRecordCreation)\ndatabase.save(subscription) { _, error in }  // Error!\n\n// GOOD: Always configure notificationInfo\nlet info = CKSubscription.NotificationInfo()\ninfo.shouldSendContentAvailable = true\nsubscription.notificationInfo = info\n```\n\n### 3. Wrong Subscription Type for Shared Database\n\n```swift\n// BAD: CKQuerySubscription doesn't work with shared database\nlet sharedDB = CKContainer.default().sharedCloudDatabase\nlet subscription = CKQuerySubscription(recordType: \"SharedItem\", predicate: predicate, options: .firesOnRecordCreation)\nsharedDB.save(subscription) { _, error in }  // Error!\n\n// GOOD: Use CKDatabaseSubscription for shared database\nlet subscription = CKDatabaseSubscription(subscriptionID: \"shared-db-subscription\")\nlet info = CKSubscription.NotificationInfo()\ninfo.shouldSendContentAvailable = true\nsubscription.notificationInfo = info\nsharedDB.save(subscription) { _, _ in }\n```\n\n### 4. Relying Solely on Push for Sync\n\n```swift\n// BAD: Only syncing when push arrives\nfunc application(_ application: UIApplication, didReceiveRemoteNotification userInfo: [AnyHashable: Any]) {\n    syncData()  // Only sync trigger\n}\n\n// GOOD: Multiple sync triggers\nfunc applicationDidBecomeActive(_ application: UIApplication) {\n    syncData()  // On app launch\n}\n\nfunc application(_ application: UIApplication, didReceiveRemoteNotification userInfo: [AnyHashable: Any]) {\n    syncData()  // On notification\n}\n// Also implement background fetch\n```\n\n### 5. Not Indexing Predicate Fields\n\n```swift\n// BAD: Field not indexed in CloudKit Dashboard\nlet predicate = NSPredicate(format: \"category == %@\", \"news\")\n// Error: CKError.invalidArguments when saving subscription\n\n// FIX: Enable \"Query\" indexing for field in CloudKit Dashboard\n```\n\n## Registration Flow\n\n```swift\n// 1. Request authorization\nUNUserNotificationCenter.current().requestAuthorization(options: [.alert, .sound, .badge]) { granted, error in\n    // 2. Register for remote notifications\n    DispatchQueue.main.async {\n        UIApplication.shared.registerForRemoteNotifications()\n    }\n}\n\n// 3. Create subscription after registration\nsubscriptionManager.ensureSubscriptionExists()\n```\n\n## Subscription Manager Pattern\n\n```swift\nclass SubscriptionManager {\n    private let subscriptionKey = \"cloudkit.subscription.created\"\n\n    func ensureSubscriptionExists() {\n        guard !UserDefaults.standard.bool(forKey: subscriptionKey) else { return }\n\n        let subscription = CKDatabaseSubscription(subscriptionID: \"all-changes\")\n        let info = CKSubscription.NotificationInfo()\n        info.shouldSendContentAvailable = true\n        subscription.notificationInfo = info\n\n        let operation = CKModifySubscriptionsOperation(\n            subscriptionsToSave: [subscription],\n            subscriptionIDsToDelete: nil\n        )\n        operation.modifySubscriptionsCompletionBlock = { saved, _, error in\n            if error == nil {\n                UserDefaults.standard.set(true, forKey: self.subscriptionKey)\n            }\n        }\n        database.add(operation)\n    }\n}\n```\n\n## Review Questions\n\n1. Is a specific `subscriptionID` used to prevent duplicates?\n2. Is `notificationInfo` properly configured before saving?\n3. Is the correct subscription type used for the database (shared needs CKDatabaseSubscription)?\n4. Are predicate fields indexed in CloudKit Dashboard?\n5. Is `shouldSendContentAvailable` set for silent notifications (without alertBody)?\n6. Does the app handle coalesced notifications (not 1:1 with changes)?\n7. Is there fallback sync logic for when notifications don't arrive?\n8. Is the schema deployed to production before App Store release?\n",
        "skills/combine-code-review/SKILL.md": "---\nname: combine-code-review\ndescription: Reviews Combine framework code for memory leaks, operator misuse, and error handling. Use when reviewing code with import Combine, AnyPublisher, @Published, PassthroughSubject, or CurrentValueSubject.\n---\n\n# Combine Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Publishers, Subjects, AnyPublisher | [references/publishers.md](references/publishers.md) |\n| map, flatMap, combineLatest, switchToLatest | [references/operators.md](references/operators.md) |\n| AnyCancellable, retain cycles, [weak self] | [references/memory.md](references/memory.md) |\n| tryMap, catch, replaceError, Never | [references/error-handling.md](references/error-handling.md) |\n\n## Review Checklist\n\n- [ ] All `sink` closures use `[weak self]` when self owns cancellable\n- [ ] No `assign(to:on:self)` usage (use `assign(to: &$property)` or sink)\n- [ ] All AnyCancellables stored in Set or property (not discarded)\n- [ ] Subjects exposed as `AnyPublisher` via `eraseToAnyPublisher()`\n- [ ] `flatMap` used correctly (not when `map + switchToLatest` needed)\n- [ ] Error handling inside `flatMap` to keep main chain alive\n- [ ] `tryMap` followed by `mapError` to restore error types\n- [ ] `receive(on: DispatchQueue.main)` before UI updates\n- [ ] PassthroughSubject for events, CurrentValueSubject for state\n- [ ] Future wrapped in Deferred when used with retry\n\n## When to Load References\n\n- Reviewing Subjects or publisher selection  publishers.md\n- Reviewing operator chains or combining publishers  operators.md\n- Reviewing subscriptions or memory issues  memory.md\n- Reviewing error handling or try* operators  error-handling.md\n\n## Review Questions\n\n1. Are all subscriptions being retained? (Check for discarded AnyCancellables)\n2. Could any sink or assign create a retain cycle with self?\n3. Does flatMap need to be switchToLatest for search/autocomplete?\n4. What happens when this publisher fails? (Will it kill the main chain?)\n5. Are error types preserved or properly mapped after try* operators?\n",
        "skills/combine-code-review/references/error-handling.md": "# Combine Error Handling\n\n## Error Types in Combine\n\nEvery publisher declares `Publisher<Output, Failure>`. Unlike other reactive frameworks, Combine enforces error types at compile time.\n\n### The `Never` Type\n- `Failure == Never` means the publisher can never fail\n- Required for `assign(to:on:)` - must convert failable publishers first\n- Created by `replaceError(with:)` or `catch` with infallible fallback\n\n### Converting Error Types\n```swift\n// setFailureType: Never  CustomError\nJust(\"Hello\")\n    .setFailureType(to: APIError.self)\n\n// mapError: URLError  APIError\nurlSession.dataTaskPublisher(for: url)\n    .mapError { .networkError($0) }\n```\n\n## try* Operators\n\nThe `try`-prefixed operators allow throwing but **erase error type to `Swift.Error`**.\n\n| Operator | Preserves Failure Type | Can Throw |\n|----------|----------------------|-----------|\n| `map` | Yes | No |\n| `tryMap` | No (erases to `Error`) | Yes |\n| `filter` | Yes | No |\n| `tryFilter` | No (erases to `Error`) | Yes |\n\n**Always follow tryMap with mapError:**\n```swift\npublisher\n    .tryMap { try JSONDecoder().decode(User.self, from: $0) }\n    .mapError { $0 as? APIError ?? .unknown($0) }\n```\n\n## catch vs replaceError\n\n| Aspect | `catch` | `replaceError(with:)` |\n|--------|---------|----------------------|\n| Returns | New publisher | Single value |\n| Can inspect error | Yes | No |\n| Post-error values | Multiple possible | One then completes |\n| Result Failure type | Depends on fallback | `Never` |\n\n```swift\n// replaceError: Simple fallback value\nimagePublisher\n    .replaceError(with: placeholderImage)\n\n// catch: Inspect error, provide fallback publisher\nprimaryAPI\n    .catch { error -> AnyPublisher<Data, Never> in\n        if case .notFound = error {\n            return fallbackAPI.replaceError(with: Data())\n        }\n        return Just(Data()).eraseToAnyPublisher()\n    }\n```\n\n## Critical Anti-Patterns\n\n### 1. Error Handling in Main Chain Kills Publisher\n\n```swift\n// BAD: Main chain dies after first error\nsearchText\n    .flatMap { query in networkRequest(query) }\n    .replaceError(with: [])  // Publisher dead after one error!\n    .sink { results in ... }\n\n// GOOD: Handle errors inside flatMap\nsearchText\n    .flatMap { query in\n        networkRequest(query)\n            .replaceError(with: [])  // Inner publisher handles error\n    }\n    .sink { results in ... }  // Main chain stays alive\n```\n\n### 2. Using tryMap Without mapError\n\n```swift\n// BAD: Loses specific error type\npublisher.tryMap { try decode($0) }\n// Failure is now plain Error\n\n// GOOD: Restore error type\npublisher.tryMap { try decode($0) }\n    .mapError { $0 as? APIError ?? .unknown($0) }\n```\n\n### 3. assertNoFailure in Production\n\n```swift\n// BAD: Crashes app on network error\nnetworkPublisher\n    .assertNoFailure()  // Fatal error!\n\n// GOOD: Handle expected errors\nnetworkPublisher\n    .catch { _ in Just(defaultValue) }\n```\n\n### 4. assign(to:on:) with Failable Publishers\n\n```swift\n// COMPILE ERROR: Failure must be Never\nnetworkPublisher  // Failure: URLError\n    .assign(to: \\.data, on: viewModel)\n\n// FIXED: Handle errors first\nnetworkPublisher\n    .replaceError(with: defaultData)  // Now Failure is Never\n    .assign(to: \\.data, on: viewModel)\n```\n\n### 5. Not Handling Errors Before Long-Lived Subscriptions\n\n```swift\n// BAD: First error kills subscription permanently\ndataPublisher\n    .receive(on: DispatchQueue.main)\n    .assign(to: \\.items, on: viewModel)  // Dead after first error\n\n// GOOD: Error handling preserves subscription\ndataPublisher\n    .catch { _ in Just([]) }\n    .receive(on: DispatchQueue.main)\n    .assign(to: \\.items, on: viewModel)\n```\n\n## Review Questions\n\n1. Is error type preserved through the pipeline? (Check for naked tryMap)\n2. Will this publisher survive its first error? (Check where catch/replaceError is)\n3. Is `assertNoFailure` used for expected errors? (Should only be programming errors)\n4. Are error types unified at API boundaries with mapError?\n5. Is the publisher infallible (`Failure == Never`) before assign(to:on:)?\n",
        "skills/combine-code-review/references/memory.md": "# Combine Memory Management\n\n## AnyCancellable Lifecycle\n\n`AnyCancellable` is a type-erasing wrapper that **automatically calls `cancel()` when deallocated**.\n\n**Critical behavior:** If not retained, the subscription cancels immediately. This often manifests as `NSURLErrorDomain -999` errors.\n\n```swift\n// BAD: Subscription cancels immediately\nfunc fetchData() {\n    publisher.sink { data in self.data = data }\n    // AnyCancellable not stored - immediately released!\n}\n\n// GOOD: Store in Set\nvar cancellables = Set<AnyCancellable>()\n\nfunc fetchData() {\n    publisher.sink { [weak self] data in\n        self?.data = data\n    }.store(in: &cancellables)\n}\n```\n\n## The Retain Cycle Pattern\n\nRetain cycles occur when:\n1. `self` owns the cancellable (via `cancellables` Set)\n2. The cancellable owns the closure\n3. The closure captures `self` strongly\n\n```\nself  cancellables  closure  self (CYCLE)\n```\n\n## Critical Anti-Patterns\n\n### 1. Strong Self in sink()\n\n```swift\n// RETAIN CYCLE\npublisher.sink { value in\n    self.property = value  // Strong capture\n}.store(in: &cancellables)\n\n// FIXED\npublisher.sink { [weak self] value in\n    self?.property = value\n}.store(in: &cancellables)\n```\n\n### 2. assign(to:on:) with self\n\n`assign(to:on:)` **always** captures its target strongly. No weak option exists.\n\n```swift\n// RETAIN CYCLE - ALWAYS\npublisher\n    .assign(to: \\.property, on: self)\n    .store(in: &cancellables)\n\n// FIX 1: Use sink with weak self\npublisher.sink { [weak self] value in\n    self?.property = value\n}.store(in: &cancellables)\n\n// FIX 2: Use assign(to:) with @Published (iOS 14+)\n@Published var property: Value\npublisher.assign(to: &$property)  // No AnyCancellable returned\n```\n\n### 3. Not Storing the Cancellable\n\n```swift\n// BUG: Subscription dies immediately\nfunc subscribe() {\n    publisher.sink { print($0) }  // Discarded!\n}\n\n// FIXED\nvar cancellables = Set<AnyCancellable>()\nfunc subscribe() {\n    publisher.sink { print($0) }\n        .store(in: &cancellables)\n}\n```\n\n### 4. Nested Closures Missing Weak Captures\n\n```swift\n// Each closure needs its own [weak self]\npublisher\n    .flatMap { [weak self] value in\n        self?.transform(value) ?? Empty()\n    }\n    .sink { [weak self] result in  // Need [weak self] again!\n        self?.handle(result)\n    }\n    .store(in: &cancellables)\n```\n\n### 5. Long-Lived Subscriptions Without Weak Self\n\n```swift\n// MEMORY LEAK: Timer keeps self alive forever\nTimer.publish(every: 1.0, on: .main, in: .common)\n    .autoconnect()\n    .sink { _ in\n        self.updateUI()  // Strong capture\n    }\n    .store(in: &cancellables)\n\n// FIXED\nTimer.publish(every: 1.0, on: .main, in: .common)\n    .autoconnect()\n    .sink { [weak self] _ in\n        self?.updateUI()\n    }\n    .store(in: &cancellables)\n```\n\n## Single Cancellable Pattern\n\nFor auto-cancelling previous subscriptions (search debouncing):\n\n```swift\nprivate var searchCancellable: AnyCancellable?\n\nfunc search(_ query: String) {\n    // Previous subscription automatically cancelled\n    searchCancellable = searchPublisher(query)\n        .sink { [weak self] results in\n            self?.results = results\n        }\n}\n```\n\n## Review Questions\n\n1. Is every `sink()` and `assign()` result stored?\n2. Does `sink()` use `[weak self]` when self owns the cancellable?\n3. Is `assign(to:on:)` used with `self`? (Always a leak)\n4. Are there nested closures missing weak captures?\n5. Are long-lived subscriptions (timers, notifications) using weak self?\n",
        "skills/combine-code-review/references/operators.md": "# Combine Operators\n\n## Key Operators by Category\n\n### Transforming\n| Operator | Purpose |\n|----------|---------|\n| `map` | Transform each value 1:1 |\n| `tryMap` | Transform with throwing closure (erases error type) |\n| `flatMap` | Transform to new publisher, flatten nested publishers |\n| `compactMap` | Transform and filter out nil values |\n| `scan` | Accumulate values over time (emits each step) |\n\n### Combining\n| Operator | Purpose |\n|----------|---------|\n| `merge` | Interleave values from publishers of same type |\n| `combineLatest` | Emit tuple of latest values when any emits |\n| `zip` | Pair values by index (waits for all to emit) |\n| `switchToLatest` | Switch to latest inner publisher, cancel previous |\n\n### Timing\n| Operator | Purpose |\n|----------|---------|\n| `debounce` | Wait for pause in emissions |\n| `throttle` | Limit rate of emissions |\n| `delay` | Shift emissions forward in time |\n| `timeout` | Fail if no value within time limit |\n\n## map vs flatMap vs switchToLatest\n\n| Scenario | Use |\n|----------|-----|\n| Transform value: `String`  `Int` | `map` |\n| Transform to publisher: `URL`  `Publisher<Data>` | `flatMap` |\n| Transform to publisher, cancel previous | `map` + `switchToLatest` |\n\n```swift\n// map: Simple transformation\npublisher.map { $0.uppercased() }\n\n// flatMap: Transformation produces a publisher\npublisher.flatMap { url in\n    URLSession.shared.dataTaskPublisher(for: url)\n}\n\n// switchToLatest: Cancel previous (search/autocomplete)\nsearchText\n    .map { query in searchAPI(query) }\n    .switchToLatest()  // Cancels previous request\n```\n\n## combineLatest vs merge vs zip\n\n| Aspect | merge | combineLatest | zip |\n|--------|-------|---------------|-----|\n| **Output** | Same type | Tuple | Tuple |\n| **Emits when** | Any emits | Any (after all emit once) | All emit new value |\n| **Use for** | Multiple event sources | Form validation | Parallel requests |\n\n```swift\n// merge: Combine same-type streams\nlet allTaps = buttonA.merge(with: buttonB)\n\n// combineLatest: React to any change (form validation)\nPublishers.CombineLatest(emailValid, passwordValid)\n    .map { $0 && $1 }\n\n// zip: Wait for both (parallel requests)\nPublishers.Zip(fetchUser, fetchPreferences)\n```\n\n## Critical Anti-Patterns\n\n### 1. flatMap Instead of switchToLatest for Search\n\n```swift\n// BAD: All requests execute, results arrive out of order\nsearchText.flatMap { query in search(query) }\n\n// GOOD: Cancel previous requests\nsearchText\n    .map { query in search(query) }\n    .switchToLatest()\n```\n\n### 2. Wrong Threading Operator\n\n```swift\n// BAD: subscribe(on:) doesn't affect where values received\nURLSession.shared.dataTaskPublisher(for: url)\n    .subscribe(on: DispatchQueue.main)  // WRONG!\n    .sink { /* NOT on main thread */ }\n\n// GOOD: Use receive(on:) for downstream\nURLSession.shared.dataTaskPublisher(for: url)\n    .receive(on: DispatchQueue.main)\n    .sink { /* On main thread */ }\n```\n\n### 3. combineLatest with Publisher That Never Emits\n\n```swift\n// BUG: Won't emit until ALL publishers emit at least once\nPublishers.CombineLatest(requiredField, optionalAction)\n// If optionalAction never fires, stream never starts\n```\n\n### 4. Using tryMap Without mapError\n\n```swift\n// BAD: Erases error type to plain Error\npublisher.tryMap { try decode($0) }\n\n// GOOD: Restore specific error type\npublisher.tryMap { try decode($0) }\n    .mapError { $0 as? APIError ?? .unknown($0) }\n```\n\n## Review Questions\n\n1. Is `flatMap` appropriate, or should it be `map + switchToLatest`?\n2. Are `combineLatest` publishers guaranteed to emit at least once?\n3. Is `receive(on:)` used before UI updates (not `subscribe(on:)`)?\n4. Are try* operators followed by `mapError` for type safety?\n5. Could `debounce` or `throttle` reduce unnecessary work?\n",
        "skills/combine-code-review/references/publishers.md": "# Combine Publishers\n\n## Built-in Publishers\n\n| Publisher | Use Case |\n|-----------|----------|\n| `Just` | Single synchronous value, placeholders |\n| `Future` | Converting callback-based APIs (executes once, caches result) |\n| `Deferred` | Lazy publisher creation, wrap Future for retry support |\n| `Empty` | No-op placeholder, completing immediately |\n| `Fail` | Immediate error emission, testing error paths |\n| `Sequence.publisher` | `[1,2,3].publisher` emits each element |\n| `Timer.Publisher` | Periodic events (requires `autoconnect()`) |\n| `DataTaskPublisher` | Network requests via URLSession |\n\n## Subject Types\n\n### PassthroughSubject - Use for Events\n\n```swift\nlet buttonTaps = PassthroughSubject<Void, Never>()\nbuttonTaps.send(())  // Subscribers only notified if already subscribed\n```\n\n- No initial value required\n- No `.value` property\n- New subscribers receive only future values\n- Best for: button taps, user actions, transient events\n\n### CurrentValueSubject - Use for State\n\n```swift\nlet loadingState = CurrentValueSubject<LoadingState, Never>(.idle)\nprint(loadingState.value)  // Can query current state\n```\n\n- Initial value required\n- `.value` property for direct access\n- New subscribers receive current value immediately\n- Best for: settings, loading state, toggles\n\n## Critical Anti-Patterns\n\n### 1. Exposing Subjects Publicly\n\n```swift\n// BAD: External code can call loginSubject.send(...)\nclass AuthManager {\n    let loginSubject = PassthroughSubject<User, Error>()\n}\n\n// GOOD: Expose as read-only publisher\nclass AuthManager {\n    private let loginSubject = PassthroughSubject<User, Error>()\n    var loginPublisher: AnyPublisher<User, Error> {\n        loginSubject.eraseToAnyPublisher()\n    }\n}\n```\n\n### 2. Using Just for Arrays When Sequence Intended\n\n```swift\n// BAD: Emits entire array as one value\nJust([1, 2, 3]).sink { print($0) }  // prints: [1, 2, 3]\n\n// GOOD: Emits each element\n[1, 2, 3].publisher.sink { print($0) }  // prints: 1, 2, 3\n```\n\n### 3. Future Without Deferred for Retry\n\n```swift\n// BAD: Retry reuses cached failure\nFuture { promise in networkCall(completion: promise) }\n    .retry(3)  // Same cached result retried!\n\n// GOOD: Wrap in Deferred\nDeferred {\n    Future { promise in networkCall(completion: promise) }\n}.retry(3)  // New Future created each retry\n```\n\n### 4. Wrong Subject Type for Use Case\n\n```swift\n// BAD: PassthroughSubject for state (late subscribers miss value)\nlet isLoggedIn = PassthroughSubject<Bool, Never>()\n\n// GOOD: CurrentValueSubject for state\nlet isLoggedIn = CurrentValueSubject<Bool, Never>(false)\n```\n\n## Review Questions\n\n1. Are Subjects exposed publicly or converted to AnyPublisher?\n2. Is the correct Subject type used (events vs state)?\n3. Is Future used with retry without Deferred wrapper?\n4. Are built-in publishers preferred over custom implementations?\n5. Is `.value` access needed? (Requires CurrentValueSubject)\n",
        "skills/dagre-react-flow/SKILL.md": "---\nname: dagre-react-flow\ndescription: Automatic graph layout using dagre with React Flow (@xyflow/react). Use when implementing auto-layout, hierarchical layouts, tree structures, or arranging nodes programmatically. Triggers on dagre, auto-layout, automatic layout, getLayoutedElements, rankdir, hierarchical graph.\n---\n\n# Dagre with React Flow\n\nDagre is a JavaScript library for laying out directed graphs. It computes optimal node positions for hierarchical/tree layouts. React Flow handles rendering; dagre handles positioning.\n\n## Quick Start\n\n```bash\npnpm add @dagrejs/dagre\n```\n\n```typescript\nimport dagre from '@dagrejs/dagre';\nimport { Node, Edge } from '@xyflow/react';\n\nconst getLayoutedElements = (\n  nodes: Node[],\n  edges: Edge[],\n  direction: 'TB' | 'LR' = 'TB'\n) => {\n  const g = new dagre.graphlib.Graph();\n  g.setGraph({ rankdir: direction });\n  g.setDefaultEdgeLabel(() => ({}));\n\n  nodes.forEach((node) => {\n    g.setNode(node.id, { width: 172, height: 36 });\n  });\n\n  edges.forEach((edge) => {\n    g.setEdge(edge.source, edge.target);\n  });\n\n  dagre.layout(g);\n\n  const layoutedNodes = nodes.map((node) => {\n    const pos = g.node(node.id);\n    return {\n      ...node,\n      position: { x: pos.x - 86, y: pos.y - 18 }, // Center to top-left\n    };\n  });\n\n  return { nodes: layoutedNodes, edges };\n};\n```\n\n## Core Concepts\n\n### Coordinate System Difference\n\n**Critical:** Dagre returns center coordinates; React Flow uses top-left.\n\n```typescript\n// Dagre output: center of node\nconst dagrePos = g.node(nodeId); // { x: 100, y: 50 } = center\n\n// React Flow expects: top-left corner\nconst rfPosition = {\n  x: dagrePos.x - nodeWidth / 2,\n  y: dagrePos.y - nodeHeight / 2,\n};\n```\n\n### Node Dimensions\n\nDagre requires explicit dimensions. Three approaches:\n\n**1. Fixed dimensions (simplest):**\n```typescript\ng.setNode(node.id, { width: 172, height: 36 });\n```\n\n**2. Per-node dimensions from data:**\n```typescript\ng.setNode(node.id, {\n  width: node.data.width ?? 172,\n  height: node.data.height ?? 36,\n});\n```\n\n**3. Measured dimensions (most accurate):**\n```typescript\n// After React Flow measures nodes\ng.setNode(node.id, {\n  width: node.measured?.width ?? 172,\n  height: node.measured?.height ?? 36,\n});\n```\n\n### Layout Directions\n\n| Value | Direction | Use Case |\n|-------|-----------|----------|\n| `TB` | Top to Bottom | Org charts, decision trees |\n| `BT` | Bottom to Top | Dependency graphs (deps at bottom) |\n| `LR` | Left to Right | Timelines, horizontal flows |\n| `RL` | Right to Left | RTL layouts |\n\n```typescript\ng.setGraph({ rankdir: 'LR' }); // Horizontal layout\n```\n\n## Complete Implementation\n\n### Basic Layout Function\n\n```typescript\nimport dagre from '@dagrejs/dagre';\nimport type { Node, Edge } from '@xyflow/react';\n\ninterface LayoutOptions {\n  direction?: 'TB' | 'BT' | 'LR' | 'RL';\n  nodeWidth?: number;\n  nodeHeight?: number;\n  nodesep?: number;  // Horizontal spacing\n  ranksep?: number;  // Vertical spacing (between ranks)\n}\n\nexport function getLayoutedElements(\n  nodes: Node[],\n  edges: Edge[],\n  options: LayoutOptions = {}\n): { nodes: Node[]; edges: Edge[] } {\n  const {\n    direction = 'TB',\n    nodeWidth = 172,\n    nodeHeight = 36,\n    nodesep = 50,\n    ranksep = 50,\n  } = options;\n\n  const g = new dagre.graphlib.Graph();\n  g.setGraph({ rankdir: direction, nodesep, ranksep });\n  g.setDefaultEdgeLabel(() => ({}));\n\n  nodes.forEach((node) => {\n    const width = node.measured?.width ?? nodeWidth;\n    const height = node.measured?.height ?? nodeHeight;\n    g.setNode(node.id, { width, height });\n  });\n\n  edges.forEach((edge) => {\n    g.setEdge(edge.source, edge.target);\n  });\n\n  dagre.layout(g);\n\n  const layoutedNodes = nodes.map((node) => {\n    const pos = g.node(node.id);\n    const width = node.measured?.width ?? nodeWidth;\n    const height = node.measured?.height ?? nodeHeight;\n\n    return {\n      ...node,\n      position: {\n        x: pos.x - width / 2,\n        y: pos.y - height / 2,\n      },\n    };\n  });\n\n  return { nodes: layoutedNodes, edges };\n}\n```\n\n### React Flow Integration\n\n```tsx\nimport { useCallback } from 'react';\nimport {\n  ReactFlow,\n  useNodesState,\n  useEdgesState,\n  useReactFlow,\n  ReactFlowProvider,\n} from '@xyflow/react';\nimport { getLayoutedElements } from './layout';\n\nconst initialNodes = [\n  { id: '1', data: { label: 'Start' }, position: { x: 0, y: 0 } },\n  { id: '2', data: { label: 'Process' }, position: { x: 0, y: 0 } },\n  { id: '3', data: { label: 'End' }, position: { x: 0, y: 0 } },\n];\n\nconst initialEdges = [\n  { id: 'e1-2', source: '1', target: '2' },\n  { id: 'e2-3', source: '2', target: '3' },\n];\n\n// Apply initial layout\nconst { nodes: layoutedNodes, edges: layoutedEdges } = getLayoutedElements(\n  initialNodes,\n  initialEdges,\n  { direction: 'TB' }\n);\n\nfunction Flow() {\n  const [nodes, setNodes, onNodesChange] = useNodesState(layoutedNodes);\n  const [edges, setEdges, onEdgesChange] = useEdgesState(layoutedEdges);\n  const { fitView } = useReactFlow();\n\n  const onLayout = useCallback((direction: 'TB' | 'LR') => {\n    const { nodes: newNodes, edges: newEdges } = getLayoutedElements(\n      nodes,\n      edges,\n      { direction }\n    );\n\n    setNodes([...newNodes]);\n    setEdges([...newEdges]);\n\n    // Fit view after layout with animation\n    window.requestAnimationFrame(() => {\n      fitView({ duration: 300 });\n    });\n  }, [nodes, edges, setNodes, setEdges, fitView]);\n\n  return (\n    <div style={{ width: '100%', height: '100vh' }}>\n      <div style={{ position: 'absolute', zIndex: 10, padding: 10 }}>\n        <button onClick={() => onLayout('TB')}>Vertical</button>\n        <button onClick={() => onLayout('LR')}>Horizontal</button>\n      </div>\n      <ReactFlow\n        nodes={nodes}\n        edges={edges}\n        onNodesChange={onNodesChange}\n        onEdgesChange={onEdgesChange}\n        fitView\n      />\n    </div>\n  );\n}\n\nexport default function App() {\n  return (\n    <ReactFlowProvider>\n      <Flow />\n    </ReactFlowProvider>\n  );\n}\n```\n\n## useAutoLayout Hook\n\nReusable hook for automatic layout:\n\n```typescript\nimport { useCallback, useEffect, useRef } from 'react';\nimport {\n  useReactFlow,\n  useNodesInitialized,\n  type Node,\n  type Edge,\n} from '@xyflow/react';\nimport dagre from '@dagrejs/dagre';\n\ninterface UseAutoLayoutOptions {\n  direction?: 'TB' | 'BT' | 'LR' | 'RL';\n  nodesep?: number;\n  ranksep?: number;\n}\n\nexport function useAutoLayout(options: UseAutoLayoutOptions = {}) {\n  const { direction = 'TB', nodesep = 50, ranksep = 50 } = options;\n  const { getNodes, getEdges, setNodes, fitView } = useReactFlow();\n  const nodesInitialized = useNodesInitialized();\n  const layoutApplied = useRef(false);\n\n  const runLayout = useCallback(() => {\n    const nodes = getNodes();\n    const edges = getEdges();\n\n    const g = new dagre.graphlib.Graph();\n    g.setGraph({ rankdir: direction, nodesep, ranksep });\n    g.setDefaultEdgeLabel(() => ({}));\n\n    nodes.forEach((node) => {\n      g.setNode(node.id, {\n        width: node.measured?.width ?? 172,\n        height: node.measured?.height ?? 36,\n      });\n    });\n\n    edges.forEach((edge) => {\n      g.setEdge(edge.source, edge.target);\n    });\n\n    dagre.layout(g);\n\n    const layouted = nodes.map((node) => {\n      const pos = g.node(node.id);\n      const width = node.measured?.width ?? 172;\n      const height = node.measured?.height ?? 36;\n\n      return {\n        ...node,\n        position: { x: pos.x - width / 2, y: pos.y - height / 2 },\n      };\n    });\n\n    setNodes(layouted);\n    window.requestAnimationFrame(() => fitView({ duration: 200 }));\n  }, [direction, nodesep, ranksep, getNodes, getEdges, setNodes, fitView]);\n\n  // Auto-layout on initialization\n  useEffect(() => {\n    if (nodesInitialized && !layoutApplied.current) {\n      runLayout();\n      layoutApplied.current = true;\n    }\n  }, [nodesInitialized, runLayout]);\n\n  return { runLayout };\n}\n```\n\nUsage:\n\n```tsx\nfunction Flow() {\n  const { runLayout } = useAutoLayout({ direction: 'LR', ranksep: 100 });\n\n  return (\n    <>\n      <button onClick={runLayout}>Re-layout</button>\n      <ReactFlow ... />\n    </>\n  );\n}\n```\n\n## Edge Options\n\nControl edge routing with weight and minlen:\n\n```typescript\nedges.forEach((edge) => {\n  g.setEdge(edge.source, edge.target, {\n    weight: edge.data?.priority ?? 1,  // Higher = more direct path\n    minlen: edge.data?.minRanks ?? 1,  // Minimum ranks between nodes\n  });\n});\n```\n\n**weight**: Higher weight edges are prioritized for shorter, more direct paths.\n\n**minlen**: Forces minimum rank separation between connected nodes.\n\n```typescript\n// Force 2 ranks between nodes\ng.setEdge('a', 'b', { minlen: 2 });\n```\n\n## Common Patterns\n\n### Handle Position Based on Direction\n\nAdjust handles for horizontal vs vertical layouts:\n\n```tsx\nfunction CustomNode({ data }: NodeProps) {\n  const isHorizontal = data.direction === 'LR' || data.direction === 'RL';\n\n  return (\n    <div>\n      <Handle\n        type=\"target\"\n        position={isHorizontal ? Position.Left : Position.Top}\n      />\n      <div>{data.label}</div>\n      <Handle\n        type=\"source\"\n        position={isHorizontal ? Position.Right : Position.Bottom}\n      />\n    </div>\n  );\n}\n```\n\n### Animated Layout Transitions\n\nSmooth position changes using CSS transitions:\n\n```css\n.react-flow__node {\n  transition: transform 300ms ease-out;\n}\n```\n\nFor programmatic animation, see [reference.md](reference.md#animated-layout-transitions).\n\n### Layout with Node Groups\n\nExclude group nodes from dagre layout:\n\n```typescript\nconst layoutWithGroups = (nodes: Node[], edges: Edge[]) => {\n  // Separate regular nodes from groups\n  const regularNodes = nodes.filter((n) => n.type !== 'group');\n  const groupNodes = nodes.filter((n) => n.type === 'group');\n\n  // Layout only regular nodes\n  const { nodes: layouted } = getLayoutedElements(regularNodes, edges);\n\n  // Combine back\n  return { nodes: [...groupNodes, ...layouted], edges };\n};\n```\n\n## Troubleshooting\n\n### Nodes Overlapping\n\nIncrease spacing:\n\n```typescript\ng.setGraph({\n  rankdir: 'TB',\n  nodesep: 100,  // Increase horizontal spacing\n  ranksep: 100,  // Increase vertical spacing\n});\n```\n\n### Layout Not Updating\n\nEnsure new array references:\n\n```typescript\n// Wrong - same reference\nsetNodes(layoutedNodes);\n\n// Correct - new reference\nsetNodes([...layoutedNodes]);\n```\n\n### Nodes at Wrong Position\n\nCheck coordinate conversion:\n\n```typescript\n// Dagre returns center, React Flow needs top-left\nposition: {\n  x: pos.x - width / 2,   // Not just pos.x\n  y: pos.y - height / 2,  // Not just pos.y\n}\n```\n\n### Performance with Large Graphs\n\n- Layout in a Web Worker\n- Debounce layout calls\n- Use `useMemo` for layout function\n- Only re-layout changed portions\n\n## Configuration Reference\n\nSee [reference.md](reference.md) for complete dagre configuration options.\n",
        "skills/dagre-react-flow/reference.md": "# Dagre Configuration Reference\n\nComplete configuration options for dagre layout algorithm.\n\n## Graph-Level Options\n\nSet via `g.setGraph(options)`:\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `rankdir` | `'TB'` | Layout direction: `'TB'` (top-bottom), `'BT'` (bottom-top), `'LR'` (left-right), `'RL'` (right-left) |\n| `align` | `undefined` | Node alignment within rank: `'UL'`, `'UR'`, `'DL'`, `'DR'`. `U`=up, `D`=down, `L`=left, `R`=right |\n| `nodesep` | `50` | Horizontal spacing between nodes in same rank (pixels) |\n| `edgesep` | `10` | Horizontal spacing between edges (pixels) |\n| `ranksep` | `50` | Vertical spacing between ranks (pixels) |\n| `marginx` | `0` | Horizontal margin around graph (pixels) |\n| `marginy` | `0` | Vertical margin around graph (pixels) |\n| `acyclicer` | `undefined` | Set to `'greedy'` for greedy cycle removal heuristic |\n| `ranker` | `'network-simplex'` | Rank assignment algorithm: `'network-simplex'`, `'tight-tree'`, `'longest-path'` |\n\n### Example\n\n```typescript\ng.setGraph({\n  rankdir: 'LR',          // Horizontal layout\n  align: 'UL',            // Align nodes to upper-left\n  nodesep: 80,            // 80px horizontal spacing\n  ranksep: 100,           // 100px between ranks\n  marginx: 20,            // 20px horizontal margin\n  marginy: 20,            // 20px vertical margin\n  ranker: 'tight-tree',   // Faster ranking algorithm\n});\n```\n\n### Ranker Algorithms\n\n| Algorithm | Speed | Quality | Use Case |\n|-----------|-------|---------|----------|\n| `network-simplex` | Slower | Best | Default, optimal for most graphs |\n| `tight-tree` | Fast | Good | Large graphs where speed matters |\n| `longest-path` | Fastest | Acceptable | Very large graphs, quick preview |\n\n## Node-Level Options\n\nSet via `g.setNode(nodeId, options)`:\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `width` | `0` | Node width in pixels (required for layout) |\n| `height` | `0` | Node height in pixels (required for layout) |\n\n### Output Properties\n\nAfter `dagre.layout(g)`, each node gains:\n\n| Property | Description |\n|----------|-------------|\n| `x` | Center x-coordinate |\n| `y` | Center y-coordinate |\n\n### Example\n\n```typescript\n// Setting node dimensions\ng.setNode('node-1', { width: 200, height: 50 });\n\n// After layout, reading position\ndagre.layout(g);\nconst { x, y } = g.node('node-1'); // Center coordinates\n```\n\n## Edge-Level Options\n\nSet via `g.setEdge(source, target, options)`:\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `minlen` | `1` | Minimum number of ranks between source and target |\n| `weight` | `1` | Edge weight for prioritization (higher = shorter path) |\n| `width` | `0` | Edge label width in pixels |\n| `height` | `0` | Edge label height in pixels |\n| `labelpos` | `'r'` | Label position: `'l'` (left), `'c'` (center), `'r'` (right) |\n| `labeloffset` | `10` | Pixels to offset label from edge |\n\n### Output Properties\n\nAfter `dagre.layout(g)`, each edge gains:\n\n| Property | Description |\n|----------|-------------|\n| `points` | Array of `{x, y}` control points for edge path |\n| `x` | Label center x-coordinate (if label dimensions set) |\n| `y` | Label center y-coordinate (if label dimensions set) |\n\n### Example\n\n```typescript\n// High priority edge (shorter path)\ng.setEdge('a', 'b', { weight: 2 });\n\n// Force separation of 3 ranks\ng.setEdge('a', 'c', { minlen: 3 });\n\n// Edge with label\ng.setEdge('a', 'd', {\n  width: 50,\n  height: 20,\n  labelpos: 'c',\n});\n\n// After layout\ndagre.layout(g);\nconst edge = g.edge('a', 'b');\nconsole.log(edge.points); // [{x: 0, y: 0}, {x: 50, y: 50}, ...]\n```\n\n## Graph Methods\n\n### Reading Graph State\n\n```typescript\n// Get all node IDs\nconst nodeIds = g.nodes(); // ['a', 'b', 'c']\n\n// Get all edges\nconst edges = g.edges(); // [{v: 'a', w: 'b'}, ...]\n\n// Check if node exists\ng.hasNode('a'); // true/false\n\n// Check if edge exists\ng.hasEdge('a', 'b'); // true/false\n\n// Get node data\ng.node('a'); // { width: 100, height: 50, x: 200, y: 100 }\n\n// Get edge data\ng.edge('a', 'b'); // { points: [...], weight: 1 }\n```\n\n### Modifying Graph\n\n```typescript\n// Remove node (also removes connected edges)\ng.removeNode('a');\n\n// Remove edge\ng.removeEdge('a', 'b');\n\n// Get predecessors (nodes with edges TO this node)\ng.predecessors('b'); // ['a']\n\n// Get successors (nodes with edges FROM this node)\ng.successors('a'); // ['b', 'c']\n\n// Get all connected nodes (in + out)\ng.neighbors('a'); // ['b', 'c', 'd']\n```\n\n## TypeScript Types\n\n```typescript\nimport dagre from '@dagrejs/dagre';\n\ninterface GraphOptions {\n  rankdir?: 'TB' | 'BT' | 'LR' | 'RL';\n  align?: 'UL' | 'UR' | 'DL' | 'DR';\n  nodesep?: number;\n  edgesep?: number;\n  ranksep?: number;\n  marginx?: number;\n  marginy?: number;\n  acyclicer?: 'greedy';\n  ranker?: 'network-simplex' | 'tight-tree' | 'longest-path';\n}\n\ninterface NodeOptions {\n  width: number;\n  height: number;\n}\n\ninterface NodeOutput extends NodeOptions {\n  x: number;\n  y: number;\n}\n\ninterface EdgeOptions {\n  minlen?: number;\n  weight?: number;\n  width?: number;\n  height?: number;\n  labelpos?: 'l' | 'c' | 'r';\n  labeloffset?: number;\n}\n\ninterface EdgeOutput extends EdgeOptions {\n  points: Array<{ x: number; y: number }>;\n  x?: number;  // If label dimensions set\n  y?: number;  // If label dimensions set\n}\n```\n\n## Performance Considerations\n\n### Graph Size Guidelines\n\n| Nodes | Performance | Recommendation |\n|-------|-------------|----------------|\n| < 100 | Fast | Use `network-simplex` |\n| 100-500 | Moderate | Consider `tight-tree` |\n| 500-1000 | Slow | Use `longest-path`, layout in worker |\n| > 1000 | Very slow | Virtualize, paginate, or use WebGL renderer |\n\n### Optimization Tips\n\n1. **Reuse graph instance** when only positions change\n2. **Layout in Web Worker** for graphs > 200 nodes\n3. **Debounce layout calls** during rapid changes\n4. **Cache layout results** for static portions\n\n### Web Worker Example\n\n```typescript\n// layout.worker.ts\nimport dagre from '@dagrejs/dagre';\n\nself.onmessage = (e) => {\n  const { nodes, edges, options } = e.data;\n\n  const g = new dagre.graphlib.Graph();\n  g.setGraph(options);\n  g.setDefaultEdgeLabel(() => ({}));\n\n  nodes.forEach((n) => g.setNode(n.id, { width: n.width, height: n.height }));\n  edges.forEach((e) => g.setEdge(e.source, e.target));\n\n  dagre.layout(g);\n\n  const positions = nodes.map((n) => ({\n    id: n.id,\n    x: g.node(n.id).x,\n    y: g.node(n.id).y,\n  }));\n\n  self.postMessage({ positions });\n};\n```\n\n## Comparison with Alternatives\n\n| Library | Best For | Bundle Size | Async |\n|---------|----------|-------------|-------|\n| **dagre** | Trees, hierarchies | ~30KB | No |\n| **elkjs** | Complex constraints | ~150KB | Yes |\n| **d3-hierarchy** | Pure trees only | ~10KB | No |\n| **d3-force** | Organic layouts | ~15KB | Iterative |\n\nChoose dagre when:\n- Graph is hierarchical/tree-like\n- Need simple, fast layouts\n- Bundle size matters\n- Don't need edge routing around nodes\n\n## Animated Layout Transitions\n\nProgrammatic animation for smooth position changes:\n\n```typescript\nconst animateLayout = (\n  currentNodes: Node[],\n  newNodes: Node[],\n  setNodes: (nodes: Node[]) => void,\n  duration = 300\n) => {\n  const startPositions = new Map(\n    currentNodes.map((n) => [n.id, { ...n.position }])\n  );\n\n  const animate = (progress: number) => {\n    const interpolated = newNodes.map((node) => {\n      const start = startPositions.get(node.id);\n      if (!start) return node;\n\n      return {\n        ...node,\n        position: {\n          x: start.x + (node.position.x - start.x) * progress,\n          y: start.y + (node.position.y - start.y) * progress,\n        },\n      };\n    });\n    setNodes(interpolated);\n  };\n\n  const startTime = Date.now();\n  const tick = () => {\n    const elapsed = Date.now() - startTime;\n    const progress = Math.min(elapsed / duration, 1);\n    // Ease-out curve\n    const eased = 1 - Math.pow(1 - progress, 3);\n    animate(eased);\n    if (progress < 1) requestAnimationFrame(tick);\n  };\n  tick();\n};\n\n// Usage\nconst onLayout = (direction: 'TB' | 'LR') => {\n  const { nodes: layouted } = getLayoutedElements(nodes, edges, { direction });\n  animateLayout(nodes, layouted, setNodes, 400);\n};\n```\n",
        "skills/deepagents-architecture/SKILL.md": "---\nname: deepagents-architecture\ndescription: Guides architectural decisions for Deep Agents applications. Use when deciding between Deep Agents vs alternatives, choosing backend strategies, designing subagent systems, or selecting middleware approaches.\n---\n\n# Deep Agents Architecture Decisions\n\n## When to Use Deep Agents\n\n### Use Deep Agents When You Need:\n\n- **Long-horizon tasks** - Complex workflows spanning dozens of tool calls\n- **Planning capabilities** - Task decomposition before execution\n- **Filesystem operations** - Reading, writing, and editing files\n- **Subagent delegation** - Isolated task execution with separate context windows\n- **Persistent memory** - Long-term storage across conversations\n- **Human-in-the-loop** - Approval gates for sensitive operations\n- **Context management** - Auto-summarization for long conversations\n\n### Consider Alternatives When:\n\n| Scenario | Alternative | Why |\n|----------|-------------|-----|\n| Single LLM call | Direct API call | Deep Agents overhead not justified |\n| Simple RAG pipeline | LangChain LCEL | Simpler abstraction |\n| Custom graph control flow | LangGraph directly | More flexibility |\n| No file operations needed | `create_react_agent` | Lighter weight |\n| Stateless tool use | Function calling | No middleware needed |\n\n## Backend Selection\n\n### Backend Comparison\n\n| Backend | Persistence | Use Case | Requires |\n|---------|-------------|----------|----------|\n| `StateBackend` | Ephemeral (per-thread) | Working files, temp data | Nothing (default) |\n| `FilesystemBackend` | Disk | Local development, real files | `root_dir` path |\n| `StoreBackend` | Cross-thread | User preferences, knowledge bases | LangGraph `store` |\n| `CompositeBackend` | Mixed | Hybrid memory patterns | Multiple backends |\n\n### Backend Decision Tree\n\n```\nNeed real disk access?\n Yes  FilesystemBackend(root_dir=\"/path\")\n No\n    Need persistence across conversations?\n       Yes  Need mixed ephemeral + persistent?\n         Yes  CompositeBackend\n         No  StoreBackend\n       No  StateBackend (default)\n```\n\n### CompositeBackend Routing\n\nRoute different paths to different storage backends:\n\n```python\nfrom deepagents import create_deep_agent\nfrom deepagents.backends import CompositeBackend, StateBackend, StoreBackend\n\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),  # Working files (ephemeral)\n        routes={\n            \"/memories/\": StoreBackend(store=store),    # Persistent\n            \"/preferences/\": StoreBackend(store=store), # Persistent\n        },\n    ),\n)\n```\n\n## Subagent Architecture\n\n### When to Use Subagents\n\n**Use subagents when:**\n- Task is complex, multi-step, and can run independently\n- Task requires heavy context that would bloat the main thread\n- Multiple independent tasks can run in parallel\n- You need isolated execution (sandboxing)\n- You only care about the final result, not intermediate steps\n\n**Don't use subagents when:**\n- Task is trivial (few tool calls)\n- You need to see intermediate reasoning\n- Splitting adds latency without benefit\n- Task depends on main thread state mid-execution\n\n### Subagent Patterns\n\n#### Pattern 1: Parallel Research\n```\n         \n           Orchestrator\n         \n    \n                        \n    \nTask A  Task B  Task C\n    \n   \n              \n      \n        Synthesize \n      \n```\n\nBest for: Research on multiple topics, parallel analysis, batch processing.\n\n#### Pattern 2: Specialized Agents\n```python\nresearch_agent = {\n    \"name\": \"researcher\",\n    \"description\": \"Deep research on complex topics\",\n    \"system_prompt\": \"You are an expert researcher...\",\n    \"tools\": [web_search, document_reader],\n}\n\ncoder_agent = {\n    \"name\": \"coder\",\n    \"description\": \"Write and review code\",\n    \"system_prompt\": \"You are an expert programmer...\",\n    \"tools\": [code_executor, linter],\n}\n\nagent = create_deep_agent(subagents=[research_agent, coder_agent])\n```\n\nBest for: Domain-specific expertise, different tool sets per task type.\n\n#### Pattern 3: Pre-compiled Subagents\n```python\nfrom deepagents import CompiledSubAgent, create_deep_agent\n\n# Use existing LangGraph graph as subagent\ncustom_graph = create_react_agent(model=..., tools=...)\n\nagent = create_deep_agent(\n    subagents=[CompiledSubAgent(\n        name=\"custom-workflow\",\n        description=\"Runs specialized workflow\",\n        runnable=custom_graph\n    )]\n)\n```\n\nBest for: Reusing existing LangGraph graphs, complex custom workflows.\n\n## Middleware Architecture\n\n### Built-in Middleware Stack\n\nDeep Agents applies middleware in this order:\n\n1. **TodoListMiddleware** - Task planning with `write_todos`/`read_todos`\n2. **FilesystemMiddleware** - File ops: `ls`, `read_file`, `write_file`, `edit_file`, `glob`, `grep`, `execute`\n3. **SubAgentMiddleware** - Delegation via `task` tool\n4. **SummarizationMiddleware** - Auto-summarizes at ~85% context or 170k tokens\n5. **AnthropicPromptCachingMiddleware** - Caches system prompts (Anthropic only)\n6. **PatchToolCallsMiddleware** - Fixes dangling tool calls from interruptions\n7. **HumanInTheLoopMiddleware** - Pauses for approval (if `interrupt_on` configured)\n\n### Custom Middleware Placement\n\n```python\nfrom langchain.agents.middleware import AgentMiddleware\n\nclass MyMiddleware(AgentMiddleware):\n    tools = [my_custom_tool]\n\n    def transform_request(self, request):\n        # Modify system prompt, inject context\n        return request\n\n    def transform_response(self, response):\n        # Post-process, log, filter\n        return response\n\n# Custom middleware added AFTER built-in stack\nagent = create_deep_agent(middleware=[MyMiddleware()])\n```\n\n### Middleware vs Tools Decision\n\n| Need | Use Middleware | Use Tools |\n|------|----------------|-----------|\n| Inject system prompt content |  |  |\n| Add tools dynamically |  |  |\n| Transform requests/responses |  |  |\n| Standalone capability |  |  |\n| User-invokable action |  |  |\n\n### Subagent Middleware Inheritance\n\nSubagents receive their own middleware stack by default:\n- TodoListMiddleware\n- FilesystemMiddleware (shared backend)\n- SummarizationMiddleware\n- AnthropicPromptCachingMiddleware\n- PatchToolCallsMiddleware\n\nOverride with `default_middleware=[]` in SubAgentMiddleware or per-subagent `middleware` key.\n\n## Architecture Decision Checklist\n\nBefore implementing:\n\n1. [ ] Is Deep Agents the right tool? (vs LangGraph directly, vs simpler agent)\n2. [ ] Backend strategy chosen?\n   - [ ] Ephemeral only  StateBackend (default)\n   - [ ] Need disk access  FilesystemBackend\n   - [ ] Need cross-thread persistence  StoreBackend or CompositeBackend\n3. [ ] Subagent strategy defined?\n   - [ ] Which tasks benefit from isolation?\n   - [ ] Custom subagents with specialized tools/prompts?\n   - [ ] Parallel execution opportunities identified?\n4. [ ] Human-in-the-loop points defined?\n   - [ ] Which tools need approval?\n   - [ ] Approval flow (approve/edit/reject)?\n5. [ ] Custom middleware needed?\n   - [ ] System prompt injection?\n   - [ ] Request/response transformation?\n6. [ ] Context management considered?\n   - [ ] Long conversations  summarization triggers\n   - [ ] Large file handling  use references\n7. [ ] Checkpointing strategy? (for persistence/resume)\n",
        "skills/deepagents-code-review/SKILL.md": "---\nname: deepagents-code-review\ndescription: Reviews Deep Agents code for bugs, anti-patterns, and improvements. Use when reviewing code that uses create_deep_agent, backends, subagents, middleware, or human-in-the-loop patterns. Catches common configuration and usage mistakes.\n---\n\n# Deep Agents Code Review\n\nWhen reviewing Deep Agents code, check for these categories of issues.\n\n## Critical Issues\n\n### 1. Missing Checkpointer with interrupt_on\n\n```python\n# BAD - interrupt_on without checkpointer\nagent = create_deep_agent(\n    tools=[send_email],\n    interrupt_on={\"send_email\": True},\n    # No checkpointer! Interrupts will fail\n)\n\n# GOOD - checkpointer required for interrupts\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nagent = create_deep_agent(\n    tools=[send_email],\n    interrupt_on={\"send_email\": True},\n    checkpointer=InMemorySaver(),\n)\n```\n\n### 2. Missing Store with StoreBackend\n\n```python\n# BAD - StoreBackend without store\nfrom deepagents.backends import StoreBackend\n\nagent = create_deep_agent(\n    backend=lambda rt: StoreBackend(rt),\n    # No store! Will raise ValueError at runtime\n)\n\n# GOOD - provide store\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\nagent = create_deep_agent(\n    backend=lambda rt: StoreBackend(rt),\n    store=store,\n)\n```\n\n### 3. Missing thread_id with Checkpointer\n\n```python\n# BAD - no thread_id when using checkpointer\nagent = create_deep_agent(checkpointer=InMemorySaver())\nagent.invoke({\"messages\": [...]})  # Error!\n\n# GOOD - always provide thread_id\nconfig = {\"configurable\": {\"thread_id\": \"user-123\"}}\nagent.invoke({\"messages\": [...]}, config)\n```\n\n### 4. Relative Paths in Filesystem Tools\n\n```python\n# BAD - relative paths not supported\nread_file(path=\"src/main.py\")\nread_file(path=\"./config.json\")\n\n# GOOD - absolute paths required\nread_file(path=\"/workspace/src/main.py\")\nread_file(path=\"/config.json\")\n```\n\n### 5. Windows Paths in Virtual Filesystem\n\n```python\n# BAD - Windows paths rejected\nread_file(path=\"C:\\\\Users\\\\file.txt\")\nwrite_file(path=\"D:/projects/code.py\", content=\"...\")\n\n# GOOD - Unix-style virtual paths\nread_file(path=\"/workspace/file.txt\")\nwrite_file(path=\"/projects/code.py\", content=\"...\")\n```\n\n## Backend Issues\n\n### 6. StateBackend Expecting Persistence\n\n```python\n# BAD - expecting files to persist across threads\nagent = create_deep_agent()  # Uses StateBackend by default\n\n# Thread 1\nagent.invoke({\"messages\": [...]}, {\"configurable\": {\"thread_id\": \"a\"}})\n# Agent writes to /data/report.txt\n\n# Thread 2 - file won't exist!\nagent.invoke({\"messages\": [...]}, {\"configurable\": {\"thread_id\": \"b\"}})\n# Agent tries to read /data/report.txt - NOT FOUND\n\n# GOOD - use StoreBackend or CompositeBackend for cross-thread persistence\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),\n        routes={\"/data/\": StoreBackend(store=store)},\n    ),\n    store=store,\n)\n```\n\n### 7. FilesystemBackend Without root_dir Restriction\n\n```python\n# BAD - unrestricted filesystem access\nagent = create_deep_agent(\n    backend=FilesystemBackend(root_dir=\"/\"),  # Full system access!\n)\n\n# GOOD - scope to project directory\nagent = create_deep_agent(\n    backend=FilesystemBackend(root_dir=\"/home/user/project\"),\n)\n```\n\n### 8. CompositeBackend Route Order Confusion\n\n```python\n# BAD - shorter prefix shadows longer prefix\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),\n        routes={\n            \"/mem/\": backend_a,        # This catches /mem/long-term/ too!\n            \"/mem/long-term/\": backend_b,  # Never reached\n        },\n    ),\n)\n\n# GOOD - CompositeBackend sorts by length automatically\n# But be explicit about your intent:\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),\n        routes={\n            \"/memories/\": persistent_backend,\n            \"/workspace/\": ephemeral_backend,\n        },\n    ),\n)\n```\n\n### 9. Expecting execute Tool Without SandboxBackend\n\n```python\n# BAD - execute tool won't work with StateBackend\nagent = create_deep_agent()  # Default StateBackend\n# Agent calls execute(\"ls -la\")  Error: not supported\n\n# GOOD - use FilesystemBackend for shell execution\nagent = create_deep_agent(\n    backend=FilesystemBackend(root_dir=\"/project\"),\n)\n# Agent calls execute(\"ls -la\")  Works\n```\n\n## Subagent Issues\n\n### 10. Subagent Missing Required Fields\n\n```python\n# BAD - missing required fields\nagent = create_deep_agent(\n    subagents=[{\n        \"name\": \"helper\",\n        # Missing: description, system_prompt, tools\n    }]\n)\n\n# GOOD - all required fields present\nagent = create_deep_agent(\n    subagents=[{\n        \"name\": \"helper\",\n        \"description\": \"General helper for misc tasks\",\n        \"system_prompt\": \"You are a helpful assistant.\",\n        \"tools\": [],  # Can be empty but must be present\n    }]\n)\n```\n\n### 11. Subagent Name Collision\n\n```python\n# BAD - duplicate subagent names\nagent = create_deep_agent(\n    subagents=[\n        {\"name\": \"research\", \"description\": \"A\", ...},\n        {\"name\": \"research\", \"description\": \"B\", ...},  # Collision!\n    ]\n)\n\n# GOOD - unique names\nagent = create_deep_agent(\n    subagents=[\n        {\"name\": \"web-research\", \"description\": \"Web-based research\", ...},\n        {\"name\": \"doc-research\", \"description\": \"Document research\", ...},\n    ]\n)\n```\n\n### 12. Overusing Subagents for Simple Tasks\n\n```python\n# BAD - subagent overhead for trivial task\n# In system prompt or agent behavior:\n\"Use the task tool to check the current time\"\n\"Delegate file reading to a subagent\"\n\n# GOOD - use subagents for complex, isolated work\n\"Use the task tool for multi-step research that requires many searches\"\n\"Delegate the full analysis workflow to a subagent\"\n```\n\n### 13. CompiledSubAgent Without Proper State\n\n```python\n# BAD - subgraph with incompatible state schema\nfrom langgraph.graph import StateGraph\n\nclass CustomState(TypedDict):\n    custom_field: str  # No messages field!\n\nsub_builder = StateGraph(CustomState)\n# ... build graph\nsubgraph = sub_builder.compile()\n\nagent = create_deep_agent(\n    subagents=[CompiledSubAgent(\n        name=\"custom\",\n        description=\"Custom workflow\",\n        runnable=subgraph,  # State mismatch!\n    )]\n)\n\n# GOOD - ensure compatible state or use message-based interface\nclass CompatibleState(TypedDict):\n    messages: Annotated[list, add_messages]\n    custom_field: str\n```\n\n## Middleware Issues\n\n### 14. Middleware Order Misunderstanding\n\n```python\n# BAD - expecting custom middleware to run first\nclass PreProcessMiddleware(AgentMiddleware):\n    def transform_request(self, request):\n        # Expecting this runs before built-in middleware\n        return request\n\nagent = create_deep_agent(middleware=[PreProcessMiddleware()])\n# Actually runs AFTER TodoList, Filesystem, SubAgent, etc.\n\n# GOOD - understand middleware runs after built-in stack\n# Built-in order:\n# 1. TodoListMiddleware\n# 2. FilesystemMiddleware\n# 3. SubAgentMiddleware\n# 4. SummarizationMiddleware\n# 5. AnthropicPromptCachingMiddleware\n# 6. PatchToolCallsMiddleware\n# 7. YOUR MIDDLEWARE HERE\n# 8. HumanInTheLoopMiddleware (if interrupt_on set)\n```\n\n### 15. Middleware Mutating Request/Response\n\n```python\n# BAD - mutating instead of returning new object\nclass BadMiddleware(AgentMiddleware):\n    def transform_request(self, request):\n        request.messages.append(extra_message)  # Mutation!\n        return request\n\n# GOOD - return modified copy\nclass GoodMiddleware(AgentMiddleware):\n    def transform_request(self, request):\n        return ModelRequest(\n            messages=[*request.messages, extra_message],\n            **other_fields\n        )\n```\n\n### 16. Middleware Tools Without Descriptions\n\n```python\n# BAD - tool without docstring\n@tool\ndef my_tool(arg: str) -> str:\n    return process(arg)\n\nclass MyMiddleware(AgentMiddleware):\n    tools = [my_tool]  # LLM won't know how to use it!\n\n# GOOD - descriptive docstring\n@tool\ndef my_tool(arg: str) -> str:\n    \"\"\"Process the input string and return formatted result.\n\n    Args:\n        arg: The string to process\n\n    Returns:\n        Formatted result string\n    \"\"\"\n    return process(arg)\n```\n\n## System Prompt Issues\n\n### 17. Duplicating Built-in Tool Instructions\n\n```python\n# BAD - re-explaining what middleware already covers\nagent = create_deep_agent(\n    system_prompt=\"\"\"You have access to these tools:\n    - write_todos: Create task lists\n    - read_file: Read files from the filesystem\n    - task: Delegate to subagents\n\n    When using files, always use absolute paths...\"\"\"\n)\n# This duplicates what FilesystemMiddleware and TodoListMiddleware inject!\n\n# GOOD - focus on domain-specific guidance\nagent = create_deep_agent(\n    system_prompt=\"\"\"You are a code review assistant.\n\n    Workflow:\n    1. Read the files to review\n    2. Create a todo list of issues found\n    3. Delegate deep analysis to subagents if needed\n    4. Compile findings into a report\"\"\"\n)\n```\n\n### 18. Contradicting Built-in Instructions\n\n```python\n# BAD - contradicting default behavior\nagent = create_deep_agent(\n    system_prompt=\"\"\"Never use the task tool.\n    Always process everything in the main thread.\n    Don't use todos, just remember everything.\"\"\"\n)\n# Fighting against the framework!\n\n# GOOD - work with the framework\nagent = create_deep_agent(\n    system_prompt=\"\"\"For simple tasks, handle directly.\n    For complex multi-step research, use subagents.\n    Track progress with todos for tasks with 3+ steps.\"\"\"\n)\n```\n\n### 19. Missing Stopping Criteria\n\n```python\n# BAD - no guidance on when to stop\nagent = create_deep_agent(\n    system_prompt=\"Research everything about the topic thoroughly.\"\n)\n# Agent may run indefinitely!\n\n# GOOD - define completion criteria\nagent = create_deep_agent(\n    system_prompt=\"\"\"Research the topic with these constraints:\n    - Maximum 5 web searches\n    - Stop when you have 3 reliable sources\n    - Limit subagent delegations to 2 parallel tasks\n    - Summarize findings within 500 words\"\"\"\n)\n```\n\n## Performance Issues\n\n### 20. Not Parallelizing Independent Subagents\n\n```python\n# BAD - sequential subagent calls (in agent behavior)\n# Agent calls: task(research topic A)  wait  task(research topic B)  wait\n\n# GOOD - parallel subagent calls\n# Agent calls in single turn:\n#   task(research topic A)\n#   task(research topic B)\n#   task(research topic C)\n# All run concurrently!\n\n# Guide via system prompt:\nagent = create_deep_agent(\n    system_prompt=\"\"\"When researching multiple topics,\n    launch all research subagents in parallel in a single response.\"\"\"\n)\n```\n\n### 21. Large Files in State\n\n```python\n# BAD - writing large files to StateBackend\n# Agent writes 10MB log file to /output/full_log.txt\n# This bloats every checkpoint!\n\n# GOOD - use FilesystemBackend for large files or paginate\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),  # Small files\n        routes={\n            \"/large_files/\": FilesystemBackend(root_dir=\"/tmp/agent\"),\n        },\n    ),\n)\n```\n\n### 22. InMemorySaver in Production\n\n```python\n# BAD - ephemeral checkpointer in production\nagent = create_deep_agent(\n    checkpointer=InMemorySaver(),  # Lost on restart!\n)\n\n# GOOD - persistent checkpointer\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\nagent = create_deep_agent(\n    checkpointer=PostgresSaver.from_conn_string(DATABASE_URL),\n)\n```\n\n### 23. Missing Recursion Awareness\n\n```python\n# BAD - no guard against long-running loops\nagent = create_deep_agent(\n    system_prompt=\"Keep improving the solution until it's perfect.\"\n)\n# May hit recursion limit (default 1000)\n\n# GOOD - explicit iteration limits\nagent = create_deep_agent(\n    system_prompt=\"\"\"Improve the solution iteratively:\n    - Maximum 3 revision cycles\n    - Stop if quality score > 90%\n    - Stop if no improvement after 2 iterations\"\"\"\n)\n```\n\n## Code Review Checklist\n\n### Configuration\n- [ ] Checkpointer provided if using `interrupt_on`\n- [ ] Store provided if using `StoreBackend`\n- [ ] Thread ID provided in config when using checkpointer\n- [ ] Backend appropriate for use case (ephemeral vs persistent)\n\n### Backends\n- [ ] FilesystemBackend scoped to safe `root_dir`\n- [ ] StoreBackend has corresponding `store` parameter\n- [ ] CompositeBackend routes don't shadow each other unintentionally\n- [ ] Not expecting persistence from StateBackend across threads\n\n### Subagents\n- [ ] All required fields present (name, description, system_prompt, tools)\n- [ ] Unique subagent names\n- [ ] CompiledSubAgent has compatible state schema\n- [ ] Subagents used for complex tasks, not trivial operations\n\n### Middleware\n- [ ] Custom middleware added after built-in stack (expected behavior)\n- [ ] Tools have descriptive docstrings\n- [ ] Not mutating request/response objects\n\n### System Prompt\n- [ ] Not duplicating built-in tool instructions\n- [ ] Not contradicting framework defaults\n- [ ] Stopping criteria defined for open-ended tasks\n- [ ] Parallelization guidance for independent tasks\n\n### Performance\n- [ ] Large files routed to appropriate backend\n- [ ] Production uses persistent checkpointer\n- [ ] Recursion/iteration limits considered\n- [ ] Independent subagents parallelized\n",
        "skills/deepagents-implementation/SKILL.md": "---\nname: deepagents-implementation\ndescription: Implements agents using Deep Agents. Use when building agents with create_deep_agent, configuring backends, defining subagents, adding middleware, or setting up human-in-the-loop workflows.\n---\n\n# Deep Agents Implementation\n\n## Core Concepts\n\nDeep Agents provides a batteries-included agent harness built on LangGraph:\n\n- **`create_deep_agent`**: Factory function that creates a configured agent\n- **Middleware**: Injected capabilities (filesystem, todos, subagents, summarization)\n- **Backends**: Pluggable file storage (state, filesystem, store, composite)\n- **Subagents**: Isolated task execution via the `task` tool\n\nThe agent returned is a compiled LangGraph `StateGraph`, compatible with streaming, checkpointing, and LangGraph Studio.\n\n## Essential Imports\n\n```python\n# Core\nfrom deepagents import create_deep_agent\n\n# Subagents\nfrom deepagents import CompiledSubAgent\n\n# Backends\nfrom deepagents.backends import (\n    StateBackend,       # Ephemeral (default)\n    FilesystemBackend,  # Real disk\n    StoreBackend,       # Persistent cross-thread\n    CompositeBackend,   # Route paths to backends\n)\n\n# LangGraph (for checkpointing, store, streaming)\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.checkpoint.postgres import PostgresSaver\nfrom langgraph.store.memory import InMemoryStore\n\n# LangChain (for custom models, tools)\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.tools import tool\n```\n\n## Basic Usage\n\n### Minimal Agent\n\n```python\nfrom deepagents import create_deep_agent\n\n# Uses Claude Sonnet 4 by default\nagent = create_deep_agent()\n\nresult = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n```\n\n### With Custom Tools\n\n```python\nfrom langchain_core.tools import tool\nfrom deepagents import create_deep_agent\n\n@tool\ndef web_search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return tavily_client.search(query)\n\nagent = create_deep_agent(\n    tools=[web_search],\n    system_prompt=\"You are a research assistant. Search the web to answer questions.\",\n)\n\nresult = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is LangGraph?\"}]})\n```\n\n### With Custom Model\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom deepagents import create_deep_agent\n\n# OpenAI\nmodel = init_chat_model(\"openai:gpt-4o\")\n\n# Or Anthropic with custom settings\nfrom langchain_anthropic import ChatAnthropic\nmodel = ChatAnthropic(model_name=\"claude-sonnet-4-5-20250929\", max_tokens=8192)\n\nagent = create_deep_agent(model=model)\n```\n\n### With Checkpointing (Persistence)\n\n```python\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom deepagents import create_deep_agent\n\nagent = create_deep_agent(checkpointer=InMemorySaver())\n\n# Must provide thread_id with checkpointer\nconfig = {\"configurable\": {\"thread_id\": \"user-123\"}}\nresult = agent.invoke({\"messages\": [...]}, config)\n\n# Resume conversation\nresult = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Follow up\"}]}, config)\n```\n\n## Streaming\n\nThe agent supports all LangGraph stream modes.\n\n### Stream Updates\n\n```python\nfor chunk in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Write a report\"}]},\n    stream_mode=\"updates\"\n):\n    print(chunk)  # {\"node_name\": {\"key\": \"value\"}}\n```\n\n### Stream Messages (Token-by-Token)\n\n```python\nfor chunk in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain quantum computing\"}]},\n    stream_mode=\"messages\"\n):\n    # Real-time token streaming\n    print(chunk.content, end=\"\", flush=True)\n```\n\n### Async Streaming\n\n```python\nasync for chunk in agent.astream(\n    {\"messages\": [...]},\n    stream_mode=\"updates\"\n):\n    print(chunk)\n```\n\n### Multiple Stream Modes\n\n```python\nfor mode, chunk in agent.stream(\n    {\"messages\": [...]},\n    stream_mode=[\"updates\", \"messages\"]\n):\n    if mode == \"messages\":\n        print(\"Token:\", chunk.content)\n    else:\n        print(\"Update:\", chunk)\n```\n\n## Backend Configuration\n\n### StateBackend (Default - Ephemeral)\n\nFiles stored in agent state, persist within thread only.\n\n```python\n# Implicit - this is the default\nagent = create_deep_agent()\n\n# Explicit\nfrom deepagents.backends import StateBackend\nagent = create_deep_agent(backend=lambda rt: StateBackend(rt))\n```\n\n### FilesystemBackend (Real Disk)\n\nRead/write actual files on disk. Enables `execute` tool for shell commands.\n\n```python\nfrom deepagents.backends import FilesystemBackend\n\nagent = create_deep_agent(\n    backend=FilesystemBackend(root_dir=\"/path/to/project\"),\n)\n```\n\n### StoreBackend (Persistent Cross-Thread)\n\nUses LangGraph Store for persistence across conversations.\n\n```python\nfrom langgraph.store.memory import InMemoryStore\nfrom deepagents.backends import StoreBackend\n\nstore = InMemoryStore()\n\nagent = create_deep_agent(\n    backend=lambda rt: StoreBackend(rt),\n    store=store,  # Required for StoreBackend\n)\n```\n\n### CompositeBackend (Hybrid Routing)\n\nRoute different paths to different backends.\n\n```python\nfrom langgraph.store.memory import InMemoryStore\nfrom deepagents.backends import CompositeBackend, StateBackend, StoreBackend\n\nstore = InMemoryStore()\n\nagent = create_deep_agent(\n    backend=CompositeBackend(\n        default=StateBackend(),           # /workspace/*  ephemeral\n        routes={\n            \"/memories/\": StoreBackend(store=store),     # persistent\n            \"/preferences/\": StoreBackend(store=store), # persistent\n        },\n    ),\n    store=store,\n)\n\n# Files under /memories/ persist across all conversations\n# Files under /workspace/ are ephemeral per-thread\n```\n\n## Subagents\n\n### Using the Default General-Purpose Agent\n\nBy default, a `general-purpose` subagent is available with all main agent tools.\n\n```python\nagent = create_deep_agent(tools=[web_search])\n\n# The agent can now delegate via the `task` tool:\n# task(subagent_type=\"general-purpose\", prompt=\"Research topic X in depth\")\n```\n\n### Defining Custom Subagents\n\n```python\nfrom deepagents import create_deep_agent\n\nresearch_agent = {\n    \"name\": \"researcher\",\n    \"description\": \"Conducts deep research on complex topics with web search\",\n    \"system_prompt\": \"\"\"You are an expert researcher.\n    Search thoroughly, cross-reference sources, and synthesize findings.\"\"\",\n    \"tools\": [web_search, document_reader],\n}\n\ncode_agent = {\n    \"name\": \"coder\",\n    \"description\": \"Writes, reviews, and debugs code\",\n    \"system_prompt\": \"You are an expert programmer. Write clean, tested code.\",\n    \"tools\": [code_executor, linter],\n    \"model\": \"openai:gpt-4o\",  # Optional: different model per subagent\n}\n\nagent = create_deep_agent(\n    subagents=[research_agent, code_agent],\n    system_prompt=\"Delegate research to the researcher and coding to the coder.\",\n)\n```\n\n### Pre-compiled LangGraph Subagents\n\nUse existing LangGraph graphs as subagents.\n\n```python\nfrom deepagents import CompiledSubAgent, create_deep_agent\nfrom langgraph.prebuilt import create_react_agent\n\n# Existing graph\ncustom_graph = create_react_agent(\n    model=\"anthropic:claude-sonnet-4-5-20250929\",\n    tools=[specialized_tool],\n    prompt=\"Custom workflow instructions\",\n)\n\nagent = create_deep_agent(\n    subagents=[CompiledSubAgent(\n        name=\"custom-workflow\",\n        description=\"Runs my specialized analysis workflow\",\n        runnable=custom_graph,\n    )]\n)\n```\n\n### Subagent with Custom Middleware\n\n```python\nfrom langchain.agents.middleware import AgentMiddleware\n\nclass LoggingMiddleware(AgentMiddleware):\n    def transform_response(self, response):\n        print(f\"Subagent response: {response}\")\n        return response\n\nagent_spec = {\n    \"name\": \"logged-agent\",\n    \"description\": \"Agent with extra logging\",\n    \"system_prompt\": \"You are helpful.\",\n    \"tools\": [],\n    \"middleware\": [LoggingMiddleware()],  # Added after default middleware\n}\n```\n\n## Human-in-the-Loop\n\n### Basic Interrupt Configuration\n\nPause execution before specific tools for human approval.\n\n```python\nfrom deepagents import create_deep_agent\n\nagent = create_deep_agent(\n    tools=[send_email, delete_file, web_search],\n    interrupt_on={\n        \"send_email\": True,      # Simple interrupt\n        \"delete_file\": True,     # Require approval before delete\n        # web_search not listed - runs without approval\n    },\n    checkpointer=checkpointer,   # Required for interrupts\n)\n```\n\n### Interrupt with Options\n\n```python\nagent = create_deep_agent(\n    tools=[send_email],\n    interrupt_on={\n        \"send_email\": {\n            \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]\n        },\n    },\n    checkpointer=checkpointer,\n)\n\n# Invoke - will pause at send_email\nconfig = {\"configurable\": {\"thread_id\": \"user-123\"}}\nresult = agent.invoke({\"messages\": [...]}, config)\n\n# Check state\nstate = agent.get_state(config)\nif state.next:  # Has pending interrupt\n    # Resume with approval\n    from langgraph.types import Command\n    agent.invoke(Command(resume={\"approved\": True}), config)\n\n    # Or resume with edit\n    agent.invoke(Command(resume={\"edited_args\": {\"to\": \"new@email.com\"}}), config)\n\n    # Or reject\n    agent.invoke(Command(resume={\"rejected\": True}), config)\n```\n\n### Interrupt on Subagent Tools\n\n```python\n# Interrupts apply to subagents too\nagent = create_deep_agent(\n    subagents=[research_agent],\n    interrupt_on={\n        \"web_search\": True,  # Interrupt even when subagent calls it\n    },\n    checkpointer=checkpointer,\n)\n```\n\n## Custom Middleware\n\n### Middleware Structure\n\n```python\nfrom langchain.agents.middleware.types import (\n    AgentMiddleware,\n    ModelRequest,\n    ModelResponse,\n)\nfrom langchain_core.tools import tool\n\nclass MyMiddleware(AgentMiddleware):\n    # Tools to inject\n    tools = []\n\n    # System prompt content to inject\n    system_prompt = \"\"\n\n    def transform_request(self, request: ModelRequest) -> ModelRequest:\n        \"\"\"Modify request before sending to model.\"\"\"\n        return request\n\n    def transform_response(self, response: ModelResponse) -> ModelResponse:\n        \"\"\"Modify response after receiving from model.\"\"\"\n        return response\n```\n\n### Injecting Tools via Middleware\n\n```python\nfrom langchain_core.tools import tool\n\n@tool\ndef get_current_time() -> str:\n    \"\"\"Get the current time.\"\"\"\n    from datetime import datetime\n    return datetime.now().isoformat()\n\nclass TimeMiddleware(AgentMiddleware):\n    tools = [get_current_time]\n    system_prompt = \"You have access to get_current_time for time-sensitive tasks.\"\n\nagent = create_deep_agent(middleware=[TimeMiddleware()])\n```\n\n### Context Injection Middleware\n\n```python\nclass UserContextMiddleware(AgentMiddleware):\n    def __init__(self, user_preferences: dict):\n        self.user_preferences = user_preferences\n\n    @property\n    def system_prompt(self):\n        return f\"User preferences: {self.user_preferences}\"\n\nagent = create_deep_agent(\n    middleware=[UserContextMiddleware({\"theme\": \"dark\", \"language\": \"en\"})]\n)\n```\n\n### Response Logging Middleware\n\n```python\nimport logging\n\nclass LoggingMiddleware(AgentMiddleware):\n    def transform_response(self, response: ModelResponse) -> ModelResponse:\n        logging.info(f\"Agent response: {response.messages[-1].content[:100]}...\")\n        return response\n\nagent = create_deep_agent(middleware=[LoggingMiddleware()])\n```\n\n## MCP Tool Integration\n\nConnect MCP (Model Context Protocol) servers to provide additional tools.\n\n```python\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom deepagents import create_deep_agent\n\nasync def main():\n    mcp_client = MultiServerMCPClient({\n        \"filesystem\": {\n            \"command\": \"npx\",\n            \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path\"],\n        },\n        \"github\": {\n            \"command\": \"npx\",\n            \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n            \"env\": {\"GITHUB_TOKEN\": os.environ[\"GITHUB_TOKEN\"]},\n        },\n    })\n\n    mcp_tools = await mcp_client.get_tools()\n\n    agent = create_deep_agent(tools=mcp_tools)\n\n    async for chunk in agent.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"List my repos\"}]}\n    ):\n        print(chunk)\n```\n\n## Additional References\n\nFor detailed reference documentation, see:\n\n- **[Built-in Tools Reference](references/tools.md)** - Complete list of tools available on every agent (filesystem, task management, subagent delegation) with path requirements\n- **[Common Patterns](references/patterns.md)** - Production-ready examples including research agents with memory, code assistants with disk access, multi-specialist teams, and production PostgreSQL setup\n",
        "skills/deepagents-implementation/references/patterns.md": "# Common Patterns\n\n## Research Agent with Memory\n\n```python\nfrom langgraph.store.memory import InMemoryStore\nfrom deepagents import create_deep_agent\nfrom deepagents.backends import CompositeBackend, StateBackend, StoreBackend\n\nstore = InMemoryStore()\n\nagent = create_deep_agent(\n    tools=[web_search],\n    system_prompt=\"\"\"You are a research assistant with persistent memory.\n    Save important findings to /memories/ for future reference.\n    Check /memories/ at the start of research tasks.\"\"\",\n    backend=CompositeBackend(\n        default=StateBackend(),\n        routes={\"/memories/\": StoreBackend(store=store)},\n    ),\n    store=store,\n    checkpointer=checkpointer,\n)\n```\n\n## Code Assistant with Disk Access\n\n```python\nfrom deepagents import create_deep_agent\nfrom deepagents.backends import FilesystemBackend\n\nagent = create_deep_agent(\n    system_prompt=\"You are a coding assistant. Help users with their codebase.\",\n    backend=FilesystemBackend(root_dir=\"/Users/dev/project\"),\n)\n\n# Agent can now read/write real files and execute shell commands\n```\n\n## Multi-Specialist Team\n\n```python\nagent = create_deep_agent(\n    subagents=[\n        {\n            \"name\": \"researcher\",\n            \"description\": \"Deep research and fact-finding\",\n            \"system_prompt\": \"Research thoroughly, cite sources.\",\n            \"tools\": [web_search],\n        },\n        {\n            \"name\": \"writer\",\n            \"description\": \"Write polished content\",\n            \"system_prompt\": \"Write clear, engaging content.\",\n            \"tools\": [],\n        },\n        {\n            \"name\": \"reviewer\",\n            \"description\": \"Review and critique content\",\n            \"system_prompt\": \"Provide constructive feedback.\",\n            \"tools\": [],\n        },\n    ],\n    system_prompt=\"\"\"Coordinate the team:\n    1. Use researcher for facts\n    2. Use writer to draft\n    3. Use reviewer to polish\"\"\",\n)\n```\n\n## Production Setup\n\n```python\nfrom langgraph.checkpoint.postgres import PostgresSaver\nfrom langgraph.store.postgres import PostgresStore\nfrom deepagents import create_deep_agent\nfrom deepagents.backends import CompositeBackend, StateBackend, StoreBackend\n\n# Production persistence\ncheckpointer = PostgresSaver.from_conn_string(DATABASE_URL)\nstore = PostgresStore.from_conn_string(DATABASE_URL)\n\nagent = create_deep_agent(\n    model=\"anthropic:claude-sonnet-4-5-20250929\",\n    tools=[...],\n    backend=CompositeBackend(\n        default=StateBackend(),\n        routes={\"/memories/\": StoreBackend(store=store)},\n    ),\n    checkpointer=checkpointer,\n    store=store,\n)\n```\n",
        "skills/deepagents-implementation/references/tools.md": "# Built-in Tools Reference\n\nEvery agent created with `create_deep_agent` has these tools:\n\n## Task Management\n\n| Tool | Description |\n|------|-------------|\n| `write_todos` | Create/update structured task lists |\n| `read_todos` | Read current todo list state |\n\n## Filesystem Operations\n\n| Tool | Description |\n|------|-------------|\n| `ls` | List directory contents (requires absolute path) |\n| `read_file` | Read file with optional offset/limit pagination |\n| `write_file` | Create new file (fails if exists) |\n| `edit_file` | String replacement in existing files |\n| `glob` | Find files matching pattern (e.g., `**/*.py`) |\n| `grep` | Search for text patterns in files |\n| `execute`* | Run shell commands |\n\n*`execute` only available with `FilesystemBackend` or backends implementing `SandboxBackendProtocol`.\n\n## Subagent Delegation\n\n| Tool | Description |\n|------|-------------|\n| `task` | Launch subagent for isolated task execution |\n\n## Tool Path Requirements\n\nAll filesystem tools require absolute paths starting with `/`:\n\n```python\n# Correct\nread_file(path=\"/workspace/main.py\")\nls(path=\"/data\")\n\n# Incorrect - will fail\nread_file(path=\"main.py\")\nread_file(path=\"./workspace/main.py\")\n```\n",
        "skills/docling/SKILL.md": "---\nname: docling\ndescription: Docling document parser for PDF, DOCX, PPTX, HTML, images, and 15+ formats. Use when parsing documents, extracting text, converting to Markdown/HTML/JSON, chunking for RAG pipelines, or batch processing files. Triggers on DocumentConverter, convert, convert_all, export_to_markdown, HierarchicalChunker, HybridChunker, ConversionResult.\n---\n\n# Docling Document Parser\n\nDocling is a document parsing library that converts PDFs, Word documents, PowerPoint, images, and other formats into structured data with advanced layout understanding.\n\n## Quick Start\n\nBasic document conversion:\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"  # URL, Path, or BytesIO\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())\n```\n\n## Core Concepts\n\n### DocumentConverter\n\nThe main entry point for document conversion. Supports various input formats and conversion options.\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\n# Basic converter (all formats enabled)\nconverter = DocumentConverter()\n\n# Restricted formats\nconverter = DocumentConverter(\n    allowed_formats=[InputFormat.PDF, InputFormat.DOCX]\n)\n\n# Custom pipeline options\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n### ConversionResult\n\nAll conversion operations return a `ConversionResult` containing:\n\n- `document`: The parsed `DoclingDocument`\n- `status`: `ConversionStatus.SUCCESS`, `PARTIAL_SUCCESS`, or `FAILURE`\n- `errors`: List of errors encountered during conversion\n- `input`: Information about the source document\n\n```python\nresult = converter.convert(\"document.pdf\")\n\nif result.status == ConversionStatus.SUCCESS:\n    markdown = result.document.export_to_markdown()\n    html = result.document.export_to_html()\n    data = result.document.export_to_dict()\n```\n\n## Supported Formats\n\n### Input Formats\n\n- **Documents**: PDF, DOCX, PPTX, XLSX\n- **Markup**: HTML, Markdown, AsciiDoc\n- **Data**: CSV, JSON (Docling format)\n- **Images**: PNG, JPEG, TIFF, BMP, WEBP\n- **Audio**: WAV, MP3\n- **Video Text**: WebVTT\n- **Schema-specific**: USPTO XML, JATS XML, METS-GBS\n\n### Output Formats\n\n- **Markdown**: `export_to_markdown()` or `save_as_markdown()`\n- **HTML**: `export_to_html()` or `save_as_html()`\n- **JSON**: `export_to_dict()` or `save_as_json()` (note: no `export_to_json()` method)\n- **Text**: `export_to_text()` or `export_to_markdown(strict_text=True)` or `save_as_markdown(strict_text=True)`\n- **DocTags**: `export_to_doctags()` or `save_as_doctags()`\n\n## Common Patterns\n\n### Single File Conversion\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\n# Export to different formats\nmarkdown = result.document.export_to_markdown()\nhtml = result.document.export_to_html()\njson_data = result.document.export_to_dict()\n\n# Or save directly to file\nresult.document.save_as_markdown(\"output.md\")\nresult.document.save_as_html(\"output.html\")\nresult.document.save_as_json(\"output.json\")\n```\n\n### Batch Processing\n\nSee [references/batch.md](references/batch.md) for details on `convert_all()`.\n\n### URL Conversion\n\n```python\nconverter = DocumentConverter()\nresult = converter.convert(\"https://example.com/document.pdf\")\n```\n\n### Binary Stream Conversion\n\n```python\nfrom io import BytesIO\nfrom docling.datamodel.base_models import DocumentStream\n\nwith open(\"document.pdf\", \"rb\") as f:\n    buf = BytesIO(f.read())\n\nsource = DocumentStream(name=\"document.pdf\", stream=buf)\nresult = converter.convert(source)\n```\n\n### Format-Specific Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\n# Configure PDF-specific options\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options.lang = [\"en\", \"es\"]\npipeline_options.do_table_structure = True\npipeline_options.generate_page_images = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n### Resource Limits\n\n```python\nconverter = DocumentConverter()\n\n# Limit file size (bytes) and page count\nresult = converter.convert(\n    \"large_document.pdf\",\n    max_file_size=20_971_520,  # 20 MB\n    max_num_pages=100\n)\n```\n\n### Document Chunking\n\nSee [references/chunking.md](references/chunking.md) for RAG integration.\n\n## DoclingDocument Structure\n\nThe `DoclingDocument` is a Pydantic model representing parsed content:\n\n```python\n# Access document structure\ndoc = result.document\n\n# Content items (lists)\ndoc.texts         # TextItem instances (paragraphs, headings, etc.)\ndoc.tables        # TableItem instances\ndoc.pictures      # PictureItem instances\ndoc.key_value_items  # Key-value pairs\n\n# Structure (tree nodes)\ndoc.body          # Main content hierarchy\ndoc.furniture     # Headers, footers, page numbers\ndoc.groups        # Lists, chapters, sections\n\n# Iterate all elements in reading order\nfor item, level in doc.iterate_items():\n    print(f\"{'  ' * level}{item.label}: {item.text[:50]}\")\n```\n\n## Advanced Features\n\n### OCR Configuration\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    EasyOcrOptions,\n    TesseractOcrOptions,\n    TesseractCliOcrOptions,\n    OcrMacOptions,\n    RapidOcrOptions\n)\n\n# EasyOCR (default)\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = EasyOcrOptions(lang=[\"en\", \"de\"])\n\n# Tesseract\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractOcrOptions(lang=[\"eng\", \"deu\"])\n\n# RapidOCR\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = RapidOcrOptions()\n```\n\n### Table Extraction Options\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    TableFormerMode\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_table_structure = True\n\n# Use cell matching (map to PDF cells)\npipeline_options.table_structure_options.do_cell_matching = True\n\n# Or use predicted cells\npipeline_options.table_structure_options.do_cell_matching = False\n\n# Choose accuracy mode\npipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE\n```\n\n### Page Images\n\n```python\npipeline_options = PdfPipelineOptions()\npipeline_options.generate_page_images = True  # Needed for HTML export with images\n\n# Export with embedded images\nresult.document.save_as_html(\n    \"output.html\",\n    image_mode=ImageRefMode.EMBEDDED\n)\n```\n\n## Error Handling\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\nresult = converter.convert(\"document.pdf\")\n\nif result.status == ConversionStatus.SUCCESS:\n    print(\"Conversion successful\")\nelif result.status == ConversionStatus.PARTIAL_SUCCESS:\n    print(\"Partial conversion:\")\n    for error in result.errors:\n        print(f\"  {error.error_message}\")\nelse:  # FAILURE\n    print(\"Conversion failed:\")\n    for error in result.errors:\n        print(f\"  {error.error_message}\")\n```\n\nFor batch processing with error handling:\n\n```python\n# Continue processing on errors\nresults = converter.convert_all(\n    [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"],\n    raises_on_error=False\n)\n\nfor result in results:\n    if result.status == ConversionStatus.SUCCESS:\n        result.document.save_as_markdown(f\"{result.input.file.stem}.md\")\n    else:\n        print(f\"Failed: {result.input.file}\")\n```\n\n## CLI Usage\n\n```bash\n# Basic conversion\ndocling document.pdf\n\n# Convert to specific output\ndocling --to markdown document.pdf\n\n# With custom model path\ndocling --artifacts-path /path/to/models document.pdf\n\n# Using VLM pipeline\ndocling --pipeline vlm --vlm-model granite_docling document.pdf\n```\n\n## Reference Documentation\n\n- [Parsing Options](references/parsing.md) - DocumentConverter initialization, format-specific options, OCR configuration\n- [Batch Processing](references/batch.md) - convert_all(), error handling, concurrency patterns\n- [Chunking](references/chunking.md) - HierarchicalChunker, HybridChunker, RAG integration\n- [Output Formats](references/output.md) - export_to_markdown(), export_to_html(), export_to_dict(), document structure\n\n## Key Types\n\n- `DocumentConverter`: Main conversion class\n- `ConversionResult`: Result of conversion with document and status\n- `DoclingDocument`: Unified document representation (Pydantic model)\n- `InputFormat`: Enum of supported input formats\n- `ConversionStatus`: SUCCESS, PARTIAL_SUCCESS, FAILURE\n- `PdfPipelineOptions`: Configuration for PDF pipeline\n- `ImageRefMode`: EMBEDDED, REFERENCED, PLACEHOLDER\n\n## Integration Examples\n\n### LangChain\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom langchain_text_splitters import MarkdownTextSplitter\n\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\nmarkdown = result.document.export_to_markdown()\n\nsplitter = MarkdownTextSplitter(chunk_size=1000)\nchunks = splitter.split_text(markdown)\n```\n\n### LlamaIndex\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom llama_index.core import Document\n\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\nchunker = HybridChunker()\nchunks = list(chunker.chunk(result.document))\n\ndocuments = [\n    Document(text=chunk.text, metadata=chunk.meta.export_json_dict())\n    for chunk in chunks\n]\n```\n\n## Notes\n\n- Docling uses a synchronous API (no native async support)\n- Models are downloaded automatically on first use (can be prefetched)\n- Supports local execution for air-gapped environments\n- Supports GPU acceleration for OCR and table detection\n- Default models run on CPU; GPU requires configuration\n",
        "skills/docling/references/batch.md": "# Docling Batch Processing Reference\n\nThis reference covers batch document processing using `convert_all()`, including error handling, concurrency patterns, and resource management.\n\n## Table of Contents\n\n- [Basic Batch Conversion](#basic-batch-conversion)\n- [ConversionStatus Handling](#conversionstatus-handling)\n- [Error Handling and Recovery](#error-handling-and-recovery)\n- [Concurrency Control](#concurrency-control)\n- [Resource Limits](#resource-limits)\n- [Export Patterns](#export-patterns)\n- [Progress Tracking](#progress-tracking)\n\n## Basic Batch Conversion\n\n### Convert Multiple Files\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom pathlib import Path\n\nconverter = DocumentConverter()\n\n# List of file paths\ninput_paths = [\n    \"doc1.pdf\",\n    \"doc2.docx\",\n    \"doc3.html\"\n]\n\n# Returns an iterator of ConversionResult objects\nresults = converter.convert_all(input_paths)\n\nfor result in results:\n    print(f\"Converted: {result.input.file}\")\n    result.document.save_as_markdown(f\"{result.input.file.stem}.md\")\n```\n\n### Using Path Objects\n\n```python\nfrom pathlib import Path\n\ndata_folder = Path(\"documents/\")\ninput_paths = list(data_folder.glob(\"*.pdf\"))\n\nresults = converter.convert_all(input_paths)\n```\n\n### Mixed Sources\n\n```python\nfrom io import BytesIO\nfrom docling.datamodel.base_models import DocumentStream\n\n# Mix of paths, URLs, and streams\nsources = [\n    Path(\"local.pdf\"),\n    \"https://example.com/remote.pdf\",\n    DocumentStream(name=\"stream.pdf\", stream=BytesIO(binary_data))\n]\n\nresults = converter.convert_all(sources)\n```\n\n## ConversionStatus Handling\n\n### Status Values\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\n# SUCCESS: Document fully converted\n# PARTIAL_SUCCESS: Converted with some errors\n# FAILURE: Conversion failed\n# SKIPPED: Document format not allowed\n```\n\n### Checking Status\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nsuccess_count = 0\npartial_count = 0\nfailure_count = 0\n\nfor result in results:\n    if result.status == ConversionStatus.SUCCESS:\n        success_count += 1\n        result.document.save_as_markdown(f\"output/{result.input.file.stem}.md\")\n    elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n        partial_count += 1\n        print(f\"Partial success for {result.input.file}:\")\n        for error in result.errors:\n            print(f\"  - {error.error_message}\")\n        # Still save the partial result\n        result.document.save_as_markdown(f\"output/{result.input.file.stem}.md\")\n    else:  # FAILURE or SKIPPED\n        failure_count += 1\n        print(f\"Failed: {result.input.file}\")\n\nprint(f\"Success: {success_count}, Partial: {partial_count}, Failed: {failure_count}\")\n```\n\n## Error Handling and Recovery\n\n### raises_on_error Parameter\n\n```python\n# Default: raises_on_error=True\n# Raises ConversionError on first failure\ntry:\n    results = converter.convert_all(input_paths, raises_on_error=True)\n    for result in results:\n        result.document.save_as_markdown(f\"{result.input.file.stem}.md\")\nexcept ConversionError as e:\n    print(f\"Conversion failed: {e}\")\n```\n\n### Continue on Error\n\n```python\n# raises_on_error=False\n# Process all documents, collect failures\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nfailed_docs = []\n\nfor result in results:\n    if result.status == ConversionStatus.SUCCESS:\n        result.document.save_as_markdown(f\"{result.input.file.stem}.md\")\n    else:\n        failed_docs.append(result.input.file)\n        if result.errors:\n            print(f\"Errors in {result.input.file}:\")\n            for error in result.errors:\n                print(f\"  {error.component_type}: {error.error_message}\")\n\n# Retry failed documents\nif failed_docs:\n    print(f\"Retrying {len(failed_docs)} failed documents...\")\n    retry_results = converter.convert_all(failed_docs, raises_on_error=False)\n```\n\n### Error Details\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\nfor result in results:\n    if result.status != ConversionStatus.SUCCESS:\n        print(f\"\\nDocument: {result.input.file}\")\n        print(f\"Status: {result.status}\")\n\n        if result.errors:\n            print(\"Errors:\")\n            for error in result.errors:\n                print(f\"  Component: {error.component_type}\")\n                print(f\"  Module: {error.module_name}\")\n                print(f\"  Message: {error.error_message}\")\n```\n\n## Concurrency Control\n\nDocling uses `ThreadPoolExecutor` internally for concurrent batch processing.\n\n### Default Concurrency\n\nControlled by settings (default: 4 threads, batch size: 10):\n\n```python\nfrom docling.datamodel.settings import settings\n\n# View current settings\nprint(f\"Batch size: {settings.perf.doc_batch_size}\")\nprint(f\"Concurrency: {settings.perf.doc_batch_concurrency}\")\n```\n\n### Custom Concurrency\n\nAdjust via environment variables or settings:\n\n```python\n# Via environment (before import)\nimport os\nos.environ[\"DOCLING_DOC_BATCH_SIZE\"] = \"20\"\nos.environ[\"DOCLING_DOC_BATCH_CONCURRENCY\"] = \"8\"\n\nfrom docling.document_converter import DocumentConverter\n```\n\n### CPU Thread Control\n\nLimit CPU threads used by models:\n\n```bash\n# Environment variable\nexport OMP_NUM_THREADS=4\n\n# Or in Python\nimport os\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n```\n\n### Sequential Processing\n\nFor debugging or controlled execution:\n\n```python\nfrom docling.datamodel.settings import settings\n\n# Force sequential processing\nsettings.perf.doc_batch_concurrency = 1\nsettings.perf.doc_batch_size = 1\n\nconverter = DocumentConverter()\nresults = converter.convert_all(input_paths)\n```\n\n## Resource Limits\n\n### Per-Document Limits\n\n```python\n# Apply limits to all documents in batch\nresults = converter.convert_all(\n    input_paths,\n    max_file_size=20_971_520,    # 20 MB per file\n    max_num_pages=100,            # 100 pages per document\n    raises_on_error=False\n)\n\nfor result in results:\n    if result.status == ConversionStatus.SKIPPED:\n        print(f\"Skipped (too large): {result.input.file}\")\n```\n\n### Page Range\n\n```python\n# Convert only first 50 pages of each document\nresults = converter.convert_all(\n    input_paths,\n    page_range=[1, 50]\n)\n```\n\n### Memory Management\n\n```python\nfrom pathlib import Path\n\n# Process in smaller batches for memory control\ndef batch_files(files, batch_size=10):\n    for i in range(0, len(files), batch_size):\n        yield files[i:i + batch_size]\n\nall_files = list(Path(\"documents/\").glob(\"*.pdf\"))\n\nfor file_batch in batch_files(all_files, batch_size=10):\n    results = converter.convert_all(file_batch, raises_on_error=False)\n\n    for result in results:\n        if result.status == ConversionStatus.SUCCESS:\n            result.document.save_as_markdown(f\"output/{result.input.file.stem}.md\")\n\n    # Results iterator consumed, memory can be freed\n```\n\n## Export Patterns\n\n### Save All to Directory\n\n```python\nfrom pathlib import Path\nfrom docling.datamodel.base_models import ConversionStatus\n\noutput_dir = Path(\"output\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nfor result in results:\n    if result.status == ConversionStatus.SUCCESS:\n        doc_name = result.input.file.stem\n\n        # Multiple formats\n        result.document.save_as_markdown(output_dir / f\"{doc_name}.md\")\n        result.document.save_as_json(output_dir / f\"{doc_name}.json\")\n        result.document.save_as_html(output_dir / f\"{doc_name}.html\")\n```\n\n### Conditional Export\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\nfor result in results:\n    doc_name = result.input.file.stem\n\n    if result.status == ConversionStatus.SUCCESS:\n        # Full export for successful conversions\n        result.document.save_as_markdown(f\"output/success/{doc_name}.md\")\n        result.document.save_as_json(f\"output/success/{doc_name}.json\")\n    elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n        # Markdown only for partial conversions\n        result.document.save_as_markdown(f\"output/partial/{doc_name}.md\")\n        # Log errors\n        with open(f\"output/partial/{doc_name}.errors.txt\", \"w\") as f:\n            for error in result.errors:\n                f.write(f\"{error.error_message}\\n\")\n```\n\n### Custom Export Function\n\n```python\nimport json\nfrom pathlib import Path\nfrom docling.datamodel.base_models import ConversionStatus\nfrom docling_core.types.doc import ImageRefMode\n\ndef export_document(result, output_dir):\n    \"\"\"Export successful conversions to multiple formats.\"\"\"\n    if result.status != ConversionStatus.SUCCESS:\n        return False\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    doc_filename = result.input.file.stem\n\n    # JSON with placeholders\n    result.document.save_as_json(\n        output_dir / f\"{doc_filename}.json\",\n        image_mode=ImageRefMode.PLACEHOLDER\n    )\n\n    # HTML with embedded images\n    result.document.save_as_html(\n        output_dir / f\"{doc_filename}.html\",\n        image_mode=ImageRefMode.EMBEDDED\n    )\n\n    # Markdown\n    result.document.save_as_markdown(output_dir / f\"{doc_filename}.md\")\n\n    # Plain text\n    result.document.save_as_markdown(\n        output_dir / f\"{doc_filename}.txt\",\n        strict_text=True\n    )\n\n    return True\n\n# Process batch\nresults = converter.convert_all(input_paths, raises_on_error=False)\nsuccess_count = sum(export_document(r, \"output\") for r in results)\nprint(f\"Exported {success_count} documents\")\n```\n\n## Progress Tracking\n\n### Simple Counter\n\n```python\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\ntotal = len(input_paths)\nfor i, result in enumerate(results, 1):\n    status_str = \"\" if result.status == ConversionStatus.SUCCESS else \"\"\n    print(f\"[{i}/{total}] {status_str} {result.input.file.name}\")\n```\n\n### Progress Bar (tqdm)\n\n```python\nfrom tqdm import tqdm\n\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nfor result in tqdm(results, total=len(input_paths), desc=\"Converting\"):\n    if result.status == ConversionStatus.SUCCESS:\n        result.document.save_as_markdown(f\"{result.input.file.stem}.md\")\n```\n\n### Detailed Logging\n\n```python\nimport logging\nimport time\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\nstart_time = time.time()\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nfor i, result in enumerate(results, 1):\n    elapsed = time.time() - start_time\n\n    if result.status == ConversionStatus.SUCCESS:\n        logger.info(\n            f\"[{i}/{len(input_paths)}] SUCCESS: {result.input.file.name} \"\n            f\"({elapsed:.1f}s elapsed)\"\n        )\n    else:\n        logger.error(\n            f\"[{i}/{len(input_paths)}] FAILED: {result.input.file.name} \"\n            f\"- {result.status}\"\n        )\n```\n\n## Advanced Patterns\n\n### Filter Before Processing\n\n```python\nfrom pathlib import Path\n\n# Get all PDFs, filter by size\ndata_folder = Path(\"documents/\")\npdf_files = [\n    f for f in data_folder.glob(\"*.pdf\")\n    if f.stat().st_size < 10_000_000  # < 10 MB\n]\n\nresults = converter.convert_all(pdf_files)\n```\n\n### Batch with Custom Headers\n\n```python\n# For URL-based sources requiring authentication\nsources = [\n    \"https://api.example.com/doc1.pdf\",\n    \"https://api.example.com/doc2.pdf\"\n]\n\nresults = converter.convert_all(\n    sources,\n    headers={\"Authorization\": \"Bearer token123\"}\n)\n```\n\n### Retry Failed Documents\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\n# First attempt\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nfailed_paths = []\nfor result in results:\n    if result.status == ConversionStatus.FAILURE:\n        failed_paths.append(result.input.file)\n\n# Retry with different options (e.g., OCR disabled)\nif failed_paths:\n    from docling.datamodel.base_models import InputFormat\n    from docling.datamodel.pipeline_options import PdfPipelineOptions\n    from docling.document_converter import PdfFormatOption\n\n    # Simpler pipeline for retry\n    retry_options = PdfPipelineOptions()\n    retry_options.do_ocr = False\n\n    retry_converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(pipeline_options=retry_options)\n        }\n    )\n\n    retry_results = retry_converter.convert_all(failed_paths, raises_on_error=False)\n    for result in retry_results:\n        if result.status == ConversionStatus.SUCCESS:\n            print(f\"Retry succeeded: {result.input.file}\")\n```\n\n### Parallel Batches with multiprocessing\n\n```python\nfrom concurrent.futures import ProcessPoolExecutor\nfrom pathlib import Path\n\ndef process_batch(file_batch):\n    \"\"\"Process a batch of files in a separate process.\"\"\"\n    from docling.document_converter import DocumentConverter\n\n    converter = DocumentConverter()\n    results = list(converter.convert_all(file_batch, raises_on_error=False))\n\n    success = sum(1 for r in results if r.status == ConversionStatus.SUCCESS)\n    return success, len(results)\n\n# Split files into batches\nall_files = list(Path(\"documents/\").glob(\"*.pdf\"))\nbatch_size = 10\nbatches = [all_files[i:i+batch_size] for i in range(0, len(all_files), batch_size)]\n\n# Process batches in parallel processes\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    batch_results = executor.map(process_batch, batches)\n\ntotal_success = 0\ntotal_processed = 0\nfor success, processed in batch_results:\n    total_success += success\n    total_processed += processed\n\nprint(f\"Processed {total_processed} documents, {total_success} successful\")\n```\n\n### Summary Statistics\n\n```python\nfrom collections import Counter\nfrom docling.datamodel.base_models import ConversionStatus\n\nresults = converter.convert_all(input_paths, raises_on_error=False)\n\nstatus_counts = Counter()\nerror_types = Counter()\n\nfor result in results:\n    status_counts[result.status] += 1\n\n    if result.errors:\n        for error in result.errors:\n            error_types[error.component_type] += 1\n\nprint(\"\\nConversion Summary:\")\nprint(f\"  SUCCESS: {status_counts[ConversionStatus.SUCCESS]}\")\nprint(f\"  PARTIAL_SUCCESS: {status_counts[ConversionStatus.PARTIAL_SUCCESS]}\")\nprint(f\"  FAILURE: {status_counts[ConversionStatus.FAILURE]}\")\nprint(f\"  SKIPPED: {status_counts[ConversionStatus.SKIPPED]}\")\n\nif error_types:\n    print(\"\\nError Types:\")\n    for error_type, count in error_types.most_common():\n        print(f\"  {error_type}: {count}\")\n```\n",
        "skills/docling/references/chunking.md": "# Docling Chunking Reference\n\nThis reference covers document chunking for RAG pipelines, including HierarchicalChunker and HybridChunker implementations.\n\n## Table of Contents\n\n- [Overview](#overview)\n- [BaseChunker Interface](#basechunker-interface)\n- [HierarchicalChunker](#hierarchicalchunker)\n- [HybridChunker](#hybridchunker)\n- [Chunk Metadata](#chunk-metadata)\n- [RAG Integration Patterns](#rag-integration-patterns)\n- [Advanced Usage](#advanced-usage)\n\n## Overview\n\nDocling chunkers operate directly on `DoclingDocument` objects, creating structure-aware chunks with rich metadata. This approach preserves document hierarchy and context better than simple text splitting.\n\n### Two Approaches\n\n1. **Native chunkers** (this reference): Operate on `DoclingDocument` objects\n2. **Post-processing**: Export to Markdown, then use external splitters\n\nNative chunkers are recommended for RAG applications requiring document structure preservation.\n\n## BaseChunker Interface\n\nAll chunkers implement the `BaseChunker` interface:\n\n```python\nfrom docling.chunking import BaseChunker, BaseChunk\nfrom docling_core.types.doc import DoclingDocument\n\nclass BaseChunker:\n    def chunk(self, dl_doc: DoclingDocument, **kwargs) -> Iterator[BaseChunk]:\n        \"\"\"Generate chunks from document.\"\"\"\n        ...\n\n    def contextualize(self, chunk: BaseChunk) -> str:\n        \"\"\"Serialize chunk with metadata for embedding.\"\"\"\n        ...\n```\n\n### BaseChunk\n\nEach chunk contains:\n\n- `text`: The chunk text content\n- `meta`: Metadata (headers, captions, page numbers, etc.)\n- `path`: Document element path\n\n## HierarchicalChunker\n\nStructure-aware chunker that creates one chunk per document element (paragraph, table, etc.), preserving document hierarchy.\n\n### Basic Usage\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HierarchicalChunker\n\n# Convert document\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\n# Chunk document\nchunker = HierarchicalChunker()\nchunks = list(chunker.chunk(result.document))\n\nprint(f\"Created {len(chunks)} chunks\")\n\nfor chunk in chunks[:3]:\n    print(f\"\\nChunk text: {chunk.text[:100]}...\")\n    print(f\"Metadata: {chunk.meta}\")\n```\n\n### Options\n\n```python\nfrom docling.chunking import HierarchicalChunker\n\nchunker = HierarchicalChunker(\n    merge_list_items=True  # Merge consecutive list items (default: True)\n)\n```\n\n### Chunk Iteration\n\n```python\nfor i, chunk in enumerate(chunker.chunk(result.document)):\n    # Access chunk data\n    text = chunk.text\n    meta = chunk.meta\n\n    # Access metadata fields\n    page_num = meta.page if hasattr(meta, 'page') else None\n    headings = meta.headings if hasattr(meta, 'headings') else []\n    doc_items = meta.doc_items if hasattr(meta, 'doc_items') else []\n\n    print(f\"Chunk {i}: page {page_num}, {len(text)} chars\")\n```\n\n### Contextualization\n\nAdd metadata context to chunk text for embedding:\n\n```python\nfor chunk in chunker.chunk(result.document):\n    # Plain text\n    plain_text = chunk.text\n\n    # Text with metadata context\n    contextualized = chunker.contextualize(chunk)\n\n    print(f\"Plain: {plain_text[:50]}\")\n    print(f\"Contextualized: {contextualized[:50]}\")\n```\n\n## HybridChunker\n\nAdvanced chunker combining hierarchical structure with token-aware splitting and merging.\n\n### Installation\n\n```bash\n# For HuggingFace tokenizers\npip install 'docling-core[chunking]'\n\n# For OpenAI tokenizers (tiktoken)\npip install 'docling-core[chunking-openai]'\n```\n\n### Basic Usage\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer\n\n# Convert document\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\n# Initialize chunker with tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n\nchunker = HybridChunker(\n    tokenizer=tokenizer,\n    max_tokens=512,\n    merge_peers=True\n)\n\n# Generate chunks\nchunks = list(chunker.chunk(result.document))\n\nprint(f\"Created {len(chunks)} chunks with max {chunker.max_tokens} tokens each\")\n```\n\n### Configuration Options\n\n```python\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\nchunker = HybridChunker(\n    tokenizer=tokenizer,\n    max_tokens=512,           # Maximum tokens per chunk\n    merge_peers=True,         # Merge undersized consecutive chunks (default: True)\n    merge_list_items=True     # Merge list items (default: True)\n)\n```\n\n### Token-Aware Processing\n\nHybridChunker performs two passes:\n\n1. **Split pass**: Splits oversized chunks to respect `max_tokens`\n2. **Merge pass**: Merges undersized consecutive chunks with same headers/captions\n\n```python\n# Disable merge pass for fixed-size chunks\nchunker = HybridChunker(\n    tokenizer=tokenizer,\n    max_tokens=256,\n    merge_peers=False  # No merging, strict token limits\n)\n```\n\n### OpenAI Tokenizer\n\n```python\nfrom docling.chunking import HybridChunker\nimport tiktoken\n\n# Use OpenAI tokenizer\nencoding = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4 encoding\n\nchunker = HybridChunker(\n    tokenizer=encoding,\n    max_tokens=1024\n)\n```\n\n## Chunk Metadata\n\n### DocMeta Structure\n\nChunks from HierarchicalChunker and HybridChunker use `DocMeta`:\n\n```python\nfrom docling.chunking import HierarchicalChunker\n\nchunker = HierarchicalChunker()\nchunks = list(chunker.chunk(doc))\n\nfor chunk in chunks:\n    meta = chunk.meta\n\n    # Common fields\n    headings = meta.headings        # List of parent headings\n    captions = meta.captions        # Associated captions\n    page = meta.page                # Page number\n    doc_items = meta.doc_items      # Source document items\n```\n\n### Accessing Metadata\n\n```python\nfor chunk in chunks:\n    # Export metadata as dict\n    meta_dict = chunk.meta.export_json_dict()\n\n    print(f\"Text: {chunk.text[:50]}\")\n    print(f\"Page: {meta_dict.get('page')}\")\n    print(f\"Headings: {meta_dict.get('headings', [])}\")\n    print(f\"Captions: {meta_dict.get('captions', [])}\")\n    print()\n```\n\n### Custom Metadata Serialization\n\n```python\ndef format_chunk_with_context(chunk):\n    \"\"\"Format chunk with metadata for embedding.\"\"\"\n    meta = chunk.meta.export_json_dict()\n\n    # Build context string\n    context_parts = []\n\n    # Add headings hierarchy\n    if meta.get('headings'):\n        context_parts.append(\"Section: \" + \" > \".join(meta['headings']))\n\n    # Add page number\n    if meta.get('page'):\n        context_parts.append(f\"Page {meta['page']}\")\n\n    # Add captions\n    if meta.get('captions'):\n        context_parts.append(\"Captions: \" + \", \".join(meta['captions']))\n\n    # Combine context with text\n    if context_parts:\n        return \" | \".join(context_parts) + \"\\n\\n\" + chunk.text\n    else:\n        return chunk.text\n\n# Use with chunks\nfor chunk in chunks:\n    formatted = format_chunk_with_context(chunk)\n    # Send to embedding model\n```\n\n## RAG Integration Patterns\n\n### LangChain Integration\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer\nfrom langchain_core.documents import Document\n\n# Convert and chunk\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nchunker = HybridChunker(tokenizer=tokenizer, max_tokens=512)\nchunks = list(chunker.chunk(result.document))\n\n# Create LangChain documents\nlangchain_docs = [\n    Document(\n        page_content=chunk.text,\n        metadata=chunk.meta.export_json_dict()\n    )\n    for chunk in chunks\n]\n\n# Use with vector store\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nvectorstore = FAISS.from_documents(langchain_docs, embeddings)\n```\n\n### LlamaIndex Integration\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer\nfrom llama_index.core import Document, VectorStoreIndex\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\n# Convert and chunk\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\")\nchunker = HybridChunker(tokenizer=tokenizer, max_tokens=512)\nchunks = list(chunker.chunk(result.document))\n\n# Create LlamaIndex documents\nllama_docs = [\n    Document(\n        text=chunk.text,\n        metadata=chunk.meta.export_json_dict()\n    )\n    for chunk in chunks\n]\n\n# Create index\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\nindex = VectorStoreIndex.from_documents(llama_docs, embed_model=embed_model)\n```\n\n### Custom RAG Pipeline\n\n```python\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Convert and chunk\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nchunker = HybridChunker(tokenizer=tokenizer, max_tokens=256)\nchunks = list(chunker.chunk(result.document))\n\n# Load embedding model\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n\ndef embed_chunks(chunks):\n    \"\"\"Generate embeddings for chunks.\"\"\"\n    embeddings = []\n\n    for chunk in chunks:\n        # Contextualize chunk\n        text = chunker.contextualize(chunk)\n\n        # Tokenize\n        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n\n        # Generate embedding\n        with torch.no_grad():\n            outputs = model(**inputs)\n            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\n        embeddings.append({\n            \"text\": chunk.text,\n            \"embedding\": embedding,\n            \"metadata\": chunk.meta.export_json_dict()\n        })\n\n    return embeddings\n\n# Create embeddings\nchunk_embeddings = embed_chunks(chunks)\n```\n\n## Advanced Usage\n\n### Multi-Document Chunking\n\n```python\nfrom pathlib import Path\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\nfrom transformers import AutoTokenizer\n\nconverter = DocumentConverter()\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nchunker = HybridChunker(tokenizer=tokenizer, max_tokens=512)\n\n# Process multiple documents\ndoc_paths = list(Path(\"documents/\").glob(\"*.pdf\"))\n\nall_chunks = []\nfor doc_path in doc_paths:\n    result = converter.convert(doc_path)\n    chunks = list(chunker.chunk(result.document))\n\n    # Add document source to metadata\n    for chunk in chunks:\n        meta_dict = chunk.meta.export_json_dict()\n        meta_dict[\"source_file\"] = str(doc_path)\n        all_chunks.append({\n            \"text\": chunk.text,\n            \"metadata\": meta_dict\n        })\n\nprint(f\"Total chunks from {len(doc_paths)} documents: {len(all_chunks)}\")\n```\n\n### Filtering Chunks\n\n```python\n# Filter out small chunks\nMIN_CHUNK_SIZE = 50\n\nfiltered_chunks = [\n    chunk for chunk in chunks\n    if len(chunk.text.strip()) >= MIN_CHUNK_SIZE\n]\n\n# Filter by metadata\ndef has_meaningful_content(chunk):\n    \"\"\"Filter out chunks with just headers or empty content.\"\"\"\n    text = chunk.text.strip()\n    meta = chunk.meta.export_json_dict()\n\n    # Skip if too short\n    if len(text) < 20:\n        return False\n\n    # Skip if only whitespace or punctuation\n    if not any(c.isalnum() for c in text):\n        return False\n\n    return True\n\nmeaningful_chunks = [c for c in chunks if has_meaningful_content(c)]\n```\n\n### Custom Chunking Strategy\n\n```python\nfrom docling.chunking import BaseChunker, BaseChunk, BaseMeta\nfrom docling_core.types.doc import DoclingDocument\nfrom typing import Iterator\n\nclass CustomChunker(BaseChunker):\n    \"\"\"Custom chunker that groups chunks by page.\"\"\"\n\n    def __init__(self, chunks_per_page: int = 1):\n        self.chunks_per_page = chunks_per_page\n\n    def chunk(self, dl_doc: DoclingDocument, **kwargs) -> Iterator[BaseChunk]:\n        \"\"\"Generate chunks grouped by page.\"\"\"\n        # Group items by page\n        pages = {}\n        for item, _ in dl_doc.iterate_items():\n            if hasattr(item, 'prov') and item.prov:\n                page_num = item.prov[0].page\n                if page_num not in pages:\n                    pages[page_num] = []\n                pages[page_num].append(item)\n\n        # Create chunks\n        for page_num, items in sorted(pages.items()):\n            text = \" \".join(item.text for item in items if hasattr(item, 'text'))\n\n            meta = BaseMeta()\n            meta.page = page_num\n\n            yield BaseChunk(text=text, meta=meta)\n\n    def contextualize(self, chunk: BaseChunk) -> str:\n        \"\"\"Add page context.\"\"\"\n        page = chunk.meta.page if hasattr(chunk.meta, 'page') else None\n        if page:\n            return f\"[Page {page}]\\n{chunk.text}\"\n        return chunk.text\n\n# Use custom chunker\ncustom_chunker = CustomChunker()\ncustom_chunks = list(custom_chunker.chunk(result.document))\n```\n\n### Chunk Size Analysis\n\n```python\nfrom collections import Counter\n\ndef analyze_chunks(chunks, tokenizer=None):\n    \"\"\"Analyze chunk statistics.\"\"\"\n    char_lengths = [len(chunk.text) for chunk in chunks]\n\n    if tokenizer:\n        token_counts = [\n            len(tokenizer.encode(chunk.text))\n            for chunk in chunks\n        ]\n    else:\n        # Approximate with word count\n        token_counts = [len(chunk.text.split()) for chunk in chunks]\n\n    print(f\"Total chunks: {len(chunks)}\")\n    print(f\"\\nCharacter counts:\")\n    print(f\"  Min: {min(char_lengths)}\")\n    print(f\"  Max: {max(char_lengths)}\")\n    print(f\"  Mean: {sum(char_lengths) / len(char_lengths):.1f}\")\n    print(f\"  Median: {sorted(char_lengths)[len(char_lengths)//2]}\")\n\n    print(f\"\\nToken counts:\")\n    print(f\"  Min: {min(token_counts)}\")\n    print(f\"  Max: {max(token_counts)}\")\n    print(f\"  Mean: {sum(token_counts) / len(token_counts):.1f}\")\n    print(f\"  Median: {sorted(token_counts)[len(token_counts)//2]}\")\n\n    # Distribution\n    bins = [0, 50, 100, 256, 512, 1024, float('inf')]\n    bin_labels = [\"0-50\", \"50-100\", \"100-256\", \"256-512\", \"512-1024\", \"1024+\"]\n    distribution = Counter()\n\n    for count in token_counts:\n        for i, (low, high) in enumerate(zip(bins[:-1], bins[1:])):\n            if low <= count < high:\n                distribution[bin_labels[i]] += 1\n                break\n\n    print(f\"\\nToken distribution:\")\n    for label in bin_labels:\n        print(f\"  {label}: {distribution[label]}\")\n\n# Analyze chunks\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nanalyze_chunks(chunks, tokenizer)\n```\n\n### Combining Chunkers\n\n```python\n# Use HierarchicalChunker, then post-process with token limits\nfrom docling.chunking import HierarchicalChunker\nfrom transformers import AutoTokenizer\n\n# Initial chunking\nhier_chunker = HierarchicalChunker()\nbase_chunks = list(hier_chunker.chunk(result.document))\n\n# Token-aware refinement\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nmax_tokens = 512\n\nrefined_chunks = []\nfor chunk in base_chunks:\n    tokens = tokenizer.encode(chunk.text)\n\n    if len(tokens) <= max_tokens:\n        refined_chunks.append(chunk)\n    else:\n        # Split oversized chunk\n        # (simplified - real implementation would preserve metadata)\n        sentences = chunk.text.split('. ')\n        current_text = \"\"\n\n        for sentence in sentences:\n            test_text = current_text + sentence + '. '\n            if len(tokenizer.encode(test_text)) <= max_tokens:\n                current_text = test_text\n            else:\n                if current_text:\n                    refined_chunks.append(BaseChunk(text=current_text, meta=chunk.meta))\n                current_text = sentence + '. '\n\n        if current_text:\n            refined_chunks.append(BaseChunk(text=current_text, meta=chunk.meta))\n```\n",
        "skills/docling/references/output.md": "# Docling Output Formats Reference\n\nThis reference covers document export methods, output formats, and accessing document structure.\n\n## Table of Contents\n\n- [DoclingDocument Structure](#doclingdocument-structure)\n- [Markdown Export](#markdown-export)\n- [HTML Export](#html-export)\n- [JSON Export](#json-export)\n- [Plain Text Export](#plain-text-export)\n- [DocTags Export](#doctags-export)\n- [Save Methods](#save-methods)\n- [Document Iteration](#document-iteration)\n- [Image Handling](#image-handling)\n\n## DoclingDocument Structure\n\nThe `DoclingDocument` is a Pydantic model with the following top-level fields:\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\nresult = converter.convert(\"document.pdf\")\ndoc = result.document\n\n# Content items (lists of DocItem instances)\ndoc.texts              # TextItem: paragraphs, headings, equations\ndoc.tables             # TableItem: tables with structure\ndoc.pictures           # PictureItem: images, figures\ndoc.key_value_items    # Key-value pairs\n\n# Structure (tree of NodeItem instances)\ndoc.body               # Main content hierarchy\ndoc.furniture          # Headers, footers, page numbers\ndoc.groups             # Lists, chapters, sections\n\n# Metadata\ndoc.name               # Document name\ndoc.origin             # Document source information\n```\n\n### Content Items\n\n```python\n# Access text items\nfor text_item in doc.texts:\n    print(f\"Label: {text_item.label}\")        # paragraph, section_header, etc.\n    print(f\"Text: {text_item.text}\")\n    if text_item.prov:\n        print(f\"Page: {text_item.prov[0].page}\")\n\n# Access tables\nfor table_item in doc.tables:\n    print(f\"Table data: {table_item.data}\")\n    # Export table to HTML\n    html = table_item.export_to_html()\n\n# Access pictures\nfor pic_item in doc.pictures:\n    print(f\"Image: {pic_item.image}\")\n    if pic_item.prov:\n        print(f\"BBox: {pic_item.prov[0].bbox}\")\n```\n\n## Markdown Export\n\n### Basic Markdown Export\n\n```python\n# Export to Markdown string\nmarkdown = result.document.export_to_markdown()\nprint(markdown)\n\n# Write to file manually\nwith open(\"output.md\", \"w\") as f:\n    f.write(markdown)\n```\n\n### Image Modes\n\n```python\nfrom docling_core.types.doc import ImageRefMode\n\n# Placeholder (default) - no actual image data\nmarkdown = result.document.export_to_markdown(\n    image_mode=ImageRefMode.PLACEHOLDER\n)\n\n# Referenced - link to image files\nmarkdown = result.document.export_to_markdown(\n    image_mode=ImageRefMode.REFERENCED\n)\n\n# Embedded - base64-encoded images (not typical for Markdown)\nmarkdown = result.document.export_to_markdown(\n    image_mode=ImageRefMode.EMBEDDED\n)\n```\n\n### Plain Text Mode\n\n```python\n# Export as plain text (no Markdown formatting)\nplain_text = result.document.export_to_markdown(strict_text=True)\n\n# Just the text content, no markers\nwith open(\"output.txt\", \"w\") as f:\n    f.write(plain_text)\n```\n\n### Partial Export\n\n```python\n# Export specific range of items\nmarkdown = result.document.export_to_markdown(\n    main_text_start=0,\n    main_text_stop=10\n)\n```\n\n## HTML Export\n\n### Basic HTML Export\n\n```python\n# Export to HTML string\nhtml = result.document.export_to_html()\n\nwith open(\"output.html\", \"w\") as f:\n    f.write(html)\n```\n\n### Image Modes\n\n```python\nfrom docling_core.types.doc import ImageRefMode\n\n# Embedded images (base64-encoded)\nhtml = result.document.export_to_html(\n    image_mode=ImageRefMode.EMBEDDED\n)\n\n# Referenced images (external files)\nhtml = result.document.export_to_html(\n    image_mode=ImageRefMode.REFERENCED\n)\n\n# Placeholders only\nhtml = result.document.export_to_html(\n    image_mode=ImageRefMode.PLACEHOLDER\n)\n```\n\n### Page Images\n\nTo include page images, enable during conversion:\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\n# Enable page image generation\npipeline_options = PdfPipelineOptions()\npipeline_options.generate_page_images = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n\nresult = converter.convert(\"document.pdf\")\n\n# Export with embedded page images\nhtml = result.document.export_to_html(image_mode=ImageRefMode.EMBEDDED)\n```\n\n## JSON Export\n\n### Dictionary Export\n\n```python\n# Export to Python dict\ndoc_dict = result.document.export_to_dict()\n\n# Access fields\nprint(doc_dict[\"name\"])\nprint(len(doc_dict[\"texts\"]))\nprint(len(doc_dict[\"tables\"]))\n```\n\n### JSON String Export\n\n```python\nimport json\n\n# Export to dict, then convert to JSON string\ndoc_dict = result.document.export_to_dict()\njson_str = json.dumps(doc_dict, indent=2)\n\n# Note: There is no export_to_json() method\n# Use export_to_dict() and then json.dumps() for JSON strings\n```\n\n### Pretty Print\n\n```python\nimport json\n\ndoc_dict = result.document.export_to_dict()\n\n# Pretty-printed JSON\nwith open(\"output.json\", \"w\") as f:\n    json.dump(doc_dict, f, indent=2)\n```\n\n### Lossless Serialization\n\nJSON export is lossless - you can reconstruct the DoclingDocument:\n\n```python\nfrom docling_core.types.doc import DoclingDocument\nimport json\n\n# Export to dict, then to JSON string\ndoc_dict = result.document.export_to_dict()\njson_str = json.dumps(doc_dict)\n\n# Reconstruct\ndoc_dict_loaded = json.loads(json_str)\nreconstructed = DoclingDocument(**doc_dict_loaded)\n\n# Identical to original\nassert reconstructed.export_to_markdown() == result.document.export_to_markdown()\n```\n\n## Plain Text Export\n\n### Using Markdown Export\n\n```python\n# Most common: use export_to_markdown with strict_text=True\nplain_text = result.document.export_to_markdown(strict_text=True)\n\nwith open(\"output.txt\", \"w\") as f:\n    f.write(plain_text)\n```\n\n### Manual Text Extraction\n\n```python\n# Extract all text content manually\nall_text = []\n\nfor item, level in result.document.iterate_items():\n    if hasattr(item, 'text') and item.text:\n        all_text.append(item.text)\n\nplain_text = \"\\n\".join(all_text)\n```\n\n## DocTags Export\n\nDocTags is a markup format for representing full content and layout characteristics.\n\n### Basic DocTags Export\n\n```python\n# Export to DocTags format\ndoctags = result.document.export_to_doctags()\n\nwith open(\"output.doctags.txt\", \"w\") as f:\n    f.write(doctags)\n```\n\n### DocTags with Options\n\n```python\n# Export specific range\ndoctags = result.document.export_to_document_tokens(\n    main_text_start=0,\n    main_text_stop=10,\n    add_page_index=True\n)\n```\n\n## Save Methods\n\nConvenience methods that combine export and file writing:\n\n### save_as_markdown()\n\n```python\nfrom pathlib import Path\nfrom docling_core.types.doc import ImageRefMode\n\n# Basic save\nresult.document.save_as_markdown(\"output.md\")\n\n# With options\nresult.document.save_as_markdown(\n    Path(\"output.md\"),\n    image_mode=ImageRefMode.PLACEHOLDER\n)\n\n# Plain text mode\nresult.document.save_as_markdown(\n    \"output.txt\",\n    strict_text=True\n)\n```\n\n### save_as_html()\n\n```python\nfrom docling_core.types.doc import ImageRefMode\n\n# Save with embedded images\nresult.document.save_as_html(\n    \"output.html\",\n    image_mode=ImageRefMode.EMBEDDED\n)\n\n# Save with referenced images\nresult.document.save_as_html(\n    \"output.html\",\n    image_mode=ImageRefMode.REFERENCED\n)\n```\n\n### save_as_json()\n\n```python\nfrom docling_core.types.doc import ImageRefMode\n\n# Save JSON\nresult.document.save_as_json(\"output.json\")\n\n# With image mode\nresult.document.save_as_json(\n    \"output.json\",\n    image_mode=ImageRefMode.PLACEHOLDER\n)\n```\n\n### save_as_doctags()\n\n```python\n# Save DocTags format\nresult.document.save_as_doctags(\"output.doctags.txt\")\n```\n\n## Document Iteration\n\n### iterate_items()\n\nIterate document elements in reading order:\n\n```python\n# Basic iteration\nfor item, level in result.document.iterate_items():\n    indent = \"  \" * level\n    if hasattr(item, 'text'):\n        print(f\"{indent}{item.label}: {item.text[:50]}\")\n```\n\n### With Filtering\n\n```python\n# Only specific item types\nfor item, level in result.document.iterate_items():\n    if item.label == \"section_header\":\n        print(f\"Header (level {level}): {item.text}\")\n    elif item.label == \"table\":\n        print(f\"Table (level {level})\")\n```\n\n### Extract Tables\n\n```python\n# Find all tables\ntables = []\nfor item, level in result.document.iterate_items():\n    if item.label == \"table\":\n        tables.append(item)\n\n# Export tables\nfor i, table in enumerate(tables):\n    html = table.export_to_html()\n    with open(f\"table_{i}.html\", \"w\") as f:\n        f.write(html)\n```\n\n### Extract Images\n\n```python\n# Find all pictures/figures\npictures = []\nfor item, level in result.document.iterate_items():\n    if item.label in [\"picture\", \"figure\"]:\n        pictures.append(item)\n\nprint(f\"Found {len(pictures)} images\")\n\n# Access image data\nfor i, pic in enumerate(pictures):\n    if pic.image:\n        # Save image\n        pic.image.pil_image.save(f\"image_{i}.png\")\n```\n\n### Build Outline\n\n```python\n# Extract document outline\noutline = []\n\nfor item, level in result.document.iterate_items():\n    if item.label in [\"section_header\", \"title\", \"subtitle_level_1\"]:\n        outline.append({\n            \"level\": level,\n            \"text\": item.text,\n            \"page\": item.prov[0].page if item.prov else None\n        })\n\n# Print outline\nfor entry in outline:\n    indent = \"  \" * entry[\"level\"]\n    page_str = f\" (p. {entry['page']})\" if entry['page'] else \"\"\n    print(f\"{indent}{entry['text']}{page_str}\")\n```\n\n## Image Handling\n\n### Image Reference Modes\n\n```python\nfrom docling_core.types.doc import ImageRefMode\n\n# PLACEHOLDER: No image data, just placeholders\n# REFERENCED: Links to external image files\n# EMBEDDED: Base64-encoded images in output\n```\n\n### Extract Images from Document\n\n```python\n# Get all picture items\nfor i, pic_item in enumerate(result.document.pictures):\n    if pic_item.image and pic_item.image.pil_image:\n        # Save as PNG\n        pic_item.image.pil_image.save(f\"figure_{i}.png\")\n\n        # Or get bytes\n        from io import BytesIO\n        buf = BytesIO()\n        pic_item.image.pil_image.save(buf, format=\"PNG\")\n        image_bytes = buf.getvalue()\n```\n\n### Generate Page Images\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\n# Enable page image generation\npipeline_options = PdfPipelineOptions()\npipeline_options.generate_page_images = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n\nresult = converter.convert(\"document.pdf\")\n\n# Access page images\nfor i, page in enumerate(result.pages):\n    if page.image:\n        page.image.pil_image.save(f\"page_{i}.png\")\n```\n\n## Advanced Export Patterns\n\n### Multi-Format Export\n\n```python\nfrom pathlib import Path\nfrom docling_core.types.doc import ImageRefMode\n\ndef export_all_formats(result, output_dir):\n    \"\"\"Export conversion result to all formats.\"\"\"\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    doc_name = result.input.file.stem\n\n    # Markdown\n    result.document.save_as_markdown(\n        output_dir / f\"{doc_name}.md\",\n        image_mode=ImageRefMode.PLACEHOLDER\n    )\n\n    # HTML with embedded images\n    result.document.save_as_html(\n        output_dir / f\"{doc_name}.html\",\n        image_mode=ImageRefMode.EMBEDDED\n    )\n\n    # JSON\n    result.document.save_as_json(output_dir / f\"{doc_name}.json\")\n\n    # Plain text\n    result.document.save_as_markdown(\n        output_dir / f\"{doc_name}.txt\",\n        strict_text=True\n    )\n\n    # DocTags\n    result.document.save_as_doctags(output_dir / f\"{doc_name}.doctags.txt\")\n\n# Use\nexport_all_formats(result, \"output\")\n```\n\n### Custom JSON Serialization\n\n```python\nimport json\n\ndef export_custom_json(doc, output_path):\n    \"\"\"Export custom JSON with selected fields.\"\"\"\n    custom_data = {\n        \"name\": doc.name,\n        \"text_count\": len(doc.texts),\n        \"table_count\": len(doc.tables),\n        \"picture_count\": len(doc.pictures),\n        \"content\": []\n    }\n\n    # Extract structured content\n    for item, level in doc.iterate_items():\n        if hasattr(item, 'text'):\n            custom_data[\"content\"].append({\n                \"level\": level,\n                \"label\": item.label,\n                \"text\": item.text,\n                \"page\": item.prov[0].page if item.prov else None\n            })\n\n    with open(output_path, \"w\") as f:\n        json.dump(custom_data, f, indent=2)\n\n# Use\nexport_custom_json(result.document, \"custom.json\")\n```\n\n### Extract Tables to CSV\n\n```python\nimport csv\nfrom bs4 import BeautifulSoup\n\ndef table_to_csv(table_item, output_path):\n    \"\"\"Convert table HTML to CSV.\"\"\"\n    html = table_item.export_to_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    rows = []\n    for tr in soup.find_all(\"tr\"):\n        row = [td.get_text(strip=True) for td in tr.find_all([\"td\", \"th\"])]\n        rows.append(row)\n\n    with open(output_path, \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerows(rows)\n\n# Extract all tables to CSV\nfor i, table in enumerate(result.document.tables):\n    table_to_csv(table, f\"table_{i}.csv\")\n```\n\n### Metadata Extraction\n\n```python\ndef extract_metadata(result):\n    \"\"\"Extract document metadata.\"\"\"\n    doc = result.document\n\n    metadata = {\n        \"filename\": result.input.file.name,\n        \"format\": result.input.format.value,\n        \"status\": result.status.value,\n        \"page_count\": len(result.pages) if hasattr(result, 'pages') else 0,\n        \"text_items\": len(doc.texts),\n        \"tables\": len(doc.tables),\n        \"pictures\": len(doc.pictures),\n        \"headings\": []\n    }\n\n    # Extract headings\n    for item, level in doc.iterate_items():\n        if item.label in [\"section_header\", \"title\"]:\n            metadata[\"headings\"].append({\n                \"level\": level,\n                \"text\": item.text\n            })\n\n    return metadata\n\n# Use\nimport json\nmetadata = extract_metadata(result)\nwith open(\"metadata.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)\n```\n\n### Page-Level Export\n\n```python\ndef export_pages_separately(result, output_dir):\n    \"\"\"Export each page to a separate Markdown file.\"\"\"\n    from pathlib import Path\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Group items by page\n    pages = {}\n    for item, _ in result.document.iterate_items():\n        if hasattr(item, 'prov') and item.prov:\n            page_num = item.prov[0].page\n            if page_num not in pages:\n                pages[page_num] = []\n            if hasattr(item, 'text'):\n                pages[page_num].append(item.text)\n\n    # Export each page\n    for page_num, texts in sorted(pages.items()):\n        page_content = \"\\n\\n\".join(texts)\n        output_file = output_dir / f\"page_{page_num:03d}.md\"\n        with open(output_file, \"w\") as f:\n            f.write(f\"# Page {page_num}\\n\\n{page_content}\")\n\n# Use\nexport_pages_separately(result, \"pages\")\n```\n",
        "skills/docling/references/parsing.md": "# Docling Parsing Reference\n\nThis reference covers document parsing operations, including converter initialization, format-specific options, and OCR configuration.\n\n## Table of Contents\n\n- [DocumentConverter Initialization](#documentconverter-initialization)\n- [Single File Conversion](#single-file-conversion)\n- [URL Conversion](#url-conversion)\n- [Binary Stream Conversion](#binary-stream-conversion)\n- [Format-Specific Options](#format-specific-options)\n- [PDF Pipeline Options](#pdf-pipeline-options)\n- [OCR Configuration](#ocr-configuration)\n- [Advanced Options](#advanced-options)\n\n## DocumentConverter Initialization\n\n### Basic Initialization\n\n```python\nfrom docling.document_converter import DocumentConverter\n\n# All formats enabled by default\nconverter = DocumentConverter()\n```\n\n### Restricted Formats\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import DocumentConverter\n\n# Only allow specific formats\nconverter = DocumentConverter(\n    allowed_formats=[\n        InputFormat.PDF,\n        InputFormat.DOCX,\n        InputFormat.HTML\n    ]\n)\n```\n\n### Custom Format Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\n# Configure PDF-specific pipeline\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n## Single File Conversion\n\n### Basic Conversion\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\n\n# From file path (str or Path)\nresult = converter.convert(\"document.pdf\")\nresult = converter.convert(Path(\"document.pdf\"))\n```\n\n### With Options\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\n\nresult = converter.convert(\n    \"document.pdf\",\n    max_num_pages=100,           # Limit to 100 pages\n    max_file_size=20_971_520,    # 20 MB limit\n    page_range=[5, 15],           # Only pages 5-15\n    raises_on_error=True          # Raise on conversion failure\n)\n```\n\n### Result Handling\n\n```python\nfrom docling.datamodel.base_models import ConversionStatus\n\nresult = converter.convert(\"document.pdf\")\n\n# Check status\nif result.status == ConversionStatus.SUCCESS:\n    doc = result.document\n    markdown = doc.export_to_markdown()\nelif result.status == ConversionStatus.PARTIAL_SUCCESS:\n    print(f\"Partial success with {len(result.errors)} errors\")\n    for error in result.errors:\n        print(f\"  {error.error_message}\")\nelse:  # FAILURE\n    print(\"Conversion failed\")\n```\n\n## URL Conversion\n\n### HTTP/HTTPS URLs\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\n\n# Convert from URL\nresult = converter.convert(\"https://arxiv.org/pdf/2408.09869\")\nresult = converter.convert(\"http://example.com/document.docx\")\n```\n\n### With Headers\n\n```python\nconverter = DocumentConverter()\n\nresult = converter.convert(\n    \"https://example.com/protected.pdf\",\n    headers={\"Authorization\": \"Bearer token123\"}\n)\n```\n\n## Binary Stream Conversion\n\n### From BytesIO\n\n```python\nfrom io import BytesIO\nfrom docling.datamodel.base_models import DocumentStream\nfrom docling.document_converter import DocumentConverter\n\n# Read file into memory\nwith open(\"document.pdf\", \"rb\") as f:\n    buf = BytesIO(f.read())\n\n# Create DocumentStream\nsource = DocumentStream(name=\"document.pdf\", stream=buf)\n\nconverter = DocumentConverter()\nresult = converter.convert(source)\n```\n\n### From Binary Data\n\n```python\nfrom io import BytesIO\nfrom docling.datamodel.base_models import DocumentStream\n\n# Binary data from any source\nbinary_data = get_pdf_bytes()  # Your function\nbuf = BytesIO(binary_data)\n\nsource = DocumentStream(name=\"my_doc.pdf\", stream=buf)\nresult = converter.convert(source)\n```\n\n### String Content\n\nFor Markdown and HTML, you can convert string content directly:\n\n```python\nconverter = DocumentConverter()\n\n# Markdown string\nresult = converter.convert_string(\n    content=\"# Title\\n\\nParagraph text\",\n    format=InputFormat.MD,\n    name=\"my_markdown\"  # Optional\n)\n\n# HTML string\nresult = converter.convert_string(\n    content=\"<h1>Title</h1><p>Paragraph</p>\",\n    format=InputFormat.HTML,\n    name=\"my_html\"\n)\n```\n\n## Format-Specific Options\n\n### PDF Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = True\npipeline_options.generate_page_images = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n### Image Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, ImageFormatOption\n\n# Images use same pipeline as PDFs\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n### Markdown Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.backend_options import MarkdownBackendOptions\nfrom docling.document_converter import DocumentConverter, MarkdownFormatOption\n\nbackend_options = MarkdownBackendOptions()\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.MD: MarkdownFormatOption(backend_options=backend_options)\n    }\n)\n```\n\n### HTML Options\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.backend_options import HTMLBackendOptions\nfrom docling.document_converter import DocumentConverter, HTMLFormatOption\n\nbackend_options = HTMLBackendOptions()\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.HTML: HTMLFormatOption(backend_options=backend_options)\n    }\n)\n```\n\n## PDF Pipeline Options\n\n### Layout and Structure\n\n```python\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\n\n# Enable/disable features\npipeline_options.do_ocr = True                    # OCR for scanned PDFs\npipeline_options.do_table_structure = True        # Table structure recognition\npipeline_options.do_picture_classification = True # Classify images\npipeline_options.do_code_enrichment = True        # Code block detection\npipeline_options.do_formula_enrichment = True     # Formula detection\n\n# Page image generation (needed for HTML export with images)\npipeline_options.generate_page_images = True\n```\n\n### Table Structure Options\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    TableFormerMode\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_table_structure = True\n\n# Cell matching: map structure to PDF cells (default: True)\npipeline_options.table_structure_options.do_cell_matching = True\n\n# Accuracy mode\npipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # or FAST\n```\n\n### Model Artifacts Path\n\nFor offline/air-gapped environments:\n\n```python\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions(\n    artifacts_path=\"/local/path/to/models\"\n)\n```\n\n## OCR Configuration\n\n### EasyOCR (Default)\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    EasyOcrOptions\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\n\n# Configure language(s)\npipeline_options.ocr_options = EasyOcrOptions(\n    lang=[\"en\"],              # Single language\n    # lang=[\"en\", \"es\", \"de\"],  # Multiple languages\n)\n```\n\n### Tesseract\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    TesseractOcrOptions\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractOcrOptions()\n```\n\n### Tesseract CLI\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    TesseractCliOcrOptions\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractCliOcrOptions()\n```\n\n### macOS System OCR\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    OcrMacOptions\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = OcrMacOptions()\n```\n\n### RapidOCR\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    RapidOcrOptions\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = RapidOcrOptions()\n```\n\n\n### GPU Acceleration\n\n```python\nfrom docling.datamodel.accelerator_options import (\n    AcceleratorDevice,\n    AcceleratorOptions\n)\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\n\n# Auto-detect best device\npipeline_options.accelerator_options = AcceleratorOptions(\n    device=AcceleratorDevice.AUTO,\n    num_threads=4\n)\n\n# Force CPU\npipeline_options.accelerator_options = AcceleratorOptions(\n    device=AcceleratorDevice.CPU,\n    num_threads=8\n)\n\n# Force GPU\npipeline_options.accelerator_options = AcceleratorOptions(\n    device=AcceleratorDevice.CUDA  # or MPS for Apple Silicon\n)\n```\n\n## Advanced Options\n\n### Pipeline Initialization\n\nPre-initialize pipelines to avoid lazy loading during first conversion:\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\n\n# Initialize pipeline for specific format\nconverter.initialize_pipeline(InputFormat.PDF)\n```\n\n### Remote Services\n\nFor cloud-based OCR or models:\n\n```python\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\npipeline_options.enable_remote_services = True  # Required for API-based models\n```\n\n### Model Download\n\nPrefetch models for offline use:\n\n```python\nfrom docling.utils.model_downloader import download_models\n\n# Download all default models\ndownload_models(target_dir=\"/local/path/to/models\")\n```\n\nOr via CLI:\n\n```bash\ndocling-tools models download\ndocling-tools models download-hf-repo ds4sd/SmolDocling-256M-preview\n```\n\n### Environment Variables\n\n```bash\n# Set artifacts path via environment\nexport DOCLING_ARTIFACTS_PATH=\"/local/path/to/models\"\n\n# Limit CPU threads\nexport OMP_NUM_THREADS=4\n\n# Run your script\npython convert_docs.py\n```\n\n### Resource Limits\n\n```python\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\n\nresult = converter.convert(\n    \"large_doc.pdf\",\n    max_file_size=52_428_800,   # 50 MB max\n    max_num_pages=500,          # 500 pages max\n    page_range=[1, 100]         # Only first 100 pages\n)\n```\n\n### Error Control\n\n```python\n# Raise on first error (default)\nresult = converter.convert(\"doc.pdf\", raises_on_error=True)\n\n# Continue on error\nresult = converter.convert(\"doc.pdf\", raises_on_error=False)\nif result.status != ConversionStatus.SUCCESS:\n    print(f\"Failed with errors: {result.errors}\")\n```\n\n## Common Patterns\n\n### Multi-Format Converter\n\n```python\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\n# Configure different options per format\npdf_options = PdfPipelineOptions()\npdf_options.do_ocr = True\npdf_options.do_table_structure = True\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)\n    }\n)\n\n# Handles PDFs with custom options, other formats with defaults\nresult1 = converter.convert(\"document.pdf\")\nresult2 = converter.convert(\"document.docx\")\nresult3 = converter.convert(\"document.html\")\n```\n\n### OCR-Only PDF Processing\n\n```python\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = False\npipeline_options.do_picture_classification = False\npipeline_options.do_code_enrichment = False\npipeline_options.do_formula_enrichment = False\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n### Fast Table Extraction\n\n```python\nfrom docling.datamodel.pipeline_options import (\n    PdfPipelineOptions,\n    TableFormerMode\n)\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = False  # Disable OCR for speed\npipeline_options.do_table_structure = True\npipeline_options.table_structure_options.mode = TableFormerMode.FAST\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n",
        "skills/docs-style/SKILL.md": "---\nname: docs-style\ndescription: Core technical documentation writing principles for voice, tone, structure, and LLM-friendly patterns. Use when writing or reviewing any documentation.\n---\n\n# Documentation Style Guide\n\nApply these principles when writing or reviewing documentation to ensure clarity, consistency, and accessibility for both human readers and LLMs.\n\n## Voice and Tone\n\n### Use Second Person\n\nAddress the reader directly as \"you\" rather than \"the user\" or \"developers.\"\n\n```markdown\n<!-- Good -->\nYou can configure the API by setting environment variables.\n\n<!-- Avoid -->\nThe user can configure the API by setting environment variables.\nDevelopers should configure the API by setting environment variables.\n```\n\n### Prefer Active Voice\n\nWrite sentences where the subject performs the action. Active voice is clearer and more direct.\n\n```markdown\n<!-- Good -->\nCreate a configuration file in the root directory.\nThe function returns an array of user objects.\n\n<!-- Avoid -->\nA configuration file should be created in the root directory.\nAn array of user objects is returned by the function.\n```\n\n### Be Concise\n\nCut unnecessary words. Every word should earn its place.\n\n```markdown\n<!-- Good -->\nRun the install command.\n\n<!-- Avoid -->\nIn order to proceed, you will need to run the install command.\n```\n\n```markdown\n<!-- Good -->\nThis endpoint returns user data.\n\n<!-- Avoid -->\nThis endpoint is used for the purpose of returning user data.\n```\n\nCommon phrases to simplify:\n\n| Instead of | Use |\n|------------|-----|\n| in order to | to |\n| for the purpose of | to, for |\n| in the event that | if |\n| at this point in time | now |\n| due to the fact that | because |\n| it is necessary to | you must |\n| is able to | can |\n| make use of | use |\n\n## Document Structure\n\n### Write Clear, Descriptive Headings\n\nHeadings should tell readers exactly what the section contains. Avoid clever or vague titles.\n\n```markdown\n<!-- Good -->\n## Install the CLI\n## Configure Authentication\n## Handle Rate Limits\n\n<!-- Avoid -->\n## Getting Started (vague)\n## The Fun Part (clever)\n## Misc (uninformative)\n```\n\n### Create Self-Contained Pages\n\nAssume readers may land on any page directly from search. Each page should:\n\n- Explain what the feature/concept is\n- State prerequisites clearly\n- Provide complete context for the topic\n\n```markdown\n<!-- Good: Self-contained -->\n# Webhooks\n\nWebhooks let you receive real-time notifications when events occur in your account.\n\n## Prerequisites\n\n- An active API key with webhook permissions\n- A publicly accessible HTTPS endpoint\n\n## Create a Webhook\n\n...\n```\n\n### Use Semantic Markup\n\nChoose the right format for the content type:\n\n- **Headings**: Follow proper hierarchy (h1 > h2 > h3, never skip levels)\n- **Lists**: Use for multiple related items\n- **Tables**: Use for structured data with consistent attributes\n- **Code blocks**: Use for any code, commands, or file paths\n\n```markdown\n<!-- Good: Table for structured data -->\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| api_key | string | Yes | Your API key |\n| timeout | integer | No | Request timeout in seconds |\n\n<!-- Good: List for steps or options -->\nTo authenticate, you can:\n- Use an API key in the header\n- Use OAuth 2.0\n- Use a service account\n```\n\n### Make Content Skimmable\n\nBreak dense paragraphs into digestible chunks:\n\n- Keep paragraphs to 3-4 sentences maximum\n- Use bullet points for lists of items\n- Add subheadings to long sections\n- Put key information first (inverted pyramid)\n\n```markdown\n<!-- Good: Skimmable -->\n## Error Handling\n\nThe API returns standard HTTP status codes.\n\n### Common Errors\n\n- **400 Bad Request**: Invalid parameters. Check the request body.\n- **401 Unauthorized**: Invalid or missing API key.\n- **429 Too Many Requests**: Rate limit exceeded. Wait and retry.\n\n### Retry Strategy\n\nFor 429 errors, use exponential backoff starting at 1 second.\n```\n\n## Consistency\n\n### Use One Term Per Concept\n\nPick a term and use it consistently. Switching terms confuses readers.\n\n```markdown\n<!-- Good: Consistent terminology -->\nGenerate an API key in the dashboard. Use your API key in the Authorization header.\n\n<!-- Avoid: Inconsistent terminology -->\nGenerate an API key in the dashboard. Use your API token in the Authorization header.\n```\n\nDocument your terminology choices:\n\n| Concept | Use | Don't use |\n|---------|-----|-----------|\n| Authentication credential | API key | API token, secret key, access key |\n| Configuration file | config file | settings file, preferences file |\n| Command line | CLI | terminal, command prompt, shell |\n\n### Apply Consistent Formatting\n\nUse the same formatting for similar content types:\n\n- **UI elements**: Bold (Click **Save**)\n- **Code/commands**: Backticks (`npm install`)\n- **File paths**: Backticks (`/etc/config.yaml`)\n- **Key terms on first use**: Bold or italics\n- **Placeholders**: SCREAMING_CASE or angle brackets (`YOUR_API_KEY` or `<api-key>`)\n\n## LLM-Friendly Patterns\n\n### State Prerequisites Explicitly\n\nList what users need before starting. This helps both humans and LLMs understand context.\n\n```markdown\n## Prerequisites\n\nBefore you begin, ensure you have:\n\n- Node.js 18 or later installed\n- An active account with admin permissions\n- Your API key (find it in **Settings > API**)\n```\n\n### Define Acronyms on First Use\n\nSpell out acronyms the first time they appear on a page.\n\n```markdown\n<!-- Good -->\nThe CLI (Command Line Interface) provides tools for managing your resources.\nSubsequent uses can just say \"CLI.\"\n\n<!-- Avoid -->\nThe CLI provides tools for managing your resources.\n```\n\n### Provide Complete, Runnable Code Examples\n\nCode examples should work when copied. Include:\n\n- All necessary imports\n- Realistic placeholder values\n- Expected output (when helpful)\n\n```markdown\n<!-- Good: Complete example -->\n```python\nimport requests\n\nAPI_KEY = \"your-api-key\"\nBASE_URL = \"https://api.example.com/v1\"\n\nresponse = requests.get(\n    f\"{BASE_URL}/users\",\n    headers={\"Authorization\": f\"Bearer {API_KEY}\"}\n)\n\nprint(response.json())\n# Output: {\"users\": [{\"id\": 1, \"name\": \"Alice\"}, ...]}\n```\n\n<!-- Avoid: Incomplete snippet -->\n```python\nresponse = requests.get(url, headers=headers)\n```\n```\n\n### Write Descriptive Titles and Meta Descriptions\n\nPage titles and descriptions help with search and LLM understanding.\n\n```markdown\n---\ntitle: \"Authentication - API Reference\"\ndescription: \"Learn how to authenticate API requests using API keys, OAuth 2.0, or service accounts.\"\n---\n```\n\n## Pitfalls to Avoid\n\n### Don't Use Product-Centric Language\n\nOrient documentation around user goals, not product features.\n\n```markdown\n<!-- Good: User-goal oriented -->\n# Send Emails\n\nSend transactional emails to your users with delivery tracking.\n\n<!-- Avoid: Product-centric -->\n# Email Service\n\nOur powerful email service provides enterprise-grade delivery.\n```\n\n### Skip Obvious Instructions\n\nDon't document self-explanatory UI actions.\n\n```markdown\n<!-- Good: Meaningful instruction -->\nEnter your webhook URL. The URL must use HTTPS and be publicly accessible.\n\n<!-- Avoid: Obvious instruction -->\nClick in the text field. Type your webhook URL. Click the Save button.\n```\n\n### Avoid Colloquialisms\n\nColloquialisms hurt clarity and localization.\n\n```markdown\n<!-- Good -->\nThis approach significantly improves performance.\n\n<!-- Avoid -->\nThis approach is a game-changer for performance.\nThis will blow your mind.\nLet's dive in!\n```\n\n## Quick Reference Checklist\n\nWhen writing documentation, verify:\n\n- [ ] Using \"you\" instead of \"the user\"\n- [ ] Active voice throughout\n- [ ] No unnecessary words\n- [ ] Headings are descriptive\n- [ ] Page is self-contained\n- [ ] Proper heading hierarchy\n- [ ] One term per concept\n- [ ] Prerequisites listed\n- [ ] Acronyms defined\n- [ ] Code examples are complete\n- [ ] No product-centric language\n- [ ] No colloquialisms\n\n## Applying This Skill\n\nUse these principles when:\n\n1. **Writing new documentation**: Apply all principles from the start\n2. **Reviewing documentation**: Check against the quick reference checklist\n3. **Editing existing docs**: Prioritize voice/tone, then structure, then consistency\n4. **Creating code examples**: Ensure they are complete and runnable\n",
        "skills/explanation-docs/SKILL.md": "---\nname: explanation-docs\ndescription: Explanation documentation patterns for understanding-oriented content - conceptual guides that explain why things work the way they do\nautoContext:\n  whenUserAsks:\n    - explanation doc\n    - explanation documentation\n    - conceptual guide\n    - conceptual documentation\n    - understanding doc\n    - background doc\n    - design rationale\n    - architecture explanation\n    - how does it work\n    - why does it work\ndependencies:\n  - docs-style\n---\n\n# Explanation Documentation Skill\n\nThis skill provides patterns for writing effective explanation documents. Explanations are understanding-oriented content for readers who want to know why things work the way they do.\n\n## Purpose & Audience\n\n**Target readers:**\n- Users who want to understand concepts deeply, not just use them\n- Architects and technical leads evaluating design decisions\n- Team members onboarding to a codebase or system\n- Anyone asking \"why?\" or \"how does this work?\"\n\n**Explanations are for reading away from the keyboard.** Unlike tutorials or how-to guides, readers aren't trying to accomplish a task while reading. They're building mental models.\n\n**Explanations are NOT:**\n- Tutorials (which teach through hands-on doing)\n- How-To guides (which accomplish specific goals)\n- Reference docs (which look up precise details)\n\n## Explanation Document Template\n\nUse this structure for all explanation documents:\n\n```markdown\n---\ntitle: \"[Concept/System Name] Explained\"\ndescription: \"Understand how [concept] works and why it was designed this way\"\n---\n\n# Understanding [Concept]\n\nBrief intro (2-3 sentences): What this document explains and why it matters. Set expectations for what the reader will understand after reading.\n\n## Overview\n\nHigh-level summary of the concept. What is it? What problem does it solve? This should be understandable without deep technical knowledge.\n\n## Background and Context\n\n### The Problem\n\nWhat situation or challenge led to this design? What were users or developers struggling with?\n\n### Historical Context\n\nHow did we get here? What came before? This helps readers understand why alternatives were rejected or why certain constraints exist.\n\n## How It Works\n\n### Core Concepts\n\nExplain the fundamental ideas. Use analogies to connect to concepts readers already understand.\n\n<Note>\nUse diagrams or visual aids when explaining complex relationships or flows.\n</Note>\n\n### The Mechanism\n\nWalk through how the system actually operates. This is conceptual, not procedural - explain the \"what happens\" rather than \"what to do.\"\n\n### Key Components\n\nBreak down the major parts and how they interact. For each component:\n- What role does it play?\n- How does it relate to other components?\n\n## Design Decisions and Trade-offs\n\n### Why This Approach?\n\nExplain the reasoning behind key design choices. What goals drove these decisions?\n\n### Trade-offs Made\n\nEvery design involves trade-offs. Be explicit about:\n- What was prioritized\n- What was sacrificed\n- Under what conditions this design excels or struggles\n\n### Constraints and Assumptions\n\nWhat constraints shaped the design? What assumptions does it rely on?\n\n## Alternatives Considered\n\n### [Alternative Approach 1]\n\nBrief description of an alternative approach. Why wasn't it chosen? Under what circumstances might it be better?\n\n### [Alternative Approach 2]\n\nAnother alternative. Comparing alternatives helps readers understand the design space.\n\n## Implications and Consequences\n\nWhat does this design mean for:\n- Performance?\n- Scalability?\n- Developer experience?\n- Future extensibility?\n\n## Related Concepts\n\n- [Related Concept 1](/concepts/related-1) - How it connects to this topic\n- [Related Concept 2](/concepts/related-2) - Another related area\n- [Deeper Technical Reference](/reference/detail) - For implementation specifics\n```\n\n## Writing Principles\n\n### Focus on Understanding, Not Doing\n\nExplanations answer \"why?\" and \"how does it work?\" rather than \"how do I?\"\n\n| Explanation (good) | How-To (wrong context) |\n|-------------------|------------------------|\n| \"The cache uses LRU eviction because memory is limited and recent items are more likely to be accessed again.\" | \"To configure the cache, set the `maxSize` parameter.\" |\n| \"Authentication tokens expire to limit the damage if they're compromised.\" | \"Refresh your token by calling the `/refresh` endpoint.\" |\n\n### Use Analogies and Mental Models\n\nConnect unfamiliar concepts to things readers already know.\n\n```markdown\n<!-- Good: Relatable analogy -->\nThink of the message queue like a post office. Messages (letters) are dropped off\nby senders and held until recipients pick them up. The post office doesn't care\nabout the content - it just ensures reliable delivery.\n\n<!-- Avoid: Jumping straight to technical details -->\nThe message queue implements a FIFO buffer with configurable persistence\nand at-least-once delivery semantics.\n```\n\n### Explain the \"Why\" Behind Design Decisions\n\nDon't just describe what exists - explain why it exists that way.\n\n```markdown\n<!-- Good: Explains rationale -->\nWe chose eventual consistency over strong consistency because our read-heavy\nworkload (100:1 read-to-write ratio) benefits more from low latency than from\nimmediate consistency. Most users never notice the brief delay.\n\n<!-- Avoid: Just states facts -->\nThe system uses eventual consistency with a 500ms propagation window.\n```\n\n### Discuss Trade-offs Honestly\n\nEvery design choice has costs. Acknowledging them builds trust and helps readers make informed decisions.\n\n```markdown\n## Trade-offs\n\nThis architecture optimizes for **write throughput** at the cost of:\n\n- **Read latency**: Queries may need to hit multiple partitions\n- **Complexity**: Developers must understand partition keys\n- **Cost**: More storage due to denormalization\n\nThis trade-off makes sense for our use case (high-volume event ingestion)\nbut may not suit read-heavy analytics workloads.\n```\n\n### Structure for Reflection, Not Action\n\nExplanations are read linearly, away from the keyboard. Structure them like essays, not manuals.\n\n- **Use flowing prose** more than bullet points\n- **Build concepts progressively** - each section prepares for the next\n- **Allow for depth** - it's okay if sections are longer than in how-to guides\n- **Include context** that would be distracting in task-focused docs\n\n### Connect to the Bigger Picture\n\nShow how this concept relates to other parts of the system or to broader industry patterns.\n\n```markdown\n## Related Concepts\n\nOur event sourcing approach is part of our broader CQRS (Command Query\nResponsibility Segregation) architecture. Understanding event sourcing\nhelps explain:\n\n- Why our read models are eventually consistent\n- How we achieve audit logging \"for free\"\n- Why replaying events is central to our testing strategy\n\nFor more on CQRS, see [Understanding Our Architecture](/concepts/cqrs-architecture).\n```\n\n## Components for Explanations\n\n### Diagrams and Visuals\n\nExplanations benefit heavily from visual aids:\n\n```markdown\n## System Architecture\n\nThe following diagram shows how requests flow through the system:\n\n```mermaid\ngraph LR\n    A[Client] --> B[Load Balancer]\n    B --> C[API Gateway]\n    C --> D[Service A]\n    C --> E[Service B]\n    D --> F[(Database)]\n    E --> F\n```\n\nThe load balancer distributes traffic across API gateway instances...\n```\n\n### Comparison Tables\n\nTables work well for comparing approaches:\n\n```markdown\n## Comparing Approaches\n\n| Aspect | Monolith | Microservices |\n|--------|----------|---------------|\n| Deployment | Single unit, simpler | Independent, more complex |\n| Scaling | Vertical | Horizontal per service |\n| Team autonomy | Lower | Higher |\n| Operational overhead | Lower | Higher |\n\nWe chose microservices because team autonomy was critical for our\n100+ engineer organization...\n```\n\n### Callouts for Key Insights\n\n```markdown\n<Note>\nThis is a common source of confusion: the \"eventual\" in eventual consistency\ndoesn't mean \"maybe\" - it means \"not immediately, but guaranteed eventually.\"\n</Note>\n\n<Warning>\nThis design assumes network partitions are rare. In environments with\nunreliable networks, consider stronger consistency guarantees.\n</Warning>\n```\n\n### Expandable Sections for Depth\n\nUse expandables for tangential but valuable details:\n\n```markdown\n<Expandable title=\"Historical note: Why we migrated from Redis\">\nOur original implementation used Redis for caching. In 2023, we migrated\nto a custom solution because...\n\nThis context explains why some older code references Redis patterns\neven though we no longer use it directly.\n</Expandable>\n```\n\n## Example Explanation Document\n\n```markdown\n---\ntitle: \"Understanding Our Authentication System\"\ndescription: \"Learn how authentication works in our platform and why we designed it this way\"\n---\n\n# Understanding Our Authentication System\n\nThis document explains how our authentication system works and the reasoning\nbehind its design. After reading, you'll understand the flow from login to\nAPI access and why we made the architectural choices we did.\n\n## Overview\n\nOur authentication system uses short-lived access tokens with long-lived refresh\ntokens. This pattern, sometimes called \"token rotation,\" balances security with\nuser experience by limiting exposure while avoiding frequent re-authentication.\n\n## Background and Context\n\n### The Problem\n\nModern web applications face competing demands: security teams want frequent\ncredential rotation, while users expect seamless experiences without constant\nlogins. Traditional session-based authentication requires server-side state,\ncomplicating horizontal scaling.\n\n### Historical Context\n\nWe originally used server-side sessions stored in Redis. As we scaled to\nmultiple regions, session synchronization became a bottleneck. JWT tokens\nemerged as an industry standard for stateless authentication, and we adopted\nthem in 2022.\n\n## How It Works\n\n### Core Concepts\n\n**Access tokens** are like day passes at a conference. They grant entry for a\nlimited time and are checked at each door (API endpoint). If someone steals\nyour day pass, they can only use it until it expires.\n\n**Refresh tokens** are like the registration confirmation you used to get your\nday pass. You don't carry it around, but you can use it to get a new day pass\nwhen yours expires.\n\n### The Authentication Flow\n\nWhen a user logs in:\n\n1. They provide credentials to the authentication service\n2. If valid, they receive both an access token (15-minute expiry) and\n   a refresh token (7-day expiry)\n3. The access token is used for API requests\n4. When the access token expires, the refresh token obtains a new one\n5. The old refresh token is invalidated, and a new one is issued\n\nThis rotation means that even if a refresh token is compromised, it can only\nbe used once before the legitimate user's next refresh invalidates it.\n\n### Key Components\n\n**Authentication Service**: Issues and validates tokens. Stateless for access\ntokens, maintains a denylist for revoked refresh tokens.\n\n**API Gateway**: Validates access tokens on every request. Rejects expired or\nmalformed tokens before requests reach backend services.\n\n**Token Store**: Maintains refresh token metadata for revocation. Uses Redis\nwith regional replication.\n\n## Design Decisions and Trade-offs\n\n### Why Short-Lived Access Tokens?\n\nWe chose 15-minute expiry based on our threat model. Shorter expiry limits the\nwindow for stolen token abuse, but more frequent refreshes increase latency\nand auth service load. Our analysis showed 15 minutes balances these concerns\nfor our traffic patterns.\n\n### Trade-offs Made\n\n**Prioritized**: Horizontal scalability, security through token rotation\n**Sacrificed**: Immediate revocation of access tokens, simplicity\n\nAccess tokens remain valid until expiry even after logout. For most use cases,\n15 minutes of continued access is acceptable. For high-security operations\n(password changes, large transfers), we require re-authentication.\n\n### Constraints and Assumptions\n\n- Clients can securely store refresh tokens (HttpOnly cookies for web)\n- Clock skew between servers is under 30 seconds\n- Redis is available for refresh token validation\n\n## Alternatives Considered\n\n### Server-Side Sessions\n\nTraditional sessions would allow immediate revocation but require sticky\nsessions or distributed session storage. We rejected this due to scaling\ncomplexity and regional latency concerns.\n\n### Longer Access Token Expiry\n\nLonger-lived tokens reduce auth service load but increase risk from token\ntheft. Given our security requirements, we prioritized shorter windows.\n\n## Implications and Consequences\n\n**Performance**: Auth service handles ~10K refresh requests per minute. Token\nvalidation is CPU-bound (signature verification), so we scale horizontally.\n\n**Developer Experience**: Services never need database access for auth - they\njust validate JWT signatures. This simplifies service development.\n\n**User Experience**: Most users never notice token refresh. Mobile apps\nrefresh proactively to avoid mid-action expiry.\n\n## Related Concepts\n\n- [API Gateway Architecture](/concepts/api-gateway) - How the gateway validates tokens\n- [Token Security Best Practices](/concepts/token-security) - Secure storage guidance\n- [Authentication API Reference](/reference/auth-api) - Endpoint documentation\n```\n\n## Checklist for Explanations\n\nBefore publishing, verify:\n\n- [ ] Title indicates this explains a concept (not a how-to)\n- [ ] Introduction sets expectations for what reader will understand\n- [ ] Background section provides context and history\n- [ ] Core concepts explained with analogies or mental models\n- [ ] Design decisions include rationale, not just facts\n- [ ] Trade-offs discussed honestly\n- [ ] Alternatives mentioned and compared\n- [ ] Implications for different concerns addressed\n- [ ] Related concepts linked\n- [ ] Written for reading away from keyboard (no tasks to follow)\n- [ ] Progressive structure builds understanding step by step\n\n## When to Use Explanation vs Other Doc Types\n\n| Reader's Question | Doc Type | Focus |\n|------------------|----------|-------|\n| \"How do I do X?\" | How-To Guide | Steps to accomplish a goal |\n| \"Teach me about X\" | Tutorial | Learning through guided doing |\n| \"What is the API for X?\" | Reference | Precise technical details |\n| \"Why does X work this way?\" | **Explanation** | Understanding and context |\n| \"What are the trade-offs of X?\" | **Explanation** | Design rationale |\n| \"How does X relate to Y?\" | **Explanation** | Conceptual connections |\n\n### Explanation Signals\n\nWrite an explanation when users:\n- Ask \"why\" questions\n- Need to make architectural decisions\n- Are evaluating whether something fits their use case\n- Want to understand design philosophy\n- Need context before diving into implementation\n\n### Not an Explanation\n\nIf users need to accomplish something while reading, it's not an explanation:\n- \"How to configure caching\" - How-To Guide\n- \"Cache API reference\" - Reference Doc\n- \"Build a caching layer tutorial\" - Tutorial\n- \"How caching works and why we use LRU\" - **Explanation**\n\n## Related Skills\n\n- **docs-style**: Core writing conventions and components\n- **howto-docs**: How-To guide patterns for task-oriented content\n- **reference-docs**: Reference documentation patterns for lookups\n- **tutorial-docs**: Tutorial patterns for learning-oriented content\n",
        "skills/fastapi-code-review/SKILL.md": "---\nname: fastapi-code-review\ndescription: Reviews FastAPI code for routing patterns, dependency injection, validation, and async handlers. Use when reviewing FastAPI apps, checking APIRouter setup, Depends() usage, or response models.\n---\n\n# FastAPI Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| APIRouter setup, response_model, status codes | [references/routes.md](references/routes.md) |\n| Depends(), yield deps, cleanup, shared deps | [references/dependencies.md](references/dependencies.md) |\n| Pydantic models, HTTPException, 422 handling | [references/validation.md](references/validation.md) |\n| Async handlers, blocking I/O, background tasks | [references/async.md](references/async.md) |\n\n## Review Checklist\n\n- [ ] APIRouter with proper prefix and tags\n- [ ] All routes specify `response_model` for type safety\n- [ ] Correct HTTP methods (GET, POST, PUT, DELETE, PATCH)\n- [ ] Proper status codes (200, 201, 204, 404, etc.)\n- [ ] Dependencies use `Depends()` not manual calls\n- [ ] Yield dependencies have proper cleanup\n- [ ] Request/Response models use Pydantic\n- [ ] HTTPException with status code and detail\n- [ ] All route handlers are `async def`\n- [ ] No blocking I/O (`requests`, `time.sleep`, `open()`)\n- [ ] Background tasks for non-blocking operations\n- [ ] No bare `except` in route handlers\n\n## Valid Patterns (Do NOT Flag)\n\nThese are idiomatic FastAPI patterns that may appear problematic but are correct:\n\n- **Pydantic validates request body automatically** - No manual validation needed when using typed Pydantic models as parameters\n- **Dependency injection for database sessions** - Sessions come from `Depends()`, not passed as function arguments\n- **HTTPException for all HTTP errors** - FastAPI handles conversion to proper HTTP responses\n- **Async def endpoint without await** - May be using sync dependencies or simple operations; FastAPI handles this\n- **Type annotation on Depends()** - This is documentation/IDE support, not a type assertion\n- **Query/Path/Body defaults** - FastAPI processes these at runtime, not traditional Python defaults\n- **Returning dict from endpoint** - Pydantic converts automatically if `response_model` is set\n\n## Context-Sensitive Rules\n\nOnly flag issues when the context warrants it:\n\n- **Flag missing validation** ONLY IF the field isn't already in a Pydantic model with validators\n- **Flag missing auth** ONLY IF the endpoint isn't using `Depends()` with an auth dependency\n- **Flag missing error handling** ONLY IF HTTPException isn't raised appropriately for error cases\n- **Flag sync in async** ONLY IF the operation is actually blocking (file I/O, network calls, CPU-bound), not just non-async\n\n## FastAPI Framework Behaviors\n\nFastAPI + Pydantic handle many concerns automatically:\n- Request validation via Pydantic models\n- Response serialization via response_model\n- Dependency injection for cross-cutting concerns\n- Exception handling via exception handlers\n\nBefore flagging \"missing\" functionality, verify FastAPI isn't handling it.\n\n## When to Load References\n\n- Reviewing route definitions  routes.md\n- Reviewing dependency injection  dependencies.md\n- Reviewing Pydantic models/validation  validation.md\n- Reviewing async route handlers  async.md\n\n## Review Questions\n\n1. Do all routes have explicit response models and status codes?\n2. Are dependencies injected via Depends() with proper cleanup?\n3. Do all Pydantic models validate inputs correctly?\n4. Are all route handlers async and non-blocking?\n\n## Before Submitting Findings\n\nLoad and follow [review-verification-protocol](../review-verification-protocol/SKILL.md) before reporting any issue.\n",
        "skills/fastapi-code-review/references/async.md": "# Async\n\n## Critical Anti-Patterns\n\n### 1. Blocking I/O in Async Handlers\n\n**Problem**: Blocks the event loop, prevents concurrent request handling.\n\n```python\n# BAD - blocking HTTP client\nimport requests\n\n@router.get(\"/external\")\nasync def fetch_external():\n    response = requests.get(\"https://api.example.com\")  # BLOCKS!\n    return response.json()\n\n# GOOD - async HTTP client\nimport httpx\n\n@router.get(\"/external\")\nasync def fetch_external():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com\")\n    return response.json()\n```\n\n### 2. Blocking Database Calls\n\n**Problem**: Synchronous DB driver blocks event loop.\n\n```python\n# BAD - sync SQLAlchemy\nfrom sqlalchemy.orm import Session\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: Session = Depends(get_db)):\n    users = db.query(User).all()  # BLOCKS!\n    return users\n\n# GOOD - async SQLAlchemy\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: AsyncSession = Depends(get_db)):\n    result = await db.execute(select(User))\n    users = result.scalars().all()\n    return users\n```\n\n### 3. Using time.sleep Instead of asyncio.sleep\n\n**Problem**: Blocks event loop during sleep.\n\n```python\n# BAD - blocking sleep\nimport time\n\n@router.post(\"/jobs\")\nasync def create_job():\n    time.sleep(5)  # BLOCKS for 5 seconds!\n    return {\"status\": \"done\"}\n\n# GOOD - async sleep\nimport asyncio\n\n@router.post(\"/jobs\")\nasync def create_job():\n    await asyncio.sleep(5)  # Yields control\n    return {\"status\": \"done\"}\n\n# BETTER - use background tasks for long operations\nfrom fastapi import BackgroundTasks\n\nasync def process_job():\n    await asyncio.sleep(5)\n    # Do actual work\n\n@router.post(\"/jobs\")\nasync def create_job(background_tasks: BackgroundTasks):\n    background_tasks.add_task(process_job)\n    return {\"status\": \"processing\"}\n```\n\n### 4. Sync File I/O in Async Handlers\n\n**Problem**: File operations block event loop.\n\n```python\n# BAD - blocking file I/O\n@router.get(\"/config\")\nasync def get_config():\n    with open(\"config.json\") as f:  # BLOCKS!\n        return json.load(f)\n\n# GOOD - async file I/O\nimport aiofiles\n\n@router.get(\"/config\")\nasync def get_config():\n    async with aiofiles.open(\"config.json\") as f:\n        content = await f.read()\n    return json.loads(content)\n\n# ACCEPTABLE - small files in executor\nimport asyncio\n\ndef read_config_sync():\n    with open(\"config.json\") as f:\n        return json.load(f)\n\n@router.get(\"/config\")\nasync def get_config():\n    loop = asyncio.get_event_loop()\n    config = await loop.run_in_executor(None, read_config_sync)\n    return config\n```\n\n### 5. Not Using Background Tasks\n\n**Problem**: Long operations block response, timeout issues.\n\n```python\n# BAD - blocks response\n@router.post(\"/emails\")\nasync def send_email(email: EmailCreate):\n    await send_email_via_smtp(email)  # Takes 5 seconds!\n    await log_email_sent(email)  # Takes 1 second!\n    return {\"status\": \"sent\"}\n\n# GOOD - use background tasks\nfrom fastapi import BackgroundTasks\n\nasync def send_email_background(email: EmailCreate):\n    await send_email_via_smtp(email)\n    await log_email_sent(email)\n\n@router.post(\"/emails\", status_code=202)\nasync def send_email(\n    email: EmailCreate,\n    background_tasks: BackgroundTasks\n):\n    background_tasks.add_task(send_email_background, email)\n    return {\"status\": \"queued\"}\n```\n\n### 6. Sequential Instead of Concurrent Calls\n\n**Problem**: Misses parallelization opportunity.\n\n```python\n# BAD - sequential (slow)\n@router.get(\"/dashboard\")\nasync def get_dashboard(user_id: int):\n    user = await get_user(user_id)\n    posts = await get_user_posts(user_id)\n    stats = await get_user_stats(user_id)\n    return {\"user\": user, \"posts\": posts, \"stats\": stats}\n\n# GOOD - concurrent (fast)\nimport asyncio\n\n@router.get(\"/dashboard\")\nasync def get_dashboard(user_id: int):\n    user, posts, stats = await asyncio.gather(\n        get_user(user_id),\n        get_user_posts(user_id),\n        get_user_stats(user_id)\n    )\n    return {\"user\": user, \"posts\": posts, \"stats\": stats}\n```\n\n### 7. Mixing Sync and Async Route Handlers\n\n**Problem**: Inconsistent patterns, sync handlers block thread pool.\n\n```python\n# BAD - mixing sync and async\n@router.get(\"/sync-route\")\ndef sync_handler():  # Blocks thread pool\n    return db.query(User).all()\n\n@router.get(\"/async-route\")\nasync def async_handler():\n    return await db.query_async(User)\n\n# GOOD - all async\n@router.get(\"/route1\")\nasync def handler1():\n    result = await db.execute(select(User))\n    return result.scalars().all()\n\n@router.get(\"/route2\")\nasync def handler2():\n    result = await db.execute(select(Post))\n    return result.scalars().all()\n```\n\n### 8. Not Awaiting Coroutines\n\n**Problem**: Coroutine never executes, silent failures.\n\n```python\n# BAD - missing await\n@router.post(\"/users\")\nasync def create_user(user: UserCreate):\n    db.create_user(user)  # Returns coroutine, doesn't execute!\n    return {\"status\": \"created\"}  # User not actually created!\n\n# GOOD - await coroutines\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    created_user = await db.create_user(user)\n    return created_user\n```\n\n### 9. Blocking External API Calls\n\n**Problem**: Synchronous requests library blocks event loop.\n\n```python\n# BAD - requests blocks\nimport requests\n\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    response = requests.get(f\"https://api.weather.com/{city}\")  # BLOCKS!\n    return response.json()\n\n# GOOD - httpx async\nimport httpx\n\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.weather.com/{city}\")\n    return response.json()\n\n# GOOD - with timeout\n@router.get(\"/weather\")\nasync def get_weather(city: str):\n    async with httpx.AsyncClient(timeout=5.0) as client:\n        try:\n            response = await client.get(f\"https://api.weather.com/{city}\")\n            return response.json()\n        except httpx.TimeoutException:\n            raise HTTPException(504, detail=\"Weather API timeout\")\n```\n\n## Review Questions\n\n1. Are all route handlers `async def`?\n2. Are there any `requests`, `time.sleep`, or `open()` calls?\n3. Is the database driver async (AsyncSession, asyncpg, etc.)?\n4. Are background tasks used for long operations?\n5. Are independent async calls parallelized with `gather()`?\n6. Are all coroutines properly awaited?\n7. Are external API calls using async HTTP clients?\n",
        "skills/fastapi-code-review/references/dependencies.md": "# Dependencies\n\n## Critical Anti-Patterns\n\n### 1. Manual Dependency Calls\n\n**Problem**: Bypasses FastAPI's injection system, no automatic cleanup.\n\n```python\n# BAD - manually calling dependency\nasync def get_db_session():\n    session = SessionLocal()\n    return session\n\n@router.get(\"/users\")\nasync def list_users():\n    db = await get_db_session()  # Manual call!\n    users = await db.query(User).all()\n    return users\n\n# GOOD - using Depends()\nfrom fastapi import Depends\n\nasync def get_db_session():\n    session = SessionLocal()\n    try:\n        yield session\n    finally:\n        await session.close()\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(db: Session = Depends(get_db_session)):\n    users = await db.query(User).all()\n    return users\n```\n\n### 2. Missing Cleanup in Yield Dependencies\n\n**Problem**: Resources leak, connections not closed.\n\n```python\n# BAD - no cleanup\nasync def get_db():\n    db = DatabaseConnection()\n    yield db\n    # Connection never closed!\n\n# GOOD - proper cleanup\nasync def get_db():\n    db = DatabaseConnection()\n    try:\n        yield db\n    finally:\n        await db.close()\n```\n\n### 3. Shared State Without Proper Scope\n\n**Problem**: Dependencies create shared mutable state across requests.\n\n```python\n# BAD - shared mutable state\ncache = {}  # Shared across all requests!\n\nasync def get_cache():\n    return cache\n\n@router.get(\"/items/{id}\")\nasync def get_item(id: int, cache: dict = Depends(get_cache)):\n    # Multiple requests share same dict - race conditions!\n    if id not in cache:\n        cache[id] = await fetch_item(id)\n    return cache[id]\n\n# GOOD - request-scoped state\nfrom contextvars import ContextVar\n\nrequest_cache: ContextVar[dict] = ContextVar('request_cache')\n\nasync def get_cache():\n    cache = {}\n    request_cache.set(cache)\n    return cache\n\n# BETTER - use proper caching library\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\nasync def get_item_cached(id: int):\n    return await fetch_item(id)\n```\n\n### 4. Nested Depends Not Utilized\n\n**Problem**: Duplicate code, no composition of dependencies.\n\n```python\n# BAD - duplicated logic\nasync def get_current_user(token: str):\n    # Verify token, decode, fetch user\n    return user\n\nasync def get_admin_user(token: str):\n    # Same verification, then check admin\n    user = await verify_and_decode(token)\n    if not user.is_admin:\n        raise HTTPException(403)\n    return user\n\n# GOOD - compose dependencies\nasync def get_current_user(token: str = Depends(oauth2_scheme)):\n    user = await verify_token(token)\n    if not user:\n        raise HTTPException(401, detail=\"Invalid token\")\n    return user\n\nasync def get_admin_user(user: User = Depends(get_current_user)):\n    if not user.is_admin:\n        raise HTTPException(403, detail=\"Admin required\")\n    return user\n```\n\n### 5. Dependencies with Side Effects\n\n**Problem**: Dependencies modify state instead of providing resources.\n\n```python\n# BAD - dependency has side effects\nasync def log_request(request: Request):\n    # Side effect: writes to database\n    await db.log_request(request)\n    return None\n\n@router.get(\"/users\")\nasync def list_users(_: None = Depends(log_request)):\n    return users\n\n# GOOD - use middleware for cross-cutting concerns\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass LoggingMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        await db.log_request(request)\n        response = await call_next(request)\n        return response\n\napp.add_middleware(LoggingMiddleware)\n\n# OR - dependency returns resource\nasync def get_logger(request: Request):\n    logger = RequestLogger(request)\n    return logger\n\n@router.get(\"/users\")\nasync def list_users(logger: RequestLogger = Depends(get_logger)):\n    logger.info(\"Listing users\")\n    return users\n```\n\n### 6. Class-Based Dependencies Without Caching\n\n**Problem**: New instance created unnecessarily.\n\n```python\n# BAD - new instance every time\nclass DatabaseService:\n    def __init__(self):\n        self.connection_pool = create_pool()  # Expensive!\n\n@router.get(\"/users\")\nasync def list_users(db: DatabaseService = Depends(DatabaseService)):\n    return await db.query_users()\n\n# GOOD - use singleton or app state\nclass DatabaseService:\n    def __init__(self, pool):\n        self.pool = pool\n\nasync def get_db_service(\n    pool = Depends(lambda: app.state.db_pool)\n) -> DatabaseService:\n    return DatabaseService(pool)\n\n# OR - use dependency with cache\nasync def get_db_service() -> DatabaseService:\n    return app.state.db_service\n\n@router.get(\"/users\")\nasync def list_users(db: DatabaseService = Depends(get_db_service)):\n    return await db.query_users()\n```\n\n### 7. Security Dependencies Not Applied Globally\n\n**Problem**: Easy to forget security on new routes.\n\n```python\n# BAD - must remember to add auth to every route\n@router.get(\"/users\", dependencies=[Depends(verify_token)])\nasync def list_users(): ...\n\n@router.get(\"/posts\")  # Forgot auth!\nasync def list_posts(): ...\n\n# GOOD - apply at router level\nrouter = APIRouter(\n    prefix=\"/api/v1\",\n    dependencies=[Depends(verify_token)]\n)\n\n@router.get(\"/users\")\nasync def list_users(): ...\n\n@router.get(\"/posts\")\nasync def list_posts(): ...\n```\n\n## Review Questions\n\n1. Are all dependencies injected via `Depends()` not manually called?\n2. Do yield dependencies have proper `try/finally` cleanup?\n3. Is there any shared mutable state across requests?\n4. Are nested dependencies used to compose common patterns?\n5. Do dependencies provide resources, not perform side effects?\n6. Are security dependencies applied at router or app level?\n",
        "skills/fastapi-code-review/references/routes.md": "# Routes\n\n## Critical Anti-Patterns\n\n### 1. Missing response_model\n\n**Problem**: No type safety, documentation unclear, response not validated.\n\n```python\n# BAD\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    return {\"id\": user_id, \"name\": \"Alice\"}\n\n# GOOD\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int):\n    return {\"id\": user_id, \"name\": \"Alice\"}\n```\n\n### 2. No APIRouter Prefix/Tags\n\n**Problem**: Routes not organized, duplicated path prefixes, unclear docs.\n\n```python\n# BAD\n@app.get(\"/api/v1/users\")\nasync def list_users(): ...\n\n@app.get(\"/api/v1/users/{id}\")\nasync def get_user(id: int): ...\n\n# GOOD\nrouter = APIRouter(prefix=\"/api/v1/users\", tags=[\"users\"])\n\n@router.get(\"\")\nasync def list_users(): ...\n\n@router.get(\"/{id}\")\nasync def get_user(id: int): ...\n\napp.include_router(router)\n```\n\n### 3. Wrong HTTP Methods\n\n**Problem**: Violates REST conventions, confusing semantics.\n\n```python\n# BAD - using GET for mutations\n@router.get(\"/users/{id}/delete\")\nasync def delete_user(id: int): ...\n\n# BAD - using POST for retrieval\n@router.post(\"/users/{id}\")\nasync def get_user(id: int): ...\n\n# GOOD\n@router.delete(\"/users/{id}\", status_code=204)\nasync def delete_user(id: int): ...\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int): ...\n```\n\n### 4. Missing Status Codes\n\n**Problem**: Always returns 200, even for creates/deletes.\n\n```python\n# BAD - creates should return 201\n@router.post(\"/users\")\nasync def create_user(user: UserCreate):\n    return created_user\n\n# BAD - deletes should return 204\n@router.delete(\"/users/{id}\")\nasync def delete_user(id: int):\n    return {\"message\": \"deleted\"}\n\n# GOOD\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    return created_user\n\n@router.delete(\"/users/{id}\", status_code=204)\nasync def delete_user(id: int):\n    # 204 returns no content\n    return None\n```\n\n### 5. Direct Exception Raising\n\n**Problem**: Returns generic 500 errors instead of proper HTTP status codes.\n\n```python\n# BAD\n@router.get(\"/users/{id}\")\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise ValueError(\"User not found\")\n    return user\n\n# GOOD\nfrom fastapi import HTTPException\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n```\n\n### 6. Multiple Response Models\n\n**Problem**: Same endpoint returns different schemas.\n\n```python\n# BAD\n@router.get(\"/users/{id}\")\nasync def get_user(id: int, full: bool = False):\n    if full:\n        return UserDetailResponse(...)\n    return UserSummaryResponse(...)\n\n# GOOD - use separate endpoints\n@router.get(\"/users/{id}\", response_model=UserSummaryResponse)\nasync def get_user(id: int):\n    return UserSummaryResponse(...)\n\n@router.get(\"/users/{id}/full\", response_model=UserDetailResponse)\nasync def get_user_full(id: int):\n    return UserDetailResponse(...)\n\n# ALTERNATIVE - use response_model with Union\nfrom typing import Union\n\n@router.get(\"/users/{id}\", response_model=Union[UserSummaryResponse, UserDetailResponse])\nasync def get_user(id: int, full: bool = False):\n    if full:\n        return UserDetailResponse(...)\n    return UserSummaryResponse(...)\n```\n\n### 7. Path Parameter Validation\n\n**Problem**: No validation on path parameters.\n\n```python\n# BAD\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    # What if user_id is negative or zero?\n    return await db.get_user(user_id)\n\n# GOOD\nfrom fastapi import Path\n\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int = Path(..., gt=0)):\n    return await db.get_user(user_id)\n```\n\n## Review Questions\n\n1. Does every route have an explicit `response_model`?\n2. Are routes organized with APIRouter using prefix and tags?\n3. Are HTTP methods semantically correct (GET for read, POST for create, etc.)?\n4. Do create operations return 201? Do deletes return 204?\n5. Are HTTPExceptions used instead of generic exceptions?\n6. Are path parameters validated?\n",
        "skills/fastapi-code-review/references/validation.md": "# Validation\n\n## Critical Anti-Patterns\n\n### 1. Manual Validation Instead of Pydantic\n\n**Problem**: Duplicate validation logic, inconsistent errors.\n\n```python\n# BAD - manual validation\n@router.post(\"/users\")\nasync def create_user(request: Request):\n    data = await request.json()\n    if \"email\" not in data:\n        raise HTTPException(400, \"Email required\")\n    if \"@\" not in data[\"email\"]:\n        raise HTTPException(400, \"Invalid email\")\n    return await db.create_user(data)\n\n# GOOD - Pydantic validation\nfrom pydantic import BaseModel, EmailStr\n\nclass UserCreate(BaseModel):\n    email: EmailStr\n    name: str\n    age: int | None = None\n\n@router.post(\"/users\", response_model=UserResponse, status_code=201)\nasync def create_user(user: UserCreate):\n    return await db.create_user(user)\n```\n\n### 2. Missing Field Validators\n\n**Problem**: Invalid data passes through.\n\n```python\n# BAD - no validation on age\nclass UserCreate(BaseModel):\n    name: str\n    age: int  # Can be negative!\n\n# GOOD - field validation\nfrom pydantic import BaseModel, Field\n\nclass UserCreate(BaseModel):\n    name: str = Field(..., min_length=1, max_length=100)\n    age: int = Field(..., ge=0, le=150)\n    email: EmailStr\n```\n\n### 3. Generic HTTPException Messages\n\n**Problem**: Users don't know what's wrong.\n\n```python\n# BAD - vague error\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    user = await db.get_user(user_id)\n    if not user:\n        raise HTTPException(404)  # No detail!\n    return user\n\n# GOOD - specific error\n@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int):\n    user = await db.get_user(user_id)\n    if not user:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"User {user_id} not found\"\n        )\n    return user\n```\n\n### 4. Not Using Pydantic Config\n\n**Problem**: Models accept extra fields, expose internal fields.\n\n```python\n# BAD - accepts any extra fields\nclass UserCreate(BaseModel):\n    name: str\n    email: str\n    # {\"name\": \"Alice\", \"email\": \"a@b.com\", \"is_admin\": true} accepted!\n\n# GOOD - strict validation\nclass UserCreate(BaseModel):\n    name: str\n    email: EmailStr\n\n    class Config:\n        extra = \"forbid\"  # Reject unknown fields\n\n# GOOD - control ORM exposure\nclass UserResponse(BaseModel):\n    id: int\n    name: str\n    email: str\n    # Don't expose password_hash, created_at, etc.\n\n    class Config:\n        from_attributes = True  # Formerly orm_mode\n```\n\n### 5. Missing Custom Validators\n\n**Problem**: Business rules not enforced.\n\n```python\n# BAD - no validation\nclass PasswordReset(BaseModel):\n    password: str\n    confirm_password: str\n    # Passwords might not match!\n\n# GOOD - custom validator\nfrom pydantic import BaseModel, model_validator\n\nclass PasswordReset(BaseModel):\n    password: str = Field(..., min_length=8)\n    confirm_password: str\n\n    @model_validator(mode='after')\n    def passwords_match(self):\n        if self.password != self.confirm_password:\n            raise ValueError('Passwords do not match')\n        return self\n```\n\n### 6. Not Handling 422 Validation Errors\n\n**Problem**: Default 422 responses unclear to clients.\n\n```python\n# BAD - default 422 response is verbose and unclear\n# (No custom handler)\n\n# GOOD - custom 422 handler\nfrom fastapi import Request, status\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\n@app.exception_handler(RequestValidationError)\nasync def validation_exception_handler(\n    request: Request,\n    exc: RequestValidationError\n):\n    errors = []\n    for error in exc.errors():\n        errors.append({\n            \"field\": \".\".join(str(x) for x in error[\"loc\"][1:]),\n            \"message\": error[\"msg\"],\n            \"type\": error[\"type\"]\n        })\n\n    return JSONResponse(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        content={\"detail\": errors}\n    )\n```\n\n### 7. Using Dict Instead of Models\n\n**Problem**: No validation, no type safety, unclear API.\n\n```python\n# BAD - dict responses\n@router.get(\"/users/{id}\")\nasync def get_user(id: int) -> dict:\n    return {\n        \"id\": id,\n        \"name\": \"Alice\",\n        \"extra_field\": \"oops\"  # Inconsistent!\n    }\n\n# GOOD - Pydantic response model\nclass UserResponse(BaseModel):\n    id: int\n    name: str\n    email: str\n\n@router.get(\"/users/{id}\", response_model=UserResponse)\nasync def get_user(id: int):\n    user = await db.get_user(id)\n    if not user:\n        raise HTTPException(404, detail=\"User not found\")\n    return user  # Auto-validates and filters fields\n```\n\n### 8. Missing Query Parameter Validation\n\n**Problem**: Invalid query parameters not validated.\n\n```python\n# BAD - no validation\n@router.get(\"/users\")\nasync def list_users(page: int = 1, size: int = 10):\n    # What if page is 0 or negative?\n    # What if size is 10000?\n    return await db.get_users(page, size)\n\n# GOOD - validated query params\nfrom fastapi import Query\n\n@router.get(\"/users\", response_model=list[UserResponse])\nasync def list_users(\n    page: int = Query(1, ge=1),\n    size: int = Query(10, ge=1, le=100)\n):\n    return await db.get_users(page, size)\n```\n\n## Review Questions\n\n1. Are all request bodies defined as Pydantic models?\n2. Do fields have proper validators (min_length, ge, EmailStr, etc.)?\n3. Do HTTPExceptions include detailed error messages?\n4. Are models configured with `extra = \"forbid\"` to reject unknown fields?\n5. Are custom validators used for business rules?\n6. Are query parameters validated with `Query()`?\n7. Are response models used instead of plain dicts?\n",
        "skills/github-projects/SKILL.md": "---\nname: github-projects\ndescription: GitHub Projects management via gh CLI for creating projects, managing items, fields, and workflows. Use when working with GitHub Projects (v2), adding issues/PRs to projects, creating custom fields, tracking project items, or automating project workflows. Triggers on gh project, project board, kanban, GitHub project, project items.\n---\n\n# GitHub Projects CLI\n\nGitHub Projects (v2) management via `gh project` commands. Requires the `project` scope which can be added with `gh auth refresh -s project`.\n\n## Prerequisites\n\nVerify authentication includes project scope:\n\n```bash\ngh auth status  # Check current scopes\ngh auth refresh -s project  # Add project scope if missing\n```\n\n## Quick Reference\n\n### List & View Projects\n\n```bash\n# List your projects\ngh project list\n\n# List org projects (including closed)\ngh project list --owner ORG_NAME --closed\n\n# View project details\ngh project view PROJECT_NUM --owner OWNER\n\n# Open in browser\ngh project view PROJECT_NUM --owner OWNER --web\n\n# JSON output with jq filtering\ngh project list --format json | jq '.projects[] | {number, title}'\n```\n\n### Create & Edit Projects\n\n```bash\n# Create project\ngh project create --owner OWNER --title \"Project Title\"\n\n# Edit project\ngh project edit PROJECT_NUM --owner OWNER --title \"New Title\"\ngh project edit PROJECT_NUM --owner OWNER --description \"New description\"\ngh project edit PROJECT_NUM --owner OWNER --visibility PUBLIC\n\n# Close/reopen project\ngh project close PROJECT_NUM --owner OWNER\ngh project close PROJECT_NUM --owner OWNER --undo  # Reopen\n```\n\n### Link Projects to Repos\n\n```bash\n# Link to repo\ngh project link PROJECT_NUM --owner OWNER --repo REPO_NAME\n\n# Link to team\ngh project link PROJECT_NUM --owner ORG --team TEAM_NAME\n\n# Unlink\ngh project unlink PROJECT_NUM --owner OWNER --repo REPO_NAME\n```\n\n## Project Items\n\n### Add Existing Issues/PRs\n\n```bash\n# Add issue to project\ngh project item-add PROJECT_NUM --owner OWNER --url https://github.com/OWNER/REPO/issues/123\n\n# Add PR to project\ngh project item-add PROJECT_NUM --owner OWNER --url https://github.com/OWNER/REPO/pull/456\n```\n\n### Create Draft Items\n\n```bash\ngh project item-create PROJECT_NUM --owner OWNER --title \"Draft item\" --body \"Description\"\n```\n\n### List Items\n\n```bash\n# List items (default 30)\ngh project item-list PROJECT_NUM --owner OWNER\n\n# List more items\ngh project item-list PROJECT_NUM --owner OWNER --limit 100\n\n# JSON output\ngh project item-list PROJECT_NUM --owner OWNER --format json\n```\n\n### Edit Items\n\nItems are edited by their ID (obtained from `item-list --format json`).\n\n```bash\n# Edit draft issue title/body\ngh project item-edit --id ITEM_ID --title \"New Title\" --body \"New body\"\n\n# Update field value (requires field-id and project-id)\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --text \"value\"\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --number 42\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --date \"2024-12-31\"\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --single-select-option-id OPTION_ID\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --iteration-id ITER_ID\n\n# Clear field value\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID --field-id FIELD_ID --clear\n```\n\n### Archive/Delete Items\n\n```bash\ngh project item-archive PROJECT_NUM --owner OWNER --id ITEM_ID\ngh project item-delete PROJECT_NUM --owner OWNER --id ITEM_ID\n```\n\n## Project Fields\n\n### List Fields\n\n```bash\ngh project field-list PROJECT_NUM --owner OWNER\ngh project field-list PROJECT_NUM --owner OWNER --format json\n```\n\n### Create Fields\n\n```bash\n# Text field\ngh project field-create PROJECT_NUM --owner OWNER --name \"Notes\" --data-type TEXT\n\n# Number field\ngh project field-create PROJECT_NUM --owner OWNER --name \"Points\" --data-type NUMBER\n\n# Date field\ngh project field-create PROJECT_NUM --owner OWNER --name \"Due Date\" --data-type DATE\n\n# Single select with options\ngh project field-create PROJECT_NUM --owner OWNER --name \"Priority\" \\\n  --data-type SINGLE_SELECT \\\n  --single-select-options \"Low,Medium,High,Critical\"\n```\n\n### Delete Fields\n\n```bash\ngh project field-delete --id FIELD_ID\n```\n\n## Common Workflows\n\n### Add Issue and Set Status\n\n```bash\n# 1. Add issue to project\ngh project item-add 1 --owner \"@me\" --url https://github.com/owner/repo/issues/123\n\n# 2. Get item ID and field IDs\ngh project item-list 1 --owner \"@me\" --format json | jq '.items[-1]'\ngh project field-list 1 --owner \"@me\" --format json\n\n# 3. Update status field\ngh project item-edit --id ITEM_ID --project-id PROJECT_ID \\\n  --field-id STATUS_FIELD_ID --single-select-option-id OPTION_ID\n```\n\n### Bulk Add Issues\n\n```bash\n# Add all open issues from a repo\ngh issue list --repo owner/repo --state open --json url -q '.[].url' | \\\n  xargs -I {} gh project item-add 1 --owner \"@me\" --url {}\n```\n\n## JSON Output & jq Patterns\n\n```bash\n# Get project IDs\ngh project list --format json | jq '.projects[] | {number, id, title}'\n\n# Get field IDs and options\ngh project field-list 1 --owner \"@me\" --format json | jq '.fields[] | {id, name, options}'\n\n# Get item IDs with field values\ngh project item-list 1 --owner \"@me\" --format json | jq '.items[] | {id, title, fieldValues}'\n\n# Filter items by status\ngh project item-list 1 --owner \"@me\" --format json | \\\n  jq '.items[] | select(.status == \"In Progress\")'\n```\n\n## Reference Files\n\n- **[items.md](references/items.md)**: Item management, editing field values, bulk operations\n- **[fields.md](references/fields.md)**: Field types, creating custom fields, option management\n\n## Command Summary\n\n| Command | Purpose |\n|---------|---------|\n| `project list` | List projects |\n| `project view` | View project details |\n| `project create` | Create new project |\n| `project edit` | Modify project settings |\n| `project close` | Close/reopen project |\n| `project link/unlink` | Connect to repo/team |\n| `project item-add` | Add existing issue/PR |\n| `project item-create` | Create draft item |\n| `project item-list` | List project items |\n| `project item-edit` | Update item fields |\n| `project item-archive` | Archive item |\n| `project item-delete` | Remove item |\n| `project field-list` | List project fields |\n| `project field-create` | Add custom field |\n| `project field-delete` | Remove field |\n",
        "skills/github-projects/references/fields.md": "# GitHub Project Fields Reference\n\nDetailed reference for managing project fields via `gh project field-*` commands.\n\n## Built-in Fields\n\nEvery project includes these system fields:\n- **Title** - Item name (from issue/PR title or draft title)\n- **Assignees** - Assigned users\n- **Status** - Single select workflow status\n- **Labels** - Issue/PR labels (read-only in project)\n- **Milestone** - Issue/PR milestone (read-only)\n- **Repository** - Source repository\n- **Reviewers** - PR reviewers\n\n## Custom Field Types\n\n| Type | Flag Value | Description |\n|------|------------|-------------|\n| Text | `TEXT` | Free-form text |\n| Number | `NUMBER` | Numeric values |\n| Date | `DATE` | Date picker (YYYY-MM-DD) |\n| Single Select | `SINGLE_SELECT` | Dropdown with predefined options |\n| Iteration | `ITERATION` | Sprint/iteration cycles |\n\n## Listing Fields\n\n```bash\ngh project field-list PROJECT_NUM --owner OWNER\n```\n\nOptions:\n| Flag | Default | Description |\n|------|---------|-------------|\n| `-L, --limit` | 30 | Max fields to fetch |\n| `--format json` | - | JSON output |\n| `-q, --jq` | - | jq filter expression |\n\n### JSON Structure\n\n```json\n{\n  \"fields\": [\n    {\n      \"id\": \"PVTF_xxx\",\n      \"name\": \"Status\",\n      \"type\": \"SINGLE_SELECT\",\n      \"options\": [\n        {\"id\": \"opt1\", \"name\": \"Todo\"},\n        {\"id\": \"opt2\", \"name\": \"In Progress\"},\n        {\"id\": \"opt3\", \"name\": \"Done\"}\n      ]\n    },\n    {\n      \"id\": \"PVTF_yyy\",\n      \"name\": \"Points\",\n      \"type\": \"NUMBER\"\n    }\n  ]\n}\n```\n\n### Useful jq Filters\n\n```bash\n# List all field names and types\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq '.fields[] | {name, type}'\n\n# Get specific field ID\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq -r '.fields[] | select(.name == \"Status\") | .id'\n\n# Get single select options\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq '.fields[] | select(.type == \"SINGLE_SELECT\") | {name, options}'\n\n# Get option ID by name\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq -r '.fields[] | select(.name == \"Priority\") | .options[] | select(.name == \"High\") | .id'\n```\n\n## Creating Fields\n\n### Text Field\n```bash\ngh project field-create PROJECT_NUM --owner OWNER \\\n  --name \"Notes\" \\\n  --data-type TEXT\n```\n\n### Number Field\n```bash\ngh project field-create PROJECT_NUM --owner OWNER \\\n  --name \"Story Points\" \\\n  --data-type NUMBER\n```\n\n### Date Field\n```bash\ngh project field-create PROJECT_NUM --owner OWNER \\\n  --name \"Due Date\" \\\n  --data-type DATE\n```\n\n### Single Select Field\n\n```bash\ngh project field-create PROJECT_NUM --owner OWNER \\\n  --name \"Priority\" \\\n  --data-type SINGLE_SELECT \\\n  --single-select-options \"Low,Medium,High,Critical\"\n```\n\nOptions are comma-separated. Field is created with all options.\n\n## Deleting Fields\n\n```bash\ngh project field-delete --id FIELD_ID\n```\n\nGet field ID from `field-list --format json`. Deleting removes the field and all its values from items.\n\n## Working with Single Select Options\n\n### Get Option IDs\n\n```bash\n# Get all options for a field\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq '.fields[] | select(.name == \"Status\") | .options[] | {id, name}'\n```\n\n### Set Item to Specific Option\n\n```bash\n# Get IDs\nPROJECT_ID=$(gh project list --format json | jq -r '.projects[0].id')\nFIELD_ID=$(gh project field-list 1 --owner \"@me\" --format json | \\\n  jq -r '.fields[] | select(.name == \"Status\") | .id')\nOPTION_ID=$(gh project field-list 1 --owner \"@me\" --format json | \\\n  jq -r '.fields[] | select(.name == \"Status\") | .options[] | select(.name == \"Done\") | .id')\n\n# Update item\ngh project item-edit --id ITEM_ID \\\n  --project-id \"$PROJECT_ID\" \\\n  --field-id \"$FIELD_ID\" \\\n  --single-select-option-id \"$OPTION_ID\"\n```\n\n## Working with Iterations\n\nIterations are managed via the web UI. The CLI can:\n- List iteration field IDs\n- Set items to specific iterations\n\n```bash\n# Get iteration field\ngh project field-list 1 --owner \"@me\" --format json | \\\n  jq '.fields[] | select(.type == \"ITERATION\")'\n\n# Set item to iteration\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id ITERATION_FIELD_ID \\\n  --iteration-id ITERATION_ID\n```\n\n## Field Patterns\n\n### Priority Field\n```bash\ngh project field-create 1 --owner \"@me\" \\\n  --name \"Priority\" \\\n  --data-type SINGLE_SELECT \\\n  --single-select-options \"P0 - Critical,P1 - High,P2 - Medium,P3 - Low\"\n```\n\n### Effort/Points Field\n```bash\ngh project field-create 1 --owner \"@me\" \\\n  --name \"Points\" \\\n  --data-type NUMBER\n```\n\n### Due Date Field\n```bash\ngh project field-create 1 --owner \"@me\" \\\n  --name \"Due Date\" \\\n  --data-type DATE\n```\n\n### Team Field\n```bash\ngh project field-create 1 --owner \"@me\" \\\n  --name \"Team\" \\\n  --data-type SINGLE_SELECT \\\n  --single-select-options \"Frontend,Backend,DevOps,Design\"\n```\n\n## Complete Setup Example\n\n```bash\n#!/bin/bash\n# Set up a new project with common fields\n\nPROJECT_NUM=1\nOWNER=\"@me\"\n\n# Create Status field (usually exists by default)\n# gh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n#   --name \"Status\" --data-type SINGLE_SELECT \\\n#   --single-select-options \"Backlog,Todo,In Progress,In Review,Done\"\n\n# Priority\ngh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n  --name \"Priority\" --data-type SINGLE_SELECT \\\n  --single-select-options \"P0,P1,P2,P3\"\n\n# Story Points\ngh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n  --name \"Points\" --data-type NUMBER\n\n# Due Date\ngh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n  --name \"Due Date\" --data-type DATE\n\n# Team\ngh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n  --name \"Team\" --data-type SINGLE_SELECT \\\n  --single-select-options \"Engineering,Product,Design\"\n\n# Notes\ngh project field-create $PROJECT_NUM --owner \"$OWNER\" \\\n  --name \"Notes\" --data-type TEXT\n\necho \"Project fields configured\"\ngh project field-list $PROJECT_NUM --owner \"$OWNER\"\n```\n\n## Limitations\n\n- Cannot modify single select options after creation (must delete and recreate field)\n- Cannot create iteration fields via CLI (use web UI)\n- Some built-in fields are read-only (Labels, Milestone, Repository)\n- Field names must be unique within a project\n",
        "skills/github-projects/references/items.md": "# GitHub Project Items Reference\n\nDetailed reference for managing project items via `gh project item-*` commands.\n\n## Item Types\n\nProjects can contain:\n- **Issues** - Added via URL\n- **Pull Requests** - Added via URL\n- **Draft Issues** - Created directly in project\n\n## Adding Items\n\n### Add Issue or PR\n\n```bash\ngh project item-add PROJECT_NUM --owner OWNER --url ISSUE_OR_PR_URL\n```\n\nOptions:\n| Flag | Description |\n|------|-------------|\n| `--url` | URL of issue/PR to add |\n| `--owner` | Project owner (`@me` for current user) |\n| `--format json` | JSON output with item ID |\n\nExample:\n```bash\n# Add and capture item ID\nITEM=$(gh project item-add 1 --owner \"@me\" \\\n  --url https://github.com/org/repo/issues/42 \\\n  --format json | jq -r '.id')\necho \"Added item: $ITEM\"\n```\n\n### Create Draft Item\n\n```bash\ngh project item-create PROJECT_NUM --owner OWNER --title \"Title\" --body \"Description\"\n```\n\nDraft items exist only within the project (not linked to any issue).\n\n## Listing Items\n\n```bash\ngh project item-list PROJECT_NUM --owner OWNER [flags]\n```\n\n| Flag | Default | Description |\n|------|---------|-------------|\n| `-L, --limit` | 30 | Max items to fetch |\n| `--format json` | - | JSON output |\n| `-q, --jq` | - | jq filter expression |\n\n### JSON Structure\n\n```json\n{\n  \"items\": [\n    {\n      \"id\": \"PVTI_xxx\",\n      \"title\": \"Issue title\",\n      \"number\": 42,\n      \"type\": \"ISSUE\",\n      \"url\": \"https://github.com/...\",\n      \"status\": \"In Progress\",\n      \"repository\": \"owner/repo\"\n    }\n  ]\n}\n```\n\n### Useful jq Filters\n\n```bash\n# Get all item IDs\ngh project item-list 1 --owner \"@me\" --format json | jq -r '.items[].id'\n\n# Filter by status\ngh project item-list 1 --owner \"@me\" --format json | \\\n  jq '.items[] | select(.status == \"Todo\")'\n\n# Get items with specific label (requires API query for labels)\ngh project item-list 1 --owner \"@me\" --format json | \\\n  jq '.items[] | select(.type == \"ISSUE\")'\n```\n\n## Editing Items\n\nItems are edited using their ID (from `item-list --format json`).\n\n### Edit Draft Issue Content\n\n```bash\ngh project item-edit --id ITEM_ID --title \"New title\"\ngh project item-edit --id ITEM_ID --body \"New description\"\ngh project item-edit --id ITEM_ID --title \"Title\" --body \"Body\"\n```\n\n### Edit Field Values\n\nRequires `--project-id` and `--field-id`. Get these from:\n```bash\n# Get project ID\ngh project list --format json | jq '.projects[] | {number, id}'\n\n# Get field IDs\ngh project field-list PROJECT_NUM --owner OWNER --format json | jq '.fields[] | {id, name}'\n```\n\n#### Text Fields\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --text \"Field value\"\n```\n\n#### Number Fields\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --number 42\n```\n\n#### Date Fields\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --date \"2024-12-31\"\n```\n\n#### Single Select Fields\n\nGet option IDs first:\n```bash\ngh project field-list PROJECT_NUM --owner OWNER --format json | \\\n  jq '.fields[] | select(.name == \"Status\") | .options'\n```\n\nThen set:\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --single-select-option-id OPTION_ID\n```\n\n#### Iteration Fields\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --iteration-id ITERATION_ID\n```\n\n#### Clear Field Value\n```bash\ngh project item-edit --id ITEM_ID \\\n  --project-id PROJECT_ID \\\n  --field-id FIELD_ID \\\n  --clear\n```\n\n## Archive & Delete\n\n### Archive (Hide)\n```bash\ngh project item-archive PROJECT_NUM --owner OWNER --id ITEM_ID\n```\n\nArchived items can be restored via the web UI.\n\n### Delete (Permanent)\n```bash\ngh project item-delete PROJECT_NUM --owner OWNER --id ITEM_ID\n```\n\nRemoves item from project. For issues/PRs, the underlying item still exists.\n\n## Bulk Operations\n\n### Add All Open Issues\n```bash\ngh issue list --repo owner/repo --state open --json url -q '.[].url' | \\\n  while read url; do\n    gh project item-add PROJECT_NUM --owner OWNER --url \"$url\"\n  done\n```\n\n### Add Issues with Label\n```bash\ngh issue list --repo owner/repo --label \"project-x\" --json url -q '.[].url' | \\\n  xargs -I {} gh project item-add PROJECT_NUM --owner OWNER --url {}\n```\n\n### Update Multiple Items\n```bash\n# Get item IDs and update each\ngh project item-list PROJECT_NUM --owner OWNER --format json | \\\n  jq -r '.items[] | select(.status == \"Todo\") | .id' | \\\n  while read id; do\n    gh project item-edit --id \"$id\" \\\n      --project-id PROJECT_ID \\\n      --field-id FIELD_ID \\\n      --single-select-option-id NEW_STATUS_ID\n  done\n```\n\n## Complete Workflow Example\n\n```bash\n#!/bin/bash\n# Add issue to project and set initial status\n\nPROJECT_NUM=1\nOWNER=\"@me\"\nISSUE_URL=\"https://github.com/org/repo/issues/42\"\n\n# 1. Get project ID\nPROJECT_ID=$(gh project list --format json | \\\n  jq -r --arg num \"$PROJECT_NUM\" '.projects[] | select(.number == ($num | tonumber)) | .id')\n\n# 2. Get Status field ID and \"In Progress\" option ID\nFIELD_DATA=$(gh project field-list $PROJECT_NUM --owner \"$OWNER\" --format json)\nSTATUS_FIELD=$(echo \"$FIELD_DATA\" | jq -r '.fields[] | select(.name == \"Status\") | .id')\nIN_PROGRESS_ID=$(echo \"$FIELD_DATA\" | jq -r '.fields[] | select(.name == \"Status\") | .options[] | select(.name == \"In Progress\") | .id')\n\n# 3. Add issue to project\nITEM_ID=$(gh project item-add $PROJECT_NUM --owner \"$OWNER\" --url \"$ISSUE_URL\" --format json | jq -r '.id')\n\n# 4. Set status to \"In Progress\"\ngh project item-edit --id \"$ITEM_ID\" \\\n  --project-id \"$PROJECT_ID\" \\\n  --field-id \"$STATUS_FIELD\" \\\n  --single-select-option-id \"$IN_PROGRESS_ID\"\n\necho \"Added item $ITEM_ID with status 'In Progress'\"\n```\n",
        "skills/go-code-review/SKILL.md": "---\nname: go-code-review\ndescription: Reviews Go code for idiomatic patterns, error handling, concurrency safety, and common mistakes. Use when reviewing .go files, checking error handling, goroutine usage, or interface design.\n---\n\n# Go Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Missing error checks, wrapped errors | [references/error-handling.md](references/error-handling.md) |\n| Race conditions, channel misuse | [references/concurrency.md](references/concurrency.md) |\n| Interface pollution, naming | [references/interfaces.md](references/interfaces.md) |\n| Resource leaks, defer misuse | [references/common-mistakes.md](references/common-mistakes.md) |\n\n## Review Checklist\n\n- [ ] All errors are checked (no `_ = err`)\n- [ ] Errors wrapped with context (`fmt.Errorf(\"...: %w\", err)`)\n- [ ] Resources closed with `defer` immediately after creation\n- [ ] No goroutine leaks (channels closed, contexts canceled)\n- [ ] Interfaces defined by consumers, not producers\n- [ ] Interface names end in `-er` (Reader, Writer, Handler)\n- [ ] Exported names have doc comments\n- [ ] No naked returns in functions > 5 lines\n- [ ] Context passed as first parameter\n- [ ] Mutexes protect shared state, not methods\n\n## When to Load References\n\n- Reviewing error return patterns  error-handling.md\n- Reviewing goroutines/channels  concurrency.md\n- Reviewing type definitions  interfaces.md\n- General Go review  common-mistakes.md\n\n## Review Questions\n\n1. Are all error returns checked and wrapped?\n2. Are goroutines properly managed with context cancellation?\n3. Are resources (files, connections) closed with defer?\n4. Are interfaces minimal and defined where used?\n\n## Valid Patterns (Do NOT Flag)\n\nThese patterns are acceptable and should NOT be flagged as issues:\n\n- **`_ = err` with reason comment** - Intentionally ignored errors with explanation\n  ```go\n  _ = conn.Close() // Best effort cleanup, already handling primary error\n  ```\n- **Empty interface `interface{}`** - For truly generic code (pre-generics codebases)\n- **Naked returns in short functions** - Acceptable in functions < 5 lines with named returns\n- **Channel without close** - When consumer stops via context cancellation, not channel close\n- **Mutex protecting struct fields** - Even if accessed only via methods, this is correct encapsulation\n- **`//nolint` directives with reason** - Acceptable when accompanied by explanation\n  ```go\n  //nolint:errcheck // Error logged but not returned per API contract\n  ```\n- **Defer in loop** - When function scope cleanup is intentional (e.g., processing files in batches)\n\n## Context-Sensitive Rules\n\nOnly flag these issues when the specific conditions apply:\n\n| Issue | Flag ONLY IF |\n|-------|--------------|\n| Missing error check | Error return is actionable (can retry, log, or propagate) |\n| Goroutine leak | No context cancellation path exists for the goroutine |\n| Missing defer | Resource isn't explicitly closed before next acquisition or return |\n| Interface pollution | Interface has > 1 method AND only one consumer exists |\n\n## Before Submitting Findings\n\nLoad and follow [review-verification-protocol](../review-verification-protocol/SKILL.md) before reporting any issue.\n",
        "skills/go-code-review/references/common-mistakes.md": "# Common Mistakes\n\n## Resource Leaks\n\n### 1. Missing defer for Close\n\n**Problem**: Resources leaked on early return.\n\n```go\n// BAD\nfunc readFile(path string) ([]byte, error) {\n    f, err := os.Open(path)\n    if err != nil {\n        return nil, err\n    }\n    data, err := io.ReadAll(f)\n    if err != nil {\n        return nil, err  // file never closed!\n    }\n    f.Close()\n    return data, nil\n}\n\n// GOOD - defer immediately\nfunc readFile(path string) ([]byte, error) {\n    f, err := os.Open(path)\n    if err != nil {\n        return nil, err\n    }\n    defer f.Close()\n    return io.ReadAll(f)\n}\n```\n\n### 2. Defer in Loop\n\n**Problem**: Resources accumulate until function returns.\n\n```go\n// BAD - files stay open until loop ends\nfor _, path := range paths {\n    f, _ := os.Open(path)\n    defer f.Close()  // deferred until function returns\n    process(f)\n}\n\n// GOOD - close in each iteration or use closure\nfor _, path := range paths {\n    func() {\n        f, _ := os.Open(path)\n        defer f.Close()\n        process(f)\n    }()\n}\n```\n\n### 3. HTTP Response Body Not Closed\n\n**Problem**: Connection pool exhaustion.\n\n```go\n// BAD\nresp, err := http.Get(url)\nif err != nil {\n    return err\n}\n// body never closed!\ndata, _ := io.ReadAll(resp.Body)\n\n// GOOD\nresp, err := http.Get(url)\nif err != nil {\n    return err\n}\ndefer resp.Body.Close()\ndata, _ := io.ReadAll(resp.Body)\n```\n\n## Naming and Style\n\n### 4. Stuttering Names\n\n**Problem**: Redundant when used with package name.\n\n```go\n// BAD\npackage user\ntype UserService struct { ... }  // user.UserService\n\n// GOOD\npackage user\ntype Service struct { ... }  // user.Service\n```\n\n### 5. Missing Doc Comments on Exports\n\n**Problem**: godoc can't generate documentation.\n\n```go\n// BAD\nfunc NewServer(addr string) *Server { ... }\n\n// GOOD\n// NewServer creates a new HTTP server listening on addr.\nfunc NewServer(addr string) *Server { ... }\n```\n\n### 6. Naked Returns in Long Functions\n\n**Problem**: Hard to track what's being returned.\n\n```go\n// BAD\nfunc process(data []byte) (result string, err error) {\n    // 50 lines of code...\n\n    return  // what's being returned?\n}\n\n// GOOD - explicit returns\nfunc process(data []byte) (string, error) {\n    // 50 lines of code...\n\n    return processedString, nil\n}\n```\n\n## Initialization\n\n### 7. Init Function Overuse\n\n**Problem**: Hidden side effects, hard to test.\n\n```go\n// BAD - global state via init\nvar db *sql.DB\n\nfunc init() {\n    var err error\n    db, err = sql.Open(\"postgres\", os.Getenv(\"DATABASE_URL\"))\n    if err != nil {\n        log.Fatal(err)\n    }\n}\n\n// GOOD - explicit initialization\ntype App struct {\n    db *sql.DB\n}\n\nfunc NewApp(dbURL string) (*App, error) {\n    db, err := sql.Open(\"postgres\", dbURL)\n    if err != nil {\n        return nil, fmt.Errorf(\"opening db: %w\", err)\n    }\n    return &App{db: db}, nil\n}\n```\n\n### 8. Global Mutable State\n\n**Problem**: Race conditions, hard to test.\n\n```go\n// BAD\nvar config Config\n\nfunc GetConfig() Config {\n    return config\n}\n\n// GOOD - dependency injection\ntype Server struct {\n    config Config\n}\n\nfunc NewServer(cfg Config) *Server {\n    return &Server{config: cfg}\n}\n```\n\n## Performance\n\n### 9. String Concatenation in Loop\n\n**Problem**: O(n) allocation overhead.\n\n```go\n// BAD\nvar result string\nfor _, s := range items {\n    result += s + \", \"\n}\n\n// GOOD\nvar b strings.Builder\nfor _, s := range items {\n    b.WriteString(s)\n    b.WriteString(\", \")\n}\nresult := b.String()\n```\n\n### 10. Slice Preallocation\n\n**Problem**: Repeated reallocations.\n\n```go\n// BAD - grows dynamically\nvar results []Result\nfor _, item := range items {\n    results = append(results, process(item))\n}\n\n// GOOD - preallocate known size\nresults := make([]Result, 0, len(items))\nfor _, item := range items {\n    results = append(results, process(item))\n}\n```\n\n## Testing\n\n### 11. Table-Driven Tests Missing\n\n**Problem**: Verbose, repetitive test code.\n\n```go\n// BAD\nfunc TestAdd(t *testing.T) {\n    if Add(1, 2) != 3 {\n        t.Error(\"1+2 should be 3\")\n    }\n    if Add(0, 0) != 0 {\n        t.Error(\"0+0 should be 0\")\n    }\n}\n\n// GOOD\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        a, b, want int\n    }{\n        {1, 2, 3},\n        {0, 0, 0},\n        {-1, 1, 0},\n    }\n    for _, tt := range tests {\n        got := Add(tt.a, tt.b)\n        if got != tt.want {\n            t.Errorf(\"Add(%d, %d) = %d, want %d\", tt.a, tt.b, got, tt.want)\n        }\n    }\n}\n```\n\n## Review Questions\n\n1. Is `defer Close()` called immediately after opening resources?\n2. Are HTTP response bodies always closed?\n3. Are package-level names not stuttering with package name?\n4. Do exported symbols have doc comments?\n5. Is mutable global state avoided?\n6. Are slices preallocated when size is known?\n",
        "skills/go-code-review/references/concurrency.md": "# Concurrency\n\n## Critical Anti-Patterns\n\n### 1. Goroutine Leak\n\n**Problem**: Goroutines block forever, consuming memory.\n\n```go\n// BAD - no way to stop the goroutine\nfunc startWorker() {\n    go func() {\n        for {\n            doWork()\n        }\n    }()\n}\n\n// GOOD - context cancellation\nfunc startWorker(ctx context.Context) {\n    go func() {\n        for {\n            select {\n            case <-ctx.Done():\n                return\n            default:\n                doWork()\n            }\n        }\n    }()\n}\n```\n\n### 2. Unbounded Channel Send\n\n**Problem**: Sender blocks forever if receiver dies.\n\n```go\n// BAD - blocks if nobody reads\nch <- result\n\n// GOOD - respect context\nselect {\ncase ch <- result:\ncase <-ctx.Done():\n    return ctx.Err()\n}\n```\n\n### 3. Closing Channel Multiple Times\n\n**Problem**: Panic at runtime.\n\n```go\n// BAD - potential double close\nclose(ch)\nclose(ch)  // panic!\n\n// GOOD - only sender closes, once\nfunc produce(ch chan<- int) {\n    defer close(ch)  // close happens exactly once\n    for i := 0; i < 10; i++ {\n        ch <- i\n    }\n}\n```\n\n### 4. Race Condition on Shared State\n\n**Problem**: Data corruption, undefined behavior.\n\n```go\n// BAD - concurrent map access\nvar cache = make(map[string]int)\nfunc Get(key string) int {\n    return cache[key]  // race!\n}\nfunc Set(key string, val int) {\n    cache[key] = val  // race!\n}\n\n// GOOD - mutex protection\nvar (\n    cache   = make(map[string]int)\n    cacheMu sync.RWMutex\n)\nfunc Get(key string) int {\n    cacheMu.RLock()\n    defer cacheMu.RUnlock()\n    return cache[key]\n}\nfunc Set(key string, val int) {\n    cacheMu.Lock()\n    defer cacheMu.Unlock()\n    cache[key] = val\n}\n\n// BETTER - sync.Map for simple cases\nvar cache sync.Map\nfunc Get(key string) (int, bool) {\n    v, ok := cache.Load(key)\n    if !ok {\n        return 0, false\n    }\n    return v.(int), true\n}\n```\n\n### 5. Missing WaitGroup\n\n**Problem**: Program exits before goroutines complete.\n\n```go\n// BAD - may exit before done\nfor _, item := range items {\n    go process(item)\n}\nreturn  // goroutines may not finish\n\n// GOOD\nvar wg sync.WaitGroup\nfor _, item := range items {\n    wg.Add(1)\n    go func(item Item) {\n        defer wg.Done()\n        process(item)\n    }(item)\n}\nwg.Wait()\n```\n\n### 6. Loop Variable Capture\n\n**Problem**: All goroutines see the same variable value.\n\n```go\n// BAD (pre-Go 1.22)\nfor _, item := range items {\n    go func() {\n        process(item)  // all see last item!\n    }()\n}\n\n// GOOD - capture in closure\nfor _, item := range items {\n    go func(item Item) {\n        process(item)\n    }(item)\n}\n\n// Note: Go 1.22+ fixes this by default\n```\n\n### 7. Context Not Propagated\n\n**Problem**: Can't cancel downstream operations.\n\n```go\n// BAD\nfunc Handler(ctx context.Context) error {\n    result := doWork()  // ignores ctx\n    return nil\n}\n\n// GOOD\nfunc Handler(ctx context.Context) error {\n    result, err := doWork(ctx)  // passes ctx\n    if err != nil {\n        return err\n    }\n    return nil\n}\n```\n\n## Worker Pool Pattern\n\n```go\nfunc processItems(ctx context.Context, items []Item) error {\n    const workers = 5\n\n    jobs := make(chan Item)\n    errs := make(chan error, 1)\n\n    var wg sync.WaitGroup\n    for i := 0; i < workers; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for item := range jobs {\n                if err := process(ctx, item); err != nil {\n                    select {\n                    case errs <- err:\n                    default:\n                    }\n                    return\n                }\n            }\n        }()\n    }\n\n    go func() {\n        wg.Wait()\n        close(errs)\n    }()\n\n    for _, item := range items {\n        select {\n        case jobs <- item:\n        case err := <-errs:\n            return err\n        case <-ctx.Done():\n            return ctx.Err()\n        }\n    }\n    close(jobs)\n\n    return <-errs\n}\n```\n\n## Review Questions\n\n1. Are all goroutines stoppable via context?\n2. Are channels always closed by the sender?\n3. Is shared state protected by mutex or sync types?\n4. Are WaitGroups used to wait for goroutine completion?\n5. Is context passed through the call chain?\n",
        "skills/go-code-review/references/error-handling.md": "# Error Handling\n\n## Critical Anti-Patterns\n\n### 1. Ignoring Errors\n\n**Problem**: Silent failures are impossible to debug.\n\n```go\n// BAD\nfile, _ := os.Open(\"config.json\")\ndata, _ := io.ReadAll(file)\n\n// GOOD\nfile, err := os.Open(\"config.json\")\nif err != nil {\n    return fmt.Errorf(\"opening config: %w\", err)\n}\ndefer file.Close()\n```\n\n### 2. Unwrapped Errors\n\n**Problem**: Loses context for debugging.\n\n```go\n// BAD - raw error\nif err != nil {\n    return err\n}\n\n// GOOD - wrapped with context\nif err != nil {\n    return fmt.Errorf(\"loading user %d: %w\", userID, err)\n}\n```\n\n### 3. String Errors Instead of Wrapping\n\n**Problem**: Breaks error inspection with `errors.Is/As`.\n\n```go\n// BAD\nreturn fmt.Errorf(\"failed: %s\", err.Error())\n\n// GOOD - preserves error chain\nreturn fmt.Errorf(\"failed: %w\", err)\n```\n\n### 4. Panic for Recoverable Errors\n\n**Problem**: Crashes the program unexpectedly.\n\n```go\n// BAD\nfunc GetConfig(path string) Config {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        panic(err)  // Never panic for expected errors\n    }\n    ...\n}\n\n// GOOD\nfunc GetConfig(path string) (Config, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return Config{}, fmt.Errorf(\"reading config: %w\", err)\n    }\n    ...\n}\n```\n\n### 5. Checking Error String Instead of Type\n\n**Problem**: Brittle, breaks with error message changes.\n\n```go\n// BAD\nif err.Error() == \"file not found\" {\n    ...\n}\n\n// GOOD\nif errors.Is(err, os.ErrNotExist) {\n    ...\n}\n\n// For custom errors\nvar ErrNotFound = errors.New(\"not found\")\nif errors.Is(err, ErrNotFound) {\n    ...\n}\n```\n\n### 6. Returning Error and Valid Value\n\n**Problem**: Confuses callers about error semantics.\n\n```go\n// BAD - what does partial result mean?\nfunc Parse(s string) (int, error) {\n    if s == \"\" {\n        return -1, errors.New(\"empty string\")  // -1 is valid integer\n    }\n    ...\n}\n\n// GOOD - zero value on error\nfunc Parse(s string) (int, error) {\n    if s == \"\" {\n        return 0, errors.New(\"empty string\")\n    }\n    ...\n}\n```\n\n## Sentinel Errors Pattern\n\n```go\n// Define at package level\nvar (\n    ErrNotFound     = errors.New(\"not found\")\n    ErrUnauthorized = errors.New(\"unauthorized\")\n)\n\n// Usage\nfunc GetUser(id int) (*User, error) {\n    user := db.Find(id)\n    if user == nil {\n        return nil, ErrNotFound\n    }\n    return user, nil\n}\n\n// Caller checks\nif errors.Is(err, ErrNotFound) {\n    http.Error(w, \"User not found\", 404)\n}\n```\n\n## Review Questions\n\n1. Are all error returns checked (no `_`)?\n2. Are errors wrapped with context using `%w`?\n3. Are sentinel errors used for expected error conditions?\n4. Does the code use `errors.Is/As` instead of string matching?\n5. Does it return zero values alongside errors?\n",
        "skills/go-code-review/references/interfaces.md": "# Interfaces\n\n## Critical Anti-Patterns\n\n### 1. Premature Interface Definition\n\n**Problem**: Interfaces defined before needed, creating abstraction overhead.\n\n```go\n// BAD - interface in producer package\npackage storage\n\ntype UserRepository interface {\n    Get(id int) (*User, error)\n    Save(user *User) error\n}\n\ntype PostgresUserRepository struct { ... }\n\n// GOOD - interface in consumer package\npackage service\n\ntype UserGetter interface {\n    Get(id int) (*User, error)\n}\n\nfunc NewUserService(users UserGetter) *UserService {\n    return &UserService{users: users}\n}\n```\n\n### 2. Interface Pollution (Too Many Methods)\n\n**Problem**: Hard to implement, hard to mock, violates ISP.\n\n```go\n// BAD - fat interface\ntype UserStore interface {\n    Get(id int) (*User, error)\n    GetAll() ([]*User, error)\n    Save(user *User) error\n    Delete(id int) error\n    Search(query string) ([]*User, error)\n    Count() (int, error)\n    // ... 10 more methods\n}\n\n// GOOD - focused interfaces\ntype UserGetter interface {\n    Get(id int) (*User, error)\n}\n\ntype UserSaver interface {\n    Save(user *User) error\n}\n\ntype UserStore interface {\n    UserGetter\n    UserSaver\n}\n```\n\n### 3. Wrong Interface Names\n\n**Problem**: Doesn't follow Go conventions, less readable.\n\n```go\n// BAD\ntype IUserService interface { ... }  // Java-style prefix\ntype UserServiceInterface { ... }    // redundant suffix\ntype UserManager interface { ... }   // vague noun\n\n// GOOD - verb forms ending in -er\ntype UserReader interface {\n    ReadUser(id int) (*User, error)\n}\n\ntype UserWriter interface {\n    WriteUser(user *User) error\n}\n```\n\n### 4. Returning Interface Instead of Concrete Type\n\n**Problem**: Hides implementation details unnecessarily.\n\n```go\n// BAD - returns interface\nfunc NewServer(addr string) Server {\n    return &httpServer{addr: addr}\n}\n\n// GOOD - returns concrete type\nfunc NewServer(addr string) *HTTPServer {\n    return &HTTPServer{addr: addr}\n}\n```\n\n### 5. Empty Interface Overuse\n\n**Problem**: Loses type safety, requires type assertions.\n\n```go\n// BAD\nfunc Process(data interface{}) interface{} {\n    switch v := data.(type) {\n    case string:\n        return strings.ToUpper(v)\n    case int:\n        return v * 2\n    }\n    return nil\n}\n\n// GOOD - use generics (Go 1.18+)\nfunc Process[T string | int](data T) T {\n    // type-safe processing\n}\n\n// Or use specific types\nfunc ProcessString(data string) string\nfunc ProcessInt(data int) int\n```\n\n### 6. Interface for Single Implementation\n\n**Problem**: Unnecessary abstraction with no benefit.\n\n```go\n// BAD - interface with only one implementation\ntype ConfigLoader interface {\n    Load() (*Config, error)\n}\n\ntype fileConfigLoader struct { ... }\n\n// GOOD - just use the concrete type\ntype ConfigLoader struct { ... }\n\nfunc (c *ConfigLoader) Load() (*Config, error) { ... }\n```\n\n## Accept Interfaces, Return Structs\n\n```go\n// Function accepts interface (flexible)\nfunc WriteData(w io.Writer, data []byte) error {\n    _, err := w.Write(data)\n    return err\n}\n\n// Function returns concrete type (explicit)\nfunc NewBuffer() *bytes.Buffer {\n    return &bytes.Buffer{}\n}\n\n// Usage\nbuf := NewBuffer()\nWriteData(buf, []byte(\"hello\"))  // Buffer implements io.Writer\n```\n\n## Standard Library Interfaces to Use\n\n```go\n// io.Reader - anything that can be read from\ntype Reader interface {\n    Read(p []byte) (n int, err error)\n}\n\n// io.Writer - anything that can be written to\ntype Writer interface {\n    Write(p []byte) (n int, err error)\n}\n\n// io.Closer - anything that can be closed\ntype Closer interface {\n    Close() error\n}\n\n// fmt.Stringer - custom string representation\ntype Stringer interface {\n    String() string\n}\n\n// error - the error interface\ntype error interface {\n    Error() string\n}\n```\n\n## Review Questions\n\n1. Are interfaces defined where they're used (consumer side)?\n2. Are interfaces minimal (1-3 methods)?\n3. Do interface names end in `-er`?\n4. Are concrete types returned from constructors?\n5. Is `interface{}` avoided in favor of generics or specific types?\n",
        "skills/go-testing-code-review/SKILL.md": "---\nname: go-testing-code-review\ndescription: Reviews Go test code for proper table-driven tests, assertions, and coverage patterns. Use when reviewing *_test.go files.\n---\n\n# Go Testing Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Test structure, naming | [references/structure.md](references/structure.md) |\n| Mocking, interfaces | [references/mocking.md](references/mocking.md) |\n\n## Review Checklist\n\n- [ ] Tests are table-driven with clear case names\n- [ ] Subtests use t.Run for parallel execution\n- [ ] Test names describe behavior, not implementation\n- [ ] Errors include got/want with descriptive message\n- [ ] Cleanup registered with t.Cleanup\n- [ ] Parallel tests don't share mutable state\n- [ ] Mocks use interfaces defined in test file\n- [ ] Coverage includes edge cases and error paths\n\n## Critical Patterns\n\n### Table-Driven Tests\n\n```go\n// BAD - repetitive\nfunc TestAdd(t *testing.T) {\n    if Add(1, 2) != 3 {\n        t.Error(\"wrong\")\n    }\n    if Add(0, 0) != 0 {\n        t.Error(\"wrong\")\n    }\n}\n\n// GOOD\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     int\n        want     int\n    }{\n        {\"positive numbers\", 1, 2, 3},\n        {\"zeros\", 0, 0, 0},\n        {\"negative\", -1, 1, 0},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := Add(tt.a, tt.b)\n            if got != tt.want {\n                t.Errorf(\"Add(%d, %d) = %d, want %d\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n```\n\n### Error Messages\n\n```go\n// BAD\nif got != want {\n    t.Error(\"wrong result\")\n}\n\n// GOOD\nif got != want {\n    t.Errorf(\"GetUser(%d) = %v, want %v\", id, got, want)\n}\n\n// For complex types\nif diff := cmp.Diff(want, got); diff != \"\" {\n    t.Errorf(\"GetUser() mismatch (-want +got):\\n%s\", diff)\n}\n```\n\n### Parallel Tests\n\n```go\nfunc TestFoo(t *testing.T) {\n    tests := []struct{...}\n\n    for _, tt := range tests {\n        tt := tt  // capture (not needed Go 1.22+)\n        t.Run(tt.name, func(t *testing.T) {\n            t.Parallel()\n            // test code\n        })\n    }\n}\n```\n\n### Cleanup\n\n```go\n// BAD - manual cleanup, skipped on failure\nfunc TestWithTempFile(t *testing.T) {\n    f, _ := os.CreateTemp(\"\", \"test\")\n    defer os.Remove(f.Name())  // skipped if test panics\n}\n\n// GOOD\nfunc TestWithTempFile(t *testing.T) {\n    f, _ := os.CreateTemp(\"\", \"test\")\n    t.Cleanup(func() {\n        os.Remove(f.Name())\n    })\n}\n```\n\n## Anti-Patterns\n\n### 1. Testing Internal Implementation\n\n```go\n// BAD - tests private state\nfunc TestUser(t *testing.T) {\n    u := NewUser(\"alice\")\n    if u.id != 1 {  // testing internal field\n        t.Error(\"wrong id\")\n    }\n}\n\n// GOOD - tests behavior\nfunc TestUser(t *testing.T) {\n    u := NewUser(\"alice\")\n    if u.ID() != 1 {\n        t.Error(\"wrong ID\")\n    }\n}\n```\n\n### 2. Shared Mutable State\n\n```go\n// BAD - tests interfere with each other\nvar testDB = setupDB()\n\nfunc TestA(t *testing.T) {\n    t.Parallel()\n    testDB.Insert(...)  // race!\n}\n\n// GOOD - isolated per test\nfunc TestA(t *testing.T) {\n    db := setupTestDB(t)\n    t.Cleanup(func() { db.Close() })\n    db.Insert(...)\n}\n```\n\n### 3. Assertions Without Context\n\n```go\n// BAD\nassert.Equal(t, want, got)  // \"expected X got Y\" - which test?\n\n// GOOD\nassert.Equal(t, want, got, \"user name after update\")\n```\n\n## When to Load References\n\n- Reviewing test file structure  structure.md\n- Reviewing mock implementations  mocking.md\n\n## Review Questions\n\n1. Are tests table-driven with named cases?\n2. Do error messages include input, got, and want?\n3. Are parallel tests isolated (no shared state)?\n4. Is cleanup done via t.Cleanup?\n5. Do tests verify behavior, not implementation?\n",
        "skills/go-testing-code-review/references/mocking.md": "# Mocking\n\n## Interface-Based Mocking\n\n### 1. Define Interface in Consumer\n\n```go\n// service.go\ntype UserStore interface {\n    Get(id int) (*User, error)\n}\n\ntype UserService struct {\n    store UserStore\n}\n\nfunc (s *UserService) GetUser(id int) (*User, error) {\n    return s.store.Get(id)\n}\n```\n\n### 2. Create Mock in Test File\n\n```go\n// service_test.go\ntype mockUserStore struct {\n    users map[int]*User\n    err   error\n}\n\nfunc (m *mockUserStore) Get(id int) (*User, error) {\n    if m.err != nil {\n        return nil, m.err\n    }\n    user, ok := m.users[id]\n    if !ok {\n        return nil, ErrNotFound\n    }\n    return user, nil\n}\n\nfunc TestGetUser(t *testing.T) {\n    mock := &mockUserStore{\n        users: map[int]*User{\n            1: {ID: 1, Name: \"Alice\"},\n        },\n    }\n\n    svc := &UserService{store: mock}\n    user, err := svc.GetUser(1)\n\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    if user.Name != \"Alice\" {\n        t.Errorf(\"name = %s, want Alice\", user.Name)\n    }\n}\n```\n\n### 3. Functional Mock Pattern\n\n```go\n// More flexible for varying behavior per test\ntype mockUserStore struct {\n    getFn func(id int) (*User, error)\n}\n\nfunc (m *mockUserStore) Get(id int) (*User, error) {\n    return m.getFn(id)\n}\n\nfunc TestGetUser_Error(t *testing.T) {\n    mock := &mockUserStore{\n        getFn: func(id int) (*User, error) {\n            return nil, errors.New(\"db error\")\n        },\n    }\n\n    svc := &UserService{store: mock}\n    _, err := svc.GetUser(1)\n\n    if err == nil {\n        t.Error(\"expected error, got nil\")\n    }\n}\n```\n\n## Testing HTTP Clients\n\n### 1. httptest Server\n\n```go\nfunc TestFetchUser(t *testing.T) {\n    // Create test server\n    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        if r.URL.Path != \"/users/1\" {\n            t.Errorf(\"unexpected path: %s\", r.URL.Path)\n        }\n        w.Header().Set(\"Content-Type\", \"application/json\")\n        w.Write([]byte(`{\"id\": 1, \"name\": \"Alice\"}`))\n    }))\n    defer ts.Close()\n\n    // Use test server URL\n    client := NewClient(ts.URL)\n    user, err := client.FetchUser(1)\n\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    if user.Name != \"Alice\" {\n        t.Errorf(\"name = %s, want Alice\", user.Name)\n    }\n}\n```\n\n### 2. RoundTripper Mock\n\n```go\ntype mockTransport struct {\n    response *http.Response\n    err      error\n}\n\nfunc (m *mockTransport) RoundTrip(*http.Request) (*http.Response, error) {\n    return m.response, m.err\n}\n\nfunc TestClient_Error(t *testing.T) {\n    client := &http.Client{\n        Transport: &mockTransport{\n            err: errors.New(\"network error\"),\n        },\n    }\n\n    _, err := FetchData(client, \"http://example.com\")\n    if err == nil {\n        t.Error(\"expected error\")\n    }\n}\n```\n\n## Testing Time\n\n### 1. Inject Time Function\n\n```go\n// Code\ntype Service struct {\n    now func() time.Time\n}\n\nfunc (s *Service) IsExpired(expiry time.Time) bool {\n    return s.now().After(expiry)\n}\n\n// Test\nfunc TestIsExpired(t *testing.T) {\n    fixedTime := time.Date(2024, 1, 15, 0, 0, 0, 0, time.UTC)\n    svc := &Service{\n        now: func() time.Time { return fixedTime },\n    }\n\n    tests := []struct {\n        name   string\n        expiry time.Time\n        want   bool\n    }{\n        {\"past\", fixedTime.Add(-time.Hour), true},\n        {\"future\", fixedTime.Add(time.Hour), false},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := svc.IsExpired(tt.expiry)\n            if got != tt.want {\n                t.Errorf(\"IsExpired() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n```\n\n## Testing Filesystem\n\n### 1. fstest.MapFS\n\n```go\nimport \"testing/fstest\"\n\nfunc TestReadConfig(t *testing.T) {\n    fs := fstest.MapFS{\n        \"config.json\": &fstest.MapFile{\n            Data: []byte(`{\"key\": \"value\"}`),\n        },\n    }\n\n    cfg, err := ReadConfig(fs, \"config.json\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    if cfg.Key != \"value\" {\n        t.Errorf(\"key = %s, want value\", cfg.Key)\n    }\n}\n```\n\n### 2. T.TempDir\n\n```go\nfunc TestWriteFile(t *testing.T) {\n    dir := t.TempDir()  // automatically cleaned up\n    path := filepath.Join(dir, \"test.txt\")\n\n    err := WriteFile(path, \"content\")\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    data, _ := os.ReadFile(path)\n    if string(data) != \"content\" {\n        t.Errorf(\"got %q, want content\", data)\n    }\n}\n```\n\n## Verifying Calls\n\n### 1. Call Recording\n\n```go\ntype mockStore struct {\n    getCalls []int\n}\n\nfunc (m *mockStore) Get(id int) (*User, error) {\n    m.getCalls = append(m.getCalls, id)\n    return &User{ID: id}, nil\n}\n\nfunc TestBatchGet(t *testing.T) {\n    mock := &mockStore{}\n    svc := &Service{store: mock}\n\n    svc.BatchGet([]int{1, 2, 3})\n\n    if len(mock.getCalls) != 3 {\n        t.Errorf(\"Get called %d times, want 3\", len(mock.getCalls))\n    }\n    if !slices.Equal(mock.getCalls, []int{1, 2, 3}) {\n        t.Errorf(\"Get called with %v, want [1,2,3]\", mock.getCalls)\n    }\n}\n```\n\n## Anti-Patterns\n\n### 1. Over-Mocking\n\n```go\n// BAD - mocking everything\nfunc TestAdd(t *testing.T) {\n    mockCalc := &mockCalculator{}\n    // just test the actual function!\n}\n\n// GOOD - only mock external dependencies\nfunc TestService(t *testing.T) {\n    mockDB := &mockDB{}  // external dependency\n    svc := NewService(mockDB)\n    // test service logic\n}\n```\n\n### 2. Mocking Concrete Types\n\n```go\n// BAD - can't inject mock\ntype Service struct {\n    store *PostgresStore\n}\n\n// GOOD - interface allows mocking\ntype Service struct {\n    store Store  // interface\n}\n```\n\n## Review Questions\n\n1. Are interfaces defined by consumers, not producers?\n2. Are mocks minimal (only implement what's tested)?\n3. Are test servers used for HTTP testing?\n4. Is time injected for time-dependent tests?\n5. Are call recordings used to verify interactions?\n",
        "skills/go-testing-code-review/references/structure.md": "# Test Structure\n\n## File Organization\n\n### 1. Test File Location\n\n```\npackage/\n user.go\n user_test.go       # same package tests\n user_internal_test.go  # internal tests if needed\n testdata/          # test fixtures\n     users.json\n```\n\n### 2. Test Naming Convention\n\n```go\n// Function test\nfunc TestFunctionName(t *testing.T) {}\n\n// Method test\nfunc TestTypeName_MethodName(t *testing.T) {}\n\n// Scenario test\nfunc TestGetUser_WhenNotFound_ReturnsError(t *testing.T) {}\n```\n\n## Test Patterns\n\n### 1. Setup and Teardown\n\n```go\nfunc TestMain(m *testing.M) {\n    // Global setup\n    setup()\n\n    code := m.Run()\n\n    // Global teardown\n    teardown()\n    os.Exit(code)\n}\n\n// Per-test setup\nfunc TestFoo(t *testing.T) {\n    db := setupTestDB(t)\n    t.Cleanup(func() {\n        db.Close()\n    })\n}\n```\n\n### 2. Helper Functions\n\n```go\n// Mark as helper for better stack traces\nfunc assertNoError(t *testing.T, err error) {\n    t.Helper()  // marks this as helper\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n}\n\nfunc createTestUser(t *testing.T, name string) *User {\n    t.Helper()\n    u, err := NewUser(name)\n    if err != nil {\n        t.Fatalf(\"creating test user: %v\", err)\n    }\n    return u\n}\n```\n\n### 3. Testdata Directory\n\n```go\nfunc TestParseConfig(t *testing.T) {\n    // Load from testdata directory\n    data, err := os.ReadFile(\"testdata/config.json\")\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    cfg, err := ParseConfig(data)\n    // ...\n}\n```\n\n## Table-Driven Tests\n\n### 1. Basic Structure\n\n```go\nfunc TestParse(t *testing.T) {\n    tests := []struct {\n        name    string\n        input   string\n        want    int\n        wantErr bool\n    }{\n        {\n            name:  \"valid number\",\n            input: \"42\",\n            want:  42,\n        },\n        {\n            name:    \"invalid input\",\n            input:   \"abc\",\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Parse(tt.input)\n\n            if tt.wantErr {\n                if err == nil {\n                    t.Error(\"expected error, got nil\")\n                }\n                return\n            }\n\n            if err != nil {\n                t.Fatalf(\"unexpected error: %v\", err)\n            }\n\n            if got != tt.want {\n                t.Errorf(\"Parse(%q) = %d, want %d\", tt.input, got, tt.want)\n            }\n        })\n    }\n}\n```\n\n### 2. With Setup Function\n\n```go\nfunc TestHandler(t *testing.T) {\n    tests := []struct {\n        name       string\n        setup      func() *Handler\n        input      Request\n        wantStatus int\n    }{\n        {\n            name: \"authorized user\",\n            setup: func() *Handler {\n                return NewHandler(WithAuth(true))\n            },\n            input:      Request{UserID: 1},\n            wantStatus: 200,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            h := tt.setup()\n            resp := h.Handle(tt.input)\n            if resp.Status != tt.wantStatus {\n                t.Errorf(\"status = %d, want %d\", resp.Status, tt.wantStatus)\n            }\n        })\n    }\n}\n```\n\n### 3. With Assertions\n\n```go\nfunc TestProcess(t *testing.T) {\n    tests := []struct {\n        name   string\n        input  []int\n        check  func(t *testing.T, result []int)\n    }{\n        {\n            name:  \"preserves order\",\n            input: []int{3, 1, 2},\n            check: func(t *testing.T, result []int) {\n                if !slices.Equal(result, []int{1, 2, 3}) {\n                    t.Errorf(\"got %v, want sorted\", result)\n                }\n            },\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := Process(tt.input)\n            tt.check(t, result)\n        })\n    }\n}\n```\n\n## Parallel Testing\n\n### 1. Top-Level Parallel\n\n```go\nfunc TestFoo(t *testing.T) {\n    t.Parallel()  // this test runs in parallel with others\n\n    // test code\n}\n```\n\n### 2. Subtests Parallel\n\n```go\nfunc TestAll(t *testing.T) {\n    tests := []struct{...}\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            t.Parallel()  // subtests run in parallel\n            // test code using tt\n        })\n    }\n}\n```\n\n### 3. Avoiding Race Conditions\n\n```go\n// Before Go 1.22, capture loop variable\nfor _, tt := range tests {\n    tt := tt  // capture!\n    t.Run(tt.name, func(t *testing.T) {\n        t.Parallel()\n        // use tt safely\n    })\n}\n\n// Go 1.22+: not needed, loop variable is per-iteration\n```\n\n## Error Assertions\n\n### 1. Using errors.Is\n\n```go\nfunc TestGetUser_NotFound(t *testing.T) {\n    _, err := GetUser(999)\n\n    if !errors.Is(err, ErrNotFound) {\n        t.Errorf(\"got %v, want ErrNotFound\", err)\n    }\n}\n```\n\n### 2. Using errors.As\n\n```go\nfunc TestValidate(t *testing.T) {\n    err := Validate(invalidInput)\n\n    var validErr *ValidationError\n    if !errors.As(err, &validErr) {\n        t.Fatalf(\"expected ValidationError, got %T\", err)\n    }\n\n    if validErr.Field != \"email\" {\n        t.Errorf(\"field = %s, want email\", validErr.Field)\n    }\n}\n```\n\n## Review Questions\n\n1. Are test files colocated with source files?\n2. Do test names describe the scenario?\n3. Are helper functions marked with t.Helper()?\n4. Are parallel tests properly isolated?\n5. Are fixtures in testdata directory?\n",
        "skills/healthkit-code-review/SKILL.md": "---\nname: healthkit-code-review\ndescription: Reviews HealthKit code for authorization patterns, query usage, background delivery, and data type handling. Use when reviewing code with import HealthKit, HKHealthStore, HKSampleQuery, HKObserverQuery, or HKQuantityType.\n---\n\n# HealthKit Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| HKHealthStore, permissions, status checks, privacy | [references/authorization.md](references/authorization.md) |\n| HKQuery types, predicates, anchored queries, statistics | [references/queries.md](references/queries.md) |\n| Background delivery, observer queries, completion handlers | [references/background.md](references/background.md) |\n| HKQuantityType, HKCategoryType, workouts, units | [references/data-types.md](references/data-types.md) |\n\n## Review Checklist\n\n- [ ] `HKHealthStore.isHealthDataAvailable()` called before any HealthKit operations\n- [ ] Authorization requested only for needed data types (minimal permissions)\n- [ ] `requestAuthorization` completion handler not misinterpreted as permission granted\n- [ ] No attempt to determine read permission status (privacy by design)\n- [ ] Query results dispatched to main thread for UI updates\n- [ ] `HKObjectQueryNoLimit` used only with bounded predicates\n- [ ] `HKStatisticsQuery` used for aggregations instead of manual summing\n- [ ] Observer query `completionHandler()` always called (use `defer`)\n- [ ] Background delivery registered in `application(_:didFinishLaunchingWithOptions:)`\n- [ ] Background delivery entitlement added (iOS 15+)\n- [ ] Correct units used for quantity types (e.g., `count/min` for heart rate)\n- [ ] Long-running queries stored as properties and stopped in `deinit`\n\n## When to Load References\n\n- Reviewing authorization/permissions flow -> authorization.md\n- Reviewing HKSampleQuery, HKAnchoredObjectQuery, or predicates -> queries.md\n- Reviewing HKObserverQuery or `enableBackgroundDelivery` -> background.md\n- Reviewing HKQuantityType, HKCategoryType, or HKWorkout -> data-types.md\n\n## Review Questions\n\n1. Is `isHealthDataAvailable()` checked before creating HKHealthStore?\n2. Does the code gracefully handle denied permissions (empty results)?\n3. Are observer query completion handlers called in all code paths?\n4. Is work in background handlers minimal (~15 second limit)?\n5. Are HKQueryAnchors persisted per sample type (not shared)?\n",
        "skills/healthkit-code-review/references/authorization.md": "# HealthKit Authorization\n\n## Authorization Model\n\nHealthKit uses **per-data-type, separate read/write authorization**. Users grant access individually for each health data type.\n\n### Required Setup\n\n1. **Entitlement**: `com.apple.developer.healthkit` capability\n2. **Info.plist Keys**:\n   - `NSHealthShareUsageDescription` - Why app needs to **read** health data\n   - `NSHealthUpdateUsageDescription` - Why app needs to **write** health data\n\n### HKAuthorizationStatus (Write Only)\n\n| Status | Meaning |\n|--------|---------|\n| `.notDetermined` | User hasn't been asked yet |\n| `.sharingAuthorized` | User granted write access |\n| `.sharingDenied` | User explicitly denied write access |\n\n**Critical**: Read permission status is intentionally hidden for privacy.\n\n### Key Methods\n\n| Method | Purpose |\n|--------|---------|\n| `isHealthDataAvailable()` | Check device support (not on iPad pre-iPadOS 17) |\n| `authorizationStatus(for:)` | Check **write** permission only |\n| `getRequestStatusForAuthorization(toShare:read:)` | Check if auth sheet would appear |\n| `requestAuthorization(toShare:read:)` | Request permissions from user |\n\n## Critical Anti-Patterns\n\n### 1. Misinterpreting requestAuthorization Success\n\n```swift\n// BAD: success does NOT mean permission granted\nhealthStore.requestAuthorization(toShare: types, read: types) { success, error in\n    if success {\n        self.startRecordingWorkout()  // May fail if permission denied!\n    }\n}\n\n// GOOD: success means dialog flow completed\nhealthStore.requestAuthorization(toShare: types, read: types) { success, error in\n    if success {\n        // Check specific type for write operations\n        if self.healthStore.authorizationStatus(for: workoutType) == .sharingAuthorized {\n            self.startRecordingWorkout()\n        }\n    }\n}\n```\n\n### 2. Checking Read Permission Status\n\n```swift\n// BAD: Cannot determine read permission status\nlet status = healthStore.authorizationStatus(for: heartRateType)\nif status == .sharingAuthorized {  // This only checks WRITE status!\n    displayHeartRateData()\n}\n\n// GOOD: Just attempt to fetch - empty results if denied\nfunc fetchHeartRateData() async {\n    let results = try? await healthStore.execute(query)\n    // Handle empty results gracefully\n}\n```\n\n### 3. Not Checking Device Availability\n\n```swift\n// BAD: HealthKit not available on iPad (pre-iPadOS 17)\nfunc requestHealthKitAccess() {\n    healthStore.requestAuthorization(toShare: types, read: types) { _, _ in }\n}\n\n// GOOD: Always check availability first\nfunc requestHealthKitAccess() {\n    guard HKHealthStore.isHealthDataAvailable() else {\n        showHealthKitNotAvailableMessage()\n        return\n    }\n    healthStore.requestAuthorization(toShare: types, read: types) { _, _ in }\n}\n```\n\n### 4. Widgets Requesting Authorization\n\n```swift\n// BAD: Widgets cannot present authorization UI\nstruct HealthWidget: Widget {\n    func getTimeline(...) {\n        healthStore.requestAuthorization(...)  // Will silently fail\n    }\n}\n\n// GOOD: Use getRequestStatusForAuthorization in widgets\nstruct HealthWidget: Widget {\n    func getTimeline(...) {\n        let status = try? await healthStore.statusForAuthorizationRequest(toShare: [], read: types)\n        if status == .shouldRequest {\n            showOpenAppPrompt()\n        } else {\n            displayHealthData()  // May be empty if denied\n        }\n    }\n}\n```\n\n### 5. Accessing Data Before Authorization Completes\n\n```swift\n// BAD: Race condition (HKError code 5)\nfunc initialize() {\n    healthStore.requestAuthorization(toShare: types, read: types) { _, _ in }\n    fetchHealthData()  // Called before authorization completes!\n}\n\n// GOOD: Wait for authorization\nfunc initialize() async {\n    do {\n        try await healthStore.requestAuthorization(toShare: types, read: types)\n        await fetchHealthData()\n    } catch {\n        handleAuthorizationError(error)\n    }\n}\n```\n\n## HKError Codes\n\n| Code | Constant | Meaning |\n|------|----------|---------|\n| - | `.errorAuthorizationDenied` | User denied permission |\n| - | `.errorAuthorizationNotDetermined` | App hasn't requested yet |\n| 4 | - | Missing HealthKit entitlement |\n| 5 | - | Transaction failed (often premature data access) |\n\n## Review Questions\n\n1. Is `isHealthDataAvailable()` called before any HealthKit operations?\n2. Is the `requestAuthorization` completion handler correctly interpreted?\n3. Is there any attempt to determine read permission status? (anti-pattern)\n4. Are all Info.plist usage description keys present with meaningful text?\n5. Do widgets avoid calling `requestAuthorization`?\n6. Is authorization status re-checked before write operations (not cached)?\n",
        "skills/healthkit-code-review/references/background.md": "# HealthKit Background Delivery\n\n## Overview\n\nBackground delivery allows apps to receive HealthKit updates without user launching the app. Requires:\n\n1. **`enableBackgroundDelivery(for:frequency:)`** - Register for notifications\n2. **`HKObserverQuery`** - Long-running query that monitors changes\n\n## Required Configuration\n\n### Entitlements (iOS 15+/Xcode 13+)\n\n```xml\n<key>com.apple.developer.healthkit</key>\n<true/>\n<key>com.apple.developer.healthkit.background-delivery</key>\n<true/>\n```\n\n### Capabilities\n\n- HealthKit > Background Delivery\n- Background Modes > Background Processing\n\n## Update Frequencies\n\n| Frequency | Behavior | Reality |\n|-----------|----------|---------|\n| `.immediate` | Wake on every change | Some types enforce hourly max (stepCount) |\n| `.hourly` | At most once per hour | iOS may defer based on battery/CPU |\n| `.daily` | At most once per day | Advisory, not guaranteed |\n| `.weekly` | At most once per week | Advisory, not guaranteed |\n\n**iOS has full discretion** to defer based on CPU, battery, connectivity, Low Power Mode.\n\n## Background Execution Constraints\n\n- **Time limit**: ~15 seconds for simple queries\n- **3 strikes rule**: After 3 failed completions, delivery stops\n- **watchOS budget**: 4 updates/hour (shared with WKApplicationRefreshBackgroundTask)\n\n## Required Setup Pattern\n\n```swift\n// AppDelegate.swift - MUST be in didFinishLaunchingWithOptions\nfunc application(_ application: UIApplication,\n                 didFinishLaunchingWithOptions launchOptions: [...]) -> Bool {\n    setupHealthKitBackgroundDelivery()\n    return true\n}\n\nfunc setupHealthKitBackgroundDelivery() {\n    let stepType = HKQuantityType(.stepCount)\n\n    // 1. Create observer query\n    let query = HKObserverQuery(sampleType: stepType, predicate: nil) {\n        query, completionHandler, error in\n        defer { completionHandler() }  // MUST always call\n\n        guard error == nil else { return }\n        self.fetchNewData()  // Keep minimal - 15 sec limit\n    }\n\n    // 2. Execute query\n    healthStore.execute(query)\n\n    // 3. Enable background delivery\n    healthStore.enableBackgroundDelivery(for: stepType, frequency: .immediate) { _, _ in }\n}\n```\n\n## Critical Anti-Patterns\n\n### 1. Not Calling completionHandler\n\n```swift\n// BAD: completionHandler not called on error path\nlet query = HKObserverQuery(...) { query, completionHandler, error in\n    if let error = error {\n        print(\"Error: \\(error)\")\n        return  // completionHandler not called!\n    }\n    self.fetchData()\n    completionHandler()\n}\n\n// GOOD: Use defer to ensure it's always called\nlet query = HKObserverQuery(...) { query, completionHandler, error in\n    defer { completionHandler() }  // Always called\n\n    guard error == nil else {\n        print(\"Error: \\(error!)\")\n        return\n    }\n    self.fetchData()\n}\n```\n\n### 2. Not Re-registering on App Launch\n\n```swift\n// BAD: Registering only once\nclass HealthManager {\n    private var hasRegistered = false\n    func setupBackgroundDelivery() {\n        guard !hasRegistered else { return }  // Won't work after app update!\n        hasRegistered = true\n        // ...\n    }\n}\n\n// GOOD: Always register in didFinishLaunchingWithOptions\n// Registration must happen every app launch\nfunc application(_ app: UIApplication, didFinishLaunchingWithOptions: [...]) -> Bool {\n    healthManager.setupBackgroundDelivery()  // Called every launch\n    return true\n}\n```\n\n### 3. Local Variable Query Gets Deallocated\n\n```swift\n// BAD: Query goes out of scope\nfunc setupObserver() {\n    let query = HKObserverQuery(...)\n    healthStore.execute(query)\n}  // query deallocated!\n\n// GOOD: Store as property\nclass HealthManager {\n    private var observerQueries: [HKObserverQuery] = []\n\n    func setupObserver() {\n        let query = HKObserverQuery(...)\n        observerQueries.append(query)  // Keep reference\n        healthStore.execute(query)\n    }\n}\n```\n\n### 4. Assuming Callback Means New Data\n\n```swift\n// BAD: Callback fires even without data changes\nlet query = HKObserverQuery(...) { query, completionHandler, error in\n    defer { completionHandler() }\n    self.processNewData()  // May process nothing - called on foreground too\n}\n\n// GOOD: Use HKAnchoredObjectQuery to get actual changes\nfunc fetchChanges(completion: @escaping () -> Void) {\n    let query = HKAnchoredObjectQuery(type: type, anchor: savedAnchor, ...) {\n        query, samples, deleted, newAnchor, error in\n        defer { completion() }\n\n        guard let samples = samples, let newAnchor = newAnchor else { return }\n        self.anchor = newAnchor  // Persist\n\n        // Only process actual new samples\n        self.process(samples: samples, deleted: deleted ?? [])\n    }\n    healthStore.execute(query)\n}\n```\n\n### 5. Long-Running Work in Background Handler\n\n```swift\n// BAD: May exceed 15-second time limit\nlet query = HKObserverQuery(...) { query, completionHandler, error in\n    self.downloadFromServer()\n    self.processAllHistoricalData()\n    self.syncToCloudKit()\n    completionHandler()\n}\n\n// GOOD: Minimal work, schedule full sync for later\nlet query = HKObserverQuery(...) { query, completionHandler, error in\n    defer { completionHandler() }  // Complete quickly\n\n    // Just fetch latest\n    self.fetchLatestSample { sample in\n        self.pendingSamples.append(sample)\n\n        // Schedule full sync when app is active\n        DispatchQueue.main.async {\n            if UIApplication.shared.applicationState == .active {\n                self.performFullSync()\n            }\n        }\n    }\n}\n```\n\n### 6. Missing Required Entitlement\n\n```xml\n<!-- BAD: Missing background delivery entitlement -->\n<key>com.apple.developer.healthkit</key>\n<true/>\n\n<!-- GOOD: All required entitlements -->\n<key>com.apple.developer.healthkit</key>\n<true/>\n<key>com.apple.developer.healthkit.background-delivery</key>\n<true/>\n```\n\n## Review Questions\n\n1. Is `enableBackgroundDelivery` called in `application(_:didFinishLaunchingWithOptions:)`?\n2. Are all required entitlements configured (especially iOS 15+)?\n3. Are observer queries stored as instance properties?\n4. Is `completionHandler()` called in ALL code paths?\n5. Is work in the observer callback minimal (~15 seconds)?\n6. Does code handle that callbacks may fire without actual data changes?\n7. Are anchors persisted to track processed data?\n8. Is the update frequency appropriate for the data type?\n",
        "skills/healthkit-code-review/references/data-types.md": "# HealthKit Data Types\n\n## Data Type Hierarchy\n\n| Type | Class | Purpose |\n|------|-------|---------|\n| Quantity | `HKQuantityType` / `HKQuantitySample` | Measurable numeric values with units |\n| Category | `HKCategoryType` / `HKCategorySample` | Enumerated categorical values |\n| Correlation | `HKCorrelationType` / `HKCorrelation` | Groups of related samples |\n| Characteristic | `HKCharacteristicType` | Static, immutable user data |\n| Workout | `HKWorkout` / `HKWorkoutBuilder` | Exercise sessions |\n\n## HKQuantityType - Measurable Data\n\nCommon quantity types and their units:\n\n| Type | Unit |\n|------|------|\n| `.stepCount` | `.count()` |\n| `.heartRate` | `HKUnit(from: \"count/min\")` |\n| `.distanceWalkingRunning` | `.meter()` |\n| `.activeEnergyBurned` | `.kilocalorie()` |\n| `.bloodPressureSystolic` | `.millimeterOfMercury()` |\n| `.oxygenSaturation` | `.percent()` |\n\n### Creating HKQuantitySample\n\n```swift\n// 1. Get quantity type\nguard let stepType = HKQuantityType.quantityType(forIdentifier: .stepCount) else { return }\n\n// 2. Create quantity with unit\nlet quantity = HKQuantity(unit: .count(), doubleValue: 10000)\n\n// 3. Create sample with metadata\nlet metadata: [String: Any] = [\n    HKMetadataKeyTimeZone: TimeZone.current.identifier,\n    HKMetadataKeyWasUserEntered: false\n]\nlet sample = HKQuantitySample(type: stepType, quantity: quantity,\n                               start: startDate, end: endDate, metadata: metadata)\n\n// 4. Save\nhealthStore.save(sample) { success, error in }\n```\n\n## HKCategoryType - Enumerated Data\n\n### Sleep Analysis (iOS 16+)\n\n```swift\nlet sleepType = HKCategoryType(.sleepAnalysis)\n\n// Create both in-bed and asleep samples\nlet inBedSample = HKCategorySample(\n    type: sleepType,\n    value: HKCategoryValueSleepAnalysis.inBed.rawValue,\n    start: bedTime, end: wakeTime\n)\nlet asleepSample = HKCategorySample(\n    type: sleepType,\n    value: HKCategoryValueSleepAnalysis.asleepCore.rawValue,  // iOS 16+\n    start: fallAsleepTime, end: actualWakeTime\n)\nhealthStore.save([inBedSample, asleepSample]) { _, _ in }\n```\n\n## HKCorrelation - Blood Pressure\n\nBlood pressure requires a correlation with both systolic and diastolic:\n\n```swift\n// Create systolic sample\nlet systolicType = HKQuantityType(.bloodPressureSystolic)\nlet systolicSample = HKQuantitySample(\n    type: systolicType,\n    quantity: HKQuantity(unit: .millimeterOfMercury(), doubleValue: 120),\n    start: date, end: date\n)\n\n// Create diastolic sample\nlet diastolicType = HKQuantityType(.bloodPressureDiastolic)\nlet diastolicSample = HKQuantitySample(\n    type: diastolicType,\n    quantity: HKQuantity(unit: .millimeterOfMercury(), doubleValue: 80),\n    start: date, end: date\n)\n\n// Create correlation\nlet bpType = HKCorrelationType(.bloodPressure)\nlet bpCorrelation = HKCorrelation(\n    type: bpType, start: date, end: date,\n    objects: [systolicSample, diastolicSample]\n)\n```\n\n**Important**: Request permissions on systolic/diastolic types, NOT the correlation type.\n\n## HKCharacteristicType - Static Data\n\nRead-only characteristics set by user in Health app:\n\n```swift\ndo {\n    let biologicalSex = try healthStore.biologicalSex().biologicalSex\n    switch biologicalSex {\n    case .female, .male, .other: // handle\n    case .notSet: // user hasn't set\n    @unknown default: break\n    }\n} catch {\n    // Permission denied or not set\n}\n```\n\n## HKWorkoutBuilder Pattern\n\n```swift\nlet config = HKWorkoutConfiguration()\nconfig.activityType = .running\nconfig.locationType = .outdoor\n\nlet builder = HKWorkoutBuilder(healthStore: healthStore, configuration: config, device: .local())\ntry await builder.beginCollection(at: startDate)\n\n// Add samples during workout\ntry await builder.addSamples([heartRateSample, distanceSample])\n\n// Finish\ntry await builder.endCollection(at: endDate)\nlet workout = try await builder.finishWorkout()\n```\n\n## Critical Anti-Patterns\n\n### 1. Wrong Units for Quantity Types\n\n```swift\n// BAD: Incompatible units\nlet heartRate = HKQuantity(unit: .count(), doubleValue: 72)  // Wrong!\nlet distance = HKQuantity(unit: .kilocalorie(), doubleValue: 5000)  // Wrong!\n\n// GOOD: Correct compatible units\nlet heartRate = HKQuantity(unit: HKUnit(from: \"count/min\"), doubleValue: 72)\nlet distance = HKQuantity(unit: .meter(), doubleValue: 5000)\n```\n\n### 2. Force Unwrapping Quantity Types\n\n```swift\n// BAD: Can crash\nlet stepType = HKQuantityType.quantityType(forIdentifier: .stepCount)!\n\n// GOOD: Safe unwrapping\nguard let stepType = HKQuantityType.quantityType(forIdentifier: .stepCount) else {\n    print(\"Step count type unavailable\")\n    return\n}\n```\n\n### 3. Requesting Correlation Type Permission\n\n```swift\n// BAD: Cannot request permission for correlation types\nlet bpType = HKCorrelationType(.bloodPressure)\nlet typesToRead: Set<HKObjectType> = [bpType]  // Will fail!\n\n// GOOD: Request underlying quantity types\nlet systolicType = HKQuantityType(.bloodPressureSystolic)\nlet diastolicType = HKQuantityType(.bloodPressureDiastolic)\nlet typesToRead: Set<HKObjectType> = [systolicType, diastolicType]\n```\n\n### 4. Not Including Time Zone Metadata\n\n```swift\n// BAD: No time zone\nlet sample = HKQuantitySample(type: type, quantity: quantity, start: start, end: end)\n\n// GOOD: Include time zone\nlet metadata: [String: Any] = [HKMetadataKeyTimeZone: TimeZone.current.identifier]\nlet sample = HKQuantitySample(type: type, quantity: quantity,\n                               start: start, end: end, metadata: metadata)\n```\n\n### 5. Reading Characteristics Without Error Handling\n\n```swift\n// BAD: Force try\nlet sex = try! healthStore.biologicalSex().biologicalSex\n\n// GOOD: Handle errors\ndo {\n    let sex = try healthStore.biologicalSex().biologicalSex\n    // Check for .notSet\n} catch {\n    // Handle permission denied or not set\n}\n```\n\n### 6. Only Creating InBed Sleep Sample\n\n```swift\n// BAD: Missing actual sleep sample\nlet inBedSample = HKCategorySample(type: sleepType,\n    value: HKCategoryValueSleepAnalysis.inBed.rawValue, ...)\n// No asleep sample!\n\n// GOOD: Create both\nlet inBedSample = HKCategorySample(type: sleepType,\n    value: HKCategoryValueSleepAnalysis.inBed.rawValue,\n    start: bedTime, end: wakeTime)\nlet asleepSample = HKCategorySample(type: sleepType,\n    value: HKCategoryValueSleepAnalysis.asleepCore.rawValue,\n    start: sleepTime, end: wakeTime)\nhealthStore.save([inBedSample, asleepSample]) { _, _ in }\n```\n\n## Unit Conversion\n\n```swift\n// HealthKit handles conversion automatically\nlet distanceInMeters = sample.quantity.doubleValue(for: .meter())\nlet distanceInMiles = sample.quantity.doubleValue(for: .mile())\n\n// User preferred units\nhealthStore.preferredUnits(for: [stepType]) { units, error in\n    let preferredUnit = units[stepType]\n}\n```\n\n## Review Questions\n\n1. Is `isHealthDataAvailable()` checked before creating HKHealthStore?\n2. Are quantity types used with compatible units?\n3. Are correlation types (blood pressure) created with all required sub-samples?\n4. Are permissions requested on underlying types, not correlation types?\n5. Are characteristics read with proper error handling for `.notSet`?\n6. Is metadata included (time zone, sync identifier)?\n7. Are sleep samples created correctly (both inBed and asleep)?\n8. Is `HKWorkoutBuilder` used instead of deprecated HKWorkout init?\n",
        "skills/healthkit-code-review/references/queries.md": "# HealthKit Queries\n\n## Query Types Overview\n\n| Query Type | Use Case | Long-Running | Returns Deletions |\n|------------|----------|--------------|-------------------|\n| `HKSampleQuery` | One-time snapshot | No | No |\n| `HKAnchoredObjectQuery` | Incremental sync, change tracking | Yes (with updateHandler) | Yes |\n| `HKStatisticsQuery` | Single aggregation (sum, avg, min, max) | No | N/A |\n| `HKStatisticsCollectionQuery` | Time-series aggregations | Yes | N/A |\n| `HKActivitySummaryQuery` | Activity rings data | Yes (optional) | No |\n\n## HKSampleQuery\n\nBasic one-time fetch with sorting:\n\n```swift\nlet query = HKSampleQuery(\n    sampleType: sampleType,\n    predicate: predicate,\n    limit: HKObjectQueryNoLimit,\n    sortDescriptors: [NSSortDescriptor(key: HKSampleSortIdentifierStartDate, ascending: false)]\n) { (query, samples, error) in\n    DispatchQueue.main.async {\n        // Handle results - update UI\n    }\n}\nhealthStore.execute(query)\n```\n\n## HKAnchoredObjectQuery\n\nFor incremental sync with deletion tracking:\n\n```swift\nlet query = HKAnchoredObjectQuery(\n    type: sampleType,\n    predicate: predicate,\n    anchor: savedAnchor,  // nil for first fetch, persisted for subsequent\n    limit: HKObjectQueryNoLimit\n) { (query, samples, deletedObjects, newAnchor, error) in\n    // Process samples AND deletedObjects\n    self.saveAnchor(newAnchor)  // Persist for next query\n}\n// Optional: continuous monitoring\nquery.updateHandler = { (query, samples, deleted, newAnchor, error) in }\nhealthStore.execute(query)\n```\n\n**Important**: HKQueryAnchor cannot be reused across different sample types.\n\n## HKStatisticsQuery\n\nFor aggregations - use correct options per data type:\n\n| Data Type | Valid Options |\n|-----------|---------------|\n| Cumulative (steps, distance) | `.cumulativeSum` |\n| Discrete (weight, heart rate) | `.discreteAverage`, `.discreteMin`, `.discreteMax` |\n\n```swift\nlet query = HKStatisticsQuery(\n    quantityType: stepCountType,\n    quantitySamplePredicate: predicate,\n    options: .cumulativeSum  // Use .discreteAverage for body mass\n) { (query, statistics, error) in\n    let sum = statistics?.sumQuantity()?.doubleValue(for: .count())\n}\n```\n\n## Predicate Building\n\n```swift\nlet predicate = HKQuery.predicateForSamples(\n    withStart: startDate,\n    end: endDate,\n    options: [.strictStartDate, .strictEndDate]\n)\n// .strictStartDate: Sample start >= startDate\n// .strictEndDate: Sample end <= endDate\n// [] (empty): Sample overlaps with range\n```\n\n## Critical Anti-Patterns\n\n### 1. HKObjectQueryNoLimit Without Predicates\n\n```swift\n// BAD: May fetch millions of samples - memory exhaustion\nlet query = HKSampleQuery(\n    sampleType: stepCountType,\n    predicate: nil,\n    limit: HKObjectQueryNoLimit,\n    sortDescriptors: nil\n) { ... }\n\n// GOOD: Always bound with predicates\nlet predicate = HKQuery.predicateForSamples(withStart: startDate, end: endDate)\nlet query = HKSampleQuery(\n    sampleType: stepCountType,\n    predicate: predicate,\n    limit: 1000,  // Safety net\n    sortDescriptors: [...]\n) { ... }\n```\n\n### 2. Manual Summing Instead of Statistics Query\n\n```swift\n// BAD: Inefficient for cumulative data\nlet query = HKSampleQuery(...) { query, samples, error in\n    var total = 0.0\n    for sample in samples as? [HKQuantitySample] ?? [] {\n        total += sample.quantity.doubleValue(for: .count())\n    }\n}\n\n// GOOD: Use HKStatisticsQuery\nlet query = HKStatisticsQuery(\n    quantityType: stepCountType,\n    quantitySamplePredicate: predicate,\n    options: .cumulativeSum\n) { query, statistics, error in\n    let total = statistics?.sumQuantity()?.doubleValue(for: .count())\n}\n```\n\n### 3. Not Handling Deleted Samples\n\n```swift\n// BAD: Ignoring deletions in anchored query\nlet query = HKAnchoredObjectQuery(...) { query, samples, deletedObjects, newAnchor, error in\n    for sample in samples ?? [] {\n        self.syncToServer(sample)\n    }\n    // Missing deletion handling!\n}\n\n// GOOD: Process both additions and deletions\nlet query = HKAnchoredObjectQuery(...) { query, samples, deletedObjects, newAnchor, error in\n    for sample in samples ?? [] {\n        self.syncToServer(sample)\n    }\n    for deleted in deletedObjects ?? [] {\n        self.deleteFromServer(deleted.uuid)  // Critical for data integrity\n    }\n    self.saveAnchor(newAnchor)\n}\n```\n\n### 4. Reusing Anchors Across Sample Types\n\n```swift\n// BAD: Single anchor for all types\nvar anchor: HKQueryAnchor?\nfunc syncWorkouts() { HKAnchoredObjectQuery(type: workoutType, anchor: anchor, ...) }\nfunc syncSteps() { HKAnchoredObjectQuery(type: stepType, anchor: anchor, ...) }  // Wrong!\n\n// GOOD: Separate anchor per type\nvar anchors: [String: HKQueryAnchor] = [:]\nfunc sync(type: HKSampleType) {\n    let query = HKAnchoredObjectQuery(type: type, anchor: anchors[type.identifier], ...) {\n        query, samples, deleted, newAnchor, error in\n        self.anchors[type.identifier] = newAnchor\n    }\n}\n```\n\n### 5. UI Updates on Background Thread\n\n```swift\n// BAD: Query handler runs on background thread\nlet query = HKSampleQuery(...) { query, samples, error in\n    self.tableView.reloadData()  // Crash or undefined behavior\n}\n\n// GOOD: Dispatch to main thread\nlet query = HKSampleQuery(...) { query, samples, error in\n    DispatchQueue.main.async {\n        self.tableView.reloadData()\n    }\n}\n```\n\n### 6. Not Stopping Long-Running Queries\n\n```swift\n// BAD: Query never stopped - memory leak\nclass HealthVC: UIViewController {\n    var query: HKObserverQuery?\n    override func viewDidLoad() {\n        query = HKObserverQuery(...)\n        healthStore.execute(query!)\n    }  // Query continues forever\n}\n\n// GOOD: Stop in deinit\nclass HealthVC: UIViewController {\n    var query: HKObserverQuery?\n    override func viewDidLoad() {\n        query = HKObserverQuery(...)\n        healthStore.execute(query!)\n    }\n    deinit {\n        if let query = query { healthStore.stop(query) }\n    }\n}\n```\n\n## Review Questions\n\n1. Is the correct query type used for the use case?\n2. Are date predicates used to bound query results?\n3. Are UI updates dispatched to the main thread?\n4. Is `HKObjectQueryNoLimit` used with appropriate predicates?\n5. Are deleted objects handled in anchored queries?\n6. Are anchors persisted separately per sample type?\n7. Are long-running queries stopped when no longer needed?\n8. Are correct statistics options used for the data type?\n",
        "skills/howto-docs/SKILL.md": "---\nname: howto-docs\ndescription: How-To guide patterns for documentation - task-oriented guides for users with specific goals\nautoContext:\n  whenUserAsks:\n    - how to guide\n    - how-to guide\n    - howto guide\n    - task guide\n    - procedural guide\n    - step-by-step guide\n    - how to documentation\ndependencies:\n  - docs-style\n---\n\n# How-To Documentation Skill\n\nThis skill provides patterns for writing effective How-To guides in documentation. How-To guides are task-oriented content for users who have a specific goal in mind.\n\n## Purpose & Audience\n\n**Target readers:**\n- Users with a specific goal they want to accomplish\n- Assumes some familiarity with the product (not complete beginners)\n- Looking for practical, actionable steps\n- Want to get things done, not learn concepts\n\n**How-To guides are NOT:**\n- Tutorials (which teach through exploration)\n- Explanations (which provide understanding)\n- Reference docs (which describe the system)\n\n## How-To Guide Template\n\nUse this structure for all how-to guides:\n\n```markdown\n---\ntitle: \"How to [achieve specific goal]\"\ndescription: \"Learn how to [goal] using [product/feature]\"\n---\n\n# How to [Goal]\n\nBrief intro (1-2 sentences): what you'll accomplish and why it's useful.\n\n## Prerequisites\n\n- [What user needs before starting]\n- [Required access, tools, or setup]\n- [Any prior knowledge assumed]\n\n## Steps\n\n### 1. [Action verb] the [thing]\n\n[Clear instruction with expected outcome]\n\n<Note>\n[Optional tip or important context]\n</Note>\n\n### 2. [Next action]\n\n[Continue with clear, single-action steps]\n\n```bash\n# Example command or code if needed\n```\n\n### 3. [Continue numbering]\n\n[Each step should be one discrete action]\n\n## Verify it worked\n\n[How to confirm success - what should user see/experience?]\n\n## Troubleshooting\n\n<AccordionGroup>\n  <Accordion title=\"[Common issue 1]\">\n    [Solution or workaround]\n  </Accordion>\n  <Accordion title=\"[Common issue 2]\">\n    [Solution or workaround]\n  </Accordion>\n</AccordionGroup>\n\n## Next steps\n\n- [Related how-to guide 1]\n- [Related how-to guide 2]\n- [Deeper dive reference doc]\n```\n\n## Writing Principles\n\n### Title Conventions\n\n- **Always start with \"How to\"** - makes the goal immediately clear\n- Use active verbs: \"How to configure...\", \"How to deploy...\", \"How to migrate...\"\n- Be specific: \"How to add SSO authentication\" not \"How to set up auth\"\n\n### Step Structure\n\n1. **One action per step** - if you write \"and\", consider splitting\n2. **Start with action verbs**: Click, Navigate, Enter, Select, Run, Create\n3. **Show expected outcomes** after key steps:\n   ```markdown\n   ### 3. Save the configuration\n\n   Click **Save**. You should see a success message: \"Configuration updated.\"\n   ```\n\n### Minimize Context\n\n- Don't explain why things work - just show how to do them\n- Link to explanations for users who want deeper understanding\n- Keep each step focused on the immediate action\n\n### User Perspective\n\nWrite from the user's perspective, not the product's:\n\n| Avoid (product-centric) | Prefer (user-centric) |\n|------------------------|----------------------|\n| \"The API accepts...\" | \"Send a request to...\" |\n| \"The system will...\" | \"You'll see...\" |\n| \"This feature allows...\" | \"You can now...\" |\n\n### Prerequisites Section\n\nBe explicit about what's needed:\n\n```markdown\n## Prerequisites\n\n- An active account with admin permissions\n- API key generated from Settings > API\n- Node.js v18 or later installed\n- Completed the [initial setup guide](/getting-started)\n```\n\n## Components for How-To Guides\n\n### Steps Component\n\nFor numbered procedures, use a Steps component:\n\n```markdown\n<Steps>\n  <Step title=\"Create a new project\">\n    Navigate to the dashboard and click **New Project**.\n  </Step>\n  <Step title=\"Configure settings\">\n    Enter your project name and select a region.\n  </Step>\n  <Step title=\"Deploy\">\n    Click **Deploy** to launch your project.\n  </Step>\n</Steps>\n```\n\n### Code Groups for Multiple Options\n\nWhen showing different approaches:\n\n```markdown\n<CodeGroup>\n```bash npm\nnpm install @company/sdk\n```\n\n```bash yarn\nyarn add @company/sdk\n```\n\n```bash pnpm\npnpm add @company/sdk\n```\n</CodeGroup>\n```\n\n### Callouts for Important Information\n\n```markdown\n<Warning>\nThis action cannot be undone. Make sure to backup your data first.\n</Warning>\n\n<Note>\nThis step may take 2-3 minutes to complete.\n</Note>\n\n<Tip>\nYou can also use keyboard shortcut Cmd+K for faster navigation.\n</Tip>\n```\n\n### Expandable Sections\n\nFor optional details that shouldn't interrupt flow:\n\n```markdown\n<Expandable title=\"Advanced options\">\n  If you need custom configuration, you can also set:\n  - `timeout`: Request timeout in milliseconds\n  - `retries`: Number of retry attempts\n</Expandable>\n```\n\n## Example How-To Guide\n\n```markdown\n---\ntitle: \"How to set up webhook notifications\"\ndescription: \"Learn how to configure webhooks to receive real-time event notifications\"\n---\n\n# How to Set Up Webhook Notifications\n\nConfigure webhooks to receive instant notifications when events occur in your account. This enables real-time integrations with your existing tools.\n\n## Prerequisites\n\n- Admin access to your account\n- A publicly accessible HTTPS endpoint to receive webhooks\n- Completed the [authentication setup](/getting-started/auth)\n\n## Steps\n\n<Steps>\n  <Step title=\"Navigate to webhook settings\">\n    Go to **Settings** > **Integrations** > **Webhooks**.\n  </Step>\n\n  <Step title=\"Add a new webhook endpoint\">\n    Click **Add Endpoint** and enter your webhook URL:\n\n    ```\n    https://your-domain.com/webhooks/receiver\n    ```\n\n    <Note>\n    Your endpoint must use HTTPS and be publicly accessible.\n    </Note>\n  </Step>\n\n  <Step title=\"Select events to subscribe\">\n    Choose which events should trigger notifications:\n\n    - `user.created` - New user sign up\n    - `payment.completed` - Successful payment\n    - `subscription.cancelled` - Subscription ended\n\n    Select at least one event to continue.\n  </Step>\n\n  <Step title=\"Save and get your signing secret\">\n    Click **Create Webhook**. Copy the signing secret shown - you'll need this to verify webhook authenticity.\n\n    <Warning>\n    Store the signing secret securely. It won't be shown again.\n    </Warning>\n  </Step>\n</Steps>\n\n## Verify it worked\n\nSend a test event by clicking **Send Test** next to your webhook. You should receive a POST request at your endpoint with this structure:\n\n```json\n{\n  \"event\": \"test.webhook\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"data\": {}\n}\n```\n\nCheck your endpoint logs to confirm receipt.\n\n## Troubleshooting\n\n<AccordionGroup>\n  <Accordion title=\"Webhook not receiving events\">\n    - Verify your endpoint is publicly accessible\n    - Check that your SSL certificate is valid\n    - Ensure your server responds with 2xx status within 30 seconds\n  </Accordion>\n\n  <Accordion title=\"Signature verification failing\">\n    - Confirm you're using the correct signing secret\n    - Check that you're reading the raw request body (not parsed JSON)\n    - See our [signature verification guide](/reference/webhook-signatures)\n  </Accordion>\n</AccordionGroup>\n\n## Next steps\n\n- [How to verify webhook signatures](/how-to/verify-webhook-signatures)\n- [Webhook event reference](/reference/webhook-events)\n- [How to handle webhook retries](/how-to/webhook-retry-handling)\n```\n\n## Checklist for How-To Guides\n\nBefore publishing, verify:\n\n- [ ] Title starts with \"How to\" and describes a specific goal\n- [ ] Prerequisites section lists all requirements\n- [ ] Each step is a single, clear action\n- [ ] Action verbs start each step (Click, Enter, Select, Run)\n- [ ] Expected outcomes shown after key steps\n- [ ] Verification section explains how to confirm success\n- [ ] Troubleshooting covers common issues\n- [ ] Next steps link to related content\n- [ ] No unnecessary explanations - links to concepts instead\n- [ ] Written from user perspective, not product perspective\n\n## When to Use How-To vs Other Doc Types\n\n| User's mindset | Doc type | Example |\n|---------------|----------|---------|\n| \"I want to learn\" | Tutorial | \"Getting started with our API\" |\n| \"I want to do X\" | How-To | \"How to configure SSO\" |\n| \"I want to understand\" | Explanation | \"How our caching works\" |\n| \"I need to look up Y\" | Reference | \"API endpoint reference\" |\n\n## Related Skills\n\n- **docs-style**: Core writing conventions and components\n- **tutorial-docs**: Tutorial patterns for learning-oriented content\n- **reference-docs**: Reference documentation patterns\n- **explanation-docs**: Conceptual documentation patterns\n",
        "skills/langgraph-architecture/SKILL.md": "---\nname: langgraph-architecture\ndescription: Guides architectural decisions for LangGraph applications. Use when deciding between LangGraph vs alternatives, choosing state management strategies, designing multi-agent systems, or selecting persistence and streaming approaches.\n---\n\n# LangGraph Architecture Decisions\n\n## When to Use LangGraph\n\n### Use LangGraph When You Need:\n\n- **Stateful conversations** - Multi-turn interactions with memory\n- **Human-in-the-loop** - Approval gates, corrections, interventions\n- **Complex control flow** - Loops, branches, conditional routing\n- **Multi-agent coordination** - Multiple LLMs working together\n- **Persistence** - Resume from checkpoints, time travel debugging\n- **Streaming** - Real-time token streaming, progress updates\n- **Reliability** - Retries, error recovery, durability guarantees\n\n### Consider Alternatives When:\n\n| Scenario | Alternative | Why |\n|----------|-------------|-----|\n| Single LLM call | Direct API call | Overhead not justified |\n| Linear pipeline | LangChain LCEL | Simpler abstraction |\n| Stateless tool use | Function calling | No persistence needed |\n| Simple RAG | LangChain retrievers | Built-in patterns |\n| Batch processing | Async tasks | Different execution model |\n\n## State Schema Decisions\n\n### TypedDict vs Pydantic\n\n| TypedDict | Pydantic |\n|-----------|----------|\n| Lightweight, faster | Runtime validation |\n| Dict-like access | Attribute access |\n| No validation overhead | Type coercion |\n| Simpler serialization | Complex nested models |\n\n**Recommendation**: Use TypedDict for most cases. Use Pydantic when you need validation or complex nested structures.\n\n### Reducer Selection\n\n| Use Case | Reducer | Example |\n|----------|---------|---------|\n| Chat messages | `add_messages` | Handles IDs, RemoveMessage |\n| Simple append | `operator.add` | `Annotated[list, operator.add]` |\n| Keep latest | None (LastValue) | `field: str` |\n| Custom merge | Lambda | `Annotated[list, lambda a, b: ...]` |\n| Overwrite list | `Overwrite` | Bypass reducer |\n\n### State Size Considerations\n\n```python\n# SMALL STATE (< 1MB) - Put in state\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n    context: str\n\n# LARGE DATA - Use Store\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n    document_ref: str  # Reference to store\n\ndef node(state, *, store: BaseStore):\n    doc = store.get(namespace, state[\"document_ref\"])\n    # Process without bloating checkpoints\n```\n\n## Graph Structure Decisions\n\n### Single Graph vs Subgraphs\n\n**Single Graph** when:\n- All nodes share the same state schema\n- Simple linear or branching flow\n- < 10 nodes\n\n**Subgraphs** when:\n- Different state schemas needed\n- Reusable components across graphs\n- Team separation of concerns\n- Complex hierarchical workflows\n\n### Conditional Edges vs Command\n\n| Conditional Edges | Command |\n|------------------|---------|\n| Routing based on state | Routing + state update |\n| Separate router function | Decision in node |\n| Clearer visualization | More flexible |\n| Standard patterns | Dynamic destinations |\n\n```python\n# Conditional Edge - when routing is the focus\ndef router(state) -> Literal[\"a\", \"b\"]:\n    return \"a\" if condition else \"b\"\nbuilder.add_conditional_edges(\"node\", router)\n\n# Command - when combining routing with updates\ndef node(state) -> Command:\n    return Command(goto=\"next\", update={\"step\": state[\"step\"] + 1})\n```\n\n### Static vs Dynamic Routing\n\n**Static Edges** (`add_edge`):\n- Fixed flow known at build time\n- Clearer graph visualization\n- Easier to reason about\n\n**Dynamic Routing** (`add_conditional_edges`, `Command`, `Send`):\n- Runtime decisions based on state\n- Agent-driven navigation\n- Fan-out patterns\n\n## Persistence Strategy\n\n### Checkpointer Selection\n\n| Checkpointer | Use Case | Characteristics |\n|--------------|----------|-----------------|\n| `InMemorySaver` | Testing only | Lost on restart |\n| `SqliteSaver` | Development | Single file, local |\n| `PostgresSaver` | Production | Scalable, concurrent |\n| Custom | Special needs | Implement BaseCheckpointSaver |\n\n### Checkpointing Scope\n\n```python\n# Full persistence (default)\ngraph = builder.compile(checkpointer=checkpointer)\n\n# Subgraph options\nsubgraph = sub_builder.compile(\n    checkpointer=None,   # Inherit from parent\n    checkpointer=True,   # Independent checkpointing\n    checkpointer=False,  # No checkpointing (runs atomically)\n)\n```\n\n### When to Disable Checkpointing\n\n- Short-lived subgraphs that should be atomic\n- Subgraphs with incompatible state schemas\n- Performance-critical paths without need for resume\n\n## Multi-Agent Architecture\n\n### Supervisor Pattern\n\nBest for:\n- Clear hierarchy\n- Centralized decision making\n- Different agent specializations\n\n```\n          \n            Supervisor \n          \n    \n                           \n   \nAgent1 Agent2 Agent3 Agent4\n   \n```\n\n### Peer-to-Peer Pattern\n\nBest for:\n- Collaborative agents\n- No clear hierarchy\n- Flexible communication\n\n```\n     \nAgent1Agent2\n     \n                \n                \n     \nAgent3Agent4\n     \n```\n\n### Handoff Pattern\n\nBest for:\n- Sequential specialization\n- Clear stage transitions\n- Different capabilities per stage\n\n```\n        \nResearchPlanningExecute \n        \n```\n\n## Streaming Strategy\n\n### Stream Mode Selection\n\n| Mode | Use Case | Data |\n|------|----------|------|\n| `updates` | UI updates | Node outputs only |\n| `values` | State inspection | Full state each step |\n| `messages` | Chat UX | LLM tokens |\n| `custom` | Progress/logs | Your data via StreamWriter |\n| `debug` | Debugging | Tasks + checkpoints |\n\n### Subgraph Streaming\n\n```python\n# Stream from subgraphs\nasync for chunk in graph.astream(\n    input,\n    stream_mode=\"updates\",\n    subgraphs=True  # Include subgraph events\n):\n    namespace, data = chunk  # namespace indicates depth\n```\n\n## Human-in-the-Loop Design\n\n### Interrupt Placement\n\n| Strategy | Use Case |\n|----------|----------|\n| `interrupt_before` | Approval before action |\n| `interrupt_after` | Review after completion |\n| `interrupt()` in node | Dynamic, contextual pauses |\n\n### Resume Patterns\n\n```python\n# Simple resume (same thread)\ngraph.invoke(None, config)\n\n# Resume with value\ngraph.invoke(Command(resume=\"approved\"), config)\n\n# Resume specific interrupt\ngraph.invoke(Command(resume={interrupt_id: value}), config)\n\n# Modify state and resume\ngraph.update_state(config, {\"field\": \"new_value\"})\ngraph.invoke(None, config)\n```\n\n## Error Handling Strategy\n\n### Retry Configuration\n\n```python\n# Per-node retry\nRetryPolicy(\n    initial_interval=0.5,\n    backoff_factor=2.0,\n    max_interval=60.0,\n    max_attempts=3,\n    retry_on=lambda e: isinstance(e, (APIError, TimeoutError))\n)\n\n# Multiple policies (first match wins)\nbuilder.add_node(\"node\", fn, retry_policy=[\n    RetryPolicy(retry_on=RateLimitError, max_attempts=5),\n    RetryPolicy(retry_on=Exception, max_attempts=2),\n])\n```\n\n### Fallback Patterns\n\n```python\ndef node_with_fallback(state):\n    try:\n        return primary_operation(state)\n    except PrimaryError:\n        return fallback_operation(state)\n\n# Or use conditional edges for complex fallback routing\ndef route_on_error(state) -> Literal[\"retry\", \"fallback\", \"__end__\"]:\n    if state.get(\"error\") and state[\"attempts\"] < 3:\n        return \"retry\"\n    elif state.get(\"error\"):\n        return \"fallback\"\n    return END\n```\n\n## Scaling Considerations\n\n### Horizontal Scaling\n\n- Use PostgresSaver for shared state\n- Consider LangGraph Platform for managed infrastructure\n- Use stores for large data outside checkpoints\n\n### Performance Optimization\n\n1. **Minimize state size** - Use references for large data\n2. **Parallel nodes** - Fan out when possible\n3. **Cache expensive operations** - Use CachePolicy\n4. **Async everywhere** - Use ainvoke, astream\n\n### Resource Limits\n\n```python\n# Set recursion limit\nconfig = {\"recursion_limit\": 50}\ngraph.invoke(input, config)\n\n# Track remaining steps in state\nclass State(TypedDict):\n    remaining_steps: RemainingSteps\n\ndef check_budget(state):\n    if state[\"remaining_steps\"] < 5:\n        return \"wrap_up\"\n    return \"continue\"\n```\n\n## Decision Checklist\n\nBefore implementing:\n\n1. [ ] Is LangGraph the right tool? (vs simpler alternatives)\n2. [ ] State schema defined with appropriate reducers?\n3. [ ] Persistence strategy chosen? (dev vs prod checkpointer)\n4. [ ] Streaming needs identified?\n5. [ ] Human-in-the-loop points defined?\n6. [ ] Error handling and retry strategy?\n7. [ ] Multi-agent coordination pattern? (if applicable)\n8. [ ] Resource limits configured?\n",
        "skills/langgraph-code-review/SKILL.md": "---\nname: langgraph-code-review\ndescription: Reviews LangGraph code for bugs, anti-patterns, and improvements. Use when reviewing code that uses StateGraph, nodes, edges, checkpointing, or other LangGraph features. Catches common mistakes in state management, graph structure, and async patterns.\n---\n\n# LangGraph Code Review\n\nWhen reviewing LangGraph code, check for these categories of issues.\n\n## Critical Issues\n\n### 1. State Mutation Instead of Return\n\n```python\n# BAD - mutates state directly\ndef my_node(state: State) -> None:\n    state[\"messages\"].append(new_message)  # Mutation!\n\n# GOOD - returns partial update\ndef my_node(state: State) -> dict:\n    return {\"messages\": [new_message]}  # Let reducer handle it\n```\n\n### 2. Missing Reducer for List Fields\n\n```python\n# BAD - no reducer, each node overwrites\nclass State(TypedDict):\n    messages: list  # Will be overwritten, not appended!\n\n# GOOD - reducer appends\nclass State(TypedDict):\n    messages: Annotated[list, operator.add]\n    # Or use add_messages for chat:\n    messages: Annotated[list, add_messages]\n```\n\n### 3. Wrong Return Type from Conditional Edge\n\n```python\n# BAD - returns invalid node name\ndef router(state) -> str:\n    return \"nonexistent_node\"  # Runtime error!\n\n# GOOD - use Literal type hint for safety\ndef router(state) -> Literal[\"agent\", \"tools\", \"__end__\"]:\n    if condition:\n        return \"agent\"\n    return END  # Use constant, not string\n```\n\n### 4. Missing Checkpointer for Interrupts\n\n```python\n# BAD - interrupt without checkpointer\ndef my_node(state):\n    answer = interrupt(\"question\")  # Will fail!\n    return {\"answer\": answer}\n\ngraph = builder.compile()  # No checkpointer!\n\n# GOOD - checkpointer required for interrupts\ngraph = builder.compile(checkpointer=InMemorySaver())\n```\n\n### 5. Forgetting Thread ID with Checkpointer\n\n```python\n# BAD - no thread_id\ngraph.invoke({\"messages\": [...]})  # Error with checkpointer!\n\n# GOOD - always provide thread_id\nconfig = {\"configurable\": {\"thread_id\": \"user-123\"}}\ngraph.invoke({\"messages\": [...]}, config)\n```\n\n## State Schema Issues\n\n### 6. Using add_messages Without Message Types\n\n```python\n# BAD - add_messages expects message-like objects\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n\ndef node(state):\n    return {\"messages\": [\"plain string\"]}  # May fail!\n\n# GOOD - use proper message types or tuples\ndef node(state):\n    return {\"messages\": [(\"assistant\", \"response\")]}\n    # Or: [AIMessage(content=\"response\")]\n```\n\n### 7. Returning Full State Instead of Partial\n\n```python\n# BAD - returns entire state (may reset other fields)\ndef my_node(state: State) -> State:\n    return {\n        \"counter\": state[\"counter\"] + 1,\n        \"messages\": state[\"messages\"],  # Unnecessary!\n        \"other\": state[\"other\"]          # Unnecessary!\n    }\n\n# GOOD - return only changed fields\ndef my_node(state: State) -> dict:\n    return {\"counter\": state[\"counter\"] + 1}\n```\n\n### 8. Pydantic State Without Annotations\n\n```python\n# BAD - Pydantic model without reducer loses append behavior\nclass State(BaseModel):\n    messages: list  # No reducer!\n\n# GOOD - use Annotated even with Pydantic\nclass State(BaseModel):\n    messages: Annotated[list, add_messages]\n```\n\n## Graph Structure Issues\n\n### 9. Missing Entry Point\n\n```python\n# BAD - no edge from START\nbuilder.add_node(\"process\", process_fn)\nbuilder.add_edge(\"process\", END)\ngraph = builder.compile()  # Error: no entrypoint!\n\n# GOOD - connect START\nbuilder.add_edge(START, \"process\")\n```\n\n### 10. Unreachable Nodes\n\n```python\n# BAD - orphan node\nbuilder.add_node(\"main\", main_fn)\nbuilder.add_node(\"orphan\", orphan_fn)  # Never reached!\nbuilder.add_edge(START, \"main\")\nbuilder.add_edge(\"main\", END)\n\n# Check with visualization\nprint(graph.get_graph().draw_mermaid())\n```\n\n### 11. Conditional Edge Without All Paths\n\n```python\n# BAD - missing path in conditional\ndef router(state) -> Literal[\"a\", \"b\", \"c\"]:\n    ...\n\nbuilder.add_conditional_edges(\"node\", router, {\"a\": \"a\", \"b\": \"b\"})\n# \"c\" path missing!\n\n# GOOD - include all possible returns\nbuilder.add_conditional_edges(\"node\", router, {\"a\": \"a\", \"b\": \"b\", \"c\": \"c\"})\n# Or omit path_map to use return values as node names\n```\n\n### 12. Command Without destinations\n\n```python\n# BAD - Command return without destinations (breaks visualization)\ndef dynamic(state) -> Command[Literal[\"next\", \"__end__\"]]:\n    return Command(goto=\"next\")\n\nbuilder.add_node(\"dynamic\", dynamic)  # Graph viz won't show edges\n\n# GOOD - declare destinations\nbuilder.add_node(\"dynamic\", dynamic, destinations=[\"next\", END])\n```\n\n## Async Issues\n\n### 13. Mixing Sync/Async Incorrectly\n\n```python\n# BAD - async node called with sync invoke\nasync def my_node(state):\n    result = await async_operation()\n    return {\"result\": result}\n\ngraph.invoke(input)  # May not await properly!\n\n# GOOD - use ainvoke for async graphs\nawait graph.ainvoke(input)\n# Or provide both sync and async versions\n```\n\n### 14. Blocking Calls in Async Context\n\n```python\n# BAD - blocking call in async node\nasync def my_node(state):\n    result = requests.get(url)  # Blocks event loop!\n    return {\"result\": result}\n\n# GOOD - use async HTTP client\nasync def my_node(state):\n    async with httpx.AsyncClient() as client:\n        result = await client.get(url)\n    return {\"result\": result}\n```\n\n## Tool Integration Issues\n\n### 15. Tool Calls Without Corresponding ToolMessage\n\n```python\n# BAD - AI message with tool_calls but no tool execution\nmessages = [\n    HumanMessage(content=\"search for X\"),\n    AIMessage(content=\"\", tool_calls=[{\"id\": \"1\", \"name\": \"search\", ...}])\n    # Missing ToolMessage! Next LLM call will fail\n]\n\n# GOOD - always pair tool_calls with ToolMessage\nmessages = [\n    HumanMessage(content=\"search for X\"),\n    AIMessage(content=\"\", tool_calls=[{\"id\": \"1\", \"name\": \"search\", ...}]),\n    ToolMessage(content=\"results\", tool_call_id=\"1\")\n]\n```\n\n### 16. Parallel Tool Calls Before Interrupt\n\n```python\n# BAD - model may call multiple tools including interrupt\nmodel = ChatOpenAI().bind_tools([interrupt_tool, other_tool])\n# If both called in parallel, interrupt behavior is undefined\n\n# GOOD - disable parallel tool calls before interrupt\nmodel = ChatOpenAI().bind_tools(\n    [interrupt_tool, other_tool],\n    parallel_tool_calls=False\n)\n```\n\n## Checkpointing Issues\n\n### 17. InMemorySaver in Production\n\n```python\n# BAD - in-memory checkpointer loses state on restart\ngraph = builder.compile(checkpointer=InMemorySaver())  # Testing only!\n\n# GOOD - use persistent storage in production\nfrom langgraph.checkpoint.postgres import PostgresSaver\ncheckpointer = PostgresSaver.from_conn_string(conn_string)\ngraph = builder.compile(checkpointer=checkpointer)\n```\n\n### 18. Subgraph Checkpointer Confusion\n\n```python\n# BAD - subgraph with explicit False prevents persistence\nsubgraph = sub_builder.compile(checkpointer=False)\n\n# GOOD - use None to inherit parent's checkpointer\nsubgraph = sub_builder.compile(checkpointer=None)  # Inherits from parent\n# Or True for independent checkpointing\nsubgraph = sub_builder.compile(checkpointer=True)\n```\n\n## Performance Issues\n\n### 19. Large State in Every Update\n\n```python\n# BAD - returning large data in every node\ndef node(state):\n    large_data = fetch_large_data()\n    return {\"large_field\": large_data}  # Checkpointed every step!\n\n# GOOD - use references or store\nfrom langgraph.store.memory import InMemoryStore\n\ndef node(state, *, store: BaseStore):\n    store.put(namespace, key, large_data)\n    return {\"data_ref\": f\"{namespace}/{key}\"}\n```\n\n### 20. Missing Recursion Limit Handling\n\n```python\n# BAD - no protection against infinite loops\ndef router(state):\n    return \"agent\"  # Always loops!\n\n# GOOD - check remaining steps or use RemainingSteps\nfrom langgraph.managed import RemainingSteps\n\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n    remaining_steps: RemainingSteps\n\ndef check_limit(state):\n    if state[\"remaining_steps\"] < 2:\n        return END\n    return \"continue\"\n```\n\n## Code Review Checklist\n\n1. [ ] State schema uses Annotated with reducers for collections\n2. [ ] Nodes return partial state updates, not mutations\n3. [ ] Conditional edges return valid node names or END\n4. [ ] Graph has path from START to all nodes\n5. [ ] Checkpointer provided if using interrupts\n6. [ ] Thread ID provided in config when using checkpointer\n7. [ ] Tool calls paired with ToolMessages\n8. [ ] Async nodes use async operations\n9. [ ] Production uses persistent checkpointer\n10. [ ] Recursion limits considered for loops\n",
        "skills/langgraph-implementation/PATTERNS.md": "# Advanced LangGraph Patterns\n\n## Multi-Agent Supervisor Pattern\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command\nfrom typing import Literal\n\nclass SupervisorState(TypedDict):\n    messages: Annotated[list, add_messages]\n    next_agent: str\n\ndef supervisor(state: SupervisorState) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n    \"\"\"Route to appropriate agent based on task.\"\"\"\n    # LLM decides which agent to use\n    decision = llm.invoke(state[\"messages\"])\n    if \"research\" in decision.content.lower():\n        return Command(goto=\"researcher\")\n    elif \"code\" in decision.content.lower():\n        return Command(goto=\"coder\")\n    return Command(goto=END)\n\ndef researcher(state: SupervisorState) -> dict:\n    result = research_agent.invoke(state[\"messages\"])\n    return {\"messages\": [result]}\n\ndef coder(state: SupervisorState) -> dict:\n    result = coding_agent.invoke(state[\"messages\"])\n    return {\"messages\": [result]}\n\nbuilder = StateGraph(SupervisorState)\nbuilder.add_node(\"supervisor\", supervisor, destinations=[\"researcher\", \"coder\", END])\nbuilder.add_node(\"researcher\", researcher)\nbuilder.add_node(\"coder\", coder)\nbuilder.add_edge(START, \"supervisor\")\nbuilder.add_edge(\"researcher\", \"supervisor\")\nbuilder.add_edge(\"coder\", \"supervisor\")\n```\n\n## Map-Reduce Pattern\n\n```python\nfrom langgraph.types import Send\n\nclass MapReduceState(TypedDict):\n    topics: list[str]\n    results: Annotated[list[str], operator.add]  # Reducer aggregates\n\ndef distribute(state: MapReduceState) -> list[Send]:\n    \"\"\"Fan out to process each topic.\"\"\"\n    return [Send(\"process_topic\", {\"topic\": t}) for t in state[\"topics\"]]\n\ndef process_topic(state: dict) -> dict:\n    \"\"\"Process individual topic (receives Send payload).\"\"\"\n    result = analyze(state[\"topic\"])\n    return {\"results\": [result]}\n\ndef aggregate(state: MapReduceState) -> dict:\n    \"\"\"Combine all results.\"\"\"\n    summary = summarize(state[\"results\"])\n    return {\"summary\": summary}\n\nbuilder = StateGraph(MapReduceState)\nbuilder.add_conditional_edges(START, distribute)\nbuilder.add_edge(\"process_topic\", \"aggregate\")\nbuilder.add_edge(\"aggregate\", END)\n```\n\n## Hierarchical Graph Pattern\n\n```python\n# Inner graph - specialized task\nclass InnerState(TypedDict):\n    query: str\n    result: str\n\ninner_builder = StateGraph(InnerState)\ninner_builder.add_node(\"search\", search_fn)\ninner_builder.add_node(\"analyze\", analyze_fn)\ninner_builder.add_edge(START, \"search\")\ninner_builder.add_edge(\"search\", \"analyze\")\ninner_builder.add_edge(\"analyze\", END)\ninner_graph = inner_builder.compile()\n\n# Outer graph - orchestration\nclass OuterState(TypedDict):\n    messages: Annotated[list, add_messages]\n    research_result: str\n\ndef prepare_research(state: OuterState) -> dict:\n    \"\"\"Transform outer state for inner graph.\"\"\"\n    return {\"query\": state[\"messages\"][-1].content}\n\ndef process_result(state: OuterState) -> dict:\n    \"\"\"Handle result from inner graph.\"\"\"\n    return {\"messages\": [AIMessage(content=state[\"research_result\"])]}\n\nouter_builder = StateGraph(OuterState)\nouter_builder.add_node(\"prepare\", prepare_research)\nouter_builder.add_node(\"research\", inner_graph)  # Subgraph as node\nouter_builder.add_node(\"process\", process_result)\nouter_builder.add_edge(START, \"prepare\")\nouter_builder.add_edge(\"prepare\", \"research\")\nouter_builder.add_edge(\"research\", \"process\")\nouter_builder.add_edge(\"process\", END)\n```\n\n## Reflection/Self-Correction Pattern\n\n```python\nclass ReflectionState(TypedDict):\n    draft: str\n    feedback: str\n    revision_count: int\n\ndef generate(state: ReflectionState) -> dict:\n    if state.get(\"feedback\"):\n        prompt = f\"Revise based on: {state['feedback']}\\n\\nDraft: {state['draft']}\"\n    else:\n        prompt = \"Generate initial draft\"\n    return {\"draft\": llm.invoke(prompt).content}\n\ndef reflect(state: ReflectionState) -> dict:\n    feedback = critic_llm.invoke(f\"Critique this: {state['draft']}\").content\n    return {\"feedback\": feedback, \"revision_count\": state.get(\"revision_count\", 0) + 1}\n\ndef should_continue(state: ReflectionState) -> Literal[\"generate\", \"__end__\"]:\n    if state[\"revision_count\"] >= 3:\n        return END\n    if \"looks good\" in state[\"feedback\"].lower():\n        return END\n    return \"generate\"\n\nbuilder = StateGraph(ReflectionState)\nbuilder.add_node(\"generate\", generate)\nbuilder.add_node(\"reflect\", reflect)\nbuilder.add_edge(START, \"generate\")\nbuilder.add_edge(\"generate\", \"reflect\")\nbuilder.add_conditional_edges(\"reflect\", should_continue)\n```\n\n## Plan-and-Execute Pattern\n\n```python\nclass PlanExecuteState(TypedDict):\n    objective: str\n    plan: list[str]\n    completed_steps: Annotated[list[str], operator.add]\n    current_step: int\n\ndef planner(state: PlanExecuteState) -> dict:\n    plan = planning_llm.invoke(f\"Create plan for: {state['objective']}\")\n    steps = parse_steps(plan.content)\n    return {\"plan\": steps, \"current_step\": 0}\n\ndef executor(state: PlanExecuteState) -> dict:\n    step = state[\"plan\"][state[\"current_step\"]]\n    result = execute_step(step)\n    return {\n        \"completed_steps\": [f\"{step}: {result}\"],\n        \"current_step\": state[\"current_step\"] + 1\n    }\n\ndef should_continue(state: PlanExecuteState) -> Literal[\"executor\", \"__end__\"]:\n    if state[\"current_step\"] >= len(state[\"plan\"]):\n        return END\n    return \"executor\"\n\nbuilder = StateGraph(PlanExecuteState)\nbuilder.add_node(\"planner\", planner)\nbuilder.add_node(\"executor\", executor)\nbuilder.add_edge(START, \"planner\")\nbuilder.add_edge(\"planner\", \"executor\")\nbuilder.add_conditional_edges(\"executor\", should_continue)\n```\n\n## Human Approval Gate Pattern\n\n```python\nfrom langgraph.types import interrupt, Command\n\nclass ApprovalState(TypedDict):\n    action: str\n    approved: bool\n    result: str\n\ndef propose_action(state: ApprovalState) -> dict:\n    action = determine_action(state)\n    return {\"action\": action}\n\ndef human_review(state: ApprovalState) -> dict:\n    decision = interrupt({\n        \"action\": state[\"action\"],\n        \"message\": \"Please approve or reject this action\"\n    })\n    return {\"approved\": decision.get(\"approved\", False)}\n\ndef execute_action(state: ApprovalState) -> dict:\n    if state[\"approved\"]:\n        result = execute(state[\"action\"])\n    else:\n        result = \"Action rejected by human\"\n    return {\"result\": result}\n\ndef route_after_review(state: ApprovalState) -> Literal[\"execute\", \"__end__\"]:\n    return \"execute\" if state[\"approved\"] else END\n\nbuilder = StateGraph(ApprovalState)\nbuilder.add_node(\"propose\", propose_action)\nbuilder.add_node(\"review\", human_review)\nbuilder.add_node(\"execute\", execute_action)\nbuilder.add_edge(START, \"propose\")\nbuilder.add_edge(\"propose\", \"review\")\nbuilder.add_conditional_edges(\"review\", route_after_review)\nbuilder.add_edge(\"execute\", END)\n\ngraph = builder.compile(checkpointer=checkpointer)\n\n# Usage\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\nresult = graph.invoke({\"action\": \"\"}, config)\n# Graph pauses at review node\n\n# Resume with approval\ngraph.invoke(Command(resume={\"approved\": True}), config)\n```\n\n## Branching and Joining\n\n```python\nclass BranchState(TypedDict):\n    input: str\n    branch_a_result: str\n    branch_b_result: str\n    final_result: str\n\nbuilder = StateGraph(BranchState)\nbuilder.add_node(\"branch_a\", branch_a_fn)\nbuilder.add_node(\"branch_b\", branch_b_fn)\nbuilder.add_node(\"join\", join_fn)\n\n# Fan out - both run in parallel\nbuilder.add_edge(START, \"branch_a\")\nbuilder.add_edge(START, \"branch_b\")\n\n# Fan in - wait for both\nbuilder.add_edge([\"branch_a\", \"branch_b\"], \"join\")\nbuilder.add_edge(\"join\", END)\n```\n\n## Looping with Counter\n\n```python\nclass LoopState(TypedDict):\n    value: int\n    iterations: int\n\ndef increment(state: LoopState) -> dict:\n    return {\n        \"value\": state[\"value\"] * 2,\n        \"iterations\": state[\"iterations\"] + 1\n    }\n\ndef should_loop(state: LoopState) -> Literal[\"increment\", \"__end__\"]:\n    if state[\"iterations\"] >= 5:\n        return END\n    if state[\"value\"] >= 1000:\n        return END\n    return \"increment\"\n\nbuilder = StateGraph(LoopState)\nbuilder.add_node(\"increment\", increment)\nbuilder.add_edge(START, \"increment\")\nbuilder.add_conditional_edges(\"increment\", should_loop)\n```\n\n## Error Recovery Pattern\n\n```python\nfrom langgraph.types import RetryPolicy\n\nclass ErrorRecoveryState(TypedDict):\n    input: str\n    result: str\n    error: str\n    attempts: int\n\ndef risky_operation(state: ErrorRecoveryState) -> dict:\n    try:\n        result = dangerous_api_call(state[\"input\"])\n        return {\"result\": result, \"error\": \"\"}\n    except Exception as e:\n        return {\"error\": str(e), \"attempts\": state.get(\"attempts\", 0) + 1}\n\ndef fallback(state: ErrorRecoveryState) -> dict:\n    return {\"result\": f\"Fallback result for: {state['input']}\"}\n\ndef route_after_operation(state: ErrorRecoveryState) -> Literal[\"fallback\", \"__end__\"]:\n    if state[\"error\"] and state[\"attempts\"] >= 3:\n        return \"fallback\"\n    if state[\"error\"]:\n        return \"risky_operation\"  # Retry\n    return END\n\n# With RetryPolicy for automatic retries\nretry = RetryPolicy(max_attempts=3, retry_on=ConnectionError)\nbuilder.add_node(\"risky_operation\", risky_operation, retry_policy=retry)\n```\n",
        "skills/langgraph-implementation/SKILL.md": "---\nname: langgraph-implementation\ndescription: Implements stateful agent graphs using LangGraph. Use when building graphs, adding nodes/edges, defining state schemas, implementing checkpointing, handling interrupts, or creating multi-agent systems with LangGraph.\n---\n\n# LangGraph Implementation\n\n## Core Concepts\n\nLangGraph builds stateful, multi-actor agent applications using a graph-based architecture:\n\n- **StateGraph**: Builder class for defining graphs with shared state\n- **Nodes**: Functions that read state and return partial updates\n- **Edges**: Define execution flow (static or conditional)\n- **Channels**: Internal state management (LastValue, BinaryOperatorAggregate)\n- **Checkpointer**: Persistence for pause/resume capabilities\n\n## Essential Imports\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import MessagesState, add_messages\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import Command, Send, interrupt, RetryPolicy\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\n```\n\n## State Schema Patterns\n\n### Basic State with TypedDict\n\n```python\nclass State(TypedDict):\n    counter: int                                    # LastValue - stores last value\n    messages: Annotated[list, operator.add]         # Reducer - appends lists\n    items: Annotated[list, lambda a, b: a + [b] if b else a]  # Custom reducer\n```\n\n### MessagesState for Chat Applications\n\n```python\nfrom langgraph.graph.message import MessagesState\n\nclass State(MessagesState):\n    # Inherits: messages: Annotated[list[AnyMessage], add_messages]\n    user_id: str\n    context: dict\n```\n\n### Pydantic State (for validation)\n\n```python\nfrom pydantic import BaseModel\n\nclass State(BaseModel):\n    messages: Annotated[list, add_messages]\n    validated_field: str  # Pydantic validates on assignment\n```\n\n## Building Graphs\n\n### Basic Pattern\n\n```python\nbuilder = StateGraph(State)\n\n# Add nodes - functions that take state, return partial updates\nbuilder.add_node(\"process\", process_fn)\nbuilder.add_node(\"decide\", decide_fn)\n\n# Add edges\nbuilder.add_edge(START, \"process\")\nbuilder.add_edge(\"process\", \"decide\")\nbuilder.add_edge(\"decide\", END)\n\n# Compile\ngraph = builder.compile()\n```\n\n### Node Function Signature\n\n```python\ndef my_node(state: State) -> dict:\n    \"\"\"Node receives full state, returns partial update.\"\"\"\n    return {\"counter\": state[\"counter\"] + 1}\n\n# With config access\ndef my_node(state: State, config: RunnableConfig) -> dict:\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    return {\"result\": process(state, thread_id)}\n\n# With Runtime context (v0.6+)\ndef my_node(state: State, runtime: Runtime[Context]) -> dict:\n    user_id = runtime.context.get(\"user_id\")\n    return {\"result\": user_id}\n```\n\n### Conditional Edges\n\n```python\nfrom typing import Literal\n\ndef router(state: State) -> Literal[\"agent\", \"tools\", \"__end__\"]:\n    last_msg = state[\"messages\"][-1]\n    if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n        return \"tools\"\n    return END  # or \"__end__\"\n\nbuilder.add_conditional_edges(\"agent\", router)\n\n# With path_map for visualization\nbuilder.add_conditional_edges(\n    \"agent\",\n    router,\n    path_map={\"agent\": \"agent\", \"tools\": \"tools\", \"__end__\": END}\n)\n```\n\n### Command Pattern (Dynamic Routing + State Update)\n\n```python\nfrom langgraph.types import Command\n\ndef dynamic_node(state: State) -> Command[Literal[\"next\", \"__end__\"]]:\n    if state[\"should_continue\"]:\n        return Command(goto=\"next\", update={\"step\": state[\"step\"] + 1})\n    return Command(goto=END)\n\n# Must declare destinations for visualization\nbuilder.add_node(\"dynamic\", dynamic_node, destinations=[\"next\", END])\n```\n\n### Send Pattern (Fan-out/Map-Reduce)\n\n```python\nfrom langgraph.types import Send\n\ndef fan_out(state: State) -> list[Send]:\n    \"\"\"Route to multiple node instances with different inputs.\"\"\"\n    return [Send(\"worker\", {\"item\": item}) for item in state[\"items\"]]\n\nbuilder.add_conditional_edges(START, fan_out)\nbuilder.add_edge(\"worker\", \"aggregate\")  # Workers converge\n```\n\n## Checkpointing\n\n### Enable Persistence\n\n```python\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.checkpoint.sqlite import SqliteSaver  # Development\nfrom langgraph.checkpoint.postgres import PostgresSaver  # Production\n\n# In-memory (testing only)\ngraph = builder.compile(checkpointer=InMemorySaver())\n\n# SQLite (development)\nwith SqliteSaver.from_conn_string(\"checkpoints.db\") as checkpointer:\n    graph = builder.compile(checkpointer=checkpointer)\n\n# Thread-based invocation\nconfig = {\"configurable\": {\"thread_id\": \"user-123\"}}\nresult = graph.invoke({\"messages\": [...]}, config)\n```\n\n### State Management\n\n```python\n# Get current state\nstate = graph.get_state(config)\n\n# Get state history\nfor state in graph.get_state_history(config):\n    print(state.values, state.next)\n\n# Update state manually\ngraph.update_state(config, {\"key\": \"new_value\"}, as_node=\"node_name\")\n```\n\n## Human-in-the-Loop\n\n### Using interrupt()\n\n```python\nfrom langgraph.types import interrupt, Command\n\ndef review_node(state: State) -> dict:\n    # Pause and surface value to client\n    human_input = interrupt({\"question\": \"Please review\", \"data\": state[\"draft\"]})\n    return {\"approved\": human_input[\"approved\"]}\n\n# Resume with Command\ngraph.invoke(Command(resume={\"approved\": True}), config)\n```\n\n### Interrupt Before/After Nodes\n\n```python\ngraph = builder.compile(\n    checkpointer=checkpointer,\n    interrupt_before=[\"human_review\"],  # Pause before node\n    interrupt_after=[\"agent\"],          # Pause after node\n)\n\n# Check pending interrupts\nstate = graph.get_state(config)\nif state.next:  # Has pending nodes\n    # Resume\n    graph.invoke(None, config)\n```\n\n## Streaming\n\n```python\n# Stream modes: \"values\", \"updates\", \"custom\", \"messages\", \"debug\"\n\n# Updates only (node outputs)\nfor chunk in graph.stream(input, stream_mode=\"updates\"):\n    print(chunk)  # {\"node_name\": {\"key\": \"value\"}}\n\n# Full state after each step\nfor chunk in graph.stream(input, stream_mode=\"values\"):\n    print(chunk)\n\n# Multiple modes\nfor mode, chunk in graph.stream(input, stream_mode=[\"updates\", \"messages\"]):\n    if mode == \"messages\":\n        print(\"Token:\", chunk)\n\n# Custom streaming from within nodes\nfrom langgraph.config import get_stream_writer\n\ndef my_node(state):\n    writer = get_stream_writer()\n    writer({\"progress\": 0.5})  # Custom event\n    return {\"result\": \"done\"}\n```\n\n## Subgraphs\n\n```python\n# Define subgraph\nsub_builder = StateGraph(SubState)\nsub_builder.add_node(\"step\", step_fn)\nsub_builder.add_edge(START, \"step\")\nsubgraph = sub_builder.compile()\n\n# Use as node in parent\nparent_builder = StateGraph(ParentState)\nparent_builder.add_node(\"subprocess\", subgraph)\nparent_builder.add_edge(START, \"subprocess\")\n\n# Subgraph checkpointing\nsubgraph = sub_builder.compile(\n    checkpointer=None,   # Inherit from parent (default)\n    # checkpointer=True,   # Use persistent checkpointing\n    # checkpointer=False,  # Disable checkpointing\n)\n```\n\n## Retry and Caching\n\n```python\nfrom langgraph.types import RetryPolicy, CachePolicy\n\nretry = RetryPolicy(\n    initial_interval=0.5,\n    backoff_factor=2.0,\n    max_attempts=3,\n    retry_on=ValueError,  # Or callable: lambda e: isinstance(e, ValueError)\n)\n\ncache = CachePolicy(ttl=3600)  # Cache for 1 hour\n\nbuilder.add_node(\"risky\", risky_fn, retry_policy=retry, cache_policy=cache)\n```\n\n## Prebuilt Components\n\n### create_react_agent (moved to langchain.agents in v1.0)\n\n```python\nfrom langgraph.prebuilt import create_react_agent, ToolNode\n\n# Simple agent\ngraph = create_react_agent(\n    model=\"anthropic:claude-3-5-sonnet\",\n    tools=[my_tool],\n    prompt=\"You are a helpful assistant\",\n    checkpointer=InMemorySaver(),\n)\n\n# Custom tool node\ntool_node = ToolNode([tool1, tool2])\nbuilder.add_node(\"tools\", tool_node)\n```\n\n## Common Patterns\n\n### Agent Loop\n\n```python\ndef should_continue(state) -> Literal[\"tools\", \"__end__\"]:\n    if state[\"messages\"][-1].tool_calls:\n        return \"tools\"\n    return END\n\nbuilder.add_node(\"agent\", call_model)\nbuilder.add_node(\"tools\", ToolNode(tools))\nbuilder.add_edge(START, \"agent\")\nbuilder.add_conditional_edges(\"agent\", should_continue)\nbuilder.add_edge(\"tools\", \"agent\")\n```\n\n### Parallel Execution\n\n```python\n# Multiple nodes execute in parallel when they share the same trigger\nbuilder.add_edge(START, \"node_a\")\nbuilder.add_edge(START, \"node_b\")  # Runs parallel with node_a\nbuilder.add_edge([\"node_a\", \"node_b\"], \"join\")  # Wait for both\n```\n\nSee [PATTERNS.md](PATTERNS.md) for advanced patterns including multi-agent systems, hierarchical graphs, and complex workflows.\n",
        "skills/llm-artifacts-detection/SKILL.md": "---\nname: llm-artifacts-detection\ndescription: Detects common LLM coding agent artifacts in codebases. Identifies test quality issues, dead code, over-abstraction, and verbose LLM style patterns. Use when cleaning up AI-generated code or reviewing for agent-introduced cruft.\n---\n\n# LLM Artifacts Detection\n\nDetect and flag common patterns introduced by LLM coding agents that reduce code quality.\n\n## Detection Categories\n\n| Category | Reference | Key Issues |\n|----------|-----------|------------|\n| Tests | [references/tests-criteria.md](references/tests-criteria.md) | DRY violations, library testing, mock boundaries |\n| Dead Code | [references/dead-code-criteria.md](references/dead-code-criteria.md) | Unused code, TODO/FIXME, backwards compat cruft |\n| Abstraction | [references/abstraction-criteria.md](references/abstraction-criteria.md) | Over-abstraction, copy-paste drift, over-configuration |\n| Style | [references/style-criteria.md](references/style-criteria.md) | Obvious comments, defensive overkill, unnecessary types |\n\n## Agent Prompts\n\nUse these prompts to spawn focused detection agents:\n\n### Tests Agent\n\n```\nAnalyze the test files for LLM-introduced test quality issues:\n\n1. **DRY Violations**: Look for setup/teardown code repeated across multiple test functions instead of using fixtures or shared helpers. Flag patterns like:\n   - Identical object creation in multiple tests\n   - Repeated mock configurations\n   - Copy-pasted database setup\n\n2. **Library Testing**: Identify tests that validate standard library or framework behavior rather than application code. Signs:\n   - No imports from the application codebase\n   - Testing built-in functions or third-party library methods\n   - Assertions about stdlib behavior\n\n3. **Mock Boundaries**: Flag mocking that's too deep or too shallow:\n   - Too deep: Mocking internal implementation details, private methods\n   - Too shallow: Mocking at the wrong layer, missing integration points\n   - Wrong level: Unit test mocks in integration tests or vice versa\n\nFor each issue found, report: [FILE:LINE] ISSUE_TITLE\n```\n\n### Dead Code Agent\n\n```\nScan the codebase for dead code and cleanup opportunities:\n\n1. **Unused Code**: Find functions, classes, and variables with no references:\n   - Functions never called\n   - Classes never instantiated\n   - Module-level variables never read\n   - Unreachable code after returns\n\n2. **TODO/FIXME Comments**: Flag all TODO, FIXME, HACK, XXX comments that indicate incomplete work\n\n3. **Backwards Compat Cruft**: Look for patterns suggesting removed features:\n   - Variables renamed with _unused, _old, _deprecated suffixes\n   - Re-exports only for backwards compatibility\n   - Comments like \"# removed\", \"# legacy\", \"# deprecated\"\n   - Empty functions/classes kept \"for compatibility\"\n\n4. **Orphaned Tests**: Tests for code that no longer exists:\n   - Test files with no corresponding source\n   - Test functions testing deleted features\n\nFor each issue found, report: [FILE:LINE] ISSUE_TITLE\n```\n\n### Abstraction Agent\n\n```\nReview the codebase for over-engineering introduced by LLM agents:\n\n1. **Over-Abstraction**: Identify unnecessary abstraction layers:\n   - Wrapper classes that just delegate to one method\n   - Interfaces/protocols with only one implementation\n   - Abstract base classes with single concrete class\n   - Factory functions that always return the same type\n\n2. **Copy-Paste Drift**: Find 3+ similar code blocks that should be parameterized:\n   - Nearly identical functions with minor variations\n   - Repeated patterns that could be a single function with parameters\n   - Similar class methods across multiple classes\n\n3. **Over-Configuration**: Flag configuration for non-configurable things:\n   - Feature flags that are never toggled\n   - Environment variables always set to one value\n   - Config options with no production variation\n   - Overly generic code for single use case\n\nFor each issue found, report: [FILE:LINE] ISSUE_TITLE\n```\n\n### Style Agent\n\n```\nCheck for verbose LLM-style patterns that reduce code clarity:\n\n1. **Obvious Comments**: Comments that restate what the code clearly does:\n   - \"# increment counter\" above counter += 1\n   - \"# return the result\" above return result\n   - Docstrings that repeat the function name\n\n2. **Over-Documentation**: Excessive documentation on trivial code:\n   - Full docstrings on simple getters/setters\n   - Parameter descriptions for obvious args\n   - Return value docs for self-evident returns\n\n3. **Defensive Overkill**: Unnecessary defensive programming:\n   - try/except around code that cannot fail\n   - Null checks on values that can't be null\n   - Type checks after type hints guarantee the type\n   - Validation of already-validated inputs\n\n4. **Unnecessary Type Hints**: Type hints that add no value:\n   - Type hints on obvious literal assignments\n   - Redundant hints on variables immediately clear from context\n   - Over-annotated internal/local variables\n\nFor each issue found, report: [FILE:LINE] ISSUE_TITLE\n```\n\n## Usage\n\n1. Load this skill when reviewing AI-generated code\n2. Spawn agents for specific detection categories as needed\n3. Use reference files for detailed criteria and examples\n4. Report issues in format: `[FILE:LINE] ISSUE_TITLE`\n\n## When to Apply\n\n- Cleaning up code written by AI coding agents\n- Post-generation code review\n- Reducing code bloat from iterative AI generation\n- Identifying patterns that reduce maintainability\n",
        "skills/llm-artifacts-detection/references/abstraction-criteria.md": "# Abstraction Criteria\n\nDetailed detection criteria for over-engineering patterns commonly introduced by LLM coding agents.\n\n## 1. Over-Abstraction\n\n### What to Look For\n\nUnnecessary abstraction layers that add complexity without providing value.\n\n### Detection Patterns\n\n**Wrapper Classes That Just Delegate**:\n```python\n# BAD - Wrapper adds nothing\nclass DatabaseWrapper:\n    def __init__(self, db):\n        self.db = db\n\n    def query(self, sql):\n        return self.db.query(sql)  # Just delegates!\n\n    def execute(self, sql):\n        return self.db.execute(sql)  # Just delegates!\n\n# Usage\nwrapper = DatabaseWrapper(actual_db)\nwrapper.query(sql)  # Why not just use actual_db directly?\n```\n\n**Interfaces With Single Implementation**:\n```python\n# BAD - Abstract class with only one implementation\nfrom abc import ABC, abstractmethod\n\nclass DataProcessor(ABC):\n    @abstractmethod\n    def process(self, data): ...\n\nclass ConcreteDataProcessor(DataProcessor):  # Only implementation!\n    def process(self, data):\n        return data.transform()\n\n# No other implementations exist - why the abstraction?\n```\n\n**Protocol With One Implementer**:\n```python\n# BAD - Protocol nobody else implements\nfrom typing import Protocol\n\nclass Fetcher(Protocol):\n    def fetch(self, url: str) -> bytes: ...\n\nclass HttpFetcher:  # Only class implementing Fetcher\n    def fetch(self, url: str) -> bytes:\n        return requests.get(url).content\n\n# The protocol adds no value if there's only one implementation\n```\n\n**Factory That Always Returns Same Type**:\n```python\n# BAD - Factory with no variation\ndef create_processor(config):\n    # Always returns the same type!\n    return DataProcessor(config)\n\n# Could just be:\nprocessor = DataProcessor(config)\n```\n\n**Unnecessary Indirection**:\n```python\n# BAD - Extra layers for no reason\nclass ServiceLocator:\n    def get_user_service(self):\n        return UserService()\n\nclass UserService:\n    def get_user(self, id):\n        return UserRepository().find(id)\n\nclass UserRepository:\n    def find(self, id):\n        return db.query(User).get(id)\n\n# 3 layers when 1 would do\n```\n\n### Signs of Over-Abstraction\n\n- Class/function just calls through to another\n- Abstract class with exactly one concrete implementation\n- Factory that always returns the same type\n- Interface defined \"for future extensibility\" (YAGNI violation)\n- Multiple layers that all have the same method signatures\n\n---\n\n## 2. Copy-Paste Drift\n\n### What to Look For\n\nThree or more similar code blocks that should be parameterized into a single function.\n\n### Detection Patterns\n\n**Nearly Identical Functions**:\n```python\n# BAD - Three similar functions\ndef process_users(users):\n    results = []\n    for user in users:\n        validated = validate(user)\n        transformed = transform(validated)\n        results.append(transformed)\n    return results\n\ndef process_orders(orders):\n    results = []\n    for order in orders:  # Same pattern!\n        validated = validate(order)\n        transformed = transform(validated)\n        results.append(transformed)\n    return results\n\ndef process_products(products):\n    results = []\n    for product in products:  # Same pattern!\n        validated = validate(product)\n        transformed = transform(validated)\n        results.append(transformed)\n    return results\n\n# GOOD - Parameterized\ndef process_items(items):\n    return [transform(validate(item)) for item in items]\n```\n\n**Repeated Patterns in Methods**:\n```python\n# BAD - Same error handling in multiple methods\nclass ApiClient:\n    def get_users(self):\n        try:\n            response = self.session.get(\"/users\")\n            response.raise_for_status()\n            return response.json()\n        except RequestException as e:\n            logger.error(f\"Failed to get users: {e}\")\n            raise ApiError(f\"Failed to get users: {e}\")\n\n    def get_orders(self):\n        try:\n            response = self.session.get(\"/orders\")  # Same pattern!\n            response.raise_for_status()\n            return response.json()\n        except RequestException as e:\n            logger.error(f\"Failed to get orders: {e}\")\n            raise ApiError(f\"Failed to get orders: {e}\")\n\n# GOOD - Extract common pattern\ndef _request(self, endpoint):\n    try:\n        response = self.session.get(endpoint)\n        response.raise_for_status()\n        return response.json()\n    except RequestException as e:\n        logger.error(f\"Failed to get {endpoint}: {e}\")\n        raise ApiError(f\"Failed to get {endpoint}: {e}\")\n\ndef get_users(self):\n    return self._request(\"/users\")\n```\n\n**Similar Class Structures**:\n```python\n# BAD - Multiple classes with same structure\nclass UserValidator:\n    def validate(self, user):\n        errors = []\n        if not user.name:\n            errors.append(\"name required\")\n        if not user.email:\n            errors.append(\"email required\")\n        return errors\n\nclass OrderValidator:\n    def validate(self, order):\n        errors = []\n        if not order.id:\n            errors.append(\"id required\")\n        if not order.total:\n            errors.append(\"total required\")\n        return errors\n\n# GOOD - Generic validator\nclass RequiredFieldValidator:\n    def __init__(self, required_fields):\n        self.required_fields = required_fields\n\n    def validate(self, obj):\n        return [f\"{f} required\" for f in self.required_fields if not getattr(obj, f)]\n```\n\n### How to Identify\n\n1. Search for similar function names (get_X, process_X, validate_X)\n2. Look for identical control flow with different variables\n3. Check for repeated try/except patterns\n4. Find similar class methods across different classes\n\n---\n\n## 3. Over-Configuration\n\n### What to Look For\n\nConfiguration and feature flags for things that don't actually vary.\n\n### Detection Patterns\n\n**Feature Flags Never Toggled**:\n```python\n# BAD - Flag always True\nENABLE_NEW_PARSER = True  # Never set to False anywhere\n\ndef parse(data):\n    if ENABLE_NEW_PARSER:  # Always true!\n        return new_parse(data)\n    return old_parse(data)  # Dead code!\n```\n\n**Environment Variables With One Value**:\n```python\n# BAD - Always the same value\nDATABASE_POOL_SIZE = int(os.getenv(\"DB_POOL_SIZE\", \"10\"))\n# But DB_POOL_SIZE is never set in any environment!\n\n# BAD - Config that doesn't vary\nconfig = {\n    \"retry_count\": os.getenv(\"RETRY_COUNT\", \"3\"),\n    \"timeout\": os.getenv(\"TIMEOUT\", \"30\"),\n}\n# All environments use the defaults\n```\n\n**Overly Generic Code for Single Use**:\n```python\n# BAD - Generic but only used once\nclass DataProcessor:\n    def __init__(self,\n                 input_format=\"json\",\n                 output_format=\"json\",\n                 encoding=\"utf-8\",\n                 validate=True,\n                 transform=True):\n        # Many options...\n        pass\n\n# Only ever called as:\nprocessor = DataProcessor()  # All defaults, always!\n```\n\n**Unused Configuration Options**:\n```python\n# config.py\nclass Settings:\n    database_url: str\n    cache_ttl: int = 3600\n    max_retries: int = 3\n    enable_metrics: bool = True  # Never read!\n    legacy_mode: bool = False  # Never read!\n    debug_sql: bool = False  # Never read!\n```\n\n### Signs of Over-Configuration\n\n- Config values that never change across environments\n- Feature flags with only one state in production\n- Options with defaults that are always used\n- Configuration loaded but never accessed\n- Environment variables with no variation\n\n---\n\n## Review Questions\n\n1. Does this abstraction have multiple implementations?\n2. Are there 3+ similar code blocks that could be parameterized?\n3. Is this configuration actually configured differently anywhere?\n4. Would removing this layer break anything meaningful?\n5. Is this factory/wrapper adding value or just indirection?\n",
        "skills/llm-artifacts-detection/references/dead-code-criteria.md": "# Dead Code Criteria\n\nDetailed detection criteria for dead code and cleanup opportunities commonly left by LLM coding agents.\n\n## 1. Unused Code\n\n### What to Look For\n\nFunctions, classes, and variables with no references anywhere in the codebase.\n\n### Detection Patterns\n\n**Unused Functions**:\n```python\n# Function defined but never called\ndef helper_process_data(data):  # No callers!\n    \"\"\"Process data helper.\"\"\"\n    return data.strip().lower()\n\ndef unused_validation(value):  # No callers!\n    \"\"\"Validate value format.\"\"\"\n    return bool(re.match(r\"^\\d+$\", value))\n```\n\n**Unused Classes**:\n```python\n# Class defined but never instantiated\nclass DataTransformer:  # Never used!\n    \"\"\"Transform data between formats.\"\"\"\n    def transform(self, data):\n        return data\n\nclass LegacyProcessor:  # Never used!\n    \"\"\"Old processor implementation.\"\"\"\n    pass\n```\n\n**Unused Variables**:\n```python\n# Module-level variables never read\nDEFAULT_TIMEOUT = 30  # Never referenced\nCACHE_SIZE = 1000  # Never referenced\n\n# Assigned but never used\ndef process():\n    result = compute()  # 'result' never used\n    intermediate = transform()  # Never used\n    return other_compute()\n```\n\n**Unreachable Code**:\n```python\ndef calculate(x):\n    if x > 0:\n        return x * 2\n    return x * -1\n\n    # Unreachable!\n    logger.info(\"Calculation complete\")\n    cleanup()\n```\n\n### How to Find\n\n1. Use IDE \"Find Usages\" on suspected dead code\n2. Run `vulture` or similar dead code detector\n3. Search for function/class name across codebase\n4. Check import statements for unused imports\n\n---\n\n## 2. TODO/FIXME Comments\n\n### What to Look For\n\nComments indicating incomplete work, technical debt, or known issues.\n\n### Detection Patterns\n\n```python\n# TODO: implement caching  <-- Incomplete feature\ndef get_user(id):\n    return db.query(User).get(id)\n\n# FIXME: this breaks with unicode  <-- Known bug\ndef parse_name(name):\n    return name.split()[0]\n\n# HACK: temporary workaround for issue #123  <-- Tech debt\nresult = data.replace(\"\\x00\", \"\")\n\n# XXX: this needs to be refactored  <-- Acknowledged mess\ndef complex_function():\n    # 200 lines of spaghetti\n    pass\n\n# NOTE: remove after migration  <-- Scheduled for deletion\nold_format = convert_legacy(data)\n```\n\n### Categories\n\n| Marker | Meaning | Action |\n|--------|---------|--------|\n| TODO | Planned work | Complete or create ticket |\n| FIXME | Known bug | Fix or document as known issue |\n| HACK | Workaround | Refactor or document why needed |\n| XXX | Needs attention | Review and address |\n| NOTE | Information | Review if still relevant |\n\n---\n\n## 3. Backwards Compatibility Cruft\n\n### What to Look For\n\nPatterns suggesting removed features kept around \"just in case\" or for backwards compatibility that's no longer needed.\n\n### Detection Patterns\n\n**Unused Renames**:\n```python\n# Variables renamed to indicate unused\n_unused_config = old_config  # Why keep it?\n_old_handler = legacy_handler  # Delete it!\n_deprecated_cache = cache_v1  # Remove!\n\n# Functions with \"old\" or \"legacy\" suffixes\ndef process_old(data):  # Is this still needed?\n    pass\n\ndef validate_legacy(value):  # Who calls this?\n    pass\n```\n\n**Re-exports for Compatibility**:\n```python\n# In __init__.py - re-exporting moved code\nfrom .new_location import Thing  # noqa: F401\nfrom .new_module import OldName as OldName  # Backwards compat\n\n# Explicit compatibility exports\n__all__ = [\n    \"NewThing\",\n    \"OldThing\",  # Deprecated, remove in v3.0\n]\n```\n\n**Removal Comments**:\n```python\n# # removed - no longer used\n# old_function = None\n\n# # legacy - kept for backwards compatibility\n# LegacyClass = NewClass\n\n# # deprecated - use new_method instead\ndef old_method():\n    return new_method()\n```\n\n**Empty Compatibility Stubs**:\n```python\nclass LegacyAdapter:\n    \"\"\"Kept for backwards compatibility.\"\"\"\n    pass  # Empty!\n\ndef deprecated_function(*args, **kwargs):\n    \"\"\"Deprecated. Use new_function instead.\"\"\"\n    pass  # Does nothing!\n```\n\n### How to Evaluate\n\n1. Check if the \"legacy\" code has any callers\n2. Search for imports of deprecated names\n3. Check if deprecation warnings are even triggered\n4. Review git history - how long has it been \"deprecated\"?\n\n---\n\n## 4. Orphaned Tests\n\n### What to Look For\n\nTests that reference code that no longer exists.\n\n### Detection Patterns\n\n**Test Files Without Source**:\n```\ntests/\n  test_old_feature.py  # But old_feature.py doesn't exist!\n  test_removed_module.py  # removed_module/ was deleted\n```\n\n**Tests Importing Deleted Code**:\n```python\n# This import fails or imports from wrong place\nfrom myapp.deleted_module import RemovedClass  # Module deleted!\n\ndef test_removed_feature():\n    obj = RemovedClass()  # Class doesn't exist!\n    assert obj.method() == expected\n```\n\n**Tests for Renamed/Moved Code**:\n```python\n# Old test file testing moved functionality\n# test_utils.py\ndef test_helper_function():\n    from myapp.utils import helper  # Moved to myapp.helpers!\n    assert helper(1) == 2\n```\n\n### How to Find\n\n1. Run the test suite - import errors reveal orphans\n2. Check test file names against source file names\n3. Review test imports for deleted modules\n4. Look for skipped tests with outdated skip reasons\n\n---\n\n## Review Questions\n\n1. Are there functions with zero callers?\n2. How old are the TODO/FIXME comments?\n3. Is \"deprecated\" code actually deprecated (with timeline)?\n4. Do all test files have corresponding source files?\n5. Are there variables assigned but never read?\n",
        "skills/llm-artifacts-detection/references/style-criteria.md": "# Style Criteria\n\nDetailed detection criteria for verbose LLM-style patterns that reduce code clarity.\n\n## 1. Obvious Comments\n\n### What to Look For\n\nComments that restate what the code clearly expresses.\n\n### Detection Patterns\n\n**Restating the Operation**:\n```python\n# BAD - Comment restates code\ncounter += 1  # increment counter\nitems.append(item)  # add item to list\nreturn result  # return the result\nuser = None  # set user to None\n\n# GOOD - No comment needed, code is clear\ncounter += 1\nitems.append(item)\nreturn result\nuser = None\n```\n\n**Describing Simple Control Flow**:\n```python\n# BAD - Obvious conditionals\n# check if user exists\nif user:\n    # process the user\n    process(user)\nelse:\n    # handle missing user\n    handle_error()\n\n# GOOD - Code is self-documenting\nif user:\n    process(user)\nelse:\n    handle_error()\n```\n\n**Docstrings That Repeat the Name**:\n```python\n# BAD - Docstring restates function name\ndef get_user_by_id(id: int) -> User:\n    \"\"\"Get a user by their ID.\"\"\"\n    return db.query(User).get(id)\n\ndef validate_email(email: str) -> bool:\n    \"\"\"Validates the email.\"\"\"\n    return bool(re.match(EMAIL_REGEX, email))\n\n# GOOD - Add value or omit\ndef get_user_by_id(id: int) -> User:\n    \"\"\"Raises UserNotFound if ID doesn't exist.\"\"\"\n    return db.query(User).get(id)\n\n# Or just no docstring for trivial functions\ndef validate_email(email: str) -> bool:\n    return bool(re.match(EMAIL_REGEX, email))\n```\n\n**Loop Comments**:\n```python\n# BAD\n# iterate over users\nfor user in users:\n    # process each user\n    process(user)\n\n# GOOD\nfor user in users:\n    process(user)\n```\n\n---\n\n## 2. Over-Documentation\n\n### What to Look For\n\nExcessive documentation on code that doesn't need it.\n\n### Detection Patterns\n\n**Full Docstrings on Trivial Functions**:\n```python\n# BAD - Overkill for simple getter\ndef get_name(self) -> str:\n    \"\"\"Get the name of this object.\n\n    Returns:\n        str: The name of the object.\n    \"\"\"\n    return self._name\n\n# GOOD - Simple is better\ndef get_name(self) -> str:\n    return self._name\n```\n\n**Parameter Descriptions for Obvious Args**:\n```python\n# BAD - Parameters are self-evident\ndef send_email(\n    to: str,\n    subject: str,\n    body: str,\n) -> None:\n    \"\"\"Send an email.\n\n    Args:\n        to: The email address to send to.\n        subject: The subject of the email.\n        body: The body of the email.\n    \"\"\"\n    ...\n\n# GOOD - Only document non-obvious aspects\ndef send_email(\n    to: str,\n    subject: str,\n    body: str,\n    priority: int = 3,\n) -> None:\n    \"\"\"Send an email.\n\n    Args:\n        priority: 1-5, where 1 is highest. Affects delivery order.\n    \"\"\"\n    ...\n```\n\n**Return Value Docs for Obvious Returns**:\n```python\n# BAD\ndef is_valid(self) -> bool:\n    \"\"\"Check if valid.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return self._valid\n\n# GOOD - Return is obvious from type hint\ndef is_valid(self) -> bool:\n    return self._valid\n```\n\n---\n\n## 3. Defensive Overkill\n\n### What to Look For\n\nUnnecessary defensive programming that can't actually prevent failures.\n\n### Detection Patterns\n\n**Try/Except Around Non-Failing Code**:\n```python\n# BAD - These operations can't fail\ntry:\n    x = 1 + 1\nexcept Exception:\n    x = 0\n\ntry:\n    result = {\"key\": \"value\"}\nexcept Exception:\n    result = {}\n\n# BAD - Already validated input\ndef process(data: ValidatedData):\n    try:\n        # ValidatedData guarantees these exist\n        name = data.name\n        email = data.email\n    except AttributeError:\n        raise ValueError(\"Invalid data\")  # Can't happen!\n```\n\n**Null Checks on Non-Nullable Values**:\n```python\n# BAD - Type hint says it's not None\ndef process(user: User) -> str:\n    if user is None:  # Can't be None per type hint!\n        raise ValueError(\"User required\")\n    return user.name\n\n# BAD - Just assigned, can't be None\nconfig = load_config()\nif config is None:  # load_config() never returns None\n    config = {}\n```\n\n**Type Checks After Type Hints**:\n```python\n# BAD - Type is already guaranteed\ndef process(items: list[str]) -> None:\n    if not isinstance(items, list):  # Already typed!\n        raise TypeError(\"Expected list\")\n    for item in items:\n        if not isinstance(item, str):  # Already typed!\n            raise TypeError(\"Expected str\")\n        print(item)\n```\n\n**Re-Validating Already-Validated Input**:\n```python\n# BAD - Pydantic already validated\nclass Request(BaseModel):\n    email: EmailStr\n    age: int = Field(ge=0, le=150)\n\ndef handle(request: Request):\n    # Pydantic already validated these!\n    if not is_valid_email(request.email):\n        raise ValueError(\"Invalid email\")\n    if request.age < 0 or request.age > 150:\n        raise ValueError(\"Invalid age\")\n```\n\n---\n\n## 4. Unnecessary Type Hints\n\n### What to Look For\n\nType hints that add no information value.\n\n### Detection Patterns\n\n**Type Hints on Obvious Literals**:\n```python\n# BAD - Type is obvious from value\nname: str = \"Alice\"\ncount: int = 0\nenabled: bool = True\nitems: list = []\n\n# GOOD - Let inference work\nname = \"Alice\"\ncount = 0\nenabled = True\nitems: list[str] = []  # Only hint if element type matters\n```\n\n**Redundant Hints on Clear Context**:\n```python\n# BAD - Context makes type obvious\nuser: User = User(name=\"Alice\")\nresult: dict = json.loads(data)  # json.loads returns dict\nitems: list = list(range(10))\n\n# GOOD\nuser = User(name=\"Alice\")\nresult = json.loads(data)\nitems = list(range(10))\n```\n\n**Over-Annotated Internal Variables**:\n```python\n# BAD - Too many internal annotations\ndef process(data: str) -> dict:\n    lines: list[str] = data.split(\"\\n\")\n    result: dict[str, int] = {}\n    count: int = 0\n    for line in lines:\n        key: str = line.strip()\n        result[key] = count\n        count += 1\n    return result\n\n# GOOD - Annotate function signature, not internals\ndef process(data: str) -> dict[str, int]:\n    lines = data.split(\"\\n\")\n    result = {}\n    for count, line in enumerate(lines):\n        result[line.strip()] = count\n    return result\n```\n\n### When Type Hints Add Value\n\n- Function parameters and return types\n- Class attributes (especially in dataclasses)\n- Variables where type isn't obvious from assignment\n- Collection types where element type matters\n- Optional/Union types\n\n---\n\n## Review Questions\n\n1. Does this comment tell me something the code doesn't?\n2. Would a new developer need this docstring?\n3. Can this exception actually be raised?\n4. Is this null check protecting against a real possibility?\n5. Would the code be equally clear without this type hint?\n",
        "skills/llm-artifacts-detection/references/tests-criteria.md": "# Test Quality Criteria\n\nDetailed detection criteria for test quality issues commonly introduced by LLM coding agents.\n\n## 1. DRY Violations\n\n### What to Look For\n\nRepeated setup/teardown code across test functions instead of using fixtures, conftest, or shared helpers.\n\n### Detection Patterns\n\n**Repeated Object Creation**:\n```python\n# BAD - Same setup in multiple tests\ndef test_user_creation():\n    db = Database(host=\"localhost\", port=5432)\n    user = User(name=\"test\", email=\"test@example.com\")\n    # test logic\n\ndef test_user_update():\n    db = Database(host=\"localhost\", port=5432)  # Repeated!\n    user = User(name=\"test\", email=\"test@example.com\")  # Repeated!\n    # test logic\n\n# GOOD - Use fixtures\n@pytest.fixture\ndef db():\n    return Database(host=\"localhost\", port=5432)\n\n@pytest.fixture\ndef test_user():\n    return User(name=\"test\", email=\"test@example.com\")\n\ndef test_user_creation(db, test_user):\n    # test logic\n```\n\n**Repeated Mock Configuration**:\n```python\n# BAD - Mock setup copied across tests\ndef test_api_success():\n    mock_response = Mock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\"data\": \"test\"}\n    with patch(\"requests.get\", return_value=mock_response):\n        # test\n\ndef test_api_parsing():\n    mock_response = Mock()  # Repeated!\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\"data\": \"test\"}\n    with patch(\"requests.get\", return_value=mock_response):  # Repeated!\n        # test\n```\n\n**Copy-Pasted Database Setup**:\n```python\n# BAD - Database initialization in every test\ndef test_query_users():\n    engine = create_engine(\"sqlite:///:memory:\")\n    Base.metadata.create_all(engine)\n    Session = sessionmaker(bind=engine)\n    session = Session()\n    # test\n\ndef test_query_orders():\n    engine = create_engine(\"sqlite:///:memory:\")  # Repeated!\n    Base.metadata.create_all(engine)  # Repeated!\n    Session = sessionmaker(bind=engine)  # Repeated!\n    session = Session()\n    # test\n```\n\n### How to Fix\n\n1. Extract to `conftest.py` fixtures\n2. Use fixture scope appropriately (function, class, module, session)\n3. Create factory fixtures for parameterized data\n4. Use fixture composition for complex setups\n\n---\n\n## 2. Library Testing\n\n### What to Look For\n\nTests that validate standard library or framework behavior rather than application code.\n\n### Detection Patterns\n\n**No Application Imports**:\n```python\n# BAD - Testing Python stdlib, not our code\nimport json\n\ndef test_json_loads():\n    result = json.loads('{\"key\": \"value\"}')\n    assert result == {\"key\": \"value\"}\n\ndef test_json_dumps():\n    result = json.dumps({\"key\": \"value\"})\n    assert result == '{\"key\": \"value\"}'\n```\n\n**Testing Framework Behavior**:\n```python\n# BAD - Testing SQLAlchemy, not our models\nfrom sqlalchemy import Column, Integer, String\n\ndef test_column_types():\n    col = Column(Integer)\n    assert col.type.__class__.__name__ == \"Integer\"\n\n# BAD - Testing Pydantic validation\nfrom pydantic import BaseModel\n\ndef test_pydantic_validates():\n    class M(BaseModel):\n        x: int\n    assert M(x=1).x == 1\n```\n\n**Signs of Library Testing**:\n- Test file imports only stdlib/third-party, no `from myapp import`\n- Tests verify documented framework behavior\n- Assertions match framework documentation examples\n- No domain logic being tested\n\n### How to Fix\n\n1. Delete tests that only verify framework behavior\n2. Focus on testing YOUR code that uses the framework\n3. Test business logic, not library internals\n4. Trust well-tested libraries\n\n---\n\n## 3. Mock Boundaries\n\n### What to Look For\n\nMocking at the wrong level - either too deep (internal implementation) or too shallow (missing integration points).\n\n### Too Deep: Mocking Internals\n\n```python\n# BAD - Mocking private methods\ndef test_process():\n    service = DataService()\n    with patch.object(service, \"_internal_helper\"):  # Too deep!\n        with patch.object(service, \"_validate_internal\"):  # Too deep!\n            service.process(data)\n\n# BAD - Mocking implementation details\ndef test_calculate():\n    with patch(\"myapp.service._cache_lookup\"):  # Internal!\n        with patch(\"myapp.service._serialize\"):  # Internal!\n            result = calculate(input)\n```\n\n**Problems with Deep Mocking**:\n- Tests break when refactoring internals\n- Tests know too much about implementation\n- False confidence - internals change, tests still pass\n\n### Too Shallow: Missing Integration Points\n\n```python\n# BAD - Not mocking external API in unit test\ndef test_get_weather():\n    # Actually calls the real weather API!\n    result = weather_service.get_current(\"NYC\")\n    assert result.temp > 0\n\n# BAD - Not mocking database in unit test\ndef test_user_service():\n    # Actually hits the real database!\n    user = user_service.get_by_id(1)\n```\n\n**Problems with Shallow Mocking**:\n- Tests are slow (real network/DB calls)\n- Tests are flaky (external dependencies)\n- Can't test edge cases easily\n\n### Correct Mock Boundaries\n\n```python\n# GOOD - Mock at integration boundaries\ndef test_weather_service(mock_weather_api):\n    mock_weather_api.get.return_value = WeatherResponse(temp=72)\n    result = weather_service.get_current(\"NYC\")\n    assert result.temp == 72\n\n# GOOD - Mock external dependencies, not internals\ndef test_data_processor(mock_database, mock_external_api):\n    mock_database.query.return_value = [...]\n    mock_external_api.fetch.return_value = {...}\n    result = processor.process()\n    # Tests OUR logic with controlled inputs\n```\n\n### Guidelines\n\n| Test Type | What to Mock | What NOT to Mock |\n|-----------|--------------|------------------|\n| Unit | External APIs, DB, file system | Internal helpers, private methods |\n| Integration | External APIs only | DB, internal services |\n| E2E | Nothing (or external APIs) | Internal systems |\n\n### Review Questions\n\n1. Are private methods (`_method`) being mocked?\n2. Are tests making real external API calls?\n3. Do mock boundaries match architectural boundaries?\n4. Would refactoring internals break these tests?\n",
        "skills/llm-judge/SKILL.md": "---\nname: llm-judge\ndescription: LLM-as-judge methodology for comparing code implementations across repositories. Scores implementations on functionality, security, test quality, overengineering, and dead code using weighted rubrics. Used by /beagle:llm-judge command.\n---\n\n# LLM Judge Skill\n\nCompare code implementations across 2+ repositories using structured evaluation.\n\n## Overview\n\nThis skill implements a two-phase LLM-as-judge evaluation:\n\n1. **Phase 1: Fact Gathering** - Parallel agents explore each repo and extract structured facts\n2. **Phase 2: Judging** - Parallel judges score each dimension using consistent rubrics\n\n## Reference Files\n\n| File | Purpose |\n|------|---------|\n| [references/fact-schema.md](references/fact-schema.md) | JSON schema for Phase 1 facts |\n| [references/scoring-rubrics.md](references/scoring-rubrics.md) | Detailed rubrics for each dimension |\n| [references/repo-agent.md](references/repo-agent.md) | Instructions for Phase 1 agents |\n| [references/judge-agents.md](references/judge-agents.md) | Instructions for Phase 2 judges |\n\n## Scoring Dimensions\n\n| Dimension | Default Weight | Evaluates |\n|-----------|----------------|-----------|\n| Functionality | 30% | Spec compliance, test pass rate |\n| Security | 25% | Vulnerabilities, security patterns |\n| Test Quality | 20% | Coverage, DRY, mock boundaries |\n| Overengineering | 15% | Unnecessary complexity |\n| Dead Code | 10% | Unused code, TODOs |\n\n## Scoring Scale\n\n| Score | Meaning |\n|-------|---------|\n| 5 | Excellent - Exceeds expectations |\n| 4 | Good - Meets requirements, minor issues |\n| 3 | Average - Functional but notable gaps |\n| 2 | Below Average - Significant issues |\n| 1 | Poor - Fails basic requirements |\n\n## Phase 1: Spawning Repo Agents\n\nFor each repository, spawn a Task agent with:\n\n```\nYou are a Phase 1 Repo Agent for the LLM Judge evaluation.\n\n**Your Repo:** $REPO_LABEL at $REPO_PATH\n**Spec Document:**\n$SPEC_CONTENT\n\n**Instructions:** Read @beagle:llm-judge references/repo-agent.md\n\nGather facts and return a JSON object following the schema in references/fact-schema.md.\n\nLoad @beagle:llm-artifacts-detection for dead code and overengineering analysis.\n\nReturn ONLY valid JSON, no markdown or explanations.\n```\n\n## Phase 2: Spawning Judge Agents\n\nAfter all Phase 1 agents complete, spawn 5 judge agents (one per dimension):\n\n```\nYou are the $DIMENSION Judge for the LLM Judge evaluation.\n\n**Spec Document:**\n$SPEC_CONTENT\n\n**Facts from all repos:**\n$ALL_FACTS_JSON\n\n**Instructions:** Read @beagle:llm-judge references/judge-agents.md\n\nScore each repo on $DIMENSION using the rubric in references/scoring-rubrics.md.\n\nReturn ONLY valid JSON following the judge output schema.\n```\n\n## Aggregation\n\nAfter Phase 2 completes:\n\n1. Collect scores from all 5 judges\n2. For each repo, compute weighted total:\n   ```\n   weighted_total = sum(score[dim] * weight[dim]) / 100\n   ```\n3. Rank repos by weighted total (descending)\n4. Generate verdict explaining the ranking\n\n## Output\n\nWrite results to `.beagle/llm-judge-report.json` and display markdown summary.\n\n## Dependencies\n\n- `@beagle:llm-artifacts-detection` - Reused by repo agents for dead code/overengineering\n",
        "skills/llm-judge/references/fact-schema.md": "# Fact Schema\n\nJSON schema for structured facts gathered by Phase 1 Repo Agents.\n\n## Full Schema\n\n```json\n{\n  \"repo_label\": \"string - Display name for this repo\",\n  \"repo_path\": \"string - Absolute path to repo\",\n  \"git_info\": {\n    \"branch\": \"string - Current branch name\",\n    \"base\": \"string - Base branch (usually main)\",\n    \"files_changed\": \"number - Count of changed files\",\n    \"additions\": \"number - Lines added\",\n    \"deletions\": \"number - Lines deleted\",\n    \"diff_summary\": \"string - Brief description of changes\"\n  },\n  \"functionality\": {\n    \"spec_requirements\": [\"array of requirement strings extracted from spec\"],\n    \"implemented\": [\"array of requirements found implemented\"],\n    \"missing\": [\"array of requirements not found\"],\n    \"partially_implemented\": [\"array of requirements with incomplete implementation\"],\n    \"test_results\": {\n      \"ran\": \"boolean - Whether tests were executed\",\n      \"framework\": \"string - pytest, jest, go test, etc.\",\n      \"passed\": \"number\",\n      \"failed\": \"number\",\n      \"skipped\": \"number\",\n      \"error_summary\": \"string - Brief description of failures if any\"\n    }\n  },\n  \"security\": {\n    \"findings\": [\n      {\n        \"file\": \"string - File path\",\n        \"line\": \"number - Line number\",\n        \"issue\": \"string - Description of security issue\",\n        \"severity\": \"high | medium | low\",\n        \"category\": \"string - OWASP category if applicable\"\n      }\n    ],\n    \"patterns_observed\": [\"array of positive security patterns found\"]\n  },\n  \"tests\": {\n    \"test_count\": \"number - Total test count\",\n    \"coverage_estimate\": \"none | low | moderate | high\",\n    \"dry_violations\": [\n      {\n        \"file\": \"string\",\n        \"line\": \"number\",\n        \"description\": \"string\"\n      }\n    ],\n    \"mocking_approach\": \"string - Description of mocking strategy\",\n    \"test_quality_notes\": \"string - General observations\"\n  },\n  \"overengineering\": {\n    \"abstractions\": [\n      {\n        \"file\": \"string\",\n        \"line\": \"number\",\n        \"issue\": \"string - Description of over-abstraction\"\n      }\n    ],\n    \"defensive_code\": [\n      {\n        \"file\": \"string\",\n        \"line\": \"number\",\n        \"issue\": \"string\"\n      }\n    ],\n    \"config_complexity\": \"low | medium | high\"\n  },\n  \"dead_code\": {\n    \"unused_imports\": [\"array of file:line references\"],\n    \"unused_functions\": [\"array of file:line references\"],\n    \"unused_variables\": [\"array of file:line references\"],\n    \"todo_comments\": \"number - Count of TODO/FIXME\",\n    \"commented_code_blocks\": \"number - Count of commented code\"\n  }\n}\n```\n\n## Example\n\n```json\n{\n  \"repo_label\": \"Claude\",\n  \"repo_path\": \"/path/to/repo-a\",\n  \"git_info\": {\n    \"branch\": \"main\",\n    \"base\": \"main\",\n    \"files_changed\": 42,\n    \"additions\": 1250,\n    \"deletions\": 380,\n    \"diff_summary\": \"Adds auth flow and data export features\"\n  },\n  \"functionality\": {\n    \"spec_requirements\": [\"auth flow\", \"data export\", \"rate limiting\"],\n    \"implemented\": [\"auth flow\", \"data export\"],\n    \"missing\": [\"rate limiting\"],\n    \"partially_implemented\": [],\n    \"test_results\": {\n      \"ran\": true,\n      \"framework\": \"pytest\",\n      \"passed\": 45,\n      \"failed\": 2,\n      \"skipped\": 1,\n      \"error_summary\": \"2 tests fail on edge case validation\"\n    }\n  },\n  \"security\": {\n    \"findings\": [\n      {\n        \"file\": \"src/api.py\",\n        \"line\": 42,\n        \"issue\": \"SQL string concatenation instead of parameterized query\",\n        \"severity\": \"high\",\n        \"category\": \"Injection\"\n      }\n    ],\n    \"patterns_observed\": [\"input validation present\", \"no secrets in code\", \"HTTPS enforced\"]\n  },\n  \"tests\": {\n    \"test_count\": 48,\n    \"coverage_estimate\": \"moderate\",\n    \"dry_violations\": [\n      {\n        \"file\": \"tests/test_api.py\",\n        \"line\": 15,\n        \"description\": \"Setup code repeated in 5 test functions\"\n      }\n    ],\n    \"mocking_approach\": \"Mocks at adapter boundary, uses pytest fixtures\",\n    \"test_quality_notes\": \"Good isolation, some DRY issues\"\n  },\n  \"overengineering\": {\n    \"abstractions\": [\n      {\n        \"file\": \"src/factory.py\",\n        \"line\": 1,\n        \"issue\": \"Factory pattern for single implementation\"\n      }\n    ],\n    \"defensive_code\": [],\n    \"config_complexity\": \"low\"\n  },\n  \"dead_code\": {\n    \"unused_imports\": [\"src/utils.py:3\"],\n    \"unused_functions\": [],\n    \"unused_variables\": [],\n    \"todo_comments\": 2,\n    \"commented_code_blocks\": 1\n  }\n}\n```\n",
        "skills/llm-judge/references/judge-agents.md": "# Judge Agent Instructions\n\nInstructions for Phase 2 agents that score implementations on a single dimension.\n\n## Role\n\nYou are a scoring judge. You receive facts gathered from ALL repositories and score each one on YOUR specific dimension using the rubrics in [scoring-rubrics.md](scoring-rubrics.md).\n\n## Inputs You Receive\n\n1. **Spec Document**: The original requirements\n2. **Facts Array**: JSON facts from all repos (output of Phase 1)\n3. **Your Dimension**: One of: functionality, security, tests, overengineering, dead_code\n\n## Your Task\n\nProduce a JSON object with scores and justifications for each repo.\n\n## Output Schema\n\n```json\n{\n  \"dimension\": \"functionality\",\n  \"scores\": {\n    \"RepoLabel1\": {\n      \"score\": 4,\n      \"justification\": \"Clear explanation of why this score was assigned\",\n      \"evidence\": [\"Specific facts that support this score\"]\n    },\n    \"RepoLabel2\": {\n      \"score\": 5,\n      \"justification\": \"...\",\n      \"evidence\": [\"...\"]\n    }\n  },\n  \"ranking\": [\"RepoLabel2\", \"RepoLabel1\"],\n  \"notes\": \"Optional comparative notes\"\n}\n```\n\n## Scoring Process\n\n1. Read the rubric for your dimension from [scoring-rubrics.md](scoring-rubrics.md)\n2. For each repo's facts:\n   - Extract the relevant section (e.g., `facts.functionality` for functionality judge)\n   - Apply the rubric criteria\n   - Assign a 1-5 score\n   - Write a clear justification citing specific evidence\n3. Rank the repos by score (highest first)\n\n## Dimension-Specific Instructions\n\n### Functionality Judge\n\nFocus on `facts.functionality`:\n- Compare `spec_requirements` to `implemented` and `missing`\n- Weight test results heavily (`test_results.passed` vs `failed`)\n- Consider `partially_implemented` as half credit\n\n### Security Judge\n\nFocus on `facts.security`:\n- Count and weight `findings` by severity\n- High severity = major deduction\n- Positive `patterns_observed` can offset minor issues\n\n### Tests Judge\n\nFocus on `facts.tests`:\n- Evaluate `coverage_estimate`\n- Count `dry_violations` (more = worse)\n- Consider `mocking_approach` quality\n- Raw `test_count` relative to codebase size\n\n### Overengineering Judge\n\nFocus on `facts.overengineering`:\n- Count `abstractions` issues\n- Count `defensive_code` issues\n- Consider `config_complexity`\n- FEWER issues = HIGHER score (inverse)\n\n### Dead Code Judge\n\nFocus on `facts.dead_code`:\n- Sum all unused items\n- Weight `unused_functions` > `unused_imports`\n- Count `todo_comments` and `commented_code_blocks`\n- FEWER issues = HIGHER score (inverse)\n\n## Important Rules\n\n1. **Use the rubric** - Don't invent criteria\n2. **Be consistent** - Apply the same standards to all repos\n3. **Cite evidence** - Every score needs justification from facts\n4. **Be comparative** - Rankings should reflect relative quality\n5. **Valid JSON only** - Output must be parseable\n",
        "skills/llm-judge/references/repo-agent.md": "# Repo Agent Instructions\n\nInstructions for Phase 1 agents that gather facts from a single repository.\n\n## Role\n\nYou are a fact-gathering agent. Your job is to explore a repository and extract structured facts WITHOUT making judgments or assigning scores. Scoring happens in Phase 2 by separate judge agents.\n\n## Inputs You Receive\n\n1. **Spec Document**: The requirements/plan that was given to the LLM to implement\n2. **Repo Path**: Absolute path to the repository you're analyzing\n3. **Repo Label**: Display name for this repo (e.g., \"Claude\", \"GPT-4\")\n4. **Branch Info**: Which branch to compare (default: current vs main)\n\n## Your Task\n\nProduce a JSON object following the schema in [fact-schema.md](fact-schema.md).\n\n## Step-by-Step Process\n\n### 1. Gather Git Info\n\n```bash\n# Get branch name\ngit -C $REPO_PATH rev-parse --abbrev-ref HEAD\n\n# Get diff stats\ngit -C $REPO_PATH diff --stat main...HEAD\n\n# Count files changed\ngit -C $REPO_PATH diff --name-only main...HEAD | wc -l\n```\n\n### 2. Analyze Functionality\n\n1. Read the spec document carefully\n2. Extract discrete requirements as a list\n3. Explore the codebase to determine which requirements are implemented\n4. Run tests if available:\n\n```bash\n# Detect and run tests\ncd $REPO_PATH\n\n# Python\nif [ -f pytest.ini ] || [ -f pyproject.toml ] || [ -d tests ]; then\n  pytest --tb=short 2>&1\nfi\n\n# JavaScript/TypeScript\nif [ -f package.json ]; then\n  npm test 2>&1 || yarn test 2>&1\nfi\n\n# Go\nif [ -f go.mod ]; then\n  go test ./... 2>&1\nfi\n```\n\n### 3. Analyze Security\n\nLook for common vulnerabilities:\n- SQL injection (string concatenation in queries)\n- Command injection (unsanitized shell commands)\n- XSS (unsanitized user input in HTML)\n- Hardcoded secrets (API keys, passwords)\n- Missing input validation\n- Insecure deserialization\n\nAlso note positive patterns:\n- Input validation present\n- Parameterized queries\n- Authentication checks\n- Rate limiting\n\n### 4. Analyze Tests\n\n- Count test files and test functions\n- Look for DRY violations (repeated setup code)\n- Assess mocking strategy\n- Estimate coverage (file count ratio, critical paths tested)\n\n### 5. Analyze Overengineering\n\nUse patterns from `@beagle:llm-artifacts-detection`:\n- Unnecessary abstractions (interfaces with single impl)\n- Factory patterns for simple objects\n- Excessive defensive coding\n- Over-configuration\n\n### 6. Analyze Dead Code\n\n- Unused imports (grep for imports, check usage)\n- TODO/FIXME comments\n- Commented-out code blocks\n- Unused functions/variables\n\n## Output Format\n\nReturn ONLY the JSON object. No markdown, no explanations. The JSON must be valid and follow [fact-schema.md](fact-schema.md).\n\n## Important Rules\n\n1. **Do not score** - Only gather facts\n2. **Be thorough** - Check all changed files\n3. **Be specific** - Include file:line references\n4. **Be objective** - Report what you find, not opinions\n5. **Use the skill** - Load `@beagle:llm-artifacts-detection` for dead code/overengineering\n",
        "skills/llm-judge/references/scoring-rubrics.md": "# Scoring Rubrics\n\nDetailed rubrics for each of the 5 judging dimensions. Judges use these to assign consistent 1-5 scores.\n\n## General Scoring Scale\n\n| Score | Meaning | General Criteria |\n|-------|---------|------------------|\n| 5 | Excellent | Exceeds expectations, best practices throughout |\n| 4 | Good | Meets all requirements, minor issues only |\n| 3 | Average | Functional but notable gaps or issues |\n| 2 | Below Average | Significant issues affecting quality |\n| 1 | Poor | Fails to meet basic requirements |\n\n---\n\n## Functionality (30% weight)\n\nEvaluates whether the implementation meets the spec requirements and works correctly.\n\n| Score | Criteria |\n|-------|----------|\n| 5 | All spec requirements implemented. All tests pass. No obvious bugs. |\n| 4 | All requirements implemented. Tests pass with minor failures (< 5%). Edge cases may be missing. |\n| 3 | Most requirements implemented (> 75%). Some test failures. Core functionality works. |\n| 2 | Partial implementation (50-75%). Significant test failures. Core features have bugs. |\n| 1 | Minimal implementation (< 50%). Tests fail or don't exist. Core functionality broken. |\n\n**Key Evidence:**\n- `functionality.implemented` vs `functionality.spec_requirements`\n- `functionality.test_results.passed` vs `functionality.test_results.failed`\n- `functionality.missing` and `functionality.partially_implemented`\n\n---\n\n## Security (25% weight)\n\nEvaluates security posture and absence of vulnerabilities.\n\n| Score | Criteria |\n|-------|----------|\n| 5 | No security findings. Positive security patterns present. OWASP Top 10 addressed. |\n| 4 | No high-severity findings. 1-2 low/medium issues. Good security hygiene. |\n| 3 | 1-2 medium-severity issues OR 3+ low-severity. Basic security present. |\n| 2 | 1+ high-severity issue OR 3+ medium. Security gaps evident. |\n| 1 | Multiple high-severity issues. Critical vulnerabilities. No security consideration. |\n\n**Severity Weights:**\n- High: SQL injection, command injection, auth bypass, secrets in code\n- Medium: XSS, CSRF, insecure deserialization, missing input validation\n- Low: Information disclosure, verbose errors, missing security headers\n\n**Key Evidence:**\n- `security.findings` (count and severity)\n- `security.patterns_observed`\n\n---\n\n## Test Quality (20% weight)\n\nEvaluates test coverage, DRY adherence, and testing practices.\n\n| Score | Criteria |\n|-------|----------|\n| 5 | High coverage. No DRY violations. Good mock boundaries. Tests are maintainable. |\n| 4 | Moderate-high coverage. Minor DRY issues (1-2). Good testing practices. |\n| 3 | Moderate coverage. Some DRY violations (3-5). Acceptable mocking. |\n| 2 | Low coverage. Significant DRY violations. Poor mock boundaries. |\n| 1 | Minimal/no tests. Severe DRY problems. Tests don't follow best practices. |\n\n**Key Evidence:**\n- `tests.coverage_estimate`\n- `tests.dry_violations` (count)\n- `tests.mocking_approach`\n- `tests.test_count` relative to codebase size\n\n---\n\n## Overengineering (15% weight)\n\nEvaluates simplicity and absence of unnecessary complexity.\n\n| Score | Criteria |\n|-------|----------|\n| 5 | Clean, simple code. No unnecessary abstractions. YAGNI followed. |\n| 4 | Mostly simple. 1-2 minor over-abstractions. Code is readable. |\n| 3 | Some complexity. 3-5 abstraction issues. Config complexity medium. |\n| 2 | Significant over-engineering. 6+ abstraction issues. Unnecessary patterns. |\n| 1 | Severely over-engineered. Abstractions everywhere. Simple tasks made complex. |\n\n**Key Evidence:**\n- `overengineering.abstractions` (count)\n- `overengineering.defensive_code` (count)\n- `overengineering.config_complexity`\n\n---\n\n## Dead Code (10% weight)\n\nEvaluates cleanliness and absence of unused/obsolete code.\n\n| Score | Criteria |\n|-------|----------|\n| 5 | No dead code. No TODOs. Clean codebase. |\n| 4 | 1-3 minor issues (unused imports). No significant dead code. |\n| 3 | 4-6 issues. Some unused functions or TODOs. |\n| 2 | 7-10 issues. Unused functions/classes. Multiple TODOs. |\n| 1 | 10+ issues. Significant dead code. Many TODOs/commented blocks. |\n\n**Key Evidence:**\n- `dead_code.unused_imports` (count)\n- `dead_code.unused_functions` (count)\n- `dead_code.todo_comments`\n- `dead_code.commented_code_blocks`\n",
        "skills/postgres-code-review/SKILL.md": "---\nname: postgres-code-review\ndescription: Reviews PostgreSQL code for indexing strategies, JSONB operations, connection pooling, and transaction safety. Use when reviewing SQL queries, database schemas, JSONB usage, or connection management.\n---\n\n# PostgreSQL Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Missing indexes, wrong index type, query performance | [references/indexes.md](references/indexes.md) |\n| JSONB queries, operators, GIN indexes | [references/jsonb.md](references/jsonb.md) |\n| Connection leaks, pool configuration, timeouts | [references/connections.md](references/connections.md) |\n| Isolation levels, deadlocks, advisory locks | [references/transactions.md](references/transactions.md) |\n\n## Review Checklist\n\n- [ ] WHERE/JOIN columns have appropriate indexes\n- [ ] Composite indexes match query patterns (column order matters)\n- [ ] JSONB columns use GIN indexes when queried\n- [ ] Using proper JSONB operators (`->`, `->>`, `@>`, `?`)\n- [ ] Connection pool configured with appropriate limits\n- [ ] Connections properly released (context managers, try/finally)\n- [ ] Appropriate transaction isolation level for use case\n- [ ] No long-running transactions holding locks\n- [ ] Advisory locks used for application-level coordination\n- [ ] Queries use parameterized statements (no SQL injection)\n\n## When to Load References\n\n- Reviewing SELECT queries with WHERE/JOIN  indexes.md\n- Reviewing JSONB columns or JSON operations  jsonb.md\n- Reviewing database connection code  connections.md\n- Reviewing BEGIN/COMMIT or concurrent updates  transactions.md\n\n## Review Questions\n\n1. Will this query use an index or perform a sequential scan?\n2. Are JSONB operations using appropriate operators and indexes?\n3. Are database connections properly managed and released?\n4. Is the transaction isolation level appropriate for this operation?\n5. Could this cause deadlocks or long-running locks?\n",
        "skills/postgres-code-review/references/connections.md": "# Connections\n\n## Critical Anti-Patterns\n\n### 1. Not Using Connection Pooling\n\n**Problem**: Creating new connection per request is slow and exhausts database connections.\n\n```python\n# BAD: New connection every time\ndef get_user(user_id: int):\n    conn = psycopg2.connect(\n        host='localhost',\n        database='mydb',\n        user='user',\n        password='password'\n    )\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n    result = cursor.fetchone()\n    conn.close()\n    return result\n\n# GOOD: Use connection pool\nfrom psycopg2.pool import ThreadedConnectionPool\n\npool = ThreadedConnectionPool(\n    minconn=5,\n    maxconn=20,\n    host='localhost',\n    database='mydb',\n    user='user',\n    password='password'\n)\n\ndef get_user(user_id: int):\n    conn = pool.getconn()\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        return cursor.fetchone()\n    finally:\n        pool.putconn(conn)\n```\n\n### 2. Connection Leaks\n\n**Problem**: Not releasing connections back to pool causes starvation.\n\n```python\n# BAD: Connection leaked on error\ndef get_user(user_id: int):\n    conn = pool.getconn()\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n    result = cursor.fetchone()\n    pool.putconn(conn)  # Not called if error occurs!\n    return result\n\n# GOOD: Always release in finally block\ndef get_user(user_id: int):\n    conn = pool.getconn()\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        return cursor.fetchone()\n    finally:\n        pool.putconn(conn)\n\n# BETTER: Use context manager\nfrom contextlib import contextmanager\n\n@contextmanager\ndef get_db_connection():\n    conn = pool.getconn()\n    try:\n        yield conn\n    finally:\n        pool.putconn(conn)\n\ndef get_user(user_id: int):\n    with get_db_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        return cursor.fetchone()\n```\n\n### 3. Wrong Pool Size\n\n**Problem**: Pool too small (connection starvation) or too large (resource waste).\n\n```python\n# BAD: Pool size not based on workload\npool = ThreadedConnectionPool(minconn=1, maxconn=100)\n\n# GOOD: Size based on concurrent requests and database limits\n# Rule of thumb: (num_cores * 2) + effective_spindle_count\n# For web server: match number of worker threads/processes\npool = ThreadedConnectionPool(\n    minconn=5,   # Keep warm connections\n    maxconn=20,  # Max concurrent requests\n    host='localhost',\n    database='mydb'\n)\n\n# Check PostgreSQL connection limit\n# SHOW max_connections;  -- Default 100\n# Ensure pool max < max_connections across all app instances\n```\n\n### 4. No Connection Timeout\n\n**Problem**: Application hangs waiting for connections.\n\n```python\n# BAD: No timeout, hangs indefinitely\npool = ThreadedConnectionPool(minconn=5, maxconn=20)\nconn = pool.getconn()  # Blocks forever if pool exhausted\n\n# GOOD: Use timeout\npool = ThreadedConnectionPool(minconn=5, maxconn=20)\nconn = pool.getconn(timeout=5)  # Raises error after 5 seconds\nif conn is None:\n    raise Exception(\"Could not get database connection\")\n\n# BETTER: Use asyncpg with async/await\nimport asyncpg\n\npool = await asyncpg.create_pool(\n    host='localhost',\n    database='mydb',\n    min_size=5,\n    max_size=20,\n    timeout=5,\n    command_timeout=30  # Query timeout\n)\n\nasync def get_user(user_id: int):\n    async with pool.acquire() as conn:\n        return await conn.fetchrow(\n            \"SELECT * FROM users WHERE id = $1\",\n            user_id\n        )\n```\n\n### 5. Not Setting Statement Timeout\n\n**Problem**: Long-running queries hold connections and locks.\n\n```python\n# BAD: No query timeout\nasync def expensive_query():\n    async with pool.acquire() as conn:\n        # Could run for hours, holding connection\n        return await conn.fetch(\"SELECT * FROM huge_table\")\n\n# GOOD: Set statement timeout\nasync def expensive_query():\n    async with pool.acquire() as conn:\n        await conn.execute(\"SET statement_timeout = '30s'\")\n        try:\n            return await conn.fetch(\"SELECT * FROM huge_table\")\n        except asyncpg.QueryCanceledError:\n            raise TimeoutError(\"Query took too long\")\n\n# BETTER: Set at connection level\npool = await asyncpg.create_pool(\n    host='localhost',\n    database='mydb',\n    command_timeout=30,  # 30 second timeout for all queries\n    server_settings={'statement_timeout': '30000'}  # milliseconds\n)\n```\n\n### 6. Not Using PgBouncer\n\n**Problem**: Application connection pool doesn't reduce database connections.\n\n```yaml\n# BAD: Each app instance has its own pool\n# 3 app servers * 20 connections = 60 database connections\n\n# GOOD: Use PgBouncer for connection pooling\n# pgbouncer.ini\n[databases]\nmydb = host=localhost port=5432 dbname=mydb\n\n[pgbouncer]\nlisten_addr = *\nlisten_port = 6432\nauth_type = md5\nauth_file = /etc/pgbouncer/userlist.txt\npool_mode = transaction  # or session\nmax_client_conn = 1000   # Application connections\ndefault_pool_size = 20   # Database connections\nreserve_pool_size = 5\n```\n\n```python\n# Application connects to PgBouncer instead of PostgreSQL\npool = await asyncpg.create_pool(\n    host='localhost',\n    port=6432,  # PgBouncer port\n    database='mydb'\n)\n# Now 3 app servers * 20 connections = 60 app connections\n# But only 20 database connections via PgBouncer\n```\n\n### 7. Holding Connections During I/O\n\n**Problem**: Holding database connection while doing network/file I/O.\n\n```python\n# BAD: Holding connection during API call\nasync def process_user(user_id: int):\n    async with pool.acquire() as conn:\n        user = await conn.fetchrow(\"SELECT * FROM users WHERE id = $1\", user_id)\n\n        # Holding connection during external API call!\n        async with httpx.AsyncClient() as client:\n            response = await client.get(f\"https://api.example.com/users/{user_id}\")\n\n        await conn.execute(\n            \"UPDATE users SET api_data = $1 WHERE id = $2\",\n            response.json(), user_id\n        )\n\n# GOOD: Release connection during I/O\nasync def process_user(user_id: int):\n    async with pool.acquire() as conn:\n        user = await conn.fetchrow(\"SELECT * FROM users WHERE id = $1\", user_id)\n\n    # Connection released during API call\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.example.com/users/{user_id}\")\n\n    async with pool.acquire() as conn:\n        await conn.execute(\n            \"UPDATE users SET api_data = $1 WHERE id = $2\",\n            response.json(), user_id\n        )\n```\n\n### 8. Not Monitoring Connection Pool\n\n**Problem**: Can't diagnose connection starvation or leaks.\n\n```python\n# BAD: No visibility into pool state\npool = ThreadedConnectionPool(minconn=5, maxconn=20)\n\n# GOOD: Monitor pool metrics\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n@contextmanager\ndef get_db_connection():\n    logger.info(f\"Pool: {pool._used}/{pool._maxconn} connections used\")\n    conn = pool.getconn()\n    try:\n        yield conn\n    finally:\n        pool.putconn(conn)\n\n# BETTER: Use metrics library\nfrom prometheus_client import Gauge\n\ndb_connections_used = Gauge('db_connections_used', 'Database connections in use')\ndb_connections_max = Gauge('db_connections_max', 'Max database connections')\n\n@contextmanager\ndef get_db_connection():\n    conn = pool.getconn()\n    db_connections_used.inc()\n    try:\n        yield conn\n    finally:\n        pool.putconn(conn)\n        db_connections_used.dec()\n\ndb_connections_max.set(pool._maxconn)\n```\n\n## Review Questions\n\n1. Is connection pooling used?\n2. Are connections always released (try/finally or context manager)?\n3. Is pool size appropriate for workload?\n4. Are connection and statement timeouts configured?\n5. Would PgBouncer help reduce database connections?\n6. Are connections released during I/O operations?\n7. Is connection pool health monitored?\n8. Are connection errors handled and logged?\n",
        "skills/postgres-code-review/references/indexes.md": "# Indexes\n\n## Critical Anti-Patterns\n\n### 1. Missing Index on WHERE Clause\n\n**Problem**: Sequential scan on large tables causes slow queries.\n\n```sql\n-- BAD: No index on email\nSELECT * FROM users WHERE email = 'user@example.com';\n\n-- GOOD: Create index\nCREATE INDEX idx_users_email ON users(email);\nSELECT * FROM users WHERE email = 'user@example.com';\n```\n\n```python\n# Check query plan\nEXPLAIN ANALYZE SELECT * FROM users WHERE email = 'user@example.com';\n# Look for \"Seq Scan\" (bad) vs \"Index Scan\" (good)\n```\n\n### 2. Wrong Column Order in Composite Index\n\n**Problem**: Index not used if query doesn't match leftmost columns.\n\n```sql\n-- BAD: Index doesn't match query pattern\nCREATE INDEX idx_orders_wrong ON orders(status, user_id);\nSELECT * FROM orders WHERE user_id = 123;  -- Won't use index!\n\n-- GOOD: Match query pattern\nCREATE INDEX idx_orders_user_status ON orders(user_id, status);\nSELECT * FROM orders WHERE user_id = 123;  -- Uses index\nSELECT * FROM orders WHERE user_id = 123 AND status = 'pending';  -- Uses index\n```\n\n**Rule**: Put high-selectivity columns first, match WHERE clause order.\n\n### 3. Not Using Partial Indexes\n\n**Problem**: Indexing entire table when only subset is queried.\n\n```sql\n-- BAD: Index includes all rows\nCREATE INDEX idx_orders_status ON orders(status);\n\n-- GOOD: Only index active orders\nCREATE INDEX idx_orders_active ON orders(user_id, created_at)\nWHERE status = 'active';\n\nSELECT * FROM orders\nWHERE status = 'active' AND user_id = 123\nORDER BY created_at DESC;  -- Uses partial index\n```\n\n### 4. Missing Index on Foreign Keys\n\n**Problem**: Slow JOINs and cascading deletes.\n\n```sql\n-- BAD: No index on foreign key\nCREATE TABLE order_items (\n    id SERIAL PRIMARY KEY,\n    order_id INTEGER REFERENCES orders(id),\n    product_id INTEGER REFERENCES products(id)\n);\n\n-- GOOD: Index foreign keys\nCREATE TABLE order_items (\n    id SERIAL PRIMARY KEY,\n    order_id INTEGER REFERENCES orders(id),\n    product_id INTEGER REFERENCES products(id)\n);\nCREATE INDEX idx_order_items_order_id ON order_items(order_id);\nCREATE INDEX idx_order_items_product_id ON order_items(product_id);\n```\n\n### 5. Not Using EXPLAIN ANALYZE\n\n**Problem**: Guessing instead of measuring query performance.\n\n```python\n# BAD: Assuming query is fast\ncursor.execute(\"SELECT * FROM orders WHERE user_id = %s\", (user_id,))\n\n# GOOD: Verify with EXPLAIN\ncursor.execute(\"\"\"\n    EXPLAIN ANALYZE\n    SELECT * FROM orders WHERE user_id = %s\n\"\"\", (user_id,))\nprint(cursor.fetchall())\n# Check: Index Scan vs Seq Scan, actual time, rows\n\n# Then run actual query\ncursor.execute(\"SELECT * FROM orders WHERE user_id = %s\", (user_id,))\n```\n\n### 6. Over-Indexing\n\n**Problem**: Slows down writes, wastes space.\n\n```sql\n-- BAD: Too many indexes on rarely-queried columns\nCREATE INDEX idx_users_created_at ON users(created_at);\nCREATE INDEX idx_users_updated_at ON users(updated_at);\nCREATE INDEX idx_users_last_login ON users(last_login);\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_username ON users(username);\n\n-- GOOD: Only index frequently-queried columns\nCREATE INDEX idx_users_email ON users(email);  -- Used for login\nCREATE INDEX idx_users_username ON users(username);  -- Used for lookup\n-- Skip indexes on created_at, updated_at, last_login if rarely queried\n```\n\n### 7. Not Using Covering Indexes\n\n**Problem**: Index scan followed by table lookup (heap fetch).\n\n```sql\n-- BAD: Index on id only, must fetch name from table\nCREATE INDEX idx_users_email ON users(email);\nSELECT id, name FROM users WHERE email = 'user@example.com';\n\n-- GOOD: Include name in index (covering index)\nCREATE INDEX idx_users_email_covering ON users(email) INCLUDE (name);\nSELECT id, name FROM users WHERE email = 'user@example.com';\n-- \"Index Only Scan\" - no heap fetch needed\n```\n\n### 8. String Pattern Matching Without Index\n\n**Problem**: LIKE with leading wildcard can't use B-tree index.\n\n```sql\n-- BAD: Can't use standard index\nCREATE INDEX idx_users_email ON users(email);\nSELECT * FROM users WHERE email LIKE '%@example.com';  -- Seq Scan\n\n-- GOOD: Use trigram index for pattern matching\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\nCREATE INDEX idx_users_email_trgm ON users USING gin(email gin_trgm_ops);\nSELECT * FROM users WHERE email LIKE '%@example.com';  -- Uses GIN index\n```\n\n## Review Questions\n\n1. Do all WHERE and JOIN columns have indexes?\n2. Are composite index column orders optimized for queries?\n3. Would partial indexes reduce index size and improve performance?\n4. Are foreign keys indexed?\n5. Has EXPLAIN ANALYZE been used to verify query plans?\n6. Are there redundant or unused indexes?\n7. Would covering indexes eliminate heap fetches?\n8. Are pattern matching queries using appropriate index types (GIN, trigram)?\n",
        "skills/postgres-code-review/references/jsonb.md": "# JSONB\n\n## Critical Anti-Patterns\n\n### 1. Using JSON Instead of JSONB\n\n**Problem**: JSON is stored as text, slower to query, no indexing.\n\n```sql\n-- BAD: Using JSON type\nCREATE TABLE events (\n    id SERIAL PRIMARY KEY,\n    metadata JSON\n);\n\n-- GOOD: Use JSONB for querying and indexing\nCREATE TABLE events (\n    id SERIAL PRIMARY KEY,\n    metadata JSONB\n);\n```\n\n**Rule**: Always use JSONB unless you need to preserve exact formatting/whitespace.\n\n### 2. Wrong JSONB Operator\n\n**Problem**: `->` returns JSONB, `->>` returns text. Using wrong one breaks queries.\n\n```sql\n-- BAD: Comparing JSONB to text\nSELECT * FROM users WHERE metadata->'age' = '25';  -- Won't work\n\n-- GOOD: Use ->> for text comparison\nSELECT * FROM users WHERE metadata->>'age' = '25';\n\n-- GOOD: Use -> for JSONB comparison\nSELECT * FROM users WHERE metadata->'age' = '25'::jsonb;\n\n-- GOOD: Cast to integer for numeric comparison\nSELECT * FROM users WHERE (metadata->>'age')::int = 25;\n```\n\n**Operators**:\n- `->` extracts as JSONB: `metadata->'address'`  `{\"city\": \"NYC\"}`\n- `->>` extracts as text: `metadata->>'name'`  `\"Alice\"`\n- `@>` contains: `metadata @> '{\"role\": \"admin\"}'`\n- `?` key exists: `metadata ? 'email'`\n\n### 3. Missing GIN Index on JSONB\n\n**Problem**: JSONB queries without indexes perform sequential scans.\n\n```sql\n-- BAD: Querying JSONB without index\nSELECT * FROM users WHERE metadata @> '{\"role\": \"admin\"}';  -- Seq Scan\n\n-- GOOD: Create GIN index\nCREATE INDEX idx_users_metadata ON users USING gin(metadata);\nSELECT * FROM users WHERE metadata @> '{\"role\": \"admin\"}';  -- Uses index\n\n-- GOOD: GIN index on specific path\nCREATE INDEX idx_users_metadata_role ON users USING gin((metadata->'role'));\n```\n\n### 4. Not Using Containment Operator\n\n**Problem**: Extracting and comparing is slower than using `@>`.\n\n```sql\n-- BAD: Extracting then comparing\nSELECT * FROM events\nWHERE metadata->>'type' = 'click' AND metadata->>'source' = 'mobile';\n\n-- GOOD: Use containment operator\nSELECT * FROM events\nWHERE metadata @> '{\"type\": \"click\", \"source\": \"mobile\"}';\n-- Much faster with GIN index\n```\n\n### 5. Storing Arrays as JSON Strings\n\n**Problem**: Can't use array operators, must parse JSON every time.\n\n```python\n# BAD: Storing array as JSON string\ncursor.execute(\"\"\"\n    INSERT INTO users (tags) VALUES (%s)\n\"\"\", (json.dumps(['python', 'postgres']),))\n\ncursor.execute(\"\"\"\n    SELECT * FROM users WHERE tags::jsonb @> '\"python\"'\n\"\"\")\n\n# GOOD: Use PostgreSQL array type for simple arrays\ncursor.execute(\"\"\"\n    INSERT INTO users (tags) VALUES (%s)\n\"\"\", (['python', 'postgres'],))\n\ncursor.execute(\"\"\"\n    SELECT * FROM users WHERE 'python' = ANY(tags)\n\"\"\")\n\n# Use JSONB only for complex nested structures\n```\n\n### 6. Deep Nesting Without Indexes\n\n**Problem**: Querying deep paths is slow without expression indexes.\n\n```sql\n-- BAD: Querying deep path without index\nSELECT * FROM events\nWHERE metadata->'user'->'profile'->>'country' = 'US';\n\n-- GOOD: Create expression index\nCREATE INDEX idx_events_country ON events(\n    (metadata->'user'->'profile'->>'country')\n);\nSELECT * FROM events\nWHERE metadata->'user'->'profile'->>'country' = 'US';\n```\n\n### 7. Not Validating JSONB Structure\n\n**Problem**: No schema validation leads to inconsistent data.\n\n```python\n# BAD: No validation\ncursor.execute(\"\"\"\n    INSERT INTO users (metadata) VALUES (%s)\n\"\"\", (json.dumps({'age': 'twenty-five'}),))  # Should be integer!\n\n# GOOD: Validate before insert\ndef validate_user_metadata(metadata: dict) -> dict:\n    assert isinstance(metadata.get('age'), int), \"age must be integer\"\n    assert isinstance(metadata.get('email'), str), \"email must be string\"\n    return metadata\n\nmetadata = validate_user_metadata({'age': 25, 'email': 'user@example.com'})\ncursor.execute(\"\"\"\n    INSERT INTO users (metadata) VALUES (%s)\n\"\"\", (json.dumps(metadata),))\n\n# BETTER: Use CHECK constraint\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    metadata JSONB,\n    CHECK (jsonb_typeof(metadata->'age') = 'number'),\n    CHECK (jsonb_typeof(metadata->'email') = 'string')\n);\n```\n\n### 8. JSONB for Relational Data\n\n**Problem**: Using JSONB when proper columns/foreign keys are better.\n\n```sql\n-- BAD: Storing relational data in JSONB\nCREATE TABLE orders (\n    id SERIAL PRIMARY KEY,\n    data JSONB  -- Contains user_id, product_id, quantity\n);\n\n-- GOOD: Use proper columns and foreign keys\nCREATE TABLE orders (\n    id SERIAL PRIMARY KEY,\n    user_id INTEGER REFERENCES users(id),\n    product_id INTEGER REFERENCES products(id),\n    quantity INTEGER,\n    metadata JSONB  -- Only for truly unstructured data\n);\n```\n\n**Rule**: Use JSONB for truly dynamic/unstructured data, not for avoiding schema design.\n\n### 9. Inefficient JSONB Aggregation\n\n**Problem**: Not using jsonb_agg or jsonb_object_agg.\n\n```python\n# BAD: Fetching and building JSON in application code\ncursor.execute(\"SELECT id, name FROM products WHERE category_id = %s\", (cat_id,))\nproducts = [{'id': row[0], 'name': row[1]} for row in cursor.fetchall()]\nresult = {'products': products}\n\n# GOOD: Build JSON in database\ncursor.execute(\"\"\"\n    SELECT jsonb_build_object(\n        'products', jsonb_agg(jsonb_build_object('id', id, 'name', name))\n    )\n    FROM products\n    WHERE category_id = %s\n\"\"\", (cat_id,))\nresult = cursor.fetchone()[0]\n```\n\n## Review Questions\n\n1. Is JSONB used instead of JSON?\n2. Are the correct operators used (`->` vs `->>`, `@>` for containment)?\n3. Do JSONB columns have GIN indexes?\n4. Are containment operators (`@>`) used instead of extracting and comparing?\n5. Is JSONB used appropriately (not for relational data)?\n6. Are deep paths indexed with expression indexes?\n7. Is JSONB structure validated?\n8. Are JSONB aggregation functions used instead of application-side building?\n",
        "skills/postgres-code-review/references/transactions.md": "# Transactions\n\n## Critical Anti-Patterns\n\n### 1. Wrong Isolation Level\n\n**Problem**: Using default isolation level when stronger guarantees needed.\n\n```python\n# BAD: Default READ COMMITTED allows non-repeatable reads\nasync def transfer_money(from_id: int, to_id: int, amount: int):\n    async with pool.acquire() as conn:\n        async with conn.transaction():\n            balance = await conn.fetchval(\n                \"SELECT balance FROM accounts WHERE id = $1\", from_id\n            )\n            if balance < amount:\n                raise ValueError(\"Insufficient funds\")\n\n            # Another transaction could modify balance here!\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\",\n                amount, from_id\n            )\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\",\n                amount, to_id\n            )\n\n# GOOD: Use SERIALIZABLE for critical operations\nasync def transfer_money(from_id: int, to_id: int, amount: int):\n    async with pool.acquire() as conn:\n        async with conn.transaction(isolation='serializable'):\n            balance = await conn.fetchval(\n                \"SELECT balance FROM accounts WHERE id = $1\", from_id\n            )\n            if balance < amount:\n                raise ValueError(\"Insufficient funds\")\n\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\",\n                amount, from_id\n            )\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\",\n                amount, to_id\n            )\n\n# BETTER: Use SELECT FOR UPDATE to lock row\nasync def transfer_money(from_id: int, to_id: int, amount: int):\n    async with pool.acquire() as conn:\n        async with conn.transaction():\n            balance = await conn.fetchval(\n                \"SELECT balance FROM accounts WHERE id = $1 FOR UPDATE\",\n                from_id\n            )\n            if balance < amount:\n                raise ValueError(\"Insufficient funds\")\n\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\",\n                amount, from_id\n            )\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\",\n                amount, to_id\n            )\n```\n\n**Isolation Levels**:\n- `READ COMMITTED` (default): Prevents dirty reads, allows non-repeatable reads\n- `REPEATABLE READ`: Prevents dirty and non-repeatable reads\n- `SERIALIZABLE`: Full isolation, prevents all anomalies\n\n### 2. Long-Running Transactions\n\n**Problem**: Holds locks, blocks other queries, bloats WAL.\n\n```python\n# BAD: Long transaction holding locks\nasync def process_orders():\n    async with pool.acquire() as conn:\n        async with conn.transaction():\n            orders = await conn.fetch(\"SELECT * FROM orders WHERE status = 'pending'\")\n\n            for order in orders:\n                # External API call inside transaction!\n                result = await external_api.process(order)\n\n                await conn.execute(\n                    \"UPDATE orders SET status = $1, result = $2 WHERE id = $3\",\n                    'processed', result, order['id']\n                )\n\n# GOOD: Keep transactions short\nasync def process_orders():\n    async with pool.acquire() as conn:\n        orders = await conn.fetch(\"SELECT * FROM orders WHERE status = 'pending'\")\n\n    # Process outside transaction\n    for order in orders:\n        result = await external_api.process(order)\n\n        async with pool.acquire() as conn:\n            async with conn.transaction():\n                await conn.execute(\n                    \"UPDATE orders SET status = $1, result = $2 WHERE id = $3\",\n                    'processed', result, order['id']\n                )\n```\n\n### 3. Deadlocks from Lock Order\n\n**Problem**: Different transactions acquire locks in different orders.\n\n```python\n# BAD: Different lock order causes deadlocks\n# Transaction 1\nasync with conn.transaction():\n    await conn.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = 1\")\n    await conn.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = 2\")\n\n# Transaction 2 (at same time)\nasync with conn.transaction():\n    await conn.execute(\"UPDATE accounts SET balance = balance - 50 WHERE id = 2\")\n    await conn.execute(\"UPDATE accounts SET balance = balance + 50 WHERE id = 1\")\n# DEADLOCK: T1 locks account 1, T2 locks account 2, both wait for each other\n\n# GOOD: Always acquire locks in same order\nasync def transfer(from_id: int, to_id: int, amount: int):\n    # Always lock lower ID first\n    first_id, second_id = sorted([from_id, to_id])\n\n    async with conn.transaction():\n        # Lock in consistent order\n        await conn.execute(\n            \"SELECT id FROM accounts WHERE id IN ($1, $2) ORDER BY id FOR UPDATE\",\n            first_id, second_id\n        )\n\n        if from_id < to_id:\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\",\n                amount, from_id\n            )\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\",\n                amount, to_id\n            )\n        else:\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\",\n                amount, to_id\n            )\n            await conn.execute(\n                \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\",\n                amount, from_id\n            )\n```\n\n### 4. Not Using Advisory Locks\n\n**Problem**: Application-level coordination requires database support.\n\n```python\n# BAD: Race condition on external resource\nasync def process_unique_job(job_id: int):\n    async with pool.acquire() as conn:\n        job = await conn.fetchrow(\"SELECT * FROM jobs WHERE id = $1\", job_id)\n\n        if job['status'] == 'pending':\n            # Another process could process same job!\n            result = await expensive_operation(job)\n\n            await conn.execute(\n                \"UPDATE jobs SET status = 'complete', result = $1 WHERE id = $2\",\n                result, job_id\n            )\n\n# GOOD: Use advisory lock\nasync def process_unique_job(job_id: int):\n    async with pool.acquire() as conn:\n        # Try to acquire advisory lock (non-blocking)\n        locked = await conn.fetchval(\n            \"SELECT pg_try_advisory_lock($1)\",\n            job_id\n        )\n\n        if not locked:\n            return  # Another process is handling this job\n\n        try:\n            job = await conn.fetchrow(\"SELECT * FROM jobs WHERE id = $1\", job_id)\n\n            if job['status'] == 'pending':\n                result = await expensive_operation(job)\n\n                await conn.execute(\n                    \"UPDATE jobs SET status = 'complete', result = $1 WHERE id = $2\",\n                    result, job_id\n                )\n        finally:\n            # Release advisory lock\n            await conn.execute(\"SELECT pg_advisory_unlock($1)\", job_id)\n```\n\n**Advisory Lock Functions**:\n- `pg_advisory_lock(key)`: Blocking lock\n- `pg_try_advisory_lock(key)`: Non-blocking, returns true/false\n- `pg_advisory_unlock(key)`: Release lock\n- `pg_advisory_xact_lock(key)`: Auto-released at transaction end\n\n### 5. Not Handling Serialization Failures\n\n**Problem**: SERIALIZABLE transactions can fail and need retry.\n\n```python\n# BAD: No retry on serialization failure\nasync def increment_counter(counter_id: int):\n    async with pool.acquire() as conn:\n        async with conn.transaction(isolation='serializable'):\n            count = await conn.fetchval(\n                \"SELECT count FROM counters WHERE id = $1\", counter_id\n            )\n            await conn.execute(\n                \"UPDATE counters SET count = $1 WHERE id = $2\",\n                count + 1, counter_id\n            )\n    # Raises SerializationError under contention\n\n# GOOD: Retry on serialization failure\nimport asyncpg\n\nasync def increment_counter(counter_id: int, max_retries: int = 3):\n    for attempt in range(max_retries):\n        try:\n            async with pool.acquire() as conn:\n                async with conn.transaction(isolation='serializable'):\n                    count = await conn.fetchval(\n                        \"SELECT count FROM counters WHERE id = $1\", counter_id\n                    )\n                    await conn.execute(\n                        \"UPDATE counters SET count = $1 WHERE id = $2\",\n                        count + 1, counter_id\n                    )\n            return  # Success\n        except asyncpg.SerializationError:\n            if attempt == max_retries - 1:\n                raise\n            # Retry with exponential backoff\n            await asyncio.sleep(0.1 * (2 ** attempt))\n```\n\n### 6. Missing ROLLBACK on Error\n\n**Problem**: Transaction left open on error, holds locks.\n\n```python\n# BAD: Transaction not rolled back on error\nconn = pool.getconn()\ncursor = conn.cursor()\ncursor.execute(\"BEGIN\")\ntry:\n    cursor.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = 1\")\n    # Error here leaves transaction open!\n    cursor.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = 2\")\n    conn.commit()\nfinally:\n    pool.putconn(conn)\n\n# GOOD: Use context manager (auto rollback)\nasync with pool.acquire() as conn:\n    async with conn.transaction():\n        await conn.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = 1\")\n        await conn.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = 2\")\n    # Automatically rolls back on exception\n\n# GOOD: Explicit rollback\nconn = pool.getconn()\ntry:\n    cursor = conn.cursor()\n    cursor.execute(\"BEGIN\")\n    try:\n        cursor.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = 1\")\n        cursor.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = 2\")\n        conn.commit()\n    except Exception:\n        conn.rollback()\n        raise\nfinally:\n    pool.putconn(conn)\n```\n\n### 7. Nested Transactions Without Savepoints\n\n**Problem**: Inner \"transaction\" doesn't actually create nested transaction.\n\n```python\n# BAD: Nested transaction blocks don't work as expected\nasync with pool.acquire() as conn:\n    async with conn.transaction():\n        await conn.execute(\"INSERT INTO logs (message) VALUES ('start')\")\n\n        try:\n            async with conn.transaction():  # This doesn't create nested transaction!\n                await conn.execute(\"INSERT INTO data (value) VALUES (123)\")\n                raise ValueError(\"Error\")\n        except ValueError:\n            pass  # Expect outer transaction to continue\n\n        await conn.execute(\"INSERT INTO logs (message) VALUES ('end')\")\n# Entire transaction is rolled back, including 'start' log\n\n# GOOD: Use savepoints for nested transactions\nasync with pool.acquire() as conn:\n    async with conn.transaction():\n        await conn.execute(\"INSERT INTO logs (message) VALUES ('start')\")\n\n        try:\n            # Create savepoint\n            await conn.execute(\"SAVEPOINT inner\")\n            await conn.execute(\"INSERT INTO data (value) VALUES (123)\")\n            raise ValueError(\"Error\")\n        except ValueError:\n            # Rollback to savepoint\n            await conn.execute(\"ROLLBACK TO SAVEPOINT inner\")\n\n        await conn.execute(\"INSERT INTO logs (message) VALUES ('end')\")\n# Both logs are committed, data insert is rolled back\n```\n\n### 8. Not Using FOR UPDATE SKIP LOCKED\n\n**Problem**: Queue processing blocked by locked rows.\n\n```python\n# BAD: Workers block on locked rows\nasync def process_next_job():\n    async with pool.acquire() as conn:\n        async with conn.transaction():\n            # Blocks if another worker locked this row\n            job = await conn.fetchrow(\"\"\"\n                SELECT * FROM jobs\n                WHERE status = 'pending'\n                ORDER BY created_at\n                LIMIT 1\n                FOR UPDATE\n            \"\"\")\n\n            if job:\n                await process_job(job)\n                await conn.execute(\n                    \"UPDATE jobs SET status = 'complete' WHERE id = $1\",\n                    job['id']\n                )\n\n# GOOD: Skip locked rows\nasync def process_next_job():\n    async with pool.acquire() as conn:\n        async with conn.transaction():\n            # Skip rows locked by other workers\n            job = await conn.fetchrow(\"\"\"\n                SELECT * FROM jobs\n                WHERE status = 'pending'\n                ORDER BY created_at\n                LIMIT 1\n                FOR UPDATE SKIP LOCKED\n            \"\"\")\n\n            if job:\n                await process_job(job)\n                await conn.execute(\n                    \"UPDATE jobs SET status = 'complete' WHERE id = $1\",\n                    job['id']\n                )\n```\n\n## Review Questions\n\n1. Is the isolation level appropriate for the operation?\n2. Are transactions kept short (no I/O inside)?\n3. Are locks always acquired in consistent order to prevent deadlocks?\n4. Would advisory locks help with application-level coordination?\n5. Are serialization failures caught and retried?\n6. Are transactions properly rolled back on error (context managers)?\n7. Are savepoints used for nested transaction semantics?\n8. Is `FOR UPDATE SKIP LOCKED` used for queue processing?\n",
        "skills/prometheus-go-code-review/SKILL.md": "---\nname: prometheus-go-code-review\ndescription: Reviews Prometheus instrumentation in Go code for proper metric types, labels, and patterns. Use when reviewing code with prometheus/client_golang metrics.\n---\n\n# Prometheus Go Code Review\n\n## Review Checklist\n\n- [ ] Metric types match measurement semantics (Counter/Gauge/Histogram)\n- [ ] Labels have low cardinality (no user IDs, timestamps, paths)\n- [ ] Metric names follow conventions (snake_case, unit suffix)\n- [ ] Histograms use appropriate bucket boundaries\n- [ ] Metrics registered once, not per-request\n- [ ] Collectors don't panic on race conditions\n- [ ] /metrics endpoint exposed and accessible\n\n## Metric Type Selection\n\n| Measurement | Type | Example |\n|-------------|------|---------|\n| Requests processed | Counter | `requests_total` |\n| Items in queue | Gauge | `queue_length` |\n| Request duration | Histogram | `request_duration_seconds` |\n| Concurrent connections | Gauge | `active_connections` |\n| Errors since start | Counter | `errors_total` |\n| Memory usage | Gauge | `memory_bytes` |\n\n## Critical Anti-Patterns\n\n### 1. High Cardinality Labels\n\n```go\n// BAD - unique per user/request\ncounter := promauto.NewCounterVec(\n    prometheus.CounterOpts{Name: \"requests_total\"},\n    []string{\"user_id\", \"path\"},  // millions of series!\n)\ncounter.WithLabelValues(userID, request.URL.Path).Inc()\n\n// GOOD - bounded label values\ncounter := promauto.NewCounterVec(\n    prometheus.CounterOpts{Name: \"requests_total\"},\n    []string{\"method\", \"status_code\"},  // <100 series\n)\ncounter.WithLabelValues(r.Method, statusCode).Inc()\n```\n\n### 2. Wrong Metric Type\n\n```go\n// BAD - using gauge for monotonic value\nrequestCount := promauto.NewGauge(prometheus.GaugeOpts{\n    Name: \"http_requests\",\n})\nrequestCount.Inc()  // should be Counter!\n\n// GOOD\nrequestCount := promauto.NewCounter(prometheus.CounterOpts{\n    Name: \"http_requests_total\",\n})\nrequestCount.Inc()\n```\n\n### 3. Registering Per-Request\n\n```go\n// BAD - new metric per request\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    counter := prometheus.NewCounter(...)  // creates new each time!\n    prometheus.MustRegister(counter)       // panics on duplicate!\n}\n\n// GOOD - register once\nvar requestCounter = promauto.NewCounter(prometheus.CounterOpts{\n    Name: \"http_requests_total\",\n})\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    requestCounter.Inc()\n}\n```\n\n### 4. Missing Unit Suffix\n\n```go\n// BAD\nduration := promauto.NewHistogram(prometheus.HistogramOpts{\n    Name: \"request_duration\",  // no unit!\n})\n\n// GOOD\nduration := promauto.NewHistogram(prometheus.HistogramOpts{\n    Name: \"request_duration_seconds\",  // unit in name\n})\n```\n\n## Good Patterns\n\n### Metric Definition\n\n```go\nvar (\n    httpRequests = promauto.NewCounterVec(\n        prometheus.CounterOpts{\n            Namespace: \"myapp\",\n            Subsystem: \"http\",\n            Name:      \"requests_total\",\n            Help:      \"Total HTTP requests processed\",\n        },\n        []string{\"method\", \"status\"},\n    )\n\n    httpDuration = promauto.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Namespace: \"myapp\",\n            Subsystem: \"http\",\n            Name:      \"request_duration_seconds\",\n            Help:      \"HTTP request latencies\",\n            Buckets:   []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},\n        },\n        []string{\"method\"},\n    )\n)\n```\n\n### Middleware Pattern\n\n```go\nfunc metricsMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        timer := prometheus.NewTimer(httpDuration.WithLabelValues(r.Method))\n        defer timer.ObserveDuration()\n\n        wrapped := &responseWriter{ResponseWriter: w, status: 200}\n        next.ServeHTTP(wrapped, r)\n\n        httpRequests.WithLabelValues(r.Method, strconv.Itoa(wrapped.status)).Inc()\n    })\n}\n```\n\n### Exposing Metrics\n\n```go\nimport \"github.com/prometheus/client_golang/prometheus/promhttp\"\n\nfunc main() {\n    http.Handle(\"/metrics\", promhttp.Handler())\n    http.ListenAndServe(\":9090\", nil)\n}\n```\n\n## Review Questions\n\n1. Are metric types correct (Counter vs Gauge vs Histogram)?\n2. Are label values bounded (no UUIDs, timestamps, paths)?\n3. Do metric names include units (_seconds, _bytes)?\n4. Are metrics registered once (not per-request)?\n5. Is /metrics endpoint properly exposed?\n",
        "skills/pydantic-ai-agent-creation/SKILL.md": "---\nname: pydantic-ai-agent-creation\ndescription: Create PydanticAI agents with type-safe dependencies, structured outputs, and proper configuration. Use when building AI agents, creating chat systems, or integrating LLMs with Pydantic validation.\n---\n\n# Creating PydanticAI Agents\n\n## Quick Start\n\n```python\nfrom pydantic_ai import Agent\n\n# Minimal agent (text output)\nagent = Agent('openai:gpt-4o')\nresult = agent.run_sync('Hello!')\nprint(result.output)  # str\n```\n\n## Model Selection\n\nModel strings follow `provider:model-name` format:\n\n```python\n# OpenAI\nagent = Agent('openai:gpt-4o')\nagent = Agent('openai:gpt-4o-mini')\n\n# Anthropic\nagent = Agent('anthropic:claude-sonnet-4-5')\nagent = Agent('anthropic:claude-haiku-4-5')\n\n# Google\nagent = Agent('google-gla:gemini-2.0-flash')\nagent = Agent('google-vertex:gemini-2.0-flash')\n\n# Others: groq:, mistral:, cohere:, bedrock:, etc.\n```\n\n## Structured Outputs\n\nUse Pydantic models for validated, typed responses:\n\n```python\nfrom pydantic import BaseModel\nfrom pydantic_ai import Agent\n\nclass CityInfo(BaseModel):\n    city: str\n    country: str\n    population: int\n\nagent = Agent('openai:gpt-4o', output_type=CityInfo)\nresult = agent.run_sync('Tell me about Paris')\nprint(result.output.city)  # \"Paris\"\nprint(result.output.population)  # int, validated\n```\n\n## Agent Configuration\n\n```python\nagent = Agent(\n    'openai:gpt-4o',\n    output_type=MyOutput,           # Structured output type\n    deps_type=MyDeps,               # Dependency injection type\n    instructions='You are helpful.',  # Static instructions\n    retries=2,                      # Retry attempts for validation\n    name='my-agent',                # For logging/tracing\n    model_settings=ModelSettings(   # Provider settings\n        temperature=0.7,\n        max_tokens=1000\n    ),\n    end_strategy='early',           # How to handle tool calls with results\n)\n```\n\n## Running Agents\n\nThree execution methods:\n\n```python\n# Async (preferred)\nresult = await agent.run('prompt', deps=my_deps)\n\n# Sync (convenience)\nresult = agent.run_sync('prompt', deps=my_deps)\n\n# Streaming\nasync with agent.run_stream('prompt') as response:\n    async for chunk in response.stream_output():\n        print(chunk, end='')\n```\n\n## Instructions vs System Prompts\n\n```python\n# Instructions: Concatenated, for agent behavior\nagent = Agent(\n    'openai:gpt-4o',\n    instructions='You are a helpful assistant. Be concise.'\n)\n\n# Dynamic instructions via decorator\n@agent.instructions\ndef add_context(ctx: RunContext[MyDeps]) -> str:\n    return f\"User ID: {ctx.deps.user_id}\"\n\n# System prompts: Static, for model context\nagent = Agent(\n    'openai:gpt-4o',\n    system_prompt=['You are an expert.', 'Always cite sources.']\n)\n```\n\n## Common Patterns\n\n### Parameterized Agent (Type-Safe)\n\n```python\nfrom dataclasses import dataclass\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass Deps:\n    api_key: str\n    user_id: int\n\nagent: Agent[Deps, str] = Agent(\n    'openai:gpt-4o',\n    deps_type=Deps,\n)\n\n# deps is now required and type-checked\nresult = agent.run_sync('Hello', deps=Deps(api_key='...', user_id=123))\n```\n\n### No Dependencies (Satisfy Type Checker)\n\n```python\n# Option 1: Explicit type annotation\nagent: Agent[None, str] = Agent('openai:gpt-4o')\n\n# Option 2: Pass deps=None\nresult = agent.run_sync('Hello', deps=None)\n```\n\n## Decision Framework\n\n| Scenario | Configuration |\n|----------|--------------|\n| Simple text responses | `Agent(model)` |\n| Structured data extraction | `Agent(model, output_type=MyModel)` |\n| Need external services | Add `deps_type=MyDeps` |\n| Validation retries needed | Increase `retries=3` |\n| Debugging/monitoring | Set `instrument=True` |\n",
        "skills/pydantic-ai-common-pitfalls/SKILL.md": "---\nname: pydantic-ai-common-pitfalls\ndescription: Avoid common mistakes and debug issues in PydanticAI agents. Use when encountering errors, unexpected behavior, or when reviewing agent implementations.\n---\n\n# PydanticAI Common Pitfalls and Debugging\n\n## Tool Decorator Errors\n\n### Wrong: RunContext in tool_plain\n\n```python\n# ERROR: RunContext not allowed in tool_plain\n@agent.tool_plain\nasync def bad_tool(ctx: RunContext[MyDeps]) -> str:\n    return \"oops\"\n# UserError: RunContext annotations can only be used with tools that take context\n```\n\n**Fix**: Use `@agent.tool` if you need context:\n```python\n@agent.tool\nasync def good_tool(ctx: RunContext[MyDeps]) -> str:\n    return \"works\"\n```\n\n### Wrong: Missing RunContext in tool\n\n```python\n# ERROR: First param must be RunContext\n@agent.tool\ndef bad_tool(user_id: int) -> str:\n    return \"oops\"\n# UserError: First parameter of tools that take context must be annotated with RunContext[...]\n```\n\n**Fix**: Add RunContext as first parameter:\n```python\n@agent.tool\ndef good_tool(ctx: RunContext[MyDeps], user_id: int) -> str:\n    return \"works\"\n```\n\n### Wrong: RunContext not first\n\n```python\n# ERROR: RunContext must be first parameter\n@agent.tool\ndef bad_tool(user_id: int, ctx: RunContext[MyDeps]) -> str:\n    return \"oops\"\n```\n\n**Fix**: RunContext must always be the first parameter.\n\n## Valid Patterns (Not Errors)\n\n### Raw Function Tool Registration\n\nThe following pattern IS valid and supported by pydantic-ai:\n\n```python\nfrom pydantic_ai import Agent, RunContext\n\nasync def search_db(ctx: RunContext[MyDeps], query: str) -> list[dict]:\n    \"\"\"Search the database.\"\"\"\n    return await ctx.deps.db.search(query)\n\nasync def get_user(ctx: RunContext[MyDeps], user_id: int) -> dict:\n    \"\"\"Get user by ID.\"\"\"\n    return await ctx.deps.db.get_user(user_id)\n\n# Valid: Pass raw functions to Agent(tools=[...])\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=MyDeps,\n    tools=[search_db, get_user]  # RunContext detected from signature\n)\n```\n\n**Why this works:** PydanticAI inspects function signatures. If the first parameter is `RunContext[T]`, it's treated as a context-aware tool. No decorator required.\n\n**Reference:** https://ai.pydantic.dev/agents/#registering-tools-via-the-tools-argument\n\n**Do NOT flag** code that passes functions with `RunContext` signatures to `Agent(tools=[...])`. This is equivalent to using `@agent.tool` and is explicitly documented.\n\n## Dependency Type Mismatches\n\n### Wrong: Missing deps at runtime\n\n```python\nagent = Agent('openai:gpt-4o', deps_type=MyDeps)\n\n# ERROR: deps required but not provided\nresult = agent.run_sync('Hello')  # Missing deps!\n```\n\n**Fix**: Always provide deps when deps_type is set:\n```python\nresult = agent.run_sync('Hello', deps=MyDeps(...))\n```\n\n### Wrong: Wrong deps type\n\n```python\n@dataclass\nclass AppDeps:\n    db: Database\n\n@dataclass\nclass WrongDeps:\n    api: ApiClient\n\nagent = Agent('openai:gpt-4o', deps_type=AppDeps)\n\n# Type error: WrongDeps != AppDeps\nresult = agent.run_sync('Hello', deps=WrongDeps(...))\n```\n\n## Output Type Issues\n\n### Pydantic validation fails\n\n```python\nclass Response(BaseModel):\n    count: int\n    items: list[str]\n\nagent = Agent('openai:gpt-4o', output_type=Response)\nresult = agent.run_sync('List items')\n# May fail if LLM returns wrong structure\n```\n\n**Fix**: Increase retries or improve prompt:\n```python\nagent = Agent(\n    'openai:gpt-4o',\n    output_type=Response,\n    retries=3,  # More attempts\n    instructions='Return JSON with count (int) and items (list of strings).'\n)\n```\n\n### Complex nested types\n\n```python\n# May cause schema issues with some models\nclass Complex(BaseModel):\n    nested: dict[str, list[tuple[int, str]]]\n```\n\n**Fix**: Simplify or use intermediate models:\n```python\nclass Item(BaseModel):\n    id: int\n    name: str\n\nclass Simple(BaseModel):\n    items: list[Item]\n```\n\n## Async vs Sync Mistakes\n\n### Wrong: Calling async in sync context\n\n```python\n# ERROR: Can't await in sync function\ndef handler():\n    result = await agent.run('Hello')  # SyntaxError!\n```\n\n**Fix**: Use run_sync or make handler async:\n```python\ndef handler():\n    result = agent.run_sync('Hello')\n\n# Or\nasync def handler():\n    result = await agent.run('Hello')\n```\n\n### Wrong: Blocking in async tools\n\n```python\n@agent.tool\nasync def slow_tool(ctx: RunContext[Deps]) -> str:\n    time.sleep(5)  # WRONG: Blocks event loop!\n    return \"done\"\n```\n\n**Fix**: Use async I/O:\n```python\n@agent.tool\nasync def slow_tool(ctx: RunContext[Deps]) -> str:\n    await asyncio.sleep(5)  # Correct\n    return \"done\"\n```\n\n## Model Configuration Errors\n\n### Missing API key\n\n```python\n# ERROR: OPENAI_API_KEY not set\nagent = Agent('openai:gpt-4o')\nresult = agent.run_sync('Hello')\n# ModelAPIError: Authentication failed\n```\n\n**Fix**: Set environment variable or use defer_model_check:\n```python\n# For testing\nagent = Agent('openai:gpt-4o', defer_model_check=True)\nwith agent.override(model=TestModel()):\n    result = agent.run_sync('Hello')\n```\n\n### Invalid model string\n\n```python\n# ERROR: Unknown provider\nagent = Agent('unknown:model')\n# ValueError: Unknown model provider\n```\n\n**Fix**: Use valid provider:model format.\n\n## Streaming Issues\n\n### Wrong: Using result before stream completes\n\n```python\nasync with agent.run_stream('Hello') as response:\n    # DON'T access .output before streaming completes\n    print(response.output)  # May be incomplete!\n\n# Correct: access after context manager\nprint(response.output)  # Complete result\n```\n\n### Wrong: Not iterating stream\n\n```python\nasync with agent.run_stream('Hello') as response:\n    pass  # Never consumed!\n\n# Stream was never read - output may be incomplete\n```\n\n**Fix**: Always consume the stream:\n```python\nasync with agent.run_stream('Hello') as response:\n    async for chunk in response.stream_output():\n        print(chunk, end='')\n```\n\n## Tool Return Issues\n\n### Wrong: Returning non-serializable\n\n```python\n@agent.tool_plain\ndef bad_return() -> object:\n    return CustomObject()  # Can't serialize!\n```\n\n**Fix**: Return serializable types (str, dict, Pydantic model):\n```python\n@agent.tool_plain\ndef good_return() -> dict:\n    return {\"key\": \"value\"}\n```\n\n## Debugging Tips\n\n### Enable tracing\n\n```python\nimport logfire\nlogfire.configure()\nlogfire.instrument_pydantic_ai()\n\n# Or per-agent\nagent = Agent('openai:gpt-4o', instrument=True)\n```\n\n### Capture messages\n\n```python\nfrom pydantic_ai import capture_run_messages\n\nwith capture_run_messages() as messages:\n    result = agent.run_sync('Hello')\n\nfor msg in messages:\n    print(type(msg).__name__, msg)\n```\n\n### Check model responses\n\n```python\nresult = agent.run_sync('Hello')\nprint(result.all_messages())  # Full message history\nprint(result.response)  # Last model response\nprint(result.usage())  # Token usage\n```\n\n## Common Error Messages\n\n| Error | Cause | Fix |\n|-------|-------|-----|\n| `First parameter... RunContext` | @agent.tool missing ctx | Add `ctx: RunContext[...]` |\n| `RunContext... only... context` | @agent.tool_plain has ctx | Remove ctx or use @agent.tool |\n| `Unknown model provider` | Invalid model string | Use valid `provider:model` |\n| `ModelAPIError` | API auth/quota | Check API key, limits |\n| `RetryPromptPart` in messages | Validation failed | Check output_type, increase retries |\n",
        "skills/pydantic-ai-dependency-injection/SKILL.md": "---\nname: pydantic-ai-dependency-injection\ndescription: Implement dependency injection in PydanticAI agents using RunContext and deps_type. Use when agents need database connections, API clients, user context, or any external resources.\n---\n\n# PydanticAI Dependency Injection\n\n## Core Pattern\n\nDependencies flow through `RunContext`:\n\n```python\nfrom dataclasses import dataclass\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass Deps:\n    db: DatabaseConn\n    api_client: HttpClient\n    user_id: int\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=Deps,  # Type for static analysis\n)\n\n@agent.tool\nasync def get_user_balance(ctx: RunContext[Deps]) -> float:\n    \"\"\"Get the current user's account balance.\"\"\"\n    return await ctx.deps.db.get_balance(ctx.deps.user_id)\n\n# At runtime, provide deps\nresult = await agent.run(\n    'What is my balance?',\n    deps=Deps(db=db_conn, api_client=client, user_id=123)\n)\n```\n\n## Defining Dependencies\n\nUse dataclasses or Pydantic models:\n\n```python\nfrom dataclasses import dataclass\nfrom pydantic import BaseModel\n\n# Dataclass (recommended for simplicity)\n@dataclass\nclass Deps:\n    db: DatabaseConnection\n    cache: CacheClient\n    user_context: UserContext\n\n# Pydantic model (if you need validation)\nclass Deps(BaseModel):\n    api_key: str\n    endpoint: str\n    timeout: int = 30\n```\n\n## Accessing Dependencies\n\nIn tools and instructions:\n\n```python\n@agent.tool\nasync def query_database(ctx: RunContext[Deps], query: str) -> list[dict]:\n    \"\"\"Run a database query.\"\"\"\n    return await ctx.deps.db.execute(query)\n\n@agent.instructions\nasync def add_user_context(ctx: RunContext[Deps]) -> str:\n    user = await ctx.deps.db.get_user(ctx.deps.user_id)\n    return f\"User name: {user.name}, Role: {user.role}\"\n\n@agent.system_prompt\ndef add_permissions(ctx: RunContext[Deps]) -> str:\n    return f\"User has permissions: {ctx.deps.permissions}\"\n```\n\n## Type Safety\n\nFull type checking with generics:\n\n```python\n# Explicit agent type annotation\nagent: Agent[Deps, OutputModel] = Agent(\n    'openai:gpt-4o',\n    deps_type=Deps,\n    output_type=OutputModel,\n)\n\n# Now these are type-checked:\n# - ctx.deps in tools is typed as Deps\n# - result.output is typed as OutputModel\n# - agent.run() requires deps: Deps\n```\n\n## No Dependencies Pattern\n\nWhen you don't need dependencies:\n\n```python\n# Option 1: No deps_type (defaults to NoneType)\nagent = Agent('openai:gpt-4o')\nresult = agent.run_sync('Hello')  # No deps needed\n\n# Option 2: Explicit None for type checker\nagent: Agent[None, str] = Agent('openai:gpt-4o')\nresult = agent.run_sync('Hello', deps=None)\n\n# In tool_plain, no context access\n@agent.tool_plain\ndef simple_calc(a: int, b: int) -> int:\n    return a + b\n```\n\n## Complete Example\n\n```python\nfrom dataclasses import dataclass\nfrom httpx import AsyncClient\nfrom pydantic import BaseModel\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass WeatherDeps:\n    client: AsyncClient\n    api_key: str\n\nclass WeatherReport(BaseModel):\n    location: str\n    temperature: float\n    conditions: str\n\nagent: Agent[WeatherDeps, WeatherReport] = Agent(\n    'openai:gpt-4o',\n    deps_type=WeatherDeps,\n    output_type=WeatherReport,\n    instructions='You are a weather assistant.',\n)\n\n@agent.tool\nasync def get_weather(\n    ctx: RunContext[WeatherDeps],\n    city: str\n) -> dict:\n    \"\"\"Fetch weather data for a city.\"\"\"\n    response = await ctx.deps.client.get(\n        f'https://api.weather.com/{city}',\n        headers={'Authorization': ctx.deps.api_key}\n    )\n    return response.json()\n\nasync def main():\n    async with AsyncClient() as client:\n        deps = WeatherDeps(client=client, api_key='secret')\n        result = await agent.run('Weather in London?', deps=deps)\n        print(result.output.temperature)\n```\n\n## Override for Testing\n\n```python\nfrom pydantic_ai.models.test import TestModel\n\n# Create mock dependencies\nmock_deps = Deps(\n    db=MockDatabase(),\n    api_client=MockClient(),\n    user_id=999\n)\n\n# Override model and deps for testing\nwith agent.override(model=TestModel(), deps=mock_deps):\n    result = agent.run_sync('Test prompt')\n```\n\n## Best Practices\n\n1. **Keep deps immutable**: Use frozen dataclasses or Pydantic models\n2. **Pass connections, not credentials**: Deps should hold initialized clients\n3. **Type your agents**: Use `Agent[DepsType, OutputType]` for full type safety\n4. **Scope deps appropriately**: Create deps at the start of a request, close after\n",
        "skills/pydantic-ai-model-integration/SKILL.md": "---\nname: pydantic-ai-model-integration\ndescription: Configure LLM providers, use fallback models, handle streaming, and manage model settings in PydanticAI. Use when selecting models, implementing resilience, or optimizing API calls.\n---\n\n# PydanticAI Model Integration\n\n## Provider Model Strings\n\nFormat: `provider:model-name`\n\n```python\nfrom pydantic_ai import Agent\n\n# OpenAI\nAgent('openai:gpt-4o')\nAgent('openai:gpt-4o-mini')\nAgent('openai:o1-preview')\n\n# Anthropic\nAgent('anthropic:claude-sonnet-4-5')\nAgent('anthropic:claude-haiku-4-5')\n\n# Google (API Key)\nAgent('google-gla:gemini-2.0-flash')\nAgent('google-gla:gemini-2.0-pro')\n\n# Google (Vertex AI)\nAgent('google-vertex:gemini-2.0-flash')\n\n# Groq\nAgent('groq:llama-3.3-70b-versatile')\nAgent('groq:mixtral-8x7b-32768')\n\n# Mistral\nAgent('mistral:mistral-large-latest')\n\n# Other providers\nAgent('cohere:command-r-plus')\nAgent('bedrock:anthropic.claude-3-sonnet')\n```\n\n## Model Settings\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.settings import ModelSettings\n\nagent = Agent(\n    'openai:gpt-4o',\n    model_settings=ModelSettings(\n        temperature=0.7,\n        max_tokens=1000,\n        top_p=0.9,\n        timeout=30.0,  # Request timeout\n    )\n)\n\n# Override per-run\nresult = await agent.run(\n    'Generate creative text',\n    model_settings=ModelSettings(temperature=1.0)\n)\n```\n\n## Fallback Models\n\nChain models for resilience:\n\n```python\nfrom pydantic_ai.models.fallback import FallbackModel\n\n# Try models in order until one succeeds\nfallback = FallbackModel(\n    'openai:gpt-4o',\n    'anthropic:claude-sonnet-4-5',\n    'google-gla:gemini-2.0-flash'\n)\n\nagent = Agent(fallback)\nresult = await agent.run('Hello')\n\n# Custom fallback conditions\nfrom pydantic_ai.exceptions import ModelAPIError\n\ndef should_fallback(error: Exception) -> bool:\n    \"\"\"Only fallback on rate limits or server errors.\"\"\"\n    if isinstance(error, ModelAPIError):\n        return error.status_code in (429, 500, 502, 503)\n    return False\n\nfallback = FallbackModel(\n    'openai:gpt-4o',\n    'anthropic:claude-sonnet-4-5',\n    fallback_on=should_fallback\n)\n```\n\n## Streaming Responses\n\n```python\nasync def stream_response():\n    async with agent.run_stream('Tell me a story') as response:\n        # Stream text output\n        async for chunk in response.stream_output():\n            print(chunk, end='', flush=True)\n\n    # Access final result after streaming\n    print(f\"\\nTokens used: {response.usage().total_tokens}\")\n```\n\n### Streaming with Structured Output\n\n```python\nfrom pydantic import BaseModel\n\nclass Story(BaseModel):\n    title: str\n    content: str\n    moral: str\n\nagent = Agent('openai:gpt-4o', output_type=Story)\n\nasync with agent.run_stream('Write a fable') as response:\n    # For structured output, stream_output yields partial JSON\n    async for partial in response.stream_output():\n        print(partial)  # Partial Story object as parsed\n\n    # Final validated result\n    story = response.output\n```\n\n## Dynamic Model Selection\n\n```python\nimport os\n\n# Environment-based selection\nmodel = os.getenv('PYDANTIC_AI_MODEL', 'openai:gpt-4o')\nagent = Agent(model)\n\n# Runtime model override\nresult = await agent.run(\n    'Hello',\n    model='anthropic:claude-sonnet-4-5'  # Override default\n)\n\n# Context manager override\nwith agent.override(model='google-gla:gemini-2.0-flash'):\n    result = agent.run_sync('Hello')\n```\n\n## Deferred Model Checking\n\nDelay model validation for testing:\n\n```python\n# Default: Validates model immediately (checks env vars)\nagent = Agent('openai:gpt-4o')\n\n# Deferred: Validates only on first run\nagent = Agent('openai:gpt-4o', defer_model_check=True)\n\n# Useful for testing with override\nwith agent.override(model=TestModel()):\n    result = agent.run_sync('Test')  # No OpenAI key needed\n```\n\n## Usage Tracking\n\n```python\nresult = await agent.run('Hello')\n\n# Request usage (last request)\nusage = result.usage()\nprint(f\"Input tokens: {usage.input_tokens}\")\nprint(f\"Output tokens: {usage.output_tokens}\")\nprint(f\"Total tokens: {usage.total_tokens}\")\n\n# Full run usage (all requests in run)\nrun_usage = result.run_usage()\nprint(f\"Total requests: {run_usage.requests}\")\n```\n\n## Usage Limits\n\n```python\nfrom pydantic_ai.usage import UsageLimits\n\n# Limit token usage\nresult = await agent.run(\n    'Generate content',\n    usage_limits=UsageLimits(\n        total_tokens=1000,\n        request_tokens=500,\n        response_tokens=500,\n    )\n)\n```\n\n## Provider-Specific Features\n\n### OpenAI\n\n```python\nfrom pydantic_ai.models.openai import OpenAIModel\n\nmodel = OpenAIModel(\n    'gpt-4o',\n    api_key='your-key',  # Or use OPENAI_API_KEY env var\n    base_url='https://custom-endpoint.com'  # For Azure, proxies\n)\n```\n\n### Anthropic\n\n```python\nfrom pydantic_ai.models.anthropic import AnthropicModel\n\nmodel = AnthropicModel(\n    'claude-sonnet-4-5',\n    api_key='your-key'  # Or ANTHROPIC_API_KEY\n)\n```\n\n## Common Model Patterns\n\n| Use Case | Recommendation |\n|----------|---------------|\n| General purpose | `openai:gpt-4o` or `anthropic:claude-sonnet-4-5` |\n| Fast/cheap | `openai:gpt-4o-mini` or `anthropic:claude-haiku-4-5` |\n| Long context | `anthropic:claude-sonnet-4-5` (200k) or `google-gla:gemini-2.0-flash` |\n| Reasoning | `openai:o1-preview` |\n| Cost-sensitive prod | `FallbackModel` with fast model first |\n",
        "skills/pydantic-ai-testing/SKILL.md": "---\nname: pydantic-ai-testing\ndescription: Test PydanticAI agents using TestModel, FunctionModel, VCR cassettes, and inline snapshots. Use when writing unit tests, mocking LLM responses, or recording API interactions.\n---\n\n# Testing PydanticAI Agents\n\n## TestModel (Deterministic Testing)\n\nUse `TestModel` for tests without API calls:\n\n```python\nimport pytest\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\n\ndef test_agent_basic():\n    agent = Agent('openai:gpt-4o')\n\n    # Override with TestModel for testing\n    result = agent.run_sync('Hello', model=TestModel())\n\n    # TestModel generates deterministic output based on output_type\n    assert isinstance(result.output, str)\n```\n\n## TestModel Configuration\n\n```python\nfrom pydantic_ai.models.test import TestModel\n\n# Custom text output\nmodel = TestModel(custom_output_text='Custom response')\nresult = agent.run_sync('Hello', model=model)\nassert result.output == 'Custom response'\n\n# Custom structured output (for output_type agents)\nfrom pydantic import BaseModel\n\nclass Response(BaseModel):\n    message: str\n    score: int\n\nagent = Agent('openai:gpt-4o', output_type=Response)\nmodel = TestModel(custom_output_args={'message': 'Test', 'score': 42})\nresult = agent.run_sync('Hello', model=model)\nassert result.output.message == 'Test'\n\n# Seed for reproducible random output\nmodel = TestModel(seed=42)\n\n# Force tool calls\nmodel = TestModel(call_tools=['my_tool', 'another_tool'])\n```\n\n## Override Context Manager\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\n\nagent = Agent('openai:gpt-4o', deps_type=MyDeps)\n\ndef test_with_override():\n    mock_deps = MyDeps(db=MockDB())\n\n    with agent.override(model=TestModel(), deps=mock_deps):\n        # All runs use TestModel and mock_deps\n        result = agent.run_sync('Hello')\n        assert result.output\n```\n\n## FunctionModel (Custom Logic)\n\nFor complete control over model responses:\n\n```python\nfrom pydantic_ai import Agent, ModelMessage, ModelResponse, TextPart\nfrom pydantic_ai.models.function import AgentInfo, FunctionModel\n\ndef custom_model(\n    messages: list[ModelMessage],\n    info: AgentInfo\n) -> ModelResponse:\n    \"\"\"Custom model that inspects messages and returns response.\"\"\"\n    # Access the last user message\n    last_msg = messages[-1]\n\n    # Return custom response\n    return ModelResponse(parts=[TextPart('Custom response')])\n\nagent = Agent(FunctionModel(custom_model))\nresult = agent.run_sync('Hello')\n```\n\n### FunctionModel with Tool Calls\n\n```python\nfrom pydantic_ai import ToolCallPart, ModelResponse\nfrom pydantic_ai.models.function import AgentInfo, FunctionModel\n\ndef model_with_tools(\n    messages: list[ModelMessage],\n    info: AgentInfo\n) -> ModelResponse:\n    # First request: call a tool\n    if len(messages) == 1:\n        return ModelResponse(parts=[\n            ToolCallPart(\n                tool_name='get_data',\n                args='{\"id\": 123}'\n            )\n        ])\n\n    # After tool response: return final result\n    return ModelResponse(parts=[TextPart('Done with tool result')])\n\nagent = Agent(FunctionModel(model_with_tools))\n\n@agent.tool_plain\ndef get_data(id: int) -> str:\n    return f\"Data for {id}\"\n\nresult = agent.run_sync('Get data')\n```\n\n## VCR Cassettes (Recorded API Calls)\n\nRecord and replay real LLM API interactions:\n\n```python\nimport pytest\n\n@pytest.mark.vcr\ndef test_with_recorded_response():\n    \"\"\"Uses recorded cassette from tests/cassettes/\"\"\"\n    agent = Agent('openai:gpt-4o')\n    result = agent.run_sync('Hello')\n    assert 'hello' in result.output.lower()\n\n# To record/update cassettes:\n# uv run pytest --record-mode=rewrite tests/test_file.py\n```\n\nCassette files are stored in `tests/cassettes/` as YAML.\n\n## Inline Snapshots\n\nAssert expected outputs with auto-updating snapshots:\n\n```python\nfrom inline_snapshot import snapshot\n\ndef test_agent_output():\n    result = agent.run_sync('Hello', model=TestModel())\n\n    # First run: creates snapshot\n    # Subsequent runs: asserts against it\n    assert result.output == snapshot('expected output here')\n\n# Update snapshots:\n# uv run pytest --inline-snapshot=fix\n```\n\n## Testing Tools\n\n```python\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.models.test import TestModel\n\ndef test_tool_is_called():\n    agent = Agent('openai:gpt-4o')\n    tool_called = False\n\n    @agent.tool_plain\n    def my_tool(x: int) -> str:\n        nonlocal tool_called\n        tool_called = True\n        return f\"Result: {x}\"\n\n    # Force TestModel to call the tool\n    result = agent.run_sync(\n        'Use my_tool',\n        model=TestModel(call_tools=['my_tool'])\n    )\n\n    assert tool_called\n```\n\n## Testing with Dependencies\n\n```python\nfrom dataclasses import dataclass\nfrom unittest.mock import AsyncMock\n\n@dataclass\nclass Deps:\n    api: ApiClient\n\ndef test_tool_with_deps():\n    # Create mock dependency\n    mock_api = AsyncMock()\n    mock_api.fetch.return_value = {'data': 'test'}\n\n    agent = Agent('openai:gpt-4o', deps_type=Deps)\n\n    @agent.tool\n    async def fetch_data(ctx: RunContext[Deps]) -> dict:\n        return await ctx.deps.api.fetch()\n\n    with agent.override(\n        model=TestModel(call_tools=['fetch_data']),\n        deps=Deps(api=mock_api)\n    ):\n        result = agent.run_sync('Fetch data')\n\n    mock_api.fetch.assert_called_once()\n```\n\n## Capture Messages\n\nInspect all messages in a run:\n\n```python\nfrom pydantic_ai import Agent, capture_run_messages\n\nagent = Agent('openai:gpt-4o')\n\nwith capture_run_messages() as messages:\n    result = agent.run_sync('Hello', model=TestModel())\n\n# Inspect captured messages\nfor msg in messages:\n    print(msg)\n```\n\n## Testing Patterns Summary\n\n| Scenario | Approach |\n|----------|----------|\n| Unit tests without API | `TestModel()` |\n| Custom model logic | `FunctionModel(func)` |\n| Recorded real responses | `@pytest.mark.vcr` |\n| Assert output structure | `inline_snapshot` |\n| Test tools are called | `TestModel(call_tools=[...])` |\n| Mock dependencies | `agent.override(deps=...)` |\n\n## pytest Configuration\n\nTypical `pyproject.toml`:\n\n```toml\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\nasyncio_mode = \"auto\"  # For async tests\n```\n\nRun tests:\n```bash\nuv run pytest tests/test_agent.py -v\nuv run pytest --inline-snapshot=fix  # Update snapshots\n```\n",
        "skills/pydantic-ai-tool-system/SKILL.md": "---\nname: pydantic-ai-tool-system\ndescription: Register and implement PydanticAI tools with proper context handling, type annotations, and docstrings. Use when adding tool capabilities to agents, implementing function calling, or creating agent actions.\n---\n\n# PydanticAI Tool System\n\n## Tool Registration\n\nTwo decorators based on whether you need context:\n\n```python\nfrom pydantic_ai import Agent, RunContext\n\nagent = Agent('openai:gpt-4o')\n\n# @agent.tool - First param MUST be RunContext\n@agent.tool\nasync def get_user_data(ctx: RunContext[MyDeps], user_id: int) -> str:\n    \"\"\"Get user data from database.\n\n    Args:\n        ctx: The run context with dependencies.\n        user_id: The user's ID.\n    \"\"\"\n    return await ctx.deps.db.get_user(user_id)\n\n# @agent.tool_plain - NO context parameter allowed\n@agent.tool_plain\ndef calculate_total(prices: list[float]) -> float:\n    \"\"\"Calculate total price.\n\n    Args:\n        prices: List of prices to sum.\n    \"\"\"\n    return sum(prices)\n```\n\n## Critical Rules\n\n1. **@agent.tool**: First parameter MUST be `RunContext[DepsType]`\n2. **@agent.tool_plain**: MUST NOT have `RunContext` parameter\n3. **Docstrings**: Required for LLM to understand tool purpose\n4. **Google-style docstrings**: Used for parameter descriptions\n\n## Docstring Formats\n\nGoogle style (default):\n```python\n@agent.tool_plain\nasync def search(query: str, limit: int = 10) -> list[str]:\n    \"\"\"Search for items.\n\n    Args:\n        query: The search query.\n        limit: Maximum results to return.\n    \"\"\"\n```\n\nSphinx style:\n```python\n@agent.tool_plain(docstring_format='sphinx')\nasync def search(query: str) -> list[str]:\n    \"\"\"Search for items.\n\n    :param query: The search query.\n    \"\"\"\n```\n\n## Tool Return Types\n\nTools can return various types:\n\n```python\n# String (direct)\n@agent.tool_plain\ndef get_info() -> str:\n    return \"Some information\"\n\n# Pydantic model (serialized to JSON)\n@agent.tool_plain\ndef get_user() -> User:\n    return User(name=\"John\", age=30)\n\n# Dict (serialized to JSON)\n@agent.tool_plain\ndef get_data() -> dict[str, Any]:\n    return {\"key\": \"value\"}\n\n# ToolReturn for custom content types\nfrom pydantic_ai import ToolReturn, ImageUrl\n\n@agent.tool_plain\ndef get_image() -> ToolReturn:\n    return ToolReturn(content=[ImageUrl(url=\"https://...\")])\n```\n\n## Accessing Context\n\nRunContext provides:\n\n```python\n@agent.tool\nasync def my_tool(ctx: RunContext[MyDeps]) -> str:\n    # Dependencies\n    db = ctx.deps.db\n    api = ctx.deps.api_client\n\n    # Model info\n    model_name = ctx.model.model_name\n\n    # Usage tracking\n    tokens_used = ctx.usage.total_tokens\n\n    # Retry info\n    attempt = ctx.retry  # Current retry attempt (0-based)\n    max_retries = ctx.max_retries\n\n    # Message history\n    messages = ctx.messages\n\n    return \"result\"\n```\n\n## Tool Prepare Functions\n\nDynamically modify tools per-request:\n\n```python\nfrom pydantic_ai.tools import ToolDefinition\n\nasync def prepare_tools(\n    ctx: RunContext[MyDeps],\n    tool_defs: list[ToolDefinition]\n) -> list[ToolDefinition]:\n    \"\"\"Filter or modify tools based on context.\"\"\"\n    if ctx.deps.user_role != 'admin':\n        # Hide admin tools from non-admins\n        return [t for t in tool_defs if not t.name.startswith('admin_')]\n    return tool_defs\n\nagent = Agent('openai:gpt-4o', prepare_tools=prepare_tools)\n```\n\n## Toolsets\n\nGroup and compose tools:\n\n```python\nfrom pydantic_ai import FunctionToolset, CombinedToolset\n\n# Create a toolset\ndb_tools = FunctionToolset()\n\n@db_tools.tool\ndef query_users(name: str) -> list[dict]:\n    \"\"\"Query users by name.\"\"\"\n    ...\n\n@db_tools.tool\ndef update_user(id: int, data: dict) -> bool:\n    \"\"\"Update user data.\"\"\"\n    ...\n\n# Use in agent\nagent = Agent('openai:gpt-4o', toolsets=[db_tools])\n\n# Combine toolsets\nall_tools = CombinedToolset([db_tools, api_tools])\n```\n\n## Common Mistakes\n\n### Wrong: Context in tool_plain\n```python\n@agent.tool_plain\nasync def bad_tool(ctx: RunContext[MyDeps]) -> str:  # ERROR!\n    ...\n```\n\n### Wrong: Missing context in tool\n```python\n@agent.tool\ndef bad_tool(user_id: int) -> str:  # ERROR!\n    ...\n```\n\n### Wrong: Context not first parameter\n```python\n@agent.tool\ndef bad_tool(user_id: int, ctx: RunContext[MyDeps]) -> str:  # ERROR!\n    ...\n```\n\n## Async vs Sync\n\nBoth work, but async is preferred for I/O:\n\n```python\n# Async (preferred for I/O operations)\n@agent.tool\nasync def fetch_data(ctx: RunContext[Deps]) -> str:\n    return await ctx.deps.client.get('/data')\n\n# Sync (fine for CPU-bound operations)\n@agent.tool_plain\ndef compute(x: int, y: int) -> int:\n    return x * y\n```\n",
        "skills/pytest-code-review/SKILL.md": "---\nname: pytest-code-review\ndescription: Reviews pytest test code for async patterns, fixtures, parametrize, and mocking. Use when reviewing test_*.py files, checking async test functions, fixture usage, or mock patterns.\n---\n\n# Pytest Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| async def test_*, AsyncMock, await patterns | [references/async-testing.md](references/async-testing.md) |\n| conftest.py, factory fixtures, scope, cleanup | [references/fixtures.md](references/fixtures.md) |\n| @pytest.mark.parametrize, DRY patterns | [references/parametrize.md](references/parametrize.md) |\n| AsyncMock tracking, patch patterns, when to mock | [references/mocking.md](references/mocking.md) |\n\n## Review Checklist\n\n- [ ] Test functions are `async def test_*` for async code under test\n- [ ] AsyncMock used for async dependencies, not Mock\n- [ ] All async mocks and coroutines are awaited\n- [ ] Fixtures in conftest.py for shared setup\n- [ ] Fixture scope appropriate (function, class, module, session)\n- [ ] Yield fixtures have proper cleanup in finally block\n- [ ] @pytest.mark.parametrize for similar test cases\n- [ ] No duplicated test logic across multiple test functions\n- [ ] Mocks track calls properly (assert_called_once_with)\n- [ ] patch() targets correct location (where used, not defined)\n- [ ] No mocking of internals that should be tested\n- [ ] Test isolation (no shared mutable state between tests)\n\n## When to Load References\n\n- Reviewing async test functions  async-testing.md\n- Reviewing fixtures or conftest.py  fixtures.md\n- Reviewing similar test cases  parametrize.md\n- Reviewing mocks and patches  mocking.md\n\n## Review Questions\n\n1. Are all async functions tested with async def test_*?\n2. Are fixtures properly scoped with appropriate cleanup?\n3. Can similar test cases be parametrized to reduce duplication?\n4. Are mocks tracking calls and used at the right locations?\n",
        "skills/pytest-code-review/references/async-testing.md": "# Async Testing\n\n## Critical Anti-Patterns\n\n### 1. Using Mock Instead of AsyncMock\n\n**Problem**: Mock returns a regular Mock object, not a coroutine. Tests pass but don't actually test async behavior.\n\n```python\n# BAD - Mock doesn't work with async\nfrom unittest.mock import Mock\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    mock_client = Mock()\n    mock_client.get.return_value = {\"data\": \"test\"}\n\n    # This won't work! mock_client.get() is not awaitable\n    result = await fetch_data(mock_client)  # TypeError!\n\n# GOOD - AsyncMock for async functions\nfrom unittest.mock import AsyncMock\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    mock_client = AsyncMock()\n    mock_client.get.return_value = {\"data\": \"test\"}\n\n    result = await fetch_data(mock_client)\n    assert result == {\"data\": \"test\"}\n```\n\n### 2. Forgetting @pytest.mark.asyncio\n\n**Problem**: Test function is not run as coroutine, async code never executes.\n\n```python\n# BAD - missing decorator\nasync def test_process_data():\n    result = await process_data()  # Never actually awaited!\n    assert result == expected\n\n# GOOD - proper async test\n@pytest.mark.asyncio\nasync def test_process_data():\n    result = await process_data()\n    assert result == expected\n```\n\n### 3. Not Awaiting Async Mocks\n\n**Problem**: Mock returns coroutine object instead of actual value.\n\n```python\n# BAD - not awaiting AsyncMock\n@pytest.mark.asyncio\nasync def test_service():\n    mock_db = AsyncMock()\n    mock_db.query.return_value = [{\"id\": 1}]\n\n    service = UserService(mock_db)\n    result = service.get_users()  # Returns coroutine, not list!\n    assert len(result) == 1  # TypeError!\n\n# GOOD - await AsyncMock\n@pytest.mark.asyncio\nasync def test_service():\n    mock_db = AsyncMock()\n    mock_db.query.return_value = [{\"id\": 1}]\n\n    service = UserService(mock_db)\n    result = await service.get_users()\n    assert len(result) == 1\n```\n\n### 4. Mixing Sync and Async in Tests\n\n**Problem**: Calling sync blocking code in async test defeats purpose.\n\n```python\n# BAD - mixing sync and async\n@pytest.mark.asyncio\nasync def test_user_flow():\n    user = create_user_sync()  # Blocking call!\n    time.sleep(1)  # Blocks event loop!\n    result = await process_user(user)\n    assert result.processed\n\n# GOOD - fully async\n@pytest.mark.asyncio\nasync def test_user_flow():\n    user = await create_user_async()\n    await asyncio.sleep(1)\n    result = await process_user(user)\n    assert result.processed\n```\n\n### 5. Not Cleaning Up Async Resources\n\n**Problem**: Background tasks, connections, or coroutines left running after test.\n\n```python\n# BAD - no cleanup\n@pytest.mark.asyncio\nasync def test_background_task():\n    task = asyncio.create_task(long_running_operation())\n    # Task still running after test ends!\n    result = await some_other_operation()\n    assert result\n\n# GOOD - proper cleanup\n@pytest.mark.asyncio\nasync def test_background_task():\n    task = asyncio.create_task(long_running_operation())\n    try:\n        result = await some_other_operation()\n        assert result\n    finally:\n        task.cancel()\n        try:\n            await task\n        except asyncio.CancelledError:\n            pass\n```\n\n### 6. Not Testing Concurrent Behavior\n\n**Problem**: Tests run sequentially, missing race conditions and timing issues.\n\n```python\n# BAD - sequential testing of concurrent code\n@pytest.mark.asyncio\nasync def test_concurrent_updates():\n    await update_counter()\n    await update_counter()\n    # Doesn't test actual concurrent access!\n    assert get_counter() == 2\n\n# GOOD - actually test concurrency\n@pytest.mark.asyncio\nasync def test_concurrent_updates():\n    results = await asyncio.gather(\n        update_counter(),\n        update_counter(),\n        update_counter()\n    )\n    # Tests actual concurrent behavior\n    assert get_counter() == 3\n```\n\n### 7. Using pytest-asyncio Without Configuration\n\n**Problem**: Tests may not run in correct mode or fail silently.\n\n```python\n# BAD - no configuration, ambiguous mode\n# test_something.py\nasync def test_feature():  # Might not run as async!\n    result = await process()\n    assert result\n\n# GOOD - explicit configuration\n# pyproject.toml or pytest.ini\n[tool.pytest.ini_options]\nasyncio_mode = \"auto\"\n\n# test_something.py\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_feature():\n    result = await process()\n    assert result\n```\n\n### 8. Not Testing Exception Paths in Async Code\n\n**Problem**: Async exceptions behave differently, need explicit testing.\n\n```python\n# BAD - not testing async exceptions\n@pytest.mark.asyncio\nasync def test_error_handling():\n    # Doesn't verify exception is properly raised\n    result = await fetch_data_with_retry()\n    assert result\n\n# GOOD - test async exception handling\n@pytest.mark.asyncio\nasync def test_error_handling():\n    mock_client = AsyncMock()\n    mock_client.get.side_effect = asyncio.TimeoutError()\n\n    with pytest.raises(asyncio.TimeoutError):\n        await fetch_data(mock_client)\n```\n\n## Review Questions\n\n1. Are all async test functions marked with `@pytest.mark.asyncio`?\n2. Are `AsyncMock` objects used instead of `Mock` for async dependencies?\n3. Are all coroutines and async mocks properly awaited?\n4. Are async resources (tasks, connections) cleaned up after tests?\n5. Do concurrent code tests actually run operations concurrently?\n6. Is pytest-asyncio configured correctly in pyproject.toml or pytest.ini?\n",
        "skills/pytest-code-review/references/fixtures.md": "# Fixtures\n\n## Critical Anti-Patterns\n\n### 1. Duplicated Setup Across Tests\n\n**Problem**: Same setup repeated in every test function instead of using fixtures.\n\n```python\n# BAD - duplicated setup\n@pytest.mark.asyncio\nasync def test_create_user():\n    db = await create_db_connection()\n    await db.setup_schema()\n    result = await create_user(db, \"Alice\")\n    await db.close()\n    assert result.name == \"Alice\"\n\n@pytest.mark.asyncio\nasync def test_delete_user():\n    db = await create_db_connection()\n    await db.setup_schema()\n    result = await delete_user(db, 1)\n    await db.close()\n    assert result.success\n\n# GOOD - fixture handles setup/teardown\n@pytest.fixture\nasync def db():\n    connection = await create_db_connection()\n    await connection.setup_schema()\n    yield connection\n    await connection.close()\n\n@pytest.mark.asyncio\nasync def test_create_user(db):\n    result = await create_user(db, \"Alice\")\n    assert result.name == \"Alice\"\n\n@pytest.mark.asyncio\nasync def test_delete_user(db):\n    result = await delete_user(db, 1)\n    assert result.success\n```\n\n### 2. Missing Cleanup in Fixtures\n\n**Problem**: Resources leak when tests fail or fixtures don't clean up.\n\n```python\n# BAD - no cleanup\n@pytest.fixture\nasync def temp_file():\n    file_path = \"/tmp/test_file.txt\"\n    async with aiofiles.open(file_path, \"w\") as f:\n        await f.write(\"test data\")\n    return file_path\n    # File never deleted!\n\n# GOOD - cleanup with yield\n@pytest.fixture\nasync def temp_file():\n    file_path = \"/tmp/test_file.txt\"\n    async with aiofiles.open(file_path, \"w\") as f:\n        await f.write(\"test data\")\n    yield file_path\n    # Cleanup always runs\n    if os.path.exists(file_path):\n        os.remove(file_path)\n```\n\n### 3. Wrong Fixture Scope\n\n**Problem**: Expensive setup repeated unnecessarily or shared state causes test coupling.\n\n```python\n# BAD - function scope for expensive operation\n@pytest.fixture(scope=\"function\")  # Runs for EVERY test!\ndef database_with_seed_data():\n    db = create_database()\n    seed_large_dataset(db)  # Takes 10 seconds!\n    return db\n\n# GOOD - module scope for expensive, read-only setup\n@pytest.fixture(scope=\"module\")\ndef database_with_seed_data():\n    db = create_database()\n    seed_large_dataset(db)\n    yield db\n    db.cleanup()\n\n# BAD - session scope for mutable state\n@pytest.fixture(scope=\"session\")\ndef user_cache():\n    return {}  # Shared across ALL tests - race conditions!\n\n# GOOD - function scope for mutable state\n@pytest.fixture(scope=\"function\")\ndef user_cache():\n    return {}  # Fresh cache per test\n```\n\n### 4. Not Using conftest.py\n\n**Problem**: Fixtures duplicated across test files.\n\n```python\n# BAD - fixture in test_users.py\n@pytest.fixture\ndef db_session():\n    session = create_session()\n    yield session\n    session.close()\n\n# BAD - same fixture duplicated in test_posts.py\n@pytest.fixture\ndef db_session():\n    session = create_session()\n    yield session\n    session.close()\n\n# GOOD - shared fixture in conftest.py\n# conftest.py\n@pytest.fixture\ndef db_session():\n    session = create_session()\n    yield session\n    session.close()\n\n# test_users.py and test_posts.py can both use db_session\n```\n\n### 5. Factory Fixtures Not Used for Variations\n\n**Problem**: Creating multiple similar fixtures instead of one factory.\n\n```python\n# BAD - separate fixture for each variation\n@pytest.fixture\ndef user_alice():\n    return User(name=\"Alice\", role=\"admin\")\n\n@pytest.fixture\ndef user_bob():\n    return User(name=\"Bob\", role=\"user\")\n\n@pytest.fixture\ndef user_charlie():\n    return User(name=\"Charlie\", role=\"guest\")\n\n# GOOD - factory fixture\n@pytest.fixture\ndef make_user():\n    def _make_user(name: str, role: str = \"user\"):\n        return User(name=name, role=role)\n    return _make_user\n\ndef test_admin_access(make_user):\n    admin = make_user(\"Alice\", role=\"admin\")\n    assert admin.can_delete()\n\ndef test_user_access(make_user):\n    user = make_user(\"Bob\")\n    assert not user.can_delete()\n```\n\n### 6. Fixture Dependencies Not Leveraged\n\n**Problem**: Manually composing dependencies instead of using fixture chaining.\n\n```python\n# BAD - manual composition\n@pytest.fixture\ndef authenticated_client():\n    app = create_app()\n    client = TestClient(app)\n    user = create_user()\n    token = generate_token(user)\n    client.headers[\"Authorization\"] = f\"Bearer {token}\"\n    return client\n\n# GOOD - fixture chaining\n@pytest.fixture\ndef app():\n    return create_app()\n\n@pytest.fixture\ndef client(app):\n    return TestClient(app)\n\n@pytest.fixture\ndef user():\n    return create_user()\n\n@pytest.fixture\ndef auth_token(user):\n    return generate_token(user)\n\n@pytest.fixture\ndef authenticated_client(client, auth_token):\n    client.headers[\"Authorization\"] = f\"Bearer {auth_token}\"\n    return client\n```\n\n### 7. Autouse Fixtures Overused\n\n**Problem**: Autouse fixtures run even when not needed, slowing tests.\n\n```python\n# BAD - autouse for specific setup\n@pytest.fixture(autouse=True)\ndef setup_database():\n    # Runs for EVERY test, even ones that don't use database\n    db = setup_test_db()\n    yield\n    db.teardown()\n\n# GOOD - explicit fixture dependency\n@pytest.fixture\ndef database():\n    db = setup_test_db()\n    yield db\n    db.teardown()\n\ndef test_with_db(database):\n    # Only runs when explicitly requested\n    assert database.is_connected()\n\ndef test_without_db():\n    # Doesn't pay database setup cost\n    assert 1 + 1 == 2\n```\n\n### 8. Async Fixtures Without Proper Cleanup\n\n**Problem**: Async cleanup not wrapped in try/finally.\n\n```python\n# BAD - no try/finally in async fixture\n@pytest.fixture\nasync def api_client():\n    client = AsyncClient(base_url=\"http://test\")\n    yield client\n    await client.close()  # Skipped if test fails!\n\n# GOOD - try/finally ensures cleanup\n@pytest.fixture\nasync def api_client():\n    client = AsyncClient(base_url=\"http://test\")\n    try:\n        yield client\n    finally:\n        await client.close()\n```\n\n### 9. Using Fixtures as Data Instead of Setup\n\n**Problem**: Fixtures return data instead of managing resources.\n\n```python\n# BAD - fixture just returns data\n@pytest.fixture\ndef sample_users():\n    return [\n        {\"name\": \"Alice\", \"role\": \"admin\"},\n        {\"name\": \"Bob\", \"role\": \"user\"}\n    ]\n\n# GOOD - use module-level constant\nSAMPLE_USERS = [\n    {\"name\": \"Alice\", \"role\": \"admin\"},\n    {\"name\": \"Bob\", \"role\": \"user\"}\n]\n\n# ACCEPTABLE - fixture when setup/teardown needed\n@pytest.fixture\nasync def sample_users(db):\n    users = await db.create_users([\n        {\"name\": \"Alice\", \"role\": \"admin\"},\n        {\"name\": \"Bob\", \"role\": \"user\"}\n    ])\n    yield users\n    await db.delete_users([u.id for u in users])\n```\n\n## Review Questions\n\n1. Are fixtures in conftest.py for cross-file reuse?\n2. Do all fixtures with resources have proper yield + cleanup?\n3. Is fixture scope appropriate (function/module/session)?\n4. Are factory fixtures used for creating test data variations?\n5. Are fixture dependencies chained instead of manually composed?\n6. Are autouse fixtures limited to truly universal setup?\n7. Do async fixtures wrap cleanup in try/finally blocks?\n",
        "skills/pytest-code-review/references/mocking.md": "# Mocking\n\n## Critical Anti-Patterns\n\n### 1. Patching Where Defined Instead of Where Used\n\n**Problem**: Mock doesn't affect the code under test because patch location is wrong.\n\n```python\n# module_a.py\ndef external_api_call():\n    return \"real data\"\n\n# module_b.py\nfrom module_a import external_api_call\n\ndef process_data():\n    return external_api_call()\n\n# BAD - patching where defined\nfrom unittest.mock import patch\n\n@patch(\"module_a.external_api_call\")  # Wrong location!\ndef test_process_data(mock_api):\n    mock_api.return_value = \"mocked data\"\n    result = process_data()\n    assert result == \"mocked data\"  # FAILS! Uses real function\n\n# GOOD - patch where used\n@patch(\"module_b.external_api_call\")  # Patch in module_b namespace\ndef test_process_data(mock_api):\n    mock_api.return_value = \"mocked data\"\n    result = process_data()\n    assert result == \"mocked data\"  # Works!\n```\n\n### 2. Not Verifying Mock Calls\n\n**Problem**: Mock used but never verified, test doesn't validate behavior.\n\n```python\n# BAD - mock not verified\n@pytest.mark.asyncio\nasync def test_user_creation(mocker):\n    mock_db = mocker.AsyncMock()\n    mock_db.insert.return_value = {\"id\": 1}\n\n    await create_user(mock_db, \"Alice\")\n    # No verification! Did it call insert? With what args?\n\n# GOOD - verify mock calls\n@pytest.mark.asyncio\nasync def test_user_creation(mocker):\n    mock_db = mocker.AsyncMock()\n    mock_db.insert.return_value = {\"id\": 1}\n\n    result = await create_user(mock_db, \"Alice\")\n\n    mock_db.insert.assert_called_once_with({\"name\": \"Alice\"})\n    assert result[\"id\"] == 1\n```\n\n### 3. Over-Mocking Internal Implementation\n\n**Problem**: Mocking internal details that should be tested, not mocked.\n\n```python\n# BAD - mocking internal helper that should be tested\nclass UserService:\n    def _validate_email(self, email):\n        return \"@\" in email\n\n    def create_user(self, email):\n        if self._validate_email(email):\n            return User(email=email)\n        raise ValueError(\"Invalid email\")\n\n@patch.object(UserService, \"_validate_email\")\ndef test_create_user(mock_validate):\n    mock_validate.return_value = True\n    service = UserService()\n    user = service.create_user(\"invalid\")  # Should fail but doesn't!\n    assert user.email == \"invalid\"\n\n# GOOD - test the actual behavior\ndef test_create_user_valid():\n    service = UserService()\n    user = service.create_user(\"valid@example.com\")\n    assert user.email == \"valid@example.com\"\n\ndef test_create_user_invalid():\n    service = UserService()\n    with pytest.raises(ValueError, match=\"Invalid email\"):\n        service.create_user(\"invalid\")\n```\n\n### 4. Using Mock Instead of AsyncMock for Async\n\n**Problem**: Regular Mock doesn't work properly with async code.\n\n```python\n# BAD - Mock for async function\nfrom unittest.mock import Mock\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    mock_client = Mock()\n    mock_client.get = Mock(return_value={\"data\": \"test\"})\n\n    result = await fetch_data(mock_client)  # TypeError: object Mock can't be used in 'await'\n\n# GOOD - AsyncMock for async functions\nfrom unittest.mock import AsyncMock\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    mock_client = AsyncMock()\n    mock_client.get.return_value = {\"data\": \"test\"}\n\n    result = await fetch_data(mock_client)\n    assert result == {\"data\": \"test\"}\n```\n\n### 5. Not Resetting Mocks Between Tests\n\n**Problem**: Mock state leaks between tests, causing flaky failures.\n\n```python\n# BAD - shared mock across tests\nmock_api = Mock()\n\ndef test_first_call():\n    mock_api.fetch.return_value = \"data1\"\n    result = process(mock_api)\n    assert result == \"data1\"\n\ndef test_second_call():\n    # Mock still has state from test_first_call!\n    mock_api.fetch.return_value = \"data2\"\n    assert mock_api.fetch.call_count == 0  # FAILS! call_count is 1\n\n# GOOD - fresh mock per test with fixture\n@pytest.fixture\ndef mock_api():\n    return Mock()\n\ndef test_first_call(mock_api):\n    mock_api.fetch.return_value = \"data1\"\n    result = process(mock_api)\n    assert result == \"data1\"\n\ndef test_second_call(mock_api):\n    mock_api.fetch.return_value = \"data2\"\n    result = process(mock_api)\n    assert mock_api.fetch.call_count == 1  # Works!\n```\n\n### 6. Not Using side_effect for Complex Behavior\n\n**Problem**: Using return_value when mock needs to raise exceptions or vary responses.\n\n```python\n# BAD - can't test retry logic with simple return_value\n@pytest.mark.asyncio\nasync def test_retry_on_failure():\n    mock_client = AsyncMock()\n    mock_client.get.return_value = {\"data\": \"test\"}  # Always succeeds!\n\n    result = await fetch_with_retry(mock_client)\n    # Can't test retry behavior!\n\n# GOOD - use side_effect for sequence of responses\n@pytest.mark.asyncio\nasync def test_retry_on_failure():\n    mock_client = AsyncMock()\n    mock_client.get.side_effect = [\n        asyncio.TimeoutError(),  # First call fails\n        asyncio.TimeoutError(),  # Second call fails\n        {\"data\": \"test\"}  # Third call succeeds\n    ]\n\n    result = await fetch_with_retry(mock_client, max_retries=3)\n    assert result == {\"data\": \"test\"}\n    assert mock_client.get.call_count == 3\n\n# GOOD - use side_effect function for dynamic behavior\ndef test_dynamic_behavior():\n    def side_effect_fn(user_id):\n        if user_id == 1:\n            return {\"name\": \"Alice\"}\n        raise ValueError(\"User not found\")\n\n    mock_db = Mock()\n    mock_db.get_user.side_effect = side_effect_fn\n\n    assert mock_db.get_user(1) == {\"name\": \"Alice\"}\n    with pytest.raises(ValueError):\n        mock_db.get_user(2)\n```\n\n### 7. Not Using spec or spec_set\n\n**Problem**: Mock accepts any attribute, allowing tests that pass but code that fails.\n\n```python\n# BAD - mock without spec\ndef test_user_service():\n    mock_db = Mock()\n    service = UserService(mock_db)\n    service.process()\n    # Typo! Should be execute(), not exectue()\n    mock_db.exectue.assert_called_once()  # Test passes! But code would fail\n\n# GOOD - use spec to catch attribute errors\ndef test_user_service():\n    mock_db = Mock(spec=Database)\n    service = UserService(mock_db)\n    service.process()\n    # AttributeError: Mock object has no attribute 'exectue'\n    mock_db.execute.assert_called_once()  # Forces correct spelling\n```\n\n### 8. Patching with Context Manager but Not Using It\n\n**Problem**: Using patch as decorator when context manager is clearer for partial mocking.\n\n```python\n# BAD - decorator for partial test mocking\n@patch(\"module.external_call\")\ndef test_process(mock_call):\n    mock_call.return_value = \"mocked\"\n    # First part of test uses mock\n    result1 = process_with_external()\n    assert result1 == \"mocked\"\n\n    # Second part wants real call, but can't!\n    result2 = process_with_external()  # Still mocked!\n\n# GOOD - context manager for scoped mocking\ndef test_process():\n    # First part uses mock\n    with patch(\"module.external_call\") as mock_call:\n        mock_call.return_value = \"mocked\"\n        result1 = process_with_external()\n        assert result1 == \"mocked\"\n\n    # Second part uses real function\n    result2 = process_with_external()\n    assert result2 != \"mocked\"\n```\n\n### 9. Not Checking Call Arguments Precisely\n\n**Problem**: Using assert_called() instead of assert_called_with().\n\n```python\n# BAD - only checks if called, not what arguments\n@pytest.mark.asyncio\nasync def test_create_user():\n    mock_db = AsyncMock()\n    await create_user(mock_db, name=\"Alice\", email=\"alice@example.com\")\n    mock_db.insert.assert_called()  # Called, but with what args?\n\n# GOOD - verify exact arguments\n@pytest.mark.asyncio\nasync def test_create_user():\n    mock_db = AsyncMock()\n    await create_user(mock_db, name=\"Alice\", email=\"alice@example.com\")\n    mock_db.insert.assert_called_once_with(\n        name=\"Alice\",\n        email=\"alice@example.com\"\n    )\n\n# ALSO GOOD - use call_args for partial matching\n@pytest.mark.asyncio\nasync def test_create_user():\n    mock_db = AsyncMock()\n    await create_user(mock_db, name=\"Alice\", email=\"alice@example.com\")\n    call_args = mock_db.insert.call_args\n    assert call_args.kwargs[\"name\"] == \"Alice\"\n    assert \"email\" in call_args.kwargs\n```\n\n### 10. Mocking Entire Objects Instead of Interfaces\n\n**Problem**: Mocking concrete class when interface would be more accurate.\n\n```python\n# BAD - mocking concrete class\nfrom unittest.mock import Mock\n\nclass PostgresDatabase:\n    def query(self, sql): ...\n    def execute(self, sql): ...\n    def internal_connection_pool(self): ...\n\ndef test_service():\n    mock_db = Mock(spec=PostgresDatabase)\n    # Test knows about PostgreSQL specifics!\n    service = UserService(mock_db)\n\n# GOOD - mock interface/protocol\nfrom typing import Protocol\n\nclass Database(Protocol):\n    async def query(self, sql: str) -> list: ...\n    async def execute(self, sql: str) -> None: ...\n\n@pytest.fixture\ndef mock_db():\n    mock = AsyncMock(spec=Database)\n    return mock\n\ndef test_service(mock_db):\n    # Test only depends on interface\n    service = UserService(mock_db)\n```\n\n### 11. Not Using pytest-mock Plugin\n\n**Problem**: Using unittest.mock directly when pytest-mock provides better integration.\n\n```python\n# BAD - manual patch cleanup\nfrom unittest.mock import patch\n\ndef test_feature():\n    patcher = patch(\"module.function\")\n    mock_fn = patcher.start()\n    mock_fn.return_value = \"test\"\n\n    result = use_function()\n\n    patcher.stop()  # Easy to forget!\n    assert result == \"test\"\n\n# GOOD - using pytest-mock mocker fixture\ndef test_feature(mocker):\n    mock_fn = mocker.patch(\"module.function\")\n    mock_fn.return_value = \"test\"\n\n    result = use_function()\n    # Automatic cleanup!\n    assert result == \"test\"\n```\n\n## Review Questions\n\n1. Are patches applied where the function is used, not where it's defined?\n2. Are mock calls verified with assert_called_once_with() or similar?\n3. Are internal implementation details tested rather than mocked?\n4. Is AsyncMock used for all async functions and methods?\n5. Are mocks fresh for each test (via fixtures or setUp)?\n6. Is side_effect used for exceptions or varying responses?\n7. Do mocks use spec or spec_set to catch attribute errors?\n8. Are call arguments verified precisely, not just call presence?\n9. Is pytest-mock used instead of raw unittest.mock?\n",
        "skills/pytest-code-review/references/parametrize.md": "# Parametrize\n\n## Critical Anti-Patterns\n\n### 1. Duplicated Test Functions for Similar Cases\n\n**Problem**: Copy-pasted test functions that differ only in input values.\n\n```python\n# BAD - duplicated test logic\n@pytest.mark.asyncio\nasync def test_validate_email_valid():\n    result = validate_email(\"user@example.com\")\n    assert result.is_valid is True\n\n@pytest.mark.asyncio\nasync def test_validate_email_valid_subdomain():\n    result = validate_email(\"user@mail.example.com\")\n    assert result.is_valid is True\n\n@pytest.mark.asyncio\nasync def test_validate_email_invalid_no_at():\n    result = validate_email(\"userexample.com\")\n    assert result.is_valid is False\n\n@pytest.mark.asyncio\nasync def test_validate_email_invalid_no_domain():\n    result = validate_email(\"user@\")\n    assert result.is_valid is False\n\n# GOOD - parametrized test\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\"email,expected\", [\n    (\"user@example.com\", True),\n    (\"user@mail.example.com\", True),\n    (\"userexample.com\", False),\n    (\"user@\", False),\n])\nasync def test_validate_email(email, expected):\n    result = validate_email(email)\n    assert result.is_valid is expected\n```\n\n### 2. Unclear Parametrize Names\n\n**Problem**: Using generic names like \"input\" and \"output\" instead of descriptive names.\n\n```python\n# BAD - unclear parameter names\n@pytest.mark.parametrize(\"input,output\", [\n    (10, 100),\n    (5, 25),\n    (0, 0),\n])\ndef test_calculation(input, output):\n    assert calculate(input) == output\n\n# GOOD - descriptive parameter names\n@pytest.mark.parametrize(\"radius,expected_area\", [\n    (10, 314.159),\n    (5, 78.539),\n    (0, 0),\n])\ndef test_circle_area(radius, expected_area):\n    assert calculate_area(radius) == pytest.approx(expected_area, rel=1e-3)\n```\n\n### 3. Not Using pytest.param for IDs\n\n**Problem**: Test output shows cryptic parameter values instead of meaningful descriptions.\n\n```python\n# BAD - unclear test IDs in output\n@pytest.mark.parametrize(\"user_role,can_access\", [\n    (\"admin\", True),\n    (\"user\", False),\n    (\"guest\", False),\n])\ndef test_access_control(user_role, can_access):\n    assert check_access(user_role) == can_access\n# Output: test_access_control[admin-True], test_access_control[user-False]\n\n# GOOD - descriptive test IDs\n@pytest.mark.parametrize(\"user_role,can_access\", [\n    pytest.param(\"admin\", True, id=\"admin_has_access\"),\n    pytest.param(\"user\", False, id=\"user_denied\"),\n    pytest.param(\"guest\", False, id=\"guest_denied\"),\n])\ndef test_access_control(user_role, can_access):\n    assert check_access(user_role) == can_access\n# Output: test_access_control[admin_has_access], test_access_control[user_denied]\n```\n\n### 4. Not Combining Multiple Parametrize Decorators\n\n**Problem**: Creating cartesian product manually instead of stacking decorators.\n\n```python\n# BAD - manual combinations\n@pytest.mark.parametrize(\"method,status,role\", [\n    (\"GET\", 200, \"admin\"),\n    (\"GET\", 200, \"user\"),\n    (\"POST\", 200, \"admin\"),\n    (\"POST\", 403, \"user\"),\n    (\"DELETE\", 200, \"admin\"),\n    (\"DELETE\", 403, \"user\"),\n])\ndef test_api_access(method, status, role):\n    assert api_call(method, role).status_code == status\n\n# GOOD - stacked parametrize for cartesian product\n@pytest.mark.parametrize(\"method\", [\"GET\", \"POST\", \"DELETE\"])\n@pytest.mark.parametrize(\"role,expected_statuses\", [\n    (\"admin\", {\"GET\": 200, \"POST\": 200, \"DELETE\": 200}),\n    (\"user\", {\"GET\": 200, \"POST\": 403, \"DELETE\": 403}),\n])\ndef test_api_access(method, role, expected_statuses):\n    assert api_call(method, role).status_code == expected_statuses[method]\n\n# ALTERNATIVE - if all admins succeed and users fail writes\n@pytest.mark.parametrize(\"method\", [\"GET\", \"POST\", \"DELETE\"])\n@pytest.mark.parametrize(\"role,can_write\", [\n    (\"admin\", True),\n    (\"user\", False),\n])\ndef test_api_access(method, role, can_write):\n    response = api_call(method, role)\n    if method in [\"POST\", \"DELETE\"] and not can_write:\n        assert response.status_code == 403\n    else:\n        assert response.status_code == 200\n```\n\n### 5. Parametrizing Fixtures Instead of Tests\n\n**Problem**: Complex parametrized fixtures when parametrized tests would be clearer.\n\n```python\n# BAD - parametrized fixture is hard to read\n@pytest.fixture(params=[\n    {\"name\": \"Alice\", \"role\": \"admin\", \"can_delete\": True},\n    {\"name\": \"Bob\", \"role\": \"user\", \"can_delete\": False},\n])\ndef user(request):\n    return User(**request.param)\n\ndef test_user_permissions(user):\n    assert user.can_delete() == user.expected_can_delete\n\n# GOOD - parametrize the test\n@pytest.fixture\ndef make_user():\n    def _make(name: str, role: str):\n        return User(name=name, role=role)\n    return _make\n\n@pytest.mark.parametrize(\"name,role,can_delete\", [\n    (\"Alice\", \"admin\", True),\n    (\"Bob\", \"user\", False),\n])\ndef test_user_permissions(make_user, name, role, can_delete):\n    user = make_user(name, role)\n    assert user.can_delete() == can_delete\n```\n\n### 6. Not Marking Expected Failures\n\n**Problem**: Including known failing cases without marking them.\n\n```python\n# BAD - test fails on known edge case\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"valid\", True),\n    (\"also_valid\", True),\n    (\"edge_case\", True),  # This actually fails but is being worked on\n])\ndef test_validator(input, expected):\n    assert validate(input) == expected\n\n# GOOD - mark expected failures\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"valid\", True),\n    (\"also_valid\", True),\n    pytest.param(\"edge_case\", True, marks=pytest.mark.xfail(reason=\"Issue #123\")),\n])\ndef test_validator(input, expected):\n    assert validate(input) == expected\n```\n\n### 7. Large Parametrize Tables in Test File\n\n**Problem**: Test file cluttered with large data tables.\n\n```python\n# BAD - 100 lines of test data inline\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"case1\", \"result1\"),\n    (\"case2\", \"result2\"),\n    # ... 100 more lines ...\n])\ndef test_parser(input, expected):\n    assert parse(input) == expected\n\n# GOOD - externalize large datasets\n# test_data/parser_cases.json\n[\n    {\"input\": \"case1\", \"expected\": \"result1\"},\n    {\"input\": \"case2\", \"expected\": \"result2\"}\n]\n\n# test_parser.py\nimport json\nfrom pathlib import Path\n\ndef load_test_cases():\n    path = Path(__file__).parent / \"test_data\" / \"parser_cases.json\"\n    with open(path) as f:\n        cases = json.load(f)\n    return [(c[\"input\"], c[\"expected\"]) for c in cases]\n\n@pytest.mark.parametrize(\"input,expected\", load_test_cases())\ndef test_parser(input, expected):\n    assert parse(input) == expected\n```\n\n### 8. Not Using Indirect Parametrization\n\n**Problem**: Creating expensive test data for every parameter combination.\n\n```python\n# BAD - creating full database for each test\n@pytest.mark.parametrize(\"user_id,expected_name\", [\n    (1, \"Alice\"),\n    (2, \"Bob\"),\n    (3, \"Charlie\"),\n])\nasync def test_get_user(user_id, expected_name):\n    db = await create_full_database()  # Expensive! Runs 3 times!\n    user = await db.get_user(user_id)\n    assert user.name == expected_name\n\n# GOOD - indirect parametrization with fixture\n@pytest.fixture\nasync def db_with_users():\n    db = await create_full_database()\n    yield db\n    await db.cleanup()\n\n@pytest.mark.parametrize(\"user_id,expected_name\", [\n    (1, \"Alice\"),\n    (2, \"Bob\"),\n    (3, \"Charlie\"),\n])\nasync def test_get_user(db_with_users, user_id, expected_name):\n    user = await db_with_users.get_user(user_id)\n    assert user.name == expected_name\n\n# EVEN BETTER - indirect parametrization\n@pytest.fixture\nasync def user(request, db):\n    user_id = request.param\n    return await db.get_user(user_id)\n\n@pytest.mark.parametrize(\"user,expected_name\", [\n    (1, \"Alice\"),\n    (2, \"Bob\"),\n    (3, \"Charlie\"),\n], indirect=[\"user\"])\nasync def test_user_name(user, expected_name):\n    assert user.name == expected_name\n```\n\n### 9. Testing Multiple Assertions Instead of Separating\n\n**Problem**: Multiple unrelated assertions in one parametrized test.\n\n```python\n# BAD - multiple unrelated assertions\n@pytest.mark.parametrize(\"user_data\", [\n    {\"name\": \"Alice\", \"age\": 30, \"role\": \"admin\"},\n    {\"name\": \"Bob\", \"age\": 25, \"role\": \"user\"},\n])\ndef test_user(user_data):\n    user = User(**user_data)\n    assert user.name == user_data[\"name\"]\n    assert user.age == user_data[\"age\"]\n    assert user.role == user_data[\"role\"]\n    assert user.is_valid()  # Unrelated to data validation\n    assert len(user.name) > 0  # Different concern\n\n# GOOD - separate tests for different concerns\n@pytest.mark.parametrize(\"name,age,role\", [\n    (\"Alice\", 30, \"admin\"),\n    (\"Bob\", 25, \"user\"),\n])\ndef test_user_creation(name, age, role):\n    user = User(name=name, age=age, role=role)\n    assert user.name == name\n    assert user.age == age\n    assert user.role == role\n\n@pytest.mark.parametrize(\"name\", [\"Alice\", \"Bob\", \"\"])\ndef test_user_name_validation(name):\n    if name:\n        user = User(name=name, age=30, role=\"user\")\n        assert user.is_valid()\n    else:\n        with pytest.raises(ValueError):\n            User(name=name, age=30, role=\"user\")\n```\n\n## Review Questions\n\n1. Can duplicated test functions be combined with parametrize?\n2. Do parametrized tests use descriptive parameter names?\n3. Are test IDs meaningful using pytest.param(id=\"...\")?\n4. Should multiple parametrize decorators be stacked for combinations?\n5. Are large test datasets externalized to separate files?\n6. Is indirect parametrization used for expensive fixture setup?\n",
        "skills/python-code-review/SKILL.md": "---\nname: python-code-review\ndescription: Reviews Python code for type safety, async patterns, error handling, and common mistakes. Use when reviewing .py files, checking type hints, async/await usage, or exception handling.\n---\n\n# Python Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Indentation, line length, whitespace, naming | [references/pep8-style.md](references/pep8-style.md) |\n| Missing/wrong type hints, Any usage | [references/type-safety.md](references/type-safety.md) |\n| Blocking calls in async, missing await | [references/async-patterns.md](references/async-patterns.md) |\n| Bare except, missing context, logging | [references/error-handling.md](references/error-handling.md) |\n| Mutable defaults, print statements | [references/common-mistakes.md](references/common-mistakes.md) |\n\n## Review Checklist\n\n### PEP8 Style\n- [ ] 4-space indentation (no tabs)\n- [ ] Line length 79 characters (72 for docstrings/comments)\n- [ ] Two blank lines around top-level definitions, one within classes\n- [ ] Imports grouped: stdlib  third-party  local (blank line between groups)\n- [ ] No whitespace inside brackets or before colons/commas\n- [ ] Naming: `snake_case` for functions/variables, `CamelCase` for classes, `UPPER_CASE` for constants\n- [ ] Inline comments separated by at least two spaces\n\n### Type Safety\n- [ ] Type hints on all function parameters and return types\n- [ ] No `Any` unless necessary (with comment explaining why)\n- [ ] Proper `T | None` syntax (Python 3.10+)\n\n### Async Patterns\n- [ ] No blocking calls (`time.sleep`, `requests`) in async functions\n- [ ] Proper `await` on all coroutines\n\n### Error Handling\n- [ ] No bare `except:` clauses\n- [ ] Specific exception types with context\n- [ ] `raise ... from` to preserve stack traces\n\n### Common Mistakes\n- [ ] No mutable default arguments\n- [ ] Using `logger` not `print()` for output\n- [ ] f-strings preferred over `.format()` or `%`\n\n## Valid Patterns (Do NOT Flag)\n\nThese patterns are intentional and correct - do not report as issues:\n\n- **Type annotation vs type assertion** - Annotations declare types but are not runtime assertions; don't confuse with missing validation\n- **Using `Any` when interacting with untyped libraries** - Required when external libraries lack type stubs\n- **Empty `__init__.py` files** - Valid for package structure, no code required\n- **`noqa` comments** - Valid when linter rule doesn't apply to specific case\n- **Using `cast()` after runtime type check** - Correct pattern to inform type checker of narrowed type\n\n## Context-Sensitive Rules\n\nOnly flag these issues when the specific conditions apply:\n\n| Issue | Flag ONLY IF |\n|-------|--------------|\n| Generic exception handling | Specific exception types are available and meaningful |\n| Unused variables | Variable lacks `_` prefix AND isn't used in f-strings, logging, or debugging |\n\n## When to Load References\n\n- Reviewing code formatting/style  pep8-style.md\n- Reviewing function signatures  type-safety.md\n- Reviewing `async def` functions  async-patterns.md\n- Reviewing try/except blocks  error-handling.md\n- General Python review  common-mistakes.md\n\n## Review Questions\n\n1. Does the code follow PEP8 formatting (indentation, line length, whitespace)?\n2. Are imports properly grouped (stdlib  third-party  local)?\n3. Do names follow conventions (snake_case, CamelCase, UPPER_CASE)?\n4. Are all function signatures fully typed?\n5. Are async functions truly non-blocking?\n6. Do exceptions include meaningful context?\n7. Are there any mutable default arguments?\n\n## Before Submitting Findings\n\nLoad and follow [review-verification-protocol](../review-verification-protocol/SKILL.md) before reporting any issue.\n",
        "skills/python-code-review/references/async-patterns.md": "# Async Patterns\n\n## Critical Anti-Patterns\n\n### 1. Blocking Calls in Async Functions\n\n**Problem**: Blocks the event loop, defeats async benefits.\n\n```python\n# BAD - blocks event loop\nasync def fetch_data():\n    response = requests.get(url)  # BLOCKING!\n    time.sleep(1)  # BLOCKING!\n    return response.json()\n\n# GOOD - non-blocking\nasync def fetch_data():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n    await asyncio.sleep(1)\n    return response.json()\n```\n\n### 2. Missing await on Coroutines\n\n**Problem**: Coroutine never executes.\n\n```python\n# BAD - coroutine created but never awaited\nasync def process():\n    fetch_data()  # Returns coroutine, doesn't execute!\n\n# GOOD\nasync def process():\n    await fetch_data()\n```\n\n### 3. Sequential Instead of Concurrent\n\n**Problem**: Misses parallelization opportunity.\n\n```python\n# BAD - sequential (slow)\nasync def get_all():\n    user = await get_user()\n    posts = await get_posts()\n    comments = await get_comments()\n    return user, posts, comments\n\n# GOOD - concurrent (fast)\nasync def get_all():\n    user, posts, comments = await asyncio.gather(\n        get_user(),\n        get_posts(),\n        get_comments()\n    )\n    return user, posts, comments\n```\n\n### 4. Missing async with for Async Context Managers\n\n**Problem**: Resource not properly managed.\n\n```python\n# BAD\nasync def query():\n    session = aiosqlite.connect(db)  # Not entered!\n    return await session.execute(sql)\n\n# GOOD\nasync def query():\n    async with aiosqlite.connect(db) as session:\n        return await session.execute(sql)\n```\n\n### 5. Sync File I/O in Async Context\n\n**Problem**: File operations block event loop.\n\n```python\n# BAD - blocks event loop\nasync def read_config():\n    with open(\"config.json\") as f:\n        return json.load(f)\n\n# GOOD - use aiofiles\nimport aiofiles\n\nasync def read_config():\n    async with aiofiles.open(\"config.json\") as f:\n        content = await f.read()\n        return json.loads(content)\n\n# ACCEPTABLE - for small files, run in executor\nasync def read_config():\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(None, load_config_sync)\n```\n\n## Review Questions\n\n1. Are there any `requests`, `time.sleep`, or `open()` calls in async functions?\n2. Is every coroutine call awaited?\n3. Are independent async calls parallelized with `gather()`?\n4. Are async context managers used with `async with`?\n",
        "skills/python-code-review/references/common-mistakes.md": "# Common Mistakes\n\n## Critical Anti-Patterns\n\n### 1. Mutable Default Arguments\n\n**Problem**: Default value is shared across all calls.\n\n```python\n# BAD - same list reused!\ndef add_item(item, items=[]):\n    items.append(item)\n    return items\n\nadd_item(\"a\")  # [\"a\"]\nadd_item(\"b\")  # [\"a\", \"b\"] - unexpected!\n\n# GOOD\ndef add_item(item, items=None):\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\n# BETTER - using dataclass\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass Container:\n    items: list = field(default_factory=list)\n```\n\n### 2. Using print() for Logging\n\n**Problem**: No log levels, no timestamps, hard to filter.\n\n```python\n# BAD\nprint(f\"Processing {item}\")\nprint(f\"Error: {e}\")\n\n# GOOD\nfrom loguru import logger\n\nlogger.info(f\"Processing {item}\")\nlogger.error(f\"Error: {e}\")\n```\n\n### 3. String Formatting Inconsistency\n\n**Problem**: Mixing formats reduces readability.\n\n```python\n# BAD - mixed formats\nmsg = \"Hello %s\" % name\nmsg = \"Hello {}\".format(name)\nmsg = f\"Hello {name}\"\n\n# GOOD - f-strings consistently\nmsg = f\"Hello {name}\"\ntotal = f\"Count: {count:,}\"  # with formatting\npath = f\"{base}/{sub}/{file}\"\n```\n\n### 4. Unused Variables\n\n**Problem**: Dead code, confusing to readers.\n\n```python\n# BAD\nresult = process()  # never used\n\n# GOOD - use underscore for intentionally ignored\n_, second, _ = get_triple()\n\n# Or just don't assign\nprocess()  # if result not needed\n```\n\n### 5. Import Order\n\n**Problem**: Hard to scan, may cause issues.\n\n```python\n# BAD - random order\nfrom myapp.utils import helper\nimport os\nfrom typing import Optional\nimport sys\nfrom myapp.models import User\n\n# GOOD - standard order\nimport os\nimport sys\nfrom typing import Optional\n\nfrom myapp.models import User\nfrom myapp.utils import helper\n```\n\n### 6. Magic Numbers\n\n**Problem**: Unclear intent, hard to maintain.\n\n```python\n# BAD\nif len(items) > 100:\n    paginate()\ntime.sleep(3600)\n\n# GOOD\nMAX_PAGE_SIZE = 100\nCACHE_TTL_SECONDS = 3600\n\nif len(items) > MAX_PAGE_SIZE:\n    paginate()\ntime.sleep(CACHE_TTL_SECONDS)\n```\n\n### 7. Nested Conditionals\n\n**Problem**: Hard to read and maintain.\n\n```python\n# BAD\ndef process(user):\n    if user:\n        if user.active:\n            if user.verified:\n                return do_work(user)\n    return None\n\n# GOOD - early returns\ndef process(user):\n    if not user:\n        return None\n    if not user.active:\n        return None\n    if not user.verified:\n        return None\n    return do_work(user)\n```\n\n## Review Questions\n\n1. Are there any mutable default arguments (list, dict, set)?\n2. Is `print()` used instead of `logger`?\n3. Are f-strings used consistently?\n4. Are there magic numbers that should be constants?\n5. Are deeply nested conditionals flattened with early returns?\n",
        "skills/python-code-review/references/error-handling.md": "# Error Handling\n\n## Critical Anti-Patterns\n\n### 1. Bare Except Clause\n\n**Problem**: Catches everything including KeyboardInterrupt, SystemExit.\n\n```python\n# BAD\ntry:\n    process()\nexcept:\n    pass\n\n# GOOD - specific exception\ntry:\n    process()\nexcept ValueError as e:\n    logger.error(f\"Invalid value: {e}\")\n    raise\n\n# ACCEPTABLE - if you must catch all\ntry:\n    process()\nexcept Exception as e:  # Still allows KeyboardInterrupt\n    logger.error(f\"Unexpected error: {e}\")\n    raise\n```\n\n### 2. Swallowing Exceptions\n\n**Problem**: Hides errors, makes debugging impossible.\n\n```python\n# BAD\ntry:\n    result = risky_operation()\nexcept Exception:\n    pass  # Error silently ignored!\n\n# GOOD - log and handle\ntry:\n    result = risky_operation()\nexcept OperationError as e:\n    logger.warning(f\"Operation failed: {e}\")\n    result = default_value\n```\n\n### 3. Losing Exception Context\n\n**Problem**: Original stack trace lost.\n\n```python\n# BAD - loses original traceback\ntry:\n    parse_config()\nexcept ValueError:\n    raise ConfigError(\"Invalid config\")\n\n# GOOD - preserves chain\ntry:\n    parse_config()\nexcept ValueError as e:\n    raise ConfigError(\"Invalid config\") from e\n```\n\n### 4. Missing Context in Error Messages\n\n**Problem**: Can't diagnose issue from logs.\n\n```python\n# BAD\nexcept KeyError:\n    raise ValueError(\"Missing key\")\n\n# GOOD - include context\nexcept KeyError as e:\n    raise ValueError(f\"Missing required key: {e.args[0]}\") from e\n```\n\n### 5. Not Logging Before Re-raising\n\n**Problem**: Exception might be caught elsewhere without logging.\n\n```python\n# BAD - no record if caught upstream\ntry:\n    process(item)\nexcept ProcessError:\n    raise\n\n# GOOD - log before re-raising\ntry:\n    process(item)\nexcept ProcessError as e:\n    logger.error(f\"Failed to process item {item.id}: {e}\")\n    raise\n```\n\n## Logging Best Practices\n\n```python\nfrom loguru import logger\n\n# BAD\nprint(f\"Processing {item}\")\nprint(f\"Error: {e}\")\n\n# GOOD\nlogger.debug(f\"Processing item {item.id}\")\nlogger.info(f\"Completed batch of {count} items\")\nlogger.warning(f\"Retry {attempt}/3 for {operation}\")\nlogger.error(f\"Failed to process {item.id}: {e}\")\n\n# With exception info\nlogger.exception(f\"Unexpected error processing {item.id}\")\n```\n\n## Review Questions\n\n1. Are there any bare `except:` clauses?\n2. Is exception context preserved with `raise ... from e`?\n3. Do error messages include enough context to diagnose?\n4. Is logging used instead of print statements?\n",
        "skills/python-code-review/references/pep8-style.md": "# PEP8 Style Guide\n\n## Indentation\n\n**Rule**: Use 4 spaces per indentation level. Never use tabs.\n\n```python\n# BAD - 2 spaces\ndef foo():\n  return bar\n\n# BAD - tabs (shown with  for visibility)\ndef foo():\n   return bar  #  actual code would have tab here\n\n# GOOD - 4 spaces\ndef foo():\n    return bar\n```\n\n### Continuation Lines\n\n```python\n# GOOD - aligned with opening delimiter\nresult = function_name(arg_one, arg_two,\n                       arg_three, arg_four)\n\n# GOOD - hanging indent\nresult = function_name(\n    arg_one, arg_two,\n    arg_three, arg_four,\n)\n\n# BAD - no alignment\nresult = function_name(arg_one, arg_two,\n    arg_three, arg_four)\n```\n\n## Line Length\n\n**Rule**: Maximum 79 characters for code, 72 for docstrings/comments.\n\n```python\n# BAD - too long\nresult = some_function(argument_one, argument_two, argument_three, argument_four, argument_five)\n\n# GOOD - broken across lines\nresult = some_function(\n    argument_one,\n    argument_two,\n    argument_three,\n    argument_four,\n    argument_five,\n)\n```\n\n## Blank Lines\n\n**Rule**: Two blank lines around top-level definitions, one blank line around methods.\n\n```python\n# GOOD\nimport os\n\n\nclass MyClass:\n    \"\"\"Docstring.\"\"\"\n\n    def method_one(self):\n        pass\n\n    def method_two(self):\n        pass\n\n\ndef top_level_function():\n    pass\n\n\ndef another_function():\n    pass\n```\n\n## Imports\n\n**Rule**: Group imports in order: stdlib  third-party  local. One blank line between groups.\n\n```python\n# GOOD\nimport os\nimport sys\nfrom pathlib import Path\n\nimport requests\nfrom pydantic import BaseModel\n\nfrom myapp.models import User\nfrom myapp.utils import helper\n```\n\n**Rule**: Avoid wildcard imports.\n\n```python\n# BAD\nfrom module import *\n\n# GOOD\nfrom module import specific_function, SpecificClass\n```\n\n## Whitespace\n\n### Inside Brackets\n\n```python\n# BAD\nspam( ham[ 1 ], { eggs: 2 } )\n\n# GOOD\nspam(ham[1], {eggs: 2})\n```\n\n### Before Colons and Commas\n\n```python\n# BAD\nif x == 4 :\n    print(x , y)\n\n# GOOD\nif x == 4:\n    print(x, y)\n```\n\n### Around Operators\n\n```python\n# BAD\nx=1\ny = x+1\nz = x +1\n\n# GOOD\nx = 1\ny = x + 1\n\n# Exception: indicate precedence\nresult = x*2 + y*3\n```\n\n### Function Arguments\n\n```python\n# BAD\ndef function(arg1 = None, arg2 = 0):\n    pass\n\n# GOOD\ndef function(arg1=None, arg2=0):\n    pass\n```\n\n## Naming Conventions\n\n| Type | Convention | Example |\n|------|------------|---------|\n| Functions/variables | `snake_case` | `my_function`, `user_count` |\n| Classes | `CamelCase` | `MyClass`, `HttpClient` |\n| Constants | `UPPER_CASE` | `MAX_SIZE`, `DEFAULT_TIMEOUT` |\n| Private | Leading underscore | `_internal_method` |\n| \"Protected\" | Double underscore | `__name_mangled` |\n\n```python\n# BAD\ndef MyFunction():  # should be snake_case\n    pass\n\nclass my_class:  # should be CamelCase\n    maxSize = 100  # should be MAX_SIZE if constant\n\n# GOOD\ndef my_function():\n    pass\n\nclass MyClass:\n    MAX_SIZE = 100\n```\n\n## Comments\n\n### Inline Comments\n\n**Rule**: Separate by at least two spaces. Use sparingly.\n\n```python\n# BAD\nx = x + 1# increment\n\n# GOOD\nx = x + 1  # compensate for border\n```\n\n### Block Comments\n\n```python\n# GOOD - aligned with code, complete sentences\n# This is a block comment explaining the\n# following code section. Each sentence\n# ends with a period.\nresult = complex_operation()\n```\n\n### Docstrings\n\n```python\n# GOOD\ndef fetch_users(limit: int = 100) -> list[User]:\n    \"\"\"Fetch users from the database.\n\n    Args:\n        limit: Maximum number of users to return.\n\n    Returns:\n        List of User objects.\n\n    Raises:\n        DatabaseError: If connection fails.\n    \"\"\"\n    pass\n```\n\n## Review Questions\n\n1. Is indentation consistently 4 spaces (no tabs)?\n2. Are lines 79 characters (72 for docstrings)?\n3. Are there two blank lines around top-level definitions?\n4. Are imports grouped correctly with blank lines between groups?\n5. Is there extraneous whitespace inside brackets or around operators?\n6. Do names follow conventions (snake_case, CamelCase, UPPER_CASE)?\n7. Are inline comments separated by at least two spaces?\n",
        "skills/python-code-review/references/type-safety.md": "# Type Safety\n\n## Critical Anti-Patterns\n\n### 1. Missing Return Type\n\n**Problem**: Callers don't know what to expect.\n\n```python\n# BAD\ndef get_user(id: int):\n    return User.query.get(id)\n\n# GOOD\ndef get_user(id: int) -> User | None:\n    return User.query.get(id)\n```\n\n### 2. Using Any Without Justification\n\n**Problem**: Defeats the purpose of type checking.\n\n```python\n# BAD\ndef process(data: Any) -> Any:\n    return data\n\n# GOOD - with justification\ndef process(data: Any) -> dict:  # Any: accepts JSON from external API\n    return json.loads(data)\n\n# BETTER - use proper types\ndef process(data: str | bytes) -> dict:\n    return json.loads(data)\n```\n\n### 3. Optional vs Union Syntax\n\n**Problem**: Inconsistent syntax, less readable.\n\n```python\n# OLD (pre-3.10)\nfrom typing import Optional, Union\ndef find(id: int) -> Optional[User]: ...\ndef parse(val: Union[str, int]) -> str: ...\n\n# GOOD (3.10+)\ndef find(id: int) -> User | None: ...\ndef parse(val: str | int) -> str: ...\n```\n\n### 4. Missing Generic Types\n\n**Problem**: Loses type information in collections.\n\n```python\n# BAD\ndef get_items() -> list:\n    return [Item(...)]\n\n# GOOD\ndef get_items() -> list[Item]:\n    return [Item(...)]\n\n# BAD\ndef get_config() -> dict:\n    return {\"key\": \"value\"}\n\n# GOOD\ndef get_config() -> dict[str, str]:\n    return {\"key\": \"value\"}\n```\n\n### 5. TypedDict for Structured Dicts\n\n**Problem**: Plain dict loses key/value type information.\n\n```python\n# BAD\ndef get_user_data() -> dict:\n    return {\"name\": \"Alice\", \"age\": 30}\n\n# GOOD\nfrom typing import TypedDict\n\nclass UserData(TypedDict):\n    name: str\n    age: int\n\ndef get_user_data() -> UserData:\n    return {\"name\": \"Alice\", \"age\": 30}\n```\n\n## Review Questions\n\n1. Are all function parameters typed?\n2. Are all return types specified?\n3. Is `Any` used only when necessary with a comment?\n4. Are collection types generic (`list[T]`, `dict[K, V]`)?\n5. Is `T | None` used instead of `Optional[T]`?\n",
        "skills/react-flow-advanced/SKILL.md": "---\nname: react-flow-advanced\ndescription: Advanced React Flow patterns for complex use cases. Use when implementing sub-flows, custom connection lines, programmatic layouts, drag-and-drop, undo/redo, or complex state synchronization.\n---\n\n# Advanced React Flow Patterns\n\n## Sub-Flows (Nested Nodes)\n\n```tsx\nconst nodes = [\n  // Parent (group) node\n  {\n    id: 'group-1',\n    type: 'group',\n    position: { x: 0, y: 0 },\n    style: { width: 400, height: 300, padding: 10 },\n    data: { label: 'Group' },\n  },\n  // Child nodes\n  {\n    id: 'child-1',\n    parentId: 'group-1',        // Reference parent\n    extent: 'parent',           // Constrain to parent bounds\n    expandParent: true,         // Auto-expand parent if dragged to edge\n    position: { x: 20, y: 50 }, // Relative to parent\n    data: { label: 'Child 1' },\n  },\n  {\n    id: 'child-2',\n    parentId: 'group-1',\n    extent: 'parent',\n    position: { x: 200, y: 50 },\n    data: { label: 'Child 2' },\n  },\n];\n```\n\n### Group Node Component\n\n```tsx\nfunction GroupNode({ data, id }: NodeProps) {\n  return (\n    <div className=\"group-node\">\n      <div className=\"group-header\">{data.label}</div>\n      {/* Children are rendered automatically by React Flow */}\n    </div>\n  );\n}\n```\n\n## Custom Connection Line\n\n```tsx\nimport { ConnectionLineComponentProps, getSmoothStepPath } from '@xyflow/react';\n\nfunction CustomConnectionLine({\n  fromX, fromY, fromPosition,\n  toX, toY, toPosition,\n  connectionStatus,\n}: ConnectionLineComponentProps) {\n  const [path] = getSmoothStepPath({\n    sourceX: fromX,\n    sourceY: fromY,\n    sourcePosition: fromPosition,\n    targetX: toX,\n    targetY: toY,\n    targetPosition: toPosition,\n  });\n\n  return (\n    <g>\n      <path\n        d={path}\n        fill=\"none\"\n        stroke={connectionStatus === 'valid' ? '#22c55e' : '#ef4444'}\n        strokeWidth={2}\n        strokeDasharray=\"5 5\"\n      />\n    </g>\n  );\n}\n\n<ReactFlow connectionLineComponent={CustomConnectionLine} />\n```\n\n## Drag and Drop from External Source\n\n```tsx\nimport { useReactFlow, useCallback, useRef } from 'react';\n\nfunction DnDFlow() {\n  const reactFlowWrapper = useRef(null);\n  const { screenToFlowPosition, addNodes } = useReactFlow();\n  const [reactFlowInstance, setReactFlowInstance] = useState(null);\n\n  const onDragOver = useCallback((event: DragEvent) => {\n    event.preventDefault();\n    event.dataTransfer.dropEffect = 'move';\n  }, []);\n\n  const onDrop = useCallback((event: DragEvent) => {\n    event.preventDefault();\n\n    const type = event.dataTransfer.getData('application/reactflow');\n    if (!type) return;\n\n    // Convert screen position to flow position\n    const position = screenToFlowPosition({\n      x: event.clientX,\n      y: event.clientY,\n    });\n\n    const newNode = {\n      id: `${Date.now()}`,\n      type,\n      position,\n      data: { label: `${type} node` },\n    };\n\n    addNodes(newNode);\n  }, [screenToFlowPosition, addNodes]);\n\n  return (\n    <div ref={reactFlowWrapper} style={{ height: '100%' }}>\n      <ReactFlow\n        onDragOver={onDragOver}\n        onDrop={onDrop}\n        onInit={setReactFlowInstance}\n      />\n    </div>\n  );\n}\n\n// Sidebar component\nfunction Sidebar() {\n  const onDragStart = (event: DragEvent, nodeType: string) => {\n    event.dataTransfer.setData('application/reactflow', nodeType);\n    event.dataTransfer.effectAllowed = 'move';\n  };\n\n  return (\n    <aside>\n      <div draggable onDragStart={(e) => onDragStart(e, 'input')}>\n        Input Node\n      </div>\n      <div draggable onDragStart={(e) => onDragStart(e, 'default')}>\n        Default Node\n      </div>\n    </aside>\n  );\n}\n```\n\n## Undo/Redo\n\n```tsx\nimport { useCallback, useState } from 'react';\n\nfunction useUndoRedo<T>(initialState: T) {\n  const [history, setHistory] = useState<T[]>([initialState]);\n  const [index, setIndex] = useState(0);\n\n  const state = history[index];\n\n  const setState = useCallback((newState: T | ((prev: T) => T)) => {\n    setHistory((prev) => {\n      const resolved = typeof newState === 'function'\n        ? (newState as (prev: T) => T)(prev[index])\n        : newState;\n\n      // Remove future states and add new state\n      const newHistory = prev.slice(0, index + 1);\n      return [...newHistory, resolved];\n    });\n    setIndex((i) => i + 1);\n  }, [index]);\n\n  const undo = useCallback(() => {\n    setIndex((i) => Math.max(0, i - 1));\n  }, []);\n\n  const redo = useCallback(() => {\n    setIndex((i) => Math.min(history.length - 1, i + 1));\n  }, [history.length]);\n\n  const canUndo = index > 0;\n  const canRedo = index < history.length - 1;\n\n  return { state, setState, undo, redo, canUndo, canRedo };\n}\n\n// Usage\nfunction Flow() {\n  const {\n    state: { nodes, edges },\n    setState,\n    undo, redo, canUndo, canRedo\n  } = useUndoRedo({ nodes: initialNodes, edges: initialEdges });\n\n  // Capture state on significant changes\n  const onNodesChange = useCallback((changes) => {\n    const hasPositionChange = changes.some(c => c.type === 'position' && !c.dragging);\n    if (hasPositionChange) {\n      setState(prev => ({\n        nodes: applyNodeChanges(changes, prev.nodes),\n        edges: prev.edges,\n      }));\n    }\n  }, [setState]);\n}\n```\n\n## Programmatic Layout with dagre\n\n```tsx\nimport dagre from 'dagre';\n\ninterface LayoutOptions {\n  direction: 'TB' | 'BT' | 'LR' | 'RL';\n  nodeWidth: number;\n  nodeHeight: number;\n}\n\nfunction getLayoutedElements(\n  nodes: Node[],\n  edges: Edge[],\n  options: LayoutOptions = { direction: 'TB', nodeWidth: 172, nodeHeight: 36 }\n) {\n  const g = new dagre.graphlib.Graph();\n  g.setGraph({ rankdir: options.direction });\n  g.setDefaultEdgeLabel(() => ({}));\n\n  nodes.forEach((node) => {\n    g.setNode(node.id, {\n      width: node.measured?.width ?? options.nodeWidth,\n      height: node.measured?.height ?? options.nodeHeight,\n    });\n  });\n\n  edges.forEach((edge) => {\n    g.setEdge(edge.source, edge.target);\n  });\n\n  dagre.layout(g);\n\n  const layoutedNodes = nodes.map((node) => {\n    const nodeWithPosition = g.node(node.id);\n    return {\n      ...node,\n      position: {\n        x: nodeWithPosition.x - (node.measured?.width ?? options.nodeWidth) / 2,\n        y: nodeWithPosition.y - (node.measured?.height ?? options.nodeHeight) / 2,\n      },\n    };\n  });\n\n  return { nodes: layoutedNodes, edges };\n}\n\n// Usage after nodes are measured\nfunction Flow() {\n  const { fitView } = useReactFlow();\n\n  const onLayout = useCallback((direction: 'TB' | 'LR') => {\n    const { nodes: layoutedNodes, edges: layoutedEdges } = getLayoutedElements(\n      nodes,\n      edges,\n      { direction, nodeWidth: 150, nodeHeight: 50 }\n    );\n\n    setNodes([...layoutedNodes]);\n    setEdges([...layoutedEdges]);\n\n    window.requestAnimationFrame(() => {\n      fitView({ duration: 500 });\n    });\n  }, [nodes, edges, setNodes, setEdges, fitView]);\n}\n```\n\n## Connection with Edge on Drop\n\n```tsx\nfunction Flow() {\n  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);\n  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);\n  const { screenToFlowPosition } = useReactFlow();\n\n  const onConnectEnd = useCallback(\n    (event: MouseEvent | TouchEvent, connectionState: FinalConnectionState) => {\n      // Only proceed if dropped on pane (not on a node)\n      if (!connectionState.isValid && connectionState.fromHandle) {\n        const id = `${Date.now()}`;\n        const { clientX, clientY } = 'changedTouches' in event\n          ? event.changedTouches[0]\n          : event;\n\n        const newNode = {\n          id,\n          position: screenToFlowPosition({ x: clientX, y: clientY }),\n          data: { label: 'New Node' },\n        };\n\n        setNodes((nds) => [...nds, newNode]);\n        setEdges((eds) => [\n          ...eds,\n          {\n            id: `e-${connectionState.fromNode?.id}-${id}`,\n            source: connectionState.fromNode?.id ?? '',\n            target: id,\n          },\n        ]);\n      }\n    },\n    [screenToFlowPosition, setNodes, setEdges]\n  );\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodesChange={onNodesChange}\n      onEdgesChange={onEdgesChange}\n      onConnectEnd={onConnectEnd}\n    />\n  );\n}\n```\n\n## Accessing Node Data from Edges\n\n```tsx\nimport { useNodesData, type EdgeProps } from '@xyflow/react';\n\nfunction DataEdge({ source, target, ...props }: EdgeProps) {\n  // Get data for source and target nodes\n  const nodesData = useNodesData([source, target]);\n  const sourceData = nodesData[0];\n  const targetData = nodesData[1];\n\n  const [path, labelX, labelY] = getSmoothStepPath(props);\n\n  return (\n    <>\n      <BaseEdge path={path} />\n      <EdgeLabelRenderer>\n        <div style={{ transform: `translate(-50%, -50%) translate(${labelX}px, ${labelY}px)` }}>\n          {sourceData?.data?.label}  {targetData?.data?.label}\n        </div>\n      </EdgeLabelRenderer>\n    </>\n  );\n}\n```\n\n## Middleware for Node Changes\n\n```tsx\n// Filter or modify changes before they're applied\nconst onNodesChangeMiddleware = useCallback((changes: NodeChange[]) => {\n  // Example: Prevent deletion of certain nodes\n  const filteredChanges = changes.filter((change) => {\n    if (change.type === 'remove') {\n      const node = nodes.find((n) => n.id === change.id);\n      return node?.data?.deletable !== false;\n    }\n    return true;\n  });\n\n  setNodes((nds) => applyNodeChanges(filteredChanges, nds));\n}, [nodes, setNodes]);\n```\n\n## Keyboard Shortcuts\n\n```tsx\nimport { useKeyPress } from '@xyflow/react';\n\nfunction Flow() {\n  const { deleteElements, getNodes, getEdges, fitView } = useReactFlow();\n\n  // Ctrl/Cmd + A: Select all\n  const selectAllPressed = useKeyPress(['Meta+a', 'Control+a']);\n\n  useEffect(() => {\n    if (selectAllPressed) {\n      setNodes((nds) => nds.map((n) => ({ ...n, selected: true })));\n      setEdges((eds) => eds.map((e) => ({ ...e, selected: true })));\n    }\n  }, [selectAllPressed]);\n\n  // Custom delete handler\n  const deletePressed = useKeyPress(['Backspace', 'Delete']);\n\n  useEffect(() => {\n    if (deletePressed) {\n      const selectedNodes = getNodes().filter((n) => n.selected);\n      const selectedEdges = getEdges().filter((e) => e.selected);\n      deleteElements({ nodes: selectedNodes, edges: selectedEdges });\n    }\n  }, [deletePressed]);\n}\n```\n\n## Performance: Memoizing Selectors\n\n```tsx\nimport { useCallback } from 'react';\nimport { useStore, type ReactFlowState } from '@xyflow/react';\nimport { shallow } from 'zustand/shallow';\n\n// Create stable selector outside component\nconst nodesSelector = (state: ReactFlowState) => state.nodes;\n\n// Or use multiple values with shallow compare\nconst flowStateSelector = (state: ReactFlowState) => ({\n  nodes: state.nodes,\n  edges: state.edges,\n  viewport: state.transform,\n});\n\nfunction FlowInfo() {\n  const { nodes, edges, viewport } = useStore(flowStateSelector, shallow);\n  return <div>Nodes: {nodes.length}, Edges: {edges.length}</div>;\n}\n```\n",
        "skills/react-flow-architecture/SKILL.md": "---\nname: react-flow-architecture\ndescription: Architectural guidance for building node-based UIs with React Flow. Use when designing flow-based applications, making decisions about state management, integration patterns, or evaluating whether React Flow fits a use case.\n---\n\n# React Flow Architecture\n\n## When to Use React Flow\n\n### Good Fit\n\n- Visual programming interfaces\n- Workflow builders and automation tools\n- Diagram editors (flowcharts, org charts)\n- Data pipeline visualization\n- Mind mapping tools\n- Node-based audio/video editors\n- Decision tree builders\n- State machine designers\n\n### Consider Alternatives\n\n- Simple static diagrams (use SVG or canvas directly)\n- Heavy real-time collaboration (may need custom sync layer)\n- 3D visualizations (use Three.js, react-three-fiber)\n- Graph analysis with 10k+ nodes (use WebGL-based solutions like Sigma.js)\n\n## Architecture Patterns\n\n### Package Structure (xyflow)\n\n```\n@xyflow/system (vanilla TypeScript)\n Core algorithms (edge paths, bounds, viewport)\n xypanzoom (d3-based pan/zoom)\n xydrag, xyhandle, xyminimap, xyresizer\n Shared types\n\n@xyflow/react (depends on @xyflow/system)\n React components and hooks\n Zustand store for state management\n Framework-specific integrations\n\n@xyflow/svelte (depends on @xyflow/system)\n Svelte components and stores\n```\n\n**Implication**: Core logic is framework-agnostic. When contributing or debugging, check if issue is in @xyflow/system or framework-specific package.\n\n### State Management Approaches\n\n#### 1. Local State (Simple Apps)\n\n```tsx\n// useNodesState/useEdgesState for prototyping\nconst [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);\nconst [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);\n```\n\n**Pros**: Simple, minimal boilerplate\n**Cons**: State isolated to component tree\n\n#### 2. External Store (Production)\n\n```tsx\n// Zustand store example\nimport { create } from 'zustand';\n\ninterface FlowStore {\n  nodes: Node[];\n  edges: Edge[];\n  setNodes: (nodes: Node[]) => void;\n  onNodesChange: OnNodesChange;\n}\n\nconst useFlowStore = create<FlowStore>((set, get) => ({\n  nodes: initialNodes,\n  edges: initialEdges,\n  setNodes: (nodes) => set({ nodes }),\n  onNodesChange: (changes) => {\n    set({ nodes: applyNodeChanges(changes, get().nodes) });\n  },\n}));\n\n// In component\nfunction Flow() {\n  const { nodes, edges, onNodesChange } = useFlowStore();\n  return <ReactFlow nodes={nodes} onNodesChange={onNodesChange} />;\n}\n```\n\n**Pros**: State accessible anywhere, easier persistence/sync\n**Cons**: More setup, need careful selector optimization\n\n#### 3. Redux/Other State Libraries\n\n```tsx\n// Connect via selectors\nconst nodes = useSelector(selectNodes);\nconst dispatch = useDispatch();\n\nconst onNodesChange = useCallback((changes: NodeChange[]) => {\n  dispatch(nodesChanged(changes));\n}, [dispatch]);\n```\n\n### Data Flow Architecture\n\n```\nUser Input  Change Event  Reducer/Handler  State Update  Re-render\n     \n[Drag node]  onNodesChange  applyNodeChanges  setNodes  ReactFlow\n     \n[Connect]    onConnect  addEdge  setEdges  ReactFlow\n     \n[Delete]     onNodesDelete  deleteElements  setNodes/setEdges  ReactFlow\n```\n\n### Sub-Flow Pattern (Nested Nodes)\n\n```tsx\n// Parent node containing child nodes\nconst nodes = [\n  {\n    id: 'group-1',\n    type: 'group',\n    position: { x: 0, y: 0 },\n    style: { width: 300, height: 200 },\n  },\n  {\n    id: 'child-1',\n    parentId: 'group-1',  // Key: parent reference\n    extent: 'parent',      // Key: constrain to parent\n    position: { x: 10, y: 30 },  // Relative to parent\n    data: { label: 'Child' },\n  },\n];\n```\n\n**Considerations**:\n- Use `extent: 'parent'` to constrain dragging\n- Use `expandParent: true` to auto-expand parent\n- Parent z-index affects child rendering order\n\n### Viewport Persistence\n\n```tsx\n// Save viewport state\nconst { toObject, setViewport } = useReactFlow();\n\nconst handleSave = () => {\n  const flow = toObject();\n  // flow.nodes, flow.edges, flow.viewport\n  localStorage.setItem('flow', JSON.stringify(flow));\n};\n\nconst handleRestore = () => {\n  const flow = JSON.parse(localStorage.getItem('flow'));\n  setNodes(flow.nodes);\n  setEdges(flow.edges);\n  setViewport(flow.viewport);\n};\n```\n\n## Integration Patterns\n\n### With Backend/API\n\n```tsx\n// Load from API\nuseEffect(() => {\n  fetch('/api/flow')\n    .then(r => r.json())\n    .then(({ nodes, edges }) => {\n      setNodes(nodes);\n      setEdges(edges);\n    });\n}, []);\n\n// Debounced auto-save\nconst debouncedSave = useMemo(\n  () => debounce((nodes, edges) => {\n    fetch('/api/flow', {\n      method: 'POST',\n      body: JSON.stringify({ nodes, edges }),\n    });\n  }, 1000),\n  []\n);\n\nuseEffect(() => {\n  debouncedSave(nodes, edges);\n}, [nodes, edges]);\n```\n\n### With Layout Algorithms\n\n```tsx\nimport dagre from 'dagre';\n\nfunction getLayoutedElements(nodes: Node[], edges: Edge[]) {\n  const g = new dagre.graphlib.Graph();\n  g.setGraph({ rankdir: 'TB' });\n  g.setDefaultEdgeLabel(() => ({}));\n\n  nodes.forEach((node) => {\n    g.setNode(node.id, { width: 150, height: 50 });\n  });\n\n  edges.forEach((edge) => {\n    g.setEdge(edge.source, edge.target);\n  });\n\n  dagre.layout(g);\n\n  return {\n    nodes: nodes.map((node) => {\n      const pos = g.node(node.id);\n      return { ...node, position: { x: pos.x, y: pos.y } };\n    }),\n    edges,\n  };\n}\n```\n\n## Performance Scaling\n\n### Node Count Guidelines\n\n| Nodes | Strategy |\n|-------|----------|\n| < 100 | Default settings |\n| 100-500 | Enable `onlyRenderVisibleElements` |\n| 500-1000 | Simplify custom nodes, reduce DOM elements |\n| > 1000 | Consider virtualization, WebGL alternatives |\n\n### Optimization Techniques\n\n```tsx\n<ReactFlow\n  // Only render nodes/edges in viewport\n  onlyRenderVisibleElements={true}\n\n  // Reduce node border radius (improves intersect calculations)\n  nodeExtent={[[-1000, -1000], [1000, 1000]]}\n\n  // Disable features not needed\n  elementsSelectable={false}\n  panOnDrag={false}\n  zoomOnScroll={false}\n/>\n```\n\n## Trade-offs\n\n### Controlled vs Uncontrolled\n\n| Controlled | Uncontrolled |\n|------------|--------------|\n| More boilerplate | Less code |\n| Full state control | Internal state |\n| Easy persistence | Need `toObject()` |\n| Better for complex apps | Good for prototypes |\n\n### Connection Modes\n\n| Strict (default) | Loose |\n|------------------|-------|\n| Source  Target only | Any handle  any handle |\n| Predictable behavior | More flexible |\n| Use for data flows | Use for diagrams |\n\n```tsx\n<ReactFlow connectionMode={ConnectionMode.Loose} />\n```\n\n### Edge Rendering\n\n| Default edges | Custom edges |\n|---------------|--------------|\n| Fast rendering | More control |\n| Limited styling | Any SVG/HTML |\n| Simple use cases | Complex labels |\n",
        "skills/react-flow-code-review/SKILL.md": "---\nname: react-flow-code-review\ndescription: Reviews React Flow code for anti-patterns, performance issues, and best practices. Use when reviewing code that uses @xyflow/react, checking for common mistakes, or optimizing node-based UI implementations.\n---\n\n# React Flow Code Review\n\n## Critical Anti-Patterns\n\n### 1. Defining nodeTypes/edgeTypes Inside Components\n\n**Problem**: Causes all nodes to re-mount on every render.\n\n```tsx\n// BAD - recreates object every render\nfunction Flow() {\n  const nodeTypes = { custom: CustomNode };  // WRONG\n  return <ReactFlow nodeTypes={nodeTypes} />;\n}\n\n// GOOD - defined outside component\nconst nodeTypes = { custom: CustomNode };\nfunction Flow() {\n  return <ReactFlow nodeTypes={nodeTypes} />;\n}\n\n// GOOD - useMemo if dynamic\nfunction Flow() {\n  const nodeTypes = useMemo(() => ({ custom: CustomNode }), []);\n  return <ReactFlow nodeTypes={nodeTypes} />;\n}\n```\n\n### 2. Missing memo() on Custom Nodes/Edges\n\n**Problem**: Custom components re-render on every parent update.\n\n```tsx\n// BAD - no memoization\nfunction CustomNode({ data }: NodeProps) {\n  return <div>{data.label}</div>;\n}\n\n// GOOD - wrapped in memo\nimport { memo } from 'react';\nconst CustomNode = memo(function CustomNode({ data }: NodeProps) {\n  return <div>{data.label}</div>;\n});\n```\n\n### 3. Inline Callbacks Without useCallback\n\n**Problem**: Creates new function references, breaking memoization.\n\n```tsx\n// BAD - inline callback\n<ReactFlow\n  onNodesChange={(changes) => setNodes(applyNodeChanges(changes, nodes))}\n/>\n\n// GOOD - memoized callback\nconst onNodesChange = useCallback(\n  (changes) => setNodes((nds) => applyNodeChanges(changes, nds)),\n  []\n);\n<ReactFlow onNodesChange={onNodesChange} />\n```\n\n### 4. Using useReactFlow Outside Provider\n\n```tsx\n// BAD - will throw error\nfunction App() {\n  const { getNodes } = useReactFlow();  // ERROR: No provider\n  return <ReactFlow ... />;\n}\n\n// GOOD - wrap in provider\nfunction FlowContent() {\n  const { getNodes } = useReactFlow();  // Works\n  return <ReactFlow ... />;\n}\n\nfunction App() {\n  return (\n    <ReactFlowProvider>\n      <FlowContent />\n    </ReactFlowProvider>\n  );\n}\n```\n\n### 5. Storing Complex Objects in Node Data\n\n**Problem**: Reference equality checks fail, causing unnecessary updates.\n\n```tsx\n// BAD - new object reference every time\nsetNodes(nodes.map(n => ({\n  ...n,\n  data: { ...n.data, config: { nested: 'value' } }  // New object each time\n})));\n\n// GOOD - use updateNodeData for targeted updates\nconst { updateNodeData } = useReactFlow();\nupdateNodeData(nodeId, { config: { nested: 'value' } });\n```\n\n## Performance Checklist\n\n### Node Rendering\n\n- [ ] Custom nodes wrapped in `memo()`\n- [ ] nodeTypes defined outside component or memoized\n- [ ] Heavy computations inside nodes use `useMemo`\n- [ ] Event handlers use `useCallback`\n\n### Edge Rendering\n\n- [ ] Custom edges wrapped in `memo()`\n- [ ] edgeTypes defined outside component or memoized\n- [ ] Edge path calculations are not duplicated\n\n### State Updates\n\n- [ ] Using functional form of setState: `setNodes((nds) => ...)`\n- [ ] Not spreading entire state for single property updates\n- [ ] Using `updateNodeData` for data-only changes\n- [ ] Batch updates when adding multiple nodes/edges\n\n### Viewport\n\n- [ ] Not calling `fitView()` on every render\n- [ ] Using `fitViewOptions` for initial fit only\n- [ ] Animation durations are reasonable (< 500ms)\n\n## Common Mistakes\n\n### Missing Container Height\n\n```tsx\n// BAD - no height, flow won't render\n<ReactFlow nodes={nodes} edges={edges} />\n\n// GOOD - explicit dimensions\n<div style={{ width: '100%', height: '100vh' }}>\n  <ReactFlow nodes={nodes} edges={edges} />\n</div>\n```\n\n### Missing CSS Import\n\n```tsx\n// Required for default styles\nimport '@xyflow/react/dist/style.css';\n```\n\n### Forgetting nodrag on Interactive Elements\n\n```tsx\n// BAD - clicking button drags node\n<button onClick={handleClick}>Click</button>\n\n// GOOD - prevents drag\n<button className=\"nodrag\" onClick={handleClick}>Click</button>\n```\n\n### Not Using Position Constants\n\n```tsx\n// BAD - string literals\n<Handle type=\"source\" position=\"right\" />\n\n// GOOD - type-safe constants\nimport { Position } from '@xyflow/react';\n<Handle type=\"source\" position={Position.Right} />\n```\n\n### Mutating Nodes/Edges Directly\n\n```tsx\n// BAD - direct mutation\nnodes[0].position = { x: 100, y: 100 };\nsetNodes(nodes);\n\n// GOOD - immutable update\nsetNodes(nodes.map(n =>\n  n.id === '1' ? { ...n, position: { x: 100, y: 100 } } : n\n));\n```\n\n## TypeScript Issues\n\n### Missing Generic Types\n\n```tsx\n// BAD - loses type safety\nconst [nodes, setNodes] = useNodesState(initialNodes);\n\n// GOOD - explicit types\ntype MyNode = Node<{ value: number }, 'custom'>;\nconst [nodes, setNodes] = useNodesState<MyNode>(initialNodes);\n```\n\n### Wrong Props Type\n\n```tsx\n// BAD - using wrong type\nfunction CustomNode(props: any) { ... }\n\n// GOOD - correct props type\nfunction CustomNode(props: NodeProps<MyNode>) { ... }\n```\n\n## Review Questions\n\n1. Are all custom components memoized?\n2. Are nodeTypes/edgeTypes defined outside render?\n3. Are callbacks wrapped in useCallback?\n4. Is the container sized properly?\n5. Are styles imported?\n6. Is useReactFlow used inside a provider?\n7. Are interactive elements marked with nodrag?\n8. Are types used consistently throughout?\n",
        "skills/react-flow-implementation/ADDITIONAL_COMPONENTS.md": "# React Flow Additional Components\n\n## MiniMap\n\n```tsx\nimport { MiniMap } from '@xyflow/react';\n\n<MiniMap\n  nodeColor={(node) => {\n    switch (node.type) {\n      case 'input': return '#6ede87';\n      case 'output': return '#ff0072';\n      default: return '#eee';\n    }\n  }}\n  nodeStrokeWidth={3}\n  zoomable\n  pannable\n/>\n```\n\n## Controls\n\n```tsx\nimport { Controls } from '@xyflow/react';\n\n<Controls\n  showZoom={true}\n  showFitView={true}\n  showInteractive={true}\n  position=\"bottom-left\"\n/>\n```\n\n## Background\n\n```tsx\nimport { Background, BackgroundVariant } from '@xyflow/react';\n\n// Dots pattern\n<Background variant={BackgroundVariant.Dots} gap={16} size={1} />\n\n// Lines pattern\n<Background variant={BackgroundVariant.Lines} gap={24} />\n\n// Cross pattern\n<Background variant={BackgroundVariant.Cross} />\n\n// Custom color\n<Background bgColor=\"#1a1a1a\" color=\"#444\" />\n```\n\n## NodeToolbar\n\n```tsx\nimport { NodeToolbar, Position } from '@xyflow/react';\n\nfunction CustomNode({ id, selected }: NodeProps) {\n  return (\n    <>\n      <NodeToolbar\n        isVisible={selected}\n        position={Position.Top}\n      >\n        <button onClick={() => console.log('delete', id)}>Delete</button>\n        <button>Edit</button>\n      </NodeToolbar>\n      <div>Node Content</div>\n    </>\n  );\n}\n```\n\n## NodeResizer\n\n```tsx\nimport { NodeResizer } from '@xyflow/react';\n\nfunction ResizableNode({ selected }: NodeProps) {\n  return (\n    <>\n      <NodeResizer\n        isVisible={selected}\n        minWidth={100}\n        minHeight={50}\n        handleStyle={{ width: 8, height: 8 }}\n      />\n      <div style={{ padding: 10 }}>\n        Resize me\n      </div>\n    </>\n  );\n}\n```\n\n## EdgeToolbar (for custom edges)\n\n```tsx\nimport { EdgeToolbar } from '@xyflow/react';\n\nfunction CustomEdge({ id, selected, ...props }: EdgeProps) {\n  const [path, labelX, labelY] = getSmoothStepPath(props);\n\n  return (\n    <>\n      <BaseEdge path={path} />\n      <EdgeToolbar x={labelX} y={labelY} isVisible={selected}>\n        <button>Edit</button>\n      </EdgeToolbar>\n    </>\n  );\n}\n```\n\n## Panel\n\n```tsx\nimport { Panel } from '@xyflow/react';\n\n// Positions: top-left, top-center, top-right, bottom-left, bottom-center, bottom-right\n<ReactFlow ...>\n  <Panel position=\"top-right\">\n    <button onClick={onSave}>Save</button>\n    <button onClick={onRestore}>Restore</button>\n  </Panel>\n</ReactFlow>\n```\n",
        "skills/react-flow-implementation/EDGE_PATHS.md": "# Edge Path Utilities\n\nReact Flow provides utilities for generating SVG paths for custom edges.\n\n## Available Path Functions\n\n### getBezierPath (Default)\n```tsx\nimport { getBezierPath, Position } from '@xyflow/react';\n\nconst [path, labelX, labelY, offsetX, offsetY] = getBezierPath({\n  sourceX: 0,\n  sourceY: 0,\n  sourcePosition: Position.Right,\n  targetX: 200,\n  targetY: 100,\n  targetPosition: Position.Left,\n  curvature: 0.25,  // optional, default 0.25\n});\n```\n\n### getSmoothStepPath\n```tsx\nimport { getSmoothStepPath } from '@xyflow/react';\n\nconst [path, labelX, labelY] = getSmoothStepPath({\n  sourceX, sourceY, sourcePosition,\n  targetX, targetY, targetPosition,\n  borderRadius: 5,      // Corner rounding\n  offset: 20,           // Distance from handle before first bend\n  stepPosition: 0.5,    // 0-1, where bend occurs (0=source, 1=target)\n});\n```\n\n### getStraightPath\n```tsx\nimport { getStraightPath } from '@xyflow/react';\n\nconst [path, labelX, labelY] = getStraightPath({\n  sourceX, sourceY,\n  targetX, targetY,\n});\n```\n\n### getSimpleBezierPath\n```tsx\nimport { getSimpleBezierPath } from '@xyflow/react';\n\nconst [path, labelX, labelY] = getSimpleBezierPath({\n  sourceX, sourceY, sourcePosition,\n  targetX, targetY, targetPosition,\n});\n```\n\n## Custom Edge Example\n\n```tsx\nimport { BaseEdge, EdgeProps, getSmoothStepPath, EdgeLabelRenderer } from '@xyflow/react';\n\nfunction CustomEdge({\n  id, sourceX, sourceY, targetX, targetY,\n  sourcePosition, targetPosition, data, style\n}: EdgeProps) {\n  const [edgePath, labelX, labelY] = getSmoothStepPath({\n    sourceX, sourceY, sourcePosition,\n    targetX, targetY, targetPosition,\n  });\n\n  return (\n    <>\n      <BaseEdge id={id} path={edgePath} style={style} />\n      <EdgeLabelRenderer>\n        <div\n          style={{\n            position: 'absolute',\n            transform: `translate(-50%, -50%) translate(${labelX}px,${labelY}px)`,\n            pointerEvents: 'all',\n          }}\n          className=\"nodrag nopan\"\n        >\n          <button onClick={() => console.log('edge clicked', id)}>\n            {data?.label}\n          </button>\n        </div>\n      </EdgeLabelRenderer>\n    </>\n  );\n}\n```\n\n## Edge Markers\n\n```tsx\n// Built-in markers\nconst edge = {\n  id: 'e1-2',\n  source: '1',\n  target: '2',\n  markerEnd: MarkerType.ArrowClosed,\n  // or custom:\n  markerEnd: {\n    type: MarkerType.Arrow,\n    color: '#f00',\n    width: 20,\n    height: 20,\n  },\n};\n```\n",
        "skills/react-flow-implementation/SKILL.md": "---\nname: react-flow-implementation\ndescription: Implements React Flow node-based UIs correctly using @xyflow/react. Use when building flow charts, diagrams, visual editors, or node-based applications with React. Covers nodes, edges, handles, custom components, state management, and viewport control.\n---\n\n# React Flow Implementation\n\n## Quick Start\n\n```tsx\nimport { ReactFlow, useNodesState, useEdgesState, addEdge } from '@xyflow/react';\nimport '@xyflow/react/dist/style.css';\n\nconst initialNodes = [\n  { id: '1', position: { x: 0, y: 0 }, data: { label: 'Node 1' } },\n  { id: '2', position: { x: 200, y: 100 }, data: { label: 'Node 2' } },\n];\n\nconst initialEdges = [{ id: 'e1-2', source: '1', target: '2' }];\n\nexport default function Flow() {\n  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);\n  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);\n\n  const onConnect = useCallback(\n    (connection) => setEdges((eds) => addEdge(connection, eds)),\n    [setEdges]\n  );\n\n  return (\n    <div style={{ width: '100%', height: '100vh' }}>\n      <ReactFlow\n        nodes={nodes}\n        edges={edges}\n        onNodesChange={onNodesChange}\n        onEdgesChange={onEdgesChange}\n        onConnect={onConnect}\n        fitView\n      />\n    </div>\n  );\n}\n```\n\n## Core Patterns\n\n### TypeScript Types\n\n```typescript\nimport type { Node, Edge, NodeProps, BuiltInNode } from '@xyflow/react';\n\n// Define custom node type with data shape\ntype CustomNode = Node<{ value: number; label: string }, 'custom'>;\n\n// Combine with built-in nodes\ntype MyNode = CustomNode | BuiltInNode;\ntype MyEdge = Edge<{ weight?: number }>;\n\n// Use throughout app\nconst [nodes, setNodes] = useNodesState<MyNode>(initialNodes);\n```\n\n### Custom Nodes\n\n```tsx\nimport { memo } from 'react';\nimport { Handle, Position, type NodeProps } from '@xyflow/react';\n\n// Define node type\ntype CounterNode = Node<{ count: number }, 'counter'>;\n\n// Always wrap in memo for performance\nconst CounterNode = memo(function CounterNode({ data, isConnectable }: NodeProps<CounterNode>) {\n  return (\n    <>\n      <Handle type=\"target\" position={Position.Top} isConnectable={isConnectable} />\n      <div className=\"counter-node\">\n        Count: {data.count}\n        {/* nodrag prevents dragging when interacting with button */}\n        <button className=\"nodrag\" onClick={() => console.log('clicked')}>\n          Increment\n        </button>\n      </div>\n      <Handle type=\"source\" position={Position.Bottom} isConnectable={isConnectable} />\n    </>\n  );\n});\n\n// Register in nodeTypes (define OUTSIDE component to avoid re-renders)\nconst nodeTypes = { counter: CounterNode };\n\n// Use in ReactFlow\n<ReactFlow nodeTypes={nodeTypes} ... />\n```\n\n### Multiple Handles\n\n```tsx\n// Use handle IDs when a node has multiple handles of same type\n<Handle type=\"source\" position={Position.Right} id=\"a\" />\n<Handle type=\"source\" position={Position.Right} id=\"b\" style={{ top: 20 }} />\n\n// Connect with specific handles\nconst edge = {\n  id: 'e1-2',\n  source: '1',\n  sourceHandle: 'a',\n  target: '2',\n  targetHandle: null\n};\n```\n\n### Custom Edges\n\n```tsx\nimport { BaseEdge, EdgeProps, getSmoothStepPath } from '@xyflow/react';\n\nfunction CustomEdge({ id, sourceX, sourceY, targetX, targetY, sourcePosition, targetPosition, data }: EdgeProps) {\n  const [edgePath, labelX, labelY] = getSmoothStepPath({\n    sourceX, sourceY, sourcePosition,\n    targetX, targetY, targetPosition,\n  });\n\n  return (\n    <>\n      <BaseEdge id={id} path={edgePath} />\n      <text x={labelX} y={labelY} className=\"edge-label\">{data?.label}</text>\n    </>\n  );\n}\n\nconst edgeTypes = { custom: CustomEdge };\n```\n\n## State Management\n\n### Controlled (Recommended for Production)\n\n```tsx\n// External state with change handlers\nconst [nodes, setNodes] = useState<Node[]>(initialNodes);\nconst [edges, setEdges] = useState<Edge[]>(initialEdges);\n\nconst onNodesChange = useCallback(\n  (changes) => setNodes((nds) => applyNodeChanges(changes, nds)),\n  []\n);\n\nconst onEdgesChange = useCallback(\n  (changes) => setEdges((eds) => applyEdgeChanges(changes, eds)),\n  []\n);\n\n<ReactFlow\n  nodes={nodes}\n  edges={edges}\n  onNodesChange={onNodesChange}\n  onEdgesChange={onEdgesChange}\n/>\n```\n\n### Using useReactFlow\n\n```tsx\nimport { useReactFlow, ReactFlowProvider } from '@xyflow/react';\n\nfunction FlowControls() {\n  const {\n    getNodes, setNodes, addNodes, updateNodeData,\n    getEdges, setEdges, addEdges,\n    fitView, zoomIn, zoomOut, setViewport,\n    deleteElements, toObject,\n  } = useReactFlow();\n\n  const addNode = () => {\n    addNodes({ id: `${Date.now()}`, position: { x: 100, y: 100 }, data: { label: 'New' } });\n  };\n\n  return <button onClick={addNode}>Add Node</button>;\n}\n\n// Must wrap in provider when using useReactFlow\nfunction App() {\n  return (\n    <ReactFlowProvider>\n      <Flow />\n      <FlowControls />\n    </ReactFlowProvider>\n  );\n}\n```\n\n### Updating Node Data\n\n```tsx\nconst { updateNodeData } = useReactFlow();\n\n// Merge with existing data\nupdateNodeData(nodeId, { label: 'Updated' });\n\n// Replace data entirely\nupdateNodeData(nodeId, { newField: 'value' }, { replace: true });\n```\n\n## Viewport & Fit View\n\n```tsx\n// Fit on initial render\n<ReactFlow fitView fitViewOptions={{ padding: 0.2, maxZoom: 1 }} />\n\n// Programmatic control\nconst { fitView, setViewport, getViewport, zoomTo } = useReactFlow();\n\n// Fit to specific nodes\nfitView({ nodes: [{ id: '1' }, { id: '2' }], duration: 500 });\n\n// Set exact viewport\nsetViewport({ x: 100, y: 100, zoom: 1.5 }, { duration: 300 });\n```\n\n## Connection Validation\n\n```tsx\nconst isValidConnection = useCallback((connection: Connection) => {\n  // Prevent self-connections\n  if (connection.source === connection.target) return false;\n\n  // Custom validation logic\n  const sourceNode = getNode(connection.source);\n  const targetNode = getNode(connection.target);\n\n  return sourceNode?.type !== targetNode?.type;\n}, []);\n\n<ReactFlow isValidConnection={isValidConnection} />\n```\n\n## Common Props Reference\n\n```tsx\n<ReactFlow\n  // Core data\n  nodes={nodes}\n  edges={edges}\n  onNodesChange={onNodesChange}\n  onEdgesChange={onEdgesChange}\n\n  // Custom types (define OUTSIDE component)\n  nodeTypes={nodeTypes}\n  edgeTypes={edgeTypes}\n\n  // Connections\n  onConnect={onConnect}\n  connectionMode={ConnectionMode.Loose}  // Allow target-to-target\n  isValidConnection={isValidConnection}\n\n  // Viewport\n  fitView\n  minZoom={0.1}\n  maxZoom={4}\n  defaultViewport={{ x: 0, y: 0, zoom: 1 }}\n\n  // Interaction\n  nodesDraggable={true}\n  nodesConnectable={true}\n  elementsSelectable={true}\n  panOnDrag={true}\n  zoomOnScroll={true}\n\n  // Additional components\n  <MiniMap />\n  <Controls />\n  <Background variant={BackgroundVariant.Dots} />\n</ReactFlow>\n```\n\n## CSS Classes for Interaction\n\n| Class | Effect |\n|-------|--------|\n| `nodrag` | Prevent dragging when clicking element |\n| `nowheel` | Prevent zoom on wheel events |\n| `nopan` | Prevent panning from element |\n| `nokey` | Prevent keyboard events (use on inputs) |\n\n## Additional Components\n\nSee [ADDITIONAL_COMPONENTS.md](ADDITIONAL_COMPONENTS.md) for MiniMap, Controls, Background, NodeToolbar, NodeResizer.\n",
        "skills/react-flow/SKILL.md": "---\nname: react-flow\ndescription: React Flow (@xyflow/react) for workflow visualization with custom nodes and edges. Use when building graph visualizations, creating custom workflow nodes, implementing edge labels, or controlling viewport. Triggers on ReactFlow, @xyflow/react, Handle, NodeProps, EdgeProps, useReactFlow, fitView.\n---\n\n# React Flow\n\nReact Flow (@xyflow/react) is a library for building node-based graphs, workflow editors, and interactive diagrams. It provides a highly customizable framework for creating visual programming interfaces, process flows, and network visualizations.\n\n## Quick Start\n\n### Installation\n\n```bash\npnpm add @xyflow/react\n```\n\n### Basic Setup\n\n```typescript\nimport { ReactFlow, Node, Edge, Background, Controls, MiniMap } from '@xyflow/react';\nimport '@xyflow/react/dist/style.css';\n\nconst initialNodes: Node[] = [\n  {\n    id: '1',\n    type: 'input',\n    data: { label: 'Input Node' },\n    position: { x: 250, y: 5 },\n  },\n  {\n    id: '2',\n    data: { label: 'Default Node' },\n    position: { x: 100, y: 100 },\n  },\n  {\n    id: '3',\n    type: 'output',\n    data: { label: 'Output Node' },\n    position: { x: 400, y: 100 },\n  },\n];\n\nconst initialEdges: Edge[] = [\n  { id: 'e1-2', source: '1', target: '2', animated: true },\n  { id: 'e2-3', source: '2', target: '3' },\n];\n\nfunction Flow() {\n  return (\n    <div style={{ width: '100vw', height: '100vh' }}>\n      <ReactFlow nodes={initialNodes} edges={initialEdges}>\n        <Background />\n        <Controls />\n        <MiniMap />\n      </ReactFlow>\n    </div>\n  );\n}\n\nexport default Flow;\n```\n\n## Core Concepts\n\n### Nodes\n\nNodes are the building blocks of the graph. Each node has:\n- `id`: Unique identifier\n- `type`: Node type (built-in or custom)\n- `position`: { x, y } coordinates\n- `data`: Custom data object\n\n```typescript\nimport { Node } from '@xyflow/react';\n\nconst node: Node = {\n  id: 'node-1',\n  type: 'default',\n  position: { x: 100, y: 100 },\n  data: { label: 'Node Label' },\n  style: { background: '#D6D5E6' },\n  className: 'custom-node',\n};\n```\n\nBuilt-in node types:\n- `default`: Standard node\n- `input`: No target handles\n- `output`: No source handles\n- `group`: Container for other nodes\n\n### Edges\n\nEdges connect nodes. Each edge requires:\n- `id`: Unique identifier\n- `source`: Source node ID\n- `target`: Target node ID\n\n```typescript\nimport { Edge } from '@xyflow/react';\n\nconst edge: Edge = {\n  id: 'e1-2',\n  source: '1',\n  target: '2',\n  type: 'smoothstep',\n  animated: true,\n  label: 'Edge Label',\n  style: { stroke: '#fff', strokeWidth: 2 },\n};\n```\n\nBuilt-in edge types:\n- `default`: Bezier curve\n- `straight`: Straight line\n- `step`: Orthogonal with sharp corners\n- `smoothstep`: Orthogonal with rounded corners\n\n### Handles\n\nHandles are connection points on nodes. Use `Position` enum for placement:\n\n```typescript\nimport { Handle, Position } from '@xyflow/react';\n\n<Handle type=\"target\" position={Position.Top} />\n<Handle type=\"source\" position={Position.Bottom} />\n```\n\nAvailable positions: `Position.Top`, `Position.Right`, `Position.Bottom`, `Position.Left`\n\n## State Management\n\n### Controlled Flow\n\nUse state hooks for full control:\n\n```typescript\nimport { useNodesState, useEdgesState, addEdge, OnConnect } from '@xyflow/react';\nimport { useCallback } from 'react';\n\nfunction ControlledFlow() {\n  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);\n  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);\n\n  const onConnect: OnConnect = useCallback(\n    (connection) => setEdges((eds) => addEdge(connection, eds)),\n    [setEdges]\n  );\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodesChange={onNodesChange}\n      onEdgesChange={onEdgesChange}\n      onConnect={onConnect}\n    />\n  );\n}\n```\n\n### useReactFlow Hook\n\nAccess the React Flow instance for programmatic control:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction FlowControls() {\n  const {\n    getNodes,\n    getEdges,\n    setNodes,\n    setEdges,\n    addNodes,\n    addEdges,\n    deleteElements,\n    fitView,\n    zoomIn,\n    zoomOut,\n    getNode,\n    getEdge,\n    updateNode,\n    updateEdge,\n  } = useReactFlow();\n\n  return (\n    <button onClick={() => fitView()}>Fit View</button>\n  );\n}\n```\n\n## Custom Nodes\n\nDefine custom nodes using `NodeProps<T>` with typed data:\n\n```typescript\nimport { NodeProps, Node, Handle, Position } from '@xyflow/react';\n\nexport type CustomNode = Node<{ label: string; status: 'active' | 'inactive' }, 'custom'>;\n\nfunction CustomNodeComponent({ data, selected }: NodeProps<CustomNode>) {\n  return (\n    <div className={`px-4 py-2 ${selected ? 'ring-2' : ''}`}>\n      <Handle type=\"target\" position={Position.Top} />\n      <div className=\"font-bold\">{data.label}</div>\n      <Handle type=\"source\" position={Position.Bottom} />\n    </div>\n  );\n}\n```\n\nRegister with `nodeTypes`:\n\n```typescript\nconst nodeTypes: NodeTypes = { custom: CustomNodeComponent };\n<ReactFlow nodeTypes={nodeTypes} />\n```\n\n### Key Patterns\n\n- **Multiple Handles**: Use `id` prop and `style` for positioning\n- **Dynamic Handles**: Call `useUpdateNodeInternals([nodeId])` after adding/removing handles\n- **Interactive Elements**: Add `className=\"nodrag\"` to prevent dragging on inputs/buttons\n\nSee [Custom Nodes Reference](./references/custom-nodes.md) for detailed patterns including styling, aviation map pins, and dynamic handles.\n\n## Custom Edges\n\nDefine custom edges using `EdgeProps<T>` and path utilities:\n\n```typescript\nimport { BaseEdge, EdgeProps, getBezierPath } from '@xyflow/react';\n\nexport type CustomEdge = Edge<{ status: 'normal' | 'error' }, 'custom'>;\n\nfunction CustomEdgeComponent(props: EdgeProps<CustomEdge>) {\n  const [edgePath] = getBezierPath(props);\n\n  return (\n    <BaseEdge\n      id={props.id}\n      path={edgePath}\n      style={{ stroke: props.data?.status === 'error' ? '#ef4444' : '#64748b' }}\n    />\n  );\n}\n```\n\n### Path Utilities\n\n- `getBezierPath()` - Smooth curves\n- `getStraightPath()` - Straight lines\n- `getSmoothStepPath()` - Orthogonal with rounded corners\n- `getSmoothStepPath({ borderRadius: 0 })` - Orthogonal with sharp corners (step edge)\n\nAll return `[path, labelX, labelY, offsetX, offsetY]`.\n\n### Interactive Labels\n\nUse `EdgeLabelRenderer` for HTML-based labels with pointer events:\n\n```typescript\nimport { EdgeLabelRenderer, BaseEdge, getBezierPath } from '@xyflow/react';\n\nfunction ButtonEdge(props: EdgeProps) {\n  const [edgePath, labelX, labelY] = getBezierPath(props);\n  return (\n    <>\n      <BaseEdge id={props.id} path={edgePath} />\n      <EdgeLabelRenderer>\n        <div\n          style={{\n            position: 'absolute',\n            transform: `translate(-50%, -50%) translate(${labelX}px, ${labelY}px)`,\n            pointerEvents: 'all',\n          }}\n          className=\"nodrag nopan\"\n        >\n          <button onClick={() => console.log('Delete')}></button>\n        </div>\n      </EdgeLabelRenderer>\n    </>\n  );\n}\n```\n\nSee [Custom Edges Reference](./references/custom-edges.md) for animated edges, time labels, and SVG text patterns.\n\n## Viewport Control\n\nUse `useReactFlow()` hook for programmatic viewport control:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction ViewportControls() {\n  const { fitView, zoomIn, zoomOut, setCenter, screenToFlowPosition } = useReactFlow();\n\n  // Fit all nodes in view\n  const handleFitView = () => fitView({ padding: 0.2, duration: 400 });\n\n  // Zoom controls\n  const handleZoomIn = () => zoomIn({ duration: 300 });\n  const handleZoomOut = () => zoomOut({ duration: 300 });\n\n  // Center on specific coordinates\n  const handleCenter = () => setCenter(250, 250, { zoom: 1.5, duration: 500 });\n\n  // Convert screen coordinates to flow coordinates\n  const addNodeAtClick = (event: React.MouseEvent) => {\n    const position = screenToFlowPosition({ x: event.clientX, y: event.clientY });\n    // Use position to add node\n  };\n\n  return null;\n}\n```\n\nSee [Viewport Reference](./references/viewport.md) for save/restore state, controlled viewport, and coordinate transformations.\n\n## Events\n\nReact Flow provides comprehensive event handling:\n\n### Node Events\n\n```typescript\nimport { NodeMouseHandler, OnNodeDrag } from '@xyflow/react';\n\nconst onNodeClick: NodeMouseHandler = (event, node) => {\n  console.log('Node clicked:', node.id);\n};\n\nconst onNodeDrag: OnNodeDrag = (event, node, nodes) => {\n  console.log('Dragging:', node.id);\n};\n\n<ReactFlow\n  onNodeClick={onNodeClick}\n  onNodeDrag={onNodeDrag}\n  onNodeDragStop={onNodeClick}\n/>\n```\n\n### Edge and Connection Events\n\n```typescript\nimport { EdgeMouseHandler, OnConnect } from '@xyflow/react';\n\nconst onEdgeClick: EdgeMouseHandler = (event, edge) => console.log('Edge:', edge.id);\nconst onConnect: OnConnect = (connection) => console.log('Connected:', connection);\n\n<ReactFlow onEdgeClick={onEdgeClick} onConnect={onConnect} />\n```\n\n### Selection and Viewport Events\n\n```typescript\nimport { useOnSelectionChange, useOnViewportChange } from '@xyflow/react';\n\nuseOnSelectionChange({\n  onChange: ({ nodes, edges }) => console.log('Selected:', nodes.length, edges.length),\n});\n\nuseOnViewportChange({\n  onChange: (viewport) => console.log('Viewport:', viewport.zoom),\n});\n```\n\nSee [Events Reference](./references/events.md) for complete event catalog including validation, deletion, and error handling.\n\n## Common Patterns\n\n### Preventing Drag/Pan\n\n```typescript\n<input className=\"nodrag\" />\n<button className=\"nodrag nopan\">Click me</button>\n```\n\n### Connection Validation\n\n```typescript\nconst isValidConnection = (connection: Connection) => {\n  return connection.source !== connection.target; // Prevent self-connections\n};\n\n<ReactFlow isValidConnection={isValidConnection} />\n```\n\n### Adding Nodes on Click\n\n```typescript\nconst { screenToFlowPosition, setNodes } = useReactFlow();\n\nconst onPaneClick = (event: React.MouseEvent) => {\n  const position = screenToFlowPosition({ x: event.clientX, y: event.clientY });\n  setNodes(nodes => [...nodes, { id: `node-${Date.now()}`, position, data: { label: 'New' } }]);\n};\n```\n\n### Updating Node Data\n\n```typescript\nconst { updateNodeData } = useReactFlow();\nupdateNodeData('node-1', { label: 'Updated' });\nupdateNodeData('node-1', (node) => ({ ...node.data, count: node.data.count + 1 }));\n```\n\n## Provider Pattern\n\nWrap the app with `ReactFlowProvider` when using `useReactFlow()` outside the flow:\n\n```typescript\nimport { ReactFlow, ReactFlowProvider, useReactFlow } from '@xyflow/react';\n\nfunction Controls() {\n  const { fitView } = useReactFlow(); // Must be inside provider\n  return <button onClick={() => fitView()}>Fit View</button>;\n}\n\nfunction App() {\n  return (\n    <ReactFlowProvider>\n      <Controls />\n      <ReactFlow nodes={nodes} edges={edges} />\n    </ReactFlowProvider>\n  );\n}\n```\n\n## Reference Files\n\nFor detailed implementation patterns, see:\n\n- [Custom Nodes](./references/custom-nodes.md) - NodeProps typing, Handle component, dynamic handles, styling patterns\n- [Custom Edges](./references/custom-edges.md) - EdgeProps typing, path utilities, EdgeLabelRenderer, animated edges\n- [Viewport](./references/viewport.md) - useReactFlow methods, fitView options, coordinate conversion\n- [Events](./references/events.md) - Node/edge/connection events, selection handling, viewport changes\n",
        "skills/react-flow/references/custom-edges.md": "# Custom Edges\n\nCustom edges in React Flow use the `EdgeProps<T>` typing pattern and path utility functions to render connections between nodes.\n\n## Table of Contents\n\n- [Edge Type Definition](#edge-type-definition)\n- [EdgeProps Structure](#edgeprops-structure)\n- [Path Utility Functions](#path-utility-functions)\n- [BaseEdge Component](#baseedge-component)\n- [EdgeLabelRenderer for Interactive Labels](#edgelabelrenderer-for-interactive-labels)\n- [Animated Edges](#animated-edges)\n- [SVG Text Labels](#svg-text-labels)\n- [EdgeText Component](#edgetext-component)\n- [Time Label Edge Example](#time-label-edge-example)\n- [Edge Registration](#edge-registration)\n- [Default Edge Options](#default-edge-options)\n\n## Edge Type Definition\n\nDefine custom edge types with typed data:\n\n```typescript\nimport { Edge, EdgeProps } from '@xyflow/react';\n\n// Define the custom edge type\nexport type TimeLabelEdge = Edge<{ time: string; label: string }, 'timeLabel'>;\n\n// Component receives EdgeProps\nexport default function TimeLabelEdge(props: EdgeProps<TimeLabelEdge>) {\n  // Edge implementation\n}\n```\n\n## EdgeProps Structure\n\nThe `EdgeProps` type includes these key properties:\n\n```typescript\ntype EdgeProps<T extends Edge = Edge> = {\n  id: string;\n  type?: string;\n  source: string;\n  target: string;\n  sourceX: number;\n  sourceY: number;\n  targetX: number;\n  targetY: number;\n  sourcePosition: Position;\n  targetPosition: Position;\n  data?: T['data'];\n  selected?: boolean;\n  animated?: boolean;\n  style?: CSSProperties;\n  markerStart?: string;\n  markerEnd?: string;\n  sourceHandleId?: string | null;\n  targetHandleId?: string | null;\n  label?: ReactNode;\n  labelStyle?: CSSProperties;\n  labelShowBg?: boolean;\n  labelBgStyle?: CSSProperties;\n  labelBgPadding?: [number, number];\n  labelBgBorderRadius?: number;\n  interactionWidth?: number;\n  pathOptions?: any;\n};\n```\n\n## Path Utility Functions\n\nReact Flow provides several path generators:\n\n### getBezierPath\n\nCreates smooth curved paths:\n\n```typescript\nimport { FC } from 'react';\nimport { BaseEdge, EdgeProps, getBezierPath } from '@xyflow/react';\n\nconst CustomEdge: FC<EdgeProps> = ({\n  id,\n  sourceX,\n  sourceY,\n  targetX,\n  targetY,\n  sourcePosition,\n  targetPosition,\n  data,\n}) => {\n  const [edgePath, labelX, labelY] = getBezierPath({\n    sourceX,\n    sourceY,\n    sourcePosition,\n    targetX,\n    targetY,\n    targetPosition,\n    curvature: 0.25, // Optional: control curve amount (default 0.25)\n  });\n\n  return <BaseEdge path={edgePath} id={id} />;\n};\n```\n\n### getStraightPath\n\nCreates direct straight lines:\n\n```typescript\nimport { getStraightPath } from '@xyflow/react';\n\nconst [edgePath, labelX, labelY] = getStraightPath({\n  sourceX,\n  sourceY,\n  targetX,\n  targetY,\n});\n```\n\n### getSmoothStepPath\n\nCreates orthogonal paths with smooth corners:\n\n```typescript\nimport { getSmoothStepPath } from '@xyflow/react';\n\nconst [edgePath, labelX, labelY] = getSmoothStepPath({\n  sourceX,\n  sourceY,\n  sourcePosition,\n  targetX,\n  targetY,\n  targetPosition,\n  borderRadius: 8, // Optional: corner radius\n  offset: 20, // Optional: offset from node\n});\n```\n\n### getSmoothStepPath with borderRadius: 0 (Step Edge)\n\nFor orthogonal paths with sharp corners, use `getSmoothStepPath` with `borderRadius: 0`:\n\n```typescript\nimport { getSmoothStepPath } from '@xyflow/react';\n\nconst [edgePath, labelX, labelY] = getSmoothStepPath({\n  sourceX,\n  sourceY,\n  sourcePosition,\n  targetX,\n  targetY,\n  targetPosition,\n  borderRadius: 0, // Sharp corners (step edge)\n  offset: 20, // Optional: offset from node\n});\n```\n\n## BaseEdge Component\n\nThe `BaseEdge` component renders the path with proper styling:\n\n```typescript\nimport { BaseEdge, EdgeProps, getBezierPath } from '@xyflow/react';\n\nfunction CustomEdge(props: EdgeProps) {\n  const [edgePath] = getBezierPath(props);\n\n  return (\n    <BaseEdge\n      id={props.id}\n      path={edgePath}\n      style={props.style}\n      markerEnd={props.markerEnd}\n      markerStart={props.markerStart}\n      interactionWidth={20} // Wider click target\n    />\n  );\n}\n```\n\n## EdgeLabelRenderer for Interactive Labels\n\nUse `EdgeLabelRenderer` to render interactive HTML labels instead of SVG text:\n\n```typescript\nimport { getBezierPath, EdgeLabelRenderer, BaseEdge, EdgeProps } from '@xyflow/react';\n\nfunction CustomEdge({ id, data, ...props }: EdgeProps) {\n  const [edgePath, labelX, labelY] = getBezierPath(props);\n\n  return (\n    <>\n      <BaseEdge id={id} path={edgePath} />\n      <EdgeLabelRenderer>\n        <div\n          style={{\n            position: 'absolute',\n            transform: `translate(-50%, -50%) translate(${labelX}px, ${labelY}px)`,\n            background: '#ffcc00',\n            padding: 10,\n            borderRadius: 5,\n            fontSize: 12,\n            fontWeight: 700,\n            pointerEvents: 'all', // Enable interactions\n          }}\n          className=\"nodrag nopan\"\n        >\n          <button onClick={() => console.log('clicked edge', id)}>\n            {data?.label || 'Delete'}\n          </button>\n        </div>\n      </EdgeLabelRenderer>\n    </>\n  );\n}\n```\n\n## Animated Edges\n\n### Dash Animation\n\nAnimate the stroke dash pattern:\n\n```typescript\nconst animatedEdgeStyle = {\n  strokeDasharray: '5 5',\n  animation: 'dashdraw 0.5s linear infinite',\n};\n\n// CSS\n// @keyframes dashdraw {\n//   to {\n//     stroke-dashoffset: -10;\n//   }\n// }\n\nfunction AnimatedEdge(props: EdgeProps) {\n  const [edgePath] = getBezierPath(props);\n  return <BaseEdge path={edgePath} style={animatedEdgeStyle} />;\n}\n```\n\n### Moving Circle Along Path\n\n```typescript\nimport { BaseEdge, EdgeProps, getBezierPath } from '@xyflow/react';\n\nfunction MovingCircleEdge(props: EdgeProps) {\n  const [edgePath] = getBezierPath(props);\n\n  return (\n    <>\n      <BaseEdge id={props.id} path={edgePath} />\n      <circle r=\"4\" fill=\"#ff0072\">\n        <animateMotion dur=\"2s\" repeatCount=\"indefinite\" path={edgePath} />\n      </circle>\n    </>\n  );\n}\n```\n\n## SVG Text Labels\n\nFor simple text labels along the path:\n\n```typescript\nimport { BaseEdge, EdgeProps, getBezierPath } from '@xyflow/react';\n\nfunction TextLabelEdge({ id, data, ...props }: EdgeProps) {\n  const [edgePath] = getBezierPath(props);\n\n  return (\n    <>\n      <BaseEdge path={edgePath} id={id} />\n      <text>\n        <textPath\n          href={`#${id}`}\n          style={{ fontSize: '12px' }}\n          startOffset=\"50%\"\n          textAnchor=\"middle\"\n        >\n          {data?.text || ''}\n        </textPath>\n      </text>\n    </>\n  );\n}\n```\n\n## EdgeText Component\n\nFor positioned text with background:\n\n```typescript\nimport { BaseEdge, EdgeText, EdgeProps, getSmoothStepPath } from '@xyflow/react';\n\nfunction LabeledEdge({ id, data, ...props }: EdgeProps) {\n  const [edgePath, labelX, labelY] = getSmoothStepPath(props);\n\n  return (\n    <>\n      <BaseEdge id={id} path={edgePath} />\n      <EdgeText\n        x={labelX}\n        y={labelY - 5}\n        label={data?.text || ''}\n        labelBgStyle={{ fill: 'white' }}\n        labelStyle={{ fill: 'black' }}\n        onClick={() => console.log(data)}\n      />\n    </>\n  );\n}\n```\n\n## Time Label Edge Example\n\nCustom edge displaying time/duration labels:\n\n```typescript\nimport { EdgeProps, getBezierPath, EdgeLabelRenderer, BaseEdge } from '@xyflow/react';\n\ntype TimeLabelData = {\n  duration: string;\n  status: 'normal' | 'delayed' | 'critical';\n};\n\nexport type TimeLabelEdge = Edge<TimeLabelData, 'timeLabel'>;\n\nfunction TimeLabelEdge({ id, data, selected, ...props }: EdgeProps<TimeLabelEdge>) {\n  const [edgePath, labelX, labelY] = getBezierPath(props);\n\n  const statusColors = {\n    normal: 'bg-green-100 text-green-800',\n    delayed: 'bg-yellow-100 text-yellow-800',\n    critical: 'bg-red-100 text-red-800',\n  };\n\n  return (\n    <>\n      <BaseEdge\n        id={id}\n        path={edgePath}\n        style={{\n          strokeWidth: selected ? 2 : 1,\n          stroke: data?.status === 'critical' ? '#ef4444' : undefined,\n        }}\n      />\n      <EdgeLabelRenderer>\n        <div\n          style={{\n            position: 'absolute',\n            transform: `translate(-50%, -50%) translate(${labelX}px, ${labelY}px)`,\n            pointerEvents: 'all',\n          }}\n          className=\"nodrag nopan\"\n        >\n          <div className={`px-2 py-1 rounded text-xs font-medium ${statusColors[data?.status || 'normal']}`}>\n            {data?.duration || '0m'}\n          </div>\n        </div>\n      </EdgeLabelRenderer>\n    </>\n  );\n}\n```\n\n## Edge Registration\n\nRegister custom edges in the `edgeTypes` prop:\n\n```typescript\nimport { ReactFlow, EdgeTypes } from '@xyflow/react';\nimport TimeLabelEdge from './TimeLabelEdge';\nimport AnimatedEdge from './AnimatedEdge';\n\nconst edgeTypes: EdgeTypes = {\n  timeLabel: TimeLabelEdge,\n  animated: AnimatedEdge,\n};\n\nfunction Flow() {\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      edgeTypes={edgeTypes}\n    />\n  );\n}\n```\n\n## Default Edge Options\n\nSet default properties for all edges:\n\n```typescript\nimport { DefaultEdgeOptions } from '@xyflow/react';\n\nconst defaultEdgeOptions: DefaultEdgeOptions = {\n  animated: true,\n  type: 'smoothstep',\n  style: { stroke: '#fff', strokeWidth: 2 },\n};\n\n<ReactFlow defaultEdgeOptions={defaultEdgeOptions} />\n```\n",
        "skills/react-flow/references/custom-nodes.md": "# Custom Nodes\n\nReact Flow custom nodes use the `NodeProps<T>` typing pattern where `T` is the specific node type with custom data.\n\n## Table of Contents\n\n- [Node Type Definition](#node-type-definition)\n- [Handle Component](#handle-component)\n- [Multiple Handles](#multiple-handles)\n- [Dynamic Handles with useUpdateNodeInternals](#dynamic-handles-with-useupdatenodeinternals)\n- [Styling Nodes](#styling-nodes)\n- [Aviation Map Pin Node Example](#aviation-map-pin-node-example)\n- [Preventing Drag and Pan](#preventing-drag-and-pan)\n- [Node Registration](#node-registration)\n\n## Node Type Definition\n\nDefine custom nodes with typed data and specify the node type string:\n\n```typescript\nimport { Node, NodeProps } from '@xyflow/react';\n\n// Define the custom node type\nexport type CounterNode = Node<{ initialCount?: number }, 'counter'>;\n\n// Component receives NodeProps<CounterNode>\nexport default function CounterNode(props: NodeProps<CounterNode>) {\n  const [count, setCount] = useState(props.data?.initialCount ?? 0);\n\n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button className=\"nodrag\" onClick={() => setCount(count + 1)}>\n        Increment\n      </button>\n    </div>\n  );\n}\n```\n\n## Handle Component\n\nThe `Handle` component defines connection points on nodes. Use `type=\"target\"` for incoming connections and `type=\"source\"` for outgoing connections.\n\n```typescript\nimport { Handle, Position } from '@xyflow/react';\n\nfunction CustomNode({ data }) {\n  return (\n    <>\n      <Handle type=\"target\" position={Position.Left} />\n      <div>{data.label}</div>\n      <Handle type=\"source\" position={Position.Right} />\n    </>\n  );\n}\n```\n\n### Multiple Handles\n\nUse the `id` prop to create multiple handles on a single node:\n\n```typescript\nimport { Handle, Position, CSSProperties } from '@xyflow/react';\n\nconst sourceHandleStyleA: CSSProperties = { top: 10 };\nconst sourceHandleStyleB: CSSProperties = { bottom: 10, top: 'auto' };\n\nfunction MultiHandleNode({ data, isConnectable }: NodeProps<ColorSelectorNode>) {\n  return (\n    <>\n      <Handle type=\"target\" position={Position.Left} />\n      <div>{data.label}</div>\n\n      {/* Multiple source handles with IDs */}\n      <Handle\n        type=\"source\"\n        position={Position.Right}\n        id=\"a\"\n        style={sourceHandleStyleA}\n        isConnectable={isConnectable}\n      />\n      <Handle\n        type=\"source\"\n        position={Position.Right}\n        id=\"b\"\n        style={sourceHandleStyleB}\n        isConnectable={isConnectable}\n      />\n    </>\n  );\n}\n```\n\n## Dynamic Handles with useUpdateNodeInternals\n\nWhen adding or removing handles dynamically, use `useUpdateNodeInternals()` to notify React Flow:\n\n```typescript\nimport { useState, useMemo } from 'react';\nimport { Handle, Position, useUpdateNodeInternals, NodeProps } from '@xyflow/react';\n\nfunction DynamicHandleNode({ id }: NodeProps) {\n  const [handleCount, setHandleCount] = useState(1);\n  const updateNodeInternals = useUpdateNodeInternals();\n\n  const handles = useMemo(\n    () =>\n      Array.from({ length: handleCount }, (x, i) => {\n        const handleId = `handle-${i}`;\n        return (\n          <Handle\n            key={handleId}\n            type=\"source\"\n            position={Position.Right}\n            id={handleId}\n            style={{ top: 10 * i }}\n          />\n        );\n      }),\n    [handleCount]\n  );\n\n  return (\n    <div>\n      <Handle type=\"target\" position={Position.Left} />\n      <div>output handle count: {handleCount}</div>\n      <button\n        onClick={() => {\n          setHandleCount((c) => c + 1);\n          updateNodeInternals(id); // Critical: notify React Flow\n        }}\n      >\n        add handle\n      </button>\n      {handles}\n    </div>\n  );\n}\n```\n\n## Styling Nodes\n\n### CSS Classes\n\nApply styles with `className` and `style` props on the node definition:\n\n```typescript\nconst nodes: Node[] = [\n  {\n    id: '1',\n    type: 'custom',\n    data: { label: 'Styled Node' },\n    position: { x: 250, y: 5 },\n    style: { border: '1px solid #777', padding: 10 },\n    className: 'custom-node',\n  },\n];\n```\n\n### Inline Styles in Component\n\n```typescript\nimport { CSSProperties } from 'react';\n\nconst nodeStyles: CSSProperties = { padding: 10, border: '1px solid #ddd' };\n\nfunction StyledNode({ data }: NodeProps) {\n  return (\n    <div style={nodeStyles}>\n      {data.label}\n    </div>\n  );\n}\n```\n\n### Tailwind CSS\n\nReact Flow works seamlessly with Tailwind:\n\n```typescript\nfunction TailwindNode({ data }: NodeProps) {\n  return (\n    <div className=\"px-4 py-2 shadow-md rounded-md bg-white border-2 border-stone-400\">\n      <div className=\"flex\">\n        <div className=\"ml-2\">\n          <div className=\"text-lg font-bold\">{data.name}</div>\n          <div className=\"text-gray-500\">{data.job}</div>\n        </div>\n      </div>\n      <Handle type=\"target\" position={Position.Top} className=\"w-16 !bg-teal-500\" />\n      <Handle type=\"source\" position={Position.Bottom} className=\"w-16 !bg-teal-500\" />\n    </div>\n  );\n}\n```\n\n## Aviation Map Pin Node Example\n\nCustom node with status-based styling using data-driven approach:\n\n```typescript\nimport { NodeProps, Handle, Position } from '@xyflow/react';\n\ntype MapPinData = {\n  label: string;\n  status: 'active' | 'warning' | 'inactive';\n  coordinate: { lat: number; lon: number };\n};\n\nexport type MapPinNode = Node<MapPinData, 'mapPin'>;\n\nfunction MapPinNode({ data, selected }: NodeProps<MapPinNode>) {\n  const statusColors = {\n    active: 'bg-green-500',\n    warning: 'bg-yellow-500',\n    inactive: 'bg-gray-400',\n  };\n\n  return (\n    <div className={`relative ${selected ? 'ring-2 ring-blue-500' : ''}`}>\n      {/* Beacon glow for active status */}\n      {data.status === 'active' && (\n        <div className=\"absolute inset-0 animate-ping bg-green-500 rounded-full opacity-75\" />\n      )}\n\n      {/* Pin icon */}\n      <div className={`relative w-8 h-8 rounded-full ${statusColors[data.status]}`}>\n        <div className=\"absolute inset-0 flex items-center justify-center text-white font-bold\">\n          {data.label}\n        </div>\n      </div>\n\n      {/* Connection handle at bottom */}\n      <Handle type=\"source\" position={Position.Bottom} className=\"opacity-0\" />\n    </div>\n  );\n}\n```\n\n## Preventing Drag and Pan\n\nUse `nodrag` and `nopan` classes to prevent interactions on specific elements:\n\n```typescript\nfunction InteractiveNode({ data }: NodeProps) {\n  return (\n    <div>\n      <input\n        className=\"nodrag\"\n        type=\"text\"\n        defaultValue={data.label}\n      />\n      <button className=\"nodrag nopan\" onClick={() => console.log('clicked')}>\n        Click me\n      </button>\n    </div>\n  );\n}\n```\n\n## Node Registration\n\nRegister custom nodes in the `nodeTypes` prop:\n\n```typescript\nimport { ReactFlow, NodeTypes } from '@xyflow/react';\nimport CustomNode from './CustomNode';\nimport MapPinNode from './MapPinNode';\n\nconst nodeTypes: NodeTypes = {\n  custom: CustomNode,\n  mapPin: MapPinNode,\n};\n\nfunction Flow() {\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      nodeTypes={nodeTypes}\n    />\n  );\n}\n```\n",
        "skills/react-flow/references/events.md": "# Events\n\nReact Flow provides comprehensive event handling for nodes, edges, connections, selections, and viewport changes.\n\n## Table of Contents\n\n- [Node Events](#node-events)\n  - [Click Events](#click-events)\n  - [Drag Events](#drag-events)\n  - [Hover Events](#hover-events)\n- [Edge Events](#edge-events)\n  - [Click Events](#click-events-1)\n  - [Hover Events](#hover-events-1)\n  - [Edge Update and Reconnect](#edge-update-and-reconnect)\n- [Connection Events](#connection-events)\n  - [Basic Connection](#basic-connection)\n  - [Connection Start and End](#connection-start-and-end)\n  - [Validate Connections](#validate-connections)\n- [Selection Events](#selection-events)\n  - [useOnSelectionChange Hook](#useonselectionchange-hook)\n  - [Selection Drag](#selection-drag)\n  - [Selection Context Menu](#selection-context-menu)\n- [Viewport Events](#viewport-events)\n  - [useOnViewportChange Hook](#useonviewportchange-hook)\n  - [Move Events](#move-events)\n- [Pane Events](#pane-events)\n  - [Click Events](#click-events-2)\n  - [Mouse Events](#mouse-events)\n- [Init and Delete Events](#init-and-delete-events)\n  - [Initialization](#initialization)\n  - [Delete Events](#delete-events)\n- [Error Handling](#error-handling)\n\n## Node Events\n\n### Click Events\n\n```typescript\nimport { ReactFlow, NodeMouseHandler, Node } from '@xyflow/react';\n\nfunction NodeClickExample() {\n  const onNodeClick: NodeMouseHandler = (event, node) => {\n    console.log('Node clicked:', node.id, node.data);\n  };\n\n  const onNodeDoubleClick: NodeMouseHandler = (event, node) => {\n    console.log('Node double-clicked:', node.id);\n  };\n\n  const onNodeContextMenu: NodeMouseHandler = (event, node) => {\n    event.preventDefault();\n    console.log('Node right-clicked:', node.id);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodeClick={onNodeClick}\n      onNodeDoubleClick={onNodeDoubleClick}\n      onNodeContextMenu={onNodeContextMenu}\n    />\n  );\n}\n```\n\n### Drag Events\n\n```typescript\nimport { ReactFlow, OnNodeDrag, NodeMouseHandler } from '@xyflow/react';\n\nfunction NodeDragExample() {\n  const onNodeDragStart: NodeMouseHandler = (event, node) => {\n    console.log('Drag started:', node.id);\n  };\n\n  const onNodeDrag: OnNodeDrag = (event, node, nodes) => {\n    console.log('Dragging:', node.id, 'at', node.position);\n    console.log('All dragged nodes:', nodes.map(n => n.id));\n  };\n\n  const onNodeDragStop: NodeMouseHandler = (event, node) => {\n    console.log('Drag stopped:', node.id, 'at', node.position);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodeDragStart={onNodeDragStart}\n      onNodeDrag={onNodeDrag}\n      onNodeDragStop={onNodeDragStop}\n    />\n  );\n}\n```\n\n### Hover Events\n\n```typescript\nimport { ReactFlow, NodeMouseHandler } from '@xyflow/react';\n\nfunction NodeHoverExample() {\n  const onNodeMouseEnter: NodeMouseHandler = (event, node) => {\n    console.log('Mouse entered:', node.id);\n  };\n\n  const onNodeMouseMove: NodeMouseHandler = (event, node) => {\n    console.log('Mouse moving over:', node.id);\n  };\n\n  const onNodeMouseLeave: NodeMouseHandler = (event, node) => {\n    console.log('Mouse left:', node.id);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodeMouseEnter={onNodeMouseEnter}\n      onNodeMouseMove={onNodeMouseMove}\n      onNodeMouseLeave={onNodeMouseLeave}\n    />\n  );\n}\n```\n\n## Edge Events\n\n### Click Events\n\n```typescript\nimport { ReactFlow, EdgeMouseHandler } from '@xyflow/react';\n\nfunction EdgeClickExample() {\n  const onEdgeClick: EdgeMouseHandler = (event, edge) => {\n    console.log('Edge clicked:', edge.id);\n    console.log('From:', edge.source, 'To:', edge.target);\n  };\n\n  const onEdgeDoubleClick: EdgeMouseHandler = (event, edge) => {\n    console.log('Edge double-clicked:', edge.id);\n  };\n\n  const onEdgeContextMenu: EdgeMouseHandler = (event, edge) => {\n    event.preventDefault();\n    console.log('Edge right-clicked:', edge.id);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onEdgeClick={onEdgeClick}\n      onEdgeDoubleClick={onEdgeDoubleClick}\n      onEdgeContextMenu={onEdgeContextMenu}\n    />\n  );\n}\n```\n\n### Hover Events\n\n```typescript\nimport { ReactFlow, EdgeMouseHandler } from '@xyflow/react';\n\nfunction EdgeHoverExample() {\n  const onEdgeMouseEnter: EdgeMouseHandler = (event, edge) => {\n    console.log('Mouse entered edge:', edge.id);\n  };\n\n  const onEdgeMouseMove: EdgeMouseHandler = (event, edge) => {\n    console.log('Mouse moving over edge:', edge.id);\n  };\n\n  const onEdgeMouseLeave: EdgeMouseHandler = (event, edge) => {\n    console.log('Mouse left edge:', edge.id);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onEdgeMouseEnter={onEdgeMouseEnter}\n      onEdgeMouseMove={onEdgeMouseMove}\n      onEdgeMouseLeave={onEdgeMouseLeave}\n    />\n  );\n}\n```\n\n### Edge Update and Reconnect\n\n```typescript\nimport { ReactFlow, OnReconnect, OnReconnectStart, OnReconnectEnd } from '@xyflow/react';\n\nfunction EdgeReconnectExample() {\n  const onReconnect: OnReconnect = (oldEdge, newConnection) => {\n    console.log('Edge reconnected:', oldEdge.id);\n    console.log('New connection:', newConnection);\n  };\n\n  const onReconnectStart: OnReconnectStart = (event, edge, handleType) => {\n    console.log('Reconnect started:', edge.id, 'handle:', handleType);\n  };\n\n  const onReconnectEnd: OnReconnectEnd = (event, edge, handleType, connectionState) => {\n    console.log('Reconnect ended:', edge.id);\n    console.log('Connection state:', connectionState);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onReconnect={onReconnect}\n      onReconnectStart={onReconnectStart}\n      onReconnectEnd={onReconnectEnd}\n      edgesReconnectable={true}\n    />\n  );\n}\n```\n\n## Connection Events\n\n### Basic Connection\n\n```typescript\nimport { ReactFlow, OnConnect, addEdge } from '@xyflow/react';\nimport { useCallback } from 'react';\n\nfunction ConnectionExample() {\n  const [edges, setEdges] = useState<Edge[]>([]);\n\n  const onConnect: OnConnect = useCallback(\n    (connection) => {\n      console.log('Connection made:', connection);\n      console.log('Source:', connection.source);\n      console.log('Target:', connection.target);\n      console.log('Source Handle:', connection.sourceHandle);\n      console.log('Target Handle:', connection.targetHandle);\n\n      setEdges((eds) => addEdge(connection, eds));\n    },\n    [setEdges]\n  );\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onConnect={onConnect}\n    />\n  );\n}\n```\n\n### Connection Start and End\n\n```typescript\nimport { ReactFlow, OnConnectStart, OnConnectEnd } from '@xyflow/react';\n\nfunction ConnectionLifecycleExample() {\n  const onConnectStart: OnConnectStart = (event, { nodeId, handleId, handleType }) => {\n    console.log('Connection started from:', nodeId);\n    console.log('Handle:', handleId, 'Type:', handleType);\n  };\n\n  const onConnectEnd: OnConnectEnd = (event, connectionState) => {\n    console.log('Connection ended');\n    console.log('Was valid:', connectionState.isValid);\n    console.log('From node:', connectionState.fromNode?.id);\n    console.log('To node:', connectionState.toNode?.id);\n    console.log('From handle:', connectionState.fromHandle);\n    console.log('To handle:', connectionState.toHandle);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onConnectStart={onConnectStart}\n      onConnectEnd={onConnectEnd}\n    />\n  );\n}\n```\n\n### Validate Connections\n\n```typescript\nimport { ReactFlow, Connection, Edge, Node } from '@xyflow/react';\n\nfunction ValidatedConnectionExample() {\n  const isValidConnection = (connection: Connection | Edge) => {\n    // Prevent self-connections\n    if (connection.source === connection.target) {\n      return false;\n    }\n\n    // Custom validation logic\n    const sourceNode = nodes.find(n => n.id === connection.source);\n    const targetNode = nodes.find(n => n.id === connection.target);\n\n    // Prevent connections from output nodes\n    if (sourceNode?.type === 'output') {\n      return false;\n    }\n\n    // Prevent connections to input nodes\n    if (targetNode?.type === 'input') {\n      return false;\n    }\n\n    return true;\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      isValidConnection={isValidConnection}\n    />\n  );\n}\n```\n\n## Selection Events\n\n### useOnSelectionChange Hook\n\n```typescript\nimport { useOnSelectionChange, OnSelectionChangeParams } from '@xyflow/react';\nimport { useCallback } from 'react';\n\nfunction SelectionLogger() {\n  const onChange = useCallback(({ nodes, edges }: OnSelectionChangeParams) => {\n    console.log('Selected nodes:', nodes.map(n => n.id));\n    console.log('Selected edges:', edges.map(e => e.id));\n  }, []);\n\n  useOnSelectionChange({\n    onChange,\n  });\n\n  return null;\n}\n\nfunction SelectionExample() {\n  return (\n    <ReactFlow nodes={nodes} edges={edges}>\n      <SelectionLogger />\n    </ReactFlow>\n  );\n}\n```\n\n### Selection Drag\n\n```typescript\nimport { ReactFlow, SelectionDragHandler } from '@xyflow/react';\n\nfunction SelectionDragExample() {\n  const onSelectionDragStart: SelectionDragHandler = (event, nodes) => {\n    console.log('Selection drag started:', nodes.length, 'nodes');\n  };\n\n  const onSelectionDrag: SelectionDragHandler = (event, nodes) => {\n    console.log('Dragging selection:', nodes.map(n => n.id));\n  };\n\n  const onSelectionDragStop: SelectionDragHandler = (event, nodes) => {\n    console.log('Selection drag stopped');\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onSelectionDragStart={onSelectionDragStart}\n      onSelectionDrag={onSelectionDrag}\n      onSelectionDragStop={onSelectionDragStop}\n    />\n  );\n}\n```\n\n### Selection Context Menu\n\n```typescript\nimport { ReactFlow, Node, Edge } from '@xyflow/react';\n\nfunction SelectionContextMenuExample() {\n  const onSelectionContextMenu = (event: React.MouseEvent, nodes: Node[]) => {\n    event.preventDefault();\n    console.log('Context menu on selection:', nodes.map(n => n.id));\n\n    // Show custom context menu\n    // ... context menu logic\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onSelectionContextMenu={onSelectionContextMenu}\n    />\n  );\n}\n```\n\n## Viewport Events\n\n### useOnViewportChange Hook\n\n```typescript\nimport { useOnViewportChange, Viewport } from '@xyflow/react';\nimport { useCallback } from 'react';\n\nfunction ViewportLogger() {\n  const onStart = useCallback((viewport: Viewport) => {\n    console.log('Viewport change started:', viewport);\n  }, []);\n\n  const onChange = useCallback((viewport: Viewport) => {\n    console.log('Viewport:', {\n      x: viewport.x,\n      y: viewport.y,\n      zoom: viewport.zoom,\n    });\n  }, []);\n\n  const onEnd = useCallback((viewport: Viewport) => {\n    console.log('Viewport change ended:', viewport);\n  }, []);\n\n  useOnViewportChange({\n    onStart,\n    onChange,\n    onEnd,\n  });\n\n  return null;\n}\n```\n\n### Move Events\n\n```typescript\nimport { ReactFlow, OnMove } from '@xyflow/react';\n\nfunction MoveExample() {\n  const onMove: OnMove = (event, viewport) => {\n    console.log('Viewport moved to:', viewport);\n  };\n\n  const onMoveStart: OnMove = (event, viewport) => {\n    console.log('Move started from:', viewport);\n  };\n\n  const onMoveEnd: OnMove = (event, viewport) => {\n    console.log('Move ended at:', viewport);\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onMove={onMove}\n      onMoveStart={onMoveStart}\n      onMoveEnd={onMoveEnd}\n    />\n  );\n}\n```\n\n## Pane Events\n\n### Click Events\n\n```typescript\nimport { ReactFlow } from '@xyflow/react';\nimport { MouseEvent } from 'react';\n\nfunction PaneClickExample() {\n  const onPaneClick = (event: MouseEvent) => {\n    console.log('Pane clicked at:', event.clientX, event.clientY);\n  };\n\n  const onPaneContextMenu = (event: MouseEvent) => {\n    event.preventDefault();\n    console.log('Pane right-clicked');\n  };\n\n  const onPaneScroll = (event?: MouseEvent | WheelEvent) => {\n    console.log('Pane scrolled');\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onPaneClick={onPaneClick}\n      onPaneContextMenu={onPaneContextMenu}\n      onPaneScroll={onPaneScroll}\n    />\n  );\n}\n```\n\n### Mouse Events\n\n```typescript\nimport { ReactFlow } from '@xyflow/react';\nimport { MouseEvent } from 'react';\n\nfunction PaneMouseExample() {\n  const onPaneMouseEnter = (event: MouseEvent) => {\n    console.log('Mouse entered pane');\n  };\n\n  const onPaneMouseMove = (event: MouseEvent) => {\n    console.log('Mouse moving over pane');\n  };\n\n  const onPaneMouseLeave = (event: MouseEvent) => {\n    console.log('Mouse left pane');\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onPaneMouseEnter={onPaneMouseEnter}\n      onPaneMouseMove={onPaneMouseMove}\n      onPaneMouseLeave={onPaneMouseLeave}\n    />\n  );\n}\n```\n\n## Init and Delete Events\n\n### Initialization\n\n```typescript\nimport { ReactFlow, OnInit, ReactFlowInstance } from '@xyflow/react';\n\nfunction InitExample() {\n  const onInit: OnInit = (reactFlowInstance: ReactFlowInstance) => {\n    console.log('React Flow initialized');\n    console.log('Viewport:', reactFlowInstance.getViewport());\n    reactFlowInstance.fitView();\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onInit={onInit}\n    />\n  );\n}\n```\n\n### Delete Events\n\n```typescript\nimport { ReactFlow, OnNodesDelete, OnEdgesDelete, OnBeforeDelete } from '@xyflow/react';\n\nfunction DeleteExample() {\n  const onNodesDelete: OnNodesDelete = (nodes) => {\n    console.log('Nodes deleted:', nodes.map(n => n.id));\n  };\n\n  const onEdgesDelete: OnEdgesDelete = (edges) => {\n    console.log('Edges deleted:', edges.map(e => e.id));\n  };\n\n  const onBeforeDelete: OnBeforeDelete = async ({ nodes, edges }) => {\n    console.log('About to delete:', nodes.length, 'nodes and', edges.length, 'edges');\n\n    // Return true to allow deletion, false to cancel\n    const confirmed = window.confirm('Delete selected elements?');\n    return confirmed;\n  };\n\n  const onDelete = ({ nodes, edges }) => {\n    console.log('Deleted:', nodes.length, 'nodes and', edges.length, 'edges');\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onNodesDelete={onNodesDelete}\n      onEdgesDelete={onEdgesDelete}\n      onBeforeDelete={onBeforeDelete}\n      onDelete={onDelete}\n    />\n  );\n}\n```\n\n## Error Handling\n\n```typescript\nimport { ReactFlow, OnError } from '@xyflow/react';\n\nfunction ErrorHandlingExample() {\n  const onError: OnError = (code, message) => {\n    console.error(`React Flow Error [${code}]:`, message);\n\n    // Handle specific error codes\n    if (code === '010') {\n      console.error('Handle must be rendered inside a custom node');\n    }\n  };\n\n  return (\n    <ReactFlow\n      nodes={nodes}\n      edges={edges}\n      onError={onError}\n    />\n  );\n}\n```\n",
        "skills/react-flow/references/viewport.md": "# Viewport Control\n\nReact Flow provides viewport control through the `useReactFlow()` hook, which exposes methods for programmatic navigation, zoom, and coordinate transformations.\n\n## Table of Contents\n\n- [useReactFlow Hook](#usereactflow-hook)\n- [fitView Method](#fitview-method)\n- [Zoom Methods](#zoom-methods)\n- [setViewport Method](#setviewport-method)\n- [setCenter Method](#setcenter-method)\n- [screenToFlowPosition Method](#screentoflowposition-method)\n- [flowToScreenPosition Method](#flowtoscreenposition-method)\n- [Save and Restore Viewport State](#save-and-restore-viewport-state)\n- [Programmatic Pan to Node](#programmatic-pan-to-node)\n- [Controlled Viewport](#controlled-viewport)\n- [useOnViewportChange Hook](#useonviewportchange-hook)\n- [getNodesBounds Method](#getnodesbounds-method)\n- [viewportInitialized Flag](#viewportinitialized-flag)\n\n## useReactFlow Hook\n\nThe main hook for accessing viewport and flow instance methods:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction ViewportControls() {\n  const reactFlow = useReactFlow();\n\n  // Access viewport methods\n  const handleZoomIn = () => reactFlow.zoomIn();\n  const handleFitView = () => reactFlow.fitView();\n\n  return (\n    <div>\n      <button onClick={handleZoomIn}>Zoom In</button>\n      <button onClick={handleFitView}>Fit View</button>\n    </div>\n  );\n}\n```\n\n## fitView Method\n\nAdjusts the viewport to fit all nodes in view:\n\n```typescript\nimport { useReactFlow, FitViewOptions } from '@xyflow/react';\n\nfunction FitViewExample() {\n  const { fitView } = useReactFlow();\n\n  const handleFitView = async () => {\n    // Basic usage\n    await fitView();\n\n    // With options\n    await fitView({\n      padding: 0.2, // 20% padding around nodes\n      includeHiddenNodes: false, // Don't include hidden nodes\n      minZoom: 0.5, // Minimum zoom level\n      maxZoom: 2, // Maximum zoom level\n      duration: 200, // Animation duration in ms\n    });\n  };\n\n  return <button onClick={handleFitView}>Fit View</button>;\n}\n```\n\n### fitView with Specific Nodes\n\nFit viewport to a subset of nodes:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction FitSpecificNodes() {\n  const { fitView, getNodes } = useReactFlow();\n\n  const fitSelectedNodes = async () => {\n    const selectedNodes = getNodes().filter(node => node.selected);\n\n    if (selectedNodes.length > 0) {\n      await fitView({\n        nodes: selectedNodes,\n        padding: 0.3,\n        duration: 400,\n      });\n    }\n  };\n\n  return <button onClick={fitSelectedNodes}>Fit Selected</button>;\n}\n```\n\n## Zoom Methods\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction ZoomControls() {\n  const { zoomIn, zoomOut, zoomTo, getZoom } = useReactFlow();\n\n  const handleZoomIn = () => {\n    zoomIn({ duration: 300 }); // Animated zoom\n  };\n\n  const handleZoomOut = () => {\n    zoomOut({ duration: 300 });\n  };\n\n  const handleZoomTo = () => {\n    zoomTo(1.5, { duration: 500 }); // Zoom to specific level\n  };\n\n  const handleGetZoom = () => {\n    const currentZoom = getZoom();\n    console.log('Current zoom:', currentZoom);\n  };\n\n  return (\n    <div>\n      <button onClick={handleZoomIn}>Zoom In</button>\n      <button onClick={handleZoomOut}>Zoom Out</button>\n      <button onClick={handleZoomTo}>Zoom to 1.5x</button>\n      <button onClick={handleGetZoom}>Get Zoom</button>\n    </div>\n  );\n}\n```\n\n## setViewport Method\n\nDirectly set the viewport position and zoom:\n\n```typescript\nimport { useReactFlow, Viewport } from '@xyflow/react';\n\nfunction ViewportSetter() {\n  const { setViewport, getViewport } = useReactFlow();\n\n  const handleSetViewport = () => {\n    const newViewport: Viewport = {\n      x: 100,\n      y: 100,\n      zoom: 1.2,\n    };\n\n    setViewport(newViewport, { duration: 400 });\n  };\n\n  const handleGetViewport = () => {\n    const viewport = getViewport();\n    console.log('Current viewport:', viewport);\n    // { x: 0, y: 0, zoom: 1 }\n  };\n\n  return (\n    <div>\n      <button onClick={handleSetViewport}>Set Viewport</button>\n      <button onClick={handleGetViewport}>Get Viewport</button>\n    </div>\n  );\n}\n```\n\n## setCenter Method\n\nCenter the viewport on specific coordinates:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction CenterControls() {\n  const { setCenter } = useReactFlow();\n\n  const centerOnPosition = () => {\n    setCenter(\n      250, // x coordinate\n      250, // y coordinate\n      {\n        zoom: 1.5,\n        duration: 500,\n      }\n    );\n  };\n\n  return <button onClick={centerOnPosition}>Center on (250, 250)</button>;\n}\n```\n\n## screenToFlowPosition Method\n\nConvert screen coordinates to flow coordinates:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\nimport { MouseEvent } from 'react';\n\nfunction ClickToAddNode() {\n  const { screenToFlowPosition, setNodes } = useReactFlow();\n\n  const handlePaneClick = (event: MouseEvent) => {\n    // Convert click position to flow coordinates\n    const position = screenToFlowPosition({\n      x: event.clientX,\n      y: event.clientY,\n    });\n\n    // Add node at click position\n    setNodes((nodes) => [\n      ...nodes,\n      {\n        id: `node-${Date.now()}`,\n        position,\n        data: { label: 'New Node' },\n      },\n    ]);\n  };\n\n  return <ReactFlow onPaneClick={handlePaneClick} />;\n}\n```\n\n## flowToScreenPosition Method\n\nConvert flow coordinates to screen coordinates:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction PositionConverter() {\n  const { flowToScreenPosition } = useReactFlow();\n\n  const getScreenPosition = () => {\n    const screenPos = flowToScreenPosition({\n      x: 100,\n      y: 100,\n    });\n    console.log('Screen position:', screenPos);\n  };\n\n  return <button onClick={getScreenPosition}>Get Screen Position</button>;\n}\n```\n\n## Save and Restore Viewport State\n\n```typescript\nimport { useState } from 'react';\nimport { useReactFlow, Viewport } from '@xyflow/react';\n\nfunction ViewportPersistence() {\n  const { setViewport, getViewport } = useReactFlow();\n  const [savedViewport, setSavedViewport] = useState<Viewport | null>(null);\n\n  const saveViewport = () => {\n    const viewport = getViewport();\n    setSavedViewport(viewport);\n    // Optionally save to localStorage\n    localStorage.setItem('flowViewport', JSON.stringify(viewport));\n  };\n\n  const restoreViewport = () => {\n    if (savedViewport) {\n      setViewport(savedViewport, { duration: 300 });\n    } else {\n      // Load from localStorage\n      const stored = localStorage.getItem('flowViewport');\n      if (stored) {\n        const viewport = JSON.parse(stored) as Viewport;\n        setViewport(viewport, { duration: 300 });\n      }\n    }\n  };\n\n  return (\n    <div>\n      <button onClick={saveViewport}>Save Viewport</button>\n      <button onClick={restoreViewport}>Restore Viewport</button>\n    </div>\n  );\n}\n```\n\n## Programmatic Pan to Node\n\nPan the viewport to focus on a specific node:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction PanToNode() {\n  const { getNode, setCenter } = useReactFlow();\n\n  const panToNodeById = (nodeId: string) => {\n    const node = getNode(nodeId);\n\n    if (node) {\n      const x = node.position.x + (node.width ?? 0) / 2;\n      const y = node.position.y + (node.height ?? 0) / 2;\n\n      setCenter(x, y, { zoom: 1.5, duration: 500 });\n    }\n  };\n\n  return (\n    <button onClick={() => panToNodeById('node-1')}>\n      Pan to Node 1\n    </button>\n  );\n}\n```\n\n## Controlled Viewport\n\nControl viewport directly through state:\n\n```typescript\nimport { useState, useCallback } from 'react';\nimport { ReactFlow, Viewport, useReactFlow } from '@xyflow/react';\n\nfunction ControlledViewportFlow() {\n  const [viewport, setViewport] = useState<Viewport>({ x: 0, y: 0, zoom: 1 });\n  const { fitView } = useReactFlow();\n\n  const handleViewportChange = useCallback((newViewport: Viewport) => {\n    setViewport(newViewport);\n  }, []);\n\n  const updateViewport = () => {\n    setViewport((vp) => ({ ...vp, y: vp.y + 10 }));\n  };\n\n  return (\n    <>\n      <button onClick={updateViewport}>Move Down</button>\n      <button onClick={() => fitView()}>Fit View</button>\n\n      <ReactFlow\n        nodes={nodes}\n        edges={edges}\n        viewport={viewport}\n        onViewportChange={handleViewportChange}\n      />\n    </>\n  );\n}\n```\n\n## useOnViewportChange Hook\n\nListen to viewport changes:\n\n```typescript\nimport { useOnViewportChange, Viewport } from '@xyflow/react';\nimport { useCallback } from 'react';\n\nfunction ViewportLogger() {\n  const onStart = useCallback((viewport: Viewport) => {\n    console.log('Viewport change started:', viewport);\n  }, []);\n\n  const onChange = useCallback((viewport: Viewport) => {\n    console.log('Viewport changing:', viewport);\n  }, []);\n\n  const onEnd = useCallback((viewport: Viewport) => {\n    console.log('Viewport change ended:', viewport);\n  }, []);\n\n  useOnViewportChange({\n    onStart,\n    onChange,\n    onEnd,\n  });\n\n  return null;\n}\n```\n\n## getNodesBounds Method\n\nGet bounding box of specific nodes:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction NodeBounds() {\n  const { getNodesBounds, getNodes } = useReactFlow();\n\n  const logSelectedBounds = () => {\n    const selectedNodes = getNodes().filter(n => n.selected);\n    const bounds = getNodesBounds(selectedNodes);\n\n    console.log('Bounds:', {\n      x: bounds.x,\n      y: bounds.y,\n      width: bounds.width,\n      height: bounds.height,\n    });\n  };\n\n  return <button onClick={logSelectedBounds}>Log Selected Bounds</button>;\n}\n```\n\n## viewportInitialized Flag\n\nCheck if viewport is initialized before using methods:\n\n```typescript\nimport { useReactFlow } from '@xyflow/react';\n\nfunction SafeViewportControls() {\n  const { viewportInitialized, fitView } = useReactFlow();\n\n  const handleFitView = () => {\n    if (viewportInitialized) {\n      fitView();\n    } else {\n      console.warn('Viewport not yet initialized');\n    }\n  };\n\n  return (\n    <button onClick={handleFitView} disabled={!viewportInitialized}>\n      Fit View\n    </button>\n  );\n}\n```\n",
        "skills/react-router-code-review/SKILL.md": "---\nname: react-router-code-review\ndescription: Reviews React Router code for proper data loading, mutations, error handling, and navigation patterns. Use when reviewing React Router v6.4+ code, loaders, actions, or navigation logic.\n---\n\n# React Router Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| useEffect for data, missing loaders, params | [references/data-loading.md](references/data-loading.md) |\n| Form vs useFetcher, action patterns | [references/mutations.md](references/mutations.md) |\n| Missing error boundaries, errorElement | [references/error-handling.md](references/error-handling.md) |\n| navigate() vs Link, pending states | [references/navigation.md](references/navigation.md) |\n\n## Review Checklist\n\n- [ ] Data loaded via `loader` not `useEffect`\n- [ ] Route params accessed type-safely with validation\n- [ ] Using `defer()` for parallel data fetching when appropriate\n- [ ] Mutations use `<Form>` or `useFetcher` not manual fetch\n- [ ] Actions handle both success and error cases\n- [ ] Error boundaries with `errorElement` on routes\n- [ ] Using `isRouteErrorResponse()` to check error types\n- [ ] Navigation uses `<Link>` over `navigate()` where possible\n- [ ] Pending states shown via `useNavigation()` or `fetcher.state`\n- [ ] No navigation in render (only in effects or handlers)\n\n## Valid Patterns (Do NOT Flag)\n\nThese patterns are correct React Router usage - do not report as issues:\n\n- **useEffect for client-only data** - Loaders run server-side; localStorage, window dimensions, and browser APIs must use useEffect\n- **navigate() in event handlers** - Link is for declarative navigation; navigate() is correct for imperative navigation in callbacks/handlers\n- **Type annotation on loader data** - `useLoaderData<typeof loader>()` is a type annotation, not a type assertion\n- **Empty errorElement at route level** - Route may intentionally rely on parent error boundary\n- **Form without action prop** - Posts to current URL by convention; explicit action is optional\n- **loader returning null** - Valid when data may not exist; null is a legitimate loader return value\n- **Using fetcher.data without checking fetcher.state** - May be intentional when stale data is acceptable during revalidation\n\n## Context-Sensitive Rules\n\nOnly flag these issues when the specific context applies:\n\n| Issue | Flag ONLY IF |\n|-------|--------------|\n| Missing loader | Data is available server-side (not client-only) |\n| useEffect for data fetching | Data is NOT client-only (localStorage, browser APIs, window size) |\n| Missing errorElement | No parent route in the hierarchy has an error boundary |\n| navigate() instead of Link | Navigation is NOT triggered by an event handler or conditional logic |\n\n## When to Load References\n\n- Reviewing data fetching code  data-loading.md\n- Reviewing forms or mutations  mutations.md\n- Reviewing error handling  error-handling.md\n- Reviewing navigation logic  navigation.md\n\n## Review Questions\n\n1. Is data loaded in loaders instead of effects?\n2. Are mutations using Form/action patterns?\n3. Are there error boundaries at appropriate route levels?\n4. Is navigation declarative with Link components?\n5. Are pending states properly handled?\n\n## Before Submitting Findings\n\nLoad and follow [review-verification-protocol](../review-verification-protocol/SKILL.md) before reporting any issue.\n",
        "skills/react-router-code-review/references/data-loading.md": "# Data Loading\n\n## Critical Anti-Patterns\n\n### 1. Using useEffect Instead of Loaders\n\n**Problem**: Race conditions, loading states, unnecessary client-side fetching.\n\n```tsx\n// BAD - Loading data in useEffect\nfunction UserProfile() {\n  const [user, setUser] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const { userId } = useParams();\n\n  useEffect(() => {\n    setLoading(true);\n    fetch(`/api/users/${userId}`)\n      .then(r => r.json())\n      .then(setUser)\n      .finally(() => setLoading(false));\n  }, [userId]);\n\n  if (loading) return <div>Loading...</div>;\n  return <div>{user.name}</div>;\n}\n\n// GOOD - Using loader\n// Route definition\n{\n  path: \"users/:userId\",\n  element: <UserProfile />,\n  loader: async ({ params }) => {\n    const response = await fetch(`/api/users/${params.userId}`);\n    if (!response.ok) throw new Response(\"Not Found\", { status: 404 });\n    return response.json();\n  }\n}\n\n// Component\nfunction UserProfile() {\n  const user = useLoaderData<User>();\n  return <div>{user.name}</div>;\n}\n```\n\n### 2. Unsafe Route Params Access\n\n**Problem**: Runtime errors from missing or invalid params.\n\n```tsx\n// BAD - No validation\nconst loader = async ({ params }) => {\n  // params.userId could be undefined!\n  return fetch(`/api/users/${params.userId}`);\n};\n\n// GOOD - Validate params\nconst loader = async ({ params }) => {\n  const userId = params.userId;\n  if (!userId) {\n    throw new Response(\"User ID required\", { status: 400 });\n  }\n\n  // Optional: validate format\n  if (!/^\\d+$/.test(userId)) {\n    throw new Response(\"Invalid user ID\", { status: 400 });\n  }\n\n  return fetch(`/api/users/${userId}`);\n};\n\n// BETTER - Type-safe with zod\nimport { z } from \"zod\";\n\nconst ParamsSchema = z.object({\n  userId: z.string().regex(/^\\d+$/)\n});\n\nconst loader = async ({ params }) => {\n  const { userId } = ParamsSchema.parse(params);\n  return fetch(`/api/users/${userId}`);\n};\n```\n\n### 3. Sequential Data Fetching\n\n**Problem**: Slow page loads when data can be fetched in parallel.\n\n```tsx\n// BAD - Sequential fetching\nconst loader = async ({ params }) => {\n  const user = await fetchUser(params.userId);\n  const posts = await fetchPosts(params.userId);\n  const comments = await fetchComments(params.userId);\n\n  return { user, posts, comments };\n};\n\n// GOOD - Parallel fetching\nconst loader = async ({ params }) => {\n  const [user, posts, comments] = await Promise.all([\n    fetchUser(params.userId),\n    fetchPosts(params.userId),\n    fetchComments(params.userId),\n  ]);\n\n  return { user, posts, comments };\n};\n\n// BETTER - Using defer for progressive loading\nimport { defer } from \"react-router-dom\";\n\nconst loader = async ({ params }) => {\n  // Critical data - await it\n  const user = await fetchUser(params.userId);\n\n  // Non-critical data - defer it\n  return defer({\n    user,\n    posts: fetchPosts(params.userId), // Don't await\n    comments: fetchComments(params.userId), // Don't await\n  });\n};\n\n// Component with Suspense\nfunction UserProfile() {\n  const { user, posts, comments } = useLoaderData();\n\n  return (\n    <div>\n      <h1>{user.name}</h1>\n\n      <Suspense fallback={<div>Loading posts...</div>}>\n        <Await resolve={posts}>\n          {(posts) => <PostList posts={posts} />}\n        </Await>\n      </Suspense>\n\n      <Suspense fallback={<div>Loading comments...</div>}>\n        <Await resolve={comments}>\n          {(comments) => <CommentList comments={comments} />}\n        </Await>\n      </Suspense>\n    </div>\n  );\n}\n```\n\n### 4. Not Revalidating After Mutations\n\n**Problem**: Stale data after updates, manual cache invalidation.\n\n```tsx\n// BAD - Manual refetch\nfunction UserProfile() {\n  const user = useLoaderData<User>();\n  const [localUser, setLocalUser] = useState(user);\n\n  const handleUpdate = async (data) => {\n    await fetch(`/api/users/${user.id}`, {\n      method: \"PATCH\",\n      body: JSON.stringify(data),\n    });\n\n    // Manual refetch - easy to forget!\n    const updated = await fetch(`/api/users/${user.id}`).then(r => r.json());\n    setLocalUser(updated);\n  };\n\n  return <UserForm user={localUser} onSubmit={handleUpdate} />;\n}\n\n// GOOD - Automatic revalidation\n// Action automatically triggers loader revalidation\nconst action = async ({ request, params }) => {\n  const formData = await request.formData();\n  const response = await fetch(`/api/users/${params.userId}`, {\n    method: \"PATCH\",\n    body: formData,\n  });\n\n  if (!response.ok) throw new Response(\"Update failed\", { status: 400 });\n  return redirect(`/users/${params.userId}`);\n};\n\nfunction UserProfile() {\n  const user = useLoaderData<User>();\n  // No useState needed - loader data auto-revalidates\n  return <UserForm user={user} />;\n}\n```\n\n### 5. Missing Error Handling in Loaders\n\n**Problem**: Uncaught errors, poor user experience.\n\n```tsx\n// BAD - No error handling\nconst loader = async ({ params }) => {\n  const response = await fetch(`/api/users/${params.userId}`);\n  return response.json(); // What if response is 404 or 500?\n};\n\n// GOOD - Proper error handling\nconst loader = async ({ params }) => {\n  const response = await fetch(`/api/users/${params.userId}`);\n\n  if (!response.ok) {\n    throw new Response(\"User not found\", {\n      status: response.status,\n      statusText: response.statusText\n    });\n  }\n\n  return response.json();\n};\n\n// BETTER - Detailed error responses\nconst loader = async ({ params }) => {\n  try {\n    const response = await fetch(`/api/users/${params.userId}`);\n\n    if (response.status === 404) {\n      throw new Response(\"User not found\", { status: 404 });\n    }\n\n    if (response.status === 403) {\n      throw new Response(\"You don't have permission to view this user\", {\n        status: 403\n      });\n    }\n\n    if (!response.ok) {\n      throw new Response(\"Failed to load user\", {\n        status: response.status\n      });\n    }\n\n    return response.json();\n  } catch (error) {\n    if (error instanceof Response) throw error;\n\n    // Network error or other unexpected error\n    throw new Response(\"Network error - please try again\", {\n      status: 503\n    });\n  }\n};\n```\n\n### 6. Accessing Search Params Without URLSearchParams\n\n**Problem**: Manual string parsing, inconsistent handling.\n\n```tsx\n// BAD - Manual parsing\nconst loader = async ({ request }) => {\n  const url = new URL(request.url);\n  const search = url.search.slice(1); // Remove '?'\n  const page = search.split('&').find(p => p.startsWith('page='))?.split('=')[1] || '1';\n\n  return fetchUsers(parseInt(page));\n};\n\n// GOOD - Using URLSearchParams\nconst loader = async ({ request }) => {\n  const url = new URL(request.url);\n  const page = url.searchParams.get('page') || '1';\n\n  return fetchUsers(parseInt(page, 10));\n};\n\n// BETTER - Type-safe search params\nimport { z } from \"zod\";\n\nconst SearchParamsSchema = z.object({\n  page: z.coerce.number().min(1).default(1),\n  sort: z.enum(['name', 'date', 'popular']).default('name'),\n  filter: z.string().optional(),\n});\n\nconst loader = async ({ request }) => {\n  const url = new URL(request.url);\n  const rawParams = Object.fromEntries(url.searchParams);\n  const { page, sort, filter } = SearchParamsSchema.parse(rawParams);\n\n  return fetchUsers({ page, sort, filter });\n};\n```\n\n## Review Questions\n\n1. Is all route data loaded via loaders, not useEffect?\n2. Are route params validated before use?\n3. Are independent data fetches executed in parallel?\n4. Is defer() used for non-critical data?\n5. Do loaders throw proper Response objects on errors?\n6. Are search params parsed with URLSearchParams?\n",
        "skills/react-router-code-review/references/error-handling.md": "# Error Handling\n\n## Critical Anti-Patterns\n\n### 1. Missing Error Boundaries\n\n**Problem**: Entire app crashes on route errors, poor UX.\n\n```tsx\n// BAD - No error handling\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    children: [\n      {\n        path: \"users/:userId\",\n        element: <UserProfile />,\n        loader: async ({ params }) => {\n          // If this fails, entire app shows error\n          return fetch(`/api/users/${params.userId}`).then(r => r.json());\n        }\n      }\n    ]\n  }\n]);\n\n// GOOD - Error boundaries at route level\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    errorElement: <RootErrorBoundary />, // Catch all errors\n    children: [\n      {\n        path: \"users/:userId\",\n        element: <UserProfile />,\n        errorElement: <UserErrorBoundary />, // Scoped error handling\n        loader: async ({ params }) => {\n          const response = await fetch(`/api/users/${params.userId}`);\n          if (!response.ok) {\n            throw new Response(\"User not found\", { status: 404 });\n          }\n          return response.json();\n        }\n      }\n    ]\n  }\n]);\n\n// Error boundary component\nfunction UserErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    if (error.status === 404) {\n      return <div>User not found</div>;\n    }\n    if (error.status === 403) {\n      return <div>You don't have permission to view this user</div>;\n    }\n  }\n\n  return <div>Something went wrong loading this user</div>;\n}\n```\n\n### 2. Not Using isRouteErrorResponse\n\n**Problem**: Unsafe error access, runtime errors in error handlers.\n\n```tsx\n// BAD - Unsafe error access\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  // error might not have these properties!\n  return (\n    <div>\n      <h1>Error {error.status}</h1>\n      <p>{error.statusText}</p>\n      <p>{error.data}</p>\n    </div>\n  );\n}\n\n// GOOD - Type-safe error checking\nimport { isRouteErrorResponse } from 'react-router-dom';\n\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    // Now we know error has status, statusText, data\n    return (\n      <div>\n        <h1>Error {error.status}</h1>\n        <p>{error.statusText}</p>\n        {typeof error.data === 'string' && <p>{error.data}</p>}\n      </div>\n    );\n  }\n\n  if (error instanceof Error) {\n    return (\n      <div>\n        <h1>Unexpected Error</h1>\n        <p>{error.message}</p>\n        {import.meta.env.DEV && <pre>{error.stack}</pre>}\n      </div>\n    );\n  }\n\n  return <div>An unknown error occurred</div>;\n}\n```\n\n### 3. Throwing Raw Errors Instead of Responses\n\n**Problem**: Missing status codes, inconsistent error format.\n\n```tsx\n// BAD - Throwing raw errors\nconst loader = async ({ params }) => {\n  const user = await db.user.findUnique({\n    where: { id: params.userId }\n  });\n\n  if (!user) {\n    throw new Error('User not found'); // No status code!\n  }\n\n  if (!user.isPublic && !currentUser) {\n    throw new Error('Unauthorized'); // Should be 403, not 500!\n  }\n\n  return user;\n};\n\n// GOOD - Throwing Response objects\nconst loader = async ({ params }) => {\n  const user = await db.user.findUnique({\n    where: { id: params.userId }\n  });\n\n  if (!user) {\n    throw new Response('User not found', { status: 404 });\n  }\n\n  if (!user.isPublic && !currentUser) {\n    throw new Response('You must be logged in to view this profile', {\n      status: 403\n    });\n  }\n\n  return user;\n};\n\n// BETTER - Using json() helper for structured errors\nimport { json } from 'react-router-dom';\n\nconst loader = async ({ params }) => {\n  const user = await db.user.findUnique({\n    where: { id: params.userId }\n  });\n\n  if (!user) {\n    throw json(\n      { message: 'User not found', userId: params.userId },\n      { status: 404 }\n    );\n  }\n\n  if (!user.isPublic && !currentUser) {\n    throw json(\n      { message: 'Login required', redirectTo: `/login?return=/users/${params.userId}` },\n      { status: 403 }\n    );\n  }\n\n  return user;\n};\n\n// Error boundary using structured error\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    if (error.status === 403 && error.data?.redirectTo) {\n      return (\n        <div>\n          <p>{error.data.message}</p>\n          <Link to={error.data.redirectTo}>Log in</Link>\n        </div>\n      );\n    }\n\n    if (error.status === 404) {\n      return <div>{error.data.message}</div>;\n    }\n  }\n\n  return <div>Something went wrong</div>;\n}\n```\n\n### 4. Not Differentiating Error Types\n\n**Problem**: Same handling for different errors, poor UX.\n\n```tsx\n// BAD - Generic error handling\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  // Everything gets same treatment\n  return <div>Error: {String(error)}</div>;\n}\n\n// GOOD - Specific handling per error type\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  // Network/fetch errors\n  if (error instanceof TypeError && error.message.includes('fetch')) {\n    return (\n      <div className=\"error\">\n        <h1>Network Error</h1>\n        <p>Unable to connect to the server. Please check your connection.</p>\n        <button onClick={() => window.location.reload()}>Retry</button>\n      </div>\n    );\n  }\n\n  // Route errors\n  if (isRouteErrorResponse(error)) {\n    if (error.status === 404) {\n      return (\n        <div className=\"error\">\n          <h1>Page Not Found</h1>\n          <p>The page you're looking for doesn't exist.</p>\n          <Link to=\"/\">Go home</Link>\n        </div>\n      );\n    }\n\n    if (error.status === 403) {\n      return (\n        <div className=\"error\">\n          <h1>Access Denied</h1>\n          <p>You don't have permission to access this resource.</p>\n          <Link to=\"/login\">Log in</Link>\n        </div>\n      );\n    }\n\n    if (error.status === 500) {\n      return (\n        <div className=\"error\">\n          <h1>Server Error</h1>\n          <p>Something went wrong on our end. Please try again later.</p>\n        </div>\n      );\n    }\n\n    // Generic HTTP error\n    return (\n      <div className=\"error\">\n        <h1>Error {error.status}</h1>\n        <p>{error.statusText}</p>\n      </div>\n    );\n  }\n\n  // JavaScript errors\n  if (error instanceof Error) {\n    return (\n      <div className=\"error\">\n        <h1>Unexpected Error</h1>\n        <p>{error.message}</p>\n        {import.meta.env.DEV && (\n          <details>\n            <summary>Stack trace</summary>\n            <pre>{error.stack}</pre>\n          </details>\n        )}\n      </div>\n    );\n  }\n\n  // Unknown error\n  return (\n    <div className=\"error\">\n      <h1>Unknown Error</h1>\n      <p>An unexpected error occurred.</p>\n    </div>\n  );\n}\n```\n\n### 5. Missing Root Error Boundary\n\n**Problem**: Uncaught errors bubble to browser, blank screen.\n\n```tsx\n// BAD - No root error boundary\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    children: [\n      // children routes...\n    ]\n  }\n]);\n\n// GOOD - Root error boundary catches everything\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    errorElement: <RootErrorBoundary />,\n    children: [\n      {\n        path: \"users\",\n        element: <Users />,\n        errorElement: <UsersErrorBoundary />, // Scoped\n      },\n      // other routes...\n    ]\n  }\n]);\n\n// Root error boundary with full-page layout\nfunction RootErrorBoundary() {\n  const error = useRouteError();\n\n  return (\n    <html lang=\"en\">\n      <head>\n        <title>Error - My App</title>\n        <meta charSet=\"utf-8\" />\n        <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n      </head>\n      <body>\n        <div className=\"error-page\">\n          <header>\n            <Link to=\"/\">\n              <img src=\"/logo.png\" alt=\"My App\" />\n            </Link>\n          </header>\n          <main>\n            {isRouteErrorResponse(error) ? (\n              <>\n                <h1>Error {error.status}</h1>\n                <p>{error.statusText}</p>\n              </>\n            ) : error instanceof Error ? (\n              <>\n                <h1>Unexpected Error</h1>\n                <p>{error.message}</p>\n              </>\n            ) : (\n              <h1>Unknown Error</h1>\n            )}\n            <Link to=\"/\">Go back home</Link>\n          </main>\n        </div>\n      </body>\n    </html>\n  );\n}\n```\n\n### 6. Not Logging Errors\n\n**Problem**: No visibility into production errors, hard to debug.\n\n```tsx\n// BAD - Silent errors\nfunction ErrorBoundary() {\n  const error = useRouteError();\n  return <div>Error occurred</div>;\n}\n\n// GOOD - Errors logged to monitoring service\nfunction ErrorBoundary() {\n  const error = useRouteError();\n\n  React.useEffect(() => {\n    // Log to error tracking service\n    if (isRouteErrorResponse(error)) {\n      logError({\n        type: 'RouteError',\n        status: error.status,\n        statusText: error.statusText,\n        data: error.data,\n      });\n    } else if (error instanceof Error) {\n      logError({\n        type: 'JavaScriptError',\n        message: error.message,\n        stack: error.stack,\n      });\n    } else {\n      logError({\n        type: 'UnknownError',\n        error: String(error),\n      });\n    }\n  }, [error]);\n\n  return <ErrorDisplay error={error} />;\n}\n\n// BETTER - Centralized error logging\nfunction useErrorLogging(error: unknown) {\n  React.useEffect(() => {\n    // Don't log in development\n    if (import.meta.env.DEV) return;\n\n    // Send to monitoring service (Sentry, etc.)\n    if (isRouteErrorResponse(error)) {\n      window.analytics?.track('Route Error', {\n        status: error.status,\n        statusText: error.statusText,\n        path: window.location.pathname,\n      });\n    } else if (error instanceof Error) {\n      window.analytics?.track('JavaScript Error', {\n        message: error.message,\n        stack: error.stack,\n        path: window.location.pathname,\n      });\n    }\n  }, [error]);\n}\n\nfunction ErrorBoundary() {\n  const error = useRouteError();\n  useErrorLogging(error);\n\n  return <ErrorDisplay error={error} />;\n}\n```\n\n## Review Questions\n\n1. Does every route have an errorElement?\n2. Is isRouteErrorResponse used to check error types?\n3. Are loaders/actions throwing Response objects with status codes?\n4. Are different error types handled differently?\n5. Is there a root error boundary?\n6. Are errors logged to a monitoring service?\n",
        "skills/react-router-code-review/references/mutations.md": "# Mutations\n\n## Critical Anti-Patterns\n\n### 1. Manual Form Submission with fetch\n\n**Problem**: Missing navigation state, manual revalidation, no progressive enhancement.\n\n```tsx\n// BAD - Manual fetch in handler\nfunction CreateUser() {\n  const [loading, setLoading] = useState(false);\n  const navigate = useNavigate();\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n\n    const formData = new FormData(e.target);\n    const response = await fetch('/api/users', {\n      method: 'POST',\n      body: JSON.stringify(Object.fromEntries(formData)),\n    });\n\n    if (response.ok) {\n      navigate('/users');\n    } else {\n      alert('Error creating user');\n    }\n    setLoading(false);\n  };\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <input name=\"name\" />\n      <button disabled={loading}>\n        {loading ? 'Creating...' : 'Create'}\n      </button>\n    </form>\n  );\n}\n\n// GOOD - Using Form and action\n// Route definition\n{\n  path: \"users/new\",\n  element: <CreateUser />,\n  action: async ({ request }) => {\n    const formData = await request.formData();\n    const response = await fetch('/api/users', {\n      method: 'POST',\n      body: formData,\n    });\n\n    if (!response.ok) {\n      return { error: 'Failed to create user' };\n    }\n\n    return redirect('/users');\n  }\n}\n\n// Component\nimport { Form, useNavigation, useActionData } from 'react-router-dom';\n\nfunction CreateUser() {\n  const navigation = useNavigation();\n  const actionData = useActionData();\n  const isSubmitting = navigation.state === 'submitting';\n\n  return (\n    <Form method=\"post\">\n      <input name=\"name\" />\n      {actionData?.error && <div className=\"error\">{actionData.error}</div>}\n      <button disabled={isSubmitting}>\n        {isSubmitting ? 'Creating...' : 'Create'}\n      </button>\n    </Form>\n  );\n}\n```\n\n### 2. Using Form When useFetcher is Appropriate\n\n**Problem**: Unnecessary navigation, losing current page state.\n\n```tsx\n// BAD - Form causes navigation away from current page\nfunction TodoList() {\n  const todos = useLoaderData<Todo[]>();\n\n  return (\n    <div>\n      {todos.map(todo => (\n        <div key={todo.id}>\n          <span>{todo.text}</span>\n          {/* This will navigate away! */}\n          <Form method=\"post\" action={`/todos/${todo.id}/toggle`}>\n            <button>Toggle</button>\n          </Form>\n        </div>\n      ))}\n    </div>\n  );\n}\n\n// GOOD - useFetcher stays on current page\nimport { useFetcher } from 'react-router-dom';\n\nfunction TodoList() {\n  const todos = useLoaderData<Todo[]>();\n\n  return (\n    <div>\n      {todos.map(todo => (\n        <TodoItem key={todo.id} todo={todo} />\n      ))}\n    </div>\n  );\n}\n\nfunction TodoItem({ todo }) {\n  const fetcher = useFetcher();\n\n  // Optimistic UI - show state immediately\n  const isComplete = fetcher.formData\n    ? fetcher.formData.get('complete') === 'true'\n    : todo.complete;\n\n  return (\n    <div>\n      <span style={{ textDecoration: isComplete ? 'line-through' : 'none' }}>\n        {todo.text}\n      </span>\n      <fetcher.Form method=\"post\" action={`/todos/${todo.id}/toggle`}>\n        <input type=\"hidden\" name=\"complete\" value={String(!isComplete)} />\n        <button disabled={fetcher.state !== 'idle'}>\n          {fetcher.state !== 'idle' ? 'Toggling...' : 'Toggle'}\n        </button>\n      </fetcher.Form>\n    </div>\n  );\n}\n```\n\n### 3. Not Validating Action Data\n\n**Problem**: Runtime errors, poor error messages.\n\n```tsx\n// BAD - No validation\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n\n  // What if name is missing or invalid?\n  const name = formData.get('name');\n  const email = formData.get('email');\n\n  await createUser({ name, email });\n  return redirect('/users');\n};\n\n// GOOD - Validation with helpful errors\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n  const name = formData.get('name');\n  const email = formData.get('email');\n\n  const errors = {};\n\n  if (!name || typeof name !== 'string' || name.trim().length === 0) {\n    errors.name = 'Name is required';\n  }\n\n  if (!email || typeof email !== 'string') {\n    errors.email = 'Email is required';\n  } else if (!/^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(email)) {\n    errors.email = 'Invalid email format';\n  }\n\n  if (Object.keys(errors).length > 0) {\n    return { errors };\n  }\n\n  await createUser({ name, email });\n  return redirect('/users');\n};\n\n// BETTER - Schema validation\nimport { z } from 'zod';\n\nconst CreateUserSchema = z.object({\n  name: z.string().min(1, 'Name is required').max(100),\n  email: z.string().email('Invalid email format'),\n});\n\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n  const data = Object.fromEntries(formData);\n\n  try {\n    const validated = CreateUserSchema.parse(data);\n    await createUser(validated);\n    return redirect('/users');\n  } catch (error) {\n    if (error instanceof z.ZodError) {\n      return {\n        errors: error.flatten().fieldErrors\n      };\n    }\n    throw error;\n  }\n};\n\n// Component using validation errors\nfunction CreateUser() {\n  const actionData = useActionData<{ errors?: Record<string, string[]> }>();\n\n  return (\n    <Form method=\"post\">\n      <div>\n        <input name=\"name\" />\n        {actionData?.errors?.name && (\n          <span className=\"error\">{actionData.errors.name[0]}</span>\n        )}\n      </div>\n      <div>\n        <input name=\"email\" type=\"email\" />\n        {actionData?.errors?.email && (\n          <span className=\"error\">{actionData.errors.email[0]}</span>\n        )}\n      </div>\n      <button>Create User</button>\n    </Form>\n  );\n}\n```\n\n### 4. Missing Optimistic UI\n\n**Problem**: Slow perceived performance, no immediate feedback.\n\n```tsx\n// BAD - No optimistic update\nfunction LikeButton({ postId, liked }: { postId: string; liked: boolean }) {\n  const fetcher = useFetcher();\n\n  return (\n    <fetcher.Form method=\"post\" action={`/posts/${postId}/like`}>\n      <button>\n        {/* Only updates after server responds */}\n        {liked ? '' : ''}\n      </button>\n    </fetcher.Form>\n  );\n}\n\n// GOOD - Optimistic UI\nfunction LikeButton({ postId, liked }: { postId: string; liked: boolean }) {\n  const fetcher = useFetcher();\n\n  // Show optimistic state immediately\n  const optimisticLiked = fetcher.formData\n    ? fetcher.formData.get('liked') === 'true'\n    : liked;\n\n  return (\n    <fetcher.Form method=\"post\" action={`/posts/${postId}/like`}>\n      <input type=\"hidden\" name=\"liked\" value={String(!optimisticLiked)} />\n      <button disabled={fetcher.state !== 'idle'}>\n        {optimisticLiked ? '' : ''}\n      </button>\n    </fetcher.Form>\n  );\n}\n\n// BETTER - Optimistic UI with count\nfunction LikeButton({\n  postId,\n  liked,\n  likeCount\n}: {\n  postId: string;\n  liked: boolean;\n  likeCount: number;\n}) {\n  const fetcher = useFetcher();\n\n  const optimisticLiked = fetcher.formData\n    ? fetcher.formData.get('liked') === 'true'\n    : liked;\n\n  const optimisticCount = fetcher.formData\n    ? optimisticLiked\n      ? likeCount + 1\n      : likeCount - 1\n    : likeCount;\n\n  return (\n    <fetcher.Form method=\"post\" action={`/posts/${postId}/like`}>\n      <input type=\"hidden\" name=\"liked\" value={String(!optimisticLiked)} />\n      <button disabled={fetcher.state !== 'idle'}>\n        {optimisticLiked ? '' : ''} {optimisticCount}\n      </button>\n    </fetcher.Form>\n  );\n}\n```\n\n### 5. Not Handling Action Errors\n\n**Problem**: Silent failures, poor error UX.\n\n```tsx\n// BAD - No error handling\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n  // If this throws, user sees error boundary\n  await createUser(Object.fromEntries(formData));\n  return redirect('/users');\n};\n\n// GOOD - Graceful error handling\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n\n  try {\n    await createUser(Object.fromEntries(formData));\n    return redirect('/users');\n  } catch (error) {\n    // Return error to show in form, not error boundary\n    if (error instanceof Error) {\n      return { error: error.message };\n    }\n    return { error: 'An unexpected error occurred' };\n  }\n};\n\n// BETTER - Typed errors with status\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n\n  try {\n    await createUser(Object.fromEntries(formData));\n    return redirect('/users');\n  } catch (error) {\n    if (error instanceof Response) {\n      // API returned error response\n      const body = await error.json();\n      return { error: body.message, status: error.status };\n    }\n\n    if (error instanceof Error) {\n      return { error: error.message };\n    }\n\n    return { error: 'An unexpected error occurred' };\n  }\n};\n\n// Component showing errors\nfunction CreateUser() {\n  const actionData = useActionData<{ error?: string; status?: number }>();\n\n  return (\n    <div>\n      {actionData?.error && (\n        <div className={actionData.status === 400 ? 'warning' : 'error'}>\n          {actionData.error}\n        </div>\n      )}\n      <Form method=\"post\">\n        {/* form fields */}\n      </Form>\n    </div>\n  );\n}\n```\n\n### 6. Action Without Intent\n\n**Problem**: Multiple actions in one endpoint, unclear intent.\n\n```tsx\n// BAD - Multiple actions in one action function\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n  const action = formData.get('_action');\n\n  if (action === 'create') {\n    // create logic\n  } else if (action === 'update') {\n    // update logic\n  } else if (action === 'delete') {\n    // delete logic\n  }\n\n  return redirect('/users');\n};\n\n// GOOD - Separate action routes\n// Route definition\n{\n  path: \"users\",\n  children: [\n    {\n      path: \"new\",\n      element: <CreateUser />,\n      action: createUserAction,\n    },\n    {\n      path: \":userId/edit\",\n      element: <EditUser />,\n      action: updateUserAction,\n    },\n    {\n      path: \":userId/delete\",\n      action: deleteUserAction,\n    }\n  ]\n}\n\n// ACCEPTABLE - Multiple intents with clear intent field\nconst action = async ({ request }) => {\n  const formData = await request.formData();\n  const intent = formData.get('intent');\n\n  switch (intent) {\n    case 'archive':\n      return handleArchive(formData);\n    case 'unarchive':\n      return handleUnarchive(formData);\n    default:\n      throw new Response('Invalid intent', { status: 400 });\n  }\n};\n\n// Component making intent clear\n<fetcher.Form method=\"post\">\n  <input type=\"hidden\" name=\"intent\" value=\"archive\" />\n  <button>Archive</button>\n</fetcher.Form>\n```\n\n## Review Questions\n\n1. Are mutations using Form/fetcher.Form instead of manual fetch?\n2. Is useFetcher used for actions that shouldn't navigate?\n3. Are action inputs validated before processing?\n4. Are optimistic UI updates shown for immediate feedback?\n5. Do actions handle and return errors gracefully?\n6. Is action intent clear and single-purpose?\n",
        "skills/react-router-code-review/references/navigation.md": "# Navigation\n\n## Critical Anti-Patterns\n\n### 1. Using navigate() Instead of Link\n\n**Problem**: Missing accessibility, no progressive enhancement, can't open in new tab.\n\n```tsx\n// BAD - navigate() for user-initiated navigation\nfunction UserCard({ userId }: { userId: string }) {\n  const navigate = useNavigate();\n\n  return (\n    <div onClick={() => navigate(`/users/${userId}`)}>\n      <h3>User {userId}</h3>\n    </div>\n  );\n}\n\n// Problems:\n// - Can't right-click to open in new tab\n// - Can't Cmd+Click to open in new tab\n// - Screen readers don't know it's a link\n// - No keyboard navigation\n\n// GOOD - Use Link for navigation\nfunction UserCard({ userId }: { userId: string }) {\n  return (\n    <Link to={`/users/${userId}`} className=\"user-card\">\n      <h3>User {userId}</h3>\n    </Link>\n  );\n}\n\n// Benefits:\n// - Right-click works\n// - Cmd/Ctrl+Click works\n// - Accessible to screen readers\n// - Tab navigation works\n// - Shows URL on hover\n```\n\n### 2. Imperative Navigation in Render\n\n**Problem**: Navigation happens during render, causes infinite loops.\n\n```tsx\n// BAD - navigate() during render\nfunction ProtectedRoute({ children }: { children: React.ReactNode }) {\n  const user = useLoaderData<User | null>();\n  const navigate = useNavigate();\n\n  if (!user) {\n    navigate('/login'); // BAD: navigate during render!\n    return null;\n  }\n\n  return <>{children}</>;\n}\n\n// GOOD - Navigate in effect\nfunction ProtectedRoute({ children }: { children: React.ReactNode }) {\n  const user = useLoaderData<User | null>();\n  const navigate = useNavigate();\n\n  React.useEffect(() => {\n    if (!user) {\n      navigate('/login');\n    }\n  }, [user, navigate]);\n\n  if (!user) {\n    return <div>Redirecting...</div>;\n  }\n\n  return <>{children}</>;\n}\n\n// BETTER - Handle in loader\nconst loader = async ({ request }) => {\n  const user = await getUser(request);\n\n  if (!user) {\n    // Redirect before component renders\n    throw redirect('/login');\n  }\n\n  return user;\n};\n```\n\n### 3. Missing Pending UI States\n\n**Problem**: No feedback during navigation, feels broken.\n\n```tsx\n// BAD - No loading state\nfunction UserList() {\n  const users = useLoaderData<User[]>();\n\n  return (\n    <div>\n      <h1>Users</h1>\n      <ul>\n        {users.map(user => (\n          <li key={user.id}>\n            <Link to={`/users/${user.id}`}>{user.name}</Link>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\n// User clicks link, nothing happens for 2 seconds, then page changes\n// Bad UX!\n\n// GOOD - Show loading state\nimport { useNavigation } from 'react-router-dom';\n\nfunction UserList() {\n  const users = useLoaderData<User[]>();\n  const navigation = useNavigation();\n\n  return (\n    <div>\n      <h1>Users</h1>\n      {navigation.state === 'loading' && (\n        <div className=\"loading-bar\" />\n      )}\n      <ul className={navigation.state === 'loading' ? 'opacity-50' : ''}>\n        {users.map(user => (\n          <li key={user.id}>\n            <Link to={`/users/${user.id}`}>{user.name}</Link>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\n// BETTER - Global loading indicator\nfunction Root() {\n  const navigation = useNavigation();\n\n  return (\n    <div>\n      {navigation.state !== 'idle' && (\n        <div className=\"global-loading-bar\">\n          Loading...\n        </div>\n      )}\n\n      <nav>\n        <Link to=\"/\">Home</Link>\n        <Link to=\"/users\">Users</Link>\n      </nav>\n\n      <main className={navigation.state === 'loading' ? 'loading' : ''}>\n        <Outlet />\n      </main>\n    </div>\n  );\n}\n```\n\n### 4. Not Using NavLink for Active Styles\n\n**Problem**: Manual active state management, inconsistent UI.\n\n```tsx\n// BAD - Manual active state\nfunction Navigation() {\n  const location = useLocation();\n\n  return (\n    <nav>\n      <Link\n        to=\"/\"\n        className={location.pathname === '/' ? 'active' : ''}\n      >\n        Home\n      </Link>\n      <Link\n        to=\"/users\"\n        className={location.pathname.startsWith('/users') ? 'active' : ''}\n      >\n        Users\n      </Link>\n      <Link\n        to=\"/settings\"\n        className={location.pathname === '/settings' ? 'active' : ''}\n      >\n        Settings\n      </Link>\n    </nav>\n  );\n}\n\n// GOOD - NavLink with className function\nimport { NavLink } from 'react-router-dom';\n\nfunction Navigation() {\n  return (\n    <nav>\n      <NavLink\n        to=\"/\"\n        end // Only match exact path\n        className={({ isActive }) => isActive ? 'active' : ''}\n      >\n        Home\n      </NavLink>\n      <NavLink\n        to=\"/users\"\n        className={({ isActive }) => isActive ? 'active' : ''}\n      >\n        Users\n      </NavLink>\n      <NavLink\n        to=\"/settings\"\n        className={({ isActive }) => isActive ? 'active' : ''}\n      >\n        Settings\n      </NavLink>\n    </nav>\n  );\n}\n\n// BETTER - NavLink with style function\nfunction Navigation() {\n  const activeStyle = {\n    fontWeight: 'bold',\n    color: 'var(--primary)',\n    borderBottom: '2px solid var(--primary)',\n  };\n\n  return (\n    <nav>\n      <NavLink\n        to=\"/\"\n        end\n        style={({ isActive }) => isActive ? activeStyle : undefined}\n      >\n        Home\n      </NavLink>\n      <NavLink\n        to=\"/users\"\n        style={({ isActive }) => isActive ? activeStyle : undefined}\n      >\n        Users\n      </NavLink>\n    </nav>\n  );\n}\n```\n\n### 5. Not Preserving Search Params on Navigation\n\n**Problem**: Lost state, broken URLs, poor UX.\n\n```tsx\n// BAD - Navigation loses search params\nfunction UserFilters() {\n  return (\n    <div>\n      {/* Current URL: /users?sort=name&filter=active */}\n      {/* After clicking, URL becomes: /users?sort=date (filter lost!) */}\n      <Link to=\"/users?sort=date\">Sort by date</Link>\n    </div>\n  );\n}\n\n// GOOD - Preserve existing search params\nfunction UserFilters() {\n  const [searchParams] = useSearchParams();\n\n  const getSortLink = (sort: string) => {\n    const params = new URLSearchParams(searchParams);\n    params.set('sort', sort);\n    return `/users?${params.toString()}`;\n  };\n\n  return (\n    <div>\n      <Link to={getSortLink('date')}>Sort by date</Link>\n      <Link to={getSortLink('name')}>Sort by name</Link>\n    </div>\n  );\n}\n\n// BETTER - Reusable hook\nfunction useSearchParamsWithPreserve() {\n  const [searchParams, setSearchParams] = useSearchParams();\n\n  const updateSearchParam = React.useCallback(\n    (key: string, value: string | null) => {\n      setSearchParams(prev => {\n        const params = new URLSearchParams(prev);\n        if (value === null) {\n          params.delete(key);\n        } else {\n          params.set(key, value);\n        }\n        return params;\n      });\n    },\n    [setSearchParams]\n  );\n\n  return [searchParams, updateSearchParam] as const;\n}\n\nfunction UserFilters() {\n  const [searchParams, updateSearchParam] = useSearchParamsWithPreserve();\n\n  return (\n    <div>\n      <button onClick={() => updateSearchParam('sort', 'date')}>\n        Sort by date\n      </button>\n      <button onClick={() => updateSearchParam('sort', 'name')}>\n        Sort by name\n      </button>\n    </div>\n  );\n}\n```\n\n### 6. Blocking Navigation Without Confirmation\n\n**Problem**: Lost unsaved changes, data loss.\n\n```tsx\n// BAD - No confirmation on navigation\nfunction EditUser() {\n  const [formData, setFormData] = useState({});\n  const [isDirty, setIsDirty] = useState(false);\n\n  // User can navigate away and lose changes!\n  return (\n    <form>\n      <input\n        onChange={(e) => {\n          setFormData({ ...formData, name: e.target.value });\n          setIsDirty(true);\n        }}\n      />\n    </form>\n  );\n}\n\n// GOOD - Block navigation with confirmation\nimport { useBlocker } from 'react-router-dom';\n\nfunction EditUser() {\n  const [formData, setFormData] = useState({});\n  const [isDirty, setIsDirty] = useState(false);\n\n  // Block navigation if form is dirty\n  const blocker = useBlocker(\n    ({ currentLocation, nextLocation }) =>\n      isDirty && currentLocation.pathname !== nextLocation.pathname\n  );\n\n  return (\n    <>\n      {blocker.state === 'blocked' && (\n        <div className=\"modal\">\n          <p>You have unsaved changes. Are you sure you want to leave?</p>\n          <button onClick={() => blocker.proceed()}>Leave</button>\n          <button onClick={() => blocker.reset()}>Stay</button>\n        </div>\n      )}\n\n      <form>\n        <input\n          onChange={(e) => {\n            setFormData({ ...formData, name: e.target.value });\n            setIsDirty(true);\n          }}\n        />\n      </form>\n    </>\n  );\n}\n\n// BETTER - Also handle browser navigation\nfunction EditUser() {\n  const [formData, setFormData] = useState({});\n  const [isDirty, setIsDirty] = useState(false);\n\n  const blocker = useBlocker(\n    ({ currentLocation, nextLocation }) =>\n      isDirty && currentLocation.pathname !== nextLocation.pathname\n  );\n\n  // Handle browser back/forward, refresh, close\n  React.useEffect(() => {\n    const handleBeforeUnload = (e: BeforeUnloadEvent) => {\n      if (isDirty) {\n        e.preventDefault();\n        e.returnValue = ''; // Required for Chrome\n      }\n    };\n\n    window.addEventListener('beforeunload', handleBeforeUnload);\n    return () => window.removeEventListener('beforeunload', handleBeforeUnload);\n  }, [isDirty]);\n\n  return (\n    <>\n      {blocker.state === 'blocked' && (\n        <ConfirmationModal\n          onConfirm={() => blocker.proceed()}\n          onCancel={() => blocker.reset()}\n        />\n      )}\n      <form>{/* form fields */}</form>\n    </>\n  );\n}\n```\n\n### 7. Not Using Relative Paths\n\n**Problem**: Brittle routes, hard to refactor.\n\n```tsx\n// BAD - Absolute paths everywhere\n// Route: /projects/:projectId/tasks/:taskId\n\nfunction TaskDetail() {\n  const { projectId, taskId } = useParams();\n\n  return (\n    <div>\n      <Link to={`/projects/${projectId}/tasks`}>Back to tasks</Link>\n      <Link to={`/projects/${projectId}/tasks/${taskId}/edit`}>Edit</Link>\n      <Link to={`/projects/${projectId}`}>Back to project</Link>\n    </div>\n  );\n}\n\n// If you change the route structure, all these links break!\n\n// GOOD - Relative paths\nfunction TaskDetail() {\n  return (\n    <div>\n      {/* Go up one level */}\n      <Link to=\"..\">Back to tasks</Link>\n\n      {/* Stay at current level, append /edit */}\n      <Link to=\"edit\">Edit</Link>\n\n      {/* Go up two levels */}\n      <Link to=\"../..\">Back to project</Link>\n    </div>\n  );\n}\n\n// BETTER - Mix relative and absolute as appropriate\nfunction TaskDetail() {\n  const { projectId } = useParams();\n\n  return (\n    <div>\n      {/* Relative for sibling/parent routes */}\n      <Link to=\"..\">Back to tasks</Link>\n      <Link to=\"edit\">Edit</Link>\n\n      {/* Absolute for cross-section navigation */}\n      <Link to=\"/\">Home</Link>\n      <Link to=\"/settings\">Settings</Link>\n\n      {/* Template when you need params */}\n      <Link to={`/projects/${projectId}/settings`}>Project Settings</Link>\n    </div>\n  );\n}\n```\n\n## Review Questions\n\n1. Are Links used for navigation instead of navigate()?\n2. Is navigate() only called in effects or handlers, not render?\n3. Are pending states shown during navigation?\n4. Is NavLink used for navigation with active states?\n5. Are search params preserved when updating URLs?\n6. Are unsaved changes protected with useBlocker?\n7. Are relative paths used within route hierarchies?\n",
        "skills/react-router-v7/ACTIONS.md": "# Actions and Mutations\n\n## Basic Action Pattern\n\n```tsx\n{\n  path: \"/projects/:id\",\n  action: async ({ request, params }) => {\n    const formData = await request.formData();\n    const title = formData.get(\"title\");\n    await updateProject(params.id, { title });\n    return { success: true };\n  },\n  Component: Project,\n}\n```\n\n## Form Submission\n\n```tsx\nfunction Project() {\n  const actionData = useActionData();\n\n  return (\n    <Form method=\"post\">\n      <input type=\"text\" name=\"title\" />\n      <button type=\"submit\">Save</button>\n      {actionData?.success && <p>Saved!</p>}\n    </Form>\n  );\n}\n```\n\n## Redirect After Action\n\n```tsx\nimport { redirect } from \"react-router\";\n\nexport async function action({ request }) {\n  const formData = await request.formData();\n  const project = await createProject(formData);\n  return redirect(`/projects/${project.id}`);\n}\n```\n\n## Form Validation\n\n```tsx\nimport { data } from \"react-router\";\n\nexport async function action({ request }: Route.ActionArgs) {\n  const formData = await request.formData();\n  const email = String(formData.get(\"email\"));\n  const password = String(formData.get(\"password\"));\n\n  const errors: Record<string, string> = {};\n\n  if (!email.includes(\"@\")) {\n    errors.email = \"Invalid email address\";\n  }\n  if (password.length < 12) {\n    errors.password = \"Password must be at least 12 characters\";\n  }\n\n  if (Object.keys(errors).length > 0) {\n    return data({ errors }, { status: 400 }); // 400 prevents revalidation\n  }\n\n  return redirect(\"/dashboard\");\n}\n\nexport default function Signup() {\n  const fetcher = useFetcher();\n  const errors = fetcher.data?.errors;\n\n  return (\n    <fetcher.Form method=\"post\">\n      <input type=\"email\" name=\"email\" />\n      {errors?.email && <em>{errors.email}</em>}\n\n      <input type=\"password\" name=\"password\" />\n      {errors?.password && <em>{errors.password}</em>}\n\n      <button type=\"submit\">Sign Up</button>\n    </fetcher.Form>\n  );\n}\n```\n\n## Fetchers (Non-Navigation Mutations)\n\nUse fetchers when you DON'T want URL changes:\n\n```tsx\nimport { useFetcher } from \"react-router\";\n\nfunction TodoItem({ todo }) {\n  const fetcher = useFetcher();\n  const isDeleting = fetcher.state !== \"idle\";\n\n  return (\n    <li>\n      <span>{todo.title}</span>\n      <fetcher.Form method=\"post\" action=\"/todos/delete\">\n        <input type=\"hidden\" name=\"id\" value={todo.id} />\n        <button type=\"submit\" disabled={isDeleting}>\n          {isDeleting ? \"Deleting...\" : \"Delete\"}\n        </button>\n      </fetcher.Form>\n    </li>\n  );\n}\n```\n\n## Optimistic UI with Fetchers\n\n```tsx\nfunction Component() {\n  const data = useLoaderData();\n  const fetcher = useFetcher();\n\n  // Show optimistic state while submitting\n  const title = fetcher.formData?.get(\"title\") || data.title;\n\n  return (\n    <div>\n      <h1>{title}</h1>\n      <fetcher.Form method=\"post\">\n        <input type=\"text\" name=\"title\" />\n        {fetcher.state !== \"idle\" && <p>Saving...</p>}\n      </fetcher.Form>\n    </div>\n  );\n}\n```\n\n## Fetcher for Data Loading (Combobox)\n\n```tsx\nfunction UserSearchCombobox() {\n  const fetcher = useFetcher<typeof loader>();\n\n  return (\n    <div>\n      <fetcher.Form method=\"get\" action=\"/search-users\">\n        <input\n          type=\"text\"\n          name=\"q\"\n          onChange={(e) => fetcher.submit(e.currentTarget.form)}\n        />\n      </fetcher.Form>\n      {fetcher.data && (\n        <ul style={{ opacity: fetcher.state === \"idle\" ? 1 : 0.25 }}>\n          {fetcher.data.map((user) => (\n            <li key={user.id}>{user.name}</li>\n          ))}\n        </ul>\n      )}\n    </div>\n  );\n}\n```\n\n## Optimistic List Updates\n\n```tsx\nfunction TodoList() {\n  const { todos } = useLoaderData();\n  const fetcher = useFetcher();\n\n  const displayedTodos = todos.filter(todo => {\n    const isDeleting = fetcher.formData?.get(\"id\") === todo.id;\n    return !isDeleting;\n  });\n\n  return (\n    <ul>\n      {displayedTodos.map(todo => (\n        <li key={todo.id}>\n          {todo.title}\n          <fetcher.Form method=\"post\" action=\"/todos/delete\">\n            <input type=\"hidden\" name=\"id\" value={todo.id} />\n            <button type=\"submit\">Delete</button>\n          </fetcher.Form>\n        </li>\n      ))}\n    </ul>\n  );\n}\n```\n",
        "skills/react-router-v7/ADVANCED.md": "# Advanced Patterns\n\n## Error Boundaries\n\n### Root Error Boundary (Required)\n\n```tsx\nimport { useRouteError, isRouteErrorResponse } from \"react-router\";\n\nfunction RootErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    return (\n      <>\n        <h1>{error.status} {error.statusText}</h1>\n        <p>{error.data}</p>\n      </>\n    );\n  } else if (error instanceof Error) {\n    return (\n      <div>\n        <h1>Error</h1>\n        <p>{error.message}</p>\n        <pre>{error.stack}</pre>\n      </div>\n    );\n  } else {\n    return <h1>Unknown Error</h1>;\n  }\n}\n\ncreateBrowserRouter([\n  {\n    path: \"/\",\n    ErrorBoundary: RootErrorBoundary,\n    Component: Root,\n  },\n]);\n```\n\n### Throwing Errors in Loaders\n\n```tsx\nimport { data } from \"react-router\";\n\nexport async function loader({ params }) {\n  const record = await db.getRecord(params.id);\n  if (!record) {\n    throw data(\"Record Not Found\", { status: 404 });\n  }\n  return record;\n}\n```\n\n### Nested Error Boundaries\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/app\",\n    ErrorBoundary: AppErrorBoundary,\n    children: [\n      {\n        path: \"invoices/:id\",\n        ErrorBoundary: InvoiceErrorBoundary,\n        Component: Invoice,\n      },\n    ],\n  },\n]);\n```\n\n## Protected Routes\n\n### Component-Based Protection\n\n```tsx\nimport { Navigate, useLocation } from \"react-router\";\n\nfunction RequireAuth({ children }: { children: JSX.Element }) {\n  const auth = useAuth();\n  const location = useLocation();\n\n  if (!auth.user) {\n    return <Navigate to=\"/login\" state={{ from: location }} replace />;\n  }\n\n  return children;\n}\n\n// Route configuration\n{\n  path: \"/protected\",\n  element: (\n    <RequireAuth>\n      <ProtectedPage />\n    </RequireAuth>\n  ),\n}\n\n// In login handler - redirect back\nfunction LoginPage() {\n  const navigate = useNavigate();\n  const location = useLocation();\n  const from = location.state?.from?.pathname || \"/\";\n\n  function handleLogin() {\n    auth.signin(() => {\n      navigate(from, { replace: true });\n    });\n  }\n}\n```\n\n### Middleware (Framework Mode)\n\n```tsx\nimport { redirect } from \"react-router\";\n\nasync function authMiddleware({ context, request }) {\n  const userId = getUserId(request);\n\n  if (!userId) {\n    throw redirect(\"/login\");\n  }\n\n  const user = await getUserById(userId);\n  context.set(userContext, user);\n}\n\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    middleware: [authMiddleware],\n    Component: Dashboard,\n  },\n]);\n```\n\n## Lazy Loading / Code Splitting\n\n### Data Mode Lazy Loading\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/app\",\n    lazy: async () => {\n      const [Component, loader] = await Promise.all([\n        import(\"./app\"),\n        import(\"./app-loader\"),\n      ]);\n      return { Component, loader };\n    },\n  },\n]);\n```\n\n### Declarative Mode Lazy Loading\n\n```tsx\nimport React from \"react\";\n\nconst About = React.lazy(() => import(\"./pages/About\"));\n\n<Routes>\n  <Route\n    path=\"about\"\n    element={\n      <React.Suspense fallback={<>Loading...</>}>\n        <About />\n      </React.Suspense>\n    }\n  />\n</Routes>\n```\n\n## Common Route Patterns\n\n### Optional Segments\n\n```tsx\n{ path: \":lang?/categories\" }     // Optional dynamic segment\n{ path: \"users/:userId/edit?\" }   // Optional static segment at end\n```\n\n### Catch-All / Splat Routes\n\n```tsx\n{ path: \"files/*\" }\n\n// Access splat in loader\nloader: ({ params }) => {\n  const filePath = params[\"*\"]; // \"path/to/file.txt\"\n}\n```\n\n### Multiple Params\n\n```tsx\n{ path: \"users/:userId/posts/:postId\" }\n\n// params.userId, params.postId available in loader/component\n```\n\n## Index vs Path Routes\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    Component: Dashboard,\n    children: [\n      // Index route - renders when parent path matches exactly\n      { index: true, Component: DashboardHome },\n\n      // Path route - renders at parent + path\n      { path: \"settings\", Component: Settings },\n      { path: \"profile\", Component: Profile },\n    ],\n  },\n]);\n```\n\n**Index renders at**: `/dashboard`\n**Settings renders at**: `/dashboard/settings`\n",
        "skills/react-router-v7/LOADERS.md": "# Data Loading Patterns\n\n## Basic Loader\n\n```tsx\n{\n  path: \"/teams/:teamId\",\n  loader: async ({ params, request }) => {\n    const url = new URL(request.url);\n    const query = url.searchParams.get(\"q\");\n    const team = await fetchTeam(params.teamId, query);\n    return { team, name: team.name };\n  },\n  Component: Team,\n}\n\nfunction Team() {\n  const data = useLoaderData();\n  return <h1>{data.name}</h1>;\n}\n```\n\n## Parallel Data Loading\n\nNested routes load data in parallel automatically:\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/\",\n    loader: rootLoader,    // Loads in parallel\n    children: [\n      {\n        path: \"project/:id\",\n        loader: projectLoader, // Loads in parallel with rootLoader\n      },\n    ],\n  },\n]);\n```\n\n## Search Params in Loaders\n\n```tsx\n{\n  path: \"/search\",\n  loader: async ({ request }) => {\n    const url = new URL(request.url);\n    const query = url.searchParams.get(\"q\");\n    const page = url.searchParams.get(\"page\") || \"1\";\n    return { results: await search(query, parseInt(page)) };\n  },\n}\n\nfunction SearchPage() {\n  const { results } = useLoaderData();\n  return (\n    <Form method=\"get\">\n      <input type=\"text\" name=\"q\" />\n      <button type=\"submit\">Search</button>\n    </Form>\n  );\n}\n```\n\n## useSearchParams Hook\n\n```tsx\nimport { useSearchParams } from \"react-router\";\n\nfunction SearchPage() {\n  const [searchParams, setSearchParams] = useSearchParams();\n  const query = searchParams.get(\"q\");\n\n  return (\n    <input\n      value={query || \"\"}\n      onChange={(e) => setSearchParams({ q: e.target.value })}\n    />\n  );\n}\n```\n\n## Revalidation Control\n\n```tsx\nfunction shouldRevalidate({ currentUrl, nextUrl, formAction }) {\n  return currentUrl.pathname !== nextUrl.pathname;\n}\n\ncreateBrowserRouter([\n  {\n    path: \"/data\",\n    shouldRevalidate,\n    loader: dataLoader,\n  },\n]);\n```\n\n## Framework Mode Loaders\n\n```tsx\n// product.tsx\nimport { Route } from \"./+types/product\";\n\nexport async function loader({ params }: Route.LoaderArgs) {\n  const product = await getProduct(params.pid);\n  return { product };\n}\n\nexport default function Product({ loaderData }: Route.ComponentProps) {\n  return <div>{loaderData.product.name}</div>;\n}\n```\n",
        "skills/react-router-v7/NAVIGATION.md": "# Navigation Patterns\n\n## NavLink (Active Styling)\n\n```tsx\nimport { NavLink } from \"react-router\";\n\n<NavLink to=\"/messages\" end>\n  Messages\n</NavLink>\n\n// CSS styling\na.active { color: red; }\na.pending { animation: pulse 1s infinite; }\n\n// Callback styling\n<NavLink\n  to=\"/messages\"\n  className={({ isActive, isPending }) =>\n    isActive ? \"active\" : isPending ? \"pending\" : \"\"\n  }\n>\n  Messages\n</NavLink>\n```\n\n## Link (No Active Styling)\n\n```tsx\nimport { Link } from \"react-router\";\n\n<Link to=\"/login\">Login</Link>\n<Link to={{ pathname: \"/search\", search: \"?q=term\" }}>Search</Link>\n```\n\n## Programmatic Navigation\n\n```tsx\nimport { useNavigate } from \"react-router\";\n\nfunction Component() {\n  const navigate = useNavigate();\n\n  // Use sparingly - only for non-user-initiated navigation\n  useEffect(() => {\n    if (inactivityTimeout) {\n      navigate(\"/logout\");\n    }\n  }, [inactivityTimeout]);\n\n  // Or with options\n  navigate(\"/dashboard\", { replace: true });\n  navigate(-1); // Go back\n}\n```\n\n## Redirect in Loaders\n\n```tsx\nimport { redirect } from \"react-router\";\n\nexport async function loader({ request }) {\n  const user = await getUser(request);\n  if (!user) {\n    return redirect(\"/login\");\n  }\n  return { user };\n}\n```\n\n## Pending UI (Navigation State)\n\n```tsx\nimport { useNavigation } from \"react-router\";\n\nfunction Root() {\n  const navigation = useNavigation();\n  const isNavigating = navigation.state !== \"idle\";\n\n  return (\n    <div>\n      {isNavigating && <GlobalSpinner />}\n      <Outlet />\n    </div>\n  );\n}\n```\n\n## Form Submission State\n\n```tsx\nfunction Component() {\n  const navigation = useNavigation();\n  const isSubmitting = navigation.formAction === \"/recipes/new\";\n\n  return (\n    <Form method=\"post\" action=\"/recipes/new\">\n      <button type=\"submit\">\n        {isSubmitting ? \"Saving...\" : \"Create Recipe\"}\n      </button>\n    </Form>\n  );\n}\n```\n\n## Index Routes\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    Component: Dashboard,\n    children: [\n      { index: true, Component: DashboardHome }, // Renders at /dashboard\n      { path: \"settings\", Component: Settings }, // Renders at /dashboard/settings\n    ],\n  },\n]);\n```\n\n## Layout Routes (No Path)\n\n```tsx\ncreateBrowserRouter([\n  {\n    Component: MarketingLayout, // No path, just layout wrapper\n    children: [\n      { index: true, Component: Home },\n      { path: \"contact\", Component: Contact },\n    ],\n  },\n]);\n```\n\n## Navigate Component\n\n```tsx\nimport { Navigate, useLocation } from \"react-router\";\n\nfunction RequireAuth({ children }) {\n  const auth = useAuth();\n  const location = useLocation();\n\n  if (!auth.user) {\n    return <Navigate to=\"/login\" state={{ from: location }} replace />;\n  }\n\n  return children;\n}\n```\n",
        "skills/react-router-v7/SKILL.md": "---\nname: react-router-v7\ndescription: React Router v7 best practices for data-driven routing. Use when implementing routes, loaders, actions, Form components, fetchers, navigation guards, protected routes, or URL search params. Triggers on createBrowserRouter, RouterProvider, useLoaderData, useActionData, useFetcher, NavLink, Outlet.\n---\n\n# React Router v7 Best Practices\n\n## Quick Reference\n\n**Router Setup (Data Mode)**:\n```tsx\nimport { createBrowserRouter, RouterProvider } from \"react-router\";\n\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    Component: Root,\n    ErrorBoundary: RootErrorBoundary,\n    loader: rootLoader,\n    children: [\n      { index: true, Component: Home },\n      { path: \"products/:productId\", Component: Product, loader: productLoader },\n    ],\n  },\n]);\n\nReactDOM.createRoot(root).render(<RouterProvider router={router} />);\n```\n\n**Framework Mode (Vite plugin)**:\n```ts\n// routes.ts\nimport { index, route } from \"@react-router/dev/routes\";\n\nexport default [\n  index(\"./home.tsx\"),\n  route(\"products/:pid\", \"./product.tsx\"),\n];\n```\n\n## Route Configuration\n\n### Nested Routes with Outlets\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    Component: Dashboard,\n    children: [\n      { index: true, Component: DashboardHome },\n      { path: \"settings\", Component: Settings },\n    ],\n  },\n]);\n\nfunction Dashboard() {\n  return (\n    <div>\n      <h1>Dashboard</h1>\n      <Outlet /> {/* Renders child routes */}\n    </div>\n  );\n}\n```\n\n### Dynamic Segments and Splats\n\n```tsx\n{ path: \"teams/:teamId\" }           // params.teamId\n{ path: \":lang?/categories\" }       // Optional segment\n{ path: \"files/*\" }                 // Splat: params[\"*\"]\n```\n\n## Key Decision Points\n\n### Form vs Fetcher\n\n**Use `<Form>`**: Creating/deleting with URL change, adding to history\n**Use `useFetcher`**: Inline updates, list operations, popovers - no URL change\n\n### Loader vs useEffect\n\n**Use loader**: Data before render, server-side fetch, automatic revalidation\n**Use useEffect**: Client-only data, user-interaction dependent, subscriptions\n\n## Additional Documentation\n\n- **Data Loading**: See [references/loaders.md](references/loaders.md) for loader patterns, parallel loading, search params\n- **Mutations**: See [references/actions.md](references/actions.md) for actions, Form, fetchers, validation\n- **Navigation**: See [references/navigation.md](references/navigation.md) for Link, NavLink, programmatic nav\n- **Advanced**: See [references/advanced.md](references/advanced.md) for error boundaries, protected routes, lazy loading\n\n## Mode Comparison\n\n| Feature | Framework Mode | Data Mode | Declarative Mode |\n|---------|---------------|-----------|------------------|\n| Setup | Vite plugin | `createBrowserRouter` | `<BrowserRouter>` |\n| Type Safety | Auto-generated types | Manual | Manual |\n| SSR Support | Built-in | Manual | Limited |\n| Use Case | Full-stack apps | SPAs with control | Simple/legacy |\n",
        "skills/react-router-v7/references/actions.md": "# Actions and Mutations\n\n## Contents\n\n- [Basic Action Pattern](#basic-action-pattern)\n- [Form Submission](#form-submission)\n- [Redirect After Action](#redirect-after-action)\n- [Form Validation](#form-validation)\n- [Fetchers (Non-Navigation Mutations)](#fetchers-non-navigation-mutations)\n- [Optimistic UI with Fetchers](#optimistic-ui-with-fetchers)\n- [Fetcher for Data Loading (Combobox)](#fetcher-for-data-loading-combobox)\n- [Optimistic List Updates](#optimistic-list-updates)\n\n---\n\n## Basic Action Pattern\n\n```tsx\n{\n  path: \"/projects/:id\",\n  action: async ({ request, params }) => {\n    const formData = await request.formData();\n    const title = formData.get(\"title\");\n    await updateProject(params.id, { title });\n    return { success: true };\n  },\n  Component: Project,\n}\n```\n\n## Form Submission\n\n```tsx\nfunction Project() {\n  const actionData = useActionData();\n\n  return (\n    <Form method=\"post\">\n      <input type=\"text\" name=\"title\" />\n      <button type=\"submit\">Save</button>\n      {actionData?.success && <p>Saved!</p>}\n    </Form>\n  );\n}\n```\n\n## Redirect After Action\n\n```tsx\nimport { redirect } from \"react-router\";\n\nexport async function action({ request }) {\n  const formData = await request.formData();\n  const project = await createProject(formData);\n  return redirect(`/projects/${project.id}`);\n}\n```\n\n## Form Validation\n\n```tsx\nimport { data } from \"react-router\";\n\nexport async function action({ request }: Route.ActionArgs) {\n  const formData = await request.formData();\n  const email = String(formData.get(\"email\"));\n  const password = String(formData.get(\"password\"));\n\n  const errors: Record<string, string> = {};\n\n  if (!email.includes(\"@\")) {\n    errors.email = \"Invalid email address\";\n  }\n  if (password.length < 12) {\n    errors.password = \"Password must be at least 12 characters\";\n  }\n\n  if (Object.keys(errors).length > 0) {\n    return data({ errors }, { status: 400 }); // 400 prevents revalidation\n  }\n\n  return redirect(\"/dashboard\");\n}\n\nexport default function Signup() {\n  const fetcher = useFetcher();\n  const errors = fetcher.data?.errors;\n\n  return (\n    <fetcher.Form method=\"post\">\n      <input type=\"email\" name=\"email\" />\n      {errors?.email && <em>{errors.email}</em>}\n\n      <input type=\"password\" name=\"password\" />\n      {errors?.password && <em>{errors.password}</em>}\n\n      <button type=\"submit\">Sign Up</button>\n    </fetcher.Form>\n  );\n}\n```\n\n## Fetchers (Non-Navigation Mutations)\n\nUse fetchers when you DON'T want URL changes:\n\n```tsx\nimport { useFetcher } from \"react-router\";\n\nfunction TodoItem({ todo }) {\n  const fetcher = useFetcher();\n  const isDeleting = fetcher.state !== \"idle\";\n\n  return (\n    <li>\n      <span>{todo.title}</span>\n      <fetcher.Form method=\"post\" action=\"/todos/delete\">\n        <input type=\"hidden\" name=\"id\" value={todo.id} />\n        <button type=\"submit\" disabled={isDeleting}>\n          {isDeleting ? \"Deleting...\" : \"Delete\"}\n        </button>\n      </fetcher.Form>\n    </li>\n  );\n}\n```\n\n## Optimistic UI with Fetchers\n\n```tsx\nfunction Component() {\n  const data = useLoaderData();\n  const fetcher = useFetcher();\n\n  // Show optimistic state while submitting\n  const title = fetcher.formData?.get(\"title\") || data.title;\n\n  return (\n    <div>\n      <h1>{title}</h1>\n      <fetcher.Form method=\"post\">\n        <input type=\"text\" name=\"title\" />\n        {fetcher.state !== \"idle\" && <p>Saving...</p>}\n      </fetcher.Form>\n    </div>\n  );\n}\n```\n\n## Fetcher for Data Loading (Combobox)\n\n```tsx\nfunction UserSearchCombobox() {\n  const fetcher = useFetcher<typeof loader>();\n\n  return (\n    <div>\n      <fetcher.Form method=\"get\" action=\"/search-users\">\n        <input\n          type=\"text\"\n          name=\"q\"\n          onChange={(e) => fetcher.submit(e.currentTarget.form)}\n        />\n      </fetcher.Form>\n      {fetcher.data && (\n        <ul style={{ opacity: fetcher.state === \"idle\" ? 1 : 0.25 }}>\n          {fetcher.data.map((user) => (\n            <li key={user.id}>{user.name}</li>\n          ))}\n        </ul>\n      )}\n    </div>\n  );\n}\n```\n\n## Optimistic List Updates\n\n```tsx\nfunction TodoList() {\n  const { todos } = useLoaderData();\n  const fetcher = useFetcher();\n\n  const displayedTodos = todos.filter(todo => {\n    const isDeleting = fetcher.formData?.get(\"id\") === todo.id;\n    return !isDeleting;\n  });\n\n  return (\n    <ul>\n      {displayedTodos.map(todo => (\n        <li key={todo.id}>\n          {todo.title}\n          <fetcher.Form method=\"post\" action=\"/todos/delete\">\n            <input type=\"hidden\" name=\"id\" value={todo.id} />\n            <button type=\"submit\">Delete</button>\n          </fetcher.Form>\n        </li>\n      ))}\n    </ul>\n  );\n}\n```\n",
        "skills/react-router-v7/references/advanced.md": "# Advanced Patterns\n\n## Contents\n\n- [Error Boundaries](#error-boundaries)\n  - [Root Error Boundary (Required)](#root-error-boundary-required)\n  - [Throwing Errors in Loaders](#throwing-errors-in-loaders)\n  - [Nested Error Boundaries](#nested-error-boundaries)\n- [Protected Routes](#protected-routes)\n  - [Component-Based Protection](#component-based-protection)\n  - [Middleware (Framework Mode)](#middleware-framework-mode)\n- [Lazy Loading / Code Splitting](#lazy-loading--code-splitting)\n  - [Data Mode Lazy Loading](#data-mode-lazy-loading)\n  - [Declarative Mode Lazy Loading](#declarative-mode-lazy-loading)\n- [Common Route Patterns](#common-route-patterns)\n  - [Optional Segments](#optional-segments)\n  - [Catch-All / Splat Routes](#catch-all--splat-routes)\n  - [Multiple Params](#multiple-params)\n- [Index vs Path Routes](#index-vs-path-routes)\n\n---\n\n## Error Boundaries\n\n### Root Error Boundary (Required)\n\n```tsx\nimport { useRouteError, isRouteErrorResponse } from \"react-router\";\n\nfunction RootErrorBoundary() {\n  const error = useRouteError();\n\n  if (isRouteErrorResponse(error)) {\n    return (\n      <>\n        <h1>{error.status} {error.statusText}</h1>\n        <p>{error.data}</p>\n      </>\n    );\n  } else if (error instanceof Error) {\n    return (\n      <div>\n        <h1>Error</h1>\n        <p>{error.message}</p>\n        <pre>{error.stack}</pre>\n      </div>\n    );\n  } else {\n    return <h1>Unknown Error</h1>;\n  }\n}\n\ncreateBrowserRouter([\n  {\n    path: \"/\",\n    ErrorBoundary: RootErrorBoundary,\n    Component: Root,\n  },\n]);\n```\n\n### Throwing Errors in Loaders\n\n```tsx\nimport { data } from \"react-router\";\n\nexport async function loader({ params }) {\n  const record = await db.getRecord(params.id);\n  if (!record) {\n    throw data(\"Record Not Found\", { status: 404 });\n  }\n  return record;\n}\n```\n\n### Nested Error Boundaries\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/app\",\n    ErrorBoundary: AppErrorBoundary,\n    children: [\n      {\n        path: \"invoices/:id\",\n        ErrorBoundary: InvoiceErrorBoundary,\n        Component: Invoice,\n      },\n    ],\n  },\n]);\n```\n\n## Protected Routes\n\n### Component-Based Protection\n\n```tsx\nimport { Navigate, useLocation } from \"react-router\";\n\nfunction RequireAuth({ children }: { children: JSX.Element }) {\n  const auth = useAuth();\n  const location = useLocation();\n\n  if (!auth.user) {\n    return <Navigate to=\"/login\" state={{ from: location }} replace />;\n  }\n\n  return children;\n}\n\n// Route configuration\n{\n  path: \"/protected\",\n  element: (\n    <RequireAuth>\n      <ProtectedPage />\n    </RequireAuth>\n  ),\n}\n\n// In login handler - redirect back\nfunction LoginPage() {\n  const navigate = useNavigate();\n  const location = useLocation();\n  const from = location.state?.from?.pathname || \"/\";\n\n  function handleLogin() {\n    auth.signin(() => {\n      navigate(from, { replace: true });\n    });\n  }\n}\n```\n\n### Middleware (Framework Mode Only)\n\nMiddleware requires Framework Mode and the `future.v8_middleware` flag. Export middleware from route modules:\n\n```tsx\n// app/routes/dashboard.tsx (Framework Mode)\nimport { redirect, createContext } from \"react-router\";\n\nexport const userContext = createContext<User | null>(null);\n\nexport const middleware = [\n  async function authMiddleware({ request, context }, next) {\n    const userId = getUserId(request);\n\n    if (!userId) {\n      throw redirect(\"/login\");\n    }\n\n    const user = await getUserById(userId);\n    context.set(userContext, user);\n\n    return next();\n  },\n];\n\nexport async function loader({ context }: Route.LoaderArgs) {\n  const user = context.get(userContext);\n  return { user };\n}\n```\n\nNote: Middleware is NOT available in Data Mode (createBrowserRouter). Use loaders for auth checks in Data Mode.\n\n## Lazy Loading / Code Splitting\n\n### Data Mode Lazy Loading\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/app\",\n    lazy: async () => {\n      const [Component, loader] = await Promise.all([\n        import(\"./app\"),\n        import(\"./app-loader\"),\n      ]);\n      return { Component, loader };\n    },\n  },\n]);\n```\n\n### Declarative Mode Lazy Loading\n\n```tsx\nimport React from \"react\";\n\nconst About = React.lazy(() => import(\"./pages/About\"));\n\n<Routes>\n  <Route\n    path=\"about\"\n    element={\n      <React.Suspense fallback={<>Loading...</>}>\n        <About />\n      </React.Suspense>\n    }\n  />\n</Routes>\n```\n\n## Common Route Patterns\n\n### Optional Segments\n\n```tsx\n{ path: \":lang?/categories\" }     // Optional dynamic segment\n{ path: \"users/:userId/edit?\" }   // Optional static segment at end\n```\n\n### Catch-All / Splat Routes\n\n```tsx\n{ path: \"files/*\" }\n\n// Access splat in loader\nloader: ({ params }) => {\n  const filePath = params[\"*\"]; // \"path/to/file.txt\"\n}\n```\n\n### Multiple Params\n\n```tsx\n{ path: \"users/:userId/posts/:postId\" }\n\n// params.userId, params.postId available in loader/component\n```\n\n## Index vs Path Routes\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    Component: Dashboard,\n    children: [\n      // Index route - renders when parent path matches exactly\n      { index: true, Component: DashboardHome },\n\n      // Path route - renders at parent + path\n      { path: \"settings\", Component: Settings },\n      { path: \"profile\", Component: Profile },\n    ],\n  },\n]);\n```\n\n**Index renders at**: `/dashboard`\n**Settings renders at**: `/dashboard/settings`\n",
        "skills/react-router-v7/references/loaders.md": "# Data Loading Patterns\n\n## Contents\n\n- [Basic Loader](#basic-loader)\n- [Parallel Data Loading](#parallel-data-loading)\n- [Search Params in Loaders](#search-params-in-loaders)\n- [useSearchParams Hook](#usesearchparams-hook)\n- [Revalidation Control](#revalidation-control)\n- [Framework Mode Loaders](#framework-mode-loaders)\n\n---\n\n## Basic Loader\n\n```tsx\n{\n  path: \"/teams/:teamId\",\n  loader: async ({ params, request }) => {\n    const url = new URL(request.url);\n    const query = url.searchParams.get(\"q\");\n    const team = await fetchTeam(params.teamId, query);\n    return { team, name: team.name };\n  },\n  Component: Team,\n}\n\nfunction Team() {\n  const data = useLoaderData();\n  return <h1>{data.name}</h1>;\n}\n```\n\n## Parallel Data Loading\n\nNested routes load data in parallel automatically:\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/\",\n    loader: rootLoader,    // Loads in parallel\n    children: [\n      {\n        path: \"project/:id\",\n        loader: projectLoader, // Loads in parallel with rootLoader\n      },\n    ],\n  },\n]);\n```\n\n## Search Params in Loaders\n\n```tsx\n{\n  path: \"/search\",\n  loader: async ({ request }) => {\n    const url = new URL(request.url);\n    const query = url.searchParams.get(\"q\");\n    const page = url.searchParams.get(\"page\") || \"1\";\n    return { results: await search(query, parseInt(page)) };\n  },\n}\n\nfunction SearchPage() {\n  const { results } = useLoaderData();\n  return (\n    <Form method=\"get\">\n      <input type=\"text\" name=\"q\" />\n      <button type=\"submit\">Search</button>\n    </Form>\n  );\n}\n```\n\n## useSearchParams Hook\n\n```tsx\nimport { useSearchParams } from \"react-router\";\n\nfunction SearchPage() {\n  const [searchParams, setSearchParams] = useSearchParams();\n  const query = searchParams.get(\"q\");\n\n  return (\n    <input\n      value={query || \"\"}\n      onChange={(e) => setSearchParams({ q: e.target.value })}\n    />\n  );\n}\n```\n\n## Revalidation Control\n\n```tsx\nfunction shouldRevalidate({ currentUrl, nextUrl, formAction }) {\n  return currentUrl.pathname !== nextUrl.pathname;\n}\n\ncreateBrowserRouter([\n  {\n    path: \"/data\",\n    shouldRevalidate,\n    loader: dataLoader,\n  },\n]);\n```\n\n## Framework Mode Loaders\n\n```tsx\n// product.tsx\nimport { Route } from \"./+types/product\";\n\nexport async function loader({ params }: Route.LoaderArgs) {\n  const product = await getProduct(params.pid);\n  return { product };\n}\n\nexport default function Product({ loaderData }: Route.ComponentProps) {\n  return <div>{loaderData.product.name}</div>;\n}\n```\n",
        "skills/react-router-v7/references/navigation.md": "# Navigation Patterns\n\n## Contents\n\n- [NavLink (Active Styling)](#navlink-active-styling)\n- [Link (No Active Styling)](#link-no-active-styling)\n- [Programmatic Navigation](#programmatic-navigation)\n- [Redirect in Loaders](#redirect-in-loaders)\n- [Pending UI (Navigation State)](#pending-ui-navigation-state)\n- [Form Submission State](#form-submission-state)\n- [Index Routes](#index-routes)\n- [Layout Routes (No Path)](#layout-routes-no-path)\n- [Navigate Component](#navigate-component)\n\n---\n\n## NavLink (Active Styling)\n\n```tsx\nimport { NavLink } from \"react-router\";\n\n<NavLink to=\"/messages\" end>\n  Messages\n</NavLink>\n\n// CSS styling\na.active { color: red; }\na.pending { animation: pulse 1s infinite; }\n\n// Callback styling\n<NavLink\n  to=\"/messages\"\n  className={({ isActive, isPending }) =>\n    isActive ? \"active\" : isPending ? \"pending\" : \"\"\n  }\n>\n  Messages\n</NavLink>\n```\n\n## Link (No Active Styling)\n\n```tsx\nimport { Link } from \"react-router\";\n\n<Link to=\"/login\">Login</Link>\n<Link to={{ pathname: \"/search\", search: \"?q=term\" }}>Search</Link>\n```\n\n## Programmatic Navigation\n\n```tsx\nimport { useNavigate } from \"react-router\";\n\nfunction Component() {\n  const navigate = useNavigate();\n\n  // Use sparingly - only for non-user-initiated navigation\n  useEffect(() => {\n    if (inactivityTimeout) {\n      navigate(\"/logout\");\n    }\n  }, [inactivityTimeout]);\n\n  // Or with options\n  navigate(\"/dashboard\", { replace: true });\n  navigate(-1); // Go back\n}\n```\n\n## Redirect in Loaders\n\n```tsx\nimport { redirect } from \"react-router\";\n\nexport async function loader({ request }) {\n  const user = await getUser(request);\n  if (!user) {\n    return redirect(\"/login\");\n  }\n  return { user };\n}\n```\n\n## Pending UI (Navigation State)\n\n```tsx\nimport { useNavigation } from \"react-router\";\n\nfunction Root() {\n  const navigation = useNavigation();\n  const isNavigating = navigation.state !== \"idle\";\n\n  return (\n    <div>\n      {isNavigating && <GlobalSpinner />}\n      <Outlet />\n    </div>\n  );\n}\n```\n\n## Form Submission State\n\n```tsx\nfunction Component() {\n  const navigation = useNavigation();\n  const isSubmitting = navigation.formAction === \"/recipes/new\";\n\n  return (\n    <Form method=\"post\" action=\"/recipes/new\">\n      <button type=\"submit\">\n        {isSubmitting ? \"Saving...\" : \"Create Recipe\"}\n      </button>\n    </Form>\n  );\n}\n```\n\n## Index Routes\n\n```tsx\ncreateBrowserRouter([\n  {\n    path: \"/dashboard\",\n    Component: Dashboard,\n    children: [\n      { index: true, Component: DashboardHome }, // Renders at /dashboard\n      { path: \"settings\", Component: Settings }, // Renders at /dashboard/settings\n    ],\n  },\n]);\n```\n\n## Layout Routes (No Path)\n\n```tsx\ncreateBrowserRouter([\n  {\n    Component: MarketingLayout, // No path, just layout wrapper\n    children: [\n      { index: true, Component: Home },\n      { path: \"contact\", Component: Contact },\n    ],\n  },\n]);\n```\n\n## Navigate Component\n\n```tsx\nimport { Navigate, useLocation } from \"react-router\";\n\nfunction RequireAuth({ children }) {\n  const auth = useAuth();\n  const location = useLocation();\n\n  if (!auth.user) {\n    return <Navigate to=\"/login\" state={{ from: location }} replace />;\n  }\n\n  return children;\n}\n```\n",
        "skills/receive-feedback/EVALUATION.md": "# Evaluation Rules\n\n## Decision Matrix\n\n| Condition | Action | Response |\n|-----------|--------|----------|\n| **Correct & In Scope** | Implement immediately | \"Fixed in [file:line]\" |\n| **Correct but Out of Scope** | Defer | \"Valid point. Out of scope; added to backlog.\" |\n| **Technically Incorrect** | Reject with evidence | \"Verified: [evidence]. Maintaining current implementation.\" |\n| **Ambiguous / Unclear** | STOP and ask | \"Clarification needed: [specific question]\" |\n| **Violates YAGNI** | Reject | \"Not currently used by any consumer. Skipping (YAGNI).\" |\n| **Conflicts with codebase patterns** | Flag for discussion | \"Conflicts with established pattern in [location]. Discuss?\" |\n\n## Evaluation Order\n\nProcess feedback items in this order:\n\n1. **Clarify** - Resolve all ambiguous items first\n2. **Critical** - Security issues, breaking bugs\n3. **Simple** - Typos, imports, formatting\n4. **Complex** - Refactoring, logic changes, architecture\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Conflicts with established codebase patterns\n- Legacy/compatibility reasons exist\n\n## Anti-Patterns\n\n| Forbidden | Why | Instead |\n|-----------|-----|---------|\n| \"You're absolutely right!\" | Performative, adds no value | State the fix or push back |\n| \"Great catch!\" | Social noise | Just fix it |\n| Implementing without verifying | May introduce bugs | Verify first |\n| Batch implementing | Hard to isolate regressions | One at a time, test each |\n",
        "skills/receive-feedback/RESPONSE.md": "# Response Format\n\n## Structured Output Template\n\nAfter processing all feedback items, produce this summary:\n\n```markdown\n## Feedback Response\n\n### Implemented\n| # | Item | Location | Notes |\n|---|------|----------|-------|\n| 1 | Fixed null check | `src/auth.py:42` | Added validation |\n| 3 | Renamed variable | `src/utils.py:15` | `data`  `user_data` |\n\n### Rejected\n| # | Item | Reason | Evidence |\n|---|------|--------|----------|\n| 2 | Remove validate_user | Function is used | Called in `middleware.py:45` |\n| 5 | Add generator | Premature optimization | Processes <1KB once at startup |\n\n### Deferred\n| # | Item | Reason |\n|---|------|--------|\n| 4 | Add caching layer | Out of scope for this PR |\n\n### Needs Clarification\n| # | Item | Question |\n|---|------|----------|\n| 6 | \"Fix the auth flow\" | Which specific aspect? Token refresh? Session handling? |\n```\n\n## Response Guidelines\n\n- **Be terse** - No filler words, no apologies\n- **Be specific** - Include file:line references\n- **Be evidenced** - Rejections must cite verification results\n- **Be actionable** - Clarification questions should be specific\n\n## Single-Item Responses\n\nFor quick acknowledgments during implementation:\n\n| Outcome | Response Format |\n|---------|-----------------|\n| Implemented | \"Fixed in `file:line`\" |\n| Rejected | \"Verified: [evidence]. Keeping current implementation.\" |\n| Deferred | \"Valid. Out of scope for this task.\" |\n| Unclear | \"Need clarification: [specific question]\" |\n",
        "skills/receive-feedback/SKILL.md": "---\nname: receive-feedback\ndescription: Process external code review feedback with technical rigor. Use when receiving feedback from another LLM, human reviewer, or CI tool. Verifies claims before implementing, tracks disposition.\n---\n\n# Receive Feedback\n\n## Overview\n\nProcess code review feedback with verification-first discipline.\nNo performative agreement. Technical correctness over social comfort.\n\n## Quick Reference\n\n```\n          \n   VERIFY         EVALUATE        EXECUTE   \n (tool-based)      (decision          (implement/ \n                    matrix)            reject/    \n            defer)     \n                                         \n```\n\n## Core Principle\n\n**Verify before implementing. Ask before assuming.**\n\n## When To Use\n\n- Receiving code review from another LLM session\n- Processing PR review comments\n- Evaluating CI/linter feedback\n- Handling suggestions from pair programming\n\n## Workflow\n\nFor each feedback item:\n\n1. **Verify** - Use tools to check if feedback is technically valid\n2. **Evaluate** - Apply decision matrix to determine action\n3. **Execute** - Implement, reject with evidence, or defer\n\n## Files\n\n- `VERIFICATION.md` - Tool-based verification workflow\n- `EVALUATION.md` - Decision matrix and rules\n- `RESPONSE.md` - Structured output format\n- `TRACKING.md` - Logging disposition to CSV\n- `references/skill-integration.md` - Using with code-review skills\n",
        "skills/receive-feedback/TRACKING.md": "# Feedback Tracking\n\n## Purpose\n\nMaintain a log of processed feedback for:\n- Reference during follow-up discussions\n- Pattern recognition (recurring feedback types)\n- Accountability (what was decided and why)\n\n## Tracking Prompt\n\nAfter processing feedback, always ask:\n\n> \"Log this feedback session to `.feedback-log.csv`? (y/n)\"\n\nDo not assume. Do not auto-track. Always prompt.\n\n## Log Format\n\nAppend to `.feedback-log.csv` in project root:\n\n```csv\ndate,source,item_number,item_summary,disposition,location,evidence\n2025-01-15,PR #123 @reviewer,1,Fix null check,implemented,auth.py:42,\n2025-01-15,PR #123 @reviewer,2,Remove unused fn,rejected,validate_user,Used in middleware.py:45\n2025-01-15,PR #123 @reviewer,3,Add caching,deferred,,Out of scope\n```\n\n## CSV Columns\n\n| Column | Description |\n|--------|-------------|\n| date | ISO date (YYYY-MM-DD) |\n| source | Origin of feedback (PR #, reviewer, session) |\n| item_number | Feedback item number from source |\n| item_summary | Brief description of the item |\n| disposition | implemented / rejected / deferred / clarified |\n| location | File:line where change was made (if applicable) |\n| evidence | Reason for rejection/deferral (if applicable) |\n\n## Log Location\n\nDefault: `.feedback-log.csv` in project root (gitignored)\n",
        "skills/receive-feedback/VERIFICATION.md": "# Verification Workflow\n\n## Principle\n\nDo not trust feedback. Verify it against the current codebase state.\n\n## Verification by Feedback Type\n\n| Feedback Type | Verification Method |\n|---------------|---------------------|\n| \"Unused code\" | `Grep` for usage across codebase |\n| \"Bug/Error\" | Reproduce with test or script |\n| \"Missing import\" | Check file, run linter |\n| \"Style/Convention\" | Check existing patterns in codebase |\n| \"Performance issue\" | Profile or benchmark if possible |\n| \"Security concern\" | Trace data flow, check sanitization |\n\n## Verification Steps\n\nFor EACH feedback item:\n\n1. **Locate**: Find the referenced code (`Read` tool)\n2. **Context**: Understand why it exists (`Grep` for usage, git blame)\n3. **Validate**: Test the claim (run tests, reproduce issue)\n4. **Document**: Note verification result before proceeding\n\n## Using Code-Review Skills for Verification\n\nWhen feedback relates to a specific domain, load the relevant skill:\n\n| Domain | Skill to Reference |\n|--------|-------------------|\n| Python quality | python-code-review |\n| FastAPI routes | fastapi-code-review |\n| SQLAlchemy ORM | sqlalchemy-code-review |\n| React components | shadcn-code-review |\n| Routing | react-router-code-review |\n| Database queries | postgres-code-review |\n| Tests | pytest-code-review, vitest-testing |\n\nThese skills contain the authoritative patterns for this codebase.\nIf feedback conflicts with skill guidance, flag for discussion.\n\n## Example\n\nFeedback: \"Remove unused `validate_user` function\"\n\nVerification:\n1. `Grep` for \"validate_user\" across codebase\n2. Found: Called in `auth/middleware.py:45`\n3. Result: **Feedback incorrect** - function is used\n4. Action: Push back with evidence\n",
        "skills/receive-feedback/references/skill-integration.md": "# Skill Integration\n\n## Using Code-Review Skills for Verification\n\nWhen feedback relates to a specific technology, load the relevant skill\nto verify against established codebase patterns.\n\n## Skill Lookup Table\n\n| Feedback Domain | Skill | Key Patterns to Check |\n|-----------------|-------|----------------------|\n| Python code quality | python-code-review | Type hints, error handling, naming |\n| FastAPI endpoints | fastapi-code-review | Dependency injection, response models |\n| SQLAlchemy models | sqlalchemy-code-review | Relationships, session handling |\n| Pytest tests | pytest-code-review | Fixtures, parametrization, mocking |\n| PostgreSQL queries | postgres-code-review | Indexes, joins, transactions |\n| React components | shadcn-code-review | Component composition, accessibility |\n| React Router | react-router-code-review | Loaders, actions, error boundaries |\n| Tailwind styling | tailwind-v4 | Utility classes, responsive design |\n| State management | zustand-state | Store structure, selectors |\n| Vitest tests | vitest-testing | Test structure, mocking |\n\n## Integration Workflow\n\n1. **Identify domain** - What technology does the feedback concern?\n2. **Load skill** - Use Skill tool: `Skill(skill: \"beagle:<skill-name>\")`\n3. **Cross-reference** - Does feedback align with skill guidance?\n4. **Resolve conflicts** - If feedback contradicts skill, flag for discussion\n\n## Conflict Resolution\n\nIf reviewer feedback conflicts with skill guidance:\n\n```\nSkill says: [pattern from skill]\nReviewer says: [contradicting suggestion]\n\nFlag: \"Feedback conflicts with established pattern. Discuss before implementing.\"\n```\n\nCodebase patterns (captured in skills) take precedence over external opinions.\n",
        "skills/reference-docs/SKILL.md": "---\nname: reference-docs\ndescription: Reference documentation patterns for API and symbol documentation. Use when writing reference docs, API docs, parameter tables, or technical specifications. Triggers on reference docs, API reference, function reference, parameters table, symbol documentation.\n---\n\n# Reference Documentation Patterns\n\nReference documentation is information-oriented - helping experienced users find precise technical details quickly. This skill provides patterns for writing clear, scannable reference pages.\n\n**Dependency:** Always use this skill in conjunction with `docs-style` for core writing principles.\n\n## Purpose and Audience\n\n- **Who:** Experienced users seeking specific information\n- **Goal:** Quick lookup of technical details\n- **Mode:** Not for learning, for looking up\n- **Expectation:** Brevity, consistency, completeness\n\n## Document Structure Template\n\nUse this template when creating reference documentation:\n\n```markdown\n---\ntitle: \"[Symbol/API Name]\"\ndescription: \"One-line description of what it does\"\n---\n\n# [Name]\n\nBrief description (1-2 sentences). State what it is and its primary purpose.\n\n## Parameters\n\n| Name | Type | Required | Description |\n|------|------|----------|-------------|\n| `param1` | `string` | Yes | What this parameter controls |\n| `param2` | `number` | No | Optional behavior modification. Default: `10` |\n\n## Returns\n\n| Type | Description |\n|------|-------------|\n| `ReturnType` | What the function returns and when |\n\n## Example\n\n```language\nimport { symbolName } from 'package';\n\n// Complete, runnable example showing common use case\nconst result = symbolName({\n  param1: 'realistic-value',\n  param2: 42\n});\n\nconsole.log(result);\n// Expected output: { ... }\n```\n\n## Related\n\n- [RelatedSymbol](/reference/related-symbol) - Brief description\n- [AnotherSymbol](/reference/another-symbol) - Brief description\n```\n\n## Writing Principles\n\n### Brevity Over Explanation\n\n- State facts, not rationale\n- Avoid \"why\" - save that for Explanation docs\n- Cut unnecessary words\n\n**Do:**\n```markdown\nReturns the user's display name.\n```\n\n**Avoid:**\n```markdown\nThis function is useful when you need to get the user's display name\nbecause it handles all the edge cases for you automatically.\n```\n\n### Scannable Tables, Not Prose\n\n**Do:**\n```markdown\n| Name | Type | Description |\n|------|------|-------------|\n| `userId` | `string` | Unique user identifier |\n| `options` | `Options` | Configuration object |\n```\n\n**Avoid:**\n```markdown\nThe first parameter is `userId`, which should be a string containing\nthe unique user identifier. The second parameter is `options`, which\nis an Options object containing the configuration.\n```\n\n### Consistent Format Across Entries\n\nAll reference pages for similar items should follow identical structure:\n\n- Same heading order\n- Same table columns\n- Same code example format\n- Same related links section\n\n### Every Example Must Be Runnable\n\n- Include all imports\n- Show complete, working code\n- Use realistic values (not \"foo\", \"bar\", \"test123\")\n- Include expected output when helpful\n\n## Code Example Patterns\n\n### Show Common Use Case First\n\n```markdown\n## Example\n\n### Basic Usage\n\n```typescript\nconst user = await getUser('user-123');\nconsole.log(user.name);\n```\n\n### With Options\n\n```typescript\nconst user = await getUser('user-123', {\n  includeMetadata: true,\n  fields: ['name', 'email', 'role']\n});\n```\n```\n\n### Include Setup and Context\n\n```markdown\n```typescript\nimport { Client } from '@example/sdk';\n\n// Initialize client (required once per application)\nconst client = new Client({ apiKey: process.env.API_KEY });\n\n// Now use the function\nconst result = await client.users.list();\n```\n```\n\n### Use Realistic Values\n\n**Do:** `userId: 'usr_a1b2c3d4'`\n**Avoid:** `userId: 'foo'`\n\n**Do:** `email: 'jane.smith@company.com'`\n**Avoid:** `email: 'test@test.com'`\n\n## Parameter Documentation Patterns\n\n### Required vs Optional\n\nClearly indicate which parameters are required:\n\n```markdown\n| Name | Type | Required | Default | Description |\n|------|------|----------|---------|-------------|\n| `apiKey` | `string` | Yes | - | Your API key |\n| `timeout` | `number` | No | `30000` | Request timeout in ms |\n| `retries` | `number` | No | `3` | Number of retry attempts |\n```\n\n### Complex Types\n\nFor object parameters, document the shape:\n\n```markdown\n## Parameters\n\n| Name | Type | Required | Description |\n|------|------|----------|-------------|\n| `options` | `UserOptions` | No | Configuration options |\n\n### UserOptions\n\n| Property | Type | Required | Description |\n|----------|------|----------|-------------|\n| `includeDeleted` | `boolean` | No | Include soft-deleted users |\n| `fields` | `string[]` | No | Fields to return |\n| `limit` | `number` | No | Maximum results (default: 100) |\n```\n\n### Enum Values\n\nDocument allowed values clearly:\n\n```markdown\n| Name | Type | Values | Description |\n|------|------|--------|-------------|\n| `status` | `string` | `active`, `pending`, `suspended` | User account status |\n```\n\n## Return Value Documentation\n\n### Simple Returns\n\n```markdown\n## Returns\n\n`User` - The requested user object, or `null` if not found.\n```\n\n### Complex Returns\n\n```markdown\n## Returns\n\n| Property | Type | Description |\n|----------|------|-------------|\n| `data` | `User[]` | Array of user objects |\n| `pagination` | `Pagination` | Pagination metadata |\n| `total` | `number` | Total matching records |\n```\n\n### Error Conditions\n\n```markdown\n## Errors\n\n| Error | Condition |\n|-------|-----------|\n| `NotFoundError` | User does not exist |\n| `UnauthorizedError` | Invalid or expired API key |\n| `RateLimitError` | Too many requests |\n```\n\n## API Reference Specifics\n\n### HTTP Endpoints\n\n```markdown\n## Endpoint\n\n```http\nGET /api/v1/users/{userId}\n```\n\n## Path Parameters\n\n| Name | Type | Description |\n|------|------|-------------|\n| `userId` | `string` | The user's unique identifier |\n\n## Query Parameters\n\n| Name | Type | Required | Description |\n|------|------|----------|-------------|\n| `fields` | `string` | No | Comma-separated list of fields |\n\n## Headers\n\n| Name | Required | Description |\n|------|----------|-------------|\n| `Authorization` | Yes | Bearer token |\n| `X-Request-ID` | No | Request tracking ID |\n\n## Response\n\n```json\n{\n  \"id\": \"usr_a1b2c3d4\",\n  \"name\": \"Jane Smith\",\n  \"email\": \"jane@company.com\"\n}\n```\n```\n\n## Component/Props Reference\n\nFor UI components:\n\n```markdown\n## Props\n\n| Prop | Type | Default | Description |\n|------|------|---------|-------------|\n| `variant` | `'primary' \\| 'secondary'` | `'primary'` | Visual style |\n| `size` | `'sm' \\| 'md' \\| 'lg'` | `'md'` | Button size |\n| `disabled` | `boolean` | `false` | Disable interactions |\n| `onClick` | `() => void` | - | Click handler |\n\n## Slots\n\n| Name | Description |\n|------|-------------|\n| `default` | Button content |\n| `icon` | Icon to display before text |\n```\n\n## Related Links Section\n\nAlways include links to related content:\n\n```markdown\n## Related\n\n- [createUser](/reference/create-user) - Create a new user\n- [updateUser](/reference/update-user) - Modify user properties\n- [deleteUser](/reference/delete-user) - Remove a user\n- [User Authentication Guide](/guides/authentication) - How authentication works\n```\n\n## Checklist for Reference Pages\n\nBefore considering a reference page complete:\n\n- [ ] Title matches the symbol/API name exactly\n- [ ] Description is one clear sentence\n- [ ] All parameters documented with types\n- [ ] Required vs optional clearly marked\n- [ ] Default values specified for optional parameters\n- [ ] Return type and structure documented\n- [ ] At least one complete, runnable example\n- [ ] Example uses realistic values\n- [ ] Related pages linked\n- [ ] Format matches other reference pages in the docs\n",
        "skills/review-feedback-schema/SKILL.md": "---\nname: review-feedback-schema\ndescription: Schema for tracking code review outcomes to enable feedback-driven skill improvement. Use when logging review results or analyzing review quality.\n---\n\n# Review Feedback Schema\n\n## Purpose\n\nStructured format for logging code review outcomes. This data enables:\n1. Identifying rules that produce false positives\n2. Tracking skill accuracy over time\n3. Automated skill improvement via pattern analysis\n\n## Schema\n\n```csv\ndate,file,line,rule_source,category,severity,issue,verdict,rationale\n```\n\n| Field | Type | Description | Example Values |\n|-------|------|-------------|----------------|\n| `date` | ISO date | When review occurred | `2025-12-23` |\n| `file` | path | Relative file path | `amelia/agents/developer.py` |\n| `line` | string | Line number(s) | `128`, `190-191` |\n| `rule_source` | string | Skill and rule that triggered issue | `python-code-review/common-mistakes:unused-variables`, `pydantic-ai-common-pitfalls:tool-decorator` |\n| `category` | enum | Issue taxonomy | `type-safety`, `async`, `error-handling`, `style`, `patterns`, `testing`, `security` |\n| `severity` | enum | As flagged by reviewer | `critical`, `major`, `minor` |\n| `issue` | string | Brief description | `Return type list[Any] loses type safety` |\n| `verdict` | enum | Human decision | `ACCEPT`, `REJECT`, `DEFER`, `ACKNOWLEDGE` |\n| `rationale` | string | Why verdict was chosen | `pydantic-ai docs explicitly support this pattern` |\n\n## Verdict Types\n\n| Verdict | Meaning | Action |\n|---------|---------|--------|\n| `ACCEPT` | Issue is valid, will fix | Code change made |\n| `REJECT` | Issue is invalid/wrong | No change; may improve skill |\n| `DEFER` | Valid but not fixing now | Tracked for later |\n| `ACKNOWLEDGE` | Valid but intentional | Document why it's intentional |\n\n### When to Use Each\n\n**ACCEPT**: The reviewer correctly identified a real issue.\n```csv\n2025-12-27,amelia/agents/developer.py,128,python-code-review:type-safety,type-safety,major,Return type list[Any] loses type safety,ACCEPT,Changed to list[AgentMessage]\n```\n\n**REJECT**: The reviewer was wrong - the code is correct.\n```csv\n2025-12-23,amelia/drivers/api/openai.py,102,python-code-review:line-length,style,minor,Line too long (104 > 100),REJECT,ruff check passes - no E501 violation exists\n```\n\n**DEFER**: Valid issue but out of scope for current work.\n```csv\n2025-12-22,api/handlers.py,45,fastapi-code-review:error-handling,error-handling,minor,Missing specific exception type,DEFER,Refactoring planned for Q1\n```\n\n**ACKNOWLEDGE**: Intentional design decision.\n```csv\n2025-12-21,core/cache.py,89,python-code-review:optimization,patterns,minor,Using dict instead of dataclass,ACKNOWLEDGE,Performance-critical path - intentional\n```\n\n## Rule Source Format\n\nFormat: `skill-name/section:rule-id` or `skill-name:rule-id`\n\nExamples:\n- `python-code-review/common-mistakes:unused-variables`\n- `pydantic-ai-common-pitfalls:tool-decorator`\n- `fastapi-code-review:dependency-injection`\n- `pytest-code-review:fixture-scope`\n\nUse the skill folder name and identify the specific rule or section that triggered the issue.\n\n## Category Taxonomy\n\n| Category | Description | Examples |\n|----------|-------------|----------|\n| `type-safety` | Type annotation issues | Missing types, incorrect types, `Any` usage |\n| `async` | Async/await issues | Blocking in async, missing await |\n| `error-handling` | Exception handling | Bare except, missing error handling |\n| `style` | Code style/formatting | Line length, naming conventions |\n| `patterns` | Design patterns | Anti-patterns, framework misuse |\n| `testing` | Test quality | Missing coverage, flaky tests |\n| `security` | Security issues | Injection, secrets exposure |\n\n## Writing Good Rationales\n\n### For ACCEPT\n\nExplain what you fixed:\n- \"Changed Exception to (FileNotFoundError, OSError)\"\n- \"Fixed using model_copy(update={...})\"\n- \"Removed unused Any import\"\n\n### For REJECT\n\nExplain why the issue is invalid:\n- \"ruff check passes - no E501 violation exists\" (linter authoritative)\n- \"pydantic-ai docs explicitly support this pattern\" (framework idiom)\n- \"Intentional optimization documented in code comment\" (documented decision)\n\n### For DEFER\n\nExplain when/why it will be addressed:\n- \"Tracked in issue #123\"\n- \"Refactoring planned for Q1\"\n- \"Blocked on dependency upgrade\"\n\n### For ACKNOWLEDGE\n\nExplain why it's intentional:\n- \"Performance-critical path per CLAUDE.md\"\n- \"Legacy API compatibility requirement\"\n- \"Matches upstream library pattern\"\n\n## Example Log\n\n```csv\ndate,file,line,rule_source,category,severity,issue,verdict,rationale\n2025-12-20,tests/integration/test_cli_flows.py,407,pytest-code-review:parametrization,testing,minor,Unused extra_args parameter in parametrization,ACCEPT,Fixed - removed dead parameter\n2025-12-20,tests/integration/test_cli_flows.py,237-242,pytest-code-review:coverage,testing,major,Missing review --local in git repo error test,REJECT,Not applicable - review uses different error path\n2025-12-21,amelia/server/orchestrator/service.py,1702,python-code-review:immutability,patterns,critical,Direct mutation of frozen ExecutionState,ACCEPT,Fixed using model_copy(update={...})\n2025-12-23,amelia/drivers/api/tools.py,48-53,pydantic-ai-common-pitfalls:tool-decorator,patterns,major,Misleading RunContext pattern - should use decorators,REJECT,pydantic-ai docs explicitly support passing raw functions with RunContext to Agent(tools=[])\n2025-12-23,amelia/drivers/api/openai.py,102,python-code-review:line-length,style,minor,Line too long (104 > 100),REJECT,ruff check passes - no E501 violation exists\n2025-12-27,amelia/core/orchestrator.py,190-191,python-code-review:exception-handling,error-handling,major,Generic exception handling in get_code_changes_for_review,ACCEPT,Changed Exception to (FileNotFoundError OSError)\n2025-12-27,amelia/agents/developer.py,128,python-code-review:type-safety,type-safety,major,Return type list[Any] loses type safety,ACCEPT,Changed to list[AgentMessage] and removed unused Any import\n```\n\n## Pre-Review Verification Checklist\n\nBefore reporting ANY finding, reviewers MUST verify:\n\n### Verification Steps\n\n1. **Confirm the issue exists**: Read the actual code, don't infer from context\n2. **Check surrounding code**: The issue may be handled elsewhere (guards, earlier checks)\n3. **Trace state/variable usage**: Search for all references before claiming \"unused\"\n4. **Verify assertions**: If claiming \"X is missing\", confirm X isn't present\n5. **Check framework handling**: Many frameworks handle validation/errors automatically\n6. **Validate syntax understanding**: Verify against current docs (Tailwind v4, TS 5.x, etc.)\n\n### Common False Positive Patterns\n\n| Pattern | Root Cause | Prevention |\n|---------|------------|------------|\n| \"Unused variable\" | Variable used elsewhere | Search all references |\n| \"Missing validation\" | Framework validates | Check Pydantic/Zod/etc. |\n| \"Type assertion\" | Actually annotation | Confirm `as` vs `:` |\n| \"Memory leak\" | Cleanup exists | Check effect returns |\n| \"Wrong syntax\" | New framework version | Verify against current docs |\n| \"Style issue\" | Preference not rule | Both approaches valid |\n\n### Signals of False Positive Risk\n\nIf you're about to flag any of these, double-check:\n- \"This variable appears unused\"  Search for ALL references first\n- \"Missing error handling\"  Check parent/framework handling\n- \"Should use X instead of Y\"  Both may be valid\n- \"This syntax looks wrong\"  Verify against current version docs\n\nReference: [review-verification-protocol](../review-verification-protocol/SKILL.md) for full verification workflow.\n\n## How This Feeds Into Skill Improvement\n\n1. **Aggregate by rule_source**: Identify which rules have high REJECT rates\n2. **Analyze rationales**: Find common themes in rejections\n3. **Update skills**: Add exceptions, clarifications, or verification steps\n4. **Track impact**: Measure if changes reduce rejection rate\n\nSee `review-skill-improver` skill for the full analysis workflow.\n\n### Improvement Signals\n\n| Pattern | Skill Improvement |\n|---------|-------------------|\n| \"linter passes\" rejections | Add linter verification step before flagging style issues |\n| \"docs support this\" rejections | Add exception for documented framework patterns |\n| \"intentional\" rejections | Add codebase context check before flagging |\n| \"wrong code path\" rejections | Add code tracing step before claiming gaps |\n",
        "skills/review-skill-improver/SKILL.md": "---\nname: review-skill-improver\ndescription: Analyzes feedback logs to identify patterns and suggest improvements to review skills. Use when you have accumulated feedback data and want to improve review accuracy.\n---\n\n# Review Skill Improver\n\n## Purpose\n\nAnalyzes structured feedback logs to:\n1. Identify rules that produce false positives (high REJECT rate)\n2. Identify missing rules (issues that should have been caught)\n3. Suggest specific skill modifications\n\n## Input\n\nFeedback log in enhanced schema format (see `review-feedback-schema` skill).\n\n## Analysis Process\n\n### Step 1: Aggregate by Rule Source\n\n```\nFor each unique rule_source:\n  - Count total issues flagged\n  - Count ACCEPT vs REJECT\n  - Calculate rejection rate\n  - Extract rejection rationales\n```\n\n### Step 2: Identify High-Rejection Rules\n\nRules with >30% rejection rate warrant investigation:\n- Read the rejection rationales\n- Identify common themes\n- Determine if rule needs refinement or exception\n\n### Step 3: Pattern Analysis\n\nGroup rejections by rationale theme:\n- \"Linter already handles this\" -> Add linter verification step\n- \"Framework supports this pattern\" -> Add exception to skill\n- \"Intentional design decision\" -> Add codebase context check\n- \"Wrong code path assumed\" -> Add code tracing step\n\n### Step 4: Generate Improvement Recommendations\n\nFor each identified issue, produce:\n\n```markdown\n## Recommendation: [SHORT_TITLE]\n\n**Affected Skill:** `skill-name/SKILL.md` or `skill-name/references/file.md`\n\n**Problem:** [What's causing false positives]\n\n**Evidence:**\n- [X] rejections with rationale \"[common theme]\"\n- Example: [file:line] - [issue] - [rationale]\n\n**Proposed Fix:**\n```markdown\n[Exact text to add/modify in the skill]\n```\n\n**Expected Impact:** Reduce false positive rate for [rule] from X% to Y%\n```\n\n## Output Format\n\n```markdown\n# Review Skill Improvement Report\n\n## Summary\n- Feedback entries analyzed: [N]\n- Unique rules triggered: [N]\n- High-rejection rules identified: [N]\n- Recommendations generated: [N]\n\n## High-Rejection Rules\n\n| Rule Source | Total | Rejected | Rate | Theme |\n|-------------|-------|----------|------|-------|\n| ... | ... | ... | ... | ... |\n\n## Recommendations\n\n[Numbered list of recommendations in format above]\n\n## Rules Performing Well\n\n[Rules with <10% rejection rate - preserve these]\n```\n\n## Usage\n\n```bash\n# In a project with feedback log\n/review-skill-improver --log .feedback-log.csv --output improvement-report.md\n```\n\n## Example Analysis\n\nGiven this feedback data:\n\n```csv\nrule_source,verdict,rationale\npython-code-review:line-length,REJECT,ruff check passes\npython-code-review:line-length,REJECT,no E501 violation\npython-code-review:line-length,REJECT,linter config allows 120\npython-code-review:line-length,ACCEPT,fixed long line\npydantic-ai-common-pitfalls:tool-decorator,REJECT,docs support raw functions\npython-code-review:type-safety,ACCEPT,added type annotation\npython-code-review:type-safety,ACCEPT,fixed Any usage\n```\n\nAnalysis output:\n\n```markdown\n# Review Skill Improvement Report\n\n## Summary\n- Feedback entries analyzed: 7\n- Unique rules triggered: 3\n- High-rejection rules identified: 2\n- Recommendations generated: 2\n\n## High-Rejection Rules\n\n| Rule Source | Total | Rejected | Rate | Theme |\n|-------------|-------|----------|------|-------|\n| python-code-review:line-length | 4 | 3 | 75% | linter handles this |\n| pydantic-ai-common-pitfalls:tool-decorator | 1 | 1 | 100% | framework supports pattern |\n\n## Recommendations\n\n### 1. Add Linter Verification for Line Length\n\n**Affected Skill:** `commands/review-python.md`\n\n**Problem:** Flagging line length issues that linters confirm don't exist\n\n**Evidence:**\n- 3 rejections with rationale \"linter passes/handles this\"\n- Example: amelia/drivers/api/openai.py:102 - Line too long - ruff check passes\n\n**Proposed Fix:**\nAdd step to run `ruff check` before manual review. If linter passes for line length, do not flag manually.\n\n**Expected Impact:** Reduce false positive rate for line-length from 75% to <10%\n\n### 2. Add Raw Function Tool Registration Exception\n\n**Affected Skill:** `skills/pydantic-ai-common-pitfalls/SKILL.md`\n\n**Problem:** Flagging valid pydantic-ai pattern as error\n\n**Evidence:**\n- 1 rejection with rationale \"docs support raw functions\"\n\n**Proposed Fix:**\nAdd \"Valid Patterns\" section documenting that passing functions with RunContext to Agent(tools=[...]) is valid.\n\n**Expected Impact:** Eliminate false positives for this pattern\n\n## Rules Performing Well\n\n| Rule Source | Total | Accepted | Rate |\n|-------------|-------|----------|------|\n| python-code-review:type-safety | 2 | 2 | 100% |\n```\n\n## Future: Automated Skill Updates\n\nOnce confidence is high, this skill can:\n1. Generate PRs to beagle with skill improvements\n2. Track improvement impact over time\n3. A/B test rule variations\n\n## Feedback Loop\n\n```\nReview Code -> Log Outcomes -> Analyze Patterns -> Improve Skills -> Better Reviews\n     ^                                                                    |\n     +--------------------------------------------------------------------+\n```\n\nThis creates a continuous improvement cycle where review quality improves based on empirical data rather than guesswork.\n",
        "skills/review-verification-protocol/SKILL.md": "---\nname: review-verification-protocol\ndescription: Mandatory verification steps for all code reviews to reduce false positives. Load this skill before reporting ANY code review findings.\n---\n\n# Review Verification Protocol\n\nThis protocol MUST be followed before reporting any code review finding. Skipping these steps leads to false positives that waste developer time and erode trust in reviews.\n\n## Pre-Report Verification Checklist\n\nBefore flagging ANY issue, verify:\n\n- [ ] **I read the actual code** - Not just the diff context, but the full function/class\n- [ ] **I searched for usages** - Before claiming \"unused\", searched all references\n- [ ] **I checked surrounding code** - The issue may be handled elsewhere (guards, earlier checks)\n- [ ] **I verified syntax against current docs** - Framework syntax evolves (Tailwind v4, TS 5.x, React 19)\n- [ ] **I distinguished \"wrong\" from \"different style\"** - Both approaches may be valid\n- [ ] **I considered intentional design** - Checked comments, CLAUDE.md, architectural context\n\n## Verification by Issue Type\n\n### \"Unused Variable/Function\"\n\n**Before flagging**, you MUST:\n1. Search for ALL references in the codebase (grep/find)\n2. Check if it's exported and used by external consumers\n3. Check if it's used via reflection, decorators, or dynamic dispatch\n4. Verify it's not a callback passed to a framework\n\n**Common false positives:**\n- State setters in React (may trigger re-renders even if value appears unused)\n- Variables used in templates/JSX\n- Exports used by consuming packages\n\n### \"Missing Validation/Error Handling\"\n\n**Before flagging**, you MUST:\n1. Check if validation exists at a higher level (caller, middleware, route handler)\n2. Check if the framework provides validation (Pydantic, Zod, TypeScript)\n3. Verify the \"missing\" check isn't present in a different form\n\n**Common false positives:**\n- Framework already validates (FastAPI + Pydantic, React Hook Form)\n- Parent component validates before passing props\n- Error boundary catches at higher level\n\n### \"Type Assertion/Unsafe Cast\"\n\n**Before flagging**, you MUST:\n1. Confirm it's actually an assertion, not an annotation\n2. Check if the type is narrowed by runtime checks before the point\n3. Verify if framework guarantees the type (loader data, form data)\n\n**Valid patterns often flagged incorrectly:**\n```typescript\n// Type annotation, NOT assertion\nconst data: UserData = await loader()\n\n// Type narrowing makes this safe\nif (isUser(data)) {\n  data.name  // TypeScript knows this is User\n}\n```\n\n### \"Potential Memory Leak/Race Condition\"\n\n**Before flagging**, you MUST:\n1. Verify cleanup function is actually missing (not just in a different location)\n2. Check if AbortController signal is checked after awaits\n3. Confirm the component can actually unmount during the async operation\n\n**Common false positives:**\n- Cleanup exists in useEffect return\n- Signal is checked (code reviewer missed it)\n- Operation completes before unmount is possible\n\n### \"Performance Issue\"\n\n**Before flagging**, you MUST:\n1. Confirm the code runs frequently enough to matter (render vs click handler)\n2. Verify the optimization would have measurable impact\n3. Check if the framework already optimizes this (React compiler, memoization)\n\n**Do NOT flag:**\n- Functions created in click handlers (runs once per click)\n- Array methods on small arrays (< 100 items)\n- Object creation in event handlers\n\n## Severity Calibration\n\n### Critical (Block Merge)\n\n**ONLY use for:**\n- Security vulnerabilities (injection, auth bypass, data exposure)\n- Data corruption bugs\n- Crash-causing bugs in happy path\n- Breaking changes to public APIs\n\n### Major (Should Fix)\n\n**Use for:**\n- Logic bugs that affect functionality\n- Missing error handling that causes poor UX\n- Performance issues with measurable impact\n- Accessibility violations\n\n### Minor (Consider Fixing)\n\n**Use for:**\n- Code clarity improvements\n- Documentation gaps\n- Inconsistent style (within reason)\n- Non-critical test coverage gaps\n\n### Do NOT Flag At All\n\n- Style preferences where both approaches are valid\n- Optimizations with no measurable benefit\n- Test code not meeting production standards (intentionally simpler)\n- Library/framework internal code (shadcn components, generated code)\n- Hypothetical issues that require unlikely conditions\n\n## Valid Patterns (Do NOT Flag)\n\n### TypeScript\n\n| Pattern | Why It's Valid |\n|---------|----------------|\n| `map.get(key) \\|\\| []` | `Map.get()` returns `T \\| undefined`, fallback is correct |\n| Class exports without separate type export | Classes work as both value and type |\n| `as const` on literal arrays | Creates readonly tuple types |\n| Type annotation on variable declaration | Not a type assertion |\n| `satisfies` instead of `as` | Type checking without assertion |\n\n### React\n\n| Pattern | Why It's Valid |\n|---------|----------------|\n| Array index as key (static list) | Valid when: items don't reorder, list is static, no item identity needed |\n| Inline arrow in onClick | Valid for non-performance-critical handlers (runs once per click) |\n| State that appears unused | May be set via refs, external callbacks, or triggers re-renders |\n| Empty dependency array with refs | Refs are stable, don't need to be dependencies |\n| Non-null assertion after check | TypeScript narrowing may not track through all patterns |\n\n### Testing\n\n| Pattern | Why It's Valid |\n|---------|----------------|\n| `toHaveTextContent` without regex | Handles nested text correctly |\n| Mock at module level | Defined once, not duplicated |\n| Index-based test data | Tests don't need stable identity |\n| Simplified error messages | Test clarity over production polish |\n\n### General\n\n| Pattern | Why It's Valid |\n|---------|----------------|\n| `+?` lazy quantifier in regex | Prevents over-matching, correct for many patterns |\n| Direct string concatenation | Simpler than template literals for simple cases |\n| Multiple returns in function | Can improve readability |\n| Comments explaining \"why\" | Better than no comments |\n\n## Context-Sensitive Rules\n\n### React Keys\n\nFlag array index as key **ONLY IF ALL** of these are true:\n- [ ] Items CAN be reordered (sortable list, drag-drop)\n- [ ] Items CAN be inserted/removed from middle\n- [ ] Items HAVE stable identifiers available (id, uuid)\n- [ ] The list is NOT completely replaced atomically\n\n### useEffect Dependencies\n\nFlag missing dependency **ONLY IF**:\n- [ ] The value actually changes during component lifetime\n- [ ] Stale closure would cause incorrect behavior\n- [ ] The value is NOT a ref (refs are stable)\n- [ ] The value is NOT a stable callback (useCallback with empty deps)\n\n### Error Handling\n\nFlag missing try/catch **ONLY IF**:\n- [ ] No error boundary catches this at a higher level\n- [ ] The framework doesn't handle errors (loader errorElement)\n- [ ] The error would cause a crash, not just a failed operation\n- [ ] User needs specific feedback for this error type\n\n## Before Submitting Review\n\nFinal verification:\n1. Re-read each finding and ask: \"Did I verify this is actually an issue?\"\n2. For each finding, can you point to the specific line that proves the issue exists?\n3. Would a domain expert agree this is a problem, or is it a style preference?\n4. Does fixing this provide real value, or is it busywork?\n\nIf uncertain about any finding, either:\n- Remove it from the review\n- Mark it as a question rather than an issue\n- Verify by reading more code context\n",
        "skills/shadcn-code-review/SKILL.md": "---\nname: shadcn-code-review\ndescription: Reviews shadcn/ui components for CVA patterns, composition with asChild, accessibility states, and data-slot usage. Use when reviewing React components using shadcn/ui, Radix primitives, or Tailwind styling.\n---\n\n# shadcn/ui Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| className in CVA, missing VariantProps, compound variants | [references/cva-patterns.md](references/cva-patterns.md) |\n| asChild without Slot, missing Context, component composition | [references/composition.md](references/composition.md) |\n| Missing focus-visible, aria-invalid, disabled states | [references/accessibility.md](references/accessibility.md) |\n| Missing data-slot, incorrect CSS targeting | [references/data-slot.md](references/data-slot.md) |\n\n## Review Checklist\n\n- [ ] `cn()` receives className, not CVA variants\n- [ ] `VariantProps<typeof variants>` exported for consumers\n- [ ] Compound variants used for complex state combinations\n- [ ] `asChild` pattern uses `@radix-ui/react-slot`\n- [ ] Context used for component composition (Card, Accordion, etc.)\n- [ ] `focus-visible:` states, not just `:focus`\n- [ ] `aria-invalid`, `aria-disabled` for form states\n- [ ] `disabled:` variants for all interactive elements\n- [ ] `sr-only` for screen reader text\n- [ ] `data-slot` attributes for targetable composition parts\n- [ ] CSS uses `has()` selectors for state-based styling\n- [ ] No direct className overrides of variant styles\n\n## Valid Patterns (Do NOT Flag)\n\nThese are correct patterns that should NOT be flagged as issues:\n\n- `max-h-(--var)` - correct Tailwind v4 CSS variable syntax (NOT v3 bracket notation)\n- `text-[color:var(--x)]` - valid arbitrary value syntax\n- Copying shadcn component code into project - intended usage pattern\n- Not documenting copied shadcn components - library internals, not custom code\n- Using cn() with many arguments - composition is the pattern\n- Conditional classes in cn() arrays - valid Tailwind pattern\n- Extending primitive components without additional docs - well-known base\n\n## Context-Sensitive Rules\n\nApply these rules with appropriate context awareness:\n\n- Flag accessibility issues ONLY IF not handled by Radix primitives underneath\n- Flag missing aria labels ONLY IF component isn't using accessible radix primitive\n- Flag variant proliferation ONLY IF variants could be composed from existing\n- Flag component documentation ONLY IF it's custom code, not copied shadcn\n\n## Library Convention Note\n\nshadcn/ui components are designed to be copied and modified. Code review should focus on:\n- Custom modifications made to copied components\n- Integration with application state/data\n- Accessibility in custom usage contexts\n\nDo NOT flag:\n- Standard shadcn component internals\n- Radix primitive usage patterns\n- Default variant implementations\n\n## When to Load References\n\n- Reviewing variant definitions  cva-patterns.md\n- Reviewing component composition with asChild  composition.md\n- Reviewing form components or interactive elements  accessibility.md\n- Reviewing multi-part components (Card, Select, etc.)  data-slot.md\n\n## Review Questions\n\n1. Are CVA variants properly separated from className props?\n2. Does asChild composition work correctly with Slot?\n3. Are all accessibility states (focus, invalid, disabled) handled?\n4. Are data-slot attributes used for component part targeting?\n5. Can consumers extend variants without breaking composition?\n\n## Before Submitting Findings\n\nLoad and follow [review-verification-protocol](../review-verification-protocol/SKILL.md) before reporting any issue.\n",
        "skills/shadcn-code-review/references/accessibility.md": "# Accessibility Patterns\n\n## Critical Anti-Patterns\n\n### 1. Using :focus Instead of :focus-visible\n\n**Problem**: Visible focus rings on mouse clicks create poor UX. Use focus-visible for keyboard-only focus.\n\n```tsx\n// BAD - :focus shows ring on click\nconst buttonVariants = cva(\n  \"rounded focus:ring-2 focus:ring-primary\" // Shows ring on mouse click\n)\n\n// GOOD - :focus-visible shows ring only for keyboard\nconst buttonVariants = cva(\n  \"rounded focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2\"\n)\n\n// Also apply to inputs:\nconst inputVariants = cva(\n  \"border rounded px-3 py-2 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring\"\n)\n```\n\n### 2. Missing aria-invalid for Form States\n\n**Problem**: Screen readers cannot announce validation errors without aria-invalid.\n\n```tsx\n// BAD - visual error state only\nexport function Input({ error, className, ...props }) {\n  return (\n    <input\n      className={cn(\n        \"border rounded\",\n        error && \"border-red-500\", // Visual only\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// GOOD - aria-invalid with proper error announcement\nexport function Input({ error, className, ...props }) {\n  const errorId = React.useId()\n\n  return (\n    <div>\n      <input\n        className={cn(\n          \"border rounded focus-visible:ring-2\",\n          error && \"border-destructive focus-visible:ring-destructive\",\n          className\n        )}\n        aria-invalid={error ? \"true\" : undefined}\n        aria-describedby={error ? errorId : undefined}\n        {...props}\n      />\n      {error && (\n        <p id={errorId} className=\"text-sm text-destructive mt-1\">\n          {error}\n        </p>\n      )}\n    </div>\n  )\n}\n```\n\n### 3. Missing Disabled States\n\n**Problem**: Disabled elements must have both visual and semantic disabled states.\n\n```tsx\n// BAD - CSS only, no semantic disabled\nexport function Button({ disabled, children }) {\n  return (\n    <button className={disabled ? \"opacity-50 cursor-not-allowed\" : \"\"}>\n      {children}\n    </button>\n    // Missing disabled attribute and aria-disabled\n  )\n}\n\n// GOOD - semantic + visual disabled\nconst buttonVariants = cva(\"rounded px-4 py-2\", {\n  variants: {\n    variant: {\n      default: \"bg-primary text-primary-foreground hover:bg-primary/90\",\n      outline: \"border hover:bg-accent\",\n    },\n  },\n  defaultVariants: { variant: \"default\" },\n})\n\nexport function Button({ disabled, variant, className, ...props }) {\n  return (\n    <button\n      className={cn(\n        buttonVariants({ variant }),\n        disabled && \"opacity-50 cursor-not-allowed pointer-events-none\",\n        className\n      )}\n      disabled={disabled}\n      aria-disabled={disabled}\n      {...props}\n    />\n  )\n}\n```\n\n### 4. Missing Screen Reader Text\n\n**Problem**: Icon-only buttons or visual indicators need sr-only text for screen readers.\n\n```tsx\n// BAD - icon button with no label\nexport function CloseButton({ onClick }) {\n  return (\n    <button onClick={onClick}>\n      <X className=\"h-4 w-4\" /> {/* No text for screen readers */}\n    </button>\n  )\n}\n\n// GOOD - sr-only text for screen readers\nexport function CloseButton({ onClick }) {\n  return (\n    <button\n      onClick={onClick}\n      aria-label=\"Close\" // For simple cases\n    >\n      <X className=\"h-4 w-4\" />\n    </button>\n  )\n}\n\n// BETTER - visible text with icon\nexport function CloseButton({ onClick }) {\n  return (\n    <button onClick={onClick}>\n      <X className=\"h-4 w-4\" />\n      <span className=\"sr-only\">Close</span>\n    </button>\n  )\n}\n\n// For status indicators:\nexport function Badge({ status, children }) {\n  return (\n    <div className=\"flex items-center gap-2\">\n      <div className={cn(\n        \"h-2 w-2 rounded-full\",\n        status === \"online\" && \"bg-green-500\",\n        status === \"offline\" && \"bg-gray-500\"\n      )} />\n      <span className=\"sr-only\">{status === \"online\" ? \"Online\" : \"Offline\"}</span>\n      {children}\n    </div>\n  )\n}\n```\n\n### 5. Missing Keyboard Navigation\n\n**Problem**: Interactive custom elements must support keyboard navigation.\n\n```tsx\n// BAD - div with onClick, no keyboard support\nexport function Card({ onClick, children }) {\n  return (\n    <div onClick={onClick} className=\"cursor-pointer\">\n      {children}\n    </div>\n  )\n}\n\n// GOOD - proper button with keyboard support\nexport function Card({ onClick, children, ...props }) {\n  if (onClick) {\n    return (\n      <button\n        onClick={onClick}\n        className=\"text-left w-full\"\n        {...props}\n      >\n        {children}\n      </button>\n    )\n  }\n\n  return <div {...props}>{children}</div>\n}\n\n// For custom interactive elements:\nexport function Tab({ active, onClick, children }) {\n  return (\n    <button\n      role=\"tab\"\n      aria-selected={active}\n      onClick={onClick}\n      onKeyDown={(e) => {\n        if (e.key === \"Enter\" || e.key === \" \") {\n          e.preventDefault()\n          onClick(e)\n        }\n      }}\n      tabIndex={active ? 0 : -1}\n      className={cn(\n        \"px-4 py-2\",\n        active && \"border-b-2 border-primary\"\n      )}\n    >\n      {children}\n    </button>\n  )\n}\n```\n\n### 6. Color as Only Indicator\n\n**Problem**: Color alone cannot convey state (WCAG 1.4.1).\n\n```tsx\n// BAD - color only for required fields\nexport function Label({ required, children }) {\n  return (\n    <label className={required ? \"text-red-500\" : \"\"}>\n      {children}\n    </label>\n  )\n}\n\n// GOOD - color + text/icon indicator\nexport function Label({ required, children }) {\n  return (\n    <label>\n      {children}\n      {required && (\n        <>\n          <span className=\"text-destructive ml-1\" aria-hidden=\"true\">*</span>\n          <span className=\"sr-only\">(required)</span>\n        </>\n      )}\n    </label>\n  )\n}\n\n// For status:\nexport function Status({ status }) {\n  const icons = {\n    success: <Check className=\"h-4 w-4\" />,\n    error: <X className=\"h-4 w-4\" />,\n    warning: <AlertTriangle className=\"h-4 w-4\" />,\n  }\n\n  return (\n    <div className={cn(\n      \"flex items-center gap-2\",\n      status === \"success\" && \"text-green-600\",\n      status === \"error\" && \"text-destructive\",\n      status === \"warning\" && \"text-yellow-600\"\n    )}>\n      {icons[status]}\n      <span>{status}</span> {/* Text accompanies color */}\n    </div>\n  )\n}\n```\n\n### 7. Missing Loading States\n\n**Problem**: Async actions must indicate loading state for screen readers.\n\n```tsx\n// BAD - visual spinner only\nexport function Button({ loading, children, ...props }) {\n  return (\n    <button {...props}>\n      {loading ? <Spinner /> : children}\n    </button>\n  )\n}\n\n// GOOD - aria-busy with announcement\nexport function Button({ loading, children, ...props }) {\n  return (\n    <button\n      aria-busy={loading}\n      disabled={loading}\n      {...props}\n    >\n      {loading && <Spinner className=\"mr-2 h-4 w-4 animate-spin\" />}\n      {children}\n      {loading && <span className=\"sr-only\">Loading...</span>}\n    </button>\n  )\n}\n```\n\n## Review Questions\n\n1. Are focus-visible styles used instead of focus?\n2. Is aria-invalid set for error states with describedby?\n3. Do disabled elements have both disabled and aria-disabled?\n4. Are icon-only buttons labeled with sr-only text or aria-label?\n5. Do custom interactive elements support keyboard navigation?\n6. Is state conveyed through more than just color?\n7. Are loading states announced with aria-busy?\n",
        "skills/shadcn-code-review/references/composition.md": "# Component Composition\n\n## Critical Anti-Patterns\n\n### 1. asChild Without Slot\n\n**Problem**: The asChild pattern requires @radix-ui/react-slot to work correctly.\n\n```tsx\n// BAD - asChild without Slot\nexport function Button({ asChild, children, ...props }) {\n  if (asChild) {\n    return children // WRONG - doesn't merge props\n  }\n  return <button {...props}>{children}</button>\n}\n\n// Usage breaks:\n<Button asChild>\n  <Link href=\"/\">Home</Link> {/* Link doesn't receive Button's props */}\n</Button>\n\n// GOOD - using Slot\nimport { Slot } from \"@radix-ui/react-slot\"\n\nexport function Button({ asChild, className, variant, size, ...props }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      className={cn(buttonVariants({ variant, size }), className)}\n      {...props}\n    />\n  )\n}\n\n// Usage works correctly:\n<Button asChild variant=\"outline\">\n  <Link href=\"/\">Home</Link> {/* Link receives variant styles and all props */}\n</Button>\n```\n\n### 2. Missing Context for Compound Components\n\n**Problem**: Component parts cannot communicate state without Context.\n\n```tsx\n// BAD - no context, state passed via props (brittle)\nexport function Card({ variant, children }) {\n  return (\n    <div className={cardVariants({ variant })}>\n      {React.Children.map(children, child =>\n        React.cloneElement(child, { variant }) // WRONG - fragile, breaks with fragments\n      )}\n    </div>\n  )\n}\n\nexport function CardHeader({ variant, children }) {\n  return <div className={headerVariants({ variant })}>{children}</div>\n}\n\n// GOOD - using Context\nconst CardContext = React.createContext<{ variant?: string }>({})\n\nexport function Card({ variant = \"default\", children, ...props }) {\n  return (\n    <CardContext.Provider value={{ variant }}>\n      <div className={cn(cardVariants({ variant }))} {...props}>\n        {children}\n      </div>\n    </CardContext.Provider>\n  )\n}\n\nexport function CardHeader({ className, ...props }) {\n  const { variant } = React.useContext(CardContext)\n  return (\n    <div\n      className={cn(headerVariants({ variant }), className)}\n      {...props}\n    />\n  )\n}\n\n// Usage is clean:\n<Card variant=\"elevated\">\n  <CardHeader>Title</CardHeader> {/* Automatically gets variant */}\n  <CardContent>Content</CardContent>\n</Card>\n```\n\n### 3. Slot Props Not Merged Correctly\n\n**Problem**: When using asChild, child props must be merged with component props.\n\n```tsx\n// BAD - props collision\nexport function Button({ asChild, onClick, ...props }) {\n  const Comp = asChild ? Slot : \"button\"\n  return <Comp onClick={onClick} {...props} /> // Child's onClick is overwritten\n}\n\n// GOOD - proper prop merging with composeEventHandlers\nimport { composeEventHandlers } from \"@radix-ui/primitive\"\nimport { Slot } from \"@radix-ui/react-slot\"\n\nexport function Button({ asChild, onClick, ...props }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      {...props}\n      onClick={composeEventHandlers(onClick, (e) => {\n        // Component's onClick logic\n      })}\n    />\n  )\n}\n\n// Or use Radix's component approach:\nexport const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ asChild = false, onClick, ...props }, ref) => {\n    const Comp = asChild ? Slot : \"button\"\n\n    return (\n      <Comp\n        ref={ref}\n        onClick={onClick}\n        {...props}\n      />\n    )\n  }\n)\n```\n\n### 4. Not Forwarding Refs with asChild\n\n**Problem**: Refs break when using asChild without forwardRef.\n\n```tsx\n// BAD - ref not forwarded\nexport function Button({ asChild, ...props }) {\n  const Comp = asChild ? Slot : \"button\"\n  return <Comp {...props} /> // ref won't work\n}\n\n// Usage breaks:\nconst ref = useRef()\n<Button ref={ref} asChild>\n  <Link>Home</Link> {/* ref is lost */}\n</Button>\n\n// GOOD - forwardRef with asChild\nexport const Button = React.forwardRef<\n  HTMLButtonElement,\n  ButtonProps\n>(({ asChild = false, className, variant, size, ...props }, ref) => {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      className={cn(buttonVariants({ variant, size }), className)}\n      ref={ref}\n      {...props}\n    />\n  )\n})\nButton.displayName = \"Button\"\n```\n\n### 5. Polymorphic Components Without Type Safety\n\n**Problem**: Using 'as' prop without proper TypeScript typing loses type safety.\n\n```tsx\n// BAD - no type safety\nexport function Text({ as = \"p\", ...props }) {\n  const Comp = as\n  return <Comp {...props} /> // No type checking for Comp-specific props\n}\n\n// GOOD - typed polymorphic component\nimport { ElementType, ComponentPropsWithoutRef } from \"react\"\n\ntype PolymorphicProps<E extends ElementType> = {\n  as?: E\n} & ComponentPropsWithoutRef<E>\n\nexport function Text<E extends ElementType = \"p\">({\n  as,\n  className,\n  ...props\n}: PolymorphicProps<E>) {\n  const Comp = as || \"p\"\n\n  return (\n    <Comp\n      className={cn(\"text-base\", className)}\n      {...props}\n    />\n  )\n}\n\n// Usage is type-safe:\n<Text as=\"h1\" onClick={(e) => {/* e is typed correctly */}}>Title</Text>\n<Text as=\"a\" href=\"/about\">Link</Text> {/* href required for 'a' */}\n```\n\n### 6. Overusing React.cloneElement\n\n**Problem**: cloneElement is fragile and breaks with fragments, context, or complex children.\n\n```tsx\n// BAD - cloneElement everywhere\nexport function List({ spacing, children }) {\n  return (\n    <ul>\n      {React.Children.map(children, child =>\n        React.cloneElement(child, { spacing }) // Breaks with fragments, context\n      )}\n    </ul>\n  )\n}\n\n// GOOD - use Context\nconst ListContext = React.createContext({ spacing: \"md\" })\n\nexport function List({ spacing = \"md\", children, ...props }) {\n  return (\n    <ListContext.Provider value={{ spacing }}>\n      <ul {...props}>{children}</ul>\n    </ListContext.Provider>\n  )\n}\n\nexport function ListItem({ className, ...props }) {\n  const { spacing } = React.useContext(ListContext)\n  return (\n    <li\n      className={cn(listItemVariants({ spacing }), className)}\n      {...props}\n    />\n  )\n}\n```\n\n## Review Questions\n\n1. Does asChild use Slot from @radix-ui/react-slot?\n2. Are compound components using Context for state sharing?\n3. Are refs forwarded with React.forwardRef?\n4. Are event handlers composed correctly with asChild?\n5. Is React.cloneElement avoided in favor of Context?\n",
        "skills/shadcn-code-review/references/cva-patterns.md": "# CVA Patterns\n\n## Critical Anti-Patterns\n\n### 1. className Passed to CVA Instead of cn()\n\n**Problem**: CVA variants cannot be overridden by consumers. The className should be passed to cn() after CVA, not as a CVA variant.\n\n```tsx\n// BAD - className in CVA\nimport { cva } from \"class-variance-authority\"\n\nconst buttonVariants = cva(\"base-styles\", {\n  variants: {\n    variant: { default: \"bg-primary\", destructive: \"bg-destructive\" },\n    size: { sm: \"h-9\", lg: \"h-11\" },\n    className: {}, // WRONG - className is not a variant\n  },\n})\n\nexport function Button({ variant, size, className }) {\n  return <button className={buttonVariants({ variant, size })} />\n}\n\n// GOOD - className in cn()\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { cn } from \"@/lib/utils\"\n\nconst buttonVariants = cva(\"base-styles\", {\n  variants: {\n    variant: { default: \"bg-primary\", destructive: \"bg-destructive\" },\n    size: { sm: \"h-9\", lg: \"h-11\" },\n  },\n  defaultVariants: {\n    variant: \"default\",\n    size: \"default\",\n  },\n})\n\nexport interface ButtonProps extends VariantProps<typeof buttonVariants> {\n  className?: string\n}\n\nexport function Button({ variant, size, className, ...props }: ButtonProps) {\n  return (\n    <button\n      className={cn(buttonVariants({ variant, size }), className)}\n      {...props}\n    />\n  )\n}\n```\n\n### 2. Missing VariantProps Export\n\n**Problem**: Consumers cannot type-check variant props correctly.\n\n```tsx\n// BAD - no type export\nconst buttonVariants = cva(...)\n\nexport function Button({ variant, size }: { variant?: string, size?: string }) {\n  return <button className={buttonVariants({ variant, size })} />\n}\n\n// GOOD - export VariantProps\nimport { type VariantProps } from \"class-variance-authority\"\n\nconst buttonVariants = cva(...)\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {\n  asChild?: boolean\n}\n\nexport function Button({ variant, size, className, ...props }: ButtonProps) {\n  return <button className={cn(buttonVariants({ variant, size }), className)} {...props} />\n}\n```\n\n### 3. Not Using Compound Variants\n\n**Problem**: Complex state combinations create verbose, repetitive variant definitions.\n\n```tsx\n// BAD - manual combinations\nconst buttonVariants = cva(\"rounded font-medium\", {\n  variants: {\n    variant: {\n      default: \"bg-primary text-primary-foreground\",\n      outline: \"border border-input bg-background\",\n      ghost: \"hover:bg-accent hover:text-accent-foreground\",\n    },\n    size: {\n      sm: \"h-9 px-3 text-xs\",\n      default: \"h-10 px-4 py-2\",\n      lg: \"h-11 px-8\",\n    },\n    // Trying to handle all combinations manually - WRONG\n    variantSize: {\n      \"outline-sm\": \"border-2\", // Don't do this\n      \"ghost-lg\": \"hover:bg-accent/50\",\n    }\n  },\n})\n\n// GOOD - use compoundVariants\nconst buttonVariants = cva(\"rounded font-medium\", {\n  variants: {\n    variant: {\n      default: \"bg-primary text-primary-foreground\",\n      outline: \"border border-input bg-background\",\n      ghost: \"hover:bg-accent hover:text-accent-foreground\",\n    },\n    size: {\n      sm: \"h-9 px-3 text-xs\",\n      default: \"h-10 px-4 py-2\",\n      lg: \"h-11 px-8\",\n    },\n  },\n  compoundVariants: [\n    {\n      variant: \"outline\",\n      size: \"sm\",\n      class: \"border-2\",\n    },\n    {\n      variant: \"ghost\",\n      size: \"lg\",\n      class: \"hover:bg-accent/50\",\n    },\n  ],\n  defaultVariants: {\n    variant: \"default\",\n    size: \"default\",\n  },\n})\n```\n\n### 4. Hardcoding State Classes Instead of Variants\n\n**Problem**: State-dependent styling should be variants for consistency and reusability.\n\n```tsx\n// BAD - hardcoded state classes\nexport function Input({ disabled, invalid, className }) {\n  return (\n    <input\n      className={cn(\n        \"rounded border px-3 py-2\",\n        disabled && \"opacity-50 cursor-not-allowed\",\n        invalid && \"border-red-500\",\n        className\n      )}\n      disabled={disabled}\n    />\n  )\n}\n\n// GOOD - state variants\nconst inputVariants = cva(\"rounded border px-3 py-2\", {\n  variants: {\n    state: {\n      default: \"\",\n      invalid: \"border-destructive focus-visible:ring-destructive\",\n      disabled: \"opacity-50 cursor-not-allowed\",\n    },\n  },\n  defaultVariants: {\n    state: \"default\",\n  },\n})\n\nexport function Input({ disabled, invalid, className, ...props }) {\n  const state = disabled ? \"disabled\" : invalid ? \"invalid\" : \"default\"\n\n  return (\n    <input\n      className={cn(inputVariants({ state }), className)}\n      disabled={disabled}\n      aria-invalid={invalid}\n      {...props}\n    />\n  )\n}\n```\n\n### 5. Missing defaultVariants\n\n**Problem**: Component behavior is unpredictable without defaults.\n\n```tsx\n// BAD - no defaults\nconst buttonVariants = cva(\"base\", {\n  variants: {\n    variant: { default: \"bg-primary\", outline: \"border\" },\n    size: { sm: \"h-9\", lg: \"h-11\" },\n  },\n  // Missing defaultVariants - what happens with <Button />?\n})\n\n// GOOD - explicit defaults\nconst buttonVariants = cva(\"base\", {\n  variants: {\n    variant: { default: \"bg-primary\", outline: \"border\" },\n    size: { sm: \"h-9\", lg: \"h-11\" },\n  },\n  defaultVariants: {\n    variant: \"default\",\n    size: \"sm\",\n  },\n})\n```\n\n## Review Questions\n\n1. Is className passed to cn() after CVA variants?\n2. Are VariantProps exported for type safety?\n3. Are compound variants used for complex state combinations?\n4. Are state-dependent styles defined as variants?\n5. Are defaultVariants specified for all variant groups?\n",
        "skills/shadcn-code-review/references/data-slot.md": "# data-slot Pattern\n\n## Critical Anti-Patterns\n\n### 1. Missing data-slot Attributes\n\n**Problem**: Component parts cannot be targeted by consumers for custom styling without data-slot.\n\n```tsx\n// BAD - no way to target subcomponents\nexport function Card({ children, ...props }) {\n  return (\n    <div className=\"border rounded-lg\" {...props}>\n      {children}\n    </div>\n  )\n}\n\nexport function CardHeader({ children, ...props }) {\n  return (\n    <div className=\"p-6\" {...props}>\n      {children}\n    </div>\n  )\n}\n\n// Consumer cannot style CardHeader inside Card without fragile selectors:\n<Card className=\"[&>div]:bg-red-500\"> {/* BRITTLE - breaks if structure changes */}\n  <CardHeader>Title</CardHeader>\n</Card>\n\n// GOOD - data-slot for targetable parts\nexport function Card({ children, ...props }) {\n  return (\n    <div className=\"border rounded-lg\" data-slot=\"card\" {...props}>\n      {children}\n    </div>\n  )\n}\n\nexport function CardHeader({ children, ...props }) {\n  return (\n    <div className=\"p-6\" data-slot=\"card-header\" {...props}>\n      {children}\n    </div>\n  )\n}\n\n// Consumer can target with stable selector:\n<Card className=\"[&_[data-slot=card-header]]:bg-red-500\">\n  <CardHeader>Title</CardHeader>\n</Card>\n```\n\n### 2. Not Using has() Selectors for State-Based Styling\n\n**Problem**: Parent styling based on child state requires data-slot + has().\n\n```tsx\n// BAD - manual state prop threading\nexport function Card({ hasError, children }) {\n  return (\n    <div className={cn(\"border\", hasError && \"border-red-500\")}>\n      {children}\n    </div>\n  )\n}\n\nexport function CardContent({ error, children }) {\n  return (\n    <div>\n      {error && <p className=\"text-red-500\">{error}</p>}\n      {children}\n    </div>\n  )\n}\n\n// Usage is verbose:\nconst [error, setError] = useState(\"\")\n<Card hasError={!!error}>\n  <CardContent error={error}>...</CardContent>\n</Card>\n\n// GOOD - has() selector with data-slot\nexport function Card({ children, ...props }) {\n  return (\n    <div\n      className=\"border has-[[data-slot=card-content][data-error]]:border-destructive\"\n      data-slot=\"card\"\n      {...props}\n    >\n      {children}\n    </div>\n  )\n}\n\nexport function CardContent({ error, children, ...props }) {\n  return (\n    <div data-slot=\"card-content\" data-error={error ? \"\" : undefined} {...props}>\n      {error && (\n        <p className=\"text-sm text-destructive\" data-slot=\"card-error\">\n          {error}\n        </p>\n      )}\n      {children}\n    </div>\n  )\n}\n\n// Usage is clean:\n<Card>\n  <CardContent error={error}>...</CardContent>\n</Card>\n```\n\n### 3. Incorrect CSS Targeting Without data-slot\n\n**Problem**: Targeting by element type or class is fragile and breaks with structural changes.\n\n```tsx\n// BAD - targeting by element type\nconst selectVariants = cva(\n  // Targeting trigger button directly - fragile\n  \"[&>button]:flex [&>button]:items-center [&>button]:justify-between\",\n  // Targeting value span - fragile\n  \"[&>button>span]:text-sm [&>button>span]:text-muted-foreground\"\n)\n\nexport function Select({ children }) {\n  return <div className={selectVariants()}>{children}</div>\n}\n\n// GOOD - targeting by data-slot\nconst selectVariants = cva(\n  \"[&_[data-slot=select-trigger]]:flex [&_[data-slot=select-trigger]]:items-center\",\n  \"[&_[data-slot=select-value]]:text-sm [&_[data-slot=select-value]]:text-muted-foreground\"\n)\n\nexport function Select({ children, ...props }) {\n  return (\n    <div className={selectVariants()} data-slot=\"select\" {...props}>\n      {children}\n    </div>\n  )\n}\n\nexport function SelectTrigger({ children, ...props }) {\n  return (\n    <button data-slot=\"select-trigger\" {...props}>\n      {children}\n    </button>\n  )\n}\n\nexport function SelectValue({ children, ...props }) {\n  return (\n    <span data-slot=\"select-value\" {...props}>\n      {children}\n    </span>\n  )\n}\n```\n\n### 4. data-state Without data-slot\n\n**Problem**: data-state is useful but needs data-slot for scoped targeting.\n\n```tsx\n// BAD - data-state only, no scoping\nexport function Accordion({ open, children }) {\n  return (\n    <div data-state={open ? \"open\" : \"closed\"}>\n      {children}\n    </div>\n  )\n}\n\nexport function AccordionTrigger({ children }) {\n  return <button>{children}</button>\n}\n\n// Consumer cannot target trigger based on parent state:\n// Can't write: [&[data-state=open]_button]:rotate-180\n\n// GOOD - data-slot + data-state\nexport function Accordion({ open, children, ...props }) {\n  return (\n    <div\n      data-slot=\"accordion\"\n      data-state={open ? \"open\" : \"closed\"}\n      {...props}\n    >\n      {children}\n    </div>\n  )\n}\n\nexport function AccordionTrigger({ children, ...props }) {\n  return (\n    <button data-slot=\"accordion-trigger\" {...props}>\n      {children}\n    </button>\n  )\n}\n\n// Consumer can target:\n<Accordion className=\"[&[data-state=open]_[data-slot=accordion-trigger]]:rotate-180\">\n  <AccordionTrigger>...</AccordionTrigger>\n</Accordion>\n\n// Or use has():\n<Accordion className=\"has-[[data-slot=accordion-trigger][aria-expanded=true]]:bg-accent\">\n```\n\n### 5. Nested Component Targeting\n\n**Problem**: Deeply nested components need data-slot for stable targeting.\n\n```tsx\n// BAD - descendant selectors by element\nexport function Table({ children }) {\n  return (\n    <table className=\"[&_thead_tr]:border-b [&_tbody_tr]:border-b [&_td]:p-4\">\n      {children}\n    </table>\n  )\n}\n\n// Breaks if you add divs or other elements in structure\n\n// GOOD - data-slot for all parts\nexport function Table({ children, ...props }) {\n  return (\n    <table\n      data-slot=\"table\"\n      className=\"[&_[data-slot=table-header-row]]:border-b [&_[data-slot=table-row]]:border-b [&_[data-slot=table-cell]]:p-4\"\n      {...props}\n    >\n      {children}\n    </table>\n  )\n}\n\nexport function TableHeader({ children, ...props }) {\n  return (\n    <thead data-slot=\"table-header\" {...props}>\n      {children}\n    </thead>\n  )\n}\n\nexport function TableRow({ children, ...props }) {\n  return (\n    <tr data-slot=\"table-row\" {...props}>\n      {children}\n    </tr>\n  )\n}\n\nexport function TableCell({ children, ...props }) {\n  return (\n    <td data-slot=\"table-cell\" {...props}>\n      {children}\n    </td>\n  )\n}\n```\n\n### 6. Using data-slot for State Instead of data-state\n\n**Problem**: data-slot is for targeting parts, data-state is for state values.\n\n```tsx\n// BAD - using data-slot for state\nexport function Tab({ active, children }) {\n  return (\n    <button\n      data-slot={active ? \"tab-active\" : \"tab-inactive\"} // WRONG - use data-state\n    >\n      {children}\n    </button>\n  )\n}\n\n// GOOD - data-slot for type, data-state for state\nexport function Tab({ active, children, ...props }) {\n  return (\n    <button\n      data-slot=\"tab\"\n      data-state={active ? \"active\" : \"inactive\"}\n      role=\"tab\"\n      aria-selected={active}\n      {...props}\n    >\n      {children}\n    </button>\n  )\n}\n\n// Targeting:\n<TabList className=\"[&_[data-slot=tab][data-state=active]]:border-b-2\">\n  <Tab active>...</Tab>\n</TabList>\n```\n\n## Review Questions\n\n1. Do all component parts have data-slot attributes?\n2. Are has() selectors used for state-based parent styling?\n3. Is CSS targeting using data-slot instead of element types?\n4. Are data-state and data-slot used together for stateful components?\n5. Can consumers reliably target nested component parts?\n6. Is data-slot used for identification and data-state for values?\n",
        "skills/shadcn-ui/SKILL.md": "---\nname: shadcn-ui\ndescription: shadcn/ui component patterns with Radix primitives and Tailwind styling. Use when building UI components, using CVA variants, implementing compound components, or styling with data-slot attributes. Triggers on shadcn, cva, cn(), data-slot, Radix, Button, Card, Dialog, VariantProps.\n---\n\n# shadcn/ui Component Development\n\n## Contents\n\n- [CLI Commands](#cli-commands) - Installing and adding components\n- [Quick Reference](#quick-reference) - cn(), basic CVA pattern\n- [Component Anatomy](#component-anatomy) - Props typing, asChild, data-slot\n- [Component Patterns](#component-patterns) - Compound components\n- [Styling Techniques](#styling-techniques) - CVA variants, modern CSS selectors, accessibility states\n- [Decision Tables](#decision-tables) - When to use CVA, compound components, asChild, Context\n- [Common Patterns](#common-patterns) - Form elements, dialogs, sidebars\n- [Reference Files](#reference-files) - Full implementations and advanced patterns\n\n## CLI Commands\n\n### Initialize shadcn/ui\n\n```bash\nnpx shadcn@latest init\n```\n\nThis creates a `components.json` configuration file and sets up:\n- Tailwind CSS configuration\n- CSS variables for theming\n- cn() utility function\n- Required dependencies\n\n### Add Components\n\n```bash\n# Add a single component\nnpx shadcn@latest add button\n\n# Add multiple components\nnpx shadcn@latest add button card dialog\n\n# Add all available components\nnpx shadcn@latest add --all\n```\n\n**Important:** The package name changed in 2024:\n- Old (deprecated): `npx shadcn-ui@latest add`\n- Current: `npx shadcn@latest add`\n\n### Common Options\n\n- `-y, --yes` - Skip confirmation prompt\n- `-o, --overwrite` - Overwrite existing files\n- `-c, --cwd <cwd>` - Set working directory\n- `--src-dir` - Use src directory structure\n\n## Quick Reference\n\n### cn() Utility\n\n```tsx\nimport { clsx, type ClassValue } from \"clsx\"\nimport { twMerge } from \"tailwind-merge\"\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n}\n```\n\n### Basic CVA Pattern\n\n```tsx\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nconst buttonVariants = cva(\n  \"base-classes-applied-to-all-variants\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground\",\n        outline: \"border bg-background\",\n      },\n      size: {\n        sm: \"h-8 px-3\",\n        lg: \"h-10 px-6\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"sm\",\n    },\n  }\n)\n\nfunction Button({\n  variant,\n  size,\n  className,\n  ...props\n}: React.ComponentProps<\"button\"> & VariantProps<typeof buttonVariants>) {\n  return (\n    <button\n      className={cn(buttonVariants({ variant, size }), className)}\n      {...props}\n    />\n  )\n}\n\nexport { Button, buttonVariants }\n```\n\n## Component Anatomy\n\n### Props Typing Patterns\n\n```tsx\n// HTML elements\nfunction Component({ className, ...props }: React.ComponentProps<\"div\">) {\n  return <div className={cn(\"base-classes\", className)} {...props} />\n}\n\n// Radix primitives\nfunction Component({ className, ...props }: React.ComponentProps<typeof RadixPrimitive.Root>) {\n  return <RadixPrimitive.Root className={cn(\"base-classes\", className)} {...props} />\n}\n\n// With CVA variants\nfunction Component({\n  variant, size, className, ...props\n}: React.ComponentProps<\"button\"> & VariantProps<typeof variants>) {\n  return <button className={cn(variants({ variant, size }), className)} {...props} />\n}\n```\n\n### asChild Pattern\n\nEnables polymorphic rendering via `@radix-ui/react-slot`:\n\n```tsx\nimport { Slot } from \"@radix-ui/react-slot\"\n\nfunction Button({\n  asChild = false,\n  className,\n  variant,\n  size,\n  ...props\n}: React.ComponentProps<\"button\"> & VariantProps<typeof buttonVariants> & { asChild?: boolean }) {\n  const Comp = asChild ? Slot : \"button\"\n  return (\n    <Comp\n      data-slot=\"button\"\n      className={cn(buttonVariants({ variant, size }), className)}\n      {...props}\n    />\n  )\n}\n```\n\n**Usage:**\n```tsx\n<Button>Click me</Button>                           // Renders <button>\n<Button asChild><a href=\"/home\">Home</a></Button>   // Renders <a> with button styling\n<Button asChild><Link href=\"/dash\">Dash</Link></Button>  // Works with Next.js Link\n```\n\n### data-slot Attributes\n\nEvery component includes `data-slot` for CSS targeting:\n\n```tsx\nfunction Card({ ...props }) { return <div data-slot=\"card\" {...props} /> }\nfunction CardHeader({ ...props }) { return <div data-slot=\"card-header\" {...props} /> }\n```\n\n**CSS/Tailwind targeting:**\n```css\n[data-slot=\"button\"] { /* styles */ }\n[data-slot=\"card\"] [data-slot=\"button\"] { /* nested targeting */ }\n```\n\n```tsx\n<div className=\"[&_[data-slot=button]]:shadow-lg\">\n  <Button>Automatically styled</Button>\n</div>\n```\n\n**Conditional layouts with has():**\n```tsx\n<div\n  data-slot=\"card-header\"\n  className={cn(\n    \"grid gap-2\",\n    \"has-data-[slot=card-action]:grid-cols-[1fr_auto]\"\n  )}\n/>\n```\n\n## Component Patterns\n\n### Compound Components\n\n```tsx\nexport { Card, CardHeader, CardTitle, CardDescription, CardContent, CardFooter }\n\nfunction Card({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card\"\n      className={cn(\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardHeader({ className, ...props }: React.ComponentProps<\"div\">) {\n  return <div data-slot=\"card-header\" className={cn(\"grid gap-2 px-6\", className)} {...props} />\n}\n\nfunction CardTitle({ className, ...props }: React.ComponentProps<\"div\">) {\n  return <div data-slot=\"card-title\" className={cn(\"leading-none font-semibold\", className)} {...props} />\n}\n```\n\n## Styling Techniques\n\n### CVA Variants\n\n**Multiple dimensions:**\n```tsx\nconst buttonVariants = cva(\"base-classes\", {\n  variants: {\n    variant: {\n      default: \"bg-primary text-primary-foreground\",\n      destructive: \"bg-destructive text-white\",\n      outline: \"border bg-background\",\n      ghost: \"hover:bg-accent\",\n      link: \"text-primary underline-offset-4 hover:underline\",\n    },\n    size: {\n      default: \"h-9 px-4 py-2\",\n      sm: \"h-8 px-3\",\n      lg: \"h-10 px-6\",\n      icon: \"size-9\",\n    },\n  },\n  defaultVariants: { variant: \"default\", size: \"default\" },\n})\n```\n\n**Compound variants:**\n```tsx\ncompoundVariants: [\n  { variant: \"outline\", size: \"lg\", class: \"border-2\" },\n]\n```\n\n**Type extraction:**\n```tsx\ntype ButtonVariants = VariantProps<typeof buttonVariants>\n// Result: { variant?: \"default\" | \"outline\" | ..., size?: \"sm\" | \"lg\" | ... }\n```\n\n### Modern CSS Selectors in Tailwind\n\n**has() selector:**\n```tsx\n<button className=\"px-4 has-[>svg]:px-3\">  // Adjusts padding when contains icon\n<div className=\"has-data-[slot=action]:grid-cols-[1fr_auto]\">  // Conditional layout\n```\n\n**Group/peer selectors:**\n```tsx\n<div className=\"group\" data-state=\"collapsed\">\n  <div className=\"group-data-[state=collapsed]:hidden\">Hidden when collapsed</div>\n</div>\n\n<button className=\"peer/menu\" data-active=\"true\">Menu</button>\n<div className=\"peer-data-[active=true]/menu:text-accent\">Styled when sibling active</div>\n```\n\n**Container queries:**\n```tsx\n<div className=\"@container/card\">\n  <div className=\"@md:flex-row\">Responds to container width</div>\n</div>\n```\n\n### Accessibility States\n\n```tsx\nclassName={cn(\n  // Focus\n  \"outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]\",\n  // Invalid\n  \"aria-invalid:border-destructive aria-invalid:ring-destructive/20\",\n  // Disabled\n  \"disabled:pointer-events-none disabled:opacity-50\",\n)}\n\n<span className=\"sr-only\">Close</span>  // Screen reader only\n```\n\n### Dark Mode\n\nSemantic tokens adapt automatically:\n```tsx\nclassName=\"bg-background text-foreground dark:bg-input/30 dark:hover:bg-input/50\"\n```\n\nTokens: `bg-background`, `text-foreground`, `bg-primary`, `text-primary-foreground`, `bg-card`, `text-card-foreground`, `border-input`, `text-muted-foreground`\n\n## Decision Tables\n\n### When to Use CVA\n\n| Scenario | Use CVA | Alternative |\n|----------|---------|-------------|\n| Multiple visual variants (primary, outline, ghost) | Yes | Plain className |\n| Size variations (sm, md, lg) | Yes | Plain className |\n| Compound conditions (outline + large = thick border) | Yes | Conditional cn() |\n| One-off custom styling | No | className prop |\n| Dynamic colors from props | No | Inline styles or CSS variables |\n\n### When to Use Compound Components\n\n| Scenario | Use Compound | Alternative |\n|----------|--------------|-------------|\n| Complex UI with multiple semantic parts | Yes | Single component with many props |\n| Optional sections (header, footer) | Yes | Boolean show/hide props |\n| Different styling for each part | Yes | CSS selectors |\n| Shared state between parts | Yes + Context | Props drilling |\n| Simple wrapper with children | No | Single component |\n\n### When to Use asChild\n\n| Scenario | Use asChild | Alternative |\n|----------|-------------|-------------|\n| Component should work as link or button | Yes | Duplicate component |\n| Need button styles on custom element | Yes | Export variant styles |\n| Integration with routing libraries | Yes | Wrapper components |\n| Always renders same element | No | Standard component |\n\n### When to Use Context\n\n| Scenario | Use Context | Alternative |\n|----------|-------------|-------------|\n| Deep prop drilling (>3 levels) | Yes | Props |\n| State shared by many siblings | Yes | Lift state up |\n| Plugin/extension architecture | Yes | Props |\n| Simple parent-child communication | No | Props |\n\n## Common Patterns\n\n### Form Input\n\n```tsx\nfunction Input({ className, type, ...props }: React.ComponentProps<\"input\">) {\n  return (\n    <input\n      type={type}\n      data-slot=\"input\"\n      className={cn(\n        \"h-9 w-full rounded-md border px-3 py-1\",\n        \"outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]\",\n        \"aria-invalid:border-destructive aria-invalid:ring-destructive/20\",\n        \"disabled:cursor-not-allowed disabled:opacity-50\",\n        \"placeholder:text-muted-foreground dark:bg-input/30\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n```\n\n### Dialog Content\n\n```tsx\nfunction DialogContent({ children, showCloseButton = true, ...props }) {\n  return (\n    <DialogPortal>\n      <DialogOverlay />\n      <DialogPrimitive.Content\n        data-slot=\"dialog-content\"\n        className={cn(\n          \"fixed top-[50%] left-[50%] translate-x-[-50%] translate-y-[-50%] w-full max-w-lg\",\n          \"bg-background border rounded-lg p-6 shadow-lg\",\n          \"data-[state=open]:animate-in data-[state=open]:fade-in-0 data-[state=open]:zoom-in-95\",\n          \"data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95\",\n        )}\n        {...props}\n      >\n        {children}\n        {showCloseButton && (\n          <DialogPrimitive.Close className=\"absolute top-4 right-4\">\n            <XIcon /><span className=\"sr-only\">Close</span>\n          </DialogPrimitive.Close>\n        )}\n      </DialogPrimitive.Content>\n    </DialogPortal>\n  )\n}\n```\n\n### Sidebar with Context\n\n```tsx\nfunction SidebarProvider({ defaultOpen = true, children }) {\n  const isMobile = useIsMobile()\n  const [open, setOpen] = React.useState(defaultOpen)\n\n  React.useEffect(() => {\n    const handleKeyDown = (e: KeyboardEvent) => {\n      if (e.key === \"b\" && (e.metaKey || e.ctrlKey)) {\n        e.preventDefault()\n        setOpen(o => !o)\n      }\n    }\n    window.addEventListener(\"keydown\", handleKeyDown)\n    return () => window.removeEventListener(\"keydown\", handleKeyDown)\n  }, [])\n\n  const contextValue = React.useMemo(\n    () => ({ state: open ? \"expanded\" : \"collapsed\", open, setOpen, isMobile }),\n    [open, setOpen, isMobile]\n  )\n\n  return (\n    <SidebarContext.Provider value={contextValue}>\n      <div\n        data-slot=\"sidebar-wrapper\"\n        style={{ \"--sidebar-width\": \"16rem\", \"--sidebar-width-icon\": \"3rem\" } as React.CSSProperties}\n      >\n        {children}\n      </div>\n    </SidebarContext.Provider>\n  )\n}\n```\n\n## Reference Files\n\nFor comprehensive examples and advanced patterns:\n\n- **[components.md](./references/components.md)** - Full implementations: Button, Card, Badge, Input, Label, Textarea, Dialog\n- **[cva.md](./references/cva.md)** - CVA patterns: compound variants, responsive variants, type extraction\n- **[patterns.md](./references/patterns.md)** - Architectural patterns: compound components, asChild, controlled state, Context, data-slot, has() selectors\n",
        "skills/shadcn-ui/references/components.md": "# shadcn/ui Component Reference\n\nThis document provides complete component implementations from shadcn/ui, demonstrating proper TypeScript typing, variant patterns, and data-slot usage.\n\n## Table of Contents\n\n- [Button Component](#button-component)\n- [Card Compound Component](#card-compound-component)\n- [Badge Component](#badge-component)\n- [Input Component](#input-component)\n- [Label Component](#label-component)\n- [Textarea Component](#textarea-component)\n- [Dialog Component](#dialog-component)\n\n## Button Component\n\nThe Button component demonstrates CVA variants, asChild polymorphism, and proper TypeScript typing.\n\n```tsx\nimport * as React from \"react\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { cn } from \"@/lib/utils\"\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground hover:bg-primary/90\",\n        destructive:\n          \"bg-destructive text-white hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50\",\n        secondary:\n          \"bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n        ghost:\n          \"hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2 has-[>svg]:px-3\",\n        sm: \"h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5\",\n        lg: \"h-10 rounded-md px-6 has-[>svg]:px-4\",\n        icon: \"size-9\",\n        \"icon-sm\": \"size-8\",\n        \"icon-lg\": \"size-10\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n\nfunction Button({\n  className,\n  variant,\n  size,\n  asChild = false,\n  ...props\n}: React.ComponentProps<\"button\"> &\n  VariantProps<typeof buttonVariants> & {\n    asChild?: boolean\n  }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      data-slot=\"button\"\n      className={cn(buttonVariants({ variant, size, className }))}\n      {...props}\n    />\n  )\n}\n\nexport { Button, buttonVariants }\n```\n\n**Key Features:**\n- CVA variants for `variant` and `size` props\n- `defaultVariants` specify fallback values\n- `asChild` pattern using `@radix-ui/react-slot` for polymorphism\n- TypeScript: `React.ComponentProps<\"button\">` + `VariantProps<typeof buttonVariants>`\n- `data-slot=\"button\"` for CSS targeting\n- `has-[>svg]:px-3` - modern CSS selector for conditional padding\n\n## Card Compound Component\n\nThe Card component family demonstrates the compound component pattern with multiple related components.\n\n```tsx\nimport * as React from \"react\"\nimport { cn } from \"@/lib/utils\"\n\nfunction Card({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card\"\n      className={cn(\n        \"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardHeader({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-header\"\n      className={cn(\n        \"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardTitle({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-title\"\n      className={cn(\"leading-none font-semibold\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardDescription({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-description\"\n      className={cn(\"text-muted-foreground text-sm\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardAction({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-action\"\n      className={cn(\n        \"col-start-2 row-span-2 row-start-1 self-start justify-self-end\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardContent({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-content\"\n      className={cn(\"px-6\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardFooter({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-footer\"\n      className={cn(\"flex items-center px-6 [.border-t]:pt-6\", className)}\n      {...props}\n    />\n  )\n}\n\nexport {\n  Card,\n  CardHeader,\n  CardFooter,\n  CardTitle,\n  CardAction,\n  CardDescription,\n  CardContent,\n}\n```\n\n**Key Features:**\n- Compound component pattern - each part is independently exported\n- Each component has its own `data-slot` attribute\n- Container queries: `@container/card-header`\n- Advanced selectors: `has-data-[slot=card-action]:grid-cols-[1fr_auto]`\n- Parent class selectors: `[.border-b]:pb-6`\n- Consistent `React.ComponentProps<\"div\">` typing\n\n**Usage Example:**\n```tsx\n<Card>\n  <CardHeader>\n    <CardTitle>Title</CardTitle>\n    <CardDescription>Description</CardDescription>\n    <CardAction>\n      <Button>Action</Button>\n    </CardAction>\n  </CardHeader>\n  <CardContent>Content here</CardContent>\n  <CardFooter>Footer content</CardFooter>\n</Card>\n```\n\n## Badge Component\n\nThe Badge component shows variant-based styling with asChild support.\n\n```tsx\nimport * as React from \"react\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { cn } from \"@/lib/utils\"\n\nconst badgeVariants = cva(\n  \"inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90\",\n        secondary:\n          \"border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90\",\n        destructive:\n          \"border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nfunction Badge({\n  className,\n  variant,\n  asChild = false,\n  ...props\n}: React.ComponentProps<\"span\"> &\n  VariantProps<typeof badgeVariants> & { asChild?: boolean }) {\n  const Comp = asChild ? Slot : \"span\"\n\n  return (\n    <Comp\n      data-slot=\"badge\"\n      className={cn(badgeVariants({ variant }), className)}\n      {...props}\n    />\n  )\n}\n\nexport { Badge, badgeVariants }\n```\n\n**Key Features:**\n- `[a&]:hover:bg-primary/90` - parent selector for link wrappers\n- `transition-[color,box-shadow]` - specific transition properties\n- `asChild` polymorphism for rendering as different elements\n- Single variant dimension with four options\n\n## Input Component\n\nThe Input component shows form element styling with focus and validation states.\n\n```tsx\nimport * as React from \"react\"\nimport { cn } from \"@/lib/utils\"\n\nfunction Input({ className, type, ...props }: React.ComponentProps<\"input\">) {\n  return (\n    <input\n      type={type}\n      data-slot=\"input\"\n      className={cn(\n        \"file:text-foreground placeholder:text-muted-foreground selection:bg-primary selection:text-primary-foreground dark:bg-input/30 border-input h-9 w-full min-w-0 rounded-md border bg-transparent px-3 py-1 text-base shadow-xs transition-[color,box-shadow] outline-none file:inline-flex file:h-7 file:border-0 file:bg-transparent file:text-sm file:font-medium disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n        \"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]\",\n        \"aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Input }\n```\n\n**Key Features:**\n- `file:*` pseudo-element styling for file inputs\n- `placeholder:*` pseudo-class styling\n- `selection:*` pseudo-element for text selection\n- `aria-invalid:*` accessibility state styling\n- `focus-visible:*` for keyboard navigation focus\n- Responsive text sizing: `text-base md:text-sm`\n\n## Label Component\n\nThe Label component wraps Radix UI primitives with proper styling.\n\n```tsx\nimport * as React from \"react\"\nimport * as LabelPrimitive from \"@radix-ui/react-label\"\nimport { cn } from \"@/lib/utils\"\n\nfunction Label({\n  className,\n  ...props\n}: React.ComponentProps<typeof LabelPrimitive.Root>) {\n  return (\n    <LabelPrimitive.Root\n      data-slot=\"label\"\n      className={cn(\n        \"flex items-center gap-2 text-sm leading-none font-medium select-none group-data-[disabled=true]:pointer-events-none group-data-[disabled=true]:opacity-50 peer-disabled:cursor-not-allowed peer-disabled:opacity-50\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Label }\n```\n\n**Key Features:**\n- Wraps `@radix-ui/react-label` primitive\n- `React.ComponentProps<typeof LabelPrimitive.Root>` - type from primitive\n- `group-data-[disabled=true]:*` - group state styling\n- `peer-disabled:*` - sibling state styling\n\n## Textarea Component\n\nThe Textarea component demonstrates form element with field-sizing.\n\n```tsx\nimport * as React from \"react\"\nimport { cn } from \"@/lib/utils\"\n\nfunction Textarea({ className, ...props }: React.ComponentProps<\"textarea\">) {\n  return (\n    <textarea\n      data-slot=\"textarea\"\n      className={cn(\n        \"border-input placeholder:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 flex field-sizing-content min-h-16 w-full rounded-md border bg-transparent px-3 py-2 text-base shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Textarea }\n```\n\n**Key Features:**\n- `field-sizing-content` - auto-grow textarea\n- `min-h-16` with auto-expand capability\n- Same focus/validation states as Input\n- Consistent form element styling patterns\n\n## Dialog Component\n\nThe Dialog component demonstrates Radix UI integration with compound components.\n\n```tsx\nimport * as React from \"react\"\nimport * as DialogPrimitive from \"@radix-ui/react-dialog\"\nimport { XIcon } from \"lucide-react\"\nimport { cn } from \"@/lib/utils\"\n\nfunction Dialog({\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Root>) {\n  return <DialogPrimitive.Root data-slot=\"dialog\" {...props} />\n}\n\nfunction DialogTrigger({\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Trigger>) {\n  return <DialogPrimitive.Trigger data-slot=\"dialog-trigger\" {...props} />\n}\n\nfunction DialogPortal({\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Portal>) {\n  return <DialogPrimitive.Portal data-slot=\"dialog-portal\" {...props} />\n}\n\nfunction DialogClose({\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Close>) {\n  return <DialogPrimitive.Close data-slot=\"dialog-close\" {...props} />\n}\n\nfunction DialogOverlay({\n  className,\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Overlay>) {\n  return (\n    <DialogPrimitive.Overlay\n      data-slot=\"dialog-overlay\"\n      className={cn(\n        \"data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction DialogContent({\n  className,\n  children,\n  showCloseButton = true,\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Content> & {\n  showCloseButton?: boolean\n}) {\n  return (\n    <DialogPortal data-slot=\"dialog-portal\">\n      <DialogOverlay />\n      <DialogPrimitive.Content\n        data-slot=\"dialog-content\"\n        className={cn(\n          \"bg-background data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 fixed top-[50%] left-[50%] z-50 grid w-full max-w-[calc(100%-2rem)] translate-x-[-50%] translate-y-[-50%] gap-4 rounded-lg border p-6 shadow-lg duration-200 sm:max-w-lg\",\n          className\n        )}\n        {...props}\n      >\n        {children}\n        {showCloseButton && (\n          <DialogPrimitive.Close\n            data-slot=\"dialog-close\"\n            className=\"ring-offset-background focus:ring-ring data-[state=open]:bg-accent data-[state=open]:text-muted-foreground absolute top-4 right-4 rounded-xs opacity-70 transition-opacity hover:opacity-100 focus:ring-2 focus:ring-offset-2 focus:outline-hidden disabled:pointer-events-none [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4\"\n          >\n            <XIcon />\n            <span className=\"sr-only\">Close</span>\n          </DialogPrimitive.Close>\n        )}\n      </DialogPrimitive.Content>\n    </DialogPortal>\n  )\n}\n\nfunction DialogHeader({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"dialog-header\"\n      className={cn(\"flex flex-col gap-2 text-center sm:text-left\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction DialogFooter({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"dialog-footer\"\n      className={cn(\n        \"flex flex-col-reverse gap-2 sm:flex-row sm:justify-end\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction DialogTitle({\n  className,\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Title>) {\n  return (\n    <DialogPrimitive.Title\n      data-slot=\"dialog-title\"\n      className={cn(\"text-lg leading-none font-semibold\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction DialogDescription({\n  className,\n  ...props\n}: React.ComponentProps<typeof DialogPrimitive.Description>) {\n  return (\n    <DialogPrimitive.Description\n      data-slot=\"dialog-description\"\n      className={cn(\"text-muted-foreground text-sm\", className)}\n      {...props}\n    />\n  )\n}\n\nexport {\n  Dialog,\n  DialogClose,\n  DialogContent,\n  DialogDescription,\n  DialogFooter,\n  DialogHeader,\n  DialogOverlay,\n  DialogPortal,\n  DialogTitle,\n  DialogTrigger,\n}\n```\n\n**Key Features:**\n- Wraps multiple Radix UI Dialog primitives\n- `data-[state=open]:*` - animation based on primitive state\n- Portal for overlay rendering outside DOM hierarchy\n- Optional `showCloseButton` prop with default value\n- `sr-only` for screen reader text\n- Center positioning with transform: `top-[50%] left-[50%] translate-x-[-50%] translate-y-[-50%]`\n\n**Usage Example:**\n```tsx\n<Dialog>\n  <DialogTrigger asChild>\n    <Button>Open Dialog</Button>\n  </DialogTrigger>\n  <DialogContent>\n    <DialogHeader>\n      <DialogTitle>Dialog Title</DialogTitle>\n      <DialogDescription>Dialog description text.</DialogDescription>\n    </DialogHeader>\n    <div>Content goes here</div>\n    <DialogFooter>\n      <Button>Cancel</Button>\n      <Button>Confirm</Button>\n    </DialogFooter>\n  </DialogContent>\n</Dialog>\n```\n",
        "skills/shadcn-ui/references/cva.md": "# Class Variance Authority (CVA) Reference\n\nThis document covers CVA patterns used in shadcn/ui for variant-based styling with Tailwind CSS.\n\n## Basic CVA Pattern\n\n```tsx\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nconst componentVariants = cva(\n  // Base classes applied to all variants\n  \"base-class-1 base-class-2\",\n  {\n    variants: {\n      // Variant dimension name\n      variantName: {\n        // Variant option: classes\n        option1: \"classes-for-option-1\",\n        option2: \"classes-for-option-2\",\n      },\n    },\n    defaultVariants: {\n      variantName: \"option1\",\n    },\n  }\n)\n\n// Extract TypeScript types from the variant definition\ntype ComponentVariants = VariantProps<typeof componentVariants>\n```\n\n## Button Variants Example\n\n```tsx\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground hover:bg-primary/90\",\n        destructive: \"bg-destructive text-white hover:bg-destructive/90\",\n        outline: \"border bg-background shadow-xs hover:bg-accent\",\n        ghost: \"hover:bg-accent hover:text-accent-foreground\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2\",\n        sm: \"h-8 rounded-md gap-1.5 px-3\",\n        lg: \"h-10 rounded-md px-6\",\n        icon: \"size-9\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n```\n\n**Usage in Component:**\n```tsx\nfunction Button({\n  className,\n  variant,\n  size,\n  ...props\n}: React.ComponentProps<\"button\"> &\n  VariantProps<typeof buttonVariants>) {\n  return (\n    <button\n      className={cn(buttonVariants({ variant, size, className }))}\n      {...props}\n    />\n  )\n}\n```\n\n## Compound Variants\n\nCompound variants apply classes when multiple variant conditions are met simultaneously.\n\n```tsx\nconst buttonVariants = cva(\n  \"base-classes\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary\",\n        outline: \"border\",\n      },\n      size: {\n        sm: \"h-8\",\n        lg: \"h-12\",\n      },\n      disabled: {\n        true: \"opacity-50\",\n        false: \"\",\n      },\n    },\n    compoundVariants: [\n      {\n        // When variant=outline AND size=lg\n        variant: \"outline\",\n        size: \"lg\",\n        class: \"border-2\", // Use thicker border\n      },\n      {\n        // When variant=default AND disabled=true\n        variant: \"default\",\n        disabled: true,\n        class: \"bg-primary/50\", // Dim the background\n      },\n    ],\n    defaultVariants: {\n      variant: \"default\",\n      size: \"sm\",\n      disabled: false,\n    },\n  }\n)\n```\n\n## Sidebar Menu Button Variants\n\nReal-world example with compound variants from Sidebar component:\n\n```tsx\nconst sidebarMenuButtonVariants = cva(\n  \"peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left text-sm outline-hidden ring-sidebar-ring transition-[width,height,padding] hover:bg-sidebar-accent focus-visible:ring-2 disabled:pointer-events-none disabled:opacity-50 group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2!\",\n  {\n    variants: {\n      variant: {\n        default: \"hover:bg-sidebar-accent hover:text-sidebar-accent-foreground\",\n        outline:\n          \"bg-background shadow-[0_0_0_1px_hsl(var(--sidebar-border))] hover:shadow-[0_0_0_1px_hsl(var(--sidebar-accent))]\",\n      },\n      size: {\n        default: \"h-8 text-sm\",\n        sm: \"h-7 text-xs\",\n        lg: \"h-12 text-sm group-data-[collapsible=icon]:p-0!\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n```\n\n**Key Features:**\n- `peer/menu-button` - named peer for sibling selectors\n- `group-data-[collapsible=icon]:size-8!` - conditional sizing based on parent state\n- `transition-[width,height,padding]` - specific transition properties\n- Custom CSS variables: `hsl(var(--sidebar-border))`\n\n## Default Variants\n\nDefault variants specify which variant options are used when no props are provided:\n\n```tsx\nconst badgeVariants = cva(\n  \"inline-flex items-center rounded-full border px-2 py-0.5 text-xs font-medium\",\n  {\n    variants: {\n      variant: {\n        default: \"border-transparent bg-primary text-primary-foreground\",\n        secondary: \"border-transparent bg-secondary text-secondary-foreground\",\n        destructive: \"border-transparent bg-destructive text-white\",\n        outline: \"text-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\", // Used when no variant prop provided\n    },\n  }\n)\n\n// Usage\n<Badge /> // Uses variant=\"default\"\n<Badge variant=\"destructive\" /> // Uses variant=\"destructive\"\n```\n\n## Responsive Variants with Container Queries\n\nCVA variants can include responsive modifiers and container query classes:\n\n```tsx\nconst cardVariants = cva(\n  \"rounded-lg border p-4\",\n  {\n    variants: {\n      layout: {\n        compact: \"gap-2 @container/card:gap-4\",\n        comfortable: \"gap-4 @container/card:gap-6\",\n        spacious: \"gap-6 @container/card:gap-8\",\n      },\n      responsive: {\n        true: \"flex-col @md:flex-row\",\n        false: \"flex-col\",\n      },\n    },\n    defaultVariants: {\n      layout: \"comfortable\",\n      responsive: true,\n    },\n  }\n)\n```\n\n**Key Features:**\n- `@container/card:gap-4` - container query modifier\n- `@md:flex-row` - container breakpoint\n- Boolean variants for toggleable behavior\n\n## Integration with cn() Utility\n\nCVA works seamlessly with the `cn()` utility for merging class names:\n\n```tsx\nimport { clsx, type ClassValue } from \"clsx\"\nimport { twMerge } from \"tailwind-merge\"\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n}\n\n// In component\nfunction Button({\n  className,\n  variant,\n  size,\n  ...props\n}: React.ComponentProps<\"button\"> & VariantProps<typeof buttonVariants>) {\n  return (\n    <button\n      className={cn(\n        buttonVariants({ variant, size }), // CVA output\n        className // User-provided overrides\n      )}\n      {...props}\n    />\n  )\n}\n```\n\n**How it works:**\n1. `buttonVariants({ variant, size })` generates variant classes\n2. User's `className` prop can override specific properties\n3. `clsx()` conditionally combines classes\n4. `twMerge()` intelligently merges Tailwind classes, resolving conflicts\n\n## Type Extraction\n\nExtract TypeScript types from variant definitions:\n\n```tsx\nimport { type VariantProps } from \"class-variance-authority\"\n\nconst buttonVariants = cva(\"base\", {\n  variants: {\n    variant: { default: \"\", destructive: \"\" },\n    size: { sm: \"\", md: \"\", lg: \"\" },\n  },\n})\n\n// Extract types for use in component props\ntype ButtonVariants = VariantProps<typeof buttonVariants>\n// Result:\n// {\n//   variant?: \"default\" | \"destructive\"\n//   size?: \"sm\" | \"md\" | \"lg\"\n// }\n\n// Use in component\ninterface ButtonProps extends React.ComponentProps<\"button\">, ButtonVariants {\n  asChild?: boolean\n}\n```\n\n## Export Pattern\n\nAlways export both the component and the variants for reusability:\n\n```tsx\nconst buttonVariants = cva(/* ... */)\n\nfunction Button({ ... }) {\n  // Implementation\n}\n\n// Export both for external use\nexport { Button, buttonVariants }\n```\n\n**Why export variants:**\n- Allows style reuse in other components\n- Enables composition of variant styles\n- Supports extending components with same styling\n\n**Example:**\n```tsx\nimport { buttonVariants } from \"@/components/ui/button\"\n\nfunction CustomButton() {\n  return (\n    <a\n      className={cn(\n        buttonVariants({ variant: \"outline\", size: \"lg\" }),\n        \"custom-additional-classes\"\n      )}\n    >\n      Link styled as button\n    </a>\n  )\n}\n```\n\n## Advanced Pattern: Nullable Variants\n\nHandle optional variant states with explicit null/undefined handling:\n\n```tsx\nconst alertVariants = cva(\n  \"rounded-lg border p-4\",\n  {\n    variants: {\n      severity: {\n        info: \"border-blue-500 bg-blue-50\",\n        warning: \"border-yellow-500 bg-yellow-50\",\n        error: \"border-red-500 bg-red-50\",\n        success: \"border-green-500 bg-green-50\",\n      },\n      dismissible: {\n        true: \"pr-10\",\n        false: \"pr-4\",\n      },\n    },\n    // No defaultVariants means undefined is valid\n  }\n)\n\n// TypeScript allows undefined\nfunction Alert({\n  severity,\n  dismissible = false,\n}: VariantProps<typeof alertVariants>) {\n  // severity can be undefined\n  return <div className={cn(alertVariants({ severity, dismissible }))} />\n}\n```\n\n## Performance Considerations\n\nCVA generates static classes that can be tree-shaken:\n\n```tsx\n// Good: Variants are statically analyzable\nconst buttonVariants = cva(\"base\", {\n  variants: {\n    variant: {\n      primary: \"bg-blue-500\",\n      secondary: \"bg-gray-500\",\n    },\n  },\n})\n\n// Avoid: Dynamic class generation loses tree-shaking\nconst dynamicButton = (color: string) => cn(`bg-${color}-500`)\n```\n\n**Best Practices:**\n- Define all variant options statically\n- Use CVA for variant-based styling, not arbitrary values\n- Leverage defaultVariants for sensible defaults\n- Export variants for reusability\n- Combine with `cn()` for user overrides\n",
        "skills/shadcn-ui/references/patterns.md": "# shadcn/ui Component Patterns\n\nThis document covers architectural patterns used in shadcn/ui components.\n\n## Table of Contents\n\n- [Compound Component Pattern](#compound-component-pattern)\n- [asChild / Slot Polymorphism](#aschild--slot-polymorphism)\n- [Controlled vs Uncontrolled State](#controlled-vs-uncontrolled-state)\n- [Context for Complex Components](#context-for-complex-components)\n- [data-slot CSS Targeting](#data-slot-css-targeting)\n- [has() Selector Usage](#has-selector-usage)\n\n## Compound Component Pattern\n\nCompound components split complex UI into multiple related components that work together.\n\n### Card Example\n\n```tsx\n// Export multiple related components\nexport {\n  Card,          // Container\n  CardHeader,    // Header section\n  CardTitle,     // Title element\n  CardDescription, // Description text\n  CardContent,   // Main content area\n  CardFooter,    // Footer section\n  CardAction,    // Action area (optional)\n}\n\n// Usage - compose as needed\n<Card>\n  <CardHeader>\n    <CardTitle>Dashboard</CardTitle>\n    <CardDescription>Overview of your account</CardDescription>\n    <CardAction>\n      <Button>Settings</Button>\n    </CardAction>\n  </CardHeader>\n  <CardContent>\n    Main content here\n  </CardContent>\n  <CardFooter>\n    Footer content\n  </CardFooter>\n</Card>\n```\n\n**Key Benefits:**\n- Flexible composition - use only needed parts\n- Clear semantic structure\n- Each component handles its own styling\n- Type-safe with independent prop types\n\n### Dialog Example\n\n```tsx\nexport {\n  Dialog,              // Root component (state container)\n  DialogTrigger,       // Opens the dialog\n  DialogContent,       // Modal content wrapper\n  DialogHeader,        // Header section\n  DialogTitle,         // Title (accessibility required)\n  DialogDescription,   // Description (accessibility)\n  DialogFooter,        // Footer for actions\n  DialogClose,         // Close button\n}\n\n// Usage\n<Dialog>\n  <DialogTrigger asChild>\n    <Button>Open</Button>\n  </DialogTrigger>\n  <DialogContent>\n    <DialogHeader>\n      <DialogTitle>Confirm Action</DialogTitle>\n      <DialogDescription>This action cannot be undone.</DialogDescription>\n    </DialogHeader>\n    <DialogFooter>\n      <DialogClose asChild>\n        <Button variant=\"outline\">Cancel</Button>\n      </DialogClose>\n      <Button>Confirm</Button>\n    </DialogFooter>\n  </DialogContent>\n</Dialog>\n```\n\n### Sidebar Context Example\n\nComplex compound components use Context for shared state:\n\n```tsx\n// 1. Define context type\ntype SidebarContextProps = {\n  state: \"expanded\" | \"collapsed\"\n  open: boolean\n  setOpen: (open: boolean) => void\n  toggleSidebar: () => void\n  isMobile: boolean\n}\n\n// 2. Create context\nconst SidebarContext = React.createContext<SidebarContextProps | null>(null)\n\n// 3. Custom hook for consuming context\nfunction useSidebar() {\n  const context = React.useContext(SidebarContext)\n  if (!context) {\n    throw new Error(\"useSidebar must be used within a SidebarProvider.\")\n  }\n  return context\n}\n\n// 4. Provider component\nfunction SidebarProvider({ children, defaultOpen = true, ...props }) {\n  const [open, setOpen] = React.useState(defaultOpen)\n  const isMobile = useIsMobile()\n\n  const toggleSidebar = React.useCallback(() => {\n    setOpen((open) => !open)\n  }, [])\n\n  const contextValue = React.useMemo(\n    () => ({\n      state: open ? \"expanded\" : \"collapsed\",\n      open,\n      setOpen,\n      toggleSidebar,\n      isMobile,\n    }),\n    [open, setOpen, toggleSidebar, isMobile]\n  )\n\n  return (\n    <SidebarContext.Provider value={contextValue}>\n      {children}\n    </SidebarContext.Provider>\n  )\n}\n\n// 5. Child components consume context\nfunction SidebarTrigger({ ...props }) {\n  const { toggleSidebar } = useSidebar()\n\n  return (\n    <Button onClick={toggleSidebar} {...props}>\n      Toggle\n    </Button>\n  )\n}\n\n// Usage\n<SidebarProvider>\n  <Sidebar>\n    <SidebarHeader>Header</SidebarHeader>\n    <SidebarContent>Content</SidebarContent>\n  </Sidebar>\n  <SidebarTrigger />\n</SidebarProvider>\n```\n\n## asChild / Slot Polymorphism\n\nThe `asChild` pattern allows components to render as different elements while preserving styling and behavior.\n\n### Basic Pattern\n\n```tsx\nimport { Slot } from \"@radix-ui/react-slot\"\n\nfunction Button({\n  asChild = false,\n  className,\n  ...props\n}: React.ComponentProps<\"button\"> & { asChild?: boolean }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      className={cn(buttonVariants({ className }))}\n      {...props}\n    />\n  )\n}\n```\n\n### Usage Examples\n\n```tsx\n// Renders as <button>\n<Button>Click me</Button>\n\n// Renders as <a> with button styling\n<Button asChild>\n  <a href=\"/home\">Home</a>\n</Button>\n\n// Renders as Next.js Link\n<Button asChild>\n  <Link href=\"/dashboard\">Dashboard</Link>\n</Button>\n\n// Renders as custom component\n<Button asChild>\n  <motion.div whileHover={{ scale: 1.05 }}>\n    Animated Button\n  </motion.div>\n</Button>\n```\n\n### How Slot Works\n\nThe `Slot` component from Radix UI merges props and classes from the wrapper onto the child:\n\n```tsx\n// With asChild=true\n<Button asChild className=\"custom-class\" onClick={handler}>\n  <a href=\"/home\">Home</a>\n</Button>\n\n// Renders as:\n<a\n  href=\"/home\"\n  className=\"button-variant-classes custom-class\"\n  onClick={handler}\n>\n  Home\n</a>\n```\n\n### Badge with asChild\n\n```tsx\nfunction Badge({\n  asChild = false,\n  variant,\n  className,\n  ...props\n}: React.ComponentProps<\"span\"> &\n  VariantProps<typeof badgeVariants> &\n  { asChild?: boolean }) {\n  const Comp = asChild ? Slot : \"span\"\n\n  return (\n    <Comp\n      data-slot=\"badge\"\n      className={cn(badgeVariants({ variant }), className)}\n      {...props}\n    />\n  )\n}\n\n// Usage\n<Badge asChild variant=\"destructive\">\n  <a href=\"/alerts\">5 Alerts</a>\n</Badge>\n```\n\n## Controlled vs Uncontrolled State\n\nComponents support both controlled (parent manages state) and uncontrolled (internal state) patterns.\n\n### Uncontrolled Pattern\n\n```tsx\nfunction Checkbox({ defaultChecked = false, ...props }) {\n  const [checked, setChecked] = React.useState(defaultChecked)\n\n  return (\n    <input\n      type=\"checkbox\"\n      checked={checked}\n      onChange={(e) => setChecked(e.target.checked)}\n      {...props}\n    />\n  )\n}\n\n// Usage - component manages own state\n<Checkbox defaultChecked={true} />\n```\n\n### Controlled Pattern\n\n```tsx\nfunction Checkbox({ checked, onCheckedChange, ...props }) {\n  return (\n    <input\n      type=\"checkbox\"\n      checked={checked}\n      onChange={(e) => onCheckedChange?.(e.target.checked)}\n      {...props}\n    />\n  )\n}\n\n// Usage - parent controls state\nconst [checked, setChecked] = useState(false)\n<Checkbox checked={checked} onCheckedChange={setChecked} />\n```\n\n### Hybrid Pattern (Sidebar)\n\nSupport both controlled and uncontrolled usage:\n\n```tsx\nfunction SidebarProvider({\n  defaultOpen = true,\n  open: openProp,\n  onOpenChange: setOpenProp,\n  ...props\n}) {\n  // Internal state\n  const [_open, _setOpen] = React.useState(defaultOpen)\n\n  // Use prop if provided, otherwise internal state\n  const open = openProp ?? _open\n\n  const setOpen = React.useCallback(\n    (value: boolean | ((value: boolean) => boolean)) => {\n      const openState = typeof value === \"function\" ? value(open) : value\n\n      // Call prop callback if provided\n      if (setOpenProp) {\n        setOpenProp(openState)\n      } else {\n        // Otherwise update internal state\n        _setOpen(openState)\n      }\n    },\n    [setOpenProp, open]\n  )\n\n  return (\n    <SidebarContext.Provider value={{ open, setOpen }}>\n      {children}\n    </SidebarContext.Provider>\n  )\n}\n\n// Uncontrolled usage\n<SidebarProvider defaultOpen={false}>\n  <Sidebar />\n</SidebarProvider>\n\n// Controlled usage\nconst [sidebarOpen, setSidebarOpen] = useState(true)\n<SidebarProvider open={sidebarOpen} onOpenChange={setSidebarOpen}>\n  <Sidebar />\n</SidebarProvider>\n```\n\n## Context for Complex Components\n\nUse React Context for components with multiple children sharing state.\n\n### When to Use Context\n\n- Multiple child components need access to shared state\n- Props drilling would be excessive\n- State logic is complex (e.g., Sidebar open/collapsed/mobile states)\n- Component has plugin/extension architecture\n\n### Form Context Example\n\n```tsx\ntype FormContextValue = {\n  formId: string\n  errors: Record<string, string>\n  register: (name: string) => void\n  unregister: (name: string) => void\n}\n\nconst FormContext = React.createContext<FormContextValue | null>(null)\n\nfunction useFormContext() {\n  const context = React.useContext(FormContext)\n  if (!context) {\n    throw new Error(\"Form components must be used within Form\")\n  }\n  return context\n}\n\nfunction Form({ children, onSubmit }: FormProps) {\n  const [errors, setErrors] = React.useState({})\n  const formId = React.useId()\n\n  const contextValue = React.useMemo(\n    () => ({\n      formId,\n      errors,\n      register: (name) => { /* ... */ },\n      unregister: (name) => { /* ... */ },\n    }),\n    [formId, errors]\n  )\n\n  return (\n    <FormContext.Provider value={contextValue}>\n      <form id={formId} onSubmit={onSubmit}>\n        {children}\n      </form>\n    </FormContext.Provider>\n  )\n}\n\nfunction FormField({ name, ...props }) {\n  const { formId, errors, register } = useFormContext()\n\n  React.useEffect(() => {\n    register(name)\n    return () => unregister(name)\n  }, [name])\n\n  return (\n    <div>\n      <input id={`${formId}-${name}`} {...props} />\n      {errors[name] && <span>{errors[name]}</span>}\n    </div>\n  )\n}\n```\n\n### Best Practices\n\n1. **Memoize context value** to prevent unnecessary re-renders:\n```tsx\nconst contextValue = React.useMemo(\n  () => ({ state, setState, helpers }),\n  [state, setState, helpers]\n)\n```\n\n2. **Type the context properly**:\n```tsx\nconst Context = React.createContext<ContextType | null>(null)\n```\n\n3. **Provide helpful error messages**:\n```tsx\nif (!context) {\n  throw new Error(\"useComponent must be used within ComponentProvider\")\n}\n```\n\n4. **Use custom hooks** for consuming context:\n```tsx\nfunction useComponent() {\n  const context = React.useContext(ComponentContext)\n  if (!context) throw new Error(\"...\")\n  return context\n}\n```\n\n## data-slot CSS Targeting\n\nEvery shadcn/ui component includes a `data-slot` attribute for CSS targeting.\n\n### Basic Usage\n\n```tsx\nfunction Button({ ...props }) {\n  return <button data-slot=\"button\" {...props} />\n}\n\nfunction Card({ ...props }) {\n  return <div data-slot=\"card\" {...props} />\n}\n```\n\n**CSS Targeting:**\n```css\n/* Target all buttons */\n[data-slot=\"button\"] {\n  /* styles */\n}\n\n/* Target buttons within cards */\n[data-slot=\"card\"] [data-slot=\"button\"] {\n  /* styles */\n}\n```\n\n**Tailwind Usage:**\n```tsx\n<div className=\"[&_[data-slot=button]]:shadow-lg\">\n  <Button>Styled via parent</Button>\n</div>\n```\n\n### Advanced Patterns\n\n#### Conditional Layouts Based on Slots\n\n```tsx\nfunction CardHeader({ className, ...props }) {\n  return (\n    <div\n      data-slot=\"card-header\"\n      className={cn(\n        \"grid gap-2 px-6\",\n        // If CardAction is present, use two columns\n        \"has-data-[slot=card-action]:grid-cols-[1fr_auto]\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// Usage\n<CardHeader>\n  <CardTitle>Title</CardTitle>\n  {/* When CardAction is added, layout changes automatically */}\n  <CardAction>\n    <Button>Action</Button>\n  </CardAction>\n</CardHeader>\n```\n\n#### Parent Selectors with Slots\n\n```tsx\nfunction CardFooter({ className, ...props }) {\n  return (\n    <div\n      data-slot=\"card-footer\"\n      className={cn(\n        \"flex items-center px-6\",\n        // If parent has .border-t class, add top padding\n        \"[.border-t]:pt-6\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// Usage\n<Card className=\"border-t\">\n  <CardFooter>Footer gets top padding</CardFooter>\n</Card>\n```\n\n#### Multiple data-* Attributes\n\nComponents can have multiple data attributes for different purposes:\n\n```tsx\nfunction Sidebar({ variant, side, collapsible, ...props }) {\n  return (\n    <div\n      data-slot=\"sidebar\"\n      data-variant={variant}\n      data-side={side}\n      data-collapsible={collapsible}\n      className={cn(\n        \"group\",\n        \"group-data-[variant=floating]:rounded-lg\",\n        \"group-data-[side=left]:border-r\",\n        \"group-data-[collapsible=icon]:w-12\"\n      )}\n      {...props}\n    />\n  )\n}\n```\n\n## has() Selector Usage\n\nModern CSS `:has()` selector enables parent styling based on children.\n\n### Basic Pattern\n\n```tsx\n// Button with icon adjusts padding\n<button className=\"px-4 has-[>svg]:px-3\">\n  <Icon />\n  Text\n</button>\n```\n\n**How it works:**\n- `has-[>svg]` - if button has direct child `<svg>`\n- Apply `px-3` instead of base `px-4`\n- Automatically adjusts based on content\n\n### Size Variants with Icons\n\n```tsx\nconst buttonVariants = cva(\"...\", {\n  variants: {\n    size: {\n      default: \"h-9 px-4 py-2 has-[>svg]:px-3\",\n      sm: \"h-8 px-3 has-[>svg]:px-2.5\",\n      lg: \"h-10 px-6 has-[>svg]:px-4\",\n    },\n  },\n})\n\n// Padding adjusts automatically\n<Button size=\"sm\">\n  <Icon />\n  Text\n</Button>\n```\n\n### CardHeader Grid Layout\n\n```tsx\nfunction CardHeader({ className, ...props }) {\n  return (\n    <div\n      className={cn(\n        \"grid gap-2\",\n        // Single column by default\n        \"grid-rows-[auto_auto]\",\n        // When CardAction exists, add second column\n        \"has-data-[slot=card-action]:grid-cols-[1fr_auto]\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// Layout adapts based on children\n<CardHeader>\n  <CardTitle>Title</CardTitle>\n  <CardDescription>Description</CardDescription>\n  {/* Adding this changes layout to two columns */}\n  <CardAction>\n    <Button>Action</Button>\n  </CardAction>\n</CardHeader>\n```\n\n### Conditional Border Padding\n\n```tsx\nfunction CardFooter({ className, ...props }) {\n  return (\n    <div\n      className={cn(\n        \"flex items-center px-6\",\n        // Add padding only if parent has border-t class\n        \"[.border-t]:pt-6\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n```\n\n### Group-based Conditional Styling\n\n```tsx\nfunction SidebarGroupLabel({ className, ...props }) {\n  return (\n    <div\n      className={cn(\n        \"flex h-8 items-center px-2\",\n        // Hide when sidebar is collapsed (icon mode)\n        \"group-data-[collapsible=icon]:-mt-8\",\n        \"group-data-[collapsible=icon]:opacity-0\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// Parent controls child visibility\n<div className=\"group\" data-collapsible=\"icon\">\n  <SidebarGroupLabel>Hidden in icon mode</SidebarGroupLabel>\n</div>\n```\n\n### Peer-based Interactions\n\n```tsx\nfunction SidebarMenuButton({ size, isActive, className, ...props }) {\n  return (\n    <button\n      data-slot=\"sidebar-menu-button\"\n      data-size={size}\n      data-active={isActive}\n      className={cn(\n        \"peer/menu-button\",\n        \"flex items-center gap-2\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction SidebarMenuAction({ showOnHover, className, ...props }) {\n  return (\n    <button\n      data-slot=\"sidebar-menu-action\"\n      className={cn(\n        \"absolute right-1\",\n        // Show when peer (menu button) is hovered\n        showOnHover && \"peer-hover/menu-button:opacity-100 md:opacity-0\",\n        // Highlight when peer is active\n        \"peer-data-[active=true]/menu-button:text-accent-foreground\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\n// Usage\n<div>\n  <SidebarMenuButton isActive={true}>Menu</SidebarMenuButton>\n  <SidebarMenuAction showOnHover />\n</div>\n```\n\n### Browser Support\n\nThe `:has()` selector is supported in all modern browsers (Chrome 105+, Safari 15.4+, Firefox 121+). For older browsers, provide fallback styling:\n\n```tsx\nclassName={cn(\n  // Fallback for browsers without :has() support\n  \"px-4\",\n  // Modern browsers with :has() support\n  \"has-[>svg]:px-3\",\n)}\n```\n",
        "skills/sqlalchemy-code-review/SKILL.md": "---\nname: sqlalchemy-code-review\ndescription: Reviews SQLAlchemy code for session management, relationships, N+1 queries, and migration patterns. Use when reviewing SQLAlchemy 2.0 code, checking session lifecycle, relationship() usage, or Alembic migrations.\n---\n\n# SQLAlchemy Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Session lifecycle, context managers, async sessions | [references/sessions.md](references/sessions.md) |\n| relationship(), lazy loading, N+1, joinedload | [references/relationships.md](references/relationships.md) |\n| select() vs query(), ORM overhead, bulk ops | [references/queries.md](references/queries.md) |\n| Alembic patterns, reversible migrations, data migrations | [references/migrations.md](references/migrations.md) |\n\n## Review Checklist\n\n- [ ] Sessions use context managers (`with`, `async with`)\n- [ ] No session sharing across requests or threads\n- [ ] Sessions closed/cleaned up properly\n- [ ] `relationship()` uses appropriate `lazy` strategy\n- [ ] Explicit `joinedload`/`selectinload` to avoid N+1\n- [ ] No lazy loading in loops (N+1 queries)\n- [ ] Using SQLAlchemy 2.0 `select()` syntax, not legacy `query()`\n- [ ] Bulk operations use bulk_insert/bulk_update, not ORM loops\n- [ ] Async sessions use proper async context managers\n- [ ] Migrations are reversible with `downgrade()`\n- [ ] Data migrations use `op.execute()` not ORM models\n- [ ] Migration dependencies properly ordered\n\n## When to Load References\n\n- Reviewing session creation/cleanup  sessions.md\n- Reviewing model relationships  relationships.md\n- Reviewing database queries  queries.md\n- Reviewing Alembic migration files  migrations.md\n\n## Review Questions\n\n1. Are all sessions properly managed with context managers?\n2. Are relationships configured to avoid N+1 queries?\n3. Are queries using SQLAlchemy 2.0 `select()` syntax?\n4. Are all migrations reversible and properly tested?\n",
        "skills/sqlalchemy-code-review/references/migrations.md": "# Migrations\n\n## Critical Anti-Patterns\n\n### 1. Non-Reversible Migrations\n\n**Problem**: Can't rollback, stuck on failed deploys.\n\n```python\n# BAD - no downgrade\n\"\"\"Add user_role column\n\nRevision ID: abc123\n\"\"\"\n\ndef upgrade():\n    op.add_column('users', sa.Column('role', sa.String(50)))\n\ndef downgrade():\n    pass  # Can't rollback!\n\n# GOOD - reversible migration\ndef upgrade():\n    op.add_column('users', sa.Column('role', sa.String(50), nullable=True))\n\ndef downgrade():\n    op.drop_column('users', 'role')\n```\n\n### 2. Not Making New Columns Nullable First\n\n**Problem**: Migration fails on existing data.\n\n```python\n# BAD - adding non-nullable column to existing table\ndef upgrade():\n    # Fails if table has existing rows!\n    op.add_column('users', sa.Column('email', sa.String(255), nullable=False))\n\n# GOOD - two-step migration\ndef upgrade():\n    # Step 1: Add nullable column\n    op.add_column('users', sa.Column('email', sa.String(255), nullable=True))\n\n# Then in a separate migration after backfilling data:\ndef upgrade():\n    # Step 2: Make it non-nullable\n    op.alter_column('users', 'email', nullable=False)\n\ndef downgrade():\n    op.alter_column('users', 'email', nullable=True)\n\n# BETTER - add with server_default\ndef upgrade():\n    op.add_column(\n        'users',\n        sa.Column('email', sa.String(255), nullable=False, server_default='')\n    )\n    # Remove server_default in next migration after cleanup\n```\n\n### 3. Using ORM Models in Migrations\n\n**Problem**: Model changes break old migrations.\n\n```python\n# BAD - using ORM models directly\nfrom app.models import User  # DON'T!\n\ndef upgrade():\n    session = Session()\n    users = session.query(User).all()  # Model might change!\n    for user in users:\n        user.email = f\"{user.username}@example.com\"\n    session.commit()\n\n# GOOD - use op.execute with raw SQL\ndef upgrade():\n    op.execute(\n        \"\"\"\n        UPDATE users\n        SET email = username || '@example.com'\n        WHERE email IS NULL\n        \"\"\"\n    )\n\n# BETTER - use Core Table for complex operations\nfrom sqlalchemy import table, column, String, Integer\n\ndef upgrade():\n    users_table = table(\n        'users',\n        column('id', Integer),\n        column('username', String),\n        column('email', String)\n    )\n\n    connection = op.get_bind()\n    users = connection.execute(\n        select(users_table.c.id, users_table.c.username)\n        .where(users_table.c.email.is_(None))\n    ).fetchall()\n\n    for user in users:\n        connection.execute(\n            update(users_table)\n            .where(users_table.c.id == user.id)\n            .values(email=f\"{user.username}@example.com\")\n        )\n```\n\n### 4. Not Handling Concurrent Migrations\n\n**Problem**: Multiple developers create conflicting migrations.\n\n```python\n# BAD - no dependency management\n\"\"\"Add status column\n\nRevision ID: abc123\nRevises: xyz789\n\"\"\"\n\n# Developer B also based on xyz789 - conflict!\n\"\"\"Add priority column\n\nRevision ID: def456\nRevises: xyz789  # Same parent!\n\"\"\"\n\n# GOOD - use down_revision properly\n# Developer A\n\"\"\"Add status column\n\nRevision ID: abc123\nRevises: xyz789\n\"\"\"\n\n# Developer B rebases\n\"\"\"Add priority column\n\nRevision ID: def456\nRevises: abc123  # Updated after merge\n\"\"\"\n\n# BETTER - use alembic branches for long-running features\n$ alembic revision -m \"feature branch\" --branch-label feature_x --depends-on abc123\n```\n\n### 5. Dangerous DDL Without Transactions\n\n**Problem**: Partial migrations leave database in broken state.\n\n```python\n# BAD - multiple DDL operations without transaction\ndef upgrade():\n    op.create_table('temp_users', ...)\n    op.execute(\"INSERT INTO temp_users SELECT * FROM users\")\n    op.drop_table('users')  # If this fails, temp_users exists but users is gone!\n    op.rename_table('temp_users', 'users')\n\n# GOOD - use batch operations for SQLite\ndef upgrade():\n    with op.batch_alter_table('users') as batch_op:\n        batch_op.add_column(sa.Column('new_col', sa.String(50)))\n        batch_op.drop_column('old_col')\n\n# PostgreSQL supports transactional DDL\ndef upgrade():\n    # These all happen in a transaction by default\n    op.add_column('users', sa.Column('new_col', sa.String(50)))\n    op.drop_column('users', 'old_col')\n\n# For operations that can't be in a transaction\ndef upgrade():\n    op.execute(\"CREATE INDEX CONCURRENTLY idx_users_email ON users(email)\")\n\ndef downgrade():\n    op.execute(\"DROP INDEX CONCURRENTLY idx_users_email\")\n```\n\n### 6. Not Testing Migrations\n\n**Problem**: Migrations fail in production.\n\n```python\n# BAD - no testing\ndef upgrade():\n    # Hope this works in production!\n    op.add_column('users', sa.Column('role', sa.String(50)))\n\n# GOOD - test migrations in CI\n# tests/test_migrations.py\nimport pytest\nfrom alembic import command\nfrom alembic.config import Config\n\ndef test_migration_upgrade_downgrade():\n    config = Config(\"alembic.ini\")\n\n    # Test upgrade\n    command.upgrade(config, \"head\")\n\n    # Test downgrade\n    command.downgrade(config, \"-1\")\n\n    # Test re-upgrade\n    command.upgrade(config, \"head\")\n\n# BETTER - test with actual data\ndef test_migration_preserves_data():\n    config = Config(\"alembic.ini\")\n\n    # Setup test data\n    connection = engine.connect()\n    connection.execute(\n        \"INSERT INTO users (username, email) VALUES ('test', 'test@example.com')\"\n    )\n\n    # Run migration\n    command.upgrade(config, \"head\")\n\n    # Verify data preserved\n    result = connection.execute(\"SELECT * FROM users WHERE username = 'test'\")\n    assert result.rowcount == 1\n```\n\n### 7. Not Using Batch Operations for SQLite\n\n**Problem**: SQLite doesn't support many ALTER TABLE operations.\n\n```python\n# BAD - doesn't work on SQLite\ndef upgrade():\n    op.alter_column('users', 'email', type_=sa.String(512))  # Fails on SQLite!\n\n# GOOD - use batch operations\ndef upgrade():\n    with op.batch_alter_table('users', schema=None) as batch_op:\n        batch_op.alter_column('email', type_=sa.String(512))\n\ndef downgrade():\n    with op.batch_alter_table('users', schema=None) as batch_op:\n        batch_op.alter_column('email', type_=sa.String(255))\n```\n\n### 8. Not Handling Large Data Migrations\n\n**Problem**: Migration times out or locks table.\n\n```python\n# BAD - single UPDATE locks entire table\ndef upgrade():\n    op.execute(\n        \"UPDATE users SET normalized_email = LOWER(email)\"\n    )  # Locks millions of rows!\n\n# GOOD - batch updates\ndef upgrade():\n    connection = op.get_bind()\n    batch_size = 1000\n    offset = 0\n\n    while True:\n        result = connection.execute(\n            f\"\"\"\n            UPDATE users\n            SET normalized_email = LOWER(email)\n            WHERE id IN (\n                SELECT id FROM users\n                WHERE normalized_email IS NULL\n                ORDER BY id\n                LIMIT {batch_size} OFFSET {offset}\n            )\n            \"\"\"\n        )\n\n        if result.rowcount == 0:\n            break\n\n        offset += batch_size\n        # Sleep to avoid overwhelming the database\n        import time\n        time.sleep(0.1)\n\n# BETTER - use queue/background job for very large tables\ndef upgrade():\n    # Add column\n    op.add_column('users', sa.Column('normalized_email', sa.String(255)))\n\n    # Create background job to populate\n    # (Actual backfill happens outside migration)\n    pass\n```\n\n### 9. Not Managing Indexes Properly\n\n**Problem**: Slow queries after migration, or failed migrations.\n\n```python\n# BAD - adding index inline blocks table\ndef upgrade():\n    op.add_column('users', sa.Column('email', sa.String(255)))\n    op.create_index('idx_users_email', 'users', ['email'])  # Locks table!\n\n# GOOD - create index concurrently (PostgreSQL)\ndef upgrade():\n    op.add_column('users', sa.Column('email', sa.String(255)))\n\n    # Separate connection for concurrent index\n    op.execute(\"COMMIT\")  # End transaction\n    op.execute(\"CREATE INDEX CONCURRENTLY idx_users_email ON users(email)\")\n\ndef downgrade():\n    op.execute(\"DROP INDEX CONCURRENTLY idx_users_email\")\n    op.drop_column('users', 'email')\n\n# BETTER - track index creation separately\ndef upgrade():\n    op.add_column('users', sa.Column('email', sa.String(255)))\n    # Create index in a separate migration\n```\n\n### 10. Not Documenting Complex Migrations\n\n**Problem**: Team doesn't understand migration purpose or impact.\n\n```python\n# BAD - no documentation\n\"\"\"revision abc123\n\"\"\"\n\ndef upgrade():\n    op.execute(\"complex SQL here...\")\n\n# GOOD - clear documentation\n\"\"\"Add normalized_email column for case-insensitive lookups\n\nThis migration:\n1. Adds a new normalized_email column (nullable initially)\n2. Backfills it with lowercase email values\n3. Creates a unique index on normalized_email\n4. Does NOT make it non-nullable yet (requires follow-up migration)\n\nExpected duration: ~2 minutes for 1M users\nLocks: Brief lock during index creation\nRollback safe: Yes\n\nRevision ID: abc123\nRevises: xyz789\nCreate Date: 2024-01-15 10:30:00\n\"\"\"\n\ndef upgrade():\n    # Step 1: Add column\n    op.add_column(\n        'users',\n        sa.Column('normalized_email', sa.String(255), nullable=True)\n    )\n\n    # Step 2: Backfill in batches\n    connection = op.get_bind()\n    batch_size = 1000\n    # ... batched update logic ...\n\n    # Step 3: Create index\n    op.create_index(\n        'idx_users_normalized_email',\n        'users',\n        ['normalized_email'],\n        unique=True\n    )\n\ndef downgrade():\n    op.drop_index('idx_users_normalized_email', table_name='users')\n    op.drop_column('users', 'normalized_email')\n```\n\n### 11. Not Using Check Constraints\n\n**Problem**: Invalid data gets inserted.\n\n```python\n# BAD - no constraints, rely on application validation\ndef upgrade():\n    op.add_column('users', sa.Column('age', sa.Integer))\n\n# GOOD - add check constraints\ndef upgrade():\n    op.add_column('users', sa.Column('age', sa.Integer))\n    op.create_check_constraint(\n        'ck_users_age_positive',\n        'users',\n        'age >= 0 AND age <= 150'\n    )\n\ndef downgrade():\n    op.drop_constraint('ck_users_age_positive', 'users')\n    op.drop_column('users', 'age')\n\n# BETTER - use enum for limited values\nfrom sqlalchemy import Enum\n\ndef upgrade():\n    role_enum = sa.Enum('user', 'admin', 'moderator', name='user_role')\n    role_enum.create(op.get_bind())\n\n    op.add_column(\n        'users',\n        sa.Column('role', role_enum, nullable=False, server_default='user')\n    )\n\ndef downgrade():\n    op.drop_column('users', 'role')\n    sa.Enum(name='user_role').drop(op.get_bind())\n```\n\n## Review Questions\n\n1. Does every migration have a working `downgrade()` function?\n2. Are new non-nullable columns added in two steps (nullable first, then constrain)?\n3. Are data migrations using `op.execute()` not ORM models?\n4. Are large data updates batched to avoid timeouts?\n5. Are indexes created with CONCURRENTLY on PostgreSQL?\n6. Are complex migrations documented with expected duration and impact?\n7. Are constraints (CHECK, UNIQUE, FK) properly created and dropped?\n",
        "skills/sqlalchemy-code-review/references/queries.md": "# Queries\n\n## Critical Anti-Patterns\n\n### 1. Using Legacy query() Instead of select()\n\n**Problem**: Legacy API, deprecated in SQLAlchemy 2.0.\n\n```python\n# BAD - legacy query() API (deprecated)\ndef get_active_users():\n    with Session() as session:\n        users = session.query(User).filter(User.active == True).all()\n        return users\n\n# GOOD - SQLAlchemy 2.0 select() syntax\nfrom sqlalchemy import select\n\ndef get_active_users():\n    with Session() as session:\n        result = session.execute(\n            select(User).where(User.active == True)\n        )\n        return result.scalars().all()\n\n# ASYNC version\nasync def get_active_users():\n    async with AsyncSession() as session:\n        result = await session.execute(\n            select(User).where(User.active == True)\n        )\n        return result.scalars().all()\n```\n\n### 2. Loading Full Objects When Only Columns Needed\n\n**Problem**: ORM overhead, unnecessary data transfer.\n\n```python\n# BAD - loading full ORM objects just for one column\ndef get_user_emails():\n    with Session() as session:\n        users = session.execute(select(User)).scalars().all()\n        return [user.email for user in users]  # Loaded entire object!\n\n# GOOD - select only needed columns\ndef get_user_emails():\n    with Session() as session:\n        result = session.execute(\n            select(User.email)\n        )\n        return result.scalars().all()\n\n# BETTER - multiple columns as tuples\ndef get_user_info():\n    with Session() as session:\n        result = session.execute(\n            select(User.id, User.name, User.email)\n        )\n        return result.all()  # Returns list of tuples\n```\n\n### 3. Using all() When Only One Result Expected\n\n**Problem**: Confusing API, loads unnecessary data.\n\n```python\n# BAD - using all() when expecting one result\ndef get_user_by_email(email: str):\n    with Session() as session:\n        users = session.execute(\n            select(User).where(User.email == email)\n        ).scalars().all()\n        return users[0] if users else None  # Awkward!\n\n# GOOD - use scalar_one_or_none()\ndef get_user_by_email(email: str) -> User | None:\n    with Session() as session:\n        return session.execute(\n            select(User).where(User.email == email)\n        ).scalar_one_or_none()\n\n# Use scalar_one() if must exist (raises if not found)\ndef get_user_by_id(user_id: int) -> User:\n    with Session() as session:\n        return session.execute(\n            select(User).where(User.id == user_id)\n        ).scalar_one()  # Raises NoResultFound or MultipleResultsFound\n```\n\n### 4. Not Using Bulk Operations\n\n**Problem**: ORM overhead per object, slow inserts/updates.\n\n```python\n# BAD - ORM insert in loop\ndef create_users(user_data: list[dict]):\n    with Session() as session:\n        for data in user_data:\n            user = User(**data)\n            session.add(user)  # Individual ORM overhead per user\n        session.commit()\n\n# GOOD - bulk insert\ndef create_users(user_data: list[dict]):\n    with Session() as session:\n        session.bulk_insert_mappings(User, user_data)\n        session.commit()\n\n# BETTER - Core insert for maximum performance\nfrom sqlalchemy import insert\n\ndef create_users(user_data: list[dict]):\n    with Session() as session:\n        session.execute(\n            insert(User),\n            user_data\n        )\n        session.commit()\n\n# ASYNC bulk insert\nasync def create_users(user_data: list[dict]):\n    async with AsyncSession() as session:\n        await session.execute(\n            insert(User),\n            user_data\n        )\n        await session.commit()\n```\n\n### 5. Not Using Bulk Updates\n\n**Problem**: ORM overhead, multiple UPDATE statements.\n\n```python\n# BAD - update in loop\ndef deactivate_old_users(cutoff_date):\n    with Session() as session:\n        users = session.execute(\n            select(User).where(User.last_login < cutoff_date)\n        ).scalars().all()\n\n        for user in users:\n            user.active = False  # Individual UPDATE per user\n        session.commit()\n\n# GOOD - single UPDATE statement\nfrom sqlalchemy import update\n\ndef deactivate_old_users(cutoff_date):\n    with Session() as session:\n        session.execute(\n            update(User)\n            .where(User.last_login < cutoff_date)\n            .values(active=False)\n        )\n        session.commit()\n\n# ASYNC version\nasync def deactivate_old_users(cutoff_date):\n    async with AsyncSession() as session:\n        await session.execute(\n            update(User)\n            .where(User.last_login < cutoff_date)\n            .values(active=False)\n        )\n        await session.commit()\n```\n\n### 6. Not Using exists() for Existence Checks\n\n**Problem**: Loads unnecessary data just to check existence.\n\n```python\n# BAD - loading data just to check existence\ndef user_exists(email: str) -> bool:\n    with Session() as session:\n        user = session.execute(\n            select(User).where(User.email == email)\n        ).scalar_one_or_none()\n        return user is not None  # Loaded entire object!\n\n# GOOD - use exists()\nfrom sqlalchemy import exists, select\n\ndef user_exists(email: str) -> bool:\n    with Session() as session:\n        return session.execute(\n            select(exists().where(User.email == email))\n        ).scalar()\n\n# Alternative with count (less efficient but sometimes clearer)\nfrom sqlalchemy import func\n\ndef user_exists(email: str) -> bool:\n    with Session() as session:\n        count = session.execute(\n            select(func.count()).select_from(User).where(User.email == email)\n        ).scalar()\n        return count > 0\n```\n\n### 7. Not Using Pagination\n\n**Problem**: Memory exhaustion on large result sets.\n\n```python\n# BAD - loading all results into memory\ndef get_all_users():\n    with Session() as session:\n        users = session.execute(select(User)).scalars().all()  # OOM on millions!\n        return users\n\n# GOOD - use limit/offset for pagination\ndef get_users_page(page: int = 1, page_size: int = 100):\n    with Session() as session:\n        offset = (page - 1) * page_size\n        users = session.execute(\n            select(User)\n            .offset(offset)\n            .limit(page_size)\n        ).scalars().all()\n        return users\n\n# BETTER - use keyset pagination for large datasets\ndef get_users_after(last_id: int | None = None, page_size: int = 100):\n    with Session() as session:\n        query = select(User).order_by(User.id)\n        if last_id:\n            query = query.where(User.id > last_id)\n\n        users = session.execute(\n            query.limit(page_size)\n        ).scalars().all()\n        return users\n\n# BEST - stream results for very large datasets\ndef stream_all_users():\n    with Session() as session:\n        result = session.execute(select(User))\n        for user in result.scalars():  # Streams, doesn't load all\n            yield user\n```\n\n### 8. Not Using with_for_update for Row Locking\n\n**Problem**: Race conditions in concurrent updates.\n\n```python\n# BAD - race condition in concurrent requests\ndef decrement_stock(product_id: int, quantity: int):\n    with Session() as session:\n        product = session.execute(\n            select(Product).where(Product.id == product_id)\n        ).scalar_one()\n\n        # Another request could modify stock here!\n        if product.stock >= quantity:\n            product.stock -= quantity\n            session.commit()\n        else:\n            raise ValueError(\"Insufficient stock\")\n\n# GOOD - use SELECT FOR UPDATE\ndef decrement_stock(product_id: int, quantity: int):\n    with Session() as session:\n        with session.begin():\n            product = session.execute(\n                select(Product)\n                .where(Product.id == product_id)\n                .with_for_update()  # Row locked until commit\n            ).scalar_one()\n\n            if product.stock >= quantity:\n                product.stock -= quantity\n            else:\n                raise ValueError(\"Insufficient stock\")\n\n# ASYNC version\nasync def decrement_stock(product_id: int, quantity: int):\n    async with AsyncSession() as session:\n        async with session.begin():\n            result = await session.execute(\n                select(Product)\n                .where(Product.id == product_id)\n                .with_for_update()\n            )\n            product = result.scalar_one()\n\n            if product.stock >= quantity:\n                product.stock -= quantity\n            else:\n                raise ValueError(\"Insufficient stock\")\n```\n\n### 9. Using String-Based Filters Instead of Column Objects\n\n**Problem**: No IDE support, error-prone, SQL injection risk.\n\n```python\n# BAD - string-based filters\ndef search_users(name: str):\n    with Session() as session:\n        users = session.execute(\n            select(User).filter_by(name=name)  # String-based\n        ).scalars().all()\n        return users\n\n# WORSE - string SQL (SQL injection risk!)\ndef search_users(name: str):\n    with Session() as session:\n        users = session.execute(\n            f\"SELECT * FROM users WHERE name = '{name}'\"  # NEVER DO THIS!\n        ).all()\n\n# GOOD - column object filters\ndef search_users(name: str):\n    with Session() as session:\n        users = session.execute(\n            select(User).where(User.name == name)  # Type-safe\n        ).scalars().all()\n        return users\n\n# BETTER - parameterized for complex filters\nfrom sqlalchemy import text\n\ndef search_users_complex(filters: dict):\n    with Session() as session:\n        query = select(User)\n        if \"name\" in filters:\n            query = query.where(User.name.contains(filters[\"name\"]))\n        if \"active\" in filters:\n            query = query.where(User.active == filters[\"active\"])\n\n        users = session.execute(query).scalars().all()\n        return users\n```\n\n### 10. Not Using Subqueries Efficiently\n\n**Problem**: Multiple queries instead of single subquery.\n\n```python\n# BAD - multiple queries\ndef get_users_with_recent_posts():\n    with Session() as session:\n        # First query\n        recent_post_user_ids = session.execute(\n            select(Post.user_id)\n            .where(Post.created_at > datetime.now() - timedelta(days=7))\n            .distinct()\n        ).scalars().all()\n\n        # Second query\n        users = session.execute(\n            select(User).where(User.id.in_(recent_post_user_ids))\n        ).scalars().all()\n        return users\n\n# GOOD - single query with subquery\ndef get_users_with_recent_posts():\n    with Session() as session:\n        recent_posts_subq = (\n            select(Post.user_id)\n            .where(Post.created_at > datetime.now() - timedelta(days=7))\n            .distinct()\n            .subquery()\n        )\n\n        users = session.execute(\n            select(User).where(User.id.in_(select(recent_posts_subq.c.user_id)))\n        ).scalars().all()\n        return users\n\n# BETTER - use join\ndef get_users_with_recent_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User)\n            .join(Post)\n            .where(Post.created_at > datetime.now() - timedelta(days=7))\n            .distinct()\n        ).scalars().all()\n        return users\n```\n\n### 11. Not Using union/union_all\n\n**Problem**: Multiple queries when one combined query would work.\n\n```python\n# BAD - multiple queries\ndef get_all_content():\n    with Session() as session:\n        posts = session.execute(select(Post)).scalars().all()\n        pages = session.execute(select(Page)).scalars().all()\n        return {\"posts\": posts, \"pages\": pages}\n\n# GOOD - union query (if columns match)\nfrom sqlalchemy import union_all\n\ndef get_all_content_items():\n    with Session() as session:\n        posts_query = select(\n            Post.id,\n            Post.title,\n            Post.created_at,\n            literal(\"post\").label(\"type\")\n        )\n\n        pages_query = select(\n            Page.id,\n            Page.title,\n            Page.created_at,\n            literal(\"page\").label(\"type\")\n        )\n\n        combined = union_all(posts_query, pages_query)\n        result = session.execute(combined).all()\n        return result\n```\n\n## Review Questions\n\n1. Are all queries using SQLAlchemy 2.0 `select()` syntax not legacy `query()`?\n2. Are bulk operations used for batch inserts/updates?\n3. Are only required columns selected when full objects aren't needed?\n4. Is `exists()` used instead of loading objects for existence checks?\n5. Is pagination implemented for large result sets?\n6. Is `with_for_update()` used for concurrent updates?\n7. Are column objects used instead of string-based filters?\n",
        "skills/sqlalchemy-code-review/references/relationships.md": "# Relationships\n\n## Critical Anti-Patterns\n\n### 1. N+1 Query Problem\n\n**Problem**: One query per related object, severe performance degradation.\n\n```python\n# BAD - N+1 queries\ndef get_users_with_posts():\n    with Session() as session:\n        users = session.execute(select(User)).scalars().all()\n        result = []\n        for user in users:\n            # Each access triggers a separate query!\n            posts = user.posts  # SELECT * FROM posts WHERE user_id = ?\n            result.append({\"user\": user, \"posts\": posts})\n        return result\n\n# GOOD - eager load with joinedload\nfrom sqlalchemy.orm import joinedload\n\ndef get_users_with_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User).options(joinedload(User.posts))\n        ).unique().scalars().all()\n        return users\n\n# ASYNC version\nasync def get_users_with_posts():\n    async with AsyncSession() as session:\n        result = await session.execute(\n            select(User).options(joinedload(User.posts))\n        )\n        return result.unique().scalars().all()\n```\n\n### 2. Wrong Lazy Loading Strategy\n\n**Problem**: Default lazy loading causes N+1 in most real-world scenarios.\n\n```python\n# BAD - default lazy='select' causes N+1\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\")  # lazy='select' by default\n\n# GOOD - choose appropriate lazy strategy\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n\n    # Option 1: lazy='joined' - always join\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"joined\")\n\n    # Option 2: lazy='selectin' - single extra query\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"selectin\")\n\n    # Option 3: lazy='raise' - force explicit loading\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"raise\")\n\n# BEST - use lazy='raise' and explicit loading at query time\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"raise\")\n\n# Then explicitly load when needed\ndef get_user_with_posts(user_id: int):\n    with Session() as session:\n        user = session.execute(\n            select(User)\n            .options(selectinload(User.posts))\n            .where(User.id == user_id)\n        ).scalar_one()\n        return user\n```\n\n### 3. Missing back_populates\n\n**Problem**: One-way relationship, inconsistent state, bugs.\n\n```python\n# BAD - missing back_populates\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\")\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"))\n    # No relationship back to User!\n\n# GOOD - bidirectional with back_populates\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\")\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"))\n    user = relationship(\"User\", back_populates=\"posts\")\n```\n\n### 4. Cascade Not Set Properly\n\n**Problem**: Orphaned records, foreign key violations.\n\n```python\n# BAD - no cascade, orphaned posts when user deleted\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\")\n\n# Deleting user leaves orphaned posts or fails with FK constraint\n\n# GOOD - proper cascade for composition\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\n        \"Post\",\n        back_populates=\"user\",\n        cascade=\"all, delete-orphan\"  # Delete posts when user deleted\n    )\n\n# For many-to-many, different cascade\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    groups = relationship(\n        \"Group\",\n        secondary=\"user_groups\",\n        back_populates=\"users\",\n        cascade=\"save-update, merge\"  # Don't delete groups\n    )\n```\n\n### 5. Using joinedload with Many-to-Many\n\n**Problem**: Cartesian product explosion, duplicate rows.\n\n```python\n# BAD - joinedload with many-to-many causes duplicates\ndef get_users_with_groups_and_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User)\n            .options(joinedload(User.groups))\n            .options(joinedload(User.posts))\n        ).scalars().all()  # Cartesian product: users  groups  posts!\n\n# GOOD - use selectinload for collections\nfrom sqlalchemy.orm import selectinload\n\ndef get_users_with_groups_and_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User)\n            .options(selectinload(User.groups))\n            .options(selectinload(User.posts))\n        ).scalars().all()  # Two separate IN queries, no cartesian product\n```\n\n### 6. Not Using contains_eager for Filtered Joins\n\n**Problem**: Inefficient loading when filtering related objects.\n\n```python\n# BAD - loads all posts, then filters in Python\ndef get_users_with_published_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User).options(selectinload(User.posts))\n        ).scalars().all()\n\n        # Filters in Python, wasteful\n        return [\n            {\n                \"user\": user,\n                \"posts\": [p for p in user.posts if p.published]\n            }\n            for user in users\n        ]\n\n# GOOD - use contains_eager with join filter\nfrom sqlalchemy.orm import contains_eager\n\ndef get_users_with_published_posts():\n    with Session() as session:\n        users = session.execute(\n            select(User)\n            .join(User.posts)\n            .where(Post.published == True)\n            .options(contains_eager(User.posts))\n        ).unique().scalars().all()\n        return users\n```\n\n### 7. Circular Eager Loading\n\n**Problem**: Infinite recursion with bidirectional relationships.\n\n```python\n# BAD - circular eager loading\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"joined\")\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"))\n    user = relationship(\"User\", back_populates=\"posts\", lazy=\"joined\")\n\n# Querying User loads Posts which loads User which loads Posts...\n\n# GOOD - one side lazy, or explicit loading\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    posts = relationship(\"Post\", back_populates=\"user\", lazy=\"raise\")\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"))\n    user = relationship(\"User\", back_populates=\"posts\", lazy=\"raise\")\n\n# Explicitly load what you need\ndef get_user_with_posts(user_id: int):\n    with Session() as session:\n        return session.execute(\n            select(User)\n            .options(selectinload(User.posts))\n            .where(User.id == user_id)\n        ).scalar_one()\n```\n\n### 8. Not Using Association Object for Rich M2M\n\n**Problem**: Can't store additional attributes on join table.\n\n```python\n# BAD - simple secondary table, can't add attributes\nuser_groups = Table(\n    \"user_groups\",\n    Base.metadata,\n    Column(\"user_id\", ForeignKey(\"users.id\")),\n    Column(\"group_id\", ForeignKey(\"groups.id\"))\n)\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    groups = relationship(\"Group\", secondary=user_groups)\n\n# Can't store \"joined_at\" or \"role\" on the relationship!\n\n# GOOD - association object pattern\nclass UserGroup(Base):\n    __tablename__ = \"user_groups\"\n    user_id = Column(Integer, ForeignKey(\"users.id\"), primary_key=True)\n    group_id = Column(Integer, ForeignKey(\"groups.id\"), primary_key=True)\n    joined_at = Column(DateTime, default=datetime.utcnow)\n    role = Column(String)  # \"admin\", \"member\", etc.\n\n    user = relationship(\"User\", back_populates=\"group_associations\")\n    group = relationship(\"Group\", back_populates=\"user_associations\")\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True)\n    group_associations = relationship(\"UserGroup\", back_populates=\"user\")\n\n    # Convenience property\n    @property\n    def groups(self):\n        return [assoc.group for assoc in self.group_associations]\n\nclass Group(Base):\n    __tablename__ = \"groups\"\n    id = Column(Integer, primary_key=True)\n    user_associations = relationship(\"UserGroup\", back_populates=\"group\")\n```\n\n### 9. Not Using raiseload for Debugging\n\n**Problem**: N+1 queries slip into production unnoticed.\n\n```python\n# BAD - lazy loading hidden issues in production\nfrom sqlalchemy.orm import Session\n\ndef get_users():\n    with Session() as session:\n        users = session.execute(select(User)).scalars().all()\n        # Accessing posts triggers lazy load - silent N+1 in production\n        for user in users:\n            print(user.posts)\n\n# GOOD - use raiseload in development to catch issues\nfrom sqlalchemy.orm import raiseload\n\ndef get_users():\n    with Session() as session:\n        users = session.execute(\n            select(User).options(raiseload(\"*\"))  # Raise on any lazy load\n        ).scalars().all()\n        # This will raise immediately, forcing us to fix it\n        for user in users:\n            print(user.posts)  # InvalidRequestError!\n\n# FIX - explicit loading\ndef get_users():\n    with Session() as session:\n        users = session.execute(\n            select(User).options(selectinload(User.posts))\n        ).scalars().all()\n        for user in users:\n            print(user.posts)  # No lazy load, efficient!\n```\n\n## Review Questions\n\n1. Are all relationship queries using explicit eager loading (joinedload, selectinload)?\n2. Is `lazy='raise'` used to prevent accidental lazy loading?\n3. Do all relationships have proper `back_populates`?\n4. Are cascade options set appropriately for composition vs association?\n5. Is `selectinload` used instead of `joinedload` for collections?\n6. Are association objects used for many-to-many with attributes?\n",
        "skills/sqlalchemy-code-review/references/sessions.md": "# Sessions\n\n## Critical Anti-Patterns\n\n### 1. Session Not Closed\n\n**Problem**: Connection pool exhaustion, memory leaks.\n\n```python\n# BAD - session never closed\ndef get_user(user_id: int):\n    session = Session()\n    user = session.get(User, user_id)\n    return user  # Session leaked!\n\n# GOOD - using context manager\ndef get_user(user_id: int) -> User | None:\n    with Session() as session:\n        user = session.get(User, user_id)\n        return user\n```\n\n### 2. Session Shared Across Requests\n\n**Problem**: Concurrent modifications, race conditions, data corruption.\n\n```python\n# BAD - global session shared across requests\nsession = Session()  # Module-level!\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    user = session.get(User, user_id)  # Multiple requests share session!\n    return user\n\n# GOOD - request-scoped session\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def get_db_session():\n    async with AsyncSession() as session:\n        try:\n            yield session\n        finally:\n            await session.close()\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, session = Depends(get_db_session)):\n    user = await session.get(User, user_id)\n    return user\n```\n\n### 3. Manual Commit Without Rollback Handling\n\n**Problem**: Partial commits, inconsistent state on errors.\n\n```python\n# BAD - no rollback on error\ndef create_user(name: str, email: str):\n    session = Session()\n    user = User(name=name, email=email)\n    session.add(user)\n    session.commit()  # If this fails, session corrupted\n    session.close()\n    return user\n\n# GOOD - proper error handling\ndef create_user(name: str, email: str) -> User:\n    with Session() as session:\n        try:\n            user = User(name=name, email=email)\n            session.add(user)\n            session.commit()\n            return user\n        except Exception:\n            session.rollback()\n            raise\n```\n\n### 4. Using Sync Session in Async Context\n\n**Problem**: Blocks event loop, poor performance.\n\n```python\n# BAD - blocking sync session in async\nfrom sqlalchemy.orm import Session\n\nasync def get_user(user_id: int):\n    with Session() as session:  # Blocks event loop!\n        user = session.get(User, user_id)\n        return user\n\n# GOOD - async session\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nasync def get_user(user_id: int) -> User | None:\n    async with AsyncSession() as session:\n        result = await session.execute(\n            select(User).where(User.id == user_id)\n        )\n        return result.scalar_one_or_none()\n```\n\n### 5. Session Used After Commit\n\n**Problem**: DetachedInstanceError, expired objects.\n\n```python\n# BAD - accessing object after session closed\ndef get_user_data(user_id: int):\n    with Session() as session:\n        user = session.get(User, user_id)\n    return user.email  # DetachedInstanceError! Session closed\n\n# GOOD - access data before session closes\ndef get_user_data(user_id: int) -> str | None:\n    with Session() as session:\n        user = session.get(User, user_id)\n        if user:\n            return user.email\n        return None\n\n# BETTER - use expunge or eager loading\nfrom sqlalchemy.orm import joinedload\n\ndef get_user_with_posts(user_id: int) -> User | None:\n    with Session() as session:\n        user = session.execute(\n            select(User)\n            .options(joinedload(User.posts))\n            .where(User.id == user_id)\n        ).scalar_one_or_none()\n\n        if user:\n            session.expunge(user)  # Detach from session\n        return user\n```\n\n### 6. Not Using Session.begin() for Transactions\n\n**Problem**: AutoCommit confusion, no explicit transaction boundaries.\n\n```python\n# BAD - implicit transaction boundaries\ndef transfer_money(from_id: int, to_id: int, amount: float):\n    with Session() as session:\n        from_account = session.get(Account, from_id)\n        to_account = session.get(Account, to_id)\n\n        from_account.balance -= amount\n        session.commit()  # First commit\n\n        to_account.balance += amount\n        session.commit()  # Second commit - money lost if this fails!\n\n# GOOD - explicit transaction with begin()\ndef transfer_money(from_id: int, to_id: int, amount: float):\n    with Session() as session:\n        with session.begin():\n            from_account = session.get(Account, from_id)\n            to_account = session.get(Account, to_id)\n\n            if from_account.balance < amount:\n                raise ValueError(\"Insufficient funds\")\n\n            from_account.balance -= amount\n            to_account.balance += amount\n            # Both committed together or rolled back together\n\n# ASYNC version\nasync def transfer_money(from_id: int, to_id: int, amount: float):\n    async with AsyncSession() as session:\n        async with session.begin():\n            result = await session.execute(\n                select(Account).where(Account.id.in_([from_id, to_id]))\n            )\n            accounts = {acc.id: acc for acc in result.scalars()}\n\n            from_account = accounts[from_id]\n            to_account = accounts[to_id]\n\n            if from_account.balance < amount:\n                raise ValueError(\"Insufficient funds\")\n\n            from_account.balance -= amount\n            to_account.balance += amount\n```\n\n### 7. Session Factory Not Configured Properly\n\n**Problem**: Inconsistent session behavior, connection issues.\n\n```python\n# BAD - new engine every time\ndef get_session():\n    engine = create_engine(\"postgresql://...\")  # New engine each call!\n    Session = sessionmaker(bind=engine)\n    return Session()\n\n# GOOD - reuse engine and session factory\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\n# Module level - create once\nengine = create_engine(\n    \"postgresql://...\",\n    pool_pre_ping=True,  # Verify connections\n    pool_size=10,\n    max_overflow=20\n)\n\nSessionLocal = sessionmaker(\n    bind=engine,\n    expire_on_commit=False,  # Don't expire objects on commit\n    autocommit=False,\n    autoflush=False\n)\n\ndef get_session():\n    return SessionLocal()\n\n# ASYNC version\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\nasync_engine = create_async_engine(\n    \"postgresql+asyncpg://...\",\n    pool_pre_ping=True,\n    pool_size=10\n)\n\nAsyncSessionLocal = sessionmaker(\n    async_engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n    autocommit=False,\n    autoflush=False\n)\n\nasync def get_async_session():\n    async with AsyncSessionLocal() as session:\n        yield session\n```\n\n### 8. Missing Session Refresh After Background Operations\n\n**Problem**: Stale data when session persists across long operations.\n\n```python\n# BAD - using stale session data\nasync def process_order(order_id: int):\n    async with AsyncSession() as session:\n        order = await session.get(Order, order_id)\n\n        # Long running background task\n        await process_payment(order.id)  # Another process might update order\n\n        # order.status might be stale here!\n        if order.status == \"pending\":\n            order.status = \"completed\"\n            await session.commit()\n\n# GOOD - refresh after external operations\nasync def process_order(order_id: int):\n    async with AsyncSession() as session:\n        order = await session.get(Order, order_id)\n\n        await process_payment(order.id)\n\n        # Refresh to get latest state\n        await session.refresh(order)\n\n        if order.status == \"pending\":\n            order.status = \"completed\"\n            await session.commit()\n```\n\n## Review Questions\n\n1. Are all sessions using context managers (`with` or `async with`)?\n2. Is each request/thread getting its own session instance?\n3. Are transactions using explicit `session.begin()`?\n4. Are async contexts using `AsyncSession` not sync `Session`?\n5. Are objects accessed before the session closes?\n6. Is the session factory configured once and reused?\n",
        "skills/sqlite-vec/SKILL.md": "---\nname: sqlite-vec\ndescription: sqlite-vec extension for vector similarity search in SQLite. Use when storing embeddings, performing KNN queries, or building semantic search features. Triggers on sqlite-vec, vec0, MATCH, vec_distance, partition key, float[N], int8[N], bit[N], serialize_float32, serialize_int8, vec_f32, vec_int8, vec_bit, vec_normalize, vec_quantize_binary, distance_metric, metadata columns, auxiliary columns.\n---\n\n# sqlite-vec\n\nsqlite-vec is a lightweight SQLite extension for vector similarity search. It enables storing and querying vector embeddings directly in SQLite databases without external vector databases.\n\n## Quick Reference\n\n### Load Extension\n```python\nimport sqlite3\nimport sqlite_vec\nfrom sqlite_vec import serialize_float32\n\ndb = sqlite3.connect(\":memory:\")\ndb.enable_load_extension(True)\nsqlite_vec.load(db)\ndb.enable_load_extension(False)\n```\n\n### Basic KNN Query\n```sql\n-- Create table\nCREATE VIRTUAL TABLE vec_items USING vec0(\n  embedding float[4]\n);\n\n-- Insert vectors (use serialize_float32() in Python)\nINSERT INTO vec_items(rowid, embedding)\nVALUES (1, X'CDCCCC3DCDCC4C3E9A99993E00008040');\n\n-- KNN query\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH '[0.3, 0.3, 0.3, 0.3]'\n  AND k = 10\nORDER BY distance;\n```\n\n## Core Concepts\n\n### Vector Types\n\nsqlite-vec supports three vector element types:\n\n1. **float[N]** - 32-bit floating point (4 bytes per element)\n   - Most common for embeddings (OpenAI, Cohere, etc.)\n   - Example: `float[1536]` for text-embedding-3-small\n\n2. **int8[N]** - 8-bit signed integers (1 byte per element)\n   - Range: -128 to 127\n   - Used for quantized embeddings\n\n3. **bit[N]** - Binary vectors (1 bit per element, packed into bytes)\n   - Most compact storage\n   - Used for binary quantization\n\n### Binary Serialization Format\n\nVectors must be provided as binary BLOBs or JSON strings. Python helper functions:\n\n```python\nfrom sqlite_vec import serialize_float32, serialize_int8\nimport struct\n\n# Float32 vectors\nvector = [0.1, 0.2, 0.3, 0.4]\nblob = serialize_float32(vector)\n# Equivalent to: struct.pack(\"%sf\" % len(vector), *vector)\n\n# Int8 vectors\nint_vector = [1, 2, 3, 4]\nblob = serialize_int8(int_vector)\n# Equivalent to: struct.pack(\"%sb\" % len(int_vector), *int_vector)\n```\n\nNumPy arrays can be passed directly (must cast to float32):\n```python\nimport numpy as np\nembedding = np.array([0.1, 0.2, 0.3, 0.4]).astype(np.float32)\ndb.execute(\"SELECT vec_length(?)\", [embedding])\n```\n\n## vec0 Virtual Tables\n\nThe vec0 virtual table is the primary data structure for vector search.\n\n### Basic Table Creation\n```sql\nCREATE VIRTUAL TABLE vec_documents USING vec0(\n  document_id integer primary key,\n  contents_embedding float[768]\n);\n```\n\n### Distance Metrics\n```sql\nCREATE VIRTUAL TABLE vec_items USING vec0(\n  embedding float[768] distance_metric=cosine\n);\n```\n\nSupported metrics: `l2` (default), `cosine`, `hamming` (bit vectors only)\n\n### Column Types\n\nvec0 tables support four column types:\n\n1. **Vector columns** - Store embeddings (float[N], int8[N], bit[N])\n2. **Metadata columns** - Indexed, filterable in KNN queries\n3. **Partition key columns** - Internal sharding for faster filtered queries\n4. **Auxiliary columns** - Unindexed storage (prefix with +)\n\nExample with all column types:\n```sql\nCREATE VIRTUAL TABLE vec_knowledge_base USING vec0(\n  document_id integer primary key,\n\n  -- Partition keys (sharding)\n  organization_id integer partition key,\n  created_month text partition key,\n\n  -- Vector column\n  content_embedding float[768] distance_metric=cosine,\n\n  -- Metadata columns (filterable in KNN)\n  document_type text,\n  language text,\n  word_count integer,\n  is_public boolean,\n\n  -- Auxiliary columns (not filterable)\n  +title text,\n  +full_content text,\n  +url text\n);\n```\n\n## KNN Queries\n\n### Standard Query Syntax\n```sql\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH ?\n  AND k = 10\nORDER BY distance;\n```\n\nKey components:\n- `WHERE embedding MATCH ?` - Triggers KNN query\n- `AND k = 10` - Limit to 10 nearest neighbors\n- `ORDER BY distance` - Sort results by proximity\n\n### Metadata Filtering\n```sql\nSELECT document_id, distance\nFROM vec_movies\nWHERE synopsis_embedding MATCH ?\n  AND k = 5\n  AND genre = 'scifi'\n  AND num_reviews BETWEEN 100 AND 500\n  AND mean_rating > 3.5\n  AND contains_violence = false\nORDER BY distance;\n```\n\nSupported operators on metadata: `=`, `!=`, `>`, `>=`, `<`, `<=`, `BETWEEN`\n\nNot supported: `IS NULL`, `LIKE`, `GLOB`, `REGEXP`, scalar functions\n\n### Partition Key Filtering\n```sql\nSELECT document_id, distance\nFROM vec_documents\nWHERE contents_embedding MATCH ?\n  AND k = 20\n  AND user_id = 123  -- Partition key pre-filters\nORDER BY distance;\n```\n\nPartition keys enable multi-tenant or temporal sharding. Best practices:\n- Each unique partition value should have 100+ vectors\n- Use 1-2 partition keys maximum\n- Avoid over-sharding (too many unique values)\n\n### Joining with Source Tables\n```sql\nWITH knn_matches AS (\n  SELECT document_id, distance\n  FROM vec_documents\n  WHERE contents_embedding MATCH ?\n    AND k = 10\n)\nSELECT\n  documents.id,\n  documents.title,\n  knn_matches.distance\nFROM knn_matches\nLEFT JOIN documents ON documents.id = knn_matches.document_id\nORDER BY knn_matches.distance;\n```\n\n## Distance Functions\n\nFor manual distance calculations (non-vec0 tables):\n\n```sql\n-- L2 distance\nSELECT vec_distance_l2('[1, 2]', '[3, 4]');\n-- 2.8284...\n\n-- Cosine distance\nSELECT vec_distance_cosine('[1, 1]', '[2, 2]');\n-- ~0.0\n\n-- Hamming distance (bit vectors)\nSELECT vec_distance_hamming(vec_bit(X'F0'), vec_bit(X'0F'));\n-- 8\n```\n\n## Vector Operations\n\n### Constructors\n```sql\n-- Float32\nSELECT vec_f32('[.1, .2, .3, 4]');  -- Subtype 223\n\n-- Int8\nSELECT vec_int8('[1, 2, 3, 4]');  -- Subtype 225\n\n-- Bit\nSELECT vec_bit(X'F0');  -- Subtype 224\n```\n\n### Metadata Functions\n```sql\n-- Get length\nSELECT vec_length('[1, 2, 3]');  -- 3\n\n-- Get type\nSELECT vec_type(vec_int8('[1, 2]'));  -- 'int8'\n\n-- Convert to JSON\nSELECT vec_to_json(vec_f32('[1, 2]'));  -- '[1.000000,2.000000]'\n```\n\n### Arithmetic\n```sql\n-- Add vectors\nSELECT vec_to_json(\n  vec_add('[.1, .2, .3]', '[.4, .5, .6]')\n);\n-- '[0.500000,0.700000,0.900000]'\n\n-- Subtract vectors\nSELECT vec_to_json(\n  vec_sub('[.1, .2, .3]', '[.4, .5, .6]')\n);\n-- '[-0.300000,-0.300000,-0.300000]'\n```\n\n### Transformations\n```sql\n-- Normalize (L2 norm)\nSELECT vec_to_json(\n  vec_normalize('[2, 3, 1, -4]')\n);\n-- '[0.365148,0.547723,0.182574,-0.730297]'\n\n-- Slice (for Matryoshka embeddings)\nSELECT vec_to_json(\n  vec_slice('[1, 2, 3, 4]', 0, 2)\n);\n-- '[1.000000,2.000000]'\n\n-- Matryoshka pattern: slice then normalize\nSELECT vec_normalize(vec_slice(embedding, 0, 256))\nFROM vec_items;\n```\n\n### Quantization\n```sql\n-- Binary quantization (positive1, negative0)\nSELECT vec_quantize_binary('[1, 2, 3, 4, -5, -6, -7, -8]');\n-- X'0F'\n\n-- Visualize\nSELECT vec_to_json(\n  vec_quantize_binary('[1, 2, -3, 4, -5, 6, -7, 8]')\n);\n-- '[0,1,0,0,1,0,1,0]'\n```\n\n### Iteration\n```sql\n-- Iterate through elements\nSELECT rowid, value\nFROM vec_each('[1, 2, 3, 4]');\n/*\n\n rowid  value \n\n 0      1     \n 1      2     \n 2      3     \n 3      4     \n\n*/\n```\n\n## Python Integration\n\n### Complete Example\n```python\nimport sqlite3\nimport sqlite_vec\nfrom sqlite_vec import serialize_float32\n\n# Setup\ndb = sqlite3.connect(\":memory:\")\ndb.enable_load_extension(True)\nsqlite_vec.load(db)\ndb.enable_load_extension(False)\n\n# Create table\ndb.execute(\"\"\"\n    CREATE VIRTUAL TABLE vec_items USING vec0(\n        embedding float[4]\n    )\n\"\"\")\n\n# Insert vectors\nitems = [\n    (1, [0.1, 0.1, 0.1, 0.1]),\n    (2, [0.2, 0.2, 0.2, 0.2]),\n    (3, [0.3, 0.3, 0.3, 0.3])\n]\n\nwith db:\n    for rowid, vector in items:\n        db.execute(\n            \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n            [rowid, serialize_float32(vector)]\n        )\n\n# Query\nquery = [0.25, 0.25, 0.25, 0.25]\nresults = db.execute(\n    \"\"\"\n    SELECT rowid, distance\n    FROM vec_items\n    WHERE embedding MATCH ?\n      AND k = 2\n    ORDER BY distance\n    \"\"\",\n    [serialize_float32(query)]\n).fetchall()\n\nfor rowid, distance in results:\n    print(f\"rowid={rowid}, distance={distance}\")\n```\n\n### Embedding API Integration\n```python\nfrom openai import OpenAI\nfrom sqlite_vec import serialize_float32\n\nclient = OpenAI()\n\n# Generate embedding\nresponse = client.embeddings.create(\n    input=\"your text here\",\n    model=\"text-embedding-3-small\"\n)\nembedding = response.data[0].embedding\n\n# Store in sqlite-vec\ndb.execute(\n    \"INSERT INTO vec_documents(id, embedding) VALUES(?, ?)\",\n    [doc_id, serialize_float32(embedding)]\n)\n\n# Query\nquery_embedding = client.embeddings.create(\n    input=\"search query\",\n    model=\"text-embedding-3-small\"\n).data[0].embedding\n\nresults = db.execute(\n    \"\"\"\n    SELECT id, distance\n    FROM vec_documents\n    WHERE embedding MATCH ?\n      AND k = 10\n    \"\"\",\n    [serialize_float32(query_embedding)]\n).fetchall()\n```\n\n## Performance Tips\n\n1. **Use partition keys** for multi-tenant or temporally-filtered queries\n2. **Keep k reasonable** (10-100 for most use cases)\n3. **Filter with metadata** columns when possible\n4. **Choose appropriate distance metric** for your embeddings\n5. **Batch operations** in transactions\n6. **Use auxiliary columns** for large data not needed in filtering\n7. **Ensure partition keys have 100+ vectors** per unique value\n\n## Common Patterns\n\n### Multi-tenant Search\n```sql\nCREATE VIRTUAL TABLE vec_docs USING vec0(\n  doc_id integer primary key,\n  user_id integer partition key,\n  embedding float[768]\n);\n\nSELECT doc_id, distance\nFROM vec_docs\nWHERE embedding MATCH ? AND k = 10 AND user_id = 123;\n```\n\n### Hybrid Search\n```sql\nSELECT product_id, distance\nFROM vec_products\nWHERE embedding MATCH ?\n  AND k = 20\n  AND category = 'electronics'\n  AND price < 1000.0\nORDER BY distance;\n```\n\n### Matryoshka Embeddings\n```sql\n-- Adaptive dimensions: slice then normalize\nSELECT vec_normalize(vec_slice(embedding, 0, 256))\nFROM vec_items;\n```\n\n## Reference Files\n\n- [setup.md](./references/setup.md) - Installation, extension loading, Python bindings, NumPy integration\n- [tables.md](./references/tables.md) - vec0 table creation, column types, metadata/partition/auxiliary columns\n- [queries.md](./references/queries.md) - KNN query patterns, metadata filtering, partition filtering, optimization\n- [operations.md](./references/operations.md) - Vector operations, constructors, transformations, quantization, batch operations\n\n## Resources\n\n- Official documentation: https://alexgarcia.xyz/sqlite-vec\n- GitHub repository: https://github.com/asg017/sqlite-vec\n- Python package: https://pypi.org/project/sqlite-vec/\n- API reference: https://alexgarcia.xyz/sqlite-vec/api-reference.html\n",
        "skills/sqlite-vec/references/operations.md": "# sqlite-vec Vector Operations\n\n## Table of Contents\n- [Constructor Functions](#constructor-functions)\n- [Vector Metadata](#vector-metadata)\n- [Arithmetic Operations](#arithmetic-operations)\n- [Transformations](#transformations)\n- [Quantization](#quantization)\n- [Iteration](#iteration)\n- [Batch Operations](#batch-operations)\n\n## Constructor Functions\n\n### vec_f32() - Float32 Vectors\nCreates a float32 vector from JSON or BLOB:\n\n```sql\n-- From JSON\nSELECT vec_f32('[.1, .2, .3, 4]');\n-- Returns: X'CDCCCC3DCDCC4C3E9A99993E00008040'\n\n-- From BLOB\nSELECT vec_f32(X'AABBCCDD');\n-- Returns: X'AABBCCDD' (with subtype 223)\n\n-- Check subtype\nSELECT subtype(vec_f32('[.1, .2, .3, 4]'));\n-- Returns: 223\n\n-- Convert back to JSON\nSELECT vec_to_json(vec_f32(X'AABBCCDD'));\n-- Returns: '[-1844071490169864000.000000]'\n```\n\nPython usage:\n```python\nfrom sqlite_vec import serialize_float32\n\nvector = [0.1, 0.2, 0.3, 0.4]\nblob = serialize_float32(vector)\n\n# Or manually\nimport struct\nblob = struct.pack(\"%sf\" % len(vector), *vector)\n```\n\n### vec_int8() - Int8 Vectors\nCreates an 8-bit integer vector:\n\n```sql\n-- From JSON\nSELECT vec_int8('[1, 2, 3, 4]');\n-- Returns: X'01020304' (subtype 225)\n\n-- Valid range: -128 to 127\nSELECT vec_int8('[127, -128, 0, 64]');\n-- Returns: X'7F800040'\n\n-- Out of range error\nSELECT vec_int8('[999]');\n-- ERROR: value out of range for int8\n```\n\nPython usage:\n```python\nfrom sqlite_vec import serialize_int8\n\nvector = [1, 2, 3, 4]\nblob = serialize_int8(vector)\n\n# Or manually\nimport struct\nblob = struct.pack(\"%sb\" % len(vector), *vector)\n```\n\n### vec_bit() - Binary Vectors\nCreates a bit vector from BLOB:\n\n```sql\n-- From BLOB (8 bits per byte)\nSELECT vec_bit(X'F0');\n-- Returns: X'F0' (subtype 224)\n\nSELECT vec_to_json(vec_bit(X'F0'));\n-- Returns: '[0,0,0,0,1,1,1,1]'\n\n-- Multiple bytes\nSELECT vec_to_json(vec_bit(X'FF00'));\n-- Returns: '[0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]'\n```\n\n## Vector Metadata\n\n### vec_length() - Get Dimension\n```sql\n-- Float32 (default)\nSELECT vec_length('[.1, .2]');\n-- Returns: 2\n\nSELECT vec_length(X'AABBCCDD');\n-- Returns: 1 (one 4-byte float)\n\nSELECT vec_length(vec_int8(X'AABBCCDD'));\n-- Returns: 4 (four 1-byte ints)\n\nSELECT vec_length(vec_bit(X'AABBCCDD'));\n-- Returns: 32 (32 bits)\n```\n\n### vec_type() - Get Element Type\n```sql\nSELECT vec_type('[.1, .2]');\n-- Returns: 'float32'\n\nSELECT vec_type(vec_int8('[1, 2]'));\n-- Returns: 'int8'\n\nSELECT vec_type(vec_bit(X'FF'));\n-- Returns: 'bit'\n```\n\n### vec_to_json() - Convert to JSON\n```sql\nSELECT vec_to_json(X'AABBCCDD');\n-- Returns: '[-1844071490169864000.000000]'\n\nSELECT vec_to_json(vec_int8(X'AABBCCDD'));\n-- Returns: '[-86,-69,-52,-35]'\n\nSELECT vec_to_json(vec_bit(X'F0'));\n-- Returns: '[0,0,0,0,1,1,1,1]'\n```\n\n## Arithmetic Operations\n\n### vec_add() - Vector Addition\nAdd corresponding elements of two vectors:\n\n```sql\nSELECT vec_to_json(\n  vec_add('[.1, .2, .3]', '[.4, .5, .6]')\n);\n-- Returns: '[0.500000,0.700000,0.900000]'\n\n-- Int8 vectors\nSELECT vec_to_json(\n  vec_add(vec_int8('[1, 2, 3]'), vec_int8('[4, 5, 6]'))\n);\n-- Returns: '[5,7,9]'\n\n-- Type mismatch error\nSELECT vec_add('[.1]', vec_int8('[1]'));\n-- ERROR: Vector type mismatch\n```\n\n### vec_sub() - Vector Subtraction\nSubtract corresponding elements:\n\n```sql\nSELECT vec_to_json(\n  vec_sub('[.1, .2, .3]', '[.4, .5, .6]')\n);\n-- Returns: '[-0.300000,-0.300000,-0.300000]'\n\n-- Int8 vectors\nSELECT vec_to_json(\n  vec_sub(vec_int8('[10, 20, 30]'), vec_int8('[1, 2, 3]'))\n);\n-- Returns: '[9,18,27]'\n```\n\n## Transformations\n\n### vec_normalize() - L2 Normalization\nNormalize vector to unit length (L2 norm):\n\n```sql\nSELECT vec_to_json(\n  vec_normalize('[2, 3, 1, -4]')\n);\n-- Returns: '[0.365148,0.547723,0.182574,-0.730297]'\n\n-- Only supports float32\nSELECT vec_normalize(vec_int8('[1, 2, 3]'));\n-- ERROR: Only float32 vectors supported\n```\n\nPython usage for Matryoshka embeddings:\n```python\n# Normalize after slicing for adaptive-length embeddings\ndb.execute(\"\"\"\n    SELECT vec_to_json(\n      vec_normalize(\n        vec_slice(embedding, 0, 256)\n      )\n    )\n    FROM vec_items\n\"\"\")\n```\n\n### vec_slice() - Extract Subvector\nExtract elements from start (inclusive) to end (exclusive):\n\n```sql\n-- Extract first 2 elements\nSELECT vec_to_json(\n  vec_slice('[1, 2, 3, 4]', 0, 2)\n);\n-- Returns: '[1.000000,2.000000]'\n\n-- Extract last 2 elements\nSELECT vec_to_json(\n  vec_slice('[1, 2, 3, 4]', 2, 4)\n);\n-- Returns: '[3.000000,4.000000]'\n\n-- Matryoshka pattern: slice then normalize\nSELECT vec_to_json(\n  vec_normalize(\n    vec_slice('[2, 3, 1, -4]', 0, 2)\n  )\n);\n-- Returns: '[0.554700,0.832050]'\n```\n\nConstraints:\n- `start >= 0`\n- `end > start`\n- `end <= vec_length(vector)`\n- For bit vectors, start and end must be divisible by 8\n\n## Quantization\n\n### vec_quantize_binary() - Binary Quantization\nConvert float32/int8 to bit vector (positive1, negative0):\n\n```sql\nSELECT vec_quantize_binary('[1, 2, 3, 4, 5, 6, 7, 8]');\n-- Returns: X'FF' (all positive)\n\nSELECT vec_quantize_binary('[1, 2, 3, 4, -5, -6, -7, -8]');\n-- Returns: X'0F' (first 4 positive, last 4 negative)\n\nSELECT vec_quantize_binary('[-1, -2, -3, -4, -5, -6, -7, -8]');\n-- Returns: X'00' (all negative)\n\n-- Visualize\nSELECT vec_to_json(\n  vec_quantize_binary('[1, 2, 3, 4, -5, -6, -7, -8]')\n);\n-- Returns: '[0,0,0,0,1,1,1,1]'\n```\n\nRequirements:\n- Vector length must be divisible by 8\n- Only float32 or int8 vectors\n\n### vec_quantize_int8() - Int8 Quantization\nQuantize float32 to int8 using the specified method:\n\n```sql\nSELECT vec_quantize_int8('[1.5, 2.7, -3.2, 4.9]', 'unit');\n-- Quantizes to int8 range [-128, 127]\n-- Second parameter specifies quantization method (e.g., 'unit')\n```\n\n## Iteration\n\n### vec_each() - Iterate Elements\nTable function returning one row per vector element:\n\n```sql\nSELECT rowid, value\nFROM vec_each('[1, 2, 3, 4]');\n/*\n\n rowid  value \n\n 0      1     \n 1      2     \n 2      3     \n 3      4     \n\n*/\n\n-- Int8 vector\nSELECT rowid, value\nFROM vec_each(vec_int8('[10, 20, 30]'));\n/*\n\n rowid  value \n\n 0      10    \n 1      20    \n 2      30    \n\n*/\n\n-- Bit vector\nSELECT rowid, value\nFROM vec_each(vec_bit(X'F0'));\n/*\n\n rowid  value \n\n 0      1     \n 1      1     \n 2      1     \n 3      1     \n 4      0     \n 5      0     \n 6      0     \n 7      0     \n\n*/\n```\n\nUse cases:\n- Debugging vectors\n- Computing custom statistics\n- Element-wise operations\n\n## Batch Operations\n\n### Batch Insert\n```python\nfrom sqlite_vec import serialize_float32\n\nvectors = [\n    (1, [0.1, 0.2, 0.3, 0.4]),\n    (2, [0.5, 0.6, 0.7, 0.8]),\n    (3, [0.9, 1.0, 1.1, 1.2])\n]\n\nwith db:\n    for rowid, vector in vectors:\n        db.execute(\n            \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n            [rowid, serialize_float32(vector)]\n        )\n```\n\n### Batch Insert from Query\n```sql\n-- From embeddings table\nINSERT INTO vec_items(rowid, embedding)\nSELECT id, embedding\nFROM source_embeddings;\n\n-- With transformation\nINSERT INTO vec_items(rowid, embedding)\nSELECT id, vec_normalize(embedding)\nFROM source_embeddings;\n```\n\n### Bulk Update\n```python\n# Update multiple vectors\nupdates = [\n    (serialize_float32([1.1, 1.2, 1.3, 1.4]), 1),\n    (serialize_float32([2.1, 2.2, 2.3, 2.4]), 2),\n    (serialize_float32([3.1, 3.2, 3.3, 3.4]), 3)\n]\n\nwith db:\n    for embedding, rowid in updates:\n        db.execute(\n            \"UPDATE vec_items SET embedding = ? WHERE rowid = ?\",\n            [embedding, rowid]\n        )\n```\n\n### Batch Delete\n```sql\n-- Delete by rowid list\nDELETE FROM vec_items\nWHERE rowid IN (1, 2, 3, 4, 5);\n\n-- Delete by metadata condition\nDELETE FROM vec_movies\nWHERE year < 1950;\n```\n\n### Batch Operations Best Practices\n\n1. Use transactions for bulk operations:\n```python\nwith db:  # Automatic transaction\n    for item in large_batch:\n        db.execute(...)\n```\n\n2. Prepare statements for repeated operations:\n```python\nstmt = db.execute(\"INSERT INTO vec_items VALUES (?, ?)\")\nwith db:\n    for item in items:\n        stmt.execute([item.id, serialize_float32(item.vector)])\n```\n\n3. Batch size recommendations:\n- Small batches (100-1000): Better memory usage\n- Large batches (10000+): Fewer transactions, faster overall\n- Balance based on available memory\n\n4. Monitor performance:\n```python\nimport time\n\nstart = time.time()\nwith db:\n    for i, vector in enumerate(vectors):\n        db.execute(...)\n        if i % 1000 == 0:\n            print(f\"Inserted {i} vectors in {time.time() - start:.2f}s\")\n```\n",
        "skills/sqlite-vec/references/queries.md": "# sqlite-vec Query Patterns\n\n## Table of Contents\n- [KNN Query Basics](#knn-query-basics)\n- [Distance Functions](#distance-functions)\n- [Metadata Filtering](#metadata-filtering)\n- [Partition Key Filtering](#partition-key-filtering)\n- [Point Queries](#point-queries)\n- [Full Table Scan](#full-table-scan)\n- [Query Optimization](#query-optimization)\n\n## KNN Query Basics\n\n### Standard KNN Syntax\n```sql\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH ?\n  AND k = 10\nORDER BY distance;\n```\n\nKey components:\n- `WHERE embedding MATCH ?` - Triggers KNN query on the embedding column\n- `AND k = 10` - Limit to 10 nearest neighbors\n- `ORDER BY distance` - Sort by proximity (distance column auto-generated)\n\n### Using LIMIT (SQLite 3.41+)\n```sql\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH ?\nLIMIT 10;\n```\n\nLIMIT only works correctly on SQLite 3.41+. Use `k =` for older versions.\n\n### Python Example\n```python\nfrom sqlite_vec import serialize_float32\n\nquery = [0.3, 0.3, 0.3, 0.3]\n\nresults = db.execute(\n    \"\"\"\n    SELECT rowid, distance\n    FROM vec_items\n    WHERE embedding MATCH ?\n      AND k = 5\n    ORDER BY distance\n    \"\"\",\n    [serialize_float32(query)]\n).fetchall()\n\nfor rowid, distance in results:\n    print(f\"rowid={rowid}, distance={distance}\")\n```\n\n### Joining with Source Tables\n```sql\nWITH knn_matches AS (\n  SELECT document_id, distance\n  FROM vec_documents\n  WHERE contents_embedding MATCH ?\n    AND k = 10\n)\nSELECT\n  documents.id,\n  documents.title,\n  documents.contents,\n  knn_matches.distance\nFROM knn_matches\nLEFT JOIN documents ON documents.id = knn_matches.document_id\nORDER BY knn_matches.distance;\n```\n\n## Distance Functions\n\n### Distance Metric in Table Definition\n```sql\nCREATE VIRTUAL TABLE vec_cosine USING vec0(\n  embedding float[768] distance_metric=cosine\n);\n\n-- KNN query uses cosine distance automatically\nSELECT rowid, distance\nFROM vec_cosine\nWHERE embedding MATCH ?\n  AND k = 10;\n```\n\nSupported metrics:\n- `l2` - Euclidean distance (default)\n- `cosine` - Cosine distance\n- `hamming` - Hamming distance (for bit vectors)\n\n### Manual Distance Calculation\n\nFor regular tables (not vec0):\n\n```sql\n-- L2 distance\nSELECT\n  id,\n  contents,\n  vec_distance_l2(contents_embedding, ?) as distance\nFROM documents\nORDER BY distance\nLIMIT 10;\n\n-- Cosine distance\nSELECT\n  id,\n  vec_distance_cosine(contents_embedding, ?) as distance\nFROM documents\nORDER BY distance\nLIMIT 10;\n\n-- Hamming distance (bit vectors)\nSELECT\n  id,\n  vec_distance_hamming(signature, ?) as distance\nFROM documents\nORDER BY distance\nLIMIT 10;\n```\n\n## Metadata Filtering\n\n### Single Metadata Filter\n```sql\nSELECT rowid, genre, distance\nFROM vec_movies\nWHERE synopsis_embedding MATCH ?\n  AND k = 10\n  AND genre = 'scifi'\nORDER BY distance;\n```\n\n### Multiple Metadata Filters\n```sql\nSELECT rowid, distance\nFROM vec_movies\nWHERE synopsis_embedding MATCH ?\n  AND k = 5\n  AND genre = 'scifi'\n  AND num_reviews BETWEEN 100 AND 500\n  AND mean_rating > 3.5\n  AND contains_violence = false\nORDER BY distance;\n```\n\n### Range Queries\n```sql\n-- Numeric ranges\nWHERE rating BETWEEN 3.0 AND 5.0\nWHERE year >= 2020\nWHERE budget < 1000000\n\n-- Text equality (no LIKE in KNN)\nWHERE category = 'technology'\nWHERE language = 'en'\n```\n\n### Boolean Filters\n```sql\nWHERE is_published = true\nWHERE has_images = false\nWHERE is_archived != true\n```\n\n## Partition Key Filtering\n\n### Single Partition Key\n```sql\nSELECT document_id, distance\nFROM vec_documents\nWHERE contents_embedding MATCH ?\n  AND k = 20\n  AND user_id = 123  -- Partition key filter\nORDER BY distance;\n```\n\nThis query only searches vectors belonging to user 123, making it much faster.\n\n### Date Range Partition\n```sql\nSELECT article_id, distance\nFROM vec_articles\nWHERE headline_embedding MATCH ?\n  AND k = 10\n  AND published_date BETWEEN '2024-01-01' AND '2024-12-31'\nORDER BY distance;\n```\n\n### Multiple Partition Keys\n```sql\nSELECT document_id, distance\nFROM vec_multi_tenant\nWHERE embedding MATCH ?\n  AND k = 10\n  AND organization_id = 456\n  AND region = 'us-west'\n  AND created_month = '2024-12'\nORDER BY distance;\n```\n\n### IN Constraint (Advanced)\n```sql\n-- Partition key with IN clause\nSELECT document_id, distance\nFROM vec_documents\nWHERE contents_embedding MATCH ?\n  AND k = 10\n  AND user_id IN (123, 456, 789)\nORDER BY distance;\n```\n\n## Point Queries\n\nRetrieve a single vector by rowid or primary key:\n\n### By rowid\n```sql\nSELECT rowid, embedding\nFROM vec_items\nWHERE rowid = 42;\n```\n\n### By Primary Key\n```sql\nSELECT document_id, contents_embedding\nFROM vec_documents\nWHERE document_id = 123;\n```\n\n### With Auxiliary Data\n```sql\nSELECT document_id, embedding, title, contents\nFROM vec_documents\nWHERE document_id = 123;\n```\n\n## Full Table Scan\n\nQuery all vectors without KNN:\n\n```sql\n-- All vectors\nSELECT rowid, embedding\nFROM vec_items;\n\n-- With metadata filter (no vector MATCH)\nSELECT rowid, genre\nFROM vec_movies\nWHERE genre = 'scifi';\n\n-- Count vectors\nSELECT COUNT(*) FROM vec_items;\n```\n\n## Query Optimization\n\n### Selecting Specific Columns\n```sql\n-- Only what you need\nSELECT document_id, distance\nFROM vec_documents\nWHERE embedding MATCH ?\n  AND k = 10;\n\n-- With auxiliary data\nSELECT document_id, title, url, distance\nFROM vec_documents\nWHERE embedding MATCH ?\n  AND k = 10;\n```\n\n### Using Indexes on Metadata\nMetadata columns in vec0 are automatically indexed for KNN queries.\n\n### Batch Queries\n```python\n# Query multiple vectors efficiently\nqueries = [\n    [0.1, 0.2, 0.3, 0.4],\n    [0.5, 0.6, 0.7, 0.8],\n    [0.9, 1.0, 1.1, 1.2]\n]\n\nresults = []\nfor query in queries:\n    rows = db.execute(\n        \"\"\"\n        SELECT rowid, distance\n        FROM vec_items\n        WHERE embedding MATCH ?\n          AND k = 5\n        \"\"\",\n        [serialize_float32(query)]\n    ).fetchall()\n    results.append(rows)\n```\n\n### Result Pagination\n```sql\n-- Not directly supported, use k parameter\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH ?\n  AND k = 50  -- Get top 50, handle pagination in application\nORDER BY distance;\n```\n\n### Query Performance Tips\n\n1. Use partition keys for multi-tenant/filtered queries\n2. Keep k value reasonable (10-100 for most use cases)\n3. Filter with metadata columns when possible\n4. Use appropriate distance metric for your embeddings\n5. Ensure partition keys have 100+ vectors per unique value\n6. Batch similar queries together\n7. Use auxiliary columns for large data not needed in filtering\n\n### Complex Query Example\n```python\nfrom sqlite_vec import serialize_float32\n\n# Multi-condition filtered KNN query\nquery_embedding = get_embedding(\"semantic search query\")\n\nresults = db.execute(\n    \"\"\"\n    SELECT\n      document_id,\n      title,\n      url,\n      distance\n    FROM vec_knowledge_base\n    WHERE content_embedding MATCH ?\n      AND k = 20\n      AND organization_id = ?\n      AND created_month = ?\n      AND document_type IN ('article', 'blog')\n      AND is_public = true\n      AND language = 'en'\n      AND word_count > 500\n    ORDER BY distance\n    \"\"\",\n    [\n        serialize_float32(query_embedding),\n        123,  # organization_id\n        '2024-12'  # created_month\n    ]\n).fetchall()\n\nfor doc_id, title, url, dist in results:\n    print(f\"{title}: {dist:.4f}\")\n```\n\n### Combining with Regular SQL\n```sql\n-- Subquery with KNN\nSELECT\n  d.id,\n  d.title,\n  COUNT(c.id) as comment_count,\n  v.distance\nFROM (\n  SELECT document_id, distance\n  FROM vec_documents\n  WHERE embedding MATCH ?\n    AND k = 10\n) v\nJOIN documents d ON d.id = v.document_id\nLEFT JOIN comments c ON c.document_id = d.id\nGROUP BY d.id, d.title, v.distance\nORDER BY v.distance;\n```\n\n### Similarity Search with Threshold\n```sql\n-- Find all items within distance threshold\nSELECT rowid, distance\nFROM vec_items\nWHERE embedding MATCH ?\n  AND k = 1000  -- Large k to get more candidates\n  AND distance < 0.5  -- Filter by distance threshold\nORDER BY distance;\n```\n",
        "skills/sqlite-vec/references/setup.md": "# sqlite-vec Setup\n\n## Table of Contents\n- [Installation](#installation)\n- [Loading the Extension](#loading-the-extension)\n- [Binary Serialization Helper](#binary-serialization-helper)\n- [NumPy Integration](#numpy-integration)\n- [Connection Setup Pattern](#connection-setup-pattern)\n- [SQLite Version Requirements](#sqlite-version-requirements)\n- [MacOS Considerations](#macos-considerations)\n\n## Installation\n\n### Python\n```bash\npip install sqlite-vec\n```\n\n### Other Languages\n- Node.js: `pnpm add sqlite-vec`\n- Ruby: `gem install sqlite-vec`\n- Go: `go get -u github.com/asg017/sqlite-vec/bindings/go`\n- Rust: `cargo add sqlite-vec`\n\n## Loading the Extension\n\n### Python\n```python\nimport sqlite3\nimport sqlite_vec\n\ndb = sqlite3.connect(\":memory:\")\ndb.enable_load_extension(True)\nsqlite_vec.load(db)\ndb.enable_load_extension(False)\n\n# Verify installation\nvec_version, = db.execute(\"select vec_version()\").fetchone()\nprint(f\"vec_version={vec_version}\")\n```\n\n### CLI\n```sql\n.load ./vec0\nselect vec_version();\n```\n\n## Binary Serialization Helper\n\n### serialize_float32()\nConverts a Python list of floats into the compact BLOB format sqlite-vec expects:\n\n```python\nfrom sqlite_vec import serialize_float32\nimport struct\n\nembedding = [0.1, 0.2, 0.3, 0.4]\n\n# Using the helper function\nblob = serialize_float32(embedding)\n\n# Equivalent to:\nblob = struct.pack(\"%sf\" % len(embedding), *embedding)\n\n# Use in queries\ndb.execute(\n    \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n    [1, serialize_float32(embedding)]\n)\n```\n\n### serialize_int8()\nFor int8 vectors:\n\n```python\nfrom sqlite_vec import serialize_int8\n\nint_vector = [1, 2, 3, 4]\nblob = serialize_int8(int_vector)\n```\n\n## NumPy Integration\n\n### Using NumPy Arrays\nNumPy arrays can be passed directly as they implement the Buffer protocol. Cast to float32:\n\n```python\nimport numpy as np\n\nembedding = np.array([0.1, 0.2, 0.3, 0.4])\n\n# Must cast to float32\ndb.execute(\n    \"SELECT vec_length(?)\",\n    [embedding.astype(np.float32)]\n)\n```\n\n### register_numpy()\nFor advanced NumPy integration with static blobs:\n\n```python\nfrom sqlite_vec import register_numpy\nimport numpy as np\n\n# Create a NumPy array of vectors\nvectors = np.array([\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n], dtype=np.float32)\n\n# Register as a static blob table\nregister_numpy(db, \"my_vectors\", vectors)\n\n# Query the static blob table\nresults = db.execute(\n    \"SELECT rowid, vector FROM my_vectors\"\n).fetchall()\n```\n\n## Connection Setup Pattern\n\nComplete setup pattern for Python:\n\n```python\nimport sqlite3\nimport sqlite_vec\nfrom sqlite_vec import serialize_float32\nimport struct\n\n# Create connection\ndb = sqlite3.connect(\":memory:\")  # or use a file path\ndb.enable_load_extension(True)\nsqlite_vec.load(db)\ndb.enable_load_extension(False)\n\n# Verify version\nsqlite_version, vec_version = db.execute(\n    \"select sqlite_version(), vec_version()\"\n).fetchone()\nprint(f\"sqlite_version={sqlite_version}, vec_version={vec_version}\")\n\n# Create vec0 table\ndb.execute(\"\"\"\n    CREATE VIRTUAL TABLE vec_items USING vec0(\n        embedding float[4]\n    )\n\"\"\")\n\n# Insert vectors\nitems = [\n    (1, [0.1, 0.1, 0.1, 0.1]),\n    (2, [0.2, 0.2, 0.2, 0.2]),\n    (3, [0.3, 0.3, 0.3, 0.3])\n]\n\nwith db:\n    for rowid, vector in items:\n        db.execute(\n            \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n            [rowid, serialize_float32(vector)]\n        )\n\n# Query\nquery = [0.25, 0.25, 0.25, 0.25]\nresults = db.execute(\n    \"\"\"\n    SELECT rowid, distance\n    FROM vec_items\n    WHERE embedding MATCH ?\n      AND k = 2\n    ORDER BY distance\n    \"\"\",\n    [serialize_float32(query)]\n).fetchall()\n```\n\n## SQLite Version Requirements\n\nsqlite-vec requires SQLite 3.41+ for full functionality. Check version:\n\n```bash\npython -c 'import sqlite3; print(sqlite3.sqlite_version)'\n```\n\n### Upgrade Options\n1. Use `pysqlite3` package (bundles updated SQLite)\n2. Compile custom SQLite with LD_PRELOAD/DYLD_LIBRARY_PATH\n3. Upgrade Python version (3.12+ usually has recent SQLite)\n\n## MacOS Considerations\n\nDefault MacOS Python doesn't support SQLite extensions. Solutions:\n\n1. Use Homebrew Python: `brew install python`\n2. Use `/opt/homebrew/bin/python3` instead of system Python\n3. Install `pysqlite3` package\n\nError indicating this issue:\n```\nAttributeError: 'sqlite3.Connection' object has no attribute 'enable_load_extension'\n```\n",
        "skills/sqlite-vec/references/tables.md": "# vec0 Virtual Tables\n\n## Table of Contents\n- [Basic Table Creation](#basic-table-creation)\n- [Vector Column Types](#vector-column-types)\n- [Metadata Columns](#metadata-columns)\n- [Partition Key Columns](#partition-key-columns)\n- [Auxiliary Columns](#auxiliary-columns)\n- [Performance Tuning](#performance-tuning)\n\n## Basic Table Creation\n\n### Simple vec0 Table\n```sql\nCREATE VIRTUAL TABLE vec_items USING vec0(\n  embedding float[4]\n);\n```\n\n### With Primary Key\n```sql\nCREATE VIRTUAL TABLE vec_documents USING vec0(\n  document_id integer primary key,\n  contents_embedding float[768]\n);\n```\n\n### With Distance Metric\n```sql\nCREATE VIRTUAL TABLE vec_documents USING vec0(\n  document_id integer primary key,\n  contents_embedding float[768] distance_metric=cosine\n);\n```\n\nDistance metrics: `l2` (default), `cosine`, `hamming` (for bit vectors)\n\n## Vector Column Types\n\n### float[N] - Float32 Vectors\n4 bytes per element, most common for embeddings:\n\n```sql\nCREATE VIRTUAL TABLE vec_embeddings USING vec0(\n  embedding float[1536]  -- OpenAI text-embedding-3-small\n);\n```\n\n### int8[N] - 8-bit Integer Vectors\n1 byte per element, for quantized embeddings:\n\n```sql\nCREATE VIRTUAL TABLE vec_quantized USING vec0(\n  embedding int8[768]\n);\n```\n\n### bit[N] - Binary Vectors\n1 bit per element (packed into bytes), for binary quantization:\n\n```sql\nCREATE VIRTUAL TABLE vec_binary USING vec0(\n  embedding bit[768]  -- 96 bytes storage\n);\n```\n\n## Metadata Columns\n\nMetadata columns are indexed alongside vectors and can be filtered in KNN queries.\n\n### Supported Types\n- `TEXT` - strings\n- `INTEGER` - 8-byte integers\n- `FLOAT` - 8-byte floating point\n- `BOOLEAN` - 1-bit (0 or 1)\n\nMaximum: 16 metadata columns per table\n\n### Declaration\n```sql\nCREATE VIRTUAL TABLE vec_movies USING vec0(\n  movie_id integer primary key,\n  synopsis_embedding float[1024],\n  genre text,\n  num_reviews integer,\n  mean_rating float,\n  contains_violence boolean\n);\n```\n\n### Inserting with Metadata\n```python\ndb.execute(\"\"\"\n    INSERT INTO vec_movies(movie_id, synopsis_embedding, genre, num_reviews, mean_rating, contains_violence)\n    VALUES (?, ?, ?, ?, ?, ?)\n\"\"\", [\n    1,\n    serialize_float32(embedding),\n    'scifi',\n    250,\n    4.2,\n    False\n])\n```\n\n### Filtering in KNN Queries\n```sql\nSELECT *\nFROM vec_movies\nWHERE synopsis_embedding MATCH ?\n  AND k = 5\n  AND genre = 'scifi'\n  AND num_reviews BETWEEN 100 AND 500\n  AND mean_rating > 3.5\n  AND contains_violence = false\nORDER BY distance;\n```\n\n### Supported Operators\n- `=` - Equals\n- `!=` - Not equals\n- `>` - Greater than\n- `>=` - Greater than or equal\n- `<` - Less than\n- `<=` - Less than or equal\n\nBOOLEAN columns only support `=` and `!=`\n\nUnsupported: `IS NULL`, `LIKE`, `GLOB`, `REGEXP`, scalar functions\n\n## Partition Key Columns\n\nPartition keys internally shard the vector index for faster filtered queries.\n\nMaximum: 4 partition key columns per table\n\n### Use Cases\n1. Multi-tenant data (user_id, organization_id)\n2. Temporal data (published_date, created_month)\n3. Category-based filtering (document_type, region)\n\n### Single Partition Key\n```sql\nCREATE VIRTUAL TABLE vec_documents USING vec0(\n  document_id integer primary key,\n  user_id integer partition key,\n  contents_embedding float[1024]\n);\n```\n\nQuery with partition filtering:\n```sql\nSELECT document_id, distance\nFROM vec_documents\nWHERE contents_embedding MATCH :query\n  AND k = 20\n  AND user_id = 123;\n```\n\n### Multiple Partition Keys\n```sql\nCREATE VIRTUAL TABLE vec_articles USING vec0(\n  article_id integer primary key,\n  organization_id integer partition key,\n  published_date text partition key,\n  headline_embedding float[1024]\n);\n```\n\nQuery with multiple partition filters:\n```sql\nSELECT article_id, distance\nFROM vec_articles\nWHERE headline_embedding MATCH :query\n  AND k = 10\n  AND organization_id = 456\n  AND published_date BETWEEN '2024-01-01' AND '2024-12-31';\n```\n\n### Best Practices\n- Each unique partition key value should have 100+ vectors\n- Avoid over-sharding (too many unique partition values)\n- Consider broader keys if queries are slow (e.g., month instead of day)\n- Use 1-2 partition keys maximum in most cases\n\n### Supported Operators\n- `=` - Equals\n- `BETWEEN` - Range (inclusive)\n\n## Auxiliary Columns\n\nAuxiliary columns store unindexed data separately, avoiding JOIN operations.\n\nMaximum: 16 auxiliary columns per table\n\n### Use Cases\n- Large text content\n- Raw image/document BLOBs\n- URLs, metadata not used in WHERE clauses\n- Data appearing in SELECT but not WHERE\n\n### Declaration\nPrefix column name with `+`:\n\n```sql\nCREATE VIRTUAL TABLE vec_chunks USING vec0(\n  contents_embedding float[1024],\n  +contents text\n);\n```\n\n### Multiple Auxiliary Columns\n```sql\nCREATE VIRTUAL TABLE vec_documents USING vec0(\n  document_id integer primary key,\n  embedding float[768],\n  +title text,\n  +url text,\n  +full_text text,\n  +metadata_json text\n);\n```\n\n### Querying\nAuxiliary columns can appear in SELECT but not in WHERE:\n\n```sql\n--  Valid: auxiliary column in SELECT\nSELECT rowid, contents, distance\nFROM vec_chunks\nWHERE contents_embedding MATCH ?\n  AND k = 10;\n\n--  Invalid: auxiliary column in WHERE\nSELECT rowid, distance\nFROM vec_chunks\nWHERE contents_embedding MATCH ?\n  AND contents LIKE '%search%';  -- ERROR\n```\n\n### Image Storage Example\n```sql\nCREATE VIRTUAL TABLE vec_images USING vec0(\n  image_id integer primary key,\n  image_embedding float[512],\n  +image blob,\n  +image_url text\n);\n\nSELECT image_id, image, image_url, distance\nFROM vec_images\nWHERE image_embedding MATCH ?\n  AND k = 5\nORDER BY distance;\n```\n\n## Performance Tuning\n\n### chunk_size Parameter\nControls internal chunking for better performance:\n\n```sql\nCREATE VIRTUAL TABLE vec_large USING vec0(\n  embedding float[1536],\n  chunk_size=512\n);\n```\n\nDefault chunk_size is appropriate for most use cases. Tune for:\n- Very large tables (millions of vectors)\n- Specific memory constraints\n- Bulk insert performance\n\n### Column Type Comparison\n\n| Column Type   | Use Case                          | In WHERE? | In SELECT? | Max Count |\n|---------------|-----------------------------------|-----------|------------|-----------|\n| Vector        | Embeddings                        | MATCH     |           | Multiple  |\n| Metadata      | Filtered searches                 |          |           | 16        |\n| Partition Key | Multi-tenant/temporal sharding    |          |           | 4         |\n| Auxiliary     | Large content, no filtering       |          |           | 16        |\n\n### Complete Example\n\n```sql\nCREATE VIRTUAL TABLE vec_knowledge_base USING vec0(\n  -- Primary key\n  document_id integer primary key,\n\n  -- Partition keys (multi-tenant + temporal)\n  organization_id integer partition key,\n  created_month text partition key,\n\n  -- Vector column\n  content_embedding float[768] distance_metric=cosine,\n\n  -- Metadata columns (filterable)\n  document_type text,\n  language text,\n  word_count integer,\n  is_public boolean,\n\n  -- Auxiliary columns (not filterable)\n  +title text,\n  +full_content text,\n  +url text,\n  +metadata_json text,\n\n  chunk_size=256\n);\n```\n\nQuery example:\n```sql\nSELECT\n  document_id,\n  title,\n  full_content,\n  distance\nFROM vec_knowledge_base\nWHERE content_embedding MATCH ?\n  AND k = 10\n  AND organization_id = 123\n  AND created_month = '2024-12'\n  AND document_type = 'article'\n  AND is_public = true\n  AND language = 'en'\n  AND word_count > 500\nORDER BY distance;\n```\n",
        "skills/swift-code-review/SKILL.md": "---\nname: swift-code-review\ndescription: Reviews Swift code for concurrency safety, error handling, memory management, and common mistakes. Use when reviewing .swift files for async/await patterns, actor isolation, Sendable conformance, or general Swift best practices.\n---\n\n# Swift Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| async/await, actors, Sendable, Task | [references/concurrency.md](references/concurrency.md) |\n| @Observable, @ObservationIgnored, @Bindable | [references/observable.md](references/observable.md) |\n| throws, Result, try?, typed throws | [references/error-handling.md](references/error-handling.md) |\n| Force unwraps, retain cycles, naming | [references/common-mistakes.md](references/common-mistakes.md) |\n\n## Review Checklist\n\n- [ ] No force unwraps (`!`) on runtime data (network, user input, files)\n- [ ] Closures stored as properties use `[weak self]`\n- [ ] Delegate properties are `weak`\n- [ ] Independent async operations use `async let` or `TaskGroup`\n- [ ] Long-running Tasks check `Task.isCancelled`\n- [ ] Actors have mutable state to protect (no stateless actors)\n- [ ] Sendable types are truly thread-safe (beware `@unchecked`)\n- [ ] Errors handled explicitly (no empty catch blocks)\n- [ ] Custom errors conform to `LocalizedError` with descriptive messages\n- [ ] Nested @Observable objects are also marked @Observable\n- [ ] @Bindable used for two-way bindings to Observable objects\n\n## When to Load References\n\n- Reviewing async/await, actors, or TaskGroups  concurrency.md\n- Reviewing @Observable or SwiftUI state  observable.md\n- Reviewing error handling or throws  error-handling.md\n- General Swift review  common-mistakes.md\n\n## Review Questions\n\n1. Are async operations that could run concurrently using `async let`?\n2. Could actor state change across suspension points (reentrancy bug)?\n3. Is `@unchecked Sendable` backed by actual synchronization?\n4. Are errors logged and presented with helpful context?\n5. Could any closure or delegate create a retain cycle?\n",
        "skills/swift-code-review/references/common-mistakes.md": "# Swift Common Mistakes\n\n## Critical Anti-Patterns\n\n### 1. Force Unwrapping Runtime Data\n\n```swift\n// BAD - crashes on invalid input\nlet url = URL(string: userProvidedString)!\nlet first = response.items.first!\nlet value = dictionary[\"key\"]!\n\n// GOOD - safe unwrapping\nguard let url = URL(string: userProvidedString) else {\n    showError(\"Invalid URL\")\n    return\n}\nlet first = response.items.first ?? defaultItem\nlet value = dictionary[\"key\", default: fallback]\n\n// ACCEPTABLE force unwrap - compile-time verifiable\nlet url = URL(string: \"https://apple.com\")!\nlet image = UIImage(named: \"AppIcon\")!\n```\n\n### 2. Retain Cycles in Closures\n\n```swift\n// BAD - closure captures self strongly\nclass ViewController {\n    var onComplete: (() -> Void)?\n    func setup() {\n        onComplete = { self.updateUI() }  // Retain cycle!\n    }\n}\n\n// GOOD - weak capture\nonComplete = { [weak self] in\n    guard let self else { return }\n    self.updateUI()\n}\n```\n\n### 3. Delegate Without Weak\n\n```swift\n// BAD - strong delegate causes cycle\nvar delegate: SomeDelegate?\n\n// GOOD - delegates are always weak\nweak var delegate: SomeDelegate?\n```\n\n### 4. Nil Check Then Force Unwrap\n\n```swift\n// BAD - dangerous pattern\nif optionalString != nil {\n    print(optionalString!.count)\n}\n\n// GOOD - optional binding\nif let string = optionalString {\n    print(string.count)\n}\n\n// Swift 5.7+ shorthand\nif let optionalString {\n    print(optionalString.count)\n}\n```\n\n### 5. Unnecessary Optionals\n\n```swift\n// BAD - always has value but declared optional\nstruct Person {\n    let name: String?  // Set in init, never nil\n    init(name: String) { self.name = name }\n}\n\n// GOOD - non-optional when always present\nstruct Person {\n    let name: String\n    init(name: String) { self.name = name }\n}\n```\n\n### 6. Unchecked Array Access\n\n```swift\n// BAD - crashes if out of bounds\nlet item = items[index]\nlet first = items[0]  // Crashes if empty\n\n// GOOD - bounds checking\nif items.indices.contains(index) {\n    let item = items[index]\n}\nlet first = items.first  // Returns optional\n\n// Safe subscript extension\nextension Collection {\n    subscript(safe index: Index) -> Element? {\n        indices.contains(index) ? self[index] : nil\n    }\n}\n```\n\n### 7. Implicitly Unwrapped Optionals\n\n```swift\n// BAD - IUO for regular properties\nclass UserProfile {\n    var name: String!\n    var avatar: UIImage!  // Never set - crash!\n}\n\n// GOOD - proper optionals or non-optionals\nclass UserProfile {\n    let name: String\n    var avatar: UIImage?  // Truly optional\n    init(name: String) { self.name = name }\n}\n\n// ACCEPTABLE IUO - @IBOutlet only\n@IBOutlet weak var titleLabel: UILabel!\n```\n\n## Naming Conventions\n\n```swift\n// BAD naming\nfunc chkPwd(_ p: String) -> Bool  // Unclear abbreviation\nlet stringName: String  // Type in name\nvar enabled: Bool  // Missing is/has prefix\nfunc sort() -> [Int]  // Reads like mutation\n\n// GOOD naming\nfunc checkPassword(_ password: String) -> Bool\nlet userName: String  // Name by role\nvar isEnabled: Bool  // Predicate prefix\nfunc sorted() -> [Int]  // Non-mutating returns new value\nmutating func sort()  // Mutating is imperative verb\n```\n\n## Best Practices Summary\n\n| Topic | Best Practice |\n|-------|---------------|\n| Force Unwrap | Only for compile-time verifiable constants |\n| Retain Cycles | `weak` delegates, `[weak self]` in closures |\n| Optionals | Use binding, not nil-check + force-unwrap |\n| Collections | Use `.first`, `.last`, or safe subscript |\n| IUOs | Only for @IBOutlet |\n\n## Review Questions\n\n1. Is this force unwrap (`!`) backed by compile-time certainty?\n2. Could this closure stored as a property cause a retain cycle?\n3. Are delegate properties marked `weak`?\n4. Is this optional really necessary, or is it always set?\n5. Is collection access bounds-checked?\n",
        "skills/swift-code-review/references/concurrency.md": "# Swift Concurrency\n\n## Critical Anti-Patterns\n\n### 1. Sequential Execution When Concurrent Is Possible\n\n```swift\n// BAD - sequential awaits on independent operations\nlet user = await fetchUser()\nlet avatar = await fetchAvatar(for: user.id)      // Waits unnecessarily\nlet prefs = await fetchPreferences(for: user.id)  // Waits unnecessarily\n\n// GOOD - async let for independent operations\nlet user = await fetchUser()\nasync let avatar = fetchAvatar(for: user.id)\nasync let prefs = fetchPreferences(for: user.id)\nreturn Profile(user: user, avatar: try await avatar, prefs: try await prefs)\n```\n\n### 2. Memory Leaks from Task Self-Capture\n\n```swift\n// BAD - self captured indefinitely in async sequence\nTask {\n    for await notification in stream {\n        handleNotification(notification)  // implicit self\n    }\n}\n\n// GOOD - weak self with guard inside the loop\nTask { [weak self] in\n    for await notification in stream {\n        guard let self else { return }\n        self.handleNotification(notification)\n    }\n}\n```\n\n### 3. Actor Reentrancy Bugs\n\n```swift\n// BAD - state check before await, mutation after\nactor BankAccount {\n    var balance: Double = 1000\n    func withdraw(_ amount: Double) async -> Bool {\n        guard balance >= amount else { return false }\n        await recordTransaction(amount)  // state can change here!\n        balance -= amount  // may go negative\n        return true\n    }\n}\n\n// GOOD - mutate state before await\nfunc withdraw(_ amount: Double) async -> Bool {\n    guard balance >= amount else { return false }\n    balance -= amount  // safe - done before suspension\n    await recordTransaction(amount)\n    return true\n}\n```\n\n### 4. Stateless Actors\n\n```swift\n// BAD - actor with nothing to protect\nactor NetworkService {\n    func fetchData(from url: URL) async throws -> Data {\n        try await URLSession.shared.data(from: url).0\n    }\n}\n\n// GOOD - use enum or struct for stateless operations\nenum NetworkService {\n    static func fetchData(from url: URL) async throws -> Data {\n        try await URLSession.shared.data(from: url).0\n    }\n}\n```\n\n### 5. Ignoring Task Cancellation\n\n```swift\n// BAD - long loop ignores cancellation\nfor item in items {\n    await process(item)\n}\n\n// GOOD - check cancellation\nfor item in items {\n    try Task.checkCancellation()\n    await process(item)\n}\n```\n\n### 6. Non-Sendable Types Across Actors\n\n```swift\n// BAD - mutable class crossing boundaries\nclass Session { var token: String? }\n\n// GOOD - immutable struct\nstruct Session: Sendable { let token: String }\n\n// GOOD - @unchecked with actual lock\nfinal class Session: @unchecked Sendable {\n    private let lock = NSLock()\n    private var _token: String?\n    var token: String? {\n        get { lock.withLock { _token } }\n        set { lock.withLock { _token = newValue } }\n    }\n}\n```\n\n### 7. Errors Silently Ignored in Tasks\n\n```swift\n// BAD - error lost\nTask { try await database.save(data) }\n\n// GOOD - handle explicitly\nTask {\n    do { try await database.save(data) }\n    catch { logger.error(\"Save failed: \\(error)\") }\n}\n```\n\n## Best Practices\n\n- **Use `async let`** for 2-3 independent operations\n- **Use `TaskGroup`** for dynamic number of concurrent tasks with result aggregation\n- **Apply `@MainActor` at type level** for ViewModels, not scattered `MainActor.run`\n- **Use `.task` modifier** in SwiftUI instead of `Task` in `onAppear`\n- **Use `nonisolated`** for pure functions in @MainActor types\n- **Limit TaskGroup concurrency** with iterator pattern for large workloads\n\n## Review Questions\n\n1. Are independent async operations running concurrently?\n2. Could actor state change across suspension points (reentrancy)?\n3. Is `@unchecked Sendable` backed by actual synchronization?\n4. Are long-running Tasks checking `Task.isCancelled`?\n5. Are errors in Task closures being handled or silently lost?\n",
        "skills/swift-code-review/references/error-handling.md": "# Swift Error Handling\n\n## Critical Anti-Patterns\n\n### 1. Force Try in Production Code\n\n```swift\n// BAD - crashes if file missing or JSON invalid\nlet data = try! Data(contentsOf: configURL)\nlet config = try! JSONDecoder().decode(Config.self, from: data)\n\n// GOOD - handle failures\ndo {\n    let data = try Data(contentsOf: configURL)\n    let config = try JSONDecoder().decode(Config.self, from: data)\n} catch {\n    logger.error(\"Failed to load config: \\(error)\")\n    return Config.default\n}\n```\n\n### 2. Silencing Errors Without Logging\n\n```swift\n// BAD - error context lost\nlet user = try? fetchUser(id: userId)\nif user == nil { showError(\"Something went wrong\") }\n\n// GOOD - log the actual error\ndo {\n    let user = try fetchUser(id: userId)\n    display(user)\n} catch {\n    logger.error(\"Failed to fetch user \\(userId): \\(error)\")\n    showError(error.localizedDescription)\n}\n```\n\n### 3. Empty Catch Blocks\n\n```swift\n// BAD - user thinks save succeeded\ndo { try saveDocument() } catch { }\n\n// GOOD - inform user of failure\ndo {\n    try saveDocument()\n    showSuccess(\"Document saved\")\n} catch {\n    showError(\"Failed to save: \\(error.localizedDescription)\")\n}\n```\n\n### 4. Generic Error Messages\n\n```swift\n// BAD - cryptic error display\nenum NetworkError: Error {\n    case requestFailed\n}\n\n// GOOD - LocalizedError with descriptions\nenum NetworkError: LocalizedError {\n    case requestFailed(statusCode: Int)\n\n    var errorDescription: String? {\n        switch self {\n        case .requestFailed(let code):\n            return \"Request failed with status \\(code)\"\n        }\n    }\n}\n```\n\n### 5. Losing Error Context When Wrapping\n\n```swift\n// BAD - original error lost\ncatch { throw ProfileError.loadFailed }\n\n// GOOD - preserve underlying error\nenum ProfileError: LocalizedError {\n    case networkFailed(underlying: Error)\n\n    var errorDescription: String? {\n        switch self {\n        case .networkFailed(let error):\n            return \"Network error: \\(error.localizedDescription)\"\n        }\n    }\n}\n```\n\n### 6. Completion Handler Not Called on All Paths\n\n```swift\n// BAD - completion never called on guard failure\nfunc fetchData(completion: @escaping (Result<Data, Error>) -> Void) {\n    guard let url = buildURL() else { return }  // Bug!\n    // ...\n}\n\n// GOOD - always call completion\nguard let url = buildURL() else {\n    completion(.failure(NetworkError.invalidURL))\n    return\n}\n```\n\n## try, try?, try! Guidelines\n\n| Variant | Use When |\n|---------|----------|\n| `try` | Need to handle specific errors with recovery logic |\n| `try?` | Error details unimportant, just need success/failure |\n| `try!` | Compile-time certainty only: hardcoded URLs, bundled assets |\n\n```swift\n// Acceptable try!\nlet url = URL(string: \"https://api.example.com\")!  // Hardcoded, verified\n\n// Never try! with runtime data\nlet url = URL(string: userInput)!  // CRASH RISK\n```\n\n## Swift 6 Typed Throws\n\n```swift\n// Typed throws - compiler enforces error type\nfunc readFile(at path: String) throws(FileError) -> Data {\n    guard fileExists(path) else { throw .notFound }\n    // ...\n}\n\n// Benefits: self-documenting API, shorthand .case syntax\n// Avoid for: public APIs (locks you into error contract)\n```\n\n## Result Type vs throws\n\n| Use `throws` | Use `Result` |\n|--------------|--------------|\n| Synchronous code | Completion handlers |\n| async/await code | Storing error state |\n| Complex recovery | Delaying handling |\n\n## Review Questions\n\n1. Are all `try!` usages backed by compile-time certainty?\n2. Are errors logged with enough context to diagnose issues?\n3. Do custom errors conform to `LocalizedError`?\n4. Are completion handlers called on every code path?\n5. Is the underlying error preserved when wrapping?\n",
        "skills/swift-code-review/references/observable.md": "# Swift Observation Framework\n\n## Critical Anti-Patterns\n\n### 1. Incorrect @State Initialization\n\n```swift\n// BAD - model recreated on view reconstruction\nstruct ContentView: View {\n    @State private var viewModel = ExpensiveViewModel()  // init() runs repeatedly\n}\n\n// GOOD - initialize at App level\n@main\nstruct MyApp: App {\n    @State private var viewModel = ExpensiveViewModel()\n    var body: some Scene {\n        WindowGroup { ContentView(viewModel: viewModel) }\n    }\n}\n```\n\n### 2. Using @State in Child Views\n\n```swift\n// BAD - child ignores parent's instance changes\nstruct ChildView: View {\n    @State var model: Model  // Wrong! Preserves first instance\n\n    var body: some View { Text(model.name) }\n}\n\n// GOOD - child receives model directly\nstruct ChildView: View {\n    var model: Model  // No wrapper - updates when parent changes\n\n    var body: some View { Text(model.name) }\n}\n```\n\n### 3. Missing @Bindable for Two-Way Bindings\n\n```swift\n// BAD - cannot create binding\nstruct EditView: View {\n    var user: User\n    var body: some View {\n        TextField(\"Name\", text: $user.name)  // Error: cannot find '$user'\n    }\n}\n\n// GOOD - use @Bindable\nstruct EditView: View {\n    @Bindable var user: User\n    var body: some View {\n        TextField(\"Name\", text: $user.name)  // Works\n    }\n}\n```\n\n### 4. Property Wrappers Without @ObservationIgnored\n\n```swift\n// BAD - property wrapper conflicts with @Observable\n@Observable class ViewModel {\n    @Injected var repository: Repository  // Error\n}\n\n// GOOD - exclude from observation\n@Observable class ViewModel {\n    @ObservationIgnored\n    @Injected var repository: Repository\n}\n```\n\n### 5. Nested Objects Not Observable\n\n```swift\n// BAD - nested object changes don't trigger updates\n@Observable class Store {\n    var items: [Item] = []  // Item is regular class\n}\nclass Item { var name: String = \"\" }\n\n// GOOD - nested types also @Observable\n@Observable class Store {\n    var items: [Item] = []\n}\n@Observable class Item { var name: String = \"\" }\n```\n\n### 6. Combining @Environment with @Bindable\n\n```swift\n// BAD - cannot combine property wrappers\nstruct SettingsView: View {\n    @Bindable @Environment(AppSettings.self) var settings  // Error\n}\n\n// GOOD - create local @Bindable\nstruct SettingsView: View {\n    @Environment(AppSettings.self) var settings\n    var body: some View {\n        @Bindable var settings = settings\n        Toggle(\"Dark Mode\", isOn: $settings.darkMode)\n    }\n}\n```\n\n### 7. withObservationTracking willSet Semantics\n\n```swift\n// BAD - onChange gets OLD value\nwithObservationTracking {\n    _ = model.name\n} onChange: {\n    print(model.name)  // Prints old value!\n}\n\n// GOOD - dispatch to get new value\nwithObservationTracking {\n    _ = model.name\n} onChange: {\n    DispatchQueue.main.async {\n        print(model.name)  // Now has new value\n    }\n}\n```\n\n## Migration from ObservableObject\n\n| Before (Combine) | After (Observation) |\n|------------------|---------------------|\n| `class: ObservableObject` | `@Observable class` |\n| `@Published var` | `var` (automatic) |\n| `@StateObject` | `@State` |\n| `@ObservedObject` | Direct property or `@Bindable` |\n| `@EnvironmentObject` | `@Environment(Type.self)` |\n\n## When to Use Each Wrapper\n\n| Wrapper | Use Case |\n|---------|----------|\n| `@State` | View owns/creates the observable |\n| `@Bindable` | Need two-way binding to properties |\n| `@Environment` | Access observable from environment |\n| `@ObservationIgnored` | Exclude from tracking (DI, Combine, timers) |\n\n## Review Questions\n\n1. Is `@State` only used in the view that creates the object?\n2. Are nested observable objects also marked `@Observable`?\n3. Is `@Bindable` used when two-way bindings are needed?\n4. Are property wrappers marked with `@ObservationIgnored`?\n5. Does `init()` have expensive side effects that could repeat?\n",
        "skills/swift-testing-code-review/SKILL.md": "---\nname: swift-testing-code-review\ndescription: Reviews Swift Testing code for proper use of #expect/#require, parameterized tests, async testing, and organization. Use when reviewing .swift files with import Testing, @Test, #expect, @Suite, or confirmation patterns.\n---\n\n# Swift Testing Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| #expect vs #require, expression capture, error testing | [references/expect-macro.md](references/expect-macro.md) |\n| @Test with arguments, traits, zip() pitfalls | [references/parameterized.md](references/parameterized.md) |\n| confirmation, async sequences, completion handlers | [references/async-testing.md](references/async-testing.md) |\n| @Suite, tags, parallel execution, .serialized | [references/organization.md](references/organization.md) |\n\n## Review Checklist\n\n- [ ] Expressions embedded directly in `#expect` (not pre-computed booleans)\n- [ ] `#require` used only for preconditions, `#expect` for assertions\n- [ ] Error tests check specific types (not generic `(any Error).self`)\n- [ ] Parameterized tests with pairs use `zip()` (not Cartesian product)\n- [ ] No logic mirroring implementation in parameterized expected values\n- [ ] Async sequences tested with `confirmation(expectedCount:)`\n- [ ] Completion handlers use `withCheckedContinuation`, not `confirmation`\n- [ ] `.serialized` applied only where necessary (shared resources)\n- [ ] Sibling serialized suites nested under parent if mutually exclusive\n- [ ] No assumption of state persistence between `@Test` functions\n- [ ] Disabled tests have explanations and bug links\n\n## When to Load References\n\n- Reviewing #expect or #require usage -> expect-macro.md\n- Reviewing @Test with arguments or traits -> parameterized.md\n- Reviewing confirmation or async testing -> async-testing.md\n- Reviewing @Suite or test organization -> organization.md\n\n## Review Questions\n\n1. Could pre-computed booleans in `#expect` lose diagnostic context?\n2. Is `#require` stopping tests prematurely instead of revealing all failures?\n3. Are multi-argument parameterized tests creating accidental Cartesian products?\n4. Could `zip()` silently drop test cases due to unequal array lengths?\n5. Are completion handlers incorrectly tested with `confirmation`?\n",
        "skills/swift-testing-code-review/references/async-testing.md": "# Async Testing\n\n## Critical Anti-Patterns\n\n### 1. Using confirmation for Completion Handlers\n\n```swift\n// BAD - Closure exits before callback fires\n@Test func badCallbackTest() async {\n    await confirmation { confirm in\n        networkService.fetch { _ in\n            confirm()  // Never reached in time!\n        }\n    }\n}\n\n// GOOD - Use withCheckedContinuation instead\n@Test func goodCallbackTest() async {\n    await withCheckedContinuation { continuation in\n        networkService.fetch { result in\n            #expect(result.isSuccess)\n            continuation.resume()\n        }\n    }\n}\n```\n\n### 2. Unsafe Counter Variables\n\n```swift\n// BAD - Counter variable causes Swift 6 concurrency error\n@Test func badStreamTest() async {\n    var count = 0  // Unsafe in concurrent context\n    for await _ in generator {\n        count += 1\n    }\n    #expect(count == 10)\n}\n\n// GOOD - Thread-safe confirmation\n@Test func goodStreamTest() async {\n    await confirmation(expectedCount: 10) { confirm in\n        for await _ in generator {\n            confirm()\n        }\n    }\n}\n```\n\n### 3. Tasks Execute Immediately Assumption\n\n```swift\n// BAD - Task hasn't executed yet\n@Test func badTaskTest() {\n    sut.refreshData()  // Creates Task internally\n    #expect(mockRepo.loadCallCount == 1)  // Still 0!\n}\n\n// GOOD - Wait for task completion\n@Test func goodTaskTest() async {\n    mockRepo.stubResponse = .success([])\n    let exp = expectation(description: #function)\n    mockRepo.didLoad = { exp.fulfill() }\n    sut.refreshData()\n    await fulfillment(of: [exp], timeout: 1)\n    #expect(mockRepo.loadCallCount == 1)\n}\n```\n\n### 4. Using sleep() in Tests\n\n```swift\n// BAD - Slow, flaky, arbitrary timing\n@Test func badSleepTest() async throws {\n    startLongOperation()\n    try await Task.sleep(for: .seconds(2))  // Arbitrary delay\n    #expect(operationCompleted)\n}\n\n// GOOD - Use proper async/await or confirmations\n@Test func goodAsyncTest() async throws {\n    let result = try await performOperation()\n    #expect(result.isSuccess)\n}\n```\n\n### 5. Blocking with DispatchSemaphore/DispatchGroup\n\n```swift\n// BAD - Risk of deadlock, especially on main thread\n@Test func badBlockingTest() async {\n    let semaphore = DispatchSemaphore(value: 0)\n    Task {\n        await asyncOperation()\n        semaphore.signal()\n    }\n    semaphore.wait()  // Deadlock risk!\n}\n\n// GOOD - Use structured async/await\n@Test func goodAsyncTest() async {\n    await asyncOperation()\n    #expect(result.isSuccess)\n}\n```\n\n## confirmation API Usage\n\nThe `confirmation` API verifies callbacks/events occur a specific number of times.\n\n```swift\n// Default: expects exactly one confirmation\nawait confirmation { confirm in\n    for await event in eventStream {\n        confirm()\n    }\n}\n\n// Custom count\nawait confirmation(expectedCount: 10) { confirm in\n    for await _ in generator {\n        confirm()\n    }\n}\n\n// Verify something never happens\nawait confirmation(expectedCount: 0) { confirm in\n    // If confirm() is called, test fails\n}\n```\n\n**Critical**: All `confirm()` calls MUST execute before the `confirmation` closure returns (eager evaluation). Unlike XCTest's `XCTestExpectation` with `fulfillment(of:timeout:)`, confirmations do not suspend waiting for future events.\n\nFor completion-handler APIs:\n- **Option A**: Convert to async/await and `await` the async work inside the confirmation closure\n- **Option B**: Use `withCheckedContinuation` (shown in Anti-Pattern #1 above)\n- **Option C**: For callback-style tests that need waiting, use XCTest's `fulfillment(of:timeout:)` instead\n\n## Time Limits\n\n```swift\n// Test-level time limit\n@Test(.timeLimit(.minutes(1)))\nfunc loadNames() async {\n    let viewModel = ViewModel()\n    await viewModel.loadNames()\n    #expect(viewModel.names.isEmpty == false)\n}\n\n// Suite-level (shorter of suite/test wins)\n@Suite(.timeLimit(.minutes(2)))\nstruct NetworkTests {\n    @Test(.timeLimit(.minutes(1)))  // 1 minute wins\n    func fastTest() async { }\n}\n```\n\n## Best Practices\n\n- **Use async/await directly** when available\n- **Use `confirmation`** for async sequences and streams\n- **Use `withCheckedContinuation`** for completion handler APIs\n- **Store Task references** for testing unstructured concurrency\n- **Use `withKnownIssue`** for flaky tests\n- **Use `.timeLimit`** trait for tests with external dependencies\n\n## Review Questions\n\n1. Are completion handlers being tested with `withCheckedContinuation`, not `confirmation`?\n2. Are async sequences tested with `confirmation(expectedCount:)`?\n3. Are mutable counters in concurrent contexts replaced with confirmations?\n4. Are unstructured Tasks being awaited before assertions?\n5. Is `sleep()` being used instead of proper async patterns?\n",
        "skills/swift-testing-code-review/references/expect-macro.md": "# #expect Macro\n\n## Critical Anti-Patterns\n\n### 1. Computing Booleans Outside #expect\n\n```swift\n// BAD - Loses expression capture and diagnostic context\nlet passed = user.age >= 18 && user.hasVerifiedEmail\n#expect(passed)\n// Failure shows: Expectation failed: passed\n\n// GOOD - Full expression capture\n#expect(user.age >= 18, \"User must be adult\")\n#expect(user.hasVerifiedEmail, \"Email verification required\")\n// Failure shows: (user.age  16) >= 18\n```\n\n### 2. Overusing #require Instead of #expect\n\n```swift\n// BAD - Stops at first failure, hides other issues\n@Test func testUserProfile() throws {\n    let user = try #require(fetchUser())\n    try #require(user.name == \"Alice\")  // Stops here if fails\n    try #require(user.isActive)          // Never checked\n}\n\n// GOOD - #require only for preconditions, #expect for assertions\n@Test func testUserProfile() throws {\n    let user = try #require(fetchUser())  // Required to proceed\n    #expect(user.name == \"Alice\")  // Soft check - continues\n    #expect(user.isActive)          // Also checked\n}\n```\n\n### 3. Mixing XCTest and Swift Testing\n\n```swift\n// BAD - Frameworks incompatible\n@Test func testMixedFrameworks() {\n    XCTAssertEqual(value, expected)  // WRONG\n    #expect(otherValue == expected)\n}\n\n// GOOD - Use one framework per test\n@Test func testWithSwiftTesting() {\n    #expect(value == expected)\n    #expect(otherValue == expected)\n}\n```\n\n### 4. Generic Error Testing\n\n```swift\n// BAD - Overly generic, masks specific failures\n#expect(throws: (any Error).self) { try validate(input) }\n\n// GOOD - Specific error case\n#expect(throws: ValidationError.invalidFormat) { try validate(input) }\n\n// GOOD - Custom validation for associated values\n#expect(performing: { try validate(input) }, throws: { error in\n    guard let validationError = error as? ValidationError,\n          validationError.code == 400 else { return false }\n    return true\n})\n```\n\n### 5. Force Unwrap After nil Check\n\n```swift\n// BAD - Assertion followed by force unwrap\n#expect(optionalValue != nil)\nlet value = optionalValue!\n\n// GOOD - Combine unwrap and assertion\nlet value = try #require(optionalValue)\n```\n\n## Best Practices\n\n- **Embed expressions directly** in `#expect` for full diagnostic capture\n- **Use `#expect`** for assertions (soft fail, continues), **`#require`** for preconditions (hard fail, stops)\n- **Include descriptive messages** when failure reason isn't obvious\n- **Test specific error cases** rather than generic `(any Error).self`\n- **Implement `CustomTestStringConvertible`** for complex types to improve failure messages\n\n## Migration from XCTest\n\n| XCTest | Swift Testing |\n|--------|---------------|\n| `XCTAssertTrue(value)` | `#expect(value)` |\n| `XCTAssertFalse(value)` | `#expect(!value)` |\n| `XCTAssertNil(value)` | `#expect(value == nil)` |\n| `XCTAssertNotNil(value)` | `#expect(value != nil)` |\n| `XCTAssertEqual(a, b)` | `#expect(a == b)` |\n| `XCTUnwrap(optional)` | `try #require(optional)` |\n| `XCTFail(message)` | `Issue.record(message)` |\n\n## Review Questions\n\n1. Are expressions embedded directly in `#expect` for full capture?\n2. Is `#require` used only for essential preconditions, not all assertions?\n3. Are error tests checking specific error types, not generic `(any Error).self`?\n4. Do complex types implement `CustomTestStringConvertible`?\n5. Are assertion messages provided when failure reason isn't self-evident?\n",
        "skills/swift-testing-code-review/references/organization.md": "# Test Organization\n\n## Critical Anti-Patterns\n\n### 1. Expecting State Persistence Between Tests\n\n```swift\n// BAD - Each test gets fresh instance, state doesn't persist\n@Suite(.serialized)\nstruct StatefulTests {\n    var value = 0\n\n    @Test mutating func step1() { value = 42 }\n    @Test func step2() { #expect(value == 42) }  // Fails! Fresh instance\n}\n\n// GOOD - Use init() for setup\nstruct Tests {\n    let value: Int\n    init() { value = 42 }\n    @Test func verify() { #expect(value == 42) }\n}\n\n// GOOD - Combine into one test for dependent steps\n@Test func completeFlow() {\n    var value = 0\n    value = 42\n    #expect(value == 42)\n}\n```\n\n### 2. Serializing Everything\n\n```swift\n// BAD - Slow, defeats parallelism\n@Suite(.serialized)\nstruct AllTests {\n    // 200 tests that could run in parallel\n}\n\n// GOOD - Only serialize what needs it\nstruct AllTests {\n    struct FastTests { }  // Parallel by default\n    @Suite(.serialized) struct DatabaseTests { }  // Only these\n}\n```\n\n### 3. Incorrect Nested Serialization\n\n```swift\n// BAD - Suites run in parallel with each other!\n@Suite(.serialized) struct Suite1 { @Test func a() {} }\n@Suite(.serialized) struct Suite2 { @Test func b() {} }\n\n// GOOD - Nested under parent\n@Suite(.serialized) struct DatabaseSuites {\n    @Suite struct Suite1 { @Test func a() {} }\n    @Suite struct Suite2 { @Test func b() {} }  // Waits for Suite1\n}\n```\n\n### 4. Using Static State for Sharing\n\n```swift\n// BAD - Race conditions with parallel tests\nstruct UnsafeTests {\n    static var shared = \"\"\n\n    @Test func create() { Self.shared = \"value\" }\n    @Test func check() { #expect(Self.shared == \"value\") }  // Race!\n}\n\n// GOOD - Fresh instance per test\nfinal class SafeTests {\n    let database: Database\n    init() throws { database = try Database(path: UUID().uuidString) }\n    deinit { try? database.cleanup() }\n\n    @Test func query() { }  // Own database instance\n}\n```\n\n### 5. Silent Test Skip Without Explanation\n\n```swift\n// BAD - No explanation why disabled\n@Test(.disabled())\nfunc flakyTest() {}\n\n// GOOD - Reason and bug link\n@Test(.disabled(\"Waiting for backend fix\"), .bug(\"PROJ-123\"))\nfunc flakyTest() {}\n```\n\n## @Suite Fundamentals\n\nAny type containing `@Test` functions is implicitly a suite. Use explicit `@Suite` for:\n- Display names: `@Suite(\"User Validation Tests\")`\n- Traits: `@Suite(.serialized)`\n- Nested organization\n\n```swift\n@Suite(\"Dessert Tests\")\nstruct DessertTests {\n    @Suite struct WarmDesserts {\n        @Test func applePieCrustLayers() { }\n    }\n    @Suite struct ColdDesserts {\n        @Test func cheesecakeBakingStrategy() { }\n    }\n}\n```\n\n**Supported types**: `struct` (preferred), `class` (for `deinit` teardown), `actor`\n**NOT supported**: `enum` (cannot contain tests directly)\n\n## Tags\n\nDeclare tags as extensions on `Tag`:\n\n```swift\nextension Tag {\n    @Tag static var unitTests: Self\n    @Tag static var integrationTests: Self\n    @Tag static var networking: Self\n}\n```\n\nApply to tests or suites (traits cascade to nested items):\n\n```swift\n@Suite(.tags(.database))\nstruct DatabaseTests {\n    @Test func testInsert() { }  // Inherits .database\n    @Test(.tags(.critical)) func testTransaction() { }  // .database + .critical\n}\n```\n\n## Parallel Execution\n\nSwift Testing runs all tests in parallel by default. Key implications:\n\n- Each `@Test` gets its own fresh suite instance\n- Global/static state causes race conditions\n- Use `.serialized` only when necessary (shared resources, external services)\n\n## Lifecycle\n\n```swift\nfinal class DatabaseServiceTests {\n    let sut: DatabaseService\n    let tempDirectory: URL\n\n    init() throws {  // Setup - runs before EACH test\n        self.tempDirectory = FileManager.default.temporaryDirectory\n            .appendingPathComponent(UUID().uuidString)\n        self.sut = DatabaseService(database: TestDatabase(storageURL: tempDirectory))\n    }\n\n    deinit {  // Teardown - runs after EACH test (requires class)\n        try? FileManager.default.removeItem(at: tempDirectory)\n    }\n}\n```\n\n## Review Questions\n\n1. Are tests assuming state persists between test functions?\n2. Is `.serialized` applied only where necessary, not everywhere?\n3. Are sibling `.serialized` suites nested under a parent if they must be mutually exclusive?\n4. Is static/global state avoided in tests?\n5. Do disabled tests have explanations and bug links?\n",
        "skills/swift-testing-code-review/references/parameterized.md": "# Parameterized Tests\n\n## Critical Anti-Patterns\n\n### 1. Accidental Cartesian Product\n\n```swift\n// BAD - Creates 25 tests (5x5) when you need 5 pairs\n@Test(arguments: [18, 30, 50, 70, 80], [77.0, 73, 65, 61, 55])\nfunc verifyNormalHeartRate(age: Int, bpm: Double) { }\n\n// GOOD - Creates exactly 5 paired tests with zip\n@Test(arguments: zip([18, 30, 50, 70, 80], [77.0, 73, 65, 61, 55]))\nfunc verifyNormalHeartRate(age: Int, bpm: Double) { }\n```\n\n### 2. Logic Mirroring Implementation\n\n```swift\n// BAD - Test logic mirrors implementation, masks bugs\n@Test(arguments: Day.allCases)\nfunc greeting(day: Day) {\n    #expect(greeting(of: day) == \"Happy \\(day.rawValue)!\")\n}\n\n// GOOD - Explicit expected values\n@Test(arguments: [\n    (Day.monday, \"Happy Monday!\"),\n    (Day.tuesday, \"Happy Tuesday!\")\n])\nfunc greeting(day: Day, expected: String) {\n    #expect(greeting(of: day) == expected)\n}\n```\n\n### 3. Silent Drops with zip()\n\n```swift\n// BAD - If arrays have different lengths, extras are silently dropped\n@Test(arguments: zip(Ingredient.allCases, Dish.allCases))\nfunc cook(_ ingredient: Ingredient, into dish: Dish) { }\n// If Ingredient has 5 cases but Dish has 4, one ingredient goes untested!\n\n// GOOD - Explicit array ensures complete coverage\n@Test(arguments: [\n    (Ingredient.rice, Dish.onigiri),\n    (Ingredient.potato, Dish.fries),\n    (Ingredient.tomato, Dish.salad)\n])\nfunc cook(_ ingredient: Ingredient, into dish: Dish) { }\n```\n\n### 4. CaseIterable Order Dependency\n\n```swift\n// BAD - Breaks if enum cases are reordered\n@Test(arguments: zip(Status.allCases, [\"P\", \"A\", \"C\"]))\nfunc statusCode(status: Status, code: String) { }\n\n// GOOD - Explicit mapping immune to reordering\n@Test(arguments: [\n    (Status.pending, \"P\"),\n    (Status.active, \"A\"),\n    (Status.completed, \"C\")\n])\nfunc statusCode(status: Status, code: String) { }\n```\n\n### 5. For-Loops Instead of Parameterized Tests\n\n```swift\n// BAD - Stops at first failure, unclear which value failed\n@Test func doesNotContainNuts() throws {\n    for flavor in [Flavor.vanilla, .chocolate] {\n        try #require(!flavor.containsNuts)\n    }\n}\n\n// GOOD - Each value is independent test case\n@Test(arguments: [Flavor.vanilla, .chocolate])\nfunc doesNotContainNuts(flavor: Flavor) throws {\n    try #require(!flavor.containsNuts)\n}\n```\n\n### 6. Missing .serialized for Shared Resources\n\n```swift\n// BAD - Random failures when server limits connections\n@Test(arguments: [1, 2, 3, 4, 5])\nfunc uploadFile(id: Int) async {\n    await server.upload(fileId: id)\n}\n\n// GOOD - Sequential execution for resource-constrained tests\n@Test(.serialized, arguments: [1, 2, 3, 4, 5])\nfunc uploadFile(id: Int) async {\n    await server.upload(fileId: id)\n}\n```\n\n## Best Practices\n\n- **Use explicit tuple arrays** over `zip(allCases, allCases)` for clarity\n- **Use `zip()`** only when intentionally pairing two sequences\n- **Prefer `#expect`** over `#require` in parameterized tests to see all failures\n- **Implement `CustomTestStringConvertible`** for readable test names\n- **Use `.serialized`** when tests share limited resources\n\n## Available Traits\n\n| Trait | Purpose |\n|-------|---------|\n| `.disabled(_:)` | Skip with explanation |\n| `.disabled(if:_:)` | Conditional skip |\n| `.enabled(if:)` | Execute only when condition met |\n| `.bug(_:)` | Link to bug tracker |\n| `.timeLimit(_:)` | Set max runtime (per test case) |\n| `.serialized` | Force sequential execution |\n| `.tags(_:)` | Classify for selective execution |\n\n## Review Questions\n\n1. Are multi-argument tests using `zip()` for pairs, or accidentally creating Cartesian products?\n2. Do parameterized tests use explicit expected values, or mirror implementation logic?\n3. Could unequal-length `zip()` silently drop test cases?\n4. Are tests that access shared resources using `.serialized`?\n5. Is `CustomTestStringConvertible` implemented for complex parameter types?\n",
        "skills/swiftdata-code-review/SKILL.md": "---\nname: swiftdata-code-review\ndescription: Reviews SwiftData code for model design, queries, concurrency, and migrations. Use when reviewing .swift files with import SwiftData, @Model, @Query, @ModelActor, or VersionedSchema.\n---\n\n# SwiftData Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| @Model, @Attribute, @Relationship, delete rules | [references/model-design.md](references/model-design.md) |\n| @Query, #Predicate, FetchDescriptor, #Index | [references/queries.md](references/queries.md) |\n| @ModelActor, ModelContext, background operations | [references/concurrency.md](references/concurrency.md) |\n| VersionedSchema, MigrationStage, lightweight/custom | [references/migrations.md](references/migrations.md) |\n\n## Review Checklist\n\n- [ ] Models marked `final` (subclassing crashes)\n- [ ] @Relationship decorator on ONE side only (not both)\n- [ ] Delete rules explicitly set (not relying on default .nullify)\n- [ ] Relationships initialized to empty arrays, not default objects\n- [ ] Batch operations used for bulk inserts (`append(contentsOf:)`)\n- [ ] @Query not loading thousands of items on main thread\n- [ ] External values in predicates captured in local variables\n- [ ] Scalar comparisons in predicates (not object references)\n- [ ] @ModelActor used for background operations\n- [ ] PersistentIdentifier/DTOs used to pass data between actors\n- [ ] VersionedSchema defined for each shipped version\n- [ ] MigrationPlan passed to ModelContainer\n\n## When to Load References\n\n- Reviewing @Model or relationships -> model-design.md\n- Reviewing @Query or #Predicate -> queries.md\n- Reviewing @ModelActor or background work -> concurrency.md\n- Reviewing schema changes or migrations -> migrations.md\n\n## Review Questions\n\n1. Could this relationship assignment cause NULL foreign keys?\n2. Is @Relationship on both sides creating circular references?\n3. Could this @Query block the main thread with large datasets?\n4. Are model objects being passed between actors unsafely?\n5. Would schema changes require a migration plan?\n",
        "skills/swiftdata-code-review/references/concurrency.md": "# SwiftData Concurrency\n\n## Best Practices\n\n| Practice | Description |\n|----------|-------------|\n| @ModelActor for background work | Proper thread isolation for SwiftData |\n| PersistentIdentifier for cross-actor | Model objects are NOT Sendable |\n| Sendable DTOs for data exchange | Create separate types for transfer |\n| Task.detached for background | Ensures actor runs off main thread |\n| Explicit `save()` in Task | Autosave may not execute in time |\n| @Query for display, @ModelActor for mutations | Separate concerns |\n\n## @ModelActor Pattern\n\n```swift\n@ModelActor\nactor DataHandler {\n    func importItems(_ data: [ImportData]) throws {\n        for item in data {\n            modelContext.insert(Item(name: item.name))\n        }\n        try modelContext.save()\n    }\n\n    func updateItem(id: PersistentIdentifier, name: String) throws {\n        guard let item = self[id, as: Item.self] else { return }\n        item.name = name\n        try modelContext.save()\n    }\n}\n```\n\n## Sendable DTO Pattern\n\n```swift\nstruct ItemDTO: Sendable, Identifiable {\n    let id: PersistentIdentifier\n    let name: String\n    let timestamp: Date\n}\n\n@ModelActor\nactor DataService {\n    func fetchItems() throws -> [ItemDTO] {\n        try modelContext.fetch(FetchDescriptor<Item>())\n            .map { ItemDTO(id: $0.persistentModelID, name: $0.name, timestamp: $0.timestamp) }\n    }\n}\n```\n\n## Background Actor Creation\n\n```swift\n// GOOD: Ensures background execution\nTask.detached {\n    let handler = DataHandler(modelContainer: container)\n    try await handler.importLargeDataset(data)\n}\n\n// Factory method alternative\n@ModelActor\nactor DataService {\n    static nonisolated func createBackground(container: ModelContainer) async -> DataService {\n        await Task.detached { DataService(modelContainer: container) }.value\n    }\n}\n```\n\n## Critical Anti-Patterns\n\n### Passing Model Objects Between Actors\n\n```swift\n// BAD: Model objects are not Sendable\nfunc getItem(id: UUID) throws -> Item {  // Crash or undefined behavior\n    try modelContext.fetch(...).first!\n}\nlet item = try await dataHandler.getItem(id: someId)\nitem.name = \"New\"  // Wrong thread!\n\n// GOOD: Return DTO or use identifier\nfunc getItemDTO(id: UUID) throws -> ItemDTO { ... }\nfunc updateItem(id: PersistentIdentifier, name: String) throws { ... }\n```\n\n### Creating Actor on Main Thread\n\n```swift\n// BAD: Actor runs on main thread\n@MainActor\nfunc setup() {\n    let handler = DataHandler(modelContainer: container)\n}\n\n// GOOD: Create off main actor\nfunc setup() async {\n    await Task.detached {\n        let handler = DataHandler(modelContainer: container)\n    }.value\n}\n```\n\n### Single Actor Bottleneck\n\n```swift\n// BAD: All operations serialize\nTask { try await sharedHandler.heavyImport1() }\nTask { try await sharedHandler.heavyImport2() }  // Waits for import1!\n\n// GOOD: Separate actors for independent work\nTask.detached {\n    let handler1 = DataHandler(modelContainer: container)\n    try await handler1.heavyImport1()\n}\nTask.detached {\n    let handler2 = DataHandler(modelContainer: container)\n    try await handler2.heavyImport2()\n}\n```\n\n### Modifying After Actor Boundary\n\n```swift\n// BAD: Retaining models from background\nlet items = try await backgroundActor.fetchAllItems()  // [Item]\nitems[0].name = \"Changed\"  // CRASH - wrong context!\n\n// GOOD: Use identifiers to load locally\nlet identifier = try await backgroundActor.getItemIdentifier()\nawait MainActor.run {\n    let item = mainContext.model(for: identifier) as? Item\n    item?.name = \"Changed\"\n}\n```\n\n### Missing @MainActor on Observable\n\n```swift\n// BAD: UI updates may happen off main thread\n@Observable\nclass ViewModel {\n    var items: [Item] = []\n    func load() async {\n        items = await dataService.fetchItems()  // May update from background\n    }\n}\n\n// GOOD: Explicit main actor isolation\n@Observable @MainActor\nclass ViewModel {\n    var items: [Item] = []\n}\n```\n\n## Review Questions\n\n- [ ] Is @ModelActor used for heavy data operations?\n- [ ] Are model objects passed between actors? (They shouldn't be)\n- [ ] Is Task.detached used for background actor creation?\n- [ ] Is explicit `save()` called in Task contexts?\n- [ ] Are ViewModels marked @Observable @MainActor?\n- [ ] Are Sendable DTOs used for cross-actor data?\n- [ ] Could a single actor become a bottleneck?\n- [ ] Are PersistentIdentifiers used for cross-context references?\n",
        "skills/swiftdata-code-review/references/migrations.md": "# SwiftData Migrations\n\n## Best Practices\n\n| Practice | Description |\n|----------|-------------|\n| VersionedSchema from start | Even before shipping, makes future migrations easier |\n| Semantic versioning | `Schema.Version(1, 0, 0)` format |\n| Typealias for latest | `typealias User = UsersSchemaV2.User` |\n| Enums for schema versions | Won't be instantiated directly |\n| Stages for ALL versions | Even lightweight ones |\n| Chronological order | In `SchemaMigrationPlan.schemas` |\n| `@Attribute(originalName:)` | When renaming properties to preserve data |\n| Keep originalName annotation | For future installs from old versions |\n\n## VersionedSchema Setup\n\n```swift\nenum UsersSchemaV1: VersionedSchema {\n    static var versionIdentifier = Schema.Version(1, 0, 0)\n\n    static var models: [any PersistentModel.Type] { [User.self] }\n\n    @Model\n    class User {\n        var name: String\n        init(name: String) { self.name = name }\n    }\n}\n\nenum UsersSchemaV2: VersionedSchema {\n    static var versionIdentifier = Schema.Version(2, 0, 0)\n\n    static var models: [any PersistentModel.Type] { [User.self] }\n\n    @Model\n    class User {\n        @Attribute(originalName: \"name\") var fullName: String  // Renamed\n        @Attribute(.unique) var email: String  // Added\n        init(fullName: String, email: String) { ... }\n    }\n}\n\ntypealias User = UsersSchemaV2.User\n```\n\n## Migration Plan\n\n```swift\nenum UsersMigrationPlan: SchemaMigrationPlan {\n    static var schemas: [any VersionedSchema.Type] {\n        [UsersSchemaV1.self, UsersSchemaV2.self]\n    }\n\n    static var stages: [MigrationStage] { [migrateV1toV2] }\n\n    // Custom: clean duplicates before adding .unique\n    static let migrateV1toV2 = MigrationStage.custom(\n        fromVersion: UsersSchemaV1.self,\n        toVersion: UsersSchemaV2.self,\n        willMigrate: { context in\n            let users = try context.fetch(FetchDescriptor<UsersSchemaV1.User>())\n            var seen = Set<String>()\n            for user in users where seen.contains(user.email) {\n                context.delete(user)\n            }\n            try context.save()\n        },\n        didMigrate: nil\n    )\n\n    // Lightweight: simple changes\n    static let migrateV2toV3 = MigrationStage.lightweight(\n        fromVersion: UsersSchemaV2.self,\n        toVersion: UsersSchemaV3.self\n    )\n}\n```\n\n## ModelContainer Configuration\n\n```swift\nlet container = try ModelContainer(\n    for: User.self,\n    migrationPlan: UsersMigrationPlan.self\n)\n```\n\n## Critical Anti-Patterns\n\n### Renaming Without originalName\n\n```swift\n// BAD: Data LOST\nvar fullName: String  // Was \"name\", no mapping\n\n// GOOD: Data preserved\n@Attribute(originalName: \"name\") var fullName: String\n```\n\n### Adding .unique to Duplicated Data\n\n```swift\n// BAD: Crash if duplicates exist\n@Attribute(.unique) var email: String\n\n// GOOD: Clean duplicates in willMigrate first\nwillMigrate: { context in\n    // Remove duplicates before schema applies .unique\n}\n```\n\n### Custom Migrations with CloudKit\n\n```swift\n// BAD: Crashes with CloudKit\nMigrationStage.custom(willMigrate: { ... }, didMigrate: { ... })\n\n// GOOD: Lightweight only for CloudKit apps\nMigrationStage.lightweight(fromVersion:, toVersion:)\n// Handle complex logic in app initialization\n```\n\n### Wrong Schema in Migration Closure\n\n```swift\n// BAD: V2 not available in willMigrate\nwillMigrate: { context in\n    try context.fetch(FetchDescriptor<SchemaV2.User>())  // WRONG\n}\n\n// GOOD: V1 in willMigrate, V2 in didMigrate\nwillMigrate: { context in\n    try context.fetch(FetchDescriptor<SchemaV1.User>())  // Correct\n}\ndidMigrate: { context in\n    try context.fetch(FetchDescriptor<SchemaV2.User>())  // Correct\n}\n```\n\n### Missing MigrationPlan\n\n```swift\n// BAD: Migration not applied\nlet container = try ModelContainer(for: User.self)\n\n// GOOD: Migration plan specified\nlet container = try ModelContainer(\n    for: User.self,\n    migrationPlan: UsersMigrationPlan.self\n)\n```\n\n## Lightweight vs Custom\n\n**Lightweight migrations support:**\n- Adding properties with default values\n- Renaming with `@Attribute(originalName:)`\n- Deleting properties\n- Adjusting delete rules\n\n**Custom migrations needed for:**\n- Data transformation\n- Deduplication before `.unique`\n- Complex relationship changes\n- Default value calculation from existing data\n\n## Review Questions\n\n- [ ] Is every shipped schema wrapped in VersionedSchema?\n- [ ] Does each schema have a unique versionIdentifier?\n- [ ] Are schemas listed in chronological order?\n- [ ] Is there a MigrationStage for each version transition?\n- [ ] Is MigrationPlan passed to ModelContainer?\n- [ ] Do renamed properties use `@Attribute(originalName:)`?\n- [ ] If adding `.unique`, are duplicates handled in willMigrate?\n- [ ] Does willMigrate only access old schema models?\n- [ ] Is CloudKit enabled? (Custom migrations will crash)\n- [ ] Is `context.save()` called in migration closures?\n",
        "skills/swiftdata-code-review/references/model-design.md": "# SwiftData Model Design\n\n## Best Practices\n\n| Practice | Description |\n|----------|-------------|\n| Mark models `final` | Subclassing causes runtime crashes |\n| Explicit initializers | Required even with default values |\n| `var` for relationships | `let` causes runtime crashes |\n| Avoid `description` property | Reserved word; use `details` or `content` |\n| @Relationship on ONE side | Both sides causes circular reference errors |\n| Explicit delete rules | Don't rely on default `.nullify` |\n| Optional relationships | Non-optional with `.nullify` crashes |\n| Empty array init | `= []` not default objects |\n| Batch operations | `append(contentsOf:)` not individual `append()` |\n\n## @Attribute Options\n\n| Option | When to Use |\n|--------|-------------|\n| `.unique` | Natural identifiers (NOT with CloudKit) |\n| `.externalStorage` | Large binary data (images, files) |\n| `.spotlight` | User-searchable text content |\n| `.transformable` | Custom types needing serialization |\n| `.allowsCloudEncryption` | Sensitive synced data |\n| `.transient` | Computed/cached values |\n\n## Delete Rules\n\n```swift\n@Relationship(deleteRule: .cascade)    // Deletes children (owned relationships)\n@Relationship(deleteRule: .nullify)    // Sets to nil (default, fragile)\n@Relationship(deleteRule: .deny)       // Prevents deletion if children exist\n@Relationship(deleteRule: .noAction)   // Does nothing (dangerous!)\n```\n\n## Critical Anti-Patterns\n\n### Decorating Both Sides of Relationship\n\n```swift\n// BAD: Circular reference error\n@Model class Student {\n    @Relationship(inverse: \\TestResult.student) var testResults: [TestResult]\n}\n@Model class TestResult {\n    @Relationship(inverse: \\Student.testResults) var student: Student?\n}\n\n// GOOD: @Relationship on one side only\n@Model class Student {\n    @Relationship(deleteRule: .cascade, inverse: \\TestResult.student)\n    var testResults: [TestResult] = []\n}\n@Model class TestResult {\n    var student: Student?  // No decorator\n}\n```\n\n### Assignment in Initializer\n\n```swift\n// BAD: Foreign keys become NULL\ninit(floors: [Floor]) {\n    self.floors = floors  // Bypasses tracking!\n}\n\n// GOOD: Use append\ninit(floors: [Floor]) {\n    self.floors.append(contentsOf: floors)\n}\n```\n\n### Default Values for Relationships\n\n```swift\n// BAD: Runtime crash\nvar tag: Tag = Tag(name: \"default\")\n\n// GOOD: Optional or set after insertion\nvar tag: Tag?\n```\n\n### Individual Appends in Loop\n\n```swift\n// BAD: 700x slower than Core Data\nfor i in 0..<1000 {\n    item.tags.append(Tag(name: \"\\(i)\"))\n}\n\n// GOOD: Batch operation\nvar tags = (0..<1000).map { Tag(name: \"\\($0)\") }\nitem.tags.append(contentsOf: tags)\n```\n\n### Arrays for Searchable Data\n\n```swift\n// BAD: Stored as blob, not searchable\nvar tags: [String]\n\n// GOOD: Relationship model\n@Relationship(deleteRule: .cascade) var tags: [Tag] = []\n```\n\n### Unique with CloudKit\n\n```swift\n// BAD: Breaks CloudKit sync\n@Attribute(.unique) var email: String\n\n// GOOD: Handle uniqueness programmatically\nvar email: String\n```\n\n## Review Questions\n\n- [ ] Is the model marked `final`?\n- [ ] Does it have an explicit initializer?\n- [ ] Are relationships `var`, not `let`?\n- [ ] Is @Relationship on only ONE side of bidirectional relationships?\n- [ ] Does delete rule match optionality?\n- [ ] Are relationships initialized to `= []`?\n- [ ] Are batch operations used for bulk additions?\n- [ ] If using CloudKit, are there any `.unique` attributes?\n",
        "skills/swiftdata-code-review/references/queries.md": "# SwiftData Queries\n\n## Best Practices\n\n| Practice | Description |\n|----------|-------------|\n| Local variables for external values | Copy `Date.now` before using in predicate |\n| Compare scalars, not objects | Use `id` (UUID), not object references |\n| Restrictive checks first | Most selective conditions first |\n| `localizedStandardContains()` | Case-insensitive text search |\n| `starts(with:)` | `hasPrefix()` is NOT supported |\n| `fetchCount()` for counts | Never fetch array just for `.count` |\n| `fetchLimit`/`fetchOffset` | Pagination for large datasets |\n| #Index for filtered properties | iOS 18+ performance optimization |\n\n## @Query Patterns\n\n```swift\n// Static query\n@Query var items: [Item]\n\n// Sorted query\n@Query(sort: \\Item.timestamp, order: .reverse) var items: [Item]\n\n// Multi-field sort\n@Query(sort: [SortDescriptor(\\Item.priority, order: .reverse),\n              SortDescriptor(\\Item.name)]) var items: [Item]\n\n// Dynamic filtering in init\ninit(showCompleted: Bool) {\n    let completed = showCompleted  // Capture external value\n    _items = Query(filter: #Predicate<Item> { item in\n        completed || !item.isCompleted\n    })\n}\n```\n\n## FetchDescriptor Patterns\n\n```swift\nvar descriptor = FetchDescriptor<Item>(\n    predicate: #Predicate { $0.createdAt > cutoffDate },\n    sortBy: [SortDescriptor(\\.createdAt, order: .reverse)]\n)\ndescriptor.fetchLimit = 50\ndescriptor.fetchOffset = page * 50\ndescriptor.propertiesToFetch = [\\.id, \\.title]\n\nlet count = try context.fetchCount(descriptor)  // Count without fetching\nlet items = try context.fetch(descriptor)\n```\n\n## #Index (iOS 18+)\n\n```swift\n@Model final class Order {\n    #Index<Order>(\n        [\\.status],              // Filter by status\n        [\\.createdAt],           // Sort by date\n        [\\.status, \\.createdAt]  // Compound index\n    )\n    var status: String\n    var createdAt: Date\n}\n```\n\n## Critical Anti-Patterns\n\n### External Values Directly in @Query\n\n```swift\n// BAD: Date.now evaluated at macro expansion\n@Query(filter: #Predicate<Event> { $0.date > Date.now })\nvar events: [Event]\n\n// GOOD: Capture in local variable\nstatic var now: Date { Date.now }\n@Query(filter: #Predicate<Event> { $0.date > now })\nvar events: [Event]\n```\n\n### Object Comparison in Predicate\n\n```swift\n// BAD: Runtime crash\nlet predicate = #Predicate<Post> { $0.author == selectedUser }\n\n// GOOD: Compare identifier\nlet userId = selectedUser.id\nlet predicate = #Predicate<Post> { $0.author.id == userId }\n```\n\n### Unsupported String Methods\n\n```swift\n// BAD: These crash\nitem.name.hasPrefix(\"A\")     // Use starts(with:)\nitem.name.hasSuffix(\"z\")     // Not supported\nitem.name.uppercased()       // Not translatable\n\n// GOOD: Supported methods\nitem.name.starts(with: \"A\")\nitem.name.localizedStandardContains(\"test\")\n```\n\n### Wrong Boolean Comparison\n\n```swift\n// BAD: Runtime crash\n#Predicate<Movie> { $0.cast.isEmpty == false }\n\n// GOOD: Negation operator\n#Predicate<Movie> { !$0.cast.isEmpty }\n```\n\n### Fetching Just to Count\n\n```swift\n// BAD: Loads all objects into memory\nlet count = try context.fetch(FetchDescriptor<Item>()).count\n\n// GOOD: Dedicated count method\nlet count = try context.fetchCount(FetchDescriptor<Item>())\n```\n\n### Heavy @Query on Main Thread\n\n```swift\n// BAD: Freezes UI\n@Query var allPhotos: [Photo]  // 10,000+ items\n\n// GOOD: Pagination in view model\nvar descriptor = FetchDescriptor<Photo>()\ndescriptor.fetchLimit = 50\ndescriptor.fetchOffset = offset\n```\n\n## Review Questions\n\n- [ ] Is @Query loading only what the view needs?\n- [ ] Are external values captured in local variables?\n- [ ] Are comparisons using scalars, not object references?\n- [ ] Are string methods limited to supported ones?\n- [ ] Is `!isEmpty` used instead of `isEmpty == false`?\n- [ ] Is `fetchCount()` used instead of fetching for counts?\n- [ ] Are `fetchLimit`/`fetchOffset` used for pagination?\n- [ ] Are frequently filtered properties indexed (iOS 18+)?\n",
        "skills/swiftui-code-review/SKILL.md": "---\nname: swiftui-code-review\ndescription: Reviews SwiftUI code for view composition, state management, performance, and accessibility. Use when reviewing .swift files containing SwiftUI views, property wrappers (@State, @Binding, @Observable), or UI code.\n---\n\n# SwiftUI Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| View extraction, modifiers, body complexity | [references/view-composition.md](references/view-composition.md) |\n| @State, @Binding, @Observable, @Bindable | [references/state-management.md](references/state-management.md) |\n| LazyStacks, AnyView, ForEach, identity | [references/performance.md](references/performance.md) |\n| VoiceOver, Dynamic Type, labels, traits | [references/accessibility.md](references/accessibility.md) |\n\n## Review Checklist\n\n- [ ] View body under 10 composed elements (extract subviews)\n- [ ] Modifiers in correct order (padding before background)\n- [ ] @StateObject for view-owned objects, @ObservedObject for passed objects\n- [ ] @Bindable used for two-way bindings to @Observable (iOS 17+)\n- [ ] LazyVStack/LazyHStack for scrolling lists with 50+ items\n- [ ] No AnyView (use @ViewBuilder or generics instead)\n- [ ] ForEach uses stable Identifiable IDs (not array indices)\n- [ ] All images/icons have accessibilityLabel\n- [ ] Custom controls have accessibilityAddTraits(.isButton)\n- [ ] Dynamic Type supported (no fixed font sizes)\n- [ ] .task modifier for async work (not onAppear + Task)\n\n## When to Load References\n\n- Complex view bodies or modifier chains -> view-composition.md\n- Property wrapper usage (@State, @Observable) -> state-management.md\n- List performance or view identity issues -> performance.md\n- VoiceOver or accessibility implementation -> accessibility.md\n\n## Review Questions\n\n1. Could this large view body be split into smaller, reusable Views?\n2. Is modifier order intentional? (padding -> background -> frame)\n3. Is @StateObject/@ObservedObject usage correct for ownership?\n4. Could LazyVStack improve this ScrollView's performance?\n5. Would VoiceOver users understand this interface?\n",
        "skills/swiftui-code-review/references/accessibility.md": "# Accessibility\n\n## Accessibility Labels\n\nAll interactive elements need descriptive labels.\n\n```swift\n// BAD - VoiceOver says \"heart\"\nButton(action: { addToFavorites() }) {\n    Image(systemName: \"heart\")\n}\n\n// GOOD - VoiceOver says \"Add to favorites\"\nButton(action: { addToFavorites() }) {\n    Image(systemName: \"heart\")\n}\n.accessibilityLabel(\"Add to favorites\")\n.accessibilityHint(\"Double tap to add to your favorites\")\n```\n\n## Decorative Images\n\nHide non-informative images from VoiceOver.\n\n```swift\n// BAD - VoiceOver reads \"star fill\"\nHStack {\n    Image(systemName: \"star.fill\")\n    Text(\"Premium Feature\")\n}\n\n// GOOD - decorative image hidden\nHStack {\n    Image(decorative: \"star.fill\")\n    Text(\"Premium Feature\")\n}\n\n// Alternative\nImage(systemName: \"star.fill\")\n    .accessibilityHidden(true)\n```\n\n## Custom Control Traits\n\nCustom interactive views need accessibility traits.\n\n```swift\n// BAD - VoiceOver doesn't know it's tappable\nstruct CustomCheckbox: View {\n    @Binding var isChecked: Bool\n    var body: some View {\n        Image(systemName: isChecked ? \"checkmark.square\" : \"square\")\n            .onTapGesture { isChecked.toggle() }\n    }\n}\n\n// GOOD - proper accessibility\nstruct CustomCheckbox: View {\n    @Binding var isChecked: Bool\n    var body: some View {\n        Image(systemName: isChecked ? \"checkmark.square\" : \"square\")\n            .onTapGesture { isChecked.toggle() }\n            .accessibilityLabel(\"Agreement\")\n            .accessibilityAddTraits(.isButton)\n            .accessibilityAddTraits(isChecked ? .isSelected : [])\n            .accessibilityValue(isChecked ? \"Checked\" : \"Unchecked\")\n    }\n}\n```\n\n## Common Traits\n\n| Trait | Use Case |\n|-------|----------|\n| `.isButton` | Custom tappable views |\n| `.isHeader` | Section headers |\n| `.isSelected` | Current selection state |\n| `.isLink` | External navigation |\n\n## Grouping Elements\n\nCombine related elements for VoiceOver.\n\n```swift\n// BAD - read separately\nVStack {\n    Text(\"John Doe\")\n    Text(\"Senior Developer\")\n    Text(\"San Francisco\")\n}\n\n// GOOD - single announcement\nVStack {\n    Text(\"John Doe\")\n    Text(\"Senior Developer\")\n    Text(\"San Francisco\")\n}\n.accessibilityElement(children: .combine)\n```\n\n## Dynamic Type\n\nUse semantic fonts, not fixed sizes.\n\n```swift\n// BAD - ignores user preference\nText(\"Settings\")\n    .font(.system(size: 17))\n\n// GOOD - scales with preference\nText(\"Settings\")\n    .font(.body)\n```\n\n## Environment Properties\n\nCheck accessibility settings.\n\n```swift\n@Environment(\\.accessibilityReduceMotion) var reduceMotion\n@Environment(\\.accessibilityDifferentiateWithoutColor) var noColor\n@Environment(\\.dynamicTypeSize) var typeSize\n```\n\n## Critical Anti-Patterns\n\n| Pattern | Issue |\n|---------|-------|\n| Interactive element without label | VoiceOver can't describe it |\n| Decorative image not hidden | Clutters VoiceOver reading |\n| Custom control without traits | VoiceOver doesn't indicate interactivity |\n| Fixed font sizes | Ignores Dynamic Type |\n| Color-only information | Excludes color blind users |\n| Touch target < 44pt | Hard to tap |\n\n## Review Questions\n\n1. Do all interactive elements have accessibilityLabel?\n2. Are decorative images hidden from VoiceOver?\n3. Do custom controls have proper accessibility traits?\n4. Are related UI elements grouped for VoiceOver?\n5. Does the UI support Dynamic Type (no fixed font sizes)?\n6. Is color paired with other indicators (shape, text, icon)?\n",
        "skills/swiftui-code-review/references/performance.md": "# Performance\n\n## Lazy Stacks\n\nUse LazyVStack/LazyHStack for scrolling content with many items.\n\n```swift\n// BAD - all 1000 items rendered immediately\nScrollView {\n    VStack {\n        ForEach(items) { ItemView(item: $0) }\n    }\n}\n\n// GOOD - only visible items rendered\nScrollView {\n    LazyVStack {\n        ForEach(items) { ItemView(item: $0) }\n    }\n}\n```\n\n## AnyView Avoidance\n\nAnyView defeats SwiftUI's type-based diffing.\n\n```swift\n// BAD - SwiftUI can't diff\nfunc makeView(type: ViewType) -> some View {\n    switch type {\n    case .a: return AnyView(ViewA())\n    case .b: return AnyView(ViewB())\n    }\n}\n\n// GOOD - preserves type information\n@ViewBuilder\nfunc makeView(type: ViewType) -> some View {\n    switch type {\n    case .a: ViewA()\n    case .b: ViewB()\n    }\n}\n```\n\n## ForEach Identity\n\nUse stable Identifiable IDs, never array indices.\n\n```swift\n// BAD - index changes when array changes\nForEach(items.indices, id: \\.self) { index in\n    ItemView(item: items[index])\n}\n\n// GOOD - stable ID from Identifiable\nForEach(items) { item in\n    ItemView(item: item)\n}\n\n// BAD - dynamic range without id\n@State var count = 5\nList(0..<count) { i in Text(\"Row \\(i)\") }  // Crashes!\n\n// GOOD - dynamic range with id\nList(0..<count, id: \\.self) { i in Text(\"Row \\(i)\") }\n```\n\n## Equatable Views\n\nFor complex views, implement Equatable to optimize diffing.\n\n```swift\nstruct CalendarView: View, Equatable {\n    let events: [Event]\n    let selectedDate: Date\n\n    static func == (lhs: Self, rhs: Self) -> Bool {\n        lhs.events.count == rhs.events.count &&\n        lhs.selectedDate == rhs.selectedDate\n    }\n\n    var body: some View { /* expensive */ }\n}\n\n// Usage\nParentView()\n    .equatable()\n```\n\n## View Body Efficiency\n\nAvoid expensive operations in view body.\n\n```swift\n// BAD - formatter created on every rebuild\nvar body: some View {\n    let formatter = DateFormatter()\n    formatter.dateStyle = .long\n    return Text(formatter.string(from: date))\n}\n\n// GOOD - cached formatter\nprivate static let formatter: DateFormatter = {\n    let f = DateFormatter()\n    f.dateStyle = .long\n    return f\n}()\n```\n\n## Expensive Visual Effects\n\nBlur, shadow, and mask cause offscreen rendering.\n\n```swift\n// CAUTION - expensive in lists\nForEach(items) { item in\n    ItemView(item: item)\n        .blur(radius: 5)      // Expensive\n        .shadow(radius: 10)   // Expensive\n}\n```\n\n## Critical Anti-Patterns\n\n| Pattern | Issue |\n|---------|-------|\n| VStack in ScrollView with 100+ items | All items rendered at once |\n| AnyView | Defeats type-based diffing |\n| ForEach with array index as id | View recreation on array change |\n| .id() modifier inside List | Prevents List optimization |\n| DateFormatter in view body | Recreated on every rebuild |\n\n## Review Questions\n\n1. Should this VStack/HStack be Lazy for scrolling performance?\n2. Is AnyView used? Can @ViewBuilder replace it?\n3. Does ForEach use stable Identifiable IDs?\n4. Are expensive computations cached outside view body?\n5. Are visual effects (blur, shadow) used sparingly in lists?\n",
        "skills/swiftui-code-review/references/state-management.md": "# State Management\n\n## Property Wrapper Quick Reference\n\n| iOS Version | View Creates Object | View Receives Object | Two-Way Binding |\n|-------------|---------------------|---------------------|-----------------|\n| < iOS 17 | `@StateObject` | `@ObservedObject` | `@Binding` |\n| iOS 17+ | `@State` (for @Observable) | Plain property | `@Bindable` |\n\n## @StateObject vs @ObservedObject\n\nUse @StateObject when the view creates and owns the object. Use @ObservedObject when passed from a parent.\n\n```swift\n// BAD - recreated on every view rebuild\nstruct ContentView: View {\n    @ObservedObject var viewModel = ViewModel()  // Wrong!\n}\n\n// GOOD - survives view rebuilds\nstruct ContentView: View {\n    @StateObject var viewModel = ViewModel()\n}\n\n// GOOD - received from parent\nstruct ChildView: View {\n    @ObservedObject var viewModel: ViewModel  // Not creating it\n}\n```\n\n## iOS 17+ @Observable Pattern\n\nWith @Observable, use @State at app level, plain properties in children.\n\n```swift\n@Observable class AppStore { /* ... */ }\n\n@main\nstruct MyApp: App {\n    @State private var store = AppStore()\n    var body: some Scene {\n        WindowGroup { ContentView(store: store) }\n    }\n}\n\n// Child receives without wrapper\nstruct ChildView: View {\n    var store: AppStore  // Read-only access\n}\n\n// For two-way bindings, use @Bindable\nstruct EditView: View {\n    @Bindable var user: User\n    var body: some View {\n        TextField(\"Name\", text: $user.name)\n    }\n}\n```\n\n## @State Mistakes\n\n```swift\n// BAD - @State ignores external updates\nstruct ChildView: View {\n    @State var user: User  // Updates from parent ignored!\n}\n\n// BAD - property observers don't work\n@State var count = 0 {\n    didSet { print(\"Changed\") }  // Never called!\n}\n\n// GOOD - use .onChange modifier\n.onChange(of: count) { oldValue, newValue in\n    print(\"Changed from \\(oldValue) to \\(newValue)\")\n}\n```\n\n## Environment Usage (iOS 17+)\n\n```swift\n// Old syntax\n@Environment(\\.modelContext) private var context\n\n// New syntax for custom types\n@Environment(AuthService.self) private var authService\n```\n\n## Critical Anti-Patterns\n\n| Pattern | Issue |\n|---------|-------|\n| `@ObservedObject var vm = ViewModel()` | Creates new object on rebuild |\n| `@State var model: SomeClass` | Reference types need @StateObject |\n| `@State` in child for passed data | Ignores parent updates |\n| didSet on @State | Property observers don't fire |\n| Missing @Bindable for bindings | Can't bind to @Observable properties |\n\n## Review Questions\n\n1. Is @StateObject used when the view creates the object?\n2. Is @ObservedObject only used for objects passed from parent?\n3. For iOS 17+, is @State with @Observable in a stable parent view?\n4. Is @Bindable used where two-way bindings are needed?\n5. Is .onChange used instead of didSet on @State?\n",
        "skills/swiftui-code-review/references/view-composition.md": "# View Composition\n\n## View Body Complexity\n\nKeep view bodies under 10 composed elements. Extract subviews when bodies grow large.\n\n```swift\n// BAD - massive body\nstruct ProductView: View {\n    let product: Product\n\n    var body: some View {\n        VStack {\n            // 50+ lines of inline views\n        }\n    }\n}\n\n// GOOD - extracted subviews\nstruct ProductView: View {\n    let product: Product\n\n    var body: some View {\n        VStack {\n            PriceSection(price: product.price)\n            DetailsSection(description: product.description)\n        }\n    }\n}\n```\n\n## Computed Property Views\n\nAvoid computed property views - they prevent SwiftUI diffing.\n\n```swift\n// BAD - can't be diffed\nvar priceSection: some View {\n    VStack { /* content */ }\n}\n\n// GOOD - proper View struct enables diffing\nstruct PriceSection: View {\n    let price: Decimal\n    var body: some View { /* content */ }\n}\n```\n\n## Modifier Ordering\n\nModifiers apply in order. Common patterns:\n\n```swift\n// BAD - background only covers text\nText(\"Hello\")\n    .background(.blue)\n    .padding()\n\n// GOOD - background covers padded area\nText(\"Hello\")\n    .padding()\n    .background(.blue)\n\n// BAD - shadow clipped away\nRoundedRectangle()\n    .shadow(radius: 5)\n    .clipShape(Circle())\n\n// GOOD - shadow visible\nRoundedRectangle()\n    .clipShape(Circle())\n    .shadow(radius: 5)\n```\n\n## Subview Parameters\n\nPass simple parameters, not domain models, for reusability.\n\n```swift\n// BAD - coupled to model\nstruct PriceLabel: View {\n    let product: Product  // Tightly coupled\n}\n\n// GOOD - model-agnostic\nstruct PriceLabel: View {\n    let price: Decimal\n    let discount: Decimal?\n}\n```\n\n## Critical Anti-Patterns\n\n| Pattern | Issue |\n|---------|-------|\n| `var section: some View {}` | Computed views prevent diffing |\n| Body over 10 composed elements | Hard to maintain and test |\n| `.background().padding()` | Wrong modifier order |\n| Inline closures with complex logic | Extract to methods or views |\n\n## Review Questions\n\n1. Could this view body be split into smaller View structs?\n2. Are there computed property views that should be View structs?\n3. Is the modifier order intentional and correct?\n4. Are subviews model-agnostic and reusable?\n",
        "skills/tailwind-v4/SKILL.md": "---\nname: tailwind-v4\ndescription: Tailwind CSS v4 with CSS-first configuration and design tokens. Use when setting up Tailwind v4, defining theme variables, using OKLCH colors, or configuring dark mode. Triggers on @theme, @tailwindcss/vite, oklch, CSS variables, --color-, tailwind v4.\n---\n\n# Tailwind CSS v4 Best Practices\n\n## Quick Reference\n\n**Vite Plugin Setup**:\n```ts\n// vite.config.ts\nimport tailwindcss from '@tailwindcss/vite';\nimport { defineConfig } from 'vite';\n\nexport default defineConfig({\n  plugins: [tailwindcss()],\n});\n```\n\n**CSS Entry Point**:\n```css\n/* src/index.css */\n@import 'tailwindcss';\n```\n\n**@theme Inline Directive**:\n```css\n@theme inline {\n  --color-primary: oklch(60% 0.24 262);\n  --color-surface: oklch(98% 0.002 247);\n}\n```\n\n## Key Differences from v3\n\n| Feature | v3 | v4 |\n|---------|----|----|\n| Configuration | tailwind.config.js | @theme in CSS |\n| Build Tool | PostCSS plugin | @tailwindcss/vite |\n| Colors | rgb() / hsl() | oklch() (default) |\n| Theme Extension | extend: {} in JS | CSS variables |\n| Dark Mode | darkMode config option | CSS variants |\n\n## @theme Directive Modes\n\n### default (standard mode)\nGenerates CSS variables that can be referenced elsewhere:\n```css\n@theme {\n  --color-brand: oklch(60% 0.24 262);\n}\n\n/* Generates: :root { --color-brand: oklch(...); } */\n/* Usage: text-brand  color: var(--color-brand) */\n```\n\n**Note**: You can also use `@theme default` explicitly to mark theme values that can be overridden by non-default @theme declarations.\n\n### inline\nInlines values directly without CSS variables (better performance):\n```css\n@theme inline {\n  --color-brand: oklch(60% 0.24 262);\n}\n\n/* Usage: text-brand  color: oklch(60% 0.24 262) */\n```\n\n### reference\nInlines values as fallbacks without emitting CSS variables:\n```css\n@theme reference {\n  --color-internal: oklch(50% 0.1 180);\n}\n\n/* No :root variable, but utilities use fallback */\n/* Usage: bg-internal  background-color: var(--color-internal, oklch(50% 0.1 180)) */\n```\n\n## OKLCH Color Format\n\nOKLCH provides perceptually uniform colors with better consistency across hues:\n\n```css\noklch(L% C H)\n```\n\n- **L (Lightness)**: 0% (black) to 100% (white)\n- **C (Chroma)**: 0 (gray) to ~0.4 (vibrant)\n- **H (Hue)**: 0-360 degrees (red  yellow  green  blue  magenta)\n\n**Examples**:\n```css\n--color-sky-500: oklch(68.5% 0.169 237.323);  /* Bright blue */\n--color-red-600: oklch(57.7% 0.245 27.325);   /* Vibrant red */\n--color-zinc-900: oklch(21% 0.006 285.885);   /* Near-black gray */\n```\n\n## CSS Variable Naming\n\nTailwind v4 uses double-dash CSS variable naming conventions:\n\n```css\n@theme {\n  /* Colors: --color-{name}-{shade} */\n  --color-primary-500: oklch(60% 0.24 262);\n\n  /* Spacing: --spacing multiplier */\n  --spacing: 0.25rem;  /* Base unit for spacing scale */\n\n  /* Fonts: --font-{family} */\n  --font-display: 'Inter Variable', system-ui, sans-serif;\n\n  /* Breakpoints: --breakpoint-{size} */\n  --breakpoint-lg: 64rem;\n\n  /* Custom animations: --animate-{name} */\n  --animate-fade-in: fade-in 0.3s ease-out;\n}\n```\n\n## No Config Files Needed\n\nTailwind v4 eliminates configuration files:\n\n- **No `tailwind.config.js`** - Use @theme in CSS instead\n- **No `postcss.config.js`** - Use @tailwindcss/vite plugin\n- **TypeScript support** - Add `@types/node` for path resolution\n\n```json\n{\n  \"devDependencies\": {\n    \"@tailwindcss/vite\": \"^4.0.0\",\n    \"@types/node\": \"^22.0.0\",\n    \"tailwindcss\": \"^4.0.0\",\n    \"vite\": \"^6.0.0\"\n  }\n}\n```\n\n## Progressive Disclosure\n\n- **Setup & Installation**: See [references/setup.md](references/setup.md) for Vite plugin configuration, package setup, TypeScript config\n- **Theming & Design Tokens**: See [references/theming.md](references/theming.md) for @theme modes, color palettes, custom fonts, animations\n- **Dark Mode Strategies**: See [references/dark-mode.md](references/dark-mode.md) for media queries, class-based, attribute-based approaches\n\n## Decision Guide\n\n### When to use @theme inline vs default\n\n**Use `@theme inline`**:\n- Better performance (no CSS variable overhead)\n- Static color values that won't change\n- Animation keyframes with multiple values\n- Utilities that need direct value inlining\n\n**Use `@theme` (default)**:\n- Dynamic theming with JavaScript\n- CSS variable references in custom CSS\n- Values that change based on context\n- Better debugging (inspect CSS variables in DevTools)\n\n### When to use @theme reference\n\n**Use `@theme reference`**:\n- Provide fallback values without CSS variable overhead\n- Values that should work even if variable isn't defined\n- Reducing :root bloat while maintaining utility support\n- Combining with inline for direct value substitution\n\n## Common Patterns\n\n### Two-Tier Variable System\n\nSemantic variables that map to design tokens:\n\n```css\n@theme {\n  /* Design tokens (OKLCH colors) */\n  --color-blue-600: oklch(54.6% 0.245 262.881);\n  --color-slate-800: oklch(27.9% 0.041 260.031);\n\n  /* Semantic mappings */\n  --color-primary: var(--color-blue-600);\n  --color-surface: var(--color-slate-800);\n}\n\n/* Usage: bg-primary, bg-surface */\n```\n\n### Custom Font Configuration\n\n```css\n@theme {\n  --font-display: 'Inter Variable', system-ui, sans-serif;\n  --font-mono: 'JetBrains Mono', ui-monospace, monospace;\n\n  --font-display--font-variation-settings: 'wght' 400;\n  --font-display--font-feature-settings: 'cv02', 'cv03', 'cv04';\n}\n\n/* Usage: font-display, font-mono */\n```\n\n### Animation Keyframes\n\n```css\n@theme inline {\n  --animate-beacon: beacon 2s ease-in-out infinite;\n\n  @keyframes beacon {\n    0%, 100% {\n      opacity: 1;\n      transform: scale(1);\n    }\n    50% {\n      opacity: 0.5;\n      transform: scale(1.05);\n    }\n  }\n}\n\n/* Usage: animate-beacon */\n```\n",
        "skills/tailwind-v4/references/dark-mode.md": "# Dark Mode Strategies\n\n## Contents\n\n- [Media Query Strategy](#media-query-strategy)\n- [Class-Based Strategy](#class-based-strategy)\n- [Attribute-Based Strategy](#attribute-based-strategy)\n- [Theme Switching Implementation](#theme-switching-implementation)\n- [Respecting User Preferences](#respecting-user-preferences)\n\n---\n\n## Media Query Strategy\n\nUse the system preference for dark mode detection.\n\n### Configuration\n\n**Default behavior** (v4):\n```css\n/* No configuration needed - dark: variant works by default */\n@import 'tailwindcss';\n```\n\n**Generated CSS**:\n```css\n@media (prefers-color-scheme: dark) {\n  .dark\\:bg-slate-900 {\n    background-color: oklch(20.8% 0.042 265.755);\n  }\n}\n```\n\n### Usage\n\n```tsx\nexport function Card({ children }: { children: React.ReactNode }) {\n  return (\n    <div className=\"bg-white dark:bg-slate-900 text-slate-900 dark:text-slate-50\">\n      {children}\n    </div>\n  );\n}\n```\n\n### Pros & Cons\n\n**Pros**:\n- Respects system preference automatically\n- No JavaScript needed\n- Simple implementation\n- No FOUC (flash of unstyled content)\n\n**Cons**:\n- Users can't override system preference\n- No manual toggle control\n- Changes when system setting changes\n\n### When to Use\n\n- Documentation sites\n- Content-focused websites\n- Apps where system preference is preferred\n- No need for manual theme switching\n\n## Class-Based Strategy\n\nToggle dark mode with a `.dark` class on the root element.\n\n### Configuration\n\n**Pure v4 approach**: Use a v3 config file with darkMode setting:\n\n```js\n// tailwind.config.js (for v3 compatibility)\nmodule.exports = {\n  darkMode: 'class',  // or 'selector' (same as 'class')\n};\n```\n\n**Note**: In pure v4, the default `dark:` variant uses media queries (`prefers-color-scheme: dark`). To use class-based dark mode, you need to either:\n1. Use a v3 config file with `darkMode: 'class'` (shown above)\n2. Use `@import \"tailwindcss/compat\"` and provide a config\n3. Define a custom variant with `@custom-variant`\n\n### Generated CSS\n\n```css\n.dark .dark\\:bg-slate-900 {\n  background-color: oklch(20.8% 0.042 265.755);\n}\n```\n\n### Usage\n\n```tsx\nexport function App() {\n  const [isDark, setIsDark] = useState(false);\n\n  useEffect(() => {\n    if (isDark) {\n      document.documentElement.classList.add('dark');\n    } else {\n      document.documentElement.classList.remove('dark');\n    }\n  }, [isDark]);\n\n  return (\n    <div className=\"bg-white dark:bg-slate-900\">\n      <button onClick={() => setIsDark(!isDark)}>\n        Toggle Theme\n      </button>\n    </div>\n  );\n}\n```\n\n### Pros & Cons\n\n**Pros**:\n- Full JavaScript control\n- User can override system preference\n- Easy to implement manual toggle\n- Widely supported pattern\n\n**Cons**:\n- Requires JavaScript\n- Potential FOUC without SSR handling\n- Class management overhead\n\n### When to Use\n\n- Applications with theme toggle\n- User preference override needed\n- Dashboard/admin interfaces\n- Apps with per-user theme settings\n\n## Attribute-Based Strategy\n\nUse a `data-theme` attribute for more semantic theming.\n\n### Configuration (v3 compat)\n\n```js\n// tailwind.config.js (v3 compat mode)\nmodule.exports = {\n  darkMode: ['class', '[data-theme=\"dark\"]'],\n};\n```\n\n### Generated CSS\n\n```css\n[data-theme=\"dark\"] .dark\\:bg-slate-900 {\n  background-color: oklch(20.8% 0.042 265.755);\n}\n```\n\n### Usage\n\n```tsx\nexport function App() {\n  const [theme, setTheme] = useState<'light' | 'dark'>('light');\n\n  useEffect(() => {\n    document.documentElement.setAttribute('data-theme', theme);\n  }, [theme]);\n\n  return (\n    <div className=\"bg-white dark:bg-slate-900\">\n      <button onClick={() => setTheme(theme === 'dark' ? 'light' : 'dark')}>\n        Toggle Theme\n      </button>\n    </div>\n  );\n}\n```\n\n### Multiple Themes\n\nExtend beyond light/dark with multiple theme attributes:\n\n```tsx\ntype Theme = 'light' | 'dark' | 'aviation' | 'high-contrast';\n\nexport function App() {\n  const [theme, setTheme] = useState<Theme>('light');\n\n  useEffect(() => {\n    document.documentElement.setAttribute('data-theme', theme);\n  }, [theme]);\n\n  return (\n    <div className=\"bg-white dark:bg-slate-900 [&[data-theme='aviation']]:bg-blue-950\">\n      <select value={theme} onChange={(e) => setTheme(e.target.value as Theme)}>\n        <option value=\"light\">Light</option>\n        <option value=\"dark\">Dark</option>\n        <option value=\"aviation\">Aviation</option>\n        <option value=\"high-contrast\">High Contrast</option>\n      </select>\n    </div>\n  );\n}\n```\n\n### Pros & Cons\n\n**Pros**:\n- Semantic HTML attribute\n- Supports multiple themes (not just light/dark)\n- Easy to inspect in DevTools\n- Clear intent\n\n**Cons**:\n- Requires JavaScript\n- More verbose selector in CSS\n- Less common pattern\n\n### When to Use\n\n- Multi-theme applications\n- Semantic HTML preferences\n- Complex theming systems\n- Better DevTools debugging\n\n## Theme Switching Implementation\n\nComplete implementation with persistence and SSR support.\n\n### React Hook\n\n```tsx\n// hooks/use-theme.ts\nimport { useEffect, useState } from 'react';\n\ntype Theme = 'light' | 'dark' | 'system';\n\nexport function useTheme() {\n  const [theme, setTheme] = useState<Theme>(() => {\n    if (typeof window === 'undefined') return 'system';\n    return (localStorage.getItem('theme') as Theme) || 'system';\n  });\n\n  useEffect(() => {\n    const root = document.documentElement;\n    const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches\n      ? 'dark'\n      : 'light';\n\n    const effectiveTheme = theme === 'system' ? systemTheme : theme;\n\n    root.classList.remove('light', 'dark');\n    root.classList.add(effectiveTheme);\n\n    localStorage.setItem('theme', theme);\n  }, [theme]);\n\n  // Listen for system theme changes\n  useEffect(() => {\n    if (theme !== 'system') return;\n\n    const mediaQuery = window.matchMedia('(prefers-color-scheme: dark)');\n    const handleChange = () => {\n      const systemTheme = mediaQuery.matches ? 'dark' : 'light';\n      document.documentElement.classList.remove('light', 'dark');\n      document.documentElement.classList.add(systemTheme);\n    };\n\n    mediaQuery.addEventListener('change', handleChange);\n    return () => mediaQuery.removeEventListener('change', handleChange);\n  }, [theme]);\n\n  return { theme, setTheme };\n}\n```\n\n### Theme Provider Component\n\n```tsx\n// components/theme-provider.tsx\nimport { createContext, useContext, type ReactNode } from 'react';\nimport { useTheme } from '@/hooks/use-theme';\n\ntype ThemeContextValue = ReturnType<typeof useTheme>;\n\nconst ThemeContext = createContext<ThemeContextValue | undefined>(undefined);\n\nexport function ThemeProvider({ children }: { children: ReactNode }) {\n  const value = useTheme();\n\n  return (\n    <ThemeContext.Provider value={value}>\n      {children}\n    </ThemeContext.Provider>\n  );\n}\n\nexport function useThemeContext() {\n  const context = useContext(ThemeContext);\n  if (!context) {\n    throw new Error('useThemeContext must be used within ThemeProvider');\n  }\n  return context;\n}\n```\n\n### Theme Toggle Component\n\n```tsx\n// components/theme-toggle.tsx\nimport { Moon, Sun, Monitor } from 'lucide-react';\nimport { useThemeContext } from '@/components/theme-provider';\nimport { Button } from '@/components/ui/button';\n\nexport function ThemeToggle() {\n  const { theme, setTheme } = useThemeContext();\n\n  const cycleTheme = () => {\n    const themes: Array<'light' | 'dark' | 'system'> = ['light', 'dark', 'system'];\n    const currentIndex = themes.indexOf(theme);\n    const nextIndex = (currentIndex + 1) % themes.length;\n    setTheme(themes[nextIndex]);\n  };\n\n  const Icon = theme === 'light' ? Sun : theme === 'dark' ? Moon : Monitor;\n\n  return (\n    <Button\n      variant=\"outline\"\n      size=\"icon\"\n      onClick={cycleTheme}\n      aria-label={`Current theme: ${theme}. Click to cycle themes.`}\n    >\n      <Icon className=\"h-4 w-4\" />\n    </Button>\n  );\n}\n```\n\n### SSR Script (Prevent FOUC)\n\nInject this script before any styled content to prevent flash:\n\n```tsx\n// app/layout.tsx (Next.js example)\nexport default function RootLayout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\" suppressHydrationWarning>\n      <head>\n        <script\n          dangerouslySetInnerHTML={{\n            __html: `\n              (function() {\n                const theme = localStorage.getItem('theme') || 'system';\n                const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n                const effectiveTheme = theme === 'system' ? systemTheme : theme;\n                document.documentElement.classList.add(effectiveTheme);\n              })();\n            `,\n          }}\n        />\n      </head>\n      <body>\n        <ThemeProvider>\n          {children}\n        </ThemeProvider>\n      </body>\n    </html>\n  );\n}\n```\n\n## Respecting User Preferences\n\n### Reduced Motion\n\nAlways respect `prefers-reduced-motion`:\n\n```css\n@media (prefers-reduced-motion: reduce) {\n  *,\n  *::before,\n  *::after {\n    animation-duration: 0.01ms !important;\n    animation-iteration-count: 1 !important;\n    transition-duration: 0.01ms !important;\n    scroll-behavior: auto !important;\n  }\n}\n```\n\n**Usage in components**:\n```tsx\nexport function Card() {\n  return (\n    <div className=\"transition-all duration-300 motion-reduce:transition-none\">\n      Content\n    </div>\n  );\n}\n```\n\n### High Contrast\n\nSupport high contrast mode:\n\n```css\n@media (prefers-contrast: high) {\n  .button {\n    border-width: 2px;\n  }\n}\n```\n\n**Tailwind utilities**:\n```html\n<button class=\"border contrast-more:border-2\">\n  High Contrast Button\n</button>\n```\n\n### Forced Colors\n\nRespect forced colors mode (Windows High Contrast):\n\n```tsx\nexport function Card() {\n  return (\n    <div className=\"bg-white dark:bg-slate-900 forced-colors:bg-[Canvas] forced-colors:border forced-colors:border-[CanvasText]\">\n      Content\n    </div>\n  );\n}\n```\n\n### Combined Example\n\n```tsx\nexport function AccessibleCard({ children }: { children: React.ReactNode }) {\n  return (\n    <div\n      className={`\n        bg-white dark:bg-slate-900\n        text-slate-900 dark:text-slate-50\n        rounded-lg\n        transition-colors duration-200\n        motion-reduce:transition-none\n        border border-transparent\n        contrast-more:border-slate-300\n        forced-colors:bg-[Canvas]\n        forced-colors:border-[CanvasText]\n      `}\n    >\n      {children}\n    </div>\n  );\n}\n```\n",
        "skills/tailwind-v4/references/setup.md": "# Setup & Installation\n\n## Contents\n\n- [Package Installation](#package-installation)\n- [Vite Plugin Configuration](#vite-plugin-configuration)\n- [TypeScript Configuration](#typescript-configuration)\n- [CSS Entry Point](#css-entry-point)\n- [Why No Config Files](#why-no-config-files)\n\n---\n\n## Package Installation\n\nInstall Tailwind CSS v4 with the Vite plugin:\n\n```bash\npnpm add -D tailwindcss@next @tailwindcss/vite@next\n```\n\n**Complete package.json example**:\n```json\n{\n  \"name\": \"amelia-dashboard\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"react\": \"^19.0.0\",\n    \"react-dom\": \"^19.0.0\"\n  },\n  \"devDependencies\": {\n    \"@tailwindcss/vite\": \"^4.0.0\",\n    \"@types/node\": \"^22.0.0\",\n    \"@vitejs/plugin-react\": \"^5.0.0\",\n    \"tailwindcss\": \"^4.0.0\",\n    \"typescript\": \"^5.6.0\",\n    \"vite\": \"^6.0.0\"\n  }\n}\n```\n\n## Vite Plugin Configuration\n\nUse the `@tailwindcss/vite` plugin (NOT the PostCSS plugin):\n\n```ts\n// vite.config.ts\nimport tailwindcss from '@tailwindcss/vite';\nimport react from '@vitejs/plugin-react';\nimport { defineConfig } from 'vite';\n\nexport default defineConfig({\n  plugins: [\n    react(),\n    tailwindcss(),\n  ],\n});\n```\n\n**Plugin options**:\n```ts\nexport type PluginOptions = {\n  /**\n   * Optimize and minify the output CSS.\n   * Default: true in build mode, false in dev mode\n   */\n  optimize?: boolean | { minify?: boolean };\n};\n\n// Example with options\ntailwindcss({\n  optimize: {\n    minify: true,\n  },\n});\n```\n\n**How it works**:\n- Scans source files for Tailwind class candidates\n- Intercepts CSS files containing `@import 'tailwindcss'`\n- Generates utilities based on detected classes\n- Watches for file changes in dev mode\n- Optimizes and minifies in build mode\n\n## TypeScript Configuration\n\nAdd `@types/node` for path resolution in Vite config:\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"useDefineForClassFields\": true,\n    \"lib\": [\"ES2020\", \"DOM\", \"DOM.Iterable\"],\n    \"module\": \"ESNext\",\n    \"skipLibCheck\": true,\n\n    /* Bundler mode */\n    \"moduleResolution\": \"bundler\",\n    \"allowImportingTsExtensions\": true,\n    \"isolatedModules\": true,\n    \"moduleDetection\": \"force\",\n    \"noEmit\": true,\n    \"jsx\": \"react-jsx\",\n\n    /* Linting */\n    \"strict\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noFallthroughCasesInSwitch\": true,\n\n    /* Path resolution */\n    \"types\": [\"node\"],\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/*\": [\"./src/*\"]\n    }\n  },\n  \"include\": [\"src\"]\n}\n```\n\n**Why `@types/node` is needed**:\n- Vite uses Node.js path resolution APIs\n- Required for `import.meta.env` types\n- Enables `path.resolve()` in config files\n\n## CSS Entry Point\n\nCreate a single CSS file that imports Tailwind:\n\n```css\n/* src/index.css */\n@import 'tailwindcss';\n```\n\n**That's it.** No other imports or configuration needed.\n\n**Import in your app**:\n```tsx\n// src/main.tsx\nimport './index.css';\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n```\n\n**Advanced: Multiple entry points**:\n```css\n/* src/index.css */\n@import 'tailwindcss';\n\n/* Custom theme for this entry point */\n@theme {\n  --color-primary: oklch(60% 0.24 262);\n}\n\n/* Custom utilities */\n@layer utilities {\n  .content-auto {\n    content-visibility: auto;\n  }\n}\n```\n\n## Why No Config Files\n\nTailwind v4 eliminates separate configuration files in favor of CSS-first configuration.\n\n### No `tailwind.config.js`\n\n**v3 approach** (separate JS config):\n```js\n// tailwind.config.js\nmodule.exports = {\n  theme: {\n    extend: {\n      colors: {\n        primary: '#3b82f6',\n      },\n    },\n  },\n};\n```\n\n**v4 approach** (CSS-first):\n```css\n@theme {\n  --color-primary: oklch(60% 0.24 262);\n}\n```\n\n**Benefits**:\n- Configuration lives with styles\n- No build-time JS evaluation\n- Better CSS tooling support (syntax highlighting, autocomplete)\n- Easier to understand what CSS gets generated\n- No context switching between files\n\n### No `postcss.config.js`\n\n**v3 approach** (PostCSS plugin):\n```js\n// postcss.config.js\nmodule.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n};\n```\n\n**v4 approach** (Vite plugin):\n```ts\n// vite.config.ts\nimport tailwindcss from '@tailwindcss/vite';\n\nexport default defineConfig({\n  plugins: [tailwindcss()],\n});\n```\n\n**Benefits**:\n- Faster builds (no PostCSS overhead)\n- Integrated with Vite's dev server\n- Better HMR (Hot Module Replacement)\n- Automatic source map generation\n- Native ES modules support\n\n### Content Detection\n\n**v3 approach** (manual content paths):\n```js\n// tailwind.config.js\nmodule.exports = {\n  content: ['./src/**/*.{js,ts,jsx,tsx}'],\n};\n```\n\n**v4 approach** (automatic scanning):\n```css\n/* Auto-scans all files by default */\n@import 'tailwindcss';\n\n/* Optional: Custom source patterns */\n@source \"src/**/*.{js,ts,jsx,tsx}\";\n@source \"components/**/*.vue\";\n```\n\n**Benefits**:\n- Zero configuration by default\n- Explicit control when needed\n- CSS-based configuration\n- Easier to understand and debug\n",
        "skills/tailwind-v4/references/theming.md": "# Theming & Design Tokens\n\n## Contents\n\n- [@theme Directive Modes](#theme-directive-modes)\n- [CSS Variable Naming Conventions](#css-variable-naming-conventions)\n- [OKLCH Color System](#oklch-color-system)\n- [Aviation Theme Example](#aviation-theme-example)\n- [Two-Tier Variable System](#two-tier-variable-system)\n- [Custom Font Configuration](#custom-font-configuration)\n- [Animation Keyframes](#animation-keyframes)\n\n---\n\n## @theme Directive Modes\n\nTailwind v4 provides multiple modes for defining theme values. Modes can be combined (e.g., `@theme default inline`, `@theme inline reference`).\n\n### @theme (default mode)\n\nGenerates CSS variables that can be referenced in custom CSS:\n\n```css\n@theme {\n  --color-brand: oklch(60% 0.24 262);\n  --spacing: 0.25rem;\n}\n```\n\n**Generated CSS**:\n```css\n:root {\n  --color-brand: oklch(60% 0.24 262);\n  --spacing: 0.25rem;\n}\n```\n\n**Usage in utilities**:\n```html\n<div class=\"text-brand\">Uses var(--color-brand)</div>\n```\n\n**Usage in custom CSS**:\n```css\n.custom-element {\n  color: var(--color-brand);\n  padding: calc(var(--spacing) * 4);\n}\n```\n\n### @theme inline\n\nInlines values directly without CSS variable indirection:\n\n```css\n@theme inline {\n  --color-brand: oklch(60% 0.24 262);\n}\n```\n\n**Generated CSS** (when `text-brand` is used):\n```css\n.text-brand {\n  color: oklch(60% 0.24 262);\n}\n```\n\n**When to use**:\n- Better performance (no `var()` lookups)\n- Static values that won't change\n- Utilities with multiple values (animations, shadows)\n- Production builds with no runtime theming\n\n### @theme reference\n\nInlines values as fallbacks without emitting CSS variables to :root:\n\n```css\n@theme reference {\n  --color-internal: oklch(50% 0.1 180);\n}\n```\n\n**Generated CSS** (when `bg-internal` is used):\n```css\n.bg-internal {\n  background-color: var(--color-internal, oklch(50% 0.1 180));\n}\n```\n\n**Key behavior**: No `:root` variable is created, but the utility still works by using the value as a fallback in `var()`.\n\n**When to use**:\n- Provide fallback values without CSS variable overhead\n- Reduce :root bloat while maintaining utility functionality\n- Values that should work even if the variable isn't defined elsewhere\n- Combine with `inline` for direct value substitution (e.g., `@theme reference inline`)\n\n### @theme default\n\nExplicitly marks theme values as defaults that can be overridden:\n\n```css\n@theme default {\n  --color-primary: oklch(60% 0.24 262);\n}\n\n/* Later in the file or another file */\n@theme {\n  --color-primary: oklch(70% 0.20 180);  /* This overrides the default */\n}\n```\n\n**Generated CSS**:\n```css\n:root, :host {\n  --color-primary: oklch(70% 0.20 180);\n}\n```\n\n**When to use**:\n- Providing base theme values that can be customized\n- Library or framework default themes\n- Creating overridable design systems\n- Used extensively in Tailwind's built-in `theme.css`\n\n**Mode combinations**:\n- `@theme default inline` - Default values, inlined directly\n- `@theme default reference` - Default fallbacks without :root emission\n- `@theme default inline reference` - All three combined\n\n## CSS Variable Naming Conventions\n\nTailwind v4 uses consistent naming patterns for theme variables:\n\n### Colors\n\n```css\n--color-{name}-{shade}\n```\n\n**Examples**:\n```css\n@theme {\n  --color-primary-500: oklch(60% 0.24 262);\n  --color-surface-900: oklch(21% 0.006 286);\n  --color-success-600: oklch(62.7% 0.194 149);\n}\n\n/* Usage: text-primary-500, bg-surface-900, border-success-600 */\n```\n\n### Spacing\n\n```css\n--spacing: {base-unit}\n```\n\n**Example**:\n```css\n@theme {\n  --spacing: 0.25rem;  /* Base unit (4px at 16px root) */\n}\n\n/* Generated scale:\n  p-1   padding: calc(0.25rem * 1)   4px\n  p-4   padding: calc(0.25rem * 4)   16px\n  p-12  padding: calc(0.25rem * 12)  48px\n*/\n```\n\n### Fonts\n\n```css\n--font-{family}\n--font-{family}--{feature}\n```\n\n**Examples**:\n```css\n@theme {\n  --font-sans: ui-sans-serif, system-ui, sans-serif;\n  --font-mono: 'JetBrains Mono', monospace;\n  --font-display: 'Inter Variable', system-ui;\n\n  --font-display--font-variation-settings: 'wght' 400;\n  --font-display--font-feature-settings: 'cv02', 'cv03';\n}\n\n/* Usage: font-sans, font-mono, font-display */\n```\n\n### Breakpoints\n\n```css\n--breakpoint-{size}: {value}\n```\n\n**Examples**:\n```css\n@theme {\n  --breakpoint-sm: 40rem;   /* 640px */\n  --breakpoint-md: 48rem;   /* 768px */\n  --breakpoint-lg: 64rem;   /* 1024px */\n  --breakpoint-xl: 80rem;   /* 1280px */\n  --breakpoint-2xl: 96rem;  /* 1536px */\n}\n```\n\n### Animations\n\n```css\n--animate-{name}: {animation-value}\n```\n\n**Examples**:\n```css\n@theme inline {\n  --animate-spin: spin 1s linear infinite;\n  --animate-pulse: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;\n  --animate-beacon: beacon 2s ease-in-out infinite;\n\n  @keyframes spin {\n    to { transform: rotate(360deg); }\n  }\n\n  @keyframes pulse {\n    50% { opacity: 0.5; }\n  }\n\n  @keyframes beacon {\n    0%, 100% { opacity: 1; transform: scale(1); }\n    50% { opacity: 0.5; transform: scale(1.05); }\n  }\n}\n\n/* Usage: animate-spin, animate-pulse, animate-beacon */\n```\n\n## OKLCH Color System\n\nOKLCH (Oklab LCH) provides perceptually uniform colors with consistent lightness across all hues.\n\n### Syntax\n\n```css\noklch(L% C H / A)\n```\n\n- **L (Lightness)**: 0% (black) to 100% (white)\n- **C (Chroma)**: 0 (gray) to ~0.4 (vibrant)\n- **H (Hue)**: 0-360 degrees\n- **A (Alpha)**: Optional, 0-1\n\n### Hue Wheel\n\n```\n  0 / 360 - Red\n  30       - Orange\n  60       - Yellow\n  120      - Green\n  180      - Cyan\n  240      - Blue\n  270      - Indigo\n  300      - Magenta\n```\n\n### Complete Color Palette\n\n```css\n@theme {\n  /* Blue scale (H  260) */\n  --color-blue-50: oklch(97% 0.014 254.604);\n  --color-blue-100: oklch(93.2% 0.032 255.585);\n  --color-blue-200: oklch(88.2% 0.059 254.128);\n  --color-blue-300: oklch(80.9% 0.105 251.813);\n  --color-blue-400: oklch(70.7% 0.165 254.624);\n  --color-blue-500: oklch(62.3% 0.214 259.815);\n  --color-blue-600: oklch(54.6% 0.245 262.881);\n  --color-blue-700: oklch(48.8% 0.243 264.376);\n  --color-blue-800: oklch(42.4% 0.199 265.638);\n  --color-blue-900: oklch(37.9% 0.146 265.522);\n  --color-blue-950: oklch(28.2% 0.091 267.935);\n\n  /* Slate scale (neutral with slight blue tint) */\n  --color-slate-50: oklch(98.4% 0.003 247.858);\n  --color-slate-100: oklch(96.8% 0.007 247.896);\n  --color-slate-200: oklch(92.9% 0.013 255.508);\n  --color-slate-300: oklch(86.9% 0.022 252.894);\n  --color-slate-400: oklch(70.4% 0.04 256.788);\n  --color-slate-500: oklch(55.4% 0.046 257.417);\n  --color-slate-600: oklch(44.6% 0.043 257.281);\n  --color-slate-700: oklch(37.2% 0.044 257.287);\n  --color-slate-800: oklch(27.9% 0.041 260.031);\n  --color-slate-900: oklch(20.8% 0.042 265.755);\n  --color-slate-950: oklch(12.9% 0.042 264.695);\n}\n```\n\n### Chroma Guidelines\n\n- **0**: Pure gray (achromatic)\n- **0.01-0.05**: Subtle tint (slate, zinc)\n- **0.10-0.15**: Muted colors (good for backgrounds)\n- **0.15-0.25**: Vibrant colors (good for UI elements)\n- **0.25-0.40**: Maximum saturation (use sparingly)\n\n## Aviation Theme Example\n\nCustom color palette for an aviation-themed dashboard:\n\n```css\n@theme {\n  /* Flight status colors */\n  --color-on-time: oklch(72.3% 0.219 149.579);      /* Green-600 */\n  --color-delayed: oklch(76.9% 0.188 70.08);        /* Amber-500 */\n  --color-cancelled: oklch(63.7% 0.237 25.331);     /* Red-500 */\n  --color-diverted: oklch(68.5% 0.169 237.323);     /* Sky-500 */\n\n  /* Navigation colors */\n  --color-runway: oklch(87.1% 0.006 286.286);       /* Zinc-300 */\n  --color-taxiway: oklch(70.5% 0.015 286.067);      /* Zinc-400 */\n  --color-apron: oklch(55.2% 0.016 285.938);        /* Zinc-500 */\n\n  /* Radar colors */\n  --color-primary-radar: oklch(74.6% 0.16 232.661); /* Sky-400 */\n  --color-secondary-radar: oklch(76.5% 0.177 163.223); /* Emerald-400 */\n\n  /* Map layers */\n  --color-airspace-class-a: oklch(70.7% 0.165 254.624); /* Blue-400 */\n  --color-airspace-class-b: oklch(84.1% 0.238 128.85);  /* Lime-400 */\n  --color-airspace-class-c: oklch(71.8% 0.202 349.761); /* Pink-400 */\n}\n```\n\n## Two-Tier Variable System\n\nSeparate design tokens from semantic naming:\n\n```css\n@theme {\n  /* Tier 1: Design tokens (OKLCH primitives) */\n  --color-blue-600: oklch(54.6% 0.245 262.881);\n  --color-slate-50: oklch(98.4% 0.003 247.858);\n  --color-slate-800: oklch(27.9% 0.041 260.031);\n  --color-slate-900: oklch(20.8% 0.042 265.755);\n  --color-emerald-500: oklch(69.6% 0.17 162.48);\n\n  /* Tier 2: Semantic mappings */\n  --color-primary: var(--color-blue-600);\n  --color-surface: var(--color-slate-900);\n  --color-surface-raised: var(--color-slate-800);\n  --color-text: var(--color-slate-50);\n  --color-success: var(--color-emerald-500);\n}\n\n/* Usage in components */\n.button-primary {\n  background-color: var(--color-primary);\n  color: var(--color-text);\n}\n\n.card {\n  background-color: var(--color-surface-raised);\n}\n```\n\n**Benefits**:\n- Design tokens maintain consistency\n- Semantic names convey intent\n- Easy theme switching (just remap tier 2)\n- Clear separation of concerns\n\n## Custom Font Configuration\n\nConfigure custom fonts with variable font features:\n\n```css\n@theme {\n  /* Font families */\n  --font-sans: 'Inter Variable', ui-sans-serif, system-ui, sans-serif;\n  --font-mono: 'JetBrains Mono', ui-monospace, monospace;\n  --font-display: 'Manrope Variable', system-ui, sans-serif;\n\n  /* Variable font settings for --font-display */\n  --font-display--font-variation-settings: 'wght' 600;\n\n  /* OpenType features for --font-display */\n  --font-display--font-feature-settings: 'ss01', 'ss02', 'cv05';\n\n  /* Font weights */\n  --font-weight-normal: 400;\n  --font-weight-medium: 500;\n  --font-weight-semibold: 600;\n  --font-weight-bold: 700;\n\n  /* Letter spacing */\n  --tracking-tight: -0.025em;\n  --tracking-normal: 0em;\n  --tracking-wide: 0.025em;\n}\n```\n\n**Load fonts in HTML**:\n```html\n<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap\" rel=\"stylesheet\">\n```\n\n**Usage**:\n```html\n<h1 class=\"font-display font-semibold tracking-tight\">Aviation Dashboard</h1>\n<code class=\"font-mono text-sm\">ATC-1234</code>\n```\n\n## Animation Keyframes\n\nDefine custom animations with `@theme inline` and `@keyframes`:\n\n```css\n@theme inline {\n  /* Simple animations */\n  --animate-fade-in: fade-in 0.3s ease-out;\n  --animate-slide-up: slide-up 0.4s cubic-bezier(0.16, 1, 0.3, 1);\n\n  /* Complex animations */\n  --animate-beacon: beacon 2s ease-in-out infinite;\n  --animate-pulse-glow: pulse-glow 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite;\n\n  /* Keyframe definitions */\n  @keyframes fade-in {\n    from {\n      opacity: 0;\n    }\n    to {\n      opacity: 1;\n    }\n  }\n\n  @keyframes slide-up {\n    from {\n      transform: translateY(10px);\n      opacity: 0;\n    }\n    to {\n      transform: translateY(0);\n      opacity: 1;\n    }\n  }\n\n  @keyframes beacon {\n    0%, 100% {\n      opacity: 1;\n      transform: scale(1);\n      box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7);\n    }\n    50% {\n      opacity: 0.9;\n      transform: scale(1.05);\n      box-shadow: 0 0 0 10px rgba(59, 130, 246, 0);\n    }\n  }\n\n  @keyframes pulse-glow {\n    0%, 100% {\n      box-shadow: 0 0 8px 2px rgba(34, 197, 94, 0.4);\n    }\n    50% {\n      box-shadow: 0 0 16px 4px rgba(34, 197, 94, 0.8);\n    }\n  }\n}\n```\n\n**Usage**:\n```html\n<div class=\"animate-fade-in\">Fades in on mount</div>\n<div class=\"animate-beacon\">Pulsing beacon effect</div>\n<div class=\"animate-pulse-glow\">Glowing status indicator</div>\n```\n\n**Respecting prefers-reduced-motion**:\n```css\n@media (prefers-reduced-motion: reduce) {\n  * {\n    animation-duration: 0.01ms !important;\n    animation-iteration-count: 1 !important;\n    transition-duration: 0.01ms !important;\n  }\n}\n```\n",
        "skills/tutorial-docs/SKILL.md": "---\nname: tutorial-docs\ndescription: Tutorial patterns for documentation - learning-oriented guides that teach through guided doing\nautoContext:\n  whenUserAsks:\n    - tutorial\n    - tutorials\n    - learning guide\n    - getting started guide\n    - onboarding guide\n    - beginner guide\n    - introductory guide\n    - learn by doing\n    - hands-on guide\ndependencies:\n  - docs-style\n---\n\n# Tutorial Documentation Skill\n\nThis skill provides patterns for writing effective tutorials following the Diataxis framework. Tutorials are learning-oriented content where the reader learns by doing under the guidance of a teacher.\n\n## Purpose & Audience\n\n**Target readers:**\n- Complete beginners with no prior experience\n- Users who want to learn, not accomplish a specific task\n- People who need a successful first experience with the product\n- Learners who benefit from guided, hands-on practice\n\n**Tutorials are NOT:**\n- How-To guides (which help accomplish specific tasks)\n- Explanations (which provide understanding)\n- Reference docs (which describe the system)\n\n## Core Principles (Diataxis Framework)\n\n### 1. Learn by Doing, Not by Reading\n\nTutorials teach through action, not explanation. The reader should be doing something at every moment.\n\n| Avoid | Prefer |\n|-------|--------|\n| \"REST APIs use HTTP methods to...\" | \"Run this command to make your first API call:\" |\n| \"Authentication is important because...\" | \"Add your API key to authenticate:\" |\n| \"The dashboard contains several sections...\" | \"Click **Create Project** in the dashboard.\" |\n\n### 2. Deliver Visible Results at Every Step\n\nAfter each action, tell readers exactly what they should see. This confirms success and builds confidence.\n\n```markdown\nRun the development server:\n\n```bash\nnpm run dev\n```\n\nYou should see:\n\n```\n> Local: http://localhost:3000\n> Ready in 500ms\n```\n\nOpen http://localhost:3000 in your browser. You should see a welcome page with \"Hello, World!\" displayed.\n```\n\n### 3. One Clear Path, Minimize Choices\n\nTutorials should not offer alternatives. Pick one way and guide the reader through it completely.\n\n| Avoid | Prefer |\n|-------|--------|\n| \"You can use npm, yarn, or pnpm...\" | \"Install the dependencies:\" |\n| \"There are several ways to configure...\" | \"Create a config file:\" |\n| \"Optionally, you might want to...\" | [Omit optional steps entirely] |\n\n### 4. The Teacher Takes Responsibility\n\nIf the reader fails, the tutorial failed. Anticipate problems and prevent them. Never blame the reader.\n\n```markdown\n<Warning>\nMake sure you're in the project directory before running this command.\nIf you see \"command not found\", return to Step 2 to verify the installation.\n</Warning>\n```\n\n### 5. Permit Repetition to Build Confidence\n\nRepeating similar actions in slightly different contexts helps cement learning. Don't try to be efficient.\n\n## Tutorial Template\n\nUse this structure for all tutorials:\n\n```markdown\n---\ntitle: \"Build your first [thing]\"\ndescription: \"Learn the basics of [product] by building a working [thing]\"\n---\n\n# Build Your First [Thing]\n\nIn this tutorial, you'll build a [concrete deliverable]. By the end, you'll have a working [thing] that [does something visible].\n\n<Note>\nThis tutorial takes approximately [X] minutes to complete.\n</Note>\n\n## What you'll build\n\n[Screenshot or diagram of the end result]\n\nA [brief description of the concrete deliverable] that:\n- [Visible capability 1]\n- [Visible capability 2]\n- [Visible capability 3]\n\n## Prerequisites\n\nBefore starting, make sure you have:\n\n- [Minimal requirement 1 - link to install guide if needed]\n- [Minimal requirement 2]\n\n<Tip>\nNew to [prerequisite]? [Link to external resource] has a quick setup guide.\n</Tip>\n\n## Step 1: [Set up your project]\n\n[First action - always start with something that produces visible output]\n\n```bash\n[command]\n```\n\nYou should see:\n\n```\n[expected output]\n```\n\n[Brief confirmation of what this means]\n\n## Step 2: [Create your first thing]\n\n[Next action with clear instruction]\n\n```code\n[code to add or modify]\n```\n\nSave the file. You should see [visible change].\n\n<Note>\n[Optional tip to prevent common mistakes]\n</Note>\n\n## Step 3: [Continue building]\n\n[Continue with more steps, each producing visible output]\n\n## Step 4: [Add the final piece]\n\n[Bring it together with a final step]\n\nYou should now see [final visible result].\n\n[Screenshot of completed project]\n\n## What you've learned\n\nIn this tutorial, you:\n\n- [Concrete skill 1 - what they can now do]\n- [Concrete skill 2]\n- [Concrete skill 3]\n\n## Next steps\n\nNow that you have a working [thing], you can:\n\n- **[Tutorial 2 title]** - Continue learning by [next learning goal]\n- **[How-to guide]** - Learn how to [specific task] with your [thing]\n- **[Concepts page]** - Understand [concept] in more depth\n```\n\n## Writing Principles\n\n### Title Conventions\n\n- **Start with action outcomes**: \"Build your first...\", \"Create a...\", \"Deploy your...\"\n- Focus on what they'll make, not what they'll learn\n- Be concrete: \"Build a chat application\" not \"Learn about real-time messaging\"\n\n### Step Structure\n\n1. **Lead with the action** - don't explain before doing\n2. **Show exactly what to type or click** - no ambiguity\n3. **Confirm success after every step** - \"You should see...\"\n4. **Keep steps small** - one visible change per step\n\n### Managing Prerequisites\n\nTutorials are for beginners, so minimize prerequisites:\n\n```markdown\n## Prerequisites\n\n- A computer with macOS, Windows, or Linux\n- A text editor (we recommend VS Code)\n- 15 minutes of time\n\n<Tip>\nYou don't need any programming experience. This tutorial explains everything as we go.\n</Tip>\n```\n\n### The \"You should see\" Pattern\n\nThis is the most important pattern in tutorial writing. Use it constantly:\n\n```markdown\nClick **Save**. You should see a green checkmark appear next to the filename.\n\nRun the test:\n\n```bash\nnpm test\n```\n\nYou should see:\n\n```\nPASS  src/app.test.js\n   renders welcome message (23ms)\n\nTests: 1 passed, 1 total\n```\n```\n\n### Handling Errors Gracefully\n\nAnticipate failures and guide readers back on track:\n\n```markdown\n<Warning>\nIf you see \"Module not found\", make sure you saved the file from Step 2.\nReturn to Step 2 and verify the import statement matches exactly.\n</Warning>\n```\n\n## Components for Tutorials\n\n### Frame Component for Screenshots\n\nShow what success looks like:\n\n```markdown\n<Frame caption=\"Your completed dashboard should look like this\">\n  ![Dashboard screenshot](/images/tutorial-dashboard.png)\n</Frame>\n```\n\n### Steps Component for Procedures\n\nFor numbered sequences within a step:\n\n```markdown\n<Steps>\n  <Step title=\"Open the settings panel\">\n    Click the gear icon in the top right corner.\n  </Step>\n  <Step title=\"Find the API section\">\n    Scroll down to **Developer Settings**.\n  </Step>\n  <Step title=\"Generate a key\">\n    Click **Create New Key** and copy the value shown.\n  </Step>\n</Steps>\n```\n\n### Callouts for Guidance\n\n```markdown\n<Note>\nDon't worry if the colors look different on your screen.\nWe'll customize the theme in the next step.\n</Note>\n\n<Warning>\nMake sure to save the file before continuing.\nThe next step won't work without this change.\n</Warning>\n\n<Tip>\nYou can press Cmd+S (Mac) or Ctrl+S (Windows) to save quickly.\n</Tip>\n```\n\n### Code with Highlighted Lines\n\nDraw attention to what matters:\n\n```markdown\n```javascript {3-4}\nfunction App() {\n  return (\n    <h1>Hello, World!</h1>\n    <p>Welcome to your first app.</p>\n  );\n}\n```\n```\n\n## Example Tutorial\n\nSee [references/example-weather-api.md](references/example-weather-api.md) for a complete example tutorial demonstrating all principles above. The example builds a weather dashboard that fetches real API data.\n\n## Checklist for Tutorials\n\nBefore publishing, verify:\n\n- [ ] Title describes what they'll build, not what they'll learn\n- [ ] Introduction shows the concrete end result\n- [ ] Prerequisites are minimal (beginners don't have much)\n- [ ] Every step produces visible output\n- [ ] \"You should see\" appears after each significant action\n- [ ] No choices offered - one clear path only\n- [ ] No explanations of why things work (save for docs)\n- [ ] Potential failures are anticipated with recovery guidance\n- [ ] \"What you've learned\" summarizes concrete skills gained\n- [ ] Next steps guide to continued learning\n- [ ] Tutorial tested end-to-end by someone unfamiliar with it\n\n## When to Use Tutorial vs Other Doc Types\n\n| User's mindset | Doc type | Example |\n|---------------|----------|---------|\n| \"I want to learn\" | **Tutorial** | \"Build your first chatbot\" |\n| \"I want to do X\" | How-To | \"How to configure SSO\" |\n| \"I want to understand\" | Explanation | \"How our caching works\" |\n| \"I need to look up Y\" | Reference | \"API endpoint reference\" |\n\n### Tutorial vs How-To: Key Differences\n\n| Aspect | Tutorial | How-To |\n|--------|----------|--------|\n| **Purpose** | Learning through doing | Accomplishing a specific task |\n| **Audience** | Complete beginners | Users with some experience |\n| **Structure** | Linear journey with one path | Steps to achieve a goal |\n| **Choices** | None - one prescribed way | May show alternatives |\n| **Explanations** | Minimal - action over theory | Minimal - focus on steps |\n| **Success** | Reader learns and gains confidence | Reader completes their task |\n| **Length** | Longer, more hand-holding | Shorter, more direct |\n\n## Related Skills\n\n- **docs-style**: Core writing conventions and components\n- **howto-docs**: How-To guide patterns for task-oriented content\n- **reference-docs**: Reference documentation patterns\n- **explanation-docs**: Conceptual documentation patterns\n",
        "skills/tutorial-docs/references/example-weather-api.md": "# Example Tutorial: Weather API Integration\n\nThis is a complete example tutorial demonstrating all principles from the tutorial-docs skill.\n\n```markdown\n---\ntitle: \"Build your first API integration\"\ndescription: \"Learn the basics of our API by building a working weather dashboard\"\n---\n\n# Build Your First API Integration\n\nIn this tutorial, you'll build a weather dashboard that fetches real data from our API. By the end, you'll have a working page that displays current weather for any city.\n\n<Note>\nThis tutorial takes approximately 20 minutes to complete.\n</Note>\n\n## What you'll build\n\n<Frame caption=\"The completed weather dashboard\">\n  ![Weather dashboard showing temperature and conditions](/images/weather-dashboard.png)\n</Frame>\n\nA simple weather dashboard that:\n- Accepts a city name as input\n- Fetches real weather data from our API\n- Displays temperature and conditions\n\n## Prerequisites\n\nBefore starting, make sure you have:\n\n- Node.js 18 or later installed ([download here](https://nodejs.org))\n- A free account ([sign up](https://example.com/signup))\n\n## Step 1: Create your project\n\nOpen your terminal and create a new project folder:\n\n```bash\nmkdir weather-dashboard\ncd weather-dashboard\nnpm init -y\n```\n\nYou should see:\n\n```\nWrote to /weather-dashboard/package.json\n```\n\nThis creates a new project with default settings.\n\n## Step 2: Install the SDK\n\nInstall our JavaScript SDK:\n\n```bash\nnpm install @example/weather-sdk\n```\n\nYou should see output ending with:\n\n```\nadded 1 package in 2s\n```\n\n## Step 3: Get your API key\n\n<Steps>\n  <Step title=\"Open the dashboard\">\n    Go to [dashboard.example.com](https://dashboard.example.com) and sign in.\n  </Step>\n  <Step title=\"Navigate to API keys\">\n    Click **Settings** in the sidebar, then **API Keys**.\n  </Step>\n  <Step title=\"Create a key\">\n    Click **Create Key**, name it \"weather-tutorial\", and click **Generate**.\n  </Step>\n  <Step title=\"Copy the key\">\n    Copy the key shown. You'll need it in the next step.\n  </Step>\n</Steps>\n\n<Warning>\nKeep this key secret. Don't share it or commit it to version control.\n</Warning>\n\n## Step 4: Write your first API call\n\nCreate a new file called `weather.js`:\n\n```javascript\nconst Weather = require('@example/weather-sdk');\n\nconst client = new Weather({\n  apiKey: 'your-api-key-here'  // Replace with your key from Step 3\n});\n\nasync function getWeather(city) {\n  const data = await client.current(city);\n  console.log(`Weather in ${city}:`);\n  console.log(`  Temperature: ${data.temp}F`);\n  console.log(`  Conditions: ${data.conditions}`);\n}\n\ngetWeather('San Francisco');\n```\n\nReplace `'your-api-key-here'` with the API key you copied in Step 3.\n\nSave the file.\n\n## Step 5: Run your dashboard\n\nRun your script:\n\n```bash\nnode weather.js\n```\n\nYou should see:\n\n```\nWeather in San Francisco:\n  Temperature: 62F\n  Conditions: Partly cloudy\n```\n\nYou've just made your first API call.\n\n<Note>\nThe temperature will vary based on current conditions.\nAny valid output means your integration is working.\n</Note>\n\n## Step 6: Try another city\n\nChange the last line of `weather.js`:\n\n```javascript\ngetWeather('Tokyo');\n```\n\nRun it again:\n\n```bash\nnode weather.js\n```\n\nYou should see weather data for Tokyo:\n\n```\nWeather in Tokyo:\n  Temperature: 75F\n  Conditions: Clear\n```\n\n## What you've learned\n\nIn this tutorial, you:\n\n- Created a new Node.js project\n- Installed and configured our SDK\n- Generated an API key\n- Made API calls to fetch weather data\n\n## Next steps\n\nNow that you have a working API integration, you can:\n\n- **[Build a weather CLI](/tutorials/weather-cli)** - Continue learning by adding command-line arguments\n- **[How to handle API errors](/how-to/handle-api-errors)** - Learn to handle rate limits and network issues\n- **[API reference](/reference/weather-api)** - Explore all available weather endpoints\n```\n",
        "skills/urlsession-code-review/SKILL.md": "---\nname: urlsession-code-review\ndescription: Reviews URLSession networking code for iOS/macOS. Covers async/await patterns, request building, error handling, caching, and background sessions.\ntriggers:\n  - URLSession\n  - URLRequest\n  - URLCache\n  - URLError\n  - iOS networking\n---\n\n# URLSession Code Review\n\n## Quick Reference\n\n| Topic | Reference |\n|-------|-----------|\n| Async/Await | [async-networking.md](references/async-networking.md) |\n| Requests | [request-building.md](references/request-building.md) |\n| Errors | [error-handling.md](references/error-handling.md) |\n| Caching | [caching.md](references/caching.md) |\n\n## Review Checklist\n\n### Response Validation\n- [ ] HTTP status codes validated - URLSession does NOT throw on 404/500\n- [ ] Response cast to HTTPURLResponse before checking status\n- [ ] Both transport errors (URLError) and HTTP errors handled\n\n### Memory & Resources\n- [ ] Downloaded files moved/deleted (async API doesn't auto-delete)\n- [ ] Sessions with delegates call `finishTasksAndInvalidate()`\n- [ ] Long-running tasks use `[weak self]`\n- [ ] Stored Task references cancelled when appropriate\n\n### Configuration\n- [ ] `timeoutIntervalForResource` set (default is 7 days!)\n- [ ] URLCache sized adequately (default 512KB too small)\n- [ ] Sessions reused for connection pooling\n\n### Background Sessions\n- [ ] Unique identifier (especially with app extensions)\n- [ ] File-based uploads (not data-based)\n- [ ] Delegate methods used (not completion handlers)\n\n### Security\n- [ ] No hardcoded secrets (use Keychain)\n- [ ] Header values sanitized for CRLF injection\n- [ ] Query params via URLComponents (not string concat)\n\n## Output Format\n\n```markdown\n### Critical\n1. [FILE:LINE] Missing HTTP status validation\n   - Issue: 404/500 responses not treated as errors\n   - Fix: Check `httpResponse.statusCode` is 200-299\n```\n",
        "skills/urlsession-code-review/references/async-networking.md": "# URLSession Async/Await Reference\n\n> Minimum deployment: iOS 15+, macOS 12+\n\n## Quick Reference\n\n### Core Async Methods\n\n| Method | Returns | Use Case |\n|--------|---------|----------|\n| `data(from: URL)` | `(Data, URLResponse)` | Simple GET requests |\n| `data(for: URLRequest)` | `(Data, URLResponse)` | Configured requests (POST, headers) |\n| `download(from: URL)` | `(URL, URLResponse)` | Large files to disk |\n| `download(for: URLRequest)` | `(URL, URLResponse)` | Large files with custom request |\n| `upload(for: URLRequest, from: Data)` | `(Data, URLResponse)` | Upload data in memory |\n| `upload(for: URLRequest, fromFile: URL)` | `(Data, URLResponse)` | Upload file from disk |\n| `bytes(from: URL)` | `(AsyncBytes, URLResponse)` | Streaming response body |\n\n## Data Tasks\n\n```swift\n// Basic GET\nfunc fetchData(from url: URL) async throws -> Data {\n    let (data, response) = try await URLSession.shared.data(from: url)\n    guard let httpResponse = response as? HTTPURLResponse,\n          (200...299).contains(httpResponse.statusCode) else {\n        throw NetworkError.invalidResponse\n    }\n    return data\n}\n\n// POST with URLRequest\nfunc postData<T: Encodable>(_ body: T, to url: URL) async throws -> Data {\n    var request = URLRequest(url: url)\n    request.httpMethod = \"POST\"\n    request.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n    request.httpBody = try JSONEncoder().encode(body)\n    let (data, response) = try await URLSession.shared.data(for: request)\n    // Validate response...\n    return data\n}\n```\n\n## Download Tasks\n\n```swift\nfunc downloadFile(from url: URL, to destination: URL) async throws {\n    let (tempURL, response) = try await URLSession.shared.download(from: url)\n    guard let httpResponse = response as? HTTPURLResponse,\n          (200...299).contains(httpResponse.statusCode) else {\n        throw NetworkError.invalidResponse\n    }\n    // CRITICAL: Move or delete the file - it is NOT auto-deleted\n    try FileManager.default.moveItem(at: tempURL, to: destination)\n}\n```\n\n**Key difference**: The async/await download API does NOT automatically delete temporary files.\n\n## Streaming with AsyncBytes\n\n```swift\n// Line-by-line processing\nfunc streamLines(from url: URL) async throws {\n    let (bytes, _) = try await URLSession.shared.bytes(from: url)\n    for try await line in bytes.lines {\n        processLine(line)\n    }\n}\n\n// Server-Sent Events\nfunc subscribeToEvents(url: URL) async throws {\n    let (bytes, _) = try await URLSession.shared.bytes(from: url)\n    for try await line in bytes.lines {\n        if line.hasPrefix(\"data: \") {\n            let jsonString = String(line.dropFirst(6))\n            // Parse and handle event\n        }\n    }\n}\n```\n\n## Task Cancellation\n\nTask cancellation **automatically propagates** to URLSession requests.\n\n```swift\nclass DataLoader {\n    private var loadTask: Task<Data, Error>?\n\n    func load(from url: URL) {\n        loadTask?.cancel()  // Cancel previous request\n        loadTask = Task {\n            try await URLSession.shared.data(from: url).0\n        }\n    }\n}\n```\n\nSwiftUI's `.task` modifier automatically cancels when the view disappears.\n\n## Memory Management\n\nTasks implicitly capture `self` strongly. Use `[weak self]` for long-running tasks:\n\n```swift\ndownloadTask = Task { [weak self] in\n    guard let url = self?.downloadURL else { return }\n    let (data, _) = try await URLSession.shared.data(from: url)\n    self?.processData(data)\n}\n```\n\n## Critical Anti-Patterns\n\n### 1. Not Checking HTTP Status Codes\n\n```swift\n// BAD: 404 does not throw an error\nlet (data, _) = try await URLSession.shared.data(from: url)\nlet decoded = try JSONDecoder().decode(Model.self, from: data)  // Crashes on error HTML\n\n// GOOD: Validate response\nlet (data, response) = try await URLSession.shared.data(from: url)\nguard let httpResponse = response as? HTTPURLResponse,\n      (200...299).contains(httpResponse.statusCode) else {\n    throw NetworkError.serverError\n}\n```\n\n### 2. Forgetting to Delete Downloaded Files\n\n```swift\n// BAD: Temporary file wastes storage\nlet (tempURL, _) = try await URLSession.shared.download(from: url)\n// File is never moved or deleted\n\n// GOOD: Always handle temporary file\nlet (tempURL, _) = try await URLSession.shared.download(from: url)\ndefer { try? FileManager.default.removeItem(at: tempURL) }\nlet data = try Data(contentsOf: tempURL)\n```\n\n### 3. Upload Without HTTP Method\n\n```swift\n// BAD: GET cannot have a body\nvar request = URLRequest(url: url)\ntry await URLSession.shared.upload(for: request, from: data)  // Fails\n\n// GOOD: Set HTTP method\nrequest.httpMethod = \"POST\"\ntry await URLSession.shared.upload(for: request, from: data)\n```\n\n### 4. Storing Tasks Without Cancellation\n\n```swift\n// BAD: Tasks accumulate\nfunc search(query: String) {\n    Task { let results = try await performSearch(query) }\n}\n\n// GOOD: Cancel previous task\nprivate var searchTask: Task<Void, Never>?\nfunc search(query: String) {\n    searchTask?.cancel()\n    searchTask = Task {\n        guard !Task.isCancelled else { return }\n        let results = try? await performSearch(query)\n    }\n}\n```\n\n### 5. Strong Self in Infinite Loops\n\n```swift\n// BAD: Permanent memory leak\nlistenerTask = Task {\n    for try await line in bytes.lines {\n        self.handleEvent(line)  // Never deallocates\n    }\n}\n\n// GOOD: Weak self\nlistenerTask = Task { [weak self] in\n    for try await line in bytes.lines {\n        guard let self else { return }\n        self.handleEvent(line)\n    }\n}\n```\n\n## Review Questions\n\n- [ ] Are HTTP status codes validated (not just assuming success)?\n- [ ] Are downloaded files moved/deleted after use?\n- [ ] Are upload requests setting HTTP method (POST/PUT)?\n- [ ] Are long-running tasks using `[weak self]`?\n- [ ] Are stored Task references cancelled when appropriate?\n- [ ] Is cancellation handled in `viewWillDisappear`?\n- [ ] Is SwiftUI's `.task` modifier used instead of manual Task management?\n- [ ] For streaming, is response status checked before iterating?\n",
        "skills/urlsession-code-review/references/caching.md": "# URLSession Caching and Configuration Reference\n\n## Quick Reference\n\n### URLSessionConfiguration Types\n\n| Type | Persistence | Use Case |\n|------|-------------|----------|\n| `.default` | Disk cache, cookies | Normal networking |\n| `.ephemeral` | Memory only | Privacy-sensitive |\n| `.background(withIdentifier:)` | System-managed | Large transfers |\n\n### Cache Policies\n\n| Policy | Behavior | When to Use |\n|--------|----------|-------------|\n| `.useProtocolCachePolicy` | Follows HTTP headers | Default |\n| `.reloadIgnoringLocalCacheData` | Always fetch fresh | Fresh data required |\n| `.returnCacheDataElseLoad` | Cache first | Offline-first |\n| `.returnCacheDataDontLoad` | Cache only | Strict offline |\n\n### Timeout Defaults\n\n| Property | Default | Typical Setting |\n|----------|---------|-----------------|\n| `timeoutIntervalForRequest` | 60s | 30-60s |\n| `timeoutIntervalForResource` | **7 days** | 2-5 minutes |\n\n### URLCache Sizing\n\n| Type | Default | Recommended |\n|------|---------|-------------|\n| Memory | 512 KB | 20 MB |\n| Disk | 10 MB | 100 MB |\n\n## URLCache Configuration\n\n```swift\n// Default cache is too small - configure early in app lifecycle\nfunc application(_ application: UIApplication,\n                 didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n    URLCache.shared = URLCache(\n        memoryCapacity: 20 * 1024 * 1024,  // 20 MB\n        diskCapacity: 100 * 1024 * 1024,    // 100 MB\n        directory: nil\n    )\n    return true\n}\n```\n\n**Cache rules**: Response must be <= 5% of disk cache size to be cached. ([Apple Developer Documentation](https://developer.apple.com/documentation/foundation/urlsessiondatadelegate/urlsession(_:datatask:willcacheresponse:completionhandler:)))\n\n## Session Configuration\n\n### Default Configuration\n\n```swift\nlet config = URLSessionConfiguration.default\nconfig.timeoutIntervalForRequest = 30.0\nconfig.timeoutIntervalForResource = 300.0  // Not 7 days!\nconfig.waitsForConnectivity = true\nlet session = URLSession(configuration: config)\n```\n\n### Ephemeral (Privacy Mode)\n\n```swift\n// No disk persistence - RAM only\nlet session = URLSession(configuration: .ephemeral)\n```\n\n### Background Configuration\n\n```swift\nlet config = URLSessionConfiguration.background(\n    withIdentifier: \"com.yourapp.backgroundSession\"\n)\nconfig.isDiscretionary = false  // Start immediately\nconfig.sessionSendsLaunchEvents = true\nlet session = URLSession(configuration: config, delegate: self, delegateQueue: nil)\n```\n\n## Background Session Implementation\n\n### AppDelegate Handler (Required)\n\n```swift\nvar backgroundCompletionHandler: (() -> Void)?\n\nfunc application(_ application: UIApplication,\n                 handleEventsForBackgroundURLSession identifier: String,\n                 completionHandler: @escaping () -> Void) {\n    backgroundCompletionHandler = completionHandler\n}\n```\n\n### Delegate Methods\n\n```swift\nfunc urlSession(_ session: URLSession,\n                downloadTask: URLSessionDownloadTask,\n                didFinishDownloadingTo location: URL) {\n    // Move file immediately - location deleted after method returns\n    try? FileManager.default.moveItem(at: location, to: permanentURL)\n}\n\nfunc urlSessionDidFinishEvents(forBackgroundURLSession session: URLSession) {\n    DispatchQueue.main.async {\n        self.backgroundCompletionHandler?()\n        self.backgroundCompletionHandler = nil\n    }\n}\n```\n\n## Connection Pooling\n\n```swift\n// CORRECT: Reuse sessions for HTTP/2 multiplexing\nclass NetworkService {\n    static let shared = NetworkService()\n    private let session = URLSession(configuration: .default)\n}\n\n// ANTI-PATTERN: New session per request - loses pooling\nfunc badFetch(_ url: URL) async throws -> Data {\n    let session = URLSession(configuration: .default)  // Bad!\n    return try await session.data(from: url).0\n}\n```\n\n## Critical Anti-Patterns\n\n### 1. Memory Leak from Strong Delegate\n\n```swift\n// BUG: URLSession retains delegate forever\nclass LeakyManager {\n    var session: URLSession!\n    init() {\n        session = URLSession(configuration: .default, delegate: self, delegateQueue: nil)\n    }\n    // deinit never called - memory leak\n}\n\n// CORRECT: Invalidate session\nclass CorrectManager {\n    var session: URLSession!\n    init() {\n        session = URLSession(configuration: .default, delegate: self, delegateQueue: nil)\n    }\n    deinit {\n        session.finishTasksAndInvalidate()\n    }\n}\n```\n\n### 2. Background Session Identifier Conflicts\n\n```swift\n// BUG: Same identifier in app and extension\n// Main app\nlet config = URLSessionConfiguration.background(withIdentifier: \"downloads\")\n// Extension (CONFLICT!)\nlet config = URLSessionConfiguration.background(withIdentifier: \"downloads\")\n\n// CORRECT: Unique per process\n\"com.yourapp.main.downloads\"\n\"com.yourapp.extension.downloads\"\n```\n\n### 3. Data-Based Background Uploads\n\n```swift\n// BUG: Data uploads don't persist in background\nbackgroundSession.uploadTask(with: request, from: data)  // Fails!\n\n// CORRECT: File-based uploads\nlet fileURL = saveDataToFile(data)\nbackgroundSession.uploadTask(with: request, fromFile: fileURL)\n```\n\n### 4. Completion Handlers in Background Sessions\n\n```swift\n// BUG: Completion handlers not called\nbackgroundSession.dataTask(with: url) { data, _, _ in\n    // Never executed!\n}\n\n// CORRECT: Use delegate methods only\n```\n\n### 5. Inadequate Cache Size\n\n```swift\n// BUG: Default 512KB memory, 10MB disk - too small\nlet session = URLSession.shared\n\n// CORRECT: Configure adequate cache\nURLCache.shared = URLCache(\n    memoryCapacity: 20 * 1024 * 1024,\n    diskCapacity: 100 * 1024 * 1024,\n    directory: nil\n)\n```\n\n### 6. Battery Drain from Immediate Transfers\n\n```swift\n// ANTI-PATTERN: Non-urgent but immediate\nconfig.isDiscretionary = false  // Immediate regardless of conditions\n\n// CORRECT: Let system optimize\nconfig.isDiscretionary = true  // Waits for WiFi, charging\n```\n\n### 7. Missing Background Event Handler\n\n```swift\n// BUG: No handleEventsForBackgroundURLSession\nclass IncompleteAppDelegate: UIResponder, UIApplicationDelegate {\n    // App never notified of completion\n}\n```\n\n### 8. Unresumed Tasks\n\n```swift\n// BUG: Task created but never resumed\ntask = session.dataTask(with: url) { ... }\n// MISSING: task.resume()\n// Completion handler retained indefinitely\n\n// CORRECT\ntask.resume()  // Always call\n```\n\n## Review Questions\n\n### Cache\n- [ ] Is URLCache configured with adequate capacity?\n- [ ] Is cache configured before network calls?\n- [ ] Is ephemeral config used for sensitive data?\n\n### Session Management\n- [ ] Are sessions reused (not created per request)?\n- [ ] Is session invalidated when done?\n- [ ] Are timeouts configured (not 7-day default)?\n\n### Background Sessions\n- [ ] Is identifier unique (especially with extensions)?\n- [ ] Is `handleEventsForBackgroundURLSession` implemented?\n- [ ] Is `urlSessionDidFinishEvents` calling completion handler?\n- [ ] Are uploads file-based (not data-based)?\n- [ ] Are delegate methods used (not completion handlers)?\n- [ ] Is `isDiscretionary` set for non-urgent transfers?\n- [ ] Is background session at app level (not ViewController)?\n\n### Memory\n- [ ] Is session delegate invalidated to break retain cycle?\n- [ ] Are tasks always resumed after creation?\n",
        "skills/urlsession-code-review/references/error-handling.md": "# URLSession Error Handling Reference\n\n## Quick Reference\n\n### URLError Codes\n\n| Code | Name | Retryable | User Message |\n|------|------|-----------|--------------|\n| -1009 | `notConnectedToInternet` | No* | \"You're offline\" |\n| -1001 | `timedOut` | Yes | \"Request timed out\" |\n| -999 | `cancelled` | No | (Silent) |\n| -1003 | `cannotFindHost` | Yes | \"Unable to reach server\" |\n| -1004 | `cannotConnectToHost` | Yes | \"Unable to connect\" |\n| -1005 | `networkConnectionLost` | Yes | \"Connection lost\" |\n| -1200 | `secureConnectionFailed` | No | \"Security error\" |\n\n*Wait for network to reconnect\n\n### HTTP Status Codes\n\n| Range | Category | Retryable | Handling |\n|-------|----------|-----------|----------|\n| 200-299 | Success | N/A | Process response |\n| 400 | Bad Request | No | Show validation error |\n| 401 | Unauthorized | No | Re-authenticate |\n| 404 | Not Found | No | Show not found |\n| 429 | Too Many Requests | Yes | Respect Retry-After |\n| 500-599 | Server Error | Yes | Retry with backoff |\n\n## Transport vs HTTP Errors\n\n**Critical**: URLSession does NOT treat non-2xx status codes as errors automatically.\n\n```swift\n// Transport errors via error parameter\nif let error = error as? URLError {\n    switch error.code {\n    case .notConnectedToInternet: // Device offline\n    case .timedOut: // Request timed out\n    case .cancelled: // User cancelled\n    default: break\n    }\n}\n\n// HTTP errors via status code (MUST check manually)\nguard let httpResponse = response as? HTTPURLResponse,\n      (200...299).contains(httpResponse.statusCode) else {\n    // Server returned error - data may contain error body\n}\n```\n\n## Response Validation\n\n```swift\nfunc validateResponse(_ data: Data?, _ response: URLResponse?, _ error: Error?) throws -> Data {\n    // 1. Transport errors first\n    if let error = error {\n        throw NetworkError.transport(error)\n    }\n    // 2. Validate response type\n    guard let httpResponse = response as? HTTPURLResponse else {\n        throw NetworkError.invalidResponse\n    }\n    // 3. Check status code\n    guard (200...299).contains(httpResponse.statusCode) else {\n        throw NetworkError.httpError(httpResponse.statusCode, data)\n    }\n    // 4. Validate data\n    guard let data = data, !data.isEmpty else {\n        throw NetworkError.noData\n    }\n    return data\n}\n```\n\n## Retry Strategy\n\n### Determining Retryability\n\n```swift\nextension URLError.Code {\n    var isRetryable: Bool {\n        switch self {\n        case .timedOut, .cannotFindHost, .cannotConnectToHost,\n             .networkConnectionLost, .dnsLookupFailed:\n            return true\n        case .notConnectedToInternet, .cancelled,\n             .secureConnectionFailed, .userAuthenticationRequired:\n            return false\n        default:\n            return false\n        }\n    }\n}\n\nextension Int {\n    var isRetryableStatusCode: Bool {\n        [408, 429, 500, 502, 503, 504].contains(self)\n    }\n}\n```\n\n### Exponential Backoff with Jitter\n\n```swift\nstruct RetryConfiguration {\n    let maxRetries: Int = 3\n    let baseDelay: TimeInterval = 1.0\n    let maxDelay: TimeInterval = 30.0\n\n    func delay(for attempt: Int) -> TimeInterval {\n        let exponential = baseDelay * pow(2.0, Double(attempt))\n        let clamped = min(exponential, maxDelay)\n        let jitter = Double.random(in: 0...(0.1 * clamped))\n        return clamped + jitter\n    }\n}\n```\n\n### Retry-After Header\n\n```swift\nfunc retryDelay(from response: HTTPURLResponse, fallback: TimeInterval) -> TimeInterval {\n    if let retryAfter = response.value(forHTTPHeaderField: \"Retry-After\"),\n       let seconds = Double(retryAfter) {\n        return seconds\n    }\n    return fallback\n}\n```\n\n## Network Conditions\n\n### waitsForConnectivity (Recommended)\n\n```swift\nlet config = URLSessionConfiguration.default\nconfig.waitsForConnectivity = true  // Wait instead of failing\nconfig.timeoutIntervalForResource = 300  // Don't use 7-day default\n\n// Delegate for UI feedback\nfunc urlSession(_ session: URLSession,\n                taskIsWaitingForConnectivity task: URLSessionTask) {\n    // Show \"waiting for network\" UI\n}\n```\n\n**Important**: Don't pre-check network before requests - race condition.\n\n## Critical Anti-Patterns\n\n### 1. Silent Error Swallowing\n\n```swift\n// DANGEROUS\nURLSession.shared.dataTask(with: request) { data, _, error in\n    guard let data = data else { return }  // Error ignored!\n}\n\n// CORRECT\nURLSession.shared.dataTask(with: request) { data, response, error in\n    if let error = error { handleError(error); return }\n    guard let httpResponse = response as? HTTPURLResponse,\n          (200...299).contains(httpResponse.statusCode) else {\n        handleHTTPError(response); return\n    }\n    guard let data = data else { handleNoData(); return }\n}\n```\n\n### 2. Missing Status Code Validation\n\n```swift\n// DANGEROUS: Assumes nil error means success\nlet (data, _) = try await URLSession.shared.data(for: request)\nreturn data  // Could be 404 error page!\n\n// CORRECT\nlet (data, response) = try await URLSession.shared.data(for: request)\nguard let httpResponse = response as? HTTPURLResponse,\n      (200...299).contains(httpResponse.statusCode) else {\n    throw NetworkError.httpError\n}\n```\n\n### 3. Retrying Non-Retryable Errors\n\n```swift\n// DANGEROUS: Retrying 401 won't help\nfor _ in 0..<3 {\n    do { return try await fetch() }\n    catch { continue }  // Retries ALL errors\n}\n\n// CORRECT\ncatch let error as URLError where error.code.isRetryable {\n    continue  // Only retry network issues\n}\n```\n\n### 4. Blocking Retry Without Backoff\n\n```swift\n// DANGEROUS: Hammers server\nwhile true {\n    do { return try await fetch() }\n    catch { continue }  // Immediate retry\n}\n\n// CORRECT: Exponential backoff\nfor attempt in 0..<maxRetries {\n    do { return try await fetch() }\n    catch {\n        let delay = baseDelay * pow(2.0, Double(attempt))\n        try await Task.sleep(nanoseconds: UInt64(delay * 1_000_000_000))\n    }\n}\n```\n\n### 5. Technical Errors to Users\n\n```swift\n// DANGEROUS\nshowAlert(error.localizedDescription)\n// \"Error Domain=NSURLErrorDomain Code=-1004...\"\n\n// CORRECT\nshowAlert(userFriendlyMessage(for: error))\n// \"Unable to connect. Please check your internet.\"\n```\n\n### 6. Ignoring Cancellation\n\n```swift\n// DANGEROUS: Shows error for user cancel\ncatch { showError(error) }\n\n// CORRECT\ncatch let error as URLError where error.code == .cancelled {\n    return  // Silent - user initiated\n}\ncatch { showError(error) }\n```\n\n## Review Questions\n\n### Error Handling\n- [ ] Are both transport errors and HTTP status codes handled?\n- [ ] Is there a centralized error handling strategy?\n- [ ] Are error types mapped to user-friendly messages?\n\n### Response Validation\n- [ ] Is response cast to HTTPURLResponse?\n- [ ] Are non-2xx status codes treated as errors?\n- [ ] Are error response bodies parsed for messages?\n\n### Retry Logic\n- [ ] Are only appropriate errors retried (not 4xx)?\n- [ ] Is exponential backoff with jitter implemented?\n- [ ] Is there a maximum retry count?\n- [ ] Is Retry-After header respected for 429/503?\n\n### User Experience\n- [ ] Are cancellation errors handled silently?\n- [ ] Is there a retry option for recoverable errors?\n- [ ] Are authentication errors handled separately?\n",
        "skills/urlsession-code-review/references/request-building.md": "# URLRequest Building Reference\n\n## Quick Reference\n\n### URLRequest Configuration\n\n| Property | Type | Default | Description |\n|----------|------|---------|-------------|\n| `url` | `URL?` | nil | Request URL |\n| `httpMethod` | `String?` | \"GET\" | HTTP method |\n| `httpBody` | `Data?` | nil | Request body |\n| `timeoutInterval` | `TimeInterval` | 60.0 | Timeout in seconds |\n| `cachePolicy` | `CachePolicy` | `.useProtocolCachePolicy` | Cache behavior |\n\n### Cache Policies\n\n| Policy | Use Case |\n|--------|----------|\n| `.useProtocolCachePolicy` | Default; respects server headers |\n| `.reloadIgnoringLocalCacheData` | Always fetch fresh |\n| `.returnCacheDataElseLoad` | Offline-first apps |\n| `.returnCacheDataDontLoad` | Strictly offline |\n\n### Content-Types\n\n| Content Type | Use Case |\n|--------------|----------|\n| `application/json` | JSON body |\n| `application/x-www-form-urlencoded` | Form data |\n| `multipart/form-data; boundary=xxx` | File uploads |\n\n## HTTP Headers\n\n```swift\n// Set headers\nrequest.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\nrequest.setValue(\"Bearer \\(token)\", forHTTPHeaderField: \"Authorization\")\n\n// Set all at once\nrequest.allHTTPHeaderFields = [\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"application/json\"\n]\n```\n\n## Body Encoding\n\n### JSON (Recommended)\n\n```swift\nstruct CreateUserRequest: Encodable {\n    let name: String\n    let email: String\n}\n\nlet body = CreateUserRequest(name: \"John\", email: \"john@example.com\")\nrequest.httpBody = try JSONEncoder().encode(body)\nrequest.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n```\n\n### Form URL Encoded\n\n```swift\n// CORRECT: Use URLComponents for proper encoding\nvar components = URLComponents()\ncomponents.queryItems = [\n    URLQueryItem(name: \"username\", value: \"john\"),\n    URLQueryItem(name: \"password\", value: \"secret\")\n]\n// percentEncodedQuery encodes spaces as + and handles reserved characters\nrequest.httpBody = components.percentEncodedQuery?.data(using: .utf8)\nrequest.setValue(\"application/x-www-form-urlencoded\", forHTTPHeaderField: \"Content-Type\")\n```\n\n> **Warning**: Don't use `.urlQueryAllowed` for form-encoded values. It includes reserved characters (`&`, `=`, `+`, `/`, `?`) that must be escaped in parameter values. Use `URLComponents` or a custom charset with only RFC 3986 unreserved characters.\n\n### Multipart Form Data\n\n```swift\nlet boundary = UUID().uuidString\nrequest.setValue(\"multipart/form-data; boundary=\\(boundary)\", forHTTPHeaderField: \"Content-Type\")\n\nvar body = Data()\nbody.append(\"--\\(boundary)\\r\\n\".data(using: .utf8)!)\nbody.append(\"Content-Disposition: form-data; name=\\\"file\\\"; filename=\\\"image.jpg\\\"\\r\\n\".data(using: .utf8)!)\nbody.append(\"Content-Type: image/jpeg\\r\\n\\r\\n\".data(using: .utf8)!)\nbody.append(imageData)\nbody.append(\"\\r\\n--\\(boundary)--\\r\\n\".data(using: .utf8)!)\nrequest.httpBody = body\n```\n\n## URL Query Parameters\n\n```swift\n// CORRECT: Use URLComponents\nvar components = URLComponents(string: \"https://api.example.com/search\")!\ncomponents.queryItems = [\n    URLQueryItem(name: \"query\", value: \"swift programming\"),\n    URLQueryItem(name: \"page\", value: \"1\")\n]\nlet request = URLRequest(url: components.url!)\n\n// Handle plus signs (not encoded by default)\nlet encodedValue = value?.replacingOccurrences(of: \"+\", with: \"%2B\")\n```\n\n## Timeout Configuration\n\n```swift\n// Request-level\nvar request = URLRequest(url: url)\nrequest.timeoutInterval = 30.0\n\n// Session-level\nlet config = URLSessionConfiguration.default\nconfig.timeoutIntervalForRequest = 30.0   // Resets on each packet\nconfig.timeoutIntervalForResource = 300.0 // Total time (default: 7 days!)\n```\n\n> **Note**: Per-request `timeoutInterval` only takes effect if it's not more restrictive than the session's `timeoutIntervalForRequest`. If the session enforces a stricter limit, that limit applies instead.\n\n## Critical Anti-Patterns\n\n### 1. CRLF Injection (CVE-2022-3918)\n\n> **Note**: This vulnerability affects swift-corelibs-foundation versions before 5.7.3. In 5.7.3+, URLRequest rejects CR/LF in header values at the framework level. Manual sanitization is only needed for projects that cannot upgrade.\n\n```swift\n// DANGEROUS: User input in headers (affects swift-corelibs-foundation < 5.7.3)\nlet userInput = \"value\\r\\nEvil-Header: injected\"\nrequest.setValue(userInput, forHTTPHeaderField: \"X-Custom\")\n\n// SAFE: Sanitize header values (for pre-5.7.3 or as defense-in-depth)\nlet sanitized = userInput.replacingOccurrences(of: \"\\r\", with: \"\")\n    .replacingOccurrences(of: \"\\n\", with: \"\")\nrequest.setValue(sanitized, forHTTPHeaderField: \"X-Custom\")\n```\n\n### 2. Hardcoded Secrets\n\n```swift\n// DANGEROUS\nrequest.setValue(\"sk_live_abc123xyz\", forHTTPHeaderField: \"Authorization\")\n\n// SAFE: From Keychain\nlet token = KeychainService.shared.getAPIToken()\nrequest.setValue(\"Bearer \\(token)\", forHTTPHeaderField: \"Authorization\")\n```\n\n### 3. Content-Type/Body Mismatch\n\n```swift\n// BUG: JSON body but wrong Content-Type\nrequest.httpBody = try JSONEncoder().encode(user)\nrequest.setValue(\"text/plain\", forHTTPHeaderField: \"Content-Type\")\n\n// CORRECT\nrequest.httpBody = try JSONEncoder().encode(user)\nrequest.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n```\n\n### 4. Manual URL Concatenation\n\n```swift\n// DANGEROUS: Injection risk\nlet url = URL(string: \"https://api.com/search?q=\\(userQuery)\")!\n\n// SAFE: URLComponents\nvar components = URLComponents(string: \"https://api.com/search\")!\ncomponents.queryItems = [URLQueryItem(name: \"q\", value: userQuery)]\n```\n\n### 5. Memory Issues with Large Files\n\n```swift\n// DANGEROUS: Loads entire file into memory\nlet largeFileData = try Data(contentsOf: largeFileURL)\nrequest.httpBody = largeFileData\n\n// SAFE: Use file-based upload\nsession.uploadTask(with: request, fromFile: largeFileURL)\n```\n\n### 6. Creating Sessions Per Request\n\n```swift\n// INEFFICIENT\nfunc makeRequest() {\n    let session = URLSession(configuration: .default)  // New each time!\n    session.dataTask(with: request).resume()\n}\n\n// EFFICIENT: Reuse session\nclass NetworkManager {\n    private let session = URLSession(configuration: .default)\n}\n```\n\n## Review Questions\n\n### Security\n- [ ] Are header values sanitized for CRLF characters?\n- [ ] Are secrets from Keychain, not hardcoded?\n- [ ] Is SSL/TLS validation proper (no blanket trust)?\n- [ ] Are credentials excluded from URLs and logs?\n\n### Correctness\n- [ ] Does Content-Type match body encoding?\n- [ ] Is HTTP method appropriate (no body on GET)?\n- [ ] Are query parameters built with URLComponents?\n- [ ] Are special characters (+, ;, ,) encoded correctly?\n\n### Performance\n- [ ] Is URLSession reused across requests?\n- [ ] Are timeouts configured appropriately?\n- [ ] Are large uploads using file-based API?\n- [ ] Is `timeoutIntervalForResource` set (not 7-day default)?\n",
        "skills/vercel-ai-sdk/SKILL.md": "---\nname: vercel-ai-sdk\ndescription: Vercel AI SDK for building chat interfaces with streaming. Use when implementing useChat hook, handling tool calls, streaming responses, or building chat UI. Triggers on useChat, @ai-sdk/react, UIMessage, ChatStatus, streamText, toUIMessageStreamResponse, addToolOutput, onToolCall, sendMessage.\n---\n\n# Vercel AI SDK\n\nThe Vercel AI SDK provides React hooks and server utilities for building streaming chat interfaces with support for tool calls, file attachments, and multi-step reasoning.\n\n## Quick Reference\n\n### Basic useChat Setup\n\n```typescript\nimport { useChat } from '@ai-sdk/react';\n\nconst { messages, status, sendMessage, stop, regenerate } = useChat({\n  id: 'chat-id',\n  messages: initialMessages,\n  onFinish: ({ message, messages, isAbort, isError }) => {\n    console.log('Chat finished');\n  },\n  onError: (error) => {\n    console.error('Chat error:', error);\n  }\n});\n\n// Send a message\nsendMessage({ text: 'Hello', metadata: { createdAt: Date.now() } });\n\n// Send with files\nsendMessage({\n  text: 'Analyze this',\n  files: fileList // FileList or FileUIPart[]\n});\n```\n\n### ChatStatus States\n\nThe `status` field indicates the current state of the chat:\n\n- **`ready`**: Chat is idle and ready to accept new messages\n- **`submitted`**: Message sent to API, awaiting response stream start\n- **`streaming`**: Response actively streaming from the API\n- **`error`**: An error occurred during the request\n\n### Message Structure\n\nMessages use the `UIMessage` type with a parts-based structure:\n\n```typescript\ninterface UIMessage {\n  id: string;\n  role: 'system' | 'user' | 'assistant';\n  metadata?: unknown;\n  parts: Array<UIMessagePart>; // text, file, tool-*, reasoning, etc.\n}\n```\n\nPart types include:\n- `text`: Text content with optional streaming state\n- `file`: File attachments (images, documents)\n- `tool-{toolName}`: Tool invocations with state machine\n- `reasoning`: AI reasoning traces\n- `data-{typeName}`: Custom data parts\n\n### Server-Side Streaming\n\n```typescript\nimport { streamText } from 'ai';\nimport { convertToModelMessages } from 'ai';\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n  tools: {\n    getWeather: tool({\n      description: 'Get weather',\n      inputSchema: z.object({ city: z.string() }),\n      execute: async ({ city }) => {\n        return { temperature: 72, weather: 'sunny' };\n      }\n    })\n  }\n});\n\nreturn result.toUIMessageStreamResponse({\n  originalMessages: uiMessages,\n  onFinish: ({ messages }) => {\n    // Save to database\n  }\n});\n```\n\n### Tool Handling Patterns\n\n**Client-Side Tool Execution:**\n```typescript\nconst { addToolOutput } = useChat({\n  onToolCall: async ({ toolCall }) => {\n    if (toolCall.toolName === 'getLocation') {\n      addToolOutput({\n        tool: 'getLocation',\n        toolCallId: toolCall.toolCallId,\n        output: 'San Francisco'\n      });\n    }\n  }\n});\n```\n\n**Rendering Tool States:**\n```typescript\n{message.parts.map(part => {\n  if (part.type === 'tool-getWeather') {\n    switch (part.state) {\n      case 'input-streaming':\n        return <pre>{JSON.stringify(part.input, null, 2)}</pre>;\n      case 'input-available':\n        return <div>Getting weather for {part.input.city}...</div>;\n      case 'output-available':\n        return <div>Weather: {part.output.weather}</div>;\n      case 'output-error':\n        return <div>Error: {part.errorText}</div>;\n    }\n  }\n})}\n```\n\n## Reference Files\n\nDetailed documentation on specific aspects:\n\n- **[use-chat.md](references/use-chat.md)**: Complete useChat API reference\n- **[messages.md](references/messages.md)**: UIMessage structure and part types\n- **[streaming.md](references/streaming.md)**: Server-side streaming implementation\n- **[tools.md](references/tools.md)**: Tool definition and execution patterns\n\n## Common Patterns\n\n### Error Handling\n\n```typescript\nconst { error, clearError } = useChat({\n  onError: (error) => {\n    toast.error(error.message);\n  }\n});\n\n// Clear error and reset to ready state\nif (error) {\n  clearError();\n}\n```\n\n### Message Regeneration\n\n```typescript\nconst { regenerate } = useChat();\n\n// Regenerate last assistant message\nawait regenerate();\n\n// Regenerate specific message\nawait regenerate({ messageId: 'msg-123' });\n```\n\n### Custom Transport\n\n```typescript\nimport { DefaultChatTransport } from 'ai';\n\nconst { messages } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/chat',\n    prepareSendMessagesRequest: ({ id, messages, trigger, messageId }) => ({\n      body: {\n        chatId: id,\n        lastMessage: messages[messages.length - 1],\n        trigger,\n        messageId\n      }\n    })\n  })\n});\n```\n\n### Performance Optimization\n\n```typescript\n// Throttle UI updates to reduce re-renders\nconst chat = useChat({\n  experimental_throttle: 100 // Update max once per 100ms\n});\n```\n\n### Automatic Message Sending\n\n```typescript\nimport { lastAssistantMessageIsCompleteWithToolCalls } from 'ai';\n\nconst chat = useChat({\n  sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls\n  // Automatically resend when all tool calls have outputs\n});\n```\n\n## Type Safety\n\nThe SDK provides full type inference for tools and messages:\n\n```typescript\nimport { InferUITools, UIMessage } from 'ai';\n\nconst tools = {\n  getWeather: tool({\n    inputSchema: z.object({ city: z.string() }),\n    execute: async ({ city }) => ({ weather: 'sunny' })\n  })\n};\n\ntype MyMessage = UIMessage<\n  { createdAt: number }, // Metadata type\n  UIDataTypes,\n  InferUITools<typeof tools> // Tool types\n>;\n\nconst { messages } = useChat<MyMessage>();\n```\n\n## Key Concepts\n\n### Parts-Based Architecture\n\nMessages use a parts array instead of a single content field. This allows:\n- Streaming text while maintaining other parts\n- Tool calls with independent state machines\n- File attachments and custom data mixed with text\n\n### Tool State Machine\n\nTool parts progress through states:\n1. `input-streaming`: Tool input streaming (optional)\n2. `input-available`: Tool input complete\n3. `approval-requested`: Waiting for user approval (optional)\n4. `approval-responded`: User approved/denied (optional)\n5. `output-available`: Tool execution complete\n6. `output-error`: Tool execution failed\n7. `output-denied`: User denied approval\n\n### Streaming Protocol\n\nThe SDK uses Server-Sent Events (SSE) with UIMessageChunk types:\n- `text-start`, `text-delta`, `text-end`\n- `tool-input-available`, `tool-output-available`\n- `reasoning-start`, `reasoning-delta`, `reasoning-end`\n- `start`, `finish`, `abort`\n\n### Client vs Server Tools\n\n**Server-side tools** have an `execute` function and run on the API route.\n\n**Client-side tools** omit `execute` and are handled via `onToolCall` and `addToolOutput`.\n\n## Best Practices\n\n1. Always handle the `error` state and provide user feedback\n2. Use `experimental_throttle` for high-frequency updates\n3. Implement proper loading states based on `status`\n4. Type your messages with custom metadata and tools\n5. Use `sendAutomaticallyWhen` for multi-turn tool workflows\n6. Handle all tool states in the UI for better UX\n7. Use `stop()` to allow users to cancel long-running requests\n8. Validate messages with `validateUIMessages` on the server\n",
        "skills/vercel-ai-sdk/references/messages.md": "# UIMessage Structure Reference\n\nComplete reference for the UIMessage type system and message parts.\n\n## Table of Contents\n\n- [UIMessage Interface](#uimessage-interface)\n- [Message Parts](#message-parts)\n- [Text Parts](#text-parts)\n- [Tool Parts](#tool-parts)\n- [File Parts](#file-parts)\n- [Reasoning Parts](#reasoning-parts)\n- [Data Parts](#data-parts)\n- [Type Guards](#type-guards)\n- [Type Inference](#type-inference)\n\n## UIMessage Interface\n\n```typescript\ninterface UIMessage<\n  METADATA = unknown,\n  DATA_PARTS extends UIDataTypes = UIDataTypes,\n  TOOLS extends UITools = UITools,\n> {\n  // Unique identifier\n  id: string;\n\n  // Message role\n  role: 'system' | 'user' | 'assistant';\n\n  // Optional custom metadata\n  metadata?: METADATA;\n\n  // Array of message parts\n  parts: Array<UIMessagePart<DATA_PARTS, TOOLS>>;\n}\n```\n\n### Role Guidelines\n\n- **`system`**: System prompts (avoid in UI messages, set on server instead)\n- **`user`**: User-generated messages (text, files)\n- **`assistant`**: AI-generated messages (text, reasoning, tools, files)\n\n### Parts-Based Architecture\n\nUnlike traditional chat systems with single `content` fields, UIMessages use a `parts` array. This enables:\n\n- Multiple content types in a single message\n- Independent streaming states for each part\n- Tool calls with their own state machines\n- File attachments mixed with text\n- Custom data parts for specialized UI\n\n## Message Parts\n\n```typescript\ntype UIMessagePart<DATA_TYPES, TOOLS> =\n  | TextUIPart\n  | ReasoningUIPart\n  | ToolUIPart<TOOLS>\n  | DynamicToolUIPart\n  | SourceUrlUIPart\n  | SourceDocumentUIPart\n  | FileUIPart\n  | DataUIPart<DATA_TYPES>\n  | StepStartUIPart;\n```\n\n## Text Parts\n\n### TextUIPart\n\n```typescript\ninterface TextUIPart {\n  type: 'text';\n  text: string;\n  state?: 'streaming' | 'done';\n  providerMetadata?: ProviderMetadata;\n}\n```\n\n### Usage\n\n```typescript\n// Complete text\nconst textPart: TextUIPart = {\n  type: 'text',\n  text: 'Hello, world!',\n  state: 'done'\n};\n\n// Streaming text\nconst streamingPart: TextUIPart = {\n  type: 'text',\n  text: 'Hello, wor',\n  state: 'streaming'\n};\n```\n\n### Rendering\n\n```typescript\nfunction renderTextPart(part: TextUIPart) {\n  return (\n    <div className={part.state === 'streaming' ? 'opacity-70' : ''}>\n      {part.text}\n      {part.state === 'streaming' && <Cursor />}\n    </div>\n  );\n}\n```\n\n## Tool Parts\n\n### ToolUIPart\n\nType-safe tool parts with tool name in the type.\n\n```typescript\ntype ToolUIPart<TOOLS extends UITools> = ValueOf<{\n  [NAME in keyof TOOLS & string]: {\n    type: `tool-${NAME}`;\n  } & UIToolInvocation<TOOLS[NAME]>;\n}>;\n```\n\n### UIToolInvocation States\n\nTool parts have a state machine with the following states:\n\n```typescript\ntype UIToolInvocation<TOOL> =\n  | { state: 'input-streaming'; input: Partial<ToolInput> | undefined; }\n  | { state: 'input-available'; input: ToolInput; callProviderMetadata?: ProviderMetadata; }\n  | { state: 'approval-requested'; input: ToolInput; approval: { id: string }; }\n  | { state: 'approval-responded'; input: ToolInput; approval: { id: string; approved: boolean; reason?: string }; }\n  | { state: 'output-available'; input: ToolInput; output: ToolOutput; preliminary?: boolean; }\n  | { state: 'output-error'; input: ToolInput | undefined; errorText: string; }\n  | { state: 'output-denied'; input: ToolInput; approval: { id: string; approved: false; reason?: string }; }\n```\n\n**Common fields:**\n- `toolCallId: string` - Unique identifier for this tool call\n- `title?: string` - Optional display title\n- `providerExecuted?: boolean` - True if provider executed the tool\n\n### State Progression\n\n```\ninput-streaming  input-available  [approval flow]  output-available\n                                  \n                            approval-requested  approval-responded  output-available/output-denied\n                                                                    \n                                                              (at any point)  output-error\n```\n\n### Example: Rendering Tool Parts\n\n```typescript\nfunction renderToolPart(part: ToolUIPart<MyTools>) {\n  // Extract common fields\n  const { toolCallId, title } = part;\n\n  // Type narrows based on tool type\n  if (part.type === 'tool-getWeather') {\n    switch (part.state) {\n      case 'input-streaming':\n        return (\n          <div>\n            Preparing weather request...\n            <pre>{JSON.stringify(part.input, null, 2)}</pre>\n          </div>\n        );\n\n      case 'input-available':\n        return <div>Fetching weather for {part.input.city}...</div>;\n\n      case 'output-available':\n        return (\n          <div>\n            Weather in {part.input.city}: {part.output.weather}\n            {part.preliminary && <Badge>Preliminary</Badge>}\n          </div>\n        );\n\n      case 'output-error':\n        return <div className=\"error\">{part.errorText}</div>;\n    }\n  }\n\n  if (part.type === 'tool-askConfirmation') {\n    switch (part.state) {\n      case 'approval-requested':\n        return (\n          <div>\n            {part.input.message}\n            <button onClick={() => approve(part.approval.id)}>Yes</button>\n            <button onClick={() => deny(part.approval.id)}>No</button>\n          </div>\n        );\n\n      case 'approval-responded':\n        return (\n          <div>\n            User {part.approval.approved ? 'approved' : 'denied'}\n            {part.approval.reason && `: ${part.approval.reason}`}\n          </div>\n        );\n    }\n  }\n}\n```\n\n### DynamicToolUIPart\n\nFor tools not known at compile time.\n\n```typescript\ninterface DynamicToolUIPart {\n  type: 'dynamic-tool';\n  toolName: string; // Name as string, not in type\n  toolCallId: string;\n  title?: string;\n  providerExecuted?: boolean;\n  // Same state union as UIToolInvocation but with unknown types\n  state: 'input-streaming' | 'input-available' | ...;\n  input: unknown;\n  output?: unknown;\n  errorText?: string;\n}\n```\n\n### Tool Type Utilities\n\n```typescript\n// Check if part is a tool part\nif (isToolUIPart(part)) {\n  const toolName = getToolName(part); // Type-safe tool name\n}\n\n// Check if tool or dynamic tool\nif (isToolOrDynamicToolUIPart(part)) {\n  const name = getToolOrDynamicToolName(part); // string\n}\n\n// Check if dynamic tool\nif (isDynamicToolUIPart(part)) {\n  console.log(part.toolName); // Access toolName field\n}\n```\n\n## File Parts\n\n### FileUIPart\n\n```typescript\ninterface FileUIPart {\n  type: 'file';\n  mediaType: string; // IANA media type\n  filename?: string;\n  url: string; // Hosted URL or Data URL\n  providerMetadata?: ProviderMetadata;\n}\n```\n\n### Usage\n\n```typescript\n// Image file\nconst imagePart: FileUIPart = {\n  type: 'file',\n  mediaType: 'image/png',\n  filename: 'screenshot.png',\n  url: 'data:image/png;base64,iVBORw0KG...'\n};\n\n// PDF document\nconst pdfPart: FileUIPart = {\n  type: 'file',\n  mediaType: 'application/pdf',\n  filename: 'report.pdf',\n  url: 'https://example.com/files/report.pdf'\n};\n```\n\n### Rendering\n\n```typescript\nfunction renderFilePart(part: FileUIPart) {\n  if (part.mediaType.startsWith('image/')) {\n    return <img src={part.url} alt={part.filename} />;\n  }\n\n  if (part.mediaType.startsWith('video/')) {\n    return <video src={part.url} controls />;\n  }\n\n  return (\n    <a href={part.url} download={part.filename}>\n      {part.filename || 'Download file'}\n    </a>\n  );\n}\n```\n\n## Reasoning Parts\n\n### ReasoningUIPart\n\nFor AI reasoning traces (e.g., from OpenAI o1 models).\n\n```typescript\ninterface ReasoningUIPart {\n  type: 'reasoning';\n  text: string;\n  state?: 'streaming' | 'done';\n  providerMetadata?: ProviderMetadata;\n}\n```\n\n### Usage\n\n```typescript\nfunction renderReasoningPart(part: ReasoningUIPart) {\n  return (\n    <details>\n      <summary>Reasoning</summary>\n      <div className=\"reasoning\">\n        {part.text}\n        {part.state === 'streaming' && <Spinner />}\n      </div>\n    </details>\n  );\n}\n```\n\n## Data Parts\n\n### DataUIPart\n\nCustom data parts for specialized UI components.\n\n```typescript\ntype DataUIPart<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n  };\n}>;\n```\n\n### Defining Custom Data Types\n\n```typescript\n// Define data types\ntype MyDataTypes = {\n  progress: { percent: number; status: string };\n  chart: { data: number[]; labels: string[] };\n};\n\n// Use in message type\ntype MyMessage = UIMessage<unknown, MyDataTypes>;\n\n// Create data parts\nconst progressPart: DataUIPart<MyDataTypes> = {\n  type: 'data-progress',\n  data: { percent: 75, status: 'Processing...' }\n};\n\nconst chartPart: DataUIPart<MyDataTypes> = {\n  type: 'data-chart',\n  id: 'chart-1',\n  data: {\n    data: [10, 20, 30],\n    labels: ['A', 'B', 'C']\n  }\n};\n```\n\n### Rendering Custom Data\n\n```typescript\nfunction renderDataPart(part: UIMessagePart<MyDataTypes, MyTools>) {\n  if (isDataUIPart(part)) {\n    if (part.type === 'data-progress') {\n      return (\n        <ProgressBar\n          percent={part.data.percent}\n          label={part.data.status}\n        />\n      );\n    }\n\n    if (part.type === 'data-chart') {\n      return <Chart data={part.data.data} labels={part.data.labels} />;\n    }\n  }\n}\n```\n\n## Source Parts\n\n### SourceUrlUIPart\n\n```typescript\ninterface SourceUrlUIPart {\n  type: 'source-url';\n  sourceId: string;\n  url: string;\n  title?: string;\n  providerMetadata?: ProviderMetadata;\n}\n```\n\n### SourceDocumentUIPart\n\n```typescript\ninterface SourceDocumentUIPart {\n  type: 'source-document';\n  sourceId: string;\n  mediaType: string;\n  title: string;\n  filename?: string;\n  providerMetadata?: ProviderMetadata;\n}\n```\n\n### Usage\n\n```typescript\n// URL source\nconst urlSource: SourceUrlUIPart = {\n  type: 'source-url',\n  sourceId: 'src-1',\n  url: 'https://example.com/article',\n  title: 'Example Article'\n};\n\n// Document source\nconst docSource: SourceDocumentUIPart = {\n  type: 'source-document',\n  sourceId: 'src-2',\n  mediaType: 'application/pdf',\n  title: 'Research Paper',\n  filename: 'paper.pdf'\n};\n```\n\n## Step Parts\n\n### StepStartUIPart\n\nMarks the beginning of a new reasoning/execution step.\n\n```typescript\ninterface StepStartUIPart {\n  type: 'step-start';\n}\n```\n\n### Rendering\n\n```typescript\nfunction renderMessage(message: UIMessage) {\n  return (\n    <div>\n      {message.parts.map((part, index) => {\n        if (part.type === 'step-start' && index > 0) {\n          return <hr key={index} className=\"step-divider\" />;\n        }\n        return renderPart(part, index);\n      })}\n    </div>\n  );\n}\n```\n\n## Type Guards\n\n```typescript\n// Text\nif (isTextUIPart(part)) {\n  console.log(part.text);\n}\n\n// File\nif (isFileUIPart(part)) {\n  console.log(part.url, part.mediaType);\n}\n\n// Reasoning\nif (isReasoningUIPart(part)) {\n  console.log(part.text);\n}\n\n// Tool (static)\nif (isToolUIPart(part)) {\n  const toolName = getToolName(part);\n}\n\n// Dynamic tool\nif (isDynamicToolUIPart(part)) {\n  console.log(part.toolName);\n}\n\n// Tool or dynamic tool\nif (isToolOrDynamicToolUIPart(part)) {\n  const name = getToolOrDynamicToolName(part);\n}\n\n// Data\nif (isDataUIPart(part)) {\n  // Check specific data type\n  if (part.type === 'data-progress') {\n    console.log(part.data.percent);\n  }\n}\n```\n\n## Type Inference\n\n### Infer from UIMessage\n\n```typescript\ntype MyMessage = UIMessage<\n  { createdAt: number },\n  { progress: { percent: number } },\n  { getTool: { input: string; output: number } }\n>;\n\n// Infer metadata type\ntype Metadata = InferUIMessageMetadata<MyMessage>;\n// { createdAt: number }\n\n// Infer data types\ntype DataTypes = InferUIMessageData<MyMessage>;\n// { progress: { percent: number } }\n\n// Infer tool types\ntype Tools = InferUIMessageTools<MyMessage>;\n// { getTool: { input: string; output: number } }\n\n// Infer tool outputs\ntype ToolOutputs = InferUIMessageToolOutputs<MyMessage>;\n// number\n\n// Infer tool calls\ntype ToolCall = InferUIMessageToolCall<MyMessage>;\n// ToolCall<'getTool', string> | ...\n\n// Infer part type\ntype Part = InferUIMessagePart<MyMessage>;\n// TextUIPart | ToolUIPart<...> | DataUIPart<...> | ...\n```\n\n### Infer Tool Types\n\n```typescript\nimport { InferUITool, InferUITools } from 'ai';\n\nconst weatherTool = tool({\n  inputSchema: z.object({ city: z.string() }),\n  execute: async ({ city }) => ({ temp: 72 })\n});\n\n// Infer single tool\ntype WeatherTool = InferUITool<typeof weatherTool>;\n// { input: { city: string }; output: { temp: number } }\n\n// Infer tool set\nconst tools = { weather: weatherTool };\ntype MyTools = InferUITools<typeof tools>;\n// { weather: { input: { city: string }; output: { temp: number } } }\n```\n\n## Complete Example\n\n```typescript\nimport { UIMessage, InferUITools, isTextUIPart, isToolUIPart } from 'ai';\n\n// Define tools\nconst tools = {\n  getWeather: tool({\n    inputSchema: z.object({ city: z.string() }),\n    execute: async ({ city }) => ({ weather: 'sunny', temp: 72 })\n  })\n};\n\n// Define message type\ntype MyMessage = UIMessage<\n  { createdAt: number },\n  { progress: { percent: number } },\n  InferUITools<typeof tools>\n>;\n\n// Render function\nfunction Message({ message }: { message: MyMessage }) {\n  return (\n    <div className={`message message-${message.role}`}>\n      <div className=\"timestamp\">\n        {new Date(message.metadata.createdAt).toLocaleString()}\n      </div>\n\n      <div className=\"parts\">\n        {message.parts.map((part, index) => {\n          if (isTextUIPart(part)) {\n            return <div key={index}>{part.text}</div>;\n          }\n\n          if (part.type === 'tool-getWeather') {\n            if (part.state === 'output-available') {\n              return (\n                <div key={index}>\n                  Weather: {part.output.weather}, {part.output.temp}F\n                </div>\n              );\n            }\n          }\n\n          if (part.type === 'data-progress') {\n            return (\n              <ProgressBar\n                key={index}\n                percent={part.data.percent}\n              />\n            );\n          }\n\n          return null;\n        })}\n      </div>\n    </div>\n  );\n}\n```\n",
        "skills/vercel-ai-sdk/references/streaming.md": "# Streaming Reference\n\nServer-side streaming implementation with the Vercel AI SDK.\n\n## Table of Contents\n\n- [Basic Streaming Setup](#basic-streaming-setup)\n- [streamText Function](#streamtext-function)\n- [toUIMessageStreamResponse](#touimessagestreamresponse)\n- [UIMessageChunk Types](#uimessagechunk-types)\n- [SSE Protocol](#sse-protocol)\n- [Tool Execution Flow](#tool-execution-flow)\n- [Error Handling](#error-handling)\n- [Advanced Patterns](#advanced-patterns)\n\n## Basic Streaming Setup\n\n### Server Route\n\n```typescript\nimport { streamText, convertToModelMessages } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4'),\n    messages: convertToModelMessages(messages)\n  });\n\n  return result.toUIMessageStreamResponse();\n}\n```\n\n### Client Setup\n\n```typescript\nimport { useChat } from '@ai-sdk/react';\n\nfunction Chat() {\n  const { messages, sendMessage } = useChat({\n    api: '/api/chat'\n  });\n\n  return <ChatUI messages={messages} onSend={sendMessage} />;\n}\n```\n\n## streamText Function\n\n### Basic Options\n\n```typescript\nconst result = streamText({\n  // Model to use\n  model: openai('gpt-4'),\n\n  // Messages (converted from UIMessage)\n  messages: convertToModelMessages(uiMessages),\n\n  // System prompt (optional)\n  system: 'You are a helpful assistant.',\n\n  // Temperature, max tokens, etc.\n  temperature: 0.7,\n  maxTokens: 2000,\n\n  // Abort signal\n  abortSignal: abortController.signal\n});\n```\n\n### With Tools\n\n```typescript\nimport { tool } from 'ai';\nimport { z } from 'zod';\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  tools: {\n    getWeather: tool({\n      description: 'Get weather for a city',\n      inputSchema: z.object({\n        city: z.string()\n      }),\n      execute: async ({ city }) => {\n        const data = await fetchWeather(city);\n        return { temperature: data.temp, weather: data.conditions };\n      }\n    })\n  }\n});\n```\n\n### Multi-Step Tool Execution\n\n```typescript\nimport { stepCountIs } from 'ai';\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n  tools: {\n    getWeather: weatherTool,\n    searchWeb: searchTool\n  },\n\n  // Allow up to 5 steps (model can call tools multiple times)\n  stopWhen: stepCountIs(5)\n});\n```\n\n### Streaming Tool Outputs\n\n```typescript\nconst getWeatherTool = tool({\n  description: 'Get weather information',\n  inputSchema: z.object({ city: z.string() }),\n\n  // Generator function for streaming outputs\n  async *execute({ city }) {\n    // Yield preliminary results\n    yield { state: 'loading' as const };\n\n    const data = await fetchWeather(city);\n\n    // Yield intermediate results\n    yield {\n      state: 'partial' as const,\n      temperature: data.temp\n    };\n\n    // Yield final result\n    yield {\n      state: 'complete' as const,\n      temperature: data.temp,\n      weather: data.conditions,\n      forecast: data.forecast\n    };\n  }\n});\n```\n\n### Callbacks\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  // Called on each chunk\n  onChunk({ chunk }) {\n    console.log('Chunk:', chunk);\n  },\n\n  // Called when a step finishes (with multi-step)\n  onStepFinish({ request, response, toolCalls, toolResults }) {\n    console.log('Step finished');\n    console.log('Tool calls:', toolCalls);\n    console.log('Tool results:', toolResults);\n  },\n\n  // Called when generation finishes\n  onFinish({ text, finishReason, usage }) {\n    console.log('Generated text:', text);\n    console.log('Finish reason:', finishReason);\n    console.log('Token usage:', usage);\n  }\n});\n```\n\n## toUIMessageStreamResponse\n\nConvert streamText result to a UIMessage stream response.\n\n### Basic Usage\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages)\n});\n\nreturn result.toUIMessageStreamResponse();\n```\n\n### With Options\n\n```typescript\nreturn result.toUIMessageStreamResponse({\n  // Include original messages in the stream\n  originalMessages: uiMessages,\n\n  // Custom message ID generator\n  generateMessageId: () => crypto.randomUUID(),\n\n  // Add/update message metadata\n  messageMetadata: ({ part, message }) => {\n    if (part.type === 'start') {\n      return { createdAt: Date.now() };\n    }\n    if (part.type === 'finish') {\n      return { finishedAt: Date.now() };\n    }\n  },\n\n  // Called when streaming finishes\n  onFinish: ({ messages, finishReason }) => {\n    // Save to database\n    saveMessages(messages);\n  }\n});\n```\n\n### Custom Headers\n\n```typescript\nconst response = result.toUIMessageStreamResponse({\n  originalMessages: uiMessages\n});\n\n// Add custom headers\nresponse.headers.set('X-Custom-Header', 'value');\n\nreturn response;\n```\n\n## UIMessageChunk Types\n\nChunks sent over the stream as Server-Sent Events.\n\n### Text Chunks\n\n```typescript\n// Text streaming starts\n{ type: 'text-start', id: 'text-1' }\n\n// Text delta (incremental update)\n{ type: 'text-delta', id: 'text-1', delta: 'Hello' }\n{ type: 'text-delta', id: 'text-1', delta: ' world' }\n\n// Text streaming ends\n{ type: 'text-end', id: 'text-1' }\n```\n\n### Reasoning Chunks\n\n```typescript\n// Reasoning starts\n{ type: 'reasoning-start', id: 'reasoning-1' }\n\n// Reasoning delta\n{ type: 'reasoning-delta', id: 'reasoning-1', delta: 'First, ' }\n{ type: 'reasoning-delta', id: 'reasoning-1', delta: 'I will...' }\n\n// Reasoning ends\n{ type: 'reasoning-end', id: 'reasoning-1' }\n```\n\n### Tool Chunks\n\n```typescript\n// Tool input streaming starts\n{\n  type: 'tool-input-start',\n  toolCallId: 'call-123',\n  toolName: 'getWeather',\n  dynamic: false\n}\n\n// Tool input delta (for large inputs)\n{\n  type: 'tool-input-delta',\n  toolCallId: 'call-123',\n  inputTextDelta: '{\"city\": '\n}\n\n// Tool input complete\n{\n  type: 'tool-input-available',\n  toolCallId: 'call-123',\n  toolName: 'getWeather',\n  input: { city: 'San Francisco' }\n}\n\n// Tool output available\n{\n  type: 'tool-output-available',\n  toolCallId: 'call-123',\n  output: { temperature: 72, weather: 'sunny' },\n  preliminary: false\n}\n\n// Tool execution error\n{\n  type: 'tool-output-error',\n  toolCallId: 'call-123',\n  errorText: 'API unavailable'\n}\n```\n\n### Tool Approval Chunks\n\n```typescript\n// Tool needs approval\n{\n  type: 'tool-approval-request',\n  approvalId: 'approval-1',\n  toolCallId: 'call-123'\n}\n\n// User responded (handled client-side, not streamed)\n```\n\n### Control Chunks\n\n```typescript\n// Stream starts\n{\n  type: 'start',\n  messageId: 'msg-123',\n  messageMetadata: { createdAt: 1234567890 }\n}\n\n// Stream finishes\n{\n  type: 'finish',\n  finishReason: 'stop', // or 'length', 'tool-calls', 'content-filter'\n  messageMetadata: { finishedAt: 1234567890 }\n}\n\n// Stream aborted\n{ type: 'abort' }\n\n// Error occurred\n{ type: 'error', errorText: 'Something went wrong' }\n\n// Metadata update\n{\n  type: 'message-metadata',\n  messageMetadata: { updated: true }\n}\n```\n\n### Step Chunks\n\n```typescript\n// New step starts (for multi-step reasoning)\n{ type: 'start-step' }\n\n// Step finishes\n{ type: 'finish-step' }\n```\n\n### Data Chunks\n\n```typescript\n// Custom data part\n{\n  type: 'data-progress',\n  id: 'progress-1',\n  data: { percent: 50, status: 'Processing...' },\n  transient: false // If true, not added to final message\n}\n```\n\n### File Chunks\n\n```typescript\n{\n  type: 'file',\n  url: 'https://example.com/image.png',\n  mediaType: 'image/png'\n}\n```\n\n## SSE Protocol\n\n### Format\n\n```\nevent: message\ndata: {\"type\":\"text-start\",\"id\":\"text-1\"}\n\nevent: message\ndata: {\"type\":\"text-delta\",\"id\":\"text-1\",\"delta\":\"Hello\"}\n\nevent: message\ndata: {\"type\":\"text-delta\",\"id\":\"text-1\",\"delta\":\" world\"}\n\nevent: message\ndata: {\"type\":\"text-end\",\"id\":\"text-1\"}\n\nevent: message\ndata: {\"type\":\"finish\",\"finishReason\":\"stop\"}\n```\n\n### Client-Side Parsing\n\nThe SDK handles parsing automatically, but for custom implementations:\n\n```typescript\nconst eventSource = new EventSource('/api/chat');\n\neventSource.addEventListener('message', (event) => {\n  const chunk: UIMessageChunk = JSON.parse(event.data);\n\n  switch (chunk.type) {\n    case 'text-delta':\n      appendText(chunk.id, chunk.delta);\n      break;\n\n    case 'tool-output-available':\n      updateToolOutput(chunk.toolCallId, chunk.output);\n      break;\n\n    case 'finish':\n      console.log('Finished:', chunk.finishReason);\n      eventSource.close();\n      break;\n  }\n});\n```\n\n## Tool Execution Flow\n\n### Server-Side Tools\n\n```typescript\n// 1. Client sends message\nsendMessage({ text: 'What is the weather in SF?' });\n\n// 2. Server streams tool invocation\n{ type: 'tool-input-available', toolCallId: 'call-1', input: { city: 'San Francisco' } }\n\n// 3. Server executes tool and streams output\n{ type: 'tool-output-available', toolCallId: 'call-1', output: { temp: 72 } }\n\n// 4. Server continues with model response\n{ type: 'text-delta', delta: 'The weather is sunny...' }\n```\n\n### Client-Side Tools\n\n```typescript\n// 1. Client sends message\nsendMessage({ text: 'Get my location' });\n\n// 2. Server streams tool call (no execute)\n{ type: 'tool-input-available', toolCallId: 'call-1', toolName: 'getLocation', input: {} }\n\n// 3. Client handles tool call\nonToolCall: async ({ toolCall }) => {\n  const location = await getCurrentLocation();\n  addToolOutput({\n    toolCallId: toolCall.toolCallId,\n    tool: 'getLocation',\n    output: location\n  });\n}\n\n// 4. Client sends tool output back to server\n// 5. Server streams final response\n```\n\n### Preliminary Tool Outputs\n\nFor streaming tool results:\n\n```typescript\n// Tool yields intermediate result\n{\n  type: 'tool-output-available',\n  toolCallId: 'call-1',\n  output: { state: 'loading' },\n  preliminary: true\n}\n\n// Tool yields final result\n{\n  type: 'tool-output-available',\n  toolCallId: 'call-1',\n  output: { state: 'complete', data: {...} },\n  preliminary: false // or omitted\n}\n```\n\n## Error Handling\n\n### Server-Side Errors\n\n```typescript\ntry {\n  const result = streamText({\n    model: openai('gpt-4'),\n    messages: convertToModelMessages(uiMessages)\n  });\n\n  return result.toUIMessageStreamResponse();\n} catch (error) {\n  // Stream error chunk\n  return new Response(\n    new ReadableStream({\n      start(controller) {\n        const chunk: UIMessageChunk = {\n          type: 'error',\n          errorText: error.message\n        };\n        controller.enqueue(\n          new TextEncoder().encode(\n            `event: message\\ndata: ${JSON.stringify(chunk)}\\n\\n`\n          )\n        );\n        controller.close();\n      }\n    }),\n    {\n      headers: {\n        'Content-Type': 'text/event-stream',\n        'Cache-Control': 'no-cache'\n      }\n    }\n  );\n}\n```\n\n### Tool Execution Errors\n\n```typescript\nconst weatherTool = tool({\n  inputSchema: z.object({ city: z.string() }),\n  async execute({ city }) {\n    try {\n      return await fetchWeather(city);\n    } catch (error) {\n      // Error is automatically converted to tool-output-error chunk\n      throw new Error(`Failed to fetch weather: ${error.message}`);\n    }\n  }\n});\n```\n\n### Client-Side Error Handling\n\n```typescript\nconst { error } = useChat({\n  onError: (error) => {\n    console.error('Stream error:', error);\n    toast.error(error.message);\n  }\n});\n```\n\n## Advanced Patterns\n\n### Custom Data Streaming\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  onChunk({ chunk }) {\n    // Stream custom progress updates\n    if (chunk.type === 'text-delta') {\n      // Calculate progress based on tokens\n      const progress = calculateProgress(chunk);\n      // Custom data will be sent via data-* chunk\n    }\n  }\n});\n```\n\n### Resumable Streams\n\n```typescript\nimport { createResumableStreamContext } from 'resumable-stream';\n\nexport async function POST(req: Request) {\n  const { chatId } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4'),\n    messages: convertToModelMessages(uiMessages)\n  });\n\n  return result.toUIMessageStreamResponse({\n    async consumeSseStream({ stream }) {\n      const streamId = generateId();\n      const streamContext = createResumableStreamContext();\n\n      // Store stream for resumption\n      await streamContext.createNewResumableStream(streamId, () => stream);\n\n      // Save stream ID to database\n      await saveActiveStreamId(chatId, streamId);\n    }\n  });\n}\n```\n\n### Backpressure Handling\n\nThe SDK automatically handles backpressure, but for custom implementations:\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  // Throttle chunk processing\n  onChunk: throttle(async ({ chunk }) => {\n    await processChunk(chunk);\n  }, 100)\n});\n```\n\n### Conditional Streaming\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  onChunk({ chunk }) {\n    // Only stream certain content\n    if (shouldFilterChunk(chunk)) {\n      return; // Skip this chunk\n    }\n  }\n});\n```\n\n### Custom Transform\n\n```typescript\nimport { processUIMessageStream } from 'ai';\n\nconst stream = await transport.sendMessages({...});\n\nconst transformedStream = processUIMessageStream({\n  stream,\n  onToolCall,\n  onData,\n  runUpdateMessageJob: async ({ state, write }) => {\n    // Custom message update logic\n    customTransform(state.message);\n    write();\n  }\n});\n```\n\n## Performance Considerations\n\n### Throttling\n\n```typescript\n// Client-side throttling\nconst { messages } = useChat({\n  experimental_throttle: 100 // Max one update per 100ms\n});\n\n// Server-side throttling\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages,\n  onChunk: throttle(processChunk, 100)\n});\n```\n\n### Batch Updates\n\n```typescript\nlet pendingDeltas: string[] = [];\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages,\n  onChunk({ chunk }) {\n    if (chunk.type === 'text-delta') {\n      pendingDeltas.push(chunk.delta);\n\n      // Flush every 10 deltas or 100ms\n      if (pendingDeltas.length >= 10) {\n        flushDeltas();\n      }\n    }\n  }\n});\n```\n\n### Memory Management\n\n```typescript\n// Clean up old messages to prevent memory leaks\nconst { messages, setMessages } = useChat();\n\nuseEffect(() => {\n  if (messages.length > 100) {\n    setMessages(messages.slice(-50)); // Keep last 50\n  }\n}, [messages]);\n```\n\n## Complete Example\n\n```typescript\n// Server route\nexport async function POST(req: Request) {\n  const { messages, chatId } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4'),\n    messages: convertToModelMessages(messages),\n    tools: {\n      getWeather: tool({\n        description: 'Get weather',\n        inputSchema: z.object({ city: z.string() }),\n        async *execute({ city }) {\n          yield { state: 'loading' };\n          const data = await fetchWeather(city);\n          yield { state: 'complete', ...data };\n        }\n      })\n    },\n    stopWhen: stepCountIs(5),\n    onStepFinish({ toolCalls }) {\n      console.log('Tools called:', toolCalls);\n    }\n  });\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    messageMetadata: ({ part }) => {\n      if (part.type === 'start') {\n        return { createdAt: Date.now() };\n      }\n    },\n    onFinish: async ({ messages }) => {\n      await saveChat(chatId, messages);\n    }\n  });\n}\n\n// Client component\nfunction Chat() {\n  const { messages, sendMessage, status } = useChat({\n    experimental_throttle: 100,\n    onError: (error) => toast.error(error.message),\n    onFinish: ({ finishReason }) => {\n      console.log('Finished:', finishReason);\n    }\n  });\n\n  return (\n    <div>\n      {messages.map(msg => (\n        <Message key={msg.id} message={msg} />\n      ))}\n      <ChatInput\n        disabled={status !== 'ready'}\n        onSubmit={sendMessage}\n      />\n    </div>\n  );\n}\n```\n",
        "skills/vercel-ai-sdk/references/tools.md": "# Tools Reference\n\nComplete reference for tool definition and execution in the Vercel AI SDK.\n\n## Table of Contents\n\n- [Tool Definition](#tool-definition)\n- [Server-Side Tools](#server-side-tools)\n- [Client-Side Tools](#client-side-tools)\n- [Tool State Machine](#tool-state-machine)\n- [Tool Approval Flow](#tool-approval-flow)\n- [Rendering Tool States](#rendering-tool-states)\n- [Type Safety](#type-safety)\n- [Advanced Patterns](#advanced-patterns)\n\n## Tool Definition\n\n### Basic Tool\n\n```typescript\nimport { tool } from 'ai';\nimport { z } from 'zod';\n\nconst getWeatherTool = tool({\n  // Description for the AI model\n  description: 'Get current weather for a city',\n\n  // Input schema using Zod\n  inputSchema: z.object({\n    city: z.string().describe('The city name'),\n    units: z.enum(['celsius', 'fahrenheit']).optional()\n  }),\n\n  // Optional output schema\n  outputSchema: z.object({\n    temperature: z.number(),\n    weather: z.string(),\n    humidity: z.number()\n  }),\n\n  // Execution function (server-side only)\n  execute: async ({ city, units = 'celsius' }) => {\n    const data = await fetchWeather(city);\n    return {\n      temperature: convertTemp(data.temp, units),\n      weather: data.conditions,\n      humidity: data.humidity\n    };\n  }\n});\n```\n\n### Tool Without Execute (Client-Side)\n\n```typescript\nconst askConfirmationTool = tool({\n  description: 'Ask the user for confirmation',\n  inputSchema: z.object({\n    message: z.string()\n  }),\n  outputSchema: z.string()\n  // No execute function - handled on client\n});\n```\n\n## Server-Side Tools\n\nTools with `execute` functions run on the server during streaming.\n\n### Simple Execution\n\n```typescript\nconst searchTool = tool({\n  description: 'Search the web',\n  inputSchema: z.object({\n    query: z.string()\n  }),\n  async execute({ query }) {\n    const results = await searchWeb(query);\n    return {\n      results: results.slice(0, 5),\n      count: results.length\n    };\n  }\n});\n```\n\n### Streaming Tool Outputs\n\nUse generator functions to stream intermediate results:\n\n```typescript\nconst analysisTool = tool({\n  description: 'Analyze data',\n  inputSchema: z.object({\n    data: z.array(z.number())\n  }),\n\n  async *execute({ data }) {\n    // Yield preliminary status\n    yield { state: 'processing', progress: 0 };\n\n    // Perform analysis in stages\n    const mean = calculateMean(data);\n    yield { state: 'processing', progress: 33, mean };\n\n    const median = calculateMedian(data);\n    yield { state: 'processing', progress: 66, mean, median };\n\n    const stdDev = calculateStdDev(data);\n\n    // Yield final result\n    yield {\n      state: 'complete',\n      progress: 100,\n      mean,\n      median,\n      stdDev\n    };\n  }\n});\n```\n\n### Tool Callbacks\n\n```typescript\nconst verboseTool = tool({\n  description: 'Tool with callbacks',\n  inputSchema: z.object({ query: z.string() }),\n\n  // Called when input streaming starts\n  onInputStart: () => {\n    console.log('Tool input starting');\n  },\n\n  // Called on each input delta (for large inputs)\n  onInputDelta: ({ inputTextDelta }) => {\n    console.log('Input delta:', inputTextDelta);\n  },\n\n  // Called when input is complete\n  onInputAvailable: ({ input }) => {\n    console.log('Input available:', input);\n  },\n\n  async execute({ query }) {\n    return await search(query);\n  }\n});\n```\n\n### Error Handling\n\n```typescript\nconst fallibleTool = tool({\n  description: 'Tool that might fail',\n  inputSchema: z.object({ id: z.string() }),\n\n  async execute({ id }) {\n    try {\n      const data = await fetchData(id);\n      if (!data) {\n        throw new Error('Data not found');\n      }\n      return data;\n    } catch (error) {\n      // Error is automatically sent as tool-output-error chunk\n      throw new Error(`Failed to fetch data: ${error.message}`);\n    }\n  }\n});\n```\n\n### Multi-Step Tools\n\nTools can trigger additional model calls:\n\n```typescript\nimport { streamText, stepCountIs } from 'ai';\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n\n  tools: {\n    search: searchTool,\n    analyze: analyzeTool,\n    summarize: summarizeTool\n  },\n\n  // Allow up to 5 steps (model can call tools multiple times)\n  stopWhen: stepCountIs(5),\n\n  onStepFinish({ toolCalls, toolResults }) {\n    console.log('Step finished');\n    console.log('Called:', toolCalls.map(t => t.toolName));\n    console.log('Results:', toolResults);\n  }\n});\n```\n\n## Client-Side Tools\n\nTools without `execute` are handled on the client via `onToolCall` and `addToolOutput`.\n\n### Automatic Execution\n\n```typescript\nconst { addToolOutput } = useChat({\n  onToolCall: async ({ toolCall }) => {\n    if (toolCall.toolName === 'getLocation') {\n      try {\n        const location = await getCurrentLocation();\n        addToolOutput({\n          tool: 'getLocation',\n          toolCallId: toolCall.toolCallId,\n          output: location\n        });\n      } catch (error) {\n        addToolOutput({\n          state: 'output-error',\n          tool: 'getLocation',\n          toolCallId: toolCall.toolCallId,\n          errorText: error.message\n        });\n      }\n    }\n  }\n});\n```\n\n### User Interaction\n\nFor tools that require user input, handle them in the render phase:\n\n```typescript\nfunction Message({ message, addToolOutput }) {\n  return (\n    <div>\n      {message.parts.map(part => {\n        if (part.type === 'tool-askConfirmation') {\n          if (part.state === 'input-available') {\n            return (\n              <div>\n                <p>{part.input.message}</p>\n                <button\n                  onClick={() =>\n                    addToolOutput({\n                      tool: 'askConfirmation',\n                      toolCallId: part.toolCallId,\n                      output: 'Yes, confirmed'\n                    })\n                  }\n                >\n                  Confirm\n                </button>\n                <button\n                  onClick={() =>\n                    addToolOutput({\n                      state: 'output-error',\n                      tool: 'askConfirmation',\n                      toolCallId: part.toolCallId,\n                      errorText: 'User declined'\n                    })\n                  }\n                >\n                  Cancel\n                </button>\n              </div>\n            );\n          }\n\n          if (part.state === 'output-available') {\n            return <div>User confirmed: {part.output}</div>;\n          }\n        }\n      })}\n    </div>\n  );\n}\n```\n\n### Automatic Resending\n\n```typescript\nimport { lastAssistantMessageIsCompleteWithToolCalls } from 'ai';\n\nconst { messages } = useChat({\n  // Automatically resend when all tool outputs are available\n  sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,\n\n  onToolCall: async ({ toolCall }) => {\n    // Execute client-side tools\n    // Message will automatically be resent when all tools complete\n  }\n});\n```\n\n## Tool State Machine\n\nTool parts progress through states:\n\n### State Flow\n\n```\n1. input-streaming (optional)\n   \n2. input-available\n   \n3a. [No approval needed]  output-available\n   OR\n3b. approval-requested  approval-responded  output-available/output-denied\n   OR\n   (at any point)  output-error\n```\n\n### State Definitions\n\n```typescript\ntype ToolState =\n  | 'input-streaming'     // Tool input streaming (large inputs)\n  | 'input-available'     // Tool input complete\n  | 'approval-requested'  // Waiting for user approval\n  | 'approval-responded'  // User responded (approved/denied)\n  | 'output-available'    // Tool execution complete\n  | 'output-error'        // Tool execution failed\n  | 'output-denied';      // User denied approval\n```\n\n### State Properties\n\n```typescript\n// input-streaming\n{\n  state: 'input-streaming',\n  input: Partial<ToolInput> | undefined // Partial input while streaming\n}\n\n// input-available\n{\n  state: 'input-available',\n  input: ToolInput, // Complete input\n  callProviderMetadata?: ProviderMetadata\n}\n\n// approval-requested\n{\n  state: 'approval-requested',\n  input: ToolInput,\n  approval: {\n    id: string // Approval ID for response\n  }\n}\n\n// approval-responded\n{\n  state: 'approval-responded',\n  input: ToolInput,\n  approval: {\n    id: string,\n    approved: boolean,\n    reason?: string\n  }\n}\n\n// output-available\n{\n  state: 'output-available',\n  input: ToolInput,\n  output: ToolOutput,\n  preliminary?: boolean, // True for intermediate streaming outputs\n  approval?: {\n    id: string,\n    approved: true,\n    reason?: string\n  }\n}\n\n// output-error\n{\n  state: 'output-error',\n  input: ToolInput | undefined,\n  errorText: string,\n  approval?: { ... } // If error after approval\n}\n\n// output-denied\n{\n  state: 'output-denied',\n  input: ToolInput,\n  approval: {\n    id: string,\n    approved: false,\n    reason?: string\n  }\n}\n```\n\n## Tool Approval Flow\n\n### Defining Approval Requirements\n\n```typescript\nconst deleteTool = tool({\n  description: 'Delete a file',\n  inputSchema: z.object({\n    filename: z.string()\n  }),\n\n  // Request approval before execution\n  requiresApproval: true,\n\n  async execute({ filename }) {\n    await deleteFile(filename);\n    return { deleted: filename };\n  }\n});\n```\n\n### Handling Approval Requests\n\n```typescript\nfunction ToolApproval({ part, addToolApprovalResponse }) {\n  if (part.type === 'tool-deleteFile' && part.state === 'approval-requested') {\n    return (\n      <div>\n        <p>Delete {part.input.filename}?</p>\n        <button\n          onClick={() =>\n            addToolApprovalResponse({\n              id: part.approval.id,\n              approved: true,\n              reason: 'User confirmed deletion'\n            })\n          }\n        >\n          Approve\n        </button>\n        <button\n          onClick={() =>\n            addToolApprovalResponse({\n              id: part.approval.id,\n              approved: false,\n              reason: 'User cancelled'\n            })\n          }\n        >\n          Deny\n        </button>\n      </div>\n    );\n  }\n}\n```\n\n### Automatic Resending After Approval\n\n```typescript\nconst { addToolApprovalResponse } = useChat({\n  sendAutomaticallyWhen: ({ messages }) => {\n    const lastMsg = messages[messages.length - 1];\n    return lastMsg.parts.every(part => {\n      if (part.type.startsWith('tool-')) {\n        // Resend when all tools are either:\n        // - output-available\n        // - output-error\n        // - output-denied\n        // - approval-responded (waiting for backend)\n        return ['output-available', 'output-error', 'output-denied', 'approval-responded']\n          .includes(part.state);\n      }\n      return true;\n    });\n  }\n});\n```\n\n## Rendering Tool States\n\n### Complete Tool Renderer\n\n```typescript\nfunction ToolPart({ part, addToolOutput, addToolApprovalResponse }) {\n  // Type guard\n  if (!part.type.startsWith('tool-')) return null;\n\n  const toolName = part.type.replace('tool-', '');\n\n  switch (part.state) {\n    case 'input-streaming':\n      return (\n        <div className=\"tool-streaming\">\n          <Spinner />\n          <span>Preparing {toolName}...</span>\n          <pre>{JSON.stringify(part.input, null, 2)}</pre>\n        </div>\n      );\n\n    case 'input-available':\n      return (\n        <div className=\"tool-executing\">\n          <Spinner />\n          <span>Executing {toolName}...</span>\n          {part.title && <h4>{part.title}</h4>}\n        </div>\n      );\n\n    case 'approval-requested':\n      return (\n        <div className=\"tool-approval\">\n          <h4>Approval Required</h4>\n          <p>Allow {toolName}?</p>\n          <div className=\"tool-input\">\n            <pre>{JSON.stringify(part.input, null, 2)}</pre>\n          </div>\n          <button\n            onClick={() =>\n              addToolApprovalResponse({\n                id: part.approval.id,\n                approved: true\n              })\n            }\n          >\n            Approve\n          </button>\n          <button\n            onClick={() =>\n              addToolApprovalResponse({\n                id: part.approval.id,\n                approved: false,\n                reason: 'User declined'\n              })\n            }\n          >\n            Deny\n          </button>\n        </div>\n      );\n\n    case 'approval-responded':\n      return (\n        <div className=\"tool-approval-responded\">\n          {part.approval.approved ? (\n            <span> Approved, executing...</span>\n          ) : (\n            <span> Denied: {part.approval.reason}</span>\n          )}\n        </div>\n      );\n\n    case 'output-available':\n      return (\n        <div className=\"tool-output\">\n          <h4>{toolName} Result</h4>\n          {part.preliminary && <Badge>Preliminary</Badge>}\n          <ToolOutput toolName={toolName} output={part.output} />\n        </div>\n      );\n\n    case 'output-error':\n      return (\n        <div className=\"tool-error\">\n          <h4>{toolName} Error</h4>\n          <p className=\"error\">{part.errorText}</p>\n          {part.input && (\n            <details>\n              <summary>Input</summary>\n              <pre>{JSON.stringify(part.input, null, 2)}</pre>\n            </details>\n          )}\n        </div>\n      );\n\n    case 'output-denied':\n      return (\n        <div className=\"tool-denied\">\n          <span> Tool execution denied</span>\n          {part.approval.reason && <p>{part.approval.reason}</p>}\n        </div>\n      );\n\n    default:\n      return null;\n  }\n}\n```\n\n### Tool-Specific Renderers\n\n```typescript\nfunction WeatherToolOutput({ part }) {\n  if (part.type !== 'tool-getWeather') return null;\n\n  if (part.state === 'output-available') {\n    const { weather, temperature } = part.output;\n    return (\n      <div className=\"weather-card\">\n        <WeatherIcon condition={weather} />\n        <span>{temperature}F</span>\n        <span>{weather}</span>\n      </div>\n    );\n  }\n\n  if (part.state === 'input-available') {\n    return <div>Fetching weather for {part.input.city}...</div>;\n  }\n\n  return null;\n}\n```\n\n## Type Safety\n\n### Typed Tools\n\n```typescript\nconst tools = {\n  getWeather: tool({\n    inputSchema: z.object({ city: z.string() }),\n    execute: async ({ city }) => ({ temp: 72, weather: 'sunny' })\n  }),\n  searchWeb: tool({\n    inputSchema: z.object({ query: z.string() }),\n    execute: async ({ query }) => ({ results: [] })\n  })\n} as const;\n\n// Infer tool types\ntype MyTools = InferUITools<typeof tools>;\n// {\n//   getWeather: { input: { city: string }; output: { temp: number; weather: string } }\n//   searchWeb: { input: { query: string }; output: { results: any[] } }\n// }\n\n// Use in message type\ntype MyMessage = UIMessage<unknown, UIDataTypes, MyTools>;\n```\n\n### Type-Safe Tool Rendering\n\n```typescript\nfunction renderToolPart(part: InferUIMessagePart<MyMessage>) {\n  // TypeScript knows the exact tool types\n  if (part.type === 'tool-getWeather') {\n    if (part.state === 'output-available') {\n      // part.output is typed as { temp: number; weather: string }\n      return <div>{part.output.weather}: {part.output.temp}F</div>;\n    }\n  }\n\n  if (part.type === 'tool-searchWeb') {\n    if (part.state === 'output-available') {\n      // part.output is typed as { results: any[] }\n      return <SearchResults results={part.output.results} />;\n    }\n  }\n}\n```\n\n### Type-Safe addToolOutput\n\n```typescript\nconst { addToolOutput } = useChat<MyMessage>();\n\n// TypeScript enforces correct tool name and output type\naddToolOutput({\n  tool: 'getWeather', // Must be a key in MyTools\n  toolCallId: 'call-123',\n  output: { temp: 72, weather: 'sunny' } // Must match getWeather output type\n});\n\n// Error: Type '\"invalid\"' is not assignable to type '\"getWeather\" | \"searchWeb\"'\naddToolOutput({\n  tool: 'invalid',\n  toolCallId: 'call-123',\n  output: {}\n});\n```\n\n## Advanced Patterns\n\n### Conditional Tool Availability\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages: convertToModelMessages(uiMessages),\n  tools: user.isPremium\n    ? { search: searchTool, analyze: analyzeTool }\n    : { search: searchTool }\n});\n```\n\n### Tool Chaining\n\n```typescript\nconst tools = {\n  search: tool({\n    description: 'Search for information',\n    inputSchema: z.object({ query: z.string() }),\n    async execute({ query }) {\n      return await searchWeb(query);\n    }\n  }),\n  analyze: tool({\n    description: 'Analyze search results',\n    inputSchema: z.object({ results: z.array(z.any()) }),\n    async execute({ results }) {\n      return await analyzeResults(results);\n    }\n  })\n};\n\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages,\n  tools,\n  stopWhen: stepCountIs(5) // Allow chaining\n});\n```\n\n### Parallel Tool Execution\n\nThe AI model can invoke multiple tools in parallel:\n\n```typescript\nconst result = streamText({\n  model: openai('gpt-4'),\n  messages,\n  tools: {\n    getWeather: weatherTool,\n    getNews: newsTool,\n    getStocks: stocksTool\n  },\n  maxToolRoundtrips: 1 // One round with multiple parallel tools\n});\n```\n\n### Tool Metadata\n\n```typescript\nconst enrichedTool = tool({\n  description: 'Search with metadata',\n  inputSchema: z.object({ query: z.string() }),\n\n  async execute({ query }, { messages, abortSignal }) {\n    // Access message history\n    const context = extractContext(messages);\n\n    // Support cancellation\n    const results = await searchWithAbort(query, abortSignal);\n\n    return {\n      results,\n      metadata: {\n        searchTime: Date.now(),\n        contextUsed: context\n      }\n    };\n  }\n});\n```\n\n### Custom Tool Validation\n\n```typescript\nconst validatedTool = tool({\n  description: 'Tool with validation',\n  inputSchema: z.object({\n    amount: z.number().min(0).max(1000)\n  }),\n\n  async execute({ amount }) {\n    // Additional runtime validation\n    if (amount > 500) {\n      throw new Error('Amount requires additional approval');\n    }\n\n    return await processPayment(amount);\n  }\n});\n```\n\n## Complete Example\n\n```typescript\n// Server route\nconst tools = {\n  // Server-side tool\n  getWeather: tool({\n    description: 'Get weather for a city',\n    inputSchema: z.object({ city: z.string() }),\n    async *execute({ city }) {\n      yield { state: 'loading' };\n      const data = await fetchWeather(city);\n      yield { state: 'complete', ...data };\n    }\n  }),\n\n  // Client-side tool with approval\n  getLocation: tool({\n    description: 'Get user location (requires permission)',\n    inputSchema: z.object({}),\n    outputSchema: z.string(),\n    requiresApproval: true\n  })\n};\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4'),\n    messages: convertToModelMessages(messages),\n    tools\n  });\n\n  return result.toUIMessageStreamResponse();\n}\n\n// Client component\ntype MyMessage = UIMessage<unknown, UIDataTypes, InferUITools<typeof tools>>;\n\nfunction Chat() {\n  const { messages, addToolOutput, addToolApprovalResponse } = useChat<MyMessage>({\n    // Handle client-side tool automatically\n    onToolCall: async ({ toolCall }) => {\n      if (toolCall.toolName === 'getLocation') {\n        const location = await getCurrentLocation();\n        addToolOutput({\n          tool: 'getLocation',\n          toolCallId: toolCall.toolCallId,\n          output: location\n        });\n      }\n    },\n\n    // Resend when all tools complete\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls\n  });\n\n  return (\n    <div>\n      {messages.map(msg => (\n        <div key={msg.id}>\n          {msg.parts.map((part, i) => (\n            <ToolPart\n              key={i}\n              part={part}\n              addToolOutput={addToolOutput}\n              addToolApprovalResponse={addToolApprovalResponse}\n            />\n          ))}\n        </div>\n      ))}\n    </div>\n  );\n}\n```\n",
        "skills/vercel-ai-sdk/references/use-chat.md": "# useChat Hook Reference\n\nComplete API reference for the `useChat` hook from `@ai-sdk/react`.\n\n## Table of Contents\n\n- [Hook Signature](#hook-signature)\n- [Options](#options)\n- [Return Values](#return-values)\n- [Methods](#methods)\n- [Callbacks](#callbacks)\n- [Types](#types)\n\n## Hook Signature\n\n```typescript\nfunction useChat<UI_MESSAGE extends UIMessage = UIMessage>(\n  options?: UseChatOptions<UI_MESSAGE>\n): UseChatHelpers<UI_MESSAGE>\n```\n\n## Options\n\n### Basic Options\n\n```typescript\ninterface UseChatOptions<UI_MESSAGE extends UIMessage> {\n  // Chat instance (existing) or initialization parameters\n  chat?: Chat<UI_MESSAGE>;\n\n  // Chat identifier (auto-generated if not provided)\n  id?: string;\n\n  // Initial messages\n  messages?: UI_MESSAGE[];\n\n  // Whether to resume an ongoing stream on mount\n  resume?: boolean;\n\n  // Custom transport for API communication\n  transport?: ChatTransport<UI_MESSAGE>;\n\n  // ID generator function\n  generateId?: IdGenerator;\n}\n```\n\n### Schema Options\n\n```typescript\ninterface UseChatOptions<UI_MESSAGE extends UIMessage> {\n  // Schema for message metadata validation\n  messageMetadataSchema?: FlexibleSchema<InferUIMessageMetadata<UI_MESSAGE>>;\n\n  // Schemas for custom data parts\n  dataPartSchemas?: UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>;\n}\n```\n\n### Performance Options\n\n```typescript\ninterface UseChatOptions<UI_MESSAGE extends UIMessage> {\n  // Throttle message updates (in milliseconds)\n  // Default: undefined (no throttling)\n  experimental_throttle?: number;\n}\n```\n\n### Callback Options\n\n```typescript\ninterface UseChatOptions<UI_MESSAGE extends UIMessage> {\n  // Called when an error occurs\n  onError?: (error: Error) => void;\n\n  // Called when a tool call is received\n  onToolCall?: (options: {\n    toolCall: InferUIMessageToolCall<UI_MESSAGE>;\n  }) => void | PromiseLike<void>;\n\n  // Called when streaming finishes\n  onFinish?: (options: {\n    message: UI_MESSAGE;\n    messages: UI_MESSAGE[];\n    isAbort: boolean;\n    isDisconnect: boolean;\n    isError: boolean;\n    finishReason?: FinishReason;\n  }) => void;\n\n  // Called when a data part is received\n  onData?: (dataPart: DataUIPart<InferUIMessageData<UI_MESSAGE>>) => void;\n}\n```\n\n### Automation Options\n\n```typescript\ninterface UseChatOptions<UI_MESSAGE extends UIMessage> {\n  // Automatically send messages when condition is met\n  sendAutomaticallyWhen?: (options: {\n    messages: UI_MESSAGE[];\n  }) => boolean | PromiseLike<boolean>;\n}\n```\n\n## Return Values\n\n```typescript\ninterface UseChatHelpers<UI_MESSAGE extends UIMessage> {\n  // Chat identifier\n  readonly id: string;\n\n  // Current chat status\n  status: ChatStatus;\n\n  // Current error (if any)\n  error: Error | undefined;\n\n  // Array of all messages\n  messages: UI_MESSAGE[];\n\n  // Methods (see below)\n  sendMessage: (message?, options?) => Promise<void>;\n  regenerate: (options?) => Promise<void>;\n  stop: () => Promise<void>;\n  resumeStream: (options?) => Promise<void>;\n  setMessages: (messages) => void;\n  clearError: () => void;\n  addToolOutput: (options) => Promise<void>;\n  addToolApprovalResponse: (options) => Promise<void>;\n\n  // Deprecated\n  addToolResult: (options) => Promise<void>; // Use addToolOutput\n}\n```\n\n### ChatStatus Type\n\n```typescript\ntype ChatStatus = 'ready' | 'submitted' | 'streaming' | 'error';\n```\n\n- **`ready`**: No active request, ready for new messages\n- **`submitted`**: Request sent, awaiting stream start\n- **`streaming`**: Response actively streaming\n- **`error`**: Error occurred during request\n\n## Methods\n\n### sendMessage\n\nSend a new user message or replace an existing one.\n\n```typescript\n// Send text message\nawait sendMessage({ text: 'Hello' });\n\n// Send with files\nawait sendMessage({\n  text: 'Analyze this image',\n  files: fileList // FileList or FileUIPart[]\n});\n\n// Send with metadata\nawait sendMessage({\n  text: 'Hello',\n  metadata: { createdAt: Date.now(), userId: '123' }\n});\n\n// Replace existing message\nawait sendMessage({\n  text: 'Updated message',\n  messageId: 'msg-123'\n});\n\n// Send full UIMessage structure\nawait sendMessage({\n  parts: [\n    { type: 'text', text: 'Hello' },\n    { type: 'file', url: 'data:...', mediaType: 'image/png' }\n  ],\n  metadata: { custom: 'data' }\n});\n\n// Send with request options\nawait sendMessage(\n  { text: 'Hello' },\n  {\n    headers: { 'X-Custom': 'value' },\n    body: { extra: 'data' },\n    metadata: { custom: 'metadata' }\n  }\n);\n\n// Continue existing conversation (no message)\nawait sendMessage();\n```\n\n**Signature:**\n```typescript\nsendMessage: (\n  message?:\n    | { text: string; files?: FileList | FileUIPart[]; metadata?: Metadata; messageId?: string }\n    | { files: FileList | FileUIPart[]; metadata?: Metadata; messageId?: string }\n    | CreateUIMessage<UI_MESSAGE> & { messageId?: string },\n  options?: ChatRequestOptions\n) => Promise<void>\n```\n\n### regenerate\n\nRegenerate an assistant message.\n\n```typescript\n// Regenerate last assistant message\nawait regenerate();\n\n// Regenerate specific message\nawait regenerate({ messageId: 'msg-123' });\n\n// With request options\nawait regenerate({\n  messageId: 'msg-123',\n  headers: { 'X-Custom': 'value' }\n});\n```\n\n**Signature:**\n```typescript\nregenerate: (options?: {\n  messageId?: string;\n  headers?: Record<string, string> | Headers;\n  body?: object;\n  metadata?: unknown;\n}) => Promise<void>\n```\n\n### stop\n\nStop the current streaming request.\n\n```typescript\nawait stop();\n```\n\nAborts the active request and sets status to `ready`. Keeps any tokens generated so far.\n\n### resumeStream\n\nResume an interrupted streaming response.\n\n```typescript\nawait resumeStream();\n\n// With options\nawait resumeStream({\n  headers: { 'X-Session': 'token' }\n});\n```\n\n**Signature:**\n```typescript\nresumeStream: (options?: ChatRequestOptions) => Promise<void>\n```\n\n### setMessages\n\nUpdate messages locally without triggering a request.\n\n```typescript\n// Set messages directly\nsetMessages([...newMessages]);\n\n// Update with function\nsetMessages(current => current.filter(m => m.role !== 'system'));\n\n// Clear all messages\nsetMessages([]);\n```\n\n**Signature:**\n```typescript\nsetMessages: (\n  messages: UI_MESSAGE[] | ((messages: UI_MESSAGE[]) => UI_MESSAGE[])\n) => void\n```\n\n### clearError\n\nClear error state and reset to ready.\n\n```typescript\nif (error) {\n  clearError();\n}\n```\n\n### addToolOutput\n\nProvide output for a client-side tool call.\n\n```typescript\n// Successful tool execution\nawait addToolOutput({\n  tool: 'getWeather',\n  toolCallId: 'call-123',\n  output: { temperature: 72, weather: 'sunny' }\n});\n\n// Tool execution error\nawait addToolOutput({\n  state: 'output-error',\n  tool: 'getWeather',\n  toolCallId: 'call-123',\n  errorText: 'API unavailable'\n});\n```\n\n**Signature:**\n```typescript\naddToolOutput: <TOOL extends keyof Tools>(\n  options:\n    | {\n        state?: 'output-available';\n        tool: TOOL;\n        toolCallId: string;\n        output: ToolOutput<TOOL>;\n      }\n    | {\n        state: 'output-error';\n        tool: TOOL;\n        toolCallId: string;\n        errorText: string;\n      }\n) => Promise<void>\n```\n\n### addToolApprovalResponse\n\nRespond to a tool approval request.\n\n```typescript\n// Approve tool execution\nawait addToolApprovalResponse({\n  id: 'approval-123',\n  approved: true,\n  reason: 'Safe to proceed'\n});\n\n// Deny tool execution\nawait addToolApprovalResponse({\n  id: 'approval-123',\n  approved: false,\n  reason: 'User denied location access'\n});\n```\n\n**Signature:**\n```typescript\naddToolApprovalResponse: (options: {\n  id: string;\n  approved: boolean;\n  reason?: string;\n}) => Promise<void>\n```\n\n## Callbacks\n\n### onError\n\nCalled when any error occurs during the chat.\n\n```typescript\nuseChat({\n  onError: (error) => {\n    console.error('Chat error:', error);\n    toast.error(error.message);\n  }\n});\n```\n\n### onToolCall\n\nCalled when a tool call is received. Use for automatic client-side tool execution.\n\n```typescript\nuseChat({\n  onToolCall: async ({ toolCall }) => {\n    // Handle different tools\n    if (toolCall.toolName === 'getLocation') {\n      const location = await getCurrentLocation();\n      addToolOutput({\n        tool: 'getLocation',\n        toolCallId: toolCall.toolCallId,\n        output: location\n      });\n    }\n  }\n});\n```\n\n**Important**: This callback is for automatic execution. For user-interactive tools (like confirmations), handle them in the render phase.\n\n### onFinish\n\nCalled when streaming completes (success, abort, or error).\n\n```typescript\nuseChat({\n  onFinish: ({ message, messages, isAbort, isDisconnect, isError, finishReason }) => {\n    if (isError) {\n      console.error('Stream ended with error');\n      return;\n    }\n\n    if (isAbort) {\n      console.log('User aborted request');\n      return;\n    }\n\n    if (isDisconnect) {\n      console.warn('Network disconnected');\n      return;\n    }\n\n    // Save to database\n    saveMessages(messages);\n\n    console.log('Finish reason:', finishReason); // 'stop' | 'length' | 'tool-calls' | ...\n  }\n});\n```\n\n### onData\n\nCalled when custom data parts are received.\n\n```typescript\nuseChat<UIMessage<never, { progress: { percent: number } }>>({\n  onData: (dataPart) => {\n    if (dataPart.type === 'data-progress') {\n      updateProgressBar(dataPart.data.percent);\n    }\n  }\n});\n```\n\n## Types\n\n### ChatRequestOptions\n\n```typescript\ninterface ChatRequestOptions {\n  // Additional headers for the API request\n  headers?: Record<string, string> | Headers;\n\n  // Additional body properties for the API request\n  body?: object;\n\n  // Request-specific metadata\n  metadata?: unknown;\n}\n```\n\n### CreateUIMessage\n\n```typescript\ntype CreateUIMessage<UI_MESSAGE extends UIMessage> = Omit<\n  UI_MESSAGE,\n  'id' | 'role'\n> & {\n  id?: UI_MESSAGE['id'];\n  role?: UI_MESSAGE['role'];\n};\n```\n\nUsed for creating messages without requiring `id` and `role` (auto-generated).\n\n## Examples\n\n### Basic Chat\n\n```typescript\nfunction ChatComponent() {\n  const { messages, status, sendMessage } = useChat({\n    id: 'my-chat',\n    onError: (error) => toast.error(error.message)\n  });\n\n  return (\n    <div>\n      {messages.map(msg => (\n        <div key={msg.id}>{msg.role}: {msg.parts[0]?.text}</div>\n      ))}\n      <input\n        disabled={status !== 'ready'}\n        onSubmit={(text) => sendMessage({ text })}\n      />\n    </div>\n  );\n}\n```\n\n### With Tools\n\n```typescript\nfunction ChatWithTools() {\n  const { messages, addToolOutput } = useChat<MyToolMessage>({\n    onToolCall: async ({ toolCall }) => {\n      if (toolCall.toolName === 'autoExecute') {\n        const result = await executeAutomatically();\n        addToolOutput({\n          tool: 'autoExecute',\n          toolCallId: toolCall.toolCallId,\n          output: result\n        });\n      }\n    },\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls\n  });\n\n  return (\n    <div>\n      {messages.map(msg => (\n        <Message\n          key={msg.id}\n          message={msg}\n          onToolApprove={(toolCallId) =>\n            addToolOutput({\n              tool: 'userConfirm',\n              toolCallId,\n              output: 'confirmed'\n            })\n          }\n        />\n      ))}\n    </div>\n  );\n}\n```\n\n### Custom Transport\n\n```typescript\nconst { messages } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/my-chat',\n    prepareSendMessagesRequest: ({ id, messages, trigger, messageId }) => ({\n      url: `/api/my-chat/${id}`,\n      body: {\n        lastMessage: messages[messages.length - 1],\n        action: trigger,\n        targetMessageId: messageId\n      },\n      headers: {\n        'X-Session-Token': getSessionToken()\n      }\n    })\n  })\n});\n```\n\n### Throttled Updates\n\n```typescript\n// Update UI at most once per 100ms during streaming\nconst { messages } = useChat({\n  experimental_throttle: 100\n});\n```\n\n### Resume Interrupted Stream\n\n```typescript\nfunction ChatComponent({ chatId }) {\n  const [shouldResume, setShouldResume] = useState(false);\n\n  useEffect(() => {\n    // Check if there's an active stream for this chat\n    checkActiveStream(chatId).then(setShouldResume);\n  }, [chatId]);\n\n  const chat = useChat({\n    id: chatId,\n    resume: shouldResume\n  });\n\n  return <ChatUI {...chat} />;\n}\n```\n",
        "skills/vitest-testing/CONFIG.md": "# Configuration\n\n## Basic Config\n\n```ts\n// vitest.config.ts\nimport { defineConfig } from 'vitest/config'\n\nexport default defineConfig({\n  test: {\n    globals: true,              // Use global test APIs (describe, it, expect)\n    environment: 'node',        // 'node' | 'jsdom' | 'happy-dom'\n    setupFiles: './test/setup.ts',\n    coverage: {\n      provider: 'v8',           // 'v8' | 'istanbul'\n      reporter: ['text', 'json', 'html'],\n      exclude: ['**/*.test.ts', '**/node_modules/**']\n    },\n    include: ['**/*.test.ts'],\n    exclude: ['node_modules', 'dist'],\n    testTimeout: 10000,\n  }\n})\n```\n\n## Global Setup\n\n```ts\n// test/setup.ts\nimport { beforeEach, afterEach, vi } from 'vitest'\n\n// Global beforeEach/afterEach\nbeforeEach(() => {\n  vi.clearAllMocks()\n})\n\n// Extend matchers\nimport { expect } from 'vitest'\nexpect.extend({\n  toBeWithinRange(received, floor, ceiling) {\n    const pass = received >= floor && received <= ceiling\n    return {\n      pass,\n      message: () => `expected ${received} to be within ${floor}-${ceiling}`\n    }\n  }\n})\n```\n\n## DOM Testing\n\n```ts\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    environment: 'jsdom',\n    setupFiles: './test/setup.ts'\n  }\n})\n\n// Tests\nit('updates DOM', () => {\n  document.body.innerHTML = '<div id=\"app\"></div>'\n  const app = document.querySelector('#app')\n  expect(app).toBeTruthy()\n  expect(app?.textContent).toBe('')\n})\n```\n\n## Concurrent Tests\n\n```ts\n// Run tests in parallel\ndescribe.concurrent('suite', () => {\n  it('test 1', async () => { /* ... */ })\n  it('test 2', async () => { /* ... */ })\n})\n\n// Individual concurrent tests\nit.concurrent('test 1', async () => { /* ... */ })\nit.concurrent('test 2', async () => { /* ... */ })\n\n// Use local expect for concurrent tests\nit.concurrent('test', async ({ expect }) => {\n  expect(value).toBe(1)\n})\n```\n\n## Test Isolation\n\n```ts\nexport default defineConfig({\n  test: {\n    isolate: false,           // Share environment between tests (faster)\n    pool: 'threads',          // 'threads' | 'forks' | 'vmThreads'\n    poolOptions: {\n      threads: {\n        singleThread: true    // Run tests in single thread\n      }\n    }\n  }\n})\n```\n\n## Type Testing\n\n```ts\nimport { expectTypeOf, assertType } from 'vitest'\n\n// Compile-time type assertions\nexpectTypeOf({ a: 1 }).toEqualTypeOf<{ a: number }>()\nexpectTypeOf('string').toBeString()\nexpectTypeOf(promise).resolves.toBeNumber()\n\nassertType<string>('hello')  // Type guard\n```\n\n## Environment Variables\n\n```ts\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    env: {\n      TEST_VAR: 'test-value'\n    }\n  }\n})\n\n// Or use .env.test file\n// Tests can access via process.env.TEST_VAR\n```\n\n## Coverage Configuration\n\n```ts\nexport default defineConfig({\n  test: {\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html', 'lcov'],\n      reportsDirectory: './coverage',\n      include: ['src/**/*.ts'],\n      exclude: [\n        'node_modules',\n        'test',\n        '**/*.d.ts',\n        '**/*.test.ts',\n        '**/types.ts'\n      ],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80\n      }\n    }\n  }\n})\n```\n",
        "skills/vitest-testing/MOCKING.md": "# Mocking Patterns\n\n## Module Mocking\n\n```ts\n// Mock entire module (hoisted automatically)\nvi.mock('./module', () => ({\n  namedExport: vi.fn(() => 'mocked'),\n  default: vi.fn()\n}))\n\n// Partial mock with importActual\nvi.mock('./utils', async () => {\n  const actual = await vi.importActual('./utils')\n  return {\n    ...actual,\n    specificFunction: vi.fn()\n  }\n})\n\n// Access mocked module\nimport { specificFunction } from './utils'\nvi.mocked(specificFunction).mockReturnValue('value')\n\n// Mock with spy (keeps implementation)\nvi.mock('./calculator', { spy: true })\n```\n\n## Function Mocking\n\n```ts\n// Create mock function\nconst mockFn = vi.fn()\nconst mockFnWithImpl = vi.fn((x) => x * 2)\n\n// Mock return values\nmockFn.mockReturnValue(42)\nmockFn.mockReturnValueOnce(1).mockReturnValueOnce(2)\n\n// Mock async returns\nmockFn.mockResolvedValue({ data: 'value' })\nmockFn.mockRejectedValue(new Error('failed'))\n\n// Mock implementation\nmockFn.mockImplementation((arg) => arg + 1)\nmockFn.mockImplementationOnce(() => 'once')\n```\n\n## Mock Assertions\n\n```ts\nexpect(mockFn).toHaveBeenCalled()\nexpect(mockFn).toHaveBeenCalledTimes(2)\nexpect(mockFn).toHaveBeenCalledWith('arg1', 'arg2')\nexpect(mockFn).toHaveBeenLastCalledWith('arg')\nexpect(mockFn).toHaveReturnedWith(42)\n\n// Access mock state\nmockFn.mock.calls        // [['arg1'], ['arg2']]\nmockFn.mock.results      // [{ type: 'return', value: 42 }]\nmockFn.mock.lastCall     // ['arg2']\n```\n\n## Spying\n\n```ts\n// Spy on object methods\nconst obj = { method: () => 'real' }\nconst spy = vi.spyOn(obj, 'method')\n\n// Spy with custom implementation\nvi.spyOn(obj, 'method').mockImplementation(() => 'mocked')\n\n// Spy on getters/setters\nvi.spyOn(obj, 'property', 'get').mockReturnValue('value')\nvi.spyOn(obj, 'property', 'set')\n\n// Restore original\nspy.mockRestore()\n```\n\n## Mock Cleanup\n\n```ts\nimport { vi, beforeEach, afterEach } from 'vitest'\n\nbeforeEach(() => {\n  vi.clearAllMocks()    // Clear mock history\n  vi.resetAllMocks()    // Clear history + reset implementations\n  vi.restoreAllMocks()  // Restore original implementations (spies)\n})\n\n// Or configure in vitest.config.ts\nexport default defineConfig({\n  test: {\n    clearMocks: true,      // Auto-clear before each test\n    mockReset: true,       // Auto-reset before each test\n    restoreMocks: true,    // Auto-restore before each test\n  }\n})\n```\n\n## Mock Methods Quick Reference\n\n| Method | Purpose |\n|--------|---------|\n| `vi.fn()` | Create mock function |\n| `vi.spyOn()` | Spy on method |\n| `vi.mock()` | Mock module |\n| `vi.importActual()` | Import real module |\n| `vi.mocked()` | Type helper for mocks |\n| `vi.clearAllMocks()` | Clear call history |\n| `vi.resetAllMocks()` | Reset implementations |\n| `vi.restoreAllMocks()` | Restore originals |\n",
        "skills/vitest-testing/PATTERNS.md": "# Common Patterns\n\n## Fake Timers\n\n```ts\nimport { vi, beforeEach, afterEach } from 'vitest'\n\nbeforeEach(() => {\n  vi.useFakeTimers()\n})\n\nafterEach(() => {\n  vi.useRealTimers()\n})\n\nit('executes after timeout', () => {\n  const callback = vi.fn()\n  setTimeout(callback, 1000)\n\n  vi.advanceTimersByTime(1000)\n  expect(callback).toHaveBeenCalled()\n})\n\n// Timer methods\nvi.runAllTimers()\nvi.runOnlyPendingTimers()\nvi.advanceTimersByTime(1000)\nvi.advanceTimersToNextTimer()\nvi.setSystemTime(new Date('2024-01-01'))\n```\n\n## Waiting Utilities\n\n```ts\n// Wait for condition\nawait vi.waitFor(() => {\n  expect(element).toBeTruthy()\n}, { timeout: 1000, interval: 50 })\n\n// Wait until truthy\nconst element = await vi.waitUntil(\n  () => document.querySelector('.loaded'),\n  { timeout: 1000 }\n)\n```\n\n## Snapshots\n\n```ts\n// Basic snapshot\nit('matches snapshot', () => {\n  const data = { foo: 'bar' }\n  expect(data).toMatchSnapshot()\n})\n\n// Inline snapshot (updates test file)\nit('matches inline snapshot', () => {\n  expect(render()).toMatchInlineSnapshot(`\n    <div>\n      <h1>Title</h1>\n    </div>\n  `)\n})\n\n// File snapshot\nit('matches file snapshot', async () => {\n  const html = renderHTML()\n  await expect(html).toMatchFileSnapshot('./expected.html')\n})\n\n// Property matchers for dynamic values\nexpect(data).toMatchSnapshot({\n  id: expect.any(Number),\n  timestamp: expect.any(Date),\n  uuid: expect.stringMatching(/^[a-f0-9-]+$/)\n})\n\n// Update snapshots: vitest -u\n```\n\n## Testing Errors\n\n```ts\n// Sync errors\nexpect(() => throwError()).toThrow()\nexpect(() => throwError()).toThrow('specific message')\nexpect(() => throwError()).toThrow(/pattern/)\nexpect(() => throwError()).toThrowError(CustomError)\n\n// Async errors\nawait expect(asyncThrow()).rejects.toThrow()\nawait expect(asyncThrow()).rejects.toThrow('message')\n```\n\n## Anti-Patterns to Avoid\n\n```ts\n// Don't nest describes excessively\ndescribe('A', () => {\n  describe('B', () => {\n    describe('C', () => {\n      describe('D', () => { /* too nested */ })\n    })\n  })\n})\n\n// Don't forget await on async expects\nexpect(promise).resolves.toBe(value)  // Wrong - false positive!\nawait expect(promise).resolves.toBe(value)  // Correct\n\n// Don't test implementation details\nexpect(component.state.internalFlag).toBe(true)  // Brittle\n\n// Don't share state between tests\nlet sharedVariable\nit('test 1', () => { sharedVariable = 'value' })\nit('test 2', () => { expect(sharedVariable).toBe('value') }) // Flaky!\n\n// Don't vi.mock inside tests (hoisting issues)\nit('test', () => {\n  vi.mock('./module')  // Won't work!\n})\n```\n\n## Best Practices\n\n```ts\n// Keep describes shallow\ndescribe('UserService', () => {\n  it('creates user with valid data')\n  it('throws on invalid email')\n})\n\n// Always await async expects\nawait expect(promise).resolves.toBe(value)\n\n// Test behavior, not implementation\nexpect(getUserName()).toBe('John Doe')\n\n// Use beforeEach for isolation\nbeforeEach(() => {\n  state = createFreshState()\n})\n\n// vi.mock at top level (before imports)\nvi.mock('./module')\nimport { fn } from './module'\n```\n\n## Environment Methods\n\n| Method | Purpose |\n|--------|---------|\n| `vi.useFakeTimers()` | Enable fake timers |\n| `vi.useRealTimers()` | Restore real timers |\n| `vi.setSystemTime()` | Mock system time |\n| `vi.stubGlobal()` | Mock global variable |\n| `vi.stubEnv()` | Mock environment variable |\n",
        "skills/vitest-testing/SKILL.md": "---\nname: vitest-testing\ndescription: Vitest testing framework patterns and best practices. Use when writing unit tests, integration tests, configuring vitest.config, mocking with vi.mock/vi.fn, using snapshots, or setting up test coverage. Triggers on describe, it, expect, vi.mock, vi.fn, beforeEach, afterEach, vitest.\n---\n\n# Vitest Best Practices\n\n## Quick Reference\n\n```ts\nimport { describe, it, expect, beforeEach, vi } from 'vitest'\n\ndescribe('feature name', () => {\n  beforeEach(() => {\n    vi.clearAllMocks()\n  })\n\n  it('should do something specific', () => {\n    expect(actual).toBe(expected)\n  })\n\n  it.todo('planned test')\n  it.skip('temporarily disabled')\n  it.only('run only this during dev')\n})\n```\n\n## Common Assertions\n\n```ts\n// Equality\nexpect(value).toBe(42)                    // Strict (===)\nexpect(obj).toEqual({ a: 1 })             // Deep equality\nexpect(obj).toStrictEqual({ a: 1 })       // Strict deep (checks types)\n\n// Truthiness\nexpect(value).toBeTruthy()\nexpect(value).toBeFalsy()\nexpect(value).toBeNull()\nexpect(value).toBeUndefined()\n\n// Numbers\nexpect(0.1 + 0.2).toBeCloseTo(0.3)\nexpect(value).toBeGreaterThan(5)\n\n// Strings/Arrays\nexpect(str).toMatch(/pattern/)\nexpect(str).toContain('substring')\nexpect(array).toContain(item)\nexpect(array).toHaveLength(3)\n\n// Objects\nexpect(obj).toHaveProperty('key')\nexpect(obj).toHaveProperty('nested.key', 'value')\nexpect(obj).toMatchObject({ subset: 'of properties' })\n\n// Exceptions\nexpect(() => fn()).toThrow()\nexpect(() => fn()).toThrow('error message')\nexpect(() => fn()).toThrow(/pattern/)\n```\n\n## Async Testing\n\n```ts\n// Async/await (preferred)\nit('fetches data', async () => {\n  const data = await fetchData()\n  expect(data).toEqual({ id: 1 })\n})\n\n// Promise matchers - ALWAYS await these\nawait expect(fetchData()).resolves.toEqual({ id: 1 })\nawait expect(fetchData()).rejects.toThrow('Error')\n\n// Wrong - creates false positive\nexpect(promise).resolves.toBe(value)  // Missing await!\n```\n\n## Quick Mock Reference\n\n```ts\nconst mockFn = vi.fn()\nmockFn.mockReturnValue(42)\nmockFn.mockResolvedValue({ data: 'value' })\n\nexpect(mockFn).toHaveBeenCalled()\nexpect(mockFn).toHaveBeenCalledWith('arg1', 'arg2')\nexpect(mockFn).toHaveBeenCalledTimes(2)\n```\n\n## Additional Documentation\n\n- **Mocking**: See [references/mocking.md](references/mocking.md) for module mocking, spying, cleanup\n- **Configuration**: See [references/config.md](references/config.md) for vitest.config, setup files, coverage\n- **Patterns**: See [references/patterns.md](references/patterns.md) for timers, snapshots, anti-patterns\n\n## Test Methods Quick Reference\n\n| Method | Purpose |\n|--------|---------|\n| `it()` / `test()` | Define test |\n| `describe()` | Group tests |\n| `beforeEach()` / `afterEach()` | Per-test hooks |\n| `beforeAll()` / `afterAll()` | Per-suite hooks |\n| `.skip` | Skip test/suite |\n| `.only` | Run only this |\n| `.todo` | Placeholder |\n| `.concurrent` | Parallel execution |\n| `.each([...])` | Parameterized tests |\n",
        "skills/vitest-testing/references/config.md": "# Configuration\n\n## Contents\n\n- [Basic Config](#basic-config)\n- [Global Setup](#global-setup)\n- [DOM Testing](#dom-testing)\n- [Concurrent Tests](#concurrent-tests)\n- [Test Isolation](#test-isolation)\n- [Type Testing](#type-testing)\n- [Environment Variables](#environment-variables)\n- [Coverage Configuration](#coverage-configuration)\n\n---\n\n## Basic Config\n\n```ts\n// vitest.config.ts\nimport { defineConfig } from 'vitest/config'\n\nexport default defineConfig({\n  test: {\n    globals: true,              // Use global test APIs (describe, it, expect)\n    environment: 'node',        // 'node' | 'jsdom' | 'happy-dom'\n    setupFiles: './test/setup.ts',\n    coverage: {\n      provider: 'v8',           // 'v8' | 'istanbul'\n      reporter: ['text', 'json', 'html'],\n      exclude: ['**/*.test.ts', '**/node_modules/**']\n    },\n    include: ['**/*.test.ts'],\n    exclude: ['node_modules', 'dist'],\n    testTimeout: 10000,\n  }\n})\n```\n\n## Global Setup\n\n```ts\n// test/setup.ts\nimport { beforeEach, afterEach, vi } from 'vitest'\n\n// Global beforeEach/afterEach\nbeforeEach(() => {\n  vi.clearAllMocks()\n})\n\n// Extend matchers\nimport { expect } from 'vitest'\nexpect.extend({\n  toBeWithinRange(received, floor, ceiling) {\n    const pass = received >= floor && received <= ceiling\n    return {\n      pass,\n      message: () => `expected ${received} to be within ${floor}-${ceiling}`\n    }\n  }\n})\n```\n\n## DOM Testing\n\n```ts\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    environment: 'jsdom',\n    setupFiles: './test/setup.ts'\n  }\n})\n\n// Tests\nit('updates DOM', () => {\n  document.body.innerHTML = '<div id=\"app\"></div>'\n  const app = document.querySelector('#app')\n  expect(app).toBeTruthy()\n  expect(app?.textContent).toBe('')\n})\n```\n\n## Concurrent Tests\n\n```ts\n// Run tests in parallel\ndescribe.concurrent('suite', () => {\n  it('test 1', async () => { /* ... */ })\n  it('test 2', async () => { /* ... */ })\n})\n\n// Individual concurrent tests\nit.concurrent('test 1', async () => { /* ... */ })\nit.concurrent('test 2', async () => { /* ... */ })\n\n// Use local expect for concurrent tests\nit.concurrent('test', async ({ expect }) => {\n  expect(value).toBe(1)\n})\n```\n\n## Test Isolation\n\n```ts\nexport default defineConfig({\n  test: {\n    isolate: false,           // Share environment between tests (faster)\n    pool: 'threads',          // 'threads' | 'forks' | 'vmThreads'\n    poolOptions: {\n      threads: {\n        singleThread: true    // Run tests in single thread\n      }\n    }\n  }\n})\n```\n\n## Type Testing\n\n```ts\nimport { expectTypeOf, assertType } from 'vitest'\n\n// Compile-time type assertions\nexpectTypeOf({ a: 1 }).toEqualTypeOf<{ a: number }>()\nexpectTypeOf('string').toBeString()\nexpectTypeOf(promise).resolves.toBeNumber()\n\nassertType<string>('hello')  // Type guard\n```\n\n## Environment Variables\n\n```ts\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    env: {\n      TEST_VAR: 'test-value'\n    }\n  }\n})\n\n// Or use .env.test file\n// Tests can access via process.env.TEST_VAR\n```\n\n## Coverage Configuration\n\n```ts\nexport default defineConfig({\n  test: {\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html', 'lcov'],\n      reportsDirectory: './coverage',\n      include: ['src/**/*.ts'],\n      exclude: [\n        'node_modules',\n        'test',\n        '**/*.d.ts',\n        '**/*.test.ts',\n        '**/types.ts'\n      ],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80\n      }\n    }\n  }\n})\n```\n",
        "skills/vitest-testing/references/mocking.md": "# Mocking Patterns\n\n## Contents\n\n- [Module Mocking](#module-mocking)\n- [Function Mocking](#function-mocking)\n- [Mock Assertions](#mock-assertions)\n- [Spying](#spying)\n- [Mock Cleanup](#mock-cleanup)\n- [Mock Methods Quick Reference](#mock-methods-quick-reference)\n\n---\n\n## Module Mocking\n\n```ts\n// Mock entire module (hoisted automatically)\nvi.mock('./module', () => ({\n  namedExport: vi.fn(() => 'mocked'),\n  default: vi.fn()\n}))\n\n// Partial mock with importActual (two ways)\n// Option 1: Use vi.importActual directly\nvi.mock('./utils', async () => {\n  const actual = await vi.importActual<typeof import('./utils')>('./utils')\n  return {\n    ...actual,\n    specificFunction: vi.fn()\n  }\n})\n\n// Option 2: Use the importOriginal helper parameter\nvi.mock('./utils', async (importOriginal) => {\n  const actual = await importOriginal<typeof import('./utils')>()\n  return {\n    ...actual,\n    specificFunction: vi.fn()\n  }\n})\n\n// Access mocked module\nimport { specificFunction } from './utils'\nvi.mocked(specificFunction).mockReturnValue('value')\n\n// Mock with spy (keeps implementation)\nvi.mock('./calculator', { spy: true })\n```\n\n## Function Mocking\n\n```ts\n// Create mock function\nconst mockFn = vi.fn()\nconst mockFnWithImpl = vi.fn((x) => x * 2)\n\n// Mock return values\nmockFn.mockReturnValue(42)\nmockFn.mockReturnValueOnce(1).mockReturnValueOnce(2)\n\n// Mock async returns\nmockFn.mockResolvedValue({ data: 'value' })\nmockFn.mockRejectedValue(new Error('failed'))\n\n// Mock implementation\nmockFn.mockImplementation((arg) => arg + 1)\nmockFn.mockImplementationOnce(() => 'once')\n```\n\n## Mock Assertions\n\n```ts\nexpect(mockFn).toHaveBeenCalled()\nexpect(mockFn).toHaveBeenCalledTimes(2)\nexpect(mockFn).toHaveBeenCalledWith('arg1', 'arg2')\nexpect(mockFn).toHaveBeenLastCalledWith('arg')\nexpect(mockFn).toHaveReturnedWith(42)\n\n// Access mock state\nmockFn.mock.calls        // [['arg1'], ['arg2']]\nmockFn.mock.results      // [{ type: 'return', value: 42 }]\nmockFn.mock.lastCall     // ['arg2']\n```\n\n## Spying\n\n```ts\n// Spy on object methods\nconst obj = { method: () => 'real' }\nconst spy = vi.spyOn(obj, 'method')\n\n// Spy with custom implementation\nvi.spyOn(obj, 'method').mockImplementation(() => 'mocked')\n\n// Spy on getters/setters\nvi.spyOn(obj, 'property', 'get').mockReturnValue('value')\nvi.spyOn(obj, 'property', 'set')\n\n// Restore original\nspy.mockRestore()\n```\n\n## Mock Cleanup\n\n```ts\nimport { vi, beforeEach, afterEach } from 'vitest'\n\nbeforeEach(() => {\n  vi.clearAllMocks()    // Clear mock history\n  vi.resetAllMocks()    // Clear history + reset implementations\n  vi.restoreAllMocks()  // Restore original implementations (spies)\n})\n\n// Or configure in vitest.config.ts\nexport default defineConfig({\n  test: {\n    clearMocks: true,      // Auto-clear before each test\n    mockReset: true,       // Auto-reset before each test\n    restoreMocks: true,    // Auto-restore before each test\n  }\n})\n```\n\n## Mock Methods Quick Reference\n\n| Method | Purpose |\n|--------|---------|\n| `vi.fn()` | Create mock function |\n| `vi.spyOn()` | Spy on method |\n| `vi.mock()` | Mock module |\n| `vi.importActual()` | Import real module |\n| `vi.mocked()` | Type helper for mocks |\n| `vi.clearAllMocks()` | Clear call history |\n| `vi.resetAllMocks()` | Reset implementations |\n| `vi.restoreAllMocks()` | Restore originals |\n",
        "skills/vitest-testing/references/patterns.md": "# Common Patterns\n\n## Contents\n\n- [Fake Timers](#fake-timers)\n- [Waiting Utilities](#waiting-utilities)\n- [Snapshots](#snapshots)\n- [Testing Errors](#testing-errors)\n- [Anti-Patterns to Avoid](#anti-patterns-to-avoid)\n- [Best Practices](#best-practices)\n- [Environment Methods](#environment-methods)\n\n---\n\n## Fake Timers\n\n```ts\nimport { vi, beforeEach, afterEach } from 'vitest'\n\nbeforeEach(() => {\n  vi.useFakeTimers()\n})\n\nafterEach(() => {\n  vi.useRealTimers()\n})\n\nit('executes after timeout', () => {\n  const callback = vi.fn()\n  setTimeout(callback, 1000)\n\n  vi.advanceTimersByTime(1000)\n  expect(callback).toHaveBeenCalled()\n})\n\n// Timer methods\nvi.runAllTimers()\nvi.runOnlyPendingTimers()\nvi.advanceTimersByTime(1000)\nvi.advanceTimersToNextTimer()\nvi.setSystemTime(new Date('2024-01-01'))\n```\n\n## Waiting Utilities\n\n```ts\n// Wait for condition\nawait vi.waitFor(() => {\n  expect(element).toBeTruthy()\n}, { timeout: 1000, interval: 50 })\n\n// Wait until truthy\nconst element = await vi.waitUntil(\n  () => document.querySelector('.loaded'),\n  { timeout: 1000 }\n)\n```\n\n## Snapshots\n\n```ts\n// Basic snapshot\nit('matches snapshot', () => {\n  const data = { foo: 'bar' }\n  expect(data).toMatchSnapshot()\n})\n\n// Inline snapshot (updates test file)\nit('matches inline snapshot', () => {\n  expect(render()).toMatchInlineSnapshot(`\n    <div>\n      <h1>Title</h1>\n    </div>\n  `)\n})\n\n// File snapshot\nit('matches file snapshot', async () => {\n  const html = renderHTML()\n  await expect(html).toMatchFileSnapshot('./expected.html')\n})\n\n// Property matchers for dynamic values\nexpect(data).toMatchSnapshot({\n  id: expect.any(Number),\n  timestamp: expect.any(Date),\n  uuid: expect.stringMatching(/^[a-f0-9-]+$/)\n})\n\n// Update snapshots: vitest -u\n```\n\n## Testing Errors\n\n```ts\n// Sync errors\nexpect(() => throwError()).toThrow()\nexpect(() => throwError()).toThrow('specific message')\nexpect(() => throwError()).toThrow(/pattern/)\nexpect(() => throwError()).toThrowError(CustomError)\n\n// Async errors\nawait expect(asyncThrow()).rejects.toThrow()\nawait expect(asyncThrow()).rejects.toThrow('message')\n```\n\n## Anti-Patterns to Avoid\n\n```ts\n// Don't nest describes excessively\ndescribe('A', () => {\n  describe('B', () => {\n    describe('C', () => {\n      describe('D', () => { /* too nested */ })\n    })\n  })\n})\n\n// Don't forget await on async expects\nexpect(promise).resolves.toBe(value)  // Wrong - false positive!\nawait expect(promise).resolves.toBe(value)  // Correct\n\n// Don't test implementation details\nexpect(component.state.internalFlag).toBe(true)  // Brittle\n\n// Don't share state between tests\nlet sharedVariable\nit('test 1', () => { sharedVariable = 'value' })\nit('test 2', () => { expect(sharedVariable).toBe('value') }) // Flaky!\n\n// Don't vi.mock inside tests (hoisting issues)\nit('test', () => {\n  vi.mock('./module')  // Won't work!\n})\n```\n\n## Best Practices\n\n```ts\n// Keep describes shallow\ndescribe('UserService', () => {\n  it('creates user with valid data')\n  it('throws on invalid email')\n})\n\n// Always await async expects\nawait expect(promise).resolves.toBe(value)\n\n// Test behavior, not implementation\nexpect(getUserName()).toBe('John Doe')\n\n// Use beforeEach for isolation\nbeforeEach(() => {\n  state = createFreshState()\n})\n\n// vi.mock at top level (before imports)\nvi.mock('./module')\nimport { fn } from './module'\n```\n\n## Environment Methods\n\n| Method | Purpose |\n|--------|---------|\n| `vi.useFakeTimers()` | Enable fake timers |\n| `vi.useRealTimers()` | Restore real timers |\n| `vi.setSystemTime()` | Mock system time |\n| `vi.stubGlobal()` | Mock global variable |\n| `vi.stubEnv()` | Mock environment variable |\n",
        "skills/watchos-code-review/SKILL.md": "---\nname: watchos-code-review\ndescription: Reviews watchOS code for app lifecycle, complications (ClockKit/WidgetKit), WatchConnectivity, and performance constraints. Use when reviewing code with import WatchKit, WKExtension, WKApplicationDelegate, WCSession, or watchOS-specific patterns.\n---\n\n# watchOS Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| App lifecycle, scenes, background modes, extended runtime | [references/lifecycle.md](references/lifecycle.md) |\n| ClockKit, WidgetKit, timeline providers, Smart Stack | [references/complications.md](references/complications.md) |\n| WCSession, message passing, file transfer, reachability | [references/connectivity.md](references/connectivity.md) |\n| Memory limits, background refresh, battery optimization | [references/performance.md](references/performance.md) |\n\n## Review Checklist\n\n- [ ] SwiftUI App protocol used with `@WKApplicationDelegateAdaptor` for lifecycle events\n- [ ] `scenePhase` read from root view (not sheets/modals where it's always `.active`)\n- [ ] `WKExtendedRuntimeSession` started only while app is active (not from background)\n- [ ] Workout sessions recovered in `applicationDidFinishLaunching` (not just delegate)\n- [ ] Background tasks scheduled at least 5 minutes apart; next scheduled before completing current\n- [ ] `URLSessionDownloadTask` (not `DataTask`) used for background network requests\n- [ ] WidgetKit used instead of ClockKit for watchOS 9+ complications\n- [ ] Timeline includes future entries (not just current state); gaps avoided\n- [ ] `TimelineEntryRelevance` implemented for Smart Stack prioritization\n- [ ] WCSession delegate set before `activate()`; singleton pattern used\n- [ ] `isReachable` checked before `sendMessage`; `transferUserInfo` for critical data\n- [ ] Received files moved synchronously before delegate callback returns\n\n## When to Load References\n\n- Reviewing app lifecycle, background modes, or extended sessions -> lifecycle.md\n- Reviewing complications, widgets, or timeline providers -> complications.md\n- Reviewing WCSession, iPhone-Watch communication -> connectivity.md\n- Reviewing memory, battery, or performance issues -> performance.md\n\n## Review Questions\n\n1. Is the app using modern SwiftUI lifecycle with delegate adaptor?\n2. Are background tasks completing properly (calling `setTaskCompletedWithSnapshot`)?\n3. Is UI update frequency reduced when `isLuminanceReduced` is true?\n4. Are WatchConnectivity delegate callbacks dispatching to main thread?\n5. Is `TabView` nested within another `TabView`? (Memory leak on watchOS)\n",
        "skills/watchos-code-review/references/complications.md": "# watchOS Complications\n\n## Evolution\n\n- **ClockKit**: Deprecated framework (watchOS 2-8)\n- **WidgetKit**: Modern replacement (watchOS 9+)\n- **watchOS 10**: Smart Stack with relevance-based prioritization\n- **watchOS 11**: `RelevantContext` API for context-aware widgets\n\n## Widget Families (WidgetKit)\n\n| Family | Use Case | ClockKit Equivalent |\n|--------|----------|---------------------|\n| `accessoryRectangular` | Multiple lines, graphs | `graphicRectangular` |\n| `accessoryCircular` | Gauges, progress | `graphicCircular` variants |\n| `accessoryInline` | Single text line | `utilitarianSmallFlat` |\n| `accessoryCorner` | Icon + curved label (watchOS only) | `utilitarianSmall` |\n\n## Timeline Provider Types\n\n### Static Widget\n\n```swift\nstruct Provider: TimelineProvider {\n    func placeholder(in context: Context) -> SimpleEntry\n    func getSnapshot(in context: Context, completion: @escaping (SimpleEntry) -> ())\n    func getTimeline(in context: Context, completion: @escaping (Timeline<SimpleEntry>) -> ())\n}\n```\n\n### Configurable Widget (AppIntents)\n\n```swift\nstruct Provider: AppIntentTimelineProvider {\n    func placeholder(in context: Context) -> SimpleEntry\n    func snapshot(for configuration: ConfigIntent, in context: Context) async -> SimpleEntry\n    func timeline(for configuration: ConfigIntent, in context: Context) async -> Timeline<SimpleEntry>\n    func recommendations() -> [AppIntentRecommendation<ConfigIntent>]\n}\n```\n\n## Smart Stack Relevance\n\n```swift\nstruct SimpleEntry: TimelineEntry {\n    var date: Date\n    var event: Event?\n\n    var relevance: TimelineEntryRelevance? {\n        guard let event = event else {\n            return TimelineEntryRelevance(score: 0)\n        }\n        return TimelineEntryRelevance(\n            score: 10,\n            duration: event.endDate.timeIntervalSince(date)\n        )\n    }\n}\n```\n\n## Critical Anti-Patterns\n\n### 1. Exceeding Refresh Budget\n\n```swift\n// BAD: Called on every data change\nfunc dataDidUpdate() {\n    WidgetCenter.shared.reloadTimelines(ofKind: \"MyWidget\")\n}\n\n// GOOD: Throttle reloads, use timeline entries\nfunc getTimeline(...) {\n    var entries: [Entry] = []\n    for hourOffset in 0..<24 {\n        let date = Calendar.current.date(byAdding: .hour, value: hourOffset, to: Date())!\n        entries.append(Entry(date: date, data: predictedData(for: date)))\n    }\n    completion(Timeline(entries: entries, policy: .atEnd))\n}\n```\n\n**Budget**: ~40-70 refreshes/day (~every 15-60 minutes)\n\n### 2. Gaps in Timeline\n\n```swift\n// BAD: Only entries for events\nfunc getTimeline(...) {\n    for event in events {\n        entries.append(Entry(date: event.startDate, event: event))\n    }\n}\n\n// GOOD: Entries for state changes\nfunc getTimeline(...) {\n    entries.append(Entry(date: Date(), event: currentEvent))\n    for event in upcomingEvents {\n        entries.append(Entry(date: event.startDate, event: event))\n        entries.append(Entry(date: event.endDate, event: nil))  // End state\n    }\n}\n```\n\n### 3. Expensive Operations in Placeholder\n\n```swift\n// BAD: Blocks UI\nfunc placeholder(in context: Context) -> Entry {\n    let data = fetchLatestData()  // Network call!\n    return Entry(date: Date(), data: data)\n}\n\n// GOOD: Return static data immediately\nfunc placeholder(in context: Context) -> Entry {\n    return Entry(date: Date(), data: .placeholder)\n}\n```\n\n### 4. AsyncImage in Widget\n\n```swift\n// BAD: Won't work\nvar body: some View {\n    AsyncImage(url: imageURL)  // Widgets can't do async in view\n}\n\n// GOOD: Fetch in timeline provider\nfunc getTimeline(...) {\n    let imageData = try? Data(contentsOf: imageURL)\n    let entry = Entry(date: Date(), imageData: imageData)\n    completion(Timeline(entries: [entry], policy: .atEnd))\n}\n```\n\n### 5. Not Implementing Migration\n\n```swift\n// BAD: User complications become blank\nclass ComplicationController: NSObject, CLKComplicationDataSource {\n    // Missing: var widgetMigrator: CLKComplicationWidgetMigrator\n}\n\n// GOOD: Implement migration\nextension ComplicationController: CLKComplicationWidgetMigrator {\n    func widgetConfiguration(\n        from descriptor: CLKComplicationDescriptor\n    ) async -> CLKComplicationWidgetMigrationConfiguration? {\n        return CLKComplicationStaticWidgetMigrationConfiguration(\n            kind: \"MyWidget\",\n            extensionBundleIdentifier: \"com.myapp.widget\"\n        )\n    }\n}\n```\n\n## Key Modifiers\n\n| Modifier | Purpose |\n|----------|---------|\n| `.widgetAccentable()` | Mark for accent coloring |\n| `.widgetLabel { }` | Curved text for corner/circular |\n| `.containerBackground(for: .widget)` | Smart Stack background |\n| `.privacySensitive()` | Redact in Always-On |\n| `AccessoryWidgetBackground()` | Consistent backdrop |\n\n## Always-On Display\n\n```swift\nvar body: some View {\n    VStack {\n        Image(systemName: \"heart.fill\")\n            .widgetAccentable()\n\n        if isLuminanceReduced {\n            Text(\"\\(value)\")\n                .redacted(reason: .placeholder)  // Hide sensitive\n        } else {\n            Text(\"\\(value) BPM\")\n                .privacySensitive()\n        }\n    }\n}\n```\n\n## Review Questions\n\n1. Is WidgetKit used instead of ClockKit (watchOS 9+)?\n2. Does `placeholder()` return immediately without async work?\n3. Does the timeline include future entries (not just current)?\n4. Is `TimelineEntryRelevance` implemented for Smart Stack?\n5. Is `.privacySensitive()` applied to sensitive content?\n6. Is `@Environment(\\.isLuminanceReduced)` checked for Always-On?\n7. Are images pre-fetched (not using AsyncImage)?\n8. Is ClockKit migration implemented if updating from older app?\n",
        "skills/watchos-code-review/references/connectivity.md": "# WatchConnectivity\n\n## Communication Methods\n\n| Method | Use Case | Guaranteed | Queuing |\n|--------|----------|------------|---------|\n| `sendMessage(_:)` | Real-time, immediate | No | None |\n| `transferUserInfo(_:)` | Critical data | Yes | FIFO |\n| `updateApplicationContext(_:)` | State sync, latest only | Yes (latest) | Overwrites |\n| `transferFile(_:)` | Large files | Yes | FIFO |\n| `transferCurrentComplicationUserInfo(_:)` | Complication data | Yes | Budget limited |\n\n## Session Setup\n\n```swift\nfinal class WatchConnectivityService: NSObject, WCSessionDelegate {\n    static let shared = WatchConnectivityService()\n\n    override private init() {\n        super.init()\n        #if !os(watchOS)\n        guard WCSession.isSupported() else { return }\n        #endif\n        WCSession.default.delegate = self\n        WCSession.default.activate()\n    }\n}\n```\n\n## Required Delegate Methods\n\n**iOS (all three required):**\n- `session(_:activationDidCompleteWith:error:)`\n- `sessionDidBecomeInactive(_:)`\n- `sessionDidDeactivate(_:)`\n\n**watchOS (one required):**\n- `session(_:activationDidCompleteWith:error:)`\n\n## Pre-Send Validation\n\n```swift\nprivate func canSendToPeer() -> Bool {\n    guard WCSession.default.activationState == .activated else { return false }\n\n    #if os(watchOS)\n    guard WCSession.default.isCompanionAppInstalled else { return false }\n    #else\n    guard WCSession.default.isWatchAppInstalled else { return false }\n    #endif\n\n    return true\n}\n\n// For sendMessage only\nif WCSession.default.isReachable {\n    WCSession.default.sendMessage(message, replyHandler: nil, errorHandler: nil)\n}\n```\n\n## Critical Anti-Patterns\n\n### 1. Setup in View Controller\n\n```swift\n// BAD: Won't be called during background launches\nclass MyViewController: UIViewController {\n    override func viewDidLoad() {\n        WCSession.default.delegate = self\n        WCSession.default.activate()\n    }\n}\n\n// GOOD: Singleton in early lifecycle\n// In AppDelegate\nfunc application(...) -> Bool {\n    _ = WatchConnectivityService.shared\n    return true\n}\n```\n\n### 2. Using sendMessage for Critical Data\n\n```swift\n// BAD: Lost when counterpart not reachable\nfunc sendToWatch(_ data: [String: Any]) {\n    WCSession.default.sendMessage(data, replyHandler: nil, errorHandler: nil)\n}\n\n// GOOD: Use appropriate method based on criticality\nfunc sendToWatch(_ data: [String: Any], critical: Bool) {\n    guard canSendToPeer() else { return }\n\n    if critical {\n        WCSession.default.transferUserInfo(data)\n    } else if WCSession.default.isReachable {\n        WCSession.default.sendMessage(data, replyHandler: nil, errorHandler: nil)\n    }\n}\n```\n\n### 3. UI Updates on Background Thread\n\n```swift\n// BAD: Delegate runs on background thread\nfunc session(_ session: WCSession, didReceiveMessage message: [String: Any]) {\n    self.label.text = message[\"text\"] as? String  // Crash!\n}\n\n// GOOD: Dispatch to main\nfunc session(_ session: WCSession, didReceiveMessage message: [String: Any]) {\n    DispatchQueue.main.async {\n        self.label.text = message[\"text\"] as? String\n    }\n}\n```\n\n### 4. Async File Handling\n\n```swift\n// BAD: File deleted before async completes\nfunc session(_ session: WCSession, didReceive file: WCSessionFile) {\n    DispatchQueue.global().async {\n        try? FileManager.default.moveItem(at: file.fileURL, to: destination)\n    }\n}\n\n// GOOD: Synchronous move first\nfunc session(_ session: WCSession, didReceive file: WCSessionFile) {\n    do {\n        try FileManager.default.moveItem(at: file.fileURL, to: destination)\n        DispatchQueue.main.async {\n            self.processFile(at: destination)\n        }\n    } catch {\n        print(\"Failed: \\(error)\")\n    }\n}\n```\n\n### 5. Not Reactivating After Deactivation\n\n```swift\n// BAD: Session unusable after watch swap\nfunc sessionDidDeactivate(_ session: WCSession) {\n    // Nothing\n}\n\n// GOOD: Reactivate for watch swaps\nfunc sessionDidDeactivate(_ session: WCSession) {\n    WCSession.default.activate()\n}\n```\n\n### 6. Reply Handler When Not Expecting Reply\n\n```swift\n// BAD: OS generates errors\nWCSession.default.sendMessage(data, replyHandler: { _ in }, errorHandler: nil)\n\n// GOOD: nil when no reply expected\nWCSession.default.sendMessage(data, replyHandler: nil, errorHandler: { error in\n    print(\"Error: \\(error)\")\n})\n```\n\n## Data Type Requirements\n\nOnly Plist-encodable types allowed:\n- String, Int, Double, Bool\n- Data\n- Array, Dictionary (of above types)\n\n```swift\n// BAD: Custom types\nWCSession.default.sendMessage([\"user\": myUser], ...)\n\n// GOOD: Encode first\nlet data = try JSONEncoder().encode(myUser)\nWCSession.default.sendMessage([\"userData\": data], ...)\n```\n\n## Review Questions\n\n1. Is `WCSession.isSupported()` checked on iOS before setup?\n2. Is delegate set before `activate()` (use singleton)?\n3. Is `activationState == .activated` checked before sending?\n4. Is `isReachable` checked for `sendMessage` calls?\n5. Is `transferUserInfo` used for data that must be delivered?\n6. Are delegate callbacks dispatching UI updates to main thread?\n7. Are received files moved synchronously before delegate returns?\n8. Is `sessionDidDeactivate` reactivating the session on iOS?\n9. Are only Plist-encodable types being sent?\n",
        "skills/watchos-code-review/references/lifecycle.md": "# WatchKit App Lifecycle\n\n## Lifecycle Architecture\n\nwatchOS uses two lifecycle models:\n\n### SwiftUI App Protocol (Modern)\n\n```swift\n@main\nstruct MyWatchApp: App {\n    @WKApplicationDelegateAdaptor var appDelegate: MyAppDelegate\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n```\n\n### WKApplicationDelegate\n\nUse for lifecycle events not covered by SwiftUI's `scenePhase`. Note: `WKExtensionDelegate` was renamed to `WKApplicationDelegate` in Xcode 14.\n\n### Scene Phase States\n\n| State | Description |\n|-------|-------------|\n| `.active` | App in foreground, user can interact |\n| `.inactive` | Visible but no interaction (wrist lowered, screen on) |\n| `.background` | Not visible, may be terminated |\n\n**Note**: On watchOS, `.inactive` does NOT mean the app isn't running.\n\n## Background Execution Modes\n\n| Mode | Use Case | Constraints |\n|------|----------|-------------|\n| `BGAppRefreshTask` | Data updates | 4 per hour; 4s CPU, 15s total |\n| `HKWorkoutSession` | Workout tracking | Continuous; use for workouts only |\n| `WKExtendedRuntimeSession` | Self-care, mindfulness | Start while active only |\n| Background URLSession | Downloads | Requires complication or dock |\n\n### WKExtendedRuntimeSession Types\n\n| Type | Duration | Notes |\n|------|----------|-------|\n| Self Care | 10 minutes | |\n| Mindfulness | 1 hour | |\n| Physical Therapy | 1 hour | Allows background multitasking |\n| Health Monitoring | Variable | Requires entitlement |\n| Alarm | 30 minutes | Use `startAtDate()` to schedule |\n\n## Critical Anti-Patterns\n\n### 1. Heavy Work in Lifecycle Methods\n\n```swift\n// BAD: Slows resume time\nfunc applicationDidBecomeActive() {\n    loadAllDataFromDisk()\n    syncWithServer()\n}\n\n// GOOD: Defer to background\nfunc applicationDidBecomeActive() {\n    Task.detached(priority: .background) {\n        await self.prefetchData()\n    }\n}\n```\n\n### 2. Reading scenePhase in Sheets\n\n```swift\n// BAD: Always returns .active in sheets\nstruct SettingsSheet: View {\n    @Environment(\\.scenePhase) var scenePhase  // Broken!\n}\n\n// GOOD: Pass from root view\nstruct ContentView: View {\n    @Environment(\\.scenePhase) var scenePhase\n\n    var body: some View {\n        Button(\"Settings\") { showSettings = true }\n            .sheet(isPresented: $showSettings) {\n                SettingsSheet(scenePhase: scenePhase)\n            }\n    }\n}\n```\n\n### 3. Starting Extended Sessions from Background\n\n```swift\n// BAD: Cannot start from background\nfunc applicationDidEnterBackground() {\n    let session = WKExtendedRuntimeSession()\n    session.start()  // Error!\n}\n\n// GOOD: Start while active\nfunc startMindfulnessSession() {\n    guard WKApplication.shared().applicationState == .active else { return }\n    extendedSession = WKExtendedRuntimeSession()\n    extendedSession?.start()\n}\n```\n\n### 4. Not Recovering Workout Sessions\n\n```swift\n// BAD: handleActiveWorkoutRecovery NOT called on reboot\nclass AppDelegate: NSObject, WKApplicationDelegate {\n    func handleActiveWorkoutRecovery() {\n        recoverWorkout()\n    }\n}\n\n// GOOD: Check in applicationDidFinishLaunching\nfunc applicationDidFinishLaunching() {\n    Task {\n        do {\n            let (session, builder) = try await HKHealthStore().recoverActiveWorkoutSession()\n            workoutManager.resume(session: session, builder: builder)\n        } catch {\n            // No session to recover\n        }\n    }\n}\n```\n\n### 5. Network Calls During Background Transition\n\n```swift\n// BAD: Not enough time\nfunc applicationWillResignActive() {\n    URLSession.shared.dataTask(with: url) { ... }  // Won't complete\n}\n\n// GOOD: Use expiring activity\nfunc applicationWillResignActive() {\n    ProcessInfo.processInfo.performExpiringActivity(withReason: \"Sync\") { expired in\n        guard !expired else { return }\n        self.quickSync()\n    }\n}\n```\n\n## Background App Refresh\n\n### Correct Pattern\n\n```swift\nfunc handle(_ backgroundTasks: Set<WKRefreshBackgroundTask>) {\n    for task in backgroundTasks {\n        if let refreshTask = task as? WKApplicationRefreshBackgroundTask {\n            // 1. Schedule next FIRST\n            scheduleNextRefresh()\n\n            // 2. Use download task (not data task)\n            let config = URLSessionConfiguration.background(withIdentifier: \"com.app.refresh\")\n            let session = URLSession(configuration: config, delegate: self, delegateQueue: nil)\n            session.downloadTask(with: url).resume()\n\n            // 3. Complete this task\n            refreshTask.setTaskCompletedWithSnapshot(false)\n        }\n    }\n}\n\nfunc scheduleNextRefresh() {\n    // At least 5 minutes in future\n    let preferredDate = Date().addingTimeInterval(5 * 60)\n    WKApplication.shared().scheduleBackgroundRefresh(\n        withPreferredDate: preferredDate,\n        userInfo: nil\n    ) { _ in }\n}\n```\n\n## Review Questions\n\n1. Is SwiftUI App protocol used with `@WKApplicationDelegateAdaptor` for lifecycle events?\n2. Is `scenePhase` read from root view (not sheets/modals)?\n3. Are extended runtime sessions started only while app is active?\n4. Is `HKHealthStore().recoverActiveWorkoutSession()` called in `applicationDidFinishLaunching`?\n5. Are background tasks scheduled at least 5 minutes apart?\n6. Is `URLSessionDownloadTask` (not `DataTask`) used for background network?\n7. Is next refresh scheduled BEFORE completing current task?\n",
        "skills/watchos-code-review/references/performance.md": "# watchOS Performance\n\n## Constraints\n\n### Memory\n\n| Constraint | Limit |\n|------------|-------|\n| Device RAM | ~1 GB (Series 9/10/Ultra 2) |\n| App bundle | ~50 MB |\n| Widget/Complication images | ~30 MB |\n| Background task memory | Limited |\n\n### CPU and Battery\n\n| Constraint | Limit |\n|------------|-------|\n| CPU usage threshold | <80% sustained |\n| Background task duration | ~3 min when backgrounding; ~30s when resumed |\n| Background refresh | 4 per hour with complication; 15+ min apart |\n| Extended runtime | Battery-intensive; end promptly |\n\n### Network\n\n| Consideration | Details |\n|---------------|---------|\n| Connection | URLSession abstracts Bluetooth/Wi-Fi/cellular |\n| WebSocket/Stream | Not supported |\n| Background minimum interval | 10+ minutes recommended |\n\n## Critical Anti-Patterns\n\n### 1. Nested TabViews (Memory Leak)\n\n```swift\n// BAD: Causes memory leaks\nNavigationStack {\n    TabView {\n        TabView {  // DON'T NEST!\n            ContentView()\n        }\n    }\n}\n\n// GOOD: Single level\nNavigationStack {\n    TabView {\n        ContentView()\n    }\n}\n```\n\n### 2. Not Completing Background Tasks\n\n```swift\n// BAD: Missing completion handler\nfunc handle(_ backgroundTasks: Set<WKRefreshBackgroundTask>) {\n    for task in backgroundTasks {\n        if let refreshTask = task as? WKApplicationRefreshBackgroundTask {\n            doWork()\n            // MISSING: setTaskCompletedWithSnapshot!\n        }\n    }\n}\n\n// GOOD: Always complete with defer\nfunc handle(_ backgroundTasks: Set<WKRefreshBackgroundTask>) {\n    for task in backgroundTasks {\n        if let refreshTask = task as? WKApplicationRefreshBackgroundTask {\n            defer { refreshTask.setTaskCompletedWithSnapshot(false) }\n            doWork()\n        }\n    }\n}\n```\n\n### 3. Protected File Access in Background\n\n```swift\n// BAD: Fails when screen locked\nfunc backgroundHandler() {\n    let data = try? Data(contentsOf: protectedFileURL)  // Fails!\n}\n\n// GOOD: Use no file protection for background data\ntry data.write(to: url, options: .noFileProtection)\n```\n\n### 4. WKInterface Property Updates\n\n```swift\n// BAD: Each property = ~200ms message\nfunc updateUI() {\n    label.setText(newText)      // Update 1\n    label.setTextColor(.red)    // Update 2\n    image.setImage(newImage)    // Update 3\n}\n\n// GOOD: Only set when values change\nfunc updateUI() {\n    if textChanged {\n        label.setText(newText)\n    }\n    if colorChanged {\n        label.setTextColor(.red)\n    }\n}\n```\n\n### 5. Constant UI Updates During Workout\n\n```swift\n// BAD: Updates even when dimmed\nstruct WorkoutView: View {\n    let timer = Timer.publish(every: 1, on: .main, in: .common).autoconnect()\n\n    var body: some View {\n        Text(\"\\(heartRate)\")\n            .onReceive(timer) { _ in updateUI() }\n    }\n}\n\n// GOOD: Adaptive update rate\nstruct WorkoutView: View {\n    @Environment(\\.isLuminanceReduced) var isLuminanceReduced\n\n    var body: some View {\n        TimelineView(.periodic(from: .now, by: updateInterval)) { _ in\n            Text(\"\\(heartRate)\")\n        }\n    }\n\n    var updateInterval: TimeInterval {\n        isLuminanceReduced ? 10.0 : 1.0  // Slower when dimmed\n    }\n}\n```\n\n### 6. Large WKInterfaceTable\n\n```swift\n// BAD: All cells load upfront (no reuse)\nfunc loadTable(items: [Item]) {\n    table.setNumberOfRows(items.count, withRowType: \"Row\")  // 100+ rows = bad\n}\n\n// GOOD: Keep under 20 rows, use incremental updates\nfunc loadTable(items: [Item]) {\n    let limitedItems = Array(items.prefix(20))\n    table.setNumberOfRows(limitedItems.count, withRowType: \"Row\")\n}\n\nfunc addRows(at indexes: IndexSet) {\n    table.insertRows(at: indexes, withRowType: \"Row\")  // Incremental\n}\n```\n\n### 7. Loading All Data\n\n```swift\n// BAD: Load everything\nfunc loadRecords() async -> [Record] {\n    return await database.fetchAll()\n}\n\n// GOOD: Load what's displayed\nfunc loadRecords(limit: Int = 10) async -> [Record] {\n    return await database.fetch(limit: limit)\n}\n```\n\n## Battery Optimization\n\n### Extended Runtime Sessions\n\n```swift\n// Always end when activity completes\nclass MindfulnessManager {\n    var session: WKExtendedRuntimeSession?\n\n    func startSession(duration: TimeInterval) {\n        session = WKExtendedRuntimeSession()\n        session?.start()\n\n        DispatchQueue.main.asyncAfter(deadline: .now() + duration) { [weak self] in\n            self?.session?.invalidate()\n            self?.session = nil\n        }\n    }\n}\n```\n\n### Image Optimization\n\n```swift\n// Downsample to display size\nfunc displayImage(_ image: UIImage, targetSize: CGSize) {\n    let renderer = UIGraphicsImageRenderer(size: targetSize)\n    let downsampledImage = renderer.image { _ in\n        image.draw(in: CGRect(origin: .zero, size: targetSize))\n    }\n    imageView.setImage(downsampledImage)\n}\n```\n\n### HealthKit Queries\n\n```swift\n// Store and stop long-running queries\nclass HealthManager {\n    var observerQuery: HKObserverQuery?\n\n    deinit {\n        if let query = observerQuery {\n            healthStore.stop(query)\n        }\n    }\n}\n```\n\n## Review Questions\n\n1. Is `TabView` nested within another `TabView`? (Memory leak)\n2. Are all `WKRefreshBackgroundTask` completion handlers called?\n3. Are files using `.noFileProtection` if accessed in background?\n4. Is UI update frequency reduced when `isLuminanceReduced` is true?\n5. Is `WKExtendedRuntimeSession` invalidated when activity completes?\n6. Are WKInterface properties only set when values change?\n7. Are WKInterfaceTables kept under 20 rows?\n8. Are images downsampled to display size?\n9. Are long-running queries stored and stopped in `deinit`?\n",
        "skills/widgetkit-code-review/SKILL.md": "---\nname: widgetkit-code-review\ndescription: Reviews WidgetKit code for timeline management, view composition, configurable intents, and performance. Use when reviewing code with import WidgetKit, TimelineProvider, Widget protocol, or @main struct Widget.\n---\n\n# WidgetKit Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| TimelineProvider, entries, reload policies | [references/timeline.md](references/timeline.md) |\n| Widget families, containerBackground, deep linking | [references/views.md](references/views.md) |\n| AppIntentConfiguration, EntityQuery, @Parameter | [references/intents.md](references/intents.md) |\n| Refresh budget, memory limits, caching | [references/performance.md](references/performance.md) |\n\n## Review Checklist\n\n- [ ] `placeholder(in:)` returns immediately without async work\n- [ ] Timeline entries spaced at least 5 minutes apart\n- [ ] `getSnapshot` checks `context.isPreview` for gallery previews\n- [ ] `containerBackground(for:)` used for iOS 17+ compatibility\n- [ ] `widgetURL` used for systemSmall (not Link)\n- [ ] No Button views (use Link or widgetURL)\n- [ ] No AsyncImage or UIViewRepresentable in widget views\n- [ ] Images downsampled to widget display size (~30MB limit)\n- [ ] App Groups configured for data sharing between app and widget\n- [ ] EntityQuery implements `defaultResult()` for non-optional parameters\n- [ ] New intent parameters handle nil for existing widgets after updates\n- [ ] `reloadTimelines` called strategically (not on every data change)\n\n## When to Load References\n\n- TimelineProvider implementation or refresh issues -> timeline.md\n- Widget sizes, Lock Screen, containerBackground -> views.md\n- Configurable widgets, AppIntent migration -> intents.md\n- Memory issues, caching, budget management -> performance.md\n\n## Review Questions\n\n1. Does the widget provide fallback entries for when system delays refresh?\n2. Are Lock Screen families (accessoryCircular/Rectangular/Inline) handled appropriately?\n3. Would migrating from IntentConfiguration break existing user widgets?\n4. Is timeline populated with future entries or does it rely on frequent refreshes?\n5. Is data cached via App Groups for widget access?\n",
        "skills/widgetkit-code-review/references/intents.md": "# Configurable Widgets\n\n## Configuration Approaches\n\n| Approach | iOS | Status |\n|----------|-----|--------|\n| `StaticConfiguration` | 14+ | Non-configurable widgets |\n| `IntentConfiguration` | 14+ | Legacy SiriKit intents |\n| `AppIntentConfiguration` | 17+ | Modern App Intents |\n\n**Migration warning**: Changing from `IntentConfiguration` to `AppIntentConfiguration` can cause existing user widgets to disappear or freeze.\n\n## AppIntentTimelineProvider\n\n```swift\nstruct ConfigurableProvider: AppIntentTimelineProvider {\n    func placeholder(in context: Context) -> MyEntry { .placeholder }  // Sync, instant\n\n    func snapshot(for config: MyIntent, in context: Context) async -> MyEntry {\n        MyEntry(date: .now, item: config.selectedItem)\n    }\n\n    func timeline(for config: MyIntent, in context: Context) async -> Timeline<MyEntry> {\n        let entry = MyEntry(date: .now, item: config.selectedItem)\n        return Timeline(entries: [entry], policy: .after(.now.addingTimeInterval(900)))\n    }\n}\n```\n\n## Widget Configuration\n\n```swift\nstruct MyWidgetIntent: WidgetConfigurationIntent {\n    static var title: LocalizedStringResource = \"Configure Widget\"\n\n    @Parameter(title: \"Name\", default: \"Default\") var name: String\n    @Parameter(title: \"Style\") var style: DisplayStyle  // AppEnum\n    @Parameter(title: \"Item\") var selectedItem: ItemEntity?  // AppEntity\n}\n\nstruct MyWidget: Widget {\n    var body: some WidgetConfiguration {\n        AppIntentConfiguration(kind: \"com.app.widget\", intent: MyWidgetIntent.self,\n                               provider: ConfigurableProvider()) { entry in\n            MyWidgetView(entry: entry)\n        }\n    }\n}\n```\n\n## Dynamic Options\n\n### EntityStringQuery for Custom Types\n\n```swift\nstruct ItemEntity: AppEntity {\n    static var defaultQuery = ItemQuery()\n    var id: String\n    var name: String\n    var displayRepresentation: DisplayRepresentation { DisplayRepresentation(title: \"\\(name)\") }\n}\n\nstruct ItemQuery: EntityStringQuery {\n    func entities(for identifiers: [String]) async throws -> [ItemEntity] { /* fetch by IDs */ }\n    func entities(matching string: String) async throws -> [ItemEntity] { /* search */ }\n    func suggestedEntities() async throws -> [ItemEntity] { /* default list */ }\n    func defaultResult() async -> ItemEntity? { /* REQUIRED for non-optional params */ }\n}\n```\n\n### DynamicOptionsProvider for Simple Types\n\n```swift\n@Parameter(title: \"Hour\", optionsProvider: HourOptionsProvider()) var hour: Int\n\nstruct HourOptionsProvider: DynamicOptionsProvider {\n    func results() async throws -> [Int] { Array(0..<24) }\n    func defaultResult() async -> Int? { 12 }\n}\n```\n\n## Critical Anti-Patterns\n\n### Missing defaultResult()\n```swift\n// BAD: Widget shows \"Select\" instead of value\nstruct ItemQuery: EntityStringQuery { /* no defaultResult() */ }\n\n// GOOD: Always implement for non-optional entity parameters\nfunc defaultResult() async -> ItemEntity? { items.first }\n```\n\n### Ignoring Nil After App Updates\n```swift\n// BAD: Parameters added in updates are nil for existing widgets\nlet name = config.newParameter.name  // Crash!\n\n// GOOD: Handle optional parameters\nlet name = config.newParameter?.name ?? \"Default\"\n```\n\n### Heavy Work in Placeholder\n```swift\n// BAD: Blocks UI\nfunc placeholder(in context: Context) -> Entry { Entry(data: fetchSync()) }\n\n// GOOD: Return static data instantly\nfunc placeholder(in context: Context) -> Entry { .placeholder }\n```\n\n### Breaking Migration\n```swift\n// BAD: Same kind causes widget disappearance\nAppIntentConfiguration(kind: \"widget\", ...)  // Was IntentConfiguration\n\n// GOOD: Use new kind for new configuration type\nAppIntentConfiguration(kind: \"widget.v2\", ...)\n```\n\n## Review Questions\n\n1. **Does EntityQuery implement `defaultResult()`?** Missing causes \"Select\" UI instead of default.\n2. **Are new parameters optional-safe?** Parameters added in updates are nil for existing widgets.\n3. **Is placeholder instant?** Must be synchronous with static data only.\n4. **Does migration use new kind?** Same kind string breaks existing widgets.\n5. **Is configuration stored in timeline entry?** Entry must hold intent for view access.\n6. **Are AppEntity types Codable?** Required for WidgetKit to persist configuration.\n",
        "skills/widgetkit-code-review/references/performance.md": "# Widget Performance\n\n## Budget System\n\nWidgets operate under strict refresh budgets to conserve battery:\n\n- **Daily budget**: 40-70 refreshes for frequently viewed widgets\n- **Refresh interval**: Every 15-60 minutes in production\n- **Debug mode**: No limits during development\n\n### Timeline Policies\n\n```swift\nTimeline(entries: entries, policy: .atEnd)       // Refresh when timeline exhausted\nTimeline(entries: entries, policy: .after(date)) // Refresh after specific date\nTimeline(entries: entries, policy: .never)       // Manual refresh via reloadTimelines()\n```\n\nPopulate timelines with as many future entries as possible. Keep entries at least 5 minutes apart.\n\n## Memory Limits\n\nWidgets are constrained to approximately **30MB** - this applies collectively across all timeline entries.\n\n```swift\n// BAD: Loading full-resolution images\nlet image = UIImage(contentsOfFile: path)\n\n// GOOD: Downsample to widget display size\nfunc downsample(imageAt url: URL, to size: CGSize, scale: CGFloat) -> UIImage? {\n    let options = [kCGImageSourceShouldCache: false] as CFDictionary\n    guard let source = CGImageSourceCreateWithURL(url as CFURL, options) else { return nil }\n    let maxDim = max(size.width, size.height) * scale\n    let downsampleOptions = [\n        kCGImageSourceCreateThumbnailFromImageAlways: true,\n        kCGImageSourceThumbnailMaxPixelSize: maxDim\n    ] as CFDictionary\n    guard let cg = CGImageSourceCreateThumbnailAtIndex(source, 0, downsampleOptions) else { return nil }\n    return UIImage(cgImage: cg)\n}\n```\n\n## Data Fetching\n\nNetwork calls must complete within timeline generation. Never call APIs in `getSnapshot()`:\n\n```swift\nfunc getTimeline(in context: Context, completion: @escaping (Timeline<Entry>) -> Void) {\n    Task {\n        guard let data = try? await fetchData() else {\n            completion(Timeline(entries: [Entry(date: Date(), data: cachedData)], policy: .after(Date().addingTimeInterval(900))))\n            return\n        }\n        completion(Timeline(entries: [Entry(date: Date(), data: data)], policy: .after(Date().addingTimeInterval(3600))))\n    }\n}\n\nfunc getSnapshot(in context: Context, completion: @escaping (Entry) -> Void) {\n    completion(context.isPreview ? .sample : Entry(date: Date(), data: cachedData ?? .sample))\n}\n```\n\nFor background downloads, use `onBackgroundURLSessionEvents` modifier on the widget configuration.\n\n## Caching Strategies\n\n### App Groups for Shared Data\n\n```swift\nlet sharedDefaults = UserDefaults(suiteName: \"group.com.yourapp.widgets\")\n\n// Main app: save and notify widget\nfunc saveWidgetData(_ data: WidgetData) {\n    if let encoded = try? JSONEncoder().encode(data) {\n        sharedDefaults?.set(encoded, forKey: \"widgetData\")\n        WidgetCenter.shared.reloadAllTimelines()\n    }\n}\n\n// Widget: read cached data\nfunc loadWidgetData() -> WidgetData? {\n    guard let data = sharedDefaults?.data(forKey: \"widgetData\") else { return nil }\n    return try? JSONDecoder().decode(WidgetData.self, from: data)\n}\n```\n\nBoth app and widget extension must have the same App Group in Signing & Capabilities.\n\n## Critical Anti-Patterns\n\n### AsyncImage Not Supported\n\n```swift\n// BAD: Widgets render synchronously\nAsyncImage(url: imageURL)\n\n// GOOD: Pre-fetch in timeline provider\nImage(uiImage: cachedImage)\n```\n\n### Excessive Reloads\n\n```swift\n// BAD: Burns budget quickly\nWidgetCenter.shared.reloadAllTimelines()\n\n// GOOD: Reload specific widget strategically\nWidgetCenter.shared.reloadTimelines(ofKind: \"specificWidget\")\n```\n\n### UIKit Components\n\n```swift\n// BAD: UIViewRepresentable not supported\nMapViewRepresentable()\n\n// GOOD: Use MKMapSnapshotter for map images\nImage(uiImage: mapSnapshot)\n```\n\n### Keychain Access\n\nKeychain can fail with `errSecInteractionNotAllowed` after extended periods. Use App Groups instead.\n\n### Sparse Timelines\n\n```swift\n// BAD: Forces frequent refreshes\nTimeline(entries: [entry], policy: .after(Date().addingTimeInterval(60)))\n\n// GOOD: Pre-computed entries\nlet entries = (0..<24).map { Entry(date: Date().addingTimeInterval(Double($0) * 3600), data: data) }\nTimeline(entries: entries, policy: .atEnd)\n```\n\n## Review Questions\n\n1. Does the widget downsample images to display size, or load full-resolution assets?\n2. Are timeline entries pre-computed for future dates to minimize refresh frequency?\n3. Does `getSnapshot()` avoid network calls and use cached/sample data?\n4. Is App Groups configured correctly for both app and widget extension targets?\n5. Are `reloadTimelines()` calls strategic, or does every data update trigger a reload?\n6. Does the widget view avoid AsyncImage and other async loading patterns?\n",
        "skills/widgetkit-code-review/references/timeline.md": "# Timeline Management\n\n## Core Concepts\n\nWidgetKit renders widgets as static snapshots at predetermined times. The system controls refresh timing to optimize battery life, allowing 40-70 refreshes per day (every 15-60 minutes). Timeline entries should be at least 5 minutes apart. The system may delay refreshes significantly beyond requested times.\n\n## TimelineProvider Protocol\n\nThree required methods with distinct purposes:\n\n| Method | Sync/Async | Purpose |\n|--------|-----------|---------|\n| `placeholder(in:)` | Synchronous | Redacted loading state; return immediately |\n| `getSnapshot(in:completion:)` | Async | Widget gallery preview; check `context.isPreview` |\n| `getTimeline(in:completion:)` | Async | Primary content; returns entries array + reload policy |\n\n```swift\nstruct Provider: TimelineProvider {\n    func placeholder(in context: Context) -> Entry {\n        Entry(date: .now, data: .placeholder)  // Must be instant\n    }\n\n    func getSnapshot(in context: Context, completion: @escaping (Entry) -> ()) {\n        completion(Entry(date: .now, data: context.isPreview ? .sample : .current))\n    }\n\n    func getTimeline(in context: Context, completion: @escaping (Timeline<Entry>) -> ()) {\n        let entries = (0..<12).map { hour in\n            Entry(date: Calendar.current.date(byAdding: .hour, value: hour, to: .now)!, data: .forHour(hour))\n        }\n        completion(Timeline(entries: entries, policy: .atEnd))\n    }\n}\n```\n\n## TimelineEntry\n\nRequires only `date` property. Add custom properties for widget data:\n\n```swift\nstruct MyEntry: TimelineEntry {\n    let date: Date                          // Required: when to display\n    let relevance: TimelineEntryRelevance?  // Optional: Smart Stack ranking\n    let title: String                       // Custom data\n}\n```\n\n## Reload Policies\n\n| Policy | Behavior | Use Case |\n|--------|----------|----------|\n| `.atEnd` | Request new timeline after last entry expires | Regularly changing content |\n| `.after(Date)` | Wait until specified date | Known future update time |\n| `.never` | No auto-refresh; requires `reloadTimelines` call | App-driven updates only |\n\nAll policies are suggestions. System decides actual timing based on budget and battery.\n\n## App-Driven Reloads\n\n```swift\nWidgetCenter.shared.reloadTimelines(ofKind: \"MyWidget\")  // Specific widget\nWidgetCenter.shared.reloadAllTimelines()                  // All widgets\n```\n\nLimitations: Not immediate; may only update when app backgrounds; subject to daily budget.\n\n## Critical Anti-Patterns\n\n```swift\n// BAD: Entries too close together\nfor minute in 0..<60 {\n    let date = Calendar.current.date(byAdding: .minute, value: minute, to: now)!\n    entries.append(Entry(date: date))\n}\n\n// GOOD: Reasonable intervals (5+ minutes minimum)\nfor hour in 0..<24 {\n    let date = Calendar.current.date(byAdding: .hour, value: hour, to: now)!\n    entries.append(Entry(date: date))\n}\n```\n\n```swift\n// BAD: Heavy work in synchronous placeholder\nfunc placeholder(in context: Context) -> Entry {\n    let data = fetchDataSync()  // Blocks UI, may timeout\n    return Entry(date: .now, data: data)\n}\n```\n\n```swift\n// BAD: Ignoring isPreview\nfunc getSnapshot(in context: Context, completion: @escaping (Entry) -> ()) {\n    fetchRealData { completion(Entry(date: .now, data: $0)) }  // Slow for gallery\n}\n\n// GOOD: Sample data for previews, real data otherwise\nfunc getSnapshot(in context: Context, completion: @escaping (Entry) -> ()) {\n    if context.isPreview {\n        completion(Entry(date: .now, data: .sample))\n    } else {\n        completion(Entry(date: .now, data: .current))\n    }\n}\n```\n\n```swift\n// BAD: Expecting exact refresh timing\nTimeline(entries: entries, policy: .after(exactDeadline))  // May refresh hours late\n\n// GOOD: Include fallback entries past critical times\n```\n\n## Review Questions\n\n1. **Does `placeholder(in:)` return immediately without async work?**\n2. **Are timeline entries spaced at least 5 minutes apart?**\n3. **Does `getSnapshot` check `context.isPreview` for gallery previews?**\n4. **Is the reload policy appropriate?** Static: `.never`; Dynamic: `.atEnd`/`.after`\n5. **Are there fallback entries past critical times?** System may delay refreshes.\n6. **Is `reloadTimelines` called only when necessary?** Each call consumes budget.\n",
        "skills/widgetkit-code-review/references/views.md": "# Widget Views\n\n## Widget Families\n\n**Home Screen:** `systemSmall`, `systemMedium`, `systemLarge`, `systemExtraLarge` (iPad only)\n\n**Lock Screen (iOS 16+):** `accessoryCircular`, `accessoryRectangular`, `accessoryInline`\n\n```swift\n.supportedFamilies([.systemSmall, .systemMedium, .accessoryCircular, .accessoryRectangular])\n```\n\n## View Composition\n\nUse `@Environment(\\.widgetFamily)` for adaptive layouts:\n\n```swift\n@Environment(\\.widgetFamily) var widgetFamily\n\nvar body: some View {\n    switch widgetFamily {\n    case .systemSmall: CompactView()\n    case .accessoryCircular: CircularWidgetView()\n    case .accessoryInline: Text(entry.summary)\n    default: DetailedView()\n    }\n}\n```\n\n- Use `@Environment(\\.widgetRenderingMode)` to detect Lock Screen vibrant mode\n- `AccessoryWidgetBackground()` works for `accessoryCircular`/`accessoryRectangular` only\n- Use `ViewThatFits` for content that may truncate\n\n## containerBackground\n\n**Required for iOS 17+.** Widgets show error without this modifier.\n\n```swift\nText(\"Content\")\n    .containerBackground(for: .widget) { Color.blue }\n```\n\n**Backwards compatibility:**\n```swift\nextension View {\n    func widgetBackground(_ bg: some View) -> some View {\n        if #available(iOSApplicationExtension 17.0, *) {\n            return containerBackground(for: .widget) { bg }\n        } else { return background(bg) }\n    }\n}\n```\n\n**Configuration modifiers:**\n- `.containerBackgroundRemovable(false)` - Prevent removal in StandBy\n- `.contentMarginsDisabled()` - Opt out of automatic margins\n\n## Deep Linking\n\n| Size | Method | Notes |\n|------|--------|-------|\n| `systemSmall` | `widgetURL()` | Entire widget is one tap target |\n| `systemMedium`/`Large` | `Link` or `widgetURL()` | Multiple tappable regions |\n\n```swift\n// Small widgets: entire widget taps\n.widgetURL(URL(string: \"myapp://item/\\(entry.id)\")!)\n\n// Medium/Large: multiple targets\nLink(destination: URL(string: \"myapp://section1\")!) { Text(\"Section 1\") }\n```\n\nHandle in app with `.onOpenURL { url in handleDeepLink(url) }`\n\n## Critical Anti-Patterns\n\n| Issue | Problem |\n|-------|---------|\n| Missing `containerBackground` | iOS 17 shows error instead of widget |\n| `Link` in `systemSmall` | Silently fails, only `widgetURL` works |\n| `Button` in widgets | Never works, use `Link` or `widgetURL` |\n| Same view for all families | Content truncated or wasted space |\n| `AccessoryWidgetBackground` in `accessoryInline` | Renders empty view |\n| No URL validation in `onOpenURL` | Security risk from malformed deep links |\n\n## Review Questions\n\n1. Does the widget use `containerBackground(for:)` for iOS 17+ compatibility?\n2. Are Lock Screen families handled with appropriate compact layouts?\n3. Is `widgetURL` used for `systemSmall` instead of `Link`?\n4. Does the code avoid `Button` views (never work in widgets)?\n5. Is `AccessoryWidgetBackground` excluded from `accessoryInline` contexts?\n6. Are deep link URLs validated before navigation?\n",
        "skills/wish-ssh-code-review/SKILL.md": "---\nname: wish-ssh-code-review\ndescription: Reviews Wish SSH server code for proper middleware, session handling, and security patterns. Use when reviewing SSH server code using charmbracelet/wish.\n---\n\n# Wish SSH Code Review\n\n## Quick Reference\n\n| Issue Type | Reference |\n|------------|-----------|\n| Server setup, middleware | [references/server.md](references/server.md) |\n| Session handling, security | [references/sessions.md](references/sessions.md) |\n\n## Review Checklist\n\n- [ ] Host keys are loaded from file or generated securely\n- [ ] Middleware order is correct (logging first, auth early)\n- [ ] Session context is used for per-connection state\n- [ ] Graceful shutdown handles active sessions\n- [ ] PTY requests are handled for terminal apps\n- [ ] Connection limits prevent resource exhaustion\n- [ ] Timeout middleware prevents hung connections\n- [ ] BubbleTea middleware correctly configured\n\n## Critical Patterns\n\n### Server Setup\n\n```go\n// GOOD - complete server setup\ns, err := wish.NewServer(\n    wish.WithAddress(fmt.Sprintf(\"%s:%d\", host, port)),\n    wish.WithHostKeyPath(\".ssh/id_ed25519\"),\n    wish.WithMiddleware(\n        logging.Middleware(),       // first: log all connections\n        activeterm.Middleware(),    // handle terminal sizing\n        bubbletea.Middleware(teaHandler),\n    ),\n)\nif err != nil {\n    return fmt.Errorf(\"creating server: %w\", err)\n}\n```\n\n### Graceful Shutdown\n\n```go\n// BAD - abrupt shutdown\nlog.Fatal(s.ListenAndServe())\n\n// GOOD - graceful shutdown\ndone := make(chan os.Signal, 1)\nsignal.Notify(done, os.Interrupt, syscall.SIGTERM)\n\ngo func() {\n    if err := s.ListenAndServe(); err != nil && !errors.Is(err, ssh.ErrServerClosed) {\n        log.Error(\"server error\", \"error\", err)\n    }\n}()\n\n<-done\nctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\ndefer cancel()\nif err := s.Shutdown(ctx); err != nil {\n    log.Error(\"shutdown error\", \"error\", err)\n}\n```\n\n### BubbleTea Handler\n\n```go\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()\n\n    model := NewModel(pty.Window.Width, pty.Window.Height)\n\n    return model, []tea.ProgramOption{\n        tea.WithAltScreen(),\n        tea.WithMouseCellMotion(),\n    }\n}\n```\n\n## When to Load References\n\n- Reviewing server initialization  server.md\n- Reviewing authentication, session state  sessions.md\n\n## Review Questions\n\n1. Are host keys handled securely?\n2. Is middleware order correct?\n3. Is graceful shutdown implemented?\n4. Are PTY window sizes passed to the TUI?\n5. Are connection timeouts configured?\n",
        "skills/wish-ssh-code-review/references/server.md": "# Server Setup\n\n## Host Key Management\n\n### 1. Use Persistent Keys\n\n```go\n// BAD - generates new key each start (fingerprint changes)\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    // no host key specified - generates random\n)\n\n// GOOD - load from file\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    wish.WithHostKeyPath(\"/data/ssh_host_ed25519_key\"),\n)\n\n// GOOD - generate if missing, persist for reuse\nfunc ensureHostKey(path string) error {\n    if _, err := os.Stat(path); os.IsNotExist(err) {\n        _, priv, err := ed25519.GenerateKey(rand.Reader)\n        if err != nil {\n            return err\n        }\n        // save to file...\n    }\n    return nil\n}\n```\n\n### 2. Support Multiple Key Types\n\n```go\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    wish.WithHostKeyPath(\"/data/ssh_host_ed25519_key\"),\n    wish.WithHostKeyPEM(rsaKeyBytes),  // additional key type\n)\n```\n\n## Middleware Configuration\n\n### 1. Correct Middleware Order\n\n```go\n// Middleware executes in order - first added runs first\nwish.WithMiddleware(\n    // 1. Logging - see all connections\n    logging.Middleware(),\n\n    // 2. Timeout - prevent hung connections\n    wish.WithIdleTimeout(10*time.Minute),\n    wish.WithMaxTimeout(30*time.Minute),\n\n    // 3. Active terminal - handle PTY/window sizing\n    activeterm.Middleware(),\n\n    // 4. Your app handler - BubbleTea or custom\n    bubbletea.Middleware(teaHandler),\n)\n```\n\n### 2. Custom Middleware\n\n```go\nfunc customMiddleware() wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            // Before handling\n            log.Info(\"connection\", \"user\", s.User(), \"remote\", s.RemoteAddr())\n\n            // Call next handler\n            next(s)\n\n            // After handling (session ended)\n            log.Info(\"disconnected\", \"user\", s.User())\n        }\n    }\n}\n```\n\n### 3. Metrics Middleware\n\n```go\nfunc metricsMiddleware(metrics *Metrics) wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            metrics.ActiveConnections.Inc()\n            start := time.Now()\n\n            defer func() {\n                metrics.ActiveConnections.Dec()\n                metrics.SessionDuration.Observe(time.Since(start).Seconds())\n            }()\n\n            next(s)\n        }\n    }\n}\n```\n\n## Server Lifecycle\n\n### 1. Graceful Shutdown\n\n```go\nfunc run() error {\n    s, err := wish.NewServer(...)\n    if err != nil {\n        return err\n    }\n\n    // Start server in goroutine\n    errCh := make(chan error, 1)\n    go func() {\n        errCh <- s.ListenAndServe()\n    }()\n\n    // Wait for shutdown signal\n    quit := make(chan os.Signal, 1)\n    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\n    select {\n    case err := <-errCh:\n        return err\n    case <-quit:\n    }\n\n    // Graceful shutdown with timeout\n    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n    defer cancel()\n\n    return s.Shutdown(ctx)\n}\n```\n\n### 2. Health Checks\n\n```go\n// Run HTTP health endpoint alongside SSH\nhttp.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    w.WriteHeader(http.StatusOK)\n    w.Write([]byte(\"ok\"))\n})\n\ngo http.ListenAndServe(\":8080\", nil)\n```\n\n## Connection Handling\n\n### 1. Connection Limits\n\n```go\n// Limit concurrent connections\nvar connLimiter = make(chan struct{}, 100)\n\nfunc connectionLimitMiddleware() wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            select {\n            case connLimiter <- struct{}{}:\n                defer func() { <-connLimiter }()\n                next(s)\n            default:\n                s.Exit(1)\n            }\n        }\n    }\n}\n```\n\n### 2. Rate Limiting\n\n```go\nimport \"golang.org/x/time/rate\"\n\nvar limiter = rate.NewLimiter(rate.Every(time.Second), 10)  // 10/sec\n\nfunc rateLimitMiddleware() wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            if !limiter.Allow() {\n                io.WriteString(s, \"Too many connections, try again later\\n\")\n                s.Exit(1)\n                return\n            }\n            next(s)\n        }\n    }\n}\n```\n\n## Anti-Patterns\n\n### 1. No Error Handling on ListenAndServe\n\n```go\n// BAD\ngo s.ListenAndServe()\n\n// GOOD\ngo func() {\n    if err := s.ListenAndServe(); err != nil && !errors.Is(err, ssh.ErrServerClosed) {\n        log.Fatal(\"server error\", \"error\", err)\n    }\n}()\n```\n\n### 2. Ignoring Context in Shutdown\n\n```go\n// BAD - no timeout\ns.Shutdown(context.Background())  // could hang forever\n\n// GOOD\nctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\ndefer cancel()\ns.Shutdown(ctx)\n```\n\n## Review Questions\n\n1. Are host keys persisted (not regenerated on restart)?\n2. Is middleware order correct (logging first)?\n3. Is graceful shutdown implemented with timeout?\n4. Are connection/rate limits in place?\n5. Is there a health check endpoint?\n",
        "skills/wish-ssh-code-review/references/sessions.md": "# Sessions & Security\n\n## Session Handling\n\n### 1. Access Session Info\n\n```go\nfunc handler(s ssh.Session) {\n    // User info\n    user := s.User()\n    remoteAddr := s.RemoteAddr()\n\n    // Public key (if key auth)\n    key := s.PublicKey()\n\n    // Environment variables\n    env := s.Environ()\n\n    // Command (if not interactive)\n    cmd := s.Command()\n\n    // PTY info (if allocated)\n    pty, winCh, isPty := s.Pty()\n    if isPty {\n        width := pty.Window.Width\n        height := pty.Window.Height\n    }\n}\n```\n\n### 2. Handle Window Resize\n\n```go\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, winCh, _ := s.Pty()\n\n    model := NewModel(pty.Window.Width, pty.Window.Height)\n\n    // Window change channel is passed via activeterm middleware\n    // BubbleTea handles this automatically when using bubbletea.Middleware\n\n    return model, []tea.ProgramOption{tea.WithAltScreen()}\n}\n```\n\n### 3. Session Context for State\n\n```go\n// Store per-session state using context\ntype contextKey string\n\nconst sessionDataKey contextKey = \"sessionData\"\n\ntype SessionData struct {\n    User      string\n    ConnectAt time.Time\n    PageViews int\n}\n\nfunc sessionMiddleware() wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            data := &SessionData{\n                User:      s.User(),\n                ConnectAt: time.Now(),\n            }\n            ctx := context.WithValue(s.Context(), sessionDataKey, data)\n            // Note: wish.Session doesn't expose SetContext\n            // Store in sync.Map keyed by session ID instead\n            next(s)\n        }\n    }\n}\n```\n\n## Security\n\n### 1. Authentication\n\n```go\n// Public key authentication\nwish.WithPublicKeyAuth(func(ctx ssh.Context, key ssh.PublicKey) bool {\n    // Check against authorized keys\n    authorized := loadAuthorizedKeys()\n    for _, authKey := range authorized {\n        if ssh.KeysEqual(key, authKey) {\n            return true\n        }\n    }\n    return false\n}),\n\n// Password authentication (not recommended for production)\nwish.WithPasswordAuth(func(ctx ssh.Context, password string) bool {\n    // Never do this - use public key auth\n    return password == os.Getenv(\"SSH_PASSWORD\")\n}),\n```\n\n### 2. Authorization\n\n```go\nfunc authorizationMiddleware(allowedUsers map[string]bool) wish.Middleware {\n    return func(next ssh.Handler) ssh.Handler {\n        return func(s ssh.Session) {\n            if !allowedUsers[s.User()] {\n                io.WriteString(s, \"Access denied\\n\")\n                s.Exit(1)\n                return\n            }\n            next(s)\n        }\n    }\n}\n```\n\n### 3. Secure Defaults\n\n```go\ns, err := wish.NewServer(\n    wish.WithAddress(\":22\"),\n    wish.WithHostKeyPath(\"./host_key\"),\n\n    // Timeouts prevent hung connections\n    wish.WithIdleTimeout(10*time.Minute),\n    wish.WithMaxTimeout(60*time.Minute),\n\n    // Require public key auth\n    wish.WithPublicKeyAuth(authHandler),\n\n    wish.WithMiddleware(\n        logging.Middleware(),  // audit trail\n        activeterm.Middleware(),\n        bubbletea.Middleware(teaHandler),\n    ),\n)\n```\n\n## BubbleTea Integration\n\n### 1. Basic Handler\n\n```go\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()\n\n    renderer := bubbletea.MakeRenderer(s)\n    model := NewModel(renderer, pty.Window.Width, pty.Window.Height)\n\n    return model, []tea.ProgramOption{\n        tea.WithAltScreen(),\n    }\n}\n```\n\n### 2. Passing Session to Model\n\n```go\ntype Model struct {\n    renderer *lipgloss.Renderer\n    user     string\n    width    int\n    height   int\n}\n\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()\n    renderer := bubbletea.MakeRenderer(s)\n\n    model := Model{\n        renderer: renderer,\n        user:     s.User(),\n        width:    pty.Window.Width,\n        height:   pty.Window.Height,\n    }\n\n    return model, []tea.ProgramOption{tea.WithAltScreen()}\n}\n```\n\n### 3. Per-Session Styles\n\n```go\n// Each session needs its own renderer for correct color detection\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    renderer := bubbletea.MakeRenderer(s)\n\n    // Create styles with session's renderer\n    styles := NewStyles(renderer)\n\n    model := Model{\n        styles: styles,\n    }\n\n    return model, nil\n}\n\ntype Styles struct {\n    Title lipgloss.Style\n    Item  lipgloss.Style\n}\n\nfunc NewStyles(r *lipgloss.Renderer) Styles {\n    return Styles{\n        Title: r.NewStyle().Bold(true).Foreground(lipgloss.Color(\"205\")),\n        Item:  r.NewStyle().PaddingLeft(2),\n    }\n}\n```\n\n## Anti-Patterns\n\n### 1. Ignoring PTY\n\n```go\n// BAD - assumes PTY always exists\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, _ := s.Pty()  // may be nil!\n    model := NewModel(pty.Window.Width, pty.Window.Height)  // panic!\n}\n\n// GOOD - handle non-PTY connections\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    pty, _, hasPty := s.Pty()\n\n    width, height := 80, 24  // sensible defaults\n    if hasPty {\n        width = pty.Window.Width\n        height = pty.Window.Height\n    }\n\n    model := NewModel(width, height)\n    return model, nil\n}\n```\n\n### 2. Global Lipgloss Styles\n\n```go\n// BAD - global styles don't detect terminal capabilities per-session\nvar titleStyle = lipgloss.NewStyle().Bold(true)\n\n// GOOD - per-session renderer\nfunc teaHandler(s ssh.Session) (tea.Model, []tea.ProgramOption) {\n    renderer := bubbletea.MakeRenderer(s)\n    titleStyle := renderer.NewStyle().Bold(true)\n    // ...\n}\n```\n\n## Review Questions\n\n1. Is PTY presence checked before accessing window size?\n2. Are per-session renderers used for Lipgloss?\n3. Is authentication configured (public key preferred)?\n4. Are session timeouts set?\n5. Is logging middleware capturing connection info?\n",
        "skills/zustand-state/MIDDLEWARE.md": "# Middleware\n\n## Persist (localStorage)\n\n```typescript\nimport { persist, createJSONStorage } from 'zustand/middleware'\n\nconst useStore = create<State>()(\n  persist(\n    (set) => ({\n      bears: 0,\n      increase: () => set((s) => ({ bears: s.bears + 1 })),\n    }),\n    {\n      name: 'bear-storage',\n      storage: createJSONStorage(() => localStorage),\n    }\n  )\n)\n\n// Partial persistence\nconst useStore = create(\n  persist(\n    (set) => ({ bears: 0, fish: 0 }),\n    {\n      name: 'storage',\n      partialize: (state) => ({ bears: state.bears }), // only persist bears\n    }\n  )\n)\n```\n\n## DevTools\n\n```typescript\nimport { devtools } from 'zustand/middleware'\n\nconst useStore = create<State>()(\n  devtools(\n    (set) => ({\n      bears: 0,\n      increase: () => set(\n        (s) => ({ bears: s.bears + 1 }),\n        undefined,\n        'bear/increase'  // Action name for DevTools\n      ),\n    }),\n    { name: 'BearStore' }\n  )\n)\n```\n\n## Immer (Mutable Updates)\n\n```typescript\nimport { immer } from 'zustand/middleware/immer'\n\nconst useStore = create<State>()(\n  immer((set) => ({\n    nested: { count: 0 },\n    increment: () =>\n      set((state) => {\n        state.nested.count += 1  // mutate directly with immer\n      }),\n  }))\n)\n```\n\n## Combine Middleware\n\n```typescript\nimport { create } from 'zustand'\nimport { devtools, persist } from 'zustand/middleware'\nimport { immer } from 'zustand/middleware/immer'\n\nconst useStore = create<State>()(\n  devtools(\n    persist(\n      immer((set) => ({\n        // store implementation\n      })),\n      { name: 'storage' }\n    ),\n    { name: 'DevToolsName' }\n  )\n)\n```\n\n## SubscribeWithSelector\n\n```typescript\nimport { subscribeWithSelector } from 'zustand/middleware'\n\nconst useStore = create(\n  subscribeWithSelector((set) => ({ bears: 0, fish: 0 }))\n)\n\n// Subscribe to specific field changes\nconst unsub = useStore.subscribe(\n  (state) => state.bears,\n  (bears, prevBears) => console.log(bears, prevBears),\n  { fireImmediately: true }\n)\n```\n\n## Next.js / SSR Hydration\n\n```typescript\nimport { useEffect, useState } from 'react'\n\nconst useHydration = () => {\n  const [hydrated, setHydrated] = useState(false)\n\n  useEffect(() => {\n    setHydrated(useBearStore.persist.hasHydrated())\n    return useBearStore.persist.onFinishHydration(() => setHydrated(true))\n  }, [])\n\n  return hydrated\n}\n\nfunction Component() {\n  const hydrated = useHydration()\n  const bears = useBearStore((state) => state.bears)\n\n  if (!hydrated) return <div>Loading...</div>\n  return <div>{bears} bears</div>\n}\n```\n\n## Async Persistence\n\n```typescript\nconst useStore = create(\n  persist(\n    (set) => ({ data: null }),\n    {\n      name: 'async-storage',\n      storage: createJSONStorage(() => ({\n        getItem: async (name) => {\n          const value = await asyncStorage.getItem(name)\n          return value\n        },\n        setItem: async (name, value) => {\n          await asyncStorage.setItem(name, value)\n        },\n        removeItem: async (name) => {\n          await asyncStorage.removeItem(name)\n        },\n      })),\n    }\n  )\n)\n```\n",
        "skills/zustand-state/PATTERNS.md": "# Patterns & Best Practices\n\n## Slices Pattern (Store Composition)\n\n```typescript\n// fishSlice.ts\nconst createFishSlice = (set) => ({\n  fish: 0,\n  addFish: () => set((state) => ({ fish: state.fish + 1 })),\n})\n\n// bearSlice.ts\nconst createBearSlice = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\n// Combined store\nimport { create } from 'zustand'\n\nconst useBoundStore = create((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## TypeScript Slices\n\n```typescript\nimport { StateCreator } from 'zustand'\n\ninterface BearSlice {\n  bears: number\n  addBear: () => void\n}\n\ninterface FishSlice {\n  fish: number\n  addFish: () => void\n}\n\nconst createBearSlice: StateCreator<\n  BearSlice & FishSlice,\n  [],\n  [],\n  BearSlice\n> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\nconst useBoundStore = create<BearSlice & FishSlice>()((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## Testing\n\n### Mock Store Setup (Vitest)\n\n```typescript\n// __mocks__/zustand.ts\nimport { act } from '@testing-library/react'\nimport type * as ZustandExportedTypes from 'zustand'\n\nexport * from 'zustand'\n\nconst { create: actualCreate } =\n  await vi.importActual<typeof ZustandExportedTypes>('zustand')\n\nexport const storeResetFns = new Set<() => void>()\n\nexport const create = (<T>(stateCreator) => {\n  const store = actualCreate(stateCreator)\n  const initialState = store.getInitialState()\n  storeResetFns.add(() => store.setState(initialState, true))\n  return store\n}) as typeof actualCreate\n\nafterEach(() => {\n  act(() => storeResetFns.forEach((fn) => fn()))\n})\n```\n\n### Component Tests\n\n```typescript\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\n\ntest('increments count', async () => {\n  const user = userEvent.setup()\n  render(<Counter />)\n\n  expect(await screen.findByText('0')).toBeInTheDocument()\n  await user.click(screen.getByRole('button', { name: /increment/i }))\n  expect(await screen.findByText('1')).toBeInTheDocument()\n})\n\ntest('reads store directly', () => {\n  expect(useCountStore.getState().count).toBe(0)\n})\n```\n\n## Reset Store\n\n```typescript\nconst useStore = create<State & Actions>()((set, get, store) => ({\n  bears: 0,\n  fish: 0,\n  reset: () => set(store.getInitialState()),\n}))\n```\n\n## Computed Values (Derived State)\n\n```typescript\n// Don't store computed values - derive in selectors\nconst totalFood = useBearStore((s) => s.bears * s.foodPerBear)\n\n// Or in the component\nconst totalFood = bears * foodPerBear\n```\n\n## Transient Updates (No Rerender)\n\n```typescript\nfunction Component() {\n  const scratchRef = useRef(useScratchStore.getState().scratches)\n\n  useEffect(() =>\n    useScratchStore.subscribe(\n      (state) => { scratchRef.current = state.scratches }\n    ), []\n  )\n\n  // Use scratchRef.current without causing rerenders\n}\n```\n\n## Best Practices\n\n### Single Store Per Domain\nUse one store for each domain (user, cart, ui). Split large stores with slices.\n\n### Colocate Actions\n```typescript\n// Good - actions in store\nconst useStore = create((set) => ({\n  count: 0,\n  increment: () => set((s) => ({ count: s.count + 1 })),\n}))\n\n// Avoid - external actions\nconst increment = () => useStore.setState((s) => ({ count: s.count + 1 }))\n```\n\n### Selector Stability\n```typescript\n// Bad - creates new function every render\nconst action = useBearStore((state) => () => state.increase(1))\n\n// Good - select function directly\nconst increase = useBearStore((state) => state.increase)\n```\n\n## Pitfalls to Avoid\n\n### Don't Mutate State\n```typescript\n// Wrong\nset((state) => {\n  state.count += 1  // Mutation!\n  return state\n})\n\n// Correct (without immer)\nset((state) => ({ count: state.count + 1 }))\n```\n\n### Avoid Fetching Entire Store\n```typescript\n// Bad - rerenders on any change\nconst { bears, fish, cats } = useBearStore()\n\n// Good - subscribe only to needed values\nconst bears = useBearStore((state) => state.bears)\n```\n\n### React Context (Dependency Injection)\n\n```typescript\nimport { createContext, useContext, useRef } from 'react'\nimport { createStore, useStore } from 'zustand'\n\nconst StoreContext = createContext(null)\n\nconst StoreProvider = ({ children }) => {\n  const storeRef = useRef()\n  if (!storeRef.current) {\n    storeRef.current = createStore((set) => ({\n      bears: 0,\n      increase: () => set((s) => ({ bears: s.bears + 1 })),\n    }))\n  }\n  return (\n    <StoreContext.Provider value={storeRef.current}>\n      {children}\n    </StoreContext.Provider>\n  )\n}\n\nconst useBearStore = (selector) => {\n  const store = useContext(StoreContext)\n  return useStore(store, selector)\n}\n```\n",
        "skills/zustand-state/SKILL.md": "---\nname: zustand-state\ndescription: Zustand state management for React and vanilla JavaScript. Use when creating stores, using selectors, persisting state to localStorage, integrating devtools, or managing global state without Redux complexity. Triggers on zustand, create(), createStore, useStore, persist, devtools, immer middleware.\n---\n\n# Zustand State Management\n\nMinimal state management - no providers, minimal boilerplate.\n\n## Quick Reference\n\n```typescript\nimport { create } from 'zustand'\n\ninterface BearState {\n  bears: number\n  increase: (by: number) => void\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n}))\n\n// In component - select only what you need\nconst bears = useBearStore((state) => state.bears)\nconst increase = useBearStore((state) => state.increase)\n```\n\n## State Updates\n\n```typescript\n// Flat updates (auto-merged at one level)\nset({ bears: 5 })\nset((state) => ({ bears: state.bears + 1 }))\n\n// Nested objects (manual spread required)\nset((state) => ({\n  nested: { ...state.nested, count: state.nested.count + 1 }\n}))\n\n// Replace entire state (no merge)\nset({ bears: 0 }, true)\n```\n\n## Selectors & Performance\n\n```typescript\n// Good - subscribes only to bears\nconst bears = useBearStore((state) => state.bears)\n\n// Bad - rerenders on any change\nconst state = useBearStore()\n\n// Multiple values with useShallow (prevents rerenders with shallow comparison)\nimport { useShallow } from 'zustand/react/shallow'\n\nconst { bears, fish } = useBearStore(\n  useShallow((state) => ({ bears: state.bears, fish: state.fish }))\n)\n\n// Array destructuring also works\nconst [bears, fish] = useBearStore(\n  useShallow((state) => [state.bears, state.fish])\n)\n```\n\n## Access Outside Components\n\n```typescript\n// Get current state (non-reactive)\nconst state = useBearStore.getState()\n\n// Update state\nuseBearStore.setState({ bears: 5 })\n\n// Subscribe to changes\nconst unsub = useBearStore.subscribe((state) => console.log(state))\nunsub() // unsubscribe\n```\n\n## Vanilla Store (No React)\n\n```typescript\nimport { createStore } from 'zustand/vanilla'\n\nconst store = createStore((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n}))\n\nstore.getState().bears\nstore.setState({ bears: 10 })\nstore.subscribe((state) => console.log(state))\n```\n\n## Additional Documentation\n\n- **Middleware**: See [references/middleware.md](references/middleware.md) for persist, devtools, immer\n- **Patterns**: See [references/patterns.md](references/patterns.md) for slices, testing, best practices\n- **TypeScript**: See [references/typescript.md](references/typescript.md) for advanced typing patterns\n\n## Key Patterns\n\n| Pattern | When to Use |\n|---------|-------------|\n| Single selector | One piece of state needed |\n| `useShallow` | Multiple values, avoid rerenders |\n| `getState()` | Outside React, event handlers |\n| `subscribe()` | External systems, logging |\n| Vanilla store | Non-React environments |\n",
        "skills/zustand-state/TYPESCRIPT.md": "# TypeScript Patterns\n\n## Curried Create Syntax\n\n```typescript\n// Required for TypeScript - note the double parentheses\nconst useStore = create<State>()((set) => ({\n  // implementation\n}))\n\n// Wrong - type inference fails with middleware\ncreate<State>((set) => ({ ... }))\n\n// Correct\ncreate<State>()((set) => ({ ... }))\n```\n\n## Separate State and Actions\n\n```typescript\ninterface State {\n  bears: number\n  fish: number\n}\n\ninterface Actions {\n  increase: () => void\n  reset: () => void\n}\n\nconst useStore = create<State & Actions>()((set, get, store) => ({\n  bears: 0,\n  fish: 0,\n  increase: () => set((state) => ({ bears: state.bears + 1 })),\n  reset: () => set(store.getInitialState()),\n}))\n```\n\n## Extract Store Type\n\n```typescript\nimport { type ExtractState } from 'zustand'\n\nconst useBearStore = create((set) => ({\n  bears: 3,\n  increase: (by: number) => set((s) => ({ bears: s.bears + by })),\n}))\n\n// Extract type for reuse\nexport type BearState = ExtractState<typeof useBearStore>\n```\n\n## Async Actions\n\n```typescript\ninterface State {\n  data: Data | null\n  loading: boolean\n}\n\ninterface Actions {\n  fetchData: () => Promise<void>\n}\n\nconst useStore = create<State & Actions>((set) => ({\n  data: null,\n  loading: false,\n\n  fetchData: async () => {\n    set({ loading: true })\n    try {\n      const response = await fetch('/api/data')\n      const data = await response.json()\n      set({ data, loading: false })\n    } catch (error) {\n      set({ loading: false })\n    }\n  },\n}))\n```\n\n## Typed Slices with StateCreator\n\n```typescript\nimport { StateCreator } from 'zustand'\n\ninterface BearSlice {\n  bears: number\n  addBear: () => void\n}\n\ninterface FishSlice {\n  fish: number\n  addFish: () => void\n}\n\ntype BoundStore = BearSlice & FishSlice\n\nconst createBearSlice: StateCreator<\n  BoundStore,  // Full store type\n  [],          // Middleware applied before\n  [],          // Middleware applied after\n  BearSlice    // This slice's type\n> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\nconst createFishSlice: StateCreator<\n  BoundStore,\n  [],\n  [],\n  FishSlice\n> = (set) => ({\n  fish: 0,\n  addFish: () => set((state) => ({ fish: state.fish + 1 })),\n})\n\nconst useBoundStore = create<BoundStore>()((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## Middleware Type Parameters\n\n```typescript\nimport { create } from 'zustand'\nimport { devtools, persist } from 'zustand/middleware'\n\ninterface State {\n  count: number\n  increment: () => void\n}\n\nconst useStore = create<State>()(\n  devtools(\n    persist(\n      (set) => ({\n        count: 0,\n        increment: () => set((state) => ({ count: state.count + 1 })),\n      }),\n      { name: 'count-storage' }\n    ),\n    { name: 'CountStore' }\n  )\n)\n```\n\n## Typed Selectors\n\n```typescript\ninterface BearState {\n  bears: number\n  increase: (by: number) => void\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n}))\n\n// Selector is automatically typed\nconst bears = useBearStore((state) => state.bears)        // number\nconst increase = useBearStore((state) => state.increase)  // (by: number) => void\n```\n\n## Custom Equality Functions\n\n```typescript\nimport { createWithEqualityFn } from 'zustand/traditional'\nimport { shallow } from 'zustand/shallow'\n\nconst useStore = createWithEqualityFn<State>()(\n  (set) => ({\n    // store implementation\n  }),\n  shallow  // Use shallow comparison by default\n)\n```\n\n## Vanilla Store with Types\n\n```typescript\nimport { createStore } from 'zustand/vanilla'\n\ninterface CounterState {\n  count: number\n  increment: () => void\n  decrement: () => void\n}\n\nconst counterStore = createStore<CounterState>((set) => ({\n  count: 0,\n  increment: () => set((state) => ({ count: state.count + 1 })),\n  decrement: () => set((state) => ({ count: state.count - 1 })),\n}))\n\n// Typed access\nconst count: number = counterStore.getState().count\n```\n",
        "skills/zustand-state/references/middleware.md": "# Middleware\n\n## Contents\n\n- [Persist (localStorage)](#persist-localstorage)\n- [DevTools](#devtools)\n- [Immer (Mutable Updates)](#immer-mutable-updates)\n- [Combine Middleware](#combine-middleware)\n- [SubscribeWithSelector](#subscribewithselector)\n- [Next.js / SSR Hydration](#nextjs--ssr-hydration)\n- [Async Persistence](#async-persistence)\n\n---\n\n## Persist (localStorage)\n\n```typescript\nimport { persist, createJSONStorage } from 'zustand/middleware'\n\nconst useStore = create<State>()(\n  persist(\n    (set) => ({\n      bears: 0,\n      increase: () => set((s) => ({ bears: s.bears + 1 })),\n    }),\n    {\n      name: 'bear-storage',\n      storage: createJSONStorage(() => localStorage),\n    }\n  )\n)\n\n// Partial persistence\nconst useStore = create(\n  persist(\n    (set) => ({ bears: 0, fish: 0 }),\n    {\n      name: 'storage',\n      partialize: (state) => ({ bears: state.bears }), // only persist bears\n    }\n  )\n)\n```\n\n## DevTools\n\n```typescript\nimport { devtools } from 'zustand/middleware'\n\nconst useStore = create<State>()(\n  devtools(\n    (set) => ({\n      bears: 0,\n      increase: () => set(\n        (s) => ({ bears: s.bears + 1 }),\n        undefined,\n        'bear/increase'  // Action name for DevTools\n      ),\n    }),\n    { name: 'BearStore' }\n  )\n)\n```\n\n## Immer (Mutable Updates)\n\n```typescript\nimport { immer } from 'zustand/middleware/immer'\n\nconst useStore = create<State>()(\n  immer((set) => ({\n    nested: { count: 0 },\n    increment: () =>\n      set((state) => {\n        state.nested.count += 1  // mutate directly with immer\n      }),\n  }))\n)\n```\n\n## Combine Middleware\n\n```typescript\nimport { create } from 'zustand'\nimport { devtools, persist } from 'zustand/middleware'\nimport { immer } from 'zustand/middleware/immer'\n\nconst useStore = create<State>()(\n  devtools(\n    persist(\n      immer((set) => ({\n        // store implementation\n      })),\n      { name: 'storage' }\n    ),\n    { name: 'DevToolsName' }\n  )\n)\n```\n\n## SubscribeWithSelector\n\n```typescript\nimport { subscribeWithSelector } from 'zustand/middleware'\n\nconst useStore = create(\n  subscribeWithSelector((set) => ({ bears: 0, fish: 0 }))\n)\n\n// Subscribe to specific field changes\nconst unsub = useStore.subscribe(\n  (state) => state.bears,\n  (bears, prevBears) => console.log(bears, prevBears),\n  { fireImmediately: true }\n)\n```\n\n## Next.js / SSR Hydration\n\n```typescript\nimport { useEffect, useState } from 'react'\n\nconst useHydration = () => {\n  const [hydrated, setHydrated] = useState(false)\n\n  useEffect(() => {\n    setHydrated(useBearStore.persist.hasHydrated())\n    return useBearStore.persist.onFinishHydration(() => setHydrated(true))\n  }, [])\n\n  return hydrated\n}\n\nfunction Component() {\n  const hydrated = useHydration()\n  const bears = useBearStore((state) => state.bears)\n\n  if (!hydrated) return <div>Loading...</div>\n  return <div>{bears} bears</div>\n}\n```\n\n## Async Persistence\n\n```typescript\nconst useStore = create(\n  persist(\n    (set) => ({ data: null }),\n    {\n      name: 'async-storage',\n      storage: createJSONStorage(() => ({\n        getItem: async (name) => {\n          const value = await asyncStorage.getItem(name)\n          return value\n        },\n        setItem: async (name, value) => {\n          await asyncStorage.setItem(name, value)\n        },\n        removeItem: async (name) => {\n          await asyncStorage.removeItem(name)\n        },\n      })),\n    }\n  )\n)\n```\n",
        "skills/zustand-state/references/patterns.md": "# Patterns & Best Practices\n\n## Contents\n\n- [Slices Pattern (Store Composition)](#slices-pattern-store-composition)\n- [TypeScript Slices](#typescript-slices)\n- [Testing](#testing)\n  - [Mock Store Setup (Vitest)](#mock-store-setup-vitest)\n  - [Component Tests](#component-tests)\n- [Reset Store](#reset-store)\n- [Computed Values (Derived State)](#computed-values-derived-state)\n- [Transient Updates (No Rerender)](#transient-updates-no-rerender)\n- [Best Practices](#best-practices)\n  - [Single Store Per Domain](#single-store-per-domain)\n  - [Colocate Actions](#colocate-actions)\n  - [Selector Stability](#selector-stability)\n- [Pitfalls to Avoid](#pitfalls-to-avoid)\n  - [Don't Mutate State](#dont-mutate-state)\n  - [Avoid Fetching Entire Store](#avoid-fetching-entire-store)\n  - [React Context (Dependency Injection)](#react-context-dependency-injection)\n\n---\n\n## Slices Pattern (Store Composition)\n\n```typescript\n// fishSlice.ts\nconst createFishSlice = (set) => ({\n  fish: 0,\n  addFish: () => set((state) => ({ fish: state.fish + 1 })),\n})\n\n// bearSlice.ts\nconst createBearSlice = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\n// Combined store\nimport { create } from 'zustand'\n\nconst useBoundStore = create((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## TypeScript Slices\n\n```typescript\nimport { StateCreator } from 'zustand'\n\ninterface BearSlice {\n  bears: number\n  addBear: () => void\n}\n\ninterface FishSlice {\n  fish: number\n  addFish: () => void\n}\n\nconst createBearSlice: StateCreator<\n  BearSlice & FishSlice,\n  [],\n  [],\n  BearSlice\n> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\nconst useBoundStore = create<BearSlice & FishSlice>()((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## Testing\n\n### Mock Store Setup (Vitest)\n\n```typescript\n// __mocks__/zustand.ts\nimport { act } from '@testing-library/react'\nimport type * as ZustandExportedTypes from 'zustand'\n\nexport * from 'zustand'\n\nconst { create: actualCreate } =\n  await vi.importActual<typeof ZustandExportedTypes>('zustand')\n\nexport const storeResetFns = new Set<() => void>()\n\nexport const create = (<T>(stateCreator) => {\n  const store = actualCreate(stateCreator)\n  const initialState = store.getInitialState()\n  storeResetFns.add(() => store.setState(initialState, true))\n  return store\n}) as typeof actualCreate\n\nafterEach(() => {\n  act(() => storeResetFns.forEach((fn) => fn()))\n})\n```\n\n### Component Tests\n\n```typescript\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\n\ntest('increments count', async () => {\n  const user = userEvent.setup()\n  render(<Counter />)\n\n  expect(await screen.findByText('0')).toBeInTheDocument()\n  await user.click(screen.getByRole('button', { name: /increment/i }))\n  expect(await screen.findByText('1')).toBeInTheDocument()\n})\n\ntest('reads store directly', () => {\n  expect(useCountStore.getState().count).toBe(0)\n})\n```\n\n## Reset Store\n\n```typescript\nconst useStore = create<State & Actions>()((set, get, store) => ({\n  bears: 0,\n  fish: 0,\n  reset: () => set(store.getInitialState()),\n}))\n```\n\n## Computed Values (Derived State)\n\n```typescript\n// Don't store computed values - derive in selectors\nconst totalFood = useBearStore((s) => s.bears * s.foodPerBear)\n\n// Or in the component\nconst totalFood = bears * foodPerBear\n```\n\n## Transient Updates (No Rerender)\n\n```typescript\nfunction Component() {\n  const scratchRef = useRef(useScratchStore.getState().scratches)\n\n  useEffect(() =>\n    useScratchStore.subscribe(\n      (state) => { scratchRef.current = state.scratches }\n    ), []\n  )\n\n  // Use scratchRef.current without causing rerenders\n}\n```\n\n## Best Practices\n\n### Single Store Per Domain\nUse one store for each domain (user, cart, ui). Split large stores with slices.\n\n### Colocate Actions\n```typescript\n// Good - actions in store\nconst useStore = create((set) => ({\n  count: 0,\n  increment: () => set((s) => ({ count: s.count + 1 })),\n}))\n\n// Avoid - external actions\nconst increment = () => useStore.setState((s) => ({ count: s.count + 1 }))\n```\n\n### Selector Stability\n```typescript\n// Bad - creates new function every render\nconst action = useBearStore((state) => () => state.increase(1))\n\n// Good - select function directly\nconst increase = useBearStore((state) => state.increase)\n```\n\n## Pitfalls to Avoid\n\n### Don't Mutate State\n```typescript\n// Wrong\nset((state) => {\n  state.count += 1  // Mutation!\n  return state\n})\n\n// Correct (without immer)\nset((state) => ({ count: state.count + 1 }))\n```\n\n### Avoid Fetching Entire Store\n```typescript\n// Bad - rerenders on any change\nconst { bears, fish, cats } = useBearStore()\n\n// Good - subscribe only to needed values\nconst bears = useBearStore((state) => state.bears)\n```\n\n### React Context (Dependency Injection)\n\n```typescript\nimport { createContext, useContext, useRef } from 'react'\nimport { createStore, useStore } from 'zustand'\n\nconst StoreContext = createContext(null)\n\nconst StoreProvider = ({ children }) => {\n  const storeRef = useRef()\n  if (!storeRef.current) {\n    storeRef.current = createStore((set) => ({\n      bears: 0,\n      increase: () => set((s) => ({ bears: s.bears + 1 })),\n    }))\n  }\n  return (\n    <StoreContext.Provider value={storeRef.current}>\n      {children}\n    </StoreContext.Provider>\n  )\n}\n\nconst useBearStore = (selector) => {\n  const store = useContext(StoreContext)\n  return useStore(store, selector)\n}\n```\n",
        "skills/zustand-state/references/typescript.md": "# TypeScript Patterns\n\n## Contents\n\n- [Curried Create Syntax](#curried-create-syntax)\n- [Separate State and Actions](#separate-state-and-actions)\n- [Extract Store Type](#extract-store-type)\n- [Async Actions](#async-actions)\n- [Typed Slices with StateCreator](#typed-slices-with-statecreator)\n- [Middleware Type Parameters](#middleware-type-parameters)\n- [Typed Selectors](#typed-selectors)\n- [Custom Equality Functions](#custom-equality-functions)\n- [Vanilla Store with Types](#vanilla-store-with-types)\n\n---\n\n## Curried Create Syntax\n\n```typescript\n// Required for TypeScript - note the double parentheses\nconst useStore = create<State>()((set) => ({\n  // implementation\n}))\n\n// Wrong - type inference fails with middleware\ncreate<State>((set) => ({ ... }))\n\n// Correct\ncreate<State>()((set) => ({ ... }))\n```\n\n## Separate State and Actions\n\n```typescript\ninterface State {\n  bears: number\n  fish: number\n}\n\ninterface Actions {\n  increase: () => void\n  reset: () => void\n}\n\nconst useStore = create<State & Actions>()((set, get, store) => ({\n  bears: 0,\n  fish: 0,\n  increase: () => set((state) => ({ bears: state.bears + 1 })),\n  reset: () => set(store.getInitialState()),\n}))\n```\n\n## Extract Store Type\n\n```typescript\nimport { type ExtractState } from 'zustand'\n\nconst useBearStore = create((set) => ({\n  bears: 3,\n  increase: (by: number) => set((s) => ({ bears: s.bears + by })),\n}))\n\n// Extract type for reuse\nexport type BearState = ExtractState<typeof useBearStore>\n```\n\n## Async Actions\n\n```typescript\ninterface State {\n  data: Data | null\n  loading: boolean\n}\n\ninterface Actions {\n  fetchData: () => Promise<void>\n}\n\nconst useStore = create<State & Actions>((set) => ({\n  data: null,\n  loading: false,\n\n  fetchData: async () => {\n    set({ loading: true })\n    try {\n      const response = await fetch('/api/data')\n      const data = await response.json()\n      set({ data, loading: false })\n    } catch (error) {\n      set({ loading: false })\n    }\n  },\n}))\n```\n\n## Typed Slices with StateCreator\n\n```typescript\nimport { StateCreator } from 'zustand'\n\ninterface BearSlice {\n  bears: number\n  addBear: () => void\n}\n\ninterface FishSlice {\n  fish: number\n  addFish: () => void\n}\n\ntype BoundStore = BearSlice & FishSlice\n\nconst createBearSlice: StateCreator<\n  BoundStore,  // Full store type\n  [],          // Middleware applied before\n  [],          // Middleware applied after\n  BearSlice    // This slice's type\n> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n})\n\nconst createFishSlice: StateCreator<\n  BoundStore,\n  [],\n  [],\n  FishSlice\n> = (set) => ({\n  fish: 0,\n  addFish: () => set((state) => ({ fish: state.fish + 1 })),\n})\n\nconst useBoundStore = create<BoundStore>()((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}))\n```\n\n## Middleware Type Parameters\n\n```typescript\nimport { create } from 'zustand'\nimport { devtools, persist } from 'zustand/middleware'\n\ninterface State {\n  count: number\n  increment: () => void\n}\n\nconst useStore = create<State>()(\n  devtools(\n    persist(\n      (set) => ({\n        count: 0,\n        increment: () => set((state) => ({ count: state.count + 1 })),\n      }),\n      { name: 'count-storage' }\n    ),\n    { name: 'CountStore' }\n  )\n)\n```\n\n## Typed Selectors\n\n```typescript\ninterface BearState {\n  bears: number\n  increase: (by: number) => void\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n}))\n\n// Selector is automatically typed\nconst bears = useBearStore((state) => state.bears)        // number\nconst increase = useBearStore((state) => state.increase)  // (by: number) => void\n```\n\n## Custom Equality Functions\n\n```typescript\nimport { createWithEqualityFn } from 'zustand/traditional'\nimport { shallow } from 'zustand/shallow'\n\nconst useStore = createWithEqualityFn<State>()(\n  (set) => ({\n    // store implementation\n  }),\n  shallow  // Use shallow comparison by default\n)\n\n// Note: For most cases, use useShallow instead\n// useShallow is imported from 'zustand/react/shallow' or 'zustand/shallow'\n// The former is React-specific, the latter includes both shallow and useShallow\n```\n\n## Vanilla Store with Types\n\n```typescript\nimport { createStore } from 'zustand/vanilla'\n\ninterface CounterState {\n  count: number\n  increment: () => void\n  decrement: () => void\n}\n\nconst counterStore = createStore<CounterState>((set) => ({\n  count: 0,\n  increment: () => set((state) => ({ count: state.count + 1 })),\n  decrement: () => set((state) => ({ count: state.count - 1 })),\n}))\n\n// Typed access\nconst count: number = counterStore.getState().count\n```\n"
      },
      "plugins": [
        {
          "name": "beagle",
          "source": "./",
          "description": "Code review skills and verification workflows for Python, Go, React, and AI frameworks",
          "version": "1.12.0",
          "keywords": [
            "code-review",
            "python",
            "go",
            "react",
            "ai",
            "langgraph",
            "pydantic",
            "fastapi",
            "bubbletea"
          ],
          "categories": [
            "ai",
            "bubbletea",
            "code-review",
            "fastapi",
            "go",
            "langgraph",
            "pydantic",
            "python",
            "react"
          ],
          "install_commands": [
            "/plugin marketplace add existential-birds/beagle",
            "/plugin install beagle@existential-birds"
          ]
        }
      ]
    }
  ]
}