{
  "author": {
    "id": "MarkWells-Dev",
    "display_name": "Mark Wells Dev",
    "avatar_url": "https://avatars.githubusercontent.com/u/255475426?v=4"
  },
  "marketplaces": [
    {
      "name": "catenary",
      "version": null,
      "description": "LSP bridge for Claude Code - access IDE-quality code intelligence through MCP",
      "repo_full_name": "MarkWells-Dev/Catenary",
      "repo_url": "https://github.com/MarkWells-Dev/Catenary",
      "repo_description": "A bridge between MCP (Model Context Protocol) and LSP (Language Server Protocol)",
      "signals": {
        "stars": 3,
        "forks": 1,
        "pushed_at": "2026-02-18T19:27:47Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"catenary\",\n  \"description\": \"LSP bridge for Claude Code - access IDE-quality code intelligence through MCP\",\n  \"owner\": {\n    \"name\": \"Mark Wells Dev\",\n    \"email\": \"contact@markwells.dev\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"catenary\",\n      \"description\": \"Bridge between MCP and LSP, providing IDE-quality code intelligence (hover, go-to-definition, references, diagnostics, completions, and more) for any language with an LSP server\",\n      \"version\": \"1.3.2\",\n      \"author\": {\n        \"name\": \"Mark Wells Dev\",\n        \"email\": \"contact@markwells.dev\"\n      },\n      \"source\": \"./plugins/catenary\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/MarkWells-Dev/Catenary\"\n    }\n  ]\n}\n",
        "README.md": "# Catenary\n\n[![CI](https://github.com/MarkWells-Dev/Catenary/actions/workflows/ci.yml/badge.svg)](https://github.com/MarkWells-Dev/Catenary/actions/workflows/ci.yml)\n[![CD](https://github.com/MarkWells-Dev/Catenary/actions/workflows/cd.yml/badge.svg)](https://github.com/MarkWells-Dev/Catenary/actions/workflows/cd.yml)\n\n**Stop wasting context on redundant file reads.**\n\nAI coding agents are smart. The bottleneck isn't intelligence — it's I/O.\nEvery file an agent reads goes into an append-only context window. Every edit\ncreates another copy. Three rounds of read-edit-verify on a single file puts\nthree full copies in context, re-processed on every subsequent turn. In a\ntypical session, this produces a **1,000x+ amplification** between what you\ntype and what the model actually processes.\n\nCatenary replaces brute-force file scanning with **graph navigation**. Instead\nof reading a 500-line file to find a type signature, the agent asks the\nlanguage server directly — 50 tokens instead of 2,000. Instead of grepping\nacross 20 files to find a definition, one LSP query returns the exact\nlocation. The context stays lean across the entire session.\n\n## How It Works\n\n```mermaid\ngraph LR\n    A[\"AI Assistant<br/>(Claude, Gemini)\"] <-->|MCP| B[\"Catenary<br/><br/>MCP ↔ LSP<br/>Bridge\"]\n    B <-->|LSP| C[rust-analyzer]\n    B <-->|LSP| D[pyright]\n    B <-->|LSP| E[gopls]\n```\n\nCatenary bridges [MCP](https://modelcontextprotocol.io/) and\n[LSP](https://microsoft.github.io/language-server-protocol/), giving agents\nthe same code intelligence that powers your IDE. It manages multiple language\nservers, routes requests by file type, and provides automatic post-edit\ndiagnostics — all through a single MCP server.\n\n## Quick Start\n\n### 1. Install\n\n```bash\ncargo install catenary-mcp\n```\n\n### 2. Configure language servers\n\nAdd your language servers to `~/.config/catenary/config.toml`:\n\n```toml\n[server.rust]\ncommand = \"rust-analyzer\"\n\n[server.python]\ncommand = \"pyright-langserver\"\nargs = [\"--stdio\"]\n```\n\n### 3. Connect your AI assistant\n\n**Claude Code**\n```\n/plugin marketplace add https://github.com/MarkWells-Dev/Catenary\n/plugin install catenary@catenary\n```\n\nThe plugin configures the MCP server and adds a `PostToolUse` hook that\nreturns LSP diagnostics after every edit.\n\n**Gemini CLI**\n```bash\ngemini extensions install https://github.com/MarkWells-Dev/Catenary\n```\n\nThe extension configures the MCP server and adds an `AfterTool` hook that\nreturns LSP diagnostics after every edit.\n\nOptionally, install the [policy file](https://markwells-dev.github.io/catenary/cli-integration.html#gemini-cli)\nto `~/.gemini/policies/catenary-constrained.toml` to block text-scanning\ncommands and force LSP-first navigation.\n\n> Catenary also works as a supplement alongside built-in tools — just add the\n> MCP server without restricting permissions. But you'll get the most value in\n> **[constrained mode](https://markwells-dev.github.io/catenary/cli-integration.html)**,\n> where the agent is forced to use efficient LSP queries instead of falling\n> back to file reads and grep.\n\n### 4. Verify\n\nCheck that your language servers are working:\n\n```bash\ncatenary doctor\n```\n\n```\nrust         rust-analyzer       ✓ ready\n             hover definition references document_symbols search code_actions rename call_hierarchy\n\npython       pyright-langserver  ✓ ready\n             hover definition references document_symbols search rename\n\ntoml         taplo               - skipped (no matching files)\n```\n\nThen edit any source file — you should see LSP diagnostics appear in the\nmodel's context after each edit. Catenary's `PostToolUse` hook automatically\nnotifies the running LSP servers and returns any errors or warnings.\n\n## Why This Matters\n\n| Operation | Tokens | Copies in context |\n|-----------|--------|-------------------|\n| Read a 500-line file | ~2,000 | +1 per read |\n| Rewrite that file | ~2,000 | +1 (now 2 copies) |\n| Read it again to verify | ~2,000 | +1 (now 3 copies) |\n| **Total for one file** | **~6,000** | **3 copies** |\n\n| LSP alternative | Tokens | Copies in context |\n|-----------------|--------|-------------------|\n| `hover` for type info | ~100 | 0 (stateless) |\n| `definition` | ~50 | 0 |\n| Native edit + notify hook diagnostics | ~300 | 0 (no re-read needed) |\n| **Total** | **~450** | **0 copies** |\n\nEvery token in context is re-processed on every turn. Bigger context windows\ndon't fix this — they just let you waste more before hitting the wall.\n\n## Tools\n\n| Tool | Description |\n|------|-------------|\n| `hover` | Documentation and type info |\n| `definition` | Go to definition |\n| `find_references` | Find all references |\n| `search` | Symbol search with grep fallback |\n| `diagnostics` | Errors and warnings |\n| `list_directory` | List directory contents |\n| `catenary notify` | PostToolUse hook — returns LSP diagnostics after edits |\n| ... | [See all tools](https://github.com/MarkWells-Dev/Catenary/wiki/Overview#available-tools) |\n\n## Known Limitations\n\n**MCP tool display in CLIs.** Claude Code and Gemini CLI render built-in tools\nwith clean, purpose-built UI — diffs for edits, syntax highlighting for reads.\nMCP tools get none of this. Catenary's LSP tool calls show raw escaped JSON in\nthe approval prompt. This is a host CLI limitation, not something Catenary can\nfix — MCP tools need the same display treatment as built-in tools.\n\nFile I/O uses the host's native tools (with full diff/highlight UX) and\nCatenary provides diagnostics via the `PostToolUse` hook.\n\n## Documentation\n\nFull documentation at **[markwells-dev.github.io/catenary](https://markwells-dev.github.io/catenary/)**\n\n- **[Overview](https://markwells-dev.github.io/catenary/overview.html)** — The problem, the solution, available tools\n- **[Installation](https://markwells-dev.github.io/catenary/installation.html)** — Setup for Claude Code, Claude Desktop, Gemini CLI\n- **[Configuration](https://markwells-dev.github.io/catenary/configuration.html)** — Language servers, `catenary doctor`\n- **[CLI Integration](https://markwells-dev.github.io/catenary/cli-integration.html)** — Constrained mode for Claude Code and Gemini CLI\n- **[AI Agents](https://markwells-dev.github.io/catenary/ai-agents.html)** — System prompt suggestions and workflow patterns\n\n## License\n\n**GPL-3.0** — See [LICENSE](LICENSE) for details.\n\n**Commercial licensing** available for proprietary use. Contact `contact@markwells.dev`.\n",
        "plugins/catenary/README.md": "# Catenary\n\nA high-performance multiplexing bridge between MCP (Model Context Protocol) and LSP (Language Server Protocol). Enables LLMs to access IDE-grade code intelligence across multiple languages simultaneously with smart routing and UTF-8 accuracy.\n\n## Installation\n\n### 1. Install Catenary\n\n```bash\ncargo install catenary-mcp\n```\n\n### 2. Install the Plugin\n\n```\n/plugin marketplace add https://github.com/MarkWells-Dev/Catenary\n/plugin install catenary@catenary\n```\n\nThe plugin configures the MCP server and adds hooks for LSP diagnostics after edits and `/add-dir` root syncing.\n\n## Configuration\n\nSee `config.example.toml` in this directory or the [Official Configuration Guide](https://markwells-dev.github.io/catenary/configuration.html).\n\n## Documentation\n\nFor full features, tool lists, and troubleshooting, please visit the **[Main Repository](https://github.com/MarkWells-Dev/Catenary)**.\n"
      },
      "plugins": [
        {
          "name": "catenary",
          "description": "Bridge between MCP and LSP, providing IDE-quality code intelligence (hover, go-to-definition, references, diagnostics, completions, and more) for any language with an LSP server",
          "version": "1.3.2",
          "author": {
            "name": "Mark Wells Dev",
            "email": "contact@markwells.dev"
          },
          "source": "./plugins/catenary",
          "category": "development",
          "homepage": "https://github.com/MarkWells-Dev/Catenary",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add MarkWells-Dev/Catenary",
            "/plugin install catenary@catenary"
          ]
        }
      ]
    }
  ]
}