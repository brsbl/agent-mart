{
  "author": {
    "id": "MarkWells-Dev",
    "display_name": "Mark Wells Dev",
    "avatar_url": "https://avatars.githubusercontent.com/u/255475426?v=4"
  },
  "marketplaces": [
    {
      "name": "catenary",
      "version": null,
      "description": "LSP bridge for Claude Code - access IDE-quality code intelligence through MCP",
      "repo_full_name": "MarkWells-Dev/Catenary",
      "repo_url": "https://github.com/MarkWells-Dev/Catenary",
      "repo_description": "A bridge between MCP (Model Context Protocol) and LSP (Language Server Protocol)",
      "signals": {
        "stars": 3,
        "forks": 1,
        "pushed_at": "2026-02-17T18:54:50Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"catenary\",\n  \"description\": \"LSP bridge for Claude Code - access IDE-quality code intelligence through MCP\",\n  \"owner\": {\n    \"name\": \"Mark Wells Dev\",\n    \"email\": \"contact@markwells.dev\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"catenary\",\n      \"description\": \"Bridge between MCP and LSP, providing IDE-quality code intelligence (hover, go-to-definition, references, diagnostics, completions, and more) for any language with an LSP server\",\n      \"version\": \"1.2.2\",\n      \"author\": {\n        \"name\": \"Mark Wells Dev\",\n        \"email\": \"contact@markwells.dev\"\n      },\n      \"source\": \"./plugins/catenary\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/MarkWells-Dev/Catenary\"\n    }\n  ]\n}\n",
        "README.md": "# Catenary\n\n[![CI](https://github.com/MarkWells-Dev/Catenary/actions/workflows/ci.yml/badge.svg)](https://github.com/MarkWells-Dev/Catenary/actions/workflows/ci.yml)\n[![CD](https://github.com/MarkWells-Dev/Catenary/actions/workflows/cd.yml/badge.svg)](https://github.com/MarkWells-Dev/Catenary/actions/workflows/cd.yml)\n\n**Stop wasting context on redundant file reads.**\n\nAI coding agents are smart. The bottleneck isn't intelligence — it's I/O.\nEvery file an agent reads goes into an append-only context window. Every edit\ncreates another copy. Three rounds of read-edit-verify on a single file puts\nthree full copies in context, re-processed on every subsequent turn. In a\ntypical session, this produces a **1,000x+ amplification** between what you\ntype and what the model actually processes.\n\nCatenary replaces brute-force file scanning with **graph navigation**. Instead\nof reading a 500-line file to find a type signature, the agent asks the\nlanguage server directly — 50 tokens instead of 2,000. Instead of grepping\nacross 20 files to find a definition, one LSP query returns the exact\nlocation. The context stays lean across the entire session.\n\n## How It Works\n\n```mermaid\ngraph LR\n    A[\"AI Assistant<br/>(Claude, Gemini)\"] <-->|MCP| B[\"Catenary<br/><br/>MCP ↔ LSP<br/>Bridge\"]\n    B <-->|LSP| C[rust-analyzer]\n    B <-->|LSP| D[pyright]\n    B <-->|LSP| E[gopls]\n```\n\nCatenary bridges [MCP](https://modelcontextprotocol.io/) and\n[LSP](https://microsoft.github.io/language-server-protocol/), giving agents\nthe same code intelligence that powers your IDE. It manages multiple language\nservers, routes requests by file type, and provides file I/O with automatic\ndiagnostics — all through a single MCP server.\n\n## Quick Start\n\n### 1. Install\n\n```bash\ncargo install catenary-mcp\n```\n\n### 2. Configure language servers\n\nAdd your language servers to `~/.config/catenary/config.toml`:\n\n```toml\n[server.rust]\ncommand = \"rust-analyzer\"\n\n[server.python]\ncommand = \"pyright-langserver\"\nargs = [\"--stdio\"]\n```\n\n### 3. Connect your AI assistant\n\n**Claude Code** (recommended — constrained mode)\n```bash\nclaude mcp add catenary -- catenary\n```\n\nThen add to `.claude/settings.json` to replace built-in tools with Catenary:\n\n```json\n{\n  \"permissions\": {\n    \"deny\": [\"Read\", \"Edit\", \"Write\", \"Bash\", \"Grep\", \"Glob\", \"Task\", \"NotebookEdit\"],\n    \"allow\": [\"WebSearch\", \"WebFetch\", \"mcp__catenary__*\", \"ToolSearch\", \"AskUserQuestion\"]\n  }\n}\n```\n\n**Gemini CLI** (recommended — constrained mode)\n```json\n{\n  \"tools\": {\n    \"core\": [\"web_fetch\", \"google_web_search\", \"save_memory\"]\n  },\n  \"mcpServers\": {\n    \"catenary\": { \"command\": \"catenary\" }\n  }\n}\n```\n\n> Catenary also works as a supplement alongside built-in tools — just add the\n> MCP server without restricting permissions. But you'll get the most value in\n> constrained mode, where the agent is forced to use efficient LSP queries\n> instead of falling back to file reads and grep.\n\n### 4. Display hooks (optional)\n\nCatenary's `edit_file` and `write_file` tools pass raw JSON to the CLI, which\nis hard to review. The bundled hook formats these as colorized diffs and\npreviews.\n\n**Claude Code**\n```bash\nmkdir -p ~/.claude/hooks\ncp .claude-plugin/plugins/catenary/hooks/format_tool_output.py ~/.claude/hooks/\nchmod +x ~/.claude/hooks/format_tool_output.py\n```\n\nAdd to `~/.claude/settings.json`:\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"mcp__.*__edit_file|mcp__.*__write_file\",\n        \"hooks\": [{ \"type\": \"command\", \"command\": \"~/.claude/hooks/format_tool_output.py\" }]\n      }\n    ]\n  }\n}\n```\n\n**Gemini CLI** — not currently supported. Gemini's `BeforeTool` hook fires\nafter the user approves the tool call, so there's no way to show a formatted\ndiff in the approval prompt. The raw JSON parameters are all that's available\nat decision time.\n\n## Why This Matters\n\n| Operation | Tokens | Copies in context |\n|-----------|--------|-------------------|\n| Read a 500-line file | ~2,000 | +1 per read |\n| Rewrite that file | ~2,000 | +1 (now 2 copies) |\n| Read it again to verify | ~2,000 | +1 (now 3 copies) |\n| **Total for one file** | **~6,000** | **3 copies** |\n\n| LSP alternative | Tokens | Copies in context |\n|-----------------|--------|-------------------|\n| `hover` for type info | ~100 | 0 (stateless) |\n| `definition` | ~50 | 0 |\n| `edit_file` (returns diagnostics) | ~300 | 0 (no re-read needed) |\n| **Total** | **~450** | **0 copies** |\n\nEvery token in context is re-processed on every turn. Bigger context windows\ndon't fix this — they just let you waste more before hitting the wall.\n\n## Tools\n\n| Tool | Description |\n|------|-------------|\n| `hover` | Documentation and type info |\n| `definition` | Go to definition |\n| `find_references` | Find all references |\n| `search` | Symbol search with grep fallback |\n| `diagnostics` | Errors and warnings |\n| `read_file` | Read file contents + diagnostics |\n| `write_file` | Write file + diagnostics |\n| `edit_file` | Search-and-replace edit + diagnostics |\n| `list_directory` | List directory contents |\n| `run` | Execute shell commands (allowlist enforced) |\n| ... | [See all tools](https://github.com/MarkWells-Dev/Catenary/wiki/Overview#available-tools) |\n\n## Known Limitations\n\n**MCP tool display in CLIs.** Claude Code and Gemini CLI render built-in tools\nwith clean, purpose-built UI — diffs for edits, syntax highlighting for reads.\nMCP tools get none of this. Every Catenary tool call shows raw escaped JSON in\nthe approval prompt, making the normally sleek UX feel like a debug console.\n\nThe bundled display hook (step 4 above) patches this for `edit_file` and\n`write_file` in Claude Code, but every other tool still renders as JSON. This\nis a host CLI limitation, not something Catenary can fix — MCP tools need the\nsame display treatment as built-in tools.\n\n**Gemini CLI hooks fire post-approval.** Gemini's `BeforeTool` hook runs after\nthe user accepts the tool call, so display hooks can't improve the approval\nprompt. The formatted output only appears in the debug console.\n\n## Documentation\n\n- **[Overview](https://github.com/MarkWells-Dev/Catenary/wiki/Overview)** — The problem, the solution, available tools\n- **[Install](https://github.com/MarkWells-Dev/Catenary/wiki/Install)** — Setup for Claude Code, Claude Desktop, Gemini CLI\n- **[Config](https://github.com/MarkWells-Dev/Catenary/wiki/Config)** — Configuration reference\n- **[LSPs](https://github.com/MarkWells-Dev/Catenary/wiki/LSPs)** — Language server setup guides\n- **[AI Agents](https://github.com/MarkWells-Dev/Catenary/wiki/AI-Agents)** — System prompt suggestions and workflow patterns\n\n## License\n\n**GPL-3.0** — See [LICENSE](LICENSE) for details.\n\n**Commercial licensing** available for proprietary use. Contact `contact@markwells.dev`.\n",
        "plugins/catenary/README.md": "# Catenary\n\nA high-performance multiplexing bridge between MCP (Model Context Protocol) and LSP (Language Server Protocol). Enables LLMs to access IDE-grade code intelligence across multiple languages simultaneously with smart routing and UTF-8 accuracy.\n\n## Installation\n\n### 1. Install Catenary\n\n```bash\ncargo install catenary-mcp\n```\n\n### 2. Connect your AI Assistant\n\n**Claude Code**\n```bash\nclaude mcp add catenary -- catenary\n```\n\n**Gemini CLI**\nAdd to `~/.gemini/settings.json`:\n```json\n{\n  \"mcpServers\": {\n    \"catenary\": { \"command\": \"catenary\" }\n  }\n}\n```\n\n## Configuration\n\nSee `config.example.toml` in this directory or the [Official Configuration Guide](https://github.com/MarkWells-Dev/Catenary/wiki/Config).\n\n## Documentation\n\nFor full features, tool lists, and troubleshooting, please visit the **[Main Repository](https://github.com/MarkWells-Dev/Catenary)**.\n"
      },
      "plugins": [
        {
          "name": "catenary",
          "description": "Bridge between MCP and LSP, providing IDE-quality code intelligence (hover, go-to-definition, references, diagnostics, completions, and more) for any language with an LSP server",
          "version": "1.2.2",
          "author": {
            "name": "Mark Wells Dev",
            "email": "contact@markwells.dev"
          },
          "source": "./plugins/catenary",
          "category": "development",
          "homepage": "https://github.com/MarkWells-Dev/Catenary",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add MarkWells-Dev/Catenary",
            "/plugin install catenary@catenary"
          ]
        }
      ]
    }
  ]
}