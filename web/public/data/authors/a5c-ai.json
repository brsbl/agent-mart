{
  "author": {
    "id": "a5c-ai",
    "display_name": "a5c.ai",
    "avatar_url": "https://avatars.githubusercontent.com/u/197881114?v=4"
  },
  "marketplaces": [
    {
      "name": "a5c.ai",
      "version": null,
      "description": "Babysitter",
      "repo_full_name": "a5c-ai/babysitter",
      "repo_url": "https://github.com/a5c-ai/babysitter",
      "repo_description": "Babysitter enables Claude Code to manage sophisticated development workflows through deterministic, resumable orchestration",
      "signals": {
        "stars": 16,
        "forks": 1,
        "pushed_at": "2026-01-30T07:43:39Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"a5c.ai\",\n  \"owner\": {\n    \"name\": \"a5c.ai\",\n    \"email\": \"support@a5c.ai\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"babysitter\",\n      \"source\": \"./plugins/babysitter\",\n      \"description\": \"Babysitter\",\n      \"version\": \"4.0.122\",\n      \"author\": {\n        \"name\": \"a5c.ai\"\n      }\n    }\n  ]\n}\n",
        "README.md": "<div align=\"center\">\n\n# Babysitter\n\n[![npm version](https://img.shields.io/npm/v/@a5c-ai/babysitter-sdk.svg)](https://www.npmjs.com/package/@a5c-ai/babysitter-sdk)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub issues](https://img.shields.io/github/issues/a5c-ai/babysitter.svg)](https://github.com/a5c-ai/babysitter/issues)\n[![GitHub stars](https://img.shields.io/github/stars/a5c-ai/babysitter.svg)](https://github.com/a5c-ai/babysitter/stargazers)\n\n> **Orchestrate complex, multi-step workflows with human-in-the-loop approval, iterative refinement, and quality convergence.**\n\nBabysitter enables Claude Code to manage sophisticated development workflows through deterministic, resumable orchestration. Just ask Claude to use the babysitter skill, and it will handle the rest.\n\n[Getting Started](#installation) • [Documentation](#how-it-works) • [Examples](#example-workflows) • [Community](#community-and-support)\n\n</div>\n\n---\n\n## Table of Contents\n\n- [What is Babysitter?](#what-is-babysitter)\n- [What is @a5c-ai?](#what-is-a5c-ai)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Complete End-to-End Example](#complete-end-to-end-example)\n- [How It Works](#how-it-works)\n- [Why Babysitter?](#why-babysitter)\n- [Comparison with Alternative Approaches](#comparison-with-alternative-approaches)\n- [Commands](#commands)\n- [Behind the Scenes: Process Examples](#behind-the-scenes-process-examples)\n- [Common Use Cases](#common-use-cases)\n- [Methodologies](#methodologies)\n- [Example Workflows](#example-workflows)\n- [Task Types](#task-types)\n- [Resuming Work](#resuming-work)\n- [Best Practices](#best-practices)\n- [Performance Expectations](#performance-expectations)\n- [Security Best Practices](#security-best-practices)\n- [Monitoring and Observability](#monitoring-and-observability)\n- [Troubleshooting](#troubleshooting)\n- [Architecture Overview](#architecture-overview)\n- [Limitations and Known Issues](#limitations-and-known-issues)\n- [FAQ](#faq)\n- [Contributing](#contributing)\n- [Community and Support](#community-and-support)\n- [License](#license)\n- [Further Reading](#further-reading)\n\n---\n\n## What is Babysitter?\n\nBabysitter is an orchestration framework for Claude Code that enables deterministic, event-sourced workflow management. It allows you to build complex, multi-step development processes with built-in quality gates, human approval checkpoints, and automatic iteration until quality targets are met.\n\nBabysitter works seamlessly with your prexisting subagents, skills and tools. It can be used to orchestrate them into complex workflows.\n\n## What is a5c.ai?\n\n**a5c.ai** is an organization focused on building advanced AI orchestration and automation tools. The name stands for \"agentic ai\". It's a collection of tools that enable AI systems like Claude and others to work more effectively on complex, real-world software development tasks (but not limited to). The Babysitter project is part of this ecosystem, providing structured workflow orchestration for agentic ai.\n\n## Prerequisites\n\nBefore installing Babysitter, ensure you have:\n\n- **Node.js**: Version 20.0.0 or higher (recommend 22.x LTS) - ideally using nvm to manage node versions\n- **Claude Code**: Latest version installed and configured - see [Claude Code documentation](https://code.claude.com/docs/en/quickstart)\n- **Git**: For cloning the repository (optional, for manual installation)\n\n---\n\n## Installation\n\n### 1. Install the SDK\n\n```bash\nnpm install -g @a5c-ai/babysitter@latest @a5c-ai/babysitter-sdk@latest @a5c-ai/babysitter-breakpoints@latest\n```\n\n### 2. Install the Plugin\n\n**Via Claude Code (Recommended):**\n\n```bash\n# Add the plugin repository\nclaude plugin marketplace add a5c-ai/babysitter\n\n# Install the plugin\nclaude plugin install --scope user babysitter@a5c.ai\n\n# Enable per user\nclaude plugin enable --scope user babysitter@a5c.ai \n```\n\nThen restart Claude Code.\n\nTip: Run update daily or \n```bash\nclaude plugin marketplace update a5c.ai \n\nclaude plugin update babysitter@a5c.ai \n```\n\n### 3. Verify Installation\n\nIn Claude Code, type `/skills` to verify \"babysit\" appears in the list.\n\n### 4. Run the babysitter breakpoints service\n\nIn a new terminal, run the following command:\n\n```bash\nnpx -y @a5c-ai/babysitter-breakpoints@latest start\n```\n\nThis will start the babysitter breakpoints service at http://localhost:3184\n\nYou can either:\n\n1. use a tunneling service like ngrok to expose the service to the internet:\n\n```bash\nngrok http 3184\n```\n\nOR\n\n2. configure the telegram extension of the breakpoints service. (from the breakpoints ui)\n\n---\n\n## Quick Start\n\nSimply ask Claude to use the babysitter skill:\n\n\n```bash\nclaude \"/babysit implement user authentication with TDD\"\n```\n\nor in English:\n\n```\nUse the babysitter skill to implement user authentication with TDD\n```\n\nClaude will:\n1. Create an orchestration run\n2. Set up the iteration loop\n3. Execute tasks step-by-step\n4. Handle quality checks and approvals\n5. Continue until completion\n\n---\n\n## Complete End-to-End Example\n\n> **Note**: Screenshots and GIFs demonstrating this workflow are planned for future releases. For now, this section provides detailed command outputs and process flows.\n\nLet's walk through a complete real-world example: building a REST API with authentication using TDD and quality convergence.\n\n### Step 1: Start the Run\n\n**Command:**\n```\nUse the babysitter skill to build a REST API for task management with:\n- User authentication (JWT)\n- CRUD operations for tasks\n- Express.js and SQLite\n- TDD with 85% quality target\n- Max 5 iterations\n```\n\n**Babysitter Output:**\n```\nCreating new babysitter run: rest-api-auth-20260122-143012\n\nProcess Definition: TDD Quality Convergence\nTarget Quality: 85%\nMax Iterations: 5\n\nRun ID: 01KFFTSF8TK8C9GT3YM9QYQ6WG\nRun Directory: .a5c/runs/01KFFTSF8TK8C9GT3YM9QYQ6WG/\n```\n\n### Step 2: Research Phase\n\n**Console Output:**\n```\n[Iteration 1/5] Starting research phase...\n\nTask: Research Codebase Patterns\n- Analyzing existing Express.js patterns... ✓\n- Checking authentication implementations... ✓\n- Reviewing database schemas... ✓\n- Identifying test frameworks... ✓\n\nResearch Summary:\n- Found existing Express setup with middleware pattern\n- JWT authentication pattern in /auth module\n- Using Jest + Supertest for API testing\n- SQLite with better-sqlite3 driver\n```\n\n### Step 3: Specifications Phase\n\n**Console Output:**\n```\nTask: Generate Specifications\nCreating detailed specs for task management API...\n\nSpecifications:\n✓ Endpoints: POST /auth/register, POST /auth/login, GET/POST/PUT/DELETE /tasks\n✓ Authentication: JWT tokens, refresh tokens, password hashing with bcrypt\n✓ Database: Users table, Tasks table with foreign keys\n✓ Tests: Unit tests for auth logic, integration tests for endpoints\n✓ Quality Metrics: 85% coverage, ESLint passing, no security issues\n\nWaiting for approval...\n```\n\n### Step 4: Human Approval (Breakpoint)\n\n**Breakpoint UI:**\n```\n┌─────────────────────────────────────────────────────────┐\n│ Breakpoint: Specification Review                        │\n├─────────────────────────────────────────────────────────┤\n│ Question: Review and approve specifications?            │\n│                                                         │\n│ Context:                                                │\n│ - 5 endpoints defined (auth + CRUD)                     │\n│ - JWT authentication with refresh tokens                │\n│ - SQLite database with 2 tables                         │\n│ - Jest test suite with Supertest                        │\n│                                                         │\n│ [Approve] [Reject] [Comment]                            │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Action:** Click \"Approve\"\n\n### Step 5: TDD Implementation Loop\n\n**Iteration 1:**\n```\n[Iteration 1/5] Starting TDD implementation...\n\nTask: Write Tests\n- Writing auth endpoint tests... ✓ (15 test cases)\n- Writing task CRUD tests... ✓ (20 test cases)\n- Writing middleware tests... ✓ (8 test cases)\n\nTask: Implement Code\n- Implementing auth endpoints... ✓\n- Implementing task CRUD... ✓\n- Implementing middleware... ✓\n\nParallel Quality Checks:\n├─ Coverage: 72% (target: 85%) ⚠\n├─ ESLint: 3 warnings\n├─ Security Scan: No issues ✓\n└─ Tests: 41/43 passing (2 failures)\n\nAgent Quality Score: 68/100 (below target)\nIssues: Coverage too low, 2 failing tests, ESLint warnings\n\nContinuing to next iteration...\n```\n\n**Iteration 2:**\n```\n[Iteration 2/5] Refining implementation...\n\nTask: Fix Failing Tests\n- Fixed auth token expiry test ✓\n- Fixed task deletion cascade test ✓\n\nTask: Improve Coverage\n- Added edge case tests for invalid inputs ✓\n- Added tests for error handling paths ✓\n\nTask: Fix ESLint Issues\n- Fixed unused variable warnings ✓\n- Applied consistent code style ✓\n\nParallel Quality Checks:\n├─ Coverage: 88% (target: 85%) ✓\n├─ ESLint: 0 warnings ✓\n├─ Security Scan: No issues ✓\n└─ Tests: 43/43 passing ✓\n\nAgent Quality Score: 92/100 (target met!)\n\nQuality target achieved in 2 iterations.\n```\n\n### Step 6: Final Approval\n\n**Breakpoint UI:**\n```\n┌─────────────────────────────────────────────────────────┐\n│ Breakpoint: Deployment Approval                         │\n├─────────────────────────────────────────────────────────┤\n│ Question: Deploy to production?                         │\n│                                                         │\n│ Results:                                                │\n│ ✓ Quality score: 92/100 (target: 85)                    │\n│ ✓ Test coverage: 88%                                    │\n│ ✓ All 43 tests passing                                  │\n│ ✓ No ESLint warnings                                    │\n│ ✓ No security issues                                    │\n│                                                         │\n│ Files changed: 12 files, +847 lines                     │\n│                                                         │\n│ [Approve] [Reject] [View Changes]                       │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Action:** Click \"Approve\"\n\n### Step 7: Completion\n\n**Final Output:**\n```\n✓ Run completed successfully!\n\nSummary:\n- Total Iterations: 2 of 5\n- Final Quality Score: 92/100\n- Test Coverage: 88%\n- Files Created: 12\n- Tests: 43 passing\n- Duration: 4m 32s\n\nRun ID: 01KFFTSF8TK8C9GT3YM9QYQ6WG\nJournal: .a5c/runs/01KFFTSF8TK8C9GT3YM9QYQ6WG/journal/journal.jsonl\n\nNext Steps:\n- Review changes: git diff\n- Run tests: npm test\n- Start server: npm start\n```\n\n### Behind the Scenes: Process Definition\n\nThis workflow was orchestrated by this process definition:\n\n```javascript\nexport async function process(inputs, ctx) {\n  const { feature, targetQuality = 85, maxIterations = 5 } = inputs;\n\n  // Phase 1: Research\n  const research = await ctx.task(researchTask, { feature });\n\n  // Phase 2: Specifications\n  const specs = await ctx.task(specificationsTask, { research });\n\n  // Breakpoint: Approve specifications\n  await ctx.breakpoint({\n    question: 'Review and approve specifications?',\n    title: 'Specification Review',\n    context: specs\n  });\n\n  // Phase 3: TDD Loop\n  let iteration = 0;\n  let quality = 0;\n\n  while (iteration < maxIterations && quality < targetQuality) {\n    iteration++;\n    ctx.log(`[Iteration ${iteration}/${maxIterations}] Starting TDD implementation...`);\n\n    // Write tests first\n    const tests = await ctx.task(writeTestsTask, { specs, iteration });\n\n    // Implement code\n    const impl = await ctx.task(implementTask, { tests, specs });\n\n    // Parallel quality checks\n    const [coverage, lint, security, testResults] = await ctx.parallel.all([\n      () => ctx.task(coverageTask, {}),\n      () => ctx.task(lintTask, {}),\n      () => ctx.task(securityTask, {}),\n      () => ctx.task(runTestsTask, {})\n    ]);\n\n    // Agent scores quality\n    const score = await ctx.task(agentScoringTask, {\n      tests, impl, coverage, lint, security, testResults\n    });\n\n    quality = score.overall;\n    ctx.log(`Agent Quality Score: ${quality}/100`);\n\n    if (quality >= targetQuality) {\n      ctx.log('Quality target achieved!');\n      break;\n    }\n  }\n\n  // Final approval before deployment\n  await ctx.breakpoint({\n    question: 'Deploy to production?',\n    title: 'Deployment Approval',\n    context: { quality, iteration, targetQuality }\n  });\n\n  return { success: true, quality, iterations: iteration };\n}\n```\n\n### Key Takeaways\n\n1. **Structured Workflow**: Clear phases with automatic progression\n2. **Quality Convergence**: Iterates until quality target met (2 iterations)\n3. **Human-in-the-Loop**: Two approval gates for critical decisions\n4. **Parallel Execution**: Quality checks run concurrently for speed\n5. **Full Traceability**: Complete audit trail in journal\n6. **Resumable**: Can pause/resume at any point\n\n### Inspecting the Run\n\nView the journal to see complete event history:\n\n```bash\ncat .a5c/runs/01KFFTSF8TK8C9GT3YM9QYQ6WG/journal/journal.jsonl\n```\n\n**Sample Journal Events:**\n```jsonl\n{\"type\":\"RUN_STARTED\",\"timestamp\":\"2026-01-22T14:30:12.445Z\",\"runId\":\"01KFFTSF8TK8C9GT3YM9QYQ6WG\"}\n{\"type\":\"ITERATION_STARTED\",\"timestamp\":\"2026-01-22T14:30:12.567Z\",\"iteration\":1}\n{\"type\":\"TASK_STARTED\",\"timestamp\":\"2026-01-22T14:30:13.123Z\",\"taskId\":\"research-001\",\"taskType\":\"agent\"}\n{\"type\":\"TASK_COMPLETED\",\"timestamp\":\"2026-01-22T14:30:45.789Z\",\"taskId\":\"research-001\",\"result\":{\"status\":\"success\"}}\n{\"type\":\"BREAKPOINT_REQUESTED\",\"timestamp\":\"2026-01-22T14:31:12.234Z\",\"breakpointId\":\"bp-001\"}\n{\"type\":\"BREAKPOINT_APPROVED\",\"timestamp\":\"2026-01-22T14:31:45.123Z\",\"breakpointId\":\"bp-001\"}\n{\"type\":\"QUALITY_SCORE\",\"timestamp\":\"2026-01-22T14:33:23.456Z\",\"iteration\":1,\"score\":68}\n{\"type\":\"QUALITY_SCORE\",\"timestamp\":\"2026-01-22T14:34:44.789Z\",\"iteration\":2,\"score\":92}\n{\"type\":\"RUN_COMPLETED\",\"timestamp\":\"2026-01-22T14:34:44.890Z\",\"status\":\"success\"}\n```\n\n---\n\n## How It Works\n\nBabysitter uses an **event-sourced orchestration model**:\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│                     Babysitter Loop                              │\n│                                                                  │\n│   ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐   │\n│   │ Iterate │ ──▶ │  Get    │ ──▶ │ Execute │ ──▶ │  Post   │   │\n│   │         │     │ Effects │     │ Tasks   │     │ Results │   │\n│   └─────────┘     └─────────┘     └─────────┘     └─────────┘   │\n│        │                                               │         │\n│        └───────────────── repeat ◀────────────────────┘         │\n│                                                                  │\n└──────────────────────────────────────────────────────────────────┘\n```\n\n**Each iteration:**\n1. **Iterate** - Advance the process, request pending effects\n2. **Get Effects** - Check what tasks need to be executed\n3. **Execute** - Run tasks (agents, skills, breakpoints, scripts)\n4. **Post Results** - Record outcomes in the journal\n5. **Repeat** - Continue until process completes\n\n**Everything is recorded:**\n- `.a5c/runs/<runId>/journal/` - Append-only event log\n- `.a5c/runs/<runId>/tasks/` - Task inputs and results\n- `.a5c/runs/<runId>/state.json` - Current state cache\n\nThis means you can **pause, resume, or recover** at any point.\n\n---\n\n## Why Babysitter?\n\n| Traditional Approach | Babysitter |\n|---------------------|------------|\n| Run script once, hope it works | Iterate until quality target met |\n| Manual approval via chat | Structured breakpoints with context |\n| State lost on session end | Event-sourced, fully resumable |\n| Single task execution | Parallel execution, dependencies |\n| No audit trail | Complete journal of all events |\n| Fixed workflow | Process-driven, customizable |\n\n**Key differentiators:**\n- **Deterministic replay** - Rerun from any point in history\n- **Quality convergence** - Loop until metrics are satisfied\n- **Human-in-the-loop** - Breakpoints for approval gates\n- **Agent scoring** - LLM-based quality assessment\n- **Parallel execution** - Run independent tasks concurrently\n\n---\n\n## Comparison with Alternative Approaches\n\nUnderstanding how Babysitter compares to other workflow tools helps you choose the right solution:\n\n### vs. GitHub Actions / CI/CD Pipelines\n\n| Feature | GitHub Actions | Babysitter |\n|---------|---------------|------------|\n| **Trigger** | Git events (push, PR) | Natural language command |\n| **Iteration** | Fixed steps, no loops | Iterative quality convergence |\n| **Human approval** | External approval systems | Built-in breakpoints with UI |\n| **Resumability** | Restart from beginning | Resume from any point |\n| **Use case** | Automated testing/deployment | Development workflows |\n\n**When to use Babysitter**: Development workflows that need iteration, quality gates, and human judgment. GitHub Actions is better for post-commit automation.\n\n### vs. Make / Task Runners\n\n| Feature | Make / npm scripts | Babysitter |\n|---------|-------------------|------------|\n| **Orchestration** | Sequential/parallel tasks | Event-sourced processes |\n| **Quality gates** | Manual checks | Automated scoring + iteration |\n| **State management** | None | Full event journal |\n| **Resumability** | Restart from beginning | Resume from any point |\n| **Human-in-loop** | Manual execution | Structured breakpoints |\n\n**When to use Babysitter**: Complex multi-step workflows with quality requirements. Make/npm is better for simple build tasks.\n\n### vs. Agentic Frameworks (LangGraph, CrewAI, AutoGPT)\n\n| Feature | Agentic Frameworks | Babysitter |\n|---------|-------------------|------------|\n| **Agent focus** | General-purpose agents | Claude Code specialized |\n| **Determinism** | Varied | Event-sourced, reproducible |\n| **IDE integration** | External | Native Claude Code |\n| **Process control** | Agent decides | Structured process definitions |\n| **Audit trail** | Depends on framework | Complete journal always |\n\n**When to use Babysitter**: Software development workflows in Claude Code with deterministic execution. Agentic frameworks are better for general AI automation tasks.\n\n### vs. Manual Claude Code Usage\n\n| Feature | Manual Claude | Babysitter |\n|---------|--------------|------------|\n| **Session persistence** | Lost on restart | Event-sourced, resumable |\n| **Quality iteration** | Manual prompting | Automated convergence |\n| **Approval gates** | Chat-based | Structured breakpoints |\n| **Parallel execution** | Sequential only | Built-in parallelism |\n| **Audit trail** | Chat history | Structured journal |\n\n**When to use Babysitter**: Complex projects requiring multiple iterations, quality gates, or team collaboration. Manual Claude is better for quick one-off tasks.\n\n---\n\n## Commands\n\n### Start a New Run\n\n```\n/babysitter:babysit <prompt> [--max-iterations <n>]\n```\n\n**Examples:**\n```\n/babysitter:babysit Build a todo app with Next.js and SQLite\n/babysitter:babysit Implement user authentication --max-iterations 20\n/babysitter:babysit Refactor the payment module for better error handling\n```\n\n### Resume an Existing Run\n\n```\n/babysitter:babysit resume --run-id <runId>\n```\n\n**Examples:**\n```\n/babysitter:babysit resume --run-id 01KFFTSF8TK8C9GT3YM9QYQ6WG\n/babysitter:babysit resume --run-id todo-app-20260121-084244 --max-iterations 10\n```\n\n### Natural Language (via Skill)\n\nYou can also just ask Claude naturally:\n```\nUse the babysitter skill to build a REST API with TDD\nResume the babysitter run and continue implementation\n```\n\n---\n\n## Behind the Scenes: Process Examples\n\nBabysitter runs are driven by **process definitions** - JavaScript functions that orchestrate tasks.\n\n### Example 1: Simple Build & Test\n\n```javascript\nexport async function process(inputs, ctx) {\n  // Build the project\n  const buildResult = await ctx.task(buildTask, {\n    command: 'npm run build'\n  });\n\n  // Run tests\n  const testResult = await ctx.task(testTask, {\n    command: 'npm test'\n  });\n\n  // Require approval before deploy\n  await ctx.breakpoint({\n    question: 'Build passed. Deploy to production?',\n    title: 'Deployment Approval'\n  });\n\n  return { success: true, build: buildResult, tests: testResult };\n}\n```\n\n### Example 2: TDD Quality Convergence\n\n```javascript\nexport async function process(inputs, ctx) {\n  const { feature, targetQuality = 85, maxIterations = 5 } = inputs;\n\n  // Phase 1: Planning with agent\n  const plan = await ctx.task(agentPlanningTask, { feature });\n\n  // Breakpoint: Review plan\n  await ctx.breakpoint({\n    question: `Review plan for \"${feature}\"?`,\n    title: 'Plan Review'\n  });\n\n  // Phase 2: TDD Loop\n  let iteration = 0;\n  let quality = 0;\n\n  while (iteration < maxIterations && quality < targetQuality) {\n    iteration++;\n\n    // Write tests\n    const tests = await ctx.task(writeTestsTask, { plan, iteration });\n\n    // Implement code\n    const impl = await ctx.task(implementTask, { tests, iteration });\n\n    // Parallel quality checks\n    const [coverage, lint, security] = await ctx.parallel.all([\n      () => ctx.task(coverageTask, {}),\n      () => ctx.task(lintTask, {}),\n      () => ctx.task(securityTask, {})\n    ]);\n\n    // Agent scores quality\n    const score = await ctx.task(agentScoringTask, {\n      tests, impl, coverage, lint, security\n    });\n\n    quality = score.overall;\n    ctx.log(`Iteration ${iteration}: ${quality}/${targetQuality}`);\n  }\n\n  return { converged: quality >= targetQuality, iterations: iteration };\n}\n```\n\n### Task Types in Processes\n\n| Task | Definition | Example Use |\n|------|------------|-------------|\n| `ctx.task(task, args)` | Execute a defined task | Run build, tests, agents |\n| `ctx.breakpoint(opts)` | Wait for human approval | Review plan, approve deploy |\n| `ctx.parallel.all([...])` | Run tasks concurrently | Multiple quality checks |\n| `ctx.hook(name, data)` | Trigger custom hooks | Notifications, integrations |\n\n---\n\n## Common Use Cases\n\n### 1. TDD Development with Quality Gates\n\n```\nUse the babysitter skill to build a REST API with:\n- Test-driven development\n- Quality score target of 85%\n- Breakpoint approval before merging\n```\n\n**What happens:**\n- Research phase → specifications → implementation plan\n- Write tests first, then implementation\n- Agent scores quality after each iteration\n- Continue refining until quality target met\n- Human approval before final merge\n\n### 2. Multi-Phase Build Pipeline\n\n```\nUse babysitter to set up a build pipeline that:\n1. Runs linting and type checking\n2. Executes unit tests in parallel\n3. Generates coverage report\n4. Requires approval for deployment\n```\n\n**What happens:**\n- Tasks run in sequence or parallel as specified\n- Breakpoint pauses for human approval\n- All results tracked in event-sourced journal\n\n### 3. Iterative Code Review\n\n```\nUse the babysitter skill to review and improve the authentication module:\n- Check for security issues\n- Analyze code quality\n- Suggest and apply improvements\n- Iterate until quality score > 90\n```\n\n**What happens:**\n- Initial analysis via agent task\n- Improvement suggestions generated\n- Changes applied and re-scored\n- Loop continues until target met\n\n### 4. Planning → Implementation → Verification\n\n```\nUse babysitter to implement a new feature:\n1. Research existing patterns\n2. Create detailed specifications  \n3. Plan implementation components\n4. Implement with TDD\n5. Verify and document\n```\n\n**What happens:**\n- Each phase builds on the previous\n- Breakpoints for approval at key decisions\n- Full traceability via journal events\n\n---\n\n## Methodologies\n\n### TDD Quality Convergence\n\nThe recommended methodology for feature development:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Research → Specs → Plan → TDD Loop → Verify → Complete    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Phases:**\n1. **Research** - Analyze codebase, identify patterns\n2. **Specifications** - Define requirements, acceptance criteria\n3. **Planning** - Break into components, define implementation order\n4. **TDD Implementation** - For each component:\n   - Write tests first\n   - Implement to pass tests\n   - Score quality\n   - Iterate if below target\n5. **Verification** - Final quality check\n6. **Completion** - Merge and document\n\n### Iterative Refinement\n\nWhen you need to improve existing code:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Analyze → Score → Improve → Re-score → Repeat until done  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Use for:**\n- Code quality improvements\n- Refactoring with safety nets\n- Performance optimization\n- Security hardening\n\n### Human-in-the-Loop Workflows\n\nWhen human judgment is required:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Prepare → Breakpoint (wait) → Approved → Continue         │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Breakpoint scenarios:**\n- Production deployment approval\n- Major architectural decisions\n- Security-sensitive changes\n- External integrations\n\n---\n\n## Example Workflows\n\n### Example 1: Build a Todo App\n\n```\nUse the babysitter skill to build a complete todo app with:\n- Next.js frontend\n- SQLite database with Drizzle ORM\n- Full CRUD operations\n- TDD with 85% quality target\n```\n\n### Example 2: Add Authentication\n\n```\nUse babysitter to add user authentication:\n- JWT-based auth\n- Login/register/logout endpoints\n- Protected routes\n- Test coverage for auth flows\n```\n\n### Example 3: Refactor Module\n\n```\nUse the babysitter skill to refactor the payment module:\n- Improve error handling\n- Add input validation\n- Increase test coverage to 90%\n- Document public APIs\n```\n\n### Example 4: Security Audit\n\n```\nUse babysitter to audit the codebase for security issues:\n- Check for common vulnerabilities\n- Validate input sanitization\n- Review authentication flows\n- Create remediation plan with breakpoint approval\n```\n\n---\n\n## Task Types\n\nBabysitter supports different task types for different needs:\n\n| Type | Use Case | Example |\n|------|----------|---------|\n| **Agent** | LLM-powered tasks | Planning, scoring, review |\n| **Skill** | Claude Code skills | Code analysis, refactoring |\n| **Breakpoint** | Human approval | Deployment gates, decisions |\n| **Node** | Scripts | Build, test, deploy |\n| **Shell** | Commands | File operations, git |\n\n---\n\n## Resuming Work\n\nIf a session ends or you need to continue later:\n\n```\nResume the babysitter run for the todo app\n```\n\nClaude will:\n1. Find the existing run\n2. Check current state\n3. Continue from where it left off\n\nAll progress is preserved in the event-sourced journal.\n\n---\n\n## Best Practices\n\n### 1. Be Specific About Quality Targets\n\n```\n✅ \"85% quality score with TDD\"\n❌ \"make it good\"\n```\n\n### 2. Use Breakpoints for Important Decisions\n\n```\n✅ \"Add breakpoint approval before deploying\"\n❌ \"Just deploy when done\"\n```\n\n### 3. Define Clear Phases\n\n```\n✅ \"Research, then plan, then implement\"\n❌ \"Build everything\"\n```\n\n### 4. Set Iteration Limits\n\n```\n✅ \"Max 10 iterations, target 90% quality\"\n❌ \"Keep improving forever\"\n```\n\n---\n\n## Performance Expectations\n\nUnderstanding performance characteristics helps set realistic expectations for your workflows.\n\n### Typical Execution Times\n\n| Workflow Type | Size | Expected Duration | Notes |\n|--------------|------|-------------------|-------|\n| **Simple Build & Test** | Small | 30s - 2m | Single iteration, no agents |\n| **TDD Feature** | Medium | 3m - 10m | 2-3 iterations with quality checks |\n| **Complex Refactoring** | Large | 10m - 30m | 5+ iterations, extensive testing |\n| **Full Application** | X-Large | 30m - 2h | Multiple phases, breakpoints |\n\n### Performance Factors\n\n**What affects execution time:**\n1. **LLM API latency** - Agent tasks require API calls (typically 2-5s per call)\n2. **Iteration count** - More iterations = longer runtime (quality convergence)\n3. **Parallel tasks** - Up to 4x speedup for independent quality checks\n4. **Task complexity** - Large codebases take longer to analyze\n5. **Breakpoint delays** - Human approval time is not counted\n\n### Optimization Strategies\n\n**Speed up your workflows:**\n\n1. **Use parallel execution** for independent tasks:\n   ```javascript\n   // Slow: Sequential (15s total)\n   await ctx.task(lintTask, {});\n   await ctx.task(testTask, {});\n   await ctx.task(securityTask, {});\n\n   // Fast: Parallel (5s total)\n   await ctx.parallel.all([\n     () => ctx.task(lintTask, {}),\n     () => ctx.task(testTask, {}),\n     () => ctx.task(securityTask, {})\n   ]);\n   ```\n\n2. **Set iteration limits** to prevent runaway loops:\n   ```\n   Use babysitter with max 3 iterations for faster results\n   ```\n\n3. **Scope down agent tasks** - Smaller context = faster responses:\n   ```javascript\n   // Instead of analyzing entire codebase\n   const analysis = await ctx.task(analyzeTask, { files: ['auth.js'] });\n   ```\n\n4. **Cache research results** - Reuse between iterations when possible\n\n### Resource Usage\n\n| Resource | Light Usage | Heavy Usage | Limits |\n|----------|------------|-------------|--------|\n| **Disk Space** | 1-5 MB/run | 50-100 MB/run | Clean old runs |\n| **Memory** | 100-200 MB | 500 MB - 1 GB | Node.js heap |\n| **Network** | Agent calls only | Continuous API usage | Rate limits |\n| **CPU** | Minimal | Test/build tasks | Process-dependent |\n\n**Monitoring disk usage:**\n```bash\n# Check total .a5c size\ndu -sh .a5c/\n\n# List runs by size\ndu -h .a5c/runs/* | sort -h\n\n# Clean old runs (optional)\nrm -rf .a5c/runs/<old-run-id>\n```\n\n### Scalability Considerations\n\n**Small projects (< 100 files):**\n- Excellent performance\n- Full codebase analysis feasible\n- Multiple parallel runs possible\n\n**Medium projects (100-1000 files):**\n- Good performance\n- Scope agent tasks to relevant files\n- One run at a time recommended\n\n**Large projects (1000+ files):**\n- May need optimization\n- Always scope agent tasks\n- Consider splitting into sub-projects\n- Monitor journal size (should stay < 10 MB)\n\n---\n\n## Security Best Practices\n\nBabysitter handles code and credentials - follow these security guidelines for production use.\n\n### General Security\n\n**DO:**\n- Review all code changes before final approval\n- Use breakpoints before deploying to production\n- Keep `.a5c/` directories out of version control (add to `.gitignore`)\n- Regularly update to latest versions\n- Run with least privilege necessary\n\n**DON'T:**\n- Commit `.a5c/` directories with sensitive data\n- Run untrusted process definitions without review\n- Expose breakpoints service publicly without authentication\n- Store credentials in journal files\n\n### Breakpoints Service Security\n\nThe breakpoints service requires external access - secure it properly:\n\n**Production Setup:**\n\n1. **Use HTTPS with ngrok/tunneling:**\n   ```bash\n   # Bad: HTTP exposed publicly\n   ngrok http 3184\n\n   # Better: Use authentication\n   ngrok http 3184 --basic-auth \"user:secure-password\"\n   ```\n\n2. **Or use Telegram notifications:**\n   - No public endpoint needed\n   - Notifications via Telegram bot\n   - Configure in breakpoints UI\n   - More secure for production\n\n3. **Firewall rules:**\n   - Restrict access to known IPs\n   - Use VPN for team access\n   - Don't expose to 0.0.0.0 in production\n\n**Example production setup:**\n```bash\n# Start with localhost only\nnpx -y @a5c-ai/babysitter-breakpoints@latest start --host 127.0.0.1\n\n# Use SSH tunnel for remote access\nssh -L 3184:localhost:3184 production-server\n\n# Or use Telegram (recommended)\n# Configure in UI at http://localhost:3184\n```\n\n### Credential Management\n\n**Handling secrets in workflows:**\n\n1. **Environment variables** (recommended):\n   ```javascript\n   // In process definition\n   const apiKey = process.env.API_KEY;\n   await ctx.task(deployTask, { apiKey });\n   ```\n\n2. **Never hardcode credentials:**\n   ```javascript\n   // BAD - Don't do this!\n   const apiKey = \"sk-1234567890abcdef\";\n\n   // GOOD - Use environment variables\n   const apiKey = process.env.API_KEY;\n   ```\n\n3. **Use breakpoints for sensitive operations:**\n   ```javascript\n   await ctx.breakpoint({\n     question: 'Deploy with production credentials?',\n     title: 'Production Deployment',\n     context: { environment: 'production', critical: true }\n   });\n   ```\n\n4. **Review journal files** before sharing:\n   ```bash\n   # Check for leaked secrets\n   grep -i \"password\\|secret\\|key\\|token\" .a5c/runs/*/journal/journal.jsonl\n   ```\n\n### Code Review Security\n\n**Before approving breakpoints:**\n\n1. **Review generated code** for security issues:\n   - SQL injection vulnerabilities\n   - XSS vulnerabilities\n   - Insecure dependencies\n   - Hardcoded secrets\n\n2. **Check test coverage** for security tests:\n   - Authentication tests\n   - Authorization tests\n   - Input validation tests\n   - Error handling tests\n\n3. **Run security scans** before approval:\n   ```javascript\n   const security = await ctx.task(securityScanTask, {\n     tools: ['npm audit', 'eslint-plugin-security']\n   });\n   ```\n\n### Network Security\n\n**For distributed teams:**\n\n1. **Use VPN** for breakpoints service access\n2. **Implement authentication** on breakpoints UI\n3. **Use HTTPS** for all external connections\n4. **Audit access logs** regularly\n\n### Compliance Considerations\n\n**For regulated environments:**\n\n- **Audit trail**: Journal provides complete event history\n- **Approval gates**: Breakpoints create approval records\n- **Access control**: Limit who can approve production deployments\n- **Data retention**: Define policy for old run cleanup\n- **Encryption**: Encrypt `.a5c/` directories if needed\n\n---\n\n## Monitoring and Observability\n\nTrack the health and performance of your Babysitter workflows.\n\n### Built-in Monitoring\n\n**Journal Events:**\n\nEvery action is logged in the journal. Monitor key events:\n\n```bash\n# Watch run progress in real-time\ntail -f .a5c/runs/<runId>/journal/journal.jsonl | jq .\n\n# Count iterations\njq 'select(.type==\"ITERATION_STARTED\")' .a5c/runs/*/journal/journal.jsonl | wc -l\n\n# Track quality scores\njq 'select(.type==\"QUALITY_SCORE\") | .score' .a5c/runs/*/journal/journal.jsonl\n\n# Find failed tasks\njq 'select(.type==\"TASK_FAILED\")' .a5c/runs/*/journal/journal.jsonl\n```\n\n**State Inspection:**\n\n```bash\n# Check current run state\ncat .a5c/runs/<runId>/state.json | jq .\n\n# View task results\nls -la .a5c/runs/<runId>/tasks/\n\n# Check run status\njq '.status' .a5c/runs/<runId>/state.json\n```\n\n### Key Metrics to Track\n\n| Metric | How to Measure | Target |\n|--------|---------------|--------|\n| **Success Rate** | Completed / Total runs | > 90% |\n| **Avg Iterations** | Iterations per run | 2-3 for TDD |\n| **Quality Score** | Final quality score | > 85 |\n| **Duration** | Run completion time | < 10m typical |\n| **Error Rate** | Failed tasks / Total | < 5% |\n\n### Breakpoints Service Monitoring\n\n**Health check:**\n```bash\n# Check if service is running\ncurl http://localhost:3184/health\n\n# Expected response\n{\"status\":\"ok\",\"uptime\":12345}\n```\n\n**Breakpoint metrics:**\n```bash\n# Check breakpoints UI\nopen http://localhost:3184\n\n# Monitor pending breakpoints\ncurl http://localhost:3184/api/breakpoints | jq '.[] | select(.status==\"pending\")'\n```\n\n### Custom Logging\n\n**Add logging to process definitions:**\n\n```javascript\nexport async function process(inputs, ctx) {\n  ctx.log('Starting workflow', { inputs });\n\n  const start = Date.now();\n  const result = await ctx.task(someTask, {});\n  const duration = Date.now() - start;\n\n  ctx.log('Task completed', { duration, result });\n\n  return result;\n}\n```\n\n### Integration with External Monitoring\n\n**Export metrics to monitoring systems:**\n\n```javascript\n// Example: Send metrics to Datadog/Prometheus\nexport async function process(inputs, ctx) {\n  const result = await ctx.task(buildTask, {});\n\n  // Hook to send metrics\n  await ctx.hook('metrics', {\n    metric: 'babysitter.build.duration',\n    value: result.duration,\n    tags: { status: result.success ? 'success' : 'failure' }\n  });\n\n  return result;\n}\n```\n\n### Alerts and Notifications\n\n**Set up alerts for critical events:**\n\n1. **Run failures:**\n   ```bash\n   # Example: Alert on failed runs\n   jq 'select(.type==\"RUN_FAILED\")' .a5c/runs/*/journal/journal.jsonl \\\n     | mail -s \"Babysitter Run Failed\" team@example.com\n   ```\n\n2. **Long-running workflows:**\n   ```bash\n   # Alert if run exceeds 30 minutes\n   find .a5c/runs -name state.json -mmin +30 \\\n     -exec jq 'select(.status==\"running\")' {} \\;\n   ```\n\n3. **Quality threshold breaches:**\n   ```javascript\n   const score = await ctx.task(qualityScoreTask, {});\n   if (score.overall < 70) {\n     await ctx.hook('alert', {\n       severity: 'warning',\n       message: `Quality below threshold: ${score.overall}/100`\n     });\n   }\n   ```\n\n### Debugging and Troubleshooting Monitoring\n\n**Enable verbose logging:**\n\n```bash\n# Set environment variable for detailed logs\nexport BABYSITTER_LOG_LEVEL=debug\nnpx -y @a5c-ai/babysitter-sdk@latest run <args>\n```\n\n**Trace specific runs:**\n\n```bash\n# Extract full timeline for a run\njq 'select(.runId==\"<runId>\") | {type, timestamp, taskId}' \\\n  .a5c/runs/*/journal/journal.jsonl\n```\n\n---\n\n## Troubleshooting\n\nThis section covers common errors with specific solutions.\n\n### Error: \"Run encountered an error\"\n\n**Symptom:**\n```\nError: Run encountered an error\n  at processIteration (process.js:123)\n  Caused by: Journal conflict detected\n```\n\n**Cause:** Journal write conflict from concurrent operations or corrupted state.\n\n**Solution:**\n```bash\n# 1. Check journal integrity\ncat .a5c/runs/<runId>/journal/journal.jsonl | jq empty\n\n# 2. If corrupted, Claude can analyze and recover\n```\nThen ask Claude:\n```\nAnalyze the babysitter run error for <runId> and try to recover\n```\n\n**Prevention:** Avoid running multiple babysitter instances in the same directory simultaneously.\n\n---\n\n### Error: \"Breakpoint not resolving\"\n\n**Symptom:**\n```\nWaiting for breakpoint approval...\nTimeout after 300s\nError: Breakpoint bp-001 timed out\n```\n\n**Cause:** Breakpoints service not running or not accessible.\n\n**Solution:**\n\n1. **Check service status:**\n   ```bash\n   curl http://localhost:3184/health\n   ```\n\n2. **Start service if not running:**\n   ```bash\n   npx -y @a5c-ai/babysitter-breakpoints@latest start\n   ```\n\n3. **Check ngrok tunnel (if using):**\n   ```bash\n   ngrok http 3184\n   # Note the public URL and verify access\n   ```\n\n4. **Verify breakpoint registration:**\n   ```bash\n   curl http://localhost:3184/api/breakpoints\n   ```\n\n**Prevention:** Start breakpoints service before running babysitter workflows.\n\n---\n\n### Error: \"Session ended unexpectedly\"\n\n**Symptom:**\n```\nClaude Code session terminated\nRun ID: 01KFFTSF8TK8C9GT3YM9QYQ6WG\nStatus: interrupted\n```\n\n**Cause:** Network issue, Claude Code crash, or manual exit.\n\n**Solution:**\n```\nResume the babysitter run 01KFFTSF8TK8C9GT3YM9QYQ6WG\n```\n\nClaude will:\n- Load state from journal\n- Continue from last completed task\n- Preserve all progress\n\n**Prevention:** Babysitter is designed to be resumable - interruptions are normal.\n\n---\n\n### Error: \"Task execution failed: ENOENT\"\n\n**Symptom:**\n```\nTask failed: test-task-001\nError: ENOENT: no such file or directory\n  at runTests (task.js:45)\n```\n\n**Cause:** Task trying to access non-existent file or command not found.\n\n**Solution:**\n\n1. **Check file paths in task definition:**\n   ```javascript\n   // Ensure paths are correct\n   const testPath = path.join(__dirname, 'tests', 'auth.test.js');\n   ```\n\n2. **Verify dependencies installed:**\n   ```bash\n   npm install\n   # or\n   npm install jest supertest\n   ```\n\n3. **Check task working directory:**\n   ```javascript\n   ctx.log('Current directory:', process.cwd());\n   ```\n\n---\n\n### Error: \"Quality score not improving\"\n\n**Symptom:**\n```\nIteration 5/5: Quality score 65/100\nTarget not met: 85/100\nRun completed with quality below target\n```\n\n**Cause:** Issues preventing quality improvement (failing tests, low coverage, linting errors).\n\n**Solution:**\n\n1. **Review iteration logs** to identify blocking issues:\n   ```bash\n   jq 'select(.type==\"TASK_COMPLETED\")' .a5c/runs/<runId>/journal/journal.jsonl\n   ```\n\n2. **Check specific quality metrics:**\n   - Test failures: `npm test`\n   - Coverage: `npm run coverage`\n   - Linting: `npm run lint`\n\n3. **Increase iteration limit:**\n   ```\n   Resume the run with max 10 iterations\n   ```\n\n4. **Lower quality target if unrealistic:**\n   ```\n   Use babysitter with 75% quality target instead\n   ```\n\n---\n\n### Error: \"Agent task timeout\"\n\n**Symptom:**\n```\nTask timeout: agent-task-planning-001\nExecution exceeded 120s\n```\n\n**Cause:** Agent task taking too long (large context, API issues, complex analysis).\n\n**Solution:**\n\n1. **Reduce agent task scope:**\n   ```javascript\n   // Instead of entire codebase\n   const analysis = await ctx.task(analyzeTask, {\n     files: ['src/auth.js'],  // Specific files only\n     maxDepth: 2\n   });\n   ```\n\n2. **Increase timeout (if necessary):**\n   ```javascript\n   await ctx.task(analyzeTask, { /* args */ }, {\n     timeout: 300000  // 5 minutes\n   });\n   ```\n\n3. **Check API status** if using external LLM providers.\n\n---\n\n### Error: \"Cannot find module '@a5c-ai/babysitter-sdk'\"\n\n**Symptom:**\n```\nError: Cannot find module '@a5c-ai/babysitter-sdk'\n  at require (internal/modules/cjs/loader.js:883)\n```\n\n**Cause:** SDK not installed or wrong version.\n\n**Solution:**\n```bash\n# Install globally\nnpm install -g @a5c-ai/babysitter-sdk\n\n# Or locally in project\nnpm install @a5c-ai/babysitter-sdk\n\n# Verify installation\nnpm list -g @a5c-ai/babysitter-sdk\n```\n\n---\n\n### Error: \"Plugin not found: babysitter@a5c.ai\"\n\n**Symptom:**\n```\nError: Plugin 'babysitter@a5c.ai' not found\nAvailable plugins: [...]\n```\n\n**Cause:** Plugin not installed in Claude Code.\n\n**Solution:**\n```bash\n# In Claude Code\n/plugin marketplace add a5c-ai/babysitter\n/plugin install babysitter@a5c.ai\n\n# Restart Claude Code\n```\n\n**Verification:**\n```bash\n# Check plugin list\n/plugins\n\n# Should see: babysitter@a5c.ai [active]\n```\n\n---\n\n### Performance Issues\n\n**Symptom:** Workflows running slower than expected.\n\n**Diagnosis:**\n\n1. **Check iteration count:**\n   ```bash\n   jq 'select(.type==\"ITERATION_STARTED\")' .a5c/runs/<runId>/journal/journal.jsonl | wc -l\n   ```\n\n2. **Identify slow tasks:**\n   ```bash\n   jq 'select(.type==\"TASK_COMPLETED\") | {taskId, duration}' \\\n     .a5c/runs/<runId>/journal/journal.jsonl | sort -k2 -n\n   ```\n\n3. **Review agent task complexity:**\n   - Large context sizes\n   - Unnecessary codebase analysis\n   - Sequential when parallel possible\n\n**Solutions:**\n- Use parallel execution for independent tasks\n- Reduce agent task scope\n- Set iteration limits\n- Increase quality threshold (lower target)\n\n---\n\n### Getting Additional Help\n\nIf issues persist:\n\n1. **Check journal for details:**\n   ```bash\n   cat .a5c/runs/<runId>/journal/journal.jsonl | jq .\n   ```\n\n2. **Ask Claude to analyze:**\n   ```\n   Analyze the babysitter run <runId> and diagnose the error\n   ```\n\n3. **Report bugs:**\n   - [GitHub Issues](https://github.com/a5c-ai/babysitter/issues)\n   - Include run ID, error message, and journal excerpt\n\n---\n\n## Architecture Overview\n\n### High-Level Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Claude Code Session                                        │\n│  ┌───────────────────────────────────────────────────────┐  │\n│  │  Babysitter Skill (orchestrates via CLI)              │  │\n│  └───────────────────────────────────────────────────────┘  │\n│                           │                                  │\n│                           ▼                                  │\n│  ┌───────────────────────────────────────────────────────┐  │\n│  │  .a5c/runs/<runId>/                                   │  │\n│  │  ├── journal.jsonl  (event log)                       │  │\n│  │  ├── state.json     (current state)                   │  │\n│  │  └── tasks/         (task artifacts)                  │  │\n│  └───────────────────────────────────────────────────────┘  │\n│                           │                                  │\n│                           ▼                                  │\n│  ┌───────────────────────────────────────────────────────┐  │\n│  │  Breakpoints Service (human approval)                 │  │\n│  └───────────────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Core Components\n\n#### 1. Babysitter Skill Plugin\n\n**Location:** `plugins/babysitter/skills/babysit/`\n\n**Responsibilities:**\n- Parses natural language commands into process inputs\n- Orchestrates the run loop via SDK CLI\n- Manages iteration lifecycle\n- Handles resumption from saved state\n- Reports progress to Claude Code\n\n**Technology:** Claude Code Plugin System (JavaScript)\n\n---\n\n#### 2. Babysitter SDK\n\n**Package:** `@a5c-ai/babysitter-sdk`\n\n**Core Modules:**\n\n| Module | Purpose | Key Functions |\n|--------|---------|--------------|\n| **Process Engine** | Executes process definitions | `runProcess()`, `iterate()` |\n| **Journal Manager** | Event-sourced persistence | `append()`, `replay()`, `getState()` |\n| **Task Executor** | Runs tasks (agent, skill, node) | `executeTask()`, `parallel.all()` |\n| **State Manager** | Maintains run state cache | `saveState()`, `loadState()` |\n| **Hook System** | Extensibility points | `registerHook()`, `trigger()` |\n\n**Technology:** Node.js, TypeScript\n\n---\n\n#### 3. Event-Sourced Journal\n\n**Format:** JSONL (JSON Lines) - one event per line\n\n**Event Types:**\n\n```typescript\ntype JournalEvent =\n  | { type: 'RUN_STARTED', runId: string, timestamp: string, inputs: any }\n  | { type: 'ITERATION_STARTED', iteration: number, timestamp: string }\n  | { type: 'TASK_STARTED', taskId: string, taskType: string, args: any }\n  | { type: 'TASK_COMPLETED', taskId: string, result: any, duration: number }\n  | { type: 'TASK_FAILED', taskId: string, error: string }\n  | { type: 'BREAKPOINT_REQUESTED', breakpointId: string, question: string }\n  | { type: 'BREAKPOINT_APPROVED', breakpointId: string, timestamp: string }\n  | { type: 'BREAKPOINT_REJECTED', breakpointId: string, reason: string }\n  | { type: 'QUALITY_SCORE', iteration: number, score: number, metrics: any }\n  | { type: 'RUN_COMPLETED', status: 'success' | 'failed', timestamp: string }\n  | { type: 'RUN_FAILED', error: string, timestamp: string }\n```\n\n**Benefits:**\n- **Deterministic replay**: Reconstruct exact state at any point\n- **Audit trail**: Complete history of all actions\n- **Debugging**: Trace execution flow and identify issues\n- **Resumability**: Continue from last event after interruption\n\n**Implementation:**\n```javascript\n// Append-only writes\nfunction appendEvent(event) {\n  fs.appendFileSync(journalPath, JSON.stringify(event) + '\\n');\n}\n\n// Replay to reconstruct state\nfunction replayJournal() {\n  const events = fs.readFileSync(journalPath, 'utf-8')\n    .split('\\n')\n    .filter(line => line.trim())\n    .map(line => JSON.parse(line));\n\n  return events.reduce(applyEvent, initialState);\n}\n```\n\n---\n\n#### 4. Process Definitions\n\n**Format:** JavaScript/TypeScript functions\n\n**Execution Model:**\n\n```\n┌──────────────────────────────────────────────────────────┐\n│ Process Definition (JavaScript)                          │\n│                                                          │\n│  export async function process(inputs, ctx) {           │\n│    // User-defined orchestration logic                  │\n│    const result = await ctx.task(someTask, args);       │\n│    await ctx.breakpoint({ question: '...' });           │\n│    return result;                                        │\n│  }                                                       │\n└──────────────────────────────────────────────────────────┘\n                          │\n                          ▼\n┌──────────────────────────────────────────────────────────┐\n│ Context API (ctx)                                        │\n│                                                          │\n│  - ctx.task(task, args, opts)       Execute task        │\n│  - ctx.breakpoint(opts)             Wait for approval   │\n│  - ctx.parallel.all([...])          Run in parallel     │\n│  - ctx.hook(name, data)             Trigger hooks       │\n│  - ctx.log(msg, data)               Log to journal      │\n│  - ctx.getState(key)                Access state        │\n│  - ctx.setState(key, value)         Update state        │\n└──────────────────────────────────────────────────────────┘\n```\n\n**Process Lifecycle:**\n\n1. **Load**: Process definition loaded from file or default\n2. **Initialize**: Context created with state and journal access\n3. **Execute**: Process function called with inputs and context\n4. **Iterate**: Process may loop internally or be called multiple times\n5. **Complete**: Process returns final result\n\n---\n\n#### 5. Task Execution System\n\n**Task Types:**\n\n| Type | Executor | Use Case | Example |\n|------|----------|----------|---------|\n| **Agent** | LLM API | Planning, analysis, scoring | GPT-4, Claude |\n| **Skill** | Claude Code | Code operations | Refactoring, search |\n| **Node** | Node.js | Scripts and tools | Build, test, deploy |\n| **Shell** | System shell | Commands | git, npm, docker |\n| **Breakpoint** | Breakpoints service | Human approval | Review, approve |\n\n**Execution Flow:**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│ Task Request                                            │\n│ ctx.task(taskDef, args, opts)                           │\n└────────────────┬────────────────────────────────────────┘\n                 │\n                 ▼\n┌─────────────────────────────────────────────────────────┐\n│ Task Validation                                         │\n│ - Validate arguments                                    │\n│ - Check dependencies                                    │\n│ - Generate task ID                                      │\n└────────────────┬────────────────────────────────────────┘\n                 │\n                 ▼\n┌─────────────────────────────────────────────────────────┐\n│ Journal Event: TASK_STARTED                             │\n└────────────────┬────────────────────────────────────────┘\n                 │\n                 ▼\n┌─────────────────────────────────────────────────────────┐\n│ Execute Task                                            │\n│ - Agent: Call LLM API                                   │\n│ - Skill: Invoke Claude Code skill                       │\n│ - Node: Run JavaScript function                         │\n│ - Shell: Execute command                                │\n│ - Breakpoint: Wait for approval                         │\n└────────────────┬────────────────────────────────────────┘\n                 │\n                 ▼\n┌─────────────────────────────────────────────────────────┐\n│ Journal Event: TASK_COMPLETED or TASK_FAILED            │\n└────────────────┬────────────────────────────────────────┘\n                 │\n                 ▼\n┌─────────────────────────────────────────────────────────┐\n│ Return Result                                           │\n│ - Success: Return task output                           │\n│ - Failure: Throw error or return error object           │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Parallel Execution:**\n\n```javascript\n// Tasks run concurrently with Promise.all\nawait ctx.parallel.all([\n  () => ctx.task(task1, args1),\n  () => ctx.task(task2, args2),\n  () => ctx.task(task3, args3)\n]);\n\n// All results returned when all complete\n// If any fails, entire parallel group fails\n```\n\n---\n\n#### 6. Breakpoints Service\n\n**Package:** `@a5c-ai/babysitter-breakpoints`\n\n**Architecture:**\n\n```\n┌────────────────────────────────────────────────────────┐\n│ Web UI (http://localhost:3184)                         │\n│ - View pending breakpoints                             │\n│ - Approve/reject with comments                         │\n│ - Review context and history                           │\n└────────────────┬───────────────────────────────────────┘\n                 │\n                 ▼\n┌────────────────────────────────────────────────────────┐\n│ REST API                                               │\n│ - POST /api/breakpoints      Create breakpoint         │\n│ - GET /api/breakpoints       List breakpoints          │\n│ - POST /api/breakpoints/:id  Approve/reject            │\n│ - GET /health                Health check              │\n└────────────────┬───────────────────────────────────────┘\n                 │\n                 ▼\n┌────────────────────────────────────────────────────────┐\n│ In-Memory State                                        │\n│ - Active breakpoints                                   │\n│ - Pending approvals                                    │\n│ - Response handlers                                    │\n└────────────────┬───────────────────────────────────────┘\n                 │\n                 ▼\n┌────────────────────────────────────────────────────────┐\n│ Notification Integrations (Optional)                   │\n│ - Telegram bot                                         │\n│ - Email                                                │\n│ - Slack (future)                                       │\n└────────────────────────────────────────────────────────┘\n```\n\n**Communication Flow:**\n\n1. **Request**: Task executor creates breakpoint via POST\n2. **Poll**: Task executor polls for response (long-polling)\n3. **Notify**: Service sends notification (Telegram/email)\n4. **Review**: Human reviews context in UI\n5. **Respond**: Human approves/rejects\n6. **Resume**: Task executor receives response, continues\n\n**Technology:** Node.js, Express, WebSockets (optional)\n\n---\n\n### Data Flow\n\n**Complete Request Flow:**\n\n```\n1. User Command\n   │\n   └──> Claude Code\n        │\n        └──> Babysitter Skill\n             │\n             ├──> Parse intent\n             ├──> Load/create run\n             └──> CLI: npx -y @a5c-ai/babysitter-sdk@latest run:iterate\n                  │\n                  └──> SDK Process Engine\n                       │\n                       ├──> Load process definition\n                       ├──> Replay journal → restore state\n                       ├──> Execute process function\n                       │    │\n                       │    ├──> ctx.task() → Execute tasks\n                       │    │    │\n                       │    │    ├──> Append TASK_STARTED\n                       │    │    ├──> Run executor (agent/skill/node/shell)\n                       │    │    └──> Append TASK_COMPLETED\n                       │    │\n                       │    └──> ctx.breakpoint() → Wait for approval\n                       │         │\n                       │         ├──> POST to breakpoints service\n                       │         ├──> Append BREAKPOINT_REQUESTED\n                       │         ├──> Poll for response\n                       │         └──> Append BREAKPOINT_APPROVED\n                       │\n                       ├──> Append iteration events to journal\n                       ├──> Save state cache\n                       └──> Return results to skill\n                            │\n                            └──> Report to Claude Code\n                                 │\n                                 └──> Display to user\n```\n\n---\n\n### State Management\n\n**Two-Layer State System:**\n\n1. **Journal (source of truth)**:\n   - Append-only event log\n   - Immutable history\n   - Replayed to reconstruct state\n\n2. **State Cache (performance)**:\n   - Snapshot of current state\n   - Rebuilt from journal if missing\n   - Fast access without replay\n\n**State Structure:**\n\n```typescript\ninterface RunState {\n  runId: string;\n  status: 'running' | 'paused' | 'completed' | 'failed';\n  iteration: number;\n  inputs: any;\n  outputs?: any;\n  processState: Map<string, any>;  // Process-specific state\n  taskResults: Map<string, any>;    // Cached task results\n  metrics: {\n    startTime: number;\n    endTime?: number;\n    iterations: number;\n    qualityScores: number[];\n  };\n}\n```\n\n---\n\n### Extensibility\n\n**Hook System:**\n\n```javascript\n// Register custom hooks\nctx.hook('task:completed', async (taskResult) => {\n  await sendMetricsToDatadog(taskResult);\n});\n\nctx.hook('quality:score', async (score) => {\n  if (score < 70) {\n    await sendAlert('Low quality score');\n  }\n});\n\n// Built-in hook points\n- 'run:started'\n- 'run:completed'\n- 'iteration:started'\n- 'iteration:completed'\n- 'task:started'\n- 'task:completed'\n- 'breakpoint:requested'\n- 'breakpoint:resolved'\n- 'quality:score'\n```\n\n**Custom Task Types:**\n\n```javascript\n// Define custom task executor\nfunction registerCustomTask(type, executor) {\n  taskExecutors.set(type, executor);\n}\n\n// Use custom task\nawait ctx.task({ type: 'custom', fn: myExecutor }, args);\n```\n\n---\n\n### Technology Stack\n\n| Component | Technology | Purpose |\n|-----------|-----------|---------|\n| **Plugin** | JavaScript | Claude Code integration |\n| **SDK** | TypeScript + Node.js | Core orchestration engine |\n| **Process Definitions** | JavaScript/TypeScript | User workflow logic |\n| **Journal** | JSONL (text files) | Event persistence |\n| **Breakpoints Service** | Node.js + Express | Human approval UI/API |\n| **CLI** | Commander.js | Command-line interface |\n\n---\n\n### Design Patterns\n\n**Event Sourcing:**\n- All state changes recorded as events\n- State derived from event replay\n- Time-travel debugging possible\n\n**Command Query Responsibility Segregation (CQRS):**\n- Write: Append events to journal\n- Read: Query state cache or replay\n\n**Saga Pattern:**\n- Long-running workflows with compensation\n- Breakpoints as decision points\n- Resumable across sessions\n\n**Plugin Architecture:**\n- Extensible via hooks\n- Custom task types\n- Process definitions as plugins\n\n---\n\n## Limitations and Known Issues\n\n### Current Limitations\n\n1. **Windows Support**: Some shell commands may require WSL or Git Bash on Windows systems\n2. **Concurrent Runs**: Running multiple babysitter processes simultaneously in the same directory may cause journal conflicts\n3. **Large Codebases**: Performance may degrade with very large repositories (>100k files)\n4. **Network Dependency**: Breakpoints require the breakpoints service to be running and accessible\n5. **LLM Token Limits**: Very large task outputs may exceed context window limits\n\n### Known Issues\n\n- **Journal Conflicts**: In rare cases, concurrent writes to the journal may cause corruption. Use the resume command to recover.\n- **Breakpoint Timeout**: Breakpoints may timeout if the service is not properly configured or accessible\n- **State Serialization**: Some complex objects may not serialize properly in the state cache\n\nFor the latest issues and workarounds, see our [GitHub Issues](https://github.com/a5c-ai/babysitter/issues).\n\n---\n\n## FAQ\n\n### General Questions\n\n**Q: What is the difference between Babysitter and regular Claude Code?**\nA: Babysitter adds orchestration capabilities to Claude Code, enabling deterministic workflows, quality convergence loops, human approval gates, and resumable sessions with full audit trails.\n\n**Q: Do I need to know programming to use Babysitter?**\nA: No. You interact with Babysitter using natural language. Just ask Claude to use the babysitter skill with your requirements.\n\n**Q: Can I use Babysitter with other AI tools?**\nA: Babysitter is specifically designed for Claude Code, but the underlying orchestration concepts could be adapted for other systems.\n\n### Installation and Setup\n\n**Q: Why do I need the breakpoints service?**\nA: The breakpoints service provides a UI for human-in-the-loop approval. Without it, breakpoints will fail. You can expose it via ngrok or configure Telegram notifications.\n\n**Q: Can I run babysitter offline?**\nA: Yes, but breakpoints require network access to the breakpoints service. All other features work offline.\n\n**Q: How much disk space does babysitter use?**\nA: The `.a5c/runs/` directory stores all run data. A typical run uses 1-10MB. You can safely delete old runs to reclaim space.\n\n### Usage Questions\n\n**Q: How do I pause a babysitter run?**\nA: Simply close Claude Code. The run is automatically saved and can be resumed later with the resume command.\n\n**Q: Can I edit the process definition for a running workflow?**\nA: No. Process definitions are fixed when a run starts. You can create a new run with a different process.\n\n**Q: How do I debug a failed run?**\nA: Check the journal at `.a5c/runs/<runId>/journal/journal.jsonl` for the full event history. Ask Claude to analyze it.\n\n**Q: Can I run multiple tasks in parallel?**\nA: Yes. Use `ctx.parallel.all([...])` in your process definition to run independent tasks concurrently.\n\n### Quality and Testing\n\n**Q: What is a quality score?**\nA: Quality scores are LLM-generated assessments of code quality based on tests, coverage, linting, security, and other metrics you define.\n\n**Q: How do I set a quality target?**\nA: Include it in your prompt: \"Use babysitter with TDD and 85% quality target\"\n\n**Q: Can I customize quality scoring?**\nA: Yes. You can define custom agent tasks that score based on your specific criteria.\n\n---\n\n## Contributing\n\nWe welcome contributions from the community! Here's how you can help:\n\n### Ways to Contribute\n\n- **Report bugs**: Open an issue on [GitHub](https://github.com/a5c-ai/babysitter/issues)\n- **Suggest features**: Share your ideas for improvements\n- **Submit pull requests**: Fix bugs or add features\n- **Improve documentation**: Help make our docs clearer\n- **Share examples**: Contribute example workflows and processes\n\n### Development Setup\n\n1. Fork the repository on GitHub\n2. Clone your fork locally\n3. Install dependencies: `npm install`\n4. Make your changes\n5. Test thoroughly\n6. Submit a pull request\n\n### Contribution Guidelines\n\n- Follow existing code style and conventions\n- Write clear commit messages\n- Add tests for new features\n- Update documentation as needed\n- Be respectful and collaborative\n\nFor detailed guidelines, see [CONTRIBUTING.md](https://github.com/a5c-ai/babysitter/blob/main/CONTRIBUTING.md) (if available).\n\n---\n\n## Community and Support\n\n### Get Help\n\n- **GitHub Issues**: [Report bugs or request features](https://github.com/a5c-ai/babysitter/issues)\n- **GitHub Discussions**: [Ask questions and share ideas](https://github.com/a5c-ai/babysitter/discussions)\n- **Documentation**: [Full specification and guides](https://github.com/a5c-ai/babysitter)\n\n### Stay Connected\n\n- **GitHub**: [github.com/a5c-ai/babysitter](https://github.com/a5c-ai/babysitter)\n- **npm**: [@a5c-ai/babysitter-sdk](https://www.npmjs.com/package/@a5c-ai/babysitter-sdk)\n\n### Code of Conduct\n\nWe are committed to providing a welcoming and inclusive environment. Please be respectful, professional, and considerate in all interactions.\n\n---\n\n## License\n\nThis project is licensed under the **MIT License**.\n\n```\nMIT License\n\nCopyright (c) 2025 A5C AI\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```\n\nSee [LICENSE](https://github.com/a5c-ai/babysitter/blob/main/LICENSE) for full details.\n\n---\n\n## Further Reading\n\n### Internal Documentation\n\n- `plugins/babysitter/skills/babysit/SKILL.md` - Detailed skill reference\n- `plugins/babysitter/skills/babysit/process/` - Example processes\n- `plugins/babysitter/BABYSITTER_PLUGIN_SPECIFICATION.md` - Full specification\n\n### External Resources\n\n- [Claude Code Documentation](https://claude.com/claude-code)\n- [Event Sourcing Pattern](https://martinfowler.com/eaaDev/EventSourcing.html)\n- [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development)\n\n---\n\n<div align=\"center\">\n\n**Built with Claude by A5C AI**\n\n[⬆ Back to Top](#babysitter)\n\n</div>\n",
        "plugins/babysitter/README.md": "# Babysitter Plugin for Claude Code\n\n> **Orchestrate complex, multi-step workflows with event-sourced state management, hook-based extensibility, and human-in-the-loop approval.**\n\nThe Babysitter plugin enables Claude Code to manage sophisticated development workflows through deterministic, resumable orchestration. Built on the `@a5c-ai/babysitter-sdk`, it provides event-sourced state management, native hooks, and composable process definitions.\n\n---\n\n## 🎯 What is Babysitter?\n\nBabysitter orchestrates `.a5c/runs/<runId>/` directories through iterative execution:\n\n- **Event-sourced state** - All changes recorded as immutable events in `journal.jsonl`\n- **Resumable workflows** - Pause and resume at any point\n- **Hook-driven architecture** - Extensible lifecycle hooks at every step\n- **Human-in-the-loop** - Approval gates via breakpoints\n- **Multi-task orchestration** - Node scripts, LLM agents, Claude skills, breakpoints, sleep gates\n- **Parallel execution** - Run independent tasks concurrently\n\n**Use cases:**\n- TDD workflows with quality convergence\n- Multi-phase build/test/deploy pipelines\n- Code review with agent scoring\n- Iterative refinement until quality targets met\n- Complex planning → execution → verification workflows\n\n---\n\n## 🚀 Quick Start\n\n### 1. Installation\n\n#### Prerequisites\n\n- **Claude Code CLI** installed and configured\n- **Node.js** v18+ and npm (for SDK CLI)\n- Git (for cloning plugin repositories)\n\n#### Install the Plugin\n\n**Option A: Via Claude Code Marketplace (Recommended)**\n\nInstall from the marketplace:\n\n```bash\n# Add the plugin repository to marketplace\n/plugin marketplace add a5c-ai/babysitter\n\n# Install the plugin\n/plugin install babysitter@a5c.ai\n```\n\nThen:\n1. Restart Claude Code if prompted\n2. Verify installation with `/skills` - you should see \"babysitter\" in the list\n\n**Option B: Manual Installation**\n\n```bash\n# Clone the plugin repository\ngit clone https://github.com/a5c-ai/babysitter.git ~/.claude/plugins/babysitter\n\n# Or if you already have it in your project\ncp -r plugins/babysitter ~/.claude/plugins/\n\n# Verify installation\nls ~/.claude/plugins/babysitter/\n```\n\n**Option C: Project-Local Installation**\n\nFor project-specific plugin usage:\n\n```bash\n# Create plugin directory in your project\nmkdir -p .claude/plugins\n\n# Copy or clone the plugin\ngit clone https://github.com/a5c-ai/babysitter.git .claude/plugins/babysitter\n\n# Claude Code will automatically detect plugins in .claude/plugins/\n```\n\n#### Install the SDK CLI\n\nThe Babysitter SDK CLI is used for orchestration:\n\n```bash\n# Install globally (recommended)\nnpm install -g @a5c-ai/babysitter-sdk@latest\n\n# Or use npx (no installation required)\nnpx -y @a5c-ai/babysitter-sdk@latest --version\n\n# Set up CLI alias for convenience\necho 'alias babysitter=\"npx -y @a5c-ai/babysitter-sdk@latest\"' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n#### Verify Installation\n\n```bash\n# Verify plugin is loaded\n# In Claude Code, type:\n/skills\n\n# You should see \"babysitter\" in the list\n\n# Verify SDK CLI\nnpx -y @a5c-ai/babysitter-sdk@latest --version\n\n# Test the babysitter skill\n# In Claude Code, ask:\n# \"Use the babysitter skill to show me the available commands\"\n```\n\n#### Configuration (Optional)\n\n**Claude Code Settings**\n\nConfigure plugin behavior in `.claude/settings.json` or `.claude/settings.local.json`:\n\n```json\n{\n  \"plugins\": {\n    \"babysitter\": {\n      \"enabled\": true,\n      \"defaultRunsDir\": \".a5c/runs\",\n      \"autoNodeMaxTasks\": 10\n    }\n  }\n}\n```\n\n**Environment Variables**\n\n```bash\n# Default runs directory\nexport BABYSITTER_RUNS_DIR=\".a5c/runs\"\n\n# Enable verbose logging\nexport BABYSITTER_LOG_LEVEL=\"debug\"\n\n# Allow secret logs (use with caution)\nexport BABYSITTER_ALLOW_SECRET_LOGS=\"false\"\n```\n\n**Hook Configuration**\n\nEnable custom hooks by creating hook directories:\n\n```bash\n# Per-project hooks\nmkdir -p .a5c/hooks/on-run-start\nmkdir -p .a5c/hooks/on-breakpoint\n\n# Per-user hooks\nmkdir -p ~/.config/babysitter/hooks/on-run-start\nmkdir -p ~/.config/babysitter/hooks/on-breakpoint\n```\n\n### 2. Create Your First Run\n\n```bash\n# Create a run with example process\n$CLI run:create \\\n  --process-id babysitter/tdd-quality-convergence \\\n  --entry .claude/skills/babysit/process/tdd-quality-convergence.js#process \\\n  --inputs .claude/skills/babysit/process/examples/tdd-quality-convergence-example.json\n```\n\n### 3. Drive Orchestration\n\n```bash\n# Run a single iteration (repeat in a loop)\n$CLI run:iterate .a5c/runs/<runId> --json --iteration 1\n```\n\n### 4. Use with Claude Code\n\n**Via Skills (Recommended)**\n\nJust ask Claude to use the babysitter skill:\n\n```\nUse the babysitter skill to implement user authentication with TDD,\ntargeting 90% quality score with iterative refinement.\n```\n\nClaude will:\n1. Analyze your request\n2. Create a process definition\n3. Request approval via breakpoint\n4. Orchestrate execution step-by-step\n5. Handle quality convergence automatically\n\n**Via Commands**\n\nUse Claude Code commands for specific actions:\n\n```bash\n# Create a new babysitter run\n/babysitter:babysit \"Implement user authentication\"\n\n# Resume an existing run\n/babysitter:babysit resume run-20260120-auth\n```\n\n**Check Available Skills**\n\n```bash\n# List all loaded skills\n/skills\n\n# Should show:\n# - babysitter\n# - babysitter-breakpoint (deprecated, now integrated)\n# - babysitter-score\n```\n\n**Example Prompts**\n\n- \"Use babysitter to implement feature X with TDD and quality gates\"\n- \"Create a babysitter run for a multi-phase deployment pipeline\"\n- \"Resume babysitter run run-20260120-xyz and continue execution\"\n- \"Use babysitter to set up an iterative code review workflow\"\n\n---\n\n## 📚 Core Concepts\n\n### Runs\n\nA **run** is a directory under `.a5c/runs/<runId>/` containing:\n\n```\n.a5c/runs/<runId>/\n├── run.json           # Run metadata\n├── inputs.json        # Process inputs\n├── journal.jsonl      # Event log (append-only)\n├── state.json         # Current state cache\n├── code/              # Process implementation\n│   └── main.js        # Process entry point\n├── tasks/             # Task execution artifacts\n│   └── <effectId>/\n│       ├── input.json\n│       ├── result.json\n│       ├── stdout.log\n│       └── stderr.log\n└── artifacts/         # Human-readable outputs\n    └── *.md\n```\n\n### Processes\n\nA **process** is a JavaScript function that orchestrates tasks:\n\n```javascript\nexport async function process(inputs, ctx) {\n  // Phase 1: Build\n  const buildResult = await ctx.task(buildTask, { command: 'npm run build' });\n\n  // Phase 2: Test (with parallel checks)\n  const [testResult, lintResult] = await ctx.parallel.all([\n    () => ctx.task(testTask, { command: 'npm test' }),\n    () => ctx.task(lintTask, { command: 'npm run lint' })\n  ]);\n\n  // Phase 3: Approve\n  await ctx.breakpoint({\n    question: 'Build and tests passed. Deploy to production?',\n    context: { runId: ctx.runId }\n  });\n\n  return { success: true, buildResult, testResult, lintResult };\n}\n```\n\n### Tasks\n\n**Tasks** are the atomic units of work. Types:\n\n| Kind | Description | Example |\n|------|-------------|---------|\n| `node` | Node.js script | Run tests, build code |\n| `agent` | LLM agent | Planning, scoring, review |\n| `skill` | Claude Code skill | Code analysis, refactoring |\n| `breakpoint` | Human approval | Review and approve |\n| `sleep` | Time gate | Wait until specific time |\n\n**Task definition:**\n\n```javascript\nimport { defineTask } from '@a5c-ai/babysitter-sdk';\n\nexport const buildTask = defineTask('build', (args, taskCtx) => ({\n  kind: 'node',\n  title: 'Build project',\n  node: {\n    entry: './scripts/build.js',\n    args: ['--output', 'dist/']\n  },\n  io: {\n    outputJsonPath: `tasks/${taskCtx.effectId}/result.json`\n  }\n}));\n```\n\n### Hooks\n\n**Hooks** are shell scripts that execute at lifecycle events:\n\n```bash\n# plugins/babysitter/hooks/on-run-start/notify.sh\n#!/bin/bash\nPAYLOAD=$(cat)  # Read JSON payload from stdin\n\nRUN_ID=$(echo \"$PAYLOAD\" | jq -r '.runId')\necho \"🚀 Run started: $RUN_ID\"\n\n# Send notification, update dashboard, etc.\n```\n\n**Hook types:**\n- `on-run-start` - Run begins\n- `on-run-complete` - Run succeeds\n- `on-run-fail` - Run fails\n- `on-task-start` - Task begins\n- `on-breakpoint` - Breakpoint reached\n- Custom hooks via `ctx.hook()`\n\n**Hook search order:**\n1. Per-repo: `.a5c/hooks/<hook-name>/*.sh`\n2. Per-user: `~/.config/babysitter/hooks/<hook-name>/*.sh`\n3. Plugin: `plugins/babysitter/hooks/<hook-name>/*.sh`\n\n---\n\n## 🏗️ Directory Structure\n\n```\nplugins/babysitter/\n├── README.md                          # This file\n├── BABYSITTER_PLUGIN_SPECIFICATION.md # Complete specification\n├── HOOKS.md                           # Hook system guide\n├── todos.md                           # Development roadmap\n│\n├── commands/                          # Claude Code commands\n│   ├── babysitter-run.md\n│   ├── babysitter-resume.md\n│   └── setup-babysitter-run-resume.sh\n│\n├── hooks/                             # Plugin hooks\n│   ├── hook-dispatcher.sh             # Main dispatcher\n│   ├── on-breakpoint-dispatcher.sh    # Breakpoint hooks\n│   ├── on-run-start/\n│   ├── on-run-complete/\n│   ├── on-run-fail/\n│   ├── on-task-start/\n│   └── on-breakpoint/\n│       └── breakpoint-cli.sh          # Default breakpoint handler\n│\n└── skills/                            # Claude Code skills\n    └── babysitter/\n        ├── SKILL.md                   # Main orchestration skill\n        ├── reference/\n        │   └── ADVANCED_PATTERNS.md   # Advanced patterns guide\n        └── process/                   # Packaged processes\n            ├── tdd-quality-convergence.js\n            ├── tdd-quality-convergence.md\n            └── examples/\n                └── *.json\n```\n\n---\n\n## 💡 Usage Examples\n\n### Example 1: Simple Build and Test\n\n```javascript\nexport async function process(inputs, ctx) {\n  const buildResult = await ctx.task(buildTask, {\n    command: 'npm run build'\n  });\n\n  if (!buildResult.success) {\n    throw new Error('Build failed');\n  }\n\n  const testResult = await ctx.task(testTask, {\n    command: 'npm test'\n  });\n\n  return { success: testResult.success };\n}\n```\n\n### Example 2: Agent-Based Quality Scoring\n\n```javascript\nimport { defineTask } from '@a5c-ai/babysitter-sdk';\n\nexport const agentScoringTask = defineTask('agent-scorer', (args, taskCtx) => ({\n  kind: 'agent',\n\n  agent: {\n    name: 'quality-scorer',\n    prompt: {\n      role: 'senior QA engineer',\n      task: 'Analyze test results and provide quality score 0-100',\n      context: {\n        testResults: args.testResults,\n        coverage: args.coverage\n      },\n      instructions: [\n        'Review test pass rate',\n        'Assess code coverage',\n        'Calculate overall score',\n        'Provide recommendations'\n      ],\n      outputFormat: 'JSON with score, analysis, recommendations'\n    },\n    outputSchema: {\n      type: 'object',\n      required: ['score', 'analysis'],\n      properties: {\n        score: { type: 'number', minimum: 0, maximum: 100 },\n        analysis: { type: 'string' },\n        recommendations: { type: 'array', items: { type: 'string' } }\n      }\n    }\n  },\n\n  io: {\n    inputJsonPath: `tasks/${taskCtx.effectId}/input.json`,\n    outputJsonPath: `tasks/${taskCtx.effectId}/result.json`\n  }\n}));\n\nexport async function process(inputs, ctx) {\n  const testResult = await ctx.task(testTask, {});\n\n  const qualityScore = await ctx.task(agentScoringTask, {\n    testResults: testResult,\n    coverage: testResult.coverage\n  });\n\n  ctx.log(`Quality score: ${qualityScore.score}/100`);\n\n  return { score: qualityScore.score };\n}\n```\n\n### Example 3: Parallel Execution\n\n```javascript\nexport async function process(inputs, ctx) {\n  // Run quality checks in parallel\n  const [coverage, lint, typeCheck, security] = await ctx.parallel.all([\n    () => ctx.task(coverageTask, {}),\n    () => ctx.task(lintTask, {}),\n    () => ctx.task(typeCheckTask, {}),\n    () => ctx.task(securityTask, {})\n  ]);\n\n  return { coverage, lint, typeCheck, security };\n}\n```\n\n### Example 4: Iterative Convergence\n\n```javascript\nexport async function process(inputs, ctx) {\n  const targetQuality = inputs.targetQuality || 85;\n  const maxIterations = inputs.maxIterations || 5;\n  let iteration = 0;\n  let currentQuality = 0;\n\n  while (iteration < maxIterations && currentQuality < targetQuality) {\n    iteration++;\n\n    // Implement and test\n    const impl = await ctx.task(implementTask, { iteration });\n    const test = await ctx.task(testTask, {});\n\n    // Agent scores quality\n    const score = await ctx.task(agentScoringTask, {\n      implementation: impl,\n      tests: test\n    });\n\n    currentQuality = score.overallScore;\n\n    ctx.log(`Iteration ${iteration}: Quality ${currentQuality}/${targetQuality}`);\n\n    if (currentQuality < targetQuality) {\n      // Breakpoint for review\n      await ctx.breakpoint({\n        question: `Quality ${currentQuality}/${targetQuality}. Continue?`,\n        context: { iteration, score }\n      });\n    }\n  }\n\n  return { converged: currentQuality >= targetQuality, iterations: iteration };\n}\n```\n\n### Example 5: Skill Invocation\n\n```javascript\nexport const skillTask = defineTask('analyzer', (args, taskCtx) => ({\n  kind: 'skill',\n\n  skill: {\n    name: 'codebase-analyzer',\n    context: {\n      scope: args.scope,\n      analysisType: 'consistency',\n      criteria: ['Naming conventions', 'Error handling'],\n      instructions: [\n        'Scan specified paths',\n        'Check consistency',\n        'Analyze patterns',\n        'Generate report'\n      ]\n    }\n  },\n\n  io: {\n    inputJsonPath: `tasks/${taskCtx.effectId}/input.json`,\n    outputJsonPath: `tasks/${taskCtx.effectId}/result.json`\n  }\n}));\n\nexport async function process(inputs, ctx) {\n  const analysis = await ctx.task(skillTask, { scope: 'src/' });\n  return { analysis };\n}\n```\n\n---\n\n## 🎓 Core Workflow\n\nBabysitter uses a **4-step iteration loop**:\n\n### 1. Run Iteration\n\n```bash\n$CLI run:iterate .a5c/runs/<runId> --json --iteration <n>\n```\n\n**Output:**\n```json\n{\n  \"iteration\": 1,\n  \"status\": \"executed|waiting|completed|failed|none\",\n  \"action\": \"executed-tasks|waiting|none\",\n  \"count\": 3\n}\n```\n\n**Status values:**\n- `executed` - Tasks executed, continue looping\n- `waiting` - Breakpoint/sleep, pause until released\n- `completed` - Run finished successfully\n- `failed` - Run failed with error\n- `none` - No pending effects\n\n### 2. Get Effects\n\n```bash\n$CLI task:list .a5c/runs/<runId> --pending --json\n```\n\n**Output:**\n```json\n{\n  \"tasks\": [\n    {\n      \"effectId\": \"effect-abc123\",\n      \"kind\": \"node|agent|skill|breakpoint\",\n      \"label\": \"auto\",\n      \"status\": \"requested\"\n    }\n  ]\n}\n```\n\n### 3. Perform Effects\n\n```bash\n$CLI task:post .a5c/runs/<runId> <effectId> --status <ok|error> --json\n```\n\n**Output:**\n```json\n{\n  \"status\": \"ok|error\",\n  \"committed\": {\n    \"resultRef\": \"tasks/effect-abc123/result.json\",\n    \"stdoutRef\": \"tasks/effect-abc123/stdout.log\",\n    \"stderrRef\": \"tasks/effect-abc123/stderr.log\"\n  },\n  \"stdoutRef\": \"tasks/effect-abc123/stdout.log\",\n  \"stderrRef\": \"tasks/effect-abc123/stderr.log\",\n  \"resultRef\": \"tasks/effect-abc123/result.json\"\n}\n```\n\n### 4. Results Posted\n\nAfter executing the effect externally (or inside a hook), `task:post`:\n- Writes result to `tasks/<effectId>/result.json`\n- Appends event to `journal.jsonl`\n- Updates `state.json` cache\n\n---\n\n## 🔧 CLI Quick Reference\n\n```bash\nCLI=\"npx -y @a5c-ai/babysitter-sdk@latest\"\n\n# Create run\n$CLI run:create \\\n  --process-id <id> \\\n  --entry <path>#<export> \\\n  --inputs <path>\n\n# Check status\n$CLI run:status <runId> --json\n\n# View events\n$CLI run:events <runId> --limit 20 --reverse\n\n# Iterate once\n$CLI run:iterate <runId> --json --iteration 1\n\n# List tasks\n$CLI task:list <runId> --pending --json\n\n# Post task result\n$CLI task:post <runId> <effectId> --status <ok|error> --json\n```\n\n---\n\n## 🚦 Advanced Features\n\n### Agent Tasks\n\nUse LLMs for planning, scoring, and review:\n\n```javascript\n{\n  kind: 'agent',\n  agent: {\n    name: 'feature-planner',\n    prompt: {\n      role: 'senior architect',\n      task: 'Generate implementation plan',\n      context: { feature: '...' },\n      instructions: ['Analyze', 'Plan', 'Recommend'],\n      outputFormat: 'JSON with approach, steps, risks'\n    },\n    outputSchema: { /* JSON schema */ }\n  },\n  io: { /* ... */ }\n}\n```\n\n### Skill Tasks\n\nInvoke Claude Code skills as tasks:\n\n```javascript\n{\n  kind: 'skill',\n  skill: {\n    name: 'codebase-analyzer',\n    context: {\n      scope: 'src/',\n      instructions: ['Scan', 'Analyze', 'Report']\n    }\n  },\n  io: { /* ... */ }\n}\n```\n\n### Breakpoints\n\nRequest human approval:\n\n```javascript\nawait ctx.breakpoint({\n  question: 'Approve deployment to production?',\n  title: 'Production Deployment',\n  context: {\n    runId: ctx.runId,\n    files: [\n      { path: 'artifacts/deploy-plan.md', format: 'markdown' }\n    ]\n  }\n});\n```\n\n### Custom Hooks\n\nAdd custom lifecycle hooks:\n\n```javascript\n// In process\nawait ctx.hook('pre-commit', {\n  files: ['src/feature.ts'],\n  message: 'feat: add new feature'\n});\n```\n\n```bash\n# .a5c/hooks/pre-commit/lint-check.sh\n#!/bin/bash\nPAYLOAD=$(cat)\nFILES=$(echo \"$PAYLOAD\" | jq -r '.files[]')\n\n# Run linter on changed files\nnpx eslint $FILES\n```\n\n### Parallel Execution\n\nRun independent tasks concurrently:\n\n```javascript\nconst results = await ctx.parallel.all([\n  () => ctx.task(task1, { ... }),\n  () => ctx.task(task2, { ... }),\n  () => ctx.task(task3, { ... })\n]);\n```\n\n### Quality Convergence\n\nIterate until quality target met:\n\n```javascript\nlet quality = 0;\nwhile (quality < targetQuality && iteration < maxIterations) {\n  // Implement, test, score\n  const score = await ctx.task(agentScoringTask, { ... });\n  quality = score.overallScore;\n  iteration++;\n}\n```\n\n---\n\n## 📖 Documentation\n\n### Core Documentation\n\n- **[BABYSITTER_PLUGIN_SPECIFICATION.md](./BABYSITTER_PLUGIN_SPECIFICATION.md)** - Complete specification (architecture, components, API)\n- **[HOOKS.md](./HOOKS.md)** - Hook system guide (types, development, examples)\n- **[skills/babysit/SKILL.md](./skills/babysit/SKILL.md)** - Main orchestration skill instructions\n- **[skills/babysit/reference/ADVANCED_PATTERNS.md](./skills/babysit/reference/ADVANCED_PATTERNS.md)** - Advanced patterns (agents, skills, convergence)\n\n### Process Documentation\n\n- **[tdd-quality-convergence.md](./.claude/skills/babysit/process/tdd-quality-convergence.md)** - Comprehensive TDD example with agent scoring\n- **[PACKAGING_PROCESSES_WITH_SKILLS.md](./PACKAGING_PROCESSES_WITH_SKILLS.md)** - How to package processes with skills\n\n### SDK Documentation\n\n- **[packages/sdk/sdk.md](../../packages/sdk/sdk.md)** - Babysitter SDK API reference\n\n---\n\n## 🎯 Example Processes\n\n### TDD Quality Convergence\n\n**Location:** `.claude/skills/babysit/process/tdd-quality-convergence.js`\n\nDemonstrates:\n- Agent-based planning\n- TDD red-green-refactor cycle\n- Quality convergence with iterative feedback\n- Parallel quality checks\n- Human-in-the-loop breakpoints\n- Agent-based quality scoring\n- Final review and approval\n\n**Usage:**\n```bash\n$CLI run:create \\\n  --process-id babysitter/tdd-quality-convergence \\\n  --entry .claude/skills/babysit/process/tdd-quality-convergence.js#process \\\n  --inputs .claude/skills/babysit/process/examples/tdd-quality-convergence-example.json\n```\n\n---\n\n## 🔍 Troubleshooting\n\n### CLI not found\n\n```bash\n# Install globally (optional)\nnpm install -g @a5c-ai/babysitter-sdk@latest\n\n# Or use npx\nnpx -y @a5c-ai/babysitter-sdk@latest --version\n```\n\n### Run stuck in \"waiting\"\n\nCheck for breakpoints:\n\n```bash\n$CLI run:status .a5c/runs/<runId>\n# Look for \"Awaiting input\" or breakpoint in pending tasks\n```\n\nRelease breakpoint via hooks or CLI (depending on setup).\n\n### Journal corruption\n\n```bash\n# Verify journal integrity\n$CLI run:events .a5c/runs/<runId> --json\n\n# If corrupted, restore from backup or rebuild state\n```\n\n### Task fails silently\n\nCheck task logs:\n\n```bash\n# View task stdout/stderr\ncat .a5c/runs/<runId>/tasks/<effectId>/stdout.log\ncat .a5c/runs/<runId>/tasks/<effectId>/stderr.log\n\n# View task with verbose output\n$CLI task:show .a5c/runs/<runId> <effectId> --json\n```\n\n### Hook not executing\n\nVerify hook permissions and search order:\n\n```bash\n# Make hook executable\nchmod +x .a5c/hooks/on-run-start/my-hook.sh\n\n# Test hook manually\necho '{\"runId\":\"test\"}' | .a5c/hooks/on-run-start/my-hook.sh\n```\n\n### Need alternate runs directory\n\n```bash\n# Specify custom runs directory\n$CLI run:create --runs-dir /path/to/runs ...\n$CLI run:status /path/to/runs/<runId>\n```\n\n---\n\n## 🤝 Contributing\n\n### Adding Custom Hooks\n\n1. Create hook script in `.a5c/hooks/<hook-name>/`\n2. Make it executable: `chmod +x <script>.sh`\n3. Read JSON payload from stdin\n4. Exit 0 for success, non-zero for failure\n\n### Creating Processes\n\n1. Create process file: `.a5c/processes/<category>/<name>.js`\n2. Export `process` function\n3. Define tasks with `defineTask`\n4. Test with `run:create`\n\n### Packaging Processes with Skills\n\n1. Create process in `.claude/skills/<skill-name>/process/`\n2. Add documentation: `<process-name>.md`\n3. Add example inputs: `examples/<process-name>-example.json`\n4. Reference in skill's `SKILL.md`\n\nSee [PACKAGING_PROCESSES_WITH_SKILLS.md](./PACKAGING_PROCESSES_WITH_SKILLS.md) for details.\n\n---\n\n## 📋 Key Features Summary\n\n✅ **Event-sourced orchestration** - Deterministic, reproducible workflows\n✅ **Resumable execution** - Pause and resume at any point\n✅ **Hook-driven extensibility** - Customize behavior at every lifecycle event\n✅ **Human-in-the-loop** - Breakpoints for approval and review\n✅ **Multi-task types** - Node scripts, LLM agents, Claude skills, breakpoints, sleep gates\n✅ **Parallel execution** - Run independent tasks concurrently\n✅ **Quality convergence** - Iterate until quality targets met\n✅ **Agent-based scoring** - LLM assessment of quality and progress\n✅ **CLI-driven** - Complete control via `@a5c-ai/babysitter-sdk` CLI\n✅ **Skill integration** - Package processes with Claude Code skills\n\n---\n\n## 📝 License\n\nSee main project LICENSE.\n\n---\n\n## 🔗 Quick Links\n\n- [Plugin Specification](./BABYSITTER_PLUGIN_SPECIFICATION.md)\n- [Hooks Guide](./HOOKS.md)\n- [Advanced Patterns](./skills/babysit/reference/ADVANCED_PATTERNS.md)\n- [SDK API Reference](../../packages/sdk/sdk.md)\n- [TDD Example Process](./.claude/skills/babysit/process/tdd-quality-convergence.js)\n- [Process Packaging Guide](./PACKAGING_PROCESSES_WITH_SKILLS.md)\n\n---\n\n**Get started:** Ask Claude to \"use the babysitter skill\" for your next complex workflow!\n"
      },
      "plugins": [
        {
          "name": "babysitter",
          "source": "./plugins/babysitter",
          "description": "Babysitter",
          "version": "4.0.122",
          "author": {
            "name": "a5c.ai"
          },
          "categories": [],
          "install_commands": [
            "/plugin marketplace add a5c-ai/babysitter",
            "/plugin install babysitter@a5c.ai"
          ]
        }
      ]
    }
  ]
}