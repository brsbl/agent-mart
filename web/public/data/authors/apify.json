{
  "author": {
    "id": "apify",
    "display_name": "apify",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/24586296?v=4",
    "url": "https://github.com/apify",
    "bio": "We're making the web more programmable.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 12,
      "total_commands": 1,
      "total_skills": 11,
      "total_stars": 56,
      "total_forks": 2
    }
  },
  "marketplaces": [
    {
      "name": "apify-agent-skills",
      "version": null,
      "description": "Official Apify agent skills for web scraping, data extraction, and automation",
      "owner_info": {
        "name": "Apify",
        "email": "support@apify.com"
      },
      "keywords": [],
      "repo_full_name": "apify/agent-skills",
      "repo_url": "https://github.com/apify/agent-skills",
      "repo_description": "Collection of Apify Agent Skills",
      "homepage": "",
      "signals": {
        "stars": 56,
        "forks": 2,
        "pushed_at": "2026-01-29T11:17:03Z",
        "created_at": "2026-01-07T13:37:31Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 7586
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 470
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5141
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/AGENTS.md",
          "type": "blob",
          "size": 3835
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/create-actor.md",
          "type": "blob",
          "size": 8631
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-actor-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-actor-development/SKILL.md",
          "type": "blob",
          "size": 8474
        },
        {
          "path": "skills/apify-actor-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-actor-development/references/actor-json.md",
          "type": "blob",
          "size": 2347
        },
        {
          "path": "skills/apify-actor-development/references/dataset-schema.md",
          "type": "blob",
          "size": 6260
        },
        {
          "path": "skills/apify-actor-development/references/input-schema.md",
          "type": "blob",
          "size": 1985
        },
        {
          "path": "skills/apify-actor-development/references/key-value-store-schema.md",
          "type": "blob",
          "size": 3717
        },
        {
          "path": "skills/apify-actor-development/references/logging.md",
          "type": "blob",
          "size": 2764
        },
        {
          "path": "skills/apify-actor-development/references/output-schema.md",
          "type": "blob",
          "size": 1986
        },
        {
          "path": "skills/apify-actor-development/references/standby-mode.md",
          "type": "blob",
          "size": 3197
        },
        {
          "path": "skills/apify-actorization",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-actorization/SKILL.md",
          "type": "blob",
          "size": 6468
        },
        {
          "path": "skills/apify-actorization/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-actorization/references/cli-actorization.md",
          "type": "blob",
          "size": 2262
        },
        {
          "path": "skills/apify-actorization/references/js-ts-actorization.md",
          "type": "blob",
          "size": 2422
        },
        {
          "path": "skills/apify-actorization/references/python-actorization.md",
          "type": "blob",
          "size": 2467
        },
        {
          "path": "skills/apify-actorization/references/schemas-and-output.md",
          "type": "blob",
          "size": 4225
        },
        {
          "path": "skills/apify-audience-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-audience-analysis/SKILL.md",
          "type": "blob",
          "size": 4623
        },
        {
          "path": "skills/apify-brand-reputation-monitoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-brand-reputation-monitoring/SKILL.md",
          "type": "blob",
          "size": 4492
        },
        {
          "path": "skills/apify-competitor-intelligence",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-competitor-intelligence/SKILL.md",
          "type": "blob",
          "size": 5287
        },
        {
          "path": "skills/apify-content-analytics",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-content-analytics/SKILL.md",
          "type": "blob",
          "size": 4236
        },
        {
          "path": "skills/apify-influencer-discovery",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-influencer-discovery/SKILL.md",
          "type": "blob",
          "size": 4344
        },
        {
          "path": "skills/apify-lead-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-lead-generation/SKILL.md",
          "type": "blob",
          "size": 4411
        },
        {
          "path": "skills/apify-market-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-market-research/SKILL.md",
          "type": "blob",
          "size": 4058
        },
        {
          "path": "skills/apify-trend-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-trend-analysis/SKILL.md",
          "type": "blob",
          "size": 4247
        },
        {
          "path": "skills/apify-ultimate-scraper",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/apify-ultimate-scraper/SKILL.md",
          "type": "blob",
          "size": 9591
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"apify-agent-skills\",\n  \"owner\": {\n    \"name\": \"Apify\",\n    \"email\": \"support@apify.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Official Apify agent skills for web scraping, data extraction, and automation\",\n    \"version\": \"1.6.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"apify-lead-generation\",\n      \"source\": \"./skills/apify-lead-generation\",\n      \"skills\": \"./\",\n      \"description\": \"Generate B2B/B2C leads by scraping Google Maps, websites, Instagram, TikTok, Facebook, LinkedIn, YouTube, and Google Search using Apify Actors\",\n      \"keywords\": [\n        \"leads\",\n        \"sales\",\n        \"prospecting\",\n        \"b2b\",\n        \"b2c\",\n        \"scraping\",\n        \"apify\",\n        \"google-maps\",\n        \"instagram\",\n        \"tiktok\",\n        \"facebook\",\n        \"linkedin\",\n        \"youtube\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.1.11\"\n    },\n    {\n      \"name\": \"apify-brand-reputation-monitoring\",\n      \"source\": \"./skills/apify-brand-reputation-monitoring\",\n      \"skills\": \"./\",\n      \"description\": \"Track reviews, ratings, sentiment, and brand mentions across Google Maps, Booking.com, TripAdvisor, Facebook, Instagram, YouTube, and TikTok\",\n      \"keywords\": [\n        \"reputation\",\n        \"reviews\",\n        \"sentiment\",\n        \"monitoring\",\n        \"brand\",\n        \"ratings\",\n        \"google-maps\",\n        \"booking\",\n        \"tripadvisor\",\n        \"facebook\",\n        \"instagram\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.1\"\n    },\n    {\n      \"name\": \"apify-competitor-intelligence\",\n      \"source\": \"./skills/apify-competitor-intelligence\",\n      \"skills\": \"./\",\n      \"description\": \"Analyze competitor strategies, content, pricing, ads, and market positioning across Google Maps, Booking.com, Facebook, Instagram, YouTube, and TikTok\",\n      \"keywords\": [\n        \"competitor\",\n        \"intelligence\",\n        \"analysis\",\n        \"benchmarking\",\n        \"strategy\",\n        \"ads\",\n        \"google-maps\",\n        \"booking\",\n        \"facebook\",\n        \"instagram\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.1.1\"\n    },\n    {\n      \"name\": \"apify-market-research\",\n      \"source\": \"./skills/apify-market-research\",\n      \"skills\": \"./\",\n      \"description\": \"Analyze market conditions, geographic opportunities, pricing, consumer behavior, and product validation across Google Maps, Facebook, Instagram, Booking.com, and TripAdvisor\",\n      \"keywords\": [\n        \"market\",\n        \"research\",\n        \"analysis\",\n        \"pricing\",\n        \"geographic\",\n        \"validation\",\n        \"trends\",\n        \"google-maps\",\n        \"facebook\",\n        \"instagram\",\n        \"booking\",\n        \"tripadvisor\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.1\"\n    },\n    {\n      \"name\": \"apify-influencer-discovery\",\n      \"source\": \"./skills/apify-influencer-discovery\",\n      \"skills\": \"./\",\n      \"description\": \"Find and evaluate influencers for brand partnerships, verify authenticity, and track collaboration performance across Instagram, Facebook, YouTube, and TikTok\",\n      \"keywords\": [\n        \"influencer\",\n        \"discovery\",\n        \"partnership\",\n        \"creator\",\n        \"collaboration\",\n        \"authenticity\",\n        \"instagram\",\n        \"facebook\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"apify-trend-analysis\",\n      \"source\": \"./skills/apify-trend-analysis\",\n      \"skills\": \"./\",\n      \"description\": \"Discover and track emerging trends across Google Trends, Instagram, Facebook, YouTube, and TikTok to inform content strategy\",\n      \"keywords\": [\n        \"trends\",\n        \"analysis\",\n        \"hashtags\",\n        \"viral\",\n        \"discovery\",\n        \"content\",\n        \"google-trends\",\n        \"instagram\",\n        \"facebook\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"apify-content-analytics\",\n      \"source\": \"./skills/apify-content-analytics\",\n      \"skills\": \"./\",\n      \"description\": \"Track engagement metrics, measure campaign ROI, and analyze content performance across Instagram, Facebook, YouTube, and TikTok\",\n      \"keywords\": [\n        \"analytics\",\n        \"engagement\",\n        \"performance\",\n        \"metrics\",\n        \"ROI\",\n        \"content\",\n        \"instagram\",\n        \"facebook\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"apify-audience-analysis\",\n      \"source\": \"./skills/apify-audience-analysis\",\n      \"skills\": \"./\",\n      \"description\": \"Understand audience demographics, preferences, behavior patterns, and engagement quality across Facebook, Instagram, YouTube, and TikTok\",\n      \"keywords\": [\n        \"audience\",\n        \"demographics\",\n        \"behavior\",\n        \"engagement\",\n        \"analysis\",\n        \"followers\",\n        \"facebook\",\n        \"instagram\",\n        \"youtube\",\n        \"tiktok\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"apify-ultimate-scraper\",\n      \"source\": \"./skills/apify-ultimate-scraper\",\n      \"skills\": \"./\",\n      \"description\": \"Universal AI-powered web scraper for any platform. Scrape data from Instagram, Facebook, TikTok, YouTube, Google Maps, Google Search, Google Trends, Booking.com, and TripAdvisor for lead generation, brand monitoring, competitor analysis, influencer discovery, trend research, and more\",\n      \"keywords\": [\n        \"scraper\",\n        \"universal\",\n        \"instagram\",\n        \"facebook\",\n        \"tiktok\",\n        \"youtube\",\n        \"google-maps\",\n        \"leads\",\n        \"monitoring\",\n        \"competitor\",\n        \"trends\",\n        \"influencer\"\n      ],\n      \"category\": \"data-extraction\",\n      \"version\": \"1.4.0\"\n    },\n    {\n      \"name\": \"apify-actor-development\",\n      \"source\": \"./skills/apify-actor-development\",\n      \"skills\": \"./\",\n      \"description\": \"Develop, debug, and deploy Apify Actors - serverless cloud programs for web scraping, automation, and data processing\",\n      \"keywords\": [\n        \"apify\",\n        \"actor\",\n        \"web-scraping\",\n        \"automation\",\n        \"crawlee\",\n        \"playwright\",\n        \"cheerio\",\n        \"serverless\",\n        \"development\"\n      ],\n      \"category\": \"development\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"apify-actor-commands\",\n      \"description\": \"Commands for Apify Actor development workflow\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Apify\",\n        \"email\": \"support@apify.com\"\n      },\n      \"source\": \"./\",\n      \"category\": \"development\",\n      \"commands\": [\n        \"./commands/create-actor.md\"\n      ]\n    },\n    {\n      \"name\": \"apify-actorization\",\n      \"source\": \"./skills/apify-actorization\",\n      \"skills\": \"./\",\n      \"description\": \"Convert existing projects into Apify Actors - serverless cloud programs. Actorize JavaScript/TypeScript (SDK with Actor.init/exit), Python (async context manager), or any language (CLI wrapper). Use when migrating code to Apify, wrapping CLI tools as Actors, or adding Actor SDK to existing projects.\",\n      \"keywords\": [\n        \"actorization\",\n        \"convert\",\n        \"migrate\",\n        \"actor\",\n        \"apify\",\n        \"sdk\",\n        \"deployment\",\n        \"crawlee\",\n        \"serverless\"\n      ],\n      \"category\": \"development\",\n      \"version\": \"1.0.0\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"apify-agent-skills\",\n  \"version\": \"1.6.0\",\n  \"description\": \"Official Apify agent skills for web scraping, data extraction, and automation\",\n  \"author\": {\n    \"name\": \"Apify\",\n    \"email\": \"support@apify.com\"\n  },\n  \"homepage\": \"https://github.com/apify/agent-skills\",\n  \"repository\": \"https://github.com/apify/agent-skills\",\n  \"license\": \"Apache-2.0\",\n  \"keywords\": [\n    \"apify\",\n    \"scraping\",\n    \"automation\",\n    \"leads\",\n    \"data-extraction\"\n  ]\n}\n",
        "README.md": "# Apify Agent Skills\n\nOfficial Apify agent skills for web scraping, data extraction, and automation. Works with Claude Code, Cursor, Codex, Gemini CLI, and other AI coding assistants.\n\n## Available Skills\n\n<!-- BEGIN_SKILLS_TABLE -->\n| Name | Description | Documentation |\n|------|-------------|---------------|\n| `apify-actor-development` | Develop, debug, and deploy Apify Actors - serverless cloud programs for web scraping, automation, and data processing | [SKILL.md](skills/apify-actor-development/SKILL.md) |\n| `apify-actorization` | Convert existing projects into Apify Actors - serverless cloud programs. Actorize JavaScript/TypeScript (SDK with Actor.init/exit), Python (async context manager), or any language (CLI wrapper). Use when migrating code to Apify, wrapping CLI tools as Actors, or adding Actor SDK to existing projects. | [SKILL.md](skills/apify-actorization/SKILL.md) |\n| `apify-audience-analysis` | Understand audience demographics, preferences, behavior patterns, and engagement quality across Facebook, Instagram, YouTube, and TikTok | [SKILL.md](skills/apify-audience-analysis/SKILL.md) |\n| `apify-brand-reputation-monitoring` | Track reviews, ratings, sentiment, and brand mentions across Google Maps, Booking.com, TripAdvisor, Facebook, Instagram, YouTube, and TikTok | [SKILL.md](skills/apify-brand-reputation-monitoring/SKILL.md) |\n| `apify-competitor-intelligence` | Analyze competitor strategies, content, pricing, ads, and market positioning across Google Maps, Booking.com, Facebook, Instagram, YouTube, and TikTok | [SKILL.md](skills/apify-competitor-intelligence/SKILL.md) |\n| `apify-content-analytics` | Track engagement metrics, measure campaign ROI, and analyze content performance across Instagram, Facebook, YouTube, and TikTok | [SKILL.md](skills/apify-content-analytics/SKILL.md) |\n| `apify-influencer-discovery` | Find and evaluate influencers for brand partnerships, verify authenticity, and track collaboration performance across Instagram, Facebook, YouTube, and TikTok | [SKILL.md](skills/apify-influencer-discovery/SKILL.md) |\n| `apify-lead-generation` | Generate B2B/B2C leads by scraping Google Maps, websites, Instagram, TikTok, Facebook, LinkedIn, YouTube, and Google Search using Apify Actors | [SKILL.md](skills/apify-lead-generation/SKILL.md) |\n| `apify-market-research` | Analyze market conditions, geographic opportunities, pricing, consumer behavior, and product validation across Google Maps, Facebook, Instagram, Booking.com, and TripAdvisor | [SKILL.md](skills/apify-market-research/SKILL.md) |\n| `apify-trend-analysis` | Discover and track emerging trends across Google Trends, Instagram, Facebook, YouTube, and TikTok to inform content strategy | [SKILL.md](skills/apify-trend-analysis/SKILL.md) |\n| `apify-ultimate-scraper` | Universal AI-powered web scraper for any platform. Scrape data from Instagram, Facebook, TikTok, YouTube, Google Maps, Google Search, Google Trends, Booking.com, and TripAdvisor for lead generation, brand monitoring, competitor analysis, influencer discovery, trend research, and more | [SKILL.md](skills/apify-ultimate-scraper/SKILL.md) |\n<!-- END_SKILLS_TABLE -->\n\n## Installation\n\n```bash\nnpx skills add apify/agent-skills\n```\n\n### Claude Code\n\n```bash\n# Add the marketplace\n/plugin marketplace add https://github.com/apify/agent-skills\n\n# Install a skill\n/plugin install apify-ultimate-scraper@apify-agent-skills\n```\n\n### Cursor / Windsurf\n\nAdd to your project's `.cursor/settings.json` or use the same Claude Code plugin format.\n\n### Codex / Gemini CLI\n\nPoint your agent to the `agents/AGENTS.md` file which contains skill descriptions and paths:\n\n```bash\n# Gemini CLI uses gemini-extension.json automatically\n# For Codex, reference agents/AGENTS.md in your configuration\n```\n\n### Other AI Tools\n\nAny AI tool that supports markdown context can use the skills by pointing to:\n- `agents/AGENTS.md` - Auto-generated skill index\n- `skills/*/SKILL.md` - Individual skill documentation\n\n## Prerequisites\n\n1. **Apify Account** - [apify.com](https://apify.com)\n2. **API Token** - Get from [Apify Console](https://console.apify.com/account/integrations), add `APIFY_TOKEN=your_token` to `.env`\n3. **Node.js 20.6+**\n4. **mcpc CLI** - `npm install -g @apify/mcpc`\n\n## Output Formats\n\n- **Quick Answer** - Top 5 results displayed in chat (no file saved)\n- **CSV** - Full export with all fields\n- **JSON** - Full data export\n\n## Pricing\n\nApify Actors use pay-per-result pricing. Check individual Actor pricing on [apify.com](https://apify.com).\n\n## Contributing\n\n1. Fork this repository\n2. Create your skill in `skills/your-skill-name/`\n3. Add `SKILL.md` with proper frontmatter:\n   ```yaml\n   ---\n   name: your-skill-name\n   description: What your skill does and when to use it\n   ---\n   ```\n4. Add entry to `.claude-plugin/marketplace.json`\n5. Run `uv run scripts/generate_agents.py` to update AGENTS.md\n6. Submit a pull request\n\n## Development\n\n```bash\n# Regenerate AGENTS.md and validate marketplace.json\nuv run scripts/generate_agents.py\n```\n\n## Support\n\n- [Apify Documentation](https://docs.apify.com)\n- [Apify Discord](https://discord.gg/jyEM2PRvMU)\n",
        "agents/AGENTS.md": "<skills>\n\nYou have additional SKILLs documented in directories containing a \"SKILL.md\" file.\n\nThese skills are:\n - apify-actor-development -> \"skills/apify-actor-development/SKILL.md\"\n - apify-actorization -> \"skills/apify-actorization/SKILL.md\"\n - apify-audience-analysis -> \"skills/apify-audience-analysis/SKILL.md\"\n - apify-brand-reputation-monitoring -> \"skills/apify-brand-reputation-monitoring/SKILL.md\"\n - apify-competitor-intelligence -> \"skills/apify-competitor-intelligence/SKILL.md\"\n - apify-content-analytics -> \"skills/apify-content-analytics/SKILL.md\"\n - apify-influencer-discovery -> \"skills/apify-influencer-discovery/SKILL.md\"\n - apify-lead-generation -> \"skills/apify-lead-generation/SKILL.md\"\n - apify-market-research -> \"skills/apify-market-research/SKILL.md\"\n - apify-trend-analysis -> \"skills/apify-trend-analysis/SKILL.md\"\n - apify-ultimate-scraper -> \"skills/apify-ultimate-scraper/SKILL.md\"\n\nIMPORTANT: You MUST read the SKILL.md file whenever the description of the skills matches the user intent, or may help accomplish their task.\n\n<available_skills>\n\napify-actor-development: `Develop, debug, and deploy Apify Actors - serverless cloud programs for web scraping, automation, and data processing. Use when creating new Actors, modifying existing ones, or troubleshooting Actor code.`\napify-actorization: `Convert existing projects into Apify Actors - serverless cloud programs. Actorize JavaScript/TypeScript (SDK with Actor.init/exit), Python (async context manager), or any language (CLI wrapper). Use when migrating code to Apify, wrapping CLI tools as Actors, or adding Actor SDK to existing projects.`\napify-audience-analysis: `Understand audience demographics, preferences, behavior patterns, and engagement quality across Facebook, Instagram, YouTube, and TikTok.`\napify-brand-reputation-monitoring: `Track reviews, ratings, sentiment, and brand mentions across Google Maps, Booking.com, TripAdvisor, Facebook, Instagram, YouTube, and TikTok. Use when user asks to monitor brand reputation, analyze reviews, track mentions, or gather customer feedback.`\napify-competitor-intelligence: `Analyze competitor strategies, content, pricing, ads, and market positioning across Google Maps, Booking.com, Facebook, Instagram, YouTube, and TikTok.`\napify-content-analytics: `Track engagement metrics, measure campaign ROI, and analyze content performance across Instagram, Facebook, YouTube, and TikTok.`\napify-influencer-discovery: `Find and evaluate influencers for brand partnerships, verify authenticity, and track collaboration performance across Instagram, Facebook, YouTube, and TikTok.`\napify-lead-generation: `Generates B2B/B2C leads by scraping Google Maps, websites, Instagram, TikTok, Facebook, LinkedIn, YouTube, and Google Search. Use when user asks to find leads, prospects, businesses, build lead lists, enrich contacts, or scrape profiles for sales outreach.`\napify-market-research: `Analyze market conditions, geographic opportunities, pricing, consumer behavior, and product validation across Google Maps, Facebook, Instagram, Booking.com, and TripAdvisor.`\napify-trend-analysis: `Discover and track emerging trends across Google Trends, Instagram, Facebook, YouTube, and TikTok to inform content strategy.`\napify-ultimate-scraper: `Universal AI-powered web scraper for any platform. Scrape data from Instagram, Facebook, TikTok, YouTube, Google Maps, Google Search, Google Trends, Booking.com, and TripAdvisor. Use for lead generation, brand monitoring, competitor analysis, influencer discovery, trend research, content analytics, audience analysis, or any data extraction task.`\n</available_skills>\n\nPaths referenced within SKILL.md files are relative to that SKILL folder. For example `reference/workflows.md` refers to the workflows file inside the skill's reference folder.\n\n</skills>\n",
        "commands/create-actor.md": "---\ndescription: Guided Apify Actor development with best practices and systematic workflow\nargument-hint: Optional actor description\n---\n\n# Actor Development\n\nYou are helping a developer create an Apify Actor - a serverless cloud program for web scraping, automation, and data processing. Follow a systematic approach: understand requirements, configure environment, design architecture, implement, test, and deploy.\n\n## Core Principles\n\n- **Ask clarifying questions**: Identify target websites, data requirements, edge cases, and constraints before implementation\n- **Follow Apify best practices**: Use appropriate crawlers (Cheerio vs Playwright), implement proper error handling, respect rate limits\n- **Validate early**: Check CLI installation and authentication before starting\n- **Use TodoWrite**: Track all progress throughout\n- **Security first**: Use `apify/log` for censoring sensitive data, validate input, handle errors gracefully\n\n---\n\n## Phase 1: Discovery\n\n**Goal**: Understand what actor needs to be built\n\nInitial request: $ARGUMENTS\n\n**Actions**:\n1. Create todo list with all phases\n2. Ask user for clarification if needed:\n   - What is the actor's primary purpose? (web scraping, automation, data processing)\n   - What websites/services will it interact with?\n   - What data should it extract or what actions should it perform?\n   - Any specific requirements or constraints?\n3. Summarize understanding and confirm with user\n\n---\n\n## Phase 2: Environment Setup\n\n**Goal**: Verify Apify CLI is installed and authenticated\n\n**CRITICAL**: Do not proceed without proper setup\n\n**Actions**:\n1. Check if Apify CLI is installed: `apify --help`\n2. If not installed, guide user to install:\n   ```bash\n   curl -fsSL https://apify.com/install-cli.sh | bash\n   # Or: brew install apify-cli (Mac)\n   # Or: npm install -g apify-cli\n   ```\n3. Verify authentication: `apify info`\n4. If not logged in:\n   - Check for APIFY_TOKEN environment variable\n   - If missing, ask user to generate token at https://console.apify.com/settings/integrations\n   - Login with: `apify login -t $APIFY_TOKEN`\n\n---\n\n## Phase 3: Language Selection\n\n**Goal**: Choose programming language and template\n\n**Actions**:\n1. **Ask user which language they prefer:**\n   - JavaScript (skills/apify-actor-development/references/actor-template-js.md)\n   - TypeScript (skills/apify-actor-development/references/actor-template-ts.md)\n   - Python (skills/apify-actor-development/references/actor-template-python.md)\n2. Note: Additional packages (Crawlee, Playwright, etc.) can be installed later as needed\n\n---\n\n## Phase 4: Requirements & Architecture Design\n\n**Goal**: Define input/output schemas and implementation approach\n\n**Actions**:\n1. Clarify detailed requirements:\n   - What input parameters should the actor accept?\n   - What output format is needed? (dataset items, key-value store files, both)\n   - Should it use CheerioCrawler (10x faster for static HTML) or PlaywrightCrawler (for JavaScript-heavy sites)?\n   - Concurrency settings? (HTTP: 10-50, Browser: 1-5)\n   - Rate limiting and retry strategies?\n   - Should standby mode be enabled?\n2. Design architecture:\n   - Input schema structure\n   - Output/dataset schema structure\n   - Key-value store schema (if needed)\n   - Error handling approach\n   - Data validation and cleaning strategy\n3. Present architecture to user and get approval\n\n---\n\n## Phase 5: Actor Creation\n\n**Goal**: Create actor from template and configure schemas\n\n**DO NOT START WITHOUT USER APPROVAL**\n\n**Actions**:\n1. Wait for explicit user approval\n2. Copy appropriate language template from `skills/apify-actor-development/references/` directory\n3. Update `.actor/actor.json`:\n   - Set actor name and version\n   - **IMPORTANT**: Fill in `generatedBy` property with current model name\n   - Configure runtime, memory, timeout\n   - Set `usesStandbyMode` if applicable\n4. Create/update `.actor/input_schema.json` with input parameters\n5. Create/update `.actor/output_schema.json` with output structure\n6. Create/update `.actor/dataset_schema.json` if using datasets\n7. Create/update `.actor/key_value_store_schema.json` if using key-value store\n8. Update todos as you progress\n\n**Reference documentation:**\n- [skills/apify-actor-development/references/actor-json.md](skills/apify-actor-development/references/actor-json.md)\n- [skills/apify-actor-development/references/input-schema.md](skills/apify-actor-development/references/input-schema.md)\n- [skills/apify-actor-development/references/output-schema.md](skills/apify-actor-development/references/output-schema.md)\n- [skills/apify-actor-development/references/dataset-schema.md](skills/apify-actor-development/references/dataset-schema.md)\n- [skills/apify-actor-development/references/key-value-store-schema.md](skills/apify-actor-development/references/key-value-store-schema.md)\n\n---\n\n## Phase 6: Implementation\n\n**Goal**: Implement actor logic following best practices\n\n**Actions**:\n1. Implement actor code in `src/main.py`, `src/main.js`, or `src/main.ts`\n2. Follow best practices:\n   - ✓ Use Apify SDK (`apify`) for code running on Apify platform\n   - ✓ Validate input early with proper error handling\n   - ✓ Use CheerioCrawler for static HTML (10x faster)\n   - ✓ Use PlaywrightCrawler only for JavaScript-heavy sites\n   - ✓ Use router pattern for complex crawls\n   - ✓ Implement retry strategies with exponential backoff\n   - ✓ Use proper concurrency settings\n   - ✓ Clean and validate data before pushing to dataset\n   - ✓ **Always use `apify/log` package** - censors sensitive data\n   - ✓ Implement readiness probe handler if using standby mode\n   - ✗ Don't use browser crawlers when HTTP/Cheerio works\n   - ✗ Don't hard code values that should be in input schema\n   - ✗ Don't skip input validation or error handling\n   - ✗ Don't overload servers - use appropriate concurrency and delays\n3. Implement standby mode readiness probe if `usesStandbyMode: true` (see [skills/apify-actor-development/references/standby-mode.md](skills/apify-actor-development/references/standby-mode.md))\n4. Use proper logging (see [skills/apify-actor-development/references/logging.md](skills/apify-actor-development/references/logging.md))\n5. Update todos as you progress\n\n---\n\n## Phase 7: Documentation\n\n**Goal**: Create comprehensive README for marketplace\n\n**Actions**:\n1. Create README.md with:\n   - Clear description of what the actor does\n   - Input parameters with examples\n   - Output format with examples\n   - Usage instructions\n   - Limitations and known issues\n   - Example runs\n2. Include code examples for common use cases\n3. Mention rate limits, costs, or legal considerations if applicable\n\n---\n\n## Phase 8: Local Testing\n\n**Goal**: Test actor locally before deployment\n\n**Actions**:\n1. Install dependencies:\n   - JavaScript/TypeScript: `npm install`\n   - Python: `pip install -r requirements.txt`\n2. Create test input file at `storage/key_value_stores/default/INPUT.json` with sample parameters\n3. Run actor locally: `apify run`\n4. Verify:\n   - Input is parsed correctly\n   - Actor completes successfully\n   - Output is in expected format\n   - Error handling works\n   - Logging is appropriate\n5. Fix any issues found\n6. Test edge cases and error scenarios\n\n---\n\n## Phase 9: Deployment\n\n**Goal**: Deploy actor to Apify platform\n\n**DO NOT DEPLOY WITHOUT USER APPROVAL**\n\n**Actions**:\n1. **Ask user if they want to deploy now**\n2. If yes, deploy with: `apify push`\n3. Actor will be deployed with name from `.actor/actor.json`\n4. Provide user with:\n   - Deployment confirmation\n   - Actor URL on Apify platform\n   - Instructions for running on platform\n\n---\n\n## Phase 10: Summary\n\n**Goal**: Document what was accomplished\n\n**Actions**:\n1. Mark all todos complete\n2. Summarize:\n   - What actor was built\n   - Key features and capabilities\n   - Input/output schemas\n   - Files created/modified\n   - Deployment status\n   - Suggested next steps (testing on platform, publishing to store, monitoring)\n\n---\n\n## Additional Resources\n\n**MCP Tools** (if configured):\n- `search-apify-docs` - Search documentation\n- `fetch-apify-docs` - Get full doc pages\n\n**Documentation:**\n- [docs.apify.com/llms.txt](https://docs.apify.com/llms.txt) - Apify quick reference\n- [docs.apify.com/llms-full.txt](https://docs.apify.com/llms-full.txt) - Apify complete docs\n- [crawlee.dev/llms.txt](https://crawlee.dev/llms.txt) - Crawlee quick reference\n- [crawlee.dev/llms-full.txt](https://crawlee.dev/llms-full.txt) - Crawlee complete docs\n- [whitepaper.actor](https://raw.githubusercontent.com/apify/actor-whitepaper/refs/heads/master/README.md) - Complete Actor specification\n",
        "skills/apify-actor-development/SKILL.md": "---\nname: apify-actor-development\ndescription: Develop, debug, and deploy Apify Actors - serverless cloud programs for web scraping, automation, and data processing. Use when creating new Actors, modifying existing ones, or troubleshooting Actor code.\n---\n\n# Apify Actor Development\n\n**Important:** Before you begin, fill in the `generatedBy` property in the meta section of `.actor/actor.json`. Replace it with the tool and model you're currently using, such as \"Claude Code with Claude Sonnet 4.5\". This helps Apify monitor and improve AGENTS.md for specific AI tools and models.\n\n## What are Apify Actors?\n\nActors are serverless programs inspired by the UNIX philosophy - programs that do one thing well and can be easily combined to build complex systems. They're packaged as Docker images and run in isolated containers in the cloud.\n\n**Core Concepts:**\n- Accept well-defined JSON input\n- Perform isolated tasks (web scraping, automation, data processing)\n- Produce structured JSON output to datasets and/or store data in key-value stores\n- Can run from seconds to hours or even indefinitely\n- Persist state and can be restarted\n\n## Prerequisites & Setup (MANDATORY)\n\nBefore creating or modifying actors, verify that `apify` CLI is installed `apify --help`.\n\nIf it is not installed, you can run:\n\n```bash\ncurl -fsSL https://apify.com/install-cli.sh | bash\n\n# Or (Mac): brew install apify-cli\n# Or (Windows): irm https://apify.com/install-cli.ps1 | iex\n# Or: npm install -g apify-cli\n```\n\nWhen the apify CLI is installed, check that it is logged in with:\n\n```bash\napify info  # Should return your username\n```\n\nIf it is not logged in, check if the APIFY_TOKEN environment variable is defined (if not, ask the user to generate one on https://console.apify.com/settings/integrations and then define APIFY_TOKEN with it).\n\nThen run:\n\n```bash\napify login -t $APIFY_TOKEN\n```\n\n## Template Selection\n\n**IMPORTANT:** Before starting actor development, always ask the user which programming language they prefer:\n- **JavaScript** - Use `apify create <actor-name> -t project_empty`\n- **TypeScript** - Use `apify create <actor-name> -t ts_empty`\n- **Python** - Use `apify create <actor-name> -t python-empty`\n\nUse the appropriate CLI command based on the user's language choice. Additional packages (Crawlee, Playwright, etc.) can be installed later as needed.\n\n## Quick Start Workflow\n\n1. **Create actor project** - Run the appropriate `apify create` command based on user's language preference (see Template Selection above)\n2. **Install dependencies**\n   - JavaScript/TypeScript: `npm install`\n   - Python: `pip install -r requirements.txt`\n3. **Implement logic** - Write the actor code in `src/main.py`, `src/main.js`, or `src/main.ts`\n4. **Configure schemas** - Update input/output schemas in `.actor/input_schema.json`, `.actor/output_schema.json`, `.actor/dataset_schema.json`\n5. **Configure platform settings** - Update `.actor/actor.json` with actor metadata (see [references/actor-json.md](references/actor-json.md))\n6. **Write documentation** - Create comprehensive README.md for the marketplace\n7. **Test locally** - Run `apify run` to verify functionality (see Local Testing section below)\n8. **Deploy** - Run `apify push` to deploy the actor on the Apify platform (actor name is defined in `.actor/actor.json`)\n\n## Best Practices\n\n**✓ Do:**\n- Use `apify run` to test actors locally (configures Apify environment and storage)\n- Use Apify SDK (`apify`) for code running ON Apify platform\n- Validate input early with proper error handling and fail gracefully\n- Use CheerioCrawler for static HTML (10x faster than browsers)\n- Use PlaywrightCrawler only for JavaScript-heavy sites\n- Use router pattern (createCheerioRouter/createPlaywrightRouter) for complex crawls\n- Implement retry strategies with exponential backoff\n- Use proper concurrency: HTTP (10-50), Browser (1-5)\n- Set sensible defaults in `.actor/input_schema.json`\n- Define output schema in `.actor/output_schema.json`\n- Clean and validate data before pushing to dataset\n- Use semantic CSS selectors with fallback strategies\n- Respect robots.txt, ToS, and implement rate limiting\n- **Always use `apify/log` package** - censors sensitive data (API keys, tokens, credentials)\n- Implement readiness probe handler (required if your Actor uses standby mode)\n\n**✗ Don't:**\n- Use `npm start`, `npm run start`, `npx apify run`, or similar commands to run actors (use `apify run` instead)\n- Rely on `Dataset.getInfo()` for final counts on Cloud\n- Use browser crawlers when HTTP/Cheerio works\n- Hard code values that should be in input schema or environment variables\n- Skip input validation or error handling\n- Overload servers - use appropriate concurrency and delays\n- Scrape prohibited content or ignore Terms of Service\n- Store personal/sensitive data unless explicitly permitted\n- Use deprecated options like `requestHandlerTimeoutMillis` on CheerioCrawler (v3.x)\n- Use `additionalHttpHeaders` - use `preNavigationHooks` instead\n- Disable standby mode without explicit permission\n\n## Logging\n\nSee [references/logging.md](references/logging.md) for complete logging documentation including available log levels and best practices for JavaScript/TypeScript and Python.\n\nCheck `usesStandbyMode` in `.actor/actor.json` - only implement if set to `true`.\n\n## Commands\n\n```bash\napify run          # Run Actor locally\napify login        # Authenticate account\napify push         # Deploy to Apify platform (uses name from .actor/actor.json)\napify help         # List all commands\n```\n\n**IMPORTANT:** Always use `apify run` to test actors locally. Do not use `npm run start`, `npm start`, `yarn start`, or other package manager commands - these will not properly configure the Apify environment and storage.\n\n## Local Testing\n\nWhen testing an actor locally with `apify run`, provide input data by creating a JSON file at:\n\n```\nstorage/key_value_stores/default/INPUT.json\n```\n\nThis file should contain the input parameters defined in your `.actor/input_schema.json`. The actor will read this input when running locally, mirroring how it receives input on the Apify platform.\n\n## Standby Mode\n\nSee [references/standby-mode.md](references/standby-mode.md) for complete standby mode documentation including readiness probe implementation for JavaScript/TypeScript and Python.\n\n## Project Structure\n\n```\n.actor/\n├── actor.json           # Actor config: name, version, env vars, runtime\n├── input_schema.json    # Input validation & Console form definition\n└── output_schema.json   # Output storage and display templates\nsrc/\n└── main.js/ts/py       # Actor entry point\nstorage/                # Local storage (mirrors Cloud)\n├── datasets/           # Output items (JSON objects)\n├── key_value_stores/   # Files, config, INPUT\n└── request_queues/     # Pending crawl requests\nDockerfile              # Container image definition\n```\n\n## Actor Configuration\n\nSee [references/actor-json.md](references/actor-json.md) for complete actor.json structure and configuration options.\n\n## Input Schema\n\nSee [references/input-schema.md](references/input-schema.md) for input schema structure and examples.\n\n## Output Schema\n\nSee [references/output-schema.md](references/output-schema.md) for output schema structure, examples, and template variables.\n\n## Dataset Schema\n\nSee [references/dataset-schema.md](references/dataset-schema.md) for dataset schema structure, configuration, and display properties.\n\n## Key-Value Store Schema\n\nSee [references/key-value-store-schema.md](references/key-value-store-schema.md) for key-value store schema structure, collections, and configuration.\n\n\n## Apify MCP Tools\n\nIf MCP server is configured, use these tools for documentation:\n\n- `search-apify-docs` - Search documentation\n- `fetch-apify-docs` - Get full doc pages\n\nOtherwise, the MCP Server url: `https://mcp.apify.com/?tools=docs`.\n\n## Resources\n\n- [docs.apify.com/llms.txt](https://docs.apify.com/llms.txt) - Apify quick reference documentation\n- [docs.apify.com/llms-full.txt](https://docs.apify.com/llms-full.txt) - Apify complete documentation\n- [https://crawlee.dev/llms.txt](https://crawlee.dev/llms.txt) - Crawlee quick reference documentation\n- [https://crawlee.dev/llms-full.txt](https://crawlee.dev/llms-full.txt) - Crawlee complete documentation\n- [whitepaper.actor](https://raw.githubusercontent.com/apify/actor-whitepaper/refs/heads/master/README.md) - Complete Actor specification\n",
        "skills/apify-actor-development/references/actor-json.md": "# Actor Configuration (actor.json)\n\nThe `.actor/actor.json` file contains the Actor's configuration including metadata, schema references, and platform settings.\n\n## Structure\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"project-name\",\n    \"title\": \"Project Title\",\n    \"description\": \"Actor description\",\n    \"version\": \"0.0\",\n    \"meta\": {\n        \"templateId\": \"template-id\",\n        \"generatedBy\": \"<FILL-IN-TOOL-AND-MODEL>\"\n    },\n    \"input\": \"./input_schema.json\",\n    \"output\": \"./output_schema.json\",\n    \"storages\": {\n        \"dataset\": \"./dataset_schema.json\"\n    },\n    \"dockerfile\": \"../Dockerfile\"\n}\n```\n\n## Example\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"project-cheerio-crawler-javascript\",\n    \"title\": \"Project Cheerio Crawler Javascript\",\n    \"description\": \"Crawlee and Cheerio project in javascript.\",\n    \"version\": \"0.0\",\n    \"meta\": {\n        \"templateId\": \"js-crawlee-cheerio\",\n        \"generatedBy\": \"Claude Code with Claude Sonnet 4.5\"\n    },\n    \"input\": \"./input_schema.json\",\n    \"output\": \"./output_schema.json\",\n    \"storages\": {\n        \"dataset\": \"./dataset_schema.json\"\n    },\n    \"dockerfile\": \"../Dockerfile\"\n}\n```\n\n## Properties\n\n- `actorSpecification` (integer, required) - Version of actor specification (currently 1)\n- `name` (string, required) - Actor identifier (lowercase, hyphens allowed)\n- `title` (string, required) - Human-readable title displayed in UI\n- `description` (string, optional) - Actor description for marketplace\n- `version` (string, required) - Semantic version number\n- `meta` (object, optional) - Metadata about actor generation\n  - `templateId` (string) - ID of template used to create the actor\n  - `generatedBy` (string) - Tool and model name that generated/modified the actor (e.g., \"Claude Code with Claude Sonnet 4.5\")\n- `input` (string, optional) - Path to input schema file\n- `output` (string, optional) - Path to output schema file\n- `storages` (object, optional) - Storage schema references\n  - `dataset` (string) - Path to dataset schema file\n  - `keyValueStore` (string) - Path to key-value store schema file\n- `dockerfile` (string, optional) - Path to Dockerfile\n\n**Important:** Always fill in the `generatedBy` property with the tool and model you're currently using (e.g., \"Claude Code with Claude Sonnet 4.5\") to help Apify improve documentation.\n",
        "skills/apify-actor-development/references/dataset-schema.md": "# Dataset Schema Reference\n\nThe dataset schema defines how your Actor's output data is structured, transformed, and displayed in the Output tab in the Apify Console.\n\n## Examples\n\n### JavaScript and TypeScript\n\nConsider an example Actor that calls `Actor.pushData()` to store data into dataset:\n\n```javascript\nimport { Actor } from 'apify';\n// Initialize the JavaScript SDK\nawait Actor.init();\n\n/**\n * Actor code\n */\nawait Actor.pushData({\n    numericField: 10,\n    pictureUrl: 'https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png',\n    linkUrl: 'https://google.com',\n    textField: 'Google',\n    booleanField: true,\n    dateField: new Date(),\n    arrayField: ['#hello', '#world'],\n    objectField: {},\n});\n\n// Exit successfully\nawait Actor.exit();\n```\n\n### Python\n\nConsider an example Actor that calls `Actor.push_data()` to store data into dataset:\n\n```python\n# Dataset push example (Python)\nimport asyncio\nfrom datetime import datetime\nfrom apify import Actor\n\nasync def main():\n    await Actor.init()\n\n    # Actor code\n    await Actor.push_data({\n        'numericField': 10,\n        'pictureUrl': 'https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png',\n        'linkUrl': 'https://google.com',\n        'textField': 'Google',\n        'booleanField': True,\n        'dateField': datetime.now().isoformat(),\n        'arrayField': ['#hello', '#world'],\n        'objectField': {},\n    })\n\n    # Exit successfully\n    await Actor.exit()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## Configuration\n\nTo set up the Actor's output tab UI, reference a dataset schema file in `.actor/actor.json`:\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"book-library-scraper\",\n    \"title\": \"Book Library Scraper\",\n    \"version\": \"1.0.0\",\n    \"storages\": {\n        \"dataset\": \"./dataset_schema.json\"\n    }\n}\n```\n\nThen create the dataset schema in `.actor/dataset_schema.json`:\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"fields\": {},\n    \"views\": {\n        \"overview\": {\n            \"title\": \"Overview\",\n            \"transformation\": {\n                \"fields\": [\n                    \"pictureUrl\",\n                    \"linkUrl\",\n                    \"textField\",\n                    \"booleanField\",\n                    \"arrayField\",\n                    \"objectField\",\n                    \"dateField\",\n                    \"numericField\"\n                ]\n            },\n            \"display\": {\n                \"component\": \"table\",\n                \"properties\": {\n                    \"pictureUrl\": {\n                        \"label\": \"Image\",\n                        \"format\": \"image\"\n                    },\n                    \"linkUrl\": {\n                        \"label\": \"Link\",\n                        \"format\": \"link\"\n                    },\n                    \"textField\": {\n                        \"label\": \"Text\",\n                        \"format\": \"text\"\n                    },\n                    \"booleanField\": {\n                        \"label\": \"Boolean\",\n                        \"format\": \"boolean\"\n                    },\n                    \"arrayField\": {\n                        \"label\": \"Array\",\n                        \"format\": \"array\"\n                    },\n                    \"objectField\": {\n                        \"label\": \"Object\",\n                        \"format\": \"object\"\n                    },\n                    \"dateField\": {\n                        \"label\": \"Date\",\n                        \"format\": \"date\"\n                    },\n                    \"numericField\": {\n                        \"label\": \"Number\",\n                        \"format\": \"number\"\n                    }\n                }\n            }\n        }\n    }\n}\n```\n\n## Structure\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"fields\": {},\n    \"views\": {\n        \"<VIEW_NAME>\": {\n            \"title\": \"string (required)\",\n            \"description\": \"string (optional)\",\n            \"transformation\": {\n                \"fields\": [\"string (required)\"],\n                \"unwind\": [\"string (optional)\"],\n                \"flatten\": [\"string (optional)\"],\n                \"omit\": [\"string (optional)\"],\n                \"limit\": \"integer (optional)\",\n                \"desc\": \"boolean (optional)\"\n            },\n            \"display\": {\n                \"component\": \"table (required)\",\n                \"properties\": {\n                    \"<FIELD_NAME>\": {\n                        \"label\": \"string (optional)\",\n                        \"format\": \"text|number|date|link|boolean|image|array|object (optional)\"\n                    }\n                }\n            }\n        }\n    }\n}\n```\n\n## Properties\n\n### Dataset Schema Properties\n\n- `actorSpecification` (integer, required) - Specifies the version of dataset schema structure document (currently only version 1)\n- `fields` (JSONSchema object, required) - Schema of one dataset object (use JsonSchema Draft 2020-12 or compatible)\n- `views` (DatasetView object, required) - Object with API and UI views description\n\n### DatasetView Properties\n\n- `title` (string, required) - Visible in UI Output tab and API\n- `description` (string, optional) - Only available in API response\n- `transformation` (ViewTransformation object, required) - Data transformation applied when loading from Dataset API\n- `display` (ViewDisplay object, required) - Output tab UI visualization definition\n\n### ViewTransformation Properties\n\n- `fields` (string[], required) - Fields to present in output (order matches column order)\n- `unwind` (string[], optional) - Deconstructs nested children into parent object\n- `flatten` (string[], optional) - Transforms nested object into flat structure\n- `omit` (string[], optional) - Removes specified fields from output\n- `limit` (integer, optional) - Maximum number of results (default: all)\n- `desc` (boolean, optional) - Sort order (true = newest first)\n\n### ViewDisplay Properties\n\n- `component` (string, required) - Only `table` is available\n- `properties` (Object, optional) - Keys matching `transformation.fields` with ViewDisplayProperty values\n\n### ViewDisplayProperty Properties\n\n- `label` (string, optional) - Table column header\n- `format` (string, optional) - One of: `text`, `number`, `date`, `link`, `boolean`, `image`, `array`, `object`\n",
        "skills/apify-actor-development/references/input-schema.md": "# Input Schema Reference\n\nThe input schema defines the input parameters for an Actor. It's a JSON object comprising various field types supported by the Apify platform.\n\n## Structure\n\n```json\n{\n    \"title\": \"<INPUT-SCHEMA-TITLE>\",\n    \"type\": \"object\",\n    \"schemaVersion\": 1,\n    \"properties\": {\n        /* define input fields here */\n    },\n    \"required\": []\n}\n```\n\n## Example\n\n```json\n{\n    \"title\": \"E-commerce Product Scraper Input\",\n    \"type\": \"object\",\n    \"schemaVersion\": 1,\n    \"properties\": {\n        \"startUrls\": {\n            \"title\": \"Start URLs\",\n            \"type\": \"array\",\n            \"description\": \"URLs to start scraping from (category pages or product pages)\",\n            \"editor\": \"requestListSources\",\n            \"default\": [{ \"url\": \"https://example.com/category\" }],\n            \"prefill\": [{ \"url\": \"https://example.com/category\" }]\n        },\n        \"followVariants\": {\n            \"title\": \"Follow Product Variants\",\n            \"type\": \"boolean\",\n            \"description\": \"Whether to scrape product variants (different colors, sizes)\",\n            \"default\": true\n        },\n        \"maxRequestsPerCrawl\": {\n            \"title\": \"Max Requests per Crawl\",\n            \"type\": \"integer\",\n            \"description\": \"Maximum number of pages to scrape (0 = unlimited)\",\n            \"default\": 1000,\n            \"minimum\": 0\n        },\n        \"proxyConfiguration\": {\n            \"title\": \"Proxy Configuration\",\n            \"type\": \"object\",\n            \"description\": \"Proxy settings for anti-bot protection\",\n            \"editor\": \"proxy\",\n            \"default\": { \"useApifyProxy\": false }\n        },\n        \"locale\": {\n            \"title\": \"Locale\",\n            \"type\": \"string\",\n            \"description\": \"Language/country code for localized content\",\n            \"default\": \"cs\",\n            \"enum\": [\"cs\", \"en\", \"de\", \"sk\"],\n            \"enumTitles\": [\"Czech\", \"English\", \"German\", \"Slovak\"]\n        }\n    },\n    \"required\": [\"startUrls\"]\n}\n```\n",
        "skills/apify-actor-development/references/key-value-store-schema.md": "# Key-Value Store Schema Reference\n\nThe key-value store schema organizes keys into logical groups called collections for easier data management.\n\n## Examples\n\n### JavaScript and TypeScript\n\nConsider an example Actor that calls `Actor.setValue()` to save records into the key-value store:\n\n```javascript\nimport { Actor } from 'apify';\n// Initialize the JavaScript SDK\nawait Actor.init();\n\n/**\n * Actor code\n */\nawait Actor.setValue('document-1', 'my text data', { contentType: 'text/plain' });\n\nawait Actor.setValue(`image-${imageID}`, imageBuffer, { contentType: 'image/jpeg' });\n\n// Exit successfully\nawait Actor.exit();\n```\n\n### Python\n\nConsider an example Actor that calls `Actor.set_value()` to save records into the key-value store:\n\n```python\n# Key-Value Store set example (Python)\nimport asyncio\nfrom apify import Actor\n\nasync def main():\n    await Actor.init()\n\n    # Actor code\n    await Actor.set_value('document-1', 'my text data', content_type='text/plain')\n\n    image_id = '123'          # example placeholder\n    image_buffer = b'...'     # bytes buffer with image data\n    await Actor.set_value(f'image-{image_id}', image_buffer, content_type='image/jpeg')\n\n    # Exit successfully\n    await Actor.exit()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## Configuration\n\nTo configure the key-value store schema, reference a schema file in `.actor/actor.json`:\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"data-collector\",\n    \"title\": \"Data Collector\",\n    \"version\": \"1.0.0\",\n    \"storages\": {\n        \"keyValueStore\": \"./key_value_store_schema.json\"\n    }\n}\n```\n\nThen create the key-value store schema in `.actor/key_value_store_schema.json`:\n\n```json\n{\n    \"actorKeyValueStoreSchemaVersion\": 1,\n    \"title\": \"Key-Value Store Schema\",\n    \"collections\": {\n        \"documents\": {\n            \"title\": \"Documents\",\n            \"description\": \"Text documents stored by the Actor\",\n            \"keyPrefix\": \"document-\"\n        },\n        \"images\": {\n            \"title\": \"Images\",\n            \"description\": \"Images stored by the Actor\",\n            \"keyPrefix\": \"image-\",\n            \"contentTypes\": [\"image/jpeg\"]\n        }\n    }\n}\n```\n\n## Structure\n\n```json\n{\n    \"actorKeyValueStoreSchemaVersion\": 1,\n    \"title\": \"string (required)\",\n    \"description\": \"string (optional)\",\n    \"collections\": {\n        \"<COLLECTION_NAME>\": {\n            \"title\": \"string (required)\",\n            \"description\": \"string (optional)\",\n            \"key\": \"string (conditional - use key OR keyPrefix)\",\n            \"keyPrefix\": \"string (conditional - use key OR keyPrefix)\",\n            \"contentTypes\": [\"string (optional)\"],\n            \"jsonSchema\": \"object (optional)\"\n        }\n    }\n}\n```\n\n## Properties\n\n### Key-Value Store Schema Properties\n\n- `actorKeyValueStoreSchemaVersion` (integer, required) - Version of key-value store schema structure document (currently only version 1)\n- `title` (string, required) - Title of the schema\n- `description` (string, optional) - Description of the schema\n- `collections` (Object, required) - Object where each key is a collection ID and value is a Collection object\n\n### Collection Properties\n\n- `title` (string, required) - Collection title shown in UI tabs\n- `description` (string, optional) - Description appearing in UI tooltips\n- `key` (string, conditional) - Single specific key for this collection\n- `keyPrefix` (string, conditional) - Prefix for keys included in this collection\n- `contentTypes` (string[], optional) - Allowed content types for validation\n- `jsonSchema` (object, optional) - JSON Schema Draft 07 format for `application/json` content type validation\n\nEither `key` or `keyPrefix` must be specified for each collection, but not both.\n",
        "skills/apify-actor-development/references/logging.md": "# Actor Logging Reference\n\n## JavaScript and TypeScript\n\n**ALWAYS use the `apify/log` package for logging** - This package contains critical security logic including censoring sensitive data (Apify tokens, API keys, credentials) to prevent accidental exposure in logs.\n\n### Available Log Levels in `apify/log`\n\nThe Apify log package provides the following methods for logging:\n\n- `log.debug()` - Debug level logs (detailed diagnostic information)\n- `log.info()` - Info level logs (general informational messages)\n- `log.warning()` - Warning level logs (warning messages for potentially problematic situations)\n- `log.warningOnce()` - Warning level logs (same warning message logged only once)\n- `log.error()` - Error level logs (error messages for failures)\n- `log.exception()` - Exception level logs (for exceptions with stack traces)\n- `log.perf()` - Performance level logs (performance metrics and timing information)\n- `log.deprecated()` - Deprecation level logs (warnings about deprecated code)\n- `log.softFail()` - Soft failure logs (non-critical failures that don't stop execution, e.g., input validation errors, skipped items)\n- `log.internal()` - Internal level logs (internal/system messages)\n\n### Best Practices\n\n- Use `log.debug()` for detailed operation-level diagnostics (inside functions)\n- Use `log.info()` for general informational messages (API requests, successful operations)\n- Use `log.warning()` for potentially problematic situations (validation failures, unexpected states)\n- Use `log.error()` for actual errors and failures\n- Use `log.exception()` for caught exceptions with stack traces\n\n## Python\n\n**ALWAYS use `Actor.log` for logging** - This logger contains critical security logic including censoring sensitive data (Apify tokens, API keys, credentials) to prevent accidental exposure in logs.\n\n### Available Log Levels\n\nThe Apify Actor logger provides the following methods for logging:\n\n- `Actor.log.debug()` - Debug level logs (detailed diagnostic information)\n- `Actor.log.info()` - Info level logs (general informational messages)\n- `Actor.log.warning()` - Warning level logs (warning messages for potentially problematic situations)\n- `Actor.log.error()` - Error level logs (error messages for failures)\n- `Actor.log.exception()` - Exception level logs (for exceptions with stack traces)\n\n### Best Practices\n\n- Use `Actor.log.debug()` for detailed operation-level diagnostics (inside functions)\n- Use `Actor.log.info()` for general informational messages (API requests, successful operations)\n- Use `Actor.log.warning()` for potentially problematic situations (validation failures, unexpected states)\n- Use `Actor.log.error()` for actual errors and failures\n- Use `Actor.log.exception()` for caught exceptions with stack traces\n",
        "skills/apify-actor-development/references/output-schema.md": "# Output Schema Reference\n\nThe Actor output schema builds upon the schemas for the dataset and key-value store. It specifies where an Actor stores its output and defines templates for accessing that output. Apify Console uses these output definitions to display run results.\n\n## Structure\n\n```json\n{\n    \"actorOutputSchemaVersion\": 1,\n    \"title\": \"<OUTPUT-SCHEMA-TITLE>\",\n    \"properties\": {\n        /* define your outputs here */\n    }\n}\n```\n\n## Example\n\n```json\n{\n    \"actorOutputSchemaVersion\": 1,\n    \"title\": \"Output schema of the files scraper\",\n    \"properties\": {\n        \"files\": {\n            \"type\": \"string\",\n            \"title\": \"Files\",\n            \"template\": \"{{links.apiDefaultKeyValueStoreUrl}}/keys\"\n        },\n        \"dataset\": {\n            \"type\": \"string\",\n            \"title\": \"Dataset\",\n            \"template\": \"{{links.apiDefaultDatasetUrl}}/items\"\n        }\n    }\n}\n```\n\n## Output Schema Template Variables\n\n- `links` (object) - Contains quick links to most commonly used URLs\n- `links.publicRunUrl` (string) - Public run url in format `https://console.apify.com/view/runs/:runId`\n- `links.consoleRunUrl` (string) - Console run url in format `https://console.apify.com/actors/runs/:runId`\n- `links.apiRunUrl` (string) - API run url in format `https://api.apify.com/v2/actor-runs/:runId`\n- `links.apiDefaultDatasetUrl` (string) - API url of default dataset in format `https://api.apify.com/v2/datasets/:defaultDatasetId`\n- `links.apiDefaultKeyValueStoreUrl` (string) - API url of default key-value store in format `https://api.apify.com/v2/key-value-stores/:defaultKeyValueStoreId`\n- `links.containerRunUrl` (string) - URL of a webserver running inside the run in format `https://<containerId>.runs.apify.net/`\n- `run` (object) - Contains information about the run same as it is returned from the `GET Run` API endpoint\n- `run.defaultDatasetId` (string) - ID of the default dataset\n- `run.defaultKeyValueStoreId` (string) - ID of the default key-value store\n",
        "skills/apify-actor-development/references/standby-mode.md": "# Actor Standby Mode Reference\n\n## JavaScript and TypeScript\n\n- **NEVER disable standby mode (`usesStandbyMode: false`) in `.actor/actor.json` without explicit permission** - Actor Standby mode solves this problem by letting you have the Actor ready in the background, waiting for the incoming HTTP requests. In a sense, the Actor behaves like a real-time web server or standard API server instead of running the logic once to process everything in batch. Always keep `usesStandbyMode: true` unless there is a specific documented reason to disable it\n- **ALWAYS implement readiness probe handler for standby Actors** - Handle the `x-apify-container-server-readiness-probe` header at GET / endpoint to ensure proper Actor lifecycle management\n\nYou can recognize a standby Actor by checking the `usesStandbyMode` property in `.actor/actor.json`. Only implement the readiness probe if this property is set to `true`.\n\n### Readiness Probe Implementation Example\n\n```javascript\n// Apify standby readiness probe at root path\napp.get('/', (req, res) => {\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\n    if (req.headers['x-apify-container-server-readiness-probe']) {\n        res.end('Readiness probe OK\\n');\n    } else {\n        res.end('Actor is ready\\n');\n    }\n});\n```\n\nKey points:\n\n- Detect the `x-apify-container-server-readiness-probe` header in incoming requests\n- Respond with HTTP 200 status code for both readiness probe and normal requests\n- This enables proper Actor lifecycle management in standby mode\n\n## Python\n\n- **NEVER disable standby mode (`usesStandbyMode: false`) in `.actor/actor.json` without explicit permission** - Actor Standby mode solves this problem by letting you have the Actor ready in the background, waiting for the incoming HTTP requests. In a sense, the Actor behaves like a real-time web server or standard API server instead of running the logic once to process everything in batch. Always keep `usesStandbyMode: true` unless there is a specific documented reason to disable it\n- **ALWAYS implement readiness probe handler for standby Actors** - Handle the `x-apify-container-server-readiness-probe` header at GET / endpoint to ensure proper Actor lifecycle management\n\nYou can recognize a standby Actor by checking the `usesStandbyMode` property in `.actor/actor.json`. Only implement the readiness probe if this property is set to `true`.\n\n### Readiness Probe Implementation Example\n\n```python\n# Apify standby readiness probe\nfrom http.server import SimpleHTTPRequestHandler\n\nclass GetHandler(SimpleHTTPRequestHandler):\n    def do_GET(self):\n        # Handle Apify standby readiness probe\n        if 'x-apify-container-server-readiness-probe' in self.headers:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Readiness probe OK')\n            return\n\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(b'Actor is ready')\n```\n\nKey points:\n\n- Detect the `x-apify-container-server-readiness-probe` header in incoming requests\n- Respond with HTTP 200 status code for both readiness probe and normal requests\n- This enables proper Actor lifecycle management in standby mode\n",
        "skills/apify-actorization/SKILL.md": "---\nname: apify-actorization\ndescription: Convert existing projects into Apify Actors - serverless cloud programs. Actorize JavaScript/TypeScript (SDK with Actor.init/exit), Python (async context manager), or any language (CLI wrapper). Use when migrating code to Apify, wrapping CLI tools as Actors, or adding Actor SDK to existing projects.\n---\n\n# Apify Actorization\n\nActorization converts existing software into reusable serverless applications compatible with the Apify platform. Actors are programs packaged as Docker images that accept well-defined JSON input, perform an action, and optionally produce structured JSON output.\n\n## Quick Start\n\n1. Run `apify init` in project root\n2. Wrap code with SDK lifecycle (see language-specific section below)\n3. Configure `.actor/input_schema.json`\n4. Test with `apify run --input '{\"key\": \"value\"}'`\n5. Deploy with `apify push`\n\n## When to Use This Skill\n\n- Converting an existing project to run on Apify platform\n- Adding Apify SDK integration to a project\n- Wrapping a CLI tool or script as an Actor\n- Migrating a Crawlee project to Apify\n\n## Prerequisites\n\nVerify `apify` CLI is installed:\n\n```bash\napify --help\n```\n\nIf not installed:\n\n```bash\ncurl -fsSL https://apify.com/install-cli.sh | bash\n\n# Or (Mac): brew install apify-cli\n# Or (Windows): irm https://apify.com/install-cli.ps1 | iex\n# Or: npm install -g apify-cli\n```\n\nVerify CLI is logged in:\n\n```bash\napify info  # Should return your username\n```\n\nIf not logged in, check if `APIFY_TOKEN` environment variable is defined. If not, ask the user to generate one at https://console.apify.com/settings/integrations, then:\n\n```bash\napify login -t $APIFY_TOKEN\n```\n\n## Actorization Checklist\n\nCopy this checklist to track progress:\n\n- [ ] Step 1: Analyze project (language, entry point, inputs, outputs)\n- [ ] Step 2: Run `apify init` to create Actor structure\n- [ ] Step 3: Apply language-specific SDK integration\n- [ ] Step 4: Configure `.actor/input_schema.json`\n- [ ] Step 5: Configure `.actor/output_schema.json` (if applicable)\n- [ ] Step 6: Update `.actor/actor.json` metadata\n- [ ] Step 7: Test locally with `apify run`\n- [ ] Step 8: Deploy with `apify push`\n\n## Step 1: Analyze the Project\n\nBefore making changes, understand the project:\n\n1. **Identify the language** - JavaScript/TypeScript, Python, or other\n2. **Find the entry point** - The main file that starts execution\n3. **Identify inputs** - Command-line arguments, environment variables, config files\n4. **Identify outputs** - Files, console output, API responses\n5. **Check for state** - Does it need to persist data between runs?\n\n## Step 2: Initialize Actor Structure\n\nRun in the project root:\n\n```bash\napify init\n```\n\nThis creates:\n- `.actor/actor.json` - Actor configuration and metadata\n- `.actor/input_schema.json` - Input definition for the Apify Console\n- `Dockerfile` (if not present) - Container image definition\n\n## Step 3: Apply Language-Specific Changes\n\nChoose based on your project's language:\n\n- **JavaScript/TypeScript**: See [js-ts-actorization.md](references/js-ts-actorization.md)\n- **Python**: See [python-actorization.md](references/python-actorization.md)\n- **Other Languages (CLI-based)**: See [cli-actorization.md](references/cli-actorization.md)\n\n### Quick Reference\n\n| Language | Install | Wrap Code |\n|----------|---------|-----------|\n| JS/TS | `npm install apify` | `await Actor.init()` ... `await Actor.exit()` |\n| Python | `pip install apify` | `async with Actor:` |\n| Other | Use CLI in wrapper script | `apify actor:get-input` / `apify actor:push-data` |\n\n## Steps 4-6: Configure Schemas\n\nSee [schemas-and-output.md](references/schemas-and-output.md) for detailed configuration of:\n- Input schema (`.actor/input_schema.json`)\n- Output schema (`.actor/output_schema.json`)\n- Actor configuration (`.actor/actor.json`)\n- State management (request queues, key-value stores)\n\nValidate schemas against `@apify/json_schemas` npm package.\n\n## Step 7: Test Locally\n\nRun the actor with inline input (for JS/TS and Python actors):\n\n```bash\napify run --input '{\"startUrl\": \"https://example.com\", \"maxItems\": 10}'\n```\n\nOr use an input file:\n\n```bash\napify run --input-file ./test-input.json\n```\n\n**Important:** Always use `apify run`, not `npm start` or `python main.py`. The CLI sets up the proper environment and storage.\n\n## Step 8: Deploy\n\n```bash\napify push\n```\n\nThis uploads and builds your actor on the Apify platform.\n\n## Monetization (Optional)\n\nAfter deploying, you can monetize your actor in the Apify Store. The recommended model is **Pay Per Event (PPE)**:\n\n- Per result/item scraped\n- Per page processed\n- Per API call made\n\nConfigure PPE in the Apify Console under Actor > Monetization. Charge for events in your code with `await Actor.charge('result')`.\n\nOther options: **Rental** (monthly subscription) or **Free** (open source).\n\n## Pre-Deployment Checklist\n\n- [ ] `.actor/actor.json` exists with correct name and description\n- [ ] `.actor/actor.json` validates against `@apify/json_schemas` (`actor.schema.json`)\n- [ ] `.actor/input_schema.json` defines all required inputs\n- [ ] `.actor/input_schema.json` validates against `@apify/json_schemas` (`input.schema.json`)\n- [ ] `.actor/output_schema.json` defines output structure (if applicable)\n- [ ] `.actor/output_schema.json` validates against `@apify/json_schemas` (`output.schema.json`)\n- [ ] `Dockerfile` is present and builds successfully\n- [ ] `Actor.init()` / `Actor.exit()` wraps main code (JS/TS)\n- [ ] `async with Actor:` wraps main code (Python)\n- [ ] Inputs are read via `Actor.getInput()` / `Actor.get_input()`\n- [ ] Outputs use `Actor.pushData()` or key-value store\n- [ ] `apify run` executes successfully with test input\n- [ ] `generatedBy` is set in actor.json meta section\n\n## Apify MCP Tools\n\nIf MCP server is configured, use these tools for documentation:\n\n- `search-apify-docs` - Search documentation\n- `fetch-apify-docs` - Get full doc pages\n\nOtherwise, the MCP Server url: `https://mcp.apify.com/?tools=docs`.\n\n## Resources\n\n- [Actorization Academy](https://docs.apify.com/academy/actorization) - Comprehensive guide\n- [Apify SDK for JavaScript](https://docs.apify.com/sdk/js) - Full SDK reference\n- [Apify SDK for Python](https://docs.apify.com/sdk/python) - Full SDK reference\n- [Apify CLI Reference](https://docs.apify.com/cli) - CLI commands\n- [Actor Specification](https://raw.githubusercontent.com/apify/actor-whitepaper/refs/heads/master/README.md) - Complete specification\n",
        "skills/apify-actorization/references/cli-actorization.md": "# CLI-Based Actorization\n\nFor languages without an SDK (Go, Rust, Java, etc.), create a wrapper script that uses the Apify CLI.\n\n## Create Wrapper Script\n\nCreate `start.sh` in project root:\n\n```bash\n#!/bin/bash\nset -e\n\n# Get input from Apify key-value store\nINPUT=$(apify actor:get-input)\n\n# Parse input values (adjust based on your input schema)\nMY_PARAM=$(echo \"$INPUT\" | jq -r '.myParam // \"default\"')\n\n# Run your application with the input\n./your-application --param \"$MY_PARAM\"\n\n# If your app writes to a file, push it to key-value store\n# apify actor:set-value OUTPUT --contentType application/json < output.json\n\n# Or push structured data to dataset\n# apify actor:push-data '{\"result\": \"value\"}'\n```\n\n## Update Dockerfile\n\nReference the [cli-start template Dockerfile](https://github.com/apify/actor-templates/blob/master/templates/cli-start/Dockerfile) which includes the `ubi` utility for installing binaries from GitHub releases.\n\n```dockerfile\nFROM apify/actor-node:20\n\n# Install ubi for easy GitHub release installation\nRUN curl --silent --location \\\n    https://raw.githubusercontent.com/houseabsolute/ubi/master/bootstrap/bootstrap-ubi.sh | sh\n\n# Install your CLI tool from GitHub releases (example)\n# RUN ubi --project your-org/your-tool --in /usr/local/bin\n\n# Or install apify-cli and jq manually\nRUN npm install -g apify-cli\nRUN apt-get update && apt-get install -y jq\n\n# Copy your application\nCOPY . .\n\n# Build your application if needed\n# RUN ./build.sh\n\n# Make start script executable\nRUN chmod +x start.sh\n\n# Run the wrapper script\nCMD [\"./start.sh\"]\n```\n\n## Testing CLI-Based Actors\n\nFor CLI-based actors (shell wrapper scripts), you may need to test the underlying application directly with mock input, as `apify run` requires a Node.js or Python entry point.\n\nTest your wrapper script locally:\n\n```bash\n# Set up mock input\nexport INPUT='{\"myParam\": \"test-value\"}'\n\n# Run wrapper script\n./start.sh\n```\n\n## CLI Commands Reference\n\n| Command | Description |\n|---------|-------------|\n| `apify actor:get-input` | Get input JSON from key-value store |\n| `apify actor:set-value KEY` | Store value in key-value store |\n| `apify actor:push-data JSON` | Push data to dataset |\n| `apify actor:get-value KEY` | Retrieve value from key-value store |\n",
        "skills/apify-actorization/references/js-ts-actorization.md": "# JavaScript/TypeScript Actorization\n\n## Install the Apify SDK\n\n```bash\nnpm install apify\n```\n\n## Wrap Main Code with Actor Lifecycle\n\n```javascript\nimport { Actor } from 'apify';\n\n// Initialize connection to Apify platform\nawait Actor.init();\n\n// ============================================\n// Your existing code goes here\n// ============================================\n\n// Example: Get input from Apify Console or API\nconst input = await Actor.getInput();\nconsole.log('Input:', input);\n\n// Example: Your crawler or processing logic\n// const crawler = new PlaywrightCrawler({ ... });\n// await crawler.run([input.startUrl]);\n\n// Example: Push results to dataset\n// await Actor.pushData({ result: 'data' });\n\n// ============================================\n// End of your code\n// ============================================\n\n// Graceful shutdown\nawait Actor.exit();\n```\n\n## Key Points\n\n- `Actor.init()` configures storage to use Apify API when running on platform\n- `Actor.exit()` handles graceful shutdown and cleanup\n- Both calls must be awaited\n- Local execution remains unchanged - the SDK automatically detects the environment\n\n## Crawlee Projects\n\nCrawlee projects require minimal changes - just wrap with Actor lifecycle:\n\n```javascript\nimport { Actor } from 'apify';\nimport { PlaywrightCrawler } from 'crawlee';\n\nawait Actor.init();\n\n// Get and validate input\nconst input = await Actor.getInput();\nconst {\n    startUrl = 'https://example.com',\n    maxItems = 100,\n} = input ?? {};\n\nlet itemCount = 0;\n\nconst crawler = new PlaywrightCrawler({\n    requestHandler: async ({ page, request, pushData }) => {\n        if (itemCount >= maxItems) return;\n\n        const title = await page.title();\n        await pushData({ url: request.url, title });\n        itemCount++;\n    },\n});\n\nawait crawler.run([startUrl]);\n\nawait Actor.exit();\n```\n\n## Express/HTTP Servers\n\nFor web servers, use standby mode in actor.json:\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"my-api\",\n    \"usesStandbyMode\": true\n}\n```\n\nThen implement readiness probe. See [standby-mode.md](../../apify-actor-development/references/standby-mode.md).\n\n## Batch Processing Scripts\n\n```javascript\nimport { Actor } from 'apify';\n\nawait Actor.init();\n\nconst input = await Actor.getInput();\nconst items = input.items || [];\n\nfor (const item of items) {\n    const result = processItem(item);\n    await Actor.pushData(result);\n}\n\nawait Actor.exit();\n```\n",
        "skills/apify-actorization/references/python-actorization.md": "# Python Actorization\n\n## Install the Apify SDK\n\n```bash\npip install apify\n```\n\n## Wrap Main Function with Actor Context Manager\n\n```python\nimport asyncio\nfrom apify import Actor\n\nasync def main() -> None:\n    async with Actor:\n        # ============================================\n        # Your existing code goes here\n        # ============================================\n\n        # Example: Get input from Apify Console or API\n        actor_input = await Actor.get_input()\n        print(f'Input: {actor_input}')\n\n        # Example: Your crawler or processing logic\n        # crawler = PlaywrightCrawler(...)\n        # await crawler.run([actor_input.get('startUrl')])\n\n        # Example: Push results to dataset\n        # await Actor.push_data({'result': 'data'})\n\n        # ============================================\n        # End of your code\n        # ============================================\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## Key Points\n\n- `async with Actor:` handles both initialization and cleanup\n- Automatically manages platform event listeners and graceful shutdown\n- Local execution remains unchanged - the SDK automatically detects the environment\n\n## Crawlee Python Projects\n\n```python\nimport asyncio\nfrom apify import Actor\nfrom crawlee.playwright_crawler import PlaywrightCrawler\n\nasync def main() -> None:\n    async with Actor:\n        # Get and validate input\n        actor_input = await Actor.get_input() or {}\n        start_url = actor_input.get('startUrl', 'https://example.com')\n        max_items = actor_input.get('maxItems', 100)\n\n        item_count = 0\n\n        async def request_handler(context):\n            nonlocal item_count\n            if item_count >= max_items:\n                return\n\n            title = await context.page.title()\n            await context.push_data({'url': context.request.url, 'title': title})\n            item_count += 1\n\n        crawler = PlaywrightCrawler(request_handler=request_handler)\n        await crawler.run([start_url])\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## Batch Processing Scripts\n\n```python\nimport asyncio\nfrom apify import Actor\n\nasync def main() -> None:\n    async with Actor:\n        actor_input = await Actor.get_input() or {}\n        items = actor_input.get('items', [])\n\n        for item in items:\n            result = process_item(item)\n            await Actor.push_data(result)\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n",
        "skills/apify-actorization/references/schemas-and-output.md": "# Schemas and Output Configuration\n\n## Input Schema\n\nMap your application's inputs to `.actor/input_schema.json`. Validate against the JSON Schema from the `@apify/json_schemas` npm package (`input.schema.json`).\n\n```json\n{\n    \"title\": \"My Actor Input\",\n    \"type\": \"object\",\n    \"schemaVersion\": 1,\n    \"properties\": {\n        \"startUrl\": {\n            \"title\": \"Start URL\",\n            \"type\": \"string\",\n            \"description\": \"The URL to start processing from\",\n            \"editor\": \"textfield\",\n            \"prefill\": \"https://example.com\"\n        },\n        \"maxItems\": {\n            \"title\": \"Max Items\",\n            \"type\": \"integer\",\n            \"description\": \"Maximum number of items to process\",\n            \"default\": 100,\n            \"minimum\": 1\n        }\n    },\n    \"required\": [\"startUrl\"]\n}\n```\n\n### Mapping Guidelines\n\n- Command-line arguments → input schema properties\n- Environment variables → input schema or Actor env vars in actor.json\n- Config files → input schema with object/array types\n- Flatten deeply nested structures for better UX\n\n## Output Schema\n\nDefine output structure in `.actor/output_schema.json`. Validate against the JSON Schema from the `@apify/json_schemas` npm package (`output.schema.json`).\n\n### For Table-Like Data (Multiple Items)\n\n- Use `Actor.pushData()` (JS) or `Actor.push_data()` (Python)\n- Each item becomes a row in the dataset\n\n### For Single Files or Blobs\n\n- Use key-value store: `Actor.setValue()` / `Actor.set_value()`\n- Get the public URL and include it in the dataset:\n\n```javascript\n// Store file with public access\nawait Actor.setValue('report.pdf', pdfBuffer, { contentType: 'application/pdf' });\n\n// Get the public URL\nconst storeInfo = await Actor.openKeyValueStore();\nconst publicUrl = `https://api.apify.com/v2/key-value-stores/${storeInfo.id}/records/report.pdf`;\n\n// Include URL in dataset output\nawait Actor.pushData({ reportUrl: publicUrl });\n```\n\n### For Multiple Files with a Common Prefix (Collections)\n\n```javascript\n// Store multiple files with a prefix\nfor (const [name, data] of files) {\n    await Actor.setValue(`screenshots/${name}`, data, { contentType: 'image/png' });\n}\n// Files are accessible at: .../records/screenshots%2F{name}\n```\n\n## Actor Configuration (actor.json)\n\nConfigure `.actor/actor.json`. Validate against the JSON Schema from the `@apify/json_schemas` npm package (`actor.schema.json`).\n\n```json\n{\n    \"actorSpecification\": 1,\n    \"name\": \"my-actor\",\n    \"title\": \"My Actor\",\n    \"description\": \"Brief description of what the actor does\",\n    \"version\": \"1.0.0\",\n    \"meta\": {\n        \"templateId\": \"ts_empty\",\n        \"generatedBy\": \"Claude Code with Claude Opus 4.5\"\n    },\n    \"input\": \"./input_schema.json\",\n    \"dockerfile\": \"../Dockerfile\"\n}\n```\n\n**Important:** Fill in the `generatedBy` property with the tool/model used.\n\n## State Management\n\n### Request Queue - For Pausable Task Processing\n\nThe request queue works for any task processing, not just web scraping. Use a dummy URL with custom `uniqueKey` and `userData` for non-URL tasks:\n\n```javascript\nconst requestQueue = await Actor.openRequestQueue();\n\n// Add tasks to the queue (works for any processing, not just URLs)\nawait requestQueue.addRequest({\n    url: 'https://placeholder.local',  // Dummy URL for non-scraping tasks\n    uniqueKey: `task-${taskId}`,       // Unique identifier for deduplication\n    userData: { itemId: 123, action: 'process' },  // Your custom task data\n});\n\n// Process tasks from the queue (with Crawlee)\nconst crawler = new BasicCrawler({\n    requestQueue,\n    requestHandler: async ({ request }) => {\n        const { itemId, action } = request.userData;\n        // Process your task using userData\n        await processTask(itemId, action);\n    },\n});\nawait crawler.run();\n\n// Or manually consume without Crawlee:\nlet request;\nwhile ((request = await requestQueue.fetchNextRequest())) {\n    await processTask(request.userData);\n    await requestQueue.markRequestHandled(request);\n}\n```\n\n### Key-Value Store - For Checkpoint State\n\n```javascript\n// Save state\nawait Actor.setValue('STATE', { processedCount: 100 });\n\n// Restore state on restart\nconst state = await Actor.getValue('STATE') || { processedCount: 0 };\n```\n",
        "skills/apify-audience-analysis/SKILL.md": "---\nname: apify-audience-analysis\ndescription: Understand audience demographics, preferences, behavior patterns, and engagement quality across Facebook, Instagram, YouTube, and TikTok.\n---\n\n# Audience Analysis\n\nAnalyze and understand your audience using Apify Actors to extract follower demographics, engagement patterns, and behavior data from multiple platforms.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Identify audience analysis type (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the analysis script\n- [ ] Step 5: Summarize findings\n```\n\n### Step 1: Identify Audience Analysis Type\n\nSelect the appropriate Actor based on analysis needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Facebook follower demographics | `apify/facebook-followers-following-scraper` | FB followers/following lists |\n| Facebook engagement behavior | `apify/facebook-likes-scraper` | FB post likes analysis |\n| Facebook video audience | `apify/facebook-reels-scraper` | FB Reels viewers |\n| Facebook comment analysis | `apify/facebook-comments-scraper` | FB post/video comments |\n| Facebook content engagement | `apify/facebook-posts-scraper` | FB post engagement metrics |\n| Instagram audience sizing | `apify/instagram-profile-scraper` | IG profile demographics |\n| Instagram location-based | `apify/instagram-search-scraper` | IG geo-tagged audience |\n| Instagram tagged network | `apify/instagram-tagged-scraper` | IG tag network analysis |\n| Instagram comprehensive | `apify/instagram-scraper` | Full IG audience data |\n| Instagram API-based | `apify/instagram-api-scraper` | IG API access |\n| Instagram follower counts | `apify/instagram-followers-count-scraper` | IG follower tracking |\n| Instagram comment export | `apify/export-instagram-comments-posts` | IG comment bulk export |\n| Instagram comment analysis | `apify/instagram-comment-scraper` | IG comment sentiment |\n| YouTube viewer feedback | `streamers/youtube-comments-scraper` | YT comment analysis |\n| YouTube channel audience | `streamers/youtube-channel-scraper` | YT channel subscribers |\n| TikTok follower demographics | `clockworks/tiktok-followers-scraper` | TT follower lists |\n| TikTok profile analysis | `clockworks/tiktok-profile-scraper` | TT profile demographics |\n| TikTok comment analysis | `clockworks/tiktok-comments-scraper` | TT comment engagement |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `apify/facebook-followers-following-scraper`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Findings\n\nAfter completion, report:\n- Number of audience members/profiles analyzed\n- File location and name\n- Key demographic insights\n- Suggested next steps (deeper analysis, segmentation)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-brand-reputation-monitoring/SKILL.md": "---\nname: apify-brand-reputation-monitoring\ndescription: Track reviews, ratings, sentiment, and brand mentions across Google Maps, Booking.com, TripAdvisor, Facebook, Instagram, YouTube, and TikTok. Use when user asks to monitor brand reputation, analyze reviews, track mentions, or gather customer feedback.\n---\n\n# Brand Reputation Monitoring\n\nScrape reviews, ratings, and brand mentions from multiple platforms using Apify Actors.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Determine data source (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the monitoring script\n- [ ] Step 5: Summarize results\n```\n\n### Step 1: Determine Data Source\n\nSelect the appropriate Actor based on user needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Google Maps reviews | `compass/crawler-google-places` | Business reviews, ratings |\n| Google Maps review export | `compass/Google-Maps-Reviews-Scraper` | Dedicated review scraping |\n| Booking.com hotels | `voyager/booking-scraper` | Hotel data, scores |\n| Booking.com reviews | `voyager/booking-reviews-scraper` | Detailed hotel reviews |\n| TripAdvisor reviews | `maxcopell/tripadvisor-reviews` | Attraction/restaurant reviews |\n| Facebook reviews | `apify/facebook-reviews-scraper` | Page reviews |\n| Facebook comments | `apify/facebook-comments-scraper` | Post comment monitoring |\n| Facebook page metrics | `apify/facebook-pages-scraper` | Page ratings overview |\n| Facebook reactions | `apify/facebook-likes-scraper` | Reaction type analysis |\n| Instagram comments | `apify/instagram-comment-scraper` | Comment sentiment |\n| Instagram hashtags | `apify/instagram-hashtag-scraper` | Brand hashtag monitoring |\n| Instagram search | `apify/instagram-search-scraper` | Brand mention discovery |\n| Instagram tagged posts | `apify/instagram-tagged-scraper` | Brand tag tracking |\n| Instagram export | `apify/export-instagram-comments-posts` | Bulk comment export |\n| Instagram comprehensive | `apify/instagram-scraper` | Full Instagram monitoring |\n| Instagram API | `apify/instagram-api-scraper` | API-based monitoring |\n| YouTube comments | `streamers/youtube-comments-scraper` | Video comment sentiment |\n| TikTok comments | `clockworks/tiktok-comments-scraper` | TikTok sentiment |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `compass/crawler-google-places`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Results\n\nAfter completion, report:\n- Number of reviews/mentions found\n- File location and name\n- Key fields available\n- Suggested next steps (sentiment analysis, filtering)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-competitor-intelligence/SKILL.md": "---\nname: apify-competitor-intelligence\ndescription: Analyze competitor strategies, content, pricing, ads, and market positioning across Google Maps, Booking.com, Facebook, Instagram, YouTube, and TikTok.\n---\n\n# Competitor Intelligence\n\nAnalyze competitors using Apify Actors to extract data from multiple platforms.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Identify competitor analysis type (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the analysis script\n- [ ] Step 5: Summarize findings\n```\n\n### Step 1: Identify Competitor Analysis Type\n\nSelect the appropriate Actor based on analysis needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Competitor business data | `compass/crawler-google-places` | Location analysis |\n| Competitor contact discovery | `poidata/google-maps-email-extractor` | Email extraction |\n| Feature benchmarking | `compass/google-maps-extractor` | Detailed business data |\n| Competitor review analysis | `compass/Google-Maps-Reviews-Scraper` | Review comparison |\n| Hotel competitor data | `voyager/booking-scraper` | Hotel benchmarking |\n| Hotel review comparison | `voyager/booking-reviews-scraper` | Review analysis |\n| Competitor ad strategies | `apify/facebook-ads-scraper` | Ad creative analysis |\n| Competitor page metrics | `apify/facebook-pages-scraper` | Page performance |\n| Competitor content analysis | `apify/facebook-posts-scraper` | Post strategies |\n| Competitor reels performance | `apify/facebook-reels-scraper` | Reels analysis |\n| Competitor audience analysis | `apify/facebook-comments-scraper` | Comment sentiment |\n| Competitor event monitoring | `apify/facebook-events-scraper` | Event tracking |\n| Competitor audience overlap | `apify/facebook-followers-following-scraper` | Follower analysis |\n| Competitor review benchmarking | `apify/facebook-reviews-scraper` | Review comparison |\n| Competitor ad monitoring | `apify/facebook-search-scraper` | Ad discovery |\n| Competitor profile metrics | `apify/instagram-profile-scraper` | Profile analysis |\n| Competitor content monitoring | `apify/instagram-post-scraper` | Post tracking |\n| Competitor engagement analysis | `apify/instagram-comment-scraper` | Comment analysis |\n| Competitor reel performance | `apify/instagram-reel-scraper` | Reel metrics |\n| Competitor growth tracking | `apify/instagram-followers-count-scraper` | Follower tracking |\n| Comprehensive competitor data | `apify/instagram-scraper` | Full analysis |\n| API-based competitor analysis | `apify/instagram-api-scraper` | API access |\n| Competitor video analysis | `streamers/youtube-scraper` | Video metrics |\n| Competitor sentiment analysis | `streamers/youtube-comments-scraper` | Comment sentiment |\n| Competitor channel metrics | `streamers/youtube-channel-scraper` | Channel analysis |\n| TikTok competitor analysis | `clockworks/tiktok-scraper` | TikTok data |\n| Competitor video strategies | `clockworks/tiktok-video-scraper` | Video analysis |\n| Competitor TikTok profiles | `clockworks/tiktok-profile-scraper` | Profile data |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `compass/crawler-google-places`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Findings\n\nAfter completion, report:\n- Number of competitors analyzed\n- File location and name\n- Key competitive insights\n- Suggested next steps (deeper analysis, benchmarking)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-content-analytics/SKILL.md": "---\nname: apify-content-analytics\ndescription: Track engagement metrics, measure campaign ROI, and analyze content performance across Instagram, Facebook, YouTube, and TikTok.\n---\n\n# Content Analytics\n\nTrack and analyze content performance using Apify Actors to extract engagement metrics from multiple platforms.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Identify content analytics type (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the analytics script\n- [ ] Step 5: Summarize findings\n```\n\n### Step 1: Identify Content Analytics Type\n\nSelect the appropriate Actor based on analytics needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Post engagement metrics | `apify/instagram-post-scraper` | Post performance |\n| Reel performance | `apify/instagram-reel-scraper` | Reel analytics |\n| Follower growth tracking | `apify/instagram-followers-count-scraper` | Growth metrics |\n| Comment engagement | `apify/instagram-comment-scraper` | Comment analysis |\n| Hashtag performance | `apify/instagram-hashtag-scraper` | Branded hashtags |\n| Mention tracking | `apify/instagram-tagged-scraper` | Tag tracking |\n| Comprehensive metrics | `apify/instagram-scraper` | Full data |\n| API-based analytics | `apify/instagram-api-scraper` | API access |\n| Facebook post performance | `apify/facebook-posts-scraper` | Post metrics |\n| Reaction analysis | `apify/facebook-likes-scraper` | Engagement types |\n| Facebook Reels metrics | `apify/facebook-reels-scraper` | Reels performance |\n| Ad performance tracking | `apify/facebook-ads-scraper` | Ad analytics |\n| Facebook comment analysis | `apify/facebook-comments-scraper` | Comment engagement |\n| Page performance audit | `apify/facebook-pages-scraper` | Page metrics |\n| YouTube video metrics | `streamers/youtube-scraper` | Video performance |\n| YouTube Shorts analytics | `streamers/youtube-shorts-scraper` | Shorts performance |\n| TikTok content metrics | `clockworks/tiktok-scraper` | TikTok analytics |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `apify/instagram-post-scraper`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Findings\n\nAfter completion, report:\n- Number of content pieces analyzed\n- File location and name\n- Key performance insights\n- Suggested next steps (deeper analysis, content optimization)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-influencer-discovery/SKILL.md": "---\nname: apify-influencer-discovery\ndescription: Find and evaluate influencers for brand partnerships, verify authenticity, and track collaboration performance across Instagram, Facebook, YouTube, and TikTok.\n---\n\n# Influencer Discovery\n\nDiscover and analyze influencers across multiple platforms using Apify Actors.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Determine discovery source (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the discovery script\n- [ ] Step 5: Summarize results\n```\n\n### Step 1: Determine Discovery Source\n\nSelect the appropriate Actor based on user needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Influencer profiles | `apify/instagram-profile-scraper` | Profile metrics, bio, follower counts |\n| Find by hashtag | `apify/instagram-hashtag-scraper` | Discover influencers using specific hashtags |\n| Reel engagement | `apify/instagram-reel-scraper` | Analyze reel performance and engagement |\n| Discovery by niche | `apify/instagram-search-scraper` | Search for influencers by keyword/niche |\n| Brand mentions | `apify/instagram-tagged-scraper` | Track who tags brands/products |\n| Comprehensive data | `apify/instagram-scraper` | Full profile, posts, comments analysis |\n| API-based discovery | `apify/instagram-api-scraper` | Fast API-based data extraction |\n| Engagement analysis | `apify/export-instagram-comments-posts` | Export comments for sentiment analysis |\n| Facebook content | `apify/facebook-posts-scraper` | Analyze Facebook post performance |\n| Micro-influencers | `apify/facebook-groups-scraper` | Find influencers in niche groups |\n| Influential pages | `apify/facebook-search-scraper` | Search for influential pages |\n| YouTube creators | `streamers/youtube-channel-scraper` | Channel metrics and subscriber data |\n| TikTok influencers | `clockworks/tiktok-scraper` | Comprehensive TikTok data extraction |\n| TikTok (free) | `clockworks/free-tiktok-scraper` | Free TikTok data extractor |\n| Live streamers | `clockworks/tiktok-live-scraper` | Discover live streaming influencers |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `apify/instagram-profile-scraper`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Results\n\nAfter completion, report:\n- Number of influencers found\n- File location and name\n- Key metrics available (followers, engagement rate, etc.)\n- Suggested next steps (filtering, outreach, deeper analysis)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-lead-generation/SKILL.md": "---\nname: apify-lead-generation\ndescription: Generates B2B/B2C leads by scraping Google Maps, websites, Instagram, TikTok, Facebook, LinkedIn, YouTube, and Google Search. Use when user asks to find leads, prospects, businesses, build lead lists, enrich contacts, or scrape profiles for sales outreach.\n---\n\n# Lead Generation\n\nScrape leads from multiple platforms using Apify Actors.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Determine lead source (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the lead finder script\n- [ ] Step 5: Summarize results\n```\n\n### Step 1: Determine Lead Source\n\nSelect the appropriate Actor based on user needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Local businesses | `compass/crawler-google-places` | Restaurants, gyms, shops |\n| Contact enrichment | `vdrmota/contact-info-scraper` | Emails, phones from URLs |\n| Instagram profiles | `apify/instagram-profile-scraper` | Influencer discovery |\n| Instagram posts/comments | `apify/instagram-scraper` | Posts, comments, hashtags, places |\n| Instagram search | `apify/instagram-search-scraper` | Places, users, hashtags discovery |\n| TikTok videos/hashtags | `clockworks/tiktok-scraper` | Comprehensive TikTok data extraction |\n| TikTok hashtags/profiles | `clockworks/free-tiktok-scraper` | Free TikTok data extractor |\n| TikTok user search | `clockworks/tiktok-user-search-scraper` | Find users by keywords |\n| TikTok profiles | `clockworks/tiktok-profile-scraper` | Creator outreach |\n| TikTok followers/following | `clockworks/tiktok-followers-scraper` | Audience analysis, segmentation |\n| Facebook pages | `apify/facebook-pages-scraper` | Business contacts |\n| Facebook page contacts | `apify/facebook-page-contact-information` | Extract emails, phones, addresses |\n| Facebook groups | `apify/facebook-groups-scraper` | Buying intent signals |\n| Facebook events | `apify/facebook-events-scraper` | Event networking, partnerships |\n| Google Search | `apify/google-search-scraper` | Broad lead discovery |\n| YouTube channels | `streamers/youtube-scraper` | Creator partnerships |\n| Google Maps emails | `poidata/google-maps-email-extractor` | Direct email extraction |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `compass/crawler-google-places`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Results\n\nAfter completion, report:\n- Number of leads found\n- File location and name\n- Key fields available\n- Suggested next steps (filtering, enrichment)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-market-research/SKILL.md": "---\nname: apify-market-research\ndescription: Analyze market conditions, geographic opportunities, pricing, consumer behavior, and product validation across Google Maps, Facebook, Instagram, Booking.com, and TripAdvisor.\n---\n\n# Market Research\n\nConduct market research using Apify Actors to extract data from multiple platforms.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Identify market research type (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the analysis script\n- [ ] Step 5: Summarize findings\n```\n\n### Step 1: Identify Market Research Type\n\nSelect the appropriate Actor based on research needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Market density | `compass/crawler-google-places` | Location analysis |\n| Geospatial analysis | `compass/google-maps-extractor` | Business mapping |\n| Regional interest | `apify/google-trends-scraper` | Trend data |\n| Pricing and demand | `apify/facebook-marketplace-scraper` | Market pricing |\n| Event market | `apify/facebook-events-scraper` | Event analysis |\n| Consumer needs | `apify/facebook-groups-scraper` | Group research |\n| Market landscape | `apify/facebook-pages-scraper` | Business pages |\n| Business density | `apify/facebook-page-contact-information` | Contact data |\n| Cultural insights | `apify/facebook-photos-scraper` | Visual research |\n| Niche targeting | `apify/instagram-hashtag-scraper` | Hashtag research |\n| Hashtag stats | `apify/instagram-hashtag-stats` | Market sizing |\n| Market activity | `apify/instagram-reel-scraper` | Activity analysis |\n| Market intelligence | `apify/instagram-scraper` | Full data |\n| Product launch research | `apify/instagram-api-scraper` | API access |\n| Hospitality market | `voyager/booking-scraper` | Hotel data |\n| Tourism insights | `maxcopell/tripadvisor-reviews` | Review analysis |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `compass/crawler-google-places`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Findings\n\nAfter completion, report:\n- Number of results found\n- File location and name\n- Key market insights\n- Suggested next steps (deeper analysis, validation)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-trend-analysis/SKILL.md": "---\nname: apify-trend-analysis\ndescription: Discover and track emerging trends across Google Trends, Instagram, Facebook, YouTube, and TikTok to inform content strategy.\n---\n\n# Trend Analysis\n\nDiscover and track emerging trends using Apify Actors to extract data from multiple platforms.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Identify trend type (select Actor)\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the analysis script\n- [ ] Step 5: Summarize findings\n```\n\n### Step 1: Identify Trend Type\n\nSelect the appropriate Actor based on research needs:\n\n| User Need | Actor ID | Best For |\n|-----------|----------|----------|\n| Search trends | `apify/google-trends-scraper` | Google Trends data |\n| Hashtag tracking | `apify/instagram-hashtag-scraper` | Hashtag content |\n| Hashtag metrics | `apify/instagram-hashtag-stats` | Performance stats |\n| Visual trends | `apify/instagram-post-scraper` | Post analysis |\n| Trending discovery | `apify/instagram-search-scraper` | Search trends |\n| Comprehensive tracking | `apify/instagram-scraper` | Full data |\n| API-based trends | `apify/instagram-api-scraper` | API access |\n| Engagement trends | `apify/export-instagram-comments-posts` | Comment tracking |\n| Product trends | `apify/facebook-marketplace-scraper` | Marketplace data |\n| Visual analysis | `apify/facebook-photos-scraper` | Photo trends |\n| Community trends | `apify/facebook-groups-scraper` | Group monitoring |\n| YouTube Shorts | `streamers/youtube-shorts-scraper` | Short-form trends |\n| YouTube hashtags | `streamers/youtube-video-scraper-by-hashtag` | Hashtag videos |\n| TikTok hashtags | `clockworks/tiktok-hashtag-scraper` | Hashtag content |\n| Trending sounds | `clockworks/tiktok-sound-scraper` | Audio trends |\n| TikTok ads | `clockworks/tiktok-ads-scraper` | Ad trends |\n| Discover page | `clockworks/tiktok-discover-scraper` | Discover trends |\n| Explore trends | `clockworks/tiktok-explore-scraper` | Explore content |\n| Trending content | `clockworks/tiktok-trends-scraper` | Viral content |\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `apify/google-trends-scraper`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Findings\n\nAfter completion, report:\n- Number of results found\n- File location and name\n- Key trend insights\n- Suggested next steps (deeper analysis, content opportunities)\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n",
        "skills/apify-ultimate-scraper/SKILL.md": "---\nname: apify-ultimate-scraper\ndescription: Universal AI-powered web scraper for any platform. Scrape data from Instagram, Facebook, TikTok, YouTube, Google Maps, Google Search, Google Trends, Booking.com, and TripAdvisor. Use for lead generation, brand monitoring, competitor analysis, influencer discovery, trend research, content analytics, audience analysis, or any data extraction task.\n---\n\n# Universal Web Scraper\n\nAI-driven data extraction from 55+ Actors across all major platforms. This skill automatically selects the best Actor for your task.\n\n## Prerequisites\n(No need to check it upfront)\n\n- `.env` file with `APIFY_TOKEN`\n- Node.js 20.6+ (for native `--env-file` support)\n- `mcpc` CLI tool (for fetching Actor schemas)\n\n## Workflow\n\nCopy this checklist and track progress:\n\n```\nTask Progress:\n- [ ] Step 1: Understand user goal and select Actor\n- [ ] Step 2: Fetch Actor schema via mcpc\n- [ ] Step 3: Ask user preferences (format, filename)\n- [ ] Step 4: Run the scraper script\n- [ ] Step 5: Summarize results and offer follow-ups\n```\n\n### Step 1: Understand User Goal and Select Actor\n\nFirst, understand what the user wants to achieve. Then select the best Actor from the options below.\n\n#### Instagram Actors (12)\n\n| Actor ID | Best For |\n|----------|----------|\n| `apify/instagram-profile-scraper` | Profile data, follower counts, bio info |\n| `apify/instagram-post-scraper` | Individual post details, engagement metrics |\n| `apify/instagram-comment-scraper` | Comment extraction, sentiment analysis |\n| `apify/instagram-hashtag-scraper` | Hashtag content, trending topics |\n| `apify/instagram-hashtag-stats` | Hashtag performance metrics |\n| `apify/instagram-reel-scraper` | Reels content and metrics |\n| `apify/instagram-search-scraper` | Search users, places, hashtags |\n| `apify/instagram-tagged-scraper` | Posts tagged with specific accounts |\n| `apify/instagram-followers-count-scraper` | Follower count tracking |\n| `apify/instagram-scraper` | Comprehensive Instagram data |\n| `apify/instagram-api-scraper` | API-based Instagram access |\n| `apify/export-instagram-comments-posts` | Bulk comment/post export |\n\n#### Facebook Actors (14)\n\n| Actor ID | Best For |\n|----------|----------|\n| `apify/facebook-pages-scraper` | Page data, metrics, contact info |\n| `apify/facebook-page-contact-information` | Emails, phones, addresses from pages |\n| `apify/facebook-posts-scraper` | Post content and engagement |\n| `apify/facebook-comments-scraper` | Comment extraction |\n| `apify/facebook-likes-scraper` | Reaction analysis |\n| `apify/facebook-reviews-scraper` | Page reviews |\n| `apify/facebook-groups-scraper` | Group content and members |\n| `apify/facebook-events-scraper` | Event data |\n| `apify/facebook-ads-scraper` | Ad creative and targeting |\n| `apify/facebook-search-scraper` | Search results |\n| `apify/facebook-reels-scraper` | Reels content |\n| `apify/facebook-photos-scraper` | Photo extraction |\n| `apify/facebook-marketplace-scraper` | Marketplace listings |\n| `apify/facebook-followers-following-scraper` | Follower/following lists |\n\n#### TikTok Actors (14)\n\n| Actor ID | Best For |\n|----------|----------|\n| `clockworks/tiktok-scraper` | Comprehensive TikTok data |\n| `clockworks/free-tiktok-scraper` | Free TikTok extraction |\n| `clockworks/tiktok-profile-scraper` | Profile data |\n| `clockworks/tiktok-video-scraper` | Video details and metrics |\n| `clockworks/tiktok-comments-scraper` | Comment extraction |\n| `clockworks/tiktok-followers-scraper` | Follower lists |\n| `clockworks/tiktok-user-search-scraper` | Find users by keywords |\n| `clockworks/tiktok-hashtag-scraper` | Hashtag content |\n| `clockworks/tiktok-sound-scraper` | Trending sounds |\n| `clockworks/tiktok-ads-scraper` | Ad content |\n| `clockworks/tiktok-discover-scraper` | Discover page content |\n| `clockworks/tiktok-explore-scraper` | Explore content |\n| `clockworks/tiktok-trends-scraper` | Trending content |\n| `clockworks/tiktok-live-scraper` | Live stream data |\n\n#### YouTube Actors (5)\n\n| Actor ID | Best For |\n|----------|----------|\n| `streamers/youtube-scraper` | Video data and metrics |\n| `streamers/youtube-channel-scraper` | Channel information |\n| `streamers/youtube-comments-scraper` | Comment extraction |\n| `streamers/youtube-shorts-scraper` | Shorts content |\n| `streamers/youtube-video-scraper-by-hashtag` | Videos by hashtag |\n\n#### Google Maps Actors (4)\n\n| Actor ID | Best For |\n|----------|----------|\n| `compass/crawler-google-places` | Business listings, ratings, contact info |\n| `compass/google-maps-extractor` | Detailed business data |\n| `compass/Google-Maps-Reviews-Scraper` | Review extraction |\n| `poidata/google-maps-email-extractor` | Email discovery from listings |\n\n#### Other Actors (6)\n\n| Actor ID | Best For |\n|----------|----------|\n| `apify/google-search-scraper` | Google search results |\n| `apify/google-trends-scraper` | Google Trends data |\n| `voyager/booking-scraper` | Booking.com hotel data |\n| `voyager/booking-reviews-scraper` | Booking.com reviews |\n| `maxcopell/tripadvisor-reviews` | TripAdvisor reviews |\n| `vdrmota/contact-info-scraper` | Contact enrichment from URLs |\n\n---\n\n#### Actor Selection by Use Case\n\n| Use Case | Primary Actors |\n|----------|---------------|\n| **Lead Generation** | `compass/crawler-google-places`, `poidata/google-maps-email-extractor`, `vdrmota/contact-info-scraper` |\n| **Influencer Discovery** | `apify/instagram-profile-scraper`, `clockworks/tiktok-profile-scraper`, `streamers/youtube-channel-scraper` |\n| **Brand Monitoring** | `apify/instagram-tagged-scraper`, `apify/instagram-hashtag-scraper`, `compass/Google-Maps-Reviews-Scraper` |\n| **Competitor Analysis** | `apify/facebook-pages-scraper`, `apify/facebook-ads-scraper`, `apify/instagram-profile-scraper` |\n| **Content Analytics** | `apify/instagram-post-scraper`, `clockworks/tiktok-scraper`, `streamers/youtube-scraper` |\n| **Trend Research** | `apify/google-trends-scraper`, `clockworks/tiktok-trends-scraper`, `apify/instagram-hashtag-stats` |\n| **Review Analysis** | `compass/Google-Maps-Reviews-Scraper`, `voyager/booking-reviews-scraper`, `maxcopell/tripadvisor-reviews` |\n| **Audience Analysis** | `apify/instagram-followers-count-scraper`, `clockworks/tiktok-followers-scraper`, `apify/facebook-followers-following-scraper` |\n\n---\n\n#### Multi-Actor Workflows\n\nFor complex tasks, chain multiple Actors:\n\n| Workflow | Step 1 | Step 2 |\n|----------|--------|--------|\n| **Lead enrichment** | `compass/crawler-google-places` → | `vdrmota/contact-info-scraper` |\n| **Influencer vetting** | `apify/instagram-profile-scraper` → | `apify/instagram-comment-scraper` |\n| **Competitor deep-dive** | `apify/facebook-pages-scraper` → | `apify/facebook-posts-scraper` |\n| **Local business analysis** | `compass/crawler-google-places` → | `compass/Google-Maps-Reviews-Scraper` |\n\n#### Can't Find a Suitable Actor?\n\nIf none of the Actors above match the user's request, search the Apify Store directly:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call search-actors keywords:=\"SEARCH_KEYWORDS\" limit:=10 offset:=0 category:=\"\" | jq -r '.content[0].text'\n```\n\nReplace `SEARCH_KEYWORDS` with 1-3 simple terms (e.g., \"LinkedIn profiles\", \"Amazon products\", \"Twitter\").\n\n### Step 2: Fetch Actor Schema\n\nFetch the Actor's input schema and details dynamically using mcpc:\n\n```bash\nexport $(grep APIFY_TOKEN .env | xargs) && mcpc --json mcp.apify.com --header \"Authorization: Bearer $APIFY_TOKEN\" tools-call fetch-actor-details actor:=\"ACTOR_ID\" | jq -r \".content\"\n```\n\nReplace `ACTOR_ID` with the selected Actor (e.g., `compass/crawler-google-places`).\n\nThis returns:\n- Actor description and README\n- Required and optional input parameters\n- Output fields (if available)\n\n### Step 3: Ask User Preferences\n\nBefore running, ask:\n1. **Output format**:\n   - **Quick answer** - Display top few results in chat (no file saved)\n   - **CSV** - Full export with all fields\n   - **JSON** - Full export in JSON format\n2. **Number of results**: Based on character of use case\n\n### Step 4: Run the Script\n\n**Quick answer (display in chat, no file):**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT'\n```\n\n**CSV:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.csv \\\n  --format csv\n```\n\n**JSON:**\n```bash\nnode --env-file=.env ${CLAUDE_PLUGIN_ROOT}/reference/scripts/run_actor.js \\\n  --actor \"ACTOR_ID\" \\\n  --input 'JSON_INPUT' \\\n  --output YYYY-MM-DD_OUTPUT_FILE.json \\\n  --format json\n```\n\n### Step 5: Summarize Results and Offer Follow-ups\n\nAfter completion, report:\n- Number of results found\n- File location and name\n- Key fields available\n- **Suggested follow-up workflows** based on results:\n\n| If User Got | Suggest Next |\n|-------------|--------------|\n| Business listings | Enrich with `vdrmota/contact-info-scraper` or get reviews |\n| Influencer profiles | Analyze engagement with comment scrapers |\n| Competitor pages | Deep-dive with post/ad scrapers |\n| Trend data | Validate with platform-specific hashtag scrapers |\n\n\n## Error Handling\n\n`APIFY_TOKEN not found` - Ask user to create `.env` with `APIFY_TOKEN=your_token`\n`mcpc not found` - Ask user to install `npm install -g @apify/mcpc`\n`Actor not found` - Check Actor ID spelling\n`Run FAILED` - Ask user to check Apify console link in error output\n`Timeout` - Reduce input size or increase `--timeout`\n"
      },
      "plugins": [
        {
          "name": "apify-lead-generation",
          "source": "./skills/apify-lead-generation",
          "skills": "./",
          "description": "Generate B2B/B2C leads by scraping Google Maps, websites, Instagram, TikTok, Facebook, LinkedIn, YouTube, and Google Search using Apify Actors",
          "keywords": [
            "leads",
            "sales",
            "prospecting",
            "b2b",
            "b2c",
            "scraping",
            "apify",
            "google-maps",
            "instagram",
            "tiktok",
            "facebook",
            "linkedin",
            "youtube"
          ],
          "category": "data-extraction",
          "version": "1.1.11",
          "categories": [
            "apify",
            "b2b",
            "b2c",
            "data-extraction",
            "facebook",
            "google-maps",
            "instagram",
            "leads",
            "linkedin",
            "prospecting",
            "sales",
            "scraping",
            "tiktok",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-lead-generation@apify-agent-skills"
          ]
        },
        {
          "name": "apify-brand-reputation-monitoring",
          "source": "./skills/apify-brand-reputation-monitoring",
          "skills": "./",
          "description": "Track reviews, ratings, sentiment, and brand mentions across Google Maps, Booking.com, TripAdvisor, Facebook, Instagram, YouTube, and TikTok",
          "keywords": [
            "reputation",
            "reviews",
            "sentiment",
            "monitoring",
            "brand",
            "ratings",
            "google-maps",
            "booking",
            "tripadvisor",
            "facebook",
            "instagram",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.0.1",
          "categories": [
            "booking",
            "brand",
            "data-extraction",
            "facebook",
            "google-maps",
            "instagram",
            "monitoring",
            "ratings",
            "reputation",
            "reviews",
            "sentiment",
            "tiktok",
            "tripadvisor",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-brand-reputation-monitoring@apify-agent-skills"
          ]
        },
        {
          "name": "apify-competitor-intelligence",
          "source": "./skills/apify-competitor-intelligence",
          "skills": "./",
          "description": "Analyze competitor strategies, content, pricing, ads, and market positioning across Google Maps, Booking.com, Facebook, Instagram, YouTube, and TikTok",
          "keywords": [
            "competitor",
            "intelligence",
            "analysis",
            "benchmarking",
            "strategy",
            "ads",
            "google-maps",
            "booking",
            "facebook",
            "instagram",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.1.1",
          "categories": [
            "ads",
            "analysis",
            "benchmarking",
            "booking",
            "competitor",
            "data-extraction",
            "facebook",
            "google-maps",
            "instagram",
            "intelligence",
            "strategy",
            "tiktok",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-competitor-intelligence@apify-agent-skills"
          ]
        },
        {
          "name": "apify-market-research",
          "source": "./skills/apify-market-research",
          "skills": "./",
          "description": "Analyze market conditions, geographic opportunities, pricing, consumer behavior, and product validation across Google Maps, Facebook, Instagram, Booking.com, and TripAdvisor",
          "keywords": [
            "market",
            "research",
            "analysis",
            "pricing",
            "geographic",
            "validation",
            "trends",
            "google-maps",
            "facebook",
            "instagram",
            "booking",
            "tripadvisor"
          ],
          "category": "data-extraction",
          "version": "1.0.1",
          "categories": [
            "analysis",
            "booking",
            "data-extraction",
            "facebook",
            "geographic",
            "google-maps",
            "instagram",
            "market",
            "pricing",
            "research",
            "trends",
            "tripadvisor",
            "validation"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-market-research@apify-agent-skills"
          ]
        },
        {
          "name": "apify-influencer-discovery",
          "source": "./skills/apify-influencer-discovery",
          "skills": "./",
          "description": "Find and evaluate influencers for brand partnerships, verify authenticity, and track collaboration performance across Instagram, Facebook, YouTube, and TikTok",
          "keywords": [
            "influencer",
            "discovery",
            "partnership",
            "creator",
            "collaboration",
            "authenticity",
            "instagram",
            "facebook",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.0.0",
          "categories": [
            "authenticity",
            "collaboration",
            "creator",
            "data-extraction",
            "discovery",
            "facebook",
            "influencer",
            "instagram",
            "partnership",
            "tiktok",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-influencer-discovery@apify-agent-skills"
          ]
        },
        {
          "name": "apify-trend-analysis",
          "source": "./skills/apify-trend-analysis",
          "skills": "./",
          "description": "Discover and track emerging trends across Google Trends, Instagram, Facebook, YouTube, and TikTok to inform content strategy",
          "keywords": [
            "trends",
            "analysis",
            "hashtags",
            "viral",
            "discovery",
            "content",
            "google-trends",
            "instagram",
            "facebook",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.0.0",
          "categories": [
            "analysis",
            "content",
            "data-extraction",
            "discovery",
            "facebook",
            "google-trends",
            "hashtags",
            "instagram",
            "tiktok",
            "trends",
            "viral",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-trend-analysis@apify-agent-skills"
          ]
        },
        {
          "name": "apify-content-analytics",
          "source": "./skills/apify-content-analytics",
          "skills": "./",
          "description": "Track engagement metrics, measure campaign ROI, and analyze content performance across Instagram, Facebook, YouTube, and TikTok",
          "keywords": [
            "analytics",
            "engagement",
            "performance",
            "metrics",
            "ROI",
            "content",
            "instagram",
            "facebook",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.0.0",
          "categories": [
            "analytics",
            "content",
            "data-extraction",
            "engagement",
            "facebook",
            "instagram",
            "metrics",
            "performance",
            "roi",
            "tiktok",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-content-analytics@apify-agent-skills"
          ]
        },
        {
          "name": "apify-audience-analysis",
          "source": "./skills/apify-audience-analysis",
          "skills": "./",
          "description": "Understand audience demographics, preferences, behavior patterns, and engagement quality across Facebook, Instagram, YouTube, and TikTok",
          "keywords": [
            "audience",
            "demographics",
            "behavior",
            "engagement",
            "analysis",
            "followers",
            "facebook",
            "instagram",
            "youtube",
            "tiktok"
          ],
          "category": "data-extraction",
          "version": "1.0.0",
          "categories": [
            "analysis",
            "audience",
            "behavior",
            "data-extraction",
            "demographics",
            "engagement",
            "facebook",
            "followers",
            "instagram",
            "tiktok",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-audience-analysis@apify-agent-skills"
          ]
        },
        {
          "name": "apify-ultimate-scraper",
          "source": "./skills/apify-ultimate-scraper",
          "skills": "./",
          "description": "Universal AI-powered web scraper for any platform. Scrape data from Instagram, Facebook, TikTok, YouTube, Google Maps, Google Search, Google Trends, Booking.com, and TripAdvisor for lead generation, brand monitoring, competitor analysis, influencer discovery, trend research, and more",
          "keywords": [
            "scraper",
            "universal",
            "instagram",
            "facebook",
            "tiktok",
            "youtube",
            "google-maps",
            "leads",
            "monitoring",
            "competitor",
            "trends",
            "influencer"
          ],
          "category": "data-extraction",
          "version": "1.4.0",
          "categories": [
            "competitor",
            "data-extraction",
            "facebook",
            "google-maps",
            "influencer",
            "instagram",
            "leads",
            "monitoring",
            "scraper",
            "tiktok",
            "trends",
            "universal",
            "youtube"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-ultimate-scraper@apify-agent-skills"
          ]
        },
        {
          "name": "apify-actor-development",
          "source": "./skills/apify-actor-development",
          "skills": "./",
          "description": "Develop, debug, and deploy Apify Actors - serverless cloud programs for web scraping, automation, and data processing",
          "keywords": [
            "apify",
            "actor",
            "web-scraping",
            "automation",
            "crawlee",
            "playwright",
            "cheerio",
            "serverless",
            "development"
          ],
          "category": "development",
          "version": "1.0.0",
          "categories": [
            "actor",
            "apify",
            "automation",
            "cheerio",
            "crawlee",
            "development",
            "playwright",
            "serverless",
            "web-scraping"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-actor-development@apify-agent-skills"
          ]
        },
        {
          "name": "apify-actor-commands",
          "description": "Commands for Apify Actor development workflow",
          "version": "1.0.0",
          "author": {
            "name": "Apify",
            "email": "support@apify.com"
          },
          "source": "./",
          "category": "development",
          "commands": [
            "./commands/create-actor.md"
          ],
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-actor-commands@apify-agent-skills"
          ]
        },
        {
          "name": "apify-actorization",
          "source": "./skills/apify-actorization",
          "skills": "./",
          "description": "Convert existing projects into Apify Actors - serverless cloud programs. Actorize JavaScript/TypeScript (SDK with Actor.init/exit), Python (async context manager), or any language (CLI wrapper). Use when migrating code to Apify, wrapping CLI tools as Actors, or adding Actor SDK to existing projects.",
          "keywords": [
            "actorization",
            "convert",
            "migrate",
            "actor",
            "apify",
            "sdk",
            "deployment",
            "crawlee",
            "serverless"
          ],
          "category": "development",
          "version": "1.0.0",
          "categories": [
            "actor",
            "actorization",
            "apify",
            "convert",
            "crawlee",
            "deployment",
            "development",
            "migrate",
            "sdk",
            "serverless"
          ],
          "install_commands": [
            "/plugin marketplace add apify/agent-skills",
            "/plugin install apify-actorization@apify-agent-skills"
          ]
        }
      ]
    }
  ]
}