{
  "author": {
    "id": "Codename-Inc",
    "display_name": "Codename",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/211721538?v=4",
    "url": "https://github.com/Codename-Inc",
    "bio": "Building New June ü§ñ + ‚õ≥Ô∏è",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 2,
      "total_skills": 2,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "spectre-labs",
      "version": "3.6.0",
      "description": "Experimental features for SPECTRE workflow framework.",
      "owner_info": {
        "name": "Joe Fernandez",
        "email": "joe@subspace.build"
      },
      "keywords": [],
      "repo_full_name": "Codename-Inc/spectre-labs",
      "repo_url": "https://github.com/Codename-Inc/spectre-labs",
      "repo_description": "Experimental features for SPECTRE workflow framework",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-28T01:08:36Z",
        "created_at": "2026-01-25T23:06:49Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 534
        },
        {
          "path": "sparks",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 400
        },
        {
          "path": "sparks/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/commands/find.md",
          "type": "blob",
          "size": 124
        },
        {
          "path": "sparks/commands/learn.md",
          "type": "blob",
          "size": 440
        },
        {
          "path": "sparks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/hooks/hooks.json",
          "type": "blob",
          "size": 272
        },
        {
          "path": "sparks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/hooks/scripts/load-knowledge.py",
          "type": "blob",
          "size": 3097
        },
        {
          "path": "sparks/hooks/scripts/migrate_to_skills.py",
          "type": "blob",
          "size": 6323
        },
        {
          "path": "sparks/hooks/scripts/register_spark.py",
          "type": "blob",
          "size": 4250
        },
        {
          "path": "sparks/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/skills/sparks-apply",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/skills/sparks-apply/SKILL.md",
          "type": "blob",
          "size": 8582
        },
        {
          "path": "sparks/skills/sparks-learn",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/skills/sparks-learn/SKILL.md",
          "type": "blob",
          "size": 19088
        },
        {
          "path": "sparks/skills/sparks-learn/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "sparks/skills/sparks-learn/references/find-template.md",
          "type": "blob",
          "size": 825
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"spectre-labs\",\n  \"version\": \"3.6.0\",\n  \"owner\": {\n    \"name\": \"Joe Fernandez\",\n    \"email\": \"joe@subspace.build\"\n  },\n  \"metadata\": {\n    \"description\": \"Experimental features for SPECTRE workflow framework.\",\n    \"homepage\": \"https://github.com/Codename-Inc/spectre-labs\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sparks\",\n      \"source\": \"./sparks\",\n      \"description\": \"Knowledge capture and recall. Use /learn to save learnings, they'll be automatically recalled when relevant.\",\n      \"version\": \"3.6.0\"\n    }\n  ]\n}\n",
        "sparks/.claude-plugin/plugin.json": "{\n  \"name\": \"sparks\",\n  \"version\": \"3.6.0\",\n  \"description\": \"Knowledge capture and recall. Use /learn to save learnings, they'll be automatically recalled when relevant.\",\n  \"keywords\": [\n    \"knowledge\",\n    \"learning\",\n    \"memory\",\n    \"context\"\n  ],\n  \"author\": {\n    \"name\": \"Joe Fernandez\",\n    \"email\": \"joe@subspace.build\"\n  },\n  \"homepage\": \"https://github.com/Codename-Inc/spectre-labs\"\n}\n",
        "sparks/commands/find.md": "# /find - Search Project Knowledge\n\nLoad the `sparks-find` skill and follow its instructions.\n\n**Search query**: $ARGUMENTS\n",
        "sparks/commands/learn.md": "# /learn - Capture Project Knowledge\n\n**Arguments provided**: $ARGUMENTS\n\n---\n\n<CRITICAL>\nYou MUST invoke the Skill tool to load `sparks-learn` before proceeding:\n\n```\nSkill({ skill: \"sparks:sparks-learn\" })\n```\n\nDo NOT interpret this command as already having the skill loaded. The skill is NOT expanded here ‚Äî you must load it via the Skill tool.\n\nIf you proceed without invoking Skill(), you are NOT following instructions.\n</CRITICAL>",
        "sparks/hooks/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"startup|clear|compact\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/scripts/load-knowledge.py\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "sparks/hooks/scripts/load-knowledge.py": "#!/usr/bin/env python3\n\"\"\"\nload-knowledge.py\n\nSessionStart hook that injects the apply skill content with embedded registry\ndirectly into Claude's context.\n\nReads:\n- Apply skill from plugin: skills/sparks-apply/SKILL.md\n- Registry from project: .claude/skills/sparks-find/references/registry.toon\n\nCombines them by replacing the Registry Location section with actual registry content.\n\"\"\"\n\nimport json\nimport os\nimport re\nimport sys\nfrom pathlib import Path\n\n\ndef count_registry_entries(lines: list[str]) -> int:\n    \"\"\"Count registry entries (lines with | that aren't comments).\"\"\"\n    return sum(\n        1 for line in lines\n        if line.strip() and '|' in line and not line.startswith('#')\n    )\n\n\ndef strip_frontmatter(content: str) -> str:\n    \"\"\"Remove YAML frontmatter from markdown content.\"\"\"\n    if content.startswith('---'):\n        # Find the closing ---\n        end = content.find('---', 3)\n        if end != -1:\n            return content[end + 3:].strip()\n    return content\n\n\ndef main():\n    \"\"\"Main entry point for SessionStart hook.\"\"\"\n    project_dir = Path.cwd()\n    plugin_root = Path(os.environ.get('CLAUDE_PLUGIN_ROOT', ''))\n\n    # Paths\n    registry_path = project_dir / \".claude\" / \"skills\" / \"sparks-find\" / \"references\" / \"registry.toon\"\n    apply_skill_path = plugin_root / \"skills\" / \"sparks-apply\" / \"SKILL.md\"\n\n    if not registry_path.exists():\n        sys.exit(0)\n\n    if not apply_skill_path.exists():\n        sys.exit(0)\n\n    # Read registry\n    registry_content = registry_path.read_text().strip()\n    lines = registry_content.split('\\n') if registry_content else []\n\n    # Count entries\n    entry_count = count_registry_entries(lines)\n\n    if entry_count == 0:\n        sys.exit(0)\n\n    # Read apply skill and strip frontmatter\n    apply_content = apply_skill_path.read_text()\n    apply_content = strip_frontmatter(apply_content)\n\n    # Replace the Registry Location section with embedded registry\n    # The apply skill has a section that tells you to read the registry file\n    # We replace that with the actual registry content\n    registry_section = f\"\"\"## Registry\n\n**Format**: `skill-name|category|triggers|description`\n\n```\n{registry_content}\n```\n\nEach entry corresponds to a skill that can be loaded via `Skill({{skill-name}})`\n\n**Categories:** feature, gotchas, patterns, decisions, procedures, integration, performance, testing, ux, strategy\"\"\"\n\n    # Replace the Registry Location section\n    apply_content = re.sub(\n        r'## Registry Location.*?(?=## Workflow)',\n        registry_section + '\\n\\n',\n        apply_content,\n        flags=re.DOTALL\n    )\n\n    # Build final context\n    context = f\"<sparks-knowledge>\\n{apply_content}\\n</sparks-knowledge>\"\n\n    # Visible notice\n    visible_notice = f\"‚ö°Ô∏èSparks: {entry_count} knowledge skills available\"\n\n    output = {\n        \"systemMessage\": visible_notice,\n        \"hookSpecificOutput\": {\n            \"hookEventName\": \"SessionStart\",\n            \"additionalContext\": context\n        }\n    }\n\n    print(json.dumps(output), flush=True)\n    sys.exit(0)\n\n\nif __name__ == \"__main__\":\n    main()\n",
        "sparks/hooks/scripts/migrate_to_skills.py": "#!/usr/bin/env python3\n\"\"\"\nmigrate_to_skills.py\n\nMigration script for existing projects using the old sparks format.\nConverts from:\n  .claude/skills/apply/references/{category}/{slug}.md\nTo:\n  .claude/skills/{category}-{slug}/SKILL.md\n\nUsage:\n    migrate_to_skills.py --project-root \"/path/to/project\" [--dry-run]\n\"\"\"\n\nimport argparse\nimport re\nimport sys\nfrom pathlib import Path\n\n\ndef parse_old_registry(skill_content: str) -> list[dict]:\n    \"\"\"Parse registry entries from old apply skill format.\"\"\"\n    # Find ## Registry section\n    registry_match = re.search(r'## Registry\\s*\\n(.*)', skill_content, re.DOTALL)\n    if not registry_match:\n        return []\n\n    registry_section = registry_match.group(1)\n    entries = []\n\n    for line in registry_section.strip().split('\\n'):\n        line = line.strip()\n        if not line or line.startswith('#') or '|' not in line:\n            continue\n\n        parts = line.split('|')\n        if len(parts) >= 4:\n            path, category, triggers, description = parts[0], parts[1], parts[2], parts[3]\n            # Extract slug from path like \"references/feature/my-slug.md\"\n            path_parts = path.replace('references/', '').replace('.md', '').split('/')\n            if len(path_parts) >= 2:\n                slug = path_parts[1]\n            else:\n                slug = path_parts[0]\n\n            entries.append({\n                'old_path': path,\n                'category': category,\n                'slug': slug,\n                'triggers': triggers,\n                'description': description,\n                'skill_name': f\"{category}-{slug}\"\n            })\n\n    return entries\n\n\ndef read_old_learning(project_root: Path, old_path: str) -> str | None:\n    \"\"\"Read content from old learning location.\"\"\"\n    full_path = project_root / \".claude\" / \"skills\" / \"apply\" / old_path\n    if full_path.exists():\n        return full_path.read_text()\n    return None\n\n\ndef convert_to_skill_format(content: str, entry: dict) -> str:\n    \"\"\"Convert old learning content to new skill format.\"\"\"\n    # Check if content already has frontmatter\n    if content.strip().startswith('---'):\n        # Already has frontmatter, update it\n        # Find end of frontmatter\n        end_match = re.search(r'^---\\s*$', content[3:], re.MULTILINE)\n        if end_match:\n            end_pos = end_match.end() + 3\n            old_frontmatter = content[:end_pos]\n            body = content[end_pos:].strip()\n\n            # Build new frontmatter\n            new_frontmatter = f\"\"\"---\nname: {entry['skill_name']}\ndescription: {entry['description']}\nuser-invocable: false\n---\"\"\"\n            return f\"{new_frontmatter}\\n\\n{body}\"\n\n    # No frontmatter, add it\n    frontmatter = f\"\"\"---\nname: {entry['skill_name']}\ndescription: {entry['description']}\nuser-invocable: false\n---\"\"\"\n    return f\"{frontmatter}\\n\\n{content}\"\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Migrate sparks from old format to per-skill format\"\n    )\n    parser.add_argument(\n        \"--project-root\",\n        required=True,\n        help=\"Root directory of the project\"\n    )\n    parser.add_argument(\n        \"--dry-run\",\n        action=\"store_true\",\n        help=\"Show what would be done without making changes\"\n    )\n\n    args = parser.parse_args()\n    project_root = Path(args.project_root)\n    dry_run = args.dry_run\n\n    # Check for old apply skill\n    old_skill_path = project_root / \".claude\" / \"skills\" / \"apply\" / \"SKILL.md\"\n    if not old_skill_path.exists():\n        print(\"No old apply skill found at .claude/skills/apply/SKILL.md\")\n        sys.exit(0)\n\n    # Parse old registry\n    old_content = old_skill_path.read_text()\n    entries = parse_old_registry(old_content)\n\n    if not entries:\n        print(\"No registry entries found in old apply skill\")\n        sys.exit(0)\n\n    print(f\"Found {len(entries)} entries to migrate\")\n    if dry_run:\n        print(\"\\n[DRY RUN - no changes will be made]\\n\")\n\n    # Prepare new registry\n    new_registry_lines = [\n        \"# Sparks Knowledge Registry\",\n        \"# Format: skill-name|category|triggers|description\",\n        \"\"\n    ]\n\n    migrated = 0\n    skipped = 0\n\n    for entry in entries:\n        skill_name = entry['skill_name']\n        old_path = entry['old_path']\n\n        print(f\"\\nMigrating: {old_path} -> .claude/skills/{skill_name}/SKILL.md\")\n\n        # Read old learning content\n        old_content = read_old_learning(project_root, old_path)\n        if not old_content:\n            print(f\"  WARNING: Could not read {old_path}, skipping\")\n            skipped += 1\n            continue\n\n        # Convert to skill format\n        new_content = convert_to_skill_format(old_content, entry)\n\n        # Create new skill directory and file\n        new_skill_dir = project_root / \".claude\" / \"skills\" / skill_name\n        new_skill_path = new_skill_dir / \"SKILL.md\"\n\n        if not dry_run:\n            new_skill_dir.mkdir(parents=True, exist_ok=True)\n            new_skill_path.write_text(new_content)\n            print(f\"  Created: .claude/skills/{skill_name}/SKILL.md\")\n        else:\n            print(f\"  Would create: .claude/skills/{skill_name}/SKILL.md\")\n\n        # Add to new registry\n        registry_entry = f\"{skill_name}|{entry['category']}|{entry['triggers']}|{entry['description']}\"\n        new_registry_lines.append(registry_entry)\n        migrated += 1\n\n    # Write new registry\n    new_registry_dir = project_root / \".claude\" / \"skills\" / \"apply\" / \"references\"\n    new_registry_path = new_registry_dir / \"sparks-registry.toon\"\n\n    registry_content = '\\n'.join(new_registry_lines) + '\\n'\n\n    if not dry_run:\n        new_registry_dir.mkdir(parents=True, exist_ok=True)\n        new_registry_path.write_text(registry_content)\n        print(f\"\\nCreated new registry: .claude/skills/apply/references/sparks-registry.toon\")\n    else:\n        print(f\"\\nWould create registry: .claude/skills/apply/references/sparks-registry.toon\")\n\n    print(f\"\\nMigration complete: {migrated} migrated, {skipped} skipped\")\n\n    if not dry_run:\n        print(\"\\nNext steps:\")\n        print(\"1. Verify the migrated skills in .claude/skills/\")\n        print(\"2. Update the apply skill to reference the new registry location\")\n        print(\"3. Optionally remove old references/ directory after verification\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
        "sparks/hooks/scripts/register_spark.py": "#!/usr/bin/env python3\n\"\"\"\nregister_spark.py\n\nRegisters a spark learning and manages the project-level find skill.\n\nResponsibilities:\n1. Create/update registry at .claude/skills/find/references/registry.toon\n2. Read find-template.md from plugin\n3. Generate .claude/skills/find/SKILL.md with embedded registry\n\nUsage:\n    register_spark.py \\\n        --project-root \"/path/to/project\" \\\n        --skill-name \"feature-my-feature\" \\\n        --category \"feature\" \\\n        --triggers \"keyword1, keyword2\" \\\n        --description \"Use when doing X or Y\"\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nfrom pathlib import Path\n\n\ndef get_registry_header() -> list[str]:\n    \"\"\"Return header lines for a new registry.\"\"\"\n    return [\n        \"# Sparks Knowledge Registry\",\n        \"# Format: skill-name|category|triggers|description\",\n        \"\"\n    ]\n\n\ndef update_registry(registry_path: Path, entry: str, skill_name: str) -> str:\n    \"\"\"Update registry file with new/updated entry. Returns full registry content.\"\"\"\n    entry_prefix = skill_name + '|'\n\n    if registry_path.exists():\n        content = registry_path.read_text()\n        lines = content.strip().split('\\n') if content.strip() else []\n    else:\n        lines = get_registry_header()\n\n    # Check if entry already exists (by skill-name at start of line)\n    entry_exists = False\n    updated_lines = []\n\n    for line in lines:\n        if line.startswith(entry_prefix):\n            # Update existing entry\n            updated_lines.append(entry)\n            entry_exists = True\n        else:\n            updated_lines.append(line)\n\n    if not entry_exists:\n        updated_lines.append(entry)\n\n    # Ensure trailing newline\n    content = '\\n'.join(updated_lines)\n    if not content.endswith('\\n'):\n        content += '\\n'\n\n    registry_path.write_text(content)\n    return content\n\n\ndef generate_find_skill(find_skill_path: Path, template_path: Path, registry_content: str):\n    \"\"\"Generate the find skill with embedded registry.\"\"\"\n    if not template_path.exists():\n        print(f\"Warning: Template not found at {template_path}\", file=sys.stderr)\n        return\n\n    template = template_path.read_text()\n\n    # Replace placeholder with actual registry\n    skill_content = template.replace(\"{{REGISTRY}}\", registry_content.strip())\n\n    # Ensure directory exists\n    find_skill_path.parent.mkdir(parents=True, exist_ok=True)\n\n    find_skill_path.write_text(skill_content)\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Register a spark and update the project find skill\"\n    )\n    parser.add_argument(\n        \"--project-root\",\n        required=True,\n        help=\"Root directory of the project\"\n    )\n    parser.add_argument(\n        \"--skill-name\",\n        required=True,\n        help=\"Name of the skill (e.g., feature-my-feature)\"\n    )\n    parser.add_argument(\n        \"--category\",\n        required=True,\n        help=\"Category of the learning\"\n    )\n    parser.add_argument(\n        \"--triggers\",\n        required=True,\n        help=\"Comma-separated trigger keywords\"\n    )\n    parser.add_argument(\n        \"--description\",\n        required=True,\n        help=\"Short description starting with 'Use when...'\"\n    )\n\n    args = parser.parse_args()\n\n    project_root = Path(args.project_root)\n\n    # New paths: registry lives inside sparks-find skill\n    find_dir = project_root / \".claude\" / \"skills\" / \"sparks-find\"\n    registry_dir = find_dir / \"references\"\n    registry_path = registry_dir / \"registry.toon\"\n    find_skill_path = find_dir / \"SKILL.md\"\n\n    # Template is in the plugin\n    plugin_root = Path(os.environ.get('CLAUDE_PLUGIN_ROOT', ''))\n    template_path = plugin_root / \"skills\" / \"sparks-learn\" / \"references\" / \"find-template.md\"\n\n    # Ensure directories exist\n    registry_dir.mkdir(parents=True, exist_ok=True)\n\n    # Build the registry entry\n    entry = f\"{args.skill_name}|{args.category}|{args.triggers}|{args.description}\"\n\n    # Update registry and get full content\n    registry_content = update_registry(registry_path, entry, args.skill_name)\n\n    # Generate find skill with embedded registry\n    generate_find_skill(find_skill_path, template_path, registry_content)\n\n    print(f\"Registered: {entry}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
        "sparks/skills/sparks-apply/SKILL.md": "---\nname: sparks-apply\ndescription: Use when starting implementation, debugging, or feature work on a project with captured knowledge.\nuser-invocable: false\n---\n\n# Apply Knowledge\n\n## Why This Exists\n\nThis project has captured knowledge ‚Äî patterns, gotchas, decisions, and feature context ‚Äî from previous sessions. This knowledge:\n\n- **Prevents repeated mistakes** ‚Äî gotchas you've already debugged\n- **Maintains consistency** ‚Äî decisions and patterns the team has established\n- **Provides instant context** ‚Äî feature designs, key files, common tasks\n- **Makes searching efficient** ‚Äî know WHERE to look before searching\n\nWithout this, you'd waste time rediscovering what's already known or make decisions that contradict established patterns.\n\n## The Rule\n\n<CRITICAL>\nIf ANY entry's triggers or description match your current task, you MUST load the skill FIRST using the Skill tool.\n\n**Trigger matches are sufficient.** If a trigger word appears in the user's request, load the skill‚Äîyou don't need the description to also match. Don't reframe the user's request to avoid triggers.\n\nThe registry tells you exactly where relevant knowledge is. Loading it first makes you faster and more accurate.\n\nDO NOT search the codebase or dispatch agents BEFORE loading relevant knowledge‚Äîeven if you think you already have enough context. Partial context from Read results or error messages is not a substitute for the complete picture in the skill.\n\n**You are also responsible for keeping knowledge current.** After completing significant work ‚Äî implementing features, fixing bugs, discovering gotchas, making architectural decisions, or changing patterns ‚Äî you MUST proactively check whether any loaded skills need updating, and whether new skills should be captured.\n\nDo NOT wait for the user to say \"/learn\" or \"update the skill.\" If you changed how something works, the skill that describes it is now stale. Fix it.\n</CRITICAL>\n\n## Registry Location\n\nThe registry is stored at `{{project_root}}/.claude/skills/sparks-find/references/registry.toon`\n\n**Format**: `{skill-name}|{category}|{triggers}|{description}`\n\nEach entry corresponds to a skill that can be loaded via `Skill({skill-name})`\n\n**Categories:** feature, gotchas, patterns, decisions, procedures, integration, performance, testing, ux, strategy\n\n## Workflow\n\n1. **Read the registry** at `{{project_root}}/.claude/skills/sparks-find/references/registry.toon`\n2. **Scan entries** ‚Äî if ANY trigger word OR the description matches your task, that's a match\n3. **For each match**, load the skill:\n   ```\n   Skill({skill-name})\n   ```\n4. **Apply the knowledge** ‚Äî use it to guide your approach, know where to look\n5. **Then proceed** ‚Äî now you can search/implement with context\n6. **No matches?** Proceed normally\n\n## Keeping Knowledge Current\n\nLoading skills is half the job. The other half is **leaving them better than you found them**.\n\n### When to Update (Proactively ‚Äî Don't Wait to Be Asked)\n\nAfter completing work, ask yourself:\n\n1. **Did I load a skill that's now outdated?** ‚Üí Update it immediately\n2. **Did I discover something capture-worthy?** (gotcha, pattern, decision) ‚Üí Run `/learn`\n3. **Did I change key files, flows, or architecture?** ‚Üí Update the relevant feature skill\n4. **Did I make a decision with non-obvious rationale?** ‚Üí Capture it before the session ends\n\n### How to Update\n\n- **Existing skill needs changes**: Read the skill file, Edit it directly, keep the same format\n- **New knowledge worth capturing**: Use `Skill(sparks-learn)` or tell the user you'd like to `/learn`\n- **Registry entry needs new triggers**: Edit `{{project_root}}/.claude/skills/sparks-find/references/registry.toon`\n\n### The Standard\n\nWhen you finish a task that touched areas covered by loaded skills, **the skills should reflect the current state before you move on**. Stale knowledge is worse than no knowledge ‚Äî it actively misleads future sessions.\n\n## Red Flags\n\n| Thought | Reality |\n|---------|---------|\n| \"Let me search the codebase first\" | Knowledge tells you WHERE to search. Load the skill first. |\n| \"I'll dispatch an agent to find this\" | The skill name is in the registry. Just use `Skill({name})`. |\n| \"I need more context first\" | The knowledge IS the context. |\n| \"This seems simple\" | Simple tasks benefit from captured patterns too. |\n| \"I already have context from a Read/system message\" | Partial context is dangerous. The skill has the full picture‚Äîincluding related changes you don't know about yet. |\n| \"The error/issue is narrow and specific\" | Narrow symptoms often stem from broader changes (like namespace renames) that the skill documents. |\n| \"I can figure this out faster by just searching\" | You're trading 1 skill load for multiple speculative searches. The skill tells you exactly where to look. |\n| \"This is really about X, not Y\" | Don't reframe the user's words. If they said \"release,\" match against \"release\"‚Äînot your interpretation of the underlying concern. |\n| \"I have the exact files I'm editing\" | File contents ‚â† architectural context. Skills tell you related files, patterns across the codebase, and what you don't know you don't know. |\n| \"The edit is surgical/mechanical\" | Surgical edits in isolation risk inconsistency. Skills reveal if similar changes are needed elsewhere. |\n| \"I'll update the skill later\" | Later never comes. Update before moving to the next task. |\n| \"The user didn't ask me to update knowledge\" | You don't need permission. Keeping skills current is part of the job. |\n| \"The change was small\" | Small changes accumulate into large drift. Update now. |\n\n## Real Failure Example\n\n**Task**: Fix \"Template not found at skills/learn/references/find-template.md\"\n\n**Rationalization**: \"I already have register_spark.py in context from a Read result. The error points to the exact path. This is a simple path mismatch‚ÄîI'll just Glob to find where the template actually is.\"\n\n**What happened**: Skipped loading `feature-sparks-plugin` skill. Used Glob to find the file. Fixed it.\n\n**What the skill would have provided**: Immediate knowledge that skills were renamed to `sparks-*` namespace, exact file paths in the \"Key Files\" table, no searching required.\n\n**Cost**: Extra tool calls, wasted tokens, and reinforced bad habits.\n\n## Real Failure Example #2\n\n**Task**: User asks about \"npm run release process\"\n\n**Rationalization**: \"This is really about URL management for updates, not about the release mechanics itself. The procedure-release skill talks about signing and notarization, which isn't what they're asking about.\"\n\n**What happened**: Skipped loading `procedure-release`. Searched the codebase for update URLs. Missed that the skill documents the entire release infrastructure including how URLs are configured.\n\n**What the skill would have provided**: Complete context on release targets, URL configuration, and how staging vs production channels work.\n\n**The lesson**: Trigger match (\"release\") was sufficient. The LLM shouldn't have required the description to also match, and shouldn't have reframed the task to avoid the trigger.\n\n## Real Failure Example #3\n\n**Task**: Add commit message to the commit step in `/spectre:clean` and `/spectre:test` commands\n\n**Rationalization**: \"I already have the full contents of both clean.md and test.md from Read results. The task is surgical‚ÄîI know exactly which lines to edit. I don't need broader context to make this specific change.\"\n\n**What happened**: Skipped loading `feature-spectre-plugin` despite triggers matching (\"spectre\", \"clean\", \"test\"). Made the edit successfully but without understanding the broader SPECTRE workflow architecture.\n\n**What the skill would have provided**:\n- Knowledge that similar commit patterns exist in other commands that might need the same change\n- Understanding of how commands relate to each other in the workflow\n- Commit message conventions used across SPECTRE\n- Awareness of the artifact system and how commits are structured\n\n**The lesson**: Having file contents is not the same as having architectural context. The skill tells you what you don't know you don't know‚Äîrelated files, patterns across commands, conventions. A \"surgical\" edit without skill context risks being inconsistent with the broader system.\n\n## Example\n\nUser: \"How does /sparks work?\"\n\nRegistry entry: `feature-sparks-plugin|feature|sparks, /sparks, knowledge|Use when modifying sparks plugin or debugging hooks`\n\nAction: `Skill(feature-sparks-plugin)`\n\nThen: Use the key files and patterns from that knowledge to guide your work.\n",
        "sparks/skills/sparks-learn/SKILL.md": "---\nname: sparks-learn\ndescription: Use when user invokes /learn or wants to save patterns, decisions, gotchas, procedures, or feature knowledge from a conversation for later re-use. Look for user requests like \"please remember\" or \"what did we learn from this?\".\n---\n\n# Learning Agent\n\nYou capture durable project knowledge into Skills that Claude Code loads on-demand.\n\n## Proactive Skill Updates\n\nIf you loaded a skill earlier in this session (via `Skill({name})`) and subsequently:\n- Discovered the skill was incomplete, outdated, or wrong\n- Learned something new that extends the skill's coverage\n- Found better patterns, files, or approaches than documented\n- Debugged an issue the skill should have warned about\n\n**You should offer to update that skill** before the session ends.\n\nWhen invoking `/learn` in this case:\n1. Reference the skill you loaded: \"I'd update the skill: `{skill-name}`\"\n2. Show what changed: current vs. proposed\n3. Follow the UPDATE flow below\n\nThis keeps knowledge fresh without requiring users to remember to call `/learn`.\n\n## Goal\n\n**Enable someone with zero context to become productive on this topic.**\n\nEvery learning you create should allow a new team member (human or AI) to complete a task without asking follow-up questions. If they'd need to dig further to actually DO something, the learning isn't complete.\n\n## Content Principles\n\nThese principles apply to ALL categories. Structure varies by category, but depth is universal.\n\n### 1. Lead with the insight\nWhat's the ONE thing they must know? Put it first, not buried. Don't make them read 5 paragraphs to find the key point.\n\n### 2. Orient before details\nWhy does this exist? What problem does it solve? 2-3 sentences max, then move on. Someone with zero context needs to understand WHY before HOW.\n\n### 3. Make it actionable\nInclude something they can DO: commands to run, code to copy, steps to follow. Information without action is trivia. If there's nothing actionable, question whether it's worth capturing.\n\n### 4. Show, don't tell\nExamples > explanations. A code snippet is worth 100 words of description. Every learning should have at least one concrete example.\n\n### 5. Anticipate mistakes\nWhat will trip them up? Call out pitfalls explicitly. The best learnings prevent errors, not just explain concepts.\n\n### 6. Keep it scannable\nHeaders, tables, code blocks. Someone should get 80% of the value in 60 seconds of skimming. Dense paragraphs bury knowledge.\n\n## Quality Test\n\nBefore proposing ANY learning, ask yourself:\n\n- **\"Could someone complete a task using only this?\"** - If they'd need to search elsewhere, add more.\n- **\"Does this tell them HOW, not just WHAT?\"** - Facts without application aren't useful.\n- **\"Would I have saved hours if I'd had this when I started?\"** - If the answer is \"maybe 10 minutes\", it might not be worth capturing.\n\nIf any answer is no, add more depth or reconsider capturing it.\n\n## Path Convention\n\n`{{project_root}}` refers to the root of the current project (typically the git repository root or cwd).\n\n## Storage Structure\n\nEach learning becomes its own skill at the project level:\n\n```\n{{project_root}}/.claude/skills/\n‚îú‚îÄ‚îÄ sparks-find/\n‚îÇ   ‚îú‚îÄ‚îÄ SKILL.md                      # Find skill (discovery + embedded registry)\n‚îÇ   ‚îî‚îÄ‚îÄ references/\n‚îÇ       ‚îî‚îÄ‚îÄ registry.toon             # Registry source of truth\n‚îú‚îÄ‚îÄ {category}-{slug}/                # Learning = Skill\n‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îú‚îÄ‚îÄ {category}-{slug}/                # Learning = Skill\n‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îî‚îÄ‚îÄ ...\n```\n\n## Registry\n\nThe registry is stored at `{{project_root}}/.claude/skills/sparks-find/references/registry.toon`\n\nBefore proposing a learning, read the registry to check for existing learnings:\n\n```\n{{project_root}}/.claude/skills/sparks-find/references/registry.toon\n```\n\nFormat: `{skill-name}|{category}|{triggers}|{description}` (one learning per line)\n\nExample: `feature-sparks-plugin|feature|sparks, /learn, /find|Use when modifying sparks plugin or debugging hooks`\n\n## Workflow\n\n### 1. Parse Input\n\n**With arguments**: Use the explicit topic/content as the knowledge to capture.\n**Without arguments**: Analyze recent conversation (last 10-20 messages) to identify what's worth preserving.\n\n### 2. Check Context\n\nDetermine if you have sufficient context to create a quality learning.\n\n**Ask yourself**: Can I answer the category's required questions (from Section 6) using:\n- The current conversation context?\n- My existing knowledge of this codebase from this session?\n\n| Situation | Action |\n|-----------|--------|\n| Topic was discussed in detail in recent messages | Proceed to Step 4 (Apply Capture Criteria) |\n| You already understand the topic from this session | Proceed to Step 4 (Apply Capture Criteria) |\n| Topic is unfamiliar / not discussed / you'd be guessing | **Trigger Investigation Mode** (Step 2b) |\n\n<CRITICAL>\nDo NOT fabricate knowledge. If you haven't seen how something works in this session, you don't know how it works. Investigation Mode exists precisely for this situation.\n</CRITICAL>\n\n### 2b. Investigation Mode\n\nWhen you lack context, investigate the codebase using subagents before creating a learning.\n\n#### Step 1: Determine Category\n\nClassify the topic into a likely category. If ambiguous, ask the user:\n```\nI'll investigate \"{topic}\" in the codebase. Which type of learning?\n- feature (how it works end-to-end)\n- gotchas (debugging knowledge)\n- patterns (repeatable solutions)\n- decisions (architectural choices)\n- procedures (multi-step processes)\n- integration (external systems)\n```\n\n#### Step 2: File Discovery\n\nDispatch an `Explore` agent to map relevant files:\n\n```\nTask(subagent_type=\"Explore\", prompt=\"\"\"\nFind all files related to \"{topic}\" in this codebase:\n- Entry points (routes, CLI commands, exports, event handlers)\n- Core logic (main implementation files)\n- Tests (unit tests, integration tests)\n- Config (configuration, environment, constants)\n- Docs (READMEs, comments, existing documentation)\n\nReturn a file map with:\n- File path\n- Brief description of what the file does\n- Relevance to {topic} (high/medium/low)\n\nFocus on HIGH and MEDIUM relevance files.\n\"\"\")\n```\n\n#### Step 3: Parallel Investigation\n\nBased on the category, dispatch 2-3 `general-purpose` agents in parallel. Each agent gets:\n- The file map from Step 2\n- 1-2 specific questions to answer\n- Instructions to cite specific files and line numbers\n\n**For feature investigations:**\n```\nAgent 1: \"What is {topic} and what problem does it solve? How do users interact with it?\n         Cite entry points and user-facing code.\"\n\nAgent 2: \"What is the technical architecture? How do components connect?\n         Cite core implementation files.\"\n\nAgent 3: \"What are common tasks someone would need to do? What files would they modify?\n         Cite specific functions/files for each task.\"\n```\n\n**For gotcha investigations:**\n```\nAgent 1: \"What are the symptoms when {topic} goes wrong? What errors appear?\n         Cite error handling code and logs.\"\n\nAgent 2: \"What is the root cause? What non-obvious behavior exists?\n         Cite the specific code that causes confusion.\"\n\nAgent 3: \"What is the solution? How do you fix or work around it?\n         Cite the correct approach with code examples.\"\n```\n\n**For other categories:** Generate investigation questions from the category's required sections.\n\n#### Step 4: Synthesize Findings\n\nAfter subagents return:\n\n1. **Cross-reference** - Connect insights across agents. Look for:\n   - Files mentioned by multiple agents (likely important)\n   - Flows that span multiple components\n   - Patterns that repeat\n\n2. **Resolve conflicts** - If agents contradict each other:\n   - Read the disputed code directly to verify\n   - Note uncertainty in the learning if unresolved\n\n3. **Identify gaps** - What required sections couldn't be answered?\n   - If critical gaps exist, dispatch additional investigation\n   - If minor gaps, note them as \"needs investigation\" in the learning\n\n4. **Structure findings** - Map synthesized knowledge to the category template from Section 6\n\nAfter synthesis, proceed to Step 7 (Generate Skill Name).\n\n---\n\n### 4. Apply Capture Criteria\n\nMust meet **at least 2 of 4**:\n\n| Criterion  | Question                         |\n| ---------- | -------------------------------- |\n| Frequency  | Will this come up again?         |\n| Pain       | Did it cost real debugging time? |\n| Surprise   | Was it non-obvious?              |\n| Durability | Still true in 6 months?          |\n\n**Capture**: Patterns, decisions with rationale, debugging insights, conventions, tribal knowledge.\n**Skip**: One-off solutions, generic knowledge, temporary workarounds, simple preferences (-> CLAUDE.md).\n\n### 5. Categorize\n\n**ONLY use these categories.** Do not invent new ones.\n\n| Category    | Categorize as this when the knowledge is about...        |\n| ----------- | -------------------------------------------------------- |\n| feature     | How a feature works end-to-end: design, flows, key files |\n| gotchas     | Hard-won debugging knowledge, non-obvious pitfalls       |\n| patterns    | Repeatable solutions used across the codebase            |\n| decisions   | Architectural choices + rationale                        |\n| procedures  | Multi-step processes (deploy, release, etc.)             |\n| integration | Third-party APIs, vendor quirks, external systems        |\n| performance | Optimization learnings, benchmarks, scaling decisions    |\n| testing     | Test strategies, coverage decisions, QA patterns         |\n| ux          | Design patterns, user research insights, interactions    |\n| strategy    | Roadmap decisions, prioritization rationale              |\n\n**Category selection guide:**\n- \"How does X feature work?\" ‚Üí `feature`\n- \"Why did we choose X over Y?\" ‚Üí `decisions`\n- \"X keeps breaking in weird ways\" ‚Üí `gotchas`\n- \"How do we deploy/release/migrate X?\" ‚Üí `procedures`\n- \"How do we talk to X API?\" ‚Üí `integration`\n\n### 6. Category-Specific Structure\n\nEach category has expected sections. These are minimums - add more depth as needed to meet the Content Principles.\n\n#### Feature Learnings\n\nFeature learnings are comprehensive \"dossiers\" that enable someone to work on a feature without prior context.\n\n**Required sections:**\n- **What is {Feature}?** - 2-3 sentences explaining what it is and why it exists\n- **Why Use It? / Use Cases** - Problem/solution pairs or concrete scenarios (at least 3)\n- **User Flows** - How users interact with it (at least 2 flows)\n- **Technical Design** - Architecture, key patterns, how it works\n- **Key Files** - Files that matter with their purposes (at least 3)\n- **Common Tasks** - Things someone will need to do, with how-to (at least 2)\n\n#### Gotcha Learnings\n\nGotchas capture hard-won debugging knowledge.\n\n**Required sections:**\n- **Symptom** - What you observe when you hit this\n- **Root Cause** - Why it happens (the non-obvious part)\n- **Solution** - How to fix it, with code/commands\n- **Prevention** - How to avoid hitting it again (if applicable)\n\n#### Pattern Learnings\n\nPatterns document repeatable solutions.\n\n**Required sections:**\n- **Problem** - What situation calls for this pattern\n- **Solution** - The pattern itself, with code example\n- **When to Use** - Specific scenarios where this applies\n- **Trade-offs** - What you give up by using this pattern\n\n#### Decision Learnings\n\nDecisions preserve architectural choices and rationale.\n\n**Required sections:**\n- **Context** - What situation prompted this decision\n- **Options Considered** - What alternatives existed\n- **Decision** - What we chose\n- **Rationale** - Why we chose it (the important part)\n- **Consequences** - What this decision enables/prevents\n\n#### Procedure Learnings\n\nProcedures document multi-step processes.\n\n**Required sections:**\n- **When to Use** - What triggers this procedure\n- **Prerequisites** - What you need before starting\n- **Steps** - Numbered steps with commands/code\n- **Verification** - How to confirm it worked\n\n#### Integration Learnings\n\nIntegrations document external system connections.\n\n**Required sections:**\n- **What it is** - The external system and why we use it\n- **How we connect** - Auth, endpoints, SDK usage\n- **Key Operations** - Common tasks with code examples\n- **Gotchas** - Vendor-specific quirks and workarounds\n\n#### Other Categories (performance, testing, ux, strategy)\n\nFollow the Content Principles. Include:\n- Context (why this matters)\n- The knowledge itself (specific, actionable)\n- Examples (code, commands, or concrete scenarios)\n- Pitfalls (what to watch out for)\n\n### 7. Generate Skill Name\n\nThe skill name follows the pattern `{category}-{slug}`:\n\n**Naming rules (CRITICAL for discoverability):**\n\n```\nVALID:   feature-auth-flows, gotchas-hook-timeout, patterns-retry-logic\nINVALID: auth-flows (no category), feature/auth-flows (no slashes), feature_auth_flows (no underscores)\n```\n\nRules:\n- **{category}-{slug}** format: category prefix, then descriptive slug\n- **lowercase-kebab-case ONLY**: letters, numbers, hyphens\n- **NO special characters**: no colons, slashes, underscores, or parentheses\n- **Descriptive slug**: `session-restore`, `handling-timeouts`\n- **3-5 words max in slug**: enough to be specific, short enough to scan\n\n### 8. Match, Update, or Create\n\nRead the registry to find candidates, then **read the actual skill file** to compare content.\n\n**Registry scan** - look for:\n- Same category prefix\n- Overlapping trigger keywords\n- Related topic\n\n**If candidate found**, read `{{project_root}}/.claude/skills/{skill-name}/SKILL.md` and check:\n\n1. **UPDATE** - New knowledge contradicts, extends, or supersedes an existing learning\n   - Same topic but new/better information\n   - Original learning was incomplete or wrong\n   - Circumstances changed (dependency updated, API changed, etc.)\n\n2. **APPEND** - New learning belongs in same skill but is distinct\n   - Related topic, different specific insight\n   - Same category, different trigger keywords\n\n3. **CREATE** - No semantic match in registry\n   - New topic area\n   - Different category\n\n**Decision priority**: UPDATE > APPEND > CREATE (prefer consolidation over proliferation)\n\n### 9. Verify Learning\n\nBefore proposing, verify the learning is accurate. This is especially important for Investigation Mode learnings.\n\n**Verification checklist:**\n\n1. **Spot-check key claims** (2-3 minimum)\n   - Pick specific claims from your draft (\"File X handles Y\")\n   - Read the actual file to confirm\n   - If wrong, correct the learning\n\n2. **Verify file purposes**\n   - For each file in \"Key Files\", quick-read to confirm description\n   - Remove files that don't match their described purpose\n\n3. **Trace one flow** (for feature learnings)\n   - Pick a user flow from the learning\n   - Trace through actual code to confirm accuracy\n   - Note any discrepancies\n\n**If verification fails:**\n- Correct the learning before proposing\n- If uncertainty remains, flag it explicitly:\n  ```\n  > **Note**: The {specific area} couldn't be fully verified.\n  > This may need confirmation.\n  ```\n\n**Confidence calibration based on verification:**\n\n| Verification Result | Confidence |\n|---------------------|------------|\n| All claims verified, flows traced | high |\n| Most verified, minor gaps | medium |\n| Significant uncertainty, partial verification | low |\n\nFor Investigation Mode learnings, default to `medium` unless verification is thorough.\n\n### 10. Propose\n\nStop and wait for user response. Format depends on action type:\n\n**For UPDATE** (revising existing learning):\n```\nI'd update the skill: `{skill-name}`\n\n**Current**: {1-2 sentence summary of existing}\n**Proposed**: {1-2 sentence summary of revision}\n**Reason**: {contradicts|extends|supersedes} - {why}\n\n{Updated content preview - FULL content, not summary}\n\nUpdate this? [Y/n/edit]\n```\n\n**For APPEND** (adding to existing skill):\n```\nI'd append to the skill: `{skill-name}`\n\n**{Title}**\n\n{Full content following category structure}\n\nTrigger: {keywords}\nConfidence: {low|medium|high}\n\nSave this? [Y/n/edit]\n```\n\n**For CREATE** (new skill):\n```\nI'd create a new skill: `{skill-name}`\n\n**{Title}**\n\n{Full content following category structure}\n\nTrigger: {keywords}\nConfidence: {low|medium|high}\n\nCreate this? [Y/n/edit]\n```\n\n**Confidence** (determined in Step 9 - Verify Learning):\n- low = observed once, or Investigation Mode with partial verification\n- medium = repeated/taught, or Investigation Mode with solid verification\n- high = battle-tested, or fully verified with traced flows\n\n<CRITICAL>\nAlways show FULL proposed content, not summaries. The user needs to see exactly what will be saved to approve it. Sparse proposals lead to sparse learnings.\n</CRITICAL>\n\n### 11. Handle Response\n\n- `y`/`yes` -> write as proposed\n- `n`/`no` -> cancel\n- `edit` or custom text -> modify first\n- Different skill name -> use that instead\n\n### 12. Write Learning\n\n**Location**: `{{project_root}}/.claude/skills/{skill-name}/SKILL.md`\n\n**Skill Template**:\n\n```markdown\n---\nname: {skill-name}\ndescription: Use when {triggering conditions - MUST start with \"Use when\"}\nuser-invocable: false\n---\n\n# {Title}\n\n**Trigger**: {keywords}\n**Confidence**: {level}\n**Created**: {YYYY-MM-DD}\n**Updated**: {YYYY-MM-DD}\n**Version**: 1\n\n{Content - follows category-specific structure from Section 6}\n```\n\n**UPDATE** - Revise existing skill:\n\n1. Preserve `**Created**` date\n2. Set `**Updated**` to today\n3. Increment `**Version**` by 1\n4. Update confidence if warranted (e.g., low ‚Üí medium after verification)\n\n**APPEND** - For skills with multiple sections, add new section:\n\n```markdown\n---\n\n## {New Section Title}\n\n**Trigger**: {keywords}\n**Confidence**: {level}\n**Created**: {YYYY-MM-DD}\n**Updated**: {YYYY-MM-DD}\n**Version**: 1\n\n{Explanation}\n```\n\n### 13. Register the Learning\n\nAfter writing the skill file, register it by calling the register script:\n\n```bash\npython3 \"${CLAUDE_PLUGIN_ROOT}/hooks/scripts/register_spark.py\" \\\n  --project-root \"{{project_root}}\" \\\n  --skill-name \"{skill-name}\" \\\n  --category \"{category}\" \\\n  --triggers \"{triggers}\" \\\n  --description \"{description}\"\n```\n\nThis updates the registry and regenerates the find skill at `.claude/skills/sparks-find/`.\n\n<CRITICAL>\n**Registry description format:**\n\nThe `--description` parameter is used to MATCH knowledge to tasks. It must describe WHEN to use the knowledge, not what it contains.\n\n- MUST start with \"Use when...\"\n- Describes triggering CONDITIONS\n- Focuses on tasks/scenarios that need this knowledge\n\n**Good descriptions:**\n- `\"Use when modifying sparks plugin, debugging hooks, or adding knowledge categories\"`\n- `\"Use when auth fails silently or tokens expire unexpectedly\"`\n- `\"Use when adding new API endpoints or modifying request handling\"`\n\n**Bad descriptions:**\n- `\"Sparks plugin architecture - how knowledge capture works\"` (describes content, not when to use)\n- `\"Authentication system overview\"` (too vague, no triggering conditions)\n- `\"API patterns\"` (no actionable context)\n</CRITICAL>\n\n### 14. Confirm\n\n```\nSaved .claude/skills/{skill-name}/SKILL.md\n```\n",
        "sparks/skills/sparks-learn/references/find-template.md": "---\nname: sparks-find\ndescription: Use when user wants to search for existing knowledge, find a specific learning, or discover what knowledge is available.\n---\n\n# Find Knowledge\n\nSearch and load relevant knowledge from the project's sparks into your context.\n\n## Registry\n\n{{REGISTRY}}\n\n## How to Use\n\n1. **Scan registry above** ‚Äî match triggers/description against your current task\n2. **Load matching skills**: `Skill({skill-name})`\n3. **Apply knowledge** ‚Äî use it to guide your approach\n\n## Search Commands\n\n- `/find {query}` ‚Äî search registry for matches\n- `/find` ‚Äî show all available knowledge by category\n\n## Workflow\n\n**Single match** ‚Üí Load automatically via `Skill({skill-name})`\n\n**Multiple matches** ‚Üí List options, ask user which to load\n\n**No matches** ‚Üí Suggest `/learn` to capture new knowledge\n"
      },
      "plugins": [
        {
          "name": "sparks",
          "source": "./sparks",
          "description": "Knowledge capture and recall. Use /learn to save learnings, they'll be automatically recalled when relevant.",
          "version": "3.6.0",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Codename-Inc/spectre-labs",
            "/plugin install sparks@spectre-labs"
          ]
        }
      ]
    }
  ]
}