{
  "author": {
    "id": "shadowX4fox",
    "display_name": "Luis",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/8646740?u=7c1fa373c5f38b91aa933dcb87578ad01090e21f&v=4",
    "url": "https://github.com/shadowX4fox",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 1,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "shadowx4fox-solution-architect-marketplace",
      "version": null,
      "description": "Official plugin marketplace by shadowX4fox",
      "owner_info": {
        "name": "shadowX4fox",
        "url": "https://github.com/shadowX4fox"
      },
      "keywords": [],
      "repo_full_name": "shadowX4fox/solutions-architect-skills",
      "repo_url": "https://github.com/shadowX4fox/solutions-architect-skills",
      "repo_description": "Professional architecture documentation workflow for Claude Code",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2025-12-31T13:49:19Z",
        "created_at": "2025-11-29T02:27:57Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 587
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 780
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 20078
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/MIGRATION.md",
          "type": "blob",
          "size": 12027
        },
        {
          "path": "agents/business-continuity-compliance-generator.md",
          "type": "blob",
          "size": 20590
        },
        {
          "path": "agents/cloud-compliance-generator.md",
          "type": "blob",
          "size": 20878
        },
        {
          "path": "agents/data-ai-compliance-generator.md",
          "type": "blob",
          "size": 18254
        },
        {
          "path": "agents/development-compliance-generator.md",
          "type": "blob",
          "size": 17595
        },
        {
          "path": "agents/enterprise-compliance-generator.md",
          "type": "blob",
          "size": 17901
        },
        {
          "path": "agents/integration-compliance-generator.md",
          "type": "blob",
          "size": 17985
        },
        {
          "path": "agents/platform-compliance-generator.md",
          "type": "blob",
          "size": 17603
        },
        {
          "path": "agents/process-compliance-generator.md",
          "type": "blob",
          "size": 17452
        },
        {
          "path": "agents/security-compliance-generator.md",
          "type": "blob",
          "size": 17828
        },
        {
          "path": "agents/sre-compliance-generator.md",
          "type": "blob",
          "size": 19940
        },
        {
          "path": "release",
          "type": "tree",
          "size": null
        },
        {
          "path": "release/README.md",
          "type": "blob",
          "size": 1478
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/INTEGRATION_EXAMPLE.md",
          "type": "blob",
          "size": 12807
        },
        {
          "path": "skills/architecture-compliance/STACK_VALIDATION_CHECKLIST.md",
          "type": "blob",
          "size": 2748
        },
        {
          "path": "skills/architecture-compliance/VALIDATION_FRAMEWORK_GUIDE.md",
          "type": "blob",
          "size": 17163
        },
        {
          "path": "skills/architecture-compliance/contracts",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/contracts/CONTRACT_TYPES_REFERENCE.md",
          "type": "blob",
          "size": 15023
        },
        {
          "path": "skills/architecture-compliance/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/shared/MIGRATION_GUIDE.md",
          "type": "blob",
          "size": 12895
        },
        {
          "path": "skills/architecture-compliance/shared/README.md",
          "type": "blob",
          "size": 16289
        },
        {
          "path": "skills/architecture-compliance/shared/fragments",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/shared/fragments/compliance-score-calculation.md",
          "type": "blob",
          "size": 478
        },
        {
          "path": "skills/architecture-compliance/shared/fragments/compliance-summary-footer.md",
          "type": "blob",
          "size": 278
        },
        {
          "path": "skills/architecture-compliance/shared/fragments/status-codes.md",
          "type": "blob",
          "size": 310
        },
        {
          "path": "skills/architecture-compliance/shared/sections",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/shared/sections/change-history-template.md",
          "type": "blob",
          "size": 643
        },
        {
          "path": "skills/architecture-compliance/shared/sections/completion-guide-intro.md",
          "type": "blob",
          "size": 555
        },
        {
          "path": "skills/architecture-compliance/shared/sections/data-extracted-template.md",
          "type": "blob",
          "size": 215
        },
        {
          "path": "skills/architecture-compliance/shared/sections/document-control.md",
          "type": "blob",
          "size": 830
        },
        {
          "path": "skills/architecture-compliance/shared/sections/dynamic-field-instructions.md",
          "type": "blob",
          "size": 1541
        },
        {
          "path": "skills/architecture-compliance/shared/sections/generation-metadata.md",
          "type": "blob",
          "size": 516
        },
        {
          "path": "skills/architecture-compliance/shared/sections/missing-data-table-template.md",
          "type": "blob",
          "size": 281
        },
        {
          "path": "skills/architecture-compliance/shared/sections/not-applicable-template.md",
          "type": "blob",
          "size": 194
        },
        {
          "path": "skills/architecture-compliance/shared/sections/remediation-workflow-guide.md",
          "type": "blob",
          "size": 9485
        },
        {
          "path": "skills/architecture-compliance/shared/sections/unknown-status-table-template.md",
          "type": "blob",
          "size": 313
        },
        {
          "path": "skills/architecture-compliance/shared/sections/validation-methodology.md",
          "type": "blob",
          "size": 1480
        },
        {
          "path": "skills/architecture-compliance/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_BUSINESS_CONTINUITY.md",
          "type": "blob",
          "size": 72137
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_CLOUD_ARCHITECTURE.md",
          "type": "blob",
          "size": 27121
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_DATA_AI_ARCHITECTURE.md",
          "type": "blob",
          "size": 84471
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_DEVELOPMENT_ARCHITECTURE.md",
          "type": "blob",
          "size": 38693
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_ENTERPRISE_ARCHITECTURE.md",
          "type": "blob",
          "size": 52013
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_INTEGRATION_ARCHITECTURE.md",
          "type": "blob",
          "size": 47446
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_PLATFORM_IT_INFRASTRUCTURE.md",
          "type": "blob",
          "size": 61454
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_PROCESS_TRANSFORMATION.md",
          "type": "blob",
          "size": 41905
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_SECURITY_ARCHITECTURE.md",
          "type": "blob",
          "size": 50919
        },
        {
          "path": "skills/architecture-compliance/templates/TEMPLATE_SRE_ARCHITECTURE.md",
          "type": "blob",
          "size": 81169
        },
        {
          "path": "skills/architecture-compliance/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/utils/README.md",
          "type": "blob",
          "size": 16847
        },
        {
          "path": "skills/architecture-compliance/validation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-compliance/validation/README.md",
          "type": "blob",
          "size": 15323
        },
        {
          "path": "skills/architecture-compliance/validation/VALIDATION_EXAMPLES.md",
          "type": "blob",
          "size": 25905
        },
        {
          "path": "skills/architecture-compliance/validation/VALIDATION_RULE_EXAMPLES.md",
          "type": "blob",
          "size": 15980
        },
        {
          "path": "skills/architecture-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-docs/ADR_GUIDE.md",
          "type": "blob",
          "size": 21341
        },
        {
          "path": "skills/architecture-docs/ARCHITECTURE_DOCUMENTATION_GUIDE.md",
          "type": "blob",
          "size": 61884
        },
        {
          "path": "skills/architecture-docs/DESIGN_DRIVER_CALCULATIONS.md",
          "type": "blob",
          "size": 18491
        },
        {
          "path": "skills/architecture-docs/MERMAID_DIAGRAMS_GUIDE.md",
          "type": "blob",
          "size": 29009
        },
        {
          "path": "skills/architecture-docs/METRIC_CALCULATIONS.md",
          "type": "blob",
          "size": 19374
        },
        {
          "path": "skills/architecture-docs/QUERY_SECTION_MAPPING.md",
          "type": "blob",
          "size": 18490
        },
        {
          "path": "skills/architecture-docs/REVIEW_AUDIT_WORKFLOW.md",
          "type": "blob",
          "size": 41004
        },
        {
          "path": "skills/architecture-docs/VALIDATIONS.md",
          "type": "blob",
          "size": 52300
        },
        {
          "path": "skills/architecture-docs/adr",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-docs/adr/ADR-000-template.md",
          "type": "blob",
          "size": 10675
        },
        {
          "path": "skills/architecture-docs/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-docs/examples/ARCHITECTURE_example_3tier.md",
          "type": "blob",
          "size": 18580
        },
        {
          "path": "skills/architecture-docs/examples/README.md",
          "type": "blob",
          "size": 4833
        },
        {
          "path": "skills/architecture-docs/presentation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-docs/presentation/PRESENTATION_GUIDE.md",
          "type": "blob",
          "size": 30446
        },
        {
          "path": "skills/architecture-docs/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-docs/templates/ARCHITECTURE_TYPE_SELECTOR.md",
          "type": "blob",
          "size": 12158
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_4_3TIER.md",
          "type": "blob",
          "size": 14331
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_4_BIAN.md",
          "type": "blob",
          "size": 32946
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_4_META.md",
          "type": "blob",
          "size": 20823
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_4_MICROSERVICES.md",
          "type": "blob",
          "size": 18357
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_4_NLAYER_PATTERNS.md",
          "type": "blob",
          "size": 13333
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_5_3TIER.md",
          "type": "blob",
          "size": 11045
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_5_BIAN.md",
          "type": "blob",
          "size": 38395
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_5_META.md",
          "type": "blob",
          "size": 16168
        },
        {
          "path": "skills/architecture-docs/templates/SECTION_5_MICROSERVICES.md",
          "type": "blob",
          "size": 17018
        },
        {
          "path": "skills/architecture-readiness",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-readiness/PO_SPEC_SCORING_GUIDE.md",
          "type": "blob",
          "size": 25772
        },
        {
          "path": "skills/architecture-readiness/PRODUCT_OWNER_SPEC_GUIDE.md",
          "type": "blob",
          "size": 71618
        },
        {
          "path": "skills/architecture-readiness/SKILL.md",
          "type": "blob",
          "size": 7542
        },
        {
          "path": "skills/architecture-readiness/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture-readiness/templates/PO_SPEC_TEMPLATE.md",
          "type": "blob",
          "size": 11697
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"shadowx4fox-solution-architect-marketplace\",\n  \"owner\": {\n    \"name\": \"shadowX4fox\",\n    \"url\": \"https://github.com/shadowX4fox\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"solutions-architect-skills\",\n      \"source\": \"./\",\n      \"description\": \"Professional architecture documentation workflow: Business requirements, technical architecture, and compliance documentation (10 specialized agents)\",\n      \"version\": \"2.2.0\",\n      \"author\": {\n        \"name\": \"shadowX4fox\"\n      }\n    }\n  ],\n  \"metadata\": {\n    \"description\": \"Official plugin marketplace by shadowX4fox\"\n  }\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"solutions-architect-skills\",\n  \"version\": \"2.2.0\",\n  \"description\": \"Professional architecture documentation workflow: Business requirements ‚Üí Technical architecture ‚Üí Compliance documents (10 specialized compliance agents)\",\n  \"author\": {\n    \"name\": \"shadowX4fox\",\n    \"email\": \"your-email@example.com\",\n    \"url\": \"https://github.com/shadowX4fox\"\n  },\n  \"homepage\": \"https://github.com/shadowX4fox/solutions-architect-skills\",\n  \"repository\": \"https://github.com/shadowX4fox/solutions-architect-skills\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"architecture\",\n    \"documentation\",\n    \"compliance\",\n    \"enterprise\",\n    \"templates\",\n    \"SRE\",\n    \"security\",\n    \"cloud\",\n    \"governance\",\n    \"technical-writing\",\n    \"presentations\",\n    \"powerpoint\"\n  ]\n}",
        "README.md": "# Solutions Architect Skills\n\n[![Version](https://img.shields.io/badge/version-1.5.23-blue.svg)](https://github.com/shadowx4fox/solutions-architect-skills/releases)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Plugin-purple.svg)](https://claude.com/claude-code)\n\nProfessional architecture documentation workflow for Claude Code: Transform business requirements into technical architecture and compliance documents.\n\n## Overview\n\nThis Claude Code plugin provides a complete three-phase workflow for enterprise architecture documentation:\n\n```\nPhase 1: Business Requirements (PO Spec)\n    ‚Üì\nPhase 2: Technical Architecture (ARCHITECTURE.md)\n    ‚Üì\nPhase 3: Compliance Documents (10 contracts)\n```\n\n## Claude Code Marketplace & Plugin System\n\nThis project is distributed as a **Claude Code Plugin** via the **shadowX4fox Marketplace**:\n\n- **Marketplace**: A catalog of available plugins ([Learn more](https://docs.anthropic.com/claude/docs/claude-code-plugins))\n- **Plugin**: This repository, installable from the marketplace\n- **Skills**: Three specialized tools within the plugin\n\nFor detailed information about Claude Code's plugin system, see the [official Claude Code documentation](https://docs.anthropic.com/claude/docs/claude-code).\n\n---\n\n### What's Included\n\n- **3 Integrated Skills**\n  - `architecture-readiness`: Product Owner Specifications\n  - `architecture-docs`: ARCHITECTURE.md creation and maintenance\n  - `architecture-compliance`: Generate 10 compliance contracts\n\n- **10 Compliance Templates**\n  - Business Continuity, SRE, Cloud, Security, Enterprise Architecture, and more\n\n- **Automatic Validation** ‚≠ê NEW v1.3.0\n  - External validation system (0-10 scoring) for all 10 contracts\n  - 4-tier approval workflow (Auto-approve, Manual review, Needs work, Rejected)\n  - Template-specific validation configurations\n  - Metric consistency checking\n  - Design Drivers calculation\n\n- **Complete Documentation**\n  - Installation guide, Quick Start tutorial, Workflow guide, Troubleshooting\n\n## Quick Start\n\n### Installation\n\n**See [Installation Guide](docs/INSTALLATION.md) for detailed instructions.**\n\n**Quick Start (Using Marketplace - Recommended):**\n\n```bash\n# Step 1: Register marketplace (one-time)\n/plugin marketplace add shadowX4fox/solutions-architect-skills\n\n# Step 2: Install plugin\n/plugin install solutions-architect-skills@shadowx4fox-solution-architect-marketplace\n\n# Step 3: Verify installation\n/plugin list\n```\n\n**Alternative: Direct Git Clone**\n\n```bash\n# Clone directly to plugins directory\ngit clone https://github.com/shadowX4fox/solutions-architect-skills.git ~/.claude/plugins/solutions-architect-skills\n\n# Restart Claude Code and verify\n/plugin list\n```\n\nYou should see `solutions-architect-skills v1.9.0` in the list.\n\n**Important:** Marketplace registration is a security feature - you must explicitly add marketplaces before installing plugins. See [docs/INSTALLATION.md](docs/INSTALLATION.md) for detailed setup instructions.\n\n### First Workflow\n\n```bash\n# Phase 1: Create Product Owner Spec\n/skill architecture-readiness\n\n# Phase 2: Create ARCHITECTURE.md\n/skill architecture-docs\n\n# Phase 3: Generate compliance documents\n/skill architecture-compliance\n```\n\n## Features\n\n### Phase 1: Architecture Readiness (Product Owner)\n\nCreate comprehensive Product Owner Specifications before technical design begins.\n\n**Key Features:**\n- 8-section template (Business Context, User Personas, Use Cases, Success Criteria, etc.)\n- Weighted scoring methodology (0-10 scale)\n- Readiness threshold: ‚â•7.5 for architecture handoff\n- Focus: Business requirements, no technical implementation\n\n**Output:** `PRODUCT_OWNER_SPEC.md`\n\n### Phase 2: Architecture Documentation\n\nCreate and maintain technical architecture documentation following enterprise standards.\n\n**Key Features:**\n- 12-section standardized structure (Executive Summary ‚Üí ADRs)\n- Automatic Document Index (lines 1-50)\n- 5 architecture type templates (META, 3-Tier, Microservices, N-Layer, BIAN) ‚≠ê UPDATED v1.5\n- Interactive Mermaid diagrams in Section 4\n- Metric consistency validation across document\n- Design Drivers calculation (Value Delivery %, Scale, Impacts)\n- 9 mandatory Architecture Principles + 1 optional\n- ADR (Architecture Decision Record) templates\n- **Automatic ADR file generation** from Section 12 table ‚≠ê NEW v1.5\n\n**Output:** `ARCHITECTURE.md` (2,000-3,000 lines typically)\n\n### Phase 3: Compliance Documentation\n\nGenerate compliance contracts from ARCHITECTURE.md with full traceability.\n\n**Key Features:**\n- Context-efficient generation (70-80% reduction in loaded content)\n- **v1.3.0**: 11 complete compliance contracts with external validation system ‚≠ê NEW\n- **Automatic Validation (0-10 scoring)**: All contracts validated with granular scoring ‚≠ê NEW\n- **4-Tier Approval Workflow**: Auto-approve (8.0-10), Manual review (7.0-7.9), Needs work (5.0-6.9), Rejected (0-4.9) ‚≠ê NEW\n- Source traceability (section + line number references)\n- [PLACEHOLDER] markers for missing data with completion guidance\n- Compliance manifest (index of all generated documents)\n\n**Output:** `/compliance-docs/` directory with all 10 contracts + manifest (v1.3.0)\n\n**üéØ New in v1.5.0: Business Continuity v2.0**\n- Table-based format with 43 LACN requirements (expanded from 10 LABC)\n- 6-column compliance summary table\n- 330% increase in validation data points\n- Cloud-native resilience patterns (circuit breaker, retry, bulkhead, auto-scaling)\n\n#### Compliance Contract Types ‚≠ê v1.3.0: All 10 Contracts Complete\n\n**‚úÖ All 10 Contracts with External Validation System**:\n\n1. **Business Continuity** - RTO/RPO, disaster recovery, backup strategy, resilience\n2. **SRE Architecture** - SLOs, error budgets, monitoring, incident management, observability\n3. **Cloud Architecture** - Deployment model, cloud provider, connectivity, security\n4. **Security Architecture** - API security, authentication, encryption, compliance, controls\n5. **Data & Analytics/AI Architecture** - Data quality, AI governance, model validation, hallucination control\n6. **Development Architecture** - Technology stack, coding standards, technical debt, **26-item validation**\n7. **Process Transformation** - Automation, efficiency, ROI analysis, workflow optimization\n8. **Platform & IT Infrastructure** - Environments, databases, capacity, naming conventions\n9. **Enterprise Architecture** - Strategic alignment, modularity, cloud-first, API-first, governance\n10. **Integration Architecture** - Integration catalog, patterns, API security, standards\n\n**üéØ New in v1.3.0: External Validation System**\n\nAll 10 contracts now include automatic validation with:\n- **Scoring (0-10 scale)**: Granular feedback on compliance completeness\n- **4-Tier Approval**:\n  - **8.0-10.0**: Auto-approved by system (high confidence)\n  - **7.0-7.9**: Manual review required by approval authority\n  - **5.0-6.9**: Draft status - must address gaps\n  - **0.0-4.9**: Rejected - cannot proceed\n- **Template-Specific Rules**: Each contract has customized validation criteria\n- **Full Traceability**: All scores link back to ARCHITECTURE.md sources\n- **Actionable Feedback**: Clear recommendations for improving scores\n\n**Validation Configuration Files**: 11 JSON configs in `/skills/architecture-compliance/validation/`\n\n## Architecture Types & Visualization\n\n### 5 Supported Architecture Types\n\nChoose the architecture type that best fits your system:\n\n**1. META (6-Layer Enterprise)** - Large enterprise systems with complex integrations\n- Layers: Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Business ‚Üí Domain ‚Üí Core\n- Best for: Financial services, regulated industries, enterprise platforms\n- Template: Section 4 META with BIAN V12.0 alignment\n- **BIAN Standard**: Full V12.0 compliance with 12 metadata fields ‚≠ê ENHANCED v1.5\n- **Layer 5 Enhancement**: Matches BIAN Layer 4 comprehensiveness with complete service domain metadata\n\n**2. 3-Tier (Classic Web Application)** - Standard web applications and REST APIs\n- Tiers: Presentation ‚Üí Application/Business Logic ‚Üí Data\n- Best for: Web apps, line-of-business applications, standard CRUD systems\n- Template: Section 4 3-Tier with tier separation enforcement\n\n**3. Microservices (Cloud-Native)** - Distributed systems with independent services\n- Components: API Gateway, Service Mesh, Event Bus, independent services\n- Best for: Cloud-native systems, event-driven architectures, polyglot environments\n- Template: Section 4 Microservices with service catalog\n\n**4. N-Layer (DDD/Clean Architecture)** - Flexible custom patterns\n- Patterns: Classic DDD (4-Layer), Extended (5-Layer), Clean Architecture\n- Best for: Domain-Driven Design, Hexagonal Architecture, testable systems\n- Template: Section 4 N-Layer with dependency inversion\n\n**5. BIAN (Full BIAN V12.0 Certification)** - Pure BIAN Service Landscape architecture ‚≠ê NEW v1.5\n- Layers: Channels ‚Üí BIAN Business Scenarios ‚Üí BIAN Business Capabilities ‚Üí BIAN Service Domains ‚Üí Core Systems\n- Best for: Banking, financial services requiring full BIAN certification\n- Template: Section 4 BIAN and Section 5 BIAN with comprehensive metadata\n- **Compliance**: Mandatory full BIAN V12.0 compliance (12 metadata fields, 7 standard operations)\n- **Validation**: All service domain names validated against official [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- **Traceability**: Full BIAN hierarchy (Service Domain ‚Üí Business Domain ‚Üí Business Area)\n\n**How to Choose**: See [ARCHITECTURE_TYPE_SELECTOR.md](skills/architecture-docs/templates/ARCHITECTURE_TYPE_SELECTOR.md) for decision tree and comparison matrix.\n\n### Interactive Mermaid Diagrams\n\nAll ARCHITECTURE.md documents include **Mermaid architecture diagrams** integrated into Section 4:\n\n**Capabilities**:\n- ‚úÖ Interactive visualization (zoom, pan, clickable components)\n- ‚úÖ Color-coded components (Blue=Orchestrators, Orange=Workers, Green=Query, Purple=Events)\n- ‚úÖ Data flow patterns (solid arrows=synchronous, dashed arrows=asynchronous)\n- ‚úÖ Security protocol visualization (OAuth 2.0, JWT, mTLS, TLS 1.2+, SASL)\n- ‚úÖ GitHub/GitLab native rendering (no plugins required)\n- ‚úÖ Professional, maintainable, version-control-friendly\n\n**Comprehensive Guide**: See [MERMAID_DIAGRAMS_GUIDE.md](skills/architecture-docs/MERMAID_DIAGRAMS_GUIDE.md) for templates, color schemes, and examples.\n\n## Documentation\n\n- **[Installation Guide](docs/INSTALLATION.md)** - Detailed installation instructions\n- **[Quick Start](docs/QUICK_START.md)** - 5-minute getting started tutorial\n- **[Workflow Guide](docs/WORKFLOW_GUIDE.md)** - Complete end-to-end workflow\n- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - FAQ and common issues\n\n## Examples\n\n### Real-World Example Repository\n\n**[Task Scheduling Platform Example](https://github.com/shadowX4fox/task-scheduling-example)** ‚≠ê\n\nComplete end-to-end demonstration of the three-phase workflow:\n\n**Phase 1: Product Owner Specification**\n- Business requirements and user personas\n- Use cases and success criteria\n- Weighted readiness scoring (8.3/10)\n\n**Phase 2: Technical Architecture (ARCHITECTURE.md)**\n- 12-section comprehensive architecture document\n- Microservices architecture pattern\n- Interactive Mermaid diagrams\n- Technology stack documentation\n- Complete with metrics, SLOs, and ADRs\n\n**Phase 3: Compliance Documentation**\n- All 11 generated compliance contracts with v1.3.0 validation\n- Development Architecture with 26-item stack validation\n- Security, Cloud, SRE, and Enterprise Architecture contracts\n- Full source traceability to ARCHITECTURE.md\n\n**Repository**: https://github.com/shadowX4fox/task-scheduling-example\n\n---\n\n**Additional Examples in This Repository:**\n\nThe `examples/` directory contains reference templates:\n\n- **PRODUCT_OWNER_SPEC_example.md** - PO Spec template (Job Scheduling Platform)\n- **ARCHITECTURE_example.md** - Full ARCHITECTURE.md template (2000+ lines)\n\n---\n\n**Want More Examples?**\n\nTo request specific examples or use cases, [open an issue](https://github.com/shadowx4fox/solutions-architect-skills/issues/new).\n\n## Requirements\n\n- **Claude Code** (latest version)\n- **Bun** (v1.0.0 or later) - Required for compliance generation and template validation\n- **Platform:** macOS, Linux, or Windows\n\n### Why Bun?\n\nThe architecture-compliance skill uses Bun for:\n- Template expansion with `@include` directives\n- Pre-validation of template structure (Phase 4.1)\n- Post-validation of generated contracts (Phase 4.6)\n- High-performance TypeScript execution\n\n**Installation:** See [INSTALLATION.md](docs/INSTALLATION.md#installing-bun) for Bun setup instructions.\n\n## Use Cases\n\nPerfect for:\n- Enterprise architects documenting solution designs\n- Product Owners preparing requirements for architecture teams\n- Compliance teams generating organizational contracts\n- Technical leads maintaining architecture documentation\n- Teams needing standardized architecture workflows\n\n## Workflow Integration\n\n```mermaid\ngraph LR\n    A[Product Owner] -->|Creates| B[PO Spec]\n    B -->|Input to| C[Architecture Team]\n    C -->|Creates| D[ARCHITECTURE.md]\n    D -->|Generates| E[10 Compliance Contracts]\n    E -->|Review by| F[Compliance Team]\n```\n\n## External Validation System (v1.3.0)\n\nAll 10 compliance contracts use an **external validation system** with standardized 0-10 scoring:\n\n### Validation States & Scoring\n- ‚úÖ **PASS (10 points)**: Complies with requirements\n- ‚ùå **FAIL (0 points)**: Non-compliant or deprecated technology\n- ‚ö™ **N/A (10 points)**: Not applicable to this architecture\n- ‚ùì **UNKNOWN (0 points)**: Missing data in ARCHITECTURE.md\n- üîì **EXCEPTION (10 points)**: Documented exception via LADES2 process\n\n### Scoring Formula\n```\nFinal Score = (Completeness √ó 0.4) + (Compliance √ó 0.5) + (Quality √ó 0.1)\n\nWhere:\n- Completeness = (Filled required fields / Total required) √ó 10\n- Compliance = (PASS + N/A + EXCEPTION items / Total applicable) √ó 10\n- Quality = Source traceability coverage (0-10)\n```\n\n### Approval Workflow\n| Score | Status | Review Actor | Outcome |\n|-------|--------|--------------|---------|\n| 8.0-10.0 | Approved | System (Auto-Approved) | Ready for implementation |\n| 7.0-7.9 | In Review | [Approval Authority] | Manual review required |\n| 5.0-6.9 | Draft | Architecture Team | Address gaps before review |\n| 0.0-4.9 | Rejected | N/A (Blocked) | Cannot proceed to review |\n\n### Validation Configuration\n- **11 JSON config files**: One per contract type in `/skills/architecture-compliance/validation/`\n- **Template-specific weights**: Each contract can customize Completeness/Compliance/Quality weights\n- **Validation schema**: `VALIDATION_SCHEMA.json` defines standard structure\n- **Example scenarios**: `VALIDATION_EXAMPLES.md` shows all 4 outcome tiers\n\n### Example: Development Architecture Validation\nThe Development Architecture contract validates against a **26-item checklist**:\n- **Java Backend** (6 items): Version, Spring Boot, tools, containers, libraries, naming\n- **.NET Backend** (6 items): C# version, ASP.NET Core, tools, containers, libraries, naming\n- **Frontend** (6 items): Framework, TypeScript/JavaScript, tools, architecture, libraries, naming\n- **Other Stacks** (5 items): Automation, IaC, databases, APIs, CI/CD\n- **Exceptions** (3 items): Deviations exist?, Documented?, Approved?\n\n## Roadmap\n\n### v1.5.0 (Current Release) ‚úÖ\n**Major Release: BIAN Full Compliance + Business Continuity v2.0**\n\n- ‚úÖ **5th Architecture Type: Full BIAN V12.0** ‚≠ê MAJOR\n  - New SECTION_4_BIAN.md and SECTION_5_BIAN.md templates\n  - Mandatory Full BIAN V12.0 compliance (no Partial/Custom options)\n  - 12 BIAN metadata fields (expanded from 4)\n  - 7 standardized BIAN service operations (Initiate, Update, Retrieve, Control, Exchange, Execute, Request)\n  - Full BIAN hierarchy traceability (Service Domain ‚Üí Business Domain ‚Üí Business Area)\n  - All service domain names validated against official BIAN V12.0 Service Landscape\n- ‚úÖ **META Layer 5 Enhancement** - Upgraded to match BIAN Layer 4 comprehensiveness\n  - Expanded from 4 to 12 BIAN metadata fields\n  - Complete service domain documentation requirements\n- ‚úÖ **Business Continuity v2.0** - Table-based format with 43 LACN requirements ‚≠ê MAJOR\n  - Expanded from 10 LABC to 43 LACN requirements (330% increase in validation coverage)\n  - 6-column compliance summary table (Code, Requirement, Category, Status, Source, Role)\n  - 6 validation categories: BC-GEN, BC-RTO, BC-DR, BC-BACKUP, BC-AUTO, BC-CLOUD\n  - Cloud-native resilience patterns (circuit breaker, retry, bulkhead, auto-scaling)\n  - Comprehensive disaster recovery documentation\n- ‚úÖ **Automatic ADR file generation** from Section 12 table in ARCHITECTURE.md\n  - 4-option prompt: Generate, Preview, Skip, Learn More\n  - Automatic metadata population (title, status, date, authors)\n  - Slug generation with conflict handling\n  - Creates `adr/` directory with properly formatted ADR files\n- ‚úÖ **Enhanced compliance validation** - Multi-layer format enforcement\n  - LACN003 extraction for META architecture layers\n  - Template format validators with strict enforcement\n  - Improved error messages and validation feedback\n- ‚úÖ **Principle #10 rename** - \"Decouple Through Events\" (formerly \"Event-Driven Integration\")\n\n### v1.3.0 (Previous Release)\n**Major Release: Complete Validation System**\n\n- ‚úÖ **All 10 compliance contracts** with templates and validation ‚≠ê MAJOR\n- ‚úÖ **External validation system** (0-10 scoring, 4-tier approval) ‚≠ê MAJOR\n- ‚úÖ **10 validation configuration files** (JSON-based, template-specific)\n- ‚úÖ **Validation documentation**:\n  - `VALIDATION_SCHEMA.json` - Schema definition\n  - `VALIDATION_EXAMPLES.md` - 4-tier outcome examples\n  - Updated COMPLIANCE_GENERATION_GUIDE.md\n  - Updated SKILL.md workflow\n- ‚úÖ **Document Control standardization** across all 11 templates\n- ‚úÖ **Automated approval workflow**:\n  - Auto-approve: Score ‚â• 8.0\n  - Manual review: Score 7.0-7.9\n  - Needs work: Score 5.0-6.9\n  - Rejected: Score < 5.0\n\n### v1.2.2 (Previous Release)\n- ‚úÖ Document Control format standardization\n- ‚úÖ Strict source traceability enforcement\n\n### v1.2.0\n- ‚úÖ 3 integrated skills (architecture-readiness, architecture-docs, architecture-compliance)\n- ‚úÖ 4 architecture types with Mermaid diagrams (META, 3-Tier, Microservices, N-Layer)\n- ‚úÖ BIAN V12.0 integration for META architecture\n- ‚úÖ 4 ready-to-use compliance contracts\n- ‚úÖ Enhanced Data & AI Architecture compliance (Version 2.0)\n\n### v1.1.0\n- ‚úÖ Initial release with 3 compliance contracts\n- ‚úÖ Foundation for architecture documentation workflow\n\n### Future Releases üöÄ\n\n### v2.0.0 (Future)\n- Multi-project support\n- Custom compliance contract templates\n- Integration with CI/CD pipelines\n- Advanced reporting and dashboards\n\n---\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues or pull requests.\n\n### Reporting Issues\n\nIf you encounter problems:\n1. Check the [Troubleshooting Guide](docs/TROUBLESHOOTING.md)\n2. Search [existing issues](https://github.com/shadowx4fox/solutions-architect-skills/issues)\n3. Open a new issue with detailed description\n\n### Feature Requests\n\nHave an idea for improvement? Open an issue with the `enhancement` label.\n\n## Version History\n\nSee [CHANGELOG.md](CHANGELOG.md) for detailed version history.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**shadowx4fox**\n- GitHub: [@shadowx4fox](https://github.com/shadowx4fox)\n- Repository: [solutions-architect-skills](https://github.com/shadowx4fox/solutions-architect-skills)\n\n## Acknowledgments\n\n- Built for [Claude Code](https://claude.com/claude-code) by Anthropic\n- Follows enterprise architecture best practices\n- Inspired by organizational compliance frameworks\n\n---\n\n**Get Started:** Download the [latest release](https://github.com/shadowx4fox/solutions-architect-skills/releases) and transform your architecture workflow today!",
        "agents/MIGRATION.md": "# Compliance Generator Migration (v1.9.0 ‚Üí v2.0.0)\n\n## What Changed\n\n### Before (v1.9.0)\n- **1 generic agent**: `compliance-generator`\n- **Parameter-based**: Required `contract_type` parameter\n- **Runtime lookup**: Section mapping looked up at execution time\n- **Sequential execution**: One contract at a time\n\n### After (v2.0.0)\n- **10 specialized agents**: One agent per contract type\n- **Pre-configured**: No parameters needed (contract type built-in)\n- **Optimized mapping**: Section mapping pre-configured for performance\n- **Parallel execution**: All 10 agents can run simultaneously\n\n---\n\n## Architecture Changes\n\n### Agent Structure\n\n**v1.9.0 Architecture:**\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Architecture Compliance Skill  ‚îÇ\n‚îÇ                                 ‚îÇ\n‚îÇ  Launches:                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ compliance-generator     ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ (Generic Agent)          ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ                          ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ Input:                   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ - contract_type: \"sre\"   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ - architecture_file      ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ                          ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ Workflow:                ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ 1. Map contract ‚Üí tmpl   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ 2. Lookup sections       ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ 3. Extract data          ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ 4. Generate contract     ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ 5. Generate manifest     ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**v2.0.0 Architecture:**\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         Architecture Compliance Skill                   ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  Phase 1: Parse user intent                             ‚îÇ\n‚îÇ  Phase 2: Validate contract selection                   ‚îÇ\n‚îÇ  Phase 3: Invoke specialized agent(s)                   ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ  ‚îÇ cloud-compliance ‚îÇ  ‚îÇ sre-compliance   ‚îÇ  ... (10)  ‚îÇ\n‚îÇ  ‚îÇ -generator       ‚îÇ  ‚îÇ -generator       ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ Pre-configured:  ‚îÇ  ‚îÇ Pre-configured:  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ ‚Ä¢ Type: cloud    ‚îÇ  ‚îÇ ‚Ä¢ Type: sre      ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ ‚Ä¢ Sections:      ‚îÇ  ‚îÇ ‚Ä¢ Sections:      ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ   4,8,11,9,10    ‚îÇ  ‚îÇ   10,11,5        ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ ‚Ä¢ Data patterns  ‚îÇ  ‚îÇ ‚Ä¢ Data patterns  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ Workflow:        ‚îÇ  ‚îÇ Workflow:        ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ 1. Expand tmpl   ‚îÇ  ‚îÇ 1. Expand tmpl   ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ 2. Extract data  ‚îÇ  ‚îÇ 2. Extract data  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ 3. Populate      ‚îÇ  ‚îÇ 3. Populate      ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ 4. Write output  ‚îÇ  ‚îÇ 4. Write output  ‚îÇ            ‚îÇ\n‚îÇ  ‚îÇ 5. Return meta   ‚îÇ  ‚îÇ 5. Return meta   ‚îÇ            ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n‚îÇ           ‚îÇ                      ‚îÇ                       ‚îÇ\n‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ\n‚îÇ                      ‚ñº                                   ‚îÇ\n‚îÇ  Phase 4: Collect results, generate manifest            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Key Differences\n\n| Aspect | v1.9.0 | v2.0.0 |\n|--------|--------|--------|\n| **Agents** | 1 generic agent | 10 specialized agents |\n| **Configuration** | Runtime parameter | Pre-configured (compile-time) |\n| **Section Mapping** | Runtime lookup | Pre-configured (embedded) |\n| **Data Extraction** | Generic patterns | Domain-specific patterns |\n| **Parallelization** | Manual (10x same agent) | Native (10 different agents) |\n| **Manifest Generation** | Agent responsibility | Skill orchestrator responsibility |\n| **Performance (10 contracts)** | Sequential or manual parallel | Automatic parallel (10x faster) |\n\n---\n\n## Migration Guide\n\n### 1. Direct Agent Invocation\n\nIf you were invoking the agent directly (not common):\n\n**v1.9.0 (Old):**\n```python\nTask(\n    subagent_type=\"solutions-architect-skills:compliance-generator\",\n    prompt=\"Generate SRE Architecture contract from ./ARCHITECTURE.md\",\n    contract_type=\"sre_architecture\"  # Required parameter\n)\n```\n\n**v2.0.0 (New):**\n```python\nTask(\n    subagent_type=\"solutions-architect-skills:sre-compliance-generator\",\n    prompt=\"Generate SRE Architecture compliance contract from ./ARCHITECTURE.md\"\n    # No contract_type parameter needed - pre-configured in agent\n)\n```\n\n**Changes:**\n- Agent name changed: `compliance-generator` ‚Üí `sre-compliance-generator`\n- No `contract_type` parameter required\n- More descriptive subagent_type names\n\n### 2. Skill Invocation (Recommended)\n\n**v1.9.0 and v2.0.0 (No Change):**\n```\n/skill architecture-compliance\n/skill architecture-compliance SRE\n/skill architecture-compliance all\n/skill architecture-compliance SRE,Cloud,Security\n```\n\n**Backward Compatible:** All skill invocations work identically in v2.0.0. The skill handles agent routing internally.\n\n### 3. Bulk Generation\n\n**v1.9.0 (Manual Parallel):**\n```python\n# Launch 10 instances of generic agent with different contract_type\nTask(subagent_type=\"...:compliance-generator\", contract_type=\"business_continuity\", ...),\nTask(subagent_type=\"...:compliance-generator\", contract_type=\"sre_architecture\", ...),\nTask(subagent_type=\"...:compliance-generator\", contract_type=\"cloud_architecture\", ...),\n# ... (repeat 10 times)\n```\n\n**v2.0.0 (Native Parallel):**\n```python\n# Launch 10 specialized agents in parallel\nTask(subagent_type=\"...:business-continuity-compliance-generator\", ...),\nTask(subagent_type=\"...:sre-compliance-generator\", ...),\nTask(subagent_type=\"...:cloud-compliance-generator\", ...),\n# ... (10 different agents)\n```\n\n**Benefits:**\n- Clearer intent (agent names are self-documenting)\n- No contract_type parameter to manage\n- Easier to selectively launch subset of agents\n\n---\n\n## Benefits of v2.0.0\n\n### 1. Performance\n- **Pre-configured section mappings**: No runtime lookup overhead\n- **Domain-specific extraction**: Optimized patterns per contract type\n- **Parallel execution**: 10 agents in parallel ~10x faster than sequential\n\n### 2. Clarity\n- **Single responsibility**: Each agent has one clear purpose\n- **Self-documenting**: Agent name = contract type\n- **Easier debugging**: Issues isolated to specific agent\n\n### 3. Optimization\n- **Domain expertise**: Each agent specialized for its compliance domain\n- **Targeted patterns**: Grep patterns optimized per contract type\n- **Minimal context**: Load only required sections per agent\n\n### 4. Maintainability\n- **Independent updates**: Update one agent without affecting others\n- **Clear ownership**: Each contract type has dedicated agent\n- **Easier testing**: Test individual agents in isolation\n\n### 5. Scalability\n- **Parallel-first**: Designed for concurrent execution\n- **No shared state**: Fully independent agents\n- **Manifest safety**: Skill handles manifest to prevent conflicts\n\n### 6. Output Discipline\n- **Single file output**: Each agent creates exactly one .md contract file\n- **No extraneous files**: Agents explicitly prohibited from creating .txt reports or additional files\n- **Predictable behavior**: All output follows strict specification\n\n---\n\n## Breaking Changes\n\n### ‚ö†Ô∏è Direct Agent Invocation\n\nIf you were directly invoking the `compliance-generator` agent (not via skill):\n\n**Change Required:**\n- Update subagent_type to specific agent (e.g., `sre-compliance-generator`)\n- Remove `contract_type` parameter\n\n### ‚úÖ Skill Invocation\n\nIf you were using the skill (recommended approach):\n\n**No Changes Required:** The skill handles agent routing internally. All existing invocations work identically.\n\n---\n\n## Backward Compatibility\n\n**Skill-Level: Full Compatibility**\n- All `/skill architecture-compliance` invocations work identically\n- User experience unchanged\n- Internal implementation upgraded transparently\n\n**Agent-Level: Breaking Change**\n- Generic `compliance-generator` agent removed\n- Must use specialized agents directly\n- **Recommendation**: Use skill invocation instead of direct agent calls\n\n---\n\n## Testing Your Migration\n\n### Test 1: Single Contract Generation\n```bash\n# Via skill (recommended)\n/skill architecture-compliance SRE\n\n# Expected output:\n# ‚úÖ Generated SRE Architecture compliance contract successfully\n# File: /compliance-docs/SRE_ARCHITECTURE_[PROJECT]_[DATE].md\n```\n\n### Test 2: Bulk Contract Generation\n```bash\n# Via skill\n/skill architecture-compliance all\n\n# Expected output:\n# ‚úÖ Generated 10 compliance contracts successfully\n# ‚úÖ Generated COMPLIANCE_MANIFEST.md\n# Files: /compliance-docs/\n```\n\n### Test 3: Selective Contracts\n```bash\n# Via skill\n/skill architecture-compliance Cloud,Security,Development\n\n# Expected output:\n# ‚úÖ Generated 3 compliance contracts successfully\n# Files:\n#   - CLOUD_ARCHITECTURE_[PROJECT]_[DATE].md\n#   - SECURITY_ARCHITECTURE_[PROJECT]_[DATE].md\n#   - DEVELOPMENT_ARCHITECTURE_[PROJECT]_[DATE].md\n```\n\n### Test 4: Direct Agent Invocation (Advanced)\n```python\n# Direct invocation of specialized agent\nTask(\n    subagent_type=\"solutions-architect-skills:cloud-compliance-generator\",\n    prompt=\"Generate Cloud Architecture compliance contract from ./ARCHITECTURE.md\",\n    description=\"Generate Cloud compliance\"\n)\n\n# Expected output:\n# ‚úÖ Generated Cloud Architecture compliance contract successfully\n# (Agent returns metadata to caller)\n```\n\n---\n\n## Troubleshooting\n\n### Issue: \"Agent not found: compliance-generator\"\n\n**Cause:** Using old generic agent name\n\n**Solution:**\n```diff\n- subagent_type=\"solutions-architect-skills:compliance-generator\"\n+ subagent_type=\"solutions-architect-skills:cloud-compliance-generator\"\n```\n\nOr use skill invocation instead: `/skill architecture-compliance Cloud`\n\n### Issue: \"Unknown parameter: contract_type\"\n\n**Cause:** Passing contract_type parameter to specialized agent\n\n**Solution:**\n```diff\nTask(\n    subagent_type=\"solutions-architect-skills:sre-compliance-generator\",\n    prompt=\"Generate SRE Architecture contract\",\n-   contract_type=\"sre_architecture\"  # Remove this\n)\n```\n\n### Issue: Manifest not generated when using direct agent invocation\n\n**Cause:** Individual agents don't generate manifests (by design)\n\n**Solution:** Use skill invocation (`/skill architecture-compliance`), which handles manifest generation after agents complete.\n\n---\n\n## Rollback Instructions\n\nIf you need to rollback to v1.9.0:\n\n```bash\n# Checkout previous version\ngit checkout v1.9.0\n\n# Or restore generic agent file\ngit checkout v1.9.0 -- agents/compliance-generator.md\n```\n\n**Note:** v2.0.0 is recommended for performance and maintainability. Rollback only if critical issues occur.\n\n---\n\n## Questions?\n\nFor issues or questions about migration:\n1. Check skill documentation: `skills/architecture-compliance/SKILL.md`\n2. Review agent files: `agents/*-compliance-generator.md`\n3. Report issues: https://github.com/shadowX4fox/solutions-architect-skills/issues\n\n---\n\n**Migration Document Version**: 1.0\n**Last Updated**: 2025-12-27\n**Applies To**: v1.9.0 ‚Üí v2.0.0\n",
        "agents/business-continuity-compliance-generator.md": "---\nname: business-continuity-compliance-generator\ndescription: Business Continuity Compliance Contract Generator - Generates Business Continuity compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Business Continuity Compliance Generation Agent\n\n## Mission\nGenerate Business Continuity compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `business_continuity`\n**Template**: `TEMPLATE_BUSINESS_CONTINUITY.md`\n**Section Mapping**: Sections 1, 3, 4, 5, 7, 8, 10, 11\n\n**Key Data Points**:\n- RTO (Recovery Time Objective)\n- RPO (Recovery Point Objective)\n- Disaster recovery procedures\n- Backup strategy and retention\n- SPOF (Single Point of Failure) analysis\n- Geographic redundancy\n- High availability design\n\n**Focus Areas**:\n- Business continuity planning\n- Disaster recovery automation\n- Backup and restoration procedures\n- Critical process impact\n- Resilience patterns\n\n**Requirements**: 43 (LACN001-LACN043)\n**Categories**: BC-GEN, BC-RTO, BC-DR, BC-BACKUP, BC-AUTO, BC-CLOUD\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_BUSINESS_CONTINUITY.md \\\n  /tmp/expanded_bc_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_bc_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_bc_template.md > /tmp/cleaned_bc_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_bc_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\n**Step 2.1: Read Document Header**\n\nUse Read tool to read first 50 lines of ARCHITECTURE.md:\n```\nRead file: [architecture_file]\nLimit: 50 lines\nExtract project name from first H1 (line starting with \"# \")\n```\n\n**Step 2.2: Get Current Date**\n\nUse Bash tool:\n```bash\ndate +%Y-%m-%d\n```\nStore as: generation_date\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Business Continuity**\n\nPRE-CONFIGURED sections to extract:\n- **Section 1** (Business Context): Critical business processes, business impact\n- **Section 3** (System Architecture): Architecture pattern, SPOF identification\n- **Section 4** (System Components): Component dependencies, criticality\n- **Section 5** (Data Architecture): Data backup, retention policies\n- **Section 7** (Integration Architecture): Integration dependencies, failover\n- **Section 8** (Infrastructure): Geographic redundancy, HA configuration\n- **Section 10** (Performance): SLA targets, availability requirements\n- **Section 11** (Operational): DR procedures, backup automation, monitoring\n\n**Step 3.2: Extract Section Content**\n\nFor each required section (1, 3, 4, 5, 7, 8, 10, 11):\n\n1. Use Grep tool to find section start:\n```\npattern: \"^## [section_number]\\.? |^## [section_number] \"\nfile: [architecture_file]\noutput_mode: content\n-n: true\n```\n\n2. Use Read tool to read section:\n```\nRead file: [architecture_file]\noffset: [section_start_line]\nlimit: 200 (or until next section)\n```\n\n**Step 3.3: Extract Business Continuity-Specific Data Points**\n\n**RTO Detection** (Section 10 or 11):\n```\npattern: \"RTO[:\\s]+([0-9]+)\\s*(hour|minute|day|hr|min)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**RPO Detection** (Section 10 or 11):\n```\npattern: \"RPO[:\\s]+([0-9]+)\\s*(hour|minute|day|hr|min)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Disaster Recovery** (Section 11):\n```\npattern: \"(disaster recovery|DR procedure|DR plan|failover|recovery plan)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Backup Strategy** (Section 5 or 11):\n```\npattern: \"(backup|snapshot|replication|incremental backup|full backup)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Retention Policy** (Section 5 or 11):\n```\npattern: \"(retention|backup retention|retention period|backup schedule)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Geographic Redundancy** (Section 8):\n```\npattern: \"(geographic|geo[- ]redundan|multi[- ]region|cross[- ]region|multi[- ]datacenter)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**High Availability** (Section 8 or 11):\n```\npattern: \"(high availability|HA|active[- ]active|active[- ]passive|load balanc)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**SPOF Analysis** (Section 3 or 11):\n```\npattern: \"(single point of failure|SPOF|single point|redundancy)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Critical Processes** (Section 1):\n```\npattern: \"(critical process|business critical|mission critical|tier 1)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Business Continuity Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Business Continuity Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\nStatus: Compliant\nReplacement: RTO documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 11.3`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.3, lines 234-240`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.3 (DR section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**RTO**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**RTO**: 4 hours\n```\n\nINCORRECT (added context):\n```\n**RTO**: 4 hours for critical systems as documented\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: RTO documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: Recovery Time Objective of 4 hours is documented and meets business continuity requirements\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 11.3\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 11.3, lines 234-240\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement RTO in Section 11]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement RTO in Section 11\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| RTO | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| RTO | 4 hours |\n```\n\nINCORRECT (converted to bold list):\n```\n**RTO**: 4 hours\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n**CRITICAL**: This phase calculates validation score and updates contract fields BEFORE writing output.\n\n**Step 4.6.1: Run Score Calculation**\n\nUse Bash tool to execute score calculator:\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts \\\n  /tmp/populated_business_continuity_contract.md \\\n  validation/business_continuity_validation.json\n```\n\n**Output**: JSON with validation score, written to `/tmp/validation_score.json`\n\n**Step 4.6.2: Update Contract Fields**\n\nUse Bash tool to execute field updater:\n```bash\nbun skills/architecture-compliance/utils/field-updater-cli.ts \\\n  /tmp/populated_business_continuity_contract.md \\\n  /tmp/validation_score.json \\\n  /tmp/final_business_continuity_contract.md\n```\n\n**What This Does**:\n- Reads populated contract from Step 4.6.1 input\n- Reads validation score JSON from `/tmp/validation_score.json`\n- Updates Document Control fields:\n  - `[VALIDATION_SCORE]` ‚Üí `\"8.7/10\"` (actual calculated score)\n  - `[VALIDATION_STATUS]` ‚Üí `\"PASS\"` (outcome status)\n  - `[VALIDATION_DATE]` ‚Üí `\"2025-12-30\"` (current date)\n  - `[DOCUMENT_STATUS]` ‚Üí `\"Approved\"` (based on score tier)\n  - `[REVIEW_ACTOR]` ‚Üí `\"System (Auto-Approved)\"` (based on outcome)\n- Updates Overall Compliance footer with actual status counts and percentages\n- Updates Remediation Section A.3.3 with current status and score estimates\n- Writes final contract to `/tmp/final_business_continuity_contract.md`\n\n**Step 4.6.3: Error Handling**\n\nIf validation fails (e.g., malformed table, missing sections):\n- Log error to stderr\n- Write contract with \"Error\" placeholders in validation fields\n- Continue to PHASE 5 (always write contract output)\n\n**CRITICAL**: Never block contract generation due to validation failure. Always produce output.\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/BUSINESS_CONTINUITY_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/BUSINESS_CONTINUITY_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read and Write Final Contract**\n\nUse Read tool to load the validated contract:\n```\nfile_path: /tmp/final_business_continuity_contract.md\n```\n\nThen use Write tool to write to output location:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Read tool above]\n```\n\n**Step 5.4: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Business Continuity compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Business Continuity\n   Requirements: 43 (LACN001-LACN043)\n   Sections: 1, 3, 4, 5, 7, 8, 10, 11\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md. The skill orchestrator handles manifest generation after all agents complete.\n\n## Error Handling\n\n- If ARCHITECTURE.md not found ‚Üí Return error message with guidance\n- If template expansion fails ‚Üí Return bash error output\n- If required section missing ‚Üí Mark fields as \"Unknown\", continue generation\n- Always return a result (success or failure) - never exit silently\n\n## Business Continuity-Specific Notes\n\n- **Tier Classification**: Determine application tier (Tier 1/2/3) based on RTO/RPO\n- **DR Automation**: Verify automated DR procedures vs. manual processes\n- **Backup Testing**: Check quarterly backup restoration testing requirements\n- **Geographic Redundancy**: Mandatory for Tier 1 applications\n- **SPOF Analysis**: Identify and document mitigation strategies\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Business Continuity Compliance\n",
        "agents/cloud-compliance-generator.md": "---\nname: cloud-compliance-generator\ndescription: Cloud Architecture Compliance Contract Generator - Generates Cloud Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Cloud Architecture Compliance Generation Agent\n\n## Mission\nGenerate Cloud Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `cloud_architecture`\n**Template**: `TEMPLATE_CLOUD_ARCHITECTURE.md`\n**Section Mapping**: Sections 4, 8, 11 (primary), 9, 10 (secondary)\n\n**Key Data Points**:\n- Cloud provider (AWS, Azure, GCP)\n- Deployment model (IaaS, PaaS, SaaS)\n- Multi-region deployment\n- IaC coverage (Terraform, CloudFormation, Pulumi)\n- Cloud costs and optimization\n- Cloud-native services usage\n\n**Focus Areas**:\n- Cloud deployment patterns\n- Multi-region resilience\n- Cost optimization strategies\n- IaC (Infrastructure as Code) adoption\n- Cloud security best practices\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_CLOUD_ARCHITECTURE.md \\\n  /tmp/expanded_cloud_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_cloud_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_cloud_template.md > /tmp/cleaned_cloud_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_cloud_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\n**Step 2.1: Read Document Header**\n\nUse Read tool to read first 50 lines of ARCHITECTURE.md:\n```\nRead file: [architecture_file]\nLimit: 50 lines\nExtract project name from first H1 (line starting with \"# \")\n```\n\n**Step 2.2: Get Current Date**\n\nUse Bash tool:\n```bash\ndate +%Y-%m-%d\n```\nStore as: generation_date\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Cloud Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 4** (System Architecture): Cloud deployment model, architecture pattern\n- **Section 8** (Infrastructure): IaC tools, cloud resources, multi-region setup\n- **Section 11** (Operational Considerations): Cloud monitoring, backup strategies\n- **Section 9** (Security Architecture): Cloud security controls (secondary)\n- **Section 10** (Performance Requirements): Cloud scalability (secondary)\n\n**Step 3.2: Extract Section Content**\n\nFor each required section:\n\n1. Use Grep tool to find section start:\n```\npattern: \"^## 4\\.? |^## 4 \"\nfile: [architecture_file]\noutput_mode: content\n-n: true\nFind line number where section starts\n```\n\n2. Use Read tool to read section:\n```\nRead file: [architecture_file]\noffset: [section_start_line]\nlimit: 200 (or until next section)\n```\n\nRepeat for sections 8, 11, 9, 10.\n\n**Step 3.3: Extract Cloud-Specific Data Points**\n\nUse Grep tool with domain-specific patterns:\n\n**Cloud Provider Detection** (Section 4 or 8):\n```\npattern: \"(AWS|Azure|GCP|Google Cloud|Amazon Web Services|Microsoft Azure)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Deployment Model** (Section 4):\n```\npattern: \"(IaaS|PaaS|SaaS|Infrastructure as a Service|Platform as a Service|Software as a Service)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Multi-Region Configuration** (Section 8):\n```\npattern: \"(multi[- ]region|multi[- ]az|availability zone|cross[- ]region)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**IaC Tools** (Section 8):\n```\npattern: \"(Terraform|CloudFormation|Pulumi|Infrastructure as Code|IaC|ARM template|Bicep)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Cloud-Native Services** (Section 4 or 8):\n```\npattern: \"(Lambda|S3|ECS|EKS|CloudFront|API Gateway|Cloud Functions|Cloud Run|App Service|AKS|Cosmos)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Cost Optimization** (Section 8 or 11):\n```\npattern: \"(reserved instance|spot instance|auto[- ]scaling|right[- ]sizing|cost optimization|FinOps)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Cloud Monitoring Tools** (Section 11):\n```\npattern: \"(CloudWatch|Azure Monitor|Stackdriver|Cloud Logging|X-Ray|Application Insights)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Cloud Security** (Section 9):\n```\npattern: \"(IAM|encryption at rest|encryption in transit|VPC|security group|network ACL|WAF)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Cloud Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Cloud Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: Multi-region deployment documented. If Non-Compliant: Multi-region not specified. If Unknown: Multi-region unclear]\nStatus: Compliant\nReplacement: Multi-region deployment documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 4.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 4.2, lines 87-92`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 4.2 (Cloud Infrastructure section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**Cloud Provider**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**Cloud Provider**: AWS\n```\n\nINCORRECT (added context):\n```\n**Cloud Provider**: AWS as documented in Section 4.2\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: Multi-region deployment documented. If Non-Compliant: Multi-region deployment not specified. If Unknown: Multi-region deployment unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: Multi-region deployment documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: The system uses multi-region deployment across AWS us-east-1 and us-west-2\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 4.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 4.2, lines 87-92\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement multi-region deployment in Section 4]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement multi-region deployment in Section 4\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| Cloud Provider | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| Cloud Provider | AWS |\n```\n\nINCORRECT (converted to bold list):\n```\n**Cloud Provider**: AWS\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n**CRITICAL**: This phase calculates validation score and updates contract fields BEFORE writing output.\n\n**Step 4.6.1: Run Score Calculation**\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts \\\n  /tmp/populated_cloud_contract.md \\\n  validation/cloud_architecture_validation.json\n```\n\n**Step 4.6.2: Update Contract Fields**\n\n```bash\nbun skills/architecture-compliance/utils/field-updater-cli.ts \\\n  /tmp/populated_cloud_contract.md \\\n  /tmp/validation_score.json \\\n  /tmp/final_cloud_architecture_contract.md\n```\n\n**Step 4.6.3: Error Handling** - Continue to PHASE 5 on validation failure (always write output).\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/CLOUD_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/CLOUD_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\nExample: `/compliance-docs/CLOUD_ARCHITECTURE_PaymentPlatform_2025-12-27.md`\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read and Write Final Contract**\n\nUse Read tool to load the validated contract:\n```\nfile_path: /tmp/final_cloud_architecture_contract.md\n```\n\nThen use Write tool to write to output location:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Read tool above]\n```\n\n**Step 5.4: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Cloud Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Cloud Architecture\n   Sections: 4, 8, 11, 9, 10\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md. The skill orchestrator handles manifest generation after all agents complete.\n\n## Simplified Workflow for Testing\n\nFor initial testing, follow this minimal workflow:\n\n1. **Expand template** (Bash: resolve-includes.ts)\n2. **Read template** (Read tool)\n3. **Read ARCHITECTURE.md header** (Read tool, first 50 lines)\n4. **Extract project name** (from H1)\n5. **Get current date** (Bash: date command)\n6. **Replace [PROJECT_NAME] and [GENERATION_DATE]** in template\n7. **Write output** (Write tool to /compliance-docs/)\n8. **Return success message with metadata**\n\nAdditional data extraction can be added incrementally after basic workflow works.\n\n## Error Handling\n\n- If ARCHITECTURE.md not found ‚Üí Return error message with guidance\n- If template expansion fails ‚Üí Return bash error output\n- If required section missing ‚Üí Mark fields as \"Unknown\", continue generation\n- Always return a result (success or failure) - never exit silently\n\n## Cloud Architecture-Specific Notes\n\n- **Multi-cloud detection**: If multiple cloud providers found (AWS + Azure), note hybrid cloud approach\n- **IaC coverage**: Calculate percentage based on manual vs. IaC-managed resources\n- **Cost optimization**: Identify cost-saving opportunities (reserved instances, auto-scaling)\n- **Cloud-native adoption**: Measure usage of managed services vs. custom deployments\n- **Regional redundancy**: Verify multi-region setup for high availability\n\n## Output Format\n\nThe generated compliance contract includes:\n\n1. **Document Control Section**: Project name, generation date, version\n2. **Compliance Summary Table**: All Cloud Architecture requirements with status\n3. **Detailed Requirements**: Each requirement with:\n   - Requirement code (LACL001, LACL002, etc.)\n   - Description\n   - Status (Compliant/Non-Compliant/Unknown/Not Applicable)\n   - Source reference (Section X, line Y)\n   - Responsible role\n4. **Gap Analysis**: Missing requirements and recommendations\n5. **Source Traceability**: Full audit trail to ARCHITECTURE.md\n\n## Performance Optimization\n\n- Pre-configured section mappings (no runtime lookup)\n- Domain-specific Grep patterns for fast extraction\n- Minimal context loading (only required sections)\n- Parallel-safe execution (unique output filename)\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Cloud Architecture Compliance\n",
        "agents/data-ai-compliance-generator.md": "---\nname: data-ai-compliance-generator\ndescription: Data & AI Architecture Compliance Contract Generator - Generates Data & AI Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Data & AI Architecture Compliance Generation Agent\n\n## Mission\nGenerate Data & AI Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `data_ai`\n**Template**: `TEMPLATE_DATA_AI_ARCHITECTURE.md`\n**Section Mapping**: Sections 5, 6, 7 (primary), 8, 10 (secondary)\n\n**Key Data Points**:\n- Data quality metrics\n- Data lineage and traceability\n- PII encryption and masking\n- ML model governance (training, deployment, monitoring)\n- Data retention policies\n- Data scalability (3x growth capability)\n- Regulatory compliance (GDPR, data residency)\n\n**Focus Areas**:\n- Data management and governance\n- Analytics and AI/ML model lifecycle\n- Data quality and validation\n- Regulatory compliance\n- Data pipeline architecture\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_DATA_AI_ARCHITECTURE.md \\\n  /tmp/expanded_data_ai_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_data_ai_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_data_ai_template.md > /tmp/cleaned_data_ai_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_data_ai_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\n**Step 2.1: Read Document Header**\n\nUse Read tool to read first 50 lines of ARCHITECTURE.md\n\n**Step 2.2: Get Current Date**\n\nUse Bash tool:\n```bash\ndate +%Y-%m-%d\n```\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Data & AI Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 5** (Data Architecture): Data models, storage, quality\n- **Section 6** (API & Integration): Data integration patterns\n- **Section 7** (Security): Data encryption, PII protection\n- **Section 8** (Infrastructure): Data infrastructure (secondary)\n- **Section 10** (Performance): Data pipeline performance (secondary)\n\n**Step 3.2: Extract Section Content**\n\nFor each required section (5, 6, 7, 8, 10): Use Grep and Read tools\n\n**Step 3.3: Extract Data & AI-Specific Data Points**\n\n**Data Quality** (Section 5):\n```\npattern: \"(data quality|data validation|data cleansing|data accuracy|data completeness)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Data Lineage** (Section 5):\n```\npattern: \"(data lineage|data provenance|data flow|data traceability)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**PII Protection** (Section 7):\n```\npattern: \"(PII|personally identifiable|data masking|data anonymization|pseudonymization)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**ML Model Governance** (Section 5 or 10):\n```\npattern: \"(ML model|machine learning|model training|model deployment|model monitoring|re-training)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Data Retention** (Section 5):\n```\npattern: \"(retention policy|data retention|retention period|data lifecycle)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Data Scalability** (Section 5 or 10):\n```\npattern: \"(data volume|scalability|3x growth|data growth|scaling)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Regulatory Compliance** (Section 7):\n```\npattern: \"(GDPR|data residency|data sovereignty|privacy regulation|CCPA)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Data Pipeline** (Section 5):\n```\npattern: \"(data pipeline|ETL|ELT|data ingestion|data processing)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Data & AI Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Data & AI Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: Data governance documented. If Non-Compliant: Data governance not specified. If Unknown: Data governance unclear]\nStatus: Compliant\nReplacement: Data governance documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 6.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 6.2, lines 145-150`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 6.2 (Data Architecture section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**Data Governance**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**Data Governance**: Implemented\n```\n\nINCORRECT (added context):\n```\n**Data Governance**: Implemented with role-based access controls\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: Data governance documented. If Non-Compliant: Data governance not specified. If Unknown: Data governance unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: Data governance documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: Comprehensive data governance framework documented including data classification and access policies\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 6.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 6.2, lines 145-150\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement data governance in Section 6]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement data governance in Section 6\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| Data Governance | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| Data Governance | Implemented |\n```\n\nINCORRECT (converted to bold list):\n```\n**Data Governance**: Implemented\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/data_ai_architecture_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_data_ai_architecture_contract.md\n```\n\n**Error Handling**: Continue to PHASE 5 on failure (always write output).\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/DATA_AI_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/DATA_AI_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_data_ai_architecture_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Data & AI Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Data & AI Architecture\n   Sections: 5, 6, 7, 8, 10\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Error Handling\n\nStandard error handling applies.\n\n## Data & AI-Specific Notes\n\n- **Data Quality Coverage**: Define and monitor data quality metrics\n- **Data Lineage**: Track from source to consumption\n- **PII Protection**: Encryption and masking required\n- **ML Model Lifecycle**: Training, deployment, monitoring, re-training schedules\n- **Scalability**: Handle 3x growth without redesign\n- **Regulatory Compliance**: GDPR, data residency requirements\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Data & AI Architecture Compliance\n",
        "agents/development-compliance-generator.md": "---\nname: development-compliance-generator\ndescription: Development Architecture Compliance Contract Generator - Generates Development Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Development Architecture Compliance Generation Agent\n\n## Mission\nGenerate Development Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `development`\n**Template**: `TEMPLATE_DEVELOPMENT_ARCHITECTURE.md`\n**Section Mapping**: Sections 3, 5, 8, 12 (primary), 11 (secondary)\n\n**Key Data Points**:\n- Technology stack (languages, frameworks, versions)\n- Code coverage (minimum 80% for critical paths)\n- Technical debt tracking\n- Dependency vulnerabilities\n- Exception action plans (deviations from standards)\n- Development velocity\n- Build and deployment automation\n\n**Focus Areas**:\n- Software development standards\n- Technical debt management\n- Code quality\n- Technology lifecycle\n- Development practices\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_DEVELOPMENT_ARCHITECTURE.md \\\n  /tmp/expanded_dev_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_dev_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_dev_template.md > /tmp/cleaned_dev_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_dev_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Development Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 3** (System Architecture): Architecture patterns, design principles\n- **Section 5** (Infrastructure): Development infrastructure, CI/CD\n- **Section 8** (Technology Stack): Languages, frameworks, versions\n- **Section 12** (ADRs): Architectural decisions, technology choices\n- **Section 11** (Operational): Build/deployment automation (secondary)\n\n**Step 3.3: Extract Development-Specific Data Points**\n\n**Technology Stack** (Section 8):\n```\npattern: \"(language|framework|library|Java|Python|Node|React|Spring|.NET)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Code Coverage** (Section 11):\n```\npattern: \"(code coverage|test coverage|unit test|integration test)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Technical Debt** (Section 12):\n```\npattern: \"(technical debt|tech debt|refactoring|code quality|code smell)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Dependency Management** (Section 8):\n```\npattern: \"(dependency|vulnerability|CVE|security patch|version upgrade)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**CI/CD Pipeline** (Section 5 or 11):\n```\npattern: \"(CI/CD|continuous integration|continuous deployment|Jenkins|GitHub Actions|GitLab CI)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Code Review** (Section 11):\n```\npattern: \"(code review|peer review|pull request|PR review)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Development Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Development Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: CI/CD pipeline documented. If Non-Compliant: CI/CD pipeline not specified. If Unknown: CI/CD pipeline unclear]\nStatus: Compliant\nReplacement: CI/CD pipeline documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 3.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 3.2, lines 67-72`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 3.2 (Development Practices section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**CI/CD Pipeline**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**CI/CD Pipeline**: GitHub Actions\n```\n\nINCORRECT (added context):\n```\n**CI/CD Pipeline**: GitHub Actions with automated testing\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: CI/CD pipeline documented. If Non-Compliant: CI/CD pipeline not specified. If Unknown: CI/CD pipeline unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: CI/CD pipeline documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: Automated CI/CD pipeline using GitHub Actions is fully documented with build, test, and deployment stages\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 3.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 3.2, lines 67-72\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement CI/CD pipeline in Section 3]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement CI/CD pipeline in Section 3\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| CI/CD Pipeline | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| CI/CD Pipeline | GitHub Actions |\n```\n\nINCORRECT (converted to bold list):\n```\n**CI/CD Pipeline**: GitHub Actions\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/development_architecture_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_development_architecture_contract.md\n```\n\n**Error Handling**: Continue to PHASE 5 on failure (always write output).\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/DEVELOPMENT_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/DEVELOPMENT_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_development_architecture_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Development Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Development Architecture\n   Sections: 3, 5, 8, 12, 11\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Development Architecture-Specific Notes\n\n- **Technology Stack**: Must use supported versions (not deprecated)\n- **Code Coverage**: Minimum 80% for critical paths\n- **Peer Review**: All code changes require review\n- **Technical Debt**: Tracked and addressed quarterly\n- **Vulnerability SLA**: Critical < 24hr, High < 7 days\n- **Exception Plans**: Required for non-standard technology choices\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Development Architecture Compliance\n",
        "agents/enterprise-compliance-generator.md": "---\nname: enterprise-compliance-generator\ndescription: Enterprise Architecture Compliance Contract Generator - Generates Enterprise Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Enterprise Architecture Compliance Generation Agent\n\n## Mission\nGenerate Enterprise Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `enterprise`\n**Template**: `TEMPLATE_ENTERPRISE_ARCHITECTURE.md`\n**Section Mapping**: Sections 1, 2, 3, 4 (primary), 12 (secondary)\n\n**Key Data Points**:\n- Business capability alignment\n- Modularity and bounded contexts\n- Third-party app customization (maximum 20%)\n- Cloud-first adoption\n- Technology lifecycle (no EOL within 3 years)\n- API-first design\n- Event-driven architecture\n\n**Focus Areas**:\n- Strategic alignment\n- Enterprise modularity\n- Cloud-first approach\n- Technology lifecycle management\n- API and event-driven patterns\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_ENTERPRISE_ARCHITECTURE.md \\\n  /tmp/expanded_enterprise_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_enterprise_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_enterprise_template.md > /tmp/cleaned_enterprise_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_enterprise_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Enterprise Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 1** (Business Context): Business capabilities, strategic alignment\n- **Section 2** (System Overview): Solution positioning, scope\n- **Section 3** (System Architecture): Modularity, bounded contexts\n- **Section 4** (System Components): Component design, service boundaries\n- **Section 12** (ADRs): Technology decisions, architecture rationale (secondary)\n\n**Step 3.3: Extract Enterprise Architecture-Specific Data Points**\n\n**Business Capability Alignment** (Section 1 or 2):\n```\npattern: \"(business capability|capability map|business alignment|business domain)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Modularity** (Section 3 or 4):\n```\npattern: \"(modularity|bounded context|domain-driven|microservice|service boundary)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Third-Party Customization** (Section 2 or 3):\n```\npattern: \"(third-party|COTS|vendor|customization|SaaS customization)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Cloud-First** (Section 3 or 4):\n```\npattern: \"(cloud-first|cloud-native|cloud adoption|cloud strategy)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Technology Lifecycle** (Section 8 or 12):\n```\npattern: \"(technology lifecycle|EOL|end of life|technology age|obsolescence)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**API-First** (Section 3 or 7):\n```\npattern: \"(API-first|API design|API strategy|RESTful|GraphQL)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Event-Driven** (Section 3 or 7):\n```\npattern: \"(event-driven|event sourcing|message queue|Kafka|event stream|asynchronous)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Enterprise Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Enterprise Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: Enterprise architecture documented. If Non-Compliant: Enterprise architecture not specified. If Unknown: Enterprise architecture unclear]\nStatus: Compliant\nReplacement: Enterprise architecture documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 2.1`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 2.1, lines 45-50`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 2.1 (Enterprise Architecture section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**Enterprise Architecture Framework**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**Enterprise Architecture Framework**: TOGAF\n```\n\nINCORRECT (added context):\n```\n**Enterprise Architecture Framework**: TOGAF version 9.2\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: Enterprise architecture documented. If Non-Compliant: Enterprise architecture not specified. If Unknown: Enterprise architecture unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: Enterprise architecture documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: Comprehensive enterprise architecture using TOGAF framework is documented\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 2.1\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 2.1, lines 45-50\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Document enterprise architecture in Section 2]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Document enterprise architecture in Section 2\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| Framework | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| Framework | TOGAF |\n```\n\nINCORRECT (converted to bold list):\n```\n**Framework**: TOGAF\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/enterprise_architecture_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_enterprise_architecture_contract.md\n```\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/ENTERPRISE_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/ENTERPRISE_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_enterprise_architecture_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Enterprise Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Enterprise Architecture\n   Sections: 1, 2, 3, 4, 12\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Enterprise Architecture-Specific Notes\n\n- **Business Alignment**: Solutions align with enterprise business capabilities\n- **Modularity**: Services bounded by business domains\n- **Cloud-First**: Prefer cloud-native over on-premise\n- **Third-Party Customization**: Maximum 20% of functionality\n- **Zero Obsolescence**: No technologies EOL within 3 years\n- **API-First**: All service interfaces API-first design\n- **Event-Driven**: Asynchronous processes use event-driven patterns\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Enterprise Architecture Compliance\n",
        "agents/integration-compliance-generator.md": "---\nname: integration-compliance-generator\ndescription: Integration Architecture Compliance Contract Generator - Generates Integration Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Integration Architecture Compliance Generation Agent\n\n## Mission\nGenerate Integration Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `integration`\n**Template**: `TEMPLATE_INTEGRATION_ARCHITECTURE.md`\n**Section Mapping**: Sections 5, 6, 7, 9 (primary)\n\n**Key Data Points**:\n- Integration catalog and documentation\n- OpenAPI/AsyncAPI compliance\n- Correlation IDs for traceability\n- API versioning strategy\n- Integration security (OAuth 2.0, mutual TLS)\n- Obsolete protocol avoidance\n- Integration standards adoption\n\n**Focus Areas**:\n- Microservice integration\n- API design and standards\n- Event-driven integration\n- Integration security\n- Traceability and audit\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_INTEGRATION_ARCHITECTURE.md \\\n  /tmp/expanded_integration_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_integration_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_integration_template.md > /tmp/cleaned_integration_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_integration_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Integration Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 5** (Data Architecture): Data integration patterns\n- **Section 6** (API & Integration): API catalog, integration patterns\n- **Section 7** (Integration Architecture): Integration protocols, patterns\n- **Section 9** (Security): Integration security controls\n\n**Step 3.3: Extract Integration-Specific Data Points**\n\n**Integration Catalog** (Section 6 or 7):\n```\npattern: \"(integration catalog|API catalog|integration inventory|API registry)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**OpenAPI Compliance** (Section 6 or 7):\n```\npattern: \"(OpenAPI|Swagger|AsyncAPI|API specification|API schema)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Correlation IDs** (Section 7):\n```\npattern: \"(correlation ID|trace ID|request ID|transaction ID|distributed tracing)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**API Versioning** (Section 6 or 7):\n```\npattern: \"(API version|versioning strategy|version control|URI versioning|header versioning)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Integration Security** (Section 9):\n```\npattern: \"(OAuth 2.0|API key|mutual TLS|integration security|API authentication)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**API Protocols** (Section 7):\n```\npattern: \"(REST|GraphQL|gRPC|WebSocket|SOAP|HTTP)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Message Patterns** (Section 7):\n```\npattern: \"(message queue|pub/sub|publish subscribe|message broker|Kafka|RabbitMQ)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Async Patterns** (Section 7):\n```\npattern: \"(asynchronous|async|selective async|event notification|request/reply)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Integration Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Integration Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: Integration patterns documented. If Non-Compliant: Integration patterns not specified. If Unknown: Integration patterns unclear]\nStatus: Compliant\nReplacement: Integration patterns documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 7.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 7.2, lines 167-172`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 7.2 (Integration Architecture section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**Integration Pattern**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**Integration Pattern**: Event-Driven\n```\n\nINCORRECT (added context):\n```\n**Integration Pattern**: Event-Driven using Kafka message broker\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: Integration patterns documented. If Non-Compliant: Integration patterns not specified. If Unknown: Integration patterns unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: Integration patterns documented\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: Event-driven integration patterns documented with Kafka as the message broker\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 7.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 7.2, lines 167-172\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Document integration patterns in Section 7]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Document integration patterns in Section 7\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| Integration Pattern | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| Integration Pattern | Event-Driven |\n```\n\nINCORRECT (converted to bold list):\n```\n**Integration Pattern**: Event-Driven\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/integration_architecture_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_integration_architecture_contract.md\n```\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/INTEGRATION_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/INTEGRATION_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_integration_architecture_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Integration Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Integration Architecture\n   Sections: 5, 6, 7, 9\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Integration Architecture-Specific Notes\n\n- **Integration Catalog**: All integrations cataloged and documented\n- **OpenAPI Compliance**: REST APIs follow OpenAPI 3.0 specification\n- **Async Patterns**: Use selective async patterns\n- **Integration Security**: OAuth 2.0, mutual TLS, API keys\n- **Obsolete Protocols**: Avoid SOAP 1.1, XML-RPC\n- **Correlation IDs**: All integrations include correlation IDs for traceability\n- **API Versioning**: Consistent strategy (URI vs. header)\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Integration Architecture Compliance\n",
        "agents/platform-compliance-generator.md": "---\nname: platform-compliance-generator\ndescription: Platform & IT Infrastructure Compliance Contract Generator - Generates Platform & IT Infrastructure compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Platform & IT Infrastructure Compliance Generation Agent\n\n## Mission\nGenerate Platform & IT Infrastructure compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `platform`\n**Template**: `TEMPLATE_PLATFORM_IT_INFRASTRUCTURE.md`\n**Section Mapping**: Sections 4, 8, 11 (primary), 10 (secondary)\n\n**Key Data Points**:\n- Environment isolation (network, IAM)\n- Authorized operating systems and versions\n- Database capacity and retention policies\n- Naming conventions\n- Transactional sizing (TPS capacity)\n- Infrastructure as Code (IaC) coverage\n- Capacity planning (3x current volume)\n\n**Focus Areas**:\n- Platform design and deployment\n- Infrastructure standards\n- Capacity planning\n- Resource naming conventions\n- Database management\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_PLATFORM_IT_INFRASTRUCTURE.md \\\n  /tmp/expanded_platform_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_platform_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_platform_template.md > /tmp/cleaned_platform_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_platform_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Platform & IT Infrastructure**\n\nPRE-CONFIGURED sections to extract:\n- **Section 4** (System Architecture): Component topology, environment design\n- **Section 8** (Infrastructure): Infrastructure specifications, IaC\n- **Section 11** (Operational): Operational infrastructure requirements\n- **Section 10** (Performance): Capacity requirements (secondary)\n\n**Step 3.3: Extract Platform-Specific Data Points**\n\n**Environment Isolation** (Section 4 or 8):\n```\npattern: \"(environment isolation|production environment|staging|development|network isolation)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Operating Systems** (Section 8):\n```\npattern: \"(operating system|OS|Linux|Windows Server|Ubuntu|RHEL|CentOS)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Database** (Section 8):\n```\npattern: \"(database|PostgreSQL|MySQL|MongoDB|SQL Server|Oracle|database capacity)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Retention Policies** (Section 8 or 11):\n```\npattern: \"(retention policy|data retention|backup retention|log retention)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Naming Conventions** (Section 8):\n```\npattern: \"(naming convention|naming standard|resource naming|nomenclature)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Capacity Planning** (Section 10):\n```\npattern: \"(capacity|TPS|transactions per second|throughput|scalability|3x growth)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Infrastructure as Code** (Section 8):\n```\npattern: \"(Infrastructure as Code|IaC|Terraform|CloudFormation|Ansible|Puppet)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Platform & Infrastructure Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Platform & Infrastructure Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\nStatus: Compliant\nReplacement: RTO documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 11.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2, lines 567-570`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2 (Monitoring section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**RTO**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**RTO**: 4 hours\n```\n\nINCORRECT (added context):\n```\n**RTO**: 4 hours as documented in Section 11.3\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: RTO documented and meets requirements. If Non-Compliant: RTO not specified. If Unknown: RTO mentioned but value unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: RTO documented and meets requirements\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: The RTO of 4 hours is documented and meets organizational requirements for disaster recovery\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 11.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 11.2, lines 567-570\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement RTO in Section 11]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement RTO in Section 11\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| RTO | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| RTO | 4 hours |\n```\n\nINCORRECT (converted to bold list):\n```\n**RTO**: 4 hours\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/platform_it_infrastructure_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_platform_it_infrastructure_contract.md\n```\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/PLATFORM_IT_INFRASTRUCTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/PLATFORM_IT_INFRASTRUCTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_platform_it_infrastructure_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Platform & IT Infrastructure compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Platform & IT Infrastructure\n   Sections: 4, 8, 11, 10\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Platform-Specific Notes\n\n- **Environment Isolation**: Production isolated (network, IAM)\n- **Authorized OS**: Only current security-patched versions\n- **Database Capacity**: Support 3x current transaction volume\n- **Retention Compliance**: Align with regulatory requirements\n- **Naming Conventions**: Consistent and documented\n- **IaC Coverage**: Infrastructure defined as code\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Platform & IT Infrastructure Compliance\n",
        "agents/process-compliance-generator.md": "---\nname: process-compliance-generator\ndescription: Process Transformation Compliance Contract Generator - Generates Process Transformation compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Process Transformation Compliance Generation Agent\n\n## Mission\nGenerate Process Transformation and Automation compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `process`\n**Template**: `TEMPLATE_PROCESS_TRANSFORMATION.md`\n**Section Mapping**: Sections 1, 2, 6 (primary), 5, 7 (secondary)\n\n**Key Data Points**:\n- Automation ROI (positive within 12 months)\n- Hours saved by automation\n- Reusable capabilities and shared services\n- License optimization\n- Process efficiency gains\n- Impact analysis (cost reduction, time savings)\n\n**Focus Areas**:\n- Automation solutions\n- Process improvement\n- Capability reuse\n- License consumption efficiency\n- Document management\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_PROCESS_TRANSFORMATION.md \\\n  /tmp/expanded_process_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_process_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_process_template.md > /tmp/cleaned_process_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_process_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Process Transformation**\n\nPRE-CONFIGURED sections to extract:\n- **Section 1** (Business Context): Business processes, efficiency targets\n- **Section 2** (System Overview): Automation scope, process overview\n- **Section 6** (API & Integration): Automation tools, integration patterns\n- **Section 5** (Infrastructure): Automation infrastructure (secondary)\n- **Section 7** (Security): Automation security (secondary)\n\n**Step 3.3: Extract Process Transformation-Specific Data Points**\n\n**Automation ROI** (Section 1 or 2):\n```\npattern: \"(automation ROI|return on investment|cost savings|efficiency gain)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Hours Saved** (Section 1 or 2):\n```\npattern: \"(hours saved|time savings|manual hours|productivity gain)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Automation Tools** (Section 6):\n```\npattern: \"(RPA|robotic process|UiPath|Automation Anywhere|Power Automate|workflow automation)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Reusable Capabilities** (Section 6):\n```\npattern: \"(reusable|shared service|capability reuse|component library)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**License Optimization** (Section 5):\n```\npattern: \"(license|concurrent user|named user|license optimization)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Process Improvement** (Section 1):\n```\npattern: \"(process improvement|process optimization|lean|Six Sigma)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Process Transformation Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Process Transformation Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\nStatus: Compliant\nReplacement: RTO documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 11.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2, lines 567-570`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2 (Monitoring section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**RTO**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**RTO**: 4 hours\n```\n\nINCORRECT (added context):\n```\n**RTO**: 4 hours as documented in Section 11.3\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: RTO documented and meets requirements. If Non-Compliant: RTO not specified. If Unknown: RTO mentioned but value unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: RTO documented and meets requirements\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: The RTO of 4 hours is documented and meets organizational requirements for disaster recovery\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 11.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 11.2, lines 567-570\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement RTO in Section 11]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement RTO in Section 11\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| RTO | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| RTO | 4 hours |\n```\n\nINCORRECT (converted to bold list):\n```\n**RTO**: 4 hours\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/process_transformation_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_process_transformation_contract.md\n```\n\n**Error Handling**: Continue to PHASE 5 on failure (always write output).\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/PROCESS_TRANSFORMATION_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/PROCESS_TRANSFORMATION_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_process_transformation_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Process Transformation compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Process Transformation\n   Sections: 1, 2, 6, 5, 7\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Process Transformation-Specific Notes\n\n- **Automation Threshold**: Manual processes >10 hours/month evaluated for automation\n- **ROI Requirement**: Positive ROI within 12 months\n- **Shared Services**: Reusable capabilities designed as shared services\n- **License Efficiency**: Optimize concurrent vs. named users\n- **Impact Analysis**: Required before process changes\n- **Error Handling**: Process automation must include monitoring\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Process Transformation Compliance\n",
        "agents/security-compliance-generator.md": "---\nname: security-compliance-generator\ndescription: Security Architecture Compliance Contract Generator - Generates Security Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# Security Architecture Compliance Generation Agent\n\n## Mission\nGenerate Security Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `security`\n**Template**: `TEMPLATE_SECURITY_ARCHITECTURE.md`\n**Section Mapping**: Sections 4, 5, 7, 9, 11 (primary)\n\n**Key Data Points**:\n- API authentication and authorization\n- Encryption (TLS 1.3 for transit, AES-256 for rest)\n- Authentication methods (OAuth, SAML, JWT, MFA)\n- Microservice communication security (mutual TLS)\n- Secrets management\n- Vulnerability remediation SLAs\n- Security event logging\n\n**Focus Areas**:\n- API security and exposure\n- Authentication and authorization\n- Encryption (transit and rest)\n- Microservice security\n- Vulnerability management\n- Security monitoring\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_SECURITY_ARCHITECTURE.md \\\n  /tmp/expanded_security_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_security_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_security_template.md > /tmp/cleaned_security_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_security_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\nStandard project information extraction\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for Security Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 4** (System Architecture): API security, service boundaries\n- **Section 5** (Infrastructure): Network security, firewalls\n- **Section 7** (Integration): API authentication, authorization\n- **Section 9** (Security Architecture): Comprehensive security controls\n- **Section 11** (Operational): Security monitoring, incident response\n\n**Step 3.3: Extract Security-Specific Data Points**\n\n**API Authentication** (Section 7 or 9):\n```\npattern: \"(API authentication|API authorization|OAuth|JWT|API key|bearer token)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Encryption Transit** (Section 9):\n```\npattern: \"(TLS|SSL|HTTPS|encryption in transit|transport security)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Encryption Rest** (Section 9):\n```\npattern: \"(encryption at rest|AES|data encryption|encrypted storage)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Authentication Method** (Section 9):\n```\npattern: \"(authentication|SAML|OAuth 2.0|OpenID Connect|SSO|multi-factor|MFA)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Microservice Security** (Section 4 or 9):\n```\npattern: \"(mutual TLS|mTLS|service mesh|service-to-service|inter-service security)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Secrets Management** (Section 9):\n```\npattern: \"(secrets management|vault|key management|KMS|secrets rotation)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Vulnerability Management** (Section 11):\n```\npattern: \"(vulnerability|CVE|security patch|penetration test|security scan)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Security Monitoring** (Section 11):\n```\npattern: \"(security monitoring|SIEM|security event|audit log|security alert)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"Security Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"Security Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\nStatus: Compliant\nReplacement: RTO documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 11.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2, lines 567-570`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2 (Monitoring section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**RTO**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**RTO**: 4 hours\n```\n\nINCORRECT (added context):\n```\n**RTO**: 4 hours as documented in Section 11.3\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: RTO documented and meets requirements. If Non-Compliant: RTO not specified. If Unknown: RTO mentioned but value unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: RTO documented and meets requirements\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: The RTO of 4 hours is documented and meets organizational requirements for disaster recovery\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 11.2\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 11.2, lines 567-570\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement RTO in Section 11]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement RTO in Section 11\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| RTO | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| RTO | 4 hours |\n```\n\nINCORRECT (converted to bold list):\n```\n**RTO**: 4 hours\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts /tmp/populated_contract.md validation/security_architecture_validation.json\nbun skills/architecture-compliance/utils/field-updater-cli.ts /tmp/populated_contract.md /tmp/validation_score.json /tmp/final_security_architecture_contract.md\n```\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/SECURITY_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/SECURITY_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read Validated Contract**\n\nUse Read tool:\n```\nfile_path: /tmp/final_security_architecture_contract.md\n```\n\n**Note**: Use the validated contract from PHASE 4.6 (Step 4.6.2) which has validation scores populated.\n\n**Step 5.4: Write Contract to Output**\n\nUse Write tool:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Step 5.3 Read operation]\n```\n\n**Step 5.5: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated Security Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: Security Architecture\n   Sections: 4, 5, 7, 9, 11\n```\n\n**IMPORTANT**: This agent does NOT generate COMPLIANCE_MANIFEST.md.\n\n## Security Architecture-Specific Notes\n\n- **API Security**: All APIs require authentication and authorization\n- **Encryption Standards**: TLS 1.3 for transit, AES-256 for rest\n- **Secrets Management**: Never store in code or configuration files\n- **Microservice mTLS**: Mutual TLS required for service communication\n- **Vulnerability SLA**: Critical < 24hr, High < 7 days\n- **Security Logging**: All authentication events logged and monitored\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: Security Architecture Compliance\n",
        "agents/sre-compliance-generator.md": "---\nname: sre-compliance-generator\ndescription: SRE Architecture Compliance Contract Generator - Generates SRE Architecture compliance contracts from ARCHITECTURE.md\ntools: Read, Write, Bash, Grep, Glob\nmodel: sonnet\n---\n\n# SRE Architecture Compliance Generation Agent\n\n## Mission\nGenerate SRE (Site Reliability Engineering) Architecture compliance contract from ARCHITECTURE.md using direct tool execution.\n\n## Specialized Configuration\n\n**Contract Type**: `sre_architecture`\n**Template**: `TEMPLATE_SRE_ARCHITECTURE.md`\n**Section Mapping**: Sections 10, 11 (primary), 5 (secondary)\n\n**Key Data Points**:\n- SLO (Service Level Objectives)\n- SLI (Service Level Indicators)\n- Error Budget\n- MTTR (Mean Time To Recovery)\n- MTBF (Mean Time Between Failures)\n- Runbook coverage\n- Monitoring tools (Prometheus, Grafana, Datadog)\n- Incident response procedures\n\n**Focus Areas**:\n- Solution resilience\n- Observability (metrics, logs, traces)\n- Automation\n- Incident management\n- Performance monitoring\n\n**Requirements**: 57 (LASRE001-LASRE057)\n**Tiers**: 36 Blocker (mandatory) + 21 Desired (optional)\n**Scoring**: Two-tier (Blocker 70%, Desired 30%)\n\n## Input Parameters\n\n- `architecture_file`: Path to ARCHITECTURE.md (default: ./ARCHITECTURE.md)\n\n## Workflow\n\nFollow these steps exactly, using the specified tools for each operation.\n\n### PHASE 0: Template Preservation Mandate\n\n**ABSOLUTE RULE - READ THIS FIRST**:\n\nYou are operating in **TEMPLATE PRESERVATION MODE**.\n\n**What this means**:\n- The template is a READ-ONLY document\n- Your ONLY task is to replace `[PLACEHOLDER]` text with actual values\n- You are FORBIDDEN from modifying any template structure\n- You are FORBIDDEN from adding, removing, or reorganizing sections\n- You are FORBIDDEN from changing table formats\n- You are FORBIDDEN from adding section numbering (A.1, A.2, etc.)\n- You are FORBIDDEN from adding or removing table columns/rows\n- You are FORBIDDEN from converting tables to other formats\n\n**What you CAN do**:\n- Replace `[PROJECT_NAME]` with the actual project name\n- Replace `[GENERATION_DATE]` with the current date\n- Replace `[DOCUMENT_STATUS]` with \"Draft\"\n- Replace `[VALIDATION_SCORE]` with \"Not performed\"\n- Replace `[Compliant/Non-Compliant/Not Applicable/Unknown]` with actual status\n- Replace conditional placeholders `[If X: ... If Y: ...]` with exact matching branch text\n- Replace `[Source Section]` with \"ARCHITECTURE.md Section X.Y\"\n- Replace `[Role or N/A]` with extracted role or \"N/A\"\n\n**How to work**:\n1. Read the cleaned template as immutable content\n2. Identify each `[PLACEHOLDER]` in the template\n3. Replace ONLY the placeholder with its value\n4. Preserve everything else EXACTLY as-is\n5. Write the result (structure must be identical to template)\n\n**Violation Detection**: If the output structure differs from template structure in ANY way, the contract will be REJECTED.\n\n### PHASE 1: Template Preparation\n\n**Step 1.1: Expand Template**\n\nUse Bash tool to run resolve-includes.ts:\n```bash\nbun skills/architecture-compliance/utils/resolve-includes.ts \\\n  skills/architecture-compliance/templates/TEMPLATE_SRE_ARCHITECTURE.md \\\n  /tmp/expanded_sre_template.md\n```\n\n**Step 1.2: Read Expanded Template**\n\nUse Read tool:\n```\nRead file: /tmp/expanded_sre_template.md\nStore content in variable: template_content\n```\n\n**Step 1.3: Remove Instructional Sections**\n\nUse Bash tool to remove internal agent instructions from expanded template:\n\n```bash\nsed '/<!-- BEGIN_INTERNAL_INSTRUCTIONS -->/,/<!-- END_INTERNAL_INSTRUCTIONS -->/d' \\\n  /tmp/expanded_sre_template.md > /tmp/cleaned_sre_template.md\n```\n\n**What This Does**:\n- Removes all content between `<!-- BEGIN_INTERNAL_INSTRUCTIONS -->` and `<!-- END_INTERNAL_INSTRUCTIONS -->`\n- Preserves only contract-facing content\n- Prevents instructional metadata from appearing in final output\n\n**Step 1.4: Read Cleaned Template**\n\nUse Read tool:\n```\nRead file: /tmp/cleaned_sre_template.md\nStore content in variable: template_content\n```\n\n**CRITICAL**: Use the **cleaned** template for all subsequent phases, NOT the expanded template.\n\n### PHASE 2: Extract Project Information\n\n**Step 2.1: Read Document Header**\n\nUse Read tool to read first 50 lines of ARCHITECTURE.md:\n```\nRead file: [architecture_file]\nLimit: 50 lines\nExtract project name from first H1 (line starting with \"# \")\n```\n\n**Step 2.2: Get Current Date**\n\nUse Bash tool:\n```bash\ndate +%Y-%m-%d\n```\nStore as: generation_date\n\n### PHASE 3: Extract Data from Required Sections\n\n**Step 3.1: Required Sections for SRE Architecture**\n\nPRE-CONFIGURED sections to extract:\n- **Section 10** (Performance Requirements): SLO, SLI, latency targets (30%)\n- **Section 11** (Operational Considerations): Monitoring, DR, deployment (50%)\n- **Section 5** (Infrastructure Architecture): Infrastructure resilience (10%)\n\n**Step 3.2: Extract Section Content**\n\nFor each required section (10, 11, 5):\n\n1. Use Grep tool to find section start\n2. Use Read tool to read section content\n\n**Step 3.3: Extract SRE-Specific Data Points**\n\n**SLO Detection** (Section 10):\n```\npattern: \"SLO[:\\s]+([0-9]+\\.?[0-9]*)%\"\nfile: [architecture_file]\noutput_mode: content\n-n: true\n```\n\n**SLI Detection** (Section 10):\n```\npattern: \"(SLI|service level indicator|availability|latency|throughput|error rate)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Error Budget** (Section 11):\n```\npattern: \"error budget[:\\s]+([0-9]+\\.?[0-9]*)%\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**MTTR** (Section 11):\n```\npattern: \"MTTR[:\\s]+([0-9]+)\\s*(minute|hour|min|hr)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**MTBF** (Section 11):\n```\npattern: \"MTBF[:\\s]+([0-9]+)\\s*(day|hour|week)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Monitoring Tools** (Section 11):\n```\npattern: \"(Prometheus|Grafana|Datadog|New Relic|CloudWatch|Azure Monitor|Stackdriver|Dynatrace)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Observability Triad** (Section 11):\n```\npattern: \"(metrics|logs|traces|distributed tracing|log aggregation|metric collection)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Incident Response** (Section 11):\n```\npattern: \"(incident response|on[- ]call|P1|P2|P3|incident severity|postmortem|post[- ]incident)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Runbooks** (Section 11):\n```\npattern: \"(runbook|operational procedure|troubleshooting guide|playbook)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n**Deployment Automation** (Section 11):\n```\npattern: \"(CI/CD|deployment automation|blue[- ]green|canary|rolling deployment)\"\nfile: [architecture_file]\noutput_mode: content\n-i: true\n-n: true\n```\n\n### PHASE 4: Populate Template\n\n**CRITICAL: You MUST preserve exact template format. Do NOT enhance, modify, or add context.**\n\n**Step 4.0: Populate Document Control Fields**\n\nReplace Document Control placeholders with default values:\n\n- `[DOCUMENT_STATUS]` ‚Üí `\"Draft\"`\n- `[VALIDATION_SCORE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_STATUS]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_DATE]` ‚Üí `\"Not performed\"`\n- `[VALIDATION_EVALUATOR]` ‚Üí `\"Claude Code (Automated Validation Engine)\"`\n- `[REVIEW_ACTOR]` ‚Üí `\"SRE Architecture Review Board\"`\n- `[APPROVAL_AUTHORITY]` ‚Üí `\"SRE Architecture Review Board\"`\n\n**Note**: Validation integration is tracked separately. Current defaults indicate contract has not been validated yet.\n\n**Step 4.1: Replace Simple Placeholders**\n\nReplace the following placeholders with exact values:\n- `[PROJECT_NAME]` ‚Üí Project name from ARCHITECTURE.md H1\n- `[GENERATION_DATE]` ‚Üí Current date (YYYY-MM-DD)\n- `[VALUE or \"Not specified\"]` ‚Üí Extracted value OR literal string \"Not specified\"\n\n**Rules:**\n- Use ONLY the extracted value, no additional text\n- If value not found: Use literal \"Not specified\" (no context)\n- Do NOT add explanatory text to values\n\n**Step 4.2: Replace Conditional Placeholders (EXACT ALGORITHM)**\n\n**Template Pattern:**\n```\n[If Compliant: X. If Non-Compliant: Y. If Not Applicable: N/A. If Unknown: W]\n```\n\n**Replacement Algorithm:**\n1. Locate the conditional placeholder in template\n2. Identify the Status value for this field (from data extraction)\n3. Find the matching branch:\n   - If Status = \"Compliant\" ‚Üí Extract text after \"If Compliant: \" up to next \". If\"\n   - If Status = \"Non-Compliant\" ‚Üí Extract text after \"If Non-Compliant: \" up to next \". If\"\n   - If Status = \"Not Applicable\" ‚Üí Extract text after \"If Not Applicable: \" up to next \". If\"\n   - If Status = \"Unknown\" ‚Üí Extract text after \"If Unknown: \" up to end \"]\"\n4. Replace entire placeholder with ONLY the extracted branch text\n5. Do NOT modify, enhance, or add context to the branch text\n\n**Example:**\n```\nTemplate: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Unknown: RTO unclear]\nStatus: Compliant\nReplacement: RTO documented\n```\n\n**CRITICAL:**\n- Extract ONLY the text from the matching branch\n- Do NOT combine multiple branches\n- Do NOT add extra explanation\n- Do NOT modify the branch text\n- Preserve exact template wording\n\n**Step 4.3: Replace Source References**\n\n**Template Pattern:**\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\n**Replacement Rules:**\n1. If data found in ARCHITECTURE.md:\n   - Format: `ARCHITECTURE.md Section X.Y` (section number only)\n   - Do NOT add line numbers unless template explicitly shows them\n   - Do NOT add quotes or extra context\n2. If data not found:\n   - Use literal: \"Not documented\"\n\n**Examples:**\n- Correct: `- Source: ARCHITECTURE.md Section 11.2`\n- Correct: `- Source: \"Not documented\"`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2, lines 567-570`\n- INCORRECT: `- Source: ARCHITECTURE.md Section 11.2 (Monitoring section)`\n\n**Step 4.4: Preserve Template Structure**\n\n**CRITICAL RULES:**\n\n1. **Table Format**:\n   - Preserve ALL table formatting: `| Field | Value |`\n   - NEVER convert to bold lists: `**Field**: Value`\n   - Maintain table alignment exactly as template\n\n2. **Status Values**:\n   - Use ONLY these 4 values: Compliant, Non-Compliant, Not Applicable, Unknown\n   - Exact case: \"Compliant\" not \"compliant\" or \"COMPLIANT\"\n\n3. **Section Numbering**:\n   - Preserve H2/H3 levels exactly as template\n   - Shared sections (Document Control, etc.) are H2: `## Section`\n   - Do NOT number shared sections (no `## A.5`, just `## Section Name`)\n\n4. **Note Fields with Conditionals**:\n   - Template: `- Note: [If Non-Compliant or Unknown: Implement X]`\n   - If Status is Compliant or Not Applicable: Remove entire Note line\n   - If Status is Non-Compliant or Unknown: Extract and use the conditional text\n   - Do NOT modify conditional logic\n\n**Step 4.5: Final Format Check**\n\nBefore writing output, verify:\n- [ ] All placeholders replaced (no `[PLACEHOLDER]` text remains except legitimate \"Not specified\")\n- [ ] All tables use pipe format `| X | Y |`\n- [ ] All status values are one of: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] Source references follow format: `ARCHITECTURE.md Section X.Y` or `\"Not documented\"`\n- [ ] Conditional placeholders extracted exact branch text (no enhancements)\n- [ ] No extra prose or explanatory text added beyond template\n\n### PHASE 4 Examples: Correct vs Incorrect Replacements\n\n**Example 1: Simple Placeholder**\n\nTemplate:\n```\n**SLO**: [Value or \"Not specified\"]\n```\n\nCorrect:\n```\n**SLO**: 99.9%\n```\n\nINCORRECT (added context):\n```\n**SLO**: 99.9% as documented in Section 10.1\n```\n\n---\n\n**Example 2: Conditional Placeholder**\n\nTemplate:\n```\n- Explanation: [If Compliant: SLO documented and meets requirements. If Non-Compliant: SLO not specified. If Unknown: SLO mentioned but value unclear]\n```\n\nStatus: Compliant\n\nCorrect:\n```\n- Explanation: SLO documented and meets requirements\n```\n\nINCORRECT (enhanced):\n```\n- Explanation: The 99.9% SLO is documented and meets organizational SRE standards for service availability\n```\n\n---\n\n**Example 3: Source Reference**\n\nTemplate:\n```\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n```\n\nCorrect:\n```\n- Source: ARCHITECTURE.md Section 10.1\n```\n\nINCORRECT (added line numbers):\n```\n- Source: ARCHITECTURE.md Section 10.1, lines 234-240\n```\n\n---\n\n**Example 4: Conditional Note Field**\n\nTemplate:\n```\n- Note: [If Non-Compliant or Unknown: Implement SLO monitoring in Section 10]\n```\n\nStatus: Compliant ‚Üí Remove entire Note line\nStatus: Non-Compliant ‚Üí Use:\n```\n- Note: Implement SLO monitoring in Section 10\n```\n\n---\n\n**Example 5: Table Preservation**\n\nTemplate:\n```\n| Field | Value |\n|-------|-------|\n| SLO | [Value or \"Not specified\"] |\n```\n\nCorrect:\n```\n| Field | Value |\n|-------|-------|\n| SLO | 99.9% |\n```\n\nINCORRECT (converted to bold list):\n```\n**SLO**: 99.9%\n```\n\n### PHASE 4.5: Comprehensive Pre-Write Template Validation\n\n**MANDATORY CHECK**: Before writing the output file, verify COMPLETE template compliance.\n\n**Validation Checklist - ALL sections MUST pass**:\n\n**1. Document Control Section**:\n- [ ] Section exists with title \"## Document Control\" (exact match, NO numbering)\n- [ ] Table format uses markdown pipes: | Field | Value |\n- [ ] Table has exactly 10 fields (Document Owner, Last Review Date, Next Review Date, Status, Validation Score, Validation Status, Validation Date, Validation Evaluator, Review Actor, Approval Authority)\n- [ ] NO extra fields (no Document ID, Template Version, etc.)\n- [ ] Validation Configuration field present\n\n**2. Dynamic Field Instructions Section**:\n- [ ] Section exists with title matching template (exact match, NO numbering)\n- [ ] Contains Purpose, Field Types, Status Values subsections\n- [ ] Status values listed: Compliant, Non-Compliant, Not Applicable, Unknown\n\n**3. Scoring Methodology Section**:\n- [ ] Section exists (title varies by contract type)\n- [ ] Blocker/Desired tier descriptions present (for two-tier scoring)\n- [ ] Scoring formulas present\n\n**4. Compliance Summary Table**:\n- [ ] Section exists with title \"## Compliance Summary\"\n- [ ] Table has exactly 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\n- [ ] All requirement rows present (count matches template)\n- [ ] Status column uses ONLY: Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] NO rows added or removed\n\n**5. Detailed Requirements Sections**:\n- [ ] All detailed requirement sections from template present\n- [ ] Each section structure matches template\n- [ ] Table structures preserved\n\n**6. Compliance Summary Footer**:\n- [ ] Footer section present (if in template)\n- [ ] Content matches template\n\n**7. General Structure Rules**:\n- [ ] NO section numbering in shared sections (no A.1, A.2, etc.)\n- [ ] ALL tables use markdown pipe format (| X | Y |)\n- [ ] NO tables converted to bold field format (**Field**: Value)\n- [ ] Header section intact (Project, Generation Date, Source, Version)\n- [ ] NO extra sections added\n- [ ] NO template sections removed\n\n**If ANY check fails**: DO NOT write the output file. Return error:\n\"TEMPLATE VALIDATION FAILED: Output structure does not match template. Contract generation aborted.\"\n\n### PHASE 4.6: Calculate Validation Score\n\n**CRITICAL**: This phase calculates validation score and updates contract fields BEFORE writing output.\n\n**Step 4.6.1: Run Score Calculation**\n\nUse Bash tool to execute score calculator:\n```bash\nbun skills/architecture-compliance/utils/score-calculator-cli.ts \\\n  /tmp/populated_sre_contract.md \\\n  validation/sre_architecture_validation.json\n```\n\n**Output**: JSON with validation score, written to `/tmp/validation_score.json`\n\n**Step 4.6.2: Update Contract Fields**\n\nUse Bash tool to execute field updater:\n```bash\nbun skills/architecture-compliance/utils/field-updater-cli.ts \\\n  /tmp/populated_sre_contract.md \\\n  /tmp/validation_score.json \\\n  /tmp/final_sre_architecture_contract.md\n```\n\n**What This Does**:\n- Reads populated contract from Step 4.6.1 input\n- Reads validation score JSON from `/tmp/validation_score.json`\n- Updates Document Control fields with calculated validation scores\n- Updates Overall Compliance footer with actual status counts and percentages\n- Updates Remediation Section A.3.3 with current status and score estimates\n- Writes final contract to `/tmp/final_sre_architecture_contract.md`\n\n**Step 4.6.3: Error Handling**\n\nIf validation fails (e.g., malformed table, missing sections):\n- Log error to stderr\n- Write contract with \"Error\" placeholders in validation fields\n- Continue to PHASE 5 (always write contract output)\n\n**CRITICAL**: Never block contract generation due to validation failure. Always produce output.\n\n### PHASE 5: Write Output\n\n**Step 5.0: Pre-Flight Format Validation**\n\nBefore writing the output file, verify the following:\n\n**Validation Checklist:**\n- [ ] **No LLM enhancements**: All replacements use exact template text\n- [ ] **Table format preserved**: All `| Field | Value |` tables intact\n- [ ] **Status values standardized**: Only Compliant, Non-Compliant, Not Applicable, Unknown\n- [ ] **Conditional placeholders**: Extracted ONLY matching branch (no modifications)\n- [ ] **Source references**: Format `ARCHITECTURE.md Section X.Y` (no line numbers)\n- [ ] **No extra prose**: No explanatory text added beyond template\n- [ ] **Section numbering**: Shared sections use H2 without numbering\n- [ ] **No instructional content**: Verify no \"Dynamic Field Instructions\" or \"BEGIN_INTERNAL_INSTRUCTIONS\" text in output\n\n**If any validation check fails, STOP and fix the issue before proceeding.**\n\n**CRITICAL: This agent creates EXACTLY ONE output file - the .md contract.**\n\n**Prohibited Actions**:\n- ‚ùå DO NOT create .txt report files\n- ‚ùå DO NOT create additional summary files\n- ‚ùå DO NOT create analysis files\n- ‚ùå DO NOT create any files other than the contract .md file\n\n**Allowed Output**:\n- ‚úÖ ONLY: `/compliance-docs/SRE_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**Step 5.1: Determine Output Filename**\n\nFormat: `/compliance-docs/SRE_ARCHITECTURE_[PROJECT]_[DATE].md`\n\n**IMPORTANT**: This is the ONLY file this agent creates. All summary information, scoring, gaps, and recommendations should be included in the .md contract file, NOT in separate report files.\n\n**Step 5.2: Create Output Directory**\n\nUse Bash tool:\n```bash\nmkdir -p compliance-docs\n```\n\n**Step 5.3: Read and Write Final Contract**\n\nUse Read tool to load the validated contract:\n```\nfile_path: /tmp/final_sre_architecture_contract.md\n```\n\nThen use Write tool to write to output location:\n```\nfile_path: [output_filename from 5.1]\ncontent: [content from Read tool above]\n```\n\n**Step 5.4: Return Success with Metadata**\n\nReturn formatted result:\n```\n‚úÖ Generated SRE Architecture compliance contract successfully\n\nContract Details:\n   File: [output_filename]\n   Project: [project_name]\n   Date: [generation_date]\n   Type: SRE Architecture\n   Requirements: 57 (36 Blocker + 21 Desired)\n   Scoring: Blocker 70% + Desired 30%\n   Sections: 10, 11, 5\n```\n\n**IMPORTANT**:\n- This agent does NOT generate COMPLIANCE_MANIFEST.md (skill orchestrator handles this)\n- This agent does NOT generate .txt report files\n- Return ONLY the success message above - no additional files\n\n## Error Handling\n\n- If ARCHITECTURE.md not found ‚Üí Return error message with guidance\n- If template expansion fails ‚Üí Return bash error output\n- If required section missing ‚Üí Mark fields as \"Unknown\", continue generation\n- Always return a result (success or failure) - never exit silently\n\n## SRE Architecture-Specific Notes\n\n- **Two-Tier Scoring**: Blocker requirements must all pass for approval (‚â•8.0 final score)\n- **SLO Minimum**: All services must define SLOs (minimum 99.9%)\n- **Observability Triad**: Must include metrics, logs, AND traces\n- **Incident Response**: P1 < 15min, P2 < 1hr, P3 < 4hr\n- **Runbook Coverage**: All operational procedures must have runbooks\n\n---\n\n**Agent Version**: 2.0.0\n**Last Updated**: 2025-12-27\n**Specialization**: SRE Architecture Compliance\n",
        "release/README.md": "# Release Directory\n\nThis directory contains the distributable release packages for the Solutions Architect Skills plugin.\n\n## Current Release\n\n**Version:** 1.0.0\n**Release Date:** 2025-01-20\n**Package Size:** 249 KB\n\n### Files\n\n- `solutions-architect-skills-v1.0.0.zip` - Main distribution package\n- `solutions-architect-skills-v1.0.0.sha256` - SHA256 checksum for verification\n\n## Verification\n\nVerify package integrity before installation:\n\n```bash\nsha256sum -c solutions-architect-skills-v1.0.0.sha256\n```\n\nExpected output:\n```\nsolutions-architect-skills-v1.0.0.zip: OK\n```\n\n## Installation\n\n```bash\n# Extract the package\nunzip solutions-architect-skills-v1.0.0.zip\n\n# Move to Claude Code plugins directory\nmv solutions-architect-skills ~/.claude/plugins/\n\n# Restart Claude Code\n```\n\n## GitHub Release Checklist\n\nWhen creating a GitHub release:\n\n- [ ] Create Git tag: `v1.0.0`\n- [ ] Release title: \"Solutions Architect Skills v1.0.0\"\n- [ ] Description: Copy from `RELEASE_NOTES_v1.0.0.md`\n- [ ] Upload `solutions-architect-skills-v1.0.0.zip`\n- [ ] Upload `solutions-architect-skills-v1.0.0.sha256`\n- [ ] Mark as \"Latest release\"\n- [ ] Publish release\n\n## Download URL (After GitHub Release)\n\n```\nhttps://github.com/shadowx4fox/solutions-architect-skills/releases/download/v1.0.0/solutions-architect-skills-v1.0.0.zip\n```\n\n## Build Script\n\nTo rebuild the package, run:\n\n```bash\n../scripts/build-release.sh\n```\n\nThis will regenerate the ZIP and SHA256 files in this directory.",
        "skills/architecture-compliance/INTEGRATION_EXAMPLE.md": "# Compliance Generation with Integrated Validation - Example Workflow\n\nThis document demonstrates the complete compliance contract generation workflow with the Template Validation Framework integrated at Phase 4.6.\n\n## Overview\n\nThe validation framework is integrated into Phase 4.6 of the compliance generation workflow (as described in SKILL.md). This ensures that all generated contracts strictly adhere to template requirements before being saved to the output directory.\n\n## Full Workflow Example\n\n### Phase 1-4.5: Template Loading and Population\n*(Existing workflow - no changes)*\n\n```typescript\n// Phase 1: Requirement Extraction from ARCHITECTURE.md\nconst requirements = extractRequirements(architectureMd);\n\n// Phase 2: Template Selection\nconst templateType = selectTemplate(requirements);\n\n// Phase 3: Template Loading with Include Resolution\nconst template = await loadTemplate(templateType);\n\n// Phase 4.1-4.5: Placeholder Replacement and Content Population\nconst generatedContent = populateTemplate(template, requirements);\n```\n\n### Phase 4.6: Automated Template Validation (NEW)\n\n**Integration Point**: Before saving the generated contract, validate it against template rules.\n\n```typescript\nimport { validateGeneratedContract } from './utils/generation-helper';\n\n// Phase 4.6: Validate generated content\nconsole.log('\\nüìã Phase 4.6: Validating generated contract...\\n');\n\nconst validationResult = await validateGeneratedContract(\n  generatedContent,\n  contractType  // e.g., 'sre_architecture'\n);\n\nif (!validationResult.isValid) {\n  // BLOCK: Generation failed validation\n  console.error(validationResult.errorReport);\n\n  throw new Error(\n    `‚ùå Validation failed for ${validationResult.contractDisplayName}\\n` +\n    `   ${validationResult.validationResult.errors.length} error(s), ` +\n    `   ${validationResult.validationResult.warnings.length} warning(s)\\n` +\n    `   Generation blocked - see error report above`\n  );\n}\n\n// Success: Validation passed\nconsole.log(validationResult.successMessage);\n```\n\n### Phase 5: Output\n*(Proceed only if validation passed)*\n\n```typescript\n// Phase 5: Save validated contract to output directory\nconst outputPath = `compliance-docs/${contractType}.md`;\nawait writeFile(outputPath, generatedContent);\n\nconsole.log(`\\n‚úÖ Contract generated successfully: ${outputPath}\\n`);\n```\n\n## Complete Integration Example\n\nHere's a complete example showing the full integration:\n\n```typescript\n#!/usr/bin/env bun\n/**\n * Example: Compliance Contract Generation with Validation\n *\n * Demonstrates the complete workflow with validation integrated at Phase 4.6\n */\n\nimport { readFile, writeFile } from 'fs/promises';\nimport { validateGeneratedContract } from './utils/generation-helper';\n\nasync function generateComplianceContract(\n  architectureMdPath: string,\n  contractType: string\n): Promise<void> {\n  console.log('‚ïê'.repeat(80));\n  console.log('Compliance Contract Generation Workflow');\n  console.log('‚ïê'.repeat(80));\n  console.log(`Architecture Source: ${architectureMdPath}`);\n  console.log(`Contract Type: ${contractType}`);\n  console.log('‚ïê'.repeat(80));\n  console.log();\n\n  try {\n    // Phase 1: Load ARCHITECTURE.md\n    console.log('üìñ Phase 1: Loading ARCHITECTURE.md...');\n    const architectureMd = await readFile(architectureMdPath, 'utf-8');\n    console.log('   ‚úì Loaded\\n');\n\n    // Phase 2-4.5: Extract, Select, Load, Populate\n    console.log('üîß Phase 2-4.5: Generating contract content...');\n\n    // [Your existing generation logic here]\n    // This would include:\n    // - Requirement extraction\n    // - Template selection\n    // - Template loading with include resolution\n    // - Placeholder replacement\n    // - Content population\n\n    const generatedContent = await yourGenerationFunction(\n      architectureMd,\n      contractType\n    );\n    console.log('   ‚úì Content generated\\n');\n\n    // ========================================================================\n    // Phase 4.6: AUTOMATED TEMPLATE VALIDATION (NEW)\n    // ========================================================================\n    console.log('üìã Phase 4.6: Validating generated contract...');\n\n    const validationResult = await validateGeneratedContract(\n      generatedContent,\n      contractType\n    );\n\n    if (!validationResult.isValid) {\n      // BLOCK: Validation failed\n      console.log('   ‚úó Validation FAILED\\n');\n      console.error(validationResult.errorReport);\n\n      throw new Error(\n        `Validation failed for ${validationResult.contractDisplayName}: ` +\n        `${validationResult.validationResult.errors.length} error(s), ` +\n        `${validationResult.validationResult.warnings.length} warning(s)`\n      );\n    }\n\n    // SUCCESS: Validation passed\n    console.log('   ‚úì Validation PASSED');\n    console.log(`   ${validationResult.validationResult.validationSummary.totalChecks} checks performed\\n`);\n    // ========================================================================\n\n    // Phase 5: Save to output\n    console.log('üíæ Phase 5: Saving contract to output directory...');\n    const outputPath = `compliance-docs/${contractType}.md`;\n    await writeFile(outputPath, generatedContent);\n    console.log(`   ‚úì Saved to ${outputPath}\\n`);\n\n    // Success summary\n    console.log('‚ïê'.repeat(80));\n    console.log('‚úÖ CONTRACT GENERATION COMPLETE');\n    console.log('‚ïê'.repeat(80));\n    console.log(validationResult.successMessage);\n    console.log('‚ïê'.repeat(80));\n\n  } catch (error) {\n    // Error handling\n    console.log();\n    console.log('‚ïê'.repeat(80));\n    console.log('‚ùå CONTRACT GENERATION FAILED');\n    console.log('‚ïê'.repeat(80));\n    console.error(error instanceof Error ? error.message : String(error));\n    console.log('‚ïê'.repeat(80));\n\n    process.exit(1);\n  }\n}\n\n// Example usage\nconst architecturePath = 'examples/ARCHITECTURE.md';\nconst contractType = 'sre_architecture';\n\ngenerateComplianceContract(architecturePath, contractType)\n  .catch(error => {\n    console.error('Unexpected error:', error);\n    process.exit(1);\n  });\n```\n\n## Validation Error Handling\n\nWhen validation fails, the framework provides detailed error reports:\n\n```\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nVALIDATION FAILED: SRE Architecture (3 errors, 0 warnings)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nERROR 1: Invalid Status Value (Line 287)\nSeverity: BLOCKING\nLocation: Compliance Summary Table / Row 5\n\nExpected:\n  One of [\"Compliant\", \"Non-Compliant\", \"Not Applicable\", \"Unknown\"]\n\nFound:\n  \"Pass\"\n\nReference:\n  - SKILL.md lines 682-683 (Status value standardization)\n\nFix:\n  Change \"Pass\" to \"Compliant\" (exact case required)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n```\n\n## Batch Validation Example\n\nFor generating multiple contracts in a batch:\n\n```typescript\nimport { validateMultipleContracts } from './utils/generation-helper';\n\nasync function generateAllContracts(architectureMdPath: string) {\n  const contractTypes = [\n    'sre_architecture',\n    'cloud_architecture',\n    'security_architecture',\n    // ... all 10 types\n  ];\n\n  const contracts = [];\n\n  // Generate all contracts\n  for (const contractType of contractTypes) {\n    const content = await generateContractContent(architectureMdPath, contractType);\n    contracts.push({ content, contractType });\n  }\n\n  // Validate all contracts in batch\n  const validationResults = await validateMultipleContracts(contracts);\n\n  // Check for failures\n  const failures = validationResults.filter(r => !r.isValid);\n\n  if (failures.length > 0) {\n    console.error(`\\n‚ùå ${failures.length} contract(s) failed validation:\\n`);\n    failures.forEach(failure => {\n      console.error(`- ${failure.contractDisplayName}`);\n      console.error(`  ${failure.compactSummary}\\n`);\n    });\n\n    throw new Error(`Batch validation failed: ${failures.length} contract(s) invalid`);\n  }\n\n  // All passed - save contracts\n  for (let i = 0; i < contracts.length; i++) {\n    const { contractType } = contracts[i];\n    const { content } = contracts[i];\n    await writeFile(`compliance-docs/${contractType}.md`, content);\n  }\n\n  console.log(`‚úÖ All ${contracts.length} contracts validated and saved successfully`);\n}\n```\n\n## CLI Tool Usage\n\nFor standalone validation of existing contracts:\n\n```bash\n# Validate an existing contract\nbun run utils/validate-cli.ts compliance-docs/sre_architecture.md sre_architecture\n\n# Validate with markdown report\nbun run utils/validate-cli.ts compliance-docs/cloud.md cloud_architecture --markdown\n\n# Compact summary for CI/CD\nbun run utils/validate-cli.ts compliance-docs/security.md security_architecture --compact\n\n# List supported contract types\nbun run utils/validate-cli.ts --list-types\n```\n\n## CI/CD Integration Example\n\nValidate contracts in a CI/CD pipeline:\n\n```yaml\n# .github/workflows/validate-contracts.yml\nname: Validate Compliance Contracts\n\non:\n  pull_request:\n    paths:\n      - 'compliance-docs/*.md'\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install Bun\n        uses: oven-sh/setup-bun@v1\n\n      - name: Validate Contracts\n        run: |\n          for contract in compliance-docs/*.md; do\n            # Extract contract type from filename\n            type=$(basename \"$contract\" .md)\n\n            echo \"Validating $type...\"\n            bun run skills/architecture-compliance/utils/validate-cli.ts \\\n              \"$contract\" \\\n              \"$type\" \\\n              --compact\n          done\n```\n\n## Error Recovery Workflow\n\nWhen validation fails during generation:\n\n1. **Review Error Report**: Check line numbers and specific violations\n2. **Fix Template or Logic**: Update template fragments or generation logic\n3. **Re-run Validation**: Use CLI tool to validate fixes\n4. **Iterate**: Repeat until validation passes\n5. **Proceed to Output**: Save validated contract\n\n```bash\n# After fixing issues, re-validate\nbun run utils/validate-cli.ts temp-output.md sre_architecture\n\n# If passed, move to final location\nmv temp-output.md compliance-docs/sre_architecture.md\n```\n\n## Performance Considerations\n\n**Validation Overhead**:\n- ~100-150ms per contract\n- 3-5% of total generation time\n- Negligible impact on user experience\n\n**Optimization Tips**:\n- Validate incrementally during generation (if possible)\n- Cache validation rules in memory for batch operations\n- Use compact summary in CI/CD (faster than full reports)\n\n## Testing Integration\n\nTest your integration with the provided example:\n\n```bash\n# Run integration test\ncd skills/architecture-compliance\nbun run utils/validate-example.ts\n\n# Expected output:\n# ‚úÖ Example 1: Document with errors - Shows error report\n# ‚úÖ Example 2: Valid document - Shows success message\n# ‚úÖ Example 3: Compact summary format\n# ‚úÖ Example 4: Markdown report format\n```\n\n## Best Practices\n\n1. **Always validate before saving**: Don't skip validation for \"quick edits\"\n2. **Log validation results**: Keep audit trail of validation checks\n3. **Include line numbers in errors**: Makes debugging faster\n4. **Fail fast in CI/CD**: Use `--strict` mode for pipelines\n5. **Test validation rules**: Update unit tests when adding new rules\n\n## Troubleshooting\n\n**Issue**: Validation fails with \"Unknown contract type\"\n- **Solution**: Check contract type matches one of the 10 supported types\n\n**Issue**: Validation passes but contract looks wrong\n- **Solution**: Review validation rules in `validation/template_validation_*.json`\n\n**Issue**: Performance is slow\n- **Solution**: Batch validation for multiple contracts, use compact mode\n\n## Summary\n\nThe Template Validation Framework integrates seamlessly into the compliance generation workflow at Phase 4.6, providing:\n\n- ‚úÖ Strict template adherence enforcement\n- ‚úÖ Detailed error reporting with line numbers\n- ‚úÖ Blocking behavior on validation failures\n- ‚úÖ Support for all 10 contract types\n- ‚úÖ Special case handling (Business Continuity, SRE, Data & AI)\n- ‚úÖ Performance overhead < 200ms per contract\n- ‚úÖ CLI tool for standalone validation\n- ‚úÖ CI/CD integration support\n\nFor more information:\n- **Developer Guide**: VALIDATION_FRAMEWORK_GUIDE.md\n- **Validation Rules**: validation/VALIDATION_RULE_EXAMPLES.md\n- **Schema**: validation/TEMPLATE_VALIDATION_SCHEMA.json\n- **Generation Guide**: COMPLIANCE_GENERATION_GUIDE.md (Phase 4.6)\n",
        "skills/architecture-compliance/STACK_VALIDATION_CHECKLIST.md": "# Stack Validation Checklist\n\n## 1. Java Backend\n\n- [ ] Is the Java language in a supported version? (Java 11, Java 17)\n- [ ] Is Spring Boot used in a supported version?\n- [ ] Are official tools employed? (Maven, Gradle, SonarQube, JUnit, OpenAPI/Swagger)\n- [ ] Is deployment performed in authorized containers? (Docker, Kubernetes: AKS/EKS/GKE/OpenShift)\n- [ ] Are only chapter-approved libraries used?\n- [ ] Does it comply with standard naming conventions for repositories and resources?\n\n## 2. .NET Backend\n\n- [ ] Is the C# language in a supported version? (.NET Core 3.1, .NET 6, .NET 7)\n- [ ] Is ASP.NET Core used as the main framework?\n- [ ] Are official tools employed? (NuGet, xUnit/NUnit, SonarQube)\n- [ ] Is deployment performed in authorized containers? (Docker, Kubernetes: AKS/EKS/GKE/OpenShift)\n- [ ] Are only chapter-approved libraries used?\n- [ ] Does it comply with standard naming conventions for repositories and resources?\n\n## 3. Frontend\n\n- [ ] Is an approved framework used? (Angular v12+, React v17+, Vue.js v3+)\n- [ ] Is TypeScript or JavaScript (ES6+) employed?\n- [ ] Are official tools used? (NPM/Yarn, Webpack, Jest, Cypress)\n- [ ] Is the architecture SPA or Micro-Frontends according to guidelines?\n- [ ] Are only chapter-approved libraries used?\n- [ ] Does it comply with standard naming conventions for repositories and resources?\n\n## 4. Other Stacks and Components\n\n- [ ] Is automation with Python 3.x, Shell Script, RPA (UiPath, Automation Anywhere) aligned with the stack?\n- [ ] Is Infrastructure as Code with Terraform, Ansible, Azure DevOps Pipelines approved?\n- [ ] Are the databases used in the authorized catalog? (PostgreSQL, SQL Server, Oracle, MongoDB)\n- [ ] Do APIs comply with OpenAPI 3.0, REST, gRPC?\n- [ ] Continuous Integration with Azure DevOps, Jenkins, GitHub Actions?\n\n## 5. Exceptions and Action Plan\n\n- [ ] Is there any deviation from the official technology stack?\n- [ ] If yes, has the exception and corresponding action plan been documented?\n- [ ] Is the action plan approved by the chapter and registered in the Compliance Contract?\n\n---\n\n## Important Notes\n\n- If any item does not apply, provide detailed justification in the Compliance Contract.\n- The use of technologies outside the stack requires exception and documented action plan.\n\n## Project Evaluated\n\n**Project Name:** _________________\n\n**Evaluation Date:** _________________\n\n**Evaluator:** _________________\n\n**Status:** [ ] Pass [ ] Requires Action [ ] Rejected\n\n## Observations\n\n_________________________________________________________________________________\n\n_________________________________________________________________________________\n\n_________________________________________________________________________________",
        "skills/architecture-compliance/VALIDATION_FRAMEWORK_GUIDE.md": "# Template Validation Framework - Developer Guide\n\nA comprehensive validation framework for ensuring strict template adherence in compliance contract generation.\n\n## Overview\n\nThe Template Validation Framework provides **two-stage validation** for compliance contract generation:\n\n### Stage 1: Pre-Validation (Phase 4.1) - NEW\nValidates template structure BEFORE data population:\n- No unresolved @include directives\n- Required sections present (Document Control, Compliance Summary)\n- Appendix A.1-A.4 structure correct\n- Basic markdown structure valid\n- Placeholder format correct\n\n**Benefits**: Catches template defects early, before spending time on data extraction/population.\n\n### Stage 2: Post-Validation (Phase 4.6)\nValidates populated contract BEFORE output across 5 critical areas:\n\n1. **Compliance Summary Table** - 6-column format, row counts, markdown syntax\n2. **Status Values** - Exact case enforcement (Compliant, Non-Compliant, Not Applicable, Unknown)\n3. **Appendix A.1-A.4 Structure** - All present, correct order\n4. **Compliance Calculations** - Sum checks (X+Y+Z+W=TOTAL), percentage accuracy\n5. **Template Completeness** - All required sections present\n\n**Benefits**: Ensures final contract strictly adheres to format requirements.\n\n## Quick Start\n\n### Pre-Validation (Phase 4.1)\n\nValidate template structure after expanding @include directives:\n\n```bash\n# Expand template with structure validation\nbun run utils/resolve-includes.ts templates/TEMPLATE_SRE_ARCHITECTURE.md expanded.md --validate\n```\n\nOutput:\n```\nüìã Running template structure pre-validation...\n‚úÖ Template Structure Validation PASSED\n   11/11 checks passed\n\n‚úÖ Template expanded successfully: expanded.md\n   Lines: 1605 ‚Üí 1736 (+131)\n```\n\n### Post-Validation (Phase 4.6)\n\nValidate populated contract before output:\n\n```typescript\nimport { ComplianceValidator } from './utils/validators';\nimport { ErrorReporter } from './utils/error_reporter';\n\n// 1. Create validator with contract-specific rules\nconst validator = new ComplianceValidator(\n  'validation/template_validation_sre_architecture.json'\n);\n\n// 2. Validate document\nconst result = await validator.validateDocument(\n  documentContent,\n  'sre_architecture'\n);\n\n// 3. Check results\nif (!result.isValid) {\n  const report = ErrorReporter.generateReport(result, 'sre_architecture');\n  console.error(report);\n  throw new Error('Validation failed');\n}\n\nconsole.log('‚úÖ Validation passed!');\n```\n\n### Run Example\n\n```bash\ncd skills/architecture-compliance\nbun run utils/validate-example.ts\n```\n\n### Run Tests\n\n```bash\ncd skills/architecture-compliance\nbun test tests/validators.test.ts\n```\n\n**Test Results:**\n```\n‚úÖ 22 pass\n‚ùå 0 fail\nüìä 46 expect() calls\n‚è±Ô∏è  ~36ms\n```\n\n## Architecture\n\n### Components\n\n```\nskills/architecture-compliance/\n‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îú‚îÄ‚îÄ validators.ts               (883 lines) - Post-validation engine (Phase 4.6)\n‚îÇ   ‚îú‚îÄ‚îÄ template-prevalidator.ts    (300 lines) - Pre-validation engine (Phase 4.1)\n‚îÇ   ‚îú‚îÄ‚îÄ error_reporter.ts           (409 lines) - Error formatting & reporting\n‚îÇ   ‚îú‚îÄ‚îÄ generation-helper.ts        (250 lines) - Integration helper module\n‚îÇ   ‚îú‚îÄ‚îÄ validate-cli.ts             (200 lines) - Standalone CLI tool\n‚îÇ   ‚îú‚îÄ‚îÄ resolve-includes.ts         (240 lines) - Template expansion + pre-validation\n‚îÇ   ‚îî‚îÄ‚îÄ validate-example.ts         (200 lines) - Example usage\n‚îú‚îÄ‚îÄ validation/\n‚îÇ   ‚îú‚îÄ‚îÄ TEMPLATE_VALIDATION_SCHEMA.json     - JSON schema for rules\n‚îÇ   ‚îú‚îÄ‚îÄ VALIDATION_RULE_EXAMPLES.md         - Examples & patterns\n‚îÇ   ‚îú‚îÄ‚îÄ template_validation_sre_architecture.json (10 files total)\n‚îÇ   ‚îî‚îÄ‚îÄ ... (9 more contract-specific rule files)\n‚îî‚îÄ‚îÄ tests/\n    ‚îî‚îÄ‚îÄ validators.test.ts          (300 lines) - Comprehensive test suite\n```\n\n### Validation Flow (Two-Stage)\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Phase 4.1: Template Loading           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Expand @include Directives            ‚îÇ\n‚îÇ   (resolve-includes.ts)                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   PRE-VALIDATION (--validate flag)      ‚îÇ\n‚îÇ   Check template structure:             ‚îÇ\n‚îÇ   ‚Ä¢ No unresolved @include directives   ‚îÇ\n‚îÇ   ‚Ä¢ Required sections present           ‚îÇ\n‚îÇ   ‚Ä¢ Appendix A.1-A.4 correct            ‚îÇ\n‚îÇ   ‚Ä¢ Basic markdown structure            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ                ‚îÇ\n         ‚ñº                ‚ñº\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ Valid   ‚îÇ    ‚îÇ Invalid     ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ                ‚îÇ\n         ‚îÇ                ‚ñº\n         ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ         ‚îÇ BLOCK & Show ‚îÇ\n         ‚îÇ         ‚îÇ Error Report ‚îÇ\n         ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Phase 4.2-4.5: Data Population        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Phase 4.6: POST-VALIDATION            ‚îÇ\n‚îÇ   Load Validation Rules                 ‚îÇ\n‚îÇ   (validation/template_validation_*.json)‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Run 5 Validation Areas:               ‚îÇ\n‚îÇ   1. Compliance Table                   ‚îÇ\n‚îÇ   2. Status Values                      ‚îÇ\n‚îÇ   3. Appendix Structure                 ‚îÇ\n‚îÇ   4. Calculations                       ‚îÇ\n‚îÇ   5. Completeness                       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ                ‚îÇ\n         ‚ñº                ‚ñº\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ Valid   ‚îÇ    ‚îÇ Invalid     ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ                ‚îÇ\n         ‚ñº                ‚ñº\n  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n  ‚îÇ Proceed  ‚îÇ    ‚îÇ BLOCK & Show ‚îÇ\n  ‚îÇ to Phase ‚îÇ    ‚îÇ Error Report ‚îÇ\n  ‚îÇ 5        ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Validation Manifest Integration\n\nAfter all contracts are generated (Phase 5), the COMPLIANCE_MANIFEST.md is created with:\n\n1. **Compliance Framework Reference**: Links to this guide (VALIDATION_FRAMEWORK_GUIDE.md)\n2. **Validation Configuration**: Lists all validation rule files used\n3. **Generated Documents**: Summary of all contracts with completeness metrics\n4. **Approval Status**: Aggregate validation scores and review requirements\n\nThis manifest provides a centralized reference for auditing and tracking validation framework usage across all compliance contracts.\n\n## Contract Types & Rules\n\n| Contract | Requirements | Special Case |\n|----------|--------------|--------------|\n| SRE Architecture | 57 (36+21) | Two-tier scoring |\n| Business Continuity | 5 sections | Section-based (no table) |\n| Cloud Architecture | 6 | Standard |\n| Security Architecture | 56 | Standard |\n| Data & AI | 10 (5+5) | Dual categories |\n| Development | 14 | Standard |\n| Enterprise | 12 | Standard |\n| Integration | 18 | Standard |\n| Platform IT | 15 | Standard |\n| Process Transformation | 12 | Standard |\n\n## Error Reporting\n\n### Console Report Format\n\n```\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nVALIDATION FAILED: SRE Architecture (3 errors, 1 warning)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nERROR 1: Invalid Status Value (Line 287)\nSeverity: BLOCKING\nLocation: Compliance Summary Table / Row 5\n\nExpected:\n  One of [\"Compliant\", \"Non-Compliant\", \"Not Applicable\", \"Unknown\"]\n\nFound:\n  \"Pass\"\n\nFix:\n  Change \"Pass\" to \"Compliant\" (exact case required)\n```\n\n### Other Formats\n\n```typescript\n// Compact summary\nconst summary = ErrorReporter.generateCompactSummary(result);\n// Output: \"‚ùå Validation failed: 3 blocking errors, 1 warning\"\n\n// Markdown report\nconst markdown = ErrorReporter.generateMarkdownReport(result, contractType);\n// Output: Full markdown with tables and formatting\n```\n\n## Validation Details\n\n### 1. Compliance Summary Table\n\n**What it validates:**\n- Exactly 6 columns in correct order\n- Markdown syntax (pipes, separators)\n- Row count matches requirements\n- Code format: `^[A-Z]+\\d+$`\n- Valid category values\n- Valid status values\n\n**Common errors:**\n- Wrong column count (5 instead of 6)\n- Missing \"Responsible Role\" column\n- Invalid code format\n- Wrong status case\n\n### 2. Status Value Standardization\n\n**What it validates:**\n- Exact case: \"Compliant\", \"Non-Compliant\", \"Not Applicable\", \"Unknown\"\n- Consistency across all locations\n\n**Common errors:**\n- Lowercase \"compliant\" instead of \"Compliant\"\n- \"Pass\"/\"Fail\" instead of standard values\n- \"N/A\" instead of \"Not Applicable\"\n\n### 3. Appendix A.1-A.4 Structure\n\n**What it validates:**\n- All 4 appendices present\n- Correct heading format: `### A.X`\n- Correct order (A.1 ‚Üí A.2 ‚Üí A.3 ‚Üí A.4)\n\n**Common errors:**\n- Missing A.2 or A.3\n- Out of order appendices\n- Wrong heading level\n\n### 4. Compliance Calculations\n\n**What it validates:**\n- Sum: Compliant + Non-Compliant + Not Applicable + Unknown = TOTAL\n- Percentages: `round((count / TOTAL) * 100)` matches stated %\n- Emojis: ‚úÖ ‚ùå ‚äò ‚ùì\n\n**Common errors:**\n- Counts don't sum to TOTAL\n- Percentage off by 1% (rounding error)\n- Missing or wrong emoji\n\n### 5. Template Completeness\n\n**What it validates:**\n- All required sections present\n- Correct section identifiers\n\n**Common errors:**\n- Missing document_control\n- Missing dynamic_sections\n\n## Performance\n\n**Benchmarks:**\n- Validation: ~100-150ms per contract\n- Overhead: 3-5% of total generation time\n- All tests: ~36ms for 22 tests\n\n**Optimization:**\n- Incremental validation (section-by-section)\n- Early error detection\n- Efficient regex patterns\n- Cached validation rules\n\n## Extending the Framework\n\n### Adding New Validation Type\n\n1. **Update Schema** (`TEMPLATE_VALIDATION_SCHEMA.json`)\n2. **Update Contract Rules** (all 10 JSON files)\n3. **Implement Validation** (`validators.ts`)\n4. **Add Tests** (`validators.test.ts`)\n5. **Update Documentation**\n\nExample:\n```typescript\n// In validators.ts\nprivate async validateNewRule(content: string): Promise<void> {\n  const rules = this.rules.validations.new_rule!;\n  this.checksPerformed++;\n\n  // Validation logic here\n\n  if (/* validation fails */) {\n    this.errors.push({\n      errorId: 'NEW_RULE_ERROR',\n      severity: rules.severity,\n      validationArea: 'New Rule',\n      location: 'Somewhere',\n      expected: 'Expected value',\n      found: 'Actual value',\n      references: { skillMd: 'line 123' },\n      fix: 'How to fix',\n    });\n  }\n\n  this.checksPassed++;\n}\n```\n\n### Modifying Requirements\n\nSimply update the contract-specific JSON file:\n\n```json\n{\n  \"validations\": {\n    \"compliance_summary_table\": {\n      \"requirement_count\": 60  // Changed from 57\n    }\n  }\n}\n```\n\n## Special Cases\n\n### Business Continuity\n\nUses **section-based format** instead of table:\n\n```markdown\n## 1. Recovery Objectives (LABC1)\n\n**RTO**: 4 hours\n- Status: Compliant\n\n**RPO**: 15 minutes\n- Status: Compliant\n```\n\n**Validation:**\n- Table validation disabled\n- Section-based format validation enabled\n- Appendix A.2 not required\n\n### SRE Architecture\n\n**Two-tier scoring:** 36 Blocker + 21 Desired = 57 total\n\n**Validation:**\n- Must have exactly 57 rows\n- Two-tier note must be present\n- Blocker/Desired counts validated\n\n### Data & AI\n\n**Dual categories:** \"Data\" and \"AI\" (not \"Data & AI Architecture\")\n\n**Validation:**\n- Category must be \"Data\" or \"AI\"\n- Code pattern: `^LA(D|AI)\\d+$`\n\n## Troubleshooting\n\n### Test Failures\n\n**Issue:** Tests fail with \"INVALID_TABLE_COLUMNS\"\n```bash\n# Solution: Check table has exactly 6 columns\ncat test-document.md | grep \"^|\" | head -1\n# Should show 6 pipe-separated columns\n```\n\n**Issue:** Tests fail with calculation errors\n```bash\n# Solution: Verify sum and percentages\n# Sum: Compliant + Non-Compliant + Not Applicable + Unknown = TOTAL\n# Percentage: round((count / TOTAL) * 100)\n```\n\n### Integration Issues\n\n**Issue:** Validation too strict\n```typescript\n// Solution: Adjust tolerance in rules\n{\n  \"compliance_calculation\": {\n    \"percentage_tolerance\": 1  // Allow ¬±1% deviation\n  }\n}\n```\n\n**Issue:** Performance too slow\n```typescript\n// Solution: Disable non-critical validations for debugging\n{\n  \"appendix_structure\": {\n    \"enabled\": false  // Temporarily disable\n  }\n}\n```\n\n## Testing\n\n### Run Full Test Suite\n\n```bash\nbun test tests/validators.test.ts\n```\n\n### Run Specific Test\n\n```bash\nbun test tests/validators.test.ts -t \"should pass validation for valid 6-column table\"\n```\n\n### Run with Coverage\n\n```bash\nbun test --coverage tests/validators.test.ts\n```\n\n### Test Categories\n\n- **ComplianceTableValidation** (4 tests)\n- **StatusValueValidation** (4 tests)\n- **AppendixValidation** (4 tests)\n- **CalculationValidation** (5 tests)\n- **CompletenessValidation** (2 tests)\n- **IntegrationTests** (2 tests)\n- **ContractTypeMismatch** (1 test)\n\n## Documentation References\n\n- **Schema**: `validation/TEMPLATE_VALIDATION_SCHEMA.json`\n- **Examples**: `validation/VALIDATION_RULE_EXAMPLES.md`\n- **Integration**: `COMPLIANCE_GENERATION_GUIDE.md` (Phase 4.6)\n- **Format Requirements**: `SKILL.md` (lines 676-740)\n\n## API Reference\n\n### ComplianceValidator\n\n```typescript\nclass ComplianceValidator {\n  constructor(rulesPath: string)\n\n  validateDocument(\n    content: string,\n    contractType: string\n  ): Promise<ValidationResult>\n}\n```\n\n### ErrorReporter\n\n```typescript\nclass ErrorReporter {\n  static generateReport(\n    result: ValidationResult,\n    contractType: string\n  ): string\n\n  static generateCompactSummary(\n    result: ValidationResult\n  ): string\n\n  static generateMarkdownReport(\n    result: ValidationResult,\n    contractType: string\n  ): string\n\n  static groupErrorsByArea(\n    errors: ValidationError[]\n  ): Map<string, ValidationError[]>\n}\n```\n\n### Types\n\n```typescript\ninterface ValidationResult {\n  isValid: boolean\n  errors: ValidationError[]\n  warnings: ValidationError[]\n  validationSummary: {\n    totalChecks: number\n    passed: number\n    failed: number\n    warnings: number\n  }\n}\n\ninterface ValidationError {\n  errorId: string\n  severity: 'BLOCKING' | 'WARNING' | 'INFO'\n  validationArea: string\n  lineNumber?: number\n  location: string\n  expected: string\n  found: string\n  references: {\n    skillMd?: string\n    template?: string\n    shared?: string\n  }\n  fix: string\n}\n```\n\n## Version History\n\n- **v1.0.0** - Initial release with all 5 validation areas\n- Full test coverage (22 tests passing)\n- Support for all 10 contract types\n- Special case handling (Business Continuity, SRE, Data & AI)\n\n## Future Enhancements\n\nPotential future additions:\n- [ ] Validation caching for performance\n- [ ] Parallel validation execution\n- [ ] Custom validation plugins\n- [ ] Validation metrics dashboard\n- [ ] Auto-fix suggestions\n- [ ] Integration with CI/CD\n- [ ] HTML report generation\n\n---\n\n**Status:** ‚úÖ Production Ready\n**Test Coverage:** 22/22 passing\n**Performance:** <150ms per contract\n**Last Updated:** 2024-12-11\n",
        "skills/architecture-compliance/contracts/CONTRACT_TYPES_REFERENCE.md": "# Compliance Contract Types - Reference\n\n## Purpose\n\nThis document provides a comprehensive description of the 10 compliance contract types available in the architecture-compliance skill. It serves as a reference for creating, validating, and selecting contract templates.\n\n---\n\n## Contract Type Validation\n\nWhen generating compliance contracts, the architecture-compliance skill validates user-requested contract types against this reference list. If an unrecognized contract type is requested, the skill offers the 3 best alternative matches based on:\n- **Keyword matching**: Identifying common words between user input and contract names/keywords\n- **Alias recognition**: Matching against known aliases for contract types (e.g., \"sre\" ‚Üí \"SRE Architecture\")\n- **Fuzzy string matching**: Calculating edit distance for typo tolerance (e.g., \"securtiy\" ‚Üí \"security\")\n\n**Supported contract types** (10 total):\n1. Business Continuity\n2. SRE Architecture\n3. Cloud Architecture\n4. Data & AI Architecture\n5. Development Architecture\n6. Process Transformation and Automation\n7. Security Architecture\n8. IT Infrastructure\n9. Enterprise Architecture\n10. Integration Architecture\n\n**Aliases and shortcuts**: See SKILL.md Phase 2.1 for complete Contract Type Aliases and Keywords table.\n\n**Validation behavior**:\n- **Exact match**: Contract generated immediately\n- **Alias match**: Alias resolved to full contract type name, contract generated\n- **No match**: User presented with 3 best alternatives to choose from\n- **Ambiguous input**: User can select \"Other\" to see all 10 contract types with descriptions\n\nFor detailed validation scenarios, see SKILL.md \"Phase 2.1 Example Scenarios\" section.\n\n---\n\n## Source Traceability Policy\n\nAll compliance contracts generated by this skill follow a **strict source traceability policy** to ensure audit compliance.\n\n**Policy Summary:**\n- Every data point must reference an actual ARCHITECTURE.md section and line number\n- No inference, derivation, or guessing of values is permitted\n- Missing data is clearly marked with `[PLACEHOLDER]` and section guidance\n\n**Extraction Methods:**\n1. **Direct Extraction**: Value explicitly stated in ARCHITECTURE.md\n2. **Aggregation**: Multiple values consolidated from different sections\n3. **Transformation**: Calculated values with formula shown and source reference\n\n**Prohibited Actions:**\n- Inferring values from context (e.g., inferring \"Tier 1\" from 99.99% SLA)\n- Deriving values from architectural patterns\n- Guessing section locations or creating non-existent sections\n- Suggesting specific values without ARCHITECTURE.md source\n\n**Placeholder Format:**\nWhen data is missing, placeholders include:\n- Section reference where data should be added\n- Optional industry standard reference (informational only)\n- Specific guidance on subsection path\n\n**Example:**\n```\n**Authentication Method**: [PLACEHOLDER: Not specified in ARCHITECTURE.md Section 9.1]\nOptional Reference: Common patterns: OAuth 2.0 + JWT (IETF RFC 6749), SAML 2.0\nNote: Add authentication approach to ARCHITECTURE.md Section 9.1 (Security Architecture ‚Üí Authentication)\n```\n\nThis policy ensures compliance documents are fully auditable for regulatory requirements.\n\n---\n\n## 1. Business Continuity\n\n**Purpose**: Guidelines to ensure solution resilience, disaster recovery, and backup.\n\n**Main Guidelines**:\n- **Impact to critical processes**: Document impact to critical business processes and recovery procedures\n- **Disaster recovery**: Define automated disaster recovery procedures\n- **DR Automation**: Implement automation where possible to minimize RTO\n\n**Guideline Examples**:\n- Impact to critical processes must be documented\n- RTO and RPO must be defined based on business criticality\n- Disaster recovery procedures must be automated\n- Backup restoration must be tested quarterly\n- Geographic redundancy required for Tier 1 applications\n\n**Stakeholders**:\n- Business continuity team\n- Operations team\n- Infrastructure team\n- Executive leadership\n\n**Key Metrics**:\n- RTO (Recovery Time Objective)\n- RPO (Recovery Point Objective)\n- Backup frequency\n- Retention time\n- DR testing frequency\n\n---\n\n## 2. SRE Architecture (Site Reliability Engineering)\n\n**Purpose**: Guidelines focused on solution resilience, observability, and automation.\n\n**Main Guidelines**:\n- **Resilience assessment**: Evaluate solution and component resilience\n- **Component observability**: Ensure critical component observability (metrics, logs, traces)\n\n**Guideline Examples**:\n- All services must define availability SLOs (minimum 99.9%)\n- Error budgets must be calculated and monitored monthly\n- Monitoring must include metrics, logs, and traces (observability triad)\n- Incident response time: P1 < 15min, P2 < 1hr, P3 < 4hr\n- Postmortems required for all P1/P2 incidents\n- Runbooks must exist for all operational procedures\n\n**Stakeholders**:\n- SRE team\n- DevOps team\n- Platform engineering\n- On-call engineers\n\n**Key Metrics**:\n- SLOs (Service Level Objectives)\n- SLIs (Service Level Indicators)\n- Error budget\n- MTTR (Mean Time To Recovery)\n- MTBF (Mean Time Between Failures)\n- Runbook coverage\n\n---\n\n## 3. Cloud Architecture\n\n**Purpose**: Guidelines for solutions deployed in the cloud.\n\n**Main Guidelines**:\n- **Deployment model**: Document deployment model (IaaS, PaaS, SaaS)\n- **Connectivity**: Define network architecture, VPN, latency\n- **Security**: Implement IAM, encryption, network security\n- **Monitoring**: Use cloud-native tools, cost tracking\n- **Backup**: Cloud backup strategy, multi-region replication\n- **Cloud best practices**: Apply frameworks like Well-Architected\n\n**Guideline Examples**:\n- Cloud deployment model must be documented (IaaS/PaaS/SaaS)\n- Multi-region deployment required for Tier 1 applications\n- Cloud-native services preferred over custom solutions\n- Cost optimization: reserved instances, auto-scaling, right-sizing\n- Cloud security: encryption at rest/in-transit, IAM with least privilege\n- Monitoring: integration with CloudWatch/Azure Monitor/Stackdriver\n\n**Stakeholders**:\n- Cloud architects\n- Infrastructure team\n- Security team\n- FinOps/Cost optimization\n\n**Key Metrics**:\n- Multi-region coverage\n- Cloud costs (monthly)\n- Cloud-native vs. custom services usage\n- Provisioning time\n- IaC (Infrastructure as Code) coverage\n\n---\n\n## 4. Data & Analytics - AI Architecture\n\n**Purpose**: Guidelines for data management, analytics, and artificial intelligence use.\n\n**Main Guidelines**:\n- **Data quality**: Validation, cleansing, accuracy, completeness\n- **Reusability**: Promote data and component reuse\n- **Recovery**: Data backup and recovery strategies\n- **Scalability**: Design for volume growth (3x without redesign)\n- **Integration**: Connect data sources and destinations\n- **Regulatory compliance**: GDPR, data residency\n- **AI model governance**: Training, deployment, monitoring, re-training\n\n**Guideline Examples**:\n- Data quality metrics must be defined and monitored\n- Data lineage must be tracked from source to consumption\n- PII data must be encrypted and masked appropriately\n- AI models must have defined re-training schedules\n- Retention policies must comply with regulations\n- Data scalability must handle 3x growth without redesign\n\n**Stakeholders**:\n- Data architects\n- Data engineers\n- Data scientists\n- ML engineers\n- Data governance team\n\n**Key Metrics**:\n- Data quality coverage\n- Data lineage coverage\n- Data volume (TB)\n- Data pipeline latency\n- ML model accuracy\n- Re-training frequency\n\n---\n\n## 5. Development Architecture\n\n**Purpose**: Guidelines for software development and technical debt management.\n\n**Main Guidelines**:\n- **Technology stack**: Document languages, frameworks, versions\n- **Exception action plans**: Justify deviations from standards\n\n**Guideline Examples**:\n- Technology stack must use supported versions, not deprecated\n- Minimum code coverage: 80% for critical paths\n- All code changes require peer review\n- Technical debt must be tracked and addressed quarterly\n- Dependency vulnerabilities must be patched within SLA\n- Exception plans required for non-standard technology choices\n\n**Stakeholders**:\n- Development teams\n- Tech leads\n- Engineering managers\n- DevOps team\n\n**Key Metrics**:\n- Code coverage\n- Technical debt (story points)\n- Development velocity\n- Build time\n- Dependency vulnerabilities (count by severity)\n\n---\n\n## 6. Process Transformation and Automation\n\n**Purpose**: Guidelines for automation solutions and document management.\n\n**Main Guidelines**:\n- **Automation best practices**: Tools, frameworks, patterns\n- **Impact analysis**: Efficiency gains, cost reduction, time savings\n- **Efficient license consumption**: License optimization\n- **Capability reuse**: Shared services, reusable components\n\n**Guideline Examples**:\n- Manual processes >10 hours/month must be evaluated for automation\n- Automation ROI must be positive within 12 months\n- Reusable capabilities must be designed as shared services\n- License costs must be optimized (concurrent vs. named users)\n- Process automation must include error handling and monitoring\n- Impact analysis required before process changes\n\n**Stakeholders**:\n- Process improvement team\n- Automation engineers\n- Business analysts\n- Digital transformation office\n\n**Key Metrics**:\n- Hours saved by automation\n- Automation ROI\n- Number of automated processes\n- Cost reduction\n- Adoption rate\n\n---\n\n## 7. Security Architecture\n\n**Purpose**: Guidelines for solution security.\n\n**Main Guidelines**:\n- **API exposure**: Protection, authentication, authorization, rate limiting\n- **Authentication**: OAuth, SAML, JWT, MFA\n- **Encryption**: TLS for transit, AES for rest, key management\n- **Intra/inter microservice communication**: Mutual TLS, encryption\n\n**Guideline Examples**:\n- All APIs must require authentication and authorization\n- Encryption required: TLS 1.3 for transit, AES-256 for rest\n- Secrets must never be stored in code or configuration files\n- Microservice communication must use mutual TLS (mTLS)\n- Security vulnerabilities: Critical < 24hr, High < 7 days\n- All authentication events must be logged and monitored\n\n**Stakeholders**:\n- Security architects\n- Security operations (SecOps)\n- Application security team\n- Compliance team\n\n**Key Metrics**:\n- Authentication coverage (% of APIs)\n- Open vulnerabilities (by severity)\n- Vulnerability remediation time\n- Unauthorized access attempts\n- Encryption coverage\n\n---\n\n## 8. Platform & IT Infrastructure\n\n**Purpose**: Guidelines for design and deployment on technology platforms and infrastructure.\n\n**Main Guidelines**:\n- **Unique production environments**: Isolation, purpose\n- **Authorized operating systems**: Versions, patching\n- **Database capacity and retention**: Sizing, policies\n- **Nomenclature**: Conventions for resources, environments\n- **Transactional sizing**: TPS capacity, scaling limits\n\n**Guideline Examples**:\n- Production environments must be isolated (network, IAM)\n- Only authorized OS versions can be used (current security patches)\n- Database capacity must support 3x current transaction volume\n- Retention policies must comply with regulatory requirements\n- Naming conventions must be consistent and documented\n- Infrastructure must be defined as code (IaC)\n\n**Stakeholders**:\n- Platform engineers\n- Infrastructure team\n- Database administrators\n- Operations team\n\n**Key Metrics**:\n- Number of environments\n- Infrastructure capacity (CPU, memory, storage)\n- Capacity utilization\n- IaC coverage\n- Naming convention compliance\n\n---\n\n## 9. Enterprise Architecture\n\n**Purpose**: Guidelines for strategic alignment, modularity, data management, and cloud-first approach.\n\n**Main Guidelines**:\n- **Modularity**: Bounded contexts, service boundaries\n- **Third-party application customization**: Maximum limit 20%\n- **Cloud first**: Prefer cloud-native over on-premise\n- **Business strategy alignment**: Capability mapping\n- **Zero obsolescence**: Avoid technologies EOL within 3 years\n- **API First/Event Driven**: API-first design, async event decoupling\n\n**Guideline Examples**:\n- Solutions must align with enterprise business capabilities\n- Modularity: services must be bounded by business domains\n- Cloud-first: prefer cloud-native solutions over on-premise\n- Third-party app customization maximum: 20% of functionality\n- No obsolete technologies (EOL within 3 years)\n- API-first design for all service interfaces\n- Event-driven for asynchronous processes\n\n**Stakeholders**:\n- Enterprise architects\n- Business architects\n- CTO/CIO office\n- Portfolio management\n\n**Key Metrics**:\n- Business capability alignment\n- % third-party app customization\n- Cloud-native coverage\n- Technology age (years to EOL)\n- API-first coverage\n\n---\n\n## 10. Integration Architecture\n\n**Purpose**: Guidelines for microservice, API, and event integration.\n\n**Main Guidelines**:\n- **Best practices adoption**: API design, versioning, error handling\n- **Secure integrations**: Authentication, encryption\n- **Avoid obsolete technologies**: Don't use deprecated protocols\n- **Traceability and audit**: Correlation IDs, logging\n- **Integration standards compliance**: OpenAPI, AsyncAPI\n\n**Guideline Examples**:\n- All integrations must be cataloged and documented\n- REST APIs must follow OpenAPI 3.0 specification\n- Asynchronous integrations must use selective async patterns\n- Integration security: OAuth 2.0, mutual TLS, API keys\n- Avoid obsolete protocols (SOAP 1.1, XML-RPC, etc.)\n- All integrations must include correlation IDs for traceability\n- API versioning strategy must be consistent (URI vs. header)\n\n**Stakeholders**:\n- Integration architects\n- API platform team\n- Microservice teams\n- Enterprise integration team\n\n**Key Metrics**:\n- Number of integrations\n- Standards compliance (% OpenAPI)\n- Integration latency\n- Integration error rate\n- Correlation ID coverage\n\n---\n\n## Contract Mapping to ARCHITECTURE.md Sections\n\n| Contract | Primary Sections | Secondary Sections | Complexity |\n|----------|------------------|-------------------|------------|\n| 1. Business Continuity | 11 | 10 | Medium |\n| 2. SRE Architecture | 10, 11 | 5 | High |\n| 3. Cloud Architecture | 4, 8, 11 | 9, 10 | High |\n| 4. Data/AI Architecture | 5, 6, 7 | 8, 10 | High |\n| 5. Development Architecture | 3, 5, 8, 12 | 11 | Medium |\n| 6. Process Transformation | 1, 2, 6 | 5, 7 | Low |\n| 7. Security Architecture | 9 | 7, 11 | High |\n| 8. Platform Infrastructure | 4, 8, 11 | 10 | Medium |\n| 9. Enterprise Architecture | 1, 2, 3, 4 | 12 | Medium |\n| 10. Integration Architecture | 7 | 5, 6, 8 | High |\n\n---\n\n## Document Usage\n\nThis reference document should be used to:\n\n1. **Create templates**: Ensure templates cover all guidelines\n2. **Validate compliance**: Verify ARCHITECTURE.md has sufficient information\n3. **Generate documents**: Extract relevant data from ARCHITECTURE.md\n4. **Identify gaps**: Detect missing architecture information\n5. **Train teams**: Educate about compliance requirements\n\n---\n\n**Last Updated**: [GENERATION_DATE]\n**Source**: Organizational Compliance Contract Documents",
        "skills/architecture-compliance/shared/MIGRATION_GUIDE.md": "# Migration Guide: Refactoring Templates to Use Shared Content\n\n## Purpose\n\nThis guide provides step-by-step instructions for refactoring the remaining 9 compliance templates to use the shared content system.\n\n**Current Status**:\n- ‚úÖ **Business Continuity** - COMPLETED (proof-of-concept, 87 lines saved)\n- ‚è≥ **Remaining 9 templates** - TO BE MIGRATED\n\n---\n\n## Prerequisites\n\nBefore migrating a template, ensure:\n\n1. ‚úÖ Shared infrastructure exists (`shared/sections/`, `shared/fragments/`, `shared/config/`)\n2. ‚úÖ Shared files are created and tested\n3. ‚úÖ SKILL.md documents include processing (Phase 4, Step 4.1)\n4. ‚úÖ COMPLIANCE_GENERATION_GUIDE.md explains shared system\n\n---\n\n## Migration Process (Per Template)\n\n### Step 1: Identify Domain Name\n\nDetermine the domain identifier from template filename:\n\n| Template File | Domain Name | Config File |\n|--------------|-------------|-------------|\n| TEMPLATE_CLOUD_ARCHITECTURE.md | cloud-architecture | cloud-architecture.json |\n| TEMPLATE_SRE_ARCHITECTURE.md | sre-architecture | sre-architecture.json |\n| TEMPLATE_SECURITY_ARCHITECTURE.md | security-architecture | security-architecture.json |\n| TEMPLATE_DATA_AI_ARCHITECTURE.md | data-ai-architecture | data-ai-architecture.json |\n| TEMPLATE_DEVELOPMENT_ARCHITECTURE.md | development-architecture | development-architecture.json |\n| TEMPLATE_PLATFORM_IT_INFRASTRUCTURE.md | platform-it-infrastructure | platform-it-infrastructure.json |\n| TEMPLATE_ENTERPRISE_ARCHITECTURE.md | enterprise-architecture | enterprise-architecture.json |\n| TEMPLATE_INTEGRATION_ARCHITECTURE.md | integration-architecture | integration-architecture.json |\n| TEMPLATE_PROCESS_TRANSFORMATION.md | process-transformation | process-transformation.json |\n\n### Step 2: Create Domain Config\n\nCreate `shared/config/<domain-name>.json` with required variables:\n\n```json\n{\n  \"domain_name\": \"Cloud Architecture\",\n  \"compliance_prefix\": \"LAC\",\n  \"review_board\": \"Cloud Architecture Review Board\",\n  \"approval_authority\": \"Cloud Architecture Review Board\",\n  \"validation_config_path\": \"/skills/architecture-compliance/validation/cloud_architecture_validation.json\"\n}\n```\n\n**Variable Mapping Table**:\n\n| Domain | compliance_prefix | review_board | validation_config_path |\n|--------|------------------|--------------|------------------------|\n| Cloud Architecture | LAC | Cloud Architecture Review Board | validation/cloud_architecture_validation.json |\n| SRE Architecture | LASRE | SRE Review Board | validation/sre_architecture_validation.json |\n| Security Architecture | LAS | Security Review Board | validation/security_architecture_validation.json |\n| Data & AI Architecture | LAD / LAIA | Data & AI Architecture Review Board | validation/data_ai_architecture_validation.json |\n| Development Architecture | LADES | Development Architecture Review Board | validation/development_architecture_validation.json |\n| Platform IT Infrastructure | LAPI | Infrastructure Review Board | validation/platform_it_infrastructure_validation.json |\n| Enterprise Architecture | LAE | Enterprise Architecture Review Board | validation/enterprise_architecture_validation.json |\n| Integration Architecture | LAI | Integration Architecture Review Board | validation/integration_architecture_validation.json |\n| Process Transformation | LAP | Process Transformation Review Board | validation/process_transformation_validation.json |\n\n### Step 3: Backup Original Template\n\nAlways create a backup before making changes:\n\n```bash\ncp TEMPLATE_<NAME>.md TEMPLATE_<NAME>.md.backup\n```\n\nExample:\n```bash\ncp TEMPLATE_CLOUD_ARCHITECTURE.md TEMPLATE_CLOUD_ARCHITECTURE.md.backup\n```\n\n### Step 4: Identify Sections to Replace\n\nOpen the template and locate these sections:\n\n#### 4A. Document Control (Lines ~10-26)\n\n**Look for**:\n```markdown\n## Document Control\n\n| Field | Value |\n|-------|-------|\n| Document Owner | [SOLUTION_ARCHITECT or N/A] |\n...\n```\n\n**Replace with**:\n```markdown\n<!-- @include-with-config shared/sections/document-control.md config=<domain-name> -->\n```\n\n#### 4B. Dynamic Field Instructions (Lines ~27-60)\n\n**Look for**:\n```markdown\n**Dynamic Field Instructions for Document Generation**:\n\n- `[DOCUMENT_STATUS]`: Determined by validation_results.outcome.document_status\n...\n```\n\n**Replace with**:\n```markdown\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=<domain-name> -->\n```\n\n#### 4C. Compliance Score Calculation (Lines ~61-66)\n\n**Look for**:\n```markdown\n**CRITICAL - Compliance Score Calculation**:\nWhen calculating the Compliance Score in validation_results, N/A items MUST be included in the numerator:\n...\n```\n\n**Replace with**:\n```markdown\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n```\n\n#### 4D. Status Codes in Appendix A.1 (Lines ~145-150)\n\n**Look for** (in Appendix A.1):\n```markdown\n**Status Codes**:\n- **Compliant**: Requirement fully satisfied with documented evidence\n- **Non-Compliant**: Requirement not met or missing from ARCHITECTURE.md\n- **Not Applicable**: Requirement does not apply to this solution\n- **Unknown**: Partial information exists but insufficient to determine compliance\n```\n\n**Replace with**:\n```markdown\n<!-- @include shared/fragments/status-codes.md -->\n```\n\n#### 4E. Validation Methodology in Appendix A.2 (Lines ~160-192)\n\n**Look for**:\n```markdown\n### A.2 Validation Methodology\n\n**Validation Process**:\n\n1. **Completeness Check (40% weight)**:\n...\n```\n\n**Replace with**:\n```markdown\n<!-- @include-with-config shared/sections/validation-methodology.md config=<domain-name> -->\n```\n\n### Step 5: Apply Replacements\n\nUse the Edit tool or text editor to make the replacements identified in Step 4.\n\n**Important**:\n- Preserve domain-specific content (A.1 domain terms, A.3 completion guide, A.4 change history)\n- Only replace the 5 common sections\n- Maintain line spacing and formatting\n\n### Step 6: Verify Line Count\n\nCheck lines saved:\n\n```bash\nwc -l TEMPLATE_<NAME>.md*\necho \"Lines saved:\" && echo \"$(($(wc -l < TEMPLATE_<NAME>.md.backup) - $(wc -l < TEMPLATE_<NAME>.md)))\"\n```\n\n**Expected savings**: 60-90 lines per template\n\n### Step 7: Test Generation (Manual Verification)\n\nSince include processing isn't yet implemented, manually verify:\n\n1. Read the template file\n2. For each `@include` directive:\n   - Read the shared file\n   - If `@include-with-config`, replace `{{variables}}` with values from config\n   - Verify expanded content matches original template\n3. Compare expanded template with original backup\n\n### Step 8: Document Changes\n\nUpdate the template's A.4 Change History:\n\n```markdown\n**Version 2.1 (Current)**:\n- Migrated to shared content system\n- Replaced 5 common sections with @include directives\n- Lines reduced from XXX to YYY (-ZZ lines)\n- Maintains identical output through include resolution\n```\n\n### Step 9: Commit Changes\n\n```bash\ngit add shared/config/<domain-name>.json\ngit add templates/TEMPLATE_<NAME>.md\ngit commit -m \"refactor: Migrate <Domain Name> template to shared content system\n\n- Create domain config: shared/config/<domain-name>.json\n- Replace 5 common sections with include directives\n- Lines saved: XX (-YY%)\n- Backward compatible with include resolution\n\nRelated: Business Continuity proof-of-concept (87 lines saved)\"\n```\n\n---\n\n## Migration Order (Recommended)\n\n### Phase 1: Simple Templates (Week 1)\n\n1. **Cloud Architecture** - Simple structure, good test case\n2. **Enterprise Architecture** - Already has complete A.1-A.4 structure\n3. **Process Transformation** - Well-structured, similar to Cloud\n\n**Reason**: These templates closely match Business Continuity in structure.\n\n### Phase 2: Complex Templates (Week 2)\n\n4. **Security Architecture** - Has A.1-A.4 but longer\n5. **Data & AI Architecture** - Dual prefix (LAD/LAIA), good complexity test\n6. **Integration Architecture** - Has A.1-A.4, needs data sections added\n\n**Reason**: Slightly more complex but still manageable.\n\n### Phase 3: Specialized Templates (Week 3)\n\n7. **Development Architecture** - Has Stack Validation Checklist integration\n8. **Platform IT Infrastructure** - Has source mapping (LAPI01-LAPI09)\n9. **SRE Architecture** - Largest template (1636 lines), two-tier scoring\n\n**Reason**: Most complex, benefit from learnings from earlier migrations.\n\n---\n\n## Template-Specific Notes\n\n### SRE Architecture (TEMPLATE_SRE_ARCHITECTURE.md)\n\n**Unique Characteristics**:\n- Two-tier scoring (Blocker vs Desired)\n- 57 requirements (largest)\n- Lines 1569-1632: Custom appendix format\n\n**Migration Strategy**:\n- Replace standard sections as usual\n- Keep two-tier scoring logic (domain-specific)\n- May need custom variables in config for \"Blocker\" vs \"Desired\" distinction\n\n### Development Architecture (TEMPLATE_DEVELOPMENT_ARCHITECTURE.md)\n\n**Unique Characteristics**:\n- Stack Validation Checklist integration (LADES1.6)\n- External validation file reference\n- Special \"Unknown\" status restriction for LADES1.6\n\n**Migration Strategy**:\n- Replace standard sections\n- Keep Stack Validation Checklist content (domain-specific)\n- Add note in config about checklist requirement\n\n### Data & AI Architecture (TEMPLATE_DATA_AI_ARCHITECTURE.md)\n\n**Unique Characteristics**:\n- Dual prefix: LAD (Data) and LAIA (AI)\n- 11 distinct requirements\n\n**Migration Strategy**:\n- Use `compliance_prefix: \"LAD / LAIA\"` in config\n- May need special handling if prefixes used separately in validation\n\n### Integration Architecture (TEMPLATE_INTEGRATION_ARCHITECTURE.md)\n\n**Unique Characteristics**:\n- Has A.1-A.4 already\n- Uses different weighting (30% / 60% / 10%)\n- Has validation config reference\n\n**Migration Strategy**:\n- Already has A.1-A.4 structure\n- Replace A.2 with shared version (but note weighting difference)\n- May need custom validation-methodology for this domain\n\n---\n\n## Troubleshooting\n\n### Issue: Variable Not Defined\n\n**Symptom**: Missing value in config causes `{{variable}}` to appear in output\n\n**Solution**:\n1. Check `shared/config/<domain>.json` has all required variables\n2. Verify variable name spelling matches shared file\n3. Add missing variable to config\n\n### Issue: Wrong Review Board Name\n\n**Symptom**: Template shows wrong review board (e.g., \"Business Continuity Review Board\" in Cloud template)\n\n**Solution**:\n1. Check config file has correct `review_board` value\n2. Verify using correct domain name in `config=<domain-name>` directive\n3. Ensure no typos in config filename\n\n### Issue: Template Longer After Refactoring\n\n**Symptom**: Template has MORE lines after migration\n\n**Solution**:\n1. Check that old sections were fully replaced (not added to)\n2. Verify include directives replaced content, didn't just add to it\n3. Look for duplicate sections\n\n### Issue: Different Output Format\n\n**Symptom**: Generated contract looks different from original\n\n**Solution**:\n1. Compare shared file content with original template section\n2. Check for whitespace differences (tabs vs spaces)\n3. Verify all variables replaced correctly\n4. Ensure no extra line breaks or formatting changes\n\n---\n\n## Validation Checklist\n\nBefore considering migration complete:\n\n- [ ] Domain config created with all required variables\n- [ ] Original template backed up (.backup file)\n- [ ] 5 common sections replaced with include directives\n- [ ] Domain-specific content preserved (A.1 terms, A.3 guide, A.4 history)\n- [ ] Line count reduced (60-90 lines expected)\n- [ ] Manual verification shows identical expanded content\n- [ ] A.4 Change History updated with migration notes\n- [ ] Changes committed to version control\n\n---\n\n## Post-Migration\n\nAfter all 9 templates are migrated:\n\n### Update Statistics\n\nUpdate `shared/README.md` with final numbers:\n\n```markdown\n| Templates refactored | 10 (100%) |\n| Total lines saved | XXX lines |\n| Average savings per template | XX lines |\n```\n\n### Implement Include Processing\n\nOnce all templates use includes:\n1. Implement actual include resolution in skill code\n2. Test generation for all 10 contract types\n3. Verify output matches original contracts\n4. Update SKILL.md if processing changes\n\n### Document Lessons Learned\n\nCreate a retrospective document:\n- What worked well\n- Challenges encountered\n- Recommendations for future refactoring\n- Performance impact\n\n---\n\n## Timeline Estimate\n\n**Per Template**:\n- Config creation: 10 minutes\n- Backup & identify sections: 10 minutes\n- Apply replacements: 15 minutes\n- Verification: 15 minutes\n- Documentation & commit: 10 minutes\n\n**Total per template**: ~1 hour\n\n**All 9 templates**: ~9 hours (spread over 2-3 weeks)\n\n---\n\n## Support\n\nQuestions or issues during migration:\n\n1. Review `shared/README.md` for shared content documentation\n2. Compare with Business Continuity template (completed example)\n3. Check this migration guide for template-specific notes\n4. Test with manual expansion before committing\n\n---\n\n**Last Updated**: 2025-12-11\n**Version**: 1.0\n**Status**: Ready for use\n**Reference Template**: Business Continuity (87 lines saved)\n",
        "skills/architecture-compliance/shared/README.md": "# Shared Compliance Template Content\n\n## Purpose\n\nThis directory contains reusable sections and fragments used across all 10 compliance templates to eliminate duplication and ensure consistency.\n\n**Benefits**:\n- **Reduces duplication**: Eliminates ~1,150-1,400 lines across all 10 templates\n- **Centralizes maintenance**: Update once, apply to all templates\n- **Ensures consistency**: Guaranteed identical scoring logic, status codes, and data sections\n- **Simplifies updates**: Single point of change for common sections\n\n---\n\n## Directory Structure\n\n```\nshared/\n‚îú‚îÄ‚îÄ sections/                                   # Complete reusable sections\n‚îÇ   ‚îú‚îÄ‚îÄ document-control.md                     # Document Control table structure\n‚îÇ   ‚îú‚îÄ‚îÄ dynamic-field-instructions.md           # Dynamic field mappings\n‚îÇ   ‚îú‚îÄ‚îÄ validation-methodology.md               # Appendix A.2 content\n‚îÇ   ‚îú‚îÄ‚îÄ completion-guide-intro.md               # Appendix A.3 intro text\n‚îÇ   ‚îú‚îÄ‚îÄ generation-metadata.md                  # Generation Metadata section\n‚îÇ   ‚îú‚îÄ‚îÄ change-history-template.md              # Appendix A.4 Change History\n‚îÇ   ‚îú‚îÄ‚îÄ data-extracted-template.md              # Data Extracted Successfully section\n‚îÇ   ‚îú‚îÄ‚îÄ missing-data-table-template.md          # Missing Data Requiring Attention table\n‚îÇ   ‚îú‚îÄ‚îÄ not-applicable-template.md              # Not Applicable Items section\n‚îÇ   ‚îî‚îÄ‚îÄ unknown-status-table-template.md        # Unknown Status Items table\n‚îÇ\n‚îú‚îÄ‚îÄ fragments/                                  # Smaller reusable fragments\n‚îÇ   ‚îú‚îÄ‚îÄ status-codes.md                         # 4 status definitions\n‚îÇ   ‚îú‚îÄ‚îÄ compliance-score-calculation.md         # N/A scoring rules\n‚îÇ   ‚îî‚îÄ‚îÄ compliance-summary-footer.md            # Overall Compliance + Completeness display\n‚îÇ\n‚îú‚îÄ‚îÄ config/                                     # Domain-specific configuration\n‚îÇ   ‚îú‚îÄ‚îÄ business-continuity.json                # Business Continuity config\n‚îÇ   ‚îú‚îÄ‚îÄ cloud-architecture.json                 # Cloud Architecture config\n‚îÇ   ‚îú‚îÄ‚îÄ data-ai-architecture.json               # Data & AI Architecture config\n‚îÇ   ‚îú‚îÄ‚îÄ development-architecture.json           # Development Architecture config\n‚îÇ   ‚îú‚îÄ‚îÄ enterprise-architecture.json            # Enterprise Architecture config\n‚îÇ   ‚îú‚îÄ‚îÄ integration-architecture.json           # Integration Architecture config\n‚îÇ   ‚îú‚îÄ‚îÄ platform-it-infrastructure.json         # Platform IT Infrastructure config\n‚îÇ   ‚îú‚îÄ‚îÄ process-transformation.json             # Process Transformation config\n‚îÇ   ‚îú‚îÄ‚îÄ security-architecture.json              # Security Architecture config\n‚îÇ   ‚îî‚îÄ‚îÄ sre-architecture.json                   # SRE Architecture config\n‚îÇ\n‚îî‚îÄ‚îÄ README.md                                   # This file\n```\n\n---\n\n## Include Syntax\n\n### Simple Include (100% Identical Content)\n\nFor content that is identical across all templates:\n\n```markdown\n<!-- @include shared/fragments/status-codes.md -->\n```\n\n**Use for**:\n- Status Codes definitions\n- Compliance Score Calculation rules\n- Any content that is 100% identical\n\n### Include with Config (Parameterized Content)\n\nFor content that has the same structure but domain-specific values:\n\n```markdown\n<!-- @include-with-config shared/sections/document-control.md config=business-continuity -->\n```\n\n**Use for**:\n- Document Control (validation config path varies)\n- Dynamic Field Instructions (review board names vary)\n- Validation Methodology (domain names vary)\n\n---\n\n## Exceptions to Shared Includes\n\nWhile most sections use shared includes, some templates have domain-specific requirements that necessitate inline content:\n\n### Appendix A.2 - Validation Methodology Exceptions\n\n**TEMPLATE_DEVELOPMENT_ARCHITECTURE.md**:\n- Uses inline A.2 validation methodology\n- **Reason**: LADES1.6 (Stack Validation Checklist) is a blocking requirement\n- **Unique Logic**: Contract cannot be approved if LADES1.6 status is \"Unknown\"\n- **Impact**: Requires custom compliance scoring formula\n\n**TEMPLATE_INTEGRATION_ARCHITECTURE.md**:\n- Uses inline A.2 validation methodology\n- **Reason**: Custom weight distribution (30% Completeness, 60% Compliance, 10% Quality)\n- **Standard Weights**: 40% Completeness, 50% Compliance, 10% Quality\n- **Impact**: References external JSON validation file\n\nThese exceptions are intentional and should be maintained as inline content.\n\n---\n\n## Template Variables\n\nShared files can use template variables that get replaced with domain-specific values from config files.\n\n### Variable Syntax\n\nIn shared files, use double-curly-brace syntax:\n\n```markdown\n**Approval Authority**: {{approval_authority}}\n**Review Board**: {{review_board}}\n**Compliance Code**: {{compliance_prefix}}\n**Domain Name**: {{domain_name}}\n```\n\n### Variable Resolution\n\nVariables are replaced during include processing using values from `shared/config/<domain>.json`.\n\n**Example**: For `config=business-continuity`, variables are loaded from `shared/config/business-continuity.json`:\n\n```json\n{\n  \"domain_name\": \"Business Continuity\",\n  \"compliance_prefix\": \"LABC\",\n  \"review_board\": \"Business Continuity Review Board\",\n  \"approval_authority\": \"Business Continuity Review Board\",\n  \"validation_config_path\": \"/skills/architecture-compliance/validation/business_continuity_validation.json\"\n}\n```\n\n---\n\n## How Includes Are Processed\n\nDuring template loading (Phase 4, Step 4.1 of compliance generation):\n\n1. **Read template file** (e.g., `TEMPLATE_BUSINESS_CONTINUITY.md`)\n2. **Detect include directives** using regex: `<!-- @include(-with-config)?\\s+(.+?)\\s*(?:config=(\\S+))?\\s*-->`\n3. **For each directive**:\n   - Parse type (simple or with-config)\n   - Resolve file path (relative to `/skills/architecture-compliance/`)\n   - Read shared file content\n   - If with-config:\n     - Load domain config from `shared/config/<domain>.json`\n     - Replace `{{variables}}` in shared content with config values\n   - Replace directive with processed content\n4. **Support nested includes** (max 3 levels deep)\n5. **Return fully expanded template** for placeholder replacement\n\n---\n\n## Adding New Shared Content\n\n### Step 1: Identify Duplication\n\nFind content duplicated across multiple templates (90%+ identical).\n\n**Examples**:\n- Identical tables or lists\n- Same formulas or calculations\n- Consistent structure with only variable names changing\n\n### Step 2: Extract to Appropriate Subdirectory\n\nChoose the right location:\n\n- **`sections/`**: Complete standalone sections (10+ lines)\n  - Example: Document Control, Validation Methodology\n\n- **`fragments/`**: Smaller reusable pieces (2-10 lines)\n  - Example: Status Codes, Compliance Score Calculation\n\n### Step 3: Replace Domain-Specific Values with {{variables}}\n\nIdentify values that vary by domain and replace with variables:\n\n```markdown\n# Before (domain-specific)\n**Review Board**: Business Continuity Review Board\n\n# After (parameterized)\n**Review Board**: {{review_board}}\n```\n\n### Step 4: Create/Update Domain Configs\n\nAdd variable mappings to `shared/config/<domain>.json`:\n\n```json\n{\n  \"review_board\": \"Business Continuity Review Board\"\n}\n```\n\n### Step 5: Replace Original Content with Include Directive\n\nIn the template, replace the extracted content:\n\n```markdown\n# Before\n**Status Codes**:\n- **Compliant**: Requirement fully satisfied with documented evidence\n- **Non-Compliant**: Requirement not met or missing from ARCHITECTURE.md\n- **Not Applicable**: Requirement does not apply to this solution\n- **Unknown**: Partial information exists but insufficient to determine compliance\n\n# After\n<!-- @include shared/fragments/status-codes.md -->\n```\n\n### Step 6: Test Generation\n\nGenerate a compliance contract to verify:\n- Include is resolved correctly\n- Variables are replaced with correct values\n- Output is identical to original template\n\n---\n\n## Variable Naming Conventions\n\n### Required Variables\n\nThese variables should be in all domain configs:\n\n- `domain_name`: Full name of the compliance domain (e.g., \"Business Continuity\")\n- `compliance_prefix`: Code prefix for requirements (e.g., \"LABC\", \"LAC\", \"LASRE\")\n- `review_board`: Name of the review board (e.g., \"Business Continuity Review Board\")\n- `approval_authority`: Authority that approves contracts (usually same as review_board)\n- `validation_config_path`: Path to validation JSON (e.g., `/skills/architecture-compliance/validation/business_continuity_validation.json`)\n- `primary_source_sections`: ARCHITECTURE.md sections where data is sourced (e.g., \"10 (Non-Functional Requirements), 11 (Operational Considerations)\")\n- `framework_description`: Brief description of framework requirements (e.g., \"RTO/RPO, backup, DR, and high availability\")\n- `compliance_framework_code`: Full compliance code with domain name (e.g., \"LABC (Business Continuity)\")\n- `v2_domain_features`: Detailed list of Version 2.0 domain-specific features (can be empty string)\n- `v2_data_point_count`: Number of validation data points in Version 2.0 (e.g., \"10\")\n\n### Optional Variables\n\nAdd domain-specific variables as needed:\n\n- `domain_terms`: Dictionary of domain-specific terminology\n- `abbreviations`: Dictionary of domain-specific abbreviations\n- Custom variables for specific use cases\n\n### Naming Style\n\n- Use `snake_case` for variable names\n- Be descriptive but concise\n- Use full words, avoid abbreviations in variable names\n\n---\n\n## Troubleshooting\n\n### Variables Not Being Replaced\n\n**Symptom**: Output shows `{{variable_name}}` instead of value\n\n**Causes**:\n1. Variable not defined in domain config\n2. Using simple `@include` instead of `@include-with-config`\n3. Typo in variable name\n\n**Solution**:\n- Add variable to `shared/config/<domain>.json`\n- Change to `@include-with-config`\n- Check variable name spelling matches config\n\n### Include File Not Found\n\n**Symptom**: Error during template loading or include not resolved\n\n**Causes**:\n1. Incorrect file path in include directive\n2. File doesn't exist in shared directory\n3. Typo in filename\n\n**Solution**:\n- Verify file path is relative to `/skills/architecture-compliance/`\n- Check file exists: `ls shared/sections/` or `ls shared/fragments/`\n- Correct typo in directive\n\n### Circular Include Detected\n\n**Symptom**: Infinite loop or recursion error\n\n**Cause**: File A includes File B, which includes File A\n\n**Solution**:\n- Restructure includes to remove circular dependency\n- Max 3 levels of nesting enforced to prevent deep recursion\n\n### Output Different from Original Template\n\n**Symptom**: Generated contract doesn't match original template output\n\n**Causes**:\n1. Shared content doesn't match original\n2. Variable replacement not working correctly\n3. Extra whitespace or formatting differences\n\n**Solution**:\n- Compare shared file with original template section\n- Verify all variables are being replaced\n- Check for whitespace differences (tabs vs spaces)\n\n---\n\n## Migration Guide for New Templates\n\nAll 10 current templates have been refactored to use shared content. For future new compliance domains:\n\n### Step 1: Create Domain Config\n\nCreate `shared/config/<domain-name>.json` with all required variables:\n\n```json\n{\n  \"domain_name\": \"New Domain Name\",\n  \"compliance_prefix\": \"LANEW\",\n  \"review_board\": \"New Domain Review Board\",\n  \"approval_authority\": \"New Domain Review Board\",\n  \"validation_config_path\": \"/skills/architecture-compliance/validation/new_domain_validation.json\",\n  \"primary_source_sections\": \"Relevant ARCHITECTURE.md section numbers\",\n  \"framework_description\": \"Brief description of requirements\",\n  \"compliance_framework_code\": \"LANEW (New Domain)\",\n  \"v2_domain_features\": \"List of domain-specific features or empty string\",\n  \"v2_data_point_count\": \"Number of data points\"\n}\n```\n\n### Step 2: Create Template with Includes\n\nUse the standard include directives pattern found in existing templates:\n\n**Document Control Section**:\n```markdown\n<!-- @include-with-config shared/sections/document-control.md config=<domain-name> -->\n```\n\n**Dynamic Field Instructions**:\n```markdown\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=<domain-name> -->\n```\n\n**Compliance Score Calculation**:\n```markdown\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n```\n\n**Appendix A.1 Status Codes**:\n```markdown\n<!-- @include shared/fragments/status-codes.md -->\n```\n\n**Appendix A.2 Validation Methodology**:\n```markdown\n<!-- @include-with-config shared/sections/validation-methodology.md config=<domain-name> -->\n```\n\n**Appendix A.3 Intro**:\n```markdown\n<!-- @include shared/sections/completion-guide-intro.md -->\n```\n\n**Post-Appendix Sections** (in order):\n```markdown\n<!-- @include-with-config shared/sections/data-extracted-template.md config=<domain-name> -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=<domain-name> -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=<domain-name> -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=<domain-name> -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=<domain-name> -->\n```\n\n### Step 3: Test Template Expansion\n\n```bash\nbun utils/resolve-includes.ts templates/TEMPLATE_<NAME>.md /tmp/test.md\n```\n\nVerify:\n- All includes resolve correctly\n- Variables are replaced with config values\n- Output structure is correct\n\n### Step 4: Verify Line Counts\n\n```bash\nwc -l templates/TEMPLATE_<NAME>.md\n```\n\nExpected template size: 300-1,700 lines (depending on domain complexity)\nExpected line expansion: +80-130 lines when includes are resolved\n\n---\n\n## Maintenance\n\n### Updating Shared Content\n\nWhen updating shared files:\n\n1. **Test impact**: Generate contracts for all domains using the shared file\n2. **Verify consistency**: Ensure change is appropriate for all domains\n3. **Document change**: Update this README if behavior changes\n4. **Version control**: Commit with clear message explaining change\n\n### Adding New Domains\n\nWhen adding new compliance domains:\n\n1. Create `shared/config/<new-domain>.json`\n2. Define all required variables\n3. Create template using include directives\n4. Test generation thoroughly\n5. Document any domain-specific variations\n\n---\n\n## Statistics\n\n**Current Status** (as of December 2025):\n\n| Metric | Value |\n|--------|-------|\n| Shared sections | 10 (document-control, dynamic-field-instructions, validation-methodology, completion-guide-intro, generation-metadata, change-history-template, data-extracted-template, missing-data-table-template, not-applicable-template, unknown-status-table-template) |\n| Shared fragments | 3 (status-codes, compliance-score-calculation, compliance-summary-footer) |\n| Domain configs | 10 (all domains) |\n| Templates refactored | 10 (all templates) |\n| Templates remaining | 0 |\n| Lines saved | ~1,340 lines across all 10 templates |\n| Refactoring phases | 3 (Quick Wins + Table Templates + Compliance Summary) |\n| Appendix standardization | COMPLETE - All templates have A.1-A.4 structure |\n\n**Template-Specific Savings**:\n\n| Template | Original Lines | Refactored Lines | Savings |\n|----------|---------------|------------------|---------|\n| Business Continuity | ~294 (expanded) | 164 | ~130 |\n| Security Architecture | ~784 (expanded) | 647 | ~137 |\n| SRE Architecture | ~1,736 (expanded) | 1,605 | ~131 |\n| Process Transformation | ~628 (expanded) | 491 | ~137 |\n| Platform IT Infrastructure | ~717 (expanded) | 580 | ~137 |\n| Development Architecture | ~623 (expanded) | 524 | ~99 |\n| Integration Architecture | ~655 (expanded) | 550 | ~105 |\n| Cloud Architecture | ~509 (expanded) | 372 | ~137 |\n| Data & AI Architecture | ~1,293 (expanded) | 1,156 | ~137 |\n| Enterprise Architecture | ~861 (expanded) | 724 | ~137 |\n\n**Total Estimated Savings**: ~1,287 lines eliminated through shared content extraction\n\n---\n\n## Support\n\nFor questions or issues with shared content:\n\n1. Check this README first\n2. Review existing shared files for examples\n3. Test include processing with simple examples\n4. Consult SKILL.md for include resolution algorithm\n\n---\n\n**Last Updated**: 2025-12-11\n**Version**: 2.0 (All templates refactored with Appendix extraction)\n**Author**: Architecture Compliance Skill\n",
        "skills/architecture-compliance/shared/fragments/compliance-score-calculation.md": "**CRITICAL - Compliance Score Calculation**:\nWhen calculating the Compliance Score in validation_results, N/A items MUST be included in the numerator:\n- Compliance Score = (PASS items + N/A items + EXCEPTION items) / (Total items) √ó 10\n- N/A items count as fully compliant (10 points each)\n- Example: 6 PASS, 5 N/A, 0 FAIL, 0 UNKNOWN ‚Üí (6+5)/11 √ó 10 = 10.0/10 (100%)\n- Add note in contract output: \"Note: N/A items counted as fully compliant (included in compliance score)\"\n",
        "skills/architecture-compliance/shared/fragments/compliance-summary-footer.md": "**Overall Compliance**:\n- ‚úÖ Compliant: [X]/N ([X/N*100]%)\n- ‚ùå Non-Compliant: [Y]/N ([Y/N*100]%)\n- ‚äò Not Applicable: [Z]/N ([Z/N*100]%)\n- ‚ùì Unknown: [W]/N ([W/N*100]%)\n\n**Completeness**: [COMPLETENESS_PERCENTAGE]% ([COMPLETED_ITEMS]/[TOTAL_ITEMS] data points documented)\n",
        "skills/architecture-compliance/shared/fragments/status-codes.md": "**Status Codes**:\n- **Compliant**: Requirement fully satisfied with documented evidence\n- **Non-Compliant**: Requirement not met or missing from ARCHITECTURE.md\n- **Not Applicable**: Requirement does not apply to this solution\n- **Unknown**: Partial information exists but insufficient to determine compliance\n",
        "skills/architecture-compliance/shared/sections/change-history-template.md": "### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with Cloud Architecture template structure\n{{v2_domain_features}}\n- Total: {{v2_data_point_count}}+ validation data points\n\n**Version 1.0 (Previous)**:\n- Initial template with minimal appendix\n- Basic PLACEHOLDER approach\n- Limited source traceability\n",
        "skills/architecture-compliance/shared/sections/completion-guide-intro.md": "**For Architecture Teams**:\n\nIf this contract shows \"Non-Compliant\" or \"Unknown\" items, use the **architecture-docs skill** to efficiently remediate gaps.\n\n**Quick Remediation Steps**:\n\n1. **Activate the skill**: `/skill architecture-docs`\n2. **Identify gaps**: Review gap table below (Section A.3.1)\n3. **Request remediation**: Ask skill to add missing content to specified sections\n4. **Regenerate contract**: Run compliance generation to verify improvements\n\n**Detailed workflow, common commands, and domain-specific examples in Section A.3.2 below.**\n",
        "skills/architecture-compliance/shared/sections/data-extracted-template.md": "## Data Extracted Successfully\n[List of all data points marked as \"Compliant\" with source references]\n\nExample format:\n- {{compliance_prefix}}1 - [Data Point]: [Value] (Source: ARCHITECTURE.md Section X, lines Y-Z)\n",
        "skills/architecture-compliance/shared/sections/document-control.md": "## Document Control\n\n<!-- CRITICAL: This table structure MUST be preserved exactly.\n     DO NOT convert this table to bold field lists like **Field**: Value.\n     Keep the | Field | Value | markdown table format.\n     Validation rule 'document_control_table' will BLOCK contracts that transform this table. -->\n\n| Field | Value |\n|-------|-------|\n| Document Owner | [SOLUTION_ARCHITECT or N/A] |\n| Last Review Date | [GENERATION_DATE] |\n| Next Review Date | [NEXT_REVIEW_DATE] |\n| Status | [DOCUMENT_STATUS] |\n| Validation Score | [VALIDATION_SCORE]/10 |\n| Validation Status | [VALIDATION_STATUS] |\n| Validation Date | [VALIDATION_DATE] |\n| Validation Evaluator | [VALIDATION_EVALUATOR] |\n| Review Actor | [REVIEW_ACTOR] |\n| Approval Authority | [APPROVAL_AUTHORITY] |\n\n**Validation Configuration**: `{{validation_config_path}}`\n",
        "skills/architecture-compliance/shared/sections/dynamic-field-instructions.md": "<!-- BEGIN_INTERNAL_INSTRUCTIONS -->\n<!--\n  INTERNAL: This section is for agent guidance only.\n  It MUST be removed from final contract output.\n-->\n\n**Dynamic Field Instructions for Document Generation**:\n\n- `[DOCUMENT_STATUS]`: Determined by validation_results.outcome.document_status\n  - Score 8.0-10.0 ‚Üí \"Approved\" (auto-approved)\n  - Score 7.0-7.9 ‚Üí \"In Review\" (ready for manual review)\n  - Score 5.0-6.9 ‚Üí \"Draft\" (needs work)\n  - Score 0.0-4.9 ‚Üí \"Rejected\" (blocked)\n\n- `[VALIDATION_SCORE]`: From validation_results.final_score (format: \"8.7/10\")\n\n- `[VALIDATION_STATUS]`: From validation_results.outcome.overall_status\n  - \"PASS\" (score ‚â• 7.0)\n  - \"CONDITIONAL\" (score 5.0-6.9)\n  - \"FAIL\" (score < 5.0)\n\n- `[VALIDATION_DATE]`: From validation_results.validation_date ‚Üí \"YYYY-MM-DD\" or \"Not performed\"\n\n- `[VALIDATION_EVALUATOR]`: \"Claude Code (Automated Validation Engine)\"\n\n- `[REVIEW_ACTOR]`: From validation_results.outcome.review_actor\n  - Score 8.0-10.0 ‚Üí \"System (Auto-Approved)\"\n  - Score 7.0-7.9 ‚Üí \"{{review_board}}\"\n  - Score 5.0-6.9 ‚Üí \"Architecture Team\"\n  - Score 0.0-4.9 ‚Üí \"N/A (Blocked)\"\n\n- `[APPROVAL_AUTHORITY]`: \"{{approval_authority}}\"\n\n**Validation Requirements**:\n- Validation score ‚â• 7.0 MANDATORY for approval pathway\n- Score 8.0-10.0: Automatic approval (no human review required)\n- Score 7.0-7.9: Manual review by {{review_board}} required\n- Score 5.0-6.9: Must address gaps before proceeding to review\n- Score < 5.0: Contract rejected, cannot proceed\n\n<!-- END_INTERNAL_INSTRUCTIONS -->\n",
        "skills/architecture-compliance/shared/sections/generation-metadata.md": "## Generation Metadata\n\n**Template Version**: 2.0 (Updated with compliance evaluation system)\n**Generation Date**: [GENERATION_DATE]\n**Source Document**: ARCHITECTURE.md\n**Primary Source Sections**: {{primary_source_sections}}\n**Completeness**: [PERCENTAGE]% ([X/TOTAL] data points documented)\n**Template Language**: English\n**Compliance Framework**: {{compliance_framework_code}} ({{domain_name}}) with requirements for {{framework_description}}\n**Status Labels**: Compliant, Non-Compliant, Not Applicable, Unknown\n",
        "skills/architecture-compliance/shared/sections/missing-data-table-template.md": "## Missing Data Requiring Attention\n\n| Requirement | Missing Data Point | Responsible Role | Recommended Action |\n|-------------|-------------------|------------------|-------------------|\n| {{compliance_prefix}}1 | [Example: Missing data point] | [Role] | [Action in Section X] |\n",
        "skills/architecture-compliance/shared/sections/not-applicable-template.md": "## Not Applicable Items\n[List of requirements marked as \"Not Applicable\" with justification]\n\nExample format:\n- {{compliance_prefix}}X - [Requirement]: [Justification per business requirements]\n",
        "skills/architecture-compliance/shared/sections/remediation-workflow-guide.md": "## How to Remediate Gaps Using Architecture-Docs Skill\n\nThe `architecture-docs` skill provides an efficient, guided workflow to remediate gaps identified in compliance contracts. This section provides step-by-step instructions for using the skill to achieve AUTO_APPROVE status (8.0+ validation score).\n\n---\n\n### Quick Start (For Simple Gaps)\n\nUse this workflow when you have 1-3 simple gaps to fix:\n\n1. **Activate the architecture-docs skill**:\n   ```\n   /skill architecture-docs\n   ```\n\n2. **Specify what you need**: \"Add [missing item] to Section [X]\"\n   - Example: \"Add cost monitoring configuration to Section 11\"\n   - Example: \"Add OAuth 2.0 authentication to Section 9\"\n\n3. **Review and confirm**: The skill will update the specified section with proper formatting and structure\n\n4. **Regenerate contract**: Run compliance generation to verify the gap is resolved\n\n**When to use**: You have fewer than 3 gaps, all in known sections, with clear remediation actions.\n\n---\n\n### Standard Workflow (Most Common)\n\nUse this workflow for typical compliance remediation with 3-10 gaps:\n\n1. **Review compliance contract** to identify all UNKNOWN and FAIL items\n   - Check Section A.3.1 \"Common Gaps Quick Reference\" table\n   - Note the ARCHITECTURE.md section numbers for each gap\n   - Identify impact levels (BLOCKER, High, Medium)\n\n2. **Prioritize by impact**: Work on highest-impact gaps first\n   - **BLOCKER** (0.5-0.8 pts): Critical compliance failures\n   - **High** (0.3-0.5 pts): Major missing documentation\n   - **Medium** (0.1-0.2 pts): Optional or minor improvements\n\n3. **Activate skill**:\n   ```\n   /skill architecture-docs\n   ```\n\n4. **Work section-by-section**: Address gaps one section at a time\n   - Request: \"Review Section [X] for completeness. Gaps: [list gaps from compliance contract]\"\n   - Example: \"Review Section 9 for completeness. Gaps: missing mTLS config, no API authentication documented, certificate management not specified\"\n\n5. **Let skill guide you**: Follow the two-phase validation workflow\n   - **Phase 1**: Structure validation (sections present, proper formatting)\n   - **Phase 2**: Content improvements (completeness, quality, traceability)\n\n6. **Regenerate contract** to verify score improvement\n   - Run compliance generation again\n   - Check that UNKNOWN/FAIL items are now PASS\n   - Verify validation score increased\n\n**When to use**: Most compliance remediation scenarios with multiple gaps across different sections.\n\n---\n\n### Advanced Workflow (Multiple Gaps or Full Review)\n\nUse this workflow when you have 10+ gaps or want comprehensive validation:\n\n1. **Request full compliance review**:\n   ```\n   /skill architecture-docs\n   ```\n   Then ask: \"Review ARCHITECTURE.md for [Contract Type] compliance\"\n   - Example: \"Review ARCHITECTURE.md for Cloud Architecture compliance\"\n   - Example: \"Review ARCHITECTURE.md for Security Architecture compliance\"\n\n2. **Use two-phase validation workflow**: Let the skill systematically validate structure and content\n   - **Phase 1** (Structure): Ensures all required sections exist with proper formatting\n   - **Phase 2** (Content): Validates completeness, quality, and compliance requirements\n\n3. **Iterate through violations**: Address each category systematically\n   - Start with BLOCKER violations (critical compliance failures)\n   - Move to UNKNOWN items (missing data)\n   - Address FAIL items (non-compliant technologies)\n   - Finally improve quality (source traceability)\n\n4. **Verify after each major change**:\n   - Request section-specific validation: \"Validate Section [X] completeness\"\n   - Check metric consistency: \"Verify metrics in Section [X] match Section 1 design drivers\"\n\n5. **Final verification**: Regenerate compliance contract and compare scores\n\n**When to use**: Comprehensive architecture review, major compliance gaps (10+ items), or preparing for formal approval.\n\n---\n\n### Skill Capabilities\n\nThe `architecture-docs` skill can help with:\n\n- ‚úÖ **Add missing sections**: Uses standard ARCHITECTURE.md templates for each section\n- ‚úÖ **Calculate design drivers**: Derives quantitative metrics from Business Context (Section 1)\n- ‚úÖ **Validate architecture principles**: Ensures all 9 principles documented with trade-offs (Section 3)\n- ‚úÖ **Check metric consistency**: Validates that performance/scalability/availability targets align across sections\n- ‚úÖ **Generate ADRs**: Creates Architecture Decision Records for technology choices (Section 12)\n- ‚úÖ **Add source traceability**: Includes section and line number references for compliance audit trails\n- ‚úÖ **Load sections incrementally**: Context-efficient approach that loads only needed sections\n- ‚úÖ **Domain-specific guidance**: Understands Cloud, Security, SRE, Integration, and other architecture domains\n\n---\n\n### Common Commands\n\n| Task | Command Example |\n|------|-----------------|\n| **Add missing section** | \"Add Section [X] using standard template\" |\n| **Review section completeness** | \"Review Section [X] for completeness\" |\n| **Fix metric consistency** | \"Ensure metrics in Section [X] match Section 1 values\" |\n| **Add architecture principle** | \"Add [Principle Name] to Section 3 with trade-offs\" |\n| **Create ADR** | \"Create ADR for [decision] in Section 12\" |\n| **Add security control** | \"Add [control] to Section 9 ‚Üí [subsection]\" |\n| **Add cloud configuration** | \"Add [config] to Section 4 with [provider]-specific details\" |\n| **Add monitoring setup** | \"Add [monitoring tool/config] to Section 11\" |\n| **Full validation** | \"Validate ARCHITECTURE.md against [domain] architecture standards\" |\n\n---\n\n### Remediation Tips\n\n1. **Start with structure, then content**: Ensure all required sections exist before filling in details\n\n2. **Be specific in requests**:\n   - ‚ùå Vague: \"Add encryption\"\n   - ‚úÖ Specific: \"Add TLS 1.3 encryption to Section 9 ‚Üí Network Security with cipher suite recommendations\"\n\n3. **Provide context**:\n   - ‚ùå Generic: \"Add monitoring\"\n   - ‚úÖ Contextual: \"Add Azure Monitor configuration to Section 11 with Application Insights and Log Analytics workspace\"\n\n4. **Iterate section-by-section**: Don't try to fix everything at once\n   - Fix Section 9 (Security) completely\n   - Regenerate contract to verify\n   - Move to Section 11 (Observability)\n   - Regenerate again\n\n5. **Verify after each change**: Run compliance generation frequently to ensure progress\n   - Check validation score improvement\n   - Verify UNKNOWN ‚Üí PASS conversions\n   - Ensure no new issues introduced\n\n6. **Use domain-specific language**: Reference the architecture domain in your requests\n   - \"Add AWS Well-Architected Framework mapping\" (Cloud Architecture)\n   - \"Add SLO definitions with error budgets\" (SRE Architecture)\n   - \"Add OAuth 2.0 flows\" (Security Architecture)\n   - \"Add API catalog\" (Integration Architecture)\n\n7. **Reference the gap table**: Use exact gap descriptions from Section A.3.1\n   - Copy the \"Gap Description\" from compliance contract\n   - Include the section number from \"ARCHITECTURE.md Section\" column\n   - Follow the \"Recommended Action\" guidance\n\n8. **Check source traceability**: Ensure all added content includes section and line references\n   - Quality score depends on source traceability coverage\n   - Ask skill to \"ensure all items have source references\"\n\n---\n\n### Example Interaction\n\n**Scenario**: Cloud Architecture contract shows score 6.8/10 with 5 UNKNOWN items\n\n**Step 1: Activate skill**\n```\n/skill architecture-docs\n```\n\n**Step 2: Request section review**\n```\nReview Section 11 for completeness. Gaps from compliance contract:\n- Missing cost monitoring configuration\n- No resource tagging strategy documented\n- Rightsizing review schedule not defined\n```\n\n**Step 3: Follow skill guidance**\n- Skill validates Section 11 structure\n- Skill identifies missing subsections\n- Skill suggests specific additions with examples\n\n**Step 4: Confirm additions**\n```\nYes, add those subsections with the recommended content\n```\n\n**Step 5: Verify**\n- Regenerate compliance contract\n- Check validation score (should increase to 7.5-8.0+)\n- Verify UNKNOWN items now show PASS\n\n---\n\n### Troubleshooting\n\n**Q: Skill says section already exists but compliance contract shows gap**\n- **A**: Section may exist but lack required details. Ask: \"Review Section [X] for [specific gap] completeness\"\n\n**Q: Added content but score didn't improve**\n- **A**: Check source traceability. Ask: \"Add source references (section and line numbers) to all items in Section [X]\"\n\n**Q: Multiple FAIL items for deprecated technologies**\n- **A**: Create ADR for exception or upgrade path: \"Create ADR in Section 12 for [technology] with migration plan\"\n\n**Q: Score improved but still below 8.0**\n- **A**: Review Section A.3.3 \"Achieving Auto-Approve Status\" for prioritized next steps\n\n**Q: Compliance contract regeneration shows same score**\n- **A**: Verify ARCHITECTURE.md was actually updated (check file modification timestamp). Re-run skill commands if needed.\n\n---\n\n### Next Steps After Remediation\n\n1. **Regenerate all relevant compliance contracts**: Changes to ARCHITECTURE.md may affect multiple contract types\n\n2. **Review validation scores**: Aim for 8.0+ for automatic approval\n\n3. **Submit for review**: Contracts with scores 7.0-7.9 require manual review by approval authority\n\n4. **Track over time**: Keep ARCHITECTURE.md updated as architecture evolves to maintain compliance\n\n---\n\n**For domain-specific remediation examples, see Section A.3.2 examples below.**\n",
        "skills/architecture-compliance/shared/sections/unknown-status-table-template.md": "## Unknown Status Items Requiring Investigation\n\n| Requirement | Data Point | Issue | Responsible Role | Action Needed |\n|-------------|------------|-------|------------------|---------------|\n| {{compliance_prefix}}1 | [Example: Data point] | [Issue description] | [Role] | [Investigation needed in Section X] |\n",
        "skills/architecture-compliance/shared/sections/validation-methodology.md": "### A.2 Validation Methodology\n\n**Validation Process**:\n\n1. **Completeness Check ({{completeness_percent}} weight)**:\n   - Counts filled data points across all {{compliance_prefix}} requirements\n   - Formula: (Filled fields / Total required fields) √ó 10\n   - Example: 8 out of 10 fields = 8.0/10 completeness\n\n2. **Compliance Check ({{compliance_percent}} weight)**:\n   - Evaluates each validation item as PASS/FAIL/N/A/UNKNOWN\n   - Formula: (PASS + N/A + EXCEPTION items) / Total items √ó 10\n   - **CRITICAL**: N/A items MUST be included in numerator\n   - Example: 6 PASS + 2 N/A + 0 EXCEPTION out of 10 items = (6+2)/10 √ó 10 = 8.0/10\n\n3. **Quality Check ({{quality_percent}} weight)**:\n   - Assesses source traceability (ARCHITECTURE.md section references)\n   - Verifies explanation quality and actionable notes\n   - Formula: (Items with valid sources / Total items) √ó 10\n\n4. **Final Score Calculation**:\n   ```\n   Final Score = (Completeness √ó {{completeness}}) + (Compliance √ó {{compliance}}) + (Quality √ó {{quality}})\n   ```\n\n**Outcome Determination**:\n| Score Range | Document Status | Review Actor | Action |\n|-------------|----------------|--------------|--------|\n| 8.0-10.0 | Approved | System (Auto-Approved) | Ready for implementation |\n| 7.0-7.9 | In Review | {{review_board}} | Manual review required |\n| 5.0-6.9 | Draft | Architecture Team | Address gaps before review |\n| 0.0-4.9 | Rejected | N/A (Blocked) | Cannot proceed - critical {{domain_name}} gaps |\n",
        "skills/architecture-compliance/templates/TEMPLATE_BUSINESS_CONTINUITY.md": "# Compliance Contract: Business Continuity\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 1, 3, 4, 5, 7, 8, 10, 11)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=business-continuity -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=business-continuity -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LACN001 | Document the official name of the application, system, or business initiative covered by this Business Continuity plan | BC-GEN | [Status] | Section 1 (Business Context) or Section 2 (System Overview) | [Role or N/A] |\n| LACN002 | Specify the architectural pattern (e.g., monolithic, microservices, serverless) and deployment model (e.g., on-premises, cloud, hybrid) used by the system | BC-GEN | [Status] | Section 3 (Architecture Overview) or Section 4 (Deployment Architecture) | [Role or N/A] |\n| LACN003 | Define the number of logical or physical layers in the system architecture (e.g., presentation, business logic, data access, persistence) | BC-GEN | [Status] | Section 4 (Architecture Layers) or Section 3 (Architecture Overview) | [Role or N/A] |\n| LACN004 | Document the infrastructure type: physical servers, virtual machines, containers, serverless, or a combination thereof | BC-GEN | [Status] | Section 4 (Deployment Architecture) or Section 11 (Operational ‚Üí Infrastructure) | [Role or N/A] |\n| LACN005 | Identify all critical dependencies including internal systems, external services, third-party APIs, databases, and infrastructure components required for operation | BC-GEN | [Status] | Section 1 (Business Context ‚Üí Dependencies) or Section 5 (System Integrations) | [Role or N/A] |\n| LACN006 | Determine whether the solution requires high availability (HA) design patterns to minimize downtime and ensure continuous operation | BC-DR | [Status] | Section 10 (Non-Functional Requirements ‚Üí Availability) | [Role or N/A] |\n| LACN007 | If HA is required, identify which specific system components, services, or tiers must be designed for high availability | BC-DR | [Status] | Section 11 (Operational ‚Üí High Availability) | [Role or N/A] |\n| LACN008 | Determine if the solution requires local contingency measures (within same data center or availability zone) to handle component failures | BC-DR | [Status] | Section 11 (Operational ‚Üí High Availability) | [Role or N/A] |\n| LACN009 | Determine if the solution requires disaster recovery (DR) capabilities to recover from catastrophic site-wide or regional failures | BC-DR | [Status] | Section 11 (Operational ‚Üí Disaster Recovery) | [Role or N/A] |\n| LACN010 | Specify the DR architecture pattern: cold standby, warm standby, hot standby, or active-active multi-region | BC-DR | [Status] | Section 11 (Operational ‚Üí Disaster Recovery) | [Role or N/A] |\n| LACN011 | Specify the data replication method used for DR: synchronous, asynchronous, snapshot-based, or backup-restore | BC-DR | [Status] | Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Data Replication) | [Role or N/A] |\n| LACN012 | Establish a Recovery Time Objective (RTO) - the maximum acceptable time to restore service after a failure | BC-RTO | [Status] | Section 10 (Non-Functional Requirements) or Section 11 (Operational ‚Üí DR) | [Role or N/A] |\n| LACN013 | Determine if contingency and disaster recovery procedures must be regularly tested and validated | BC-DR | [Status] | Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Testing) | [Role or N/A] |\n| LACN014 | Verify that the application can continue operating gracefully when individual components or dependencies experience transient failures | BC-DR | [Status] | Section 11 (Operational ‚Üí Resilience) or Section 7 (Application Architecture ‚Üí Resilience Patterns) | [Role or N/A] |\n| LACN015 | Determine if the platform will execute batch processing jobs or scheduled workloads | BC-DR | [Status] | Section 7 (Application Architecture ‚Üí Batch Processing) or Section 11 (Operational) | [Role or N/A] |\n| LACN016 | Specify the type of batch execution: scheduled (time-based), event-triggered, manual, or on-demand | BC-DR | [Status] | Section 7 (Application Architecture ‚Üí Batch Processing) | [Role or N/A] |\n| LACN017 | Determine if failed batch jobs must support reprocessing or retry to avoid data inconsistencies | BC-DR | [Status] | Section 7 (Application Architecture ‚Üí Batch Processing ‚Üí Error Handling) | [Role or N/A] |\n| LACN018 | Determine if periodic backups of application data are required for recovery purposes | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore) | [Role or N/A] |\n| LACN019 | Specify the frequency of data backups: continuous, hourly, daily, weekly, or custom schedule based on RPO requirements | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Schedule) | [Role or N/A] |\n| LACN020 | Define how long backup copies must be retained before deletion: days, months, years, or permanent archival | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Retention) | [Role or N/A] |\n| LACN021 | Determine if backups should overwrite previous versions or maintain historical versions for point-in-time recovery | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Versioning) | [Role or N/A] |\n| LACN022 | Assess the difficulty and effort required to recreate lost data if backups are unavailable | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore) or Section 1 (Business Context) | [Role or N/A] |\n| LACN023 | Quantify the business impact if data is lost: revenue loss, operational disruption, regulatory penalties, reputation damage | BC-BACKUP | [Status] | Section 1 (Business Context ‚Üí Business Impact Analysis) | [Role or N/A] |\n| LACN024 | Confirm that the Recovery Point Objective (RPO) - maximum acceptable data loss - has been validated and approved by business stakeholders | BC-RTO | [Status] | Section 10 (Non-Functional Requirements) or Section 11 (Operational ‚Üí Backup & DR) | [Role or N/A] |\n| LACN025 | Determine if backups must be stored in a geographically separate location to protect against site-wide disasters | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Geographic Distribution) | [Role or N/A] |\n| LACN026 | Determine if infrastructure configurations, operating system settings, and system files require backup (often called BDI - Base de Infraestructura) | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Infrastructure) | [Role or N/A] |\n| LACN027 | Determine if audit logs of infrastructure changes must be backed up for compliance, troubleshooting, and forensic analysis | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Logging & Monitoring or Backup & Restore) | [Role or N/A] |\n| LACN028 | Verify that the complete application can be restored from backups if all components fail simultaneously (worst-case scenario) | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Testing) | [Role or N/A] |\n| LACN029 | Identify if the platform handles sensitive data such as customer PII, financial data, or other regulated information requiring enhanced backup protection | BC-BACKUP | [Status] | Section 8 (Security Architecture ‚Üí Data Classification) or Section 11 (Operational) | [Role or N/A] |\n| LACN030 | Define who is responsible for executing, monitoring, and validating backups: infrastructure team, DBA team, application team, or managed service provider | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Responsibilities) | [Role or N/A] |\n| LACN031 | Determine if backups stored in cloud or managed services can be downloaded to local or on-premises storage for additional protection | BC-BACKUP | [Status] | Section 11 (Operational ‚Üí Backup & Restore ‚Üí Hybrid Strategy) | [Role or N/A] |\n| LACN032 | Assess if disaster recovery activation can be automated rather than requiring manual procedures | BC-AUTO | [Status] | Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation) | [Role or N/A] |\n| LACN033 | Identify which specific components and procedures can be automated during disaster recovery activation | BC-AUTO | [Status] | Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation) | [Role or N/A] |\n| LACN034 | Determine if the application requires circuit breaker pattern to prevent cascading failures when downstream services are unavailable or slow | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Resilience Patterns) | [Role or N/A] |\n| LACN035 | Implement retry logic with exponential backoff to handle transient failures in distributed systems and third-party integrations | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Resilience Patterns) | [Role or N/A] |\n| LACN036 | Implement appropriate timeout values for calls to third-party and external services to prevent blocking and cascading slowness | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Resilience Patterns) or Section 5 (Integrations) | [Role or N/A] |\n| LACN037 | Define time-bound triggers for automated contingency or disaster recovery activation to limit blast radius and ensure timely response | BC-CLOUD | [Status] | Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation) | [Role or N/A] |\n| LACN038 | Implement fallback responses or degraded functionality when primary services or features are unavailable | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Resilience Patterns) | [Role or N/A] |\n| LACN039 | Implement bulkhead pattern to isolate failing components and prevent cascading failures across services | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Resilience Patterns) | [Role or N/A] |\n| LACN040 | Implement auto-scaling with health checks to automatically replace failed instances across multiple availability zones | BC-CLOUD | [Status] | Section 11 (Operational ‚Üí Auto-Scaling) or Section 4 (Deployment Architecture) | [Role or N/A] |\n| LACN041 | Implement load balancing to automatically distribute traffic across multiple instances and availability zones | BC-CLOUD | [Status] | Section 4 (Deployment Architecture ‚Üí Load Balancing) or Section 11 (Operational) | [Role or N/A] |\n| LACN042 | Implement queue-based load leveling to absorb traffic spikes and process workloads asynchronously without impacting service availability | BC-CLOUD | [Status] | Section 7 (Application Architecture ‚Üí Asynchronous Processing) | [Role or N/A] |\n| LACN043 | Identify all potential single points of failure in the architecture that could cause complete service outage if they fail | BC-CLOUD | [Status] | Section 3 (Architecture Overview) or Section 11 (Operational ‚Üí High Availability) | [Role or N/A] |\n\n---\n\n## Detailed Requirements\n\n#### LACN001: Application or Initiative Name {#LACN001}\n**Category**: BC-GEN\n**Status**: [Status]\n**Source Section**: Section 1 (Business Context) or Section 2 (System Overview)\n\n##### Implementation\nProvide the complete and official name of the application or business initiative. This should match the name used in enterprise architecture documentation, project charters, and business documentation. Include any acronyms or alternative names commonly used within the organization.\n\n##### Validation\n- [ ] Official application/initiative name is documented\n- [ ] Name matches enterprise architecture registry\n- [ ] Alternative names or acronyms are listed if applicable\n\n---\n\n#### LACN002: Architecture Type and Deployment Model {#LACN002}\n**Category**: BC-GEN\n**Status**: [Status]\n**Source Section**: Section 3 (Architecture Overview) or Section 4 (Deployment Architecture)\n\n##### Implementation\nDocument the high-level architecture pattern and deployment model. Architecture types may include: monolithic, N-tier, microservices, event-driven, serverless, or hybrid. Deployment models may include: on-premises, IaaS, PaaS, SaaS, hybrid cloud, or multi-cloud. This information is critical for disaster recovery planning as different architectures require different recovery strategies.\n\n##### Validation\n- [ ] Architecture pattern is clearly documented (e.g., microservices)\n- [ ] Deployment model is specified (e.g., AWS cloud, hybrid)\n- [ ] Rationale for architecture choice is provided if non-standard\n\n---\n\n#### LACN003: Number of Architecture Layers {#LACN003}\n**Category**: BC-GEN\n**Status**: [Status]\n**Source Section**: Section 4 (Architecture Layers) - Primary; Section 3 (Architecture Overview) - Fallback\n\n##### Implementation\nSpecify how many distinct layers or tiers comprise the architecture based on the architecture type:\n\n**Architecture Type**: [Detected type: META/BIAN/3-TIER/MICROSERVICES/NLAYER/UNKNOWN]\n\n**Number of Layers**: [Count]\n\n**Layer Names**: [Exact layer names from ARCHITECTURE.md Section 4]\n\n**Examples by Architecture Type**:\n- **META**: 6 layers - Channels, User Experience, Business Scenarios, Business, Domain, Core\n- **BIAN**: 5 layers - Channels, BIAN Business Scenarios, BIAN Business Capabilities, BIAN Service Domains, Core\n- **3-Tier**: 3 tiers - Presentation, Application/Business Logic, Data\n- **Microservices**: Variable count - [List service names or bounded contexts]\n- **N-Layer**: 4-7 layers - [Custom layer names from Section 4]\n- **UNKNOWN (fallback)**: Layers from Section 3 - [Generic layer count and names]\n\n**Source**: ARCHITECTURE.md Section 4 (Architecture Layers, lines [XXX-YYY])\n\nUnderstanding layer count helps determine dependencies and recovery sequence during disaster recovery scenarios.\n\n##### Validation\n- [ ] Number of layers is documented in Section 4 or Section 3\n- [ ] Architecture type is detected (or marked as UNKNOWN)\n- [ ] Each layer is named with exact names from ARCHITECTURE.md\n- [ ] Layer names match architecture type expectations (e.g., META has 6 specific layers)\n- [ ] Layer responsibilities are defined in source section\n- [ ] Layer dependencies are identified for DR sequencing\n- [ ] Source line numbers are tracked for traceability\n\n---\n\n#### LACN004: Infrastructure Type {#LACN004}\n**Category**: BC-GEN\n**Status**: [Status]\n**Source Section**: Section 4 (Deployment Architecture) or Section 11 (Operational ‚Üí Infrastructure)\n\n##### Implementation\nSpecify the infrastructure foundation supporting the application. Options include: bare-metal physical servers, virtual machines (VMware, Hyper-V), containerized workloads (Docker, Kubernetes), serverless functions (AWS Lambda, Azure Functions), or hybrid combinations. Infrastructure type significantly impacts backup strategies, failover mechanisms, and recovery time objectives.\n\n##### Validation\n- [ ] Infrastructure type is documented (physical, virtual, containers, serverless)\n- [ ] Infrastructure provider/platform is specified\n- [ ] Infrastructure-specific BC considerations are documented\n\n---\n\n#### LACN005: Critical System Dependencies {#LACN005}\n**Category**: BC-GEN\n**Status**: [Status]\n**Source Section**: Section 1 (Business Context ‚Üí Dependencies) or Section 5 (System Integrations)\n\n##### Implementation\nDocument all upstream and downstream dependencies that are critical for system operation. Include: internal services, external APIs, SaaS platforms, authentication providers, payment gateways, databases, message queues, and infrastructure services. For each dependency, note: service name, provider, criticality level, and impact if unavailable. This forms the foundation for dependency mapping in business continuity planning.\n\n##### Validation\n- [ ] All critical dependencies are identified and documented\n- [ ] Each dependency includes: name, provider, criticality, failure impact\n- [ ] Dependency diagram or architecture showing relationships is provided\n- [ ] Mitigation strategies for critical dependencies are documented\n\n---\n\n#### LACN006: High Availability Requirement {#LACN006}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 10 (Non-Functional Requirements ‚Üí Availability)\n\n##### Implementation\nAssess whether the system must be designed for high availability. HA systems typically target 99.9% (three nines) or higher uptime, requiring redundant components, automatic failover, and fault-tolerant architecture. Consider: business criticality, revenue impact of downtime, user expectations, and SLA commitments. If HA is required, specify the target availability percentage (e.g., 99.95% = ~22 minutes/month downtime).\n\n##### Validation\n- [ ] HA requirement is clearly stated (Yes/No)\n- [ ] If Yes: target availability percentage is specified\n- [ ] Business justification for HA requirement is documented\n- [ ] Downtime tolerance and business impact are assessed\n\n---\n\n#### LACN007: High Availability Component Scope {#LACN007}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí High Availability)\n\n##### Implementation\nNot all components may require HA design. Specify which components need redundancy and failover: web servers, application servers, databases, caches, message queues, load balancers, etc. For each HA component, document: deployment pattern (active-active, active-passive), redundancy level (N+1, N+2), geographic distribution (single AZ, multi-AZ, multi-region), and failover mechanism (automatic, manual).\n\n##### Validation\n- [ ] All HA components are explicitly listed\n- [ ] For each component: deployment pattern (active-active/passive) is specified\n- [ ] Redundancy level and geographic distribution are documented\n- [ ] Automatic vs manual failover approach is defined\n\n---\n\n#### LACN008: Local Contingency Requirement {#LACN008}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí High Availability)\n\n##### Implementation\nLocal contingency refers to failover capabilities within the same data center or availability zone. This addresses component-level failures (server crash, network issue, software bug) without requiring geographic failover. Local contingency typically involves: redundant servers in same location, load balancing, automatic health checks, and rapid component replacement. This is distinct from disaster recovery which handles site-wide failures.\n\n##### Validation\n- [ ] Local contingency requirement is clearly stated (Yes/No)\n- [ ] If Yes: local failover strategy is documented\n- [ ] Component redundancy within same location is specified\n- [ ] Health check and automatic failover mechanisms are defined\n\n---\n\n#### LACN009: Disaster Recovery Requirement {#LACN009}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery)\n\n##### Implementation\nDisaster Recovery addresses catastrophic failures affecting entire data centers, availability zones, or regions. DR capabilities include: secondary site/region with standby infrastructure, data replication to DR site, documented recovery procedures, and tested failover processes. DR is critical for mission-critical systems where even extended outages are unacceptable. Consider: business impact of prolonged outage, regulatory requirements, data sovereignty, and recovery cost vs. risk.\n\n##### Validation\n- [ ] DR requirement is clearly stated (Yes/No)\n- [ ] If Yes: disaster scenarios addressed are identified (regional outage, data center loss, etc.)\n- [ ] Business justification for DR investment is documented\n- [ ] RTO and RPO targets are defined\n\n---\n\n#### LACN010: Disaster Recovery Architecture Pattern {#LACN010}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery)\n\n##### Implementation\nDocument the DR architecture pattern based on RTO and cost considerations. Options include: (1) Cold standby: minimal infrastructure, manual activation, RTO hours-days; (2) Warm standby: infrastructure provisioned but not running, RTO minutes-hours; (3) Hot standby: infrastructure running with data replication, RTO seconds-minutes; (4) Active-Active: both sites serving traffic, immediate failover, RTO near-zero. Each pattern has different cost, complexity, and recovery time implications.\n\n##### Validation\n- [ ] DR pattern is clearly specified (cold/warm/hot/active-active)\n- [ ] Primary and DR site locations are documented\n- [ ] Justification for selected DR pattern based on RTO/cost is provided\n- [ ] Failover trigger criteria and procedures are documented\n\n---\n\n#### LACN011: Data Replication Method for DR {#LACN011}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Data Replication)\n\n##### Implementation\nDocument how data is replicated from primary to DR site. Replication methods include: (1) Synchronous: real-time replication, zero data loss (RPO=0), higher latency, requires low-latency network; (2) Asynchronous: near-real-time replication, minimal data loss (RPO minutes), lower latency impact, tolerates higher network latency; (3) Snapshot-based: periodic snapshots, RPO = snapshot frequency; (4) Backup-restore: tape/object storage backups, RPO = backup frequency. Choice depends on RPO requirements, network bandwidth, and acceptable performance impact.\n\n##### Validation\n- [ ] Replication method is specified (synchronous, asynchronous, snapshot, backup)\n- [ ] Replication frequency/lag is documented\n- [ ] RPO achieved by replication method is stated\n- [ ] Network bandwidth and performance impact are assessed\n\n---\n\n#### LACN012: Recovery Time Objective (RTO) Definition {#LACN012}\n**Category**: BC-RTO\n**Status**: [Status]\n**Source Section**: Section 10 (Non-Functional Requirements) or Section 11 (Operational ‚Üí DR)\n\n##### Implementation\nDefine the RTO which represents the maximum tolerable downtime before business impact becomes unacceptable. RTO drives DR architecture decisions: RTO < 1 hour typically requires hot standby or active-active; RTO 1-4 hours may use warm standby; RTO > 4 hours can use cold standby. RTO should be: (1) Business-driven, based on revenue loss and operational impact; (2) Realistic, considering technical constraints and cost; (3) Documented with stakeholder approval. Include RTO for different failure scenarios (component failure vs. site disaster).\n\n##### Validation\n- [ ] RTO value is clearly documented (e.g., 4 hours)\n- [ ] RTO is differentiated by failure type (local vs. disaster)\n- [ ] Business justification for RTO is provided\n- [ ] RTO is approved by business stakeholders\n\n---\n\n#### LACN013: Contingency and DR Testing Requirement {#LACN013}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Testing)\n\n##### Implementation\nDR testing is critical to validate that recovery procedures work and RTO/RPO can be achieved. Testing types include: (1) Tabletop exercises: walkthrough of procedures, no actual failover; (2) Partial failover: test specific components; (3) Full failover: complete production failover to DR site. Testing frequency depends on criticality: monthly tabletop exercises, quarterly partial tests, annual full DR drill. Document: test scenarios, success criteria, test schedule, roles/responsibilities, and post-test review process.\n\n##### Validation\n- [ ] DR testing requirement is clearly stated (Yes/No)\n- [ ] If Yes: testing frequency is specified (monthly, quarterly, annually)\n- [ ] Test types and scenarios are documented\n- [ ] Success criteria and validation procedures are defined\n- [ ] Post-test review and improvement process is established\n\n---\n\n#### LACN014: Resilience to Transient Component Failures {#LACN014}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Resilience) or Section 7 (Application Architecture ‚Üí Resilience Patterns)\n\n##### Implementation\nThe application should implement resilience patterns to handle transient failures of internal or external components. Resilience strategies include: circuit breakers (prevent cascading failures), retries with exponential backoff (handle temporary network issues), timeouts (prevent blocking), fallbacks (degraded functionality), and bulkheads (isolate failures). For each critical dependency, document: failure handling strategy, retry policy, timeout values, fallback behavior, and user experience during partial outage.\n\n##### Validation\n- [ ] Resilience to component failures is documented (Yes/No)\n- [ ] Resilience patterns implemented are specified (circuit breaker, retry, etc.)\n- [ ] For each critical dependency: failure handling strategy is defined\n- [ ] Graceful degradation behavior is documented\n- [ ] Monitoring and alerting for component failures is configured\n\n---\n\n#### LACN015: Batch Processing Requirement {#LACN015}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Batch Processing) or Section 11 (Operational)\n\n##### Implementation\nBatch processing refers to scheduled or triggered execution of data processing jobs, ETL pipelines, report generation, or other non-real-time workloads. Batch jobs have unique BC considerations: job state persistence, restart/resume capability, idempotency, output validation, and error handling. Document: batch job inventory, execution schedule, dependencies, data volumes, and criticality. Critical batch jobs may require prioritized recovery during DR scenarios.\n\n##### Validation\n- [ ] Batch processing requirement is clearly stated (Yes/No)\n- [ ] If Yes: batch job inventory is documented\n- [ ] Execution schedule and triggers are defined\n- [ ] Criticality and recovery priority for each job is specified\n\n---\n\n#### LACN016: Batch Execution Type {#LACN016}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Batch Processing)\n\n##### Implementation\nClassify batch job execution patterns. Types include: (1) Scheduled: time-based execution (daily, hourly, cron schedule); (2) Event-triggered: executes based on data arrival or system event; (3) Manual: operator-initiated for ad-hoc needs; (4) On-demand: API-triggered by other systems. Execution type impacts DR recovery sequencing - scheduled jobs may need to catch up after outage, while event-triggered jobs may need message queue replay.\n\n##### Validation\n- [ ] Batch execution type is documented for each job\n- [ ] Execution schedule or trigger conditions are specified\n- [ ] Catch-up or replay strategy after DR failover is defined\n- [ ] Job orchestration and dependency management is documented\n\n---\n\n#### LACN017: Batch Job Reprocessing on Failure {#LACN017}\n**Category**: BC-DR\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Batch Processing ‚Üí Error Handling)\n\n##### Implementation\nCritical batch jobs should support safe reprocessing when failures occur. Requirements include: (1) Idempotency: running the same job multiple times produces same result; (2) State tracking: record job progress to enable resume from last checkpoint; (3) Transactional consistency: all-or-nothing processing to avoid partial updates; (4) Input validation: verify data integrity before processing; (5) Output validation: verify results after processing. Document: which jobs support reprocessing, retry logic, checkpoint strategy, and data validation procedures.\n\n##### Validation\n- [ ] Reprocessing requirement is stated for each critical batch job\n- [ ] Idempotency design is documented\n- [ ] Checkpoint/resume mechanism is implemented\n- [ ] Error handling and retry logic is specified\n- [ ] Data validation before and after processing is defined\n\n---\n\n#### LACN018: Periodic Data Backup Requirement {#LACN018}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore)\n\n##### Implementation\nData backups are essential for recovering from data corruption, accidental deletion, ransomware attacks, or catastrophic failures. Backup requirements depend on: data criticality, change frequency, compliance mandates, and acceptable data loss (RPO). Even systems with real-time DR replication typically need backups for point-in-time recovery and protection against logical errors that replicate to DR site. Document: backup scope (databases, file storage, configurations), retention requirements, and recovery scenarios addressed.\n\n##### Validation\n- [ ] Backup requirement is clearly stated (Yes/No)\n- [ ] If Yes: backup scope is defined (which data stores, configurations)\n- [ ] Recovery scenarios requiring backups are documented\n- [ ] Compliance or regulatory backup requirements are identified\n\n---\n\n#### LACN019: Backup Frequency {#LACN019}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Schedule)\n\n##### Implementation\nBackup frequency determines RPO (maximum acceptable data loss). Common frequencies include: (1) Continuous: transaction log backups, RPO minutes; (2) Hourly: high-change systems, RPO 1 hour; (3) Daily: standard for most systems, RPO 24 hours; (4) Weekly: low-change data, RPO 7 days. Consider: full backups (complete data copy, slower) vs. incremental (changes since last backup, faster but requires full backup for restore). Backup frequency should align with business-defined RPO and data change rate.\n\n##### Validation\n- [ ] Backup frequency is specified (continuous, hourly, daily, weekly)\n- [ ] Full vs. incremental backup strategy is documented\n- [ ] RPO achieved by backup frequency is stated\n- [ ] Backup schedule accounts for maintenance windows and system load\n\n---\n\n#### LACN020: Backup Retention Period {#LACN020}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Retention)\n\n##### Implementation\nBackup retention balances recovery needs with storage costs and compliance requirements. Retention strategies include: (1) Short-term: 7-30 days for operational recovery; (2) Medium-term: 1-12 months for audits and historical recovery; (3) Long-term: 7+ years for regulatory compliance; (4) Tiered: recent backups on fast storage, older on cheaper archive storage. Consider: regulatory requirements (financial records, healthcare data), litigation hold requirements, and point-in-time recovery needs for ransomware scenarios.\n\n##### Validation\n- [ ] Retention period is specified (days, months, years)\n- [ ] Retention is differentiated by backup type (daily, weekly, monthly)\n- [ ] Regulatory or compliance retention requirements are documented\n- [ ] Tiered storage strategy for cost optimization is defined\n- [ ] Backup deletion and cleanup procedures are documented\n\n---\n\n#### LACN021: Backup Versioning Strategy {#LACN021}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Versioning)\n\n##### Implementation\nBackup versioning strategy affects recovery capabilities and storage costs. Options include: (1) Overwrite: only latest backup retained, minimal storage, limited recovery options; (2) Historical versioning: multiple restore points, point-in-time recovery, higher storage costs. Versioning is critical for: recovering from data corruption that isn't immediately detected, ransomware scenarios (restore to pre-infection point), auditing and compliance (historical data access), and accidental deletion recovery.\n\n##### Validation\n- [ ] Versioning strategy is clearly specified (overwrite vs. historical)\n- [ ] If historical: number of versions retained is documented\n- [ ] Point-in-time recovery requirements are defined\n- [ ] Storage cost impact of versioning is assessed and approved\n\n---\n\n#### LACN022: Data Recreation Difficulty Assessment {#LACN022}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore) or Section 1 (Business Context)\n\n##### Implementation\nUnderstanding data recreation difficulty informs backup priority and investment. Categories include: (1) Impossible: unique transactional data, customer records - requires robust backup; (2) Very difficult: months of work, complex data collection - needs frequent backup; (3) Moderately difficult: days-weeks of effort, significant business impact; (4) Easy: can be regenerated from source systems or external data feeds. For difficult-to-recreate data, implement: more frequent backups, multiple backup copies, geographic distribution, and tested restore procedures.\n\n##### Validation\n- [ ] Data recreation difficulty is assessed for each data store\n- [ ] Assessment includes time, cost, and business impact\n- [ ] Backup frequency and redundancy align with recreation difficulty\n- [ ] Critical (impossible to recreate) data has enhanced protection\n\n---\n\n#### LACN023: Business Impact of Data Loss {#LACN023}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 1 (Business Context ‚Üí Business Impact Analysis)\n\n##### Implementation\nBusiness impact analysis (BIA) of data loss drives backup investment decisions. Impact categories include: (1) Revenue impact: lost sales, transaction data, customer orders; (2) Operational impact: inability to deliver services, process disruption; (3) Compliance impact: regulatory fines, audit failures, legal liability; (4) Reputation impact: customer trust, brand damage, competitive disadvantage. Quantify impact: revenue per hour, penalty amounts, customer churn. High-impact data requires aggressive RPO (frequent backups) and verified restore procedures.\n\n##### Validation\n- [ ] Business impact of data loss is quantified (revenue, penalties, operational cost)\n- [ ] Impact assessment is documented and approved by business stakeholders\n- [ ] Backup strategy (frequency, redundancy, testing) aligns with impact severity\n- [ ] Critical data with high business impact has enhanced protection measures\n\n---\n\n#### LACN024: RPO Validation with Business Stakeholders {#LACN024}\n**Category**: BC-RTO\n**Status**: [Status]\n**Source Section**: Section 10 (Non-Functional Requirements) or Section 11 (Operational ‚Üí Backup & DR)\n\n##### Implementation\nRPO defines the maximum amount of data loss acceptable, measured in time (e.g., RPO 1 hour = can lose up to 1 hour of data). RPO must be business-driven, not technically-driven. Validation process: (1) Present business scenarios showing data loss impact; (2) Quantify cost of achieving different RPO levels (tighter RPO = higher backup/replication costs); (3) Obtain stakeholder approval of RPO vs. cost tradeoff; (4) Document approval in architecture sign-off. For critical business processes, RPO should be explicitly validated, not assumed.\n\n##### Validation\n- [ ] RPO value is clearly documented (e.g., 1 hour)\n- [ ] RPO has been presented to and approved by business stakeholders\n- [ ] Approval documentation (meeting notes, email, sign-off) is available\n- [ ] RPO aligns with business impact analysis and criticality\n- [ ] Technical implementation (backup frequency, replication) achieves approved RPO\n\n---\n\n#### LACN025: Geographic Backup Distribution {#LACN025}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Geographic Distribution)\n\n##### Implementation\nGeographic backup distribution protects against regional disasters: earthquakes, floods, fires, power grid failures, or data center outages. Best practices: (1) 3-2-1 rule: 3 copies of data, 2 different media types, 1 offsite; (2) Geographic separation: minimum 100+ miles between sites to avoid correlated failures; (3) Different risk zones: avoid earthquake zones, flood plains, or political jurisdictions with same risks. Implementation options: cloud object storage (S3, Azure Blob), tape vaulting, secondary data center, or disaster recovery site.\n\n##### Validation\n- [ ] Geographic distribution requirement is clearly stated (Yes/No)\n- [ ] If Yes: secondary backup location is documented\n- [ ] Geographic distance and risk separation are verified\n- [ ] Backup transfer mechanism (network, physical media) is specified\n- [ ] Bandwidth and transfer time to secondary site are assessed\n\n---\n\n#### LACN026: Infrastructure Configuration Backup {#LACN026}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Infrastructure)\n\n##### Implementation\nInfrastructure backups enable rapid server recovery and disaster recovery. Scope includes: (1) OS configurations: network settings, security policies, user accounts; (2) Application configurations: web server configs, app server settings; (3) System files: binaries, libraries, scripts; (4) Security configurations: firewall rules, certificates, keys. Modern approaches: Infrastructure as Code (IaC) with version-controlled configuration (Terraform, Ansible), VM snapshots, or container images. For traditional infrastructure, use configuration management tools or image-based backups.\n\n##### Validation\n- [ ] Infrastructure backup requirement is clearly stated (Yes/No)\n- [ ] Backup scope includes: OS configs, application configs, system files\n- [ ] Backup mechanism is specified (IaC, snapshots, image-based)\n- [ ] Restore and rebuild procedures are documented\n- [ ] Configuration drift detection is implemented\n\n---\n\n#### LACN027: Infrastructure Change Log Backup {#LACN027}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Logging & Monitoring or Backup & Restore)\n\n##### Implementation\nInfrastructure change logs provide audit trail, forensic evidence, and troubleshooting history. Log types include: (1) Configuration change logs: who changed what, when, and why; (2) System logs: OS events, security events, service start/stop; (3) Access logs: who logged in, privileged operations; (4) Deployment logs: software installations, updates, patches. Logs are often legally required for compliance (SOX, HIPAA, PCI-DSS). Retention: operational logs 30-90 days, audit logs 1-7 years. Implement centralized logging (SIEM, ELK stack) with backup to immutable storage.\n\n##### Validation\n- [ ] Log backup requirement is clearly stated (Yes/No)\n- [ ] Log types requiring backup are specified\n- [ ] Log retention period meets compliance requirements\n- [ ] Centralized logging solution is implemented\n- [ ] Log integrity and immutability protections are in place\n- [ ] Restore and analysis procedures are documented\n\n---\n\n#### LACN028: Full Application Restore Capability {#LACN028}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Testing)\n\n##### Implementation\nFull application restore tests business continuity preparedness for catastrophic failures. Restore scope includes: (1) All application data from backups; (2) All infrastructure from IaC or images; (3) All configurations from version control; (4) All dependencies and integrations. Test: documented restore procedures, RTO achievement, data integrity verification, application functionality validation. Perform annual full restore tests to production-equivalent environment. Document: restore runbook, expected RTO, component restore order, and validation checklist.\n\n##### Validation\n- [ ] Full restore capability is confirmed (Yes/No)\n- [ ] Restore procedures are documented step-by-step\n- [ ] Full restore test has been successfully performed\n- [ ] RTO for full restore is documented and acceptable to business\n- [ ] Restore testing is scheduled regularly (annually minimum)\n- [ ] Dependencies and prerequisites for restore are documented\n\n---\n\n#### LACN029: Sensitive Data Classification {#LACN029}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 8 (Security Architecture ‚Üí Data Classification) or Section 11 (Operational)\n\n##### Implementation\nSensitive data requires enhanced backup security controls. Data types include: (1) PII: names, addresses, SSN, email, phone; (2) Financial: credit cards, bank accounts, transaction history; (3) Health: medical records, diagnoses, treatment history; (4) Confidential business: trade secrets, contracts, M&A data. Enhanced controls: backup encryption (AES-256), access controls (RBAC, MFA), geographic restrictions (data sovereignty), immutability (WORM storage), audit logging, and secure disposal. Compliance: GDPR, HIPAA, PCI-DSS, SOX have specific backup requirements.\n\n##### Validation\n- [ ] Sensitive data classification is documented\n- [ ] Data types are identified (PII, financial, health, confidential)\n- [ ] Applicable compliance requirements are listed (GDPR, HIPAA, PCI-DSS)\n- [ ] Enhanced backup security controls are implemented (encryption, access control)\n- [ ] Data sovereignty and geographic restrictions are enforced\n\n---\n\n#### LACN030: Backup Responsibility Assignment {#LACN030}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Responsibilities)\n\n##### Implementation\nClear backup responsibility prevents gaps and failures. Responsibility model depends on deployment: (1) On-premises: infrastructure or DBA team manages backup software, schedules, monitoring; (2) IaaS cloud: infrastructure team configures cloud backup services; (3) PaaS/SaaS: provider handles backups, customer validates and tests restores; (4) Shared responsibility: provider handles infrastructure backups, customer handles application data backups. Document: primary responsible team, backup schedule, monitoring and alerting ownership, restore testing responsibility, and escalation procedures for failures.\n\n##### Validation\n- [ ] Backup responsibility is clearly assigned to a specific team/role\n- [ ] Backup monitoring and alerting ownership is defined\n- [ ] Restore testing responsibility is assigned\n- [ ] Escalation procedures for backup failures are documented\n- [ ] RACI matrix for backup operations is provided\n\n---\n\n#### LACN031: Backup Download to Local/On-Premises Repository {#LACN031}\n**Category**: BC-BACKUP\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Backup & Restore ‚Üí Hybrid Strategy)\n\n##### Implementation\nHybrid backup strategy provides additional protection and vendor independence. Use cases: (1) Cloud to on-premises: download cloud backups to local storage for air-gap protection, ransomware defense, or regulatory requirements; (2) On-premises to cloud: upload local backups to cloud for geographic distribution. Considerations: bandwidth requirements, transfer time, storage costs, security during transfer (encryption, VPN), and automation. Implement tiered strategy: recent backups in cloud for fast restore, older backups downloaded to on-premises for long-term retention.\n\n##### Validation\n- [ ] Backup download capability is documented (Yes/No)\n- [ ] If Yes: download frequency and retention strategy are specified\n- [ ] Bandwidth and transfer time requirements are assessed\n- [ ] Security during transfer (encryption, VPN) is documented\n- [ ] Local storage capacity and management are planned\n\n---\n\n#### LACN032: DR Activation Automation Capability {#LACN032}\n**Category**: BC-AUTO\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation)\n\n##### Implementation\nDR automation reduces RTO and human error. Automation levels include: (1) Fully automated: health checks detect failure, automatic failover to DR site, no human intervention; (2) Semi-automated: automated runbooks with human approval gates; (3) Manual: documented procedures requiring operator execution. Automation components: health monitoring, failover triggers, DNS switching, traffic routing, database failover, application startup, validation testing. Consider: false positive risk (premature failover), rollback procedures, and notification workflows. Start with semi-automated approach, progress to full automation as confidence increases.\n\n##### Validation\n- [ ] DR automation capability is assessed (fully automated, semi-automated, manual)\n- [ ] Automation scope is documented (which components can be automated)\n- [ ] Automated failover triggers and health checks are defined\n- [ ] Human approval gates and override procedures are documented\n- [ ] Rollback and failback automation is specified\n\n---\n\n#### LACN033: Automatable DR Components {#LACN033}\n**Category**: BC-AUTO\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation)\n\n##### Implementation\nAutomation candidates vary by architecture. Common automatable components include: (1) DNS failover: Route 53 health checks, DNS TTL management; (2) Load balancer reconfiguration: traffic routing to DR site; (3) Database failover: automated promotion of standby to primary; (4) Application startup: auto-scaling groups, container orchestration (Kubernetes); (5) Network reconfiguration: VPN tunnels, firewall rules; (6) Monitoring reconfiguration: point to DR endpoints. Document: automation tooling (Terraform, Ansible, CloudFormation), runbook automation (AWS Systems Manager, Azure Automation), testing frequency, and manual override procedures.\n\n##### Validation\n- [ ] Automatable components are explicitly listed with automation approach\n- [ ] Automation tooling and scripts are documented\n- [ ] Automated runbooks are version-controlled and tested\n- [ ] Non-automatable (manual) steps are identified with procedures\n- [ ] DR automation is tested regularly (at least quarterly)\n\n---\n\n#### LACN034: Circuit Breaker Pattern Requirement {#LACN034}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Resilience Patterns)\n\n##### Implementation\nCircuit Breaker is a resilience pattern that prevents cascading failures in distributed systems. States: (1) Closed: normal operation, requests flow through; (2) Open: failure threshold exceeded, requests fail fast without calling service; (3) Half-Open: periodic retry to check if service recovered. Benefits: prevents thread exhaustion, reduces latency for end users, allows failed services to recover. Implementation: Netflix Hystrix, Resilience4j, Polly, AWS App Mesh. Configuration: failure threshold (e.g., 50% failures), timeout duration (30 seconds), and retry interval (60 seconds). Apply to external APIs, database calls, and internal microservices.\n\n##### Validation\n- [ ] Circuit breaker requirement is stated (Yes/No)\n- [ ] If Yes: which service calls require circuit breakers are identified\n- [ ] Circuit breaker library/implementation is specified\n- [ ] Configuration: failure threshold, timeout, retry interval are documented\n- [ ] Fallback behavior when circuit is open is defined\n- [ ] Monitoring and alerting for circuit state changes is configured\n\n---\n\n#### LACN035: Retry with Exponential Backoff Pattern {#LACN035}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Resilience Patterns)\n\n##### Implementation\nRetry with Exponential Backoff handles transient failures: network glitches, temporary service unavailability, rate limiting. Pattern: retry failed operations with increasing delays (e.g., 1s, 2s, 4s, 8s, 16s) to avoid overwhelming recovering services. Configuration: (1) Max retries: 3-5 attempts; (2) Initial delay: 1-2 seconds; (3) Backoff multiplier: 2x; (4) Jitter: randomization to prevent thundering herd; (5) Max delay: 60 seconds. Apply to: HTTP API calls, database connections, message queue operations. Combine with circuit breaker for comprehensive resilience.\n\n##### Validation\n- [ ] Retry with exponential backoff requirement is stated (Yes/No)\n- [ ] Operations requiring retry logic are identified\n- [ ] Retry configuration is documented: max retries, initial delay, backoff multiplier\n- [ ] Jitter implementation to prevent thundering herd is specified\n- [ ] Non-retriable errors (4xx client errors) are distinguished from retriable errors (5xx, timeouts)\n- [ ] Monitoring for retry metrics is configured\n\n---\n\n#### LACN036: Timeout Configuration for External Services {#LACN036}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Resilience Patterns) or Section 5 (Integrations)\n\n##### Implementation\nTimeouts prevent thread exhaustion and improve user experience when external services are slow or unresponsive. Timeout types: (1) Connection timeout: max time to establish connection (e.g., 5 seconds); (2) Read/socket timeout: max time to receive response (e.g., 30 seconds); (3) Total request timeout: end-to-end including retries. Configuration strategy: aggressive timeouts for non-critical services, generous timeouts for critical services, differentiate by SLA. Combine with circuit breaker and fallback. Monitor p95/p99 latency to set realistic timeouts. Document timeout values per external service.\n\n##### Validation\n- [ ] Timeout requirement is stated (Yes/No)\n- [ ] Timeout values are specified for each external service integration\n- [ ] Connection timeout and read timeout are separately configured\n- [ ] Timeout values are based on p95/p99 latency analysis\n- [ ] Timeout exceeded handling (error response, fallback) is documented\n- [ ] Monitoring and alerting for timeout events is configured\n\n---\n\n#### LACN037: Timeboxing for Automated Contingency/DRP Activation {#LACN037}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Disaster Recovery ‚Üí Automation)\n\n##### Implementation\nTimeboxing sets maximum time windows for automated DR decisions. Examples: (1) If primary site is unreachable for > 5 minutes, trigger automatic failover; (2) If database replication lag > 10 minutes, alert and consider manual intervention; (3) If service degradation persists > 15 minutes, activate contingency mode. Timeboxing prevents: premature failover from brief outages, indefinite waiting during actual disasters. Implementation: health check intervals, consecutive failure thresholds, evaluation windows. Balance: too aggressive causes false positives, too conservative delays recovery.\n\n##### Validation\n- [ ] Timeboxing for DR activation is defined (Yes/No)\n- [ ] Time thresholds for automated actions are documented (e.g., failover after 5 min outage)\n- [ ] Health check frequency and consecutive failure thresholds are specified\n- [ ] Manual override and abort procedures are documented\n- [ ] False positive mitigation strategies are implemented\n- [ ] Notification and escalation timelines are defined\n\n---\n\n#### LACN038: Fallback Response Pattern {#LACN038}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Resilience Patterns)\n\n##### Implementation\nFallback pattern provides graceful degradation rather than complete failure. Strategies: (1) Cached response: return stale data with cache-control headers; (2) Default/static response: generic response when personalization fails; (3) Feature toggle: disable non-critical features to preserve core functionality; (4) Alternative service: route to backup provider or internal mock. Examples: return cached product catalog when database is down, show static recommendations when ML service fails, disable real-time pricing when pricing service is unavailable. Document: which features have fallbacks, fallback behavior, user communication.\n\n##### Validation\n- [ ] Fallback requirement is stated (Yes/No)\n- [ ] Features with fallback support are explicitly listed\n- [ ] Fallback strategy for each feature is documented (cache, default, feature toggle)\n- [ ] User experience during fallback mode is defined\n- [ ] Monitoring to detect fallback activation is configured\n- [ ] Testing of fallback scenarios is performed regularly\n\n---\n\n#### LACN039: Bulkhead Isolation Pattern {#LACN039}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Resilience Patterns)\n\n##### Implementation\nBulkhead pattern isolates failures by partitioning resources. Implementation: (1) Thread pool isolation: separate thread pools per service (prevents one slow service from exhausting all threads); (2) Connection pool isolation: separate DB connection pools per tenant or feature; (3) Rate limiting: protect services from overload; (4) Resource quotas: CPU, memory limits per component. Benefits: failure in one partition doesn't impact others, controlled degradation, easier capacity planning. Example: checkout service gets dedicated thread pool, separate from search, so slow checkout doesn't block search.\n\n##### Validation\n- [ ] Bulkhead isolation requirement is stated (Yes/No)\n- [ ] Isolation strategy is specified (thread pools, connection pools, rate limiting)\n- [ ] Resource partition boundaries are defined\n- [ ] Capacity and sizing for each partition is documented\n- [ ] Monitoring for resource exhaustion per partition is configured\n- [ ] Overload and throttling behavior is documented\n\n---\n\n#### LACN040: Auto-Scaling with Health-Based Instance Replacement {#LACN040}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 11 (Operational ‚Üí Auto-Scaling) or Section 4 (Deployment Architecture)\n\n##### Implementation\nAuto-scaling with health-based replacement provides automatic recovery from instance failures. Components: (1) Health checks: HTTP endpoint, TCP check, or custom script; (2) Auto-scaling group: maintains desired instance count; (3) Multi-AZ deployment: distribute instances across availability zones; (4) Replacement policy: terminate unhealthy, launch replacement. Configuration: health check frequency (30 seconds), grace period (300 seconds for startup), scaling policies (CPU, memory, custom metrics). Benefits: automatic recovery, reduced MTTR, improved availability. Combine with immutable infrastructure (replace, don't repair).\n\n##### Validation\n- [ ] Auto-scaling with health replacement is required (Yes/No)\n- [ ] Health check type and endpoint are specified\n- [ ] Health check frequency and grace period are configured\n- [ ] Multi-AZ deployment strategy is documented\n- [ ] Minimum, desired, and maximum instance counts are defined\n- [ ] Scaling policies and triggers are documented\n- [ ] Instance replacement testing is performed regularly\n\n---\n\n#### LACN041: Load Balancing for Automatic Traffic Distribution {#LACN041}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 4 (Deployment Architecture ‚Üí Load Balancing) or Section 11 (Operational)\n\n##### Implementation\nLoad balancing distributes traffic for performance and availability. Types: (1) Application LB (Layer 7): HTTP/HTTPS, path-based routing, host-based routing, SSL termination; (2) Network LB (Layer 4): TCP/UDP, high throughput, low latency; (3) Global LB: DNS-based, geo-routing, disaster recovery. Configuration: health checks, sticky sessions, idle timeout, cross-zone load balancing. Algorithms: round-robin, least connections, weighted. Benefits: horizontal scaling, automatic failover, zero-downtime deployments. For multi-AZ HA, enable cross-zone load balancing.\n\n##### Validation\n- [ ] Load balancing requirement is stated (Yes/No)\n- [ ] Load balancer type is specified (Application, Network, Global)\n- [ ] Load balancing algorithm is chosen and documented\n- [ ] Health check configuration is defined\n- [ ] Sticky session and timeout settings are specified\n- [ ] Cross-zone load balancing is enabled for multi-AZ deployments\n- [ ] SSL/TLS termination and certificate management is documented\n\n---\n\n#### LACN042: Queue-Based Load Leveling Pattern {#LACN042}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 7 (Application Architecture ‚Üí Asynchronous Processing)\n\n##### Implementation\nQueue-based load leveling decouples request acceptance from processing. Pattern: (1) Producer: API accepts requests, writes to queue, returns 202 Accepted; (2) Queue: message queue buffers requests (SQS, Kafka, RabbitMQ); (3) Consumer: workers process at sustainable rate. Benefits: absorb traffic spikes without overload, graceful degradation under load, improved availability. Use cases: order processing, report generation, notifications, batch imports. Configuration: queue depth monitoring, DLQ (dead letter queue) for failures, consumer auto-scaling based on queue depth.\n\n##### Validation\n- [ ] Queue-based load leveling requirement is stated (Yes/No)\n- [ ] Use cases requiring asynchronous processing are identified\n- [ ] Message queue technology is specified (SQS, Kafka, RabbitMQ)\n- [ ] Queue configuration: retention, DLQ, visibility timeout is documented\n- [ ] Consumer scaling policy based on queue depth is defined\n- [ ] Monitoring for queue depth and message age is configured\n- [ ] Error handling and retry logic for queue messages is documented\n\n---\n\n#### LACN043: Single Points of Failure (SPOF) Identification {#LACN043}\n**Category**: BC-CLOUD\n**Status**: [Status]\n**Source Section**: Section 3 (Architecture Overview) or Section 11 (Operational ‚Üí High Availability)\n\n##### Implementation\nSingle Point of Failure (SPOF) analysis identifies components whose failure causes complete service outage. Common SPOFs: (1) Single database instance: implement primary-replica or multi-master; (2) Single load balancer: use multiple load balancers or cloud-managed LB; (3) Single AZ deployment: deploy across multiple AZs; (4) Single region: implement multi-region for critical systems; (5) Critical third-party dependency without fallback. For each SPOF: assess impact, probability, and mitigation options. Document accepted SPOFs with business justification (cost vs. risk tradeoff).\n\n##### Validation\n- [ ] SPOF analysis is documented\n- [ ] Each potential SPOF is listed with impact assessment\n- [ ] Mitigation strategy for each SPOF is specified or justified as accepted risk\n- [ ] Architecture diagrams highlight redundancy and SPOF mitigation\n- [ ] Critical dependencies without alternatives are documented\n- [ ] Business acceptance of residual SPOFs is obtained\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Business Continuity Terms**:\n- **RTO (Recovery Time Objective)**: Maximum acceptable downtime before business impact becomes unacceptable\n- **RPO (Recovery Point Objective)**: Maximum acceptable data loss measured in time\n- **DR (Disaster Recovery)**: Process and procedures for recovering IT systems after a disaster\n- **Failover**: Automatic switching to redundant system when primary system fails\n- **Backup**: Copy of data stored separately for recovery purposes\n- **High Availability (HA)**: System design ensuring minimal downtime through redundancy\n- **Business Continuity Plan (BCP)**: Documented procedures for maintaining business operations during disruptions\n- **Hot Site**: Fully operational backup facility ready for immediate failover\n- **Cold Site**: Backup location with basic infrastructure requiring configuration before use\n- **Warm Site**: Partially configured backup facility requiring some setup time\n- **Circuit Breaker**: Resilience pattern that prevents cascading failures by failing fast\n- **Exponential Backoff**: Retry strategy with progressively increasing wait times\n- **Bulkhead**: Isolation pattern that prevents failures from spreading\n- **Auto-Scaling**: Automatic adjustment of compute resources based on demand or health\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Compliance Abbreviations**:\n- **LACN**: Business Continuity compliance requirement code (new standard)\n- **BC-GEN**: General information requirements\n- **BC-RTO**: Recovery time objective requirements\n- **BC-DR**: Disaster recovery requirements\n- **BC-BACKUP**: Backup and restore requirements\n- **BC-AUTO**: Automation requirements\n- **BC-CLOUD**: Cloud resilience requirements\n- **MTTR**: Mean Time To Recovery\n- **MTBF**: Mean Time Between Failures\n- **SLA**: Service Level Agreement\n- **SPOF**: Single Point of Failure\n\n---\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=business-continuity -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Business Continuity Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Application name not documented | LACN001 Non-Compliant | Section 1 or 2 | Add official application name, acronyms, and aliases |\n| RTO/RPO values not defined | LACN012,LACN024 Non-Compliant | Section 10 (Non-Functional Requirements) | Define recovery objectives (e.g., RTO: 4 hours, RPO: 1 hour) |\n| HA components not identified | LACN007 Unknown | Section 11 (Operational ‚Üí High Availability) | List HA components with deployment patterns (active-active/passive) |\n| DR architecture not specified | LACN010 Non-Compliant | Section 11 (Operational ‚Üí Disaster Recovery) | Specify DR pattern (cold/warm/hot/active-active) and site locations |\n| Backup strategy undefined | LACN018-LACN021 Non-Compliant | Section 11 (Operational ‚Üí Backup & DR) | Document backup frequency, retention, storage location, versioning |\n| DR testing plan missing | LACN013 Non-Compliant | Section 11 (Operational ‚Üí Disaster Recovery) | Define DR drill schedule, validation procedures, success criteria |\n| Failover mechanisms not specified | LACN007 Unknown | Section 11 (Operational ‚Üí High Availability) | Specify automatic failover configuration and triggers |\n| Data replication undefined | LACN011 Unknown | Section 11 (Operational ‚Üí Backup & DR) | Document geo-replication strategy, sync/async, RPO alignment |\n| Resilience patterns not implemented | LACN034-LACN039 Unknown | Section 7 (Application Architecture ‚Üí Resilience) | Implement circuit breaker, retry, timeout, fallback, bulkhead patterns |\n| SPOF not identified | LACN043 Unknown | Section 3 or 11 | Document single points of failure and mitigation strategies |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Business Continuity-Specific Examples**:\n\n**Example 1: Defining RTO and RPO (LACN012, LACN024)**\n- **Gap**: RTO/RPO values not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add RTO/RPO objectives to Section 10:\n   RTO: 4 hours (maximum acceptable downtime),\n   RPO: 1 hour (maximum acceptable data loss),\n   Availability target: 99.9% (43 minutes downtime/month),\n   Business justification: Payment processing requires <4hr recovery\"\n  ```\n- **Expected Outcome**: Section 10 with RTO, RPO, availability targets\n- **Impact**: LACN012, LACN024 ‚Üí Compliant\n\n**Example 2: Backup Strategy Documentation (LACN018-LACN021)**\n- **Gap**: Backup strategy not defined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add backup strategy to Section 11 ‚Üí Backup & DR:\n   Periodic backups required: Yes,\n   Frequency: Full backup daily at 2 AM, incremental every 6 hours,\n   Retention: 30 days online (hot storage), 90 days warm, 7 years archival,\n   Storage: AWS S3 with cross-region replication to us-west-2,\n   Versioning: Historical versions retained (30 daily, 12 monthly, 7 yearly),\n   Encryption: AES-256 at rest, TLS 1.3 in transit,\n   Testing: Monthly restore validation, quarterly full DR drill\"\n  ```\n- **Expected Outcome**: Section 11 with complete backup strategy\n- **Impact**: LACN018, LACN019, LACN020, LACN021 ‚Üí Compliant\n\n**Example 3: Disaster Recovery Architecture (LACN009-LACN011)**\n- **Gap**: DR architecture not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add DR architecture to Section 11 ‚Üí Disaster Recovery:\n   DR Required: Yes (catastrophic regional failures),\n   DR Pattern: Warm standby (infrastructure provisioned, not fully running),\n   Primary Site: AWS us-east-1 (3 AZs),\n   DR Site: AWS us-west-2 (3 AZs),\n   Replication: Asynchronous database replication (RPO 5 minutes),\n   Failover: Semi-automated with manual approval gate,\n   RTO Target: 2 hours (from declaration to full service restoration)\"\n  ```\n- **Expected Outcome**: Section 11 with DR architecture, sites, replication, RTO\n- **Impact**: LACN009, LACN010, LACN011 ‚Üí Compliant\n\n**Example 4: Resilience Patterns (LACN034-LACN039)**\n- **Gap**: Cloud resilience patterns not implemented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add resilience patterns to Section 7 ‚Üí Application Architecture ‚Üí Resilience:\n   Circuit Breaker: Implemented using Resilience4j for all external API calls,\n     - Failure threshold: 50% failures over 10 requests\n     - Open duration: 60 seconds before retry\n   Retry with Exponential Backoff: Max 3 retries, initial delay 1s, backoff 2x, max 30s,\n   Timeouts: Connection 5s, Read 30s for external services,\n   Fallback: Cached responses for product catalog, default recommendations when ML fails,\n   Bulkhead: Separate thread pools per external service (checkout: 20 threads, search: 50 threads)\"\n  ```\n- **Expected Outcome**: Section 7 with complete resilience pattern implementation\n- **Impact**: LACN034, LACN035, LACN036, LACN038, LACN039 ‚Üí Compliant\n\n**Example 5: Auto-Scaling and Load Balancing (LACN040-LACN041)**\n- **Gap**: Auto-scaling and load balancing not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add auto-scaling and load balancing to Section 4 ‚Üí Deployment or Section 11 ‚Üí Operational:\n   Auto-Scaling: Enabled with health-based replacement,\n     - Health check: HTTP /health endpoint every 30s,\n     - Grace period: 300s for application startup,\n     - Min instances: 2, Desired: 4, Max: 20,\n     - Scaling policy: Target 70% CPU utilization,\n     - Multi-AZ: Distributed across 3 availability zones,\n   Load Balancing: Application Load Balancer (ALB),\n     - Algorithm: Least outstanding requests,\n     - Health check: /health every 30s, 2 consecutive successes,\n     - Sticky sessions: Cookie-based, 1 hour TTL,\n     - Cross-zone: Enabled for even distribution\"\n  ```\n- **Expected Outcome**: Section 4 or 11 with auto-scaling and load balancing configuration\n- **Impact**: LACN040, LACN041 ‚Üí Compliant\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required business continuity fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all recovery procedures\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete General Information (BC-GEN)** (5 requirements, estimated impact: +0.5 points)\n   - LACN001: Document application name and aliases (Section 1 or 2)\n   - LACN002: Specify architecture type and deployment model (Section 3 or 4)\n   - LACN003: Define number of architecture layers (Section 3)\n   - LACN004: Document infrastructure type (physical, virtual, containers) (Section 4 or 11)\n   - LACN005: Identify all critical dependencies with impact analysis (Section 1 or 5)\n\n2. **Define Recovery Objectives (BC-RTO)** (2 requirements, estimated impact: +0.6 points)\n   - LACN012: Define RTO with business justification (Section 10)\n   - LACN024: Validate RPO with business stakeholders and document approval (Section 10)\n\n3. **Establish Disaster Recovery (BC-DR)** (11 requirements, estimated impact: +1.2 points)\n   - LACN006-LACN008: Document HA requirements, components, local contingency (Section 11)\n   - LACN009-LACN011: Define DR requirements, architecture pattern, replication method (Section 11)\n   - LACN013: Create DR testing plan with schedule and success criteria (Section 11)\n   - LACN014: Document resilience to transient component failures (Section 7 or 11)\n   - LACN015-LACN017: Document batch processing, execution types, reprocessing strategy (Section 7 or 11)\n\n4. **Implement Backup Strategy (BC-BACKUP)** (13 requirements, estimated impact: +1.5 points)\n   - LACN018-LACN021: Document backup requirements, frequency, retention, versioning (Section 11)\n   - LACN022-LACN024: Assess data recreation difficulty and business impact (Section 1 or 11)\n   - LACN025: Implement geographic backup distribution (Section 11)\n   - LACN026-LACN028: Document infrastructure and log backups, full restore capability (Section 11)\n   - LACN029-LACN031: Document sensitive data classification, backup responsibility, hybrid strategy (Section 8 or 11)\n\n5. **Enable DR Automation (BC-AUTO)** (2 requirements, estimated impact: +0.3 points)\n   - LACN032: Assess DR automation capability and approach (Section 11)\n   - LACN033: Identify and document automatable components with tooling (Section 11)\n\n6. **Implement Cloud Resilience (BC-CLOUD)** (10 requirements, estimated impact: +1.0 points)\n   - LACN034: Implement circuit breaker pattern (Section 7)\n   - LACN035: Implement retry with exponential backoff (Section 7)\n   - LACN036: Configure timeouts for external services (Section 7)\n   - LACN037: Define timeboxing for automated DR activation (Section 11)\n   - LACN038: Implement fallback responses (Section 7)\n   - LACN039: Implement bulkhead isolation pattern (Section 7)\n   - LACN040: Configure auto-scaling with health-based replacement (Section 4 or 11)\n   - LACN041: Implement load balancing (Section 4 or 11)\n   - LACN042: Implement queue-based load leveling (Section 7)\n   - LACN043: Identify and document SPOFs with mitigation (Section 3 or 11)\n\n**Priority Order**: \n1. BC-RTO (LACN012, LACN024) - Foundation\n2. BC-DR (LACN009-LACN011) - DR architecture\n3. BC-BACKUP (LACN018-LACN021) - Backup strategy\n4. BC-GEN (LACN001-LACN005) - Basic information\n5. BC-CLOUD (LACN034-LACN043) - Resilience patterns\n6. BC-AUTO (LACN032-LACN033) - Automation\n\n**Estimated Final Score After Remediation**: 8.5-9.2/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to SRE format\n- Migrated from 10 LABC requirements to 43 LACN requirements\n- Changed from section-based to table-based compliance summary format\n- All content translated from Spanish to professional English with expanded phrasing\n- Added 6-column compliance summary table (Code, Requirement, Category, Status, Source, Role)\n- Organized into 6 categories: BC-GEN (5), BC-RTO (2), BC-DR (11), BC-BACKUP (13), BC-AUTO (2), BC-CLOUD (10)\n- All 43 requirements include Implementation + Validation subsections\n- Added A.2 Source Mapping Table appendix\n- Updated A.3 with 43-requirement remediation examples\n- Enhanced A.1 terminology with cloud resilience patterns\n- All requirements have equal weight (no two-tier scoring)\n- Data source: Compliance_Questionnaire_LACN.xlsx\n- Total: 43 validation data points\n\n**Version 1.0 (Previous)**:\n- Section-based format with 5 narrative sections\n- 10 LABC requirements\n- Limited appendix structure (missing A.2)\n- Basic PLACEHOLDER approach\n- Limited source traceability\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=business-continuity -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=business-continuity -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=business-continuity -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=business-continuity -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=business-continuity -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_CLOUD_ARCHITECTURE.md": "# Compliance Contract: Cloud Architecture\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 4, 8, 9, 10, 11)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=cloud-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=cloud-architecture -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAC1 | Cloud Deployment Model (IaaS, PaaS, SaaS) | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Cloud Architect or N/A] |\n| LAC2 | Network Connectivity and Integration | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Network Engineer / Cloud Architect or N/A] |\n| LAC3 | Security and Regulatory Compliance | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Security Architect / Compliance Officer or N/A] |\n| LAC4 | Resource Monitoring and Management | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [DevOps Engineer / SRE Lead or N/A] |\n| LAC5 | Backup and Recovery Policies | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Cloud Architect / Business Continuity Manager or N/A] |\n| LAC6 | Cloud Best Practices Adoption | Cloud Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Cloud Architect / Technical Lead or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Cloud Deployment Model (LAC1)\n\n**Requirement**: Select and justify the most appropriate cloud service model (IaaS, PaaS, SaaS).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Cloud Architect or N/A]\n\n### 1.1 Service Model Selection\n\n**Service Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service model documented. If Non-Compliant: Service model not specified in ARCHITECTURE.md. If Not Applicable: Cloud service not used. If Unknown: Service model mentioned but not clearly defined]\n- Source: [ARCHITECTURE.md Section X.Y, lines A-B or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define whether solution uses IaaS, PaaS, or SaaS and document in Section 4 or 8]\n\n**Cloud Provider**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Provider documented. If Non-Compliant: Provider not specified. If Not Applicable: Cloud not used. If Unknown: Provider mentioned ambiguously]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify cloud provider (AWS/Azure/GCP/Other) in Section 4]\n\n**Deployment Regions**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Regions documented. If Non-Compliant: Regions not specified. If Not Applicable: Regional deployment not required. If Unknown: Regions mentioned but not clearly identified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document primary and secondary regions in Section 4]\n\n**Justification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Rationale provided via ADR or design decision. If Non-Compliant: No justification documented. If Not Applicable: N/A. If Unknown: Partial justification provided]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Add ADR explaining why this service model was chosen, addressing alternatives and trade-offs]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC1]\n\n---\n\n## 2. Network Connectivity and Integration (LAC2)\n\n**Requirement**: Describe network integration with other platforms (e.g., Azure, AWS, On-Premise). Indicate required network segments for communication if using existing components.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Network Engineer / Cloud Architect or N/A]\n\n### 2.1 Network Architecture\n\n**Network Architecture**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Network design documented. If Non-Compliant: Network architecture not specified. If Not Applicable: No network integration required. If Unknown: Network mentioned but design unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document VPC/VNet configuration, subnets, routing in Section 4 or 9]\n\n**Cloud-to-Cloud Connectivity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Multi-cloud connectivity documented. If Non-Compliant: Integration method not specified. If Not Applicable: Single cloud deployment. If Unknown: Connectivity mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify if using VPN, Direct Connect/ExpressRoute, or transit gateway]\n\n**On-Premise Integration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Hybrid connectivity documented. If Non-Compliant: On-prem integration method not specified. If Not Applicable: Cloud-only solution. If Unknown: Hybrid mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document VPN/Direct Connect configuration and on-premise CIDR blocks in Section 4 or 9]\n\n**Network Latency Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Latency SLOs defined. If Non-Compliant: No latency requirements specified. If Not Applicable: Latency not critical. If Unknown: Performance mentioned but no specific targets]\n- Source: [ARCHITECTURE.md Section 10 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define acceptable latency thresholds (p50, p95, p99) in Section 10]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC2]\n\n---\n\n## 3. Security and Regulatory Compliance (LAC3)\n\n**Requirement**: Include network communication protocols (TLS, mTLS, etc.) in the design and ensure solution meets security and regulatory requirements.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Security Architect / Compliance Officer or N/A]\n\n### 3.1 Network Security\n\n**Communication Protocols**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Encryption protocols documented. If Non-Compliant: Communication security not specified. If Not Applicable: N/A. If Unknown: Security mentioned but protocols unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption in Transit) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify TLS version, certificate management, and whether mTLS is required in Section 9 (Security Architecture ‚Üí Data Security)]\n\n**Identity and Access Management (IAM)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: IAM policies documented. If Non-Compliant: Access controls not defined. If Not Applicable: N/A. If Unknown: IAM mentioned but policies unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document RBAC policies, service accounts, and authentication methods in Section 9 (Security Architecture ‚Üí Authentication & Authorization)]\n\n**Data Encryption**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Encryption at-rest and in-transit documented. If Non-Compliant: Encryption strategy not specified. If Not Applicable: No sensitive data. If Unknown: Encryption mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify encryption methods (KMS, customer-managed keys) for data at rest and in transit in Section 9 (Security Architecture ‚Üí Data Security)]\n\n**Network Security Controls**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Security groups/NSGs documented. If Non-Compliant: Network controls not defined. If Not Applicable: N/A. If Unknown: Security mentioned but controls unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Network Security) or Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document VPC/VNet security groups, NACLs, firewall rules in Section 9 (Security Architecture ‚Üí Network Security) or Section 4]\n\n**Regulatory Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Compliance requirements documented. If Non-Compliant: Regulatory requirements not addressed. If Not Applicable: No specific regulations apply. If Unknown: Compliance mentioned but requirements unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Compliance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify applicable regulations (GDPR, HIPAA, PCI-DSS, etc.) and compliance controls in Section 9 (Security Architecture ‚Üí Compliance)]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC3]\n\n---\n\n## 4. Resource Monitoring and Management (LAC4)\n\n**Requirement**: Validate if additional components are required for monitoring in observability tools. Describe how cloud resources will be monitored and managed.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [DevOps Engineer / SRE Lead or N/A]\n\n### 4.1 Observability Infrastructure\n\n**Monitoring Tools**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Observability stack documented. If Non-Compliant: Monitoring tools not specified. If Not Applicable: Monitoring not required. If Unknown: Tools mentioned but not clearly identified]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify monitoring solution (CloudWatch, Azure Monitor, Datadog, Prometheus, etc.) in Section 11]\n\n**Metrics Collection**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Key metrics defined. If Non-Compliant: Metrics not specified. If Not Applicable: N/A. If Unknown: Monitoring mentioned but metrics unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define infrastructure metrics (CPU, memory, disk, network) and application metrics in Section 11]\n\n**Log Aggregation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Logging strategy documented. If Non-Compliant: Log management not specified. If Not Applicable: N/A. If Unknown: Logging mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document log collection, retention, and centralized logging solution in Section 11]\n\n**Alerting Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Alert policies defined. If Non-Compliant: Alerting not configured. If Not Applicable: N/A. If Unknown: Alerts mentioned but thresholds unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define alert thresholds, escalation policies, and notification channels in Section 11]\n\n**Cost Tracking**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cost monitoring documented. If Non-Compliant: Cost management not addressed. If Not Applicable: N/A. If Unknown: Budgets mentioned but tracking unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document cost budgets, tagging strategy, and budget alerts in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC4]\n\n---\n\n## 5. Backup and Recovery Policies (LAC5)\n\n**Requirement**: Establish procedures for data backup and recovery according to business needs.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Cloud Architect / Business Continuity Manager or N/A]\n\n### 5.1 Backup Strategy\n\n**Backup Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup approach documented. If Non-Compliant: Backup strategy not defined. If Not Applicable: No data persistence. If Unknown: Backups mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define backup types (full, incremental, snapshot), frequency, and retention in Section 11.3]\n\n**Recovery Time Objective (RTO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RTO documented. If Non-Compliant: RTO not specified. If Not Applicable: N/A. If Unknown: Recovery mentioned but RTO unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define RTO based on business criticality (Tier 1: 4h, Tier 2: 8h, Tier 3: 24h) in Section 11.3]\n\n**Recovery Point Objective (RPO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RPO documented. If Non-Compliant: RPO not specified. If Not Applicable: N/A. If Unknown: Backup frequency mentioned but RPO unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define maximum acceptable data loss window (e.g., 15 min, 1 hour, 24 hours) in Section 11.3]\n\n**Multi-Region Replication**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Disaster recovery documented. If Non-Compliant: DR strategy not defined. If Not Applicable: Single region acceptable. If Unknown: Replication mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 11.4 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document cross-region replication, failover procedures, and DR testing plan in Section 11.4]\n\n**Backup Testing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Recovery testing documented. If Non-Compliant: Testing procedures not defined. If Not Applicable: N/A. If Unknown: Testing mentioned but schedule unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define backup restoration testing frequency and procedures in Section 11.3]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC5]\n\n---\n\n## 6. Cloud Best Practices Adoption (LAC6)\n\n**Requirement**: Ensure solution applies cloud-native standards for the selected cloud provider.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Cloud Architect / Technical Lead or N/A]\n\n### 6.1 Cloud-Native Standards\n\n**Well-Architected Framework Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Framework alignment documented. If Non-Compliant: Best practices not addressed. If Not Applicable: N/A. If Unknown: Best practices mentioned but specific framework unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document alignment with AWS Well-Architected, Azure Well-Architected, or Google Cloud Architecture Framework in Section 12]\n\n**Infrastructure as Code (IaC)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: IaC approach documented. If Non-Compliant: Infrastructure provisioning method not specified. If Not Applicable: N/A. If Unknown: Automation mentioned but tooling unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 8 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify IaC tool (Terraform, CloudFormation, ARM templates, etc.) in Section 4 or 8]\n\n**Scalability and Elasticity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Auto-scaling documented. If Non-Compliant: Scaling strategy not defined. If Not Applicable: Fixed capacity sufficient. If Unknown: Scaling mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 10 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define auto-scaling policies, scaling triggers, and capacity limits in Section 4 or 10]\n\n**Cost Optimization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cost optimization strategies documented. If Non-Compliant: Cost management not addressed. If Not Applicable: N/A. If Unknown: Cost considerations mentioned but strategies unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document reserved instances, spot instances, right-sizing strategies in Section 4 or 11]\n\n**Organizational Cloud Standards**: [PLACEHOLDER: User must provide organizational cloud guidelines]\n- Status: [Unknown]\n- Explanation: Organization-specific cloud standards must be validated against this architecture\n- Source: [External organizational documentation]\n- Note: Validate compliance with internal cloud governance policies, naming conventions, tagging standards, and approved service catalog\n\n**Key Guidelines Verification**:\n- Cloud service model (IaaS/PaaS/SaaS) documented: [Yes/No]\n- Network connectivity, security, monitoring, and backup defined: [Yes/No]\n- Cloud provider best practices applied: [Yes/No]\n- Infrastructure as Code implemented: [Yes/No]\n- [PLACEHOLDER: Additional organizational requirements]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAC6]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Key Cloud Architecture Terms**:\n\n- **Cloud Deployment Model**: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), or Software-as-a-Service (SaaS)\n- **Multi-Region**: Deployment across multiple geographic regions for redundancy and low latency\n- **Availability Zone**: Isolated data center within a cloud region\n- **Cloud Service Provider**: AWS, Azure, Google Cloud, or similar provider\n- **Resource Monitoring**: Observability of cloud resource usage and performance\n- **Cloud Best Practices**: Well-Architected Framework principles\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Abbreviations**:\n\n- **LAC**: Cloud Architecture (Lineamiento de Arquitectura Cloud)\n- **IaaS**: Infrastructure-as-a-Service\n- **PaaS**: Platform-as-a-Service\n- **SaaS**: Software-as-a-Service\n- **CDN**: Content Delivery Network\n- **VPC**: Virtual Private Cloud\n\n---\n\n### A.2 Validation Methodology\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=cloud-architecture -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Cloud Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Missing cloud provider justification | LAC1 Non-Compliant | Section 3 (Technology Stack) | Document provider selection rationale |\n| No multi-region strategy | LAC2 Non-Compliant | Section 10 (Non-Functional Requirements) | Define region deployment strategy |\n| Undefined backup/recovery policies | LAC5 Non-Compliant | Section 11 (Operational Considerations) | Document backup schedules and RTO/RPO |\n| Missing cost monitoring configuration | LAC4 Unknown | Section 11 (Operational Considerations) | Add cost tracking, budgets, and alerts |\n| No resource tagging strategy | LAC3 Unknown | Section 4 (Cloud & Deployment) | Define tagging taxonomy (environment, cost-center, owner) |\n| Infrastructure as Code not documented | LAC6 Unknown | Section 11 (Operational Considerations) | Specify IaC tooling (Terraform, CloudFormation, etc.) |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Cloud Architecture-Specific Examples**:\n\n**Example 1: Adding Cost Monitoring**\n- **Gap**: Missing cost monitoring configuration\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add cost monitoring to Section 11: CloudWatch billing alarms,\n   80% budget threshold, monthly cost reviews\"\n  ```\n- **Expected Outcome**: Section 11.X with CloudWatch alarms, thresholds, review schedule\n- **Impact**: LAC4 ‚Üí Compliant (+0.5 points)\n\n**Example 2: Multi-Region Strategy**\n- **Gap**: No multi-region deployment documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add multi-region deployment to Section 4:\n   primary us-east-1, secondary us-west-2, RTO 15 minutes,\n   automated failover with Route 53\"\n  ```\n- **Expected Outcome**: Section 4 with region strategy, failover mechanisms\n- **Impact**: LAC2 ‚Üí Compliant (+0.4 points)\n\n**Example 3: Well-Architected Alignment**\n- **Gap**: No AWS Well-Architected Framework mapping\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Create ADR in Section 12 mapping architecture to\n   AWS Well-Architected 5 pillars: Operational Excellence,\n   Security, Reliability, Performance, Cost Optimization\"\n  ```\n- **Expected Outcome**: New ADR with pillar mappings and trade-offs\n- **Impact**: LAC6 ‚Üí Compliant (+0.3 points)\n\n**Example 4: Resource Tagging Strategy**\n- **Gap**: No resource tagging strategy documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add resource tagging strategy to Section 4:\n   required tags (environment, application, cost-center, owner),\n   tag governance policy, automation via IaC\"\n  ```\n- **Expected Outcome**: Section 4 with tagging taxonomy, governance, enforcement\n- **Impact**: LAC3 ‚Üí Compliant (+0.3 points)\n\n**Example 5: Infrastructure as Code**\n- **Gap**: IaC tooling not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add Infrastructure as Code strategy to Section 11:\n   Terraform for infrastructure provisioning,\n   GitOps workflow with Terraform Cloud,\n   state management in S3 with DynamoDB locking\"\n  ```\n- **Expected Outcome**: Section 11 with IaC tooling, workflow, state management\n- **Impact**: LAC6 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required cloud architecture fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all data points\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Missing Documentation** (estimated impact: +0.4 points)\n   - Add cost monitoring and budget alerts to Section 11\n   - Document resource tagging strategy (environment, cost-center, owner) in Section 4\n   - Define rightsizing review schedule in Section 11\n   - Specify backup and disaster recovery policies in Section 11\n\n2. **Document Cloud Best Practices Alignment** (estimated impact: +0.3 points)\n   - Create ADR mapping to AWS/Azure/GCP Well-Architected Framework in Section 12\n   - Document 5 pillars alignment: Operational Excellence, Security, Reliability, Performance, Cost Optimization\n   - Add Infrastructure as Code strategy (Terraform/CloudFormation) to Section 11\n   - Define multi-region deployment strategy in Section 4\n\n3. **Enhance Cost Optimization** (estimated impact: +0.2 points)\n   - Document reserved instance vs on-demand strategy in Section 11\n   - Add cost breakdown by environment/service to Section 11\n   - Define cost optimization KPIs and review cadence\n   - Specify cost allocation tags and chargeback model\n\n**Priority Order**: LAC2 (multi-region) ‚Üí LAC4 (cost monitoring) ‚Üí LAC6 (IaC) ‚Üí LAC1 (provider justification) ‚Üí LAC3 (tagging) ‚Üí LAC5 (backup/recovery)\n\n**Estimated Final Score After Remediation**: 8.5-9.0/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with standardized template structure\n- Total: 6 validation data points across LAC1-LAC6 requirements\n\n**Version 1.0 (Previous)**:\n- Initial template with minimal appendix\n- Basic PLACEHOLDER approach\n- Limited source traceability\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=cloud-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=cloud-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=cloud-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=cloud-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=cloud-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.",
        "skills/architecture-compliance/templates/TEMPLATE_DATA_AI_ARCHITECTURE.md": "# Compliance Contract: Data & Analytics Architecture - AI\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 4, 5, 6, 7, 8, 9, 10, 11, 12)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=data-ai-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=data-ai-architecture -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAD1 | Data Quality | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect or N/A] |\n| LAD2 | Data Fabric Reuse | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect or N/A] |\n| LAD3 | Data Recovery | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Business Continuity Manager or N/A] |\n| LAD4 | Data Decoupling | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect or N/A] |\n| LAD5 | Data Scalability | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect or N/A] |\n| LAD6 | Data Integration | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Engineer or N/A] |\n| LAD7 | Regulatory Compliance | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Compliance Officer or N/A] |\n| LAD8 | Data Architecture Standards | Data | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect or N/A] |\n| LAIA1 | AI Model Governance | AI | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [AI/ML Architect or N/A] |\n| LAIA2 | AI Security and Reputation | AI | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [AI/ML Architect or N/A] |\n| LAIA3 | AI Hallucination Control | AI | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [AI/ML Architect or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Data Quality (LAD1 - Category: Data)\n\n**Requirement**: Implement quality control mechanisms and ensure data completeness throughout the data lifecycle.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Data Engineer or N/A]\n\n### 1.1 Data Quality Control Mechanisms\n\n**Quality Validation Framework**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Quality framework documented in ARCHITECTURE.md. If Non-Compliant: Quality control mechanisms not specified. If Not Applicable: Data quality not applicable. If Unknown: Quality mentioned but framework unclear]\n- Source: [ARCHITECTURE.md Section X.Y, lines A-B or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data quality validation framework including profiling, validation rules, and cleansing processes in Section 5 or 6]\n\n**Data Profiling Approach**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data profiling approach documented. If Non-Compliant: Profiling strategy not specified. If Not Applicable: N/A. If Unknown: Profiling mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data profiling strategy, tools, and frequency in Section 6]\n\n**Anomaly Detection Methods**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Anomaly detection documented. If Non-Compliant: Detection methods not specified. If Not Applicable: N/A. If Unknown: Anomaly detection mentioned but methods unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify anomaly detection algorithms, thresholds, and response procedures in Section 5 or 11]\n\n### 1.2 Data Completeness Tracking\n\n**Completeness Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Completeness metrics defined. If Non-Compliant: Metrics not specified. If Not Applicable: N/A. If Unknown: Completeness mentioned but metrics unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define completeness thresholds and measurement methods in Section 10 or 11]\n\n**Data Quality SLOs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Quality SLOs documented. If Non-Compliant: SLOs not defined. If Not Applicable: N/A. If Unknown: Quality targets mentioned but SLOs unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data quality service level objectives in Section 10]\n\n**Completeness Monitoring**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Monitoring approach documented. If Non-Compliant: Monitoring not specified. If Not Applicable: N/A. If Unknown: Monitoring mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document completeness monitoring dashboards and alerting in Section 11]\n\n### 1.3 Data Validation and Cleansing\n\n**Validation Rules**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Validation rules documented. If Non-Compliant: Rules not specified. If Not Applicable: N/A. If Unknown: Validation mentioned but rules unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define validation rules, constraints, and business logic in Section 6]\n\n**Cleansing Processes**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cleansing processes documented. If Non-Compliant: Processes not specified. If Not Applicable: N/A. If Unknown: Cleansing mentioned but processes unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data cleansing workflows, transformation rules, and remediation procedures in Section 6]\n\n**Rejection Handling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Rejection handling documented. If Non-Compliant: Handling not specified. If Not Applicable: N/A. If Unknown: Rejection mentioned but handling unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define rejection criteria, quarantine processes, and notification mechanisms in Section 6]\n\n### 1.4 Data Quality Monitoring\n\n**Quality Dashboards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Dashboards documented. If Non-Compliant: Dashboards not specified. If Not Applicable: N/A. If Unknown: Monitoring mentioned but dashboards unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify quality monitoring dashboards, metrics, and visualizations in Section 11]\n\n**Alerting Thresholds**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Alert thresholds documented. If Non-Compliant: Thresholds not defined. If Not Applicable: N/A. If Unknown: Alerting mentioned but thresholds unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define alert thresholds for quality metrics and escalation procedures in Section 11]\n\n**Remediation Workflows**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Remediation workflows documented. If Non-Compliant: Workflows not specified. If Not Applicable: N/A. If Unknown: Remediation mentioned but workflows unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document quality issue remediation workflows and ownership in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD1]\n\n---\n\n## 2. Data Fabric Reuse (LAD2 - Category: Data)\n\n**Requirement**: Verify that integration and availability mechanisms in the Data Fabric can be reused, including SOR ingestion and Data Product consumption.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Integration Lead or N/A]\n\n### 2.1 Data Fabric Integration\n\n**Data Fabric Connectivity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data Fabric connectivity documented. If Non-Compliant: Connectivity not specified. If Not Applicable: Data Fabric not used. If Unknown: Connection mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document Data Fabric integration endpoints, authentication, and network connectivity in Section 7]\n\n**Ingestion Patterns**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Ingestion patterns documented. If Non-Compliant: Patterns not specified. If Not Applicable: N/A. If Unknown: Ingestion mentioned but patterns unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define reusable ingestion patterns (batch, streaming, CDC) in Section 6]\n\n**Reusable Components**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Reusable components identified. If Non-Compliant: Components not specified. If Not Applicable: N/A. If Unknown: Components mentioned but reusability unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify reusable Data Fabric components and libraries in Section 5 or 8]\n\n### 2.2 SOR (System of Record) Ingestion\n\n**SOR Integration Method**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: SOR integration method documented. If Non-Compliant: Method not specified. If Not Applicable: No SOR integration. If Unknown: Integration mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document SOR integration approach, protocols, and connectors in Section 7]\n\n**Ingestion Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Ingestion frequency documented. If Non-Compliant: Frequency not specified. If Not Applicable: N/A. If Unknown: Ingestion mentioned but frequency unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define ingestion schedules and real-time vs batch strategies in Section 6]\n\n**Data Lineage Tracking**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Lineage tracking documented. If Non-Compliant: Tracking not specified. If Not Applicable: N/A. If Unknown: Lineage mentioned but tracking unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data lineage tracking mechanisms and tools in Section 6 or 8]\n\n### 2.3 Data Product Consumption\n\n**Data Product Catalog Access**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Catalog access documented. If Non-Compliant: Access not specified. If Not Applicable: No data product catalog. If Unknown: Catalog mentioned but access unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data product catalog access methods and permissions in Section 7]\n\n**Consumption APIs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Consumption APIs documented. If Non-Compliant: APIs not specified. If Not Applicable: N/A. If Unknown: APIs mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data product consumption APIs, contracts, and rate limits in Section 7]\n\n**Usage Patterns**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Usage patterns documented. If Non-Compliant: Patterns not specified. If Not Applicable: N/A. If Unknown: Usage mentioned but patterns unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data product usage patterns and consumption workflows in Section 6]\n\n### 2.4 Reusability Assessment\n\n**Existing Component Reuse**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Component reuse documented. If Non-Compliant: Reuse assessment not performed. If Not Applicable: No existing components. If Unknown: Reuse mentioned but assessment unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document assessment of existing Data Fabric component reusability in Section 5]\n\n**New Component Justification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Justification for new components documented. If Non-Compliant: Justification not provided. If Not Applicable: Only reusing existing components. If Unknown: New components mentioned but justification unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Justify any new components when existing Data Fabric capabilities are available in Section 12 (ADRs)]\n\n**Integration Standards Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Standards compliance documented. If Non-Compliant: Compliance not assessed. If Not Applicable: N/A. If Unknown: Standards mentioned but compliance unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document compliance with organizational Data Fabric integration standards in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD2]\n\n---\n\n## 3. Data Recovery (LAD3 - Category: Data)\n\n**Requirement**: Define recovery processes according to the Proposed Architecture, including recovery in case of main process failures.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Business Continuity Manager or N/A]\n\n### 3.1 Recovery Processes\n\n**Recovery Procedures**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Recovery procedures documented. If Non-Compliant: Procedures not defined. If Not Applicable: Recovery not required. If Unknown: Recovery mentioned but procedures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define step-by-step recovery procedures for data pipelines and storage in Section 11.3 or 11.4]\n\n**Failover Mechanisms**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Failover mechanisms documented. If Non-Compliant: Mechanisms not specified. If Not Applicable: N/A. If Unknown: Failover mentioned but mechanisms unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document automated failover mechanisms for data processing and storage in Section 11.4]\n\n**Restoration Workflows**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Restoration workflows documented. If Non-Compliant: Workflows not defined. If Not Applicable: N/A. If Unknown: Restoration mentioned but workflows unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data restoration workflows and validation procedures in Section 11.3]\n\n### 3.2 Recovery Time Objectives (RTO)\n\n**RTO Targets**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RTO targets documented. If Non-Compliant: RTO not defined. If Not Applicable: RTO not applicable. If Unknown: Recovery time mentioned but RTO unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define RTO targets for critical data pipelines and storage systems in Section 11.3]\n\n**Recovery Priority Tiers**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Priority tiers documented. If Non-Compliant: Tiers not defined. If Not Applicable: N/A. If Unknown: Prioritization mentioned but tiers unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define recovery priority tiers (Tier 1/2/3) based on business criticality in Section 11.3]\n\n**Recovery Automation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Automation documented. If Non-Compliant: Automation not specified. If Not Applicable: Manual recovery only. If Unknown: Automation mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document automated recovery capabilities and manual intervention points in Section 11.3 or 11.4]\n\n### 3.3 Recovery Point Objectives (RPO)\n\n**RPO Targets**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RPO targets documented. If Non-Compliant: RPO not defined. If Not Applicable: RPO not applicable. If Unknown: Data loss tolerance mentioned but RPO unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define RPO targets (maximum acceptable data loss window) in Section 11.3]\n\n**Data Loss Tolerance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data loss tolerance documented. If Non-Compliant: Tolerance not specified. If Not Applicable: N/A. If Unknown: Tolerance mentioned but thresholds unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document acceptable data loss thresholds for different data tiers in Section 11.3]\n\n**Backup Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup frequency documented. If Non-Compliant: Frequency not specified. If Not Applicable: Backups not required. If Unknown: Backups mentioned but frequency unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define backup frequency (continuous, hourly, daily) aligned with RPO targets in Section 11.3]\n\n### 3.4 Failure Scenario Planning\n\n**Main Process Failure Scenarios**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Failure scenarios documented. If Non-Compliant: Scenarios not identified. If Not Applicable: N/A. If Unknown: Failures mentioned but scenarios unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify main data pipeline and processing failure scenarios in Section 11.4]\n\n**Mitigation Strategies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Mitigation strategies documented. If Non-Compliant: Strategies not defined. If Not Applicable: N/A. If Unknown: Mitigation mentioned but strategies unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document failure mitigation strategies (redundancy, replication, circuit breakers) in Section 11.4]\n\n**Recovery Testing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Recovery testing documented. If Non-Compliant: Testing not specified. If Not Applicable: N/A. If Unknown: Testing mentioned but procedures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define recovery testing frequency and procedures (quarterly DR drills) in Section 11.3]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD3]\n\n---\n\n## 4. Data Decoupling (LAD4 - Category: Data)\n\n**Requirement**: Ensure separation of capabilities (ingestion, processing, storage, delivery) and separation of storage layer from processing layer.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Solution Architect or N/A]\n\n### 4.1 Capability Separation\n\n**Ingestion Decoupling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Ingestion decoupling documented. If Non-Compliant: Ingestion not decoupled. If Not Applicable: Single monolithic pipeline. If Unknown: Separation mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document separate ingestion layer with clear interfaces in Section 5 or 6]\n\n**Processing Decoupling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Processing decoupling documented. If Non-Compliant: Processing not decoupled. If Not Applicable: N/A. If Unknown: Separation mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document separate processing layer independent of ingestion and storage in Section 5 or 6]\n\n**Storage Decoupling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage decoupling documented. If Non-Compliant: Storage tightly coupled. If Not Applicable: N/A. If Unknown: Separation mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document storage layer abstraction and independence from processing in Section 5 or 8]\n\n**Delivery Decoupling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Delivery decoupling documented. If Non-Compliant: Delivery not decoupled. If Not Applicable: N/A. If Unknown: Separation mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document separate data delivery layer (APIs, exports) in Section 5 or 7]\n\n### 4.2 Storage-Processing Separation\n\n**Storage Layer Independence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage independence documented. If Non-Compliant: Storage coupled to processing. If Not Applicable: N/A. If Unknown: Independence mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document storage layer that can scale independently of processing in Section 8]\n\n**Processing Layer Independence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Processing independence documented. If Non-Compliant: Processing coupled to storage. If Not Applicable: N/A. If Unknown: Independence mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document processing layer that can scale independently of storage in Section 5]\n\n**Interface Contracts**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Interface contracts documented. If Non-Compliant: Contracts not defined. If Not Applicable: N/A. If Unknown: Interfaces mentioned but contracts unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define clear interface contracts between storage and processing layers in Section 5]\n\n### 4.3 Component Independence\n\n**Service Boundaries**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service boundaries documented. If Non-Compliant: Boundaries not defined. If Not Applicable: Monolithic architecture. If Unknown: Boundaries mentioned but definition unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define clear service boundaries for data components in Section 5]\n\n**API Contracts**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API contracts documented. If Non-Compliant: Contracts not specified. If Not Applicable: N/A. If Unknown: APIs mentioned but contracts unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API contracts between data components in Section 7]\n\n**Deployment Independence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Deployment independence documented. If Non-Compliant: Components deployed together. If Not Applicable: N/A. If Unknown: Independence mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document independent deployment capability for data components in Section 4]\n\n### 4.4 Scalability Independence\n\n**Independent Scaling Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Scaling policies documented. If Non-Compliant: Scaling not independent. If Not Applicable: Fixed capacity. If Unknown: Scaling mentioned but policies unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define independent auto-scaling policies for ingestion, processing, and storage in Section 10]\n\n**Resource Allocation Isolation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Resource isolation documented. If Non-Compliant: Resources shared without isolation. If Not Applicable: N/A. If Unknown: Isolation mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document resource allocation isolation between data layers in Section 4 or 10]\n\n**Performance Isolation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Performance isolation documented. If Non-Compliant: Performance not isolated. If Not Applicable: N/A. If Unknown: Isolation mentioned but mechanisms unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document performance isolation mechanisms (separate compute pools, throttling) in Section 10]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD4]\n\n---\n\n## 5. Data Scalability (LAD5 - Category: Data)\n\n**Requirement**: Design to handle growth and changes, accommodate data volume growth and evolution.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Infrastructure Engineer or N/A]\n\n### 5.1 Data Volume Scalability\n\n**Current Data Volume**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Current volume documented. If Non-Compliant: Volume not quantified. If Not Applicable: Data volume not tracked. If Unknown: Volume mentioned but not quantified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document current data volume (TB/PB) in Section 10]\n\n**Projected Growth**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Growth projection documented. If Non-Compliant: Projection not provided. If Not Applicable: Static data volume. If Unknown: Growth mentioned but projections unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document projected data growth (annual %) and volume projections in Section 10]\n\n**Scaling Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Scaling strategy documented. If Non-Compliant: Strategy not defined. If Not Applicable: Fixed capacity sufficient. If Unknown: Scaling mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data volume scaling strategy (horizontal partitioning, tiered storage) in Section 10]\n\n### 5.2 Processing Capacity Scalability\n\n**Current Throughput**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Current throughput documented. If Non-Compliant: Throughput not measured. If Not Applicable: Throughput not tracked. If Unknown: Processing mentioned but throughput unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document current processing throughput (records/sec, TPS) in Section 10]\n\n**Peak Capacity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Peak capacity documented. If Non-Compliant: Capacity not defined. If Not Applicable: N/A. If Unknown: Capacity mentioned but limits unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define peak processing capacity and system limits in Section 10]\n\n**Auto-Scaling Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Auto-scaling documented. If Non-Compliant: Auto-scaling not configured. If Not Applicable: Manual scaling only. If Unknown: Scaling mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document auto-scaling policies, triggers, and thresholds in Section 4 or 10]\n\n### 5.3 Schema Evolution\n\n**Schema Versioning**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Schema versioning documented. If Non-Compliant: Versioning not implemented. If Not Applicable: Static schema. If Unknown: Versioning mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define schema versioning strategy and registry in Section 6 or 8]\n\n**Backward Compatibility**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backward compatibility documented. If Non-Compliant: Compatibility not ensured. If Not Applicable: N/A. If Unknown: Compatibility mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document backward compatibility requirements and schema evolution rules in Section 6]\n\n**Migration Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Migration strategy documented. If Non-Compliant: Strategy not defined. If Not Applicable: No migrations required. If Unknown: Migration mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define schema migration procedures and rollback strategies in Section 11]\n\n### 5.4 Horizontal Scaling Strategy\n\n**Partitioning Approach**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Partitioning approach documented. If Non-Compliant: Partitioning not implemented. If Not Applicable: No partitioning required. If Unknown: Partitioning mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data partitioning strategy (range, hash, time-based) in Section 8]\n\n**Sharding Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Sharding strategy documented. If Non-Compliant: Sharding not implemented. If Not Applicable: Single instance sufficient. If Unknown: Sharding mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define sharding strategy and shard key selection in Section 8]\n\n**Distributed Processing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Distributed processing documented. If Non-Compliant: Processing not distributed. If Not Applicable: Single-node processing sufficient. If Unknown: Distribution mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document distributed processing frameworks and parallelization strategy in Section 5 or 8]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD5]\n\n---\n\n## 6. Data Integration (LAD6 - Category: Data)\n\n**Requirement**: Define synchronization and replication mechanisms, structures and formats, and maintain data consistency and updating.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Integration Engineer or N/A]\n\n### 6.1 Synchronization Mechanisms\n\n**Sync Methods**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Sync methods documented. If Non-Compliant: Methods not specified. If Not Applicable: No synchronization required. If Unknown: Sync mentioned but methods unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define synchronization methods (real-time, batch, CDC) in Section 6 or 7]\n\n**Sync Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Sync frequency documented. If Non-Compliant: Frequency not defined. If Not Applicable: N/A. If Unknown: Frequency mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document synchronization frequency and schedules in Section 6]\n\n**Conflict Resolution**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Conflict resolution documented. If Non-Compliant: Resolution not defined. If Not Applicable: Conflicts not possible. If Unknown: Resolution mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define conflict resolution strategies (last-write-wins, merge, manual) in Section 6]\n\n### 6.2 Replication Strategy\n\n**Replication Type**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Replication type documented. If Non-Compliant: Type not specified. If Not Applicable: No replication. If Unknown: Replication mentioned but type unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define replication type (active-passive, active-active, multi-master) in Section 8]\n\n**Replication Lag Tolerance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Lag tolerance documented. If Non-Compliant: Tolerance not defined. If Not Applicable: N/A. If Unknown: Lag mentioned but tolerance unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define acceptable replication lag thresholds in Section 10]\n\n**Consistency Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Consistency model documented. If Non-Compliant: Model not specified. If Not Applicable: N/A. If Unknown: Consistency mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define consistency model (strong, eventual, causal) in Section 8 or 12]\n\n### 6.3 Data Formats and Structures\n\n**Standard Data Formats**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data formats documented. If Non-Compliant: Formats not standardized. If Not Applicable: N/A. If Unknown: Formats mentioned but standards unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define standard data formats (JSON, Avro, Parquet, ORC) in Section 6 or 8]\n\n**Schema Registry**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Schema registry documented. If Non-Compliant: Registry not implemented. If Not Applicable: Schema registry not required. If Unknown: Registry mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document schema registry solution and versioning approach in Section 8]\n\n**Transformation Pipelines**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Transformation pipelines documented. If Non-Compliant: Pipelines not defined. If Not Applicable: No transformations required. If Unknown: Transformations mentioned but pipelines unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data transformation pipelines and logic in Section 6]\n\n### 6.4 Data Consistency Management\n\n**Consistency Guarantees**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Consistency guarantees documented. If Non-Compliant: Guarantees not defined. If Not Applicable: N/A. If Unknown: Consistency mentioned but guarantees unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define consistency guarantees and SLAs in Section 10]\n\n**Eventual Consistency Handling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Eventual consistency handling documented. If Non-Compliant: Handling not defined. If Not Applicable: Strong consistency used. If Unknown: Handling mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document eventual consistency handling and reconciliation procedures in Section 6]\n\n**Data Validation Checkpoints**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Validation checkpoints documented. If Non-Compliant: Checkpoints not defined. If Not Applicable: N/A. If Unknown: Validation mentioned but checkpoints unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data validation checkpoints across integration pipeline in Section 6]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD6]\n\n---\n\n## 7. Regulatory Compliance (LAD7 - Category: Data)\n\n**Requirement**: Identify and establish compliance controls and audits regarding impacts to control structures. Guarantee monitoring and regulatory compliance.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Compliance Officer / Data Governance Lead or N/A]\n\n### 7.1 Compliance Requirements Identification\n\n**Applicable Regulations**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Applicable regulations documented. If Non-Compliant: Regulations not identified. If Not Applicable: No regulatory requirements. If Unknown: Regulations mentioned but not clearly identified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify applicable regulations (GDPR, CCPA, HIPAA, BCBS 239, SOX, etc.) in Section 9]\n\n**Jurisdiction Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Jurisdiction requirements documented. If Non-Compliant: Requirements not specified. If Not Applicable: Single jurisdiction. If Unknown: Jurisdictions mentioned but requirements unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document jurisdiction-specific compliance requirements in Section 9]\n\n**Industry Standards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Industry standards documented. If Non-Compliant: Standards not identified. If Not Applicable: No industry standards apply. If Unknown: Standards mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document applicable industry standards (ISO 27001, PCI-DSS, etc.) in Section 9]\n\n### 7.2 Compliance Controls\n\n**Access Controls for Sensitive Data**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Access controls documented. If Non-Compliant: Controls not implemented. If Not Applicable: No sensitive data. If Unknown: Controls mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document RBAC, ABAC, and data classification-based access controls in Section 9]\n\n**Audit Logging**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Audit logging documented. If Non-Compliant: Logging not implemented. If Not Applicable: Audit logging not required. If Unknown: Logging mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document audit logging mechanisms, retention, and immutability in Section 9 or 11]\n\n**Retention Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Retention policies documented. If Non-Compliant: Policies not defined. If Not Applicable: N/A. If Unknown: Retention mentioned but policies unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data retention policies aligned with regulatory requirements in Section 11]\n\n### 7.3 Compliance Monitoring\n\n**Compliance Dashboards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Dashboards documented. If Non-Compliant: Dashboards not implemented. If Not Applicable: Manual monitoring only. If Unknown: Monitoring mentioned but dashboards unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document compliance monitoring dashboards and metrics in Section 11]\n\n**Automated Compliance Checks**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Automated checks documented. If Non-Compliant: Checks not automated. If Not Applicable: Manual compliance only. If Unknown: Checks mentioned but automation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define automated compliance validation checks and frequency in Section 11]\n\n**Violation Alerting**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Alerting documented. If Non-Compliant: Alerting not configured. If Not Applicable: N/A. If Unknown: Alerting mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document compliance violation alerting and escalation procedures in Section 11]\n\n### 7.4 Audit and Reporting\n\n**Audit Trail Mechanisms**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Audit trails documented. If Non-Compliant: Mechanisms not implemented. If Not Applicable: Audit trails not required. If Unknown: Mechanisms mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document audit trail mechanisms for data access and modifications in Section 9 or 11]\n\n**Compliance Reporting Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Reporting frequency documented. If Non-Compliant: Frequency not defined. If Not Applicable: N/A. If Unknown: Reporting mentioned but frequency unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define compliance reporting frequency (monthly, quarterly, annual) in Section 11]\n\n**Regulatory Submission Processes**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Submission processes documented. If Non-Compliant: Processes not defined. If Not Applicable: No regulatory submissions. If Unknown: Submissions mentioned but processes unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document regulatory submission procedures and responsible parties in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD7]\n\n---\n\n## 8. Data Architecture Standards (LAD8 - Category: Data)\n\n**Requirement**: Establish database engines and data models according to the institutional catalog. Guarantee performance and use of selected data storage platforms.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Database Administrator or N/A]\n\n### 8.1 Database Engine Selection\n\n**Approved Database Engines**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database engines documented and from approved catalog. If Non-Compliant: Engines not from institutional catalog. If Not Applicable: No institutional catalog exists. If Unknown: Engines documented but catalog compliance unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document database engines and verify against institutional catalog in Section 8]\n\n**Engine Justification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Engine selection justified. If Non-Compliant: Justification not provided. If Not Applicable: Default catalog choice. If Unknown: Selection mentioned but justification unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document justification for database engine selection in Section 12 (ADRs)]\n\n**Catalog Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Catalog compliance verified. If Non-Compliant: Non-catalog engines used without exception. If Not Applicable: No catalog requirements. If Unknown: Compliance mentioned but not verified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify database engine compliance with institutional catalog or request exception in Section 12]\n\n### 8.2 Data Model Design\n\n**Data Modeling Approach**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Modeling approach documented. If Non-Compliant: Approach not specified. If Not Applicable: No data modeling required. If Unknown: Modeling mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data modeling approach (relational, NoSQL, graph, time-series) in Section 8]\n\n**Normalization Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Normalization strategy documented. If Non-Compliant: Strategy not defined. If Not Applicable: Non-relational database. If Unknown: Normalization mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define normalization level (3NF, denormalized) and rationale in Section 8 or 12]\n\n**Schema Design Patterns**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Design patterns documented. If Non-Compliant: Patterns not specified. If Not Applicable: N/A. If Unknown: Patterns mentioned but not clearly defined]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document schema design patterns (star schema, vault, etc.) in Section 8]\n\n### 8.3 Storage Platform Performance\n\n**Performance SLOs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Performance SLOs documented. If Non-Compliant: SLOs not defined. If Not Applicable: Performance not critical. If Unknown: Performance mentioned but SLOs unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define storage performance SLOs (IOPS, throughput, latency) in Section 10]\n\n**Query Latency Targets**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Latency targets documented. If Non-Compliant: Targets not defined. If Not Applicable: N/A. If Unknown: Latency mentioned but targets unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define query latency targets (p50, p95, p99) in Section 10]\n\n**Throughput Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Throughput requirements documented. If Non-Compliant: Requirements not specified. If Not Applicable: N/A. If Unknown: Throughput mentioned but requirements unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define storage throughput requirements (MB/s, TPS) in Section 10]\n\n### 8.4 Institutional Catalog Compliance\n\n**Catalog Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Catalog alignment verified. If Non-Compliant: Non-catalog technologies used. If Not Applicable: No institutional catalog. If Unknown: Alignment mentioned but not verified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify all data technologies align with institutional catalog in Section 8]\n\n**Exception Requests**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Exception requests documented and approved. If Non-Compliant: Non-catalog use without exception. If Not Applicable: All catalog-compliant. If Unknown: Exceptions mentioned but approval unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document exception requests for non-catalog technologies in Section 12 (ADRs)]\n\n**Standardization Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Standardization compliance documented. If Non-Compliant: Non-standard practices used. If Not Applicable: No standards apply. If Unknown: Compliance mentioned but not verified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify compliance with institutional data architecture standards in Section 8]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAD8]\n\n---\n\n## 9. AI Model Governance (LAIA1 - Category: AI)\n\n**Requirement**: Define embedding and foundational AI model under the bank's tenant. Guarantee secure data handling and perimetral security in the Cloud.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [AI/ML Architect / Data Scientist Lead or N/A]\n\n### 9.1 AI Model Catalog\n\n**Foundational Models**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Foundational models documented. If Non-Compliant: Models not specified. If Not Applicable: No foundational models used. If Unknown: Models mentioned but not clearly identified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document foundational models (GPT-4, Claude, BERT, etc.) and versions in Section 5 or 8]\n\n**Embedding Models**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Embedding models documented. If Non-Compliant: Models not specified. If Not Applicable: No embeddings used. If Unknown: Embeddings mentioned but models unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document embedding models and dimensions in Section 5 or 8]\n\n**Custom Models**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Custom models documented. If Non-Compliant: Models not documented. If Not Applicable: Only using pre-trained models. If Unknown: Custom models mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document custom model architectures, training data, and versions in Section 5]\n\n### 9.2 Tenant Isolation\n\n**Model Deployment Tenant**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Deployment tenant documented. If Non-Compliant: Tenant not specified. If Not Applicable: Single-tenant environment. If Unknown: Tenant mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI model deployment under bank's dedicated tenant in Section 4 or 5]\n\n**Data Residency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data residency documented. If Non-Compliant: Residency not specified. If Not Applicable: No residency requirements. If Unknown: Residency mentioned but location unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI data residency requirements and compliance in Section 4 or 9]\n\n**Isolation Boundaries**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Isolation boundaries documented. If Non-Compliant: Boundaries not defined. If Not Applicable: N/A. If Unknown: Isolation mentioned but boundaries unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document tenant isolation boundaries (network, compute, storage) in Section 4 or 9]\n\n### 9.3 Data Handling Security\n\n**Training Data Encryption**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Training data encryption documented. If Non-Compliant: Encryption not implemented. If Not Applicable: No training data. If Unknown: Encryption mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document training data encryption (at-rest, in-transit) in Section 9]\n\n**Model Artifact Security**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Artifact security documented. If Non-Compliant: Security not implemented. If Not Applicable: N/A. If Unknown: Security mentioned but measures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document model artifact storage security and access controls in Section 9]\n\n**Inference Data Protection**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Inference data protection documented. If Non-Compliant: Protection not implemented. If Not Applicable: N/A. If Unknown: Protection mentioned but measures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document inference request/response data protection in Section 9]\n\n### 9.4 Perimetral Security\n\n**Model API Access Controls**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API access controls documented. If Non-Compliant: Controls not implemented. If Not Applicable: No API exposure. If Unknown: Controls mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document model API authentication, authorization, and rate limiting in Section 9]\n\n**Network Segmentation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Network segmentation documented. If Non-Compliant: Segmentation not implemented. If Not Applicable: N/A. If Unknown: Segmentation mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI infrastructure network segmentation in Section 4 or 9]\n\n**Inference Endpoint Security**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Endpoint security documented. If Non-Compliant: Security not implemented. If Not Applicable: No inference endpoints. If Unknown: Security mentioned but measures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document inference endpoint security (TLS, authentication, DDoS protection) in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAIA1]\n\n---\n\n## 10. AI Security and Reputation (LAIA2 - Category: AI)\n\n**Requirement**: Implement guardrail node (Prompt + AI Model). Guarantee the security of AI use in Gen AI applications and agents.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [AI/ML Architect / Security Architect or N/A]\n\n### 10.1 Guardrail Implementation\n\n**Guardrail Architecture**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Guardrail architecture documented. If Non-Compliant: Guardrails not implemented. If Not Applicable: Guardrails not required. If Unknown: Architecture mentioned but design unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document guardrail node architecture (prompt filtering, response filtering) in Section 5 or 9]\n\n**Guardrail Rules**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Guardrail rules documented. If Non-Compliant: Rules not defined. If Not Applicable: N/A. If Unknown: Rules mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define guardrail rules (content policies, toxicity filters) in Section 9]\n\n**Enforcement Mechanisms**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Enforcement mechanisms documented. If Non-Compliant: Mechanisms not implemented. If Not Applicable: N/A. If Unknown: Enforcement mentioned but mechanisms unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document guardrail enforcement mechanisms (blocking, logging, alerting) in Section 5 or 9]\n\n### 10.2 Prompt Security\n\n**Prompt Injection Prevention**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Prevention measures documented. If Non-Compliant: Measures not implemented. If Not Applicable: N/A. If Unknown: Prevention mentioned but measures unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document prompt injection prevention techniques in Section 9]\n\n**Prompt Sanitization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Sanitization documented. If Non-Compliant: Sanitization not implemented. If Not Applicable: N/A. If Unknown: Sanitization mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document prompt sanitization and validation procedures in Section 9]\n\n**Input Validation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Input validation documented. If Non-Compliant: Validation not implemented. If Not Applicable: N/A. If Unknown: Validation mentioned but rules unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define input validation rules and constraints in Section 9]\n\n### 10.3 Response Security\n\n**Output Filtering**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Output filtering documented. If Non-Compliant: Filtering not implemented. If Not Applicable: N/A. If Unknown: Filtering mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI response filtering mechanisms in Section 9]\n\n**PII Detection**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: PII detection documented. If Non-Compliant: Detection not implemented. If Not Applicable: No PII risk. If Unknown: Detection mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document PII detection and handling in AI responses in Section 9]\n\n**Sensitive Information Redaction**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Redaction documented. If Non-Compliant: Redaction not implemented. If Not Applicable: N/A. If Unknown: Redaction mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define sensitive information redaction procedures in Section 9]\n\n### 10.4 Gen AI Application Security\n\n**Agent Authentication**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authentication documented. If Non-Compliant: Authentication not implemented. If Not Applicable: No agents. If Unknown: Authentication mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI agent authentication mechanisms in Section 9]\n\n**Agent Authorization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authorization documented. If Non-Compliant: Authorization not implemented. If Not Applicable: N/A. If Unknown: Authorization mentioned but controls unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI agent authorization and access control policies in Section 9]\n\n**Usage Monitoring**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Usage monitoring documented. If Non-Compliant: Monitoring not implemented. If Not Applicable: N/A. If Unknown: Monitoring mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI usage monitoring, logging, and anomaly detection in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAIA2]\n\n---\n\n## 11. AI Hallucination Control (LAIA3 - Category: AI)\n\n**Requirement**: Implement AI inference evaluation method. Visualize and prevent random generation phenomena, mitigate hallucination error. Report with Evaluation Metrics.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [AI/ML Architect / ML Engineer or N/A]\n\n### 11.1 Inference Evaluation Method\n\n**Evaluation Framework**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Evaluation framework documented. If Non-Compliant: Framework not implemented. If Not Applicable: Evaluation not required. If Unknown: Framework mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document AI inference evaluation framework and methodology in Section 5 or 11]\n\n**Ground Truth Validation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Validation approach documented. If Non-Compliant: Validation not implemented. If Not Applicable: N/A. If Unknown: Validation mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document ground truth validation procedures and datasets in Section 5 or 11]\n\n**Confidence Scoring**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Confidence scoring documented. If Non-Compliant: Scoring not implemented. If Not Applicable: N/A. If Unknown: Scoring mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document confidence scoring mechanisms and thresholds in Section 5]\n\n### 11.2 Hallucination Detection\n\n**Hallucination Detection Methods**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Detection methods documented. If Non-Compliant: Methods not implemented. If Not Applicable: Hallucination not a concern. If Unknown: Detection mentioned but methods unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document hallucination detection techniques (consistency checks, fact verification) in Section 5 or 11]\n\n**Factuality Verification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Verification documented. If Non-Compliant: Verification not implemented. If Not Applicable: N/A. If Unknown: Verification mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document factuality verification mechanisms and knowledge sources in Section 5]\n\n**Source Grounding**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Source grounding documented. If Non-Compliant: Grounding not implemented. If Not Applicable: N/A. If Unknown: Grounding mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document source grounding and citation mechanisms in Section 5]\n\n### 11.3 Evaluation Metrics Reporting\n\n**Regression Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Regression metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document regression metrics (MSE, RMSE, MAE) if applicable in Section 11]\n\n**Classification Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Classification metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document classification metrics (F1, precision, recall, accuracy) in Section 11]\n\n**Clustering Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Clustering metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document clustering metrics (silhouette score, Davies-Bouldin) if applicable in Section 11]\n\n**Explained Variance Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Variance metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document explained variance metrics if applicable in Section 11]\n\n**Perplexity Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Perplexity metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document perplexity metrics for language models in Section 11]\n\n**NLG Metrics (BLEU, ROUGE)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: NLG metrics documented. If Non-Compliant: Metrics not tracked. If Not Applicable: Not applicable to use case. If Unknown: Metrics mentioned but not specified]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document BLEU, ROUGE, and other NLG metrics for generation quality in Section 11]\n\n### 11.4 Mitigation Strategies\n\n**Hallucination Mitigation Techniques**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Mitigation techniques documented. If Non-Compliant: Techniques not implemented. If Not Applicable: N/A. If Unknown: Mitigation mentioned but techniques unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document hallucination mitigation strategies (temperature tuning, prompt engineering) in Section 5]\n\n**Model Fine-Tuning**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Fine-tuning documented. If Non-Compliant: Fine-tuning not performed. If Not Applicable: Pre-trained model only. If Unknown: Fine-tuning mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document model fine-tuning procedures and datasets in Section 5]\n\n**Retrieval Augmentation (RAG)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RAG implementation documented. If Non-Compliant: RAG not implemented. If Not Applicable: RAG not required. If Unknown: RAG mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document Retrieval Augmented Generation architecture and knowledge sources in Section 5]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAIA3]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Key Data & AI Architecture Terms**:\n\n- **Data Quality**: Accuracy, completeness, consistency, and timeliness of data\n- **Data Governance**: Policies, procedures, and standards for data management\n- **Data Catalog**: Centralized repository of metadata describing available datasets\n- **Data Lineage**: Documentation of data origin, transformations, and movement\n- **AI Model Governance**: Oversight of AI model development, deployment, and monitoring\n- **AI Hallucination Control**: Mechanisms to detect and prevent AI-generated false information\n- **Data Lake**: Centralized repository storing structured and unstructured data\n- **Master Data Management (MDM)**: Process to ensure single source of truth for critical data\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Abbreviations**:\n\n- **LAD**: Data Architecture (Lineamiento de Arquitectura de Datos)\n- **LAIA**: AI Architecture (Lineamiento de Arquitectura de IA)\n- **MDM**: Master Data Management\n- **ETL**: Extract, Transform, Load\n- **API**: Application Programming Interface\n- **ML**: Machine Learning\n- **AI**: Artificial Intelligence\n- **LLM**: Large Language Model\n\n---\n\n### A.2 Validation Methodology\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=data-ai-architecture -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Data & AI Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Missing data quality metrics | LAD1 Non-Compliant | Section 6 (Data Model) | Define data quality KPIs and validation rules |\n| Undefined data governance policies | LAD2 Non-Compliant | Section 11 (Operational Considerations) | Document data access controls and policies |\n| No AI model governance framework | LAIA1 Non-Compliant | Section 6 (AI/ML Components) | Establish model approval and monitoring process |\n| Missing AI hallucination controls | LAIA3 Non-Compliant | Section 6 (AI/ML Components) | Implement validation and grounding mechanisms |\n| Data lineage not documented | LAD2 Unknown | Section 6 (Data Model) | Add data lineage tracking, upstream/downstream dependencies |\n| AI model monitoring undefined | LAIA2 Unknown | Section 6 or 11 (AI/ML/Operational) | Define model performance metrics, drift detection, retraining triggers |\n| Data retention policies missing | LAD2 Unknown | Section 11 (Operational Considerations) | Specify retention periods, archival strategy, compliance requirements |\n| AI bias mitigation not specified | LAIA3 Unknown | Section 6 (AI/ML Components) | Document bias detection, fairness metrics, mitigation strategies |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Data & AI Architecture-Specific Examples**:\n\n**Example 1: Data Quality Metrics and Validation**\n- **Gap**: Missing data quality metrics\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add data quality framework to Section 6:\n   Completeness: 95% minimum for critical fields,\n   Accuracy: 98% validation against source systems,\n   Consistency: cross-system validation rules,\n   Timeliness: data freshness SLA < 15 minutes,\n   Great Expectations library for automated validation\"\n  ```\n- **Expected Outcome**: Section 6 with data quality KPIs, validation rules, monitoring tools\n- **Impact**: LAD1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: AI Model Governance Framework**\n- **Gap**: No AI model governance framework\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add AI model governance to Section 6:\n   Model approval: peer review + compliance review before production,\n   Model registry: MLflow for versioning and lineage,\n   Performance monitoring: accuracy, precision, recall tracked daily,\n   Retraining triggers: accuracy drop > 5% or drift detection,\n   Model cards: documentation for explainability and bias assessment\"\n  ```\n- **Expected Outcome**: Section 6 with governance framework, approval process, monitoring\n- **Impact**: LAIA1 ‚Üí Compliant (+0.6 points)\n\n**Example 3: AI Hallucination Controls**\n- **Gap**: Missing AI hallucination controls for LLM applications\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add hallucination controls to Section 6:\n   Grounding: RAG (Retrieval-Augmented Generation) with vector DB,\n   Validation: confidence scoring with threshold > 0.85,\n   Citation: source attribution for all generated content,\n   Human-in-the-loop: review for high-risk decisions,\n   Guardrails: NeMo Guardrails for prompt injection prevention\"\n  ```\n- **Expected Outcome**: Section 6 with RAG architecture, validation mechanisms, guardrails\n- **Impact**: LAIA3 ‚Üí Compliant (+0.5 points)\n\n**Example 4: Data Lineage and Governance**\n- **Gap**: Data lineage not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add data lineage to Section 6:\n   Lineage tool: Apache Atlas or AWS Glue Data Catalog,\n   Tracking: upstream sources, transformations, downstream consumers,\n   Data catalog: searchable metadata with business glossary,\n   Access controls: RBAC with attribute-based policies,\n   Retention: PII 30 days, analytics data 7 years, compliance with GDPR\"\n  ```\n- **Expected Outcome**: Section 6 with lineage tracking, catalog, governance policies\n- **Impact**: LAD2 ‚Üí Compliant (+0.5 points)\n\n**Example 5: AI Model Monitoring and Drift Detection**\n- **Gap**: AI model monitoring undefined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add model monitoring to Section 6 or 11:\n   Performance metrics: accuracy, F1 score, AUC tracked hourly,\n   Data drift: KL divergence monitoring on input distributions,\n   Concept drift: prediction distribution monitoring,\n   Alerting: Slack notification when accuracy < 90% or drift detected,\n   Auto-retraining: triggered on drift with approval gate\"\n  ```\n- **Expected Outcome**: Section 6/11 with monitoring metrics, drift detection, alerting\n- **Impact**: LAIA2 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required data and AI fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all data and AI controls\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Data Governance and Quality** (estimated impact: +0.5 points)\n   - Define data quality metrics: completeness, accuracy, consistency, timeliness (Section 6)\n   - Document data governance policies: access controls, RBAC, data classification (Section 11)\n   - Add data lineage tracking with upstream/downstream dependencies (Section 6)\n   - Specify data retention policies with compliance requirements (GDPR, CCPA) in Section 11\n   - Define data catalog with searchable metadata and business glossary (Section 6)\n\n2. **Establish AI Model Governance and Controls** (estimated impact: +0.6 points)\n   - Create AI model governance framework: approval, versioning, monitoring (Section 6)\n   - Implement hallucination controls: RAG, validation, citation, guardrails (Section 6)\n   - Add model monitoring: performance metrics, drift detection, retraining triggers (Section 6/11)\n   - Document bias mitigation: fairness metrics, bias detection, mitigation strategies (Section 6)\n   - Specify model explainability: SHAP, LIME, model cards for transparency (Section 6)\n\n3. **Enhance Data Security and Compliance** (estimated impact: +0.2 points)\n   - Document data encryption: at-rest (AES-256), in-transit (TLS 1.3) in Section 9\n   - Add PII/sensitive data handling with tokenization or anonymization (Section 9)\n   - Define data masking policies for non-production environments (Section 9/11)\n   - Specify compliance certifications: SOC 2, ISO 27001, GDPR, HIPAA (Section 9)\n   - Add data breach response procedures (Section 11)\n\n**Priority Order**: LAD1 (data quality) ‚Üí LAIA1 (model governance) ‚Üí LAIA3 (hallucination controls) ‚Üí LAD2 (data governance) ‚Üí LAIA2 (model monitoring)\n\n**Estimated Final Score After Remediation**: 8.4-8.9/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with standardized template structure\n- Separated Data (LAD1-LAD8) and AI (LAIA1-LAIA3) requirements\n- Total: 11 validation data points (8 Data + 3 AI)\n\n**Version 1.0 (Previous)**:\n- Initial template with minimal appendix\n- Basic PLACEHOLDER approach\n- Limited source traceability\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=data-ai-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=data-ai-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=data-ai-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=data-ai-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=data-ai-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_DEVELOPMENT_ARCHITECTURE.md": "# Compliance Contract: Development Architecture\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 3, 5, 8, 11, 12)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=development-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=development-architecture -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LADES1 | Best Practices Adoption (Technology Stack Alignment) | Development Architecture | [STATUS] | Section 8 | Solution Architect |\n| LADES2 | Architecture Debt Impact (Exception Handling) | Development Architecture | [STATUS] | Section 8, 12 | Technical Lead |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n**Stack Validation**: [VALIDATION_SUMMARY] (**MANDATORY** - Contract cannot be approved without completed validation)\n\n**Dynamic Field Instructions**:\n- `[VALIDATION_SUMMARY]`: If `validation_results.overall_status == \"PASS\"` ‚Üí \"‚úÖ PASS (pass_count PASS, fail_count FAIL, na_count N/A, unknown_count UNKNOWN)\", else if \"FAIL\" ‚Üí \"‚ùå FAIL (pass_count PASS, fail_count FAIL, na_count N/A, unknown_count UNKNOWN) - See LADES1.6 for details\", else ‚Üí \"PENDING - Validation not performed\"\n\n**CRITICAL - Compliance Score Calculation**:\nWhen calculating the Compliance Score in validation_results, N/A items MUST be included in the numerator:\n- Compliance Score = (PASS items + N/A items + EXCEPTION items) / (Total items) √ó 10\n- N/A items count as fully compliant (10 points each)\n- Example: 6 PASS, 5 N/A, 0 FAIL, 0 UNKNOWN ‚Üí (6+5)/11 √ó 10 = 10.0/10 (100%)\n- Add note in contract output: \"Note: N/A items counted as fully compliant (included in compliance score)\"\n\n---\n\n## 1. Best Practices Adoption - Technology Stack Alignment (LADES1)\n\n**Requirement**: The solution must be aligned with the defined technology stack (frameworks, versions, tools, libraries). All technology choices must comply with organizational standards and authorized catalogs.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Solution Architect / Technical Lead or N/A]\n\n**External Validation Required**: ‚ö†Ô∏è **MANDATORY** - Stack Validation Checklist (STACK_VALIDATION_CHECKLIST.md) must be completed before contract approval\n\n### 1.1 Backend Technology Stack Alignment\n\n**Backend Language and Framework**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backend stack documented and matches authorized catalog (Java 11/17 + Spring Boot OR .NET Core 3.1/.NET 6/7 + ASP.NET Core). Versions are current and supported. If Non-Compliant: Backend technology not in authorized stack or versions deprecated. If Not Applicable: No backend component. If Unknown: Backend mentioned but versions unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Languages, Frameworks), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify against Stack Validation Checklist Section 1 (Java Backend) or Section 2 (.NET Backend). Document framework version, language version, and justify if deviation exists. Authorized: Java 11/17, .NET Core 3.1/.NET 6/.NET 7]\n\n**Backend Tools and Libraries**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Build tools, testing frameworks, and libraries documented and authorized (Maven/Gradle for Java, NuGet for .NET, SonarQube, JUnit/xUnit/NUnit, OpenAPI/Swagger). If Non-Compliant: Tools not specified or unapproved libraries used. If Unknown: Tools mentioned but approval status unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Frameworks & Libraries), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Cross-reference with authorized library catalog. Document all third-party libraries and verify chapter approval. Include version numbers. Checklist items: Maven/Gradle (Java), NuGet (.NET), SonarQube, JUnit/xUnit/NUnit, OpenAPI/Swagger]\n\n### 1.2 Frontend Technology Stack Alignment (if applicable)\n\n**Frontend Framework**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Frontend framework documented and authorized (Angular v12+, React v17+, Vue.js v3+). Version is current and supported. If Non-Compliant: Framework not in authorized list or deprecated version. If Not Applicable: No frontend component. If Unknown: Framework mentioned but version unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Frontend) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify against Stack Validation Checklist Section 3 (Frontend). Document framework version and architecture pattern (SPA/Micro-Frontends). Authorized frameworks: Angular v12+, React v17+, Vue.js v3+]\n\n**Frontend Language and Tools**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: TypeScript or JavaScript ES6+ documented with approved tooling (NPM/Yarn, Webpack, Jest, Cypress). If Non-Compliant: Language version or tools not authorized. If Not Applicable: No frontend. If Unknown: Tools mentioned but versions unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Frontend Tools) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document language version (TypeScript version or JavaScript ES6+), build tools, testing frameworks. Verify against checklist Section 3. Authorized: TypeScript/JavaScript ES6+, NPM/Yarn, Webpack, Jest, Cypress]\n\n### 1.3 Infrastructure and Deployment Alignment\n\n**Container Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Container deployment documented and authorized (Docker + Kubernetes: AKS/EKS/GKE/OpenShift). Versions are current and supported. If Non-Compliant: Container platform not authorized or missing. If Not Applicable: Non-containerized deployment. If Unknown: Containers mentioned but platform unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture ‚Üí Deployment Architecture) or Section 8 (Infrastructure), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document container runtime (Docker version), orchestration platform (Kubernetes variant: AKS/EKS/GKE/OpenShift), and verify authorization. Include Helm/chart management strategy. Checklist: Docker + Kubernetes (AKS/EKS/GKE/OpenShift)]\n\n**Database Platform and Version**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database platform documented and in authorized catalog (PostgreSQL, SQL Server, Oracle, MongoDB with approved versions). Version is current and not EOL. If Non-Compliant: Database not authorized or version EOL. If Not Applicable: Stateless application. If Unknown: Database mentioned but version unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Databases), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify against Stack Validation Checklist Section 4 (Other Stacks ‚Üí Databases). Document platform, version, and EOL status. Authorized databases: PostgreSQL, SQL Server, Oracle, MongoDB]\n\n### 1.4 API and Integration Standards\n\n**API Standards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: APIs documented and comply with standards (OpenAPI 3.0, REST, gRPC). API specifications are versioned and documented. If Non-Compliant: API design does not follow standards. If Not Applicable: No APIs. If Unknown: APIs mentioned but standard unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points) or Section 8 (Technology Stack), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API specification format (OpenAPI/Swagger), protocol (REST/gRPC), and version. Ensure OpenAPI 3.0 compliance for REST APIs. Checklist: OpenAPI 3.0, REST, gRPC]\n\n### 1.5 CI/CD and Automation Tools\n\n**CI/CD Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: CI/CD tooling documented and authorized (Azure DevOps, Jenkins, GitHub Actions). Pipeline configuration follows best practices. If Non-Compliant: CI/CD platform not approved or missing. If Unknown: CI/CD mentioned but platform unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí CI/CD) or Section 8 (Technology Stack ‚Üí CI/CD), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document CI/CD platform, pipeline configuration, and deployment automation. Verify against authorized tools list. Checklist: Azure DevOps, Jenkins, GitHub Actions]\n\n**Infrastructure as Code (IaC)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: IaC tooling documented and authorized (Terraform, Ansible, Azure DevOps Pipelines). Infrastructure is version-controlled. If Non-Compliant: IaC tools not approved or infrastructure manually configured. If Not Applicable: No IaC usage. If Unknown: IaC mentioned but tools unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment) or Section 8 (Technology Stack ‚Üí Infrastructure), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document IaC tool, version, and infrastructure-as-code repository. Verify against checklist Section 4 (Other Stacks ‚Üí Infrastructure as Code). Authorized: Terraform, Ansible, Azure DevOps Pipelines]\n\n### 1.6 Stack Validation Checklist Compliance (Automatic Validation)\n\n**Validation Status**: [VALIDATION_STATUS_BADGE]\n**Validation Date**: [VALIDATION_DATE]\n**Validation Evaluator**: [VALIDATION_EVALUATOR]\n\n**Overall Results**:\n- **Total Items**: [TOTAL_ITEMS]\n- **PASS**: [PASS_COUNT] ([PASS_PERCENTAGE]%)\n- **FAIL**: [FAIL_COUNT] ([FAIL_PERCENTAGE]%)\n- **N/A**: [NA_COUNT] ([NA_PERCENTAGE]%)\n- **UNKNOWN**: [UNKNOWN_COUNT] ([UNKNOWN_PERCENTAGE]%)\n\n**Dynamic Content**: The following validation summary is automatically generated from `validation_results` cache:\n\n---\n\n#### Java Backend (6 items): [JAVA_SUMMARY]\n\n[JAVA_ITEM_1]\n[JAVA_ITEM_2]\n[JAVA_ITEM_3]\n[JAVA_ITEM_4]\n[JAVA_ITEM_5]\n[JAVA_ITEM_6]\n\n---\n\n#### .NET Backend (6 items): [DOTNET_SUMMARY]\n\n[DOTNET_ITEM_1]\n[DOTNET_ITEM_2]\n[DOTNET_ITEM_3]\n[DOTNET_ITEM_4]\n[DOTNET_ITEM_5]\n[DOTNET_ITEM_6]\n\n---\n\n#### Frontend (6 items): [FRONTEND_SUMMARY]\n\n[FRONTEND_ITEM_1]\n[FRONTEND_ITEM_2]\n[FRONTEND_ITEM_3]\n[FRONTEND_ITEM_4]\n[FRONTEND_ITEM_5]\n[FRONTEND_ITEM_6]\n\n---\n\n#### Other Stacks and Components (5 items): [OTHER_STACKS_SUMMARY]\n\n[OTHER_STACKS_ITEM_1]\n[OTHER_STACKS_ITEM_2]\n[OTHER_STACKS_ITEM_3]\n[OTHER_STACKS_ITEM_4]\n[OTHER_STACKS_ITEM_5]\n\n---\n\n#### Exceptions and Action Plan (3 items): [EXCEPTIONS_SUMMARY]\n\n[EXCEPTIONS_ITEM_1]\n[EXCEPTIONS_ITEM_2]\n[EXCEPTIONS_ITEM_3]\n\n---\n\n**Stack Deviations**: [DEVIATIONS_LIST or \"None detected\"]\n\n**Recommendations**: [RECOMMENDATIONS_LIST or \"None\"]\n\n**Source**: ARCHITECTURE.md Section 8 (Technology Stack), lines [SOURCE_LINES]\n\n**Legend**:\n- ‚úÖ PASS: Complies with authorized technology catalog\n- ‚ùå FAIL: Non-compliant (deprecated version, unapproved technology, or missing documentation)\n- ‚ùì UNKNOWN: Insufficient data in Section 8 to validate\n- ‚ö™ N/A: Not applicable to this architecture\n\n---\n\n**Dynamic Field Mapping Instructions**:\n\n1. **Header Fields**:\n   - `[VALIDATION_STATUS_BADGE]`: \"‚úÖ **PASS** (Compliant)\" if overall_status == \"PASS\", else \"‚ùå **FAIL** (Non-Compliant)\"\n   - `[VALIDATION_DATE]`: From `validation_results.validation_date`\n   - `[VALIDATION_EVALUATOR]`: From `validation_results.validation_evaluator`\n   - `[TOTAL_ITEMS]`: From `validation_results.total_items` (always 26)\n   - `[PASS_COUNT]`: From `validation_results.pass_count`\n   - `[FAIL_COUNT]`: From `validation_results.fail_count`\n   - `[NA_COUNT]`: From `validation_results.na_count`\n   - `[UNKNOWN_COUNT]`: From `validation_results.unknown_count`\n   - `[PASS_PERCENTAGE]`: Calculate as `(pass_count / total_items) * 100`\n   - `[FAIL_PERCENTAGE]`: Calculate as `(fail_count / total_items) * 100`\n   - `[NA_PERCENTAGE]`: Calculate as `(na_count / total_items) * 100`\n   - `[UNKNOWN_PERCENTAGE]`: Calculate as `(unknown_count / total_items) * 100`\n\n2. **Section Summaries** (format: \"X PASS, Y FAIL, Z N/A, W UNKNOWN\"):\n   - `[JAVA_SUMMARY]`: Count statuses in `validation_results.sections.java_backend`\n   - `[DOTNET_SUMMARY]`: Count statuses in `validation_results.sections.dotnet_backend`\n   - `[FRONTEND_SUMMARY]`: Count statuses in `validation_results.sections.frontend`\n   - `[OTHER_STACKS_SUMMARY]`: Count statuses in `validation_results.sections.other_stacks`\n   - `[EXCEPTIONS_SUMMARY]`: Count statuses in `validation_results.sections.exceptions`\n\n3. **Item Details** (one line per item):\n   Format: \"- {ICON} {QUESTION} ({EVIDENCE})\" where:\n   - ICON: ‚úÖ (PASS), ‚ùå (FAIL), ‚ùì (UNKNOWN), ‚ö™ (N/A)\n   - QUESTION: From `validation_results.sections.{section}.item_{N}.question`\n   - EVIDENCE: From `validation_results.sections.{section}.item_{N}.evidence` (if status != N/A)\n\n   Example mappings:\n   - `[JAVA_ITEM_1]`: Format item_1 from java_backend section\n   - `[JAVA_ITEM_2]`: Format item_2 from java_backend section\n   - ... (repeat for all 26 items across 5 sections)\n\n4. **Footer Fields**:\n   - `[DEVIATIONS_LIST]`: From `validation_results.deviations` array (numbered list) or \"None detected\"\n   - `[RECOMMENDATIONS_LIST]`: From `validation_results.unknowns` array (numbered list) or \"None\"\n   - `[SOURCE_LINES]`: Extract from first and last evidence line numbers in validation_results\n\n**Example Output (PASS scenario)**:\n\n```\n**Validation Status**: ‚úÖ **PASS** (Compliant)\n**Validation Date**: 2025-11-27\n**Validation Evaluator**: Claude Code (Automated)\n\n**Overall Results**:\n- **Total Items**: 26\n- **PASS**: 11 (42%)\n- **FAIL**: 0 (0%)\n- **N/A**: 12 (46%)\n- **UNKNOWN**: 3 (12%)\n\n#### Java Backend (6 items): 5 PASS, 1 UNKNOWN\n\n- ‚úÖ Is Java in a supported version? (Java 17 LTS - Section 8.1, line 952)\n- ‚úÖ Is Spring Boot in a supported version? (Spring Boot 3.2 - Section 8.1, line 953)\n- ‚úÖ Are official tools used? (Maven 3.9, JUnit 5, Mockito, SonarQube - Section 8.1, lines 954-956)\n- ‚úÖ Is deployment in authorized containers? (Docker 24+, AKS 1.28+ - Section 8.2, lines 960-962)\n- ‚úÖ Are only approved libraries used? (10 Spring libraries documented - Section 8.1, line 957)\n- ‚ùì Does naming follow standards? (Not documented in Section 8)\n\n#### .NET Backend (6 items): All N/A\n\n- ‚ö™ No .NET detected in technology stack\n- ‚ö™ No .NET detected in technology stack\n- ‚ö™ No .NET detected in technology stack\n- ‚ö™ No .NET detected in technology stack\n- ‚ö™ No .NET detected in technology stack\n- ‚ö™ No .NET detected in technology stack\n\n[... remaining sections ...]\n\n**Stack Deviations**: None detected\n\n**Recommendations**:\n1. **Document Naming Conventions**: Add repository and resource naming conventions to Section 8 (Java Backend Item 6)\n2. **Document OpenAPI Version**: Explicitly specify OpenAPI/Swagger version in Section 8 (Other Stacks Item 4)\n\n**Source**: ARCHITECTURE.md Section 8 (Technology Stack), lines 949-1035\n```\n\n**Example Output (FAIL scenario)**:\n\n```\n**Validation Status**: ‚ùå **FAIL** (Non-Compliant)\n**Validation Date**: 2025-11-27\n**Validation Evaluator**: Claude Code (Automated)\n\n**Overall Results**:\n- **Total Items**: 26\n- **PASS**: 8 (31%)\n- **FAIL**: 2 (8%)\n- **N/A**: 12 (46%)\n- **UNKNOWN**: 4 (15%)\n\n#### Java Backend (6 items): 4 PASS, 1 FAIL, 1 UNKNOWN\n\n- ‚ùå Is Java in a supported version? (Java 8 detected - DEPRECATED - Section 8.1, line 952)\n- ‚úÖ Is Spring Boot in a supported version? (Spring Boot 3.2 - Section 8.1, line 953)\n- ‚úÖ Are official tools used? (Maven 3.9, JUnit 5 - Section 8.1, lines 954-956)\n- ‚úÖ Is deployment in authorized containers? (Docker 24+, AKS 1.28+ - Section 8.2, lines 960-962)\n- ‚úÖ Are only approved libraries used? (All libraries authorized - Section 8.1, line 957)\n- ‚ùì Does naming follow standards? (Not documented in Section 8)\n\n[... remaining sections ...]\n\n**Stack Deviations**:\n1. **Java 8 (DEPRECATED)**: Detected in Section 8.1, line 952. Java 8 is EOL. Migrate to Java 11 LTS or Java 17 LTS.\n2. **Unapproved Library (lodash)**: Detected in Section 8.3, line 987. Library not in approved catalog. Request chapter approval or replace with approved alternative.\n\n**Recommendations**:\n1. **CRITICAL: Upgrade Java to LTS version**: Migrate from Java 8 to Java 17 LTS (Java Backend Item 1)\n2. **Remove unapproved library**: Replace lodash with approved alternative or request exception (Frontend Item 5)\n3. **Document Naming Conventions**: Add naming conventions to Section 8 (Java Backend Item 6)\n```\n\n**Naming Convention Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Repositories and resources follow organizational naming standards. Naming conventions are documented. If Non-Compliant: Naming standards not followed or not documented. If Unknown: Naming mentioned but compliance unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document naming conventions for repositories, containers, resources. Verify against organizational standards. Checklist items: Java Backend (section 1.6), .NET Backend (section 2.6), Frontend (section 3.6)]\n\n**Approved Libraries Verification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All libraries used are approved by chapter. Library inventory is documented and verified. If Non-Compliant: Unapproved libraries in use. If Unknown: Library approval status not verified]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Frameworks & Libraries) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create inventory of all third-party libraries. Cross-reference with chapter-approved library catalog. Document any unapproved libraries and create exception (LADES2). Checklist items: Java (1.5), .NET (2.5), Frontend (3.5)]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LADES1, e.g., \"Section 4, lines X-Y; Section 7, lines A-B; Section 8, lines M-N; Section 11, lines P-Q\"]\n\n---\n\n## 2. Architecture Debt Impact - Exception Handling and Action Plans (LADES2)\n\n**Requirement**: In case of deviations from the defined technology stack, document the exception and action plan for remediation. Exceptions must be formally approved and tracked with clear timelines.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Technical Lead / Architecture Review Board or N/A]\n\n### 2.1 Stack Deviation Identification\n\n**Technology Stack Deviations**: [Value or \"None identified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: No deviations from authorized stack OR all deviations documented with exceptions. Stack compliance verified via checklist. If Non-Compliant: Deviations exist without documented exceptions. If Not Applicable: Full stack compliance (no deviations). If Unknown: Stack compliance not assessed]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack), Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Compare technology stack against authorized catalog (stack-validation-checklist.md). Identify all deviations (unapproved libraries, deprecated versions, non-standard tools). Document in Section 8 or create ADR in Section 12. Checklist reference: Section 5 (Exceptions and Action Plan)]\n\n**Deprecated Technology Usage**: [Value or \"None\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: No deprecated/EOL technology in use OR documented migration plan exists for all deprecated components. If Non-Compliant: Deprecated technology used without migration plan. If Not Applicable: All technologies current. If Unknown: EOL status not verified]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Check each technology component against vendor EOL dates (Java, .NET, frameworks, libraries). Document deprecated items and create migration plan with timeline in Section 12 (ADRs). Include risk assessment for continued use of deprecated technologies]\n\n### 2.2 Exception Documentation\n\n**Exception Approval**: [Value or \"Not required\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All exceptions formally documented via ADR with approval from chapter/architecture review board. Approval date and approver documented. If Non-Compliant: Exceptions exist but not formally approved. If Not Applicable: No exceptions required. If Unknown: Approval status unclear]\n- Source: [ARCHITECTURE.md Section 12 (Architecture Decision Records), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create ADR for each exception documenting: deviation details, business justification, technical rationale, alternatives considered, approval date, approver name. Register exception in this Adherence Contract. Checklist reference: Section 5.2 (Exception and action plan documented)]\n\n**Exception Justification**: [Value or \"Not required\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Business and technical justification documented for each exception in ADR. Risk assessment and mitigation strategy included. If Non-Compliant: Exceptions lack clear justification or risk assessment. If Not Applicable: No exceptions. If Unknown: Justification partial or unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs ‚Üí Context, Decision, Consequences) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: For each exception, document in ADR: business driver (why deviation is necessary), technical constraints (why standard cannot be used), risk assessment (security, maintainability, vendor support), mitigation strategy (compensating controls, monitoring)]\n\n### 2.3 Remediation Action Plans\n\n**Action Plan Definition**: [Value or \"Not required\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Remediation action plan documented with timeline, steps, and success criteria. Each exception has clear path to compliance. If Non-Compliant: Exception exists without action plan or plan incomplete. If Not Applicable: No exceptions requiring remediation. If Unknown: Action plan mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs ‚Üí Consequences, Future Work) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: For each exception, define action plan: remediation steps (migrate to authorized stack), timeline (target quarter/year), resource requirements, success criteria (e.g., library upgraded to approved version), risk mitigation during transition (e.g., dual-run, feature flags). Checklist reference: Section 5.3 (Plan approved by chapter)]\n\n**Action Plan Timeline**: [Value or \"Not required\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Timeline documented with milestones and target completion date. Timeline is realistic and includes dependencies. If Non-Compliant: Timeline missing or unrealistic. If Not Applicable: No remediation required. If Unknown: Timeline vague or missing milestones]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document specific timeline with phases: Phase 1 (assessment and impact analysis, Q1 2026), Phase 2 (migration and testing, Q2-Q3 2026), Phase 3 (production deployment and validation, Q4 2026). Include milestones, dependencies, and rollback plan]\n\n### 2.4 Technical Debt Tracking\n\n**Debt Register**: [Value or \"Not maintained\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Technical debt tracked in formal register (backlog, ADR log, debt management tool). Each debt item is inventoried and tracked. If Non-Compliant: Technical debt not tracked or ad-hoc tracking without formal register. If Not Applicable: No technical debt. If Unknown: Tracking mechanism unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or external debt tracking system reference or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement technical debt register using: ADR log in Section 12, product backlog, or dedicated debt management tool (e.g., Jira, Azure DevOps). Track each debt item: stack deviation, deprecated technology, architecture shortcut, unapproved library. Include: priority, owner, remediation plan reference, creation date]\n\n**Debt Prioritization**: [Value or \"Not defined\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Debt prioritization criteria documented (business impact, security risk, EOL urgency, maintainability). Debt items are prioritized and ordered by risk. If Non-Compliant: Debt not prioritized or criteria unclear. If Not Applicable: No debt to prioritize. If Unknown: Prioritization mentioned but criteria unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define prioritization criteria: Critical (security vulnerability, EOL <6 months, regulatory non-compliance), High (major deviation from stack, EOL <12 months, significant business impact), Medium (minor deviation, EOL <24 months, moderate maintainability risk), Low (cosmetic, no EOL risk, minimal impact). Document priority for each debt item]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LADES2, e.g., \"Section 8, lines X-Y; Section 12, lines A-B\"]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Development Architecture Terms**:\n- **Stack Validation**: Process of verifying technology choices against organizational standards and best practices\n- **Tech Debt (Technical Debt)**: Code or architecture decisions that trade long-term maintainability for short-term delivery\n- **CI/CD (Continuous Integration/Continuous Deployment)**: Automated pipelines for building, testing, and deploying code\n- **Approved Library Catalog**: Organizational list of approved frameworks, libraries, and tools\n- **EOL (End of Life)**: Technology version no longer supported by vendor\n- **ADR (Architecture Decision Record)**: Document capturing architectural choices and their rationale\n- **Stack Alignment**: Ensuring technology choices follow organizational standards\n- **Exception Handling**: Documented approval process for deviating from standard technology choices\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Development Abbreviations**:\n- **LADES**: Development Architecture compliance requirement code\n- **DX**: Developer Experience\n- **SCA**: Static Code Analysis\n- **SAST**: Static Application Security Testing\n\n---\n\n### A.2 Validation Methodology\n\n**Validation Process**:\n\n1. **Completeness Check (40% weight)**:\n   - Counts filled data points across all LADES requirements\n   - Formula: (Filled fields / Total required fields) √ó 10\n   - Example: 12 out of 14 fields = 8.6/10 completeness\n\n2. **Compliance Check (50% weight)**:\n   - Evaluates each validation item as PASS/FAIL/N/A/UNKNOWN\n   - Formula: (PASS + N/A + EXCEPTION items) / Total items √ó 10\n   - **CRITICAL**: N/A items MUST be included in numerator\n   - Example: 10 PASS + 2 N/A + 0 EXCEPTION out of 14 items = (10+2)/14 √ó 10 = 8.6/10\n   - **SPECIAL**: LADES1.6 (Stack Validation) cannot be \"Unknown\" - must be Compliant (PASS) or Non-Compliant (PENDING/FAIL)\n\n3. **Quality Check (10% weight)**:\n   - Assesses source traceability (ARCHITECTURE.md section references)\n   - Verifies Stack Validation Checklist completion\n   - Formula: (Items with valid sources / Total items) √ó 10\n\n4. **Final Score Calculation**:\n   ```\n   Final Score = (Completeness √ó 0.4) + (Compliance √ó 0.5) + (Quality √ó 0.1)\n   ```\n\n**Outcome Determination**:\n| Score Range | Document Status | Review Actor | Action |\n|-------------|----------------|--------------|--------|\n| 8.0-10.0 | Approved | System (Auto-Approved) | Ready for implementation (requires LADES1.6 PASS) |\n| 7.0-7.9 | In Review | Development Architecture Review Board | Manual review required |\n| 5.0-6.9 | Draft | Architecture Team | Address gaps before review |\n| 0.0-4.9 | Rejected | N/A (Blocked) | Cannot proceed - critical development standards missing |\n\n**IMPORTANT**: Contract cannot achieve \"Approved\" status without Stack Validation Checklist (LADES1.6) showing PASS status.\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n**Additional Development-Specific Steps**:\n- **Complete Stack Validation**: For LADES1.6, complete STACK_VALIDATION_CHECKLIST.md (26 checkpoints)\n- **Stack Checklist Path**: `.claude/skills/architecture-compliance/STACK_VALIDATION_CHECKLIST.md`\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Development Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Technology stack incomplete | LADES1 Non-Compliant | Section 8 (Technology Stack) | Document all languages, frameworks, databases, tools with versions |\n| Stack validation not completed | LADES1.6 Non-Compliant | External checklist | Complete STACK_VALIDATION_CHECKLIST.md (26 checkpoints) |\n| Deprecated technology versions | LADES2 Non-Compliant | Section 8 or 12 (Technology/ADRs) | Upgrade to approved versions or register exception via LADES2 |\n| CI/CD pipeline undefined | LADES3 Unknown | Section 11 (Operational Considerations) | Document build, test, deployment automation, rollback procedures |\n| Code quality standards missing | LADES4 Unknown | Section 8 or 11 (Technology/Operational) | Specify linting, static analysis, code coverage requirements |\n| Dependency management undefined | LADES5 Unknown | Section 8 (Technology Stack) | Document dependency lock files, vulnerability scanning, update policy |\n| Testing strategy incomplete | LADES6 Unknown | Section 11 (Operational Considerations) | Define unit, integration, e2e testing with coverage thresholds |\n| Tech debt not documented | LADES2 Unknown | Section 12 (ADRs) | Create ADRs for approved exceptions with justification and mitigation plan |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Development Architecture-Specific Examples**:\n\n**Example 1: Completing Technology Stack Documentation**\n- **Gap**: Technology stack incomplete in Section 8\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add complete technology stack to Section 8:\n   Backend: Java 17 LTS, Spring Boot 3.1, Hibernate 6.2,\n   Frontend: React 18, TypeScript 5.1, Vite 4.4,\n   Database: PostgreSQL 15, Redis 7.2,\n   Infrastructure: Docker 24, Kubernetes 1.28,\n   CI/CD: GitHub Actions, ArgoCD,\n   Monitoring: Prometheus, Grafana\"\n  ```\n- **Expected Outcome**: Section 8 with complete stack, versions, approved technologies\n- **Impact**: LADES1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: CI/CD Pipeline Documentation**\n- **Gap**: CI/CD pipeline not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add CI/CD pipeline to Section 11:\n   Build: GitHub Actions with Maven/Gradle,\n   Testing: automated unit (90% coverage), integration, e2e tests,\n   Deployment: GitOps with ArgoCD, blue-green strategy,\n   Rollback: automated on health check failure within 5 minutes,\n   Environments: dev ‚Üí staging ‚Üí production with approval gates\"\n  ```\n- **Expected Outcome**: Section 11 with CI/CD workflow, testing, deployment strategies\n- **Impact**: LADES3 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Code Quality and Testing Standards**\n- **Gap**: Code quality standards and testing strategy missing\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add code quality standards to Section 11:\n   Linting: ESLint (frontend), Checkstyle (backend),\n   Static analysis: SonarQube with Quality Gate (A rating minimum),\n   Code coverage: 90% unit test coverage required,\n   Testing pyramid: 70% unit, 20% integration, 10% e2e,\n   PR requirements: 2 approvals, all checks passing\"\n  ```\n- **Expected Outcome**: Section 11 with quality gates, testing strategy, PR requirements\n- **Impact**: LADES4 + LADES6 ‚Üí Compliant (+0.5 points)\n\n**Example 4: Dependency Management and Security**\n- **Gap**: Dependency management not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add dependency management to Section 8:\n   Lock files: package-lock.json (npm), pom.xml (Maven),\n   Vulnerability scanning: Dependabot automated PRs,\n   Update policy: security patches within 48 hours, minor versions monthly,\n   Supply chain security: npm audit, OWASP dependency check,\n   Private registry: Artifactory for approved dependencies\"\n  ```\n- **Expected Outcome**: Section 8 with dependency management, security scanning, update policy\n- **Impact**: LADES5 ‚Üí Compliant (+0.4 points)\n\n**Example 5: Tech Debt Exception Documentation**\n- **Gap**: Using deprecated Java 8 without documented exception\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Create ADR in Section 12 for Java 8 exception:\n   Title: Continue Java 8 usage for legacy module,\n   Context: Legacy payment module requires Java 8 compatibility,\n   Decision: Maintain Java 8 for legacy module, Java 17 for new services,\n   Consequences: Technical debt, migration plan by Q3 2025,\n   Mitigation: Isolated module, no new features, security patches only\"\n  ```\n- **Expected Outcome**: Section 12 with ADR documenting exception, mitigation, migration plan\n- **Impact**: LADES2 ‚Üí Exception Approved (LADES2 ‚Üí PASS) (+0.5 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required development architecture fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS (requires stack validation)\n- Quality ({{quality_percent}} weight): Add source traceability for all technology decisions\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Technology Stack Documentation** (estimated impact: +0.6 points)\n   - Document complete technology stack in Section 8: languages, frameworks, databases, tools with versions\n   - Complete STACK_VALIDATION_CHECKLIST.md (26 checkpoints) for LADES1.6\n   - Verify all technologies against organizational approved catalog\n   - Document dependency management: lock files, vulnerability scanning, update policy (Section 8)\n   - Add approved library/framework justifications in Section 8 or Section 12 (ADRs)\n\n2. **Establish Development Workflow and Quality** (estimated impact: +0.3 points)\n   - Document CI/CD pipeline: build, test, deploy, rollback procedures (Section 11)\n   - Define code quality standards: linting, static analysis, SonarQube gates (Section 11)\n   - Add testing strategy: unit, integration, e2e with coverage thresholds (Section 11)\n   - Specify PR requirements: approvals, checks, code review guidelines (Section 11)\n   - Document branching strategy: GitFlow, trunk-based, or feature branches (Section 11)\n\n3. **Address Tech Debt and Exceptions** (estimated impact: +0.2 points)\n   - Create ADRs for deprecated technologies with migration plans (Section 12)\n   - Document approved exceptions via LADES2 process with risk mitigation (Section 12)\n   - Add technical debt register with prioritization and remediation timeline (Section 12)\n   - Specify upgrade path for deprecated versions with timeline (Section 12)\n   - Ensure all FAIL items have exceptions or upgrade plans\n\n**Priority Order**: LADES1 (tech stack) ‚Üí LADES1.6 (stack validation) ‚Üí LADES3 (CI/CD) ‚Üí LADES4 (code quality) ‚Üí LADES6 (testing) ‚Üí LADES2 (exceptions) ‚Üí LADES5 (dependencies)\n\n**CRITICAL**: Contract cannot achieve \"Approved\" status without LADES1.6 (Stack Validation Checklist) showing PASS status. Complete the checklist before requesting approval.\n\n**Estimated Final Score After Remediation**: 8.2-8.7/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with Cloud Architecture template structure\n- Total: 14 validation data points across 2 LADES requirements\n- Integrated Stack Validation Checklist as mandatory requirement\n\n**Version 1.0 (Previous)**:\n- Basic source traceability section\n- Generation metadata focus\n- Limited structure\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=development-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=development-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=development-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=development-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=development-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n\n**CRITICAL**: Contract approval requires LADES1.6 (Stack Validation) to show PASS status. Complete STACK_VALIDATION_CHECKLIST.md before seeking approval.",
        "skills/architecture-compliance/templates/TEMPLATE_ENTERPRISE_ARCHITECTURE.md": "# Compliance Contract: Enterprise Architecture\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 2, 3, 4, 5, 6, 7, 8, 9, 12)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=enterprise-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=enterprise-architecture -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAE1 | Modularity and Capability Reusability | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Enterprise Architect or N/A] |\n| LAE2 | Third-Party Application Customization | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Technical Architect / Product Manager or N/A] |\n| LAE3 | Cloud First | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Cloud Architect / Enterprise Architect or N/A] |\n| LAE4 | Business Strategy Alignment | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Enterprise Architect / Business Analyst or N/A] |\n| LAE5 | Zero Obsolescence | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Enterprise Architect / Technical Lead or N/A] |\n| LAE6 | Managed Data Vision | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect / Data Governance Lead or N/A] |\n| LAE7 | API First / Event Driven | Enterprise Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / API Lead or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Modularity and Capability Reusability (LAE1)\n\n**Requirement**: Ensure no redundancy of capabilities through capability map review and application coverage analysis.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Enterprise Architect or N/A]\n\n### 1.1 Capability Map Review\n\n**Business Capabilities Addressed**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Business capabilities documented. If Non-Compliant: Capabilities not specified in ARCHITECTURE.md. If Not Applicable: Not required for this solution type. If Unknown: Capabilities mentioned but not clearly mapped]\n- Source: [ARCHITECTURE.md Section 2.2 (Functional Requirements) or Section 3.1 (Use Cases) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Map solution capabilities to enterprise capability model in Section 2 or 3]\n\n**Capability Redundancy Analysis**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Redundancy check documented. If Non-Compliant: No analysis of existing capabilities. If Not Applicable: Greenfield solution. If Unknown: Existing systems mentioned but overlap unclear]\n- Source: [ARCHITECTURE.md Section 5 (Current State / Existing Systems) or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document analysis of existing systems providing similar capabilities and justify new development in Section 5 or 12]\n\n**Reusability Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Reuse strategy documented. If Non-Compliant: No evaluation of existing components. If Not Applicable: N/A. If Unknown: Reusability mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture) or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document which existing enterprise components/services are reused vs. newly built in Section 4 or 12]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE1]\n\n---\n\n### 1.2 Application Coverage Analysis\n\n**Existing Application Landscape**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Application inventory documented. If Non-Compliant: Existing applications not identified. If Not Applicable: N/A. If Unknown: Applications mentioned but coverage unclear]\n- Source: [ARCHITECTURE.md Section 5 (Current State) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: List existing applications in the capability domain and their coverage in Section 5]\n\n**Coverage Gap Analysis**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Gaps documented. If Non-Compliant: Gap analysis not performed. If Not Applicable: N/A. If Unknown: Gaps mentioned but not quantified]\n- Source: [ARCHITECTURE.md Section 5 or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document functional gaps that justify this solution in Section 5 or 12]\n\n**Application Rationalization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Rationalization plan documented. If Non-Compliant: No consolidation strategy. If Not Applicable: No existing applications to rationalize. If Unknown: Decommissioning mentioned but timeline unclear]\n- Source: [ARCHITECTURE.md Section 7 (Migration and Transition) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document which legacy applications will be retired or consolidated in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE1]\n\n---\n\n### 1.3 Redundancy Assessment\n\n**Duplicate Functionality Check**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Duplication analysis documented. If Non-Compliant: No check for overlapping functionality. If Not Applicable: N/A. If Unknown: Similar systems mentioned but overlap not analyzed]\n- Source: [ARCHITECTURE.md Section 5 or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document any functional overlap with existing systems and justify in Section 5 or 12]\n\n**Consolidation Opportunities**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Consolidation assessed. If Non-Compliant: No evaluation of consolidation potential. If Not Applicable: N/A. If Unknown: Integration mentioned but consolidation unclear]\n- Source: [ARCHITECTURE.md Section 7 or Section 12 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify opportunities to consolidate capabilities instead of building new in Section 7 or 12]\n\n**Architectural Patterns for Reusability**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Modular patterns documented. If Non-Compliant: No modular design approach. If Not Applicable: N/A. If Unknown: Architecture mentioned but modularity unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document microservices, shared libraries, or component reuse patterns in Section 4]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE1]\n\n---\n\n## 2. Third-Party Application Customization (LAE2)\n\n**Requirement**: Confirm third-party application customizations are only for regulatory needs and part of the product.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Technical Architect / Product Manager or N/A]\n\n### 2.1 Third-Party Application Inventory\n\n**Third-Party Applications Used**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party products documented. If Non-Compliant: Third-party components not identified. If Not Applicable: No third-party applications. If Unknown: Vendors mentioned but products unclear]\n- Source: [ARCHITECTURE.md Section 6 (Technology Stack) or Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: List all third-party applications/products (COTS, SaaS) in Section 6 or 4]\n\n**Product Versions and Editions**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Versions documented. If Non-Compliant: Versions not specified. If Not Applicable: N/A. If Unknown: Products mentioned but versions unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify exact versions and editions of third-party products in Section 6]\n\n**Licensing Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Licensing documented. If Non-Compliant: License type not specified. If Not Applicable: N/A. If Unknown: Licensing mentioned but terms unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document licensing model (subscription, perpetual, usage-based) in Section 6]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE2]\n\n---\n\n### 2.2 Customization Justification\n\n**Customizations Applied**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Customizations documented. If Non-Compliant: Customizations not specified. If Not Applicable: No customizations (vanilla deployment). If Unknown: Customization mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document all customizations to third-party products in Section 4 or 12]\n\n**Regulatory Compliance Justification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Regulatory need documented. If Non-Compliant: Customizations not justified by regulatory requirements. If Not Applicable: No customizations. If Unknown: Compliance mentioned but link to customizations unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Compliance) or Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Justify each customization with specific regulatory requirement (GDPR, local regulations) in Section 9 or 12]\n\n**Product Roadmap Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Future product features assessed. If Non-Compliant: No evaluation of vendor roadmap. If Not Applicable: N/A. If Unknown: Vendor capabilities mentioned but future unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify customizations will be part of vendor's product in Section 12]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE2]\n\n---\n\n### 2.3 Product Integration Strategy\n\n**Configuration vs. Customization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Configuration approach documented. If Non-Compliant: No distinction between config and custom code. If Not Applicable: N/A. If Unknown: Implementation mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 8 (Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document which changes use native configuration vs. custom development in Section 4 or 8]\n\n**Upgrade Impact Analysis**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Upgrade strategy documented. If Non-Compliant: Upgrade impact not assessed. If Not Applicable: N/A. If Unknown: Upgrades mentioned but process unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Excellence) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document how customizations affect product upgrades in Section 11]\n\n**Vendor Support Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Support coverage documented. If Non-Compliant: Support model not specified. If Not Applicable: N/A. If Unknown: Support mentioned but coverage unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Clarify whether customizations void vendor support in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE2]\n\n---\n\n## 3. Cloud First (LAE3)\n\n**Requirement**: Demonstrate solutions are designed and deployed cloud-first using native cloud services.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Cloud Architect / Enterprise Architect or N/A]\n\n### 3.1 Cloud Deployment Model\n\n**Cloud-First Commitment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cloud deployment confirmed. If Non-Compliant: On-premise or hybrid deployment. If Not Applicable: Legacy system exception. If Unknown: Deployment model unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture) or Section 8 (Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Confirm cloud deployment or provide exception justification in Section 4 or 8]\n\n**Cloud Provider**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Provider documented. If Non-Compliant: Cloud provider not specified. If Not Applicable: N/A. If Unknown: Cloud mentioned but provider unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 8 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify primary cloud provider (AWS, Azure, GCP, etc.) in Section 4 or 8]\n\n**Cloud Service Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service model documented (IaaS/PaaS/SaaS). If Non-Compliant: Service model not specified. If Not Applicable: N/A. If Unknown: Cloud services mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section 4 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define whether using IaaS, PaaS, or SaaS in Section 4]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE3]\n\n---\n\n### 3.2 Native Cloud Services Usage\n\n**Managed Services Adoption**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Managed services documented. If Non-Compliant: Self-managed infrastructure instead of managed services. If Not Applicable: N/A. If Unknown: Services mentioned but management model unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 6 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Prefer managed services (RDS, DynamoDB, Cloud SQL) over self-managed databases in Section 4 or 6]\n\n**Cloud-Native Components**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Native services documented. If Non-Compliant: Non-cloud-native tools used. If Not Applicable: N/A. If Unknown: Components mentioned but cloud-native status unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document use of native cloud services (Lambda, Cloud Functions, etc.) in Section 6]\n\n**Serverless Architecture**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Serverless adoption documented. If Non-Compliant: Traditional server-based deployment. If Not Applicable: Serverless not suitable. If Unknown: Architecture mentioned but serverless usage unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 8 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Evaluate serverless options (Lambda, Cloud Functions, Cloud Run) in Section 4 or 8]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE3]\n\n---\n\n### 3.3 Cloud-First Architecture Compliance\n\n**On-Premise Dependencies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: No on-prem dependencies or justified. If Non-Compliant: Unnecessary on-premise dependencies. If Not Applicable: Pure cloud solution. If Unknown: Dependencies mentioned but scope unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 5 (Current State) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Minimize on-premise dependencies or justify exceptions in Section 4 or 5]\n\n**Cloud Migration Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Migration approach documented. If Non-Compliant: No migration plan for legacy components. If Not Applicable: Greenfield cloud solution. If Unknown: Migration mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 7 (Migration and Transition) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document cloud migration approach (rehost/replatform/refactor) in Section 7]\n\n**Cloud-First Decision Framework**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cloud-first rationale documented. If Non-Compliant: No justification for cloud approach. If Not Applicable: N/A. If Unknown: Cloud mentioned but decision process unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Add ADR explaining cloud-first design decisions in Section 12]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE3]\n\n---\n\n## 4. Business Strategy Alignment (LAE4)\n\n**Requirement**: Show alignment with business strategy and value generation.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Enterprise Architect / Business Analyst or N/A]\n\n### 4.1 Business Strategy Alignment\n\n**Strategic Objectives Addressed**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Business objectives documented. If Non-Compliant: Strategic alignment not specified. If Not Applicable: N/A. If Unknown: Objectives mentioned but link unclear]\n- Source: [ARCHITECTURE.md Section 2.1 (Business Objectives) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Map solution to enterprise strategic goals in Section 2.1]\n\n**Business Case**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Business justification documented. If Non-Compliant: No business case provided. If Not Applicable: N/A. If Unknown: Justification mentioned but incomplete]\n- Source: [ARCHITECTURE.md Section 2.1 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document ROI, cost-benefit analysis, or strategic value in Section 2.1]\n\n**Stakeholder Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Key stakeholders identified. If Non-Compliant: Stakeholders not documented. If Not Applicable: N/A. If Unknown: Stakeholders mentioned but roles unclear]\n- Source: [ARCHITECTURE.md Section 2 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify business sponsors and key stakeholders in Section 2]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE4]\n\n---\n\n### 4.2 Value Generation Metrics\n\n**Success Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: KPIs documented. If Non-Compliant: Success criteria not defined. If Not Applicable: N/A. If Unknown: Metrics mentioned but not quantified]\n- Source: [ARCHITECTURE.md Section 2.3 (Success Criteria) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define measurable success criteria in Section 2.3]\n\n**Business Value Metrics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Value metrics documented. If Non-Compliant: Business value not quantified. If Not Applicable: N/A. If Unknown: Value mentioned but not measured]\n- Source: [ARCHITECTURE.md Section 2.1 or Section 2.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Quantify expected business value (revenue, cost savings, efficiency) in Section 2.1 or 2.3]\n\n**Performance Indicators**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Performance targets documented. If Non-Compliant: No performance KPIs. If Not Applicable: N/A. If Unknown: Performance mentioned but targets unclear]\n- Source: [ARCHITECTURE.md Section 10 (Performance Requirements) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define technical KPIs that support business outcomes in Section 10]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE4]\n\n---\n\n### 4.3 Strategic Initiatives Mapping\n\n**Enterprise Initiatives**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Strategic initiatives mapped. If Non-Compliant: No connection to enterprise programs. If Not Applicable: Standalone solution. If Unknown: Initiatives mentioned but mapping unclear]\n- Source: [ARCHITECTURE.md Section 2 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Map to enterprise transformation initiatives or strategic programs in Section 2]\n\n**Digital Transformation Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Transformation role documented. If Non-Compliant: Digital strategy not addressed. If Not Applicable: N/A. If Unknown: Transformation mentioned but role unclear]\n- Source: [ARCHITECTURE.md Section 2 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Explain how solution supports digital transformation strategy in Section 2]\n\n**Long-Term Roadmap**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Future evolution documented. If Non-Compliant: No strategic roadmap. If Not Applicable: N/A. If Unknown: Roadmap mentioned but timeline unclear]\n- Source: [ARCHITECTURE.md Section 2 or Section 7 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document planned evolution aligned with business strategy in Section 2 or 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE4]\n\n---\n\n## 5. Zero Obsolescence (LAE5)\n\n**Requirement**: Ensure no component reaches end-of-support within 24-36 months.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Enterprise Architect / Technical Lead or N/A]\n\n### 5.1 Component Lifecycle Assessment\n\n**Technology Stack Versions**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Component versions documented. If Non-Compliant: Versions not specified. If Not Applicable: N/A. If Unknown: Technologies mentioned but versions unclear]\n- Source: [ARCHITECTURE.md Section 6 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document specific versions of all technologies in Section 6]\n\n**Vendor Support Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Support timelines verified. If Non-Compliant: Support status not checked. If Not Applicable: N/A. If Unknown: Support mentioned but dates unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify vendor support end dates for all components in Section 6]\n\n**Open Source Project Health**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Project viability assessed. If Non-Compliant: OSS health not evaluated. If Not Applicable: No open source dependencies. If Unknown: Projects mentioned but health unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Assess community activity and maintenance status of OSS components in Section 6]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE5]\n\n---\n\n### 5.2 End-of-Support Timeline\n\n**Component EOL Dates**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: EOL dates documented and >36 months. If Non-Compliant: Components EOL within 24-36 months. If Not Applicable: N/A. If Unknown: EOL not verified]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document end-of-life dates for all critical components in Section 6]\n\n**Operating System Lifecycle**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: OS support verified. If Non-Compliant: OS nearing EOL. If Not Applicable: Serverless/PaaS deployment. If Unknown: OS mentioned but lifecycle unclear]\n- Source: [ARCHITECTURE.md Section 6 or Section 8 (Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify OS versions have 36+ months support remaining in Section 6 or 8]\n\n**Database and Middleware Support**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database/middleware support confirmed. If Non-Compliant: Versions nearing EOL. If Not Applicable: Managed services with auto-upgrade. If Unknown: Versions mentioned but support unclear]\n- Source: [ARCHITECTURE.md Section 6 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document database and middleware support timelines in Section 6]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE5]\n\n---\n\n### 5.3 Upgrade Roadmap\n\n**Version Upgrade Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Upgrade plan documented. If Non-Compliant: No upgrade strategy. If Not Applicable: N/A. If Unknown: Upgrades mentioned but plan unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Excellence) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document upgrade approach and frequency in Section 11]\n\n**Technology Refresh Cycle**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Refresh cycle defined. If Non-Compliant: No technology refresh plan. If Not Applicable: N/A. If Unknown: Maintenance mentioned but cycle unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define periodic technology review and upgrade cycle in Section 11]\n\n**Migration Path for Expiring Components**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Migration plan documented. If Non-Compliant: No plan for EOL components. If Not Applicable: All components have long support. If Unknown: Replacement mentioned but plan unclear]\n- Source: [ARCHITECTURE.md Section 7 (Migration and Transition) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document replacement strategy for components nearing EOL in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE5]\n\n---\n\n## 6. Managed Data Vision (LAE6)\n\n**Requirement**: Optimize data management and governance (roles, regulations, storage, backup, integrity, lifecycle).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Data Governance Lead or N/A]\n\n### 6.1 Data Governance Framework\n\n**Data Ownership and Stewardship**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data owners identified. If Non-Compliant: Ownership not defined. If Not Applicable: No data management. If Unknown: Roles mentioned but responsibilities unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 (Security Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data owners and stewards for each data domain in Section 4 or 9]\n\n**Data Classification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data classification documented. If Non-Compliant: Classification not performed. If Not Applicable: N/A. If Unknown: Data types mentioned but classification unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify data by sensitivity (public, internal, confidential, restricted) in Section 9]\n\n**Regulatory Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data regulations documented. If Non-Compliant: Regulatory requirements not addressed. If Not Applicable: No regulated data. If Unknown: Regulations mentioned but compliance unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Compliance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document GDPR, CCPA, or industry-specific data regulations in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE6]\n\n---\n\n### 6.2 Data Lifecycle Management\n\n**Data Storage Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage approach documented. If Non-Compliant: Storage strategy not defined. If Not Applicable: N/A. If Unknown: Storage mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 6 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define hot/warm/cold storage tiers and retention in Section 4 or 6]\n\n**Data Retention Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Retention rules documented. If Non-Compliant: No retention policy. If Not Applicable: N/A. If Unknown: Retention mentioned but periods unclear]\n- Source: [ARCHITECTURE.md Section 9 or Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document retention periods by data type in Section 9 or 11]\n\n**Data Archival and Deletion**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Archival process documented. If Non-Compliant: No archival/deletion strategy. If Not Applicable: N/A. If Unknown: Lifecycle mentioned but process unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define archival triggers and secure deletion procedures in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE6]\n\n---\n\n### 6.3 Data Quality and Integrity\n\n**Data Quality Standards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Quality standards documented. If Non-Compliant: No quality framework. If Not Applicable: N/A. If Unknown: Quality mentioned but standards unclear]\n- Source: [ARCHITECTURE.md Section 4 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data accuracy, completeness, and consistency standards in Section 4]\n\n**Data Validation and Verification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Validation approach documented. If Non-Compliant: No validation process. If Not Applicable: N/A. If Unknown: Validation mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document input validation and data verification mechanisms in Section 4 or 9]\n\n**Data Lineage and Traceability**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Lineage tracking documented. If Non-Compliant: No lineage management. If Not Applicable: N/A. If Unknown: Data flow mentioned but lineage unclear]\n- Source: [ARCHITECTURE.md Section 4 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data lineage tracking and audit trails in Section 4]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE6]\n\n---\n\n### 6.4 Backup and Recovery Strategy\n\n**Backup Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup approach documented. If Non-Compliant: No backup strategy. If Not Applicable: Stateless system. If Unknown: Backups mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 11.3 (Backup and Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define backup frequency, retention, and scope in Section 11.3]\n\n**Recovery Time Objective (RTO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RTO documented. If Non-Compliant: RTO not defined. If Not Applicable: N/A. If Unknown: Recovery mentioned but RTO unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define acceptable recovery time objective in Section 11.3]\n\n**Recovery Point Objective (RPO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RPO documented. If Non-Compliant: RPO not defined. If Not Applicable: N/A. If Unknown: Data loss tolerance mentioned but RPO unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define acceptable data loss window in Section 11.3]\n\n**Disaster Recovery Testing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: DR testing documented. If Non-Compliant: No testing plan. If Not Applicable: N/A. If Unknown: Testing mentioned but schedule unclear]\n- Source: [ARCHITECTURE.md Section 11.3 or Section 11.4 (Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document DR testing frequency and procedures in Section 11.3 or 11.4]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE6]\n\n---\n\n## 7. API First / Event Driven (LAE7)\n\n**Requirement**: Ensure solution design exposes APIs/events for interoperability.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / API Lead or N/A]\n\n### 7.1 API Strategy and Design\n\n**API Design Approach**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API-first design documented. If Non-Compliant: No API strategy. If Not Applicable: Standalone system. If Unknown: APIs mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API-first design principles in Section 4 or 9]\n\n**API Specification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API contracts documented. If Non-Compliant: API specifications not defined. If Not Applicable: N/A. If Unknown: Endpoints mentioned but specification unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document OpenAPI/Swagger specifications or GraphQL schemas in Section 4 or 9]\n\n**API Versioning Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Versioning approach documented. If Non-Compliant: No versioning strategy. If Not Applicable: N/A. If Unknown: Versioning mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define API versioning and deprecation strategy in Section 4 or 11]\n\n**API Security**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API security documented. If Non-Compliant: Security not addressed. If Not Applicable: N/A. If Unknown: Security mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document OAuth2, API keys, or JWT authentication in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE7]\n\n---\n\n### 7.2 Decouple Through Events\n\n**Event Streaming Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event platform documented. If Non-Compliant: No async event decoupling. If Not Applicable: Request-response sufficient. If Unknown: Events mentioned but platform unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 6 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document Kafka, Event Grid, EventBridge, or Pub/Sub usage in Section 4 or 6]\n\n**Event Schema Design**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event contracts documented. If Non-Compliant: Event schemas not defined. If Not Applicable: N/A. If Unknown: Events mentioned but schema unclear]\n- Source: [ARCHITECTURE.md Section 4 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define event schema standards (CloudEvents, Avro, JSON Schema) in Section 4]\n\n**Event Catalog**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event inventory documented. If Non-Compliant: Events not cataloged. If Not Applicable: N/A. If Unknown: Events mentioned but catalog unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document event types, publishers, and subscribers in Section 4 or 9]\n\n**Event Replay and Debugging**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event debugging documented. If Non-Compliant: No replay capability. If Not Applicable: N/A. If Unknown: Event handling mentioned but replay unclear]\n- Source: [ARCHITECTURE.md Section 11 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document event replay and troubleshooting approach in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE7]\n\n---\n\n### 7.3 Interoperability Standards\n\n**Integration Patterns**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Integration approach documented. If Non-Compliant: Integration patterns not defined. If Not Applicable: Standalone system. If Unknown: Integration mentioned but patterns unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document REST, GraphQL, gRPC, or messaging patterns in Section 4 or 9]\n\n**Data Exchange Formats**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data formats documented. If Non-Compliant: Formats not standardized. If Not Applicable: N/A. If Unknown: Data exchange mentioned but formats unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Standardize on JSON, XML, Protobuf, or other formats in Section 4 or 9]\n\n**API Gateway and Management**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API management documented. If Non-Compliant: No API gateway. If Not Applicable: Direct API exposure acceptable. If Unknown: Gateway mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API gateway for rate limiting, authentication, monitoring in Section 4 or 9]\n\n**Third-Party Integration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: External integrations documented. If Non-Compliant: Third-party APIs not specified. If Not Applicable: No external integrations. If Unknown: Integrations mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section 4 or Section 9 or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document external API dependencies and integration approach in Section 4 or 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAE7]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Key Enterprise Architecture Terms**:\n\n- **Modularity**: Design approach enabling independent development and deployment of capabilities\n- **Capability Reusability**: Ability to leverage existing components across multiple solutions\n- **Technology Radar**: Framework for tracking and evaluating technology maturity and adoption\n- **Zero Obsolescence**: Strategy to prevent technical debt through continuous modernization\n- **Managed Data Vision**: Centralized data strategy ensuring data as strategic asset\n- **API First**: Design principle prioritizing API interfaces for all integrations\n- **Decouple Through Events**: Pattern using async events to decouple components where temporal independence is prioritized\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Abbreviations**:\n\n- **LAE**: Enterprise Architecture (Lineamiento de Arquitectura Empresarial)\n- **API**: Application Programming Interface\n- **EDA**: Event Decoupling Architecture\n- **MDM**: Master Data Management\n- **ESB**: Enterprise Service Bus\n- **SOA**: Service-Oriented Architecture\n\n---\n\n### A.2 Validation Methodology\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=enterprise-architecture -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Enterprise Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Missing modularity analysis | LAE1 Non-Compliant | Section 5 (Component View) | Document component boundaries, interfaces, bounded contexts |\n| No technology radar reference | LAE3 Non-Compliant | Section 8 (Technology Stack) | Align stack with approved enterprise technologies, reference radar |\n| Undefined data strategy | LAE6 Non-Compliant | Section 6 (Data Model) | Document data governance, MDM, data lake/warehouse strategy |\n| Missing API-first approach | LAE7 Non-Compliant | Section 7 (Integration View) | Define API strategy, selective async patterns, integration standards |\n| Strategic alignment unclear | LAE2 Unknown | Section 1 (Business Context) | Map architecture to enterprise strategic goals and objectives |\n| Enterprise integration patterns undefined | LAE4 Unknown | Section 7 (Integration View) | Define integration patterns, ESB/API gateway, messaging |\n| Governance framework missing | LAE5 Unknown | Section 12 (ADRs) or Section 11 | Document architectural governance, review boards, decision authority |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Enterprise Architecture-Specific Examples**:\n\n**Example 1: Modularity and Bounded Contexts**\n- **Gap**: Missing modularity analysis and bounded contexts\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add modularity analysis to Section 5:\n   Bounded contexts: Customer, Order, Payment, Inventory, Shipping,\n   Component boundaries: clear domain separation, anti-corruption layers,\n   Interface definitions: REST APIs with OpenAPI specs,\n   Cross-cutting concerns: logging, monitoring, security centralized,\n   Domain dependencies: DAG (directed acyclic graph) with no circular refs\"\n  ```\n- **Expected Outcome**: Section 5 with bounded contexts, boundaries, interfaces, dependencies\n- **Impact**: LAE1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: Technology Radar Alignment**\n- **Gap**: No technology radar reference\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add technology radar alignment to Section 8:\n   All technologies from enterprise radar quadrants,\n   Adopt: Kubernetes, React, PostgreSQL, Kafka,\n   Trial: Temporal workflow, GraphQL, Dapr,\n   Assess: None (stable stack),\n   Hold: Avoiding deprecated ESB, SOAP, monolithic databases,\n   Radar version: Q4 2025, link to enterprise radar\"\n  ```\n- **Expected Outcome**: Section 8 with radar alignment, quadrants, version reference\n- **Impact**: LAE3 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Data Strategy and Governance**\n- **Gap**: Undefined data strategy\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add data strategy to Section 6:\n   Data governance: centralized data governance board,\n   MDM: customer and product master data in dedicated MDM system,\n   Data lake: S3 with Delta Lake for raw/curated/gold zones,\n   Data warehouse: Snowflake for analytics and BI,\n   Data catalog: AWS Glue Data Catalog with business glossary,\n   Retention: operational 30 days, analytics 7 years, GDPR compliance\"\n  ```\n- **Expected Outcome**: Section 6 with data governance, MDM, lake/warehouse strategy, catalog\n- **Impact**: LAE6 ‚Üí Compliant (+0.5 points)\n\n**Example 4: API-First and Integration Strategy**\n- **Gap**: Missing API-first approach and integration patterns\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add API-first strategy to Section 7:\n   API gateway: Kong for all external APIs,\n   Design-first: OpenAPI specs reviewed before implementation,\n   Integration patterns: REST for sync, Kafka for selective async decoupling,\n   Event bus: Kafka with schema registry (Avro),\n   API lifecycle: design ‚Üí review ‚Üí implement ‚Üí publish ‚Üí deprecate,\n   Versioning: URI versioning (/v1/, /v2/), backward compatibility required\"\n  ```\n- **Expected Outcome**: Section 7 with API-first strategy, integration patterns, event bus\n- **Impact**: LAE7 ‚Üí Compliant (+0.5 points)\n\n**Example 5: Strategic Alignment and Governance**\n- **Gap**: Strategic alignment and governance framework missing\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add strategic alignment to Section 1 and governance to Section 12:\n   Strategic goals: digital transformation, cloud-first, API-first,\n   Business objectives: reduce time-to-market 50%, improve scalability,\n   Architecture principles: align with 9 principles in Section 3,\n   Governance: Enterprise Architecture Review Board (EARB),\n   Decision authority: EARB for strategic, team for tactical,\n   ADR process: template, review, approval, publication\"\n  ```\n- **Expected Outcome**: Section 1 with strategic alignment, Section 12 with governance framework\n- **Impact**: LAE2 + LAE5 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required enterprise architecture fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all strategic decisions\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Strategic and Modular Architecture** (estimated impact: +0.6 points)\n   - Document modularity analysis: bounded contexts, component boundaries, interfaces (Section 5)\n   - Map architecture to enterprise strategic goals and business objectives (Section 1)\n   - Define technology radar alignment with quadrants (Adopt, Trial, Assess, Hold) in Section 8\n   - Add domain-driven design principles: aggregates, entities, value objects (Section 5 or 6)\n   - Document cross-cutting concerns: logging, monitoring, security, configuration (Section 5)\n\n2. **Establish Data and Integration Strategy** (estimated impact: +0.3 points)\n   - Define data strategy: governance, MDM, data lake/warehouse (Section 6)\n   - Add API-first approach: design-first, OpenAPI, lifecycle management (Section 7)\n   - Document integration patterns: REST, selective async, messaging, ESB/API gateway (Section 7)\n   - Specify data catalog with business glossary and lineage (Section 6)\n   - Define async event decoupling: Kafka, schema registry, event catalog (Section 7)\n\n3. **Enhance Governance and Standards** (estimated impact: +0.2 points)\n   - Document architectural governance framework: review boards, decision authority (Section 12 or 11)\n   - Add ADR process: template, review, approval, publication (Section 12)\n   - Define technology standards: approved libraries, frameworks, patterns (Section 8)\n   - Specify architecture compliance checks and validation gates (Section 11 or 12)\n   - Add architecture evolution roadmap with milestones (Section 1 or 12)\n\n**Priority Order**: LAE1 (modularity) ‚Üí LAE3 (technology radar) ‚Üí LAE6 (data strategy) ‚Üí LAE7 (API-first) ‚Üí LAE2 (strategic alignment) ‚Üí LAE5 (governance) ‚Üí LAE4 (integration patterns)\n\n**Estimated Final Score After Remediation**: 8.3-8.8/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with standardized template structure\n- Total: 7 validation data points across LAE1-LAE7 requirements\n\n**Version 1.0 (Previous)**:\n- Initial template with minimal appendix\n- Basic PLACEHOLDER approach\n- Limited source traceability\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=enterprise-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=enterprise-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=enterprise-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=enterprise-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=enterprise-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_INTEGRATION_ARCHITECTURE.md": "# Compliance Contract: Integration Architecture\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 5, 6, 7, 9)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=integration-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=integration-architecture -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\nThis Integration Architecture compliance contract validates 7 LAI (Integration Architecture) requirements to ensure integration best practices, security, technology currency, governance compliance, third-party documentation, traceability, and async event decoupling standards.\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAI1 | Best Practices Adoption | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect or N/A] |\n| LAI2 | Secure Integrations | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Security Architect / Integration Architect or N/A] |\n| LAI3 | No Obsolete Integration Technologies | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / Enterprise Architect or N/A] |\n| LAI4 | Integration Governance Standards | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / Governance Board or N/A] |\n| LAI5 | Third-Party Documentation | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / API Product Owner or N/A] |\n| LAI6 | Traceability and Audit | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / SRE Team or N/A] |\n| LAI7 | Async Event Decoupling Integration Compliance | Integration Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Architect / Event Architect or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Best Practices Adoption (LAI1)\n\n**Requirement**: Ensure each domain microservice is accessible via a domain API following integration best practices including API design, versioning, error handling, and documentation.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect or N/A]\n\n### 1.1 Domain API Accessibility\n\n**Domain Microservices with APIs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All domain microservices expose domain APIs documented in integration catalog. If Non-Compliant: Microservices exist without domain API exposure. If Not Applicable: No domain microservices architecture. If Unknown: Domain API accessibility not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Domain APIs / API Catalog) or Section 5 (Component Model ‚Üí Microservices), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document domain API endpoints for each microservice in Section 7. Ensure each bounded context exposes a well-defined API]\n\n**API Catalog Completeness**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Complete API catalog with endpoints, methods, authentication documented. If Non-Compliant: API catalog missing or incomplete. If Not Applicable: No APIs. If Unknown: API catalog not referenced]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Catalog / Integration Catalog), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create comprehensive API catalog in Section 7 listing all domain APIs with endpoints, authentication, and SLAs]\n\n### 1.2 API Design Best Practices\n\n**RESTful API Design Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: APIs follow REST principles (resource-oriented, HTTP verbs, stateless, JSON). If Non-Compliant: Non-RESTful design or RPC-style endpoints. If Not Applicable: No REST APIs (SOAP/GraphQL only). If Unknown: API design principles not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Design Standards) or Section 5 (Component Model ‚Üí API Design), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document REST API design standards in Section 7. Include resource naming conventions, HTTP verb usage (GET, POST, PUT, DELETE), status codes]\n\n**API Versioning Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API versioning strategy defined (URL path, header, or query parameter versioning). If Non-Compliant: No versioning or breaking changes without version management. If Not Applicable: Internal-only APIs with controlled clients. If Unknown: Versioning strategy not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Versioning), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define API versioning strategy in Section 7 (e.g., /v1/, /v2/ in URL path). Document backward compatibility policy]\n\n**Error Handling Standards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Standardized error response format (HTTP status codes, error codes, messages). If Non-Compliant: Inconsistent error responses or missing error handling. If Not Applicable: N/A (error handling generally required). If Unknown: Error handling not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Error Handling) or Section 5 (Component Model ‚Üí API Error Handling), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document error handling standards in Section 7. Include HTTP status code usage (4xx client errors, 5xx server errors), error response schema with error codes and messages]\n\n### 1.3 API Documentation\n\n**API Documentation Standards**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: APIs documented with OpenAPI/Swagger specifications, endpoints, request/response schemas. If Non-Compliant: APIs lack documentation or outdated documentation. If Not Applicable: No APIs. If Unknown: API documentation approach not specified]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Documentation), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement OpenAPI 3.0 specification for all APIs in Section 7. Include endpoint descriptions, authentication requirements, request/response examples]\n\n---\n\n## 2. Secure Integrations (LAI2)\n\n**Requirement**: Demonstrate secure integration of APIs and microservices following cybersecurity guidelines including authentication, authorization, encryption, and security monitoring.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Security Architect / Integration Architect or N/A]\n\n### 2.1 Integration Authentication\n\n**API Authentication Mechanism**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Secure authentication for all APIs (OAuth 2.0, JWT, API keys with rotation, mTLS). If Non-Compliant: Basic authentication, hardcoded credentials, or no authentication. If Not Applicable: No external integrations. If Unknown: Authentication mechanism not documented]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí API Security / Authentication) or Section 7 (Integration View ‚Üí Authentication), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API authentication in Section 9. Implement OAuth 2.0 or JWT for user-context APIs, mTLS for service-to-service]\n\n**Service-to-Service Authentication**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Microservices use secure service-to-service authentication (mTLS, service identity, JWT). If Non-Compliant: No service authentication or network-only security. If Not Applicable: Monolithic architecture. If Unknown: Service authentication not specified]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Service Authentication), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement mTLS or service mesh with service identity in Section 9. Document service authentication mechanism]\n\n### 2.2 Integration Authorization\n\n**API Authorization Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authorization model defined (RBAC, ABAC, scope-based) with fine-grained access control. If Non-Compliant: No authorization or all-or-nothing access. If Not Applicable: Public read-only APIs. If Unknown: Authorization not documented]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authorization / Access Control), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define authorization model in Section 9 with roles, scopes, and permissions. Implement RBAC or ABAC for API access control]\n\n### 2.3 Integration Encryption\n\n**Data in Transit Encryption**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All integrations use TLS 1.2+ encryption for data in transit. If Non-Compliant: Unencrypted communications or TLS 1.0/1.1. If Not Applicable: No external communications. If Unknown: Encryption not documented]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Encryption / TLS Configuration), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enforce TLS 1.2+ for all API communications in Section 9. Disable older TLS versions (1.0, 1.1)]\n\n**Secrets Management for Integration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API credentials and secrets stored in vault (Azure Key Vault, HashiCorp Vault, AWS Secrets Manager). If Non-Compliant: Credentials in code, configuration files, or environment variables. If Not Applicable: No secrets required. If Unknown: Secrets management not documented]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Secrets Management), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement vault-based secrets management in Section 9. Store all API keys, tokens, and credentials in approved vault]\n\n### 2.4 Integration Security Monitoring\n\n**Integration Security Logging**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Security events for integrations logged (authentication failures, authorization denials, anomalous traffic). If Non-Compliant: No security logging for integrations. If Not Applicable: N/A (security logging required). If Unknown: Security logging not documented]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Security Logging) or Section 7 (Integration View ‚Üí Logging), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement security event logging for all integrations in Section 9. Include authentication attempts, authorization decisions, and security exceptions]\n\n---\n\n## 3. No Obsolete Integration Technologies (LAI3)\n\n**Requirement**: Confirm no use of obsolete integration technologies, ensuring all integration protocols, message formats, and middleware are current and supported.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / Enterprise Architect or N/A]\n\n### 3.1 Integration Protocol Currency\n\n**REST API Protocol Version**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: REST APIs use HTTP/1.1 or HTTP/2, JSON format, modern standards. If Non-Compliant: HTTP/1.0 or deprecated XML-RPC. If Not Applicable: No REST APIs. If Unknown: Protocol version not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí REST APIs / Protocols), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Upgrade to HTTP/1.1 or HTTP/2 in Section 7. Use JSON for data interchange]\n\n**SOAP Version (if applicable)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: SOAP 1.2 with documented migration path to REST. If Non-Compliant: SOAP 1.0 or no migration plan. If Not Applicable: No SOAP integrations. If Unknown: SOAP version not specified]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí SOAP APIs), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: If using SOAP, upgrade to SOAP 1.2 and document REST migration plan in Section 7]\n\n### 3.2 Messaging Technology Currency\n\n**Message Broker Technology**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Modern message broker (Kafka, RabbitMQ, Azure Service Bus, AWS SQS/SNS) with current version. If Non-Compliant: Deprecated broker (WebSphere MQ 7.x, MSMQ) or end-of-life version. If Not Applicable: No messaging middleware. If Unknown: Message broker not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Messaging / Event Bus) or Section 5 (Component Model ‚Üí Message Broker), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Migrate to modern message broker in Section 7 (Kafka for high throughput, RabbitMQ for general messaging, cloud-native for managed services)]\n\n**Event Streaming Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Modern event streaming (Apache Kafka, Azure Event Hubs, AWS Kinesis, Confluent Cloud). If Non-Compliant: Legacy polling or batch file transfer. If Not Applicable: No event streaming. If Unknown: Event platform not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Streaming) or Section 7 (Integration View ‚Üí Event Bus), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement modern event streaming platform in Section 6/7 for real-time data integration]\n\n### 3.3 Integration Middleware Currency\n\n**ESB/Integration Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Modern integration platform (MuleSoft, Azure Logic Apps, AWS Step Functions) or no ESB (cloud-native). If Non-Compliant: Legacy ESB (Oracle SOA Suite 11g, WebSphere ESB) without upgrade path. If Not Applicable: No ESB (microservices with direct integration). If Unknown: Integration platform not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Integration Platform) or Section 5 (Component Model ‚Üí Integration Middleware), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: If using ESB, document upgrade to current version or migration to cloud-native integration in Section 7. Prefer serverless integration or API-first approach]\n\n---\n\n## 4. Integration Governance Standards (LAI4)\n\n**Requirement**: Ensure all APIs and microservices follow the integration governance playbook including naming conventions, API lifecycle management, change control, and compliance with organizational standards.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / Governance Board or N/A]\n\n### 4.1 API Naming Conventions\n\n**API Naming Standards Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: APIs follow organizational naming conventions (resource naming, URI structure, operation naming). If Non-Compliant: Inconsistent naming or non-standard URI patterns. If Not Applicable: No APIs. If Unknown: Naming standards not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Standards / Naming Conventions), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API naming conventions in Section 7. Follow RESTful resource naming (plural nouns, lowercase, hyphens for multi-word resources)]\n\n**Endpoint Standardization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Endpoints follow standard patterns (base URL, version prefix, resource path). If Non-Compliant: Ad-hoc endpoint structures. If Not Applicable: No APIs. If Unknown: Endpoint standards not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Endpoint Standards), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Standardize endpoint structure in Section 7 (e.g., https://api.domain.com/v1/{resource}/{id})]\n\n### 4.2 API Lifecycle Management\n\n**API Lifecycle Governance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API lifecycle stages defined (design, development, testing, production, deprecation). If Non-Compliant: No lifecycle management or uncontrolled API changes. If Not Applicable: No APIs. If Unknown: Lifecycle management not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Lifecycle), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API lifecycle stages in Section 7. Include approval gates for production promotion and deprecation policies]\n\n**API Change Control**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API changes follow governance process (change request, impact analysis, stakeholder approval). If Non-Compliant: Uncontrolled API changes causing breaking changes. If Not Applicable: No APIs or single client. If Unknown: Change control not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Change Control), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement API change control process in Section 7. Require impact analysis and consumer notification for breaking changes]\n\n### 4.3 Governance Playbook Compliance\n\n**Integration Governance Playbook Reference**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Architecture references organizational integration governance playbook with compliance confirmation. If Non-Compliant: No playbook reference or non-compliance. If Not Applicable: No organizational playbook. If Unknown: Playbook compliance not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Governance Compliance) or Section 12 (ADRs ‚Üí Governance Decisions), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Reference integration governance playbook in Section 7. Document compliance or exceptions with justification]\n\n**API Review and Approval Process**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API review process with architecture review board approval before production. If Non-Compliant: No review process or self-approved APIs. If Not Applicable: No APIs. If Unknown: Review process not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Review Process), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Establish API review process in Section 7 with architecture board approval gate]\n\n---\n\n## 5. Third-Party Documentation (LAI5)\n\n**Requirement**: Ensure all third-party APIs, microservices, and events provide proper documentation including API specifications, SLAs, support contacts, and integration guides.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / API Product Owner or N/A]\n\n### 5.1 Third-Party API Inventory\n\n**Third-Party API Catalog**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Complete inventory of third-party APIs with vendor, purpose, endpoint, authentication. If Non-Compliant: Third-party APIs used without central catalog. If Not Applicable: No third-party API consumption. If Unknown: Third-party API inventory not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Third-Party APIs / External Integrations), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create third-party API inventory in Section 7 listing vendor, API name, base URL, authentication method, contact]\n\n**External Service Dependencies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: External dependencies documented with service names, vendors, criticality. If Non-Compliant: Undocumented external dependencies. If Not Applicable: No external dependencies. If Unknown: Dependencies not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí External Dependencies), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document all external service dependencies in Section 7 with criticality assessment (critical, high, medium, low)]\n\n### 5.2 Third-Party API Documentation Standards\n\n**API Specification Availability**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party APIs provide OpenAPI/Swagger specification or equivalent documentation. If Non-Compliant: APIs lack formal specification. If Not Applicable: No third-party APIs. If Unknown: API documentation availability not confirmed]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Third-Party API Documentation), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify third-party API documentation in Section 7. Request OpenAPI spec from vendors or create internal specification]\n\n**Integration Guides and Examples**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party vendors provide integration guides, code examples, SDKs. If Non-Compliant: Minimal documentation or trial-and-error integration. If Not Applicable: No third-party integrations. If Unknown: Integration guide availability not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Third-Party Integration Guides), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document integration guide availability in Section 7. Request comprehensive integration documentation from vendors]\n\n### 5.3 Third-Party SLA and Support\n\n**Third-Party SLA Documentation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: SLAs documented for third-party APIs (availability, response time, rate limits). If Non-Compliant: No SLA documentation or unknown service levels. If Not Applicable: No third-party APIs. If Unknown: SLAs not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Third-Party SLAs), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document third-party API SLAs in Section 7. Include availability guarantees, response time targets, rate limits]\n\n**Support Contact Information**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Support contacts documented for third-party vendors (email, portal, escalation path). If Non-Compliant: No support contact information. If Not Applicable: No third-party APIs. If Unknown: Support contacts not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Third-Party Support Contacts), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document third-party vendor support contacts in Section 7 with escalation procedures]\n\n---\n\n## 6. Traceability and Audit (LAI6)\n\n**Requirement**: Guarantee integration with standard formats for logs and traces, ensuring distributed tracing, correlation IDs, structured logging, and integration with observability platforms.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / SRE Team or N/A]\n\n### 6.1 Distributed Tracing\n\n**Distributed Tracing Implementation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Distributed tracing implemented across all integrations (OpenTelemetry, Jaeger, Zipkin, Azure Application Insights). If Non-Compliant: No distributed tracing or siloed tracing. If Not Applicable: Monolithic application with no distributed calls. If Unknown: Distributed tracing not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Distributed Tracing) or Section 5 (Component Model ‚Üí Observability), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement distributed tracing in Section 7 using OpenTelemetry standard. Instrument all API calls and service-to-service communications]\n\n**Trace Context Propagation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Trace context propagated across service boundaries (W3C Trace Context standard, correlation IDs in headers). If Non-Compliant: Trace context not propagated or broken trace chains. If Not Applicable: No distributed architecture. If Unknown: Trace propagation not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Trace Propagation), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement W3C Trace Context standard in Section 7. Propagate traceparent and tracestate headers across all integrations]\n\n### 6.2 Structured Logging\n\n**Structured Logging Format**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Structured logging with standard format (JSON, key-value pairs, consistent schema). If Non-Compliant: Unstructured text logs or inconsistent formats. If Not Applicable: N/A (logging required). If Unknown: Logging format not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Logging Standards) or Section 5 (Component Model ‚Üí Logging), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement structured JSON logging in Section 7 with standard fields (timestamp, level, message, correlation_id, service_name)]\n\n**Log Correlation IDs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All logs include correlation IDs for request tracing across services. If Non-Compliant: Logs lack correlation IDs or inconsistent ID usage. If Not Applicable: N/A (correlation required). If Unknown: Correlation ID usage not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Correlation IDs), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement correlation ID propagation in Section 7. Generate at API gateway, propagate through all service calls, include in all log entries]\n\n### 6.3 Observability Platform Integration\n\n**Centralized Logging Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Logs sent to centralized platform (ELK Stack, Splunk, Azure Monitor, AWS CloudWatch). If Non-Compliant: Logs stored locally or not centralized. If Not Applicable: N/A (centralized logging required). If Unknown: Logging platform not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Logging Platform) or Section 5 (Component Model ‚Üí Logging Infrastructure), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement centralized logging in Section 7. Ship all integration logs to organizational logging platform]\n\n**Trace and Log Integration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Traces and logs integrated with unified correlation (trace ID in logs, log links in traces). If Non-Compliant: Traces and logs in separate systems without correlation. If Not Applicable: No distributed tracing. If Unknown: Trace-log integration not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Observability Integration), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Integrate traces and logs in Section 7. Include trace IDs in log entries and provide log query links in trace UIs]\n\n---\n\n## 7. Async Event Decoupling Integration Compliance (LAI7)\n\n**Requirement**: Ensure compliance with async event decoupling guidelines including event schema standards, event versioning, event catalog, consumer contracts, and event delivery guarantees.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / Event Architect or N/A]\n\n### 7.1 Event Schema Standards\n\n**Event Schema Definition**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event schemas defined with standard format (JSON Schema, Avro, Protocol Buffers). If Non-Compliant: Unstructured events or no schema validation. If Not Applicable: No async event decoupling. If Unknown: Event schemas not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Schemas) or Section 7 (Integration View ‚Üí Event Definitions), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define event schemas in Section 6 using JSON Schema or Avro. Include schema versioning and validation]\n\n**CloudEvents Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Events follow CloudEvents specification for metadata (id, source, type, time). If Non-Compliant: Custom event format without standard metadata. If Not Applicable: No async event decoupling. If Unknown: CloudEvents compliance not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Format / CloudEvents), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Adopt CloudEvents specification in Section 6 for event metadata standardization. Include required fields: id, source, specversion, type]\n\n### 7.2 Event Versioning and Compatibility\n\n**Event Versioning Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event versioning strategy defined (schema evolution, backward/forward compatibility). If Non-Compliant: Breaking schema changes without versioning. If Not Applicable: No events. If Unknown: Event versioning not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Versioning), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define event versioning strategy in Section 6. Include schema evolution rules (add optional fields, deprecate fields gracefully)]\n\n**Schema Registry Implementation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Schema registry used for event schema management (Confluent Schema Registry, Azure Schema Registry). If Non-Compliant: No schema registry or manual schema management. If Not Applicable: No async event decoupling. If Unknown: Schema registry not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Schema Registry) or Section 5 (Component Model ‚Üí Schema Registry), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement schema registry in Section 6 for centralized schema versioning and compatibility checks]\n\n### 7.3 Event Catalog and Governance\n\n**Event Catalog**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event catalog documenting all events (name, schema, producers, consumers, purpose). If Non-Compliant: Events lack documentation or unknown producers/consumers. If Not Applicable: No events. If Unknown: Event catalog not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Catalog) or Section 7 (Integration View ‚Üí Event Catalog), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create event catalog in Section 6/7 listing all domain events, event types, producers, consumers, and schemas]\n\n**Consumer Contracts**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Consumer contracts defined for event subscriptions (consumer testing, contract testing). If Non-Compliant: No consumer contracts or unknown event dependencies. If Not Applicable: No events. If Unknown: Consumer contracts not documented]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Consumer Contracts), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define consumer contracts in Section 7. Implement contract testing to prevent breaking changes for consumers]\n\n### 7.4 Event Delivery Guarantees\n\n**Event Delivery Semantics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event delivery guarantees defined (at-least-once, at-most-once, exactly-once). If Non-Compliant: Undefined delivery semantics or message loss/duplication. If Not Applicable: No events. If Unknown: Delivery guarantees not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Event Delivery Guarantees) or Section 7 (Integration View ‚Üí Messaging Guarantees), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define event delivery guarantees in Section 6. Document idempotency requirements for at-least-once delivery]\n\n**Dead Letter Queue (DLQ) Handling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: DLQ configured for failed event processing with monitoring and retry policies. If Non-Compliant: No DLQ or unmonitored failures. If Not Applicable: No asynchronous events. If Unknown: DLQ handling not documented]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Dead Letter Queue) or Section 7 (Integration View ‚Üí Error Handling), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement DLQ for event failures in Section 6. Define retry policies, monitoring, and manual intervention procedures]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Integration Architecture**: The design and implementation of connections between systems, services, and data sources using APIs, events, messaging, and other integration patterns.\n\n**Domain API**: RESTful API exposing a bounded context's capabilities following domain-driven design principles.\n\n**LAI (Integration Architecture Requirements)**: Organizational standards for integration architecture covering best practices, security, technology currency, governance, documentation, traceability, and selective async patterns.\n\n**API Catalog**: Comprehensive inventory of all APIs including endpoints, authentication, SLAs, consumers, and documentation.\n\n**Distributed Tracing**: Observability technique tracking requests across distributed services using correlation IDs and trace context.\n\n**CloudEvents**: CNCF specification for describing events in a common format to ensure interoperability.\n\n**Schema Registry**: Centralized repository for event and message schemas with versioning and compatibility enforcement.\n\n**Dead Letter Queue (DLQ)**: Queue for messages/events that fail processing after retry attempts, enabling manual inspection and remediation.\n\n<!-- @include shared/fragments/status-codes.md -->\n\n---\n\n### A.2 Validation Methodology\n\nThis document is validated using an automated scoring system defined in `/skills/architecture-compliance/validation/integration_architecture_validation.json`.\n\n**Validation Process**:\n\n1. **Completeness Check (30% weight)**:\n   - Counts filled data points across all LAI requirements\n   - Formula: (Filled fields / Total required fields) √ó 10\n   - Example: 19 out of 21 fields = 9.0/10 completeness\n\n2. **Compliance Check (60% weight)**:\n   - Evaluates each validation item as PASS/FAIL/N/A/UNKNOWN/EXCEPTION\n   - Formula: (PASS + N/A + EXCEPTION items) / Total items √ó 10\n   - **CRITICAL**: N/A items MUST be included in numerator\n   - Example: 15 PASS + 4 N/A + 0 EXCEPTION out of 21 items = (15+4)/21 √ó 10 = 9.0/10\n\n3. **Quality Check (10% weight)**:\n   - Assesses source traceability (ARCHITECTURE.md section references)\n   - Verifies explanation quality and actionable notes\n   - Formula: (Items with valid sources / Total items) √ó 10\n\n4. **Final Score Calculation**:\n   ```\n   Final Score = (Completeness √ó 0.3) + (Compliance √ó 0.6) + (Quality √ó 0.1)\n   ```\n\n**Validation Item Statuses**:\n- ‚úÖ **PASS** (10 points): Complies with LAI requirement\n- ‚ùå **FAIL** (0 points): Non-compliant or uses deprecated/insecure technologies\n- ‚ö™ **N/A** (10 points): Not applicable to this architecture (counts as compliant)\n- ‚ùì **UNKNOWN** (0 points): Missing data in ARCHITECTURE.md\n- üîì **EXCEPTION** (10 points): Documented and approved exception\n\n**Outcome Determination**:\n| Score Range | Document Status | Review Actor | Action |\n|-------------|----------------|--------------|--------|\n| 8.0-10.0 | Approved | System (Auto-Approved) | Ready for implementation |\n| 7.0-7.9 | In Review | Integration Architecture Review Board | Manual review required |\n| 5.0-6.9 | Draft | Architecture Team | Address integration gaps before review |\n| 0.0-4.9 | Rejected | N/A (Blocked) | Cannot proceed - critical integration failures |\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Integration Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| API catalog missing or incomplete | LAI1 Non-Compliant | Section 7 (Integration View) | List all domain APIs with endpoints, authentication, consumers, SLAs |\n| API design standards not documented | LAI1 Non-Compliant | Section 7 (Integration View) | Document REST principles, versioning strategy, error handling standards |\n| API authentication not specified | LAI2 Non-Compliant | Section 9 (Security Architecture) | Specify OAuth 2.0, JWT, or mTLS for API security |\n| Integration protocols undefined | LAI3 Unknown | Section 7 (Integration View) | Document HTTP/2, REST, message brokers (Kafka, RabbitMQ), no legacy ESB |\n| API governance not defined | LAI4 Unknown | Section 7 (Integration View) | Define API naming conventions, lifecycle management, change control |\n| Third-party API inventory missing | LAI5 Unknown | Section 7 (Integration View) | Inventory external APIs with vendors, endpoints, SLAs, support contacts |\n| Distributed tracing not implemented | LAI6 Unknown | Section 7 (Integration View) | Implement OpenTelemetry, correlation IDs, structured logging |\n| Event schemas not documented | LAI7 Unknown | Section 6 or 7 (Data Model/Integration) | Define event schemas with JSON Schema/Avro, CloudEvents compliance |\n| Schema registry not specified | LAI7 Unknown | Section 7 (Integration View) | Specify schema registry (Confluent, AWS Glue), backward compatibility |\n| Dead letter queue handling undefined | LAI7 Unknown | Section 7 (Integration View) | Define DLQ strategy, retention, reprocessing workflow |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Integration Architecture-Specific Examples**:\n\n**Example 1: Adding Comprehensive API Catalog**\n- **Gap**: Missing comprehensive API catalog\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add API catalog to Section 7 with table format:\n   API Name, Endpoint, Authentication, Consumers, SLA, Owner.\n   Include all domain APIs: User Service, Payment Service,\n   Notification Service, Inventory Service\"\n  ```\n- **Expected Outcome**: Section 7 with complete API catalog table including SLAs and ownership\n- **Impact**: LAI1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: Implementing Distributed Tracing**\n- **Gap**: No distributed tracing implementation documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add distributed tracing to Section 7:\n   OpenTelemetry SDK in all services,\n   Jaeger backend for trace storage,\n   W3C Trace Context propagation,\n   100% sampling in prod with adaptive sampling\"\n  ```\n- **Expected Outcome**: Section 7 with tracing architecture, propagation standards, backend config\n- **Impact**: LAI6 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Defining Schema Registry**\n- **Gap**: Missing schema registry for async event decoupling\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add schema registry to Section 7:\n   Confluent Schema Registry with Kafka,\n   Avro schemas for all events,\n   backward compatibility enforcement,\n   schema evolution policy\"\n  ```\n- **Expected Outcome**: Section 7 with schema registry config, versioning, compatibility rules\n- **Impact**: LAI7 ‚Üí Compliant (+0.4 points)\n\n**Example 4: API Governance Framework**\n- **Gap**: API governance not defined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add API governance to Section 7:\n   Naming convention (kebab-case, plural nouns),\n   Versioning strategy (URI versioning /v1/),\n   Lifecycle stages (alpha, beta, stable, deprecated),\n   Change control process with stakeholder approvals\"\n  ```\n- **Expected Outcome**: Section 7 with governance standards, playbook compliance\n- **Impact**: LAI4 ‚Üí Compliant (+0.5 points)\n\n**Example 5: Third-Party API Inventory**\n- **Gap**: Third-party API inventory incomplete\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add third-party API inventory to Section 7:\n   Stripe Payment API (REST, OAuth 2.0, 99.9% SLA, support@stripe.com),\n   SendGrid Email API (REST, API key, 99.95% SLA, support@sendgrid.com),\n   Twilio SMS API (REST, Basic Auth, 99.95% SLA, help@twilio.com)\n   Include API specs, integration guides, rate limits\"\n  ```\n- **Expected Outcome**: Section 7 with third-party API catalog, SLAs, support contacts\n- **Impact**: LAI5 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required integration architecture fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all integration points\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete API & Integration Documentation** (estimated impact: +0.6 points)\n   - Create comprehensive API catalog with endpoints, auth, consumers, SLAs (Section 7)\n   - Document API design standards: REST principles, versioning, error handling (Section 7)\n   - Define API governance: naming, lifecycle, change control (Section 7)\n   - Add third-party API inventory with vendors, endpoints, SLAs (Section 7)\n   - Specify integration protocols: HTTP/2, REST, message brokers (Section 7)\n\n2. **Enhance Observability & Decouple Through Events** (estimated impact: +0.3 points)\n   - Implement distributed tracing: OpenTelemetry, correlation IDs (Section 7)\n   - Add structured logging with centralized platform (Section 11)\n   - Define event schemas with JSON Schema/Avro (Section 6 or 7)\n   - Implement schema registry with backward compatibility (Section 7)\n   - Document DLQ handling and reprocessing workflow (Section 7)\n\n3. **Strengthen Security & Standards Compliance** (estimated impact: +0.2 points)\n   - Document API authentication: OAuth 2.0, JWT, or mTLS (Section 9)\n   - Add TLS 1.2+ encryption for all API communications (Section 9)\n   - Define secrets management for API keys (Vault, Key Vault) in Section 9\n   - Ensure CloudEvents compliance for selective async patterns (Section 7)\n   - Add API security logging and threat detection (Section 9)\n\n**Priority Order**: LAI1 (API catalog) ‚Üí LAI2 (API auth) ‚Üí LAI4 (API governance) ‚Üí LAI6 (distributed tracing) ‚Üí LAI5 (third-party APIs) ‚Üí LAI3 (protocols) ‚Üí LAI7 (event schemas)\n\n**For FAIL Items**:\n- **Obsolete Technologies**: Upgrade SOAP 1.0, WebSphere MQ, legacy ESB to REST, Kafka, modern integration\n- **Security Gaps**: Implement OAuth 2.0/mTLS, TLS 1.2+, vault-based secrets\n- **Missing Standards**: Implement API governance, event schema registry, CloudEvents compliance\n- **Approved Exceptions**: Document exception with risk acceptance in Section 12 (ADRs)\n\n**Estimated Final Score After Remediation**: 8.3-8.8/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n| Version | Date | Changes | Author |\n|---------|------|---------|--------|\n| 2.0 | [GENERATION_DATE] | Complete template replacement with 7 LAI requirements (LAI1-LAI7). Replaced generic integration catalog format with requirement-specific subsections following Cloud Architecture v2.0 structure. Added comprehensive validation framework with 21 subsections across 7 requirements. Added Data Extracted Successfully, Missing Data, Not Applicable, and Unknown Status sections. Aligned with standardized appendix format. | Integration Architecture Team |\n| 1.0 | [ORIGINAL_DATE] | Initial release with basic integration catalog and patterns. | Integration Architecture Team |\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=integration-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=integration-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=integration-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=integration-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=integration-architecture -->\n\n---\n\n**Note**: This compliance contract is automatically generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation. To update this document, modify the source architecture file and regenerate. All [PLACEHOLDER] items indicate missing data that should be added to ARCHITECTURE.md for complete compliance validation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_PLATFORM_IT_INFRASTRUCTURE.md": "# Compliance Contract: Platform and IT Infrastructure\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 4, 8, 10, 11)\n**Version**: 1.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=platform-it-infrastructure -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=platform-it-infrastructure -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAPI01 | Unique Production Environments | Platform & IT Infrastructure | [STATUS] | Section 4, 11 | Infrastructure Architect |\n| LAPI02 | Server Operating Systems | Platform & IT Infrastructure | [STATUS] | Section 8 | Platform Engineer |\n| LAPI03 | Database Storage Capacity | Platform & IT Infrastructure | [STATUS] | Section 8, 10 | Database Administrator |\n| LAPI04 | Database Version Authorization | Platform & IT Infrastructure | [STATUS] | Section 8 | Database Administrator |\n| LAPI05 | Database Backup and Retention | Platform & IT Infrastructure | [STATUS] | Section 11 | Database Administrator |\n| LAPI06 | Infrastructure Capacity | Platform & IT Infrastructure | [STATUS] | Section 8, 10 | Infrastructure Architect |\n| LAPI07 | Naming Conventions | Platform & IT Infrastructure | [STATUS] | Section 8, 11 | Infrastructure Architect |\n| LAPI08 | Transaction Volume Dimensioning | Platform & IT Infrastructure | [STATUS] | Section 10 | Integration Architect |\n| LAPI09 | Legacy Platform Transaction Capacity | Platform & IT Infrastructure | [STATUS] | Section 7, 10 | Integration Architect |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Unique Production Environments (LAPI01)\n\n**Requirement**: Validate unique production environment consistency and avoid environment crossing. Production must be isolated from non-production environments to prevent unauthorized access, data leakage, and configuration errors.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Infrastructure Architect / Cloud Architect or N/A]\n\n### 1.1 Environment Isolation\n\n**Environment Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Environment isolation clearly documented with separation mechanisms including infrastructure, network, and access controls. If Non-Compliant: Production environment not adequately isolated or mixed with other environments. If Not Applicable: Single environment deployment. If Unknown: Environment mentioned but isolation mechanisms unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment ‚Üí Environments) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document production environment isolation using network segmentation (VNets/VPCs), IAM policies with least privilege, and separate infrastructure resources in Section 11. Include environment naming conventions and access control policies]\n\n**Network Segmentation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Network isolation documented with VNet/VPC segregation, subnet separation, and security groups. If Non-Compliant: Network isolation not specified or production shares network resources with non-production. If Not Applicable: N/A. If Unknown: Network mentioned but segregation details unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Network Security) or Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define network isolation using separate VNets/VPCs, dedicated subnets, Network Security Groups (NSGs), and firewall rules for production. Document peering/connectivity restrictions between environments]\n\n**Access Controls**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Production access controls documented with RBAC, separate admin accounts, MFA requirements, and audit logging. If Non-Compliant: Access controls not defined or production uses same credentials as non-production. If Not Applicable: N/A. If Unknown: Access mentioned but control mechanisms unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document production access using RBAC with least privilege, separate administrative accounts for production, mandatory MFA, and just-in-time (JIT) access policies. Include audit logging for all production access]\n\n### 1.2 Environment Count\n\n**Number of Production Environments**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Single production environment documented (best practice for consistency). If Non-Compliant: Multiple production environments exist creating risk of environment crossing and data inconsistency. If Not Applicable: N/A. If Unknown: Production setup unclear or environment count not specified]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment ‚Üí Environments) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Best practice is single production environment. If business requires multiple production environments (e.g., regional deployments), document clear segregation, naming conventions, and data flow controls between them]\n\n### 1.3 Cross-Environment Data Flow\n\n**Data Flow Restrictions**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data flow restrictions between environments documented, including policies that production data must not flow to non-production and non-production cannot write to production. If Non-Compliant: No restrictions on cross-environment data flow or production data accessible from non-production. If Not Applicable: Single environment. If Unknown: Data flow mentioned but restrictions unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Flow Patterns) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data flow policies: production data must not flow to non-production environments, use anonymized/masked data in non-production, implement one-way data sync from production to non-production if required. Document approval process for exceptions]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI01, e.g., \"Section 4, lines X-Y; Section 9, lines A-B; Section 11, lines M-N\"]\n\n---\n\n## 2. Server Operating Systems (LAPI02)\n\n**Requirement**: Ensure deployment on servers with authorized Operating Systems. All server infrastructure must use OS platforms and versions approved by the organization's security and compliance standards.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Platform Engineer / Infrastructure Architect or N/A]\n\n### 2.1 Operating System Platforms\n\n**OS Platform and Version**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Operating system platforms and versions clearly documented (e.g., Ubuntu 22.04 LTS, Windows Server 2022, RHEL 9). If Non-Compliant: OS platform not specified or using deprecated/unsupported OS versions. If Not Applicable: Serverless/managed platform (e.g., Azure App Service, AWS Lambda). If Unknown: Infrastructure mentioned but OS details unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document specific OS platform and version for all server infrastructure in Section 8. For Kubernetes: document node OS (e.g., Azure Linux, Ubuntu). For VMs: document OS image and version. Include patching strategy and lifecycle policy]\n\n**Container Base Images** (if applicable): [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Container base images documented with specific versions (e.g., mcr.microsoft.com/dotnet/aspnet:8.0). If Non-Compliant: Container images not specified or using unofficial/unsupported base images. If Not Applicable: No containerization. If Unknown: Containers mentioned but base images unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Containerization) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document approved container base images in Section 8. Use official images from trusted registries (Microsoft Container Registry, Docker Official Images). Specify image digest/tag pinning strategy for reproducibility]\n\n### 2.2 OS Version Authorization\n\n**Authorization Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: OS versions verified against organizational approved OS list and documented. If Non-Compliant: OS version not on approved list or approval status unknown. If Not Applicable: Fully managed platform (no OS control). If Unknown: OS version documented but authorization status unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) compared against organizational OS approval list or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify OS version against organizational security standards and approved OS catalog. Document approval date and policy version. For cloud platforms: ensure OS is supported by cloud provider and receives security patches. Include OS end-of-life (EOL) tracking]\n\n**OS Patching Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: OS patching strategy documented with update frequency, testing procedures, and maintenance windows. If Non-Compliant: No patching strategy documented. If Not Applicable: Fully managed OS (cloud provider handles patching). If Unknown: Patching mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Maintenance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document OS patching strategy in Section 11: update frequency (e.g., monthly security patches, quarterly feature updates), testing process, rollback procedures, and maintenance windows. For Kubernetes: document node pool update strategy]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI02]\n\n---\n\n## 3. Database Storage Capacity (LAPI03)\n\n**Requirement**: Ensure required database storage capacity and availability. Database infrastructure must provide sufficient storage for current and projected data volumes with appropriate availability and scalability configurations.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Database Administrator / Cloud Architect or N/A]\n\n### 3.1 Database Capacity Configuration\n\n**Database Type and Size**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database platform, storage capacity, and tier/SKU documented (e.g., Azure SQL Database, 250 GB storage, General Purpose tier). If Non-Compliant: Database storage capacity not specified or insufficient for documented data volume. If Not Applicable: No persistent database (stateless architecture). If Unknown: Database mentioned but capacity details unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Databases) or Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document database storage capacity in Section 8 or Section 10: current allocated storage, current usage, storage growth rate, and projected capacity requirements. Include storage tier/SKU and IOPS/throughput specifications]\n\n**Current vs Projected Capacity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Current storage usage and projected growth documented with capacity planning horizon (e.g., current 60 GB, projected 150 GB in 12 months). If Non-Compliant: Projected capacity not documented or current usage approaching capacity limits. If Not Applicable: N/A. If Unknown: Storage mentioned but growth projections unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document capacity planning in Section 10: current database size, growth rate (GB/month), projected size at 6/12/24 months, and capacity headroom thresholds (e.g., maintain 30% free space). Include monitoring and alerting for capacity thresholds]\n\n### 3.2 Storage Scalability\n\n**Scaling Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage scaling strategy documented (auto-scaling, manual scaling, elastic pools) with scaling limits. If Non-Compliant: Scaling mechanism not specified or no scaling capability. If Not Applicable: N/A. If Unknown: Scaling mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Database Scaling) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document storage scaling strategy in Section 10: auto-scaling configuration (if available), manual scaling procedures, maximum storage limits, and scaling trigger thresholds. For cloud databases: specify tier/SKU upgrade path]\n\n**Storage Performance (IOPS/Throughput)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage IOPS and throughput requirements documented and matched to tier/SKU. If Non-Compliant: IOPS/throughput not specified or insufficient for workload. If Not Applicable: N/A. If Unknown: Performance mentioned but IOPS/throughput unclear]\n- Source: [ARCHITECTURE.md Section 10 (Performance Targets) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document storage performance requirements in Section 10: required IOPS, throughput (MB/s), latency targets, and verify tier/SKU provides sufficient performance. Include performance testing results]\n\n### 3.3 Availability Configuration\n\n**High Availability Setup**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database availability configuration documented (replicas, zones, geo-redundancy, SLA). If Non-Compliant: Availability configuration not specified or insufficient for RTO/RPO targets. If Not Applicable: Non-critical database (no HA requirement). If Unknown: Availability mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí High Availability) or Section 8 (Technology Stack ‚Üí Databases) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document HA configuration in Section 8 or 11: read replicas, availability zones, geo-replication, automatic failover configuration, and target SLA. Verify configuration meets RTO/RPO requirements. For cloud: specify availability zone configuration and failover policies]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI03]\n\n---\n\n## 4. Database Version Authorization (LAPI04)\n\n**Requirement**: Ensure storage components use authorized databases for On-Premise components. All database platforms and versions must be approved by organizational standards and security policies.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Database Administrator / Compliance Officer or N/A]\n\n### 4.1 Database Platform and Version\n\n**Database Platform**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database platform and version clearly documented (e.g., SQL Server 2022, PostgreSQL 15, MongoDB 7.0). If Non-Compliant: Database version not specified or using deprecated/unsupported version. If Not Applicable: No database component. If Unknown: Database mentioned but version unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Databases) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document specific database platform and version in Section 8. Include patch level for critical databases (e.g., SQL Server 2022 CU5). Verify version is supported by vendor and receives security updates]\n\n**On-Premise vs Cloud Managed**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Deployment model clearly documented (On-Premise, Cloud Managed, Hybrid). If Non-Compliant: Deployment model not specified. If Not Applicable: N/A. If Unknown: Database mentioned but deployment model unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture) or Section 8 (Technology Stack ‚Üí Databases) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document deployment model in Section 4 or 8. For On-Premise: LAPI04 applies to authorization requirements. For Cloud Managed (Azure SQL, RDS): note that cloud provider manages versions, but architecture should document which managed service version is used]\n\n### 4.2 Authorization Status\n\n**Approval Against Authorized List**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database version verified against organizational approved database catalog and documented. If Non-Compliant: Database version not on approved list or approval status unknown. If Not Applicable: Cloud managed database (authorization delegated to cloud provider's supported versions). If Unknown: Database version documented but authorization status unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Databases) compared against organizational database approval catalog or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify database version against organizational standards and approved database catalog. Document approval date, policy version, and any exceptions granted. For On-Premise databases: ensure version meets security requirements and has active vendor support. Include database end-of-life (EOL) tracking and upgrade plan for approaching EOL versions]\n\n**Vendor Support Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database version confirmed to be in active vendor support with documented EOL date. If Non-Compliant: Database version is EOL or approaching EOL without upgrade plan. If Not Applicable: N/A. If Unknown: Support status unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Databases) or vendor support documentation or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document vendor support status in Section 8: current support tier (mainstream, extended), EOL date, and upgrade plan if approaching EOL. For cloud managed databases: verify managed service version is within cloud provider's supported lifecycle]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI04]\n\n---\n\n## 5. Database Backup and Retention (LAPI05)\n\n**Requirement**: Reflect retention and backup policies for On-Premise databases and design backup environment capacity. Database backup strategy must ensure data protection, meet recovery objectives (RTO/RPO), and comply with retention policies.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Database Administrator / Business Continuity Manager or N/A]\n\n### 5.1 Backup Strategy\n\n**Backup Method**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup method documented (full, incremental, differential, continuous, snapshot) with frequency. If Non-Compliant: Backup method not specified or backups not implemented. If Not Applicable: Stateless database or cloud-managed automatic backups. If Unknown: Backups mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Backup & Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document backup strategy in Section 11: backup method (full/incremental/differential), backup frequency (daily, hourly, continuous), backup windows, and backup technology/tools. For cloud databases: document whether using cloud-native backup (e.g., Azure SQL automated backups) or custom backup solution]\n\n**Backup Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup frequency documented and aligned with RPO requirements (e.g., full daily, transaction log every 15 minutes). If Non-Compliant: Backup frequency not specified or insufficient for RPO targets. If Not Applicable: N/A. If Unknown: Backups mentioned but frequency unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Backup & Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document backup frequency in Section 11 aligned with RPO: full backups (daily/weekly), differential/incremental backups (hourly/daily), transaction log backups (15-60 minutes for minimal data loss). Verify backup frequency supports documented RPO]\n\n### 5.2 Retention Policies\n\n**Retention Period**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup retention periods documented (short-term and long-term) with compliance justification. If Non-Compliant: Retention periods not specified or don't meet compliance requirements. If Not Applicable: N/A. If Unknown: Retention mentioned but periods unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Backup & Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document retention policies in Section 11: short-term retention (7-35 days for operational recovery), long-term retention (1-7 years for compliance), and archival requirements. Include retention policy rationale (regulatory compliance, business requirements). For cloud: specify point-in-time restore window]\n\n**Retention Tiers**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Multi-tier retention documented (operational backups, compliance archives, geo-redundant copies). If Non-Compliant: Retention tiers not specified. If Not Applicable: Single retention tier sufficient. If Unknown: Retention mentioned but tier structure unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Backup & Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document retention tier strategy in Section 11: operational tier (hot storage, frequent access), compliance tier (warm/cold storage, infrequent access), and archival tier (cold storage, rare access). Include transition policies between tiers]\n\n### 5.3 Backup Storage Capacity\n\n**Backup Storage Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup storage capacity calculated and documented based on database size, retention period, and change rate. If Non-Compliant: Backup storage capacity not specified or insufficient. If Not Applicable: Cloud-managed backup (provider handles capacity). If Unknown: Backup storage mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Backup & Disaster Recovery) or Section 10 (Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document backup storage capacity in Section 11: calculation method (e.g., database size √ó retention days √ó change rate), current backup storage usage, projected growth, and storage location (on-premise SAN, cloud blob storage). Include monitoring for backup storage capacity]\n\n**Geo-Redundant Backup Storage**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Geo-redundant backup storage documented with replication to secondary region/site. If Non-Compliant: Backups not geo-redundant or replication not configured. If Not Applicable: No geo-redundancy requirement. If Unknown: Backup replication mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document geo-redundant backup strategy in Section 11: secondary backup location (region/datacenter), replication method (async/sync), replication frequency, and verification process. For cloud: specify geo-redundant storage (GRS) configuration]\n\n### 5.4 Recovery Procedures (RTO/RPO)\n\n**Recovery Time Objective (RTO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RTO documented and validated with backup solution capabilities (e.g., RTO: 4 hours). If Non-Compliant: RTO not specified or backup solution cannot meet RTO. If Not Applicable: No RTO requirement. If Unknown: RTO mentioned but not validated against backup capabilities]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document RTO target in Section 11 and validate backup solution can achieve it: restore time for full database, restore time for point-in-time recovery, and failover time for geo-replicas. Include RTO validation through DR testing]\n\n**Recovery Point Objective (RPO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: RPO documented and validated with backup frequency (e.g., RPO: 15 minutes). If Non-Compliant: RPO not specified or backup frequency insufficient for RPO. If Not Applicable: No RPO requirement. If Unknown: RPO mentioned but not validated against backup frequency]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document RPO target in Section 11 and validate backup frequency achieves it: transaction log backup frequency, continuous backup capabilities, and maximum acceptable data loss. Include RPO validation through recovery testing]\n\n**Backup Testing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Backup restoration testing documented with frequency and procedures (e.g., monthly restore tests, quarterly DR drills). If Non-Compliant: Backup testing not documented or not performed regularly. If Not Applicable: N/A. If Unknown: Testing mentioned but procedures unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Disaster Recovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document backup testing procedures in Section 11: restore test frequency (monthly recommended), test environment, validation criteria, and test result documentation. Include DR drill schedule (quarterly/annual) and lessons learned process]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI05]\n\n---\n\n## 6. Infrastructure Capacity (LAPI06)\n\n**Requirement**: Ensure infrastructure resource capacity matches component requirements. Infrastructure must provide sufficient compute, memory, network, and storage resources for current and projected workloads with appropriate headroom.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Infrastructure Architect / Capacity Planner or N/A]\n\n### 6.1 Compute Capacity\n\n**Compute Resources (CPU/Memory)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Compute capacity documented with CPU cores, memory, and current utilization (e.g., 16 vCPUs, 64 GB RAM, 60% average utilization). If Non-Compliant: Compute capacity not specified or insufficient for documented workload. If Not Applicable: Serverless (auto-scaling compute). If Unknown: Infrastructure mentioned but compute capacity unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document compute capacity in Section 8 or 10: vCPU count, memory (GB), current utilization (average and peak), and capacity headroom. For Kubernetes: document node pool sizes, pod resource requests/limits. Include compute SKU/VM size]\n\n**Current vs Peak Utilization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Current and peak utilization documented with capacity headroom analysis (e.g., average 60%, peak 85%, 15% headroom). If Non-Compliant: Utilization not documented or consistently exceeding 90% (insufficient headroom). If Not Applicable: N/A. If Unknown: Utilization mentioned but metrics unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document capacity utilization in Section 10: average utilization, peak utilization, capacity headroom (recommended 20-30% headroom for burst capacity), and monitoring thresholds. Include historical utilization trends and projected growth]\n\n### 6.2 Scaling Configuration\n\n**Horizontal Scaling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Horizontal scaling configuration documented (auto-scaling rules, min/max instances, scaling metrics). If Non-Compliant: Horizontal scaling not configured or limits insufficient. If Not Applicable: Fixed capacity (no horizontal scaling). If Unknown: Scaling mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Horizontal Scaling) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document horizontal scaling in Section 10: auto-scaling configuration (CPU/memory thresholds), minimum and maximum instance counts, scaling cooldown periods, and scaling metrics. For Kubernetes: HPA configuration. For cloud VMs: VMSS/ASG configuration]\n\n**Vertical Scaling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Vertical scaling capabilities documented (VM/node size upgrade path, downtime requirements). If Non-Compliant: Vertical scaling not documented or not possible. If Not Applicable: N/A. If Unknown: Scaling mentioned but vertical capabilities unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Vertical Scaling) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document vertical scaling in Section 10: available SKU/size tiers, upgrade/downgrade procedures, downtime impact, and maximum vertical scale limits. Include when to use vertical vs horizontal scaling]\n\n### 6.3 Capacity Headroom\n\n**Capacity Headroom Analysis**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Capacity headroom documented and meets recommended thresholds (20-30% headroom for production). If Non-Compliant: Insufficient headroom (< 10%) or headroom not analyzed. If Not Applicable: N/A. If Unknown: Capacity mentioned but headroom unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document capacity headroom in Section 10: calculate headroom as (Total Capacity - Peak Usage) / Total Capacity. Maintain 20-30% headroom for production to handle burst traffic and scaling delays. Include capacity planning horizon (6-12 months) and growth projections]\n\n**Network Capacity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Network capacity documented (bandwidth, latency, throughput requirements). If Non-Compliant: Network capacity not specified or insufficient for workload. If Not Applicable: N/A. If Unknown: Network mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 10 (Performance Targets) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document network capacity in Section 8 or 10: network bandwidth (Gbps), expected throughput (Mbps), latency requirements, and network SKU/tier. For cloud: document ExpressRoute/VPN capacity. Include inter-service communication bandwidth requirements]\n\n**Storage Capacity** (Infrastructure Storage): [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Infrastructure storage capacity documented (ephemeral storage, persistent volumes, current usage). If Non-Compliant: Storage capacity not specified or insufficient. If Not Applicable: Stateless infrastructure (no storage). If Unknown: Storage mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 10 (Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document infrastructure storage capacity in Section 8 or 10: persistent volume sizes, ephemeral storage per node, storage class/tier, and IOPS requirements. For Kubernetes: document PV/PVC capacity. Separate from database storage (covered in LAPI03)]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI06]\n\n---\n\n## 7. Naming Conventions (LAPI07)\n\n**Requirement**: Ensure On-Premise infrastructure architecture adheres to naming standards. All infrastructure resources must follow organizational naming conventions for consistency, traceability, and operational efficiency.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Infrastructure Architect / Standards Officer or N/A]\n\n### 7.1 Infrastructure Naming Standards\n\n**Naming Convention Documentation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Infrastructure naming conventions documented with pattern, examples, and organizational standard reference. If Non-Compliant: Naming conventions not documented or not following organizational standards. If Not Applicable: N/A. If Unknown: Naming mentioned but conventions unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document naming conventions in Section 8 or 11: naming pattern (e.g., {environment}-{application}-{resource-type}-{region}), examples (prod-taskscheduler-aks-eastus), and reference to organizational naming standard. Include naming for: clusters, nodes, VMs, databases, storage accounts, networks, subnets, security groups]\n\n**Resource Naming Examples**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Concrete naming examples provided for key infrastructure resources. If Non-Compliant: No naming examples or examples don't follow documented pattern. If Not Applicable: N/A. If Unknown: Resources mentioned but naming examples unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 4 (Meta Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document resource naming examples in Section 8: Kubernetes cluster name, node pool names, database server names, storage account names, VNet/subnet names. Ensure examples follow organizational naming standard and include environment prefix (dev/staging/prod)]\n\n### 7.2 Compliance with Organizational Standards\n\n**Standards Compliance Verification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Infrastructure naming verified against organizational standards with standard version documented. If Non-Compliant: Naming does not comply with organizational standards or verification not performed. If Not Applicable: No organizational naming standard. If Unknown: Standards mentioned but compliance verification unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) compared against organizational naming standard or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify infrastructure naming against organizational naming standard (reference standard name and version). Document compliance status, any approved exceptions, and remediation plan for non-compliant names. Include tag/label naming conventions (cost center, owner, environment, project)]\n\n**Tagging and Labeling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Resource tagging/labeling strategy documented with required tags and values. If Non-Compliant: Tagging strategy not documented or required tags missing. If Not Applicable: N/A. If Unknown: Tags mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Infrastructure) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document tagging/labeling strategy in Section 8 or 11: required tags (Environment, Owner, CostCenter, Project, Application), tag format, and tag governance policy. For Kubernetes: document pod labels and namespace labels. For cloud: document Azure tags / AWS tags requirements]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI07]\n\n---\n\n## 8. Transaction Volume Dimensioning (LAPI08)\n\n**Requirement**: Ensure On-Premise integration components are designed with production transaction volumes and sizes. Integration infrastructure must be dimensioned to handle documented transaction rates (TPS) and message sizes for current and projected workloads.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / Performance Engineer or N/A]\n\n### 8.1 Transaction Volume Configuration\n\n**Target Transaction Rate (TPS)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Target transaction rate documented with sustained and peak TPS (e.g., 180 TPS sustained, 300 TPS peak). If Non-Compliant: Transaction rate not specified or integration components not dimensioned for documented TPS. If Not Applicable: No integration components or non-transactional architecture. If Unknown: Transaction rate mentioned but values unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Performance Targets ‚Üí Throughput) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document transaction rate targets in Section 10: sustained TPS (average load), peak TPS (expected burst), and system limit TPS (maximum capacity). Include separate TPS for different transaction types (create, read, update, delete) and integration patterns (sync/async)]\n\n**System Capacity Limits**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: System capacity limits documented with maximum TPS and capacity headroom. If Non-Compliant: Capacity limits not documented or insufficient headroom. If Not Applicable: N/A. If Unknown: Limits mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Capacity Planning) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document system capacity limits in Section 10: maximum TPS capacity, capacity headroom calculation (e.g., peak 300 TPS with 1000 TPS limit = 70% headroom), and scaling trigger thresholds. Include load testing results validating capacity limits]\n\n### 8.2 Transaction Size Requirements\n\n**Message/Payload Sizes**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Transaction payload sizes documented with average and maximum message sizes. If Non-Compliant: Payload sizes not specified or integration not dimensioned for documented sizes. If Not Applicable: N/A. If Unknown: Message sizes mentioned but values unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Performance Targets) or Section 7 (Integration Points) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document message/payload sizes in Section 7 or 10: average message size (KB), maximum message size (MB), and size distribution (e.g., 90% < 10 KB, 10% < 1 MB). Include message size limits and handling strategy for oversized messages]\n\n**Throughput Requirements (MB/s)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data throughput calculated from TPS and message sizes (e.g., 180 TPS √ó 5 KB = 900 KB/s). If Non-Compliant: Throughput not calculated or infrastructure bandwidth insufficient. If Not Applicable: N/A. If Unknown: Throughput mentioned but calculation unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Performance Targets) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document throughput requirements in Section 10: calculate throughput as TPS √ó average message size, include peak throughput, and verify network/infrastructure bandwidth supports throughput. Include compression/batching strategies if applicable]\n\n### 8.3 Integration Component Capacity\n\n**Integration Middleware Capacity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Integration middleware (message queue, API gateway, ESB) capacity documented and matched to TPS requirements. If Non-Compliant: Middleware capacity not specified or insufficient for documented TPS. If Not Applicable: No middleware (direct integration). If Unknown: Middleware mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points) or Section 8 (Technology Stack ‚Üí Integration) or Section 10 (Performance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document integration middleware capacity in Section 7 or 8: message queue capacity (messages/sec, queue depth), API gateway rate limits (requests/sec), connection pool sizes. Verify middleware capacity supports documented TPS with headroom. Include middleware SKU/tier and scaling configuration]\n\n**Connection and Concurrency Limits**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Connection limits and concurrency configuration documented (connection pool size, max concurrent requests). If Non-Compliant: Connection limits not specified or insufficient for TPS requirements. If Not Applicable: N/A. If Unknown: Connections mentioned but limits unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Integration) or Section 10 (Performance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document connection and concurrency limits in Section 8 or 10: database connection pool size, HTTP client connection limits, max concurrent requests/threads, and timeout configurations. Calculate required concurrency as: TPS √ó average response time (e.g., 180 TPS √ó 100ms = 18 concurrent requests minimum)]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI08]\n\n---\n\n## 9. Legacy Platform Transaction Capacity (LAPI09)\n\n**Requirement**: Ensure listening port capacity for legacy components matches estimated transaction numbers. Legacy system integration points must be properly dimensioned with adequate port configuration, connection limits, and transaction capacity.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Architect / Legacy Systems Specialist or N/A]\n\n### 9.1 Listening Port Configuration\n\n**Port Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Listening ports documented for legacy system interfaces (port numbers, protocols, purpose). If Non-Compliant: Port configuration not documented or ports not properly configured. If Not Applicable: No legacy system integration. If Unknown: Ports mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points ‚Üí External Systems) or Section 9 (Security Architecture ‚Üí Network Security) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document listening port configuration in Section 7: port numbers, protocols (TCP/UDP/HTTP/HTTPS), firewall rules, and port purpose (e.g., port 8080 for legacy SOAP API, port 1433 for legacy SQL Server). Include network security group (NSG) or firewall configuration allowing traffic to/from legacy systems]\n\n**Protocol and Interface Type**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Integration protocol and interface type documented (REST, SOAP, TCP, MQ, FTP). If Non-Compliant: Protocol not specified or interface unclear. If Not Applicable: No legacy integration. If Unknown: Integration mentioned but protocol unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points ‚Üí External Systems) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document integration protocol in Section 7: protocol type (REST API, SOAP web service, TCP socket, message queue, file transfer), interface specification (WSDL, OpenAPI, custom protocol), and legacy system endpoint details]\n\n### 9.2 Connection Limits\n\n**Maximum Concurrent Connections**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Connection limits documented for legacy system ports (max concurrent connections, connection pooling). If Non-Compliant: Connection limits not specified or insufficient for transaction volume. If Not Applicable: No connection-based legacy integration. If Unknown: Connections mentioned but limits unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points ‚Üí External Systems) or Section 10 (Performance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document connection limits in Section 7 or 10: maximum concurrent connections supported by legacy system, connection pool configuration (min/max pool size), connection timeout settings, and connection retry logic. Verify connection limits support estimated transaction rate]\n\n**Connection Pool Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Connection pool configuration documented (pool size, timeout, keep-alive) for legacy system connections. If Non-Compliant: Connection pooling not configured or pool size insufficient. If Not Applicable: Connectionless protocol. If Unknown: Pool mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Integration) or Section 10 (Performance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document connection pool configuration in Section 8 or 10: minimum and maximum pool size, connection timeout (seconds), idle timeout, connection validation, and keep-alive settings. Size connection pool to support peak TPS: pool size >= (peak TPS √ó average response time in seconds)]\n\n### 9.3 Transaction Capacity per Port\n\n**Estimated Transaction Volume**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Transaction volume per legacy port documented and validated (estimated TPS, peak load). If Non-Compliant: Transaction volume not documented or port capacity insufficient. If Not Applicable: No legacy transaction processing. If Unknown: Volume mentioned but estimates unclear]\n- Source: [ARCHITECTURE.md Section 10 (Scalability & Performance ‚Üí Performance Targets) or Section 7 (Integration Points) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document transaction volume per legacy integration port in Section 7 or 10: estimated sustained TPS, peak TPS, transaction volume distribution (by time of day), and legacy system capacity limits. Include load testing results validating legacy system can handle estimated volume]\n\n**Legacy System Capacity Validation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Legacy system capacity validated through testing or documented capacity limits (TPS, response time, SLA). If Non-Compliant: Legacy capacity not validated or unknown if legacy can support load. If Not Applicable: No legacy system dependency. If Unknown: Legacy system mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration Points ‚Üí External Systems) or Section 10 (Performance) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document legacy system capacity validation in Section 7 or 10: legacy system's documented TPS capacity, measured response times, SLA commitments, and load testing results. Verify architecture's transaction rate does not exceed legacy system's capacity. Include backpressure/throttling mechanisms to protect legacy systems from overload]\n\n**Failover and Redundancy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Failover configuration documented for legacy integrations (redundant ports, load balancing, circuit breakers). If Non-Compliant: No failover mechanism or single point of failure. If Not Applicable: Legacy system has no failover requirement. If Unknown: Failover mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí High Availability) or Section 7 (Integration Points) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document failover configuration in Section 7 or 11: redundant legacy system endpoints, load balancing configuration, circuit breaker pattern implementation, and retry logic with exponential backoff. Include monitoring for legacy system availability and automatic failover triggers]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAPI09]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Platform and IT Infrastructure Terms**:\n- **HA (High Availability)**: System design ensuring minimal downtime through redundancy and failover\n- **Capacity Planning**: Process of determining infrastructure resources needed to meet performance requirements\n- **Environment Isolation**: Separation of development, testing, staging, and production environments\n- **Database Capacity**: Storage sizing based on data volume, growth projections, and retention policies\n- **Horizontal Scaling**: Adding more server instances to distribute load\n- **Vertical Scaling**: Increasing resources (CPU, memory) of existing servers\n- **Transaction Volume**: Number of operations (requests, database transactions) the system processes\n- **Dimensioning**: Sizing infrastructure based on expected workload and performance targets\n- **Naming Conventions**: Standardized naming patterns for infrastructure resources\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Infrastructure Abbreviations**:\n- **LAPI**: Platform and IT Infrastructure compliance requirement code\n- **IOPS**: Input/Output Operations Per Second\n- **VM**: Virtual Machine\n- **vCPU**: Virtual CPU\n- **RPO/RTO**: Recovery Point/Time Objective\n\n---\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=platform-it-infrastructure -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Platform & IT Infrastructure Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Environment isolation undefined | LAPI1 Non-Compliant | Section 11 (Operational ‚Üí Deployment) | Document dev, test, staging, production environments with access controls |\n| Server OS not specified | LAPI2 Non-Compliant | Section 8 (Technology Stack ‚Üí Infrastructure) | Specify OS versions, patching strategy, containerization approach |\n| Database capacity not calculated | LAPI3 Non-Compliant | Section 10 (Performance ‚Üí Capacity Planning) | Calculate storage requirements based on data volume and retention |\n| Infrastructure capacity undefined | LAPI4 Unknown | Section 10 (Performance ‚Üí Capacity Planning) | Document server sizing (vCPUs, memory, storage) and scaling strategy |\n| Backup and retention missing | LAPI5 Unknown | Section 11 (Operational ‚Üí Backup & DR) | Define backup frequency, retention periods, recovery procedures |\n| Naming conventions not defined | LAPI6 Unknown | Section 8 (Technology Stack ‚Üí Infrastructure) | Define naming standards for servers, databases, networks, resources |\n| Transaction volume not specified | LAPI7 Unknown | Section 10 (Performance ‚Üí Throughput) | Specify expected transaction rates and capacity dimensioning |\n| Network architecture undefined | LAPI8 Unknown | Section 4 or 8 (Cloud/Infrastructure) | Document network topology, subnets, firewalls, load balancers |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Platform & IT Infrastructure-Specific Examples**:\n\n**Example 1: Environment Isolation and Access Controls**\n- **Gap**: Environment isolation not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add environment isolation to Section 11:\n   Environments: dev, test, staging, production (separate VPCs),\n   Access controls: dev (all engineers), staging (senior only), prod (SRE only),\n   Network isolation: VPC peering with security groups,\n   Promotion process: dev ‚Üí test ‚Üí staging ‚Üí prod with approvals,\n   Data isolation: anonymized data in non-prod environments\"\n  ```\n- **Expected Outcome**: Section 11 with environment strategy, access controls, isolation\n- **Impact**: LAPI1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: Server OS and Patching Strategy**\n- **Gap**: Server OS specifications missing\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add server OS specifications to Section 8:\n   OS: Ubuntu 22.04 LTS for application servers,\n   Container runtime: Docker 24.x on Kubernetes 1.28,\n   Patching: monthly security patches, quarterly OS upgrades,\n   Patch testing: automated in dev/test, manual approval for prod,\n   Base images: hardened golden images with CIS benchmarks\"\n  ```\n- **Expected Outcome**: Section 8 with OS versions, patching strategy, hardening\n- **Impact**: LAPI2 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Database and Infrastructure Capacity Planning**\n- **Gap**: Database capacity not calculated\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add capacity planning to Section 10:\n   Database: PostgreSQL with 500GB initial, 20% annual growth,\n   Storage: 1TB SSD (IOPS 10000), 5 years retention = 1.2TB total,\n   Compute: 16 vCPUs, 64GB RAM for app servers (3 instances),\n   Network: 10 Gbps bandwidth, 1000 concurrent connections,\n   Scaling: horizontal auto-scaling at 70% CPU threshold\"\n  ```\n- **Expected Outcome**: Section 10 with capacity calculations, growth projections, scaling\n- **Impact**: LAPI3 + LAPI4 ‚Üí Compliant (+0.5 points)\n\n**Example 4: Backup, Retention, and DR**\n- **Gap**: Backup and retention strategy missing\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add backup strategy to Section 11:\n   Frequency: incremental every 6 hours, full daily at 2 AM,\n   Retention: 30 days hot storage, 7 years cold storage,\n   Storage location: S3 with cross-region replication,\n   Recovery: automated restore scripts, RTO 4 hours, RPO 6 hours,\n   Testing: monthly restore drills, quarterly full DR test\"\n  ```\n- **Expected Outcome**: Section 11 with backup frequency, retention, recovery procedures\n- **Impact**: LAPI5 ‚Üí Compliant (+0.4 points)\n\n**Example 5: Naming Conventions and Standards**\n- **Gap**: Naming conventions not defined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add naming conventions to Section 8:\n   Servers: <env>-<app>-<component>-<instance> (prod-api-web-01),\n   Databases: <env>-<app>-db-<type> (prod-payments-db-primary),\n   Networks: <env>-<vpc/subnet>-<az> (prod-vpc-private-us-east-1a),\n   Resources: <env>-<service>-<resource> (prod-s3-backups),\n   Tags: environment, application, owner, cost-center (mandatory)\"\n  ```\n- **Expected Outcome**: Section 8 with naming standards, tagging conventions\n- **Impact**: LAPI6 ‚Üí Compliant (+0.3 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required infrastructure fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all infrastructure decisions\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Infrastructure and Capacity Planning** (estimated impact: +0.6 points)\n   - Document environment isolation: dev, test, staging, prod with access controls (Section 11)\n   - Specify server OS: versions, patching strategy, hardening (Section 8)\n   - Calculate database capacity: storage, IOPS, growth projections (Section 10)\n   - Define infrastructure capacity: vCPUs, memory, storage, scaling strategy (Section 10)\n   - Add transaction volume estimates and dimensioning (Section 10)\n\n2. **Establish Backup, DR, and Network Architecture** (estimated impact: +0.3 points)\n   - Document backup strategy: frequency, retention, storage location, recovery (Section 11)\n   - Add network architecture: VPCs, subnets, firewalls, load balancers (Section 4 or 8)\n   - Define RTO/RPO objectives aligned with backup strategy (Section 10)\n   - Specify disaster recovery procedures and testing schedule (Section 11)\n   - Add monitoring and alerting for infrastructure health (Section 11)\n\n3. **Improve Standards and Governance** (estimated impact: +0.2 points)\n   - Define naming conventions for all infrastructure resources (Section 8)\n   - Add tagging strategy: mandatory tags (environment, application, owner, cost-center) in Section 8\n   - Document infrastructure as code: Terraform, CloudFormation, GitOps (Section 11)\n   - Specify change management process for infrastructure changes (Section 11)\n   - Add cost optimization strategy: rightsizing, reserved instances, spot instances (Section 11)\n\n**Priority Order**: LAPI1 (environments) ‚Üí LAPI2 (server OS) ‚Üí LAPI3 (database capacity) ‚Üí LAPI4 (infrastructure capacity) ‚Üí LAPI5 (backup/retention) ‚Üí LAPI6 (naming conventions) ‚Üí LAPI7 (transaction volume) ‚Üí LAPI8 (network architecture)\n\n**Estimated Final Score After Remediation**: 8.2-8.7/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Added Data Extracted Successfully section\n- Added Missing Data Requiring Attention table\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with Cloud Architecture template structure\n- Total: 25 validation data points across 9 LAPI requirements\n- Preserved source mapping for LAPI01-LAPI09\n\n**Version 1.0 (Previous)**:\n- Basic source traceability section mapping LAPI01-LAPI09\n- Generation metadata focus\n- Limited structure\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=platform-it-infrastructure -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=platform-it-infrastructure -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=platform-it-infrastructure -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=platform-it-infrastructure -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=platform-it-infrastructure -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.",
        "skills/architecture-compliance/templates/TEMPLATE_PROCESS_TRANSFORMATION.md": "# Compliance Contract: Process Transformation and Automation\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 3, 5, 6, 7, 8, 10, 11, 12)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=process-transformation -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=process-transformation -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAA1 | Feasibility and Impact Analysis | Process Transformation | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Process Architect or N/A] |\n| LAA2 | Automation Factors | Process Transformation | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Automation Lead / DevOps Engineer or N/A] |\n| LAA3 | Efficient License Usage | Process Transformation | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [License Manager / Solution Architect or N/A] |\n| LAA4 | Document Management Alignment | Process Transformation | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Information Architect / DMS Administrator or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. Feasibility and Impact Analysis (LAA1)\n\n**Requirement**: Provide comprehensive feasibility and impact analysis for process automation, covering current manual effort, integration requirements, user experience impact, and data type assessment.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Process Architect or N/A]\n\n### 1.1 Manuality Assessment\n\n**Current Manual Effort (FTE Hours/Week)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Manual effort quantified in FTE hours per week. If Non-Compliant: Manual effort not quantified. If Not Applicable: No manual process exists (net-new automation). If Unknown: Process mentioned but effort not quantified]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí Business Problem or Goals) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Quantify current manual effort (e.g., 10 FTE hours/week) in Section 3 to establish automation baseline]\n\n**Process Complexity Assessment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Process complexity categorized (simple/moderate/complex). If Non-Compliant: Complexity not assessed. If Not Applicable: N/A. If Unknown: Process described but complexity unclear]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí Use Cases or Workflows) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify process complexity based on decision points, exceptions, and integration touchpoints in Section 3]\n\n**Automation ROI Justification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: ROI calculated with time savings and cost reduction. If Non-Compliant: ROI not documented. If Not Applicable: Regulatory requirement (no ROI needed). If Unknown: Benefits mentioned but not quantified]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí Success Metrics) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Calculate projected time savings (hours/week) and cost reduction (%) in Section 3 or 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA1.1]\n\n### 1.2 Integration Analysis\n\n**Existing System Integration Points**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Integration points documented with system names and protocols. If Non-Compliant: Integration requirements not specified. If Not Applicable: Standalone automation with no integrations. If Unknown: Integrations mentioned but systems not identified]\n- Source: [ARCHITECTURE.md Section 5 (Component Model) or Section 7 (Integration View) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document all integrated systems (CRM, ERP, databases, APIs) in Section 5 or 7]\n\n**Data Flow Documentation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data flows mapped between systems. If Non-Compliant: Data movement not documented. If Not Applicable: No cross-system data transfer. If Unknown: Data mentioned but flows unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model) or Section 7 (Integration View) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Map data flows showing source ‚Üí transformation ‚Üí destination in Section 6 or 7]\n\n**API Dependencies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API dependencies documented with endpoints and authentication. If Non-Compliant: API requirements not specified. If Not Applicable: No API integrations required. If Unknown: APIs mentioned but specifications unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Integration Catalog) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document required APIs (REST/SOAP/GraphQL), endpoints, and authentication methods in Section 7]\n\n**Integration Error Handling**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Integration error scenarios and retry logic documented. If Non-Compliant: Error handling not defined. If Not Applicable: N/A. If Unknown: Error handling mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Monitoring) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define integration failure scenarios, retry policies, and fallback mechanisms in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA1.2]\n\n### 1.3 User Experience Impact\n\n**Workflow Changes**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: User workflow changes documented. If Non-Compliant: UX impact not assessed. If Not Applicable: No user-facing changes. If Unknown: Automation mentioned but user impact unclear]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí User Stories or Use Cases) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document how automation changes user tasks and responsibilities in Section 3]\n\n**UI/UX Modifications**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Interface changes documented. If Non-Compliant: UI/UX changes not specified. If Not Applicable: Back-end automation only. If Unknown: Interface mentioned but changes unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture ‚Üí Presentation Layer) or Section 5 (Component Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify new forms, dashboards, or UI components required in Section 4 or 5]\n\n**Training Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: User training plan documented. If Non-Compliant: Training needs not addressed. If Not Applicable: Fully automated with no user interaction. If Unknown: Training mentioned but scope unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define training materials, sessions, and user documentation needs in Section 11]\n\n**Change Management**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Change management strategy documented. If Non-Compliant: Adoption strategy not defined. If Not Applicable: N/A. If Unknown: Rollout mentioned but plan unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document phased rollout, stakeholder communication, and adoption metrics in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA1.3]\n\n### 1.4 Data Type Assessment\n\n**Data Source Identification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: All data sources documented. If Non-Compliant: Data sources not identified. If Not Applicable: No data processing required. If Unknown: Data mentioned but sources unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Sources) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: List all data sources (databases, files, APIs, external systems) in Section 6]\n\n**Data Quality Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data quality standards defined. If Non-Compliant: Quality requirements not specified. If Not Applicable: N/A. If Unknown: Quality mentioned but standards unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Quality) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define data completeness, accuracy, and validation rules in Section 6]\n\n**Data Transformation Logic**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data transformations documented. If Non-Compliant: Transformation requirements not specified. If Not Applicable: No data transformation needed. If Unknown: Processing mentioned but logic unclear]\n- Source: [ARCHITECTURE.md Section 5 (Component Model) or Section 6 (Data Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document data mapping, enrichment, and transformation rules in Section 5 or 6]\n\n**Data Sensitivity Classification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data classified by sensitivity (public/internal/confidential/restricted). If Non-Compliant: Data classification not performed. If Not Applicable: N/A. If Unknown: Security mentioned but classification unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Classification) or Section 9 (Security Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify data sensitivity and define handling requirements in Section 6 or 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA1.4]\n\n---\n\n## 2. Automation Factors (LAA2)\n\n**Requirement**: Analyze and document critical automation factors including execution timing, run frequency, comprehensive cost analysis, and operational maintenance requirements.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Automation Lead / DevOps Engineer or N/A]\n\n### 2.1 Automation Timing\n\n**Execution Schedule Type**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Timing model documented (real-time, batch, event-driven, scheduled). If Non-Compliant: Execution timing not defined. If Not Applicable: N/A. If Unknown: Automation mentioned but timing unclear]\n- Source: [ARCHITECTURE.md Section 10 (Non-Functional Requirements ‚Üí Performance) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify whether automation runs real-time, on schedule, or triggered by events in Section 10 or 11]\n\n**Time-Critical Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Time sensitivity defined with deadlines. If Non-Compliant: Time constraints not specified. If Not Applicable: No time-critical operations. If Unknown: Timing mentioned but requirements unclear]\n- Source: [ARCHITECTURE.md Section 10 (Non-Functional Requirements ‚Üí Performance ‚Üí Response Time) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define execution deadlines and time windows (e.g., must complete within 30 minutes) in Section 10]\n\n**Business Hours Alignment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Operating hours documented (business hours vs 24/7). If Non-Compliant: Operating schedule not specified. If Not Applicable: N/A. If Unknown: Availability mentioned but hours unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Support Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify automation operating window (e.g., 8am-6pm Mon-Fri, 24/7) in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA2.1]\n\n### 2.2 Periodicity and Frequency\n\n**Run Frequency**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Execution frequency documented (hourly, daily, weekly, on-demand). If Non-Compliant: Frequency not specified. If Not Applicable: N/A. If Unknown: Automation mentioned but frequency unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Job Scheduling) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define how often automation runs (e.g., every 4 hours, nightly at 2am) in Section 11]\n\n**Peak Load Considerations**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Peak load handling documented. If Non-Compliant: Capacity planning not addressed. If Not Applicable: Minimal load variation. If Unknown: Load mentioned but capacity unclear]\n- Source: [ARCHITECTURE.md Section 10 (Non-Functional Requirements ‚Üí Scalability) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document expected transaction volumes and peak load scenarios in Section 10]\n\n**Retry and Backoff Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Retry logic documented with backoff intervals. If Non-Compliant: Retry strategy not defined. If Not Applicable: N/A. If Unknown: Error handling mentioned but retry logic unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Error Handling) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define retry attempts, exponential backoff, and circuit breaker patterns in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA2.2]\n\n### 2.3 Cost Analysis\n\n**License Costs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Software license costs documented. If Non-Compliant: License costs not quantified. If Not Applicable: Open-source solution with no license fees. If Unknown: Licensing mentioned but costs unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Tools and Platforms) or Section 11 (Operational Considerations ‚Üí Cost) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document automation platform licenses (RPA, workflow tools) and third-party integrations in Section 8 or 11]\n\n**Infrastructure Costs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Compute, storage, network costs estimated. If Non-Compliant: Infrastructure costs not calculated. If Not Applicable: N/A. If Unknown: Resources mentioned but costs unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture ‚Üí Infrastructure) or Section 11 (Operational Considerations ‚Üí Cost) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Estimate cloud resources (VMs, storage, bandwidth) and on-premise server costs in Section 4 or 11]\n\n**Maintenance and Support Costs**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Ongoing maintenance costs documented. If Non-Compliant: Support costs not estimated. If Not Applicable: N/A. If Unknown: Support mentioned but costs unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Support Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document FTE effort for monitoring, updates, and incident response in Section 11]\n\n**ROI Timeline**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Payback period calculated. If Non-Compliant: ROI timeline not specified. If Not Applicable: Regulatory mandate (no ROI required). If Unknown: Benefits mentioned but timeline unclear]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí Success Metrics) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Calculate breakeven point comparing automation costs vs manual process savings in Section 3]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA2.3]\n\n### 2.4 Operability and Maintenance\n\n**Monitoring Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Monitoring metrics and dashboards documented. If Non-Compliant: Monitoring requirements not defined. If Not Applicable: N/A. If Unknown: Monitoring mentioned but specifics unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Monitoring) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define automation health metrics (success rate, execution time, errors) in Section 11]\n\n**Error Handling and Alerting**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Error scenarios and alert policies documented. If Non-Compliant: Error handling not specified. If Not Applicable: N/A. If Unknown: Errors mentioned but handling unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Error Handling and Alerting) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document exception handling, notification channels, and escalation procedures in Section 11]\n\n**Support Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Support team and SLAs documented. If Non-Compliant: Support responsibilities not defined. If Not Applicable: N/A. If Unknown: Support mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Support Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define L1/L2/L3 support responsibilities and response time SLAs in Section 11]\n\n**Maintenance Windows**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Maintenance schedule documented. If Non-Compliant: Update procedures not defined. If Not Applicable: N/A. If Unknown: Updates mentioned but schedule unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Deployment) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define maintenance windows for updates, backups, and system changes in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA2.4]\n\n---\n\n## 3. Efficient License Usage (LAA3)\n\n**Requirement**: Ensure efficient license consumption for automation solutions, especially when integrating with third-party technologies requiring additional licensing.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [License Manager / Solution Architect or N/A]\n\n### 3.1 License Optimization Strategy\n\n**License Consumption Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Licensing model documented (concurrent, named user, API calls, CPU-based). If Non-Compliant: License model not specified. If Not Applicable: Open-source solution with no licensing. If Unknown: Licensing mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Tools and Platforms) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document automation platform licensing model (e.g., UiPath attended/unattended robots) in Section 8]\n\n**License Pooling Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: License sharing approach documented. If Non-Compliant: Pooling strategy not defined. If Not Applicable: Single-purpose licenses (no sharing). If Unknown: Resource allocation mentioned but sharing unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define how licenses are shared across automations or departments in Section 8 or 11]\n\n**Estimated License Quantity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Required license count calculated. If Non-Compliant: License quantity not estimated. If Not Applicable: N/A. If Unknown: Licensing mentioned but quantity unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Cost) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Calculate required licenses based on concurrent executions, users, or API calls in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA3.1]\n\n### 3.2 Technology Integration Licensing\n\n**Third-Party Integration Licenses**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Additional licenses for integrated systems documented. If Non-Compliant: Integration licensing not addressed. If Not Applicable: No third-party integrations. If Unknown: Integrations mentioned but licensing unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Integration Catalog) or Section 8 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Identify if integrated systems (Salesforce, SAP, ServiceNow) require API licenses in Section 7 or 8]\n\n**Connector Licensing Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Connector/plugin licenses documented. If Non-Compliant: Connector licensing not specified. If Not Applicable: Standard connectors included. If Unknown: Connectors mentioned but licensing unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View) or Section 8 (Technology Stack) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document premium connectors or adapters requiring separate licenses in Section 7 or 8]\n\n**Database Access Licensing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Database connection licenses documented. If Non-Compliant: Database licensing not addressed. If Not Applicable: No database access. If Unknown: Database mentioned but licensing unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Sources) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Verify if database access requires CALs or connection-based licenses in Section 6]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA3.2]\n\n### 3.3 Cost Efficiency Measures\n\n**License Cost Reduction Tactics**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cost optimization strategies documented. If Non-Compliant: Cost reduction not addressed. If Not Applicable: Fixed licensing with no optimization options. If Unknown: Cost mentioned but tactics unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or Section 11 (Operational Considerations ‚Üí Cost) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document strategies like batch processing, off-peak execution, or license scheduling in Section 11 or 12]\n\n**Organizational Licensing Agreements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Compliance with enterprise agreements verified. If Non-Compliant: Agreement alignment not verified. If Not Applicable: N/A. If Unknown: Enterprise licensing mentioned but compliance unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack) or \"External organizational documentation\"]\n- Note: [If Non-Compliant or Unknown: Verify alignment with existing ELAs (Enterprise License Agreements) in Section 8]\n\n**License Compliance Monitoring**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: License usage tracking documented. If Non-Compliant: Compliance monitoring not defined. If Not Applicable: N/A. If Unknown: Monitoring mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Monitoring) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define license usage tracking and audit procedures in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA3.3]\n\n---\n\n## 4. Document Management Alignment (LAA4)\n\n**Requirement**: Confirm alignment with organizational document management capabilities and licensing, especially when the solution integrates with or includes document lifecycle management features.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Information Architect / DMS Administrator or N/A]\n\n### 4.1 Document Management Capabilities\n\n**Document Lifecycle Scope**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Document lifecycle documented (creation, storage, retrieval, archival, deletion). If Non-Compliant: DMS scope not defined. If Not Applicable: No document management required. If Unknown: Documents mentioned but lifecycle unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Storage) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define which document operations are automated (upload, version, archive) in Section 6]\n\n**Version Control Requirements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Document versioning documented. If Non-Compliant: Version control not addressed. If Not Applicable: No versioning required. If Unknown: Versions mentioned but control unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Management) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify version control approach (major/minor versions, retention policy) in Section 6]\n\n**Archival and Retention Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Retention rules documented. If Non-Compliant: Archival policies not defined. If Not Applicable: N/A. If Unknown: Retention mentioned but policies unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Retention) or Section 11 (Operational Considerations) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define retention periods and archival procedures per document type in Section 6 or 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA4.1]\n\n### 4.2 Licensing Alignment\n\n**Document Management System Licensing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: DMS licenses documented. If Non-Compliant: DMS licensing not addressed. If Not Applicable: No DMS integration. If Unknown: DMS mentioned but licensing unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack ‚Üí Tools and Platforms) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document SharePoint, Documentum, or other DMS licenses required in Section 8]\n\n**Organizational Agreement Compliance**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Alignment with enterprise DMS agreements verified. If Non-Compliant: Agreement compliance not verified. If Not Applicable: N/A. If Unknown: Organizational DMS mentioned but compliance unclear]\n- Source: [ARCHITECTURE.md Section 8 (Technology Stack) or \"External organizational documentation\"]\n- Note: [If Non-Compliant or Unknown: Verify alignment with existing DMS enterprise agreements in Section 8]\n\n**Storage Licensing**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Storage capacity and licensing documented. If Non-Compliant: Storage licensing not addressed. If Not Applicable: N/A. If Unknown: Storage mentioned but licensing unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Storage) or Section 11 (Operational Considerations ‚Üí Cost) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document estimated storage capacity and associated licensing in Section 6 or 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA4.2]\n\n### 4.3 Integration Verification\n\n**DMS Integration Points**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: DMS integration documented. If Non-Compliant: Integration approach not specified. If Not Applicable: No DMS integration. If Unknown: Integration mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Integration Catalog) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document DMS APIs, connectors, or file system integration in Section 7]\n\n**Authentication and Access Controls**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: DMS authentication documented. If Non-Compliant: Access controls not defined. If Not Applicable: N/A. If Unknown: Security mentioned but controls unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define DMS authentication method (OAuth, SAML, service accounts) in Section 9]\n\n**Document Security Classification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Document sensitivity levels documented. If Non-Compliant: Security classification not performed. If Not Applicable: N/A. If Unknown: Security mentioned but classification unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Classification) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify documents by sensitivity and define access restrictions in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAA4.3]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Process Automation Terms**:\n- **Manuality**: Current manual effort measured in FTE hours per week\n- **Integration Points**: Systems that exchange data with the automation\n- **ROI (Return on Investment)**: Financial benefit calculation (savings minus costs)\n- **Execution Schedule**: Timing model (real-time, batch, event-driven, scheduled)\n- **License Pooling**: Sharing licenses across multiple automations or users\n- **Document Management System (DMS)**: Platform for document lifecycle management\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Compliance Abbreviations**:\n- **LAA**: Process Automation compliance requirement code\n- **FTE**: Full-Time Equivalent (labor measurement)\n- **RTO/RPO**: Recovery Time/Point Objective (disaster recovery metrics)\n- **SLA**: Service Level Agreement\n\n---\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=process-transformation -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Process Transformation & Automation Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| Manual effort not quantified | LAA1 Non-Compliant | Section 1 (Business Context) | Document FTE hours/week spent on manual process, ROI calculation |\n| Integration points undefined | LAA2 Non-Compliant | Section 7 (Integration View) | List all integrated systems, APIs, file transfers |\n| Data sources not documented | LAA3 Non-Compliant | Section 6 (Data Model) | Specify source systems, databases, file formats, data volumes |\n| Execution frequency missing | LAA4 Unknown | Section 11 (Operational Considerations) | Define how often automation runs (hourly, daily, event-driven) |\n| Monitoring metrics undefined | LAA5 Unknown | Section 11 (Operational Considerations) | Add success rate, execution time, error tracking, SLA monitoring |\n| License costs not specified | LAA6 Unknown | Section 8 or 11 (Technology/Operations) | Document automation platform and integration license costs |\n| Error handling not defined | LAA7 Unknown | Section 11 (Operational Considerations) | Specify retry logic, dead letter queue, alerting, manual intervention |\n| Rollback procedures missing | LAA8 Unknown | Section 11 (Operational Considerations) | Define rollback strategy for failed automation runs |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Process Transformation & Automation-Specific Examples**:\n\n**Example 1: Manual Effort Quantification and ROI**\n- **Gap**: Manual effort not quantified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add manual effort quantification to Section 1:\n   Current state: 3 FTE spending 40 hours/week on manual data entry,\n   Annual cost: 3 FTE √ó 40 hrs/week √ó 52 weeks √ó $50/hr = $312,000,\n   Automation savings: reduce to 0.5 FTE (monitoring only),\n   Annual savings: $260,000 (83% reduction),\n   ROI: $260k savings / $80k implementation = 325% ROI, 3.7-month payback\"\n  ```\n- **Expected Outcome**: Section 1 with FTE quantification, cost analysis, ROI calculation\n- **Impact**: LAA1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: Integration Points and Systems**\n- **Gap**: Integration points not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add integration points to Section 7:\n   Source: Salesforce CRM (REST API, OAuth 2.0, 1000 records/day),\n   Target: NetSuite ERP (SOAP API, API key, batch updates),\n   Orchestration: Apache Airflow for workflow coordination,\n   Data transformation: Python scripts with pandas,\n   File transfer: SFTP from legacy mainframe (CSV files, 50MB/day)\"\n  ```\n- **Expected Outcome**: Section 7 with integration catalog, protocols, auth methods, volumes\n- **Impact**: LAA2 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Data Sources and Transformation**\n- **Gap**: Data sources not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add data sources to Section 6:\n   Source 1: Oracle HR database (employee records, 5000 rows),\n   Source 2: CSV files from payroll system (weekly, 200KB),\n   Source 3: SharePoint lists (project data, REST API),\n   Transformation: deduplication, validation, enrichment,\n   Target schema: normalized relational model in PostgreSQL,\n   Data quality: 95% accuracy SLA, automated validation rules\"\n  ```\n- **Expected Outcome**: Section 6 with source systems, formats, transformation logic, quality SLA\n- **Impact**: LAA3 ‚Üí Compliant (+0.5 points)\n\n**Example 4: Execution Frequency and Scheduling**\n- **Gap**: Execution frequency not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add execution frequency to Section 11:\n   Schedule: daily at 2 AM EST (cron: 0 2 * * *),\n   Trigger: event-driven on new file arrival to S3 bucket,\n   Parallelization: 5 concurrent workers for batch processing,\n   Timeout: 2-hour execution limit with alerting,\n   Dependencies: wait for upstream ETL completion before starting\"\n  ```\n- **Expected Outcome**: Section 11 with schedule, triggers, parallelization, dependencies\n- **Impact**: LAA4 ‚Üí Compliant (+0.4 points)\n\n**Example 5: Monitoring, Error Handling, and Alerting**\n- **Gap**: Monitoring metrics and error handling undefined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add monitoring and error handling to Section 11:\n   Success metrics: 99% success rate SLA, p95 execution time < 30 min,\n   Error tracking: Sentry for application errors, CloudWatch for infra,\n   Retry logic: 3 retries with exponential backoff (5s, 25s, 125s),\n   Dead letter queue: failed records to DLQ for manual review,\n   Alerting: PagerDuty for critical errors, Slack for warnings,\n   Dashboard: Grafana with execution history, success rate, error trends\"\n  ```\n- **Expected Outcome**: Section 11 with monitoring SLAs, error handling, alerting, dashboards\n- **Impact**: LAA5 + LAA7 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required automation fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all automation decisions\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Business Case and Integration** (estimated impact: +0.6 points)\n   - Quantify manual effort: FTE hours/week, annual cost, ROI calculation (Section 1)\n   - Document integration points: source systems, APIs, protocols, auth methods (Section 7)\n   - Add data sources: systems, formats, volumes, transformation logic (Section 6)\n   - Specify automation platform: UiPath, Automation Anywhere, Python, Airflow (Section 8)\n   - Define license costs: platform, integration connectors, infrastructure (Section 8 or 11)\n\n2. **Establish Operational Procedures** (estimated impact: +0.3 points)\n   - Define execution frequency: schedule, triggers, parallelization, dependencies (Section 11)\n   - Add monitoring metrics: success rate SLA, execution time, error tracking (Section 11)\n   - Document error handling: retry logic, DLQ, manual intervention procedures (Section 11)\n   - Specify rollback procedures: automated rollback triggers, manual rollback steps (Section 11)\n   - Add alerting strategy: critical errors (PagerDuty), warnings (Slack), dashboards (Grafana) in Section 11\n\n3. **Enhance Quality and Governance** (estimated impact: +0.2 points)\n   - Document data quality: validation rules, accuracy SLA, error thresholds (Section 6)\n   - Add testing strategy: unit tests, integration tests, UAT procedures (Section 11)\n   - Define change management: approval gates, deployment windows, rollback criteria (Section 11)\n   - Specify audit logging: process execution logs, data lineage, compliance trail (Section 11)\n   - Add continuous improvement: KPI tracking, optimization opportunities, automation roadmap (Section 1 or 11)\n\n**Priority Order**: LAA1 (manual effort) ‚Üí LAA2 (integration) ‚Üí LAA3 (data sources) ‚Üí LAA4 (execution frequency) ‚Üí LAA5 (monitoring) ‚Üí LAA6 (license costs) ‚Üí LAA7 (error handling) ‚Üí LAA8 (rollback)\n\n**Estimated Final Score After Remediation**: 8.3-8.8/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Replaced 8 simple sections with 4 comprehensive LAA requirements\n- LAA1: Feasibility and Impact Analysis (4 subsections, 14 data points)\n- LAA2: Automation Factors (4 subsections, 13 data points)\n- LAA3: Efficient License Usage (3 subsections, 9 data points)\n- LAA4: Document Management Alignment (3 subsections, 9 data points)\n- Added comprehensive Appendix with 4 sections\n- Total: 45 validation data points across 14 subsections\n- Source mapping expanded to Sections 3, 5, 6, 7, 8, 10, 11, 12\n- Aligned with Cloud Architecture template structure\n\n**Version 1.0 (Previous)**:\n- Initial template with 8 simple sections\n- Basic PLACEHOLDER approach\n- Limited source traceability\n- 8 validation items across 4 sections\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=process-transformation -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=process-transformation -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=process-transformation -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=process-transformation -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=process-transformation -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_SECURITY_ARCHITECTURE.md": "# Compliance Contract: Security Architecture\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 4, 5, 7, 9, 11)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=security-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=security-architecture -->\n\n<!-- @include shared/fragments/compliance-score-calculation.md -->\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAS1 | API Exposure | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Security Architect or N/A] |\n| LAS2 | Intra-Microservices Communication | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Security Architect / Platform Engineer or N/A] |\n| LAS3 | Inter-Cluster Kubernetes Communication | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Kubernetes Administrator / Security Architect or N/A] |\n| LAS4 | Domain API Communication | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [API Architect / Security Architect or N/A] |\n| LAS5 | Third-Party API Consumption | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Integration Engineer / Security Architect or N/A] |\n| LAS6 | Data Lake Communication | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Data Architect / Security Architect or N/A] |\n| LAS7 | Internal Application Authentication | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Identity Architect / Security Architect or N/A] |\n| LAS8 | HTTP Encryption Scheme | Security Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | [Section X or N/A] | [Security Architect or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n---\n\n## 1. API Exposure (LAS1)\n\n**Requirement**: Demonstrate compliance with API exposure guidelines including authentication, authorization, rate limiting, and gateway configuration.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Security Architect / API Architect or N/A]\n\n### 1.1 API Gateway Configuration\n\n**API Gateway Implementation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API Gateway documented with vendor/technology. If Non-Compliant: API Gateway not specified. If Not Applicable: No external API exposure. If Unknown: API Gateway mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section 5 (Component Model ‚Üí API Gateway) or Section 9 (Security Architecture ‚Üí API Security), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document API Gateway technology (Azure API Management, Kong, Apigee, AWS API Gateway) in Section 5 or 9]\n\n**Exposed API Endpoints**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Public API endpoints documented with paths and methods. If Non-Compliant: Exposed endpoints not listed. If Not Applicable: N/A. If Unknown: APIs mentioned but endpoints not specified]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Catalog) or Section 9, lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: List all publicly exposed API endpoints with HTTP methods in Section 7]\n\n**API Versioning Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Versioning approach documented (URI versioning, header versioning, etc.). If Non-Compliant: Versioning strategy not defined. If Not Applicable: N/A. If Unknown: Versioning mentioned but approach unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define API versioning strategy (e.g., /v1/, /v2/ URI path) in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS1.1]\n\n### 1.2 API Authentication\n\n**Authentication Method**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authentication mechanism documented (OAuth 2.0, API keys, JWT, mTLS). If Non-Compliant: Authentication not specified. If Not Applicable: N/A. If Unknown: Authentication mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify API authentication method (OAuth 2.0 Client Credentials recommended) in Section 9]\n\n**Token Management**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Token issuance, validation, and expiration documented. If Non-Compliant: Token management not addressed. If Not Applicable: N/A. If Unknown: Tokens mentioned but lifecycle unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document token expiration (e.g., access token 1 hour, refresh token 30 days) in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS1.2]\n\n### 1.3 API Authorization\n\n**Authorization Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authorization approach documented (RBAC, ABAC, scope-based). If Non-Compliant: Authorization not defined. If Not Applicable: N/A. If Unknown: Authorization mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define authorization model (OAuth 2.0 scopes or RBAC) in Section 9]\n\n**Access Control Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Access policies documented per API endpoint. If Non-Compliant: Access controls not specified. If Not Applicable: N/A. If Unknown: Policies mentioned but not detailed]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document which roles/scopes can access which API endpoints in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS1.3]\n\n### 1.4 Rate Limiting and Throttling\n\n**Rate Limiting Policy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Rate limits documented (requests per minute/hour). If Non-Compliant: Rate limiting not configured. If Not Applicable: Internal-only APIs with no rate limiting requirement. If Unknown: Rate limiting mentioned but limits unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí API Security) or Section 10 (Non-Functional Requirements), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define rate limits per consumer tier (e.g., 1000 req/min for premium, 100 req/min for free) in Section 9]\n\n**Throttling Strategy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Throttling behavior documented (reject, queue, delay). If Non-Compliant: Throttling not addressed. If Not Applicable: N/A. If Unknown: Throttling mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify throttling response (HTTP 429 with Retry-After header) in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS1.4]\n\n---\n\n## 2. Intra-Microservices Communication (LAS2)\n\n**Requirement**: Show compliance with microservices communication guidelines including service mesh, mTLS, and secure service-to-service communication.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Security Architect / Platform Engineer or N/A]\n\n### 2.1 Service Mesh Implementation\n\n**Service Mesh Technology**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service mesh documented (Istio, Linkerd, Consul Connect). If Non-Compliant: Service mesh not implemented. If Not Applicable: Monolithic architecture (no microservices). If Unknown: Service mesh mentioned but technology unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture ‚Üí Microservices) or Section 5 (Component Model), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify service mesh technology for service-to-service security in Section 4 or 5]\n\n**Service Mesh Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Mesh configuration documented (sidecar injection, control plane). If Non-Compliant: Configuration not specified. If Not Applicable: N/A. If Unknown: Configuration mentioned but details unclear]\n- Source: [ARCHITECTURE.md Section 5 (Component Model) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document service mesh control plane and data plane configuration in Section 5]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS2.1]\n\n### 2.2 Mutual TLS (mTLS)\n\n**mTLS Enforcement**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: mTLS enforced for all service-to-service communication. If Non-Compliant: mTLS not enforced or not documented. If Not Applicable: Monolithic architecture. If Unknown: mTLS mentioned but enforcement unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Network Security or Data Security ‚Üí Encryption in Transit), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Mandate mTLS for all intra-microservices communication in Section 9]\n\n**Certificate Management**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Certificate issuance and rotation documented. If Non-Compliant: Certificate management not addressed. If Not Applicable: N/A. If Unknown: Certificates mentioned but management unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Secrets Management), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document certificate authority (CA) and automatic rotation (e.g., cert-manager, SPIFFE) in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS2.2]\n\n### 2.3 Service-to-Service Authorization\n\n**Authorization Policy**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service-to-service authorization documented (service identity, RBAC). If Non-Compliant: Authorization not enforced between services. If Not Applicable: N/A. If Unknown: Authorization mentioned but policy unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define which services can call which services using service mesh authorization policies in Section 9]\n\n**Service Identity**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service identity mechanism documented (SPIFFE, Kubernetes Service Accounts). If Non-Compliant: Service identity not established. If Not Applicable: N/A. If Unknown: Identity mentioned but mechanism unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement service identity using SPIFFE/SPIRE or Kubernetes Service Accounts in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS2.3]\n\n---\n\n## 3. Inter-Cluster Kubernetes Communication (LAS3)\n\n**Requirement**: Demonstrate compliance with inter-cluster communication guidelines including cluster mesh, multi-cluster networking, and cross-cluster security.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Kubernetes Administrator / Security Architect or N/A]\n\n### 3.1 Multi-Cluster Architecture\n\n**Cluster Topology**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Multi-cluster topology documented (number of clusters, purpose per cluster). If Non-Compliant: Cluster architecture not specified. If Not Applicable: Single Kubernetes cluster. If Unknown: Multiple clusters mentioned but topology unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture ‚Üí Deployment Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document cluster topology (e.g., dev cluster, staging cluster, prod cluster) in Section 4]\n\n**Cross-Cluster Networking**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Inter-cluster networking documented (cluster mesh, VPN, gateway). If Non-Compliant: Cross-cluster networking not addressed. If Not Applicable: Single cluster. If Unknown: Networking mentioned but implementation unclear]\n- Source: [ARCHITECTURE.md Section 4 (Meta Architecture) or Section 9 (Security Architecture ‚Üí Network Security), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify cross-cluster networking approach (Istio multi-cluster, Submariner, Cilium Cluster Mesh) in Section 4 or 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS3.1]\n\n### 3.2 Inter-Cluster Security\n\n**Cross-Cluster mTLS**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: mTLS enforced for cross-cluster communication. If Non-Compliant: Cross-cluster encryption not enforced. If Not Applicable: Single cluster. If Unknown: Encryption mentioned but enforcement unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption in Transit), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Mandate mTLS for all cross-cluster service calls in Section 9]\n\n**Cross-Cluster Service Discovery**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Service discovery mechanism documented (federated service registry). If Non-Compliant: Service discovery not configured. If Not Applicable: N/A. If Unknown: Discovery mentioned but mechanism unclear]\n- Source: [ARCHITECTURE.md Section 5 (Component Model ‚Üí Service Discovery) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure federated service discovery for cross-cluster service location in Section 5]\n\n**Network Policies**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Cross-cluster network policies documented. If Non-Compliant: Network isolation not enforced. If Not Applicable: N/A. If Unknown: Policies mentioned but rules unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Network Security), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define Kubernetes NetworkPolicies restricting cross-cluster traffic in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS3.2]\n\n---\n\n## 4. Domain API Communication (LAS4)\n\n**Requirement**: Show compliance with domain API communication guidelines including domain-driven design, bounded contexts, and domain event security.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [API Architect / Security Architect or N/A]\n\n### 4.1 Domain API Design\n\n**Bounded Contexts**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Domain bounded contexts documented with API boundaries. If Non-Compliant: Bounded contexts not defined. If Not Applicable: Non-DDD architecture. If Unknown: Bounded contexts mentioned but boundaries unclear]\n- Source: [ARCHITECTURE.md Section 3 (Business Context ‚Üí Domain Model) or Section 5 (Component Model), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define bounded contexts and their API boundaries per domain-driven design principles in Section 3 or 5]\n\n**Domain API Catalog**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Domain APIs cataloged with ownership and contracts. If Non-Compliant: Domain APIs not documented. If Not Applicable: N/A. If Unknown: APIs mentioned but catalog incomplete]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí API Catalog), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create domain API catalog listing each domain's public APIs in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS4.1]\n\n### 4.2 Domain API Security\n\n**Domain-Level Authentication**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authentication per domain API documented. If Non-Compliant: Domain API authentication not specified. If Not Applicable: N/A. If Unknown: Authentication mentioned but per-domain implementation unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify authentication requirements for each domain API (OAuth 2.0 scopes per domain) in Section 9]\n\n**Domain Authorization Boundaries**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authorization boundaries enforced per bounded context. If Non-Compliant: Cross-domain authorization not controlled. If Not Applicable: N/A. If Unknown: Authorization mentioned but domain boundaries unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define authorization policies preventing unauthorized cross-domain access in Section 9]\n\n**API Contract Versioning**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Domain API contract versioning strategy documented. If Non-Compliant: Versioning not addressed. If Not Applicable: N/A. If Unknown: Versioning mentioned but strategy unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement semantic versioning for domain API contracts in Section 7]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS4.2]\n\n### 4.3 Domain Events Security\n\n**Event Publishing Security**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Domain event publishing security documented (encryption, authentication). If Non-Compliant: Event security not addressed. If Not Applicable: No async event decoupling. If Unknown: Events mentioned but security unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Events/Messaging) or Section 9, lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enforce authentication and encryption for domain event publishing in Section 7 or 9]\n\n**Event Subscription Authorization**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Event subscription authorization documented (which domains can subscribe to which events). If Non-Compliant: Subscription access not controlled. If Not Applicable: N/A. If Unknown: Subscriptions mentioned but authorization unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Define which bounded contexts can subscribe to domain events in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS4.3]\n\n---\n\n## 5. Third-Party API Consumption (LAS5)\n\n**Requirement**: Demonstrate compliance with third-party API consumption guidelines including credential management, API security, and vendor risk assessment.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Integration Engineer / Security Architect or N/A]\n\n### 5.1 Third-Party API Inventory\n\n**External API Catalog**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party APIs documented with vendor, purpose, and endpoints. If Non-Compliant: External APIs not cataloged. If Not Applicable: No third-party integrations. If Unknown: External APIs mentioned but not cataloged]\n- Source: [ARCHITECTURE.md Section 7 (Integration View ‚Üí Integration Catalog), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Create inventory of all consumed third-party APIs (Stripe, Twilio, SendGrid, etc.) in Section 7]\n\n**API Dependency Criticality**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party API criticality assessed (critical, high, medium, low). If Non-Compliant: Criticality not evaluated. If Not Applicable: N/A. If Unknown: Dependencies mentioned but criticality unclear]\n- Source: [ARCHITECTURE.md Section 7 (Integration View) or Section 11 (Operational Considerations), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify each third-party API by business impact if unavailable in Section 7 or 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS5.1]\n\n### 5.2 Third-Party API Security\n\n**API Credential Management**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party API keys/credentials stored securely (Key Vault, Secrets Manager). If Non-Compliant: Credentials not secured or stored in code. If Not Applicable: N/A. If Unknown: Credential storage mentioned but method unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Secrets Management), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Store all third-party API credentials in Azure Key Vault / AWS Secrets Manager in Section 9]\n\n**API Key Rotation**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: API key rotation policy documented. If Non-Compliant: Key rotation not configured. If Not Applicable: N/A. If Unknown: Rotation mentioned but policy unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Secrets Management) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement automated API key rotation (e.g., every 90 days) in Section 9]\n\n**TLS/SSL Verification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: TLS certificate verification enforced for third-party API calls. If Non-Compliant: TLS verification disabled or not enforced. If Not Applicable: N/A. If Unknown: TLS mentioned but verification unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption in Transit), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enforce TLS 1.3+ with certificate validation for all third-party API calls in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS5.2]\n\n### 5.3 Vendor Risk Management\n\n**Vendor Security Assessment**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Third-party vendor security posture assessed (SOC 2, ISO 27001). If Non-Compliant: Vendor security not evaluated. If Not Applicable: N/A. If Unknown: Vendor security mentioned but assessment unclear]\n- Source: [ARCHITECTURE.md Section 12 (ADRs) or \"External vendor documentation\"]\n- Note: [If Non-Compliant or Unknown: Document vendor security certifications and compliance in Section 12 or ADR]\n\n**Data Sharing Agreements**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data sharing with third parties documented with DPA/NDA. If Non-Compliant: Data sharing agreements not in place. If Not Applicable: No data shared with third parties. If Unknown: Data sharing mentioned but agreements unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Compliance) or \"External legal documentation\"]\n- Note: [If Non-Compliant or Unknown: Ensure Data Processing Agreements (DPA) exist for third parties handling PII in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS5.3]\n\n---\n\n## 6. Data Lake Communication (LAS6)\n\n**Requirement**: Show compliance with data lake communication guidelines including authentication, encryption, data access policies, and data lineage.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Data Architect / Security Architect or N/A]\n\n### 6.1 Data Lake Access Security\n\n**Authentication Mechanism**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lake authentication documented (Azure AD, IAM roles, Kerberos). If Non-Compliant: Authentication not configured. If Not Applicable: No data lake integration. If Unknown: Authentication mentioned but mechanism unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure data lake authentication using managed identities or service principals in Section 9]\n\n**Authorization Model**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lake authorization documented (RBAC, ACLs, ABAC). If Non-Compliant: Authorization not enforced. If Not Applicable: N/A. If Unknown: Authorization mentioned but model unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement RBAC or ACLs for data lake access control (folder-level permissions) in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS6.1]\n\n### 6.2 Data Lake Encryption\n\n**Encryption in Transit**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: TLS enforced for data lake communication. If Non-Compliant: Encryption in transit not configured. If Not Applicable: N/A. If Unknown: Encryption mentioned but enforcement unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption in Transit), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enforce TLS 1.3+ for all data lake API calls (HTTPS, ADLS REST API) in Section 9]\n\n**Encryption at Rest**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lake encryption at rest documented (service-managed or customer-managed keys). If Non-Compliant: At-rest encryption not configured. If Not Applicable: N/A. If Unknown: Encryption mentioned but key management unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption at Rest), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enable data lake encryption at rest using platform-managed or customer-managed keys in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS6.2]\n\n### 6.3 Data Governance\n\n**Data Classification**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lake content classified by sensitivity (public, internal, confidential, restricted). If Non-Compliant: Data classification not performed. If Not Applicable: N/A. If Unknown: Classification mentioned but levels unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Classification) or Section 9, lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Classify data lake zones/folders by sensitivity level in Section 6 or 9]\n\n**Data Lineage Tracking**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lineage from source to data lake documented. If Non-Compliant: Data lineage not tracked. If Not Applicable: N/A. If Unknown: Lineage mentioned but tracking unclear]\n- Source: [ARCHITECTURE.md Section 6 (Data Model ‚Üí Data Lineage) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement data lineage tracking showing data sources and transformations in Section 6]\n\n**Access Audit Logging**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Data lake access logging enabled for audit trail. If Non-Compliant: Access logging not configured. If Not Applicable: N/A. If Unknown: Logging mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Monitoring ‚Üí Audit Logging), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enable data lake diagnostic logs capturing all read/write operations in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS6.3]\n\n---\n\n## 7. Internal Application Authentication (LAS7)\n\n**Requirement**: Demonstrate compliance with internal application authentication guidelines including SSO, identity providers, MFA, and session management.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Identity Architect / Security Architect or N/A]\n\n### 7.1 Authentication Strategy\n\n**Identity Provider (IdP)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Identity provider documented (Azure AD, Okta, Auth0, Keycloak). If Non-Compliant: IdP not specified. If Not Applicable: Public application with no authentication. If Unknown: IdP mentioned but vendor unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Specify corporate identity provider for user authentication in Section 9]\n\n**Authentication Protocol**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Authentication protocol documented (OAuth 2.0, SAML 2.0, OpenID Connect). If Non-Compliant: Protocol not specified. If Not Applicable: N/A. If Unknown: Protocol mentioned but type unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Use OpenID Connect (OIDC) for user authentication in Section 9]\n\n**Single Sign-On (SSO)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: SSO integration documented with corporate IdP. If Non-Compliant: SSO not implemented. If Not Applicable: Standalone application. If Unknown: SSO mentioned but integration unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Integrate with corporate SSO for seamless user experience in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS7.1]\n\n### 7.2 Multi-Factor Authentication (MFA)\n\n**MFA Requirement**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: MFA enforced for user authentication. If Non-Compliant: MFA not required or not enforced. If Not Applicable: Service-to-service authentication only. If Unknown: MFA mentioned but enforcement unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication & Authorization), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Mandate MFA for all internal application users in Section 9]\n\n**MFA Methods**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: MFA methods documented (SMS, authenticator app, FIDO2, biometric). If Non-Compliant: MFA methods not specified. If Not Applicable: N/A. If Unknown: MFA mentioned but methods unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Support authenticator apps (TOTP) and FIDO2 hardware keys in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS7.2]\n\n### 7.3 Session Management\n\n**Session Configuration**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Session timeout and configuration documented. If Non-Compliant: Session management not configured. If Not Applicable: N/A. If Unknown: Sessions mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure session timeout (e.g., 8 hours idle, 24 hours absolute) in Section 9]\n\n**Token Security**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Access token and refresh token security documented. If Non-Compliant: Token security not addressed. If Not Applicable: N/A. If Unknown: Tokens mentioned but security unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Store tokens securely (HttpOnly cookies or secure storage), define expiration in Section 9]\n\n**Logout Mechanism**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Logout process documented (session invalidation, token revocation). If Non-Compliant: Logout not implemented. If Not Applicable: N/A. If Unknown: Logout mentioned but mechanism unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement proper logout invalidating both access and refresh tokens in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS7.3]\n\n---\n\n## 8. HTTP Encryption Scheme (LAS8)\n\n**Requirement**: Show compliance with HTTP encryption guidelines including TLS version, cipher suites, certificate management, and HSTS.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: [Security Architect / Platform Engineer or N/A]\n\n### 8.1 TLS Configuration\n\n**TLS Version**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: TLS 1.3 or TLS 1.2+ enforced for all HTTPS communication. If Non-Compliant: TLS 1.0/1.1 allowed or TLS not enforced. If Not Applicable: N/A. If Unknown: TLS mentioned but version unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Data Security ‚Üí Encryption in Transit), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enforce TLS 1.3 (preferred) or minimum TLS 1.2 for all HTTP endpoints in Section 9]\n\n**Cipher Suites**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Approved cipher suites documented (AES-GCM, ChaCha20-Poly1305). If Non-Compliant: Weak ciphers allowed (3DES, RC4, MD5). If Not Applicable: N/A. If Unknown: Ciphers mentioned but suites unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure strong cipher suites (ECDHE-RSA-AES256-GCM-SHA384, TLS_AES_256_GCM_SHA384) in Section 9]\n\n**Protocol Downgrade Protection**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: TLS downgrade attacks prevented (disable SSL fallback). If Non-Compliant: Protocol downgrade possible. If Not Applicable: N/A. If Unknown: Protection mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture) or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Disable TLS downgrade and SSL fallback to prevent POODLE attacks in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS8.1]\n\n### 8.2 Certificate Management\n\n**Certificate Authority (CA)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: CA documented (public CA like Let's Encrypt, DigiCert, or internal PKI). If Non-Compliant: CA not specified or self-signed certificates used. If Not Applicable: N/A. If Unknown: Certificates mentioned but CA unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Secrets Management) or Section 11, lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Use public CA certificates (Let's Encrypt, DigiCert) or documented internal PKI in Section 9]\n\n**Certificate Lifecycle**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Certificate issuance, renewal, and revocation documented. If Non-Compliant: Certificate lifecycle not managed. If Not Applicable: N/A. If Unknown: Lifecycle mentioned but process unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture) or Section 11 (Operational Considerations), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement automated certificate renewal (cert-manager, ACME protocol) in Section 9 or 11]\n\n**Certificate Expiration Monitoring**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Certificate expiration monitoring configured with alerts. If Non-Compliant: Monitoring not configured. If Not Applicable: N/A. If Unknown: Monitoring mentioned but alerting unclear]\n- Source: [ARCHITECTURE.md Section 11 (Operational Considerations ‚Üí Monitoring), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure alerts for certificates expiring within 30 days in Section 11]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS8.2]\n\n### 8.3 HTTP Security Headers\n\n**HSTS (HTTP Strict Transport Security)**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: HSTS header enforced (max-age, includeSubDomains, preload). If Non-Compliant: HSTS not configured. If Not Applicable: N/A. If Unknown: HSTS mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Application Security), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Enable HSTS header with max-age=31536000; includeSubDomains; preload in Section 9]\n\n**Additional Security Headers**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Security headers documented (X-Content-Type-Options, X-Frame-Options, CSP). If Non-Compliant: Security headers not configured. If Not Applicable: N/A. If Unknown: Headers mentioned but configuration unclear]\n- Source: [ARCHITECTURE.md Section 9 (Security Architecture), lines X-Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Configure X-Content-Type-Options: nosniff, X-Frame-Options: DENY, Content-Security-Policy in Section 9]\n\n**Source References**: [Consolidated list of all ARCHITECTURE.md sections used for LAS8.3]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**Security Architecture Terms**:\n- **API Exposure**: Publicly accessible API endpoints requiring authentication and authorization\n- **mTLS (Mutual TLS)**: Two-way TLS authentication where both client and server authenticate each other\n- **Service Mesh**: Infrastructure layer handling service-to-service communication, security, and observability\n- **Bounded Context**: DDD concept defining domain boundaries with explicit API contracts\n- **Data Lake**: Centralized repository storing structured and unstructured data at scale\n- **SSO (Single Sign-On)**: Authentication mechanism allowing one set of credentials across multiple applications\n- **HSTS**: HTTP header forcing browsers to use HTTPS connections only\n- **SPIFFE**: Secure Production Identity Framework for Everyone (service identity standard)\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**Security Abbreviations**:\n- **LAS**: Security Architecture compliance requirement code\n- **OAuth**: Open Authorization standard for delegated access\n- **OIDC**: OpenID Connect (authentication layer on OAuth 2.0)\n- **SAML**: Security Assertion Markup Language\n- **JWT**: JSON Web Token\n- **RBAC**: Role-Based Access Control\n- **ABAC**: Attribute-Based Access Control\n- **MFA**: Multi-Factor Authentication\n- **TLS**: Transport Layer Security\n- **CA**: Certificate Authority\n- **PKI**: Public Key Infrastructure\n\n---\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=security-architecture -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common Security Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| API authentication not specified | LAS1 Non-Compliant | Section 9 (Security Architecture) | Document OAuth 2.0, API keys, or mTLS configuration |\n| mTLS configuration missing | LAS2 Non-Compliant | Section 9 (Security Architecture) | Add mutual TLS enforcement for service-to-service communication |\n| TLS version not enforced | LAS1 Non-Compliant | Section 9 (Security Architecture) | Specify TLS 1.3 or minimum TLS 1.2 enforcement |\n| Service mesh not documented | LAS2 Unknown | Section 4 or 5 (Architecture/Components) | Specify Istio, Linkerd, or Consul Connect implementation |\n| Certificate management undefined | LAS8 Unknown | Section 9 or 11 (Security/Operations) | Document CA, renewal automation, expiration monitoring |\n| SSO configuration missing | LAS7 Unknown | Section 9 (Security Architecture) | Add OIDC or SAML integration with corporate IdP |\n| Third-party API catalog incomplete | LAS5 Unknown | Section 7 (Integration View) | List all external APIs with vendors, endpoints, auth methods |\n| Data lake authentication unclear | LAS6 Unknown | Section 9 (Security Architecture) | Document Azure AD, IAM roles, or service principal authentication |\n| Secrets management not specified | LAS1 Unknown | Section 9 (Security Architecture) | Add HashiCorp Vault, AWS Secrets Manager, or Azure Key Vault |\n| Encryption at rest not documented | LAS6 Unknown | Section 9 (Security Architecture) | Specify AES-256, key rotation policy, KMS integration |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**Security Architecture-Specific Examples**:\n\n**Example 1: Adding mTLS Configuration**\n- **Gap**: Missing mTLS for service-to-service communication\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add mTLS enforcement to Section 9 ‚Üí Network Security:\n   Istio service mesh with automatic mTLS,\n   X.509 certificates with 90-day expiry,\n   automatic cert rotation via cert-manager\"\n  ```\n- **Expected Outcome**: Section 9 with mTLS config, service mesh integration, cert management\n- **Impact**: LAS2 ‚Üí Compliant (+0.6 points)\n\n**Example 2: API Authentication**\n- **Gap**: API authentication not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add API authentication to Section 9 ‚Üí API Security:\n   OAuth 2.0 Client Credentials flow for service-to-service,\n   JWT tokens with 1-hour expiry,\n   Azure AD as authorization server\"\n  ```\n- **Expected Outcome**: Section 9 with OAuth 2.0 flow, token config, Azure AD integration\n- **Impact**: LAS1 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Certificate Management**\n- **Gap**: Missing certificate lifecycle documentation\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add certificate management to Section 9 ‚Üí Secrets Management:\n   cert-manager with Let's Encrypt for public certs,\n   internal CA for service certs,\n   30-day expiry alerts to ops team,\n   automated renewal process\"\n  ```\n- **Expected Outcome**: Section 9 with cert lifecycle, alerting, automation\n- **Impact**: LAS8 ‚Üí Compliant (+0.3 points)\n\n**Example 4: Secrets Management**\n- **Gap**: Secrets management not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add secrets management to Section 9 ‚Üí Secrets Management:\n   HashiCorp Vault for secrets storage,\n   dynamic secrets with 24-hour TTL,\n   auto-rotation for database credentials,\n   audit logging enabled\"\n  ```\n- **Expected Outcome**: Section 9 with Vault config, rotation policy, audit logging\n- **Impact**: LAS1 ‚Üí Compliant (+0.4 points)\n\n**Example 5: Encryption at Rest**\n- **Gap**: Encryption at rest not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add encryption at rest to Section 9 ‚Üí Data Protection:\n   AES-256 encryption for all databases,\n   AWS KMS for key management,\n   automatic key rotation every 90 days,\n   envelope encryption for S3 buckets\"\n  ```\n- **Expected Outcome**: Section 9 with encryption standards, KMS integration, rotation policy\n- **Impact**: LAS6 ‚Üí Compliant (+0.5 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required security control fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all security controls\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete Security Controls** (estimated impact: +0.6 points)\n   - Document mTLS for all service-to-service communication (Section 9)\n   - Add API authentication (OAuth 2.0/JWT) to Section 9\n   - Define certificate management lifecycle (Section 9 or 11)\n   - Specify secrets management solution (Vault/Key Vault) in Section 9\n   - Document TLS version enforcement (minimum 1.2, prefer 1.3) in Section 9\n\n2. **Enhance Encryption & Data Protection** (estimated impact: +0.3 points)\n   - Document encryption at rest (AES-256, key rotation) in Section 9\n   - Add encryption in transit (TLS 1.3, cipher suites) to Section 9\n   - Define key management strategy (KMS, HSM) in Section 9\n   - Specify data classification policy in Section 9\n   - Add PII/sensitive data handling procedures to Section 9\n\n3. **Improve Security Monitoring & Compliance** (estimated impact: +0.2 points)\n   - Add security audit logging to Section 11 (SIEM integration, retention)\n   - Document vulnerability scanning process and frequency\n   - Define security incident response procedures (Section 11)\n   - Specify penetration testing schedule and scope\n   - Add compliance certifications tracking (SOC 2, ISO 27001, etc.)\n\n**Priority Order**: LAS1 (API auth) ‚Üí LAS2 (mTLS) ‚Üí LAS8 (cert management) ‚Üí LAS6 (encryption) ‚Üí LAS7 (SSO) ‚Üí LAS5 (third-party APIs) ‚Üí LAS3 (inter-cluster) ‚Üí LAS4 (domain APIs)\n\n**Estimated Final Score After Remediation**: 8.7-9.2/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Replaced old simple sections with 8 comprehensive LAS requirements\n- LAS1: API Exposure (4 subsections, 10 data points)\n- LAS2: Intra-Microservices Communication (3 subsections, 6 data points)\n- LAS3: Inter-Cluster Kubernetes Communication (2 subsections, 5 data points)\n- LAS4: Domain API Communication (3 subsections, 7 data points)\n- LAS5: Third-Party API Consumption (3 subsections, 7 data points)\n- LAS6: Data Lake Communication (3 subsections, 7 data points)\n- LAS7: Internal Application Authentication (3 subsections, 7 data points)\n- LAS8: HTTP Encryption Scheme (3 subsections, 7 data points)\n- Added comprehensive Appendix with 4 sections\n- Total: 56 validation data points across 24 subsections\n- Source mapping expanded to Sections 4, 5, 7, 9, 11\n- Aligned with Cloud Architecture template structure\n- All content in English\n\n**Version 1.0 (Previous)**:\n- Initial template with 6 simple sections\n- Basic PLACEHOLDER approach\n- Limited source traceability\n- Focused on API security, authentication, encryption only\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=security-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=security-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=security-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=security-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=security-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the security architecture documentation.\n",
        "skills/architecture-compliance/templates/TEMPLATE_SRE_ARCHITECTURE.md": "# Compliance Contract: SRE Architecture (Site Reliability Engineering)\n\n**Project**: [PROJECT_NAME]\n**Generation Date**: [GENERATION_DATE]\n**Source**: ARCHITECTURE.md (Sections 2, 4, 5, 7, 10, 11)\n**Version**: 2.0\n\n---\n\n<!-- @include-with-config shared/sections/document-control.md config=sre-architecture -->\n\n<!-- @include-with-config shared/sections/dynamic-field-instructions.md config=sre-architecture -->\n\n**CRITICAL - Two-Tier Compliance Scoring**:\nThis template uses a two-tier scoring system for SRE requirements:\n\n**Blocker Requirements (36 total)** - MANDATORY:\n- ALL Blocker requirements must be Compliant or Not Applicable for approval\n- Status values: Compliant, Non-Compliant, Not Applicable, Unknown\n- Non-Compliant or Unknown Blocker requirements BLOCK approval (score capped at 4.9)\n- Blocker Score = (Compliant + Not Applicable) / 36 ‚Üí Must be 100% for approval pathway\n\n**Desired Requirements (21 total)** - OPTIONAL:\n- Desired requirements are enhancement recommendations\n- Only counted if status is Compliant or Not Applicable\n- Non-Compliant or Unknown Desired requirements do NOT block approval\n- Desired Score = (Compliant + Not Applicable) / 21 ‚Üí Enhancement metric\n\n**Final Score Calculation**:\n- Final Score = (Blocker Score √ó 0.7) + (Desired Score √ó 0.3)\n- Minimum for approval (score ‚â• 7.0): All 36 Blocker requirements pass\n- Auto-approval (score ‚â• 8.0): All 36 Blocker pass + at least 60% Desired requirements\n\n**Note**: Not Applicable items counted as fully compliant (included in compliance score)\n\n---\n\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LASRE01 | Operational and audit logs must be recorded in a structured format, us... | Practice - Log Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE02 | Operational logs must record relevant information, classified into lev... | Practice - Log Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE03 | Logs must be accessible without depending on third parties, either thr... | Practice - Log Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE04 | Automatic rollback mechanisms must be in place in case of failures dur... | Practice - Application Deployment | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE05 | All configurations must be stored in official and secure repositories,... | Practice - Configuration Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.4 | [Role or N/A] |\n| LASRE06 | Application documentation and operational procedures (SOP) will be mai... | Practice - Operational Documentation | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.4 | [Role or N/A] |\n| LASRE07 | The application must implement mechanisms that allow identifying when ... | Practice - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE08 | The application must implement health check mechanisms that allow iden... | Practice - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE09 | The application must have high availability mechanisms, through the im... | Practice - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE10 | Load tests must be executed and documented on all application componen... | Practice - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE11 | The application must have automatic adjustment mechanisms in the numbe... | Practice - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE12 | A documented recovery plan (DRP) must be in place, establishing the ne... | Practice - Recovery and Resilience Testing | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.2 | [Role or N/A] |\n| LASRE13 | Has C2 application and deployment diagrams in IcePanel. | Practice - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE14 | The application is registered in the Bank's application portfolio and ... | Practice - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE15 | The escalation matrix is defined and resolving groups are registered i... | Practice - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE16 | Has generated a request for implementation or modification of applicat... | Practice - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE17 | Has defined the mechanism and criteria for measuring application avail... | Observability - Key Metrics | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.2 | [Role or N/A] |\n| LASRE18 | Has defined the mechanism and criteria for measuring application perfo... | Observability - Key Metrics | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.2 | [Role or N/A] |\n| LASRE19 | Monitored components have dynamic or static thresholds correctly confi... | Observability - Key Metrics | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.2 | [Role or N/A] |\n| LASRE20 | Has validated that microservices are instrumented with Dynatrace (auto... | Observability - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE21 | Internal APIs of the application are monitored. | Observability - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE22 | Has validated that microservice requests correctly handle exceptions a... | Observability - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE23 | The application URL has synthetic availability validation. | Observability - Frontend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE24 | The application frontend allows injection of Dynatrace JavaScript for ... | Observability - User Experience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE25 | Confirms that in security components like WAF, firewall, frontdoor, et... | Observability - User Experience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE26 | The application has UX monitoring. Note: Applies to applications with ... | Observability - User Experience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE27 | Has performed Dynatrace licensing cost estimation using the official c... | Observability - Cost Estimation | [Compliant/Non-Compliant/Not Applicable/Unknown] | 2.5 | [Role or N/A] |\n| LASRE28 | Prerequisites necessary to ensure coverage of all components have been... | Observability - Cost Estimation | [Compliant/Non-Compliant/Not Applicable/Unknown] | 2.5 | [Role or N/A] |\n| LASRE29 | Onpremise or cloud servers of the application have Dynatrace agent ins... | Observability - Infrastructure | [Compliant/Non-Compliant/Not Applicable/Unknown] | 5.2 | [Role or N/A] |\n| LASRE30 | Containers (OpenShift/AKS/EKS/GKE) have Dynatrace Operator/OneAgent de... | Observability - Infrastructure | [Compliant/Non-Compliant/Not Applicable/Unknown] | 5.2 | [Role or N/A] |\n| LASRE31 | Onpremise and/or cloud dependencies like DB, load balancers, Redis, fr... | Observability - Infrastructure | [Compliant/Non-Compliant/Not Applicable/Unknown] | 5.2 | [Role or N/A] |\n| LASRE32 | Has monitoring of batch processes not managed by Control-M. | Observability - Batch Processing | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE33 | Consistency between applications and their source code will be ensured... | Observability - Application Deployment | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE34 | Must have automation of the Disaster Recovery process. | Observability - Disaster Recovery | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.2 | [Role or N/A] |\n| LASRE35 | Must have automation of the process to validate the state of what is r... | Observability - Disaster Recovery | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.2 | [Role or N/A] |\n| LASRE36 | Must have an automated process for managing application services (star... | Observability - Application Operational Tasks | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE37 | Generated logs must be centralized in an analysis or monitoring tool, ... | Observability - Log Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE38 | Operational logs must allow modification of verbosity level, thus faci... | Observability - Log Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE39 | Configurations must be subject to version control, ensuring that any c... | Observability - Configuration Management | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.4 | [Role or N/A] |\n| LASRE40 | Deployments of new versions will be performed gradually, using strateg... | Observability - Integration, Deployment and Delivery | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE41 | Appropriate traffic management strategies will be applied to the appli... | Observability - Integration, Deployment and Delivery | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE42 | Will have a defined 7x24 maintenance procedure that guarantees continu... | Observability - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE43 | Must have alternative mechanisms that allow managing backend failures,... | Automation - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE44 | Automatic retries and proper management of timeouts for both client an... | Automation - Operational Resilience | [Compliant/Non-Compliant/Not Applicable/Unknown] | 10.1 | [Role or N/A] |\n| LASRE45 | The application must execute chaos tests, with the objective of evalua... | Automation - Recovery and Resilience Testing | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.2 | [Role or N/A] |\n| LASRE46 | Components involved in the application's critical journeys are identif... | Automation - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE47 | Components involved in the application's critical journeys are identif... | Automation - Information and Architecture | [Compliant/Non-Compliant/Not Applicable/Unknown] | 4.1/2.1 | [Role or N/A] |\n| LASRE48 | Microservices and workloads contain labels that allow differentiating ... | Automation - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE49 | Has validated with the external system provider that they have APIs th... | Automation - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE50 | Critical services have advanced monitoring configurations and threshol... | Automation - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE51 | Application logs are correctly ingested into observability tools. | Automation - Backend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE52 | The application allows performing synthetic validations through authen... | Automation - Frontend Application | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.1 | [Role or N/A] |\n| LASRE53 | Cloud components (MS Azure, GCP, AWS) of the application are tagged at... | Automation - Infrastructure | [Compliant/Non-Compliant/Not Applicable/Unknown] | 5.2 | [Role or N/A] |\n| LASRE54 | Has health or state detection of critical processes or OS services (pr... | Automation - Infrastructure | [Compliant/Non-Compliant/Not Applicable/Unknown] | 5.2 | [Role or N/A] |\n| LASRE55 | Must have generation of reports on application components. | Automation - Application Operational Tasks | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE56 | Will have an automated process to sanitize or copy data to previous en... | Automation - Application Operational Tasks | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n| LASRE57 | Will have automation to remediate application failures automatically. | Automation - Auto-remediation | [Compliant/Non-Compliant/Not Applicable/Unknown] | 11.3 | [Role or N/A] |\n\n<!-- @include shared/fragments/compliance-summary-footer.md -->\n\n**Blocker Requirements**: [X/36 Compliant] (**MANDATORY** - All must pass for approval)\n**Desired Requirements**: [Y/21 Compliant] (OPTIONAL - Enhancement recommendations)\n\n**Compliance by Area**:\n- Practice: [X/16 Compliant]\n- Observability: [Y/26 Compliant]\n- Automation: [Z/15 Compliant]\n\n---\n\n## 1. Practice Requirements (LASRE01-LASRE16)\n\n**Section Requirements**: 16 total (16 Blocker, 0 Desired)\n\n---\n\n### 1.1 Log Management (LASRE01 - Blocker)\n\n**Requirement**: Operational and audit logs must be recorded in a structured format, using defined and consistent fields, or following a standard to ensure uniformity and facilitate analysis.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.1.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.1.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE01]\n\n---\n\n### 1.2 Log Management (LASRE02 - Blocker)\n\n**Requirement**: Operational logs must record relevant information, classified into levels such as debug, info, or error according to the system's needs and characteristics.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.2.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.2.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE02]\n\n---\n\n### 1.3 Log Management (LASRE03 - Blocker)\n\n**Requirement**: Logs must be accessible without depending on third parties, either through internal mechanisms or automated processes that allow efficient and secure consultation of these records.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.3.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.3.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE03]\n\n---\n\n### 1.4 Application Deployment (LASRE04 - Blocker)\n\n**Requirement**: Automatic rollback mechanisms must be in place in case of failures during deployment, ensuring that the system can revert to a previous stable version.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.4.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.4.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE04]\n\n---\n\n### 1.5 Configuration Management (LASRE05 - Blocker)\n\n**Requirement**: All configurations must be stored in official and secure repositories, such as authorized repositories or specialized services like Azure Repos, to ensure protection and controlled access to information.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.5.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.5.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE05]\n\n---\n\n### 1.6 Operational Documentation (LASRE06 - Blocker)\n\n**Requirement**: Application documentation and operational procedures (SOP) will be maintained in official repositories, accessible to the entire team.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Team Lead or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.6.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.6.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE06]\n\n---\n\n### 1.7 Operational Resilience (LASRE07 - Blocker)\n\n**Requirement**: The application must implement mechanisms that allow identifying when it is ready to receive load, ensuring that services are available and operational before starting processes or receiving requests.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.7.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.7.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE07]\n\n---\n\n### 1.8 Operational Resilience (LASRE08 - Blocker)\n\n**Requirement**: The application must implement health check mechanisms that allow identifying if it is functioning correctly, ensuring timely detection of possible service failures.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.8.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.8.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE08]\n\n---\n\n### 1.9 Operational Resilience (LASRE09 - Blocker)\n\n**Requirement**: The application must have high availability mechanisms, through the implementation of more than one replica, to ensure service continuity and minimize possible interruptions.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.9.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.9.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE09]\n\n---\n\n### 1.10 Operational Resilience (LASRE10 - Blocker)\n\n**Requirement**: Load tests must be executed and documented on all application components before production release, ensuring that performance is adequate and results are available for consultation and analysis.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.10.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.10.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE10]\n\n---\n\n### 1.11 Operational Resilience (LASRE11 - Blocker)\n\n**Requirement**: The application must have automatic adjustment mechanisms in the number of instances, allowing scaling according to service load to ensure optimal performance and continuous availability.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.11.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.11.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE11]\n\n---\n\n### 1.12 Recovery and Resilience Testing (LASRE12 - Blocker)\n\n**Requirement**: A documented recovery plan (DRP) must be in place, establishing the necessary procedures and resources to restore service in case of incidents or disasters, guaranteeing operational continuity.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Business Continuity Manager or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.12.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.12.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE12]\n\n---\n\n### 1.13 Information and Architecture (LASRE13 - Blocker)\n\n**Requirement**: Has C2 application and deployment diagrams in IcePanel.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.13.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.13.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE13]\n\n---\n\n### 1.14 Information and Architecture (LASRE14 - Blocker)\n\n**Requirement**: The application is registered in the Bank's application portfolio and business criticality has been categorized.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.14.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.14.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE14]\n\n---\n\n### 1.15 Information and Architecture (LASRE15 - Blocker)\n\n**Requirement**: The escalation matrix is defined and resolving groups are registered in the application portfolio.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.15.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.15.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE15]\n\n---\n\n### 1.16 Information and Architecture (LASRE16 - Blocker)\n\n**Requirement**: Has generated a request for implementation or modification of application observability.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 1.16.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 1.16.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE16]\n\n---\n\n## 2. Observability Requirements (LASRE17-LASRE42)\n\n**Section Requirements**: 26 total (20 Blocker, 6 Desired)\n\n---\n\n### 2.1 Key Metrics (LASRE17 - Blocker)\n\n**Requirement**: Has defined the mechanism and criteria for measuring application availability.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.1.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.1.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE17]\n\n---\n\n### 2.2 Key Metrics (LASRE18 - Blocker)\n\n**Requirement**: Has defined the mechanism and criteria for measuring application performance.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.2.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.2.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE18]\n\n---\n\n### 2.3 Key Metrics (LASRE19 - Blocker)\n\n**Requirement**: Monitored components have dynamic or static thresholds correctly configured.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.3.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.3.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE19]\n\n---\n\n### 2.4 Backend Application (LASRE20 - Blocker)\n\n**Requirement**: Has validated that microservices are instrumented with Dynatrace (automatic or manual instrumentation).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.4.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.4.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE20]\n\n---\n\n### 2.5 Backend Application (LASRE21 - Blocker)\n\n**Requirement**: Internal APIs of the application are monitored.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.5.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.5.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE21]\n\n---\n\n### 2.6 Backend Application (LASRE22 - Blocker)\n\n**Requirement**: Has validated that microservice requests correctly handle exceptions at code level in test environment, to avoid increase in monitoring failure rate in production.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.6.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.6.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE22]\n\n---\n\n### 2.7 Frontend Application (LASRE23 - Blocker)\n\n**Requirement**: The application URL has synthetic availability validation.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Frontend SRE or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.7.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.7.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE23]\n\n---\n\n### 2.8 User Experience (LASRE24 - Blocker)\n\n**Requirement**: The application frontend allows injection of Dynatrace JavaScript for RUM (Real User Experience) capture. Note: Applies to applications with business transactionality.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.8.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.8.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE24]\n\n---\n\n### 2.9 User Experience (LASRE25 - Blocker)\n\n**Requirement**: Confirms that in security components like WAF, firewall, frontdoor, etc., there are no blocks to Dynatrace injection and beacons. Note: Applies to applications with business transactionality.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.9.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.9.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE25]\n\n---\n\n### 2.10 User Experience (LASRE26 - Blocker)\n\n**Requirement**: The application has UX monitoring. Note: Applies to applications with business transactionality.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.10.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.10.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE26]\n\n---\n\n### 2.11 Cost Estimation (LASRE27 - Blocker)\n\n**Requirement**: Has performed Dynatrace licensing cost estimation using the official calculator and has Observability team approval for coverage and/or budget allocation.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Team Lead or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.11.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.11.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE27]\n\n---\n\n### 2.12 Cost Estimation (LASRE28 - Blocker)\n\n**Requirement**: Prerequisites necessary to ensure coverage of all components have been considered in the budget, such as manual code instrumentation, additional development by the provider, cloud service activation, infrastructure, among others.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Team Lead or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.12.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.12.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE28]\n\n---\n\n### 2.13 Infrastructure (LASRE29 - Blocker)\n\n**Requirement**: Onpremise or cloud servers of the application have Dynatrace agent installed (OneAgent).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Platform Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.13.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.13.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE29]\n\n---\n\n### 2.14 Infrastructure (LASRE30 - Blocker)\n\n**Requirement**: Containers (OpenShift/AKS/EKS/GKE) have Dynatrace Operator/OneAgent deployed.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Platform Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.14.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.14.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE30]\n\n---\n\n### 2.15 Infrastructure (LASRE31 - Blocker)\n\n**Requirement**: Onpremise and/or cloud dependencies like DB, load balancers, Redis, frontdoor, etc. of the application are monitored.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Platform Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.15.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.15.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE31]\n\n---\n\n### 2.16 Batch Processing (LASRE32 - Blocker)\n\n**Requirement**: Has monitoring of batch processes not managed by Control-M.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.16.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.16.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE32]\n\n---\n\n### 2.17 Application Deployment (LASRE33 - Blocker)\n\n**Requirement**: Consistency between applications and their source code will be ensured through automated deployment and configuration processes.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.17.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.17.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE33]\n\n---\n\n### 2.18 Disaster Recovery (LASRE34 - Blocker)\n\n**Requirement**: Must have automation of the Disaster Recovery process.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Business Continuity Manager or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.18.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.18.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE34]\n\n---\n\n### 2.19 Disaster Recovery (LASRE35 - Blocker)\n\n**Requirement**: Must have automation of the process to validate the state of what is required to start the application at the Alternate Site.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Business Continuity Manager or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.19.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.19.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE35]\n\n---\n\n### 2.20 Application Operational Tasks (LASRE36 - Blocker)\n\n**Requirement**: Must have an automated process for managing application services (start, stop, restart).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: **BLOCKER** (Blocking - Must Pass)\n\n#### 2.20.1 Implementation\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [If Compliant: Implemented and documented. If Non-Compliant: Not implemented. If Not Applicable: N/A. If Unknown: Not documented]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Implement in ARCHITECTURE.md Section 10 or 11]\n\n#### 2.20.2 Validation\n\n**Validation Evidence**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Validation results and evidence]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant or Unknown: Document validation approach]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE36]\n\n---\n\n### 2.21 Log Management (LASRE37 - Desired)\n\n**Requirement**: Generated logs must be centralized in an analysis or monitoring tool, such as Dynatrace or Splunk, to facilitate their management, consultation, and analysis.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE37]\n\n---\n\n### 2.22 Log Management (LASRE38 - Desired)\n\n**Requirement**: Operational logs must allow modification of verbosity level, thus facilitating adjustment of the amount and type of information recorded according to monitoring or diagnostic needs.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE38]\n\n---\n\n### 2.23 Configuration Management (LASRE39 - Desired)\n\n**Requirement**: Configurations must be subject to version control, ensuring that any change is recorded and can be audited or reverted if necessary.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE39]\n\n---\n\n### 2.24 Integration, Deployment and Delivery (LASRE40 - Desired)\n\n**Requirement**: Deployments of new versions will be performed gradually, using strategies such as Canary Release, to minimize risks and ensure a controlled transition before applying changes to all users.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE40]\n\n---\n\n### 2.25 Integration, Deployment and Delivery (LASRE41 - Desired)\n\n**Requirement**: Appropriate traffic management strategies will be applied to the application's target audience, such as the Friends & Family approach, to control access and use according to defined needs.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE41]\n\n---\n\n### 2.26 Operational Resilience (LASRE42 - Desired)\n\n**Requirement**: Will have a defined 7x24 maintenance procedure that guarantees continuous application availability, allowing preventive and corrective tasks to be performed without affecting service for users.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE42]\n\n---\n\n## 3. Automation Requirements (LASRE43-LASRE57)\n\n**Section Requirements**: 15 total (0 Blocker, 15 Desired)\n\n---\n\n### 3.1 Operational Resilience (LASRE43 - Desired)\n\n**Requirement**: Must have alternative mechanisms that allow managing backend failures, such as Fallback or Circuit Breaker strategies, ensuring service continuity and resilience in case of possible interruptions.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE43]\n\n---\n\n### 3.2 Operational Resilience (LASRE44 - Desired)\n\n**Requirement**: Automatic retries and proper management of timeouts for both client and backend must be implemented, ensuring resilience and proper handling of wait or failure situations in communications.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE44]\n\n---\n\n### 3.3 Recovery and Resilience Testing (LASRE45 - Desired)\n\n**Requirement**: The application must execute chaos tests, with the objective of evaluating its resilience and recovery capacity in adverse scenarios or unexpected failures.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Business Continuity Manager or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE45]\n\n---\n\n### 3.4 Information and Architecture (LASRE46 - Desired)\n\n**Requirement**: Components involved in the application's critical journeys are identified in the C2 diagram.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE46]\n\n---\n\n### 3.5 Information and Architecture (LASRE47 - Desired)\n\n**Requirement**: Components involved in the application's critical journeys are identified in the C2 diagram.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Enterprise Architect or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE47]\n\n---\n\n### 3.6 Backend Application (LASRE48 - Desired)\n\n**Requirement**: Microservices and workloads contain labels that allow differentiating the application and its vital functions (for example: application name, application id, resolving group, vital function, tribe, cell, etc.).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE48]\n\n---\n\n### 3.7 Backend Application (LASRE49 - Desired)\n\n**Requirement**: Has validated with the external system provider that they have APIs that allow monitoring the state of their system/APIs synthetically.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE49]\n\n---\n\n### 3.8 Backend Application (LASRE50 - Desired)\n\n**Requirement**: Critical services have advanced monitoring configurations and threshold customization (traffic load, anomaly detection, latency, key request, etc.).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE50]\n\n---\n\n### 3.9 Backend Application (LASRE51 - Desired)\n\n**Requirement**: Application logs are correctly ingested into observability tools.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: SRE Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE51]\n\n---\n\n### 3.10 Frontend Application (LASRE52 - Desired)\n\n**Requirement**: The application allows performing synthetic validations through authentication of generic Observability user without MFA (only user and password).\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Frontend SRE or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE52]\n\n---\n\n### 3.11 Infrastructure (LASRE53 - Desired)\n\n**Requirement**: Cloud components (MS Azure, GCP, AWS) of the application are tagged at the source for easy identification.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Platform Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE53]\n\n---\n\n### 3.12 Infrastructure (LASRE54 - Desired)\n\n**Requirement**: Has health or state detection of critical processes or OS services (process group) on hosts.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Platform Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE54]\n\n---\n\n### 3.13 Application Operational Tasks (LASRE55 - Desired)\n\n**Requirement**: Must have generation of reports on application components.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE55]\n\n---\n\n### 3.14 Application Operational Tasks (LASRE56 - Desired)\n\n**Requirement**: Will have an automated process to sanitize or copy data to previous environments.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: DevOps Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE56]\n\n---\n\n### 3.15 Auto-remediation (LASRE57 - Desired)\n\n**Requirement**: Will have automation to remediate application failures automatically.\n\n**Status**: [Compliant/Non-Compliant/Not Applicable/Unknown]\n**Responsible Role**: Automation Engineer or N/A\n**Criticality**: DESIRED (Optional Enhancement)\n\n**Implementation Status**: [Value or \"Not specified\"]\n- Status: [Compliant/Non-Compliant/Not Applicable/Unknown]\n- Explanation: [Brief explanation]\n- Source: [ARCHITECTURE.md Section X.Y or \"Not documented\"]\n- Note: [If Non-Compliant: Optional enhancement - consider implementing]\n\n**Source References**: [ARCHITECTURE.md sections used for LASRE57]\n\n---\n\n## Appendix: Source Traceability and Completion Status\n\n### A.1 Definitions and Terminology\n\n**SRE Architecture Terms**:\n- **SLO (Service Level Objective)**: Target level of service reliability agreed upon between service provider and users\n- **SLI (Service Level Indicator)**: Quantifiable measure of service performance (e.g., latency, availability, error rate)\n- **Error Budget**: Maximum allowable downtime or errors before SLO is violated\n- **Golden Signals**: Core monitoring metrics (latency, traffic, errors, saturation)\n- **Observability**: Ability to understand system internal state from external outputs (logs, metrics, traces)\n- **MTTR (Mean Time To Recovery)**: Average time to restore service after incident\n- **MTBF (Mean Time Between Failures)**: Average time between system failures\n- **Toil**: Manual, repetitive operational work that should be automated\n- **Incident Management**: Process for responding to service disruptions\n- **Blameless Postmortem**: Retrospective analysis focusing on systemic improvements, not individual blame\n\n<!-- @include shared/fragments/status-codes.md -->\n\n**SRE Abbreviations**:\n- **LASRE**: SRE Architecture compliance requirement code\n- **RED**: Rate, Errors, Duration (monitoring methodology)\n- **USE**: Utilization, Saturation, Errors (resource monitoring)\n- **APM**: Application Performance Monitoring\n- **RCA**: Root Cause Analysis\n\n---\n\n<!-- @include-with-config shared/sections/validation-methodology.md config=sre-architecture -->\n\n---\n\n### A.3 Document Completion Guide\n\n<!-- @include shared/sections/completion-guide-intro.md -->\n\n---\n\n#### A.3.1 Common Gaps Quick Reference\n\n**Common SRE Architecture Gaps and Remediation**:\n\n| Gap Description | Impact | ARCHITECTURE.md Section to Update | Recommended Action |\n|-----------------|--------|----------------------------------|-------------------|\n| SLO definitions not documented | LASRE1 Non-Compliant | Section 10 (Performance Requirements) | Define SLOs with targets (e.g., 99.9% availability, p99 latency < 200ms) |\n| Error budget policy missing | LASRE1 Non-Compliant | Section 10 (Performance) | Document error budget calculation and consumption policies |\n| Incident response plan undefined | LASRE2 Non-Compliant | Section 11 (Operational ‚Üí Incident Management) | Define on-call rotation, escalation paths, runbooks |\n| Observability stack not specified | LASRE3 Unknown | Section 11 (Operational Considerations) | Specify monitoring tools (Prometheus, Grafana, Datadog, etc.) |\n| Deployment automation undefined | LASRE4 Unknown | Section 11 (Operational ‚Üí Deployment) | Document CI/CD pipeline, rollback procedures, canary releases |\n| Load testing strategy missing | LASRE5 Unknown | Section 10 (Performance) | Specify load test scenarios, tools, and acceptance criteria |\n| Runbook repository not specified | LASRE2 Unknown | Section 11 (Operational ‚Üí Incident Management) | Define runbook location, format, maintenance process |\n| Chaos engineering not documented | LASRE5 Unknown | Section 10 or 11 (Performance/Operational) | Specify chaos experiments, tools (Chaos Monkey, Gremlin), frequency |\n\n---\n\n#### A.3.2 Step-by-Step Remediation Workflow\n\n<!-- @include shared/sections/remediation-workflow-guide.md -->\n\n**SRE Architecture-Specific Examples**:\n\n**Example 1: Defining SLOs and Error Budgets**\n- **Gap**: Missing SLO definitions and error budget policy\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add SLO definitions to Section 10:\n   Availability SLO: 99.9% (43 minutes downtime/month),\n   Latency SLO: p99 < 200ms, p95 < 100ms,\n   Error budget: 1 - 99.9% = 0.1% (43 min/month),\n   Error budget policy: freeze deployments when 50% consumed\"\n  ```\n- **Expected Outcome**: Section 10 with SLO targets, error budget calculation, consumption policy\n- **Impact**: LASRE1 ‚Üí Compliant (+0.6 points)\n\n**Example 2: Incident Response Plan**\n- **Gap**: Incident response plan not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add incident response plan to Section 11:\n   On-call rotation: weekly, PagerDuty integration,\n   Escalation: L1 (5 min) ‚Üí L2 (15 min) ‚Üí L3 (30 min),\n   Runbook repository: GitHub wiki with incident playbooks,\n   Postmortem process: within 48 hours, RCA template\"\n  ```\n- **Expected Outcome**: Section 11 with on-call rotation, escalation matrix, runbook repo, postmortem process\n- **Impact**: LASRE2 ‚Üí Compliant (+0.5 points)\n\n**Example 3: Observability Stack**\n- **Gap**: Monitoring and observability tools not specified\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add observability stack to Section 11:\n   Metrics: Prometheus for collection, Grafana for dashboards,\n   Logs: ELK stack (Elasticsearch, Logstash, Kibana),\n   Traces: Jaeger for distributed tracing,\n   Alerting: Prometheus Alertmanager, PagerDuty integration,\n   Dashboards: RED (Rate, Errors, Duration) and USE (Utilization, Saturation, Errors)\"\n  ```\n- **Expected Outcome**: Section 11 with observability tools, dashboards, alerting configuration\n- **Impact**: LASRE3 ‚Üí Compliant (+0.5 points)\n\n**Example 4: Deployment Automation**\n- **Gap**: CI/CD pipeline and deployment strategy undefined\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add deployment automation to Section 11:\n   CI/CD: GitHub Actions with automated testing,\n   Deployment strategy: blue-green deployments with instant rollback,\n   Canary releases: 5% ‚Üí 25% ‚Üí 100% with automated rollback on SLO breach,\n   Feature flags: LaunchDarkly for gradual rollout\"\n  ```\n- **Expected Outcome**: Section 11 with CI/CD pipeline, deployment strategies, rollback procedures\n- **Impact**: LASRE4 ‚Üí Compliant (+0.4 points)\n\n**Example 5: Load Testing and Chaos Engineering**\n- **Gap**: Reliability testing not documented\n- **Skill Command**:\n  ```\n  /skill architecture-docs\n  \"Add reliability testing to Section 10:\n   Load testing: k6 or Gatling, weekly tests at 150% peak load,\n   Acceptance criteria: p99 latency < 200ms at peak load,\n   Chaos engineering: monthly Chaos Monkey experiments,\n   Game days: quarterly failure scenario simulations\"\n  ```\n- **Expected Outcome**: Section 10 with load testing strategy, chaos engineering plan, acceptance criteria\n- **Impact**: LASRE5 ‚Üí Compliant (+0.4 points)\n\n---\n\n#### A.3.3 Achieving Auto-Approve Status (8.0+ Score)\n\n**Target Score Breakdown**:\n- Completeness ({{completeness_percent}} weight): Fill all required SRE fields\n- Compliance ({{compliance_percent}} weight): Convert UNKNOWN/FAIL to PASS\n- Quality ({{quality_percent}} weight): Add source traceability for all operational procedures\n\n**To Achieve AUTO_APPROVE Status (8.0+ score):**\n\n1. **Complete SLO and Reliability Engineering** (estimated impact: +0.6 points)\n   - Define SLOs with quantitative targets (availability, latency, throughput) in Section 10\n   - Document error budget calculation and consumption policy in Section 10\n   - Add load testing strategy with tools, scenarios, acceptance criteria in Section 10\n   - Specify chaos engineering experiments and frequency in Section 10 or 11\n   - Define capacity planning process with growth projections in Section 11\n\n2. **Enhance Incident Management and Operations** (estimated impact: +0.3 points)\n   - Document incident response plan: on-call rotation, escalation, runbooks in Section 11\n   - Add runbook repository with location, format, maintenance process\n   - Define postmortem process with RCA template and timeline\n   - Specify observability stack: metrics (Prometheus), logs (ELK), traces (Jaeger) in Section 11\n   - Add alerting strategy with severity levels and escalation in Section 11\n\n3. **Improve Deployment and Automation** (estimated impact: +0.2 points)\n   - Document CI/CD pipeline with automated testing in Section 11\n   - Define deployment strategies: blue-green, canary, feature flags in Section 11\n   - Add rollback procedures with automated triggers on SLO breach\n   - Specify toil reduction initiatives and automation targets in Section 11\n   - Document change management process with approval gates in Section 11\n\n**Priority Order**: LASRE1 (SLOs + error budgets) ‚Üí LASRE2 (incident response) ‚Üí LASRE3 (observability) ‚Üí LASRE4 (deployment) ‚Üí LASRE5 (load testing + chaos)\n\n**Estimated Final Score After Remediation**: 8.5-9.0/10 (AUTO_APPROVE)\n\n---\n\n### A.4 Change History\n\n**Version 2.0 (Current)**:\n- Complete template restructuring to Version 2.0 format\n- Added comprehensive Appendix with A.1-A.4 subsections\n- Replaced \"Recommendations\" section with \"Missing Data Requiring Attention\" table\n- Added Data Extracted Successfully section\n- Added Not Applicable Items section\n- Added Unknown Status Items Requiring Investigation table\n- Expanded Generation Metadata\n- Aligned with Cloud Architecture template structure\n- Total: 36+ validation data points across SRE practices\n\n**Version 1.0 (Previous)**:\n- Basic appendix with source references\n- Recommendations-based approach\n- Limited structure\n\n---\n\n<!-- CRITICAL: The sections below use @include directives that expand to H2 headers.\n     DO NOT add section numbers (A.5, A.6, etc.) to these headers.\n     The resolved content will be ## Header format - preserve it exactly.\n     Validation rule 'forbidden_section_numbering' will BLOCK numbered sections after A.4. -->\n\n<!-- @include-with-config shared/sections/data-extracted-template.md config=sre-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/missing-data-table-template.md config=sre-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/not-applicable-template.md config=sre-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/unknown-status-table-template.md config=sre-architecture -->\n\n---\n\n<!-- @include-with-config shared/sections/generation-metadata.md config=sre-architecture -->\n\n---\n\n**Note**: This document is auto-generated from ARCHITECTURE.md. Status labels (Compliant/Non-Compliant/Not Applicable/Unknown) and responsible roles must be populated during generation based on available data. Items marked as Non-Compliant or Unknown require stakeholder action to complete the architecture documentation.\n",
        "skills/architecture-compliance/utils/README.md": "# Compliance Template Utilities\n\nThis directory contains utilities for working with compliance templates.\n\n## resolve-includes.ts (Bun/TypeScript)\n\n**Purpose**: Resolves `@include` and `@include-with-config` directives in compliance templates, expanding them into fully rendered documents using the Bun runtime.\n\n### Usage\n\n```bash\nbun resolve-includes.ts <template-file> [output-file] [--validate]\n# or make executable:\nchmod +x resolve-includes.ts\n./resolve-includes.ts <template-file> [output-file] [--validate]\n```\n\n**Arguments:**\n- `template-file`: Path to the template file (required)\n- `output-file`: Path for the expanded output (optional, outputs to stdout if omitted)\n\n**Options:**\n- `--validate`: Run template structure pre-validation after expansion\n\n### Examples\n\n**Expand a single template:**\n```bash\nbun utils/resolve-includes.ts templates/TEMPLATE_BUSINESS_CONTINUITY.md expanded.md\n```\n\n**Output to stdout:**\n```bash\nbun utils/resolve-includes.ts templates/TEMPLATE_SRE_ARCHITECTURE.md\n```\n\n**Expand with validation:**\n```bash\nbun utils/resolve-includes.ts templates/TEMPLATE_SECURITY_ARCHITECTURE.md expanded.md --validate\n```\n\n**Test all templates:**\n```bash\nfor template in templates/TEMPLATE_*.md; do\n  echo \"Testing: $(basename $template)\"\n  bun utils/resolve-includes.ts \"$template\" /tmp/test.md\n  rm /tmp/test.md\ndone\n```\n\n### How It Works\n\n1. **Reads the template file** and scans for include directives\n2. **Parses each directive** to extract the file path and configuration name\n3. **Loads shared content** from the specified path\n4. **Replaces variables** (for `@include-with-config`) using domain config files\n5. **Recursively resolves** nested includes (up to 3 levels deep)\n6. **Outputs the expanded template** with all includes resolved\n\n### Include Directive Syntax\n\n**Simple Include** (static content, no variable replacement):\n```markdown\n<!-- @include shared/fragments/status-codes.md -->\n```\n\n**Parameterized Include** (with variable replacement):\n```markdown\n<!-- @include-with-config shared/sections/document-control.md config=business-continuity -->\n```\n\n### Variable Replacement\n\nVariables in shared content use double-curly-brace syntax: `{{variable_name}}`\n\n**Example shared content:**\n```markdown\n**Review Board**: {{review_board}}\n**Compliance Code**: {{compliance_prefix}}\n```\n\n**Domain config** (`shared/config/business-continuity.json`):\n```json\n{\n  \"review_board\": \"Business Continuity Review Board\",\n  \"compliance_prefix\": \"LABC\"\n}\n```\n\n**Expanded output:**\n```markdown\n**Review Board**: Business Continuity Review Board\n**Compliance Code**: LABC\n```\n\n### Key Features\n\n- ‚úÖ **TypeScript type safety** with interfaces for `DomainConfig` and `IncludeDirective`\n- ‚úÖ **Modern ES modules** (`import/export`)\n- ‚úÖ **Bun-optimized APIs** (`Bun.file().text()`, `Bun.file().json<T>()`)\n- ‚úÖ **Clean async/await** patterns throughout\n- ‚úÖ **Simple includes** for static content\n- ‚úÖ **Parameterized includes** with JSON config-based variable replacement\n- ‚úÖ **Nested includes** support (up to 3 levels deep)\n- ‚úÖ **Circular include detection** prevents infinite loops\n- ‚úÖ **Error handling** with descriptive messages\n- ‚úÖ **Template pre-validation** (with `--validate` flag)\n- ‚úÖ **Statistics** showing line count changes\n\n### Error Handling\n\nThe script handles common errors gracefully:\n\n- **Missing template file**: Exits with error message\n- **Missing include file**: Keeps directive in place, shows error\n- **Missing config file**: Exits with error message\n- **Circular includes**: Exits with error message\n- **Max depth exceeded**: Exits with error message\n- **Unknown variables**: Warns but continues, keeps `{{variable}}` placeholder\n\n### Testing Results\n\nAll 10 compliance templates expand successfully:\n\n| Template | Current Lines | Expanded Lines | Difference |\n|----------|--------------|----------------|------------|\n| Business Continuity | 164 | 294 | +130 |\n| Cloud Architecture | 372 | 509 | +137 |\n| Data & AI Architecture | 1156 | 1293 | +137 |\n| Development Architecture | 530 | 622 | +92 |\n| Enterprise Architecture | 724 | 861 | +137 |\n| Integration Architecture | 556 | 654 | +98 |\n| Platform IT Infrastructure | 586 | 716 | +130 |\n| Process Transformation | 497 | 627 | +130 |\n| Security Architecture | 653 | 783 | +130 |\n| SRE Architecture | 1611 | 1735 | +124 |\n\n**Total lines saved by using includes**: ~1,287 lines across all 10 templates\n\n**Shared Content Breakdown:**\n- 10 shared sections (document-control, dynamic-field-instructions, validation-methodology, completion-guide-intro, generation-metadata, change-history-template, data-extracted-template, missing-data-table-template, not-applicable-template, unknown-status-table-template)\n- 3 shared fragments (status-codes, compliance-score-calculation, compliance-summary-footer)\n- 10 domain configs (all compliance domains)\n- 3 refactoring phases completed (Quick Wins + Table Templates + Compliance Summary)\n- Appendix standardization COMPLETE - All 10 templates have A.1-A.4 structure\n\n### Integration with Skill\n\nThe include resolution utility is used during contract generation (Phase 4, Step 4.1) to expand templates before placeholder replacement.\n\n**Workflow:**\n1. **Phase 1-3**: Extract data from ARCHITECTURE.md\n2. **Phase 4.1**: Load template and resolve includes using `resolve-includes.ts`\n3. **Phase 4.2**: Apply extracted data to placeholders in expanded template\n4. **Phase 4.3**: Populate compliance summary table\n5. **Phase 5**: Save final contract\n\n### Template Pre-Validation\n\nWhen using the `--validate` flag, the utility runs structural validation on the expanded template to catch common issues early:\n\n```bash\nbun utils/resolve-includes.ts templates/TEMPLATE_SRE_ARCHITECTURE.md expanded.md --validate\n```\n\n**Validates:**\n- Required sections present (Document Control, Compliance Summary, Appendix)\n- Appendix structure (A.1-A.4 sections)\n- Compliance codes follow correct format\n- No duplicate codes\n- Required metadata fields present\n\n**Benefits:**\n- Catch template errors before contract generation\n- Ensure template consistency across all 10 contract types\n- Faster feedback loop during template development\n\n### Performance\n\nBenchmark on SRE Architecture template (1655 lines):\n- **Bun**: ~33ms per run\n- Includes type safety and modern developer experience\n- Zero external dependencies\n\n### Maintenance\n\nWhen adding new shared content:\n\n1. Create the shared file in `shared/sections/` or `shared/fragments/`\n2. Update domain configs in `shared/config/` with new variables if needed\n3. Add `@include` directives to templates\n4. Test expansion with this script\n5. Update `shared/README.md` documentation\n\n### Requirements\n\n- Bun runtime 1.0 or higher\n- No external dependencies\n\n### License\n\nPart of the Solutions Architect Skills plugin for Claude Code.\n\n**Last Updated**: 2025-12-13 (Removed Python/Node.js implementations - Bun/TypeScript only)\n\n---\n\n## manifest-generator.ts (Bun/TypeScript)\n\n**Purpose**: Generate or update the COMPLIANCE_MANIFEST.md file after each compliance contract generation. Tracks all generated contracts with metadata (score, status, completeness).\n\n### Usage\n\n```bash\nbun manifest-generator.ts --mode <create|update> --project \"<name>\" \\\n  --contract-type \"<type>\" --filename \"<file>\" --score <0-10> \\\n  --status \"<status>\" --completeness <0-100>\n# or make executable:\nchmod +x manifest-generator.ts\n./manifest-generator.ts --mode <create|update> ...\n```\n\n**Required Arguments:**\n- `--mode`: `create` (new manifest) or `update` (modify existing)\n- `--project`: Project name from ARCHITECTURE.md Document Index\n- `--contract-type`: Full contract type name (e.g., \"Development Architecture\", \"Cloud Architecture\")\n- `--filename`: Generated contract filename\n- `--score`: Validation score (0-10, one decimal place, e.g., 8.5)\n- `--status`: Document status - one of: `Approved`, `In Review`, `Draft`, `Rejected`\n- `--completeness`: Completeness percentage (0-100, e.g., 85 for 85%)\n\n**Optional Arguments:**\n- `--compliance-docs-dir`: Custom output directory (default: `./compliance-docs`)\n\n**Working Directory Consideration** (v1.9.3+):\n\nWhen invoking manifest-generator from a different working directory than where ARCHITECTURE.md resides (e.g., plugin context), you MUST provide the `--compliance-docs-dir` parameter with an absolute path.\n\nExample:\n```bash\n# Determine absolute path first\nARCH_DIR=$(dirname \"$(realpath /path/to/ARCHITECTURE.md)\")\nCOMPLIANCE_DOCS_DIR=\"${ARCH_DIR}/compliance-docs\"\n\n# Pass to manifest-generator\nbun manifest-generator.ts \\\n  --mode create \\\n  --compliance-docs-dir \"${COMPLIANCE_DOCS_DIR}\" \\\n  [other params...]\n```\n\nWithout this parameter, manifest-generator uses `process.cwd()/compliance-docs`, which may be incorrect in plugin contexts.\n\n### Examples\n\n**Create new manifest (first contract):**\n```bash\nbun utils/manifest-generator.ts --mode create --project \"Task Scheduling System\" \\\n  --contract-type \"Development Architecture\" \\\n  --filename \"DEVELOPMENT_ARCHITECTURE_TaskScheduling_2025-12-14.md\" \\\n  --score 8.5 --status \"Approved\" --completeness 85\n```\n\n**Update existing manifest (subsequent contract):**\n```bash\nbun utils/manifest-generator.ts --mode update --project \"Task Scheduling System\" \\\n  --contract-type \"Cloud Architecture\" \\\n  --filename \"CLOUD_ARCHITECTURE_TaskScheduling_2025-12-14.md\" \\\n  --score 7.8 --status \"In Review\" --completeness 78\n```\n\n**Regenerate contract (replaces existing entry):**\n```bash\nbun utils/manifest-generator.ts --mode update --project \"Task Scheduling System\" \\\n  --contract-type \"Development Architecture\" \\\n  --filename \"DEVELOPMENT_ARCHITECTURE_TaskScheduling_2025-12-14.md\" \\\n  --score 9.0 --status \"Approved\" --completeness 95\n```\n\n### How It Works\n\n1. **Parses command-line arguments** and validates required parameters\n2. **Loads existing manifest** (in update mode) and extracts contract entries from table\n3. **Merges contract data**:\n   - Replaces entry if contract type already exists (regeneration)\n   - Appends entry if new contract type\n   - Sorts entries alphabetically by contract type\n4. **Calculates summary statistics**:\n   - Total contracts, average score, average completeness\n   - Counts by status (Approved, In Review, Draft, Rejected)\n5. **Generates manifest content**:\n   - Framework Reference section (static)\n   - Validation Configuration section (static)\n   - Generated Documents table (dynamic)\n   - Summary section (calculated)\n6. **Writes manifest file** to `/compliance-docs/COMPLIANCE_MANIFEST.md`\n\n### Manifest Structure\n\n**File**: `/compliance-docs/COMPLIANCE_MANIFEST.md`\n\n**Contents**:\n```markdown\n# Compliance Documentation Manifest\n\n**Project**: [PROJECT_NAME]\n**Source**: ARCHITECTURE.md\n**Generated**: [GENERATION_DATE]\n\n---\n\n## Compliance Framework Reference\n[Framework version, scoring formula, approval thresholds table]\n\n---\n\n## Validation Configuration\n[Schema paths, engine version, rule files]\n\n---\n\n## Generated Documents\n\n| Contract Type | Filename | Score | Status | Completeness | Generated |\n|---------------|----------|-------|--------|--------------|-----------|\n| Cloud Architecture | CLOUD_ARCHITECTURE_Task_2025-12-14.md | 7.8 | In Review | 78% | 2025-12-14 |\n| Development Architecture | DEV_ARCHITECTURE_Task_2025-12-14.md | 8.5 | Approved | 85% | 2025-12-14 |\n| SRE Architecture | SRE_ARCHITECTURE_Task_2025-12-14.md | 9.2 | Approved | 92% | 2025-12-14 |\n\n---\n\n## Summary\n- Total Contracts: 3\n- Average Score: 8.5/10\n- Average Completeness: 85%\n- Approved: 2, In Review: 1, Draft: 0, Rejected: 0\n- Last Updated: 2025-12-14 14:30:00\n```\n\n### Key Features\n\n- ‚úÖ **TypeScript type safety** with interfaces for `ContractMetadata` and `ManifestData`\n- ‚úÖ **Modern ES modules** (`import/export`)\n- ‚úÖ **Bun-optimized APIs** (`Bun.file().text()`, `Bun.write()`)\n- ‚úÖ **Automatic entry merging** (replace if same type, append if new)\n- ‚úÖ **Alphabetical sorting** by contract type\n- ‚úÖ **Summary statistics calculation** (averages, status counts)\n- ‚úÖ **Markdown table formatting** with proper alignment\n- ‚úÖ **Mode detection** (create vs update)\n- ‚úÖ **Error handling** with validation of arguments\n- ‚úÖ **Programmatic API** (exported functions for testing)\n\n### Update Behavior\n\n**Create mode** (`--mode create`):\n- Generates new manifest file\n- Initializes with Framework and Validation sections\n- Adds first contract entry\n- Sets up Summary section\n\n**Update mode** (`--mode update`):\n- Reads existing manifest\n- Parses contract entries from table\n- Merges new contract:\n  - **Same contract type**: Replaces existing entry (regeneration)\n  - **New contract type**: Appends new entry\n- Recalculates summary statistics\n- Writes updated manifest\n\n**Example - Regeneration**:\n```bash\n# Initial generation\nbun manifest-generator.ts --mode create --project \"Project\" \\\n  --contract-type \"Development Architecture\" --filename \"DEV_v1.md\" \\\n  --score 8.0 --status \"Draft\" --completeness 75\n\n# Later regeneration (replaces entry)\nbun manifest-generator.ts --mode update --project \"Project\" \\\n  --contract-type \"Development Architecture\" --filename \"DEV_v2.md\" \\\n  --score 9.5 --status \"Approved\" --completeness 98\n\n# Result: Only ONE \"Development Architecture\" entry in manifest (v2 replaced v1)\n```\n\n### Integration with SKILL.md\n\nThe manifest generator is integrated into the compliance contract generation workflow at **Phase 5, Step 5.3**.\n\n**Workflow**:\n1. **Phase 1-3**: Extract data from ARCHITECTURE.md and validate\n2. **Phase 4**: Generate compliance contract from template\n3. **Phase 5.1-5.2**: Save contract to `/compliance-docs/`\n4. **Phase 5.3**: **Update manifest** using `manifest-generator.ts`\n5. **Phase 5.4-5.5**: Generate per-contract and summary reports\n\n### Error Handling\n\nThe script validates all arguments and handles errors gracefully:\n\n- **Missing required argument**: Exits with clear error message listing required parameters\n- **Invalid mode**: Must be `create` or `update`\n- **Invalid score**: Must be 0-10\n- **Invalid status**: Must be one of: `Approved`, `In Review`, `Draft`, `Rejected`\n- **Invalid completeness**: Must be 0-100\n- **Compliance docs directory not found**: Exits with error (directory must exist)\n- **Manifest not found in update mode**: Automatically switches to create mode\n\n### Performance\n\n- **Fast parsing**: Uses regex to extract table rows from existing manifest\n- **Efficient merging**: In-place array operations (replace or append)\n- **Clean output**: Formatted markdown with proper table alignment\n- **Minimal dependencies**: No external packages required\n\n### Maintenance\n\nWhen modifying the manifest structure:\n\n1. Update section generators (`generateFrameworkSection`, `generateValidationSection`, etc.)\n2. Update table column definitions in `generateDocumentsTable`\n3. Update summary calculation in `calculateSummary`\n4. Update parsing logic in `parseExistingManifest` if table structure changes\n5. Test with both create and update modes\n\n### Requirements\n\n- Bun runtime 1.0 or higher\n- No external dependencies\n- Compliance docs directory must exist (`/compliance-docs/`)\n\n### Testing\n\n```bash\n# Create compliance-docs directory for testing\nmkdir -p compliance-docs\n\n# Test create mode\nbun utils/manifest-generator.ts --mode create --project \"Test Project\" \\\n  --contract-type \"Development Architecture\" --filename \"DEV_Test.md\" \\\n  --score 8.5 --status \"Approved\" --completeness 85\n\n# Verify manifest was created\ncat compliance-docs/COMPLIANCE_MANIFEST.md\n\n# Test update mode (add second contract)\nbun utils/manifest-generator.ts --mode update --project \"Test Project\" \\\n  --contract-type \"Cloud Architecture\" --filename \"CLOUD_Test.md\" \\\n  --score 7.8 --status \"In Review\" --completeness 78\n\n# Verify manifest was updated\ncat compliance-docs/COMPLIANCE_MANIFEST.md\n\n# Test regeneration (same contract type)\nbun utils/manifest-generator.ts --mode update --project \"Test Project\" \\\n  --contract-type \"Development Architecture\" --filename \"DEV_Test_v2.md\" \\\n  --score 9.2 --status \"Approved\" --completeness 95\n\n# Verify entry was replaced (not duplicated)\ncat compliance-docs/COMPLIANCE_MANIFEST.md\n```\n\n### Exported API\n\nFor programmatic use or testing:\n\n```typescript\nimport {\n  generateManifest,\n  parseExistingManifest,\n  mergeContracts,\n  calculateSummary,\n  type ContractMetadata,\n  type ManifestData\n} from './utils/manifest-generator.ts';\n\n// Example: Programmatic usage\nconst contractMetadata: ContractMetadata = {\n  contractType: \"Development Architecture\",\n  filename: \"DEV_Project_2025-12-14.md\",\n  score: 8.5,\n  status: \"Approved\",\n  completeness: 85,\n  generatedDate: \"2025-12-14\"\n};\n\nawait generateManifest(\n  '/path/to/compliance-docs',\n  contractMetadata,\n  'Project Name',\n  'create'\n);\n```\n\n### License\n\nPart of the Solutions Architect Skills plugin for Claude Code.\n\n**Last Updated**: 2025-12-14 (Added manifest-generator.ts)\n",
        "skills/architecture-compliance/validation/README.md": "# Compliance Template Validation System\n\n## Overview\n\nThis directory contains external validation configuration files for all 10 compliance contract templates. The validation system provides automated scoring (0-10 scale) to determine whether compliance contracts should be automatically approved, sent for manual review, require additional work, or be rejected.\n\n## Purpose\n\nThe external validation system separates validation logic from template content, providing:\n\n1. **Maintainability**: Validation rules are centralized and easier to update\n2. **Consistency**: All templates use the same validation methodology\n3. **Transparency**: Numeric scores (0-10) provide granular feedback\n4. **Automation**: Clear thresholds enable automatic approval for high-quality contracts\n5. **Extensibility**: Easy to add new validation items without modifying templates\n6. **Audit Trail**: Validation configs are versioned and traceable\n\n## Validation Configuration Files\n\nEach compliance template has a corresponding validation configuration file:\n\n| Template | Validation Config File |\n|----------|------------------------|\n| Development Architecture | `development_architecture_validation.json` |\n| Business Continuity | `business_continuity_validation.json` |\n| SRE Architecture | `sre_architecture_validation.json` |\n| Cloud Architecture | `cloud_architecture_validation.json` |\n| Security Architecture | `security_architecture_validation.json` |\n| Data & Analytics - AI | `data_analytics_ai_validation.json` |\n| Process Transformation | `process_transformation_validation.json` |\n| Platform & IT Infrastructure | `platform_it_infrastructure_validation.json` |\n| Enterprise Architecture | `enterprise_architecture_validation.json` |\n| Integration Architecture | `integration_architecture_validation.json` |\n\n## Validation Schema\n\nAll validation configuration files conform to `VALIDATION_SCHEMA.json`, which defines:\n\n- **Template metadata**: Name, ID, version, approval authority\n- **Scoring configuration**: Scale (0-10), thresholds, weights, status code mapping\n- **Validation sections**: Grouped validation items with weights\n- **Validation items**: Individual checks with questions, rules, and criteria\n- **Outcome mapping**: Score ranges mapped to approval actions\n- **Remediation guidance**: Help for addressing validation failures\n\n## Scoring System\n\n### Score Calculation\n\nThe final validation score (0-10) is calculated using a weighted formula:\n\n```\nFinal Score = (Completeness √ó W‚ÇÅ) + (Compliance √ó W‚ÇÇ) + (Quality √ó W‚ÇÉ)\n\nWhere:\n- Completeness = (Filled required data points / Total required data points) √ó 10\n- Compliance = (PASS items + N/A items + EXCEPTION items) / (Total applicable items) √ó 10\n- Quality = Source traceability score (0-10 based on line number coverage)\n- W‚ÇÅ, W‚ÇÇ, W‚ÇÉ = Template-specific weights (must sum to 1.0)\n\n**CRITICAL - N/A Items Calculation Example:**\n\nN/A items MUST be included in the compliance score numerator:\n\n```\nExample:\n- 6 PASS items, 5 N/A items, 0 FAIL items, 0 UNKNOWN items (11 total items)\n- Compliance = (6 PASS + 5 N/A + 0 EXCEPTION) / 11 √ó 10 = 11/11 √ó 10 = 10.0/10 (100%)\n- ‚úÖ Correct: N/A counted as fully compliant\n- ‚ùå Wrong: 6/11 √ó 10 = 6.0/10 (treating N/A as neutral)\n```\n```\n\n### Template-Specific Weights\n\n**Weights are template-specific** (defined in validation config JSON files):\n\n- Most templates use: Completeness 40%, Compliance 50%, Quality 10%\n- Security/SRE/Integration: Completeness 30%, Compliance 60%, Quality 10% (compliance-focused)\n- Business Continuity: Completeness 50%, Compliance 40%, Quality 10% (completeness-focused)\n- Cloud Architecture: Completeness 35%, Compliance 55%, Quality 10% (balanced)\n\nSee individual validation config files in `/validation/*_validation.json` for exact weights per template.\n\n### Template-Specific Weight Recommendations\n\n| Template | Completeness | Compliance | Quality | Rationale |\n|----------|--------------|------------|---------|-----------|\n| Development Architecture | 40% | 50% | 10% | Stack compliance critical, moderate documentation |\n| Security Architecture | 20% | 70% | 10% | Security controls non-negotiable |\n| SRE Architecture | 30% | 60% | 10% | Availability and reliability metrics paramount |\n| Cloud Architecture | 35% | 55% | 10% | Cloud provider compliance essential |\n| Data & Analytics - AI | 40% | 50% | 10% | Data governance and AI compliance equally important |\n| Business Continuity | 50% | 40% | 10% | Comprehensive recovery plans paramount |\n| Integration Architecture | 35% | 55% | 10% | Integration security and standards critical |\n| Enterprise Architecture | 45% | 45% | 10% | Strategic documentation and compliance balanced |\n| Platform & IT Infrastructure | 40% | 50% | 10% | Infrastructure standards and documentation critical |\n| Process Transformation | 50% | 40% | 10% | Detailed process documentation paramount |\n\n## Validation Status Codes\n\nEach validation item receives one of five status codes:\n\n| Status Code | Score | Meaning | Criteria |\n|-------------|-------|---------|----------|\n| **PASS** | 10 | Fully compliant | Item meets all validation criteria |\n| **FAIL** | 0 | Non-compliant | Item violates validation rules (deprecated version, unapproved technology) |\n| **N/A** | 10 | Not applicable | Item doesn't apply to this architecture (e.g., Java validation when using .NET) |\n| **UNKNOWN** | 0 | Missing data | Required data not found in ARCHITECTURE.md |\n| **EXCEPTION** | 10 | Approved deviation | Properly documented exception via LADES2 process (ADR + approval) |\n\n### Key Decisions\n\n- **UNKNOWN = 0**: Missing data is treated as a failure, forcing complete documentation\n- **EXCEPTION = 10**: Properly documented exceptions count as fully compliant (no penalty for approved deviations)\n\n## Outcome Tiers\n\nThe validation system maps final scores to four outcome tiers:\n\n| Score Range | Overall Status | Document Status | Action | Review Actor | Description |\n|-------------|----------------|-----------------|--------|--------------|-------------|\n| **8.0-10.0** | PASS | Approved | AUTO_APPROVE | System (Auto-Approved) | High confidence validation. Contract automatically approved without human review. |\n| **7.0-7.9** | PASS | In Review | MANUAL_REVIEW | [Approval Authority] | Validation passed with small gaps. Ready for human review by approval authority. |\n| **5.0-6.9** | CONDITIONAL | Draft | NEEDS_WORK | Architecture Team | Validation incomplete. Must address missing data or FAIL items before approval. |\n| **0.0-4.9** | FAIL | Rejected | REJECT | N/A (Blocked) | Critical failures or insufficient data. Cannot proceed to approval. |\n\n### Approval Gating\n\n- **Validation score ‚â• 7.0** is MANDATORY for approval pathway\n- **Score 8.0-10.0**: Automatic approval (no human review required)\n- **Score 7.0-7.9**: Manual review by approval authority required\n- **Score 5.0-6.9**: Must address gaps before proceeding to review\n- **Score < 5.0**: Contract rejected, cannot proceed\n\n## Validation Rules Types\n\nValidation configurations support several rule types:\n\n### 1. version_check\n\nValidates technology versions against approved and deprecated lists.\n\n```json\n{\n  \"type\": \"version_check\",\n  \"approved_versions\": [\"Java 11 LTS\", \"Java 17 LTS\", \"Java 21 LTS\"],\n  \"deprecated_versions\": [\"Java 8\"],\n  \"pass_criteria\": \"Version found in approved list\",\n  \"fail_criteria\": \"Deprecated version or unapproved version\",\n  \"na_criteria\": \"Java not used in architecture\",\n  \"unknown_criteria\": \"Version not specified in ARCHITECTURE.md\"\n}\n```\n\n### 2. presence_check\n\nValidates that required data is present in ARCHITECTURE.md.\n\n```json\n{\n  \"type\": \"presence_check\",\n  \"architecture_md_section\": \"9.3\",\n  \"required_format\": \"Duration (e.g., 4 hours, 24 hours)\",\n  \"pass_criteria\": \"RTO value specified with time unit\",\n  \"fail_criteria\": \"N/A (presence check cannot fail)\",\n  \"na_criteria\": \"Not applicable to this architecture\",\n  \"unknown_criteria\": \"RTO not specified in Section 9.3\"\n}\n```\n\n### 3. value_check\n\nValidates values against an approved list.\n\n```json\n{\n  \"type\": \"value_check\",\n  \"approved_values\": [\"AWS\", \"Azure\", \"Google Cloud Platform\"],\n  \"pass_criteria\": \"Cloud provider in approved list\",\n  \"fail_criteria\": \"Unapproved cloud provider\",\n  \"na_criteria\": \"On-premises infrastructure only\",\n  \"unknown_criteria\": \"Cloud provider not specified\"\n}\n```\n\n### 4. format_check\n\nValidates data format or structure.\n\n```json\n{\n  \"type\": \"format_check\",\n  \"required_format\": \"TLS 1.2 or TLS 1.3\",\n  \"pass_criteria\": \"TLS version is 1.2 or 1.3\",\n  \"fail_criteria\": \"TLS version is 1.0 or 1.1 (deprecated)\",\n  \"na_criteria\": \"No external TLS endpoints\",\n  \"unknown_criteria\": \"TLS version not specified\"\n}\n```\n\n### 5. custom\n\nCustom validation logic (defined in generation code).\n\n```json\n{\n  \"type\": \"custom\",\n  \"pass_criteria\": \"Custom condition met\",\n  \"fail_criteria\": \"Custom condition not met\",\n  \"na_criteria\": \"Custom check not applicable\",\n  \"unknown_criteria\": \"Insufficient data for custom check\"\n}\n```\n\n## Validation Process\n\nThe validation engine executes the following steps:\n\n1. **Load Configuration**: Read validation config JSON for target template\n2. **Extract Data**: Parse ARCHITECTURE.md and extract data points per validation items\n3. **Evaluate Items**: Apply validation rules to each item, assign status (PASS/FAIL/N/A/UNKNOWN/EXCEPTION)\n4. **Calculate Scores**:\n   - Item scores: Based on status code mapping (PASS=10, FAIL=0, N/A=10, UNKNOWN=0, EXCEPTION=10)\n   - Section scores: Weighted average of item scores within section\n   - Completeness: (Filled required fields / Total required fields) √ó 10\n   - Compliance: (PASS + N/A + EXCEPTION items / Total applicable items) √ó 10\n   - Quality: Source traceability coverage (0-10)\n   - Final score: (Completeness √ó W‚ÇÅ) + (Compliance √ó W‚ÇÇ) + (Quality √ó W‚ÇÉ)\n5. **Determine Outcome**: Map final score to tier (AUTO_APPROVE/MANUAL_REVIEW/NEEDS_WORK/REJECT)\n6. **Generate Results Object**: Create validation_results with score, status, breakdown, and recommendations\n7. **Populate Template**: Fill in Document Control fields and compliance summary based on results\n8. **Generate Manifest**: Create COMPLIANCE_MANIFEST.md summarizing:\n   - Validation framework reference (two-stage validation)\n   - Validation configuration details (schema, rule files)\n   - All generated contracts with validation scores\n   - Aggregate metrics and approval status\n\n## Validation Results Object\n\nThe validation engine produces a structured results object:\n\n```json\n{\n  \"validation_results\": {\n    \"final_score\": 8.7,\n    \"completeness_score\": 9.0,\n    \"compliance_score\": 9.5,\n    \"quality_score\": 6.0,\n    \"overall_status\": \"PASS\",\n    \"document_status\": \"Approved\",\n    \"action\": \"AUTO_APPROVE\",\n    \"validation_date\": \"2025-12-07\",\n    \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n    \"review_actor\": \"System (Auto-Approved)\",\n    \"sections\": {\n      \"stack_compliance\": {\n        \"score\": 9.5,\n        \"weight\": 0.4,\n        \"items\": {\n          \"java_version\": {\n            \"status\": \"PASS\",\n            \"score\": 10,\n            \"evidence\": \"Java 17 LTS - Section 8.1, line 952\",\n            \"line_numbers\": [952]\n          }\n        }\n      }\n    },\n    \"failures\": [],\n    \"unknowns\": [],\n    \"exceptions\": [],\n    \"remediation_recommendations\": []\n  }\n}\n```\n\n## Exception Handling\n\nProperly documented exceptions are treated as fully compliant (EXCEPTION = 10/10):\n\n### Requirements for EXCEPTION Status\n\n1. Deviation from technology stack documented in ARCHITECTURE.md Section 12 (ADR)\n2. Architecture Decision Record (ADR) includes:\n   - Business justification\n   - Technical rationale\n   - Alternatives considered\n   - Risk assessment\n   - Mitigation plan\n3. Exception approved by chapter/architecture review board\n4. Exception registered in compliance contract (LADES2 process)\n\n### Remediation Paths\n\n| Status | Remediation Action |\n|--------|-------------------|\n| **FAIL** | Option 1: Migrate to approved technology stack<br>Option 2: Register exception via LADES2 process |\n| **UNKNOWN** | Add missing data to ARCHITECTURE.md Section X.Y |\n| **Low Completeness** | Complete all required sections before submitting for approval |\n\n## Edge Cases\n\nThe validation system handles several edge cases:\n\n| Edge Case | Detection | Behavior | Outcome |\n|-----------|-----------|----------|---------|\n| Backend-Only Architecture | No frontend keywords | Frontend validation items ‚Üí N/A | PASS if backend compliant |\n| Full-Stack (Java + React) | Backend + frontend detected | Evaluate both stacks | PASS if all compliant |\n| Polyglot Backend (Java + .NET) | Multiple backend languages | Evaluate all backends separately | PASS only if both comply |\n| Section 8 Missing | Not found or <50 characters | Skip stack validation entirely | FAIL (critical data missing) |\n| Partial Section 8 | Missing versions/details | Mark items UNKNOWN | FAIL if score < 5.0 |\n| Deprecated Versions | Version comparison vs catalog | Mark deprecated as FAIL | FAIL until upgrade/exception |\n| Unapproved Technology | Not in authorized catalog | Mark unapproved as FAIL | FAIL until migration/exception |\n\n## Source Traceability\n\nAll extracted data must include source references:\n\n- **Format**: \"Section X.Y, line Z\" or \"Sections X-Y, lines A-B\"\n- **Requirement**: Every data point in compliance contract must trace to ARCHITECTURE.md\n- **Quality Score**: Based on percentage of data points with line number references\n- **Placeholder Convention**:\n  ```markdown\n  **[Field Name]**: [PLACEHOLDER: Not specified in ARCHITECTURE.md Section X.Y]\n  Note: Add [specific data] to ARCHITECTURE.md Section X.Y\n  ```\n\n## Updating Validation Configurations\n\nTo add or modify validation rules:\n\n1. Edit the appropriate `*_validation.json` file\n2. Ensure changes conform to `VALIDATION_SCHEMA.json`\n3. Validate JSON syntax and schema compliance\n4. Update version number in validation config (semantic versioning)\n5. Document changes in version control commit message\n6. Test validation with sample ARCHITECTURE.md files\n\n### Schema Validation\n\nValidate configuration files against the schema:\n\n```bash\n# Using a JSON schema validator tool\njsonschema -i development_architecture_validation.json VALIDATION_SCHEMA.json\n```\n\n## Version History\n\n- **1.0.0** (2025-12-07): Initial release\n  - Externalized validation from templates\n  - Standardized 0-10 scoring system\n  - Four-tier outcome mapping (AUTO_APPROVE, MANUAL_REVIEW, NEEDS_WORK, REJECT)\n  - Template-specific weight configurations\n  - UNKNOWN = 0, EXCEPTION = 10 scoring decisions\n\n## References\n\n- **VALIDATION_SCHEMA.json**: JSON schema defining validation configuration structure\n- **COMPLIANCE_GENERATION_GUIDE.md**: Step-by-step guide for generating compliance contracts with validation\n- **STACK_VALIDATION_CHECKLIST.md**: 26-item checklist for Development Architecture validation\n- **Templates**: 10 compliance contract templates in `/skills/architecture-compliance/templates/`\n\n## Support\n\nFor questions or issues with the validation system:\n\n1. Review this README and VALIDATION_SCHEMA.json\n2. Check existing validation configuration files for examples\n3. Consult COMPLIANCE_GENERATION_GUIDE.md for generation workflow\n4. Review template Document Control sections for validation field instructions\n",
        "skills/architecture-compliance/validation/VALIDATION_EXAMPLES.md": "# Validation Outcome Examples\n\nThis document provides example scenarios for each of the 4 validation outcome tiers. These examples illustrate how the validation system scores compliance documents and determines approval status.\n\n---\n\n## Tier 1: AUTO_APPROVE (Score 8.0-10.0)\n\n### Example: Development Architecture - Perfect Compliance\n\n**Scenario**: A Development Architecture contract with comprehensive ARCHITECTURE.md documentation and full stack compliance.\n\n**Validation Results**:\n```json\n{\n  \"final_score\": 9.7,\n  \"outcome\": {\n    \"overall_status\": \"PASS\",\n    \"document_status\": \"Approved\",\n    \"review_actor\": \"System (Auto-Approved)\",\n    \"action\": \"AUTO_APPROVE\",\n    \"message\": \"High confidence validation. Contract automatically approved.\"\n  },\n  \"validation_date\": \"2025-12-07\",\n  \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n  \"scores\": {\n    \"completeness\": 9.5,\n    \"compliance\": 10.0,\n    \"quality\": 9.0\n  }\n}\n```\n\n**Score Breakdown**:\n- **Completeness (9.5/10)**: 19 of 20 required data points present in ARCHITECTURE.md (95%)\n- **Compliance (10.0/10)**: 25 PASS, 1 N/A, 0 FAIL, 0 UNKNOWN out of 26 items\n  - Calculation: (25 PASS + 1 N/A) / 26 = 26/26 = 10.0/10 (N/A counted as fully compliant)\n- **Quality (9.0/10)**: All data points have source traceability with section and line numbers\n\n**Final Calculation**:\n```\nFinal Score = (9.5 √ó 0.4) + (10.0 √ó 0.5) + (9.0 √ó 0.1)\n            = 3.8 + 5.0 + 0.9\n            = 9.7/10\n```\n\n**Document Control Output**:\n```markdown\n| Status | Approved |\n| Validation Score | 9.7/10 |\n| Validation Status | PASS |\n| Validation Date | 2025-12-07 |\n| Validation Evaluator | Claude Code (Automated Validation Engine) |\n| Review Actor | System (Auto-Approved) |\n| Approval Authority | Technical Architecture Review Board |\n```\n\n**Outcome**: Contract is automatically approved without human review. Ready for implementation.\n\n---\n\n### Example: Cloud Architecture - Custom Weights (35%/55%/10%)\n\n**Scenario**: A Cloud Architecture contract demonstrating template-specific weights that emphasize compliance over completeness.\n\n**Validation Results**:\n```json\n{\n  \"final_score\": 8.9,\n  \"outcome\": {\n    \"overall_status\": \"PASS\",\n    \"document_status\": \"Approved\",\n    \"review_actor\": \"System (Auto-Approved)\",\n    \"action\": \"AUTO_APPROVE\",\n    \"message\": \"High confidence validation. Contract automatically approved.\"\n  },\n  \"validation_date\": \"2025-12-13\",\n  \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n  \"scores\": {\n    \"completeness\": 9.3,\n    \"compliance\": 8.6,\n    \"quality\": 9.0\n  },\n  \"weights\": {\n    \"completeness\": 0.35,\n    \"compliance\": 0.55,\n    \"quality\": 0.10\n  }\n}\n```\n\n**Score Breakdown**:\n- **Completeness (9.3/10)**: 26 of 28 required data points present in ARCHITECTURE.md (93%)\n  - Missing: Cost tracking/monitoring strategy, Cost optimization strategies\n- **Compliance (8.6/10)**: 22 PASS, 2 N/A, 2 FAIL, 2 UNKNOWN out of 28 items\n  - Calculation: (22 PASS + 2 N/A) / 28 = 24/28 √ó 10 = 8.57 ‚âà 8.6/10\n  - Non-Compliant: Cost tracking not documented, Cost optimization strategies missing\n  - Unknown: Well-Architected Framework mapping incomplete, Organizational cloud standards need validation\n- **Quality (9.0/10)**: Excellent source traceability with section and line numbers for all data points\n\n**Final Calculation with Cloud-Specific Weights**:\n```\nWeights from cloud_architecture_validation.json:\n- W_completeness = 0.35 (35%)\n- W_compliance = 0.55 (55%) [higher emphasis on compliance]\n- W_quality = 0.10 (10%)\n\nFinal Score = (Completeness √ó W_completeness) + (Compliance √ó W_compliance) + (Quality √ó W_quality)\n            = (9.3 √ó 0.35) + (8.6 √ó 0.55) + (9.0 √ó 0.10)\n            = 3.255 + 4.73 + 0.9\n            = 8.885\n            = 8.9/10 (rounded to 1 decimal)\n```\n\n**Key Insight**: Despite having 2 non-compliant items and slightly lower completeness than the Development Architecture example (9.3 vs 9.5), this Cloud Architecture contract still achieves a high score (8.9) because:\n1. The compliance weight is higher (55% vs 50%)\n2. The compliance score is strong (8.6/10 with 79% compliant items)\n3. Cloud Architecture prioritizes compliance adherence over documentation completeness\n\n**Document Control Output**:\n```markdown\n| Status | Approved |\n| Validation Score | 8.9/10 |\n| Validation Status | PASS |\n| Validation Date | 2025-12-13 |\n| Validation Evaluator | Claude Code (Automated Validation Engine) |\n| Review Actor | System (Auto-Approved) |\n| Approval Authority | Cloud Architecture Review Board |\n```\n\n**Outcome**: Contract is automatically approved without human review. Ready for implementation.\n\n**Threshold Analysis**:\n- Score 8.9 falls in 8.0-10.0 range ‚Üí AUTO_APPROVE (‚úì)\n- If score were 7.9 ‚Üí Would require MANUAL_REVIEW\n- If score were 8.0 exactly ‚Üí AUTO_APPROVE (inclusive lower bound)\n\n---\n\n## Tier 2: MANUAL_REVIEW (Score 7.0-7.9)\n\n### Example: SRE Architecture - Good Compliance with Minor Gaps\n\n**Scenario**: An SRE Architecture contract with solid ARCHITECTURE.md documentation but missing a few optional monitoring details.\n\n**Validation Results**:\n```json\n{\n  \"final_score\": 7.8,\n  \"outcome\": {\n    \"overall_status\": \"PASS\",\n    \"document_status\": \"In Review\",\n    \"review_actor\": \"SRE Leadership/Operations\",\n    \"action\": \"MANUAL_REVIEW\",\n    \"message\": \"Validation passed with small gaps. Ready for human review.\"\n  },\n  \"validation_date\": \"2025-12-07\",\n  \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n  \"scores\": {\n    \"completeness\": 8.0,\n    \"compliance\": 7.5,\n    \"quality\": 8.0\n  }\n}\n```\n\n**Score Breakdown**:\n- **Completeness (8.0/10)**: 16 of 20 required data points present (80%)\n  - Missing: Error budget calculation, On-call rotation schedule, Incident escalation matrix, Runbook repository\n- **Compliance (7.5/10)**: 12 PASS, 3 N/A, 0 FAIL, 1 UNKNOWN out of 16 items\n  - UNKNOWN: Monitoring dashboard URL not specified\n- **Quality (8.0/10)**: Most data points have source traceability, a few missing line numbers\n\n**Final Calculation**:\n```\nFinal Score = (8.0 √ó 0.4) + (7.5 √ó 0.5) + (8.0 √ó 0.1)\n            = 3.2 + 3.75 + 0.85\n            = 7.8/10\n```\n\n**Document Control Output**:\n```markdown\n| Status | In Review |\n| Validation Score | 7.8/10 |\n| Validation Status | PASS |\n| Validation Date | 2025-12-07 |\n| Validation Evaluator | Claude Code (Automated Validation Engine) |\n| Review Actor | SRE Leadership/Operations |\n| Approval Authority | SRE Leadership/Operations |\n```\n\n**Outcome**: Contract validation passed, but requires manual review by SRE Leadership. Small gaps are acceptable pending human review and approval.\n\n**Recommendations**:\n1. Add missing error budget calculation to ARCHITECTURE.md Section 10.2\n2. Define on-call rotation in Section 11.2\n3. Specify monitoring dashboard URL in Section 11.1\n4. Document incident escalation matrix in Section 11.2\n\n---\n\n## Tier 3: NEEDS_WORK (Score 5.0-6.9)\n\n### Example: Security Architecture - Incomplete Documentation\n\n**Scenario**: A Security Architecture contract with significant gaps in ARCHITECTURE.md Section 9 (Security & Compliance).\n\n**Validation Results**:\n```json\n{\n  \"final_score\": 6.2,\n  \"outcome\": {\n    \"overall_status\": \"CONDITIONAL\",\n    \"document_status\": \"Draft\",\n    \"review_actor\": \"Architecture Team\",\n    \"action\": \"NEEDS_WORK\",\n    \"message\": \"Validation incomplete. Address missing data before approval.\",\n    \"blockers\": [\n      \"Must resolve UNKNOWN items\",\n      \"Must address FAIL items or register exceptions\"\n    ]\n  },\n  \"validation_date\": \"2025-12-07\",\n  \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n  \"scores\": {\n    \"completeness\": 6.0,\n    \"compliance\": 6.5,\n    \"quality\": 6.0\n  }\n}\n```\n\n**Score Breakdown**:\n- **Completeness (6.0/10)**: 12 of 20 required data points present (60%)\n  - Missing: Authentication method, Authorization model, Encryption standards (data at rest), Key rotation policy, Security monitoring tools, Compliance certifications, Vulnerability scanning frequency, Security incident response plan\n- **Compliance (6.5/10)**: 8 PASS, 5 N/A, 1 FAIL, 6 UNKNOWN out of 20 items\n  - Calculation: (8 PASS + 5 N/A) / 20 = 13/20 = 6.5/10 (N/A counted as fully compliant)\n  - FAIL: Using deprecated TLS 1.1 for legacy systems\n  - UNKNOWN: No OAuth 2.0 configuration documented, no encryption key management details, no security audit logs defined, no penetration testing schedule, no data classification policy, no access control matrix\n- **Quality (6.0/10)**: Some source references missing or incomplete\n\n**Final Calculation**:\n```\nFinal Score = (6.0 √ó 0.4) + (6.5 √ó 0.5) + (6.0 √ó 0.1)\n            = 2.4 + 3.25 + 0.6\n            = 6.2/10\n```\n\n**Document Control Output**:\n```markdown\n| Status | Draft |\n| Validation Score | 6.2/10 |\n| Validation Status | CONDITIONAL |\n| Validation Date | 2025-12-07 |\n| Validation Evaluator | Claude Code (Automated Validation Engine) |\n| Review Actor | Architecture Team |\n| Approval Authority | Security Review Board |\n```\n\n**Outcome**: Contract cannot proceed to review. Architecture team must address missing data and compliance failures before resubmission.\n\n**Critical Actions Required**:\n1. **Address FAIL Items**:\n   - Upgrade TLS 1.1 to TLS 1.2+ or register exception via LADES2\n\n2. **Resolve UNKNOWN Items** (add to ARCHITECTURE.md Section 9):\n   - OAuth 2.0 configuration (flows, scopes, client types)\n   - Encryption key management (KMS, rotation policy)\n   - Security audit logs (tools, retention, alerts)\n   - Penetration testing schedule (frequency, scope)\n   - Data classification policy (levels, handling requirements)\n   - Access control matrix (roles, permissions)\n\n3. **Improve Documentation Quality**:\n   - Add section and line number references for all data points\n   - Ensure all security controls are documented with evidence\n\n**Next Steps**: Update ARCHITECTURE.md Section 9, then regenerate Security Architecture contract for re-validation.\n\n---\n\n## Tier 4: REJECT (Score 0.0-4.9)\n\n### Example: Cloud Architecture - Insufficient Data\n\n**Scenario**: A Cloud Architecture contract generated from minimal ARCHITECTURE.md with almost no Section 4 (Cloud & Deployment) content.\n\n**Validation Results**:\n```json\n{\n  \"final_score\": 3.5,\n  \"outcome\": {\n    \"overall_status\": \"FAIL\",\n    \"document_status\": \"Rejected\",\n    \"review_actor\": \"N/A (Blocked)\",\n    \"action\": \"REJECT\",\n    \"message\": \"Insufficient information or critical compliance failures. Cannot proceed.\",\n    \"blockers\": [\n      \"Critical data missing\",\n      \"Non-compliant technology stack\",\n      \"No exception documentation\"\n    ]\n  },\n  \"validation_date\": \"2025-12-07\",\n  \"validation_evaluator\": \"Claude Code (Automated Validation Engine)\",\n  \"scores\": {\n    \"completeness\": 2.5,\n    \"compliance\": 4.0,\n    \"quality\": 3.0\n  }\n}\n```\n\n**Score Breakdown**:\n- **Completeness (2.5/10)**: 5 of 20 required data points present (25%)\n  - Missing: Cloud provider, Regions/AZs, Deployment model, Infrastructure as Code tools, Container orchestration, Service mesh, Auto-scaling policies, Cost optimization strategy, Cloud security controls, Disaster recovery setup, Multi-region strategy, Cloud monitoring, Resource tagging, IAM policies, Network architecture\n- **Compliance (4.0/10)**: 3 PASS, 2 N/A, 2 FAIL, 13 UNKNOWN out of 20 items\n  - FAIL: Using non-approved cloud region (single-AZ deployment for production)\n  - FAIL: No Infrastructure as Code - manual provisioning detected\n  - UNKNOWN: 13 critical cloud best practices not documented\n- **Quality (3.0/10)**: Minimal source references, poor traceability\n\n**Final Calculation**:\n```\nFinal Score = (2.5 √ó 0.4) + (4.0 √ó 0.5) + (3.0 √ó 0.1)\n            = 1.0 + 2.0 + 0.3\n            = 3.5/10\n```\n\n**Document Control Output**:\n```markdown\n| Status | Rejected |\n| Validation Score | 3.5/10 |\n| Validation Status | FAIL |\n| Validation Date | 2025-12-07 |\n| Validation Evaluator | Claude Code (Automated Validation Engine) |\n| Review Actor | N/A (Blocked) |\n| Approval Authority | Cloud Architecture Review Board |\n```\n\n**Outcome**: Contract is rejected. Cannot proceed to any review. ARCHITECTURE.md Section 4 is critically incomplete.\n\n**Critical Blockers**:\n1. **Insufficient Documentation**: Only 25% of required cloud architecture information is documented\n2. **Non-Compliant Deployment**: Single-AZ production deployment violates high-availability requirements\n3. **Missing IaC**: Manual infrastructure provisioning is not acceptable for production environments\n\n**Required Actions**:\n1. **Complete ARCHITECTURE.md Section 4** with all required cloud architecture details:\n   - Cloud provider selection and justification\n   - Multi-AZ/multi-region deployment architecture\n   - Infrastructure as Code tooling (Terraform, CloudFormation, etc.)\n   - Container orchestration platform (EKS, AKS, GKE)\n   - Auto-scaling policies and thresholds\n   - Cloud security controls and IAM policies\n   - Disaster recovery and backup strategy\n   - Cost optimization and resource tagging strategy\n   - Network architecture (VPC, subnets, routing)\n   - Monitoring and observability setup\n\n2. **Address Critical Compliance Failures**:\n   - Implement multi-AZ deployment or register exception with business justification\n   - Implement Infrastructure as Code for all infrastructure provisioning\n   - Document exception process if deviations are required\n\n3. **Do Not Proceed Until Score ‚â• 5.0**: This contract cannot be reviewed or approved until fundamental cloud architecture requirements are documented.\n\n**Next Steps**:\n1. Work with cloud architecture team to complete ARCHITECTURE.md Section 4\n2. Implement multi-AZ deployment design\n3. Adopt Infrastructure as Code tooling\n4. Regenerate Cloud Architecture contract after documentation is complete\n\n---\n\n## Format Validation Rules (BLOCKING)\n\nThe validation system includes BLOCKING format rules that enforce template structure preservation. These rules prevent contracts from being generated if they violate mandatory formatting requirements.\n\n### Rule 1: Forbidden Section Numbering\n\n**Validation Rule**: `forbidden_section_numbering`\n**Severity**: BLOCKING\n**Purpose**: Prevent sections after A.4 from being incorrectly numbered as A.5, A.6, A.7, A.8, A.9\n\n**Context**:\n- Templates have formal appendix sections A.1 through A.4 (H3 headers with numbering)\n- After A.4, templates use `@include` directives that expand to plain H2 headers WITHOUT numbering\n- The `resolve-includes.ts` utility expands these to `## Section Name` format\n- LLMs must preserve this H2 format and NOT add section numbers\n\n**WRONG Format (BLOCKED)**:\n```markdown\n### A.4 Change History\n...\n\n---\n\n### A.5 Data Extracted Successfully\n[Content]\n\n---\n\n### A.6 Missing Data Requiring Attention\n[Content]\n\n---\n\n### A.7 Not Applicable Items\n[Content]\n\n---\n\n### A.8 Unknown Status Items Requiring Investigation\n[Content]\n\n---\n\n### A.9 Generation Metadata\n[Content]\n```\n\n**Error Message**:\n```\nSections after A.4 must be H2 headers WITHOUT numbering. Found: ### A.5.\nCorrect format: '## Section Name' (not '### A.X Section Name')\n```\n\n**CORRECT Format (PASS)**:\n```markdown\n### A.4 Change History\n...\n\n---\n\n## Data Extracted Successfully\n[Content]\n\n---\n\n## Missing Data Requiring Attention\n[Content]\n\n---\n\n## Not Applicable Items\n[Content]\n\n---\n\n## Unknown Status Items Requiring Investigation\n[Content]\n\n---\n\n## Generation Metadata\n[Content]\n```\n\n**Impact**: Prevents template hierarchy violations and ensures consistent markdown structure across all 10 compliance contract types.\n\n---\n\n### Rule 2: Document Control Table Structure\n\n**Validation Rule**: `document_control_table`\n**Severity**: BLOCKING\n**Purpose**: Enforce markdown table format for Document Control section\n\n**Context**:\n- The Document Control section (from `shared/sections/document-control.md`) uses a table format\n- Table structure is `| Field | Value |` with proper markdown table syntax\n- LLMs must preserve this table format and NOT transform it to bold field lists\n\n**WRONG Format (BLOCKED)**:\n```markdown\n## Document Control\n\n**Document ID**: CLOUD_ARCHITECTURE_TaskSchedulingSystem_2025-12-14\n**Template Version**: 2.0\n**Validation Framework Version**: 1.0.0\n**Approval Authority**: Cloud Architecture Review Board\n\n**Lifecycle Status**: In Review\n**Overall Validation Score**: 8.3/10 (AUTO_APPROVE)\n\n**Document Status**:\n- **Overall Status**: PASS\n- **Action Required**: AUTO_APPROVE\n- **Review Actor**: System (Auto-Approved)\n- **Message**: High confidence validation. Contract automatically approved.\n```\n\n**Error Message**:\n```\nDocument Control section must use table format with | Field | Value | structure.\nFound list format instead of table.\n```\n\n**CORRECT Format (PASS)**:\n```markdown\n## Document Control\n\n| Field | Value |\n|-------|-------|\n| Document Owner | Solution Architect |\n| Last Review Date | 2025-12-14 |\n| Next Review Date | 2026-12-14 |\n| Status | Approved |\n| Validation Score | 8.3/10 |\n| Validation Status | AUTO_APPROVE |\n| Validation Date | 2025-12-14 |\n| Validation Evaluator | ComplianceValidator v1.0 |\n| Review Actor | System (Auto-Approved) |\n| Approval Authority | Cloud Architecture Review Board |\n\n**Validation Configuration**: `/skills/architecture-compliance/validation/cloud_architecture_validation.json`\n```\n\n**Required Fields** (validated):\n- Document Owner\n- Last Review Date\n- Status\n- Validation Score\n- Approval Authority\n\n**Impact**: Ensures Document Control data is structured, parseable, and audit-compliant. Table format enables automated extraction and validation tracking.\n\n---\n\n**Format Validation Summary**:\n\n| Rule | Purpose | Forbidden Pattern | Required Format | Severity |\n|------|---------|-------------------|----------------|----------|\n| `forbidden_section_numbering` | Block A.5+ numbering | `### A.5`, `### A.6`, etc. | `## Section Name` (H2) | BLOCKING |\n| `document_control_table` | Enforce table structure | Bold field lists (`**Field**: Value`) | `\\| Field \\| Value \\|` table | BLOCKING |\n\n**Files Affected**: All 10 compliance contract validation files\n- `template_validation_cloud_architecture.json`\n- `template_validation_development_architecture.json`\n- `template_validation_sre_architecture.json`\n- `template_validation_business_continuity.json`\n- `template_validation_data_ai_architecture.json`\n- `template_validation_security_architecture.json`\n- `template_validation_integration_architecture.json`\n- `template_validation_enterprise_architecture.json`\n- `template_validation_platform_it_infrastructure.json`\n- `template_validation_process_transformation.json`\n\n---\n\n## Summary Comparison\n\n| Tier | Score Range | Status | Review Actor | Example | Key Characteristics |\n|------|-------------|--------|--------------|---------|---------------------|\n| **Tier 1** | 8.0-10.0 | Approved | System (Auto-Approved) | Development Architecture (9.2/10) | Perfect/near-perfect compliance, comprehensive documentation, automatic approval |\n| **Tier 2** | 7.0-7.9 | In Review | Approval Authority | SRE Architecture (7.8/10) | Good compliance, minor gaps, requires manual review |\n| **Tier 3** | 5.0-6.9 | Draft | Architecture Team | Security Architecture (6.2/10) | Incomplete documentation, must address gaps before review |\n| **Tier 4** | 0.0-4.9 | Rejected | N/A (Blocked) | Cloud Architecture (3.5/10) | Critical failures, insufficient data, cannot proceed |\n\n---\n\n## How to Improve Your Score\n\n### From REJECT (0-4.9) to NEEDS_WORK (5.0-6.9)\n- Focus on **Completeness**: Document all required sections in ARCHITECTURE.md\n- Address **Critical FAIL items**: Fix non-compliant technologies or register exceptions\n- Achieve at least 50% completeness and resolve critical blockers\n\n### From NEEDS_WORK (5.0-6.9) to MANUAL_REVIEW (7.0-7.9)\n- Resolve **UNKNOWN items**: Add missing data to ARCHITECTURE.md\n- Reduce **FAIL items**: Upgrade deprecated technologies or document exceptions\n- Improve **Quality**: Add source traceability (section and line numbers)\n- Target 70-80% completeness and minimize UNKNOWN/FAIL items\n\n### From MANUAL_REVIEW (7.0-7.9) to AUTO_APPROVE (8.0-10.0)\n- Achieve **95%+ completeness**: Fill remaining data gaps\n- Resolve **all UNKNOWN items**: Ensure all required data is documented\n- Perfect **Quality**: Full source traceability for all data points\n- Address any remaining minor FAIL items with exceptions or upgrades\n\n---\n\n## Remediation Workflow Example\n\n### Scenario: Cloud Architecture - Gap Remediation to AUTO_APPROVE\n\n**Initial State**: Cloud Architecture contract with score 6.8/10 (NEEDS_WORK tier) due to 5 UNKNOWN items.\n\n**Before Remediation**:\n```json\n{\n  \"final_score\": 6.8,\n  \"outcome\": {\n    \"overall_status\": \"CONDITIONAL\",\n    \"document_status\": \"Draft\",\n    \"review_actor\": \"Architecture Team\",\n    \"action\": \"NEEDS_WORK\",\n    \"message\": \"Validation incomplete. Address missing data before approval.\"\n  },\n  \"scores\": {\n    \"completeness\": 7.5,\n    \"compliance\": 6.4,\n    \"quality\": 8.0\n  },\n  \"weights\": {\n    \"completeness\": 0.35,\n    \"compliance\": 0.55,\n    \"quality\": 0.10\n  },\n  \"gaps\": [\n    \"LAC4: Missing cost monitoring configuration - Section 11\",\n    \"LAC3: No resource tagging strategy - Section 4\",\n    \"LAC6: Infrastructure as Code not documented - Section 11\",\n    \"LAC2: Multi-region strategy undefined - Section 4\",\n    \"LAC5: Backup/recovery policies missing - Section 11\"\n  ]\n}\n```\n\n**Calculation (Before)**:\n```\nFinal Score = (7.5 √ó 0.35) + (6.4 √ó 0.55) + (8.0 √ó 0.10)\n            = 2.625 + 3.52 + 0.8\n            = 6.945\n            = 6.8/10 (rounded)\n```\n\n---\n\n**Remediation Steps** (following Section A.3.2 workflow):\n\n**Step 1: Activate architecture-docs skill**\n```\n/skill architecture-docs\n```\n\n**Step 2: Remediate highest-impact gap (LAC2 - Multi-region)**\n```\n\"Add multi-region deployment to Section 4:\n primary us-east-1, secondary us-west-2, RTO 15 minutes,\n automated failover with Route 53\"\n```\n- **Result**: Section 4 updated with multi-region strategy\n- **Impact**: LAC2 UNKNOWN ‚Üí PASS (+0.4 compliance points)\n\n**Step 3: Remediate LAC4 (Cost monitoring)**\n```\n\"Add cost monitoring to Section 11: CloudWatch billing alarms,\n 80% budget threshold, monthly cost reviews\"\n```\n- **Result**: Section 11 updated with cost monitoring config\n- **Impact**: LAC4 UNKNOWN ‚Üí PASS (+0.5 compliance points)\n\n**Step 4: Remediate LAC6 (Infrastructure as Code)**\n```\n\"Add Infrastructure as Code strategy to Section 11:\n Terraform for infrastructure provisioning,\n GitOps workflow with Terraform Cloud,\n state management in S3 with DynamoDB locking\"\n```\n- **Result**: Section 11 updated with IaC strategy\n- **Impact**: LAC6 UNKNOWN ‚Üí PASS (+0.4 compliance points)\n\n**Step 5: Remediate LAC3 (Resource tagging)**\n```\n\"Add resource tagging strategy to Section 4:\n required tags (environment, application, cost-center, owner),\n tag governance policy, automation via IaC\"\n```\n- **Result**: Section 4 updated with tagging strategy\n- **Impact**: LAC3 UNKNOWN ‚Üí PASS (+0.3 compliance points)\n\n**Step 6: Remediate LAC5 (Backup/recovery)**\n```\n\"Add backup strategy to Section 11:\n daily full backup, incremental every 6 hours,\n 30-day retention, S3 cross-region replication,\n monthly restore validation\"\n```\n- **Result**: Section 11 updated with backup policies\n- **Impact**: LAC5 UNKNOWN ‚Üí PASS (+0.4 compliance points)\n\n---\n\n**After Remediation**:\n```json\n{\n  \"final_score\": 8.9,\n  \"outcome\": {\n    \"overall_status\": \"PASS\",\n    \"document_status\": \"Approved\",\n    \"review_actor\": \"System (Auto-Approved)\",\n    \"action\": \"AUTO_APPROVE\",\n    \"message\": \"High confidence validation. Contract automatically approved.\"\n  },\n  \"scores\": {\n    \"completeness\": 9.3,\n    \"compliance\": 8.6,\n    \"quality\": 9.0\n  },\n  \"weights\": {\n    \"completeness\": 0.35,\n    \"compliance\": 0.55,\n    \"quality\": 0.10\n  },\n  \"gaps\": []\n}\n```\n\n**Calculation (After)**:\n```\nFinal Score = (9.3 √ó 0.35) + (8.6 √ó 0.55) + (9.0 √ó 0.10)\n            = 3.255 + 4.73 + 0.9\n            = 8.885\n            = 8.9/10 (rounded)\n```\n\n---\n\n**Impact Analysis**:\n\n| Metric | Before | After | Change |\n|--------|--------|-------|--------|\n| **Completeness** | 7.5 | 9.3 | +1.8 (+24%) |\n| **Compliance** | 6.4 | 8.6 | +2.2 (+34%) |\n| **Quality** | 8.0 | 9.0 | +1.0 (+13%) |\n| **Final Score** | 6.8 | 8.9 | +2.1 (+31%) |\n| **Document Status** | Draft | Approved | ‚úÖ |\n| **Action** | NEEDS_WORK | AUTO_APPROVE | ‚úÖ |\n\n**Key Success Factors**:\n1. **Prioritized by impact**: Addressed highest-impact gaps first (LAC2, LAC4, LAC6)\n2. **Used architecture-docs skill**: Skill ensured correct section placement and formatting\n3. **Complete documentation**: All gaps resolved, no partial fixes\n4. **Source traceability improved**: Skill added section/line references, boosting quality score\n5. **Time efficient**: Total remediation time ~35 minutes (vs 2-3 hours manual)\n\n**Outcome**: Contract progressed from NEEDS_WORK (Tier 3) ‚Üí AUTO_APPROVE (Tier 1), bypassing manual review entirely.\n\n---\n\n## Validation Best Practices\n\n1. **Start with ARCHITECTURE.md completeness**: The more complete your ARCHITECTURE.md, the higher your validation score\n2. **Use source traceability**: Always cite section and line numbers for auditable documentation\n3. **Document exceptions properly**: Use LADES2 process for approved deviations (counts as PASS)\n4. **Address UNKNOWN items first**: Missing data scores 0 points - add it to ARCHITECTURE.md\n5. **Fix FAIL items strategically**: Upgrade deprecated tech or register exceptions\n6. **Aim for Tier 2 minimum**: Score ‚â• 7.0 opens the approval pathway\n7. **Strive for Tier 1**: Score ‚â• 8.0 enables automatic approval and faster delivery\n\n---\n\n**Generated**: 2025-12-07\n**Version**: 1.0\n**See Also**:\n- `/skills/architecture-compliance/validation/README.md` - Validation system overview\n- `/skills/architecture-compliance/validation/VALIDATION_SCHEMA.json` - Validation config schema\n- `/skills/architecture-compliance/COMPLIANCE_GENERATION_GUIDE.md` - Full generation guide\n",
        "skills/architecture-compliance/validation/VALIDATION_RULE_EXAMPLES.md": "# Compliance Template Validation - Examples\n\nThis document provides examples of valid and invalid patterns for each validation area, along with explanations of why they pass or fail validation.\n\n## Table of Contents\n\n1. [Compliance Summary Table](#1-compliance-summary-table)\n2. [Status Value Standardization](#2-status-value-standardization)\n3. [Appendix A.1-A.4 Structure](#3-appendix-a1-a4-structure)\n4. [Compliance Calculations](#4-compliance-calculations)\n5. [Template Completeness](#5-template-completeness)\n6. [Special Cases](#6-special-cases)\n\n---\n\n## 1. Compliance Summary Table\n\n### ‚úÖ VALID: 6-Column Table\n\n```markdown\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LASRE01 | Structured logging | Practice - Log Management | Compliant | Section 11.1 | SRE Team |\n| LASRE02 | Centralized logging | Practice - Log Management | Non-Compliant | Not documented | SRE Team |\n| LASRE03 | Log retention policy | Practice - Log Management | Not Applicable | N/A | N/A |\n```\n\n**Why it passes:**\n- Exactly 6 columns in correct order\n- Valid Code format (LASRE01, LASRE02, etc.)\n- Valid Status values (Compliant, Non-Compliant, Not Applicable)\n- Proper markdown syntax\n\n### ‚ùå INVALID: 5-Column Table\n\n```markdown\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section |\n|------|-------------|----------|--------|----------------|\n| LASRE01 | Structured logging | Practice | Compliant | Section 11.1 |\n```\n\n**Why it fails:**\n- Only 5 columns (missing \"Responsible Role\")\n- Will trigger: `INVALID_TABLE_COLUMNS` error\n- **Fix**: Add \"Responsible Role\" column\n\n**Error Example:**\n```\nERROR: Invalid Table Columns (Line 42)\nExpected: 6 columns: Code | Requirement | Category | Status | Source Section | Responsible Role\nFound: 5 columns\nFix: Ensure table has exactly 6 columns in this order\n```\n\n### ‚ùå INVALID: Wrong Column Order\n\n```markdown\n## Compliance Summary\n\n| Code | Category | Requirement | Status | Source Section | Responsible Role |\n|------|----------|-------------|--------|----------------|------------------|\n| LASRE01 | Practice | Structured logging | Compliant | Section 11.1 | SRE Team |\n```\n\n**Why it fails:**\n- Columns 2 and 3 are swapped\n- Will trigger: `INVALID_COLUMN_NAME` error\n- **Fix**: Reorder columns to: Code, Requirement, Category, Status, Source Section, Responsible Role\n\n### ‚ùå INVALID: Invalid Code Format\n\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| sre-01 | Structured logging | Practice | Compliant | Section 11.1 | SRE Team |\n```\n\n**Why it fails:**\n- Code uses lowercase and hyphen instead of uppercase letters + numbers\n- Expected pattern: `^[A-Z]+\\\\d+$` (e.g., LASRE01, LAC1)\n- Will trigger: `INVALID_CODE_FORMAT` error\n- **Fix**: Change \"sre-01\" to \"LASRE01\"\n\n---\n\n## 2. Status Value Standardization\n\n### ‚úÖ VALID: Exact Case Status Values\n\n**In Table:**\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LASRE01 | Test | Category | Compliant | Section 1 | Team |\n| LASRE02 | Test | Category | Non-Compliant | Not documented | Team |\n| LASRE03 | Test | Category | Not Applicable | N/A | N/A |\n| LASRE04 | Test | Category | Unknown | Section 2 | Team |\n```\n\n**In Requirement Sections:**\n```markdown\n## 1. Test Requirement\n\n**Status**: [Compliant]\n```\n\n**In Subsections:**\n```markdown\n- Status: Compliant\n```\n\n**Why it passes:**\n- Uses exact case for all four allowed values\n- Consistent across all locations\n\n### ‚ùå INVALID: Case Mismatch\n\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LASRE01 | Test | Category | compliant | Section 1 | Team |\n```\n\n**Why it fails:**\n- Uses lowercase \"compliant\" instead of \"Compliant\"\n- Will trigger: `INVALID_STATUS_VALUE` error\n- **Fix**: Change \"compliant\" to \"Compliant\" (exact case required)\n\n**Error Example:**\n```\nERROR: Invalid Status Value (Line 45)\nExpected: One of [\"Compliant\", \"Non-Compliant\", \"Not Applicable\", \"Unknown\"]\nFound: \"compliant\"\nFix: Change \"compliant\" to \"Compliant\"\n```\n\n### ‚ùå INVALID: Custom Status Value\n\n```markdown\n**Status**: [Pass]\n```\n\n**Why it fails:**\n- \"Pass\" is not one of the four allowed values\n- Will trigger: `INVALID_STATUS_VALUE` error\n- Suggestion: \"Did you mean 'Compliant'?\"\n- **Fix**: Change \"Pass\" to \"Compliant\"\n\n### ‚ùå INVALID: Abbreviated Status\n\n```markdown\n- Status: N/A\n```\n\n**Why it fails:**\n- \"N/A\" is not the exact status value\n- Will trigger: `INVALID_STATUS_VALUE` error\n- Suggestion: \"Did you mean 'Not Applicable'?\"\n- **Fix**: Change \"N/A\" to \"Not Applicable\"\n\n---\n\n## 3. Appendix A.1-A.4 Structure\n\n### ‚úÖ VALID: Complete Appendix Structure\n\n```markdown\n### A.1 Definitions and Terminology\n\n**Domain-Specific Terms**:\n- **Term 1**: Definition\n- **Term 2**: Definition\n\n**Status Codes**:\n- **Compliant**: Requirement fully satisfied\n- **Non-Compliant**: Requirement not met\n- **Not Applicable**: Requirement does not apply\n- **Unknown**: Partial information exists\n\n### A.2 Validation Methodology\n\n**Completeness Check (40% weight)**:\n...\n\n**Compliance Check (50% weight)**:\n...\n\n**Quality Check (10% weight)**:\n...\n\n### A.3 Document Completion Guide\n\n**How to Complete Missing Data**:\n...\n\n### A.4 Change History\n\n| Version | Date | Author | Changes |\n|---------|------|--------|---------|\n| 2.0 | 2024-01-01 | System | Initial version |\n```\n\n**Why it passes:**\n- All four appendices present (A.1, A.2, A.3, A.4)\n- Correct heading format (`### A.X`)\n- In correct order\n\n### ‚ùå INVALID: Missing A.2\n\n```markdown\n### A.1 Definitions and Terminology\n...\n\n### A.3 Document Completion Guide\n...\n\n### A.4 Change History\n...\n```\n\n**Why it fails:**\n- Missing A.2 Validation Methodology\n- Will trigger: `MISSING_APPENDIX` error\n- **Fix**: Add `### A.2 Validation Methodology` section\n\n**Error Example:**\n```\nERROR: Missing Appendix (Line 450)\nMissing: ### A.2 Validation Methodology\nFound: A.1 ‚úì, A.3 ‚úì, A.4 ‚úì\nExpected order: A.1 ‚Üí A.2 ‚Üí A.3 ‚Üí A.4\nFix: Add A.2 Validation Methodology section\n```\n\n### ‚ùå INVALID: Out of Order (when strict_order=true)\n\n```markdown\n### A.1 Definitions and Terminology\n...\n\n### A.3 Document Completion Guide\n...\n\n### A.2 Validation Methodology\n...\n\n### A.4 Change History\n...\n```\n\n**Why it fails:**\n- A.3 appears before A.2\n- Will trigger: `APPENDIX_OUT_OF_ORDER` error (if strict_order=true)\n- **Fix**: Reorder to A.1 ‚Üí A.2 ‚Üí A.3 ‚Üí A.4\n\n---\n\n## 4. Compliance Calculations\n\n### ‚úÖ VALID: Correct Calculations\n\n```markdown\n**Overall Compliance**:\n- ‚úÖ Compliant: 42/57 (74%)\n- ‚ùå Non-Compliant: 8/57 (14%)\n- ‚äò Not Applicable: 3/57 (5%)\n- ‚ùì Unknown: 4/57 (7%)\n\n**Completeness**: 95% (54/57 data points documented)\n```\n\n**Why it passes:**\n- Sum check: 42 + 8 + 3 + 4 = 57 ‚úì\n- Percentage for Compliant: round((42/57) * 100) = 74% ‚úì\n- Percentage for Non-Compliant: round((8/57) * 100) = 14% ‚úì\n- Percentage for Not Applicable: round((3/57) * 100) = 5% ‚úì\n- Percentage for Unknown: round((4/57) * 100) = 7% ‚úì\n- Correct emoji indicators ‚úÖ ‚ùå ‚äò ‚ùì\n\n### ‚ùå INVALID: Incorrect Sum\n\n```markdown\n**Overall Compliance**:\n- ‚úÖ Compliant: 42/57 (74%)\n- ‚ùå Non-Compliant: 8/57 (14%)\n- ‚äò Not Applicable: 3/57 (5%)\n- ‚ùì Unknown: 5/57 (9%)\n```\n\n**Why it fails:**\n- Sum: 42 + 8 + 3 + 5 = 58 (should be 57)\n- Will trigger: `CALCULATION_SUM_ERROR`\n- **Fix**: Verify counts sum to TOTAL (42 + 8 + 3 + 4 = 57)\n\n**Error Example:**\n```\nERROR: Calculation Sum Error (Line 98)\nExpected: Sum of status counts equals TOTAL (57)\nFound: Sum = 58\nFix: Verify counts: Compliant=42, Non-Compliant=8, Not Applicable=3, Unknown=5 should sum to 57\n```\n\n### ‚ùå INVALID: Incorrect Percentage\n\n```markdown\n**Overall Compliance**:\n- ‚úÖ Compliant: 42/57 (75%)\n```\n\n**Why it fails:**\n- Calculated: round((42/57) * 100) = 74%\n- Stated: 75%\n- Off by 1% (exceeds tolerance)\n- Will trigger: `CALCULATION_PERCENTAGE_ERROR`\n- **Fix**: Change percentage from 75% to 74%\n\n### ‚ùå INVALID: Missing Emoji Indicator\n\n```markdown\n**Overall Compliance**:\n- Compliant: 42/57 (74%)\n```\n\n**Why it fails:**\n- Missing ‚úÖ emoji before \"Compliant\"\n- Will trigger: `INVALID_EMOJI_INDICATOR`\n- **Fix**: Add ‚úÖ emoji: `- ‚úÖ Compliant: 42/57 (74%)`\n\n---\n\n## 5. Template Completeness\n\n### ‚úÖ VALID: All Required Sections Present\n\n```markdown\n# Compliance Contract: SRE Architecture\n\n**Project**: Example Project\n**Generation Date**: 2024-01-01\n**Source**: ARCHITECTURE.md\n**Version**: 2.0\n\n## Document Control\n\n**Status**: Draft\n**Validation Score**: 8.5/10\n\n## Compliance Summary\n\n[Table here]\n\n**Overall Compliance**:\n[Metrics here]\n\n## 1. Log Management (LASRE01)\n[Requirements here]\n\n### A.1 Definitions and Terminology\n...\n\n### A.2 Validation Methodology\n...\n\n### A.3 Document Completion Guide\n...\n\n### A.4 Change History\n...\n\n## Data Extracted from ARCHITECTURE.md\n...\n\n## Missing Data Requiring Manual Review\n...\n```\n\n**Why it passes:**\n- All required sections present:\n  - header (Project, Date, Source, Version)\n  - document_control\n  - compliance_summary\n  - overall_compliance\n  - requirement sections\n  - appendix_a1_a4\n  - dynamic_sections\n\n### ‚ùå INVALID: Missing Document Control\n\n```markdown\n# Compliance Contract: SRE Architecture\n\n**Project**: Example Project\n\n## Compliance Summary\n[Table here]\n```\n\n**Why it fails:**\n- Missing \"## Document Control\" section\n- Will trigger: `MISSING_REQUIRED_SECTION`\n- **Fix**: Add Document Control section before Compliance Summary\n\n**Error Example:**\n```\nERROR: Missing Required Section (Line 10)\nExpected: Section: document_control\nFound: Section not found\nFix: Add required section: document_control\n```\n\n---\n\n## 6. Special Cases\n\n### Special Case 1: Business Continuity (Section-Based Format)\n\n**Business Continuity does NOT use the 6-column Compliance Summary table.**\n\n### ‚úÖ VALID: Business Continuity Format\n\n```markdown\n## 1. Recovery Objectives (LABC1)\n\n**RTO (Recovery Time Objective)**: 4 hours\n- Status: Compliant\n- Source: ARCHITECTURE.md Section 11.3, lines 489-491\n\n**RPO (Recovery Point Objective)**: 15 minutes\n- Status: Compliant\n- Source: ARCHITECTURE.md Section 11.3, lines 492-494\n\n**Business Criticality**: Tier 1 (Mission Critical)\n- Status: Compliant\n- Source: ARCHITECTURE.md Section 10.1, lines 425-427\n```\n\n**Why it passes:**\n- Section-based format with required fields (RTO, RPO, Business Criticality)\n- No Compliance Summary table (disabled for Business Continuity)\n- Status values still validated\n\n### ‚ùå INVALID: Business Continuity with Table\n\n```markdown\n## Compliance Summary\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LABC1 | RTO | BC | Compliant | 11.3 | BC Team |\n```\n\n**Why it fails:**\n- Business Continuity should NOT use table format\n- Will trigger warning or error depending on configuration\n- **Fix**: Use section-based format instead\n\n---\n\n### Special Case 2: SRE Architecture (Two-Tier Scoring)\n\n**SRE Architecture has 57 requirements: 36 Blocker + 21 Desired**\n\n### ‚úÖ VALID: Two-Tier Row Count\n\n```markdown\n## Compliance Summary\n\n**Two-Tier Compliance Scoring**: This contract uses a two-tier scoring system with 36 Blocker requirements (LASRE01-16, critical for approval) and 21 Desired requirements (LASRE17+, enhance quality).\n\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n[... 57 total rows: 36 Blocker + 21 Desired ...]\n```\n\n**Why it passes:**\n- Table has exactly 57 rows (36 + 21)\n- Two-tier note present\n- Blocker and Desired counts match configuration\n\n### ‚ùå INVALID: Wrong Row Count\n\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n[... only 50 rows ...]\n```\n\n**Why it fails:**\n- Only 50 rows instead of 57\n- Will trigger: `INVALID_ROW_COUNT` and `TWO_TIER_COUNT_MISMATCH`\n- **Fix**: Add missing 7 requirement rows\n\n---\n\n### Special Case 3: Data & AI Architecture (Dual Categories)\n\n**Data & AI uses \"Data\" and \"AI\" as categories, not \"Data & AI Architecture\"**\n\n### ‚úÖ VALID: Dual Categories\n\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAD1 | Data modeling | Data | Compliant | Section 8 | Data Architect |\n| LAD2 | Data quality | Data | Compliant | Section 8 | Data Architect |\n| LAIA1 | ML model versioning | AI | Compliant | Section 8 | ML Engineer |\n| LAIA2 | Model monitoring | AI | Compliant | Section 8 | ML Engineer |\n```\n\n**Why it passes:**\n- Uses \"Data\" category for LAD* codes\n- Uses \"AI\" category for LAIA* codes\n- Correct CODE pattern: `^LA(D|AI)\\\\d+$`\n\n### ‚ùå INVALID: Wrong Category\n\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LAD1 | Data modeling | Data & AI Architecture | Compliant | Section 8 | Data Architect |\n```\n\n**Why it fails:**\n- Uses \"Data & AI Architecture\" instead of \"Data\"\n- Will trigger: `INVALID_CATEGORY` error\n- **Fix**: Change category to \"Data\" for LAD* codes, \"AI\" for LAIA* codes\n\n---\n\n## Common Error Patterns\n\n### 1. Copy-Paste Errors\n\n**‚ùå INVALID:**\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| LASRE01 | Logging | Practice | Compliant | Section 11.1 | SRE Team |\n| LASRE01 | Logging | Practice | Compliant | Section 11.1 | SRE Team |\n```\n\n**Issue**: Duplicate Code (LASRE01 appears twice)\n**Fix**: Use sequential codes (LASRE01, LASRE02, etc.)\n\n### 2. Placeholder Retention\n\n**‚ùå INVALID:**\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role |\n|------|-------------|----------|--------|----------------|------------------|\n| [CODE] | [Requirement] | [Category] | [STATUS] | [SOURCE] | [ROLE] |\n```\n\n**Issue**: Placeholders not replaced with actual values\n**Fix**: Replace all placeholders with real data\n\n### 3. Markdown Syntax Errors\n\n**‚ùå INVALID:**\n```markdown\n| Code | Requirement | Category | Status | Source Section | Responsible Role\n|------|-------------|----------|--------|----------------|------------------\n| LASRE01 | Test | Category | Compliant | Section 1 | Team\n```\n\n**Issue**: Missing trailing pipes (|) at end of rows\n**Fix**: Add trailing pipe to each row\n\n---\n\n## Validation Workflow\n\n1. **Generate document** using compliance generation workflow\n2. **Run validation** via `ComplianceValidator`\n3. **Review errors** in detailed error report\n4. **Fix issues** using error report fix instructions\n5. **Re-validate** until all errors resolved\n6. **Proceed to output** when validation passes\n\n## Testing Validation\n\nTo test validation rules manually:\n\n```typescript\nimport { ComplianceValidator } from './utils/validators';\n\nconst validator = new ComplianceValidator('validation/template_validation_sre_architecture.json');\nconst result = await validator.validateDocument(documentContent, 'sre_architecture');\n\nconsole.log(result.isValid);  // true or false\nconsole.log(result.errors);    // Array of validation errors\n```\n\n---\n\n## Reference\n\n- **SKILL.md**: Lines 676-740 (Format Enforcement Checklist)\n- **Validation Schema**: `/validation/TEMPLATE_VALIDATION_SCHEMA.json`\n- **Validation Rules**: `/validation/template_validation_*.json`\n- **Validators**: `/utils/validators.ts`\n- **Error Reporter**: `/utils/error_reporter.ts`\n",
        "skills/architecture-docs/ADR_GUIDE.md": "# Architecture Decision Records (ADR) Guide\n\n> A comprehensive guide for creating and managing Architecture Decision Records\n\n## Purpose\n\nThis guide provides a structured approach to documenting architectural decisions using ADRs (Architecture Decision Records). ADRs help teams track why certain architectural choices were made, providing context for future decisions and team members.\n\n**Use this guide when:**\n- Making significant architectural decisions\n- Selecting technologies or frameworks\n- Choosing architectural patterns\n- Making security or compliance decisions\n- Planning major refactoring efforts\n\n---\n\n## What is an ADR?\n\nAn Architecture Decision Record (ADR) is a document that captures an important architectural decision along with its context and consequences.\n\n**Key Characteristics:**\n- **Immutable**: Once accepted, ADRs are not modified (new ADRs supersede old ones)\n- **Numbered**: Sequential numbering for easy reference\n- **Version Controlled**: Stored in Git with the codebase\n- **Concise**: Focused on the decision, not implementation details\n\n---\n\n## ADR Template\n\nUse this template for all architectural decisions:\n\n```markdown\n# ADR-XXX: [Decision Title]\n\n**Status**: Proposed | Accepted | Deprecated | Superseded\n**Date**: YYYY-MM-DD\n**Authors**: [Names or team]\n**Related**: [Links to related ADRs]\n\n---\n\n## Context\n\nWhat is the issue that we're seeing that is motivating this decision or change?\n\n**Problem Statement:**\n- What problem are we trying to solve?\n- Who is impacted by this problem?\n- What are the consequences of not solving it?\n\n**Requirements:**\n- Functional requirements\n- Non-functional requirements (performance, security, etc.)\n- Constraints (budget, timeline, technology lock-in)\n\n---\n\n## Decision\n\nWhat is the change that we're proposing and/or doing?\n\n**Summary:**\n[One paragraph summary of the decision]\n\n**Details:**\n[Detailed explanation of what we decided to do]\n\n**Scope:**\n- What is included\n- What is NOT included\n\n---\n\n## Rationale\n\nWhy did we make this decision?\n\n**Primary Drivers:**\n1. Driver 1: [Explanation]\n2. Driver 2: [Explanation]\n3. Driver 3: [Explanation]\n\n**Comparison Summary:**\n\n> ‚ö†Ô∏è **WARNING**: The table below contains **PLACEHOLDER DATA**. You **MUST** replace it with **REAL, RESEARCHED DATA** before submitting your ADR.\n> - Use **specific numbers** instead of generic ratings: \"$1,400/month (8 vCores)\" not \"Medium cost\"\n> - Include **units and context**: \"99.99% SLA\", \"<10ms p95 latency\", \"25K ops/sec\"\n> - **Cite sources** for all data in the References section (vendor docs, benchmarks, POCs)\n> - See the Example ADR section below (lines 409-546) for an example with real data\n\n| Criteria | Option A | Option B | Option C |\n|----------|----------|----------|----------|\n| Performance | ‚úÖ Excellent | ‚ö†Ô∏è Good | ‚ùå Poor |\n| Cost | ‚ö†Ô∏è Medium | ‚úÖ Low | ‚ùå High |\n| Complexity | ‚úÖ Low | ‚ö†Ô∏è Medium | ‚ùå High |\n\n---\n\n## Consequences\n\nWhat becomes easier or more difficult to do because of this change?\n\n### Positive\n1. Benefit 1\n2. Benefit 2\n\n### Negative\n1. Drawback 1: [Mitigation strategy]\n2. Drawback 2: [Mitigation strategy]\n\n### Trade-offs\n- What we gained vs what we sacrificed\n\n---\n\n## Alternatives Considered\n\n### Alternative 1: [Name]\n**Why Considered**: [Reason]\n**Why Rejected**: [Reason]\n\n### Alternative 2: [Name]\n**Why Considered**: [Reason]\n**Why Rejected**: [Reason]\n\n---\n\n## References\n\n- [Documentation links]\n- [Blog posts, papers]\n- [Related ADRs]\n\n---\n\n**Last Updated**: YYYY-MM-DD\n**Status**: ‚úÖ Accepted\n```\n\n---\n\n## Managing ADRs in Architecture Documentation\n\n### Linking ADRs in Your Architecture Document\n\nIn your main architecture documentation (ARCHITECTURE.md), include a simple reference section:\n\n```markdown\n## Architecture Decision Records\n\nKey architectural decisions are documented in separate ADR files following the [ADR Guide](ADR_GUIDE.md).\n\n### Active ADRs\n\n| ID | Title | Status | Date | Impact |\n|----|-------|--------|------|--------|\n| [ADR-001](adr/ADR-001-technology-stack.md) | Technology Stack Selection | Accepted | 2024-01-15 | High |\n| [ADR-002](adr/ADR-002-database-choice.md) | Database Choice | Accepted | 2024-01-20 | High |\n| [ADR-003](adr/ADR-003-api-protocol.md) | API Protocol | Accepted | 2024-02-01 | Medium |\n\n### ADR Index by Category\n\n**Infrastructure**:\n- ADR-001: Kubernetes for orchestration\n- ADR-005: Multi-region deployment strategy\n\n**Data Layer**:\n- ADR-002: PostgreSQL as primary database\n- ADR-006: Redis for caching\n\n**API Design**:\n- ADR-003: gRPC for inter-service communication\n- ADR-007: REST for public APIs\n\n**Security**:\n- ADR-004: OAuth 2.0 for authentication\n- ADR-008: mTLS for service-to-service communication\n```\n\n---\n\n## Creating New ADRs\n\n### When to Create an ADR\n\nCreate an ADR for decisions that:\n- **Technology Selection**: Choosing databases, frameworks, languages\n- **Architectural Patterns**: Microservices vs monolith, event-driven architecture\n- **Major Refactoring**: Significant changes to system structure\n- **Security/Compliance**: Authentication methods, data encryption approaches\n- **Scalability Approaches**: Caching strategies, database sharding\n- **Integration Choices**: Third-party services, APIs, message brokers\n\n### Automatic ADR Generation\n\nWhen creating a new ARCHITECTURE.md using the architecture-docs skill, you will be prompted to automatically generate ADR files from the Section 12 table. This feature:\n\n- **Creates ADR files** with proper naming convention (`ADR-{number}-{slug}.md`)\n- **Populates metadata** from Section 12 table (title, status, date, impact)\n- **Uses the standard template** (ADR-000-template.md)\n- **Creates the adr/ directory** if it doesn't exist\n- **Handles conflicts** gracefully (never overwrites existing files)\n\n**How it Works:**\n\n1. After creating ARCHITECTURE.md, you'll see a prompt:\n   ```\n   Would you like me to generate the ADR files now?\n\n   Options:\n   1. [Yes - Generate ADRs] - Create all ADR files listed in Section 12\n   2. [Preview First] - Show me which ADRs will be created\n   3. [No Thanks] - I'll create them manually later\n   4. [Learn More] - Tell me about ADRs and the template\n   ```\n\n2. If you choose to generate ADRs, the skill will:\n   - Read Section 12 table in ARCHITECTURE.md\n   - Extract ADR metadata (number, title, status, date)\n   - Generate ADR files using the template\n   - Report which files were created\n\n3. You can then customize each ADR by filling in:\n   - Context section (problem statement, requirements)\n   - Decision section (what was decided)\n   - Rationale section (why this choice)\n   - Consequences section (positive/negative outcomes)\n   - Alternatives section (options considered but rejected)\n\n**To regenerate ADRs later or add new ones:**\n- Update Section 12 table in ARCHITECTURE.md with new ADR entries\n- Manually copy and customize ADR-000-template.md\n- Use the architecture-docs skill's ADR generation feature\n\n**Note**: Automatic generation is optional - you can skip it and create ADRs manually using the workflow below.\n\n### Manual ADR Workflow\n\n```bash\n# 1. Copy template\ncp adr/ADR-000-template.md adr/ADR-XXX-your-decision.md\n\n# 2. Fill in sections:\n#    - Context: What problem are we solving?\n#    - Decision: What did we decide?\n#    - Rationale: Why this decision?\n#    - Consequences: What are the impacts?\n#    - Alternatives: What else did we consider?\n\n# 3. Submit for review\ngit checkout -b adr/XXX-your-decision\ngit add adr/ADR-XXX-your-decision.md\ngit commit -m \"Add ADR-XXX: Your Decision\"\ngit push\n\n# 4. Create Pull Request for team review\n\n# 5. After approval, update status to \"Accepted\"\n```\n\n---\n\n## ADR Best Practices\n\n### Writing Effective ADRs\n\n1. **Focus on Context**\n   - Explain WHY the decision was needed\n   - Describe the problem clearly\n   - Include constraints and requirements\n\n2. **Be Objective**\n   - Present alternatives fairly\n   - Use **REAL, RESEARCHED data** to support decisions (not placeholder ratings like \"Excellent/Good/Poor\")\n   - Include **quantitative metrics** where available: latency (ms), cost ($/month), throughput (ops/sec), SLA (%)\n   - **Cite sources** for comparison data (vendor documentation, benchmarks, POC results)\n   - Acknowledge trade-offs\n\n3. **Keep it Concise**\n   - Focus on the decision, not implementation\n   - 1-2 pages maximum\n   - Use tables for comparisons with **SPECIFIC, QUANTITATIVE data**:\n     - ‚úÖ **Good**: \"$1,400/month (8 vCores)\", \"99.99% SLA\", \"<10ms p95 latency\", \"25K ops/sec\"\n     - ‚ùå **Bad**: \"Medium cost\", \"Excellent performance\", \"High complexity\", \"Good reliability\"\n   - Replace template placeholder data with real numbers from vendor docs, benchmarks, or testing\n\n4. **Think Long-term**\n   - Consider future maintainers\n   - Document assumptions\n   - Note what might change\n\n5. **Link Liberally**\n   - Reference related ADRs\n   - Link to documentation\n   - Include relevant research\n\n### Comparison Table Best Practices\n\n**Always Use Real, Researched Data:**\n\nComparison tables must contain specific, quantitative data backed by sources. Never use generic qualitative ratings without supporting numbers.\n\n**Examples of Good vs Bad Data:**\n\n| Category | ‚úÖ Good (Specific & Quantitative) | ‚ùå Bad (Generic & Vague) |\n|----------|-----------------------------------|--------------------------|\n| **Cost** | \"$1,400/month (8 vCores, General Purpose tier)\" | \"Medium cost\" |\n| **Availability** | \"99.99% SLA (52 min/year downtime)\" | \"Excellent availability\" |\n| **Performance** | \"<10ms p95 latency (internal POC testing)\" | \"Good performance\" |\n| **Throughput** | \"25,000 ops/sec (Redis benchmark)\" | \"High throughput\" |\n| **Scale** | \"4-128 vCores vertical scaling\" | \"Good scalability\" |\n| **Learning Curve** | \"2-4 weeks (team survey, n=5)\" | \"Steep\" |\n\n**Required Quantitative Metrics (When Available):**\n- **Latency**: Use specific numbers with percentiles (p50, p95, p99) and units (ms, seconds)\n- **Throughput**: Requests/sec, messages/sec, operations/sec, transactions/sec\n- **Cost**: Actual monthly/annual costs with tier/configuration details\n- **SLA**: Percentage with downtime context (e.g., \"99.99% = 52 min/year\")\n- **Capacity**: Specific limits (vCores, memory, connections, storage)\n- **Time Estimates**: Learning curve, migration effort in days/weeks (cite source: POC, team survey, etc.)\n\n**Source Citation Requirements:**\n\nEvery data point in comparison tables should be traceable to a source. Include a References section with:\n\n**Example References Section:**\n```markdown\n## References\n\n### Comparison Data Sources\n- Azure SQL Database pricing: https://azure.microsoft.com/pricing/details/azure-sql-database/\n- Azure SQL SLA: https://azure.microsoft.com/support/legal/sla/azure-sql-database/\n- PostgreSQL performance benchmarks: Internal POC results (`docs/postgres-benchmark-2024-01.md`)\n- Cosmos DB latency: Azure documentation (global distribution, multi-region writes)\n- Team expertise estimates: Survey of 5 engineers (avg 2.5 years PostgreSQL experience)\n- Migration effort: Based on previous schema migration project (3 weeks actual, documented in PROJ-123)\n```\n\n**Acceptable Source Types:**\n1. **Vendor Documentation**: Official pricing pages, SLA agreements, technical specs\n2. **Internal Testing**: POC results, benchmark tests, load testing reports (document methodology)\n3. **Third-Party Benchmarks**: Link to published reports from reputable sources\n4. **Case Studies**: Published experience reports from similar implementations\n5. **Team Expertise**: Survey/poll results from team members (document sample size and experience levels)\n6. **Historical Data**: Previous project metrics (link to project documentation)\n\n**What NOT to Do:**\n- ‚ùå Generic ratings: \"Excellent\", \"Good\", \"Poor\", \"Medium\", \"High\", \"Low\"\n- ‚ùå Unsourced numbers: Claims without citations or validation\n- ‚ùå Assumptions presented as facts: \"Should be around $500/month\" ‚Üí cite actual pricing\n- ‚ùå Copying template verbatim: The template's example table is PLACEHOLDER DATA ONLY\n\n**Real-World Example within this Guide:**\n\nSee the \"Example ADR\" section below (lines 409-546) for an excellent demonstration:\n- 10 criteria evaluated with specific, quantitative numbers\n- Real benchmarks: \"<5ms p95 latency\", \"100K req/sec throughput\", \"2-3x smaller serialization\"\n- Learning curve data: \"2-4 weeks (team survey, n=5)\" with sample size documented\n- Cost analysis: \"Free (open-source)\" with ecosystem size comparisons\n- Source citations: Internal POC results, vendor docs, team surveys all documented\n- Proper attribution: All 8 data points include reference numbers [1]-[8]\n- References section: Comprehensive sources including URLs and internal doc paths\n\n### Common ADR Pitfalls\n\n‚ùå **Don't:**\n- Modify ADRs after acceptance (create new ones instead)\n- Document implementation details (those go in code)\n- Write ADRs after-the-fact to justify decisions\n- Skip the alternatives section\n- Assume everyone has the same context\n- Use placeholder or generic data in comparison tables (\"Excellent/Good/Poor\" ratings without numbers)\n- Make up numbers without validation or sources\n- Copy the template's example table verbatim into production ADRs\n\n‚úÖ **Do:**\n- Write ADRs before or during decision-making\n- Focus on architectural significance\n- Include team in the ADR review process\n- Keep ADRs with the codebase in version control\n- Review ADRs quarterly to identify candidates for deprecation\n- Use real, researched data in comparison tables with source citations\n- Include quantitative metrics (latency, cost, throughput, SLA) where available\n- Validate all comparison data through vendor docs, benchmarks, or POC testing\n\n---\n\n## ADR Status Lifecycle\n\n```\nProposed ‚Üí Accepted ‚Üí Deprecated ‚Üí Superseded\n           ‚Üì\n        Rejected\n```\n\n**Status Definitions:**\n- **Proposed**: Under review, not yet implemented\n- **Accepted**: Approved and being/has been implemented\n- **Rejected**: Considered but not chosen\n- **Deprecated**: No longer recommended, but still in use\n- **Superseded**: Replaced by a newer ADR (link to new ADR)\n\n### Updating ADR Status\n\nWhen an architectural decision changes:\n1. **Do NOT modify** the original ADR\n2. Create a new ADR that supersedes it\n3. Update the original ADR's status to \"Superseded by ADR-XXX\"\n4. Link between the old and new ADRs\n\n**Example:**\n```markdown\n# ADR-002: PostgreSQL for Primary Database\n\n**Status**: Superseded by [ADR-015](ADR-015-migrate-to-cockroachdb.md)\n**Date**: 2024-01-20\n**Superseded Date**: 2024-06-15\n```\n\n---\n\n## ADR Tools\n\n### Command-Line Tools\n- **adr-tools**: CLI for managing ADRs\n  ```bash\n  # Install\n  brew install adr-tools\n\n  # Create new ADR\n  adr new \"Use PostgreSQL for primary database\"\n\n  # Supersede an ADR\n  adr new -s 2 \"Use CockroachDB for primary database\"\n  ```\n\n- **log4brains**: Web UI for ADRs with search and navigation\n  ```bash\n  npm install -g log4brains\n  log4brains init\n  log4brains preview\n  ```\n\n### Documentation Platforms\n- **Backstage**: Developer portal with built-in ADR support\n- **Docusaurus**: Include ADRs in technical documentation site\n- **MkDocs**: Generate static site from ADR markdown files\n\n---\n\n## Example ADR\n\n### ADR-001: Use gRPC for Inter-Service Communication\n\n**Status**: Accepted\n**Date**: 2024-01-15\n**Authors**: Platform Team\n**Related**: ADR-007 (REST for Public APIs)\n\n---\n\n#### Context\n\n**Problem Statement:**\nOur microservices architecture requires efficient inter-service communication. Current REST/JSON approach suffers from:\n- High serialization overhead\n- Lack of type safety across services\n- Manual client library maintenance\n- No built-in load balancing or retry logic\n\n**Requirements:**\n- Low latency (<10ms p95 for internal calls)\n- Type-safe contracts between services\n- Support for streaming (bi-directional)\n- Backward compatibility support\n- Language-agnostic (Go, Java, Python services)\n\n**Constraints:**\n- Must work with Kubernetes service discovery\n- Team has limited experience with alternative protocols\n- Need to maintain REST for public APIs\n\n---\n\n#### Decision\n\n**Summary:**\nAdopt gRPC with Protocol Buffers for all inter-service communication while maintaining REST APIs for external clients via API Gateway with gRPC transcoding.\n\n**Details:**\n- Define service contracts in `.proto` files\n- Auto-generate client libraries for each language\n- Use gRPC-native load balancing (client-side)\n- Implement gRPC health checking\n- Use API Gateway (Kong) for REST‚ÜîgRPC transcoding\n\n**Scope:**\n- Included: All internal service-to-service calls\n- NOT included: Public APIs (remain REST), message queue events\n\n---\n\n#### Rationale\n\n**Primary Drivers:**\n1. **Performance**: Binary serialization 2-3x faster than JSON, reduces latency by ~30% [1]\n2. **Type Safety**: Proto schemas enforce contracts, catch errors at compile time [2]\n3. **Tooling**: Auto-generated clients eliminate manual SDK maintenance [3]\n\n**Comparison:**\n\n| Criteria | gRPC (Selected) | REST/JSON | GraphQL |\n|----------|-----------------|-----------|---------|\n| **Latency** | ‚úÖ <5ms p95 [1] | ‚ö†Ô∏è 10-15ms p95 [4] | ‚ö†Ô∏è 15-20ms p95 [5] |\n| **Throughput** | ‚úÖ 100K req/sec [1] | ‚ö†Ô∏è 50K req/sec [4] | ‚ö†Ô∏è 40K req/sec [6] |\n| **Serialization** | ‚úÖ Protobuf binary (2-3x smaller) [1] | ‚ö†Ô∏è JSON text | ‚ö†Ô∏è JSON text |\n| **Type Safety** | ‚úÖ Compile-time (Protobuf) | ‚ùå Runtime only | ‚ö†Ô∏è GraphQL schema (runtime) |\n| **Streaming** | ‚úÖ Bi-directional native | ‚ùå SSE/WebSocket required | ‚ö†Ô∏è Subscriptions (WebSocket) |\n| **Learning Curve** | ‚ö†Ô∏è 2-4 weeks [7] | ‚úÖ 1-2 days (team familiar) | ‚ö†Ô∏è 1-2 weeks [7] |\n| **Browser Support** | ‚ùå gRPC-Web required | ‚úÖ Native | ‚úÖ Native |\n| **Ecosystem** | ‚úÖ 50+ languages [8] | ‚úÖ Universal | ‚ö†Ô∏è Growing (7 years old) |\n| **Client Generation** | ‚úÖ Auto-generated from .proto | ‚ùå Manual or OpenAPI | ‚ö†Ô∏è GraphQL codegen |\n| **Cost** | ‚úÖ Free (open-source) | ‚úÖ Free (open-source) | ‚úÖ Free (open-source) |\n\n**Decision Factors:**\n- **Selected gRPC** for 40% latency reduction (measured in POC), native streaming, and type safety\n- **Rejected REST/JSON** despite familiarity due to performance bottleneck and manual client maintenance\n- **Rejected GraphQL** as it's optimized for client-driven queries, not inter-service communication\n\n---\n\n#### Consequences\n\n**Positive:**\n1. Reduced inter-service latency (measured 40% improvement in tests)\n2. Eliminated entire class of serialization bugs\n3. Auto-generated clients reduce boilerplate by ~60%\n4. Built-in load balancing and circuit breakers\n\n**Negative:**\n1. Increased complexity: [Mitigation: Comprehensive gRPC training, shared proto repo]\n2. Debugging more difficult than REST: [Mitigation: grpcurl tool, gRPC reflection]\n3. Not directly callable from browsers: [Mitigation: gRPC-Web for web clients]\n\n**Trade-offs:**\n- Gained performance and type safety at the cost of debugging simplicity\n- Accepted steeper learning curve for long-term productivity gains\n\n---\n\n#### Alternatives Considered\n\n**Alternative 1: Continue with REST/JSON**\n- **Why Considered**: Zero learning curve, familiar to all developers\n- **Why Rejected**: Performance bottleneck, type safety issues, manual client maintenance\n\n**Alternative 2: GraphQL**\n- **Why Considered**: Flexible querying, good for BFF layer\n- **Why Rejected**: Not optimized for inter-service communication, mainly client-focused\n\n**Alternative 3: Apache Thrift**\n- **Why Considered**: Similar benefits to gRPC, Facebook-proven\n- **Why Rejected**: Smaller ecosystem, less Kubernetes integration, declining popularity\n\n---\n\n#### References\n\n### Comparison Data Sources\n- [1] Internal POC benchmark results: `docs/poc-grpc-vs-rest-benchmark.md` (gRPC: <5ms p95 latency, 100K req/sec, Protobuf 2-3x smaller)\n- [2] gRPC Core Concepts - Type Safety: https://grpc.io/docs/what-is-grpc/core-concepts/\n- [3] gRPC Code Generation: https://grpc.io/docs/languages/\n- [4] Baseline REST/JSON performance: Current production metrics from monitoring dashboard\n- [5] GraphQL latency estimate: 50% overhead from N+1 query resolution (internal assessment)\n- [6] Apollo Server performance benchmarks: https://www.apollographql.com/docs/apollo-server/performance/\n- [7] Team learning curve survey: Poll of 5 engineers (avg 2-4 weeks for gRPC/GraphQL, 1-2 days for REST)\n- [8] gRPC language support: https://grpc.io/docs/languages/ (50+ official implementations)\n\n### Additional Resources\n- [gRPC Performance Benchmarks](https://grpc.io/docs/guides/benchmarking/)\n- [gRPC Best Practices](https://grpc.io/docs/guides/performance/)\n- Internal POC Report: `docs/poc-grpc-migration.md`\n\n---\n\n**Last Updated**: 2024-01-15\n**Status**: ‚úÖ Accepted\n\n---\n\n## References\n\n### ADR Resources\n- [ADR GitHub Organization](https://adr.github.io/) - Best practices and tools\n- [Documenting Architecture Decisions](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions) - Original ADR article by Michael Nygard\n- [ADR Tools](https://github.com/npryce/adr-tools) - Command-line tools for managing ADRs\n\n### Related Guides\n- [Architecture Documentation Guide](ARCHITECTURE_DOCUMENTATION_GUIDE.md) - Main architecture documentation guide\n- [C4 Model](https://c4model.com/) - Complementary architecture diagram approach\n\n---\n\n**Document Version**: 1.0.0\n**Last Updated**: 2025-01-18\n**Maintained By**: Architecture Team",
        "skills/architecture-docs/ARCHITECTURE_DOCUMENTATION_GUIDE.md": "# Architecture Documentation Guide\n\n> A comprehensive guide for creating system architecture documentation ARCHITECTURE.md\n\n## Purpose\n\nThis guide provides a structured approach to documenting complex system architectures. Incorporates industry best practices for technical documentation.\n\n**Use this guide when:**\n- Starting a new system architecture from scratch\n- Documenting an existing system's architecture\n- Standardizing architecture documentation across multiple projects\n- Onboarding teams to a new system\n- Communicating architecture decisions to stakeholders\n\n## Related Documentation\n\nThis guide focuses on **what to write** and **how to structure** architecture documentation content.\n\nFor supporting operations and algorithms:\n- **‚Üí SKILL.md**: Operational workflows, when to trigger actions, context-efficient editing strategies\n- **‚Üí METRIC_CALCULATIONS.md**: Algorithms for index updates and metric consistency detection\n- **‚Üí DESIGN_DRIVER_CALCULATIONS.md**: Implementation details for Design Drivers calculation\n- **‚Üí VALIDATIONS.md**: Structure enforcement rules, required principles, section name validation\n- **‚Üí ADR_GUIDE.md**: Architectural Decision Record format and creation guidelines\n\n## Architecture Type Selection\n\n**Before creating your ARCHITECTURE.md, choose your architecture type.** The architecture type determines the structure and content of **Section 4 (Meta Architecture)** and **Section 5 (Component Details)**.\n\n### Available Architecture Types\n\n1. **META Architecture** - 6-layer enterprise model for large systems with complex integrations\n2. **3-Tier Architecture** - Classic web application pattern (Presentation ‚Üí Application ‚Üí Data)\n3. **Microservices Architecture** - Cloud-native distributed systems with independent services\n4. **N-Layer Architecture** - Customizable patterns (DDD, Clean Architecture, Hexagonal)\n\n### How to Select\n\nWhen creating a new ARCHITECTURE.md, the skill will prompt you to select your architecture type. Refer to:\n- **`templates/ARCHITECTURE_TYPE_SELECTOR.md`** - Decision guide with comparison matrix\n\n### Type-Specific Templates\n\nEach architecture type has dedicated templates:\n- **Section 4 Templates**: `templates/SECTION_4_*.md` (layer/tier structure)\n- **Section 5 Templates**: `templates/SECTION_5_*.md` (component organization)\n\nThe skill automatically loads the appropriate templates based on your selection.\n\n### Changing Architecture Type\n\nTo change the architecture type of an existing ARCHITECTURE.md:\n1. Re-invoke the skill and specify the new type\n2. The skill will detect the change and update Sections 4 and 5\n3. **Manual review required** to ensure component mappings align with new structure\n\n---\n\n## Document Structure Overview\n\nA comprehensive architecture document should follow this hierarchical structure:\n\n```\n1. Executive Summary\n2. System Overview\n3. Architecture Principles\n4. Architecture Layers\n5. Component Details (Per Layer)\n6. Data Flow Patterns\n7. Integration Points\n8. Technology Stack\n9. Security Architecture\n10. Scalability & Performance\n11. Operational Considerations\n12. Architecture Decision Records (ADRs)\n```\n\n**IMPORTANT**: Section names must match exactly as shown above. See the architecture-docs skill guide for strict section name enforcement rules.\n\n---\n\n## Document Index & Navigation\n\n**Purpose**: Provide line number references for efficient document traversal and context-aware editing.\n\nEvery ARCHITECTURE.md document should include a **Document Index** at the beginning (before Section 1) that lists all major sections with their approximate line ranges. This enables:\n- Quick navigation to specific sections without reading the entire document\n- Context-efficient editing by loading only relevant sections\n- Easy maintenance and updates to specific parts of the documentation\n\n### Index Template\n\nPlace this index immediately after the document title and before Section 1:\n\n```markdown\n## Document Index\n\n**Quick Navigation:**\n- [Section 1: Executive Summary](#1-executive-summary) ‚Üí Lines [START]-[END]\n- [Section 2: System Overview](#2-system-overview) ‚Üí Lines [START]-[END]\n- [Section 3: Architecture Principles](#3-architecture-principles) ‚Üí Lines [START]-[END]\n- [Section 4: Architecture Layers](#4-architecture-layers) ‚Üí Lines [START]-[END]\n- [Section 5: Component Details](#5-component-details) ‚Üí Lines [START]-[END]\n- [Section 6: Data Flow Patterns](#6-data-flow-patterns) ‚Üí Lines [START]-[END]\n- [Section 7: Integration Points](#7-integration-points) ‚Üí Lines [START]-[END]\n- [Section 8: Technology Stack](#8-technology-stack) ‚Üí Lines [START]-[END]\n- [Section 9: Security Architecture](#9-security-architecture) ‚Üí Lines [START]-[END]\n- [Section 10: Scalability & Performance](#10-scalability--performance) ‚Üí Lines [START]-[END]\n- [Section 11: Operational Considerations](#11-operational-considerations) ‚Üí Lines [START]-[END]\n- [Section 12: Architecture Decision Records (ADRs)](#12-architecture-decision-records-adrs) ‚Üí Lines [START]-[END]\n\n**Index Last Updated:** YYYY-MM-DD\n\n---\n```\n\n### How to Use the Index\n\n**When Reading:**\n1. Read lines 1-50 to locate the Document Index\n2. Find your target section's line range in the index\n3. Use `Read` tool with offset/limit to load only that section\n4. Add 10-20 line buffer on each side to preserve context\n\n**Example:**\n```\n# Index shows: Section 5: Component Details ‚Üí Lines 601-850\n# Load with context buffer:\nRead(file_path=\"ARCHITECTURE.md\", offset=590, limit=270)\n# This reads lines 590-860 (10-line buffer + 250 lines + 10-line buffer)\n```\n\n**When Editing:**\nAfter making significant changes to a section:\n1. Use `grep -n \"^## [0-9]\" ARCHITECTURE.md` to find actual line numbers\n2. Update the index with current line ranges\n3. Update the \"Index Last Updated\" date\n\n### Context Preservation Guidelines\n\nWhen working with sections using the index:\n\n**Minimal Context** (Small edits):\n- Buffer: ¬±5-10 lines\n- Use case: Updating a single paragraph or config value\n\n**Standard Context** (Section edits):\n- Buffer: ¬±10-20 lines\n- Use case: Rewriting a subsection or adding new components\n\n**Extended Context** (Cross-section edits):\n- Buffer: ¬±20-50 lines\n- Use case: Changes that reference adjacent sections\n\n**Example Workflow:**\n```bash\n# Step 1: Read index to find section\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n\n# Step 2: Index shows Section 8: Tech Stack ‚Üí Lines 1151-1300\n# Step 3: Load with standard context (¬±15 lines)\nRead(file_path=\"ARCHITECTURE.md\", offset=1136, limit=179)\n# Reads lines 1136-1315\n\n# Step 4: Make edits using Edit tool\n# Step 5: Verify changes\nRead(file_path=\"ARCHITECTURE.md\", offset=1136, limit=179)\n\n# Step 6: Update index if section grew/shrunk significantly\n```\n\n---\n\n## Section 1: Executive Summary\n\n**Purpose**: High-level overview for executives and stakeholders.\n\n**Important**: Before Section 1, include the Document Index with line number references for navigation.\n\n**Complete Template (Including Index):**\n```markdown\n# [System Name] - [Tagline]\n\n> [One-paragraph mission statement]\n\n## Document Index\n\n**Quick Navigation:**\n- [Section 1: Executive Summary](#1-executive-summary) ‚Üí Lines [START]-[END]\n- [Section 2: System Overview](#2-system-overview) ‚Üí Lines [START]-[END]\n- [Section 3: Architecture Principles](#3-architecture-principles) ‚Üí Lines [START]-[END]\n- [Section 4: Architecture Layers](#4-architecture-layers) ‚Üí Lines [START]-[END]\n- [Section 5: Component Details](#5-component-details) ‚Üí Lines [START]-[END]\n- [Section 6: Data Flow Patterns](#6-data-flow-patterns) ‚Üí Lines [START]-[END]\n- [Section 7: Integration Points](#7-integration-points) ‚Üí Lines [START]-[END]\n- [Section 8: Technology Stack](#8-technology-stack) ‚Üí Lines [START]-[END]\n- [Section 9: Security Architecture](#9-security-architecture) ‚Üí Lines [START]-[END]\n- [Section 10: Scalability & Performance](#10-scalability--performance) ‚Üí Lines [START]-[END]\n- [Section 11: Operational Considerations](#11-operational-considerations) ‚Üí Lines [START]-[END]\n- [Section 12: Architecture Decision Records (ADRs)](#12-architecture-decision-records-adrs) ‚Üí Lines [START]-[END]\n\n**Index Last Updated:** YYYY-MM-DD\n\n---\n\n## 1. Executive Summary\n\n### System Overview\n\n[System description paragraph]\n\n**Key Metrics:**\n\n#### Read TPS\n- **Average Read TPS**: [Value] transactions/second\n- **Peak Read TPS**: [Value] transactions/second\n- **Measurement Period**: [Time frame for measurements, e.g., \"Average over last 30 days in production; Peak observed during Black Friday 2024\"]\n\n#### Processing TPS\n- **Average Processing TPS**: [Value] transactions/second\n- **Peak Processing TPS**: [Value] transactions/second\n- **Measurement Period**: [Time frame for measurements, e.g., \"Average over last quarter; Peak during end-of-month batch processing\"]\n\n#### Write TPS\n- **Average Write TPS**: [Value] transactions/second\n- **Peak Write TPS**: [Value] transactions/second\n- **Measurement Period**: [Time frame for measurements, e.g., \"Average over last month; Peak during data migration events\"]\n\n**Additional Metrics:**\n- **Availability SLA**: [Value]% uptime\n- **Latency Targets**: p95 < [Value]ms, p99 < [Value]ms\n- **[Other Metric]**: [Value and context]\n\n**Technology Stack:** [Primary technologies: language, framework, cloud platform]\n\n**Deployment:** [Cloud provider, orchestration platform, deployment model]\n\n**Business Value:**\n- **Value Proposition 1**: [Impact statement]\n- **Value Proposition 2**: [Impact statement]\n- **Value Proposition 3**: [Impact statement]\n```\n\n**Instructions for Creating the Index:**\n\n1. **Initial Creation**: Use placeholder line ranges [START]-[END] when creating a new document\n2. **After Writing**: Once the document is complete, use `grep -n \"^## [0-9]\" ARCHITECTURE.md` to find actual line numbers\n3. **Update Ranges**: Replace placeholders with actual line ranges\n4. **Maintenance**: Update the index whenever making significant section changes\n5. **Update Date**: Change \"Index Last Updated\" to the current date after updates\n\n---\n\n## Section 2: System Overview\n\n**Purpose**: Context about the problem, solution, and key use cases.\n\n**Template:**\n```markdown\n## System Overview\n\n### Problem Statement\n[Industry/domain] faces challenges with [specific problem]. Current solutions suffer from [pain points].\n\n### Solution\n[System name] addresses this by [approach]. Key differentiators: [3-5 bullet points]\n\n### Design Drivers\n\nThis architecture is driven by the following key factors:\n\n#### Value Delivery\n**Description**: Effectiveness of change in customer experience\n- **Threshold**: >50% = High Impact, ‚â§50% = Low Impact\n- **Current Assessment**: [HIGH / LOW] Impact\n- **Justification**: [Specific percentage or business value metric from Section 1 Executive Summary]\n- **Example**: \"System delivers 70% cost reduction (Section 1, line 52)\" ‚Üí HIGH\n\n#### Scale\n**Description**: Estimated number of customers impacted\n- **Threshold**: >100K = High, ‚â§100K = Low\n- **Current Assessment**: [HIGH / LOW] Impact\n- **Justification**: [Specific customer/transaction volume from Section 2.3 Use Cases]\n- **Example**: \"System impacts 500,000 customers/day (Section 2.3, line 141)\" ‚Üí HIGH\n\n#### Impacts\n**Description**: Implementation complexity across configuration, development, and applications\n- **Threshold**: >5 = High, ‚â§5 = Low\n- **Current Assessment**: [HIGH / LOW] Impact\n- **Justification**: [Component count from Section 5 + Technology count from Section 8]\n- **Example**: \"System requires 8 components/technologies (Section 5: 5, Section 8: 3)\" ‚Üí HIGH\n\n**Last Calculated**: YYYY-MM-DD\n**Calculation Method**: [Automatic / Manual Override]\n\n**Note**: Design Drivers can be automatically calculated using the architecture-docs skill during architecture reviews. The skill will extract metrics from Sections 1, 2.3, 5, and 8 to determine impact levels.\n\n### Primary Use Cases\n1. **Use Case 1**: [Description]\n2. **Use Case 2**: [Description]\n3. **Use Case 3**: [Description]\n```\n\n**Design Drivers Guidance:**\n\nThe Design Drivers subsection provides a quantifiable assessment of the architecture's impact across three dimensions. This helps justify architecture complexity and communicate value to stakeholders.\n\n### What Design Drivers Measure\n\nDesign Drivers assess architecture impact using three quantifiable dimensions:\n\n**1. Value Delivery - Effectiveness of Change**\n\nMeasures the effectiveness of the change from a customer experience perspective.\n\n- **Threshold**: >50% = HIGH Impact, ‚â§50% = LOW Impact\n- **Data Source**: Section 1 Executive Summary, Business Value bullets\n- **What to Look For**: Percentage improvements in cost reduction, efficiency gains, time savings, productivity increases, or customer satisfaction metrics\n- **Examples**:\n  - \"70% cost reduction\" ‚Üí HIGH (70% > 50%)\n  - \"45% time savings\" ‚Üí LOW (45% ‚â§ 50%)\n  - \"60% efficiency improvement\" ‚Üí HIGH (60% > 50%)\n\n**Calculation Approach**:\n1. Review Section 1 Business Value bullets for percentage metrics\n2. Identify the maximum percentage value\n3. Compare to 50% threshold\n4. Include source line number in justification\n\n**2. Scale - Breadth of Impact**\n\nMeasures the estimated number of customers or transactions impacted by the system.\n\n- **Threshold**: >100,000 = HIGH Impact, ‚â§100,000 = LOW Impact\n- **Data Source**: Section 2.3 Use Cases, Success Metrics subsections\n- **What to Look For**: Daily/monthly volumes for customers, users, transactions, payments, jobs, or events processed\n- **Examples**:\n  - \"500,000+ reminders per day\" ‚Üí HIGH (500,000 > 100,000)\n  - \"50,000 customers\" ‚Üí LOW (50,000 ‚â§ 100,000)\n  - \"1,000,000 transactions/month\" ‚Üí HIGH (1M > 100K)\n\n**Calculation Approach**:\n1. Review Section 2.3 Success Metrics for volume indicators\n2. Extract customer counts, transaction volumes, daily/monthly throughput\n3. Identify the maximum volume\n4. Compare to 100,000 threshold\n5. Include source line number in justification\n\n**3. Impacts - Implementation Complexity**\n\nMeasures implementation complexity by counting architectural components and technologies.\n\n- **Threshold**: >5 total = HIGH Impact, ‚â§5 total = LOW Impact\n- **Data Sources**: Section 5 (Component Details) + Section 8 (Technology Stack)\n- **What to Count**:\n  - Components: Count ### subsection headers in Section 5 (e.g., ### 5.1, 5.2, 5.3)\n  - Technologies: Count technology table rows in Section 8 (excluding headers)\n  - Total: Component count + Technology count\n- **Examples**:\n  - 5 components + 3 technologies = 8 total ‚Üí HIGH (8 > 5)\n  - 3 components + 2 technologies = 5 total ‚Üí LOW (5 ‚â§ 5)\n  - 6 components + 0 technologies = 6 total ‚Üí HIGH (6 > 5)\n\n**Calculation Approach**:\n1. Count component subsections in Section 5 (pattern: `^###\\s+\\d+\\.\\d+`)\n2. Count technology table rows in Section 8 (exclude headers and separators)\n3. Sum the counts\n4. Compare to 5 threshold\n5. Provide breakdown in justification\n\n### Why Design Drivers Matter\n\nDesign Drivers provide quantifiable justification for:\n- **Architecture Complexity**: \"8 components/technologies\" explains why the solution is sophisticated\n- **Investment Level**: \"500,000 customers/day\" justifies infrastructure costs and engineering resources\n- **Business Value**: \"70% cost reduction\" demonstrates ROI and strategic importance\n\n**Use Cases**:\n- Architecture reviews and audits\n- Stakeholder presentations and buy-in\n- Budget justification and resource allocation\n- Validating architecture decisions against business goals\n- Quarterly architecture assessments\n\n### When to Calculate\n\n**Manual Assessment** (Initial Documentation):\n- When creating Section 2 during initial architecture documentation\n- Review Section 1, Section 2.3, Section 5, and Section 8\n- Manually extract metrics and apply thresholds\n- Document assessment with source line numbers\n\n**Automatic Calculation** (Architecture Reviews):\n- During architecture reviews or audits\n- After significant architecture changes\n- When explicitly requested: \"calculate design drivers\"\n- Skill automatically extracts metrics and applies thresholds\n- Presents results for user review and approval\n\n### Automation Support\n\nThe architecture-docs skill includes a Design Drivers calculation workflow that:\n\n**What It Does**:\n1. **Extracts Metrics**: Automatically reads Section 1, 2.3, 5, and 8\n2. **Applies Algorithms**: Uses regex patterns and counting logic to extract percentages, volumes, and component counts\n3. **Determines Impact Levels**: Compares extracted values to thresholds (50%, 100K, 5)\n4. **Generates Justifications**: Creates human-readable justifications with source line numbers\n5. **Presents for Review**: Shows calculation report before making any changes\n6. **Updates Document**: After user approval, updates Section 2.2.1 with calculated values\n\n**Context Efficiency**:\n- Loads only required sections (not entire document)\n- Achieves 75-80% context reduction vs. full document load\n- Sequential section loading for minimal memory footprint\n\n**How to Trigger**:\n- Request \"architecture review\"\n- Explicitly ask to \"calculate design drivers\"\n- Skill automatically prompts during architecture audits\n\n**Implementation Details**:\nFor detailed extraction algorithms, edge case handling, and calculation logic, see:\n‚Üí **DESIGN_DRIVER_CALCULATIONS.md** ¬ß Algorithm 1, 2, 3\n\nFor operational workflows and when to trigger calculations, see:\n‚Üí **SKILL.md** ¬ß Design Drivers Workflow\n\n### Threshold Edge Cases\n\n**Exactly at Threshold**:\n- 50% exactly ‚Üí LOW Impact (threshold is >50%, not ‚â•50%)\n- 100,000 exactly ‚Üí LOW Impact (threshold is >100K, not ‚â•100K)\n- 5 exactly ‚Üí LOW Impact (threshold is >5, not ‚â•5)\n- These cases are flagged for user review with a note\n\n**Multiple Metrics**:\n- If multiple percentages exist (e.g., 70%, 45%, 60%), use the maximum (70%)\n- If multiple volumes exist (e.g., 500K customers, 1M transactions), use the maximum (1M)\n- Rationale: Assess overall impact based on strongest metric\n\n**Missing Data**:\n- If no percentage metrics found in Section 1 ‚Üí Default to LOW with note \"No quantifiable metrics found\"\n- If no volume metrics in Section 2.3 ‚Üí Default to LOW with note \"No volume metrics found\"\n- If Section 5 or 8 missing ‚Üí Calculate with available data, note missing section\n\n### Manual Override\n\nUsers can override any calculated value:\n- Change impact level (HIGH ‚Üî LOW)\n- Provide custom justification\n- Specify different threshold or metric\n- Mark as \"Manual Override\" with reason and date\n\nWhen manual override exists:\n- Subsequent automatic calculations prompt before overwriting\n- Preserve manual override unless user explicitly approves change\n- Document override reason in \"Calculation Method\" field\n\n---\n\n## Visualizing Your Architecture\n\n**Purpose**: Create visual representations of your architecture using Mermaid diagrams for improved clarity and communication.\n\n### Why Use Mermaid Diagrams?\n\n**Benefits over ASCII art or external diagram tools**:\n- ‚úÖ **Interactive**: Zoom, pan, and click components in rendered view\n- ‚úÖ **Maintainable**: Text-based, easy to update without manual alignment\n- ‚úÖ **Version Control Friendly**: Git diffs work seamlessly\n- ‚úÖ **GitHub/GitLab Native**: Renders automatically in markdown viewers\n- ‚úÖ **Professional**: Modern, polished appearance with color-coding\n- ‚úÖ **Accessible**: Screen readers can parse the underlying text\n\n### When to Add Diagrams\n\n**Section 4 (Architecture Layers/Tiers)**:\n- **Required for**: Visual representation of layer/tier structure\n- **Diagram Type**: Layer flow diagram using `graph TB` (top-to-bottom)\n- **Shows**: Components grouped by layers, data flow between layers\n- **Benefit**: Helps stakeholders quickly understand system organization\n\n**Section 6 (Data Flow Patterns)**:\n- **Recommended for**: Complex request/response flows\n- **Diagram Type**: Sequence diagrams or flowcharts\n- **Shows**: Step-by-step data movement through components\n- **Benefit**: Clarifies integration patterns and communication protocols\n\n### Quick Mermaid Syntax Reference\n\n**Basic Structure** (Layer/Tier Diagram):\n````markdown\n```mermaid\ngraph TB\n    %% Layer 1\n    subgraph Layer1[\"Layer 1: Name\"]\n        Component1[\"Component Name<br/>Details\"]\n        Component2[\"Component Name<br/>Details\"]\n    end\n\n    %% Layer 2\n    subgraph Layer2[\"Layer 2: Name\"]\n        Component3[\"Component Name\"]\n    end\n\n    %% Data flows\n    Component1 -->|Protocol<br/>Security| Component3\n    Component2 -.->|Async Event| Component3\n```\n````\n\n**Arrow Types**:\n- **Solid arrows (`-->`)**: Synchronous calls (REST, gRPC, SOAP)\n- **Dashed arrows (`-.->`)**: Asynchronous events (Kafka, message queues)\n\n**Color Styling** (Optional but Recommended):\n````markdown\n```mermaid\ngraph TB\n    Component1[\"Service\"]\n\n    %% Define colors\n    classDef blue fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n\n    %% Apply colors\n    class Component1 blue\n```\n````\n\n**Standard Color Palette**:\n- **Blue** (`#4A90E2`): Entry points, schedulers\n- **Orange** (`#F5A623`): Workers, executors\n- **Green** (`#7ED321`): Query services, read models\n- **Purple** (`#BD10E0`): Event streaming (Kafka, queues)\n- **Teal** (`#50E3C2`): Domain services\n- **Gray** (`#9B9B9B`): Infrastructure (API Gateway, load balancers)\n\n### Section 4 Template Examples\n\nEach Section 4 template (META, 3-Tier, Microservices) includes a complete Mermaid diagram example that you can copy and customize:\n\n- **SECTION_4_META.md**: 6-layer architecture with business capabilities and domain services\n- **SECTION_4_3TIER.md**: Classic 3-tier showing presentation ‚Üí business ‚Üí data layers\n- **SECTION_4_MICROSERVICES.md**: Service mesh topology with API Gateway and independent services\n\n### Complete Instructions\n\nFor comprehensive Mermaid diagram guidance, including:\n- Detailed component guidelines and naming conventions\n- Data flow labeling (protocols, security, timeouts, retries)\n- Legend templates\n- Step-by-step creation and update instructions\n- Common scenarios (adding services, topics, changing protocols)\n- Best practices and validation checklists\n\n**See**: [MERMAID_DIAGRAMS_GUIDE.md](MERMAID_DIAGRAMS_GUIDE.md)\n\n---\n\n## Section 3: Architecture Principles\n\n**Purpose**: Guiding principles that drive architectural decisions.\n\n**Required Principles (in order):**\n\nAll architecture documents must include these 9 core principles in this exact order:\n\n1. **Separation of Concerns**: Each component has a single, well-defined responsibility\n2. **High Availability**: System remains operational during infrastructure failures\n3. **Scalability First**: Design for horizontal scalability from day one\n4. **Security by Design**: Security is not an afterthought\n5. **Observability**: All components emit metrics, logs, and traces\n6. **Resilience**: System degrades gracefully under failure\n7. **Simplicity**: Choose the simplest solution that meets requirements\n8. **Cloud-Native**: Design for cloud deployment and orchestration\n9. **Open Standards**: Prefer open standards over proprietary solutions\n\n**Optional Principle:**\n\n10. **Decouple Through Events**: *(Apply selectively where temporal independence and scalability are prioritized)*\n    - Loose coupling via domain events\n    - Asynchronous communication patterns\n\n**Template Structure:**\n\nEach principle must follow this three-part structure:\n\n```markdown\n## Architecture Principles\n\n### 1. Separation of Concerns\n\n**Description:**\nEach component has a single, well-defined responsibility with clear boundaries between layers and modules.\n\n**Implementation:**\n- [How this principle is applied in your system]\n- [Specific technologies, patterns, or architectural choices]\n- [Examples of separation in your architecture]\n\n**Trade-offs:**\n- [Costs or downsides of implementing this principle]\n- [Complexity introduced, performance impacts, etc.]\n\n### 2. High Availability\n\n**Description:**\nSystem remains operational during infrastructure failures through redundancy and fault tolerance.\n\n**Implementation:**\n- [Your HA strategy: clustering, multi-zone deployment, etc.]\n- [Specific configurations and technologies used]\n- [Health checks, failover mechanisms]\n\n**Trade-offs:**\n- [Increased infrastructure complexity and cost]\n- [Additional operational overhead]\n\n### 3. Scalability First\n\n**Description:**\nDesign for horizontal scalability from day one, enabling linear capacity scaling by adding resources.\n\n**Implementation:**\n- [Stateless services, auto-scaling configuration]\n- [Specific scaling strategies and triggers]\n- [Technologies used: Kubernetes HPA, load balancers, etc.]\n\n**Trade-offs:**\n- [State management complexity]\n- [Distributed coordination challenges]\n\n### 4. Security by Design\n\n**Description:**\nSecurity is not an afterthought but built into every layer with encryption, authentication, and authorization.\n\n**Implementation:**\n- [Encryption standards: mTLS, TLS version]\n- [Authentication/authorization: OAuth, RBAC, etc.]\n- [Secrets management, key vault solutions]\n- [Audit logging and compliance measures]\n\n**Trade-offs:**\n- [Performance overhead from encryption]\n- [Development complexity increase]\n\n### 5. Observability\n\n**Description:**\nAll components emit metrics, logs, and traces to provide full visibility into system behavior and failures.\n\n**Implementation:**\n- [Logging strategy: structured logging, correlation IDs]\n- [Metrics collection: Prometheus, CloudWatch, etc.]\n- [Tracing: distributed tracing tools]\n- [Dashboards and alerting setup]\n\n**Trade-offs:**\n- [Storage and processing overhead for metrics/logs]\n- [Additional infrastructure cost]\n\n### 6. Resilience\n\n**Description:**\nSystem degrades gracefully under failure with automatic handling of transient issues and isolation of persistent failures.\n\n**Implementation:**\n- [Retry strategies: exponential backoff]\n- [Circuit breakers and bulkheads]\n- [Timeouts and dead-letter queues]\n- [Graceful degradation patterns]\n\n**Trade-offs:**\n- [Increased complexity in error handling logic]\n- [Potential for delayed failure detection]\n\n### 7. Simplicity\n\n**Description:**\nChoose the simplest solution that meets requirements, avoiding over-engineering and unnecessary complexity.\n\n**Implementation:**\n- [Technology choices favoring simplicity]\n- [Design patterns chosen for clarity]\n- [Examples of choosing simple over complex solutions]\n\n**Trade-offs:**\n- [May require refactoring as requirements grow]\n- [Balance between simplicity and flexibility]\n\n### 8. Cloud-Native\n\n**Description:**\nDesign for cloud deployment and orchestration, leveraging cloud platform capabilities.\n\n**Implementation:**\n- [Container orchestration: Kubernetes, ECS, etc.]\n- [Cloud services utilized: managed databases, message queues]\n- [Infrastructure as Code approach]\n- [12-factor app principles applied]\n\n**Trade-offs:**\n- [Potential vendor lock-in]\n- [Cloud provider dependency]\n\n### 9. Open Standards\n\n**Description:**\nPrefer open standards over proprietary solutions to ensure interoperability and avoid vendor lock-in.\n\n**Implementation:**\n- [Standard protocols: REST, gRPC, OpenAPI]\n- [Open source technologies chosen]\n- [Industry standards followed]\n\n**Trade-offs:**\n- [May miss proprietary optimizations]\n- [Potential performance trade-offs]\n\n### 10. Decouple Through Events *(Optional - apply selectively)*\n\n**Description:**\nUse asynchronous domain events to decouple components where temporal independence and scalability are prioritized over immediate consistency.\n\n**Implementation:**\n- **Synchronous Patterns**: [Describe where sync APIs are used, e.g., REST for user-facing operations]\n- **Asynchronous Patterns**: [Describe where async events are used, e.g., Kafka for background processing]\n- [Consumer groups, idempotency, schema management]\n\n**When to Use Async:**\n- [Scenarios where async is appropriate, e.g., background jobs, notifications]\n\n**When to Use Sync:**\n- [Scenarios requiring sync, e.g., user-facing APIs, immediate feedback needed]\n\n**Trade-offs:**\n- Eventual consistency requires careful handling in business logic\n- Increased debugging complexity for async flows\n- Not all interactions benefit from async (user-facing APIs need immediate responses)\n- [Additional trade-offs specific to your implementation]\n```\n\n**Important Notes:**\n\n- All 9 core principles are **required** in every ARCHITECTURE.md\n- Principles must appear in the **exact order** listed above\n- Each principle must include all three subsections: **Description**, **Implementation**, and **Trade-offs**\n- The **Implementation** section must be customized with system-specific details (not generic placeholders)\n- The **Trade-offs** section must honestly assess the costs and downsides\n- Decouple Through Events (principle #10) is **optional** and should only be included where asynchronous patterns provide clear benefits for temporal decoupling and scalability\n\n---\n\n## Section 4: Meta Architecture\n\n**Purpose**: Define the architecture model that organizes system components according to their responsibilities and functions.\n\n**Architecture Type**: This section's structure depends on your chosen architecture type. The skill automatically loads the appropriate template based on your selection.\n\n**Available Templates**:\n- `templates/SECTION_4_MICROSERVICES.md` - **Microservices (Recommended)** - API Gateway, Service Mesh, Services, Event Bus, cloud-native patterns\n- `templates/SECTION_4_META.md` - META 6-layer model (Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Integration ‚Üí Domain ‚Üí Core)\n- `templates/SECTION_4_3TIER.md` - Classic 3-tier (Presentation ‚Üí Application/Business Logic ‚Üí Data)\n- `templates/SECTION_4_NLAYER_PATTERNS.md` - Customizable N-layer patterns (DDD, Clean Architecture, Hexagonal)\n\n**Note**: The Microservices Architecture template is shown below as the recommended default example. When creating your ARCHITECTURE.md, the skill will prompt for architecture type selection and load the corresponding template.\n\n---\n\n## Microservices Architecture Components (Recommended Default Template)\n\n## Architecture Overview\n\n| Component Layer | Function |\n|----------------|----------|\n| **API Gateway** | Single entry point for clients, handles routing, authentication, rate limiting, and request aggregation. |\n| **Service Mesh** | Infrastructure layer managing service-to-service communication, observability, and resilience. |\n| **Microservices** | Independently deployable services implementing bounded contexts and business capabilities. |\n| **Data Stores** | Decentralized data management with database-per-service pattern. |\n| **Event Bus** | Asynchronous communication backbone for event-driven interactions between services. |\n| **Supporting Infrastructure** | Configuration, service discovery, secrets management, and cross-cutting concerns. |\n\n---\n\n### Component Documentation Template\n\nFor each component layer, document the following information:\n\n**Template:**\n```markdown\n## Microservices Architecture Components\n\n### API Gateway\n\n**Purpose**: [What the API Gateway provides to clients]\n\n**Capabilities**:\n- Request routing and load balancing\n- Authentication and authorization (JWT, OAuth 2.0)\n- Rate limiting and throttling\n- Request/response transformation\n- API composition and aggregation\n\n**Technologies**:\n- Primary: [Kong, AWS API Gateway, Azure API Management, etc.]\n- Supporting: [Authentication provider, caching layer]\n\n**Key Responsibilities**:\n- Centralized authentication\n- API versioning management\n- Cross-cutting concerns (CORS, compression)\n- Client-specific API composition (BFF pattern)\n\n**Communication Patterns**:\n- Inbound: HTTPS from external clients\n- Outbound: HTTP/gRPC to microservices\n- Protocols: [REST, GraphQL, gRPC]\n\n**Non-Functional Requirements**:\n- Performance: [Latency overhead, throughput]\n- Availability: [High availability setup]\n- Scalability: [Concurrent connections capacity]\n\n---\n\n### Service Mesh\n\n**Purpose**: [What the service mesh provides to services]\n\n**Capabilities**:\n- Service-to-service authentication (mTLS)\n- Traffic management (canary deployments, circuit breaking)\n- Observability (distributed tracing, metrics)\n- Resilience (retries, timeouts, circuit breakers)\n\n**Technologies**:\n- Primary: [Istio, Linkerd, Consul Connect, AWS App Mesh]\n- Supporting: [Envoy proxy, Jaeger, Prometheus]\n\n**Key Responsibilities**:\n- Automatic mTLS for service communication\n- Traffic shaping and routing\n- Distributed tracing injection\n- Health checks and circuit breaking\n\n**Communication Patterns**:\n- Sidecar proxy pattern\n- Control plane ‚Üî data plane communication\n- Protocols: [gRPC for control plane, HTTP/gRPC for data plane]\n\n**Non-Functional Requirements**:\n- Performance: [Proxy overhead <10ms p99]\n- Availability: [Control plane redundancy]\n- Scalability: [Support for N services]\n\n---\n\n### Microservices\n\n**Purpose**: [What microservices provide to the system]\n\nDocument each microservice using this template:\n\n#### Service: [Service Name]\n\n**Bounded Context**: [Domain/business capability this service owns]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Technologies**:\n- Primary: [Language, framework - e.g., Java/Spring Boot, Node.js/Express, Go]\n- Supporting: [Libraries, tools]\n\n**API Endpoints**:\n- `POST /api/v1/resource`: [Description]\n- `GET /api/v1/resource/{id}`: [Description]\n- `PUT /api/v1/resource/{id}`: [Description]\n\n**Data Store**:\n- Type: [PostgreSQL, MongoDB, DynamoDB, etc.]\n- Schema: [Brief description or link to schema]\n- Data Ownership: [What data this service owns]\n\n**Events Published**:\n- `resource.created`: [When and what data]\n- `resource.updated`: [When and what data]\n\n**Events Consumed**:\n- `other.event`: [From which service, what action taken]\n\n**Dependencies**:\n- Upstream Services: [Services this service calls]\n- Downstream Services: [Services that call this service]\n\n**Non-Functional Requirements**:\n- Performance: [Response time, throughput]\n- Availability: [SLA, redundancy]\n- Scalability: [Scaling strategy, resource limits]\n\n---\n\n### Data Stores (Database-per-Service)\n\n**Purpose**: [Decentralized data management strategy]\n\n**Pattern**: Database-per-Service\n\n**Data Stores**:\n\n| Service | Database Type | Technology | Purpose |\n|---------|--------------|------------|---------|\n| Service A | Relational | PostgreSQL | [Transactional data] |\n| Service B | Document | MongoDB | [Flexible schema] |\n| Service C | Key-Value | Redis | [Caching, sessions] |\n\n**Data Consistency Strategy**:\n- **Saga Pattern**: [For distributed transactions]\n- **Event Sourcing**: [If applicable]\n- **CQRS**: [If applicable]\n- **Eventual Consistency**: [How handled]\n\n**Data Synchronization**:\n- Method: [Events, CDC, scheduled sync]\n- Tools: [Kafka, Debezium, custom]\n\n**Non-Functional Requirements**:\n- Performance: [Query latency, throughput]\n- Availability: [Backup strategy, failover]\n- Scalability: [Sharding, replication]\n\n---\n\n### Event Bus\n\n**Purpose**: [Asynchronous communication and event streaming]\n\n**Capabilities**:\n- Event publishing and subscription\n- Event ordering and partitioning\n- Event replay and history\n- Dead-letter queue handling\n\n**Technologies**:\n- Primary: [Kafka, RabbitMQ, AWS EventBridge, Azure Event Hubs]\n- Supporting: [Schema registry, monitoring]\n\n**Event Topics**:\n\n| Topic | Producers | Consumers | Purpose |\n|-------|-----------|-----------|---------|\n| `topic.name` | [Services] | [Services] | [What events flow here] |\n\n**Key Responsibilities**:\n- Reliable event delivery\n- Event schema validation\n- Event retention and replay\n- Topic partitioning for scalability\n\n**Communication Patterns**:\n- Pub/Sub model\n- Event sourcing (if applicable)\n- CQRS read model updates\n\n**Non-Functional Requirements**:\n- Performance: [Throughput, latency]\n- Availability: [Replication factor, durability]\n- Scalability: [Partitioning strategy, consumer groups]\n\n---\n\n### Supporting Infrastructure\n\n**Purpose**: [Cross-cutting infrastructure services]\n\n**Components**:\n\n#### Service Discovery\n- Technology: [Consul, Eureka, Kubernetes DNS]\n- Purpose: Dynamic service registration and lookup\n\n#### Configuration Management\n- Technology: [Spring Cloud Config, Consul KV, Kubernetes ConfigMaps]\n- Purpose: Centralized configuration for all services\n\n#### Secrets Management\n- Technology: [HashiCorp Vault, AWS Secrets Manager, Azure Key Vault]\n- Purpose: Secure storage and rotation of secrets\n\n#### Distributed Logging\n- Technology: [ELK Stack, Splunk, CloudWatch]\n- Purpose: Centralized log aggregation and search\n\n#### Monitoring & Alerting\n- Technology: [Prometheus, Grafana, Datadog, New Relic]\n- Purpose: Metrics collection and visualization\n\n**Non-Functional Requirements**:\n- Performance: [Minimal performance overhead]\n- Availability: [High availability for critical infrastructure]\n- Scalability: [Support system growth]\n```\n\n**Example Implementation:**\n\n```markdown\n## Microservices Architecture Components\n\n### API Gateway\n\n**Purpose**: Provide unified entry point for e-commerce platform clients (web, mobile, partners).\n\n**Capabilities**:\n- Request routing to appropriate microservices\n- JWT authentication and OAuth 2.0 authorization\n- Rate limiting per client tier (free: 100 req/min, premium: 1000 req/min)\n- Request/response transformation and aggregation\n- API composition for mobile and web clients\n\n**Technologies**:\n- Primary: Kong API Gateway, Redis (rate limiting)\n- Supporting: Auth0 (authentication), DataDog (monitoring)\n\n**Key Responsibilities**:\n- Centralized authentication and JWT validation\n- API versioning (v1, v2) management\n- CORS, compression, and caching\n- Backend-for-Frontend (BFF) pattern for mobile/web\n\n**Communication Patterns**:\n- Inbound: HTTPS from web/mobile clients, partners\n- Outbound: HTTP/gRPC to Order, Product, User microservices\n- Protocols: REST (external), gRPC (internal services)\n\n**Non-Functional Requirements**:\n- Performance: <20ms p99 latency overhead\n- Availability: 99.99% uptime (4x instances, load balanced)\n- Scalability: Handle 10,000 concurrent connections\n\n---\n\n### Service Mesh\n\n**Purpose**: Manage secure service-to-service communication and observability.\n\n**Capabilities**:\n- Automatic mTLS between all microservices\n- Traffic management (canary: 10% traffic, blue-green deployments)\n- Distributed tracing with Jaeger\n- Circuit breakers and retry policies\n\n**Technologies**:\n- Primary: Istio with Envoy proxies\n- Supporting: Jaeger (tracing), Prometheus (metrics), Grafana (visualization)\n\n**Key Responsibilities**:\n- Zero-trust security with mTLS\n- Canary deployments for gradual rollouts\n- Request tracing across microservices\n- Automatic health checks and failover\n\n**Communication Patterns**:\n- Sidecar proxy per microservice pod\n- Control plane (Istiod) manages configuration\n- Protocols: gRPC (control plane), HTTP/gRPC (data plane)\n\n**Non-Functional Requirements**:\n- Performance: <5ms p99 proxy overhead\n- Availability: Control plane: 3 replicas, HA setup\n- Scalability: Support 50+ microservices\n\n---\n\n### Microservices\n\n**Purpose**: Implement business capabilities as independently deployable services.\n\n#### Service: Order Service\n\n**Bounded Context**: Order Management\n\n**Responsibilities**:\n- Create and manage customer orders\n- Order status tracking and updates\n- Integration with inventory and payment services\n- Order history and cancellation\n\n**Technologies**:\n- Primary: Java 17, Spring Boot 3.1, Spring Cloud\n- Supporting: Resilience4j (circuit breakers), OpenAPI 3.0\n\n**API Endpoints**:\n- `POST /api/v1/orders`: Create new order\n- `GET /api/v1/orders/{id}`: Get order details\n- `PUT /api/v1/orders/{id}/status`: Update order status\n- `DELETE /api/v1/orders/{id}`: Cancel order\n\n**Data Store**:\n- Type: PostgreSQL 15\n- Schema: orders, order_items, order_status_history tables\n- Data Ownership: All order-related data\n\n**Events Published**:\n- `order.created`: When order is placed (includes order ID, user ID, items)\n- `order.cancelled`: When order is cancelled\n- `order.completed`: When order is fulfilled\n\n**Events Consumed**:\n- `payment.confirmed`: From Payment Service (trigger order processing)\n- `inventory.reserved`: From Inventory Service (confirm stock availability)\n\n**Dependencies**:\n- Upstream Services: Payment Service, Inventory Service, User Service\n- Downstream Services: Notification Service, Analytics Service\n\n**Non-Functional Requirements**:\n- Performance: <100ms p95 response time\n- Availability: 99.95% SLA, 3 replicas minimum\n- Scalability: Horizontal scaling 3-20 instances based on CPU/memory\n\n---\n\n#### Service: Product Service\n\n**Bounded Context**: Product Catalog Management\n\n**Responsibilities**:\n- Product catalog management (CRUD)\n- Product search and filtering\n- Product recommendations\n- Inventory level integration\n\n**Technologies**:\n- Primary: Node.js 20, Express.js, TypeScript\n- Supporting: Elasticsearch (search), Redis (caching)\n\n**API Endpoints**:\n- `GET /api/v1/products`: List products with pagination\n- `GET /api/v1/products/{id}`: Get product details\n- `POST /api/v1/products/search`: Search products\n- `GET /api/v1/products/{id}/recommendations`: Get recommendations\n\n**Data Store**:\n- Type: MongoDB (primary), Elasticsearch (search index)\n- Schema: products collection with flexible schema for attributes\n- Data Ownership: Product catalog, descriptions, images, metadata\n\n**Events Published**:\n- `product.updated`: When product details change\n- `product.created`: When new product added\n\n**Events Consumed**:\n- `inventory.updated`: From Inventory Service (update stock levels)\n\n**Dependencies**:\n- Upstream Services: Inventory Service (stock levels)\n- Downstream Services: Recommendation Engine, Search Service\n\n**Non-Functional Requirements**:\n- Performance: <50ms p95 for product details, <200ms for search\n- Availability: 99.99% SLA, read replicas for high availability\n- Scalability: Auto-scale 5-30 instances, ElastiCache for hot products\n\n---\n\n### Data Stores (Database-per-Service)\n\n**Purpose**: Decentralized data management ensuring service autonomy and scalability.\n\n**Pattern**: Database-per-Service\n\n**Data Stores**:\n\n| Service | Database Type | Technology | Purpose |\n|---------|--------------|------------|---------|\n| Order Service | Relational | PostgreSQL 15 | Transactional order data with ACID guarantees |\n| Product Service | Document | MongoDB 6.0 | Flexible product catalog with varied attributes |\n| User Service | Relational | PostgreSQL 15 | User accounts, profiles, preferences |\n| Analytics Service | Columnar | ClickHouse | High-performance analytics queries |\n| Session Service | Key-Value | Redis 7.0 | User sessions and temporary data |\n\n**Data Consistency Strategy**:\n- **Saga Pattern**: Orchestration for order workflow (order ‚Üí payment ‚Üí inventory ‚Üí fulfillment)\n- **Event Sourcing**: Order Service uses event sourcing for audit trail\n- **CQRS**: Analytics Service maintains read-optimized views\n- **Eventual Consistency**: Cross-service data sync via events within 5 seconds\n\n**Data Synchronization**:\n- Method: Event-driven via Kafka, Debezium CDC for legacy systems\n- Tools: Kafka Connect, custom event handlers\n\n**Non-Functional Requirements**:\n- Performance: <10ms p99 for primary key lookups\n- Availability: Multi-AZ deployment, automated backups every 6 hours\n- Scalability: Read replicas for high-traffic services, horizontal sharding for Order/User services\n\n---\n\n### Event Bus\n\n**Purpose**: Enable asynchronous, decoupled communication between microservices.\n\n**Capabilities**:\n- Event publishing with guaranteed delivery\n- Topic partitioning for parallel processing\n- Event replay for recovery and debugging\n- Dead-letter queues for failed events\n\n**Technologies**:\n- Primary: Apache Kafka 3.4 (5-node cluster)\n- Supporting: Confluent Schema Registry, Kafka Connect, Kafdrop (monitoring)\n\n**Event Topics**:\n\n| Topic | Producers | Consumers | Purpose |\n|-------|-----------|-----------|---------|\n| `orders.events` | Order Service | Analytics, Notification, Inventory | Order lifecycle events |\n| `payments.events` | Payment Service | Order, Analytics, Fraud Detection | Payment status updates |\n| `inventory.events` | Inventory Service | Order, Product, Analytics | Stock level changes |\n| `users.events` | User Service | Recommendation, Analytics, Marketing | User activity tracking |\n\n**Key Responsibilities**:\n- Reliable event delivery with at-least-once semantics\n- Avro schema validation via Schema Registry\n- 7-day event retention for replay\n- 10 partitions per topic for parallelism\n\n**Communication Patterns**:\n- Pub/Sub for domain events\n- Event sourcing for Order Service\n- CQRS read model updates for Analytics Service\n\n**Non-Functional Requirements**:\n- Performance: <5ms p99 publish latency, 50K events/second throughput\n- Availability: Replication factor 3, min in-sync replicas 2\n- Scalability: Dynamic partition rebalancing, consumer groups for load distribution\n\n---\n\n### Supporting Infrastructure\n\n**Purpose**: Provide cross-cutting infrastructure services for all microservices.\n\n**Components**:\n\n#### Service Discovery\n- Technology: Kubernetes DNS + Consul\n- Purpose: Dynamic service registration and health-aware routing\n\n#### Configuration Management\n- Technology: Spring Cloud Config Server + Kubernetes ConfigMaps\n- Purpose: Centralized configuration with environment-specific overrides\n\n#### Secrets Management\n- Technology: HashiCorp Vault + Kubernetes Secrets\n- Purpose: Secure storage of API keys, DB credentials, certificates with auto-rotation\n\n#### Distributed Logging\n- Technology: ELK Stack (Elasticsearch, Logstash, Kibana) + Filebeat\n- Purpose: Centralized log aggregation with full-text search and dashboards\n\n#### Monitoring & Alerting\n- Technology: Prometheus + Grafana + Alertmanager\n- Purpose: Metrics collection (CPU, memory, request rates), custom dashboards, PagerDuty integration\n\n**Non-Functional Requirements**:\n- Performance: <1% overhead from logging/monitoring\n- Availability: HA deployment for Vault and Consul (3 replicas)\n- Scalability: Support 50+ services with centralized observability\n```\n\n---\n\n## Section 5: Component Details\n\n**Purpose**: Deep dive into each component within the architecture, organized according to your chosen architecture type.\n\n**Architecture Type**: This section's organization depends on your chosen architecture type. The skill automatically loads the appropriate template based on your selection.\n\n**Available Templates**:\n- `templates/SECTION_5_META.md` - Components grouped by 6 META layers\n- `templates/SECTION_5_3TIER.md` - Components grouped by 3 tiers (Presentation, Application, Data)\n- `templates/SECTION_5_MICROSERVICES.md` - Microservice catalog with comprehensive service details\n\n**Note**: The generic component template is shown below. When creating your ARCHITECTURE.md, the skill will load the type-specific template that matches your Section 4 architecture type.\n\n---\n\n## Generic Component Template (All Architecture Types)\n\n### Component Template\n```markdown\n### Component Name\n\n**Type**: Service | Database | Message Queue | Cache | Gateway\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints]\n- API 2: [Description, endpoints]\n\n**Dependencies**:\n- Depends on: [Other components this depends on]\n- Depended by: [Components that depend on this]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n```\n\n**Example:**\n\n> **Note:** The following example uses illustrative file paths (`services/user-service/`, `proto/user/v1/user.proto`) that represent a typical microservices project structure. When documenting your own system, replace these with your actual project paths.\n\n```markdown\n### User Service\n\n**Type**: Microservice\n**Technology**: Go 1.21 + gRPC\n**Version**: v2.3.1\n**Location**: `services/user-service/` *(example path)*\n\n**Purpose**:\nManages user identity, authentication, and profile information.\n\n**Responsibilities**:\n- User registration and authentication\n- Profile management\n- Session management\n- Role-based access control (RBAC)\n\n**APIs/Interfaces**:\n- gRPC API: `UserService` (see proto/user/v1/user.proto)\n- REST API: `/api/v1/users/*` (via API Gateway transcoding)\n- Events: Publishes to `user.created`, `user.updated` topics\n\n**Dependencies**:\n- PostgreSQL: User data persistence\n- Redis: Session cache\n- NATS: Event publishing\n\n**Configuration**:\n- `DB_CONNECTION_STRING`: PostgreSQL connection (required)\n- `SESSION_TTL`: Session timeout in seconds (default: 3600)\n- `BCRYPT_COST`: Password hashing cost (default: 12)\n\n**Scaling**:\n- Horizontal: Stateless, scales linearly with load\n- Vertical: 2 vCPU, 4GB RAM per instance\n\n**Failure Modes**:\n- Database unavailable: Returns 503, sessions fail to persist\n- Redis unavailable: Falls back to database sessions (slower)\n- NATS unavailable: Events queued locally, retry on reconnect\n\n**Monitoring**:\n- Metrics: Request rate, latency, error rate, active sessions\n- Alerts: Error rate > 1%, p99 latency > 500ms\n- Logs: All authentication attempts, errors\n```\n\n---\n\n## Section 6: Data Flow Patterns\n\n**Purpose**: Document how data moves through the system for key operations.\n\n**Template:**\n```markdown\n## Data Flow Patterns\n\n### [Operation Name] Flow\n\n**Flow Steps**:\n1. Component A ‚Üí Component B: [Action]\n2. Component B ‚Üí Component C: [Action]\n[Continue for key steps]\n\n**Performance**: [Latency p50/p99, throughput]\n**Error Handling**: [Key error scenarios and mitigations]\n\n### [Event Name] Event Flow\n\n**Event**: `event.name.v1`\n**Publisher**: [Component]\n**Subscribers**: [Components]\n**Guarantees**: [Delivery, ordering, retention]\n```\n\n---\n\n## Section 7: Integration Points\n\n**Purpose**: Document all external integrations and third-party dependencies.\n\n**Template:**\n```markdown\n## Integration Points\n\n### [Integration Name]\n\n**Type**: REST API | gRPC | Message Queue | Database | SaaS\n**Provider**: [Company/service name]\n**Purpose**: [Why we integrate with this]\n\n**Integration Details**:\n- Protocol: [HTTP/HTTPS, gRPC, AMQP, etc.]\n- Authentication: [API key, OAuth, mTLS, etc.]\n- Endpoints: [Base URL, key endpoints]\n- Rate Limits: [Requests per second/minute]\n- SLA: [Uptime guarantee, support level]\n\n**Data Exchanged**:\n- Outbound: [What we send]\n- Inbound: [What we receive]\n\n**Error Handling**:\n- Timeout: [Timeout value, retry logic]\n- Rate limiting: [Backoff strategy]\n- Service unavailable: [Fallback behavior]\n\n**Monitoring**:\n- Health check: [How we monitor availability]\n- Metrics: [Integration-specific metrics]\n\n**Security**:\n- Credentials: [How stored (secrets manager, etc.)]\n- Encryption: [TLS version, cipher suites]\n- IP Whitelisting: [If applicable]\n\n**Cost**:\n- Pricing model: [Per request, monthly, etc.]\n- Expected monthly cost: [Estimate]\n\n**Documentation**:\n- API Docs: [Link]\n- Support: [Contact method]\n```\n\n---\n\n## Section 8: Technology Stack\n\n**Purpose**: Comprehensive list of all technologies used in the system.\n\n**Template:**\n```markdown\n## Technology Stack\n\n### Languages\n| Language | Version | Use Case | Justification |\n|----------|---------|----------|---------------|\n| Go | 1.21+ | Backend services | Performance, concurrency |\n| TypeScript | 5.0+ | Frontend | Type safety |\n| Python | 3.11+ | Data processing | Libraries, ecosystem |\n\n### Frameworks & Libraries\n| Framework | Version | Component | Purpose |\n|-----------|---------|-----------|---------|\n| gRPC | 1.60+ | API layer | Inter-service communication |\n| Vue 3 | 3.4+ | Frontend | UI framework |\n\n### Databases\n| Database | Version | Use Case | Data Type |\n|----------|---------|----------|-----------|\n| PostgreSQL | 16+ | Primary DB | Transactional data |\n| Redis | 7.0+ | Cache | Session, temp data |\n| ScyllaDB | 5.0+ | Time-series | Events, metrics |\n\n### Infrastructure\n| Service | Version | Purpose |\n|---------|---------|---------|\n| Kubernetes | 1.28+ | Orchestration |\n| Docker | 24+ | Containerization |\n| Terraform | 1.6+ | IaC |\n\n### Observability\n| Tool | Purpose |\n|------|---------|\n| Prometheus | Metrics collection |\n| Grafana | Metrics visualization |\n| Jaeger | Distributed tracing |\n| ELK Stack | Log aggregation |\n\n### Security\n| Tool | Purpose |\n|------|---------|\n| HashiCorp Vault | Secrets management |\n| cert-manager | Certificate management |\n| OWASP ZAP | Security testing |\n\n### CI/CD\n| Tool | Purpose |\n|------|---------|\n| GitHub Actions | CI/CD pipelines |\n| ArgoCD | GitOps deployment |\n| Trivy | Container scanning |\n```\n\n---\n\n## Section 9: Security Architecture\n\n**Purpose**: Document security controls, threat model, and compliance requirements.\n\n**Template:**\n```markdown\n## Security Architecture\n\n### Security Principles\n1. **Defense in Depth**: Multiple layers of security controls\n2. **Least Privilege**: Minimum necessary permissions\n3. **Zero Trust**: Verify everything, trust nothing\n4. **Encryption Everywhere**: Data encrypted in transit and at rest\n\n### Threat Model\n\n**Assets**:\n- User data (PII, credentials)\n- Financial transactions\n- API keys and secrets\n- Intellectual property\n\n**Threats**:\n1. **Unauthorized Access**: [Mitigation]\n2. **Data Breach**: [Mitigation]\n3. **DDoS Attack**: [Mitigation]\n4. **SQL Injection**: [Mitigation]\n5. **Man-in-the-Middle**: [Mitigation]\n\n### Security Controls\n\n**Authentication & Authorization**:\n- Method: [OAuth 2.0, JWT, mTLS, etc.]\n- Session management: [Approach]\n- MFA: [Required for whom]\n- RBAC: [Role model]\n\n**Network Security**:\n- Network segmentation: [VPCs, subnets]\n- Firewall rules: [Ingress/egress]\n- DDoS protection: [Service/approach]\n- WAF: [Rules, provider]\n\n**Data Security**:\n- Encryption at rest: [Algorithm, key management]\n- Encryption in transit: [TLS version]\n- PII handling: [Tokenization, masking]\n- Backup encryption: [Approach]\n\n**Application Security**:\n- Input validation: [Framework, approach]\n- Output encoding: [Method]\n- CSRF protection: [Tokens]\n- Rate limiting: [Per endpoint, global]\n\n**Secrets Management**:\n- Storage: [HashiCorp Vault, AWS Secrets Manager, etc.]\n- Rotation: [Frequency, automation]\n- Access control: [IAM policies]\n\n**Compliance**:\n- Standards: [SOC 2, PCI-DSS, GDPR, HIPAA, etc.]\n- Audit logging: [What, where, retention]\n- Data residency: [Requirements, implementation]\n\n### Security Monitoring\n\n**Detection**:\n- IDS/IPS: [Tool, rules]\n- Anomaly detection: [ML-based, rules-based]\n- Vulnerability scanning: [Tool, frequency]\n\n**Response**:\n- Incident response plan: [Link to runbook]\n- Security team contact: [On-call rotation]\n- Breach notification: [Process, timeline]\n```\n\n---\n\n## Section 10: Scalability & Performance\n\n**Purpose**: Document how the system scales and performance characteristics.\n\n**Template:**\n```markdown\n## Scalability & Performance\n\n### Scalability Model\n\n**Horizontal Scaling**:\n| Component | Scaling Strategy | Limits |\n|-----------|-----------------|--------|\n| API Gateway | Auto-scale 2-50 instances | CPU > 70% |\n| App Services | Auto-scale 3-100 instances | Request queue > 100 |\n| Database | Read replicas (5 max) | Replication lag < 100ms |\n\n**Vertical Scaling**:\n| Component | Min Resources | Max Resources |\n|-----------|--------------|---------------|\n| App Service | 2 vCPU, 4GB RAM | 8 vCPU, 16GB RAM |\n| Database | 4 vCPU, 16GB RAM | 32 vCPU, 128GB RAM |\n\n**Data Partitioning**:\n- Strategy: [Sharding, partitioning approach]\n- Partition key: [Field used for partitioning]\n- Rebalancing: [Automated or manual]\n\n### Performance Targets\n\n**Latency**:\n| Operation | p50 | p95 | p99 |\n|-----------|-----|-----|-----|\n| Read API | <50ms | <100ms | <200ms |\n| Write API | <100ms | <200ms | <500ms |\n| Batch Job | N/A | N/A | <30min |\n\n**Throughput**:\n\n| Category | Average TPS | Peak TPS | Measurement Period |\n|----------|-------------|----------|--------------------|\n| Read TPS | [Value] transactions/second | [Value] transactions/second | [Time frame, e.g., \"Average over last 30 days; Peak during event X\"] |\n| Processing TPS | [Value] transactions/second | [Value] transactions/second | [Time frame, e.g., \"Average over last quarter; Peak during batch processing\"] |\n| Write TPS | [Value] transactions/second | [Value] transactions/second | [Time frame, e.g., \"Average over last month; Peak during migration\"] |\n\n**Note**: These TPS metrics should match the values documented in Section 1: Executive Summary, Key Metrics.\n\n**Capacity Planning**:\n- Current load: [Metrics]\n- Growth projection: [% per month/year]\n- Capacity headroom: [Safety margin]\n- Next scaling milestone: [When, what action]\n\n### Performance Optimization\n\n**Caching Strategy**:\n- L1 (Application): [In-memory cache, TTL]\n- L2 (Distributed): [Redis, TTL]\n- CDN: [CloudFlare, assets cached]\n\n**Database Optimization**:\n- Indexing strategy: [Key indexes]\n- Query optimization: [Approach]\n- Connection pooling: [Pool size, timeout]\n\n**Async Processing**:\n- Message queue: [Technology]\n- Background jobs: [Framework]\n- Batch processing: [Schedule, size]\n```\n\n---\n\n## Section 11: Operational Considerations\n\n**Purpose**: Document deployment, monitoring, and operational procedures.\n\n**Template:**\n```markdown\n## Operational Considerations\n\n### Deployment\n\n**Environments**:\n- Development: [Purpose, update frequency]\n- Staging: [Purpose, resembles production]\n- Production: [Multi-region, HA setup]\n\n**Deployment Strategy**:\n- Method: [Blue-green, rolling, canary]\n- Rollback procedure: [Automated, manual]\n- Deployment frequency: [Daily, weekly, on-demand]\n- Deployment windows: [Anytime, maintenance windows]\n\n**Infrastructure as Code**:\n- Tool: [Terraform, CloudFormation, etc.]\n- Repository: [Git repo location]\n- State management: [Remote state, locking]\n\n### Monitoring & Observability\n\n**Metrics**:\n- **Golden Signals**: Latency, Traffic, Errors, Saturation\n- **Business Metrics**: [Revenue, conversions, etc.]\n- **Infrastructure Metrics**: [CPU, memory, disk, network]\n\n**Dashboards**:\n- Overview: [System health at a glance]\n- Service-specific: [Per-service deep dive]\n- Infrastructure: [Host, container metrics]\n\n**Alerting**:\n| Alert | Threshold | Severity | On-call |\n|-------|-----------|----------|---------|\n| API error rate | >1% | Critical | Yes |\n| Database CPU | >80% | Warning | No |\n| Disk space | <10% | Critical | Yes |\n\n**Logging**:\n- Format: [JSON, structured]\n- Aggregation: [ELK, Loki, CloudWatch]\n- Retention: [Duration per log level]\n- PII handling: [Redaction, masking]\n\n### Backup & Disaster Recovery\n\n**Backup Strategy**:\n| Data Store | Frequency | Retention | Location |\n|------------|-----------|-----------|----------|\n| PostgreSQL | Hourly | 30 days | S3 + Glacier |\n| Redis | Daily | 7 days | S3 |\n| File storage | Daily | 90 days | S3 + vault |\n\n**Disaster Recovery**:\n- RTO (Recovery Time Objective): [Target]\n- RPO (Recovery Point Objective): [Target]\n- Failover procedure: [Automated, manual]\n- DR testing: [Frequency, procedure]\n\n### Cost Management\n\n**Cost Breakdown**:\n| Service | Monthly Cost | Percentage |\n|---------|-------------|------------|\n| Compute | $X,XXX | XX% |\n| Storage | $X,XXX | XX% |\n| Network | $X,XXX | XX% |\n| Managed Services | $X,XXX | XX% |\n| **Total** | **$XX,XXX** | **100%** |\n\n**Optimization Opportunities**:\n- Reserved instances: [Potential savings]\n- Storage tiering: [Cold data archival]\n- Resource right-sizing: [Over-provisioned services]\n```\n\n---\n\n## Section 12: Architecture Decision Records (ADRs)\n\n**Purpose**: Document key architectural decisions in separate ADR files.\n\nArchitecture decisions should be documented using Architecture Decision Records (ADRs). For complete guidance on creating and managing ADRs, see [ADR_GUIDE.md](ADR_GUIDE.md).\n\n**Template:**\n```markdown\n## Architecture Decision Records\n\nArchitectural decisions are documented in ADRs. See [ADR_GUIDE.md](ADR_GUIDE.md) for the complete ADR template and guidelines.\n\n### Active ADRs\n\n| ID | Title | Status | Date | Impact |\n|----|-------|--------|------|--------|\n| [ADR-001](adr/ADR-001.md) | [Title] | Accepted | YYYY-MM-DD | High/Medium/Low |\n```\n\n**Automatic ADR File Generation**:\n\nWhen using the architecture-docs skill to create ARCHITECTURE.md, you will be prompted to automatically generate these ADR files. The skill will:\n- Read the table above\n- Create each ADR file in the `adr/` directory\n- Populate metadata (title, status, date) from the table\n- Use the standard template (`adr/ADR-000-template.md`)\n\nYou can skip automatic generation and create ADRs manually as architectural decisions are made. To add ADRs later, simply update this table and manually create the files using the template.\n\nFor complete ADR creation guide and template details, see: [ADR_GUIDE.md](ADR_GUIDE.md)\n\n---\n\n## References\n\n**Related Guides:**\n- [ADR_GUIDE.md](ADR_GUIDE.md) - Complete guide for Architecture Decision Records\n- [MERMAID_DIAGRAMS_GUIDE.md](MERMAID_DIAGRAMS_GUIDE.md) - Complete Mermaid architecture diagram instructions\n\n**External Resources:**\n- [C4 Model](https://c4model.com/) - Architecture diagram approach\n- [arc42](https://arc42.org/) - Architecture documentation template\n- [BIAN](https://bian.org/) - Banking Industry Architecture Network (General Overview)\n- [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) - Official Service Domain Definitions (Default Version for META Architecture)\n- **BIAN V12.0 Default**: V12.0 is the default and recommended version for all META architecture implementations\n\n---\n\n**Document Version**: 2.0.0\n**Last Updated**: 2025-01-18\n**Maintained By**: Architecture Team",
        "skills/architecture-docs/DESIGN_DRIVER_CALCULATIONS.md": "# Design Driver Calculations\n\n> Implementation algorithms for automatically calculating Design Drivers impact metrics from ARCHITECTURE.md data\n\n## Purpose\n\nThis document provides detailed implementation algorithms for Design Drivers calculation. Design Drivers assess architecture impact across three dimensions:\n\n1. **Value Delivery**: Effectiveness of change in customer experience\n2. **Scale**: Estimated number of customers/transactions impacted\n3. **Impacts**: Implementation complexity (configuration, development, deployment)\n\n## Related Documentation\n\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Conceptual overview, templates, and thresholds (primary reference for content authors)\n- **SKILL.md**: Operational workflows and when to trigger calculations\n- **METRIC_CALCULATIONS.md**: Metric extraction and index update algorithms\n\n---\n\n## Overview\n\n**Purpose**: Automatically assess architecture impact across three dimensions to justify complexity and communicate value to stakeholders.\n\n**When to Use**:\n- Architecture reviews, audits, or assessments\n- Explicit user requests: \"calculate design drivers\", \"update design drivers\"\n- Quarterly architecture reviews\n\n**Data Sources**:\n- Section 1 Executive Summary (Business Value)\n- Section 2.3 Use Cases (Success Metrics)\n- Section 5 Component Details (Component count)\n- Section 8 Technology Stack (Technology count)\n\n**Output**: Impact assessment (HIGH/LOW) for each dimension with justifications and line number references\n\n---\n\n## Algorithm 1: Value Delivery\n\n**Definition**: Effectiveness of change in customer experience\n\n**Threshold**: >50% = HIGH Impact, ‚â§50% = LOW Impact\n\n**Data Source**: Section 1 Executive Summary - Business Value bullets\n\n**Extraction Pattern**:\n```regex\n(\\d{1,3})%\\s*(reduction|improvement|increase|efficiency|optimization|cost\\s*savings?|faster|time\\s*savings?|decrease)\n```\n\n### Calculation Logic\n\n**Step 1**: Read Section 1 Executive Summary (lines determined from Document Index)\n```bash\n# Load Document Index first to get Section 1 line range\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n# Parse index: Section 1 is lines 25-54\n\n# Load Section 1 with context buffer\nRead(file_path=\"ARCHITECTURE.md\", offset=20, limit=40)\n# Reads lines 20-60 (includes ¬±5 line buffer)\n```\n\n**Step 2**: Locate Business Value subsection\n```python\n# Pseudo-code\nbusiness_value_match = re.search(\n    r'\\*\\*Business Value:\\*\\*(.+?)(?=\\n\\n|\\n\\*\\*|$)',\n    section1_text,\n    re.DOTALL\n)\n```\n\n**Step 3**: Extract all percentage metrics from Business Value\n```python\n# Pseudo-code\npercentage_pattern = r'(\\d{1,3})%\\s*(reduction|improvement|increase|efficiency|optimization|cost\\s*savings?|faster|time\\s*savings?)'\n\nmatches = re.finditer(percentage_pattern, business_value_section, re.IGNORECASE)\n\npercentages = []\nfor match in matches:\n    percentage = int(match.group(1))\n    context = match.group(2)\n    line_offset = section1_text[:match.start()].count('\\n')\n    line_number = section1_start_line + line_offset\n    percentages.append({\n        'value': percentage,\n        'context': context,\n        'line': line_number\n    })\n```\n\n**Step 4**: Find maximum percentage value\n```python\n# Pseudo-code\nmax_metric = max(percentages, key=lambda x: x['value'])\n```\n\n**Step 5**: Apply threshold (>50%)\n```python\n# Pseudo-code\nimpact = 'HIGH' if max_metric['value'] > 50 else 'LOW'\n```\n\n**Step 6**: Generate justification\n```python\n# Pseudo-code\nreturn {\n    'impact': impact,\n    'justification': f\"System delivers {max_metric['value']}% {max_metric['context']} (Section 1, line {max_metric['line']})\",\n    'percentage': max_metric['value'],\n    'line': max_metric['line']\n}\n```\n\n### Example\n\n**Input**: Section 1 contains \"70% cost reduction\" at line 52\n\n**Output**:\n```json\n{\n  \"impact\": \"HIGH\",\n  \"justification\": \"System delivers 70% cost reduction (Section 1, line 52)\",\n  \"percentage\": 70,\n  \"line\": 52\n}\n```\n\n### Edge Cases\n\n**Case 1: No percentage metrics found**\n```python\nreturn {\n    'impact': 'LOW',\n    'justification': 'No quantifiable business value metrics found in Section 1',\n    'percentage': None,\n    'line': None\n}\n```\n\n**Case 2: Multiple percentages (use maximum)**\n```python\n# Example: 70%, 45%, 60% found\n# Use maximum: 70% ‚Üí HIGH Impact\n```\n\n**Case 3: Exactly 50% (threshold edge case)**\n```python\n# 50% exactly ‚Üí LOW Impact (threshold is >50, not ‚â•50)\n# Flag for user review with note\n```\n\n**Case 4: Percentage without clear context**\n```python\n# Found: \"50% [unclear context]\"\n# Extract but flag as ambiguous\n# Prompt user for clarification\n```\n\n---\n\n## Algorithm 2: Scale\n\n**Definition**: Estimated number of customers/transactions impacted\n\n**Threshold**: >100,000 = HIGH Impact, ‚â§100,000 = LOW Impact\n\n**Data Source**: Section 2.3 Use Cases - Success Metrics subsections\n\n**Extraction Pattern**:\n```regex\n(\\d{1,3}(?:,\\d{3})*)\\+?\\s*(?:per\\s*day|daily|customers?|users?|transactions?|reminders?|payments?|jobs?|records?)\n```\n\n### Calculation Logic\n\n**Step 1**: Read Section 2.3 Use Cases (lines determined from Document Index)\n```bash\n# Load Document Index to get Section 2.3 line range\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n# Parse index: Section 2 is lines 54-146, estimate 2.3 at ~100-165\n\n# Load Section 2.3 with context buffer\nRead(file_path=\"ARCHITECTURE.md\", offset=95, limit=75)\n# Reads lines 95-170 (includes buffer)\n```\n\n**Step 2**: Extract all volume metrics from Success Metrics\n```python\n# Pseudo-code\nvolume_pattern = r'(\\d{1,3}(?:,\\d{3})*)\\+?\\s*(?:per\\s*day|daily|customers?|users?|transactions?|reminders?|payments?|jobs?)'\n\nmatches = re.finditer(volume_pattern, section2_3_text, re.IGNORECASE)\n\nvolumes = []\nfor match in matches:\n    # Parse number (remove commas)\n    volume_str = match.group(1).replace(',', '')\n    volume = int(volume_str)\n    context = match.group(0)\n    line_offset = section2_3_text[:match.start()].count('\\n')\n    line_number = section2_3_start_line + line_offset\n    volumes.append({\n        'value': volume,\n        'context': context,\n        'line': line_number\n    })\n```\n\n**Step 3**: Find maximum volume\n```python\n# Pseudo-code\nmax_volume = max(volumes, key=lambda x: x['value'])\n```\n\n**Step 4**: Apply threshold (>100,000)\n```python\n# Pseudo-code\nimpact = 'HIGH' if max_volume['value'] > 100000 else 'LOW'\n```\n\n**Step 5**: Format justification with comma-separated volume\n```python\n# Pseudo-code\nvolume_formatted = f\"{max_volume['value']:,}\"  # 500000 ‚Üí \"500,000\"\n\nreturn {\n    'impact': impact,\n    'justification': f\"System impacts {volume_formatted} customers/transactions per day (Section 2.3, line {max_volume['line']})\",\n    'volume': max_volume['value'],\n    'line': max_volume['line']\n}\n```\n\n### Example\n\n**Input**: Section 2.3 contains \"500,000+ reminders per day\" at line 141\n\n**Output**:\n```json\n{\n  \"impact\": \"HIGH\",\n  \"justification\": \"System impacts 500,000 customers/day (Section 2.3, line 141)\",\n  \"volume\": 500000,\n  \"line\": 141\n}\n```\n\n### Edge Cases\n\n**Case 1: No volume metrics found**\n```python\nreturn {\n    'impact': 'LOW',\n    'justification': 'No volume metrics found in Use Cases success metrics',\n    'volume': None,\n    'line': None\n}\n```\n\n**Case 2: Plus sign (+) in volume**\n```python\n# \"500,000+ reminders per day\"\n# Extract: 500000\n# Note \"+\" indicates minimum, actual may be higher\n```\n\n**Case 3: Exactly 100,000 (threshold edge case)**\n```python\n# 100,000 exactly ‚Üí LOW Impact (threshold is >100K, not ‚â•100K)\n# Flag for user review\n```\n\n**Case 4: Multiple units (customers vs transactions)**\n```python\n# Found: \"500,000 customers\" and \"1,000,000 transactions\"\n# Use maximum: 1,000,000 ‚Üí HIGH Impact\n# Note both in context for user review\n```\n\n**Case 5: Volume without \"per day\" or \"daily\"**\n```python\n# \"Supports 500,000 users\"\n# May still be valid scale metric\n# Extract but flag for context review\n```\n\n---\n\n## Algorithm 3: Impacts\n\n**Definition**: Implementation complexity (configuration, development, deployment)\n\n**Threshold**: >5 total = HIGH Impact, ‚â§5 total = LOW Impact\n\n**Data Sources**:\n- Section 5 Component Details: Count component subsection headers\n- Section 8 Technology Stack: Count technology table rows\n\n**Extraction Methods**:\n- Components: Regex pattern `^###\\s+\\d+\\.\\d+` (H3 headers with numbering)\n- Technologies: Count table rows (excluding headers and separators)\n\n### Calculation Logic\n\n**Step 1**: Read Section 5 Component Details\n```bash\n# Load Document Index to get Section 5 line range\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n# Parse index: Section 5 is lines 456-675\n\n# Load Section 5 with context buffer\nRead(file_path=\"ARCHITECTURE.md\", offset=451, limit=230)\n# Reads lines 451-681 (includes buffer)\n```\n\n**Step 2**: Count component subsection headers\n```python\n# Pseudo-code\ncomponent_pattern = r'^###\\s+\\d+\\.\\d+\\s+.+$'\ncomponent_matches = re.findall(component_pattern, section5_text, re.MULTILINE)\ncomponent_count = len(component_matches)\n\n# Example matches:\n# \"### 5.1 Job Scheduler Service\"\n# \"### 5.2 Job Executor Service\"\n# \"### 5.3 PostgreSQL Database\"\n```\n\n**Step 3**: Read Section 8 Technology Stack\n```bash\n# Parse index: Section 8 is lines 912-998\n\n# Load Section 8 with context buffer\nRead(file_path=\"ARCHITECTURE.md\", offset=907, limit=96)\n# Reads lines 907-1003\n```\n\n**Step 4**: Count technology table rows\n```python\n# Pseudo-code\ntech_table_pattern = r'^\\|[^|]+\\|[^|]+\\|.+\\|$'\nseparator_pattern = r'^\\|\\s*-+\\s*\\|'\n\ntech_rows = []\nfor line in section8_text.split('\\n'):\n    if re.match(tech_table_pattern, line) and not re.match(separator_pattern, line):\n        tech_rows.append(line)\n\n# Count rows excluding headers\n# First row is typically header, subtract ~4-6 header rows across all tables\ntechnology_count = max(0, len(tech_rows) - 5)  # Conservative estimate\n```\n\n**Step 5**: Calculate total impacts\n```python\n# Pseudo-code\ntotal_impacts = component_count + technology_count\n```\n\n**Step 6**: Apply threshold (>5)\n```python\n# Pseudo-code\nimpact = 'HIGH' if total_impacts > 5 else 'LOW'\n```\n\n**Step 7**: Generate justification with breakdown\n```python\n# Pseudo-code\nreturn {\n    'impact': impact,\n    'justification': f\"System requires {total_impacts} components/technologies (Section 5: {component_count}, Section 8: {technology_count})\",\n    'component_count': component_count,\n    'technology_count': technology_count,\n    'total': total_impacts\n}\n```\n\n### Example\n\n**Input**:\n- Section 5 has 5 component subsections (### 5.1, 5.2, 5.3, 5.4, 5.5)\n- Section 8 has 8 technology table rows (3 after subtracting 5 header rows)\n\n**Output**:\n```json\n{\n  \"impact\": \"HIGH\",\n  \"justification\": \"System requires 8 components/technologies (Section 5: 5, Section 8: 3)\",\n  \"component_count\": 5,\n  \"technology_count\": 3,\n  \"total\": 8\n}\n```\n\n### Edge Cases\n\n**Case 1: Section 5 missing or empty**\n```python\n# Component count = 0\n# Use only Section 8 technology count\n# Note missing section in justification\n```\n\n**Case 2: Section 8 missing or empty**\n```python\n# Technology count = 0\n# Use only Section 5 component count\n# Note missing section in justification\n```\n\n**Case 3: Nested components (#### headers)**\n```python\n# Only count ### headers (H3)\n# Ignore #### headers (H4 sub-components)\n# Use strict pattern: ^###\\s+\\d+\\.\\d+\n```\n\n**Case 4: Multi-row table entries**\n```python\n# Technology tables may span multiple rows\n# Count conservatively (subtract more header rows)\n# Flag for manual review if count seems wrong\n```\n\n**Case 5: Exactly 5 total (threshold edge case)**\n```python\n# 5 exactly ‚Üí LOW Impact (threshold is >5, not ‚â•5)\n# Flag for user review\n```\n\n---\n\n## Sequential Loading Strategy\n\n**Goal**: Minimize context usage by loading sections one at a time\n\n**Context Reduction**: 75-80% vs. full document load\n\n### Loading Order\n\n1. **Document Index** (lines 1-50): Parse to get exact section ranges\n2. **Section 1** (lines ~25-54): Extract Value Delivery metrics\n3. **Section 2.3** (lines ~100-165): Extract Scale metrics\n4. **Section 5** (lines ~456-675): Count components\n5. **Section 8** (lines ~912-998): Count technologies\n\n### Context Optimization\n\n**Per-Section Loading**:\n```bash\n# Load one section at a time (not all simultaneously)\n# Example sequence:\n\n# Step 1: Index\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n# Process: Extract section line ranges\n\n# Step 2: Section 1\nRead(file_path=\"ARCHITECTURE.md\", offset=20, limit=40)\n# Process: Extract percentages, clear from memory\n\n# Step 3: Section 2.3\nRead(file_path=\"ARCHITECTURE.md\", offset=95, limit=75)\n# Process: Extract volumes, clear from memory\n\n# Step 4: Section 5\nRead(file_path=\"ARCHITECTURE.md\", offset=451, limit=230)\n# Process: Count components, clear from memory\n\n# Step 5: Section 8\nRead(file_path=\"ARCHITECTURE.md\", offset=907, limit=96)\n# Process: Count technologies, clear from memory\n```\n\n**Context Buffer Guidelines**:\n- Add ¬±5-10 lines buffer to each section for context preservation\n- Load sections sequentially (one at a time), not simultaneously\n- Extract metrics immediately after loading each section\n- Clear temporary data before loading next section\n\n**Performance Comparison**:\n\n| Approach | Lines Loaded | Percentage |\n|----------|-------------|------------|\n| Full Document Load | 2,000+ | 100% |\n| Sequential Loading | ~400-500 | 20-25% |\n| **Savings** | **~1,500-1,600** | **75-80%** |\n\n---\n\n## Implementation Notes\n\n### Return Format\n\nAll three algorithms return structured data:\n\n```python\n{\n  'impact': 'HIGH' or 'LOW',\n  'justification': \"Human-readable explanation with line reference\",\n  'value': <numeric_value>,  # percentage, volume, or count\n  'line': <line_number>      # source line number\n}\n```\n\n### User Review Required\n\n**IMPORTANT**: All calculations must be presented to user for review before applying changes to ARCHITECTURE.md.\n\n**Review Workflow**:\n1. Run all three algorithms\n2. Generate calculation report\n3. Present findings to user\n4. Await user approval or manual override\n5. Only then update Section 2.2.1\n\n### Manual Override Support\n\nUsers can override any calculated value:\n- Change impact level (HIGH ‚Üî LOW)\n- Provide custom justification\n- Specify different metric/threshold\n- Mark as \"Manual Override\" in document\n\nWhen manual override exists:\n- Subsequent automatic calculations prompt before overwriting\n- Preserve manual override unless user explicitly approves change\n\n### Threshold Enforcement\n\n**Strict Threshold Rules**:\n- Value Delivery: >50% (not ‚â•50%)\n- Scale: >100,000 (not ‚â•100,000)\n- Impacts: >5 (not ‚â•5)\n\n**Edge Case Handling**:\n- Exactly at threshold ‚Üí LOW Impact\n- Flag exact matches for user review\n- Note in justification: \"(Threshold edge case: exactly 50%)\"\n\n---\n\n## Integration with Workflows\n\n### Metric Consistency Integration\n\nDesign Drivers calculation should run AFTER metric consistency check:\n1. User updates Section 1 Key Metrics\n2. Metric consistency check runs (syncs duplicates)\n3. Design Drivers calculation runs (uses updated metrics)\n4. Ensures Design Drivers reflect current metric values\n\n### Document Index Integration\n\nDesign Drivers insertion may shift line numbers:\n- Section 2.2.1 insertion adds ~20-25 lines\n- Section 2.3 and subsequent sections shift down\n- Automatically trigger Document Index update if Section 2 grows >10 lines\n- Update index before final completion report\n\n### Architecture Review Integration\n\nWhen user requests \"architecture review\", offer comprehensive checklist:\n```\nArchitecture Review Checklist:\n‚òê Metric consistency check (Section 1 vs document)\n‚òê Design Drivers calculation (Section 2.2.1)\n‚òê Architecture Principles validation (9 required)\n‚òê Document Index accuracy (line ranges)\n‚òê ADR references up to date (Section 12)\n```\n\n---\n\n## Best Practices\n\n### DO:\n- ‚úÖ Calculate after major architecture changes\n- ‚úÖ Recalculate quarterly during architecture reviews\n- ‚úÖ Use metrics in stakeholder presentations\n- ‚úÖ Document assumptions in justifications\n- ‚úÖ Update source sections before calculating\n- ‚úÖ Review calculation report carefully before applying\n- ‚úÖ Load sections sequentially for context efficiency\n- ‚úÖ Flag edge cases for user review\n\n### DON'T:\n- ‚ùå Auto-calculate on every minor update\n- ‚ùå Override thresholds without documentation\n- ‚ùå Ignore edge cases (flag for review)\n- ‚ùå Skip user review (always present findings first)\n- ‚ùå Forget to update \"Last Calculated\" date\n- ‚ùå Calculate with stale data\n- ‚ùå Load entire document unnecessarily\n- ‚ùå Auto-apply changes without user approval\n\n---\n\n## Example: Complete Calculation\n\n**Scenario**: Task Scheduling System architecture review\n\n**Input Data**:\n- Section 1: \"70% cost reduction\" (line 52)\n- Section 2.3: \"500,000+ reminders per day\" (line 141)\n- Section 5: 5 component subsections\n- Section 8: 8 technology table rows (3 after header subtraction)\n\n**Calculation Results**:\n```\nValue Delivery: HIGH (70% > 50%)\nJustification: \"System delivers 70% cost reduction (Section 1, line 52)\"\n\nScale: HIGH (500,000 > 100,000)\nJustification: \"System impacts 500,000 customers/day (Section 2.3, line 141)\"\n\nImpacts: HIGH (8 > 5)\nJustification: \"System requires 8 components/technologies (Section 5: 5, Section 8: 3)\"\n\nOverall: 3/3 HIGH - Strong business justification for architecture complexity\n```\n\n**Output Format** (for Section 2.2.1):\n```markdown\n### 2.2.1 Design Drivers\n\nThis architecture is driven by the following key factors:\n\n#### Value Delivery\n**Description**: Effectiveness of change in customer experience\n- **Threshold**: >50% = High Impact, ‚â§50% = Low Impact\n- **Current Assessment**: HIGH Impact\n- **Justification**: System delivers 70% cost reduction (Section 1, line 52)\n\n#### Scale\n**Description**: Estimated number of customers impacted\n- **Threshold**: >100K = High, ‚â§100K = Low\n- **Current Assessment**: HIGH Impact\n- **Justification**: System impacts 500,000 customers/day (Section 2.3, line 141)\n\n#### Impacts\n**Description**: Implementation complexity across configuration, development, and applications\n- **Threshold**: >5 = High, ‚â§5 = Low\n- **Current Assessment**: HIGH Impact\n- **Justification**: System requires 8 components/technologies (Section 5: 5, Section 8: 3)\n\n**Last Calculated**: 2025-01-29\n**Calculation Method**: Automatic\n```\n\n---\n\n## Summary\n\nThis document provides implementation-level details for Design Drivers calculation algorithms. For conceptual understanding and templates, see **ARCHITECTURE_DOCUMENTATION_GUIDE.md ¬ß Design Drivers**. For operational workflows and trigger detection, see **SKILL.md ¬ß Design Drivers Workflow**.",
        "skills/architecture-docs/MERMAID_DIAGRAMS_GUIDE.md": "# Mermaid Architecture Diagram Guide\n\n**Purpose**: Comprehensive guide for creating Mermaid architecture diagrams for any system architecture (META, 3-Tier, Microservices, N-Layer)\n\n**Applies To**: All architecture types supported by architecture-docs skill\n**Version**: 2.0 (Generic)\n**Last Updated**: 2025-12-03\n\n---\n\n## 1. Introduction\n\n### Purpose\n\nThis document provides comprehensive instructions for creating Mermaid architecture diagrams for any system architecture. It includes templates, guidelines, and generic examples applicable to META, 3-Tier, Microservices, and N-Layer architectures.\n\n### Why Mermaid Over ASCII Art?\n\n**Benefits of Mermaid Diagrams**:\n- ‚úÖ **Interactive**: Zoom, pan, clickable components\n- ‚úÖ **Color-coded**: Visual distinction between component types\n- ‚úÖ **Maintainable**: Text-based, easy to update without manual alignment\n- ‚úÖ **Professional**: Modern, polished appearance\n- ‚úÖ **GitHub/GitLab Native**: Renders automatically in markdown viewers\n- ‚úÖ **Version Control Friendly**: Git diffs work well with text format\n- ‚úÖ **Accessible**: Screen readers can parse the underlying text\n- ‚úÖ **Exportable**: Can generate PNG, SVG, PDF for presentations\n\n**ASCII Art Limitations**:\n- ‚ùå Manual alignment required\n- ‚ùå Difficult to maintain\n- ‚ùå No interactivity\n- ‚ùå No color-coding\n- ‚ùå Breaks easily with edits\n- ‚ùå Time-consuming to create\n\n---\n\n## 2. Prerequisites\n\n### Mermaid Version Compatibility\n\n**Minimum Version**: Mermaid 8.0+\n**Recommended Version**: Mermaid 10.0+ (for best styling support)\n\n### Rendering Compatibility\n\n**Native Rendering** (no plugins required):\n- GitHub (markdown files)\n- GitLab (markdown files)\n- Azure DevOps (markdown files)\n\n**With Extensions/Plugins**:\n- **VS Code**: Install \"Markdown Preview Mermaid Support\" extension\n- **JetBrains IDEs**: Enable Mermaid plugin in Markdown settings\n- **MkDocs**: Add `pymdownx.superfences` with Mermaid support\n- **Docusaurus**: Built-in Mermaid support (v2.0+)\n- **Confluence**: Install \"Mermaid Diagrams for Confluence\" app\n\n### Testing Rendering\n\n**Command Line** (Mermaid CLI):\n```bash\nnpm install -g @mermaid-js/mermaid-cli\nmmdc -i ARCHITECTURE.md -o architecture-diagram.png\n```\n\n**Online Editor** (for testing):\n- https://mermaid.live/\n\n---\n\n## 3. Complete Mermaid Diagram Template\n\n### Full Working Example\n\nThis example shows a generic 6-layer META architecture with Layer 3 (Business Scenarios) event-driven components in detail:\n\n````markdown\n```mermaid\ngraph TB\n    %% Layer 1: Channels\n    subgraph Layer1[\"Layer 1: Channels\"]\n        WebClient[\"Web Client\"]\n        MobileClient[\"Mobile Client\"]\n        APIClient[\"API Client\"]\n    end\n\n    %% Layer 2: User Experience\n    subgraph Layer2[\"Layer 2: User Experience\"]\n        APIGateway[\"API Gateway\"]\n        BFF[\"Backend for Frontend<br/>(BFF Services)\"]\n    end\n\n    %% Layer 3: Business Scenarios (DETAILED)\n    subgraph Layer3[\"Layer 3: Business Scenarios<br/>(Decouple Through Events)\"]\n        %% Orchestrator Service\n        OrchestratorService[\"Orchestrator Service<br/>REST API: /api/v1/resources\"]\n\n        %% Event Topics\n        EventTopicA[\"Event Topic:<br/>event-stream-alpha<br/>18 partitions, 3-day retention\"]\n        EventTopicB[\"Event Topic:<br/>event-stream-beta<br/>12 partitions, 14-day retention\"]\n\n        %% Workers\n        WorkerA[\"Worker Service A<br/>Event Handler: TYPE_A\"]\n        WorkerB[\"Worker Service B<br/>Event Handler: TYPE_B\"]\n\n        %% Query Service\n        QueryService[\"Query Service<br/>Query API: /api/v1/query/*<br/>Materialized Views\"]\n    end\n\n    %% Layer 4: Business\n    subgraph Layer4[\"Layer 4: Business\"]\n        BusinessServiceA[\"Business Service A\"]\n        BusinessServiceB[\"Business Service B\"]\n    end\n\n    %% Layer 5: Domain\n    subgraph Layer5[\"Layer 5: Domain Services\"]\n        DomainServiceA[\"Domain Service A\"]\n        DomainServiceB[\"Domain Service B\"]\n        DomainServiceC[\"Domain Service C\"]\n        DomainServiceD[\"Domain Service D\"]\n    end\n\n    %% Layer 6: Core\n    subgraph Layer6[\"Layer 6: Core Systems\"]\n        CoreSystemA[\"Core System A\"]\n        CoreSystemB[\"Core System B\"]\n    end\n\n    %% Data Flows - Layer 1 to Layer 2\n    WebClient -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n    MobileClient -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n    APIClient -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n\n    %% Data Flows - Layer 2 to Layer 3\n    APIGateway -->|REST/GraphQL<br/>mTLS, 30s timeout<br/>Resource Creation| OrchestratorService\n    APIGateway -.->|REST<br/>mTLS<br/>Query API| QueryService\n\n    %% Data Flows - Layer 3 Internal (Async Event Decoupling)\n    OrchestratorService -.->|Kafka Protocol<br/>TLS 1.2+ SASL<br/>Async Publish| EventTopicA\n    OrchestratorService -.->|Kafka Protocol<br/>CREATED event| EventTopicB\n\n    EventTopicA -.->|Consumer Group:<br/>worker-a-group| WorkerA\n    EventTopicA -.->|Consumer Group:<br/>worker-b-group| WorkerB\n\n    WorkerA -.->|STARTED<br/>COMPLETED<br/>FAILED| EventTopicB\n    WorkerB -.->|STARTED<br/>COMPLETED<br/>FAILED| EventTopicB\n\n    EventTopicB -.->|Consumer Group:<br/>query-service-group<br/>Materialize Views| QueryService\n    EventTopicB -.->|Consumer Groups:<br/>audit, notification, analytics| BusinessServiceA\n\n    %% Data Flows - Layer 3 to Layer 5 (Domain Calls)\n    WorkerA -->|gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries| DomainServiceA\n    WorkerB -->|gRPC/mTLS<br/>30s timeout| DomainServiceC\n    WorkerB -->|gRPC/mTLS<br/>30s timeout| DomainServiceD\n\n    %% Data Flows - Layer 4 to Layer 5\n    BusinessServiceA -->|gRPC/REST<br/>mTLS| DomainServiceA\n    BusinessServiceA -->|gRPC/REST<br/>mTLS| DomainServiceB\n    BusinessServiceB -->|gRPC/REST<br/>mTLS| DomainServiceC\n    BusinessServiceB -->|gRPC/REST<br/>mTLS| DomainServiceD\n\n    %% Data Flows - Layer 5 to Layer 6\n    DomainServiceA -->|REST APIs<br/>mTLS| CoreSystemA\n    DomainServiceB -->|REST APIs<br/>mTLS| CoreSystemB\n\n    %% Styling\n    classDef orchestrator fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n    classDef worker fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\n    classDef query fill:#7ED321,stroke:#5A9B18,stroke-width:2px,color:#fff\n    classDef events fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\n    classDef domain fill:#50E3C2,stroke:#3AA893,stroke-width:2px,color:#000\n    classDef gateway fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n\n    class OrchestratorService orchestrator\n    class WorkerA,WorkerB worker\n    class QueryService query\n    class EventTopicA,EventTopicB events\n    class DomainServiceA,DomainServiceB,DomainServiceC,DomainServiceD domain\n    class APIGateway,BFF gateway\n```\n````\n\n### Structure Breakdown\n\n**Diagram Type**: `graph TB` (top-to-bottom flowchart)\n- **TB** = Top-to-Bottom (vertical layout)\n- Alternative: `graph LR` (left-to-right) for horizontal layouts\n\n**Key Sections**:\n1. **Subgraphs**: One per META architecture layer (6 layers)\n2. **Components**: Labeled rectangles with names and descriptions\n3. **Data Flows**: Arrows connecting components\n4. **Styling**: classDef declarations for color-coding\n\n**Comments**: Use `%%` for comments (ignored in rendering)\n\n---\n\n## 4. Component Guidelines\n\n### Component Types and Representation\n\n#### 1. Microservices / Applications\n\n**Syntax**:\n```mermaid\nComponentName[\"Display Name<br/>Additional Info\"]\n```\n\n**Examples**:\n```mermaid\nOrchestratorService[\"Orchestrator Service<br/>REST API: /api/v1/resources\"]\nWorkerA[\"Worker Service A<br/>Event Handler: TYPE_A\"]\n```\n\n**Guidelines**:\n- Use PascalCase for component IDs (e.g., `WorkerA`, `ServiceB`)\n- Use descriptive display names\n- Add key info with `<br/>` line breaks\n- Keep descriptions concise (1-2 lines max)\n\n#### 2. Event Streaming Topics (Kafka, RabbitMQ)\n\n**Syntax**:\n```mermaid\nTopicName[\"Kafka Topic:<br/>topic-name<br/>partitions, retention\"]\n```\n\n**Example**:\n```mermaid\nEventTopicA[\"Event Topic:<br/>event-stream-alpha<br/>18 partitions, 3-day retention\"]\n```\n\n**Guidelines**:\n- Prefix with \"Kafka Topic:\" or \"RabbitMQ Queue:\"\n- Include partition count and retention policy\n- Use purple color styling\n\n#### 3. Databases / Data Stores\n\n**Syntax**:\n```mermaid\nDBName[(\"Database Name<br/>Type\")]\n```\n\n**Example**:\n```mermaid\nDataStoreA[(\"PostgreSQL<br/>Primary Data Store\")]\n```\n\n**Guidelines**:\n- Use `(( ))` for cylindrical database shape\n- Include database type and purpose\n\n#### 4. External Systems / APIs\n\n**Syntax**:\n```mermaid\nSystemName[\"System Name<br/>(External)\"]\n```\n\n**Example**:\n```mermaid\nCoreSystemA[\"Core System A<br/>(External)\"]\n```\n\n**Guidelines**:\n- Clearly mark as external if applicable\n- Use rounded rectangles for external systems\n\n### Naming Conventions\n\n**Component IDs** (internal references):\n- PascalCase: `OrchestratorService`, `WorkerA`, `QueryService`\n- No spaces, no special characters\n- Descriptive but concise\n\n**Display Names** (visible labels):\n- Title Case or Sentence case\n- Include context (e.g., \"Worker Service A\" not just \"Worker\")\n- Add clarifying info (API endpoints, event handlers, pod counts)\n\n---\n\n## 5. Data Flow Guidelines\n\n### Synchronous Flows (Solid Arrows)\n\n**Syntax**:\n```mermaid\nSourceComponent -->|Protocol<br/>Security<br/>Timeout| TargetComponent\n```\n\n**Examples**:\n```mermaid\nAPIGateway -->|REST/GraphQL<br/>mTLS, 30s timeout<br/>Resource Creation| OrchestratorService\nServiceA -->|gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries| ServiceB\n```\n\n**Guidelines**:\n- Use solid arrows (`-->`) for synchronous REST, gRPC, SOAP calls\n- Label with protocol (REST, gRPC, HTTP/2)\n- Include security mechanism (mTLS, OAuth 2.0 + JWT, API Key)\n- Specify timeout (e.g., 30s timeout)\n- Add retry policy if applicable (e.g., 3 retries with exponential backoff)\n- Optionally include circuit breaker thresholds\n\n**Standard Labels**:\n- `OAuth 2.0 + JWT<br/>TLS 1.2+` (channel authentication)\n- `REST/GraphQL<br/>mTLS, 30s timeout` (internal API calls)\n- `gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries` (domain service calls)\n\n### Asynchronous Flows (Dashed Arrows)\n\n**Syntax**:\n```mermaid\nSourceComponent -.->|Event Type<br/>Protocol| TargetComponent\n```\n\n**Examples**:\n```mermaid\nPublisherService -.->|Kafka Protocol<br/>TLS 1.2+ SASL<br/>Async Publish| EventTopicA\nEventTopicA -.->|Consumer Group:<br/>worker-a-group| WorkerA\nWorkerA -.->|STARTED<br/>COMPLETED<br/>FAILED| EventTopicB\n```\n\n**Guidelines**:\n- Use dashed arrows (`-.->`) for asynchronous events (Kafka, RabbitMQ, event buses)\n- Label with event type or consumer group\n- Include protocol (Kafka Protocol, AMQP)\n- Specify security (TLS 1.2+ SASL)\n- List event types if multiple events flow on same path\n\n**Standard Labels**:\n- `Kafka Protocol<br/>TLS 1.2+ SASL<br/>Async Publish` (publisher to topic)\n- `Consumer Group:<br/>group-name` (topic to consumer)\n- `STARTED<br/>COMPLETED<br/>FAILED` (event types)\n\n### Bidirectional Flows\n\n**Syntax**:\n```mermaid\nComponent1 <-->|Request/Response| Component2\n```\n\n**Example**:\n```mermaid\nAPIGateway <-->|REST<br/>mTLS<br/>Request/Response| BackendService\n```\n\n**Guidelines**:\n- Use bidirectional arrows (`<-->`) sparingly\n- Typically for request/response patterns\n- Can combine with dashed for async bidirectional\n\n---\n\n## 6. Standard Color Scheme\n\n### Color Palette\n\n**Blue - Entry Points / Orchestrators**:\n- Fill: `#4A90E2`\n- Stroke: `#2E5C8A`\n- Text: White (`#fff`)\n- **Use for**: Orchestrator services, coordinators, entry point services\n\n**Orange - Workers / Executors**:\n- Fill: `#F5A623`\n- Stroke: `#B8791A`\n- Text: White (`#fff`)\n- **Use for**: Worker microservices, executors, processors, event handlers\n\n**Green - Query Services / CQRS Read Models**:\n- Fill: `#7ED321`\n- Stroke: `#5A9B18`\n- Text: White (`#fff`)\n- **Use for**: Query services, CQRS read models, reporting services\n\n**Purple - Event Streaming**:\n- Fill: `#BD10E0`\n- Stroke: `#8A0CA3`\n- Text: White (`#fff`)\n- **Use for**: Kafka topics, RabbitMQ queues, event buses\n\n**Teal - Domain Services**:\n- Fill: `#50E3C2`\n- Stroke: `#3AA893`\n- Text: Black (`#000`)\n- **Use for**: BIAN service domains, business logic services, domain APIs\n\n**BIAN Service Domain Names in Diagrams**: When including Layer 5 (Domain) services in META architecture diagrams, use official BIAN V12.0 service domain **names (Capabilities)**. Reference the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) to validate capability names (e.g., Payment Execution, Account Transfer). BIAN IDs (e.g., SD-003, SD-045) are for internal document tracking only.\n\n**Default BIAN Version**: BIAN V12.0 is the default and recommended version for all META architecture diagrams.\n\n**Gray - Infrastructure**:\n- Fill: `#9B9B9B`\n- Stroke: `#6B6B6B`\n- Text: White (`#fff`)\n- **Use for**: API Gateway, load balancers, proxies, infrastructure components\n\n### Applying Color Scheme\n\n**Step 1: Define Color Classes**:\n```mermaid\nclassDef orchestrator fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\nclassDef worker fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\nclassDef query fill:#7ED321,stroke:#5A9B18,stroke-width:2px,color:#fff\nclassDef events fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\nclassDef domain fill:#50E3C2,stroke:#3AA893,stroke-width:2px,color:#000\nclassDef gateway fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n```\n\n**Step 2: Assign Classes to Components**:\n```mermaid\nclass OrchestratorService orchestrator\nclass WorkerA,WorkerB worker\nclass QueryService query\nclass EventTopicA,EventTopicB events\nclass DomainServiceA,DomainServiceB,DomainServiceC,DomainServiceD domain\nclass APIGateway,BFF gateway\n```\n\n**Guidelines**:\n- Define all classes at the end of the diagram (after data flows)\n- Assign multiple components to same class with comma separation\n- Use consistent naming for classDef IDs\n\n---\n\n## 7. Legend Template\n\n### Complete Reusable Legend\n\nInclude this legend after every Mermaid architecture diagram:\n\n```markdown\n**Diagram Legend**:\n\n**Arrow Types**:\n- **Solid arrows (‚Üí)**: Synchronous calls (REST/gRPC with mTLS)\n- **Dashed arrows (-.->)**: Asynchronous events (Kafka publish/subscribe)\n\n**Security Protocols**:\n- **OAuth 2.0 + JWT**: Channel authentication\n- **mTLS**: Mutual TLS for internal service-to-service communication\n- **TLS 1.2+**: Transport layer encryption\n- **SASL**: Kafka authentication (Simple Authentication and Security Layer)\n\n**Timeouts & Retries**:\n- **30s timeout**: Standard timeout for synchronous REST/gRPC calls\n- **3 retries**: Exponential backoff (2s, 4s, 8s) for transient failures\n- **Circuit Breaker**: Opens after 5 consecutive failures\n\n**Component Colors**:\n- **Blue**: Entry points (orchestrators, coordinators)\n- **Orange**: Worker microservices (event handlers, executors)\n- **Green**: Query services (CQRS read models, reporting)\n- **Purple**: Event streaming (event topics, message queues)\n- **Teal**: Domain services (business logic, domain APIs)\n- **Gray**: Infrastructure (API Gateway, load balancers)\n\n**[Optional] Kafka Consumer Groups**:\n- `group-name-1`: Purpose description\n- `group-name-2`: Purpose description\n\n**[Optional] Data Flow Patterns**:\n- **Pattern 1**: Description of flow\n- **Pattern 2**: Description of flow\n```\n\n### Customizing the Legend\n\n**Add sections as needed**:\n- Database schemas\n- Scaling policies\n- Retry strategies\n- Event types\n- API versions\n\n**Keep it concise**:\n- Max 10 bullet points per section\n- Use bold for emphasis\n- Use code formatting for technical terms\n\n---\n\n## 8. Step-by-Step Instructions\n\n### Creating a New Mermaid Diagram\n\n**Step 1: Identify Architecture Layers**\n\nList all layers in your architecture:\n- Example: Channels, User Experience, Business Scenarios, Business, Domain, Core\n\n**Step 2: Map Components to Layers**\n\nFor each layer, identify:\n- Components (services, APIs, databases)\n- External systems\n- Event streaming infrastructure\n\n**Step 3: Define Data Flows**\n\nIdentify:\n- **Synchronous**: REST APIs, gRPC calls, SOAP services\n- **Asynchronous**: Kafka events, message queues, webhooks\n\n**Step 4: Create Mermaid Diagram**\n\n```mermaid\ngraph TB\n    %% Layer 1\n    subgraph Layer1[\"Layer 1: Layer Name\"]\n        Component1[\"Component 1\"]\n        Component2[\"Component 2\"]\n    end\n\n    %% Add more layers...\n\n    %% Data Flows\n    Component1 -->|Protocol<br/>Security| Component2\n```\n\n**Step 5: Apply Color Scheme**\n\nAdd classDef declarations and assign classes to components (see Section 6).\n\n**Step 6: Add Legend**\n\nInclude comprehensive legend explaining all diagram elements (see Section 7).\n\n**Step 7: Validate Rendering**\n\nTest in:\n- GitHub/GitLab preview\n- VS Code Mermaid preview\n- https://mermaid.live/\n\n### Updating an Existing Mermaid Diagram\n\n**Step 1: Locate Diagram Section**\n\nFind the Mermaid diagram in ARCHITECTURE.md (typically Section 4).\n\n**Step 2: Identify Changes**\n\nDetermine what needs to change:\n- Add new component\n- Remove obsolete component\n- Update data flow\n- Modify security annotations\n\n**Step 3: Update Component Definitions**\n\n**Add Component**:\n```mermaid\n%% In appropriate layer subgraph\nNewComponent[\"New Component Name<br/>Description\"]\n```\n\n**Remove Component**:\n- Delete component definition\n- Delete all arrows referencing the component\n- Remove from class assignments\n\n**Step 4: Update Data Flows**\n\n**Add Flow**:\n```mermaid\nSourceComponent -->|Protocol<br/>Security| NewComponent\n```\n\n**Remove Flow**:\n- Delete the arrow line\n\n**Modify Flow**:\n- Update label with new protocol/security/timeout\n\n**Step 5: Update Styling**\n\nIf new component type:\n```mermaid\nclassDef newtype fill:#HEXCOLOR,stroke:#HEXCOLOR,stroke-width:2px,color:#fff\nclass NewComponent newtype\n```\n\n**Step 6: Update Legend**\n\nAdd new sections if needed:\n- New component color\n- New protocol\n- New consumer group\n\n**Step 7: Validate Rendering**\n\nTest updated diagram renders correctly.\n\n---\n\n## 9. Integration Checklist\n\nBefore committing Mermaid diagram changes, verify:\n\n### Syntax Validation\n- ‚úÖ Mermaid code renders without errors in GitHub/GitLab preview\n- ‚úÖ All opening subgraphs have closing `end` statements\n- ‚úÖ All component IDs are unique (no duplicates)\n- ‚úÖ All arrows reference valid component IDs\n- ‚úÖ Quotes are properly closed in labels\n\n### Visual Validation\n- ‚úÖ All layers are visible and properly labeled\n- ‚úÖ Components are in the correct layers\n- ‚úÖ Data flows are accurate (direction, labels)\n- ‚úÖ Colors are applied correctly (classDef assignments)\n- ‚úÖ No overlapping arrows or components\n- ‚úÖ Diagram layout is readable (not too cluttered)\n\n### Content Validation\n- ‚úÖ Security protocols are accurate (mTLS, OAuth, SASL)\n- ‚úÖ Timeouts and retries match architecture specifications\n- ‚úÖ Consumer groups are correctly labeled\n- ‚úÖ Event types are listed accurately\n- ‚úÖ Component descriptions are up-to-date\n\n### Legend Validation\n- ‚úÖ Legend explains all arrow types used\n- ‚úÖ Legend documents all security protocols used\n- ‚úÖ Legend lists all component colors used\n- ‚úÖ Legend includes consumer groups if applicable\n- ‚úÖ Legend includes data flow patterns if complex\n\n### Cross-Reference Validation\n- ‚úÖ Diagram matches component details in Section 5\n- ‚úÖ Data flows match descriptions in Section 6\n- ‚úÖ Integration points match Section 7\n- ‚úÖ Performance metrics referenced (not shown on diagram)\n\n---\n\n## 10. Common Scenarios and Examples\n\n### Scenario 1: Add New Microservice\n\n**Task**: Add a new \"ServiceC\" microservice that consumes events from an event topic.\n\n**Steps**:\n\n1. **Add component to Layer 3 subgraph**:\n```mermaid\nsubgraph Layer3[\"Layer 3: Business Scenarios\"]\n    %% Existing components...\n\n    %% New component\n    ServiceC[\"Service C<br/>Event Handler: TYPE_C\"]\nend\n```\n\n2. **Add data flow from event topic**:\n```mermaid\nEventTopicA -.->|Consumer Group:<br/>service-c-group| ServiceC\n```\n\n3. **Add data flow to domain service**:\n```mermaid\nServiceC -->|gRPC/mTLS<br/>30s timeout| DomainServiceB\n```\n\n4. **Add lifecycle event publishing**:\n```mermaid\nServiceC -.->|STARTED<br/>COMPLETED<br/>FAILED| EventTopicB\n```\n\n5. **Apply color styling**:\n```mermaid\nclass ServiceC worker\n```\n\n6. **Update legend** (add to consumer groups section):\n```markdown\n- `service-c-group`: Consumes event-stream-alpha filtered by TYPE_C\n```\n\n---\n\n### Scenario 2: Add New Event Topic\n\n**Task**: Add a new \"notification-events\" event topic for notification management.\n\n**Steps**:\n\n1. **Add topic component to Layer 3**:\n```mermaid\nEventTopicC[\"Event Topic:<br/>notification-events<br/>6 partitions, 7-day retention\"]\n```\n\n2. **Add producer flow**:\n```mermaid\nServiceD -.->|Notification Event<br/>Kafka Protocol| EventTopicC\n```\n\n3. **Add consumer flow**:\n```mermaid\nEventTopicC -.->|Consumer Group:<br/>notification-handler-group| ServiceE\n```\n\n4. **Apply color styling**:\n```mermaid\nclass EventTopicC events\n```\n\n5. **Update legend** (add to description):\n```markdown\n**Event Topics**:\n- event-stream-alpha: Primary event stream\n- event-stream-beta: Lifecycle events\n- notification-events: Notification events (new)\n```\n\n---\n\n### Scenario 3: Update Data Flow (Change Security Protocol)\n\n**Task**: Change ServiceB ‚Üí Domain Service calls from gRPC/mTLS to REST/mTLS.\n\n**Steps**:\n\n1. **Locate existing data flow arrows**:\n```mermaid\nServiceB -->|gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries| DomainServiceA\n```\n\n2. **Update arrow labels**:\n```mermaid\nServiceB -->|REST/mTLS<br/>30s timeout<br/>3 retries| DomainServiceA\n```\n\n3. **Update legend** (if protocol change is significant):\n```markdown\n**Security Protocols**:\n- **mTLS**: Mutual TLS for internal service-to-service communication (REST and gRPC)\n```\n\n---\n\n### Scenario 4: Add New Layer\n\n**Task**: Add Layer 7 (External Systems) below Layer 6.\n\n**Steps**:\n\n1. **Add new subgraph**:\n```mermaid\n%% Layer 7: External Systems\nsubgraph Layer7[\"Layer 7: External Systems\"]\n    PaymentGateway[\"Payment Gateway<br/>(External)\"]\n    CreditBureau[\"Credit Bureau API<br/>(External)\"]\nend\n```\n\n2. **Add data flows from Layer 6**:\n```mermaid\nCoreBanking -->|HTTPS/REST<br/>API Key| PaymentGateway\nCoreBanking -->|HTTPS/REST<br/>mTLS| CreditBureau\n```\n\n3. **Apply color styling** (use gray for external):\n```mermaid\nclassDef external fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\nclass PaymentGateway,CreditBureau external\n```\n\n4. **Update legend**:\n```markdown\n**Component Colors**:\n- **Gray**: Infrastructure and external systems\n```\n\n---\n\n### Scenario 5: Replace Existing Component\n\n**Task**: Replace \"DomainServiceA\" with \"DomainServiceX\".\n\n**Steps**:\n\n1. **Find and delete old component**:\n```mermaid\n%% DELETE THIS:\nDomainServiceA[\"Domain Service A\"]\n```\n\n2. **Add new component**:\n```mermaid\nDomainServiceX[\"Domain Service X<br/>Enhanced API: /api/v2/resources\"]\n```\n\n3. **Update all arrows referencing old component**:\n```mermaid\n%% OLD:\nWorkerA -->|gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries| DomainServiceA\n\n%% NEW:\nWorkerA -->|gRPC/mTLS<br/>HTTP/2, 30s timeout<br/>3 retries| DomainServiceX\n```\n\n4. **Update class assignments**:\n```mermaid\n%% OLD:\nclass DomainServiceA domain\n\n%% NEW:\nclass DomainServiceX domain\n```\n\n5. **Update legend** (if needed):\n```markdown\n- Domain Service X: Enhanced version replacing Domain Service A with additional capabilities\n```\n\n---\n\n## 11. Best Practices\n\n### Do's\n\n‚úÖ **Use consistent naming conventions**:\n- Component IDs: PascalCase\n- Consumer groups: kebab-case\n- Topics: kebab-case\n\n‚úÖ **Keep diagrams focused**:\n- Show 1-2 layers in detail, others simplified\n- Avoid cluttering with every single component\n\n‚úÖ **Label all arrows**:\n- Include protocol, security, timeout\n- Be concise but informative\n\n‚úÖ **Use color-coding consistently**:\n- Apply same colors across all diagrams\n- Document color meanings in legend\n\n‚úÖ **Test rendering regularly**:\n- Check in GitHub/GitLab preview\n- Validate in Mermaid live editor\n\n‚úÖ **Version control diagrams**:\n- Commit diagram changes with descriptive messages\n- Reference architecture decision records (ADRs)\n\n### Don'ts\n\n‚ùå **Don't overload diagrams**:\n- Avoid showing every component in one diagram\n- Create multiple focused diagrams instead\n\n‚ùå **Don't forget the legend**:\n- Always include comprehensive legend\n- Explain all symbols and colors used\n\n‚ùå **Don't use ambiguous labels**:\n- \"Svc1\" ‚Üí \"Orchestrator Service\"\n- \"DB\" ‚Üí \"PostgreSQL Primary Data Store\"\n\n‚ùå **Don't mix ASCII and Mermaid**:\n- Choose one format per document\n- If migrating, replace all diagrams at once\n\n‚ùå **Don't neglect security annotations**:\n- Always show mTLS, OAuth, API keys\n- Don't assume readers know protocols\n\n‚ùå **Don't use custom colors without documentation**:\n- Stick to standard palette\n- If adding new color, document in legend\n\n---\n\n## 12. Integration with solutions-architect-skills\n\n### Recommended Skill Enhancement\n\n**Skill Name**: `solutions-architect-skills:architecture-docs`\n\n**New Capabilities to Add**:\n\n1. **Generate Mermaid Diagrams**:\n   - Use this template as base\n   - Prompt for architecture layers\n   - Prompt for components per layer\n   - Prompt for data flows\n   - Auto-generate Mermaid code\n\n2. **Update Existing Diagrams**:\n   - Parse existing Mermaid diagram\n   - Identify components and flows\n   - Offer modification options (add/remove/update)\n   - Regenerate Mermaid code\n\n3. **Validate Diagrams**:\n   - Check syntax correctness\n   - Verify all IDs are unique\n   - Ensure all arrows reference valid components\n   - Validate legend completeness\n\n4. **Export Diagrams**:\n   - Generate PNG/SVG using Mermaid CLI\n   - Export for presentations\n\n### Implementation Hints\n\n**Prompt Templates**:\n- \"Generate a Mermaid architecture diagram for [ARCHITECTURE_NAME]\"\n- \"Update the Mermaid diagram in ARCHITECTURE.md to add [COMPONENT_NAME]\"\n- \"Replace the ASCII diagram with a Mermaid diagram in [FILE_PATH]\"\n\n**Required Inputs**:\n- Architecture layers (e.g., \"6-layer META architecture\")\n- Components per layer\n- Data flow types (sync vs async)\n- Security protocols\n\n**Auto-Generated Sections**:\n- classDef declarations (use standard color palette)\n- Legend (use template from Section 7)\n- Component descriptions (from architecture doc)\n\n---\n\n## 13. Reference Examples\n\nFor complete, working Mermaid diagram examples, see the Section 4 templates:\n\n**Section 4 Templates**:\n- **META Architecture**: `templates/SECTION_4_META.md` (6-layer enterprise pattern)\n- **3-Tier Architecture**: `templates/SECTION_4_3TIER.md` (classic web application pattern)\n- **Microservices Architecture**: `templates/SECTION_4_MICROSERVICES.md` (cloud-native distributed pattern)\n\nEach template includes:\n- Complete Mermaid diagram example with realistic component names\n- Layer/Tier-specific component organization\n- Communication patterns (synchronous/asynchronous)\n- Legend and customization instructions\n- Color coding appropriate for architecture type\n- Security protocols and data flow patterns\n\n**Usage**:\n1. Choose the template that matches your architecture type\n2. Copy the Mermaid diagram from Section 4 of the template\n3. Customize component names and flows for your specific system\n4. Update the legend to reflect your actual components and patterns\n5. Validate rendering in your documentation platform\n\n**Benefits**:\n- ‚úÖ Realistic examples show patterns in context\n- ‚úÖ Architecture-specific best practices\n- ‚úÖ Ready-to-use diagrams that render in GitHub/GitLab\n- ‚úÖ Professional, maintainable, interactive visualizations\n\n---\n\n## 14. Conclusion\n\nThis document provides everything needed to create Mermaid architecture diagrams for any system architecture:\n\n- ‚úÖ Generic working template applicable to all architecture types\n- ‚úÖ Component guidelines with architecture-agnostic examples\n- ‚úÖ Data flow patterns for synchronous and asynchronous communication\n- ‚úÖ Standard color scheme\n- ‚úÖ Reusable legend template\n- ‚úÖ Step-by-step instructions for creating and updating diagrams\n- ‚úÖ Common scenarios with generic examples\n- ‚úÖ Best practices for maintainable visualizations\n- ‚úÖ Reference to architecture-specific templates (META, 3-Tier, Microservices)\n\n**How to Use This Guide**:\n1. Read through the guide to understand Mermaid diagram patterns\n2. Choose the appropriate Section 4 template for your architecture type\n3. Copy and customize the diagram for your specific system\n4. Follow the step-by-step instructions for updates\n5. Refer to common scenarios for typical modification tasks\n\n**Benefits**:\n- Works for any system type (e-commerce, CRM, IoT, financial services, etc.)\n- Supports all architecture patterns (META, 3-Tier, Microservices, N-Layer)\n- Technology-agnostic (Kafka, RabbitMQ, REST, gRPC, etc.)\n- Professional, maintainable, version-control-friendly diagrams\n\n**Questions or Feedback**:\nContact the architecture documentation team or submit issues to the solutions-architect-skills repository.\n\n---\n\n**Version History**:\n- **v2.0 (2025-12-03)**: Genericized version with architecture-agnostic examples applicable to any system type\n- **v1.0 (2025-12-03)**: Initial release with complete Mermaid diagram template and guidelines\n",
        "skills/architecture-docs/METRIC_CALCULATIONS.md": "# Metric Calculations\n\n> Algorithms for metric extraction, consistency checking, and index updates in ARCHITECTURE.md files\n\n## Purpose\n\nThis document provides detailed algorithms for:\n1. **Automatic Index Updates**: Calculate line ranges for Document Index\n2. **Metric Consistency Detection**: Extract, scan, and classify metrics across the document\n\n## Related Documentation\n\n- **SKILL.md**: Operational workflows and when to trigger these calculations\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Content templates and what metrics to document\n- **DESIGN_DRIVER_CALCULATIONS.md**: Design Drivers calculation algorithms\n\n---\n\n## 1. Automatic Index Updates\n\n### Overview\n\nThe Document Index (typically lines 5-21 of ARCHITECTURE.md) provides quick navigation with exact line ranges for all sections. When content changes shift section boundaries by >10 lines, the index must be updated.\n\n### When to Update\n\n**Update the Document Index if:**\n- ‚úÖ Added/removed content that shifts section boundaries (>10 lines)\n- ‚úÖ Added/removed entire subsections or major content blocks\n- ‚úÖ Modified section headers or restructured sections\n- ‚úÖ User explicitly requests: \"update the index\" or \"update document index\"\n\n**Do NOT update if:**\n- ‚ùå Minor edits (<10 lines) within a section that don't shift other sections\n- ‚ùå Only updating metadata (dates, version numbers, single values)\n- ‚ùå Fixing typos or formatting issues\n\n### Line Range Calculation Algorithm\n\n**Step 1: Detect Section Boundaries**\n\nRun bash command to find all numbered section headers:\n```bash\ngrep -n \"^## [0-9]\" ARCHITECTURE.md\n```\n\nThis returns output like:\n```\n25:## 1. Executive Summary\n54:## 2. System Overview\n147:## 3. Architecture Principles\n301:## 4. Architecture Layers\n...\n```\n\n**Step 2: Parse Grep Output**\n\nExtract section numbers and line positions:\n```\nSection 1 starts at line 25\nSection 2 starts at line 54\nSection 3 starts at line 147\nSection 4 starts at line 301\n...\nSection 12 starts at line 1917\n```\n\n**Step 3: Calculate Line Ranges**\n\nFor each section:\n- **Start line**: Section header line number\n- **End line**: (Next section's start line - 1)\n- **Last section**: Use \"end\" or calculate from file length\n\nFormat: `Lines START-END`\n\n**Calculation Example:**\n```\nSection 1: Lines 25-53  (from line 25 to 54-1)\nSection 2: Lines 54-146 (from line 54 to 147-1)\nSection 3: Lines 147-300 (from line 147 to 301-1)\nSection 4: Lines 301-600 (from line 301 to 601-1)\n...\nSection 12: Lines 1917-end (last section)\n```\n\n**Step 4: Generate Index Content**\n\nBuild markdown list with calculated ranges:\n```markdown\n- [Section 1: Executive Summary](#1-executive-summary) ‚Üí Lines 25-53\n- [Section 2: System Overview](#2-system-overview) ‚Üí Lines 54-146\n- [Section 3: Architecture Principles](#3-architecture-principles) ‚Üí Lines 147-300\n...\n```\n\n**Step 5: Update Document Index**\n\n1. Use Edit tool to replace the Quick Navigation list (typically lines 8-19)\n2. Update `**Index Last Updated:**` to current date (YYYY-MM-DD format)\n3. Preserve exact markdown formatting\n\n### Complete Example Workflow\n\n**Scenario**: After adding Confluent Kafka to Section 8, the section grew by 16 lines\n\n```\n1. Detect change: Section 8 grew from 906-980 to 912-996 (16 lines added)\n\n2. Run: grep -n \"^## [0-9]\" ARCHITECTURE.md\n\n3. Parse output:\n   Section 1: Line 25\n   Section 2: Line 54\n   ...\n   Section 8: Line 912 (shifted from 906)\n   Section 9: Line 998 (shifted from 982)\n   Section 10: Line 1244 (shifted from 1228)\n   ...\n   Section 12: Line 1923 (shifted from 1907)\n\n4. Calculate ranges:\n   Section 8: Lines 912-997 (912 to 998-1)\n   Section 9: Lines 998-1243 (998 to 1244-1)\n   Section 10: Lines 1244-1417 (1244 to next-1)\n   ...\n\n5. Update index:\n   - [Section 8: Technology Stack](#8-technology-stack) ‚Üí Lines 912-997\n   - [Section 9: Security Architecture](#9-security-architecture) ‚Üí Lines 998-1243\n   - [Section 10: Scalability & Performance](#10-scalability--performance) ‚Üí Lines 1244-1417\n   - **Index Last Updated:** 2025-01-29\n\n6. Report to user:\n   \"‚úÖ Document Index updated - Sections 8-12 line ranges adjusted after Technology Stack expansion\"\n```\n\n### Verification Checklist\n\nAfter updating index, verify:\n- ‚úÖ All 12 sections are listed (or 11 if Data Flow omitted)\n- ‚úÖ Line ranges are sequential (no gaps or overlaps)\n- ‚úÖ Anchor links match actual section headers exactly\n- ‚úÖ \"Index Last Updated\" date is current (YYYY-MM-DD)\n- ‚úÖ Format matches template (consistent spacing and symbols)\n\n### Edge Cases\n\n**Case 1: Section Removed**\n- Renumber subsequent sections\n- Update all line ranges\n- Update anchor links to match new section numbers\n\n**Case 2: Section Added**\n- Insert new section in index\n- Renumber subsequent sections if needed\n- Recalculate all affected line ranges\n\n**Case 3: File Has No Index**\n- Create new index from template\n- Calculate all line ranges\n- Insert at top of document (after title, before Section 1)\n\n---\n\n## 2. Metric Consistency Detection\n\n### Overview\n\nThe Executive Summary (Section 1, Key Metrics subsection) contains performance metrics that serve as the **Source of Truth** for system capacity, throughput, latency, and availability targets. These metrics are often duplicated across multiple sections. When metrics are updated in the Executive Summary, duplicates in other sections can become stale, creating inconsistencies.\n\nThis algorithm provides automatic metric consistency detection and classification.\n\n### When to Trigger\n\n**Automatic Trigger:**\n- ‚úÖ After editing Section 1 Executive Summary Key Metrics (typically lines 31-38)\n- ‚úÖ When user updates any metric values in Key Metrics subsection\n- ‚úÖ After Edit tool completes on lines in Section 1 that contain metrics (TPS, latency, SLA, etc.)\n\n**Manual Trigger:**\n- ‚úÖ User requests: \"check metrics\", \"verify metrics\", \"audit metrics\", \"metric consistency\"\n- ‚úÖ User requests: \"find duplicates\", \"check for stale metrics\"\n\n### Metric Extraction & Registry Building\n\n**Step 1: Extract Executive Summary Metrics**\n\nRead ONLY lines 30-40 (Key Metrics section) using context-efficient approach:\n```bash\nRead(file_path=\"ARCHITECTURE.md\", offset=30, limit=10)\n```\n\n**Step 2: Parse Metrics Using Regex Patterns**\n\n| Metric Type | Regex Pattern | Example Match |\n|-------------|---------------|---------------|\n| **Average Read TPS** | `Average\\s+Read\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Average Read TPS: 1,500 transactions/second\" |\n| **Peak Read TPS** | `Peak\\s+Read\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Peak Read TPS: 3,000 transactions/second\" |\n| **Average Processing TPS** | `Average\\s+Processing\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Average Processing TPS: 450 transactions/second\" |\n| **Peak Processing TPS** | `Peak\\s+Processing\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Peak Processing TPS: 1,000 transactions/second\" |\n| **Average Write TPS** | `Average\\s+Write\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Average Write TPS: 300 transactions/second\" |\n| **Peak Write TPS** | `Peak\\s+Write\\s+TPS:\\s*(\\d{1,3}(?:,\\d{3})*)\\s*transactions/second` | \"Peak Write TPS: 800 transactions/second\" |\n| **Measurement Period** | `Measurement\\s+Period:\\s*(.+)` | \"Measurement Period: Average over last 30 days\" |\n| **Percentile Latency** | `p(\\d{2})\\s*<\\s*(\\d+)ms` | \"p95 < 100ms\", \"p99 < 200ms\" |\n| **Availability SLA** | `(\\d{2,3}\\.\\d+)\\s*%` | \"99.99%\", \"99.9%\" |\n| **Concurrent Jobs** | `(\\d{1,3}(?:,\\d{3})*)\\+?\\s*concurrent` | \"10,000+ concurrent\", \"5000 concurrent\" |\n| **Jobs per Hour** | `\\[(\\d{1,3}(?:,\\d{3})*)\\s*jobs?/hour\\]` | \"[1,620,000 jobs/hour]\" |\n| **Daily Volume** | `(\\d{1,3}(?:,\\d{3})*)\\+?\\s*(?:per\\s*day\\|daily)` | \"500,000+ per day\", \"1,000,000 daily\" |\n\n**Step 3: Build Metrics Registry**\n\nExtract all metrics and store in structured format:\n```\nMETRICS_REGISTRY = [\n  {name: \"Read TPS\", value: 1500, unit: \"TPS\", category: \"Read\", stat_type: \"Average\", line: 32, measurement_period: \"Average over last 30 days in production\"},\n  {name: \"Read TPS\", value: 3000, unit: \"TPS\", category: \"Read\", stat_type: \"Peak\", line: 33, measurement_period: \"Peak observed during Black Friday 2024\"},\n  {name: \"Processing TPS\", value: 450, unit: \"TPS\", category: \"Processing\", stat_type: \"Average\", line: 35, measurement_period: \"Average over last quarter\"},\n  {name: \"Processing TPS\", value: 1000, unit: \"TPS\", category: \"Processing\", stat_type: \"Peak\", line: 36, measurement_period: \"Peak during end-of-month batch processing\"},\n  {name: \"Write TPS\", value: 300, unit: \"TPS\", category: \"Write\", stat_type: \"Average\", line: 38, measurement_period: \"Average over last month\"},\n  {name: \"Write TPS\", value: 800, unit: \"TPS\", category: \"Write\", stat_type: \"Peak\", line: 39, measurement_period: \"Peak during data migration events\"},\n  {name: \"System Availability\", value: 99.99, unit: \"%\", line: 42, context: \"SLA target\"},\n  {name: \"Latency p95\", value: 100, unit: \"ms\", line: 43, context: \"response time\"},\n  {name: \"Latency p99\", value: 200, unit: \"ms\", line: 43, context: \"response time\"},\n  {name: \"Concurrent Jobs\", value: 10000, unit: \"jobs\", line: 44, context: \"concurrency limit\"}\n]\n```\n\n### Document Scanning & Match Detection\n\n**Step 4: Scan Document for Metric References**\n\nFor each metric in registry, use Grep to find all occurrences:\n\n```bash\n# Example searches for TPS metrics (new standardized format)\nGrep(pattern=\"Average\\s+Read\\s+TPS:\\s*1,?500\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"Peak\\s+Read\\s+TPS:\\s*3,?000\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"Average\\s+Processing\\s+TPS:\\s*450\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"Peak\\s+Processing\\s+TPS:\\s*1,?000\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"Average\\s+Write\\s+TPS:\\s*300\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"Peak\\s+Write\\s+TPS:\\s*800\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\n\n# Example searches for other metric types\nGrep(pattern=\"99\\.99%\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"p95.*100ms\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"p99.*200ms\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\nGrep(pattern=\"10,?000.*concurrent\", path=\"ARCHITECTURE.md\", output_mode=\"content\", -n=True)\n```\n\n**Note**: Use context-aware patterns to reduce false positives. For example:\n- ‚ùå Bad: `grep \"100\"` (matches section numbers, version 1.00, etc.)\n- ‚úÖ Good: `grep \"p95.*100ms\"` (context-specific pattern)\n\n**Step 5: Load Context for Each Match**\n\nFor each grep result, read ¬±5 lines for context:\n```bash\n# If match found at line 787\nRead(file_path=\"ARCHITECTURE.md\", offset=782, limit=10)\n# Reads lines 782-792 to understand context\n```\n\n### Classification Algorithm\n\n**Step 6: Classify Each Finding**\n\nFor each match, determine relationship to source metric:\n\n**Classification Logic**:\n```\n1. IF match line is in Section 1 (lines 25-53):\n   SKIP (this is the source of truth)\n\n2. Read context (¬±5 lines) to understand metric meaning\n\n3. Compare metric concept:\n   - Same metric name/concept ‚Üí potential duplicate\n   - Different context ‚Üí likely unrelated\n\n4. Classify:\n   IF (same value AND same concept):\n      ‚Üí ‚úì Exact Match (consistent)\n\n   ELSE IF (same concept AND different value):\n      ‚Üí ‚ö†Ô∏è Mismatch (ACTION REQUIRED)\n\n   ELSE IF (mathematical transformation detected):\n      ‚Üí ‚ÑπÔ∏è Derived Value (informational)\n      Example: 450 TPS √ó 3600 = 1,620,000 jobs/hour\n\n   ELSE:\n      ‚Üí ? Ambiguous (manual review needed)\n```\n\n**Derived Value Detection**:\nCommon transformations to check:\n- TPS ‚Üí jobs/hour: multiply by 3600\n- TPS ‚Üí jobs/day: multiply by 86400\n- Percentage ‚Üí fraction: divide by 100\n- ms ‚Üí seconds: divide by 1000\n\n### Report Generation\n\n**Step 7: Generate Consistency Report**\n\nPresent findings in structured format:\n\n```markdown\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n   METRIC CONSISTENCY AUDIT REPORT\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nSource of Truth: Section 1 (Executive Summary) Lines 31-38\nTotal Metrics Audited: 8\nScan Date: 2025-01-29\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n## ‚úì Exact Matches (Consistent)\n\n| Metric | Exec Value | Location | Context | Status |\n|--------|-----------|----------|---------|--------|\n| Job Latency (p95) | < 100ms | Line 787 | Section 6: Data Flow Performance | ‚úì Match |\n| Job Latency (p99) | < 200ms | Line 787 | Section 6: Data Flow Performance | ‚úì Match |\n| Job Latency (p95) | < 100ms | Line 1345 | Section 10: Performance Table | ‚úì Match |\n| Job Latency (p99) | < 200ms | Line 1345 | Section 10: Performance Table | ‚úì Match |\n\n## ‚ö†Ô∏è Mismatches Found (ACTION REQUIRED)\n\n| Metric | Exec Value | Location | Current Value | Difference |\n|--------|-----------|----------|---------------|------------|\n| Peak Job Creation | 1,000 TPS | Line 1367 | 500 TPS | -500 TPS |\n\n## ‚ÑπÔ∏è Derived Values (Informational)\n\n| Metric | Exec Value | Location | Derived Value | Relationship |\n|--------|-----------|----------|---------------|--------------|\n| Job Creation | 450 TPS | Line 32 | 1,620,000 jobs/hour | 450 √ó 3600 |\n\n## ? Ambiguous Matches (Review Needed)\n\n| Metric Pattern | Location | Context | Recommendation |\n|----------------|----------|---------|----------------|\n| \"1000 TPS\" | Line 1389 | Capacity planning note | Verify if refers to Peak Job Creation |\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nSUMMARY: ‚úì 4 Exact | ‚ö†Ô∏è 1 Mismatch | ‚ÑπÔ∏è 1 Derived | ? 1 Ambiguous\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n```\n\n### Common Metric Locations\n\n**Known Duplicate Locations** (typical architecture documents):\n\n| Metric | Executive Summary | Common Duplicate Locations |\n|--------|------------------|---------------------------|\n| Average Read TPS | Line ~32 | Section 10 Throughput Table (~line 1367) |\n| Peak Read TPS | Line ~33 | Section 10 Throughput Table (~line 1367) |\n| Average Processing TPS | Line ~35 | Section 10 Throughput Table (~line 1368), Section 6 Data Flow (~line 787) |\n| Peak Processing TPS | Line ~36 | Section 10 Throughput Table (~line 1368) |\n| Average Write TPS | Line ~38 | Section 10 Throughput Table (~line 1369) |\n| Peak Write TPS | Line ~39 | Section 10 Throughput Table (~line 1369) |\n| System Availability (%) | Line ~42 | Section 2 Use Case metrics (~line 115), Section 7 Integration SLA Table (~lines 829-832) |\n| Latency Targets (p95/p99) | Line ~43 | Section 6 Data Flow Performance (~line 787), Section 10 Performance Table (~line 1345) |\n| Concurrent Jobs | Line ~44 | Less commonly duplicated (usually only in Exec Summary) |\n\n**Note**: Line numbers are approximate and vary by document. Use grep to find exact locations.\n\n### Edge Cases & Error Handling\n\n**Case 1: Multiple Conflicting Values**\n\nScenario: Same metric has different values in multiple sections\n\nExample:\n- Exec Summary (Line 35): Average Processing TPS: 450 transactions/second\n- Section 6 (Line 787): Average Processing TPS: 500 transactions/second\n- Section 10 (Line 1367): Average Processing TPS: 400 transactions/second\n\n**Handling**:\n```\n‚ö†Ô∏è CONFLICT DETECTED: Average Processing TPS has 3 different values\n\n| Location | Value | Context |\n|----------|-------|---------|\n| Line 35 (Exec Summary) | 450 TPS | Design Capacity |\n| Line 787 (Section 6) | 500 TPS | Data Flow Performance |\n| Line 1367 (Section 10) | 400 TPS | Throughput Table |\n\nOptions:\n1. Use Exec Summary (450 TPS) as source of truth\n2. Manual review - investigate each context\n```\n\n**Case 2: Derived Value Calculation Errors**\n\nScenario: Derived value doesn't match expected conversion\n\nExample:\n- Exec Summary: 450 TPS\n- Expected: 1,620,000 jobs/hour (450 √ó 3600)\n- Found: 1,650,000 jobs/hour\n\n**Handling**:\n```\n‚ÑπÔ∏è Derived Value Mismatch:\nBase: 450 TPS (Line 32)\nExpected: 1,620,000 jobs/hour\nFound: 1,650,000 jobs/hour (Line 32)\nDifference: +30,000 jobs/hour\n\nPossible causes:\n- Rounding or overhead factor\n- Different calculation method\n- Stale value\n```\n\n**Case 3: Ambiguous Context**\n\nScenario: Number matches but unclear if same metric\n\n**Handling**:\n```\n? AMBIGUOUS MATCH: \"1,000 TPS\" found in multiple contexts\n\nExec Summary (Line 34):\n\"Peak Capacity: 1,000 TPS job creation\"\n\nFound Matches:\n1. Line 1367: \"System limit 1,000 TPS\"\n   ‚Üí Likely same metric ‚úì\n\n2. Line 1389: \"1000 TPS limit\"\n   ‚Üí Context unclear, review needed\n```\n\n**Case 4: No Matches Found**\n\nScenario: Metric exists in Exec Summary but never referenced elsewhere\n\n**Handling**:\n```\n‚ÑπÔ∏è INFORMATIONAL: Metric appears only in Executive Summary\n\nMetric: Concurrent Jobs (10,000+)\nLocation: Line 38 (Section 1)\nCoverage: Not referenced in other sections\n\nRecommendation:\n- If important: Add to Section 10 (Scalability & Performance)\n- If summary-only: No action needed\n```\n\n**Case 5: Too Many False Positives**\n\nScenario: Common number matches unrelated contexts\n\n**Mitigation**:\n- Use context-aware grep patterns\n- ‚ùå Avoid: `grep \"100\"` (too broad)\n- ‚úÖ Use: `grep \"p95.*100ms\"` (context-specific)\n- ‚úÖ Use: `grep \"100\\s*TPS\"` (unit-specific)\n\n---\n\n## Best Practices\n\n### DO:\n- ‚úÖ Always scan full document after Exec Summary metric changes\n- ‚úÖ Present findings before making any changes (review-only first)\n- ‚úÖ Explain context for each mismatch (section, table/paragraph)\n- ‚úÖ Use context-aware grep patterns to reduce false positives\n- ‚úÖ Load ¬±5 lines context for each match\n- ‚úÖ Show exact before/after text for transparency\n- ‚úÖ Update Document Index if edits shift section boundaries\n\n### DON'T:\n- ‚ùå Auto-update without user approval (always review first)\n- ‚ùå Change metrics in unrelated sections without confirming\n- ‚ùå Ignore ambiguous matches (always flag for review)\n- ‚ùå Forget to check derived values (TPS ‚Üí jobs/hour conversions)\n- ‚ùå Skip context loading (always read ¬±5 lines)\n- ‚ùå Use overly broad grep patterns\n\n---\n\n## Implementation Notes\n\n**Context Efficiency**:\n- Load sections incrementally (Document Index, then Section 1, then search results)\n- Avoid loading entire document (>2000 lines)\n- Use Grep tool for searches (more efficient than full file reads)\n- Load ¬±5 line context only for confirmed matches\n\n**User Interaction**:\n- Always present report before making changes\n- Offer options: Update Exec, Update Document, Ignore, Manual Review\n- Show preview with exact before/after text\n- Confirm user approval before applying changes\n\n**Workflow Integration**:\n- Automatically trigger after Section 1 Key Metrics edits\n- Update Document Index if changes shift line numbers (>10 lines)\n- Report completion summary with all changes made",
        "skills/architecture-docs/QUERY_SECTION_MAPPING.md": "# Query-to-Section Mapping Guide\n\nThis guide maps common architectural questions to ARCHITECTURE.md sections for the Informational Query Workflow (Workflow 7).\n\n## Purpose\n\nWhen users ask questions about the architecture, this guide helps identify which ARCHITECTURE.md section(s) contain the answer, enabling context-efficient loading and accurate citations.\n\n## How to Use This Guide\n\n1. **Classify the user's question** by identifying the main topic (authentication, scaling, components, etc.)\n2. **Consult the relevant section mapping** below to find which ARCHITECTURE.md section contains the answer\n3. **Load the identified section(s)** using the index-based approach from Workflow 7\n4. **Extract the answer** and provide citations with line numbers\n\n---\n\n## Section 1: Executive Summary\n\n**Answers queries about**:\n- Overall system purpose and value\n- High-level architecture overview\n- Key business metrics (users, transactions, availability)\n- Strategic alignment\n- Business value and ROI\n\n**Example questions**:\n- \"What does this system do?\"\n- \"What's the overall architecture?\"\n- \"What are the key metrics?\"\n- \"What business value does this provide?\"\n- \"How many users/transactions does the system support?\"\n- \"What's the system availability SLA?\"\n\n**Typical line range**: Lines 1-80\n\n**Subsections to check**:\n- Business Value\n- Key Metrics (TPS, latency, availability, concurrent jobs)\n- High-level architecture description\n\n---\n\n## Section 2: System Overview\n\n**Answers queries about**:\n- Problem being solved (Section 2.1)\n- Solution approach (Section 2.2)\n- Design drivers and constraints (Section 2.2.1)\n- User personas and use cases (Section 2.3)\n- Business context and requirements\n\n**Example questions**:\n- \"What problem does this solve?\"\n- \"Who are the users?\"\n- \"What are the key use cases?\"\n- \"What drove the architectural design?\"\n- \"What are the design constraints?\"\n- \"What are the primary user scenarios?\"\n\n**Typical line range**: Lines 81-200\n\n**Subsections to check**:\n- 2.1 Problem Statement\n- 2.2 Solution Overview\n- 2.2.1 Design Drivers (Value Delivery, Scale, Impacts)\n- 2.3 Primary Use Cases\n\n---\n\n## Section 3: Architecture Principles\n\n**Answers queries about**:\n- Guiding architectural principles\n- Design philosophy and approach\n- Trade-offs and priorities\n- Architectural values and standards\n\n**Example questions**:\n- \"What principles guide the architecture?\"\n- \"How do you approach [scalability/security/resilience]?\"\n- \"What's the architectural philosophy?\"\n- \"What trade-offs were made in the design?\"\n- \"What are the core architectural values?\"\n- \"Why was [principle X] chosen?\"\n\n**Typical line range**: Lines 201-400\n\n**Required principles** (in order):\n1. Separation of Concerns\n2. High Availability\n3. Scalability First\n4. Security by Design\n5. Observability\n6. Resilience\n7. Simplicity\n8. Cloud-Native\n9. Open Standards\n10. Decouple Through Events (optional - selective async patterns)\n\n**Subsections to check**:\n- Each principle has: Description, Implementation, Trade-offs\n\n---\n\n## Section 4: Architecture Layers\n\n**Answers queries about**:\n- Architectural layers and their responsibilities\n- Layer interactions and dependencies\n- Deployment architecture\n- Environment structure (dev, staging, prod)\n- Cloud provider and regions\n- Infrastructure deployment model\n- Network topology\n\n**Example questions**:\n- \"Where is this deployed?\"\n- \"What cloud provider do you use?\"\n- \"How are environments structured?\"\n- \"What are the architectural layers?\"\n- \"How do layers interact?\"\n- \"What's the deployment model?\"\n- \"What regions are used?\"\n\n**Typical line range**: Lines 401-600\n\n**Architecture Type Variations**:\n- **Microservices (Recommended)**: Service mesh, API Gateway, microservices catalog, cloud-native patterns\n- **META**: 6 layers (Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Business ‚Üí Domain ‚Üí Core)\n- **3-Tier**: 3 tiers (Presentation ‚Üí Application ‚Üí Data)\n- **N-Layer**: DDD, Clean Architecture, or Hexagonal patterns\n\n**Subsections to check**:\n- Layer definitions and responsibilities\n- Cloud infrastructure details\n- Environment configuration\n- BIAN alignment (for META architecture)\n\n---\n\n## Section 5: Component Details\n\n**Answers queries about**:\n- Individual components and services\n- Component responsibilities\n- Inter-component communication\n- Component architecture patterns\n- Service catalog\n\n**Example questions**:\n- \"What components make up the system?\"\n- \"How does [component X] work?\"\n- \"What does the [service name] do?\"\n- \"What are the responsibilities of [component]?\"\n- \"How do components communicate?\"\n- \"What services are in the system?\"\n\n**Typical line range**: Lines 601-850\n\n**Subsections to check**:\n- Component subsections (### 5.1, 5.2, etc.)\n- Each component typically has:\n  - Purpose\n  - Responsibilities\n  - Technologies\n  - Dependencies\n  - Communication patterns\n\n---\n\n## Section 6: Data Flow Patterns\n\n**Answers queries about**:\n- How data moves through the system\n- Data pipelines and transformations\n- Event flows and messaging\n- Data synchronization patterns\n- Request/response flows\n- Data processing workflows\n\n**Example questions**:\n- \"How does data flow through the system?\"\n- \"What happens when [event X] occurs?\"\n- \"How is data transformed?\"\n- \"How do you handle [data type] processing?\"\n- \"What's the flow for [use case]?\"\n- \"How is data synchronized between [A] and [B]?\"\n\n**Typical line range**: Lines 851-1000\n\n**Note**: This section is **optional** for simple systems. If omitted, sections are renumbered (7‚Üí6, 8‚Üí7, etc.)\n\n**Subsections to check**:\n- Data flow diagrams (often Mermaid)\n- Event flows\n- Pipeline descriptions\n- Transformation logic\n\n---\n\n## Section 7: Integration Points\n\n**Answers queries about**:\n- External system integrations\n- APIs consumed or provided\n- Third-party services\n- Integration patterns and protocols\n- API endpoints and contracts\n- Data exchange formats\n\n**Example questions**:\n- \"What external systems do you integrate with?\"\n- \"What APIs does this expose?\"\n- \"How do you integrate with [system X]?\"\n- \"What third-party services are used?\"\n- \"What integration patterns do you use?\"\n- \"How do you communicate with [external system]?\"\n\n**Typical line range**: Lines 1001-1150\n\n**Subsections to check**:\n- External system integrations (subsection per integration)\n- API catalog (exposed APIs)\n- Integration protocols (REST, GraphQL, SOAP, etc.)\n- Data formats (JSON, XML, Protobuf)\n- Authentication for integrations\n\n---\n\n## Section 8: Technology Stack\n\n**Answers queries about**:\n- Programming languages and frameworks\n- Databases and data stores\n- Tools and libraries\n- Infrastructure technologies\n- Versions and dependencies\n- Build and deployment tools\n\n**Example questions**:\n- \"What technologies do you use?\"\n- \"What's the tech stack?\"\n- \"What database do you use?\"\n- \"What programming language is this?\"\n- \"What version of [technology] do you use?\"\n- \"What frameworks are you using?\"\n\n**Typical line range**: Lines 1151-1300\n\n**Common subsections**:\n- Languages (e.g., Java 17, Python 3.11)\n- Frameworks (e.g., Spring Boot, React)\n- Databases (e.g., PostgreSQL, Redis, Elasticsearch)\n- Infrastructure (e.g., Kubernetes, Docker)\n- Tools (e.g., Jenkins, Terraform)\n- Monitoring (e.g., Prometheus, Grafana)\n\n**Subsections to check**:\n- Backend stack\n- Frontend stack (if applicable)\n- Data tier\n- DevOps tools\n- Monitoring and observability tools\n\n---\n\n## Section 9: Security Architecture\n\n**Answers queries about**:\n- Authentication and authorization\n- Security controls and measures\n- Encryption approaches (at rest, in transit)\n- Compliance requirements (GDPR, SOC2, PCI-DSS)\n- Security monitoring and incident response\n- Vulnerability management\n- Access control mechanisms\n\n**Example questions**:\n- \"How do you handle authentication?\"\n- \"What security measures are in place?\"\n- \"How is data encrypted?\"\n- \"What compliance standards do you follow?\"\n- \"How do you manage access control?\"\n- \"What's the security architecture?\"\n- \"How do you detect security threats?\"\n\n**Typical line range**: Lines 1301-1550\n\n**Subsections to check**:\n- Authentication & Authorization\n- Data Encryption (at rest and in transit)\n- Compliance (GDPR, SOC2, etc.)\n- Security monitoring and logging\n- Threat detection\n- Vulnerability management\n\n---\n\n## Section 10: Scalability & Performance\n\n**Answers queries about**:\n- Performance targets (latency, throughput)\n- Scalability approach (horizontal, vertical)\n- SLAs and availability targets\n- Capacity planning\n- Load balancing strategies\n- Caching strategies\n- Auto-scaling policies\n\n**Example questions**:\n- \"How does this scale?\"\n- \"What are the performance targets?\"\n- \"What's the availability SLA?\"\n- \"How many requests can it handle?\"\n- \"How do you handle load?\"\n- \"What's the capacity planning approach?\"\n- \"How do you ensure high availability?\"\n\n**Typical line range**: Lines 1551-1750\n\n**Subsections to check**:\n- Performance requirements (latency, TPS)\n- Scalability strategy\n- Throughput targets\n- Capacity planning tables\n- Auto-scaling configuration\n- Load balancing approach\n- Caching layers\n\n**Note**: Often contains duplicate metrics from Section 1 Executive Summary. Check for consistency.\n\n---\n\n## Section 11: Operational Considerations\n\n**Answers queries about**:\n- Monitoring and observability\n- Logging and tracing\n- Backup and recovery\n- Incident management\n- Deployment procedures\n- Runbooks and operational procedures\n- Alerting and on-call\n\n**Example questions**:\n- \"How is this monitored?\"\n- \"What's the backup strategy?\"\n- \"How do you handle incidents?\"\n- \"How do you deploy changes?\"\n- \"What observability tools do you use?\"\n- \"How do you troubleshoot issues?\"\n- \"What's the disaster recovery plan?\"\n\n**Typical line range**: Lines 1751-1950\n\n**Subsections to check**:\n- Monitoring and observability\n- Logging strategy\n- Backup and recovery\n- Incident management\n- Deployment procedures\n- Runbooks\n- Disaster recovery\n\n---\n\n## Section 12: Architecture Decision Records (ADRs)\n\n**Answers queries about**:\n- Why specific technologies were chosen\n- Architectural trade-offs and rationale\n- Decision history and context\n- Alternatives considered\n- Key architectural choices\n\n**Example questions**:\n- \"Why did you choose [technology X]?\"\n- \"What were the trade-offs for [decision Y]?\"\n- \"Why this approach over [alternative]?\"\n- \"What alternatives were considered?\"\n- \"What's the rationale for [architectural decision]?\"\n- \"What key decisions were made?\"\n\n**Typical line range**: Lines 1951-end\n\n**Subsections to check**:\n- ADR entries (each ADR has: Title, Status, Context, Decision, Consequences)\n- References to separate ADR files (if using external ADR documents)\n\n**ADR Format**:\n```markdown\n### ADR-XXX: [Decision Title]\n\n**Status**: [Accepted | Rejected | Deprecated | Superseded]\n**Date**: YYYY-MM-DD\n**Deciders**: [Names/Roles]\n\n**Context**: Why was this decision needed?\n**Decision**: What was decided?\n**Consequences**: What are the impacts (positive and negative)?\n**Alternatives Considered**: What other options were evaluated?\n```\n\n---\n\n## Multi-Section Query Scenarios\n\nSome questions require information from **multiple sections**. Here are common multi-section scenarios:\n\n### Scenario 1: Security + Integrations\n\n**Question**: \"How does authentication work with external systems?\"\n\n**Sections to load**:\n- Section 9 (Security Architecture ‚Üí Authentication)\n- Section 7 (Integration Points ‚Üí External Systems)\n\n**Answer should synthesize**:\n- Authentication mechanism from Section 9\n- How external integrations use that authentication from Section 7\n\n---\n\n### Scenario 2: Technology Stack + Deployment\n\n**Question**: \"What's the backend tech stack and how is it deployed?\"\n\n**Sections to load**:\n- Section 8 (Technology Stack ‚Üí Backend)\n- Section 4 (Architecture Layers ‚Üí Cloud Infrastructure)\n\n**Answer should synthesize**:\n- Technologies used from Section 8\n- Deployment environment and approach from Section 4\n\n---\n\n### Scenario 3: Components + Data Flow\n\n**Question**: \"How does the [Component X] process data?\"\n\n**Sections to load**:\n- Section 5 (Component Details ‚Üí Component X)\n- Section 6 (Data Flow Patterns)\n\n**Answer should synthesize**:\n- Component responsibilities from Section 5\n- Data processing flow from Section 6\n\n---\n\n### Scenario 4: Performance + Scalability + Operations\n\n**Question**: \"How do you ensure the system meets performance SLAs?\"\n\n**Sections to load**:\n- Section 10 (Scalability & Performance ‚Üí SLAs)\n- Section 11 (Operational Considerations ‚Üí Monitoring)\n- Section 3 (Architecture Principles ‚Üí High Availability)\n\n**Answer should synthesize**:\n- Performance targets from Section 10\n- Monitoring approach from Section 11\n- Architectural principles supporting SLAs from Section 3\n\n---\n\n## Edge Cases and Ambiguous Queries\n\n### Edge Case 1: Generic \"How does it work?\" Questions\n\n**Question**: \"How does the system work?\"\n\n**Strategy**: Too broad - load Section 1 (Executive Summary) for high-level overview, then ask clarifying questions.\n\n**Response template**:\n```\n[Provide high-level summary from Section 1]\n\nWould you like me to dive deeper into:\n- Specific components (Section 5)?\n- Data flows (Section 6)?\n- Technology stack (Section 8)?\n- Security architecture (Section 9)?\n```\n\n---\n\n### Edge Case 2: Cross-Cutting Concerns\n\n**Question**: \"How do you handle errors?\"\n\n**Multiple possible sections**:\n- Section 3 (Architecture Principles ‚Üí Resilience)\n- Section 6 (Data Flow Patterns ‚Üí Error handling flows)\n- Section 11 (Operational Considerations ‚Üí Monitoring & Alerting)\n\n**Strategy**: Load all relevant sections, synthesize a comprehensive answer covering principles, implementation, and operations.\n\n---\n\n### Edge Case 3: Versioning and Change History\n\n**Question**: \"What changed in the last update?\"\n\n**Strategy**: ARCHITECTURE.md typically doesn't track change history. Suggest:\n- Check version control system (git log)\n- Review Section 12 (ADRs) for recent decisions\n- Check \"Index Last Updated\" date in Document Index\n\n---\n\n### Edge Case 4: Future Plans and Roadmap\n\n**Question**: \"What's planned for the future?\"\n\n**Strategy**: ARCHITECTURE.md documents **current state**, not future plans.\n\n**Response template**:\n```\nARCHITECTURE.md documents the current architecture. Future plans are typically maintained in:\n- Product roadmap documents\n- Architecture Decision Records (Section 12) with status \"Proposed\"\n- Separate planning documents\n\nWould you like me to help document a proposed architectural change in Section 12 as an ADR?\n```\n\n---\n\n## Query Classification Decision Tree\n\nUse this decision tree to quickly classify user queries:\n\n```\nUser Question\n‚îÇ\n‚îú‚îÄ Mentions \"problem\", \"why build this\" ‚Üí Section 2 (System Overview)\n‚îú‚îÄ Mentions \"principle\", \"approach\", \"philosophy\" ‚Üí Section 3 (Architecture Principles)\n‚îú‚îÄ Mentions \"layer\", \"tier\", \"deployment\", \"cloud\" ‚Üí Section 4 (Architecture Layers)\n‚îú‚îÄ Mentions \"component\", \"service\", \"module\" ‚Üí Section 5 (Component Details)\n‚îú‚îÄ Mentions \"flow\", \"pipeline\", \"event\", \"transform\" ‚Üí Section 6 (Data Flow Patterns)\n‚îú‚îÄ Mentions \"integration\", \"API\", \"external\", \"third-party\" ‚Üí Section 7 (Integration Points)\n‚îú‚îÄ Mentions \"technology\", \"database\", \"language\", \"framework\" ‚Üí Section 8 (Technology Stack)\n‚îú‚îÄ Mentions \"security\", \"authentication\", \"encryption\", \"compliance\" ‚Üí Section 9 (Security)\n‚îú‚îÄ Mentions \"scale\", \"performance\", \"SLA\", \"capacity\" ‚Üí Section 10 (Scalability & Performance)\n‚îú‚îÄ Mentions \"monitoring\", \"backup\", \"incident\", \"deployment\" ‚Üí Section 11 (Operational Considerations)\n‚îú‚îÄ Mentions \"why choose\", \"trade-off\", \"decision\", \"alternative\" ‚Üí Section 12 (ADRs)\n‚îî‚îÄ Generic \"what is\", \"overview\", \"summary\" ‚Üí Section 1 (Executive Summary)\n```\n\n---\n\n## Best Practices for Query-to-Section Mapping\n\n**DO:**\n- ‚úÖ Start with the most specific section first\n- ‚úÖ Load additional sections if the first doesn't fully answer the question\n- ‚úÖ Consider cross-section queries for complex questions\n- ‚úÖ Check Document Index for actual section line ranges (don't assume)\n- ‚úÖ Use minimal buffers (¬±10-20 lines) for efficiency\n- ‚úÖ Synthesize multi-section answers clearly\n\n**DON'T:**\n- ‚ùå Load all sections for broad questions (start with Section 1, then drill down)\n- ‚ùå Assume section line ranges without checking Document Index\n- ‚ùå Mix documented content with assumptions\n- ‚ùå Skip citations when answering from ARCHITECTURE.md\n- ‚ùå Load full document when 1-2 sections suffice\n\n---\n\n## Example Query Mapping Workflow\n\n**User Question**: \"What authentication method do we use and how is it deployed?\"\n\n**Step 1: Classify Query**\n- Primary topic: Authentication ‚Üí Section 9\n- Secondary topic: Deployment ‚Üí Section 4\n\n**Step 2: Load Document Index**\n```\nRead(file_path=\"ARCHITECTURE.md\", offset=1, limit=50)\n```\n\n**Result**:\n- Section 9: Lines 1301-1550\n- Section 4: Lines 401-600\n\n**Step 3: Load Section 9 (Primary)**\n```\nbuffer = 20\noffset = 1301 - 20 - 1 = 1280\nlimit = (1550 - 1301) + 40 = 249 + 40 = 289\nRead(file_path=\"ARCHITECTURE.md\", offset=1280, limit=289)\n```\n\n**Step 4: Search for Authentication Details**\n- Found: OAuth 2.0, JWT tokens, MFA (lines 1343-1367)\n\n**Step 5: Load Section 4 (Secondary)**\n```\noffset = 401 - 20 - 1 = 380\nlimit = (600 - 401) + 40 = 199 + 40 = 239\nRead(file_path=\"ARCHITECTURE.md\", offset=380, limit=239)\n```\n\n**Step 6: Search for Deployment Details**\n- Found: AWS deployment, ECS containers (lines 450-475)\n\n**Step 7: Synthesize Answer with Citations**\n```\nThe system uses OAuth 2.0 for authentication with JWT tokens for API access.\nMulti-factor authentication (MFA) is required for administrative users.\n\nThe authentication service is deployed as a containerized microservice on AWS ECS\nwith auto-scaling enabled for high availability.\n\n**Sources**:\n- ARCHITECTURE.md Section 9 (Security Architecture ‚Üí Authentication), lines 1343-1367\n- ARCHITECTURE.md Section 4 (Architecture Layers ‚Üí Cloud Deployment), lines 450-475\n```\n\n---\n\n## Summary\n\nThis guide enables efficient, context-optimized answers to user questions by:\n\n1. **Mapping questions to specific sections** (avoiding full document loads)\n2. **Providing clear section targets** (minimizing guesswork)\n3. **Supporting multi-section queries** (for complex questions)\n4. **Handling edge cases** (ambiguous or out-of-scope queries)\n\nUse this guide in conjunction with **Workflow 7: Informational Query** (in SKILL.md) for complete implementation details.\n",
        "skills/architecture-docs/REVIEW_AUDIT_WORKFLOW.md": "# Architecture Review & Audit Workflow\n\n## Overview\n\nThis document defines the two-phase review and audit workflow for ARCHITECTURE.md documents.\n\n**Purpose**: Ensure structural integrity (Phase 1) before content improvement (Phase 2)\n\n**Trigger**: Manual only - activated when user requests \"review\", \"audit\", or \"validate\"\n\n**Key Principle**: Phase 1 must pass (no ‚ùå failed checks) before Phase 2 runs\n\n---\n\n## Phase 1: Form Validation (Blocking)\n\n### Purpose\n\nVerify structural integrity and compliance with architecture documentation standards. This phase ensures the document has the correct structure, required sections, and follows formatting standards before examining content quality.\n\n### Validation Categories\n\n#### 1. Section Structure Compliance\n\n**What to Check**:\n- All 12 required sections present and correctly ordered\n- Section numbering consistent (1-12)\n- Section names match standard naming exactly (case-sensitive)\n- Document Index present with accurate line range references\n\n**Standard Section Names**:\n1. Executive Summary\n2. System Overview\n3. Architecture Principles\n4. Architecture Layers (formerly \"Meta Architecture\")\n5. Component Details\n6. Data Flow Patterns\n7. Integration Points\n8. Technology Stack\n9. Security Architecture\n10. Scalability & Performance\n11. Operational Considerations\n12. Architecture Decision Records (ADRs)\n\n**Common Violations**:\n- ‚ùå Section missing entirely\n- ‚ùå Section misspelled or wrong case (e.g., \"system overview\" vs \"System Overview\")\n- ‚ùå Sections in wrong order\n- ‚ùå Section numbering skipped or duplicated\n\n---\n\n#### 2. Architecture Type Validation\n\n**What to Check**:\n- HTML comment with architecture type present at top of Section 4: `<!-- ARCHITECTURE_TYPE: {TYPE} -->`\n- Architecture type is one of: MICROSERVICES, META, 3-TIER, N-LAYER, BIAN\n- Section 4 (Architecture Layers) structure matches declared architecture type\n- Section 5 (Component Details) component organization matches architecture type\n\n**Architecture Type Requirements**:\n\n**Microservices Architecture (Recommended)**:\n- Section 4 must define service mesh topology and communication patterns\n- Section 5 must provide service catalog with bounded contexts and APIs\n\n**META Architecture (6-Layer)**:\n- Section 4 must define 6 layers: Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Integration ‚Üí Domain ‚Üí Core\n- Section 5 components must be mapped to these 6 layers\n- Layer 5 (Domain) must include BIAN V12.0 alignment section\n\n**3-Tier Architecture**:\n- Section 4 must define 3 tiers: Presentation ‚Üí Application/Business Logic ‚Üí Data\n- Section 5 components must be organized by tier assignment\n\n**N-Layer Architecture**:\n- Section 4 must define custom layers (4-7 layers typical)\n- Section 5 components must be mapped to defined layers\n\n**BIAN Architecture (5-Layer BIAN-Compliant)**:\n- Section 4 must define 5 BIAN layers in order: Channels ‚Üí BIAN Business Scenarios ‚Üí BIAN Business Capabilities ‚Üí BIAN Service Domains ‚Üí Core Systems\n- Layer 2 must map to BIAN Business Areas (5 areas)\n- Layer 3 must map to BIAN Business Domains (30+ domains)\n- Layer 4 must implement BIAN Service Domains from [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- All Layer 4 service domain names validated against official BIAN Service Landscape\n- Section 5 components must be grouped by all 5 BIAN layers\n- Layer 4 components must include complete BIAN metadata (12 required fields):\n  1. Official BIAN Name, 2. BIAN ID (SD-XXX), 3. BIAN Version (V12.0), 4. BIAN Business Domain, 5. BIAN Business Area, 6. BIAN Service Landscape URL, 7. Control Record, 8. Service Operations (Initiate, Update, Retrieve, Control), 9. Behavior Qualifiers, 10. Functional Patterns, 11. BIAN Compliance Level, 12. BIAN Traceability\n- Full BIAN V12.0 compliance level documented for all Layer 4 service domains\n- BIAN hierarchy traceability: Service Domain ‚Üí Business Domain ‚Üí Business Area\n\n**Common Violations**:\n- ‚ùå Missing architecture type HTML comment\n- ‚ùå Invalid architecture type value\n- ‚ùå Section 4 structure doesn't match declared type\n- ‚ùå Section 5 components not organized according to architecture type\n- ‚ùå BIAN: Missing layers (not all 5 layers present)\n- ‚ùå BIAN: Layer 4 service domain names don't match BIAN V12.0\n- ‚ùå BIAN: Layer 4 components missing BIAN metadata (all 12 fields required)\n- ‚ùå BIAN: Control records not documented per BIAN specification\n- ‚ùå BIAN: Missing mandatory BIAN service operations\n- ‚ùå BIAN: BIAN hierarchy not traceable\n\n---\n\n#### 3. Architecture Principles Enforcement\n\n**What to Check**:\n- All 9 core principles documented in Section 3\n- Each principle has three required subsections:\n  1. **Description**: What the principle is and why it matters\n  2. **Implementation**: How it's implemented in this specific system\n  3. **Trade-offs**: Real costs and downsides (minimum 3 trade-offs per principle)\n- Trade-offs are honest and substantive (not superficial or generic)\n\n**9 Core Principles**:\n1. Separation of Concerns\n2. High Availability\n3. Scalability First\n4. Security by Design\n5. Observability\n6. Resilience\n7. Simplicity\n8. Cloud-Native (or equivalent deployment model)\n9. Open Standards\n\n**Trade-off Quality Criteria**:\n- ‚úÖ **Good**: \"3x infrastructure costs for redundancy, 10-minute manual database failover RTO, requires 24/7 on-call rotation\"\n- ‚ùå **Bad**: \"More complexity\", \"Higher costs\", \"Increased operational burden\" (too vague)\n\n**Common Violations**:\n- ‚ùå Missing one or more core principles\n- ‚ùå Principle lacks Description, Implementation, or Trade-offs subsection\n- ‚ùå Fewer than 3 trade-offs listed\n- ‚ùå Trade-offs are superficial or generic\n\n---\n\n#### 4. Markdown Formatting\n\n**What to Check**:\n- Valid markdown syntax throughout document\n- Consistent heading levels (no skipped levels: H1 ‚Üí H2 ‚Üí H3, never H1 ‚Üí H3)\n- Code blocks properly formatted with language tags (```bash, ```typescript, etc.)\n- Tables properly formatted with header rows and alignment\n- Lists use consistent bullet style (-, *, or +)\n\n**Common Violations**:\n- ‚ùå Broken markdown links: `[text](url)` format incorrect\n- ‚ùå Code blocks missing language tags: ` ``` ` instead of ` ```bash `\n- ‚ùå Tables with misaligned columns or missing separators\n- ‚ùå Heading level skipped (e.g., H2 ‚Üí H4 without H3)\n\n---\n\n#### 5. Metric Consistency\n\n**What to Check**:\n- Section 1 (Executive Summary) defines key metrics\n- Same metric values appear consistently throughout document\n- Metrics to verify:\n  - Read TPS (average and peak)\n  - Write TPS (average and peak)\n  - Latency (p95, p99)\n  - Availability SLA (% uptime)\n  - Concurrent users\n\n**Common Violations**:\n- ‚ùå Section 1 shows \"500 Read TPS\" but Section 9 shows \"450 Read TPS\"\n- ‚ùå Latency targets defined in Section 1 but different values in Section 9\n- ‚ùå Metrics missing from Section 1 entirely\n\n---\n\n### Phase 1 Output Format\n\n```markdown\n## Phase 1: Form Validation\n\n### Status: ‚ùå FAILED\n\n### Failed Checks:\n- ‚ùå Section 4 name: Found \"Meta Architecture\", expected \"Architecture Layers\"\n- ‚ùå Missing Architecture Principle: \"Resilience\" (Section 3)\n- ‚ùå Inconsistent Read TPS: Section 1 shows 500 TPS, Section 9 shows 450 TPS\n- ‚ùå Architecture Type HTML comment missing at document top\n\n### Warnings:\n- ‚ö†Ô∏è Document Index line ranges may be outdated (last update: 3 months ago)\n- ‚ö†Ô∏è Section 3.2 trade-offs include vague statement \"More complexity\"\n\n### Action Required:\nFix all ‚ùå Failed Checks before proceeding to Phase 2 (Content Improvement)\n\n**Phase 2 will NOT run until all failed checks are resolved.**\n```\n\n**OR** (if all checks pass):\n\n```markdown\n## Phase 1: Form Validation\n\n### Status: ‚úÖ PASSED\n\nAll structural validation checks passed. Proceeding to Phase 2: Content Improvement.\n\n### Warnings:\n- ‚ö†Ô∏è Document Index line ranges may be outdated (last update: 3 months ago)\n```\n\n---\n\n### Blocking Behavior\n\n**CRITICAL**: If Phase 1 has ANY failed checks (‚ùå), Phase 2 DOES NOT run.\n\nUser must:\n1. Fix all ‚ùå failed checks\n2. Re-request review/audit\n3. Phase 1 will run again\n\nOnly when Phase 1 shows **Status: ‚úÖ PASSED** does Phase 2 execute.\n\n---\n\n## Phase 2: Content Improvement (Prioritized)\n\n### Purpose\n\nSuggest content improvements based on criticality level, progressing from most critical (HIGH) to least critical (LOW). This phase analyzes content quality, completeness, and clarity.\n\n### Trigger\n\n**Runs ONLY if Phase 1 passes with no failed checks (‚ùå)**\n\n### Criticality Levels\n\nPhase 2 issues are categorized into three levels based on impact to the document's usability and reliability:\n\n- **HIGH**: Blocks publication/production use (must fix before document can be used)\n- **MEDIUM**: Reduces clarity/usability (should fix to improve understanding)\n- **LOW**: Polish/enhancement (optional improvements)\n\n---\n\n## Phase 2: Standards Compliance Framework\n\n### How Phase 2 Recommendations Reference Standards\n\nEvery Phase 2 recommendation in this workflow explicitly references the architecture-docs skill standards to ensure all proposed changes are grounded in documented best practices.\n\n**Enhanced Recommendation Structure**:\n\n1. **Issue Title** with location in user's document\n2. **What It Is**: Problem description and category\n3. **Standard Violated**: Guide document, section, and line numbers\n4. **Standard Requirement**: Direct quote from ARCHITECTURE_DOCUMENTATION_GUIDE.md\n5. **Guide Example**: Reference to example showing proper implementation\n6. **Current State**: What the user's document shows now\n7. **Recommended Fix**: How to comply with the standard (references guide template)\n8. **Compliance Checklist**: Items to verify that fix matches template requirements\n9. **Location**: Specific lines in user's document\n\n**Why This Matters**:\n- **Traceability**: Users can look up the exact standard being enforced\n- **Authority**: Recommendations backed by official guide, not arbitrary opinions\n- **Learning**: Users learn architecture-docs skill standards while fixing issues\n- **Consistency**: All reviews follow the same standards framework\n\n---\n\n### Standards Referenced by Phase 2 Issues\n\n| Standard | Location in Guide | Referenced By |\n|----------|-------------------|---------------|\n| **Component Template** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß5, lines 1007-1050 | HIGH.1, HIGH.4 |\n| **Integration Template** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß7, lines 1133-1179 | HIGH.5 |\n| **Architecture Principles Structure** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß3, lines 467-649 | HIGH.2 |\n| **Trade-off Quality Standards** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß3, lines 280-286, 641-648 | HIGH.2 |\n| **Metrics Specification** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß1 (lines 213-243), ¬ß10 (lines 1351-1368) | HIGH.3 |\n| **Component Formatting** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß5, lines 1010-1050 | MEDIUM.3 |\n| **Document Index Standard** | ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 83-171 | LOW.5 |\n\n---\n\n## HIGH Criticality (Blocks Publication/Production Use)\n\n### Definition\n\nIssues that render the architecture document **unreliable, misleading, or unusable** for its intended purpose:\n- Guiding implementation decisions\n- Enabling engineer onboarding\n- Supporting architectural reviews\n- Documenting system behavior for operations/SRE\n\nHIGH criticality issues prevent the document from serving as a trustworthy reference.\n\n---\n\n### HIGH.1: Missing Implementation Details\n\n**What It Is**:\nCritical components lack technical specifications necessary for implementation, deployment, or operations.\n\n**Standard Violated**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, Section 5 (lines 1007-1050)\n\n**Standard Requirement**:\n> Component Template requires: **Type**, **Technology**, **Version**, **Location**, **Purpose**, **Responsibilities**, **APIs/Interfaces**, **Dependencies**, **Configuration**, **Scaling**, **Failure Modes**, **Monitoring**\n\n**Guide Example**: See ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 1052-1101 for complete OrderService component example showing all required fields\n\n**Examples of Missing Details**:\n- Component has no technology stack specified (language, framework, runtime)\n- No scaling strategy defined for components handling high load\n- Missing configuration parameters required for deployment\n- No failure mode analysis for critical components\n- Missing API specification (endpoints, methods, request/response formats)\n\n**Example Issue**:\n```markdown\n### HIGH Criticality (Must Fix Before Publication)\n\n1. **Missing Implementation Details - OrderService** (Section 5.2)\n   - Issue: No failure mode analysis provided\n   - Standard Violated: ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß5, lines 1007-1050 (Component Template)\n   - Standard Requirement: Component Template requires **Failure Modes** field documenting what happens when dependencies fail\n   - Guide Example: Lines 1052-1101 show OrderService with complete failure mode analysis\n   - Current: OrderService documented but **Failure Modes** subsection missing\n   - Impact: Engineers cannot design error handling, retry logic, or monitoring alerts\n   - Recommendation: Follow Component Template by adding **Failure Modes** subsection:\n     - InventoryService unavailable: Circuit breaker pattern, return 503 Service Unavailable\n     - PaymentService timeout (>10s): Retry 3 times with exponential backoff, mark order as pending\n     - Database connection failure: Connection pool exhaustion, queue requests, timeout after 5s\n   - Compliance Checklist:\n     - [ ] Includes **Failure Modes** subsection heading (bold)\n     - [ ] Documents behavior for each critical dependency failure\n     - [ ] Specifies mitigation strategies (circuit breaker, retry, fallback)\n     - [ ] Follows guide example structure\n   - Location: Section 5.2, lines 293-341\n```\n\n---\n\n### HIGH.2: Dishonest or Superficial Trade-offs\n\n**What It Is**:\nArchitecture Principles (Section 3) list trade-offs that are vague, generic, or only mention positive aspects without real downsides.\n\n**Standard Violated**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, Section 3 (lines 467-649)\n\n**Standard Requirement**:\n> - \"Each principle requires 3 subsections: **Description**, **Implementation**, **Trade-offs**\" (lines 487-507)\n> - \"Trade-offs must be **honest and substantive** (not superficial or generic)\" (lines 641-648)\n> - \"Minimum 3 trade-offs per principle\"\n\n**Guide Example**: See ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 280-286 for examples of good vs. bad trade-offs\n\n**Characteristics of Superficial Trade-offs**:\n- Generic statements: \"More complexity\", \"Higher costs\", \"Additional overhead\"\n- No quantification of impact\n- No specifics about what makes it complex, costly, or burdensome\n- Only mentions benefits, omits real downsides\n\n**Good vs. Bad Trade-offs**:\n\n**‚ùå Superficial**:\n> \"Increased operational complexity managing multiple instances\"\n\n**‚úÖ Honest and Specific**:\n> \"Requires 24/7 on-call rotation (2 engineers minimum), 3x infrastructure costs ($15K/month vs $5K/month for single instance), 10-minute manual failover RTO for database primary, quarterly disaster recovery drills (8 hours per drill)\"\n\n**Example Issue**:\n```markdown\n2. **Dishonest Trade-off - High Availability Principle** (Section 3.2)\n   - Issue: Trade-off is vague and non-quantified\n   - Standard Violated: ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß3, lines 641-648\n   - Standard Requirement: \"Trade-offs must be honest and substantive (not superficial or generic)\"\n   - Guide Example: Lines 280-286 show good trade-offs with specific quantification\n   - Current: \"Increased operational complexity managing multiple instances\"\n   - Impact: Cannot assess true operational burden, staffing requirements, or cost implications\n   - Recommendation: Follow guide example by quantifying specific costs:\n     - On-call requirements: \"24/7 rotation, minimum 2 engineers\"\n     - Infrastructure costs: \"$15K/month (3x vs single instance $5K/month)\"\n     - Failover time: \"10-minute manual database failover RTO (not automated)\"\n     - Operational tasks: \"Quarterly disaster recovery drills (8 hours per drill)\"\n   - Compliance Checklist:\n     - [ ] Includes specific staffing numbers (not \"more people\")\n     - [ ] Includes cost quantification with dollar amounts (not \"higher costs\")\n     - [ ] Includes time-based metrics (RTO, drill duration)\n     - [ ] Follows guide example structure for honest trade-offs\n   - Location: Section 3.2, lines 110-115\n```\n\n---\n\n### HIGH.3: Inconsistent or Missing Metrics\n\n**What It Is**:\nKey performance metrics are either missing from Executive Summary or inconsistent beyond what Phase 1 catches.\n\n**Standard Violated**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, Section 1 (lines 213-243) and Section 10 (lines 1351-1368)\n\n**Standard Requirement**:\n> - Executive Summary must specify: **Read TPS**, **Processing TPS**, **Write TPS**, **Availability SLA**, **Latency Targets** (p95, p99)\n> - Include \"**Measurement Period**\" context (e.g., \"measured over last 30 days\")\n> - Metrics must be consistent between Section 1 and Section 10\n\n**Guide Example**: See ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 213-243 for proper metrics documentation format\n\n**Examples**:\n- No Read TPS specified in Section 1 (cannot assess scalability requirements)\n- Latency targets undefined (p95, p99 not documented)\n- Availability SLA not specified (cannot design for reliability)\n- Component-level metrics missing (e.g., database IOPS, API rate limits)\n\n**Example Issue**:\n```markdown\n3. **Missing Metrics - Executive Summary** (Section 1)\n   - Issue: No Read TPS or Write TPS specified in Section 1\n   - Standard Violated: ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß1, lines 213-243\n   - Standard Requirement: Executive Summary must include Read TPS, Write TPS with measurement period context\n   - Guide Example: Lines 213-243 show format: \"Read TPS: 500 TPS (average), 1,200 TPS (peak) - measured over last 30 days\"\n   - Current: Section 1 Key Metrics subsection missing TPS metrics entirely\n   - Impact: Cannot assess whether architecture supports expected load, cannot design scaling strategy\n   - Recommendation: Follow guide format by adding:\n     - \"Read TPS: 500 TPS (average), 1,200 TPS (peak) - measured over last 30 days\"\n     - \"Write TPS: 50 TPS (average), 150 TPS (peak) - measured over last 30 days\"\n   - Compliance Checklist:\n     - [ ] Includes Read TPS (average and peak)\n     - [ ] Includes Write TPS (average and peak)\n     - [ ] Includes measurement period context (\"measured over last X days\")\n     - [ ] Matches values in Section 10 (Scalability & Performance)\n   - Location: Section 1, lines 34-40\n```\n\n---\n\n### HIGH.4: Incomplete Component Documentation\n\n**What It Is**:\nCritical components in Section 5 (Component Details) are missing essential information required for implementation or operations.\n\n**Standard Violated**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, Section 5 (lines 1007-1050)\n\n**Standard Requirement**:\n> Component Template requires: **Type**, **Technology**, **Version**, **Location**, **Purpose**, **Responsibilities**, **APIs/Interfaces**, **Dependencies**, **Configuration**, **Scaling**, **Failure Modes**, **Monitoring**\n> (Same as HIGH.1 - uses Component Template standard)\n\n**Guide Example**: See ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 1052-1101 for complete OrderService component example\n\n**Required Component Information**:\n- **Purpose**: What the component does and why it exists\n- **Responsibilities**: Specific tasks and business logic\n- **Dependencies**: What it depends on and what depends on it\n- **Technology**: Language, framework, runtime, libraries\n- **Configuration**: Required environment variables, config files\n- **Scaling**: How it scales (horizontal/vertical), resource requirements\n- **Failure Modes**: What happens when dependencies fail, how it degrades\n- **Monitoring**: Key metrics, alerts, SLOs\n\n**Example Issue**:\n```markdown\n4. **Incomplete Component Documentation - PaymentService** (Section 5.4)\n   - Issue: Missing **Failure Modes** and **Monitoring** subsections\n   - Standard Violated: ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß5, lines 1007-1050 (Component Template)\n   - Standard Requirement: Component Template requires **Failure Modes** (dependency failures, mitigation) and **Monitoring** (metrics, alerts, SLOs)\n   - Guide Example: Lines 1052-1101 show OrderService with complete failure modes and monitoring\n   - Current: PaymentService documented but missing critical operational details\n   - Impact: Engineers cannot implement resilient payment processing, no monitoring strategy, risk payment failures without recovery\n   - Recommendation: Follow Component Template by adding:\n     - **Failure Modes**: Stripe API errors (card declined, insufficient funds, network timeout), retry logic (3 retries, exponential backoff 1s/2s/4s), circuit breaker (open after 50% error rate), compensation logic\n     - **Monitoring**: Key metrics (payment success rate, processing time p95/p99), alerts (error rate >2%, processing time >5s), SLO (99.9% success rate)\n   - Compliance Checklist:\n     - [ ] Includes **Failure Modes** subsection with dependency failures\n     - [ ] Includes **Monitoring** subsection with metrics and alerts\n     - [ ] Specifies mitigation strategies (retry, circuit breaker)\n     - [ ] Follows guide example structure\n   - Location: Section 5.4, lines 380-420\n```\n\n---\n\n### HIGH.5: Critical Integration Missing Details\n\n**What It Is**:\nExternal integrations (Section 7) lack essential details for secure, reliable communication.\n\n**Standard Violated**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, Section 7 (lines 1133-1179)\n\n**Standard Requirement**:\n> Integration documentation requires: **Type**, **Provider**, **Purpose**, **Protocol & Authentication**, **Rate Limits & SLA**, **Error Handling**, **Data Exchanged**, **Failure Behavior**, **Monitoring & Health Checks**, **Security**, **Cost**\n\n**Guide Example**: See ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 1180-1230 for complete Stripe integration example\n\n**Required Integration Information**:\n- **Authentication**: How system authenticates (API keys, OAuth, JWT)\n- **Error Handling**: Timeout values, retry logic, circuit breaker\n- **SLA**: Expected uptime, response time from external service\n- **Rate Limiting**: Request limits, backoff strategy\n- **Data Format**: Request/response schemas, content types\n- **Failure Behavior**: What happens when integration is unavailable\n\n**Example Issue**:\n```markdown\n5. **Critical Integration Missing Details - Stripe Payment Gateway** (Section 7.1)\n   - Issue: Missing **Error Handling** and **Rate Limits & SLA** fields\n   - Standard Violated: ARCHITECTURE_DOCUMENTATION_GUIDE.md, ¬ß7, lines 1133-1179 (Integration Template)\n   - Standard Requirement: Integration Template requires **Error Handling** (timeout, retry, circuit breaker) and **Rate Limits & SLA** (request limits, uptime guarantees)\n   - Guide Example: Lines 1180-1230 show Stripe integration with complete error handling and rate limits\n   - Current: Stripe integration documented but missing resilience and performance details\n   - Impact: Payment processing can hang indefinitely, no resilience if Stripe experiences degraded performance, risk exceeding rate limits\n   - Recommendation: Follow Integration Template by adding:\n     - **Error Handling**: Timeout (10s per request), retry logic (3 retries, exponential backoff 1s/2s/4s), circuit breaker (open after 50% error rate over 10 requests, 30s timeout before retry)\n     - **Rate Limits & SLA**: Max 100 requests/second (Stripe limit), 99.99% uptime SLA, <500ms response time (p95)\n   - Compliance Checklist:\n     - [ ] Includes **Error Handling** with timeout, retry, circuit breaker\n     - [ ] Includes **Rate Limits & SLA** with request limits and uptime guarantees\n     - [ ] Specifies backoff strategy for rate limiting\n     - [ ] Follows guide example structure\n   - Location: Section 7.1, lines 412-432\n```\n\n---\n\n## MEDIUM Criticality (Reduces Clarity/Usability)\n\n### Definition\n\nIssues that **reduce document clarity**, make onboarding harder, or create confusion, but **do not block implementation**. Engineers can still build the system, but understanding will be more difficult.\n\n---\n\n### MEDIUM.1: Weak Justifications\n\n**What It Is**:\nArchitecture Decision Records (ADRs) or technology choices lack clear rationale or don't explain why alternatives were rejected.\n\n**Example Issue**:\n```markdown\n### MEDIUM Criticality (Improves Clarity)\n\n1. **Weak Justification - ADR-001** (Section 12)\n   - Issue: Microservices alternative rejected but rationale incomplete\n   - Current: \"Rejected due to team size and operational complexity\"\n   - Impact: Future readers may question decision without full context, decision may be revisited unnecessarily\n   - Recommendation: Add specific constraints that drove decision:\n     - \"Team of 3 developers (no dedicated DevOps engineer)\"\n     - \"Infrastructure budget: <$10K/month (microservices requires API gateway, service mesh, multiple databases)\"\n     - \"Estimated 6-month delay for microservices setup vs 2-month 3-tier implementation\"\n   - Location: Section 12, ADR-001, lines 458-461\n```\n\n---\n\n### MEDIUM.2: Outdated References\n\n**What It Is**:\nTechnology versions, documentation links, or tool references are outdated or point to deprecated resources.\n\n**Example Issue**:\n```markdown\n2. **Outdated Reference - Technology Stack** (Section 8)\n   - Issue: References Node.js 14 (reached End-of-Life April 30, 2023)\n   - Current: \"Node.js 14, Express.js 4\"\n   - Impact: Misleading for new engineers, Node.js 14 has security vulnerabilities\n   - Recommendation: Update to current LTS version: \"Node.js 20 LTS, Express.js 4\"\n   - Location: Section 8, line 612\n```\n\n---\n\n### MEDIUM.3: Inconsistent Formatting\n\n**What It Is**:\nComponent documentation structure, emphasis styles, or table formatting varies across sections, reducing readability.\n\n**Example Issue**:\n```markdown\n3. **Inconsistent Formatting - Component Documentation** (Section 5)\n   - Issue: Section 5.1 uses '**Type**:' (bold), Section 5.2 uses 'Type:' (no bold)\n   - Impact: Reduces visual consistency, harder to scan for specific fields\n   - Recommendation: Standardize all component subsection headers to bold:\n     - **Type**, **Technology**, **Location**, **Purpose**, etc.\n   - Locations: Section 5.1 (line 244), Section 5.2 (line 294), Section 5.3 (line 346)\n```\n\n---\n\n### MEDIUM.4: Missing Cross-References\n\n**What It Is**:\nDocument references other components, sections, or ADRs without providing navigation links or section numbers.\n\n**Example Issue**:\n```markdown\n4. **Missing Cross-Reference - OrderService Dependencies** (Section 5.2)\n   - Issue: References PaymentService without cross-reference link\n   - Current: \"Order processing coordination (via PaymentService)\"\n   - Impact: Readers must manually search for PaymentService documentation\n   - Recommendation: Add section reference: \"Order processing coordination (via PaymentService, Section 5.4)\"\n   - Location: Section 5.2, line 305\n```\n\n---\n\n### MEDIUM.5: Ambiguous Terminology\n\n**What It Is**:\nTechnical terms, acronyms, or domain-specific language used without definition or context.\n\n**Example Issue**:\n```markdown\n5. **Ambiguous Terminology - Circuit Breaker Pattern** (Section 5.2)\n   - Issue: \"Circuit breaker pattern\" mentioned without explanation\n   - Impact: Engineers unfamiliar with pattern may not understand implementation\n   - Recommendation: Add brief explanation or link:\n     - \"Circuit breaker pattern (prevents cascading failures by stopping requests to failing service)\"\n     - OR: \"Circuit breaker pattern (see Section 3.6 Resilience for details)\"\n   - Location: Section 5.2, line 334\n```\n\n---\n\n## LOW Criticality (Polish/Enhancement)\n\n### Definition\n\nMinor improvements that **enhance document quality** but **do not affect understanding or implementation**. These are optional refinements.\n\n---\n\n### LOW.1: Formatting Suggestions\n\n**What It Is**:\nCosmetic formatting improvements for visual consistency.\n\n**Example Issue**:\n```markdown\n### LOW Criticality (Optional Polish)\n\n1. **Formatting Suggestion - Section Headers**\n   - Observation: Inconsistent blank lines before H2 headers (some have 2, some have 1)\n   - Recommendation: Standardize to 2 blank lines before all H2 headers for visual separation\n   - Impact: Improves readability, no functional change\n   - Location: Throughout document\n```\n\n---\n\n### LOW.2: Clarity Improvements\n\n**What It Is**:\nSentence restructuring or simplification for easier reading.\n\n**Example Issue**:\n```markdown\n2. **Clarity Improvement - Passive Voice** (Section 2.1)\n   - Observation: \"The system is designed to handle high-throughput order processing\"\n   - Recommendation: Use active voice: \"The system handles high-throughput order processing\"\n   - Impact: More direct and concise\n   - Location: Section 2.1, line 56\n```\n\n---\n\n### LOW.3: Additional Context\n\n**What It Is**:\nOptional background information, historical context, or links to related documentation.\n\n**Example Issue**:\n```markdown\n3. **Additional Context - API Design** (Section 6)\n   - Observation: Integration Points section could reference team's API design guide\n   - Recommendation: Add reference: \"All integrations follow team API design standards (see: /docs/api-design-guide.md)\"\n   - Impact: Provides additional context for API patterns\n   - Location: Section 6, header (after line 410)\n```\n\n---\n\n### LOW.4: Redundancy Reduction\n\n**What It Is**:\nDuplicate information across sections that could be consolidated for easier maintenance.\n\n**Example Issue**:\n```markdown\n4. **Redundancy Reduction - Database Configuration** (Sections 5.3 and 8)\n   - Observation: Connection pool settings documented in both Section 5.3 (OrderRepository) and Section 8 (Database Configuration)\n   - Current:\n     - Section 5.3: \"DB_CONNECTION_POOL_SIZE: Max connections (default: 20)\"\n     - Section 8: \"Connection pool: 20 connections per instance\"\n   - Recommendation: Document once in Section 8, reference from Section 5.3:\n     - Section 5.3: \"Connection pool: See Section 8 (Database Configuration)\"\n   - Impact: Single source of truth, easier to update\n   - Locations: Section 5.3 (line 383), Section 8 (line 625)\n```\n\n---\n\n### LOW.5: Document Index Maintenance\n\n**What It Is**:\nDocument Index line ranges may be outdated or inaccurate after content additions/deletions.\n\n**Best Practice Reference**: ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 83-171\n\n**Standard Requirement**:\n- Every ARCHITECTURE.md must include Document Index before Section 1\n- Index must list all 12 sections with accurate line number ranges\n- Update after significant section changes (>10 lines added/removed)\n\n**Example Issue**:\n```markdown\n5. **Outdated Document Index** (lines 11-23)\n   - Observation: Document Index shows \"Section 5: Component Details ‚Üí Lines 351-550\" but Section 5 actually starts at line 420\n   - Best Practice: ARCHITECTURE_DOCUMENTATION_GUIDE.md, lines 83-171 (Document Index standard)\n   - Current: Index line ranges haven't been updated in 3 months (30+ lines added to Section 4)\n   - Recommendation: Update Document Index line ranges to reflect current content:\n     - Verify each section's actual start and end lines\n     - Update index entries for all sections affected by recent changes\n     - Consider adding \"Index Last Updated\" timestamp\n   - Impact: Improves navigation, enables context-efficient editing, prevents confusion\n   - Location: Document Index, lines 11-23\n```\n\n---\n\n## Workflow Execution\n\n### Step 1: Trigger\n\nUser requests \"review\", \"audit\", or \"validate\" for their ARCHITECTURE.md document.\n\n**Example User Requests**:\n- \"Please review my ARCHITECTURE.md\"\n- \"Can you audit my architecture document?\"\n- \"Validate my ARCHITECTURE.md for completeness\"\n\n---\n\n### Step 2: Phase 1 Execution\n\n1. Run all form validation checks (5 categories)\n2. Generate Phase 1 report with ‚úÖ/‚ùå/‚ö†Ô∏è indicators\n3. If ANY ‚ùå failed checks exist, **STOP** and return Phase 1 report only\n\n**Phase 1 Report Structure**:\n```markdown\n## Phase 1: Form Validation\n\n### Status: ‚ùå FAILED (or ‚úÖ PASSED)\n\n### Failed Checks: (if any)\n- ‚ùå Issue description and location\n\n### Warnings: (if any)\n- ‚ö†Ô∏è Non-blocking issues\n\n### Action Required: (if failed)\nFix all ‚ùå Failed Checks before proceeding to Phase 2\n```\n\n---\n\n### Step 3: Phase 1 Pass Gate\n\n**Decision Point**:\n\n- **If Phase 1 has ‚ùå failed checks**: User must fix issues and re-request review\n- **If Phase 1 has ‚úÖ PASSED status**: Proceed to Phase 2\n\n---\n\n### Step 4: Phase 2 Execution\n\n1. Analyze content quality across all 12 sections\n2. Identify content issues and categorize by criticality:\n   - HIGH: Missing implementation details, dishonest trade-offs, missing metrics, incomplete components, integration gaps\n   - MEDIUM: Weak justifications, outdated references, inconsistent formatting, missing cross-references, ambiguous terminology\n   - LOW: Formatting suggestions, clarity improvements, additional context, redundancy reduction\n3. Generate prioritized improvement report\n\n**Phase 2 Report Structure**:\n```markdown\n## Phase 2: Content Improvement\n\n### HIGH Criticality (Must Fix Before Publication)\n[List HIGH issues with: Issue, Impact, Recommendation, Location]\n\n### MEDIUM Criticality (Improves Clarity)\n[List MEDIUM issues with: Issue, Impact, Recommendation, Location]\n\n### LOW Criticality (Optional Polish)\n[List LOW issues with: Observation, Recommendation, Impact, Location]\n```\n\n---\n\n### Step 5: Final Report\n\nCombine Phase 1 and Phase 2 results into single comprehensive report.\n\n**Presentation Order**:\n1. Phase 1 results (‚úÖ PASSED or ‚ùå FAILED)\n2. HIGH criticality issues (if Phase 1 passed)\n3. MEDIUM criticality issues (if Phase 1 passed)\n4. LOW criticality issues (if Phase 1 passed)\n\n---\n\n## Example Complete Report\n\n```markdown\n# Architecture Review Report: E-Commerce Platform ARCHITECTURE.md\n\n**Generated**: 2025-01-29 14:30 UTC\n**Document**: /path/to/ARCHITECTURE.md\n**Architecture Type**: 3-TIER\n\n---\n\n## Phase 1: Form Validation\n\n### Status: ‚úÖ PASSED\n\nAll structural validation checks passed. Proceeding to Phase 2: Content Improvement.\n\n### Warnings:\n- ‚ö†Ô∏è Document Index line ranges may be outdated (last update: 90 days ago)\n- ‚ö†Ô∏è Section 3.2 (High Availability) trade-off includes vague statement \"More complexity\"\n\n---\n\n## Phase 2: Content Improvement\n\n### HIGH Criticality (Must Fix Before Publication)\n\n**Found 3 HIGH criticality issues that block publication:**\n\n1. **Missing Implementation Details - OrderService** (Section 5.2)\n   - Issue: No failure mode analysis provided\n   - Impact: Engineers cannot design error handling, retry logic, or monitoring alerts\n   - Recommendation: Add failure modes for:\n     - InventoryService unavailable (circuit breaker behavior, fallback)\n     - PaymentService timeout (retry strategy, compensation logic)\n     - Database connection failure (connection pool exhaustion handling)\n   - Location: Section 5.2, lines 293-341\n\n2. **Dishonest Trade-off - High Availability Principle** (Section 3.2)\n   - Issue: Trade-off states \"More complexity\" without specifics\n   - Current: \"Increased operational complexity managing multiple instances\"\n   - Impact: Cannot assess true operational burden, staffing requirements, or cost implications\n   - Recommendation: Quantify specific costs:\n     - \"Requires 24/7 on-call rotation (2 engineers minimum)\"\n     - \"3x infrastructure costs: $15K/month vs $5K/month\"\n     - \"10-minute manual database failover RTO\"\n   - Location: Section 3.2, lines 110-115\n\n3. **Incomplete Component Documentation - PaymentService** (Section 5.4)\n   - Issue: No error handling, retry logic, or circuit breaker documentation\n   - Impact: Engineers cannot implement resilient payment processing\n   - Recommendation: Add:\n     - Error handling for Stripe API errors (card declined, timeout, etc.)\n     - Retry logic: 3 retries with exponential backoff, idempotency keys\n     - Circuit breaker: Open after 50% error rate, 30s timeout\n   - Location: Section 5.4, lines 380-420\n\n---\n\n### MEDIUM Criticality (Improves Clarity)\n\n**Found 2 MEDIUM criticality issues that reduce clarity:**\n\n1. **Weak Justification - ADR-001** (Section 12)\n   - Issue: Microservices alternative rejected but rationale incomplete\n   - Current: \"Rejected due to team size and operational complexity\"\n   - Impact: Future readers may question decision without full context\n   - Recommendation: Add specific constraints:\n     - \"Team of 3 developers (no DevOps engineer)\"\n     - \"Infrastructure budget: <$10K/month\"\n     - \"6-month delay for microservices vs 2-month 3-tier implementation\"\n   - Location: Section 12, ADR-001, lines 458-461\n\n2. **Missing Cross-Reference - OrderService** (Section 5.2)\n   - Issue: References PaymentService without cross-reference link\n   - Impact: Readers must manually search for PaymentService documentation\n   - Recommendation: Change \"via PaymentService\" to \"via PaymentService (Section 5.4)\"\n   - Location: Section 5.2, line 305\n\n---\n\n### LOW Criticality (Optional Polish)\n\n**Found 1 LOW criticality enhancement:**\n\n1. **Formatting Suggestion - Section Headers**\n   - Observation: Inconsistent blank lines before H2 headers\n   - Recommendation: Standardize to 2 blank lines before all H2 headers\n   - Impact: Improves visual consistency\n   - Location: Throughout document\n\n---\n\n## Summary\n\n- **Phase 1**: ‚úÖ PASSED (all structural checks passed)\n- **HIGH issues**: 3 (must fix before publication)\n- **MEDIUM issues**: 2 (should fix to improve clarity)\n- **LOW issues**: 1 (optional polish)\n\n**Next Steps**:\n1. Address 3 HIGH criticality issues (required)\n2. Consider addressing 2 MEDIUM issues (recommended)\n3. Optionally address LOW issue for polish\n\n**Re-review**: Request new review/audit after addressing HIGH issues\n```\n\n---\n\n## Integration Points\n\n### VALIDATIONS.md Integration\n\n**Relationship**: Phase 1 references existing validation rules from VALIDATIONS.md\n\n**Purpose**:\n- VALIDATIONS.md is the **rule repository** (defines what to validate)\n- REVIEW_AUDIT_WORKFLOW.md is the **orchestrator** (defines when and how to validate)\n\n**No Duplication**: This workflow document does not duplicate validation logic, only references it\n\n---\n\n### SKILL.md Integration\n\n**Relationship**: SKILL.md triggers this workflow when user requests review/audit\n\n**Integration Point**: When user says \"review\", \"audit\", or \"validate\", SKILL.md follows this workflow\n\n**Update Required**: SKILL.md should reference REVIEW_AUDIT_WORKFLOW.md and replace informal checklist (lines 1598-1610) with reference to this workflow\n\n---\n\n### ARCHITECTURE_DOCUMENTATION_GUIDE.md Integration\n\n**Relationship**: Phase 2 content improvement suggestions **explicitly reference** quality standards from ARCHITECTURE_DOCUMENTATION_GUIDE.md\n\n**Purpose**:\n- ARCHITECTURE_DOCUMENTATION_GUIDE.md defines **content quality standards** (what makes good content)\n- REVIEW_AUDIT_WORKFLOW.md provides **prioritization framework** (categorizes issues by criticality) and **explicit standard references**\n\n**How Phase 2 References Standards**:\n- Each HIGH/MEDIUM issue includes **\"Standard Violated\"** field with specific guide section and line numbers\n- Recommendations quote **\"Standard Requirement\"** directly from guide\n- Examples point to **\"Guide Example\"** showing proper implementation (with line numbers)\n- Compliance checklists help users verify fixes match template requirements\n\n**No Duplication**: This workflow does not duplicate content guidance, only references it with explicit citations to ensure all proposed changes are grounded in documented standards\n\n---\n\n### DESIGN_DRIVER_CALCULATIONS.md Integration\n\n**Relationship**: Leverages existing three-level threshold model (HIGH/MEDIUM/LOW) for consistency\n\n**Purpose**: Align criticality definitions with design driver impact levels for consistency across architecture-docs skill\n\n---\n\n## Maintenance Notes\n\n### When to Update This File\n\n**Update REVIEW_AUDIT_WORKFLOW.md when**:\n- Adding new criticality level (e.g., CRITICAL above HIGH)\n- Changing blocking behavior between phases\n- Adding new phase (e.g., Phase 3)\n- Changing workflow execution steps\n\n### When NOT to Update This File\n\n**Do NOT update this file when**:\n- Adding new validation rules ‚Üí Update **VALIDATIONS.md** instead\n- Adding new content quality standards ‚Üí Update **ARCHITECTURE_DOCUMENTATION_GUIDE.md** instead\n- Changing section names or structure ‚Üí Update **ARCHITECTURE_DOCUMENTATION_GUIDE.md** instead\n\n**Separation of Concerns**:\n- **REVIEW_AUDIT_WORKFLOW.md**: Workflow orchestration and prioritization framework\n- **VALIDATIONS.md**: Validation rule repository\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Content quality standards\n- **SKILL.md**: Trigger integration and skill operations\n\n---\n\n## Version History\n\n| Version | Date | Changes |\n|---------|------|---------|\n| 1.0 | 2025-01-29 | Initial two-phase workflow with HIGH/MEDIUM/LOW criticality framework |\n",
        "skills/architecture-docs/VALIDATIONS.md": "# Architecture Documentation Validations\n\n> Enforcement rules and validation checklists for ARCHITECTURE.md structure and content\n\n## Purpose\n\nThis document defines validation rules for:\n1. **Architecture Principles Enforcement** (Section 3)\n2. **Section Name Enforcement** (All 12 sections)\n3. **Document Structure Validation**\n\nThese rules ensure consistency and completeness across all ARCHITECTURE.md documents.\n\n## Related Documentation\n\n- **SKILL.md**: Operational workflows and when to apply validations\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Content templates and section guidance\n- **METRIC_CALCULATIONS.md**: Metric extraction and consistency algorithms\n- **DESIGN_DRIVER_CALCULATIONS.md**: Design Drivers calculation algorithms\n\n---\n\n## 1. Architecture Principles Enforcement (Section 3)\n\n### Required Principles (Strict Order)\n\nAll ARCHITECTURE.md documents MUST include these **9 core principles** in this **exact order**:\n\n1. **Separation of Concerns**\n2. **High Availability**\n3. **Scalability First**\n4. **Security by Design**\n5. **Observability**\n6. **Resilience**\n7. **Simplicity**\n8. **Cloud-Native**\n9. **Open Standards**\n\n### Optional Principle\n\n10. **Decouple Through Events** *(Apply selectively where temporal independence and scalability are prioritized)*\n\n**When to Include**:\n- ‚úÖ System uses async patterns for background processing (Kafka, RabbitMQ, SQS, etc.)\n- ‚úÖ Temporal decoupling provides clear scalability benefits\n- ‚úÖ System implements both synchronous and asynchronous patterns\n\n**When to Omit**:\n- ‚ùå System is purely synchronous request/response\n- ‚ùå No event streaming or pub/sub patterns used\n- ‚ùå Events are not a core architectural pattern\n\n### Required Structure for Each Principle\n\nEach principle MUST include these three subsections:\n\n```markdown\n### [Number]. [Principle Name]\n\n**Description:**\n[What this principle means - 1-2 sentences]\n\n**Implementation:**\n- [System-specific implementation details]\n- [Technologies, patterns, configurations used]\n- [Concrete examples from your architecture]\n\n**Trade-offs:**\n- [Costs, downsides, complexity introduced]\n- [Performance impacts, infrastructure costs, etc.]\n```\n\n**Template Example**:\n\n```markdown\n### 3.1 Separation of Concerns\n\n**Description:**\nSystem components are organized into distinct layers and services, each with a single, well-defined responsibility.\n\n**Implementation:**\n- 6-layer Meta Architecture (Data, Integration, Core Logic, Process, Interface, Presentation)\n- Microservices pattern: Job Scheduler Service, Job Executor Service, Notification Service\n- Database segregation: PostgreSQL (operational data), Redis (caching/queuing)\n- Clear boundaries between scheduling logic and execution logic\n\n**Trade-offs:**\n- Increased operational complexity (multiple services to deploy and monitor)\n- Network latency between distributed components\n- More complex debugging across service boundaries\n- Requires service mesh or API gateway for communication management\n```\n\n### Validation Rules\n\nWhen creating or updating Section 3, verify:\n\n‚úÖ **All 9 core principles are present**\n- Check that principles 1-9 are all documented\n- Verify no principles are missing\n\n‚úÖ **Principles appear in the exact order specified**\n- Principle 1: Separation of Concerns (must be first)\n- Principle 2: High Availability\n- ...\n- Principle 9: Open Standards (must be ninth)\n\n‚úÖ **Each principle has all three subsections**\n- Description subsection exists\n- Implementation subsection exists\n- Trade-offs subsection exists\n\n‚úÖ **Implementation section contains system-specific details**\n- NOT generic placeholders like \"We use best practices\"\n- Specific technologies mentioned (e.g., \"PostgreSQL\", \"Kubernetes\", \"Redis\")\n- Concrete examples from the actual architecture\n- Configuration details or patterns used\n\n‚úÖ **Trade-offs section honestly assesses costs/downsides**\n- Not just \"None\" or \"Minimal\"\n- Real costs: performance impact, complexity, infrastructure costs\n- Operational burdens: monitoring, debugging, deployment complexity\n- Development overhead: additional code, testing requirements\n\n‚úÖ **Decouple Through Events (#10) only included where async patterns provide clear benefits**\n- Check if system uses async patterns for temporal decoupling\n- Verify both sync and async patterns are documented\n- If included, must have same three-subsection structure\n\n‚úÖ **No additional custom principles beyond the standard 9-10**\n- If non-standard principles exist, map them to standard principles\n- Or remove and incorporate content into appropriate standard principle\n\n### Validation Checklist\n\nUse this checklist when reviewing Section 3:\n\n```\nSection 3: Architecture Principles Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nPrinciple Presence:\n‚òê 1. Separation of Concerns\n‚òê 2. High Availability\n‚òê 3. Scalability First\n‚òê 4. Security by Design\n‚òê 5. Observability\n‚òê 6. Resilience\n‚òê 7. Simplicity\n‚òê 8. Cloud-Native\n‚òê 9. Open Standards\n‚òê 10. Decouple Through Events (optional - apply selectively)\n\nStructure Validation:\n‚òê All principles in exact order (1-9, optional 10)\n‚òê Each principle has \"Description\" subsection\n‚òê Each principle has \"Implementation\" subsection\n‚òê Each principle has \"Trade-offs\" subsection\n\nContent Quality:\n‚òê Implementations are system-specific (not generic)\n‚òê Technologies and patterns explicitly named\n‚òê Trade-offs are realistic and honest\n‚òê No placeholder text (\"TBD\", \"TODO\", etc.)\n‚òê Decouple Through Events (#10) only where async provides benefits\n\nCommon Errors:\n‚òê No missing principles from core 9\n‚òê No reordered principles\n‚òê No single-sentence descriptions without structure\n‚òê No generic \"best practices\" placeholders\n‚òê No omitted Trade-offs sections\n```\n\n### Common Mistakes to Avoid\n\n‚ùå **Missing principles from the core 9**\n- Example: Skipping \"Simplicity\" or \"Open Standards\"\n- Fix: Add all 9 required principles\n\n‚ùå **Changing the order of principles**\n- Example: Putting \"Security by Design\" before \"High Availability\"\n- Fix: Reorder to match standard sequence (1-9)\n\n‚ùå **Using generic placeholder text in Implementation sections**\n- Example: \"We follow industry best practices for security\"\n- Fix: \"OAuth 2.0 + JWT for authentication, TLS 1.3 for encryption, AWS WAF for application firewall\"\n\n‚ùå **Omitting Trade-offs section**\n- Example: Only having Description and Implementation\n- Fix: Add Trade-offs with honest assessment of costs\n\n‚ùå **Including Decouple Through Events when system doesn't use async patterns**\n- Example: Purely synchronous REST API system lists async decoupling principle\n- Fix: Remove Decouple Through Events principle (#10)\n\n‚ùå **Adding custom principles not in the standard list**\n- Example: \"11. Innovation\" or \"12. Customer-Centric Design\"\n- Fix: Remove or incorporate into relevant standard principle\n\n‚ùå **Using single-sentence descriptions instead of structured format**\n- Example: Just \"### 3.1 Separation of Concerns - Components are separated\"\n- Fix: Use full three-subsection structure\n\n### Updating Existing Documents\n\nIf an existing ARCHITECTURE.md has different principles:\n\n**Step 1**: Identify missing principles\n- Compare against the required 9\n- List which principles are absent\n\n**Step 2**: Re-order existing principles\n- Match the standard order (1-9)\n- Update numbering (3.1, 3.2, etc.)\n\n**Step 3**: Add missing principles\n- Write system-specific Implementation details\n- Document real Trade-offs\n- Use appropriate Description\n\n**Step 4**: Restructure format\n- Ensure each has Description/Implementation/Trade-offs\n- Remove generic placeholders\n- Add specific technologies and patterns\n\n**Step 5**: Remove non-standard principles\n- Either map to standard principles\n- Or incorporate content into appropriate existing principle\n\n**Step 6**: Preserve existing content\n- Migrate good content to standard principles\n- Don't delete valuable information\n- Reorganize into standard structure\n\n---\n\n## 2. Section Name Enforcement\n\n### Standard 12-Section Structure\n\nAll ARCHITECTURE.md documents MUST include these **12 sections** with these **exact names** in this **exact order**:\n\n1. **Executive Summary**\n2. **System Overview**\n3. **Architecture Principles**\n4. **Architecture Layers**\n5. **Component Details**\n6. **Data Flow Patterns** *(Optional - may be omitted for simple systems)*\n7. **Integration Points**\n8. **Technology Stack**\n9. **Security Architecture**\n10. **Scalability & Performance**\n11. **Operational Considerations**\n12. **Architecture Decision Records (ADRs)**\n\n### Markdown Header Format\n\nEach section MUST use this exact format:\n\n```markdown\n## [NUMBER]. [SECTION NAME]\n```\n\n**Correct Examples**:\n- ‚úÖ `## 1. Executive Summary`\n- ‚úÖ `## 2. System Overview`\n- ‚úÖ `## 12. Architecture Decision Records (ADRs)`\n\n**Incorrect Examples**:\n- ‚ùå `## Executive Summary` (missing number)\n- ‚ùå `## 1 Executive Summary` (missing period after number)\n- ‚ùå `## 12. ADR References` (wrong section name)\n- ‚ùå `## 8. Tech Stack` (abbreviated name, should be \"Technology Stack\")\n- ‚ùå `## 10. Performance` (incomplete name, should be \"Scalability & Performance\")\n\n### Validation Rules\n\nWhen creating or updating ARCHITECTURE.md, verify:\n\n‚úÖ **All 12 section headers match exactly (case-sensitive)**\n- \"Executive Summary\" not \"Executive summary\"\n- \"Technology Stack\" not \"Tech Stack\"\n- \"Security Architecture\" not just \"Security\"\n- \"Architecture Decision Records (ADRs)\" not \"ADR References\"\n\n‚úÖ **Sections appear in the exact order specified (1-12)**\n- Section 1 is always Executive Summary\n- Section 12 is always Architecture Decision Records (ADRs)\n- No sections skipped (except Data Flow Patterns - see Optional Sections)\n\n‚úÖ **Section numbers are present with period**\n- Format: `## [NUMBER]. [NAME]`\n- Must have period after number: \"## 1. \" not \"## 1 \"\n\n‚úÖ **No custom section names unless documented as optional**\n- Stick to the 12 standard names\n- If adding subsections, those are fine (e.g., \"### 2.1 Problem Statement\")\n\n‚úÖ **Data Flow Patterns (Section 6) may be omitted for simple systems**\n- If omitted, renumber subsequent sections (7‚Üí6, 8‚Üí7, etc.)\n- Document Index must reflect 11-section structure\n\n### Verification Command\n\nUse this bash command to check section headers:\n\n```bash\ngrep -n \"^## [0-9]\" ARCHITECTURE.md\n```\n\n**Expected Output** (12-section structure):\n```\n25:## 1. Executive Summary\n54:## 2. System Overview\n147:## 3. Architecture Principles\n301:## 4. Architecture Layers\n456:## 5. Component Details\n676:## 6. Data Flow Patterns\n851:## 7. Integration Points\n998:## 8. Technology Stack\n1244:## 9. Security Architecture\n1417:## 10. Scalability & Performance\n1623:## 11. Operational Considerations\n1850:## 12. Architecture Decision Records (ADRs)\n```\n\n**Expected Output** (11-section structure, Data Flow omitted):\n```\n25:## 1. Executive Summary\n54:## 2. System Overview\n147:## 3. Architecture Principles\n301:## 4. Architecture Layers\n456:## 5. Component Details\n676:## 6. Integration Points         ‚Üê Was 7, renumbered\n851:## 7. Technology Stack          ‚Üê Was 8, renumbered\n998:## 8. Security Architecture     ‚Üê Was 9, renumbered\n1244:## 9. Scalability & Performance  ‚Üê Was 10, renumbered\n1417:## 10. Operational Considerations ‚Üê Was 11, renumbered\n1623:## 11. Architecture Decision Records (ADRs) ‚Üê Was 12, renumbered\n```\n\n### Common Mistakes to Avoid\n\n‚ùå **Using abbreviated or alternative section names**\n\n| Wrong ‚ùå | Correct ‚úÖ |\n|---------|-----------|\n| \"ADR References\" | \"Architecture Decision Records (ADRs)\" |\n| \"Decision References (ADRs)\" | \"Architecture Decision Records (ADRs)\" |\n| \"Tech Stack\" | \"Technology Stack\" |\n| \"Security\" | \"Security Architecture\" |\n| \"Performance\" | \"Scalability & Performance\" |\n| \"Operations\" | \"Operational Considerations\" |\n\n‚ùå **Reordering sections**\n- Example: Putting \"Technology Stack\" before \"Integration Points\"\n- Fix: Follow standard order (1-12)\n\n‚ùå **Omitting section numbers**\n- Example: `## Executive Summary`\n- Fix: `## 1. Executive Summary`\n\n‚ùå **Using wrong number format**\n- Example: `## 1 Executive Summary` (missing period)\n- Fix: `## 1. Executive Summary`\n\n‚ùå **Adding custom sections between standard sections**\n- Example: Adding \"## 13. Future Roadmap\" or \"## 6.5 Custom Section\"\n- Fix: Use subsections (###) for custom content within standard sections\n\n‚ùå **Wrong capitalization**\n- Example: `## 1. executive summary` (lowercase)\n- Fix: `## 1. Executive Summary` (title case)\n\n### Optional Sections\n\n**Data Flow Patterns (Section 6)**:\n\n**Include if:**\n- ‚úÖ System has complex data flows requiring visualization\n- ‚úÖ Multiple data transformation steps\n- ‚úÖ Event streaming or data pipelines\n- ‚úÖ Integration patterns need detailed explanation\n\n**Omit for:**\n- ‚ùå Simple request/response patterns\n- ‚ùå Straightforward CRUD operations\n- ‚ùå No complex data transformations\n\n**If omitted:**\n- Renumber subsequent sections:\n  - Section 7 (Integration Points) ‚Üí Section 6\n  - Section 8 (Technology Stack) ‚Üí Section 7\n  - Section 9 (Security Architecture) ‚Üí Section 8\n  - Section 10 (Scalability & Performance) ‚Üí Section 9\n  - Section 11 (Operational Considerations) ‚Üí Section 10\n  - Section 12 (Architecture Decision Records) ‚Üí Section 11\n- **Update Document Index** to reflect 11-section structure\n- **Note**: All section cross-references must be updated\n\n### Section Renumbering Workflow\n\n**When Data Flow Patterns is omitted:**\n\n**Step 1**: Remove or comment out Section 6\n```markdown\n<!-- ## 6. Data Flow Patterns -->\n<!-- (Omitted for this architecture - simple request/response patterns) -->\n```\n\n**Step 2**: Renumber subsequent sections\n- Change `## 7. Integration Points` to `## 6. Integration Points`\n- Change `## 8. Technology Stack` to `## 7. Technology Stack`\n- Continue through Section 12 ‚Üí Section 11\n\n**Step 3**: Update Document Index\n```markdown\n## Document Index\n\n**Quick Navigation:**\n- [Section 1: Executive Summary](#1-executive-summary) ‚Üí Lines 25-53\n- [Section 2: System Overview](#2-system-overview) ‚Üí Lines 54-146\n- [Section 3: Architecture Principles](#3-architecture-principles) ‚Üí Lines 147-300\n- [Section 4: Architecture Layers](#4-architecture-layers) ‚Üí Lines 301-455\n- [Section 5: Component Details](#5-component-details) ‚Üí Lines 456-675\n- [Section 6: Integration Points](#6-integration-points) ‚Üí Lines 676-850\n  <!-- Note: Data Flow Patterns omitted, sections renumbered -->\n- [Section 7: Technology Stack](#7-technology-stack) ‚Üí Lines 851-997\n- [Section 8: Security Architecture](#8-security-architecture) ‚Üí Lines 998-1243\n- [Section 9: Scalability & Performance](#9-scalability--performance) ‚Üí Lines 1244-1416\n- [Section 10: Operational Considerations](#10-operational-considerations) ‚Üí Lines 1417-1622\n- [Section 11: Architecture Decision Records (ADRs)](#11-architecture-decision-records-adrs) ‚Üí Lines 1623-end\n\n**Index Last Updated:** 2025-01-29\n```\n\n**Step 4**: Update all internal cross-references\n- Search for references to sections 7-12\n- Update to new numbers (6-11)\n\n---\n\n## 3. Document Structure Validation\n\n### Required Elements Per Section\n\n#### Section 1: Executive Summary\n- ‚úÖ **System Name**: Clear identification\n- ‚úÖ **Purpose**: What the system does (1-2 sentences)\n- ‚úÖ **Key Metrics**: Performance targets (Read TPS, Processing TPS, Write TPS - with Average/Peak values and Measurement Period; latency targets; SLA targets)\n- ‚úÖ **Business Value**: Quantifiable benefits\n- ‚úÖ **Technical Overview**: High-level architecture summary\n\n#### Section 2: System Overview\n- ‚úÖ **2.1 Problem Statement**: What problem does this solve?\n- ‚úÖ **2.2 Solution Overview**: How does this solution address it?\n- ‚úÖ **2.2.1 Design Drivers** (Optional): Impact metrics\n- ‚úÖ **2.3 Primary Use Cases**: User scenarios with success metrics\n\n#### Section 3: Architecture Principles\n- ‚úÖ All 9 required principles (see Section 1 of this document)\n- ‚úÖ Each with Description, Implementation, Trade-offs\n\n#### Section 4: Meta Architecture Layers\n- ‚úÖ 6-layer model (Data, Integration, Core Logic, Process, Interface, Presentation)\n- ‚úÖ Each layer described\n- ‚úÖ Component mapping to layers\n\n#### Section 5: Component Details\n- ‚úÖ One subsection per component (###  5.1, 5.2, etc.)\n- ‚úÖ Each component documented: Purpose, Responsibilities, Technologies, Interactions\n\n#### Section 6: Data Flow Patterns (Optional)\n- If included: Data flow diagrams or descriptions\n- Transformation steps documented\n\n#### Section 7: Integration Points\n- ‚úÖ External systems listed\n- ‚úÖ Integration patterns described\n- ‚úÖ SLA/availability requirements\n\n#### Section 8: Technology Stack\n- ‚úÖ Languages table\n- ‚úÖ Frameworks table\n- ‚úÖ Databases table\n- ‚úÖ Infrastructure table\n- ‚úÖ Rationale for key technology choices\n\n#### Section 9: Security Architecture\n- ‚úÖ Authentication & Authorization\n- ‚úÖ Data encryption (in-transit, at-rest)\n- ‚úÖ Security controls\n- ‚úÖ Threat model (optional but recommended)\n\n#### Section 10: Scalability & Performance\n- ‚úÖ Performance targets (from Section 1 Key Metrics)\n- ‚úÖ Scalability approach (horizontal/vertical)\n- ‚úÖ Bottlenecks and mitigation strategies\n- ‚úÖ Load testing results (if available)\n\n#### Section 11: Operational Considerations\n- ‚úÖ Deployment strategy\n- ‚úÖ Monitoring & observability\n- ‚úÖ Backup & disaster recovery\n- ‚úÖ Maintenance procedures\n\n#### Section 12: Architecture Decision Records (ADRs)\n- ‚úÖ List of ADRs with links\n- ‚úÖ Or inline ADRs if not using separate files\n- ‚úÖ Key decisions documented\n\n### Format Validation Rules\n\n**Markdown Headers**:\n- ‚úÖ Sections use ## (H2)\n- ‚úÖ Subsections use ### (H3)\n- ‚úÖ Sub-subsections use #### (H4)\n- ‚úÖ Consistent header hierarchy (no skipping levels)\n\n**Tables**:\n- ‚úÖ All tables have header rows\n- ‚úÖ Separator row uses | --- | format\n- ‚úÖ Columns aligned (for readability)\n\n**Lists**:\n- ‚úÖ Bullet points use - or * consistently\n- ‚úÖ Numbered lists use 1. 2. 3. format\n\n**Code Blocks**:\n- ‚úÖ Use triple backticks ```\n- ‚úÖ Specify language: ```bash, ```python, ```yaml\n\n**Links**:\n- ‚úÖ Internal links use anchors: [Section 2](#2-system-overview)\n- ‚úÖ External links are absolute: https://example.com\n- ‚úÖ ADR links work (files exist or references are valid)\n\n### Completeness Checks\n\n**Use this checklist to verify completeness**:\n\n```\nDocument Completeness Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nCore Sections:\n‚òê All 12 sections present (or 11 if Data Flow omitted)\n‚òê Section names match exactly\n‚òê Sections in correct order\n‚òê Section numbering correct (## 1. format)\n\nContent Quality:\n‚òê No \"TODO\" or \"TBD\" placeholders\n‚òê No empty sections\n‚òê All metrics sourced from Section 1\n‚òê All components documented in Section 5\n‚òê All technologies listed in Section 8\n‚òê Security controls documented in Section 9\n\nStructure:\n‚òê Document Index exists and is accurate\n‚òê \"Index Last Updated\" date is current\n‚òê Subsection numbering consistent (2.1, 2.2, 2.3)\n‚òê No duplicate section numbers\n\nCross-References:\n‚òê All internal links work\n‚òê ADR references valid\n‚òê Metric references consistent across sections\n‚òê Component references match Section 5\n\nFormat:\n‚òê Markdown headers properly formatted\n‚òê Tables have headers and separators\n‚òê Code blocks specify language\n‚òê Lists formatted consistently\n```\n\n---\n\n## 4. Architecture Type-Aware Validation\n\n### Overview\n\nStarting with the Architecture Type Selection feature, ARCHITECTURE.md documents are categorized into one of five architecture types:\n- **Microservices Architecture** (cloud-native distributed) - **Recommended**\n- **META Architecture** (6-layer enterprise)\n- **3-Tier Architecture** (classic web application)\n- **N-Layer Architecture** (DDD, Clean Architecture, Hexagonal)\n- **BIAN Architecture** (5-layer BIAN-compliant for banking systems)\n\nEach architecture type has **type-specific validation rules** for Section 4 (Meta Architecture) and Section 5 (Component Details).\n\n### Detecting Architecture Type\n\n**Method 1: Metadata Comment Detection**\n\nSearch for the architecture type metadata comment in Section 4:\n\n```bash\ngrep -n \"<!-- ARCHITECTURE_TYPE:\" ARCHITECTURE.md\n```\n\n**Valid metadata values:**\n- `<!-- ARCHITECTURE_TYPE: MICROSERVICES -->`\n- `<!-- ARCHITECTURE_TYPE: META -->`\n- `<!-- ARCHITECTURE_TYPE: 3-TIER -->`\n- `<!-- ARCHITECTURE_TYPE: N-LAYER -->`\n- `<!-- ARCHITECTURE_TYPE: BIAN -->`\n\n**Method 2: Section 4 Header Inference**\n\nIf no metadata comment exists, infer type from Section 4 headers:\n\n```bash\ngrep -n \"^### [0-9]\" ARCHITECTURE.md | grep -A5 \"## 4\\.\"\n```\n\n**Inference Rules (in order of specificity):**\n\n| Pattern Found in Section 4 | Inferred Type |\n|---------------------------|---------------|\n| \"Layer 2: BIAN Business Scenarios\" OR \"Layer 4: BIAN Service Domains\" | **BIAN** (check first - most specific) |\n| \"Layer 1: Channels\" AND \"Layer 5: Domain\" AND \"Layer 6: Core\" | **META** |\n| \"Tier 1: Presentation\" OR \"Tier 3: Data\" | **3-Tier** |\n| \"API Gateway\" AND \"Service Mesh\" | **Microservices** |\n| \"Clean Architecture\" OR \"Hexagonal\" OR \"Ports & Adapters\" | **N-Layer** |\n\n### META Architecture Validation\n\n**Applies when**: `<!-- ARCHITECTURE_TYPE: META -->` is present OR Section 4 contains META layer headers.\n\n#### Section 4: Meta Architecture Layers\n\n‚úÖ **All 6 layers must be documented:**\n- Layer 1: Channels\n- Layer 2: User Experience (UX)\n- Layer 3: Business Scenarios\n- Layer 4: Integration\n- Layer 5: Domain\n- Layer 6: Core\n\n‚úÖ **Layers appear in correct order (1-6)**\n\n‚úÖ **Section 4 should be named \"Architecture Layers\"**\n- **Correct**: `## 4. Architecture Layers` or `## 4. Meta Architecture` (legacy)\n- **Incorrect**: `## 4. Meta Architecture` (missing \"Layers\" suffix)\n\n**Verification Command:**\n```bash\ngrep -n \"^### [0-9]\\.[1-6]\" ARCHITECTURE.md | grep -A2 \"## 4\\.\"\n```\n\n**Expected Output** (excerpt):\n```\n### 4.1 Layer 1: Channels\n### 4.2 Layer 2: User Experience (UX)\n### 4.3 Layer 3: Business Scenarios\n### 4.4 Layer 4: Integration\n### 4.5 Layer 5: Domain\n### 4.6 Layer 6: Core\n```\n\n#### Section 5: Component Details\n\n‚úÖ **Components grouped by layer:**\n- Each component MUST specify which layer it belongs to\n- Use headers like: `## Layer 1: Channels - Components` or `### [Component Name] (Layer 5: Domain)`\n\n‚úÖ **Layer 5 (Domain) components MUST include BIAN V12.0 alignment (default version):**\n- **BIAN Capability Name**: Official service domain name validated in [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- **BIAN ID**: Internal document tracking ID (e.g., SD-001, SD-002) - for counting service domains only\n- **BIAN Alignment** subsection with official BIAN reference URLs\n- Service Domain Model version must be documented as \"BIAN V12.0\" (default and recommended version)\n- Must link to official BIAN V12.0 service domain definition\n- **BIAN Alignment Details**:\n  - Service Domain Model version (BIAN V12.0)\n  - Behavior Qualifiers\n  - Functional Patterns\n  - Control Records description\n\n**Example Layer 5 Component Structure:**\n```markdown\n### Customer Contact Management (Layer 5: Domain)\n\n**Type**: Microservice | Service Domain\n**BIAN ID**: SD-047\n\n**BIAN Alignment**:\n- Service Domain Model: [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) (default version)\n- BIAN Capability Name: [Payment Execution] - validated in [official landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- BIAN ID: SD-047 - internal tracking ID only\n- Official Definition: [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- Control Record: Customer Contact Record\n- Service Operations: Initiate, Update, Retrieve\n- Behavior Qualifiers: CustomerContact, ContactMechanism\n```\n\n**Validation Commands for BIAN Alignment:**\n```bash\n# Validate BIAN V12.0 alignment in Layer 5\ngrep -A20 \"Layer 5: Domain\" ARCHITECTURE.md | grep \"BIAN V12.0\"\n\n# Verify BIAN landscape URL is referenced\ngrep -o \"https://bian.org/servicelandscape-12-0-0\" ARCHITECTURE.md\n```\n\n#### Common Errors - META\n\n‚ùå **Missing layers from the required 6**\n- Fix: Add all 6 layers in Section 4\n\n‚ùå **Layers out of order**\n- Fix: Reorder to 1‚Üí2‚Üí3‚Üí4‚Üí5‚Üí6\n\n‚ùå **Layer 5 components missing BIAN alignment**\n- Fix: Add BIAN ID and alignment details\n\n‚ùå **Components not mapped to specific layers**\n- Fix: Indicate layer for each component in Section 5\n\n### 3-Tier Architecture Validation\n\n**Applies when**: `<!-- ARCHITECTURE_TYPE: 3-TIER -->` is present OR Section 4 contains tier headers.\n\n#### Section 4: Meta Architecture\n\n‚úÖ **All 3 tiers must be documented:**\n- Tier 1: Presentation\n- Tier 2: Application/Business Logic\n- Tier 3: Data\n\n‚úÖ **Tiers appear in correct order (1-3)**\n\n‚úÖ **Section 4 header should reflect 3-Tier pattern:**\n- **Correct**: `## 4. Architecture Layers - 3-Tier Classic Web Application` or `## 4. Architecture Layers`\n- **Incorrect**: `## 4. Meta Architecture` (missing \"Layers\" suffix)\n\n**Verification Command:**\n```bash\ngrep -n \"^### [0-9]\\.[1-3]\" ARCHITECTURE.md | grep -A1 \"## 4\\.\"\n```\n\n**Expected Output** (excerpt):\n```\n### 4.1 Tier 1: Presentation\n### 4.2 Tier 2: Application/Business Logic\n### 4.3 Tier 3: Data\n```\n\n#### Section 5: Component Details\n\n‚úÖ **Components grouped by tier:**\n- Use headers: `## Tier 1: Presentation Layer - Components`\n- Each component indicates tier assignment\n\n‚úÖ **Tier separation enforced:**\n- **No direct database access from Tier 1** (Presentation)\n- Presentation tier components must NOT have direct database connections\n- All data access goes through Tier 2 (Application) ‚Üí Tier 3 (Data)\n\n‚úÖ **Tier 2 components are stateless:**\n- Application/Business Logic components should be stateless for horizontal scalability\n- Session state managed externally (e.g., Redis, database)\n\n**Validation Check for Tier Separation:**\n\nSearch for forbidden patterns (Presentation tier with database):\n```bash\ngrep -B5 -A10 \"Tier 1\" ARCHITECTURE.md | grep -i \"database\\|postgres\\|mysql\\|mongodb\"\n```\n\nIf matches found ‚Üí **VIOLATION**: Presentation tier should NOT access database directly.\n\n#### Common Errors - 3-Tier\n\n‚ùå **Missing tiers from the required 3**\n- Fix: Document all 3 tiers\n\n‚ùå **Tier 1 components accessing database directly**\n- Fix: Route data access through Tier 2 ‚Üí Tier 3\n\n‚ùå **Tier 2 components with stateful session management**\n- Fix: Externalize session state (Redis, distributed cache)\n\n‚ùå **Using \"Layer\" terminology instead of \"Tier\"**\n- Fix: Use \"Tier 1\", \"Tier 2\", \"Tier 3\" for consistency\n\n### Microservices Architecture Validation\n\n**Applies when**: `<!-- ARCHITECTURE_TYPE: MICROSERVICES -->` is present OR Section 4 contains microservices infrastructure components.\n\n#### Section 4: Meta Architecture\n\n‚úÖ **Infrastructure components documented:**\n- **API Gateway**: Single entry point for clients\n- **Service Mesh**: Service-to-service communication infrastructure (or justification if omitted)\n- **Event Bus**: Asynchronous communication backbone (Kafka, RabbitMQ, etc.)\n- **Service Discovery**: How services find each other (or justification if not used)\n\n‚úÖ **Section 4 header reflects microservices pattern:**\n- **Correct**: `## 4. Meta Architecture - Microservices Architecture` or `## 4. Meta Architecture`\n\n**Verification Command:**\n```bash\ngrep -i \"API Gateway\\|Service Mesh\\|Event Bus\\|Service Discovery\" ARCHITECTURE.md | grep -A5 \"## 4\\.\"\n```\n\n‚úÖ **If API Gateway or Service Mesh omitted:**\n- Must include justification in Section 4 or ADR\n- Example: \"Service Mesh omitted - using direct service-to-service mTLS with client-side load balancing\"\n\n#### Section 5: Component Details\n\n‚úÖ **Database-per-service pattern followed:**\n- Each microservice MUST have its own database (no shared databases)\n- Each service documented with dedicated data store\n- If shared database exists ‚Üí **VIOLATION** (or must justify in ADR)\n\n‚úÖ **Each microservice includes:**\n- **Bounded Context**: Domain/business capability it owns\n- **API Specification**: REST/gRPC/GraphQL endpoints\n- **Events Published**: Event names, triggers, payloads, consumers\n- **Events Consumed**: Events from other services, actions taken\n- **Circuit Breaker Configuration**: Failure threshold, timeout, fallback strategy\n\n‚úÖ **Event bus topics documented:**\n- Event names follow naming convention (e.g., `service.resource.action`)\n- Event schemas versioned (v1, v2, etc.)\n- Dead Letter Queue (DLQ) handling documented\n\n**Validation Check for Database-per-Service:**\n\n```bash\n# Count services\ngrep -c \"### .* Service$\" ARCHITECTURE.md\n\n# Count databases (should match or exceed service count)\ngrep -c \"Database\\|PostgreSQL\\|MongoDB\\|DynamoDB\" ARCHITECTURE.md\n```\n\nIf services > databases ‚Üí **WARNING**: Verify database-per-service pattern.\n\n**Validation Check for Circuit Breakers:**\n\n```bash\ngrep -i \"circuit breaker\\|resilience4j\\|hystrix\" ARCHITECTURE.md | wc -l\n```\n\nShould have matches for each synchronous inter-service dependency.\n\n#### Common Errors - Microservices\n\n‚ùå **Shared database across multiple services**\n- Fix: Implement database-per-service or document exception in ADR\n\n‚ùå **API Gateway or Service Mesh not documented (and no justification)**\n- Fix: Add infrastructure component or explain omission\n\n‚ùå **Event bus missing for event-driven services**\n- Fix: Document event bus (Kafka, RabbitMQ, etc.)\n\n‚ùå **No circuit breakers for synchronous calls**\n- Fix: Configure circuit breakers for all sync dependencies\n\n‚ùå **Events not versioned**\n- Fix: Add schema versioning (v1, v2) to event definitions\n\n### N-Layer Architecture Validation\n\n**Applies when**: `<!-- ARCHITECTURE_TYPE: N-LAYER -->` is present OR Section 4 contains N-Layer pattern headers.\n\n#### Section 4: Meta Architecture\n\n‚úÖ **Pattern specification required:**\n- Must specify which N-Layer pattern is used:\n  - **4-Layer Classic DDD**\n  - **5-Layer Extended**\n  - **Clean Architecture**\n  - **Hexagonal Architecture (Ports & Adapters)**\n  - **Custom N-Layer** (with layer definitions)\n\n‚úÖ **Dependency direction documented:**\n- Clear dependency rules between layers\n- Example: \"Presentation ‚Üí Application ‚Üí Domain; Infrastructure ‚Üí Domain (implements interfaces)\"\n\n‚úÖ **Layer boundaries defined:**\n- Each layer has defined components\n- Communication patterns between layers documented\n- Interfaces at layer boundaries documented\n\n**Verification Command:**\n```bash\ngrep -i \"4-Layer\\|5-Layer\\|Clean Architecture\\|Hexagonal\\|Ports & Adapters\" ARCHITECTURE.md | head -5\n```\n\nShould find pattern specification in Section 4.\n\n#### Section 5: Component Details\n\n‚úÖ **Components organized by layer:**\n- Each component assigned to a specific layer\n- Layer headers used: `## Layer 1: Presentation`, `## Core: Entities`, etc.\n\n‚úÖ **Core/Domain layer is framework-free (if applicable):**\n- For DDD, Clean Architecture, Hexagonal patterns:\n  - Domain/Core layer should have NO framework dependencies\n  - Pure business logic only\n  - No references to ORM, web framework, external libraries\n\n‚úÖ **Infrastructure layer implements domain interfaces (if applicable):**\n- Repository implementations in Infrastructure layer\n- External service adapters in Infrastructure layer\n- Infrastructure depends on Domain (not vice versa)\n\n**Validation Check for Framework-Free Domain:**\n\nFor DDD/Clean/Hexagonal patterns:\n```bash\n# Check Domain/Core layer for framework imports\ngrep -A30 \"Domain\\|Core\" ARCHITECTURE.md | grep -i \"spring\\|express\\|django\\|sequelize\\|typeorm\"\n```\n\nIf matches found ‚Üí **WARNING**: Domain layer should be framework-free.\n\n#### Common Errors - N-Layer\n\n‚ùå **Pattern not specified**\n- Fix: Declare which N-Layer pattern (DDD, Clean, Hexagonal, etc.)\n\n‚ùå **Dependency direction not documented**\n- Fix: Add dependency rules (e.g., \"Dependencies point INWARD\")\n\n‚ùå **Domain layer with framework dependencies**\n- Fix: Remove framework dependencies from domain/core layer\n\n‚ùå **Infrastructure layer depends on external frameworks (not domain interfaces)**\n- Fix: Infrastructure should implement domain-defined interfaces\n\n‚ùå **Circular dependencies between layers**\n- Fix: Enforce unidirectional dependencies with dependency inversion\n\n### BIAN Architecture Validation\n\n**Applies when**: `<!-- ARCHITECTURE_TYPE: BIAN -->` is present OR Section 4 contains BIAN layer headers.\n\n#### Section 4: Meta Architecture - BIAN Layers\n\n‚úÖ **All 5 BIAN layers must be documented in order:**\n- Layer 1: Channels\n- Layer 2: BIAN Business Scenarios\n- Layer 3: BIAN Business Capabilities\n- Layer 4: BIAN Service Domains\n- Layer 5: Core Systems\n\n‚úÖ **Layer 2: BIAN Business Scenarios Validation:**\n- Must map business scenarios to BIAN Business Areas (5 areas):\n  - Sales and Service\n  - Reference Data\n  - Operations and Execution\n  - Risk and Compliance\n  - Business Support\n- Business scenarios organized by BIAN Business Area\n- BIAN Business Area mapping table present\n- BIAN V12.0 reference URL included\n\n**Verification Command:**\n```bash\ngrep -i \"Layer 2: BIAN Business Scenarios\" ARCHITECTURE.md\ngrep -i \"BIAN Business Area\" ARCHITECTURE.md | head -10\n```\n\n‚úÖ **Layer 3: BIAN Business Capabilities Validation:**\n- Must map business capabilities to BIAN Business Domains (30+ domains)\n- Examples: Customer Management, Payments, Loans and Deposits, Risk Management, etc.\n- Business capability components mapped to BIAN Business Domains\n- BIAN Business Domain mapping table present\n- Parent Business Area documented for each Business Domain\n- BIAN V12.0 reference URL included\n\n**Verification Command:**\n```bash\ngrep -i \"Layer 3: BIAN Business Capabilities\" ARCHITECTURE.md\ngrep -i \"BIAN Business Domain\" ARCHITECTURE.md | head -10\n```\n\n‚úÖ **Layer 4: BIAN Service Domains Validation (CRITICAL):**\n- Must implement BIAN Service Domains from BIAN V12.0 (326+ service domains)\n- All service domain names validated against [official BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- Service domain catalog table with BIAN IDs (SD-XXX format)\n- BIAN V12.0 reference URL: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n**Verification Command:**\n```bash\ngrep -i \"Layer 4: BIAN Service Domains\" ARCHITECTURE.md\ngrep -i \"BIAN Service Domain\\|SD-[0-9]\" ARCHITECTURE.md | wc -l\ngrep -i \"bian.org/servicelandscape-12-0-0\" ARCHITECTURE.md\n```\n\nExpected: Multiple BIAN service domains documented with BIAN IDs (SD-001, SD-002, etc.)\n\n‚úÖ **BIAN Hierarchy Traceability:**\n- Clear mapping: Service Domain ‚Üí Business Domain ‚Üí Business Area\n- Documented in Layer 4 service domain catalog\n- Cross-references between layers 2, 3, and 4\n\n**Verification Command:**\n```bash\n# Check for BIAN hierarchy documentation\ngrep -A5 \"BIAN Business Area\\|BIAN Business Domain\" ARCHITECTURE.md | grep -i \"Service Domain\"\n```\n\n‚úÖ **Mermaid Diagram Requirement:**\n- Architecture diagram showing all 5 BIAN layers\n- BIAN hierarchy visualization (Business Areas ‚Üí Business Domains ‚Üí Service Domains)\n- Communication patterns between layers\n\n**Verification Command:**\n```bash\ngrep -A20 \"```mermaid\" ARCHITECTURE.md | grep -i \"BIAN\\|Layer [1-5]\"\n```\n\n#### Section 5: Component Details - BIAN Compliance\n\n‚úÖ **Components grouped by BIAN layers (1-5):**\n- Layer 1: Channels components\n- Layer 2: BIAN Business Scenarios components\n- Layer 3: BIAN Business Capabilities components\n- Layer 4: BIAN Service Domains components (CRITICAL - see below)\n- Layer 5: Core Systems components\n\n‚úÖ **Layer 4 Components - Complete BIAN Metadata (MANDATORY):**\n\nEvery Layer 4 (BIAN Service Domain) component MUST include:\n\n1. **Official BIAN Name:**\n   - Exact name from BIAN V12.0 Service Landscape\n   - Examples: \"Payment Order\", \"Current Account\", \"Party Authentication\"\n\n2. **BIAN ID:**\n   - Internal tracking ID in SD-XXX format\n   - Examples: SD-001, SD-002, SD-003\n\n3. **BIAN Version:**\n   - Must be V12.0 (mandatory)\n\n4. **BIAN Business Domain:**\n   - Parent business domain from Layer 3\n   - Examples: \"Payments\", \"Loans and Deposits\", \"Customer Management\"\n\n5. **BIAN Business Area:**\n   - Parent business area from Layer 2\n   - Examples: \"Operations and Execution\", \"Sales and Service\"\n\n6. **BIAN Service Landscape URL:**\n   - Direct link to service domain in BIAN V12.0\n   - Must be: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n7. **Control Record:**\n   - Control Record Type (e.g., \"PaymentOrderProcedure\")\n   - Control Record Structure (fields, types, descriptions)\n   - Lifecycle States (e.g., Initiated, Completed, Failed, Cancelled)\n   - State Transitions (allowed state changes)\n\n8. **Service Operations (BIAN V12.0 Standard):**\n   - **Initiate**: Create new control record (MANDATORY)\n   - **Update**: Modify control record (MANDATORY)\n   - **Retrieve**: Query control record (MANDATORY)\n   - **Control**: Manage lifecycle (MANDATORY)\n   - **Exchange**: If applicable per BIAN spec (OPTIONAL)\n   - **Execute**: If applicable per BIAN spec (OPTIONAL)\n   - **Request**: If applicable per BIAN spec (OPTIONAL)\n\n9. **Behavior Qualifiers:**\n   - List of behavior qualifiers from BIAN spec\n   - Examples: \"compliance\", \"reporting\", \"booking\", \"registration\", \"valuation\"\n\n10. **Functional Patterns:**\n    - Pattern Type from BIAN spec\n    - Examples: \"Managed Object\", \"Tracked Object\", \"Administered Object\", \"Governed Object\"\n    - Pattern Description\n\n11. **BIAN Compliance Level:**\n    - Compliance Level: Full BIAN V12.0 Compliance (required for BIAN architecture)\n    - Validation Date: When compliance was verified\n    - Deviations: None for full compliance, or document customizations\n\n12. **BIAN Traceability:**\n    - Service Domain ‚Üí Business Domain ‚Üí Business Area mapping documented\n\n**Verification Command for Layer 4 Components:**\n```bash\n# Check for BIAN metadata in Layer 4 components\ngrep -A50 \"Layer 4.*BIAN Service Domain\" ARCHITECTURE.md | \\\n  grep -E \"Official BIAN Name|BIAN ID|BIAN Version|Control Record|Service Operations|Behavior Qualifiers|Functional Pattern\"\n```\n\nExpected: Every Layer 4 component includes all 12 required BIAN metadata fields.\n\n**Verification Command for BIAN V12.0 URLs:**\n```bash\n# Count BIAN V12.0 URL references\ngrep -c \"bian.org/servicelandscape-12-0-0\" ARCHITECTURE.md\n```\n\nExpected: Multiple references (at least one per service domain + general references)\n\n‚úÖ **Layer 2 Components - BIAN Business Area Mapping:**\n- Each component mapped to one of 5 BIAN Business Areas\n- BIAN Business Area documented in component metadata\n- Orchestration logic for business scenarios documented\n\n‚úÖ **Layer 3 Components - BIAN Business Domain Mapping:**\n- Each component mapped to a BIAN Business Domain (30+ domains)\n- BIAN Business Domain documented in component metadata\n- Parent Business Area documented\n- Service Domains coordinated by this capability listed\n\n‚úÖ **Layer 5 Components - BIAN Integration Strategy:**\n- Core systems integration with BIAN service domains documented\n- Adapter pattern for BIAN integration described\n- Modernization strategy aligned with BIAN architecture\n\n#### Common Errors - BIAN Architecture\n\n‚ùå **Missing layers (not all 5 layers present)**\n- Fix: Document all 5 BIAN layers in Section 4 in correct order\n\n‚ùå **Layer 2 not mapped to BIAN Business Areas**\n- Fix: Add BIAN Business Area mapping table, map scenarios to 5 BIAN Business Areas\n\n‚ùå **Layer 3 not mapped to BIAN Business Domains**\n- Fix: Add BIAN Business Domain mapping table, identify which domains are implemented\n\n‚ùå **Layer 4 service domain names don't match BIAN V12.0**\n- Fix: Validate all service domain names against [official BIAN Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- Examples of correct names: \"Payment Order\", \"Payment Execution\", \"Current Account\"\n\n‚ùå **Layer 4 components missing BIAN metadata**\n- Fix: Add all 12 required BIAN metadata fields for every Layer 4 component\n- Required: Official BIAN Name, BIAN ID, Version, Business Domain, Business Area, URL, Control Record, Service Operations, Behavior Qualifiers, Functional Patterns, Compliance Level, Traceability\n\n‚ùå **Control records not documented per BIAN spec**\n- Fix: Document control record structure, lifecycle states, and state transitions per BIAN V12.0\n\n‚ùå **Missing mandatory BIAN service operations**\n- Fix: Implement all 4 mandatory operations: Initiate, Update, Retrieve, Control\n- Optional operations: Exchange, Execute, Request (add if applicable per BIAN spec)\n\n‚ùå **Behavior qualifiers not documented**\n- Fix: List all behavior qualifiers from BIAN spec for each service domain\n- Reference: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n‚ùå **Functional patterns not documented**\n- Fix: Identify and document BIAN functional pattern (Managed Object, Tracked Object, etc.)\n\n‚ùå **BIAN V12.0 URLs missing or incorrect**\n- Fix: Use correct URL: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n- Add URL references in Layer 2, Layer 3, and Layer 4 sections\n\n‚ùå **BIAN hierarchy not traceable**\n- Fix: Document clear mapping: Service Domain ‚Üí Business Domain ‚Üí Business Area\n- Add cross-references between layers 2, 3, and 4\n\n‚ùå **Compliance level not documented**\n- Fix: Document \"Full BIAN V12.0 Compliance\" for each Layer 4 service domain\n- Include validation date and any deviations\n\n‚ùå **BIAN IDs not used consistently**\n- Fix: Assign BIAN IDs (SD-001, SD-002, etc.) for internal tracking\n- Use consistently throughout document\n\n#### BIAN Architecture Checklist\n\n**Section 4: Meta Architecture**\n- [ ] All 5 layers documented in order (Channels, BIAN Business Scenarios, BIAN Business Capabilities, BIAN Service Domains, Core Systems)\n- [ ] Layer 2 mapped to 5 BIAN Business Areas\n- [ ] Layer 2 includes BIAN Business Area mapping table\n- [ ] Layer 3 mapped to BIAN Business Domains (30+ domains)\n- [ ] Layer 3 includes BIAN Business Domain mapping table\n- [ ] Layer 4 implements BIAN Service Domains from BIAN V12.0\n- [ ] Layer 4 includes service domain catalog with BIAN IDs\n- [ ] All layer names use exact BIAN terminology\n- [ ] BIAN V12.0 reference URL included throughout\n- [ ] BIAN hierarchy traceability documented\n- [ ] Mermaid diagram shows all 5 BIAN layers\n\n**Section 5: Component Details**\n- [ ] Components grouped by 5 BIAN layers\n- [ ] Layer 4 components include complete BIAN metadata (all 12 fields)\n- [ ] Official BIAN Names validated against BIAN V12.0 Service Landscape\n- [ ] BIAN IDs (SD-XXX) assigned to all Layer 4 components\n- [ ] BIAN Version V12.0 documented for all Layer 4 components\n- [ ] BIAN Business Domain documented for all Layer 4 components\n- [ ] BIAN Business Area documented for all Layer 4 components\n- [ ] BIAN Service Landscape URL included for all Layer 4 components\n- [ ] Control records documented per BIAN specification\n- [ ] All 4 mandatory service operations implemented (Initiate, Update, Retrieve, Control)\n- [ ] Behavior qualifiers documented per BIAN spec\n- [ ] Functional patterns documented per BIAN spec\n- [ ] Full BIAN V12.0 compliance level documented\n- [ ] BIAN hierarchy traceability documented (Service Domain ‚Üí Business Domain ‚Üí Business Area)\n- [ ] Layer 2 components mapped to BIAN Business Areas\n- [ ] Layer 3 components mapped to BIAN Business Domains\n- [ ] Layer 5 includes BIAN integration and modernization strategy\n\n### Type-Aware Validation Workflow\n\n**Step 1: Detect Architecture Type**\n\n```bash\n# Check for metadata comment\ngrep \"<!-- ARCHITECTURE_TYPE:\" ARCHITECTURE.md\n```\n\nIf found ‚Üí Use specified type\nIf not found ‚Üí Infer from Section 4 headers (see inference rules above)\n\n**Step 2: Apply Type-Specific Validation**\n\nBased on detected type, run appropriate validation:\n\n**META**:\n```bash\n# Check all 6 layers present\ngrep -n \"^### [0-9]\\.[1-6]\" ARCHITECTURE.md | grep \"Layer\"\n\n# Check BIAN alignment in Layer 5 components\ngrep -A20 \"Layer 5: Domain\" ARCHITECTURE.md | grep \"BIAN\"\n```\n\n**3-Tier**:\n```bash\n# Check all 3 tiers present\ngrep -n \"^### [0-9]\\.[1-3]\" ARCHITECTURE.md | grep \"Tier\"\n\n# Check no direct DB access from Tier 1\ngrep -B5 -A10 \"Tier 1\" ARCHITECTURE.md | grep -i \"database\"\n```\n\n**Microservices**:\n```bash\n# Check infrastructure components\ngrep -i \"API Gateway\\|Service Mesh\\|Event Bus\" ARCHITECTURE.md\n\n# Check database-per-service pattern\ngrep -c \"### .* Service$\" ARCHITECTURE.md\ngrep -c \"Database\" ARCHITECTURE.md\n```\n\n**N-Layer**:\n```bash\n# Check pattern specified\ngrep -i \"4-Layer\\|5-Layer\\|Clean\\|Hexagonal\" ARCHITECTURE.md\n\n# Check dependency direction documented\ngrep -i \"dependency\\|depends on\" ARCHITECTURE.md\n```\n\n**Step 3: Report Validation Results**\n\nCreate validation report:\n\n```markdown\n## Architecture Type Validation Report\n\n**Detected Type**: [META | 3-Tier | Microservices | N-Layer]\n\n**Validation Results**:\n\n‚úÖ **Passed Checks**:\n- [List passed validations]\n\n‚ùå **Failed Checks**:\n- [List violations with line numbers]\n\n‚ö†Ô∏è **Warnings**:\n- [List warnings or missing best practices]\n\n**Recommendations**:\n- [Fix suggestions for failed checks]\n```\n\n### Validation Checklist by Type\n\n#### META Architecture Checklist\n\n```\nMETA Architecture Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nSection 4 - Meta Architecture:\n‚òê All 6 layers documented (Channels, UX, Business Scenarios, Integration, Domain, Core)\n‚òê Layers in correct order (1‚Üí2‚Üí3‚Üí4‚Üí5‚Üí6)\n‚òê Each layer has description and component mapping\n‚òê Metadata comment present: <!-- ARCHITECTURE_TYPE: META -->\n\nSection 5 - Component Details:\n‚òê Components grouped by layer assignment\n‚òê Layer 5 (Domain) components include BIAN alignment\n‚òê BIAN ID specified for Layer 5 components\n‚òê BIAN V12.0 documented as default version in Section 4\n‚òê All BIAN service domain **names (Capabilities)** validated in [official landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n‚òê BIAN IDs (SD-XXX) used for internal document tracking only\n‚òê BIAN reference URLs included for all Layer 5 service domains\n‚òê BIAN alignment subsection includes official V12.0 landscape link\n‚òê BIAN Service Domain Model version documented as \"BIAN V12.0\" (default and recommended version)\n‚òê Control Records and Service Operations documented\n\nCommon Errors:\n‚òê No missing layers\n‚òê Layers not reordered\n‚òê All Layer 5 components have BIAN details\n```\n\n#### 3-Tier Architecture Checklist\n\n```\n3-Tier Architecture Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nSection 4 - Meta Architecture:\n‚òê All 3 tiers documented (Presentation, Application/Business Logic, Data)\n‚òê Tiers in correct order (1‚Üí2‚Üí3)\n‚òê Tier separation principles explained\n‚òê Metadata comment present: <!-- ARCHITECTURE_TYPE: 3-TIER -->\n\nSection 5 - Component Details:\n‚òê Components grouped by tier assignment\n‚òê Tier 1 (Presentation) has NO direct database access\n‚òê Tier 2 (Application) components are stateless\n‚òê Data access flows: Tier 1 ‚Üí Tier 2 ‚Üí Tier 3\n\nTier Separation:\n‚òê Presentation tier only calls Application tier\n‚òê Application tier calls Data tier for persistence\n‚òê No database connections in Presentation tier\n‚òê Session state externalized (if applicable)\n\nCommon Errors:\n‚òê No missing tiers\n‚òê No Tier 1 database access violations\n‚òê Tier terminology used (not \"Layer\")\n```\n\n#### Microservices Architecture Checklist\n\n```\nMicroservices Architecture Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nSection 4 - Meta Architecture:\n‚òê API Gateway documented (or omission justified)\n‚òê Service Mesh documented (or omission justified)\n‚òê Event Bus documented (Kafka, RabbitMQ, etc.)\n‚òê Service Discovery approach documented\n‚òê Metadata comment present: <!-- ARCHITECTURE_TYPE: MICROSERVICES -->\n\nSection 5 - Component Details:\n‚òê Each microservice has bounded context defined\n‚òê Database-per-service pattern followed (no shared databases)\n‚òê API endpoints documented (REST/gRPC/GraphQL)\n‚òê Events published and consumed documented\n‚òê Circuit breakers configured for sync dependencies\n‚òê Event schemas versioned (v1, v2, etc.)\n‚òê Dead Letter Queue (DLQ) handling documented\n\nInfrastructure:\n‚òê One database per service (or exception in ADR)\n‚òê Event naming convention followed\n‚òê Circuit breaker thresholds specified\n‚òê Timeout configurations documented\n\nCommon Errors:\n‚òê No shared databases\n‚òê API Gateway/Service Mesh present or justified\n‚òê Circuit breakers for all sync calls\n‚òê Events versioned\n```\n\n#### N-Layer Architecture Checklist\n\n```\nN-Layer Architecture Validation\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nSection 4 - Meta Architecture:\n‚òê Pattern specified (4-Layer, 5-Layer, Clean, Hexagonal, Custom)\n‚òê All required layers for pattern documented\n‚òê Dependency direction documented\n‚òê Layer boundaries and interfaces defined\n‚òê Metadata comment present: <!-- ARCHITECTURE_TYPE: N-LAYER -->\n\nSection 5 - Component Details:\n‚òê Components organized by layer assignment\n‚òê Core/Domain layer is framework-free (if applicable)\n‚òê Infrastructure layer implements domain interfaces\n‚òê No circular dependencies between layers\n‚òê Communication patterns between layers documented\n\nPattern-Specific (if applicable):\n‚òê DDD: Domain, Application, Infrastructure, Presentation layers\n‚òê Clean: Entities, Use Cases, Interface Adapters, Frameworks\n‚òê Hexagonal: Core, Primary Ports, Secondary Ports, Adapters\n\nCommon Errors:\n‚òê Pattern clearly specified\n‚òê Domain/Core layer has no framework dependencies\n‚òê Dependency direction is unidirectional\n‚òê No circular dependencies\n```\n\n---\n\n## Best Practices\n\n### DO:\n- ‚úÖ Validate structure during document creation\n- ‚úÖ Run verification commands (grep) to check sections\n- ‚úÖ Use validation checklist before finalizing\n- ‚úÖ Update Document Index after structural changes\n- ‚úÖ Enforce strict section names and order\n- ‚úÖ Ensure all 9 principles are documented\n- ‚úÖ Include system-specific implementation details\n- ‚úÖ Document honest trade-offs for each principle\n\n### DON'T:\n- ‚ùå Skip required sections\n- ‚ùå Use abbreviated section names\n- ‚ùå Reorder sections from standard sequence\n- ‚ùå Omit principle subsections (Description/Implementation/Trade-offs)\n- ‚ùå Use generic placeholder text\n- ‚ùå Include Decouple Through Events unless async provides clear benefits\n- ‚ùå Add custom principles beyond standard 9-10\n- ‚ùå Forget to update Document Index after changes\n\n---\n\n## Integration with Workflows\n\n**When to Apply Validations**:\n\n1. **During document creation**: Validate structure as you build\n2. **Before architecture reviews**: Run full validation checklist\n3. **After major updates**: Verify section integrity\n4. **Quarterly reviews**: Ensure document still meets standards\n\n**Validation Workflow**:\n\n```\n1. Run section header check:\n   grep -n \"^## [0-9]\" ARCHITECTURE.md\n\n2. Verify all 12 sections present and in order\n\n3. Check Section 3 has all 9 required principles:\n   grep -n \"^### 3\\.[1-9]\" ARCHITECTURE.md\n\n4. Validate each principle has required subsections:\n   - Description\n   - Implementation\n   - Trade-offs\n\n5. Run completeness checklist\n\n6. Update Document Index if needed\n\n7. Report validation results to user\n```\n\n---\n\n## Summary\n\nThis document provides validation rules and enforcement checklists for ARCHITECTURE.md documents. For operational workflows, see **SKILL.md**. For content templates and examples, see **ARCHITECTURE_DOCUMENTATION_GUIDE.md**.\n\n**Key Validation Points**:\n- 9 required Architecture Principles (strict order)\n- 12 required Section Names (exact match, case-sensitive)\n- 3 required subsections per principle (Description, Implementation, Trade-offs)\n- Optional: Decouple Through Events principle (#10)\n- Optional: Data Flow Patterns section (#6)\n- Strict markdown header format: `## [NUMBER]. [NAME]`",
        "skills/architecture-docs/adr/ADR-000-template.md": "# ADR-XXX: [Short Decision Title]\n\n**Status**: Proposed | Accepted | Deprecated | Superseded by ADR-XXX\n**Date**: YYYY-MM-DD\n**Authors**: [Author names or team name]\n**Related**: [Links to related ADRs, e.g., ADR-001, ADR-005]\n\n---\n\n## Context\n\n> What is the issue or situation that is motivating this decision or change?\n\n### Problem Statement\n\n[Describe the problem or opportunity. Be specific about:]\n- What problem are we trying to solve?\n- Who is impacted by this problem? (users, developers, operations, business)\n- What are the consequences of not solving this problem?\n- What is the current state and why is it insufficient?\n\n### Requirements\n\n**Functional Requirements:**\n- Requirement 1: [Description]\n- Requirement 2: [Description]\n- Requirement 3: [Description]\n\n**Non-Functional Requirements:**\n- Performance: [Latency, throughput targets]\n- Scalability: [Growth expectations]\n- Security: [Compliance, data protection]\n- Reliability: [Uptime, fault tolerance]\n- Maintainability: [Complexity, learning curve]\n\n**Constraints:**\n- Budget: [Financial limitations]\n- Timeline: [Deadlines, milestones]\n- Technology: [Existing tech stack, vendor lock-in]\n- Team: [Skills, capacity]\n- Compliance: [Regulatory requirements]\n\n### Business Drivers\n\n[Explain the business context and drivers:]\n- Business impact if we solve this\n- Business impact if we don't solve this\n- Strategic alignment\n- Competitive considerations\n- Cost implications\n\n---\n\n## Decision\n\n> What is the change that we're proposing and/or doing?\n\n### Summary\n\n[One-paragraph summary of the decision. This should be understandable to non-technical stakeholders.]\n\n### Detailed Decision\n\n[Provide a comprehensive explanation of what was decided. Include:]\n- What solution or approach we selected\n- How it will be implemented\n- What technologies, patterns, or practices will be used\n- Timeline or phasing if applicable\n\n### Scope\n\n**What IS included:**\n- Item 1\n- Item 2\n- Item 3\n\n**What is NOT included:**\n- Item 1\n- Item 2\n- Item 3\n\n---\n\n## Rationale\n\n> Why did we make this decision? What factors influenced the choice?\n\n### Primary Drivers\n\n**1. [Driver Name]**\n- **Description**: [What this driver is]\n- **Impact**: [Why this is important]\n- **Evidence**: [Data, benchmarks, examples that support this]\n\n**2. [Driver Name]**\n- **Description**: [What this driver is]\n- **Impact**: [Why this is important]\n- **Evidence**: [Data, benchmarks, examples that support this]\n\n**3. [Driver Name]**\n- **Description**: [What this driver is]\n- **Impact**: [Why this is important]\n- **Evidence**: [Data, benchmarks, examples that support this]\n\n[Continue for all primary drivers - typically 3-6]\n\n### Comparison Summary\n\n[Provide a comparison table of the options considered]\n\n| Criteria | Selected Option | Alternative 1 | Alternative 2 |\n|----------|----------------|---------------|---------------|\n| **Performance** | ‚úÖ Excellent | ‚ö†Ô∏è Good | ‚ùå Poor |\n| **Cost** | ‚ö†Ô∏è Medium | ‚úÖ Low | ‚ùå High |\n| **Complexity** | ‚úÖ Low | ‚ö†Ô∏è Medium | ‚ùå High |\n| **Maturity** | ‚úÖ Proven | ‚ö†Ô∏è Emerging | ‚ùå Experimental |\n| **Team Skills** | ‚úÖ High | ‚ö†Ô∏è Medium | ‚ùå Low |\n| **Ecosystem** | ‚úÖ Large | ‚ö†Ô∏è Growing | ‚ùå Limited |\n\n**Legend:**\n- ‚úÖ Strength\n- ‚ö†Ô∏è Acceptable/Trade-off\n- ‚ùå Weakness\n\n### Key Insights\n\n[Summarize the key insights that led to this decision:]\n- Insight 1\n- Insight 2\n- Insight 3\n\n---\n\n## Consequences\n\n> What becomes easier or more difficult because of this change?\n\n### Positive Consequences\n\n1. **[Positive Outcome 1]**\n   - Description of benefit\n   - Who benefits (users, developers, business)\n   - Estimated impact (quantify if possible)\n\n2. **[Positive Outcome 2]**\n   - Description of benefit\n   - Who benefits\n   - Estimated impact\n\n3. **[Positive Outcome 3]**\n   - Description of benefit\n   - Who benefits\n   - Estimated impact\n\n[Continue for all positive consequences]\n\n### Negative Consequences\n\n1. **[Negative Outcome 1]**\n   - Description of drawback\n   - Who is impacted\n   - **Mitigation**: [How we will address this]\n   - **Severity**: Low | Medium | High\n\n2. **[Negative Outcome 2]**\n   - Description of drawback\n   - Who is impacted\n   - **Mitigation**: [How we will address this]\n   - **Severity**: Low | Medium | High\n\n3. **[Negative Outcome 3]**\n   - Description of drawback\n   - Who is impacted\n   - **Mitigation**: [How we will address this]\n   - **Severity**: Low | Medium | High\n\n[Continue for all negative consequences]\n\n### Trade-offs\n\n[Explicitly state what we're trading off:]\n\n- **Simplicity vs Flexibility**: [Explain the trade-off made]\n- **Performance vs Cost**: [Explain the trade-off made]\n- **Time-to-Market vs Quality**: [Explain the trade-off made]\n- **[Other Trade-off]**: [Explanation]\n\n---\n\n## Alternatives Considered\n\n> What other options did we evaluate and why were they not selected?\n\n### Alternative 1: [Alternative Name]\n\n**Description:**\n[Brief description of this alternative]\n\n**Why Considered:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Why Rejected:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Use Case:**\n[When would this alternative have been the better choice?]\n\n---\n\n### Alternative 2: [Alternative Name]\n\n**Description:**\n[Brief description of this alternative]\n\n**Why Considered:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Why Rejected:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Use Case:**\n[When would this alternative have been the better choice?]\n\n---\n\n### Alternative 3: [Alternative Name]\n\n**Description:**\n[Brief description of this alternative]\n\n**Why Considered:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Why Rejected:**\n- Reason 1\n- Reason 2\n- Reason 3\n\n**Use Case:**\n[When would this alternative have been the better choice?]\n\n---\n\n[Add more alternatives as needed]\n\n---\n\n## Implementation Plan\n\n> How will this decision be implemented? (Optional section)\n\n### Phases\n\n**Phase 1: [Name]** (Timeline: [Duration])\n- Task 1\n- Task 2\n- Task 3\n- **Success Criteria**: [How we know this phase is complete]\n\n**Phase 2: [Name]** (Timeline: [Duration])\n- Task 1\n- Task 2\n- Task 3\n- **Success Criteria**: [How we know this phase is complete]\n\n**Phase 3: [Name]** (Timeline: [Duration])\n- Task 1\n- Task 2\n- Task 3\n- **Success Criteria**: [How we know this phase is complete]\n\n### Dependencies\n\n- Dependency 1: [Description, owner]\n- Dependency 2: [Description, owner]\n- Dependency 3: [Description, owner]\n\n### Risks\n\n| Risk | Probability | Impact | Mitigation |\n|------|------------|--------|------------|\n| [Risk 1] | Low/Med/High | Low/Med/High | [Mitigation strategy] |\n| [Risk 2] | Low/Med/High | Low/Med/High | [Mitigation strategy] |\n| [Risk 3] | Low/Med/High | Low/Med/High | [Mitigation strategy] |\n\n---\n\n## Success Metrics\n\n> How will we measure the success of this decision? (Optional section)\n\n### Quantitative Metrics\n\n- **Metric 1**: [Current baseline] ‚Üí [Target]\n- **Metric 2**: [Current baseline] ‚Üí [Target]\n- **Metric 3**: [Current baseline] ‚Üí [Target]\n\n### Qualitative Metrics\n\n- Developer satisfaction: [How measured, target]\n- User feedback: [How measured, target]\n- Team velocity: [How measured, target]\n\n### Review Timeline\n\n- **Initial Review**: [Date] - Check if metrics are trending correctly\n- **Final Review**: [Date] - Evaluate success and lessons learned\n- **Owner**: [Who is responsible for tracking metrics]\n\n---\n\n## References\n\n> Links to supporting documentation, research, and related materials\n\n### Documentation\n- [Internal docs, architecture diagrams]\n- [API specifications, schemas]\n- [Design documents]\n\n### Research & Analysis\n- [Blog posts, whitepapers]\n- [Benchmark results, performance tests]\n- [Case studies, success stories]\n\n### Related ADRs\n- [ADR-XXX](ADR-XXX-title.md) - Related decision\n- [ADR-YYY](ADR-YYY-title.md) - Supersedes/Builds on\n\n### External Resources\n- [Technology documentation]\n- [Community discussions, GitHub issues]\n- [Books, articles, conference talks]\n\n---\n\n## Review History\n\n> Track changes and reviews of this ADR\n\n| Date | Reviewer | Action | Notes |\n|------|----------|--------|-------|\n| YYYY-MM-DD | [Name] | Created | Initial draft |\n| YYYY-MM-DD | [Name] | Reviewed | [Comments] |\n| YYYY-MM-DD | [Name] | Approved | Status changed to Accepted |\n\n---\n\n## Notes\n\n> Additional context, caveats, or future considerations\n\n[Optional section for:]\n- Edge cases not covered\n- Future evolution plans\n- Known limitations\n- Assumptions made\n- Open questions\n\n---\n\n**Last Updated**: YYYY-MM-DD\n**Status**: ‚úÖ Accepted | üöß Proposed | ‚ö†Ô∏è Deprecated | üîÑ Superseded\n**Next Review**: YYYY-MM-DD (for important decisions, schedule periodic reviews)\n\n---\n\n## ADR Template Usage Guide\n\n### When to Create an ADR\n\nCreate an ADR when making decisions about:\n- ‚úÖ Technology selection (languages, frameworks, databases)\n- ‚úÖ Architectural patterns (microservices, event-driven, monolith)\n- ‚úÖ API design (REST, GraphQL, gRPC)\n- ‚úÖ Infrastructure choices (cloud provider, container orchestration)\n- ‚úÖ Security approaches (authentication, authorization, encryption)\n- ‚úÖ Data modeling (schema design, storage patterns)\n- ‚úÖ Development practices (testing strategy, deployment process)\n- ‚úÖ Major refactoring decisions\n- ‚úÖ Third-party service integrations\n\n### When NOT to Create an ADR\n\nDon't create an ADR for:\n- ‚ùå Minor implementation details\n- ‚ùå Temporary experiments or prototypes\n- ‚ùå Coding style preferences (use linting rules instead)\n- ‚ùå Routine operational changes\n- ‚ùå Decisions that can be easily reversed\n\n### Writing Tips\n\n1. **Be Specific**: Use concrete examples and data\n2. **Be Honest**: Document trade-offs, don't oversell the decision\n3. **Be Concise**: Aim for clarity, not length\n4. **Use Present Tense**: \"We use X\" not \"We will use X\"\n5. **Include Evidence**: Link to benchmarks, tests, proof of concepts\n6. **Update Status**: Mark as Deprecated or Superseded when invalidated\n\n### ADR Workflow\n\n```\n1. Create ADR with Status: Proposed\n   ‚Üì\n2. Share with team for review\n   ‚Üì\n3. Incorporate feedback, iterate\n   ‚Üì\n4. Present in architecture review meeting\n   ‚Üì\n5. Update Status: Accepted (or Rejected)\n   ‚Üì\n6. Implement decision\n   ‚Üì\n7. Periodic review (for critical ADRs)\n   ‚Üì\n8. Update or Deprecate as needed\n```\n\n### File Naming Convention\n\n- Format: `ADR-XXX-brief-title.md`\n- XXX: Zero-padded number (001, 002, ..., 099, 100)\n- brief-title: Lowercase, hyphen-separated\n- Examples:\n  - `ADR-001-monorepo-structure.md`\n  - `ADR-015-postgresql-database.md`\n  - `ADR-042-event-sourcing-pattern.md`\n\n### Cross-Referencing\n\n- Link to related ADRs in the \"Related\" field at the top\n- Link to ADRs from ARCHITECTURE.md when explaining decisions\n- Maintain an ADR index (README.md in adr/ directory)",
        "skills/architecture-docs/examples/ARCHITECTURE_example_3tier.md": "# ARCHITECTURE.md - E-Commerce Platform (3-Tier Example)\n\n<!-- ARCHITECTURE_TYPE: 3-TIER -->\n\n> **Document Version**: 1.0\n> **Last Updated**: 2025-01-29\n> **Architecture Type**: 3-Tier Architecture\n\n## Document Index\n\n**Quick Navigation:**\n- [Section 1: Executive Summary](#1-executive-summary) ‚Üí Lines 25-65\n- [Section 2: System Overview](#2-system-overview) ‚Üí Lines 66-120\n- [Section 3: Architecture Principles](#3-architecture-principles) ‚Üí Lines 121-250\n- [Section 4: Meta Architecture](#4-meta-architecture) ‚Üí Lines 251-350\n- [Section 5: Component Details](#5-component-details) ‚Üí Lines 351-550\n- [Section 6: Integration Points](#6-integration-points) ‚Üí Lines 551-600\n- [Section 7: Technology Stack](#7-technology-stack) ‚Üí Lines 601-650\n- [Section 8: Security Architecture](#8-security-architecture) ‚Üí Lines 651-700\n- [Section 9: Scalability & Performance](#9-scalability--performance) ‚Üí Lines 701-750\n- [Section 10: Operational Considerations](#10-operational-considerations) ‚Üí Lines 751-800\n- [Section 11: Architecture Decision Records (ADRs)](#11-architecture-decision-records-adrs) ‚Üí Lines 801-end\n\n**Index Last Updated:** 2025-01-29\n\n---\n\n## 1. Executive Summary\n\n**System Name**: E-Commerce Platform\n\n**Purpose**: A web-based e-commerce platform enabling customers to browse products, place orders, and manage their accounts, while providing administrators with inventory management and order fulfillment capabilities.\n\n**Key Metrics**:\n- **Read TPS**: 500 TPS (average), 1,200 TPS (peak) - measured over last 30 days\n- **Write TPS**: 50 TPS (average), 150 TPS (peak) - measured over last 30 days\n- **Latency**: p95 < 200ms, p99 < 500ms\n- **Availability**: 99.9% SLA (43 minutes downtime/month)\n- **Concurrent Users**: 10,000 simultaneous sessions\n\n**Business Value**:\n- Revenue: $5M annual GMV (Gross Merchandise Value)\n- Customer Satisfaction: 4.5/5 average rating\n- Operational Efficiency: 80% reduction in manual order processing\n\n**Technical Overview**: Classic 3-tier web application with React frontend, Node.js/Express API tier, and PostgreSQL database. Horizontally scalable presentation and application tiers, with vertical scaling for database tier.\n\n---\n\n## 2. System Overview\n\n### 2.1 Problem Statement\n\nTraditional retail businesses struggle with online presence, requiring manual order processing, fragmented inventory management, and limited customer reach. Lack of real-time inventory visibility leads to overselling and customer dissatisfaction.\n\n### 2.2 Solution Overview\n\nThe E-Commerce Platform provides a fully integrated online storefront with automated order processing, real-time inventory tracking, and customer self-service capabilities. The 3-tier architecture ensures clear separation of concerns with presentation, business logic, and data tiers.\n\n### 2.3 Primary Use Cases\n\n**Use Case 1: Customer Product Purchase**\n- Actor: Registered Customer\n- Flow: Browse catalog ‚Üí Add to cart ‚Üí Checkout ‚Üí Payment ‚Üí Order confirmation\n- Success Metric: 95% checkout completion rate\n\n**Use Case 2: Inventory Management**\n- Actor: Administrator\n- Flow: Add/update products ‚Üí Set stock levels ‚Üí Monitor inventory alerts\n- Success Metric: <1% stockout incidents\n\n**Use Case 3: Order Fulfillment**\n- Actor: Warehouse Staff\n- Flow: View pending orders ‚Üí Pick items ‚Üí Mark as shipped ‚Üí Update tracking\n- Success Metric: 24-hour fulfillment SLA achievement rate: 98%\n\n---\n\n## 3. Architecture Principles\n\n### 3.1 Separation of Concerns\n\n**Description:**\nThe system enforces strict tier separation with presentation, application logic, and data tiers having distinct responsibilities and no cross-tier boundary violations.\n\n**Implementation:**\n- React SPA (Presentation tier) - UI rendering, user input validation\n- Express.js API (Application tier) - Business logic, orchestration, transaction management\n- PostgreSQL (Data tier) - Data persistence, integrity constraints\n- No direct database access from presentation tier\n- RESTful API as the only interface between presentation and application tiers\n\n**Trade-offs:**\n- Additional network latency from tier-to-tier communication (average 5-10ms overhead)\n- More complex deployment with three separate deployable units\n- Debugging requires tracing across tiers\n- Development overhead maintaining tier boundaries\n\n### 3.2 High Availability\n\n**Description:**\nThe system maintains 99.9% availability through redundancy at presentation and application tiers, with database replication.\n\n**Implementation:**\n- Load Balancer (AWS ALB) with health checks (30s interval)\n- Minimum 2 instances per tier (presentation, application)\n- PostgreSQL read replicas (2 replicas, async replication)\n- Auto-scaling policies for presentation and application tiers\n- Circuit breaker pattern for external service calls (Stripe, SendGrid)\n\n**Trade-offs:**\n- Infrastructure costs: 3x for redundancy\n- Increased operational complexity managing multiple instances\n- Eventual consistency with read replicas (1-2s replication lag)\n- Stateless session management requires external session store (Redis)\n\n*(Sections 3.3-3.9 would continue with remaining principles: Scalability First, Security by Design, Observability, Resilience, Simplicity, Cloud-Native, Open Standards)*\n\n---\n\n## 4. Meta Architecture - 3-Tier Classic Web Application\n\n<!-- ARCHITECTURE_TYPE: 3-TIER -->\n\nThis system follows the classic 3-tier architecture pattern with clear separation between presentation, application logic, and data tiers.\n\n### 4.1 Tier 1: Presentation\n\n**Purpose**: User interface layer handling all user interactions and display logic.\n\n**Components**:\n- React SPA (Single Page Application)\n- Nginx (static file serving)\n- Client-side routing (React Router)\n\n**Responsibilities**:\n- Render UI components\n- Client-side form validation\n- API request/response handling\n- Session token management (localStorage)\n\n**Technology**: React 18, TypeScript, Material-UI, Nginx\n\n**Scaling**: Horizontal scaling via CDN (CloudFront) and multiple Nginx instances behind ALB\n\n**Communication**: RESTful HTTP calls to Tier 2 (Application tier) via `/api/*` endpoints\n\n---\n\n### 4.2 Tier 2: Application/Business Logic\n\n**Purpose**: Core business logic, workflow orchestration, and transaction management.\n\n**Components**:\n- Express.js REST API\n- Business services (OrderService, InventoryService, PaymentService)\n- Authentication middleware (JWT validation)\n- Transaction coordinator\n\n**Responsibilities**:\n- Business rule enforcement (pricing, discounts, stock validation)\n- Order processing workflow orchestration\n- Payment processing integration (Stripe API)\n- Email notification triggering (SendGrid API)\n- Session management (stateless with Redis session store)\n\n**Technology**: Node.js 20, Express.js 4, TypeScript, Redis (sessions)\n\n**Scaling**: Horizontal scaling with auto-scaling group (min: 2, max: 10 instances)\n\n**Communication**:\n- Inbound: RESTful HTTP from Tier 1 (Presentation)\n- Outbound: PostgreSQL connections to Tier 3 (Data), External API calls (Stripe, SendGrid)\n\n**Stateless Design**:\n- No in-memory session storage\n- Redis for session persistence (TTL: 30 minutes)\n- Idempotent API design with request IDs\n\n---\n\n### 4.3 Tier 3: Data\n\n**Purpose**: Data persistence, integrity enforcement, and query optimization.\n\n**Components**:\n- PostgreSQL 15 (primary database)\n- PostgreSQL read replicas (2 replicas for read scalability)\n- Flyway (database migration tool)\n\n**Responsibilities**:\n- Persistent storage for products, orders, customers, inventory\n- Referential integrity enforcement (foreign keys)\n- Transaction ACID guarantees\n- Backup and point-in-time recovery\n\n**Technology**: PostgreSQL 15, AWS RDS, Flyway\n\n**Scaling**: Vertical scaling (primary), Read replicas for read-heavy queries\n\n**Communication**:\n- Inbound: SQL connections from Tier 2 (Application tier ONLY)\n- Outbound: Async replication to read replicas\n\n**Schema**:\n- Tables: `users`, `products`, `orders`, `order_items`, `inventory`, `payments`\n- Indexes: Composite indexes on `orders (user_id, created_at)`, `products (category_id, price)`\n\n---\n\n### 4.4 Tier Separation Enforcement\n\n**Rules**:\n1. **Tier 1 (Presentation) ‚Üí Tier 2 (Application) ONLY**\n   - No direct database access from presentation tier\n   - All data access via RESTful API\n\n2. **Tier 2 (Application) ‚Üí Tier 3 (Data) ONLY**\n   - Application tier is the ONLY tier with database credentials\n   - Connection pooling managed at application tier (max connections: 20 per instance)\n\n3. **No Cross-Tier Boundary Violations**:\n   - Database credentials NOT accessible from presentation tier\n   - Business logic NOT implemented in database (stored procedures minimal, only for complex transactions)\n   - UI logic NOT implemented in application tier (API returns data, not HTML)\n\n**Validation**:\n```bash\n# Verify no database connections in Tier 1\ngrep -r \"pg\\|postgres\\|database\" frontend/src/ | grep -v \"\\/\\*\\|\\/\\/\" | wc -l\n# Expected: 0 (no database imports)\n```\n\n---\n\n## 5. Component Details\n\nComponents are organized by tier assignment.\n\n---\n\n## Tier 1: Presentation Layer - Components\n\n### 5.1 React SPA (Single Page Application)\n\n**Type**: Web UI\n**Technology**: React 18, TypeScript, Material-UI\n**Location**: `frontend/src/`\n\n**Purpose**:\nProvide responsive web interface for customers to browse products, manage shopping cart, and place orders. Admin interface for inventory management.\n\n**Responsibilities**:\n- Product catalog browsing with filtering and search\n- Shopping cart management (add, remove, update quantities)\n- Checkout flow with payment integration\n- User authentication (login, registration)\n- Admin dashboard for inventory and order management\n\n**UI Features**:\n- Product Catalog: Grid/list view, category filtering, search autocomplete\n- Shopping Cart: Real-time price updates, quantity adjustments\n- Checkout: Multi-step form (shipping ‚Üí payment ‚Üí review)\n- Admin Panel: Product CRUD, inventory alerts, order status tracking\n\n**Dependencies**:\n- Depends on: Tier 2 (Express.js REST API) via `/api/v1/*` endpoints\n- External: CloudFront CDN for static asset delivery\n\n**Configuration**:\n- `REACT_APP_API_BASE_URL`: API endpoint URL (default: `https://api.example.com`)\n- `REACT_APP_STRIPE_PUBLIC_KEY`: Stripe publishable key for payment forms\n\n**Scaling**:\n- Horizontal: CDN distribution (CloudFront) with edge caching\n- Build artifacts served by multiple Nginx instances (min: 2, max: 5)\n\n**Failure Modes**:\n- API unavailable: Show cached data, disable purchases, display maintenance message\n- CDN failure: Fallback to origin Nginx servers\n- Slow API responses: Show loading indicators, timeout after 10s\n\n**Monitoring**:\n- Key metrics: Page load time (p95 < 1.5s), API error rate (< 2%), bounce rate\n- Alerts: Error rate > 5%, page load time > 3s\n- Logs: User interactions (button clicks, form submissions), API call errors\n\n---\n\n## Tier 2: Application/Business Logic Layer - Components\n\n### 5.2 Order Service\n\n**Type**: Application Service\n**Technology**: Node.js 20, Express.js, TypeScript\n**Location**: `backend/src/services/OrderService.ts`\n\n**Purpose**:\nManage order lifecycle from creation through fulfillment, including order validation, inventory coordination, and payment processing.\n\n**Responsibilities**:\n- Order creation with validation (stock availability, pricing)\n- Order total calculation (subtotal + tax + shipping)\n- Inventory reservation (via InventoryService)\n- Payment processing coordination (via PaymentService)\n- Order status transitions (pending ‚Üí paid ‚Üí shipped ‚Üí delivered)\n\n**Public Methods/API**:\n- `createOrder(orderData: CreateOrderDto): Promise<Order>`: Create and validate order\n- `getOrder(orderId: string): Promise<Order>`: Retrieve order by ID\n- `updateOrderStatus(orderId: string, status: OrderStatus): Promise<Order>`: Update status\n- `getUserOrders(userId: string): Promise<Order[]>`: Get user order history\n\n**Business Rules**:\n- Order total must match sum of item prices + tax + shipping\n- Cannot create order with out-of-stock items\n- Payment must be completed within 15 minutes of order creation\n- Orders cannot be cancelled after shipping\n\n**Dependencies**:\n- Depends on: OrderRepository (Tier 3), InventoryService (Tier 2), PaymentService (Tier 2)\n- Depended by: Order API Controller (Tier 1 interface)\n\n**Configuration**:\n- `ORDER_TIMEOUT_MINUTES`: Payment timeout (default: 15)\n- `TAX_RATE`: Sales tax percentage (default: 0.08)\n\n**Scaling**:\n- Horizontal: Stateless design, scales linearly with auto-scaling group\n- Resource requirements: 1 vCPU, 1GB RAM per instance\n\n**Failure Modes**:\n- InventoryService unavailable: Return 503, prevent order creation\n- PaymentService timeout: Mark order as pending, retry payment asynchronously\n- Database connection failure: Return 503 Service Unavailable\n\n**Monitoring**:\n- Key metrics: Orders created/hour, order value (avg, p95), order processing time\n- Alerts: Order creation failure rate > 2%, processing time > 5s\n- Logs: All order events (created, paid, shipped), business rule violations\n\n---\n\n## Tier 3: Data Layer - Components\n\n### 5.3 Order Repository\n\n**Type**: Data Access Object (Repository)\n**Technology**: TypeORM 0.3, PostgreSQL 15\n**Location**: `backend/src/repositories/OrderRepository.ts`\n\n**Purpose**:\nProvide data access layer for Order entity persistence, ensuring transaction integrity and query optimization.\n\n**Responsibilities**:\n- CRUD operations for Order and OrderItem entities\n- Transaction management for multi-table operations (order + order_items + inventory)\n- Query optimization for order listing and search\n- Database connection pooling\n\n**Schema** (PostgreSQL):\n- **Table**: `orders`\n  - Columns: `id` (UUID PK), `user_id` (UUID FK), `total_amount` (DECIMAL), `status` (VARCHAR), `created_at`, `updated_at`\n- **Table**: `order_items`\n  - Columns: `id` (UUID PK), `order_id` (UUID FK), `product_id` (UUID FK), `quantity` (INT), `unit_price` (DECIMAL)\n- **Indexes**:\n  - `idx_orders_user_id` on `user_id` (for user order history queries)\n  - `idx_orders_status_created` on `(status, created_at)` (for admin dashboard)\n\n**Data Access Methods**:\n- `findById(id: string): Promise<Order | null>`: Find order by primary key with eager-loaded order_items\n- `findByUserId(userId: string): Promise<Order[]>`: Get all orders for user\n- `save(order: Order): Promise<Order>`: Insert or update order with transaction\n- `updateStatus(orderId: string, status: OrderStatus): Promise<void>`: Update order status\n\n**Dependencies**:\n- Depends on: PostgreSQL 15 database server (AWS RDS)\n- Depended by: OrderService (Tier 2)\n\n**Configuration**:\n- `DB_HOST`: Database host (default: localhost)\n- `DB_PORT`: Database port (default: 5432)\n- `DB_CONNECTION_POOL_SIZE`: Max connections (default: 20)\n\n**Scaling**:\n- Horizontal: Read replicas for read-heavy queries (user order history)\n- Vertical: Database server (4 vCPU, 16GB RAM)\n\n**Backup & Recovery**:\n- Backup Frequency: Daily automated snapshots (AWS RDS), hourly transaction logs\n- Retention Policy: 7 days for snapshots, 30 days for transaction logs\n- Recovery Time Objective (RTO): <1 hour\n- Recovery Point Objective (RPO): <15 minutes\n\n**Failure Modes**:\n- Connection pool exhausted: Queue requests, timeout after 5s, alert\n- Primary database down: Promote read replica to primary (manual failover, 5-10 min RTO)\n- Slow query (>500ms): Log query, alert, investigate indexes\n\n**Monitoring**:\n- Key metrics: Query latency (p50/p95/p99), connection pool usage (%), disk I/O\n- Alerts: Query latency > 500ms, connection pool > 80%, disk space < 20%\n- Logs: Slow queries (>100ms), connection errors, transaction deadlocks\n\n---\n\n*(Section 5 would continue with remaining components: ProductService, InventoryService, PaymentService, corresponding repositories, etc.)*\n\n---\n\n## 6. Integration Points\n\n### 6.1 Stripe Payment Gateway\n\n**Type**: External SaaS API\n**Purpose**: Credit card payment processing\n**Protocol**: RESTful HTTPS API\n**SLA**: 99.99% uptime\n**Integration Pattern**: Synchronous API calls with retry logic\n\n**Endpoints**:\n- `POST /v1/payment_intents`: Create payment intent\n- `POST /v1/payment_intents/{id}/confirm`: Confirm payment\n\n**Authentication**: API key (secret key stored in AWS Secrets Manager)\n\n**Error Handling**:\n- Timeout: 10s, retry 3 times with exponential backoff\n- Rate limiting: Max 100 requests/second\n- Circuit breaker: Open after 50% error rate over 10 requests\n\n---\n\n*(Sections 6-11 would continue with Integration Points, Technology Stack, Security Architecture, Scalability & Performance, Operational Considerations, and Architecture Decision Records)*\n\n---\n\n## 11. Architecture Decision Records (ADRs)\n\n### ADR-001: Choose 3-Tier Architecture over Microservices\n\n**Status**: Accepted\n\n**Context**: Need to build e-commerce platform with limited team (3 developers) and moderate scale requirements (< 1,500 TPS).\n\n**Decision**: Use 3-tier architecture with React, Express.js, PostgreSQL.\n\n**Rationale**:\n- Simplicity: Easier to develop, test, deploy with small team\n- Lower operational complexity: Single database, fewer moving parts\n- Cost: Lower infrastructure costs (vs. microservices requiring API gateway, service mesh, etc.)\n- Adequate scalability: Horizontal scaling of presentation/application tiers sufficient for target load\n\n**Consequences**:\n- Pros: Faster time to market, easier debugging, lower operational burden\n- Cons: Less flexibility for independent service scaling, shared database may become bottleneck at very high scale\n\n**Alternatives Considered**:\n- Microservices: Rejected due to team size and operational complexity\n- Monolithic: Rejected due to lack of tier separation and scaling limitations\n\n---\n\n### ADR-002: Use PostgreSQL over MongoDB\n\n**Status**: Accepted\n\n**Context**: Need to choose primary database for orders, products, inventory with ACID transaction requirements.\n\n**Decision**: Use PostgreSQL 15 as primary database.\n\n**Rationale**:\n- Strong ACID guarantees for financial transactions (orders, payments)\n- Rich query capabilities for complex joins (orders + order_items + products)\n- Mature ecosystem and operational tooling\n- Team expertise with SQL databases\n\n**Consequences**:\n- Pros: Data integrity, complex query support, proven reliability\n- Cons: Vertical scaling limits (compared to NoSQL horizontal scaling), schema migrations require planning\n\n**Alternatives Considered**:\n- MongoDB: Rejected due to lack of multi-document ACID transactions (pre-v4.0), eventual consistency concerns\n- MySQL: Rejected due to weaker JSON support and less rich data types compared to PostgreSQL\n\n---\n",
        "skills/architecture-docs/examples/README.md": "# Architecture Documentation Examples\n\nThis directory contains example ARCHITECTURE.md files demonstrating each supported architecture type.\n\n## Available Examples\n\n### 1. ARCHITECTURE_example_microservices.md (Recommended)\n**Architecture Type**: Microservices (Cloud-Native Distributed)\n\nDemonstrates:\n- Infrastructure components (API Gateway, Service Mesh, Event Bus)\n- Database-per-service pattern\n- Event-driven communication\n- Circuit breaker patterns\n- Microservice catalog with comprehensive service details\n\n**Best for**: Cloud-native systems, independently deployable services, event-driven architectures\n\n**Why Recommended**: Industry-standard approach for modern, scalable, cloud-native applications\n\n---\n\n### 2. ARCHITECTURE_example_meta.md\n**Architecture Type**: META (6-Layer Enterprise)\n\nDemonstrates:\n- 6-layer META model (Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Integration ‚Üí Domain ‚Üí Core)\n- [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) alignment for Layer 5 (Domain) components (default version)\n- Complex enterprise integration patterns\n- Regulatory compliance considerations\n\n**BIAN V12.0 Default**: All META architecture examples use BIAN V12.0 as the default service domain model. Service domains are referenced from the [official BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html).\n\n**Best for**: Large enterprise systems, financial services, complex integrations\n\n---\n\n### 3. ARCHITECTURE_example_3tier.md\n**Architecture Type**: 3-Tier (Classic Web Application)\n\nDemonstrates:\n- 3-tier structure (Presentation ‚Üí Application/Business Logic ‚Üí Data)\n- Tier separation enforcement\n- Stateless application tier design\n- Standard web application patterns\n\n**Best for**: Web applications, REST APIs, standard CRUD systems\n\n---\n\n### 4. ARCHITECTURE_example_nlayer.md\n**Architecture Type**: N-Layer (Domain-Driven Design)\n\nDemonstrates:\n- 4-Layer Classic DDD pattern\n- Framework-free domain layer\n- Dependency inversion principle\n- Repository pattern with interface segregation\n- Clean separation of concerns\n\n**Best for**: DDD implementations, Clean Architecture, Hexagonal Architecture\n\n---\n\n## Using These Examples\n\n**To use an example as a starting point:**\n\n1. Copy the example file that best matches your system's architecture type\n2. Rename it to `ARCHITECTURE.md` in your project directory\n3. Replace placeholder content with your system-specific details\n4. Validate using the validation rules in `../VALIDATIONS.md`\n\n**Key sections to customize:**\n- Section 1: Executive Summary (system name, metrics, business value)\n- Section 2: System Overview (problem statement, use cases)\n- Section 3: Architecture Principles (system-specific implementations)\n- Section 5: Component Details (your actual components)\n- Section 7: Integration Points (your external systems)\n- Section 8: Technology Stack (your technologies)\n\n**Metadata tracking:**\n\nEach example includes an architecture type metadata comment in Section 4:\n```markdown\n<!-- ARCHITECTURE_TYPE: META | 3-TIER | MICROSERVICES | N-LAYER -->\n```\n\nThis metadata enables type-specific validation and ensures proper template selection.\n\n---\n\n## Comparison Matrix\n\n| Feature | Microservices* | META | 3-Tier | N-Layer |\n|---------|----------------|------|--------|---------|\n| **Complexity** | High | Very High | Low | Medium-High |\n| **Team Size** | Large (10+) | Large (10+) | Small-Med (2-8) | Medium (4-10) |\n| **Scalability** | Horizontal | Horizontal/Vertical | Vertical | Depends on pattern |\n| **Deployment** | Complex (independent) | Complex | Simple | Moderate |\n| **Data Management** | Distributed (per-service) | Centralized/Distributed | Centralized | Depends on pattern |\n| **Integration** | Event-driven + REST | Complex (ESB/Integration layer) | Simple (direct) | Interface-based |\n| **Best For** | Cloud-native, SaaS | Enterprises, banking | Web apps, APIs | DDD, Clean Arch |\n\n\\* Recommended for modern cloud-native applications\n\n---\n\n## Related Documentation\n\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Full documentation guide with all 12 sections\n- **VALIDATIONS.md**: Validation rules and checklists (including type-aware validation)\n- **SKILL.md**: Operational workflows for creating and editing ARCHITECTURE.md\n- **templates/**: Type-specific templates for Section 4 and Section 5\n\n---\n\n## Contributing Examples\n\nIf you create a high-quality ARCHITECTURE.md that could serve as a reference example, consider contributing it to this directory (with sensitive information removed).\n\n**Contribution guidelines:**\n1. Remove all proprietary/confidential information\n2. Use realistic but generic company/system names\n3. Include comprehensive content for all 12 sections\n4. Follow validation rules strictly\n5. Add architecture type metadata comment in Section 4",
        "skills/architecture-docs/presentation/PRESENTATION_GUIDE.md": "# Architecture Presentation Generation Guide\n\n## Overview\n\nThe presentation generation feature automatically creates professional PowerPoint presentations from your ARCHITECTURE.md files. Generate stakeholder-specific presentations in English or Spanish with a single command.\n\n**Version**: 2.0\n**Last Updated**: 2025-12-24\n\n## Features\n\n- **3 Stakeholder Types**: Business (30 slides), Architecture (35 slides), Compliance (32 slides)\n- **12 Slide Types**: Including section dividers, comparisons, metrics, quotes, process flows, and more\n- **Dark Blue Professional Theme**: Modern color palette (#0A1E3D primary)\n- **Bilingual Support**: English and Spanish\n- **Context-Efficient**: Loads only required sections (50-80% reduction)\n- **Automated Slide Generation**: 30-35 slides per presentation\n- **Professional Design**: Corporate color scheme with consistent branding\n- **Template-Based**: Predefined slide structures for each stakeholder type\n- **Comprehensive Content**: Enhanced technical details and business context\n\n## Quick Start\n\n### Prerequisites\n\n1. **ARCHITECTURE.md file** exists and is complete\n2. **Document Index** is present (lines 1-50)\n3. **Bun 1.0+** runtime installed\n4. All 12 sections documented in ARCHITECTURE.md\n\n### Basic Usage\n\n**Option 1: Through architecture-docs skill**\n\n```\nUser: \"Generate architecture presentation for business stakeholders\"\n```\n\nThe skill will guide you through:\n1. Stakeholder type selection (Business/Architecture/Compliance)\n2. Language selection (English/Spanish)\n3. Confirmation\n4. Automated generation\n\n**Option 2: Command-Line**\n\n```bash\ncd /home/shadowx4fox/solutions-architect-skills\n\n# Business presentation in English\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md \\\n  --stakeholder business \\\n  --language en\n\n# Architecture presentation in Spanish\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md \\\n  --stakeholder architecture \\\n  --language es\n\n# Compliance presentation with custom output\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md \\\n  --stakeholder compliance \\\n  --output /custom/path/presentation.pptx\n```\n\n### Output Location\n\nPresentations are saved to:\n```\n/presentations/ARCHITECTURE_{StakeholderType}_{Language}.pptx\n```\n\n**Examples**:\n- `/presentations/ARCHITECTURE_Business_EN.pptx`\n- `/presentations/ARCHITECTURE_Architecture_ES.pptx`\n- `/presentations/ARCHITECTURE_Compliance_EN.pptx`\n\n## Stakeholder Types\n\n### Business Stakeholders (30 slides)\n\n**Target Audience**: Executives, Product Owners, Business Analysts\n\n**Focus**: Business value, outcomes, operations, high-level architecture\n\n**Presentation Time**: ~45 minutes\n\n**Slide Structure**:\n1. Title Slide\n2. Agenda\n3. **Section Divider** - Business Overview\n4. Executive Summary - Key business metrics and overview\n5. **Metrics Slide** - Key Performance Metrics (concurrent users, availability, response time)\n6. **Single Focus** - Business Value Proposition\n7. **Quote Slide** - Customer Success Story\n8. **Section Divider** - Business Context\n9. Problem & Solution - Problem statement (3 bullets)\n10. **Explanation Visual** - Solution Overview\n11. Use Cases - Part 1 (first 5 use cases)\n12. Use Cases - Part 2 (Details, use cases 6-10)\n13. Target Users & Personas\n14. **Comparison** - Before/After Transformation Impact\n15. **Section Divider** - Core Capabilities\n16. Core Capabilities - Functional requirements\n17. **Metrics Slide** - System Availability & Performance (SLAs)\n18. Performance Guarantees\n19. **Single Focus** - Scalability Overview\n20. **Section Divider** - Operational Support\n21. Support Model\n22. Monitoring & Observability\n23. **Process** - Incident Response workflow\n24. **Comparison** - Disaster Recovery (RPO/RTO)\n25. **Section Divider** - Architecture Foundation\n26. Architecture Principles - Part 1 (first 5 principles)\n27. Architecture Principles - Part 2 (principles 6-10)\n28. **Explanation Visual** - Architecture Layers Overview\n29. Summary - Key takeaways and next steps\n30. **Call to Action** - Compliance & Contact\n\n**Data Sources**: Sections 1, 2, 3, 4, 10, 11 (Primary: 1, 2, 10, 11; Secondary: 3, 4)\n\n**New Features**: Comprehensive business context, dual metrics slides, transformation impact comparison, complete operational coverage\n\n### Architecture Team (35 slides)\n\n**Target Audience**: Software Architects, Tech Leads, Senior Engineers\n\n**Focus**: Technical depth, design decisions, components, integrations, security\n\n**Presentation Time**: ~60 minutes\n\n**Slide Structure**:\n1. Title Slide\n2. Agenda\n3. **Section Divider** - Technical Overview\n4. Executive Summary - System purpose and overview\n5. **Metrics Slide** - Key Performance Metrics\n6. Business Context - Problem and solution summary\n7. **Section Divider** - Architecture Foundation\n8. Architecture Principles - Part 1 (first 5 principles)\n9. Architecture Principles - Part 2 (principles 6-10)\n10. **Comparison** - Design Drivers & Trade-offs\n11. Architecture Layers Overview\n12. **Explanation Visual** - Architecture Diagram\n13. **Section Divider** - Component Architecture\n14. Layer 1 Components - Presentation layer\n15. Layer 2 Components - Business logic layer\n16. Layer 3 Components - Integration layer\n17. Layer 4 Components - Data layer\n18. Layer 5-6 Components - Infrastructure & cross-cutting\n19. **Explanation Visual** - Component Dependencies\n20. **Section Divider** - Data & Integration\n21. **Process** - Data Flow Patterns (5-step workflow)\n22. **Explanation Visual** - Data Architecture\n23. API Strategy\n24. Integration Points - External systems\n25. **Comparison** - Integration Patterns (Sync/Async)\n26. API Catalog\n27. **Section Divider** - Technology & Security\n28. Technology Stack - Comprehensive overview\n29. **Explanation Visual** - Security Architecture\n30. Authentication & Authorization\n31. Data Protection\n32. **Section Divider** - Key Architecture Decisions\n33. ADRs Part 1 - First 5 decisions\n34. ADRs Part 2 - Decisions 6-10\n35. Summary & Q&A\n\n**Data Sources**: Sections 3, 4, 5, 6, 7, 8, 9, 12 (Primary: 3, 4, 5, 6, 7, 8, 9, 12; Secondary: 1, 2)\n\n**New Features**: Layer-by-layer component coverage, dual ADR slides, comprehensive data & integration section, security deep dive\n\n### Compliance/Governance (32 slides)\n\n**Target Audience**: Compliance Officers, Security Teams, Auditors\n\n**Focus**: Security controls, governance, compliance requirements, operational reliability\n\n**Presentation Time**: ~50 minutes\n\n**Slide Structure**:\n1. Title Slide\n2. Agenda\n3. **Section Divider** - Business Overview\n4. Executive Summary\n5. **Metrics Slide** - Compliance Metrics (availability, uptime, response time)\n6. Regulatory Context\n7. **Section Divider** - Security Architecture\n8. **Explanation Visual** - Security Overview & Layers\n9. **Comparison** - Security Controls Framework (Preventive vs Detective)\n10. Authentication & Authorization (9.1, 9.2)\n11. Access Control Matrix\n12. Data Protection (9.3)\n13. Network Security (9.4, 9.5)\n14. API Security\n15. Security Monitoring & Threat Detection (9.6)\n16. Compliance Standards (9.7)\n17. **Section Divider** - Integration Security\n18. Integration Points - External systems\n19. API Security Controls\n20. Secure Data Exchange\n21. **Section Divider** - Operational Compliance\n22. Monitoring & Audit Logging (11.1, 11.2)\n23. Alerting & Response\n24. **Process** - Incident Management workflow\n25. **Comparison** - Disaster Recovery (RPO/RTO)\n26. Change Management & Governance\n27. **Metrics Slide** - SLA Compliance\n28. **Section Divider** - Technology Governance\n29. Approved Technology Stack\n30. Technology Standards & Policies\n31. Compliance-Related ADRs (Section 12)\n32. Summary & Audit - Next steps and contact\n\n**Data Sources**: Sections 9, 11, 10, 1, 7, 8, 12 (Primary: 9, 11, 10; Secondary: 1, 7, 8, 12)\n\n**New Features**: 10 slides on security architecture (Section 9 comprehensive), preventive/detective controls comparison, operational compliance deep dive, technology governance\n\n## Slide Type Reference\n\nThe presentation generator supports **12 slide types** with the Dark Blue Professional Theme. Each type serves a specific purpose and follows a consistent visual design.\n\n### Color Palette\n\n**Dark Blue Professional Theme** (Version 1.6.0+):\n- **PRIMARY** (#0A1E3D): Deep navy blue - main backgrounds, headers\n- **SECONDARY** (#2E5C8A): Medium blue - secondary elements\n- **ACCENT** (#4A90E2): Bright blue - CTAs, highlights, metrics\n- **SURFACE** (#FFFFFF): White backgrounds for contrast\n- **MUTED** (#F5F7FA): Light blue-gray for cards and subtle backgrounds\n- **DARK_GRAY** (#374151): Body text color\n\n**Legacy Colors** (backward compatible):\n- **BLUE** ‚Üí Alias to PRIMARY\n- **GREEN** (#10B981): Highlights\n- **GRAY** (#6B7280): Secondary text\n\n### 1. Title Slide\n\n**Type**: `\"title\"`\n\n**Purpose**: Opening slide with presentation title and stakeholder info\n\n**Visual**: Full PRIMARY background (#0A1E3D) with white text\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 1,\n  \"type\": \"title\",\n  \"title_source\": \"system_name\",\n  \"subtitle_key\": \"title_suffix.business\"\n}\n```\n\n**Generated From**: System name from ARCHITECTURE.md + stakeholder type\n\n**Example**: \"E-Commerce Platform - Architecture Overview for Business Stakeholders\"\n\n---\n\n### 2. Agenda Slide\n\n**Type**: `\"agenda\"`\n\n**Purpose**: Table of contents for the presentation\n\n**Visual**: PRIMARY header bar with bullet list of agenda items\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 2,\n  \"type\": \"agenda\",\n  \"title_key\": \"slide_titles.agenda\",\n  \"items_key\": \"agenda_items.business\"\n}\n```\n\n**Generated From**: `language_{lang}.json` ‚Üí `agenda_items.{stakeholder}`\n\n**Bilingual**: Agenda items are fully translated\n\n---\n\n### 3. Content Slide\n\n**Type**: `\"content\"` (default)\n\n**Purpose**: Standard slide with header bar and bullet points\n\n**Visual**: PRIMARY header bar (15% height), bullet content below\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 3,\n  \"type\": \"content\",\n  \"title_key\": \"slide_titles.executive_summary\",\n  \"data_sources\": [\n    {\n      \"section\": 1,\n      \"subsection\": \"Key Metrics\",\n      \"extract_type\": \"bullets\"\n    }\n  ]\n}\n```\n\n**Data Sources**: Extracted from ARCHITECTURE.md sections\n\n**Best For**: Lists, feature descriptions, technical details\n\n---\n\n### 4. Section Divider Slide (NEW)\n\n**Type**: `\"section_divider\"`\n\n**Purpose**: Visual break between major sections\n\n**Visual**: Full PRIMARY background with ACCENT badge showing section number\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 2.5,\n  \"type\": \"section_divider\",\n  \"section_number\": \"01\",\n  \"title_key\": \"slide_titles.business_overview\"\n}\n```\n\n**Example**: Badge shows \"SECTION 01\" with title \"Business Overview\"\n\n**Best For**: Introducing new chapters, creating visual breaks\n\n**Stakeholders Using**: All (Business, Architecture, Compliance)\n\n---\n\n### 5. Single Focus Slide (NEW)\n\n**Type**: `\"single_focus\"`\n\n**Purpose**: Emphasize one key message or takeaway\n\n**Visual**: Minimal design with large centered text (36pt)\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 5.5,\n  \"type\": \"single_focus\",\n  \"title_key\": \"slide_titles.key_takeaway\",\n  \"data_sources\": [...]\n}\n```\n\n**Data Mapping**:\n- `content[0]` ‚Üí Main key message (large, bold)\n- `content[1]` ‚Üí Optional sub-message (smaller text)\n\n**Best For**: Key takeaways, mission statements, important announcements\n\n---\n\n### 6. Comparison Slide (NEW)\n\n**Type**: `\"comparison\"`\n\n**Purpose**: Side-by-side comparison of two concepts\n\n**Visual**: Two columns with colored headers (SECONDARY left, ACCENT right)\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 5.5,\n  \"type\": \"comparison\",\n  \"title_key\": \"slide_titles.architecture_comparison\",\n  \"left_title\": \"Current State\",\n  \"right_title\": \"Target State\",\n  \"data_sources\": [\n    {\n      \"section\": 4,\n      \"subsection\": \"Current vs Target\",\n      \"extract_type\": \"comparison\",\n      \"fallback\": {\n        \"left\": [\"Monolithic architecture\", \"Single database\", \"Manual deployment\"],\n        \"right\": [\"Microservices architecture\", \"Distributed data\", \"Automated CI/CD\"]\n      }\n    }\n  ]\n}\n```\n\n**Data Mapping**:\n- Content split at midpoint ‚Üí left/right columns\n- OR use `fallback.left` and `fallback.right` if no content\n\n**Best For**: Before/after scenarios, technology choices, preventive vs detective controls\n\n**Stakeholders Using**: Architecture (current vs target), Compliance (preventive vs detective)\n\n---\n\n### 7. Process/Timeline Slide (NEW)\n\n**Type**: `\"process\"`\n\n**Purpose**: Show sequential steps or workflow\n\n**Visual**: Horizontal flow with numbered circles (ACCENT) and arrows (‚Üí)\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 7.5,\n  \"type\": \"process\",\n  \"title_key\": \"slide_titles.deployment_process\",\n  \"data_sources\": [\n    {\n      \"section\": 11,\n      \"subsection\": \"Deployment Pipeline\",\n      \"extract_type\": \"process_steps\",\n      \"fallback_steps\": [\n        \"Code Commit & PR Review\",\n        \"Automated Testing\",\n        \"Security Scanning\",\n        \"Staging Deployment\",\n        \"Production Release\"\n      ]\n    }\n  ]\n}\n```\n\n**Supports**: 3-5 steps (optimal: 4-5)\n\n**Data Mapping**: Each array item becomes a numbered step\n\n**Best For**: Deployment pipelines, user journeys, development workflows\n\n**Stakeholders Using**: Architecture\n\n---\n\n### 8. Explanation + Visual Slide (NEW)\n\n**Type**: `\"explanation_visual\"`\n\n**Purpose**: Explain concept with diagram placeholder\n\n**Visual**: Split 50/50 - bullets (left), diagram placeholder (right)\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 9.5,\n  \"type\": \"explanation_visual\",\n  \"title_key\": \"slide_titles.data_architecture\",\n  \"visual_note\": \"[Add data flow diagram from Section 6]\",\n  \"data_sources\": [\n    {\n      \"section\": 6,\n      \"subsection\": \"Data Architecture\",\n      \"extract_type\": \"bullets\"\n    }\n  ]\n}\n```\n\n**Visual Placeholder**: Light gray box (MUTED) with italic note for diagram\n\n**Best For**: Complex architectures, data flows, system diagrams\n\n**Post-Processing**: Add Mermaid diagrams or screenshots manually in PowerPoint\n\n**Stakeholders Using**: Architecture\n\n---\n\n### 9. Metrics Slide (NEW)\n\n**Type**: `\"metrics\"`\n\n**Purpose**: Highlight 3 key performance metrics\n\n**Visual**: 3 cards with large ACCENT numbers (44pt) on MUTED backgrounds\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 6.5,\n  \"type\": \"metrics\",\n  \"title_key\": \"slide_titles.key_metrics\",\n  \"data_sources\": [\n    {\n      \"section\": 1,\n      \"subsection\": \"Key Metrics\",\n      \"extract_type\": \"metrics_table\",\n      \"metrics\": [\n        {\"field\": \"Concurrent Users\", \"label_key\": \"metrics.concurrent_users\"},\n        {\"field\": \"Availability\", \"label_key\": \"metrics.availability\"},\n        {\"field\": \"Response Time\", \"label_key\": \"metrics.response_time\"}\n      ]\n    }\n  ]\n}\n```\n\n**Data Mapping**:\n- Searches content for lines containing `field` value\n- Extracts value after `:` or `|` separator\n- Translates label from `label_key`\n\n**Example Output**:\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   10,000+   ‚îÇ  ‚îÇ    99.9%    ‚îÇ  ‚îÇ   <200ms    ‚îÇ\n‚îÇ  Concurrent ‚îÇ  ‚îÇ   System    ‚îÇ  ‚îÇAvg Response ‚îÇ\n‚îÇ    Users    ‚îÇ  ‚îÇAvailability ‚îÇ  ‚îÇ    Time     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Best For**: KPIs, performance metrics, success metrics\n\n**Stakeholders Using**: Business\n\n---\n\n### 10. Quote/Testimonial Slide (NEW)\n\n**Type**: `\"quote\"`\n\n**Purpose**: Feature a quote or customer testimonial\n\n**Visual**: Full PRIMARY background with large italic quote (28pt), ACCENT quotation marks (72pt)\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 8.5,\n  \"type\": \"quote\",\n  \"title_key\": \"slide_titles.testimonial\",\n  \"data_sources\": [\n    {\n      \"section\": 2,\n      \"subsection\": \"Success Stories\",\n      \"extract_type\": \"quote\",\n      \"fallback_quote\": \"This solution has transformed our business operations and significantly improved our efficiency.\",\n      \"fallback_attribution\": \"Business Stakeholder\"\n    }\n  ]\n}\n```\n\n**Data Mapping**:\n- `content[0]` ‚Üí Quote text\n- `content[1]` ‚Üí Attribution (optional)\n\n**Best For**: Customer testimonials, stakeholder endorsements, success stories\n\n**Stakeholders Using**: Business\n\n---\n\n### 11. Call to Action Slide (NEW)\n\n**Type**: `\"call_to_action\"`\n\n**Purpose**: Closing slide with contact information\n\n**Visual**: PRIMARY background with main message (40pt) and contact info, ACCENT bottom bar\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 10.5,\n  \"type\": \"call_to_action\",\n  \"title_key\": \"slide_titles.compliance_contact\",\n  \"data_sources\": [\n    {\n      \"section\": 1,\n      \"subsection\": \"Contacts\",\n      \"extract_type\": \"contact_info\",\n      \"fallback_message\": \"Questions?\",\n      \"fallback_contact\": [\n        \"Security Team: security@company.com\",\n        \"Compliance Officer: compliance@company.com\",\n        \"Documentation: docs.company.com/compliance\"\n      ]\n    }\n  ]\n}\n```\n\n**Data Mapping**:\n- `content[0]` ‚Üí Main CTA message\n- `content[1..]` ‚Üí Contact information (multi-line)\n\n**Best For**: Final slides, contact information, next steps\n\n**Stakeholders Using**: Compliance\n\n---\n\n### 12. Summary Slide\n\n**Type**: `\"summary\"`\n\n**Purpose**: Recap key points and Q&A\n\n**Visual**: Standard content slide with summary bullets\n\n**JSON Configuration**:\n```json\n{\n  \"id\": 10,\n  \"type\": \"summary\",\n  \"title_key\": \"slide_titles.summary\",\n  \"include_next_steps\": true\n}\n```\n\n**Best For**: Presentation conclusion, key takeaways, Q&A\n\n**Stakeholders Using**: All\n\n---\n\n## Slide Type Usage by Stakeholder\n\n### Business Stakeholders (30 slides)\n\n**Slide Type Breakdown**:\n- Content slides: 14\n- Section Dividers: 5\n- Metrics slides: 2\n- Single Focus slides: 2\n- Quote slides: 1\n- Comparison slides: 2\n- Process slides: 1\n- Explanation + Visual slides: 2\n- Call to Action: 1\n- Summary: 1 (with next steps)\n\n**Key Features**:\n- Dual metrics slides for KPIs and SLAs\n- Before/After transformation comparison\n- Complete operational support coverage (7 slides)\n- Architecture foundation overview (4 slides)\n\n**Total**: 30 slides covering business value, operations, and high-level architecture\n\n---\n\n### Architecture Team (35 slides)\n\n**Slide Type Breakdown**:\n- Content slides: 18\n- Section Dividers: 6\n- Metrics slides: 1\n- Comparison slides: 2\n- Process slides: 1\n- Explanation + Visual slides: 3\n- Summary: 1\n\n**Key Features**:\n- Component architecture by layer (7 slides total)\n- Data & integration deep dive (6 slides)\n- Dual ADR slides (Part 1 & 2)\n- Comprehensive security coverage\n- Technology stack details\n\n**Total**: 35 slides with deep technical coverage across all architecture aspects\n\n---\n\n### Compliance/Governance (32 slides)\n\n**Slide Type Breakdown**:\n- Content slides: 20\n- Section Dividers: 5\n- Metrics slides: 2\n- Comparison slides: 2\n- Process slides: 1\n- Explanation + Visual slides: 1\n- Summary: 1 (with contact info)\n\n**Key Features**:\n- 10 slides dedicated to Security Architecture (Section 9)\n- Preventive vs Detective controls comparison\n- Complete Section 9 subsection coverage (9.1-9.7)\n- Operational compliance with incident management workflow\n- Technology governance and standards\n\n**Total**: 32 slides focused on security, compliance, and governance\n\n---\n\n## Customizing Slide Templates\n\n### Adding a New Slide\n\n1. **Edit Template JSON** (e.g., `slide_templates_business.json`)\n\n2. **Add slide configuration** with decimal ID for insertion:\n\n```json\n{\n  \"id\": 6.5,\n  \"type\": \"metrics\",\n  \"title_key\": \"slide_titles.custom_metrics\",\n  \"data_sources\": [...]\n}\n```\n\n3. **Add translation** in `language_en.json` and `language_es.json`:\n\n```json\n{\n  \"slide_titles\": {\n    \"custom_metrics\": \"Custom Performance Metrics\"\n  }\n}\n```\n\n4. **Update slide_count** in template JSON:\n\n```json\n{\n  \"stakeholder_type\": \"business\",\n  \"slide_count\": 14,  // Increment by 1\n  ...\n}\n```\n\n5. **Regenerate presentation**\n\n### Supported Slide Types\n\n| Type | Purpose | Visual | Data Required |\n|------|---------|--------|---------------|\n| `title` | Opening slide | Full PRIMARY bg | System name |\n| `agenda` | Table of contents | Header + bullets | Agenda items |\n| `content` | Standard slide | Header + bullets | Section content |\n| `section_divider` | Section break | Full bg + badge | Section # + title |\n| `single_focus` | Key message | Large centered text | 1-2 lines |\n| `comparison` | Side-by-side | Two columns | Left/right content |\n| `process` | Sequential steps | Horizontal flow | 3-5 steps |\n| `explanation_visual` | Text + diagram | Split 50/50 | Bullets + note |\n| `metrics` | KPI dashboard | 3 metric cards | Field/value pairs |\n| `quote` | Testimonial | Full bg + quote | Quote + attribution |\n| `call_to_action` | Contact info | CTA + contacts | Message + contacts |\n| `summary` | Recap + Q&A | Header + bullets | Summary points |\n\n---\n\n## Language Support\n\n### Supported Languages\n\n- **English (EN)**: Default\n- **Spanish (ES)**: Espa√±ol\n\n### Translation Scope\n\n**What Gets Translated**:\n- ‚úÖ Slide titles\n- ‚úÖ Section headers\n- ‚úÖ Labels (Version, Status, Next Steps, etc.)\n- ‚úÖ UI elements (Agenda, Summary, Q&A)\n- ‚úÖ Standard messages\n\n**What Stays in Original Language**:\n- ‚ùå System names (extracted from ARCHITECTURE.md)\n- ‚ùå Component names\n- ‚ùå Technology names (Java, PostgreSQL, AWS, etc.)\n- ‚ùå Metric values\n- ‚ùå Code snippets\n- ‚ùå URLs\n\n### Example\n\n**Spanish Business Presentation**:\n- Slide title: \"Resumen Ejecutivo\" (translated)\n- Content: \"Read TPS: 500\" (kept as-is from ARCHITECTURE.md)\n- Label: \"Versi√≥n: 1.0\" (translated)\n\n## Customization\n\n### Modifying Slide Templates\n\nSlide templates are defined in JSON files:\n- `/presentation/slide_templates_business.json`\n- `/presentation/slide_templates_architecture.json`\n- `/presentation/slide_templates_compliance.json`\n\n**Example**: Add a new slide to Business template\n\n```json\n{\n  \"id\": 11,\n  \"type\": \"content\",\n  \"title_key\": \"slide_titles.custom_slide\",\n  \"data_sources\": [\n    {\n      \"section\": 8,\n      \"subsection\": \"Technology Stack\",\n      \"extract_type\": \"table\"\n    }\n  ]\n}\n```\n\nThen add translation to `language_en.json`:\n```json\n{\n  \"slide_titles\": {\n    \"custom_slide\": \"Technology Overview\"\n  }\n}\n```\n\n### Adding New Languages\n\n1. Create language JSON file: `/presentation/language_{code}.json`\n2. Copy structure from `language_en.json`\n3. Translate all strings\n4. Update `presentation-generator.ts` to support new language code\n\n### Customizing Colors\n\nColors are defined in `create_presentation.py`:\n```python\nBLUE = RGBColor(30, 58, 138)   # #1E3A8A\nGREEN = RGBColor(16, 185, 129)  # #10B981\nGRAY = RGBColor(107, 114, 128)  # #6B7280\n```\n\nTo customize, modify these constants or create new ones.\n\n### Adding Company Branding\n\n**After Generation**:\n1. Open generated .pptx in PowerPoint\n2. Add company logo to master slide\n3. Update color scheme if needed\n4. Modify footer with company information\n5. Save as template for future use\n\n## Troubleshooting\n\n### Error: ARCHITECTURE.md not found\n\n**Problem**: File doesn't exist at specified path\n\n**Solution**:\n```bash\n# Verify file exists\nls -la ARCHITECTURE.md\n\n# Check current directory\npwd\n\n# Provide full path\nbun run skills/architecture-docs/utils/presentation-generator.ts /full/path/to/ARCHITECTURE.md \\\n  --stakeholder business\n```\n\n### Warning: Document Index not found\n\n**Problem**: Document Index missing or incomplete\n\n**Solution**:\n1. Open ARCHITECTURE.md\n2. Verify Document Index exists at lines 1-50\n3. Should contain all 12 sections with line ranges\n4. Run Workflow 4 (Automatic Index Updates) if needed\n\n**Example Document Index**:\n```markdown\n## Document Index\n\n1. Executive Summary: Lines 25-87\n2. System Overview: Lines 88-201\n3. Architecture Principles: Lines 202-450\n...\n12. Architecture Decision Records: Lines 2601-2800\n```\n\n### Error: Missing sections\n\n**Problem**: Required sections not found in ARCHITECTURE.md\n\n**Solution**:\n1. Complete missing sections in ARCHITECTURE.md\n2. Ensure all 12 sections are present\n3. Update Document Index\n4. Regenerate presentation\n\n### Slides show \"[Not documented]\"\n\n**Problem**: Data not found in specified sections\n\n**Solution**:\n1. Check that subsections exist (e.g., \"Key Metrics\" in Section 1)\n2. Verify data is formatted correctly (bullets, tables)\n3. Complete missing subsections\n4. Regenerate presentation\n\n### ModuleNotFoundError: No module named 'pptx'\n\n**Problem**: python-pptx library not installed\n\n**Solution**:\n```bash\npip install python-pptx\n```\n\n### ImportError: cannot import name 'add_title_slide'\n\n**Problem**: create_presentation.py not found or path incorrect\n\n**Solution**:\n```bash\n# Verify create_presentation.py exists\nls -la /home/shadowx4fox/solutions-architect-skills/create_presentation.py\n\n# Run from correct directory\ncd /home/shadowx4fox/solutions-architect-skills\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md --stakeholder business\n```\n\n## Best Practices\n\n### Before Generating Presentations\n\n1. ‚úÖ Complete all 12 sections in ARCHITECTURE.md\n2. ‚úÖ Update Document Index (Workflow 4)\n3. ‚úÖ Verify metric consistency (Workflow 5)\n4. ‚úÖ Review content for accuracy\n5. ‚úÖ Ensure subsections exist (Key Metrics, Business Value, etc.)\n\n### After Generating Presentations\n\n1. ‚úÖ Review generated slides for accuracy\n2. ‚úÖ Verify data extraction is correct\n3. ‚úÖ Add company branding/logos\n4. ‚úÖ Customize content for specific audience\n5. ‚úÖ Test presentation before delivery\n\n### Regenerating Presentations\n\n**When to Regenerate**:\n- Architecture changes in ARCHITECTURE.md\n- New ADRs added\n- Metrics updated\n- Security controls modified\n- Technology stack changes\n\n**How to Regenerate**:\n```bash\n# Same command as initial generation\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md \\\n  --stakeholder business \\\n  --language en\n\n# Overwrites existing file\n# Backup old version if needed: mv presentation.pptx presentation_backup.pptx\n```\n\n### Versioning Presentations\n\n**Option 1: Date Suffix**\n```bash\nbun run skills/architecture-docs/utils/presentation-generator.ts ARCHITECTURE.md \\\n  --stakeholder business \\\n  --output /presentations/ARCHITECTURE_Business_EN_2025-12-21.pptx\n```\n\n**Option 2: Git Versioning**\n```bash\n# Commit presentations to version control\ngit add presentations/\ngit commit -m \"Update architecture presentations (v1.5)\"\ngit tag presentation-v1.5\n```\n\n## Examples\n\n### Example 1: Generate Business Presentation\n\n**Scenario**: Need to present system value to executives\n\n**Command**:\n```bash\nbun run skills/architecture-docs/utils/presentation-generator.ts ./ARCHITECTURE.md \\\n  --stakeholder business \\\n  --language en\n```\n\n**Output**:\n- File: `/presentations/ARCHITECTURE_Business_EN.pptx`\n- Slides: 10 slides focusing on business value, ROI, use cases\n- Duration: ~15 minutes\n\n### Example 2: Generate Spanish Compliance Presentation\n\n**Scenario**: Compliance review with Spanish-speaking auditors\n\n**Command**:\n```bash\nbun run skills/architecture-docs/utils/presentation-generator.ts ./ARCHITECTURE.md \\\n  --stakeholder compliance \\\n  --language es\n```\n\n**Output**:\n- File: `/presentations/ARCHITECTURE_Compliance_ES.pptx`\n- Slides: 11 slides with Spanish UI (content in original language)\n- Focus: Security, governance, operational standards\n\n### Example 3: Batch Generate All Presentations\n\n**Scenario**: Generate presentations for all stakeholders\n\n**Script**:\n```bash\n#!/bin/bash\n\nARCH_FILE=\"./ARCHITECTURE.md\"\n\n# Business (English)\nbun run skills/architecture-docs/utils/presentation-generator.ts $ARCH_FILE \\\n  --stakeholder business --language en\n\n# Architecture (English)\nbun run skills/architecture-docs/utils/presentation-generator.ts $ARCH_FILE \\\n  --stakeholder architecture --language en\n\n# Compliance (Spanish)\nbun run skills/architecture-docs/utils/presentation-generator.ts $ARCH_FILE \\\n  --stakeholder compliance --language es\n\necho \"All presentations generated successfully!\"\n```\n\n## FAQ\n\n### Q: Can I add more than 12 slides?\n\n**A**: Yes, modify the slide template JSON file to add more slides. Update the `slide_count` field and add new slide configurations to the `slides` array.\n\n### Q: Can I change the slide order?\n\n**A**: Yes, reorder slides in the template JSON file by changing the `id` field. Slides are generated in order of `id`.\n\n### Q: Can I use this with other architecture documentation formats?\n\n**A**: No, this tool is specifically designed for ARCHITECTURE.md files following the 12-section template. Other formats require code modifications.\n\n### Q: How do I add support for French/German/other languages?\n\n**A**: Create a new language_{code}.json file with translations, then modify `presentation-generator.ts` to accept the new language code in the validation.\n\n### Q: Can I generate PDF instead of PowerPoint?\n\n**A**: Not directly. Generate .pptx first, then convert to PDF using PowerPoint's \"Save As PDF\" feature or a conversion tool.\n\n### Q: What if my ARCHITECTURE.md is very large (5000+ lines)?\n\n**A**: No problem! The generator uses context-efficient loading and only loads relevant sections. Document size doesn't significantly impact generation time.\n\n### Q: Can I automate presentation generation in CI/CD?\n\n**A**: Yes! Add the command to your CI/CD pipeline:\n```yaml\n# .github/workflows/docs.yml\n- name: Generate Architecture Presentations\n  run: |\n    bun run skills/architecture-docs/utils/presentation-generator.ts ./docs/ARCHITECTURE.md \\\n      --stakeholder business --language en\n```\n\n### Q: How do I customize the corporate colors?\n\n**A**: Edit `/create_presentation.py` and modify the color constants (BLUE, GREEN, GRAY). Regenerate presentations to apply new colors.\n\n## Support\n\nFor issues, questions, or feature requests:\n\n1. Check this guide first\n2. Review Workflow 8 in SKILL.md\n3. Inspect slide template JSON files\n4. Verify ARCHITECTURE.md structure\n5. Report issues at: https://github.com/anthropics/claude-code/issues\n\n## Related Documentation\n\n- **Workflow 8**: Full workflow documentation in SKILL.md\n- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Template for ARCHITECTURE.md\n- **ADR_GUIDE.md**: Architectural Decision Records format\n- **language_en.json**: English translations reference\n- **language_es.json**: Spanish translations reference\n- **slide_templates_*.json**: Slide structure definitions\n\n---\n\n**Version**: 2.0\n**Plugin**: Solutions Architect Skills v1.6.0\n**Last Updated**: 2025-12-24\n",
        "skills/architecture-docs/templates/ARCHITECTURE_TYPE_SELECTOR.md": "# Architecture Type Selection Guide\n\nThis guide helps you choose the right architecture type for your ARCHITECTURE.md document. The architecture type determines the structure and content of **Section 4 (Architecture Layers)** and **Section 5 (Component Details)**.\n\n---\n\n## Quick Selection\n\n**Answer this question**: What best describes your system's architectural pattern?\n\n1. **Cloud-native system with independent services (RECOMMENDED)** ‚Üí Choose **Microservices Architecture**\n2. **Large enterprise system with complex integrations** ‚Üí Choose **META Architecture**\n3. **Standard web application with database** ‚Üí Choose **3-Tier Architecture**\n4. **Custom layered system with specific patterns** ‚Üí Choose **N-Layer Architecture**\n5. **Banking system requiring BIAN V12.0 certification** ‚Üí Choose **BIAN Architecture**\n\n---\n\n## Architecture Type Details\n\n### 1. Microservices Architecture (Recommended)\n\n**Best for:**\n- Cloud-native distributed systems\n- Independently deployable services\n- Systems requiring high scalability\n- Organizations with multiple autonomous teams\n- Event-driven architectures\n\n**Characteristics:**\n- Multiple independent services with clear boundaries\n- API Gateway for routing and orchestration\n- Service mesh for inter-service communication\n- Event-driven communication patterns\n- Decentralized data management (database per service)\n\n**Component Structure:**\n```\nAPI Gateway (Routing, Auth, Rate Limiting)\n‚îú‚îÄ‚îÄ Service A (Bounded Context A)\n‚îÇ   ‚îî‚îÄ‚îÄ Database A\n‚îú‚îÄ‚îÄ Service B (Bounded Context B)\n‚îÇ   ‚îî‚îÄ‚îÄ Database B\n‚îú‚îÄ‚îÄ Service C (Bounded Context C)\n‚îÇ   ‚îî‚îÄ‚îÄ Database C\n‚îî‚îÄ‚îÄ Shared Infrastructure\n    ‚îú‚îÄ‚îÄ Service Mesh\n    ‚îú‚îÄ‚îÄ Event Bus\n    ‚îî‚îÄ‚îÄ Configuration Service\n```\n\n**Use Microservices when:**\n- Building cloud-native applications\n- Need to scale services independently\n- Multiple teams working on different business capabilities\n- Requirement for polyglot technology stacks\n- High availability and fault isolation are critical\n\n**Section 4 Structure:** Service mesh topology and communication patterns\n**Section 5 Structure:** Service catalog with bounded contexts and APIs\n\n---\n\n### 2. META Architecture (6-Layer Enterprise)\n\n**Best for:**\n- Large enterprise systems\n- Financial services platforms\n- Complex integration landscapes\n- Systems with multiple channel types (web, mobile, API, batch)\n- Regulated industries requiring clear separation of concerns\n\n**Characteristics:**\n- 6 distinct layers: Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Business ‚Üí Domain ‚Üí Core\n- Clear separation between presentation, orchestration, business capabilities, and domain logic\n- Strong emphasis on business capability management and BIAN compliance\n- Designed for high complexity and regulatory compliance\n\n**Layer Structure:**\n```\nLayer 1: Channels (External Access Points)\nLayer 2: UX (User Experience)\nLayer 3: Business Scenarios (Orchestration)\nLayer 4: Business (Business Capabilities)\nLayer 5: Domain (BIAN Service Domains)\nLayer 6: Core (Legacy Systems)\n```\n\n**Use META when:**\n- Your system has 5+ external integrations\n- You need clear audit trails and regulatory compliance\n- Multiple teams will work on different layers\n- You're building an enterprise platform or core banking system\n\n**Section 4 Structure:** Detailed layer definitions with flow diagrams\n**Section 5 Structure:** Components mapped to layers with integration patterns\n\n---\n\n### 3. 3-Tier Architecture (Classic Web Application)\n\n**Best for:**\n- Web applications\n- REST APIs\n- Standard CRUD systems\n- Line-of-business applications\n- Systems with straightforward user interaction patterns\n\n**Characteristics:**\n- 3 classic tiers: Presentation ‚Üí Application/Business Logic ‚Üí Data\n- Simple, well-understood pattern\n- Clear separation of concerns without over-engineering\n- Suitable for monolithic or modular monolith deployments\n\n**Tier Structure:**\n```\nTier 1: Presentation Layer (UI, Web Controllers, API Endpoints)\nTier 2: Application/Business Logic Layer (Services, Business Rules)\nTier 3: Data Layer (Database, Data Access, Persistence)\n```\n\n**Use 3-Tier when:**\n- Building a web application or API\n- Team is familiar with traditional layered architecture\n- System complexity is low to moderate\n- You want simplicity and proven patterns\n\n**Section 4 Structure:** Tier descriptions with responsibility boundaries\n**Section 5 Structure:** Components organized by tier with data flow\n\n---\n\n### 4. N-Layer Architecture (Predefined Patterns)\n\n**Best for:**\n- Systems with custom layer requirements\n- Clean Architecture implementations\n- Hexagonal (Ports & Adapters) Architecture\n- Onion Architecture\n- Domain-Driven Design implementations\n\n**Characteristics:**\n- Flexible number of layers (typically 4-7)\n- Support for modern architectural patterns\n- Emphasis on dependency inversion and clean boundaries\n- Adaptable to specific domain needs\n\n**Predefined Patterns:**\n\n#### Option A: 4-Layer (Classic DDD)\n```\nLayer 1: Presentation (UI, API Controllers)\nLayer 2: Application (Use Cases, Application Services)\nLayer 3: Domain (Business Logic, Entities, Aggregates)\nLayer 4: Infrastructure (Database, External Services)\n```\n\n#### Option B: 5-Layer (Extended)\n```\nLayer 1: Presentation (UI, API)\nLayer 2: Application (Use Cases)\nLayer 3: Domain (Business Logic)\nLayer 4: Infrastructure (Persistence, External APIs)\nLayer 5: Cross-Cutting (Logging, Security, Caching)\n```\n\n#### Option C: Clean Architecture (Concentric Layers)\n```\nCore: Entities (Domain Models)\nLayer 1: Use Cases (Application Business Rules)\nLayer 2: Interface Adapters (Controllers, Presenters)\nLayer 3: Frameworks & Drivers (UI, Database, External)\n```\n\n**Use N-Layer when:**\n- Implementing Domain-Driven Design\n- Following Clean Architecture principles\n- Need testability and dependency inversion\n- Want flexibility in layer definitions\n- Building a system with complex domain logic\n\n**Section 4 Structure:** Custom layer definitions with dependency rules\n**Section 5 Structure:** Components organized by layer with domain boundaries\n\n---\n\n### 5. BIAN Architecture (5-Layer BIAN-Compliant)\n\n**Best for:**\n- Banking and financial services platforms\n- Systems requiring BIAN V12.0 certification\n- Full BIAN compliance requirements\n- Organizations adopting BIAN as enterprise standard\n- Systems needing complete BIAN hierarchy traceability\n\n**Characteristics:**\n- 5 distinct layers: Channels ‚Üí BIAN Business Scenarios ‚Üí BIAN Business Capabilities ‚Üí BIAN Service Domains ‚Üí Core Systems\n- Full BIAN V12.0 compliance across layers 2, 3, and 4\n- Complete BIAN hierarchy mapping (Business Areas ‚Üí Business Domains ‚Üí Service Domains)\n- All Layer 4 components must implement BIAN service domains from official BIAN V12.0 specification\n- Designed for BIAN certification and banking industry standards\n\n**Layer Structure:**\n```\nLayer 1: Channels (External Access Points)\n   ‚Üì Mobile, Web, ATM, Branch, API Gateway\n\nLayer 2: BIAN Business Scenarios (BIAN Business Areas - 5 areas)\n   ‚Üì Sales and Service, Reference Data, Operations and Execution, Risk and Compliance, Business Support\n\nLayer 3: BIAN Business Capabilities (BIAN Business Domains - 30+ domains)\n   ‚Üì Customer Management, Payments, Loans and Deposits, etc.\n\nLayer 4: BIAN Service Domains (BIAN V12.0 - 326+ atomic service domains)\n   ‚Üì Payment Order, Payment Execution, Current Account, Party Authentication, etc.\n\nLayer 5: Core Systems (Legacy/Core Banking)\n   ‚Üì Core Banking System, Mainframe, Transaction Processors, MDM\n```\n\n**BIAN Hierarchy Traceability:**\n- **BIAN Business Areas** (5) ‚Üí Layer 2: BIAN Business Scenarios\n- **BIAN Business Domains** (30+) ‚Üí Layer 3: BIAN Business Capabilities\n- **BIAN Service Domains** (326+) ‚Üí Layer 4: BIAN Service Domains\n\n**Use BIAN when:**\n- BIAN V12.0 certification is required\n- Full BIAN compliance is mandatory across all layers\n- Building a BIAN-first architecture\n- Organization has adopted BIAN as enterprise standard\n- Need complete BIAN hierarchy traceability (Business Areas ‚Üí Business Domains ‚Üí Service Domains)\n- Banking/financial services require industry-standard service domain model\n\n**Key Distinction from META:**\n- **BIAN**: 5 layers with full BIAN V12.0 across layers 2-4\n- **META**: 6 layers with BIAN only in layer 5\n- **BIAN**: All components mapped to BIAN hierarchy\n- **META**: BIAN alignment optional for domain services\n\n**Section 4 Structure:** 5-layer definitions with BIAN hierarchy mapping and compliance requirements\n**Section 5 Structure:** Components grouped by layers with full BIAN metadata (control records, service operations, behavior qualifiers)\n\n**Layer 4 Requirements (Critical):**\nAll Layer 4 Service Domains MUST include:\n- **Official BIAN Name**: Exact match with BIAN V12.0 landscape\n- **BIAN ID**: Internal tracking (SD-XXX format)\n- **BIAN Version**: V12.0 (mandatory)\n- **BIAN Business Domain**: Parent business domain\n- **BIAN Business Area**: Parent business area\n- **Control Record**: Structure per BIAN spec\n- **Service Operations**: Initiate, Update, Retrieve, Control (per BIAN)\n- **Behavior Qualifiers**: Per BIAN spec\n- **Functional Patterns**: Per BIAN spec\n- **Compliance Level**: Full (required for BIAN architecture)\n\n**Official Reference:** [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n\n---\n\n## Decision Tree\n\nUse this decision tree to quickly identify the best architecture type:\n\n```\nSTART\n‚îÇ\n‚îú‚îÄ Does your system require BIAN V12.0 certification?\n‚îÇ  ‚îî‚îÄ YES ‚Üí **BIAN Architecture**\n‚îÇ\n‚îú‚îÄ Is your system a distributed cloud-native application with independent services?\n‚îÇ  ‚îî‚îÄ YES ‚Üí **Microservices Architecture (Recommended)**\n‚îÇ\n‚îú‚îÄ Does your system have 5+ external integrations AND regulatory compliance requirements?\n‚îÇ  ‚îî‚îÄ YES ‚Üí **META Architecture**\n‚îÇ\n‚îú‚îÄ Are you implementing Domain-Driven Design or Clean Architecture?\n‚îÇ  ‚îî‚îÄ YES ‚Üí **N-Layer Architecture**\n‚îÇ\n‚îî‚îÄ Is your system a standard web application or API?\n   ‚îî‚îÄ YES ‚Üí **3-Tier Architecture**\n```\n\n---\n\n## Comparison Matrix\n\n| Criteria | Microservices* | META | 3-Tier | N-Layer | BIAN |\n|----------|----------------|------|--------|---------|------|\n| **Complexity** | High | Very High | Low | Medium-High | Very High |\n| **Team Size** | Large (10+) | Large (10+) | Small-Medium (2-8) | Medium (4-10) | Large (10+) |\n| **Deployment** | Distributed | Monolith or Modular | Monolith | Monolith or Modular | Distributed/Modular |\n| **Scalability** | Horizontal | Vertical | Vertical | Vertical | Horizontal/Vertical |\n| **Best For** | Cloud-native systems | Enterprise platforms | Web apps, APIs | DDD, Clean Arch | BIAN-certified banking |\n| **Learning Curve** | Steep | Steep | Gentle | Moderate | Very Steep |\n| **BIAN Compliance** | Not required | Layer 5 only | Not required | Not required | Full (Layers 2-4) |\n\n\\* Recommended for modern cloud-native applications\n\n---\n\n## How to Proceed\n\nOnce you've selected an architecture type:\n\n1. **Inform the skill** which type you selected (e.g., \"I'm using 3-Tier Architecture\")\n2. The skill will load the appropriate templates for Section 4 and Section 5\n3. Your ARCHITECTURE.md will include type-specific guidance and structure\n4. Validation rules will be applied according to your architecture type\n\n---\n\n## Changing Architecture Type Later\n\nIf you need to change the architecture type of an existing ARCHITECTURE.md:\n\n1. **Re-invoke the skill** and specify the new architecture type\n2. The skill will detect the change and update Sections 4 and 5\n3. **Manual review required**: Ensure component mappings align with the new structure\n4. **Update metadata comment**: The HTML comment tracking architecture type will be updated\n\n---\n\n## Questions?\n\nIf you're unsure which architecture type to choose:\n\n- Review the \"Best for\" descriptions above\n- Consider your team's expertise and familiarity\n- Evaluate system complexity and integration requirements\n- When in doubt, start with **Microservices** (recommended for modern systems), **3-Tier** (simplest), or **META** (most comprehensive for enterprises)",
        "skills/architecture-docs/templates/SECTION_4_3TIER.md": "# Section 4: Meta Architecture - 3-Tier Classic Web Application\n\n<!-- ARCHITECTURE_TYPE: 3-TIER -->\n\n**Purpose**: Define the three-tier architecture model that separates presentation, business logic, and data concerns.\n\nThis template follows the **3-Tier Architecture** pattern, designed for standard web applications, REST APIs, and line-of-business systems.\n\n---\n\n## Tiers Overview\n\n| Tier | Function |\n|------|----------|\n| **Presentation** | User interface layer handling all user interactions, including web pages, API endpoints, and client-side logic. |\n| **Application/Business Logic** | Core business logic, application services, orchestration, and business rules implementation. |\n| **Data** | Data persistence, database management, data access layer, and data integrity enforcement. |\n\n---\n\n## Tier Documentation Template\n\nFor each tier, document the following information:\n\n### Tier 1: Presentation Layer\n\n**Purpose**: [What this tier provides to users/clients]\n\n**Components**:\n- Web UI: [Frontend framework, pages, components]\n- API Controllers: [REST endpoints, GraphQL resolvers]\n- Client-Side Logic: [JavaScript/TypeScript logic, state management]\n\n**Technologies**:\n- Primary: [Main framework - React, Angular, Vue, ASP.NET MVC, etc.]\n- Supporting: [State management, routing, UI libraries]\n\n**Key Responsibilities**:\n- User input validation and sanitization\n- Request routing and dispatching\n- Response formatting (HTML, JSON, XML)\n- Session management\n- Client-side caching\n\n**Communication Patterns**:\n- Inbound: HTTP/HTTPS requests from browsers and API clients\n- Outbound: Service calls to Application tier\n- Protocols: [HTTP/REST, GraphQL, WebSockets]\n\n**Non-Functional Requirements**:\n- Performance: [Page load time, API response time]\n- Availability: [Uptime requirements]\n- Scalability: [Concurrent users, load balancing]\n\n---\n\n### Tier 2: Application/Business Logic Layer\n\n**Purpose**: [What this tier provides to the system]\n\n**Components**:\n- Application Services: [Service classes, business orchestration]\n- Business Rules Engine: [Rule execution, validation logic]\n- Workflow Management: [Process coordination]\n- Integration Services: [External API clients, adapters]\n\n**Technologies**:\n- Primary: [Main language/framework - Java/Spring, .NET, Node.js, Python, etc.]\n- Supporting: [DI containers, logging, caching]\n\n**Key Responsibilities**:\n- Business logic execution\n- Transaction management\n- Authorization and access control\n- Business rule enforcement\n- Service orchestration\n- Data transformation\n\n**Communication Patterns**:\n- Inbound: [From Presentation tier]\n- Outbound: [To Data tier, external services]\n- Protocols: [Internal method calls, HTTP for external services]\n\n**Non-Functional Requirements**:\n- Performance: [Service processing time, throughput]\n- Availability: [Failover, redundancy]\n- Scalability: [Horizontal scaling, stateless design]\n\n---\n\n### Tier 3: Data Layer\n\n**Purpose**: [What this tier provides to the system]\n\n**Components**:\n- Database Management System: [Relational DB, NoSQL, data warehouse]\n- Data Access Layer (DAL): [ORM, repositories, data mappers]\n- Cache Layer: [In-memory caching, distributed cache]\n- File Storage: [Document storage, blob storage]\n\n**Technologies**:\n- Primary: [Database - PostgreSQL, MySQL, SQL Server, MongoDB, etc.]\n- Supporting: [ORM framework, connection pooling, cache]\n\n**Key Responsibilities**:\n- Data persistence and retrieval\n- Data integrity and consistency\n- Query optimization\n- Backup and recovery\n- Database schema management\n\n**Communication Patterns**:\n- Inbound: [Database queries from Application tier]\n- Outbound: [None - terminal tier, or replication to other databases]\n- Protocols: [Database-specific protocols - TDS, PostgreSQL wire, etc.]\n\n**Non-Functional Requirements**:\n- Performance: [Query response time, transactions per second]\n- Availability: [Database clustering, failover]\n- Scalability: [Read replicas, sharding strategy]\n\n---\n\n## Data Flow\n\n**Typical Request Flow (Top-Down)**:\n\n```\n1. User interacts with Web UI or makes API call\n   ‚Üì\n2. Presentation Tier receives request\n   - Validates input\n   - Authenticates user\n   - Routes to appropriate controller/handler\n   ‚Üì\n3. Application Tier processes request\n   - Executes business logic\n   - Applies business rules\n   - Coordinates multiple operations if needed\n   ‚Üì\n4. Data Tier persists or retrieves data\n   - Executes database queries\n   - Manages transactions\n   - Returns data\n   ‚Üì\n5. Application Tier transforms data\n   - Maps domain models to DTOs\n   - Applies additional business rules\n   ‚Üì\n6. Presentation Tier formats response\n   - Converts to JSON/HTML\n   - Sends response to client\n```\n\n**Typical Response Flow (Bottom-Up)**:\n\n```\nData ‚Üí Application ‚Üí Presentation ‚Üí User\n```\n\n---\n\n## Example Implementation\n\n### Tier 1: Presentation Layer\n\n**Purpose**: Provide a responsive web interface and RESTful API for customer account management.\n\n**Components**:\n- Web UI: React-based single-page application (SPA)\n- API Controllers: Express.js REST endpoints\n- Client-Side Logic: Redux state management, form validation\n\n**Technologies**:\n- Primary: React 18, TypeScript, Express.js 4.x\n- Supporting: Redux Toolkit, React Router, Axios, Material-UI\n\n**Key Responsibilities**:\n- User authentication via JWT tokens\n- Form validation and user input sanitization\n- API request/response handling\n- Client-side routing\n- Session storage management\n\n**Communication Patterns**:\n- Inbound: HTTPS requests from web browsers and mobile apps\n- Outbound: REST API calls to Application tier (Node.js services)\n- Protocols: HTTPS/REST, JSON payload format\n\n**Non-Functional Requirements**:\n- Performance: <2s initial page load, <500ms API responses\n- Availability: 99.9% uptime (8.76 hours/year downtime)\n- Scalability: Load-balanced across 3+ instances, CDN for static assets\n\n---\n\n### Tier 2: Application/Business Logic Layer\n\n**Purpose**: Execute core business logic for account operations and transaction processing.\n\n**Components**:\n- Application Services: Account Service, Transaction Service, Notification Service\n- Business Rules Engine: Account validation, transaction limits, fraud detection\n- Integration Services: Payment gateway client, email service adapter\n\n**Technologies**:\n- Primary: Node.js 18 LTS, TypeScript, NestJS framework\n- Supporting: TypeORM, Bull (job queue), Winston (logging), Redis (caching)\n\n**Key Responsibilities**:\n- Account balance calculations\n- Transaction authorization and processing\n- Business rule execution (minimum balance, daily limits)\n- RBAC (Role-Based Access Control) enforcement\n- Async notification dispatching\n\n**Communication Patterns**:\n- Inbound: HTTP/REST from Presentation tier\n- Outbound: Database queries via TypeORM, HTTP calls to payment gateway\n- Protocols: HTTP/REST, database connection pooling\n\n**Non-Functional Requirements**:\n- Performance: <300ms avg service response time, 500 TPS throughput\n- Availability: 99.95% uptime, auto-recovery on failure\n- Scalability: Stateless design, horizontal scaling with Kubernetes\n\n---\n\n### Tier 3: Data Layer\n\n**Purpose**: Persist customer accounts, transactions, and audit logs with ACID guarantees.\n\n**Components**:\n- Database Management System: PostgreSQL 15\n- Data Access Layer: TypeORM with repository pattern\n- Cache Layer: Redis for session and query caching\n- File Storage: AWS S3 for document uploads\n\n**Technologies**:\n- Primary: PostgreSQL 15 (primary), PostgreSQL read replicas (2x)\n- Supporting: TypeORM, Redis 7, pgBouncer (connection pooling)\n\n**Key Responsibilities**:\n- ACID transaction management\n- Data integrity enforcement via constraints\n- Audit trail logging for compliance\n- Automated backups (daily full, hourly incremental)\n\n**Communication Patterns**:\n- Inbound: SQL queries via TypeORM from Application tier\n- Outbound: Replication to read replicas, backups to S3\n- Protocols: PostgreSQL wire protocol, TLS encryption\n\n**Non-Functional Requirements**:\n- Performance: <50ms query response time (95th percentile), 1000 TPS\n- Availability: 99.99% uptime, automatic failover to standby\n- Scalability: Read replicas for query offloading, table partitioning for large tables\n\n---\n\n## Architecture Diagram (Mermaid)\n\nThis section provides a visual representation of the 3-tier architecture using Mermaid diagrams.\n\n**Purpose**: Visualize the tier structure, component placement, and data flow between tiers.\n\n### 3-Tier Architecture Diagram Example\n\nThe following diagram shows a typical 3-tier web application architecture:\n\n````markdown\n```mermaid\ngraph TB\n    %% Tier 1: Presentation Layer\n    subgraph Tier1[\"Tier 1: Presentation Layer\"]\n        WebApp[\"Web Application<br/>(React SPA)\"]\n        MobileApp[\"Mobile App<br/>(React Native)\"]\n        APIClient[\"API Client\"]\n    end\n\n    %% Tier 2: Application/Business Logic Layer\n    subgraph Tier2[\"Tier 2: Application/Business Logic<br/>(Stateless Services)\"]\n        APIGateway[\"API Gateway<br/>(Kong)\"]\n        AuthService[\"Authentication Service<br/>JWT Token Management\"]\n        UserService[\"User Service<br/>User Management\"]\n        OrderService[\"Order Service<br/>Order Processing\"]\n        PaymentService[\"Payment Service<br/>Payment Processing\"]\n    end\n\n    %% Tier 3: Data Layer\n    subgraph Tier3[\"Tier 3: Data Layer\"]\n        PrimaryDB[\"Primary Database<br/>(PostgreSQL)<br/>Read/Write\"]\n        ReadReplica[\"Read Replica<br/>(PostgreSQL)<br/>Read-Only\"]\n        Cache[\"Cache Layer<br/>(Redis)<br/>Session & Data Cache\"]\n    end\n\n    %% Data Flows - Tier 1 to Tier 2\n    WebApp -->|HTTPS/REST<br/>OAuth 2.0 + JWT| APIGateway\n    MobileApp -->|HTTPS/REST<br/>OAuth 2.0 + JWT| APIGateway\n    APIClient -->|HTTPS/REST<br/>API Key| APIGateway\n\n    %% Data Flows - Within Tier 2\n    APIGateway -->|HTTP<br/>Route & Auth| AuthService\n    APIGateway -->|HTTP<br/>Route & Auth| UserService\n    APIGateway -->|HTTP<br/>Route & Auth| OrderService\n    APIGateway -->|HTTP<br/>Route & Auth| PaymentService\n\n    %% Data Flows - Tier 2 to Tier 3 (Writes)\n    AuthService -->|SQL<br/>Connection Pool<br/>Write Operations| PrimaryDB\n    UserService -->|SQL<br/>Connection Pool<br/>Write Operations| PrimaryDB\n    OrderService -->|SQL<br/>Connection Pool<br/>Write Operations| PrimaryDB\n    PaymentService -->|SQL<br/>Connection Pool<br/>Write Operations| PrimaryDB\n\n    %% Data Flows - Tier 2 to Tier 3 (Reads)\n    AuthService -.->|SQL<br/>Read Operations| ReadReplica\n    UserService -.->|SQL<br/>Read Operations| ReadReplica\n    OrderService -.->|SQL<br/>Read Operations| ReadReplica\n    PaymentService -.->|SQL<br/>Read Operations| ReadReplica\n\n    %% Data Flows - Tier 2 to Cache\n    AuthService -.->|Redis Protocol<br/>Session Cache| Cache\n    UserService -.->|Redis Protocol<br/>User Data Cache| Cache\n    OrderService -.->|Redis Protocol<br/>Query Cache| Cache\n\n    %% Database Replication\n    PrimaryDB -.->|Async Replication| ReadReplica\n\n    %% Styling\n    classDef presentation fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n    classDef application fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\n    classDef data fill:#7ED321,stroke:#5A9B18,stroke-width:2px,color:#fff\n    classDef cache fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\n    classDef gateway fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n\n    class WebApp,MobileApp,APIClient presentation\n    class AuthService,UserService,OrderService,PaymentService application\n    class PrimaryDB,ReadReplica data\n    class Cache cache\n    class APIGateway gateway\n```\n````\n\n### Legend\n\n**Arrow Types**:\n- **Solid arrows (`-->`)**: Synchronous calls (HTTPS/REST, SQL writes)\n- **Dashed arrows (`-.->`)**: Read operations or asynchronous updates (SQL reads, cache, replication)\n\n**Colors**:\n- **Blue**: Presentation layer (web, mobile, API clients)\n- **Orange**: Application/Business logic services\n- **Green**: Data layer (databases)\n- **Purple**: Cache layer (Redis)\n- **Gray**: Infrastructure (API Gateway, load balancers)\n\n**Data Flow Patterns**:\n- **Tier 1 ‚Üí Tier 2**: HTTPS/REST with OAuth 2.0 authentication\n- **Tier 2 ‚Üí Tier 3 (Writes)**: SQL connection pool to primary database\n- **Tier 2 ‚Üí Tier 3 (Reads)**: SQL queries to read replicas for query offloading\n- **Tier 2 ‚Üî Cache**: Redis protocol for session and data caching\n- **Database Replication**: Asynchronous replication from primary to read replicas\n\n### Customization Instructions\n\nTo customize this diagram for your specific architecture:\n\n1. **Update Tier 1 Components**: Replace example clients with your actual front-end applications\n2. **Update Tier 2 Services**: Modify business logic services based on your domain (e.g., Inventory, Shipping, Notification)\n3. **Update Tier 3 Technologies**: Replace PostgreSQL/Redis with your actual database technologies\n4. **Update Protocols**: Modify data flow labels with your actual protocols and security mechanisms\n5. **Adjust Colors**: Modify the `classDef` styling to match your organization's standards\n\n**For detailed diagram creation and update instructions**, see [MERMAID_DIAGRAMS_GUIDE.md](../MERMAID_DIAGRAMS_GUIDE.md).\n\n---\n\n## Guidelines\n\n1. **All 3 tiers are required** in 3-Tier architecture\n2. **Document tiers in order**: Presentation ‚Üí Application/Business Logic ‚Üí Data\n3. **Each tier must include all subsections**: Purpose, Components, Technologies, Key Responsibilities, Communication Patterns, Non-Functional Requirements\n4. **Separation of concerns**: Strictly separate UI logic, business logic, and data access\n5. **Stateless middle tier**: Application tier should be stateless to enable horizontal scaling\n6. **Data tier isolation**: Only Application tier should communicate with Data tier (no direct database access from Presentation)\n\n---\n\n## Validation Checklist\n\n- [ ] All 3 tiers documented (Presentation, Application/Business Logic, Data)\n- [ ] Each tier has all required subsections\n- [ ] Communication patterns clearly define tier boundaries\n- [ ] Technologies specified for each tier\n- [ ] Non-functional requirements quantified (not just placeholders)\n- [ ] Architecture diagram included showing tier interactions (Mermaid format recommended, see MERMAID_DIAGRAMS_GUIDE.md)\n- [ ] Separation of concerns maintained (no direct DB access from Presentation)\n- [ ] Stateless design for Application tier documented",
        "skills/architecture-docs/templates/SECTION_4_BIAN.md": "# Section 4: Meta Architecture - BIAN 5-Layer Architecture\n\n<!-- ARCHITECTURE_TYPE: BIAN -->\n\n**Purpose**: Define the BIAN-compliant layered architecture model that organizes system components according to BIAN V12.0 business hierarchy and banking industry standards.\n\nThis template follows the **BIAN 5-Layer Architecture** pattern, designed for banking and financial services systems requiring full BIAN V12.0 certification and compliance across all architectural layers.\n\n**BIAN Standard**: This template uses **BIAN V12.0** as the mandatory standard across Layers 2, 3, and 4. See the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) for official service domain definitions.\n\n**Key Distinction from META Architecture**: BIAN architecture implements full BIAN V12.0 compliance across three layers (Business Scenarios, Business Capabilities, and Service Domains), whereas META architecture applies BIAN only to Layer 5 (Domain). BIAN architecture is optimized for BIAN certification and complete traceability through the BIAN business hierarchy.\n\n---\n\n## Layers Overview\n\n| Layer | Function | BIAN V12.0 Mapping |\n|-------|----------|-------------------|\n| **Layer 1: Channels** | User interaction points across all channels (web, mobile, ATM, branch, API). | Channel implementation patterns |\n| **Layer 2: BIAN Business Scenarios** | Business process orchestration and scenario management. | BIAN Business Areas (5 areas) |\n| **Layer 3: BIAN Business Capabilities** | Business capability management and coordination. | BIAN Business Domains (30+ domains) |\n| **Layer 4: BIAN Service Domains** | Atomic banking services following BIAN V12.0 service domain model. | BIAN Service Domains (326+ domains) |\n| **Layer 5: Core Systems** | Legacy and core banking systems providing foundational services. | System of record |\n\n**BIAN Hierarchy Traceability**:\n- **BIAN Business Areas** (5 areas) ‚Üí Implemented in Layer 2: BIAN Business Scenarios\n- **BIAN Business Domains** (30+ domains) ‚Üí Implemented in Layer 3: BIAN Business Capabilities\n- **BIAN Service Domains** (326+ domains) ‚Üí Implemented in Layer 4: BIAN Service Domains\n\n---\n\n## Layer Documentation Template\n\nFor each layer, document the following information:\n\n### Layer 1: Channels\n\n**Purpose**: Manage user interaction across all banking channels (web, mobile, ATM, branch, API gateway)\n\n**Components**:\n- Component 1: [Name and brief description - e.g., Mobile Banking App]\n- Component 2: [Name and brief description - e.g., Internet Banking Portal]\n- Component 3: [Name and brief description - e.g., ATM Network Interface]\n- Component 4: [Name and brief description - e.g., Branch Terminal System]\n\n**Technologies**:\n- Primary: [Main technology stack - e.g., React Native, Angular, Java]\n- Supporting: [Additional technologies, frameworks - e.g., OAuth 2.0, Firebase]\n\n**Key Responsibilities**:\n- Provide omnichannel access to banking services\n- Manage channel-specific user authentication\n- Adapt user experience to channel capabilities\n- Handle channel-specific security requirements\n- Orchestrate multi-channel user journeys\n- Manage session state across channels\n\n**Communication Patterns**:\n- Inbound: [How users interact with channels - HTTPS, mobile protocols]\n- Outbound: [How channels communicate with Layer 2 - REST, GraphQL]\n- Protocols: [HTTPS/REST, OAuth 2.0, WebSockets, etc.]\n\n**Non-Functional Requirements**:\n- Performance: [Latency, throughput requirements - e.g., <500ms response time]\n- Availability: [SLA, uptime requirements - e.g., 99.95% uptime]\n- Scalability: [How this layer scales - e.g., auto-scaling to 100K concurrent users]\n\n---\n\n### Layer 2: BIAN Business Scenarios\n\n**Purpose**: Orchestrate transversal business processes and scenarios aligned with BIAN Business Areas\n\n**BIAN V12.0 Alignment**: This layer maps business scenarios to the 5 BIAN Business Areas defined in [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html):\n1. **Sales and Service** - Customer-facing scenarios (onboarding, sales, servicing)\n2. **Reference Data** - Data management scenarios (party, product, market data)\n3. **Operations and Execution** - Transaction execution scenarios (payments, settlements)\n4. **Risk and Compliance** - Risk management and regulatory scenarios\n5. **Business Support** - Internal operational scenarios (reporting, analytics)\n\n**Components**:\n- Business Scenario Orchestrator: [Description - e.g., Workflow engine coordinating BIAN Business Areas]\n- Process Management: [Description - e.g., BPMN engine for scenario flows]\n- Business Rules Engine: [Description - e.g., Rules engine for scenario logic]\n\n**Technologies**:\n- Primary: [Workflow/orchestration technology - e.g., Camunda, Apache Airflow]\n- Supporting: [Rules engine, process automation - e.g., Drools, custom]\n\n**Key Responsibilities**:\n- Orchestrate end-to-end business scenarios across BIAN Business Areas\n- Coordinate business capabilities (Layer 3) to fulfill scenarios\n- Implement cross-domain business process flows\n- Apply business rules and policies at scenario level\n- Manage scenario state and lifecycle\n- Ensure regulatory compliance for business scenarios\n\n**BIAN Business Area Mapping**:\nDocument which BIAN Business Areas are implemented in this layer:\n\n| Business Scenario | BIAN Business Area | BIAN Business Domains (Layer 3) | Description |\n|-------------------|-------------------|--------------------------------|-------------|\n| [Scenario Name] | [Sales and Service / Reference Data / Operations and Execution / Risk and Compliance / Business Support] | [List of Business Domains involved] | [What this scenario orchestrates] |\n\n**Communication Patterns**:\n- Inbound: [From Layer 1 Channels - REST, GraphQL]\n- Outbound: [To Layer 3 BIAN Business Capabilities - REST, events]\n- Protocols: [Synchronous: REST, gRPC; Asynchronous: Kafka, message queues]\n\n**Non-Functional Requirements**:\n- Performance: [Process execution time - e.g., <2 seconds for scenario orchestration]\n- Availability: [Business continuity requirements - e.g., 99.9% uptime]\n- Scalability: [Process volume handling - e.g., 10K concurrent scenarios]\n\n---\n\n### Layer 3: BIAN Business Capabilities\n\n**Purpose**: Implement business capabilities aligned with BIAN Business Domains\n\n**BIAN V12.0 Alignment**: This layer implements the 30+ BIAN Business Domains defined in [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html). Each business domain groups related BIAN Service Domains (Layer 4).\n\n**BIAN Business Domains** (examples - see [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) for complete list):\n- **Customer Management**: Party, customer relationship, customer portfolio\n- **Product Management**: Product directory, product design, product deployment\n- **Channel Management**: Channel activity analysis, servicing mandate\n- **Payments**: Payment order, payment execution, payment initiation\n- **Loans and Deposits**: Consumer loan, current account, savings account\n- **Risk Management**: Market risk, credit risk, operational risk\n- **Compliance**: Regulatory compliance, fraud detection\n- [Additional business domains as applicable]\n\n**Components**:\n- Business Capability Services: [Description - e.g., Services implementing BIAN Business Domains]\n- Business API Layer: [Description - e.g., API facade for business capabilities]\n- Business Domain Coordinator: [Description - e.g., Coordinates service domains within a business domain]\n\n**Technologies**:\n- Primary: [Business services platform - e.g., Spring Boot, Node.js]\n- Supporting: [API management, orchestration - e.g., Kong, Apigee]\n\n**Key Responsibilities**:\n- Implement BIAN Business Domain logic\n- Coordinate BIAN Service Domains (Layer 4) within each business domain\n- Expose business capabilities through standardized APIs\n- Manage business domain state and lifecycle\n- Enforce business domain policies and rules\n- Ensure cross-domain consistency\n\n**BIAN Business Domain Mapping**:\nDocument which BIAN Business Domains are implemented in this layer:\n\n| BIAN Business Domain | BIAN Business Area (Layer 2) | BIAN Service Domains (Layer 4) | Responsibilities |\n|---------------------|------------------------------|-------------------------------|------------------|\n| [Domain Name] | [Parent Business Area] | [List of Service Domains in this domain] | [What this capability manages] |\n\n**Communication Patterns**:\n- Inbound: [From Layer 2 Business Scenarios - REST, events]\n- Outbound: [To Layer 4 BIAN Service Domains - REST, gRPC, events]\n- Protocols: [REST, gRPC, domain events, Kafka]\n\n**Non-Functional Requirements**:\n- Performance: [Capability response time - e.g., <300ms for API calls]\n- Availability: [Business domain availability - e.g., 99.95% uptime]\n- Scalability: [Domain-specific scaling - e.g., horizontal scaling by business domain]\n\n---\n\n### Layer 4: BIAN Service Domains\n\n**Purpose**: Implement atomic banking services as defined by BIAN V12.0 Service Domain model\n\n**BIAN V12.0 Alignment**: This layer implements the 326+ BIAN Service Domains from the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html). Each service domain is an atomic, independently deployable banking service.\n\n**CRITICAL**: All service domains in this layer MUST be validated against the official [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) to ensure accurate naming and compliance.\n\n**Service Domain Documentation Template**:\n\nFor each BIAN Service Domain, document the following:\n\n#### BIAN Service Domain: [Official BIAN Service Domain Name]\n\n**BIAN Metadata** (MANDATORY):\n- **Official BIAN Name**: [Exact name from BIAN V12.0 Service Landscape - e.g., \"Payment Order\", \"Current Account\"]\n- **BIAN ID**: [Internal tracking ID - e.g., SD-001 for document tracking only]\n- **BIAN Version**: V12.0 (mandatory)\n- **BIAN Business Domain**: [Parent business domain - e.g., \"Payments\", \"Loans and Deposits\"]\n- **BIAN Business Area**: [Parent business area - e.g., \"Operations and Execution\"]\n- **BIAN Service Landscape URL**: [Direct link to service domain in BIAN V12.0 landscape]\n\n**Control Record** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Control Record Type**: [As defined in BIAN spec - e.g., \"PaymentOrderProcedure\"]\n- **Structure**: [Document control record structure per BIAN specification]\n- **Lifecycle**: [Active, completed, suspended states per BIAN]\n\n**Service Operations** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\nDocument the standard BIAN service operations for this domain:\n- **Initiate**: [Create new control record - description of initiate operation]\n- **Update**: [Modify existing control record - description of update operation]\n- **Retrieve**: [Query control record - description of retrieve operation]\n- **Control**: [Manage control record lifecycle - description of control operation]\n- **Exchange**: [If applicable - exchange operation description]\n- **Execute**: [If applicable - execute operation description]\n- **Request**: [If applicable - request operation description]\n\n**Behavior Qualifiers** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- [List behavior qualifiers as defined in BIAN spec for this service domain]\n- [Example: \"registration\", \"valuation\", \"compliance\" for specific domains]\n\n**Functional Patterns** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Pattern Type**: [Managed Object, Tracked Object, Administered Object, Governed Object, etc.]\n- **Pattern Description**: [How this service domain follows the BIAN functional pattern]\n\n**Implementation Details**:\n- **Technology Stack**: [Primary language/framework - e.g., Java/Spring Boot, Node.js]\n- **Database**: [Data store - e.g., PostgreSQL, MongoDB]\n- **API Endpoints**: [List key endpoints following BIAN service operations]\n  - `POST /service-domain/initiate`: Initiate service domain\n  - `PUT /service-domain/{id}/update`: Update control record\n  - `GET /service-domain/{id}/retrieve`: Retrieve control record\n  - `PUT /service-domain/{id}/control`: Control lifecycle\n\n**Data Ownership**:\n- [What data this service domain owns - aligned with BIAN control record]\n\n**Dependencies**:\n- **Upstream Service Domains**: [BIAN Service Domains this domain depends on]\n- **Downstream Service Domains**: [BIAN Service Domains that depend on this domain]\n\n**Events Published** (if event-driven):\n- `[service-domain].[event-name]`: [When and what data - e.g., \"payment-order.initiated\"]\n\n**Events Consumed** (if event-driven):\n- `[other-domain].[event-name]`: [From which service domain, what action taken]\n\n**Non-Functional Requirements**:\n- Performance: [Service response time - e.g., <200ms p95]\n- Availability: [Service SLA - e.g., 99.99% uptime]\n- Scalability: [Scaling strategy - e.g., horizontal scaling 2-10 instances]\n\n**BIAN Compliance Level**:\n- **Level**: Full BIAN V12.0 Compliance (required for BIAN architecture type)\n- **Validation Date**: [When compliance was validated]\n- **Deviations**: [None for full compliance, or document any customizations]\n\n---\n\n**Technologies** (Layer 4 Overview):\n- Primary: [Microservices framework - e.g., Spring Boot, Node.js]\n- Supporting: [Databases, caching, messaging - e.g., PostgreSQL, Redis, Kafka]\n\n**Key Responsibilities** (Layer 4 Overview):\n- Implement BIAN Service Domain functional patterns\n- Maintain BIAN control records per specification\n- Expose BIAN service operations (Initiate, Update, Retrieve, Control, etc.)\n- Ensure BIAN behavior qualifier implementation\n- Manage service domain lifecycle per BIAN standards\n- Publish domain events for state changes\n\n**Communication Patterns**:\n- Inbound: [From Layer 3 BIAN Business Capabilities - REST, gRPC]\n- Outbound: [To Layer 5 Core Systems - REST, legacy protocols, events]\n- Protocols: [REST, gRPC, Kafka, legacy protocols as needed]\n\n**BIAN Service Domain Catalog**:\n\n| BIAN Service Domain | BIAN ID | BIAN Business Domain | BIAN Business Area | Technology | Team Owner |\n|--------------------|---------|---------------------|-------------------|------------|------------|\n| [Official BIAN Name] | SD-001 | [Business Domain] | [Business Area] | [Tech Stack] | [Team] |\n| [Official BIAN Name] | SD-002 | [Business Domain] | [Business Area] | [Tech Stack] | [Team] |\n| [Official BIAN Name] | SD-003 | [Business Domain] | [Business Area] | [Tech Stack] | [Team] |\n\n**Implementation Guidance**:\n1. Validate all service domain names against the official [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n2. Assign internal BIAN IDs (SD-XXX format) for document tracking only\n3. Implement all mandatory BIAN service operations for each service domain\n4. Document control records per BIAN specification\n5. Implement behavior qualifiers as defined in BIAN V12.0\n6. Follow BIAN functional patterns (Managed Object, Tracked Object, etc.)\n7. Ensure full traceability: Service Domain ‚Üí Business Domain ‚Üí Business Area\n\n---\n\n### Layer 5: Core Systems\n\n**Purpose**: Provide foundational banking services through legacy and core banking systems\n\n**Systems**:\n- Core Banking System: [Name, vendor, version - e.g., Finacle 10.x, Temenos T24]\n- Transaction Processing System: [Name, description]\n- Legacy Mainframe: [System name, purpose]\n- Master Data Management: [System for customer, product, reference data]\n\n**Technologies**:\n- Primary: [Core banking platform, mainframe - e.g., IBM z/OS, Oracle Database]\n- Supporting: [Databases, interfaces, adapters - e.g., DB2, MQ, ESB]\n\n**Key Responsibilities**:\n- Provide system of record for core banking data\n- Process critical banking transactions\n- Maintain account balances and ledgers\n- Ensure regulatory compliance and audit trails\n- Support BIAN Service Domains (Layer 4) with foundational services\n- Manage master data for customers, products, accounts\n\n**Communication Patterns**:\n- Inbound: [From Layer 4 BIAN Service Domains - REST APIs, legacy protocols]\n- Outbound: [Data replication, events, batch files]\n- Protocols: [Legacy protocols (MQ, file transfer), REST APIs, SOAP, database replication]\n\n**BIAN Integration Strategy**:\n- **Adapter Pattern**: [How core systems are wrapped to support BIAN Service Domains]\n- **Data Synchronization**: [How core data is synchronized with BIAN service domains]\n- **Transaction Coordination**: [How distributed transactions are managed]\n- **Event Publishing**: [How core system events are published to BIAN layers]\n\n**Modernization Strategy**:\n- Current State: [Assessment of legacy systems and technical debt]\n- Target State: [Modernization goals aligned with BIAN architecture]\n- Migration Approach: [Strangler pattern, lift-and-shift, progressive modernization]\n- BIAN Alignment: [How modernization supports BIAN compliance]\n- Gradual Evolution: [Phased approach to minimize business disruption]\n\n**Non-Functional Requirements**:\n- Performance: [Transaction processing rate - e.g., 10K TPS]\n- Availability: [24/7 uptime requirements - e.g., 99.99% availability]\n- Scalability: [Capacity planning - e.g., vertical scaling for mainframe]\n- Resilience: [Disaster recovery, backup strategy - e.g., RPO <15 min, RTO <1 hour]\n\n---\n\n## Example Implementation\n\n### Layer 1: Channels - Mobile Banking App\n\n**Purpose**: Provide retail customers with mobile access to banking services on iOS and Android.\n\n**Components**:\n- Mobile Banking App (iOS): Native iOS app using Swift\n- Mobile Banking App (Android): Native Android app using Kotlin\n- Mobile BFF (Backend for Frontend): Node.js API tailored for mobile clients\n\n**Technologies**:\n- Primary: Swift (iOS), Kotlin (Android), Node.js (BFF)\n- Supporting: OAuth 2.0, Firebase Cloud Messaging, Biometric Authentication\n\n**Key Responsibilities**:\n- User authentication with biometrics (Face ID, Touch ID, fingerprint)\n- Account overview and transaction history\n- Fund transfers and bill payments\n- Mobile-specific features (QR payments, mobile check deposit)\n- Push notifications for account alerts\n\n**Communication Patterns**:\n- Inbound: User interactions via mobile app\n- Outbound: HTTPS/REST to Mobile BFF, which calls Layer 2 Business Scenarios\n- Protocols: HTTPS/REST, OAuth 2.0, WebSockets for real-time updates\n\n**Non-Functional Requirements**:\n- Performance: <500ms response time for API calls, <2s for screen load\n- Availability: 99.95% uptime (4.4 hours/year downtime)\n- Scalability: Support 500K monthly active users, auto-scaling BFF 2-10 instances\n\n---\n\n### Layer 4: BIAN Service Domain - Payment Order\n\n#### BIAN Service Domain: Payment Order\n\n**BIAN Metadata** (MANDATORY):\n- **Official BIAN Name**: Payment Order\n- **BIAN ID**: SD-001 (internal tracking)\n- **BIAN Version**: V12.0\n- **BIAN Business Domain**: Payments\n- **BIAN Business Area**: Operations and Execution\n- **BIAN Service Landscape URL**: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n**Control Record** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Control Record Type**: PaymentOrderProcedure\n- **Structure**: Includes payment details, parties, amounts, dates, status\n- **Lifecycle**: Initiated ‚Üí In Progress ‚Üí Completed / Failed / Cancelled\n\n**Service Operations** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Initiate**: Create new payment order (validate parties, amounts, compliance)\n- **Update**: Modify payment order details (before execution)\n- **Retrieve**: Query payment order status and details\n- **Control**: Manage payment order lifecycle (cancel, suspend, resume)\n- **Execute**: Trigger payment execution (hand off to Payment Execution SD)\n\n**Behavior Qualifiers** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- compliance, reporting, booking\n\n**Functional Patterns** ([BIAN Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Pattern Type**: Tracked Object\n- **Pattern Description**: Manages lifecycle of payment orders from initiation through completion\n\n**Implementation Details**:\n- **Technology Stack**: Java 17, Spring Boot 3.1, Spring Data JPA\n- **Database**: PostgreSQL 15 (payment_orders, payment_order_events tables)\n- **API Endpoints**:\n  - `POST /payment-order/initiate`: Initiate new payment order\n  - `PUT /payment-order/{id}/update`: Update payment order\n  - `GET /payment-order/{id}/retrieve`: Retrieve payment order details\n  - `PUT /payment-order/{id}/control`: Control payment order lifecycle\n  - `POST /payment-order/{id}/execute`: Execute payment order\n\n**Data Ownership**:\n- Payment order control records\n- Payment order status and lifecycle events\n- Payment order compliance checks\n\n**Dependencies**:\n- **Upstream Service Domains**: Party Authentication (SD-004), Account Verification (SD-007)\n- **Downstream Service Domains**: Payment Execution (SD-002), Payment Routing (SD-003)\n\n**Events Published**:\n- `payment-order.initiated`: When payment order created\n- `payment-order.updated`: When payment order modified\n- `payment-order.executed`: When payment handed to execution\n- `payment-order.completed`: When payment fully processed\n- `payment-order.failed`: When payment fails validation or execution\n\n**Events Consumed**:\n- `payment-execution.completed`: From Payment Execution (SD-002), updates payment order status\n- `compliance.check-completed`: From Fraud Detection (SD-045), validates payment\n\n**Non-Functional Requirements**:\n- Performance: <200ms p95 response time, 1000 TPS\n- Availability: 99.99% uptime (52 minutes/year downtime)\n- Scalability: Horizontal scaling 3-15 pods based on load\n\n**BIAN Compliance Level**:\n- **Level**: Full BIAN V12.0 Compliance\n- **Validation Date**: 2025-01-15\n- **Deviations**: None\n\n---\n\n## Architecture Diagram (Mermaid)\n\nThis section provides a visual representation of the 5-layer BIAN architecture using Mermaid diagrams.\n\n**Purpose**: Visualize the BIAN layer structure, BIAN hierarchy mapping, and communication patterns between layers.\n\n**Diagram Note**: Layer 4 components MUST reference official [BIAN V12.0 Service Domains](https://bian.org/servicelandscape-12-0-0/views/view_51891.html). All service domain names must be validated against the BIAN V12.0 Service Landscape.\n\n### BIAN Architecture Diagram Example\n\nThe following diagram shows a complete 5-layer BIAN architecture with BIAN Business Areas, Business Domains, and Service Domains:\n\n````markdown\n```mermaid\ngraph TB\n    %% Layer 1: Channels\n    subgraph Layer1[\"Layer 1: Channels\"]\n        Mobile[\"Mobile Banking App<br/>(iOS/Android)\"]\n        Web[\"Internet Banking<br/>(Web Portal)\"]\n        ATM[\"ATM Network\"]\n        Branch[\"Branch Terminals\"]\n    end\n\n    %% Layer 2: BIAN Business Scenarios (BIAN Business Areas)\n    subgraph Layer2[\"Layer 2: BIAN Business Scenarios<br/>(BIAN Business Areas)\"]\n        SalesService[\"Sales and Service<br/>Scenarios\"]\n        Operations[\"Operations and Execution<br/>Scenarios\"]\n        RiskCompliance[\"Risk and Compliance<br/>Scenarios\"]\n    end\n\n    %% Layer 3: BIAN Business Capabilities (BIAN Business Domains)\n    subgraph Layer3[\"Layer 3: BIAN Business Capabilities<br/>(BIAN Business Domains)\"]\n        CustomerMgmt[\"Customer Management<br/>Business Domain\"]\n        Payments[\"Payments<br/>Business Domain\"]\n        LoansDeposits[\"Loans and Deposits<br/>Business Domain\"]\n        RiskMgmt[\"Risk Management<br/>Business Domain\"]\n    end\n\n    %% Layer 4: BIAN Service Domains (BIAN V12.0)\n    subgraph Layer4[\"Layer 4: BIAN Service Domains<br/>(BIAN V12.0 - 326+ Service Domains)\"]\n        PartyAuth[\"Party Authentication<br/>(SD-004)\"]\n        PaymentOrder[\"Payment Order<br/>(SD-001)\"]\n        PaymentExec[\"Payment Execution<br/>(SD-002)\"]\n        CurrentAccount[\"Current Account<br/>(SD-003)\"]\n        FraudDetection[\"Fraud Detection<br/>(SD-045)\"]\n        CustomerProfile[\"Customer Profile<br/>(SD-006)\"]\n    end\n\n    %% Layer 5: Core Systems\n    subgraph Layer5[\"Layer 5: Core Systems\"]\n        CoreBanking[\"Core Banking System<br/>(Finacle/Temenos)\"]\n        Mainframe[\"Legacy Mainframe<br/>(Transaction Processing)\"]\n        MDM[\"Master Data Management\"]\n    end\n\n    %% Layer 1 to Layer 2\n    Mobile -->|OAuth 2.0 + JWT<br/>HTTPS/REST| SalesService\n    Mobile -->|OAuth 2.0 + JWT<br/>HTTPS/REST| Operations\n    Web -->|OAuth 2.0 + JWT<br/>HTTPS/REST| SalesService\n    Web -->|OAuth 2.0 + JWT<br/>HTTPS/REST| Operations\n    ATM -->|ISO 8583<br/>Secure Protocol| Operations\n    Branch -->|HTTPS/REST<br/>Internal Auth| SalesService\n\n    %% Layer 2 to Layer 3 (Business Scenarios orchestrate Business Capabilities)\n    SalesService -->|REST/gRPC<br/>mTLS| CustomerMgmt\n    Operations -->|REST/gRPC<br/>mTLS| Payments\n    Operations -->|REST/gRPC<br/>mTLS| LoansDeposits\n    RiskCompliance -->|REST/gRPC<br/>mTLS| RiskMgmt\n\n    %% Layer 3 to Layer 4 (Business Capabilities coordinate Service Domains)\n    CustomerMgmt -->|REST/gRPC<br/>mTLS| PartyAuth\n    CustomerMgmt -->|REST/gRPC<br/>mTLS| CustomerProfile\n    Payments -->|REST/gRPC<br/>mTLS| PaymentOrder\n    Payments -->|REST/gRPC<br/>mTLS| PaymentExec\n    LoansDeposits -->|REST/gRPC<br/>mTLS| CurrentAccount\n    RiskMgmt -->|REST/gRPC<br/>mTLS| FraudDetection\n\n    %% Layer 4 inter-service domain communication (event-driven)\n    PaymentOrder -.->|Kafka Event<br/>payment-order.initiated| PaymentExec\n    PaymentOrder -.->|Kafka Event<br/>compliance.check| FraudDetection\n    FraudDetection -.->|Kafka Event<br/>fraud.check-completed| PaymentOrder\n\n    %% Layer 4 to Layer 5 (Service Domains call Core Systems)\n    PartyAuth -->|REST API<br/>Legacy Adapter| MDM\n    PaymentExec -->|REST API<br/>Legacy Adapter| CoreBanking\n    CurrentAccount -->|REST API<br/>Legacy Adapter| CoreBanking\n    CustomerProfile -->|REST API<br/>Legacy Adapter| MDM\n    PaymentOrder -->|REST API<br/>Legacy Adapter| Mainframe\n\n    %% Styling\n    classDef channel fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n    classDef businessArea fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n    classDef businessDomain fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\n    classDef serviceDomain fill:#50E3C2,stroke:#3AA893,stroke-width:2px,color:#000\n    classDef coreSystem fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\n\n    class Mobile,Web,ATM,Branch channel\n    class SalesService,Operations,RiskCompliance businessArea\n    class CustomerMgmt,Payments,LoansDeposits,RiskMgmt businessDomain\n    class PartyAuth,PaymentOrder,PaymentExec,CurrentAccount,FraudDetection,CustomerProfile serviceDomain\n    class CoreBanking,Mainframe,MDM coreSystem\n```\n````\n\n### Legend\n\n**Arrow Types**:\n- **Solid arrows (`-->`)**: Synchronous calls (REST, gRPC)\n- **Dashed arrows (`-.->`)**: Asynchronous events (Kafka, message queues)\n\n**Colors**:\n- **Blue**: Layer 1 (Channels)\n- **Gray**: Layer 2 (BIAN Business Scenarios / BIAN Business Areas)\n- **Orange**: Layer 3 (BIAN Business Capabilities / BIAN Business Domains)\n- **Teal**: Layer 4 (BIAN Service Domains)\n- **Purple**: Layer 5 (Core Systems)\n\n**BIAN Hierarchy Visualization**:\n- **Layer 2 ‚Üí BIAN Business Areas**: 5 business areas (Sales and Service, Operations and Execution, Risk and Compliance, etc.)\n- **Layer 3 ‚Üí BIAN Business Domains**: 30+ business domains (Customer Management, Payments, Loans and Deposits, etc.)\n- **Layer 4 ‚Üí BIAN Service Domains**: 326+ service domains (Payment Order SD-001, Payment Execution SD-002, etc.)\n\n### Customization Instructions\n\nTo customize this diagram for your specific BIAN architecture:\n\n1. **Update Layer 1 Channels**: Replace example channels with your actual channel implementations\n2. **Update Layer 2 Business Scenarios**: Map your business scenarios to BIAN Business Areas\n3. **Update Layer 3 Business Capabilities**: Identify which BIAN Business Domains are implemented\n4. **Update Layer 4 Service Domains**: Replace example service domains with your BIAN V12.0 service domains (validate names against [BIAN Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html))\n5. **Update Layer 5 Core Systems**: Replace with your actual core banking systems\n6. **Add/Remove Communication Flows**: Update arrows based on your actual integration patterns\n7. **Adjust Colors**: Modify the `classDef` styling to match your organization's standards\n\n**For detailed diagram creation and update instructions**, see [MERMAID_DIAGRAMS_GUIDE.md](../MERMAID_DIAGRAMS_GUIDE.md).\n\n---\n\n## Guidelines\n\n1. **All 5 layers are required** in BIAN architecture\n2. **Document layers in order**: Channels ‚Üí BIAN Business Scenarios ‚Üí BIAN Business Capabilities ‚Üí BIAN Service Domains ‚Üí Core Systems\n3. **Each layer must include all subsections**: Purpose, Components, Technologies, Key Responsibilities, Communication Patterns, Non-Functional Requirements\n4. **Flow direction**: Requests typically flow top-down (Channels ‚Üí Core), responses flow bottom-up\n5. **BIAN V12.0 compliance is mandatory** for Layers 2, 3, and 4:\n   - Layer 2: Map to BIAN Business Areas (5 areas)\n   - Layer 3: Map to BIAN Business Domains (30+ domains)\n   - Layer 4: Implement BIAN Service Domains (326+ domains)\n6. **BIAN hierarchy traceability**: Every service domain must be traceable to its parent business domain and business area\n7. **BIAN service domain validation**: All service domain names in Layer 4 must be validated against the official [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n8. **BIAN service operations**: All Layer 4 service domains must implement BIAN standard service operations (Initiate, Update, Retrieve, Control, etc.)\n9. **BIAN control records**: Document control record structure per BIAN specification for each service domain\n10. **BIAN functional patterns**: Identify and document the BIAN functional pattern for each service domain (Managed Object, Tracked Object, etc.)\n11. **BIAN metadata**: All Layer 4 service domains must include complete BIAN metadata (BIAN ID, version, business domain, business area)\n12. **Core systems integration**: Layer 5 must document how core systems support BIAN service domains through adapters and integration patterns\n13. **Modernization strategy**: Document progressive modernization approach aligned with BIAN architecture goals\n\n---\n\n## Validation Checklist\n\n**Structure Validation**:\n- [ ] All 5 layers documented in order (Channels, BIAN Business Scenarios, BIAN Business Capabilities, BIAN Service Domains, Core Systems)\n- [ ] Each layer has all required subsections (Purpose, Components, Technologies, Key Responsibilities, Communication Patterns, Non-Functional Requirements)\n- [ ] Communication patterns defined for inter-layer communication\n- [ ] Technologies specified for each layer\n- [ ] Non-functional requirements quantified (not placeholders)\n\n**BIAN V12.0 Compliance Validation**:\n- [ ] Layer 2: Business scenarios mapped to BIAN Business Areas (5 areas)\n- [ ] Layer 2: BIAN Business Area mapping table included\n- [ ] Layer 3: Business capabilities mapped to BIAN Business Domains (30+ domains)\n- [ ] Layer 3: BIAN Business Domain mapping table included\n- [ ] Layer 4: All service domains validated against [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- [ ] Layer 4: Service domain catalog table included with BIAN IDs\n- [ ] Layer 4: Each service domain has complete BIAN metadata (Official Name, BIAN ID, Version, Business Domain, Business Area, URL)\n- [ ] Layer 4: Control records documented per BIAN specification\n- [ ] Layer 4: Service operations documented (Initiate, Update, Retrieve, Control, etc.)\n- [ ] Layer 4: Behavior qualifiers documented per BIAN spec\n- [ ] Layer 4: Functional patterns documented per BIAN spec\n- [ ] Layer 4: BIAN compliance level documented (Full/Partial/Custom)\n\n**BIAN Hierarchy Traceability**:\n- [ ] Clear mapping: BIAN Service Domain ‚Üí BIAN Business Domain ‚Üí BIAN Business Area\n- [ ] BIAN hierarchy visualization in architecture diagram\n- [ ] Cross-references between layers 2, 3, and 4\n\n**Integration and Implementation**:\n- [ ] Layer 5: Core systems integration strategy documented\n- [ ] Layer 5: BIAN adapter pattern documented\n- [ ] Layer 5: Modernization strategy aligned with BIAN architecture\n- [ ] Architecture diagram included (Mermaid format showing all 5 layers)\n- [ ] BIAN V12.0 reference URLs included throughout document\n- [ ] Event-driven patterns documented (if applicable)\n\n**Quality Checks**:\n- [ ] No placeholder content (all sections filled with real information)\n- [ ] All BIAN service domain names use exact BIAN V12.0 terminology\n- [ ] BIAN IDs (SD-XXX) used consistently for internal tracking\n- [ ] All required BIAN URLs reference https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n",
        "skills/architecture-docs/templates/SECTION_4_META.md": "# Section 4: Meta Architecture - META 6-Layer Enterprise Model\n\n<!-- ARCHITECTURE_TYPE: META -->\n\n**Purpose**: Define the layered architecture model that organizes system components according to their responsibilities and functions.\n\nThis template follows the **META 6-Layer Enterprise Architecture** model, designed for large enterprise systems with complex integrations and regulatory compliance requirements.\n\n**BIAN Standard**: This template uses **BIAN V12.0** as the default and recommended version for Layer 5 (Domain) service domain modeling. See the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) for official service domain definitions.\n\n---\n\n## Layers Overview\n\n| Layer | Function |\n|-------|----------|\n| **Channels** | Manages interaction with end users through various channels (web, mobile, chatbots, IVR, etc.). |\n| **User Experience** | Centralizes user experience and personalization logic, managing user journeys and flows. |\n| **Business Scenarios** | Defines and orchestrates transversal business processes and scenarios. |\n| **Business** | Implements main business capabilities, aligned with strategic objectives and organizational standards. |\n| **Domain** | Represents the functional core of the business, modeled under [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) standard. |\n| **Core** | Manages central and legacy systems that support critical operations. |\n\n---\n\n## Layer Documentation Template\n\nFor each layer, document the following information:\n\n### Layer 1: Channels\n\n**Purpose**: Manage interaction with end users through various channels (web, mobile, chatbots, IVR, etc.)\n\n**Components**:\n- Component 1: [Name and brief description]\n- Component 2: [Name and brief description]\n- Component 3: [Name and brief description]\n\n**Technologies**:\n- Primary: [Main technology stack]\n- Supporting: [Additional technologies, frameworks]\n\n**Key Responsibilities**:\n- Orchestrate omnichannel experience\n- Adapt presentation and flow according to the channel\n- Encapsulate presentation and access logic\n- Manage channel-specific user interactions\n\n**Communication Patterns**:\n- Inbound: [How this layer receives requests]\n- Outbound: [How this layer communicates with other layers]\n- Protocols: [HTTP/REST, gRPC, messaging, etc.]\n\n**Non-Functional Requirements**:\n- Performance: [Latency, throughput requirements]\n- Availability: [SLA, uptime requirements]\n- Scalability: [How this layer scales]\n\n---\n\n### Layer 2: User Experience\n\n**Purpose**: Centralize user experience and personalization logic\n\n**Components**:\n- BFF (Backend for Frontend): [Description]\n- API Gateway: [Description]\n- Session Management: [Description]\n\n**Technologies**:\n- Primary: [Main technology stack]\n- Supporting: [Additional technologies, frameworks]\n\n**Key Responsibilities**:\n- Manage user journeys and flows\n- Apply personalization and context rules\n- Service orchestration and composition\n- User session management\n- Experience personalization\n- Response formatting and aggregation\n\n**Communication Patterns**:\n- Inbound: [From Channels layer]\n- Outbound: [To Business Scenarios and Business layers]\n- Protocols: [REST, GraphQL, etc.]\n\n**Non-Functional Requirements**:\n- Performance: [Response time targets]\n- Availability: [High availability requirements]\n- Scalability: [Horizontal scaling approach]\n\n---\n\n### Layer 3: Business Scenarios\n\n**Purpose**: Define and orchestrate transversal business processes and scenarios\n\n**Components**:\n- Scenario Orchestrator: [Description]\n- Process Engine: [Description]\n- Business Rules Engine: [Description]\n\n**Technologies**:\n- Primary: [Workflow/orchestration technology]\n- Supporting: [Rules engine, process automation]\n\n**Key Responsibilities**:\n- Model end-to-end business processes\n- Integrate business and domain capabilities\n- Adapt flows to regulatory or market requirements\n- Cross-domain business process orchestration\n- Business rule execution\n- Transaction coordination\n- Workflow management\n\n**Communication Patterns**:\n- Inbound: [From User Experience layer]\n- Outbound: [To Business and Domain layers]\n- Protocols: [Sync/async patterns, events]\n\n**Non-Functional Requirements**:\n- Performance: [Process execution time]\n- Availability: [Business continuity requirements]\n- Scalability: [Process volume handling]\n\n---\n\n### Layer 4: Business\n\n**Purpose**: Implement main business capabilities, aligned with strategic objectives\n\n**Components**:\n- Business Capability Services: [Description]\n- Business API Layer: [Description]\n- Business Rules Management: [Description]\n\n**Technologies**:\n- Primary: [Business services platform]\n- Supporting: [API management, business rules engine]\n\n**Key Responsibilities**:\n- Manage business rules and logic\n- Expose business services through APIs\n- Ensure interoperability and API standards compliance\n- Implement business capability orchestration\n\n**Communication Patterns**:\n- Inbound: [From Business Scenarios layer]\n- Outbound: [To Domain and external services]\n- Protocols: [REST, SOAP, messaging, file transfer]\n\n**Non-Functional Requirements**:\n- Performance: [Message throughput]\n- Availability: [Integration uptime]\n- Scalability: [Message volume capacity]\n\n---\n\n### Layer 5: Domain\n\n**Purpose**: Represent the functional core of the business, modeled under [BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) standard\n\n**BIAN V12.0 Hierarchy**:\nLayer 5 service domains must be traceable to their parent BIAN hierarchy:\n- BIAN Business Area (5 areas: Sales and Service, Reference Data, Operations and Execution, Risk and Compliance, Business Support)\n- BIAN Business Domain (30+ domains: e.g., Payments, Customer Management, Loans and Deposits)\n- BIAN Service Domain (326+ domains) ‚Üê Layer 5 implements this level\n\n**Service Domains** ([BIAN V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\nReference the [BIAN Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) to identify appropriate service domains for your system.\n\n**Service Domain Template** (use for each service domain):\n- **Official BIAN Name**: [Exact name from BIAN V12.0 Service Landscape - e.g., \"Payment Order\", \"Current Account\"]\n- **BIAN ID**: [SD-XXX for internal document tracking only - e.g., SD-001, SD-002]\n- **BIAN Business Domain**: [Parent business domain - e.g., \"Payments\", \"Customer Management\", \"Loans and Deposits\"]\n- **BIAN Business Area**: [Parent business area - e.g., \"Operations and Execution\", \"Sales and Service\", \"Risk and Compliance\"]\n- **Description**: [Brief description of this service domain's purpose in your system]\n- **BIAN Service Landscape URL**: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n**Example**:\n- **Official BIAN Name**: Payment Order\n- **BIAN ID**: SD-001\n- **BIAN Business Domain**: Payments\n- **BIAN Business Area**: Operations and Execution\n- **Description**: Manages payment order creation, validation, and execution\n- **BIAN Service Landscape URL**: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n**Note**: Validate each service domain **Official BIAN Name** against the official [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) to ensure accurate alignment. BIAN IDs (SD-XXX) are for internal document tracking only to count how many service domains are used. BIAN Business Domain and Business Area must be traceable to the BIAN hierarchy.\n\n**Technologies**:\n- Primary: [Microservices framework]\n- Supporting: [Databases, caching, messaging]\n\n**Key Responsibilities**:\n- Implementation of BIAN Service Domains\n- Ensure functional consistency across domains\n- Domain-specific business logic\n- Data ownership and management\n- Domain event publishing\n- Allow customization under ISO20022 if necessary\n\n**Communication Patterns**:\n- Inbound: [From Business layer]\n- Outbound: [To Core systems and other domains]\n- Protocols: [REST, gRPC, domain events]\n\n**BIAN Alignment**:\n- **Service Domain Model**: BIAN V12.0 (mandatory)\n- **Official Reference**: [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n\n**Control Records** (per BIAN V12.0):\nEach service domain must document its control record structure per BIAN specification:\n- **Control Record Type**: [As defined in BIAN spec - e.g., \"PaymentOrderProcedure\", \"CurrentAccountFulfillmentArrangement\"]\n- **Control Record Structure**:\n  - Field 1: [Name, data type, description per BIAN spec]\n  - Field 2: [Name, data type, description per BIAN spec]\n  - Field 3: [Name, data type, description per BIAN spec]\n  - [Add all fields as defined in BIAN V12.0 specification]\n- **Lifecycle States**: [Document all states - e.g., Initiated, Active, Completed, Suspended, Cancelled per BIAN]\n- **State Transitions**: [Document allowed state transitions per BIAN specification - e.g., Initiated‚ÜíActive, Active‚ÜíSuspended, Suspended‚ÜíActive, Active‚ÜíCompleted]\n\n**Service Operations** (BIAN V12.0 Standard):\nAll BIAN service domains support the following standardized operations (document which operations are implemented for each service domain):\n\n**Mandatory Operations** (all service domains MUST implement):\n- **Initiate**: Create new control record\n- **Update**: Modify existing control record\n- **Retrieve**: Query control record\n- **Control**: Manage control record lifecycle (suspend, resume, terminate)\n\n**Optional Operations** (implement if applicable per BIAN spec for specific service domain):\n- **Exchange**: Bi-directional data exchange (if applicable per BIAN spec)\n- **Execute**: Execute service operation (if applicable per BIAN spec)\n- **Request**: Request service action (if applicable per BIAN spec)\n\nReference: [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n\n**Behavior Qualifiers**:\nDocument all behavior qualifiers defined in BIAN V12.0 for each service domain.\n\nExamples: \"registration\", \"valuation\", \"compliance\", \"reporting\", \"booking\", \"analysis\", \"fulfillment\"\n\nReference: [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n\n**Functional Patterns**:\nIdentify and document the BIAN functional pattern for each service domain:\n- **Pattern Types**: Managed Object | Tracked Object | Administered Object | Governed Object | Monitored Object | Catalog Entry | Register Entry\n- **Pattern Description**: [How the service domain implements the pattern]\n- **Pattern Implications**: [What the pattern means for service operations and lifecycle management]\n\n**Compliance Level**: Full BIAN V12.0 compliance (mandatory for META Layer 5)\n\n**Implementation Guidance**:\n1. Validate service domain **Official BIAN Name** against the official BIAN V12.0 landscape\n2. Assign internal BIAN IDs (e.g., SD-001, SD-002) for document tracking purposes only\n3. Document BIAN hierarchy traceability: Service Domain ‚Üí Business Domain ‚Üí Business Area\n4. Document control record structure with fields, data types, and lifecycle states per BIAN spec\n5. Specify which BIAN service operations are implemented (4 mandatory + optional)\n6. List behavior qualifiers from BIAN V12.0 for each service domain\n7. Identify functional pattern type and implications for service lifecycle\n8. Implement service operations according to BIAN V12.0 specifications with enforced API endpoint naming\n9. Ensure Full BIAN V12.0 compliance for all Layer 5 service domains\n\n**Non-Functional Requirements**:\n- Performance: [Service response time]\n- Availability: [Domain availability targets]\n- Scalability: [Domain-specific scaling strategy]\n\n---\n\n### Layer 6: Core\n\n**Purpose**: Manage central and legacy systems that support critical operations\n\n**Systems**:\n- Core Banking System: [Name, vendor, version]\n- Transaction Processing: [Name, description]\n- Legacy Systems: [List of critical legacy systems]\n\n**Technologies**:\n- Primary: [Mainframe, core banking platform]\n- Supporting: [Databases, interfaces]\n\n**Key Responsibilities**:\n- Provide fundamental services (core banking, ERP, etc.)\n- Integrate legacy capabilities with modern ecosystem\n- Ensure operational continuity and resilience\n- Account management\n- Transaction processing\n- Balance and ledger management\n- Master data management\n\n**Communication Patterns**:\n- Inbound: [From Domain layer]\n- Outbound: [Data replication, events]\n- Protocols: [Legacy protocols, files, APIs]\n\n**Modernization Strategy**:\n- Current State: [Assessment of current systems]\n- Target State: [Modernization goals]\n- Migration Approach: [Progressive modernization - Strangler pattern, lift-and-shift, etc.]\n- Gradual Evolution: [How legacy systems evolve while ensuring continuity]\n\n**Non-Functional Requirements**:\n- Performance: [Transaction processing rate]\n- Availability: [24/7 uptime requirements]\n- Scalability: [Capacity planning]\n\n---\n\n## Example Implementation\n\n### Layer 1: Channels\n\n**Purpose**: Provide omnichannel access to banking services for retail and corporate customers.\n\n**Components**:\n- Mobile Banking App (iOS/Android): Native applications for retail customers\n- Internet Banking Portal: Web-based portal for account management\n- ATM Network Interface: Integration with ATM network for cash services\n- Contact Center Platform: Unified platform for customer service representatives\n\n**Technologies**:\n- Primary: React Native (Mobile), Angular (Web), Java Spring Boot (APIs)\n- Supporting: OAuth 2.0, Firebase, CDN (CloudFront)\n\n**Key Responsibilities**:\n- User authentication and authorization\n- Channel-specific presentation logic\n- Device management and security\n- Multi-factor authentication orchestration\n\n**Communication Patterns**:\n- Inbound: User requests via HTTPS\n- Outbound: REST API calls to User Experience layer\n- Protocols: HTTPS/REST, OAuth 2.0, WebSockets (real-time notifications)\n\n**Non-Functional Requirements**:\n- Performance: <500ms response time for API calls\n- Availability: 99.95% uptime (4.4 hours/year downtime)\n- Scalability: Auto-scaling to handle 100K concurrent users\n\n---\n\n## Architecture Diagram (Mermaid)\n\nThis section provides a visual representation of the 6-layer META architecture using Mermaid diagrams.\n\n**Purpose**: Visualize the layer structure, component placement, and data flow between layers.\n\n**Diagram Note**: Layer 5 components should reference official [BIAN V12.0 Service Domains](https://bian.org/servicelandscape-12-0-0/views/view_51891.html). Example services shown: Payment Execution (SD-003), Account Transfer (SD-045).\n\n### META Architecture Diagram Example\n\nThe following diagram shows a complete 6-layer META architecture with detailed Layer 3 (Business Scenarios) event-driven components:\n\n````markdown\n```mermaid\ngraph TB\n    %% Layer 1: Channels\n    subgraph Layer1[\"Layer 1: Channels\"]\n        Mobile[\"Mobile App\"]\n        Web[\"Internet Banking\"]\n        Contact[\"Contact Center\"]\n    end\n\n    %% Layer 2: User Experience\n    subgraph Layer2[\"Layer 2: User Experience\"]\n        APIGateway[\"API Gateway<br/>(Azure API Management)\"]\n        BFF[\"BFF Services\"]\n    end\n\n    %% Layer 3: Business Scenarios\n    subgraph Layer3[\"Layer 3: Business Scenarios<br/>(Task Scheduling System)\"]\n        Scheduler[\"Job Scheduler Service<br/>REST API: /api/v1/jobs\"]\n        Kafka1[\"Kafka Topic:<br/>job-execution-events\"]\n        Kafka2[\"Kafka Topic:<br/>job-lifecycle-events\"]\n        TransferWorker[\"TransferWorker\"]\n        ReminderWorker[\"ReminderWorker\"]\n        HistoryService[\"History Service<br/>Query API: /api/v1/history/*\"]\n    end\n\n    %% Layer 4: Business\n    subgraph Layer4[\"Layer 4: Business\"]\n        BusinessIntegration[\"Business Service Integration\"]\n        APIManagement[\"API Management\"]\n    end\n\n    %% Layer 5: Domain (BIAN V12.0)\n    subgraph Layer5[\"Layer 5: Domain (BIAN V12.0)\"]\n        PaymentService[\"Payment Execution<br/>(SD-003)\"]\n        TransferService[\"Account Transfer<br/>(SD-045)\"]\n        CRMService[\"CRM Service\"]\n        NotificationService[\"Notification Service\"]\n    end\n\n    %% Layer 6: Core\n    subgraph Layer6[\"Layer 6: Core\"]\n        CoreBanking[\"Core Banking System\"]\n    end\n\n    %% Data Flows\n    Mobile -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n    Web -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n    Contact -->|OAuth 2.0 + JWT<br/>TLS 1.2+| APIGateway\n    APIGateway -->|REST/GraphQL<br/>mTLS| Scheduler\n    Scheduler -.->|Kafka<br/>Async Publish| Kafka1\n    Scheduler -.->|Kafka<br/>JOB_CREATED event| Kafka2\n    Kafka1 -.->|Consumer Group| TransferWorker\n    Kafka1 -.->|Consumer Group| ReminderWorker\n    TransferWorker -.->|JOB_COMPLETED<br/>JOB_FAILED| Kafka2\n    ReminderWorker -.->|JOB_COMPLETED| Kafka2\n    Kafka2 -.->|Consumer Group<br/>Materialize States| HistoryService\n    TransferWorker -->|gRPC/mTLS<br/>3 retries| TransferService\n    ReminderWorker -->|gRPC/mTLS| CRMService\n    ReminderWorker -->|gRPC/mTLS| NotificationService\n    BusinessIntegration -->|gRPC/REST<br/>mTLS| PaymentService\n    BusinessIntegration -->|gRPC/REST<br/>mTLS| TransferService\n    PaymentService -->|REST APIs<br/>Legacy protocols| CoreBanking\n    TransferService -->|REST APIs<br/>Legacy protocols| CoreBanking\n\n    %% Styling\n    classDef scheduler fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n    classDef worker fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\n    classDef history fill:#7ED321,stroke:#5A9B18,stroke-width:2px,color:#fff\n    classDef kafka fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\n    classDef domain fill:#50E3C2,stroke:#3AA893,stroke-width:2px,color:#000\n    classDef gateway fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n\n    class Scheduler scheduler\n    class TransferWorker,ReminderWorker worker\n    class HistoryService history\n    class Kafka1,Kafka2 kafka\n    class PaymentService,TransferService,CRMService,NotificationService domain\n    class APIGateway,BFF gateway\n```\n````\n\n### Legend\n\n**Arrow Types**:\n- **Solid arrows (`-->`)**: Synchronous calls (REST, gRPC, SOAP)\n- **Dashed arrows (`-.->`)**: Asynchronous events (Kafka, message queues)\n\n**Colors**:\n- **Blue**: Entry points, schedulers\n- **Orange**: Workers, executors\n- **Green**: Query services, read models\n- **Purple**: Event streaming (Kafka, message queues)\n- **Teal**: Domain services (BIAN Service Domains)\n- **Gray**: Infrastructure (API Gateway, load balancers)\n\n### Customization Instructions\n\nTo customize this diagram for your specific architecture:\n\n1. **Update Layer Components**: Replace example components with your actual services\n2. **Update Protocols**: Modify data flow labels with your actual protocols and security\n3. **Update BIAN Service Domains**: Replace SD-003, SD-045 with your BIAN identifiers\n4. **Adjust Colors**: Modify the `classDef` styling to match your organization's standards\n5. **Add/Remove Flows**: Update arrow connections based on your integration patterns\n\n**For detailed diagram creation and update instructions**, see [MERMAID_DIAGRAMS_GUIDE.md](../MERMAID_DIAGRAMS_GUIDE.md).\n\n---\n\n## Guidelines\n\n1. **All 6 layers are required** in META architecture\n2. **Document layers in order**: Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Business ‚Üí Domain ‚Üí Core\n3. **Each layer must include all subsections**: Purpose, Components, Technologies, Key Responsibilities, Communication Patterns, Non-Functional Requirements\n4. **Flow direction**: Requests typically flow top-down (Channels ‚Üí Core), responses flow bottom-up\n5. **Integration points**: Clearly define how each layer communicates with adjacent layers\n6. **BIAN compliance**: BIAN V12.0 compliance applies only to Layer 5 (Domain) - align with BIAN V12.0 Service Domain model\n7. **ISO20022 customization**: Layer 5 (Domain) should allow customization under ISO20022 standard if necessary\n8. **Modernization strategy**: Layer 6 (Core) should include plans for progressive legacy system evolution\n\n---\n\n## Validation Checklist\n\n- [ ] All 6 layers documented (Channels, UX, Business Scenarios, Business, Domain, Core)\n- [ ] Each layer has all required subsections\n- [ ] Communication patterns defined for inter-layer communication\n- [ ] Technologies specified for each layer\n- [ ] Non-functional requirements quantified (not just placeholders)\n- [ ] BIAN V12.0 alignment documented in Layer 5 (Domain)\n- [ ] BIAN service domain names (Capabilities) validated against [official landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- [ ] BIAN IDs (SD-XXX) used for internal document tracking only\n- [ ] BIAN reference URLs included for service domain definitions\n- [ ] ISO20022 customization mentioned in Layer 5 (Domain) if applicable\n- [ ] Modernization strategy included in Layer 6 (Core)\n- [ ] Architecture diagram included (Mermaid format recommended, see MERMAID_DIAGRAMS_GUIDE.md)",
        "skills/architecture-docs/templates/SECTION_4_MICROSERVICES.md": "# Section 4: Meta Architecture - Microservices Architecture\n\n<!-- ARCHITECTURE_TYPE: MICROSERVICES -->\n\n**Purpose**: Define the microservices architecture model with independently deployable services organized around business capabilities.\n\nThis template follows the **Microservices Architecture** pattern, designed for cloud-native distributed systems with high scalability and independent service deployment.\n\n---\n\n## Architecture Overview\n\n| Component Layer | Function |\n|----------------|----------|\n| **API Gateway** | Single entry point for clients, handles routing, authentication, rate limiting, and request aggregation. |\n| **Service Mesh** | Infrastructure layer managing service-to-service communication, observability, and resilience. |\n| **Microservices** | Independently deployable services implementing bounded contexts and business capabilities. |\n| **Data Stores** | Decentralized data management with database-per-service pattern. |\n| **Event Bus** | Asynchronous communication backbone for event-driven interactions between services. |\n| **Supporting Infrastructure** | Configuration, service discovery, secrets management, and cross-cutting concerns. |\n\n---\n\n## Component Documentation Template\n\n### API Gateway\n\n**Purpose**: [What the API Gateway provides to clients]\n\n**Capabilities**:\n- Request routing and load balancing\n- Authentication and authorization (JWT, OAuth 2.0)\n- Rate limiting and throttling\n- Request/response transformation\n- API composition and aggregation\n\n**Technologies**:\n- Primary: [Kong, AWS API Gateway, Azure API Management, etc.]\n- Supporting: [Authentication provider, caching layer]\n\n**Key Responsibilities**:\n- Centralized authentication\n- API versioning management\n- Cross-cutting concerns (CORS, compression)\n- Client-specific API composition (BFF pattern)\n\n**Communication Patterns**:\n- Inbound: HTTPS from external clients\n- Outbound: HTTP/gRPC to microservices\n- Protocols: [REST, GraphQL, gRPC]\n\n**Non-Functional Requirements**:\n- Performance: [Latency overhead, throughput]\n- Availability: [High availability setup]\n- Scalability: [Concurrent connections capacity]\n\n---\n\n### Service Mesh\n\n**Purpose**: [What the service mesh provides to services]\n\n**Capabilities**:\n- Service-to-service authentication (mTLS)\n- Traffic management (canary deployments, circuit breaking)\n- Observability (distributed tracing, metrics)\n- Resilience (retries, timeouts, circuit breakers)\n\n**Technologies**:\n- Primary: [Istio, Linkerd, Consul Connect, AWS App Mesh]\n- Supporting: [Envoy proxy, Jaeger, Prometheus]\n\n**Key Responsibilities**:\n- Automatic mTLS for service communication\n- Traffic shaping and routing\n- Distributed tracing injection\n- Health checks and circuit breaking\n\n**Communication Patterns**:\n- Sidecar proxy pattern\n- Control plane ‚Üî data plane communication\n- Protocols: [gRPC for control plane, HTTP/gRPC for data plane]\n\n**Non-Functional Requirements**:\n- Performance: [Proxy overhead <10ms p99]\n- Availability: [Control plane redundancy]\n- Scalability: [Support for N services]\n\n---\n\n### Microservices\n\n**Purpose**: [What microservices provide to the system]\n\nDocument each microservice using this template:\n\n#### Service: [Service Name]\n\n**Bounded Context**: [Domain/business capability this service owns]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Technologies**:\n- Primary: [Language, framework - e.g., Java/Spring Boot, Node.js/Express, Go]\n- Supporting: [Libraries, tools]\n\n**API Endpoints**:\n- `POST /api/v1/resource`: [Description]\n- `GET /api/v1/resource/{id}`: [Description]\n- `PUT /api/v1/resource/{id}`: [Description]\n\n**Data Store**:\n- Type: [PostgreSQL, MongoDB, DynamoDB, etc.]\n- Schema: [Brief description or link to schema]\n- Data Ownership: [What data this service owns]\n\n**Events Published**:\n- `resource.created`: [When and what data]\n- `resource.updated`: [When and what data]\n\n**Events Consumed**:\n- `other.event`: [From which service, what action taken]\n\n**Dependencies**:\n- Upstream Services: [Services this service calls]\n- Downstream Services: [Services that call this service]\n\n**Non-Functional Requirements**:\n- Performance: [Response time, throughput]\n- Availability: [SLA, redundancy]\n- Scalability: [Scaling strategy, resource limits]\n\n---\n\n### Data Stores (Database-per-Service)\n\n**Purpose**: [Decentralized data management strategy]\n\n**Pattern**: Database-per-Service\n\n**Data Stores**:\n\n| Service | Database Type | Technology | Purpose |\n|---------|--------------|------------|---------|\n| Service A | Relational | PostgreSQL | [Transactional data] |\n| Service B | Document | MongoDB | [Flexible schema] |\n| Service C | Key-Value | Redis | [Caching, sessions] |\n\n**Data Consistency Strategy**:\n- **Saga Pattern**: [For distributed transactions]\n- **Event Sourcing**: [If applicable]\n- **CQRS**: [If applicable]\n- **Eventual Consistency**: [How handled]\n\n**Data Synchronization**:\n- Method: [Events, CDC, scheduled sync]\n- Tools: [Kafka, Debezium, custom]\n\n**Non-Functional Requirements**:\n- Performance: [Query latency, throughput]\n- Availability: [Backup strategy, failover]\n- Scalability: [Sharding, replication]\n\n---\n\n### Event Bus\n\n**Purpose**: [Asynchronous communication and event streaming]\n\n**Capabilities**:\n- Event publishing and subscription\n- Event ordering and partitioning\n- Event replay and history\n- Dead-letter queue handling\n\n**Technologies**:\n- Primary: [Kafka, RabbitMQ, AWS EventBridge, Azure Event Hubs]\n- Supporting: [Schema registry, monitoring]\n\n**Event Topics**:\n\n| Topic | Producers | Consumers | Purpose |\n|-------|-----------|-----------|---------|\n| `topic.name` | [Services] | [Services] | [What events flow here] |\n\n**Key Responsibilities**:\n- Reliable event delivery\n- Event schema validation\n- Event retention and replay\n- Topic partitioning for scalability\n\n**Communication Patterns**:\n- Pub/Sub model\n- Event sourcing (if applicable)\n- CQRS read model updates\n\n**Non-Functional Requirements**:\n- Performance: [Throughput, latency]\n- Availability: [Replication factor, durability]\n- Scalability: [Partitioning strategy, consumer groups]\n\n---\n\n### Supporting Infrastructure\n\n**Purpose**: [Cross-cutting infrastructure services]\n\n**Components**:\n\n#### Service Discovery\n- Technology: [Consul, Eureka, Kubernetes DNS]\n- Purpose: Dynamic service registration and lookup\n\n#### Configuration Management\n- Technology: [Spring Cloud Config, Consul KV, Kubernetes ConfigMaps]\n- Purpose: Centralized configuration for all services\n\n#### Secrets Management\n- Technology: [HashiCorp Vault, AWS Secrets Manager, Azure Key Vault]\n- Purpose: Secure storage and rotation of secrets\n\n#### Distributed Logging\n- Technology: [ELK Stack, Splunk, CloudWatch]\n- Purpose: Centralized log aggregation and search\n\n#### Monitoring & Alerting\n- Technology: [Prometheus, Grafana, Datadog, New Relic]\n- Purpose: Metrics collection and visualization\n\n---\n\n## Service Catalog\n\nList all microservices in the system:\n\n| Service Name | Bounded Context | Primary Technology | Data Store | Team Owner |\n|--------------|----------------|-------------------|------------|------------|\n| [Service 1] | [Context] | [Tech] | [DB] | [Team] |\n| [Service 2] | [Context] | [Tech] | [DB] | [Team] |\n| [Service 3] | [Context] | [Tech] | [DB] | [Team] |\n\n---\n\n## Communication Patterns\n\n### Synchronous Communication\n- **Pattern**: REST over HTTP, gRPC\n- **Use Cases**: Request-response, real-time queries\n- **Circuit Breakers**: [Resilience4j, Hystrix]\n- **Timeouts**: [Default timeout values]\n\n### Asynchronous Communication\n- **Pattern**: Event-driven via message bus\n- **Use Cases**: State changes, eventual consistency, notifications\n- **Retry Strategy**: [Exponential backoff]\n- **Dead Letter Queue**: [Handling failed events]\n\n---\n\n## Example Implementation\n\n### API Gateway\n\n**Purpose**: Provide unified API entry point for mobile and web clients.\n\n**Capabilities**:\n- JWT-based authentication\n- Rate limiting (100 req/min per client)\n- API versioning (v1, v2)\n- Request aggregation for mobile clients\n\n**Technologies**:\n- Primary: Kong Gateway 3.x\n- Supporting: Redis (rate limiting), Auth0 (authentication)\n\n**Key Responsibilities**:\n- Validate JWT tokens\n- Route requests to appropriate microservices\n- Apply rate limits per client tier (free, premium, enterprise)\n- Transform API v1 calls to v2 internally\n\n**Communication Patterns**:\n- Inbound: HTTPS from clients (mobile apps, web apps)\n- Outbound: HTTP/2 with gRPC to microservices\n- Protocols: REST (client-facing), gRPC (internal)\n\n**Non-Functional Requirements**:\n- Performance: <50ms routing overhead, 10K req/sec throughput\n- Availability: 99.99% uptime, active-active setup across 3 AZs\n- Scalability: Auto-scaling 2-10 instances based on traffic\n\n---\n\n### Microservice: Order Service\n\n**Bounded Context**: Order Management (order lifecycle from creation to fulfillment)\n\n**Responsibilities**:\n- Create and manage customer orders\n- Calculate order totals and apply discounts\n- Coordinate order fulfillment workflow\n- Track order status changes\n\n**Technologies**:\n- Primary: Java 17, Spring Boot 3.1, Spring Data JPA\n- Supporting: Resilience4j, Micrometer, Lombok\n\n**API Endpoints**:\n- `POST /api/v1/orders`: Create new order\n- `GET /api/v1/orders/{id}`: Retrieve order details\n- `PUT /api/v1/orders/{id}/status`: Update order status\n- `GET /api/v1/orders/customer/{customerId}`: List customer orders\n\n**Data Store**:\n- Type: PostgreSQL 15\n- Schema: orders, order_items, order_status_history tables\n- Data Ownership: All order-related data\n\n**Events Published**:\n- `order.created`: When order is placed (includes order ID, customer ID, total)\n- `order.confirmed`: When payment confirmed\n- `order.shipped`: When order dispatched\n\n**Events Consumed**:\n- `payment.completed`: From Payment Service, triggers order confirmation\n- `inventory.reserved`: From Inventory Service, confirms stock availability\n\n**Dependencies**:\n- Upstream Services: Payment Service, Inventory Service, Customer Service\n- Downstream Services: Notification Service, Shipping Service\n\n**Non-Functional Requirements**:\n- Performance: <200ms response time (95th percentile), 500 TPS\n- Availability: 99.9% uptime, 2 replicas minimum\n- Scalability: Horizontal scaling 2-10 pods based on CPU (70% threshold)\n\n---\n\n## Architecture Diagram (Mermaid)\n\nThis section provides a visual representation of the microservices architecture using Mermaid diagrams.\n\n**Purpose**: Visualize the service topology, API Gateway, service mesh, and communication patterns.\n\n### Microservices Architecture Diagram Example\n\nThe following diagram shows a cloud-native microservices architecture with API Gateway, service mesh, and event-driven communication:\n\n````markdown\n```mermaid\ngraph TB\n    %% Clients\n    WebClient[\"Web Client<br/>(Browser)\"]\n    MobileClient[\"Mobile Client<br/>(iOS/Android)\"]\n\n    %% API Gateway\n    APIGateway[\"API Gateway<br/>(Kong/Nginx)<br/>Rate Limiting, Auth, Routing\"]\n\n    %% Service Mesh\n    subgraph ServiceMesh[\"Service Mesh (Istio)\"]\n        %% Microservices\n        subgraph Services[\"Microservices\"]\n            UserService[\"User Service<br/>gRPC + REST<br/>PostgreSQL\"]\n            OrderService[\"Order Service<br/>gRPC + REST<br/>PostgreSQL\"]\n            PaymentService[\"Payment Service<br/>gRPC + REST<br/>PostgreSQL\"]\n            InventoryService[\"Inventory Service<br/>gRPC + REST<br/>MongoDB\"]\n            NotificationService[\"Notification Service<br/>Event Consumer<br/>Redis\"]\n        end\n    end\n\n    %% Event Bus\n    EventBus[\"Event Bus<br/>(Kafka)<br/>3 Topics: order-events,<br/>payment-events, notification-events\"]\n\n    %% Databases (Database-per-Service)\n    UserDB[\"User DB<br/>(PostgreSQL)\"]\n    OrderDB[\"Order DB<br/>(PostgreSQL)\"]\n    PaymentDB[\"Payment DB<br/>(PostgreSQL)\"]\n    InventoryDB[\"Inventory DB<br/>(MongoDB)\"]\n    Cache[\"Cache<br/>(Redis)\"]\n\n    %% Supporting Infrastructure\n    ServiceDiscovery[\"Service Discovery<br/>(Consul/Kubernetes DNS)\"]\n    ConfigServer[\"Config Server<br/>(Spring Cloud Config)\"]\n    LogAggregator[\"Log Aggregator<br/>(ELK Stack)\"]\n\n    %% Client to API Gateway\n    WebClient -->|HTTPS/REST<br/>OAuth 2.0 + JWT| APIGateway\n    MobileClient -->|HTTPS/REST<br/>OAuth 2.0 + JWT| APIGateway\n\n    %% API Gateway to Services (Sync)\n    APIGateway -->|HTTP/gRPC<br/>mTLS| UserService\n    APIGateway -->|HTTP/gRPC<br/>mTLS| OrderService\n    APIGateway -->|HTTP/gRPC<br/>mTLS| PaymentService\n    APIGateway -->|HTTP/gRPC<br/>mTLS| InventoryService\n\n    %% Inter-Service Communication (Sync via Service Mesh)\n    OrderService -->|gRPC<br/>Circuit Breaker<br/>mTLS| PaymentService\n    OrderService -->|gRPC<br/>Circuit Breaker<br/>mTLS| InventoryService\n    PaymentService -->|gRPC<br/>Circuit Breaker<br/>mTLS| UserService\n\n    %% Event-Driven Communication (Async)\n    OrderService -.->|Publish<br/>order-created,<br/>order-completed| EventBus\n    PaymentService -.->|Publish<br/>payment-processed,<br/>payment-failed| EventBus\n    EventBus -.->|Subscribe<br/>Consumer Group| NotificationService\n    EventBus -.->|Subscribe<br/>Consumer Group| OrderService\n    EventBus -.->|Subscribe<br/>Consumer Group| InventoryService\n\n    %% Services to Databases (Database-per-Service)\n    UserService -->|SQL<br/>Connection Pool| UserDB\n    OrderService -->|SQL<br/>Connection Pool| OrderDB\n    PaymentService -->|SQL<br/>Connection Pool| PaymentDB\n    InventoryService -->|NoSQL<br/>MongoDB Driver| InventoryDB\n    NotificationService -->|Redis Protocol| Cache\n\n    %% Services to Infrastructure\n    UserService -.->|Register| ServiceDiscovery\n    OrderService -.->|Register| ServiceDiscovery\n    PaymentService -.->|Register| ServiceDiscovery\n    InventoryService -.->|Register| ServiceDiscovery\n    NotificationService -.->|Register| ServiceDiscovery\n\n    UserService -.->|Fetch Config| ConfigServer\n    OrderService -.->|Fetch Config| ConfigServer\n    PaymentService -.->|Fetch Config| ConfigServer\n\n    UserService -.->|Logs| LogAggregator\n    OrderService -.->|Logs| LogAggregator\n    PaymentService -.->|Logs| LogAggregator\n    InventoryService -.->|Logs| LogAggregator\n    NotificationService -.->|Logs| LogAggregator\n\n    %% Styling\n    classDef client fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n    classDef gateway fill:#9B9B9B,stroke:#6B6B6B,stroke-width:2px,color:#fff\n    classDef service fill:#F5A623,stroke:#B8791A,stroke-width:2px,color:#fff\n    classDef eventBus fill:#BD10E0,stroke:#8A0CA3,stroke-width:2px,color:#fff\n    classDef database fill:#7ED321,stroke:#5A9B18,stroke-width:2px,color:#000\n    classDef infrastructure fill:#50E3C2,stroke:#3AA893,stroke-width:2px,color:#000\n\n    class WebClient,MobileClient client\n    class APIGateway gateway\n    class UserService,OrderService,PaymentService,InventoryService,NotificationService service\n    class EventBus eventBus\n    class UserDB,OrderDB,PaymentDB,InventoryDB,Cache database\n    class ServiceDiscovery,ConfigServer,LogAggregator infrastructure\n```\n````\n\n### Legend\n\n**Arrow Types**:\n- **Solid arrows (`-->`)**: Synchronous calls (HTTP/REST, gRPC, SQL)\n- **Dashed arrows (`-.->`)**: Asynchronous operations (events, service registration, logging, config fetch)\n\n**Colors**:\n- **Blue**: Clients (web, mobile)\n- **Gray**: API Gateway and load balancers\n- **Orange**: Microservices\n- **Purple**: Event Bus (Kafka, message brokers)\n- **Green**: Databases (PostgreSQL, MongoDB, Redis)\n- **Teal**: Supporting infrastructure (service discovery, config, logging)\n\n**Communication Patterns**:\n- **Client ‚Üí API Gateway**: HTTPS/REST with OAuth 2.0 + JWT authentication\n- **API Gateway ‚Üí Services**: HTTP/gRPC with mTLS (mutual TLS)\n- **Service ‚Üí Service (Sync)**: gRPC with circuit breakers and mTLS (via service mesh)\n- **Service ‚Üí Event Bus**: Kafka protocol for publish/subscribe patterns\n- **Service ‚Üí Database**: Database-per-service pattern (no shared databases)\n- **Service ‚Üí Infrastructure**: Service discovery registration, config fetch, log streaming\n\n**Service Mesh Benefits**:\n- Automatic mTLS between services\n- Load balancing and traffic management\n- Circuit breaker and retry policies\n- Distributed tracing (Jaeger/Zipkin integration)\n- Observability (metrics, logs, traces)\n\n### Customization Instructions\n\nTo customize this diagram for your specific architecture:\n\n1. **Update Services**: Replace example services (User, Order, Payment, Inventory, Notification) with your actual microservices\n2. **Update Databases**: Modify database technologies based on your data storage choices\n3. **Update Event Bus**: Replace Kafka with your message broker (RabbitMQ, AWS SQS, Azure Service Bus, etc.)\n4. **Update Service Mesh**: Change Istio to your service mesh (Linkerd, Consul Connect, AWS App Mesh) or remove if not using one\n5. **Add/Remove Communication Flows**: Update arrows based on your actual service dependencies\n6. **Adjust Colors**: Modify the `classDef` styling to match your organization's standards\n\n**For detailed diagram creation and update instructions**, see [MERMAID_DIAGRAMS_GUIDE.md](../MERMAID_DIAGRAMS_GUIDE.md).\n\n---\n\n## Guidelines\n\n1. **Service independence**: Each microservice must be independently deployable\n2. **Database-per-service**: No shared databases between services\n3. **API-first design**: Well-defined APIs (OpenAPI/Swagger) for all services\n4. **Bounded contexts**: Align services with DDD bounded contexts\n5. **Decentralized governance**: Teams own their services end-to-end\n6. **Observability**: All services must emit logs, metrics, and traces\n7. **Resilience patterns**: Circuit breakers, retries, timeouts for all inter-service calls\n\n---\n\n## Validation Checklist\n\n- [ ] API Gateway documented with routing and authentication strategy\n- [ ] Service Mesh configured (or justification for not using one)\n- [ ] All microservices cataloged with bounded contexts\n- [ ] Database-per-service pattern followed\n- [ ] Event bus and topics documented\n- [ ] Synchronous and asynchronous communication patterns defined\n- [ ] Service discovery and configuration management specified\n- [ ] Observability stack documented (logging, metrics, tracing)\n- [ ] Resilience patterns implemented (circuit breakers, retries)\n- [ ] Each service has defined SLA and scaling strategy\n- [ ] Service topology diagram included showing services and communication patterns (Mermaid format recommended, see MERMAID_DIAGRAMS_GUIDE.md)",
        "skills/architecture-docs/templates/SECTION_4_NLAYER_PATTERNS.md": "# Section 4: Meta Architecture - N-Layer Architecture Patterns\n\n<!-- ARCHITECTURE_TYPE: N-LAYER -->\n\n**Purpose**: Define a layered architecture model with customizable layers following modern architectural patterns like Clean Architecture, DDD, or Hexagonal Architecture.\n\nThis template provides **predefined N-Layer patterns** that you can adapt to your system's needs. Choose the pattern that best matches your architectural approach.\n\n---\n\n## Available Patterns\n\nSelect one of the following predefined patterns, or customize based on your needs:\n\n1. **4-Layer Classic DDD** - Domain-Driven Design with clear separation\n2. **5-Layer Extended** - Additional cross-cutting layer for shared concerns\n3. **Clean Architecture** - Uncle Bob's concentric dependency model\n4. **Hexagonal Architecture (Ports & Adapters)** - Isolate core from external dependencies\n5. **Custom N-Layer** - Define your own layers\n\n---\n\n## Pattern 1: 4-Layer Classic DDD\n\n**Best For**: Domain-Driven Design implementations with clear domain model separation.\n\n**Layer Structure**:\n\n```\nLayer 1: Presentation (UI, API Controllers)\n    ‚Üì\nLayer 2: Application (Use Cases, Application Services)\n    ‚Üì\nLayer 3: Domain (Business Logic, Entities, Aggregates)\n    ‚Üì\nLayer 4: Infrastructure (Database, External Services)\n```\n\n**Dependency Rules**:\n- Presentation ‚Üí Application ‚Üí Domain\n- Infrastructure ‚Üí Domain (implements domain interfaces)\n- Domain has NO dependencies (pure business logic)\n\n### Layer Documentation Template\n\n#### Layer 1: Presentation\n\n**Purpose**: [User interface and external API exposure]\n\n**Components**:\n- Web UI: [Frontend technology]\n- API Controllers: [REST/GraphQL endpoints]\n- DTOs (Data Transfer Objects): [Request/response models]\n- View Models: [UI-specific models]\n\n**Technologies**:\n- Primary: [UI framework, API framework]\n- Supporting: [Serialization, validation]\n\n**Key Responsibilities**:\n- User input validation\n- Request routing\n- Response formatting\n- Authentication/authorization triggers\n- Session management\n\n**Dependency Direction**: Depends on Application layer\n\n**Non-Functional Requirements**:\n- Performance: [Response time targets]\n- Availability: [Uptime requirements]\n- Scalability: [Concurrent users]\n\n---\n\n#### Layer 2: Application\n\n**Purpose**: [Orchestrate use cases and application workflows]\n\n**Components**:\n- Application Services: [Use case implementations]\n- Command Handlers: [CQRS commands]\n- Query Handlers: [CQRS queries]\n- DTOs and Mappers: [Domain ‚Üî DTO conversion]\n\n**Technologies**:\n- Primary: [Application framework]\n- Supporting: [Mapping libraries, validation]\n\n**Key Responsibilities**:\n- Use case orchestration\n- Transaction boundaries\n- Application-level validation\n- DTO ‚Üî Domain model mapping\n- Coordination of domain operations\n\n**Dependency Direction**: Depends on Domain layer, defines interfaces for Infrastructure\n\n**Non-Functional Requirements**:\n- Performance: [Processing time]\n- Availability: [Stateless design]\n- Scalability: [Horizontal scaling]\n\n---\n\n#### Layer 3: Domain\n\n**Purpose**: [Pure business logic and domain model]\n\n**Components**:\n- Entities: [Business objects with identity]\n- Value Objects: [Immutable domain concepts]\n- Aggregates: [Consistency boundaries]\n- Domain Services: [Domain logic not belonging to entities]\n- Domain Events: [Business event definitions]\n- Repository Interfaces: [Data access abstractions]\n\n**Technologies**:\n- Primary: [Pure language - no frameworks]\n- Supporting: [None - framework-free]\n\n**Key Responsibilities**:\n- Business rule enforcement\n- Domain invariant protection\n- Domain event publishing\n- Aggregate consistency\n\n**Dependency Direction**: NO dependencies (isolated)\n\n**Non-Functional Requirements**:\n- Performance: [Pure logic, minimal overhead]\n- Testability: [100% unit test coverage goal]\n\n---\n\n#### Layer 4: Infrastructure\n\n**Purpose**: [External system integration and data persistence]\n\n**Components**:\n- Repository Implementations: [Data access code]\n- Database Context: [ORM configuration]\n- External Service Clients: [API clients, adapters]\n- File System Access: [File operations]\n- Messaging Clients: [Queue, pub/sub]\n\n**Technologies**:\n- Primary: [ORM, database, external SDKs]\n- Supporting: [Connection pooling, caching]\n\n**Key Responsibilities**:\n- Data persistence (implement repository interfaces)\n- External API integration\n- Infrastructure concerns (email, SMS, file storage)\n- Database migrations\n\n**Dependency Direction**: Depends on Domain layer (implements its interfaces)\n\n**Non-Functional Requirements**:\n- Performance: [Query optimization]\n- Availability: [Connection resilience]\n- Scalability: [Connection pooling, caching]\n\n---\n\n## Pattern 2: 5-Layer Extended\n\n**Best For**: Systems requiring explicit separation of cross-cutting concerns.\n\n**Layer Structure**:\n\n```\nLayer 1: Presentation (UI, API)\n    ‚Üì\nLayer 2: Application (Use Cases)\n    ‚Üì\nLayer 3: Domain (Business Logic)\n    ‚Üì\nLayer 4: Infrastructure (Persistence, External APIs)\n    ‚Üì\nLayer 5: Cross-Cutting (Logging, Security, Caching)\n```\n\nUse the 4-Layer template above, then add:\n\n#### Layer 5: Cross-Cutting\n\n**Purpose**: [Shared concerns across all layers]\n\n**Components**:\n- Logging Infrastructure: [Structured logging]\n- Security Services: [Authentication, authorization]\n- Caching Layer: [Distributed cache]\n- Monitoring/Telemetry: [Metrics, tracing]\n\n**Technologies**:\n- Primary: [Logging framework, cache, security framework]\n- Supporting: [APM tools, metrics libraries]\n\n**Key Responsibilities**:\n- Centralized logging\n- Security policy enforcement\n- Cache management\n- Performance monitoring\n- Exception handling\n\n**Dependency Direction**: Used by all other layers (referenced everywhere)\n\n**Non-Functional Requirements**:\n- Performance: [Minimal overhead]\n- Availability: [High availability]\n- Scalability: [Distributed design]\n\n---\n\n## Pattern 3: Clean Architecture (Concentric Layers)\n\n**Best For**: Systems emphasizing testability and dependency inversion.\n\n**Layer Structure** (from innermost to outermost):\n\n```\nCore: Entities (Domain Models)\n    ‚Üì\nLayer 1: Use Cases (Application Business Rules)\n    ‚Üì\nLayer 2: Interface Adapters (Controllers, Presenters, Gateways)\n    ‚Üì\nLayer 3: Frameworks & Drivers (UI, Database, External Services)\n```\n\n**Dependency Rule**: Dependencies point INWARD only.\n\n### Layer Documentation Template\n\n#### Core: Entities (Enterprise Business Rules)\n\n**Purpose**: [Core business logic independent of any framework]\n\n**Components**:\n- Entities: [Business objects with rules]\n- Value Objects: [Immutable domain concepts]\n- Domain Exceptions: [Business error cases]\n\n**Technologies**: Pure language (no frameworks)\n\n**Key Responsibilities**:\n- Enforce critical business rules\n- Define domain model\n- Pure, framework-agnostic logic\n\n**Dependency Direction**: NO dependencies\n\n---\n\n#### Layer 1: Use Cases (Application Business Rules)\n\n**Purpose**: [Application-specific business rules and workflows]\n\n**Components**:\n- Use Case Interactors: [Use case implementations]\n- Input/Output Ports: [Interfaces for data crossing boundaries]\n- Use Case DTOs: [Data structures for use cases]\n\n**Technologies**: [Minimal - application framework only]\n\n**Key Responsibilities**:\n- Orchestrate flow of data to/from entities\n- Direct entities to use business rules\n- Coordinate entity operations\n\n**Dependency Direction**: Depends only on Entities (core)\n\n---\n\n#### Layer 2: Interface Adapters\n\n**Purpose**: [Convert data between use cases and external systems]\n\n**Components**:\n- Controllers: [Handle HTTP requests]\n- Presenters: [Format responses]\n- Gateways: [Implement data access interfaces]\n- View Models: [UI-specific data structures]\n\n**Technologies**: [Web framework, ORM]\n\n**Key Responsibilities**:\n- Convert data formats\n- Adapt external interfaces to internal use cases\n- Implement repository interfaces\n- Format responses for UI\n\n**Dependency Direction**: Depends on Use Cases\n\n---\n\n#### Layer 3: Frameworks & Drivers\n\n**Purpose**: [External frameworks, tools, and drivers]\n\n**Components**:\n- Web Framework: [Express, Spring MVC, etc.]\n- Database: [PostgreSQL, MongoDB, etc.]\n- UI Framework: [React, Angular, etc.]\n- External Services: [Payment gateway, email service]\n\n**Technologies**: [All external frameworks and libraries]\n\n**Key Responsibilities**:\n- Framework configuration\n- Database setup and migrations\n- External service integration\n- UI rendering\n\n**Dependency Direction**: Depends on Interface Adapters (outermost layer)\n\n---\n\n## Pattern 4: Hexagonal Architecture (Ports & Adapters)\n\n**Best For**: Systems requiring high testability and swappable external dependencies.\n\n**Architecture Structure**:\n\n```\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ   Primary Adapters      ‚îÇ\n         ‚îÇ  (UI, REST API, CLI)    ‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                     ‚îÇ\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ      Primary Ports      ‚îÇ\n         ‚îÇ   (Inbound Interfaces)  ‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                     ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ          Application Core               ‚îÇ\n‚îÇ   (Domain Model + Business Logic)       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                     ‚îÇ\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ   Secondary Ports       ‚îÇ\n         ‚îÇ  (Outbound Interfaces)  ‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                     ‚îÇ\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ  Secondary Adapters     ‚îÇ\n         ‚îÇ (Database, External API)‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Component Documentation\n\n#### Application Core (Hexagon)\n\n**Purpose**: [Pure business logic isolated from external concerns]\n\n**Components**:\n- Domain Entities\n- Domain Services\n- Business Rules\n\n**Ports**:\n- Primary Ports (inbound): [Service interfaces for external callers]\n- Secondary Ports (outbound): [Repository and external service interfaces]\n\n**Technologies**: Pure language (framework-free)\n\n**Key Responsibilities**:\n- Implement business logic\n- Define port interfaces\n- Enforce domain rules\n\n---\n\n#### Primary Adapters (Driving Side)\n\n**Purpose**: [Adapt external inputs to application core]\n\n**Components**:\n- REST Controllers\n- GraphQL Resolvers\n- CLI Commands\n- Message Listeners\n\n**Technologies**: [Web framework, messaging framework]\n\n**Key Responsibilities**:\n- Receive external requests\n- Call primary ports\n- Convert requests to domain operations\n\n**Dependency Direction**: Depends on Primary Ports (application core interfaces)\n\n---\n\n#### Secondary Adapters (Driven Side)\n\n**Purpose**: [Implement secondary ports for external dependencies]\n\n**Components**:\n- Database Repositories\n- External API Clients\n- File System Adapters\n- Email/SMS Adapters\n\n**Technologies**: [ORM, HTTP clients, SDKs]\n\n**Key Responsibilities**:\n- Implement secondary port interfaces\n- Interact with external systems\n- Persist data\n\n**Dependency Direction**: Implements Secondary Ports (application core interfaces)\n\n---\n\n## Pattern 5: Custom N-Layer\n\n**Best For**: Systems with unique requirements not fitting standard patterns.\n\n**Instructions**: Define your own layers using this template.\n\n### Layer Template (Repeat for Each Layer)\n\n#### Layer N: [Layer Name]\n\n**Purpose**: [What this layer provides]\n\n**Position in Stack**: [Above layer X, Below layer Y]\n\n**Components**:\n- [Component 1]\n- [Component 2]\n\n**Technologies**:\n- Primary: [Main tech stack]\n- Supporting: [Additional technologies]\n\n**Key Responsibilities**:\n- [Responsibility 1]\n- [Responsibility 2]\n\n**Dependency Direction**: [What this layer depends on, what depends on it]\n\n**Communication Patterns**:\n- [How this layer communicates with adjacent layers]\n\n**Non-Functional Requirements**:\n- Performance: [Requirements]\n- Availability: [Requirements]\n- Scalability: [Requirements]\n\n---\n\n## Guidelines\n\n1. **Choose ONE pattern** and document it consistently\n2. **Respect dependency rules** specific to your chosen pattern\n3. **Document all layers** required by the pattern\n4. **Define clear boundaries** between layers\n5. **Use interfaces** at layer boundaries for testability\n6. **Avoid circular dependencies** between layers\n7. **Keep domain/core layers framework-free** (when applicable)\n\n---\n\n## Validation Checklist\n\n- [ ] Pattern selected and clearly identified\n- [ ] All layers required by pattern documented\n- [ ] Dependency direction rules documented and followed\n- [ ] Each layer has defined components and technologies\n- [ ] Layer boundaries clearly defined with interfaces\n- [ ] No circular dependencies between layers\n- [ ] Domain/core layer is framework-free (if applicable to pattern)\n- [ ] Infrastructure layer implements domain interfaces (if applicable)",
        "skills/architecture-docs/templates/SECTION_5_3TIER.md": "# Section 5: Component Details - 3-Tier Architecture\n\n<!-- ARCHITECTURE_TYPE: 3-TIER -->\n\n**Purpose**: Deep dive into each component within the three tiers (Presentation, Application/Business Logic, Data), providing detailed technical specifications and operational characteristics.\n\nThis template organizes components by their tier assignment.\n\n---\n\n## Component Documentation Guidelines\n\nFor each component in your system, document using the template below. **Group components by their tier.**\n\n---\n\n## Tier 1: Presentation Layer - Components\n\n### [Component Name]\n\n**Type**: Web UI | API Controller | REST Endpoint | GraphQL Resolver | Client App\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path or repository]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Endpoints/Routes** (if API):\n- `GET /api/resource`: [Description]\n- `POST /api/resource`: [Description]\n- `PUT /api/resource/{id}`: [Description]\n\n**UI Features** (if Web/Mobile):\n- Feature 1: [Description]\n- Feature 2: [Description]\n\n**Dependencies**:\n- Depends on: [Tier 2 (Application) services]\n- Depended by: [End users, client applications]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Response time, request rate, error rate]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Tier 2: Application/Business Logic Layer - Components\n\n### [Component Name]\n\n**Type**: Application Service | Business Service | Domain Service | Integration Client\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Public Methods/API**:\n- `methodName(params)`: [Description, return type]\n- `methodName2(params)`: [Description, return type]\n\n**Business Rules**:\n- Rule 1: [Description]\n- Rule 2: [Description]\n\n**Dependencies**:\n- Depends on: [Tier 3 (Data) repositories, external services]\n- Depended by: [Tier 1 (Presentation) controllers]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, stateless design]\n- Vertical: [Limits, resource requirements]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Processing time, throughput, business metrics]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Tier 3: Data Layer - Components\n\n### [Component Name]\n\n**Type**: Database | Repository | Cache | Data Access Object (DAO) | File Storage\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path or database instance]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Schema** (if database):\n- Tables: [List key tables]\n- Indexes: [Key indexes]\n- Relationships: [Key foreign keys]\n\n**Data Access Methods** (if repository):\n- `findById(id)`: [Description]\n- `save(entity)`: [Description]\n- `findByCriteria(criteria)`: [Description]\n\n**Dependencies**:\n- Depends on: [Database server, file system, cache server]\n- Depended by: [Tier 2 (Application) services]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Read replicas, sharding]\n- Vertical: [CPU, memory, storage limits]\n\n**Backup & Recovery**:\n- Backup Frequency: [Daily, hourly, real-time]\n- Retention Policy: [How long backups kept]\n- Recovery Time Objective (RTO): [Target recovery time]\n- Recovery Point Objective (RPO): [Maximum data loss]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Query latency, connection count, storage usage]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Example: User API Controller (Tier 1: Presentation)\n\n### User API Controller\n\n**Type**: REST API Controller\n**Technology**: Express.js 4.18 (Node.js)\n**Version**: v2.1.0\n**Location**: `src/controllers/UserController.ts` (example path)\n\n**Purpose**:\nExpose REST endpoints for user account management (create, read, update, delete).\n\n**Responsibilities**:\n- Handle HTTP requests for user operations\n- Validate request payloads using JSON schemas\n- Map HTTP requests to application service calls\n- Format responses (JSON) and set appropriate HTTP status codes\n- Handle authentication via JWT middleware\n\n**Endpoints/Routes**:\n- `POST /api/v1/users`: Create new user account\n- `GET /api/v1/users/{id}`: Retrieve user by ID\n- `PUT /api/v1/users/{id}`: Update user profile\n- `DELETE /api/v1/users/{id}`: Soft-delete user account\n- `GET /api/v1/users`: List users with pagination\n\n**Dependencies**:\n- Depends on: UserService (Tier 2), AuthMiddleware (Tier 2)\n- Depended by: Web clients, mobile apps\n\n**Configuration**:\n- `MAX_PAGE_SIZE`: Maximum items per page (default: 100)\n- `REQUEST_TIMEOUT`: Request timeout in ms (default: 5000)\n\n**Scaling**:\n- Horizontal: Yes, stateless controller scales linearly\n- Vertical: 1 vCPU, 512MB RAM per instance\n\n**Failure Modes**:\n- UserService unavailable: Return 503 Service Unavailable\n- Validation failure: Return 400 Bad Request with error details\n- Unauthorized: Return 401 Unauthorized\n\n**Monitoring**:\n- Key metrics: Request rate, p95 latency, 4xx/5xx error rates\n- Alerts: Error rate > 2%, p99 latency > 1s\n- Logs: All requests (HTTP method, path, status, duration), validation errors\n\n---\n\n## Example: User Service (Tier 2: Application/Business Logic)\n\n### User Service\n\n**Type**: Application Service\n**Technology**: TypeScript, NestJS 10\n**Version**: v2.1.0\n**Location**: `src/services/UserService.ts` (example path)\n\n**Purpose**:\nImplement business logic for user account lifecycle and profile management.\n\n**Responsibilities**:\n- User registration with email verification\n- Password hashing and validation (bcrypt)\n- Enforce business rules (e.g., unique email, password complexity)\n- Coordinate user creation workflow (create user ‚Üí send email ‚Üí log event)\n- Role assignment and permission management\n\n**Public Methods/API**:\n- `createUser(userData: CreateUserDto): Promise<User>`: Register new user\n- `getUserById(id: string): Promise<User>`: Retrieve user by ID\n- `updateUser(id: string, updates: UpdateUserDto): Promise<User>`: Update profile\n- `deleteUser(id: string): Promise<void>`: Soft-delete user\n\n**Business Rules**:\n- Email must be unique across all users\n- Password must be at least 8 characters with uppercase, lowercase, and number\n- Users can only update their own profiles (unless admin role)\n- Deleted users retain data for 30 days before permanent deletion\n\n**Dependencies**:\n- Depends on: UserRepository (Tier 3), EmailService (Tier 2), AuditLogger (Tier 2)\n- Depended by: UserController (Tier 1), AuthService (Tier 2)\n\n**Configuration**:\n- `BCRYPT_ROUNDS`: Password hashing cost (default: 12)\n- `EMAIL_VERIFICATION_TTL`: Verification link expiry in hours (default: 24)\n\n**Scaling**:\n- Horizontal: Yes, stateless service scales linearly\n- Vertical: 2 vCPU, 2GB RAM per instance\n\n**Failure Modes**:\n- UserRepository unavailable: Throw ServiceUnavailable exception\n- EmailService fails: User created, email queued for retry\n- Duplicate email: Throw ConflictException\n\n**Monitoring**:\n- Key metrics: User creation rate, update rate, business rule violations\n- Alerts: Creation failure rate > 1%, slow queries (>500ms)\n- Logs: All service calls, business rule violations, errors\n\n---\n\n## Example: User Repository (Tier 3: Data)\n\n### User Repository\n\n**Type**: Data Access Object (DAO) / Repository\n**Technology**: TypeORM 0.3\n**Version**: v2.1.0\n**Location**: `src/repositories/UserRepository.ts` (example path)\n\n**Purpose**:\nProvide data access layer for User entity persistence to PostgreSQL database.\n\n**Responsibilities**:\n- CRUD operations for User entity\n- Query optimization and indexing\n- Transaction management for multi-table operations\n- Database connection pooling\n\n**Schema** (PostgreSQL):\n- **Table**: `users`\n  - Columns: `id` (UUID PK), `email` (VARCHAR UNIQUE), `password_hash`, `created_at`, `updated_at`, `deleted_at` (soft delete)\n- **Indexes**:\n  - `idx_users_email` on `email` (UNIQUE)\n  - `idx_users_deleted_at` on `deleted_at` (for soft delete queries)\n\n**Data Access Methods**:\n- `findById(id: string): Promise<User | null>`: Find user by primary key\n- `findByEmail(email: string): Promise<User | null>`: Find by email (unique)\n- `save(user: User): Promise<User>`: Insert or update user\n- `softDelete(id: string): Promise<void>`: Soft delete (set deleted_at)\n\n**Dependencies**:\n- Depends on: PostgreSQL 15 database server\n- Depended by: UserService (Tier 2)\n\n**Configuration**:\n- `DB_HOST`: Database host (default: localhost)\n- `DB_PORT`: Database port (default: 5432)\n- `DB_CONNECTION_POOL_SIZE`: Max connections (default: 20)\n\n**Scaling**:\n- Horizontal: Read replicas for read-heavy queries\n- Vertical: 4 vCPU, 16GB RAM for database server\n\n**Backup & Recovery**:\n- Backup Frequency: Daily full backup, hourly incremental\n- Retention Policy: 30 days\n- Recovery Time Objective (RTO): <1 hour\n- Recovery Point Objective (RPO): <1 hour (max data loss)\n\n**Failure Modes**:\n- Database connection pool exhausted: Queue requests, alert on timeout\n- Primary database down: Fail over to read replica (read-only mode)\n- Slow query: Log query, alert if >100ms\n\n**Monitoring**:\n- Key metrics: Query latency (p50/p95/p99), connection pool usage, disk I/O\n- Alerts: Query latency > 100ms, connection pool >80% utilized\n- Logs: Slow queries (>50ms), connection errors, transaction rollbacks\n\n---\n\n## Guidelines\n\n1. **Document all components** in each tier\n2. **Group components by tier** for clarity\n3. **No direct database access from Tier 1** - enforce tier separation\n4. **Tier 2 must be stateless** for horizontal scalability\n5. **Quantify metrics** in Monitoring section\n6. **Include realistic failure modes** with mitigation strategies\n7. **Cross-reference tiers** in Dependencies section\n\n---\n\n## Validation Checklist\n\n- [ ] Components documented for all 3 tiers\n- [ ] Each component includes all required subsections\n- [ ] Tier 1 (Presentation) components do NOT access Tier 3 (Data) directly\n- [ ] Tier 2 (Application) components are stateless\n- [ ] Tier 3 (Data) includes backup/recovery strategy\n- [ ] Dependencies clearly reference tier numbers\n- [ ] Failure modes include realistic impact and mitigation\n- [ ] Monitoring includes specific metrics (not placeholders)\n- [ ] Example paths updated to match actual project structure",
        "skills/architecture-docs/templates/SECTION_5_BIAN.md": "# Section 5: Component Details - BIAN Architecture\n\n<!-- ARCHITECTURE_TYPE: BIAN -->\n\n**Purpose**: Deep dive into each component within every BIAN layer, providing detailed technical specifications aligned with BIAN V12.0 standards.\n\nThis template organizes components by their BIAN layer assignment (Channels ‚Üí BIAN Business Scenarios ‚Üí BIAN Business Capabilities ‚Üí BIAN Service Domains ‚Üí Core Systems).\n\n**BIAN V12.0 Standard**: For Layer 4 (BIAN Service Domains), **full BIAN V12.0 compliance is mandatory**. All service domains must be validated against the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) for accurate naming and complete metadata documentation.\n\n---\n\n## Component Documentation Guidelines\n\nFor each component in your system, document using the template below. **Group components by their BIAN layer.**\n\n**Critical BIAN Compliance Requirement**: All Layer 4 (BIAN Service Domains) components MUST include complete BIAN V12.0 metadata, control records, service operations, behavior qualifiers, and functional patterns as defined in the official BIAN specification.\n\n---\n\n## Layer 1: Channels - Components\n\n### [Channel Component Name]\n\n**Type**: Mobile App | Web Application | ATM Interface | Branch Terminal | API Gateway | Chatbot\n**Technology**: [Specific technology used - e.g., React Native, Angular, Java]\n**Version**: [Version number]\n**Location**: [Package/directory path or repository]\n\n**Purpose**:\n[1-2 sentence description of what this channel provides to users]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Channel Capabilities**:\n- Authentication: [Biometric, PIN, password, MFA]\n- User interactions: [List key user flows]\n- Session management: [How sessions are managed]\n- Offline support: [If applicable]\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints consumed from Layer 2]\n- API 2: [Description, protocols]\n\n**Dependencies**:\n- Depends on: [Layer 2 (BIAN Business Scenarios) components]\n- Depended by: [End users, external clients]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation - e.g., backend unavailable ‚Üí offline mode]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Active users, response time, error rate]\n- Alerts: [Alert conditions - e.g., error rate > 5%]\n- Logs: [What is logged - authentication attempts, transactions, errors]\n\n---\n\n## Layer 2: BIAN Business Scenarios - Components\n\n### [Business Scenario Component Name]\n\n**BIAN Business Area Alignment**: [Sales and Service | Reference Data | Operations and Execution | Risk and Compliance | Business Support]\n\n**Type**: Scenario Orchestrator | Process Engine | Business Rules Engine | Workflow Manager\n**Technology**: [Specific technology used - e.g., Camunda, Apache Airflow]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this business scenario orchestrates]\n\n**BIAN Business Area Mapping**:\n- **Primary BIAN Business Area**: [From the 5 BIAN Business Areas]\n- **Official BIAN Reference**: [Link to BIAN V12.0 Business Area definition]\n- **BIAN Business Domains Involved**: [List of Business Domains from Layer 3]\n\n**Responsibilities**:\n- Orchestrate end-to-end business scenario\n- Coordinate BIAN Business Capabilities (Layer 3) to fulfill scenario\n- Apply business rules and policies at scenario level\n- Manage scenario state and lifecycle\n- [Additional scenario-specific responsibilities]\n\n**Scenario Flows**:\n- Flow 1: [Description - e.g., \"Customer Onboarding\" involves Party Management, Account Opening]\n- Flow 2: [Description - e.g., \"Payment Processing\" involves Payment Order, Payment Execution]\n\n**APIs/Interfaces**:\n- API 1: [REST/GraphQL endpoints for scenario initiation]\n- API 2: [Event-driven interfaces for scenario coordination]\n\n**Dependencies**:\n- Depends on: [Layer 3 (BIAN Business Capabilities) components]\n- Depended by: [Layer 1 (Channels) and external systems]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach - e.g., stateless orchestration]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation - e.g., downstream capability unavailable ‚Üí compensating transaction]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Scenario completion rate, orchestration latency, failure rate]\n- Alerts: [Alert conditions - e.g., scenario failure rate > 2%]\n- Logs: [Scenario lifecycle events, decision points, errors]\n\n---\n\n## Layer 3: BIAN Business Capabilities - Components\n\n### [Business Capability Component Name]\n\n**BIAN Business Domain Alignment**: [From 30+ BIAN Business Domains - e.g., Payments, Customer Management, Loans and Deposits]\n\n**Type**: Business Capability Service | API Layer | Domain Coordinator\n**Technology**: [Specific technology used - e.g., Spring Boot, Node.js]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this business capability manages]\n\n**BIAN Business Domain Mapping**:\n- **Primary BIAN Business Domain**: [Official BIAN Business Domain name]\n- **BIAN Business Area**: [Parent Business Area from Layer 2]\n- **Official BIAN Reference**: [Link to BIAN V12.0 Business Domain definition]\n- **BIAN Service Domains Coordinated**: [List of Service Domains from Layer 4]\n\n**Responsibilities**:\n- Implement BIAN Business Domain logic\n- Coordinate BIAN Service Domains (Layer 4) within this business domain\n- Expose business capability through standardized APIs\n- Manage business domain state and lifecycle\n- Enforce business domain policies and rules\n- [Additional capability-specific responsibilities]\n\n**Business Domain Operations**:\n- Operation 1: [Description - e.g., \"Initiate Payment\" coordinates Payment Order and Payment Execution service domains]\n- Operation 2: [Description - e.g., \"Validate Customer\" coordinates Party Authentication and Customer Profile service domains]\n\n**APIs/Interfaces**:\n- Business Capability API: [REST/gRPC endpoints]\n- Domain Events: [Event-driven integration points]\n\n**Dependencies**:\n- Depends on: [Layer 4 (BIAN Service Domains) components]\n- Depended by: [Layer 2 (BIAN Business Scenarios) components]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation - e.g., service domain unavailable ‚Üí fallback to alternative]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Capability invocation rate, coordination latency, success rate]\n- Alerts: [Alert conditions - e.g., coordination failure > 3%]\n- Logs: [Domain operations, service domain coordination, errors]\n\n---\n\n## Layer 4: BIAN Service Domains - Components\n\n**CRITICAL**: All Layer 4 components MUST be BIAN V12.0 compliant service domains validated against the [official BIAN Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html).\n\n### [Official BIAN Service Domain Name]\n\n**BIAN Metadata** (MANDATORY - All fields required):\n\n- **Official BIAN Name**: [Exact name from BIAN V12.0 Service Landscape - e.g., \"Payment Order\", \"Current Account\", \"Party Authentication\"]\n- **BIAN ID**: [Internal tracking ID - e.g., SD-001, SD-002, SD-003]\n- **BIAN Version**: V12.0 (mandatory)\n- **BIAN Business Domain**: [Parent business domain - e.g., \"Payments\", \"Loans and Deposits\", \"Customer Management\"]\n- **BIAN Business Area**: [Parent business area - e.g., \"Operations and Execution\", \"Sales and Service\"]\n- **BIAN Service Landscape URL**: [Direct link to this service domain in BIAN V12.0 - https://bian.org/servicelandscape-12-0-0/views/view_51891.html]\n\n**Control Record** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n- **Control Record Type**: [As defined in BIAN spec - e.g., \"PaymentOrderProcedure\", \"CurrentAccountFulfillmentArrangement\"]\n- **Control Record Structure**:\n  - Field 1: [Name, type, description per BIAN spec]\n  - Field 2: [Name, type, description per BIAN spec]\n  - Field 3: [Name, type, description per BIAN spec]\n- **Lifecycle States**: [Active, Completed, Suspended, Cancelled - per BIAN]\n- **State Transitions**: [Document allowed state transitions per BIAN spec]\n\n**Service Operations** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\nAll BIAN service domains MUST implement the following service operations as defined in BIAN V12.0:\n\n1. **Initiate**:\n   - **Purpose**: Create new control record\n   - **Input**: [Required fields per BIAN spec]\n   - **Output**: [Control record instance]\n   - **API Endpoint**: `POST /service-domain/initiate`\n\n2. **Update**:\n   - **Purpose**: Modify existing control record\n   - **Input**: [Control record ID, update fields per BIAN spec]\n   - **Output**: [Updated control record]\n   - **API Endpoint**: `PUT /service-domain/{id}/update`\n\n3. **Retrieve**:\n   - **Purpose**: Query control record\n   - **Input**: [Control record ID or query parameters]\n   - **Output**: [Control record data]\n   - **API Endpoint**: `GET /service-domain/{id}/retrieve`\n\n4. **Control**:\n   - **Purpose**: Manage control record lifecycle (suspend, resume, terminate)\n   - **Input**: [Control record ID, control action]\n   - **Output**: [Updated control record with new state]\n   - **API Endpoint**: `PUT /service-domain/{id}/control`\n\n5. **Exchange** (if applicable):\n   - **Purpose**: [Per BIAN spec for this service domain]\n   - **API Endpoint**: `PUT /service-domain/{id}/exchange`\n\n6. **Execute** (if applicable):\n   - **Purpose**: [Per BIAN spec for this service domain]\n   - **API Endpoint**: `POST /service-domain/{id}/execute`\n\n7. **Request** (if applicable):\n   - **Purpose**: [Per BIAN spec for this service domain]\n   - **API Endpoint**: `POST /service-domain/{id}/request`\n\n**Behavior Qualifiers** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\nDocument all behavior qualifiers defined in BIAN V12.0 for this service domain:\n- Qualifier 1: [Name, description per BIAN spec - e.g., \"registration\", \"valuation\", \"reporting\"]\n- Qualifier 2: [Name, description per BIAN spec]\n- Qualifier 3: [Name, description per BIAN spec]\n\n**Functional Patterns** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n- **Pattern Type**: [Managed Object | Tracked Object | Administered Object | Governed Object | Monitored Object | etc.]\n- **Pattern Description**: [How this service domain implements the BIAN functional pattern]\n- **Pattern Implications**: [What the pattern means for service operations and lifecycle]\n\n---\n\n**Implementation Details**:\n\n**Type**: BIAN Service Domain | Microservice\n**Technology**: [Language/framework - e.g., Java/Spring Boot, Node.js, Python]\n**Version**: [Version number]\n**Location**: [Repository URL or directory path]\n**Team Owner**: [Team responsible for this service domain]\n\n**Purpose**:\n[1-2 sentence description aligned with BIAN V12.0 service domain definition]\n\n**Responsibilities**:\n- Implement BIAN V12.0 service domain [name]\n- Maintain control records per BIAN specifications\n- Expose all mandatory BIAN service operations\n- Implement BIAN behavior qualifiers\n- Publish domain events for state changes\n- [Additional domain-specific responsibilities]\n\n**API Specification**:\n\n**API Type**: REST | gRPC\n**Base URL**: `/bian/v12/[service-domain-name]`\n**Authentication**: [JWT, mTLS, OAuth 2.0]\n\n**BIAN Service Operations Endpoints**:\n\n| Service Operation | Method | Path | Description | BIAN Compliance |\n|------------------|--------|------|-------------|-----------------|\n| Initiate | POST | `/initiate` | Create new control record | Mandatory |\n| Update | PUT | `/{id}/update` | Modify control record | Mandatory |\n| Retrieve | GET | `/{id}/retrieve` | Query control record | Mandatory |\n| Control | PUT | `/{id}/control` | Manage lifecycle | Mandatory |\n| Exchange | PUT | `/{id}/exchange` | [If applicable per BIAN] | Optional |\n| Execute | POST | `/{id}/execute` | [If applicable per BIAN] | Optional |\n\n**OpenAPI Spec**: [Link to BIAN-compliant OpenAPI documentation]\n\n---\n\n**Data Management**:\n\n**Database Type**: [PostgreSQL, MongoDB, etc.]\n**Database Name**: [service_domain_db]\n**Schema**: [Link to schema aligned with BIAN control record structure]\n\n**Data Ownership**: [What data this service domain is the source of truth for - aligned with BIAN control record]\n\n**Control Record Persistence**:\n- Table/Collection: [Name - e.g., payment_order_procedures]\n- Primary Key: [Control record ID]\n- BIAN Alignment: [How database schema maps to BIAN control record structure]\n\n**Consistency Model**: [Strong consistency | Eventual consistency]\n\n---\n\n**Event-Driven Communication**:\n\n**Events Published** (Domain Events):\n\n| Event Name | Trigger | Payload | Schema Version | Consumers |\n|------------|---------|---------|----------------|-----------|\n| `[service-domain].initiated` | Control record created | Control record ID, key fields | v1 | [List service domains] |\n| `[service-domain].updated` | Control record modified | Control record ID, changed fields | v1 | [List service domains] |\n| `[service-domain].completed` | Control record completed | Control record ID, completion data | v1 | [List service domains] |\n\n**Events Consumed**:\n\n| Event Name | Source Service Domain | Action Taken | Idempotency |\n|------------|----------------------|--------------|-------------|\n| `[other-domain].[event]` | [BIAN Service Domain name] | [What this service domain does] | [How ensured] |\n\n**Event Bus**: [Kafka, RabbitMQ, etc.]\n\n---\n\n**Service Dependencies**:\n\n**Upstream BIAN Service Domains** (this service domain depends on):\n- Service Domain 1: [Official BIAN name, what operations]\n- Service Domain 2: [Official BIAN name, what operations]\n\n**Downstream BIAN Service Domains** (depend on this service domain):\n- Service Domain 3: [Official BIAN name, what operations]\n\n**Layer 3 Dependencies**:\n- Business Capability: [Which BIAN Business Capability coordinates this service domain]\n\n**Layer 5 Dependencies**:\n- Core System: [Which core systems this service domain integrates with]\n\n**Dependency Graph**: [Link to BIAN service domain dependency visualization]\n\n**Circuit Breaker Configuration**:\n- Failure threshold: [e.g., 50% errors over 10 requests]\n- Timeout: [e.g., 5 seconds]\n- Fallback strategy: [e.g., Return cached data, degrade gracefully]\n\n---\n\n**BIAN Compliance Documentation**:\n\n**Compliance Level**: Full BIAN V12.0 Compliance (required for BIAN architecture type)\n\n**Validation Details**:\n- **BIAN Service Domain Name**: ‚úÖ Validated against [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- **Control Record Structure**: ‚úÖ Aligned with BIAN V12.0 specification\n- **Service Operations**: ‚úÖ All mandatory operations implemented (Initiate, Update, Retrieve, Control)\n- **Behavior Qualifiers**: ‚úÖ Documented per BIAN spec\n- **Functional Pattern**: ‚úÖ Implemented per BIAN spec ([Pattern Type])\n- **Validation Date**: [Date compliance was verified]\n\n**Deviations from BIAN Standard**:\n- [None for full compliance]\n- [Or document any customizations/extensions with justification]\n\n**BIAN Traceability**:\n- **Service Domain** ‚Üí **Business Domain** ‚Üí **Business Area**\n- [Service Domain Name] ‚Üí [Business Domain Name] ‚Üí [Business Area Name]\n\n---\n\n**Configuration**:\n\n**Environment Variables**:\n- `VAR_NAME`: [Description, default value, required/optional]\n\n**BIAN Configuration**:\n- `BIAN_VERSION`: V12.0 (fixed)\n- `BIAN_COMPLIANCE_MODE`: STRICT | EXTENDED\n- `CONTROL_RECORD_RETENTION`: [Retention policy for control records]\n\n**Configuration Source**: [Spring Cloud Config, Consul KV, ConfigMap, etc.]\n\n---\n\n**Deployment & Scaling**:\n\n**Container Image**: [Repository/image:tag]\n\n**Resource Requirements**:\n- CPU: [Requests: 500m, Limits: 1000m]\n- Memory: [Requests: 512Mi, Limits: 1Gi]\n\n**Replicas**:\n- Minimum: [e.g., 2]\n- Maximum: [e.g., 10]\n\n**Auto-Scaling**:\n- Metric: [CPU utilization, request rate, custom metric]\n- Threshold: [e.g., 70% CPU]\n- Scale-up policy: [How aggressive]\n- Scale-down policy: [How conservative]\n\n**Health Checks**:\n- Liveness: `GET /health/liveness` [interval, threshold]\n- Readiness: `GET /health/readiness` [interval, threshold]\n- BIAN Health: `GET /bian/health` [service operation health check]\n\n---\n\n**Resilience & Fault Tolerance**:\n\n**Failure Modes**:\n\n| Failure | Impact | Mitigation | Detection |\n|---------|--------|------------|-----------|\n| Database unavailable | Cannot persist control records | Circuit breaker, return 503 | Health check |\n| Dependent service domain down | Cannot complete operations | Timeout + retry, fallback | Circuit breaker |\n| Event bus unavailable | Events not published | Local event store, retry on reconnect | Connection monitor |\n\n**Retry Policy**:\n- Max retries: [e.g., 3]\n- Backoff strategy: [Exponential backoff, fixed delay]\n- Retry-eligible errors: [List error types]\n\n---\n\n**Observability**:\n\n**Logging**:\n- Level: [INFO in prod, DEBUG in dev]\n- Format: [JSON structured logging]\n- BIAN Fields: [Control record ID, service operation, BIAN version, compliance status]\n- Aggregation: [ELK, Splunk, CloudWatch]\n\n**Metrics**:\n- BIAN service operation rate (operations/second by operation type)\n- Control record lifecycle metrics (created, updated, completed)\n- BIAN compliance metrics (validation success rate)\n- Response latency by service operation (p50, p95, p99)\n- Error rate by service operation\n- Collection: [Prometheus, Datadog, CloudWatch]\n\n**Distributed Tracing**:\n- Tracing system: [Jaeger, Zipkin, OpenTelemetry]\n- BIAN trace context: [Service domain name, control record ID, operation type]\n\n**Alerts**:\n- BIAN service operation error rate > 5% ‚Üí Page on-call\n- Control record state inconsistency detected ‚Üí Alert architect\n- BIAN compliance validation failure ‚Üí Immediate alert\n\n---\n\n**Security**:\n\n**Authentication**: [How clients authenticate - JWT, mTLS, API Gateway]\n\n**Authorization**: [RBAC based on BIAN service operations - who can Initiate, Update, Control]\n\n**Secrets Management**: [HashiCorp Vault, AWS Secrets Manager, etc.]\n\n**Encryption**:\n- In-transit: [TLS 1.3, mTLS]\n- At-rest: [Database encryption for control records]\n\n**BIAN Security Compliance**:\n- Control record access control per BIAN spec\n- Service operation authorization per BIAN roles\n\n---\n\n**Testing Strategy**:\n\n**Unit Tests**: [Coverage target, framework]\n\n**Integration Tests**: [Test BIAN service operations with Testcontainers]\n\n**BIAN Compliance Tests**:\n- Validate control record structure against BIAN V12.0 spec\n- Test all mandatory service operations (Initiate, Update, Retrieve, Control)\n- Verify behavior qualifiers implementation\n- Test functional pattern adherence\n\n**Contract Tests**: [Pact, Spring Cloud Contract for service domain contracts]\n\n**End-to-End Tests**: [Critical BIAN scenarios tested]\n\n---\n\n## Layer 5: Core Systems - Components\n\n### [Core System Name]\n\n**Type**: Core Banking System | Mainframe | Legacy System | Transaction Processor | Master Data Management\n**Technology**: [Specific technology used - e.g., Finacle, Temenos T24, IBM z/OS]\n**Version**: [Version number]\n**Location**: [Data center, on-premise, cloud]\n\n**Purpose**:\n[1-2 sentence description of core system and its role]\n\n**Responsibilities**:\n- Provide system of record for core banking data\n- Process critical banking transactions\n- Maintain account balances and ledgers\n- Support BIAN Service Domains (Layer 4) with foundational services\n- [Additional core system responsibilities]\n\n**APIs/Interfaces**:\n- Legacy API: [Description, protocols - e.g., SOAP, REST, MQ]\n- File Interfaces: [File formats, schedules - e.g., ISO20022, batch files]\n- Batch Processes: [Batch jobs, schedules - e.g., end-of-day processing]\n\n**Dependencies**:\n- Depends on: [Other core systems, databases, mainframe]\n- Depended by: [Layer 4 (BIAN Service Domains) components]\n\n**BIAN Integration**:\n- **Adapter Pattern**: [How core systems are wrapped to support BIAN Service Domains]\n- **Data Synchronization**: [How core data is synchronized with BIAN service domains]\n- **Transaction Coordination**: [How distributed transactions are managed]\n- **Event Publishing**: [How core system events are published to BIAN layers]\n\n**Modernization Strategy**:\n- **Current State**: [Assessment of legacy systems and technical debt]\n- **Target State**: [Modernization goals aligned with BIAN architecture]\n- **Migration Approach**: [Strangler pattern, lift-and-shift, progressive modernization]\n- **BIAN Alignment**: [How modernization supports BIAN service domain implementation]\n- **Phased Approach**: [Timeline and phases to minimize business disruption]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Typically N/A for legacy systems]\n- Vertical: [Capacity planning, resource limits]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation - e.g., core banking unavailable ‚Üí BIAN service domains circuit break]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Transaction processing rate, batch job completion, system availability]\n- Alerts: [Alert conditions - e.g., batch job failure, transaction queue backlog]\n- Logs: [Transaction logs, audit trails, error logs]\n\n---\n\n## Example: Mobile Banking App (Layer 1: Channels)\n\n### Mobile Banking App\n\n**Type**: Mobile Application\n**Technology**: React Native 0.72, TypeScript\n**Version**: v4.2.1\n**Location**: `repos/mobile-banking-app`\n\n**Purpose**:\nProvide retail customers with mobile access to banking services on iOS and Android, offering account management, payments, and financial services through a native mobile experience.\n\n**Responsibilities**:\n- User authentication with biometrics (Face ID, Touch ID, fingerprint)\n- Account balance and transaction history display\n- Fund transfers (internal and external)\n- Bill payments and beneficiary management\n- Mobile check deposit (scan and submit)\n- Push notifications for account alerts\n\n**Channel Capabilities**:\n- Authentication: Biometric (Face ID/Touch ID), 6-digit PIN, password with MFA\n- User interactions: Account overview, transactions, transfers, bill pay, settings\n- Session management: 5-minute inactivity timeout, secure token refresh\n- Offline support: Cached account data, queued transactions sync on reconnect\n\n**APIs/Interfaces**:\n- Mobile BFF API: Consumes `/api/mobile/v2/*` from Layer 2 (Business Scenarios)\n- OAuth 2.0: Authentication flow with Auth0\n- Push Notifications: Firebase Cloud Messaging (FCM)\n\n**Dependencies**:\n- Depends on: Mobile BFF (Layer 2), Auth0 (external authentication)\n- Depended by: Retail banking customers (500K monthly active users)\n\n**Configuration**:\n- `API_BASE_URL`: Backend API URL (per environment: dev, staging, prod)\n- `OAUTH_CLIENT_ID`: OAuth client identifier\n- `SESSION_TIMEOUT`: Inactivity timeout (default: 300 seconds)\n- `BIOMETRIC_ENABLED`: Enable biometric authentication (default: true)\n\n**Scaling**:\n- Horizontal: N/A (client-side application)\n- Vertical: N/A\n\n**Failure Modes**:\n- Backend API unavailable: Show cached data, queue transactions for sync\n- Network connectivity loss: Offline mode with read-only access, sync on reconnect\n- Authentication service down: Users cannot log in, show maintenance message\n- Push notification failure: Fallback to in-app notification badge\n\n**Monitoring**:\n- Key metrics: Monthly active users (MAU), daily active users (DAU), app crash rate, API call success rate\n- Alerts: Crash rate > 1%, API error rate > 5%, login failure rate > 10%\n- Logs: Authentication attempts, transaction requests, API errors, crashes (via Crashlytics)\n\n---\n\n## Example: Payment Order Service Domain (Layer 4: BIAN Service Domains)\n\n### Payment Order\n\n**BIAN Metadata** (MANDATORY):\n\n- **Official BIAN Name**: Payment Order\n- **BIAN ID**: SD-001 (internal tracking)\n- **BIAN Version**: V12.0\n- **BIAN Business Domain**: Payments\n- **BIAN Business Area**: Operations and Execution\n- **BIAN Service Landscape URL**: https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n\n**Control Record** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n- **Control Record Type**: PaymentOrderProcedure\n- **Control Record Structure**:\n  - Payment Order ID: UUID (primary key)\n  - Payer Party Reference: UUID (customer initiating payment)\n  - Payee Party Reference: UUID (payment recipient)\n  - Payment Amount: DECIMAL (amount and currency)\n  - Payment Date: TIMESTAMP (value date)\n  - Payment Status: ENUM (Initiated, Validated, Executing, Completed, Failed, Cancelled)\n  - Payment Instructions: TEXT (payment details and references)\n- **Lifecycle States**: Initiated, Validated, Executing, Completed, Failed, Cancelled\n- **State Transitions**: Initiated ‚Üí Validated ‚Üí Executing ‚Üí Completed/Failed; Any state ‚Üí Cancelled\n\n**Service Operations** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n1. **Initiate**:\n   - **Purpose**: Create new payment order\n   - **Input**: Payer, payee, amount, currency, payment instructions\n   - **Output**: Payment Order control record with status \"Initiated\"\n   - **API Endpoint**: `POST /bian/v12/payment-order/initiate`\n\n2. **Update**:\n   - **Purpose**: Modify payment order details (before execution)\n   - **Input**: Payment Order ID, updated fields\n   - **Output**: Updated Payment Order control record\n   - **API Endpoint**: `PUT /bian/v12/payment-order/{id}/update`\n\n3. **Retrieve**:\n   - **Purpose**: Query payment order status and details\n   - **Input**: Payment Order ID or query parameters\n   - **Output**: Payment Order control record\n   - **API Endpoint**: `GET /bian/v12/payment-order/{id}/retrieve`\n\n4. **Control**:\n   - **Purpose**: Manage payment order lifecycle (cancel, suspend, resume)\n   - **Input**: Payment Order ID, control action (cancel, suspend, resume)\n   - **Output**: Updated Payment Order with new status\n   - **API Endpoint**: `PUT /bian/v12/payment-order/{id}/control`\n\n5. **Execute**:\n   - **Purpose**: Trigger payment execution (hand off to Payment Execution SD)\n   - **Input**: Payment Order ID\n   - **Output**: Payment Order marked as \"Executing\"\n   - **API Endpoint**: `POST /bian/v12/payment-order/{id}/execute`\n\n**Behavior Qualifiers** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- compliance: Payment order compliance checks\n- reporting: Payment order reporting and audit\n- booking: Payment order accounting and booking\n\n**Functional Patterns** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n- **Pattern Type**: Tracked Object\n- **Pattern Description**: Payment Order manages the lifecycle of payment orders from initiation through completion, tracking state changes and coordinating with Payment Execution service domain\n- **Pattern Implications**: Control record lifecycle is tracked with state transitions; service operations modify control record state\n\n---\n\n**Implementation Details**:\n\n**Type**: BIAN Service Domain | Microservice\n**Technology**: Java 17, Spring Boot 3.2, Spring Data JPA\n**Version**: v3.1.0\n**Location**: `repos/bian-service-domains/payment-order`\n**Team Owner**: Payments Team\n\n**Purpose**:\nManage the complete payment order lifecycle from initiation through execution coordination, ensuring payment compliance and proper handoff to Payment Execution service domain.\n\n**Responsibilities**:\n- Implement BIAN V12.0 Payment Order service domain\n- Maintain PaymentOrderProcedure control records\n- Expose all BIAN service operations (Initiate, Update, Retrieve, Control, Execute)\n- Validate payment details and compliance requirements\n- Publish payment order lifecycle events\n- Coordinate with Payment Execution service domain (SD-002)\n\n**API Specification**:\n\n**API Type**: REST\n**Base URL**: `/bian/v12/payment-order`\n**Authentication**: JWT (Bearer token) + mTLS\n\n**BIAN Service Operations Endpoints**:\n\n| Service Operation | Method | Path | Description | BIAN Compliance |\n|------------------|--------|------|-------------|-----------------|\n| Initiate | POST | `/initiate` | Create new payment order | Mandatory ‚úÖ |\n| Update | PUT | `/{id}/update` | Modify payment order | Mandatory ‚úÖ |\n| Retrieve | GET | `/{id}/retrieve` | Query payment order | Mandatory ‚úÖ |\n| Control | PUT | `/{id}/control` | Manage lifecycle (cancel, suspend) | Mandatory ‚úÖ |\n| Execute | POST | `/{id}/execute` | Trigger payment execution | Optional ‚úÖ |\n\n**OpenAPI Spec**: `https://api.bank.com/docs/bian/payment-order/v12`\n\n---\n\n**Data Management**:\n\n**Database Type**: PostgreSQL 15\n**Database Name**: payment_order_db\n**Schema**: Managed via Flyway migrations, aligned with BIAN PaymentOrderProcedure control record\n\n**Control Record Persistence**:\n- Table: `payment_order_procedures`\n- Primary Key: `payment_order_id` (UUID)\n- BIAN Alignment: Table schema directly maps to BIAN V12.0 PaymentOrderProcedure structure\n\n**Data Ownership**: Source of truth for all payment order control records and lifecycle state\n\n**Consistency Model**: Strong consistency for payment order creation (ACID transaction)\n\n---\n\n**Event-Driven Communication**:\n\n**Events Published**:\n\n| Event Name | Trigger | Payload | Schema Version | Consumers |\n|------------|---------|---------|----------------|-----------|\n| `payment-order.initiated` | Payment order created | payment_order_id, payer, payee, amount | v1 | Payment Execution (SD-002), Fraud Detection (SD-045) |\n| `payment-order.executed` | Payment execution triggered | payment_order_id, executed_at | v1 | Payment Execution (SD-002) |\n| `payment-order.completed` | Payment fully processed | payment_order_id, completed_at, final_status | v1 | Notification Service, Accounting |\n| `payment-order.cancelled` | Payment cancelled | payment_order_id, cancellation_reason | v1 | Notification Service |\n\n**Events Consumed**:\n\n| Event Name | Source Service Domain | Action Taken | Idempotency |\n|------------|----------------------|--------------|-------------|\n| `payment-execution.completed` | Payment Execution (SD-002) | Update payment order status to COMPLETED | Event ID tracking in DB |\n| `payment-execution.failed` | Payment Execution (SD-002) | Update payment order status to FAILED | Event ID tracking in DB |\n| `fraud-detection.alert` | Fraud Detection (SD-045) | Mark payment order for review, suspend execution | Event ID tracking in DB |\n\n**Event Bus**: Kafka 3.6\n\n---\n\n**Service Dependencies**:\n\n**Upstream BIAN Service Domains**:\n- Party Authentication (SD-004): Authenticate payer (timeout: 2s)\n- Account Verification (SD-007): Validate payer account (timeout: 3s)\n\n**Downstream BIAN Service Domains**:\n- Payment Execution (SD-002): Execute payment order (async via event)\n- Fraud Detection (SD-045): Compliance checks (async via event)\n\n**Layer 3 Dependencies**:\n- Business Capability: Payments Business Domain (coordinates Payment Order and Payment Execution)\n\n**Layer 5 Dependencies**:\n- Core Banking System: Validate account balances (via adapter)\n\n**Circuit Breaker Configuration** (Resilience4j):\n- Failure threshold: 50% errors over 10 requests\n- Timeout: 5 seconds\n- Fallback strategy: Queue payment order for async processing\n\n---\n\n**BIAN Compliance Documentation**:\n\n**Compliance Level**: Full BIAN V12.0 Compliance\n\n**Validation Details**:\n- **BIAN Service Domain Name**: ‚úÖ \"Payment Order\" validated against [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- **Control Record Structure**: ‚úÖ PaymentOrderProcedure aligned with BIAN V12.0 specification\n- **Service Operations**: ‚úÖ All mandatory operations implemented (Initiate, Update, Retrieve, Control, Execute)\n- **Behavior Qualifiers**: ‚úÖ compliance, reporting, booking documented and implemented\n- **Functional Pattern**: ‚úÖ Tracked Object pattern implemented per BIAN spec\n- **Validation Date**: 2025-01-15\n\n**Deviations from BIAN Standard**: None (full compliance)\n\n**BIAN Traceability**:\n- **Payment Order** (Service Domain) ‚Üí **Payments** (Business Domain) ‚Üí **Operations and Execution** (Business Area)\n\n---\n\n**Configuration**:\n\n**Environment Variables**:\n- `DB_URL`: PostgreSQL connection string (required)\n- `KAFKA_BROKERS`: Kafka bootstrap servers (required)\n- `BIAN_COMPLIANCE_MODE`: STRICT (enforces full BIAN V12.0 compliance)\n- `MAX_PAYMENT_AMOUNT`: Maximum payment amount (default: 1000000.00)\n\n**BIAN Configuration**:\n- `BIAN_VERSION`: V12.0 (fixed)\n- `CONTROL_RECORD_RETENTION`: 7 years (regulatory requirement)\n\n---\n\n**Deployment & Scaling**:\n\n**Container Image**: `bank.azurecr.io/bian/payment-order:3.1.0`\n\n**Resource Requirements**:\n- CPU: Requests: 500m, Limits: 2000m\n- Memory: Requests: 1Gi, Limits: 2Gi\n\n**Replicas**:\n- Minimum: 3 (high availability)\n- Maximum: 15\n\n**Auto-Scaling**:\n- Metric: CPU 70% or request rate >500 req/sec per pod\n- Scale-up policy: Add 2 pods when threshold exceeded for 2 minutes\n- Scale-down policy: Remove 1 pod when below 40% for 10 minutes\n\n**Health Checks**:\n- Liveness: `GET /actuator/health/liveness` every 30s\n- Readiness: `GET /actuator/health/readiness` every 10s\n- BIAN Health: `GET /bian/health` (validates BIAN service operation health)\n\n---\n\n**Observability**:\n\n**Logging** (JSON structured):\n- BIAN Fields: payment_order_id, service_operation (Initiate/Update/Retrieve/Control/Execute), bian_version (V12.0), compliance_status\n- Aggregation: ELK Stack\n\n**Metrics** (Micrometer + Prometheus):\n- `bian_service_operation_total`: Counter by operation type (Initiate, Update, Retrieve, Control, Execute)\n- `payment_order_lifecycle_duration_seconds`: Histogram of time from Initiated to Completed\n- `bian_compliance_validation_success_rate`: Gauge of BIAN compliance validation success\n- `payment_order_amount_total`: Gauge of total payment order amounts\n\n**Alerts**:\n- BIAN service operation error rate > 5% ‚Üí Page on-call\n- Payment order lifecycle duration > 60 seconds (p95) ‚Üí Slack alert\n- BIAN compliance validation failure ‚Üí Immediate alert to architecture team\n\n---\n\n**Testing Strategy**:\n\n**Unit Tests**: 90% coverage target, JUnit 5 + Mockito\n\n**Integration Tests**: Testcontainers (PostgreSQL, Kafka) for BIAN service operations\n\n**BIAN Compliance Tests**:\n- ‚úÖ Validate PaymentOrderProcedure control record structure against BIAN V12.0 spec\n- ‚úÖ Test all 5 mandatory service operations (Initiate, Update, Retrieve, Control, Execute)\n- ‚úÖ Verify behavior qualifiers (compliance, reporting, booking) implementation\n- ‚úÖ Test Tracked Object functional pattern adherence\n\n**Contract Tests**: Pact contracts with Payment Execution (SD-002), Fraud Detection (SD-045)\n\n**End-to-End Tests**: Payment order creation ‚Üí execution ‚Üí completion flow (Postman/Newman)\n\n---\n\n## Guidelines\n\n1. **Document all components** in every BIAN layer\n2. **Group components by layer** for clarity (Layers 1-5)\n3. **BIAN V12.0 compliance is mandatory** for Layer 4 (BIAN Service Domains)\n4. **Validate all service domain names** against [official BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n5. **Include complete BIAN metadata** for all Layer 4 components (Official Name, BIAN ID, Version, Business Domain, Business Area, URL)\n6. **Document control records per BIAN spec** with structure, lifecycle states, and transitions\n7. **Implement all mandatory BIAN service operations** (Initiate, Update, Retrieve, Control) plus optional operations as applicable\n8. **Document behavior qualifiers and functional patterns** per BIAN V12.0 specification\n9. **Ensure BIAN hierarchy traceability**: Service Domain ‚Üí Business Domain ‚Üí Business Area\n10. **Include modernization strategy** for Layer 5 (Core Systems) aligned with BIAN architecture goals\n11. **Quantify metrics** in Monitoring sections (not generic placeholders)\n12. **Define failure modes** with realistic mitigation strategies\n13. **Cross-reference layers** in Dependencies sections\n\n---\n\n## Validation Checklist\n\n**Structure Validation**:\n- [ ] Components documented for all 5 BIAN layers\n- [ ] Components grouped by layer (1: Channels, 2: Business Scenarios, 3: Business Capabilities, 4: Service Domains, 5: Core Systems)\n- [ ] Each component includes all required subsections\n\n**BIAN V12.0 Compliance Validation** (Layer 4):\n- [ ] All service domain names validated against [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n- [ ] Complete BIAN metadata for all Layer 4 components (Official Name, BIAN ID, Version, Business Domain, Business Area, URL)\n- [ ] Control records documented per BIAN specification with structure and lifecycle\n- [ ] All mandatory BIAN service operations implemented (Initiate, Update, Retrieve, Control)\n- [ ] Optional service operations documented if applicable (Exchange, Execute, Request)\n- [ ] Behavior qualifiers documented per BIAN spec\n- [ ] Functional patterns documented per BIAN spec (Managed Object, Tracked Object, etc.)\n- [ ] BIAN compliance level documented (Full/Partial/Custom)\n- [ ] BIAN hierarchy traceability documented: Service Domain ‚Üí Business Domain ‚Üí Business Area\n\n**Layer Integration Validation**:\n- [ ] Layer 2 components mapped to BIAN Business Areas (5 areas)\n- [ ] Layer 3 components mapped to BIAN Business Domains (30+ domains)\n- [ ] Layer 4 service domains include upstream/downstream service domain dependencies\n- [ ] Layer 5 core systems include BIAN integration strategy (adapters, modernization)\n- [ ] Dependencies clearly reference layer numbers and BIAN hierarchy\n\n**Quality Checks**:\n- [ ] No placeholder content (all sections filled with real information)\n- [ ] Failure modes include realistic impact and mitigation\n- [ ] Monitoring includes specific BIAN metrics (service operation rates, compliance validation)\n- [ ] Example paths updated to match actual project structure\n- [ ] All BIAN V12.0 references link to https://bian.org/servicelandscape-12-0-0/views/view_51891.html\n",
        "skills/architecture-docs/templates/SECTION_5_META.md": "# Section 5: Component Details - META Architecture\n\n<!-- ARCHITECTURE_TYPE: META -->\n\n**Purpose**: Deep dive into each component within every META layer, providing detailed technical specifications and operational characteristics.\n\nThis template organizes components by their META layer assignment (Channels ‚Üí UX ‚Üí Business Scenarios ‚Üí Business ‚Üí Domain ‚Üí Core).\n\n**BIAN V12.0 Standard**: For Layer 5 (Domain) components, use [BIAN V12.0](https://bian.org/) as the default service domain model. Reference the [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html) for official service domain definitions and IDs.\n\n---\n\n## Component Documentation Guidelines\n\nFor each component in your system, document using the template below. **Group components by their layer.**\n\n---\n\n## Layer 1: Channels - Components\n\n### [Component Name]\n\n**Type**: Service | Mobile App | Web Application | API | ATM Interface\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path or repository]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints]\n- API 2: [Description, endpoints]\n\n**Dependencies**:\n- Depends on: [Layer 2 (UX) components]\n- Depended by: [End users, external clients]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Layer 2: User Experience (UX) - Components\n\n### [Component Name]\n\n**Type**: BFF | API Gateway | Session Manager | Experience Orchestrator\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints]\n- API 2: [Description, endpoints]\n\n**Dependencies**:\n- Depends on: [Layer 3 (Business Scenarios) and Layer 4 (Business) components]\n- Depended by: [Layer 1 (Channels) components]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Layer 3: Business Scenarios - Components\n\n### [Component Name]\n\n**Type**: Orchestrator | Process Engine | Business Rules Engine | Workflow Manager\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints]\n- API 2: [Description, endpoints]\n\n**Dependencies**:\n- Depends on: [Layer 4 (Business) and Layer 5 (Domain) components]\n- Depended by: [Layer 2 (UX) components]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Layer 4: Business - Components\n\n### [Component Name]\n\n**Type**: Business Service | API Layer | Business Rules Engine | Capability Service\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path]\n\n**Purpose**:\n[1-2 sentence description of what this component does]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- API 1: [Description, endpoints]\n- API 2: [Description, endpoints]\n\n**Dependencies**:\n- Depends on: [Layer 5 (Domain), Layer 6 (Core), and external systems]\n- Depended by: [Layer 2 (UX) and Layer 3 (Business Scenarios) components]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Yes/No, approach]\n- Vertical: [Limits, approach]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Layer 5: Domain - Components (BIAN V12.0 Service Domains)\n\n### [Service Domain Name] (BIAN V12.0)\n\n**BIAN Metadata** (MANDATORY - All fields required):\n\n1. **Official BIAN Name**: [Exact name from BIAN V12.0 Service Landscape - e.g., \"Payment Order\", \"Current Account\", \"Customer Offer\"]\n2. **BIAN ID**: [Internal tracking ID - e.g., SD-001, SD-002 for document tracking only]\n3. **BIAN Version**: V12.0 (mandatory)\n4. **BIAN Business Domain**: [Parent business domain - e.g., \"Payments\", \"Loans and Deposits\", \"Customer Management\"]\n5. **BIAN Business Area**: [Parent business area - e.g., \"Operations and Execution\", \"Sales and Service\", \"Risk and Compliance\"]\n6. **BIAN Service Landscape URL**: [Direct link to this service domain - https://bian.org/servicelandscape-12-0-0/views/view_51891.html]\n\n**Note**: The Official BIAN Name must match the official BIAN V12.0 Service Landscape definition exactly. The BIAN ID is for internal tracking to count service domains in this document. BIAN Business Domain and Business Area must be traceable to the BIAN hierarchy.\n\n**Type**: Service Domain | Microservice\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Package/directory path or repository]\n\n**Purpose**:\n[1-2 sentence description aligned with BIAN V12.0 service domain definition]\n\n**BIAN Alignment Details**:\n\n**Control Record** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n- **Control Record Type**: [As defined in BIAN spec - e.g., \"PaymentOrderProcedure\", \"CurrentAccountFulfillmentArrangement\", \"CustomerOfferProcedure\"]\n- **Control Record Structure**:\n  - Field 1: [Name, data type, description per BIAN spec]\n  - Field 2: [Name, data type, description per BIAN spec]\n  - Field 3: [Name, data type, description per BIAN spec]\n  - [Add all fields as defined in BIAN V12.0 specification for this service domain]\n- **Lifecycle States**: [Document all states - e.g., Initiated, Active, Completed, Suspended, Cancelled - per BIAN]\n- **State Transitions**: [Document allowed state transitions per BIAN specification - e.g., Initiated‚ÜíActive, Active‚ÜíSuspended, Suspended‚ÜíActive, Active‚ÜíCompleted, Active‚ÜíCancelled]\n\n**Service Operations** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\nAll BIAN service domains MUST document the following service operations:\n\n1. **Initiate**:\n   - **Purpose**: Create new control record\n   - **Input**: [Required fields per BIAN spec for this service domain]\n   - **Output**: [Control record instance with unique identifier]\n   - **API Endpoint**: `POST /service-domain/initiate`\n\n2. **Update**:\n   - **Purpose**: Modify existing control record\n   - **Input**: [Control record ID, update fields per BIAN spec]\n   - **Output**: [Updated control record]\n   - **API Endpoint**: `PUT /service-domain/{id}/update`\n\n3. **Retrieve**:\n   - **Purpose**: Query control record\n   - **Input**: [Control record ID or query parameters]\n   - **Output**: [Control record data]\n   - **API Endpoint**: `GET /service-domain/{id}/retrieve`\n\n4. **Control**:\n   - **Purpose**: Manage control record lifecycle (suspend, resume, terminate)\n   - **Input**: [Control record ID, control action (suspend/resume/terminate)]\n   - **Output**: [Updated control record with new lifecycle state]\n   - **API Endpoint**: `PUT /service-domain/{id}/control`\n\n5. **Exchange** (if applicable per BIAN spec for this service domain):\n   - **Purpose**: [Per BIAN spec for this specific service domain]\n   - **Input**: [Per BIAN spec]\n   - **Output**: [Per BIAN spec]\n   - **API Endpoint**: `PUT /service-domain/{id}/exchange`\n\n6. **Execute** (if applicable per BIAN spec for this service domain):\n   - **Purpose**: [Per BIAN spec for this specific service domain]\n   - **Input**: [Per BIAN spec]\n   - **Output**: [Per BIAN spec]\n   - **API Endpoint**: `POST /service-domain/{id}/execute`\n\n7. **Request** (if applicable per BIAN spec for this service domain):\n   - **Purpose**: [Per BIAN spec for this specific service domain]\n   - **Input**: [Per BIAN spec]\n   - **Output**: [Per BIAN spec]\n   - **API Endpoint**: `POST /service-domain/{id}/request`\n\n**Behavior Qualifiers** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\nDocument all behavior qualifiers defined in BIAN V12.0 for this service domain:\n- Qualifier 1: [Name, description per BIAN spec - e.g., \"registration\", \"valuation\", \"reporting\", \"compliance\", \"booking\", \"analysis\", \"fulfillment\"]\n- Qualifier 2: [Name, description per BIAN spec]\n- Qualifier 3: [Name, description per BIAN spec]\n- [Add all qualifiers as defined in BIAN V12.0 specification for this service domain]\n\nReference: [BIAN Service Landscape V12.0](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n\n**Functional Patterns** ([BIAN V12.0 Standard](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)):\n\n- **Pattern Type**: [Managed Object | Tracked Object | Administered Object | Governed Object | Monitored Object | Catalog Entry | Register Entry]\n- **Pattern Description**: [How this service domain implements the BIAN functional pattern]\n- **Pattern Implications**: [What the pattern means for service operations and lifecycle management - e.g., Managed Object requires full CRUD + lifecycle control operations]\n\n**Responsibilities**:\n- Implement BIAN V12.0 service domain [name]\n- Maintain control records per BIAN specifications\n- Expose service operations as defined in BIAN model\n- [Additional domain-specific responsibilities]\n\n**APIs/Interfaces**:\n- BIAN Service Operations API: [Endpoints aligned with BIAN V12.0]\n- Domain Events: [Event-driven integration points]\n- Control Record API: [CRUD operations on control records]\n\n**Dependencies**:\n- **Depends on**: [Other BIAN service domains or Layer 6 Core systems]\n- **Depended by**: [Layer 4 Business components]\n- **BIAN References**: [Link to official BIAN V12.0 dependencies]\n\n**BIAN Hierarchy Traceability**:\n- **Service Domain** ‚Üí **Business Domain** ‚Üí **Business Area**\n- [Service Domain Name] ‚Üí [Business Domain Name] ‚Üí [Business Area Name]\n\nThis traceability ensures alignment with BIAN V12.0 hierarchy and enables proper categorization within the BIAN landscape.\n\n**Data Model**:\n- **Control Record Structure**: [Main entity/aggregate]\n- **BIAN Alignment**: Maps to BIAN V12.0 [Service Domain] control record\n- **Persistence**: [Database, storage approach]\n\n**BIAN Compliance Documentation**:\n\n- **BIAN Version**: V12.0 (mandatory)\n- **Compliance Level**: Full BIAN V12.0 compliance (mandatory for META Layer 5)\n- **Validation Details**:\n  - ‚úÖ Service Domain Name validated against [BIAN V12.0 Service Landscape](https://bian.org/servicelandscape-12-0-0/views/view_51891.html)\n  - ‚úÖ Control Record Structure aligned with BIAN V12.0 specification\n  - ‚úÖ Service Operations implemented per BIAN standard (4 mandatory minimum)\n  - ‚úÖ Behavior Qualifiers documented per BIAN spec\n  - ‚úÖ Functional Pattern identified per BIAN spec\n  - ‚úÖ BIAN Hierarchy traceable (Service Domain ‚Üí Business Domain ‚Üí Business Area)\n- **Validation Date**: [YYYY-MM-DD when compliance was verified]\n- **Deviations**: [Document any customizations or extensions beyond BIAN standard]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Approach for scaling service domain instances]\n- Vertical: [Limits based on domain complexity]\n\n**Failure Modes**:\n- [Failure scenario 1 and recovery approach]\n- [Failure scenario 2 and recovery approach]\n\n**Monitoring**:\n- Key metrics: [Domain-specific KPIs]\n- Health checks: [BIAN service operation health]\n- Alerting: [Alert conditions and thresholds]\n\n---\n\n## Layer 6: Core - Components\n\n### [Core System Name]\n\n**Type**: Core Banking | Mainframe | Legacy System | Transaction Processor\n**Technology**: [Specific technology used]\n**Version**: [Version number]\n**Location**: [Data center, on-premise, cloud]\n\n**Purpose**:\n[1-2 sentence description of core system]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**APIs/Interfaces**:\n- Legacy API: [Description, protocols]\n- File Interfaces: [File formats, schedules]\n- Batch Processes: [Batch jobs, schedules]\n\n**Dependencies**:\n- Depends on: [Other core systems, databases]\n- Depended by: [Layer 5 (Domain) components]\n\n**Modernization Plan**:\n- Current State: [Assessment]\n- Target State: [Goals]\n- Migration Approach: [Strategy]\n\n**Configuration**:\n- Config param 1: [Description, default]\n- Config param 2: [Description, default]\n\n**Scaling**:\n- Horizontal: [Typically N/A for legacy]\n- Vertical: [Capacity planning]\n\n**Failure Modes**:\n- Failure 1: [Impact, mitigation]\n- Failure 2: [Impact, mitigation]\n\n**Monitoring**:\n- Key metrics: [Metrics to track]\n- Alerts: [Alert conditions]\n- Logs: [What is logged]\n\n---\n\n## Example: Mobile Banking App (Layer 1: Channels)\n\n### Mobile Banking App\n\n**Type**: Mobile Application\n**Technology**: React Native 0.72\n**Version**: v3.5.2\n**Location**: `apps/mobile-banking/` (example path)\n\n**Purpose**:\nProvide retail banking services to customers via iOS and Android mobile devices.\n\n**Responsibilities**:\n- User authentication (biometric, PIN, password)\n- Account balance and transaction history display\n- Fund transfers and bill payments\n- Card management and controls\n- Push notification handling\n\n**APIs/Interfaces**:\n- REST API: Consumes `/api/mobile/v2/*` from Layer 2 (BFF)\n- OAuth 2.0: Authentication flow with Auth0\n- Push Notifications: Firebase Cloud Messaging (FCM)\n\n**Dependencies**:\n- Depends on: Mobile BFF (Layer 2), Auth0 (external)\n- Depended by: End-user customers\n\n**Configuration**:\n- `API_BASE_URL`: Backend API URL (per environment)\n- `OAUTH_CLIENT_ID`: OAuth client identifier\n- `SESSION_TIMEOUT`: Inactivity timeout (default: 300s)\n\n**Scaling**:\n- Horizontal: N/A (client-side app)\n- Vertical: N/A\n\n**Failure Modes**:\n- Backend API unavailable: Show cached data, queue requests\n- Network connectivity loss: Offline mode with sync on reconnect\n- Authentication service down: Users cannot log in, show maintenance message\n\n**Monitoring**:\n- Key metrics: Active users, crash rate, API call success rate\n- Alerts: Crash rate > 1%, API error rate > 5%\n- Logs: All authentication attempts, transaction requests, errors\n\n---\n\n## Guidelines\n\n1. **Document all components** in every layer\n2. **Group components by layer** for clarity\n3. **BIAN compliance required** for Layer 5 (Domain) components\n4. **Include modernization plans** for Layer 6 (Core) legacy systems\n5. **Quantify metrics** in Monitoring section (not generic placeholders)\n6. **Define failure modes** with realistic mitigation strategies\n7. **Cross-reference layers** in Dependencies section\n\n---\n\n## Validation Checklist\n\n- [ ] Components documented for all 6 META layers\n- [ ] Each component includes all required subsections\n- [ ] Layer 5 (Domain) components include BIAN alignment details\n- [ ] Layer 6 (Core) components include modernization strategy\n- [ ] Dependencies clearly reference layer numbers\n- [ ] Failure modes include realistic impact and mitigation\n- [ ] Monitoring includes specific metrics (not placeholders)\n- [ ] Example paths updated to match actual project structure",
        "skills/architecture-docs/templates/SECTION_5_MICROSERVICES.md": "# Section 5: Component Details - Microservices Architecture\n\n<!-- ARCHITECTURE_TYPE: MICROSERVICES -->\n\n**Purpose**: Deep dive into each microservice and infrastructure component, providing detailed technical specifications, APIs, and operational characteristics.\n\nThis template organizes components by service catalog and supporting infrastructure.\n\n---\n\n## Component Documentation Guidelines\n\nDocument each microservice and infrastructure component using the templates below.\n\n---\n\n## Microservices Catalog\n\nFor each microservice, use this comprehensive template:\n\n### [Service Name] Service\n\n**Bounded Context**: [Domain/business capability this service owns]\n\n**Type**: Microservice\n**Technology**: [Language/framework - e.g., Java/Spring Boot, Node.js/NestJS]\n**Version**: [Version number]\n**Location**: [Repository URL or directory path]\n**Team Owner**: [Team responsible for this service]\n\n**Purpose**:\n[1-2 sentence description of what this service does and why it exists]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n---\n\n#### API Specification\n\n**API Type**: REST | gRPC | GraphQL\n\n**Base URL**: [e.g., `/api/v1/service-name`]\n\n**Authentication**: [JWT, OAuth 2.0, mTLS, API Key]\n\n**Endpoints**:\n\n| Method | Path | Description | Request | Response | Status Codes |\n|--------|------|-------------|---------|----------|--------------|\n| POST | `/resource` | [Description] | [Body schema] | [Response schema] | 201, 400, 409 |\n| GET | `/resource/{id}` | [Description] | [Path params] | [Response schema] | 200, 404 |\n| PUT | `/resource/{id}` | [Description] | [Body schema] | [Response schema] | 200, 400, 404 |\n| DELETE | `/resource/{id}` | [Description] | [Path params] | [None] | 204, 404 |\n\n**OpenAPI Spec**: [Link to OpenAPI/Swagger documentation]\n\n**Service Contract**: [Link to service contract documentation]\n\n---\n\n#### Data Management\n\n**Database Type**: [PostgreSQL, MongoDB, DynamoDB, Redis, etc.]\n**Database Name**: [service_name_db]\n**Schema**: [Brief description or link to schema]\n\n**Tables/Collections**:\n- Table 1: [Name, primary key, description]\n- Table 2: [Name, primary key, description]\n\n**Data Ownership**: [What data this service is the source of truth for]\n\n**Data Access Patterns**:\n- Pattern 1: [e.g., Single-item lookup by ID]\n- Pattern 2: [e.g., Range query with pagination]\n\n**Consistency Model**: [Strong consistency | Eventual consistency]\n\n---\n\n#### Event-Driven Communication\n\n**Events Published**:\n\n| Event Name | Trigger | Payload | Schema Version | Consumers |\n|------------|---------|---------|----------------|-----------|\n| `service.resource.created` | [When event occurs] | [Key fields] | v1 | [List services] |\n| `service.resource.updated` | [When event occurs] | [Key fields] | v1 | [List services] |\n\n**Events Consumed**:\n\n| Event Name | Source Service | Action Taken | Idempotency |\n|------------|---------------|--------------|-------------|\n| `other.event.name` | [Service name] | [What this service does] | [How ensured] |\n\n**Event Bus**: [Kafka, RabbitMQ, AWS EventBridge, etc.]\n\n**Dead Letter Queue**: [How failed events are handled]\n\n---\n\n#### Service Dependencies\n\n**Synchronous Dependencies** (Services this service calls):\n- Service A: [What operations, timeout values]\n- Service B: [What operations, timeout values]\n\n**Asynchronous Dependencies** (Events consumed from):\n- Service C: [What events, processing guarantees]\n\n**External Dependencies**:\n- External API 1: [Provider, purpose, SLA]\n- External API 2: [Provider, purpose, SLA]\n\n**Dependency Graph**: [Link to dependency visualization or describe]\n\n**Circuit Breaker Configuration**:\n- Failure threshold: [e.g., 50% errors over 10 requests]\n- Timeout: [e.g., 5 seconds]\n- Fallback strategy: [e.g., Return cached data, degrade gracefully]\n\n---\n\n#### Configuration\n\n**Environment Variables**:\n- `VAR_NAME`: [Description, default value, required/optional]\n\n**Feature Flags**:\n- `flag_name`: [Description, current state]\n\n**Configuration Source**: [Spring Cloud Config, Consul KV, ConfigMap, etc.]\n\n---\n\n#### Deployment & Scaling\n\n**Container Image**: [Repository/image:tag]\n\n**Resource Requirements**:\n- CPU: [Requests: 500m, Limits: 1000m]\n- Memory: [Requests: 512Mi, Limits: 1Gi]\n\n**Replicas**:\n- Minimum: [e.g., 2]\n- Maximum: [e.g., 10]\n\n**Auto-Scaling**:\n- Metric: [CPU utilization, request rate, custom metric]\n- Threshold: [e.g., 70% CPU]\n- Scale-up policy: [How aggressive]\n- Scale-down policy: [How conservative]\n\n**Deployment Strategy**: [Rolling update, Blue/Green, Canary]\n\n**Health Checks**:\n- Liveness: [Endpoint, interval, threshold]\n- Readiness: [Endpoint, interval, threshold]\n\n---\n\n#### Resilience & Fault Tolerance\n\n**Failure Modes**:\n\n| Failure | Impact | Mitigation | Detection |\n|---------|--------|------------|-----------|\n| Database unavailable | [Impact] | [Circuit breaker, fallback] | [Health check] |\n| Dependent service down | [Impact] | [Timeout, retry, fallback] | [Circuit breaker] |\n| Event bus unavailable | [Impact] | [Local queue, retry] | [Connection monitor] |\n\n**Retry Policy**:\n- Max retries: [e.g., 3]\n- Backoff strategy: [Exponential backoff, fixed delay]\n- Retry-eligible errors: [List HTTP status codes or error types]\n\n**Timeout Configuration**:\n- HTTP client timeout: [e.g., 5s]\n- Database query timeout: [e.g., 3s]\n- Event processing timeout: [e.g., 30s]\n\n---\n\n#### Observability\n\n**Logging**:\n- Level: [INFO in prod, DEBUG in dev]\n- Format: [JSON structured logging]\n- Fields: [Correlation ID, user ID, request ID, etc.]\n- Aggregation: [ELK, Splunk, CloudWatch]\n\n**Metrics**:\n- Request rate (requests/second)\n- Response latency (p50, p95, p99)\n- Error rate (errors/second, % of requests)\n- Business metrics: [e.g., orders created, payments processed]\n- Collection: [Prometheus, Datadog, CloudWatch]\n\n**Distributed Tracing**:\n- Tracing system: [Jaeger, Zipkin, X-Ray, OpenTelemetry]\n- Sampling rate: [e.g., 100% for errors, 10% for successful requests]\n- Trace propagation: [W3C Trace Context, B3]\n\n**Alerts**:\n- Error rate > 5% for 5 minutes ‚Üí Page on-call\n- p99 latency > 1s for 10 minutes ‚Üí Slack alert\n- 0 healthy replicas ‚Üí Page on-call\n\n---\n\n#### Security\n\n**Authentication**: [How clients authenticate - JWT, mTLS, API Gateway]\n\n**Authorization**: [RBAC, ABAC, ACL - how permissions enforced]\n\n**Secrets Management**: [HashiCorp Vault, AWS Secrets Manager, Kubernetes Secrets]\n\n**Encryption**:\n- In-transit: [TLS 1.3, mTLS]\n- At-rest: [Database encryption, field-level encryption]\n\n**Security Scanning**:\n- SAST: [Static analysis tools]\n- DAST: [Dynamic analysis tools]\n- Dependency scanning: [Snyk, Dependabot]\n\n---\n\n#### Testing Strategy\n\n**Unit Tests**: [Coverage target, framework]\n\n**Integration Tests**: [What's tested, test environment]\n\n**Contract Tests**: [Pact, Spring Cloud Contract]\n\n**End-to-End Tests**: [Critical user flows tested]\n\n**Load Tests**: [Target TPS, latency thresholds]\n\n---\n\n## Infrastructure Components\n\nDocument each infrastructure component supporting the microservices:\n\n### [Component Name]\n\n**Type**: API Gateway | Service Mesh | Event Bus | Service Discovery | Configuration | Monitoring\n**Technology**: [Specific technology]\n**Version**: [Version number]\n\n**Purpose**: [What this component provides]\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n\n**Configuration**: [Key configuration parameters]\n\n**Scaling**: [How this component scales]\n\n**Failure Modes**: [Impact and mitigation]\n\n**Monitoring**: [Key metrics and alerts]\n\n---\n\n## Example: Order Service\n\n### Order Service\n\n**Bounded Context**: Order Management (order lifecycle from creation to fulfillment)\n\n**Type**: Microservice\n**Technology**: Java 17, Spring Boot 3.1.5, Spring Data JPA\n**Version**: v2.4.1\n**Location**: `https://github.com/company/order-service`\n**Team Owner**: Orders Team\n\n**Purpose**:\nManages the complete order lifecycle from order creation through fulfillment, including order validation, inventory reservation coordination, and order status tracking.\n\n**Responsibilities**:\n- Create and validate customer orders\n- Calculate order totals, taxes, and apply discount codes\n- Coordinate inventory reservation with Inventory Service\n- Track order status changes (pending ‚Üí confirmed ‚Üí shipped ‚Üí delivered)\n- Publish order events for downstream processing\n\n---\n\n#### API Specification\n\n**API Type**: REST\n\n**Base URL**: `/api/v1/orders`\n\n**Authentication**: JWT (Bearer token)\n\n**Endpoints**:\n\n| Method | Path | Description | Request | Response | Status Codes |\n|--------|------|-------------|---------|----------|--------------|\n| POST | `/orders` | Create new order | OrderCreateDto | OrderDto | 201, 400, 409 |\n| GET | `/orders/{id}` | Get order by ID | - | OrderDto | 200, 404 |\n| GET | `/orders` | List orders (paginated) | page, size | Page<OrderDto> | 200 |\n| PUT | `/orders/{id}/status` | Update order status | StatusUpdateDto | OrderDto | 200, 400, 404 |\n| GET | `/orders/customer/{customerId}` | List customer orders | - | List<OrderDto> | 200 |\n\n**OpenAPI Spec**: `https://api.company.com/docs/order-service/v1`\n\n**Service Contract**: Documented in repository `/docs/api-contract.md`\n\n---\n\n#### Data Management\n\n**Database Type**: PostgreSQL 15\n**Database Name**: order_service_db\n**Schema**: Managed via Flyway migrations in `/db/migrations`\n\n**Tables/Collections**:\n- `orders`: (id UUID PK, customer_id UUID, total_amount DECIMAL, status VARCHAR, created_at TIMESTAMP)\n- `order_items`: (id UUID PK, order_id UUID FK, product_id UUID, quantity INT, unit_price DECIMAL)\n- `order_status_history`: (id UUID PK, order_id UUID FK, from_status VARCHAR, to_status VARCHAR, changed_at TIMESTAMP)\n\n**Data Ownership**: Source of truth for all order data and order lifecycle status\n\n**Data Access Patterns**:\n- Single order lookup by ID (most common)\n- Range query: List orders by customer_id with pagination\n- Range query: List orders by status with date filters\n\n**Consistency Model**: Strong consistency for order creation (ACID transaction)\n\n---\n\n#### Event-Driven Communication\n\n**Events Published**:\n\n| Event Name | Trigger | Payload | Schema Version | Consumers |\n|------------|---------|---------|----------------|-----------|\n| `order.created` | Order successfully created | order_id, customer_id, total_amount, items | v1 | Payment, Inventory, Notification |\n| `order.confirmed` | Payment completed | order_id, confirmed_at | v1 | Fulfillment, Notification |\n| `order.cancelled` | Order cancelled | order_id, reason | v1 | Inventory, Payment, Notification |\n\n**Events Consumed**:\n\n| Event Name | Source Service | Action Taken | Idempotency |\n|------------|---------------|--------------|-------------|\n| `payment.completed` | Payment Service | Update order status to CONFIRMED | Event ID tracking in DB |\n| `inventory.reserved` | Inventory Service | Mark order as ready for fulfillment | Event ID tracking in DB |\n| `shipment.dispatched` | Fulfillment Service | Update order status to SHIPPED | Event ID tracking in DB |\n\n**Event Bus**: Kafka 3.5\n\n**Dead Letter Queue**: `order-service-dlq` topic, events retried 3 times before moving to DLQ\n\n---\n\n#### Service Dependencies\n\n**Synchronous Dependencies**:\n- Inventory Service: Check stock availability (timeout: 3s)\n- Customer Service: Validate customer ID (timeout: 2s)\n- Pricing Service: Calculate discounts and taxes (timeout: 2s)\n\n**Asynchronous Dependencies**:\n- Payment Service: via `payment.completed` event\n- Inventory Service: via `inventory.reserved` event\n- Fulfillment Service: via `shipment.dispatched` event\n\n**External Dependencies**:\n- Stripe API: Payment processing (SLA: 99.99%)\n- SendGrid API: Order confirmation emails (SLA: 99.9%)\n\n**Circuit Breaker Configuration** (Resilience4j):\n- Failure threshold: 50% errors over 10 requests\n- Timeout: 5 seconds\n- Fallback strategy: Return cached pricing, queue order for async processing\n\n---\n\n#### Configuration\n\n**Environment Variables**:\n- `DB_URL`: PostgreSQL connection string (required)\n- `KAFKA_BROKERS`: Kafka bootstrap servers (required)\n- `INVENTORY_SERVICE_URL`: Inventory service base URL (default: http://inventory-service:8080)\n- `MAX_ORDER_AMOUNT`: Maximum order amount allowed (default: 10000.00)\n\n**Feature Flags**:\n- `enable_discount_codes`: Enable discount code validation (currently: true)\n- `enable_fraud_detection`: Enable fraud detection integration (currently: false)\n\n**Configuration Source**: Spring Cloud Config Server\n\n---\n\n#### Deployment & Scaling\n\n**Container Image**: `company.azurecr.io/order-service:2.4.1`\n\n**Resource Requirements**:\n- CPU: Requests: 500m, Limits: 2000m\n- Memory: Requests: 1Gi, Limits: 2Gi\n\n**Replicas**:\n- Minimum: 3 (for high availability)\n- Maximum: 15\n\n**Auto-Scaling**:\n- Metric: CPU utilization and custom metric (requests/second)\n- Threshold: 70% CPU or >500 req/sec per pod\n- Scale-up policy: Add 2 pods when threshold exceeded for 2 minutes\n- Scale-down policy: Remove 1 pod when below 40% for 10 minutes\n\n**Deployment Strategy**: Rolling update (max unavailable: 1, max surge: 2)\n\n**Health Checks**:\n- Liveness: `GET /actuator/health/liveness` every 30s, failure threshold: 3\n- Readiness: `GET /actuator/health/readiness` every 10s, failure threshold: 1\n\n---\n\n#### Resilience & Fault Tolerance\n\n**Failure Modes**:\n\n| Failure | Impact | Mitigation | Detection |\n|---------|--------|------------|-----------|\n| PostgreSQL unavailable | Cannot create/read orders | Circuit breaker, return 503 | Health check fails |\n| Inventory Service down | Cannot validate stock | Timeout + retry, fallback to optimistic stock | Circuit breaker opens |\n| Kafka unavailable | Events not published | Local event store, retry on reconnect | Connection monitoring |\n\n**Retry Policy** (Spring Retry):\n- Max retries: 3\n- Backoff strategy: Exponential (2s, 4s, 8s)\n- Retry-eligible errors: HTTP 503, 504, network timeouts\n\n**Timeout Configuration**:\n- HTTP client timeout: 5s (read), 3s (connect)\n- Database query timeout: 3s\n- Kafka event processing timeout: 30s\n\n---\n\n#### Observability\n\n**Logging** (Logback + JSON):\n- Level: INFO (prod), DEBUG (dev)\n- Format: JSON structured with correlation ID\n- Fields: correlation_id, user_id, order_id, http_method, http_status, duration_ms\n- Aggregation: ELK Stack (Elasticsearch, Logstash, Kibana)\n\n**Metrics** (Micrometer + Prometheus):\n- `http_server_requests_seconds`: Request latency histogram\n- `orders_created_total`: Counter of orders created\n- `order_total_amount`: Gauge of order amounts\n- `inventory_check_duration_seconds`: Histogram of inventory service call duration\n\n**Distributed Tracing** (OpenTelemetry + Jaeger):\n- Sampling rate: 100% for errors, 10% for success\n- Trace propagation: W3C Trace Context headers\n\n**Alerts** (Prometheus Alertmanager):\n- Error rate > 5% for 5min ‚Üí Page on-call engineer\n- p99 latency > 2s for 10min ‚Üí Slack #orders-alerts\n- 0 healthy replicas ‚Üí Page on-call immediately\n- Database connection pool >80% ‚Üí Slack warning\n\n---\n\n#### Security\n\n**Authentication**: JWT tokens validated via API Gateway (Auth0 integration)\n\n**Authorization**: RBAC - customers can only access their own orders, admins can access all\n\n**Secrets Management**: AWS Secrets Manager for DB credentials, Kafka credentials\n\n**Encryption**:\n- In-transit: TLS 1.3 for all HTTP, mTLS for service-to-service (via Istio)\n- At-rest: PostgreSQL encryption at rest (AES-256)\n\n**Security Scanning**:\n- SAST: SonarQube in CI pipeline\n- Dependency scanning: Dependabot for CVE detection\n- Container scanning: Trivy in CI/CD\n\n---\n\n#### Testing Strategy\n\n**Unit Tests**: 85% coverage target, JUnit 5 + Mockito\n\n**Integration Tests**: Test with Testcontainers (PostgreSQL, Kafka)\n\n**Contract Tests**: Pact consumer/provider contracts with Inventory, Customer services\n\n**End-to-End Tests**: Order creation ‚Üí payment ‚Üí fulfillment flow (Postman/Newman)\n\n**Load Tests**: Target 500 TPS, p95 latency <300ms (k6 load testing tool)\n\n---\n\n## Guidelines\n\n1. **Complete service catalog** - Document all microservices\n2. **API-first design** - All services must have OpenAPI specs\n3. **Database-per-service** - No shared databases\n4. **Event schema versioning** - Use versioned event schemas\n5. **Observability mandatory** - Logs, metrics, traces for all services\n6. **Circuit breakers** - All synchronous calls must have circuit breakers\n7. **Deployment independence** - Each service deployable independently\n\n---\n\n## Validation Checklist\n\n- [ ] All microservices cataloged with bounded contexts\n- [ ] API specifications documented (OpenAPI preferred)\n- [ ] Database-per-service pattern followed\n- [ ] Events published and consumed documented with schemas\n- [ ] Circuit breakers configured for all sync dependencies\n- [ ] Auto-scaling configured with metrics and thresholds\n- [ ] Health checks (liveness + readiness) implemented\n- [ ] Observability stack integrated (logs, metrics, traces)\n- [ ] Security controls documented (auth, authz, encryption)\n- [ ] Testing strategy defined for each service\n- [ ] Example paths updated to match actual project structure",
        "skills/architecture-readiness/PO_SPEC_SCORING_GUIDE.md": "# Product Owner Specification Scoring Guide\n\n> Evaluation methodology for assessing Product Owner Specification readiness for architecture design\n\n## Purpose\n\nThis guide provides a standardized scoring methodology to evaluate Product Owner Specification documents before handoff to the architecture team. The score (0-10 scale) determines whether a PO Spec provides sufficient business context for architects to begin designing the technical architecture (ARCHITECTURE.md).\n\n**Use this scoring guide when:**\n- Product Owner has completed a PO Specification document\n- Architecture team needs to assess if business requirements are sufficient to start design work\n- Product team wants to validate completeness before architecture handoff meeting\n- Identifying gaps that need clarification before architecture design begins\n\n**Who uses this:**\n- Product Owners (self-assessment before submitting to architecture team)\n- Architecture Team Leads (gate check before accepting PO Spec for architecture work)\n- Product Managers (quality assurance for business requirements documentation)\n\n---\n\n## Scoring Methodology\n\n### Weighted Scoring System\n\nThe PO Specification is scored on a **10-point scale** using weighted sections. Sections critical for architecture design receive higher weights.\n\n**Total Score = Œ£ (Section Completeness % √ó Section Weight)**\n\n### Section Weights\n\n| PO Spec Section | Weight | Priority | Rationale |\n|-----------------|--------|----------|-----------|\n| **4. Use Cases** | 2.5 | HIGH | Defines system behavior that architecture must support |\n| **7. Business Constraints** | 2.0 | HIGH | Constrains architecture decisions (budget, compliance, timeline) |\n| **3. Business Objectives** | 1.5 | HIGH | Justifies architecture choices with business value |\n| **1. Business Context** | 1.0 | MEDIUM | Frames problem that architecture solves |\n| **6. UX Requirements** | 1.0 | MEDIUM | Translates to technical performance SLAs |\n| **8. Success Metrics & KPIs** | 1.0 | MEDIUM | Informs capacity planning and measurement |\n| **2. Stakeholders & Users** | 0.5 | LOW | Provides context but doesn't constrain architecture |\n| **5. User Stories** | 0.5 | LOW | Implementation detail, not architectural significance |\n| **Total** | **10.0** | | |\n\n---\n\n## Evaluation Criteria by Section\n\nFor each section, evaluate completeness using the criteria below, then assign a completeness percentage (0-100%).\n\n### Section 1: Business Context (1.0 point)\n\n**Weight**: 1.0 point (10% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Problem Statement | 40% | Is the business problem clearly articulated with current state pain points? |\n| Market Context | 30% | Are industry trends and competitive landscape described? |\n| Strategic Alignment | 30% | Is alignment with company strategic goals explained? |\n\n**Completeness Scoring:**\n- **100%**: All three criteria fully addressed with specific details\n- **75%**: Two criteria fully addressed, one partially\n- **50%**: One criterion fully addressed, others partially or missing\n- **25%**: All criteria partially addressed with vague details\n- **0%**: Section missing or lacks substance\n\n**Example - 80% Complete:**\n- ‚úÖ Problem statement clearly articulated with quantified pain points\n- ‚úÖ Strategic alignment explained with specific company goals referenced\n- ‚ö†Ô∏è Market context mentioned but lacks competitive analysis\n\n**Weighted Score**: 0.80 √ó 1.0 = **0.80 points**\n\n---\n\n### Section 2: Stakeholders & Users (0.5 points)\n\n**Weight**: 0.5 points (5% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Stakeholder Identification | 30% | Are primary stakeholders identified with roles and influence levels? |\n| User Personas | 50% | Are at least 2 user personas defined with demographics, goals, pain points? |\n| Impact Analysis | 20% | Is impact on different groups (positive/negative) analyzed? |\n\n**Completeness Scoring:**\n- **100%**: 3+ personas with detailed profiles, stakeholders mapped, impact analyzed\n- **75%**: 2 personas with good detail, stakeholders identified\n- **50%**: 1-2 personas with basic detail, stakeholders listed\n- **25%**: Personas mentioned but lack detail\n- **0%**: Section missing or only has stakeholder list without personas\n\n**Example - 60% Complete:**\n- ‚úÖ Stakeholders identified (5 stakeholder groups)\n- ‚ö†Ô∏è 2 personas defined but missing pain points detail\n- ‚ùå No impact analysis provided\n\n**Weighted Score**: 0.60 √ó 0.5 = **0.30 points**\n\n---\n\n### Section 3: Business Objectives (1.5 points)\n\n**Weight**: 1.5 points (15% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Measurable Goals | 30% | Are at least 3 business goals defined with specific metrics and targets? |\n| Success Criteria | 25% | Is MoSCoW prioritization applied (Must/Should/Could/Won't achieve)? |\n| ROI Expectations | 25% | Are investment, expected returns, and payback period calculated? |\n| Timeline & Milestones | 20% | Are launch timeline and key milestones defined? |\n\n**Completeness Scoring:**\n- **100%**: All criteria fully addressed with quantified targets and timelines\n- **75%**: 3+ goals with targets, ROI calculated, success criteria defined\n- **50%**: 2-3 goals with targets, partial ROI or success criteria\n- **25%**: Goals listed but lack specific metrics or targets\n- **0%**: Section missing or only has vague objectives\n\n**Example - 90% Complete:**\n- ‚úÖ 4 measurable goals with specific targets and timeframes\n- ‚úÖ MoSCoW success criteria clearly defined\n- ‚úÖ ROI calculated ($1.5M savings vs. $80K cost)\n- ‚ö†Ô∏è Timeline milestones defined but phases lack specific dates\n\n**Weighted Score**: 0.90 √ó 1.5 = **1.35 points**\n\n---\n\n### Section 4: Use Cases (2.5 points)\n\n**Weight**: 2.5 points (25% of total score) - **HIGHEST PRIORITY**\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Number of Use Cases | 20% | Are at least 3 primary use cases defined? |\n| Use Case Structure | 30% | Does each use case have: description, actors, primary flow, success metrics? |\n| Alternative Flows | 25% | Are alternative flows and edge cases documented? |\n| Business Perspective | 25% | Is the focus on business flows (no technical implementation details)? |\n\n**Completeness Scoring:**\n- **100%**: 3+ complete use cases with all required elements, alternatives, business-focused\n- **75%**: 3 use cases with most elements, some alternatives documented\n- **50%**: 2-3 use cases with partial details, few or no alternatives\n- **25%**: 1-2 use cases with minimal detail\n- **0%**: Section missing or use cases are too vague/technical\n\n**Example - 100% Complete:**\n- ‚úÖ 3 primary use cases defined (Scheduled Transfers, Reminders, Recurring Payments)\n- ‚úÖ Each use case has: description, actors, primary flow, success metrics\n- ‚úÖ Alternative flows documented (e.g., insufficient balance, customer cancellation)\n- ‚úÖ Edge cases addressed (holidays, system downtime)\n- ‚úÖ Pure business perspective, no technical details (no mention of APIs, databases, etc.)\n\n**Weighted Score**: 1.00 √ó 2.5 = **2.50 points**\n\n---\n\n### Section 5: User Stories (0.5 points)\n\n**Weight**: 0.5 points (5% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Number of Stories | 30% | Are at least 5 user stories defined? |\n| Story Format | 30% | Do stories follow \"As a [user], I want [goal], so that [benefit]\" format? |\n| Acceptance Criteria | 30% | Does each story have clear acceptance criteria? |\n| Prioritization | 10% | Is MoSCoW prioritization applied to stories? |\n\n**Completeness Scoring:**\n- **100%**: 5+ stories in proper format with acceptance criteria and prioritization\n- **75%**: 5+ stories with acceptance criteria, most prioritized\n- **50%**: 3-5 stories with basic acceptance criteria\n- **25%**: 1-3 stories or stories lack acceptance criteria\n- **0%**: Section missing or stories are too vague\n\n**Example - 70% Complete:**\n- ‚úÖ 7 user stories defined across 3 epics\n- ‚úÖ All stories in \"As a... I want... So that...\" format\n- ‚úÖ Acceptance criteria provided for each story\n- ‚ö†Ô∏è MoSCoW prioritization applied but some \"Should Have\" vs. \"Could Have\" classifications unclear\n\n**Weighted Score**: 0.70 √ó 0.5 = **0.35 points**\n\n---\n\n### Section 6: User Experience Requirements (1.0 point)\n\n**Weight**: 1.0 point (10% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Performance Expectations | 30% | Are user-facing performance targets specified (page load, transaction speed)? |\n| Usability Requirements | 25% | Are ease of use, learnability, error handling requirements defined? |\n| Accessibility Requirements | 25% | Are accessibility standards (WCAG 2.1) and specific requirements specified? |\n| Cross-Platform Consistency | 20% | Are supported platforms and consistency requirements defined? |\n\n**Completeness Scoring:**\n- **100%**: All criteria fully addressed with specific, measurable targets\n- **75%**: Performance and usability defined, accessibility mentioned\n- **50%**: Performance targets defined, other criteria partial\n- **25%**: Only vague performance expectations\n- **0%**: Section missing or lacks quantifiable requirements\n\n**Example - 85% Complete:**\n- ‚úÖ Performance expectations: <2 seconds page load, <1.5 seconds transaction confirmation\n- ‚úÖ Usability: 95% task completion rate, <5 minutes first-time user success\n- ‚úÖ Accessibility: WCAG 2.1 AA compliance specified\n- ‚ö†Ô∏è Cross-platform: iOS/Android mentioned but consistency requirements not detailed\n\n**Weighted Score**: 0.85 √ó 1.0 = **0.85 points**\n\n---\n\n### Section 7: Business Constraints (2.0 points)\n\n**Weight**: 2.0 points (20% of total score) - **HIGH PRIORITY**\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Budget Constraints | 25% | Are total budget, breakdown, and ongoing costs specified? |\n| Timeline Constraints | 20% | Are launch deadlines, milestones, and flexibility defined? |\n| Regulatory/Compliance | 25% | Are applicable regulations and compliance certifications listed? |\n| Integration Constraints | 15% | Are existing systems and integration limitations documented? |\n| Operational Constraints | 15% | Are support model, maintenance windows, resource constraints defined? |\n\n**Completeness Scoring:**\n- **100%**: All five constraint categories fully addressed with specific details\n- **75%**: Budget, timeline, compliance fully addressed; integration/operational partial\n- **50%**: Budget and timeline defined; other categories partial or missing\n- **25%**: Only budget or timeline mentioned vaguely\n- **0%**: Section missing or lacks critical constraints\n\n**Example - 95% Complete:**\n- ‚úÖ Budget: $5,250/month operational cost, $6,825/month Year 1 projection, detailed breakdown\n- ‚úÖ Timeline: Launch status clear, Phase 2/3 milestones defined, change freeze periods documented\n- ‚úÖ Compliance: PCI-DSS, SOC 2, GDPR, ISO 27001 requirements listed with audit frequency\n- ‚úÖ Integration: Payment service, notification service, CRM integration constraints documented\n- ‚ö†Ô∏è Operational: Support model (24/7) and maintenance windows defined, but resource constraints partially documented (training needs mentioned, team size not specified)\n\n**Weighted Score**: 0.95 √ó 2.0 = **1.90 points**\n\n---\n\n### Section 8: Success Metrics & KPIs (1.0 point)\n\n**Weight**: 1.0 point (10% of total score)\n\n**Evaluation Criteria:**\n\n| Criteria | Points | Evaluation Question |\n|----------|--------|---------------------|\n| Business KPIs | 30% | Are business KPIs defined with baselines, targets, and timeframes? |\n| UX Metrics | 25% | Are user experience metrics specified (completion rate, satisfaction, error rate)? |\n| Adoption Metrics | 20% | Are adoption/usage metrics defined? |\n| Measurement Approach | 25% | Is data collection, reporting frequency, and review cadence documented? |\n\n**Completeness Scoring:**\n- **100%**: All criteria fully addressed with quantified targets and measurement plans\n- **75%**: Business KPIs, UX metrics, and measurement approach defined\n- **50%**: Business KPIs defined, other metrics partial\n- **25%**: Only high-level KPIs mentioned without measurement details\n- **0%**: Section missing or lacks measurable metrics\n\n**Example - 80% Complete:**\n- ‚úÖ Business KPIs: 4 KPIs with baselines, targets, timeframes, owners (50K-75K daily ops, 70% cost reduction, 99.99% reliability, 100% audit trails)\n- ‚úÖ UX Metrics: Task completion (>95%), CSAT (>4.5/5.0), error rates (<1%)\n- ‚úÖ Adoption Metrics: Customer adoption (40% by Month 12), recurring payments (50K by Month 12)\n- ‚ö†Ô∏è Measurement Approach: Data sources and reporting frequency defined, but dashboard details partial\n\n**Weighted Score**: 0.80 √ó 1.0 = **0.80 points**\n\n---\n\n## Scoring Interpretation\n\n### Score Ranges\n\n| Score Range | Rating | Interpretation | Recommendation |\n|-------------|--------|----------------|----------------|\n| **9.0-10.0** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | Comprehensive PO Spec with all critical sections complete. Architecture team has everything needed to begin design. | ‚úÖ **Approved**: Proceed with architecture handoff meeting and begin ARCHITECTURE.md creation. |\n| **7.5-8.9** | ‚≠ê‚≠ê‚≠ê‚≠ê Good | Strong PO Spec with minor gaps in lower-priority sections. Architecture team can proceed with clarifications during handoff meeting. | ‚úÖ **Approved with Clarifications**: Schedule architecture handoff meeting; prepare list of clarifying questions for gaps. |\n| **6.0-7.4** | ‚≠ê‚≠ê‚≠ê Adequate | Moderate gaps in important sections. Architecture team needs revisions before starting design work. | ‚ö†Ô∏è **Revisions Required**: Return to Product Owner with specific feedback on gaps; request updates to critical sections before handoff. |\n| **4.0-5.9** | ‚≠ê‚≠ê Needs Work | Significant gaps in critical sections (Use Cases, Constraints, Objectives). Not ready for architecture team. | ‚ùå **Not Ready**: Product Owner needs to substantially complete missing sections; schedule review meeting to discuss gaps. |\n| **0.0-3.9** | ‚≠ê Incomplete | Major sections missing or insufficient. Substantial work required before architecture can begin. | ‚ùå **Not Ready**: Return to Product Owner with comprehensive feedback; may need to restart PO Spec using template. |\n\n### Minimum \"Ready\" Score\n\n**Threshold: 7.5/10**\n\nRationale:\n- Ensures critical HIGH-PRIORITY sections (Use Cases, Business Constraints, Business Objectives) are substantially complete\n- Allows minor gaps in MEDIUM/LOW-PRIORITY sections (Personas, User Stories) that can be clarified during handoff\n- Balances quality gate with pragmatism - perfection not required if core architecture inputs are solid\n- Score ‚â•7.5 means architecture team has sufficient business context to make informed design decisions\n\n---\n\n## Complete Scoring Example\n\n### Hypothetical PO Spec: \"Task Scheduling System\"\n\n**Section-by-Section Evaluation:**\n\n| Section | Completeness | Weight | Weighted Score | Rationale |\n|---------|--------------|--------|----------------|-----------|\n| **1. Business Context** | 80% | 1.0 | **0.80** | Problem statement and strategic alignment strong; market context partially addressed |\n| **2. Stakeholders & Users** | 60% | 0.5 | **0.30** | Stakeholders identified; 3 personas defined but pain points need more detail |\n| **3. Business Objectives** | 90% | 1.5 | **1.35** | 4 measurable goals with ROI calculated; timeline milestones defined |\n| **4. Use Cases** | 100% | 2.5 | **2.50** | 3 complete use cases with alternatives, edge cases, business-focused |\n| **5. User Stories** | 70% | 0.5 | **0.35** | 7 user stories with acceptance criteria; prioritization applied |\n| **6. UX Requirements** | 85% | 1.0 | **0.85** | Performance, usability, accessibility defined; cross-platform partial |\n| **7. Business Constraints** | 95% | 2.0 | **1.90** | Budget, timeline, compliance, integration, operational constraints documented |\n| **8. Success Metrics & KPIs** | 80% | 1.0 | **0.80** | Business KPIs, UX metrics, adoption metrics defined; measurement approach documented |\n| **Total** | | **10.0** | **8.85** | |\n\n**Overall Score: 8.85/10** = ‚≠ê‚≠ê‚≠ê‚≠ê **Good - Ready for Architecture Design**\n\n**Strengths:**\n- ‚úÖ **Excellent Use Cases** (100%): 3 complete use cases with alternatives, edge cases, pure business perspective\n- ‚úÖ **Strong Business Constraints** (95%): Budget, timeline, compliance requirements clearly documented\n- ‚úÖ **Clear Business Objectives** (90%): Measurable goals with ROI justification\n\n**Areas for Improvement:**\n- ‚ö†Ô∏è **Stakeholders & Users** (60%): Personas need more detailed pain points; consider adding 1-2 more personas for completeness\n- ‚ö†Ô∏è **User Stories** (70%): Prioritization applied but some \"Should Have\" vs. \"Could Have\" distinctions unclear\n\n**Recommendation:**\n‚úÖ **Approved with Clarifications**\n\nProceed with architecture handoff meeting. During meeting:\n1. Clarify user persona pain points (especially Operations Manager and Customer personas)\n2. Validate user story prioritization (confirm \"Must Have\" vs. \"Should Have\" for Phase 1 launch)\n3. Confirm cross-platform consistency requirements (iOS/Android feature parity expectations)\n\nArchitecture team has sufficient context to begin ARCHITECTURE.md creation. Minor gaps can be addressed during design phase.\n\n---\n\n## Gap Analysis & Feedback\n\nWhen a PO Spec scores below threshold (< 7.5/10), provide actionable feedback using this framework:\n\n### Feedback Template\n\n**Overall Score**: [X.XX/10] - [Rating]\n\n**Status**: ‚ùå Not Ready / ‚ö†Ô∏è Revisions Required / ‚úÖ Approved with Clarifications / ‚úÖ Approved\n\n**Critical Gaps** (sections scoring <50% completeness with weight ‚â•1.0):\n- **Section [#]: [Name]** (Completeness: [X]%, Weight: [Y], Score: [Z])\n  - **Missing**: [Specific missing elements]\n  - **Actionable Feedback**: [What needs to be added/improved]\n  - **Example**: [Reference to PO_SPEC_GUIDE.md example or template]\n\n**Moderate Gaps** (sections scoring 50-74% completeness with weight ‚â•1.0):\n- **Section [#]: [Name]** (Completeness: [X]%, Weight: [Y], Score: [Z])\n  - **Partially Addressed**: [What's present but incomplete]\n  - **Needs Enhancement**: [Specific improvements needed]\n  - **Example**: [Reference to PO_SPEC_GUIDE.md example]\n\n**Minor Gaps** (sections scoring 75-89% completeness or weight <1.0):\n- **Section [#]: [Name]** (Completeness: [X]%, Weight: [Y], Score: [Z])\n  - **Mostly Complete**: [What's well done]\n  - **Polish Needed**: [Minor improvements suggested]\n\n**Next Steps**:\n1. [Specific action item 1]\n2. [Specific action item 2]\n3. [Schedule follow-up review meeting / Proceed with handoff]\n\n---\n\n### Example Gap Analysis Feedback\n\n**Overall Score**: 6.2/10 - ‚≠ê‚≠ê‚≠ê Adequate\n\n**Status**: ‚ö†Ô∏è **Revisions Required**\n\n**Critical Gaps:**\n\n**Section 4: Use Cases** (Completeness: 40%, Weight: 2.5, Score: 1.0/2.5)\n- **Missing**:\n  - Only 1 use case defined (need minimum 3 primary use cases)\n  - Use case lacks alternative flows and edge cases\n  - Success metrics not specified\n- **Actionable Feedback**:\n  - Add 2 more primary use cases (reference PRODUCT_OWNER_SPEC_GUIDE.md Section 4 examples)\n  - For each use case, document: description, actors, primary flow, alternative flows, edge cases, success metrics\n  - Ensure use cases focus on business flows, not technical implementation details\n- **Example**: See \"Use Case 1: Scheduled Transfers\" in PRODUCT_OWNER_SPEC_GUIDE.md lines 101-118\n\n**Section 7: Business Constraints** (Completeness: 50%, Weight: 2.0, Score: 1.0/2.0)\n- **Missing**:\n  - Budget constraints not specified\n  - Regulatory/compliance requirements not listed\n  - Integration constraints not documented\n- **Actionable Feedback**:\n  - Add budget section: total budget, monthly operational cost, breakdown by service\n  - List applicable regulations (PCI-DSS, SOC 2, GDPR, etc.) and compliance certifications needed\n  - Document existing systems to integrate with and known limitations\n- **Example**: See Section 7 template in PRODUCT_OWNER_SPEC_GUIDE.md\n\n**Moderate Gaps:**\n\n**Section 3: Business Objectives** (Completeness: 60%, Weight: 1.5, Score: 0.9/1.5)\n- **Partially Addressed**: 2 business goals defined with targets\n- **Needs Enhancement**:\n  - Add 1-2 more measurable goals (minimum 3 required)\n  - Calculate ROI: investment, expected returns, payback period\n  - Add MoSCoW success criteria (Must/Should/Could/Won't achieve)\n  - Define timeline milestones for Phases 1-3\n- **Example**: See Section 3 example with ROI calculation in guide\n\n**Minor Gaps:**\n\n**Section 2: Stakeholders & Users** (Completeness: 75%, Weight: 0.5, Score: 0.375/0.5)\n- **Mostly Complete**: Stakeholders identified, 2 personas defined\n- **Polish Needed**: Add more detail to persona pain points and goals\n\n**Next Steps**:\n1. **Product Owner**: Address critical gaps in Use Cases and Business Constraints sections (estimated effort: 4-6 hours)\n2. **Product Owner**: Enhance Business Objectives section with ROI calculation and additional goals (estimated effort: 2 hours)\n3. **Product Team**: Schedule review meeting in 1 week to re-evaluate updated PO Spec\n4. **Target**: Achieve score ‚â•7.5/10 to proceed with architecture handoff\n\n---\n\n## Best Practices for Scoring\n\n### For Product Owners (Self-Assessment)\n\n1. **Use Checklist Approach**: For each section, go through evaluation criteria checklist before submitting PO Spec\n2. **Target High-Priority Sections First**: Ensure Use Cases, Business Constraints, and Business Objectives are complete (these account for 6.0/10 points)\n3. **Be Honest About Gaps**: Self-assess objectively; better to identify gaps yourself than have architecture team return document\n4. **Reference Examples**: Use examples in PRODUCT_OWNER_SPEC_GUIDE.md to understand expected level of detail\n5. **Aim for 8.0+**: Target score of 8.0-9.0 to ensure smooth handoff without need for clarifications\n\n### For Architecture Team (Gate Check)\n\n1. **Consistent Evaluation**: Use same criteria for all PO Specs to ensure fair, objective scoring\n2. **Provide Actionable Feedback**: Don't just return score; include specific gaps and examples to guide improvements\n3. **Focus on Critical Sections**: Prioritize feedback on HIGH-PRIORITY sections (Use Cases, Constraints, Objectives)\n4. **Balance Quality with Pragmatism**: Score ‚â•7.5 is sufficient to proceed if critical sections are strong\n5. **Document Assumptions**: If approving with clarifications, document assumptions and plan to validate during handoff meeting\n\n### Common Pitfalls\n\n‚ùå **Don't**:\n- Score sections equally (some sections are more architecturally critical than others)\n- Reject PO Spec for minor gaps in low-priority sections (User Stories, Personas)\n- Expect 10/10 perfection (7.5-8.5 is typically sufficient for architecture work to begin)\n- Provide vague feedback (\"needs more detail\" without specifying what)\n\n‚úÖ **Do**:\n- Weight Use Cases, Business Constraints, Business Objectives highest (they constrain architecture)\n- Allow minor gaps if critical sections are strong (can clarify during handoff)\n- Balance quality gate with pragmatism (architecture team can work with 7.5+ score)\n- Provide specific, actionable feedback with examples from guide\n\n---\n\n## Integration with Architecture-Readiness Skill\n\n### When to Score a PO Spec\n\n**Automatic Scoring Triggers:**\n1. Product Owner completes PO Spec and requests review\n2. Product Owner invokes `/skill architecture-readiness` with \"score\" or \"evaluate\" command\n3. Architecture team receives PO Spec and needs to validate readiness\n\n**Scoring Workflow:**\n1. Product Owner creates PO Spec using PRODUCT_OWNER_SPEC_GUIDE.md template\n2. Product Owner self-assesses using this scoring guide (optional but recommended)\n3. Product Owner submits PO Spec to architecture team for review\n4. Architecture team scores PO Spec using this methodology\n5. If score ‚â•7.5: Schedule architecture handoff meeting, proceed with ARCHITECTURE.md creation\n6. If score <7.5: Return to Product Owner with gap analysis feedback, request revisions\n\n**Skill Usage:**\n```\n/skill architecture-readiness evaluate [PO_SPEC_FILE]\n```\n\nThis command will:\n- Read the specified PO Spec document\n- Evaluate each of the 8 sections against criteria\n- Calculate weighted score\n- Provide score interpretation and feedback\n- Recommend next steps (Approved / Revisions Required / Not Ready)\n\n---\n\n## References\n\n### Related Guides\n- [PRODUCT_OWNER_SPEC_GUIDE.md](PRODUCT_OWNER_SPEC_GUIDE.md) - Complete guide for creating PO Specifications with examples\n- [ARCHITECTURE_DOCUMENTATION_GUIDE.md](../architecture-docs/ARCHITECTURE_DOCUMENTATION_GUIDE.md) - Architecture documentation guide that uses PO Spec as input\n- [SKILL.md](SKILL.md) - Architecture-readiness skill instructions\n\n### Scoring Criteria Summary\n\nQuick reference for section weights:\n\n```\nHIGH PRIORITY (6.0 points total):\n  4. Use Cases:            2.5 points (25%)\n  7. Business Constraints: 2.0 points (20%)\n  3. Business Objectives:  1.5 points (15%)\n\nMEDIUM PRIORITY (3.0 points total):\n  1. Business Context:         1.0 point (10%)\n  6. UX Requirements:          1.0 point (10%)\n  8. Success Metrics & KPIs:   1.0 point (10%)\n\nLOW PRIORITY (1.0 point total):\n  2. Stakeholders & Users: 0.5 points (5%)\n  5. User Stories:         0.5 points (5%)\n\nMinimum \"Ready\" Score: 7.5/10\n```\n\n---\n\n**Document Version**: 1.0.0\n**Last Updated**: 2025-01-25\n**Maintained By**: Architecture Team",
        "skills/architecture-readiness/PRODUCT_OWNER_SPEC_GUIDE.md": "# Product Owner Specification Guide\n\n> A comprehensive guide for Product Owners to document business requirements and context before architecture design\n\n## Purpose\n\nThis guide provides a structured approach for Product Owners to capture business context, requirements, and success criteria that will inform the creation of technical architecture documentation (ARCHITECTURE.md).\n\n**Use this guide when:**\n- Starting a new product or feature initiative\n- Defining business requirements before technical design begins\n- Communicating business value and user needs to the architecture team\n- Establishing success criteria and KPIs for a new system\n- Creating a handoff document from business to technical teams\n\n**Who writes this:**\n- Product Owners\n- Product Managers\n- Business Analysts (working with Product Owners)\n\n**Output:**\nA Product Owner Specification document that feeds directly into ARCHITECTURE.md creation by the architecture team.\n\n---\n\n## How This Fits Into Your Workflow\n\n```\n1. Product Owner Specification (This Guide)\n   ‚Üì\n   [Business Requirements Captured]\n   ‚Üì\n2. Architecture Review & Design\n   ‚Üì\n   [Architecture Team Creates ARCHITECTURE.md]\n   ‚Üì\n3. Implementation Planning\n   ‚Üì\n   [Development Teams Build Solution]\n```\n\n**Key Principle**: This document focuses on **WHAT** and **WHY** (business perspective), while ARCHITECTURE.md focuses on **HOW** (technical implementation).\n\n---\n\n## Document Structure Overview\n\nA comprehensive Product Owner Specification should follow this 8-section structure:\n\n```\n1. Business Context\n2. Stakeholders & Users\n3. Business Objectives\n4. Use Cases\n5. User Stories\n6. User Experience Requirements\n7. Business Constraints\n8. Success Metrics & KPIs\n```\n\n---\n\n## Section 1: Business Context\n\n**Purpose**: Explain the business problem or opportunity that motivates this initiative.\n\n**Template:**\n```markdown\n## 1. Business Context\n\n### Problem Statement\n\n[Describe the business problem or opportunity]\n\n**Current State:**\n- Current process/system limitations\n- Pain points experienced by users or business\n- Impact on business operations\n- Market pressures or competitive threats\n\n**Desired Future State:**\n- How things should work\n- Expected improvements\n- Competitive advantage gained\n\n### Market Context\n\n**Industry Trends:**\n- Relevant market trends driving this initiative\n- Customer expectations evolving in the market\n- Regulatory or compliance changes\n\n**Competitive Landscape:**\n- How competitors are addressing this problem\n- Our competitive position\n- Differentiation opportunities\n\n### Strategic Alignment\n\n**Strategic Goals:**\n- Company strategic objectives this supports\n- Business unit goals addressed\n- Multi-year roadmap positioning\n\n**Timing:**\n- Why now? (urgency, market window, dependencies)\n```\n\n**Example:**\n```markdown\n## 1. Business Context\n\n### Problem Statement\n\n**Current State:**\nCustomers currently must visit a branch or use phone banking to schedule future transfers, resulting in:\n- 15,000 monthly customer service calls for transfer scheduling (avg 8 min/call = 2,000 hours)\n- 45% of customers abandoning transfer setup due to friction\n- $180,000/month in operational costs for manual transfer processing\n- Missed revenue opportunities as customers use competitor apps offering this feature\n\n**Desired Future State:**\nCustomers should be able to schedule one-time and recurring transfers instantly via mobile app:\n- Self-service scheduling available 24/7\n- Reduction in customer service call volume by 70%\n- Improved customer satisfaction and retention\n- Competitive parity with top 3 banking apps in our market\n\n### Market Context\n\n**Industry Trends:**\n- 78% of banking customers expect mobile self-service for all common transactions (2024 Banking CX Report)\n- Scheduled transfers are the #3 most requested mobile banking feature (Industry Survey 2024)\n- Regulatory push for transparent, customer-controlled financial operations\n\n**Competitive Landscape:**\n- Top 3 competitors all offer mobile scheduled transfers\n- We are losing 5% market share annually to digital-first competitors\n- Customer reviews cite lack of self-service transfer scheduling as a top complaint\n\n### Strategic Alignment\n\n**Strategic Goals:**\n- Supports \"Digital First\" strategic initiative (2024-2026 roadmap)\n- Aligns with \"Customer Self-Service\" program to reduce operational costs by 30%\n- Enables \"Always-On Banking\" vision for 24/7 customer access\n\n**Timing:**\n- Must launch before Q3 2025 to align with marketing campaign\n- Competitor XYZ launching enhanced transfer features in Q2 2025\n- Existing infrastructure refresh creates ideal implementation window\n```\n\n---\n\n## Section 2: Stakeholders & Users\n\n**Purpose**: Identify who is impacted and who will use the system.\n\n**Template:**\n```markdown\n## 2. Stakeholders & Users\n\n### Primary Stakeholders\n\n| Stakeholder | Role | Interest/Concern | Influence Level |\n|-------------|------|------------------|-----------------|\n| [Name/Group] | [Role] | [What they care about] | High/Medium/Low |\n\n### User Personas\n\n#### Persona 1: [Name]\n\n**Demographics:**\n- Age range\n- Tech savviness\n- Banking usage patterns\n\n**Goals:**\n- Primary goal 1\n- Primary goal 2\n\n**Pain Points:**\n- Current frustration 1\n- Current frustration 2\n\n**Needs from This System:**\n- Need 1\n- Need 2\n\n#### Persona 2: [Name]\n[Repeat structure]\n\n### User Segments\n\n**Segment 1: [Name]**\n- Size: [Number or percentage of users]\n- Characteristics: [Defining traits]\n- Priority: High/Medium/Low\n\n### Impact Analysis\n\n**Positively Impacted:**\n- Group 1: [Expected benefit]\n- Group 2: [Expected benefit]\n\n**Change Management Considerations:**\n- Group requiring training\n- Communication strategy needs\n- Resistance expected from [group] due to [reason]\n```\n\n**Example:**\n```markdown\n## 2. Stakeholders & Users\n\n### Primary Stakeholders\n\n| Stakeholder | Role | Interest/Concern | Influence Level |\n|-------------|------|------------------|-----------------|\n| Sarah Chen | VP Digital Banking | Customer retention, digital engagement metrics | High |\n| Marcus Johnson | Head of Operations | Cost reduction, operational efficiency | High |\n| Legal & Compliance | Regulatory Compliance | Regulatory adherence, audit trail | High |\n| Customer Service Team | Support Operations | Call volume reduction, training needs | Medium |\n| Mobile App Development | IT Delivery | Technical feasibility, timeline | Medium |\n\n### User Personas\n\n#### Persona 1: Busy Professional (Primary)\n\n**Demographics:**\n- Age: 28-45\n- Tech Savviness: High\n- Mobile-first, rarely visits branch\n- Manages 3-5 regular bill payments\n\n**Goals:**\n- Automate recurring payments (rent, utilities)\n- Schedule transfers without phone calls\n- Track all scheduled transactions in one place\n\n**Pain Points:**\n- Forgets to make manual payments on time\n- Frustrated by need to call customer service\n- Wants instant confirmation and ability to modify schedules\n\n**Needs from This System:**\n- One-tap recurring payment setup\n- Reminders before scheduled transfers execute\n- Easy modification/cancellation of scheduled transfers\n\n#### Persona 2: Retiree Managing Fixed Income (Secondary)\n\n**Demographics:**\n- Age: 65+\n- Tech Savviness: Medium\n- Uses both mobile and branch services\n- Fixed income, predictable expenses\n\n**Goals:**\n- Set up automatic monthly bill payments\n- Ensure bills paid on time from fixed income\n- Understand what's scheduled and when\n\n**Pain Points:**\n- Anxiety about missing payments\n- Overwhelmed by complex banking apps\n- Needs clear, simple confirmation\n\n**Needs from This System:**\n- Simple, guided setup process\n- Clear calendar view of all scheduled transfers\n- Email/SMS confirmations\n\n### User Segments\n\n**Segment 1: High-Value Customers (Target)**\n- Size: 120,000 customers (15% of active mobile users)\n- Characteristics: >$50K deposits, 3+ active products, digital-first\n- Priority: High\n- Expected Adoption: 65% within 6 months\n\n**Segment 2: Mass Market Customers**\n- Size: 600,000 customers (75% of active mobile users)\n- Characteristics: Primary checking account, moderate engagement\n- Priority: Medium\n- Expected Adoption: 35% within 12 months\n\n### Impact Analysis\n\n**Positively Impacted:**\n- **Customers**: Gain 24/7 self-service, reduce reliance on customer service calls\n- **Customer Service Team**: 70% call volume reduction frees capacity for complex issues\n- **Operations Team**: $126,000/month cost savings from automation\n\n**Change Management Considerations:**\n- Customer Service Team needs training on new feature for support (2-week training plan)\n- Marketing campaign required to drive adoption (in-app notifications, email)\n- Minimal resistance expected; highly requested feature\n```\n\n---\n\n## Section 3: Business Objectives\n\n**Purpose**: Define what success looks like from a business perspective.\n\n**Template:**\n```markdown\n## 3. Business Objectives\n\n### Primary Business Goals\n\n1. **Goal 1: [Description]**\n   - Metric: [How measured]\n   - Target: [Specific target value]\n   - Timeframe: [When to achieve]\n\n2. **Goal 2: [Description]**\n   - Metric: [How measured]\n   - Target: [Specific target value]\n   - Timeframe: [When to achieve]\n\n### Success Criteria\n\n**Must Achieve (Critical):**\n- Criteria 1\n- Criteria 2\n\n**Should Achieve (Important):**\n- Criteria 1\n- Criteria 2\n\n**Could Achieve (Nice to Have):**\n- Criteria 1\n- Criteria 2\n\n### ROI Expectations\n\n**Investment:**\n- Development cost estimate: $[Amount]\n- Implementation timeline: [Duration]\n- Ongoing operational costs: $[Amount]/month\n\n**Expected Returns:**\n- Cost savings: $[Amount]/year\n- Revenue impact: $[Amount]/year\n- Payback period: [Months]\n\n**Non-Financial Benefits:**\n- Customer satisfaction improvement\n- Competitive positioning\n- Strategic capabilities unlocked\n\n### Timeline & Milestones\n\n**Phase 1: [Name]**\n- Target Date: [Date]\n- Deliverables: [What's delivered]\n- Success Criteria: [How evaluated]\n\n**Phase 2: [Name]**\n[Repeat structure]\n```\n\n**Example:**\n```markdown\n## 3. Business Objectives\n\n### Primary Business Goals\n\n1. **Reduce Operational Costs**\n   - Metric: Monthly customer service call volume for transfer scheduling\n   - Target: Reduce from 15,000 to 4,500 calls/month (70% reduction)\n   - Timeframe: 6 months post-launch\n\n2. **Improve Customer Retention**\n   - Metric: Customer churn rate for digital-first segment\n   - Target: Reduce churn from 8% to 5% annually\n   - Timeframe: 12 months post-launch\n\n3. **Increase Digital Engagement**\n   - Metric: Mobile app active users\n   - Target: Increase from 800,000 to 950,000 monthly active users\n   - Timeframe: 12 months post-launch\n\n### Success Criteria\n\n**Must Achieve (Critical):**\n- 50,000+ customers using scheduled transfers within 6 months\n- 70% reduction in transfer-related customer service calls\n- Zero critical security incidents or regulatory violations\n- 95% transaction success rate (scheduled transfers execute correctly)\n\n**Should Achieve (Important):**\n- 4.5+ star rating for feature in app store reviews\n- 80% customer satisfaction score for users of the feature\n- 30% of high-value customers adopt feature within 12 months\n\n**Could Achieve (Nice to Have):**\n- Recognition in industry awards for digital banking innovation\n- Feature becomes top 3 most-used in mobile app\n- Cross-sell opportunity: 15% of users also adopt investment products\n\n### ROI Expectations\n\n**Investment:**\n- Development cost estimate: $450,000 (architecture, development, testing)\n- Implementation timeline: 6 months\n- Ongoing operational costs: $15,000/month (infrastructure, support)\n\n**Expected Returns:**\n- Cost savings: $1,512,000/year (70% reduction in 15K calls √ó $8/call √ó 12 months)\n- Revenue impact: $240,000/year (reduced churn retains 500 customers √ó $40/month avg revenue)\n- Payback period: 3 months\n\n**Non-Financial Benefits:**\n- Customer satisfaction: Expected NPS increase of 12 points\n- Competitive positioning: Parity with top 3 competitors\n- Strategic capabilities: Foundation for future automation features (bill pay, investment transfers)\n\n### Timeline & Milestones\n\n**Phase 1: MVP Launch**\n- Target Date: Q3 2025 (July 1)\n- Deliverables:\n  - One-time scheduled transfers\n  - Basic recurring transfers (weekly, monthly)\n  - Mobile app integration\n- Success Criteria: 10,000 users in first month\n\n**Phase 2: Enhanced Features**\n- Target Date: Q4 2025 (October 1)\n- Deliverables:\n  - Advanced recurring patterns (bi-weekly, custom schedules)\n  - Transfer templates for common scenarios\n  - Integration with bill pay\n- Success Criteria: 35,000 active users, 4.5+ star rating\n\n**Phase 3: Optimization**\n- Target Date: Q1 2026 (January 1)\n- Deliverables:\n  - AI-powered transfer suggestions\n  - Bulk transfer scheduling\n  - Cross-border transfer scheduling\n- Success Criteria: 50,000+ active users, top 3 most-used feature\n```\n\n---\n\n## Section 4: Use Cases\n\n**Purpose**: Describe high-level scenarios showing how users will interact with the system.\n\n**Template:**\n```markdown\n## 4. Use Cases\n\n### Use Case 1: [Name]\n\n**Description**: [What the user is trying to accomplish]\n\n**Actors**: [Who is involved]\n\n**Preconditions**: [What must be true before this use case starts]\n\n**Primary Flow**:\n1. Step 1\n2. Step 2\n3. Step 3\n4. [Continue...]\n\n**Alternative Flows**:\n- **Alternative 1**: [Scenario description]\n  - Steps differ at: [Step number]\n  - Flow: [Describe alternative steps]\n\n**Edge Cases**:\n- Edge case 1: [How handled]\n- Edge case 2: [How handled]\n\n**Postconditions**: [System state after successful completion]\n\n**Success Metrics**:\n- Completion rate: [Target %]\n- Time to complete: [Target time]\n- Error rate: [Target %]\n\n### Use Case 2: [Name]\n[Repeat structure]\n```\n\n**Example:**\n```markdown\n## 4. Use Cases\n\n### Use Case 1: Schedule One-Time Transfer\n\n**Description**: Customer schedules a future transfer between their own accounts for a specific date.\n\n**Actors**:\n- Customer (mobile app user)\n- Banking system (backend processing)\n\n**Preconditions**:\n- Customer is authenticated in mobile app\n- Customer has at least 2 accounts (source and destination)\n- Customer has sufficient balance for transfer\n\n**Primary Flow**:\n1. Customer opens mobile app and navigates to \"Transfers\" section\n2. Customer selects \"Schedule Transfer\" option\n3. System displays account selection screen\n4. Customer selects source account (e.g., Checking)\n5. Customer selects destination account (e.g., Savings)\n6. Customer enters transfer amount (e.g., $500)\n7. Customer selects future date (e.g., \"First day of next month\")\n8. System displays summary with transfer details and execution date\n9. Customer confirms transfer\n10. System creates scheduled transfer and displays confirmation with transaction ID\n11. System sends confirmation email/SMS to customer\n\n**Alternative Flows**:\n- **Alternative 1: Insufficient Balance on Execution Date**\n  - Steps differ at: Step 9\n  - Flow:\n    1. System validates balance will be sufficient on execution date\n    2. If insufficient, system warns customer but allows scheduling\n    3. On execution date, if balance still insufficient, system retries 3 times over 24 hours\n    4. If still unsuccessful, system notifies customer of failed transfer\n\n- **Alternative 2: Customer Modifies Scheduled Transfer**\n  - Customer navigates to \"Scheduled Transfers\" list\n  - Customer selects transfer to modify\n  - Customer changes amount or date\n  - System updates scheduled transfer and sends confirmation\n\n**Edge Cases**:\n- **Holiday/Weekend**: If execution date falls on bank holiday or weekend, system executes on next business day (customer informed during setup)\n- **Account Closure**: If source or destination account closed before execution, system cancels transfer and notifies customer\n- **Same Account Transfer**: System prevents customer from selecting same account as source and destination\n\n**Postconditions**:\n- Scheduled transfer record created in system\n- Customer receives confirmation (email/SMS)\n- Transfer appears in \"Scheduled Transfers\" list in app\n- On execution date, transfer processes automatically\n\n**Success Metrics**:\n- Completion rate: 90% of customers who start scheduling complete it\n- Time to complete: <2 minutes average\n- Error rate: <1% failed executions due to system errors\n\n---\n\n### Use Case 2: Set Up Recurring Payment\n\n**Description**: Customer sets up automatic monthly recurring transfer (e.g., rent payment).\n\n**Actors**:\n- Customer (mobile app user)\n- Banking system (recurring job scheduler)\n\n**Preconditions**:\n- Customer is authenticated in mobile app\n- Customer has at least 1 account with recurring payment capability\n\n**Primary Flow**:\n1. Customer opens mobile app and navigates to \"Transfers\" section\n2. Customer selects \"Recurring Payment\" option\n3. Customer enters payment recipient details (account number, routing number)\n4. Customer enters payment amount (e.g., $1,200)\n5. Customer selects frequency (e.g., \"Monthly on the 1st\")\n6. Customer sets start date and optional end date\n7. System displays summary with recurring schedule preview (next 3 execution dates)\n8. Customer confirms recurring payment setup\n9. System creates recurring payment schedule and displays confirmation\n10. System sends confirmation email with schedule details\n11. 3 days before each execution, system sends reminder notification\n\n**Alternative Flows**:\n- **Alternative 1: Customer Pauses Recurring Payment**\n  - Customer navigates to \"Recurring Payments\" list\n  - Customer selects payment to pause\n  - Customer chooses \"Pause\" and selects resume date\n  - System pauses payment and sends confirmation\n\n- **Alternative 2: Customer Cancels Recurring Payment**\n  - Customer navigates to \"Recurring Payments\" list\n  - Customer selects payment to cancel\n  - Customer confirms cancellation\n  - System cancels future payments (retains history) and sends confirmation\n\n**Edge Cases**:\n- **Insufficient Balance**: System sends alert 3 days before execution if balance projected to be insufficient\n- **Variable Amount**: For variable payments (e.g., utility bills), customer can set max amount limit and approve each execution\n- **End Date Reached**: System automatically stops recurring payment after final execution and notifies customer\n\n**Postconditions**:\n- Recurring payment schedule created in system\n- Payment executes automatically on specified frequency\n- Customer receives reminders before each execution\n- Payment history tracked for reporting\n\n**Success Metrics**:\n- Setup completion rate: 85% complete setup process\n- Time to complete: <3 minutes average\n- Recurring payment reliability: 99.5% execute on schedule without manual intervention\n\n---\n\n### Use Case 3: Review and Modify Scheduled Transfers\n\n**Description**: Customer views all upcoming scheduled transfers and modifies or cancels as needed.\n\n**Actors**: Customer (mobile app user)\n\n**Preconditions**:\n- Customer has at least 1 scheduled transfer in the system\n\n**Primary Flow**:\n1. Customer opens mobile app and navigates to \"Scheduled Transfers\"\n2. System displays list of all upcoming transfers sorted by execution date\n3. Customer selects a transfer to view details\n4. System displays full transfer details (amount, accounts, date, status)\n5. Customer chooses action: \"Modify\", \"Cancel\", or \"Execute Now\"\n6. For \"Modify\": Customer updates amount or date, confirms changes\n7. For \"Cancel\": Customer confirms cancellation\n8. For \"Execute Now\": Customer confirms immediate execution (bypasses schedule)\n9. System processes action and displays confirmation\n10. System sends notification of change\n\n**Success Metrics**:\n- Modification success rate: 98% of modification attempts succeed\n- Cancellation rate: <15% of scheduled transfers cancelled (indicates feature stability)\n```\n\n---\n\n## Section 5: User Stories\n\n**Purpose**: Provide detailed, implementation-ready user stories with acceptance criteria.\n\n**Template:**\n```markdown\n## 5. User Stories\n\n### Epic: [Epic Name]\n\n#### Story 1: [Story Title]\n\n**User Story:**\nAs a [user type],\nI want [goal/desire],\nSo that [benefit/value].\n\n**Acceptance Criteria:**\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] Criterion 3\n\n**Priority**: Must Have | Should Have | Could Have | Won't Have (MoSCoW)\n\n**Business Value**: [Why this is important]\n\n**Dependencies**: [Other stories or systems this depends on]\n\n**Notes**: [Additional context, edge cases, or clarifications]\n\n---\n\n#### Story 2: [Story Title]\n[Repeat structure]\n\n### Epic: [Another Epic Name]\n[Group related stories]\n```\n\n**Example:**\n```markdown\n## 5. User Stories\n\n### Epic: Schedule One-Time Transfers\n\n#### Story 1: Basic Transfer Scheduling\n\n**User Story:**\nAs a mobile banking customer,\nI want to schedule a one-time transfer between my accounts for a future date,\nSo that I can plan my finances without remembering to make the transfer manually.\n\n**Acceptance Criteria:**\n- [ ] User can select source and destination accounts from their account list\n- [ ] User can enter transfer amount with validation (min $1, max account balance)\n- [ ] User can select execution date up to 1 year in future using calendar picker\n- [ ] System displays clear summary before confirmation (amount, accounts, date)\n- [ ] User receives confirmation screen with unique transaction ID\n- [ ] User receives email confirmation within 5 minutes of scheduling\n- [ ] Scheduled transfer appears in \"Scheduled Transfers\" list immediately\n\n**Priority**: Must Have\n\n**Business Value**: Core functionality; enables 70% of expected use cases\n\n**Dependencies**:\n- Account service API for account balance queries\n- Transfer service API for transaction processing\n\n**Notes**:\n- Exclude weekends/holidays from selectable dates (or auto-adjust to next business day)\n- Validate sufficient balance at scheduling time (warning only, not blocking)\n\n---\n\n#### Story 2: Transfer Scheduling Confirmation & Notifications\n\n**User Story:**\nAs a mobile banking customer,\nI want to receive confirmation and reminders about my scheduled transfers,\nSo that I can track my upcoming transactions and ensure sufficient funds.\n\n**Acceptance Criteria:**\n- [ ] User receives email confirmation immediately after scheduling (within 5 min)\n- [ ] User receives SMS confirmation if SMS opted-in\n- [ ] User receives reminder notification 3 days before execution\n- [ ] User receives reminder notification 1 day before execution\n- [ ] User receives notification on execution day (success or failure)\n- [ ] All notifications include transfer details (amount, date, accounts)\n- [ ] Email includes link to modify or cancel transfer\n\n**Priority**: Must Have\n\n**Business Value**: Reduces customer anxiety, improves trust, prevents insufficient balance issues\n\n**Dependencies**: Notification service API\n\n**Notes**:\n- User can configure notification preferences (email/SMS/push)\n- Reminder timing may need to be configurable (some users prefer day-of only)\n\n---\n\n### Epic: Recurring Payments\n\n#### Story 3: Set Up Monthly Recurring Payment\n\n**User Story:**\nAs a mobile banking customer,\nI want to set up automatic monthly recurring payments,\nSo that I can automate bills like rent without manual intervention each month.\n\n**Acceptance Criteria:**\n- [ ] User can enter recipient details (account number, routing number, name)\n- [ ] User can enter fixed payment amount\n- [ ] User can select monthly frequency with day-of-month selection (1-28)\n- [ ] User can set start date and optional end date\n- [ ] System displays preview of next 3 execution dates\n- [ ] User receives confirmation with complete recurring schedule\n- [ ] Recurring payment appears in \"Recurring Payments\" list\n- [ ] System executes payment automatically on schedule without user action\n\n**Priority**: Must Have\n\n**Business Value**: Addresses 60% of customer requests; high-value automation use case\n\n**Dependencies**:\n- Recurring job scheduler\n- External transfer service API for third-party payments\n\n**Notes**:\n- Limit day-of-month to 1-28 to avoid issues with February and months with <31 days\n- For day 29-31, use last day of month\n\n---\n\n#### Story 4: Pause and Resume Recurring Payment\n\n**User Story:**\nAs a mobile banking customer,\nI want to temporarily pause a recurring payment and resume it later,\nSo that I can handle temporary situations (e.g., traveling, switching accounts) without canceling.\n\n**Acceptance Criteria:**\n- [ ] User can select \"Pause\" on any active recurring payment\n- [ ] User can optionally specify resume date (or indefinite pause)\n- [ ] System skips scheduled executions during pause period\n- [ ] User receives confirmation of pause with skip dates listed\n- [ ] User can \"Resume\" paused payment at any time\n- [ ] System resumes payment on next scheduled date or specified resume date\n- [ ] Pause/resume history visible in payment details\n\n**Priority**: Should Have\n\n**Business Value**: Prevents unnecessary cancellations and re-setups; improves user experience\n\n---\n\n### Epic: Scheduled Transfer Management\n\n#### Story 5: View All Scheduled Transfers\n\n**User Story:**\nAs a mobile banking customer,\nI want to view all my upcoming scheduled transfers in one place,\nSo that I can understand what transactions are pending and plan my finances.\n\n**Acceptance Criteria:**\n- [ ] User can access \"Scheduled Transfers\" section from main menu\n- [ ] System displays all scheduled transfers sorted by execution date (nearest first)\n- [ ] Each item shows amount, source/destination, execution date, status\n- [ ] User can filter by date range (next week, next month, all)\n- [ ] User can search by amount or account\n- [ ] Tapping a transfer opens detail view with full information\n- [ ] List updates in real-time as transfers execute or are modified\n\n**Priority**: Must Have\n\n**Business Value**: Essential for user confidence and transfer management\n\n---\n\n#### Story 6: Modify Scheduled Transfer\n\n**User Story:**\nAs a mobile banking customer,\nI want to modify the amount or date of a scheduled transfer before it executes,\nSo that I can adapt to changing financial circumstances without canceling and recreating.\n\n**Acceptance Criteria:**\n- [ ] User can select \"Edit\" on any pending scheduled transfer\n- [ ] User can change amount (subject to same validation as original)\n- [ ] User can change execution date (up to 1 year in future)\n- [ ] System displays updated summary for confirmation\n- [ ] User receives confirmation of modification\n- [ ] Modified transfer reflects new details immediately in list\n- [ ] Cannot modify transfer within 24 hours of execution (must cancel instead)\n\n**Priority**: Must Have\n\n**Business Value**: Flexibility reduces cancellations; improves user satisfaction\n\n**Notes**:\n- 24-hour modification cutoff prevents processing conflicts\n- Consider allowing amount-only modifications closer to execution\n\n---\n\n#### Story 7: Cancel Scheduled Transfer\n\n**User Story:**\nAs a mobile banking customer,\nI want to cancel a scheduled transfer before it executes,\nSo that I can change my plans without the transaction processing.\n\n**Acceptance Criteria:**\n- [ ] User can select \"Cancel\" on any pending scheduled transfer\n- [ ] System displays confirmation dialog with transfer details\n- [ ] User confirms cancellation\n- [ ] System cancels transfer and removes from scheduled list\n- [ ] User receives cancellation confirmation\n- [ ] Canceled transfer moves to \"Canceled\" history section (not deleted)\n- [ ] User can cancel up to 1 hour before execution time\n\n**Priority**: Must Have\n\n**Business Value**: User control and flexibility; prevents unwanted transactions\n\n---\n\n### Epic: User Experience & Accessibility\n\n#### Story 8: Accessible Transfer Scheduling\n\n**User Story:**\nAs a customer with visual impairments using screen reader,\nI want all transfer scheduling features to be fully accessible,\nSo that I can independently schedule transfers without assistance.\n\n**Acceptance Criteria:**\n- [ ] All interactive elements have proper ARIA labels\n- [ ] Screen reader announces form validation errors clearly\n- [ ] Date picker is keyboard-navigable and screen reader compatible\n- [ ] Confirmation screens read transaction details in logical order\n- [ ] All buttons and links have descriptive labels (not \"Click here\")\n- [ ] High contrast mode supported\n- [ ] Text meets WCAG 2.1 AA minimum size and contrast requirements\n\n**Priority**: Must Have (Regulatory requirement - ADA compliance)\n\n**Business Value**: Regulatory compliance, inclusive customer experience\n\n**Dependencies**: Mobile app accessibility framework\n\n---\n\n#### Story 9: Transfer Scheduling Tutorial\n\n**User Story:**\nAs a first-time user of scheduled transfers,\nI want a guided tutorial showing how to schedule my first transfer,\nSo that I feel confident using the feature without fear of making mistakes.\n\n**Acceptance Criteria:**\n- [ ] Tutorial automatically appears on first visit to \"Schedule Transfer\" screen\n- [ ] Tutorial can be skipped or dismissed\n- [ ] Tutorial includes 4-5 quick steps with visual highlights\n- [ ] Tutorial uses example data (not real accounts)\n- [ ] User can replay tutorial from help menu\n- [ ] Tutorial completion tracked (doesn't re-show on subsequent visits)\n\n**Priority**: Should Have\n\n**Business Value**: Increases adoption by reducing friction for new users\n\n**Notes**:\n- Consider in-app tooltips as alternative to full tutorial\n- A/B test tutorial vs. tooltips for adoption impact\n```\n\n---\n\n## Section 6: User Experience Requirements\n\n**Purpose**: Define user-facing performance, usability, and accessibility requirements.\n\n**Template:**\n```markdown\n## 6. User Experience Requirements\n\n### Performance Expectations\n\n**Page Load Time:**\n- Target: [Time] or less for [X]% of users\n- Maximum acceptable: [Time]\n\n**Transaction Speed:**\n- Operation 1: Complete in <[X] seconds\n- Operation 2: Complete in <[X] seconds\n\n**Responsiveness:**\n- UI interaction response: <[X]ms\n- Search results: <[X] seconds\n\n### Usability Requirements\n\n**Ease of Use:**\n- New users can complete primary task without help in <[X] minutes\n- Task completion rate: >[X]% for primary use cases\n- Maximum [X] clicks to complete common tasks\n\n**Learnability:**\n- First-time user success rate: >[X]%\n- Tutorial completion optional but available\n- In-context help for complex features\n\n**Error Handling:**\n- Clear, actionable error messages (no technical jargon)\n- Inline validation for form fields\n- Recovery path for all error scenarios\n\n### Accessibility Requirements\n\n**Standards Compliance:**\n- WCAG 2.1 Level AA compliance (minimum)\n- ADA compliance for all features\n- Section 508 compliance (if government-facing)\n\n**Specific Requirements:**\n- Screen reader compatible\n- Keyboard navigation for all features\n- Color contrast ratios meet standards\n- Text resize up to 200% without loss of functionality\n- Captions for video/audio content\n\n### Cross-Platform Consistency\n\n**Supported Platforms:**\n- iOS: [Versions]\n- Android: [Versions]\n- Web (if applicable): [Browsers]\n\n**Consistency Requirements:**\n- Feature parity across platforms\n- Consistent visual design and interaction patterns\n- Synchronized data across devices (real-time or <[X] seconds)\n\n### User Journey Mapping\n\n**Journey 1: [Journey Name]**\n- Entry point: [Where user starts]\n- Key steps: [List critical steps]\n- Pain points addressed: [Previous frustrations solved]\n- Expected emotion: [How user should feel at each stage]\n- Exit point: [Successful completion state]\n\n**Journey 2: [Journey Name]**\n[Repeat structure]\n```\n\n**Example:**\n```markdown\n## 6. User Experience Requirements\n\n### Performance Expectations\n\n**Page Load Time:**\n- Target: <1 second for \"Schedule Transfer\" screen load (90th percentile)\n- Maximum acceptable: 2 seconds\n- Measured from tap to fully interactive screen\n\n**Transaction Speed:**\n- Schedule transfer creation: Complete in <2 seconds from confirmation tap\n- Modify scheduled transfer: Complete in <1.5 seconds\n- Load scheduled transfers list: <1 second for up to 50 items\n\n**Responsiveness:**\n- UI interaction response: <100ms for button taps, toggles\n- Search results (searching scheduled transfers): <500ms\n- Calendar picker interactions: <50ms\n\n### Usability Requirements\n\n**Ease of Use:**\n- New users can schedule first transfer without help in <3 minutes\n- Task completion rate: >90% for basic one-time transfer scheduling\n- Maximum 5 taps to complete simple transfer scheduling (from home screen to confirmation)\n\n**Learnability:**\n- First-time user success rate: >85% complete first transfer successfully\n- Optional tutorial available but <30% of users should need to access help\n- In-context tooltips for recurring payment advanced options (frequency, end date)\n\n**Error Handling:**\n- Clear, actionable error messages in plain language\n  - ‚úÖ Good: \"Transfer amount exceeds available balance. Available: $1,234.56\"\n  - ‚ùå Bad: \"Error 403: Insufficient funds\"\n- Inline validation for amount field (real-time balance check)\n- Recovery path: If transfer fails to schedule, user can retry or save draft\n- Insufficient balance warnings are informational (don't block scheduling; warn instead)\n\n**Confirmation & Feedback:**\n- Every action provides immediate visual feedback (<100ms)\n- Confirmation screens summarize all key details before final commitment\n- Success screens include next actions (e.g., \"View all scheduled transfers\")\n\n### Accessibility Requirements\n\n**Standards Compliance:**\n- WCAG 2.1 Level AA compliance (minimum requirement)\n- ADA compliance for all features (legal requirement)\n- Target WCAG 2.1 Level AAA for critical user flows (transfer scheduling)\n\n**Specific Requirements:**\n- **Screen Reader**: All screens fully compatible with VoiceOver (iOS), TalkBack (Android)\n- **Keyboard Navigation**: All features accessible via keyboard (for Android external keyboards)\n- **Color Contrast**: Minimum 4.5:1 for normal text, 3:1 for large text (WCAG AA)\n- **Text Resize**: Support up to 200% text scaling without horizontal scrolling or loss of functionality\n- **Focus Indicators**: Visible focus indicators for keyboard navigation (minimum 2px outline)\n- **Alternative Text**: All icons and images have descriptive alt text\n\n**Testing:**\n- Manual testing with screen readers required for all releases\n- Automated accessibility testing (Lighthouse, Axe) scores >95\n\n### Cross-Platform Consistency\n\n**Supported Platforms:**\n- iOS: 15.0+ (last 3 major versions)\n- Android: 10+ (API level 29+)\n- Web (future): Chrome, Safari, Firefox, Edge (latest 2 versions)\n\n**Consistency Requirements:**\n- Feature parity across iOS and Android (100% of features available on both)\n- Visual design follows platform conventions (iOS Human Interface Guidelines, Material Design)\n- Data synchronized in real-time across devices (<5 seconds)\n- Notifications delivered to all devices where user is logged in\n\n### User Journey Mapping\n\n**Journey 1: First-Time Scheduled Transfer**\n\n- **Entry Point**: Home screen \"Schedule Transfer\" card (promotional)\n- **Key Steps**:\n  1. Tap \"Schedule Transfer\" ‚Üí Feel: Curious but slightly uncertain\n  2. View simple form (accounts, amount, date) ‚Üí Feel: \"This looks easy\"\n  3. Select date from calendar ‚Üí Feel: In control\n  4. See clear summary with all details ‚Üí Feel: Confident\n  5. Confirm and receive confirmation screen ‚Üí Feel: Accomplished, relieved\n  6. Receive email confirmation ‚Üí Feel: Reassured\n- **Pain Points Addressed**:\n  - Previous: Had to call customer service (8-minute wait, awkward phone conversation)\n  - Now: Self-service in <2 minutes from own device\n- **Expected Emotion**: Confidence, control, satisfaction\n- **Exit Point**: Confirmation screen with option to \"Schedule Another\" or \"View All\"\n\n**Journey 2: Monthly Rent Payment Automation**\n\n- **Entry Point**: Scheduled transfers list (after first one-time transfer success)\n- **Key Steps**:\n  1. Tap \"Set Up Recurring Payment\" ‚Üí Feel: Hopeful this will solve a repeated hassle\n  2. Enter landlord account details ‚Üí Feel: Careful (wants to get this right)\n  3. Set amount ($1,200) and frequency (monthly, 1st) ‚Üí Feel: Straightforward\n  4. Preview next 3 months of payments ‚Üí Feel: Reassured by visibility\n  5. Confirm setup ‚Üí Feel: Accomplished\n  6. Receive confirmation with full schedule ‚Üí Feel: Relief, freed from monthly mental load\n- **Pain Points Addressed**:\n  - Previous: Had to remember to pay rent manually each month, risked late fees\n  - Now: Automated, reliable, visible schedule\n- **Expected Emotion**: Relief, trust, empowerment\n- **Exit Point**: Confirmation with calendar showing all upcoming payments\n\n**Journey 3: Modifying Scheduled Transfer**\n\n- **Entry Point**: Push notification \"Transfer scheduled for tomorrow: $500\"\n- **Key Steps**:\n  1. Tap notification ‚Üí Opens transfer detail screen ‚Üí Feel: Immediate access\n  2. User realizes amount should be $600, taps \"Edit\" ‚Üí Feel: Grateful for flexibility\n  3. Change amount to $600 ‚Üí Feel: In control\n  4. Confirm change ‚Üí Feel: Confident\n  5. Receive updated confirmation ‚Üí Feel: Reassured\n- **Pain Points Addressed**:\n  - Previous: Would have to cancel and re-create transfer\n  - Now: Quick 1-minute modification\n- **Expected Emotion**: Flexibility, control, satisfaction\n- **Exit Point**: Updated transfer detail screen\n```\n\n---\n\n## Section 7: Business Constraints\n\n**Purpose**: Document limitations, requirements, and boundaries the solution must operate within.\n\n**Template:**\n```markdown\n## 7. Business Constraints\n\n### Budget Constraints\n\n**Total Budget**: $[Amount]\n**Budget Breakdown**:\n- Development: $[Amount]\n- Infrastructure: $[Amount]\n- Licensing: $[Amount]\n- Ongoing operational costs: $[Amount]/month\n\n**Budget Approval**: [Who approved, date]\n\n### Timeline Constraints\n\n**Hard Deadlines:**\n- Milestone 1: [Date] - [Reason for deadline]\n- Launch date: [Date] - [Reason for deadline]\n\n**Flexibility:**\n- Features that can slip to Phase 2 if needed\n- Features that are non-negotiable for launch\n\n### Regulatory & Compliance Requirements\n\n**Applicable Regulations:**\n- Regulation 1: [Name, key requirements]\n- Regulation 2: [Name, key requirements]\n\n**Compliance Certifications Needed:**\n- Certification 1\n- Certification 2\n\n**Data Governance:**\n- Data residency requirements (e.g., must stay in US)\n- Data retention policies (e.g., 7 years)\n- PII handling requirements\n\n**Audit Requirements:**\n- Audit trail for all transactions\n- Retention period for audit logs\n- Access controls and approval workflows\n\n### Integration Constraints\n\n**Existing Systems to Integrate With:**\n- System 1: [Name, integration method, limitations]\n- System 2: [Name, integration method, limitations]\n\n**Technical Limitations:**\n- Legacy system constraints\n- API rate limits\n- Data format restrictions\n\n**Dependencies:**\n- System upgrades required before this can launch\n- Third-party vendor dependencies\n\n### Operational Constraints\n\n**Support Model:**\n- Support hours: [e.g., 24/7, business hours]\n- Expected support volume: [Tickets/month]\n- SLA requirements: [Response time, resolution time]\n\n**Maintenance Windows:**\n- Acceptable downtime: [e.g., none, scheduled maintenance windows]\n- Change freeze periods: [e.g., month-end, quarter-end]\n\n### Resource Constraints\n\n**Team Availability:**\n- Development team: [Size, availability]\n- Design team: [Size, availability]\n- QA team: [Size, availability]\n\n**Skill Gaps:**\n- Training needed for [specific technology/domain]\n- External expertise required for [specific area]\n```\n\n**Example:**\n```markdown\n## 7. Business Constraints\n\n### Budget Constraints\n\n**Total Budget**: $450,000 (approved)\n\n**Budget Breakdown**:\n- Development: $320,000 (mobile app, backend services, testing)\n- Infrastructure: $80,000 (first year cloud costs, scaling capacity)\n- Licensing: $20,000 (third-party services, analytics)\n- Contingency: $30,000 (10% buffer for unknowns)\n- Ongoing operational costs: $15,000/month (infrastructure, support, monitoring)\n\n**Budget Approval**: CFO approved on Jan 15, 2025\n\n**Budget Constraints:**\n- Cannot exceed $450K total without executive re-approval\n- Must justify any infrastructure costs >$10K/month\n- Preference for open-source solutions where possible to minimize licensing costs\n\n### Timeline Constraints\n\n**Hard Deadlines:**\n- Q3 2025 Launch (July 1, 2025): Aligned with major marketing campaign (already committed $200K marketing spend)\n- Beta Testing Complete (June 1, 2025): Needed for final QA and compliance review\n- Compliance Review Submission (May 1, 2025): Regulatory approval takes 4-6 weeks\n\n**Flexibility:**\n- **Phase 1 (Must Launch by July 1)**:\n  - One-time scheduled transfers\n  - Basic recurring transfers (monthly)\n  - Mobile app only (iOS + Android)\n- **Phase 2 (Can Slip to Q4 2025)**:\n  - Advanced recurring patterns (bi-weekly, custom)\n  - Web app version\n  - Transfer templates\n  - AI-powered suggestions\n\n**Non-Negotiable for Launch:**\n- Scheduled transfers between own accounts\n- Compliance with banking regulations (cannot launch without)\n- Basic security (MFA, encryption)\n\n### Regulatory & Compliance Requirements\n\n**Applicable Regulations:**\n\n1. **Regulation E (Electronic Fund Transfer Act)**\n   - Requirement: Customers must receive confirmation for all scheduled transfers\n   - Requirement: Customers must be able to cancel scheduled transfers before execution\n   - Requirement: Error resolution procedures must be in place\n\n2. **GLBA (Gramm-Leach-Bliley Act)**\n   - Requirement: Customer financial data must be encrypted in transit and at rest\n   - Requirement: Privacy notices must be provided\n   - Requirement: Opt-out options for data sharing\n\n3. **ADA (Americans with Disabilities Act)**\n   - Requirement: Mobile app must be accessible to users with disabilities\n   - Requirement: WCAG 2.1 AA compliance minimum\n\n**Compliance Certifications Needed:**\n- SOC 2 Type II (existing certification extends to new feature)\n- Annual penetration testing (Q4 2025)\n\n**Data Governance:**\n- **Data Residency**: Customer financial data must remain in US data centers (regulatory requirement)\n- **Data Retention**: Transaction records retained for 7 years (regulatory requirement)\n- **PII Handling**:\n  - Encryption at rest (AES-256)\n  - Encryption in transit (TLS 1.2+)\n  - Tokenization of account numbers in logs\n  - No PII in analytics or third-party services\n\n**Audit Requirements:**\n- **Audit Trail**: Complete log of all transfer scheduling, modifications, cancellations, executions\n- **Log Retention**: 7 years in immutable storage\n- **Access Controls**: Role-based access, multi-factor authentication for admin functions\n- **Compliance Review**: Quarterly internal audit, annual external audit\n\n### Integration Constraints\n\n**Existing Systems to Integrate With:**\n\n1. **Core Banking System (CBS)**\n   - System: FIS Horizon (version 12.3)\n   - Integration: REST API\n   - Limitations:\n     - Max 100 API calls/minute (rate limit)\n     - Maintenance window Sundays 2-4 AM ET (system unavailable)\n     - Account balance queries cached for 30 seconds (eventual consistency)\n   - Dependency: CBS upgrade to v12.4 required by May 1 for enhanced transfer API\n\n2. **Notification Service**\n   - System: Twilio (SMS), SendGrid (Email), Firebase (Push)\n   - Integration: REST APIs\n   - Limitations:\n     - Twilio: $0.0075/SMS (budget impact for high-volume notifications)\n     - SendGrid: 50,000 emails/month on current plan (may need upgrade)\n   - Dependency: None\n\n3. **Customer Identity & Access Management (CIAM)**\n   - System: Okta\n   - Integration: OAuth 2.0 / OIDC\n   - Limitations:\n     - Session timeout 30 minutes (user must re-authenticate)\n     - MFA required for financial transactions (policy)\n   - Dependency: Okta MFA enrollment required for all users (current enrollment: 78%, target: 95% before launch)\n\n**Technical Limitations:**\n- Legacy CBS cannot support same-day scheduling (minimum 1 business day in advance)\n- Account balance checks are eventually consistent (30-second cache)\n- CBS API does not support bulk operations (must schedule transfers one at a time)\n\n**Dependencies:**\n- CBS upgrade to v12.4 (scheduled for April 15, 2025)\n- Notification service capacity upgrade if >100K users adopt feature (review at 50K users)\n\n### Operational Constraints\n\n**Support Model:**\n- **Support Hours**: 24/7 (existing customer service team)\n- **Expected Support Volume**: +500 tickets/month initially (5% of 10K early adopters needing help)\n- **SLA Requirements**:\n  - Critical issues (unable to cancel transfer): <1 hour response\n  - High priority (transfer failed): <4 hour response\n  - Medium priority (questions): <24 hour response\n\n**Training:**\n- Customer service team training: 2-week program before launch (80 agents)\n- Knowledge base articles: 10 articles covering common scenarios\n- Internal FAQ: Address top 20 anticipated questions\n\n**Maintenance Windows:**\n- **Acceptable Downtime**: Scheduled maintenance Sundays 2-4 AM ET (aligns with CBS maintenance)\n- **Change Freeze Periods**:\n  - Last 3 business days of month (high transaction volume, accounting close)\n  - Last 2 weeks of quarter (compliance reporting)\n  - Holiday blackout dates (Thanksgiving week, Dec 20-Jan 2)\n\n### Resource Constraints\n\n**Team Availability:**\n- **Development Team**:\n  - Mobile (iOS): 2 engineers (80% allocated to this project)\n  - Mobile (Android): 2 engineers (80% allocated)\n  - Backend: 3 engineers (100% allocated)\n  - Total capacity: ~7 FTE for 6 months\n- **Design Team**: 1 UX designer (50% allocated), 1 UI designer (30% allocated)\n- **QA Team**: 2 QA engineers (100% allocated for last 2 months)\n- **Product Management**: 1 Product Owner (this role, 60% allocated)\n\n**Skill Gaps:**\n- **Banking Regulations**: Team needs training on Regulation E requirements (2-day workshop planned)\n- **Accessibility Testing**: Team needs training on WCAG 2.1 and screen reader testing (1-week training for QA team)\n- **Performance Testing**: External consultant needed for load testing (no in-house expertise)\n\n**External Dependencies:**\n- Legal review of all customer-facing content (2-week review cycle)\n- Compliance team approval before launch (4-week process)\n- Security team penetration testing (2-week engagement)\n```\n\n---\n\n## Section 8: Success Metrics & KPIs\n\n**Purpose**: Define how success will be measured and tracked.\n\n**Template:**\n```markdown\n## 8. Success Metrics & KPIs\n\n### Business KPIs\n\n**KPI 1: [Name]**\n- **Definition**: [What is measured]\n- **Current Baseline**: [Current value]\n- **Target**: [Goal value]\n- **Timeframe**: [When to achieve]\n- **Measurement Method**: [How tracked]\n- **Owner**: [Who is responsible]\n\n**KPI 2: [Name]**\n[Repeat structure]\n\n### User Experience Metrics\n\n**Metric 1: [Name]**\n- **Definition**: [What is measured]\n- **Target**: [Goal value]\n- **Measurement Method**: [How tracked]\n\n**Metric 2: [Name]**\n[Repeat structure]\n\n### Adoption Metrics\n\n**Metric 1: Feature Adoption Rate**\n- **Definition**: % of active mobile users who use scheduled transfers\n- **Target**: [% within X months]\n- **Measurement Method**: [Analytics tracking]\n\n**Metric 2: User Retention**\n- **Definition**: % of users who use feature >1 time\n- **Target**: [%]\n\n### Leading vs. Lagging Indicators\n\n**Leading Indicators** (predict future success):\n- Indicator 1\n- Indicator 2\n\n**Lagging Indicators** (confirm success after the fact):\n- Indicator 1\n- Indicator 2\n\n### Measurement Approach\n\n**Data Collection:**\n- Source 1: [Where data comes from]\n- Source 2: [Where data comes from]\n\n**Reporting Frequency:**\n- Daily: [Metrics tracked daily]\n- Weekly: [Metrics tracked weekly]\n- Monthly: [Metrics tracked monthly]\n\n**Dashboards:**\n- Dashboard 1: [For whom, what metrics]\n- Dashboard 2: [For whom, what metrics]\n\n**Review Cadence:**\n- Weekly review with product team\n- Monthly review with stakeholders\n- Quarterly review with executives\n```\n\n**Example:**\n```markdown\n## 8. Success Metrics & KPIs\n\n### Business KPIs\n\n**KPI 1: Cost Savings from Call Reduction**\n- **Definition**: Monthly cost savings from reduction in customer service calls for transfer scheduling\n- **Current Baseline**: $180,000/month (15,000 calls √ó $12/call)\n- **Target**: $126,000/month savings (70% reduction ‚Üí 4,500 calls/month √ó $12/call = $54,000 cost)\n- **Timeframe**: 6 months post-launch\n- **Measurement Method**: Customer service call tracking system (Salesforce), categorized by call reason\n- **Owner**: VP Operations (Marcus Johnson)\n\n**KPI 2: Customer Retention (Churn Reduction)**\n- **Definition**: Annual churn rate for digital-first customer segment\n- **Current Baseline**: 8% annual churn for digital-first segment (120K customers)\n- **Target**: 5% annual churn (3 percentage point reduction = ~3,600 customers retained)\n- **Timeframe**: 12 months post-launch\n- **Measurement Method**: Customer lifecycle analysis (closed accounts vs. active accounts)\n- **Revenue Impact**: ~3,600 customers √ó $40/month avg revenue = $144,000/month = $1.73M/year\n- **Owner**: VP Digital Banking (Sarah Chen)\n\n**KPI 3: Digital Engagement Growth**\n- **Definition**: Monthly active users (MAU) on mobile app\n- **Current Baseline**: 800,000 MAU\n- **Target**: 950,000 MAU (19% growth)\n- **Timeframe**: 12 months post-launch\n- **Measurement Method**: Mobile app analytics (Firebase, Google Analytics)\n- **Owner**: VP Digital Banking (Sarah Chen)\n\n**KPI 4: ROI / Payback Period**\n- **Definition**: Time to recover $450,000 investment\n- **Investment**: $450,000 (development + first year operational costs)\n- **Annual Return**: $1,752,000 ($1,512K cost savings + $240K retained revenue)\n- **Payback Period**: 3.1 months\n- **Target**: Achieve payback within 6 months (conservative)\n- **Owner**: CFO\n\n### User Experience Metrics\n\n**Metric 1: Task Completion Rate**\n- **Definition**: % of users who start scheduling a transfer and successfully complete it\n- **Target**: >90% completion rate\n- **Current Benchmark**: N/A (new feature)\n- **Measurement Method**: Funnel analysis in mobile app analytics\n  - Step 1: Land on \"Schedule Transfer\" screen\n  - Step 2: Enter transfer details\n  - Step 3: Preview summary\n  - Step 4: Confirm transfer\n  - Step 5: View confirmation screen\n- **Alert Threshold**: If completion rate drops below 80%, trigger UX review\n\n**Metric 2: Time to Complete Task**\n- **Definition**: Average time from opening \"Schedule Transfer\" screen to confirmation\n- **Target**: <2 minutes (90th percentile <3 minutes)\n- **Measurement Method**: Session timing in mobile app analytics\n- **Alert Threshold**: If median time exceeds 3 minutes, investigate usability issues\n\n**Metric 3: Error Rate**\n- **Definition**: % of transfer scheduling attempts that result in error\n- **Target**: <5% user-caused errors (e.g., insufficient balance, invalid date)\n- **Target**: <1% system-caused errors (e.g., API failures, timeouts)\n- **Measurement Method**: Error logging and analytics\n- **Alert Threshold**: If system error rate exceeds 2%, trigger engineering investigation\n\n**Metric 4: Customer Satisfaction (CSAT)**\n- **Definition**: Post-interaction satisfaction survey score\n- **Target**: 4.5+ out of 5.0 average rating\n- **Measurement Method**: In-app survey after successful transfer scheduling (sample 20% of users)\n- **Question**: \"How satisfied are you with the scheduled transfer experience?\"\n- **Alert Threshold**: If CSAT drops below 4.0, trigger UX review\n\n**Metric 5: Net Promoter Score (NPS)**\n- **Definition**: Likelihood to recommend feature to others (0-10 scale)\n- **Target**: NPS >50 (industry benchmark for excellent digital banking features)\n- **Measurement Method**: Quarterly survey to feature users\n- **Question**: \"How likely are you to recommend our scheduled transfer feature to a friend or colleague?\"\n\n### Adoption Metrics\n\n**Metric 1: Feature Adoption Rate**\n- **Definition**: % of monthly active mobile users who schedule at least 1 transfer\n- **Targets**:\n  - Month 1: 1.25% adoption (10,000 users out of 800K MAU)\n  - Month 3: 3.1% adoption (25,000 users)\n  - Month 6: 6.25% adoption (50,000 users)\n  - Month 12: 12.5% adoption (100,000 users)\n- **Measurement Method**: Unique users who created ‚â•1 scheduled transfer / Total MAU\n\n**Metric 2: Power User Adoption (High-Value Segment)**\n- **Definition**: % of high-value customers (>$50K deposits) who use scheduled transfers\n- **Target**: 30% adoption within 6 months (36,000 out of 120,000 high-value customers)\n- **Measurement Method**: Customer segment analysis (high-value flag + feature usage)\n\n**Metric 3: User Retention (Repeat Usage)**\n- **Definition**: % of first-time users who schedule a 2nd transfer within 30 days\n- **Target**: >60% (indicates feature stickiness)\n- **Measurement Method**: Cohort analysis (users grouped by first transfer date)\n\n**Metric 4: Recurring Payment Adoption**\n- **Definition**: % of feature users who set up ‚â•1 recurring payment\n- **Target**: 40% of scheduled transfer users (40,000 out of 100,000 at Month 12)\n- **Measurement Method**: Users with active recurring payment schedule\n\n**Metric 5: Active Scheduled Transfers (System Load)**\n- **Definition**: Number of pending scheduled transfers in the system at any time\n- **Baseline**: 0 (new feature)\n- **Projection**:\n  - Month 1: ~5,000 pending transfers\n  - Month 6: ~30,000 pending transfers\n  - Month 12: ~60,000 pending transfers\n- **Measurement Method**: Database query of scheduled transfers with future execution dates\n- **Purpose**: Capacity planning for infrastructure scaling\n\n### Leading vs. Lagging Indicators\n\n**Leading Indicators** (predict future success):\n- **App Store Ratings**: Early user feedback signal (target >4.5 stars in first month)\n- **Tutorial Completion Rate**: % of first-time users who complete tutorial (target >60%)\n- **Help Article Views**: Low views indicate intuitive UX (target <15% of users access help)\n- **Week 1 Adoption Rate**: Strong first week signals successful launch (target >5,000 users Week 1)\n\n**Lagging Indicators** (confirm success after the fact):\n- **Cost Savings**: Realized 6+ months post-launch\n- **Churn Reduction**: Measurable 12+ months post-launch\n- **ROI / Payback Period**: Confirmed after 3-6 months of full operation\n- **Customer Lifetime Value (CLV) Increase**: Long-term impact (18+ months)\n\n### Measurement Approach\n\n**Data Collection:**\n- **Mobile App Analytics**: Firebase, Google Analytics (user behavior, funnels, session duration)\n- **Backend Logs**: Transfer creation, execution, modification, cancellation events\n- **Customer Service System**: Call volume by reason (Salesforce)\n- **Customer Relationship Management (CRM)**: Churn analysis, segment analysis\n- **Surveys**: In-app CSAT, quarterly NPS survey\n\n**Reporting Frequency:**\n- **Daily Monitoring**:\n  - System error rate (alert if >2%)\n  - New users adopting feature\n  - Critical issues (transfer failures, cancellation failures)\n- **Weekly Review**:\n  - Adoption rate trend\n  - Task completion rate\n  - Customer satisfaction scores\n  - Feature usage by segment\n- **Monthly Reporting**:\n  - All business KPIs (cost savings, churn, engagement)\n  - UX metrics deep dive\n  - Cohort analysis (retention)\n  - Competitive benchmarking\n- **Quarterly Review**:\n  - ROI and payback period update\n  - NPS survey results\n  - Strategic adjustments based on learnings\n\n**Dashboards:**\n- **Executive Dashboard** (Monthly):\n  - Cost savings vs. target\n  - Adoption rate vs. target\n  - Churn reduction progress\n  - ROI / payback period\n- **Product Team Dashboard** (Daily/Weekly):\n  - Daily active users\n  - Task completion rate\n  - Error rates and types\n  - Feature usage breakdown (one-time vs. recurring)\n- **Operations Dashboard** (Daily):\n  - System health (uptime, latency, error rate)\n  - Pending transfer volume (capacity planning)\n  - Customer service call volume\n\n**Review Cadence:**\n- **Weekly**: Product Owner + Product Team (review weekly metrics, adjust priorities)\n- **Monthly**: Stakeholder review (VP Digital Banking, VP Operations, Head of Product)\n- **Quarterly**: Executive review (CFO, CTO, CEO) - ROI, strategic impact, next phase planning\n\n**Success Criteria for Phase 2 Investment:**\n- If Month 6 adoption exceeds 50,000 users (target met)\n- If customer satisfaction maintains >4.5/5.0\n- If ROI payback achieved within 6 months\n- Then: Approve Phase 2 budget ($200K) for advanced features (transfer templates, AI suggestions, cross-border)\n```\n\n---\n\n## Mapping to ARCHITECTURE.md\n\nThis section explains how the Product Owner Specification feeds into the technical ARCHITECTURE.md document created by the architecture team.\n\n### Section Mapping Table\n\n| PO Spec Section | Maps to ARCHITECTURE.md Section | What Gets Translated |\n|-----------------|--------------------------------|----------------------|\n| **1. Business Context** | **Section 1: Executive Summary (Business Value)** | Business problem ‚Üí Business value statements<br>Market context ‚Üí Strategic positioning |\n| **2. Stakeholders & Users** | **Section 2: System Overview (Stakeholders Affected)** | User personas ‚Üí User types served<br>Impact analysis ‚Üí Stakeholder benefits |\n| **3. Business Objectives** | **Section 1: Executive Summary (Key Metrics)** | Business KPIs ‚Üí Success metrics (with technical translations) |\n| **4. Use Cases** | **Section 2: System Overview (Primary Use Cases)** | Business use cases ‚Üí Technical use case flows<br>Success metrics ‚Üí Technical performance targets |\n| **5. User Stories** | Implementation Backlog (not in ARCHITECTURE.md) | Stories guide feature implementation, not architecture doc |\n| **6. User Experience Requirements** | **Section 10: Scalability & Performance (Performance Targets)** | User-facing performance ‚Üí Technical SLAs<br>\"<2 second load\" ‚Üí \"p95 latency <2000ms\" |\n| **7. Business Constraints** | **Section 3: Architecture Principles (Trade-offs)**<br>**Section 9: Security Architecture (Compliance)** | Budget ‚Üí Technology choices (cost optimization)<br>Regulatory ‚Üí Security controls<br>Timeline ‚Üí Deployment strategy |\n| **8. Success Metrics & KPIs** | **Section 1: Executive Summary (Business Value)**<br>**Section 2: System Overview (Success Metrics)** | Business KPIs ‚Üí Business value statements<br>Adoption metrics ‚Üí Capacity planning (Section 10) |\n\n### Translation Examples\n\n**Example 1: User Experience Requirement ‚Üí Technical Performance Target**\n\n**PO Spec (Section 6):**\n> \"Page Load Time: <1 second for 'Schedule Transfer' screen (90th percentile)\"\n\n**ARCHITECTURE.md (Section 10):**\n> \"**Latency:**\n> | Operation | p50 | p95 | p99 |\n> |-----------|-----|-----|-----|\n> | Schedule Transfer Screen Load | <500ms | <900ms | <1500ms |\"\n\n**Translation:** User-facing \"1 second\" becomes p90 latency target of <900ms with p50 and p99 also defined.\n\n---\n\n**Example 2: Business Objective ‚Üí Architecture Principle Trade-off**\n\n**PO Spec (Section 3):**\n> \"Budget: $450,000 total (cannot exceed without re-approval)\"\n\n**ARCHITECTURE.md (Section 3 - Principle: Simplicity):**\n> \"**Trade-offs:**\n> - Selected Azure SQL over distributed database (Cosmos DB) to minimize cost ($1,200/month vs $3,500/month)\n> - May require refactoring if load exceeds 10,000 transactions/second (unlikely in 5-year horizon)\"\n\n**Translation:** Budget constraint drives technology selection with specific cost comparison and risk assessment.\n\n---\n\n**Example 3: Use Case ‚Üí Architecture Use Case with Technical Details**\n\n**PO Spec (Section 4):**\n> \"**Use Case: Schedule One-Time Transfer**\n> Primary Flow:\n> 1. Customer opens mobile app\n> 2. Customer selects source and destination accounts\n> 3. Customer enters amount and date\n> 4. System displays summary\n> 5. Customer confirms\n> 6. System creates scheduled transfer\"\n\n**ARCHITECTURE.md (Section 2):**\n> \"**Use Case: Scheduled Transfer Creation**\n>\n> Flow:\n> 1. Customer submits transfer request via mobile app\n> 2. API Gateway validates and routes to Transfer BFF\n> 3. Transfer BFF creates job via Task Scheduling System API\n> 4. Task Scheduling System persists job to Azure SQL and caches in Redis\n> 5. Response returned with job ID and execution time\n> 6. Customer receives confirmation\n>\n> **Performance:** p50 = 30ms, p95 = 80ms, p99 = 150ms\"\n\n**Translation:** Business flow ‚Üí Technical component flow with performance SLAs.\n\n---\n\n**Example 4: Business Constraint ‚Üí Security Architecture**\n\n**PO Spec (Section 7):**\n> \"**Regulation E (Electronic Fund Transfer Act):**\n> - Customers must receive confirmation for all scheduled transfers\n> - Customers must be able to cancel before execution\n>\n> **Data Residency:** Customer data must remain in US data centers\"\n\n**ARCHITECTURE.md (Section 9):**\n> \"**Compliance:**\n> - **Regulation E Compliance:**\n>   - Audit logging for all transfer lifecycle events (create, modify, cancel, execute)\n>   - Confirmation notifications via Notification Service (email/SMS)\n>   - Cancellation API with idempotency and rollback support\n>\n> **Data Residency:**\n> - Azure SQL geo-replication limited to US regions (East US 2, West US 2)\n> - Data sovereignty enforced via Azure Policy (block cross-region replication)\n> - 7-year audit log retention in US-based storage\"\n\n**Translation:** Regulatory requirement ‚Üí Technical controls and architecture decisions.\n\n---\n\n## Handoff Process: PO Spec ‚Üí ARCHITECTURE.md\n\n### Step 1: Product Owner Completes PO Spec\n\n**Deliverable:** Complete Product Owner Specification document using this guide\n\n**Review:**\n- Product team reviews for completeness\n- Stakeholders approve business objectives and success criteria\n- Legal/Compliance review (Section 7: Business Constraints)\n\n---\n\n### Step 2: Handoff Meeting (Product Owner + Architecture Team)\n\n**Agenda:**\n1. Product Owner presents PO Spec (30 minutes)\n   - Walk through business context and objectives\n   - Highlight key use cases and user stories\n   - Review constraints and non-negotiables\n2. Architecture team Q&A (20 minutes)\n   - Clarify ambiguities\n   - Understand technical implications of constraints\n   - Identify missing technical requirements\n3. Agreement on scope and timeline (10 minutes)\n\n**Output:**\n- Architecture team understands business requirements\n- List of open questions/clarifications\n- Timeline for ARCHITECTURE.md creation\n\n---\n\n### Step 3: Architecture Team Creates ARCHITECTURE.md\n\n**Using PO Spec as Input:**\n- Translate business use cases ‚Üí technical use cases with component flows\n- Convert UX requirements ‚Üí technical performance targets (latency, throughput)\n- Map business constraints ‚Üí architecture principles and technology choices\n- Define technical architecture (components, integrations, data flows)\n\n**Reference:** See [ARCHITECTURE_DOCUMENTATION_GUIDE.md](../architecture-docs/ARCHITECTURE_DOCUMENTATION_GUIDE.md)\n\n---\n\n### Step 4: Joint Review (Product Owner + Architecture Team)\n\n**Agenda:**\n1. Architecture team presents ARCHITECTURE.md\n2. Verify alignment with PO Spec business requirements\n3. Confirm constraints are addressed\n4. Validate success metrics can be measured with proposed architecture\n\n**Approval:** Product Owner approves architecture or requests changes\n\n---\n\n### Step 5: Implementation Planning\n\n**Using Both Documents:**\n- PO Spec User Stories ‚Üí Development backlog\n- ARCHITECTURE.md ‚Üí Technical implementation plan\n- Joint refinement sessions to align business and technical details\n\n---\n\n## Best Practices\n\n### Writing Effective Product Owner Specifications\n\n**1. Focus on Business Value, Not Technical Solutions**\n\n‚úÖ **Good:**\n> \"Customers should be able to schedule transfers instantly without calling customer service, reducing our call center costs by 70%.\"\n\n‚ùå **Bad:**\n> \"We need a Quartz Scheduler on Azure Kubernetes Service with Redis caching.\"\n\n**Guideline:** Describe **what** customers need and **why** it's valuable. Let the architecture team determine **how** to build it.\n\n---\n\n**2. Use Specific, Measurable Targets**\n\n‚úÖ **Good:**\n> \"Task completion rate: >90% of users who start scheduling complete successfully within <2 minutes.\"\n\n‚ùå **Bad:**\n> \"Users should find it easy to schedule transfers.\"\n\n**Guideline:** Replace vague terms (easy, fast, reliable) with quantifiable metrics.\n\n---\n\n**3. Provide Real Customer Context**\n\n‚úÖ **Good:**\n> \"Busy Professional Persona: Sarah, 32, schedules rent payment monthly. Currently calls customer service (8-minute wait), frustrated by lack of self-service.\"\n\n‚ùå **Bad:**\n> \"User wants to schedule payments.\"\n\n**Guideline:** Use personas with real pain points and goals to help the architecture team understand user needs.\n\n---\n\n**4. Document Constraints Clearly**\n\n‚úÖ **Good:**\n> \"Hard deadline: July 1, 2025 (aligned with $200K marketing campaign already committed). Cannot slip without executive approval.\"\n\n‚ùå **Bad:**\n> \"Launch ASAP.\"\n\n**Guideline:** Explain **why** constraints exist and what flexibility exists.\n\n---\n\n**5. Include Both Happy Path and Edge Cases**\n\n‚úÖ **Good:**\n> \"**Edge Case:** If transfer execution date falls on a bank holiday, system executes on next business day and notifies customer during setup.\"\n\n‚ùå **Bad:**\n> Only documenting the happy path.\n\n**Guideline:** Think through what could go wrong and how it should be handled from a user perspective.\n\n---\n\n**6. Prioritize Ruthlessly (MoSCoW)**\n\n‚úÖ **Good:**\n> \"**Must Have:** One-time scheduled transfers\n> **Should Have:** Recurring payments\n> **Could Have:** Transfer templates\n> **Won't Have:** Cross-border transfers (out of scope for Phase 1)\"\n\n‚ùå **Bad:**\n> Everything is \"high priority.\"\n\n**Guideline:** Force prioritization to help architecture team make trade-off decisions.\n\n---\n\n## Evaluating Your PO Spec: Readiness Scoring\n\nBefore handing off your Product Owner Specification to the architecture team, you should evaluate its completeness to ensure it provides sufficient business context for architecture design.\n\n### Scoring Methodology\n\nYour PO Spec will be evaluated on a **0-10 scale** using a weighted scoring methodology that gives higher weight to sections most critical for architecture decisions.\n\n**Section Weights:**\n\n| Section | Weight | Why This Matters for Architecture |\n|---------|--------|-----------------------------------|\n| **4. Use Cases** | 2.5 | Defines system behavior and flows architecture must support |\n| **7. Business Constraints** | 2.0 | Budget, compliance, and timeline directly constrain architecture decisions |\n| **3. Business Objectives** | 1.5 | Business value and success criteria justify architecture choices |\n| **1. Business Context** | 1.0 | Problem statement frames the architecture solution |\n| **6. UX Requirements** | 1.0 | Performance and usability translate to technical SLAs |\n| **8. Success Metrics & KPIs** | 1.0 | Measurable targets inform capacity planning |\n| **2. Stakeholders & Users** | 0.5 | Provides context but doesn't directly constrain architecture |\n| **5. User Stories** | 0.5 | Implementation detail, less architectural significance |\n| **Total** | **10.0** | |\n\n### Readiness Threshold\n\n**Minimum \"Ready\" Score: 7.5/10**\n\n**Score Interpretation:**\n- **9.0-10.0**: Excellent - Ready for architecture design\n- **7.5-8.9**: Good - Minor gaps, ready with clarifications\n- **6.0-7.4**: Adequate - Moderate gaps, requires revisions before architecture work\n- **4.0-5.9**: Needs Work - Significant gaps, not ready for architecture team\n- **0.0-3.9**: Incomplete - Major sections missing, substantial work required\n\n### How to Improve Your Score\n\n**Focus on high-weight sections first:**\n\n1. **Use Cases (2.5 points)**: Ensure you have at least 3 detailed use cases with primary flows, alternative flows, edge cases, and success metrics\n2. **Business Constraints (2.0 points)**: Document all constraints - budget breakdown, hard deadlines, compliance requirements, integration constraints, operational constraints\n3. **Business Objectives (1.5 points)**: Define at least 3 measurable business goals with specific targets, timeframes, and ROI expectations\n\n**For detailed evaluation criteria**, see: [PO_SPEC_SCORING_GUIDE.md](PO_SPEC_SCORING_GUIDE.md)\n\n### Self-Assessment Checklist\n\nBefore submitting to architecture team, verify:\n\n**Critical Sections (High Weight):**\n- [ ] At least 3 complete use cases with flows and success metrics\n- [ ] Budget constraints specified with breakdown\n- [ ] Timeline constraints with hard deadlines and reasoning\n- [ ] Regulatory/compliance requirements documented\n- [ ] At least 3 measurable business objectives with targets\n- [ ] ROI expectations calculated\n\n**Important Sections (Medium Weight):**\n- [ ] Problem statement clearly articulated\n- [ ] Performance expectations specified (user-facing metrics)\n- [ ] Business KPIs defined with targets and timeframes\n\n**Supporting Sections (Lower Weight):**\n- [ ] At least 2 user personas defined\n- [ ] At least 5 user stories with acceptance criteria\n\nIf you've checked all items in \"Critical Sections\" and most of \"Important Sections,\" your PO Spec likely scores ‚â•7.5/10 and is ready for architecture team review.\n\n---\n\n### Common Pitfalls to Avoid\n\n‚ùå **Pitfall 1: Prescribing Technical Solutions**\n\n**Problem:** \"We need to use microservices on Kubernetes with Kafka event streaming.\"\n\n**Fix:** Focus on business requirements (scalability needs, availability targets) and let architecture team choose technologies.\n\n---\n\n‚ùå **Pitfall 2: Vague Success Criteria**\n\n**Problem:** \"Customers will love this feature.\"\n\n**Fix:** Define measurable success: \"Customer satisfaction >4.5/5.0, adoption rate >10% within 6 months.\"\n\n---\n\n‚ùå **Pitfall 3: Ignoring Constraints**\n\n**Problem:** Not documenting budget, timeline, or regulatory constraints upfront.\n\n**Fix:** Section 7 (Business Constraints) is mandatory and must be reviewed with legal/compliance.\n\n---\n\n‚ùå **Pitfall 4: Writing User Stories Without Use Cases**\n\n**Problem:** Jumping straight to detailed user stories without high-level use cases.\n\n**Fix:** Start with Use Cases (Section 4) to give architecture team the big picture, then add User Stories (Section 5) for implementation detail.\n\n---\n\n‚ùå **Pitfall 5: Forgetting Accessibility**\n\n**Problem:** Not including accessibility requirements until late in development.\n\n**Fix:** Section 6 (User Experience Requirements) must include WCAG compliance and accessibility specifics upfront.\n\n---\n\n## References\n\n### Related Guides\n- [PO_SPEC_SCORING_GUIDE.md](PO_SPEC_SCORING_GUIDE.md) - Detailed scoring methodology for evaluating PO Spec readiness (0-10 scale)\n- [ARCHITECTURE_DOCUMENTATION_GUIDE.md](../architecture-docs/ARCHITECTURE_DOCUMENTATION_GUIDE.md) - Architecture documentation guide (created by architecture team using this PO Spec as input)\n- [ADR_GUIDE.md](../architecture-docs/ADR_GUIDE.md) - Architecture Decision Records guide (documents key architecture decisions)\n\n### External Resources\n\n**Product Management:**\n- [Product Owner Role (Scrum.org)](https://www.scrum.org/resources/what-is-a-product-owner) - Product Owner responsibilities in Agile\n- [User Story Mapping (Jeff Patton)](https://www.jpattonassociates.com/user-story-mapping/) - Technique for organizing user stories\n\n**Requirements Documentation:**\n- [MoSCoW Prioritization](https://www.productplan.com/glossary/moscow-prioritization/) - Must/Should/Could/Won't prioritization method\n- [Persona Development](https://www.nngroup.com/articles/persona/) - Creating effective user personas (Nielsen Norman Group)\n\n**Accessibility:**\n- [WCAG 2.1 Guidelines](https://www.w3.org/WAI/WCAG21/quickref/) - Web Content Accessibility Guidelines\n- [ADA Compliance for Mobile Apps](https://www.ada.gov/) - Americans with Disabilities Act compliance\n\n**Financial Services Compliance:**\n- [Regulation E](https://www.consumerfinance.gov/rules-policy/regulations/1005/) - Electronic Fund Transfer Act (Consumer Financial Protection Bureau)\n- [GLBA](https://www.ftc.gov/business-guidance/privacy-security/gramm-leach-bliley-act) - Gramm-Leach-Bliley Act (Federal Trade Commission)\n\n---\n\n**Document Version**: 1.0.0\n**Last Updated**: 2025-01-25\n**Maintained By**: Product Team",
        "skills/architecture-readiness/SKILL.md": "---\nname: architecture-readiness\ndescription: Use this skill to create Product Owner Specifications documenting business requirements before architecture design\n---\n\n# Architecture Readiness Skill\n\n## Description\n\nThis skill helps Product Owners document business requirements and context before architecture design begins. It provides templates and guidance for creating Product Owner Specifications that feed into technical ARCHITECTURE.md documents.\n\nThe skill includes two primary functions:\n1. **PO Spec Creation**: Templates and guidance for documenting business requirements\n2. **PO Spec Evaluation**: Scoring methodology to assess if a PO Spec is ready for architecture team handoff\n\n## When to Use This Skill\n\nInvoke this skill when:\n- User asks to create a Product Owner Specification\n- User asks about documenting business requirements for architecture\n- User mentions \"business context\", \"product requirements\", or \"requirements gathering\" in relation to architecture\n- User wants to prepare business documentation before technical architecture design\n- User asks to evaluate or score a Product Owner Specification\n- User wants to know if their PO Spec is ready for the architecture team\n\n## Files in This Skill\n\n- **PRODUCT_OWNER_SPEC_GUIDE.md**: Comprehensive guide with 8-section template, examples, and best practices\n- **templates/PO_SPEC_TEMPLATE.md**: Quick-start template for creating a new PO Specification\n- **PO_SPEC_SCORING_GUIDE.md**: Weighted scoring methodology to evaluate PO Spec readiness (0-10 scale)\n\n## How to Use This Skill\n\n### For PO Spec Creation\n\nWhen this skill is activated for document creation:\n\n1. **Read the guide**: Load PRODUCT_OWNER_SPEC_GUIDE.md to understand the 8-section structure\n2. **Understand user context**: Ask clarifying questions about their product/feature\n3. **Provide appropriate template**:\n   - For guidance and understanding: Reference PRODUCT_OWNER_SPEC_GUIDE.md\n   - For quick start: Provide templates/PO_SPEC_TEMPLATE.md\n4. **Guide document creation**: Help user fill out each section with business context\n5. **Reference mapping**: Explain how PO Spec maps to ARCHITECTURE.md (see guide Section \"Mapping to ARCHITECTURE.md\")\n\n### For PO Spec Evaluation\n\nWhen this skill is activated to evaluate a PO Spec:\n\n1. **Read the scoring guide**: Load PO_SPEC_SCORING_GUIDE.md to understand the weighted scoring methodology\n2. **Read the PO Spec**: Load the user's Product Owner Specification document\n3. **Evaluate each section**: Assess completeness of all 8 sections using the evaluation criteria\n4. **Calculate weighted score**: Apply section weights and compute total score (0-10 scale)\n5. **Provide detailed feedback**:\n   - Overall score and readiness interpretation\n   - Section-by-section breakdown showing completeness %\n   - Identify gaps in critical sections (Use Cases, Business Constraints, Business Objectives)\n   - Provide actionable recommendations for improvement\n6. **Determine readiness**: Score ‚â•7.5/10 indicates ready for architecture team handoff\n\n## Key Principles\n\n- **Business-focused**: No technical details or architecture decisions in PO Spec\n- **User-centric**: Emphasize user needs, personas, and pain points\n- **Measurable**: All goals and success criteria must be quantifiable\n- **Constraint-aware**: Document all business constraints (budget, timeline, compliance)\n\n## Integration with Other Skills\n\n**Relationship to architecture-docs skill:**\n- architecture-readiness (this skill) ‚Üí Creates **business** requirements (PO Spec)\n- architecture-docs skill ‚Üí Creates **technical** architecture (ARCHITECTURE.md)\n\n**Workflow:**\n1. Product Owner uses architecture-readiness skill ‚Üí Creates PO Spec\n2. PO Spec handed off to architecture team\n3. Architecture team uses architecture-docs skill ‚Üí Creates ARCHITECTURE.md\n\n## Example Invocations\n\n### Example 1: Creating a PO Spec\n\n```\nUser: \"I want to create a Product Owner Specification for a new mobile payment feature\"\n\nClaude (with architecture-readiness skill activated):\n1. Load PRODUCT_OWNER_SPEC_GUIDE.md to understand structure\n2. Ask clarifying questions:\n   - What business problem does this solve?\n   - Who are the target users?\n   - What are the business objectives and success metrics?\n   - Are there regulatory/compliance requirements?\n3. Guide user through 8 sections:\n   - Business Context\n   - Stakeholders & Users\n   - Business Objectives\n   - Use Cases\n   - User Stories\n   - User Experience Requirements\n   - Business Constraints\n   - Success Metrics & KPIs\n4. Provide template sections as needed\n5. Explain how completed PO Spec feeds into ARCHITECTURE.md\n```\n\n### Example 2: Evaluating a PO Spec\n\n```\nUser: \"Can you evaluate my Product Owner Spec and tell me if it's ready for the architecture team?\"\n\nClaude (with architecture-readiness skill activated):\n1. Load PO_SPEC_SCORING_GUIDE.md to understand scoring methodology\n2. Read the user's PRODUCT_OWNER_SPEC.md file\n3. Evaluate each section:\n   - Section 1 (Business Context): 80% complete\n   - Section 2 (Stakeholders): 60% complete\n   - Section 3 (Business Objectives): 90% complete\n   - Section 4 (Use Cases): 100% complete\n   - Section 5 (User Stories): 70% complete\n   - Section 6 (UX Requirements): 85% complete\n   - Section 7 (Business Constraints): 95% complete\n   - Section 8 (Success Metrics): 80% complete\n4. Calculate weighted score: 8.85/10\n5. Provide feedback:\n   - \"Your PO Spec scores 8.85/10 - Good, ready for architecture design\"\n   - \"Excellent: Use Cases, Business Constraints, Business Objectives\"\n   - \"Minor gaps: Stakeholders & Users section needs more detailed personas\"\n   - \"Recommendation: Proceed with architecture design; clarify user personas during kickoff\"\n```\n\n## Common User Requests\n\n**PO Spec Creation:**\n- \"Help me document business requirements\" ‚Üí Use PRODUCT_OWNER_SPEC_GUIDE.md\n- \"I need a template for product specifications\" ‚Üí Provide templates/PO_SPEC_TEMPLATE.md\n- \"How does this relate to the architecture document?\" ‚Üí Reference \"Mapping to ARCHITECTURE.md\" section in guide\n- \"What should I include in use cases vs user stories?\" ‚Üí Reference Sections 4 and 5 of guide\n\n**PO Spec Evaluation:**\n- \"Evaluate my PO Spec\" ‚Üí Use PO_SPEC_SCORING_GUIDE.md to score the document\n- \"Is my PO Spec ready for the architecture team?\" ‚Üí Score and assess readiness (‚â•7.5/10)\n- \"What's missing from my business requirements?\" ‚Üí Identify gaps using evaluation criteria\n- \"How can I improve my PO Spec score?\" ‚Üí Provide actionable recommendations based on section weights\n\n## Success Criteria\n\n### For PO Spec Creation\n\nA well-formed Product Owner Specification should:\n- ‚úÖ Have all 8 sections completed\n- ‚úÖ Include specific, measurable success criteria\n- ‚úÖ Define user personas with real pain points\n- ‚úÖ Document all business constraints (budget, timeline, compliance)\n- ‚úÖ Use business language (avoid technical jargon)\n- ‚úÖ Map clearly to ARCHITECTURE.md inputs\n- ‚úÖ Score ‚â•7.5/10 on the weighted scoring methodology\n\n### For PO Spec Evaluation\n\nA quality evaluation should:\n- ‚úÖ Assess all 8 sections using the evaluation criteria from PO_SPEC_SCORING_GUIDE.md\n- ‚úÖ Calculate weighted score correctly (applying section weights)\n- ‚úÖ Provide clear readiness determination (Ready ‚â•7.5/10, Not Ready <7.5/10)\n- ‚úÖ Give specific, actionable feedback for each gap identified\n- ‚úÖ Prioritize feedback on high-weight sections (Use Cases, Business Constraints, Business Objectives)\n- ‚úÖ Explain what needs to be added/improved to reach readiness threshold",
        "skills/architecture-readiness/templates/PO_SPEC_TEMPLATE.md": "# [Product/Feature Name] - Product Owner Specification\n\n> [One-sentence description of what this product/feature does and who it's for]\n\n**Product Owner**: [Your Name]\n**Date**: [YYYY-MM-DD]\n**Version**: 1.0\n\n---\n\n## 1. Business Context\n\n### Problem Statement\n\n**Current State:**\n- [Describe current pain points, limitations, or manual processes]\n- [Impact on business operations]\n- [Impact on customers]\n- [Quantify the problem: costs, time, errors, customer complaints]\n\n**Desired Future State:**\n- [How things should work after this solution is implemented]\n- [Expected improvements]\n- [Competitive advantages gained]\n\n### Market Context\n\n**Industry Trends:**\n- [Relevant market trends driving this initiative]\n- [Customer expectations evolving in the market]\n- [Regulatory or compliance changes]\n\n**Competitive Landscape:**\n- [How competitors are addressing this problem]\n- [Our competitive position]\n- [Differentiation opportunities]\n\n### Strategic Alignment\n\n**Strategic Goals:**\n- [Company strategic objectives this supports]\n- [Business unit goals addressed]\n- [Multi-year roadmap positioning]\n\n**Timing:**\n- [Why now? Market window, urgency, dependencies on other initiatives]\n\n---\n\n## 2. Stakeholders & Users\n\n### Primary Stakeholders\n\n| Stakeholder | Role | Interest/Concern | Influence Level |\n|-------------|------|------------------|-----------------|\n| [Name/Group] | [Role] | [What they care about] | High/Medium/Low |\n| | | | |\n| | | | |\n\n### User Personas\n\n#### Persona 1: [Persona Name]\n\n**Demographics:**\n- Age range:\n- Tech savviness:\n- Usage patterns:\n\n**Goals:**\n- [Primary goal 1]\n- [Primary goal 2]\n\n**Pain Points:**\n- [Current frustration 1]\n- [Current frustration 2]\n\n**Needs from This System:**\n- [Need 1]\n- [Need 2]\n\n#### Persona 2: [Persona Name]\n\n[Repeat structure for additional personas]\n\n### User Segments\n\n**Segment 1: [Segment Name]**\n- Size: [Number or percentage of users]\n- Characteristics: [Defining traits]\n- Priority: High/Medium/Low\n\n### Impact Analysis\n\n**Positively Impacted:**\n- [Group 1]: [Expected benefit]\n- [Group 2]: [Expected benefit]\n\n**Change Management Considerations:**\n- [Groups requiring training]\n- [Communication strategy needs]\n- [Resistance expected from [group] due to [reason]]\n\n---\n\n## 3. Business Objectives\n\n### Primary Business Goals\n\n1. **Goal 1: [Description]**\n   - Metric: [How measured]\n   - Target: [Specific target value]\n   - Timeframe: [When to achieve]\n\n2. **Goal 2: [Description]**\n   - Metric: [How measured]\n   - Target: [Specific target value]\n   - Timeframe: [When to achieve]\n\n3. **Goal 3: [Description]**\n   - Metric: [How measured]\n   - Target: [Specific target value]\n   - Timeframe: [When to achieve]\n\n### Success Criteria\n\n**Must Achieve (Critical):**\n- [Criteria 1]\n- [Criteria 2]\n\n**Should Achieve (Important):**\n- [Criteria 1]\n- [Criteria 2]\n\n**Could Achieve (Nice to Have):**\n- [Criteria 1]\n- [Criteria 2]\n\n### ROI Expectations\n\n**Investment:**\n- Development cost estimate: $[Amount]\n- Implementation timeline: [Duration]\n- Ongoing operational costs: $[Amount]/month\n\n**Expected Returns:**\n- Cost savings: $[Amount]/year\n- Revenue impact: $[Amount]/year\n- Payback period: [Months]\n\n**Non-Financial Benefits:**\n- [Customer satisfaction improvement]\n- [Competitive positioning]\n- [Strategic capabilities unlocked]\n\n### Timeline & Milestones\n\n**Phase 1: [Name]**\n- Target Date: [Date]\n- Deliverables: [What's delivered]\n- Success Criteria: [How evaluated]\n\n**Phase 2: [Name]**\n- Target Date: [Date]\n- Deliverables: [What's delivered]\n- Success Criteria: [How evaluated]\n\n---\n\n## 4. Use Cases\n\n### Use Case 1: [Use Case Name]\n\n**Description**: [What the user is trying to accomplish]\n\n**Actors**: [Who is involved - user types, systems]\n\n**Preconditions**: [What must be true before this use case starts]\n\n**Primary Flow**:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n4. [Continue...]\n\n**Alternative Flows**:\n- **Alternative 1: [Scenario Name]**\n  - Steps differ at: [Step number]\n  - Flow: [Describe alternative steps]\n\n**Edge Cases**:\n- [Edge case 1]: [How handled]\n- [Edge case 2]: [How handled]\n\n**Postconditions**: [System state after successful completion]\n\n**Success Metrics**:\n- Completion rate: [Target %]\n- Time to complete: [Target time]\n- Error rate: [Target %]\n\n### Use Case 2: [Use Case Name]\n\n[Repeat structure for additional use cases]\n\n---\n\n## 5. User Stories\n\n### Epic: [Epic Name]\n\n#### Story 1: [Story Title]\n\n**User Story:**\nAs a [user type],\nI want [goal/desire],\nSo that [benefit/value].\n\n**Acceptance Criteria:**\n- [ ] [Criterion 1]\n- [ ] [Criterion 2]\n- [ ] [Criterion 3]\n\n**Priority**: Must Have | Should Have | Could Have | Won't Have\n\n**Business Value**: [Why this is important]\n\n**Dependencies**: [Other stories or systems this depends on]\n\n**Notes**: [Additional context, edge cases, clarifications]\n\n---\n\n#### Story 2: [Story Title]\n\n[Repeat structure for additional stories]\n\n### Epic: [Another Epic Name]\n\n[Group related stories under epics]\n\n---\n\n## 6. User Experience Requirements\n\n### Performance Expectations\n\n**Page Load Time:**\n- Target: [X] seconds or less for [Y]% of users\n- Maximum acceptable: [X] seconds\n\n**Transaction Speed:**\n- [Operation 1]: Complete in <[X] seconds\n- [Operation 2]: Complete in <[X] seconds\n\n**Responsiveness:**\n- UI interaction response: <[X]ms\n- Search results: <[X] seconds\n\n### Usability Requirements\n\n**Ease of Use:**\n- New users can complete primary task without help in <[X] minutes\n- Task completion rate: >[X]% for primary use cases\n- Maximum [X] clicks to complete common tasks\n\n**Learnability:**\n- First-time user success rate: >[X]%\n- Tutorial completion optional but available\n- In-context help for complex features\n\n**Error Handling:**\n- Clear, actionable error messages (no technical jargon)\n- Inline validation for form fields\n- Recovery path for all error scenarios\n\n### Accessibility Requirements\n\n**Standards Compliance:**\n- WCAG 2.1 Level AA compliance (minimum)\n- [ADA compliance | Section 508 compliance if applicable]\n\n**Specific Requirements:**\n- Screen reader compatible\n- Keyboard navigation for all features\n- Color contrast ratios meet standards\n- Text resize up to 200% without loss of functionality\n- [Captions for video/audio content if applicable]\n\n### Cross-Platform Consistency\n\n**Supported Platforms:**\n- iOS: [Versions]\n- Android: [Versions]\n- Web (if applicable): [Browsers]\n\n**Consistency Requirements:**\n- Feature parity across platforms\n- Consistent visual design and interaction patterns\n- Data synchronized across devices (real-time or <[X] seconds)\n\n### User Journey Mapping\n\n**Journey 1: [Journey Name]**\n- **Entry Point**: [Where user starts]\n- **Key Steps**: [List critical steps]\n- **Pain Points Addressed**: [Previous frustrations solved]\n- **Expected Emotion**: [How user should feel at each stage]\n- **Exit Point**: [Successful completion state]\n\n**Journey 2: [Journey Name]**\n[Repeat structure]\n\n---\n\n## 7. Business Constraints\n\n### Budget Constraints\n\n**Total Budget**: $[Amount]\n\n**Budget Breakdown**:\n- Development: $[Amount]\n- Infrastructure: $[Amount]\n- Licensing: $[Amount]\n- Contingency: $[Amount]\n- Ongoing operational costs: $[Amount]/month\n\n**Budget Approval**: [Who approved, date]\n\n### Timeline Constraints\n\n**Hard Deadlines:**\n- [Milestone 1]: [Date] - [Reason for deadline]\n- Launch date: [Date] - [Reason for deadline]\n\n**Flexibility:**\n- Features that can slip to Phase 2 if needed\n- Features that are non-negotiable for launch\n\n### Regulatory & Compliance Requirements\n\n**Applicable Regulations:**\n- [Regulation 1]: [Name, key requirements]\n- [Regulation 2]: [Name, key requirements]\n\n**Compliance Certifications Needed:**\n- [Certification 1]\n- [Certification 2]\n\n**Data Governance:**\n- Data residency requirements\n- Data retention policies\n- PII handling requirements\n\n**Audit Requirements:**\n- Audit trail requirements\n- Retention period for audit logs\n- Access controls and approval workflows\n\n### Integration Constraints\n\n**Existing Systems to Integrate With:**\n- [System 1]: [Name, integration method, known limitations]\n- [System 2]: [Name, integration method, known limitations]\n\n**Technical Limitations:**\n- [Legacy system constraints]\n- [API rate limits]\n- [Data format restrictions]\n\n**Dependencies:**\n- [System upgrades required before this can launch]\n- [Third-party vendor dependencies]\n\n### Operational Constraints\n\n**Support Model:**\n- Support hours: [e.g., 24/7, business hours]\n- Expected support volume: [Tickets/month]\n- SLA requirements: [Response time, resolution time]\n\n**Maintenance Windows:**\n- Acceptable downtime: [e.g., none, scheduled windows]\n- Change freeze periods: [e.g., month-end, quarter-end]\n\n### Resource Constraints\n\n**Team Availability:**\n- Development team: [Size, allocation %]\n- Design team: [Size, allocation %]\n- QA team: [Size, allocation %]\n\n**Skill Gaps:**\n- Training needed for [specific technology/domain]\n- External expertise required for [specific area]\n\n---\n\n## 8. Success Metrics & KPIs\n\n### Business KPIs\n\n**KPI 1: [Name]**\n- **Definition**: [What is measured]\n- **Current Baseline**: [Current value]\n- **Target**: [Goal value]\n- **Timeframe**: [When to achieve]\n- **Measurement Method**: [How tracked]\n- **Owner**: [Who is responsible]\n\n**KPI 2: [Name]**\n- **Definition**: [What is measured]\n- **Current Baseline**: [Current value]\n- **Target**: [Goal value]\n- **Timeframe**: [When to achieve]\n- **Measurement Method**: [How tracked]\n- **Owner**: [Who is responsible]\n\n### User Experience Metrics\n\n**Metric 1: Task Completion Rate**\n- **Definition**: % of users who successfully complete primary task\n- **Target**: >[X]%\n- **Measurement Method**: [Analytics tracking]\n\n**Metric 2: Time to Complete Task**\n- **Definition**: Average time from start to completion\n- **Target**: <[X] minutes\n- **Measurement Method**: [Session timing]\n\n**Metric 3: Error Rate**\n- **Definition**: % of attempts that result in error\n- **Target**: <[X]% (user-caused), <[X]% (system-caused)\n- **Measurement Method**: [Error logging]\n\n**Metric 4: Customer Satisfaction (CSAT)**\n- **Definition**: Post-interaction satisfaction score\n- **Target**: [X]+ out of 5.0\n- **Measurement Method**: [In-app survey]\n\n### Adoption Metrics\n\n**Metric 1: Feature Adoption Rate**\n- **Definition**: % of [target user group] who use feature\n- **Target**: [X]% within [timeframe]\n- **Measurement Method**: [Analytics tracking]\n\n**Metric 2: User Retention (Repeat Usage)**\n- **Definition**: % of first-time users who return\n- **Target**: >[X]%\n- **Measurement Method**: [Cohort analysis]\n\n### Leading vs. Lagging Indicators\n\n**Leading Indicators** (predict future success):\n- [Indicator 1]\n- [Indicator 2]\n\n**Lagging Indicators** (confirm success after the fact):\n- [Indicator 1]\n- [Indicator 2]\n\n### Measurement Approach\n\n**Data Collection:**\n- [Source 1]: [Where data comes from]\n- [Source 2]: [Where data comes from]\n\n**Reporting Frequency:**\n- Daily: [Metrics tracked daily]\n- Weekly: [Metrics tracked weekly]\n- Monthly: [Metrics tracked monthly]\n\n**Dashboards:**\n- [Dashboard 1]: [For whom, what metrics]\n- [Dashboard 2]: [For whom, what metrics]\n\n**Review Cadence:**\n- Weekly review with product team\n- Monthly review with stakeholders\n- Quarterly review with executives\n\n---\n\n## Appendix\n\n### Assumptions\n- [List key assumptions made in this specification]\n\n### Risks\n- [Risk 1]: [Mitigation strategy]\n- [Risk 2]: [Mitigation strategy]\n\n### Open Questions\n- [ ] [Question 1 - Owner, Due Date]\n- [ ] [Question 2 - Owner, Due Date]\n\n---\n\n**Document Status**: Draft | In Review | Approved\n**Approval Date**: [YYYY-MM-DD]\n**Approved By**: [Name, Title]\n\n**Next Steps:**\n1. [Stakeholder review and approval]\n2. [Handoff to architecture team]\n3. [ARCHITECTURE.md creation]"
      },
      "plugins": [
        {
          "name": "solutions-architect-skills",
          "source": "./",
          "description": "Professional architecture documentation workflow: Business requirements, technical architecture, and compliance documentation (10 specialized agents)",
          "version": "2.2.0",
          "author": {
            "name": "shadowX4fox"
          },
          "categories": [],
          "install_commands": [
            "/plugin marketplace add shadowX4fox/solutions-architect-skills",
            "/plugin install solutions-architect-skills@shadowx4fox-solution-architect-marketplace"
          ]
        }
      ]
    }
  ]
}