{
  "author": {
    "id": "BrandCast-Signage",
    "display_name": "BrandCast & FamilyCast Platforms",
    "avatar_url": "https://avatars.githubusercontent.com/u/235915822?v=4"
  },
  "marketplaces": [
    {
      "name": "agent-benchmark-kit",
      "version": null,
      "description": "Automated quality assurance for Claude Code agents using LLM-as-judge evaluation",
      "repo_full_name": "BrandCast-Signage/agent-benchmark-kit",
      "repo_url": "https://github.com/BrandCast-Signage/agent-benchmark-kit",
      "repo_description": "Automated quality assurance for Claude Code agents using LLM-as-judge evaluation. Built by BrandCast.",
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2025-11-09T23:08:01Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"agent-benchmark-kit\",\n  \"owner\": {\n    \"name\": \"BrandCast\",\n    \"email\": \"hello@brandcast.app\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"agent-benchmark-kit\",\n      \"source\": \"./\",\n      \"description\": \"Automated quality assurance for Claude Code agents using LLM-as-judge evaluation\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"agent-benchmark-kit\",\n  \"description\": \"Automated quality assurance for Claude Code agents using LLM-as-judge evaluation\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"BrandCast\",\n    \"url\": \"https://brandcast.app\"\n  },\n  \"repository\": \"https://github.com/BrandCast-Signage/agent-benchmark-kit\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"benchmarking\",\n    \"testing\",\n    \"quality-assurance\",\n    \"llm-as-judge\",\n    \"agents\",\n    \"evaluation\"\n  ],\n  \"homepage\": \"https://github.com/BrandCast-Signage/agent-benchmark-kit\"\n}\n",
        "README.md": "# Agent Benchmark Kit\n\n**Automated quality assurance for Claude Code agents using LLM-as-judge evaluation.**\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub stars](https://img.shields.io/github/stars/BrandCast-Signage/agent-benchmark-kit?style=social)](https://github.com/BrandCast-Signage/agent-benchmark-kit/stargazers)\n\n---\n\n## Why This Exists\n\nWe built AI agents at [BrandCast](https://brandcast.app) for SEO optimization, content publishing, weekly planning, as well as our technical agent fleet. They needed rigorous quality checks and continuous improvement, but manual testing was time-consuming and inconsistent.\n\nSo we built an automated benchmarking system using **AI to evaluate AI**.\n\nWe're still very early, but the approach shows promise. We're open-sourcing what we've built so far.\n\n---\n\n## What You Get\n\n‚úÖ **Slash command** - `/benchmark-agent` for one-command testing\n\n‚úÖ **Test suite creator** - Generate your first benchmark in < 1 hour\n\n‚úÖ **LLM-as-judge** - Automated, objective scoring\n\n‚úÖ **Performance tracking** - JSON-based history over time\n\n‚úÖ **Test rotation** - Keep agents challenged with fresh tests\n\n‚úÖ **Complete examples** - 2 production-tested benchmark suites\n\n---\n\n## Quick Start\n\n```bash\n# 1. Install via Claude Code Marketplace\n/plugin add https://github.com/BrandCast-Signage/agent-benchmark-kit\n\n# 2. Create your first benchmark\n/benchmark-agent --create my-agent\n\n# 3. Answer 5 questions about your agent\n# [Interactive prompts guide you through test creation]\n\n# 4. Run the benchmark\n/benchmark-agent my-agent\n\n# 5. View results and iterate\n# Results show score breakdown and recommendations\n```\n\n---\n\n## Real-World Results\n\nWe use this framework internally at BrandCast for **7 production agents**:\n\n| Agent | Baseline | Current | Improvement |\n|-------|----------|---------|-------------|\n| **SEO Specialist** | 88/100 | 90/100 | +2.3% in 8 days |\n| **Content Publisher** | 97.5/100 | 97.5/100 | Excellent baseline |\n| **Weekly Planner** | 85/100 | 87/100 | Tracked over 12 weeks |\n\nThese aren't toy examples. **These are production agents serving real users.**\n\n---\n\n## How It Works\n\n```mermaid\ngraph TD\n    A[Create Test Suite] --> B[Define Test Cases]\n    B --> C[Set Ground Truth]\n    C --> D[Run Benchmarks]\n    D --> E[Judge Scores Results]\n    E --> F[Track Performance]\n    F --> G[Iterate & Improve]\n    G --> D\n```\n\n### 1. **Create Test Cases**\nDefine inputs that test your agent's capabilities. The `test-suite-creator` agent helps you design 5 diverse, challenging tests.\n\n### 2. **Set Ground Truth**\nDefine expected outputs in JSON format. What should the agent detect? What decisions should it make?\n\n### 3. **Run Benchmarks**\nExecute tests via the `/benchmark-agent` command. Your agent processes each test case.\n\n### 4. **Judge Scores Results**\nThe `benchmark-judge` agent compares actual output to ground truth, scoring objectively (0-100).\n\n### 5. **Track Performance**\nResults stored in `performance-history.json`. See trends over time, detect regressions.\n\n### 6. **Iterate & Improve**\nUse data to guide prompt improvements. Re-run to validate changes.\n\n---\n\n## Key Features\n\n### üéØ Interactive Test Suite Creator\n\n**Problem:** Creating test cases manually is hard and time-consuming.\n\n**Solution:** Answer 5 questions about your agent, get a complete benchmark suite.\n\n```bash\n/benchmark-agent --create my-agent\n\n# Questions you'll answer:\n# 1. What does your agent do?\n# 2. What validations does it perform?\n# 3. What are common edge cases?\n# 4. What would perfect output look like?\n# 5. What would failing output look like?\n\n# Generates:\n# ‚úì 5 diverse test cases\n# ‚úì Ground truth expectations (JSON)\n# ‚úì Scoring rubric (METRICS.md)\n# ‚úì Complete documentation\n```\n\n**Time to first benchmark: < 1 hour**\n\n---\n\n### üìä LLM-as-Judge Evaluation\n\n**Consistent, objective scoring** using AI to evaluate AI output.\n\nThe `benchmark-judge` agent:\n- Compares actual output to expected results\n- Scores using your custom rubric (0-100 scale)\n- Identifies false positives and missed issues\n- Provides detailed feedback\n\n**Agreement rate with manual scoring: 95%+**\n\n---\n\n### üìà Performance Tracking\n\n**Track improvements over time** with JSON-based history.\n\n```json\n{\n  \"seo-specialist\": {\n    \"baseline\": { \"version\": \"v1\", \"score\": 88 },\n    \"current\": { \"version\": \"v2\", \"score\": 90 },\n    \"trend\": \"improving\",\n    \"runs\": [...]\n  }\n}\n```\n\n**See at a glance:**\n- Current score vs. baseline\n- Trend (improving/stable/regressing)\n- Individual test performance\n- Prompt changes and their impact\n\n---\n\n### üîÑ Intelligent Test Rotation\n\n**Keep benchmarks challenging** with automated test rotation.\n\n**When agent scores 95+ on all tests:**\n- Add new challenging test cases\n- Keep agent from \"gaming\" the tests\n\n**When agent scores 100 three times:**\n- Retire test (agent has mastered it)\n- Focus effort on remaining challenges\n\n**Real-world failures:**\n- Add as regression tests\n- Prevent same issues in future\n\n---\n\n## Examples\n\n### Content Quality Agent\n\nValidates blog posts, documentation, and marketing content.\n\n**Test cases:**\n1. Perfect content (no issues)\n2. Missing metadata (frontmatter errors)\n3. Broken citations (statistics without sources)\n4. Missing resources (hero image doesn't exist)\n5. Format errors (YAML syntax, structure issues)\n\n**Score:** 97.5/100 baseline\n\n[See complete example ‚Üí](examples/content-quality-agent/)\n\n---\n\n### Code Review Agent\n\nReviews TypeScript code for style violations and best practices.\n\n**Test cases:**\n1. Perfect code (follows all rules)\n2. Naming violations (camelCase issues)\n3. Import organization (unsorted imports)\n4. Complex types (formatting edge cases)\n5. Multiple violations (comprehensive test)\n\n**Score:** 85/100 baseline\n\n[See complete example ‚Üí](examples/code-review-agent/)\n\n---\n\n## Installation\n\n### Prerequisites\n\n- [Claude Code](https://claude.com/claude-code) installed\n- Git (for manual installation only)\n\n### Option 1: Plugin Marketplace (Recommended)\n\n```bash\n# In Claude Code, run:\n/plugin add https://github.com/BrandCast-Signage/agent-benchmark-kit\n```\n\nThis will automatically:\n1. Install the plugin with all components\n2. Make `/benchmark-agent` command available\n3. Install 3 benchmark agents\n4. Set up templates in your project\n\n**Note:** After installation, you'll need to create the `~/.agent-benchmarks/` directory for test suites:\n\n```bash\nmkdir -p ~/.agent-benchmarks/{templates,examples}\ncp ~/.claude/plugins/agent-benchmark-kit/templates/* ~/.agent-benchmarks/templates/\n```\n\n### Option 2: Install Script\n\nFor a complete setup including examples and templates:\n\n```bash\ngit clone https://github.com/BrandCast-Signage/agent-benchmark-kit.git\ncd agent-benchmark-kit\n./scripts/install.sh\n```\n\nThe install script:\n1. Copies agents to `.claude/agents/`\n2. Copies slash command to `.claude/commands/`\n3. Creates `~/.agent-benchmarks/` directory\n4. Sets up templates and examples\n\n### Option 3: Manual Installation\n\nSee [docs/getting-started.md](docs/getting-started.md) for manual setup instructions.\n\n---\n\n## Usage\n\n### Creating Your First Benchmark\n\n```bash\n# Start interactive creation\n/benchmark-agent --create my-content-agent\n\n# Answer guided questions\n# > What does your agent do?\n# > What validations does it perform?\n# > ...\n\n# Review generated suite\nls ~/.agent-benchmarks/my-content-agent/\n# test-cases/\n# ground-truth/\n# METRICS.md\n# README.md\n\n# Run the benchmark\n/benchmark-agent my-content-agent\n```\n\n---\n\n### Running Benchmarks\n\n```bash\n# Run specific agent\n/benchmark-agent seo-specialist\n\n# Run all agents\n/benchmark-agent --all\n\n# Run with test rotation\n/benchmark-agent seo-specialist --rotate\n\n# Generate report without running tests\n/benchmark-agent --report-only\n```\n\n---\n\n### Interpreting Results\n\n```markdown\n# Benchmark Results: seo-specialist\n\n**Score:** 90/100 ‚úÖ PASS (threshold: 80)\n\n## Individual Tests\n- Test #01 (mediocre content): 82/100 ‚úì\n- Test #02 (excellent content): 96/100 ‚úì\n- Test #03 (keyword stuffing): 92/100 ‚úì\n\n## Trend\n- Baseline (v1): 88/100\n- Current (v2): 90/100\n- **Improvement: +2 points (+2.3%)**\n\n## Recommendations\n- ‚úÖ PASS - Deploy v2\n- Agent shows consistent improvement\n- No regressions detected\n```\n\n---\n\n## Documentation\n\n- **[Getting Started](docs/getting-started.md)** - Installation and first benchmark\n- **[Creating Test Suites](docs/test-creation-guide.md)** - How to design effective tests\n- **[Scoring Rubrics](docs/scoring-rubrics.md)** - How to create fair scoring\n- **[Advanced Usage](docs/advanced-usage.md)** - Test rotation, tracking, tips\n- **[Architecture](docs/architecture.md)** - How the system works\n\n---\n\n## Contributing\n\nWe welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n**Ideas for contributions:**\n- üìö New example benchmark suites (different agent types)\n- üéØ Improved test rotation strategies\n- üìä Alternative storage backends (SQLite, PostgreSQL)\n- üîç Enhanced judge scoring accuracy\n- üìñ Documentation improvements\n- üêõ Bug fixes\n\n**Recognition:** Contributors featured in README and blog posts.\n\n---\n\n## Community\n\n- **GitHub Issues:** [Report bugs or request features](https://github.com/BrandCast-Signage/agent-benchmark-kit/issues)\n- **Discussions:** [Share your benchmark suites](https://github.com/BrandCast-Signage/agent-benchmark-kit/discussions)\n- **Twitter:** [@BrandCastApp](https://twitter.com/BrandCastApp)\n- **Blog:** [BrandCast Engineering Blog](https://news.brandcast.app)\n\n---\n\n## Roadmap\n\n### v1.0 (Current)\n- ‚úÖ Core framework (slash command, agents, templates)\n- ‚úÖ Test suite creator\n- ‚úÖ JSON-based performance tracking\n- ‚úÖ 2 complete examples\n\n### v1.1 (Next)\n- [ ] SQLite migration tool (optional upgrade from JSON)\n- [ ] Web dashboard for viewing trends\n- [ ] GitHub Actions integration (CI/CD)\n- [ ] More example benchmark suites\n\n### v2.0 (Future)\n- [ ] Automated test generation (LLM suggests new tests)\n- [ ] Comparative benchmarking (compare agents)\n- [ ] Team collaboration features\n- [ ] Plugin ecosystem\n\n**Vote on features:** [GitHub Discussions](https://github.com/BrandCast-Signage/agent-benchmark-kit/discussions)\n\n---\n\n## FAQ\n\n### How is this different from PromptFoo?\n\n**PromptFoo** focuses on single-shot LLM prompts.\n**Agent Benchmark Kit** focuses on multi-step Claude Code agents with complex workflows.\n\nKey differences:\n- Native Claude Code integration (Task tool, slash commands)\n- Test suite creator (guided benchmark creation)\n- Production examples (real agent use cases)\n\n### Does this work with other AI frameworks?\n\nCurrently optimized for **Claude Code agents specifically**.\n\nThe methodology could be adapted to other frameworks (LangChain, AutoGPT, etc.), but integration would require custom work.\n\n### How accurate is LLM-as-judge scoring?\n\nIn our testing: **95%+ agreement with manual human scoring**.\n\nThe judge agent:\n- Compares objective criteria (did agent detect issue X?)\n- Uses clear rubrics (defined in METRICS.md)\n- Flags ambiguous cases for human review\n\n### What's the performance overhead?\n\n**Minimal.** Running a 5-test benchmark:\n- Time: ~2-5 minutes (depending on agent complexity)\n- Cost: ~$0.10-0.25 in API costs (Claude Sonnet pricing)\n\nFor weekly runs: **~$1-2/month per agent**\n\n### Can I keep my test cases private?\n\n**Yes!** The framework is open source, but your implementation is private.\n\n**Public:** Framework code, examples, documentation\n**Private:** Your test cases, ground truth, agent prompts, performance data\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n**Use freely, even commercially.** We built this to help the community.\n\n---\n\n## Acknowledgments\n\n**Built with ‚ù§Ô∏è at [BrandCast](https://brandcast.app)**\n\nBrandCast is AI-powered digital signage for small businesses. We use Claude Code agents in production every day, and this framework ensures they work correctly.\n\n**Inspired by:**\n- [Google Cloud: Stop Guessing and Start Benchmarking](https://medium.com/google-cloud/stop-guessing-and-start-benchmarking-your-ai-prompts-312d4f01f65c)\n- The LLM-as-judge methodology from research papers\n- Our own 3+ months of production agent use\n\n**Special thanks:**\n- Claude Code team for building an amazing agent development platform\n- Early testers who provided feedback\n- Contributors who improve this framework\n\n---\n\n## Star This Repo ‚≠ê\n\nIf you find this useful, **star the repository** to show support!\n\nIt helps others discover the project and validates our decision to open source.\n\n---\n\n**Questions?** [Open an issue](https://github.com/BrandCast-Signage/agent-benchmark-kit/issues) or [start a discussion](https://github.com/BrandCast-Signage/agent-benchmark-kit/discussions).\n\n**Want to contribute?** See [CONTRIBUTING.md](CONTRIBUTING.md).\n\n**Follow our journey:** [@BrandCastApp on Twitter](https://twitter.com/BrandCastApp)\n"
      },
      "plugins": [
        {
          "name": "agent-benchmark-kit",
          "source": "./",
          "description": "Automated quality assurance for Claude Code agents using LLM-as-judge evaluation",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add BrandCast-Signage/agent-benchmark-kit",
            "/plugin install agent-benchmark-kit@agent-benchmark-kit"
          ]
        }
      ]
    },
    {
      "name": "brandcast-plugins",
      "version": "1.0.0",
      "description": "BrandCast development tools and automation workflows for Claude Code",
      "repo_full_name": "BrandCast-Signage/brandcast-plugins",
      "repo_url": "https://github.com/BrandCast-Signage/brandcast-plugins",
      "repo_description": "Claude Code plugins for blog automation, MCP integration, and digital signage development",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-10-11T01:54:28Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"brandcast-plugins\",\n  \"version\": \"1.0.0\",\n  \"description\": \"BrandCast development tools and automation workflows for Claude Code\",\n  \"owner\": {\n    \"name\": \"BrandCast\",\n    \"email\": \"dev@brandcast.app\"\n  },\n  \"metadata\": {\n    \"homepage\": \"https://github.com/BrandCast-Signage/brandcast-plugins\",\n    \"repository\": \"https://github.com/BrandCast-Signage/brandcast-plugins\",\n    \"license\": \"MIT\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"cozi-mcp-server\",\n      \"description\": \"MCP server for Cozi Family Organizer - manage shopping lists, to-do lists, and family tasks with AI\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"BrandCast Team\",\n        \"email\": \"dev@brandcast.app\"\n      },\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"BrandCast-Signage/cozi-mcp-server\"\n      },\n      \"category\": \"integration\",\n      \"keywords\": [\"cozi\", \"family\", \"lists\", \"tasks\", \"shopping\", \"mcp\", \"organizer\"],\n      \"homepage\": \"https://github.com/BrandCast-Signage/cozi-mcp-server\"\n    },\n    {\n      \"name\": \"google-tasks-mcp-server\",\n      \"description\": \"MCP server for Google Tasks - manage your Google Tasks with natural language through Claude\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"BrandCast Team\",\n        \"email\": \"dev@brandcast.app\"\n      },\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"BrandCast-Signage/tasks-mcp-server\"\n      },\n      \"category\": \"integration\",\n      \"keywords\": [\"google\", \"tasks\", \"productivity\", \"mcp\", \"todo\", \"gtd\"],\n      \"homepage\": \"https://github.com/BrandCast-Signage/tasks-mcp-server\"\n    }\n  ]\n}\n",
        "README.md": "# BrandCast Plugins for Claude Code\n\n<div align=\"center\">\n\n**Extend Claude Code with powerful automation workflows, MCP integration tools, and development utilities.**\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Plugins-blue)](https://docs.claude.com/en/docs/claude-code/plugins)\n\n[Installation](#installation) ‚Ä¢ [Plugins](#available-plugins) ‚Ä¢ [Contributing](#contributing) ‚Ä¢ [About](#about-brandcast)\n\n</div>\n\n---\n\n## üöÄ Quick Start\n\n### Installation\n\n```bash\n# Add the BrandCast marketplace to Claude Code\n/plugin marketplace add BrandCast-Signage/brandcast-plugins\n\n# Install a specific plugin\n/plugin install blog-automation@brandcast-plugins\n\n# List all available plugins\n/plugin list\n```\n\n### Prerequisites\n\n- [Claude Code](https://github.com/anthropics/claude-code) installed\n- Git and Node.js (for most plugins)\n\n---\n\n## üì¶ Available Plugins\n\n> **‚ö†Ô∏è Important:** MCP plugins require **manual configuration** after installation. You must add credentials to a settings file and restart Claude Code/Desktop. See [Getting Started Guide](./docs/getting-started.md) for detailed setup instructions.\n\n### MCP Servers\n\n#### 1. **Cozi MCP Server** ‚úÖ\n\nMCP server for [Cozi Family Organizer](https://www.cozi.com/) - manage shopping lists, to-do lists, and family tasks with AI.\n\n**Features:**\n- üìù List management (shopping & to-do)\n- ‚úÖ Item operations (add, edit, complete, remove)\n- üîÑ Real-time sync with Cozi\n- ü§ñ Natural language interface through Claude\n\n**Installation:**\n```bash\n/plugin install cozi-mcp-server@brandcast-plugins\n```\n\n**Configuration (required):**\n```bash\nclaude mcp add --transport stdio cozi npx -y @brandcast_app/cozi-mcp-server \\\n  --env COZI_USERNAME=\"your@email.com\" \\\n  --env COZI_PASSWORD=\"your-password\"\n```\n\n[Full Setup Guide ‚Üí](./docs/getting-started.md#cozi-mcp-server) | [Documentation ‚Üí](https://github.com/BrandCast-Signage/cozi-mcp-server)\n\n---\n\n#### 2. **Google Tasks MCP Server** ‚úÖ\n\nMCP server for Google Tasks - manage your tasks with natural language through Claude.\n\n**Features:**\n- üìã Task list management\n- ‚úÖ Create, update, complete, delete tasks\n- üîç Search across all lists\n- üîÑ Full task synchronization\n\n**Installation:**\n```bash\n/plugin install google-tasks-mcp-server@brandcast-plugins\n```\n\n**Configuration (required):**\n1. Get OAuth credentials from [Google Cloud Console](https://console.cloud.google.com/)\n2. Run auth flow: `npx @brandcast_app/google-tasks-mcp auth`\n3. Add configuration:\n   ```bash\n   claude mcp add --transport stdio google-tasks npx -y @brandcast_app/google-tasks-mcp \\\n     --env GOOGLE_CLIENT_ID=\"your_id\" \\\n     --env GOOGLE_CLIENT_SECRET=\"your_secret\" \\\n     --env GOOGLE_REFRESH_TOKEN=\"your_token\"\n   ```\n\n[Full Setup Guide ‚Üí](./docs/getting-started.md#google-tasks-mcp-server) | [Documentation ‚Üí](https://github.com/BrandCast-Signage/tasks-mcp-server)\n\n---\n\n### Coming Soon\n\n#### 3. **Blog Automation** (Q4 2025)\nAutomated publishing pipeline for Astro blogs with Medium cross-posting.\n\n**Features:**\n- Transform draft content to Astro frontmatter format\n- Publish to Astro blogs via git automation\n- Cross-post to Medium with canonical URLs\n- Track publishing status across platforms\n\n**Commands:** `/publish-blog`, `/publish-medium`, `/sync-content`\n**Agents:** `content-transformer`, `seo-optimizer`\n\n---\n\n#### 4. **MCP Integration Toolkit** (Q1 2026)\nScaffolding and development tools for Model Context Protocol servers.\n\n**Features:**\n- Generate MCP server boilerplate\n- Test MCP endpoints\n- Create integration documentation\n- Debug MCP connections\n\n**Commands:** `/mcp-scaffold`, `/mcp-test`, `/mcp-docs`\n**Agents:** `mcp-integration-expert`, `mcp-debugger`\n\n---\n\n#### 5. **Digital Signage Dev Kit** (Q2 2026)\nTools for building digital signage applications and custom widgets.\n\n**Features:**\n- Generate responsive layout code\n- Create widget boilerplate\n- Deploy to common platforms\n- Optimize for display screens\n\n**Commands:** `/signage-layout`, `/signage-widget`, `/signage-deploy`\n**Agents:** `signage-architect`, `widget-developer`\n\n---\n\n#### 6. **Marketing Automation** (Q2 2026)\nContent creation and SEO optimization workflows for marketers.\n\n**Features:**\n- Generate newsletters from blog posts\n- Schedule social media content\n- Analyze content for SEO\n- Create content calendars\n\n**Commands:** `/newsletter-draft`, `/social-schedule`, `/seo-analyze`\n**Agents:** `content-strategist`, `seo-optimizer`, `social-copywriter`\n\n---\n\n## üõ†Ô∏è Plugin Development\n\nWant to build your own plugin? Check out our guides:\n\n- [Creating Your First Plugin](./docs/creating-plugins.md) *(coming soon)*\n- [Plugin Best Practices](./docs/best-practices.md) *(coming soon)*\n- [Contributing Guide](./CONTRIBUTING.md) *(coming soon)*\n\n### Plugin Structure\n\n```\nplugins/my-plugin/\n‚îú‚îÄ‚îÄ commands/           # Slash commands (.md files)\n‚îÇ   ‚îî‚îÄ‚îÄ my-command.md\n‚îú‚îÄ‚îÄ agents/            # Specialized AI agents (.md files)\n‚îÇ   ‚îî‚îÄ‚îÄ my-agent.md\n‚îú‚îÄ‚îÄ hooks/             # Event handlers (optional)\n‚îî‚îÄ‚îÄ README.md          # Plugin documentation\n```\n\n---\n\n## ü§ù Contributing\n\nWe welcome contributions! Here's how you can help:\n\n1. **Report Bugs:** [Open an issue](https://github.com/BrandCast-Signage/brandcast-plugins/issues/new)\n2. **Suggest Plugins:** Share your ideas in [Discussions](https://github.com/BrandCast-Signage/brandcast-plugins/discussions)\n3. **Submit Plugins:** Fork, create, and submit a PR\n4. **Improve Docs:** Help us make the documentation better\n\n### Development Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/BrandCast-Signage/brandcast-plugins.git\ncd brandcast-plugins\n\n# Add as a local marketplace to test\n/plugin marketplace add /path/to/brandcast-plugins\n\n# Install your plugin\n/plugin install your-plugin@brandcast-plugins\n```\n\n---\n\n## üìñ Documentation\n\n- [Claude Code Plugins Documentation](https://docs.claude.com/en/docs/claude-code/plugins)\n- [BrandCast Plugin Strategy](https://github.com/BrandCast-Signage/brandcast-marketing/blob/main/strategy/claude-code-plugin-distribution-strategy.md)\n- [Plugin Marketplace Guide](https://docs.claude.com/en/docs/claude-code/plugin-marketplaces)\n\n---\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## üåü About BrandCast\n\nBrandCast builds AI-powered digital signage and family information centers. We're passionate about developer tools and open source.\n\n**Our Products:**\n- [**BrandCast**](https://brandcast.app) - Digital signage for businesses\n- [**FamilyCast**](https://familycast.app) - Family information centers\n\n**Learn More:**\n- [BrandCast Blog](https://news.brandcast.app) - Industry insights and technical deep-dives\n- [FamilyCast Blog](https://blog.familycast.app) - Family tech and home organization\n- [GitHub](https://github.com/BrandCast-Signage) - Our open source work\n\n---\n\n## üôã Support\n\n- **Questions?** [Start a discussion](https://github.com/BrandCast-Signage/brandcast-plugins/discussions)\n- **Issues?** [Report a bug](https://github.com/BrandCast-Signage/brandcast-plugins/issues)\n- **Ideas?** [Share feedback](https://github.com/BrandCast-Signage/brandcast-plugins/discussions/categories/ideas)\n\n---\n\n<div align=\"center\">\n\n**Built with ‚ù§Ô∏è by the BrandCast team**\n\n[Website](https://brandcast.app) ‚Ä¢ [Blog](https://news.brandcast.app) ‚Ä¢ [GitHub](https://github.com/BrandCast-Signage)\n\n</div>\n"
      },
      "plugins": [
        {
          "name": "cozi-mcp-server",
          "description": "MCP server for Cozi Family Organizer - manage shopping lists, to-do lists, and family tasks with AI",
          "version": "1.0.0",
          "author": {
            "name": "BrandCast Team",
            "email": "dev@brandcast.app"
          },
          "source": {
            "source": "github",
            "repo": "BrandCast-Signage/cozi-mcp-server"
          },
          "category": "integration",
          "keywords": [
            "cozi",
            "family",
            "lists",
            "tasks",
            "shopping",
            "mcp",
            "organizer"
          ],
          "homepage": "https://github.com/BrandCast-Signage/cozi-mcp-server",
          "categories": [
            "cozi",
            "family",
            "integration",
            "lists",
            "mcp",
            "organizer",
            "shopping",
            "tasks"
          ],
          "install_commands": [
            "/plugin marketplace add BrandCast-Signage/brandcast-plugins",
            "/plugin install cozi-mcp-server@brandcast-plugins"
          ]
        },
        {
          "name": "google-tasks-mcp-server",
          "description": "MCP server for Google Tasks - manage your Google Tasks with natural language through Claude",
          "version": "0.1.0",
          "author": {
            "name": "BrandCast Team",
            "email": "dev@brandcast.app"
          },
          "source": {
            "source": "github",
            "repo": "BrandCast-Signage/tasks-mcp-server"
          },
          "category": "integration",
          "keywords": [
            "google",
            "tasks",
            "productivity",
            "mcp",
            "todo",
            "gtd"
          ],
          "homepage": "https://github.com/BrandCast-Signage/tasks-mcp-server",
          "categories": [
            "google",
            "gtd",
            "integration",
            "mcp",
            "productivity",
            "tasks",
            "todo"
          ],
          "install_commands": [
            "/plugin marketplace add BrandCast-Signage/brandcast-plugins",
            "/plugin install google-tasks-mcp-server@brandcast-plugins"
          ]
        }
      ]
    }
  ]
}