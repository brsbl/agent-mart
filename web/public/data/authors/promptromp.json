{
  "author": {
    "id": "promptromp",
    "display_name": "PromptRomp",
    "avatar_url": "https://avatars.githubusercontent.com/u/210919689?v=4"
  },
  "marketplaces": [
    {
      "name": "aws-bootstrap-skill",
      "version": null,
      "description": "Claude Code skill for provisioning and managing AWS GPU instances via the aws-bootstrap CLI",
      "repo_full_name": "promptromp/aws-bootstrap-g4dn",
      "repo_url": "https://github.com/promptromp/aws-bootstrap-g4dn",
      "repo_description": "fast and easy bootstrapping of AWS EC2 instances for CUDA development. Use as a CLI, as a programmatic SDK, or as an Agent Skill!",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-06T00:15:25Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"aws-bootstrap-skill\",\n  \"owner\": {\n    \"name\": \"promptromp\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code skill for provisioning and managing AWS GPU instances via the aws-bootstrap CLI\",\n    \"version\": \"0.1.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"aws-bootstrap-skill\",\n      \"source\": \"./aws-bootstrap-skill/\",\n      \"description\": \"Provision, monitor, and tear down AWS EC2 GPU instances for ML/CUDA development\"\n    }\n  ]\n}\n",
        "README.md": "# aws-bootstrap-g4dn\n\n--------------------------------------------------------------------------------\n\n[![CI](https://github.com/promptromp/aws-bootstrap-g4dn/actions/workflows/ci.yml/badge.svg)](https://github.com/promptromp/aws-bootstrap-g4dn/actions/workflows/ci.yml)\n[![GitHub License](https://img.shields.io/github/license/promptromp/aws-bootstrap-g4dn)](https://github.com/promptromp/aws-bootstrap-g4dn/blob/main/LICENSE)\n[![PyPI - Version](https://img.shields.io/pypi/v/aws-bootstrap-g4dn)](https://pypi.org/project/aws-bootstrap-g4dn/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aws-bootstrap-g4dn)](https://pypi.org/project/aws-bootstrap-g4dn/)\n\nOne command to go from zero to a **fully configured GPU dev box** on AWS ‚Äî with CUDA-matched PyTorch, Jupyter, SSH aliases, and a GPU benchmark ready to run.\n\n```bash\naws-bootstrap launch          # Spot g4dn.xlarge in ~3 minutes\nssh aws-gpu1                  # You're in, venv activated, PyTorch works\n```\n\n### ‚ú® Key Features\n\n| | Feature | Details |\n|---|---|---|\n| üöÄ | **One-command launch** | Spot (default) or on-demand, with automatic fallback on capacity errors |\n| üîë | **Auto SSH config** | Adds `aws-gpu1` alias to `~/.ssh/config` ‚Äî no IP juggling. Cleaned up on terminate |\n| üêç | **CUDA-aware PyTorch** | Detects the installed CUDA toolkit (`nvcc`) and installs PyTorch from the matching wheel index ‚Äî no more `torch.version.cuda` mismatches |\n| ‚úÖ | **PyTorch smoke test** | Runs a quick `torch.cuda` matmul after setup to verify the GPU stack works end-to-end |\n| üìä | **GPU benchmark included** | CNN (MNIST) + Transformer benchmarks with FP16/FP32/BF16 precision and tqdm progress |\n| üìì | **Jupyter ready** | Lab server auto-starts as a systemd service on port 8888 ‚Äî just SSH tunnel and open |\n| üñ•Ô∏è | **`status --gpu`** | Shows CUDA toolkit version, driver max, GPU architecture, spot pricing, uptime, and estimated cost |\n| üíæ | **EBS data volumes** | Attach persistent storage at `/data` ‚Äî survives spot interruptions and termination, reattach to new instances |\n| üóëÔ∏è | **Clean terminate** | Stops instances, removes SSH aliases, cleans up EBS volumes (or preserves with `--keep-ebs`) |\n| ü§ñ | **[Agent Skill](https://agentskills.io/)** | Included Claude Code plugin lets LLM agents autonomously provision, manage, and tear down GPU instances |\n\n### üéØ Target Workflows\n\n1. **Jupyter server-client** ‚Äî Jupyter runs on the instance, connect from your local browser\n2. **VSCode Remote SSH** ‚Äî opens `~/workspace` with pre-configured CUDA debug/build tasks and an example `.cu` file\n3. **NVIDIA Nsight remote debugging** ‚Äî GPU debugging over SSH\n\n---\n\n## Requirements\n\n1. AWS profile configured with relevant permissions (profile name can be passed via `--profile` or read from `AWS_PROFILE` env var)\n2. AWS CLI v2 ‚Äî see [here](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)\n3. Python 3.12+ and [uv](https://github.com/astral-sh/uv)\n4. An SSH key pair (see below)\n\n## Installation\n\n### From PyPI\n\n```bash\npip install aws-bootstrap-g4dn\n```\n\n### With uvx (no install needed)\n\n[uvx](https://docs.astral.sh/uv/guides/tools/) runs the CLI directly in a temporary environment ‚Äî no global install required:\n\n```bash\nuvx --from aws-bootstrap-g4dn aws-bootstrap launch\nuvx --from aws-bootstrap-g4dn aws-bootstrap status\nuvx --from aws-bootstrap-g4dn aws-bootstrap terminate\n```\n\n### From source (development)\n\n```bash\ngit clone https://github.com/promptromp/aws-bootstrap-g4dn.git\ncd aws-bootstrap-g4dn\nuv venv\nuv sync\n```\n\nAll methods install the `aws-bootstrap` CLI.\n\n## SSH Key Setup\n\nThe CLI expects an Ed25519 SSH public key at `~/.ssh/id_ed25519.pub` by default. If you don't have one, generate it:\n\n```bash\nssh-keygen -t ed25519\n```\n\nAccept the default path (`~/.ssh/id_ed25519`) and optionally set a passphrase. The key pair will be imported into AWS automatically on first launch.\n\nTo use a different key, pass `--key-path`:\n\n```bash\naws-bootstrap launch --key-path ~/.ssh/my_other_key.pub\n```\n\n## Usage\n\n### üöÄ Launching an Instance\n\n```bash\n# Show available commands\naws-bootstrap --help\n\n# Dry run ‚Äî validates AMI lookup, key import, and security group without launching\naws-bootstrap launch --dry-run\n\n# Launch a spot g4dn.xlarge (default)\naws-bootstrap launch\n\n# Launch on-demand in a specific region with a custom instance type\naws-bootstrap launch --on-demand --instance-type g5.xlarge --region us-east-1\n\n# Launch without running the remote setup script\naws-bootstrap launch --no-setup\n\n# Use a specific Python version in the remote venv\naws-bootstrap launch --python-version 3.13\n\n# Use a non-default SSH port\naws-bootstrap launch --ssh-port 2222\n\n# Attach a persistent EBS data volume (96 GB gp3, mounted at /data)\naws-bootstrap launch --ebs-storage 96\n\n# Reattach an existing EBS volume from a previous instance\naws-bootstrap launch --ebs-volume-id vol-0abc123def456\n\n# Use a specific AWS profile\naws-bootstrap launch --profile my-aws-profile\n```\n\nAfter launch, the CLI:\n\n1. **Creates/attaches EBS volume** (if `--ebs-storage` or `--ebs-volume-id` was specified)\n2. **Adds an SSH alias** (e.g. `aws-gpu1`) to `~/.ssh/config`\n3. **Runs remote setup** ‚Äî installs utilities, creates a Python venv, installs CUDA-matched PyTorch, sets up Jupyter\n4. **Mounts EBS volume** at `/data` (if applicable ‚Äî formats new volumes, mounts existing ones as-is)\n5. **Runs a CUDA smoke test** ‚Äî verifies `torch.cuda.is_available()` and runs a quick GPU matmul\n6. **Prints connection commands** ‚Äî SSH, Jupyter tunnel, GPU benchmark, and terminate\n\n```bash\nssh aws-gpu1                  # venv auto-activates on login\n```\n\n### üîß What Remote Setup Does\n\nThe setup script runs automatically on the instance after SSH becomes available:\n\n| Step | What |\n|------|------|\n| **GPU verify** | Confirms `nvidia-smi` and `nvcc` are working |\n| **Utilities** | Installs `htop`, `tmux`, `tree`, `jq`, `ffmpeg` |\n| **Python venv** | Creates `~/venv` with `uv`, auto-activates in `~/.bashrc`. Use `--python-version` to pin a specific Python (e.g. `3.13`) |\n| **CUDA-aware PyTorch** | Detects CUDA toolkit version ‚Üí installs PyTorch from the matching `cu{TAG}` wheel index |\n| **CUDA smoke test** | Runs `torch.cuda.is_available()` + GPU matmul to verify the stack |\n| **GPU benchmark** | Copies `gpu_benchmark.py` to `~/gpu_benchmark.py` |\n| **GPU smoke test notebook** | Copies `gpu_smoke_test.ipynb` to `~/gpu_smoke_test.ipynb` (open in JupyterLab) |\n| **Jupyter** | Configures and starts JupyterLab as a systemd service on port 8888 |\n| **SSH keepalive** | Configures server-side keepalive to prevent idle disconnects |\n| **VSCode workspace** | Creates `~/workspace/.vscode/` with `launch.json` and `tasks.json` (auto-detected `cuda-gdb` path and GPU arch), plus an example `saxpy.cu` |\n\n### üìä GPU Benchmark\n\nA GPU throughput benchmark is pre-installed at `~/gpu_benchmark.py` on every instance:\n\n```bash\n# Run both CNN and Transformer benchmarks (default)\nssh aws-gpu1 'python ~/gpu_benchmark.py'\n\n# CNN only, quick run\nssh aws-gpu1 'python ~/gpu_benchmark.py --mode cnn --benchmark-batches 20'\n\n# Transformer only with custom batch size\nssh aws-gpu1 'python ~/gpu_benchmark.py --mode transformer --transformer-batch-size 16'\n\n# Run CUDA diagnostics first (tests FP16/FP32 matmul, autocast, etc.)\nssh aws-gpu1 'python ~/gpu_benchmark.py --diagnose'\n\n# Force FP32 precision (if FP16 has issues on your GPU)\nssh aws-gpu1 'python ~/gpu_benchmark.py --precision fp32'\n```\n\nReports: iterations/sec, samples/sec, peak GPU memory, and avg batch time for each model.\n\n### üìì Jupyter (via SSH Tunnel)\n\n```bash\nssh -NL 8888:localhost:8888 aws-gpu1\n# Then open: http://localhost:8888\n```\n\nOr with explicit key/IP:\n```bash\nssh -i ~/.ssh/id_ed25519 -NL 8888:localhost:8888 ubuntu@<public-ip>\n```\n\nA **GPU smoke test notebook** (`~/gpu_smoke_test.ipynb`) is pre-installed on every instance. Open it in JupyterLab to interactively verify the CUDA stack, run FP32/FP16 matmuls, train a small CNN on MNIST, and visualise training loss and GPU memory usage.\n\n### üñ•Ô∏è VSCode Remote SSH\n\nThe remote setup creates a `~/workspace` folder with pre-configured CUDA debug and build tasks:\n\n```\n~/workspace/\n‚îú‚îÄ‚îÄ .vscode/\n‚îÇ   ‚îú‚îÄ‚îÄ launch.json   # CUDA debug configs (cuda-gdb path auto-detected)\n‚îÇ   ‚îî‚îÄ‚îÄ tasks.json    # nvcc build tasks (GPU arch auto-detected, e.g. sm_75)\n‚îî‚îÄ‚îÄ saxpy.cu          # Example CUDA source ‚Äî open and press F5 to debug\n```\n\nConnect directly from your terminal:\n\n```bash\ncode --folder-uri vscode-remote://ssh-remote+aws-gpu1/home/ubuntu/workspace\n```\n\nThen install the [Nsight VSCE extension](https://marketplace.visualstudio.com/items?itemName=NVIDIA.nsight-vscode-edition) on the remote when prompted. Open `saxpy.cu`, set a breakpoint, and press F5.\n\nSee [Nsight remote profiling guide](docs/nsight-remote-profiling.md) for more details on CUDA debugging and profiling workflows.\n\n### üì§ Structured Output\n\nAll commands support `--output` / `-o` for machine-readable output ‚Äî useful for scripting, piping to `jq`, or LLM tool-use:\n\n```bash\n# JSON output (pipe to jq)\naws-bootstrap -o json status\naws-bootstrap -o json status | jq '.instances[0].instance_id'\n\n# YAML output\naws-bootstrap -o yaml status\n\n# Table output\naws-bootstrap -o table status\n\n# Works with all commands\naws-bootstrap -o json list instance-types | jq '.[].instance_type'\naws-bootstrap -o json launch --dry-run\naws-bootstrap -o json terminate --yes\naws-bootstrap -o json cleanup --dry-run\n```\n\nSupported formats: `text` (default, human-readable with color), `json`, `yaml`, `table`. Commands that require confirmation (`terminate`, `cleanup`) require `--yes` in structured output modes.\n\n### üìã Listing Resources\n\n```bash\n# List all g4dn instance types (default)\naws-bootstrap list instance-types\n\n# List a different instance family\naws-bootstrap list instance-types --prefix p3\n\n# List Deep Learning AMIs (default filter)\naws-bootstrap list amis\n\n# List AMIs with a custom filter\naws-bootstrap list amis --filter \"ubuntu/images/hvm-ssd-gp3/ubuntu-noble*\"\n\n# Use a specific region\naws-bootstrap list instance-types --region us-east-1\naws-bootstrap list amis --region us-east-1\n```\n\n### üñ•Ô∏è Managing Instances\n\n```bash\n# Show all aws-bootstrap instances (including shutting-down)\naws-bootstrap status\n\n# Include GPU info (CUDA toolkit + driver version, GPU name, architecture) via SSH\naws-bootstrap status --gpu\n\n# Hide connection commands (shown by default for each running instance)\naws-bootstrap status --no-instructions\n\n# List instances in a specific region\naws-bootstrap status --region us-east-1\n\n# Terminate all aws-bootstrap instances (with confirmation prompt)\naws-bootstrap terminate\n\n# Terminate but preserve EBS data volumes for reuse\naws-bootstrap terminate --keep-ebs\n\n# Terminate by SSH alias (resolved via ~/.ssh/config)\naws-bootstrap terminate aws-gpu1\n\n# Terminate by instance ID\naws-bootstrap terminate i-abc123\n\n# Mix aliases and instance IDs\naws-bootstrap terminate aws-gpu1 i-def456\n\n# Skip confirmation prompt\naws-bootstrap terminate --yes\n\n# Remove stale SSH config entries for terminated instances\naws-bootstrap cleanup\n\n# Preview what would be removed without modifying config\naws-bootstrap cleanup --dry-run\n\n# Also find and delete orphan EBS data volumes\naws-bootstrap cleanup --include-ebs\n\n# Preview orphan volumes without deleting\naws-bootstrap cleanup --include-ebs --dry-run\n\n# Skip confirmation prompt\naws-bootstrap cleanup --yes\n```\n\n`status --gpu` reports both the **installed CUDA toolkit** version (from `nvcc`) and the **maximum CUDA version supported by the driver** (from `nvidia-smi`), so you can see at a glance whether they match:\n\n```\nCUDA: 12.8 (driver supports up to 13.0)\n```\n\nSSH aliases are managed automatically ‚Äî they're created on `launch`, shown in `status`, and cleaned up on `terminate`. Aliases use sequential numbering (`aws-gpu1`, `aws-gpu2`, etc.) and never reuse numbers from previous instances. You can use aliases anywhere you'd use an instance ID, e.g. `aws-bootstrap terminate aws-gpu1`.\n\n## EBS Data Volumes\n\nAttach persistent EBS storage to keep datasets and model checkpoints across instance lifecycles. Volumes are mounted at `/data` and persist independently of the instance.\n\n```bash\n# Create a new 96 GB gp3 volume, formatted and mounted at /data\naws-bootstrap launch --ebs-storage 96\n\n# After terminating with --keep-ebs, reattach the same volume to a new instance\naws-bootstrap terminate --keep-ebs\n# Output: Preserving EBS volume: vol-0abc123...\n#         Reattach with: aws-bootstrap launch --ebs-volume-id vol-0abc123...\n\naws-bootstrap launch --ebs-volume-id vol-0abc123def456\n```\n\nKey behaviors:\n- `--ebs-storage` and `--ebs-volume-id` are mutually exclusive\n- New volumes are formatted as ext4; existing volumes are mounted as-is\n- Volumes are tagged for automatic discovery by `status` and `terminate`\n- `terminate` deletes data volumes by default; use `--keep-ebs` to preserve them\n- **Orphan cleanup** ‚Äî use `aws-bootstrap cleanup --include-ebs` to find and delete orphan volumes (e.g. from spot interruptions or forgotten `--keep-ebs` volumes). Use `--dry-run` to preview\n- **Spot-safe** ‚Äî data volumes survive spot interruptions. If AWS reclaims your instance, the volume detaches automatically and can be reattached to a new instance with `--ebs-volume-id`\n- EBS volumes must be in the same availability zone as the instance\n- Mount failures are non-fatal ‚Äî the instance remains usable\n\n## EC2 vCPU Quotas\n\nAWS accounts have [service quotas](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html) that limit how many vCPUs you can run per instance family. New or lightly-used accounts often have a **default quota of 0 vCPUs** for GPU instance families (G and VT), which will cause errors on launch:\n\n- **Spot**: `MaxSpotInstanceCountExceeded`\n- **On-Demand**: `VcpuLimitExceeded`\n\nCheck your current quotas (g4dn.xlarge requires at least 4 vCPUs):\n\n```bash\n# Built-in: show all GPU family quotas\naws-bootstrap quota show\n\n# Show only G/VT family quotas\naws-bootstrap quota show --family gvt\n\n# Show only P5 family quotas\naws-bootstrap quota show --family p5\n\n# Show P4/P3/P2 family quotas\naws-bootstrap quota show --family p\n\n# Or use the AWS CLI directly:\naws service-quotas get-service-quota \\\n  --service-code ec2 \\\n  --quota-code L-3819A6DF \\\n  --region us-west-2\n```\n\nRequest increases:\n\n```bash\n# Built-in: request a G/VT spot quota increase (default family)\naws-bootstrap quota request --type spot --desired-value 4\n\n# Request a P5 spot quota increase\naws-bootstrap quota request --family p5 --type spot --desired-value 192\n\n# Check request status\naws-bootstrap quota history\n\n# Or use the AWS CLI directly:\naws service-quotas request-service-quota-increase \\\n  --service-code ec2 \\\n  --quota-code L-3819A6DF \\\n  --desired-value 4 \\\n  --region us-west-2\n```\n\nQuota codes may vary by region or account type. To list the actual codes in your region:\n\n```bash\n# List all G/VT-related quotas\naws service-quotas list-service-quotas \\\n  --service-code ec2 \\\n  --region us-west-2 \\\n  --query \"Quotas[?contains(QuotaName, 'G and VT')].[QuotaCode,QuotaName,Value]\" \\\n  --output table\n```\n\nCommon quota codes:\n\n| Family | Type | Code | Description |\n|--------|------|------|-------------|\n| G/VT | Spot | `L-3819A6DF` | All G and VT Spot Instance Requests |\n| G/VT | On-Demand | `L-DB2E81BA` | Running On-Demand G and VT instances |\n| P5 | Spot | `L-C4BD4855` | All P5 Spot Instance Requests |\n| P4/P3/P2 | Spot | `L-7212CCBC` | All P4, P3 and P2 Spot Instance Requests |\n| P (all) | On-Demand | `L-417A185B` | Running On-Demand P instances (shared across P2-P5) |\n| DL | Spot | `L-85EED4F7` | All DL Spot Instance Requests |\n| DL | On-Demand | `L-6E869C2A` | Running On-Demand DL instances |\n\nSmall increases (4-8 vCPUs) are typically auto-approved within minutes. You can also request increases via the [Service Quotas console](https://console.aws.amazon.com/servicequotas/home). While waiting, you can test the full launch/poll/SSH flow with a non-GPU instance type:\n\n```bash\naws-bootstrap launch --instance-type t3.medium --ami-filter \"ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-*\"\n```\n\n## Claude Code Plugin\n\nA [Claude Code](https://docs.anthropic.com/en/docs/claude-code) plugin is included in the [`aws-bootstrap-skill/`](aws-bootstrap-skill/) directory, enabling LLM coding agents to autonomously provision and manage GPU instances.\n\n### Install from GitHub\n\n```bash\n# Add the marketplace (registers this repo as a plugin source)\n/plugin marketplace add promptromp/aws-bootstrap-g4dn\n\n# Install the plugin\n/plugin install aws-bootstrap-skill@promptromp-aws-bootstrap-g4dn\n```\n\n### Install locally (from repo checkout)\n\n```bash\nclaude --plugin-dir ./aws-bootstrap-skill\n```\n\nSee [`aws-bootstrap-skill/README.md`](aws-bootstrap-skill/README.md) for details.\n\n## Additional Resources\n\n| Topic | Link |\n|-------|------|\n| GPU instance pricing | [instances.vantage.sh](https://instances.vantage.sh/aws/ec2/g4dn.xlarge) |\n| Spot instance quotas | [AWS docs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html) |\n| Deep Learning AMIs | [AWS docs](https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html) |\n| Nsight remote GPU profiling | [Guide](docs/nsight-remote-profiling.md) ‚Äî Nsight Compute, Nsight Systems, and Nsight VSCE on EC2 |\n\nTutorials on setting up a CUDA environment on EC2 GPU instances:\n\n- [Provision an EC2 GPU Host on AWS](https://www.dolthub.com/blog/2025-03-12-provision-an-ec2-gpu-host-on-aws/) (DoltHub, 2025)\n- [AWS EC2 Setup for GPU/CUDA Programming](https://techfortalk.co.uk/2025/10/11/aws-ec2-setup-for-gpu-cuda-programming/) (TechForTalk, 2025)\n",
        "aws-bootstrap-skill/README.md": "# aws-bootstrap-skill\n\nA [Claude Code](https://docs.anthropic.com/en/docs/claude-code) plugin that provides a skill for provisioning and managing AWS EC2 GPU instances via the [aws-bootstrap](https://github.com/promptromp/aws-bootstrap-g4dn) CLI. It enables LLM coding agents to autonomously launch, monitor, and tear down GPU instances for ML/CUDA development workflows.\n\n## Installation\n\n### From GitHub\n\nRegister this repository as a plugin marketplace, then install:\n\n```bash\n# Add the marketplace (one-time setup)\n/plugin marketplace add promptromp/aws-bootstrap-g4dn\n\n# Install the plugin\n/plugin install aws-bootstrap-skill@promptromp-aws-bootstrap-g4dn\n```\n\n### Local install (from repo checkout)\n\n```bash\nclaude --plugin-dir ./aws-bootstrap-skill\n```\n\n### Prerequisites\n\nThe `aws-bootstrap` CLI must be installed separately:\n\n```bash\npip install aws-bootstrap-g4dn\n# or\nuv pip install aws-bootstrap-g4dn\n```\n\nYou also need:\n- AWS credentials configured (`AWS_PROFILE` env var or `--profile` flag)\n- An SSH key pair (default: `~/.ssh/id_ed25519`)\n\n## Usage\n\nOnce the plugin is loaded, Claude Code will automatically use the `aws-bootstrap` skill when you ask about GPU instances. Examples:\n\n- \"Launch a GPU instance for me\"\n- \"What GPU instances are running?\"\n- \"Terminate all my GPU instances\"\n- \"Show me available g5 instance types\"\n- \"Clean up stale SSH entries and orphan EBS volumes\"\n\nThe skill teaches Claude Code to use `--output json` for machine-readable output, handle spot pricing fallbacks, manage EBS data volumes, and clean up resources properly.\n\n## What's Included\n\n- **SKILL.md** -- Main skill with quick reference, common workflows, and error handling guidance\n- **references/commands.md** -- Full command reference with all options, defaults, and JSON output schemas\n\n## License\n\nMIT -- see the [main repository](https://github.com/promptromp/aws-bootstrap-g4dn) for details.\n"
      },
      "plugins": [
        {
          "name": "aws-bootstrap-skill",
          "source": "./aws-bootstrap-skill/",
          "description": "Provision, monitor, and tear down AWS EC2 GPU instances for ML/CUDA development",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add promptromp/aws-bootstrap-g4dn",
            "/plugin install aws-bootstrap-skill@aws-bootstrap-skill"
          ]
        }
      ]
    }
  ]
}