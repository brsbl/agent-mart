{
  "author": {
    "id": "prajapatimehul",
    "display_name": "Prajapati Mehul",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/58658530?u=5d63c064b2cca59401ff6d4bdc3767dd2e2f5447&v=4",
    "url": "https://github.com/prajapatimehul",
    "bio": "DevOps Engineer",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 1,
      "total_skills": 0,
      "total_stars": 6,
      "total_forks": 3
    }
  },
  "marketplaces": [
    {
      "name": "aws-cost-scanner-marketplace",
      "version": null,
      "description": "AWS Cost Optimization plugins for Claude Code",
      "owner_info": {
        "name": "Mehul Prajapati",
        "email": "mehul@example.com"
      },
      "keywords": [],
      "repo_full_name": "prajapatimehul/aws-cost-scanner",
      "repo_url": "https://github.com/prajapatimehul/aws-cost-scanner",
      "repo_description": "Claude Code plugin that finds AWS cost savings. 163 checks across EC2, RDS, S3, Lambda, and 30+ services.",
      "homepage": null,
      "signals": {
        "stars": 6,
        "forks": 3,
        "pushed_at": "2026-01-28T12:04:31Z",
        "created_at": "2026-01-19T10:58:12Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 754
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/agents/aws-cost-scanner.md",
          "type": "blob",
          "size": 12449
        },
        {
          "path": "plugins/aws-cost-scanner/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/commands/scan.md",
          "type": "blob",
          "size": 7897
        },
        {
          "path": "plugins/aws-cost-scanner/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/skills/reviewing-findings",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/skills/reviewing-findings/REVIEW_CRITERIA.md",
          "type": "blob",
          "size": 10378
        },
        {
          "path": "plugins/aws-cost-scanner/skills/reviewing-findings/reviewing-findings.md",
          "type": "blob",
          "size": 7079
        },
        {
          "path": "plugins/aws-cost-scanner/skills/validating-aws-pricing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-cost-scanner/skills/validating-aws-pricing/PRICING_REFERENCE.md",
          "type": "blob",
          "size": 12237
        },
        {
          "path": "plugins/aws-cost-scanner/skills/validating-aws-pricing/validating-aws-pricing.md",
          "type": "blob",
          "size": 7502
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"aws-cost-scanner-marketplace\",\n  \"owner\": {\n    \"name\": \"Mehul Prajapati\",\n    \"email\": \"mehul@example.com\"\n  },\n  \"metadata\": {\n    \"description\": \"AWS Cost Optimization plugins for Claude Code\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"aws-cost-scanner\",\n      \"description\": \"97 automated AWS cost optimization checks across 6 domains with parallel scanning and confidence-based filtering\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Mehul Prajapati\"\n      },\n      \"source\": \"./plugins/aws-cost-scanner\",\n      \"category\": \"infrastructure\",\n      \"tags\": [\"aws\", \"cost-optimization\", \"cloud\", \"finops\"],\n      \"keywords\": [\"aws\", \"cost\", \"optimization\", \"cloud\", \"finops\", \"savings\"]\n    }\n  ]\n}\n",
        "plugins/aws-cost-scanner/agents/aws-cost-scanner.md": "---\nname: aws-cost-scanner\ndescription: AWS cost optimization scanner. Analyzes AWS resources for cost savings. Use when scanning AWS accounts or analyzing domains (compute, storage, database, networking, serverless, reservations, containers, advanced_databases, analytics, data_pipelines, storage_advanced).\ntools: Read, Write, Grep, Glob, mcp__awslabs-aws-api__call_aws\nmodel: inherit\n---\n\n# AWS Cost Optimization Scanner\n\nScan ONE domain for cost optimization findings.\n\n## Input\n\n- `domain`: compute | storage | database | networking | serverless | reservations | containers | advanced_databases | analytics | data_pipelines | storage_advanced\n- `region`: AWS region to scan\n- `compliance`: [HIPAA, SOC2, PCI-DSS] or empty\n- `profile`: AWS profile name\n\n## 11 Domains (163 checks total)\n\n| Domain | Checks | Resources |\n|--------|--------|-----------|\n| compute | 25 | EC2, EBS, AMIs, snapshots, EIPs |\n| storage | 22 | S3, EFS, CloudWatch Logs, CloudTrail |\n| database | 15 | RDS, DynamoDB, ElastiCache |\n| networking | 15 | NAT, ELB, VPC endpoints, data transfer |\n| serverless | 10 | Lambda, API Gateway, SQS, Step Functions |\n| reservations | 10 | RI coverage, Savings Plans |\n| containers | 15 | ECS, EKS, Fargate |\n| advanced_databases | 18 | Aurora, DocumentDB, Neptune, Redshift |\n| analytics | 15 | SageMaker, EMR, OpenSearch, QuickSight |\n| data_pipelines | 12 | Kinesis, MSK, Glue, EventBridge |\n| storage_advanced | 6 | FSx, AWS Backup |\n\n## Workflow\n\n1. Read `checks/all_checks.yaml` for domain checks\n2. Run AWS CLI commands via MCP tool\n3. Save resource inventory\n4. Compare against thresholds\n5. Return findings + resources\n\n## Compliance Rules\n\n| Compliance | Rule | skip_reason |\n|------------|------|-------------|\n| HIPAA | Skip `phi=true` tags, healthcare names | `hipaa-protected` |\n| SOC2 | Don't delete logs (but CAN set retention) | `soc2-audit-required` |\n| PCI-DSS | Skip `pci=true` tags, payment VPCs | `pci-dss-protected` |\n\n## Tag-Based Exclusions\n\n### SkipCostOpt Tag\n\nResources with `SkipCostOpt=true` are **excluded from ALL checks**.\n\n### Exclusion Tags (Honor Any)\n\n| Tag Key | Truthy Values |\n|---------|---------------|\n| SkipCostOpt | true, 1, yes |\n| CostOptExclude | true, 1, yes |\n| DoNotOptimize | true, 1, yes |\n\n### Check Tags in Resource Data\n\n```bash\n# Tags included in describe-* responses\n# Check Tags array for exclusion keys\n```\n\n### Output When Excluded\n\n```json\n{\n  \"resource_id\": \"i-abc123\",\n  \"status\": \"excluded\",\n  \"exclusion_reason\": \"Tag SkipCostOpt=true\"\n}\n```\n\n## Output Format\n\n```json\n{\n  \"domain\": \"compute\",\n  \"region\": \"us-east-1\",\n  \"scanned_at\": \"2026-01-19T15:00:00Z\",\n  \"resources\": {\n    \"ec2_instances\": [...],\n    \"ebs_volumes\": [...]\n  },\n  \"resource_summary\": {\n    \"total_resources\": 17,\n    \"total_findings\": 3\n  },\n  \"findings\": [\n    {\n      \"check_id\": \"EC2-001\",\n      \"resource_id\": \"i-abc123\",\n      \"resource_name\": \"web-server-1\",\n      \"title\": \"Idle EC2 Instance\",\n      \"domain\": \"compute\",\n      \"severity\": \"high\",\n      \"category\": \"idle\",\n      \"monthly_savings\": 70.00,\n      \"confidence\": 85,\n      \"description\": \"CPU < 5% for 14+ days\",\n      \"recommendation\": \"Terminate or stop\",\n      \"environment\": \"production\",\n      \"skip_reason\": null,\n      \"actionable\": true,\n      \"details\": {...}\n    }\n  ]\n}\n```\n\n## Resource Inventory by Domain\n\n### compute\n- `ec2_instances`: All instances\n- `ebs_volumes`: All volumes\n- `elastic_ips`: All EIPs\n- `snapshots`: Account snapshots\n- `amis`: Account AMIs\n\n### storage\n- `s3_buckets`: All buckets\n- `efs_filesystems`: All EFS\n- `cloudwatch_log_groups`: All log groups with retention\n- `cloudtrail_trails`: All trails\n\n### database\n- `rds_instances`: All RDS\n- `rds_snapshots`: Manual snapshots\n- `dynamodb_tables`: All tables\n- `elasticache_clusters`: All clusters\n\n### networking\n- `nat_gateways`: All NAT gateways\n- `load_balancers`: ALBs/NLBs\n- `vpc_endpoints`: All endpoints\n\n### serverless\n- `lambda_functions`: All functions\n- `api_gateways`: REST/HTTP APIs\n- `sqs_queues`: All queues\n- `step_functions`: State machines\n\n### reservations\n- `reserved_instances`: EC2 RIs\n- `reserved_db_instances`: RDS RIs\n- `savings_plans`: Active plans\n\n### containers\n- `ecs_clusters`: All ECS clusters\n- `ecs_services`: Services per cluster\n- `ecs_task_definitions`: Task definitions\n- `eks_clusters`: All EKS clusters\n- `eks_nodegroups`: Node groups per cluster\n- `fargate_tasks`: Fargate tasks\n\n### advanced_databases\n- `aurora_clusters`: Aurora DB clusters\n- `aurora_instances`: Aurora instances\n- `documentdb_clusters`: DocumentDB clusters\n- `neptune_clusters`: Neptune clusters\n- `redshift_clusters`: Redshift clusters\n\n### analytics\n- `sagemaker_notebooks`: Notebook instances\n- `sagemaker_endpoints`: Inference endpoints\n- `emr_clusters`: Active EMR clusters\n- `opensearch_domains`: OpenSearch domains\n- `quicksight_datasets`: QuickSight datasets\n\n### data_pipelines\n- `kinesis_streams`: Data streams\n- `firehose_streams`: Firehose delivery streams\n- `msk_clusters`: MSK Kafka clusters\n- `glue_jobs`: Glue ETL jobs\n- `eventbridge_rules`: EventBridge rules\n\n### storage_advanced\n- `fsx_filesystems`: FSx file systems\n- `backup_plans`: AWS Backup plans\n- `backup_vaults`: Backup vaults\n\n## Cost-Tiered Confidence\n\nHigher-cost findings need MORE evidence before flagging.\n\n### Confidence Tiers\n\n| Tier | Monthly Cost | Min Age | Min Confidence | Signals Required |\n|------|-------------|---------|----------------|------------------|\n| LOW | < $20 | 1 day | 65% | 1 signal OK |\n| MEDIUM | $20 - $100 | 3 days | 75% | 2+ signals |\n| HIGH | > $100 | 7 days | 85% | 2+ signals |\n\n### Apply Before Reporting\n\n1. Calculate monthly_savings → determine tier\n2. Check resource age >= tier.min_age_days\n3. Check confidence >= tier.min_confidence\n4. For MEDIUM/HIGH: verify 2+ signals agree\n5. If any check fails → filter out finding\n\n### Quick Adjustments (Apply After Tier Check)\n\n- **-30%** if resource < 7 days old\n- **-10%** for production environment\n- **+10%** for dev/test environment\n- **-30%** if part of Auto Scaling Group\n\n---\n\n## Multi-Signal Idle Detection\n\n**CRITICAL**: Do NOT flag resources as idle based on CPU alone. Use weighted multi-signal scoring.\n\n### EC2 Idle Detection\n\n| Signal | Metric | Threshold | Weight |\n|--------|--------|-----------|--------|\n| CPU | CPUUtilization avg | < 5% | 0.40 |\n| Network In | NetworkIn | < 0.1 GB/day | 0.15 |\n| Network Out | NetworkOut | < 0.1 GB/day | 0.15 |\n| Connections | NetworkPacketsIn | 0 | 0.20 |\n| Disk I/O | DiskReadOps+WriteOps | < 10/sec | 0.10 |\n\n**Idle Score Formula:**\n```\nidleScore = sum(weights where threshold met)\nThreshold: idleScore >= 0.60 required to flag as idle\n```\n\n### Required AWS Commands\n\n```bash\n# Collect ALL signals (not just CPU)\naws cloudwatch get-metric-statistics --namespace AWS/EC2 \\\n  --metric-name CPUUtilization --dimensions Name=InstanceId,Value={id} \\\n  --start-time {14d_ago} --end-time {now} --period 86400 --statistics Average Maximum\n\naws cloudwatch get-metric-statistics --namespace AWS/EC2 \\\n  --metric-name NetworkIn --dimensions Name=InstanceId,Value={id} \\\n  --start-time {14d_ago} --end-time {now} --period 86400 --statistics Sum\n\naws cloudwatch get-metric-statistics --namespace AWS/EC2 \\\n  --metric-name NetworkPacketsIn --dimensions Name=InstanceId,Value={id} \\\n  --start-time {14d_ago} --end-time {now} --period 86400 --statistics Sum\n```\n\n### Finding Output Format\n\n```json\n{\n  \"check_id\": \"EC2-001\",\n  \"idle_detection\": {\n    \"signals\": {\n      \"cpu_avg\": {\"value\": 2.1, \"threshold\": 5, \"passed\": true, \"weight\": 0.40},\n      \"network_in_gb\": {\"value\": 0.05, \"threshold\": 0.1, \"passed\": true, \"weight\": 0.15},\n      \"connections\": {\"value\": 145, \"threshold\": 0, \"passed\": false, \"weight\": 0.20}\n    },\n    \"idle_score\": 0.55,\n    \"threshold\": 0.60,\n    \"result\": \"NOT_IDLE - has active connections\"\n  }\n}\n```\n\n---\n\n## Live Dependency Checks (MANDATORY SAFETY)\n\nBefore recommending deletion, verify NO active dependencies.\n\n### Dependency Check Matrix\n\n| Resource | Check Command | If Found | Action |\n|----------|--------------|----------|--------|\n| EC2 | `aws autoscaling describe-auto-scaling-instances --instance-ids {id}` | ASG member | **SKIP** |\n| NAT Gateway | `aws ec2 describe-route-tables --filters \"Name=route.nat-gateway-id,Values={id}\"` | Routes exist | **SKIP** |\n| ELB | `aws elbv2 describe-target-health --target-group-arn {arn}` | Healthy targets | **SKIP** |\n| EBS Snapshot | `aws ec2 describe-images --filters \"Name=block-device-mapping.snapshot-id,Values={id}\"` | AMI uses it | Add warning |\n| EFS | `aws efs describe-mount-targets --file-system-id {id}` | Mount targets | Add warning |\n\n### Output When Blocked\n\n```json\n{\n  \"check_id\": \"EC2-001\",\n  \"resource_id\": \"i-abc123\",\n  \"dependency_check\": {\n    \"type\": \"asg_membership\",\n    \"result\": \"member_of: my-asg\",\n    \"safe_to_recommend\": false\n  },\n  \"status\": \"skipped\",\n  \"skip_reason\": \"Resource is member of Auto Scaling Group 'my-asg'\"\n}\n```\n\n### DO NOT\n\n- Recommend deleting EC2 without checking ASG membership\n- Recommend deleting NAT without checking route tables\n- Recommend deleting ELB without checking target health\n- Skip dependency checks to save API calls\n\n## Pricing Reference (for individual finding savings only)\n\nUse these for estimating `monthly_savings` on individual findings.\n**Do NOT use these to calculate total account spend** - that comes from AWS Cost Explorer.\n\n| Resource | Monthly |\n|----------|---------|\n| t3.micro | $7.59 |\n| m5.large | $70.08 |\n| r5.xlarge | $183.96 |\n| db.r5.xlarge | $365.00 |\n| gp3/GB | $0.08 |\n| gp2/GB | $0.10 |\n| NAT Gateway | $32 + data |\n| EIP (unattached) | $3.65 |\n| CW Logs Storage | $0.03/GB-month |\n| CW Logs Ingestion | $0.50/GB (NOT recurring) |\n| EKS Cluster | $72.00 (control plane) |\n| Fargate vCPU/hr | $0.04048 |\n| Fargate GB/hr | $0.004445 |\n| Aurora r6g.large | $187.25 |\n| Redshift dc2.large | $183.96 |\n| OpenSearch m6g.large | $134.32 |\n| SageMaker ml.t3.medium | $30.37 |\n| Kinesis shard/hr | $0.015 |\n| MSK kafka.m5.large | $154.00 |\n| FSx Lustre/GB | $0.145 |\n\n---\n\n## CRITICAL: Pricing Validation Rules\n\n**MANDATORY** - Every finding MUST follow these rules:\n\n### Rule 1: Use Exact Formulas\n\n| Finding Type | Formula | Example |\n|--------------|---------|---------|\n| **Idle EC2** | `hourly_rate × 730` | t2.nano: $0.0058 × 730 = $4.23/mo |\n| **Unattached EBS** | `size_gb × price_per_gb` | 100GB gp3: 100 × $0.08 = $8.00/mo |\n| **CW Logs Retention** | `stored_gb × $0.03` | 221GB: 221 × $0.03 = $6.63/mo |\n| **Over-provisioned** | `(current - recommended) cost` | db.r5.xlarge→large: $365 - $182 = $183/mo |\n| **No RI Coverage** | `on_demand × savings_percent` | db.r5.xlarge: $365 × 40% = $146/mo |\n\n### Rule 2: Sanity Check Against Billing\n\n**BEFORE reporting a finding**, verify:\n```\nfinding.monthly_savings <= service_monthly_spend\n```\n\nExample: If CloudWatch total spend is $159/mo, a single finding CANNOT save $594/mo.\n\n### Rule 3: Distinguish Storage vs Ingestion\n\n**CloudWatch Logs has TWO cost components:**\n- **Storage:** $0.03/GB-month (recurring, reducible with retention)\n- **Ingestion:** $0.50/GB (one-time, NOT affected by retention)\n\nSetting retention ONLY reduces storage costs, NOT ingestion costs.\n\n### Rule 4: Show Calculation in Details\n\nEvery finding MUST include calculation breakdown:\n```json\n{\n  \"monthly_savings\": 6.64,\n  \"details\": {\n    \"calculation\": \"221.4 GB × $0.03/GB = $6.64\",\n    \"pricing_source\": \"CW Logs Storage: $0.03/GB-month\"\n  }\n}\n```\n\n### Rule 5: Flag Findings > $100 for Review\n\nAny finding with `monthly_savings > $100` MUST be flagged:\n```json\n{\n  \"monthly_savings\": 594.34,\n  \"requires_validation\": true,\n  \"validation_reason\": \"Exceeds $100 threshold\"\n}\n```\n\n---\n\n## Common Pricing Mistakes (DO NOT MAKE)\n\n| Mistake | Wrong | Correct |\n|---------|-------|---------|\n| CW Logs savings | stored_gb × $0.50 | stored_gb × $0.03 |\n| Confusing ingestion/storage | \"Setting retention saves $0.50/GB\" | \"Setting retention saves $0.03/GB stored\" |\n| Not checking billing | Finding: $600/mo savings | Check: Service spend only $159/mo |\n| Using wrong multiplier | stored_gb × 2.68 | stored_gb × 0.03 |\n\n---\n\n## Rules\n\n1. Only return confidence >= 50\n2. Include Name tags in `resource_name`\n3. Return `[]` if no issues\n4. Be conservative with savings\n5. **ALWAYS show calculation in details**\n6. **ALWAYS sanity-check against actual billing**\n7. **FLAG findings > $100 for validation**\n",
        "plugins/aws-cost-scanner/commands/scan.md": "---\ndescription: Scan AWS account for cost optimization\nallowed-tools: Read, Task, Write, Bash, Glob, Grep, AskUserQuestion, mcp__awslabs-aws-api__call_aws\n---\n\n# AWS Cost Optimization Scan\n\n## Step 0: Ask for AWS Profile\n\nFirst, ask the user which AWS profile to use:\n\n```json\n{\n  \"questions\": [{\n    \"header\": \"AWS Profile\",\n    \"question\": \"Which AWS profile should I use for the scan?\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\"label\": \"default\", \"description\": \"Use default AWS credentials\"},\n      {\"label\": \"Enter profile name\", \"description\": \"I'll type my profile name\"}\n    ]\n  }]\n}\n```\n\nIf user selects \"Enter profile name\" or \"Other\", ask them to type the profile name.\n\nStore the profile name for all subsequent AWS commands.\n\n**Authentication:** AWS commands work with any valid AWS credentials:\n- SSO profile: `--profile your-sso-profile`\n- Named profile: `--profile your-profile`\n- Environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`\n- IAM role (EC2/Lambda): automatic\n\n## Step 1: Discover Account\n\n```bash\naws sts get-caller-identity --profile {profile}\n```\n\nExtract:\n- **Account ID** → use in report header\n- **Profile name** → use for file naming: `reports/findings_{profile}.json`\n\n## Step 2: Find Active Regions\n\n```bash\n# Get all regions\naws ec2 describe-regions --profile {profile} --query 'Regions[].RegionName' --output json\n\n# Check which have EC2 instances (quick check)\naws ec2 describe-instances --profile {profile} --query 'Reservations[].Instances[0].Placement.AvailabilityZone' --output text\n```\n\nOnly scan regions with resources.\n\n## Step 3: Ask Compliance\n\nUse `AskUserQuestion`:\n\n```json\n{\n  \"questions\": [{\n    \"header\": \"Compliance\",\n    \"question\": \"Which compliance requirements apply?\",\n    \"multiSelect\": true,\n    \"options\": [\n      {\"label\": \"HIPAA\", \"description\": \"Healthcare - skip PHI resources\"},\n      {\"label\": \"SOC2\", \"description\": \"Audit - preserve all logs\"},\n      {\"label\": \"PCI-DSS\", \"description\": \"Payments - skip payment infra\"},\n      {\"label\": \"None\", \"description\": \"No compliance requirements\"}\n    ]\n  }]\n}\n```\n\n## Step 4: Get Actual Monthly Spend\n\n**CRITICAL:** Query AWS Cost Explorer for real billing data.\n\n```bash\naws ce get-cost-and-usage \\\n  --profile {profile} \\\n  --time-period Start={LAST_MONTH_START},End={LAST_MONTH_END} \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --group-by Type=DIMENSION,Key=SERVICE\n```\n\nStore `actual_monthly_spend` in metadata.\n\n**Note:** If no `--profile` is provided, AWS CLI uses default credentials (env vars or IAM role).\n\n## Step 5: Parallel Domain Scan\n\nLaunch 11 `aws-cost-scanner:aws-cost-scanner` subagents **in parallel**:\n\n| Agent | Domain | Checks |\n|-------|--------|--------|\n| 1 | compute | EC2, EBS, AMIs, snapshots, EIPs |\n| 2 | storage | S3, EFS, CloudWatch Logs, CloudTrail |\n| 3 | database | RDS, DynamoDB, ElastiCache |\n| 4 | networking | NAT, ELB, VPC endpoints, data transfer |\n| 5 | serverless | Lambda, API Gateway, SQS, Step Functions |\n| 6 | reservations | RI coverage, Savings Plans |\n| 7 | containers | ECS, EKS, Fargate |\n| 8 | advanced_databases | Aurora, DocumentDB, Neptune, Redshift |\n| 9 | analytics | SageMaker, EMR, OpenSearch, QuickSight |\n| 10 | data_pipelines | Kinesis, MSK, Glue, EventBridge |\n| 11 | storage_advanced | FSx, AWS Backup |\n\nPass to each:\n- `region`: Active region(s)\n- `compliance`: User's selection\n- `profile`: AWS profile name\n\n## Step 6: Merge & Quick Review\n\nCombine all 11 outputs into `reports/findings_{profile}.json`.\n\n**Quick Review (inline - no scripts):**\n\nApply 2 adjustments only:\n1. **Resource Age:** -30% confidence if created < 7 days ago\n2. **Environment:** -10% for production, +10% for dev/test (from Name tags)\n\nMark findings:\n- `approved` if confidence ≥ 70%\n- `needs_validation` if confidence 50-69%\n- `filtered` if confidence < 50%\n\n## Step 6.5: MANDATORY Price Validation\n\n**CRITICAL:** Before generating the report, validate ALL pricing calculations.\n\n### 6.5.1: Get Service-Level Billing\n\nQuery Cost Explorer for service breakdown:\n```bash\naws ce get-cost-and-usage --profile {profile} \\\n  --time-period Start={LAST_MONTH_START},End={LAST_MONTH_END} \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --group-by Type=DIMENSION,Key=SERVICE\n```\n\n### 6.5.2: Sanity Check Each Finding\n\nFor EVERY finding, verify:\n```\nfinding.monthly_savings <= service_monthly_spend\n```\n\n**Example Check:**\n- Finding: CloudWatch Logs savings = $594/mo\n- Billing: CloudWatch total = $159/mo\n- **FAIL** - Finding exceeds service spend!\n\n### 6.5.3: Verify Calculation Formula\n\nEach finding type has a SPECIFIC formula:\n\n| Finding Type | Correct Formula |\n|--------------|-----------------|\n| CW Logs Retention | `stored_gb × $0.03` (storage only) |\n| Unattached EBS | `size_gb × price_per_gb` |\n| Idle EC2 | `hourly_rate × 730` |\n| Over-provisioned | `current_cost - recommended_cost` |\n| No RI Coverage | `on_demand_cost × savings_percent` |\n| Idle EKS Cluster | `$72/mo + node_costs` |\n| Idle Fargate Task | `vCPU_hrs × $0.04048 + GB_hrs × $0.004445` |\n| Idle Aurora | `hourly_rate × 730 + storage_gb × $0.10` |\n| Idle Redshift | `node_hourly × nodes × 730` |\n| Idle SageMaker Endpoint | `hourly_rate × 730` |\n| Over-provisioned Kinesis | `shards × $0.015/hr × 730` |\n| Idle MSK Cluster | `broker_cost × brokers` |\n\n### 6.5.4: Flag & Correct Invalid Findings\n\nIf a finding fails validation:\n1. Recalculate using correct formula\n2. Update `monthly_savings` with corrected value\n3. Add `pricing_corrected: true` to details\n4. Document the correction reason\n\n### 6.5.5: Get Detailed Cost Breakdown (for >$100 findings)\n\nFor findings claiming >$100 savings, query usage type breakdown:\n```bash\naws ce get-cost-and-usage --profile {profile} \\\n  --time-period Start={LAST_MONTH_START},End={LAST_MONTH_END} \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --filter '{\"Dimensions\": {\"Key\": \"SERVICE\", \"Values\": [\"AmazonCloudWatch\"]}}' \\\n  --group-by Type=DIMENSION,Key=USAGE_TYPE\n```\n\nThis reveals actual storage vs ingestion costs.\n\n## Step 6.6: Calculate Priority Scores\n\nRank findings by actionability, not just savings amount.\n\n### Formula\n\n```\npriority_score = impact × confidence × urgency × risk_multiplier\n```\n\n### Components\n\n| Component | Calculation | Range |\n|-----------|-------------|-------|\n| Impact | min(monthly_savings / 100, 10) | 0.1 - 10 |\n| Confidence | confidence / 100 | 0.5 - 1.0 |\n| Urgency | Based on idle duration | 0.7 - 1.5 |\n| Risk Multiplier | Based on environment | 0.5 - 1.5 |\n\n### Urgency Values\n\n| Idle Duration | Urgency |\n|---------------|---------|\n| > 30 days | 1.5 |\n| 14-30 days | 1.2 |\n| 7-14 days | 1.0 |\n| < 7 days | 0.7 |\n\n### Risk Multiplier Values\n\n| Environment | Multiplier |\n|-------------|------------|\n| dev/test | 1.5 (lower risk) |\n| staging | 1.0 |\n| production | 0.5 (higher risk) |\n\n### Example\n\n```\nFinding: Idle RDS ($365/mo), 85% confidence, 21 days idle, production\n\nimpact = min(365/100, 10) = 3.65\nconfidence = 0.85\nurgency = 1.2 (14-30 days)\nrisk = 0.5 (production)\n\npriority_score = 3.65 × 0.85 × 1.2 × 0.5 = 1.86 (MEDIUM)\n```\n\n### Priority Ranking\n\n| Score | Priority | Action |\n|-------|----------|--------|\n| > 5.0 | Critical | This week |\n| 2.0-5.0 | High | This month |\n| 1.0-2.0 | Medium | Next quarter |\n| < 1.0 | Low | When convenient |\n\n## Step 7: Generate Report\n\nCreate `reports/cost_report_{profile}.md`:\n\n```markdown\n# AWS Cost Optimization Report\n\n**Account:** {account_id}\n**Profile:** {profile}\n**Date:** {scan_date}\n**Compliance:** {compliance}\n\n## Summary\n\n| Metric | Value |\n|--------|-------|\n| Actual Monthly Spend | $X,XXX |\n| Approved Savings | $XXX/mo |\n| Needs Validation | $XX/mo |\n\n## Quick Wins (Implement This Week)\n...\n\n## Top Savings Opportunities\n...\n\n## Needs Validation\n...\n```\n\nShow user:\n1. Total approved savings\n2. Top 5 findings\n3. Ask which to implement\n",
        "plugins/aws-cost-scanner/skills/reviewing-findings/REVIEW_CRITERIA.md": "# Review Criteria Reference\n\nDetailed criteria for reviewing each finding type.\n\n## Confidence Adjustments\n\n### Universal Adjustments\n\n| Factor | Adjustment |\n|--------|------------|\n| Resource < 7 days old | -40 |\n| Resource 7-14 days old | -20 |\n| Part of Auto Scaling Group | -30 |\n| Has \"dr\", \"standby\", \"backup\" in name | -25 |\n| Has \"dev\", \"test\", \"staging\" in name | +10 |\n| Production resource | -10 |\n| Multiple metrics agree | +15 |\n| Single metric only | -10 |\n| Recent configuration change | -20 |\n| Consistent pattern (14+ days) | +20 |\n\n### Starting Confidence\n\nEach finding starts with its original confidence from the scan. Adjustments are applied based on review findings.\n\n## Check-Specific Criteria\n\n### EC2-001: Idle EC2 Instance\n\n**Validation Steps:**\n1. Query CloudWatch CPUUtilization for last 14 days\n2. Query NetworkPacketsIn/Out\n3. Check Auto Scaling Group membership\n4. Review instance tags for environment\n\n**Pass Criteria:**\n- Average CPU < 5% for 14+ days\n- Network activity < 1MB/day\n- Not in ASG\n- No scheduled scaling\n\n**AWS Commands:**\n```bash\n# Check CPU\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/EC2 \\\n  --metric-name CPUUtilization \\\n  --dimensions Name=InstanceId,Value={instance_id} \\\n  --start-time {14_days_ago} \\\n  --end-time {now} \\\n  --period 86400 \\\n  --statistics Average Maximum\n\n# Check ASG membership\naws autoscaling describe-auto-scaling-instances \\\n  --instance-ids {instance_id}\n\n# Check tags\naws ec2 describe-tags \\\n  --filters \"Name=resource-id,Values={instance_id}\"\n```\n\n**Confidence Matrix:**\n| CPU Avg | CPU Max | Network | Days | Confidence |\n|---------|---------|---------|------|------------|\n| <2% | <10% | <1MB | 21+ | 95 |\n| <5% | <20% | <10MB | 14+ | 85 |\n| <5% | <40% | <100MB | 14+ | 70 |\n| <10% | <50% | Any | 7-14 | 55 |\n| Any | >60% | Any | Any | 30 |\n\n---\n\n### EC2-002: Over-provisioned EC2 Instance\n\n**Validation Steps:**\n1. Query CPUUtilization (average AND maximum)\n2. Query MemoryUtilization (if CW agent)\n3. Review peak usage times\n4. Check for burst patterns\n\n**Pass Criteria:**\n- Peak CPU < 40% for 14+ days\n- Memory (if available) < 40%\n- No burst patterns\n- Recommended size handles 2x current peak\n\n**Confidence Matrix:**\n| Peak CPU | Memory | Pattern | Confidence |\n|----------|--------|---------|------------|\n| <20% | <30% | Steady | 90 |\n| <30% | <40% | Steady | 80 |\n| <40% | <50% | Steady | 70 |\n| <40% | Any | Burst | 50 |\n| >40% | Any | Any | 30 |\n\n---\n\n### EC2-012: Unattached EBS Volume\n\n**Validation Steps:**\n1. Confirm volume status is \"available\"\n2. Check last attachment time\n3. Verify no recent activity\n4. Check for associated snapshots\n\n**Pass Criteria:**\n- Status = \"available\"\n- Unattached for 7+ days\n- No pending attachments\n\n**AWS Commands:**\n```bash\n# Check volume status\naws ec2 describe-volumes \\\n  --volume-ids {volume_id}\n\n# Check for snapshots\naws ec2 describe-snapshots \\\n  --filters \"Name=volume-id,Values={volume_id}\"\n\n# Check CloudTrail for attachment events\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=ResourceName,AttributeValue={volume_id}\n```\n\n**Confidence Matrix:**\n| Days Unattached | Has Snapshot | Size | Confidence |\n|-----------------|--------------|------|------------|\n| 30+ | Yes | Any | 95 |\n| 30+ | No | <100GB | 90 |\n| 14-30 | Yes | Any | 85 |\n| 14-30 | No | Any | 75 |\n| 7-14 | Any | Any | 60 |\n| <7 | Any | Any | 30 |\n\n---\n\n### RDS-002: Over-provisioned RDS Instance\n\n**Validation Steps:**\n1. Query CPUUtilization for 14+ days\n2. Query DatabaseConnections\n3. Query FreeableMemory\n4. Review peak patterns\n\n**Pass Criteria:**\n- Average CPU < 40% for 14+ days\n- Peak CPU < 60%\n- Connections stable (no growth trend)\n- Recommended size handles peak\n\n**AWS Commands:**\n```bash\n# CPU metrics\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/RDS \\\n  --metric-name CPUUtilization \\\n  --dimensions Name=DBInstanceIdentifier,Value={db_id} \\\n  --start-time {14_days_ago} \\\n  --end-time {now} \\\n  --period 86400 \\\n  --statistics Average Maximum\n\n# Connections\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/RDS \\\n  --metric-name DatabaseConnections \\\n  --dimensions Name=DBInstanceIdentifier,Value={db_id} \\\n  --start-time {14_days_ago} \\\n  --end-time {now} \\\n  --period 86400 \\\n  --statistics Average Maximum\n```\n\n**Confidence Matrix:**\n| CPU Avg | CPU Peak | Connections Trend | Confidence |\n|---------|----------|-------------------|------------|\n| <10% | <30% | Stable/Down | 90 |\n| <20% | <40% | Stable | 80 |\n| <30% | <50% | Stable | 70 |\n| <40% | <60% | Up | 55 |\n| Any | >60% | Any | 35 |\n\n---\n\n### RDS-005: No RI Coverage\n\n**Validation Steps:**\n1. Verify instance runs 24/7\n2. Check for planned migrations\n3. Assess workload stability\n4. Verify commitment period acceptable\n\n**Pass Criteria:**\n- Instance running 24/7\n- No planned instance type changes\n- Workload stable for 3+ months\n- Not a dev/test environment (unless long-lived)\n\n**Confidence Matrix:**\n| Uptime | Stability | Environment | Confidence |\n|--------|-----------|-------------|------------|\n| 24/7 | 90+ days | Production | 90 |\n| 24/7 | 30-90 days | Production | 75 |\n| 24/7 | Any | Dev (long-lived) | 60 |\n| Variable | Any | Any | 40 |\n| Any | <30 days | Any | 30 |\n\n---\n\n### LAMBDA-001: Memory Over-provisioning\n\n**Validation Steps:**\n1. Get function invocation count\n2. Query duration metrics\n3. Check memory utilization (if enabled)\n4. Verify invocation count sufficient for analysis\n\n**Pass Criteria:**\n- 100+ invocations in analysis period\n- Max memory used < 50% of allocated\n- Duration doesn't increase with lower memory\n\n**AWS Commands:**\n```bash\n# Invocations\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Invocations \\\n  --dimensions Name=FunctionName,Value={function_name} \\\n  --start-time {30_days_ago} \\\n  --end-time {now} \\\n  --period 2592000 \\\n  --statistics Sum\n\n# Duration\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Duration \\\n  --dimensions Name=FunctionName,Value={function_name} \\\n  --start-time {30_days_ago} \\\n  --end-time {now} \\\n  --period 86400 \\\n  --statistics Average Maximum\n```\n\n**Confidence Matrix:**\n| Invocations | Memory Used % | Duration Variance | Confidence |\n|-------------|---------------|-------------------|------------|\n| 1000+ | <30% | Low | 90 |\n| 500+ | <40% | Low | 80 |\n| 100+ | <50% | Low | 70 |\n| 50-100 | <50% | Low | 55 |\n| <50 | Any | Any | 35 |\n\n---\n\n### SEC-001: CloudWatch Logs No Retention\n\n**Validation Steps:**\n1. Confirm no retention policy set\n2. Calculate current storage size\n3. Estimate savings from retention\n4. Check for compliance requirements\n\n**Pass Criteria:**\n- No retention policy\n- Storage > 1GB\n- No compliance holds\n- Logs older than needed retention\n\n**Confidence Matrix:**\n| Storage | Age of Logs | Compliance | Confidence |\n|---------|-------------|------------|------------|\n| >100GB | >90 days | None | 95 |\n| >10GB | >90 days | None | 90 |\n| >1GB | >30 days | None | 80 |\n| <1GB | Any | None | 60 |\n| Any | Any | HIPAA/SOC | 50 |\n\n---\n\n### S3-005: Excessive Versioning\n\n**Validation Steps:**\n1. Check versioning configuration\n2. Count noncurrent versions\n3. Review lifecycle policies\n4. Estimate storage from versions\n\n**Pass Criteria:**\n- Versioning enabled\n- No lifecycle for noncurrent versions\n- Significant storage in old versions\n- Not compliance-required retention\n\n**Confidence Matrix:**\n| Version Storage % | Has Lifecycle | Compliance | Confidence |\n|-------------------|---------------|------------|------------|\n| >50% | No | None | 90 |\n| >30% | No | None | 80 |\n| >20% | Partial | None | 70 |\n| <20% | Any | None | 55 |\n| Any | Any | Required | 40 |\n\n---\n\n## False Positive Patterns\n\n### Automatically Filter These\n\n1. **ASG Members**: Instances in Auto Scaling Groups often appear idle but scale on demand\n2. **DR/Standby Resources**: Resources with \"dr\", \"standby\", \"failover\" in name\n3. **Recently Created**: Resources < 7 days old have insufficient data\n4. **Scheduled Workloads**: Resources with evening/weekend idle patterns\n5. **Burst Workloads**: Resources with periodic high utilization spikes\n\n### Require Manual Validation\n\n1. **Production Resources**: Always flag for human review\n2. **High-Value Savings**: Findings with >$500/month savings\n3. **Cross-Account Dependencies**: Resources referenced by other accounts\n4. **Compliance-Tagged**: Resources with compliance-related tags\n\n---\n\n## Batch Workload Detection\n\n**CRITICAL**: Batch workloads show low AVERAGE but high PEAK utilization. These are NOT idle.\n\n### Batch Pattern Definition\n\n```\nisBatch = cpuAvg < 15% AND cpuMax > 60% AND (cpuMax / cpuAvg) >= 4\n```\n\n### Examples\n\n| Instance | Avg CPU | Max CPU | Ratio | Classification |\n|----------|---------|---------|-------|----------------|\n| i-abc123 | 5% | 85% | 17x | **BATCH** - skip |\n| i-def456 | 3% | 12% | 4x | Truly idle - flag |\n| i-ghi789 | 25% | 80% | 3.2x | Active - not idle |\n\n### Required Metric Collection\n\n```bash\n# ALWAYS get both Average AND Maximum\naws cloudwatch get-metric-statistics --namespace AWS/EC2 \\\n  --metric-name CPUUtilization --dimensions Name=InstanceId,Value={id} \\\n  --start-time {14d_ago} --end-time {now} --period 86400 \\\n  --statistics Average Maximum\n```\n\n### When Batch Detected\n\n```json\n{\n  \"check_id\": \"EC2-001\",\n  \"batch_detection\": {\n    \"cpu_avg\": 5.2,\n    \"cpu_max\": 87.3,\n    \"ratio\": 16.8,\n    \"is_batch\": true\n  },\n  \"status\": \"skipped\",\n  \"skip_reason\": \"Batch workload pattern (avg 5.2%, max 87.3%, ratio 16.8x)\"\n}\n```\n\n---\n\n## Review Actions\n\n| Final Confidence | Action | Status |\n|------------------|--------|--------|\n| ≥80 | Recommend implementation | `approved` |\n| 60-79 | Recommend with caveats | `approved_with_review` |\n| 50-59 | Needs validation | `needs_validation` |\n| <50 | Filter from report | `filtered` |\n\n## Agent Weighting\n\nWhen combining agent scores:\n\n| Agent | Weight | Rationale |\n|-------|--------|-----------|\n| Resource Verification | 35% | Most critical - is finding still valid? |\n| Recommendation Quality | 25% | Is the recommendation actionable? |\n| Business Context | 25% | What's the risk of implementing? |\n| Historical Pattern | 15% | Are there hidden patterns? |\n\n**Final Confidence Formula:**\n```python\nfinal = (\n    resource_verification * 0.35 +\n    recommendation_quality * 0.25 +\n    business_context * 0.25 +\n    historical_pattern * 0.15\n)\n```\n",
        "plugins/aws-cost-scanner/skills/reviewing-findings/reviewing-findings.md": "---\nname: reviewing-findings\ndescription: Reviews AWS cost optimization findings for accuracy, validates recommendations, and filters false positives using confidence-based scoring. Use after scanning to ensure high-quality recommendations.\nallowed-tools:\n  - Read\n  - Write\n  - Bash\n  - Grep\n  - Glob\n  - Task\n  - mcp__awslabs-aws-api__call_aws\n---\n\n# Reviewing AWS Cost Findings\n\nMulti-perspective review of cost optimization findings with confidence-based filtering.\n\n## Quick Start\n\n```bash\n# Review findings (outputs to terminal)\n/reviewing-findings\n\n# Review and update findings.json\n/reviewing-findings --update\n```\n\n## Review Process\n\n### 1. Pre-flight Checks\n\nSkip review if:\n- No findings.json exists\n- Findings already reviewed (has `review_status`)\n- Empty findings array\n\n### 2. Multi-Agent Review (4 Parallel Agents)\n\nLaunch 4 independent review agents:\n\n```\nAgent #1: Resource Verification\n├── Verify resource still exists\n├── Check current utilization metrics\n└── Confirm finding is still valid\n\nAgent #2: Recommendation Quality\n├── Validate recommendation is actionable\n├── Check for edge cases (ASG, DR, scheduled)\n└── Verify savings calculation logic\n\nAgent #3: Business Context\n├── Identify environment (prod/dev/staging)\n├── Check for dependencies\n└── Flag potential risks\n\nAgent #4: Historical Pattern\n├── Check for burst patterns\n├── Identify seasonal usage\n└── Review recent changes\n```\n\n### 3. Confidence Scoring\n\nEach agent assigns confidence (0-100):\n\n| Score | Meaning |\n|-------|---------|\n| 90-100 | Definite savings - act immediately |\n| 70-89 | High confidence - safe to implement |\n| 50-69 | Medium confidence - needs validation |\n| 25-49 | Low confidence - likely false positive |\n| 0-24 | Skip - insufficient evidence |\n\n**Filter threshold: 50** (adjustable)\n\n### 4. Update Findings\n\nAdd review metadata to each finding:\n\n```json\n{\n  \"check_id\": \"EC2-001\",\n  \"monthly_savings\": 150.00,\n  \"review_status\": {\n    \"reviewed_at\": \"2026-01-19T15:00:00Z\",\n    \"final_confidence\": 85,\n    \"agents\": {\n      \"resource_verification\": 90,\n      \"recommendation_quality\": 80,\n      \"business_context\": 85,\n      \"historical_pattern\": 85\n    },\n    \"action\": \"recommended\",\n    \"notes\": \"Resource verified idle for 21 days\"\n  }\n}\n```\n\n## Review Criteria by Check Type\n\n### Idle Resources (EC2-001, RDS-001)\n\n**Verify:**\n- [ ] CPU/memory metrics for 14+ days\n- [ ] Network activity\n- [ ] Not part of ASG or scheduled scaling\n- [ ] Not a standby/DR instance\n\n**Red flags:**\n- Part of Auto Scaling Group → -30 confidence\n- Created < 14 days ago → -20 confidence\n- Has \"dr\" or \"standby\" in name → -25 confidence\n\n### Over-provisioned (EC2-002, RDS-002, LAMBDA-001)\n\n**Verify:**\n- [ ] Peak utilization is below threshold\n- [ ] No recent high-utilization spikes\n- [ ] Recommended size handles peak + buffer\n\n**Red flags:**\n- Peak CPU > 60% → -20 confidence\n- Burst workload pattern → -25 confidence\n- Memory not checked → -15 confidence\n\n### Unattached Storage (EC2-012, EBS-001)\n\n**Verify:**\n- [ ] Volume truly unattached (not just unmounted)\n- [ ] No recent attachment activity\n- [ ] Not a backup volume\n\n**Red flags:**\n- Detached < 7 days ago → -30 confidence\n- Has snapshot → lower urgency\n- Size > 500GB → verify with owner\n\n### Reserved Instance Coverage (RDS-005, EC2-RI-001)\n\n**Verify:**\n- [ ] Workload is steady (not variable)\n- [ ] Commitment period acceptable\n- [ ] Instance type likely to remain same\n\n**Red flags:**\n- Variable workload → -25 confidence\n- Pending migration → -40 confidence\n- Dev/test environment → -20 confidence\n\n## Agent Implementation\n\n### Agent #1: Resource Verification\n\n```\nPrompt: For each finding in findings.json, verify the resource:\n1. Call AWS API to check resource exists\n2. Get current utilization metrics (last 7 days)\n3. Compare current state vs finding state\n4. Score confidence based on verification\n\nOutput JSON with:\n- resource_verified: boolean\n- current_metrics: object\n- confidence: 0-100\n- notes: string\n```\n\n### Agent #2: Recommendation Quality\n\n```\nPrompt: For each finding, evaluate the recommendation:\n1. Is the recommendation actionable?\n2. Are there edge cases not considered?\n3. Is the savings calculation reasonable?\n4. Are there dependencies to consider?\n\nScore based on:\n- Clear next steps: +20\n- Edge cases addressed: +15\n- Accurate savings: +25\n- No dependencies: +20\n- Reasonable effort: +20\n```\n\n### Agent #3: Business Context\n\n```\nPrompt: For each finding, assess business context:\n1. Identify environment (check name, tags)\n2. Check for production dependencies\n3. Assess risk of implementing recommendation\n4. Consider compliance requirements\n\nAdjust confidence:\n- Production resource: -10 (needs careful review)\n- Has dependencies: -20\n- Compliance-related: -15\n- Dev/test: +10 (lower risk)\n```\n\n### Agent #4: Historical Pattern\n\n```\nPrompt: For each finding, analyze patterns:\n1. Check CloudWatch metrics for patterns\n2. Identify burst/scheduled workloads\n3. Review resource modification history\n4. Check for seasonal patterns\n\nRed flags:\n- Burst pattern detected: -25\n- Recent scaling event: -20\n- Seasonal variation: -15\n- Consistent low usage: +15\n```\n\n## Output Format\n\n### Terminal Output\n\n```\n## Findings Review\n\nReviewed 35 findings. Results:\n\n✓ 25 findings APPROVED (confidence ≥70)\n⚠ 6 findings NEEDS VALIDATION (confidence 50-69)\n✗ 4 findings FILTERED (confidence <50)\n\n### Top Approved Findings\n\n1. **RDS-002**: Over-provisioned RDS Instance\n   Resource: production-clinical-trial-matcher\n   Savings: $95.00/month\n   Confidence: 85%\n   Notes: CPU avg 2.6% for 31 days, no burst patterns\n\n2. **EC2-012**: Unattached EBS Volume\n   Resource: vol-0f282561946f02d6a\n   Savings: $8.00/month\n   Confidence: 92%\n   Notes: Unattached for 45 days, has snapshot backup\n\n### Needs Validation\n\n1. **LAMBDA-001**: Memory Over-provisioning\n   Resource: production-file-handler\n   Confidence: 55%\n   Issue: Only 78 invocations - insufficient data\n   Action: Monitor for 14 more days\n\n### Filtered (False Positives)\n\n1. **EC2-001**: Idle EC2 Instance\n   Resource: i-0885726ca0d3e7856\n   Original confidence: 75%\n   Final confidence: 35%\n   Reason: Part of ASG, scheduled scaling detected\n```\n\n### Updated findings.json\n\nEach finding gets a `review_status` object added.\n\n## Workflow\n\n1. Read `findings.json`\n2. Launch 4 parallel review agents (use Task tool)\n3. Collect agent results\n4. Calculate final confidence (average of 4 agents)\n5. Apply filter threshold (50)\n6. Update findings with review status\n7. Generate summary report\n8. Save updated `findings.json`\n\n## Task Checklist\n\n```\n- [ ] Load findings.json\n- [ ] Launch Agent #1: Resource Verification\n- [ ] Launch Agent #2: Recommendation Quality\n- [ ] Launch Agent #3: Business Context\n- [ ] Launch Agent #4: Historical Pattern\n- [ ] Merge agent results\n- [ ] Calculate final confidence scores\n- [ ] Apply filter threshold\n- [ ] Update findings with review_status\n- [ ] Save updated findings.json\n- [ ] Output summary to terminal\n```\n",
        "plugins/aws-cost-scanner/skills/validating-aws-pricing/PRICING_REFERENCE.md": "# AWS Pricing API Reference\n\nComplete reference for querying AWS pricing data.\n\n---\n\n## CRITICAL: Common Pricing Mistakes\n\n**READ THIS FIRST** to avoid incorrect savings estimates.\n\n### Mistake 1: CloudWatch Logs - Wrong Price Component\n\n| Component | Price | When Charged | Affected by Retention? |\n|-----------|-------|--------------|------------------------|\n| **Ingestion** | $0.50/GB | Once, when logs arrive | NO |\n| **Storage** | $0.03/GB-month | Monthly, for stored data | YES |\n\n**WRONG:** `savings = stored_gb × $0.50` (uses ingestion price)\n**CORRECT:** `savings = stored_gb × $0.03` (uses storage price)\n\n### Mistake 2: Savings Exceed Service Spend\n\n**ALWAYS verify:** `finding.monthly_savings <= service.monthly_spend`\n\nIf CloudWatch costs $159/mo total, you CANNOT save $594/mo on it.\n\n### Mistake 3: Not Checking Usage Type Breakdown\n\nFor findings > $100, query Cost Explorer with `USAGE_TYPE` grouping:\n```bash\naws ce get-cost-and-usage \\\n  --filter '{\"Dimensions\": {\"Key\": \"SERVICE\", \"Values\": [\"AmazonCloudWatch\"]}}' \\\n  --group-by Type=DIMENSION,Key=USAGE_TYPE\n```\n\nThis shows actual storage vs ingestion costs.\n\n### Mistake 4: Using Multipliers Without Understanding\n\nNever use arbitrary multipliers. Always trace back to the formula:\n\n| Finding Type | Formula |\n|--------------|---------|\n| CW Logs Retention | `stored_gb × $0.03` |\n| EBS Volume | `size_gb × price_per_gb` |\n| EC2 Instance | `hourly_rate × 730` |\n| RDS Downsize | `(current_hourly - new_hourly) × 730` |\n\n---\n\n## API Basics\n\n### Endpoint Regions\n\nThe AWS Pricing API is only available in two regions:\n- `us-east-1` (N. Virginia)\n- `ap-south-1` (Mumbai)\n\nAlways use `--region us-east-1` for pricing queries.\n\n### Location Values\n\nMap AWS regions to pricing location names:\n\n| Region Code | Location Name |\n|-------------|---------------|\n| us-east-1 | US East (N. Virginia) |\n| us-east-2 | US East (Ohio) |\n| us-west-1 | US West (N. California) |\n| us-west-2 | US West (Oregon) |\n| eu-west-1 | EU (Ireland) |\n| eu-central-1 | EU (Frankfurt) |\n| ap-southeast-1 | Asia Pacific (Singapore) |\n| ap-northeast-1 | Asia Pacific (Tokyo) |\n\n## Service Codes\n\n| Service | Service Code |\n|---------|--------------|\n| EC2 | AmazonEC2 |\n| RDS | AmazonRDS |\n| ElastiCache | AmazonElastiCache |\n| Lambda | AWSLambda |\n| S3 | AmazonS3 |\n| CloudWatch | AmazonCloudWatch |\n| DynamoDB | AmazonDynamoDB |\n| EFS | AmazonEFS |\n\n## EC2 Pricing Queries\n\n### Instance Pricing\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonEC2 \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=instanceType,Value=t2.nano\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    \"Type=TERM_MATCH,Field=operatingSystem,Value=Linux\" \\\n    \"Type=TERM_MATCH,Field=tenancy,Value=Shared\" \\\n    \"Type=TERM_MATCH,Field=preInstalledSw,Value=NA\" \\\n    \"Type=TERM_MATCH,Field=capacitystatus,Value=Used\" \\\n  --max-results 1\n```\n\n**Filter Fields:**\n- `instanceType`: e.g., t2.nano, m5.large, r5.xlarge\n- `operatingSystem`: Linux, Windows, RHEL, SUSE\n- `tenancy`: Shared, Dedicated, Host\n- `preInstalledSw`: NA, SQL Std, SQL Web, SQL Ent\n- `capacitystatus`: Used, UnusedCapacityReservation\n\n### EBS Volume Pricing\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonEC2 \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=volumeApiName,Value=gp3\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n  --max-results 5\n```\n\n**Volume Types:**\n- `gp3`: General Purpose SSD (latest)\n- `gp2`: General Purpose SSD (previous gen)\n- `io2`: Provisioned IOPS SSD\n- `io1`: Provisioned IOPS SSD (previous gen)\n- `st1`: Throughput Optimized HDD\n- `sc1`: Cold HDD\n- `standard`: Magnetic\n\n**gp3 Pricing Components:**\n- Storage: $0.08 per GB-month\n- IOPS: $0.005 per IOPS-month (above 3000 baseline)\n- Throughput: $0.04 per MB/s-month (above 125 MB/s baseline)\n\n### EBS Snapshot Pricing\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonEC2 \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=productFamily,Value=Storage Snapshot\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n  --max-results 1\n```\n\n## RDS Pricing Queries\n\n### Instance Pricing\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonRDS \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=instanceType,Value=db.r5.xlarge\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    \"Type=TERM_MATCH,Field=databaseEngine,Value=PostgreSQL\" \\\n    \"Type=TERM_MATCH,Field=deploymentOption,Value=Single-AZ\" \\\n  --max-results 1\n```\n\n**Database Engines:**\n- PostgreSQL\n- MySQL\n- MariaDB\n- Oracle\n- SQL Server\n- Aurora MySQL\n- Aurora PostgreSQL\n\n**Deployment Options:**\n- Single-AZ\n- Multi-AZ\n\n### RDS Storage Pricing\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonRDS \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=productFamily,Value=Database Storage\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    \"Type=TERM_MATCH,Field=volumeType,Value=General Purpose (SSD)\" \\\n  --max-results 1\n```\n\n## ElastiCache Pricing Queries\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonElastiCache \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=instanceType,Value=cache.t3.small\" \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    \"Type=TERM_MATCH,Field=cacheEngine,Value=Redis\" \\\n  --max-results 1\n```\n\n**Cache Engines:**\n- Redis\n- Memcached\n- Valkey\n\n## Lambda Pricing Queries\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AWSLambda \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n  --max-results 10\n```\n\n**Lambda Pricing Model:**\n- Requests: $0.20 per 1M requests\n- Duration: $0.0000166667 per GB-second (x86)\n- Duration: $0.0000133334 per GB-second (ARM64) - 20% cheaper\n\n**Calculate Lambda Cost:**\n```python\ndef calculate_lambda_cost(memory_mb, duration_ms, invocations, architecture='x86'):\n    gb_seconds = (memory_mb / 1024) * (duration_ms / 1000) * invocations\n\n    if architecture == 'arm64':\n        duration_cost = gb_seconds * 0.0000133334\n    else:\n        duration_cost = gb_seconds * 0.0000166667\n\n    request_cost = (invocations / 1_000_000) * 0.20\n    return duration_cost + request_cost\n```\n\n## CloudWatch Pricing Queries\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonCloudWatch \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n  --max-results 20\n```\n\n**CloudWatch Logs Pricing:**\n- Ingestion: $0.50 per GB (first 10TB)\n- Storage: $0.03 per GB-month\n- Insights queries: $0.005 per GB scanned\n\n## S3 Pricing Queries\n\n```bash\naws pricing get-products --region us-east-1 \\\n  --service-code AmazonS3 \\\n  --filters \\\n    \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    \"Type=TERM_MATCH,Field=storageClass,Value=General Purpose\" \\\n  --max-results 5\n```\n\n**Storage Classes:**\n- General Purpose (Standard)\n- Infrequent Access\n- One Zone-IA\n- Glacier Instant Retrieval\n- Glacier Flexible Retrieval\n- Glacier Deep Archive\n- Intelligent-Tiering\n\n## Parsing Pricing Responses\n\n### Response Structure\n\n```json\n{\n  \"PriceList\": [\n    \"{\\\"product\\\":{...},\\\"terms\\\":{\\\"OnDemand\\\":{...},\\\"Reserved\\\":{...}}}\"\n  ],\n  \"FormatVersion\": \"aws_v1\"\n}\n```\n\n### Extract On-Demand Price\n\n```python\nimport json\n\ndef parse_pricing_response(response_json):\n    \"\"\"Parse AWS Pricing API response and extract On-Demand price.\"\"\"\n    data = json.loads(response_json)\n    price_list = data.get('PriceList', [])\n\n    if not price_list:\n        return None\n\n    # Parse the nested JSON string\n    product_data = json.loads(price_list[0])\n\n    # Navigate to On-Demand pricing\n    on_demand = product_data.get('terms', {}).get('OnDemand', {})\n\n    for sku_term in on_demand.values():\n        price_dimensions = sku_term.get('priceDimensions', {})\n        for dimension in price_dimensions.values():\n            price_per_unit = dimension.get('pricePerUnit', {})\n            usd_price = price_per_unit.get('USD')\n            if usd_price:\n                return {\n                    'price': float(usd_price),\n                    'unit': dimension.get('unit'),\n                    'description': dimension.get('description')\n                }\n\n    return None\n```\n\n### Extract Reserved Instance Price\n\n```python\ndef parse_reserved_pricing(response_json, term_length='1yr', purchase_option='All Upfront'):\n    \"\"\"Extract Reserved Instance pricing for comparison.\"\"\"\n    data = json.loads(response_json)\n    price_list = data.get('PriceList', [])\n\n    if not price_list:\n        return None\n\n    product_data = json.loads(price_list[0])\n    reserved = product_data.get('terms', {}).get('Reserved', {})\n\n    for sku_term in reserved.values():\n        attrs = sku_term.get('termAttributes', {})\n        if (attrs.get('LeaseContractLength') == term_length and\n            attrs.get('PurchaseOption') == purchase_option):\n\n            upfront = 0\n            hourly = 0\n\n            for dim in sku_term.get('priceDimensions', {}).values():\n                if 'Upfront' in dim.get('description', ''):\n                    upfront = float(dim['pricePerUnit'].get('USD', 0))\n                else:\n                    hourly = float(dim['pricePerUnit'].get('USD', 0))\n\n            return {\n                'upfront': upfront,\n                'hourly': hourly,\n                'term': term_length,\n                'option': purchase_option\n            }\n\n    return None\n```\n\n## Cost Calculation Formulas\n\n### Monthly Hours\n\n```python\nHOURS_PER_MONTH = 730  # 365 days * 24 hours / 12 months\n```\n\n### EC2 Monthly Cost\n\n```python\ndef ec2_monthly_cost(hourly_rate):\n    return hourly_rate * 730\n```\n\n### EBS Monthly Cost\n\n```python\ndef ebs_monthly_cost(size_gb, volume_type='gp3', iops=3000, throughput=125):\n    if volume_type == 'gp3':\n        storage_cost = size_gb * 0.08\n        iops_cost = max(0, iops - 3000) * 0.005\n        throughput_cost = max(0, throughput - 125) * 0.04\n        return storage_cost + iops_cost + throughput_cost\n    elif volume_type == 'gp2':\n        return size_gb * 0.10\n    # Add other volume types as needed\n```\n\n### RDS Monthly Cost\n\n```python\ndef rds_monthly_cost(hourly_rate, storage_gb, multi_az=False):\n    compute_cost = hourly_rate * 730\n    storage_cost = storage_gb * 0.115  # gp2 storage\n    if multi_az:\n        compute_cost *= 2\n        storage_cost *= 2\n    return compute_cost + storage_cost\n```\n\n### Reserved Instance Savings\n\n```python\ndef ri_savings(on_demand_hourly, ri_upfront, ri_hourly, term_years=1):\n    \"\"\"Calculate monthly savings with Reserved Instance.\"\"\"\n    on_demand_monthly = on_demand_hourly * 730\n    ri_monthly = (ri_upfront / (term_years * 12)) + (ri_hourly * 730)\n    savings = on_demand_monthly - ri_monthly\n    savings_percent = (savings / on_demand_monthly) * 100\n    return {\n        'monthly_savings': savings,\n        'savings_percent': savings_percent\n    }\n```\n\n## Common Pricing (us-east-1, 2026)\n\n### EC2 Instances\n\n| Instance Type | Hourly | Monthly |\n|---------------|--------|---------|\n| t2.nano | $0.0058 | $4.23 |\n| t2.micro | $0.0116 | $8.47 |\n| t3.nano | $0.0052 | $3.80 |\n| t3.micro | $0.0104 | $7.59 |\n| t3.small | $0.0208 | $15.18 |\n| m5.large | $0.096 | $70.08 |\n| m5.xlarge | $0.192 | $140.16 |\n| r5.large | $0.126 | $91.98 |\n| r5.xlarge | $0.252 | $183.96 |\n\n### RDS Instances (PostgreSQL, Single-AZ)\n\n| Instance Type | Hourly | Monthly |\n|---------------|--------|---------|\n| db.t3.micro | $0.017 | $12.41 |\n| db.t3.small | $0.034 | $24.82 |\n| db.t3.medium | $0.068 | $49.64 |\n| db.r5.large | $0.25 | $182.50 |\n| db.r5.xlarge | $0.50 | $365.00 |\n| db.r5.2xlarge | $1.00 | $730.00 |\n\n### ElastiCache (Redis)\n\n| Node Type | Hourly | Monthly |\n|-----------|--------|---------|\n| cache.t3.micro | $0.017 | $12.41 |\n| cache.t3.small | $0.034 | $24.82 |\n| cache.t3.medium | $0.068 | $49.64 |\n| cache.r5.large | $0.182 | $132.86 |\n\n### Storage\n\n| Type | Price | Unit |\n|------|-------|------|\n| EBS gp3 | $0.08 | GB-month |\n| EBS gp2 | $0.10 | GB-month |\n| EBS io2 | $0.125 | GB-month |\n| S3 Standard | $0.023 | GB-month (first 50TB) |\n| S3 IA | $0.0125 | GB-month |\n| EFS | $0.30 | GB-month |\n| CloudWatch Logs | $0.03 | GB-month |\n",
        "plugins/aws-cost-scanner/skills/validating-aws-pricing/validating-aws-pricing.md": "---\nname: validating-aws-pricing\ndescription: MANDATORY validation of AWS cost findings. Cross-checks savings estimates against actual billing data and correct pricing formulas. Catches errors like confusing storage vs ingestion costs. Run BEFORE generating any report.\nallowed-tools:\n  - Read\n  - Write\n  - Bash\n  - Grep\n  - mcp__awslabs-aws-api__call_aws\n---\n\n# Validating AWS Pricing\n\n**MANDATORY** validation step that catches pricing errors before they reach the user.\n\n## Why This Matters\n\nCommon errors this skill catches:\n- CloudWatch Logs: Confusing $0.50/GB ingestion with $0.03/GB storage\n- Savings exceeding actual service spend (impossible)\n- Wrong multipliers or formulas\n- Missing cost components\n\n## Purpose\n\nThis skill validates pricing for significant findings using live AWS Pricing API. Smaller findings use fallback estimates to avoid unnecessary API calls.\n\n## Quick Start\n\n```bash\n# Validate with default $100 threshold (queries API only for >$100 findings)\npython skills/validating-aws-pricing/scripts/validate_pricing.py findings.json --profile ctm\n\n# Lower threshold to validate more findings\npython skills/validating-aws-pricing/scripts/validate_pricing.py findings.json --profile ctm --threshold 50\n\n# Works with any AWS auth method (SSO, access keys, IAM role)\npython skills/validating-aws-pricing/scripts/validate_pricing.py findings.json  # uses default credentials\n```\n\n## What Gets Updated\n\nFor findings **above threshold** (default $100):\n1. Queries real AWS Pricing API for EC2, RDS, EBS\n2. Updates `monthly_savings` with validated value\n3. Marks `api_validated: true` in metadata\n\nFor findings **below threshold**:\n1. Uses fallback estimates (fast, no API calls)\n2. Marks `api_validated: false` in metadata\n\nAll findings get `pricing_validated` metadata showing the source.\n\n## Pricing Calculation by Finding Type\n\n### Idle Resources (EC2-001, etc.)\nSavings = Full monthly cost of the resource\n```python\nsavings = hourly_rate * 730  # Resource should be terminated\n```\n\n### Unattached Storage (EC2-012, EBS-001)\nSavings = Storage cost per month\n```python\nsavings = size_gb * price_per_gb  # e.g., 100GB * $0.08 = $8.00\n```\n\n### Over-provisioned (RDS-002, LAMBDA-001)\nSavings = Difference between current and recommended size\n```python\ncurrent_cost = current_hourly * 730\nrecommended_cost = recommended_hourly * 730\nsavings = current_cost - recommended_cost\n```\n\n### No RI Coverage (RDS-005)\nSavings = On-Demand cost - Reserved Instance cost\n```python\non_demand_monthly = hourly_rate * 730\nri_monthly = ri_upfront / 12 + ri_hourly * 730\nsavings = on_demand_monthly - ri_monthly  # ~40-60% typically\n```\n\n### CloudWatch Logs (SEC-001)\nSavings = Storage cost that can be avoided with retention policy\n```python\nsavings = stored_gb * 0.03  # $0.03 per GB-month\n```\n\n## AWS Pricing Reference\n\nCurrent pricing (us-east-1):\n\n| Resource | Price | Unit | Monthly (730 hrs) |\n|----------|-------|------|-------------------|\n| t2.nano | $0.0058 | /hour | $4.23 |\n| t3.nano | $0.0052 | /hour | $3.80 |\n| gp3 storage | $0.08 | /GB-month | - |\n| db.r5.xlarge | $0.50 | /hour | $365.00 |\n| cache.t3.small (Valkey) | $0.0272 | /hour | $19.86 |\n| CloudWatch Logs | $0.03 | /GB-month | - |\n\nFor complete pricing, see [PRICING_REFERENCE.md](PRICING_REFERENCE.md).\n\n## Output\n\nThe script updates `findings.json` in place:\n\n```json\n{\n  \"check_id\": \"EC2-001\",\n  \"monthly_savings\": 4.23,\n  \"pricing_validated\": {\n    \"source\": \"AWS Pricing API\",\n    \"validated_at\": \"2026-01-19T10:00:00Z\",\n    \"hourly_rate\": 0.0058,\n    \"calculation\": \"0.0058 * 730 hours\"\n  }\n}\n```\n\n## Workflow\n\n1. Load `findings.json`\n2. For each finding:\n   - Identify resource type from `check_id` and `details`\n   - Query AWS Pricing API (or use cached known prices)\n   - Calculate correct savings based on finding category\n   - Update `monthly_savings` field\n   - Add `pricing_validated` metadata\n3. Recalculate `total_monthly_savings` in metadata\n4. Save updated `findings.json`\n\n## Task Checklist\n\n```\n- [ ] Load findings.json\n- [ ] Get actual billing from Cost Explorer (by service AND usage type)\n- [ ] For EACH finding:\n  - [ ] Verify formula matches finding type\n  - [ ] Check savings <= service spend (sanity check)\n  - [ ] Query AWS Pricing API if > $100\n  - [ ] Recalculate if errors found\n  - [ ] Add calculation breakdown to details\n- [ ] Flag any corrected findings with pricing_corrected: true\n- [ ] Recalculate total savings in metadata\n- [ ] Save corrected findings.json\n- [ ] Regenerate report with accurate prices\n```\n\n---\n\n## CRITICAL: Sanity Check Rules\n\n### Rule 1: Savings Cannot Exceed Service Spend\n\n```python\nassert finding.monthly_savings <= service_monthly_spend, \\\n    f\"Finding {finding.check_id} claims ${finding.monthly_savings} but service only costs ${service_monthly_spend}\"\n```\n\n**Example Failure:**\n- Finding: CloudWatch Logs retention saves $594/mo\n- Billing: CloudWatch total spend = $159/mo\n- **INVALID** - immediately flag and recalculate\n\n### Rule 2: Use Correct Cost Component\n\nMany AWS services have MULTIPLE cost components:\n\n| Service | Components | What Retention Affects |\n|---------|------------|------------------------|\n| **CloudWatch Logs** | Ingestion ($0.50/GB) + Storage ($0.03/GB) | Storage ONLY |\n| **S3** | Storage + Requests + Transfer | Storage + old versions |\n| **EBS** | Storage + IOPS + Throughput | Storage ONLY |\n| **RDS** | Compute + Storage + I/O | Depends on finding |\n\n### Rule 3: Verify With Usage Type Breakdown\n\nFor any finding > $100, get usage-type breakdown:\n\n```bash\naws ce get-cost-and-usage --profile {profile} \\\n  --time-period Start=2025-12-01,End=2026-01-01 \\\n  --granularity MONTHLY \\\n  --metrics UnblendedCost \\\n  --filter '{\"Dimensions\": {\"Key\": \"SERVICE\", \"Values\": [\"AmazonCloudWatch\"]}}' \\\n  --group-by Type=DIMENSION,Key=USAGE_TYPE\n```\n\nThis shows:\n- `DataProcessing-Bytes`: Log ingestion ($0.50/GB)\n- `TimedStorage-ByteHrs`: Log storage ($0.03/GB)\n\n**Only storage can be reduced by retention policy!**\n\n---\n\n## Common Pricing Mistakes & Corrections\n\n### CloudWatch Logs Retention\n\n**WRONG:**\n```python\nsavings = stored_gb * 0.50  # Using ingestion price!\n# 221 GB * $0.50 = $110.50  # WRONG!\n```\n\n**CORRECT:**\n```python\nsavings = stored_gb * 0.03  # Storage price\n# 221 GB * $0.03 = $6.63    # CORRECT!\n```\n\n**Even more correct (check what % is older than retention):**\n```python\n# If setting 90-day retention, only logs older than 90 days are deleted\n# Estimate 50% of stored data is older than 90 days\nsavings = stored_gb * 0.03 * 0.5\n```\n\n### Unattached EBS Volume\n\n**CORRECT:**\n```python\nsavings = size_gb * price_per_gb\n# gp3: 100 GB * $0.08 = $8.00\n# gp2: 100 GB * $0.10 = $10.00\n```\n\n### Over-provisioned RDS\n\n**CORRECT:**\n```python\ncurrent_cost = current_hourly * 730\nrecommended_cost = recommended_hourly * 730\nsavings = current_cost - recommended_cost\n\n# db.r5.xlarge -> db.r5.large\n# $0.50 * 730 - $0.25 * 730 = $365 - $182.50 = $182.50\n```\n\n---\n\n## Validation Output Format\n\nAfter validation, each finding should include:\n\n```json\n{\n  \"check_id\": \"LOG-001\",\n  \"monthly_savings\": 6.64,\n  \"pricing_validated\": {\n    \"validated_at\": \"2026-01-19T12:00:00Z\",\n    \"original_estimate\": 594.34,\n    \"corrected\": true,\n    \"correction_reason\": \"Used storage price ($0.03/GB) instead of ingestion price ($0.50/GB)\",\n    \"calculation\": \"221.4 GB × $0.03/GB = $6.64\",\n    \"sanity_check\": {\n      \"service\": \"AmazonCloudWatch\",\n      \"service_spend\": 159.13,\n      \"finding_savings\": 6.64,\n      \"passed\": true\n    }\n  }\n}\n```\n"
      },
      "plugins": [
        {
          "name": "aws-cost-scanner",
          "description": "97 automated AWS cost optimization checks across 6 domains with parallel scanning and confidence-based filtering",
          "version": "1.0.0",
          "author": {
            "name": "Mehul Prajapati"
          },
          "source": "./plugins/aws-cost-scanner",
          "category": "infrastructure",
          "tags": [
            "aws",
            "cost-optimization",
            "cloud",
            "finops"
          ],
          "keywords": [
            "aws",
            "cost",
            "optimization",
            "cloud",
            "finops",
            "savings"
          ],
          "categories": [
            "aws",
            "cloud",
            "cost",
            "cost-optimization",
            "finops",
            "infrastructure",
            "optimization",
            "savings"
          ],
          "install_commands": [
            "/plugin marketplace add prajapatimehul/aws-cost-scanner",
            "/plugin install aws-cost-scanner@aws-cost-scanner-marketplace"
          ]
        }
      ]
    }
  ]
}