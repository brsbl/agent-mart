{
  "author": {
    "id": "dnvriend",
    "display_name": "Dennis Vriend",
    "avatar_url": "https://avatars.githubusercontent.com/u/4494623?u=e818279b41fd2175b7e52829dd96677a1f7f18a7&v=4"
  },
  "marketplaces": [
    {
      "name": "obsidian-search-tool",
      "version": null,
      "description": "Search Obsidian vault via Dataview and JsonLogic",
      "repo_full_name": "dnvriend/obsidian-search-tool",
      "repo_url": "https://github.com/dnvriend/obsidian-search-tool",
      "repo_description": "CLI tool for searching Obsidian vaults through the Local REST API using Dataview DQL and JsonLogic queries",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-15T08:32:46Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"obsidian-search-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/obsidian-search-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"obsidian-search-tool\",\n            \"source\": \"./plugins/obsidian-search-tool\",\n            \"description\": \"Search Obsidian vault via Dataview and JsonLogic\"\n        }\n    ]\n}\n",
        "README.md": "<div align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"Obsidian Search Tool Logo\" width=\"200\"/>\n</div>\n\n# Obsidian Search Tool\n\n[![CI](https://github.com/dnvriend/obsidian-search-tool/actions/workflows/ci.yml/badge.svg)](https://github.com/dnvriend/obsidian-search-tool/actions/workflows/ci.yml)\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA CLI tool that searches an Obsidian vault through the Obsidian Local REST API using Dataview Query Language (DQL) - TABLE queries only - and JsonLogic queries.\n\n## Table of Contents\n\n- [About](#about)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Library Usage](#library-usage)\n- [API Limitations and Known Issues](#api-limitations-and-known-issues)\n- [Development](#development)\n- [Resources](#resources)\n- [License](#license)\n\n## About\n\n### What is Obsidian Search Tool?\n\n`obsidian-search-tool` is a command-line interface for searching through [Obsidian](https://obsidian.md/) vaults using the [Obsidian Local REST API](https://github.com/coddingtonbear/obsidian-local-rest-api) plugin. It provides **search-only** operations using:\n\n- **Dataview DQL**: TABLE queries with powerful filtering, sorting, and grouping\n- **JsonLogic**: JSON-based programmatic queries for tags, frontmatter, and content\n\n### Why This CLI Tool?\n\n**Agent-Friendly Design** - Built specifically for integration with AI agents (Claude Code), automation pipelines, and reusable building blocks:\n- **ReAct Loops**: Structured commands and error messages enable AI agents to reason and act effectively\n- **Composable Architecture**: JSON stdout and logs stderr allow easy piping and integration\n- **Reusable Building Blocks**: Commands serve as primitives for Claude Code skills, MCP servers, or custom workflows\n- **Dual-Mode Operation**: Use as CLI or importable Python library\n- **Production Quality**: Type-safe, tested, with comprehensive error handling\n\n## Use Cases\n\n- üìö **Knowledge Base Management** - Search and organize notes by tags, topics, or metadata\n- üíª **Source Code Intelligence** - Query code snippets and technical documentation\n- üîç **Semantic Search** - Find notes by content, frontmatter fields, or relationships\n- üéØ **RAG Applications** - Retrieve context for AI-powered applications\n- ü§ñ **Agent Integration** - Build Claude Code skills and MCP servers for vault access\n\n## Features\n\n- **Search Operations**:\n  - Dataview DQL TABLE queries (FROM, WHERE, SORT, LIMIT)\n  - JsonLogic queries for programmatic access (content search with \"in\" operator)\n  - Tag search, frontmatter field search, content search, file path search\n  - Access to implicit fields (file.name, file.mtime, file.size, file.tags, etc.)\n  - **Note**: GROUP BY, FLATTEN not supported by Obsidian Local REST API\n\n- **Multiple Output Formats**:\n  - JSON (default) - Machine-readable for automation\n  - Markdown text - Human-readable with metadata\n  - Pretty-printed tables - Visual inspection of structured data\n\n- **CLI-First Design**:\n  - Flat command structure for simplicity\n  - Stdin support for piping queries\n  - Rich error messages with solutions\n  - Comprehensive help with examples\n\n- **Production Quality**:\n  - Type-safe with strict mypy\n  - Tested with pytest\n  - Linted with ruff\n  - Comprehensive error handling\n  - Environment-based configuration\n\n## Prerequisites\n\n### Required\n\n1. **Obsidian** must be running\n2. **[Local REST API](https://github.com/coddingtonbear/obsidian-local-rest-api)** plugin by Adam Coddington installed and enabled\n3. **[Dataview](https://github.com/blacksmithgu/obsidian-dataview)** plugin by Michael Brenan installed and enabled\n4. **OBSIDIAN_API_KEY** environment variable set with API key from plugin settings\n5. Python 3.14+ and [uv](https://github.com/astral-sh/uv) package manager\n\n## Installation\n\n### From Source\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/obsidian-search-tool.git\ncd obsidian-search-tool\n\n# Install globally with uv\nuv tool install .\n\n# Verify installation\nobsidian-search-tool --version\n```\n\n### With mise (Recommended for Development)\n\n```bash\ncd obsidian-search-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n## Configuration\n\n### Get API Key\n\n1. Open Obsidian\n2. Go to Settings ‚Üí Community Plugins\n3. Find \"Local REST API\" plugin\n4. Click plugin settings\n5. Copy the API key from the settings page\n\n### Set Environment Variables\n\n```bash\n# Required: API key from plugin settings\nexport OBSIDIAN_API_KEY=\"your-api-key-here\"\n\n# Optional: API base URL (default: http://127.0.0.1:27123)\nexport OBSIDIAN_BASE_URL=\"http://127.0.0.1:27123\"\n\n# Optional: Request timeout in seconds (default: 30)\nexport OBSIDIAN_TIMEOUT=\"30\"\n\n# Optional: Enable verbose logging (default: false)\nexport OBSIDIAN_VERBOSE=\"false\"\n```\n\n## Usage\n\n### Quick Start\n\n```bash\n# Set API key\nexport OBSIDIAN_API_KEY=\"your-api-key-here\"\n\n# Check connectivity\nobsidian-search-tool status\n\n# Validate authentication\nobsidian-search-tool auth\n\n# Search with Dataview DQL (default)\nobsidian-search-tool search 'TABLE file.name FROM #project'\n\n# Search with JsonLogic\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"in\": [{\"var\": \"frontmatter.tags\"}, \"project\"]}'\n```\n\n### Status and Authentication\n\n```bash\n# Check API connectivity\nobsidian-search-tool status\n\n# Check with text output\nobsidian-search-tool status --text\n\n# Validate authentication\nobsidian-search-tool auth\n\n# Verbose logging\nobsidian-search-tool auth --verbose\n```\n\n### Dataview DQL Search\n\n```bash\n# Basic TABLE query\nobsidian-search-tool search 'TABLE file.name FROM #project'\n\n# With WHERE clause and sorting\nobsidian-search-tool search \\\\\n    'TABLE file.name, author WHERE author SORT file.mtime DESC'\n\n# Recent notes (modified in last 7 days)\nobsidian-search-tool search \\\\\n    'TABLE file.name, file.mtime WHERE file.mtime >= date(today) - dur(7 days) SORT file.mtime DESC'\n\n# Notes with specific field using contains()\nobsidian-search-tool search \\\\\n    'TABLE file.name, author WHERE contains(author, \"Ben\") LIMIT 5'\n\n# Files in specific folder\nobsidian-search-tool search \\\\\n    'TABLE file.name, file.folder WHERE contains(file.folder, \"ai-ml\") LIMIT 5'\n\n# Large files sorted by size\nobsidian-search-tool search \\\\\n    'TABLE file.name, file.size WHERE file.size > 10000 SORT file.size DESC'\n\n# Complex query with multiple conditions\nobsidian-search-tool search \\\\\n    'TABLE file.name, file.mtime FROM \"reference\" WHERE file.size > 5000 AND contains(file.tags, \"#docs\") SORT file.mtime DESC LIMIT 10'\n\n# From stdin\necho 'TABLE file.name FROM #meeting' | obsidian-search-tool search --stdin\n\n# Text output\nobsidian-search-tool search 'TABLE file.name' --text\n\n# Table output (best for structured data)\nobsidian-search-tool search 'TABLE file.name, status, file.mtime' --table\n```\n\n### JsonLogic Search\n\n```bash\n# Content search\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"in\": [\"Claude\", {\"var\": \"content\"}]}'\n\n# File path contains string\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"in\": [\"daily\", {\"var\": \"filename\"}]}'\n\n# Search by tag\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"in\": [{\"var\": \"frontmatter.tags\"}, \"project\"]}'\n\n# Multiple tags (AND)\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"and\": [{\"in\": [{\"var\": \"frontmatter.tags\"}, \"project\"]}, \\\\\n              {\"in\": [{\"var\": \"frontmatter.tags\"}, \"aws\"]}]}'\n\n# Has frontmatter field\nobsidian-search-tool search --type jsonlogic \\\\\n    '{\"exists\": {\"var\": \"frontmatter.status\"}}'\n```\n\n### Output Formats\n\n```bash\n# JSON output (default)\nobsidian-search-tool search 'TABLE file.name'\n\n# Markdown text output\nobsidian-search-tool search 'TABLE file.name' --text\n\n# Pretty-printed table output\nobsidian-search-tool search 'TABLE file.name, author' --table\n```\n\n## Library Usage\n\nUse as a Python library for programmatic access:\n\n```python\nfrom obsidian_search_tool import ObsidianClient\n\n# Create client (reads environment variables)\nclient = ObsidianClient()\n\n# Or with explicit configuration\nclient = ObsidianClient(\n    base_url=\"http://127.0.0.1:27123\",\n    api_key=\"your-api-key\",\n    timeout=30\n)\n\n# Check status\nstatus = client.status()\nprint(f\"Connected: {status.status}\")\n\n# Validate authentication\nauth = client.check_auth()\nprint(f\"Authenticated: {auth.status}\")\n\n# Dataview DQL search\nresponse = client.search_dataview('TABLE file.name FROM #project')\nif response.success:\n    print(f\"Found {response.result_count} results\")\n    for result in response.results:\n        print(result)\n\n# JsonLogic search\nresponse = client.search_jsonlogic('{\"in\": [{\"var\": \"frontmatter.tags\"}, \"aws\"]}')\nif response.success:\n    print(f\"Results: {response.results}\")\n```\n\n### Error Handling\n\n```python\nfrom obsidian_search_tool import (\n    ObsidianClient,\n    ObsidianAuthError,\n    ObsidianConnectionError,\n    ObsidianAPIError,\n)\n\ntry:\n    client = ObsidianClient()\n    response = client.search_dataview('TABLE file.name')\nexcept ObsidianAuthError as e:\n    print(f\"Authentication failed: {e}\")\nexcept ObsidianConnectionError as e:\n    print(f\"Connection error: {e}\")\nexcept ObsidianAPIError as e:\n    print(f\"API error [{e.status_code}]: {e}\")\n```\n\n## API Limitations and Known Issues\n\nThis section documents tested functionality and known limitations of the Obsidian Local REST API.\n\n### ‚úÖ Supported Dataview DQL Features\n\n**Data Commands** (tested and verified):\n- ‚úÖ **FROM** - Source selection by tags, folders, files, links\n- ‚úÖ **WHERE** - Filtering with all comparison operators\n- ‚úÖ **SORT** - Single and multiple field sorting (ASC/DESC)\n- ‚úÖ **LIMIT** - Result count restriction\n\n**Functions** (tested and verified):\n- ‚úÖ **date()** - Date parsing and construction: `date(today)`, `date(\"2024-01-01\")`\n- ‚úÖ **dur()** - Duration construction: `dur(7 days)`, `dur(2 hours)`\n- ‚úÖ **contains()** - String/array contains checks\n- ‚úÖ **Comparison operators** - `>`, `<`, `>=`, `<=`, `=`, `!=`\n- ‚úÖ **Logical operators** - `AND`, `OR`, `!`\n- ‚úÖ **Arithmetic** - Date math: `date(today) - dur(7 days)`\n\n**Implicit Fields** (all work correctly):\n- ‚úÖ `file.name`, `file.path`, `file.folder`, `file.size`, `file.ext`\n- ‚úÖ `file.mtime`, `file.mday`, `file.ctime`, `file.cday`\n- ‚úÖ `file.tags`, `file.etags`, `file.inlinks`, `file.outlinks`\n\n### ‚ùå Unsupported Features\n\n**Dataview DQL Commands:**\n- ‚ùå **GROUP BY** - Returns error: `TABLE WITHOUT ID queries are not supported`\n- ‚ùå **FLATTEN** - Returns error: `TABLE WITHOUT ID queries are not supported`\n- ‚ùå **LIST queries** - Only TABLE queries supported by API\n- ‚ùå **TASK queries** - Only TABLE queries supported by API\n- ‚ùå **CALENDAR queries** - Only TABLE queries supported by API\n\n**JsonLogic Operators:**\n- ‚ùå **startsWith** - Returns error: `Unrecognized operation startsWith`\n- ‚ùå **endsWith** - Returns error: `Unrecognized operation endsWith`\n- ‚úÖ **in** operator - Works for content, filename, and frontmatter searches\n\n### üí° Workarounds\n\n**Folder filtering** (since GROUP BY doesn't work):\n```bash\n# Use contains() to filter by folder path\nobsidian-search-tool search \\\n    'TABLE file.name, file.folder WHERE contains(file.folder, \"reference\")'\n```\n\n**Path pattern matching** (since startsWith doesn't work):\n```bash\n# Use JsonLogic \"in\" operator for substring matching\nobsidian-search-tool search --type jsonlogic \\\n    '{\"in\": [\"daily\", {\"var\": \"filename\"}]}'\n```\n\n**Counting results**:\n```bash\n# Get count via jq\nobsidian-search-tool search 'TABLE file.name FROM \"daily\"' | jq '.data.results | length'\n```\n\n### üêõ Common Errors\n\n| Error Message | Cause | Solution |\n|---------------|-------|----------|\n| `OBSIDIAN_API_KEY environment variable is required` | Missing API key | Set `OBSIDIAN_API_KEY` from plugin settings |\n| `Connection failed` | Obsidian not running or API plugin disabled | Start Obsidian and enable Local REST API plugin |\n| `Only TABLE dataview queries are supported` | Used LIST/TASK/CALENDAR query | Use TABLE queries only |\n| `TABLE WITHOUT ID queries are not supported` | Used GROUP BY or FLATTEN | Remove GROUP BY/FLATTEN from query |\n| `Unrecognized operation startsWith` | Used unsupported JsonLogic operator | Use `in` operator for substring matching |\n\n## Development\n\n### Setup\n\n```bash\n# Clone and install\ngit clone https://github.com/dnvriend/obsidian-search-tool.git\ncd obsidian-search-tool\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install       # Install dependencies\nmake format        # Format code with ruff\nmake lint          # Run linting with ruff\nmake typecheck     # Run type checking with mypy\nmake test          # Run tests with pytest\nmake check         # Run all checks (lint, typecheck, test)\nmake pipeline      # Full pipeline (format, check, build, install-global)\nmake build         # Build package\nmake clean         # Remove build artifacts\n```\n\n### Project Structure\n\n```\nobsidian-search-tool/\n‚îú‚îÄ‚îÄ obsidian_search_tool/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Public API exports\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py             # CLI entry point\n‚îÇ   ‚îú‚îÄ‚îÄ core/              # Core library\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py      # ObsidianClient\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py      # Data models\n‚îÇ   ‚îú‚îÄ‚îÄ commands/          # CLI commands\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_commands.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ status_commands.py\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Formatters and logging\n‚îú‚îÄ‚îÄ tests/                 # Test suite\n‚îú‚îÄ‚îÄ pyproject.toml         # Project configuration\n‚îú‚îÄ‚îÄ Makefile              # Development commands\n‚îú‚îÄ‚îÄ README.md             # This file\n‚îî‚îÄ‚îÄ CLAUDE.md             # Developer guide\n```\n\n## Resources\n\n### Official Documentation\n\n- [Obsidian](https://obsidian.md/) - Knowledge base application\n- [Obsidian Local REST API](https://github.com/coddingtonbear/obsidian-local-rest-api) - REST API plugin\n- [Dataview Plugin](https://github.com/blacksmithgu/obsidian-dataview) - Query language for Obsidian\n- [JsonLogic](https://jsonlogic.com/) - JSON-based logic expression format\n\n### Related Tools\n\n- [Python SDK](https://github.com/coddingtonbear/python-obsidian-rest) - Python client for Obsidian REST API\n- [Dataview Documentation](https://blacksmithgu.github.io/obsidian-dataview/) - Complete Dataview reference\n\n### Reference Files\n\nThe `references/` directory contains curated documentation for quick reference:\n\n- **[JsonLogic Search Examples](references/jsonlogic-search-examples.md)** - JsonLogic query patterns and examples\n- **[Dataview Query Types](references/dataview-ql-query-types.md)** - TABLE, LIST, TASK, and CALENDAR query types\n- **[Dataview Data Commands](references/dataview-ql-data-commands.md)** - FROM, WHERE, SORT, GROUP BY, LIMIT reference\n- **[Dataview Functions](references/dataview-ql-functions.md)** - Complete function reference for DQL expressions\n- **[Dataview Page Metadata](references/dataview-metadata-on-pages.md)** - Available file.* fields and implicit metadata\n\nThese files provide offline reference for common query patterns and Dataview capabilities.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n- Email: dvriend@ilionx.com\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Built with [Requests](https://requests.readthedocs.io/) for HTTP client\n- Built with [Rich](https://rich.readthedocs.io/) for terminal formatting\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n- Type-checked with [mypy](https://mypy.readthedocs.io/)\n- Linted and formatted with [ruff](https://github.com/astral-sh/ruff)\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "obsidian-search-tool",
          "source": "./plugins/obsidian-search-tool",
          "description": "Search Obsidian vault via Dataview and JsonLogic",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/obsidian-search-tool",
            "/plugin install obsidian-search-tool@obsidian-search-tool"
          ]
        }
      ]
    },
    {
      "name": "aws-polly-tts-tool",
      "version": null,
      "description": "AWS Polly TTS with agent-friendly design",
      "repo_full_name": "dnvriend/aws-polly-tts-tool",
      "repo_url": "https://github.com/dnvriend/aws-polly-tts-tool",
      "repo_description": "Professional AWS Polly TTS CLI and library for text-to-speech synthesis with agent-friendly design",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-05T06:40:50Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"aws-polly-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/aws-polly-tts-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"aws-polly-tts-tool\",\n            \"source\": \"./plugins/aws-polly-tts-tool\",\n            \"description\": \"AWS Polly TTS with agent-friendly design\"\n        }\n    ]\n}\n",
        "README.md": "<div align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"AWS Polly TTS Tool Logo\" width=\"256\">\n\n# aws-polly-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nProfessional AWS Polly TTS CLI and library for text-to-speech synthesis with agent-friendly design.\n\n</div>\n\n## Table of Contents\n\n- [About](#about)\n- [Why CLI-First?](#why-cli-first)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n  - [Basic Synthesis](#basic-synthesis)\n  - [Voice Selection](#voice-selection)\n  - [Engine Selection](#engine-selection)\n  - [SSML Support](#ssml-support)\n  - [Cost Tracking](#cost-tracking)\n  - [Verbosity and Debugging](#verbosity-and-debugging)\n  - [Shell Completion](#shell-completion)\n- [Library Usage](#library-usage)\n- [Commands](#commands)\n- [Known Issues](#known-issues)\n- [Development](#development)\n- [Resources](#resources)\n- [License](#license)\n\n## About\n\n`aws-polly-tts-tool` is a comprehensive CLI tool and Python library for Amazon Polly text-to-speech synthesis. Built with a CLI-first philosophy, it provides both command-line convenience and programmatic access to AWS Polly's full feature set.\n\n### What is Amazon Polly?\n\n[Amazon Polly](https://aws.amazon.com/polly/) is AWS's fully-managed text-to-speech service that converts text into lifelike speech using deep learning. It offers 60+ voices in 30+ languages with multiple quality tiers.\n\n### Why This Tool?\n\n- **Agent-Friendly**: Designed for Claude Code and AI agents with self-documenting help and structured errors\n- **Composable**: JSON output to stdout, logs to stderr - perfect for Unix piping\n- **Dual-Mode**: Use as CLI or import as Python library\n- **Production-Ready**: Type-safe, tested, linted with comprehensive error handling\n- **Cost-Transparent**: Real-time cost estimates and AWS billing integration\n\n## Why CLI-First?\n\nThis tool prioritizes CLI design to enable:\n\n- ü§ñ **AI Agent Integration**: Claude Code and other AI tools can use structured commands and parse outputs\n- üîÑ **ReAct Loops**: Clear error messages help agents self-correct and retry operations\n- üîó **Composability**: Standard Unix patterns (stdin/stdout/stderr) enable piping and automation\n- üß± **Building Blocks**: Commands serve as reusable components for skills, MCP servers, and scripts\n- üìä **Predictability**: Type-safe implementation ensures consistent behavior in automated workflows\n\n## Features\n\n### Voice Engines\n- ‚úÖ **Standard** - Cost-effective traditional TTS ($4/1M chars)\n- ‚úÖ **Neural** - Natural, human-like voices ($16/1M chars)\n- ‚úÖ **Generative** - Most advanced, emotionally engaged ($30/1M chars)\n- ‚úÖ **Long-form** - Optimized for audiobooks ($100/1M chars)\n\n### Voice Selection\n- üì¢ 60+ voices across 30+ languages\n- üîç Dynamic fetching from Polly API (always up-to-date)\n- üéöÔ∏è Filter by engine, language, gender\n- üåç Multiple accents and speaking styles\n\n### Output Options\n- üéµ **mp3** - General purpose (default)\n- üé∂ **ogg_vorbis** - Open format for web\n- üéôÔ∏è **pcm** - Raw audio, lowest latency\n\n### Advanced Features\n- üìù Full SSML support (prosody, breaks, emphasis, phonemes)\n- üí∞ Dual cost tracking (estimates + AWS Cost Explorer)\n- üìä Billing queries with engine breakdown\n- üîê AWS environment variable authentication\n- üì§ Stdin support for piping\n\n## Installation\n\n### Prerequisites\n\n- **Python 3.12+** (Python 3.13+ has pydub compatibility issues - see [Known Issues](#known-issues))\n- [uv](https://github.com/astral-sh/uv) package manager (recommended)\n- AWS credentials configured\n- **ffmpeg** (for audio playback - not required for file output)\n\n> **Note**: For a detailed explanation of how the TTS pipeline works and why these dependencies are needed, see [TTS Pipeline Architecture](references/tts-pipeline.md)\n\n### Install from Source\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/aws-polly-tts-tool.git\ncd aws-polly-tts-tool\n\n# Install with uv (Python 3.12)\nuv tool install . --python 3.12\n\n# Verify installation\naws-polly-tts-tool --version\n```\n\n### Install with mise (Development)\n\n```bash\ncd aws-polly-tts-tool\nmise use python@3.12\nuv sync\nuv tool install .\n```\n\n## Configuration\n\n### AWS Credentials\n\nConfigure AWS credentials using any of these methods:\n\n```bash\n# Method 1: AWS CLI configuration\naws configure\n\n# Method 2: Environment variables\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_DEFAULT_REGION=\"us-east-1\"\n\n# Verify credentials\naws-polly-tts-tool info\n```\n\n### IAM Permissions Required\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"polly:DescribeVoices\",\n        \"polly:SynthesizeSpeech\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"ce:GetCostAndUsage\"],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n## Usage\n\n### Basic Synthesis\n\n```bash\n# Play text with default voice (Joanna, neural engine)\naws-polly-tts-tool synthesize \"Hello world\"\n\n# Save to file instead of playing\naws-polly-tts-tool synthesize \"Hello world\" --output speech.mp3\n\n# Read from stdin\necho \"Hello world\" | aws-polly-tts-tool synthesize --stdin\n\n# Read from file\ncat article.txt | aws-polly-tts-tool synthesize --stdin --output article.mp3\n```\n\n### Voice Selection\n\n```bash\n# List all available voices\naws-polly-tts-tool list-voices\n\n# Filter by language\naws-polly-tts-tool list-voices --language en-US\n\n# Filter by engine and gender\naws-polly-tts-tool list-voices --engine neural --gender Female\n\n# Use specific voice\naws-polly-tts-tool synthesize \"Hello\" --voice Matthew\naws-polly-tts-tool synthesize \"Bonjour\" --voice Celine  # French\n```\n\n### Engine Selection\n\n```bash\n# List all engines with pricing\naws-polly-tts-tool list-engines\n\n# Use standard engine (cheapest)\naws-polly-tts-tool synthesize \"Hello\" --engine standard\n\n# Use neural engine (recommended)\naws-polly-tts-tool synthesize \"Hello\" --engine neural\n\n# Use generative engine (highest quality)\naws-polly-tts-tool synthesize \"Hello\" --engine generative\n\n# Use long-form for audiobooks\naws-polly-tts-tool synthesize \"$(cat book.txt)\" --engine long-form --output book.mp3\n```\n\n### SSML Support\n\n```bash\n# Basic SSML with pauses\naws-polly-tts-tool synthesize '<speak>Hello <break time=\"500ms\"/> world</speak>' --ssml\n\n# Prosody control (speed, pitch, volume)\naws-polly-tts-tool synthesize '<speak><prosody rate=\"slow\" pitch=\"low\">Deep voice</prosody></speak>' --ssml\n\n# Emphasis\naws-polly-tts-tool synthesize '<speak>I <emphasis level=\"strong\">really</emphasis> like this</speak>' --ssml\n\n# Newscaster style (select voices only)\naws-polly-tts-tool synthesize '<speak><amazon:domain name=\"news\">Breaking news today</amazon:domain></speak>' --ssml --voice Matthew\n```\n\n### Cost Tracking\n\n```bash\n# Show cost estimate after synthesis\naws-polly-tts-tool synthesize \"Hello world\" --show-cost\n\n# View pricing for all engines\naws-polly-tts-tool pricing\n\n# Query AWS billing (last 30 days)\naws-polly-tts-tool billing\n\n# Custom date range\naws-polly-tts-tool billing --start-date 2025-01-01 --end-date 2025-01-31\n\n# Last 7 days\naws-polly-tts-tool billing --days 7\n```\n\n### Verbosity and Debugging\n\nMulti-level verbosity for progressive debugging detail:\n\n```bash\n# Default: No verbose output (errors/warnings only)\naws-polly-tts-tool synthesize \"Hello world\" --output test.mp3\n\n# -V: INFO level (high-level operations)\naws-polly-tts-tool synthesize \"Hello world\" -V --output test.mp3\n[INFO] Using voice: Joanna (neural engine)\n[INFO] Synthesizing audio to file: test.mp3\n\n# -VV: DEBUG level (detailed operations, validation, character counts)\naws-polly-tts-tool synthesize \"Hello world\" -VV --output test.mp3\n[DEBUG] Validating engine: neural\n[DEBUG] Validating output format: mp3\n[DEBUG] Initializing AWS Polly client\n[DEBUG] Resolving voice ID for: Joanna\n[INFO] Using voice: Joanna (neural engine)\n[INFO] Synthesizing audio to file: test.mp3\n[DEBUG] Synthesized 11 characters\n\n# -VVV: TRACE level (full AWS SDK details, API requests/responses)\naws-polly-tts-tool synthesize \"Hello world\" -VVV --output test.mp3\n[DEBUG] Validating engine: neural\n[DEBUG] Validating output format: mp3\n[DEBUG] Initializing AWS Polly client\n[DEBUG] Looking for credentials via: env\n[DEBUG] Looking for credentials via: shared-credentials-file\n[INFO] Found credentials in shared credentials file: ~/.aws/credentials\n[DEBUG] Event creating-client-class.polly: calling handler\n[DEBUG] Starting new HTTPS connection (1): polly.eu-central-1.amazonaws.com:443\n[DEBUG] https://polly.eu-central-1.amazonaws.com:443 \"POST /v1/speech HTTP/1.1\" 200 None\n[INFO] Using voice: Joanna (neural engine)\n[INFO] Synthesizing audio to file: test.mp3\n[DEBUG] Synthesized 11 characters\n\n# Works with all commands\naws-polly-tts-tool list-voices -V --engine neural\naws-polly-tts-tool billing -VV --days 7\n```\n\n**Verbosity Levels**:\n- **Default**: Errors and warnings only - clean output\n- **`-V`** (INFO): High-level operations (voice selection, file operations)\n- **`-VV`** (DEBUG): Detailed steps (validation, API calls, character counts)\n- **`-VVV`** (TRACE): Full AWS SDK internals (credentials, HTTP requests, boto3 events)\n\n**Note**: All log output goes to stderr, keeping stdout clean for data/piping.\n\n### Shell Completion\n\nEnable tab completion for bash, zsh, or fish shells to autocomplete commands, options, and arguments:\n\n```bash\n# View installation instructions\naws-polly-tts-tool completion --help\n\n# Bash - add to ~/.bashrc for persistent completion\neval \"$(aws-polly-tts-tool completion bash)\"\n\n# Zsh - add to ~/.zshrc for persistent completion\neval \"$(aws-polly-tts-tool completion zsh)\"\n\n# Fish - one-time installation\naws-polly-tts-tool completion fish > ~/.config/fish/completions/aws-polly-tts-tool.fish\n\n# File-based installation (recommended for better performance)\naws-polly-tts-tool completion bash > ~/.aws-polly-tts-tool-complete.bash\necho 'source ~/.aws-polly-tts-tool-complete.bash' >> ~/.bashrc\n```\n\nAfter installation, restart your shell or source the config file:\n```bash\nsource ~/.bashrc  # for bash\nsource ~/.zshrc   # for zsh\n```\n\nShell completion enables:\n- **Command completion**: Type `aws-polly-tts-tool <TAB>` to see all commands\n- **Option completion**: Type `--<TAB>` to see available options\n- **Value completion**: Auto-complete for choices like engines (standard, neural, generative)\n\n## Library Usage\n\nImport and use as a Python library:\n\n```python\nfrom aws_polly_tts_tool import (\n    get_polly_client,\n    synthesize_audio,\n    save_speech,\n    VoiceManager,\n    calculate_cost,\n)\n\n# Initialize client\nclient = get_polly_client(region=\"us-east-1\")\n\n# Synthesize audio\naudio_bytes, char_count = synthesize_audio(\n    client=client,\n    text=\"Hello world\",\n    voice_id=\"Joanna\",\n    output_format=\"mp3\",\n    engine=\"neural\"\n)\n\n# Save to file\nsave_speech(\n    client=client,\n    text=\"Hello world\",\n    voice_id=\"Joanna\",\n    output_path=Path(\"output.mp3\"),\n    engine=\"neural\"\n)\n\n# List voices\nvoice_manager = VoiceManager(client)\nvoices = voice_manager.list_voices(engine=\"neural\", language=\"en\")\n\n# Calculate cost\ncost = calculate_cost(character_count=5000, engine=\"neural\")\nprint(f\"Estimated cost: ${cost:.4f}\")\n```\n\n## Commands\n\n### synthesize\nConvert text to speech with full control over voice, engine, and output.\n\n```bash\naws-polly-tts-tool synthesize [TEXT] [OPTIONS]\n  -s, --stdin         Read from stdin\n  --voice TEXT        Voice ID (default: Joanna)\n  -o, --output PATH   Save to file\n  -f, --format TEXT   mp3, ogg_vorbis, pcm\n  -e, --engine TEXT   standard, neural, generative, long-form\n  --ssml              Treat input as SSML\n  --show-cost         Display cost estimate\n  -r, --region TEXT   AWS region override\n  -V, --verbose       Verbosity (-V, -VV, -VVV for progressive detail)\n```\n\n### list-voices\nList and filter available Polly voices.\n\n```bash\naws-polly-tts-tool list-voices [OPTIONS]\n  -e, --engine TEXT    Filter by engine\n  -l, --language TEXT  Filter by language\n  -g, --gender TEXT    Filter by gender\n  -r, --region TEXT    AWS region override\n  -V, --verbose        Verbosity (-V, -VV, -VVV for progressive detail)\n```\n\n### list-engines\nDisplay all voice engines with features and pricing.\n\n```bash\naws-polly-tts-tool list-engines\n```\n\n### billing\nQuery AWS Cost Explorer for actual Polly usage costs.\n\n```bash\naws-polly-tts-tool billing [OPTIONS]\n  -d, --days INT       Number of days (default: 30)\n  --start-date TEXT    Custom start date (YYYY-MM-DD)\n  --end-date TEXT      Custom end date (YYYY-MM-DD)\n  -r, --region TEXT    AWS region override\n  -V, --verbose        Verbosity (-V, -VV, -VVV for progressive detail)\n```\n\n### pricing\nShow Polly pricing information and examples.\n\n```bash\naws-polly-tts-tool pricing\n```\n\n### info\nDisplay AWS credentials and tool configuration.\n\n```bash\naws-polly-tts-tool info\n```\n\n### completion\nGenerate shell completion scripts for bash, zsh, or fish.\n\n```bash\naws-polly-tts-tool completion [bash|zsh|fish]\n\n# Install for bash\neval \"$(aws-polly-tts-tool completion bash)\"\n\n# Install for zsh\neval \"$(aws-polly-tts-tool completion zsh)\"\n\n# Install for fish\naws-polly-tts-tool completion fish > ~/.config/fish/completions/aws-polly-tts-tool.fish\n```\n\nSee [Shell Completion](#shell-completion) section for detailed installation instructions.\n\n## Known Issues\n\n### pydub Python 3.13+ Compatibility\n\n**Issue**: The `pydub` library depends on Python's `audioop` module, which was removed in Python 3.13.\n\n**Impact**: Audio playback through speakers fails on Python 3.13+. File output (`--output`) works fine.\n\n**Workarounds**:\n1. **Use Python 3.12** (recommended)\n   ```bash\n   mise use python@3.12\n   uv tool install . --python 3.12\n   ```\n\n2. **Save to file instead of playback**\n   ```bash\n   # This works on any Python version\n   aws-polly-tts-tool synthesize \"Hello\" --output speech.mp3\n   ```\n\n3. **Future fix**: We plan to replace pydub with a Python 3.13+ compatible library (pygame or sounddevice)\n\n## Development\n\n### Setup\n\n```bash\n# Clone and setup\ngit clone https://github.com/dnvriend/aws-polly-tts-tool.git\ncd aws-polly-tts-tool\n\n# Install with Python 3.12\nmise use python@3.12\nuv sync\n\n# Run quality checks\nmake check\n```\n\n### Available Commands\n\n```bash\nmake install              # Install dependencies\nmake format               # Format with ruff\nmake lint                 # Lint with ruff\nmake typecheck            # Type check with mypy\nmake test                 # Run tests with pytest\nmake security-bandit      # Run bandit security linter\nmake security-pip-audit   # Run pip-audit for vulnerabilities\nmake security-gitleaks    # Run gitleaks secret scanner\nmake security             # Run all security checks\nmake check                # Run all checks (lint, typecheck, test, security)\nmake pipeline             # Full pipeline (format, lint, typecheck, test, security, build, install)\nmake build                # Build package\nmake clean                # Remove artifacts\n```\n\n### Security Checks\n\nThe project includes three security tools integrated into the development pipeline:\n\n- **bandit** - Python security linter that scans for common security issues\n- **pip-audit** - Dependency vulnerability scanner checking for known CVEs\n- **gitleaks** - Secret detection tool that scans git history for leaked credentials\n\n**Note**: gitleaks requires separate installation via `brew install gitleaks` (macOS) or from [GitHub releases](https://github.com/gitleaks/gitleaks/releases)\n\n### Architecture\n\n```\naws-polly-tts-tool/\n‚îú‚îÄ‚îÄ aws_polly_tts_tool/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Public API exports\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py                # CLI entry point\n‚îÇ   ‚îú‚îÄ‚îÄ voices.py             # VoiceManager (dynamic API)\n‚îÇ   ‚îú‚îÄ‚îÄ engines.py            # Engine metadata & validation\n‚îÇ   ‚îú‚îÄ‚îÄ billing.py            # Cost calculations\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py              # Shared utilities\n‚îÇ   ‚îú‚îÄ‚îÄ core/                 # Core library (CLI-independent)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py         # AWS client initialization\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ synthesize.py     # TTS functions\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cost_explorer.py  # Billing queries\n‚îÇ   ‚îî‚îÄ‚îÄ commands/             # CLI command implementations\n‚îÇ       ‚îú‚îÄ‚îÄ synthesize_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ voice_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ engine_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ billing_commands.py\n‚îÇ       ‚îî‚îÄ‚îÄ info_commands.py\n‚îú‚îÄ‚îÄ tests/\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îî‚îÄ‚îÄ Makefile\n```\n\n## Resources\n\n- [Amazon Polly Documentation](https://docs.aws.amazon.com/polly/)\n- [Polly Pricing](https://aws.amazon.com/polly/pricing/)\n- [SSML Reference](https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html)\n- [Boto3 Polly API](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/polly.html)\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n---\n\n**Built with Claude Code**\n\nThis project was created using [Claude Code](https://www.anthropic.com/claude/code), featuring AI-assisted development with human review and testing.\n\nMade with ‚ù§Ô∏è and AI ‚Ä¢ Python 3.12+\n"
      },
      "plugins": [
        {
          "name": "aws-polly-tts-tool",
          "source": "./plugins/aws-polly-tts-tool",
          "description": "AWS Polly TTS with agent-friendly design",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/aws-polly-tts-tool",
            "/plugin install aws-polly-tts-tool@aws-polly-tts-tool"
          ]
        }
      ]
    },
    {
      "name": "openai-tts-tool",
      "version": null,
      "description": "Marketplace for openai-tts-tool CLI plugin - A CLI that provides tts using OpenAI",
      "repo_full_name": "dnvriend/openai-tts-tool",
      "repo_url": "https://github.com/dnvriend/openai-tts-tool",
      "repo_description": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-05T06:33:16Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"openai-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for openai-tts-tool CLI plugin - A CLI that provides tts using OpenAI\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"openai-tts-tool\",\n            \"source\": \"./plugins/openai-tts-tool\",\n            \"description\": \"A CLI that provides tts using OpenAI\"\n        }\n    ]\n}\n",
        "README.md": "<p align=\"center\">\n  <img src=\"https://github.com/dnvriend/openai-tts-tool/blob/main/.github/assets/logo-web.png\" alt=\"openai-tts-tool Logo\" width=\"120\"/>\n</p>\n\n# openai-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\n\nA command-line interface for OpenAI Text-to-Speech API.\n\n## Features\n\n- Convert text to natural-sounding speech\n- Six high-quality voices with different characteristics\n- Two TTS models (tts-1 and tts-1-hd) for speed vs quality\n- Multiple audio formats: mp3, opus, aac, flac\n- Stream to speakers or save to files\n- Adjustable speech speed (0.25 to 4.0)\n- Multi-level verbosity logging\n- Shell completion support\n\n## Installation\n\n```bash\n# Prerequisites\n# - Python 3.14+\n# - uv package manager\n\n# Clone and install globally\ngit clone https://github.com/dnvriend/openai-tts-tool.git\ncd openai-tts-tool\nuv tool install .\n\n# Verify installation\nopenai-tts-tool --version\n```\n\n## Configuration\n\nSet the OpenAI API key:\n\n```bash\nexport OPENAI_API_KEY=\"your-api-key-here\"\n\n# Add to shell profile for persistence\necho 'export OPENAI_API_KEY=\"your-api-key-here\"' >> ~/.bashrc  # or ~/.zshrc\nsource ~/.bashrc  # or ~/.zshrc\n```\n\n## Usage\n\n```bash\n# Basic synthesis (stream to speakers)\nopenai-tts-tool synthesize \"Hello, world!\"\n\n# Save to file with specific voice\nopenai-tts-tool synthesize \"Hello, world!\" --voice nova --output hello.mp3\n\n# High-quality synthesis with custom settings\nopenai-tts-tool synthesize \"Welcome\" \\\n    --voice alloy \\\n    --model tts-1-hd \\\n    --output welcome.mp3 \\\n    --format mp3 \\\n    --speed 1.2\n\n# Read from stdin\necho \"Hello from stdin\" | openai-tts-tool synthesize --stdin --output hello.mp3\n\n# List available voices and models\nopenai-tts-tool list-voices\nopenai-tts-tool list-models\n\n# Multi-level verbosity for debugging\nopenai-tts-tool -v synthesize \"Test\"           # INFO level\nopenai-tts-tool -vv synthesize \"Test\"          # DEBUG level\nopenai-tts-tool -vvv synthesize \"Test\"         # TRACE with library logs\n```\n\n## Options\n\n### Synthesize Command\n\n| Option | Short | Description |\n|--------|-------|-------------|\n| `--voice` | `-v` | Voice to use (alloy, echo, fable, onyx, nova, shimmer) |\n| `--model` | `-m` | TTS model (tts-1, tts-1-hd) |\n| `--output` | `-o` | Output file path (default: stream to speakers) |\n| `--format` | `-f` | Audio format (mp3, opus, aac, flac) |\n| `--speed` | `-s` | Speech speed (0.25 to 4.0) |\n| `--stdin` | | Read text from stdin |\n\n### Global Options\n\n| Option | Short | Description |\n|--------|-------|-------------|\n| `--verbose` | `-v` | Verbose output: -v (INFO), -vv (DEBUG), -vvv (TRACE with library logs) |\n| `--version` | | Show version information |\n| `--help` | `-h` | Show help message |\n\n## Voices and Models\n\n### Voices\n\n| Voice | Description |\n|-------|-------------|\n| **alloy** | Balanced, natural voice (default) |\n| **echo** | Deeper, authoritative voice |\n| **fable** | Warm, engaging storyteller |\n| **onyx** | Deep, confident voice |\n| **nova** | Clear, professional voice |\n| **shimmer** | Softer, expressive voice |\n\n### Models\n\n| Model | Quality | Speed | Use Case |\n|-------|---------|-------|----------|\n| **tts-1** | Standard | Fast | Real-time applications |\n| **tts-1-hd** | High | Slower | High-quality audio production |\n\n### Audio Formats\n\n| Format | Quality | Use Case |\n|--------|---------|----------|\n| **mp3** | Good | Maximum compatibility |\n| **opus** | Excellent | Streaming, low bandwidth |\n| **aac** | Very Good | Apple devices |\n| **flac** | Lossless | High-fidelity production |\n\n## Library Usage\n\n```python\nfrom openai_tts_tool import TTSClient\n\nclient = TTSClient(api_key=\"your-key\")\n\n# Stream to speakers\nclient.synthesize(\"Hello, world!\", voice=\"alloy\")\n\n# Save to file\nclient.synthesize(\n    \"Hello, world!\",\n    voice=\"nova\",\n    model=\"tts-1-hd\",\n    output=\"hello.mp3\",\n    speed=1.2\n)\n```\n\n## Development\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake security         # Run all security checks\nmake check            # Run all checks (lint, typecheck, test, security)\nmake pipeline         # Run full pipeline\nmake build            # Build package\nmake run ARGS=\"...\"   # Run openai-tts-tool locally\n```\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nDennis Vriend - [GitHub](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "openai-tts-tool",
          "source": "./plugins/openai-tts-tool",
          "description": "A CLI that provides tts using OpenAI",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/openai-tts-tool",
            "/plugin install openai-tts-tool@openai-tts-tool"
          ]
        }
      ]
    },
    {
      "name": "gemini-file-search-tool",
      "version": null,
      "description": "Manage Gemini File Search stores and query with RAG",
      "repo_full_name": "dnvriend/gemini-file-search-tool",
      "repo_url": "https://github.com/dnvriend/gemini-file-search-tool",
      "repo_description": "Production-ready CLI and Python library for Google's Gemini File Search API - A fully managed RAG system for document search and question-answering",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-31T23:41:21Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"gemini-file-search-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/gemini-file-search-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"gemini-file-search-tool\",\n            \"source\": \"./plugins/gemini-file-search-tool\",\n            \"description\": \"Manage Gemini File Search stores and query with RAG\"\n        }\n    ]\n}\n",
        "README.md": "# gemini-file-search-tool\n\n<div align=\"center\">\n  <img src=\".github/assets/rag-icon.png\" alt=\"RAG Icon\" width=\"200\" />\n  <br>\n  <br>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\n**Gemini File Search Tool** - Production-ready CLI & Python library for Google's fully managed RAG system\n\n</div>\n\n## Table of Contents\n\n- [About](#about)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Development](#development)\n- [Testing](#testing)\n- [Known Issues](#known-issues)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n- [Resources](#resources)\n\n## About\n\n`gemini-file-search-tool` is a production-ready CLI and Python library for [Google's Gemini File Search API](https://ai.google.dev/gemini-api/docs/file-search), a fully managed Retrieval-Augmented Generation (RAG) system that eliminates the operational complexity of vector databases, embeddings, and retrieval infrastructure.\n\n### What is Gemini File Search?\n\nGemini File Search is Google's fully managed RAG solution that automatically handles document ingestion, chunking, embedding generation, and semantic retrieval. As announced in [Google's developer blog](https://blog.google/technology/developers/file-search-gemini-api/), it provides enterprise-grade document search capabilities with zero infrastructure overhead, allowing developers to focus on building intelligent applications rather than managing search infrastructure.\n\n### Why This Tool?\n\nThis tool provides a **CLI-first interface** to the Gemini File Search API, designed specifically for integration with AI agents, automation workflows, and human operators:\n\n- **Agent-Friendly Design**: CLIs provide structured commands with built-in documentation and rich error messages that AI agents can parse and act upon in ReAct (Reasoning and Acting) loops, making them superior to standalone scripts for agentic workflows\n- **Composable Architecture**: JSON output to stdout and logs to stderr enable seamless piping and integration with other tools, perfect for complex automation pipelines\n- **Reusable Building Blocks**: Commands can be composed into larger workflows, used in skills for Claude Code, or integrated into custom automation without modification\n- **Dual-Mode Operation**: Functions as both a CLI tool for command-line operations and a Python library for programmatic integration\n- **Production Quality**: Type-safe, thoroughly tested, with comprehensive error handling that provides actionable feedback for both humans and agents\n\nWhether you're building AI-powered document search, integrating RAG into agentic workflows, or automating knowledge base operations, this tool provides the foundation for reliable, maintainable solutions.\n\n## Use Cases\n\n- **üìö Knowledge Base Management**: Index documentation, research papers, wikis, and technical specifications into searchable stores for instant retrieval\n- **üíª Code-RAG (Retrieval-Augmented Generation for Code)**: Upload entire codebases to enable semantic code search and natural language querying. Ask questions like \"how does authentication work?\", \"where is error handling implemented?\", or \"explain the database architecture\". Perfect for onboarding, code reviews, architecture discovery, and building AI coding assistants.\n- **üîç Semantic Search**: Query your document stores with natural language questions and receive contextually relevant answers with automatic citation\n- **üéØ RAG Applications**: Build production-ready retrieval-augmented generation systems with JSON-formatted responses including grounding metadata and source attribution\n\n### Code-RAG Example\n\nUpload a codebase and query it with natural language:\n\n```bash\n# Upload your entire codebase\ngemini-file-search-tool upload \"src/**/*.py\" --store \"my-project-code\" -v\n\n# Query with natural language\ngemini-file-search-tool query \"How does the authentication system work?\" \\\n  --store \"my-project-code\" --show-cost -v\n\n# Ask architectural questions\ngemini-file-search-tool query \"What design patterns are used in this codebase?\" \\\n  --store \"my-project-code\" --query-model pro\n\n# Find implementations\ngemini-file-search-tool query \"Where is error handling for API calls implemented?\" \\\n  --store \"my-project-code\"\n```\n\n**Meta Note**: This tool itself was built using Code-RAG! We uploaded the codebase to a Gemini File Search store and used it to answer questions during development. The tool enables the very functionality it provides.\n\n## Features\n\n- ‚úÖ **Fully Managed RAG**: Automatic chunking, embeddings, and retrieval without infrastructure management\n- ‚úÖ **Multi-Format Support**: PDF, DOCX, TXT, JSON, CSV, HTML, and source code files\n- ‚úÖ **Code-RAG Enabled**: Upload codebases and query with natural language for semantic code search\n- ‚úÖ **Intelligent Caching**: Local mtime-based cache (O(1) performance) prevents unnecessary re-uploads\n- ‚úÖ **Async Uploads**: `--no-wait` flag for fire-and-forget uploads with manual sync capability\n- ‚úÖ **Cache Management**: sync-cache, flush-cache, and cache-report commands for operation tracking\n- ‚úÖ **Query Enhancement**: LLM-powered query optimization for better RAG retrieval (generic, code-rag, obsidian modes)\n- ‚úÖ **Natural Language Queries**: Ask questions in plain language and get contextual answers\n- ‚úÖ **Automatic Citations**: Built-in source attribution and grounding metadata\n- ‚úÖ **Multi-Level Verbosity**: Progressive logging detail with `-v` (INFO), `-vv` (DEBUG), `-vvv` (TRACE)\n- ‚úÖ **Cost Tracking**: Token usage monitoring and cost estimation for both enhancement and query operations\n- ‚úÖ **Composable CLI**: JSON output for easy integration with other tools and scripts\n- ‚úÖ **Python Library**: Import and use programmatically in your applications\n- ‚úÖ **Type-Safe**: Strict mypy type checking and modern Python 3.14+ syntax\n- ‚úÖ **Production-Ready**: Comprehensive testing, linting, and quality checks\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- Google Gemini API access (see [Configuration](#configuration))\n\n### Core Dependencies\n\nThis tool uses the [Google Generative AI Python SDK](https://github.com/googleapis/python-genai) (`google-genai`) for interacting with Google's Gemini API.\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd gemini-file-search-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\ngemini-file-search-tool --version\n```\n\n## Configuration\n\n### Environment Variables\n\nThe CLI automatically detects and supports both authentication methods. Configuration depends on whether you're using the Gemini Developer API or the Gemini API in Vertex AI.\n\n#### Gemini Developer API (Recommended)\n\nSet `GEMINI_API_KEY` or `GOOGLE_API_KEY`. The client will automatically pick up these variables. If both are set, `GOOGLE_API_KEY` takes precedence.\n\n```bash\nexport GEMINI_API_KEY='your-api-key'\n```\n\n**Get your API key:**\n1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)\n2. Create or select a project\n3. Generate an API key\n4. Set the environment variable\n\n**Example:**\n```bash\nexport GEMINI_API_KEY='AIza...'\ngemini-file-search-tool list-stores\n```\n\n#### Gemini API on Vertex AI\n\nFor Vertex AI, set the following environment variables:\n\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='your-project-id'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n```\n\n**Prerequisites:**\n- Google Cloud project with Vertex AI API enabled\n- Proper IAM permissions for Vertex AI\n- Authenticated with `gcloud auth application-default login`\n\n**Example:**\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='my-project'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n\n# Authenticate with Google Cloud\ngcloud auth application-default login\n\n# Use the CLI (automatically uses Vertex AI)\ngemini-file-search-tool list-stores\n```\n\n**Note:** The CLI automatically detects which authentication method to use based on the `GOOGLE_GENAI_USE_VERTEXAI` environment variable.\n\nFor more information, see the [Google Generative AI Python SDK documentation](https://github.com/googleapis/python-genai).\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Show help\ngemini-file-search-tool --help\n\n# Show version\ngemini-file-search-tool --version\n\n# Get help for specific commands\ngemini-file-search-tool create-store --help\ngemini-file-search-tool upload --help\n```\n\n### Store Management\n\n```bash\n# Create a new store\ngemini-file-search-tool create-store \"my-documents\"\n\n# List all stores\ngemini-file-search-tool list-stores\n\n# Get store details\ngemini-file-search-tool get-store \"my-documents\"\n\n# Update store display name\ngemini-file-search-tool update-store \"my-documents\" --display-name \"My Documents 2024\"\n\n# Delete a store\ngemini-file-search-tool delete-store \"my-documents\" --force\n```\n\n### Document Management\n\n```bash\n# Upload a single file\ngemini-file-search-tool upload document.pdf --store \"my-documents\"\n\n# Upload multiple files with glob pattern\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\"\n\n# Recursive upload\ngemini-file-search-tool upload \"docs/**/*.md\" --store \"my-documents\"\n\n# Upload with metadata\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --title \"Important Document\" \\\n  --url \"https://example.com/doc\"\n\n# Upload with custom chunking\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --max-tokens 300 \\\n  --max-overlap 25\n\n# Upload respecting .gitignore (default behavior)\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" -v\n\n# Upload ignoring .gitignore patterns\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --ignore-gitignore\n\n# Dry-run to preview files before uploading\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --dry-run -v\n\n# Upload with verbose logging (see what's happening)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -v\n\n# Upload with debug logging (see detailed operations)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vv\n\n# Upload with trace logging (see full API calls)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vvv\n\n# List documents in a store\ngemini-file-search-tool list-documents --store \"my-documents\"\n\n# List documents with verbose output\ngemini-file-search-tool list-documents --store \"my-documents\" -v\n```\n\n### Querying\n\n**‚ö° Recommended Configuration (Based on Benchmarks)**\n\nFor optimal cost-quality balance, use the default configuration with no enhancement:\n\n```bash\n# Recommended: No enhancement + Flash model (best value)\ngemini-file-search-tool query \"What are the key findings?\" \\\n  --store \"my-documents\"\n\n# With cost tracking and grounding metadata\ngemini-file-search-tool query \"Explain the methodology\" \\\n  --store \"my-documents\" --show-cost --query-grounding-metadata -v\n```\n\n**Performance Benchmarks** (30 queries across 6 configurations):\n- **Quality Score**: 97.7/100\n- **Cost**: ~$0.00013 per query\n- **Success Rate**: 100% (vs 20-80% with enhancement)\n- **Value**: 156.1 quality points per $0.001 (6.6x better than enhancement)\n\nSee `references/benchmark-model-comparison-2025-11-16.md` for detailed analysis.\n\n**Other Query Options:**\n\n```bash\n# Query with Pro model (complex analytical questions)\ngemini-file-search-tool query \"Analyze the technical architecture\" \\\n  --store \"my-documents\" --query-model pro\n\n# Query with metadata filter\ngemini-file-search-tool query \"Tell me about the book\" \\\n  --store \"my-documents\" --metadata-filter \"author=Robert Graves\"\n\n# Query with enhancement (only for vague/exploratory queries)\ngemini-file-search-tool query \"authentication stuff\" \\\n  --store \"my-documents\" --enhance-mode code-rag --show-enhancement\n\n# Query with debug logging (see API operations)\ngemini-file-search-tool query \"What are the findings?\" \\\n  --store \"my-documents\" --show-cost -vv\n\n# Query with trace logging (see full HTTP requests)\ngemini-file-search-tool query \"Analyze this\" \\\n  --store \"my-documents\" --show-cost -vvv\n```\n\n**‚ö†Ô∏è Query Enhancement Notes:**\n\nBased on comprehensive benchmarks, **query enhancement is disabled by default** and should only be used for:\n- Vague or poorly worded queries (\"authentication stuff\", \"that database thing\")\n- Exploratory queries where you're unsure what you're looking for\n- Cases where simple queries consistently fail to retrieve relevant documents\n\n**Why?** Enhancement makes queries too specific, reducing retrieval success rates from 100% to 20-80%. Simple, natural language queries work best for RAG systems (see [Lewis et al., 2020](https://arxiv.org/abs/2005.11401)).\n\n### Cost Tracking\n\nThe CLI automatically tracks token usage for query operations and can estimate costs based on current Gemini API pricing:\n\n```bash\n# View token usage (verbose mode)\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n\n# Show estimated cost\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" --show-cost -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n# [INFO] Estimated cost: $0.00010725 USD\n```\n\n**Query Response with Cost Information:**\n\n```json\n{\n  \"response_text\": \"The document discusses...\",\n  \"usage_metadata\": {\n    \"prompt_token_count\": 150,\n    \"candidates_token_count\": 320,\n    \"total_token_count\": 470\n  },\n  \"estimated_cost\": {\n    \"input_cost_usd\": 0.00001125,\n    \"output_cost_usd\": 0.000096,\n    \"total_cost_usd\": 0.00010725,\n    \"currency\": \"USD\",\n    \"model\": \"gemini-2.5-flash\",\n    \"note\": \"Estimated cost based on current pricing. Subject to change.\"\n  }\n}\n```\n\n**Current Pricing (as of 2025-01):**\n- **gemini-2.5-flash**: $0.075 input / $0.30 output per 1M tokens\n- **gemini-2.5-pro**: $1.25 input / $5.00 output per 1M tokens\n\n**Note**: Pricing is subject to change. Verify current rates at [Google AI Pricing](https://ai.google.dev/pricing).\n\n**Limitations:**\n- Token usage is only available for query operations\n- Upload costs (document embedding) are not tracked by the API\n- Cost estimates are calculated locally using published pricing\n\n### Upload Features\n\n**Intelligent Caching**:\n- **Local Cache**: Automatically tracks uploaded files at `~/.config/gemini-file-search-tool/stores/`\n- **Per-Store Isolation**: Each store maintains its own cache file (e.g., `fileSearchStores__my-store.json`)\n- **mtime Optimization**: O(n) ‚Üí O(1) performance - checks file modification time before computing expensive SHA256 hash\n- **Smart Re-uploads**: Only uploads files that have actually changed (skips identical files automatically)\n- **Cache Structure**: Stores hash, mtime, remote_id, and last_uploaded timestamp for each file\n- **Performance Impact**:\n  - **Large codebases (1000 files)**: Cache check ~0.1 seconds vs ~5-10 seconds without cache\n  - **Network I/O remains the bottleneck**: Upload time (5-10s per file) dominates hash calculation (500ms)\n  - See `docs/cache-design.md` for detailed performance analysis and architecture\n\n**Automatic File Validation**:\n- **Empty Files**: 0-byte files automatically skipped with warning\n- **File Size**: 50MB limit enforced\n- **Base64 Images**: Detects base64-encoded images in text files (can cause upload failures)\n- **System Files**: Auto-skips `__pycache__`, `.pyc`, `.DS_Store`, etc.\n- **Gitignore Support**: Automatically respects `.gitignore` patterns (use `--ignore-gitignore` to disable)\n- **MIME Types**: Automatic registration for `.toml`, `.env`, `.txt`, `.md` files\n\n**Duplicate Detection**:\n- Automatically detects existing files by name and size\n- Skips unchanged files (no re-upload)\n- Updates files when size changes (deletes old, uploads new)\n\n**Preview & Control**:\n- **Dry-Run**: Use `--dry-run` to preview which files would be uploaded without actually uploading\n- **Skip Validation**: Use `--skip-validation` to bypass checks for faster uploads\n- **Ignore Gitignore**: Use `--ignore-gitignore` to upload files normally excluded by .gitignore\n\n### Dry-Run Mode\n\nPreview which files would be uploaded without actually uploading:\n\n```bash\n# Preview files with sizes\ngemini-file-search-tool upload \"**/*.py\" --store \"code\" --dry-run -v\n\n# Output (to stderr):\n# [INFO] Loaded 38 patterns from .gitignore\n# [INFO] DRY-RUN: Would upload 13 file(s)\n\n# Output (to stdout - JSON):\n[\n  {\n    \"file\": \"/path/to/file1.py\",\n    \"size_bytes\": 1809,\n    \"size_mb\": 0.0\n  },\n  {\n    \"file\": \"/path/to/file2.py\",\n    \"size_bytes\": 2691,\n    \"size_mb\": 0.0\n  }\n]\n```\n\n**Benefits**:\n- **Preview Files**: See exactly which files match your glob pattern\n- **Verify Gitignore**: Confirm .gitignore filtering is working correctly\n- **Check Sizes**: Review file sizes before uploading\n- **No API Calls**: Completely safe, no interaction with Gemini API\n\n### Verbosity Levels\n\nAll commands support multi-level verbosity for controlling log output detail:\n\n| Flag | Level | Description | Use Case |\n|------|-------|-------------|----------|\n| (none) | WARNING | Only critical errors | Production, clean output |\n| `-v` | INFO | High-level operations | See progress, identify failures |\n| `-vv` | DEBUG | Detailed operations | Debug issues, see API calls |\n| `-vvv` | TRACE | Full API details | Deep debugging, HTTP traces |\n\n**Examples:**\n\n```bash\n# INFO level: See which files are uploaded/failed\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -v\n\n# DEBUG level: See validation, polling, API operations\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vv\n\n# TRACE level: See full HTTP requests/responses from SDK\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vvv\n```\n\n**Output:**\n\n```bash\n# With -v (INFO)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[INFO] Upload completed successfully: document.pdf\n\n# With -vv (DEBUG)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[DEBUG] Validating file: document.pdf\n[DEBUG] File validation passed: document.pdf\n[DEBUG] Starting upload operation for: document.pdf\n[DEBUG] Operation started: operations/upload-abc123\n[DEBUG] Polling operation operations/upload-abc123 (attempt 1) - waiting 2.0s\n[DEBUG] Polling operation operations/upload-abc123 (attempt 2) - waiting 3.0s\n[INFO] Upload completed successfully: document.pdf\n\n# With -vvv (TRACE) - includes all above plus:\n[DEBUG] (httpx) HTTP Request: POST https://...\n[DEBUG] (httpx) HTTP Response: 200 OK\n```\n\n**Benefits:**\n- **Real-time Feedback**: See progress and failures as they happen (not just in final JSON)\n- **Progressive Detail**: Choose the right level of verbosity for your needs\n- **Clean stdout**: All logs go to stderr, keeping JSON output clean for piping\n- **Library Logging**: At `-vvv`, see internals from `httpx`, `google-api-core`, etc.\n\n### Cache Management\n\nThe CLI provides commands to manage the local cache for asynchronous upload operations and cache maintenance.\n\n#### Asynchronous Uploads\n\nUse `--no-wait` to skip operation polling and return immediately after initiating uploads:\n\n```bash\n# Fast async uploads (don't wait for completion)\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" --no-wait -v\n\n# Output: Returns immediately with \"pending\" status\n[\n  {\"file\": \"doc1.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"},\n  {\"file\": \"doc2.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"}\n]\n```\n\n**Benefits**:\n- **Faster Returns**: No polling overhead (~2-10s per file saved)\n- **Bulk Operations**: Initiate thousands of uploads quickly\n- **Fire-and-Forget**: Useful for known-working file types where immediate feedback isn't needed\n- **Last-One-Wins**: Re-uploading a file automatically overwrites previous pending operations\n\n**Trade-offs**:\n- No immediate status (success/failure unknown until synced)\n- Requires manual `sync-cache` to check final status\n\n#### Sync Cache\n\nCheck status of pending operations and update cache with final results:\n\n```bash\n# Sync all pending operations for a store\ngemini-file-search-tool sync-cache --store \"docs\" -v\n\n# With custom number of workers (default: 4)\ngemini-file-search-tool sync-cache --store \"docs\" --num-workers 8 -v\n\n# Output (JSON - default):\n{\n  \"status\": \"success\",\n  \"total\": 10,\n  \"synced\": 8,\n  \"failed\": 1,\n  \"still_pending\": 1,\n  \"operations\": [\n    {\"file\": \"doc1.pdf\", \"status\": \"synced\", \"remote_id\": \"documents/...\"},\n    {\"file\": \"doc2.pdf\", \"status\": \"failed\", \"error\": {\"message\": \"...\"}}\n  ]\n}\n\n# Human-readable text output\ngemini-file-search-tool sync-cache --store \"docs\" --text\n\n# Output (text):\nSync Summary:\n  Total operations: 10\n  Synced: 8\n  Failed: 1\n  Still pending: 1\n```\n\n**Features**:\n- **Parallel Processing**: Fetches operation status concurrently with configurable workers (default: 4)\n- **Batch Cache Writes**: Collects all updates and writes cache once at the end (not per-operation)\n- **Progress Bar**: Visual feedback with tqdm during sync\n- **Error Details**: Captures and stores error messages from failed operations\n- **Automatic Updates**: Updates cache with remote_id when operations complete successfully\n- **Idempotent**: Safe to run multiple times (only updates changed operations)\n\n#### Cache Report\n\nGenerate reports on cache status with filtering options:\n\n```bash\n# Default report (summary + pending operations)\ngemini-file-search-tool cache-report --store \"docs\"\n\n# Show only failed operations\ngemini-file-search-tool cache-report --store \"docs\" --errors-only\n\n# Show only completed uploads\ngemini-file-search-tool cache-report --store \"docs\" --completed-only\n\n# Show all cached files\ngemini-file-search-tool cache-report --store \"docs\" --all\n\n# Human-readable text output\ngemini-file-search-tool cache-report --store \"docs\" --text\n```\n\n**Output Example (JSON)**:\n```json\n{\n  \"store\": \"docs\",\n  \"stats\": {\n    \"total_files\": 100,\n    \"completed\": 95,\n    \"pending_operations\": 3,\n    \"failed_operations\": 2\n  },\n  \"files\": [\n    {\n      \"file\": \"/path/to/doc.pdf\",\n      \"status\": \"pending\",\n      \"operation\": \"operations/...\",\n      \"hash\": \"abc123...\",\n      \"mtime\": 1731969000.0\n    }\n  ]\n}\n```\n\n**Filters**:\n- `--pending-only`: Show only files with pending operations\n- `--errors-only`: Show only files with errors\n- `--completed-only`: Show only successfully uploaded files\n- `--all`: Show all cached files (overrides other filters)\n- `--text`: Human-readable text format instead of JSON\n\n#### Flush Cache\n\nDelete cache file for a specific store:\n\n```bash\n# Flush with confirmation prompt\ngemini-file-search-tool flush-cache --store \"docs\"\n\n# Output:\nCache statistics for 'docs':\n  Total files: 100\n  Completed: 95\n  Pending operations: 3\n  Failed operations: 2\n\nAre you sure you want to delete this cache? [y/N]:\n\n# Force flush without confirmation\ngemini-file-search-tool flush-cache --store \"docs\" --force\n```\n\n**Use Cases**:\n- **Clean Slate**: Start fresh after major changes\n- **Rebuild Cache**: Use with `upload --rebuild-cache` to re-upload everything\n- **Troubleshooting**: Clear corrupted cache data\n\n#### Cache with Store Deletion\n\nWhen deleting a store, cache statistics are shown and the cache is automatically removed:\n\n```bash\n# Delete store with cache cleanup\ngemini-file-search-tool delete-store \"docs\" --force\n\n# Output shows cache stats before deletion:\n[INFO] Cache found for store 'docs':\n[INFO]   Total files: 100\n[INFO]   Completed: 95\n[INFO]   Pending operations: 3\n[INFO]   Failed operations: 2\n[INFO] Deleting store: fileSearchStores/docs-123\n[INFO] Removing cache file...\n[INFO] Cache removed successfully\n```\n\n#### Typical Workflows\n\n**Async Upload + Sync Pattern:**\n```bash\n# 1. Fast upload without waiting\ngemini-file-search-tool upload \"docs/**/*.pdf\" --store \"my-docs\" --no-wait -v\n\n# 2. Continue working on other tasks...\n\n# 3. Later, check status\ngemini-file-search-tool sync-cache --store \"my-docs\" -v\n\n# 4. Review any failures\ngemini-file-search-tool cache-report --store \"my-docs\" --errors-only\n```\n\n**Re-upload Changed Files:**\n```bash\n# Upload with last-one-wins strategy\n# If files change and you re-upload, previous pending operations are overwritten\ngemini-file-search-tool upload \"docs/*.pdf\" --store \"my-docs\" --no-wait\n\n# The cache automatically tracks the latest operation-id per file\n```\n\n**Cache Inspection:**\n```bash\n# Quick overview\ngemini-file-search-tool cache-report --store \"my-docs\" --text\n\n# Detailed analysis\ngemini-file-search-tool cache-report --store \"my-docs\" --all | jq .\n```\n\n### Library Usage\n\nYou can also use this package as a Python library:\n\n```python\nfrom pathlib import Path\nfrom gemini_file_search_tool import (\n    create_store,\n    upload_file,\n    query_store,\n    list_documents,\n)\n\n# Create a store\nstore = create_store(\"my-documents\")\nprint(f\"Created store: {store['name']}\")\n\n# Upload a file\nresult = upload_file(\n    file_path=Path(\"document.pdf\"),\n    store_name=store[\"name\"],\n    title=\"Important Document\"\n)\nprint(f\"Upload status: {result['status']}\")\n\n# Query the store\nresponse = query_store(\n    store_name=store[\"name\"],\n    prompt=\"What is in this document?\",\n    model=\"gemini-2.5-flash\"\n)\nprint(response[\"response_text\"])\n\n# List documents\ndocuments = list_documents(store[\"name\"])\nprint(f\"Found {len(documents)} documents\")\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake check            # Run all checks (lint, typecheck, test)\nmake pipeline         # Run full pipeline (format, lint, typecheck, test, build, install-global)\nmake build            # Build package\nmake run ARGS=\"...\"   # Run gemini-file-search-tool locally\nmake clean            # Remove build artifacts\n```\n\n### Project Structure\n\n```\ngemini-file-search-tool/\n‚îú‚îÄ‚îÄ gemini_file_search_tool/    # Main package\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py          # CLI entry point\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Utility functions\n‚îú‚îÄ‚îÄ tests/              # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py\n‚îú‚îÄ‚îÄ pyproject.toml      # Project configuration\n‚îú‚îÄ‚îÄ Makefile            # Development commands\n‚îú‚îÄ‚îÄ README.md           # This file\n‚îú‚îÄ‚îÄ LICENSE             # MIT License\n‚îî‚îÄ‚îÄ CLAUDE.md           # Development documentation\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_utils.py\n\n# Run with coverage\nuv run pytest tests/ --cov=gemini_file_search_tool\n```\n\n## Known Issues\n\n### SDK Bug #1661 - Document Listing with Vertex AI\n\n**Issue**: The Google Generative AI Python SDK has a bug ([#1661](https://github.com/googleapis/python-genai/issues/1661)) where `documents.list()` requires a 'parent' parameter that causes failures.\n\n**Impact**: The `list-documents` command cannot be used with Vertex AI authentication.\n\n**Workaround**: We use the REST API directly instead of the SDK's `documents.list()` method. This workaround only works with the Developer API (requires `GEMINI_API_KEY` or `GOOGLE_API_KEY`).\n\n**Status**: Waiting for upstream fix in the Google Generative AI Python SDK.\n\n**Affected Commands**:\n- `list-documents` - Only works with Developer API, not Vertex AI\n\n**Code Location**: `gemini_file_search_tool/core/documents.py:list_documents()`\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run the full pipeline (`make pipeline`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to the branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints for all functions\n- Write docstrings for public functions\n- Format code with `ruff`\n- Pass all linting and type checks\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n## Resources\n\n### Gemini File Search Documentation\n\n- **[Gemini File Search API Documentation](https://ai.google.dev/gemini-api/docs/file-search)** - Official API documentation and guides\n- **[Gemini API File Search Stores Reference](https://ai.google.dev/api/file-search/file-search-stores)** - API reference for file search stores\n- **[Introducing File Search for the Gemini API](https://blog.google/technology/developers/file-search-gemini-api/)** - Official announcement and overview from Google\n\n### Related Tools\n\n- **[Google Generative AI Python SDK](https://github.com/googleapis/python-genai)** - Python SDK for Google's Gemini API\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "gemini-file-search-tool",
          "source": "./plugins/gemini-file-search-tool",
          "description": "Manage Gemini File Search stores and query with RAG",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/gemini-file-search-tool",
            "/plugin install gemini-file-search-tool@gemini-file-search-tool"
          ]
        }
      ]
    },
    {
      "name": "elevenlabs-tts-tool",
      "version": null,
      "description": "Text-to-speech synthesis with ElevenLabs API",
      "repo_full_name": "dnvriend/elevenlabs-tts-tool",
      "repo_url": "https://github.com/dnvriend/elevenlabs-tts-tool",
      "repo_description": "Professional command-line tool for ElevenLabs text-to-speech synthesis with human-friendly voice selection",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-07T07:32:59Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"elevenlabs-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dnvriend@gmail.com\",\n        \"url\": \"https://github.com/dnvriend/elevenlabs-tts-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"elevenlabs-tts-tool\",\n            \"source\": \"./plugins/elevenlabs-tts-tool\",\n            \"description\": \"Text-to-speech synthesis with ElevenLabs API\"\n        }\n    ]\n}\n",
        "README.md": "# elevenlabs-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA command-line tool for ElevenLabs text-to-speech synthesis with human-friendly voice selection.\n\n## Table of Contents\n\n- [About](#about)\n- [Why CLI-First?](#why-cli-first)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n  - [Shell Completion](#shell-completion)\n  - [Verbosity Levels](#verbosity-levels)\n- [Usage](#usage)\n  - [Synthesize Command](#synthesize-command)\n  - [List Voices](#list-voices)\n  - [Update Voices](#update-voices)\n  - [Model Selection](#model-selection)\n  - [Subscription Info](#subscription-info)\n- [Advanced Features](#advanced-features)\n  - [Emotion Control](#emotion-control)\n  - [Pause Control (SSML)](#pause-control-ssml)\n- [Free Tier Limitations](#free-tier-limitations)\n- [Claude Code Integration](#claude-code-integration)\n- [Library Usage](#library-usage)\n- [Development](#development)\n- [Resources](#resources)\n- [License](#license)\n\n## About\n\n### What is ElevenLabs?\n\n[ElevenLabs](https://elevenlabs.io) provides cutting-edge AI voice synthesis technology that generates natural-sounding speech from text. Their Turbo v2.5 model offers fast, high-quality text-to-speech with a wide variety of realistic voices.\n\n### What is elevenlabs-tts-tool?\n\n`elevenlabs-tts-tool` transforms the ElevenLabs API into a professional, composable CLI tool designed for:\n\n- **Agent-Friendly Design**: Structured commands and error messages enable AI agents (like Claude Code) to reason and act effectively in ReAct loops\n- **Composable Architecture**: JSON output to stdout, logs to stderr - perfect for piping and automation\n- **Reusable Building Blocks**: Commands serve as foundations for Claude Code skills, MCP servers, shell scripts, or custom workflows\n- **Dual-Mode Operation**: Use as both CLI tool and Python library\n- **Production Quality**: Type-safe with strict mypy checks, comprehensive tests, and clear error handling with suggested fixes\n\n## Why CLI-First?\n\nTraditional API wrappers force you to write code for every interaction. CLI-first design provides:\n\n1. **Immediate Productivity**: Run commands without writing wrapper code\n2. **Automation Ready**: Pipe commands together in shell scripts\n3. **Agent Integration**: AI agents can invoke commands directly\n4. **Human & Machine Friendly**: Works equally well for developers and automation\n\n## Use Cases\n\n- üéôÔ∏è **Voice Notifications**: Add TTS to CI/CD pipelines and monitoring systems\n- üìö **Content Creation**: Generate audiobooks, podcasts, and video narration\n- ü§ñ **AI Agent Integration**: Build voice-enabled Claude Code skills and MCP servers\n- üõ†Ô∏è **Development Workflows**: Create audio alerts for long-running processes\n- üéØ **Accessibility**: Convert text content to audio for accessibility features\n- üîä **Testing**: Test voice UIs and audio systems\n- üîî **Claude Code Hooks**: Use as notification system for Claude Code events (see [Claude Code Integration](#claude-code-integration))\n\n## Features\n\n- ‚úÖ **Two Synthesis Modes**: Play through speakers or save to audio file\n- ‚úÖ **8 TTS Models**: Choose from quality, speed, or emotional expression models\n- ‚úÖ **42 Premium Voices**: Curated selection with human-friendly names (rachel, adam, charlotte, etc.)\n- ‚úÖ **Voice & Model Discovery**: List voices and models with characteristics\n- ‚úÖ **Emotional Expression**: Use `[happy]`, `[sad]`, etc. tags with v3 model\n- ‚úÖ **Flexible Input**: Accept text from arguments or stdin (pipe support)\n- ‚úÖ **CLI & Library**: Use as command-line tool or import as Python library\n- ‚úÖ **Type Safety**: Strict mypy checks throughout\n- ‚úÖ **Comprehensive Tests**: Full test coverage with pytest\n- ‚úÖ **Agent-Friendly Errors**: Clear error messages with suggested fixes\n- ‚úÖ **Modern Tooling**: Built with uv, mise, click, and Python 3.13+\n\n## Installation\n\n### Prerequisites\n\n- Python 3.13 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- ElevenLabs API key ([get yours here](https://elevenlabs.io/app/settings/api-keys))\n- **macOS users**: [FFmpeg](https://ffmpeg.org/) for audio playback\n\n```bash\n# macOS: Install FFmpeg via Homebrew\nbrew install ffmpeg\n\n# Linux: Install via package manager\nsudo apt-get install ffmpeg  # Debian/Ubuntu\nsudo yum install ffmpeg      # RedHat/CentOS\n```\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/elevenlabs-tts-tool.git\ncd elevenlabs-tts-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Verify installation\n\n```bash\nelevenlabs-tts-tool --version\n```\n\n## Configuration\n\n### Set API Key\n\n```bash\n# Export API key (required for all commands)\nexport ELEVENLABS_API_KEY='your-api-key-here'\n\n# Or add to your shell profile (~/.zshrc, ~/.bashrc)\necho 'export ELEVENLABS_API_KEY=\"your-api-key\"' >> ~/.zshrc\n```\n\nGet your API key from: https://elevenlabs.io/app/settings/api-keys\n\n### Shell Completion\n\nEnable tab completion for bash, zsh, or fish shells:\n\n**Bash** (add to `~/.bashrc`):\n```bash\neval \"$(elevenlabs-tts-tool completion bash)\"\n```\n\n**Zsh** (add to `~/.zshrc`):\n```bash\neval \"$(elevenlabs-tts-tool completion zsh)\"\n```\n\n**Fish** (save to completion file):\n```bash\nmkdir -p ~/.config/fish/completions\nelevenlabs-tts-tool completion fish > ~/.config/fish/completions/elevenlabs-tts-tool.fish\n```\n\n**For better performance**, save completion to a file:\n```bash\n# Bash\nelevenlabs-tts-tool completion bash > ~/.elevenlabs-tts-tool-complete.bash\necho 'source ~/.elevenlabs-tts-tool-complete.bash' >> ~/.bashrc\n\n# Zsh\nelevenlabs-tts-tool completion zsh > ~/.elevenlabs-tts-tool-complete.zsh\necho 'source ~/.elevenlabs-tts-tool-complete.zsh' >> ~/.zshrc\n```\n\nOnce installed, you can tab-complete commands, options, and even voice names!\n\n### Verbosity Levels\n\nControl logging output with progressive verbosity levels:\n\n```bash\n# Default (WARNING only) - quiet mode\nelevenlabs-tts-tool synthesize \"Hello world\"\n\n# -v (INFO) - show high-level operations\nelevenlabs-tts-tool -v synthesize \"Hello world\"\n\n# -vv (DEBUG) - show detailed steps, API calls, validation\nelevenlabs-tts-tool -vv synthesize \"Hello world\"\n\n# -vvv (TRACE) - show full API requests/responses, library internals\nelevenlabs-tts-tool -vvv synthesize \"Hello world\"\n```\n\n**Verbosity Breakdown:**\n- **No flag** (default): Only warnings and errors\n- **`-v`**: INFO level - operation status, file names, progress\n- **`-vv`**: DEBUG level - validation steps, API call details, timing\n- **`-vvv`**: TRACE level - full HTTP requests/responses, ElevenLabs SDK internals\n\n**Note:** Verbosity applies to all commands:\n```bash\nelevenlabs-tts-tool -v list-voices      # INFO level\nelevenlabs-tts-tool -vv list-models     # DEBUG level\nelevenlabs-tts-tool -vvv info           # TRACE level with API details\n```\n\n## Usage\n\n### Synthesize Command\n\nConvert text to speech with various options:\n\n```bash\n# Basic usage - play through speakers\nelevenlabs-tts-tool synthesize \"Hello world\"\n\n# Use a different voice\nelevenlabs-tts-tool synthesize \"Hello world\" --voice adam\nelevenlabs-tts-tool synthesize \"Cheerio mate\" --voice charlotte\n\n# Read from stdin\necho \"Hello from stdin\" | elevenlabs-tts-tool synthesize --stdin\ncat article.txt | elevenlabs-tts-tool synthesize --stdin\n\n# Save to MP3 file (default format)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.mp3\n\n# Save to WAV file (PCM format)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.wav --format pcm_24000\n\n# Lower quality MP3 (smaller file size)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.mp3 --format mp3_22050_32\n\n# Combine options\ncat blog-post.txt | elevenlabs-tts-tool synthesize --stdin \\\n    --voice rachel --output narration.mp3 --format mp3_44100_128\n```\n\n#### Output Formats\n\nThe `--format` option controls audio quality and file size. Different formats require different ElevenLabs subscription tiers:\n\n**Available on all tiers:**\n- `mp3_44100_128` - MP3 at 44.1kHz, 128kbps (default, ~17KB for short text)\n- `mp3_22050_32` - MP3 at 22.05kHz, 32kbps (lower quality, ~6KB for short text)\n- `pcm_16000` - PCM/WAV at 16kHz\n- `pcm_22050` - PCM/WAV at 22.05kHz\n- `pcm_24000` - PCM/WAV at 24kHz (~67KB for short text)\n- `ulaw_8000` - Œº-law at 8kHz (for Twilio)\n\n**Creator tier and above:**\n- `mp3_44100_192` - MP3 at 44.1kHz, 192kbps (higher quality)\n\n**Pro tier and above:**\n- `pcm_44100` - PCM/WAV at 44.1kHz (highest quality, largest file size)\n\n**Examples:**\n```bash\n# Default MP3 (works on all tiers)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.mp3\n\n# High-quality WAV (Pro tier required)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.wav --format pcm_44100\n\n# Lower bandwidth (works on all tiers)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.mp3 --format mp3_22050_32\n```\n\n### List Voices\n\nDiscover available voices with characteristics:\n\n```bash\n# List all 42 available voices\nelevenlabs-tts-tool list-voices\n\n# Find specific voices with grep\nelevenlabs-tts-tool list-voices | grep British\nelevenlabs-tts-tool list-voices | grep \"female.*young\"\nelevenlabs-tts-tool list-voices | grep male\n```\n\n**Popular Voices:**\n- `rachel` - Calm and friendly American female (default)\n- `adam` - Deep, authoritative American male\n- `charlotte` - Seductive and calm British female\n- `antoni` - Well-rounded American male\n- `bella` - Soft and pleasant American female\n- `daniel` - Deep and authoritative British male\n\n### Update Voices\n\nUpdate the voice lookup table from ElevenLabs API:\n\n```bash\n# Update default voice lookup (saves to ~/.config/elevenlabs-tts-tool/)\nelevenlabs-tts-tool update-voices\n\n# Save to custom location\nelevenlabs-tts-tool update-voices --output custom_voices.json\n```\n\nThe voice lookup is stored in `~/.config/elevenlabs-tts-tool/voices_lookup.json` and takes precedence over the package default.\n\n### Model Selection\n\nElevenLabs offers multiple TTS models optimized for different use cases. Use the `--model` option with the `synthesize` command to select a model.\n\n#### List Available Models\n\n```bash\n# Show all available models with characteristics\nelevenlabs-tts-tool list-models\n```\n\n#### Current Generation Models\n\n**Eleven Turbo v2.5** (Default) - `eleven_turbo_v2_5`\n- Balanced quality and speed (~250ms latency)\n- 32 languages, 40,000 char limit\n- 50% cheaper per character\n- **Best for:** General-purpose TTS\n\n```bash\nelevenlabs-tts-tool synthesize \"Hello world\" --model eleven_turbo_v2_5\n```\n\n**Eleven Multilingual v2** - `eleven_multilingual_v2`\n- Highest production quality\n- 29 languages, 10,000 char limit\n- Medium latency\n- **Best for:** Professional content, e-learning\n\n```bash\nelevenlabs-tts-tool synthesize \"Professional narration\" --model eleven_multilingual_v2\n```\n\n**Eleven Flash v2.5** - `eleven_flash_v2_5`\n- Ultra-low latency (~75ms)\n- 32 languages, 40,000 char limit\n- 50% cheaper per character\n- **Best for:** Real-time agents, bulk processing\n\n```bash\nelevenlabs-tts-tool synthesize \"Quick response\" --model eleven_flash_v2_5\n```\n\n**Eleven v3 (Alpha)** - `eleven_v3`\n- Most emotionally expressive\n- 70+ languages, 5,000 char limit\n- Higher latency\n- **Best for:** Emotional dialogue, audiobooks\n- **Note:** Supports emotional tags (`[happy]`, `[sad]`, etc.)\n\n```bash\nelevenlabs-tts-tool synthesize \"[happy] Welcome!\" --model eleven_v3\n```\n\n#### Model Selection Examples\n\n```bash\n# Use highest quality model\nelevenlabs-tts-tool synthesize \"Professional presentation\" \\\n    --voice rachel --model eleven_multilingual_v2\n\n# Ultra-fast real-time generation\nelevenlabs-tts-tool synthesize \"Quick notification\" \\\n    --voice adam --model eleven_flash_v2_5\n\n# Emotional expression (requires v3)\nelevenlabs-tts-tool synthesize \"[excited] Congratulations!\" \\\n    --voice charlotte --model eleven_v3 --output celebration.mp3\n\n# Pipe with model selection\necho \"Article content\" | elevenlabs-tts-tool synthesize --stdin \\\n    --voice daniel --model eleven_multilingual_v2 --output article.mp3\n```\n\n#### Legacy Models\n\nThe following models are deprecated but still available:\n- `eleven_turbo_v2` - Superseded by Turbo v2.5 (50% cost savings)\n- `eleven_flash_v2` - Superseded by Flash v2.5\n- `eleven_monolingual_v1` - English-only (use `eleven_multilingual_v2` instead)\n- `eleven_multilingual_v1` - Use `eleven_multilingual_v2` instead\n\n**Warning:** Using deprecated models will show a deprecation notice. Migrate to current generation models for better performance and pricing.\n\nFor detailed model information, see: [references/models.md](references/models.md)\n\n### Subscription Info\n\nView your ElevenLabs subscription status and usage statistics:\n\n```bash\n# View subscription info with last 7 days of usage\nelevenlabs-tts-tool info\n\n# View last 30 days of usage\nelevenlabs-tts-tool info --days 30\n\n# Quick quota check\nelevenlabs-tts-tool info --days 1\n```\n\n**Information Displayed:**\n- **Subscription Details:** Tier, status, voice slots, currency\n- **Character Usage:** Used/limit/remaining with percentage and visual bar\n- **Quota Reset:** When your character quota resets\n- **Historical Usage:** Daily usage breakdown for specified period\n- **Usage Statistics:** Average daily usage and projected monthly consumption\n- **Warnings:** Alerts when approaching quota limits (>75% or >90%)\n\n**Example Output:**\n```\n================================================================================\nElevenLabs Subscription Information\n================================================================================\n\nTier:           Free\nStatus:         Active\n\nCharacter Usage:\n  Used:         8,543 characters\n  Limit:        10,000 characters\n  Remaining:    1,457 characters\n  Percentage:   85.4%\n  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë]\n\nQuota Resets:   2025-11-22 00:00:00\n                (Friday, November 22, 2025)\n\nVoice Slots:    3\nCurrency:       USD\n\n================================================================================\nHistorical Usage (Last 7 Days)\n================================================================================\n\nDate            Characters Used      Bar\n--------------------------------------------------------------------------------\n2025-11-15           1,234 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n2025-11-14             892 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n2025-11-13           1,567 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n...\n--------------------------------------------------------------------------------\nTotal:               8,543 chars\n\nAverage daily usage: 1,220 characters\nProjected monthly:   36,600 characters\n\n================================================================================\n```\n\n**Use Cases:**\n- Monitor character quota consumption\n- Track usage patterns over time\n- Plan when to upgrade subscription tier\n- Avoid hitting quota limits unexpectedly\n- Understand daily/monthly usage trends\n\n## Advanced Features\n\n### Emotion Control\n\nElevenLabs v3 model (`eleven_v3`) supports emotional tags for expressive speech:\n\n```bash\n# Happy greeting (requires eleven_v3 model)\nelevenlabs-tts-tool synthesize \"[happy] Welcome! We're excited to have you here.\" --model eleven_v3\n\n# Sad message\nelevenlabs-tts-tool synthesize \"[sad] I'm sorry to hear that...\" --model eleven_v3\n\n# Excited announcement\nelevenlabs-tts-tool synthesize \"[excited] Amazing news! Your project is approved!\" --model eleven_v3\n```\n\n**Available Emotions:** `[happy]`, `[excited]`, `[sad]`, `[angry]`, `[nervous]`, `[curious]`, `[cheerfully]`, `[playfully]`, `[mischievously]`, `[resigned tone]`, `[flatly]`, `[deadpan]`\n\n**Speech Characteristics:** `[whispers]`, `[laughs]`, `[gasps]`, `[sighs]`, `[pauses]`, `[hesitates]`, `[stammers]`\n\n**Important:** Emotional tags only work with the `eleven_v3` model. They will be ignored on other models (v2.5, v2, etc.).\n\n### Pause Control (SSML)\n\nAdd natural pauses using SSML break tags:\n\n```bash\n# Add 1-second pause\nelevenlabs-tts-tool synthesize \"Welcome <break time=\\\"1.0s\\\" /> to our service.\"\n\n# Multiple pauses\nelevenlabs-tts-tool synthesize \"First point <break time=\\\"0.5s\\\" /> Second point <break time=\\\"0.5s\\\" /> Third point.\"\n```\n\n**Note:** Keep pauses under 3 seconds and limit to 2-4 breaks per generation for best results.\n\n### Combining Emotions and Pauses\n\n```bash\n# Emotional speech with pauses\nelevenlabs-tts-tool synthesize \"[happy] Good morning! <break time=\\\"0.5s\\\" /> [cheerfully] I hope you're having a great day.\"\n```\n\nFor comprehensive documentation on emotions, pauses, SSML, and voice settings, see:\n- [Emotions and Pauses Guide](references/emotions-and-pauses.md)\n\n## Free Tier Limitations\n\n**ElevenLabs Free Tier:**\n- ‚úÖ 10,000-20,000 characters per month (as of 2024-2025)\n- ‚úÖ Access to all 42 premade voices\n- ‚úÖ Create up to 3 custom voices\n- ‚úÖ MP3 formats (all bitrates)\n- ‚úÖ Basic SSML support\n- ‚úÖ Emotional tags (v3 models)\n- ‚ùå No commercial license\n- ‚ùå PCM 44.1kHz format requires Pro tier\n- ‚ö†Ô∏è Max 2,500 characters per single generation\n\n**Recommended for:**\n- Personal projects\n- Experimentation\n- Development and testing\n- Non-commercial use\n\nFor detailed free tier information and upgrade options, see:\n- [Free Tier Research](references/free-tier.md)\n- [ElevenLabs Pricing](https://elevenlabs.io/pricing)\n\n## Claude Code Integration\n\nUse `elevenlabs-tts-tool` as a notification system for Claude Code hooks to get audio alerts when tasks complete.\n\n### Setup Hook\n\nCreate a notification hook in `~/.config/claude-code/hooks.json`:\n\n```json\n{\n  \"hooks\": {\n    \"after_command\": {\n      \"type\": \"bash\",\n      \"command\": \"elevenlabs-tts-tool synthesize \\\"[happy] Task completed successfully!\\\" --voice rachel\"\n    },\n    \"on_error\": {\n      \"type\": \"bash\",\n      \"command\": \"elevenlabs-tts-tool synthesize \\\"[nervous] Error detected. Please check the output.\\\" --voice adam\"\n    }\n  }\n}\n```\n\n### Use Cases\n\n**Task Completion Alerts:**\n```bash\n# After long-running build\nelevenlabs-tts-tool synthesize \"[excited] Build completed!\" --voice rachel\n```\n\n**Error Notifications:**\n```bash\n# On test failure\nelevenlabs-tts-tool synthesize \"[sad] Tests failed. Please review.\" --voice adam\n```\n\n**Custom Workflows:**\n```bash\n# In your shell scripts\nmake build && elevenlabs-tts-tool synthesize \"[cheerfully] Build successful!\" || \\\n    elevenlabs-tts-tool synthesize \"[nervous] Build failed!\"\n```\n\n**Integration with Other Tools:**\n```bash\n# Combine with gemini-google-search-tool\ngemini-google-search-tool query \"Latest AI news\" | \\\n    elevenlabs-tts-tool synthesize --stdin --voice charlotte --output news-summary.mp3\n```\n\nThis allows you to:\n- Get audio alerts for completed tasks without monitoring the terminal\n- Hear error notifications while away from the screen\n- Create multi-step automation workflows with voice feedback\n- Build voice-enabled AI agent pipelines\n\n### Output Styles\n\nClaude Code supports custom output styles via `.claude/output-styles/` directory. Output styles allow you to customize how Claude Code responds to your requests. For comprehensive examples, see the [Claude Code Hooks Mastery repository](https://github.com/disler/claude-code-hooks-mastery/tree/main/.claude/output-styles).\n\n#### TTS Summary Output Style\n\nThe **TTS Summary** output style provides audio task completion announcements using `elevenlabs-tts-tool`. This creates a voice-enabled assistant experience where Claude Code speaks to you about what it accomplished.\n\n**How it works:**\n1. Claude Code responds normally to all requests\n2. At the end of every response, it adds an audio summary\n3. The summary is synthesized using `elevenlabs-tts-tool synthesize`\n4. You hear what was accomplished without monitoring the terminal\n\n**Example Output Style Configuration:**\n\nCreate `.claude/output-styles/tts-summary.md`:\n\n```markdown\n---\nname: TTS Summary\ndescription: Audio task completion announcements with TTS\n---\n\n# TTS Summary Output Style\n\nYou are Claude Code with an experimental TTS announcement feature designed to communicate directly with the user about what you've accomplished.\n\n## Standard Behavior\nRespond normally to all user requests, using your full capabilities for:\n- Code generation and editing\n- File operations\n- Running commands\n- Analysis and explanations\n- All standard Claude Code features\n\n## Critical Addition: Audio Task Summary\n\n**At the very END of EVERY response**, you MUST provide an audio summary for the user and run a Bash tool:\n\n```bash\nelevenlabs-tts-tool synthesize \"SUMMARY_TO_THE_USER\"\n```\n\n## Important Rules\n\n- ALWAYS include the audio summary, even for simple queries\n- ALWAYS suggest 2-3 relevant next steps after task completion\n- Report task completion status with technical precision\n- Use efficient, direct language - no conversational elaboration\n- Focus on specifications achieved and functionality delivered\n- Report as status update, not personal communication\n- Execute the command using the Bash tool, DO NOT show it on the CLI\n```\n\n**Activate the output style:**\n```bash\n# In Claude Code CLI\n/output-style\n# Select \"TTS Summary\" from the list\n```\n\n**Benefits:**\n- ‚úÖ Audio notifications for completed tasks\n- ‚úÖ Stay informed without watching the terminal\n- ‚úÖ Natural, conversational feedback\n- ‚úÖ Perfect for long-running tasks or multi-step workflows\n- ‚úÖ Voice-enabled AI assistant experience\n\n**Note:** This feature requires `elevenlabs-tts-tool` to be installed and configured with your API key.\n\n### Voice-Enabled Workflow with SuperWhisper\n\nCombine `elevenlabs-tts-tool` with [Claude Code](https://www.anthropic.com/claude/code) and [SuperWhisper](https://superwhisper.com/) for a complete voice-enabled development workflow.\n\n**The Power Trio:**\n1. **SuperWhisper** - Voice input: Speak commands to Claude Code\n2. **Claude Code** - AI assistance: Execute tasks and generate code\n3. **elevenlabs-tts-tool** - Voice output: Get audio notifications when tasks complete\n\n**Why This Works:**\n\nSpeaking is **faster than typing**. Instead of typing long commands or descriptions:\n```bash\n# Traditional typing (slow):\n\"Create a new Python function that parses JSON files and extracts all email addresses...\"\n\n# Voice with SuperWhisper (fast):\nüé§ Just speak naturally and SuperWhisper transcribes instantly\n```\n\n**Perfect For:**\n- üèÉ **Long-Running Tasks**: Start a build with voice, get audio notification when done\n- üîÑ **Multi-Step Workflows**: Chain tasks with voice commands, hear progress updates\n- üíª **Hands-Free Development**: Code while away from keyboard, get notified when ready\n- üéØ **Context Switching**: Start tasks via voice, move to other work, return on audio alert\n\n**Example Workflow:**\n```bash\n# 1. Speak to SuperWhisper: \"Run the test suite and let me know when it's done\"\n# 2. Claude Code executes: pytest tests/\n# 3. elevenlabs-tts-tool announces: \"[happy] All tests passed! 47 tests completed.\"\n\n# 4. Speak: \"Now build the Docker image and push to registry\"\n# 5. Claude Code executes: docker build && docker push\n# 6. elevenlabs-tts-tool announces: \"[excited] Docker image built and pushed successfully!\"\n```\n\n**Setup:**\n1. Install [SuperWhisper](https://superwhisper.com/) (macOS voice-to-text)\n2. Configure Claude Code with TTS Summary output style (see above)\n3. Use voice commands to control Claude Code\n4. Receive audio notifications on task completion\n\n**Benefits:**\n- ‚úÖ **10x faster input** - Speak naturally instead of typing\n- ‚úÖ **Hands-free operation** - No keyboard required for basic tasks\n- ‚úÖ **Multitasking enabled** - Start tasks, switch context, return on notification\n- ‚úÖ **Reduced cognitive load** - Voice is more natural than typing technical commands\n- ‚úÖ **Accessibility** - Works great for users with typing difficulties\n\n**Note:** SuperWhisper is currently macOS-only. For other platforms, consider [Whisper Desktop](https://github.com/Const-me/Whisper) or similar voice input tools.\n\n## Library Usage\n\nUse `elevenlabs-tts-tool` as a Python library in your projects:\n\n```python\nfrom elevenlabs_tts_tool import get_client, play_speech, save_speech\nfrom elevenlabs_tts_tool import VoiceManager\nfrom pathlib import Path\n\n# Initialize client\nclient = get_client()\n\n# Get voice ID\nvoice_manager = VoiceManager()\nvoice_id = voice_manager.get_voice_id(\"rachel\")\n\n# Play through speakers\nplay_speech(client, \"Hello from Python\", voice_id)\n\n# Save to file\nsave_speech(client, \"Save this\", voice_id, Path(\"output.wav\"))\n\n# List available voices\nfor name, profile in voice_manager.list_voices():\n    print(f\"{name}: {profile.description}\")\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/elevenlabs-tts-tool.git\ncd elevenlabs-tts-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake check            # Run all checks (lint, typecheck, test)\nmake pipeline         # Run full pipeline (format, check, build, install-global)\nmake build            # Build package\nmake clean            # Remove build artifacts\n```\n\n### Project Structure\n\n```\nelevenlabs-tts-tool/\n‚îú‚îÄ‚îÄ elevenlabs_tts_tool/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Public API exports\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py                   # CLI entry point\n‚îÇ   ‚îú‚îÄ‚îÄ voices.py                # Voice management\n‚îÇ   ‚îú‚îÄ‚îÄ voices_lookup.json       # Voice lookup table (42 voices)\n‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Core library functions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py           # ElevenLabs client\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ synthesize.py       # TTS functions\n‚îÇ   ‚îî‚îÄ‚îÄ commands/                # CLI commands\n‚îÇ       ‚îú‚îÄ‚îÄ synthesize_commands.py\n‚îÇ       ‚îî‚îÄ‚îÄ voice_commands.py\n‚îú‚îÄ‚îÄ tests/                       # Test suite\n‚îú‚îÄ‚îÄ pyproject.toml               # Project configuration\n‚îú‚îÄ‚îÄ Makefile                     # Development commands\n‚îî‚îÄ‚îÄ CLAUDE.md                    # Developer guide\n```\n\n## Resources\n\n- **ElevenLabs Documentation**: https://elevenlabs.io/docs\n- **API Reference**: https://elevenlabs.io/docs/api-reference\n- **Python SDK**: https://github.com/elevenlabs/elevenlabs-python\n- **Voice Library**: https://elevenlabs.io/voice-library\n- **Get API Key**: https://elevenlabs.io/app/settings/api-keys\n- **Claude Code Hooks Mastery**: https://github.com/disler/claude-code-hooks-mastery - Comprehensive guide to Claude Code hooks and output styles\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- [ElevenLabs](https://elevenlabs.io) for world-class TTS technology\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.13+\n"
      },
      "plugins": [
        {
          "name": "elevenlabs-tts-tool",
          "source": "./plugins/elevenlabs-tts-tool",
          "description": "Text-to-speech synthesis with ElevenLabs API",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/elevenlabs-tts-tool",
            "/plugin install elevenlabs-tts-tool@elevenlabs-tts-tool"
          ]
        }
      ]
    },
    {
      "name": "slack-messaging-tool",
      "version": null,
      "description": "Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool",
      "repo_full_name": "dnvriend/slack-messaging-tool",
      "repo_url": "https://github.com/dnvriend/slack-messaging-tool",
      "repo_description": "slack-messaging-tool",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-26T07:42:46Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"slack-messaging-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"slack-messaging-tool\",\n            \"source\": \"./plugins/slack-messaging-tool\",\n            \"description\": \"A Python CLI tool\"\n        }\n    ]\n}\n",
        "README.md": "# slack-messaging-tool\n\n<p align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"slack-messaging-tool logo\" width=\"128\">\n</p>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n\nA CLI tool that provides Slack messaging capabilities via the Slack API.\n\n## Features\n\n- Send messages to Slack channels (by name or ID)\n- Support for Slack Block Kit rich layouts\n- List available channels in workspace\n- Bot token authentication\n- Multi-level verbosity logging\n- OpenTelemetry observability\n- Shell completion (bash, zsh, fish)\n\n## Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/dnvriend/slack-messaging-tool.git\ncd slack-messaging-tool\nuv tool install .\n\n# Verify\nslack-messaging-tool --version\n```\n\n## Usage\n\n```bash\n# Set your bot token\nexport SLACK_BOT_TOKEN=xoxb-your-bot-token\n\n# List channels\nslack-messaging-tool channels\n\n# Send a message\nslack-messaging-tool send -c general -m \"Hello team!\"\n\n# Send with Block Kit\nslack-messaging-tool send -c general -m \"Fallback\" \\\n    --blocks '[{\"type\":\"section\",\"text\":{\"type\":\"mrkdwn\",\"text\":\"*Bold*\"}}]'\n\n# Enable verbose logging\nslack-messaging-tool -v channels\n```\n\n## Environment Variables\n\n| Variable | Required | Default | Description |\n|----------|----------|---------|-------------|\n| `SLACK_BOT_TOKEN` | Yes | - | Slack bot token (xoxb-...) |\n| `OTEL_ENABLED` | No | `false` | Enable OpenTelemetry |\n| `OTEL_EXPORTER_TYPE` | No | `console` | `console` or `otlp` |\n| `OTEL_EXPORTER_OTLP_ENDPOINT` | No | `http://localhost:4317` | OTLP endpoint |\n| `LOG_FILE` | No | - | Path to log file |\n\n## Documentation\n\n- [Logging](references/logging.md) - Multi-level verbosity logging\n- [Telemetry](references/telemetry.md) - OpenTelemetry observability\n- [Shell Completion](references/shell-completion.md) - Tab completion setup\n- [Development](references/development.md) - Contributing guide\n\n## Development\n\n```bash\nmake install    # Install dependencies\nmake test       # Run tests\nmake pipeline   # Full CI pipeline\n```\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Author\n\n**Dennis Vriend** - [@dnvriend](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "slack-messaging-tool",
          "source": "./plugins/slack-messaging-tool",
          "description": "A Python CLI tool",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/slack-messaging-tool",
            "/plugin install slack-messaging-tool@slack-messaging-tool"
          ]
        }
      ]
    },
    {
      "name": "pdf-to-pptx-tool",
      "version": null,
      "description": "Convert PDF documents to PowerPoint presentations",
      "repo_full_name": "dnvriend/pdf-to-pptx-tool",
      "repo_url": "https://github.com/dnvriend/pdf-to-pptx-tool",
      "repo_description": "Professional CLI tool that converts PDF documents into PowerPoint presentations",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-05T06:47:23Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"pdf-to-pptx-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/pdf-to-pptx-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"pdf-to-pptx-tool\",\n            \"source\": \"./plugins/pdf-to-pptx-tool\",\n            \"description\": \"Convert PDF documents to PowerPoint presentations\"\n        }\n    ]\n}\n",
        "README.md": "# pdf-to-pptx-tool\n\n<div align=\"center\">\n  <img src=\".github/assets/logo-web.png\" alt=\"pdf-to-pptx-tool logo\" width=\"200\"/>\n\n  [![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n  [![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n  [![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n  [![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n  [![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n</div>\n\nA professional CLI tool that converts PDF documents into PowerPoint presentations\n\n## Table of Contents\n\n- [About](#about)\n- [Features](#features)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Convert Command](#convert-command)\n- [Multi-Level Verbosity Logging](#multi-level-verbosity-logging)\n- [Shell Completion](#shell-completion)\n- [Development](#development)\n- [Testing](#testing)\n- [Security](#security)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n\n## About\n\n`pdf-to-pptx-tool` is a Python CLI tool built with modern tooling and best practices.\n\n## Features\n\n- üìÑ **PDF to PowerPoint Conversion**: Convert PDF documents to PPTX format\n- üé® **Customizable Quality**: Adjustable DPI (72-600) for quality vs file size\n- üìê **16:9 Slides**: Professional widescreen format (10\" √ó 5.625\")\n- üñºÔ∏è  **Full-Page Images**: Each PDF page becomes a full-slide image\n- üìä **Multi-level Verbosity**: Progressive logging (-v/-vv/-vvv) for debugging\n- üêö **Shell Completion**: Native completion for bash, zsh, and fish\n- ‚úÖ **Type-Safe**: Strict mypy checking for reliability\n- üîí **Security Scanned**: bandit, pip-audit, and gitleaks\n- ‚ö° **Modern Tooling**: Built with Click, uv, and Python 3.14+\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- **poppler** system library (for PDF rendering)\n  ```bash\n  # macOS\n  brew install poppler\n\n  # Ubuntu/Debian\n  sudo apt-get install poppler-utils\n\n  # Fedora\n  sudo dnf install poppler-utils\n  ```\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/pdf-to-pptx-tool.git\ncd pdf-to-pptx-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd pdf-to-pptx-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\npdf-to-pptx-tool --version\n```\n\n## Usage\n\n### Convert PDF to PowerPoint\n\n```bash\n# Basic conversion (default 200 DPI)\npdf-to-pptx-tool convert document.pdf slides.pptx\n\n# High quality conversion (300 DPI)\npdf-to-pptx-tool convert report.pdf presentation.pptx --dpi 300\n\n# With verbose logging to see progress\npdf-to-pptx-tool -v convert input.pdf output.pptx\n\n# With debug logging for troubleshooting\npdf-to-pptx-tool -vv convert problematic.pdf fixed.pptx\n```\n\n### Show Help\n\n```bash\n# General help\npdf-to-pptx-tool --help\n\n# Convert command help\npdf-to-pptx-tool convert --help\n\n# Completion command help\npdf-to-pptx-tool completion --help\n\n# Show version\npdf-to-pptx-tool --version\n```\n\n## Convert Command\n\nThe `convert` command transforms PDF documents into PowerPoint presentations.\n\n### Syntax\n\n```bash\npdf-to-pptx-tool convert INPUT_PDF OUTPUT_PPTX [OPTIONS]\n```\n\n### Arguments\n\n- `INPUT_PDF`: Path to the input PDF file (required)\n- `OUTPUT_PPTX`: Path to the output PowerPoint file (required)\n- `--dpi INTEGER`: Resolution for conversion (default: 200)\n  - Range: 72-600 DPI\n  - Higher DPI = better quality but larger files\n  - Recommended: 200-300 for most presentations\n\n### DPI Quality Guidelines\n\n| DPI | Quality | File Size | Best For |\n|-----|---------|-----------|----------|\n| 72 | Low | Smallest | Quick previews, draft slides |\n| 150 | Medium | Small | Web presentations, email |\n| **200** | **Good** | **Medium** | **Default - recommended for most** |\n| 300 | High | Large | Print quality, detailed diagrams |\n| 600 | Very High | Very Large | Professional print, posters |\n\n### Examples\n\n```bash\n# Basic conversion with default 200 DPI\npdf-to-pptx-tool convert quarterly-report.pdf q4-presentation.pptx\n\n# High quality for detailed diagrams\npdf-to-pptx-tool convert technical-doc.pdf slides.pptx --dpi 300\n\n# Quick preview with lower quality\npdf-to-pptx-tool convert draft.pdf preview.pptx --dpi 150\n\n# Batch conversion\nfor pdf in *.pdf; do\n  pdf-to-pptx-tool convert \"$pdf\" \"${pdf%.pdf}.pptx\"\ndone\n```\n\n### Output Format\n\n- **Aspect Ratio**: 16:9 widescreen\n- **Slide Size**: 10 inches √ó 5.625 inches\n- **Layout**: One full-slide image per PDF page\n- **Image Format**: PNG embedded in slides\n- **Compatibility**: PowerPoint 2007+ (Windows/Mac/Online)\n\n## Multi-Level Verbosity Logging\n\nThe CLI supports progressive verbosity levels for debugging and troubleshooting. All logs output to stderr, keeping stdout clean for data piping.\n\n### Logging Levels\n\n| Flag | Level | Output | Use Case |\n|------|-------|--------|----------|\n| (none) | WARNING | Errors and warnings only | Production, quiet mode |\n| `-v` | INFO | + High-level operations | Normal debugging |\n| `-vv` | DEBUG | + Detailed info, full tracebacks | Development, troubleshooting |\n| `-vvv` | TRACE | + Library internals | Deep debugging |\n\n### Examples\n\n```bash\n# Quiet mode - only errors and warnings\npdf-to-pptx-tool\n\n# INFO - see operations and progress\npdf-to-pptx-tool -v\n# Output:\n# [INFO] pdf-to-pptx-tool started\n# [INFO] pdf-to-pptx-tool completed\n\n# DEBUG - see detailed information\npdf-to-pptx-tool -vv\n# Output:\n# [INFO] pdf-to-pptx-tool started\n# [DEBUG] Running with verbose level: 2\n# [INFO] pdf-to-pptx-tool completed\n\n# TRACE - see library internals (configure in logging_config.py)\npdf-to-pptx-tool -vvv\n```\n\n### Customizing Library Logging\n\nTo enable DEBUG logging for third-party libraries at TRACE level (-vvv), edit `pdf_to_pptx_tool/logging_config.py`:\n\n```python\n# Configure dependent library loggers at TRACE level (-vvv)\nif verbose_count >= 3:\n    logging.getLogger(\"requests\").setLevel(logging.DEBUG)\n    logging.getLogger(\"urllib3\").setLevel(logging.DEBUG)\n    # Add your project-specific library loggers here\n```\n\n## Shell Completion\n\nThe CLI provides native shell completion for bash, zsh, and fish shells.\n\n### Supported Shells\n\n| Shell | Version Requirement | Status |\n|-------|-------------------|--------|\n| **Bash** | ‚â• 4.4 | ‚úÖ Supported |\n| **Zsh** | Any recent version | ‚úÖ Supported |\n| **Fish** | ‚â• 3.0 | ‚úÖ Supported |\n| **PowerShell** | Any version | ‚ùå Not Supported |\n\n### Installation\n\n#### Quick Setup (Temporary)\n\n```bash\n# Bash - active for current session only\neval \"$(pdf-to-pptx-tool completion bash)\"\n\n# Zsh - active for current session only\neval \"$(pdf-to-pptx-tool completion zsh)\"\n\n# Fish - active for current session only\npdf-to-pptx-tool completion fish | source\n```\n\n#### Permanent Setup (Recommended)\n\n```bash\n# Bash - add to ~/.bashrc\necho 'eval \"$(pdf-to-pptx-tool completion bash)\"' >> ~/.bashrc\nsource ~/.bashrc\n\n# Zsh - add to ~/.zshrc\necho 'eval \"$(pdf-to-pptx-tool completion zsh)\"' >> ~/.zshrc\nsource ~/.zshrc\n\n# Fish - save to completions directory\nmkdir -p ~/.config/fish/completions\npdf-to-pptx-tool completion fish > ~/.config/fish/completions/pdf-to-pptx-tool.fish\n```\n\n#### File-based Installation (Better Performance)\n\nFor better shell startup performance, generate completion scripts to files:\n\n```bash\n# Bash\npdf-to-pptx-tool completion bash > ~/.pdf-to-pptx-tool-complete.bash\necho 'source ~/.pdf-to-pptx-tool-complete.bash' >> ~/.bashrc\n\n# Zsh\npdf-to-pptx-tool completion zsh > ~/.pdf-to-pptx-tool-complete.zsh\necho 'source ~/.pdf-to-pptx-tool-complete.zsh' >> ~/.zshrc\n\n# Fish (automatic loading from completions directory)\nmkdir -p ~/.config/fish/completions\npdf-to-pptx-tool completion fish > ~/.config/fish/completions/pdf-to-pptx-tool.fish\n```\n\n### Usage\n\nOnce installed, completion works automatically:\n\n```bash\n# Tab completion for commands\npdf-to-pptx-tool <TAB>\n# Shows: completion\n\n# Tab completion for options\npdf-to-pptx-tool --<TAB>\n# Shows: --verbose --version --help\n\n# Tab completion for shell types\npdf-to-pptx-tool completion <TAB>\n# Shows: bash zsh fish\n```\n\n### Getting Help\n\n```bash\n# View completion installation instructions\npdf-to-pptx-tool completion --help\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/pdf-to-pptx-tool.git\ncd pdf-to-pptx-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install                 # Install dependencies\nmake format                  # Format code with ruff\nmake lint                    # Run linting with ruff\nmake typecheck               # Run type checking with mypy\nmake test                    # Run tests with pytest\nmake security-bandit         # Python security linter\nmake security-pip-audit      # Dependency vulnerability scanner\nmake security-gitleaks       # Secret/API key detection\nmake security                # Run all security checks\nmake check                   # Run all checks (lint, typecheck, test, security)\nmake pipeline                # Run full pipeline (format, lint, typecheck, test, security, build, install-global)\nmake build                   # Build package\nmake run ARGS=\"...\"          # Run pdf-to-pptx-tool locally\nmake clean                   # Remove build artifacts\n```\n\n### Project Structure\n\n```\npdf-to-pptx-tool/\n‚îú‚îÄ‚îÄ pdf_to_pptx_tool/    # Main package\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py          # CLI entry point\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Utility functions\n‚îú‚îÄ‚îÄ tests/              # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py\n‚îú‚îÄ‚îÄ pyproject.toml      # Project configuration\n‚îú‚îÄ‚îÄ Makefile            # Development commands\n‚îú‚îÄ‚îÄ README.md           # This file\n‚îú‚îÄ‚îÄ LICENSE             # MIT License\n‚îî‚îÄ‚îÄ CLAUDE.md           # Development documentation\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_utils.py\n\n# Run with coverage\nuv run pytest tests/ --cov=pdf_to_pptx_tool\n```\n\n## Security\n\nThe project includes lightweight security tools providing 80%+ coverage with fast scan times:\n\n### Security Tools\n\n| Tool | Purpose | Speed | Coverage |\n|------|---------|-------|----------|\n| **bandit** | Python code security linting | ‚ö°‚ö° Fast | SQL injection, hardcoded secrets, unsafe functions |\n| **pip-audit** | Dependency vulnerability scanning | ‚ö°‚ö° Fast | Known CVEs in dependencies |\n| **gitleaks** | Secret and API key detection | ‚ö°‚ö°‚ö° Very Fast | Secrets in code and git history |\n\n### Running Security Scans\n\n```bash\n# Run all security checks (~5-8 seconds)\nmake security\n\n# Or run individually\nmake security-bandit       # Python security linting\nmake security-pip-audit    # Dependency CVE scanning\nmake security-gitleaks     # Secret detection\n```\n\n### Prerequisites\n\ngitleaks must be installed separately:\n\n```bash\n# macOS\nbrew install gitleaks\n\n# Linux\n# See: https://github.com/gitleaks/gitleaks#installation\n```\n\nSecurity checks run automatically in `make check` and `make pipeline`.\n\n### What's Protected\n\n- ‚úÖ AWS credentials (AKIA*, ASIA*, etc.)\n- ‚úÖ GitHub tokens (ghp_*, gho_*, etc.)\n- ‚úÖ API keys and secrets\n- ‚úÖ Private keys\n- ‚úÖ Slack tokens\n- ‚úÖ 100+ other secret types\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run the full pipeline (`make pipeline`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to the branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints for all functions\n- Write docstrings for public functions\n- Format code with `ruff`\n- Pass all linting and type checks\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "pdf-to-pptx-tool",
          "source": "./plugins/pdf-to-pptx-tool",
          "description": "Convert PDF documents to PowerPoint presentations",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/pdf-to-pptx-tool",
            "/plugin install pdf-to-pptx-tool@pdf-to-pptx-tool"
          ]
        }
      ]
    }
  ]
}