{
  "author": {
    "id": "dnvriend",
    "display_name": "Dennis Vriend",
    "avatar_url": "https://avatars.githubusercontent.com/u/4494623?u=e818279b41fd2175b7e52829dd96677a1f7f18a7&v=4"
  },
  "marketplaces": [
    {
      "name": "bibtex-tool",
      "version": null,
      "description": "Marketplace for bibtex-tool CLI plugin - A Python CLI tool",
      "repo_full_name": "dnvriend/bibtex-tool",
      "repo_url": "https://github.com/dnvriend/bibtex-tool",
      "repo_description": "bibtex-tool",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-18T15:26:08Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"bibtex-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for bibtex-tool CLI plugin - A Python CLI tool\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"bibtex-tool\",\n            \"source\": \"./plugins/bibtex-tool\",\n            \"description\": \"A Python CLI tool\"\n        }\n    ]\n}\n",
        "README.md": "# bibtex-tool\n\n<p align=\"center\">\n  <img src=\".github/assets/logo-256.png\" alt=\"bibtex-tool logo\" width=\"128\" height=\"128\">\n</p>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA CLI tool that extracts metadata from PDFs and markdown files to generate BibTeX bibliography entries.\n\n## Features\n\n- Extract DOIs from PDFs and query CrossRef for metadata\n- Parse markdown transcripts with APA-style citations\n- Deduplicate entries with interactive conflict resolution\n- Sort bibliography entries alphabetically\n- OpenTelemetry observability support\n- Shell completion for bash, zsh, and fish\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14+\n- [uv](https://github.com/astral-sh/uv) package manager\n\n### Install from source\n\n```bash\ngit clone https://github.com/dnvriend/bibtex-tool.git\ncd bibtex-tool\nuv tool install .\n```\n\n### Verify installation\n\n```bash\nbibtex-tool --version\n```\n\n## Usage\n\n```bash\n# Generate BibTeX from PDFs\nbibtex-tool generate \"**/*.pdf\" refs.bib\n\n# Generate from markdown transcripts\nbibtex-tool generate \"*.md\" refs.bib --base-dir ~/Documents\n\n# Remove duplicates (interactive)\nbibtex-tool deduplicate refs.bib clean.bib\n\n# Remove duplicates (auto-keep first)\nbibtex-tool deduplicate refs.bib clean.bib --auto\n\n# Sort entries alphabetically\nbibtex-tool sort refs.bib sorted.bib\n\n# Enable verbose output\nbibtex-tool generate \"**/*.pdf\" refs.bib -vv\n```\n\n### Command Reference\n\n| Command | Description |\n|---------|-------------|\n| `generate PATTERN OUTPUT` | Extract metadata and create .bib entries |\n| `deduplicate INPUT OUTPUT` | Remove duplicate entries by citation key |\n| `sort INPUT OUTPUT` | Sort entries alphabetically (a-z, then 0-9) |\n| `completion generate SHELL` | Generate shell completion script |\n\n### Global Options\n\n| Option | Description |\n|--------|-------------|\n| `-v, -vv, -vvv` | Verbosity level (INFO, DEBUG, TRACE) |\n| `--telemetry` | Enable OpenTelemetry tracing |\n| `--version` | Show version |\n| `--help` | Show help |\n\n## Shell Completion\n\n```bash\n# Bash (add to ~/.bashrc)\neval \"$(bibtex-tool completion generate bash)\"\n\n# Zsh (add to ~/.zshrc)\neval \"$(bibtex-tool completion generate zsh)\"\n\n# Fish\nbibtex-tool completion generate fish > ~/.config/fish/completions/bibtex-tool.fish\n```\n\n## Development\n\n```bash\nmake install      # Install dependencies\nmake check        # Run lint, typecheck, test, security\nmake pipeline     # Full CI pipeline\n```\n\nSee [CLAUDE.md](CLAUDE.md) for detailed development documentation.\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Author\n\n**Dennis Vriend** - [@dnvriend](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "bibtex-tool",
          "source": "./plugins/bibtex-tool",
          "description": "A Python CLI tool",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/bibtex-tool",
            "/plugin install bibtex-tool@bibtex-tool"
          ]
        }
      ]
    },
    {
      "name": "gemini-file-search-tool",
      "version": null,
      "description": "Manage Gemini File Search stores and query with RAG",
      "repo_full_name": "dnvriend/gemini-file-search-tool",
      "repo_url": "https://github.com/dnvriend/gemini-file-search-tool",
      "repo_description": "Production-ready CLI and Python library for Google's Gemini File Search API - A fully managed RAG system for document search and question-answering",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-31T23:41:21Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"gemini-file-search-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/gemini-file-search-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"gemini-file-search-tool\",\n            \"source\": \"./plugins/gemini-file-search-tool\",\n            \"description\": \"Manage Gemini File Search stores and query with RAG\"\n        }\n    ]\n}\n",
        "README.md": "# gemini-file-search-tool\n\n<div align=\"center\">\n  <img src=\".github/assets/rag-icon.png\" alt=\"RAG Icon\" width=\"200\" />\n  <br>\n  <br>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\n**Gemini File Search Tool** - Production-ready CLI & Python library for Google's fully managed RAG system\n\n</div>\n\n## Table of Contents\n\n- [About](#about)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Development](#development)\n- [Testing](#testing)\n- [Known Issues](#known-issues)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n- [Resources](#resources)\n\n## About\n\n`gemini-file-search-tool` is a production-ready CLI and Python library for [Google's Gemini File Search API](https://ai.google.dev/gemini-api/docs/file-search), a fully managed Retrieval-Augmented Generation (RAG) system that eliminates the operational complexity of vector databases, embeddings, and retrieval infrastructure.\n\n### What is Gemini File Search?\n\nGemini File Search is Google's fully managed RAG solution that automatically handles document ingestion, chunking, embedding generation, and semantic retrieval. As announced in [Google's developer blog](https://blog.google/technology/developers/file-search-gemini-api/), it provides enterprise-grade document search capabilities with zero infrastructure overhead, allowing developers to focus on building intelligent applications rather than managing search infrastructure.\n\n### Why This Tool?\n\nThis tool provides a **CLI-first interface** to the Gemini File Search API, designed specifically for integration with AI agents, automation workflows, and human operators:\n\n- **Agent-Friendly Design**: CLIs provide structured commands with built-in documentation and rich error messages that AI agents can parse and act upon in ReAct (Reasoning and Acting) loops, making them superior to standalone scripts for agentic workflows\n- **Composable Architecture**: JSON output to stdout and logs to stderr enable seamless piping and integration with other tools, perfect for complex automation pipelines\n- **Reusable Building Blocks**: Commands can be composed into larger workflows, used in skills for Claude Code, or integrated into custom automation without modification\n- **Dual-Mode Operation**: Functions as both a CLI tool for command-line operations and a Python library for programmatic integration\n- **Production Quality**: Type-safe, thoroughly tested, with comprehensive error handling that provides actionable feedback for both humans and agents\n\nWhether you're building AI-powered document search, integrating RAG into agentic workflows, or automating knowledge base operations, this tool provides the foundation for reliable, maintainable solutions.\n\n## Use Cases\n\n- **üìö Knowledge Base Management**: Index documentation, research papers, wikis, and technical specifications into searchable stores for instant retrieval\n- **üíª Code-RAG (Retrieval-Augmented Generation for Code)**: Upload entire codebases to enable semantic code search and natural language querying. Ask questions like \"how does authentication work?\", \"where is error handling implemented?\", or \"explain the database architecture\". Perfect for onboarding, code reviews, architecture discovery, and building AI coding assistants.\n- **üîç Semantic Search**: Query your document stores with natural language questions and receive contextually relevant answers with automatic citation\n- **üéØ RAG Applications**: Build production-ready retrieval-augmented generation systems with JSON-formatted responses including grounding metadata and source attribution\n\n### Code-RAG Example\n\nUpload a codebase and query it with natural language:\n\n```bash\n# Upload your entire codebase\ngemini-file-search-tool upload \"src/**/*.py\" --store \"my-project-code\" -v\n\n# Query with natural language\ngemini-file-search-tool query \"How does the authentication system work?\" \\\n  --store \"my-project-code\" --show-cost -v\n\n# Ask architectural questions\ngemini-file-search-tool query \"What design patterns are used in this codebase?\" \\\n  --store \"my-project-code\" --query-model pro\n\n# Find implementations\ngemini-file-search-tool query \"Where is error handling for API calls implemented?\" \\\n  --store \"my-project-code\"\n```\n\n**Meta Note**: This tool itself was built using Code-RAG! We uploaded the codebase to a Gemini File Search store and used it to answer questions during development. The tool enables the very functionality it provides.\n\n## Features\n\n- ‚úÖ **Fully Managed RAG**: Automatic chunking, embeddings, and retrieval without infrastructure management\n- ‚úÖ **Multi-Format Support**: PDF, DOCX, TXT, JSON, CSV, HTML, and source code files\n- ‚úÖ **Code-RAG Enabled**: Upload codebases and query with natural language for semantic code search\n- ‚úÖ **Intelligent Caching**: Local mtime-based cache (O(1) performance) prevents unnecessary re-uploads\n- ‚úÖ **Async Uploads**: `--no-wait` flag for fire-and-forget uploads with manual sync capability\n- ‚úÖ **Cache Management**: sync-cache, flush-cache, and cache-report commands for operation tracking\n- ‚úÖ **Query Enhancement**: LLM-powered query optimization for better RAG retrieval (generic, code-rag, obsidian modes)\n- ‚úÖ **Natural Language Queries**: Ask questions in plain language and get contextual answers\n- ‚úÖ **Automatic Citations**: Built-in source attribution and grounding metadata\n- ‚úÖ **Multi-Level Verbosity**: Progressive logging detail with `-v` (INFO), `-vv` (DEBUG), `-vvv` (TRACE)\n- ‚úÖ **Cost Tracking**: Token usage monitoring and cost estimation for both enhancement and query operations\n- ‚úÖ **Composable CLI**: JSON output for easy integration with other tools and scripts\n- ‚úÖ **Python Library**: Import and use programmatically in your applications\n- ‚úÖ **Type-Safe**: Strict mypy type checking and modern Python 3.14+ syntax\n- ‚úÖ **Production-Ready**: Comprehensive testing, linting, and quality checks\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- Google Gemini API access (see [Configuration](#configuration))\n\n### Core Dependencies\n\nThis tool uses the [Google Generative AI Python SDK](https://github.com/googleapis/python-genai) (`google-genai`) for interacting with Google's Gemini API.\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd gemini-file-search-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\ngemini-file-search-tool --version\n```\n\n## Configuration\n\n### Environment Variables\n\nThe CLI automatically detects and supports both authentication methods. Configuration depends on whether you're using the Gemini Developer API or the Gemini API in Vertex AI.\n\n#### Gemini Developer API (Recommended)\n\nSet `GEMINI_API_KEY` or `GOOGLE_API_KEY`. The client will automatically pick up these variables. If both are set, `GOOGLE_API_KEY` takes precedence.\n\n```bash\nexport GEMINI_API_KEY='your-api-key'\n```\n\n**Get your API key:**\n1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)\n2. Create or select a project\n3. Generate an API key\n4. Set the environment variable\n\n**Example:**\n```bash\nexport GEMINI_API_KEY='AIza...'\ngemini-file-search-tool list-stores\n```\n\n#### Gemini API on Vertex AI\n\nFor Vertex AI, set the following environment variables:\n\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='your-project-id'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n```\n\n**Prerequisites:**\n- Google Cloud project with Vertex AI API enabled\n- Proper IAM permissions for Vertex AI\n- Authenticated with `gcloud auth application-default login`\n\n**Example:**\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='my-project'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n\n# Authenticate with Google Cloud\ngcloud auth application-default login\n\n# Use the CLI (automatically uses Vertex AI)\ngemini-file-search-tool list-stores\n```\n\n**Note:** The CLI automatically detects which authentication method to use based on the `GOOGLE_GENAI_USE_VERTEXAI` environment variable.\n\nFor more information, see the [Google Generative AI Python SDK documentation](https://github.com/googleapis/python-genai).\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Show help\ngemini-file-search-tool --help\n\n# Show version\ngemini-file-search-tool --version\n\n# Get help for specific commands\ngemini-file-search-tool create-store --help\ngemini-file-search-tool upload --help\n```\n\n### Store Management\n\n```bash\n# Create a new store\ngemini-file-search-tool create-store \"my-documents\"\n\n# List all stores\ngemini-file-search-tool list-stores\n\n# Get store details\ngemini-file-search-tool get-store \"my-documents\"\n\n# Update store display name\ngemini-file-search-tool update-store \"my-documents\" --display-name \"My Documents 2024\"\n\n# Delete a store\ngemini-file-search-tool delete-store \"my-documents\" --force\n```\n\n### Document Management\n\n```bash\n# Upload a single file\ngemini-file-search-tool upload document.pdf --store \"my-documents\"\n\n# Upload multiple files with glob pattern\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\"\n\n# Recursive upload\ngemini-file-search-tool upload \"docs/**/*.md\" --store \"my-documents\"\n\n# Upload with metadata\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --title \"Important Document\" \\\n  --url \"https://example.com/doc\"\n\n# Upload with custom chunking\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --max-tokens 300 \\\n  --max-overlap 25\n\n# Upload respecting .gitignore (default behavior)\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" -v\n\n# Upload ignoring .gitignore patterns\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --ignore-gitignore\n\n# Dry-run to preview files before uploading\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --dry-run -v\n\n# Upload with verbose logging (see what's happening)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -v\n\n# Upload with debug logging (see detailed operations)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vv\n\n# Upload with trace logging (see full API calls)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vvv\n\n# List documents in a store\ngemini-file-search-tool list-documents --store \"my-documents\"\n\n# List documents with verbose output\ngemini-file-search-tool list-documents --store \"my-documents\" -v\n```\n\n### Querying\n\n**‚ö° Recommended Configuration (Based on Benchmarks)**\n\nFor optimal cost-quality balance, use the default configuration with no enhancement:\n\n```bash\n# Recommended: No enhancement + Flash model (best value)\ngemini-file-search-tool query \"What are the key findings?\" \\\n  --store \"my-documents\"\n\n# With cost tracking and grounding metadata\ngemini-file-search-tool query \"Explain the methodology\" \\\n  --store \"my-documents\" --show-cost --query-grounding-metadata -v\n```\n\n**Performance Benchmarks** (30 queries across 6 configurations):\n- **Quality Score**: 97.7/100\n- **Cost**: ~$0.00013 per query\n- **Success Rate**: 100% (vs 20-80% with enhancement)\n- **Value**: 156.1 quality points per $0.001 (6.6x better than enhancement)\n\nSee `references/benchmark-model-comparison-2025-11-16.md` for detailed analysis.\n\n**Other Query Options:**\n\n```bash\n# Query with Pro model (complex analytical questions)\ngemini-file-search-tool query \"Analyze the technical architecture\" \\\n  --store \"my-documents\" --query-model pro\n\n# Query with metadata filter\ngemini-file-search-tool query \"Tell me about the book\" \\\n  --store \"my-documents\" --metadata-filter \"author=Robert Graves\"\n\n# Query with enhancement (only for vague/exploratory queries)\ngemini-file-search-tool query \"authentication stuff\" \\\n  --store \"my-documents\" --enhance-mode code-rag --show-enhancement\n\n# Query with debug logging (see API operations)\ngemini-file-search-tool query \"What are the findings?\" \\\n  --store \"my-documents\" --show-cost -vv\n\n# Query with trace logging (see full HTTP requests)\ngemini-file-search-tool query \"Analyze this\" \\\n  --store \"my-documents\" --show-cost -vvv\n```\n\n**‚ö†Ô∏è Query Enhancement Notes:**\n\nBased on comprehensive benchmarks, **query enhancement is disabled by default** and should only be used for:\n- Vague or poorly worded queries (\"authentication stuff\", \"that database thing\")\n- Exploratory queries where you're unsure what you're looking for\n- Cases where simple queries consistently fail to retrieve relevant documents\n\n**Why?** Enhancement makes queries too specific, reducing retrieval success rates from 100% to 20-80%. Simple, natural language queries work best for RAG systems (see [Lewis et al., 2020](https://arxiv.org/abs/2005.11401)).\n\n### Cost Tracking\n\nThe CLI automatically tracks token usage for query operations and can estimate costs based on current Gemini API pricing:\n\n```bash\n# View token usage (verbose mode)\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n\n# Show estimated cost\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" --show-cost -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n# [INFO] Estimated cost: $0.00010725 USD\n```\n\n**Query Response with Cost Information:**\n\n```json\n{\n  \"response_text\": \"The document discusses...\",\n  \"usage_metadata\": {\n    \"prompt_token_count\": 150,\n    \"candidates_token_count\": 320,\n    \"total_token_count\": 470\n  },\n  \"estimated_cost\": {\n    \"input_cost_usd\": 0.00001125,\n    \"output_cost_usd\": 0.000096,\n    \"total_cost_usd\": 0.00010725,\n    \"currency\": \"USD\",\n    \"model\": \"gemini-2.5-flash\",\n    \"note\": \"Estimated cost based on current pricing. Subject to change.\"\n  }\n}\n```\n\n**Current Pricing (as of 2025-01):**\n- **gemini-2.5-flash**: $0.075 input / $0.30 output per 1M tokens\n- **gemini-2.5-pro**: $1.25 input / $5.00 output per 1M tokens\n\n**Note**: Pricing is subject to change. Verify current rates at [Google AI Pricing](https://ai.google.dev/pricing).\n\n**Limitations:**\n- Token usage is only available for query operations\n- Upload costs (document embedding) are not tracked by the API\n- Cost estimates are calculated locally using published pricing\n\n### Upload Features\n\n**Intelligent Caching**:\n- **Local Cache**: Automatically tracks uploaded files at `~/.config/gemini-file-search-tool/stores/`\n- **Per-Store Isolation**: Each store maintains its own cache file (e.g., `fileSearchStores__my-store.json`)\n- **mtime Optimization**: O(n) ‚Üí O(1) performance - checks file modification time before computing expensive SHA256 hash\n- **Smart Re-uploads**: Only uploads files that have actually changed (skips identical files automatically)\n- **Cache Structure**: Stores hash, mtime, remote_id, and last_uploaded timestamp for each file\n- **Performance Impact**:\n  - **Large codebases (1000 files)**: Cache check ~0.1 seconds vs ~5-10 seconds without cache\n  - **Network I/O remains the bottleneck**: Upload time (5-10s per file) dominates hash calculation (500ms)\n  - See `docs/cache-design.md` for detailed performance analysis and architecture\n\n**Automatic File Validation**:\n- **Empty Files**: 0-byte files automatically skipped with warning\n- **File Size**: 50MB limit enforced\n- **Base64 Images**: Detects base64-encoded images in text files (can cause upload failures)\n- **System Files**: Auto-skips `__pycache__`, `.pyc`, `.DS_Store`, etc.\n- **Gitignore Support**: Automatically respects `.gitignore` patterns (use `--ignore-gitignore` to disable)\n- **MIME Types**: Automatic registration for `.toml`, `.env`, `.txt`, `.md` files\n\n**Duplicate Detection**:\n- Automatically detects existing files by name and size\n- Skips unchanged files (no re-upload)\n- Updates files when size changes (deletes old, uploads new)\n\n**Preview & Control**:\n- **Dry-Run**: Use `--dry-run` to preview which files would be uploaded without actually uploading\n- **Skip Validation**: Use `--skip-validation` to bypass checks for faster uploads\n- **Ignore Gitignore**: Use `--ignore-gitignore` to upload files normally excluded by .gitignore\n\n### Dry-Run Mode\n\nPreview which files would be uploaded without actually uploading:\n\n```bash\n# Preview files with sizes\ngemini-file-search-tool upload \"**/*.py\" --store \"code\" --dry-run -v\n\n# Output (to stderr):\n# [INFO] Loaded 38 patterns from .gitignore\n# [INFO] DRY-RUN: Would upload 13 file(s)\n\n# Output (to stdout - JSON):\n[\n  {\n    \"file\": \"/path/to/file1.py\",\n    \"size_bytes\": 1809,\n    \"size_mb\": 0.0\n  },\n  {\n    \"file\": \"/path/to/file2.py\",\n    \"size_bytes\": 2691,\n    \"size_mb\": 0.0\n  }\n]\n```\n\n**Benefits**:\n- **Preview Files**: See exactly which files match your glob pattern\n- **Verify Gitignore**: Confirm .gitignore filtering is working correctly\n- **Check Sizes**: Review file sizes before uploading\n- **No API Calls**: Completely safe, no interaction with Gemini API\n\n### Verbosity Levels\n\nAll commands support multi-level verbosity for controlling log output detail:\n\n| Flag | Level | Description | Use Case |\n|------|-------|-------------|----------|\n| (none) | WARNING | Only critical errors | Production, clean output |\n| `-v` | INFO | High-level operations | See progress, identify failures |\n| `-vv` | DEBUG | Detailed operations | Debug issues, see API calls |\n| `-vvv` | TRACE | Full API details | Deep debugging, HTTP traces |\n\n**Examples:**\n\n```bash\n# INFO level: See which files are uploaded/failed\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -v\n\n# DEBUG level: See validation, polling, API operations\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vv\n\n# TRACE level: See full HTTP requests/responses from SDK\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vvv\n```\n\n**Output:**\n\n```bash\n# With -v (INFO)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[INFO] Upload completed successfully: document.pdf\n\n# With -vv (DEBUG)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[DEBUG] Validating file: document.pdf\n[DEBUG] File validation passed: document.pdf\n[DEBUG] Starting upload operation for: document.pdf\n[DEBUG] Operation started: operations/upload-abc123\n[DEBUG] Polling operation operations/upload-abc123 (attempt 1) - waiting 2.0s\n[DEBUG] Polling operation operations/upload-abc123 (attempt 2) - waiting 3.0s\n[INFO] Upload completed successfully: document.pdf\n\n# With -vvv (TRACE) - includes all above plus:\n[DEBUG] (httpx) HTTP Request: POST https://...\n[DEBUG] (httpx) HTTP Response: 200 OK\n```\n\n**Benefits:**\n- **Real-time Feedback**: See progress and failures as they happen (not just in final JSON)\n- **Progressive Detail**: Choose the right level of verbosity for your needs\n- **Clean stdout**: All logs go to stderr, keeping JSON output clean for piping\n- **Library Logging**: At `-vvv`, see internals from `httpx`, `google-api-core`, etc.\n\n### Cache Management\n\nThe CLI provides commands to manage the local cache for asynchronous upload operations and cache maintenance.\n\n#### Asynchronous Uploads\n\nUse `--no-wait` to skip operation polling and return immediately after initiating uploads:\n\n```bash\n# Fast async uploads (don't wait for completion)\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" --no-wait -v\n\n# Output: Returns immediately with \"pending\" status\n[\n  {\"file\": \"doc1.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"},\n  {\"file\": \"doc2.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"}\n]\n```\n\n**Benefits**:\n- **Faster Returns**: No polling overhead (~2-10s per file saved)\n- **Bulk Operations**: Initiate thousands of uploads quickly\n- **Fire-and-Forget**: Useful for known-working file types where immediate feedback isn't needed\n- **Last-One-Wins**: Re-uploading a file automatically overwrites previous pending operations\n\n**Trade-offs**:\n- No immediate status (success/failure unknown until synced)\n- Requires manual `sync-cache` to check final status\n\n#### Sync Cache\n\nCheck status of pending operations and update cache with final results:\n\n```bash\n# Sync all pending operations for a store\ngemini-file-search-tool sync-cache --store \"docs\" -v\n\n# With custom number of workers (default: 4)\ngemini-file-search-tool sync-cache --store \"docs\" --num-workers 8 -v\n\n# Output (JSON - default):\n{\n  \"status\": \"success\",\n  \"total\": 10,\n  \"synced\": 8,\n  \"failed\": 1,\n  \"still_pending\": 1,\n  \"operations\": [\n    {\"file\": \"doc1.pdf\", \"status\": \"synced\", \"remote_id\": \"documents/...\"},\n    {\"file\": \"doc2.pdf\", \"status\": \"failed\", \"error\": {\"message\": \"...\"}}\n  ]\n}\n\n# Human-readable text output\ngemini-file-search-tool sync-cache --store \"docs\" --text\n\n# Output (text):\nSync Summary:\n  Total operations: 10\n  Synced: 8\n  Failed: 1\n  Still pending: 1\n```\n\n**Features**:\n- **Parallel Processing**: Fetches operation status concurrently with configurable workers (default: 4)\n- **Batch Cache Writes**: Collects all updates and writes cache once at the end (not per-operation)\n- **Progress Bar**: Visual feedback with tqdm during sync\n- **Error Details**: Captures and stores error messages from failed operations\n- **Automatic Updates**: Updates cache with remote_id when operations complete successfully\n- **Idempotent**: Safe to run multiple times (only updates changed operations)\n\n#### Cache Report\n\nGenerate reports on cache status with filtering options:\n\n```bash\n# Default report (summary + pending operations)\ngemini-file-search-tool cache-report --store \"docs\"\n\n# Show only failed operations\ngemini-file-search-tool cache-report --store \"docs\" --errors-only\n\n# Show only completed uploads\ngemini-file-search-tool cache-report --store \"docs\" --completed-only\n\n# Show all cached files\ngemini-file-search-tool cache-report --store \"docs\" --all\n\n# Human-readable text output\ngemini-file-search-tool cache-report --store \"docs\" --text\n```\n\n**Output Example (JSON)**:\n```json\n{\n  \"store\": \"docs\",\n  \"stats\": {\n    \"total_files\": 100,\n    \"completed\": 95,\n    \"pending_operations\": 3,\n    \"failed_operations\": 2\n  },\n  \"files\": [\n    {\n      \"file\": \"/path/to/doc.pdf\",\n      \"status\": \"pending\",\n      \"operation\": \"operations/...\",\n      \"hash\": \"abc123...\",\n      \"mtime\": 1731969000.0\n    }\n  ]\n}\n```\n\n**Filters**:\n- `--pending-only`: Show only files with pending operations\n- `--errors-only`: Show only files with errors\n- `--completed-only`: Show only successfully uploaded files\n- `--all`: Show all cached files (overrides other filters)\n- `--text`: Human-readable text format instead of JSON\n\n#### Flush Cache\n\nDelete cache file for a specific store:\n\n```bash\n# Flush with confirmation prompt\ngemini-file-search-tool flush-cache --store \"docs\"\n\n# Output:\nCache statistics for 'docs':\n  Total files: 100\n  Completed: 95\n  Pending operations: 3\n  Failed operations: 2\n\nAre you sure you want to delete this cache? [y/N]:\n\n# Force flush without confirmation\ngemini-file-search-tool flush-cache --store \"docs\" --force\n```\n\n**Use Cases**:\n- **Clean Slate**: Start fresh after major changes\n- **Rebuild Cache**: Use with `upload --rebuild-cache` to re-upload everything\n- **Troubleshooting**: Clear corrupted cache data\n\n#### Cache with Store Deletion\n\nWhen deleting a store, cache statistics are shown and the cache is automatically removed:\n\n```bash\n# Delete store with cache cleanup\ngemini-file-search-tool delete-store \"docs\" --force\n\n# Output shows cache stats before deletion:\n[INFO] Cache found for store 'docs':\n[INFO]   Total files: 100\n[INFO]   Completed: 95\n[INFO]   Pending operations: 3\n[INFO]   Failed operations: 2\n[INFO] Deleting store: fileSearchStores/docs-123\n[INFO] Removing cache file...\n[INFO] Cache removed successfully\n```\n\n#### Typical Workflows\n\n**Async Upload + Sync Pattern:**\n```bash\n# 1. Fast upload without waiting\ngemini-file-search-tool upload \"docs/**/*.pdf\" --store \"my-docs\" --no-wait -v\n\n# 2. Continue working on other tasks...\n\n# 3. Later, check status\ngemini-file-search-tool sync-cache --store \"my-docs\" -v\n\n# 4. Review any failures\ngemini-file-search-tool cache-report --store \"my-docs\" --errors-only\n```\n\n**Re-upload Changed Files:**\n```bash\n# Upload with last-one-wins strategy\n# If files change and you re-upload, previous pending operations are overwritten\ngemini-file-search-tool upload \"docs/*.pdf\" --store \"my-docs\" --no-wait\n\n# The cache automatically tracks the latest operation-id per file\n```\n\n**Cache Inspection:**\n```bash\n# Quick overview\ngemini-file-search-tool cache-report --store \"my-docs\" --text\n\n# Detailed analysis\ngemini-file-search-tool cache-report --store \"my-docs\" --all | jq .\n```\n\n### Library Usage\n\nYou can also use this package as a Python library:\n\n```python\nfrom pathlib import Path\nfrom gemini_file_search_tool import (\n    create_store,\n    upload_file,\n    query_store,\n    list_documents,\n)\n\n# Create a store\nstore = create_store(\"my-documents\")\nprint(f\"Created store: {store['name']}\")\n\n# Upload a file\nresult = upload_file(\n    file_path=Path(\"document.pdf\"),\n    store_name=store[\"name\"],\n    title=\"Important Document\"\n)\nprint(f\"Upload status: {result['status']}\")\n\n# Query the store\nresponse = query_store(\n    store_name=store[\"name\"],\n    prompt=\"What is in this document?\",\n    model=\"gemini-2.5-flash\"\n)\nprint(response[\"response_text\"])\n\n# List documents\ndocuments = list_documents(store[\"name\"])\nprint(f\"Found {len(documents)} documents\")\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake check            # Run all checks (lint, typecheck, test)\nmake pipeline         # Run full pipeline (format, lint, typecheck, test, build, install-global)\nmake build            # Build package\nmake run ARGS=\"...\"   # Run gemini-file-search-tool locally\nmake clean            # Remove build artifacts\n```\n\n### Project Structure\n\n```\ngemini-file-search-tool/\n‚îú‚îÄ‚îÄ gemini_file_search_tool/    # Main package\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py          # CLI entry point\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Utility functions\n‚îú‚îÄ‚îÄ tests/              # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py\n‚îú‚îÄ‚îÄ pyproject.toml      # Project configuration\n‚îú‚îÄ‚îÄ Makefile            # Development commands\n‚îú‚îÄ‚îÄ README.md           # This file\n‚îú‚îÄ‚îÄ LICENSE             # MIT License\n‚îî‚îÄ‚îÄ CLAUDE.md           # Development documentation\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_utils.py\n\n# Run with coverage\nuv run pytest tests/ --cov=gemini_file_search_tool\n```\n\n## Known Issues\n\n### SDK Bug #1661 - Document Listing with Vertex AI\n\n**Issue**: The Google Generative AI Python SDK has a bug ([#1661](https://github.com/googleapis/python-genai/issues/1661)) where `documents.list()` requires a 'parent' parameter that causes failures.\n\n**Impact**: The `list-documents` command cannot be used with Vertex AI authentication.\n\n**Workaround**: We use the REST API directly instead of the SDK's `documents.list()` method. This workaround only works with the Developer API (requires `GEMINI_API_KEY` or `GOOGLE_API_KEY`).\n\n**Status**: Waiting for upstream fix in the Google Generative AI Python SDK.\n\n**Affected Commands**:\n- `list-documents` - Only works with Developer API, not Vertex AI\n\n**Code Location**: `gemini_file_search_tool/core/documents.py:list_documents()`\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run the full pipeline (`make pipeline`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to the branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints for all functions\n- Write docstrings for public functions\n- Format code with `ruff`\n- Pass all linting and type checks\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n## Resources\n\n### Gemini File Search Documentation\n\n- **[Gemini File Search API Documentation](https://ai.google.dev/gemini-api/docs/file-search)** - Official API documentation and guides\n- **[Gemini API File Search Stores Reference](https://ai.google.dev/api/file-search/file-search-stores)** - API reference for file search stores\n- **[Introducing File Search for the Gemini API](https://blog.google/technology/developers/file-search-gemini-api/)** - Official announcement and overview from Google\n\n### Related Tools\n\n- **[Google Generative AI Python SDK](https://github.com/googleapis/python-genai)** - Python SDK for Google's Gemini API\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "gemini-file-search-tool",
          "source": "./plugins/gemini-file-search-tool",
          "description": "Manage Gemini File Search stores and query with RAG",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/gemini-file-search-tool",
            "/plugin install gemini-file-search-tool@gemini-file-search-tool"
          ]
        }
      ]
    },
    {
      "name": "slack-messaging-tool",
      "version": null,
      "description": "Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool",
      "repo_full_name": "dnvriend/slack-messaging-tool",
      "repo_url": "https://github.com/dnvriend/slack-messaging-tool",
      "repo_description": "slack-messaging-tool",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-26T07:42:46Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"slack-messaging-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"slack-messaging-tool\",\n            \"source\": \"./plugins/slack-messaging-tool\",\n            \"description\": \"A Python CLI tool\"\n        }\n    ]\n}\n",
        "README.md": "# slack-messaging-tool\n\n<p align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"slack-messaging-tool logo\" width=\"128\">\n</p>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n\nA CLI tool that provides Slack messaging capabilities via the Slack API.\n\n## Features\n\n- Send messages to Slack channels (by name or ID)\n- Support for Slack Block Kit rich layouts\n- List available channels in workspace\n- Bot token authentication\n- Multi-level verbosity logging\n- OpenTelemetry observability\n- Shell completion (bash, zsh, fish)\n\n## Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/dnvriend/slack-messaging-tool.git\ncd slack-messaging-tool\nuv tool install .\n\n# Verify\nslack-messaging-tool --version\n```\n\n## Usage\n\n```bash\n# Set your bot token\nexport SLACK_BOT_TOKEN=xoxb-your-bot-token\n\n# List channels\nslack-messaging-tool channels\n\n# Send a message\nslack-messaging-tool send -c general -m \"Hello team!\"\n\n# Send with Block Kit\nslack-messaging-tool send -c general -m \"Fallback\" \\\n    --blocks '[{\"type\":\"section\",\"text\":{\"type\":\"mrkdwn\",\"text\":\"*Bold*\"}}]'\n\n# Enable verbose logging\nslack-messaging-tool -v channels\n```\n\n## Environment Variables\n\n| Variable | Required | Default | Description |\n|----------|----------|---------|-------------|\n| `SLACK_BOT_TOKEN` | Yes | - | Slack bot token (xoxb-...) |\n| `OTEL_ENABLED` | No | `false` | Enable OpenTelemetry |\n| `OTEL_EXPORTER_TYPE` | No | `console` | `console` or `otlp` |\n| `OTEL_EXPORTER_OTLP_ENDPOINT` | No | `http://localhost:4317` | OTLP endpoint |\n| `LOG_FILE` | No | - | Path to log file |\n\n## Documentation\n\n- [Logging](references/logging.md) - Multi-level verbosity logging\n- [Telemetry](references/telemetry.md) - OpenTelemetry observability\n- [Shell Completion](references/shell-completion.md) - Tab completion setup\n- [Development](references/development.md) - Contributing guide\n\n## Development\n\n```bash\nmake install    # Install dependencies\nmake test       # Run tests\nmake pipeline   # Full CI pipeline\n```\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Author\n\n**Dennis Vriend** - [@dnvriend](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "slack-messaging-tool",
          "source": "./plugins/slack-messaging-tool",
          "description": "A Python CLI tool",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/slack-messaging-tool",
            "/plugin install slack-messaging-tool@slack-messaging-tool"
          ]
        }
      ]
    },
    {
      "name": "aws-transcribe-tool",
      "version": null,
      "description": "Marketplace for aws-transcribe-tool CLI plugin - A Python CLI tool",
      "repo_full_name": "dnvriend/aws-transcribe-tool",
      "repo_url": "https://github.com/dnvriend/aws-transcribe-tool",
      "repo_description": "aws-transcribe-tool",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-12T20:37:24Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"aws-transcribe-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for aws-transcribe-tool CLI plugin - A Python CLI tool\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"aws-transcribe-tool\",\n            \"source\": \"./plugins/aws-transcribe-tool\",\n            \"description\": \"A Python CLI tool\"\n        }\n    ]\n}\n",
        "README.md": "# aws-transcribe-tool\n\n<p align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"AWS Transcribe Tool Logo\" width=\"400\"/>\n</p>\n\n[![Python](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA CLI tool that transcribes audio files to text using Amazon Transcribe with support for 60+ languages.\n\n## Installation\n\n```bash\ngit clone https://github.com/dnvriend/aws-transcribe-tool.git\ncd aws-transcribe-tool\nuv tool install .\n```\n\n**Requirements**: Python 3.14+, uv, AWS credentials, S3 bucket.\n\n## Usage\n\n```bash\n# Transcribe audio\naws-transcribe-tool transcribe interview.mp3 transcript.txt my-s3-bucket\n\n# Specify language (default: en-US)\naws-transcribe-tool transcribe audio.wav output.txt my-bucket -l nl-NL\n\n# List supported languages\naws-transcribe-tool list-languages\n```\n\n## Options\n\n| Flag | Description |\n|------|-------------|\n| `-l, --language` | Language code (default: en-US) |\n| `-v` | Verbose output (-v INFO, -vv DEBUG, -vvv TRACE) |\n| `--telemetry` | Enable OpenTelemetry |\n| `--version` | Show version |\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "aws-transcribe-tool",
          "source": "./plugins/aws-transcribe-tool",
          "description": "A Python CLI tool",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/aws-transcribe-tool",
            "/plugin install aws-transcribe-tool@aws-transcribe-tool"
          ]
        }
      ]
    },
    {
      "name": "openai-tts-tool",
      "version": null,
      "description": "Marketplace for openai-tts-tool CLI plugin - A CLI that provides tts using OpenAI",
      "repo_full_name": "dnvriend/openai-tts-tool",
      "repo_url": "https://github.com/dnvriend/openai-tts-tool",
      "repo_description": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-05T06:33:16Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"openai-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for openai-tts-tool CLI plugin - A CLI that provides tts using OpenAI\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"openai-tts-tool\",\n            \"source\": \"./plugins/openai-tts-tool\",\n            \"description\": \"A CLI that provides tts using OpenAI\"\n        }\n    ]\n}\n",
        "README.md": "<p align=\"center\">\n  <img src=\"https://github.com/dnvriend/openai-tts-tool/blob/main/.github/assets/logo-web.png\" alt=\"openai-tts-tool Logo\" width=\"120\"/>\n</p>\n\n# openai-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\n\nA command-line interface for OpenAI Text-to-Speech API.\n\n## Features\n\n- Convert text to natural-sounding speech\n- Six high-quality voices with different characteristics\n- Two TTS models (tts-1 and tts-1-hd) for speed vs quality\n- Multiple audio formats: mp3, opus, aac, flac\n- Stream to speakers or save to files\n- Adjustable speech speed (0.25 to 4.0)\n- Multi-level verbosity logging\n- Shell completion support\n\n## Installation\n\n```bash\n# Prerequisites\n# - Python 3.14+\n# - uv package manager\n\n# Clone and install globally\ngit clone https://github.com/dnvriend/openai-tts-tool.git\ncd openai-tts-tool\nuv tool install .\n\n# Verify installation\nopenai-tts-tool --version\n```\n\n## Configuration\n\nSet the OpenAI API key:\n\n```bash\nexport OPENAI_API_KEY=\"your-api-key-here\"\n\n# Add to shell profile for persistence\necho 'export OPENAI_API_KEY=\"your-api-key-here\"' >> ~/.bashrc  # or ~/.zshrc\nsource ~/.bashrc  # or ~/.zshrc\n```\n\n## Usage\n\n```bash\n# Basic synthesis (stream to speakers)\nopenai-tts-tool synthesize \"Hello, world!\"\n\n# Save to file with specific voice\nopenai-tts-tool synthesize \"Hello, world!\" --voice nova --output hello.mp3\n\n# High-quality synthesis with custom settings\nopenai-tts-tool synthesize \"Welcome\" \\\n    --voice alloy \\\n    --model tts-1-hd \\\n    --output welcome.mp3 \\\n    --format mp3 \\\n    --speed 1.2\n\n# Read from stdin\necho \"Hello from stdin\" | openai-tts-tool synthesize --stdin --output hello.mp3\n\n# List available voices and models\nopenai-tts-tool list-voices\nopenai-tts-tool list-models\n\n# Multi-level verbosity for debugging\nopenai-tts-tool -v synthesize \"Test\"           # INFO level\nopenai-tts-tool -vv synthesize \"Test\"          # DEBUG level\nopenai-tts-tool -vvv synthesize \"Test\"         # TRACE with library logs\n```\n\n## Options\n\n### Synthesize Command\n\n| Option | Short | Description |\n|--------|-------|-------------|\n| `--voice` | `-v` | Voice to use (alloy, echo, fable, onyx, nova, shimmer) |\n| `--model` | `-m` | TTS model (tts-1, tts-1-hd) |\n| `--output` | `-o` | Output file path (default: stream to speakers) |\n| `--format` | `-f` | Audio format (mp3, opus, aac, flac) |\n| `--speed` | `-s` | Speech speed (0.25 to 4.0) |\n| `--stdin` | | Read text from stdin |\n\n### Global Options\n\n| Option | Short | Description |\n|--------|-------|-------------|\n| `--verbose` | `-v` | Verbose output: -v (INFO), -vv (DEBUG), -vvv (TRACE with library logs) |\n| `--version` | | Show version information |\n| `--help` | `-h` | Show help message |\n\n## Voices and Models\n\n### Voices\n\n| Voice | Description |\n|-------|-------------|\n| **alloy** | Balanced, natural voice (default) |\n| **echo** | Deeper, authoritative voice |\n| **fable** | Warm, engaging storyteller |\n| **onyx** | Deep, confident voice |\n| **nova** | Clear, professional voice |\n| **shimmer** | Softer, expressive voice |\n\n### Models\n\n| Model | Quality | Speed | Use Case |\n|-------|---------|-------|----------|\n| **tts-1** | Standard | Fast | Real-time applications |\n| **tts-1-hd** | High | Slower | High-quality audio production |\n\n### Audio Formats\n\n| Format | Quality | Use Case |\n|--------|---------|----------|\n| **mp3** | Good | Maximum compatibility |\n| **opus** | Excellent | Streaming, low bandwidth |\n| **aac** | Very Good | Apple devices |\n| **flac** | Lossless | High-fidelity production |\n\n## Library Usage\n\n```python\nfrom openai_tts_tool import TTSClient\n\nclient = TTSClient(api_key=\"your-key\")\n\n# Stream to speakers\nclient.synthesize(\"Hello, world!\", voice=\"alloy\")\n\n# Save to file\nclient.synthesize(\n    \"Hello, world!\",\n    voice=\"nova\",\n    model=\"tts-1-hd\",\n    output=\"hello.mp3\",\n    speed=1.2\n)\n```\n\n## Development\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake security         # Run all security checks\nmake check            # Run all checks (lint, typecheck, test, security)\nmake pipeline         # Run full pipeline\nmake build            # Build package\nmake run ARGS=\"...\"   # Run openai-tts-tool locally\n```\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nDennis Vriend - [GitHub](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "openai-tts-tool",
          "source": "./plugins/openai-tts-tool",
          "description": "A CLI that provides tts using OpenAI",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/openai-tts-tool",
            "/plugin install openai-tts-tool@openai-tts-tool"
          ]
        }
      ]
    }
  ]
}