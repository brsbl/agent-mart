{
  "author": {
    "id": "dnvriend",
    "display_name": "Dennis Vriend",
    "avatar_url": "https://avatars.githubusercontent.com/u/4494623?u=e818279b41fd2175b7e52829dd96677a1f7f18a7&v=4"
  },
  "marketplaces": [
    {
      "name": "kokoro-tts-tool",
      "version": null,
      "description": "Marketplace for kokoro-tts-tool CLI plugin - A CLI that provides text-to-speech using kokoro",
      "repo_full_name": "dnvriend/kokoro-tts-tool",
      "repo_url": "https://github.com/dnvriend/kokoro-tts-tool",
      "repo_description": "A CLI that provides local text-to-speech using Kokoro TTS on Apple Silicon",
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2025-12-07T07:41:11Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"kokoro-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for kokoro-tts-tool CLI plugin - A CLI that provides text-to-speech using kokoro\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"kokoro-tts-tool\",\n            \"source\": \"./plugins/kokoro-tts-tool\",\n            \"description\": \"A CLI that provides text-to-speech using kokoro\"\n        }\n    ]\n}\n",
        "README.md": "<p align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"kokoro-tts-tool logo\" width=\"128\">\n</p>\n\n# kokoro-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA CLI that provides local text-to-speech using Kokoro TTS on Apple Silicon. No API keys required.\n\n## Table of Contents\n\n- [About](#about)\n- [Features](#features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Usage](#usage)\n- [Infinite Streaming](#infinite-streaming)\n- [Available Voices](#available-voices)\n- [Multi-Level Verbosity Logging](#multi-level-verbosity-logging)\n- [Shell Completion](#shell-completion)\n- [Development](#development)\n- [Testing](#testing)\n- [Security](#security)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n\n## About\n\n`kokoro-tts-tool` is a Python CLI tool for local text-to-speech synthesis using the Kokoro-82M model. It runs entirely on your machine with no cloud dependencies, optimized for Apple Silicon Macs.\n\n**Key highlights:**\n- **Local inference**: Uses ONNX runtime for fast, CPU-optimized synthesis\n- **60+ voices**: Multiple languages and accents (English, Japanese, Mandarin, etc.)\n- **Near real-time**: Fast enough for interactive use on Apple Silicon\n- **Infinite streaming**: Continuous TTS for long documents without audio artifacts\n- **No API keys**: Everything runs locally, completely free\n\n## Features\n\n- Local TTS with Kokoro-82M (82 million parameters)\n- 60+ voices across 8 languages\n- Near real-time synthesis on Apple Silicon\n- Auto-download of model files (~350MB)\n- WAV output or direct speaker playback\n- Infinite streaming for long documents (books, articles)\n- Seamless audio without pop artifacts between chunks\n- Fast offline rendering (20-50x real-time on M4)\n- Type-safe with mypy strict mode\n- Tested with pytest\n- Multi-level verbosity logging (-v/-vv/-vvv)\n- Shell completion for bash, zsh, and fish\n- Security scanning with bandit, pip-audit, and gitleaks\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- Apple Silicon Mac (recommended) or any platform with Python 3.14+\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/kokoro-tts-tool.git\ncd kokoro-tts-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd kokoro-tts-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\nkokoro-tts-tool --version\n```\n\n## Quick Start\n\n```bash\n# 1. Initialize (downloads models on first run, ~350MB)\nkokoro-tts-tool init\n\n# 2. Synthesize text to speakers\nkokoro-tts-tool synthesize \"Hello world!\"\n\n# 3. Save to file\nkokoro-tts-tool synthesize \"Hello world!\" --output hello.wav\n\n# 4. Use different voice\nkokoro-tts-tool synthesize \"This is Adam.\" --voice am_adam\n\n# 5. List available voices\nkokoro-tts-tool list-voices\n```\n\n## Usage\n\n### Commands\n\n```bash\n# Show all commands\nkokoro-tts-tool --help\n\n# Download/update models\nkokoro-tts-tool init\n\n# Synthesize text\nkokoro-tts-tool synthesize \"Your text here\"\nkokoro-tts-tool synthesize \"Your text\" --output speech.wav\nkokoro-tts-tool synthesize \"Your text\" --voice bf_emma --speed 1.2\n\n# Read from stdin\necho \"Hello from stdin\" | kokoro-tts-tool synthesize --stdin\n\n# List voices\nkokoro-tts-tool list-voices\nkokoro-tts-tool list-voices --language English\nkokoro-tts-tool list-voices --gender Female\nkokoro-tts-tool list-voices --json\n\n# Show configuration\nkokoro-tts-tool info\n```\n\n### Synthesize Options\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `--voice`, `-v` | Voice ID (e.g., af_heart, am_adam) | af_heart |\n| `--output`, `-o` | Output WAV file path | (plays to speakers) |\n| `--speed` | Speech speed (0.5 to 2.0) | 1.0 |\n| `--stdin`, `-s` | Read text from stdin | false |\n\n## Infinite Streaming\n\nStream long documents (books, articles, study materials) without audio artifacts:\n\n```bash\n# Stream a markdown file to speakers\nkokoro-tts-tool infinite --input book.md\n\n# Render to WAV file (fast offline mode, 20-50x real-time on M4)\nkokoro-tts-tool infinite --input book.md --output audiobook.wav\n\n# Pipe from stdin\ncat chapter.md | kokoro-tts-tool infinite --stdin\n\n# With custom voice and speed\nkokoro-tts-tool infinite --input notes.md --voice am_adam --speed 1.2\n```\n\n### Infinite Streaming Options\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `--input`, `-i` | Input text/markdown file | - |\n| `--stdin`, `-s` | Read text from stdin | false |\n| `--output`, `-o` | Save to WAV file (fast offline mode) | (plays to speakers) |\n| `--voice` | Voice ID | af_heart |\n| `--speed` | Speech speed (0.5 to 2.0) | 1.0 |\n| `--chunk-size` | Target words per chunk (50-1000) | 200 |\n| `--pause` | Pause between chunks in ms (0-2000) | 150 |\n| `--no-markdown` | Treat input as plain text | false |\n\n## Available Voices\n\nThe tool includes 60+ voices across 8 languages:\n\n### American English (20 voices)\n| Voice ID | Gender | Grade | Description |\n|----------|--------|-------|-------------|\n| `af_heart` | Female | A | Default, emotional, soft (highest quality) |\n| `af_bella` | Female | A- | Expressive, dynamic range |\n| `am_adam` | Male | A- | Deep narrator (audiobooks) |\n| `am_michael` | Male | B+ | Natural, casual |\n\n### British English (8 voices)\n| Voice ID | Gender | Grade | Description |\n|----------|--------|-------|-------------|\n| `bf_emma` | Female | B+ | Polished, formal (education) |\n| `bm_george` | Male | B+ | Resonant, classic (history) |\n\n### Other Languages\n- **Japanese**: jf_alpha, jm_kumo, and more\n- **Mandarin**: zf_xiaobei, zm_yunjian, and more\n- **Spanish**: ef_dora, em_alex\n- **French**: ff_siwis\n- **Hindi**: hf_alpha, hm_omega\n- **Italian**: if_sara, im_nicola\n- **Portuguese (Brazilian)**: pf_dora, pm_alex\n\nRun `kokoro-tts-tool list-voices` for the complete list.\n\n### Voice Quality Grades\n- **A/A-**: Highest quality, recommended for production\n- **B+/B**: Good quality\n- **B-**: Acceptable quality\n\n## Multi-Level Verbosity Logging\n\nThe CLI supports progressive verbosity levels for debugging:\n\n| Flag | Level | Output | Use Case |\n|------|-------|--------|----------|\n| (none) | WARNING | Errors and warnings only | Production |\n| `-v` | INFO | + High-level operations | Normal debugging |\n| `-vv` | DEBUG | + Detailed info | Development |\n| `-vvv` | TRACE | + Library internals | Deep debugging |\n\n```bash\n# Quiet mode\nkokoro-tts-tool synthesize \"Hello\"\n\n# With debug output\nkokoro-tts-tool -vv synthesize \"Hello\"\n```\n\n## Shell Completion\n\nThe CLI provides native shell completion for bash, zsh, and fish:\n\n```bash\n# Bash - add to ~/.bashrc\necho 'eval \"$(kokoro-tts-tool completion bash)\"' >> ~/.bashrc\n\n# Zsh - add to ~/.zshrc\necho 'eval \"$(kokoro-tts-tool completion zsh)\"' >> ~/.zshrc\n\n# Fish - save to completions\nmkdir -p ~/.config/fish/completions\nkokoro-tts-tool completion fish > ~/.config/fish/completions/kokoro-tts-tool.fish\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\ngit clone https://github.com/dnvriend/kokoro-tts-tool.git\ncd kokoro-tts-tool\nmake install\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install         # Install dependencies\nmake format          # Format code\nmake lint            # Run linting\nmake typecheck       # Type checking\nmake test            # Run tests\nmake security        # Security scans\nmake check           # All checks\nmake pipeline        # Full pipeline\n```\n\n### Project Structure\n\n```\nkokoro-tts-tool/\n‚îú‚îÄ‚îÄ kokoro_tts_tool/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py              # CLI entry point\n‚îÇ   ‚îú‚îÄ‚îÄ engine.py           # TTS engine wrapper\n‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Model management\n‚îÇ   ‚îú‚îÄ‚îÄ voices.py           # Voice definitions\n‚îÇ   ‚îú‚îÄ‚îÄ splitter.py         # Text chunking for long documents\n‚îÇ   ‚îú‚îÄ‚îÄ streaming.py        # Audio streaming for speaker playback\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py            # Utilities\n‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py   # Logging setup\n‚îÇ   ‚îú‚îÄ‚îÄ completion.py       # Shell completion\n‚îÇ   ‚îî‚îÄ‚îÄ commands/           # CLI commands\n‚îÇ       ‚îú‚îÄ‚îÄ synthesize_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ voice_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ init_commands.py\n‚îÇ       ‚îú‚îÄ‚îÄ info_commands.py\n‚îÇ       ‚îî‚îÄ‚îÄ infinite_commands.py\n‚îú‚îÄ‚îÄ tests/\n‚îú‚îÄ‚îÄ references/             # Research documentation\n‚îú‚îÄ‚îÄ plugins/                # Claude Code plugin\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ Makefile\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ CLAUDE.md\n```\n\n## Testing\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n```\n\n## Security\n\nThe project includes security scanning:\n\n```bash\n# Run all security checks\nmake security\n\n# Individual scans\nmake security-bandit       # Python security linting\nmake security-pip-audit    # Dependency CVE scanning\nmake security-gitleaks     # Secret detection\n```\n\n### Prerequisites\n\n```bash\n# Install gitleaks (macOS)\nbrew install gitleaks\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Run `make pipeline`\n5. Submit a Pull Request\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Author\n\n**Dennis Vriend** - [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- [Kokoro-82M](https://huggingface.co/hexgrad/Kokoro-82M) - The TTS model\n- [kokoro-onnx](https://github.com/thewh1teagle/kokoro-onnx) - ONNX implementation\n- [Click](https://click.palletsprojects.com/) - CLI framework\n- [uv](https://github.com/astral-sh/uv) - Fast Python tooling\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code).\n\nMade with Python 3.14\n"
      },
      "plugins": [
        {
          "name": "kokoro-tts-tool",
          "source": "./plugins/kokoro-tts-tool",
          "description": "A CLI that provides text-to-speech using kokoro",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/kokoro-tts-tool",
            "/plugin install kokoro-tts-tool@kokoro-tts-tool"
          ]
        }
      ]
    },
    {
      "name": "gemini-file-search-tool",
      "version": null,
      "description": "Manage Gemini File Search stores and query with RAG",
      "repo_full_name": "dnvriend/gemini-file-search-tool",
      "repo_url": "https://github.com/dnvriend/gemini-file-search-tool",
      "repo_description": "Production-ready CLI and Python library for Google's Gemini File Search API - A fully managed RAG system for document search and question-answering",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-31T23:41:21Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"gemini-file-search-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/gemini-file-search-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"gemini-file-search-tool\",\n            \"source\": \"./plugins/gemini-file-search-tool\",\n            \"description\": \"Manage Gemini File Search stores and query with RAG\"\n        }\n    ]\n}\n",
        "README.md": "# gemini-file-search-tool\n\n<div align=\"center\">\n  <img src=\".github/assets/rag-icon.png\" alt=\"RAG Icon\" width=\"200\" />\n  <br>\n  <br>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\n**Gemini File Search Tool** - Production-ready CLI & Python library for Google's fully managed RAG system\n\n</div>\n\n## Table of Contents\n\n- [About](#about)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Development](#development)\n- [Testing](#testing)\n- [Known Issues](#known-issues)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n- [Resources](#resources)\n\n## About\n\n`gemini-file-search-tool` is a production-ready CLI and Python library for [Google's Gemini File Search API](https://ai.google.dev/gemini-api/docs/file-search), a fully managed Retrieval-Augmented Generation (RAG) system that eliminates the operational complexity of vector databases, embeddings, and retrieval infrastructure.\n\n### What is Gemini File Search?\n\nGemini File Search is Google's fully managed RAG solution that automatically handles document ingestion, chunking, embedding generation, and semantic retrieval. As announced in [Google's developer blog](https://blog.google/technology/developers/file-search-gemini-api/), it provides enterprise-grade document search capabilities with zero infrastructure overhead, allowing developers to focus on building intelligent applications rather than managing search infrastructure.\n\n### Why This Tool?\n\nThis tool provides a **CLI-first interface** to the Gemini File Search API, designed specifically for integration with AI agents, automation workflows, and human operators:\n\n- **Agent-Friendly Design**: CLIs provide structured commands with built-in documentation and rich error messages that AI agents can parse and act upon in ReAct (Reasoning and Acting) loops, making them superior to standalone scripts for agentic workflows\n- **Composable Architecture**: JSON output to stdout and logs to stderr enable seamless piping and integration with other tools, perfect for complex automation pipelines\n- **Reusable Building Blocks**: Commands can be composed into larger workflows, used in skills for Claude Code, or integrated into custom automation without modification\n- **Dual-Mode Operation**: Functions as both a CLI tool for command-line operations and a Python library for programmatic integration\n- **Production Quality**: Type-safe, thoroughly tested, with comprehensive error handling that provides actionable feedback for both humans and agents\n\nWhether you're building AI-powered document search, integrating RAG into agentic workflows, or automating knowledge base operations, this tool provides the foundation for reliable, maintainable solutions.\n\n## Use Cases\n\n- **üìö Knowledge Base Management**: Index documentation, research papers, wikis, and technical specifications into searchable stores for instant retrieval\n- **üíª Code-RAG (Retrieval-Augmented Generation for Code)**: Upload entire codebases to enable semantic code search and natural language querying. Ask questions like \"how does authentication work?\", \"where is error handling implemented?\", or \"explain the database architecture\". Perfect for onboarding, code reviews, architecture discovery, and building AI coding assistants.\n- **üîç Semantic Search**: Query your document stores with natural language questions and receive contextually relevant answers with automatic citation\n- **üéØ RAG Applications**: Build production-ready retrieval-augmented generation systems with JSON-formatted responses including grounding metadata and source attribution\n\n### Code-RAG Example\n\nUpload a codebase and query it with natural language:\n\n```bash\n# Upload your entire codebase\ngemini-file-search-tool upload \"src/**/*.py\" --store \"my-project-code\" -v\n\n# Query with natural language\ngemini-file-search-tool query \"How does the authentication system work?\" \\\n  --store \"my-project-code\" --show-cost -v\n\n# Ask architectural questions\ngemini-file-search-tool query \"What design patterns are used in this codebase?\" \\\n  --store \"my-project-code\" --query-model pro\n\n# Find implementations\ngemini-file-search-tool query \"Where is error handling for API calls implemented?\" \\\n  --store \"my-project-code\"\n```\n\n**Meta Note**: This tool itself was built using Code-RAG! We uploaded the codebase to a Gemini File Search store and used it to answer questions during development. The tool enables the very functionality it provides.\n\n## Features\n\n- ‚úÖ **Fully Managed RAG**: Automatic chunking, embeddings, and retrieval without infrastructure management\n- ‚úÖ **Multi-Format Support**: PDF, DOCX, TXT, JSON, CSV, HTML, and source code files\n- ‚úÖ **Code-RAG Enabled**: Upload codebases and query with natural language for semantic code search\n- ‚úÖ **Intelligent Caching**: Local mtime-based cache (O(1) performance) prevents unnecessary re-uploads\n- ‚úÖ **Async Uploads**: `--no-wait` flag for fire-and-forget uploads with manual sync capability\n- ‚úÖ **Cache Management**: sync-cache, flush-cache, and cache-report commands for operation tracking\n- ‚úÖ **Query Enhancement**: LLM-powered query optimization for better RAG retrieval (generic, code-rag, obsidian modes)\n- ‚úÖ **Natural Language Queries**: Ask questions in plain language and get contextual answers\n- ‚úÖ **Automatic Citations**: Built-in source attribution and grounding metadata\n- ‚úÖ **Multi-Level Verbosity**: Progressive logging detail with `-v` (INFO), `-vv` (DEBUG), `-vvv` (TRACE)\n- ‚úÖ **Cost Tracking**: Token usage monitoring and cost estimation for both enhancement and query operations\n- ‚úÖ **Composable CLI**: JSON output for easy integration with other tools and scripts\n- ‚úÖ **Python Library**: Import and use programmatically in your applications\n- ‚úÖ **Type-Safe**: Strict mypy type checking and modern Python 3.14+ syntax\n- ‚úÖ **Production-Ready**: Comprehensive testing, linting, and quality checks\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- Google Gemini API access (see [Configuration](#configuration))\n\n### Core Dependencies\n\nThis tool uses the [Google Generative AI Python SDK](https://github.com/googleapis/python-genai) (`google-genai`) for interacting with Google's Gemini API.\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd gemini-file-search-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\ngemini-file-search-tool --version\n```\n\n## Configuration\n\n### Environment Variables\n\nThe CLI automatically detects and supports both authentication methods. Configuration depends on whether you're using the Gemini Developer API or the Gemini API in Vertex AI.\n\n#### Gemini Developer API (Recommended)\n\nSet `GEMINI_API_KEY` or `GOOGLE_API_KEY`. The client will automatically pick up these variables. If both are set, `GOOGLE_API_KEY` takes precedence.\n\n```bash\nexport GEMINI_API_KEY='your-api-key'\n```\n\n**Get your API key:**\n1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)\n2. Create or select a project\n3. Generate an API key\n4. Set the environment variable\n\n**Example:**\n```bash\nexport GEMINI_API_KEY='AIza...'\ngemini-file-search-tool list-stores\n```\n\n#### Gemini API on Vertex AI\n\nFor Vertex AI, set the following environment variables:\n\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='your-project-id'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n```\n\n**Prerequisites:**\n- Google Cloud project with Vertex AI API enabled\n- Proper IAM permissions for Vertex AI\n- Authenticated with `gcloud auth application-default login`\n\n**Example:**\n```bash\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='my-project'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n\n# Authenticate with Google Cloud\ngcloud auth application-default login\n\n# Use the CLI (automatically uses Vertex AI)\ngemini-file-search-tool list-stores\n```\n\n**Note:** The CLI automatically detects which authentication method to use based on the `GOOGLE_GENAI_USE_VERTEXAI` environment variable.\n\nFor more information, see the [Google Generative AI Python SDK documentation](https://github.com/googleapis/python-genai).\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Show help\ngemini-file-search-tool --help\n\n# Show version\ngemini-file-search-tool --version\n\n# Get help for specific commands\ngemini-file-search-tool create-store --help\ngemini-file-search-tool upload --help\n```\n\n### Store Management\n\n```bash\n# Create a new store\ngemini-file-search-tool create-store \"my-documents\"\n\n# List all stores\ngemini-file-search-tool list-stores\n\n# Get store details\ngemini-file-search-tool get-store \"my-documents\"\n\n# Update store display name\ngemini-file-search-tool update-store \"my-documents\" --display-name \"My Documents 2024\"\n\n# Delete a store\ngemini-file-search-tool delete-store \"my-documents\" --force\n```\n\n### Document Management\n\n```bash\n# Upload a single file\ngemini-file-search-tool upload document.pdf --store \"my-documents\"\n\n# Upload multiple files with glob pattern\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\"\n\n# Recursive upload\ngemini-file-search-tool upload \"docs/**/*.md\" --store \"my-documents\"\n\n# Upload with metadata\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --title \"Important Document\" \\\n  --url \"https://example.com/doc\"\n\n# Upload with custom chunking\ngemini-file-search-tool upload document.pdf --store \"my-documents\" \\\n  --max-tokens 300 \\\n  --max-overlap 25\n\n# Upload respecting .gitignore (default behavior)\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" -v\n\n# Upload ignoring .gitignore patterns\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --ignore-gitignore\n\n# Dry-run to preview files before uploading\ngemini-file-search-tool upload \"**/*.py\" --store \"my-codebase\" --dry-run -v\n\n# Upload with verbose logging (see what's happening)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -v\n\n# Upload with debug logging (see detailed operations)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vv\n\n# Upload with trace logging (see full API calls)\ngemini-file-search-tool upload \"*.pdf\" --store \"my-documents\" -vvv\n\n# List documents in a store\ngemini-file-search-tool list-documents --store \"my-documents\"\n\n# List documents with verbose output\ngemini-file-search-tool list-documents --store \"my-documents\" -v\n```\n\n### Querying\n\n**‚ö° Recommended Configuration (Based on Benchmarks)**\n\nFor optimal cost-quality balance, use the default configuration with no enhancement:\n\n```bash\n# Recommended: No enhancement + Flash model (best value)\ngemini-file-search-tool query \"What are the key findings?\" \\\n  --store \"my-documents\"\n\n# With cost tracking and grounding metadata\ngemini-file-search-tool query \"Explain the methodology\" \\\n  --store \"my-documents\" --show-cost --query-grounding-metadata -v\n```\n\n**Performance Benchmarks** (30 queries across 6 configurations):\n- **Quality Score**: 97.7/100\n- **Cost**: ~$0.00013 per query\n- **Success Rate**: 100% (vs 20-80% with enhancement)\n- **Value**: 156.1 quality points per $0.001 (6.6x better than enhancement)\n\nSee `references/benchmark-model-comparison-2025-11-16.md` for detailed analysis.\n\n**Other Query Options:**\n\n```bash\n# Query with Pro model (complex analytical questions)\ngemini-file-search-tool query \"Analyze the technical architecture\" \\\n  --store \"my-documents\" --query-model pro\n\n# Query with metadata filter\ngemini-file-search-tool query \"Tell me about the book\" \\\n  --store \"my-documents\" --metadata-filter \"author=Robert Graves\"\n\n# Query with enhancement (only for vague/exploratory queries)\ngemini-file-search-tool query \"authentication stuff\" \\\n  --store \"my-documents\" --enhance-mode code-rag --show-enhancement\n\n# Query with debug logging (see API operations)\ngemini-file-search-tool query \"What are the findings?\" \\\n  --store \"my-documents\" --show-cost -vv\n\n# Query with trace logging (see full HTTP requests)\ngemini-file-search-tool query \"Analyze this\" \\\n  --store \"my-documents\" --show-cost -vvv\n```\n\n**‚ö†Ô∏è Query Enhancement Notes:**\n\nBased on comprehensive benchmarks, **query enhancement is disabled by default** and should only be used for:\n- Vague or poorly worded queries (\"authentication stuff\", \"that database thing\")\n- Exploratory queries where you're unsure what you're looking for\n- Cases where simple queries consistently fail to retrieve relevant documents\n\n**Why?** Enhancement makes queries too specific, reducing retrieval success rates from 100% to 20-80%. Simple, natural language queries work best for RAG systems (see [Lewis et al., 2020](https://arxiv.org/abs/2005.11401)).\n\n### Cost Tracking\n\nThe CLI automatically tracks token usage for query operations and can estimate costs based on current Gemini API pricing:\n\n```bash\n# View token usage (verbose mode)\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n\n# Show estimated cost\ngemini-file-search-tool query \"What is this about?\" \\\n  --store \"my-documents\" --show-cost -v\n\n# Output:\n# [INFO] Token usage: 150 prompt + 320 candidates = 470 total\n# [INFO] Estimated cost: $0.00010725 USD\n```\n\n**Query Response with Cost Information:**\n\n```json\n{\n  \"response_text\": \"The document discusses...\",\n  \"usage_metadata\": {\n    \"prompt_token_count\": 150,\n    \"candidates_token_count\": 320,\n    \"total_token_count\": 470\n  },\n  \"estimated_cost\": {\n    \"input_cost_usd\": 0.00001125,\n    \"output_cost_usd\": 0.000096,\n    \"total_cost_usd\": 0.00010725,\n    \"currency\": \"USD\",\n    \"model\": \"gemini-2.5-flash\",\n    \"note\": \"Estimated cost based on current pricing. Subject to change.\"\n  }\n}\n```\n\n**Current Pricing (as of 2025-01):**\n- **gemini-2.5-flash**: $0.075 input / $0.30 output per 1M tokens\n- **gemini-2.5-pro**: $1.25 input / $5.00 output per 1M tokens\n\n**Note**: Pricing is subject to change. Verify current rates at [Google AI Pricing](https://ai.google.dev/pricing).\n\n**Limitations:**\n- Token usage is only available for query operations\n- Upload costs (document embedding) are not tracked by the API\n- Cost estimates are calculated locally using published pricing\n\n### Upload Features\n\n**Intelligent Caching**:\n- **Local Cache**: Automatically tracks uploaded files at `~/.config/gemini-file-search-tool/stores/`\n- **Per-Store Isolation**: Each store maintains its own cache file (e.g., `fileSearchStores__my-store.json`)\n- **mtime Optimization**: O(n) ‚Üí O(1) performance - checks file modification time before computing expensive SHA256 hash\n- **Smart Re-uploads**: Only uploads files that have actually changed (skips identical files automatically)\n- **Cache Structure**: Stores hash, mtime, remote_id, and last_uploaded timestamp for each file\n- **Performance Impact**:\n  - **Large codebases (1000 files)**: Cache check ~0.1 seconds vs ~5-10 seconds without cache\n  - **Network I/O remains the bottleneck**: Upload time (5-10s per file) dominates hash calculation (500ms)\n  - See `docs/cache-design.md` for detailed performance analysis and architecture\n\n**Automatic File Validation**:\n- **Empty Files**: 0-byte files automatically skipped with warning\n- **File Size**: 50MB limit enforced\n- **Base64 Images**: Detects base64-encoded images in text files (can cause upload failures)\n- **System Files**: Auto-skips `__pycache__`, `.pyc`, `.DS_Store`, etc.\n- **Gitignore Support**: Automatically respects `.gitignore` patterns (use `--ignore-gitignore` to disable)\n- **MIME Types**: Automatic registration for `.toml`, `.env`, `.txt`, `.md` files\n\n**Duplicate Detection**:\n- Automatically detects existing files by name and size\n- Skips unchanged files (no re-upload)\n- Updates files when size changes (deletes old, uploads new)\n\n**Preview & Control**:\n- **Dry-Run**: Use `--dry-run` to preview which files would be uploaded without actually uploading\n- **Skip Validation**: Use `--skip-validation` to bypass checks for faster uploads\n- **Ignore Gitignore**: Use `--ignore-gitignore` to upload files normally excluded by .gitignore\n\n### Dry-Run Mode\n\nPreview which files would be uploaded without actually uploading:\n\n```bash\n# Preview files with sizes\ngemini-file-search-tool upload \"**/*.py\" --store \"code\" --dry-run -v\n\n# Output (to stderr):\n# [INFO] Loaded 38 patterns from .gitignore\n# [INFO] DRY-RUN: Would upload 13 file(s)\n\n# Output (to stdout - JSON):\n[\n  {\n    \"file\": \"/path/to/file1.py\",\n    \"size_bytes\": 1809,\n    \"size_mb\": 0.0\n  },\n  {\n    \"file\": \"/path/to/file2.py\",\n    \"size_bytes\": 2691,\n    \"size_mb\": 0.0\n  }\n]\n```\n\n**Benefits**:\n- **Preview Files**: See exactly which files match your glob pattern\n- **Verify Gitignore**: Confirm .gitignore filtering is working correctly\n- **Check Sizes**: Review file sizes before uploading\n- **No API Calls**: Completely safe, no interaction with Gemini API\n\n### Verbosity Levels\n\nAll commands support multi-level verbosity for controlling log output detail:\n\n| Flag | Level | Description | Use Case |\n|------|-------|-------------|----------|\n| (none) | WARNING | Only critical errors | Production, clean output |\n| `-v` | INFO | High-level operations | See progress, identify failures |\n| `-vv` | DEBUG | Detailed operations | Debug issues, see API calls |\n| `-vvv` | TRACE | Full API details | Deep debugging, HTTP traces |\n\n**Examples:**\n\n```bash\n# INFO level: See which files are uploaded/failed\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -v\n\n# DEBUG level: See validation, polling, API operations\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vv\n\n# TRACE level: See full HTTP requests/responses from SDK\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" -vvv\n```\n\n**Output:**\n\n```bash\n# With -v (INFO)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[INFO] Upload completed successfully: document.pdf\n\n# With -vv (DEBUG)\n[INFO] Starting upload operation\n[INFO] Uploading: document.pdf (2.50MB) to store 'fileSearchStores/docs-123'\n[DEBUG] Validating file: document.pdf\n[DEBUG] File validation passed: document.pdf\n[DEBUG] Starting upload operation for: document.pdf\n[DEBUG] Operation started: operations/upload-abc123\n[DEBUG] Polling operation operations/upload-abc123 (attempt 1) - waiting 2.0s\n[DEBUG] Polling operation operations/upload-abc123 (attempt 2) - waiting 3.0s\n[INFO] Upload completed successfully: document.pdf\n\n# With -vvv (TRACE) - includes all above plus:\n[DEBUG] (httpx) HTTP Request: POST https://...\n[DEBUG] (httpx) HTTP Response: 200 OK\n```\n\n**Benefits:**\n- **Real-time Feedback**: See progress and failures as they happen (not just in final JSON)\n- **Progressive Detail**: Choose the right level of verbosity for your needs\n- **Clean stdout**: All logs go to stderr, keeping JSON output clean for piping\n- **Library Logging**: At `-vvv`, see internals from `httpx`, `google-api-core`, etc.\n\n### Cache Management\n\nThe CLI provides commands to manage the local cache for asynchronous upload operations and cache maintenance.\n\n#### Asynchronous Uploads\n\nUse `--no-wait` to skip operation polling and return immediately after initiating uploads:\n\n```bash\n# Fast async uploads (don't wait for completion)\ngemini-file-search-tool upload \"*.pdf\" --store \"docs\" --no-wait -v\n\n# Output: Returns immediately with \"pending\" status\n[\n  {\"file\": \"doc1.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"},\n  {\"file\": \"doc2.pdf\", \"status\": \"pending\", \"operation\": \"operations/...\"}\n]\n```\n\n**Benefits**:\n- **Faster Returns**: No polling overhead (~2-10s per file saved)\n- **Bulk Operations**: Initiate thousands of uploads quickly\n- **Fire-and-Forget**: Useful for known-working file types where immediate feedback isn't needed\n- **Last-One-Wins**: Re-uploading a file automatically overwrites previous pending operations\n\n**Trade-offs**:\n- No immediate status (success/failure unknown until synced)\n- Requires manual `sync-cache` to check final status\n\n#### Sync Cache\n\nCheck status of pending operations and update cache with final results:\n\n```bash\n# Sync all pending operations for a store\ngemini-file-search-tool sync-cache --store \"docs\" -v\n\n# With custom number of workers (default: 4)\ngemini-file-search-tool sync-cache --store \"docs\" --num-workers 8 -v\n\n# Output (JSON - default):\n{\n  \"status\": \"success\",\n  \"total\": 10,\n  \"synced\": 8,\n  \"failed\": 1,\n  \"still_pending\": 1,\n  \"operations\": [\n    {\"file\": \"doc1.pdf\", \"status\": \"synced\", \"remote_id\": \"documents/...\"},\n    {\"file\": \"doc2.pdf\", \"status\": \"failed\", \"error\": {\"message\": \"...\"}}\n  ]\n}\n\n# Human-readable text output\ngemini-file-search-tool sync-cache --store \"docs\" --text\n\n# Output (text):\nSync Summary:\n  Total operations: 10\n  Synced: 8\n  Failed: 1\n  Still pending: 1\n```\n\n**Features**:\n- **Parallel Processing**: Fetches operation status concurrently with configurable workers (default: 4)\n- **Batch Cache Writes**: Collects all updates and writes cache once at the end (not per-operation)\n- **Progress Bar**: Visual feedback with tqdm during sync\n- **Error Details**: Captures and stores error messages from failed operations\n- **Automatic Updates**: Updates cache with remote_id when operations complete successfully\n- **Idempotent**: Safe to run multiple times (only updates changed operations)\n\n#### Cache Report\n\nGenerate reports on cache status with filtering options:\n\n```bash\n# Default report (summary + pending operations)\ngemini-file-search-tool cache-report --store \"docs\"\n\n# Show only failed operations\ngemini-file-search-tool cache-report --store \"docs\" --errors-only\n\n# Show only completed uploads\ngemini-file-search-tool cache-report --store \"docs\" --completed-only\n\n# Show all cached files\ngemini-file-search-tool cache-report --store \"docs\" --all\n\n# Human-readable text output\ngemini-file-search-tool cache-report --store \"docs\" --text\n```\n\n**Output Example (JSON)**:\n```json\n{\n  \"store\": \"docs\",\n  \"stats\": {\n    \"total_files\": 100,\n    \"completed\": 95,\n    \"pending_operations\": 3,\n    \"failed_operations\": 2\n  },\n  \"files\": [\n    {\n      \"file\": \"/path/to/doc.pdf\",\n      \"status\": \"pending\",\n      \"operation\": \"operations/...\",\n      \"hash\": \"abc123...\",\n      \"mtime\": 1731969000.0\n    }\n  ]\n}\n```\n\n**Filters**:\n- `--pending-only`: Show only files with pending operations\n- `--errors-only`: Show only files with errors\n- `--completed-only`: Show only successfully uploaded files\n- `--all`: Show all cached files (overrides other filters)\n- `--text`: Human-readable text format instead of JSON\n\n#### Flush Cache\n\nDelete cache file for a specific store:\n\n```bash\n# Flush with confirmation prompt\ngemini-file-search-tool flush-cache --store \"docs\"\n\n# Output:\nCache statistics for 'docs':\n  Total files: 100\n  Completed: 95\n  Pending operations: 3\n  Failed operations: 2\n\nAre you sure you want to delete this cache? [y/N]:\n\n# Force flush without confirmation\ngemini-file-search-tool flush-cache --store \"docs\" --force\n```\n\n**Use Cases**:\n- **Clean Slate**: Start fresh after major changes\n- **Rebuild Cache**: Use with `upload --rebuild-cache` to re-upload everything\n- **Troubleshooting**: Clear corrupted cache data\n\n#### Cache with Store Deletion\n\nWhen deleting a store, cache statistics are shown and the cache is automatically removed:\n\n```bash\n# Delete store with cache cleanup\ngemini-file-search-tool delete-store \"docs\" --force\n\n# Output shows cache stats before deletion:\n[INFO] Cache found for store 'docs':\n[INFO]   Total files: 100\n[INFO]   Completed: 95\n[INFO]   Pending operations: 3\n[INFO]   Failed operations: 2\n[INFO] Deleting store: fileSearchStores/docs-123\n[INFO] Removing cache file...\n[INFO] Cache removed successfully\n```\n\n#### Typical Workflows\n\n**Async Upload + Sync Pattern:**\n```bash\n# 1. Fast upload without waiting\ngemini-file-search-tool upload \"docs/**/*.pdf\" --store \"my-docs\" --no-wait -v\n\n# 2. Continue working on other tasks...\n\n# 3. Later, check status\ngemini-file-search-tool sync-cache --store \"my-docs\" -v\n\n# 4. Review any failures\ngemini-file-search-tool cache-report --store \"my-docs\" --errors-only\n```\n\n**Re-upload Changed Files:**\n```bash\n# Upload with last-one-wins strategy\n# If files change and you re-upload, previous pending operations are overwritten\ngemini-file-search-tool upload \"docs/*.pdf\" --store \"my-docs\" --no-wait\n\n# The cache automatically tracks the latest operation-id per file\n```\n\n**Cache Inspection:**\n```bash\n# Quick overview\ngemini-file-search-tool cache-report --store \"my-docs\" --text\n\n# Detailed analysis\ngemini-file-search-tool cache-report --store \"my-docs\" --all | jq .\n```\n\n### Library Usage\n\nYou can also use this package as a Python library:\n\n```python\nfrom pathlib import Path\nfrom gemini_file_search_tool import (\n    create_store,\n    upload_file,\n    query_store,\n    list_documents,\n)\n\n# Create a store\nstore = create_store(\"my-documents\")\nprint(f\"Created store: {store['name']}\")\n\n# Upload a file\nresult = upload_file(\n    file_path=Path(\"document.pdf\"),\n    store_name=store[\"name\"],\n    title=\"Important Document\"\n)\nprint(f\"Upload status: {result['status']}\")\n\n# Query the store\nresponse = query_store(\n    store_name=store[\"name\"],\n    prompt=\"What is in this document?\",\n    model=\"gemini-2.5-flash\"\n)\nprint(response[\"response_text\"])\n\n# List documents\ndocuments = list_documents(store[\"name\"])\nprint(f\"Found {len(documents)} documents\")\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/gemini-file-search-tool.git\ncd gemini-file-search-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake check            # Run all checks (lint, typecheck, test)\nmake pipeline         # Run full pipeline (format, lint, typecheck, test, build, install-global)\nmake build            # Build package\nmake run ARGS=\"...\"   # Run gemini-file-search-tool locally\nmake clean            # Remove build artifacts\n```\n\n### Project Structure\n\n```\ngemini-file-search-tool/\n‚îú‚îÄ‚îÄ gemini_file_search_tool/    # Main package\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py          # CLI entry point\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Utility functions\n‚îú‚îÄ‚îÄ tests/              # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py\n‚îú‚îÄ‚îÄ pyproject.toml      # Project configuration\n‚îú‚îÄ‚îÄ Makefile            # Development commands\n‚îú‚îÄ‚îÄ README.md           # This file\n‚îú‚îÄ‚îÄ LICENSE             # MIT License\n‚îî‚îÄ‚îÄ CLAUDE.md           # Development documentation\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_utils.py\n\n# Run with coverage\nuv run pytest tests/ --cov=gemini_file_search_tool\n```\n\n## Known Issues\n\n### SDK Bug #1661 - Document Listing with Vertex AI\n\n**Issue**: The Google Generative AI Python SDK has a bug ([#1661](https://github.com/googleapis/python-genai/issues/1661)) where `documents.list()` requires a 'parent' parameter that causes failures.\n\n**Impact**: The `list-documents` command cannot be used with Vertex AI authentication.\n\n**Workaround**: We use the REST API directly instead of the SDK's `documents.list()` method. This workaround only works with the Developer API (requires `GEMINI_API_KEY` or `GOOGLE_API_KEY`).\n\n**Status**: Waiting for upstream fix in the Google Generative AI Python SDK.\n\n**Affected Commands**:\n- `list-documents` - Only works with Developer API, not Vertex AI\n\n**Code Location**: `gemini_file_search_tool/core/documents.py:list_documents()`\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run the full pipeline (`make pipeline`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to the branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints for all functions\n- Write docstrings for public functions\n- Format code with `ruff`\n- Pass all linting and type checks\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n## Resources\n\n### Gemini File Search Documentation\n\n- **[Gemini File Search API Documentation](https://ai.google.dev/gemini-api/docs/file-search)** - Official API documentation and guides\n- **[Gemini API File Search Stores Reference](https://ai.google.dev/api/file-search/file-search-stores)** - API reference for file search stores\n- **[Introducing File Search for the Gemini API](https://blog.google/technology/developers/file-search-gemini-api/)** - Official announcement and overview from Google\n\n### Related Tools\n\n- **[Google Generative AI Python SDK](https://github.com/googleapis/python-genai)** - Python SDK for Google's Gemini API\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "gemini-file-search-tool",
          "source": "./plugins/gemini-file-search-tool",
          "description": "Manage Gemini File Search stores and query with RAG",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/gemini-file-search-tool",
            "/plugin install gemini-file-search-tool@gemini-file-search-tool"
          ]
        }
      ]
    },
    {
      "name": "slack-messaging-tool",
      "version": null,
      "description": "Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool",
      "repo_full_name": "dnvriend/slack-messaging-tool",
      "repo_url": "https://github.com/dnvriend/slack-messaging-tool",
      "repo_description": "slack-messaging-tool",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-26T07:42:46Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"slack-messaging-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend\"\n    },\n    \"metadata\": {\n        \"description\": \"Marketplace for slack-messaging-tool CLI plugin - A Python CLI tool\",\n        \"version\": \"0.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"slack-messaging-tool\",\n            \"source\": \"./plugins/slack-messaging-tool\",\n            \"description\": \"A Python CLI tool\"\n        }\n    ]\n}\n",
        "README.md": "# slack-messaging-tool\n\n<p align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"slack-messaging-tool logo\" width=\"128\">\n</p>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n\nA CLI tool that provides Slack messaging capabilities via the Slack API.\n\n## Features\n\n- Send messages to Slack channels (by name or ID)\n- Support for Slack Block Kit rich layouts\n- List available channels in workspace\n- Bot token authentication\n- Multi-level verbosity logging\n- OpenTelemetry observability\n- Shell completion (bash, zsh, fish)\n\n## Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/dnvriend/slack-messaging-tool.git\ncd slack-messaging-tool\nuv tool install .\n\n# Verify\nslack-messaging-tool --version\n```\n\n## Usage\n\n```bash\n# Set your bot token\nexport SLACK_BOT_TOKEN=xoxb-your-bot-token\n\n# List channels\nslack-messaging-tool channels\n\n# Send a message\nslack-messaging-tool send -c general -m \"Hello team!\"\n\n# Send with Block Kit\nslack-messaging-tool send -c general -m \"Fallback\" \\\n    --blocks '[{\"type\":\"section\",\"text\":{\"type\":\"mrkdwn\",\"text\":\"*Bold*\"}}]'\n\n# Enable verbose logging\nslack-messaging-tool -v channels\n```\n\n## Environment Variables\n\n| Variable | Required | Default | Description |\n|----------|----------|---------|-------------|\n| `SLACK_BOT_TOKEN` | Yes | - | Slack bot token (xoxb-...) |\n| `OTEL_ENABLED` | No | `false` | Enable OpenTelemetry |\n| `OTEL_EXPORTER_TYPE` | No | `console` | `console` or `otlp` |\n| `OTEL_EXPORTER_OTLP_ENDPOINT` | No | `http://localhost:4317` | OTLP endpoint |\n| `LOG_FILE` | No | - | Path to log file |\n\n## Documentation\n\n- [Logging](references/logging.md) - Multi-level verbosity logging\n- [Telemetry](references/telemetry.md) - OpenTelemetry observability\n- [Shell Completion](references/shell-completion.md) - Tab completion setup\n- [Development](references/development.md) - Contributing guide\n\n## Development\n\n```bash\nmake install    # Install dependencies\nmake test       # Run tests\nmake pipeline   # Full CI pipeline\n```\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Author\n\n**Dennis Vriend** - [@dnvriend](https://github.com/dnvriend)\n"
      },
      "plugins": [
        {
          "name": "slack-messaging-tool",
          "source": "./plugins/slack-messaging-tool",
          "description": "A Python CLI tool",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/slack-messaging-tool",
            "/plugin install slack-messaging-tool@slack-messaging-tool"
          ]
        }
      ]
    },
    {
      "name": "concat-glob-tool",
      "version": null,
      "description": "Concatenate files with glob patterns and separators",
      "repo_full_name": "dnvriend/concat-glob-tool",
      "repo_url": "https://github.com/dnvriend/concat-glob-tool",
      "repo_description": "A CLI tool that concatenates files matching glob patterns with intelligent separators",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-05T06:43:41Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"concat-glob-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dvriend@ilionx.com\",\n        \"url\": \"https://github.com/dnvriend/concat-glob-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"concat-glob-tool\",\n            \"source\": \"./plugins/concat-glob-tool\",\n            \"description\": \"Concatenate files with glob patterns and separators\"\n        }\n    ]\n}\n",
        "README.md": "# concat-glob-tool\n\n<div align=\"center\">\n  <img src=\".github/assets/logo-web.png\" alt=\"concat-glob-tool logo\" width=\"200\"/>\n  <p><em>Concatenate files with intelligent separators</em></p>\n</div>\n\n[![Python Version](https://img.shields.io/badge/python-3.14+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA CLI tool that concatenates files matching glob patterns with intelligent separators and agent-friendly design.\n\n## Table of Contents\n\n- [About](#about)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Library Usage](#library-usage)\n- [Multi-Level Verbosity Logging](#multi-level-verbosity-logging)\n- [Shell Completion](#shell-completion)\n- [Development](#development)\n- [Testing](#testing)\n- [Security](#security)\n- [Contributing](#contributing)\n- [License](#license)\n- [Author](#author)\n\n## About\n\n`concat-glob-tool` is a CLI-first utility that concatenates multiple files into a single output file with intelligent separators. Built with modern Python tooling and designed for both human use and AI agent integration.\n\n### What is concat-glob-tool?\n\n`concat-glob-tool` provides a simple yet powerful way to combine multiple files into a single file with clear separators between each file. It's particularly useful for:\n\n- Creating context files for Large Language Models (LLMs)\n- Combining source code for documentation or analysis\n- Aggregating log files or configuration files\n- Building single-file distributions\n\n### Why CLI-First?\n\nThis tool follows a CLI-first design philosophy, making it:\n\n- **ü§ñ Agent-Friendly**: Designed for AI agents (Claude Code) with structured commands, clear error messages, and working examples in help text\n- **üîó Composable**: JSON output to stdout, logs to stderr for easy piping and integration with automation tools\n- **üß± Reusable**: Commands serve as building blocks for Claude Code skills, MCP servers, shell scripts, or custom workflows\n- **‚úÖ Reliable**: Type-safe with comprehensive testing ensures predictable behavior in automated systems\n- **üìö Self-Documenting**: Rich help messages guide both humans and agents through usage patterns\n- **üîß Maintainable**: Modular architecture makes it easy to extend, debug, and evolve\n\n### Dual-Mode Operation\n\n- **CLI Mode**: Use as a standalone command-line tool with all features\n- **Library Mode**: Import core functions for programmatic integration in Python scripts\n\n## Use Cases\n\n- üìö **LLM Context Generation**: Combine multiple source files into a single context file for feeding to Large Language Models\n- üíª **Code Documentation**: Aggregate source code files for documentation or code review\n- üîç **Log Analysis**: Merge multiple log files with clear file separators for easier analysis\n- üì¶ **Single-File Distribution**: Create self-contained bundles of configuration or template files\n- üéØ **RAG Preparation**: Prepare documents for Retrieval-Augmented Generation systems\n- ü§ñ **Agent Integration**: Build reusable file processing pipelines for AI automation workflows\n\n## Features\n\n- üéØ **Glob Pattern Matching**: Support for multiple glob patterns including recursive patterns (`**/*.py`)\n- üì• **Stdin Support**: Read file paths from stdin for integration with other tools (e.g., `find`)\n- üîÄ **Intelligent Separators**: Files are separated with headers including the filename\n- üîç **Dry-Run Mode**: Preview operations before execution (enabled by default)\n- üí™ **Force Overwrite**: Safely overwrite existing files with explicit flag\n- üé® **Custom Separators**: Configurable separator text between files\n- ‚úÖ Type-safe with mypy strict mode\n- ‚úÖ Linted with ruff\n- ‚úÖ Tested with pytest\n- üìä Multi-level verbosity logging (-v/-vv/-vvv)\n- üêö Shell completion for bash, zsh, and fish\n- üîí Security scanning with bandit, pip-audit, and gitleaks\n- ‚úÖ Modern Python tooling (uv, mise, click)\n- üì¶ Dual-mode: CLI tool + importable Python library\n\n## Installation\n\n### Prerequisites\n\n- Python 3.14 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/concat-glob-tool.git\ncd concat-glob-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Install with mise (recommended for development)\n\n```bash\ncd concat-glob-tool\nmise trust\nmise install\nuv sync\nuv tool install .\n```\n\n### Verify installation\n\n```bash\nconcat-glob-tool --version\n```\n\n## Configuration\n\nNo configuration files are required. All settings are controlled via command-line flags.\n\n### Environment Variable Expansion\n\nGlob patterns support:\n- **Home directory expansion**: `~` expands to your home directory\n- **Environment variables**: `$VAR` or `${VAR}` expand to environment variable values\n- **Relative paths**: Automatically resolved from current working directory\n\n## Usage\n\n### Quick Start\n\n```bash\n# Preview concatenation (dry-run mode, default)\nconcat-glob-tool '*.py' --output-file result.txt\n\n# Execute concatenation\nconcat-glob-tool '*.py' --output-file result.txt --no-dry-run\n\n# Multiple patterns\nconcat-glob-tool '*.py' '*.md' -o combined.txt --no-dry-run\n\n# Recursive patterns\nconcat-glob-tool 'src/**/*.py' -o all-code.txt --no-dry-run\n```\n\n### Complete CLI Reference\n\n```bash\nconcat-glob-tool [PATTERNS...] --output-file FILE [OPTIONS]\nconcat-glob-tool --stdin --output-file FILE [OPTIONS]\n```\n\n#### Arguments\n\n- `PATTERNS...` - One or more glob patterns (e.g., `*.py`, `src/**/*.md`)\n\n#### Options\n\n| Option | Short | Description | Default |\n|--------|-------|-------------|---------|\n| `--output-file` | `-o` | Output file path (required) | - |\n| `--stdin` | `-s` | Read file paths from stdin | False |\n| `--separator` | - | Separator text between files | `---` |\n| `--dry-run` | `-n` | Preview without writing | True |\n| `--no-dry-run` | - | Execute the concatenation | False |\n| `--force` | `-f` | Overwrite existing output file | False |\n| `--verbose` | `-v` | Enable verbose output (repeatable) | 0 |\n| `--version` | - | Show version | - |\n| `--help` | - | Show help message | - |\n\n### Examples\n\n#### Basic Concatenation\n\n```bash\n# Concatenate all Python files in current directory\nconcat-glob-tool '*.py' -o output.txt --no-dry-run\n\n# Concatenate multiple file types\nconcat-glob-tool '*.py' '*.md' '*.txt' -o combined.txt --no-dry-run\n```\n\n#### Recursive Patterns\n\n```bash\n# All Python files in src/ and subdirectories\nconcat-glob-tool 'src/**/*.py' -o all-code.txt --no-dry-run\n\n# Multiple recursive patterns\nconcat-glob-tool 'src/**/*.py' 'tests/**/*.py' -o codebase.txt --no-dry-run\n```\n\n#### Stdin Integration\n\n```bash\n# Use find to locate files\nfind . -name '*.py' -type f | concat-glob-tool --stdin -o output.txt --no-dry-run\n\n# Use fd (faster find alternative)\nfd -e py | concat-glob-tool --stdin -o output.txt --no-dry-run\n\n# Filter with grep\nfind . -name '*.py' | grep -v test | concat-glob-tool --stdin -o output.txt --no-dry-run\n```\n\n#### Custom Separators\n\n```bash\n# Custom separator text\nconcat-glob-tool '*.py' -o output.txt --separator '====' --no-dry-run\n\n# Simple separator\nconcat-glob-tool '*.py' -o output.txt --separator '---' --no-dry-run\n```\n\n#### Dry-Run and Force\n\n```bash\n# Preview without writing (default)\nconcat-glob-tool '*.py' -o output.txt\n\n# Preview with verbose output\nconcat-glob-tool '*.py' -o output.txt -v\n\n# Execute concatenation\nconcat-glob-tool '*.py' -o output.txt --no-dry-run\n\n# Overwrite existing file\nconcat-glob-tool '*.py' -o existing.txt --force --no-dry-run\n```\n\n#### LLM Context Generation\n\n```bash\n# Create context file for Claude Code\nconcat-glob-tool 'src/**/*.py' 'tests/**/*.py' '*.md' \\\n    -o llm-context.txt \\\n    --separator '---' \\\n    --no-dry-run\n\n# Create documentation bundle\nconcat-glob-tool 'docs/**/*.md' 'README.md' 'CLAUDE.md' \\\n    -o full-docs.txt \\\n    --no-dry-run\n```\n\n### Output Format\n\nFiles are concatenated with this separator format between each file (except before the first file):\n\n```\n---\n# /path/to/file.py\n---\n[file contents]\n```\n\nThe separator includes:\n- Blank line before separator\n- Separator line (`---` by default)\n- Comment line with full file path\n- Separator line\n- Blank line before file contents\n\n### Error Handling\n\nThe tool provides clear error messages with solutions:\n\n```bash\n# No matches\n$ concat-glob-tool '*.nonexistent' -o out.txt --no-dry-run\nError: No files matched the patterns: *.nonexistent\n\nSolution: Verify glob patterns are correct. Examples:\n  - '*.py' for Python files in current directory\n  - '**/*.py' for Python files recursively\n\n# Output exists\n$ concat-glob-tool '*.py' -o existing.txt --no-dry-run\nError: Output file already exists: existing.txt\n\nSolution: Use --force to overwrite or choose a different output file.\n\n# Invalid stdin usage\n$ concat-glob-tool '*.py' --stdin -o out.txt\nError: Cannot use both --stdin and glob patterns.\n\nSolution: Use either --stdin OR provide glob patterns, not both.\n```\n\n## Library Usage\n\n`concat-glob-tool` can also be used as a Python library for programmatic integration.\n\n### Installation as Library\n\n```bash\npip install concat-glob-tool\n# or\nuv add concat-glob-tool\n```\n\n### Core API\n\n```python\nfrom concat_glob_tool import (\n    expand_glob_patterns,\n    concatenate_files,\n    format_separator,\n    read_paths_from_stdin,\n    ConcatError,\n    NoMatchesError,\n    OutputExistsError,\n)\nfrom pathlib import Path\n\n# Expand glob patterns\nfiles = expand_glob_patterns([\"*.py\", \"src/**/*.md\"])\nprint(f\"Found {len(files)} files\")\n\n# Concatenate files\nresult = concatenate_files(\n    files=files,\n    output_file=Path(\"output.txt\"),\n    separator=\"---\",\n    force=False,\n    dry_run=False,\n)\n\nprint(f\"Concatenated {result['files_count']} files\")\nprint(f\"Wrote {result['bytes_written']} bytes to {result['output_file']}\")\n```\n\n### Exception Handling\n\n```python\nfrom pathlib import Path\nfrom concat_glob_tool import (\n    concatenate_files,\n    expand_glob_patterns,\n    NoMatchesError,\n    OutputExistsError,\n    ConcatError,\n)\n\ntry:\n    # Expand patterns\n    files = expand_glob_patterns([\"*.py\"])\n\n    # Concatenate\n    result = concatenate_files(\n        files=files,\n        output_file=Path(\"output.txt\"),\n        force=False,\n        dry_run=False,\n    )\n\n    print(f\"Success: {result}\")\n\nexcept NoMatchesError as e:\n    print(f\"No files found: {e}\")\nexcept OutputExistsError as e:\n    print(f\"Output exists: {e}\")\nexcept ConcatError as e:\n    print(f\"Concatenation error: {e}\")\n```\n\n### Custom Separator Formatting\n\n```python\nfrom concat_glob_tool import format_separator\n\n# Format separator with filename\nsep = format_separator(\"myfile.py\", \"---\")\nprint(sep)\n# Output:\n# \\n---\\n# myfile.py\\n---\\n\n```\n\n### Reading from Stdin (Programmatic)\n\n```python\nimport sys\nfrom concat_glob_tool import read_paths_from_stdin\nfrom pathlib import Path\n\n# Simulate stdin with file paths\nsys.stdin = open(\"file_list.txt\", \"r\")\npaths = read_paths_from_stdin()\n\nfor path in paths:\n    print(f\"File: {path}\")\n```\n\n### Integration Example\n\n```python\n#!/usr/bin/env python3\n\"\"\"Example: Concatenate Python files with custom logic.\"\"\"\n\nfrom pathlib import Path\nfrom concat_glob_tool import expand_glob_patterns, concatenate_files\n\ndef main():\n    # Find all Python files\n    files = expand_glob_patterns([\"src/**/*.py\", \"tests/**/*.py\"])\n\n    # Filter files (e.g., exclude __init__.py)\n    filtered_files = [f for f in files if f.name != \"__init__.py\"]\n\n    # Concatenate\n    result = concatenate_files(\n        files=filtered_files,\n        output_file=Path(\"codebase.txt\"),\n        separator=\"===\",\n        force=True,\n        dry_run=False,\n    )\n\n    print(f\"‚úÖ Concatenated {result['files_count']} files\")\n    print(f\"üìù Output: {result['output_file']}\")\n    print(f\"üíæ Size: {result['bytes_written']} bytes\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### API Reference\n\n#### `expand_glob_patterns(patterns: list[str]) -> list[Path]`\n\nExpand glob patterns to list of file paths.\n\n**Parameters:**\n- `patterns`: List of glob patterns (e.g., `[\"*.py\", \"**/*.md\"]`)\n\n**Returns:**\n- Sorted list of unique file paths\n\n**Raises:**\n- `NoMatchesError`: If no files match any patterns\n\n#### `concatenate_files(files, output_file, separator=\"---\", force=False, dry_run=True) -> dict`\n\nConcatenate files to output file with separator.\n\n**Parameters:**\n- `files`: List of `Path` objects to concatenate\n- `output_file`: Output file path (`Path` object)\n- `separator`: Separator text (default: `\"---\"`)\n- `force`: Overwrite existing output file (default: `False`)\n- `dry_run`: Preview without writing (default: `True`)\n\n**Returns:**\n- Dictionary with keys:\n  - `files_count`: Number of files processed\n  - `output_file`: Output file path as string\n  - `bytes_written`: Total bytes written (0 in dry-run mode)\n\n**Raises:**\n- `OutputExistsError`: If output exists and `force=False`\n\n#### `format_separator(filename: str, separator_text: str) -> str`\n\nFormat the separator with filename.\n\n**Parameters:**\n- `filename`: Name of the file\n- `separator_text`: Base separator text\n\n**Returns:**\n- Formatted separator string: `\\n---\\n# FILENAME\\n---\\n`\n\n#### `read_paths_from_stdin() -> list[Path]`\n\nRead file paths from stdin (one per line).\n\n**Returns:**\n- List of file paths\n\n**Raises:**\n- `NoMatchesError`: If no valid paths provided\n- `ConcatError`: If a path doesn't exist or isn't a file\n\n## Multi-Level Verbosity Logging\n\nThe CLI supports progressive verbosity levels for debugging and troubleshooting. All logs output to stderr, keeping stdout clean for data piping.\n\n### Logging Levels\n\n| Flag | Level | Output | Use Case |\n|------|-------|--------|----------|\n| (none) | WARNING | Errors and warnings only | Production, quiet mode |\n| `-v` | INFO | + High-level operations | Normal debugging |\n| `-vv` | DEBUG | + Detailed info, full tracebacks | Development, troubleshooting |\n| `-vvv` | TRACE | + Library internals | Deep debugging |\n\n### Examples\n\n```bash\n# Quiet mode - only errors and warnings\nconcat-glob-tool\n\n# INFO - see operations and progress\nconcat-glob-tool -v\n# Output:\n# [INFO] concat-glob-tool started\n# [INFO] concat-glob-tool completed\n\n# DEBUG - see detailed information\nconcat-glob-tool -vv\n# Output:\n# [INFO] concat-glob-tool started\n# [DEBUG] Running with verbose level: 2\n# [INFO] concat-glob-tool completed\n\n# TRACE - see library internals (configure in logging_config.py)\nconcat-glob-tool -vvv\n```\n\n### Customizing Library Logging\n\nTo enable DEBUG logging for third-party libraries at TRACE level (-vvv), edit `concat_glob_tool/logging_config.py`:\n\n```python\n# Configure dependent library loggers at TRACE level (-vvv)\nif verbose_count >= 3:\n    logging.getLogger(\"requests\").setLevel(logging.DEBUG)\n    logging.getLogger(\"urllib3\").setLevel(logging.DEBUG)\n    # Add your project-specific library loggers here\n```\n\n## Shell Completion\n\nThe CLI provides native shell completion for bash, zsh, and fish shells.\n\n### Supported Shells\n\n| Shell | Version Requirement | Status |\n|-------|-------------------|--------|\n| **Bash** | ‚â• 4.4 | ‚úÖ Supported |\n| **Zsh** | Any recent version | ‚úÖ Supported |\n| **Fish** | ‚â• 3.0 | ‚úÖ Supported |\n| **PowerShell** | Any version | ‚ùå Not Supported |\n\n### Installation\n\n#### Quick Setup (Temporary)\n\n```bash\n# Bash - active for current session only\neval \"$(concat-glob-tool completion bash)\"\n\n# Zsh - active for current session only\neval \"$(concat-glob-tool completion zsh)\"\n\n# Fish - active for current session only\nconcat-glob-tool completion fish | source\n```\n\n#### Permanent Setup (Recommended)\n\n```bash\n# Bash - add to ~/.bashrc\necho 'eval \"$(concat-glob-tool completion bash)\"' >> ~/.bashrc\nsource ~/.bashrc\n\n# Zsh - add to ~/.zshrc\necho 'eval \"$(concat-glob-tool completion zsh)\"' >> ~/.zshrc\nsource ~/.zshrc\n\n# Fish - save to completions directory\nmkdir -p ~/.config/fish/completions\nconcat-glob-tool completion fish > ~/.config/fish/completions/concat-glob-tool.fish\n```\n\n#### File-based Installation (Better Performance)\n\nFor better shell startup performance, generate completion scripts to files:\n\n```bash\n# Bash\nconcat-glob-tool completion bash > ~/.concat-glob-tool-complete.bash\necho 'source ~/.concat-glob-tool-complete.bash' >> ~/.bashrc\n\n# Zsh\nconcat-glob-tool completion zsh > ~/.concat-glob-tool-complete.zsh\necho 'source ~/.concat-glob-tool-complete.zsh' >> ~/.zshrc\n\n# Fish (automatic loading from completions directory)\nmkdir -p ~/.config/fish/completions\nconcat-glob-tool completion fish > ~/.config/fish/completions/concat-glob-tool.fish\n```\n\n### Usage\n\nOnce installed, completion works automatically:\n\n```bash\n# Tab completion for commands\nconcat-glob-tool <TAB>\n# Shows: completion\n\n# Tab completion for options\nconcat-glob-tool --<TAB>\n# Shows: --verbose --version --help\n\n# Tab completion for shell types\nconcat-glob-tool completion <TAB>\n# Shows: bash zsh fish\n```\n\n### Getting Help\n\n```bash\n# View completion installation instructions\nconcat-glob-tool completion --help\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/concat-glob-tool.git\ncd concat-glob-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install                 # Install dependencies\nmake format                  # Format code with ruff\nmake lint                    # Run linting with ruff\nmake typecheck               # Run type checking with mypy\nmake test                    # Run tests with pytest\nmake security-bandit         # Python security linter\nmake security-pip-audit      # Dependency vulnerability scanner\nmake security-gitleaks       # Secret/API key detection\nmake security                # Run all security checks\nmake check                   # Run all checks (lint, typecheck, test, security)\nmake pipeline                # Run full pipeline (format, lint, typecheck, test, security, build, install-global)\nmake build                   # Build package\nmake run ARGS=\"...\"          # Run concat-glob-tool locally\nmake clean                   # Remove build artifacts\n```\n\n### Project Structure\n\n```\nconcat-glob-tool/\n‚îú‚îÄ‚îÄ concat_glob_tool/    # Main package\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py          # CLI entry point\n‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Utility functions\n‚îú‚îÄ‚îÄ tests/              # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py\n‚îú‚îÄ‚îÄ pyproject.toml      # Project configuration\n‚îú‚îÄ‚îÄ Makefile            # Development commands\n‚îú‚îÄ‚îÄ README.md           # This file\n‚îú‚îÄ‚îÄ LICENSE             # MIT License\n‚îî‚îÄ‚îÄ CLAUDE.md           # Development documentation\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\n# Run all tests\nmake test\n\n# Run tests with verbose output\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_utils.py\n\n# Run with coverage\nuv run pytest tests/ --cov=concat_glob_tool\n```\n\n## Security\n\nThe project includes lightweight security tools providing 80%+ coverage with fast scan times:\n\n### Security Tools\n\n| Tool | Purpose | Speed | Coverage |\n|------|---------|-------|----------|\n| **bandit** | Python code security linting | ‚ö°‚ö° Fast | SQL injection, hardcoded secrets, unsafe functions |\n| **pip-audit** | Dependency vulnerability scanning | ‚ö°‚ö° Fast | Known CVEs in dependencies |\n| **gitleaks** | Secret and API key detection | ‚ö°‚ö°‚ö° Very Fast | Secrets in code and git history |\n\n### Running Security Scans\n\n```bash\n# Run all security checks (~5-8 seconds)\nmake security\n\n# Or run individually\nmake security-bandit       # Python security linting\nmake security-pip-audit    # Dependency CVE scanning\nmake security-gitleaks     # Secret detection\n```\n\n### Prerequisites\n\ngitleaks must be installed separately:\n\n```bash\n# macOS\nbrew install gitleaks\n\n# Linux\n# See: https://github.com/gitleaks/gitleaks#installation\n```\n\nSecurity checks run automatically in `make check` and `make pipeline`.\n\n### What's Protected\n\n- ‚úÖ AWS credentials (AKIA*, ASIA*, etc.)\n- ‚úÖ GitHub tokens (ghp_*, gho_*, etc.)\n- ‚úÖ API keys and secrets\n- ‚úÖ Private keys\n- ‚úÖ Slack tokens\n- ‚úÖ 100+ other secret types\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run the full pipeline (`make pipeline`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to the branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints for all functions\n- Write docstrings for public functions\n- Format code with `ruff`\n- Pass all linting and type checks\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.14\n"
      },
      "plugins": [
        {
          "name": "concat-glob-tool",
          "source": "./plugins/concat-glob-tool",
          "description": "Concatenate files with glob patterns and separators",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/concat-glob-tool",
            "/plugin install concat-glob-tool@concat-glob-tool"
          ]
        }
      ]
    },
    {
      "name": "elevenlabs-tts-tool",
      "version": null,
      "description": "Text-to-speech synthesis with ElevenLabs API",
      "repo_full_name": "dnvriend/elevenlabs-tts-tool",
      "repo_url": "https://github.com/dnvriend/elevenlabs-tts-tool",
      "repo_description": "Professional command-line tool for ElevenLabs text-to-speech synthesis with human-friendly voice selection",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-07T07:32:59Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"elevenlabs-tts-tool\",\n    \"owner\": {\n        \"name\": \"Dennis Vriend\",\n        \"email\": \"dnvriend@gmail.com\",\n        \"url\": \"https://github.com/dnvriend/elevenlabs-tts-tool\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"elevenlabs-tts-tool\",\n            \"source\": \"./plugins/elevenlabs-tts-tool\",\n            \"description\": \"Text-to-speech synthesis with ElevenLabs API\"\n        }\n    ]\n}\n",
        "README.md": "# elevenlabs-tts-tool\n\n[![Python Version](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)\n[![Type checked: mypy](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](https://github.com/python/mypy)\n[![AI Generated](https://img.shields.io/badge/AI-Generated-blueviolet.svg)](https://www.anthropic.com/claude)\n[![Built with Claude Code](https://img.shields.io/badge/Built_with-Claude_Code-5A67D8.svg)](https://www.anthropic.com/claude/code)\n\nA command-line tool for ElevenLabs text-to-speech synthesis with human-friendly voice selection.\n\n## Table of Contents\n\n- [About](#about)\n- [Why CLI-First?](#why-cli-first)\n- [Use Cases](#use-cases)\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n  - [Shell Completion](#shell-completion)\n  - [Verbosity Levels](#verbosity-levels)\n- [Usage](#usage)\n  - [Synthesize Command](#synthesize-command)\n  - [List Voices](#list-voices)\n  - [Update Voices](#update-voices)\n  - [Model Selection](#model-selection)\n  - [Subscription Info](#subscription-info)\n- [Advanced Features](#advanced-features)\n  - [Emotion Control](#emotion-control)\n  - [Pause Control (SSML)](#pause-control-ssml)\n- [Free Tier Limitations](#free-tier-limitations)\n- [Claude Code Integration](#claude-code-integration)\n- [Library Usage](#library-usage)\n- [Development](#development)\n- [Resources](#resources)\n- [License](#license)\n\n## About\n\n### What is ElevenLabs?\n\n[ElevenLabs](https://elevenlabs.io) provides cutting-edge AI voice synthesis technology that generates natural-sounding speech from text. Their Turbo v2.5 model offers fast, high-quality text-to-speech with a wide variety of realistic voices.\n\n### What is elevenlabs-tts-tool?\n\n`elevenlabs-tts-tool` transforms the ElevenLabs API into a professional, composable CLI tool designed for:\n\n- **Agent-Friendly Design**: Structured commands and error messages enable AI agents (like Claude Code) to reason and act effectively in ReAct loops\n- **Composable Architecture**: JSON output to stdout, logs to stderr - perfect for piping and automation\n- **Reusable Building Blocks**: Commands serve as foundations for Claude Code skills, MCP servers, shell scripts, or custom workflows\n- **Dual-Mode Operation**: Use as both CLI tool and Python library\n- **Production Quality**: Type-safe with strict mypy checks, comprehensive tests, and clear error handling with suggested fixes\n\n## Why CLI-First?\n\nTraditional API wrappers force you to write code for every interaction. CLI-first design provides:\n\n1. **Immediate Productivity**: Run commands without writing wrapper code\n2. **Automation Ready**: Pipe commands together in shell scripts\n3. **Agent Integration**: AI agents can invoke commands directly\n4. **Human & Machine Friendly**: Works equally well for developers and automation\n\n## Use Cases\n\n- üéôÔ∏è **Voice Notifications**: Add TTS to CI/CD pipelines and monitoring systems\n- üìö **Content Creation**: Generate audiobooks, podcasts, and video narration\n- ü§ñ **AI Agent Integration**: Build voice-enabled Claude Code skills and MCP servers\n- üõ†Ô∏è **Development Workflows**: Create audio alerts for long-running processes\n- üéØ **Accessibility**: Convert text content to audio for accessibility features\n- üîä **Testing**: Test voice UIs and audio systems\n- üîî **Claude Code Hooks**: Use as notification system for Claude Code events (see [Claude Code Integration](#claude-code-integration))\n\n## Features\n\n- ‚úÖ **Two Synthesis Modes**: Play through speakers or save to audio file\n- ‚úÖ **8 TTS Models**: Choose from quality, speed, or emotional expression models\n- ‚úÖ **42 Premium Voices**: Curated selection with human-friendly names (rachel, adam, charlotte, etc.)\n- ‚úÖ **Voice & Model Discovery**: List voices and models with characteristics\n- ‚úÖ **Emotional Expression**: Use `[happy]`, `[sad]`, etc. tags with v3 model\n- ‚úÖ **Flexible Input**: Accept text from arguments or stdin (pipe support)\n- ‚úÖ **CLI & Library**: Use as command-line tool or import as Python library\n- ‚úÖ **Type Safety**: Strict mypy checks throughout\n- ‚úÖ **Comprehensive Tests**: Full test coverage with pytest\n- ‚úÖ **Agent-Friendly Errors**: Clear error messages with suggested fixes\n- ‚úÖ **Modern Tooling**: Built with uv, mise, click, and Python 3.13+\n\n## Installation\n\n### Prerequisites\n\n- Python 3.13 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- ElevenLabs API key ([get yours here](https://elevenlabs.io/app/settings/api-keys))\n- **macOS users**: [FFmpeg](https://ffmpeg.org/) for audio playback\n\n```bash\n# macOS: Install FFmpeg via Homebrew\nbrew install ffmpeg\n\n# Linux: Install via package manager\nsudo apt-get install ffmpeg  # Debian/Ubuntu\nsudo yum install ffmpeg      # RedHat/CentOS\n```\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/dnvriend/elevenlabs-tts-tool.git\ncd elevenlabs-tts-tool\n\n# Install globally with uv\nuv tool install .\n```\n\n### Verify installation\n\n```bash\nelevenlabs-tts-tool --version\n```\n\n## Configuration\n\n### Set API Key\n\n```bash\n# Export API key (required for all commands)\nexport ELEVENLABS_API_KEY='your-api-key-here'\n\n# Or add to your shell profile (~/.zshrc, ~/.bashrc)\necho 'export ELEVENLABS_API_KEY=\"your-api-key\"' >> ~/.zshrc\n```\n\nGet your API key from: https://elevenlabs.io/app/settings/api-keys\n\n### Shell Completion\n\nEnable tab completion for bash, zsh, or fish shells:\n\n**Bash** (add to `~/.bashrc`):\n```bash\neval \"$(elevenlabs-tts-tool completion bash)\"\n```\n\n**Zsh** (add to `~/.zshrc`):\n```bash\neval \"$(elevenlabs-tts-tool completion zsh)\"\n```\n\n**Fish** (save to completion file):\n```bash\nmkdir -p ~/.config/fish/completions\nelevenlabs-tts-tool completion fish > ~/.config/fish/completions/elevenlabs-tts-tool.fish\n```\n\n**For better performance**, save completion to a file:\n```bash\n# Bash\nelevenlabs-tts-tool completion bash > ~/.elevenlabs-tts-tool-complete.bash\necho 'source ~/.elevenlabs-tts-tool-complete.bash' >> ~/.bashrc\n\n# Zsh\nelevenlabs-tts-tool completion zsh > ~/.elevenlabs-tts-tool-complete.zsh\necho 'source ~/.elevenlabs-tts-tool-complete.zsh' >> ~/.zshrc\n```\n\nOnce installed, you can tab-complete commands, options, and even voice names!\n\n### Verbosity Levels\n\nControl logging output with progressive verbosity levels:\n\n```bash\n# Default (WARNING only) - quiet mode\nelevenlabs-tts-tool synthesize \"Hello world\"\n\n# -v (INFO) - show high-level operations\nelevenlabs-tts-tool -v synthesize \"Hello world\"\n\n# -vv (DEBUG) - show detailed steps, API calls, validation\nelevenlabs-tts-tool -vv synthesize \"Hello world\"\n\n# -vvv (TRACE) - show full API requests/responses, library internals\nelevenlabs-tts-tool -vvv synthesize \"Hello world\"\n```\n\n**Verbosity Breakdown:**\n- **No flag** (default): Only warnings and errors\n- **`-v`**: INFO level - operation status, file names, progress\n- **`-vv`**: DEBUG level - validation steps, API call details, timing\n- **`-vvv`**: TRACE level - full HTTP requests/responses, ElevenLabs SDK internals\n\n**Note:** Verbosity applies to all commands:\n```bash\nelevenlabs-tts-tool -v list-voices      # INFO level\nelevenlabs-tts-tool -vv list-models     # DEBUG level\nelevenlabs-tts-tool -vvv info           # TRACE level with API details\n```\n\n## Usage\n\n### Synthesize Command\n\nConvert text to speech with various options:\n\n```bash\n# Basic usage - play through speakers\nelevenlabs-tts-tool synthesize \"Hello world\"\n\n# Use a different voice\nelevenlabs-tts-tool synthesize \"Hello world\" --voice adam\nelevenlabs-tts-tool synthesize \"Cheerio mate\" --voice charlotte\n\n# Read from stdin\necho \"Hello from stdin\" | elevenlabs-tts-tool synthesize --stdin\ncat article.txt | elevenlabs-tts-tool synthesize --stdin\n\n# Save to MP3 file (default format)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.mp3\n\n# Save to WAV file (PCM format)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.wav --format pcm_24000\n\n# Lower quality MP3 (smaller file size)\nelevenlabs-tts-tool synthesize \"Save this\" --output speech.mp3 --format mp3_22050_32\n\n# Combine options\ncat blog-post.txt | elevenlabs-tts-tool synthesize --stdin \\\n    --voice rachel --output narration.mp3 --format mp3_44100_128\n```\n\n#### Output Formats\n\nThe `--format` option controls audio quality and file size. Different formats require different ElevenLabs subscription tiers:\n\n**Available on all tiers:**\n- `mp3_44100_128` - MP3 at 44.1kHz, 128kbps (default, ~17KB for short text)\n- `mp3_22050_32` - MP3 at 22.05kHz, 32kbps (lower quality, ~6KB for short text)\n- `pcm_16000` - PCM/WAV at 16kHz\n- `pcm_22050` - PCM/WAV at 22.05kHz\n- `pcm_24000` - PCM/WAV at 24kHz (~67KB for short text)\n- `ulaw_8000` - Œº-law at 8kHz (for Twilio)\n\n**Creator tier and above:**\n- `mp3_44100_192` - MP3 at 44.1kHz, 192kbps (higher quality)\n\n**Pro tier and above:**\n- `pcm_44100` - PCM/WAV at 44.1kHz (highest quality, largest file size)\n\n**Examples:**\n```bash\n# Default MP3 (works on all tiers)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.mp3\n\n# High-quality WAV (Pro tier required)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.wav --format pcm_44100\n\n# Lower bandwidth (works on all tiers)\nelevenlabs-tts-tool synthesize \"Text\" --output audio.mp3 --format mp3_22050_32\n```\n\n### List Voices\n\nDiscover available voices with characteristics:\n\n```bash\n# List all 42 available voices\nelevenlabs-tts-tool list-voices\n\n# Find specific voices with grep\nelevenlabs-tts-tool list-voices | grep British\nelevenlabs-tts-tool list-voices | grep \"female.*young\"\nelevenlabs-tts-tool list-voices | grep male\n```\n\n**Popular Voices:**\n- `rachel` - Calm and friendly American female (default)\n- `adam` - Deep, authoritative American male\n- `charlotte` - Seductive and calm British female\n- `antoni` - Well-rounded American male\n- `bella` - Soft and pleasant American female\n- `daniel` - Deep and authoritative British male\n\n### Update Voices\n\nUpdate the voice lookup table from ElevenLabs API:\n\n```bash\n# Update default voice lookup (saves to ~/.config/elevenlabs-tts-tool/)\nelevenlabs-tts-tool update-voices\n\n# Save to custom location\nelevenlabs-tts-tool update-voices --output custom_voices.json\n```\n\nThe voice lookup is stored in `~/.config/elevenlabs-tts-tool/voices_lookup.json` and takes precedence over the package default.\n\n### Model Selection\n\nElevenLabs offers multiple TTS models optimized for different use cases. Use the `--model` option with the `synthesize` command to select a model.\n\n#### List Available Models\n\n```bash\n# Show all available models with characteristics\nelevenlabs-tts-tool list-models\n```\n\n#### Current Generation Models\n\n**Eleven Turbo v2.5** (Default) - `eleven_turbo_v2_5`\n- Balanced quality and speed (~250ms latency)\n- 32 languages, 40,000 char limit\n- 50% cheaper per character\n- **Best for:** General-purpose TTS\n\n```bash\nelevenlabs-tts-tool synthesize \"Hello world\" --model eleven_turbo_v2_5\n```\n\n**Eleven Multilingual v2** - `eleven_multilingual_v2`\n- Highest production quality\n- 29 languages, 10,000 char limit\n- Medium latency\n- **Best for:** Professional content, e-learning\n\n```bash\nelevenlabs-tts-tool synthesize \"Professional narration\" --model eleven_multilingual_v2\n```\n\n**Eleven Flash v2.5** - `eleven_flash_v2_5`\n- Ultra-low latency (~75ms)\n- 32 languages, 40,000 char limit\n- 50% cheaper per character\n- **Best for:** Real-time agents, bulk processing\n\n```bash\nelevenlabs-tts-tool synthesize \"Quick response\" --model eleven_flash_v2_5\n```\n\n**Eleven v3 (Alpha)** - `eleven_v3`\n- Most emotionally expressive\n- 70+ languages, 5,000 char limit\n- Higher latency\n- **Best for:** Emotional dialogue, audiobooks\n- **Note:** Supports emotional tags (`[happy]`, `[sad]`, etc.)\n\n```bash\nelevenlabs-tts-tool synthesize \"[happy] Welcome!\" --model eleven_v3\n```\n\n#### Model Selection Examples\n\n```bash\n# Use highest quality model\nelevenlabs-tts-tool synthesize \"Professional presentation\" \\\n    --voice rachel --model eleven_multilingual_v2\n\n# Ultra-fast real-time generation\nelevenlabs-tts-tool synthesize \"Quick notification\" \\\n    --voice adam --model eleven_flash_v2_5\n\n# Emotional expression (requires v3)\nelevenlabs-tts-tool synthesize \"[excited] Congratulations!\" \\\n    --voice charlotte --model eleven_v3 --output celebration.mp3\n\n# Pipe with model selection\necho \"Article content\" | elevenlabs-tts-tool synthesize --stdin \\\n    --voice daniel --model eleven_multilingual_v2 --output article.mp3\n```\n\n#### Legacy Models\n\nThe following models are deprecated but still available:\n- `eleven_turbo_v2` - Superseded by Turbo v2.5 (50% cost savings)\n- `eleven_flash_v2` - Superseded by Flash v2.5\n- `eleven_monolingual_v1` - English-only (use `eleven_multilingual_v2` instead)\n- `eleven_multilingual_v1` - Use `eleven_multilingual_v2` instead\n\n**Warning:** Using deprecated models will show a deprecation notice. Migrate to current generation models for better performance and pricing.\n\nFor detailed model information, see: [references/models.md](references/models.md)\n\n### Subscription Info\n\nView your ElevenLabs subscription status and usage statistics:\n\n```bash\n# View subscription info with last 7 days of usage\nelevenlabs-tts-tool info\n\n# View last 30 days of usage\nelevenlabs-tts-tool info --days 30\n\n# Quick quota check\nelevenlabs-tts-tool info --days 1\n```\n\n**Information Displayed:**\n- **Subscription Details:** Tier, status, voice slots, currency\n- **Character Usage:** Used/limit/remaining with percentage and visual bar\n- **Quota Reset:** When your character quota resets\n- **Historical Usage:** Daily usage breakdown for specified period\n- **Usage Statistics:** Average daily usage and projected monthly consumption\n- **Warnings:** Alerts when approaching quota limits (>75% or >90%)\n\n**Example Output:**\n```\n================================================================================\nElevenLabs Subscription Information\n================================================================================\n\nTier:           Free\nStatus:         Active\n\nCharacter Usage:\n  Used:         8,543 characters\n  Limit:        10,000 characters\n  Remaining:    1,457 characters\n  Percentage:   85.4%\n  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë]\n\nQuota Resets:   2025-11-22 00:00:00\n                (Friday, November 22, 2025)\n\nVoice Slots:    3\nCurrency:       USD\n\n================================================================================\nHistorical Usage (Last 7 Days)\n================================================================================\n\nDate            Characters Used      Bar\n--------------------------------------------------------------------------------\n2025-11-15           1,234 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n2025-11-14             892 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n2025-11-13           1,567 chars    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n...\n--------------------------------------------------------------------------------\nTotal:               8,543 chars\n\nAverage daily usage: 1,220 characters\nProjected monthly:   36,600 characters\n\n================================================================================\n```\n\n**Use Cases:**\n- Monitor character quota consumption\n- Track usage patterns over time\n- Plan when to upgrade subscription tier\n- Avoid hitting quota limits unexpectedly\n- Understand daily/monthly usage trends\n\n## Advanced Features\n\n### Emotion Control\n\nElevenLabs v3 model (`eleven_v3`) supports emotional tags for expressive speech:\n\n```bash\n# Happy greeting (requires eleven_v3 model)\nelevenlabs-tts-tool synthesize \"[happy] Welcome! We're excited to have you here.\" --model eleven_v3\n\n# Sad message\nelevenlabs-tts-tool synthesize \"[sad] I'm sorry to hear that...\" --model eleven_v3\n\n# Excited announcement\nelevenlabs-tts-tool synthesize \"[excited] Amazing news! Your project is approved!\" --model eleven_v3\n```\n\n**Available Emotions:** `[happy]`, `[excited]`, `[sad]`, `[angry]`, `[nervous]`, `[curious]`, `[cheerfully]`, `[playfully]`, `[mischievously]`, `[resigned tone]`, `[flatly]`, `[deadpan]`\n\n**Speech Characteristics:** `[whispers]`, `[laughs]`, `[gasps]`, `[sighs]`, `[pauses]`, `[hesitates]`, `[stammers]`\n\n**Important:** Emotional tags only work with the `eleven_v3` model. They will be ignored on other models (v2.5, v2, etc.).\n\n### Pause Control (SSML)\n\nAdd natural pauses using SSML break tags:\n\n```bash\n# Add 1-second pause\nelevenlabs-tts-tool synthesize \"Welcome <break time=\\\"1.0s\\\" /> to our service.\"\n\n# Multiple pauses\nelevenlabs-tts-tool synthesize \"First point <break time=\\\"0.5s\\\" /> Second point <break time=\\\"0.5s\\\" /> Third point.\"\n```\n\n**Note:** Keep pauses under 3 seconds and limit to 2-4 breaks per generation for best results.\n\n### Combining Emotions and Pauses\n\n```bash\n# Emotional speech with pauses\nelevenlabs-tts-tool synthesize \"[happy] Good morning! <break time=\\\"0.5s\\\" /> [cheerfully] I hope you're having a great day.\"\n```\n\nFor comprehensive documentation on emotions, pauses, SSML, and voice settings, see:\n- [Emotions and Pauses Guide](references/emotions-and-pauses.md)\n\n## Free Tier Limitations\n\n**ElevenLabs Free Tier:**\n- ‚úÖ 10,000-20,000 characters per month (as of 2024-2025)\n- ‚úÖ Access to all 42 premade voices\n- ‚úÖ Create up to 3 custom voices\n- ‚úÖ MP3 formats (all bitrates)\n- ‚úÖ Basic SSML support\n- ‚úÖ Emotional tags (v3 models)\n- ‚ùå No commercial license\n- ‚ùå PCM 44.1kHz format requires Pro tier\n- ‚ö†Ô∏è Max 2,500 characters per single generation\n\n**Recommended for:**\n- Personal projects\n- Experimentation\n- Development and testing\n- Non-commercial use\n\nFor detailed free tier information and upgrade options, see:\n- [Free Tier Research](references/free-tier.md)\n- [ElevenLabs Pricing](https://elevenlabs.io/pricing)\n\n## Claude Code Integration\n\nUse `elevenlabs-tts-tool` as a notification system for Claude Code hooks to get audio alerts when tasks complete.\n\n### Setup Hook\n\nCreate a notification hook in `~/.config/claude-code/hooks.json`:\n\n```json\n{\n  \"hooks\": {\n    \"after_command\": {\n      \"type\": \"bash\",\n      \"command\": \"elevenlabs-tts-tool synthesize \\\"[happy] Task completed successfully!\\\" --voice rachel\"\n    },\n    \"on_error\": {\n      \"type\": \"bash\",\n      \"command\": \"elevenlabs-tts-tool synthesize \\\"[nervous] Error detected. Please check the output.\\\" --voice adam\"\n    }\n  }\n}\n```\n\n### Use Cases\n\n**Task Completion Alerts:**\n```bash\n# After long-running build\nelevenlabs-tts-tool synthesize \"[excited] Build completed!\" --voice rachel\n```\n\n**Error Notifications:**\n```bash\n# On test failure\nelevenlabs-tts-tool synthesize \"[sad] Tests failed. Please review.\" --voice adam\n```\n\n**Custom Workflows:**\n```bash\n# In your shell scripts\nmake build && elevenlabs-tts-tool synthesize \"[cheerfully] Build successful!\" || \\\n    elevenlabs-tts-tool synthesize \"[nervous] Build failed!\"\n```\n\n**Integration with Other Tools:**\n```bash\n# Combine with gemini-google-search-tool\ngemini-google-search-tool query \"Latest AI news\" | \\\n    elevenlabs-tts-tool synthesize --stdin --voice charlotte --output news-summary.mp3\n```\n\nThis allows you to:\n- Get audio alerts for completed tasks without monitoring the terminal\n- Hear error notifications while away from the screen\n- Create multi-step automation workflows with voice feedback\n- Build voice-enabled AI agent pipelines\n\n### Output Styles\n\nClaude Code supports custom output styles via `.claude/output-styles/` directory. Output styles allow you to customize how Claude Code responds to your requests. For comprehensive examples, see the [Claude Code Hooks Mastery repository](https://github.com/disler/claude-code-hooks-mastery/tree/main/.claude/output-styles).\n\n#### TTS Summary Output Style\n\nThe **TTS Summary** output style provides audio task completion announcements using `elevenlabs-tts-tool`. This creates a voice-enabled assistant experience where Claude Code speaks to you about what it accomplished.\n\n**How it works:**\n1. Claude Code responds normally to all requests\n2. At the end of every response, it adds an audio summary\n3. The summary is synthesized using `elevenlabs-tts-tool synthesize`\n4. You hear what was accomplished without monitoring the terminal\n\n**Example Output Style Configuration:**\n\nCreate `.claude/output-styles/tts-summary.md`:\n\n```markdown\n---\nname: TTS Summary\ndescription: Audio task completion announcements with TTS\n---\n\n# TTS Summary Output Style\n\nYou are Claude Code with an experimental TTS announcement feature designed to communicate directly with the user about what you've accomplished.\n\n## Standard Behavior\nRespond normally to all user requests, using your full capabilities for:\n- Code generation and editing\n- File operations\n- Running commands\n- Analysis and explanations\n- All standard Claude Code features\n\n## Critical Addition: Audio Task Summary\n\n**At the very END of EVERY response**, you MUST provide an audio summary for the user and run a Bash tool:\n\n```bash\nelevenlabs-tts-tool synthesize \"SUMMARY_TO_THE_USER\"\n```\n\n## Important Rules\n\n- ALWAYS include the audio summary, even for simple queries\n- ALWAYS suggest 2-3 relevant next steps after task completion\n- Report task completion status with technical precision\n- Use efficient, direct language - no conversational elaboration\n- Focus on specifications achieved and functionality delivered\n- Report as status update, not personal communication\n- Execute the command using the Bash tool, DO NOT show it on the CLI\n```\n\n**Activate the output style:**\n```bash\n# In Claude Code CLI\n/output-style\n# Select \"TTS Summary\" from the list\n```\n\n**Benefits:**\n- ‚úÖ Audio notifications for completed tasks\n- ‚úÖ Stay informed without watching the terminal\n- ‚úÖ Natural, conversational feedback\n- ‚úÖ Perfect for long-running tasks or multi-step workflows\n- ‚úÖ Voice-enabled AI assistant experience\n\n**Note:** This feature requires `elevenlabs-tts-tool` to be installed and configured with your API key.\n\n### Voice-Enabled Workflow with SuperWhisper\n\nCombine `elevenlabs-tts-tool` with [Claude Code](https://www.anthropic.com/claude/code) and [SuperWhisper](https://superwhisper.com/) for a complete voice-enabled development workflow.\n\n**The Power Trio:**\n1. **SuperWhisper** - Voice input: Speak commands to Claude Code\n2. **Claude Code** - AI assistance: Execute tasks and generate code\n3. **elevenlabs-tts-tool** - Voice output: Get audio notifications when tasks complete\n\n**Why This Works:**\n\nSpeaking is **faster than typing**. Instead of typing long commands or descriptions:\n```bash\n# Traditional typing (slow):\n\"Create a new Python function that parses JSON files and extracts all email addresses...\"\n\n# Voice with SuperWhisper (fast):\nüé§ Just speak naturally and SuperWhisper transcribes instantly\n```\n\n**Perfect For:**\n- üèÉ **Long-Running Tasks**: Start a build with voice, get audio notification when done\n- üîÑ **Multi-Step Workflows**: Chain tasks with voice commands, hear progress updates\n- üíª **Hands-Free Development**: Code while away from keyboard, get notified when ready\n- üéØ **Context Switching**: Start tasks via voice, move to other work, return on audio alert\n\n**Example Workflow:**\n```bash\n# 1. Speak to SuperWhisper: \"Run the test suite and let me know when it's done\"\n# 2. Claude Code executes: pytest tests/\n# 3. elevenlabs-tts-tool announces: \"[happy] All tests passed! 47 tests completed.\"\n\n# 4. Speak: \"Now build the Docker image and push to registry\"\n# 5. Claude Code executes: docker build && docker push\n# 6. elevenlabs-tts-tool announces: \"[excited] Docker image built and pushed successfully!\"\n```\n\n**Setup:**\n1. Install [SuperWhisper](https://superwhisper.com/) (macOS voice-to-text)\n2. Configure Claude Code with TTS Summary output style (see above)\n3. Use voice commands to control Claude Code\n4. Receive audio notifications on task completion\n\n**Benefits:**\n- ‚úÖ **10x faster input** - Speak naturally instead of typing\n- ‚úÖ **Hands-free operation** - No keyboard required for basic tasks\n- ‚úÖ **Multitasking enabled** - Start tasks, switch context, return on notification\n- ‚úÖ **Reduced cognitive load** - Voice is more natural than typing technical commands\n- ‚úÖ **Accessibility** - Works great for users with typing difficulties\n\n**Note:** SuperWhisper is currently macOS-only. For other platforms, consider [Whisper Desktop](https://github.com/Const-me/Whisper) or similar voice input tools.\n\n## Library Usage\n\nUse `elevenlabs-tts-tool` as a Python library in your projects:\n\n```python\nfrom elevenlabs_tts_tool import get_client, play_speech, save_speech\nfrom elevenlabs_tts_tool import VoiceManager\nfrom pathlib import Path\n\n# Initialize client\nclient = get_client()\n\n# Get voice ID\nvoice_manager = VoiceManager()\nvoice_id = voice_manager.get_voice_id(\"rachel\")\n\n# Play through speakers\nplay_speech(client, \"Hello from Python\", voice_id)\n\n# Save to file\nsave_speech(client, \"Save this\", voice_id, Path(\"output.wav\"))\n\n# List available voices\nfor name, profile in voice_manager.list_voices():\n    print(f\"{name}: {profile.description}\")\n```\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/dnvriend/elevenlabs-tts-tool.git\ncd elevenlabs-tts-tool\n\n# Install dependencies\nmake install\n\n# Show available commands\nmake help\n```\n\n### Available Make Commands\n\n```bash\nmake install          # Install dependencies\nmake format           # Format code with ruff\nmake lint             # Run linting with ruff\nmake typecheck        # Run type checking with mypy\nmake test             # Run tests with pytest\nmake check            # Run all checks (lint, typecheck, test)\nmake pipeline         # Run full pipeline (format, check, build, install-global)\nmake build            # Build package\nmake clean            # Remove build artifacts\n```\n\n### Project Structure\n\n```\nelevenlabs-tts-tool/\n‚îú‚îÄ‚îÄ elevenlabs_tts_tool/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Public API exports\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py                   # CLI entry point\n‚îÇ   ‚îú‚îÄ‚îÄ voices.py                # Voice management\n‚îÇ   ‚îú‚îÄ‚îÄ voices_lookup.json       # Voice lookup table (42 voices)\n‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Core library functions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py           # ElevenLabs client\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ synthesize.py       # TTS functions\n‚îÇ   ‚îî‚îÄ‚îÄ commands/                # CLI commands\n‚îÇ       ‚îú‚îÄ‚îÄ synthesize_commands.py\n‚îÇ       ‚îî‚îÄ‚îÄ voice_commands.py\n‚îú‚îÄ‚îÄ tests/                       # Test suite\n‚îú‚îÄ‚îÄ pyproject.toml               # Project configuration\n‚îú‚îÄ‚îÄ Makefile                     # Development commands\n‚îî‚îÄ‚îÄ CLAUDE.md                    # Developer guide\n```\n\n## Resources\n\n- **ElevenLabs Documentation**: https://elevenlabs.io/docs\n- **API Reference**: https://elevenlabs.io/docs/api-reference\n- **Python SDK**: https://github.com/elevenlabs/elevenlabs-python\n- **Voice Library**: https://elevenlabs.io/voice-library\n- **Get API Key**: https://elevenlabs.io/app/settings/api-keys\n- **Claude Code Hooks Mastery**: https://github.com/disler/claude-code-hooks-mastery - Comprehensive guide to Claude Code hooks and output styles\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\n**Dennis Vriend**\n\n- GitHub: [@dnvriend](https://github.com/dnvriend)\n\n## Acknowledgments\n\n- Built with [Click](https://click.palletsprojects.com/) for CLI framework\n- [ElevenLabs](https://elevenlabs.io) for world-class TTS technology\n- Developed with [uv](https://github.com/astral-sh/uv) for fast Python tooling\n\n---\n\n**Generated with AI**\n\nThis project was generated using [Claude Code](https://www.anthropic.com/claude/code), an AI-powered development tool by [Anthropic](https://www.anthropic.com/). Claude Code assisted in creating the project structure, implementation, tests, documentation, and development tooling.\n\nMade with ‚ù§Ô∏è using Python 3.13+\n"
      },
      "plugins": [
        {
          "name": "elevenlabs-tts-tool",
          "source": "./plugins/elevenlabs-tts-tool",
          "description": "Text-to-speech synthesis with ElevenLabs API",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dnvriend/elevenlabs-tts-tool",
            "/plugin install elevenlabs-tts-tool@elevenlabs-tts-tool"
          ]
        }
      ]
    }
  ]
}