{
  "author": {
    "id": "mkelk",
    "display_name": "mkelk",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/13288681?u=2850e2a43cb13dfc44bc2e3cc1135ed00227faae&v=4",
    "url": "https://github.com/mkelk",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 4,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "mkelk-marketplace",
      "version": null,
      "description": "Custom Claude Code plugins by mkelk",
      "owner_info": {
        "name": "mkelk",
        "email": "mkelk@users.noreply.github.com"
      },
      "keywords": [],
      "repo_full_name": "mkelk/claude-marketplace",
      "repo_url": "https://github.com/mkelk/claude-marketplace",
      "repo_description": "Claude Code plugin marketplace for skills, commands, hooks, and MCP servers",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-22T11:02:45Z",
        "created_at": "2026-01-21T14:48:39Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 662
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/sdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/sdd/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/sdd/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 474
        },
        {
          "path": "plugins/sdd/README.md",
          "type": "blob",
          "size": 2757
        },
        {
          "path": "plugins/sdd/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/sdd/commands/checkin-and-pr.md",
          "type": "blob",
          "size": 5252
        },
        {
          "path": "plugins/sdd/commands/checkspec.md",
          "type": "blob",
          "size": 5993
        },
        {
          "path": "plugins/sdd/commands/createplan.md",
          "type": "blob",
          "size": 14765
        },
        {
          "path": "plugins/sdd/commands/startspec.md",
          "type": "blob",
          "size": 3036
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"mkelk-marketplace\",\n  \"description\": \"Custom Claude Code plugins by mkelk\",\n  \"owner\": {\n    \"name\": \"mkelk\",\n    \"email\": \"mkelk@users.noreply.github.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sdd\",\n      \"description\": \"Spec-Driven Development workflow with ticks-based task tracking for AI agents\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"mkelk\",\n        \"email\": \"mkelk@users.noreply.github.com\"\n      },\n      \"source\": \"./plugins/sdd\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/mkelk/claude-marketplace\"\n    }\n  ]\n}\n",
        "plugins/sdd/.claude-plugin/plugin.json": "{\n  \"name\": \"sdd\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Spec-Driven Development workflow with ticks-based task tracking for AI agents\",\n  \"author\": {\n    \"name\": \"mkelk\",\n    \"url\": \"https://github.com/mkelk\"\n  },\n  \"homepage\": \"https://github.com/mkelk/claude-marketplace\",\n  \"repository\": \"https://github.com/mkelk/claude-marketplace\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"sdd\", \"spec-driven-development\", \"ticks\", \"workflow\", \"planning\"],\n  \"commands\": \"./commands/\"\n}\n",
        "plugins/sdd/README.md": "# SDD (Spec-Driven Development) Plugin\n\nA Claude Code plugin that provides a structured workflow for spec-driven development with ticks-based task tracking.\n\n## Overview\n\nThis plugin enables a systematic approach to software development:\n\n1. **Start with a specification** - Define what you're building before you build it\n2. **Create trackable tasks (ticks)** - Break down the spec into atomic, testable tasks\n3. **Commit with context** - Create well-documented PRs that reference specs and completed tasks\n\n## Commands\n\n### `/sdd:startspec [project-name]`\n\nStart a new specification document with interactive dialogue.\n\n- Creates a spec directory and file in `/docs/projects/<date>-<project-name>/`\n- Can infer project name from branch or worktree name\n- Guides you through defining requirements interactively\n\n### `/sdd:checkspec [spec-file-path]`\n\nValidate a specification document against the codebase and best practices.\n\n- Verifies referenced files and APIs exist\n- Checks technology alignment with existing stack\n- Validates testing strategy is defined\n- Produces a structured validation report with recommendations\n\n### `/sdd:createplan [spec-file-path]`\n\nCreate ticks from a specification for trackable, test-driven implementation.\n\n- Transforms specs into epics and tasks using the `tk` CLI\n- Ensures each tick is atomic, testable, and AI-agent friendly\n- Bundles tests with implementation tasks (test-first approach)\n- Creates environment validation as \"Phase 0\"\n\n### `/sdd:checkin-and-pr [spec-name or epic-id]`\n\nCommit completed work and create a pull request with ticks summary.\n\n- Verifies all ticks are complete\n- Creates conventional commit messages\n- Generates PR with ticks summary and spec references\n\n## Workflow\n\n### Starting a New Feature\n\n```bash\n# 1. Create the specification\n/sdd:startspec dark-mode\n\n# 2. Validate the spec\n/sdd:checkspec\n\n# 3. Create implementation tasks\n/sdd:createplan\n\n# 4. Work through tasks\ntk next  # or tk run <epic-id> for autonomous execution\n\n# 5. When done, create PR\n/sdd:checkin-and-pr\n```\n\n### Working with Existing Specs\n\n```bash\n# Validate an existing spec\n/sdd:checkspec docs/projects/2026-01-15-dark-mode/2026-01-15-dark-mode-spec.md\n\n# Create tasks from a validated spec\n/sdd:createplan docs/projects/2026-01-15-dark-mode/2026-01-15-dark-mode-spec.md\n```\n\n## Requirements\n\n- **`tk` CLI** - The ticks task management tool must be installed\n- **`gh` CLI** - GitHub CLI for creating pull requests\n- **Git** - For version control\n\n## File Structure\n\n```\ndocs/projects/\n  2026-01-15-dark-mode/\n    2026-01-15-dark-mode-spec.md    # Main specification\n    2026-01-15-dark-mode-notes.md   # Additional documents\n\n.tick/                               # Ticks data (managed by tk)\n```\n\n## License\n\nMIT\n",
        "plugins/sdd/commands/checkin-and-pr.md": "---\ndescription: Commit completed work and create a pull request with ticks summary\nargument-hint: [spec-name or epic-id]\n---\n\n## Context\n\n- Today's date: !`date +%Y-%m-%d`\n- Project reference: $ARGUMENTS\n- Completed ticks: !`tk list --status closed 2>/dev/null | head -10 || echo \"No ticks found\"`\n\n## Your Task\n\nYou are finalizing completed implementation work by creating a well-documented commit and pull request. Follow these steps:\n\n### Step 1: Identify the Completed Work\n\n**If `$ARGUMENTS` specifies an epic ID:**\n- Get the epic details: `tk show <epic-id>`\n- List completed ticks: `tk list --parent <epic-id> --status closed`\n\n**If `$ARGUMENTS` specifies a spec name:**\n- Look for the spec in `/docs/projects/<spec-name>/`\n- Find related epics by naming convention\n\n**If `$ARGUMENTS` is empty:**\n- List recent completed ticks: `tk list --status closed`\n- List open epics to identify which project: `tk list -t epic`\n- Ask which project to check in\n\n### Step 2: Verify Readiness\n\nBefore committing, verify:\n\n1. **Check git status** - Review all changed files\n   ```bash\n   git status\n   git diff --stat\n   ```\n\n2. **Verify ticks are complete:**\n   ```bash\n   # Check epic status\n   tk show <epic-id>\n\n   # List any remaining open ticks\n   tk list --parent <epic-id> --status open\n   ```\n\n3. **Run final tests:**\n   ```bash\n   npm run build && npm test\n   ```\n\nIf work is incomplete:\n> Implementation doesn't appear complete:\n> - Open ticks: [list]\n> - Failing tests: [list]\n>\n> Would you like to proceed anyway, or address these first?\n\n### Step 3: Gather Context for Commit Message\n\nCollect information from:\n\n1. **Spec file** (if exists): `/docs/projects/<project>/<project>-spec.md`\n2. **Completed ticks:** `tk list --parent <epic-id> --status closed`\n3. **Tick notes:** `tk notes <tick-id>` for key decisions\n4. **Git diff:** What files changed and why\n\n### Step 4: Create the Commit\n\nStage all relevant files and create a commit with this format:\n\n```\n<type>(<scope>): <summary>\n\n<body - what was done and why>\n\nTicks: <epic-id> (<count> tasks completed)\nSpec: docs/projects/<project-folder>/<project>-spec.md\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n```\n\n**Type** should be one of:\n- `feat` - New feature\n- `fix` - Bug fix\n- `refactor` - Code restructuring\n- `docs` - Documentation only\n- `style` - Formatting, styling\n- `test` - Adding tests\n- `chore` - Maintenance\n\n**Scope** is the area of the codebase affected (e.g., `ui`, `api`, `cli`, `auth`)\n\n### Step 5: Identify the Base Branch\n\nDetermine where the PR should target:\n\n1. Check current branch name for clues (e.g., `feature/dark-mode` -> base is likely `main` or `master`)\n2. Check git log to see where this branch diverged from\n3. If unclear, ask the user:\n   > Which branch should this PR target? (e.g., `main`, `master`, `develop`)\n\n### Step 6: Push and Create Pull Request\n\nPush the branch and create a PR with this format:\n\n```markdown\n## Summary\n\n[2-3 sentence overview of what this PR accomplishes]\n\n## Changes\n\n- [Bullet list of major changes, derived from completed ticks]\n\n## Ticks Completed\n\n| ID | Title |\n|----|-------|\n| <id> | <title> |\n| <id> | <title> |\n\nView full details: `tk list --parent <epic-id> --status closed`\n\n## Specification\n\n- **Spec:** `docs/projects/<project-folder>/<project>-spec.md`\n\n## Test Plan\n\n[How was this tested? Reference acceptance criteria from ticks]\n\n- [ ] All tick acceptance criteria verified\n- [ ] Build passes\n- [ ] Tests pass\n- [ ] Manual verification completed (if applicable)\n\n## Screenshots (if applicable)\n\n[For UI changes, include before/after or key states]\n\n---\n\nGenerated with [Claude Code](https://claude.ai/code)\n```\n\nUse `gh pr create` with the title and body.\n\n### Step 7: Report Completion\n\nAfter the PR is created, report:\n\n```markdown\n## Check-in Complete\n\n**Commit:** `<commit-hash>` - <commit-summary>\n**PR:** <pr-url>\n**Target:** <base-branch>\n\n### Ticks Summary\n\n- **Epic:** <epic-id> - <epic-title>\n- **Completed:** X ticks\n- **Status:** All closed\n\n### What's Next\n\n- [ ] Request code review\n- [ ] Address review feedback\n- [ ] Merge when approved\n\n### Project Documents\n\n- Spec: `<path>` (if exists)\n- Ticks: `tk list --parent <epic-id>`\n```\n\n---\n\n## Guidelines\n\n### Commit Message Quality\n\n**DO:**\n- Summarize the \"what\" in the first line (50 chars max)\n- Explain the \"why\" in the body\n- Reference the epic/ticks and spec\n- Use conventional commit format\n\n**DON'T:**\n- List every file changed\n- Include implementation details in the summary\n- Write vague messages like \"updates\" or \"fixes\"\n\n### PR Description Quality\n\n**DO:**\n- Lead with the user-facing impact\n- List completed ticks with their titles\n- Link to specification documents\n- Include test verification steps\n- Mention any known limitations or follow-up work\n\n**DON'T:**\n- Copy-paste entire tick descriptions\n- Include internal notes or TODOs\n- Skip the test plan section\n\n### Handling Incomplete Work\n\nIf some ticks remain open but you want to create a partial PR:\n\n1. List what's complete vs. remaining\n2. Create PR with `[WIP]` prefix if needed\n3. Note which ticks are deferred:\n   ```markdown\n   ## Deferred to Follow-up\n\n   | ID | Title | Reason |\n   |----|-------|--------|\n   | <id> | <title> | <why deferred> |\n   ```\n",
        "plugins/sdd/commands/checkspec.md": "---\ndescription: Validate a specification document against the codebase and best practices\nargument-hint: [spec-file-path]\n---\n\n## Context\n\n- Today's date: !`date +%Y-%m-%d`\n- Spec file: $ARGUMENTS\n\n## Your Task\n\nYou are validating a specification document to ensure it's well-defined and implementable. Follow these steps:\n\n### Step 1: Locate the Spec File\n\nSpecs live in subdirectories of `/docs/projects/` following the pattern:\n`/docs/projects/<date>-<project-name>/<date>-<project-name>-spec.md`\n\nIf no spec file path was provided (`$ARGUMENTS` is empty):\n\n1. List available spec directories in `/docs/projects/` (folders matching `YYYY-MM-DD-*/`)\n2. Look for `*-spec.md` files within those directories\n3. Ask the user which spec to validate:\n   > Which specification would you like me to validate? [list the available specs, or provide a path]\n\n### Step 2: Read and Parse the Spec\n\nRead the specification file thoroughly. Identify:\n- The stated goals and requirements\n- Any technical decisions or assumptions made\n- Referenced files, modules, or systems\n- Proposed changes or additions\n\n### Step 3: Codebase Analysis\n\nExplore the relevant parts of the codebase to check for:\n\n#### 3a. Technical Consistency\n- Do referenced files/modules actually exist?\n- Are the described APIs, functions, or interfaces accurate?\n- Does the spec use correct naming conventions matching the codebase?\n\n#### 3b. Technology Alignment\n- Does the spec propose technologies already in use, or new ones?\n- If new technologies, are there conflicts with existing choices?\n- Are there existing patterns in the codebase the spec should follow?\n\n#### 3c. Architecture Fit\n- Does the proposed design fit the existing architecture?\n- Are there existing utilities or components that should be reused?\n- Does it follow established patterns in the codebase?\n\n#### 3d. Testing Strategy\n\n**This is critical.** Before implementation begins, the spec must define how the changes will be verified. Review the project's existing test infrastructure by checking `/docs/current/test.md`, `package.json` scripts, and existing test files.\n\nEvaluate whether the spec adequately addresses:\n\n- **Testing approach per feature area:** How will each major aspect of the spec be tested? (unit tests, integration tests, manual verification, E2E tests)\n- **What needs automated tests:** Which parts require new automated tests vs. can rely on existing tests?\n- **What needs manual testing:** Which parts require manual verification and what should be checked?\n- **Edge cases and error scenarios:** How will failure modes and edge cases be verified?\n- **Regression prevention:** How will we ensure existing functionality isn't broken?\n\nThe spec does NOT need to list every individual test case. It DOES need to describe:\n- The overall testing approach for each major component/feature\n- Which testing tools/frameworks to use (based on what exists in the project)\n- Any test data or fixtures needed\n- How to verify the implementation is complete\n\n**If the testing strategy is weak or missing:**\n- Mark this as a **Critical** issue\n- Challenge the user directly:\n  > The spec lacks a clear testing strategy. Before implementation, we need to define:\n  > - How will [feature X] be tested?\n  > - What manual verification is needed for [feature Y]?\n  > - Are there edge cases that need specific test coverage?\n  >\n  > A spec without a testing strategy leads to untested code or ad-hoc testing that misses important scenarios.\n\n### Step 4: Environment Health Check\n\nBefore marking a spec as ready, verify the codebase is in a healthy state:\n\n1. Check `/docs/current/` for environment validation commands\n2. If validation docs exist, note them in the report\n3. If validation docs are missing, flag this as a gap\n\nThis ensures implementation won't be blocked by pre-existing issues.\n\n### Step 5: Gap Analysis\n\nIdentify any gaps that could cause implementation uncertainty:\n- Undefined edge cases or error handling\n- Missing details about data flow or state management\n- Unclear integration points with existing code\n- Ambiguous requirements that need clarification\n- Missing environment validation documentation in `/docs/current/`\n- **Inadequate or missing testing strategy** (see 3d above)\n\n### Step 6: Report Findings\n\nPresent a structured validation report:\n\n```markdown\n## Spec Validation Report: <spec-name>\n\n**Validated:** <today's date>\n**Status:** [READY | NEEDS REVISION | BLOCKED]\n\n### Summary\n[1-2 sentence overall assessment]\n\n### Consistency Check\n- [ ] Referenced files exist\n- [ ] APIs/interfaces are accurate\n- [ ] Naming conventions match codebase\n\n### Technology Alignment\n- [ ] Uses existing tech stack appropriately\n- [ ] No conflicts with current choices\n- [ ] Follows established patterns\n\n### Environment Validation\n- [ ] `/docs/current/` contains validation commands\n- [ ] Validation commands documented in this report (or flagged as missing)\n\n### Testing Strategy\n- [ ] Spec defines testing approach for each major feature area\n- [ ] Clear distinction between automated vs. manual testing needs\n- [ ] Edge cases and error scenarios addressed\n- [ ] Testing tools/frameworks identified (using project's existing infrastructure)\n\n**Testing Assessment:** [ADEQUATE | NEEDS WORK | MISSING]\n\n[If not adequate, list what's missing and challenge the user to define it]\n\n### Issues Found\n\n#### Critical (Must Fix)\n[List issues that would block implementation]\n\n#### Warnings (Should Address)\n[List issues that could cause problems]\n\n#### Suggestions (Nice to Have)\n[List improvements that would strengthen the spec]\n\n### Missing Information\n[List any gaps that need clarification before implementation]\n\n### Recommendations\n[Specific next steps to make the spec implementation-ready]\n```\n\n### Step 7: Offer Next Steps\n\nAfter presenting the report, ask:\n> Would you like me to:\n> 1. Update the spec with fixes for the issues found?\n> 2. Explore any specific concern in more detail?\n> 3. Create follow-up tasks for unresolved items?\n",
        "plugins/sdd/commands/createplan.md": "---\ndescription: Create ticks from a specification for trackable, test-driven implementation\nargument-hint: [spec-file-path]\n---\n\n## Context\n\n- Today's date: !`date +%Y-%m-%d`\n- Spec file: $ARGUMENTS\n- Ticks initialized: !`test -d .tick && echo \"yes\" || echo \"no\"`\n\n## Your Task\n\nYou are transforming a specification into ticks (tasks) using the `tk` CLI. Ticks are designed for AI agent execution - each tick should be atomic, testable, and independently completable.\n\n### Step 0: Verify Ticks is Initialized\n\nCheck if ticks is set up in this repository:\n\n```bash\ntk list 2>/dev/null || echo \"NOT_INITIALIZED\"\n```\n\nIf not initialized, run:\n```bash\ntk init\n```\n\n### Step 1: Locate the Spec File\n\nSpecs live in subdirectories of `/docs/projects/` following the pattern:\n`/docs/projects/<date>-<project-name>/<date>-<project-name>-spec.md`\n\nIf no spec file path was provided (`$ARGUMENTS` is empty):\n\n1. List available spec directories in `/docs/projects/` (folders matching `YYYY-MM-DD-*/`)\n2. Look for `*-spec.md` files within those directories\n3. Ask the user which spec to use:\n   > Which specification would you like me to create ticks for? [list the available specs]\n\n### Step 2: Validate Spec Readiness\n\nBefore creating ticks, verify the spec is ready:\n- Status should be \"Ready for Implementation\" (not \"Draft\" or \"Needs Revision\")\n- Testing strategy must be defined (see `/checkspec`)\n- No unresolved critical issues or blocking open questions\n\nIf the spec isn't ready:\n> This spec has status \"[status]\". Run `/checkspec` first to validate it before creating ticks.\n\n### Step 3: Analyze Implementation Scope\n\nRead the spec thoroughly and explore the codebase to understand:\n\n1. **Change Footprint**: Which files need modification? Which need creation?\n2. **Dependencies**: What order must changes happen in?\n3. **Risk Areas**: Which changes are most likely to cause issues?\n4. **Test Infrastructure**: How does this project run tests?\n   - What test command? (`go test`, `npm test`, `pytest`, etc.)\n   - What test file patterns? (`*_test.go`, `*.test.ts`, `test_*.py`)\n   - Any existing test helpers or fixtures to reuse?\n   - How to run specific tests? (`-run`, `--grep`, `-k`, etc.)\n5. **Test Points**: Where can we verify correctness automatically?\n6. **Human Tasks**: What requires human intervention (credentials, external setup, manual testing)?\n\n**Understanding test infrastructure is critical** - you'll need this to write good acceptance criteria.\n\n### Step 4: Design the Epic Structure\n\nGroup work into **epics** (parent containers). Each epic should:\n- Represent a coherent feature or phase\n- Contain 3-5 tasks (optimal for parallelization)\n- Be independently valuable when complete\n\n**Naming convention for epics:**\n```\n<spec-name>: <phase-description>\n```\n\nExample epics for a \"user-auth\" spec:\n- `user-auth: Database schema and models`\n- `user-auth: API endpoints`\n- `user-auth: Frontend components`\n- `user-auth: Manual setup tasks`\n\n### Step 5: Design Individual Ticks\n\nEach tick must be:\n\n1. **Atomic**: One deliverable, completable in a single focused session\n2. **Testable**: Clear acceptance criteria an agent can verify\n3. **Independent**: Minimize dependencies (use `--blocked-by` when necessary)\n4. **AI-friendly**: Sufficient context for autonomous completion\n\n**Good tick structure:**\n- **Title**: Action-oriented, specific (e.g., \"Add JWT validation middleware\")\n- **Description** (`-d`): What to implement, which files to modify, relevant context\n- **Acceptance** (`--acceptance`): How to verify completion - specific test commands or checks\n\n### Step 5a: Test-First Tick Design (CRITICAL)\n\n**Acceptance criteria are NOT automatically enforced.** They are presented to the agent as guidance, but nothing prevents the agent from closing a task without verification. Therefore:\n\n**Every implementation tick MUST include writing tests as part of the deliverable:**\n\n```\nBAD: Separate ticks for implementation and tests\n   - Tick 1: \"Add ParentBranch field\"\n   - Tick 2: \"Add tests for ParentBranch\"  <- Agent might skip this\n\nGOOD: Tests bundled with implementation\n   - Tick 1: \"Add ParentBranch field with tests\"\n     Description includes: \"Add tests in worktree_test.go for...\"\n     Acceptance: \"go test ./internal/worktree/... -run TestParentBranch passes\"\n```\n\n**Acceptance criteria must be:**\n1. **Executable commands** the agent can run (not prose descriptions)\n2. **Specific test patterns** that target the new code (`-run TestNewFeature`)\n3. **Verifiable by the agent** before closing the tick\n\n**Test-first tick pattern:**\n```bash\ntk create \"Add feature X with tests\" \\\n  --parent <epic-id> \\\n  -d \"Implement feature X.\n\nFiles to modify:\n- src/feature.go (implementation)\n- src/feature_test.go (tests)\n\nImplementation:\n1. [what to implement]\n\nTests to write:\n1. TestFeature_HappyPath - verify normal operation\n2. TestFeature_EdgeCase - verify edge case handling\n3. TestFeature_ErrorCase - verify error handling\n\nWrite the tests FIRST or alongside the implementation.\" \\\n  --acceptance \"go test ./src/... -run TestFeature -v passes with all 3 tests visible in output\"\n```\n\n**Why this matters:**\n- Agent sees \"tests to write\" in description -> writes them\n- Agent sees specific test command in acceptance -> runs it before closing\n- Test output shows specific test names -> agent verifies they exist and pass\n\n### Step 6: Identify Human Tasks\n\nSome tasks require human intervention. Mark these with `--awaiting work`:\n\n- Setting up credentials or API keys\n- Configuring external services\n- Manual testing on physical devices\n- Decisions requiring user input\n- App store submissions, deployments\n\nThese are skipped by `tk next` (agent queue) and must be completed by humans.\n\n### Step 7: Create the Epics and Ticks\n\nCreate epics first, then tasks under them.\n\n**Create an epic with context references:**\n\nEach epic MUST include references to the spec and relevant files so agents have full context:\n\n```bash\ntk create \"<spec-name>: <phase>\" -t epic -d \"Description of this phase\n\n## Context\n\n**Spec:** \\`<path-to-spec-file>\\`\n\n**Key files for this epic:**\n- \\`<path/to/relevant/file1>\\` - brief description\n- \\`<path/to/relevant/file2>\\` - brief description\n\n**Related docs:** (if any)\n- \\`<path/to/doc>\\` - what it covers\"\n```\n\n**Example epic with full context:**\n```bash\ntk create \"user-auth: API endpoints\" -t epic -d \"Implement authentication API endpoints\n\n## Context\n\n**Spec:** \\`docs/projects/2026-01-15-user-auth/2026-01-15-user-auth-spec.md\\`\n\n**Key files for this epic:**\n- \\`src/api/routes.ts\\` - existing route definitions to extend\n- \\`src/middleware/auth.ts\\` - authentication middleware to integrate\n- \\`src/services/userService.ts\\` - user service for data access\n\n**Related docs:**\n- \\`docs/current/api-patterns.md\\` - API conventions to follow\"\n```\n\nThis ensures any agent working on the epic can immediately access the full specification and understand which existing code is relevant.\n\n**Cross-epic dependencies:**\n\nEpics can run in parallel unless there are real dependencies between them. Only add blocking dependencies when one epic genuinely requires another to complete first.\n\n**When to add cross-epic dependencies:**\n- Epic B validates/reviews code written in Epic A -> B depends on A\n- Epic B deploys changes from Epic A -> B depends on A\n- Epic B tests integration with Epic A's changes -> B depends on A\n\n**When epics can run in parallel:**\n- Epic A works on backend, Epic B works on frontend (no shared code)\n- Epic A adds feature X, Epic B adds unrelated feature Y\n- Epic A writes docs, Epic B writes tests for different code\n\n**Adding cross-epic dependencies:**\n\nWhen a real dependency exists, block the first task of the dependent epic on the last task of the prerequisite epic:\n\n```\nEpic 1: Implementation (must complete first)\n  - task-a -> task-b -> task-c (last task)\n                              |\n                              v\nEpic 2: Validation (depends on Epic 1)\n  - task-d (blocked by task-c) -> task-e\n\nEpic 3: Documentation (independent - can run in parallel with Epic 2)\n  - task-f -> task-g\n```\n\n```bash\n# Only add if Epic 2 genuinely depends on Epic 1\ntk block <epic2-first-task> <epic1-last-task>\n```\n\n**Create tasks under the epic (with bundled tests):**\n```bash\ntk create \"Add user validation with tests\" \\\n  --parent <epic-id> \\\n  -d \"Implement user validation logic with comprehensive tests.\n\nFiles to modify:\n- src/auth/validate.ts (implementation)\n- src/auth/validate.test.ts (tests)\n\nImplementation:\n1. Add validateUser() function that checks email format and password strength\n2. Return ValidationResult with success/errors\n\nTests to write in validate.test.ts:\n1. 'validates correct email format' - test valid emails pass\n2. 'rejects invalid email format' - test invalid emails fail\n3. 'enforces password minimum length' - test short passwords rejected\n4. 'returns all validation errors' - test multiple errors collected\n\nWrite tests FIRST, then implement to make them pass.\" \\\n  --acceptance \"npm test -- --grep 'validates correct email' --grep 'rejects invalid' -v passes with all 4 test names visible in output\"\n```\n\n**Create a task with dependencies:**\n```bash\ntk create \"Task that depends on another\" \\\n  --parent <epic-id> \\\n  --blocked-by <blocker-tick-id> \\\n  -d \"Description...\" \\\n  --acceptance \"Verification steps...\"\n```\n\n**Create a human task:**\n```bash\ntk create \"Set up Firebase project and add credentials\" \\\n  --parent <epic-id> \\\n  --awaiting work \\\n  -d \"Manual setup required:\n1. Create Firebase project at console.firebase.google.com\n2. Enable Authentication\n3. Download service account key\n4. Add to .env as FIREBASE_CREDENTIALS\"\n```\n\n### Step 8: Create Environment Validation Epic\n\nAlways create a \"Phase 0\" epic for environment validation (with context references):\n\n```bash\ntk create \"<spec-name>: Environment validation\" -t epic -d \"Verify environment is healthy before implementation\n\n## Context\n\n**Spec:** \\`<path-to-spec-file>\\`\n\n**Key files:** Project root (package.json, tsconfig.json, etc.)\"\n\ntk create \"Run pre-flight checks\" \\\n  --parent <epic-id> \\\n  -d \"Verify the codebase is in a healthy state before starting implementation.\n\nCommands to run:\n- npm run build (or equivalent)\n- npm test (or equivalent)\n- npx tsc --noEmit (if TypeScript)\n\nDocument any pre-existing failures.\" \\\n  --acceptance \"Build passes; tests pass (or known failures documented)\"\n```\n\n### Step 9: Present the Created Ticks\n\nAfter creating all ticks, show a summary:\n\n```markdown\n## Ticks Created for: <spec-name>\n\n**Spec:** `<path to spec>`\n\n### Epics Overview\n\n| Epic | Tasks | Human Tasks | Description |\n|------|-------|-------------|-------------|\n| <id> | X     | Y           | Phase 0: Environment validation |\n| <id> | X     | Y           | Phase 1: ... |\n| <id> | X     | Y           | Phase 2: ... |\n\n### Human Tasks Requiring Attention\n\nThese tasks are marked `--awaiting work` and must be completed before dependent work can proceed:\n\n| ID | Title | Blocks |\n|----|-------|--------|\n| <id> | Set up credentials | <blocked-tick-ids> |\n```\n\n### Step 10: Explain How to Run and Monitor\n\nEnd by explaining how to execute the ticks:\n\n```markdown\n## Running Your Ticks\n\n### Option 1: Run with AI Agent (Autonomous)\n\n```bash\n# Run agent on an epic\ntk run <epic-id>\n\n# Run on multiple epics sequentially\ntk run <epic-id-1> <epic-id-2>\n\n# Auto-select next ready epic\ntk run --auto\n\n# Watch mode - restart when tasks become ready\ntk run <epic-id> --watch\n\n# Limit cost or iterations\ntk run <epic-id> --max-cost 5.00\ntk run <epic-id> --max-iterations 10\n```\n\n### Option 2: Manual Execution\n\n```bash\n# Get the next unblocked task\ntk next\n\n# Get next task within a specific epic\ntk next --parent <epic-id>\n\n# See all ready tasks\ntk ready\n\n# View a specific tick's details\ntk show <tick-id>\n\n# Close a tick when done\ntk close <tick-id> --reason \"Completed: description of what was done\"\n\n# Add notes during implementation\ntk note <tick-id> \"Decision: chose X because Y\"\n```\n\n### Monitoring Progress\n\n```bash\n# Visual board view (live updating)\ntk board\n\n# List all open ticks\ntk list\n\n# List completed ticks\ntk list --status closed\n\n# See what's blocked\ntk blocked\n\n# See human tasks needing attention\ntk list --awaiting work\n```\n\n### When You're Done\n\nRun `/checkin-and-pr` to commit your changes and create a pull request.\n```\n\n### Step 11: Offer Next Steps\n\nAsk:\n> Would you like me to:\n> 1. Adjust the tick breakdown?\n> 2. Add more detail to specific ticks?\n> 3. Help complete any human tasks before you start?\n\n---\n\n## Tick Quality Guidelines\n\n### Good Tick Design\n\n**DO:**\n- Make each tick atomic (one deliverable)\n- **Bundle tests with implementation** (never separate \"add tests\" ticks)\n- Include specific file paths in descriptions\n- **List specific test names** to write in the description\n- Write acceptance criteria as **executable commands**\n- **Include expected output** in acceptance (e.g., \"with TestFoo visible\")\n- Use `--blocked-by` for true dependencies only\n- Keep descriptions concise but complete\n\n**DON'T:**\n- Create ticks that are too large (split them)\n- Create ticks that are too small (combine related changes)\n- **Create separate ticks for tests** (bundle with implementation)\n- Use vague acceptance criteria (\"it works\", \"tests pass\")\n- Write acceptance criteria that can't be copy-pasted to terminal\n- Over-specify dependencies (only block when necessary)\n- Create ticks for future phases that may change\n\n### Acceptance Criteria Examples\n\n**Excellent (specific, executable, verifiable):**\n```\ngo test ./internal/worktree/... -run TestManager_Create -v passes with TestManager_Create_RecordsParentBranch visible\nnpm test -- --grep \"UserAuth\" --reporter=spec passes with \"should validate JWT token\" visible\ngo build ./... succeeds with no errors\ncurl -s localhost:3000/api/health returns {\"status\":\"ok\"}\n```\n\n**Good (executable but less specific):**\n```\nnpm test -- UserAuth.test.ts passes\ngo test ./... passes\nnpm run build succeeds\n```\n\n**Bad (not executable, agent can't verify):**\n```\nIt works\nTests pass\nLooks good\nCode is clean\nFeature is implemented\n```\n\n**Key principle:** If the agent can't copy-paste the acceptance criteria into a terminal and see pass/fail, it's not good enough.\n\n### Epic Sizing\n\n- **3-5 tasks per epic** is optimal for parallel execution\n- If an epic has 10+ tasks, split it\n- If an epic has 1 task, merge with another epic\n- Keep dependent task chains together\n- Split independent tasks across epics for parallelization\n\n### Human Task Identification\n\nMark as `--awaiting work` when the task requires:\n- Credentials, API keys, or secrets\n- External service configuration\n- Physical device testing\n- User decisions or approvals\n- Manual verification that can't be automated\n- Deployments or releases\n",
        "plugins/sdd/commands/startspec.md": "---\ndescription: Start a new specification document with interactive dialogue\nargument-hint: [project-name]\n---\n\n## Context\n\n- Today's date: !`date +%Y-%m-%d`\n- Current directory: !`pwd`\n- Current git branch: !`git branch --show-current 2>/dev/null || echo \"\"`\n- Project name argument: $ARGUMENTS\n\n## Your Task\n\nYou are starting a new specification document. Follow these steps:\n\n### Step 1: Determine the Naming Pattern\n\n**Option A: Explicit argument provided**\n\nIf `$ARGUMENTS` is not empty, use it as the project name. Generate a new naming pattern:\n1. Form the naming pattern: `<today's date>-<project-name>`\n\n**Option B: Infer from worktree or branch name**\n\nIf `$ARGUMENTS` is empty, try to infer the project name from the environment:\n\n1. **From worktree directory:** Check if the current directory name matches `<repo>-YYYY-MM-DD-<project-name>`\n   - Extract the full naming pattern: `2026-01-09-dark-mode`\n\n2. **From branch name with date:** Check if branch matches `feature/YYYY-MM-DD-<project-name>`\n   - Extract the full naming pattern: `2026-01-09-dark-mode`\n\n3. **From branch name without date:** Check if branch matches `feature/<project-name>` or just `<project-name>`\n   - Extract the project name and form new pattern: `<today's date>-<project-name>`\n   - Examples: `feature/dark-mode` -> `2026-01-21-dark-mode`, `melk-misc` -> `2026-01-21-melk-misc`\n\nIf a pattern is inferred:\n- Use this for the spec directory and file names\n- Inform the user: \"Inferred project name from branch: `<branch>`. Using naming pattern: `<pattern>`.\"\n\n**Option C: No argument and cannot infer**\n\nIf `$ARGUMENTS` is empty AND no pattern can be inferred, ask:\n> What would you like to call this spec? (e.g., \"dark-mode\", \"user-auth\", \"api-refactor\")\n\nThen generate a new naming pattern as in Option A.\n\nConvert the project name to kebab-case if needed.\n\n### Step 2: Create the Spec Directory and File\n\nUse the naming pattern determined in Step 1 (inferred from worktree/branch or newly generated).\n\n1. Create the directory: `/docs/projects/<naming-pattern>/`\n2. Create the spec file: `/docs/projects/<naming-pattern>/<naming-pattern>-spec.md`\n\nExample structure:\n```\ndocs/projects/\n  2026-01-09-dark-mode/\n    2026-01-09-dark-mode-spec.md      # The main specification\n    2026-01-09-dark-mode-research.md  # Additional documents use same prefix\n    2026-01-09-dark-mode-notes.md\n```\n\nCreate the spec file with this template:\n\n```markdown\n# <Project Name> Specification\n\n**Created:** <today's date>\n**Status:** Draft\n\n## Braindump / introductory thoughts\n\n[To be defined]\n\n## Overview\n\n[To be defined]\n\n## Open Questions\n\n- [ ]\n\n## References\n[To be defined]\n\n```\n### Step 3: Start the Dialogue\n\nAfter creating the file, begin a dialogue on the spec and continue until the spec is ready.\n\n### Step 4: Iterate until satisfactory\n\nContinue the dialogue until the spec is good.\n\n### Step 5: Remove braindump\n\nUpon spec ready, remove the Braindump section, making sure that everything important from there is now recorded elsewhere in the spec.\n"
      },
      "plugins": [
        {
          "name": "sdd",
          "description": "Spec-Driven Development workflow with ticks-based task tracking for AI agents",
          "version": "1.0.0",
          "author": {
            "name": "mkelk",
            "email": "mkelk@users.noreply.github.com"
          },
          "source": "./plugins/sdd",
          "category": "development",
          "homepage": "https://github.com/mkelk/claude-marketplace",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add mkelk/claude-marketplace",
            "/plugin install sdd@mkelk-marketplace"
          ]
        }
      ]
    }
  ]
}