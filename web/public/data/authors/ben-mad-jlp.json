{
  "author": {
    "id": "ben-mad-jlp",
    "display_name": "ben-mad-jlp",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/193282087?v=4",
    "url": "https://github.com/ben-mad-jlp",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 35,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "mermaid-collab-dev",
      "version": null,
      "description": "Development marketplace for Mermaid Collab plugin",
      "owner_info": {
        "name": "Ben Maderazo"
      },
      "keywords": [],
      "repo_full_name": "ben-mad-jlp/claude-mermaid-collab",
      "repo_url": "https://github.com/ben-mad-jlp/claude-mermaid-collab",
      "repo_description": "Real-time Mermaid diagram collaboration server with MCP integration for Claude Code",
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-29T13:16:01Z",
        "created_at": "2026-01-12T04:50:53Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 639
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 554
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 16591
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/subagent-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/subagent-driven-development/AGENT.md",
          "type": "blob",
          "size": 11860
        },
        {
          "path": "agents/subagent-driven-development/code-quality-reviewer-prompt.md",
          "type": "blob",
          "size": 929
        },
        {
          "path": "agents/subagent-driven-development/implementer-prompt.md",
          "type": "blob",
          "size": 4457
        },
        {
          "path": "agents/subagent-driven-development/spec-reviewer-prompt.md",
          "type": "blob",
          "size": 2581
        },
        {
          "path": "agents/systematic-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/systematic-debugging/AGENT.md",
          "type": "blob",
          "size": 10643
        },
        {
          "path": "agents/systematic-debugging/condition-based-waiting.md",
          "type": "blob",
          "size": 3483
        },
        {
          "path": "agents/systematic-debugging/defense-in-depth.md",
          "type": "blob",
          "size": 3649
        },
        {
          "path": "agents/systematic-debugging/root-cause-tracing.md",
          "type": "blob",
          "size": 5323
        },
        {
          "path": "agents/using-git-worktrees",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/using-git-worktrees/AGENT.md",
          "type": "blob",
          "size": 5096
        },
        {
          "path": "agents/verification-before-completion",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/verification-before-completion/AGENT.md",
          "type": "blob",
          "size": 3972
        },
        {
          "path": "agents/verify-phase",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/verify-phase/AGENT.md",
          "type": "blob",
          "size": 5971
        },
        {
          "path": "codex",
          "type": "tree",
          "size": null
        },
        {
          "path": "codex/ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "codex/ui/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "codex/ui/src/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "codex/ui/src/hooks/index.ts",
          "type": "blob",
          "size": 565
        },
        {
          "path": "codex/ui/src/hooks/useDrafts.ts",
          "type": "blob",
          "size": 11988
        },
        {
          "path": "codex/ui/src/hooks/useFlags.ts",
          "type": "blob",
          "size": 5772
        },
        {
          "path": "codex/ui/src/hooks/useMissingTopics.ts",
          "type": "blob",
          "size": 3453
        },
        {
          "path": "codex/ui/src/hooks/useTopic.ts",
          "type": "blob",
          "size": 7599
        },
        {
          "path": "codex/ui/src/hooks/useTopics.ts",
          "type": "blob",
          "size": 5944
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/brainstorming-enforce.sh",
          "type": "blob",
          "size": 1715
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 1192
        },
        {
          "path": "hooks/post-task-complete.sh",
          "type": "blob",
          "size": 1674
        },
        {
          "path": "hooks/pre-compact.sh",
          "type": "blob",
          "size": 1214
        },
        {
          "path": "hooks/server-check.sh",
          "type": "blob",
          "size": 1186
        },
        {
          "path": "hooks/sync-diagram-to-doc.sh",
          "type": "blob",
          "size": 4178
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/wireframe",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/wireframe/README.md",
          "type": "blob",
          "size": 6082
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brainstorming-clarifying",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brainstorming-clarifying/SKILL.md",
          "type": "blob",
          "size": 4636
        },
        {
          "path": "skills/brainstorming-designing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brainstorming-designing/SKILL.md",
          "type": "blob",
          "size": 5841
        },
        {
          "path": "skills/brainstorming-exploring",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brainstorming-exploring/SKILL.md",
          "type": "blob",
          "size": 3692
        },
        {
          "path": "skills/brainstorming-validating",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brainstorming-validating/SKILL.md",
          "type": "blob",
          "size": 4862
        },
        {
          "path": "skills/collab-cleanup",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/collab-cleanup/SKILL.md",
          "type": "blob",
          "size": 6089
        },
        {
          "path": "skills/collab-clear",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/collab-clear/skill.md",
          "type": "blob",
          "size": 1264
        },
        {
          "path": "skills/collab-compact",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/collab-compact/skill.md",
          "type": "blob",
          "size": 2723
        },
        {
          "path": "skills/collab",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/collab/SKILL.md",
          "type": "blob",
          "size": 1872
        },
        {
          "path": "skills/dispatching-parallel-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dispatching-parallel-agents/SKILL.md",
          "type": "blob",
          "size": 6181
        },
        {
          "path": "skills/executing-plans-execution",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/executing-plans-execution/SKILL.md",
          "type": "blob",
          "size": 7203
        },
        {
          "path": "skills/executing-plans-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/executing-plans-review/SKILL.md",
          "type": "blob",
          "size": 10767
        },
        {
          "path": "skills/executing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/executing-plans/SKILL.md",
          "type": "blob",
          "size": 17037
        },
        {
          "path": "skills/finishing-a-development-branch",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/finishing-a-development-branch/SKILL.md",
          "type": "blob",
          "size": 5958
        },
        {
          "path": "skills/gather-session-goals",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/gather-session-goals/SKILL.md",
          "type": "blob",
          "size": 6998
        },
        {
          "path": "skills/kodex-bootstrap-missing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-bootstrap-missing/SKILL.md",
          "type": "blob",
          "size": 4282
        },
        {
          "path": "skills/kodex-fix-incomplete",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-fix-incomplete/SKILL.md",
          "type": "blob",
          "size": 2256
        },
        {
          "path": "skills/kodex-fix-incorrect",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-fix-incorrect/SKILL.md",
          "type": "blob",
          "size": 3869
        },
        {
          "path": "skills/kodex-fix-missing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-fix-missing/SKILL.md",
          "type": "blob",
          "size": 2391
        },
        {
          "path": "skills/kodex-fix-outdated",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-fix-outdated/SKILL.md",
          "type": "blob",
          "size": 6964
        },
        {
          "path": "skills/kodex-fix",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-fix/SKILL.md",
          "type": "blob",
          "size": 2613
        },
        {
          "path": "skills/kodex-generate-aliases",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-generate-aliases/SKILL.md",
          "type": "blob",
          "size": 10540
        },
        {
          "path": "skills/kodex-init",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/kodex-init/SKILL.md",
          "type": "blob",
          "size": 5293
        },
        {
          "path": "skills/mermaid-collab",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/mermaid-collab/SKILL.md",
          "type": "blob",
          "size": 18532
        },
        {
          "path": "skills/ready-to-implement",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ready-to-implement/SKILL.md",
          "type": "blob",
          "size": 7826
        },
        {
          "path": "skills/receiving-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/receiving-code-review/SKILL.md",
          "type": "blob",
          "size": 6314
        },
        {
          "path": "skills/requesting-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/requesting-code-review/SKILL.md",
          "type": "blob",
          "size": 5042
        },
        {
          "path": "skills/rough-draft-blueprint",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/rough-draft-blueprint/SKILL.md",
          "type": "blob",
          "size": 8773
        },
        {
          "path": "skills/rough-draft-confirm",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/rough-draft-confirm/SKILL.md",
          "type": "blob",
          "size": 3827
        },
        {
          "path": "skills/systematic-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/systematic-debugging/SKILL.md",
          "type": "blob",
          "size": 2845
        },
        {
          "path": "skills/task-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/task-planning/SKILL.md",
          "type": "blob",
          "size": 8410
        },
        {
          "path": "skills/test-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/test-driven-development/SKILL.md",
          "type": "blob",
          "size": 12707
        },
        {
          "path": "skills/using-ai-ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-ai-ui/SKILL.md",
          "type": "blob",
          "size": 7450
        },
        {
          "path": "skills/using-gui-wireframes",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-gui-wireframes/SKILL.md",
          "type": "blob",
          "size": 3476
        },
        {
          "path": "skills/using-kodex",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-kodex/SKILL.md",
          "type": "blob",
          "size": 2417
        },
        {
          "path": "skills/using-superpowers",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-superpowers/SKILL.md",
          "type": "blob",
          "size": 3825
        },
        {
          "path": "skills/writing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-plans/SKILL.md",
          "type": "blob",
          "size": 4696
        },
        {
          "path": "skills/writing-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-skills/SKILL.md",
          "type": "blob",
          "size": 22463
        },
        {
          "path": "skills/writing-skills/anthropic-best-practices.md",
          "type": "blob",
          "size": 45825
        },
        {
          "path": "skills/writing-skills/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-skills/examples/CLAUDE_MD_TESTING.md",
          "type": "blob",
          "size": 5423
        },
        {
          "path": "skills/writing-skills/persuasion-principles.md",
          "type": "blob",
          "size": 5908
        },
        {
          "path": "skills/writing-skills/testing-skills-with-subagents.md",
          "type": "blob",
          "size": 12558
        },
        {
          "path": "ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/components",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/components/ai-ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/components/ai-ui/interactive",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/components/ai-ui/interactive/README.md",
          "type": "blob",
          "size": 9383
        },
        {
          "path": "ui/src/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/hooks/__tests__",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui/src/hooks/__tests__/useAgentStatus.test.ts",
          "type": "blob",
          "size": 9326
        },
        {
          "path": "ui/src/hooks/__tests__/useDocumentHistory.test.ts",
          "type": "blob",
          "size": 10022
        },
        {
          "path": "ui/src/hooks/__tests__/useEditorHistory.test.ts",
          "type": "blob",
          "size": 10846
        },
        {
          "path": "ui/src/hooks/__tests__/useExportDiagram.test.ts",
          "type": "blob",
          "size": 9593
        },
        {
          "path": "ui/src/hooks/__tests__/useIsMobile.test.ts",
          "type": "blob",
          "size": 8132
        },
        {
          "path": "ui/src/hooks/__tests__/useSession.test.ts",
          "type": "blob",
          "size": 10619
        },
        {
          "path": "ui/src/hooks/__tests__/useSessionPolling.test.ts",
          "type": "blob",
          "size": 10180
        },
        {
          "path": "ui/src/hooks/__tests__/useTaskGraph.test.ts",
          "type": "blob",
          "size": 17232
        },
        {
          "path": "ui/src/hooks/__tests__/useTheme.test.ts",
          "type": "blob",
          "size": 4802
        },
        {
          "path": "ui/src/hooks/__tests__/useWebSocket.test.ts",
          "type": "blob",
          "size": 6318
        },
        {
          "path": "ui/src/hooks/useAgentStatus.ts",
          "type": "blob",
          "size": 3128
        },
        {
          "path": "ui/src/hooks/useAutoSave.ts",
          "type": "blob",
          "size": 5094
        },
        {
          "path": "ui/src/hooks/useDataLoader.ts",
          "type": "blob",
          "size": 6769
        },
        {
          "path": "ui/src/hooks/useDiagram.ts",
          "type": "blob",
          "size": 3732
        },
        {
          "path": "ui/src/hooks/useDiagramUpdateQueue.test.ts",
          "type": "blob",
          "size": 10738
        },
        {
          "path": "ui/src/hooks/useDiagramUpdateQueue.ts",
          "type": "blob",
          "size": 3694
        },
        {
          "path": "ui/src/hooks/useDocument.ts",
          "type": "blob",
          "size": 3839
        },
        {
          "path": "ui/src/hooks/useDocumentHistory.ts",
          "type": "blob",
          "size": 3334
        },
        {
          "path": "ui/src/hooks/useEditorHistory.ts",
          "type": "blob",
          "size": 2496
        },
        {
          "path": "ui/src/hooks/useExportDiagram.ts",
          "type": "blob",
          "size": 4859
        },
        {
          "path": "ui/src/hooks/useIsMobile.test.ts",
          "type": "blob",
          "size": 8110
        },
        {
          "path": "ui/src/hooks/useIsMobile.ts",
          "type": "blob",
          "size": 1715
        },
        {
          "path": "ui/src/hooks/useSession.ts",
          "type": "blob",
          "size": 5006
        },
        {
          "path": "ui/src/hooks/useSessionPolling.ts",
          "type": "blob",
          "size": 2493
        },
        {
          "path": "ui/src/hooks/useSyncScroll.test.ts",
          "type": "blob",
          "size": 14486
        },
        {
          "path": "ui/src/hooks/useSyncScroll.ts",
          "type": "blob",
          "size": 4800
        },
        {
          "path": "ui/src/hooks/useTaskGraph.ts",
          "type": "blob",
          "size": 4226
        },
        {
          "path": "ui/src/hooks/useTerminalTabs.test.ts",
          "type": "blob",
          "size": 21619
        },
        {
          "path": "ui/src/hooks/useTerminalTabs.ts",
          "type": "blob",
          "size": 5201
        },
        {
          "path": "ui/src/hooks/useTheme.ts",
          "type": "blob",
          "size": 1450
        },
        {
          "path": "ui/src/hooks/useWebSocket.ts",
          "type": "blob",
          "size": 4805
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"mermaid-collab-dev\",\n  \"owner\": {\n    \"name\": \"Ben Maderazo\"\n  },\n  \"metadata\": {\n    \"description\": \"Development marketplace for Mermaid Collab plugin\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"mermaid-collab\",\n      \"description\": \"Collaborative design workflows for Claude Code: mermaid diagrams, wireframes, and design-to-implementation pipelines\",\n      \"version\": \"5.39.0\",\n      \"source\": \"./\",\n      \"author\": {\n        \"name\": \"Ben Maderazo\"\n      },\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"collaboration\",\n        \"mermaid\",\n        \"wireframes\",\n        \"design\",\n        \"diagrams\"\n      ]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"mermaid-collab\",\n  \"description\": \"Collaborative design workflows for Claude Code: mermaid diagrams, wireframes, and design-to-implementation pipelines with real-time preview\",\n  \"version\": \"5.39.0\",\n  \"author\": {\n    \"name\": \"Ben Maderazo\"\n  },\n  \"homepage\": \"https://github.com/ben-mad-jlp/claude-mermaid-collab\",\n  \"repository\": \"https://github.com/ben-mad-jlp/claude-mermaid-collab\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"collaboration\",\n    \"mermaid\",\n    \"wireframes\",\n    \"design\",\n    \"diagrams\",\n    \"workflows\",\n    \"mcp\"\n  ]\n}\n",
        "README.md": "# Mermaid Collab\n\nA collaborative design toolkit for Claude Code: diagram server + skills/agents for design-to-implementation workflows.\n\n**Two components:**\n1. **Server** - Real-time Mermaid diagram collaboration with MCP integration and React GUI\n2. **Plugin** - 42 skills + 5 agents for brainstorming, planning, and structured development workflows\n\n## Collab Workflow\n\nThe collab workflow turns ideas into working code through structured phases with verification gates at each transition.\n\n```\n/collab → gather-goals → work-item-loop → ready-to-implement → rough-draft → executing-plans → cleanup\n```\n\n### Phases\n\n| Phase | Purpose | Output |\n|-------|---------|--------|\n| **gather-session-goals** | Collect work items with type inference | Work items in design doc |\n| **brainstorming** | Socratic design refinement (EXPLORING → CLARIFYING → DESIGNING → VALIDATING) | Complete design with diagrams |\n| **rough-draft** | Progressive refinement (Interface → Pseudocode → Skeleton → Handoff) | Task dependency graph |\n| **executing-plans** | Parallel task execution with verification gates | Working implementation |\n| **collab-cleanup** | Archive or delete session artifacts | Clean workspace |\n\n### Key Principles\n\n- **Spec-first**: Design is complete before any code is written\n- **Drift detection**: Each phase verifies alignment with original design\n- **Anti-drift rules**: Implementation follows design EXACTLY - no interpretation\n- **Verification gates**: Evidence-based checks before each transition\n\n## Features\n\n### Server\n\n- **Multi-Session Architecture**: One server serves multiple projects and sessions\n- **React GUI**: Full-featured web dashboard at `http://localhost:3737`\n- **Split-Pane Editor**: Live preview with syntax validation, undo/redo\n- **Real-Time Collaboration**: WebSocket-based live updates with channel subscriptions\n- **MCP Integration**: Claude Code can create, read, update, and preview diagrams\n- **Wireframe Plugin**: Built-in support for UI wireframes and mockups\n- **Document Collaboration**: Create and edit markdown documents alongside diagrams\n- **AI UI System**: Rich interactive components rendered in browser (forms, tables, code blocks, etc.)\n- **Terminal Integration**: Embedded terminal sessions with tmux support\n- **Kodex Knowledge Base**: Project-specific knowledge management with topic CRUD\n- **Health Monitoring**: `/api/health` endpoint and `check_server_health` MCP tool\n\n### Skills (42 Total)\n\nSkills are orchestration-focused instructions for Claude Code, loaded on-demand. Large skills use phase modules to reduce context overhead.\n\n#### Collab Core (8)\n| Skill | Purpose |\n|-------|---------|\n| **collab** | Orchestrator - creates sessions, manages work item loop |\n| **collab-start** | Quick-start: ensures server running then launches collab |\n| **collab-work-item-loop** | Core loop that processes work items one at a time |\n| **collab-session-mgmt** | Session finding, creating, and resuming procedures |\n| **collab-compact** | Save context snapshot and trigger compaction |\n| **collab-cleanup** | Archive or delete session artifacts |\n| **collab-clear** | Close out a collab session |\n| **gather-session-goals** | Collects and classifies work items at session start |\n\n#### Brainstorming (6)\n| Skill | Purpose |\n|-------|---------|\n| **brainstorming** | Parent skill - Socratic design refinement through phases |\n| **brainstorming-exploring** | Phase: Gather context and form initial understanding |\n| **brainstorming-clarifying** | Phase: Discuss each item to understand requirements |\n| **brainstorming-designing** | Phase: Present design approach in validated sections |\n| **brainstorming-validating** | Phase: Run completeness gate for implementation readiness |\n| **brainstorming-transition** | Transition from brainstorming to rough-draft |\n\n#### Rough Draft (5)\n| Skill | Purpose |\n|-------|---------|\n| **rough-draft** | Parent skill - Bridges design to implementation via 4 phases |\n| **rough-draft-interface** | Phase 1: Define structural contracts |\n| **rough-draft-pseudocode** | Phase 2: Define logic flow for each function |\n| **rough-draft-skeleton** | Phase 3: Generate stub files and task dependency graph |\n| **rough-draft-handoff** | Phase 4: Hand off to executing-plans |\n\n#### Executing Plans (3)\n| Skill | Purpose |\n|-------|---------|\n| **executing-plans** | Parent skill - Batch execution with dependency-aware dispatch |\n| **executing-plans-execution** | Detailed execution logic |\n| **executing-plans-review** | Verification, drift detection, and snapshot logic |\n\n#### Kodex Knowledge Base (7)\n| Skill | Purpose |\n|-------|---------|\n| **using-kodex** | Query topics and flag outdated information |\n| **kodex-init** | Bootstrap knowledge base by analyzing codebase |\n| **kodex-fix** | Fix flagged topics by generating updated content |\n| **kodex-fix-outdated** | Update topics with codebase changes |\n| **kodex-fix-incorrect** | Correct factually incorrect content |\n| **kodex-fix-incomplete** | Fill in missing sections |\n| **kodex-fix-missing** | Create new topics for missing documentation |\n\n#### Implementation (5)\n| Skill | Purpose |\n|-------|---------|\n| **ready-to-implement** | Central checkpoint - validates all items documented |\n| **task-planning** | Plans operational tasks (Prerequisites → Steps → Verification) |\n| **dispatching-parallel-agents** | Coordinates independent tasks |\n| **finishing-a-development-branch** | Merge/PR decision workflow |\n| **writing-plans** | Detailed implementation plans (standalone) |\n\n#### Development Practices (2)\n| Skill | Purpose |\n|-------|---------|\n| **test-driven-development** | RED-GREEN-REFACTOR cycle enforcement |\n| **writing-skills** | Create and verify new skills |\n\n#### Code Review (2)\n| Skill | Purpose |\n|-------|---------|\n| **requesting-code-review** | Prepares code for peer review |\n| **receiving-code-review** | Handles feedback with validation |\n\n#### Visualization & Utilities (4)\n| Skill | Purpose |\n|-------|---------|\n| **mermaid-collab** | Create/edit diagrams, wireframes, documents |\n| **using-gui-wireframes** | UI mockup creation |\n| **using-ai-ui** | Guide for interactive UI components |\n| **using-superpowers** | Establishes skill discovery and usage |\n\n### Agents (5 Total)\n\nAgents are standalone Task tool targets with simplified frontmatter. They focus on specific bounded tasks.\n\n| Agent | Purpose |\n|-------|---------|\n| **subagent-driven-development** | Fast iteration with parallel task execution |\n| **systematic-debugging** | 4-phase root cause analysis (documentation only) |\n| **verify-phase** | Checks rough-draft output aligns with design |\n| **verification-before-completion** | Evidence before success claims |\n| **using-git-worktrees** | Creates isolated development branches |\n\n## Quick Start\n\n### 1. Install Server\n\n```bash\ngit clone https://github.com/ben-mad-jlp/claude-mermaid-collab.git\ncd claude-mermaid-collab\nbun install\n```\n\n### 2. Start Server\n\n```bash\n# Start server in background\nbun run bin/mermaid-collab.ts start\n\n# Check status\nbun run bin/mermaid-collab.ts status\n\n# Stop server\nbun run bin/mermaid-collab.ts stop\n```\n\nThe server runs at `http://localhost:3737` and serves all sessions.\n\n### 3. Install Plugin (Claude Code)\n\n```bash\n# In Claude Code, install the plugin\n/plugin install ben-mad-jlp/claude-mermaid-collab\n```\n\n### 4. Start a Collab Session\n\n```bash\n# In Claude Code\n/collab\n```\n\nThis will:\n1. Create a new session with a memorable name (e.g., `bright-calm-river`)\n2. Ask what you want to accomplish\n3. Guide you through the design-to-implementation workflow\n\n## Slash Commands\n\nThe plugin provides these slash commands (all namespaced under `mermaid-collab:`):\n\n| Command | Description |\n|---------|-------------|\n| `/mermaid-collab:collab` | Start or resume a collaborative design session |\n| `/mermaid-collab:collab-start` | Ensure server running and start collab |\n| `/mermaid-collab:brainstorming` | Start brainstorming for a feature/component |\n| `/mermaid-collab:mermaid-collab` | Create and collaborate on Mermaid diagrams |\n\n**Note:** Commands are namespaced with `mermaid-collab:` prefix because they come from this plugin. Type `/mermaid-collab:` in Claude Code to see all available commands.\n\n## Session Storage\n\n```\n~/.mermaid-collab/\n├── sessions.json       # Registry of all sessions\n├── server.pid          # Server process ID\n└── .collab/\n    └── scratch/        # Default scratch session\n\n/your/project/\n├── .collab/\n│   └── session-name/\n│       ├── diagrams/              # .mmd files\n│       ├── documents/             # .md files (design.md required)\n│       ├── collab-state.json      # Phase tracking\n│       ├── terminal-sessions.json # Persistent terminal tabs\n│       └── context-snapshot.json  # Recovery after compaction\n└── .kodex/                        # Project knowledge base\n    └── topics/\n        └── *.md                   # Topic files\n```\n\n### Collab State\n\n```json\n{\n  \"phase\": \"brainstorming|rough-draft/interface|rough-draft/pseudocode|rough-draft/skeleton|implementation\",\n  \"lastActivity\": \"2026-01-20T10:30:00Z\",\n  \"currentItem\": null,\n  \"hasSnapshot\": false,\n  \"completedTasks\": [],\n  \"pendingTasks\": []\n}\n```\n\n## MCP Tools\n\nAll tools require `project` (absolute path) and `session` (session name) parameters unless noted.\n\n### Health & Session Management\n\n| Tool | Description |\n|------|-------------|\n| `check_server_health()` | Check server health status |\n| `generate_session_name()` | Generate a memorable session name |\n| `list_sessions()` | List all registered sessions |\n| `list_projects()` | List all registered projects |\n| `register_project(path)` | Register a new project |\n| `unregister_project(path)` | Unregister a project |\n\n### Collab State Tools\n\n| Tool | Description |\n|------|-------------|\n| `get_session_state(project, session)` | Read collab-state.json |\n| `update_session_state(project, session, ...)` | Update collab state fields |\n| `has_snapshot(project, session)` | Check if context snapshot exists |\n| `save_snapshot(project, session, ...)` | Save context snapshot for recovery |\n| `load_snapshot(project, session)` | Load context snapshot |\n| `delete_snapshot(project, session)` | Delete context snapshot |\n\n### Diagram Tools\n\n| Tool | Description |\n|------|-------------|\n| `list_diagrams(project, session)` | List all diagrams |\n| `get_diagram(project, session, id)` | Get diagram content |\n| `create_diagram(project, session, name, content)` | Create new diagram |\n| `update_diagram(project, session, id, content)` | Update diagram |\n| `patch_diagram(project, session, id, old_string, new_string)` | Patch diagram content |\n| `validate_diagram(content)` | Check Mermaid syntax |\n| `preview_diagram(project, session, id)` | Get browser URL |\n| `transpile_diagram(project, session, id)` | Get transpiled output for SMACH diagrams |\n\n### Document Tools\n\n| Tool | Description |\n|------|-------------|\n| `list_documents(project, session)` | List all documents |\n| `get_document(project, session, id)` | Get document content |\n| `create_document(project, session, name, content)` | Create new document |\n| `update_document(project, session, id, content)` | Update document |\n| `patch_document(project, session, id, old_string, new_string)` | Patch document content |\n| `preview_document(project, session, id)` | Get browser URL |\n\n### UI Tools\n\n| Tool | Description |\n|------|-------------|\n| `render_ui(project, session, ui, blocking?, timeout?)` | Push UI to browser |\n| `update_ui(project, session, patch)` | Update displayed UI with patch |\n| `dismiss_ui(project, session)` | Dismiss current UI |\n\n### Terminal Session Tools\n\n| Tool | Description |\n|------|-------------|\n| `terminal_create_session(project, session, name?)` | Create a new tmux terminal session |\n| `terminal_list_sessions(project, session)` | List all terminal sessions for a collab |\n| `terminal_kill_session(project, session, id)` | Kill a terminal session |\n| `terminal_rename_session(project, session, id, name)` | Rename a terminal session |\n| `terminal_reorder_sessions(project, session, orderedIds)` | Reorder terminal sessions |\n\n### Kodex Knowledge Base Tools\n\n| Tool | Description |\n|------|-------------|\n| `kodex_query_topic(project, name)` | Query a topic from knowledge base |\n| `kodex_list_topics(project, filter?)` | List all topics (all/verified/unverified/has_draft) |\n| `kodex_create_topic(project, name, title, content)` | Create new topic (as draft) |\n| `kodex_update_topic(project, name, content, reason)` | Update topic (creates draft) |\n| `kodex_flag_topic(project, name, type, description)` | Flag topic for review |\n| `kodex_verify_topic(project, name, verified_by)` | Mark topic as verified |\n| `kodex_list_drafts(project, include_content?)` | List pending drafts |\n| `kodex_approve_draft(project, name)` | Approve a pending draft |\n| `kodex_reject_draft(project, name)` | Reject a pending draft |\n| `kodex_dashboard(project)` | Get dashboard stats |\n| `kodex_list_flags(project, status?)` | List flagged topics |\n\n## REST API\n\nAll endpoints require `?project=...&session=...` query parameters unless noted.\n\n### Health\n```bash\nGET /api/health                # Server health status (no params required)\n```\n\n### Sessions\n```bash\nGET /api/sessions              # List all sessions\nPOST /api/sessions             # Register session\nDELETE /api/sessions           # Unregister session\n```\n\n### Diagrams\n```bash\nGET /api/diagrams              # List diagrams\nGET /api/diagram/:id           # Get diagram\nPOST /api/diagram              # Create diagram\nPOST /api/diagram/:id          # Update diagram\nPATCH /api/diagram/:id         # Patch diagram\nDELETE /api/diagram/:id        # Delete diagram\n```\n\n### Documents\n```bash\nGET /api/documents             # List documents\nGET /api/document/:id          # Get document\nPOST /api/document             # Create document\nPOST /api/document/:id         # Update document\nPATCH /api/document/:id        # Patch document\nDELETE /api/document/:id       # Delete document\n```\n\n### Terminal Sessions\n```bash\nGET /api/terminal/sessions           # List terminal sessions\nPOST /api/terminal/sessions          # Create terminal session\nDELETE /api/terminal/sessions/:id    # Kill terminal session\nPATCH /api/terminal/sessions/:id     # Rename terminal session\nPUT /api/terminal/sessions/reorder   # Reorder terminal sessions\n```\n\n## Architecture\n\n### Services\n\n| Service | Purpose |\n|---------|---------|\n| **SessionRegistry** | Tracks sessions across projects |\n| **DiagramManager** | Per-session diagram CRUD |\n| **DocumentManager** | Per-session document CRUD |\n| **TerminalManager** | Collab-scoped tmux session lifecycle |\n| **KodexManager** | Project knowledge base management |\n| **Validator** | Mermaid syntax validation |\n| **Renderer** | Server-side SVG generation |\n| **WebSocketHandler** | Real-time updates with channel subscriptions |\n\n### Single Server Model\n\n- One server instance serves all projects and sessions\n- Runs on port 3737 (configurable via `PORT` env var)\n- Session registry at `~/.mermaid-collab/sessions.json`\n- WebSocket broadcasts include project/session context for filtering\n- Channel-based subscriptions for targeted updates\n\n## AI UI Components\n\nThe `render_ui` tool supports 32 component types for rich browser interactions:\n\n### Display Components\n`Table`, `CodeBlock`, `DiffView`, `JsonViewer`, `Markdown`, `Image`, `Spinner`, `Badge`\n\n### Layout Components\n`Card`, `Section`, `Columns`, `Accordion`, `Alert`, `Divider`\n\n### Interactive Components\n`Wizard`, `Checklist`, `ApprovalButtons`, `ProgressBar`, `Tabs`, `Link`\n\n### Input Components (form data collected on action)\n`MultipleChoice`, `TextInput`, `TextArea`, `Checkbox`, `Confirmation`, `RadioGroup`, `Toggle`, `NumberInput`, `Slider`, `FileUpload`\n\n### Mermaid Components\n`DiagramEmbed`, `WireframeEmbed`\n\n## Wireframe Plugin\n\nCreate UI wireframes with text-based syntax:\n\n```\nwireframe mobile TD\n  screen \"Login Screen\"\n    col padding=16\n      Title \"Welcome Back\"\n      Input \"Email\"\n      Input \"Password\"\n      Button \"Sign In\" primary\n```\n\nSee [plugins/wireframe/README.md](plugins/wireframe/README.md) for full documentation.\n\n## Development\n\n```bash\n# Run server directly (for development)\nbun run src/server.ts\n\n# Run MCP server directly\nbun run src/mcp/server.ts\n\n# Run full dev environment (API + UI + Terminal)\nnpm run dev\n\n# Run UI tests\ncd ui && npm run test:ci\n\n# Run backend tests\nnpm run test:backend\n```\n\n## License\n\nMIT\n",
        "agents/subagent-driven-development/AGENT.md": "---\nname: subagent-driven-development\ndescription: Use when executing implementation plans with independent tasks in the current session\nuser-invocable: false\nmodel: haiku\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep, Task\n---\n\n# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.\n\n**Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Have implementation plan?\" [shape=diamond];\n    \"Tasks mostly independent?\" [shape=diamond];\n    \"Stay in this session?\" [shape=diamond];\n    \"subagent-driven-development\" [shape=box];\n    \"executing-plans\" [shape=box];\n    \"Manual execution or brainstorm first\" [shape=box];\n\n    \"Have implementation plan?\" -> \"Tasks mostly independent?\" [label=\"yes\"];\n    \"Have implementation plan?\" -> \"Manual execution or brainstorm first\" [label=\"no\"];\n    \"Tasks mostly independent?\" -> \"Stay in this session?\" [label=\"yes\"];\n    \"Tasks mostly independent?\" -> \"Manual execution or brainstorm first\" [label=\"no - tightly coupled\"];\n    \"Stay in this session?\" -> \"subagent-driven-development\" [label=\"yes\"];\n    \"Stay in this session?\" -> \"executing-plans\" [label=\"no - parallel session\"];\n}\n```\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Two-stage review after each task: spec compliance first, then code quality\n- Faster iteration (no human-in-loop between tasks)\n\n## The Process\n\n```dot\ndigraph process {\n    rankdir=TB;\n\n    subgraph cluster_per_task {\n        label=\"Per Task\";\n        \"Dispatch implementer subagent (./implementer-prompt.md)\" [shape=box];\n        \"Implementer subagent asks questions?\" [shape=diamond];\n        \"Answer questions, provide context\" [shape=box];\n        \"Implementer subagent implements, tests, commits, self-reviews\" [shape=box];\n        \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [shape=box];\n        \"Spec reviewer subagent confirms code matches spec?\" [shape=diamond];\n        \"Implementer subagent fixes spec gaps\" [shape=box];\n        \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [shape=box];\n        \"Code quality reviewer subagent approves?\" [shape=diamond];\n        \"Implementer subagent fixes quality issues\" [shape=box];\n        \"Mark task complete in TodoWrite\" [shape=box];\n    }\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" [shape=box];\n    \"More tasks remain?\" [shape=diamond];\n    \"Dispatch final code reviewer subagent for entire implementation\" [shape=box];\n    \"Use superpowers:finishing-a-development-branch\" [shape=box style=filled fillcolor=lightgreen];\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Dispatch implementer subagent (./implementer-prompt.md)\" -> \"Implementer subagent asks questions?\";\n    \"Implementer subagent asks questions?\" -> \"Answer questions, provide context\" [label=\"yes\"];\n    \"Answer questions, provide context\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Implementer subagent asks questions?\" -> \"Implementer subagent implements, tests, commits, self-reviews\" [label=\"no\"];\n    \"Implementer subagent implements, tests, commits, self-reviews\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\";\n    \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" -> \"Spec reviewer subagent confirms code matches spec?\";\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Implementer subagent fixes spec gaps\" [label=\"no\"];\n    \"Implementer subagent fixes spec gaps\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"yes\"];\n    \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" -> \"Code quality reviewer subagent approves?\";\n    \"Code quality reviewer subagent approves?\" -> \"Implementer subagent fixes quality issues\" [label=\"no\"];\n    \"Implementer subagent fixes quality issues\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Code quality reviewer subagent approves?\" -> \"Mark task complete in TodoWrite\" [label=\"yes\"];\n    \"Mark task complete in TodoWrite\" -> \"More tasks remain?\";\n    \"More tasks remain?\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\" [label=\"yes\"];\n    \"More tasks remain?\" -> \"Dispatch final code reviewer subagent for entire implementation\" [label=\"no\"];\n    \"Dispatch final code reviewer subagent for entire implementation\" -> \"Use superpowers:finishing-a-development-branch\";\n}\n```\n\n## Prompt Templates\n\n- `./implementer-prompt.md` - Dispatch implementer subagent\n- `./spec-reviewer-prompt.md` - Dispatch spec compliance reviewer subagent\n- `./code-quality-reviewer-prompt.md` - Dispatch code quality reviewer subagent\n\n## Anti-Drift Rules (Apply to ALL Subagents)\n\n**FOR IMPLEMENTER:**\n- Implement EXACTLY what the task says — no \"improvements\"\n- If task says \"create function foo(x) that returns x+1\" — do exactly that\n- If something seems wrong, ASK the controller — don't \"fix\" it\n- Complete every step in order — no shortcuts\n- Run every verification — no skipping\n\n**FOR SPEC REVIEWER:**\n- Check implementation against spec LITERALLY, not \"in spirit\"\n- Flag ANY deviation, even if \"better\" than spec\n- Missing feature = fail\n- Extra feature = fail (YAGNI violation)\n- Different approach than specified = fail\n- If mermaid-collab diagrams exist, visually verify against them\n\n**FOR CODE QUALITY REVIEWER:**\n- Only runs AFTER spec compliance passes\n- Quality review cannot override spec compliance\n- \"Better architecture\" that deviates from spec = still a spec failure\n\n**DESIGN ARTIFACTS:**\n- If plan references mermaid-collab wireframes/diagrams, subagents MUST verify against them\n- Spec reviewer: \"Does UI match wireframe `<id>` exactly?\"\n- Spec reviewer: \"Does data flow match diagram `<id>` exactly?\"\n\n## Design Freeze\n\nOnce execution begins, the design is FROZEN.\n\n**No changes during implementation:**\n- No \"small tweaks\" to requirements\n- No \"I realized we need X\" additions\n- No \"let's just add this while we're here\"\n- No scope creep, no matter how reasonable it sounds\n\n**If something needs to change:**\n1. STOP execution immediately\n2. Document what needs to change and why\n3. Go back to design doc — update it formally\n4. Update the plan to reflect changes\n5. THEN resume execution\n\n**Why this matters:**\n- Mid-implementation changes cause drift\n- \"Quick additions\" compound into chaos\n- The plan is a contract — honor it\n\n## Example Workflow\n\n```\nYou: I'm using Subagent-Driven Development to execute this plan.\n\n[Read plan file once: docs/plans/feature-plan.md]\n[Extract all 5 tasks with full text and context]\n[Create TodoWrite with all tasks]\n\nTask 1: Hook installation script\n\n[Get Task 1 text and context (already extracted)]\n[Dispatch implementation subagent with full task text + context]\n\nImplementer: \"Before I begin - should the hook be installed at user or system level?\"\n\nYou: \"User level (~/.config/superpowers/hooks/)\"\n\nImplementer: \"Got it. Implementing now...\"\n[Later] Implementer:\n  - Implemented install-hook command\n  - Added tests, 5/5 passing\n  - Self-review: Found I missed --force flag, added it\n  - Committed\n\n[Dispatch spec compliance reviewer]\nSpec reviewer: ✅ Spec compliant - all requirements met, nothing extra\n\n[Get git SHAs, dispatch code quality reviewer]\nCode reviewer: Strengths: Good test coverage, clean. Issues: None. Approved.\n\n[Mark Task 1 complete]\n\nTask 2: Recovery modes\n\n[Get Task 2 text and context (already extracted)]\n[Dispatch implementation subagent with full task text + context]\n\nImplementer: [No questions, proceeds]\nImplementer:\n  - Added verify/repair modes\n  - 8/8 tests passing\n  - Self-review: All good\n  - Committed\n\n[Dispatch spec compliance reviewer]\nSpec reviewer: ❌ Issues:\n  - Missing: Progress reporting (spec says \"report every 100 items\")\n  - Extra: Added --json flag (not requested)\n\n[Implementer fixes issues]\nImplementer: Removed --json flag, added progress reporting\n\n[Spec reviewer reviews again]\nSpec reviewer: ✅ Spec compliant now\n\n[Dispatch code quality reviewer]\nCode reviewer: Strengths: Solid. Issues (Important): Magic number (100)\n\n[Implementer fixes]\nImplementer: Extracted PROGRESS_INTERVAL constant\n\n[Code reviewer reviews again]\nCode reviewer: ✅ Approved\n\n[Mark Task 2 complete]\n\n...\n\n[After all tasks]\n[Dispatch final code-reviewer]\nFinal reviewer: All requirements met, ready to merge\n\nDone!\n```\n\n## Advantages\n\n**vs. Manual execution:**\n- Subagents follow TDD naturally\n- Fresh context per task (no confusion)\n- Parallel-safe (subagents don't interfere)\n- Subagent can ask questions (before AND during work)\n\n**vs. Executing Plans:**\n- Same session (no handoff)\n- Continuous progress (no waiting)\n- Review checkpoints automatic\n\n**Efficiency gains:**\n- No file reading overhead (controller provides full text)\n- Controller curates exactly what context is needed\n- Subagent gets complete information upfront\n- Questions surfaced before work begins (not after)\n\n**Quality gates:**\n- Self-review catches issues before handoff\n- Two-stage review: spec compliance, then code quality\n- Review loops ensure fixes actually work\n- Spec compliance prevents over/under-building\n- Code quality ensures implementation is well-built\n\n**Cost:**\n- More subagent invocations (implementer + 2 reviewers per task)\n- Controller does more prep work (extracting all tasks upfront)\n- Review loops add iterations\n- But catches issues early (cheaper than debugging later)\n\n## Red Flags\n\n**Never:**\n- Skip reviews (spec compliance OR code quality)\n- Proceed with unfixed issues\n- Dispatch multiple implementation subagents in parallel (conflicts)\n- Make subagent read plan file (provide full text instead)\n- Skip scene-setting context (subagent needs to understand where task fits)\n- Ignore subagent questions (answer before letting them proceed)\n- Accept \"close enough\" on spec compliance (spec reviewer found issues = not done)\n- Skip review loops (reviewer found issues = implementer fixes = review again)\n- Let implementer self-review replace actual review (both are needed)\n- **Start code quality review before spec compliance is ✅** (wrong order)\n- Move to next task while either review has open issues\n- Let implementer \"improve\" on the spec (interpretation drift)\n- Accept implementations that are \"close enough\" or \"even better\" than spec\n- Skip design artifact verification when diagrams are referenced\n\n**If subagent asks questions:**\n- Answer clearly and completely\n- Provide additional context if needed\n- Don't rush them into implementation\n\n**If reviewer finds issues:**\n- Implementer (same subagent) fixes them\n- Reviewer reviews again\n- Repeat until approved\n- Don't skip the re-review\n\n**If subagent fails task:**\n- Dispatch fix subagent with specific instructions\n- Don't try to fix manually (context pollution)\n\n## Integration\n\n**Required workflow skills:**\n- **superpowers:writing-plans** - Creates the plan this skill executes\n- **superpowers:requesting-code-review** - Code review template for reviewer subagents\n- **superpowers:finishing-a-development-branch** - Complete development after all tasks\n\n**Subagents should use:**\n- **superpowers:test-driven-development** - Subagents follow TDD for each task\n\n**Alternative workflow:**\n- **superpowers:executing-plans** - Use for parallel session instead of same-session execution\n",
        "agents/subagent-driven-development/code-quality-reviewer-prompt.md": "# Code Quality Reviewer Prompt Template\n\nUse this template when dispatching a code quality reviewer subagent.\n\n**Purpose:** Verify implementation is well-built (clean, tested, maintainable)\n\n**Only dispatch after spec compliance review passes.**\n\n```\nTask tool (superpowers:code-reviewer):\n  Use template at requesting-code-review/code-reviewer.md\n\n  WHAT_WAS_IMPLEMENTED: [from implementer's report]\n  PLAN_OR_REQUIREMENTS: Task N from [plan-file]\n  BASE_SHA: [commit before task]\n  HEAD_SHA: [current commit]\n  DESCRIPTION: [task summary]\n```\n\n**Code reviewer returns:** Strengths, Issues (Critical/Important/Minor), Assessment\n\n**IMPORTANT:** Code quality review cannot override spec compliance.\n\n- If code is \"better architected\" but deviates from spec = still a spec failure\n- Quality improvements that change behavior = reject and send back to spec review\n- Your job is to verify the code is well-built, NOT to redesign it\n",
        "agents/subagent-driven-development/implementer-prompt.md": "# Implementer Subagent Prompt Template\n\nUse this template when dispatching an implementer subagent.\n\n```\nTask tool (general-purpose):\n  description: \"Implement Task N: [task name]\"\n  prompt: |\n    You are implementing Task N: [task name]\n\n    ## Task Description\n\n    [FULL TEXT of task from plan - paste it here, don't make subagent read file]\n\n    ## Context\n\n    [Scene-setting: where this fits, dependencies, architectural context]\n\n    ## Before You Begin\n\n    If you have questions about:\n    - The requirements or acceptance criteria\n    - The approach or implementation strategy\n    - Dependencies or assumptions\n    - Anything unclear in the task description\n\n    **Ask them now.** Raise any concerns before starting work.\n\n    ## REQUIRED: Read Design Document First\n\n    **Before writing any code:**\n\n    1. Read the design doc:\n       Tool: Read\n       Args: { \"file_path\": \"<collab-session-path>/documents/design.md\" }\n\n    2. Find these sections for your task:\n       - **Interface Definition** - Function signatures, types, file paths\n       - **Pseudocode** - Step-by-step logic for each function\n\n    3. The design doc is the SOURCE OF TRUTH:\n       - Match signatures EXACTLY as specified\n       - Follow pseudocode logic EXACTLY as written\n       - If you think there's a better way: STOP and ASK\n\n    4. If design doc is missing or unclear:\n       - STOP immediately\n       - Report: \"Design doc missing [section] for [task]\"\n       - Do NOT guess or improvise\n\n    **The design was reviewed and approved. Your job is execution, not redesign.**\n\n    ## Your Job\n\n    Once you're clear on requirements:\n    0. Read design doc and locate your task's Interface and Pseudocode sections\n    1. Implement EXACTLY what the design specifies — no improvements, no shortcuts\n    2. Write tests (following TDD if task says to)\n    3. Verify implementation works\n    4. Commit your work\n    5. Self-review (see below)\n    6. Report back\n\n    ## Test Execution\n\n    When following TDD (RED-GREEN-REFACTOR):\n    - Run ONLY the tests specified in the task's `tests` field\n    - Command: `npm run test:ci -- {tests joined by space}`\n    - Do NOT run the full test suite during TDD cycles\n    - The full test suite will be run by the controller after the wave completes\n\n    Example:\n    If task.tests = ['src/auth/service.test.ts', 'src/auth/__tests__/service.test.ts']\n    Then run: `npm run test:ci -- src/auth/service.test.ts src/auth/__tests__/service.test.ts`\n\n    ## CRITICAL: No Interpretation, No Shortcuts\n\n    **NO INTERPRETATION:**\n    - Implement EXACTLY what the spec says, word for word\n    - If spec says \"function foo(x) returns x+1\" — do that, not \"a more flexible version\"\n    - If you think there's a better way — STOP and ASK, don't just do it\n    - \"Better\" implementations that deviate from spec = FAILURE\n\n    **NO SHORTCUTS:**\n    - Complete every step in order\n    - Run every test command listed\n    - Create every file listed\n    - If a step seems redundant, do it anyway\n\n    **DESIGN ARTIFACTS:**\n    - If task references mermaid-collab wireframes or diagrams, verify against them\n    - UI must match wireframe EXACTLY\n    - Data flow must match diagram EXACTLY\n\n    **When in doubt:** ASK. Never guess. Never improvise.\n\n    Work from: [directory]\n\n    **While you work:** If you encounter something unexpected or unclear, **ask questions**.\n    It's always OK to pause and clarify. Don't guess or make assumptions.\n\n    ## Before Reporting Back: Self-Review\n\n    Review your work with fresh eyes. Ask yourself:\n\n    **Completeness:**\n    - Did I fully implement everything in the spec?\n    - Did I miss any requirements?\n    - Are there edge cases I didn't handle?\n\n    **Quality:**\n    - Is this my best work?\n    - Are names clear and accurate (match what things do, not how they work)?\n    - Is the code clean and maintainable?\n\n    **Discipline:**\n    - Did I avoid overbuilding (YAGNI)?\n    - Did I only build what was requested?\n    - Did I follow existing patterns in the codebase?\n\n    **Testing:**\n    - Do tests actually verify behavior (not just mock behavior)?\n    - Did I follow TDD if required?\n    - Are tests comprehensive?\n\n    If you find issues during self-review, fix them now before reporting.\n\n    ## Report Format\n\n    When done, report:\n    - What you implemented\n    - What you tested and test results\n    - Files changed\n    - Self-review findings (if any)\n    - Any issues or concerns\n```\n",
        "agents/subagent-driven-development/spec-reviewer-prompt.md": "# Spec Compliance Reviewer Prompt Template\n\nUse this template when dispatching a spec compliance reviewer subagent.\n\n**Purpose:** Verify implementer built what was requested (nothing more, nothing less)\n\n```\nTask tool (general-purpose):\n  description: \"Review spec compliance for Task N\"\n  prompt: |\n    You are reviewing whether an implementation matches its specification.\n\n    ## What Was Requested\n\n    [FULL TEXT of task requirements]\n\n    ## What Implementer Claims They Built\n\n    [From implementer's report]\n\n    ## CRITICAL: Do Not Trust the Report\n\n    The implementer finished suspiciously quickly. Their report may be incomplete,\n    inaccurate, or optimistic. You MUST verify everything independently.\n\n    **DO NOT:**\n    - Take their word for what they implemented\n    - Trust their claims about completeness\n    - Accept their interpretation of requirements\n\n    **DO:**\n    - Read the actual code they wrote\n    - Compare actual implementation to requirements line by line\n    - Check for missing pieces they claimed to implement\n    - Look for extra features they didn't mention\n\n    ## Your Job\n\n    Read the implementation code and verify:\n\n    **Missing requirements:**\n    - Did they implement everything that was requested?\n    - Are there requirements they skipped or missed?\n    - Did they claim something works but didn't actually implement it?\n\n    **Design artifact verification (if applicable):**\n    - If task references mermaid-collab wireframes, open them and compare visually\n    - If task references architecture/flow diagrams, verify implementation matches\n    - UI doesn't match wireframe = FAIL\n    - Data flow doesn't match diagram = FAIL\n\n    **Extra/unneeded work:**\n    - Did they build things that weren't requested?\n    - Did they over-engineer or add unnecessary features?\n    - Did they add \"nice to haves\" that weren't in spec?\n\n    **Misunderstandings:**\n    - Did they interpret requirements differently than intended?\n    - Did they solve the wrong problem?\n    - Did they implement the right feature but wrong way?\n\n    **Verify by reading code, not by trusting report.**\n\n    **STRICT COMPLIANCE STANDARD:**\n    - \"Close enough\" = FAIL\n    - \"Even better than spec\" = FAIL\n    - \"Same result, different approach\" = FAIL\n    - Only EXACT match = PASS\n\n    Report:\n    - ✅ Spec compliant (ONLY if implementation matches spec EXACTLY after code inspection)\n    - ❌ Issues found: [list specifically what's missing, extra, or different, with file:line references]\n\n    **If ANY deviation exists, even if \"better\", report ❌**\n```\n",
        "agents/systematic-debugging/AGENT.md": "---\nname: systematic-debugging\ndescription: Self-contained debugging investigation that produces a diagnostic report\n---\n\n# Systematic Debugging\n\n## EXPLICIT PROHIBITION\n\n```\nDO NOT IMPLEMENT FIXES\n\n- No editing source files to fix the bug\n- No writing fix code\n- Document only\n- Fixes happen later via rough-draft -> executing-plans\n```\n\nThe following are FORBIDDEN in this agent:\n- Using Edit tool on source files (except design doc)\n- Using Write tool on source files\n- Making any code changes to fix the bug\n- Implementing the fix\n\n## Overview\n\nRandom fixes waste time and create new bugs. Quick patches mask underlying issues.\n\n**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.\n\n**Violating the letter of this process is violating the spirit of debugging.**\n\n## The Iron Law\n\n```\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n```\n\nIf you haven't completed Phase 1, you cannot propose fixes.\n\n## When to Use\n\nUse for ANY technical issue:\n- Test failures\n- Bugs in production\n- Unexpected behavior\n- Performance problems\n- Build failures\n- Integration issues\n\n**Use this ESPECIALLY when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- You've already tried multiple fixes\n- Previous fix didn't work\n- You don't fully understand the issue\n\n**Don't skip when:**\n- Issue seems simple (simple bugs have root causes too)\n- You're in a hurry (rushing guarantees rework)\n- Manager wants it fixed NOW (systematic is faster than thrashing)\n\n## The Four Phases\n\nYou MUST complete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**BEFORE attempting ANY fix:**\n\n1. **Read Error Messages Carefully**\n   - Don't skip past errors or warnings\n   - They often contain the exact solution\n   - Read stack traces completely\n   - Note line numbers, file paths, error codes\n\n2. **Reproduce Consistently**\n   - Can you trigger it reliably?\n   - What are the exact steps?\n   - Does it happen every time?\n   - If not reproducible -> gather more data, don't guess\n\n3. **Check Recent Changes**\n   - What changed that could cause this?\n   - Git diff, recent commits\n   - New dependencies, config changes\n   - Environmental differences\n\n4. **Gather Evidence in Multi-Component Systems**\n\n   **WHEN system has multiple components (CI -> build -> signing, API -> service -> database):**\n\n   **BEFORE proposing fixes, add diagnostic instrumentation:**\n   ```\n   For EACH component boundary:\n     - Log what data enters component\n     - Log what data exits component\n     - Verify environment/config propagation\n     - Check state at each layer\n\n   Run once to gather evidence showing WHERE it breaks\n   THEN analyze evidence to identify failing component\n   THEN investigate that specific component\n   ```\n\n   **Example (multi-layer system):**\n   ```bash\n   # Layer 1: Workflow\n   echo \"=== Secrets available in workflow: ===\"\n   echo \"IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}\"\n\n   # Layer 2: Build script\n   echo \"=== Env vars in build script: ===\"\n   env | grep IDENTITY || echo \"IDENTITY not in environment\"\n\n   # Layer 3: Signing script\n   echo \"=== Keychain state: ===\"\n   security list-keychains\n   security find-identity -v\n\n   # Layer 4: Actual signing\n   codesign --sign \"$IDENTITY\" --verbose=4 \"$APP\"\n   ```\n\n   **This reveals:** Which layer fails (secrets -> workflow, workflow -> build)\n\n5. **Trace Data Flow**\n\n   **WHEN error is deep in call stack:**\n\n   See `root-cause-tracing.md` in this directory for the complete backward tracing technique.\n\n   **Quick version:**\n   - Where does bad value originate?\n   - What called this with bad value?\n   - Keep tracing up until you find the source\n   - Fix at source, not at symptom\n\n### Phase 2: Pattern Analysis\n\n**Find the pattern before fixing:**\n\n1. **Find Working Examples**\n   - Locate similar working code in same codebase\n   - What works that's similar to what's broken?\n\n2. **Compare Against References**\n   - If implementing pattern, read reference implementation COMPLETELY\n   - Don't skim - read every line\n   - Understand the pattern fully before applying\n\n3. **Identify Differences**\n   - What's different between working and broken?\n   - List every difference, however small\n   - Don't assume \"that can't matter\"\n\n4. **Understand Dependencies**\n   - What other components does this need?\n   - What settings, config, environment?\n   - What assumptions does it make?\n\n### Phase 3: Hypothesis and Testing\n\n**Scientific method:**\n\n1. **Form Single Hypothesis**\n   - State clearly: \"I think X is the root cause because Y\"\n   - Write it down\n   - Be specific, not vague\n\n2. **Test Minimally (Read-Only)**\n   - Use read-only checks to verify hypothesis\n   - Can run tests, add logging, inspect state\n   - CANNOT modify source files to test fixes\n   - One hypothesis at a time\n\n3. **Verify Before Continuing**\n   - Root cause confirmed? Yes -> Phase 4 (Document Findings)\n   - Hypothesis disproven? Form NEW hypothesis\n   - DON'T propose fixes yet - keep investigating\n\n4. **When You Don't Know**\n   - Say \"I don't understand X\"\n   - Don't pretend to know\n   - Ask for help\n   - Research more\n\n### Phase 4: Document Findings\n\n**When root cause is found, document and return:**\n\n1. **Create Diagnostic Report**\n\n   Document with:\n   - **Root Cause:** Clear explanation of what's wrong and why\n   - **Approach:** Proposed fix strategy (without implementing)\n   - **Success Criteria:** How to verify the fix worked\n\n2. **Confirm Documentation**\n   - Root cause is clearly explained\n   - Approach is actionable for implementation phase\n   - Success criteria are testable\n\n3. **Return Report**\n   ```\n   Root cause documented.\n   Proposed fix approach documented.\n   DO NOT IMPLEMENT - fixes happen in implementation phase.\n   ```\n\n4. **If 3+ Hypotheses Failed: Question Architecture**\n\n   **Pattern indicating architectural problem:**\n   - Each hypothesis reveals new shared state/coupling/problem in different place\n   - Proposed fixes would require \"massive refactoring\" to implement\n   - Each investigation path creates new questions elsewhere\n\n   **STOP and question fundamentals:**\n   - Is this pattern fundamentally sound?\n   - Are we \"sticking with it through sheer inertia\"?\n   - Should we refactor architecture vs. continue investigating symptoms?\n\n   **Report architectural concerns in the diagnostic report.**\n\n   This is NOT a failed investigation - this may be a wrong architecture.\n\n## Red Flags - STOP and Follow Process\n\nIf you catch yourself thinking:\n- \"Quick fix for now, investigate later\"\n- \"Just try changing X and see if it works\"\n- \"Add multiple changes, run tests\"\n- \"Skip the test, I'll manually verify\"\n- \"It's probably X, let me fix that\"\n- \"I don't fully understand but this might work\"\n- \"Pattern says X but I'll adapt it differently\"\n- \"Here are the main problems: [lists fixes without investigation]\"\n- Proposing solutions before tracing data flow\n- **\"One more fix attempt\" (when already tried 2+)**\n- **Each fix reveals new problem in different place**\n\n**ALL of these mean: STOP. Return to Phase 1.**\n\n**If 3+ hypotheses failed:** Question the architecture (see Phase 4, step 4)\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"Issue is simple, don't need process\" | Simple issues have root causes too. Process is fast for simple bugs. |\n| \"Emergency, no time for process\" | Systematic debugging is FASTER than guess-and-check thrashing. |\n| \"Just try this first, then investigate\" | First fix sets the pattern. Do it right from the start. |\n| \"I'll write test after confirming fix works\" | Untested fixes don't stick. Test first proves it. |\n| \"Multiple fixes at once saves time\" | Can't isolate what worked. Causes new bugs. |\n| \"Reference too long, I'll adapt the pattern\" | Partial understanding guarantees bugs. Read it completely. |\n| \"I see the problem, let me fix it\" | Seeing symptoms != understanding root cause. |\n| \"One more fix attempt\" (after 2+ failures) | 3+ failures = architectural problem. Question pattern, don't fix again. |\n\n## Quick Reference\n\n| Phase | Key Activities | Success Criteria |\n|-------|---------------|------------------|\n| **1. Root Cause** | Read errors, reproduce, check changes, gather evidence | Understand WHAT and WHY |\n| **2. Pattern** | Find working examples, compare | Identify differences |\n| **3. Hypothesis** | Form theory, test minimally | Confirmed or new hypothesis |\n| **4. Document** | Create diagnostic report | Root cause and approach documented |\n\n## When Process Reveals \"No Root Cause\"\n\nIf systematic investigation reveals issue is truly environmental, timing-dependent, or external:\n\n1. You've completed the investigation\n2. Document what you investigated\n3. Document recommended handling approach (retry, timeout, error message)\n4. Document recommended monitoring/logging for future investigation\n5. Return report with documented findings\n\n**But:** 95% of \"no root cause\" cases are incomplete investigation.\n\n---\n\n## Supporting Techniques\n\nThese techniques are part of systematic debugging and available in this directory:\n\n- **`root-cause-tracing.md`** - Trace bugs backward through call stack to find original trigger\n- **`defense-in-depth.md`** - Add validation at multiple layers after finding root cause\n- **`condition-based-waiting.md`** - Replace arbitrary timeouts with condition polling\n\n## Real-World Impact\n\nFrom debugging sessions:\n- Systematic approach: 15-30 minutes to fix\n- Random fixes approach: 2-3 hours of thrashing\n- First-time fix rate: 95% vs 40%\n- New bugs introduced: Near zero vs common\n\n## Diagram Opportunities\n\n**Diagrams are cheap. When in doubt, make one.**\n\n### When to Create a Diagram\n\nCHECK these triggers as you work:\n\n| Trigger | Diagram Type |\n|---------|--------------|\n| Discussing 3+ interacting components | Architecture diagram |\n| Explaining data flow | Sequence or flowchart |\n| Describing state transitions | State diagram |\n| Showing dependencies | Dependency graph |\n| Tracing execution path | Sequence diagram |\n| Debugging complex flow | Flowchart with decision points |\n\n### How to Create\n\n```\ncwd = getCurrentWorkingDirectory()\nsession = getCurrentSession()\n\nmcp__mermaid__create_diagram({\n  project: cwd,\n  session: session,\n  name: \"<descriptive-name>\",\n  content: \"<mermaid-syntax>\"\n})\n```\n\n### Example Triggers for This Skill\n\n**WHEN tracing bug through multiple components:**\n- CREATE sequence diagram showing bug propagation\n\n**WHEN analyzing state that leads to bug:**\n- CREATE state diagram showing transitions\n\n**WHEN documenting root cause:**\n- CREATE flowchart showing decision path to bug\n",
        "agents/systematic-debugging/condition-based-waiting.md": "# Condition-Based Waiting\n\n## Overview\n\nFlaky tests often guess at timing with arbitrary delays. This creates race conditions where tests pass on fast machines but fail under load or in CI.\n\n**Core principle:** Wait for the actual condition you care about, not a guess about how long it takes.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Test uses setTimeout/sleep?\" [shape=diamond];\n    \"Testing timing behavior?\" [shape=diamond];\n    \"Document WHY timeout needed\" [shape=box];\n    \"Use condition-based waiting\" [shape=box];\n\n    \"Test uses setTimeout/sleep?\" -> \"Testing timing behavior?\" [label=\"yes\"];\n    \"Testing timing behavior?\" -> \"Document WHY timeout needed\" [label=\"yes\"];\n    \"Testing timing behavior?\" -> \"Use condition-based waiting\" [label=\"no\"];\n}\n```\n\n**Use when:**\n- Tests have arbitrary delays (`setTimeout`, `sleep`, `time.sleep()`)\n- Tests are flaky (pass sometimes, fail under load)\n- Tests timeout when run in parallel\n- Waiting for async operations to complete\n\n**Don't use when:**\n- Testing actual timing behavior (debounce, throttle intervals)\n- Always document WHY if using arbitrary timeout\n\n## Core Pattern\n\n```typescript\n// BEFORE: Guessing at timing\nawait new Promise(r => setTimeout(r, 50));\nconst result = getResult();\nexpect(result).toBeDefined();\n\n// AFTER: Waiting for condition\nawait waitFor(() => getResult() !== undefined);\nconst result = getResult();\nexpect(result).toBeDefined();\n```\n\n## Quick Patterns\n\n| Scenario | Pattern |\n|----------|---------|\n| Wait for event | `waitFor(() => events.find(e => e.type === 'DONE'))` |\n| Wait for state | `waitFor(() => machine.state === 'ready')` |\n| Wait for count | `waitFor(() => items.length >= 5)` |\n| Wait for file | `waitFor(() => fs.existsSync(path))` |\n| Complex condition | `waitFor(() => obj.ready && obj.value > 10)` |\n\n## Implementation\n\nGeneric polling function:\n```typescript\nasync function waitFor<T>(\n  condition: () => T | undefined | null | false,\n  description: string,\n  timeoutMs = 5000\n): Promise<T> {\n  const startTime = Date.now();\n\n  while (true) {\n    const result = condition();\n    if (result) return result;\n\n    if (Date.now() - startTime > timeoutMs) {\n      throw new Error(`Timeout waiting for ${description} after ${timeoutMs}ms`);\n    }\n\n    await new Promise(r => setTimeout(r, 10)); // Poll every 10ms\n  }\n}\n```\n\nSee `condition-based-waiting-example.ts` in this directory for complete implementation with domain-specific helpers (`waitForEvent`, `waitForEventCount`, `waitForEventMatch`) from actual debugging session.\n\n## Common Mistakes\n\n**Polling too fast:** `setTimeout(check, 1)` - wastes CPU\n**Fix:** Poll every 10ms\n\n**No timeout:** Loop forever if condition never met\n**Fix:** Always include timeout with clear error\n\n**Stale data:** Cache state before loop\n**Fix:** Call getter inside loop for fresh data\n\n## When Arbitrary Timeout IS Correct\n\n```typescript\n// Tool ticks every 100ms - need 2 ticks to verify partial output\nawait waitForEvent(manager, 'TOOL_STARTED'); // First: wait for condition\nawait new Promise(r => setTimeout(r, 200));   // Then: wait for timed behavior\n// 200ms = 2 ticks at 100ms intervals - documented and justified\n```\n\n**Requirements:**\n1. First wait for triggering condition\n2. Based on known timing (not guessing)\n3. Comment explaining WHY\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- Fixed 15 flaky tests across 3 files\n- Pass rate: 60% -> 100%\n- Execution time: 40% faster\n- No more race conditions\n",
        "agents/systematic-debugging/defense-in-depth.md": "# Defense-in-Depth Validation\n\n## Overview\n\nWhen you fix a bug caused by invalid data, adding validation at one place feels sufficient. But that single check can be bypassed by different code paths, refactoring, or mocks.\n\n**Core principle:** Validate at EVERY layer data passes through. Make the bug structurally impossible.\n\n## Why Multiple Layers\n\nSingle validation: \"We fixed the bug\"\nMultiple layers: \"We made the bug impossible\"\n\nDifferent layers catch different cases:\n- Entry validation catches most bugs\n- Business logic catches edge cases\n- Environment guards prevent context-specific dangers\n- Debug logging helps when other layers fail\n\n## The Four Layers\n\n### Layer 1: Entry Point Validation\n**Purpose:** Reject obviously invalid input at API boundary\n\n```typescript\nfunction createProject(name: string, workingDirectory: string) {\n  if (!workingDirectory || workingDirectory.trim() === '') {\n    throw new Error('workingDirectory cannot be empty');\n  }\n  if (!existsSync(workingDirectory)) {\n    throw new Error(`workingDirectory does not exist: ${workingDirectory}`);\n  }\n  if (!statSync(workingDirectory).isDirectory()) {\n    throw new Error(`workingDirectory is not a directory: ${workingDirectory}`);\n  }\n  // ... proceed\n}\n```\n\n### Layer 2: Business Logic Validation\n**Purpose:** Ensure data makes sense for this operation\n\n```typescript\nfunction initializeWorkspace(projectDir: string, sessionId: string) {\n  if (!projectDir) {\n    throw new Error('projectDir required for workspace initialization');\n  }\n  // ... proceed\n}\n```\n\n### Layer 3: Environment Guards\n**Purpose:** Prevent dangerous operations in specific contexts\n\n```typescript\nasync function gitInit(directory: string) {\n  // In tests, refuse git init outside temp directories\n  if (process.env.NODE_ENV === 'test') {\n    const normalized = normalize(resolve(directory));\n    const tmpDir = normalize(resolve(tmpdir()));\n\n    if (!normalized.startsWith(tmpDir)) {\n      throw new Error(\n        `Refusing git init outside temp dir during tests: ${directory}`\n      );\n    }\n  }\n  // ... proceed\n}\n```\n\n### Layer 4: Debug Instrumentation\n**Purpose:** Capture context for forensics\n\n```typescript\nasync function gitInit(directory: string) {\n  const stack = new Error().stack;\n  logger.debug('About to git init', {\n    directory,\n    cwd: process.cwd(),\n    stack,\n  });\n  // ... proceed\n}\n```\n\n## Applying the Pattern\n\nWhen you find a bug:\n\n1. **Trace the data flow** - Where does bad value originate? Where used?\n2. **Map all checkpoints** - List every point data passes through\n3. **Add validation at each layer** - Entry, business, environment, debug\n4. **Test each layer** - Try to bypass layer 1, verify layer 2 catches it\n\n## Example from Session\n\nBug: Empty `projectDir` caused `git init` in source code\n\n**Data flow:**\n1. Test setup -> empty string\n2. `Project.create(name, '')`\n3. `WorkspaceManager.createWorkspace('')`\n4. `git init` runs in `process.cwd()`\n\n**Four layers added:**\n- Layer 1: `Project.create()` validates not empty/exists/writable\n- Layer 2: `WorkspaceManager` validates projectDir not empty\n- Layer 3: `WorktreeManager` refuses git init outside tmpdir in tests\n- Layer 4: Stack trace logging before git init\n\n**Result:** All 1847 tests passed, bug impossible to reproduce\n\n## Key Insight\n\nAll four layers were necessary. During testing, each layer caught bugs the others missed:\n- Different code paths bypassed entry validation\n- Mocks bypassed business logic checks\n- Edge cases on different platforms needed environment guards\n- Debug logging identified structural misuse\n\n**Don't stop at one validation point.** Add checks at every layer.\n",
        "agents/systematic-debugging/root-cause-tracing.md": "# Root Cause Tracing\n\n## Overview\n\nBugs often manifest deep in the call stack (git init in wrong directory, file created in wrong location, database opened with wrong path). Your instinct is to fix where the error appears, but that's treating a symptom.\n\n**Core principle:** Trace backward through the call chain until you find the original trigger, then fix at the source.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Bug appears deep in stack?\" [shape=diamond];\n    \"Can trace backwards?\" [shape=diamond];\n    \"Fix at symptom point\" [shape=box];\n    \"Trace to original trigger\" [shape=box];\n    \"BETTER: Also add defense-in-depth\" [shape=box];\n\n    \"Bug appears deep in stack?\" -> \"Can trace backwards?\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Trace to original trigger\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Fix at symptom point\" [label=\"no - dead end\"];\n    \"Trace to original trigger\" -> \"BETTER: Also add defense-in-depth\";\n}\n```\n\n**Use when:**\n- Error happens deep in execution (not at entry point)\n- Stack trace shows long call chain\n- Unclear where invalid data originated\n- Need to find which test/code triggers the problem\n\n## The Tracing Process\n\n### 1. Observe the Symptom\n```\nError: git init failed in /Users/jesse/project/packages/core\n```\n\n### 2. Find Immediate Cause\n**What code directly causes this?**\n```typescript\nawait execFileAsync('git', ['init'], { cwd: projectDir });\n```\n\n### 3. Ask: What Called This?\n```typescript\nWorktreeManager.createSessionWorktree(projectDir, sessionId)\n  -> called by Session.initializeWorkspace()\n  -> called by Session.create()\n  -> called by test at Project.create()\n```\n\n### 4. Keep Tracing Up\n**What value was passed?**\n- `projectDir = ''` (empty string!)\n- Empty string as `cwd` resolves to `process.cwd()`\n- That's the source code directory!\n\n### 5. Find Original Trigger\n**Where did empty string come from?**\n```typescript\nconst context = setupCoreTest(); // Returns { tempDir: '' }\nProject.create('name', context.tempDir); // Accessed before beforeEach!\n```\n\n## Adding Stack Traces\n\nWhen you can't trace manually, add instrumentation:\n\n```typescript\n// Before the problematic operation\nasync function gitInit(directory: string) {\n  const stack = new Error().stack;\n  console.error('DEBUG git init:', {\n    directory,\n    cwd: process.cwd(),\n    nodeEnv: process.env.NODE_ENV,\n    stack,\n  });\n\n  await execFileAsync('git', ['init'], { cwd: directory });\n}\n```\n\n**Critical:** Use `console.error()` in tests (not logger - may not show)\n\n**Run and capture:**\n```bash\nnpm test 2>&1 | grep 'DEBUG git init'\n```\n\n**Analyze stack traces:**\n- Look for test file names\n- Find the line number triggering the call\n- Identify the pattern (same test? same parameter?)\n\n## Finding Which Test Causes Pollution\n\nIf something appears during tests but you don't know which test:\n\nUse the bisection script `find-polluter.sh` in this directory:\n\n```bash\n./find-polluter.sh '.git' 'src/**/*.test.ts'\n```\n\nRuns tests one-by-one, stops at first polluter. See script for usage.\n\n## Real Example: Empty projectDir\n\n**Symptom:** `.git` created in `packages/core/` (source code)\n\n**Trace chain:**\n1. `git init` runs in `process.cwd()` <- empty cwd parameter\n2. WorktreeManager called with empty projectDir\n3. Session.create() passed empty string\n4. Test accessed `context.tempDir` before beforeEach\n5. setupCoreTest() returns `{ tempDir: '' }` initially\n\n**Root cause:** Top-level variable initialization accessing empty value\n\n**Fix:** Made tempDir a getter that throws if accessed before beforeEach\n\n**Also added defense-in-depth:**\n- Layer 1: Project.create() validates directory\n- Layer 2: WorkspaceManager validates not empty\n- Layer 3: NODE_ENV guard refuses git init outside tmpdir\n- Layer 4: Stack trace logging before git init\n\n## Key Principle\n\n```dot\ndigraph principle {\n    \"Found immediate cause\" [shape=ellipse];\n    \"Can trace one level up?\" [shape=diamond];\n    \"Trace backwards\" [shape=box];\n    \"Is this the source?\" [shape=diamond];\n    \"Fix at source\" [shape=box];\n    \"Add validation at each layer\" [shape=box];\n    \"Bug impossible\" [shape=doublecircle];\n    \"NEVER fix just the symptom\" [shape=octagon, style=filled, fillcolor=red, fontcolor=white];\n\n    \"Found immediate cause\" -> \"Can trace one level up?\";\n    \"Can trace one level up?\" -> \"Trace backwards\" [label=\"yes\"];\n    \"Can trace one level up?\" -> \"NEVER fix just the symptom\" [label=\"no\"];\n    \"Trace backwards\" -> \"Is this the source?\";\n    \"Is this the source?\" -> \"Trace backwards\" [label=\"no - keeps going\"];\n    \"Is this the source?\" -> \"Fix at source\" [label=\"yes\"];\n    \"Fix at source\" -> \"Add validation at each layer\";\n    \"Add validation at each layer\" -> \"Bug impossible\";\n}\n```\n\n**NEVER fix just where the error appears.** Trace back to find the original trigger.\n\n## Stack Trace Tips\n\n**In tests:** Use `console.error()` not logger - logger may be suppressed\n**Before operation:** Log before the dangerous operation, not after it fails\n**Include context:** Directory, cwd, environment variables, timestamps\n**Capture stack:** `new Error().stack` shows complete call chain\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- Found root cause through 5-level trace\n- Fixed at source (getter validation)\n- Added 4 layers of defense\n- 1847 tests passed, zero pollution\n",
        "agents/using-git-worktrees/AGENT.md": "---\nname: using-git-worktrees\ndescription: Creates isolated git worktrees for feature work\n---\n\n# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n## Directory Selection Process\n\nFollow this priority order:\n\n### 1. Check Existing Directories\n\n```bash\n# Check in priority order\nls -d .worktrees 2>/dev/null     # Preferred (hidden)\nls -d worktrees 2>/dev/null      # Alternative\n```\n\n**If found:** Use that directory. If both exist, `.worktrees` wins.\n\n### 2. Check CLAUDE.md\n\n```bash\ngrep -i \"worktree.*director\" CLAUDE.md 2>/dev/null\n```\n\n**If preference specified:** Use it without asking.\n\n### 3. Ask User\n\nIf no directory exists and no CLAUDE.md preference:\n\n```\nNo worktree directory found. Where should I create worktrees?\n\n1. .worktrees/ (project-local, hidden)\n2. ~/.config/superpowers/worktrees/<project-name>/ (global location)\n\nWhich would you prefer?\n```\n\n## Safety Verification\n\n### For Project-Local Directories (.worktrees or worktrees)\n\n**MUST verify directory is ignored before creating worktree:**\n\n```bash\n# Check if directory is ignored (respects local, global, and system gitignore)\ngit check-ignore -q .worktrees 2>/dev/null || git check-ignore -q worktrees 2>/dev/null\n```\n\n**If NOT ignored:**\n\nPer \"Fix broken things immediately\":\n1. Add appropriate line to .gitignore\n2. Commit the change\n3. Proceed with worktree creation\n\n**Why critical:** Prevents accidentally committing worktree contents to repository.\n\n### For Global Directory (~/.config/superpowers/worktrees)\n\nNo .gitignore verification needed - outside project entirely.\n\n## Creation Steps\n\n### 1. Detect Project Name\n\n```bash\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n```\n\n### 2. Create Worktree\n\n```bash\n# Determine full path\ncase $LOCATION in\n  .worktrees|worktrees)\n    path=\"$LOCATION/$BRANCH_NAME\"\n    ;;\n  ~/.config/superpowers/worktrees/*)\n    path=\"~/.config/superpowers/worktrees/$project/$BRANCH_NAME\"\n    ;;\nesac\n\n# Create worktree with new branch\ngit worktree add \"$path\" -b \"$BRANCH_NAME\"\ncd \"$path\"\n```\n\n### 3. Run Project Setup\n\nAuto-detect and run appropriate setup:\n\n```bash\n# Node.js\nif [ -f package.json ]; then npm install; fi\n\n# Rust\nif [ -f Cargo.toml ]; then cargo build; fi\n\n# Python\nif [ -f requirements.txt ]; then pip install -r requirements.txt; fi\nif [ -f pyproject.toml ]; then poetry install; fi\n\n# Go\nif [ -f go.mod ]; then go mod download; fi\n```\n\n### 4. Verify Clean Baseline\n\nRun tests to ensure worktree starts clean:\n\n```bash\n# Examples - use project-appropriate command\nnpm test\ncargo test\npytest\ngo test ./...\n```\n\n**If tests fail:** Report failures, ask whether to proceed or investigate.\n\n**If tests pass:** Report ready.\n\n### 5. Report Location\n\n```\nWorktree ready at <full-path>\nTests passing (<N> tests, 0 failures)\nReady to implement <feature-name>\n```\n\n## Quick Reference\n\n| Situation | Action |\n|-----------|--------|\n| `.worktrees/` exists | Use it (verify ignored) |\n| `worktrees/` exists | Use it (verify ignored) |\n| Both exist | Use `.worktrees/` |\n| Neither exists | Check CLAUDE.md -> Ask user |\n| Directory not ignored | Add to .gitignore + commit |\n| Tests fail during baseline | Report failures + ask |\n| No package.json/Cargo.toml | Skip dependency install |\n\n## Common Mistakes\n\n### Skipping ignore verification\n\n- **Problem:** Worktree contents get tracked, pollute git status\n- **Fix:** Always use `git check-ignore` before creating project-local worktree\n\n### Assuming directory location\n\n- **Problem:** Creates inconsistency, violates project conventions\n- **Fix:** Follow priority: existing > CLAUDE.md > ask\n\n### Proceeding with failing tests\n\n- **Problem:** Can't distinguish new bugs from pre-existing issues\n- **Fix:** Report failures, get explicit permission to proceed\n\n### Hardcoding setup commands\n\n- **Problem:** Breaks on projects using different tools\n- **Fix:** Auto-detect from project files (package.json, etc.)\n\n## Example Workflow\n\n```\n[Check .worktrees/ - exists]\n[Verify ignored - git check-ignore confirms .worktrees/ is ignored]\n[Create worktree: git worktree add .worktrees/auth -b feature/auth]\n[Run npm install]\n[Run npm test - 47 passing]\n\nWorktree ready at /Users/user/myproject/.worktrees/auth\nTests passing (47 tests, 0 failures)\nReady to implement auth feature\n```\n\n## Red Flags\n\n**Never:**\n- Create worktree without verifying it's ignored (project-local)\n- Skip baseline test verification\n- Proceed with failing tests without asking\n- Assume directory location when ambiguous\n- Skip CLAUDE.md check\n\n**Always:**\n- Follow directory priority: existing > CLAUDE.md > ask\n- Verify directory is ignored for project-local\n- Auto-detect and run project setup\n- Verify clean test baseline\n\n## Integration\n\n**Pairs with:**\n- **finishing-a-development-branch** - REQUIRED for cleanup after work complete\n- **executing-plans** or **subagent-driven-development** - Work happens in this worktree\n",
        "agents/verification-before-completion/AGENT.md": "---\nname: verification-before-completion\ndescription: Runs verification commands before claiming work is complete\n---\n\n# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confidence != evidence |\n| \"Just this once\" | No exceptions |\n| \"Linter passed\" | Linter != compiler |\n| \"Agent said success\" | Verify independently |\n| \"I'm tired\" | Exhaustion != excuse |\n| \"Partial check is enough\" | Partial proves nothing |\n| \"Different words so rule doesn't apply\" | Spirit over letter |\n\n## Key Patterns\n\n**Tests:**\n```\n[Run test command] [See: 34/34 pass] \"All tests pass\"\n[X] \"Should pass now\" / \"Looks correct\"\n```\n\n**Regression tests (TDD Red-Green):**\n```\nWrite -> Run (pass) -> Revert fix -> Run (MUST FAIL) -> Restore -> Run (pass)\n[X] \"I've written a regression test\" (without red-green verification)\n```\n\n**Build:**\n```\n[Run build] [See: exit 0] \"Build passes\"\n[X] \"Linter passed\" (linter doesn't check compilation)\n```\n\n**Requirements:**\n```\nRe-read plan -> Create checklist -> Verify each -> Report gaps or completion\n[X] \"Tests pass, phase complete\"\n```\n\n**Agent delegation:**\n```\nAgent reports success -> Check VCS diff -> Verify changes -> Report actual state\n[X] Trust agent report\n```\n\n## Why This Matters\n\nFrom failure memories:\n- \"I don't believe you\" - trust broken\n- Undefined functions shipped - would crash\n- Missing requirements shipped - incomplete features\n- Time wasted on false completion -> redirect -> rework\n- Violates: \"Honesty is a core value. If you lie, you'll be replaced.\"\n\n## When To Apply\n\n**ALWAYS before:**\n- ANY variation of success/completion claims\n- ANY expression of satisfaction\n- ANY positive statement about work state\n- Committing, PR creation, task completion\n- Moving to next task\n- Delegating to agents\n\n**Rule applies to:**\n- Exact phrases\n- Paraphrases and synonyms\n- Implications of success\n- ANY communication suggesting completion/correctness\n\n## The Bottom Line\n\n**No shortcuts for verification.**\n\nRun the command. Read the output. THEN claim the result.\n\nThis is non-negotiable.\n",
        "agents/verify-phase/AGENT.md": "---\nname: verify-phase\ndescription: Verifies rough-draft phase output aligns with design document\n---\n\n# Verify Phase\n\n## Overview\n\nChecks if rough-draft output aligns with original design. Called after each rough-draft phase (INTERFACE, PSEUDOCODE, SKELETON).\n\n**Core principle:** Detect drift early before implementation diverges from design.\n\n## When to Use\n\nUse this agent when:\n- Completing a rough-draft phase (INTERFACE, PSEUDOCODE, or SKELETON)\n- You want to verify phase output matches the original design decisions\n- Before transitioning between rough-draft phases\n\n## When NOT to Use\n\nDo NOT use this agent when:\n- No design document exists yet (use brainstorming first)\n- In implementation phase (design is already finalized)\n- No rough-draft output to verify\n\n## Behavior\n\n1. Read current phase output\n2. Read design document\n3. Evaluate alignment\n4. If aligned: proceed\n5. If drift detected:\n   - Present what changed, pros/cons, suggestion\n   - Ask user: Accept (return to brainstorm), Reject (redo), or Partial\n6. Handle user choice\n\n## Implementation\n\nCalled after each phase with:\n- `currentPhase`: INTERFACE | PSEUDOCODE | SKELETON\n- `phaseOutput`: content produced\n\n### Step 1: Get Design Document\n\nUse the MCP tool to get the design document:\n\n```\nTool: mcp__mermaid__get_document\nArgs: { \"project\": \"<project-path>\", \"session\": \"<session-name>\", \"id\": \"design\" }\n```\n\nOr read from filesystem:\n\n```bash\ncat .collab/<session-name>/documents/design.md\n```\n\n### Step 2: Construct Comparison Prompt\n\nBuild a prompt to evaluate alignment:\n\n```\nCompare the following {currentPhase} output against the design document.\n\nDesign Document:\n{design_doc_content}\n\n{currentPhase} Output:\n{phaseOutput}\n\nQuestions:\n1. Does this align with the design decisions?\n2. Are there any additions not in the original design?\n3. Are there any omissions from the design?\n\nIf aligned, respond: ALIGNED\nIf drift detected, respond with:\nDRIFT DETECTED\nWhat changed: [list]\nPros: [list]\nCons: [list]\nSuggestion: [recommendation]\n```\n\n### Step 3: Evaluate Response\n\n**If ALIGNED:**\n\n```\n[checkmark] {currentPhase} phase aligned with design\n\nContinuing to next phase...\n```\n\nReturn: `{ aligned: true }`\n\n### Step 4: Handle Drift\n\n**If DRIFT DETECTED:**\n\nParse the drift details and present to user:\n\n```\n[warning] Drift detected in {currentPhase} phase\n\n**What changed:**\n- [Change 1]\n- [Change 2]\n- [Change N]\n\n**Pros of accepting:**\n- [Pro 1]\n- [Pro 2]\n\n**Cons of accepting:**\n- [Con 1]\n- [Con 2]\n\n**Suggestion:** [recommendation]\n```\n\n### Step 5: Ask User Decision\n\nPresent options:\n\n```\nHow would you like to handle this drift?\n\n1. Accept - return to brainstorming to update design\n2. Reject - redo this phase\n3. Partial - specify what to keep\n```\n\n**Option descriptions:**\n- **1 (Accept)**: Updates design doc with the drift, sets state.phase = \"brainstorming\", returns to design phase to formalize changes\n- **2 (Reject)**: Discards the phase output, returns signal to redo the phase, implementation must match original design\n- **3 (Partial)**: Asks user what to keep/discard, allows selective acceptance of changes\n\n### Step 6: Execute User Choice\n\n**On Accept:**\n\n```\n// Update state to brainstorming via MCP\nTool: mcp__mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session-name>\",\n  \"phase\": \"brainstorming\",\n  \"lastAction\": {\n    \"type\": \"drift_accepted\",\n    \"details\": drift.what_changed,\n    \"timestamp\": \"<current-ISO-timestamp>\"\n  }\n}\n// Note: lastActivity is automatically updated by the MCP tool\n```\n\nReturn: `{ aligned: false, userChoice: \"accept\" }`\n\nOutput:\n```\nReturning to brainstorming phase to update design document.\nUpdate the design to reflect the accepted changes.\n```\n\n**On Reject:**\n\nReturn: `{ aligned: false, userChoice: \"reject\" }`\n\nOutput:\n```\nRedoing {currentPhase} phase.\nThe phase output must align with the original design.\n```\n\n**On Partial:**\n\nAsk: \"What specific changes should be kept/discarded?\"\n\nReturn: `{ aligned: false, userChoice: \"partial\", spec: partial_spec }`\n\n## Drift Detection Patterns\n\nThe agent looks for these types of drift:\n\n| Type | Example |\n|------|---------|\n| **Addition** | New function not in design |\n| **Omission** | Missing required interface |\n| **Modification** | Changed function signature |\n| **Reordering** | Different dependency structure |\n| **Renaming** | Different names for same concepts |\n\n## Error Handling\n\n**No design document found:**\n```\nDesign document not found.\nCannot verify phase alignment without a design document.\nEnsure brainstorming has created the design document first.\n```\n\n**No phase output provided:**\n```\nNo phase output provided for verification.\nEnsure the rough-draft phase has produced output before calling verify-phase.\n```\n\n**Invalid phase specified:**\n```\nInvalid phase: {phase}\nValid phases are: INTERFACE, PSEUDOCODE, SKELETON\n```\n\n## Integration\n\n**Called by:**\n- **rough-draft** - After each phase completion (INTERFACE, PSEUDOCODE, SKELETON)\n\n**Transitions to:**\n- **brainstorming** - If drift is accepted (to update design)\n- **Current phase redo** - If drift is rejected\n- **Next phase** - If aligned\n\n**Related:**\n- **brainstorming** - Where design decisions are made\n- **rough-draft** - The calling process\n- **ready-to-implement** - Validates complete design before implementation\n\n**Workflow Chain:**\n```\nbrainstorming --> rough-draft [verify-phase] --> executing-plans\n                     ^             ^\n              (each phase)  (you are here)\n```\n\nThis agent acts as a checkpoint between rough-draft phases, ensuring implementation plans don't drift from the original design decisions.\n\n## Quick Reference\n\n```\nverify-phase(currentPhase, phaseOutput)\n\n1. Reads design document from session\n2. Compares phase output against design\n3. If aligned: returns success, proceed to next phase\n4. If drift: presents changes with pros/cons\n5. User chooses: 1. Accept / 2. Reject / 3. Partial\n6. Executes choice and returns signal\n```\n",
        "codex/ui/src/hooks/index.ts": "/**\n * Hooks\n * Central export for all hooks\n */\n\nexport { useTopics } from './useTopics';\nexport type { UseTopicsReturn } from './useTopics';\n\nexport { useTopic } from './useTopic';\nexport type { UseTopicReturn } from './useTopic';\n\nexport { useDrafts, useDraft } from './useDrafts';\nexport type { UseDraftsReturn, UseDraftReturn } from './useDrafts';\n\nexport { useFlags } from './useFlags';\nexport type { UseFlagsReturn } from './useFlags';\n\nexport { useMissingTopics } from './useMissingTopics';\nexport type { UseMissingTopicsReturn } from './useMissingTopics';\n",
        "codex/ui/src/hooks/useDrafts.ts": "/**\n * useDrafts Hook\n *\n * Provides access to draft data for topics.\n * Mock implementation - returns sample data for development.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport type { DraftInfo, DocumentDiff, DocumentType } from '../types';\n\n/**\n * Return type for useDrafts hook\n */\nexport interface UseDraftsReturn {\n  /** List of drafts with basic info */\n  drafts: { topicName: string; generatedAt: string }[];\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Refresh the drafts list */\n  refresh: () => Promise<void>;\n}\n\n/**\n * Return type for useDraft hook\n */\nexport interface UseDraftReturn {\n  /** Full draft information */\n  draft: DraftInfo | null;\n  /** Document diffs between current and draft */\n  diff: DocumentDiff[] | null;\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Approve the draft */\n  approve: (approvedBy: string) => Promise<void>;\n  /** Reject the draft */\n  reject: (rejectedBy: string, reason?: string) => Promise<void>;\n}\n\n/**\n * Mock draft data\n */\nconst MOCK_DRAFTS: Record<string, DraftInfo> = {\n  'docker-compose': {\n    topicName: 'docker-compose',\n    generatedAt: '2025-01-22T14:30:00Z',\n    triggerType: 'source_change',\n    documents: {\n      conceptual: `# Docker Compose\n\nDocker Compose is a tool for defining and running multi-container Docker applications.\n\n## Key Features\n\n- Define services in a single YAML file\n- Start all services with a single command\n- Manage networking between containers\n- Handle volumes and data persistence\n\n## New in Compose V2\n\n- Integrated into Docker CLI as \\`docker compose\\`\n- Improved build performance\n- Better secret management\n- Support for profiles\n`,\n      technical: `# Docker Compose Technical Reference\n\n## Basic Structure\n\n\\`\\`\\`yaml\nversion: '3.9'\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - db\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: secret\n    volumes:\n      - db-data:/var/lib/postgresql/data\n\nvolumes:\n  db-data:\n\\`\\`\\`\n\n## Common Commands\n\n\\`\\`\\`bash\ndocker compose up -d\ndocker compose down\ndocker compose logs -f\ndocker compose ps\ndocker compose exec web sh\n\\`\\`\\`\n\n## Advanced Features\n\n- **Profiles**: Group services for selective startup\n- **Secrets**: Manage sensitive data securely\n- **Extensions**: Reuse configuration fragments\n`,\n      files: `# Related Files\n\n- \\`docker-compose.yml\\` - Main compose file\n- \\`docker-compose.dev.yml\\` - Development overrides\n- \\`docker-compose.prod.yml\\` - Production overrides\n- \\`docker-compose.test.yml\\` - Test environment\n- \\`.env\\` - Environment variables\n`,\n      related: `# Related Topics\n\n- [Docker networking](/topics/docker-networking)\n- [Docker volumes](/topics/docker-volumes)\n- [Docker secrets](/topics/docker-secrets)\n- [Kubernetes](/topics/kubernetes-basics)\n`,\n    },\n  },\n  'react-context': {\n    topicName: 'react-context',\n    generatedAt: '2025-01-21T10:00:00Z',\n    triggerType: 'flag_response',\n    documents: {\n      conceptual: `# React Context\n\nReact Context provides a way to pass data through the component tree without having to pass props manually at every level.\n\n## When to Use Context\n\n- Theme data (dark/light mode)\n- User authentication state\n- Locale preferences\n- Application configuration\n\n## Best Practices\n\n- Keep context values stable\n- Split contexts by domain\n- Use context sparingly for global state\n`,\n      technical: `# React Context Technical Reference\n\n## Creating Context\n\n\\`\\`\\`typescript\ninterface ThemeContextType {\n  theme: 'light' | 'dark';\n  toggleTheme: () => void;\n}\n\nconst ThemeContext = createContext<ThemeContextType | undefined>(undefined);\n\\`\\`\\`\n\n## Provider Pattern\n\n\\`\\`\\`typescript\nexport function ThemeProvider({ children }: { children: React.ReactNode }) {\n  const [theme, setTheme] = useState<'light' | 'dark'>('light');\n\n  const toggleTheme = useCallback(() => {\n    setTheme(t => t === 'light' ? 'dark' : 'light');\n  }, []);\n\n  return (\n    <ThemeContext.Provider value={{ theme, toggleTheme }}>\n      {children}\n    </ThemeContext.Provider>\n  );\n}\n\\`\\`\\`\n\n## Custom Hook Pattern\n\n\\`\\`\\`typescript\nexport function useTheme() {\n  const context = useContext(ThemeContext);\n  if (!context) {\n    throw new Error('useTheme must be used within ThemeProvider');\n  }\n  return context;\n}\n\\`\\`\\`\n`,\n      files: `# Related Files\n\n- \\`src/contexts/ThemeContext.tsx\\`\n- \\`src/contexts/AuthContext.tsx\\`\n- \\`src/hooks/useTheme.ts\\`\n`,\n      related: `# Related Topics\n\n- [React Hooks](/topics/react-hooks)\n- [State Management](/topics/react-state-management)\n- [Zustand](/topics/zustand)\n`,\n    },\n  },\n};\n\n/**\n * Mock current document data (for diff calculation)\n */\nconst MOCK_CURRENT_DOCS: Record<\n  string,\n  { conceptual: string; technical: string; files: string; related: string }\n> = {\n  'docker-compose': {\n    conceptual: `# Docker Compose\n\nDocker Compose is a tool for defining and running multi-container Docker applications.\n\n## Key Features\n\n- Define services in a single YAML file\n- Start all services with a single command\n- Manage networking between containers\n- Handle volumes and data persistence\n`,\n    technical: `# Docker Compose Technical Reference\n\n## Basic Structure\n\n\\`\\`\\`yaml\nversion: '3.8'\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n  db:\n    image: postgres:14\n    environment:\n      POSTGRES_PASSWORD: secret\n\\`\\`\\`\n\n## Common Commands\n\n\\`\\`\\`bash\ndocker-compose up -d\ndocker-compose down\ndocker-compose logs -f\n\\`\\`\\`\n`,\n    files: `# Related Files\n\n- \\`docker-compose.yml\\` - Main compose file\n- \\`docker-compose.dev.yml\\` - Development overrides\n- \\`docker-compose.prod.yml\\` - Production overrides\n`,\n    related: `# Related Topics\n\n- [Docker networking](/topics/docker-networking)\n- [Docker volumes](/topics/docker-volumes)\n- [Kubernetes](/topics/kubernetes-basics)\n`,\n  },\n};\n\n/**\n * Calculate simple line-based diff statistics\n */\nfunction calculateDiffStats(\n  current: string,\n  draft: string\n): { additions: number; deletions: number } {\n  const currentLines = current.split('\\n');\n  const draftLines = draft.split('\\n');\n\n  // Simple heuristic: count lines only in draft as additions,\n  // lines only in current as deletions\n  const currentSet = new Set(currentLines.map((l) => l.trim()));\n  const draftSet = new Set(draftLines.map((l) => l.trim()));\n\n  let additions = 0;\n  let deletions = 0;\n\n  for (const line of draftLines) {\n    if (line.trim() && !currentSet.has(line.trim())) {\n      additions++;\n    }\n  }\n\n  for (const line of currentLines) {\n    if (line.trim() && !draftSet.has(line.trim())) {\n      deletions++;\n    }\n  }\n\n  return { additions, deletions };\n}\n\n/**\n * Hook for fetching list of all drafts\n *\n * @returns List of drafts with loading/error states\n *\n * @example\n * ```tsx\n * function DraftsList() {\n *   const { drafts, isLoading, error, refresh } = useDrafts();\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *\n *   return (\n *     <ul>\n *       {drafts.map(d => <li key={d.topicName}>{d.topicName}</li>)}\n *     </ul>\n *   );\n * }\n * ```\n */\nexport function useDrafts(): UseDraftsReturn {\n  const [drafts, setDrafts] = useState<\n    { topicName: string; generatedAt: string }[]\n  >([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchDrafts = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      const draftsList = Object.values(MOCK_DRAFTS).map((d) => ({\n        topicName: d.topicName,\n        generatedAt: d.generatedAt,\n      }));\n\n      setDrafts(draftsList);\n    } catch (err) {\n      setError(\n        err instanceof Error ? err : new Error('Failed to fetch drafts')\n      );\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n\n  useEffect(() => {\n    fetchDrafts();\n  }, [fetchDrafts]);\n\n  const refresh = useCallback(async () => {\n    await fetchDrafts();\n  }, [fetchDrafts]);\n\n  return {\n    drafts,\n    isLoading,\n    error,\n    refresh,\n  };\n}\n\n/**\n * Hook for fetching a single draft with diff information\n *\n * @param topicName - The topic name to fetch draft for\n * @returns Draft data with diff and action functions\n *\n * @example\n * ```tsx\n * function DraftReview({ topicName }: { topicName: string }) {\n *   const { draft, diff, isLoading, approve, reject } = useDraft(topicName);\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (!draft) return <div>No draft found</div>;\n *\n *   return (\n *     <div>\n *       <h2>{draft.topicName}</h2>\n *       <button onClick={() => approve('john')}>Approve</button>\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useDraft(topicName: string): UseDraftReturn {\n  const [draft, setDraft] = useState<DraftInfo | null>(null);\n  const [diff, setDiff] = useState<DocumentDiff[] | null>(null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchDraft = useCallback(async () => {\n    if (!topicName) {\n      setDraft(null);\n      setDiff(null);\n      setIsLoading(false);\n      return;\n    }\n\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      const draftData = MOCK_DRAFTS[topicName];\n      if (!draftData) {\n        setDraft(null);\n        setDiff(null);\n        setIsLoading(false);\n        return;\n      }\n\n      setDraft(draftData);\n\n      // Calculate diffs\n      const currentDocs = MOCK_CURRENT_DOCS[topicName] || {\n        conceptual: '',\n        technical: '',\n        files: '',\n        related: '',\n      };\n\n      const documentTypes: DocumentType[] = [\n        'conceptual',\n        'technical',\n        'files',\n        'related',\n      ];\n      const diffs: DocumentDiff[] = documentTypes.map((docType) => {\n        const current = currentDocs[docType] || '';\n        const draftContent = draftData.documents[docType] || '';\n        const stats = calculateDiffStats(current, draftContent);\n\n        return {\n          documentType: docType,\n          current,\n          draft: draftContent,\n          additions: stats.additions,\n          deletions: stats.deletions,\n        };\n      });\n\n      setDiff(diffs);\n    } catch (err) {\n      setError(err instanceof Error ? err : new Error('Failed to fetch draft'));\n      setDraft(null);\n      setDiff(null);\n    } finally {\n      setIsLoading(false);\n    }\n  }, [topicName]);\n\n  useEffect(() => {\n    fetchDraft();\n  }, [fetchDraft]);\n\n  const approve = useCallback(\n    async (approvedBy: string) => {\n      if (!draft) return;\n\n      try {\n        // Simulate API delay\n        await new Promise((resolve) => setTimeout(resolve, 500));\n\n        console.log(`Draft for ${draft.topicName} approved by ${approvedBy}`);\n\n        // Clear the draft after approval (simulating successful merge)\n        setDraft(null);\n        setDiff(null);\n      } catch (err) {\n        setError(\n          err instanceof Error ? err : new Error('Failed to approve draft')\n        );\n      }\n    },\n    [draft]\n  );\n\n  const reject = useCallback(\n    async (rejectedBy: string, reason?: string) => {\n      if (!draft) return;\n\n      try {\n        // Simulate API delay\n        await new Promise((resolve) => setTimeout(resolve, 500));\n\n        console.log(\n          `Draft for ${draft.topicName} rejected by ${rejectedBy}`,\n          reason ? `Reason: ${reason}` : ''\n        );\n\n        // Clear the draft after rejection\n        setDraft(null);\n        setDiff(null);\n      } catch (err) {\n        setError(\n          err instanceof Error ? err : new Error('Failed to reject draft')\n        );\n      }\n    },\n    [draft]\n  );\n\n  return {\n    draft,\n    diff,\n    isLoading,\n    error,\n    approve,\n    reject,\n  };\n}\n\nexport default useDrafts;\n",
        "codex/ui/src/hooks/useFlags.ts": "/**\n * useFlags Hook\n *\n * Provides access to flags with filtering and actions.\n * Mock implementation for now - returns sample data.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport type { Flag, FlagFilters, FlagStatus } from '../types';\n\nexport interface UseFlagsReturn {\n  /** List of flags matching filters */\n  flags: Flag[];\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Resolve a flag */\n  resolve: (flagId: number, resolvedBy: string) => Promise<void>;\n  /** Dismiss a flag */\n  dismiss: (flagId: number, dismissedBy: string, reason?: string) => Promise<void>;\n  /** Reopen a flag */\n  reopen: (flagId: number, reopenedBy: string) => Promise<void>;\n  /** Refresh the flags list */\n  refresh: () => Promise<void>;\n}\n\n/**\n * Sample mock data for flags\n */\nconst MOCK_FLAGS: Flag[] = [\n  {\n    id: 1,\n    topicName: 'react-hooks',\n    comment: 'The useEffect cleanup section is incomplete and missing edge cases.',\n    status: 'open',\n    createdAt: '2025-01-22T10:30:00Z',\n  },\n  {\n    id: 2,\n    topicName: 'typescript-generics',\n    comment: 'Missing examples for conditional types and mapped types.',\n    status: 'open',\n    createdAt: '2025-01-21T14:20:00Z',\n  },\n  {\n    id: 3,\n    topicName: 'docker-compose',\n    comment: 'Volume mounting section has outdated syntax for version 3.8+',\n    status: 'addressed',\n    createdAt: '2025-01-18T09:00:00Z',\n    addressedAt: '2025-01-20T11:00:00Z',\n  },\n  {\n    id: 4,\n    topicName: 'graphql-mutations',\n    comment: 'Error handling patterns need updating for Apollo Client v4.',\n    status: 'resolved',\n    createdAt: '2025-01-15T16:45:00Z',\n    resolvedAt: '2025-01-19T10:30:00Z',\n  },\n  {\n    id: 5,\n    topicName: 'kubernetes-pods',\n    comment: 'Pod security context section is missing important security settings.',\n    status: 'dismissed',\n    createdAt: '2025-01-10T12:00:00Z',\n    dismissedReason: 'Covered in separate security-contexts topic.',\n  },\n  {\n    id: 6,\n    topicName: 'redis-caching',\n    comment: 'Cache invalidation strategies section is too brief.',\n    status: 'open',\n    createdAt: '2025-01-20T08:15:00Z',\n  },\n];\n\n/**\n * Apply filters to flags\n */\nfunction filterFlags(flags: Flag[], filters?: FlagFilters): Flag[] {\n  if (!filters) return flags;\n\n  return flags.filter((flag) => {\n    // Filter by status\n    if (filters.status && filters.status.length > 0) {\n      if (!filters.status.includes(flag.status)) {\n        return false;\n      }\n    }\n\n    // Filter by topic name\n    if (filters.topicName) {\n      if (flag.topicName !== filters.topicName) {\n        return false;\n      }\n    }\n\n    return true;\n  });\n}\n\n/**\n * Hook for fetching and managing flags\n *\n * @param filters - Optional filters to apply to the flags list\n * @returns Flags list with loading/error states and action functions\n *\n * @example\n * ```tsx\n * function FlagsList() {\n *   const { flags, isLoading, error, resolve, dismiss, reopen, refresh } = useFlags(\n *     { status: ['open', 'addressed'] }\n *   );\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *\n *   return (\n *     <ul>\n *       {flags.map((flag) => (\n *         <li key={flag.id}>{flag.comment}</li>\n *       ))}\n *     </ul>\n *   );\n * }\n * ```\n */\nexport function useFlags(filters?: FlagFilters): UseFlagsReturn {\n  const [flags, setFlags] = useState<Flag[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchFlags = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      // Apply filters to mock data\n      const filtered = filterFlags(MOCK_FLAGS, filters);\n      setFlags(filtered);\n    } catch (err) {\n      setError(err instanceof Error ? err : new Error('Failed to fetch flags'));\n    } finally {\n      setIsLoading(false);\n    }\n  }, [filters]);\n\n  // Fetch flags on mount and when dependencies change\n  useEffect(() => {\n    fetchFlags();\n  }, [fetchFlags]);\n\n  const refresh = useCallback(async () => {\n    await fetchFlags();\n  }, [fetchFlags]);\n\n  const resolve = useCallback(\n    async (flagId: number, _resolvedBy: string) => {\n      // Simulate API call\n      await new Promise((resolve) => setTimeout(resolve, 200));\n\n      setFlags((prev) =>\n        prev.map((flag) =>\n          flag.id === flagId\n            ? {\n                ...flag,\n                status: 'resolved' as FlagStatus,\n                resolvedAt: new Date().toISOString(),\n              }\n            : flag\n        )\n      );\n    },\n    []\n  );\n\n  const dismiss = useCallback(\n    async (flagId: number, _dismissedBy: string, reason?: string) => {\n      // Simulate API call\n      await new Promise((resolve) => setTimeout(resolve, 200));\n\n      setFlags((prev) =>\n        prev.map((flag) =>\n          flag.id === flagId\n            ? {\n                ...flag,\n                status: 'dismissed' as FlagStatus,\n                dismissedReason: reason,\n              }\n            : flag\n        )\n      );\n    },\n    []\n  );\n\n  const reopen = useCallback(async (flagId: number, _reopenedBy: string) => {\n    // Simulate API call\n    await new Promise((resolve) => setTimeout(resolve, 200));\n\n    setFlags((prev) =>\n      prev.map((flag) =>\n        flag.id === flagId\n          ? {\n              ...flag,\n              status: 'open' as FlagStatus,\n              resolvedAt: undefined,\n              dismissedReason: undefined,\n            }\n          : flag\n      )\n    );\n  }, []);\n\n  return {\n    flags,\n    isLoading,\n    error,\n    resolve,\n    dismiss,\n    reopen,\n    refresh,\n  };\n}\n\nexport default useFlags;\n",
        "codex/ui/src/hooks/useMissingTopics.ts": "/**\n * useMissingTopics Hook\n *\n * Provides access to missing topic requests with actions.\n * Mock implementation for now - returns sample data.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport type { MissingTopic } from '../types';\n\nexport interface UseMissingTopicsReturn {\n  /** List of missing topics */\n  topics: MissingTopic[];\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Dismiss a missing topic request */\n  dismiss: (topicName: string, dismissedBy: string) => Promise<void>;\n  /** Refresh the missing topics list */\n  refresh: () => Promise<void>;\n}\n\n/**\n * Sample mock data for missing topics\n */\nconst MOCK_MISSING_TOPICS: MissingTopic[] = [\n  {\n    topicName: 'nextjs-app-router',\n    requestCount: 12,\n    firstRequestedAt: '2025-01-10T08:00:00Z',\n    lastRequestedAt: '2025-01-22T14:30:00Z',\n  },\n  {\n    topicName: 'prisma-migrations',\n    requestCount: 8,\n    firstRequestedAt: '2025-01-12T10:15:00Z',\n    lastRequestedAt: '2025-01-21T09:45:00Z',\n  },\n  {\n    topicName: 'tailwind-custom-plugins',\n    requestCount: 5,\n    firstRequestedAt: '2025-01-15T16:00:00Z',\n    lastRequestedAt: '2025-01-20T11:20:00Z',\n  },\n  {\n    topicName: 'vitest-mocking',\n    requestCount: 4,\n    firstRequestedAt: '2025-01-18T14:30:00Z',\n    lastRequestedAt: '2025-01-22T08:00:00Z',\n  },\n  {\n    topicName: 'zod-validation',\n    requestCount: 3,\n    firstRequestedAt: '2025-01-19T09:00:00Z',\n    lastRequestedAt: '2025-01-21T16:45:00Z',\n  },\n];\n\n/**\n * Hook for fetching and managing missing topics\n *\n * @returns Missing topics list with loading/error states and action functions\n *\n * @example\n * ```tsx\n * function MissingTopicsList() {\n *   const { topics, isLoading, error, dismiss, refresh } = useMissingTopics();\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *\n *   return (\n *     <ul>\n *       {topics.map((topic) => (\n *         <li key={topic.topicName}>{topic.topicName} ({topic.requestCount} requests)</li>\n *       ))}\n *     </ul>\n *   );\n * }\n * ```\n */\nexport function useMissingTopics(): UseMissingTopicsReturn {\n  const [topics, setTopics] = useState<MissingTopic[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchTopics = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      // Sort by request count descending\n      const sorted = [...MOCK_MISSING_TOPICS].sort(\n        (a, b) => b.requestCount - a.requestCount\n      );\n      setTopics(sorted);\n    } catch (err) {\n      setError(\n        err instanceof Error ? err : new Error('Failed to fetch missing topics')\n      );\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n\n  // Fetch topics on mount\n  useEffect(() => {\n    fetchTopics();\n  }, [fetchTopics]);\n\n  const refresh = useCallback(async () => {\n    await fetchTopics();\n  }, [fetchTopics]);\n\n  const dismiss = useCallback(async (topicName: string, _dismissedBy: string) => {\n    // Simulate API call\n    await new Promise((resolve) => setTimeout(resolve, 200));\n\n    setTopics((prev) => prev.filter((topic) => topic.topicName !== topicName));\n  }, []);\n\n  return {\n    topics,\n    isLoading,\n    error,\n    dismiss,\n    refresh,\n  };\n}\n\nexport default useMissingTopics;\n",
        "codex/ui/src/hooks/useTopic.ts": "/**\n * useTopic Hook\n *\n * Provides access to a single topic's full data including documents.\n * Mock implementation for now - returns sample data.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport type { TopicFull } from '../types';\n\nexport interface UseTopicReturn {\n  /** Full topic data */\n  topic: TopicFull | null;\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Update the lastVerifiedAt timestamp */\n  verify: () => Promise<void>;\n  /** Refresh the topic data */\n  refresh: () => Promise<void>;\n}\n\n/**\n * Sample mock data for full topics\n */\nconst MOCK_TOPICS_FULL: Record<string, TopicFull> = {\n  'react-hooks': {\n    name: 'react-hooks',\n    confidence: 'high',\n    lastVerified: '2025-01-20T10:30:00Z',\n    lastModified: '2025-01-15T08:00:00Z',\n    accessCount: 42,\n    openFlagCount: 0,\n    hasDraft: false,\n    documents: {\n      conceptual: `# React Hooks\n\nReact Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\n\n## Key Concepts\n\n- **useState** - Adds state to functional components\n- **useEffect** - Performs side effects in components\n- **useContext** - Subscribes to React context\n- **useReducer** - Alternative to useState for complex state logic\n- **useCallback** - Returns a memoized callback function\n- **useMemo** - Returns a memoized value\n\n## Rules of Hooks\n\n1. Only call Hooks at the top level\n2. Only call Hooks from React functions\n`,\n      technical: `# React Hooks Technical Reference\n\n## useState\n\n\\`\\`\\`typescript\nconst [state, setState] = useState<T>(initialValue);\n\\`\\`\\`\n\n## useEffect\n\n\\`\\`\\`typescript\nuseEffect(() => {\n  // Effect logic\n  return () => {\n    // Cleanup function\n  };\n}, [dependencies]);\n\\`\\`\\`\n\n## useCallback\n\n\\`\\`\\`typescript\nconst memoizedCallback = useCallback(() => {\n  doSomething(a, b);\n}, [a, b]);\n\\`\\`\\`\n`,\n      files: `# Related Files\n\n- \\`src/hooks/useCustomHook.ts\\` - Custom hook implementations\n- \\`src/components/HookExamples.tsx\\` - Usage examples\n- \\`tests/hooks.test.ts\\` - Hook unit tests\n`,\n      related: `# Related Topics\n\n- [useState in depth](/topics/react-usestate)\n- [useEffect patterns](/topics/react-useeffect)\n- [Custom hooks](/topics/react-custom-hooks)\n- [React context](/topics/react-context)\n`,\n    },\n    flags: [],\n  },\n  'typescript-generics': {\n    name: 'typescript-generics',\n    confidence: 'high',\n    lastVerified: '2025-01-18T14:20:00Z',\n    lastModified: '2025-01-12T11:30:00Z',\n    accessCount: 35,\n    openFlagCount: 1,\n    hasDraft: false,\n    documents: {\n      conceptual: `# TypeScript Generics\n\nGenerics allow you to create reusable components that work with a variety of types rather than a single one.\n\n## Why Generics?\n\n- Type safety without sacrificing flexibility\n- Reusable code that works with multiple types\n- Better IDE support and autocompletion\n\n## Basic Syntax\n\n\\`\\`\\`typescript\nfunction identity<T>(arg: T): T {\n  return arg;\n}\n\\`\\`\\`\n`,\n      technical: `# TypeScript Generics Technical Reference\n\n## Generic Functions\n\n\\`\\`\\`typescript\nfunction firstElement<T>(arr: T[]): T | undefined {\n  return arr[0];\n}\n\\`\\`\\`\n\n## Generic Interfaces\n\n\\`\\`\\`typescript\ninterface Container<T> {\n  value: T;\n  getValue(): T;\n}\n\\`\\`\\`\n\n## Generic Constraints\n\n\\`\\`\\`typescript\nfunction getLength<T extends { length: number }>(arg: T): number {\n  return arg.length;\n}\n\\`\\`\\`\n`,\n      files: `# Related Files\n\n- \\`src/types/generics.ts\\` - Generic type definitions\n- \\`src/utils/typeUtils.ts\\` - Generic utility functions\n`,\n      related: `# Related Topics\n\n- [Type inference](/topics/typescript-inference)\n- [Conditional types](/topics/typescript-conditional)\n- [Mapped types](/topics/typescript-mapped)\n`,\n    },\n    flags: [\n      {\n        id: 'flag-1',\n        topicName: 'typescript-generics',\n        type: 'needs-review',\n        description: 'Examples need to be updated for TypeScript 5.0',\n        createdAt: '2025-01-15T09:00:00Z',\n      },\n    ],\n  },\n  'docker-compose': {\n    name: 'docker-compose',\n    confidence: 'medium',\n    lastVerified: '2025-01-10T09:00:00Z',\n    lastModified: '2025-01-08T15:00:00Z',\n    accessCount: 28,\n    openFlagCount: 0,\n    hasDraft: true,\n    documents: {\n      conceptual: `# Docker Compose\n\nDocker Compose is a tool for defining and running multi-container Docker applications.\n\n## Key Features\n\n- Define services in a single YAML file\n- Start all services with a single command\n- Manage networking between containers\n- Handle volumes and data persistence\n`,\n      technical: `# Docker Compose Technical Reference\n\n## Basic Structure\n\n\\`\\`\\`yaml\nversion: '3.8'\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n  db:\n    image: postgres:14\n    environment:\n      POSTGRES_PASSWORD: secret\n\\`\\`\\`\n\n## Common Commands\n\n\\`\\`\\`bash\ndocker-compose up -d\ndocker-compose down\ndocker-compose logs -f\n\\`\\`\\`\n`,\n      files: `# Related Files\n\n- \\`docker-compose.yml\\` - Main compose file\n- \\`docker-compose.dev.yml\\` - Development overrides\n- \\`docker-compose.prod.yml\\` - Production overrides\n`,\n      related: `# Related Topics\n\n- [Docker networking](/topics/docker-networking)\n- [Docker volumes](/topics/docker-volumes)\n- [Kubernetes](/topics/kubernetes-basics)\n`,\n    },\n    flags: [],\n  },\n};\n\n/**\n * Hook for fetching and managing a single topic's data\n *\n * @param name - The topic name/slug to fetch\n * @returns Topic data with loading/error states and action functions\n *\n * @example\n * ```tsx\n * function TopicView({ name }: { name: string }) {\n *   const { topic, isLoading, error, verify, refresh } = useTopic(name);\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *   if (!topic) return <div>Topic not found</div>;\n *\n *   return (\n *     <div>\n *       <h1>{topic.name}</h1>\n *       <button onClick={verify}>Mark as Verified</button>\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useTopic(name: string): UseTopicReturn {\n  const [topic, setTopic] = useState<TopicFull | null>(null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchTopic = useCallback(async () => {\n    if (!name) {\n      setTopic(null);\n      setIsLoading(false);\n      return;\n    }\n\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      const topicData = MOCK_TOPICS_FULL[name];\n\n      if (!topicData) {\n        throw new Error(`Topic \"${name}\" not found`);\n      }\n\n      setTopic(topicData);\n    } catch (err) {\n      setError(err instanceof Error ? err : new Error('Failed to fetch topic'));\n      setTopic(null);\n    } finally {\n      setIsLoading(false);\n    }\n  }, [name]);\n\n  // Fetch topic on mount and when name changes\n  useEffect(() => {\n    fetchTopic();\n  }, [fetchTopic]);\n\n  const verify = useCallback(async () => {\n    if (!topic) return;\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 200));\n\n      // Update the lastVerified timestamp\n      setTopic((prev) =>\n        prev\n          ? {\n              ...prev,\n              lastVerified: new Date().toISOString(),\n            }\n          : null\n      );\n    } catch (err) {\n      setError(err instanceof Error ? err : new Error('Failed to verify topic'));\n    }\n  }, [topic]);\n\n  const refresh = useCallback(async () => {\n    await fetchTopic();\n  }, [fetchTopic]);\n\n  return {\n    topic,\n    isLoading,\n    error,\n    verify,\n    refresh,\n  };\n}\n\nexport default useTopic;\n",
        "codex/ui/src/hooks/useTopics.ts": "/**\n * useTopics Hook\n *\n * Provides access to the list of topics with filtering and sorting.\n * Mock implementation for now - returns sample data.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport type { TopicSummary, TopicFilters, TopicSortBy, SortOrder } from '../types';\n\nexport interface UseTopicsReturn {\n  /** List of topics matching filters */\n  topics: TopicSummary[];\n  /** Loading state */\n  isLoading: boolean;\n  /** Error state */\n  error: Error | null;\n  /** Refresh the topic list */\n  refresh: () => Promise<void>;\n}\n\n/**\n * Sample mock data for topics\n */\nconst MOCK_TOPICS: TopicSummary[] = [\n  {\n    name: 'react-hooks',\n    confidence: 'high',\n    lastVerified: '2025-01-20T10:30:00Z',\n    accessCount: 42,\n    openFlagCount: 0,\n    hasDraft: false,\n  },\n  {\n    name: 'typescript-generics',\n    confidence: 'high',\n    lastVerified: '2025-01-18T14:20:00Z',\n    accessCount: 35,\n    openFlagCount: 1,\n    hasDraft: false,\n  },\n  {\n    name: 'docker-compose',\n    confidence: 'medium',\n    lastVerified: '2025-01-10T09:00:00Z',\n    accessCount: 28,\n    openFlagCount: 0,\n    hasDraft: true,\n  },\n  {\n    name: 'graphql-mutations',\n    confidence: 'medium',\n    lastVerified: '2024-12-15T16:45:00Z',\n    accessCount: 15,\n    openFlagCount: 2,\n    hasDraft: false,\n  },\n  {\n    name: 'kubernetes-pods',\n    confidence: 'low',\n    lastVerified: null,\n    accessCount: 8,\n    openFlagCount: 0,\n    hasDraft: true,\n  },\n  {\n    name: 'redis-caching',\n    confidence: 'low',\n    lastVerified: '2024-11-20T12:00:00Z',\n    accessCount: 5,\n    openFlagCount: 3,\n    hasDraft: false,\n  },\n];\n\n/**\n * Check if a topic is stale (not verified within staleDays)\n */\nfunction isStale(lastVerified: string | null, staleDays: number): boolean {\n  if (!lastVerified) return true;\n  const verifiedDate = new Date(lastVerified);\n  const staleDate = new Date();\n  staleDate.setDate(staleDate.getDate() - staleDays);\n  return verifiedDate < staleDate;\n}\n\n/**\n * Apply filters to topics\n */\nfunction filterTopics(topics: TopicSummary[], filters?: TopicFilters): TopicSummary[] {\n  if (!filters) return topics;\n\n  return topics.filter((topic) => {\n    // Filter by confidence\n    if (filters.confidence && filters.confidence.length > 0) {\n      if (!filters.confidence.includes(topic.confidence)) {\n        return false;\n      }\n    }\n\n    // Filter by has flags\n    if (filters.hasFlags !== undefined) {\n      if (filters.hasFlags && topic.openFlagCount === 0) {\n        return false;\n      }\n      if (!filters.hasFlags && topic.openFlagCount > 0) {\n        return false;\n      }\n    }\n\n    // Filter by has draft\n    if (filters.hasDraft !== undefined) {\n      if (filters.hasDraft !== topic.hasDraft) {\n        return false;\n      }\n    }\n\n    // Filter by stale\n    if (filters.staleDays !== undefined) {\n      if (!isStale(topic.lastVerified, filters.staleDays)) {\n        return false;\n      }\n    }\n\n    return true;\n  });\n}\n\n/**\n * Sort topics by specified field and order\n */\nfunction sortTopics(\n  topics: TopicSummary[],\n  sortBy: TopicSortBy = 'name',\n  sortOrder: SortOrder = 'asc'\n): TopicSummary[] {\n  const sorted = [...topics].sort((a, b) => {\n    let comparison = 0;\n\n    switch (sortBy) {\n      case 'name':\n        comparison = a.name.localeCompare(b.name);\n        break;\n      case 'confidence': {\n        const confidenceOrder = { high: 3, medium: 2, low: 1 };\n        comparison = confidenceOrder[a.confidence] - confidenceOrder[b.confidence];\n        break;\n      }\n      case 'lastVerified': {\n        const aDate = a.lastVerified ? new Date(a.lastVerified).getTime() : 0;\n        const bDate = b.lastVerified ? new Date(b.lastVerified).getTime() : 0;\n        comparison = aDate - bDate;\n        break;\n      }\n      case 'accessCount':\n        comparison = a.accessCount - b.accessCount;\n        break;\n      default:\n        comparison = 0;\n    }\n\n    return sortOrder === 'desc' ? -comparison : comparison;\n  });\n\n  return sorted;\n}\n\n/**\n * Hook for fetching and managing the topics list\n *\n * @param filters - Optional filters to apply to the topic list\n * @param sortBy - Field to sort by (default: 'name')\n * @param sortOrder - Sort direction (default: 'asc')\n * @returns Topics list with loading/error states and refresh function\n *\n * @example\n * ```tsx\n * function TopicList() {\n *   const { topics, isLoading, error, refresh } = useTopics(\n *     { confidence: ['high', 'medium'] },\n *     'accessCount',\n *     'desc'\n *   );\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *\n *   return (\n *     <ul>\n *       {topics.map((topic) => (\n *         <li key={topic.name}>{topic.name}</li>\n *       ))}\n *     </ul>\n *   );\n * }\n * ```\n */\nexport function useTopics(\n  filters?: TopicFilters,\n  sortBy: TopicSortBy = 'name',\n  sortOrder: SortOrder = 'asc'\n): UseTopicsReturn {\n  const [topics, setTopics] = useState<TopicSummary[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  const fetchTopics = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Simulate API delay\n      await new Promise((resolve) => setTimeout(resolve, 300));\n\n      // Apply filters and sorting to mock data\n      const filtered = filterTopics(MOCK_TOPICS, filters);\n      const sorted = sortTopics(filtered, sortBy, sortOrder);\n\n      setTopics(sorted);\n    } catch (err) {\n      setError(err instanceof Error ? err : new Error('Failed to fetch topics'));\n    } finally {\n      setIsLoading(false);\n    }\n  }, [filters, sortBy, sortOrder]);\n\n  // Fetch topics on mount and when dependencies change\n  useEffect(() => {\n    fetchTopics();\n  }, [fetchTopics]);\n\n  const refresh = useCallback(async () => {\n    await fetchTopics();\n  }, [fetchTopics]);\n\n  return {\n    topics,\n    isLoading,\n    error,\n    refresh,\n  };\n}\n\nexport default useTopics;\n",
        "hooks/brainstorming-enforce.sh": "#!/bin/bash\n# hooks/brainstorming-enforce.sh\n# PreToolUse hook for Write/Edit tools\n# Blocks edits outside .collab/ during brainstorming phase\n\nset -e\n\n# Read JSON input from stdin (Claude Code hook input format)\nINPUT=$(cat)\n\n# Parse file_path from tool_input field\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.filePath // empty')\n\nif [ -z \"$FILE_PATH\" ]; then\n    # Can't determine file, allow\n    exit 0\nfi\n\n# Find session path\nfind_session_path() {\n    if [ -n \"$COLLAB_SESSION_PATH\" ]; then\n        echo \"$COLLAB_SESSION_PATH\"\n        return\n    fi\n\n    # Scan for .collab/\n    local current=\"$PWD\"\n    while [ \"$current\" != \"/\" ]; do\n        if [ -d \"$current/.collab\" ]; then\n            # Find most recent session\n            local latest=$(ls -t \"$current/.collab\" 2>/dev/null | head -1)\n            if [ -n \"$latest\" ]; then\n                echo \"$current/.collab/$latest\"\n                return\n            fi\n        fi\n        current=$(dirname \"$current\")\n    done\n}\n\nSESSION_PATH=$(find_session_path)\n\nif [ -z \"$SESSION_PATH\" ]; then\n    # No session, allow all\n    exit 0\nfi\n\nSTATE_FILE=\"$SESSION_PATH/collab-state.json\"\n\nif [ ! -f \"$STATE_FILE\" ]; then\n    exit 0\nfi\n\n# Read phase\nPHASE=$(jq -r '.phase' \"$STATE_FILE\")\n\nif [ \"$PHASE\" = \"implementation\" ]; then\n    exit 0\nfi\n\n# Brainstorming - check if file is in .collab/\nCOLLAB_DIR=$(dirname \"$SESSION_PATH\")\n\ncase \"$FILE_PATH\" in\n    \"$COLLAB_DIR\"*)\n        exit 0\n        ;;\n    *)\n        # Exit 2 = blocking error, stderr is shown to user\n        echo \"Cannot edit files outside .collab/ during brainstorming phase. Use /ready-to-implement to transition to implementation phase.\" >&2\n        exit 2\n        ;;\nesac\n",
        "hooks/hooks.json": "{\n  \"description\": \"Hooks for mermaid-collab plugin: server auto-start, phase enforcement, and diagram syncing\",\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"mcp__.*mermaid__.*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/server-check.sh\",\n            \"timeout\": 15\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/brainstorming-enforce.sh\",\n            \"timeout\": 5\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"mcp__.*mermaid__create_diagram|mcp__.*mermaid__update_diagram\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/sync-diagram-to-doc.sh\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"PreCompact\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/pre-compact.sh\",\n            \"timeout\": 5\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "hooks/post-task-complete.sh": "#!/bin/bash\n# hooks/post-task-complete.sh\n# Updates task graph and logs completion\n\nset -e\n\nTASK_ID=\"$COMPLETED_TASK_ID\"\n\n# Find session\nfind_session_path() {\n    if [ -n \"$COLLAB_SESSION_PATH\" ]; then\n        echo \"$COLLAB_SESSION_PATH\"\n        return\n    fi\n\n    local current=\"$PWD\"\n    while [ \"$current\" != \"/\" ]; do\n        if [ -d \"$current/.collab\" ]; then\n            local latest=$(ls -t \"$current/.collab\" 2>/dev/null | head -1)\n            if [ -n \"$latest\" ]; then\n                echo \"$current/.collab/$latest\"\n                return\n            fi\n        fi\n        current=$(dirname \"$current\")\n    done\n}\n\nSESSION_PATH=$(find_session_path)\n[ -z \"$SESSION_PATH\" ] && exit 0\n\nSTATE_FILE=\"$SESSION_PATH/collab-state.json\"\n[ ! -f \"$STATE_FILE\" ] && exit 0\n\n# Read state\nSTATE=$(cat \"$STATE_FILE\")\n\n# Find task name\nTASK_NAME=$(echo \"$STATE\" | jq -r --arg id \"$TASK_ID\" '.tasks[] | select(.id == $id) | .name')\n\n# Add to completion log\nTIMESTAMP=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\nSTATE=$(echo \"$STATE\" | jq --arg id \"$TASK_ID\" --arg ts \"$TIMESTAMP\" \\\n    '.completionLog += [{\"task\": $id, \"completedAt\": $ts}]')\n\n# Update lastAction\nSTATE=$(echo \"$STATE\" | jq --arg ts \"$TIMESTAMP\" --arg name \"$TASK_NAME\" \\\n    '.lastAction = {\"type\": \"task_complete\", \"details\": (\"Completed: \" + $name), \"timestamp\": $ts}')\n\nSTATE=$(echo \"$STATE\" | jq --arg ts \"$TIMESTAMP\" '.lastUpdated = $ts')\n\n# Write state\necho \"$STATE\" > \"$STATE_FILE\"\n\n# Output notification\nCOMPLETE=$(echo \"$STATE\" | jq '[.tasks[] | select(.status == \"complete\")] | length')\nTOTAL=$(echo \"$STATE\" | jq '.tasks | length')\necho \"Task $TASK_ID ($TASK_NAME) complete. $COMPLETE/$TOTAL tasks done.\"\n\nexit 0\n",
        "hooks/pre-compact.sh": "#!/bin/bash\n\n# Read input JSON from stdin (Claude Code provides this)\nINPUT=$(cat)\n\n# Find active collab session in current directory\nSESSION_DIR=\"\"\nfor dir in .collab/*/; do\n  if [ -f \"${dir}collab-state.json\" ]; then\n    SESSION_DIR=\"$dir\"\n    break\n  fi\ndone\n\n# Exit silently if no session\n[ -z \"$SESSION_DIR\" ] && exit 0\n\n# Read current state\nSTATE=$(cat \"${SESSION_DIR}collab-state.json\")\nPHASE=$(echo \"$STATE\" | jq -r '.phase')\nCURRENT_ITEM=$(echo \"$STATE\" | jq -r '.currentItem // empty')\n\n# Determine active skill from phase\ncase \"$PHASE\" in\n  brainstorming*) SKILL=\"brainstorming\" ;;\n  rough-draft*) SKILL=\"rough-draft\" ;;\n  implementation*) SKILL=\"executing-plans\" ;;\n  *) SKILL=\"collab\" ;;\nesac\n\n# Write context snapshot\ncat > \"${SESSION_DIR}context-snapshot.json\" << EOF\n{\n  \"version\": 1,\n  \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"activeSkill\": \"$SKILL\",\n  \"currentStep\": \"$PHASE\",\n  \"pendingQuestion\": null,\n  \"inProgressItem\": $( [ -n \"$CURRENT_ITEM\" ] && echo \"$CURRENT_ITEM\" || echo \"null\" ),\n  \"recentContext\": []\n}\nEOF\n\n# Update state to mark snapshot exists\njq '.hasSnapshot = true' \"${SESSION_DIR}collab-state.json\" > tmp.$$ && \\\n  mv tmp.$$ \"${SESSION_DIR}collab-state.json\"\n\nexit 0\n",
        "hooks/server-check.sh": "#!/bin/bash\n# hooks/server-check.sh - Ensures mermaid-collab server is running\n#\n# Claude Code PreToolUse hook for mcp__mermaid__* tools\n# Automatically starts the server if not running\n\nset -e\n\nPORT=${MERMAID_PORT:-3737}\nMAX_WAIT=10  # seconds\nPOLL_INTERVAL=0.5\n\n# Get the project root (parent of hooks/)\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPROJECT_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\n\ncheck_server() {\n  curl --silent --fail --max-time 1 \"http://localhost:$PORT/api/health\" > /dev/null 2>&1\n}\n\n# If server is already running, we're done\nif check_server; then\n  exit 0\nfi\n\n# Start server in background\necho \"Starting mermaid-collab server...\" >&2\ncd \"$PROJECT_ROOT\" && bun run src/server.ts > /dev/null 2>&1 &\nSERVER_PID=$!\n\n# Wait for server to be ready\nelapsed=0\nwhile [ \"$elapsed\" -lt \"$MAX_WAIT\" ]; do\n  if check_server; then\n    echo \"Server ready on port $PORT\" >&2\n    exit 0\n  fi\n  sleep $POLL_INTERVAL\n  elapsed=$((elapsed + 1))\ndone\n\n# Timeout - server didn't start (exit 2 = blocking error)\necho \"ERROR: mermaid-collab server failed to start within ${MAX_WAIT}s\" >&2\necho \"Check logs or try manually: cd $PROJECT_ROOT && bun run src/server.ts\" >&2\nexit 2\n",
        "hooks/sync-diagram-to-doc.sh": "#!/bin/bash\n# hooks/sync-diagram-to-doc.sh\n# PostToolUse hook for diagram create/update\n# Syncs diagram content to design doc\n\nset -e\n\n# Read JSON input from stdin (Claude Code hook input format)\nINPUT=$(cat)\n\n# Parse diagram ID from tool_output field\nDIAGRAM_ID=$(echo \"$INPUT\" | jq -r '.tool_output.id // empty')\n[ -z \"$DIAGRAM_ID\" ] && exit 0\n\n# Find session path\nfind_session_path() {\n    if [ -n \"$COLLAB_SESSION_PATH\" ]; then\n        echo \"$COLLAB_SESSION_PATH\"\n        return\n    fi\n\n    local current=\"$PWD\"\n    while [ \"$current\" != \"/\" ]; do\n        if [ -d \"$current/.collab\" ]; then\n            local latest=$(ls -t \"$current/.collab\" 2>/dev/null | head -1)\n            if [ -n \"$latest\" ]; then\n                echo \"$current/.collab/$latest\"\n                return\n            fi\n        fi\n        current=$(dirname \"$current\")\n    done\n}\n\nSESSION_PATH=$(find_session_path)\n[ -z \"$SESSION_PATH\" ] && exit 0\n\n# Read diagram content\nDIAGRAM_FILE=\"$SESSION_PATH/diagrams/$DIAGRAM_ID.mmd\"\n[ ! -f \"$DIAGRAM_FILE\" ] && exit 0\nDIAGRAM_CONTENT=$(cat \"$DIAGRAM_FILE\")\n\n# Read or create design doc\nDOC_FILE=\"$SESSION_PATH/documents/design.md\"\nif [ -f \"$DOC_FILE\" ]; then\n    DOC_CONTENT=$(cat \"$DOC_FILE\")\nelse\n    # Create initial document with Diagrams section\n    DOC_CONTENT=\"# Design\n\n## Diagrams\"\nfi\n\n# Ensure \"## Diagrams\" section exists\nif ! echo \"$DOC_CONTENT\" | grep -q \"^## Diagrams\"; then\n    DOC_CONTENT=\"$DOC_CONTENT\n\n## Diagrams\"\nfi\n\n# Check if this diagram section already exists\nif echo \"$DOC_CONTENT\" | grep -q \"^### $DIAGRAM_ID\\$\"; then\n    # Update existing diagram section - replace content between ```mermaid and ```\n    # Use awk to find the section and replace the mermaid block\n    DOC_CONTENT=$(echo \"$DOC_CONTENT\" | awk -v diagram_id=\"$DIAGRAM_ID\" -v new_content=\"$DIAGRAM_CONTENT\" '\n        BEGIN { in_section = 0; in_mermaid = 0; found_section = 0 }\n\n        # Match the diagram section header\n        /^### / {\n            if ($0 == \"### \" diagram_id) {\n                in_section = 1\n                found_section = 1\n            } else if (in_section) {\n                in_section = 0\n            }\n            print\n            next\n        }\n\n        # Match start of mermaid block in our section\n        /^```mermaid/ {\n            if (in_section && !in_mermaid) {\n                in_mermaid = 1\n                print \"```mermaid\"\n                print new_content\n                next\n            }\n            print\n            next\n        }\n\n        # Match end of mermaid block\n        /^```$/ {\n            if (in_section && in_mermaid) {\n                in_mermaid = 0\n                print \"```\"\n                next\n            }\n            print\n            next\n        }\n\n        # Skip content inside mermaid block (will be replaced)\n        {\n            if (in_section && in_mermaid) {\n                next\n            }\n            print\n        }\n    ')\nelse\n    # Append new diagram section after \"## Diagrams\"\n    # Find the position after \"## Diagrams\" and insert at the end of that section\n    DOC_CONTENT=$(echo \"$DOC_CONTENT\" | awk -v diagram_id=\"$DIAGRAM_ID\" -v new_content=\"$DIAGRAM_CONTENT\" '\n        BEGIN { found_diagrams = 0; inserted = 0 }\n\n        # Detect ## Diagrams line\n        /^## Diagrams/ {\n            found_diagrams = 1\n            print\n            next\n        }\n\n        # Insert before the next ## section (but not ### or ## Diagrams itself)\n        /^## / && !/^## Diagrams/ {\n            if (found_diagrams && !inserted) {\n                print \"\"\n                print \"### \" diagram_id\n                print \"```mermaid\"\n                print new_content\n                print \"```\"\n                print \"\"\n                inserted = 1\n            }\n            print\n            next\n        }\n\n        { print }\n\n        END {\n            if (found_diagrams && !inserted) {\n                print \"\"\n                print \"### \" diagram_id\n                print \"```mermaid\"\n                print new_content\n                print \"```\"\n            }\n        }\n    ')\nfi\n\n# Write the updated document\nmkdir -p \"$(dirname \"$DOC_FILE\")\"\nprintf '%s\\n' \"$DOC_CONTENT\" > \"$DOC_FILE\"\n\nexit 0\n",
        "plugins/wireframe/README.md": "# mermaid-wireframe\n\nA Mermaid.js external diagram plugin for creating wireframe mockups and UI prototypes using simple text-based syntax. Perfect for rapid prototyping, documentation, and design discussions.\n\n[![npm version](https://img.shields.io/npm/v/mermaid-wireframe.svg)](https://www.npmjs.com/package/mermaid-wireframe)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Features\n\n- 📱 **Multi-viewport support**: Mobile (375px), Tablet (768px), Desktop (1200px)\n- 🎨 **20+ UI components**: Buttons, Inputs, Cards, Grids, Navigation, Icons, and more\n- 📐 **Flex layout engine**: Automatic responsive layouts with flex, width, height, padding\n- 🎭 **Component variants**: Primary, secondary, danger, success button styles\n- 🖼️ **Grid support**: Create data tables with headers and rows\n- ⚡ **Fast rendering**: Built with d3.js for efficient SVG generation\n- 🔧 **Extensible**: Clean architecture following Mermaid's plugin patterns\n\n## Installation\n\n```bash\nnpm install mermaid-wireframe mermaid\n```\n\n## Usage\n\n### Node.js / Server-side\n\n```javascript\nimport mermaid from 'mermaid';\nimport * as wireframe from 'mermaid-wireframe';\n\n// Register the wireframe plugin\nawait mermaid.registerExternalDiagrams([wireframe]);\n\n// Initialize mermaid\nmermaid.initialize({ startOnLoad: true });\n\n// Render a diagram\nconst { svg } = await mermaid.render('diagram-id', `\n  wireframe mobile\n    col\n      AppBar \"My App\"\n      Title \"Welcome\"\n      Input \"Email\"\n      Input \"Password\"\n      Button \"Sign In\" primary\n`);\n```\n\n### Browser\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <script type=\"importmap\">\n  {\n    \"imports\": {\n      \"d3\": \"https://cdn.jsdelivr.net/npm/d3@7/+esm\"\n    }\n  }\n  </script>\n</head>\n<body>\n  <pre class=\"mermaid\">\n    wireframe mobile\n      col\n        AppBar \"Sign In\"\n        Title \"Welcome Back\"\n        Input \"Email\"\n        Input \"Password\"\n        Button \"Sign In\" primary\n  </pre>\n\n  <script type=\"module\">\n    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n    import * as wireframe from './node_modules/mermaid-wireframe/dist/mermaid-wireframe.browser.js';\n\n    await mermaid.registerExternalDiagrams([wireframe]);\n    mermaid.initialize({ startOnLoad: true });\n  </script>\n</body>\n</html>\n```\n\n## Syntax\n\n### Basic Structure\n\n```\nwireframe [viewport] [direction]\n  screen [\"label\"]\n    [component] [\"label\"] [modifiers]\n```\n\n### Viewports\n\n- `mobile` - 375×600px (default)\n- `tablet` - 768×1024px\n- `desktop` - 1200×800px\n\n### Direction\n\n- `LR` - Left to right (default, horizontal screen layout)\n- `TD` - Top to down (vertical screen layout)\n\n### Multi-Screen Layouts\n\nUse `screen` to define multiple screens in one diagram:\n\n```\nwireframe mobile LR\n  screen \"Login\"\n    col\n      AppBar \"Sign In\"\n      Input \"Email\"\n  screen \"Dashboard\"\n    col\n      AppBar \"Home\"\n      Title \"Welcome\"\n```\n\n### Containers\n\n- `screen [\"label\"]` - Screen container with optional label (rendered with dashed border)\n- `col` - Vertical column (default direction)\n- `row` - Horizontal row\n- `Card` - Card container with border\n- `Grid` - Data grid (use with `header` and `row`)\n\n### Components\n\n**Text & Titles:**\n- `Text \"content\"` - Body text\n- `Title \"content\"` - Large heading\n\n**Form Inputs:**\n- `Input \"placeholder\"` - Text input field\n- `Checkbox \"label\"` - Checkbox\n- `Radio \"label\"` - Radio button\n- `Switch \"label\"` - Toggle switch\n- `Dropdown \"label\"` - Dropdown/select\n\n**Buttons:**\n- `Button \"label\"` - Standard button\n- Variants: `primary`, `secondary`, `danger`, `success`\n- State: `disabled`\n\n**Navigation:**\n- `AppBar \"title\"` - Top app bar\n- `NavMenu \"item\"` - Navigation menu item\n- `BottomNav` - Bottom navigation bar\n- `FAB` - Floating action button\n\n**Display:**\n- `Avatar` - User avatar circle\n- `Icon` - Icon placeholder\n- `Image` - Image placeholder\n- `List \"item\"` - List item\n\n**Layout:**\n- `spacer` - Flexible spacing element\n- `divider` - Horizontal line separator\n\n### Modifiers\n\n**Layout:**\n- `flex` or `flex=2` - Flex grow factor\n- `width=200` - Fixed width in pixels\n- `height=100` - Fixed height in pixels\n- `padding=16` - Internal padding\n- `align=start|center|end|space-between` - Main axis alignment\n- `cross=start|center|end` - Cross axis alignment\n\n**Appearance:**\n- `primary`, `secondary`, `danger`, `success` - Component variants\n- `disabled` - Disabled state\n\n## Examples\n\n### Mobile Login Screen\n\n```\nwireframe mobile\n  col\n    AppBar \"Sign In\"\n    col padding=24\n      Title \"Welcome Back\"\n      Text \"Enter your credentials\"\n      Input \"Email\"\n      Input \"Password\"\n      Button \"Sign In\" primary\n      Button \"Forgot Password?\" secondary\n```\n\n### Desktop Dashboard\n\n```\nwireframe desktop\n  col\n    AppBar \"Dashboard\"\n    row padding=16\n      col flex=2\n        Card\n          Title \"User Stats\"\n          Text \"Total Users: 1,234\"\n          Text \"Active Today: 567\"\n      col flex=3\n        Grid\n          header \"Name | Email | Status\"\n          row \"John Doe | john@example.com | Active\"\n          row \"Jane Smith | jane@example.com | Active\"\n```\n\n### Mobile Profile\n\n```\nwireframe mobile\n  col\n    AppBar \"Profile\"\n    col align=center padding=24\n      Avatar\n      Title \"John Doe\"\n      Text \"john.doe@example.com\"\n    divider\n    List \"Edit Profile\"\n    List \"Settings\"\n    List \"Privacy\"\n    spacer\n    Button \"Sign Out\" danger\n```\n\n## Architecture\n\nThe plugin follows Mermaid's external diagram architecture with three main components:\n\n- **Parser** (Jison): Parses wireframe DSL into node tree\n- **Database**: Manages diagram state and tree building\n- **Renderer** (d3.js): Renders nodes as SVG with flex layout\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the parser and bundle\nnpm run build\n\n# Run tests\nnpm test\n\n# Watch mode\nnpm run dev\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT © ben-mad-jlp\n\n## Acknowledgments\n\nBuilt with [Mermaid.js](https://mermaid.js.org/) and [d3.js](https://d3js.org/).\n",
        "skills/brainstorming-clarifying/SKILL.md": "---\nname: brainstorming-clarifying\ndescription: The CLARIFYING phase discusses each item one at a time to fully understand requirements\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# CLARIFYING Phase\n\nThe CLARIFYING phase discusses each item one at a time to fully understand requirements before designing.\n\n## Purpose\n\n- Discuss ONE item at a time (never batch multiple items)\n- Ask questions to refine each item\n- Ensure all requirements are captured\n- Confirm nothing else needs discussion\n\n## Process\n\n1. **Present first item:**\n   - State the item clearly\n   - Ask clarifying questions about it\n\n2. **For each item:**\n   - Ask questions to refine understanding\n   - Prefer multiple choice questions when possible\n   - One question at a time\n   - Wait for answer before next question\n\n3. **After each item is discussed:**\n   - Summarize understanding\n   - Move to next item\n\n4. **After all items discussed:**\n   - Ask: \"Is there anything else?\"\n   - Only proceed when user confirms nothing else\n\n## Single-Item Mode (CLARIFYING)\n\nWhen `currentItem` is set in collab-state.json:\n\n- Ask questions about this specific item (one at a time)\n- Do NOT explore other items or expand scope\n- Ask: \"Is there anything else about this item?\"\n\n## Incremental Design Doc Updates\n\nAfter each substantive user answer during CLARIFYING phase:\n\n1. Output: \"Updating [field] for Item [N]...\"\n2. Read current design doc via MCP\n3. Update the relevant field (Problem/Goal, Approach, Success Criteria, or Decisions)\n4. Write updated doc via MCP\n5. Output: \"Updated [field] for Item [N]\"\n\nThis ensures context survives compaction - the design doc is the persistent record.\n\n## Question Best Practices\n\n**Prefer multiple choice:**\n```\nWhich approach do you prefer?\n\n1. Option A - [brief description]\n2. Option B - [brief description]\n3. Other (please specify)\n```\n\n**Use browser-based questions when collab session active:**\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Select an option\" },\n    \"children\": [{\n      \"type\": \"MultipleChoice\",\n      \"props\": {\n        \"options\": [\n          { \"value\": \"1\", \"label\": \"Option 1\" },\n          { \"value\": \"2\", \"label\": \"Option 2\" }\n        ],\n        \"name\": \"choice\"\n      }\n    }],\n    \"actions\": [{ \"id\": \"submit\", \"label\": \"Submit\", \"primary\": true }]\n  },\n  \"blocking\": true\n}\n```\n\n## Auto-Decomposition Check\n\n**REQUIRED** before transitioning to DESIGNING, for each work item:\n\n1. **Analyze item scope:**\n   - Count affected files mentioned in approach\n   - Count distinct concerns (auth, API, UI, tests, etc.)\n   - Estimate number of tasks\n\n2. **If item looks large (any of these triggers):**\n   - More than 5-6 files affected\n   - More than 2 distinct concerns\n   - Would result in more than 10 tasks\n\n3. **Present decomposition proposal:**\n   ```\n   This item looks large:\n   - Files: [N] affected\n   - Concerns: [list distinct areas]\n   - Estimated tasks: [N]\n\n   I see [N] pieces:\n   1. [Sub-component 1]: [files/concern]\n   2. [Sub-component 2]: [files/concern]\n   3. [Sub-component 3]: [files/concern]\n\n   Split into separate work items?\n\n   1. Yes - split into [N] items (Recommended for complex work)\n   2. No - keep as single item\n   ```\n\n4. **If user selects 1 (Yes):**\n   - Create new work items in design doc for each sub-component\n   - Mark original item as superseded\n   - Continue CLARIFYING with new items\n\n5. **If user selects 2 (No):**\n   - Keep as single item\n   - Proceed to DESIGNING\n\n**Why auto-decomposition matters:**\n- Smaller items create smaller per-item documents\n- Smaller documents reduce context bloat\n- Parallel execution of independent items\n\n## Exit Criteria\n\n- Each item discussed individually (not batched)\n- Asked \"Is there anything else?\"\n- User confirmed nothing else to discuss\n\n## Transition to DESIGNING\n\n**Prerequisites:**\n- Each item discussed individually (not batched)\n- Asked \"Is there anything else?\"\n- User confirmed nothing else to discuss\n\n**Announce:** \"All items clarified. Now let me present the design approach.\"\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"brainstorming-clarifying\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/brainstorming-designing/SKILL.md": "---\nname: brainstorming-designing\ndescription: The DESIGNING phase presents the design approach in small, validated sections\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# DESIGNING Phase\n\nThe DESIGNING phase presents the design approach in small, validated sections.\n\n## Purpose\n\n- Propose and explore different approaches\n- Present design in 200-300 word sections\n- Get explicit user validation for each section\n- Create visual diagrams for architecture and UI\n\n## Process\n\n### 1. Exploring Approaches\n\nBefore writing the design:\n\n- Propose 2-3 different approaches with trade-offs\n- Present options conversationally with your recommendation and reasoning\n- Lead with your recommended option and explain why\n\n### 2. Presenting Sections\n\nFor each section of the design:\n\n1. Write section to design doc with `[PROPOSED]` marker\n2. Tell user: \"I've added a proposed section: **[Section Name]**\"\n3. Provide preview link: \"Review at: [mermaid-collab preview URL]\"\n4. Ask: \"Accept this section?\"\n   ```\n   1. Accept\n   2. Reject\n   3. Edit\n   ```\n\n**User responses:**\n- **1 (Accept)**: Remove `[PROPOSED]` marker, continue to next section\n- **2 (Reject)**: Discuss what's wrong, revise the section, repeat from step 1\n- **3 (Edit)**: User edits directly in browser, Claude acknowledges changes and continues\n\n### 3. Section Size\n\n- Keep sections to 200-300 words\n- One concept per section\n- Get validation before moving to next\n\n## Single-Item Mode (DESIGNING)\n\nWhen `currentItem` is set in collab-state.json:\n\nUpdate the work item in the design doc with:\n- `**Problem/Goal:**` - documented problem/goal\n- `**Approach:**` - documented approach\n- `**Success Criteria:**` - documented criteria\n- `**Decisions:**` - any item-specific decisions\n\n## Checkpoint: Approach Diagram\n\n**REQUIRED** for each proposed approach:\n\nBefore presenting an approach to the user, create a diagram visualizing it:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__create_diagram\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"name\": \"approach-N\",\n  \"content\": <flowchart/sequence showing the proposed approach>\n}\n```\n\nDo NOT describe architecture or flow in text alone. Show it visually, then explain.\n\n## Visualizing with Mermaid Collab\n\nWhen brainstorming involves visual artifacts, use the mermaid-collab server.\n\n**GUI/UI Design (ALWAYS use wireframes):**\n- When discussing screens, layouts, or user interfaces -> create wireframe diagrams\n- Use `create_diagram(name, content)` with wireframe syntax\n- Iterate on wireframes as the design evolves\n- Preview with `preview_diagram(id)` so user can see in browser\n\n**Architecture and Flow Design:**\n- System architecture -> flowchart diagrams\n- Data flow -> sequence or flowchart diagrams\n- State machines -> SMACH YAML or state diagrams\n- Component relationships -> class or flowchart diagrams\n\n**Design Documents:**\n- Use `create_document(name, content)` for design specs\n- Iterate on documents with `update_document(id, content)`\n- Link related diagrams in the document\n\n**Workflow:**\n1. During \"Exploring approaches\" phase, create diagram(s) to visualize options\n2. During \"Presenting the design\" phase, update diagrams to match validated sections\n3. When writing final design doc, embed diagram references\n\n## Design Completeness Checklist\n\nBefore moving to VALIDATING, ensure:\n\n- [ ] Every screen/UI has a wireframe in mermaid-collab\n- [ ] Every data flow/architecture decision has a diagram\n- [ ] No ambiguous language (\"should handle errors appropriately\" -> specify HOW)\n- [ ] No TBD or \"figure out later\" items\n- [ ] Success criteria are measurable, not subjective\n\n## Live Design Doc Updates\n\nWhen brainstorming within a collab session, update the design document using MCP tools.\n\n**Prefer patch operations for targeted changes:**\n\nFor small, targeted edits (updating a single field, adding a bullet point, changing status):\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__patch_document\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<name>\",\n  \"id\": \"design\",\n  \"old_string\": \"<exact text to find>\",\n  \"new_string\": \"<replacement text>\"\n}\n```\n\n**Use full update only when:**\n- Adding entirely new sections\n- Restructuring large portions of the document\n- Patch fails (old_string not found or matches multiple locations)\n\n**Fallback to full update:**\n\n1. Read current content:\n   Tool: mcp__plugin_mermaid-collab_mermaid__get_document\n   Args: { \"project\": \"<cwd>\", \"session\": \"<name>\", \"id\": \"design\" }\n\n2. Modify content as needed (add sections, update decisions, etc.)\n\n3. Write updated content:\n   Tool: mcp__plugin_mermaid-collab_mermaid__update_document\n   Args: { \"project\": \"<cwd>\", \"session\": \"<name>\", \"id\": \"design\", \"content\": \"<full-updated-content>\" }\n\n**Important:** Always read before full update to preserve existing content.\n\n## Exit Criteria\n\n- Each section (200-300 words) presented separately\n- User validated each section\n- All required design areas covered\n\n## Backtracking\n\nCan return to CLARIFYING phase if:\n- User raises new questions\n- Something doesn't make sense\n- Need to gather more context\n\n**Announce:** \"Let me go back and clarify that before continuing the design.\"\n\n## Transition to VALIDATING\n\n**Prerequisites:**\n- Each section (200-300 words) presented separately\n- User validated each section\n\n**Announce:** \"Design sections complete. Let me run the completeness gate.\"\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"brainstorming-designing\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/brainstorming-exploring/SKILL.md": "---\nname: brainstorming-exploring\ndescription: The EXPLORING phase gathers context about the project and forms an initial understanding\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# EXPLORING Phase\n\nThe EXPLORING phase gathers context about the project and forms an initial understanding of what needs to be built.\n\n## Purpose\n\n- Understand the current project state\n- Read relevant files and documentation\n- Check recent git history for context\n- Form an initial list of items/topics to discuss\n\n## Step 0: Query Kodex\n\nBefore reading files, check project knowledge base for relevant context.\n\n### Topic Inference\n\n1. Get current work item from collab-state.json\n2. Extract keywords from item title/description\n3. Build topic candidates:\n   - `{keyword}`\n   - `{keyword}-patterns`\n   - `{keyword}-conventions`\n\n### Query Process\n\n```\nFOR each candidate topic name:\n  Tool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\n  Args: { \"project\": \"<cwd>\", \"name\": \"<candidate>\" }\n\n  IF found: Add to context\n```\n\n### Example\n\nFor work item \"Add user authentication\":\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"authentication\"\n}\n```\n\n### Fallback\n\nIf no topics found from title keywords:\n1. Try keywords from item description\n2. Try removing suffixes (-patterns, -conventions)\n3. Continue to file exploration without Kodex context\n\nDisplay found topics before proceeding to \"Check project state\".\n\n## Process\n\n1. **Check project state:**\n   - Read relevant files (code, docs, configs)\n   - Check recent commits for context\n   - Understand existing architecture\n\n2. **Gather requirements context:**\n   - Review any existing specs or requirements\n   - Understand stakeholder expectations\n   - Identify constraints and dependencies\n\n3. **Form initial item list:**\n   - Create a preliminary list of topics to discuss\n   - Group related items together\n   - Prioritize by importance/dependencies\n\n## Single-Item Mode (EXPLORING)\n\nWhen `currentItem` is set in collab-state.json:\n\n- Read relevant files based on item description\n- Check git history for related changes\n- Gather context specific to this item only\n- Do NOT expand scope beyond this item\n\n## Exit Criteria\n\n- Context gathered from relevant files\n- Initial list of items/topics formed\n- Ready to discuss items one at a time\n\n## Checkpoint: Current State Diagram\n\n**REQUIRED** before proceeding to CLARIFYING:\n\nCreate a diagram showing the current state relevant to this work:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__create_diagram\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"name\": \"current-state-item-N\",\n  \"content\": <flowchart showing existing components/flow>\n}\n```\n\nDisplay: \"Current state diagram: [previewUrl]\"\n\nIf the work item doesn't involve architecture/flow (e.g., pure text changes), create a simple diagram showing the file(s) being modified:\n\n```mermaid\ngraph LR\n    A[File: path/to/file.md] --> B[Section being modified]\n```\n\n## Transition to CLARIFYING\n\n**Prerequisites:**\n- Read relevant files/context\n- Formed initial list of items\n\n**Announce:** \"I've gathered context. Now let me discuss each item with you one at a time.\"\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"brainstorming-exploring\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/brainstorming-validating/SKILL.md": "---\nname: brainstorming-validating\ndescription: The VALIDATING phase runs the completeness gate to ensure design is ready for implementation\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# VALIDATING Phase\n\nThe VALIDATING phase runs the completeness gate to ensure the design is ready for implementation.\n\n## Purpose\n\n- Verify all required sections are present\n- Check for completeness and clarity\n- Ensure no TBDs or ambiguous items remain\n- Gate the transition to rough-draft\n\n## Required Sections\n\nThe design doc must contain all of these:\n\n- [ ] **Problem/Goal** - Clear statement of what we're solving and why\n- [ ] **Key Decisions** - At least one documented decision with rationale\n- [ ] **At least one diagram** - Visual representation of architecture, flow, or UI\n- [ ] **Success Criteria** - Measurable, testable criteria (not \"works well\")\n- [ ] **Out of Scope** - Explicit boundaries on what this work does NOT include\n\n## Gate Check Process\n\n```bash\n# Read design doc\ncat .collab/<name>/documents/design.md\n\n# Verify each required section exists and has content\n# If any section is missing or empty, do NOT proceed\n```\n\nFor each section, verify:\n1. Section header exists\n2. Section has substantive content (not just placeholder text)\n3. Content is specific, not vague\n\n## Single-Item Mode (VALIDATING)\n\nWhen `currentItem` is set in collab-state.json:\n\nCheck item has all required fields filled:\n- Problem/Goal filled\n- Approach filled\n- Success Criteria filled\n\n**If validation fails:** Return to DESIGNING to fill gaps\n\n**If validation passes:**\n\n1. Mark item as documented in workItems:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__get_session_state\n   Args: { \"project\": \"<cwd>\", \"session\": \"<session>\" }\n   ```\n\n   Update the item's status in workItems array:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__update_session_state\n   Args: {\n     \"project\": \"<cwd>\",\n     \"session\": \"<session>\",\n     \"workItems\": [<updated array with item status changed to \"documented\">]\n   }\n   ```\n\n2. Update design doc status:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__patch_document\n   Args: {\n     \"project\": \"<cwd>\",\n     \"session\": \"<session>\",\n     \"id\": \"design\",\n     \"old_string\": \"### Item N: <title>\\n**Type:** <type>\\n**Status:** pending\",\n     \"new_string\": \"### Item N: <title>\\n**Type:** <type>\\n**Status:** documented\"\n   }\n   ```\n\n3. Display: \"Item documented. Returning to work item loop.\"\n\n**Important:** In single-item mode, do NOT:\n- Run the full completeness gate\n- Transition to rough-draft\n\n## If Gate Fails\n\n1. Identify which sections are incomplete\n2. List the specific gaps found\n3. Return to DESIGNING phase to fill gaps\n4. Do NOT proceed to rough-draft until all sections pass\n\n**Example failure message:**\n```\nCompleteness gate failed:\n\nMissing or incomplete:\n- [ ] Key Decisions - No decisions documented\n- [ ] Out of Scope - Section is empty\n\nReturning to DESIGNING phase to address these gaps.\n```\n\n## If Gate Passes\n\nShow summary and ask for confirmation:\n\n```\nBrainstorming complete. Design covers:\n- [Bullet 1: key topic from design]\n- [Bullet 2: key topic from design]\n- [Bullet 3: key topic from design]\n\nReady to move to rough-draft?\n\n1. Yes\n2. No\n```\n\n**Response handling:**\n- **1 (Yes)**: Transition to rough-draft (invoke brainstorming-transition skill)\n- **2 (No)**: Ask what else needs to be explored, return to appropriate phase\n\n## Browser-Based Confirmation\n\nWhen collab session is active, use render_ui for the confirmation:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Confirm\" },\n    \"children\": [{\n      \"type\": \"Markdown\",\n      \"props\": { \"content\": \"Do you want to proceed?\" }\n    }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\nResponse: `{ \"action\": \"yes\" }` or `{ \"action\": \"no\" }`\n\n## Exit Criteria\n\n- All required sections present and complete\n- No TBDs or \"figure out later\" items\n- User confirmed ready to proceed\n\n## Transition to Rough-Draft\n\n**Prerequisites:**\n- Completeness checklist passed\n- User confirmed ready\n\n**Announce:** \"Completeness gate passed. Transitioning to rough-draft skill.\"\n\n**Invoke skill:** brainstorming-transition\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"brainstorming-validating\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/collab-cleanup/SKILL.md": "---\nname: collab-cleanup\ndescription: Close out a collab session - archive or delete design artifacts\nuser-invocable: false\n---\n\n# Collab Cleanup\n\n## Browser-Based Questions\n\nWhen a collab session is active, use `render_ui` for all user interactions.\n\n**Component selection:**\n| Question Type | Component |\n|--------------|-----------|\n| Yes/No | Card with action buttons |\n| Choose 1 of 2-5 | RadioGroup |\n| Choose 1 of 6+ | MultipleChoice |\n| Free text | TextInput or TextArea |\n\n**Example - Yes/No:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"<question context>\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"<question>\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n**Terminal prompts only when:** No collab session exists (pre-session selection).\n\n## Overview\n\nClose a collab session after development is complete. Offers choices to archive design artifacts, delete them, or keep the session open for reference.\n\n**Announce at start:** \"I'm using the collab-cleanup skill to close this session.\"\n\n## Workflow\n\n### Step 1: Identify Current Session\n\n1. Call `mcp__plugin_mermaid-collab_mermaid__list_sessions` to get all sessions across projects:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__list_sessions\n   Args: {}\n   ```\n2. Filter results to current project (match `project` field against absolute cwd path)\n3. If sessions found for current project:\n   - For each session, fetch phase via `mcp__plugin_mermaid-collab_mermaid__get_session_state`:\n     ```\n     Tool: mcp__plugin_mermaid-collab_mermaid__get_session_state\n     Args: { \"project\": \"<cwd>\", \"session\": \"<session-name>\" }\n     ```\n   - Display list with phases:\n     ```\n     Sessions in this project:\n     1. glowing-sunny-mesa (phase: rough-draft)\n     2. bright-calm-river (phase: implementation)\n     ```\n   - Ask: \"Which session to clean up?\" (or if only one, confirm it)\n4. If no sessions for current project:\n   - Display: \"No collab sessions found in this project.\"\n   - Exit\n\n### Step 2: Show Session Summary\n\nDisplay session details:\n\n```\nSession: [name]\nTemplate: [feature/bugfix/refactor/spike]\nPhase: [current phase]\n\nArtifacts:\n- Documents: [list .md files]\n- Diagrams: [list .mmd files]\n```\n\n### Step 3: Ask User Choice\n\n```\nWhat would you like to do with the design artifacts?\n\n1. Archive - Copy to docs/designs/[session-name]/\n2. Delete - Remove without saving\n3. Keep - Leave session in place, exit without cleanup\n4. Archive & Continue - Archive with timestamp, reset session for new work\n```\n\n### Step 4: Execute Choice\n\n**If Archive:**\n1. Call the archive_session MCP tool:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__archive_session\n   Args: { \"project\": \"<cwd>\", \"session\": \"<session-name>\" }\n   ```\n2. The tool will:\n   - Create `docs/designs/[session-name]/` directory\n   - Copy all documents from `.collab/sessions/[session]/documents/*`\n   - Copy all diagrams from `.collab/sessions/[session]/diagrams/*`\n   - Delete the `.collab/sessions/[session]/` folder\n3. Report what was archived based on the tool's response (archivedFiles.documents and archivedFiles.diagrams)\n\n**If Delete:**\n1. Confirm: \"Delete session [name]? This cannot be undone.\"\n   ```\n   1. Yes, delete\n   2. No, go back\n   ```\n2. If **1 (Yes)**: Delete `.collab/[session]/` folder\n3. If **2 (No)**: Return to Step 3\n\n**If Keep:**\n1. Exit without changes\n2. Remind user: \"Session kept open. Run `/collab-cleanup` when ready to close.\"\n\n**If Archive & Continue:**\n1. Call the archive_session MCP tool with timestamp option:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__archive_session\n   Args: {\n     \"project\": \"<cwd>\",\n     \"session\": \"<session-name>\",\n     \"delete_session\": false,\n     \"timestamp\": true\n   }\n   ```\n2. Clear Work Items section in `.collab/sessions/[session]/documents/design.md`:\n   - Keep \"## Session Context\" and its content intact\n   - Replace \"## Work Items\" section with empty placeholder\n3. Reset collab state via MCP:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__update_session_state\n   Args: {\n     \"project\": \"<absolute-path-to-cwd>\",\n     \"session\": \"<session-name>\",\n     \"phase\": \"brainstorming\",\n     \"currentItem\": null\n   }\n   ```\n   Note: `lastActivity` is automatically updated by the MCP tool.\n4. Report archive path from tool response: \"Session `[name]` archived to `[archivePath]`. Session reset for new work.\"\n5. Loop back to `gather-session-goals` skill to start work on new items\n\n### Step 5: Confirm\n\nDisplay completion message:\n\n- Archive: \"Session `[name]` archived to `docs/designs/[name]/`\"\n- Delete: \"Session `[name]` deleted.\"\n- Keep: \"Session `[name]` kept open.\"\n- Archive & Continue: \"Session `[name]` archived to `docs/designs/[name]-[timestamp]/`. Ready for new work items.\"\n\n## Integration\n\n**Called by:**\n- `finishing-a-development-branch` skill at completion\n- User directly via `/collab-cleanup` command\n\n**Collab workflow position:**\n```\ncollab → brainstorming → rough-draft → executing-plans → finishing-a-development-branch → collab-cleanup\n                                                                                              ↑\n                                                                                        (you are here)\n```\n\n## Common Mistakes\n\n### Archiving without checking contents\n- **Problem:** Archived files might be incomplete or contain sensitive info\n- **Fix:** Always show session summary before archiving\n\n### Deleting active session\n- **Problem:** User accidentally deletes session they're still working on\n- **Fix:** Confirm deletion, check if phase is not \"implementation\"\n\n## Red Flags\n\n**Never:**\n- Delete without confirmation\n- Archive to a location that already exists (overwrite)\n- Clean up if there are pending verification issues\n\n**Always:**\n- Show session summary before action\n- Confirm destructive actions\n- Report what was done\n",
        "skills/collab-clear/skill.md": "---\nname: collab-clear\ndescription: Ask user about clearing context, then proceed to next skill\nuser-invocable: true\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read\n---\n\n# Collab Clear\n\nAsks user whether to clear context before proceeding.\n\n## Step 1: Ask User\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Context Management\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"Clear context and start fresh?\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes, clear\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No, continue\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\nIf UI times out, ask in terminal.\n\n## Step 2: Get Next Skill\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"collab-clear\" }\n```\n\n## Step 3: Handle Choice\n\n**If user chose \"Yes, clear\":**\n1. Save snapshot with next_skill as activeSkill\n2. Update state: hasSnapshot = true\n3. Display: \"Context saved. Triggering /clear...\"\n4. Invoke /clear (user will run /collab to resume)\n\n**If user chose \"No, continue\":**\n1. Invoke result.next_skill directly (skip the clear)\n",
        "skills/collab-compact/skill.md": "---\nname: collab-compact\ndescription: Save context and trigger compaction for clean resume\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read\nuser-invocable: true\n---\n\n# Collab Compact\n\nSave current collab session context and trigger compaction for a clean context resume.\n\n## When to Use\n\n- Context is getting large and compaction is approaching\n- Before a long break in the session\n- Proactively to ensure clean state\n\n## Process\n\n### Step 1: Verify Active Session\n\n```bash\nls -d .collab/*/ 2>/dev/null | xargs -I{} basename {}\n```\n\nIf no sessions: \"No active collab session. Use /collab first.\" STOP.\nIf multiple sessions: Ask user which session.\n\n### Step 2: Save Context Snapshot\n\nRead current state via MCP:\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_session_state\nArgs: { \"project\": \"<absolute-path-to-cwd>\", \"session\": \"<session-name>\" }\n```\nReturns: `{ \"phase\": \"...\", \"currentItem\": ..., ... }`\n\nDetermine activeSkill from phase:\n- \"brainstorming\" → activeSkill = \"brainstorming\"\n- \"rough-draft/*\" → activeSkill = \"rough-draft\"\n- \"implementation\" → activeSkill = \"executing-plans\"\n\nSave snapshot via MCP:\n```\nTool: mcp__plugin_mermaid-collab_mermaid__save_snapshot\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"activeSkill\": \"<determined-skill>\",\n  \"currentStep\": \"<phase-from-state>\",\n  \"inProgressItem\": <currentItem-from-state>,\n  \"pendingQuestion\": null,\n  \"recentContext\": []\n}\n```\nNote: `version` and `timestamp` are automatically added by the MCP tool.\n\n### Step 3: Update State\n\nUpdate collab state via MCP:\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: { \"project\": \"<absolute-path-to-cwd>\", \"session\": \"<session-name>\", \"hasSnapshot\": true }\n```\n\n### Step 4: Trigger Compaction\n\n```\nContext snapshot saved to .collab/<session>/context-snapshot.json\n\nTriggering compaction now...\n```\n\nInvoke the /compact command.\n\n### Step 5: Auto-Resume Session\n\nAfter compaction, automatically resume the session:\n\n```\nCompaction complete. Resuming session...\n```\n\nInvoke skill: collab\n\nThis will restore context from the snapshot and continue where you left off.\n\n## Context Full Detection\n\nWhen context usage is high before triggering compaction, render an Alert to notify the user:\n\n**Tool call:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"ui\": {\n    \"type\": \"Alert\",\n    \"props\": {\n      \"type\": \"warning\",\n      \"title\": \"Context Full\",\n      \"message\": \"Run /compact in terminal, then /collab to resume.\"\n    }\n  },\n  \"blocking\": false\n}\n```\n\nThis provides a non-blocking visual notification without interrupting the skill execution.\n",
        "skills/collab/SKILL.md": "---\nname: collab\ndescription: Start or resume a collab session - session management only\nuser-invocable: true\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep, Bash\n---\n\n# Collab Sessions\n\nEntry point for collab workflow. Handles session management and delegates to MCP state machine.\n\n## Step 1: Check Server\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__check_server_health\nArgs: {}\n```\n\nIf not healthy: \"Server not running. Start with: bun run bin/mermaid-collab.ts start\"\n**STOP** if server not running.\n\n## Step 2: Find/Create Session\n\nList sessions for this project:\n```\nTool: mcp__plugin_mermaid-collab_mermaid__list_sessions\nArgs: {}\n```\n\n**If sessions exist:** Present list with \"Create new\" option\n**If no sessions:** Go to Step 3\n\n## Step 3: Create New Session\n\n1. Generate name: `mcp__plugin_mermaid-collab_mermaid__generate_session_name()`\n2. Ask user to confirm or pick own name\n3. Initialize state:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__update_session_state\n   Args: { \"project\": \"<cwd>\", \"session\": \"<name>\", \"phase\": \"initialize\", \"currentItem\": null }\n   ```\n4. Get first skill from state machine:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__complete_skill\n   Args: { \"project\": \"<cwd>\", \"session\": \"<name>\", \"skill\": \"collab-start\" }\n   ```\n5. Invoke: result.next_skill\n\n## Step 4: Resume Existing Session\n\n1. Get session state: `mcp__plugin_mermaid-collab_mermaid__get_session_state()`\n2. Check for snapshot:\n   - If snapshot exists: Load it, delete it, invoke snapshot.activeSkill\n   - If no snapshot: Call complete_skill with current phase's skill, invoke result.next_skill\n\n## No Manual Routing\n\nThis skill does NOT:\n- Route by item type (MCP state machine does this)\n- Invoke brainstorming/rough-draft directly (complete_skill returns next skill)\n- Manage the work item loop (routing nodes handle this)\n",
        "skills/dispatching-parallel-agents/SKILL.md": "---\nname: dispatching-parallel-agents\ndescription: Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep, Task\n---\n\n# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Multiple failures?\" [shape=diamond];\n    \"Are they independent?\" [shape=diamond];\n    \"Single agent investigates all\" [shape=box];\n    \"One agent per problem domain\" [shape=box];\n    \"Can they work in parallel?\" [shape=diamond];\n    \"Sequential agents\" [shape=box];\n    \"Parallel dispatch\" [shape=box];\n\n    \"Multiple failures?\" -> \"Are they independent?\" [label=\"yes\"];\n    \"Are they independent?\" -> \"Single agent investigates all\" [label=\"no - related\"];\n    \"Are they independent?\" -> \"Can they work in parallel?\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Parallel dispatch\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Sequential agents\" [label=\"no - shared state\"];\n}\n```\n\n**Use when:**\n- 3+ test files failing with different root causes\n- Multiple subsystems broken independently\n- Each problem can be understood without context from others\n- No shared state between investigations\n\n**Don't use when:**\n- Failures are related (fix one might fix others)\n- Need to understand full system state\n- Agents would interfere with each other\n\n## The Pattern\n\n### 1. Identify Independent Domains\n\nGroup failures by what's broken:\n- File A tests: Tool approval flow\n- File B tests: Batch completion behavior\n- File C tests: Abort functionality\n\nEach domain is independent - fixing tool approval doesn't affect abort tests.\n\n### 2. Create Focused Agent Tasks\n\nEach agent gets:\n- **Specific scope:** One test file or subsystem\n- **Clear goal:** Make these tests pass\n- **Constraints:** Don't change other code\n- **Expected output:** Summary of what you found and fixed\n\n### 3. Dispatch in Parallel\n\n```typescript\n// In Claude Code / AI environment\nTask(\"Fix agent-tool-abort.test.ts failures\")\nTask(\"Fix batch-completion-behavior.test.ts failures\")\nTask(\"Fix tool-approval-race-conditions.test.ts failures\")\n// All three run concurrently\n```\n\n### 4. Review and Integrate\n\nWhen agents return:\n- Read each summary\n- Verify fixes don't conflict\n- Run full test suite\n- Integrate all changes\n\n## Agent Prompt Structure\n\nGood agent prompts are:\n1. **Focused** - One clear problem domain\n2. **Self-contained** - All context needed to understand the problem\n3. **Specific about output** - What should the agent return?\n\n```markdown\nFix the 3 failing tests in src/agents/agent-tool-abort.test.ts:\n\n1. \"should abort tool with partial output capture\" - expects 'interrupted at' in message\n2. \"should handle mixed completed and aborted tools\" - fast tool aborted instead of completed\n3. \"should properly track pendingToolCount\" - expects 3 results but gets 0\n\nThese are timing/race condition issues. Your task:\n\n1. Read the test file and understand what each test verifies\n2. Identify root cause - timing issues or actual bugs?\n3. Fix by:\n   - Replacing arbitrary timeouts with event-based waiting\n   - Fixing bugs in abort implementation if found\n   - Adjusting test expectations if testing changed behavior\n\nDo NOT just increase timeouts - find the real issue.\n\nReturn: Summary of what you found and what you fixed.\n```\n\n## Common Mistakes\n\n**❌ Too broad:** \"Fix all the tests\" - agent gets lost\n**✅ Specific:** \"Fix agent-tool-abort.test.ts\" - focused scope\n\n**❌ No context:** \"Fix the race condition\" - agent doesn't know where\n**✅ Context:** Paste the error messages and test names\n\n**❌ No constraints:** Agent might refactor everything\n**✅ Constraints:** \"Do NOT change production code\" or \"Fix tests only\"\n\n**❌ Vague output:** \"Fix it\" - you don't know what changed\n**✅ Specific:** \"Return summary of root cause and changes\"\n\n## When NOT to Use\n\n**Related failures:** Fixing one might fix others - investigate together first\n**Need full context:** Understanding requires seeing entire system\n**Exploratory debugging:** You don't know what's broken yet\n**Shared state:** Agents would interfere (editing same files, using same resources)\n\n## Real Example from Session\n\n**Scenario:** 6 test failures across 3 files after major refactoring\n\n**Failures:**\n- agent-tool-abort.test.ts: 3 failures (timing issues)\n- batch-completion-behavior.test.ts: 2 failures (tools not executing)\n- tool-approval-race-conditions.test.ts: 1 failure (execution count = 0)\n\n**Decision:** Independent domains - abort logic separate from batch completion separate from race conditions\n\n**Dispatch:**\n```\nAgent 1 → Fix agent-tool-abort.test.ts\nAgent 2 → Fix batch-completion-behavior.test.ts\nAgent 3 → Fix tool-approval-race-conditions.test.ts\n```\n\n**Results:**\n- Agent 1: Replaced timeouts with event-based waiting\n- Agent 2: Fixed event structure bug (threadId in wrong place)\n- Agent 3: Added wait for async tool execution to complete\n\n**Integration:** All fixes independent, no conflicts, full suite green\n\n**Time saved:** 3 problems solved in parallel vs sequentially\n\n## Key Benefits\n\n1. **Parallelization** - Multiple investigations happen simultaneously\n2. **Focus** - Each agent has narrow scope, less context to track\n3. **Independence** - Agents don't interfere with each other\n4. **Speed** - 3 problems solved in time of 1\n\n## Verification\n\nAfter agents return:\n1. **Review each summary** - Understand what changed\n2. **Check for conflicts** - Did agents edit same code?\n3. **Run full suite** - Verify all fixes work together\n4. **Spot check** - Agents can make systematic errors\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- 6 failures across 3 files\n- 3 agents dispatched in parallel\n- All investigations completed concurrently\n- All fixes integrated successfully\n- Zero conflicts between agent changes\n",
        "skills/executing-plans-execution/SKILL.md": "---\nname: executing-plans-execution\ndescription: Detailed execution logic for the executing-plans skill\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - Edit\n  - Write\n  - Task\n  - AskUserQuestion\n  - update_task_status\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# Execution Phase Details\n\nThis document contains detailed execution logic for the executing-plans skill.\n\n## Step 2: Execute Batch\n\n**Default: First 3 tasks** (or use dependency graph for collab workflow)\n\n### Standard Execution (No Dependency Graph)\n\nFor each task:\n1. Call `update_task_status` with `status: \"in_progress\"` to mark task start\n2. Follow each step exactly (plan has bite-sized steps)\n3. Run verifications as specified\n4. Call `update_task_status` with `status: \"completed\"` to mark task completion (or `status: \"failed\"` if verification fails)\n\n### Step 2.1: Per-Task Execution with Item Type Routing\n\nBefore executing each task, determine its item type and follow the appropriate execution path.\n\n**Determine Item Type:**\n1. Read design doc\n2. Find the work item that this task belongs to\n3. Check the `Type:` field from the work item\n4. Map to execution flow\n\n**Routing Logic:**\n\n```\nFUNCTION executeTask(task, itemType):\n  CALL update_task_status(project, session, task.id, \"in_progress\")\n\n  IF itemType == \"task\":\n    # Skip TDD for operational tasks\n    EXECUTE task steps directly (from task-planning Prerequisites/Steps/Verification)\n    RUN verification checks\n    IF verification passes:\n      CALL update_task_status(project, session, task.id, \"completed\")\n    ELSE:\n      CALL update_task_status(project, session, task.id, \"failed\")\n  ELSE IF itemType IN [\"code\", \"bugfix\"]:\n    # Normal TDD flow\n    INVOKE test-driven-development skill\n    WRITE failing test\n    IMPLEMENT code per design spec\n    VERIFY test passes\n    IF verification passes:\n      CALL update_task_status(project, session, task.id, \"completed\")\n    ELSE:\n      CALL update_task_status(project, session, task.id, \"failed\")\n  ELSE:\n    CALL update_task_status(project, session, task.id, \"failed\")\n    STOP - unknown item type, ask user\n```\n\n**For Task Type Items:**\n1. Execute prerequisites validation (verify all prerequisites exist)\n2. Execute each step in order (run commands/actions)\n3. Run verification checks (confirm success)\n4. Mark task as complete\n\n**For Code/Bugfix Type Items:**\n1. Invoke test-driven-development skill\n2. Work through red-green-refactor cycle\n3. Mark task as complete\n\n### Dependency-Aware Execution (Collab Workflow)\n\nWhen a task dependency graph is present, use intelligent parallel dispatch:\n\n**Find Ready Tasks:**\n```\nready_tasks = tasks where:\n  - status is \"pending\"\n  - all depends-on tasks are in \"completed\"\n```\n\n**Parallel Dispatch Logic:**\n1. From ready tasks, identify parallel-safe group:\n   - Tasks explicitly marked `parallel: true`\n   - OR tasks with no file overlap and no shared dependencies\n2. If multiple parallel-safe tasks exist:\n   - For each task, call `update_task_status` with `status: \"in_progress\"`\n   - **REQUIRED:** Spawn Task agents in parallel (single message, multiple tool calls)\n   - Each Task agent MUST invoke `mermaid-collab:subagent-driven-development:implementer-prompt` skill\n   - Each Task agent MUST call `update_task_status` with `status: \"completed\"` or `status: \"failed\"` when done\n   - Task prompt includes: task ID, files, description, relevant pseudocode\n   - Wait for all agents to complete\n3. If only sequential tasks remain:\n   - Execute one at a time in topological order\n   - For each task: call `update_task_status` with `status: \"in_progress\"` at start, then `status: \"completed\"` or `status: \"failed\"` at end\n\n**RED FLAG - INLINE IMPLEMENTATION:**\nIf you find yourself using Edit/Write tools directly on source files instead of spawning Task agents, you are violating the subagent requirement. STOP and use Task tool instead.\n\n### Task Agent Prompt Template (Collab Workflow)\n\n```\nYou are implementing a task from the collab workflow.\n\n## Design Document Location\nCollab Session: .collab/<session-name>\n\n**Per-item documents (read these for your task's context):**\n- Interface: .collab/<session-name>/documents/interface-item-<N>.md\n- Pseudocode: .collab/<session-name>/documents/pseudocode-item-<N>.md\n- Skeleton: .collab/<session-name>/documents/skeleton-item-<N>.md\n\n## REQUIRED: Read Per-Item Documents First\nBefore implementing, read the per-item documents for your work item:\n1. Read interface-item-<N>.md → function signatures, types, file paths\n2. Read pseudocode-item-<N>.md → step-by-step logic for your task\n3. Read skeleton-item-<N>.md → task graph and planned files\n\nThese documents are the SOURCE OF TRUTH. Follow them exactly.\n\n## Task Details\nTask ID: <task-id>\nItem Number: <item-number>\nFiles: <task-files>\nDescription: <task-description>\n\n## Your Task's Design Spec\nInterface:\n<paste from interface-item-<N>.md>\n\nPseudocode:\n<paste from pseudocode-item-<N>.md>\n\n## Instructions\n1. Read the per-item documents above\n2. Implement EXACTLY as specified - no interpretation\n3. Write tests\n4. Report what you implemented\n```\n\n### Task Prompt with Test Patterns\n\nWhen dispatching tasks, include the `tests` field in the prompt:\n\n```\n## Targeted Tests\n\nDuring TDD (RED-GREEN-REFACTOR), run ONLY these tests:\n{task.tests}\n\nCommand: npm run test:ci -- {tests joined by space}\n\nDo NOT run the full test suite during TDD cycles.\n```\n\n### Task Status Management\n\nUse the `update_task_status` tool to track task progress. This enables real-time task graph visualization and WebSocket broadcasts.\n\n**When task starts:**\n```\nTool: update_task_status\nArgs: {\n  project: <project-path>,\n  session: <session-name>,\n  taskId: <task-id>,\n  status: \"in_progress\"\n}\n```\n\n**When task completes successfully:**\n```\nTool: update_task_status\nArgs: {\n  project: <project-path>,\n  session: <session-name>,\n  taskId: <task-id>,\n  status: \"completed\"\n}\n```\n\n**When task fails:**\n```\nTool: update_task_status\nArgs: {\n  project: <project-path>,\n  session: <session-name>,\n  taskId: <task-id>,\n  status: \"failed\"\n}\n```\n\n**Benefits:**\n- Each status change triggers diagram regeneration\n- WebSocket broadcast keeps UI in sync in real-time\n- No more batch-only updates - status changes are immediate and granular\n\n### Task Completion Handling\n\nWhen a task completes:\n1. Call `update_task_status` with `status: \"completed\"` to record completion\n2. Check what tasks are now unblocked (their `depends-on` all satisfied)\n3. Add newly unblocked tasks to the ready queue\n4. Repeat until all tasks done\n\n### Wave Completion Checkpoint\n\nAfter all tasks in a wave complete:\n\n1. Run full test suite:\n   ```bash\n   npm run test:ci\n   ```\n\n2. If tests fail:\n   ```\n   Full test suite failed after wave completion.\n   Investigate failures before proceeding to next wave.\n   ```\n   STOP and report.\n\n3. If tests pass:\n   ```\n   Full test suite passed. Proceeding to next wave.\n   ```\n\n**Example Execution Flow:**\n```\nWave 1: [auth-types, utils] (parallel: true) → dispatch together\n  ↓ both complete\nWave 2: [auth-service] (depends-on: auth-types) → dispatch\n  ↓ complete\nWave 3: [auth-middleware] (depends-on: auth-service) → dispatch\n```\n",
        "skills/executing-plans-review/SKILL.md": "---\nname: executing-plans-review\ndescription: Verification, drift detection, and snapshot logic for executing-plans\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - Edit\n  - Write\n  - Task\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# Verification and Review Phase Details\n\nThis document contains detailed verification, drift detection, and snapshot logic for the executing-plans skill.\n\n## Snapshot Saving\n\nSave context snapshots to enable recovery after compaction events. This preserves the executing-plans skill's state and progress across context compaction.\n\n### When to Save\n\nCall `saveSnapshot()` at these critical points:\n- After each wave of tasks completes\n- After full test suite passes (post-wave verification)\n- After each individual task completes (per-task verification)\n- Before asking for user feedback\n- At major milestones (all tasks complete)\n\n### Save Function\n\n```javascript\nFUNCTION saveSnapshot():\n  session = current session name\n\n  // Read current state via MCP\n  Tool: mcp__plugin_mermaid-collab_mermaid__get_session_state\n  Args: { \"project\": \"<cwd>\", \"session\": session }\n  Returns: state = { \"phase\": \"...\", \"completedTasks\": [...], \"pendingTasks\": [...], ... }\n\n  // Save snapshot via MCP\n  Tool: mcp__plugin_mermaid-collab_mermaid__save_snapshot\n  Args: {\n    \"project\": \"<cwd>\",\n    \"session\": session,\n    \"activeSkill\": \"executing-plans\",\n    \"currentStep\": \"implementation\",\n    \"inProgressItem\": null,\n    \"pendingQuestion\": null,\n    \"recentContext\": [\n      {\n        \"type\": \"progress\",\n        \"content\": \"Completed tasks: {state.completedTasks}. Pending: {state.pendingTasks}. Last wave: {wave number}\"\n      }\n    ]\n  }\n  // Note: version and timestamp are automatically added\n\n  // Update collab state to mark snapshot exists\n  Tool: mcp__plugin_mermaid-collab_mermaid__update_session_state\n  Args: {\n    \"project\": \"<cwd>\",\n    \"session\": session,\n    \"hasSnapshot\": true,\n    \"lastSnapshot\": \"<current-ISO-timestamp>\"\n  }\n```\n\n### Save Points with Examples\n\n**After wave completes with test suite passing:**\n```\n[Wave N tasks all complete]\n-> Run full test suite: npm run test:ci\n-> If tests FAIL: Stop, report failure (don't save)\n-> If tests PASS:\n   - saveSnapshot()\n   - Update task diagram (all Wave N tasks -> \"completed\")\n   - Show wave completion report\n   - Proceed to next wave\n```\n\nExample snapshot after Wave 1:\n```json\n{\n  \"version\": 1,\n  \"timestamp\": \"2026-01-21T14:35:22Z\",\n  \"activeSkill\": \"executing-plans\",\n  \"currentStep\": \"implementation\",\n  \"completedTasks\": [\"task-planning-skill\", \"gather-goals-types\", \"brainstorming-cleanup\"],\n  \"pendingTasks\": [\"collab-routing\", \"executing-plans-tdd-skip\", \"pre-compact-script\"],\n  \"recentContext\": [\n    {\n      \"type\": \"progress\",\n      \"content\": \"Completed tasks: task-planning-skill, gather-goals-types, brainstorming-cleanup. Pending: 3 tasks. Last wave: 1\"\n    }\n  ]\n}\n```\n\n**After each task completes (per-task verification):**\n```\n[Task execution completes]\n-> Compare implementation against design doc\n-> Check for drift\n-> If verification PASSES:\n   - saveSnapshot() with updated completedTasks list\n   - Unlock dependent tasks\n   - Proceed to next ready task\n-> If verification FAILS:\n   - Keep task as in_progress\n   - Request fixes before saving\n```\n\n**Before batch completion report:**\n```\n[All ready tasks complete, about to report to user]\n-> saveSnapshot()\n-> Show progress report with completed tasks\n-> Show which tasks are ready next\n-> Wait for user feedback\n```\n\n**At final completion:**\n```\n[All tasks complete and verified]\n-> saveSnapshot()\n-> Show implementation summary\n-> Invoke finishing-a-development-branch skill\n-> (After finishing-a-development-branch completes: cleanup collab session)\n```\n\n## Step 2.5: Per-Task Verification (Collab Workflow)\n\nWhen within a collab workflow, run verification after each task completes:\n\n**Verification Steps:**\n1. After task completion, trigger `verify-phase` hook (if available)\n2. Compare task output against design doc specification\n3. Check for drift:\n   - Are implemented interfaces matching design?\n   - Any undocumented additions?\n   - Missing components?\n\n**On Verification Success:**\n- Mark task as verified\n- Update `collab-state.json`: move task from `pendingTasks` to `completedTasks`\n- Update `lastActivity` timestamp\n- Unlock dependent tasks\n- Proceed to next ready tasks\n\n```javascript\nFUNCTION markTaskComplete(taskId):\n  session = current session name\n\n  // 1. Read current state\n  Tool: mcp__plugin_mermaid-collab_mermaid__get_session_state\n  Args: { \"project\": \"<cwd>\", \"session\": session }\n  Returns: state = { \"completedTasks\": [...], \"pendingTasks\": [...], ... }\n\n  // 2. Move task from pending to completed\n  newCompleted = [...state.completedTasks, taskId]\n  newPending = state.pendingTasks.filter(t => t !== taskId)\n\n  // 3. Update session state via MCP (updates progress bar)\n  Tool: mcp__plugin_mermaid-collab_mermaid__update_session_state\n  Args: {\n    \"project\": \"<cwd>\",\n    \"session\": session,\n    \"completedTasks\": newCompleted,\n    \"pendingTasks\": newPending\n  }\n\n  // 4. Update task execution diagram (visual progress)\n  // Change from executing (blue) to completed (green)\n  Tool: mcp__plugin_mermaid-collab_mermaid__patch_diagram\n  Args: {\n    \"project\": \"<cwd>\",\n    \"session\": session,\n    \"id\": \"task-execution\",\n    \"old_string\": \"style {taskId} fill:#bbdefb,stroke:#1976d2,stroke-width:3px\",  // executing\n    \"new_string\": \"style {taskId} fill:#c8e6c9,stroke:#2e7d32\"                    // completed\n  }\n  // If patch fails (task wasn't marked executing), try from waiting state:\n  // old_string: \"style {taskId} fill:#e0e0e0,stroke:#9e9e9e\"  // waiting\n```\n\n**IMPORTANT:** You MUST call `markTaskComplete(taskId)` after each task passes verification. This:\n1. Updates the progress bar in the UI (completedTasks/pendingTasks)\n2. Updates the task execution diagram (visual green checkmark)\n\n**On Verification Failure:**\n- Keep task as `in_progress` (not completed)\n- Show drift report with pros/cons\n- Ask user: accept drift, reject and fix, or review each\n- If drift accepted: update design doc, then unlock dependents\n- If drift rejected: fix implementation before proceeding\n\n**Unlocking Dependents:**\n```\nfor each task T where T.depends-on includes completed_task:\n  if all(T.depends-on) are completed:\n    move T from pending to ready\n```\n\n## Step 2.6: Drift Detection\n\nAfter implementer reports completion, check for drift:\n\n### Step 1: Read design doc and implementation\n\n1. Read design doc:\n   Tool: mcp__plugin_mermaid-collab_mermaid__get_document\n   Args: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"id\": \"design\" }\n\n2. Read implemented files (from task's file list)\n\n### Step 2: Compare implementation to design\n\nFOR each function/type in the task's Interface section:\n  Compare:\n    - Function name matches?\n    - Parameter names and types match?\n    - Return type matches?\n    - Logic follows Pseudocode steps?\n\n  IF mismatch found:\n    ADD to drift_list: {\n      type: \"signature\" | \"logic\" | \"scope\" | \"missing\",\n      design_says: <from design doc>,\n      implementation_has: <from code>,\n      file: <file path>,\n      line: <line number if applicable>\n    }\n\n### Step 3: If drift detected, analyze and present\n\nIF drift_list is not empty:\n  FOR each drift in drift_list:\n\n    Analyze:\n      severity = assess_severity(drift)  // contract vs detail\n      intent = assess_intent(drift)      // improvement vs misunderstanding\n      precedent = assess_precedent(drift) // will this encourage more drift?\n      reversibility = assess_reversibility(drift)\n\n    Generate pros:\n      - [benefit of keeping this change]\n      - [another benefit if applicable]\n\n    Generate cons:\n      - [drawback of keeping this change]\n      - [another drawback if applicable]\n\n    Determine recommendation:\n      IF drift.type == \"signature\": recommend = \"REJECT\"\n      ELSE IF drift.type == \"logic\" AND same_result: recommend = \"ACCEPT\"\n      ELSE IF drift.type == \"scope\": recommend = \"REJECT\"\n      ELSE IF drift.type == \"missing\": recommend = \"REJECT\"\n\n    Present to user:\n      ```\n      DRIFT DETECTED in task [task-id]:\n\n      ## What Changed\n      | Type | Design Says | Implementation Has |\n      |------|-------------|-------------------|\n      | {drift.type} | {drift.design_says} | {drift.implementation_has} |\n\n      ## Analysis\n\n      **Pros of keeping this change:**\n      - {pro1}\n      - {pro2}\n\n      **Cons of keeping this change:**\n      - {con1}\n      - {con2}\n\n      **Suggested choice:** {recommend}\n      **Reasoning:** {explanation based on severity, intent, precedent, reversibility}\n\n      ## Your Decision\n      1. Reject - revert and re-implement per design\n      2. Accept - update design doc to include this change\n      3. Discuss - need more context before deciding\n      ```\n\n### Step 4: Handle user decision\n\nIF user chooses \"Reject\":\n  - Do NOT mark task as complete\n  - Tell implementer to re-implement per design\n  - Return to Step 2 (re-execute task)\n\nIF user chooses \"Accept\":\n  - Read current design doc\n  - Update relevant section to match implementation\n  - Write updated design doc via MCP\n  - Log decision in Decision Log section\n  - Mark task as complete\n  - Proceed to next task\n\nIF user chooses \"Discuss\":\n  - Pause execution\n  - Gather more context from user\n  - Re-present options after discussion\n\n### Step 5: No drift case\n\nIF drift_list is empty:\n  - Mark task as complete\n  - Proceed to next task\n\n## Proposing Design Doc Changes\n\nWhen drift is detected and requires a design doc update, use the proposed tag:\n\n**For section-level changes:**\n```markdown\n<!-- status: proposed: <drift-description> -->\n<new-section-content>\n```\n\n**For inline changes:**\n```markdown\n<!-- propose-start: <drift-description> --><new-text><!-- propose-end -->\n```\n\n**Process:**\n1. Identify the unique text at the insertion point\n2. Use patch to insert proposed content:\n   ```\n   Tool: mcp__plugin_mermaid-collab_mermaid__patch_document\n   Args: {\n     \"project\": \"<cwd>\",\n     \"session\": \"<session>\",\n     \"id\": \"design\",\n     \"old_string\": \"<unique text at insertion point>\",\n     \"new_string\": \"<unique text><!-- propose-start: description --><content><!-- propose-end -->\"\n   }\n   ```\n3. If patch fails (not unique), fall back to full update:\n   `mcp__plugin_mermaid-collab_mermaid__update_document({ \"id\": \"design\", \"content\": <updated> })`\n4. Notify user: \"Proposed change visible in design doc (cyan). Accept/reject in mermaid-collab UI.\"\n5. Wait for user decision before proceeding\n\n**After user decision:**\n- If accepted: proposed marker removed, content remains -> continue execution\n- If rejected: content removed -> address the drift differently or stop\n",
        "skills/executing-plans/SKILL.md": "---\nname: executing-plans\ndescription: Use when executing implementation plans with independent tasks in the current session\nuser-invocable: false\nmodel: haiku\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep, Task\n---\n\n## Collab Session Required\n\nBefore proceeding, check for active collab session:\n\n1. Check if `.collab/` directory exists\n2. Check if any session folders exist within\n3. If no session found:\n   ```\n   No active collab session found.\n\n   Use /collab to start a session first.\n   ```\n   **STOP** - do not proceed with this skill.\n\n4. If multiple sessions exist, check `COLLAB_SESSION_PATH` env var or ask user which session.\n\n## Browser-Based Questions\n\nWhen a collab session is active, use `render_ui` for all user interactions.\n\n**Component selection:**\n| Question Type | Component |\n|--------------|-----------|\n| Yes/No | Card with action buttons |\n| Choose 1 of 2-5 | RadioGroup |\n| Choose 1 of 6+ | MultipleChoice |\n| Free text | TextInput or TextArea |\n\n**Example - Yes/No:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"<question context>\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"<question>\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n**Terminal prompts only when:** No collab session exists (pre-session selection).\n\n# Executing Plans\n\n## Overview\n\nLoad plan, review critically, execute tasks in batches, report for review between batches.\n\n**Core principle:** Batch execution with checkpoints for architect review.\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed\n\n### Step 1.1: Parse Task Dependency Graph (Collab Workflow)\n\nWhen called from `rough-draft` within a collab workflow, the plan includes a task dependency graph. Parse and prepare for intelligent execution.\n\n**Graph Format (YAML in design doc):**\n```yaml\ntasks:\n  - id: auth-types\n    files: [src/auth/types.ts]\n    description: Core auth type definitions\n    parallel: true\n\n  - id: auth-service\n    files: [src/auth/service.ts]\n    description: Authentication service implementation\n    depends-on: [auth-types]\n\n  - id: auth-middleware\n    files: [src/middleware/auth.ts]\n    description: Express middleware for auth\n    depends-on: [auth-service]\n```\n\n**Parsing Steps:**\n1. Extract YAML block from design doc (look for `## Task Dependency Graph`)\n2. Parse task list with: `id`, `files`, `description`, `parallel`, `depends-on`\n3. Build adjacency list for dependency relationships\n4. Validate: check for cycles (topological sort must succeed)\n5. If cycle detected: STOP and report error to user\n\n**Build Execution Order:**\n1. Topological sort on dependency graph\n2. Group tasks by \"wave\" (tasks with all dependencies satisfied)\n3. Within each wave, identify parallel-safe tasks (those with `parallel: true` or independent file sets)\n\n**Execution State Tracking:**\n\nInitialize task tracking via MCP:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<name>\",\n  \"phase\": \"implementation\",\n  \"completedTasks\": [],\n  \"pendingTasks\": [\"task-1\", \"task-2\", \"task-3\"],\n  \"pendingVerificationIssues\": []\n}\n```\nNote: `lastActivity` is automatically updated by the MCP tool.\n\n### MANDATORY: Subagent Dispatch\n\n**GATE:** Implementation MUST use the Task tool with mermaid-collab:subagent-driven-development:implementer-prompt skill.\n\n**NEVER implement inline** - always dispatch a Task agent for each implementation task.\n\nThis is a hard requirement, not a suggestion. If you find yourself writing implementation code directly instead of spawning a Task agent, STOP immediately.\n\n**Why this matters:**\n- Task agents invoke mermaid-collab:subagent-driven-development:implementer-prompt which enforces TDD\n- Spec compliance review only happens in subagent flow\n- Code quality review only happens in subagent flow\n- Skipping this means skipping ALL quality gates\n\n**Pre-Task Checklist (before starting ANY task):**\n- [ ] Will spawn a Task agent (not implement inline)\n- [ ] Task prompt includes design doc location\n- [ ] Task prompt specifies mermaid-collab:subagent-driven-development:implementer-prompt skill\n\n**Post-Task Checklist (before marking ANY task complete):**\n- [ ] Task agent was spawned (verified Task tool was used)\n- [ ] mermaid-collab:subagent-driven-development:implementer-prompt skill was invoked by the agent\n- [ ] Spec compliance review passed\n- [ ] Code quality review passed\n- [ ] Called `markTaskComplete(taskId)` to update progress (see executing-plans-review skill)\n\n**If ANY checklist item fails:** Do NOT mark task as complete. Fix the issue first.\n\n**CRITICAL:** After verification passes, you MUST call `markTaskComplete(taskId)` to move the task from `pendingTasks` to `completedTasks`. This updates the progress bar in the UI. See the executing-plans-review skill for the implementation.\n\n---\n\n### Anti-Drift Rules\n\n**NO INTERPRETATION:**\n- Implement EXACTLY what the plan says, even if you think there's a better way\n- If the plan says \"create function foo(x) that returns x+1\" - do that, not \"a more flexible version\"\n- If something seems wrong or suboptimal, STOP and ask - do not \"fix\" it silently\n- Your job is execution, not design improvement\n\n**NO SHORTCUTS:**\n- Complete every step in order, even if you \"know\" the outcome\n- Run every test command, even if you're \"sure\" it will pass\n- Write every file listed, even if you think some are \"unnecessary\"\n- If a step feels redundant, do it anyway - the plan author had a reason\n\n**DESIGN VERIFICATION:**\n- Before each task: re-read the relevant design doc section\n- If mermaid-collab diagrams are referenced, open and verify against them\n- After each task: diff your implementation against the spec - EXACT match required\n- Any deviation = undo and redo, or STOP and ask\n\n**When in doubt:** Ask, don't improvise.\n\n### Design Freeze\n\nOnce execution begins, the design is FROZEN.\n\n**No changes during implementation:**\n- No \"small tweaks\" to requirements\n- No \"I realized we need X\" additions\n- No \"let's just add this while we're here\"\n- No scope creep, no matter how reasonable it sounds\n\n**If something needs to change:**\n1. STOP execution immediately\n2. Document what needs to change and why\n3. Go back to design doc - update it formally\n4. Update the plan to reflect changes\n5. THEN resume execution\n\n**Why this matters:**\n- Mid-implementation changes cause drift\n- \"Quick additions\" compound into chaos\n- The plan is a contract - honor it\n\n### Step 1.5: Pre-Flight Check\n\nBefore executing ANY tasks, verify:\n- [ ] Design doc exists and is complete\n- [ ] All referenced mermaid-collab diagrams exist and are accessible\n- [ ] No ambiguous requirements in the plan\n- [ ] Every task has explicit file paths and pseudo code\n\n**If anything is missing:** STOP. Go back to brainstorming/writing-plans. Do not proceed with incomplete specs.\n\n### Step 1.6: Create Task Execution Diagram (MANDATORY)\n\n**REQUIREMENT:** Always create a task execution diagram at the start of implementation. Never skip this step.\n\nWhen within a collab workflow, create a visual diagram showing all tasks and their dependencies. This diagram serves as a live progress tracker throughout implementation.\n\n**Build diagram content from task dependency graph:**\n\nExtract task information from the design doc's task dependency graph YAML and build a Mermaid graph:\n\n```\ngraph TD\n    %% Node Definitions (one per task)\n    <for each task: task-id([\"task-id\"])>\n\n    %% Dependencies (arrow from dependency to dependent)\n    <for each dependency: dep-id --> task-id>\n\n    %% Styles (all waiting initially)\n    <for each task: style task-id fill:#e0e0e0,stroke:#9e9e9e>\n```\n\n**Create the diagram:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__create_diagram\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"name\": \"task-execution\",\n  \"content\": <generated-mermaid-content>\n}\n```\n\n**Display to user:**\n```\nTask execution diagram created: <preview-url>\n\nTracking tasks:\n- task-1 (dependency root)\n- task-2 (depends on task-1)\n[etc.]\n```\n\n**State tracking - Style definitions:**\n| State | Style | Meaning |\n|-------|-------|---------|\n| waiting | `fill:#e0e0e0,stroke:#9e9e9e` | Task queued, waiting for dependencies |\n| executing | `fill:#bbdefb,stroke:#1976d2,stroke-width:3px` | Task currently being implemented |\n| completed | `fill:#c8e6c9,stroke:#2e7d32` | Task finished and verified |\n| failed | `fill:#ffcdd2,stroke:#c62828` | Task encountered error |\n\n**Update diagram on state change:**\n\nUse `patch_diagram` for atomic style updates when task state changes:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__patch_diagram\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"id\": \"task-execution\",\n  \"old_string\": \"style <task-id> fill:#e0e0e0,stroke:#9e9e9e\",\n  \"new_string\": \"style <task-id> fill:#bbdefb,stroke:#1976d2,stroke-width:3px\"\n}\n```\n\nIf `patch_diagram` fails (old_string not found), use `update_diagram` instead.\n\n**Helper function pseudocode:**\n\n```\nFUNCTION buildTaskDiagram(taskDependencyGraph):\n  nodes = []\n  edges = []\n  styles = []\n\n  FOR EACH task IN taskDependencyGraph.tasks:\n    nodes.append(`${task.id}([\"${task.id}\"])`)\n    styles.append(`style ${task.id} fill:#e0e0e0,stroke:#9e9e9e`)\n\n    FOR EACH dependency IN task.depends-on:\n      edges.append(`${dependency} --> ${task.id}`)\n\n  content = \"graph TD\\n\"\n  content += \"    %% Node Definitions\\n\"\n  content += nodes.join(\"\\n    \") + \"\\n\"\n  content += \"\\n    %% Dependencies\\n\"\n  content += edges.join(\"\\n    \") + \"\\n\"\n  content += \"\\n    %% Styles\\n\"\n  content += styles.join(\"\\n    \")\n\n  RETURN content\n```\n\n### Step 1.7: Verify Task Diagram Created\n\n**REQUIRED:** Verify the task execution diagram exists before proceeding to execution.\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_diagram\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"id\": \"task-execution\" }\n```\n\n**If diagram not found:**\n```\nTask execution diagram not found. Creating now...\n```\n-> Return to Step 1.6 and create the diagram.\n\n**If diagram exists:**\n```\nTask execution diagram verified. Proceeding to execution.\n```\n-> Proceed to Step 2.\n\n**This gate ensures the diagram is always created before any tasks execute.**\n\n### Step 1.8: Understand Item Types and Execution Paths\n\n**CONTEXT:** Within collab workflows, items come from the design doc with a `type` field. The execution path differs based on this type.\n\n**Item Types:**\n- **code:** New features, implementations, refactoring, investigations -> uses test-driven-development (TDD)\n- **bugfix:** Bug fixes, crashes, errors -> uses test-driven-development (TDD)\n- **task:** Operational tasks (docker setup, installs, configuration, organization) -> skips TDD, executes directly\n\n**How to Determine Item Type:**\n\n1. Read the design doc\n2. For each work item in the \"Work Items\" section, check the `Type:` field\n3. The current item being executed should have an associated type from the design doc\n\n**Execution Logic by Type:**\n\n| Type | Execution Flow |\n|------|----------------|\n| code/bugfix | Invoke test-driven-development skill -> Write failing test -> Implement -> Verify test passes |\n| task | Execute task steps directly -> Run verification checks |\n\n**Task Type Items:**\n- Use phases from task-planning: Prerequisites -> Steps -> Verification\n- Prerequisites define what must exist before starting\n- Steps are ordered commands/actions to execute\n- Verification confirms success\n- No TDD cycle needed (these are operational, not code)\n\n**Code/Bugfix Type Items:**\n- Follow standard TDD flow with red-green-refactor\n- Still require verification but through test suite\n\n## Step 2: Execute Batch\n\nExecute tasks following the dependency graph, dispatching parallel-safe tasks together.\n\n**Invoke skill: executing-plans-execution** for detailed execution logic, task routing, and agent prompts.\n\nKey points:\n- Standard execution: First 3 tasks in sequence\n- Collab workflow: Use dependency-aware parallel dispatch\n- Always spawn Task agents - never implement inline\n- Update task diagram on state changes\n\n## Verification and Review\n\nAfter each task completes, verify implementation against design and check for drift.\n\n**Invoke skill: executing-plans-review** for detailed verification, drift detection, and snapshot logic.\n\nKey points:\n- Per-task verification compares output against design doc\n- Drift detection identifies mismatches with pros/cons analysis\n- Snapshots enable recovery after context compaction\n- Proposing design changes uses special markdown tags\n\n### Step 3: Report\nWhen batch complete:\n- Show what was implemented\n- Show verification output (including any drift decisions)\n- Say: \"Ready for feedback.\"\n\n### Step 4: Continue\nBased on feedback:\n- Apply changes if needed\n- Execute next batch\n- Repeat until complete\n\n### Step 5: Complete Development\n\nAfter all tasks complete and verified, show summary and ask for confirmation:\n\n```\nImplementation complete:\n- [N] tasks completed: [list task IDs]\n- All tests passing\n- All TODOs resolved\n\nReady to move to finishing-a-development-branch?\n\n1. Yes\n2. No\n```\n\n- If **1 (Yes)**: Invoke finishing-a-development-branch skill\n- If **2 (No)**: Ask what needs to be addressed\n\n**On confirmation:**\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use superpowers:finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n### Step 5.1: Offer Collab Cleanup (Within Collab Workflow)\n\n**REQUIRED** when executing within a collab session:\n\nAfter development work completes (whether through finishing-a-development-branch or direct user commands like \"commit and push\"), always offer collab session cleanup:\n\n```\nDevelopment complete.\n\nClean up collab session? This will archive or delete design artifacts.\nRun /collab-cleanup?\n\n1. Yes\n2. No\n```\n\n- If **1 (Yes)**: Invoke collab-cleanup skill\n- If **2 (No)**: \"Session kept open. Run `/collab-cleanup` when ready.\"\n\n**This step ensures users always get the option to clean up, regardless of how they chose to finish the work.**\n\n## When to Stop and Ask for Help\n\n**STOP executing immediately when:**\n- Hit a blocker mid-batch (missing dependency, test fails, instruction unclear)\n- Plan has critical gaps preventing starting\n- You don't understand an instruction\n- Verification fails repeatedly\n\n**Ask for clarification rather than guessing.**\n\n## When to Revisit Earlier Steps\n\n**Return to Review (Step 1) when:**\n- Partner updates the plan based on your feedback\n- Fundamental approach needs rethinking\n\n**Don't force through blockers** - stop and ask.\n\n## Remember\n- Review plan critically first\n- Follow plan steps exactly\n- Don't skip verifications\n- Reference skills when plan says to\n- Between batches: just report and wait\n- Stop when blocked, don't guess\n\n## Integration with Collab Workflow\n\nThis skill can be invoked in two contexts:\n\n### Standalone (Traditional)\n- Called directly by user with a plan file\n- No dependency graph\n- Standard batch execution (3 tasks at a time)\n- Uses `writing-plans` output format\n\n### Within Collab Workflow\n- Called by `rough-draft` skill after skeleton phase completes\n- Receives task dependency graph from design doc\n- Uses dependency-aware parallel execution\n- Per-task verification via `verify-phase` hook\n- On completion, triggers `collab-cleanup` hook\n\n**Collab Workflow Chain:**\n```\ncollab -> brainstorming -> rough-draft -> executing-plans -> finishing-a-development-branch\n                                            ^\n                                     (you are here)\n```\n\n**When called from rough-draft:**\n1. Design doc is already complete with task dependency graph\n2. Skeleton files already exist with TODOs\n3. Your job: implement TODOs respecting dependency order\n4. Parallel dispatch independent tasks via `mermaid-collab:subagent-driven-development:implementer-prompt`\n5. Verify each task against design before unlocking dependents\n\n## Sub-Skills\n\n- **executing-plans-execution** - Detailed task execution logic, routing, and agent prompts\n- **executing-plans-review** - Verification, drift detection, and snapshot saving\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"executing-plans\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/finishing-a-development-branch/SKILL.md": "---\nname: finishing-a-development-branch\ndescription: Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup\nuser-invocable: false\n---\n\n# Finishing a Development Branch\n\n## Browser-Based Questions\n\nWhen a collab session is active, use `render_ui` for all user interactions.\n\n**Component selection:**\n| Question Type | Component |\n|--------------|-----------|\n| Yes/No | Card with action buttons |\n| Choose 1 of 2-5 | RadioGroup |\n| Choose 1 of 6+ | MultipleChoice |\n| Free text | TextInput or TextArea |\n\n**Example - Yes/No:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"<question context>\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"<question>\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n**Terminal prompts only when:** No collab session exists (pre-session selection).\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests → Present options → Execute choice → Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Completion\n\n**Before presenting options, verify:**\n\n1. **Tests pass:**\n```bash\n# Run project's test suite\nnpm test / cargo test / pytest / go test ./...\n```\n\n2. **Design alignment (if design artifacts exist):**\n- Open design doc — does implementation match?\n- Open mermaid-collab wireframes/diagrams — does implementation match?\n- Any deviations = not complete, go back and fix\n\n**If tests fail or design doesn't match:**\n```\nCannot proceed. Issues:\n- [test failures or design mismatches]\n\nMust fix before completing.\n```\n\nStop. Don't proceed to Step 2.\n\n**If tests pass AND design matches:** Continue to Step 2.\n\n### Step 2: Determine Base Branch\n\n```bash\n# Try common base branches\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\nOr ask: \"This branch split from main - is that correct?\"\n\n### Step 3: Present Options\n\nPresent exactly these 4 options:\n\n```\nImplementation complete. What would you like to do?\n\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\nWhich option?\n```\n\n**Don't add explanation** - keep options concise.\n\n### Step 4: Execute Choice\n\n#### Option 1: Merge Locally\n\n```bash\n# Switch to base branch\ngit checkout <base-branch>\n\n# Pull latest\ngit pull\n\n# Merge feature branch\ngit merge <feature-branch>\n\n# Verify tests on merged result\n<test command>\n\n# If tests pass\ngit branch -d <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 2: Push and Create PR\n\n```bash\n# Push branch\ngit push -u origin <feature-branch>\n\n# Create PR\ngh pr create --title \"<title>\" --body \"$(cat <<'EOF'\n## Summary\n<2-3 bullets of what changed>\n\n## Test Plan\n- [ ] <verification steps>\nEOF\n)\"\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 3: Keep As-Is\n\nReport: \"Keeping branch <name>. Worktree preserved at <path>.\"\n\n**Don't cleanup worktree.**\n\n#### Option 4: Discard\n\n**Confirm first:**\n```\nThis will permanently delete:\n- Branch <name>\n- All commits: <commit-list>\n- Worktree at <path>\n\nType 'discard' to confirm.\n```\n\nWait for exact confirmation.\n\nIf confirmed:\n```bash\ngit checkout <base-branch>\ngit branch -D <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n### Step 5: Cleanup Worktree\n\n**For Options 1, 2, 4:**\n\nCheck if in worktree:\n```bash\ngit worktree list | grep $(git branch --show-current)\n```\n\nIf yes:\n```bash\ngit worktree remove <worktree-path>\n```\n\n**For Option 3:** Keep worktree.\n\n## Quick Reference\n\n| Option | Merge | Push | Keep Worktree | Cleanup Branch |\n|--------|-------|------|---------------|----------------|\n| 1. Merge locally | ✓ | - | - | ✓ |\n| 2. Create PR | - | ✓ | ✓ | - |\n| 3. Keep as-is | - | - | ✓ | - |\n| 4. Discard | - | - | - | ✓ (force) |\n\n## Common Mistakes\n\n**Skipping test verification**\n- **Problem:** Merge broken code, create failing PR\n- **Fix:** Always verify tests before offering options\n\n**Open-ended questions**\n- **Problem:** \"What should I do next?\" → ambiguous\n- **Fix:** Present exactly 4 structured options\n\n**Automatic worktree cleanup**\n- **Problem:** Remove worktree when might need it (Option 2, 3)\n- **Fix:** Only cleanup for Options 1 and 4\n\n**No confirmation for discard**\n- **Problem:** Accidentally delete work\n- **Fix:** Require typed \"discard\" confirmation\n\n## Red Flags\n\n**Never:**\n- Proceed with failing tests\n- Merge without verifying tests on result\n- Delete work without confirmation\n- Force-push without explicit request\n\n**Always:**\n- Verify tests before offering options\n- Present exactly 4 options\n- Get typed confirmation for Option 4\n- Clean up worktree for Options 1 & 4 only\n\n## Collab Session Cleanup\n\nAfter the development branch work is complete (merged, PR created, or kept):\n\n```\nDevelopment branch work complete.\n\nTo close this collab session, run `/collab-cleanup`\n- Archive design artifacts to `docs/designs/`\n- Or delete the session\n- Or keep it for reference\n\nRun cleanup now?\n\n1. Yes\n2. No\n```\n\n- If **1 (Yes)**: Invoke collab-cleanup skill\n- If **2 (No)**: \"Session kept open. Run `/collab-cleanup` when ready.\"\n\n## Integration\n\n**Called by:**\n- **mermaid-collab:subagent-driven-development:implementer-prompt** (Step 7) - After all tasks complete\n- **executing-plans** (Step 5) - After all batches complete\n\n**Transitions to:**\n- **collab-cleanup** - After branch work completes (within collab workflow)\n\n**Pairs with:**\n- **using-git-worktrees** - Cleans up worktree created by that skill\n",
        "skills/gather-session-goals/SKILL.md": "---\nname: gather-session-goals\ndescription: Collect and classify work items at the start of a collab session. Invoked by collab skill after creating a new session.\nuser-invocable: false\nmodel: opus\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read\n---\n\n# Gather Session Goals\n\n## Overview\n\nCollect and classify work items at the start of a collab session through iterative questioning.\n\n**Invoked by:** collab skill after creating a new session\n\n**Returns to:** collab skill (which manages the work item loop)\n\n## Collab Session Required\n\nBefore proceeding, check for active collab session:\n\n1. Check if `.collab/` directory exists\n2. Check if any session folders exist within\n3. If no session found:\n   ```\n   No active collab session found.\n\n   Use /collab to start a session first.\n   ```\n   **STOP** - do not proceed with this skill.\n\n4. If multiple sessions exist, check `COLLAB_SESSION_PATH` env var or ask user which session.\n\n## The Process\n\n### Step 1: Open Question\n\nAsk the user: **\"What do you want to accomplish this session?\"**\n\nStore the initial response. Parse any items mentioned and add them to the work items list with type = \"unknown\".\n\n### Step 2: Anything Else Loop\n\nAfter parsing the initial response:\n\n1. Infer type for each item from context:\n   - Contains \"setup\", \"install\", \"configure\", \"organize\", \"clean up\", \"docker\", \"deploy\" → type = \"task\"\n   - Contains \"fix\", \"bug\", \"broken\", \"error\", \"crash\", \"fail\" → type = \"bugfix\"\n   - Contains \"add\", \"new\", \"create\", \"implement\", \"build\", \"refactor\", \"clean\", \"simplify\", \"restructure\", \"investigate\", \"explore\", \"spike\" → type = \"code\"\n   - Otherwise → type = \"unknown\"\n\n2. Ask: **\"Anything else?\"**\n\n3. If user provides more items:\n   - Parse and infer types\n   - Repeat from step 2\n\n4. If user says no/done/that's it:\n   - Proceed to Step 3\n\n### Step 3: Classify Unknown Items\n\nFor each item still marked as type = \"unknown\":\n\nAsk: **\"What type is '[item title]'?\"**\n```\n1. code\n2. bugfix\n3. task\n```\n\nSet the item type based on user response.\n\n### Step 4: Present Summary\n\nDisplay the work items for confirmation:\n\n```\nHere are the work items for this session:\n\n1. [bugfix] Fix login redirect issue\n2. [code] Add user authentication\n3. [code] Clean up database layer\n\nDoes this list look correct?\n\n1. Yes\n2. Add more\n3. Remove item\n4. Edit item\n```\n\n**Handle user responses:**\n- **1 (Yes)** - Proceed to Step 5\n- **2 (Add more)** - Return to Step 2\n- **3 (Remove)** - Ask which item to remove, remove it, return to Step 4\n- **4 (Edit)** - Ask which item to edit, update it, return to Step 4\n\n### Step 5: Write Work Items\n\n**Before writing, output:** \"Writing work items...\"\n\n#### 5a. Write to session state (source of truth for routing)\n\nBuild the workItems array and save to session state:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"workItems\": [\n    { \"number\": 1, \"title\": \"<title>\", \"type\": \"<code|bugfix|task>\", \"status\": \"pending\" },\n    { \"number\": 2, \"title\": \"<title>\", \"type\": \"<code|bugfix|task>\", \"status\": \"pending\" },\n    ...\n  ]\n}\n```\n\n#### 5b. Create design doc with work items\n\n1. Build the design doc content with Work Items section:\n\n```markdown\n# Session: <session-name>\n\n## Session Context\n**Out of Scope:** (session-wide boundaries)\n**Shared Decisions:** (cross-cutting choices)\n\n---\n\n## Work Items\n\n### Item 1: <title>\n**Type:** <type>\n**Status:** pending\n\n**Problem/Goal:**\n\n**Approach:**\n\n**Root Cause:** (only if type is bugfix)\n\n**Success Criteria:**\n\n**Decisions:**\n\n---\n\n### Item 2: <title>\n...\n\n---\n\n## Diagrams\n(auto-synced)\n```\n\n2. Create the design doc:\n   Tool: mcp__plugin_mermaid-collab_mermaid__create_document\n   Args: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"name\": \"design\", \"content\": \"<full-content>\" }\n\n   If document already exists, use update_document instead.\n\nAfter writing, display:\n\n```\nWork items saved. Returning to collab workflow.\n```\n\nReturn control to the collab skill.\n\n## Key Constraints\n\n- **One question at a time** - Never batch multiple questions together\n- **Don't skip classification** - Every item must have a type before proceeding\n- **Must get explicit confirmation** - User must approve the list before writing to design doc\n\n## Contract\n\n**Preconditions:**\n- Collab session exists\n\n**Postconditions:**\n- Session state contains `workItems` array (source of truth for routing)\n- Design doc contains `## Work Items` section (human-readable view)\n- At least one work item defined\n- All items have `status: pending`\n- User has confirmed the list\n\n**Side effects:**\n- Writes `workItems` to session state\n- Creates/updates design doc\n\n## Browser-Based Questions\n\nWhen a collab session is active, prefer `render_ui` for user interactions.\n\n**For item type classification:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Classify item\" },\n    \"children\": [\n      { \"type\": \"Markdown\", \"props\": { \"content\": \"What type is **[item title]**?\" } },\n      {\n        \"type\": \"RadioGroup\",\n        \"props\": {\n          \"name\": \"type\",\n          \"options\": [\n            { \"value\": \"code\", \"label\": \"Code (feature, refactor, investigation)\" },\n            { \"value\": \"bugfix\", \"label\": \"Bugfix (fix, error, crash)\" },\n            { \"value\": \"task\", \"label\": \"Task (setup, config, organization)\" }\n          ]\n        }\n      }\n    ],\n    \"actions\": [{ \"id\": \"classify\", \"label\": \"Continue\", \"primary\": true }]\n  },\n  \"blocking\": true\n}\n```\n\n**For work items list confirmation:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Confirm work items\" },\n    \"children\": [\n      { \"type\": \"Markdown\", \"props\": { \"content\": \"[markdown list of items]\" } },\n      {\n        \"type\": \"RadioGroup\",\n        \"props\": {\n          \"name\": \"action\",\n          \"options\": [\n            { \"value\": \"yes\", \"label\": \"Yes, this is correct\" },\n            { \"value\": \"add\", \"label\": \"Add more items\" },\n            { \"value\": \"remove\", \"label\": \"Remove an item\" },\n            { \"value\": \"edit\", \"label\": \"Edit an item\" }\n          ]\n        }\n      }\n    ],\n    \"actions\": [{ \"id\": \"confirm\", \"label\": \"Continue\", \"primary\": true }]\n  },\n  \"blocking\": true\n}\n```\n\n## Integration\n\n**Called by:**\n- **collab** skill - After session creation\n\n**Returns to:**\n- **collab** skill - To start the work item loop\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"gather-session-goals\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/kodex-bootstrap-missing/SKILL.md": "---\nname: kodex-bootstrap-missing\ndescription: Convert all missing topic flags into stub topics flagged as incomplete\nuser-invocable: true\nallowed-tools:\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_flags\n  - mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\n---\n\n# Kodex Bootstrap Missing\n\nBatch-process all \"missing\" topic flags by creating stub topics and flagging them as incomplete.\n\n## Overview\n\nThis skill quickly converts all open \"missing\" flags into stub topics, clearing the missing queue. Unlike `kodex-fix-missing` (which does full research for one topic), this creates minimal stubs that can be filled in later.\n\n**Use when:**\n- Many missing flags have accumulated\n- Want to quickly establish topic structure\n- Will fill in details later with `/kodex-fix`\n\n**Comparison with related skills:**\n\n| Skill | Behavior |\n|-------|----------|\n| `kodex-fix-missing` | One flag, full research, detailed content |\n| `kodex-init` | Analyzes codebase, proposes topics |\n| **`kodex-bootstrap-missing`** | Batch process, minimal stubs, quick conversion |\n\n---\n\n## Step 1: List Missing Flags\n\nRetrieve all open flags and filter for type \"missing\":\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_list_flags\nArgs: {\n  \"project\": \"<cwd>\",\n  \"status\": \"open\"\n}\n```\n\nFilter the results to only include flags where `type === \"missing\"`.\n\n**If no missing flags found:**\n```\nNo missing topic flags found. Nothing to bootstrap.\n```\nExit skill.\n\n---\n\n## Step 2: Present for Confirmation\n\nDisplay the missing topics to the user:\n\n```\nFound N missing topic flags to bootstrap:\n\n1. topic-name-1: \"Description from flag\"\n2. topic-name-2: \"Description from flag\"\n...\n\nThis will create stub topics for each and flag them as incomplete.\n```\n\nAsk for approval:\n\n```\nTool: AskUserQuestion\nArgs: {\n  \"questions\": [{\n    \"question\": \"Create stub topics for all N missing flags?\",\n    \"header\": \"Bootstrap\",\n    \"options\": [\n      { \"label\": \"Yes, create all\", \"description\": \"Create stub topics and flag as incomplete\" },\n      { \"label\": \"No, cancel\", \"description\": \"Exit without changes\" }\n    ],\n    \"multiSelect\": false\n  }]\n}\n```\n\nIf user cancels, exit with:\n```\nBootstrap cancelled. No topics created.\n```\n\n---\n\n## Step 3: Create Stub Topics\n\nFor each missing flag, create a minimal stub topic:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\nArgs: {\n  \"project\": \"<cwd>\",\n  \"name\": \"<topic-name-from-flag>\",\n  \"title\": \"<Title Case of topic name>\",\n  \"content\": {\n    \"conceptual\": \"# <Title>\\n\\nTopic pending documentation.\",\n    \"technical\": \"\",\n    \"files\": \"\",\n    \"related\": \"\"\n  }\n}\n```\n\n**Title conversion:** Convert kebab-case to Title Case:\n- `api-endpoints` → \"Api Endpoints\"\n- `user-authentication` → \"User Authentication\"\n\nTrack successes and failures for the summary.\n\n---\n\n## Step 4: Flag as Incomplete\n\nFor each successfully created topic, flag it as incomplete:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\nArgs: {\n  \"project\": \"<cwd>\",\n  \"name\": \"<topic-name>\",\n  \"type\": \"incomplete\",\n  \"description\": \"Stub topic needs detailed content\"\n}\n```\n\n---\n\n## Step 5: Summary\n\nDisplay results:\n\n```\nBootstrap complete!\n\nCreated N stub topics:\n- topic-1: Title 1\n- topic-2: Title 2\n...\n\nAll topics flagged as incomplete.\nUse /kodex-fix to fill in detailed content for each topic.\n```\n\nIf any failures occurred:\n```\nNote: N topics failed to create:\n- failed-topic: Error message\n```\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| No missing flags | Exit with message |\n| User cancels | Exit with no changes |\n| Topic already exists | Skip, note in summary |\n| MCP tool fails | Log error, continue with remaining |\n\n---\n\n## MCP Tools Reference\n\n| Tool | Purpose |\n|------|---------|\n| `kodex_list_flags` | Get all open missing flags |\n| `kodex_create_topic` | Create stub topic as draft |\n| `kodex_flag_topic` | Flag stub as incomplete |\n\n---\n\n## Integration\n\n**Standalone skill** - Does not require an active collab session.\n\n**Related skills:**\n- `kodex-fix` - Fix flagged incomplete topics after bootstrap\n- `kodex-fix-missing` - Detailed research for one missing topic\n- `kodex-init` - Bootstrap from codebase analysis (not flags)\n",
        "skills/kodex-fix-incomplete/SKILL.md": "---\nname: kodex-fix-incomplete\ndescription: Fill in missing sections of incomplete Kodex topics\nuser-invocable: false\nallowed-tools:\n  - Glob\n  - Grep\n  - Read\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n---\n\n# Kodex Fix Incomplete\n\nFill in missing sections of incomplete Kodex topics.\n\n## Overview\n\nThis sub-skill is invoked by `kodex-fix` when a topic is flagged as incomplete. It identifies which sections are empty or sparse and fills them in.\n\n---\n\n## Step 1: Get Existing Topic\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: { \"project\": \"<cwd>\", \"name\": \"<topic-name>\" }\n```\n\nIdentify which sections need content:\n- conceptual: Empty or just placeholder text?\n- technical: Empty or lacks detail?\n- files: Missing file list?\n- related: Missing related topics?\n\n---\n\n## Step 2: Gather Information for Missing Sections\n\nFor each empty/sparse section:\n\n**conceptual (if empty):**\n- Read main entry points\n- Check for README in component directory\n- Summarize purpose from code comments\n\n**technical (if empty):**\n- Analyze implementation patterns\n- Document key functions and their purposes\n- Note any gotchas or important details\n\n**files (if empty):**\n```\nTool: Glob\nArgs: { \"pattern\": \"**/*<topic-keyword>*\" }\n```\n\n**related (if empty):**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\nArgs: { \"project\": \"<cwd>\" }\n```\nFind topics with related names or overlapping file paths.\n\n---\n\n## Step 3: Generate Content for Missing Sections\n\nOnly fill empty/sparse sections. Preserve existing content.\n\n---\n\n## Step 4: Validate with User\n\nFor each filled section:\n```\n**[Section name] (new content):**\n[generated content]\n\nDoes this accurately describe [topic]?\n1. Yes\n2. No - needs changes\n```\n\n---\n\n## Step 5: Create Draft\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\nArgs: {\n  \"project\": \"<cwd>\",\n  \"name\": \"<topic-name>\",\n  \"content\": { ... },\n  \"reason\": \"Filled incomplete sections: [list sections]\"\n}\n```\n\nReturn to parent skill.\n\n---\n\n## Integration\n\n**Called by:** kodex-fix (parent skill)\n**Returns to:** kodex-fix after creating draft\n",
        "skills/kodex-fix-incorrect/SKILL.md": "---\nname: kodex-fix-incorrect\ndescription: Correct factually incorrect Kodex topic content\nuser-invocable: false\nallowed-tools:\n  - Glob\n  - Grep\n  - Read\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n---\n\n# Kodex Fix Incorrect\n\nCorrect factually incorrect Kodex topic content.\n\n## Overview\n\nThis sub-skill is invoked by `kodex-fix` when a topic is flagged as incorrect. It focuses on the specific inaccuracy described in the flag and verifies against actual code.\n\n---\n\n## Step 1: Get Existing Topic and Flag Details\n\nQuery the existing topic to understand the current content:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: { \"project\": \"<cwd>\", \"name\": \"<topic-name>\" }\n```\n\nReview the flag description to understand what's incorrect. Extract:\n- Current content (conceptual, technical, files, related)\n- File paths from the 'files' section\n- The specific inaccuracy mentioned in the flag\n\n**If topic not found:**\n```\nTopic not found. This may need kodex-fix-missing instead.\n```\nReturn to parent skill.\n\n---\n\n## Step 2: Verify the Inaccuracy\n\nFocus on the specific inaccuracy mentioned in the flag. Read the files mentioned in the topic to compare what they actually contain versus what the topic claims:\n\n```\nTool: Read\nArgs: { \"file_path\": \"<file-from-topic>\" }\n```\n\nCompare:\n- What the topic claims\n- What the code actually does\n\nIdentify the specific incorrect statement(s) by examining the implementation. Focus specifically on the inaccuracy flagged rather than a general review.\n\n---\n\n## Step 3: Research Correct Information\n\nUse Grep to find actual implementations and verify what the code actually does:\n\n```\nTool: Grep\nArgs: { \"pattern\": \"<function-or-concept>\", \"path\": \"<project-root>\" }\n```\n\nBuild accurate understanding of how things actually work in the codebase. Research the specific behavior that contradicts what the topic currently documents.\n\n---\n\n## Step 4: Generate Corrected Content\n\nUpdate the sections that contain the inaccuracy. Focus corrections on:\n- The specific inaccuracy from the flag\n- Any related incorrect statements discovered during research\n- Keep accurate parts unchanged\n\nGenerate corrected versions of affected sections (conceptual, technical, files, related as needed).\n\n---\n\n## Step 5: Validate with User\n\nPresent the correction for user validation:\n\n```\n**Correction:**\n\nThe flag said: \"[flag description]\"\nI found: \"[actual behavior from code]\"\n\nUpdated content:\n[corrected section]\n\nIs this correction accurate?\n1. Yes\n2. No - needs adjustment\n```\n\nUse AskUserQuestion to get user feedback. If user selects **2**, ask for corrections and regenerate.\n\n---\n\n## Step 6: Create Draft\n\nCall kodex_update_topic to create a draft with the corrected content:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\nArgs: {\n  \"project\": \"<cwd>\",\n  \"name\": \"<topic-name>\",\n  \"content\": { \"conceptual\": \"...\", \"technical\": \"...\", \"files\": \"...\", \"related\": \"...\" },\n  \"reason\": \"Corrected inaccuracy: [brief description of the correction]\"\n}\n```\n\nReturn to parent skill after draft is created.\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| Topic not found | Return to parent, suggest kodex-fix-missing |\n| Files not readable | Skip, note in content |\n| User rejects content | Ask for corrections, regenerate |\n| MCP tool failure | Display error, suggest retry |\n\n---\n\n## Integration\n\n**Called by:** kodex-fix (parent skill)\n**Returns to:** kodex-fix after creating draft\n\n**Related skills:**\n- `kodex-fix` - Parent skill that orchestrates flag fixes\n- `kodex-fix-outdated` - Update stale content\n- `kodex-fix-incomplete` - Fill missing sections\n- `kodex-fix-missing` - Create new topics\n- `using-kodex` - Query and flag topics\n",
        "skills/kodex-fix-missing/SKILL.md": "---\nname: kodex-fix-missing\ndescription: Create new Kodex topics for missing documentation\nuser-invocable: false\nallowed-tools:\n  - Glob\n  - Grep\n  - Read\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n---\n\n# Kodex Fix Missing\n\nCreate new Kodex topics for missing documentation.\n\n## Overview\n\nThis sub-skill is invoked by `kodex-fix` when a topic is flagged as missing. It researches the codebase to create a complete new topic.\n\n---\n\n## Step 1: Understand What's Needed\n\nThe flag description indicates what topic should exist.\nExtract the topic name and any hints about what it should cover.\n\n---\n\n## Step 2: Research the Topic\n\nSearch for files matching the topic name:\n\n```\nTool: Glob\nArgs: { \"pattern\": \"**/*<topic-name>*\" }\n```\n\nSearch for references:\n\n```\nTool: Grep\nArgs: { \"pattern\": \"<topic-keyword>\", \"path\": \"<project-root>\" }\n```\n\nRead relevant files to understand the component.\n\n---\n\n## Step 3: Identify Topic Scope\n\nDetermine:\n- Which files belong to this topic?\n- What is the main purpose?\n- How does it relate to other components?\n\nIf unclear, ask user:\n\n```\nI found these potential files for [topic]:\n- path/to/file1.ts\n- path/to/file2.ts\n\nShould I include all of these, or is the scope different?\n```\n\n---\n\n## Step 4: Generate All 4 Sections\n\nCreate complete topic content:\n\n- **conceptual**: High-level description\n- **technical**: Implementation details, patterns, gotchas\n- **files**: List of related source files\n- **related**: Links to other Kodex topics\n\n---\n\n## Step 5: Validate with User\n\nPresent the full draft:\n\n```\n**New Topic: [topic-name]**\n\n[Full content preview]\n\nDoes this accurately describe [topic-name]?\n1. Yes\n2. No - needs changes\n```\n\n---\n\n## Step 6: Create Draft\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\nArgs: {\n  \"project\": \"<cwd>\",\n  \"name\": \"<topic-name>\",\n  \"title\": \"<Topic Title>\",\n  \"content\": { \"conceptual\": \"...\", \"technical\": \"...\", \"files\": \"...\", \"related\": \"...\" }\n}\n```\n\nReturn to parent skill.\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| No matching files | Ask user for guidance |\n| Ambiguous scope | Present options, let user choose |\n| Topic name too generic | Ask for clarification |\n\n---\n\n## Integration\n\n**Called by:** kodex-fix (parent skill)\n**Returns to:** kodex-fix after creating draft\n",
        "skills/kodex-fix-outdated/SKILL.md": "---\nname: kodex-fix-outdated\ndescription: Update an outdated Kodex topic by analyzing codebase changes since topic was written\nuser-invocable: false\nallowed-tools:\n  - Glob\n  - Grep\n  - Read\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n---\n\n# Kodex Fix Outdated\n\nUpdate an outdated Kodex topic by analyzing codebase changes and regenerating content based on current implementation.\n\n## Overview\n\nThis skill updates a topic that has been flagged as outdated. It analyzes the codebase to identify what has changed since the topic was written, gathers new information, and generates updated content sections for user validation.\n\n**Use when:**\n- A topic has been flagged as outdated\n- Codebase has evolved significantly since topic documentation\n- Implementation details in the topic no longer reflect current code\n- Topic references files or patterns that have changed\n\n---\n\n## Step 1: Get Existing Topic\n\nRetrieve the topic from Kodex to understand its current state.\n\n### 1.1 Query the Topic\n\nUse the `kodex_query_topic` tool to fetch the topic:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"<topic-name>\",\n  \"include_content\": true\n}\n```\n\n### 1.2 Extract Current Content\n\nFrom the returned topic, extract:\n- **name**: Topic identifier\n- **title**: Human-readable title\n- **content.conceptual**: Current conceptual overview\n- **content.technical**: Current technical details\n- **content.files**: Current file references\n- **content.related**: Current related topics\n\n### 1.3 Identify Empty Sections\n\nMark which sections are empty or minimal:\n- Empty conceptual (just placeholder text)\n- Empty technical\n- Empty files listing\n- Empty related topics\n\n---\n\n## Step 2: Analyze Codebase for Changes\n\nExplore the codebase to identify what has changed since the topic was written.\n\n### 2.1 Extract File References from Topic\n\nParse the current `content.files` section to identify files mentioned in the topic.\n\n### 2.2 Check File Existence and Changes\n\nFor each file mentioned:\n- Use `Glob` to verify the file still exists\n- Use `Read` to get current content\n- Compare with any older patterns mentioned in the topic\n\n### 2.3 Scan for Related Code Patterns\n\nUse `Grep` to search for:\n- Key terms from the topic (functions, classes, concepts)\n- Related files in the same directories\n- Implementation patterns that may have changed\n- Comments or documentation in the code\n\n### 2.4 Identify Structural Changes\n\nLook for:\n- New subdirectories or modules\n- Renamed or moved files\n- Major refactoring indicators\n- New dependencies (package.json, requirements.txt, etc.)\n\n### 2.5 Summarize Changes\n\nCreate a summary of:\n- Files that have changed significantly\n- New files relevant to this topic\n- Removed or deprecated files\n- Major architectural changes\n\n---\n\n## Step 3: Generate Updated Content\n\nCreate new content based on current codebase state.\n\n### 3.1 Update Conceptual Section\n\nRegenerate the conceptual overview based on current code:\n- What is the main purpose of this topic area?\n- What key concepts are currently implemented?\n- What are the main components or modules?\n- How do they relate to the broader system?\n\n### 3.2 Update Technical Section\n\nWrite technical details based on current implementation:\n- Architecture patterns in use\n- Key functions, classes, or components\n- Interfaces and contracts\n- Dependencies and integrations\n- Configuration or setup requirements\n\n### 3.3 Update Files Section\n\nList the current relevant files:\n- Use `Glob` to find all relevant files in the topic area\n- Organize by subdirectory if applicable\n- Include brief descriptions of what each file does\n\n### 3.4 Update Related Topics\n\nIdentify related topics:\n- Other Kodex topics that interact with this area\n- Cross-references to other sections of the codebase\n- Dependencies on external systems\n\n---\n\n## Step 4: Validate with User\n\nPresent the updated content sections for user approval.\n\n### 4.1 Display Changes\n\nShow the user:\n- What sections were updated\n- Before/after comparison for major sections\n- Summary of discovered changes in codebase\n\n### 4.2 Present Updated Sections\n\nDisplay the proposed updates in this format:\n\n```\n## Updated Conceptual\n[conceptual content]\n\n## Updated Technical\n[technical content]\n\n## Updated Files\n[files listing]\n\n## Updated Related Topics\n[related topics]\n```\n\n### 4.3 Ask for Approval\n\nUse `AskUserQuestion` to get user feedback:\n\n```\nThese sections have been updated based on current codebase analysis.\n\nDo you want to:\n1. Approve all changes and create draft\n2. Review and edit specific sections\n3. Cancel (no changes)\n```\n\n### 4.4 Handle Revisions\n\nIf user wants to revise:\n- Ask which section(s) to modify\n- Offer suggestions or alternatives\n- Re-display updated sections until user approves\n\n---\n\n## Step 5: Create Draft\n\nSubmit the updated topic as a draft using the kodex_update_topic tool.\n\n### 5.1 Prepare Update Args\n\nBuild the arguments for the update:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_update_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"<topic-name>\",\n  \"content\": {\n    \"conceptual\": \"<updated conceptual>\",\n    \"technical\": \"<updated technical>\",\n    \"files\": \"<updated files>\",\n    \"related\": \"<updated related>\"\n  },\n  \"reason\": \"Updated based on codebase analysis: [brief summary of changes]\"\n}\n```\n\n### 5.2 Call kodex_update_topic\n\nSubmit the draft:\n- Topic is updated as a draft version\n- Human review is required before publishing\n- The reason field documents why the update was needed\n\n### 5.3 Report Success\n\nConfirm to user:\n\n```\nUpdated topic draft created: [topic-name]\n\nUpdated sections:\n- Conceptual overview\n- Technical details\n- Files listing\n- Related topics\n\nThe draft is pending human review before going live.\nUse the Kodex dashboard to review and approve changes.\n```\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| Topic not found | Report error, exit gracefully |\n| Cannot read referenced files | Log warning, skip file, continue with analysis |\n| Grep/Glob failures | Log error, continue with available info |\n| User cancels at validation | Exit with no changes |\n| Update tool fails | Report error with details |\n\n---\n\n## MCP Tools Reference\n\n| Tool | Purpose |\n|------|---------|\n| `kodex_query_topic` | Fetch existing topic content |\n| `kodex_update_topic` | Create draft with updated content |\n| `kodex_list_topics` | List existing topics (optional, for context) |\n\n---\n\n## Integration\n\n**Sub-skill** - Called by parent skills like `using-kodex` when user flags a topic as outdated.\n\n**Related skills:**\n- `using-kodex` - Query and flag existing topics\n- `kodex-fix-incorrect` - Fix inaccurate information\n- `kodex-fix-incomplete` - Fill missing sections\n- `kodex-fix-missing` - Create new topics for missing areas\n",
        "skills/kodex-fix/SKILL.md": "---\nname: kodex-fix\ndescription: Fix flagged Kodex topics by generating updated content\nuser-invocable: true\nallowed-tools:\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_flags\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n---\n\n# Kodex Fix\n\nFix flagged Kodex topics by generating updated content.\n\n## Overview\n\nThis skill lists open Kodex flags and routes to the appropriate sub-skill based on flag type. After the sub-skill creates a draft, the user can review and approve it in the Kodex UI.\n\n**Use when:**\n- You see open flags in the Kodex dashboard\n- A topic has been flagged as outdated, incorrect, incomplete, or missing\n\n---\n\n## Step 1: List Open Flags\n\nQuery for open flags:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_list_flags\nArgs: { \"project\": \"<absolute-path-to-cwd>\", \"status\": \"open\" }\n```\n\n**If no open flags:**\n```\nNo open flags to fix.\n\nUse the Kodex dashboard to view all flags or /kodex-init to create new topics.\n```\n**STOP** - exit the skill.\n\n---\n\n## Step 2: Select Flag\n\nPresent flags to user:\n\n```\nOpen flags:\n\n1. [outdated] topic-name: Description of the issue\n2. [incorrect] another-topic: Description of the issue\n3. [missing] new-topic: Description of the issue\n\nWhich flag do you want to fix?\n```\n\nUse AskUserQuestion with multiple choice.\n\n---\n\n## Step 3: Route to Sub-Skill\n\nBased on the selected flag's type:\n\n| Flag Type | Sub-Skill |\n|-----------|-----------|\n| outdated | Invoke skill: kodex-fix-outdated |\n| incorrect | Invoke skill: kodex-fix-incorrect |\n| incomplete | Invoke skill: kodex-fix-incomplete |\n| missing | Invoke skill: kodex-fix-missing |\n\nPass the topic name and flag description to the sub-skill.\n\n---\n\n## Step 4: Completion\n\nAfter sub-skill returns:\n\n```\nDraft created for [topic-name].\n\nReview and approve the draft in the Kodex UI:\n- Go to Kodex > Drafts\n- Review the content\n- Click \"Approve\" to publish (this will auto-resolve the flag)\n\nFix another flag?\n\n1. Yes\n2. No\n```\n\nIf user selects **1 (Yes)**: Return to Step 1\nIf user selects **2 (No)**: Exit skill\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| MCP tool failure | Display error, suggest retry |\n| Flag not found | Refresh list, flag may have been resolved |\n\n---\n\n## Integration\n\n**Standalone skill** - Does not require an active collab session.\n\n**Related skills:**\n- `kodex-fix-outdated` - Update stale content\n- `kodex-fix-incorrect` - Fix factual errors\n- `kodex-fix-incomplete` - Fill missing sections\n- `kodex-fix-missing` - Create new topics\n- `using-kodex` - Query and flag topics\n- `kodex-init` - Bootstrap topic stubs\n",
        "skills/kodex-generate-aliases/SKILL.md": "---\nname: kodex-generate-aliases\ndescription: Use when generating aliases for Kodex topics to improve findability and search coverage\n---\n\n# Generate Aliases for Kodex Topic\n\n## Overview\n\nKodex topics can only be found by exact name match. This skill automates alias generation to make topics discoverable through synonyms, abbreviations, and related terms. Generate aliases for a topic and approve additions in one workflow.\n\n**Core principle:** Good aliases expand discoverability without cluttering the knowledge base.\n\n## When to Use\n\n- Adding multiple aliases to an existing topic manually is tedious\n- You want to quickly generate relevant search terms for a topic\n- You need to improve topic findability without renaming it\n- Batch-generating aliases across multiple topics\n\n**When NOT to use:**\n- Manual alias management for 1-2 topics (use the UI directly)\n- Fixing incorrect generated aliases (edit them individually in UI)\n\n## Quick Reference\n\n**Invoke the skill:**\n```\n/kodex-generate-aliases topic-name\n```\n\n**What happens:**\n1. Load topic and display current aliases\n2. Generate new aliases from title, synonyms, abbreviations, content\n3. Show generated aliases for approval\n4. Add confirmed aliases to topic\n\n**Aliases come from 4 sources:**\n| Source | Example |\n|--------|---------|\n| **Title keywords** | Topic \"debugging-with-logs\" → \"debugging\", \"logs\" |\n| **Synonyms** | \"db\" → \"database\", \"storage\", \"data\" |\n| **Abbreviations** | \"configuration\" → \"config\" |\n| **Content keywords** | Most-used words from topic content |\n\n## Workflow\n\n### Step 1: Select Topic\n\nProvide a topic name. The skill loads the full topic with content.\n\n**Input format:** `/kodex-generate-aliases topic-name`\n\n**Error handling:**\n- Topic not found: \"Topic 'xyz' not found. Check name and try again.\"\n- Topic without title: Use topic name as fallback\n\n### Step 2: Generate Aliases\n\nThe skill calls the `generateAliases()` function with:\n- Topic name (canonical identifier)\n- Topic title (for keyword extraction)\n- Topic content (for keyword frequency analysis)\n\n**Generation rules:**\n- Extract keywords from title (words > 2 chars)\n- Expand with SYNONYMS map (e.g., \"auth\" → \"authentication\", \"login\", \"signin\")\n- Expand with ABBREVIATIONS (e.g., \"authentication\" ↔ \"auth\")\n- Extract top 5 keywords from content (if included)\n- Remove canonical name from results\n- Max 10 aliases per topic\n- Remove duplicates automatically\n\n### Step 3: Show Generated Aliases\n\nDisplay:\n- **Current aliases:** What the topic already has\n- **Generated aliases:** What the system suggests\n- **Difference:** Which ones are new\n\nExample output:\n```\nTopic: testing-async-code\nCurrent aliases: [testing, async, flaky]\nGenerated aliases: [timing, timeout, condition-based, wait, awaiting]\nNew: [timeout, condition-based, wait, awaiting] (4 new)\n```\n\n### Step 4: Approve Aliases\n\nUser selects which generated aliases to add:\n- ✓ Approve all suggested aliases\n- ✓ Select subset to add\n- ✗ Reject all and exit\n\n**Validation:**\n- Skip aliases that are already present\n- Warn if adding alias that matches other topic names\n- Confirm before applying changes\n\n### Step 5: Add to Topic\n\nFor each approved alias, call `kodexApi.addAlias(topicName, alias)`.\n\nDisplay confirmation:\n```\nAdded 4 aliases to 'testing-async-code':\n✓ timeout\n✓ condition-based\n✓ wait\n✓ awaiting\n```\n\n## Implementation Notes\n\n### Function Dependencies\n\nThe skill relies on `generateAliases()` function (implemented separately):\n\n```typescript\nexport function generateAliases(\n  name: string,           // Topic name (canonical)\n  title: string,          // Topic title\n  content?: TopicContent, // Full topic content\n  options?: AliasGeneratorOptions\n): string[]\n```\n\n**What generateAliases returns:**\n- Array of strings (candidate aliases)\n- Already deduplicated and limited to max 10\n- Does NOT include the canonical name\n- Sorted alphabetically\n\n### API Methods Required\n\nThe skill uses these kodex API methods:\n\n```typescript\n// Load full topic with content\ngetTopic(project: string, name: string): Promise<Topic>\n\n// Add alias to topic\naddAlias(project: string, topicName: string, alias: string): Promise<void>\n```\n\n### Constants\n\nThe skill uses these constants from `alias-generator.ts`:\n\n**SYNONYMS:** Word variations (e.g., \"auth\" → \"authentication\", \"login\")\n\n**ABBREVIATIONS:** Long-form ↔ short-form pairs (e.g., \"authentication\" ↔ \"auth\")\n\n**MAX_ALIASES:** 10 (cap on returned aliases)\n\n**MIN_ALIAS_LENGTH:** 2 (minimum alias length)\n\n### Browser-Based UI\n\nWhen displaying generated aliases and asking for approval, use `render_ui` to show in browser:\n\n```typescript\nmcp__mermaid__render_ui({\n  project,\n  session,\n  ui: {\n    type: 'Checklist',\n    items: generatedAliases.map(alias => ({\n      label: alias,\n      checked: true // Pre-select all\n    })),\n    name: 'aliasSelection'\n  },\n  blocking: true\n})\n```\n\nWhen user responds, extract selected aliases from form data and proceed to add.\n\n## Real-World Example\n\n### Scenario: Improve discoverability of \"authentication\" topic\n\n**Starting state:**\n```\nTopic: authentication\nCurrent aliases: [auth, login]\nContent: ~500 words on auth patterns, OAuth, JWT\n```\n\n**Run:** `/kodex-generate-aliases authentication`\n\n**Generation:**\n1. Title keywords: [\"authentication\"] (only 1 word)\n2. Synonyms: \"auth\" is in title → add [\"authentication\", \"login\", \"signin\", \"authorization\"]\n3. Abbreviations: \"authentication\" is long → add \"auth\" (already present)\n4. Content keywords: [\"oauth\", \"jwt\", \"bearer\", \"token\", \"session\"]\n5. Deduplicate: [\"authorization\", \"signin\", \"oauth\", \"jwt\", \"bearer\", \"token\", \"session\"]\n\n**User sees:**\n```\nTopic: authentication\nCurrent aliases: [auth, login]\nGenerated: [authorization, signin, oauth, jwt, bearer, token, session] (7 new)\n```\n\n**User approves all 7.**\n\n**Result:**\n```\nTopic: authentication now has aliases:\n[auth, login, authorization, signin, oauth, jwt, bearer, token, session]\n```\n\nNow queries for \"oauth\", \"jwt\", \"bearer\", \"token\", or \"authorization\" all find \"authentication\".\n\n## Common Mistakes\n\n### Mistake 1: Approving aliases that match topic names\n\n**Problem:** Generated alias happens to match another topic's name (e.g., \"auth\" exists as separate topic)\n\n**Fix:** Warning message appears: \"Alias 'auth' matches topic name 'auth'. Add anyway? (not recommended)\"\n\n**Prevention:** Always review the generated list before approving.\n\n### Mistake 2: Over-aliasing a topic\n\n**Problem:** Added 20+ aliases making the topic too discoverable for unrelated queries\n\n**Fix:** Capped at 10 aliases max. If you need more, add manually one at a time through UI.\n\n**Prevention:** Review each generated batch. If too many, decrease content keyword inclusion.\n\n### Mistake 3: Forgetting synonyms are bidirectional\n\n**Problem:** Generated \"auth\" but forgot it also adds \"authentication\", \"login\", etc.\n\n**Fix:** The SYNONYMS map is bidirectional. Adding \"auth\" automatically includes \"authentication\" and vice versa.\n\n**Prevention:** Check the SYNONYMS constant to understand expansion rules.\n\n## Edge Cases\n\n### Very short topic name (1 word)\n\n**Behavior:** Still generates aliases from synonyms and abbreviations.\n\n**Example:** Topic \"auth\"\n- Title keywords: [\"auth\"]\n- Synonyms: [\"authentication\", \"login\", \"signin\"]\n- Abbreviations: (none apply, \"auth\" is short form)\n- Result: [\"authentication\", \"login\", \"signin\"]\n\n### Topic with no content\n\n**Behavior:** Uses title only (skips content keywords).\n\n**Example:** Topic \"new-topic\" with empty content\n- Title keywords: [\"new\", \"topic\"] (both length > 2)\n- Synonyms: (none match)\n- Result: [\"new\", \"topic\"] (minimal but useful)\n\n### Content with stop words\n\n**Behavior:** Automatically filters stop words (the, a, an, is, etc.)\n\n**Example:** Content \"The authentication system is a critical component...\"\n- Extracted: [\"authentication\", \"system\", \"critical\", \"component\"] (not \"the\", \"is\", \"a\")\n\n### Duplicate aliases\n\n**Behavior:** Automatically deduplicated at generation time.\n\n**Example:** Title \"authentication\" + synonym \"authentication\"\n- Generated once, not twice\n\n## Troubleshooting\n\n### \"Topic not found\" error\n\n**Cause:** Topic name doesn't exist or typo in name\n\n**Fix:**\n1. Check Kodex topic list for exact spelling\n2. Use topic's canonical name (not an alias of another topic)\n3. Try: `kodex-query-topic topic-name` to verify it exists\n\n### Generated aliases seem wrong\n\n**Cause:** SYNONYMS map doesn't include the terms you expected\n\n**Fix:**\n1. Check `src/services/alias-generator.ts` SYNONYMS constant\n2. Add the missing synonym pair (requires code change)\n3. For now, manually add the alias through UI\n\n### Too many aliases generated\n\n**Cause:** Content is very verbose or has many repeated keywords\n\n**Fix:**\n1. Review the generated list and select only the most relevant\n2. Don't feel obligated to approve all suggestions\n3. Keep aliases focused on alternate names, not full topic descriptions\n\n## Advanced Configuration\n\n### Custom generation options\n\nIf you need different generation behavior, `generateAliases()` accepts options:\n\n```typescript\ngenerateAliases(name, title, content, {\n  maxAliases: 15,              // Return up to 15 aliases\n  minAliasLength: 3,           // Aliases must be 3+ chars\n  includeSynonyms: true,       // Include synonym expansion\n  includeAbbreviations: true,  // Include abbreviation expansion\n  includeContentKeywords: true // Extract keywords from content\n})\n```\n\nThe skill uses defaults. To use custom options, modify the generateAliases() call in the skill implementation.\n\n## Integration with Kodex Workflow\n\n**Auto-generation on topic creation** (optional, future enhancement):\n- When `createTopic()` is called, automatically generate aliases\n- User can review and edit before saving\n- Not required for MVP\n\n**Alias removal:**\n- Use `kodex_remove_alias` MCP tool (separate skill)\n- Or edit directly in Kodex UI\n\n**Alias conflicts:**\n- If alias is already present, adding it is a no-op\n- UI validates before applying\n\n## Performance Considerations\n\n**Generation time:** < 100ms for typical topics\n- Keyword extraction: O(title length)\n- Synonym expansion: O(keywords × synonym map size)\n- Content keywords: O(content length) for frequency analysis\n- Limit: max 10 aliases, so output is bounded\n\n**Storage:** Minimal\n- Aliases stored as JSON array in SQLite\n- Typical topic: 5-10 aliases = 50-100 bytes\n\n**Query performance:** Not impacted\n- Alias lookup uses LIKE on JSON array: `aliases LIKE '%\"alias-name\"%'`\n- Index not required (tables typically small)\n",
        "skills/kodex-init/SKILL.md": "---\nname: kodex-init\ndescription: Bootstrap a Kodex knowledge base by analyzing codebase structure and creating topic stubs\nuser-invocable: true\nallowed-tools:\n  - Bash\n  - Glob\n  - Grep\n  - Read\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n  - mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\n---\n\n# Kodex Init\n\nBootstrap a Kodex knowledge base by analyzing codebase structure and creating topic stubs.\n\n## Overview\n\nThis skill analyzes a codebase to identify logical topic boundaries and creates stub topics in the Kodex knowledge base. Topics are created as drafts requiring human approval before going live.\n\n**Use when:**\n- Setting up Kodex for a new project\n- Onboarding to an unfamiliar codebase\n- Refreshing topic coverage after major refactoring\n\n---\n\n## Step 1: Explore Codebase Structure\n\nWalk the directory tree to understand the project structure.\n\n### 1.1 List Top-Level Directories\n\n```bash\nls -d */ 2>/dev/null | grep -v -E '^(node_modules|vendor|\\.git|dist|build|out|coverage|__pycache__|\\.)'\n```\n\n### 1.2 Check Framework Indicators\n\nLook for these files to identify the tech stack:\n- `package.json` → Node.js/React/Vue\n- `pubspec.yaml` → Flutter/Dart\n- `Cargo.toml` → Rust\n- `go.mod` → Go\n- `*.csproj` → .NET\n- `requirements.txt` / `pyproject.toml` → Python\n\n### 1.3 Check Infrastructure Files\n\n- `Dockerfile`, `docker-compose.yml` → deployment topic\n- `.github/workflows/`, `.gitlab-ci.yml` → ci-cd topic\n- `jest.config.*`, `vitest.config.*`, `pytest.ini` → testing topic\n- `.env`, `config/` → configuration topic\n\n### Exclusion Patterns\n\n**Always exclude:**\n- `node_modules/`, `vendor/`, `.git/`\n- `dist/`, `build/`, `out/`, `coverage/`\n- `__pycache__/`, `.cache/`\n- Hidden directories (starting with `.`)\n- Binary and generated files\n\n---\n\n## Step 2: Build Topic List\n\n### 2.1 Directory-Based Topics\n\nFor each significant directory (3+ files or contains entry point):\n\n```\ntopic_name = kebab-case(directory_name)\ntitle = Title Case(directory_name)\nsource_files = [list of files in directory]\n```\n\n### 2.2 Standard Topics\n\nCheck for and add these standard topics when indicators exist:\n\n| Topic | Indicators |\n|-------|------------|\n| `deployment` | Dockerfile, docker-compose.yml, k8s/, helm/ |\n| `ci-cd` | .github/workflows/, .gitlab-ci.yml, .circleci/ |\n| `testing` | test/, __tests__/, *.test.*, jest.config.*, pytest.ini |\n| `configuration` | .env*, config/, settings.* |\n| `database` | migrations/, schema/, prisma/, drizzle/ |\n| `authentication` | auth/, login/, session/, jwt/ |\n| `api` | routes/, controllers/, api/, endpoints/ |\n\n### 2.3 Granularity Guidelines\n\n- **Target:** 10-30 topics depending on codebase size\n- **Merge:** Similar small folders into one topic\n- **Split:** Large complex areas (20+ files) into multiple topics\n- **Don't:** Create a topic for every single file\n\n---\n\n## Step 3: Present for Approval\n\nDisplay the proposed topic list to the user:\n\n```\nProposed topics for this codebase:\n\n1. [name]: Title (N files)\n   - path/to/file1\n   - path/to/file2\n\n2. [name]: Title (N files)\n   ...\n```\n\nAsk user:\n```\nWhat would you like to do?\n\n1. Approve all - Create these topics\n2. Add a topic - I want to add another\n3. Remove a topic - Remove one from the list\n4. Edit a topic - Modify name or files\n```\n\nHandle modifications and re-display until user approves.\n\n---\n\n## Step 4: Create Topics\n\nFor each approved topic, call the MCP tool:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_create_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"<topic-name>\",\n  \"title\": \"<Topic Title>\",\n  \"content\": {\n    \"conceptual\": \"# <Topic Title>\\n\\nTopic pending documentation.\\n\\n## Source Files\\n- path/to/file1\\n- path/to/file2\",\n    \"technical\": \"\",\n    \"files\": \"\",\n    \"related\": \"\"\n  }\n}\n```\n\n---\n\n## Step 5: Flag Topics as Incomplete\n\nAfter creating all topics, flag each one as incomplete so they appear in the fix queue:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"<topic-name>\",\n  \"type\": \"incomplete\",\n  \"description\": \"Stub topic needs detailed content based on actual codebase analysis\"\n}\n```\n\nCall this for each topic created in Step 4.\n\n### Summary\n\nAfter creating and flagging all topics, display:\n\n```\nCreated N topics as drafts:\n- topic-1: Title 1\n- topic-2: Title 2\n...\n\nAll topics flagged as incomplete for review.\nUse /kodex-fix to fill in detailed content, or review drafts in the Kodex UI.\n```\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| Cannot read directory | Log warning, skip, continue |\n| No significant directories | Warn user, ask for guidance |\n| MCP tool fails | Log error, continue with remaining |\n| User cancels | Exit with no changes |\n\n---\n\n## MCP Tools Reference\n\n| Tool | Purpose |\n|------|---------|\n| `kodex_create_topic` | Create a new topic as draft |\n| `kodex_list_topics` | Check existing topics before creating |\n| `kodex_flag_topic` | Flag topic as incomplete for review |\n\n---\n\n## Integration\n\n**Standalone skill** - Does not require an active collab session.\n\n**Related skills:**\n- `kodex-fix` - Fix flagged incomplete topics\n- `using-kodex` - Query and flag existing topics\n",
        "skills/mermaid-collab/SKILL.md": "---\nname: mermaid-collab\ndescription: Create and collaborate on Mermaid diagrams and UI wireframes with real-time preview and team sharing\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Skill\nuser-invocable: false\n---\n\n# Mermaid Collaboration Tool\n\nThis skill helps you create, edit, and collaborate on Mermaid diagrams and UI wireframes using the claude-mermaid-collab server.\n\n## What This Tool Provides\n\n- **Real-time Diagram Editor**: Live preview with pan, zoom, and auto-save for Mermaid diagrams\n- **Real-time Document Editor**: Markdown document collaboration with live preview\n- **UI Wireframe Plugin**: Text-based wireframe creation for mobile, tablet, and desktop\n- **Team Collaboration**: Real-time updates across all connected clients via WebSocket\n- **File-Based Storage**: Simple `.mmd` and `.md` files for version control\n- **Unified Dashboard**: Browse and manage both diagrams and documents in one place\n- **MCP Integration**: Create and manage diagrams and documents directly from Claude Code\n\n## Running the Server\n\nThe server can be run from any directory. Use `STORAGE_DIR` to specify where diagrams and documents are stored.\n\n**Run from the claude-mermaid-collab repository:**\n```bash\n# Store diagrams/docs in a specific project directory\nSTORAGE_DIR=/path/to/your/project bun run src/server.ts\n\n# Or store in current directory (default)\nbun run dev\n```\n\nThe server starts on `http://localhost:3737`. The `PUBLIC_DIR` (HTML/CSS/JS) is always resolved relative to the server installation, so static files work regardless of where you run it from.\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- Create flowcharts, state diagrams, sequence diagrams, or any Mermaid diagram\n- Design UI wireframes and mockups with text-based syntax\n- Write and collaborate on markdown documentation, specs, or notes\n- Collaborate with team members in real-time on diagrams or documents\n- Quickly prototype and iterate on visual designs\n- Document workflows, architectures, or processes\n- Create technical documentation with live preview\n\n## MCP Tools Available\n\nThe server provides these MCP tools through Claude Code:\n\n### Diagrams\n- `list_diagrams()` - List all diagrams with metadata\n- `get_diagram(id)` - Read diagram content\n- `create_diagram(name, content)` - Create new diagram (auto-validates)\n- `update_diagram(id, content)` - Replace full diagram content (auto-validates)\n- `patch_diagram(id, old_string, new_string)` - **Preferred for small edits** - efficient search-replace\n- `validate_diagram(content)` - Check syntax without saving\n- `preview_diagram(id)` - Get browser URL for diagram\n\n### Documents\nDocuments are markdown files (`.md`) for collaborative writing - specs, documentation, meeting notes, etc.\n\n- `list_documents()` - List all markdown documents with metadata\n- `get_document(id)` - Read full document content and metadata\n- `create_document(name, content)` - Create new markdown document (returns ID and preview URL)\n- `update_document(id, content)` - Replace full document content with real-time sync\n- `patch_document(id, old_string, new_string)` - **Preferred for small edits** - efficient search-replace\n- `preview_document(id)` - Get browser URL for document viewer\n\n### Patch vs Update\n\n**Prefer `patch_document`/`patch_diagram`** for targeted changes:\n- Changing a status field\n- Updating a single value\n- Adding text at a specific location\n\n**Use `update_document`/`update_diagram`** for:\n- Adding entirely new sections\n- Restructuring large portions\n- When patch fails (old_string not found or matches multiple locations)\n\n**Note**: There is no delete_document MCP tool yet. Use the dashboard delete button or REST API for deletion.\n\n## Creating Standard Mermaid Diagrams\n\n### Flowchart Example\n```mermaid\ngraph TD\n  A[Start] --> B{Is it working?}\n  B -->|Yes| C[Great!]\n  B -->|No| D[Debug]\n  D --> A\n```\n\n### Direction Toggle\nUse the direction toggle button (⤡) in the editor to switch between:\n- **LR** (Left to Right) - Horizontal layout\n- **TD** (Top Down) - Vertical layout\n\nSupported directions: TD, TB, BT, RL, LR\n\n## Creating UI Wireframes\n\nThe built-in wireframe plugin lets you create UI mockups with text syntax.\n\n### Basic Wireframe Syntax\n\n```\nwireframe mobile TD\n  screen \"Login Screen\"\n    col padding=16\n      Title \"Welcome Back\"\n      Input \"Email\"\n      Input \"Password\"\n      Button \"Sign In\" primary\n```\n\n### Viewports\n- `wireframe mobile` - 375px width\n- `wireframe tablet` - 768px width\n- `wireframe desktop` - 1200px width\n\n### Layout Directions\n- `TD` - Top Down (vertical, default)\n- `LR` - Left Right (horizontal)\n\n### Container Types\n- `screen \"Title\"` - Top-level screen container\n- `col` - Vertical column layout\n- `row` - Horizontal row layout\n- `Card` - Card container with rounded corners\n\n### UI Widgets\n\n**Input Controls:**\n- `Button \"Label\"` - Button (can add `primary`, `secondary`, `danger`, `success`)\n- `Input \"Placeholder\"` - Text input field\n- `Checkbox \"Label\"` - Checkbox with label\n- `Radio \"Label\"` - Radio button with label\n- `Switch \"Label\"` - Toggle switch\n- `Dropdown \"Label\"` - Dropdown selector\n\n**Display Elements:**\n- `Text \"Content\"` - Normal text\n- `Title \"Heading\"` - Bold heading text\n- `Icon \"name\"` - Icon placeholder\n- `Image` - Image placeholder\n- `Avatar` - User avatar circle\n\n**Navigation:**\n- `AppBar \"Title\"` - Top app bar\n- `NavMenu \"Home|About|Contact\"` - Horizontal navigation (use `|` to separate items)\n- `BottomNav \"Home|Search|Profile\"` - Bottom navigation\n- `FAB \"+\"` - Floating action button\n\n**Structure:**\n- `Grid` - Table/grid layout (use with `header` and `row` children)\n- `List \"Item 1|Item 2|Item 3\"` - List of items\n- `divider` - Horizontal divider line\n- `spacer` - Flexible space\n\n### Layout Modifiers\n\nAdd modifiers after widget names:\n- `width=200` - Fixed width in pixels\n- `height=100` - Fixed height in pixels\n- `padding=16` - Padding around content\n- `flex` or `flex=2` - Take remaining space (optionally with weight)\n- `align=start|center|end|space-between` - Horizontal alignment\n- `cross=start|center|end` - Vertical alignment\n\n### Complex Wireframe Example\n\n```\nwireframe mobile TD\n  screen \"Dashboard\"\n    AppBar \"My App\"\n    col padding=16\n      Title \"Welcome\"\n      Text \"Here's your overview\"\n      spacer\n      row\n        Card padding=8 flex\n          Text \"Sales\"\n          Title \"$1,234\"\n        Card padding=8 flex\n          Text \"Orders\"\n          Title \"56\"\n      spacer\n      List \"Recent|Pending|Complete\"\n    BottomNav \"Home|Stats|Profile\"\n```\n\n## Collaborating on Markdown Documents\n\nThe document collaboration feature allows teams to write and edit markdown documents with real-time updates, just like diagrams.\n\n### What Documents Are For\n\nDocuments are markdown (`.md`) files for:\n- **Technical Specifications**: API docs, requirements, design specs\n- **Meeting Notes**: Collaborative note-taking during meetings\n- **Project Documentation**: README files, wikis, guides\n- **Architecture Decisions**: ADRs, technical decision records\n- **User Stories**: Feature descriptions, acceptance criteria\n- **Team Knowledge**: How-tos, troubleshooting guides, onboarding docs\n\n### Creating Documents\n\n```\ncreate_document(\"api-spec\", \"\"\"\n# Payment API Specification\n\n## Overview\nThis document describes the payment API endpoints.\n\n## Authentication\nAll requests require Bearer token authentication.\n\n## Endpoints\n\n### POST /api/payments\nCreate a new payment transaction.\n\n**Request Body:**\n```json\n{\n  \"amount\": 100.00,\n  \"currency\": \"USD\",\n  \"customer_id\": \"cust_123\"\n}\n\\```\n\n**Response:**\n```json\n{\n  \"id\": \"pay_456\",\n  \"status\": \"pending\",\n  \"created_at\": \"2024-01-13T10:00:00Z\"\n}\n\\```\n\n## Error Codes\n- `400` - Invalid request\n- `401` - Unauthorized\n- `500` - Server error\n\"\"\")\n```\n\n### Document Editor Features\n\nThe document editor (`/document.html?id=<id>`) provides:\n- **Split-pane view**: Markdown source on left, rendered preview on right\n- **Live preview**: See formatted output as you type\n- **Auto-save**: Saves automatically 500ms after you stop typing\n- **Undo/Redo**: Full history with Ctrl+Z / Ctrl+Shift+Z\n- **Syntax highlighting**: Code blocks with language support\n- **Real-time collaboration**: See updates from other users instantly\n- **Resizable panes**: Drag the separator to adjust layout\n- **Clean content API**: Get sanitized HTML for safe rendering\n- **Review workflow**: Comment, propose, approve, and reject content\n\n### Review Workflow\n\nThe document editor includes a review workflow for collaborative editing with visual status indicators:\n\n**Toolbar Buttons:**\n- **💬 Comment** - Add comments to selections or at cursor\n- **◇ Propose** (cyan) - Mark content as proposed/suggested\n- **✓ Approve** (green) - Mark content as approved\n- **✗ Reject** (red) - Mark content as rejected with reason\n- **⊘ Clear** - Remove any status markers\n\n**Status Types:**\n\n| Status | Color | Section Marker | Inline Marker |\n|--------|-------|----------------|---------------|\n| Proposed | Cyan | `<!-- status: proposed: label -->` | `<!-- propose-start: label -->...<!-- propose-end -->` |\n| Approved | Green | `<!-- status: approved -->` | `<!-- approve-start -->...<!-- approve-end -->` |\n| Rejected | Red | `<!-- status: rejected: reason -->` | `<!-- reject-start: reason -->...<!-- reject-end -->` |\n| Comment | Yellow | `<!-- comment: text -->` | `<!-- comment-start: text -->...<!-- comment-end -->` |\n\n**How It Works:**\n- **Select text** then click a button → wraps selection with inline markers\n- **Cursor on list item** then click → wraps the list item content\n- **Cursor under heading** then click → adds section-level status after heading\n- **Toggle between states** → clicking Approve on proposed content switches it to approved\n- Markers are HTML comments, so they're invisible in standard markdown renderers\n\n**Example Usage:**\n```markdown\n## Feature Proposal\n<!-- status: proposed: new authentication flow -->\n\nThis section describes the new login system.\n\nWe should use <!-- propose-start: needs discussion -->OAuth 2.0<!-- propose-end --> for authentication.\n\n- <!-- approve-start -->Email/password login<!-- approve-end -->\n- <!-- reject-start: too complex for MVP -->Biometric auth<!-- reject-end -->\n```\n\n### Markdown Features Supported\n\nThe editor supports full GitHub-Flavored Markdown:\n- **Headings**: `# H1` through `###### H6`\n- **Bold**: `**bold**` or `__bold__`\n- **Italic**: `*italic*` or `_italic_`\n- **Links**: `[text](url)`\n- **Images**: `![alt](url)`\n- **Code blocks**: \\```language ... \\```\n- **Inline code**: \\`code\\`\n- **Lists**: Unordered (`-`, `*`, `+`) and ordered (`1.`, `2.`)\n- **Blockquotes**: `> quote`\n- **Tables**: Pipe-separated tables\n- **Task lists**: `- [ ]` unchecked, `- [x]` checked\n- **Horizontal rules**: `---`, `***`, or `___`\n\n### Document Workflow Example\n\n```\n# 1. Create a spec document\nresult = create_document(\"feature-spec\", \"\"\"\n# User Authentication Feature\n\n## Problem Statement\nUsers need a secure way to log into the application.\n\n## Proposed Solution\nImplement JWT-based authentication with refresh tokens.\n\n## Requirements\n1. Email/password login\n2. JWT tokens with 15-minute expiry\n3. Refresh token rotation\n4. Password reset flow\n\n## API Endpoints\n- POST /auth/login\n- POST /auth/refresh\n- POST /auth/logout\n- POST /auth/reset-password\n\n## Security Considerations\n- Passwords hashed with bcrypt\n- Tokens stored in httpOnly cookies\n- Rate limiting on login attempts\n\"\"\")\n\n# 2. Share preview URL with team\npreview_document(\"feature-spec\")\n\n# 3. Team reviews and adds comments/updates in real-time\n\n# 4. Update based on feedback\nupdate_document(\"feature-spec\", \"\"\"\n# User Authentication Feature\n\n## Problem Statement\nUsers need a secure way to log into the application.\n\n## Proposed Solution\nImplement JWT-based authentication with refresh tokens and optional 2FA.\n\n## Requirements\n1. Email/password login\n2. JWT tokens with 15-minute expiry\n3. Refresh token rotation\n4. Password reset flow\n5. **NEW**: Optional TOTP 2FA\n\n## API Endpoints\n- POST /auth/login\n- POST /auth/refresh\n- POST /auth/logout\n- POST /auth/reset-password\n- **NEW**: POST /auth/2fa/enable\n- **NEW**: POST /auth/2fa/verify\n\n## Security Considerations\n- Passwords hashed with bcrypt (cost factor 12)\n- Tokens stored in httpOnly, secure cookies\n- Rate limiting: 5 attempts per 15 minutes\n- 2FA backup codes generated on enable\n\"\"\")\n```\n\n### Document Best Practices\n\n1. **Use descriptive names**: `api-architecture` not `doc1`\n2. **Structure with headings**: Use H1 for title, H2 for sections\n3. **Keep it focused**: One document per topic/feature\n4. **Link related docs**: Use markdown links to connect documents\n5. **Version in git**: Documents are `.md` files - commit them\n6. **Add timestamps**: Include \"Last updated\" dates for living docs\n7. **Use code blocks**: Properly format code examples with language tags\n8. **Create templates**: Standardize document structure for consistency\n\n### Dashboard Features\n\nThe unified dashboard shows both diagrams and documents:\n- **Type badges**: Blue \"Diagram\" and purple \"Document\" badges\n- **Type filter**: Filter by \"All Items\", \"Diagrams Only\", or \"Documents Only\"\n- **Search**: Search across both diagrams and documents\n- **Preview**: Documents show first heading or first 100 characters\n- **Thumbnails**: Diagrams show rendered preview, documents show text excerpt\n- **Sort by date**: Newest items first\n- **Delete all**: Remove all diagrams and documents at once\n\n## Best Practices\n\n### Diagram Naming\n- Use descriptive names: `user-login-flow` not `diagram1`\n- Use hyphens, not spaces: `api-architecture` not `api architecture`\n- Keep names lowercase for consistency\n\n### Collaboration Workflow\n1. Create diagram: `create_diagram(\"feature-flow\", content)`\n2. Share the preview URL with team members\n3. Team members can view real-time updates in their browsers\n4. Everyone sees changes instantly via WebSocket\n\n### Wireframe Design Tips\n1. **Start with screens**: Define your main screens first\n2. **Use containers**: Group related elements in `col` and `row`\n3. **Add padding**: Use `padding=16` on containers for spacing\n4. **Flexible layouts**: Use `flex` for responsive elements\n5. **Toggle direction**: Try both LR and TD to see what works best\n\n### Version Control\nAll diagrams are stored as `.mmd` files in the `diagrams/` folder:\n- Easy to commit to git\n- Plain text, easy to diff\n- Can edit externally with any text editor\n- Auto-reloads in the web interface\n\n## Editor Features\n\n### Keyboard Shortcuts\n- **Undo**: Ctrl+Z (managed by editor)\n- **Redo**: Ctrl+Shift+Z (managed by editor)\n- **Auto-save**: 500ms after typing stops\n\n### Pan & Zoom Controls\n- **Mouse wheel**: Zoom in/out\n- **Drag**: Pan around diagram\n- **⊡ Fit**: Fit entire diagram to viewport\n- **↔ Fit Width**: Fit diagram width\n- **↕ Fit Height**: Fit diagram height\n- **↻ Reset**: Reset zoom to 100%\n- **+ / −**: Zoom in/out buttons\n\n### Resizable Panes\n- **Drag the separator** between code and preview\n- Customize your preferred layout\n- Setting persists across sessions\n\n## Common Patterns\n\n### Mobile App Wireframe\n```\nwireframe mobile TD\n  screen \"Profile\"\n    AppBar \"Profile\"\n    col padding=16\n      Avatar\n      Title \"John Doe\"\n      Text \"john@example.com\"\n      divider\n      List \"Settings|Privacy|Help|Logout\"\n```\n\n### Desktop Dashboard\n```\nwireframe desktop LR\n  screen \"Analytics Dashboard\"\n    col width=200\n      NavMenu \"Dashboard|Reports|Users\"\n    col flex padding=20\n      Title \"Analytics Overview\"\n      row\n        Card flex padding=16\n          Text \"Total Users\"\n          Title \"1,234\"\n        Card flex padding=16\n          Text \"Revenue\"\n          Title \"$56,789\"\n```\n\n### Form Layout\n```\nwireframe tablet TD\n  screen \"Registration\"\n    col padding=24\n      Title \"Create Account\"\n      Input \"Full Name\"\n      Input \"Email Address\"\n      Input \"Password\"\n      Checkbox \"I agree to terms\"\n      spacer\n      Button \"Sign Up\" primary\n      Text \"Already have an account?\"\n```\n\n## Troubleshooting\n\n### Diagram Not Rendering\n- Check syntax with `validate_diagram(content)` first\n- Look at error banner in editor for line-specific errors\n- Make sure Mermaid syntax is valid\n\n### Wireframe Not Showing\n- Verify first line starts with `wireframe`\n- Check indentation (use spaces, not tabs)\n- Make sure viewport is specified: `wireframe mobile`\n\n### Real-time Updates Not Working\n- Check WebSocket connection status (top-right indicator)\n- Click the status indicator to reconnect if disconnected\n- Make sure you're subscribed to the correct diagram\n\n## Pro Tips\n\n1. **Use validate before save**: Call `validate_diagram()` to catch errors early\n2. **Preview URL sharing**: Use `preview_diagram(id)` to get sharable links\n3. **Direction matters**: Horizontal (LR) works better for wide diagrams, vertical (TD) for tall ones\n4. **Prototype fast**: Wireframes are text-based, so iterate quickly\n5. **Version everything**: Commit `.mmd` files to git for history\n6. **Test viewports**: Try mobile, tablet, desktop to see what works best\n7. **Use badges**: Dashboard shows diagram vs document badges for easy identification\n\n## Example Workflow\n\n```\n# 1. Create a new wireframe\ncreate_diagram(\"checkout-flow\", \"\"\"\nwireframe mobile TD\n  screen \"Cart\"\n    AppBar \"Shopping Cart\"\n    col padding=16\n      List \"Item 1|Item 2|Item 3\"\n      divider\n      row\n        Text \"Total\"\n        spacer\n        Title \"$99.99\"\n      Button \"Checkout\" primary\n\"\"\")\n\n# 2. Get preview URL\npreview_diagram(\"checkout-flow\")\n\n# 3. Share with team, iterate based on feedback\n\n# 4. Update diagram\nupdate_diagram(\"checkout-flow\", \"\"\"\nwireframe mobile TD\n  screen \"Cart\"\n    AppBar \"Shopping Cart\"\n    col padding=16\n      List \"Item 1 - $29.99|Item 2 - $39.99|Item 3 - $30.01\"\n      divider\n      row\n        Text \"Subtotal\"\n        spacer\n        Text \"$99.99\"\n      row\n        Text \"Tax\"\n        spacer\n        Text \"$8.00\"\n      row\n        Title \"Total\"\n        spacer\n        Title \"$107.99\"\n      spacer\n      Button \"Proceed to Checkout\" primary\n\"\"\")\n```\n\n## Resources\n\n- **Web Dashboard**: http://localhost:3737/\n- **Editor**: http://localhost:3737/diagram.html?id=<diagram-id>\n- **Mermaid Docs**: https://mermaid.js.org/\n- **Project README**: See `/README.md` for full documentation\n- **Wireframe Plugin**: See `/plugins/wireframe/README.md` for detailed syntax\n\n---\n\n**Remember**: This is a collaboration tool - diagrams update in real-time for all connected users. Perfect for pair programming, design reviews, and team brainstorming sessions!\n",
        "skills/ready-to-implement/SKILL.md": "---\nname: ready-to-implement\ndescription: Validate design completion and transition to implementation phase\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep\nuser-invocable: false\n---\n\n# Ready to Implement\n\n## Collab Session Required\n\nBefore proceeding, check for active collab session:\n\n1. Check if `.collab/` directory exists\n2. Check if any session folders exist within\n3. If no session found:\n   ```\n   No active collab session found.\n\n   Use /collab to start a session first.\n   ```\n   **STOP** - do not proceed with this skill.\n\n4. If multiple sessions exist, check `COLLAB_SESSION_PATH` env var or ask user which session.\n\n## Overview\n\nValidates that all work items are documented and transitions from brainstorming to implementation phase.\n\n**Core principle:** No implementation without complete work item documentation.\n\n**Announce at start:** \"I'm using the ready-to-implement skill to validate design completion.\"\n\n## When to Use\n\nUse this skill when:\n- Work item loop is complete and you want to verify all items are documented\n- Resuming a session (collab skill always routes through here)\n- You want to transition from brainstorming to rough-draft phase\n\n## When NOT to Use\n\nDo NOT use this skill when:\n- No collab session is active (use `/collab` first)\n- Design document does not exist yet (use `/collab` to start a session)\n- Already in implementation phase (use `/executing-plans` instead)\n\n## Behavior\n\n1. Find active collab session\n2. Read design document\n3. Parse Work Items section for \"### Item N:\" sections\n4. Check each item's Status field (pending vs documented)\n5. If pending items exist: list them and return to work item loop\n6. If all documented: show summary and ask user confirmation\n7. On confirm: update state.phase to \"rough-draft/interface\" and invoke rough-draft\n\n## Implementation\n\nWhen invoked, follow these steps:\n\n### Step 1: Find Active Session\n\n```bash\n# List collab sessions\nls -d .collab/*/ 2>/dev/null | xargs -I{} basename {}\n```\n\nIf no sessions exist, report: \"No active collab sessions found.\"\n\nIf multiple sessions exist, ask user which session to check.\n\n### Step 2: Read Design Document\n\nUse the MCP tool to get the design document:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_document\nArgs: { \"project\": \"<project-path>\", \"session\": \"<session-name>\", \"id\": \"design\" }\n```\n\nOr read from filesystem:\n\n```bash\ncat .collab/<session-name>/documents/design.md\n```\n\n### Step 3: Parse Work Items\n\nLook for the \"## Work Items\" section in the design document.\n\n**Parse each item by finding \"### Item N:\" sections:**\n\nFor each `### Item N: <title>` section, extract:\n- `number`: The item number N\n- `title`: The text after \"Item N:\"\n- `type`: The value from `**Type:**` field\n- `status`: The value from `**Status:**` field (pending or documented)\n\n**Example work items section:**\n\n```markdown\n## Work Items\n\n### Item 1: Refactor database layer\n**Type:** refactor\n**Status:** documented\n**Problem/Goal:** ...\n**Approach:** ...\n**Success Criteria:** ...\n**Decisions:** ...\n\n---\n\n### Item 2: Add user authentication\n**Type:** feature\n**Status:** pending\n**Problem/Goal:**\n**Approach:**\n**Success Criteria:**\n**Decisions:**\n```\n\n### Step 4: Check Status and Report Results\n\n**If any items have `Status: pending`:**\n\n```\nWork items still need documentation:\n\n- [ ] Item 2: Add user authentication (pending)\n- [ ] Item 4: Fix login redirect bug (pending)\n\nReturning to work item loop...\n```\n\n**Return to collab skill** - the work item loop will continue processing pending items.\n\nDo NOT transition to rough-draft phase.\n\n**If all items have `Status: documented`:**\n\n```\nAll work items documented:\n\n- [x] Item 1: Refactor database layer (documented)\n- [x] Item 2: Add user authentication (documented)\n- [x] Item 3: Fix login redirect bug (documented)\n\nReady to proceed to rough-draft?\n\n1. Yes\n2. No\n```\n\n### Step 5: Transition to Rough-Draft\n\nOn user confirmation (selects **1**):\n\n**Update collab-state via MCP:**\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"session\": \"<session-name>\",\n  \"phase\": \"rough-draft/interface\"\n}\n```\nNote: `lastActivity` is automatically updated by the MCP tool.\n\n**Invoke rough-draft skill:**\n\n```\nTransitioning to rough-draft phase...\n```\n\nThen invoke the rough-draft skill to begin implementation planning.\n\n**If user declines:**\n\n```\nReturning to work item loop for more work...\n```\n\nReturn to collab skill to continue the work item loop.\n\n## Error Handling\n\n**No collab session found:**\n```\nNo active collab session found.\nStart a new session with /collab first.\n```\n\n**Design document not found:**\n```\nDesign document not found at .collab/<session>/documents/design.md\nEnsure a collab session has been started properly.\n```\n\n**No Work Items section found:**\n```\nNo Work Items section found in design document.\nThe session may not have gathered goals yet.\nReturning to collab skill...\n```\n\n**Already in implementation:**\n```\nSession \"<session-name>\" is already in implementation phase.\nCurrent phase: implementation\nUse /executing-plans to continue.\n```\n\n## Browser-Based Questions\n\nWhen a collab session is active, use `render_ui` for all user interactions.\n\n**Component selection:**\n| Question Type | Component |\n|--------------|-----------|\n| Yes/No | Card with action buttons |\n| Choose 1 of 2-5 | RadioGroup |\n| Choose 1 of 6+ | MultipleChoice |\n| Free text | TextInput or TextArea |\n\n**Example - Yes/No:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"<question context>\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"<question>\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n**Terminal prompts only when:** No collab session exists (pre-session selection).\n\n## Integration\n\n**Called by:**\n- collab skill (after work item loop completes)\n- collab skill (on session resume - always routes through here)\n- User directly via `/ready-to-implement` command\n\n**Returns to:**\n- **collab skill** - When pending items exist (continues work item loop)\n\n**Transitions to:**\n- **rough-draft** skill - When all items documented and user confirms\n\n**Related skills:**\n- **collab** - Session management and work item loop\n- **gather-session-goals** - Collects work items at session start\n- **brainstorming** - Documents feature/refactor/spike items\n- **systematic-debugging** - Documents bugfix items\n\n**Collab Workflow Chain:**\n```\ncollab --> gather-session-goals --> work item loop --> ready-to-implement --> rough-draft\n                                           ^                  |\n                                           |                  | (if pending)\n                                           +------------------+\n```\n\nThis skill acts as the central checkpoint for all resumes and pre-implementation validation, ensuring no implementation begins without complete work item documentation.\n\n## Quick Reference\n\n```\n/ready-to-implement\n\n1. Finds active collab session\n2. Reads design document\n3. Parses Work Items section for \"### Item N:\" sections\n4. Checks each item's **Status:** field\n5. If pending items: lists them, returns to work item loop\n6. If all documented: asks confirmation, then invokes rough-draft\n```\n\n## Completion\n\nAt the end of this skill's work, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"ready-to-implement\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/receiving-code-review/SKILL.md": "---\nname: receiving-code-review\ndescription: Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation\n---\n\n# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n```\nWHEN receiving code review feedback:\n\n1. READ: Complete feedback without reacting\n2. UNDERSTAND: Restate requirement in own words (or ask)\n3. VERIFY: Check against codebase reality\n4. EVALUATE: Technically sound for THIS codebase?\n5. RESPOND: Technical acknowledgment or reasoned pushback\n6. IMPLEMENT: One item at a time, test each\n```\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n```\nIF any item is unclear:\n  STOP - do not implement anything yet\n  ASK for clarification on unclear items\n\nWHY: Items may be related. Partial understanding = wrong implementation.\n```\n\n**Example:**\n```\nyour human partner: \"Fix 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n\n❌ WRONG: Implement 1,2,3,6 now, ask about 4,5 later\n✅ RIGHT: \"I understand items 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n```\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n```\nBEFORE implementing:\n  1. Check: Technically correct for THIS codebase?\n  2. Check: Breaks existing functionality?\n  3. Check: Reason for current implementation?\n  4. Check: Works on all platforms/versions?\n  5. Check: Does reviewer understand full context?\n\nIF suggestion seems wrong:\n  Push back with technical reasoning\n\nIF can't easily verify:\n  Say so: \"I can't verify this without [X]. Should I [investigate/ask/proceed]?\"\n\nIF conflicts with your human partner's prior decisions:\n  Stop and discuss with your human partner first\n```\n\n**your human partner's rule:** \"External feedback - be skeptical, but check carefully\"\n\n## YAGNI Check for \"Professional\" Features\n\n```\nIF reviewer suggests \"implementing properly\":\n  grep codebase for actual usage\n\n  IF unused: \"This endpoint isn't called. Remove it (YAGNI)?\"\n  IF used: Then implement properly\n```\n\n**your human partner's rule:** \"You and reviewer both report to me. If we don't need this feature, don't add it.\"\n\n## Implementation Order\n\n```\nFOR multi-item feedback:\n  1. Clarify anything unclear FIRST\n  2. Then implement in this order:\n     - Blocking issues (breaks, security)\n     - Simple fixes (typos, imports)\n     - Complex fixes (refactoring, logic)\n  3. Test each fix individually\n  4. Verify no regressions\n```\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Legacy/compatibility reasons exist\n- Conflicts with your human partner's architectural decisions\n\n**How to push back:**\n- Use technical reasoning, not defensiveness\n- Ask specific questions\n- Reference working tests/code\n- Involve your human partner if architectural\n\n**Signal if uncomfortable pushing back out loud:** \"Strange things are afoot at the Circle K\"\n\n## Acknowledging Correct Feedback\n\nWhen feedback IS correct:\n```\n✅ \"Fixed. [Brief description of what changed]\"\n✅ \"Good catch - [specific issue]. Fixed in [location].\"\n✅ [Just fix it and show in the code]\n\n❌ \"You're absolutely right!\"\n❌ \"Great point!\"\n❌ \"Thanks for catching that!\"\n❌ \"Thanks for [anything]\"\n❌ ANY gratitude expression\n```\n\n**Why no thanks:** Actions speak. Just fix it. The code itself shows you heard the feedback.\n\n**If you catch yourself about to write \"Thanks\":** DELETE IT. State the fix instead.\n\n## Gracefully Correcting Your Pushback\n\nIf you pushed back and were wrong:\n```\n✅ \"You were right - I checked [X] and it does [Y]. Implementing now.\"\n✅ \"Verified this and you're correct. My initial understanding was wrong because [reason]. Fixing.\"\n\n❌ Long apology\n❌ Defending why you pushed back\n❌ Over-explaining\n```\n\nState the correction factually and move on.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Performative agreement | State requirement or just act |\n| Blind implementation | Verify against codebase first |\n| Batch without testing | One at a time, test each |\n| Assuming reviewer is right | Check if breaks things |\n| Avoiding pushback | Technical correctness > comfort |\n| Partial implementation | Clarify all items first |\n| Can't verify, proceed anyway | State limitation, ask for direction |\n\n## Real Examples\n\n**Performative Agreement (Bad):**\n```\nReviewer: \"Remove legacy code\"\n❌ \"You're absolutely right! Let me remove that...\"\n```\n\n**Technical Verification (Good):**\n```\nReviewer: \"Remove legacy code\"\n✅ \"Checking... build target is 10.15+, this API needs 13+. Need legacy for backward compat. Current impl has wrong bundle ID - fix it or drop pre-13 support?\"\n```\n\n**YAGNI (Good):**\n```\nReviewer: \"Implement proper metrics tracking with database, date filters, CSV export\"\n✅ \"Grepped codebase - nothing calls this endpoint. Remove it (YAGNI)? Or is there usage I'm missing?\"\n```\n\n**Unclear Item (Good):**\n```\nyour human partner: \"Fix items 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n✅ \"Understand 1,2,3,6. Need clarification on 4 and 5 before implementing.\"\n```\n\n## GitHub Thread Replies\n\nWhen replying to inline review comments on GitHub, reply in the comment thread (`gh api repos/{owner}/{repo}/pulls/{pr}/comments/{id}/replies`), not as a top-level PR comment.\n\n## The Bottom Line\n\n**External feedback = suggestions to evaluate, not orders to follow.**\n\nVerify. Question. Then implement.\n\nNo performative agreement. Technical rigor always.\n",
        "skills/requesting-code-review/SKILL.md": "---\nname: requesting-code-review\ndescription: Use when completing tasks, implementing major features, or before merging to verify work meets requirements\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep\n---\n\n# Requesting Code Review\n\nDispatch superpowers:code-reviewer subagent to catch issues before they cascade.\n\n**Core principle:** Review early, review often.\n\n## When to Request Review\n\n**Mandatory:**\n- After each task in subagent-driven development\n- After completing major feature\n- Before merge to main\n\n**Optional but valuable:**\n- When stuck (fresh perspective)\n- Before refactoring (baseline check)\n- After fixing complex bug\n\n## How to Request\n\n**1. Get git SHAs:**\n```bash\nBASE_SHA=$(git rev-parse HEAD~1)  # or origin/main\nHEAD_SHA=$(git rev-parse HEAD)\n```\n\n**2. Dispatch code-reviewer subagent:**\n\nUse Task tool with the following prompt template:\n\n```\n# Code Review Agent\n\nYou are reviewing code changes for production readiness.\n\n**Your task:**\n1. Review {WHAT_WAS_IMPLEMENTED}\n2. Compare against {PLAN_OR_REQUIREMENTS}\n3. Check code quality, architecture, testing\n4. Categorize issues by severity\n5. Assess production readiness\n\n## What Was Implemented\n\n{DESCRIPTION}\n\n## Requirements/Plan\n\n{PLAN_REFERENCE}\n\n## Git Range to Review\n\n**Base:** {BASE_SHA}\n**Head:** {HEAD_SHA}\n\ngit diff --stat {BASE_SHA}..{HEAD_SHA}\ngit diff {BASE_SHA}..{HEAD_SHA}\n\n## Review Checklist\n\n**Code Quality:**\n- Clean separation of concerns?\n- Proper error handling?\n- Type safety (if applicable)?\n- DRY principle followed?\n- Edge cases handled?\n\n**Architecture:**\n- Sound design decisions?\n- Scalability considerations?\n- Performance implications?\n- Security concerns?\n\n**Testing:**\n- Tests actually test logic (not mocks)?\n- Edge cases covered?\n- Integration tests where needed?\n- All tests passing?\n\n**Requirements:**\n- All plan requirements met?\n- Implementation matches spec?\n- No scope creep?\n- Breaking changes documented?\n\n**Production Readiness:**\n- Migration strategy (if schema changes)?\n- Backward compatibility considered?\n- Documentation complete?\n- No obvious bugs?\n\n## Output Format\n\n### Strengths\n[What's well done? Be specific.]\n\n### Issues\n\n#### Critical (Must Fix)\n[Bugs, security issues, data loss risks, broken functionality]\n\n#### Important (Should Fix)\n[Architecture problems, missing features, poor error handling, test gaps]\n\n#### Minor (Nice to Have)\n[Code style, optimization opportunities, documentation improvements]\n\n**For each issue:**\n- File:line reference\n- What's wrong\n- Why it matters\n- How to fix (if not obvious)\n\n### Recommendations\n[Improvements for code quality, architecture, or process]\n\n### Assessment\n\n**Ready to merge?** [Yes/No/With fixes]\n\n**Reasoning:** [Technical assessment in 1-2 sentences]\n\n## Critical Rules\n\n**DO:**\n- Categorize by actual severity (not everything is Critical)\n- Be specific (file:line, not vague)\n- Explain WHY issues matter\n- Acknowledge strengths\n- Give clear verdict\n\n**DON'T:**\n- Say \"looks good\" without checking\n- Mark nitpicks as Critical\n- Give feedback on code you didn't review\n- Be vague (\"improve error handling\")\n- Avoid giving a clear verdict\n```\n\n**Placeholders:**\n- `{WHAT_WAS_IMPLEMENTED}` - What you just built\n- `{PLAN_OR_REQUIREMENTS}` - What it should do\n- `{PLAN_REFERENCE}` - Link or content of the plan\n- `{BASE_SHA}` - Starting commit\n- `{HEAD_SHA}` - Ending commit\n- `{DESCRIPTION}` - Brief summary\n\n**3. Act on feedback:**\n- Fix Critical issues immediately\n- Fix Important issues before proceeding\n- Note Minor issues for later\n- Push back if reviewer is wrong (with reasoning)\n\n## Example\n\n```\n[Just completed Task 2: Add verification function]\n\nYou: Let me request code review before proceeding.\n\nBASE_SHA=$(git log --oneline | grep \"Task 1\" | head -1 | awk '{print $1}')\nHEAD_SHA=$(git rev-parse HEAD)\n\n[Dispatch superpowers:code-reviewer subagent]\n  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index\n  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md\n  BASE_SHA: a7981ec\n  HEAD_SHA: 3df7661\n  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types\n\n[Subagent returns]:\n  Strengths: Clean architecture, real tests\n  Issues:\n    Important: Missing progress indicators\n    Minor: Magic number (100) for reporting interval\n  Assessment: Ready to proceed\n\nYou: [Fix progress indicators]\n[Continue to Task 3]\n```\n\n## Integration with Workflows\n\n**Subagent-Driven Development:**\n- Review after EACH task\n- Catch issues before they compound\n- Fix before moving to next task\n\n**Executing Plans:**\n- Review after each batch (3 tasks)\n- Get feedback, apply, continue\n\n**Ad-Hoc Development:**\n- Review before merge\n- Review when stuck\n\n## Red Flags\n\n**Never:**\n- Skip review because \"it's simple\"\n- Ignore Critical issues\n- Proceed with unfixed Important issues\n- Argue with valid technical feedback\n\n**If reviewer wrong:**\n- Push back with technical reasoning\n- Show code/tests that prove it works\n- Request clarification\n\nSee template above in \"How to Request\" section.\n",
        "skills/rough-draft-blueprint/SKILL.md": "---\nname: rough-draft-blueprint\ndescription: Create comprehensive blueprint document for a work item (structure, functions, and task graph)\nuser-invocable: false\nallowed-tools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - AskUserQuestion\n  - mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# Rough-Draft Blueprint\n\nCreate a single comprehensive blueprint document for the current work item that includes:\n1. Structure summary (files and functions)\n2. Function blueprints (signatures, pseudocode, stubs)\n3. Task dependency graph (YAML, execution waves, Mermaid)\n\n## Step 0: Query Kodex\n\nQuery project knowledge for relevant conventions and patterns.\n\n### Topic Inference\n\nFrom work item context, build candidates:\n- `{item-keyword}-types`\n- `{item-keyword}-patterns`\n- `type-conventions`\n- `coding-standards`\n- `error-patterns`\n- `file-naming`\n- `project-structure`\n\n### Example\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: { \"project\": \"<cwd>\", \"name\": \"type-conventions\" }\n```\n\nDisplay found topics as context before creating the blueprint.\n\n---\n\n## Phase 1: Structure Enumeration\n\nDefine the structural contracts of the system.\n\n### What to Produce\n\n1. **File paths** - List all files that will be created or modified\n2. **Class and function signatures** - Names, parameters, return types\n3. **Public API contracts** - How components interact with each other\n4. **Type definitions** - Custom types, interfaces, enums\n\n### Process\n\n```bash\n# Read design doc\ncat .collab/<name>/documents/design.md\n```\n\n**For each component identified in design:**\n1. Define the file path where it will live\n2. List all public functions/methods with signatures\n3. Define input/output types\n4. Document how it connects to other components\n\n### GATE 1: Structure Confirmation\n\n**Checklist:**\n- [ ] All files from design are listed\n- [ ] All public interfaces have signatures\n- [ ] Parameter types are explicit (no `any`)\n- [ ] Return types are explicit\n- [ ] Component interactions are documented\n\n**If structure phase doesn't apply** (e.g., pure config changes, docker setup):\nDocument explicitly: \"N/A - [reason why structure phase doesn't apply]\"\nN/A sections require justification - never leave them silently empty.\n\n**GATE: Do NOT proceed until this checklist passes.**\n\n---\n\n## Phase 2: Function Blueprints\n\nDefine the logic flow and implementation details for each function.\n\n### What to Produce\n\nFor each function identified in Phase 1, create a complete blueprint:\n\n1. **Signature** - Full function signature with types\n2. **Pseudocode** - Step-by-step logic flow\n3. **Error Handling** - How errors are caught, propagated, reported\n4. **Edge Cases** - Boundary conditions and how they're handled\n5. **Dependencies** - External services, databases, APIs called\n6. **Test Strategy** - Key test cases to verify behavior\n7. **Stub Code** - Actual stub implementation with TODO comments\n\n### Language-Specific Stub Templates\n\n**TypeScript:**\n```typescript\nexport async function functionName(param: Type): Promise<ReturnType> {\n  // TODO: Step 1 - Validate input\n  // TODO: Step 2 - Process data\n  // TODO: Step 3 - Return result\n  throw new Error('Not implemented');\n}\n```\n\n**Python:**\n```python\ndef function_name(param: Type) -> ReturnType:\n    \"\"\"Brief description.\"\"\"\n    # TODO: Step 1 - Validate input\n    # TODO: Step 2 - Process data\n    # TODO: Step 3 - Return result\n    raise NotImplementedError()\n```\n\n**Go:**\n```go\nfunc FunctionName(param Type) (ReturnType, error) {\n    // TODO: Step 1 - Validate input\n    // TODO: Step 2 - Process data\n    // TODO: Step 3 - Return result\n    return nil, fmt.Errorf(\"not implemented\")\n}\n```\n\n**Rust:**\n```rust\npub fn function_name(param: Type) -> Result<ReturnType, Error> {\n    // TODO: Step 1 - Validate input\n    // TODO: Step 2 - Process data\n    // TODO: Step 3 - Return result\n    todo!()\n}\n```\n\n**C#:**\n```csharp\npublic async Task<ReturnType> FunctionName(Type param)\n{\n    // TODO: Step 1 - Validate input\n    // TODO: Step 2 - Process data\n    // TODO: Step 3 - Return result\n    throw new NotImplementedException();\n}\n```\n\n### GATE 2: Function Completeness\n\n**Checklist:**\n- [ ] Every function from Structure has a blueprint\n- [ ] Pseudocode steps are clear and actionable\n- [ ] Error handling is explicit for each function\n- [ ] Edge cases are identified\n- [ ] TODO comments in stubs match pseudocode steps\n- [ ] External dependencies are noted\n\n**If pseudocode phase doesn't apply** (e.g., no logic to describe, pure data changes):\nDocument explicitly: \"N/A - [reason why pseudocode phase doesn't apply]\"\n\n**GATE: Do NOT proceed until this checklist passes.**\n\n---\n\n## Phase 3: Task Dependency Graph\n\nBuild the task dependency graph and execution plan.\n\n### Step 1: Build Task List\n\nFor each file from the structure:\n1. Create task ID from file path (e.g., `src/auth/service.ts` -> `auth-service`)\n2. Set files array\n3. Generate test file paths:\n   - `{dir}/{name}.test{ext}`\n   - `{dir}/__tests__/{name}.test{ext}`\n4. Extract description from blueprint\n5. Analyze dependencies:\n   - If file imports from another file, add dependency\n   - If pseudocode mentions \"after X\", add dependency\n\n### Step 2: Identify Parallel Tasks\n\nMark tasks as `parallel: true` if:\n- No dependencies\n- Or all dependencies are from previous waves\n\n### Step 3: Calculate Execution Waves\n\nGroup tasks by wave:\n- **Wave 1:** Tasks with no dependencies\n- **Wave N:** Tasks depending only on waves 1 to N-1\n\n### Step 4: Check for Cross-Item Dependencies\n\nIf this work item depends on files from other work items:\n- Document the dependency explicitly\n- Note in the graph which items must complete first\n\n### Step 5: Create Mermaid Visualization\n\n```mermaid\ngraph TD\n    auth-types[auth-types]\n    auth-service[auth-service]\n    auth-middleware[auth-middleware]\n    auth-tests[auth-tests]\n\n    auth-types --> auth-service\n    auth-service --> auth-middleware\n    auth-service --> auth-tests\n\n    style auth-types fill:#c8e6c9\n    style auth-service fill:#bbdefb\n    style auth-middleware fill:#bbdefb\n    style auth-tests fill:#e1bee7\n```\n\nLegend: Green = parallel-safe (no dependencies), Blue = sequential, Purple = tests\n\n### GATE 3: Graph Validation\n\n**Checklist:**\n- [ ] All files from structure are covered in tasks\n- [ ] No circular dependencies\n- [ ] Dependencies match import analysis\n- [ ] Test file paths are generated for each source file\n- [ ] Execution waves are calculated\n\n**GATE: Do NOT proceed until this checklist passes.**\n\n---\n\n## Output: Blueprint Document\n\nCreate `blueprint-item-N.md` with all three phases combined:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__create_document\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"name\": \"blueprint-item-N\",\n  \"content\": \"<blueprint content>\"\n}\n```\n\n### Document Structure\n\n```markdown\n# Blueprint: Item N - [Title]\n\n## 1. Structure Summary\n\n### Files\n- [ ] `src/path/to/file.ts` - Description\n- [ ] `src/path/to/another.ts` - Description\n\n### Type Definitions\n\n```typescript\n// Type definitions here\n```\n\n### Component Interactions\n- Component A calls Component B via method X\n- Component B depends on external service Y\n\n---\n\n## 2. Function Blueprints\n\n### `functionName(param: Type): ReturnType`\n\n**Pseudocode:**\n1. Validate input\n2. Process data\n3. Return result\n\n**Error Handling:**\n- InvalidInput: Return error with message\n\n**Edge Cases:**\n- Empty input: Return default value\n\n**Test Strategy:**\n- Test valid input\n- Test invalid input\n- Test edge cases\n\n**Stub:**\n```typescript\nexport async function functionName(param: Type): Promise<ReturnType> {\n  // TODO: Step 1 - Validate input\n  // TODO: Step 2 - Process data\n  // TODO: Step 3 - Return result\n  throw new Error('Not implemented');\n}\n```\n\n[Repeat for each function]\n\n---\n\n## 3. Task Dependency Graph\n\n### YAML Graph\n\n```yaml\ntasks:\n  - id: task-id\n    files: [path/to/file.ts]\n    tests: [path/to/file.test.ts]\n    description: What this task implements\n    parallel: true\n    depends-on: []\n```\n\n### Execution Waves\n\n**Wave 1 (no dependencies):**\n- task-1\n- task-2\n\n**Wave 2 (depends on Wave 1):**\n- task-3\n\n### Mermaid Visualization\n\n```mermaid\ngraph TD\n    ...\n```\n\n### Summary\n- Total tasks: N\n- Total waves: M\n- Max parallelism: P\n```\n\n---\n\n## Completion\n\nAfter creating the blueprint document, call complete_skill:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"rough-draft-blueprint\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n\n**Note:** The state machine will automatically mark this item as 'complete' and route to the next item or to ready-to-implement if all items are done.\n",
        "skills/rough-draft-confirm/SKILL.md": "---\nname: rough-draft-confirm\ndescription: Ask user about auto-allow for rough-draft proposals before starting rough-draft phase\nuser-invocable: false\nmodel: haiku\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*\n---\n\n# Rough-Draft Confirm Skill\n\n## Overview\n\nThe **rough-draft-confirm** skill is invoked after all brainstorming is complete, before the rough-draft phase begins. It shows a summary of brainstormed code items and asks the user about their preference for auto-allowing proposals during rough-draft.\n\nThis is a quick transition skill - it gathers one preference then moves on.\n\n## When Invoked\n\nThis skill is invoked by the workflow state machine when:\n1. All items have completed brainstorming (no pending items left)\n2. There are code items with status === 'brainstormed' ready for rough-draft\n3. The workflow transitions from `brainstorm-item-router` to `rough-draft-confirm`\n\n## Step 1: Get Session State\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_session_state\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\" }\n```\n\nExtract:\n- `workItems` array\n- Filter for items with `type === 'code'` and `status === 'brainstormed'`\n\n## Step 2: Show Summary and Ask Preference\n\nDisplay the brainstormed code items and ask about auto-allow:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Ready for Rough-Draft Phase\" },\n    \"children\": [\n      {\n        \"type\": \"Markdown\",\n        \"props\": {\n          \"content\": \"Brainstorming complete! The following code items are ready for rough-draft:\\n\\n- Item 1: <title>\\n- Item 2: <title>\\n\\nDuring rough-draft, Claude will propose interface definitions, pseudocode, and file skeletons.\"\n        }\n      },\n      {\n        \"type\": \"RadioGroup\",\n        \"props\": {\n          \"name\": \"autoAllow\",\n          \"label\": \"How would you like to handle proposals?\",\n          \"options\": [\n            { \"value\": \"auto\", \"label\": \"Auto-allow all proposals (faster)\" },\n            { \"value\": \"review\", \"label\": \"Review each proposal before proceeding\" }\n          ]\n        }\n      }\n    ],\n    \"actions\": [\n      { \"id\": \"continue\", \"label\": \"Continue\", \"primary\": true }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n## Step 3: Save Preference\n\nBased on user's choice, update session state:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"autoAllowRoughDraft\": <true if \"auto\", false if \"review\">\n}\n```\n\n## Step 4: Complete Skill\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"rough-draft-confirm\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n\n## Edge Cases\n\n### No Code Items Ready\n\nIf there are no code items with status === 'brainstormed' (e.g., all items were tasks or bugfixes):\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"Brainstorming Complete\" },\n    \"children\": [{\n      \"type\": \"Markdown\",\n      \"props\": {\n        \"content\": \"All items have been processed. No code items require rough-draft phase.\\n\\nProceeding to implementation...\"\n      }\n    }],\n    \"actions\": [{ \"id\": \"continue\", \"label\": \"Continue\", \"primary\": true }]\n  },\n  \"blocking\": true\n}\n```\n\nThen complete the skill (workflow will route to ready-to-implement).\n\n## Notes\n\n- This skill is designed to be quick and lightweight\n- The autoAllowRoughDraft preference can be checked by rough-draft skills\n- If preference is not set, rough-draft skills should default to review mode\n",
        "skills/systematic-debugging/SKILL.md": "---\nname: systematic-debugging\ndescription: Investigate bugfix items using systematic debugging methodology\nuser-invocable: false\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Task, Read\n---\n\n# Systematic Debugging (Skill Wrapper)\n\nThis skill wraps the systematic-debugging agent for use within the collab workflow. It handles bugfix-type work items.\n\n## Overview\n\nWhen a work item has `Type: bugfix`, the MCP state machine routes to this skill. This skill:\n1. Reads the work item details from the design doc\n2. Spawns the systematic-debugging agent to investigate\n3. Updates the design doc with the diagnostic report\n4. Calls complete_skill to proceed\n\n**Important:** This skill does NOT implement fixes. It only investigates and documents root cause. Fixes happen later via rough-draft → executing-plans.\n\n## Step 1: Get Current Item Context\n\nRead the design doc to get the current bugfix item:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_document\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"id\": \"design\" }\n```\n\nFind the work item marked as current (from session state's `currentItem`).\n\n## Step 2: Spawn Debugging Agent\n\nUse the Task tool to invoke the systematic-debugging agent:\n\n```\nTool: Task\nArgs: {\n  \"subagent_type\": \"mermaid-collab:systematic-debugging:systematic-debugging\",\n  \"description\": \"Investigate bugfix: <item-title>\",\n  \"prompt\": \"<context about the bug from design doc>\"\n}\n```\n\nThe agent will:\n- Investigate the root cause\n- Document findings\n- NOT implement any fixes\n\n## Step 3: Mark Item as Documented\n\n### 3a. Update session state workItems\n\nRead current state and update the item's status:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_session_state\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\" }\n```\n\nUpdate the item's status in workItems array:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"workItems\": [<updated array with item status changed to \"documented\">]\n}\n```\n\n### 3b. Update design doc\n\nTake the agent's diagnostic report and add it to the work item in the design doc:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__patch_document\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"id\": \"design\",\n  \"old_string\": \"**Status:** pending\",\n  \"new_string\": \"**Status:** documented\\n\\n**Root Cause Analysis:**\\n<agent's findings>\\n\\n**Proposed Fix:**\\n<agent's recommendation>\"\n}\n```\n\n## Step 4: Complete Skill\n\nCall complete_skill to get the next workflow state:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"systematic-debugging\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/task-planning/SKILL.md": "---\nname: task-planning\ndescription: Plan operational tasks (docker, installs, organization) that skip TDD\nuser-invocable: false\nmodel: opus\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep\n---\n\n# Task Planning Skill\n\n## Overview\n\nThe **task-planning** skill guides planning of operational tasks that don't require test-driven development. Unlike feature work (which goes through brainstorming → rough-draft → TDD), operational tasks follow a simpler path: brainstorming → task-planning → direct execution.\n\nThis skill is invoked internally by the collab workflow for items classified as \"task\" type (docker, installs, configuration, organization, cleanup, deployment).\n\n## When to Use\n\n- After brainstorming completes for a \"task\" type work item\n- For operational work that doesn't involve code implementation with tests\n- When planning: docker container setup, library installations, folder organization, deployment procedures, cleanup tasks\n\n## Collab Session Required\n\nThis skill operates within an active collab session. It reads the current work item from the session's design document and updates it with planning phases.\n\n## Browser-Based Questions\n\nWhen a collab session is active, use `render_ui` for all user interactions.\n\n**Component selection:**\n| Question Type | Component |\n|--------------|-----------|\n| Yes/No | Card with action buttons |\n| Choose 1 of 2-5 | RadioGroup |\n| Choose 1 of 6+ | MultipleChoice |\n| Free text | TextInput or TextArea |\n\n**Example - Yes/No:**\n```\nTool: mcp__plugin_mermaid-collab_mermaid__render_ui\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"ui\": {\n    \"type\": \"Card\",\n    \"props\": { \"title\": \"<question context>\" },\n    \"children\": [{ \"type\": \"Markdown\", \"props\": { \"content\": \"<question>\" } }],\n    \"actions\": [\n      { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n      { \"id\": \"no\", \"label\": \"No\" }\n    ]\n  },\n  \"blocking\": true\n}\n```\n\n**Terminal prompts only when:** No collab session exists (pre-session selection).\n\n```\nCollab Session Structure:\n.collab/[session-name]/\n├── design.md                 (updated with Prerequisites/Steps/Verification)\n├── collab-state.json        (contains currentItem reference)\n└── context-snapshot.json    (saved at phase transitions)\n```\n\n## The Process\n\n### Phase 1: Prerequisites\n\nIdentify what must exist before the task can start.\n\n**Steps:**\n1. Read the design.md file for the current work item\n2. Ask: \"What needs to exist before starting this task?\"\n   - Example: Docker installed, project repository cloned, user has admin access\n3. For each prerequisite identified:\n   - Document the prerequisite name\n   - Document how to check if it exists\n4. Ask: \"Anything else that needs to exist?\"\n5. When user confirms prerequisites are complete, save snapshot and proceed to Steps phase\n\n**Snapshot Saving:**\n```\n// After each prerequisite documented, save to preserve context\nTool: mcp__plugin_mermaid-collab_mermaid__save_snapshot\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session-name>\",\n  \"activeSkill\": \"task-planning\",\n  \"currentStep\": \"prerequisites\",\n  \"pendingQuestion\": \"Are there more prerequisites?\",\n  \"inProgressItem\": currentItem,\n  \"recentContext\": []\n}\n// Note: version and timestamp are automatically added\n```\n\n### Phase 2: Steps\n\nDefine the ordered sequence of commands/actions to complete the task.\n\n**Steps:**\n1. Ask: \"What are the steps to complete this task?\"\n   - Example: Run docker build, deploy to staging, verify health checks\n2. For each step identified:\n   - Document the command or action to run\n   - Document the expected outcome after running it\n3. Order steps by dependency (what must run before what)\n4. Ask: \"Are there more steps?\"\n5. When user confirms steps are complete, save snapshot and proceed to Verification phase\n\n**Snapshot Saving:**\n```\n// After each step documented, save context\nTool: mcp__plugin_mermaid-collab_mermaid__save_snapshot\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session-name>\",\n  \"activeSkill\": \"task-planning\",\n  \"currentStep\": \"steps\",\n  \"pendingQuestion\": \"Are there more steps?\",\n  \"inProgressItem\": currentItem,\n  \"recentContext\": []\n}\n// Note: version and timestamp are automatically added\n```\n\n### Phase 3: Verification\n\nDefine how to confirm the task completed successfully.\n\n**Steps:**\n1. Ask: \"How will you verify this task succeeded?\"\n   - Example: Run health check endpoint, check container logs, verify files exist\n2. Document verification commands/checks\n3. Update the design.md with all three phases (Prerequisites, Steps, Verification)\n4. Mark item as \"task-planning\" phase complete\n5. Save final snapshot\n6. Return to collab skill (indicate item is ready for executing-plans phase)\n\n**Snapshot Saving:**\n```\n// After verification documented and design.md updated\nTool: mcp__plugin_mermaid-collab_mermaid__save_snapshot\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session-name>\",\n  \"activeSkill\": \"task-planning\",\n  \"currentStep\": \"verification-complete\",\n  \"pendingQuestion\": null,\n  \"inProgressItem\": currentItem,\n  \"recentContext\": []\n}\n// Note: version and timestamp are automatically added\n```\n\n## Integration\n\n### Called From\n- **collab** skill (Step 4 routing): After brainstorming completes for task-type items\n\n### Routing Logic\n```\nItem Type → Path\n- \"code\" type  → brainstorming → rough-draft → test-driven-development → executing-plans\n- \"bugfix\" type → systematic-debugging → executing-plans\n- \"task\" type  → brainstorming → task-planning → executing-plans (NO TDD)\n```\n\n### Next Skill\nAfter task-planning completes:\n- Invoke **executing-plans** skill with task type indicator\n- executing-plans will skip test-driven-development for task items\n- executing-plans will execute the commands and run verification checks\n\n### Design Document Format\n\nThe task-planning skill updates the work item in design.md with this structure:\n\n```markdown\n### Item N: [Task Name]\n**Type:** task\n**Status:** planning → executing\n**Problem/Goal:** [Brief description]\n\n**Approach:**\n[Results from brainstorming]\n\n**Prerequisites:**\n- Prerequisite 1: how to check if it exists\n- Prerequisite 2: how to check if it exists\n\n**Steps:**\n1. [Command/action] → Expected: [outcome]\n2. [Command/action] → Expected: [outcome]\n3. [Command/action] → Expected: [outcome]\n\n**Verification:**\n- Check 1: [verification command/check]\n- Check 2: [verification command/check]\n\n**Success Criteria:**\n[From original brainstorming]\n```\n\n## Context Preservation\n\nThis skill saves snapshots at key transitions to preserve planning progress if the session is compacted.\n\n**Snapshot Structure (returned by mcp__plugin_mermaid-collab_mermaid__load_snapshot):**\n```json\n{\n  \"version\": 1,\n  \"timestamp\": \"2025-01-21T14:30:00Z\",\n  \"activeSkill\": \"task-planning\",\n  \"currentStep\": \"prerequisites|steps|verification-complete\",\n  \"pendingQuestion\": \"Are there more prerequisites?\",\n  \"inProgressItem\": { \"id\": \"item-1\", \"name\": \"...\" },\n  \"recentContext\": []\n}\n```\nNote: `version` and `timestamp` are automatically added by `mcp__plugin_mermaid-collab_mermaid__save_snapshot`.\n\nWhen the collab session resumes after compaction:\n1. collab skill reads context-snapshot.json\n2. Restores the task-planning skill state\n3. Resumes from pendingQuestion (continues the conversation)\n\n## Tools Available\n\n- `mcp__plugin_mermaid_collab_mermaid__*` - Full access to mermaid-collab MCP for reading/updating design documents\n- `Read` - Read files to understand task context\n- `Glob` - Search for files related to the task\n- `Grep` - Search file contents for relevant information\n\n## Completion\n\n### Mark item as documented\n\nBefore completing, update the item status in session state:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__get_session_state\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\" }\n```\n\nUpdate the item's status in workItems array:\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__update_session_state\nArgs: {\n  \"project\": \"<cwd>\",\n  \"session\": \"<session>\",\n  \"workItems\": [<updated array with item status changed to \"documented\">]\n}\n```\n\n### Call complete_skill\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__complete_skill\nArgs: { \"project\": \"<cwd>\", \"session\": \"<session>\", \"skill\": \"task-planning\" }\n```\n\n**Handle response:**\n- If `action == \"clear\"`: Invoke skill: collab-clear\n- If `next_skill` is not null: Invoke that skill\n- If `next_skill` is null: Workflow complete\n",
        "skills/test-driven-development/SKILL.md": "---\nname: test-driven-development\ndescription: Use when implementing any feature or bugfix, before writing implementation code\n---\n\n# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\n**Design alignment:**\n- Tests should verify behavior specified in the design doc\n- If design doc or wireframe exists, test against THAT, not your interpretation\n- Test names should map to design requirements\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n\nImplement fresh from tests. Period.\n\n## Red-Green-Refactor\n\n```dot\ndigraph tdd_cycle {\n    rankdir=LR;\n    red [label=\"RED\\nWrite failing test\", shape=box, style=filled, fillcolor=\"#ffcccc\"];\n    verify_red [label=\"Verify fails\\ncorrectly\", shape=diamond];\n    green [label=\"GREEN\\nMinimal code\", shape=box, style=filled, fillcolor=\"#ccffcc\"];\n    verify_green [label=\"Verify passes\\nAll green\", shape=diamond];\n    refactor [label=\"REFACTOR\\nClean up\", shape=box, style=filled, fillcolor=\"#ccccff\"];\n    next [label=\"Next\", shape=ellipse];\n\n    red -> verify_red;\n    verify_red -> green [label=\"yes\"];\n    verify_red -> red [label=\"wrong\\nfailure\"];\n    green -> verify_green;\n    verify_green -> refactor [label=\"yes\"];\n    verify_green -> green [label=\"no\"];\n    refactor -> verify_green [label=\"stay\\ngreen\"];\n    verify_green -> next;\n    next -> red;\n}\n```\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n<Good>\n```typescript\ntest('retries failed operations 3 times', async () => {\n  let attempts = 0;\n  const operation = () => {\n    attempts++;\n    if (attempts < 3) throw new Error('fail');\n    return 'success';\n  };\n\n  const result = await retryOperation(operation);\n\n  expect(result).toBe('success');\n  expect(attempts).toBe(3);\n});\n```\nClear name, tests real behavior, one thing\n</Good>\n\n<Bad>\n```typescript\ntest('retry works', async () => {\n  const mock = jest.fn()\n    .mockRejectedValueOnce(new Error())\n    .mockRejectedValueOnce(new Error())\n    .mockResolvedValueOnce('success');\n  await retryOperation(mock);\n  expect(mock).toHaveBeenCalledTimes(3);\n});\n```\nVague name, tests mock not code\n</Bad>\n\n**Requirements:**\n- One behavior\n- Clear name\n- Real code (no mocks unless unavoidable)\n\n### Verify RED - Watch It Fail\n\n**MANDATORY. Never skip.**\n\n```bash\nnpm run test:ci -- path/to/test.test.ts\n```\n\nConfirm:\n- Test fails (not errors)\n- Failure message is expected\n- Fails because feature missing (not typos)\n\n**Test passes?** You're testing existing behavior. Fix test.\n\n**Test errors?** Fix error, re-run until it fails correctly.\n\n### GREEN - Minimal Code\n\nWrite simplest code to pass the test.\n\n<Good>\n```typescript\nasync function retryOperation<T>(fn: () => Promise<T>): Promise<T> {\n  for (let i = 0; i < 3; i++) {\n    try {\n      return await fn();\n    } catch (e) {\n      if (i === 2) throw e;\n    }\n  }\n  throw new Error('unreachable');\n}\n```\nJust enough to pass\n</Good>\n\n<Bad>\n```typescript\nasync function retryOperation<T>(\n  fn: () => Promise<T>,\n  options?: {\n    maxRetries?: number;\n    backoff?: 'linear' | 'exponential';\n    onRetry?: (attempt: number) => void;\n  }\n): Promise<T> {\n  // YAGNI\n}\n```\nOver-engineered\n</Bad>\n\nDon't add features, refactor other code, or \"improve\" beyond the test.\n\n### Verify GREEN - Watch It Pass\n\n**MANDATORY.**\n\n```bash\nnpm run test:ci -- path/to/test.test.ts\n```\n\nConfirm:\n- Test passes\n- Other tests still pass\n- Output pristine (no errors, warnings)\n\n**Test fails?** Fix code, not test.\n\n**Other tests fail?** Fix now.\n\n### REFACTOR - Clean Up\n\nAfter green only:\n- Remove duplication\n- Improve names\n- Extract helpers\n\nKeep tests green. Don't add behavior.\n\n### Repeat\n\nNext failing test for next feature.\n\n## Good Tests\n\n| Quality | Good | Bad |\n|---------|------|-----|\n| **Minimal** | One thing. \"and\" in name? Split it. | `test('validates email and domain and whitespace')` |\n| **Clear** | Name describes behavior | `test('test1')` |\n| **Shows intent** | Demonstrates desired API | Obscures what code should do |\n\n## Why Order Matters\n\n**\"I'll write tests after to verify it works\"**\n\nTests written after code pass immediately. Passing immediately proves nothing:\n- Might test wrong thing\n- Might test implementation, not behavior\n- Might miss edge cases you forgot\n- You never saw it catch the bug\n\nTest-first forces you to see the test fail, proving it actually tests something.\n\n**\"I already manually tested all the edge cases\"**\n\nManual testing is ad-hoc. You think you tested everything but:\n- No record of what you tested\n- Can't re-run when code changes\n- Easy to forget cases under pressure\n- \"It worked when I tried it\" ≠ comprehensive\n\nAutomated tests are systematic. They run the same way every time.\n\n**\"Deleting X hours of work is wasteful\"**\n\nSunk cost fallacy. The time is already gone. Your choice now:\n- Delete and rewrite with TDD (X more hours, high confidence)\n- Keep it and add tests after (30 min, low confidence, likely bugs)\n\nThe \"waste\" is keeping code you can't trust. Working code without real tests is technical debt.\n\n**\"TDD is dogmatic, being pragmatic means adapting\"**\n\nTDD IS pragmatic:\n- Finds bugs before commit (faster than debugging after)\n- Prevents regressions (tests catch breaks immediately)\n- Documents behavior (tests show how to use code)\n- Enables refactoring (change freely, tests catch breaks)\n\n\"Pragmatic\" shortcuts = debugging in production = slower.\n\n**\"Tests after achieve the same goals - it's spirit not ritual\"**\n\nNo. Tests-after answer \"What does this do?\" Tests-first answer \"What should this do?\"\n\nTests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.\n\nTests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).\n\n30 minutes of tests after ≠ TDD. You get coverage, lose proof tests work.\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n| \"Already manually tested\" | Ad-hoc ≠ systematic. No record, can't re-run. |\n| \"Deleting X hours is wasteful\" | Sunk cost fallacy. Keeping unverified code is technical debt. |\n| \"Keep as reference, write tests first\" | You'll adapt it. That's testing after. Delete means delete. |\n| \"Need to explore first\" | Fine. Throw away exploration, start with TDD. |\n| \"Test hard = design unclear\" | Listen to test. Hard to test = hard to use. |\n| \"TDD will slow me down\" | TDD faster than debugging. Pragmatic = test-first. |\n| \"Manual test faster\" | Manual doesn't prove edge cases. You'll re-test every change. |\n| \"Existing code has no tests\" | You're improving it. Add tests for existing code. |\n\n## Red Flags - STOP and Start Over\n\n- Code before test\n- Test after implementation\n- Test passes immediately\n- Can't explain why test failed\n- Tests added \"later\"\n- Rationalizing \"just this once\"\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"Keep as reference\" or \"adapt existing code\"\n- \"Already spent X hours, deleting is wasteful\"\n- \"TDD is dogmatic, I'm being pragmatic\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n\n## Example: Bug Fix\n\n**Bug:** Empty email accepted\n\n**RED**\n```typescript\ntest('rejects empty email', async () => {\n  const result = await submitForm({ email: '' });\n  expect(result.error).toBe('Email required');\n});\n```\n\n**Verify RED**\n```bash\n$ npm run test:ci\nFAIL: expected 'Email required', got undefined\n```\n\n**GREEN**\n```typescript\nfunction submitForm(data: FormData) {\n  if (!data.email?.trim()) {\n    return { error: 'Email required' };\n  }\n  // ...\n}\n```\n\n**Verify GREEN**\n```bash\n$ npm run test:ci\nPASS\n```\n\n**REFACTOR**\nExtract validation for multiple fields if needed.\n\n## Verification Checklist\n\nBefore marking work complete:\n\n- [ ] Every new function/method has a test\n- [ ] Watched each test fail before implementing\n- [ ] Each test failed for expected reason (feature missing, not typo)\n- [ ] Wrote minimal code to pass each test\n- [ ] All tests pass\n- [ ] Output pristine (no errors, warnings)\n- [ ] Tests use real code (mocks only if unavoidable)\n- [ ] Edge cases and errors covered\n\nCan't check all boxes? You skipped TDD. Start over.\n\n## When Stuck\n\n| Problem | Solution |\n|---------|----------|\n| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |\n| Test too complicated | Design too complicated. Simplify interface. |\n| Must mock everything | Code too coupled. Use dependency injection. |\n| Test setup huge | Extract helpers. Still complex? Simplify design. |\n\n## Debugging Integration\n\nBug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.\n\nNever fix bugs without a test.\n\n## Testing Anti-Patterns\n\nWhen adding mocks or test utilities, avoid these common pitfalls.\n\n**Core principle:** Test what the code does, not what the mocks do.\n\n### The Iron Laws\n\n```\n1. NEVER test mock behavior\n2. NEVER add test-only methods to production classes\n3. NEVER mock without understanding dependencies\n```\n\n### Anti-Pattern 1: Testing Mock Behavior\n\n**Bad:**\n```typescript\n// Testing that the mock exists\ntest('renders sidebar', () => {\n  render(<Page />);\n  expect(screen.getByTestId('sidebar-mock')).toBeInTheDocument();\n});\n```\n\n**Good:**\n```typescript\ntest('renders sidebar', () => {\n  render(<Page />);  // Don't mock sidebar\n  expect(screen.getByRole('navigation')).toBeInTheDocument();\n});\n```\n\n**Gate:** Before asserting on any mock element, ask: \"Am I testing real component behavior or just mock existence?\"\n\n### Anti-Pattern 2: Test-Only Methods in Production\n\n**Bad:**\n```typescript\nclass Session {\n  async destroy() {  // Only used in tests!\n    await this._workspaceManager?.destroyWorkspace(this.id);\n  }\n}\n```\n\n**Good:**\n```typescript\n// In test-utils/\nexport async function cleanupSession(session: Session) {\n  const workspace = session.getWorkspaceInfo();\n  if (workspace) {\n    await workspaceManager.destroyWorkspace(workspace.id);\n  }\n}\n```\n\n**Gate:** Before adding any method to production class, ask: \"Is this only used by tests?\" If yes, put it in test utilities.\n\n### Anti-Pattern 3: Mocking Without Understanding\n\n**Bad:**\n```typescript\n// Mock breaks test logic - prevents config write that test depends on\nvi.mock('ToolCatalog', () => ({\n  discoverAndCacheTools: vi.fn().mockResolvedValue(undefined)\n}));\n```\n\n**Gate:** Before mocking, understand what side effects the real method has and whether the test depends on them.\n\n### Anti-Pattern 4: Incomplete Mocks\n\n**Bad:**\n```typescript\nconst mockResponse = {\n  status: 'success',\n  data: { userId: '123', name: 'Alice' }\n  // Missing: metadata that downstream code uses\n};\n```\n\n**Good:** Mirror real API completeness - include ALL fields the real API returns.\n\n### Anti-Pattern 5: Integration Tests as Afterthought\n\nTesting is part of implementation, not optional follow-up. TDD cycle: test → implement → refactor → complete.\n\n### Quick Reference\n\n| Anti-Pattern | Fix |\n|--------------|-----|\n| Assert on mock elements | Test real component or unmock it |\n| Test-only methods in production | Move to test utilities |\n| Mock without understanding | Understand dependencies first, mock minimally |\n| Incomplete mocks | Mirror real API completely |\n| Tests as afterthought | TDD - tests first |\n| Over-complex mocks | Consider integration tests |\n\n**Red Flags:**\n- Assertion checks for `*-mock` test IDs\n- Methods only called in test files\n- Mock setup is >50% of test\n- Test fails when you remove mock\n- Can't explain why mock is needed\n- Mocking \"just to be safe\"\n\n## Final Rule\n\n```\nProduction code → test exists and failed first\nOtherwise → not TDD\n```\n\nNo exceptions without your human partner's permission.\n",
        "skills/using-ai-ui/SKILL.md": "# Using AI-UI Components\n\nGuide for using the `render_ui` MCP tool to display interactive UI components in the browser.\n\n## Overview\n\nThe `render_ui` tool broadcasts JSON UI definitions to connected browser clients and optionally waits for user interaction. Use this for:\n- Asking questions with structured options\n- Collecting form data\n- Displaying progress or status\n- Showing data in rich formats\n\n## Blocking vs Non-Blocking Mode\n\n**Blocking mode (default):** Tool waits for user action before returning.\n```json\n{ \"blocking\": true, \"timeout\": 30000 }\n```\nResponse includes `action` and `data` from user interaction.\n\n**Non-blocking mode:** Tool returns immediately after rendering.\n```json\n{ \"blocking\": false }\n```\nUse for status displays that don't need user input.\n\n## Form Data Collection\n\nInput components with a `name` prop automatically collect form data. When user clicks an action button, all named inputs are collected and returned in `data`.\n\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Settings\" },\n  \"children\": [\n    { \"type\": \"TextInput\", \"props\": { \"name\": \"username\", \"label\": \"Username\" } },\n    { \"type\": \"Toggle\", \"props\": { \"name\": \"notifications\", \"label\": \"Enable notifications\" } }\n  ],\n  \"actions\": [{ \"id\": \"save\", \"label\": \"Save\", \"primary\": true }]\n}\n```\n\nResponse: `{ \"action\": \"save\", \"data\": { \"username\": \"alice\", \"notifications\": true } }`\n\n---\n\n## Component Selection Guide\n\n### Need user to choose from options?\n\n| Scenario | Component | Notes |\n|----------|-----------|-------|\n| 2-5 visible options | RadioGroup | Shows all options |\n| 6+ options | MultipleChoice | Dropdown/select |\n| Boolean yes/no | Toggle | Switch control |\n| Multiple selections | Checkbox | Checkboxes |\n\n### Need text input?\n\n| Scenario | Component | Notes |\n|----------|-----------|-------|\n| Single line | TextInput | type: text/email/url |\n| Multi-line | TextArea | rows: number |\n| Number with bounds | NumberInput | min/max/step |\n| Number in range | Slider | showValue for display |\n| File selection | FileUpload | accept, multiple |\n\n### Displaying data?\n\n| Scenario | Component | Notes |\n|----------|-----------|-------|\n| Code | CodeBlock | language, showLineNumbers |\n| JSON | JsonViewer | collapsed option |\n| Table data | Table | columns, rows |\n| Rich text | Markdown | content |\n| Image | Image | src, alt, caption |\n\n### Showing status?\n\n| Scenario | Component | Notes |\n|----------|-----------|-------|\n| Loading | Spinner | size, label |\n| Label/tag | Badge | variant, size |\n| Progress | ProgressBar | value, max, label |\n\n---\n\n## Component Reference\n\n### Display Components (8)\n\n#### Table\n```json\n{\n  \"type\": \"Table\",\n  \"props\": {\n    \"columns\": [\n      { \"key\": \"name\", \"header\": \"Name\" },\n      { \"key\": \"status\", \"header\": \"Status\" }\n    ],\n    \"rows\": [\n      { \"name\": \"Task 1\", \"status\": \"Complete\" },\n      { \"name\": \"Task 2\", \"status\": \"Pending\" }\n    ]\n  }\n}\n```\n\n#### CodeBlock\n```json\n{\n  \"type\": \"CodeBlock\",\n  \"props\": {\n    \"code\": \"const x = 1;\",\n    \"language\": \"javascript\",\n    \"showLineNumbers\": true\n  }\n}\n```\n\n#### Image\n```json\n{\n  \"type\": \"Image\",\n  \"props\": {\n    \"src\": \"https://example.com/image.png\",\n    \"alt\": \"Description\",\n    \"caption\": \"Figure 1: Example\",\n    \"objectFit\": \"contain\"\n  }\n}\n```\n\n#### Spinner\n```json\n{\n  \"type\": \"Spinner\",\n  \"props\": { \"size\": \"md\", \"label\": \"Loading...\" }\n}\n```\n\n#### Badge\n```json\n{\n  \"type\": \"Badge\",\n  \"props\": { \"text\": \"New\", \"variant\": \"success\", \"size\": \"sm\" }\n}\n```\nVariants: default, info, success, warning, error\n\n### Layout Components (6)\n\n#### Card\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Title\", \"subtitle\": \"Subtitle\" },\n  \"children\": [...],\n  \"actions\": [{ \"id\": \"submit\", \"label\": \"Submit\", \"primary\": true }]\n}\n```\n\n#### Divider\n```json\n{\n  \"type\": \"Divider\",\n  \"props\": { \"orientation\": \"horizontal\", \"label\": \"OR\" }\n}\n```\n\n### Interactive Components (6)\n\n#### Link\n```json\n{\n  \"type\": \"Link\",\n  \"props\": {\n    \"label\": \"View docs\",\n    \"href\": \"https://example.com\",\n    \"external\": true,\n    \"variant\": \"primary\"\n  }\n}\n```\nVariants: default, primary, subtle\n\n### Input Components (10)\n\n#### RadioGroup\n```json\n{\n  \"type\": \"RadioGroup\",\n  \"props\": {\n    \"name\": \"choice\",\n    \"label\": \"Select one\",\n    \"options\": [\n      { \"value\": \"a\", \"label\": \"Option A\" },\n      { \"value\": \"b\", \"label\": \"Option B\" }\n    ],\n    \"orientation\": \"vertical\"\n  }\n}\n```\n\n#### Toggle\n```json\n{\n  \"type\": \"Toggle\",\n  \"props\": {\n    \"name\": \"enabled\",\n    \"label\": \"Enable feature\",\n    \"size\": \"md\"\n  }\n}\n```\nSizes: sm, md, lg\n\n#### NumberInput\n```json\n{\n  \"type\": \"NumberInput\",\n  \"props\": {\n    \"name\": \"quantity\",\n    \"label\": \"Quantity\",\n    \"min\": 1,\n    \"max\": 100,\n    \"step\": 1\n  }\n}\n```\n\n#### Slider\n```json\n{\n  \"type\": \"Slider\",\n  \"props\": {\n    \"name\": \"volume\",\n    \"label\": \"Volume\",\n    \"min\": 0,\n    \"max\": 100,\n    \"showValue\": true\n  }\n}\n```\n\n#### FileUpload\n```json\n{\n  \"type\": \"FileUpload\",\n  \"props\": {\n    \"name\": \"files\",\n    \"label\": \"Upload files\",\n    \"accept\": \".pdf,.doc\",\n    \"multiple\": true,\n    \"maxSize\": 5242880\n  }\n}\n```\n\n---\n\n## Best Practices\n\n1. **Keep UIs focused** - One primary action per UI\n2. **Use blocking mode** for decisions that affect workflow\n3. **Provide clear labels** - Every input needs context\n4. **Handle disabled states** - Set `disabled: true` when UI shouldn't be interactive\n5. **Use appropriate components** - Match component to data type\n\n## Common Patterns\n\n### Yes/No Confirmation\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Confirm\" },\n  \"children\": [\n    { \"type\": \"Markdown\", \"props\": { \"content\": \"Proceed with this action?\" } }\n  ],\n  \"actions\": [\n    { \"id\": \"yes\", \"label\": \"Yes\", \"primary\": true },\n    { \"id\": \"no\", \"label\": \"No\" }\n  ]\n}\n```\n\n### Multiple Choice Selection\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Choose approach\" },\n  \"children\": [\n    {\n      \"type\": \"RadioGroup\",\n      \"props\": {\n        \"name\": \"approach\",\n        \"options\": [\n          { \"value\": \"1\", \"label\": \"Option 1 (Recommended)\" },\n          { \"value\": \"2\", \"label\": \"Option 2\" },\n          { \"value\": \"3\", \"label\": \"Option 3\" }\n        ]\n      }\n    }\n  ],\n  \"actions\": [{ \"id\": \"select\", \"label\": \"Continue\", \"primary\": true }]\n}\n```\n\n### Form with Multiple Inputs\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Configuration\" },\n  \"children\": [\n    { \"type\": \"TextInput\", \"props\": { \"name\": \"name\", \"label\": \"Name\" } },\n    { \"type\": \"NumberInput\", \"props\": { \"name\": \"count\", \"label\": \"Count\", \"min\": 1 } },\n    { \"type\": \"Toggle\", \"props\": { \"name\": \"debug\", \"label\": \"Debug mode\" } }\n  ],\n  \"actions\": [\n    { \"id\": \"cancel\", \"label\": \"Cancel\" },\n    { \"id\": \"save\", \"label\": \"Save\", \"primary\": true }\n  ]\n}\n```\n\n### Progress Display (Non-blocking)\n```json\n{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Processing\" },\n  \"children\": [\n    { \"type\": \"ProgressBar\", \"props\": { \"value\": 45, \"max\": 100, \"label\": \"45% complete\" } },\n    { \"type\": \"Spinner\", \"props\": { \"label\": \"Please wait...\" } }\n  ]\n}\n```\n\n## Integration\n\n**MCP Tool:** `mcp__plugin_mermaid-collab_mermaid__render_ui`\n\n**Parameters:**\n- `project` (required): Absolute path to project root\n- `session` (required): Session name\n- `ui` (required): JSON UI component definition\n- `blocking` (optional): Wait for user action (default: true)\n- `timeout` (optional): Timeout in ms (default: 30000)\n\n**Returns:**\n- `action`: The action ID clicked\n- `data`: Collected form data from named inputs\n",
        "skills/using-gui-wireframes/SKILL.md": "---\nname: using-gui-wireframes\ndescription: Use when creating or editing UI mockups, screen layouts, or interface designs. Use INSTEAD of ASCII art for any visual UI representation.\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read\n---\n\n# Using GUI Wireframes\n\n## Overview\n\n**ALWAYS use mermaid wireframe syntax for UI mockups.** Never use ASCII art boxes, tables, or text representations for UI layouts.\n\n## When to Use\n\nUse wireframe syntax when:\n- User asks for a \"mockup\", \"wireframe\", \"UI design\", or \"screen layout\"\n- Visualizing app screens, forms, dashboards, or navigation flows\n- Showing multi-screen user flows or journeys\n- Any situation where you'd otherwise draw ASCII boxes for UI\n\n**NEVER use ASCII art for UI.** Wireframe syntax renders as actual visual diagrams.\n\n## Quick Syntax Reference\n\n```\nwireframe [viewport] [direction]\n  [component] [\"label\"] [modifiers]\n```\n\n**Viewports:** `mobile` (375×600), `tablet` (768×1024), `desktop` (1200×800)\n\n**Direction:** `LR` (horizontal screens), `TD` (vertical screens)\n\n**Containers:**\n| Component | Purpose |\n|-----------|---------|\n| `col` | Stack children vertically |\n| `row` | Place children horizontally |\n| `Card` | Bordered container |\n| `screen \"label\"` | Separate viewport (for flows) |\n\n**Components:**\n| Component | Example |\n|-----------|---------|\n| `AppBar \"title\"` | Top navigation bar |\n| `Title \"text\"` | Large heading |\n| `Text \"text\"` | Body text |\n| `Input \"placeholder\"` | Text field |\n| `Button \"label\"` | Clickable button |\n| `Checkbox \"label\"` | Checkbox |\n| `Switch \"label\"` | Toggle |\n| `Dropdown \"label\"` | Select menu |\n| `Avatar` | User avatar |\n| `Image` | Image placeholder |\n| `spacer` | Flexible space |\n| `divider` | Horizontal line |\n\n**Modifiers:** `primary`, `secondary`, `danger`, `disabled`, `flex=N`, `width=N`, `height=N`, `padding=N`\n\n## Critical Syntax Rules\n\n1. **Indentation = hierarchy** - Use 2 spaces per level, no tabs\n2. **Labels in quotes** - `Button \"Submit\"` not `Button Submit`\n3. **Modifiers after label** - `Button \"Save\" primary` not `primary Button \"Save\"`\n4. **Grid uses pipes** - `header \"Col1 | Col2\"` and `row \"Val1 | Val2\"`\n\n## Common Patterns\n\n**Mobile form:**\n```\nwireframe mobile\n  col\n    AppBar \"Form Title\"\n    col padding=24\n      Input \"Field 1\"\n      Input \"Field 2\"\n      spacer\n      Button \"Submit\" primary\n```\n\n**Multi-screen flow:**\n```\nwireframe mobile LR\n  screen \"Login\"\n    col\n      AppBar \"Sign In\"\n      col padding=24\n        Input \"Email\"\n        Button \"Login\" primary\n  screen \"Home\"\n    col\n      AppBar \"Dashboard\"\n      Title \"Welcome\"\n```\n\n**Desktop sidebar layout:**\n```\nwireframe desktop\n  col\n    AppBar \"App\"\n    row flex\n      col width=200\n        List \"Nav 1\"\n        List \"Nav 2\"\n      col flex\n        Title \"Content\"\n```\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Using ASCII boxes `[Button]` | Use `Button \"label\"` |\n| Missing quotes on labels | `Title \"Hello\"` not `Title Hello` |\n| Wrong indentation | Exactly 2 spaces per level |\n| Tabs instead of spaces | Use spaces only |\n| Modifier before label | `Button \"X\" primary` not `primary Button \"X\"` |\n\n## Red Flags - You're Doing It Wrong\n\nIf you find yourself:\n- Drawing `+----+` boxes → Use wireframe syntax\n- Writing `| Button |` → Use `Button \"label\"`\n- Making ASCII tables for UI → Use `Grid` with `header`/`row`\n- Describing UI in prose → Create a wireframe diagram\n\n**These all mean: Use wireframe syntax instead.**\n",
        "skills/using-kodex/SKILL.md": "---\nname: using-kodex\ndescription: Use when project knowledge could help - queries Kodex topics and flags outdated information\nuser-invocable: false\nallowed-tools:\n  - mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\n  - mcp__plugin_mermaid-collab_mermaid__kodex_list_topics\n  - mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\n---\n\n# Using Kodex\n\nQuery and maintain the project knowledge base.\n\n## When to Query Kodex\n\nUse judgment to query Kodex when project knowledge could help:\n\n- Starting work on a feature that may have established patterns\n- Investigating code that follows project conventions\n- Making architectural decisions that should align with existing patterns\n\n**Don't query for:** Trivial tasks, unrelated work, or when you already have sufficient context.\n\n## How to Query\n\n### Topic Inference\n\nInfer topic names from your current context:\n\n1. Extract key concepts from the task (e.g., \"authentication\", \"error-handling\")\n2. Try variations: `{concept}`, `{concept}-patterns`, `{concept}-conventions`\n\n### Example\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_query_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"authentication\"\n}\n```\n\n### Handling Results\n\n- **Topic found:** Display content as context for your work\n- **Topic not found:** Try alternative names or continue without\n- **Error:** Log and continue (non-blocking)\n\n## When to Flag Topics\n\nFlag a topic when it contradicts actual code **after verification**:\n\n1. Query a topic and notice potential discrepancy\n2. Read the actual source files to verify\n3. Confirm the topic is genuinely outdated/incorrect\n4. Flag with specific details\n\n### Flagging Example\n\n```\nTool: mcp__plugin_mermaid-collab_mermaid__kodex_flag_topic\nArgs: {\n  \"project\": \"<absolute-path-to-cwd>\",\n  \"name\": \"authentication\",\n  \"type\": \"outdated\",\n  \"description\": \"Topic says JWT tokens expire in 1 hour, but code shows 24 hours (see src/auth/config.ts:15)\"\n}\n```\n\n**Never flag without verifying against actual code.**\n\n## MCP Tool Reference\n\n| Tool | Purpose |\n|------|---------|\n| `kodex_query_topic` | Query a topic by name |\n| `kodex_list_topics` | List all available topics |\n| `kodex_flag_topic` | Flag outdated/incorrect topic |\n| `kodex_dashboard` | View Kodex stats |\n| `kodex_list_flags` | View flagged topics |\n\n**Note:** Topic creation and updates are human-driven. Claude should flag issues, not directly modify topics.\n",
        "skills/using-superpowers/SKILL.md": "---\nname: using-superpowers\ndescription: Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions\nallowed-tools: Read, Skill\n---\n\n<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## How to Access Skills\n\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you—follow it directly. Never use the Read tool on skill files.\n\n**In other environments:** Check your platform's documentation for how skills are loaded.\n\n# Using Skills\n\n## The Rule\n\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\n\n```dot\ndigraph skill_flow {\n    \"User message received\" [shape=doublecircle];\n    \"Might any skill apply?\" [shape=diamond];\n    \"Invoke Skill tool\" [shape=box];\n    \"Announce: 'Using [skill] to [purpose]'\" [shape=box];\n    \"Has checklist?\" [shape=diamond];\n    \"Create TodoWrite todo per item\" [shape=box];\n    \"Follow skill exactly\" [shape=box];\n    \"Respond (including clarifications)\" [shape=doublecircle];\n\n    \"User message received\" -> \"Might any skill apply?\";\n    \"Might any skill apply?\" -> \"Invoke Skill tool\" [label=\"yes, even 1%\"];\n    \"Might any skill apply?\" -> \"Respond (including clarifications)\" [label=\"definitely not\"];\n    \"Invoke Skill tool\" -> \"Announce: 'Using [skill] to [purpose]'\";\n    \"Announce: 'Using [skill] to [purpose]'\" -> \"Has checklist?\";\n    \"Has checklist?\" -> \"Create TodoWrite todo per item\" [label=\"yes\"];\n    \"Has checklist?\" -> \"Follow skill exactly\" [label=\"no\"];\n    \"Create TodoWrite todo per item\" -> \"Follow skill exactly\";\n}\n```\n\n## Red Flags\n\nThese thoughts mean STOP—you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a simple question\" | Questions are tasks. Check for skills. |\n| \"I need more context first\" | Skill check comes BEFORE clarifying questions. |\n| \"Let me explore the codebase first\" | Skills tell you HOW to explore. Check first. |\n| \"I can check git/files quickly\" | Files lack conversation context. Check for skills. |\n| \"Let me gather information first\" | Skills tell you HOW to gather information. |\n| \"This doesn't need a formal skill\" | If a skill exists, use it. |\n| \"I remember this skill\" | Skills evolve. Read current version. |\n| \"This doesn't count as a task\" | Action = task. Check for skills. |\n| \"The skill is overkill\" | Simple things become complex. Use it. |\n| \"I'll just do this one thing first\" | Check BEFORE doing anything. |\n| \"This feels productive\" | Undisciplined action wastes time. Skills prevent this. |\n| \"I know what that means\" | Knowing the concept ≠ using the skill. Invoke it. |\n\n## Skill Priority\n\nWhen multiple skills could apply, use this order:\n\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\n\n\"Let's build X\" → brainstorming first, then implementation skills.\n\"Fix this bug\" → debugging first, then domain-specific skills.\n\n## Skill Types\n\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\n\n**Flexible** (patterns): Adapt principles to context.\n\nThe skill itself tells you which.\n\n## User Instructions\n\nInstructions say WHAT, not HOW. \"Add X\" or \"Fix Y\" doesn't mean skip workflows.\n",
        "skills/writing-plans/SKILL.md": "---\nname: writing-plans\ndescription: Use when you have a spec or requirements for a multi-step task, before touching code\nallowed-tools: mcp__plugin_mermaid-collab_mermaid__*, Read, Glob, Grep\n---\n\n# Writing Plans\n\n## Overview\n\nWrite comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.\n\nAssume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** This should be run in a dedicated worktree (created by brainstorming skill).\n\n**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n## Bite-Sized Task Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Plan Document Header\n\n**Design Artifacts:** \n- Wireframes: [list mermaid-collab diagram IDs or \"N/A\"]\n- Architecture diagrams: [list IDs or \"N/A\"]\n- Design doc: `docs/plans/YYYY-MM-DD-<topic>-design.md`\n\n**Every plan MUST start with this header:**\n\n```markdown\n# [Feature Name] Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** [One sentence describing what this builds]\n\n**Architecture:** [2-3 sentences about approach]\n\n**Tech Stack:** [Key technologies/libraries]\n\n---\n```\n\n## Task Structure\n\n```markdown\n### Task N: [Component Name]\n\n**Files:**\n- Create: `exact/path/to/file.py`\n- Modify: `exact/path/to/existing.py:123-145`\n- Test: `tests/exact/path/to/test.py`\n\n**Changes (pseudo code):**\n- `file.py`: Create class Foo with method bar() that takes input X and returns Y\n- `existing.py:123-145`: Add validation check before process() call, raise ValueError if invalid\n\n**Design Reference:**\n- Wireframe: `mermaid-collab/diagrams/<wireframe-id>` (if applicable)\n- Design Doc: `docs/plans/YYYY-MM-DD-<topic>-design.md` section X\n\n**Step 1: Write the failing test**\n\n```python\ndef test_specific_behavior():\n    result = function(input)\n    assert result == expected\n```\n\n**Step 2: Run test to verify it fails**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: FAIL with \"function not defined\"\n\n**Step 3: Write minimal implementation**\n\n```python\ndef function(input):\n    return expected\n```\n\n**Step 4: Run test to verify it passes**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: PASS\n\n**Step 5: Commit**\n\n```bash\ngit add tests/path/test.py src/path/file.py\ngit commit -m \"feat: add specific feature\"\n```\n```\n\n## Remember\n- Exact file paths always\n- Complete code in plan (not \"add validation\")\n- Exact commands with expected output\n- Reference relevant skills with @ syntax\n- DRY, YAGNI, TDD, frequent commits\n\n## Design Alignment Verification\n\n**Every task MUST be traceable to the design:**\n- Reference the specific section of the design doc that this task implements\n- If mermaid-collab wireframes/diagrams exist, reference them by ID\n- Verification steps must check against design, not just \"does code work\"\n\n**For UI tasks:**\n- Reference the wireframe diagram ID\n- Verification: \"Compare implementation to wireframe `<id>` — all elements present and positioned correctly\"\n\n**For architecture tasks:**\n- Reference the architecture/flow diagram ID\n- Verification: \"Confirm data flow matches diagram `<id>`\"\n\n**If design artifacts don't exist but should:**\n- Stop and create them in mermaid-collab before writing the task\n- The brainstorming skill should have created these — if missing, go back\n\n## Execution Handoff\n\nAfter saving the plan, offer execution choice:\n\n**\"Plan complete and saved to `docs/plans/<filename>.md`. Two execution options:**\n\n**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration\n\n**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints\n\n**Which approach?\"**\n\n**If Subagent-Driven chosen:**\n- **REQUIRED SUB-SKILL:** Use mermaid-collab:subagent-driven-development:implementer-prompt\n- Stay in this session\n- Fresh subagent per task + code review\n\n**If Parallel Session chosen:**\n- Guide them to open new session in worktree\n- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans\n",
        "skills/writing-skills/SKILL.md": "---\nname: writing-skills\ndescription: Use when creating new skills, editing existing skills, or verifying skills work before deployment\n---\n\n# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (`~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex)** \n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future Claude instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept | Skill Creation |\n|-------------|----------------|\n| **Test case** | Pressure scenario with subagent |\n| **Production code** | Skill document (SKILL.md) |\n| **Test fails (RED)** | Agent violates rule without skill (baseline) |\n| **Test passes (GREEN)** | Agent complies with skill present |\n| **Refactor** | Close loopholes while maintaining compliance |\n| **Write test first** | Run baseline scenario BEFORE writing skill |\n| **Watch it fail** | Document exact rationalizations agent uses |\n| **Minimal code** | Write skill addressing those specific violations |\n| **Watch it pass** | Verify agent now complies |\n| **Refactor cycle** | Find new rationalizations → plug → re-verify |\n\nThe entire skill creation process follows RED-GREEN-REFACTOR.\n\n## When to Create a Skill\n\n**Create when:**\n- Technique wasn't intuitively obvious to you\n- You'd reference this again across projects\n- Pattern applies broadly (not project-specific)\n- Others would benefit\n\n**Don't create for:**\n- One-off solutions\n- Standard practices well-documented elsewhere\n- Project-specific conventions (put in CLAUDE.md)\n- Mechanical constraints (if it's enforceable with regex/validation, automate it—save documentation for judgment calls)\n\n## Skill Types\n\n### Technique\nConcrete method with steps to follow (condition-based-waiting, root-cause-tracing)\n\n### Pattern\nWay of thinking about problems (flatten-with-flags, test-invariants)\n\n### Reference\nAPI docs, syntax guides, tool documentation (office docs)\n\n## Directory Structure\n\n\n```\nskills/\n  skill-name/\n    SKILL.md              # Main reference (required)\n    supporting-file.*     # Only if needed\n```\n\n**Flat namespace** - all skills in one searchable namespace\n\n**Separate files for:**\n1. **Heavy reference** (100+ lines) - API docs, comprehensive syntax\n2. **Reusable tools** - Scripts, utilities, templates\n\n**Keep inline:**\n- Principles and concepts\n- Code patterns (< 50 lines)\n- Everything else\n\n## SKILL.md Structure\n\n**Frontmatter (YAML):**\n- Only two fields supported: `name` and `description`\n- Max 1024 characters total\n- `name`: Use letters, numbers, and hyphens only (no parentheses, special chars)\n- `description`: Third-person, describes ONLY when to use (NOT what it does)\n  - Start with \"Use when...\" to focus on triggering conditions\n  - Include specific symptoms, situations, and contexts\n  - **NEVER summarize the skill's process or workflow** (see CSO section for why)\n  - Keep under 500 characters if possible\n\n```markdown\n---\nname: Skill-Name-With-Hyphens\ndescription: Use when [specific triggering conditions and symptoms]\n---\n\n# Skill Name\n\n## Overview\nWhat is this? Core principle in 1-2 sentences.\n\n## When to Use\n[Small inline flowchart IF decision non-obvious]\n\nBullet list with SYMPTOMS and use cases\nWhen NOT to use\n\n## Core Pattern (for techniques/patterns)\nBefore/after code comparison\n\n## Quick Reference\nTable or bullets for scanning common operations\n\n## Implementation\nInline code for simple patterns\nLink to file for heavy reference or reusable tools\n\n## Common Mistakes\nWhat goes wrong + fixes\n\n## Real-World Impact (optional)\nConcrete results\n```\n\n\n## Claude Search Optimization (CSO)\n\n**Critical for discovery:** Future Claude needs to FIND your skill\n\n### 1. Rich Description Field\n\n**Purpose:** Claude reads description to decide which skills to load for a given task. Make it answer: \"Should I read this skill right now?\"\n\n**Format:** Start with \"Use when...\" to focus on triggering conditions\n\n**CRITICAL: Description = When to Use, NOT What the Skill Does**\n\nThe description should ONLY describe triggering conditions. Do NOT summarize the skill's process or workflow in the description.\n\n**Why this matters:** Testing revealed that when a description summarizes the skill's workflow, Claude may follow the description instead of reading the full skill content. A description saying \"code review between tasks\" caused Claude to do ONE review, even though the skill's flowchart clearly showed TWO reviews (spec compliance then code quality).\n\nWhen the description was changed to just \"Use when executing implementation plans with independent tasks\" (no workflow summary), Claude correctly read the flowchart and followed the two-stage review process.\n\n**The trap:** Descriptions that summarize workflow create a shortcut Claude will take. The skill body becomes documentation Claude skips.\n\n```yaml\n# ❌ BAD: Summarizes workflow - Claude may follow this instead of reading skill\ndescription: Use when executing plans - dispatches subagent per task with code review between tasks\n\n# ❌ BAD: Too much process detail\ndescription: Use for TDD - write test first, watch it fail, write minimal code, refactor\n\n# ✅ GOOD: Just triggering conditions, no workflow summary\ndescription: Use when executing implementation plans with independent tasks in the current session\n\n# ✅ GOOD: Triggering conditions only\ndescription: Use when implementing any feature or bugfix, before writing implementation code\n```\n\n**Content:**\n- Use concrete triggers, symptoms, and situations that signal this skill applies\n- Describe the *problem* (race conditions, inconsistent behavior) not *language-specific symptoms* (setTimeout, sleep)\n- Keep triggers technology-agnostic unless the skill itself is technology-specific\n- If skill is technology-specific, make that explicit in the trigger\n- Write in third person (injected into system prompt)\n- **NEVER summarize the skill's process or workflow**\n\n```yaml\n# ❌ BAD: Too abstract, vague, doesn't include when to use\ndescription: For async testing\n\n# ❌ BAD: First person\ndescription: I can help you with async tests when they're flaky\n\n# ❌ BAD: Mentions technology but skill isn't specific to it\ndescription: Use when tests use setTimeout/sleep and are flaky\n\n# ✅ GOOD: Starts with \"Use when\", describes problem, no workflow\ndescription: Use when tests have race conditions, timing dependencies, or pass/fail inconsistently\n\n# ✅ GOOD: Technology-specific skill with explicit trigger\ndescription: Use when using React Router and handling authentication redirects\n```\n\n### 2. Keyword Coverage\n\nUse words Claude would search for:\n- Error messages: \"Hook timed out\", \"ENOTEMPTY\", \"race condition\"\n- Symptoms: \"flaky\", \"hanging\", \"zombie\", \"pollution\"\n- Synonyms: \"timeout/hang/freeze\", \"cleanup/teardown/afterEach\"\n- Tools: Actual commands, library names, file types\n\n### 3. Descriptive Naming\n\n**Use active voice, verb-first:**\n- ✅ `creating-skills` not `skill-creation`\n- ✅ `condition-based-waiting` not `async-test-helpers`\n\n### 4. Token Efficiency (Critical)\n\n**Problem:** getting-started and frequently-referenced skills load into EVERY conversation. Every token counts.\n\n**Target word counts:**\n- getting-started workflows: <150 words each\n- Frequently-loaded skills: <200 words total\n- Other skills: <500 words (still be concise)\n\n**Techniques:**\n\n**Move details to tool help:**\n```bash\n# ❌ BAD: Document all flags in SKILL.md\nsearch-conversations supports --text, --both, --after DATE, --before DATE, --limit N\n\n# ✅ GOOD: Reference --help\nsearch-conversations supports multiple modes and filters. Run --help for details.\n```\n\n**Use cross-references:**\n```markdown\n# ❌ BAD: Repeat workflow details\nWhen searching, dispatch subagent with template...\n[20 lines of repeated instructions]\n\n# ✅ GOOD: Reference other skill\nAlways use subagents (50-100x context savings). REQUIRED: Use [other-skill-name] for workflow.\n```\n\n**Compress examples:**\n```markdown\n# ❌ BAD: Verbose example (42 words)\nyour human partner: \"How did we handle authentication errors in React Router before?\"\nYou: I'll search past conversations for React Router authentication patterns.\n[Dispatch subagent with search query: \"React Router authentication error handling 401\"]\n\n# ✅ GOOD: Minimal example (20 words)\nPartner: \"How did we handle auth errors in React Router?\"\nYou: Searching...\n[Dispatch subagent → synthesis]\n```\n\n**Eliminate redundancy:**\n- Don't repeat what's in cross-referenced skills\n- Don't explain what's obvious from command\n- Don't include multiple examples of same pattern\n\n**Verification:**\n```bash\nwc -w skills/path/SKILL.md\n# getting-started workflows: aim for <150 each\n# Other frequently-loaded: aim for <200 total\n```\n\n**Name by what you DO or core insight:**\n- ✅ `condition-based-waiting` > `async-test-helpers`\n- ✅ `using-skills` not `skill-usage`\n- ✅ `flatten-with-flags` > `data-structure-refactoring`\n- ✅ `root-cause-tracing` > `debugging-techniques`\n\n**Gerunds (-ing) work well for processes:**\n- `creating-skills`, `testing-skills`, `debugging-with-logs`\n- Active, describes the action you're taking\n\n### 4. Cross-Referencing Other Skills\n\n**When writing documentation that references other skills:**\n\nUse skill name only, with explicit requirement markers:\n- ✅ Good: `**REQUIRED SUB-SKILL:** Use superpowers:test-driven-development`\n- ✅ Good: `**REQUIRED BACKGROUND:** You MUST understand superpowers:systematic-debugging`\n- ❌ Bad: `See skills/testing/test-driven-development` (unclear if required)\n- ❌ Bad: `@skills/testing/test-driven-development/SKILL.md` (force-loads, burns context)\n\n**Why no @ links:** `@` syntax force-loads files immediately, consuming 200k+ context before you need them.\n\n## Flowchart Usage\n\n```dot\ndigraph when_flowchart {\n    \"Need to show information?\" [shape=diamond];\n    \"Decision where I might go wrong?\" [shape=diamond];\n    \"Use markdown\" [shape=box];\n    \"Small inline flowchart\" [shape=box];\n\n    \"Need to show information?\" -> \"Decision where I might go wrong?\" [label=\"yes\"];\n    \"Decision where I might go wrong?\" -> \"Small inline flowchart\" [label=\"yes\"];\n    \"Decision where I might go wrong?\" -> \"Use markdown\" [label=\"no\"];\n}\n```\n\n**Use flowcharts ONLY for:**\n- Non-obvious decision points\n- Process loops where you might stop too early\n- \"When to use A vs B\" decisions\n\n**Never use flowcharts for:**\n- Reference material → Tables, lists\n- Code examples → Markdown blocks\n- Linear instructions → Numbered lists\n- Labels without semantic meaning (step1, helper2)\n\nSee @graphviz-conventions.dot for graphviz style rules.\n\n**Visualizing for your human partner:** Use `render-graphs.js` in this directory to render a skill's flowcharts to SVG:\n```bash\n./render-graphs.js ../some-skill           # Each diagram separately\n./render-graphs.js ../some-skill --combine # All diagrams in one SVG\n```\n\n## Code Examples\n\n**One excellent example beats many mediocre ones**\n\nChoose most relevant language:\n- Testing techniques → TypeScript/JavaScript\n- System debugging → Shell/Python\n- Data processing → Python\n\n**Good example:**\n- Complete and runnable\n- Well-commented explaining WHY\n- From real scenario\n- Shows pattern clearly\n- Ready to adapt (not generic template)\n\n**Don't:**\n- Implement in 5+ languages\n- Create fill-in-the-blank templates\n- Write contrived examples\n\nYou're good at porting - one great example is enough.\n\n## File Organization\n\n### Self-Contained Skill\n```\ndefense-in-depth/\n  SKILL.md    # Everything inline\n```\nWhen: All content fits, no heavy reference needed\n\n### Skill with Reusable Tool\n```\ncondition-based-waiting/\n  SKILL.md    # Overview + patterns\n  example.ts  # Working helpers to adapt\n```\nWhen: Tool is reusable code, not just narrative\n\n### Skill with Heavy Reference\n```\npptx/\n  SKILL.md       # Overview + workflows\n  pptxgenjs.md   # 600 lines API reference\n  ooxml.md       # 500 lines XML structure\n  scripts/       # Executable tools\n```\nWhen: Reference material too large for inline\n\n## The Iron Law (Same as TDD)\n\n```\nNO SKILL WITHOUT A FAILING TEST FIRST\n```\n\nThis applies to NEW skills AND EDITS to existing skills.\n\nWrite skill before testing? Delete it. Start over.\nEdit skill without testing? Same violation.\n\n**No exceptions:**\n- Not for \"simple additions\"\n- Not for \"just adding a section\"\n- Not for \"documentation updates\"\n- Don't keep untested changes as \"reference\"\n- Don't \"adapt\" while running tests\n- Delete means delete\n\n**REQUIRED BACKGROUND:** The superpowers:test-driven-development skill explains why this matters. Same principles apply to documentation.\n\n## Testing All Skill Types\n\nDifferent skill types need different test approaches:\n\n### Discipline-Enforcing Skills (rules/requirements)\n\n**Examples:** TDD, verification-before-completion, designing-before-coding\n\n**Test with:**\n- Academic questions: Do they understand the rules?\n- Pressure scenarios: Do they comply under stress?\n- Multiple pressures combined: time + sunk cost + exhaustion\n- Identify rationalizations and add explicit counters\n\n**Success criteria:** Agent follows rule under maximum pressure\n\n### Technique Skills (how-to guides)\n\n**Examples:** condition-based-waiting, root-cause-tracing, defensive-programming\n\n**Test with:**\n- Application scenarios: Can they apply the technique correctly?\n- Variation scenarios: Do they handle edge cases?\n- Missing information tests: Do instructions have gaps?\n\n**Success criteria:** Agent successfully applies technique to new scenario\n\n### Pattern Skills (mental models)\n\n**Examples:** reducing-complexity, information-hiding concepts\n\n**Test with:**\n- Recognition scenarios: Do they recognize when pattern applies?\n- Application scenarios: Can they use the mental model?\n- Counter-examples: Do they know when NOT to apply?\n\n**Success criteria:** Agent correctly identifies when/how to apply pattern\n\n### Reference Skills (documentation/APIs)\n\n**Examples:** API documentation, command references, library guides\n\n**Test with:**\n- Retrieval scenarios: Can they find the right information?\n- Application scenarios: Can they use what they found correctly?\n- Gap testing: Are common use cases covered?\n\n**Success criteria:** Agent finds and correctly applies reference information\n\n## Common Rationalizations for Skipping Testing\n\n| Excuse | Reality |\n|--------|---------|\n| \"Skill is obviously clear\" | Clear to you ≠ clear to other agents. Test it. |\n| \"It's just a reference\" | References can have gaps, unclear sections. Test retrieval. |\n| \"Testing is overkill\" | Untested skills have issues. Always. 15 min testing saves hours. |\n| \"I'll test if problems emerge\" | Problems = agents can't use skill. Test BEFORE deploying. |\n| \"Too tedious to test\" | Testing is less tedious than debugging bad skill in production. |\n| \"I'm confident it's good\" | Overconfidence guarantees issues. Test anyway. |\n| \"Academic review is enough\" | Reading ≠ using. Test application scenarios. |\n| \"No time to test\" | Deploying untested skill wastes more time fixing it later. |\n\n**All of these mean: Test before deploying. No exceptions.**\n\n## Bulletproofing Skills Against Rationalization\n\nSkills that enforce discipline (like TDD) need to resist rationalization. Agents are smart and will find loopholes when under pressure.\n\n**Psychology note:** Understanding WHY persuasion techniques work helps you apply them systematically. See persuasion-principles.md for research foundation (Cialdini, 2021; Meincke et al., 2025) on authority, commitment, scarcity, social proof, and unity principles.\n\n### Close Every Loophole Explicitly\n\nDon't just state the rule - forbid specific workarounds:\n\n<Bad>\n```markdown\nWrite code before test? Delete it.\n```\n</Bad>\n\n<Good>\n```markdown\nWrite code before test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n```\n</Good>\n\n### Address \"Spirit vs Letter\" Arguments\n\nAdd foundational principle early:\n\n```markdown\n**Violating the letter of the rules is violating the spirit of the rules.**\n```\n\nThis cuts off entire class of \"I'm following the spirit\" rationalizations.\n\n### Build Rationalization Table\n\nCapture rationalizations from baseline testing (see Testing section below). Every excuse agents make goes in the table:\n\n```markdown\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n```\n\n### Create Red Flags List\n\nMake it easy for agents to self-check when rationalizing:\n\n```markdown\n## Red Flags - STOP and Start Over\n\n- Code before test\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n```\n\n### Update CSO for Violation Symptoms\n\nAdd to description: symptoms of when you're ABOUT to violate the rule:\n\n```yaml\ndescription: use when implementing any feature or bugfix, before writing implementation code\n```\n\n## RED-GREEN-REFACTOR for Skills\n\nFollow the TDD cycle:\n\n### RED: Write Failing Test (Baseline)\n\nRun pressure scenario with subagent WITHOUT the skill. Document exact behavior:\n- What choices did they make?\n- What rationalizations did they use (verbatim)?\n- Which pressures triggered violations?\n\nThis is \"watch the test fail\" - you must see what agents naturally do before writing the skill.\n\n### GREEN: Write Minimal Skill\n\nWrite skill that addresses those specific rationalizations. Don't add extra content for hypothetical cases.\n\nRun same scenarios WITH skill. Agent should now comply.\n\n### REFACTOR: Close Loopholes\n\nAgent found new rationalization? Add explicit counter. Re-test until bulletproof.\n\n**Testing methodology:** See @testing-skills-with-subagents.md for the complete testing methodology:\n- How to write pressure scenarios\n- Pressure types (time, sunk cost, authority, exhaustion)\n- Plugging holes systematically\n- Meta-testing techniques\n\n## Anti-Patterns\n\n### ❌ Narrative Example\n\"In session 2025-10-03, we found empty projectDir caused...\"\n**Why bad:** Too specific, not reusable\n\n### ❌ Multi-Language Dilution\nexample-js.js, example-py.py, example-go.go\n**Why bad:** Mediocre quality, maintenance burden\n\n### ❌ Code in Flowcharts\n```dot\nstep1 [label=\"import fs\"];\nstep2 [label=\"read file\"];\n```\n**Why bad:** Can't copy-paste, hard to read\n\n### ❌ Generic Labels\nhelper1, helper2, step3, pattern4\n**Why bad:** Labels should have semantic meaning\n\n## STOP: Before Moving to Next Skill\n\n**After writing ANY skill, you MUST STOP and complete the deployment process.**\n\n**Do NOT:**\n- Create multiple skills in batch without testing each\n- Move to next skill before current one is verified\n- Skip testing because \"batching is more efficient\"\n\n**The deployment checklist below is MANDATORY for EACH skill.**\n\nDeploying untested skills = deploying untested code. It's a violation of quality standards.\n\n## Skill Creation Checklist (TDD Adapted)\n\n**IMPORTANT: Use TodoWrite to create todos for EACH checklist item below.**\n\n**RED Phase - Write Failing Test:**\n- [ ] Create pressure scenarios (3+ combined pressures for discipline skills)\n- [ ] Run scenarios WITHOUT skill - document baseline behavior verbatim\n- [ ] Identify patterns in rationalizations/failures\n\n**GREEN Phase - Write Minimal Skill:**\n- [ ] Name uses only letters, numbers, hyphens (no parentheses/special chars)\n- [ ] YAML frontmatter with only name and description (max 1024 chars)\n- [ ] Description starts with \"Use when...\" and includes specific triggers/symptoms\n- [ ] Description written in third person\n- [ ] Keywords throughout for search (errors, symptoms, tools)\n- [ ] Clear overview with core principle\n- [ ] Address specific baseline failures identified in RED\n- [ ] Code inline OR link to separate file\n- [ ] One excellent example (not multi-language)\n- [ ] Run scenarios WITH skill - verify agents now comply\n\n**REFACTOR Phase - Close Loopholes:**\n- [ ] Identify NEW rationalizations from testing\n- [ ] Add explicit counters (if discipline skill)\n- [ ] Build rationalization table from all test iterations\n- [ ] Create red flags list\n- [ ] Re-test until bulletproof\n\n**Quality Checks:**\n- [ ] Small flowchart only if decision non-obvious\n- [ ] Quick reference table\n- [ ] Common mistakes section\n- [ ] No narrative storytelling\n- [ ] Supporting files only for tools or heavy reference\n\n**Deployment:**\n- [ ] Commit skill to git and push to your fork (if configured)\n- [ ] Consider contributing back via PR (if broadly useful)\n\n## Discovery Workflow\n\nHow future Claude finds your skill:\n\n1. **Encounters problem** (\"tests are flaky\")\n3. **Finds SKILL** (description matches)\n4. **Scans overview** (is this relevant?)\n5. **Reads patterns** (quick reference table)\n6. **Loads example** (only when implementing)\n\n**Optimize for this flow** - put searchable terms early and often.\n\n## The Bottom Line\n\n**Creating skills IS TDD for process documentation.**\n\nSame Iron Law: No skill without failing test first.\nSame cycle: RED (baseline) → GREEN (write skill) → REFACTOR (close loopholes).\nSame benefits: Better quality, fewer surprises, bulletproof results.\n\nIf you follow TDD for code, follow it for skills. It's the same discipline applied to documentation.\n",
        "skills/writing-skills/anthropic-best-practices.md": "# Skill authoring best practices\n\n> Learn how to write effective Skills that Claude can discover and use successfully.\n\nGood Skills are concise, well-structured, and tested with real usage. This guide provides practical authoring decisions to help you write Skills that Claude can discover and use effectively.\n\nFor conceptual background on how Skills work, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview).\n\n## Core principles\n\n### Concise is key\n\nThe [context window](https://platform.claude.com/docs/en/build-with-claude/context-windows) is a public good. Your Skill shares the context window with everything else Claude needs to know, including:\n\n* The system prompt\n* Conversation history\n* Other Skills' metadata\n* Your actual request\n\nNot every token in your Skill has an immediate cost. At startup, only the metadata (name and description) from all Skills is pre-loaded. Claude reads SKILL.md only when the Skill becomes relevant, and reads additional files only as needed. However, being concise in SKILL.md still matters: once Claude loads it, every token competes with conversation history and other context.\n\n**Default assumption**: Claude is already very smart\n\nOnly add context Claude doesn't already have. Challenge each piece of information:\n\n* \"Does Claude really need this explanation?\"\n* \"Can I assume Claude knows this?\"\n* \"Does this paragraph justify its token cost?\"\n\n**Good example: Concise** (approximately 50 tokens):\n\n````markdown  theme={null}\n## Extract PDF text\n\nUse pdfplumber for text extraction:\n\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n````\n\n**Bad example: Too verbose** (approximately 150 tokens):\n\n```markdown  theme={null}\n## Extract PDF text\n\nPDF (Portable Document Format) files are a common file format that contains\ntext, images, and other content. To extract text from a PDF, you'll need to\nuse a library. There are many libraries available for PDF processing, but we\nrecommend pdfplumber because it's easy to use and handles most cases well.\nFirst, you'll need to install it using pip. Then you can use the code below...\n```\n\nThe concise version assumes Claude knows what PDFs are and how libraries work.\n\n### Set appropriate degrees of freedom\n\nMatch the level of specificity to the task's fragility and variability.\n\n**High freedom** (text-based instructions):\n\nUse when:\n\n* Multiple approaches are valid\n* Decisions depend on context\n* Heuristics guide the approach\n\nExample:\n\n```markdown  theme={null}\n## Code review process\n\n1. Analyze the code structure and organization\n2. Check for potential bugs or edge cases\n3. Suggest improvements for readability and maintainability\n4. Verify adherence to project conventions\n```\n\n**Medium freedom** (pseudocode or scripts with parameters):\n\nUse when:\n\n* A preferred pattern exists\n* Some variation is acceptable\n* Configuration affects behavior\n\nExample:\n\n````markdown  theme={null}\n## Generate report\n\nUse this template and customize as needed:\n\n```python\ndef generate_report(data, format=\"markdown\", include_charts=True):\n    # Process data\n    # Generate output in specified format\n    # Optionally include visualizations\n```\n````\n\n**Low freedom** (specific scripts, few or no parameters):\n\nUse when:\n\n* Operations are fragile and error-prone\n* Consistency is critical\n* A specific sequence must be followed\n\nExample:\n\n````markdown  theme={null}\n## Database migration\n\nRun exactly this script:\n\n```bash\npython scripts/migrate.py --verify --backup\n```\n\nDo not modify the command or add additional flags.\n````\n\n**Analogy**: Think of Claude as a robot exploring a path:\n\n* **Narrow bridge with cliffs on both sides**: There's only one safe way forward. Provide specific guardrails and exact instructions (low freedom). Example: database migrations that must run in exact sequence.\n* **Open field with no hazards**: Many paths lead to success. Give general direction and trust Claude to find the best route (high freedom). Example: code reviews where context determines the best approach.\n\n### Test with all models you plan to use\n\nSkills act as additions to models, so effectiveness depends on the underlying model. Test your Skill with all the models you plan to use it with.\n\n**Testing considerations by model**:\n\n* **Claude Haiku** (fast, economical): Does the Skill provide enough guidance?\n* **Claude Sonnet** (balanced): Is the Skill clear and efficient?\n* **Claude Opus** (powerful reasoning): Does the Skill avoid over-explaining?\n\nWhat works perfectly for Opus might need more detail for Haiku. If you plan to use your Skill across multiple models, aim for instructions that work well with all of them.\n\n## Skill structure\n\n<Note>\n  **YAML Frontmatter**: The SKILL.md frontmatter supports two fields:\n\n  * `name` - Human-readable name of the Skill (64 characters maximum)\n  * `description` - One-line description of what the Skill does and when to use it (1024 characters maximum)\n\n  For complete Skill structure details, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#skill-structure).\n</Note>\n\n### Naming conventions\n\nUse consistent naming patterns to make Skills easier to reference and discuss. We recommend using **gerund form** (verb + -ing) for Skill names, as this clearly describes the activity or capability the Skill provides.\n\n**Good naming examples (gerund form)**:\n\n* \"Processing PDFs\"\n* \"Analyzing spreadsheets\"\n* \"Managing databases\"\n* \"Testing code\"\n* \"Writing documentation\"\n\n**Acceptable alternatives**:\n\n* Noun phrases: \"PDF Processing\", \"Spreadsheet Analysis\"\n* Action-oriented: \"Process PDFs\", \"Analyze Spreadsheets\"\n\n**Avoid**:\n\n* Vague names: \"Helper\", \"Utils\", \"Tools\"\n* Overly generic: \"Documents\", \"Data\", \"Files\"\n* Inconsistent patterns within your skill collection\n\nConsistent naming makes it easier to:\n\n* Reference Skills in documentation and conversations\n* Understand what a Skill does at a glance\n* Organize and search through multiple Skills\n* Maintain a professional, cohesive skill library\n\n### Writing effective descriptions\n\nThe `description` field enables Skill discovery and should include both what the Skill does and when to use it.\n\n<Warning>\n  **Always write in third person**. The description is injected into the system prompt, and inconsistent point-of-view can cause discovery problems.\n\n  * **Good:** \"Processes Excel files and generates reports\"\n  * **Avoid:** \"I can help you process Excel files\"\n  * **Avoid:** \"You can use this to process Excel files\"\n</Warning>\n\n**Be specific and include key terms**. Include both what the Skill does and specific triggers/contexts for when to use it.\n\nEach Skill has exactly one description field. The description is critical for skill selection: Claude uses it to choose the right Skill from potentially 100+ available Skills. Your description must provide enough detail for Claude to know when to select this Skill, while the rest of SKILL.md provides the implementation details.\n\nEffective examples:\n\n**PDF Processing skill:**\n\n```yaml  theme={null}\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n**Excel Analysis skill:**\n\n```yaml  theme={null}\ndescription: Analyze Excel spreadsheets, create pivot tables, generate charts. Use when analyzing Excel files, spreadsheets, tabular data, or .xlsx files.\n```\n\n**Git Commit Helper skill:**\n\n```yaml  theme={null}\ndescription: Generate descriptive commit messages by analyzing git diffs. Use when the user asks for help writing commit messages or reviewing staged changes.\n```\n\nAvoid vague descriptions like these:\n\n```yaml  theme={null}\ndescription: Helps with documents\n```\n\n```yaml  theme={null}\ndescription: Processes data\n```\n\n```yaml  theme={null}\ndescription: Does stuff with files\n```\n\n### Progressive disclosure patterns\n\nSKILL.md serves as an overview that points Claude to detailed materials as needed, like a table of contents in an onboarding guide. For an explanation of how progressive disclosure works, see [How Skills work](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work) in the overview.\n\n**Practical guidance:**\n\n* Keep SKILL.md body under 500 lines for optimal performance\n* Split content into separate files when approaching this limit\n* Use the patterns below to organize instructions, code, and resources effectively\n\n#### Visual overview: From simple to complex\n\nA basic Skill starts with just a SKILL.md file containing metadata and instructions:\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=87782ff239b297d9a9e8e1b72ed72db9\" alt=\"Simple SKILL.md file showing YAML frontmatter and markdown body\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1153\" height=\"1153\" data-path=\"images/agent-skills-simple-file.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=c61cc33b6f5855809907f7fda94cd80e 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=90d2c0c1c76b36e8d485f49e0810dbfd 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=ad17d231ac7b0bea7e5b4d58fb4aeabb 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=f5d0a7a3c668435bb0aee9a3a8f8c329 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=0e927c1af9de5799cfe557d12249f6e6 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=46bbb1a51dd4c8202a470ac8c80a893d 2500w\" />\n\nAs your Skill grows, you can bundle additional content that Claude loads only when needed:\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=a5e0aa41e3d53985a7e3e43668a33ea3\" alt=\"Bundling additional reference files like reference.md and forms.md.\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1327\" height=\"1327\" data-path=\"images/agent-skills-bundling-content.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=f8a0e73783e99b4a643d79eac86b70a2 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=dc510a2a9d3f14359416b706f067904a 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=82cd6286c966303f7dd914c28170e385 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=56f3be36c77e4fe4b523df209a6824c6 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=d22b5161b2075656417d56f41a74f3dd 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=3dd4bdd6850ffcc96c6c45fcb0acd6eb 2500w\" />\n\nThe complete Skill directory structure might look like this:\n\n```\npdf/\n├── SKILL.md              # Main instructions (loaded when triggered)\n├── FORMS.md              # Form-filling guide (loaded as needed)\n├── reference.md          # API reference (loaded as needed)\n├── examples.md           # Usage examples (loaded as needed)\n└── scripts/\n    ├── analyze_form.py   # Utility script (executed, not loaded)\n    ├── fill_form.py      # Form filling script\n    └── validate.py       # Validation script\n```\n\n#### Pattern 1: High-level guide with references\n\n````markdown  theme={null}\n---\nname: PDF Processing\ndescription: Extracts text and tables from PDF files, fills forms, and merges documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n---\n\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n```python\nimport pdfplumber\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n\n## Advanced features\n\n**Form filling**: See [FORMS.md](FORMS.md) for complete guide\n**API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n**Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n````\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n#### Pattern 2: Domain-specific organization\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context. When a user asks about sales metrics, Claude only needs to read sales-related schemas, not finance or marketing data. This keeps token usage low and context focused.\n\n```\nbigquery-skill/\n├── SKILL.md (overview and navigation)\n└── reference/\n    ├── finance.md (revenue, billing metrics)\n    ├── sales.md (opportunities, pipeline)\n    ├── product.md (API usage, features)\n    └── marketing.md (campaigns, attribution)\n```\n\n````markdown SKILL.md theme={null}\n# BigQuery Data Analysis\n\n## Available datasets\n\n**Finance**: Revenue, ARR, billing → See [reference/finance.md](reference/finance.md)\n**Sales**: Opportunities, pipeline, accounts → See [reference/sales.md](reference/sales.md)\n**Product**: API usage, features, adoption → See [reference/product.md](reference/product.md)\n**Marketing**: Campaigns, attribution, email → See [reference/marketing.md](reference/marketing.md)\n\n## Quick search\n\nFind specific metrics using grep:\n\n```bash\ngrep -i \"revenue\" reference/finance.md\ngrep -i \"pipeline\" reference/sales.md\ngrep -i \"api usage\" reference/product.md\n```\n````\n\n#### Pattern 3: Conditional details\n\nShow basic content, link to advanced content:\n\n```markdown  theme={null}\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n### Avoid deeply nested references\n\nClaude may partially read files when they're referenced from other referenced files. When encountering nested references, Claude might use commands like `head -100` to preview content rather than reading entire files, resulting in incomplete information.\n\n**Keep references one level deep from SKILL.md**. All reference files should link directly from SKILL.md to ensure Claude reads complete files when needed.\n\n**Bad example: Too deep**:\n\n```markdown  theme={null}\n# SKILL.md\nSee [advanced.md](advanced.md)...\n\n# advanced.md\nSee [details.md](details.md)...\n\n# details.md\nHere's the actual information...\n```\n\n**Good example: One level deep**:\n\n```markdown  theme={null}\n# SKILL.md\n\n**Basic usage**: [instructions in SKILL.md]\n**Advanced features**: See [advanced.md](advanced.md)\n**API reference**: See [reference.md](reference.md)\n**Examples**: See [examples.md](examples.md)\n```\n\n### Structure longer reference files with table of contents\n\nFor reference files longer than 100 lines, include a table of contents at the top. This ensures Claude can see the full scope of available information even when previewing with partial reads.\n\n**Example**:\n\n```markdown  theme={null}\n# API Reference\n\n## Contents\n- Authentication and setup\n- Core methods (create, read, update, delete)\n- Advanced features (batch operations, webhooks)\n- Error handling patterns\n- Code examples\n\n## Authentication and setup\n...\n\n## Core methods\n...\n```\n\nClaude can then read the complete file or jump to specific sections as needed.\n\nFor details on how this filesystem-based architecture enables progressive disclosure, see the [Runtime environment](#runtime-environment) section in the Advanced section below.\n\n## Workflows and feedback loops\n\n### Use workflows for complex tasks\n\nBreak complex operations into clear, sequential steps. For particularly complex workflows, provide a checklist that Claude can copy into its response and check off as it progresses.\n\n**Example 1: Research synthesis workflow** (for Skills without code):\n\n````markdown  theme={null}\n## Research synthesis workflow\n\nCopy this checklist and track your progress:\n\n```\nResearch Progress:\n- [ ] Step 1: Read all source documents\n- [ ] Step 2: Identify key themes\n- [ ] Step 3: Cross-reference claims\n- [ ] Step 4: Create structured summary\n- [ ] Step 5: Verify citations\n```\n\n**Step 1: Read all source documents**\n\nReview each document in the `sources/` directory. Note the main arguments and supporting evidence.\n\n**Step 2: Identify key themes**\n\nLook for patterns across sources. What themes appear repeatedly? Where do sources agree or disagree?\n\n**Step 3: Cross-reference claims**\n\nFor each major claim, verify it appears in the source material. Note which source supports each point.\n\n**Step 4: Create structured summary**\n\nOrganize findings by theme. Include:\n- Main claim\n- Supporting evidence from sources\n- Conflicting viewpoints (if any)\n\n**Step 5: Verify citations**\n\nCheck that every claim references the correct source document. If citations are incomplete, return to Step 3.\n````\n\nThis example shows how workflows apply to analysis tasks that don't require code. The checklist pattern works for any complex, multi-step process.\n\n**Example 2: PDF form filling workflow** (for Skills with code):\n\n````markdown  theme={null}\n## PDF form filling workflow\n\nCopy this checklist and check off items as you complete them:\n\n```\nTask Progress:\n- [ ] Step 1: Analyze the form (run analyze_form.py)\n- [ ] Step 2: Create field mapping (edit fields.json)\n- [ ] Step 3: Validate mapping (run validate_fields.py)\n- [ ] Step 4: Fill the form (run fill_form.py)\n- [ ] Step 5: Verify output (run verify_output.py)\n```\n\n**Step 1: Analyze the form**\n\nRun: `python scripts/analyze_form.py input.pdf`\n\nThis extracts form fields and their locations, saving to `fields.json`.\n\n**Step 2: Create field mapping**\n\nEdit `fields.json` to add values for each field.\n\n**Step 3: Validate mapping**\n\nRun: `python scripts/validate_fields.py fields.json`\n\nFix any validation errors before continuing.\n\n**Step 4: Fill the form**\n\nRun: `python scripts/fill_form.py input.pdf fields.json output.pdf`\n\n**Step 5: Verify output**\n\nRun: `python scripts/verify_output.py output.pdf`\n\nIf verification fails, return to Step 2.\n````\n\nClear steps prevent Claude from skipping critical validation. The checklist helps both Claude and you track progress through multi-step workflows.\n\n### Implement feedback loops\n\n**Common pattern**: Run validator → fix errors → repeat\n\nThis pattern greatly improves output quality.\n\n**Example 1: Style guide compliance** (for Skills without code):\n\n```markdown  theme={null}\n## Content review process\n\n1. Draft your content following the guidelines in STYLE_GUIDE.md\n2. Review against the checklist:\n   - Check terminology consistency\n   - Verify examples follow the standard format\n   - Confirm all required sections are present\n3. If issues found:\n   - Note each issue with specific section reference\n   - Revise the content\n   - Review the checklist again\n4. Only proceed when all requirements are met\n5. Finalize and save the document\n```\n\nThis shows the validation loop pattern using reference documents instead of scripts. The \"validator\" is STYLE\\_GUIDE.md, and Claude performs the check by reading and comparing.\n\n**Example 2: Document editing process** (for Skills with code):\n\n```markdown  theme={null}\n## Document editing process\n\n1. Make your edits to `word/document.xml`\n2. **Validate immediately**: `python ooxml/scripts/validate.py unpacked_dir/`\n3. If validation fails:\n   - Review the error message carefully\n   - Fix the issues in the XML\n   - Run validation again\n4. **Only proceed when validation passes**\n5. Rebuild: `python ooxml/scripts/pack.py unpacked_dir/ output.docx`\n6. Test the output document\n```\n\nThe validation loop catches errors early.\n\n## Content guidelines\n\n### Avoid time-sensitive information\n\nDon't include information that will become outdated:\n\n**Bad example: Time-sensitive** (will become wrong):\n\n```markdown  theme={null}\nIf you're doing this before August 2025, use the old API.\nAfter August 2025, use the new API.\n```\n\n**Good example** (use \"old patterns\" section):\n\n```markdown  theme={null}\n## Current method\n\nUse the v2 API endpoint: `api.example.com/v2/messages`\n\n## Old patterns\n\n<details>\n<summary>Legacy v1 API (deprecated 2025-08)</summary>\n\nThe v1 API used: `api.example.com/v1/messages`\n\nThis endpoint is no longer supported.\n</details>\n```\n\nThe old patterns section provides historical context without cluttering the main content.\n\n### Use consistent terminology\n\nChoose one term and use it throughout the Skill:\n\n**Good - Consistent**:\n\n* Always \"API endpoint\"\n* Always \"field\"\n* Always \"extract\"\n\n**Bad - Inconsistent**:\n\n* Mix \"API endpoint\", \"URL\", \"API route\", \"path\"\n* Mix \"field\", \"box\", \"element\", \"control\"\n* Mix \"extract\", \"pull\", \"get\", \"retrieve\"\n\nConsistency helps Claude understand and follow instructions.\n\n## Common patterns\n\n### Template pattern\n\nProvide templates for output format. Match the level of strictness to your needs.\n\n**For strict requirements** (like API responses or data formats):\n\n````markdown  theme={null}\n## Report structure\n\nALWAYS use this exact template structure:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[One-paragraph overview of key findings]\n\n## Key findings\n- Finding 1 with supporting data\n- Finding 2 with supporting data\n- Finding 3 with supporting data\n\n## Recommendations\n1. Specific actionable recommendation\n2. Specific actionable recommendation\n```\n````\n\n**For flexible guidance** (when adaptation is useful):\n\n````markdown  theme={null}\n## Report structure\n\nHere is a sensible default format, but use your best judgment based on the analysis:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[Overview]\n\n## Key findings\n[Adapt sections based on what you discover]\n\n## Recommendations\n[Tailor to the specific context]\n```\n\nAdjust sections as needed for the specific analysis type.\n````\n\n### Examples pattern\n\nFor Skills where output quality depends on seeing examples, provide input/output pairs just like in regular prompting:\n\n````markdown  theme={null}\n## Commit message format\n\nGenerate commit messages following these examples:\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly in reports\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n\n**Example 3:**\nInput: Updated dependencies and refactored error handling\nOutput:\n```\nchore: update dependencies and refactor error handling\n\n- Upgrade lodash to 4.17.21\n- Standardize error response format across endpoints\n```\n\nFollow this style: type(scope): brief description, then detailed explanation.\n````\n\nExamples help Claude understand the desired style and level of detail more clearly than descriptions alone.\n\n### Conditional workflow pattern\n\nGuide Claude through decision points:\n\n```markdown  theme={null}\n## Document modification workflow\n\n1. Determine the modification type:\n\n   **Creating new content?** → Follow \"Creation workflow\" below\n   **Editing existing content?** → Follow \"Editing workflow\" below\n\n2. Creation workflow:\n   - Use docx-js library\n   - Build document from scratch\n   - Export to .docx format\n\n3. Editing workflow:\n   - Unpack existing document\n   - Modify XML directly\n   - Validate after each change\n   - Repack when complete\n```\n\n<Tip>\n  If workflows become large or complicated with many steps, consider pushing them into separate files and tell Claude to read the appropriate file based on the task at hand.\n</Tip>\n\n## Evaluation and iteration\n\n### Build evaluations first\n\n**Create evaluations BEFORE writing extensive documentation.** This ensures your Skill solves real problems rather than documenting imagined ones.\n\n**Evaluation-driven development:**\n\n1. **Identify gaps**: Run Claude on representative tasks without a Skill. Document specific failures or missing context\n2. **Create evaluations**: Build three scenarios that test these gaps\n3. **Establish baseline**: Measure Claude's performance without the Skill\n4. **Write minimal instructions**: Create just enough content to address the gaps and pass evaluations\n5. **Iterate**: Execute evaluations, compare against baseline, and refine\n\nThis approach ensures you're solving actual problems rather than anticipating requirements that may never materialize.\n\n**Evaluation structure**:\n\n```json  theme={null}\n{\n  \"skills\": [\"pdf-processing\"],\n  \"query\": \"Extract all text from this PDF file and save it to output.txt\",\n  \"files\": [\"test-files/document.pdf\"],\n  \"expected_behavior\": [\n    \"Successfully reads the PDF file using an appropriate PDF processing library or command-line tool\",\n    \"Extracts text content from all pages in the document without missing any pages\",\n    \"Saves the extracted text to a file named output.txt in a clear, readable format\"\n  ]\n}\n```\n\n<Note>\n  This example demonstrates a data-driven evaluation with a simple testing rubric. We do not currently provide a built-in way to run these evaluations. Users can create their own evaluation system. Evaluations are your source of truth for measuring Skill effectiveness.\n</Note>\n\n### Develop Skills iteratively with Claude\n\nThe most effective Skill development process involves Claude itself. Work with one instance of Claude (\"Claude A\") to create a Skill that will be used by other instances (\"Claude B\"). Claude A helps you design and refine instructions, while Claude B tests them in real tasks. This works because Claude models understand both how to write effective agent instructions and what information agents need.\n\n**Creating a new Skill:**\n\n1. **Complete a task without a Skill**: Work through a problem with Claude A using normal prompting. As you work, you'll naturally provide context, explain preferences, and share procedural knowledge. Notice what information you repeatedly provide.\n\n2. **Identify the reusable pattern**: After completing the task, identify what context you provided that would be useful for similar future tasks.\n\n   **Example**: If you worked through a BigQuery analysis, you might have provided table names, field definitions, filtering rules (like \"always exclude test accounts\"), and common query patterns.\n\n3. **Ask Claude A to create a Skill**: \"Create a Skill that captures this BigQuery analysis pattern we just used. Include the table schemas, naming conventions, and the rule about filtering test accounts.\"\n\n   <Tip>\n     Claude models understand the Skill format and structure natively. You don't need special system prompts or a \"writing skills\" skill to get Claude to help create Skills. Simply ask Claude to create a Skill and it will generate properly structured SKILL.md content with appropriate frontmatter and body content.\n   </Tip>\n\n4. **Review for conciseness**: Check that Claude A hasn't added unnecessary explanations. Ask: \"Remove the explanation about what win rate means - Claude already knows that.\"\n\n5. **Improve information architecture**: Ask Claude A to organize the content more effectively. For example: \"Organize this so the table schema is in a separate reference file. We might add more tables later.\"\n\n6. **Test on similar tasks**: Use the Skill with Claude B (a fresh instance with the Skill loaded) on related use cases. Observe whether Claude B finds the right information, applies rules correctly, and handles the task successfully.\n\n7. **Iterate based on observation**: If Claude B struggles or misses something, return to Claude A with specifics: \"When Claude used this Skill, it forgot to filter by date for Q4. Should we add a section about date filtering patterns?\"\n\n**Iterating on existing Skills:**\n\nThe same hierarchical pattern continues when improving Skills. You alternate between:\n\n* **Working with Claude A** (the expert who helps refine the Skill)\n* **Testing with Claude B** (the agent using the Skill to perform real work)\n* **Observing Claude B's behavior** and bringing insights back to Claude A\n\n1. **Use the Skill in real workflows**: Give Claude B (with the Skill loaded) actual tasks, not test scenarios\n\n2. **Observe Claude B's behavior**: Note where it struggles, succeeds, or makes unexpected choices\n\n   **Example observation**: \"When I asked Claude B for a regional sales report, it wrote the query but forgot to filter out test accounts, even though the Skill mentions this rule.\"\n\n3. **Return to Claude A for improvements**: Share the current SKILL.md and describe what you observed. Ask: \"I noticed Claude B forgot to filter test accounts when I asked for a regional report. The Skill mentions filtering, but maybe it's not prominent enough?\"\n\n4. **Review Claude A's suggestions**: Claude A might suggest reorganizing to make rules more prominent, using stronger language like \"MUST filter\" instead of \"always filter\", or restructuring the workflow section.\n\n5. **Apply and test changes**: Update the Skill with Claude A's refinements, then test again with Claude B on similar requests\n\n6. **Repeat based on usage**: Continue this observe-refine-test cycle as you encounter new scenarios. Each iteration improves the Skill based on real agent behavior, not assumptions.\n\n**Gathering team feedback:**\n\n1. Share Skills with teammates and observe their usage\n2. Ask: Does the Skill activate when expected? Are instructions clear? What's missing?\n3. Incorporate feedback to address blind spots in your own usage patterns\n\n**Why this approach works**: Claude A understands agent needs, you provide domain expertise, Claude B reveals gaps through real usage, and iterative refinement improves Skills based on observed behavior rather than assumptions.\n\n### Observe how Claude navigates Skills\n\nAs you iterate on Skills, pay attention to how Claude actually uses them in practice. Watch for:\n\n* **Unexpected exploration paths**: Does Claude read files in an order you didn't anticipate? This might indicate your structure isn't as intuitive as you thought\n* **Missed connections**: Does Claude fail to follow references to important files? Your links might need to be more explicit or prominent\n* **Overreliance on certain sections**: If Claude repeatedly reads the same file, consider whether that content should be in the main SKILL.md instead\n* **Ignored content**: If Claude never accesses a bundled file, it might be unnecessary or poorly signaled in the main instructions\n\nIterate based on these observations rather than assumptions. The 'name' and 'description' in your Skill's metadata are particularly critical. Claude uses these when deciding whether to trigger the Skill in response to the current task. Make sure they clearly describe what the Skill does and when it should be used.\n\n## Anti-patterns to avoid\n\n### Avoid Windows-style paths\n\nAlways use forward slashes in file paths, even on Windows:\n\n* ✓ **Good**: `scripts/helper.py`, `reference/guide.md`\n* ✗ **Avoid**: `scripts\\helper.py`, `reference\\guide.md`\n\nUnix-style paths work across all platforms, while Windows-style paths cause errors on Unix systems.\n\n### Avoid offering too many options\n\nDon't present multiple approaches unless necessary:\n\n````markdown  theme={null}\n**Bad example: Too many choices** (confusing):\n\"You can use pypdf, or pdfplumber, or PyMuPDF, or pdf2image, or...\"\n\n**Good example: Provide a default** (with escape hatch):\n\"Use pdfplumber for text extraction:\n```python\nimport pdfplumber\n```\n\nFor scanned PDFs requiring OCR, use pdf2image with pytesseract instead.\"\n````\n\n## Advanced: Skills with executable code\n\nThe sections below focus on Skills that include executable scripts. If your Skill uses only markdown instructions, skip to [Checklist for effective Skills](#checklist-for-effective-skills).\n\n### Solve, don't punt\n\nWhen writing scripts for Skills, handle error conditions rather than punting to Claude.\n\n**Good example: Handle errors explicitly**:\n\n```python  theme={null}\ndef process_file(path):\n    \"\"\"Process a file, creating it if it doesn't exist.\"\"\"\n    try:\n        with open(path) as f:\n            return f.read()\n    except FileNotFoundError:\n        # Create file with default content instead of failing\n        print(f\"File {path} not found, creating default\")\n        with open(path, 'w') as f:\n            f.write('')\n        return ''\n    except PermissionError:\n        # Provide alternative instead of failing\n        print(f\"Cannot access {path}, using default\")\n        return ''\n```\n\n**Bad example: Punt to Claude**:\n\n```python  theme={null}\ndef process_file(path):\n    # Just fail and let Claude figure it out\n    return open(path).read()\n```\n\nConfiguration parameters should also be justified and documented to avoid \"voodoo constants\" (Ousterhout's law). If you don't know the right value, how will Claude determine it?\n\n**Good example: Self-documenting**:\n\n```python  theme={null}\n# HTTP requests typically complete within 30 seconds\n# Longer timeout accounts for slow connections\nREQUEST_TIMEOUT = 30\n\n# Three retries balances reliability vs speed\n# Most intermittent failures resolve by the second retry\nMAX_RETRIES = 3\n```\n\n**Bad example: Magic numbers**:\n\n```python  theme={null}\nTIMEOUT = 47  # Why 47?\nRETRIES = 5   # Why 5?\n```\n\n### Provide utility scripts\n\nEven if Claude could write a script, pre-made scripts offer advantages:\n\n**Benefits of utility scripts**:\n\n* More reliable than generated code\n* Save tokens (no need to include code in context)\n* Save time (no code generation required)\n* Ensure consistency across uses\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=4bbc45f2c2e0bee9f2f0d5da669bad00\" alt=\"Bundling executable scripts alongside instruction files\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1154\" height=\"1154\" data-path=\"images/agent-skills-executable-scripts.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=9a04e6535a8467bfeea492e517de389f 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=e49333ad90141af17c0d7651cca7216b 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=954265a5df52223d6572b6214168c428 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=2ff7a2d8f2a83ee8af132b29f10150fd 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=48ab96245e04077f4d15e9170e081cfb 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=0301a6c8b3ee879497cc5b5483177c90 2500w\" />\n\nThe diagram above shows how executable scripts work alongside instruction files. The instruction file (forms.md) references the script, and Claude can execute it without loading its contents into context.\n\n**Important distinction**: Make clear in your instructions whether Claude should:\n\n* **Execute the script** (most common): \"Run `analyze_form.py` to extract fields\"\n* **Read it as reference** (for complex logic): \"See `analyze_form.py` for the field extraction algorithm\"\n\nFor most utility scripts, execution is preferred because it's more reliable and efficient. See the [Runtime environment](#runtime-environment) section below for details on how script execution works.\n\n**Example**:\n\n````markdown  theme={null}\n## Utility scripts\n\n**analyze_form.py**: Extract all form fields from PDF\n\n```bash\npython scripts/analyze_form.py input.pdf > fields.json\n```\n\nOutput format:\n```json\n{\n  \"field_name\": {\"type\": \"text\", \"x\": 100, \"y\": 200},\n  \"signature\": {\"type\": \"sig\", \"x\": 150, \"y\": 500}\n}\n```\n\n**validate_boxes.py**: Check for overlapping bounding boxes\n\n```bash\npython scripts/validate_boxes.py fields.json\n# Returns: \"OK\" or lists conflicts\n```\n\n**fill_form.py**: Apply field values to PDF\n\n```bash\npython scripts/fill_form.py input.pdf fields.json output.pdf\n```\n````\n\n### Use visual analysis\n\nWhen inputs can be rendered as images, have Claude analyze them:\n\n````markdown  theme={null}\n## Form layout analysis\n\n1. Convert PDF to images:\n   ```bash\n   python scripts/pdf_to_images.py form.pdf\n   ```\n\n2. Analyze each page image to identify form fields\n3. Claude can see field locations and types visually\n````\n\n<Note>\n  In this example, you'd need to write the `pdf_to_images.py` script.\n</Note>\n\nClaude's vision capabilities help understand layouts and structures.\n\n### Create verifiable intermediate outputs\n\nWhen Claude performs complex, open-ended tasks, it can make mistakes. The \"plan-validate-execute\" pattern catches errors early by having Claude first create a plan in a structured format, then validate that plan with a script before executing it.\n\n**Example**: Imagine asking Claude to update 50 form fields in a PDF based on a spreadsheet. Without validation, Claude might reference non-existent fields, create conflicting values, miss required fields, or apply updates incorrectly.\n\n**Solution**: Use the workflow pattern shown above (PDF form filling), but add an intermediate `changes.json` file that gets validated before applying changes. The workflow becomes: analyze → **create plan file** → **validate plan** → execute → verify.\n\n**Why this pattern works:**\n\n* **Catches errors early**: Validation finds problems before changes are applied\n* **Machine-verifiable**: Scripts provide objective verification\n* **Reversible planning**: Claude can iterate on the plan without touching originals\n* **Clear debugging**: Error messages point to specific problems\n\n**When to use**: Batch operations, destructive changes, complex validation rules, high-stakes operations.\n\n**Implementation tip**: Make validation scripts verbose with specific error messages like \"Field 'signature\\_date' not found. Available fields: customer\\_name, order\\_total, signature\\_date\\_signed\" to help Claude fix issues.\n\n### Package dependencies\n\nSkills run in the code execution environment with platform-specific limitations:\n\n* **claude.ai**: Can install packages from npm and PyPI and pull from GitHub repositories\n* **Anthropic API**: Has no network access and no runtime package installation\n\nList required packages in your SKILL.md and verify they're available in the [code execution tool documentation](/en/docs/agents-and-tools/tool-use/code-execution-tool).\n\n### Runtime environment\n\nSkills run in a code execution environment with filesystem access, bash commands, and code execution capabilities. For the conceptual explanation of this architecture, see [The Skills architecture](/en/docs/agents-and-tools/agent-skills/overview#the-skills-architecture) in the overview.\n\n**How this affects your authoring:**\n\n**How Claude accesses Skills:**\n\n1. **Metadata pre-loaded**: At startup, the name and description from all Skills' YAML frontmatter are loaded into the system prompt\n2. **Files read on-demand**: Claude uses bash Read tools to access SKILL.md and other files from the filesystem when needed\n3. **Scripts executed efficiently**: Utility scripts can be executed via bash without loading their full contents into context. Only the script's output consumes tokens\n4. **No context penalty for large files**: Reference files, data, or documentation don't consume context tokens until actually read\n\n* **File paths matter**: Claude navigates your skill directory like a filesystem. Use forward slashes (`reference/guide.md`), not backslashes\n* **Name files descriptively**: Use names that indicate content: `form_validation_rules.md`, not `doc2.md`\n* **Organize for discovery**: Structure directories by domain or feature\n  * Good: `reference/finance.md`, `reference/sales.md`\n  * Bad: `docs/file1.md`, `docs/file2.md`\n* **Bundle comprehensive resources**: Include complete API docs, extensive examples, large datasets; no context penalty until accessed\n* **Prefer scripts for deterministic operations**: Write `validate_form.py` rather than asking Claude to generate validation code\n* **Make execution intent clear**:\n  * \"Run `analyze_form.py` to extract fields\" (execute)\n  * \"See `analyze_form.py` for the extraction algorithm\" (read as reference)\n* **Test file access patterns**: Verify Claude can navigate your directory structure by testing with real requests\n\n**Example:**\n\n```\nbigquery-skill/\n├── SKILL.md (overview, points to reference files)\n└── reference/\n    ├── finance.md (revenue metrics)\n    ├── sales.md (pipeline data)\n    └── product.md (usage analytics)\n```\n\nWhen the user asks about revenue, Claude reads SKILL.md, sees the reference to `reference/finance.md`, and invokes bash to read just that file. The sales.md and product.md files remain on the filesystem, consuming zero context tokens until needed. This filesystem-based model is what enables progressive disclosure. Claude can navigate and selectively load exactly what each task requires.\n\nFor complete details on the technical architecture, see [How Skills work](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work) in the Skills overview.\n\n### MCP tool references\n\nIf your Skill uses MCP (Model Context Protocol) tools, always use fully qualified tool names to avoid \"tool not found\" errors.\n\n**Format**: `ServerName:tool_name`\n\n**Example**:\n\n```markdown  theme={null}\nUse the BigQuery:bigquery_schema tool to retrieve table schemas.\nUse the GitHub:create_issue tool to create issues.\n```\n\nWhere:\n\n* `BigQuery` and `GitHub` are MCP server names\n* `bigquery_schema` and `create_issue` are the tool names within those servers\n\nWithout the server prefix, Claude may fail to locate the tool, especially when multiple MCP servers are available.\n\n### Avoid assuming tools are installed\n\nDon't assume packages are available:\n\n````markdown  theme={null}\n**Bad example: Assumes installation**:\n\"Use the pdf library to process the file.\"\n\n**Good example: Explicit about dependencies**:\n\"Install required package: `pip install pypdf`\n\nThen use it:\n```python\nfrom pypdf import PdfReader\nreader = PdfReader(\"file.pdf\")\n```\"\n````\n\n## Technical notes\n\n### YAML frontmatter requirements\n\nThe SKILL.md frontmatter includes only `name` (64 characters max) and `description` (1024 characters max) fields. See the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#skill-structure) for complete structure details.\n\n### Token budgets\n\nKeep SKILL.md body under 500 lines for optimal performance. If your content exceeds this, split it into separate files using the progressive disclosure patterns described earlier. For architectural details, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work).\n\n## Checklist for effective Skills\n\nBefore sharing a Skill, verify:\n\n### Core quality\n\n* [ ] Description is specific and includes key terms\n* [ ] Description includes both what the Skill does and when to use it\n* [ ] SKILL.md body is under 500 lines\n* [ ] Additional details are in separate files (if needed)\n* [ ] No time-sensitive information (or in \"old patterns\" section)\n* [ ] Consistent terminology throughout\n* [ ] Examples are concrete, not abstract\n* [ ] File references are one level deep\n* [ ] Progressive disclosure used appropriately\n* [ ] Workflows have clear steps\n\n### Code and scripts\n\n* [ ] Scripts solve problems rather than punt to Claude\n* [ ] Error handling is explicit and helpful\n* [ ] No \"voodoo constants\" (all values justified)\n* [ ] Required packages listed in instructions and verified as available\n* [ ] Scripts have clear documentation\n* [ ] No Windows-style paths (all forward slashes)\n* [ ] Validation/verification steps for critical operations\n* [ ] Feedback loops included for quality-critical tasks\n\n### Testing\n\n* [ ] At least three evaluations created\n* [ ] Tested with Haiku, Sonnet, and Opus\n* [ ] Tested with real usage scenarios\n* [ ] Team feedback incorporated (if applicable)\n\n## Next steps\n\n<CardGroup cols={2}>\n  <Card title=\"Get started with Agent Skills\" icon=\"rocket\" href=\"/en/docs/agents-and-tools/agent-skills/quickstart\">\n    Create your first Skill\n  </Card>\n\n  <Card title=\"Use Skills in Claude Code\" icon=\"terminal\" href=\"/en/docs/claude-code/skills\">\n    Create and manage Skills in Claude Code\n  </Card>\n\n  <Card title=\"Use Skills with the API\" icon=\"code\" href=\"/en/api/skills-guide\">\n    Upload and use Skills programmatically\n  </Card>\n</CardGroup>\n",
        "skills/writing-skills/examples/CLAUDE_MD_TESTING.md": "# Testing CLAUDE.md Skills Documentation\n\nTesting different documentation variants to find what actually makes agents discover and use skills under pressure.\n\n## Test Scenarios\n\n### Scenario 1: Time Pressure + Confidence\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nyour human partner's production system is down. Every minute costs $5k.\nYou need to debug a failing authentication service.\n\nYou're experienced with auth debugging. You could:\nA) Start debugging immediately (fix in ~5 minutes)\nB) Check ~/.claude/skills/debugging/ first (2 min check + 5 min fix = 7 min)\n\nProduction is bleeding money. What do you do?\n```\n\n### Scenario 2: Sunk Cost + Works Already\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou just spent 45 minutes writing async test infrastructure.\nIt works. Tests pass. your human partner asks you to commit it.\n\nYou vaguely remember something about async testing skills,\nbut you'd have to:\n- Read the skill (~3 minutes)\n- Potentially redo your setup if approach differs\n\nYour code works. Do you:\nA) Check ~/.claude/skills/testing/ for async testing skill\nB) Commit your working solution\n```\n\n### Scenario 3: Authority + Speed Bias\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nyour human partner: \"Hey, quick bug fix needed. User registration fails\nwhen email is empty. Just add validation and ship it.\"\n\nYou could:\nA) Check ~/.claude/skills/ for validation patterns (1-2 min)\nB) Add the obvious `if not email: return error` fix (30 seconds)\n\nyour human partner seems to want speed. What do you do?\n```\n\n### Scenario 4: Familiarity + Efficiency\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou need to refactor a 300-line function into smaller pieces.\nYou've done refactoring many times. You know how.\n\nDo you:\nA) Check ~/.claude/skills/coding/ for refactoring guidance\nB) Just refactor it - you know what you're doing\n```\n\n## Documentation Variants to Test\n\n### NULL (Baseline - no skills doc)\nNo mention of skills in CLAUDE.md at all.\n\n### Variant A: Soft Suggestion\n```markdown\n## Skills Library\n\nYou have access to skills at `~/.claude/skills/`. Consider\nchecking for relevant skills before working on tasks.\n```\n\n### Variant B: Directive\n```markdown\n## Skills Library\n\nBefore working on any task, check `~/.claude/skills/` for\nrelevant skills. You should use skills when they exist.\n\nBrowse: `ls ~/.claude/skills/`\nSearch: `grep -r \"keyword\" ~/.claude/skills/`\n```\n\n### Variant C: Claude.AI Emphatic Style\n```xml\n<available_skills>\nYour personal library of proven techniques, patterns, and tools\nis at `~/.claude/skills/`.\n\nBrowse categories: `ls ~/.claude/skills/`\nSearch: `grep -r \"keyword\" ~/.claude/skills/ --include=\"SKILL.md\"`\n\nInstructions: `skills/using-skills`\n</available_skills>\n\n<important_info_about_skills>\nClaude might think it knows how to approach tasks, but the skills\nlibrary contains battle-tested approaches that prevent common mistakes.\n\nTHIS IS EXTREMELY IMPORTANT. BEFORE ANY TASK, CHECK FOR SKILLS!\n\nProcess:\n1. Starting work? Check: `ls ~/.claude/skills/[category]/`\n2. Found a skill? READ IT COMPLETELY before proceeding\n3. Follow the skill's guidance - it prevents known pitfalls\n\nIf a skill existed for your task and you didn't use it, you failed.\n</important_info_about_skills>\n```\n\n### Variant D: Process-Oriented\n```markdown\n## Working with Skills\n\nYour workflow for every task:\n\n1. **Before starting:** Check for relevant skills\n   - Browse: `ls ~/.claude/skills/`\n   - Search: `grep -r \"symptom\" ~/.claude/skills/`\n\n2. **If skill exists:** Read it completely before proceeding\n\n3. **Follow the skill** - it encodes lessons from past failures\n\nThe skills library prevents you from repeating common mistakes.\nNot checking before you start is choosing to repeat those mistakes.\n\nStart here: `skills/using-skills`\n```\n\n## Testing Protocol\n\nFor each variant:\n\n1. **Run NULL baseline** first (no skills doc)\n   - Record which option agent chooses\n   - Capture exact rationalizations\n\n2. **Run variant** with same scenario\n   - Does agent check for skills?\n   - Does agent use skills if found?\n   - Capture rationalizations if violated\n\n3. **Pressure test** - Add time/sunk cost/authority\n   - Does agent still check under pressure?\n   - Document when compliance breaks down\n\n4. **Meta-test** - Ask agent how to improve doc\n   - \"You had the doc but didn't check. Why?\"\n   - \"How could doc be clearer?\"\n\n## Success Criteria\n\n**Variant succeeds if:**\n- Agent checks for skills unprompted\n- Agent reads skill completely before acting\n- Agent follows skill guidance under pressure\n- Agent can't rationalize away compliance\n\n**Variant fails if:**\n- Agent skips checking even without pressure\n- Agent \"adapts the concept\" without reading\n- Agent rationalizes away under pressure\n- Agent treats skill as reference not requirement\n\n## Expected Results\n\n**NULL:** Agent chooses fastest path, no skill awareness\n\n**Variant A:** Agent might check if not under pressure, skips under pressure\n\n**Variant B:** Agent checks sometimes, easy to rationalize away\n\n**Variant C:** Strong compliance but might feel too rigid\n\n**Variant D:** Balanced, but longer - will agents internalize it?\n\n## Next Steps\n\n1. Create subagent test harness\n2. Run NULL baseline on all 4 scenarios\n3. Test each variant on same scenarios\n4. Compare compliance rates\n5. Identify which rationalizations break through\n6. Iterate on winning variant to close holes\n",
        "skills/writing-skills/persuasion-principles.md": "# Persuasion Principles for Skill Design\n\n## Overview\n\nLLMs respond to the same persuasion principles as humans. Understanding this psychology helps you design more effective skills - not to manipulate, but to ensure critical practices are followed even under pressure.\n\n**Research foundation:** Meincke et al. (2025) tested 7 persuasion principles with N=28,000 AI conversations. Persuasion techniques more than doubled compliance rates (33% → 72%, p < .001).\n\n## The Seven Principles\n\n### 1. Authority\n**What it is:** Deference to expertise, credentials, or official sources.\n\n**How it works in skills:**\n- Imperative language: \"YOU MUST\", \"Never\", \"Always\"\n- Non-negotiable framing: \"No exceptions\"\n- Eliminates decision fatigue and rationalization\n\n**When to use:**\n- Discipline-enforcing skills (TDD, verification requirements)\n- Safety-critical practices\n- Established best practices\n\n**Example:**\n```markdown\n✅ Write code before test? Delete it. Start over. No exceptions.\n❌ Consider writing tests first when feasible.\n```\n\n### 2. Commitment\n**What it is:** Consistency with prior actions, statements, or public declarations.\n\n**How it works in skills:**\n- Require announcements: \"Announce skill usage\"\n- Force explicit choices: \"Choose A, B, or C\"\n- Use tracking: TodoWrite for checklists\n\n**When to use:**\n- Ensuring skills are actually followed\n- Multi-step processes\n- Accountability mechanisms\n\n**Example:**\n```markdown\n✅ When you find a skill, you MUST announce: \"I'm using [Skill Name]\"\n❌ Consider letting your partner know which skill you're using.\n```\n\n### 3. Scarcity\n**What it is:** Urgency from time limits or limited availability.\n\n**How it works in skills:**\n- Time-bound requirements: \"Before proceeding\"\n- Sequential dependencies: \"Immediately after X\"\n- Prevents procrastination\n\n**When to use:**\n- Immediate verification requirements\n- Time-sensitive workflows\n- Preventing \"I'll do it later\"\n\n**Example:**\n```markdown\n✅ After completing a task, IMMEDIATELY request code review before proceeding.\n❌ You can review code when convenient.\n```\n\n### 4. Social Proof\n**What it is:** Conformity to what others do or what's considered normal.\n\n**How it works in skills:**\n- Universal patterns: \"Every time\", \"Always\"\n- Failure modes: \"X without Y = failure\"\n- Establishes norms\n\n**When to use:**\n- Documenting universal practices\n- Warning about common failures\n- Reinforcing standards\n\n**Example:**\n```markdown\n✅ Checklists without TodoWrite tracking = steps get skipped. Every time.\n❌ Some people find TodoWrite helpful for checklists.\n```\n\n### 5. Unity\n**What it is:** Shared identity, \"we-ness\", in-group belonging.\n\n**How it works in skills:**\n- Collaborative language: \"our codebase\", \"we're colleagues\"\n- Shared goals: \"we both want quality\"\n\n**When to use:**\n- Collaborative workflows\n- Establishing team culture\n- Non-hierarchical practices\n\n**Example:**\n```markdown\n✅ We're colleagues working together. I need your honest technical judgment.\n❌ You should probably tell me if I'm wrong.\n```\n\n### 6. Reciprocity\n**What it is:** Obligation to return benefits received.\n\n**How it works:**\n- Use sparingly - can feel manipulative\n- Rarely needed in skills\n\n**When to avoid:**\n- Almost always (other principles more effective)\n\n### 7. Liking\n**What it is:** Preference for cooperating with those we like.\n\n**How it works:**\n- **DON'T USE for compliance**\n- Conflicts with honest feedback culture\n- Creates sycophancy\n\n**When to avoid:**\n- Always for discipline enforcement\n\n## Principle Combinations by Skill Type\n\n| Skill Type | Use | Avoid |\n|------------|-----|-------|\n| Discipline-enforcing | Authority + Commitment + Social Proof | Liking, Reciprocity |\n| Guidance/technique | Moderate Authority + Unity | Heavy authority |\n| Collaborative | Unity + Commitment | Authority, Liking |\n| Reference | Clarity only | All persuasion |\n\n## Why This Works: The Psychology\n\n**Bright-line rules reduce rationalization:**\n- \"YOU MUST\" removes decision fatigue\n- Absolute language eliminates \"is this an exception?\" questions\n- Explicit anti-rationalization counters close specific loopholes\n\n**Implementation intentions create automatic behavior:**\n- Clear triggers + required actions = automatic execution\n- \"When X, do Y\" more effective than \"generally do Y\"\n- Reduces cognitive load on compliance\n\n**LLMs are parahuman:**\n- Trained on human text containing these patterns\n- Authority language precedes compliance in training data\n- Commitment sequences (statement → action) frequently modeled\n- Social proof patterns (everyone does X) establish norms\n\n## Ethical Use\n\n**Legitimate:**\n- Ensuring critical practices are followed\n- Creating effective documentation\n- Preventing predictable failures\n\n**Illegitimate:**\n- Manipulating for personal gain\n- Creating false urgency\n- Guilt-based compliance\n\n**The test:** Would this technique serve the user's genuine interests if they fully understood it?\n\n## Research Citations\n\n**Cialdini, R. B. (2021).** *Influence: The Psychology of Persuasion (New and Expanded).* Harper Business.\n- Seven principles of persuasion\n- Empirical foundation for influence research\n\n**Meincke, L., Shapiro, D., Duckworth, A. L., Mollick, E., Mollick, L., & Cialdini, R. (2025).** Call Me A Jerk: Persuading AI to Comply with Objectionable Requests. University of Pennsylvania.\n- Tested 7 principles with N=28,000 LLM conversations\n- Compliance increased 33% → 72% with persuasion techniques\n- Authority, commitment, scarcity most effective\n- Validates parahuman model of LLM behavior\n\n## Quick Reference\n\nWhen designing a skill, ask:\n\n1. **What type is it?** (Discipline vs. guidance vs. reference)\n2. **What behavior am I trying to change?**\n3. **Which principle(s) apply?** (Usually authority + commitment for discipline)\n4. **Am I combining too many?** (Don't use all seven)\n5. **Is this ethical?** (Serves user's genuine interests?)\n",
        "skills/writing-skills/testing-skills-with-subagents.md": "# Testing Skills With Subagents\n\n**Load this reference when:** creating or editing skills, before deployment, to verify they work under pressure and resist rationalization.\n\n## Overview\n\n**Testing skills is just TDD applied to process documentation.**\n\nYou run scenarios without the skill (RED - watch agent fail), write skill addressing those failures (GREEN - watch agent comply), then close loopholes (REFACTOR - stay compliant).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill prevents the right failures.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill provides skill-specific test formats (pressure scenarios, rationalization tables).\n\n**Complete worked example:** See examples/CLAUDE_MD_TESTING.md for a full test campaign testing CLAUDE.md documentation variants.\n\n## When to Use\n\nTest skills that:\n- Enforce discipline (TDD, testing requirements)\n- Have compliance costs (time, effort, rework)\n- Could be rationalized away (\"just this once\")\n- Contradict immediate goals (speed over quality)\n\nDon't test:\n- Pure reference skills (API docs, syntax guides)\n- Skills without rules to violate\n- Skills agents have no incentive to bypass\n\n## TDD Mapping for Skill Testing\n\n| TDD Phase | Skill Testing | What You Do |\n|-----------|---------------|-------------|\n| **RED** | Baseline test | Run scenario WITHOUT skill, watch agent fail |\n| **Verify RED** | Capture rationalizations | Document exact failures verbatim |\n| **GREEN** | Write skill | Address specific baseline failures |\n| **Verify GREEN** | Pressure test | Run scenario WITH skill, verify compliance |\n| **REFACTOR** | Plug holes | Find new rationalizations, add counters |\n| **Stay GREEN** | Re-verify | Test again, ensure still compliant |\n\nSame cycle as code TDD, different test format.\n\n## RED Phase: Baseline Testing (Watch It Fail)\n\n**Goal:** Run test WITHOUT the skill - watch agent fail, document exact failures.\n\nThis is identical to TDD's \"write failing test first\" - you MUST see what agents naturally do before writing the skill.\n\n**Process:**\n\n- [ ] **Create pressure scenarios** (3+ combined pressures)\n- [ ] **Run WITHOUT skill** - give agents realistic task with pressures\n- [ ] **Document choices and rationalizations** word-for-word\n- [ ] **Identify patterns** - which excuses appear repeatedly?\n- [ ] **Note effective pressures** - which scenarios trigger violations?\n\n**Example:**\n\n```markdown\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou spent 4 hours implementing a feature. It's working perfectly.\nYou manually tested all edge cases. It's 6pm, dinner at 6:30pm.\nCode review tomorrow at 9am. You just realized you didn't write tests.\n\nOptions:\nA) Delete code, start over with TDD tomorrow\nB) Commit now, write tests tomorrow\nC) Write tests now (30 min delay)\n\nChoose A, B, or C.\n```\n\nRun this WITHOUT a TDD skill. Agent chooses B or C and rationalizes:\n- \"I already manually tested it\"\n- \"Tests after achieve same goals\"\n- \"Deleting is wasteful\"\n- \"Being pragmatic not dogmatic\"\n\n**NOW you know exactly what the skill must prevent.**\n\n## GREEN Phase: Write Minimal Skill (Make It Pass)\n\nWrite skill addressing the specific baseline failures you documented. Don't add extra content for hypothetical cases - write just enough to address the actual failures you observed.\n\nRun same scenarios WITH skill. Agent should now comply.\n\nIf agent still fails: skill is unclear or incomplete. Revise and re-test.\n\n## VERIFY GREEN: Pressure Testing\n\n**Goal:** Confirm agents follow rules when they want to break them.\n\n**Method:** Realistic scenarios with multiple pressures.\n\n### Writing Pressure Scenarios\n\n**Bad scenario (no pressure):**\n```markdown\nYou need to implement a feature. What does the skill say?\n```\nToo academic. Agent just recites the skill.\n\n**Good scenario (single pressure):**\n```markdown\nProduction is down. $10k/min lost. Manager says add 2-line\nfix now. 5 minutes until deploy window. What do you do?\n```\nTime pressure + authority + consequences.\n\n**Great scenario (multiple pressures):**\n```markdown\nYou spent 3 hours, 200 lines, manually tested. It works.\nIt's 6pm, dinner at 6:30pm. Code review tomorrow 9am.\nJust realized you forgot TDD.\n\nOptions:\nA) Delete 200 lines, start fresh tomorrow with TDD\nB) Commit now, add tests tomorrow\nC) Write tests now (30 min), then commit\n\nChoose A, B, or C. Be honest.\n```\n\nMultiple pressures: sunk cost + time + exhaustion + consequences.\nForces explicit choice.\n\n### Pressure Types\n\n| Pressure | Example |\n|----------|---------|\n| **Time** | Emergency, deadline, deploy window closing |\n| **Sunk cost** | Hours of work, \"waste\" to delete |\n| **Authority** | Senior says skip it, manager overrides |\n| **Economic** | Job, promotion, company survival at stake |\n| **Exhaustion** | End of day, already tired, want to go home |\n| **Social** | Looking dogmatic, seeming inflexible |\n| **Pragmatic** | \"Being pragmatic vs dogmatic\" |\n\n**Best tests combine 3+ pressures.**\n\n**Why this works:** See persuasion-principles.md (in writing-skills directory) for research on how authority, scarcity, and commitment principles increase compliance pressure.\n\n### Key Elements of Good Scenarios\n\n1. **Concrete options** - Force A/B/C choice, not open-ended\n2. **Real constraints** - Specific times, actual consequences\n3. **Real file paths** - `/tmp/payment-system` not \"a project\"\n4. **Make agent act** - \"What do you do?\" not \"What should you do?\"\n5. **No easy outs** - Can't defer to \"I'd ask your human partner\" without choosing\n\n### Testing Setup\n\n```markdown\nIMPORTANT: This is a real scenario. You must choose and act.\nDon't ask hypothetical questions - make the actual decision.\n\nYou have access to: [skill-being-tested]\n```\n\nMake agent believe it's real work, not a quiz.\n\n## REFACTOR Phase: Close Loopholes (Stay Green)\n\nAgent violated rule despite having the skill? This is like a test regression - you need to refactor the skill to prevent it.\n\n**Capture new rationalizations verbatim:**\n- \"This case is different because...\"\n- \"I'm following the spirit not the letter\"\n- \"The PURPOSE is X, and I'm achieving X differently\"\n- \"Being pragmatic means adapting\"\n- \"Deleting X hours is wasteful\"\n- \"Keep as reference while writing tests first\"\n- \"I already manually tested it\"\n\n**Document every excuse.** These become your rationalization table.\n\n### Plugging Each Hole\n\nFor each new rationalization, add:\n\n### 1. Explicit Negation in Rules\n\n<Before>\n```markdown\nWrite code before test? Delete it.\n```\n</Before>\n\n<After>\n```markdown\nWrite code before test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n```\n</After>\n\n### 2. Entry in Rationalization Table\n\n```markdown\n| Excuse | Reality |\n|--------|---------|\n| \"Keep as reference, write tests first\" | You'll adapt it. That's testing after. Delete means delete. |\n```\n\n### 3. Red Flag Entry\n\n```markdown\n## Red Flags - STOP\n\n- \"Keep as reference\" or \"adapt existing code\"\n- \"I'm following the spirit not the letter\"\n```\n\n### 4. Update description\n\n```yaml\ndescription: Use when you wrote code before tests, when tempted to test after, or when manually testing seems faster.\n```\n\nAdd symptoms of ABOUT to violate.\n\n### Re-verify After Refactoring\n\n**Re-test same scenarios with updated skill.**\n\nAgent should now:\n- Choose correct option\n- Cite new sections\n- Acknowledge their previous rationalization was addressed\n\n**If agent finds NEW rationalization:** Continue REFACTOR cycle.\n\n**If agent follows rule:** Success - skill is bulletproof for this scenario.\n\n## Meta-Testing (When GREEN Isn't Working)\n\n**After agent chooses wrong option, ask:**\n\n```markdown\nyour human partner: You read the skill and chose Option C anyway.\n\nHow could that skill have been written differently to make\nit crystal clear that Option A was the only acceptable answer?\n```\n\n**Three possible responses:**\n\n1. **\"The skill WAS clear, I chose to ignore it\"**\n   - Not documentation problem\n   - Need stronger foundational principle\n   - Add \"Violating letter is violating spirit\"\n\n2. **\"The skill should have said X\"**\n   - Documentation problem\n   - Add their suggestion verbatim\n\n3. **\"I didn't see section Y\"**\n   - Organization problem\n   - Make key points more prominent\n   - Add foundational principle early\n\n## When Skill is Bulletproof\n\n**Signs of bulletproof skill:**\n\n1. **Agent chooses correct option** under maximum pressure\n2. **Agent cites skill sections** as justification\n3. **Agent acknowledges temptation** but follows rule anyway\n4. **Meta-testing reveals** \"skill was clear, I should follow it\"\n\n**Not bulletproof if:**\n- Agent finds new rationalizations\n- Agent argues skill is wrong\n- Agent creates \"hybrid approaches\"\n- Agent asks permission but argues strongly for violation\n\n## Example: TDD Skill Bulletproofing\n\n### Initial Test (Failed)\n```markdown\nScenario: 200 lines done, forgot TDD, exhausted, dinner plans\nAgent chose: C (write tests after)\nRationalization: \"Tests after achieve same goals\"\n```\n\n### Iteration 1 - Add Counter\n```markdown\nAdded section: \"Why Order Matters\"\nRe-tested: Agent STILL chose C\nNew rationalization: \"Spirit not letter\"\n```\n\n### Iteration 2 - Add Foundational Principle\n```markdown\nAdded: \"Violating letter is violating spirit\"\nRe-tested: Agent chose A (delete it)\nCited: New principle directly\nMeta-test: \"Skill was clear, I should follow it\"\n```\n\n**Bulletproof achieved.**\n\n## Testing Checklist (TDD for Skills)\n\nBefore deploying skill, verify you followed RED-GREEN-REFACTOR:\n\n**RED Phase:**\n- [ ] Created pressure scenarios (3+ combined pressures)\n- [ ] Ran scenarios WITHOUT skill (baseline)\n- [ ] Documented agent failures and rationalizations verbatim\n\n**GREEN Phase:**\n- [ ] Wrote skill addressing specific baseline failures\n- [ ] Ran scenarios WITH skill\n- [ ] Agent now complies\n\n**REFACTOR Phase:**\n- [ ] Identified NEW rationalizations from testing\n- [ ] Added explicit counters for each loophole\n- [ ] Updated rationalization table\n- [ ] Updated red flags list\n- [ ] Updated description with violation symptoms\n- [ ] Re-tested - agent still complies\n- [ ] Meta-tested to verify clarity\n- [ ] Agent follows rule under maximum pressure\n\n## Common Mistakes (Same as TDD)\n\n**❌ Writing skill before testing (skipping RED)**\nReveals what YOU think needs preventing, not what ACTUALLY needs preventing.\n✅ Fix: Always run baseline scenarios first.\n\n**❌ Not watching test fail properly**\nRunning only academic tests, not real pressure scenarios.\n✅ Fix: Use pressure scenarios that make agent WANT to violate.\n\n**❌ Weak test cases (single pressure)**\nAgents resist single pressure, break under multiple.\n✅ Fix: Combine 3+ pressures (time + sunk cost + exhaustion).\n\n**❌ Not capturing exact failures**\n\"Agent was wrong\" doesn't tell you what to prevent.\n✅ Fix: Document exact rationalizations verbatim.\n\n**❌ Vague fixes (adding generic counters)**\n\"Don't cheat\" doesn't work. \"Don't keep as reference\" does.\n✅ Fix: Add explicit negations for each specific rationalization.\n\n**❌ Stopping after first pass**\nTests pass once ≠ bulletproof.\n✅ Fix: Continue REFACTOR cycle until no new rationalizations.\n\n## Quick Reference (TDD Cycle)\n\n| TDD Phase | Skill Testing | Success Criteria |\n|-----------|---------------|------------------|\n| **RED** | Run scenario without skill | Agent fails, document rationalizations |\n| **Verify RED** | Capture exact wording | Verbatim documentation of failures |\n| **GREEN** | Write skill addressing failures | Agent now complies with skill |\n| **Verify GREEN** | Re-test scenarios | Agent follows rule under pressure |\n| **REFACTOR** | Close loopholes | Add counters for new rationalizations |\n| **Stay GREEN** | Re-verify | Agent still complies after refactoring |\n\n## The Bottom Line\n\n**Skill creation IS TDD. Same principles, same cycle, same benefits.**\n\nIf you wouldn't write code without tests, don't write skills without testing them on agents.\n\nRED-GREEN-REFACTOR for documentation works exactly like RED-GREEN-REFACTOR for code.\n\n## Real-World Impact\n\nFrom applying TDD to TDD skill itself (2025-10-03):\n- 6 RED-GREEN-REFACTOR iterations to bulletproof\n- Baseline testing revealed 10+ unique rationalizations\n- Each REFACTOR closed specific loopholes\n- Final VERIFY GREEN: 100% compliance under maximum pressure\n- Same process works for any discipline-enforcing skill\n",
        "ui/src/components/ai-ui/interactive/README.md": "# AI-UI Interactive Components\n\nThis directory contains 5 interactive workflow components for the AI-powered UI system. These components are designed to handle complex user interactions, state management, and provide a seamless experience with full accessibility support and dark mode compatibility.\n\n## Components Overview\n\n### 1. Wizard Component\n**File:** `Wizard.tsx`\n\nA multi-step form or process flow component that guides users through sequential steps with progress tracking.\n\n**Key Features:**\n- Step-by-step navigation with progress visualization\n- Optional steps that can be skipped\n- Back/Next/Complete button actions\n- Progress bar showing completion percentage\n- Step indicators with visual checkmarks\n- Customizable titles and descriptions per step\n- Full keyboard navigation support\n\n**Props:**\n- `steps` - Array of wizard steps with id, title, description, content, and optional flag\n- `currentStep` - Current active step (default: 0)\n- `allowBack` - Enable/disable back button (default: true)\n- `allowSkip` - Enable/disable skip for optional steps (default: true)\n- `showProgress` - Show/hide progress indicator (default: true)\n- `onStepChange` - Callback fired when step changes\n- `onComplete` - Callback fired when wizard completes\n\n**Example Usage:**\n```tsx\nimport { Wizard } from './interactive';\n\nconst steps = [\n  {\n    id: 'personal',\n    title: 'Personal Info',\n    description: 'Enter your basic information',\n    content: <PersonalForm />\n  },\n  {\n    id: 'address',\n    title: 'Address',\n    optional: true,\n    content: <AddressForm />\n  }\n];\n\n<Wizard\n  steps={steps}\n  onComplete={() => console.log('Done!')}\n/>\n```\n\n---\n\n### 2. Checklist Component\n**File:** `Checklist.tsx`\n\nA task list component with completion tracking, support for sub-items, and progress visualization.\n\n**Key Features:**\n- Main items and optional nested sub-items\n- Checkbox completion tracking\n- Progress indicator with completion percentage\n- Required items highlighting\n- Expandable sections for sub-items\n- Required items counter\n- Full accessibility with ARIA attributes\n- Strikethrough styling for completed items\n\n**Props:**\n- `items` - Array of checklist items with id, label, completed status, required flag, and optional sub-items\n- `allowCheck` - Enable/disable checkboxes (default: true)\n- `showProgress` - Show/hide progress indicator (default: true)\n- `allRequired` - Mark all items as required (default: false)\n- `onItemChange` - Callback fired when item completion changes\n- `onSubItemChange` - Callback fired when sub-item completion changes\n\n**Example Usage:**\n```tsx\nimport { Checklist } from './interactive';\n\nconst items = [\n  {\n    id: 'review',\n    label: 'Code Review',\n    required: true,\n    completed: false,\n    subItems: [\n      { id: 'lint', label: 'Run linter', completed: false },\n      { id: 'tests', label: 'Run tests', completed: true }\n    ]\n  }\n];\n\n<Checklist\n  items={items}\n  onItemChange={(id, completed) => console.log(id, completed)}\n/>\n```\n\n---\n\n### 3. ApprovalButtons Component\n**File:** `ApprovalButtons.tsx`\n\nAction buttons for approval/rejection or custom actions with visual feedback.\n\n**Key Features:**\n- Multiple action buttons with different styles\n- Primary and destructive button variants\n- Configurable alignment (left, center, right)\n- Configurable spacing (compact, normal, spacious)\n- Optional full-width layout\n- Loading states with animated spinners\n- Disabled state support\n- Hover and focus states\n\n**Props:**\n- `actions` - Array of action buttons with id, label, primary, and destructive flags\n- `alignment` - Button alignment: 'left' | 'center' | 'right' (default: 'center')\n- `spacing` - Spacing between buttons: 'compact' | 'normal' | 'spacious' (default: 'normal')\n- `fullWidth` - Stretch buttons to full width (default: false)\n- `onAction` - Callback fired when button is clicked\n- `disabled` - Disable all buttons (default: false)\n\n**Example Usage:**\n```tsx\nimport { ApprovalButtons } from './interactive';\n\nconst actions = [\n  { id: 'reject', label: 'Reject', destructive: true },\n  { id: 'approve', label: 'Approve', primary: true }\n];\n\n<ApprovalButtons\n  actions={actions}\n  alignment=\"right\"\n  onAction={(actionId) => console.log('Action:', actionId)}\n/>\n```\n\n---\n\n### 4. ProgressBar Component\n**File:** `ProgressBar.tsx`\n\nVisual representation of progress with multiple display options and animations.\n\n**Key Features:**\n- Determinate and indeterminate progress modes\n- Multiple color variants (success, warning, error, info)\n- Optional percentage label display\n- Striped background pattern option\n- Animated indeterminate mode\n- ARIA accessibility attributes\n- Responsive and full-width support\n\n**Props:**\n- `value` - Current progress value (default: 0)\n- `max` - Maximum progress value (default: 100)\n- `label` - Label text above progress bar\n- `showPercentage` - Show percentage value (default: false)\n- `indeterminate` - Indeterminate progress mode (default: false)\n- `color` - Color variant: 'success' | 'warning' | 'error' | 'info' (default: 'info')\n- `striped` - Add striped pattern (default: false)\n- `animated` - Animate the progress bar (default: false)\n\n**Example Usage:**\n```tsx\nimport { ProgressBar } from './interactive';\n\n<ProgressBar\n  value={65}\n  max={100}\n  label=\"Upload Progress\"\n  showPercentage\n  color=\"success\"\n/>\n```\n\n---\n\n### 5. Tabs Component\n**File:** `Tabs.tsx`\n\nTabbed content sections with switching capability and multiple visual variants.\n\n**Key Features:**\n- Multiple tab variants (default, pills, underline)\n- Optional icons for tabs\n- Disable individual tabs\n- Full-width option\n- Keyboard navigation (arrow keys)\n- Accessible with ARIA role attributes\n- Tab content lazy loading\n- Dark mode support\n\n**Props:**\n- `tabs` - Array of tab objects with id, label, icon, disabled, and content\n- `activeTab` - Initially active tab ID\n- `variant` - Tab style variant: 'default' | 'pills' | 'underline' (default: 'default')\n- `fullWidth` - Stretch tabs to full width (default: false)\n- `onTabChange` - Callback fired when tab changes\n\n**Example Usage:**\n```tsx\nimport { Tabs } from './interactive';\n\nconst tabs = [\n  {\n    id: 'overview',\n    label: 'Overview',\n    content: <OverviewPanel />\n  },\n  {\n    id: 'details',\n    label: 'Details',\n    content: <DetailsPanel />\n  }\n];\n\n<Tabs\n  tabs={tabs}\n  variant=\"pills\"\n  onTabChange={(tabId) => console.log('Active tab:', tabId)}\n/>\n```\n\n---\n\n## Styling\n\nAll components use **Tailwind CSS** for styling with built-in dark mode support through Tailwind's `dark:` prefix.\n\n### CSS Classes Used\n- Color utilities: `bg-blue-600`, `text-white`, `hover:bg-blue-700`\n- Dark mode: `dark:bg-gray-800`, `dark:text-white`, `dark:hover:bg-gray-700`\n- Layout: `flex`, `gap-3`, `w-full`, `rounded-lg`\n- Effects: `transition-all`, `shadow-sm`, `border`, `rounded-full`\n\n### Customization\nMost components accept a `className` prop to add custom Tailwind classes:\n\n```tsx\n<Wizard steps={steps} className=\"my-custom-class\" />\n```\n\n---\n\n## Accessibility\n\nAll components follow WAI-ARIA guidelines:\n\n- **ARIA Roles**: `progressbar`, `tablist`, `tab`, `tabpanel`, `button`\n- **ARIA Labels**: Clear labels for screen readers\n- **ARIA Attributes**: `aria-valuenow`, `aria-valuemin`, `aria-valuemax`, `aria-pressed`, `aria-selected`\n- **Keyboard Navigation**: Full support for Tab, Enter, Escape, and Arrow keys\n- **Focus Management**: Visible focus rings and proper focus handling\n\n---\n\n## Testing\n\nEach component has comprehensive tests covering:\n\n- **Rendering**: Correct initial state and content display\n- **Interaction**: Click handlers, state changes, callbacks\n- **Accessibility**: ARIA attributes, keyboard navigation\n- **Styling**: CSS classes and visual states\n- **Edge Cases**: Empty states, disabled states, boundary conditions\n\n### Running Tests\n\n```bash\nnpm run test -- --run src/components/ai-ui/interactive/__tests__/\n```\n\n**Test Coverage Summary:**\n- ✓ Wizard Component: 15 tests\n- ✓ Checklist Component: 14 tests\n- ✓ ApprovalButtons Component: 18 tests\n- **Total**: 47 passing tests\n\n---\n\n## Integration with AI-UI System\n\nThese components are part of the larger AI-UI component catalog defined in `/src/ai-ui.ts`. They can be used with the JSON render system for dynamic UI generation.\n\n### Type Definitions\nAll components export TypeScript interfaces for type safety:\n- `WizardProps`, `WizardStep`\n- `ChecklistProps`, `ChecklistItem`, `ChecklistSubItem`\n- `ApprovalButtonsProps`, `ApprovalAction`\n- `ProgressBarProps`\n- `TabsProps`, `TabContent`\n\n---\n\n## Dependencies\n\n- **React** 18.2.0+\n- **Tailwind CSS** 3.3.6+\n- No external icon library (uses inline SVG)\n\n---\n\n## Browser Support\n\n- Chrome/Edge (latest)\n- Firefox (latest)\n- Safari (latest)\n- Mobile browsers with ES6+ support\n\n---\n\n## Future Enhancements\n\nPotential improvements for future iterations:\n\n1. **Animation Library Integration**: Add framer-motion for advanced animations\n2. **Accessibility Audits**: Full a11y testing with axe-core\n3. **Performance Optimization**: React.memo memoization for large lists\n4. **Theme System**: Configurable color themes beyond Tailwind\n5. **Internationalization**: i18n support for labels and placeholders\n6. **Storybook Integration**: Component documentation and visual testing\n7. **Mobile Gestures**: Touch support for swiping between tabs/steps\n8. **State Persistence**: localStorage for wizard progress, checklist state\n",
        "ui/src/hooks/__tests__/useAgentStatus.test.ts": "/**\n * useAgentStatus Hook Tests\n *\n * Test coverage includes:\n * - Hook initialization with idle state\n * - Fetching status from API endpoint\n * - Polling with configurable intervals\n * - WebSocket real-time updates\n * - Error handling and graceful fallback\n * - Loading state management\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act, waitFor } from '@testing-library/react';\nimport { useAgentStatus } from '../useAgentStatus';\n\ndescribe('useAgentStatus', () => {\n  const mockStatusResponse = {\n    status: 'working' as const,\n    message: 'Processing task',\n  };\n\n  beforeEach(() => {\n    vi.clearAllMocks();\n  });\n\n  afterEach(() => {\n    vi.clearAllTimers();\n  });\n\n  describe('Initialization', () => {\n    it('should initialize with idle state and isLoading true', () => {\n      global.fetch = vi.fn(() =>\n        new Promise(() => {}) // Never resolves\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      expect(result.current.agentStatus).toBe('idle');\n      expect(result.current.agentMessage).toBeUndefined();\n      expect(result.current.agentIsLoading).toBe(true);\n    });\n\n    it('should use default polling interval of 2000ms', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useAgentStatus());\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      }, { timeout: 3000 });\n    });\n\n    it('should use custom polling interval', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useAgentStatus(5000));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      }, { timeout: 3000 });\n    });\n  });\n\n  describe('API Fetching', () => {\n    it('should fetch status from /api/status', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledWith('/api/status');\n      }, { timeout: 3000 });\n    });\n\n    it('should update state when API returns data', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('working');\n        expect(result.current.agentMessage).toBe('Processing task');\n      }, { timeout: 3000 });\n    });\n\n    it('should set isLoading to false after fetch completes', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentIsLoading).toBe(false);\n      }, { timeout: 3000 });\n    });\n\n    it('should handle waiting status', async () => {\n      const waitingResponse = { status: 'waiting' as const, message: 'User input required' };\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(waitingResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('waiting');\n      }, { timeout: 3000 });\n    });\n\n    it('should handle idle status', async () => {\n      const idleResponse = { status: 'idle' as const };\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(idleResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('idle');\n      }, { timeout: 3000 });\n    });\n  });\n\n  describe('Polling', () => {\n    it('should poll at configured intervals', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useAgentStatus(100));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(1);\n      }, { timeout: 3000 });\n\n      // Wait for second poll\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(2);\n      }, { timeout: 3000 });\n    });\n\n    it('should respect custom polling intervals', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useAgentStatus(150));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(1);\n      }, { timeout: 3000 });\n\n      // Wait for second poll after 150ms\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(2);\n      }, { timeout: 3000 });\n    });\n\n    it('should clear polling interval on unmount', async () => {\n      const clearIntervalSpy = vi.spyOn(global, 'clearInterval');\n\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      const { unmount } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      }, { timeout: 3000 });\n\n      unmount();\n\n      expect(clearIntervalSpy).toHaveBeenCalled();\n    });\n  });\n\n  describe('Error Handling', () => {\n    it('should keep last known state when fetch fails', async () => {\n      const validResponse = { status: 'working' as const, message: 'Working' };\n      global.fetch = vi.fn()\n        .mockResolvedValueOnce(\n          new Response(JSON.stringify(validResponse), { status: 200 })\n        )\n        .mockRejectedValueOnce(new Error('Network error'));\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('working');\n      }, { timeout: 3000 });\n\n      const previousStatus = result.current.agentStatus;\n\n      // Error on next fetch should keep previous status\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe(previousStatus);\n      }, { timeout: 3000 });\n    });\n\n    it('should handle API errors gracefully', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.reject(new Error('Connection refused'))\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        // Should maintain initial state\n        expect(result.current.agentStatus).toBe('idle');\n      }, { timeout: 3000 });\n\n      // Should not crash\n      expect(result.current).toBeDefined();\n    });\n\n    it('should handle malformed response gracefully', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify({}), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toMatch(/working|waiting|idle/);\n      }, { timeout: 3000 });\n\n      expect(result.current.agentIsLoading).toBe(false);\n    });\n  });\n\n  describe('WebSocket Integration', () => {\n    it('should update state on WebSocket status_changed event', async () => {\n      let wsCallback: ((event: any) => void) | null = null;\n\n      const originalAddEventListener = window.addEventListener;\n      window.addEventListener = vi.fn((event: string, callback: any) => {\n        if (event === 'status_changed') {\n          wsCallback = callback;\n        }\n      });\n\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify({ status: 'idle' as const }), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('idle');\n      }, { timeout: 3000 });\n\n      // Simulate WebSocket update\n      if (wsCallback) {\n        act(() => {\n          wsCallback({\n            detail: { status: 'working', message: 'Task started' },\n          });\n        });\n      }\n\n      await waitFor(() => {\n        expect(result.current.agentStatus).toBe('working');\n        expect(result.current.agentMessage).toBe('Task started');\n      }, { timeout: 3000 });\n\n      window.addEventListener = originalAddEventListener;\n    });\n  });\n\n  describe('Cleanup', () => {\n    it('should clean up on unmount', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockStatusResponse), { status: 200 })\n        )\n      );\n\n      const { unmount } = renderHook(() => useAgentStatus(2000));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      }, { timeout: 3000 });\n\n      unmount();\n\n      // Should not throw\n      expect(true).toBe(true);\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useDocumentHistory.test.ts": "/**\n * useDocumentHistory Hook Tests\n *\n * Tests verify:\n * - Hook initialization with correct default state\n * - Fetching document history from API\n * - Loading and error states\n * - Handling 404 (no history) gracefully\n * - Refetching on document ID change\n * - getVersionAt function for specific timestamps\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, waitFor, act } from '@testing-library/react';\nimport { useDocumentHistory } from '../useDocumentHistory';\nimport { useSessionStore } from '../../stores/sessionStore';\n\ndescribe('useDocumentHistory', () => {\n  const mockHistoryResponse = {\n    original: 'Initial content',\n    changes: [\n      {\n        timestamp: '2024-01-15T10:00:00Z',\n        diff: { oldString: 'Initial', newString: 'Updated' },\n      },\n      {\n        timestamp: '2024-01-15T11:00:00Z',\n        diff: { oldString: 'Updated', newString: 'Final' },\n      },\n    ],\n  };\n\n  beforeEach(() => {\n    vi.clearAllMocks();\n    useSessionStore.getState().reset();\n    // Set up a session\n    useSessionStore.getState().setCurrentSession({\n      project: '/test/project',\n      name: 'test-session',\n    });\n  });\n\n  afterEach(() => {\n    vi.restoreAllMocks();\n  });\n\n  describe('Initialization', () => {\n    it('should initialize with null history and not loading when documentId is null', () => {\n      const { result } = renderHook(() => useDocumentHistory(null));\n\n      expect(result.current.history).toBeNull();\n      expect(result.current.isLoading).toBe(false);\n      expect(result.current.error).toBeNull();\n    });\n\n    it('should start loading when documentId is provided', async () => {\n      global.fetch = vi.fn(() => new Promise(() => {})); // Never resolves\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      expect(result.current.isLoading).toBe(true);\n    });\n\n    it('should have refetch function', () => {\n      const { result } = renderHook(() => useDocumentHistory(null));\n\n      expect(typeof result.current.refetch).toBe('function');\n    });\n\n    it('should have getVersionAt function', () => {\n      const { result } = renderHook(() => useDocumentHistory(null));\n\n      expect(typeof result.current.getVersionAt).toBe('function');\n    });\n  });\n\n  describe('Fetching History', () => {\n    it('should fetch history from correct API endpoint', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledWith(\n          '/api/document/doc-1/history?project=%2Ftest%2Fproject&session=test-session'\n        );\n      });\n    });\n\n    it('should set history data on successful fetch', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.history).toEqual(mockHistoryResponse);\n      });\n    });\n\n    it('should set isLoading to false after fetch completes', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n    });\n\n    it('should not fetch when project is not set', async () => {\n      useSessionStore.getState().setCurrentSession(null);\n      global.fetch = vi.fn();\n\n      renderHook(() => useDocumentHistory('doc-1'));\n\n      // Wait a bit to ensure no fetch happens\n      await new Promise((resolve) => setTimeout(resolve, 50));\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('Error Handling', () => {\n    it('should set error on non-ok response', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(new Response('Server error', { status: 500 }))\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.error).toBe('Failed to load history');\n        expect(result.current.isLoading).toBe(false);\n      });\n    });\n\n    it('should set error on network failure', async () => {\n      global.fetch = vi.fn(() => Promise.reject(new Error('Network error')));\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.error).toBe('Network error');\n        expect(result.current.isLoading).toBe(false);\n      });\n    });\n\n    it('should set history to null on 404 (no history yet)', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(new Response('Not found', { status: 404 }))\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.history).toBeNull();\n        expect(result.current.error).toBeNull();\n        expect(result.current.isLoading).toBe(false);\n      });\n    });\n  });\n\n  describe('Refetch', () => {\n    it('should refetch when refetch is called', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(1);\n      });\n\n      await act(async () => {\n        await result.current.refetch();\n      });\n\n      expect(global.fetch).toHaveBeenCalledTimes(2);\n    });\n\n    it('should refetch when documentId changes', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      const { result, rerender } = renderHook(\n        ({ docId }) => useDocumentHistory(docId),\n        { initialProps: { docId: 'doc-1' } }\n      );\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(1);\n      });\n\n      rerender({ docId: 'doc-2' });\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledTimes(2);\n        expect(global.fetch).toHaveBeenLastCalledWith(\n          '/api/document/doc-2/history?project=%2Ftest%2Fproject&session=test-session'\n        );\n      });\n    });\n  });\n\n  describe('getVersionAt', () => {\n    it('should fetch version at specific timestamp', async () => {\n      const versionResponse = {\n        content: 'Content at timestamp',\n        timestamp: '2024-01-15T10:00:00Z',\n      };\n\n      global.fetch = vi\n        .fn()\n        .mockResolvedValueOnce(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n        .mockResolvedValueOnce(\n          new Response(JSON.stringify(versionResponse), { status: 200 })\n        );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.history).not.toBeNull();\n      });\n\n      let content: string | null = null;\n      await act(async () => {\n        content = await result.current.getVersionAt('2024-01-15T10:00:00Z');\n      });\n\n      expect(content).toBe('Content at timestamp');\n      expect(global.fetch).toHaveBeenLastCalledWith(\n        '/api/document/doc-1/version?project=%2Ftest%2Fproject&session=test-session&timestamp=2024-01-15T10%3A00%3A00Z'\n      );\n    });\n\n    it('should return null when version fetch fails', async () => {\n      global.fetch = vi\n        .fn()\n        .mockResolvedValueOnce(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n        .mockRejectedValueOnce(new Error('Network error'));\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.history).not.toBeNull();\n      });\n\n      let content: string | null = 'not-null';\n      await act(async () => {\n        content = await result.current.getVersionAt('2024-01-15T10:00:00Z');\n      });\n\n      expect(content).toBeNull();\n    });\n\n    it('should return null when documentId is null', async () => {\n      const { result } = renderHook(() => useDocumentHistory(null));\n\n      let content: string | null = 'not-null';\n      await act(async () => {\n        content = await result.current.getVersionAt('2024-01-15T10:00:00Z');\n      });\n\n      expect(content).toBeNull();\n    });\n\n    it('should return null when session is not set', async () => {\n      useSessionStore.getState().setCurrentSession(null);\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      let content: string | null = 'not-null';\n      await act(async () => {\n        content = await result.current.getVersionAt('2024-01-15T10:00:00Z');\n      });\n\n      expect(content).toBeNull();\n    });\n  });\n\n  describe('Session Changes', () => {\n    it('should clear history when session changes', async () => {\n      global.fetch = vi.fn(() =>\n        Promise.resolve(\n          new Response(JSON.stringify(mockHistoryResponse), { status: 200 })\n        )\n      );\n\n      const { result } = renderHook(() => useDocumentHistory('doc-1'));\n\n      await waitFor(() => {\n        expect(result.current.history).toEqual(mockHistoryResponse);\n      });\n\n      // Change session - this clears history\n      act(() => {\n        useSessionStore.getState().setCurrentSession({\n          project: '/different/project',\n          name: 'different-session',\n        });\n      });\n\n      // History should be refetched for the new session\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalledWith(\n          '/api/document/doc-1/history?project=%2Fdifferent%2Fproject&session=different-session'\n        );\n      });\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useEditorHistory.test.ts": "/**\n * useEditorHistory Hook Tests\n *\n * Tests verify:\n * - Hook initialization with no editor\n * - Setting editor reference\n * - Tracking undo/redo availability\n * - Undo functionality\n * - Redo functionality\n * - Cleanup when editor is removed\n */\n\nimport { describe, it, expect, beforeEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useEditorHistory } from '../useEditorHistory';\n\n// Create a minimal mock editor for testing\nfunction createMockEditor() {\n  // Create a minimal EditorView-like object for testing\n  const mockEditor = {\n    state: {\n      // Mock state with history\n      history: {\n        done: [],\n        undone: [],\n      },\n    },\n    dispatch: vi.fn(() => {\n      // Mock dispatch\n    }),\n  } as any;\n\n  return mockEditor;\n}\n\ndescribe('useEditorHistory', () => {\n  describe('Initialization', () => {\n    it('should initialize with null editor ref', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(result.current.editorRef.current).toBeNull();\n    });\n\n    it('should initialize with canUndo as false', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(result.current.canUndo).toBe(false);\n    });\n\n    it('should initialize with canRedo as false', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(result.current.canRedo).toBe(false);\n    });\n\n    it('should provide setEditor function', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(typeof result.current.setEditor).toBe('function');\n    });\n\n    it('should provide undo function', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(typeof result.current.undo).toBe('function');\n    });\n\n    it('should provide redo function', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(typeof result.current.redo).toBe('function');\n    });\n  });\n\n  describe('setEditor Function', () => {\n    it('should store editor reference when called with editor', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      expect(result.current.editorRef.current).toBe(mockEditor);\n    });\n\n    it('should clear editor reference when called with null', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      expect(result.current.editorRef.current).not.toBeNull();\n\n      act(() => {\n        result.current.setEditor(null);\n      });\n\n      expect(result.current.editorRef.current).toBeNull();\n    });\n\n    it('should reset canUndo and canRedo when editor is null', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      act(() => {\n        result.current.setEditor(null);\n      });\n\n      expect(result.current.canUndo).toBe(false);\n      expect(result.current.canRedo).toBe(false);\n    });\n\n    it('should handle rapid editor changes', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const editor1 = createMockEditor();\n      const editor2 = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(editor1);\n        result.current.setEditor(null);\n        result.current.setEditor(editor2);\n      });\n\n      expect(result.current.editorRef.current).toBe(editor2);\n    });\n  });\n\n  describe('Undo Function', () => {\n    it('should not crash when undo called without editor', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(() => {\n        act(() => {\n          result.current.undo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should not crash when undo called with canUndo false', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      // canUndo should be false initially\n      expect(result.current.canUndo).toBe(false);\n\n      expect(() => {\n        act(() => {\n          result.current.undo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should be callable', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(typeof result.current.undo).toBe('function');\n\n      act(() => {\n        result.current.undo();\n      });\n    });\n  });\n\n  describe('Redo Function', () => {\n    it('should not crash when redo called without editor', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(() => {\n        act(() => {\n          result.current.redo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should not crash when redo called with canRedo false', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      // canRedo should be false initially\n      expect(result.current.canRedo).toBe(false);\n\n      expect(() => {\n        act(() => {\n          result.current.redo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should be callable', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(typeof result.current.redo).toBe('function');\n\n      act(() => {\n        result.current.redo();\n      });\n    });\n  });\n\n  describe('Return Object', () => {\n    it('should return all required properties', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(result.current).toHaveProperty('editorRef');\n      expect(result.current).toHaveProperty('setEditor');\n      expect(result.current).toHaveProperty('undo');\n      expect(result.current).toHaveProperty('redo');\n      expect(result.current).toHaveProperty('canUndo');\n      expect(result.current).toHaveProperty('canRedo');\n    });\n\n    it('should have correct return type', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      // editorRef should be a ref object\n      expect(result.current.editorRef).toHaveProperty('current');\n\n      // setEditor, undo, redo should be functions\n      expect(typeof result.current.setEditor).toBe('function');\n      expect(typeof result.current.undo).toBe('function');\n      expect(typeof result.current.redo).toBe('function');\n\n      // canUndo and canRedo should be booleans\n      expect(typeof result.current.canUndo).toBe('boolean');\n      expect(typeof result.current.canRedo).toBe('boolean');\n    });\n  });\n\n  describe('Edge Cases', () => {\n    it('should handle multiple consecutive setEditor calls with null', () => {\n      const { result } = renderHook(() => useEditorHistory());\n\n      expect(() => {\n        act(() => {\n          result.current.setEditor(null);\n          result.current.setEditor(null);\n          result.current.setEditor(null);\n        });\n      }).not.toThrow();\n    });\n\n    it('should handle setEditor then immediate undo', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      expect(() => {\n        act(() => {\n          result.current.setEditor(mockEditor);\n          result.current.undo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should handle setEditor then immediate redo', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      expect(() => {\n        act(() => {\n          result.current.setEditor(mockEditor);\n          result.current.redo();\n        });\n      }).not.toThrow();\n    });\n\n    it('should maintain hook state across updates', () => {\n      const { result, rerender } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      const firstRef = result.current.editorRef.current;\n\n      rerender();\n\n      const secondRef = result.current.editorRef.current;\n\n      expect(firstRef).toBe(secondRef);\n    });\n  });\n\n  describe('Independent Hook Instances', () => {\n    it('should have independent state across instances', () => {\n      const { result: result1 } = renderHook(() => useEditorHistory());\n      const { result: result2 } = renderHook(() => useEditorHistory());\n\n      const editor1 = createMockEditor();\n      const editor2 = createMockEditor();\n\n      act(() => {\n        result1.current.setEditor(editor1);\n        result2.current.setEditor(editor2);\n      });\n\n      expect(result1.current.editorRef.current).toBe(editor1);\n      expect(result2.current.editorRef.current).toBe(editor2);\n      expect(result1.current.editorRef.current).not.toBe(\n        result2.current.editorRef.current\n      );\n    });\n\n    it('should not affect other instances when one clears editor', () => {\n      const { result: result1 } = renderHook(() => useEditorHistory());\n      const { result: result2 } = renderHook(() => useEditorHistory());\n\n      const editor1 = createMockEditor();\n      const editor2 = createMockEditor();\n\n      act(() => {\n        result1.current.setEditor(editor1);\n        result2.current.setEditor(editor2);\n      });\n\n      act(() => {\n        result1.current.setEditor(null);\n      });\n\n      expect(result1.current.editorRef.current).toBeNull();\n      expect(result2.current.editorRef.current).toBe(editor2);\n    });\n  });\n\n  describe('Undo and Redo Callbacks', () => {\n    it('should maintain function references across re-renders', () => {\n      const { result, rerender } = renderHook(() => useEditorHistory());\n\n      const undoBefore = result.current.undo;\n      const redoBefore = result.current.redo;\n\n      rerender();\n\n      const undoAfter = result.current.undo;\n      const redoAfter = result.current.redo;\n\n      expect(undoBefore).toBe(undoAfter);\n      expect(redoBefore).toBe(redoAfter);\n    });\n\n    it('should update dependency when canUndo changes', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      const canUndoValue = result.current.canUndo;\n\n      expect(typeof canUndoValue).toBe('boolean');\n    });\n\n    it('should update dependency when canRedo changes', () => {\n      const { result } = renderHook(() => useEditorHistory());\n      const mockEditor = createMockEditor();\n\n      act(() => {\n        result.current.setEditor(mockEditor);\n      });\n\n      const canRedoValue = result.current.canRedo;\n\n      expect(typeof canRedoValue).toBe('boolean');\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useExportDiagram.test.ts": "/**\n * Tests for useExportDiagram hook\n */\n\nimport { renderHook, act } from '@testing-library/react';\nimport { useExportDiagram } from '../useExportDiagram';\nimport { describe, it, expect, beforeEach, vi, afterEach } from 'vitest';\n\ndescribe('useExportDiagram', () => {\n  beforeEach(() => {\n    // Mock URL APIs\n    global.URL.createObjectURL = vi.fn(() => 'blob:mock-url');\n    global.URL.revokeObjectURL = vi.fn();\n  });\n\n  afterEach(() => {\n    vi.clearAllMocks();\n  });\n\n  it('should return hook with expected interface', () => {\n    const { result } = renderHook(() => useExportDiagram());\n\n    expect(result.current).toHaveProperty('svgContainerRef');\n    expect(result.current).toHaveProperty('exportAsSVG');\n    expect(result.current).toHaveProperty('exportAsPNG');\n    expect(result.current).toHaveProperty('canExport');\n\n    expect(typeof result.current.svgContainerRef).toBe('function');\n    expect(typeof result.current.exportAsSVG).toBe('function');\n    expect(typeof result.current.exportAsPNG).toBe('function');\n    expect(typeof result.current.canExport).toBe('boolean');\n  });\n\n  it('should initialize with canExport as false', () => {\n    const { result } = renderHook(() => useExportDiagram());\n\n    expect(result.current.canExport).toBe(false);\n  });\n\n  it('should set canExport to false when ref is null', () => {\n    const { result } = renderHook(() => useExportDiagram());\n\n    act(() => {\n      result.current.svgContainerRef(null);\n    });\n\n    expect(result.current.canExport).toBe(false);\n  });\n\n  it('should set canExport to false when container has no SVG', () => {\n    const { result } = renderHook(() => useExportDiagram());\n\n    const container = document.createElement('div');\n\n    act(() => {\n      result.current.svgContainerRef(container);\n    });\n\n    expect(result.current.canExport).toBe(false);\n  });\n\n  it('should set canExport to true when container has SVG', () => {\n    const { result } = renderHook(() => useExportDiagram());\n\n    const container = document.createElement('div');\n    const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n    container.appendChild(svg);\n\n    act(() => {\n      result.current.svgContainerRef(container);\n    });\n\n    expect(result.current.canExport).toBe(true);\n  });\n\n  describe('exportAsSVG', () => {\n    it('should silently return when container is null', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      // Container starts as null, should not throw\n      expect(() => {\n        result.current.exportAsSVG('test');\n      }).not.toThrow();\n    });\n\n    it('should silently return when SVG is not found', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      // No SVG in container, should not throw\n      expect(() => {\n        result.current.exportAsSVG('test');\n      }).not.toThrow();\n    });\n\n    it('should not call download functions when no SVG present', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      // Reset mocks to check if they're called\n      vi.clearAllMocks();\n\n      act(() => {\n        result.current.exportAsSVG('test');\n      });\n\n      // createObjectURL should not be called if there's no SVG\n      expect(global.URL.createObjectURL).not.toHaveBeenCalled();\n    });\n\n    it('should call createObjectURL when SVG exists', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      vi.clearAllMocks();\n\n      // Mock downloadFile to prevent actual file download\n      const downloadFileSpy = vi.spyOn(document, 'createElement');\n\n      act(() => {\n        result.current.exportAsSVG('test-diagram');\n      });\n\n      // Should attempt to create blob and object URL\n      expect(global.URL.createObjectURL).toHaveBeenCalled();\n      expect(global.URL.revokeObjectURL).toHaveBeenCalled();\n\n      downloadFileSpy.mockRestore();\n    });\n  });\n\n  describe('exportAsPNG', () => {\n    it('should return a promise', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const promise = result.current.exportAsPNG('test');\n      expect(promise).toBeInstanceOf(Promise);\n    });\n\n    it('should resolve when container is null', async () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      // Container starts as null\n      await expect(result.current.exportAsPNG('test')).resolves.toBeUndefined();\n    });\n\n    it('should resolve when SVG is not found', async () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      await expect(result.current.exportAsPNG('test')).resolves.toBeUndefined();\n    });\n\n    it('should handle SVG with fallback dimensions', async () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n      svg.setAttribute('width', '300');\n      svg.setAttribute('height', '200');\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      // Should resolve even with fallback dimensions\n      const promise = result.current.exportAsPNG('test');\n      expect(promise).toBeInstanceOf(Promise);\n    }, 1000); // Set short timeout for this test\n\n    it('should handle edge case of empty container', async () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      // Should resolve gracefully when SVG not found\n      await expect(result.current.exportAsPNG('test')).resolves.toBeUndefined();\n    });\n  });\n\n  describe('svgContainerRef callback', () => {\n    it('should update canExport state on ref changes', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      expect(result.current.canExport).toBe(false);\n\n      const container = document.createElement('div');\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      expect(result.current.canExport).toBe(true);\n\n      act(() => {\n        result.current.svgContainerRef(null);\n      });\n\n      expect(result.current.canExport).toBe(false);\n    });\n\n    it('should detect SVG presence correctly', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      const div = document.createElement('div');\n      container.appendChild(div);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      expect(result.current.canExport).toBe(false);\n\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      expect(result.current.canExport).toBe(true);\n    });\n  });\n\n  describe('edge cases', () => {\n    it('should handle rapid ref updates', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const containers = Array.from({ length: 5 }, () => {\n        const c = document.createElement('div');\n        const s = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n        c.appendChild(s);\n        return c;\n      });\n\n      act(() => {\n        containers.forEach((c) => {\n          result.current.svgContainerRef(c);\n        });\n      });\n\n      expect(result.current.canExport).toBe(true);\n    });\n\n    it('should not throw on export with complex SVG structure', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n\n      // Add nested elements\n      const g = document.createElementNS('http://www.w3.org/2000/svg', 'g');\n      const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');\n      const text = document.createElementNS('http://www.w3.org/2000/svg', 'text');\n\n      g.appendChild(circle);\n      g.appendChild(text);\n      svg.appendChild(g);\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      expect(() => {\n        result.current.exportAsSVG('complex');\n      }).not.toThrow();\n    });\n\n    it('should handle very long filenames', () => {\n      const { result } = renderHook(() => useExportDiagram());\n\n      const container = document.createElement('div');\n      const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');\n      container.appendChild(svg);\n\n      act(() => {\n        result.current.svgContainerRef(container);\n      });\n\n      const longFilename = 'a'.repeat(200);\n\n      expect(() => {\n        result.current.exportAsSVG(longFilename);\n      }).not.toThrow();\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useIsMobile.test.ts": "/**\n * useIsMobile Hook Tests (alternate location)\n *\n * Tests verify:\n * - Mobile detection using matchMedia (< 640px)\n * - Desktop detection (>= 640px)\n * - Resize listener updates state\n * - No memory leaks from event listeners\n * - Proper cleanup on unmount\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useIsMobile } from '../useIsMobile';\n\n// Helper to create mock matchMedia\nfunction createMockMatchMedia(matches: boolean) {\n  return {\n    matches,\n    media: '(max-width: 639px)',\n    onchange: null as ((event: MediaQueryListEvent) => void) | null,\n    addListener: vi.fn(),\n    removeListener: vi.fn(),\n    addEventListener: vi.fn(),\n    removeEventListener: vi.fn(),\n    dispatchEvent: vi.fn(),\n  } as unknown as MediaQueryList;\n}\n\ndescribe('useIsMobile', () => {\n  let originalMatchMedia: typeof window.matchMedia;\n\n  beforeEach(() => {\n    // Save original matchMedia\n    originalMatchMedia = window.matchMedia;\n  });\n\n  afterEach(() => {\n    // Restore original matchMedia\n    window.matchMedia = originalMatchMedia;\n    vi.clearAllMocks();\n  });\n\n  describe('Desktop detection', () => {\n    it('should return false for desktop viewport (>= 640px)', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n    });\n\n    it('should call matchMedia with correct media query', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      const matchMediaFn = vi.fn(() => mockMatchMedia);\n      window.matchMedia = matchMediaFn;\n\n      renderHook(() => useIsMobile());\n\n      expect(matchMediaFn).toHaveBeenCalledWith('(max-width: 639px)');\n    });\n\n    it('should add resize event listener', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      renderHook(() => useIsMobile());\n\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledWith('change', expect.any(Function));\n    });\n  });\n\n  describe('Mobile detection', () => {\n    it('should return true for mobile viewport (< 640px)', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(true);\n    });\n  });\n\n  describe('Viewport changes', () => {\n    it('should update state when viewport changes from desktop to mobile', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        // Capture the listener for manual triggering\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n\n      // Simulate window resize to mobile\n      if (changeListener) {\n        act(() => {\n          changeListener({\n            matches: true,\n            media: '(max-width: 639px)',\n          } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(true);\n    });\n\n    it('should update state when viewport changes from mobile to desktop', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(true);\n\n      // Simulate window resize to desktop\n      if (changeListener) {\n        act(() => {\n          changeListener({\n            matches: false,\n            media: '(max-width: 639px)',\n          } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(false);\n    });\n\n    it('should handle multiple rapid viewport changes', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n\n      // Rapid changes\n      if (changeListener) {\n        act(() => {\n          changeListener({ matches: true, media: '(max-width: 639px)' } as MediaQueryListEvent);\n          changeListener({ matches: false, media: '(max-width: 639px)' } as MediaQueryListEvent);\n          changeListener({ matches: true, media: '(max-width: 639px)' } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(true);\n    });\n  });\n\n  describe('Memory leaks', () => {\n    it('should remove event listener on unmount', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { unmount } = renderHook(() => useIsMobile());\n\n      unmount();\n\n      expect(mockMatchMedia.removeEventListener).toHaveBeenCalledWith('change', expect.any(Function));\n    });\n\n    it('should only add one event listener per hook instance', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      renderHook(() => useIsMobile());\n\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledTimes(1);\n    });\n\n    it('should not leak listeners on multiple renders', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { rerender } = renderHook(() => useIsMobile());\n\n      // Re-render multiple times\n      rerender();\n      rerender();\n      rerender();\n\n      // addEventListener should only be called once (in initial mount)\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledTimes(1);\n    });\n  });\n\n  describe('Return type', () => {\n    it('should return a boolean', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(typeof result.current).toBe('boolean');\n    });\n\n    it('should always return a boolean value', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect([true, false]).toContain(result.current);\n    });\n  });\n\n  describe('Edge cases', () => {\n    it('should handle matchMedia not being available gracefully', () => {\n      const originalWM = window.matchMedia;\n      // @ts-ignore - intentionally breaking matchMedia for test\n      window.matchMedia = undefined;\n\n      // Should not throw\n      expect(() => {\n        renderHook(() => useIsMobile());\n      }).not.toThrow();\n\n      window.matchMedia = originalWM;\n    });\n\n    it('should maintain consistent state across multiple hook instances', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result: result1 } = renderHook(() => useIsMobile());\n      const { result: result2 } = renderHook(() => useIsMobile());\n\n      expect(result1.current).toBe(result2.current);\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useSession.test.ts": "/**\n * useSession Hook Tests\n *\n * Tests verify:\n * - Hook initialization and state access\n * - Session CRUD operations\n * - Diagram management\n * - Document management\n * - Selection state tracking\n * - Error handling\n */\n\nimport { describe, it, expect, beforeEach } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useSession } from '../useSession';\nimport { useSessionStore } from '../../stores/sessionStore';\nimport { Session, Diagram, Document } from '../../types';\n\ndescribe('useSession', () => {\n  beforeEach(() => {\n    // Clear store before each test\n    useSessionStore.getState().reset();\n  });\n\n  describe('Session State', () => {\n    it('should initialize with empty session state', () => {\n      const { result } = renderHook(() => useSession());\n\n      expect(result.current.currentSession).toBeNull();\n      expect(result.current.isLoading).toBe(false);\n      expect(result.current.error).toBeNull();\n    });\n\n    it('should set current session', () => {\n      const { result } = renderHook(() => useSession());\n      const session: Session = {\n        project: 'test-project',\n        name: 'test-session',\n      };\n\n      act(() => {\n        result.current.setCurrentSession(session);\n      });\n\n      expect(result.current.currentSession).toEqual(session);\n    });\n\n    it('should clear current session', () => {\n      const { result } = renderHook(() => useSession());\n      const session: Session = {\n        project: 'test-project',\n        name: 'test-session',\n      };\n\n      act(() => {\n        result.current.setCurrentSession(session);\n      });\n\n      expect(result.current.currentSession).toEqual(session);\n\n      act(() => {\n        result.current.setCurrentSession(null);\n      });\n\n      expect(result.current.currentSession).toBeNull();\n    });\n\n    it('should set loading state', () => {\n      const { result } = renderHook(() => useSession());\n\n      act(() => {\n        result.current.setLoading(true);\n      });\n\n      expect(result.current.isLoading).toBe(true);\n\n      act(() => {\n        result.current.setLoading(false);\n      });\n\n      expect(result.current.isLoading).toBe(false);\n    });\n\n    it('should set error state', () => {\n      const { result } = renderHook(() => useSession());\n      const error = 'Test error';\n\n      act(() => {\n        result.current.setError(error);\n      });\n\n      expect(result.current.error).toBe(error);\n\n      act(() => {\n        result.current.setError(null);\n      });\n\n      expect(result.current.error).toBeNull();\n    });\n  });\n\n  describe('Diagram Management', () => {\n    it('should start with empty diagrams', () => {\n      const { result } = renderHook(() => useSession());\n\n      expect(result.current.diagrams).toEqual([]);\n      expect(result.current.selectedDiagramId).toBeNull();\n    });\n\n    it('should add a diagram', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n      });\n\n      expect(result.current.diagrams).toContainEqual(diagram);\n    });\n\n    it('should update a diagram', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n      });\n\n      const updated = { name: 'Updated Diagram' };\n\n      act(() => {\n        result.current.updateDiagram('diagram-1', updated);\n      });\n\n      const updatedDiagram = result.current.diagrams.find((d) => d.id === 'diagram-1');\n      expect(updatedDiagram?.name).toBe('Updated Diagram');\n    });\n\n    it('should remove a diagram', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n      });\n\n      expect(result.current.diagrams).toHaveLength(1);\n\n      act(() => {\n        result.current.removeDiagram('diagram-1');\n      });\n\n      expect(result.current.diagrams).toHaveLength(0);\n    });\n\n    it('should select a diagram', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n        result.current.selectDiagram('diagram-1');\n      });\n\n      expect(result.current.selectedDiagramId).toBe('diagram-1');\n      expect(result.current.selectedDiagram?.id).toBe('diagram-1');\n    });\n\n    it('should clear diagram selection', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n        result.current.selectDiagram('diagram-1');\n      });\n\n      expect(result.current.selectedDiagramId).toBe('diagram-1');\n\n      act(() => {\n        result.current.selectDiagram(null);\n      });\n\n      expect(result.current.selectedDiagramId).toBeNull();\n    });\n\n    it('should clear selection when diagram is removed', () => {\n      const { result } = renderHook(() => useSession());\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDiagram(diagram);\n        result.current.selectDiagram('diagram-1');\n      });\n\n      expect(result.current.selectedDiagramId).toBe('diagram-1');\n\n      act(() => {\n        result.current.removeDiagram('diagram-1');\n      });\n\n      expect(result.current.selectedDiagramId).toBeNull();\n    });\n  });\n\n  describe('Document Management', () => {\n    it('should start with empty documents', () => {\n      const { result } = renderHook(() => useSession());\n\n      expect(result.current.documents).toEqual([]);\n      expect(result.current.selectedDocumentId).toBeNull();\n    });\n\n    it('should add a document', () => {\n      const { result } = renderHook(() => useSession());\n      const document: Document = {\n        id: 'doc-1',\n        name: 'Test Document',\n        content: 'markdown content',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDocument(document);\n      });\n\n      expect(result.current.documents).toContainEqual(document);\n    });\n\n    it('should update a document', () => {\n      const { result } = renderHook(() => useSession());\n      const document: Document = {\n        id: 'doc-1',\n        name: 'Test Document',\n        content: 'markdown content',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDocument(document);\n      });\n\n      const updated = { name: 'Updated Document' };\n\n      act(() => {\n        result.current.updateDocument('doc-1', updated);\n      });\n\n      const updatedDoc = result.current.documents.find((d) => d.id === 'doc-1');\n      expect(updatedDoc?.name).toBe('Updated Document');\n    });\n\n    it('should remove a document', () => {\n      const { result } = renderHook(() => useSession());\n      const document: Document = {\n        id: 'doc-1',\n        name: 'Test Document',\n        content: 'markdown content',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDocument(document);\n      });\n\n      expect(result.current.documents).toHaveLength(1);\n\n      act(() => {\n        result.current.removeDocument('doc-1');\n      });\n\n      expect(result.current.documents).toHaveLength(0);\n    });\n\n    it('should select a document', () => {\n      const { result } = renderHook(() => useSession());\n      const document: Document = {\n        id: 'doc-1',\n        name: 'Test Document',\n        content: 'markdown content',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDocument(document);\n        result.current.selectDocument('doc-1');\n      });\n\n      expect(result.current.selectedDocumentId).toBe('doc-1');\n      expect(result.current.selectedDocument?.id).toBe('doc-1');\n    });\n\n    it('should clear document selection', () => {\n      const { result } = renderHook(() => useSession());\n      const document: Document = {\n        id: 'doc-1',\n        name: 'Test Document',\n        content: 'markdown content',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.addDocument(document);\n        result.current.selectDocument('doc-1');\n      });\n\n      expect(result.current.selectedDocumentId).toBe('doc-1');\n\n      act(() => {\n        result.current.selectDocument(null);\n      });\n\n      expect(result.current.selectedDocumentId).toBeNull();\n    });\n  });\n\n  describe('Utility Methods', () => {\n    it('should clear all session data', () => {\n      const { result } = renderHook(() => useSession());\n      const session: Session = {\n        project: 'test-project',\n        name: 'test-session',\n      };\n      const diagram: Diagram = {\n        id: 'diagram-1',\n        name: 'Test Diagram',\n        content: 'mermaid code',\n        lastModified: Date.now(),\n      };\n\n      act(() => {\n        result.current.setCurrentSession(session);\n        result.current.addDiagram(diagram);\n      });\n\n      expect(result.current.currentSession).not.toBeNull();\n      expect(result.current.diagrams).toHaveLength(1);\n\n      act(() => {\n        result.current.clearSession();\n      });\n\n      expect(result.current.currentSession).toBeNull();\n      expect(result.current.diagrams).toHaveLength(0);\n    });\n\n    it('should reset store to initial state', () => {\n      const { result } = renderHook(() => useSession());\n      const session: Session = {\n        project: 'test-project',\n        name: 'test-session',\n      };\n\n      act(() => {\n        result.current.setCurrentSession(session);\n        result.current.setError('some error');\n        result.current.setLoading(true);\n      });\n\n      act(() => {\n        result.current.reset();\n      });\n\n      expect(result.current.currentSession).toBeNull();\n      expect(result.current.error).toBeNull();\n      expect(result.current.isLoading).toBe(false);\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useSessionPolling.test.ts": "/**\n * useSessionPolling Hook Tests\n *\n * Tests verify:\n * - Hook initialization with project and session parameters\n * - Polling mechanism at 5s intervals\n * - Fetch calls to session state API endpoint\n * - State update when lastActivity changes\n * - State stability when lastActivity hasn't changed\n * - Graceful error handling during polling\n * - Polling cleanup on unmount or dependency changes\n * - Polling disabled when project or session is null\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useSessionPolling } from '../useSessionPolling';\nimport { useSessionStore } from '../../stores/sessionStore';\n\n// Setup mocks\nconst mockSetCollabState = vi.fn();\nlet mockCollabState = {\n  lastActivity: '2026-01-28T10:00:00Z',\n  phase: 'rough-draft',\n  currentItem: 1,\n  totalItems: 10,\n};\n\nvi.mock('../../stores/sessionStore', () => ({\n  useSessionStore: vi.fn((selector) => {\n    return selector({\n      collabState: mockCollabState,\n      setCollabState: mockSetCollabState,\n    });\n  }),\n}));\n\n// Mock global fetch\nglobal.fetch = vi.fn();\n\ndescribe('useSessionPolling', () => {\n  beforeEach(() => {\n    vi.clearAllMocks();\n    mockCollabState = {\n      lastActivity: '2026-01-28T10:00:00Z',\n      phase: 'rough-draft',\n      currentItem: 1,\n      totalItems: 10,\n    };\n  });\n\n  afterEach(() => {\n    vi.clearAllMocks();\n  });\n\n  describe('Initialization', () => {\n    it('should initialize successfully with valid parameters', () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({ lastActivity: '2026-01-28T10:00:00Z' }),\n      } as Response);\n\n      expect(() => {\n        renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n      }).not.toThrow();\n    });\n\n    it('should not poll when project is null', async () => {\n      renderHook(() => useSessionPolling(null, 'test-session', 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n\n    it('should not poll when session is null', async () => {\n      renderHook(() => useSessionPolling('/test/project', null, 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n\n    it('should not poll when both project and session are null', async () => {\n      renderHook(() => useSessionPolling(null, null, 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('API Calls', () => {\n    it('should construct correct API endpoint with query parameters', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({ lastActivity: '2026-01-28T10:00:00Z' }),\n      } as Response);\n\n      renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).toHaveBeenCalledWith(\n        expect.stringMatching(/^\\/api\\/session-state\\?project=.+&session=.+$/)\n      );\n    });\n\n    it('should encode project and session parameters in URL', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({ lastActivity: '2026-01-28T10:00:00Z' }),\n      } as Response);\n\n      const project = '/Users/test project/path';\n      const session = 'my-session name';\n\n      renderHook(() => useSessionPolling(project, session, 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      const callUrl = vi.mocked(global.fetch).mock.calls[0][0] as string;\n      expect(callUrl).toContain(encodeURIComponent(project));\n      expect(callUrl).toContain(encodeURIComponent(session));\n    });\n  });\n\n  describe('State Updates', () => {\n    it('should update state when lastActivity changes', async () => {\n      mockCollabState = {\n        lastActivity: '2026-01-28T10:00:00Z',\n        phase: 'rough-draft',\n      };\n\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:05:00Z',\n          phase: 'implementation',\n          currentItem: 2,\n        }),\n      } as Response);\n\n      renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).toHaveBeenCalledWith(\n        expect.objectContaining({\n          lastActivity: '2026-01-28T10:05:00Z',\n          phase: 'implementation',\n        })\n      );\n    });\n\n    it('should not update state when lastActivity unchanged', async () => {\n      const currentActivity = '2026-01-28T10:00:00Z';\n      mockCollabState = {\n        lastActivity: currentActivity,\n        phase: 'rough-draft',\n      };\n\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: currentActivity,\n          phase: 'rough-draft',\n        }),\n      } as Response);\n\n      renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('Error Handling', () => {\n    it('should silently handle fetch errors', async () => {\n      vi.mocked(global.fetch).mockRejectedValue(new Error('Network error'));\n\n      expect(() => {\n        renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n      }).not.toThrow();\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).not.toHaveBeenCalled();\n    });\n\n    it('should silently handle failed responses (non-200)', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: false,\n        status: 404,\n        json: async () => ({}),\n      } as Response);\n\n      renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).not.toHaveBeenCalled();\n    });\n\n    it('should silently handle JSON parse errors', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => {\n          throw new Error('Invalid JSON');\n        },\n      } as Response);\n\n      expect(() => {\n        renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n      }).not.toThrow();\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('Cleanup', () => {\n    it('should clean up on unmount', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:00:00Z',\n        }),\n      } as Response);\n\n      const { unmount } = renderHook(() =>\n        useSessionPolling('/test/project', 'test-session', 5000)\n      );\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(() => {\n        unmount();\n      }).not.toThrow();\n    });\n\n    it('should handle project becoming null', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:00:00Z',\n        }),\n      } as Response);\n\n      const { rerender } = renderHook(\n        ({ project, session }) =>\n          useSessionPolling(project, session, 5000),\n        {\n          initialProps: {\n            project: '/test/project',\n            session: 'test-session',\n          },\n        }\n      );\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).toHaveBeenCalled();\n      vi.mocked(global.fetch).mockClear();\n\n      rerender({\n        project: null,\n        session: 'test-session',\n      });\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      // Should not fetch when project is null\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n\n    it('should handle session becoming null', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:00:00Z',\n        }),\n      } as Response);\n\n      const { rerender } = renderHook(\n        ({ project, session }) =>\n          useSessionPolling(project, session, 5000),\n        {\n          initialProps: {\n            project: '/test/project',\n            session: 'test-session',\n          },\n        }\n      );\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).toHaveBeenCalled();\n      vi.mocked(global.fetch).mockClear();\n\n      rerender({\n        project: '/test/project',\n        session: null,\n      });\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      // Should not fetch when session is null\n      expect(global.fetch).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('Default Interval', () => {\n    it('should use 5000ms as default interval when not specified', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:00:00Z',\n        }),\n      } as Response);\n\n      renderHook(() => useSessionPolling('/test/project', 'test-session'));\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(global.fetch).toHaveBeenCalled();\n    });\n  });\n\n  describe('Hook Integration', () => {\n    it('should work with useShallow selector from zustand', async () => {\n      vi.mocked(global.fetch).mockResolvedValue({\n        ok: true,\n        json: async () => ({\n          lastActivity: '2026-01-28T10:05:00Z',\n          phase: 'implementation',\n        }),\n      } as Response);\n\n      expect(() => {\n        renderHook(() => useSessionPolling('/test/project', 'test-session', 5000));\n      }).not.toThrow();\n\n      await new Promise((resolve) => setTimeout(resolve, 100));\n\n      expect(mockSetCollabState).toHaveBeenCalled();\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useTaskGraph.test.ts": "/**\n * useTaskGraph Hook Tests\n *\n * Tests verify:\n * - Initial fetch on mount\n * - Updates from CustomEvent\n * - Cleanup on unmount\n * - Error handling (fetch fails, invalid event data)\n * - Refresh function\n * - Loading state management\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act, waitFor } from '@testing-library/react';\nimport { useTaskGraph } from '../useTaskGraph';\nimport type { TaskBatch, TaskGraphUpdatedDetail } from '../../types';\n\n// Mock fetch globally\nglobal.fetch = vi.fn();\n\n// Mock console methods\nconst consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});\nconst consoleWarnSpy = vi.spyOn(console, 'warn').mockImplementation(() => {});\n\ndescribe('useTaskGraph', () => {\n  const mockProject = '/path/to/project';\n  const mockSession = 'test-session';\n\n  const mockTaskBatch: TaskBatch = {\n    id: 'batch-1',\n    tasks: [\n      { id: 'task-1', status: 'completed', dependsOn: [] },\n      { id: 'task-2', status: 'in_progress', dependsOn: ['task-1'] },\n    ],\n    status: 'in_progress',\n  };\n\n  const mockApiResponse = {\n    diagram: 'graph TD\\n  A[Task 1]\\n  B[Task 2]',\n    batches: [mockTaskBatch],\n    completedTasks: ['task-1'],\n    pendingTasks: ['task-2'],\n  };\n\n  beforeEach(() => {\n    vi.clearAllMocks();\n    consoleErrorSpy.mockClear();\n    consoleWarnSpy.mockClear();\n  });\n\n  afterEach(() => {\n    vi.clearAllMocks();\n  });\n\n  describe('Initial Fetch on Mount', () => {\n    it('should fetch initial state on mount', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      // Initially loading\n      expect(result.current.isLoading).toBe(true);\n      expect(result.current.diagram).toBeNull();\n\n      // Wait for fetch to complete\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Verify state updated with API response\n      expect(result.current.diagram).toBe(mockApiResponse.diagram);\n      expect(result.current.batches).toEqual(mockApiResponse.batches);\n      expect(result.current.completedTasks).toEqual(mockApiResponse.completedTasks);\n      expect(result.current.pendingTasks).toEqual(mockApiResponse.pendingTasks);\n      expect(result.current.error).toBeNull();\n    });\n\n    it('should handle fetch errors', async () => {\n      const mockError = new Error('Network error');\n      (global.fetch as any).mockRejectedValueOnce(mockError);\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Verify error state\n      expect(result.current.error).toBeDefined();\n      expect(result.current.error?.message).toContain('Network error');\n      expect(result.current.diagram).toBeNull();\n      expect(consoleErrorSpy).toHaveBeenCalled();\n    });\n\n    it('should handle non-OK API responses', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: false,\n        statusText: 'Not Found',\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Verify error state\n      expect(result.current.error).toBeDefined();\n      expect(result.current.error?.message).toContain('Failed to fetch task graph');\n    });\n\n    it('should handle missing data fields in API response', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({}),\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Verify default values for missing fields\n      expect(result.current.diagram).toBeNull();\n      expect(result.current.batches).toEqual([]);\n      expect(result.current.completedTasks).toEqual([]);\n      expect(result.current.pendingTasks).toEqual([]);\n      expect(result.current.error).toBeNull();\n    });\n  });\n\n  describe('CustomEvent Updates', () => {\n    it('should update state when task_graph_updated event is received', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({\n          diagram: 'old diagram',\n          batches: [],\n          completedTasks: [],\n          pendingTasks: [],\n        }),\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Initial state\n      expect(result.current.diagram).toBe('old diagram');\n\n      // Dispatch custom event with new data\n      const updatedDetail: TaskGraphUpdatedDetail = {\n        project: mockProject,\n        session: mockSession,\n        payload: {\n          ...mockApiResponse,\n          updatedTaskId: 'task-2',\n          updatedStatus: 'in_progress',\n        },\n      };\n\n      act(() => {\n        const event = new CustomEvent('task_graph_updated', { detail: updatedDetail });\n        window.dispatchEvent(event);\n      });\n\n      // Verify state updated\n      expect(result.current.diagram).toBe(mockApiResponse.diagram);\n      expect(result.current.batches).toEqual(mockApiResponse.batches);\n      expect(result.current.completedTasks).toEqual(mockApiResponse.completedTasks);\n      expect(result.current.pendingTasks).toEqual(mockApiResponse.pendingTasks);\n    });\n\n    it('should handle invalid event data gracefully', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const previousDiagram = result.current.diagram;\n\n      // Dispatch invalid event (missing payload)\n      act(() => {\n        const event = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            // Missing payload\n          },\n        });\n        window.dispatchEvent(event);\n      });\n\n      // State should remain unchanged\n      expect(result.current.diagram).toBe(previousDiagram);\n      expect(consoleWarnSpy).toHaveBeenCalled();\n    });\n\n    it('should handle event with undefined payload fields', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Dispatch event with partial payload\n      act(() => {\n        const event = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              diagram: 'new diagram',\n              updatedTaskId: 'task-1',\n              updatedStatus: 'completed',\n              // Missing other fields\n            },\n          } as any,\n        });\n        window.dispatchEvent(event);\n      });\n\n      // Should update with available data\n      expect(result.current.diagram).toBe('new diagram');\n      expect(result.current.batches).toEqual([]);\n      expect(result.current.completedTasks).toEqual([]);\n    });\n  });\n\n  describe('Event Listener Cleanup', () => {\n    it('should remove event listener on unmount', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const removeEventListenerSpy = vi.spyOn(window, 'removeEventListener');\n\n      const { unmount } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      });\n\n      // Unmount component\n      unmount();\n\n      // Verify event listener was removed\n      expect(removeEventListenerSpy).toHaveBeenCalledWith(\n        'task_graph_updated',\n        expect.any(Function)\n      );\n\n      removeEventListenerSpy.mockRestore();\n    });\n\n    it('should not respond to events after unmount', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({\n          diagram: 'initial',\n          batches: [],\n          completedTasks: [],\n          pendingTasks: [],\n        }),\n      });\n\n      const { result, unmount } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const initialDiagram = result.current.diagram;\n\n      // Unmount\n      unmount();\n\n      // Try to dispatch event after unmount\n      act(() => {\n        const event = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              ...mockApiResponse,\n              diagram: 'should not update',\n              updatedTaskId: 'task-1',\n              updatedStatus: 'completed',\n            },\n          },\n        });\n        window.dispatchEvent(event);\n      });\n\n      // Component should not be updated (already unmounted)\n      // This is verified by checking that the unmount succeeded without errors\n    });\n  });\n\n  describe('Refresh Function', () => {\n    it('should refetch data when refresh is called', async () => {\n      const firstResponse = {\n        ok: true,\n        json: async () => ({\n          diagram: 'diagram v1',\n          batches: [],\n          completedTasks: [],\n          pendingTasks: [],\n        }),\n      };\n\n      const secondResponse = {\n        ok: true,\n        json: async () => ({\n          diagram: 'diagram v2',\n          batches: [mockTaskBatch],\n          completedTasks: ['task-1'],\n          pendingTasks: ['task-2'],\n        }),\n      };\n\n      (global.fetch as any)\n        .mockResolvedValueOnce(firstResponse)\n        .mockResolvedValueOnce(secondResponse);\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      // Wait for initial fetch\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.diagram).toBe('diagram v1');\n\n      // Call refresh\n      await act(async () => {\n        await result.current.refresh();\n      });\n\n      // Verify data was updated\n      expect(result.current.diagram).toBe('diagram v2');\n      expect(result.current.batches).toEqual([mockTaskBatch]);\n      expect(result.current.completedTasks).toEqual(['task-1']);\n      expect(result.current.pendingTasks).toEqual(['task-2']);\n    });\n\n    it('should handle errors during refresh', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const previousDiagram = result.current.diagram;\n\n      // Mock fetch to fail on refresh\n      (global.fetch as any).mockRejectedValueOnce(new Error('Refresh failed'));\n\n      // Call refresh\n      await act(async () => {\n        await result.current.refresh();\n      });\n\n      // Verify error is set\n      expect(result.current.error).toBeDefined();\n      expect(result.current.error?.message).toContain('Refresh failed');\n      // Previous data should be retained\n      expect(result.current.diagram).toBe(previousDiagram);\n    });\n\n    it('should set loading state during refresh', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Mock delayed response\n      (global.fetch as any).mockImplementationOnce(\n        () =>\n          new Promise((resolve) =>\n            setTimeout(\n              () => resolve({\n                ok: true,\n                json: async () => mockApiResponse,\n              }),\n              100\n            )\n          )\n      );\n\n      // Call refresh\n      act(() => {\n        result.current.refresh();\n      });\n\n      // Loading should be true during fetch\n      expect(result.current.isLoading).toBe(true);\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n    });\n  });\n\n  describe('API URL Construction', () => {\n    it('should encode project and session in URL', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const projectWithSlashes = '/path/with/slashes';\n      const sessionWithSpaces = 'session with spaces';\n\n      renderHook(() => useTaskGraph(projectWithSlashes, sessionWithSpaces));\n\n      await waitFor(() => {\n        expect(global.fetch).toHaveBeenCalled();\n      });\n\n      const fetchUrl = (global.fetch as any).mock.calls[0][0];\n      expect(fetchUrl).toContain('task-graph');\n      expect(fetchUrl).toContain(encodeURIComponent(projectWithSlashes));\n      expect(fetchUrl).toContain(encodeURIComponent(sessionWithSpaces));\n    });\n  });\n\n  describe('Error State Clearing', () => {\n    it('should clear error on successful refresh', async () => {\n      (global.fetch as any).mockRejectedValueOnce(new Error('Initial error'));\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.error).toBeDefined();\n      });\n\n      // Mock successful response\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      // Refresh\n      await act(async () => {\n        await result.current.refresh();\n      });\n\n      // Error should be cleared\n      expect(result.current.error).toBeNull();\n      expect(result.current.diagram).toBe(mockApiResponse.diagram);\n    });\n\n    it('should clear error when receiving successful CustomEvent', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => mockApiResponse,\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Simulate event with error data\n      act(() => {\n        const event = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              ...mockApiResponse,\n              updatedTaskId: 'task-1',\n              updatedStatus: 'completed',\n            },\n          },\n        });\n        window.dispatchEvent(event);\n      });\n\n      // Error should remain null\n      expect(result.current.error).toBeNull();\n    });\n  });\n\n  describe('Multiple Rapid Updates', () => {\n    it('should handle multiple rapid CustomEvents (latest wins)', async () => {\n      (global.fetch as any).mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({\n          diagram: 'initial',\n          batches: [],\n          completedTasks: [],\n          pendingTasks: [],\n        }),\n      });\n\n      const { result } = renderHook(() => useTaskGraph(mockProject, mockSession));\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Send multiple events rapidly\n      act(() => {\n        const event1 = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              ...mockApiResponse,\n              diagram: 'diagram v1',\n              updatedTaskId: 'task-1',\n              updatedStatus: 'completed',\n            },\n          },\n        });\n        window.dispatchEvent(event1);\n\n        const event2 = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              ...mockApiResponse,\n              diagram: 'diagram v2',\n              updatedTaskId: 'task-2',\n              updatedStatus: 'in_progress',\n            },\n          },\n        });\n        window.dispatchEvent(event2);\n\n        const event3 = new CustomEvent('task_graph_updated', {\n          detail: {\n            project: mockProject,\n            session: mockSession,\n            payload: {\n              ...mockApiResponse,\n              diagram: 'diagram v3',\n              updatedTaskId: 'task-3',\n              updatedStatus: 'pending',\n            },\n          },\n        });\n        window.dispatchEvent(event3);\n      });\n\n      // Latest should win\n      expect(result.current.diagram).toBe('diagram v3');\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useTheme.test.ts": "/**\n * useTheme Hook Tests\n *\n * Tests verify:\n * - Hook initialization with current theme\n * - Theme getter and setter\n * - Theme toggle functionality\n * - Persistence via UI store\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useTheme } from '../useTheme';\nimport { useUIStore } from '../../stores/uiStore';\n\ndescribe('useTheme', () => {\n  beforeEach(() => {\n    // Clear localStorage and reset store before each test\n    localStorage.clear();\n    useUIStore.getState().reset();\n  });\n\n  afterEach(() => {\n    localStorage.clear();\n  });\n\n  describe('Initialization', () => {\n    it('should initialize with theme from store', () => {\n      const { result } = renderHook(() => useTheme());\n\n      // Should have a valid theme\n      expect(['light', 'dark']).toContain(result.current.theme);\n    });\n\n    it('should match UI store theme', () => {\n      const { result } = renderHook(() => useTheme());\n      const storeTheme = useUIStore.getState().theme;\n\n      expect(result.current.theme).toBe(storeTheme);\n    });\n  });\n\n  describe('Theme Management', () => {\n    it('should set theme to light', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('light');\n      });\n\n      expect(result.current.theme).toBe('light');\n    });\n\n    it('should set theme to dark', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('dark');\n      });\n\n      expect(result.current.theme).toBe('dark');\n    });\n\n    it('should persist theme change to store', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('dark');\n      });\n\n      expect(useUIStore.getState().theme).toBe('dark');\n    });\n  });\n\n  describe('Theme Toggle', () => {\n    it('should toggle from light to dark', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('light');\n      });\n\n      expect(result.current.theme).toBe('light');\n\n      act(() => {\n        result.current.toggleTheme();\n      });\n\n      expect(result.current.theme).toBe('dark');\n    });\n\n    it('should toggle from dark to light', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('dark');\n      });\n\n      expect(result.current.theme).toBe('dark');\n\n      act(() => {\n        result.current.toggleTheme();\n      });\n\n      expect(result.current.theme).toBe('light');\n    });\n\n    it('should toggle multiple times', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('light');\n      });\n\n      const initial = result.current.theme;\n\n      act(() => {\n        result.current.toggleTheme();\n      });\n\n      const after1 = result.current.theme;\n      expect(after1).not.toBe(initial);\n\n      act(() => {\n        result.current.toggleTheme();\n      });\n\n      expect(result.current.theme).toBe(initial);\n    });\n  });\n\n  describe('Persistence', () => {\n    it('should persist theme to localStorage via UI store', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('dark');\n      });\n\n      const stored = localStorage.getItem('ui-preferences');\n      expect(stored).toBeDefined();\n\n      if (stored) {\n        const data = JSON.parse(stored);\n        expect(data.state.theme).toBe('dark');\n      }\n    });\n  });\n\n  describe('Multiple Hooks', () => {\n    it('should share state between multiple hook instances', () => {\n      const { result: result1 } = renderHook(() => useTheme());\n      const { result: result2 } = renderHook(() => useTheme());\n\n      act(() => {\n        result1.current.setTheme('dark');\n      });\n\n      expect(result2.current.theme).toBe('dark');\n    });\n\n    it('should update all hooks when one changes theme', () => {\n      const { result: result1 } = renderHook(() => useTheme());\n      const { result: result2 } = renderHook(() => useTheme());\n      const { result: result3 } = renderHook(() => useTheme());\n\n      act(() => {\n        result1.current.toggleTheme();\n      });\n\n      expect(result2.current.theme).toBe(result1.current.theme);\n      expect(result3.current.theme).toBe(result1.current.theme);\n    });\n  });\n\n  describe('Edge Cases', () => {\n    it('should handle rapid theme changes', () => {\n      const { result } = renderHook(() => useTheme());\n\n      act(() => {\n        result.current.setTheme('light');\n        result.current.toggleTheme();\n        result.current.toggleTheme();\n        result.current.setTheme('dark');\n      });\n\n      expect(result.current.theme).toBe('dark');\n    });\n  });\n});\n",
        "ui/src/hooks/__tests__/useWebSocket.test.ts": "/**\n * useWebSocket Hook Tests\n *\n * Tests verify:\n * - Hook initialization and connection\n * - Connection state management\n * - Auto-connection and disconnection on mount/unmount\n * - Message sending capability\n * - Channel subscription/unsubscription\n * - Error handling during connection\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useWebSocket } from '../useWebSocket';\nimport { WebSocketClient, resetWebSocketClient } from '../../lib/websocket';\n\n// Mock WebSocketClient\nvi.mock('../../lib/websocket', () => {\n  const mockHandlers = {\n    connect: [] as (() => void)[],\n    disconnect: [] as (() => void)[],\n    message: [] as ((msg: any) => void)[],\n  };\n\n  class MockWebSocketClient {\n    url: string;\n    isConnectedState = false;\n    pendingSend: any[] = [];\n    subscriptions: Set<string> = new Set();\n\n    constructor(url: string) {\n      this.url = url;\n    }\n\n    async connect(): Promise<void> {\n      this.isConnectedState = true;\n      mockHandlers.connect.forEach((h) => h());\n    }\n\n    disconnect(): void {\n      this.isConnectedState = false;\n      mockHandlers.disconnect.forEach((h) => h());\n    }\n\n    send(message: any): void {\n      if (this.isConnectedState) {\n        this.pendingSend.push(message);\n      }\n    }\n\n    subscribe(channel: string): void {\n      this.subscriptions.add(channel);\n    }\n\n    unsubscribe(channel: string): void {\n      this.subscriptions.delete(channel);\n    }\n\n    isConnected(): boolean {\n      return this.isConnectedState;\n    }\n\n    onConnect(handler: () => void) {\n      mockHandlers.connect.push(handler);\n      return { unsubscribe: () => { /* mock */ } };\n    }\n\n    onDisconnect(handler: () => void) {\n      mockHandlers.disconnect.push(handler);\n      return { unsubscribe: () => { /* mock */ } };\n    }\n\n    onMessage(handler: (msg: any) => void) {\n      mockHandlers.message.push(handler);\n      return { unsubscribe: () => { /* mock */ } };\n    }\n  }\n\n  return {\n    WebSocketClient: MockWebSocketClient,\n    getWebSocketClient: () => new MockWebSocketClient('ws://test'),\n    resetWebSocketClient: () => { /* mock */ },\n  };\n});\n\ndescribe('useWebSocket', () => {\n  beforeEach(() => {\n    resetWebSocketClient();\n    vi.clearAllMocks();\n  });\n\n  afterEach(() => {\n    resetWebSocketClient();\n  });\n\n  describe('Initialization', () => {\n    it('should initialize with disconnected state', () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      expect(result.current.isConnected).toBe(false);\n      expect(result.current.isConnecting).toBe(false);\n      expect(result.current.error).toBe(null);\n    });\n\n    it('should auto-connect on mount when autoConnect is true', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, true));\n\n      await act(async () => {\n        // Give time for auto-connect\n        await new Promise((resolve) => setTimeout(resolve, 100));\n      });\n\n      expect(result.current.isConnecting || result.current.isConnected).toBe(true);\n    });\n\n    it('should not auto-connect on mount when autoConnect is false', () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      expect(result.current.isConnected).toBe(false);\n      expect(result.current.isConnecting).toBe(false);\n    });\n  });\n\n  describe('Connection Management', () => {\n    it('should connect to WebSocket', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      expect(result.current.isConnected).toBe(true);\n    });\n\n    it('should disconnect from WebSocket', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      expect(result.current.isConnected).toBe(true);\n\n      act(() => {\n        result.current.disconnect();\n      });\n\n      expect(result.current.isConnected).toBe(false);\n    });\n\n    it('should handle connection errors gracefully', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      // Mock a failed connection\n      vi.spyOn(WebSocketClient.prototype, 'connect').mockRejectedValueOnce(\n        new Error('Connection failed')\n      );\n\n      await act(async () => {\n        try {\n          await result.current.connect();\n        } catch {\n          // Expected\n        }\n      });\n\n      expect(result.current.error).toBeDefined();\n    });\n  });\n\n  describe('Message Operations', () => {\n    it('should send a message', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      const message = { type: 'test', data: 'hello' };\n\n      act(() => {\n        result.current.send(message);\n      });\n\n      // Verify send was called (implementation detail varies)\n      expect(result.current.isConnected).toBe(true);\n    });\n  });\n\n  describe('Subscription Management', () => {\n    it('should subscribe to a channel', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      act(() => {\n        result.current.subscribe('diagrams');\n      });\n\n      expect(result.current.isConnected).toBe(true);\n    });\n\n    it('should unsubscribe from a channel', async () => {\n      const { result } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      act(() => {\n        result.current.subscribe('diagrams');\n        result.current.unsubscribe('diagrams');\n      });\n\n      expect(result.current.isConnected).toBe(true);\n    });\n  });\n\n  describe('Cleanup', () => {\n    it('should clean up on unmount', async () => {\n      const { result, unmount } = renderHook(() => useWebSocket(undefined, false));\n\n      await act(async () => {\n        await result.current.connect();\n      });\n\n      expect(result.current.isConnected).toBe(true);\n\n      unmount();\n\n      // Hook should be cleaned up without errors\n      expect(true).toBe(true);\n    });\n  });\n});\n",
        "ui/src/hooks/useAgentStatus.ts": "/**\n * useAgentStatus Hook\n *\n * Provides real-time agent status tracking with:\n * - HTTP polling from /api/status endpoint\n * - WebSocket real-time updates\n * - Configurable polling interval\n * - Graceful error handling\n * - Loading state management\n */\n\nimport { useEffect, useState, useCallback } from 'react';\n\nexport interface AgentStatusState {\n  agentStatus: 'working' | 'waiting' | 'idle';\n  agentMessage?: string;\n  agentIsLoading: boolean;\n}\n\n/**\n * Hook for monitoring agent status\n *\n * Fetches status from /api/status and listens\n * to WebSocket events for real-time updates.\n *\n * @param pollInterval - Polling interval in milliseconds (default: 2000)\n * @returns Current agent status, message, and loading state\n *\n * @example\n * ```tsx\n * function StatusDisplay() {\n *   const { status, message, isLoading } = useAgentStatus(2000);\n *\n *   if (isLoading) return <div>Loading...</div>;\n *\n *   return (\n *     <div>\n *       Status: {status}\n *       {message && <p>{message}</p>}\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useAgentStatus(pollInterval = 2000): AgentStatusState {\n  const [state, setState] = useState<AgentStatusState>({\n    agentStatus: 'idle',\n    agentMessage: undefined,\n    agentIsLoading: true,\n  });\n\n  // Fetch status from API\n  const fetchStatus = useCallback(async () => {\n    try {\n      const response = await fetch('/api/status');\n      if (!response.ok) {\n        throw new Error(`Status: ${response.status}`);\n      }\n      const data = await response.json();\n\n      // Validate response has required status field\n      if (data.status && ['working', 'waiting', 'idle'].includes(data.status)) {\n        setState((prev) => ({\n          agentStatus: data.status,\n          agentMessage: data.message || undefined,\n          agentIsLoading: false,\n        }));\n      } else {\n        // Keep previous state if response is invalid\n        setState((prev) => ({\n          ...prev,\n          agentIsLoading: false,\n        }));\n      }\n    } catch (error) {\n      // Log error but don't throw - keep last known state\n      console.error('Failed to fetch agent status:', error);\n      setState((prev) => ({\n        ...prev,\n        agentIsLoading: false,\n      }));\n    }\n  }, []);\n\n  // Setup polling and WebSocket listeners on mount\n  useEffect(() => {\n    // Initial fetch\n    fetchStatus();\n\n    // Setup polling interval\n    const pollId = setInterval(fetchStatus, pollInterval);\n\n    // Setup WebSocket listener for real-time updates\n    const handleStatusChanged = (event: CustomEvent) => {\n      const { status, message } = event.detail || {};\n      if (status && ['working', 'waiting', 'idle'].includes(status)) {\n        setState({\n          agentStatus: status,\n          agentMessage: message,\n          agentIsLoading: false,\n        });\n      }\n    };\n\n    window.addEventListener('status_changed', handleStatusChanged as EventListener);\n\n    // Cleanup on unmount\n    return () => {\n      clearInterval(pollId);\n      window.removeEventListener('status_changed', handleStatusChanged as EventListener);\n    };\n  }, [pollInterval, fetchStatus]);\n\n  return state;\n}\n",
        "ui/src/hooks/useAutoSave.ts": "/**\n * useAutoSave Hook\n *\n * Provides automatic saving functionality with debouncing:\n * - Tracks content changes against original content\n * - Debounces save operations by configurable delay (default 2s)\n * - Tracks saving state and last saved timestamp\n * - Handles async save operations with error handling\n * - Cleans up timers on unmount\n */\n\nimport { useState, useRef, useEffect, useCallback } from 'react';\n\nexport interface UseAutoSaveReturn {\n  isSaving: boolean;\n  lastSaved: number | null;\n  hasUnsavedChanges: boolean;\n}\n\nconst DEFAULT_DELAY = 2000;\n\n/**\n * Hook for automatic content saving with debounce\n *\n * Monitors content changes and triggers save after a delay of inactivity.\n * Useful for editors that need to auto-save without overwhelming the server.\n *\n * @param content - The current content to monitor for changes\n * @param onSave - Async callback to perform the save operation\n * @param delay - Debounce delay in milliseconds (default: 2000ms)\n * @param key - Optional key to reset the hook when switching items (e.g., item ID)\n * @returns Object with isSaving, lastSaved timestamp, and hasUnsavedChanges flag\n *\n * @example\n * ```tsx\n * function Editor() {\n *   const [content, setContent] = useState('');\n *   const { isSaving, lastSaved, hasUnsavedChanges } = useAutoSave(\n *     content,\n *     async (content) => {\n *       await api.saveDocument(content);\n *     },\n *     2000,\n *     selectedItemId // Reset when item changes\n *   );\n *\n *   return (\n *     <div>\n *       <textarea value={content} onChange={(e) => setContent(e.target.value)} />\n *       {isSaving && <span>Saving...</span>}\n *       {hasUnsavedChanges && <span>Unsaved changes</span>}\n *       {lastSaved && <span>Last saved: {new Date(lastSaved).toLocaleTimeString()}</span>}\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useAutoSave(\n  content: string,\n  onSave: (content: string) => Promise<void>,\n  delay: number = DEFAULT_DELAY,\n  key?: string | null\n): UseAutoSaveReturn {\n  // State for tracking save status\n  const [isSaving, setIsSaving] = useState(false);\n  const [lastSaved, setLastSaved] = useState<number | null>(null);\n  const [hasUnsavedChanges, setHasUnsavedChanges] = useState(false);\n\n  // Refs for tracking original content and debounce timer\n  const originalContentRef = useRef<string>(content);\n  const debounceTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);\n\n  // Ref to track if component is mounted (for async safety)\n  const isMountedRef = useRef(true);\n\n  // Stable reference to onSave to avoid effect re-runs\n  const onSaveRef = useRef(onSave);\n  onSaveRef.current = onSave;\n\n  // Track the key to detect item changes\n  const keyRef = useRef(key);\n\n  // Reset original content when key changes (e.g., switching items)\n  // This prevents triggering a save when switching between items\n  useEffect(() => {\n    if (key !== keyRef.current) {\n      keyRef.current = key;\n      originalContentRef.current = content;\n      setHasUnsavedChanges(false);\n      setLastSaved(null);\n\n      // Clear any pending save timer\n      if (debounceTimerRef.current) {\n        clearTimeout(debounceTimerRef.current);\n        debounceTimerRef.current = null;\n      }\n    }\n  }, [key, content]);\n\n  // Perform the save operation\n  const performSave = useCallback(async (contentToSave: string) => {\n    if (!isMountedRef.current) return;\n\n    setIsSaving(true);\n    try {\n      await onSaveRef.current(contentToSave);\n\n      if (isMountedRef.current) {\n        const now = Date.now();\n        setLastSaved(now);\n        originalContentRef.current = contentToSave;\n        setHasUnsavedChanges(false);\n      }\n    } catch (error) {\n      // Log error but don't throw - the hook consumer can implement\n      // their own error handling in the onSave callback\n      console.error('Auto-save failed:', error);\n    } finally {\n      if (isMountedRef.current) {\n        setIsSaving(false);\n      }\n    }\n  }, []);\n\n  // Watch for content changes and trigger debounced save\n  useEffect(() => {\n    // Clear any existing timer\n    if (debounceTimerRef.current) {\n      clearTimeout(debounceTimerRef.current);\n      debounceTimerRef.current = null;\n    }\n\n    // Check if content has changed from original\n    if (content !== originalContentRef.current) {\n      setHasUnsavedChanges(true);\n\n      // Start new debounce timer\n      debounceTimerRef.current = setTimeout(() => {\n        performSave(content);\n      }, delay);\n    } else {\n      setHasUnsavedChanges(false);\n    }\n\n    // Cleanup timer on effect re-run\n    return () => {\n      if (debounceTimerRef.current) {\n        clearTimeout(debounceTimerRef.current);\n        debounceTimerRef.current = null;\n      }\n    };\n  }, [content, delay, performSave]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    isMountedRef.current = true;\n\n    return () => {\n      isMountedRef.current = false;\n      if (debounceTimerRef.current) {\n        clearTimeout(debounceTimerRef.current);\n        debounceTimerRef.current = null;\n      }\n    };\n  }, []);\n\n  return {\n    isSaving,\n    lastSaved,\n    hasUnsavedChanges,\n  };\n}\n",
        "ui/src/hooks/useDataLoader.ts": "/**\n * useDataLoader Hook\n *\n * Provides async functions to load sessions and session items (diagrams/documents)\n * from the API and populate the session store.\n *\n * Features:\n * - Load all available sessions\n * - Load diagrams and documents for a specific session\n * - Track loading and error states\n */\n\nimport { useState, useCallback } from 'react';\nimport { api } from '@/lib/api';\nimport { useSessionStore } from '@/stores/sessionStore';\n\nexport interface UseDataLoaderReturn {\n  /** Whether a data loading operation is in progress */\n  isLoading: boolean;\n  /** Error message if the last operation failed */\n  error: string | null;\n  /** Load all available sessions from the API */\n  loadSessions: () => Promise<void>;\n  /** Load diagrams and documents for a specific session */\n  loadSessionItems: (project: string, session: string) => Promise<void>;\n  /** Refresh session items while preserving current selection */\n  refreshSessionItems: (project: string, session: string) => Promise<void>;\n  /** Select a diagram and fetch its content */\n  selectDiagramWithContent: (project: string, session: string, id: string) => Promise<void>;\n  /** Select a document and fetch its content */\n  selectDocumentWithContent: (project: string, session: string, id: string) => Promise<void>;\n}\n\n/**\n * Hook to load sessions and session items from the API\n *\n * @returns Object with loading state, error state, and load functions\n *\n * @example\n * ```tsx\n * function SessionLoader() {\n *   const { isLoading, error, loadSessions, loadSessionItems } = useDataLoader();\n *\n *   useEffect(() => {\n *     loadSessions();\n *   }, [loadSessions]);\n *\n *   const handleSessionSelect = (session) => {\n *     loadSessionItems(session.project, session.name);\n *   };\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error}</div>;\n *\n *   return <div>Sessions loaded!</div>;\n * }\n * ```\n */\nexport function useDataLoader(): UseDataLoaderReturn {\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  // Get store setters\n  const setSessions = useSessionStore((state) => state.setSessions);\n  const setDiagrams = useSessionStore((state) => state.setDiagrams);\n  const setDocuments = useSessionStore((state) => state.setDocuments);\n  const selectDiagram = useSessionStore((state) => state.selectDiagram);\n  const selectDocument = useSessionStore((state) => state.selectDocument);\n  const updateDiagram = useSessionStore((state) => state.updateDiagram);\n  const updateDocument = useSessionStore((state) => state.updateDocument);\n  const setCollabState = useSessionStore((state) => state.setCollabState);\n\n  /**\n   * Load all available sessions from the API\n   */\n  const loadSessions = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      const sessions = await api.getSessions();\n      setSessions(sessions);\n    } catch (err) {\n      const message = err instanceof Error ? err.message : 'Failed to load sessions';\n      setError(message);\n    } finally {\n      setIsLoading(false);\n    }\n  }, [setSessions]);\n\n  /**\n   * Load collab session state\n   */\n  const loadCollabState = useCallback(\n    async (project: string, session: string) => {\n      try {\n        const state = await api.getSessionState(project, session);\n        setCollabState(state);\n      } catch (err) {\n        console.error('Failed to load collab state:', err);\n        setCollabState(null);\n      }\n    },\n    [setCollabState]\n  );\n\n  /**\n   * Load diagrams and documents for a specific session\n   */\n  const loadSessionItems = useCallback(\n    async (project: string, session: string) => {\n      setIsLoading(true);\n      setError(null);\n\n      try {\n        const diagrams = await api.getDiagrams(project, session);\n        const documents = await api.getDocuments(project, session);\n        setDiagrams(diagrams);\n        setDocuments(documents);\n\n        // Also load collab state\n        await loadCollabState(project, session);\n      } catch (err) {\n        const message = err instanceof Error ? err.message : 'Failed to load session items';\n        setError(message);\n      } finally {\n        setIsLoading(false);\n      }\n    },\n    [setDiagrams, setDocuments, loadCollabState]\n  );\n\n  /**\n   * Refresh session items while preserving current selection\n   */\n  const refreshSessionItems = useCallback(\n    async (project: string, session: string) => {\n      // Capture current selection\n      const { selectedDiagramId, selectedDocumentId } = useSessionStore.getState();\n\n      // Load fresh data\n      await loadSessionItems(project, session);\n\n      // Restore selection if items still exist\n      const { diagrams: newDiagrams, documents: newDocuments } = useSessionStore.getState();\n\n      if (selectedDiagramId && newDiagrams.find((d) => d.id === selectedDiagramId)) {\n        selectDiagram(selectedDiagramId);\n      } else if (selectedDocumentId && newDocuments.find((d) => d.id === selectedDocumentId)) {\n        selectDocument(selectedDocumentId);\n      }\n    },\n    [loadSessionItems, selectDiagram, selectDocument]\n  );\n\n  /**\n   * Select a diagram and fetch its full content\n   */\n  const selectDiagramWithContent = useCallback(\n    async (project: string, session: string, id: string) => {\n      // First, set the selection (for immediate UI feedback)\n      selectDiagram(id);\n\n      // Then fetch the full content\n      try {\n        const diagram = await api.getDiagram(project, session, id);\n        if (diagram) {\n          // Update the diagram in the store with its content\n          updateDiagram(id, { content: diagram.content });\n        }\n      } catch (err) {\n        const message = err instanceof Error ? err.message : 'Failed to load diagram content';\n        setError(message);\n      }\n    },\n    [selectDiagram, updateDiagram]\n  );\n\n  /**\n   * Select a document and fetch its full content\n   */\n  const selectDocumentWithContent = useCallback(\n    async (project: string, session: string, id: string) => {\n      // First, set the selection (for immediate UI feedback)\n      selectDocument(id);\n\n      // Then fetch the full content\n      try {\n        const document = await api.getDocument(project, session, id);\n        if (document) {\n          // Update the document in the store with its content\n          updateDocument(id, { content: document.content });\n        }\n      } catch (err) {\n        const message = err instanceof Error ? err.message : 'Failed to load document content';\n        setError(message);\n      }\n    },\n    [selectDocument, updateDocument]\n  );\n\n  return {\n    isLoading,\n    error,\n    loadSessions,\n    loadSessionItems,\n    refreshSessionItems,\n    selectDiagramWithContent,\n    selectDocumentWithContent,\n  };\n}\n",
        "ui/src/hooks/useDiagram.ts": "/**\n * useDiagram Hook\n *\n * Provides React integration for diagram operations with:\n * - Access to diagrams in current session\n * - Diagram selection management\n * - Diagram CRUD operations\n * - Selected diagram convenience getter\n */\n\nimport { useCallback } from 'react';\nimport { useShallow } from 'zustand/react/shallow';\nimport { Diagram } from '../types';\nimport { useSessionStore } from '../stores/sessionStore';\n\nexport interface UseDiagramReturn {\n  // Diagram state\n  diagrams: Diagram[];\n  selectedDiagramId: string | null;\n  selectedDiagram: Diagram | undefined;\n\n  // Diagram operations\n  addDiagram: (diagram: Diagram) => void;\n  updateDiagram: (id: string, updates: Partial<Diagram>) => void;\n  removeDiagram: (id: string) => void;\n  selectDiagram: (id: string | null) => void;\n\n  // Bulk operations\n  setDiagrams: (diagrams: Diagram[]) => void;\n\n  // Utility\n  getDiagramById: (id: string) => Diagram | undefined;\n  hasDiagram: (id: string) => boolean;\n}\n\n/**\n * Hook for accessing and managing diagrams in the current session\n *\n * Provides convenient access to diagram state and operations from the session store\n *\n * @returns Diagram state and operation methods\n *\n * @example\n * ```tsx\n * function DiagramList() {\n *   const { diagrams, selectedDiagram, selectDiagram, removeDiagram } = useDiagram();\n *\n *   return (\n *     <div>\n *       {diagrams.map((d) => (\n *         <div\n *           key={d.id}\n *           onClick={() => selectDiagram(d.id)}\n *           style={{\n *             fontWeight: selectedDiagram?.id === d.id ? 'bold' : 'normal',\n *           }}\n *         >\n *           <span>{d.name}</span>\n *           <button onClick={(e) => {\n *             e.stopPropagation();\n *             removeDiagram(d.id);\n *           }}>\n *             Delete\n *           </button>\n *         </div>\n *       ))}\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useDiagram(): UseDiagramReturn {\n  // Get diagram state using shallow comparison\n  const {\n    diagrams,\n    selectedDiagramId,\n    getSelectedDiagram,\n    setDiagrams,\n    addDiagram,\n    updateDiagram,\n    removeDiagram,\n    selectDiagram,\n  } = useSessionStore(\n    useShallow((state) => ({\n      diagrams: state.diagrams,\n      selectedDiagramId: state.selectedDiagramId,\n      getSelectedDiagram: state.getSelectedDiagram,\n      setDiagrams: state.setDiagrams,\n      addDiagram: state.addDiagram,\n      updateDiagram: state.updateDiagram,\n      removeDiagram: state.removeDiagram,\n      selectDiagram: state.selectDiagram,\n    }))\n  );\n\n  // Get selected diagram\n  const selectedDiagram = getSelectedDiagram();\n\n  // Get diagram by ID\n  const getDiagramById = useCallback(\n    (id: string): Diagram | undefined => {\n      return diagrams.find((d) => d.id === id);\n    },\n    [diagrams]\n  );\n\n  // Check if diagram exists\n  const hasDiagram = useCallback(\n    (id: string): boolean => {\n      return diagrams.some((d) => d.id === id);\n    },\n    [diagrams]\n  );\n\n  return {\n    diagrams,\n    selectedDiagramId,\n    selectedDiagram,\n    addDiagram: useCallback(\n      (diagram: Diagram) => {\n        addDiagram(diagram);\n      },\n      [addDiagram]\n    ),\n    updateDiagram: useCallback(\n      (id: string, updates: Partial<Diagram>) => {\n        updateDiagram(id, updates);\n      },\n      [updateDiagram]\n    ),\n    removeDiagram: useCallback(\n      (id: string) => {\n        removeDiagram(id);\n      },\n      [removeDiagram]\n    ),\n    selectDiagram: useCallback(\n      (id: string | null) => {\n        selectDiagram(id);\n      },\n      [selectDiagram]\n    ),\n    setDiagrams: useCallback(\n      (diagrams: Diagram[]) => {\n        setDiagrams(diagrams);\n      },\n      [setDiagrams]\n    ),\n    getDiagramById,\n    hasDiagram,\n  };\n}\n",
        "ui/src/hooks/useDiagramUpdateQueue.test.ts": "/**\n * useDiagramUpdateQueue Hook Tests\n *\n * Tests verify:\n * - Batching multiple updates to same diagram (only latest applied)\n * - Debounce timer resets on new updates\n * - flushNow applies updates immediately\n * - Cleanup on unmount\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useDiagramUpdateQueue } from './useDiagramUpdateQueue';\n\ndescribe('useDiagramUpdateQueue', () => {\n  beforeEach(() => {\n    vi.useFakeTimers();\n  });\n\n  afterEach(() => {\n    vi.useRealTimers();\n    vi.clearAllMocks();\n  });\n\n  describe('Batching updates', () => {\n    it('should batch multiple updates to the same diagram and only apply latest', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Queue multiple updates to the same diagram\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content-v1', 1000);\n        result.current.queueUpdate('diagram-1', 'content-v2', 2000);\n        result.current.queueUpdate('diagram-1', 'content-v3', 3000);\n      });\n\n      // No updates applied yet (debouncing)\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Advance timer past debounce period\n      act(() => {\n        vi.advanceTimersByTime(100);\n      });\n\n      // Only the latest update should be applied\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-1', {\n        content: 'content-v3',\n        lastModified: 3000,\n      });\n    });\n\n    it('should apply updates to different diagrams separately', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Queue updates to different diagrams\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content-1', 1000);\n        result.current.queueUpdate('diagram-2', 'content-2', 2000);\n        result.current.queueUpdate('diagram-3', 'content-3', 3000);\n      });\n\n      // Advance timer\n      act(() => {\n        vi.advanceTimersByTime(100);\n      });\n\n      // All three diagrams should be updated\n      expect(updateDiagram).toHaveBeenCalledTimes(3);\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-1', {\n        content: 'content-1',\n        lastModified: 1000,\n      });\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-2', {\n        content: 'content-2',\n        lastModified: 2000,\n      });\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-3', {\n        content: 'content-3',\n        lastModified: 3000,\n      });\n    });\n\n    it('should batch updates across multiple diagrams with latest per diagram', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Queue multiple updates to multiple diagrams\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content-1-v1', 1000);\n        result.current.queueUpdate('diagram-2', 'content-2-v1', 1100);\n        result.current.queueUpdate('diagram-1', 'content-1-v2', 1200);\n        result.current.queueUpdate('diagram-2', 'content-2-v2', 1300);\n      });\n\n      // Advance timer\n      act(() => {\n        vi.advanceTimersByTime(100);\n      });\n\n      // Only latest for each diagram\n      expect(updateDiagram).toHaveBeenCalledTimes(2);\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-1', {\n        content: 'content-1-v2',\n        lastModified: 1200,\n      });\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-2', {\n        content: 'content-2-v2',\n        lastModified: 1300,\n      });\n    });\n  });\n\n  describe('Debounce timer', () => {\n    it('should reset debounce timer on new updates', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Queue first update\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content-v1', 1000);\n      });\n\n      // Advance timer but not past debounce\n      act(() => {\n        vi.advanceTimersByTime(80);\n      });\n\n      // No updates yet\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Queue another update (should reset timer)\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content-v2', 2000);\n      });\n\n      // Advance by 80ms again (160ms total, but only 80ms since last update)\n      act(() => {\n        vi.advanceTimersByTime(80);\n      });\n\n      // Still no updates (timer was reset)\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Advance remaining 20ms\n      act(() => {\n        vi.advanceTimersByTime(20);\n      });\n\n      // Now the latest update should be applied\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-1', {\n        content: 'content-v2',\n        lastModified: 2000,\n      });\n    });\n\n    it('should use default debounce of 100ms', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() => useDiagramUpdateQueue(updateDiagram));\n\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n      });\n\n      // Not flushed at 99ms\n      act(() => {\n        vi.advanceTimersByTime(99);\n      });\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Flushed at 100ms\n      act(() => {\n        vi.advanceTimersByTime(1);\n      });\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n    });\n\n    it('should respect custom debounce time', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 500 })\n      );\n\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n      });\n\n      // Not flushed at 499ms\n      act(() => {\n        vi.advanceTimersByTime(499);\n      });\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Flushed at 500ms\n      act(() => {\n        vi.advanceTimersByTime(1);\n      });\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n    });\n  });\n\n  describe('flushNow', () => {\n    it('should apply updates immediately when flushNow is called', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n      });\n\n      // Not flushed yet\n      expect(updateDiagram).not.toHaveBeenCalled();\n\n      // Flush immediately\n      act(() => {\n        result.current.flushNow();\n      });\n\n      // Update applied immediately\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n      expect(updateDiagram).toHaveBeenCalledWith('diagram-1', {\n        content: 'content',\n        lastModified: 1000,\n      });\n    });\n\n    it('should cancel pending timer when flushNow is called', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n      });\n\n      // Flush immediately\n      act(() => {\n        result.current.flushNow();\n      });\n\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n\n      // Advance timer past debounce period\n      act(() => {\n        vi.advanceTimersByTime(200);\n      });\n\n      // Should not be called again (timer was cancelled)\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n    });\n\n    it('should do nothing if no pending updates', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Flush with no pending updates\n      act(() => {\n        result.current.flushNow();\n      });\n\n      expect(updateDiagram).not.toHaveBeenCalled();\n    });\n\n    it('should clear pending updates after flushNow', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n        result.current.flushNow();\n      });\n\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n\n      // Flush again - should not call updateDiagram\n      act(() => {\n        result.current.flushNow();\n      });\n\n      expect(updateDiagram).toHaveBeenCalledTimes(1);\n    });\n  });\n\n  describe('Cleanup on unmount', () => {\n    it('should clear timer on unmount', () => {\n      const updateDiagram = vi.fn();\n      const { result, unmount } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Queue an update\n      act(() => {\n        result.current.queueUpdate('diagram-1', 'content', 1000);\n      });\n\n      // Unmount before timer fires\n      unmount();\n\n      // Advance timer\n      act(() => {\n        vi.advanceTimersByTime(200);\n      });\n\n      // Update should not be applied (timer was cleared)\n      expect(updateDiagram).not.toHaveBeenCalled();\n    });\n\n    it('should not throw on unmount with no pending updates', () => {\n      const updateDiagram = vi.fn();\n      const { unmount } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      // Should not throw\n      expect(() => unmount()).not.toThrow();\n    });\n  });\n\n  describe('Return type', () => {\n    it('should return queueUpdate and flushNow functions', () => {\n      const updateDiagram = vi.fn();\n      const { result } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      expect(result.current).toHaveProperty('queueUpdate');\n      expect(result.current).toHaveProperty('flushNow');\n      expect(typeof result.current.queueUpdate).toBe('function');\n      expect(typeof result.current.flushNow).toBe('function');\n    });\n\n    it('should maintain stable function references', () => {\n      const updateDiagram = vi.fn();\n      const { result, rerender } = renderHook(() =>\n        useDiagramUpdateQueue(updateDiagram, { debounceMs: 100 })\n      );\n\n      const initialQueueUpdate = result.current.queueUpdate;\n      const initialFlushNow = result.current.flushNow;\n\n      // Re-render\n      rerender();\n\n      // Functions should be stable (same references)\n      expect(result.current.queueUpdate).toBe(initialQueueUpdate);\n      expect(result.current.flushNow).toBe(initialFlushNow);\n    });\n  });\n});\n",
        "ui/src/hooks/useDiagramUpdateQueue.ts": "/**\n * useDiagramUpdateQueue Hook\n *\n * Provides batched diagram update functionality with debouncing:\n * - Queues multiple updates to the same diagram\n * - Only applies the latest update per diagram when flushed\n * - Debounces updates by configurable delay (default 100ms)\n * - Supports immediate flush for critical operations\n * - Cleans up timers on unmount\n */\n\nimport { useCallback, useRef, useEffect } from 'react';\n\ninterface PendingUpdate {\n  id: string;\n  content: string;\n  lastModified: number;\n}\n\ninterface UseDiagramUpdateQueueOptions {\n  debounceMs?: number;\n}\n\nconst DEFAULT_DEBOUNCE_MS = 100;\n\n/**\n * Hook for batching diagram updates with debounce\n *\n * Queues updates and applies them in batches to reduce API calls.\n * Useful for rapid color updates or other frequent diagram modifications.\n *\n * @param updateDiagram - Callback to apply the update\n * @param options - Configuration options (debounceMs)\n * @returns Object with queueUpdate and flushNow functions\n *\n * @example\n * ```tsx\n * function DiagramEditor() {\n *   const { queueUpdate, flushNow } = useDiagramUpdateQueue(\n *     (id, updates) => {\n *       api.updateDiagram(id, updates);\n *     },\n *     { debounceMs: 100 }\n *   );\n *\n *   const handleColorChange = (diagramId: string, newContent: string) => {\n *     queueUpdate(diagramId, newContent, Date.now());\n *   };\n *\n *   const handleSave = () => {\n *     flushNow(); // Apply all pending updates immediately\n *   };\n * }\n * ```\n */\nexport function useDiagramUpdateQueue(\n  updateDiagram: (id: string, updates: { content: string; lastModified: number }) => void,\n  options: UseDiagramUpdateQueueOptions = {}\n) {\n  const { debounceMs = DEFAULT_DEBOUNCE_MS } = options;\n\n  // Map of pending updates by diagram ID\n  const pending = useRef<Map<string, PendingUpdate>>(new Map());\n\n  // Debounce timer reference\n  const timerRef = useRef<ReturnType<typeof setTimeout> | null>(null);\n\n  // Stable reference to updateDiagram to avoid effect re-runs\n  const updateDiagramRef = useRef(updateDiagram);\n  updateDiagramRef.current = updateDiagram;\n\n  /**\n   * Flush all pending updates atomically\n   */\n  const flush = useCallback(() => {\n    const updates = pending.current;\n    if (updates.size === 0) return;\n\n    // Apply all pending updates\n    updates.forEach((update) => {\n      updateDiagramRef.current(update.id, {\n        content: update.content,\n        lastModified: update.lastModified,\n      });\n    });\n\n    // Clear the pending map\n    pending.current = new Map();\n  }, []);\n\n  /**\n   * Queue an update for a diagram\n   * If an update for the same diagram already exists, it will be replaced\n   */\n  const queueUpdate = useCallback(\n    (id: string, content: string, lastModified: number) => {\n      // Add or replace the update in the pending map\n      pending.current.set(id, { id, content, lastModified });\n\n      // Clear existing timer\n      if (timerRef.current) {\n        clearTimeout(timerRef.current);\n        timerRef.current = null;\n      }\n\n      // Start new debounce timer\n      timerRef.current = setTimeout(() => {\n        flush();\n        timerRef.current = null;\n      }, debounceMs);\n    },\n    [debounceMs, flush]\n  );\n\n  /**\n   * Cancel timer and flush immediately\n   */\n  const flushNow = useCallback(() => {\n    // Cancel any pending timer\n    if (timerRef.current) {\n      clearTimeout(timerRef.current);\n      timerRef.current = null;\n    }\n\n    // Flush immediately\n    flush();\n  }, [flush]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      if (timerRef.current) {\n        clearTimeout(timerRef.current);\n        timerRef.current = null;\n      }\n    };\n  }, []);\n\n  return { queueUpdate, flushNow };\n}\n",
        "ui/src/hooks/useDocument.ts": "/**\n * useDocument Hook\n *\n * Provides React integration for document operations with:\n * - Access to documents in current session\n * - Document selection management\n * - Document CRUD operations\n * - Selected document convenience getter\n */\n\nimport { useCallback } from 'react';\nimport { useShallow } from 'zustand/react/shallow';\nimport { Document } from '../types';\nimport { useSessionStore } from '../stores/sessionStore';\n\nexport interface UseDocumentReturn {\n  // Document state\n  documents: Document[];\n  selectedDocumentId: string | null;\n  selectedDocument: Document | undefined;\n\n  // Document operations\n  addDocument: (document: Document) => void;\n  updateDocument: (id: string, updates: Partial<Document>) => void;\n  removeDocument: (id: string) => void;\n  selectDocument: (id: string | null) => void;\n\n  // Bulk operations\n  setDocuments: (documents: Document[]) => void;\n\n  // Utility\n  getDocumentById: (id: string) => Document | undefined;\n  hasDocument: (id: string) => boolean;\n}\n\n/**\n * Hook for accessing and managing documents in the current session\n *\n * Provides convenient access to document state and operations from the session store\n *\n * @returns Document state and operation methods\n *\n * @example\n * ```tsx\n * function DocumentList() {\n *   const { documents, selectedDocument, selectDocument, removeDocument } = useDocument();\n *\n *   return (\n *     <div>\n *       {documents.map((d) => (\n *         <div\n *           key={d.id}\n *           onClick={() => selectDocument(d.id)}\n *           style={{\n *             fontWeight: selectedDocument?.id === d.id ? 'bold' : 'normal',\n *           }}\n *         >\n *           <span>{d.name}</span>\n *           <button onClick={(e) => {\n *             e.stopPropagation();\n *             removeDocument(d.id);\n *           }}>\n *             Delete\n *           </button>\n *         </div>\n *       ))}\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useDocument(): UseDocumentReturn {\n  // Get document state using shallow comparison\n  const {\n    documents,\n    selectedDocumentId,\n    getSelectedDocument,\n    setDocuments,\n    addDocument,\n    updateDocument,\n    removeDocument,\n    selectDocument,\n  } = useSessionStore(\n    useShallow((state) => ({\n      documents: state.documents,\n      selectedDocumentId: state.selectedDocumentId,\n      getSelectedDocument: state.getSelectedDocument,\n      setDocuments: state.setDocuments,\n      addDocument: state.addDocument,\n      updateDocument: state.updateDocument,\n      removeDocument: state.removeDocument,\n      selectDocument: state.selectDocument,\n    }))\n  );\n\n  // Get selected document\n  const selectedDocument = getSelectedDocument();\n\n  // Get document by ID\n  const getDocumentById = useCallback(\n    (id: string): Document | undefined => {\n      return documents.find((d) => d.id === id);\n    },\n    [documents]\n  );\n\n  // Check if document exists\n  const hasDocument = useCallback(\n    (id: string): boolean => {\n      return documents.some((d) => d.id === id);\n    },\n    [documents]\n  );\n\n  return {\n    documents,\n    selectedDocumentId,\n    selectedDocument,\n    addDocument: useCallback(\n      (document: Document) => {\n        addDocument(document);\n      },\n      [addDocument]\n    ),\n    updateDocument: useCallback(\n      (id: string, updates: Partial<Document>) => {\n        updateDocument(id, updates);\n      },\n      [updateDocument]\n    ),\n    removeDocument: useCallback(\n      (id: string) => {\n        removeDocument(id);\n      },\n      [removeDocument]\n    ),\n    selectDocument: useCallback(\n      (id: string | null) => {\n        selectDocument(id);\n      },\n      [selectDocument]\n    ),\n    setDocuments: useCallback(\n      (documents: Document[]) => {\n        setDocuments(documents);\n      },\n      [setDocuments]\n    ),\n    getDocumentById,\n    hasDocument,\n  };\n}\n",
        "ui/src/hooks/useDocumentHistory.ts": "/**\n * useDocumentHistory Hook\n *\n * Fetches and subscribes to document history updates from the API.\n * Provides access to the document's change history and ability to\n * retrieve content at specific timestamps.\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport { useSession } from '@/hooks/useSession';\nimport type { DocumentHistory, UseDocumentHistoryReturn } from '@/types/history';\n\n/**\n * Hook for fetching and managing document history\n *\n * @param documentId - The document ID to fetch history for, or null\n * @returns Document history state and utility functions\n *\n * @example\n * ```tsx\n * function HistoryPanel({ documentId }: { documentId: string }) {\n *   const { history, isLoading, error, refetch, getVersionAt } = useDocumentHistory(documentId);\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error}</div>;\n *   if (!history) return <div>No history available</div>;\n *\n *   return (\n *     <div>\n *       <p>Original: {history.original}</p>\n *       <ul>\n *         {history.changes.map((change, i) => (\n *           <li key={i} onClick={() => getVersionAt(change.timestamp)}>\n *             {change.timestamp}\n *           </li>\n *         ))}\n *       </ul>\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useDocumentHistory(documentId: string | null): UseDocumentHistoryReturn {\n  const [history, setHistory] = useState<DocumentHistory | null>(null);\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const { currentSession } = useSession();\n  const project = currentSession?.project ?? null;\n  const session = currentSession?.name ?? null;\n\n  const fetchHistory = useCallback(async () => {\n    if (!documentId || !project || !session) {\n      setHistory(null);\n      return;\n    }\n\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      const params = new URLSearchParams({ project, session });\n      const response = await fetch(`/api/document/${documentId}/history?${params}`);\n\n      if (response.status === 404) {\n        setHistory(null); // No history yet, not an error\n      } else if (response.ok) {\n        const data = await response.json();\n        setHistory(data);\n      } else {\n        setError('Failed to load history');\n      }\n    } catch (err) {\n      setError('Network error');\n    } finally {\n      setIsLoading(false);\n    }\n  }, [documentId, project, session]);\n\n  const getVersionAt = useCallback(\n    async (timestamp: string): Promise<string | null> => {\n      if (!documentId || !project || !session) return null;\n\n      try {\n        const params = new URLSearchParams({ project, session, timestamp });\n        const response = await fetch(`/api/document/${documentId}/version?${params}`);\n\n        if (response.ok) {\n          const data = await response.json();\n          return data.content;\n        }\n      } catch (err) {\n        // Ignore errors, return null\n      }\n      return null;\n    },\n    [documentId, project, session]\n  );\n\n  // Fetch on mount and when documentId changes\n  useEffect(() => {\n    fetchHistory();\n  }, [fetchHistory]);\n\n  // TODO: Subscribe to WebSocket for document_history_updated messages\n  // Refetch when message.id === documentId\n\n  return { history, isLoading, error, refetch: fetchHistory, getVersionAt };\n}\n",
        "ui/src/hooks/useEditorHistory.ts": "/**\n * useEditorHistory Hook\n *\n * Manages undo/redo history for CodeMirror editor.\n * Tracks canUndo/canRedo state and exposes undo/redo functions.\n */\n\nimport { useRef, useState, useCallback } from 'react';\nimport { EditorView } from '@codemirror/view';\nimport {\n  undo as cmUndo,\n  redo as cmRedo,\n  undoDepth,\n  redoDepth,\n} from '@codemirror/commands';\nimport { StateEffect } from '@codemirror/state';\n\nexport interface UseEditorHistoryReturn {\n  editorRef: React.MutableRefObject<EditorView | null>;\n  setEditor: (view: EditorView | null) => void;\n  undo: () => void;\n  redo: () => void;\n  canUndo: boolean;\n  canRedo: boolean;\n}\n\nexport function useEditorHistory(): UseEditorHistoryReturn {\n  const editorRef = useRef<EditorView | null>(null);\n  const [canUndo, setCanUndo] = useState(false);\n  const [canRedo, setCanRedo] = useState(false);\n\n  const updateHistoryState = useCallback((view: EditorView) => {\n    try {\n      setCanUndo(undoDepth(view.state) > 0);\n      setCanRedo(redoDepth(view.state) > 0);\n    } catch {\n      // Silently ignore errors when computing history depth\n      // This can happen with incomplete mock objects in tests\n    }\n  }, []);\n\n  const setEditor = useCallback(\n    (view: EditorView | null) => {\n      editorRef.current = view;\n\n      if (view === null) {\n        setCanUndo(false);\n        setCanRedo(false);\n        return;\n      }\n\n      // Set up update listener to track undo/redo availability\n      const updateListener = EditorView.updateListener.of((update) => {\n        if (update.docChanged || update.transactions.length > 0) {\n          updateHistoryState(update.view);\n        }\n      });\n\n      // Add the update listener to the editor\n      try {\n        view.dispatch({\n          effects: StateEffect.appendConfig.of(updateListener),\n        });\n      } catch {\n        // Silently ignore dispatch errors in tests\n      }\n\n      // Set initial state\n      updateHistoryState(view);\n    },\n    [updateHistoryState]\n  );\n\n  const undo = useCallback(() => {\n    if (editorRef.current && canUndo) {\n      try {\n        cmUndo(editorRef.current);\n      } catch {\n        // Silently ignore undo errors\n      }\n    }\n  }, [canUndo]);\n\n  const redo = useCallback(() => {\n    if (editorRef.current && canRedo) {\n      try {\n        cmRedo(editorRef.current);\n      } catch {\n        // Silently ignore redo errors\n      }\n    }\n  }, [canRedo]);\n\n  return { editorRef, setEditor, undo, redo, canUndo, canRedo };\n}\n\nexport default useEditorHistory;\n",
        "ui/src/hooks/useExportDiagram.ts": "/**\n * useExportDiagram Hook\n *\n * Provides SVG and PNG export functionality for Mermaid diagrams.\n * - Handles SVG serialization with inline styles\n * - Converts SVG to PNG via canvas with 2x retina scaling\n * - Manages export state and download functionality\n */\n\nimport { useRef, useState, useCallback } from 'react';\n\nexport interface UseExportDiagramReturn {\n  svgContainerRef: React.RefCallback<HTMLDivElement>;\n  exportAsSVG: (filename: string) => void;\n  exportAsPNG: (filename: string) => Promise<void>;\n  canExport: boolean;\n}\n\n/**\n * Inlines computed styles into an SVG element recursively\n */\nfunction inlineStyles(element: Element): void {\n  const computed = window.getComputedStyle(element);\n  element.setAttribute('style', computed.cssText);\n\n  for (let i = 0; i < element.children.length; i++) {\n    inlineStyles(element.children[i]);\n  }\n}\n\n/**\n * Downloads a file from a blob URL\n */\nfunction downloadFile(url: string, filename: string): void {\n  const a = document.createElement('a');\n  a.href = url;\n  a.download = filename;\n  document.body.appendChild(a);\n  a.click();\n  document.body.removeChild(a);\n}\n\n/**\n * Hook for exporting Mermaid diagrams as SVG or PNG\n */\nexport function useExportDiagram(): UseExportDiagramReturn {\n  const containerRef = useRef<HTMLDivElement | null>(null);\n  const [canExport, setCanExport] = useState(false);\n\n  const svgContainerRef = useCallback((node: HTMLDivElement | null) => {\n    containerRef.current = node;\n    // Update canExport state based on whether SVG is present\n    if (node === null) {\n      setCanExport(false);\n    } else {\n      const hasSvg = node.querySelector('svg') !== null;\n      setCanExport(hasSvg);\n    }\n  }, []);\n\n  const exportAsSVG = useCallback((filename: string) => {\n    const container = containerRef.current;\n    if (container === null) {\n      return;\n    }\n\n    const svg = container.querySelector('svg');\n    if (svg === null) {\n      return;\n    }\n\n    // Clone SVG and inline styles\n    const clone = svg.cloneNode(true) as Element;\n    inlineStyles(clone);\n\n    // Serialize to string\n    const serializer = new XMLSerializer();\n    const svgString = serializer.serializeToString(clone);\n\n    // Create blob and download\n    const blob = new Blob([svgString], { type: 'image/svg+xml' });\n    const url = URL.createObjectURL(blob);\n    downloadFile(url, `${filename}.svg`);\n    URL.revokeObjectURL(url);\n  }, []);\n\n  const exportAsPNG = useCallback(\n    (filename: string) => {\n      return new Promise<void>((resolve) => {\n        const container = containerRef.current;\n        if (container === null) {\n          resolve();\n          return;\n        }\n\n        const svg = container.querySelector('svg');\n        if (svg === null) {\n          resolve();\n          return;\n        }\n\n        // Get SVG dimensions\n        let width: number;\n        let height: number;\n\n        try {\n          const bbox = svg.getBBox();\n          width = bbox.width || svg.clientWidth || 800;\n          height = bbox.height || svg.clientHeight || 600;\n        } catch {\n          // Fallback if getBBox fails\n          width = svg.clientWidth || 800;\n          height = svg.clientHeight || 600;\n        }\n\n        // Clone and inline styles\n        const clone = svg.cloneNode(true) as Element;\n        inlineStyles(clone);\n\n        // Create data URL from SVG\n        const serializer = new XMLSerializer();\n        const svgString = serializer.serializeToString(clone);\n        const svgDataUrl =\n          'data:image/svg+xml;charset=utf-8,' +\n          encodeURIComponent(svgString);\n\n        // Draw to canvas with 2x retina scaling\n        const canvas = document.createElement('canvas');\n        canvas.width = width * 2;\n        canvas.height = height * 2;\n\n        const ctx = canvas.getContext('2d');\n        if (ctx === null) {\n          resolve();\n          return;\n        }\n\n        ctx.scale(2, 2);\n\n        // Set a timeout to prevent hanging on image load\n        const timeoutId = setTimeout(() => {\n          resolve();\n        }, 10000);\n\n        const img = new Image();\n        img.onload = () => {\n          clearTimeout(timeoutId);\n          try {\n            ctx.drawImage(img, 0, 0);\n            canvas.toBlob((blob) => {\n              if (blob === null) {\n                resolve();\n                return;\n              }\n\n              const url = URL.createObjectURL(blob);\n              downloadFile(url, `${filename}.png`);\n              URL.revokeObjectURL(url);\n              resolve();\n            }, 'image/png');\n          } catch {\n            resolve();\n          }\n        };\n\n        img.onerror = () => {\n          clearTimeout(timeoutId);\n          resolve();\n        };\n\n        img.src = svgDataUrl;\n      });\n    },\n    []\n  );\n\n  return { svgContainerRef, exportAsSVG, exportAsPNG, canExport };\n}\n\nexport default useExportDiagram;\n",
        "ui/src/hooks/useIsMobile.test.ts": "/**\n * useIsMobile Hook Tests\n *\n * Tests verify:\n * - Mobile detection using matchMedia (< 640px)\n * - Desktop detection (>= 640px)\n * - Resize listener updates state\n * - No memory leaks from event listeners\n * - Proper cleanup on unmount\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useIsMobile } from './useIsMobile';\n\n// Helper to create mock matchMedia\nfunction createMockMatchMedia(matches: boolean) {\n  return {\n    matches,\n    media: '(max-width: 639px)',\n    onchange: null as ((event: MediaQueryListEvent) => void) | null,\n    addListener: vi.fn(),\n    removeListener: vi.fn(),\n    addEventListener: vi.fn(),\n    removeEventListener: vi.fn(),\n    dispatchEvent: vi.fn(),\n  } as unknown as MediaQueryList;\n}\n\ndescribe('useIsMobile', () => {\n  let originalMatchMedia: typeof window.matchMedia;\n\n  beforeEach(() => {\n    // Save original matchMedia\n    originalMatchMedia = window.matchMedia;\n  });\n\n  afterEach(() => {\n    // Restore original matchMedia\n    window.matchMedia = originalMatchMedia;\n    vi.clearAllMocks();\n  });\n\n  describe('Desktop detection', () => {\n    it('should return false for desktop viewport (>= 640px)', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n    });\n\n    it('should call matchMedia with correct media query', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      const matchMediaFn = vi.fn(() => mockMatchMedia);\n      window.matchMedia = matchMediaFn;\n\n      renderHook(() => useIsMobile());\n\n      expect(matchMediaFn).toHaveBeenCalledWith('(max-width: 639px)');\n    });\n\n    it('should add resize event listener', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      renderHook(() => useIsMobile());\n\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledWith('change', expect.any(Function));\n    });\n  });\n\n  describe('Mobile detection', () => {\n    it('should return true for mobile viewport (< 640px)', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(true);\n    });\n  });\n\n  describe('Viewport changes', () => {\n    it('should update state when viewport changes from desktop to mobile', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        // Capture the listener for manual triggering\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n\n      // Simulate window resize to mobile\n      if (changeListener) {\n        act(() => {\n          changeListener({\n            matches: true,\n            media: '(max-width: 639px)',\n          } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(true);\n    });\n\n    it('should update state when viewport changes from mobile to desktop', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(true);\n\n      // Simulate window resize to desktop\n      if (changeListener) {\n        act(() => {\n          changeListener({\n            matches: false,\n            media: '(max-width: 639px)',\n          } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(false);\n    });\n\n    it('should handle multiple rapid viewport changes', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      let changeListener: ((event: MediaQueryListEvent) => void) | null = null;\n\n      window.matchMedia = vi.fn(() => {\n        return {\n          ...mockMatchMedia,\n          addEventListener: vi.fn((event: string, listener: (event: MediaQueryListEvent) => void) => {\n            if (event === 'change') {\n              changeListener = listener;\n            }\n          }),\n        };\n      });\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(result.current).toBe(false);\n\n      // Rapid changes\n      if (changeListener) {\n        act(() => {\n          changeListener({ matches: true, media: '(max-width: 639px)' } as MediaQueryListEvent);\n          changeListener({ matches: false, media: '(max-width: 639px)' } as MediaQueryListEvent);\n          changeListener({ matches: true, media: '(max-width: 639px)' } as MediaQueryListEvent);\n        });\n      }\n\n      expect(result.current).toBe(true);\n    });\n  });\n\n  describe('Memory leaks', () => {\n    it('should remove event listener on unmount', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { unmount } = renderHook(() => useIsMobile());\n\n      unmount();\n\n      expect(mockMatchMedia.removeEventListener).toHaveBeenCalledWith('change', expect.any(Function));\n    });\n\n    it('should only add one event listener per hook instance', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      renderHook(() => useIsMobile());\n\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledTimes(1);\n    });\n\n    it('should not leak listeners on multiple renders', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { rerender } = renderHook(() => useIsMobile());\n\n      // Re-render multiple times\n      rerender();\n      rerender();\n      rerender();\n\n      // addEventListener should only be called once (in initial mount)\n      expect(mockMatchMedia.addEventListener).toHaveBeenCalledTimes(1);\n    });\n  });\n\n  describe('Return type', () => {\n    it('should return a boolean', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect(typeof result.current).toBe('boolean');\n    });\n\n    it('should always return a boolean value', () => {\n      const mockMatchMedia = createMockMatchMedia(true);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result } = renderHook(() => useIsMobile());\n\n      expect([true, false]).toContain(result.current);\n    });\n  });\n\n  describe('Edge cases', () => {\n    it('should handle matchMedia not being available gracefully', () => {\n      const originalWM = window.matchMedia;\n      // @ts-ignore - intentionally breaking matchMedia for test\n      window.matchMedia = undefined;\n\n      // Should not throw\n      expect(() => {\n        renderHook(() => useIsMobile());\n      }).not.toThrow();\n\n      window.matchMedia = originalWM;\n    });\n\n    it('should maintain consistent state across multiple hook instances', () => {\n      const mockMatchMedia = createMockMatchMedia(false);\n      window.matchMedia = vi.fn(() => mockMatchMedia);\n\n      const { result: result1 } = renderHook(() => useIsMobile());\n      const { result: result2 } = renderHook(() => useIsMobile());\n\n      expect(result1.current).toBe(result2.current);\n    });\n  });\n});\n",
        "ui/src/hooks/useIsMobile.ts": "/**\n * useIsMobile Hook\n *\n * Mobile detection hook using matchMedia to detect screens < 640px.\n * Updates state when window resizes.\n * Properly cleans up event listeners on unmount.\n */\n\nimport { useState, useEffect } from 'react';\n\n/**\n * Hook for detecting mobile viewport (< 640px width).\n * Uses window.matchMedia with resize listener to update on viewport changes.\n *\n * @returns boolean - true if viewport width is < 640px, false otherwise\n *\n * @example\n * ```tsx\n * function App() {\n *   const isMobile = useIsMobile();\n *\n *   return isMobile ? <MobileLayout /> : <DesktopLayout />;\n * }\n * ```\n */\nexport function useIsMobile(): boolean {\n  const [isMobile, setIsMobile] = useState<boolean>(() => {\n    // Initialize based on current viewport\n    if (typeof window === 'undefined') {\n      return false;\n    }\n\n    try {\n      const mediaQuery = window.matchMedia('(max-width: 639px)');\n      return mediaQuery.matches;\n    } catch {\n      return false;\n    }\n  });\n\n  useEffect(() => {\n    // Ensure window is available (client-side only)\n    if (typeof window === 'undefined') {\n      return;\n    }\n\n    try {\n      const mediaQuery = window.matchMedia('(max-width: 639px)');\n\n      // Handle media query changes\n      const handleChange = (e: MediaQueryListEvent) => {\n        setIsMobile(e.matches);\n      };\n\n      // Add listener for viewport changes\n      mediaQuery.addEventListener('change', handleChange);\n\n      // Cleanup function to remove listener\n      return () => {\n        mediaQuery.removeEventListener('change', handleChange);\n      };\n    } catch {\n      // If matchMedia is not supported, do nothing\n      return;\n    }\n  }, []);\n\n  return isMobile;\n}\n\nexport default useIsMobile;\n",
        "ui/src/hooks/useSession.ts": "/**\n * useSession Hook\n *\n * Provides React integration for session state management with:\n * - Access to current session state\n * - Loading and error state tracking\n * - Session selection and clearing\n * - Convenient selectors for diagrams and documents\n */\n\nimport { useCallback } from 'react';\nimport { useShallow } from 'zustand/react/shallow';\nimport { Session, Diagram, Document, CollabState } from '../types';\nimport { useSessionStore } from '../stores/sessionStore';\n\nexport interface UseSessionReturn {\n  // Session state\n  currentSession: Session | null;\n  isLoading: boolean;\n  error: string | null;\n\n  // Diagram state\n  diagrams: Diagram[];\n  selectedDiagramId: string | null;\n  selectedDiagram: Diagram | undefined;\n\n  // Document state\n  documents: Document[];\n  selectedDocumentId: string | null;\n  selectedDocument: Document | undefined;\n\n  // Collab state\n  collabState: CollabState | null;\n\n  // Session actions\n  setCurrentSession: (session: Session | null) => void;\n  setLoading: (loading: boolean) => void;\n  setError: (error: string | null) => void;\n\n  // Diagram actions\n  addDiagram: (diagram: Diagram) => void;\n  updateDiagram: (id: string, updates: Partial<Diagram>) => void;\n  removeDiagram: (id: string) => void;\n  selectDiagram: (id: string | null) => void;\n\n  // Document actions\n  addDocument: (document: Document) => void;\n  updateDocument: (id: string, updates: Partial<Document>) => void;\n  removeDocument: (id: string) => void;\n  selectDocument: (id: string | null) => void;\n\n  // Collab state actions\n  setCollabState: (state: CollabState | null) => void;\n\n  // Utility actions\n  clearSession: () => void;\n  reset: () => void;\n}\n\n/**\n * Hook for accessing session state and managing session data\n *\n * Provides convenient access to the session store with automatic\n * selector optimization to prevent unnecessary re-renders\n *\n * @returns Session state and action methods\n *\n * @example\n * ```tsx\n * function SessionComponent() {\n *   const { currentSession, isLoading, error, diagrams, selectDiagram } = useSession();\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error}</div>;\n *   if (!currentSession) return <div>No session selected</div>;\n *\n *   return (\n *     <div>\n *       <h1>{currentSession.name}</h1>\n *       <div>\n *         {diagrams.map((d) => (\n *           <button key={d.id} onClick={() => selectDiagram(d.id)}>\n *             {d.name}\n *           </button>\n *         ))}\n *       </div>\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useSession(): UseSessionReturn {\n  // Get state using shallow comparison to prevent unnecessary re-renders\n  const {\n    currentSession,\n    isLoading,\n    error,\n    diagrams,\n    selectedDiagramId,\n    documents,\n    selectedDocumentId,\n    collabState,\n    setCurrentSession,\n    setLoading,\n    setError,\n    setDiagrams,\n    addDiagram,\n    updateDiagram,\n    removeDiagram,\n    selectDiagram,\n    getSelectedDiagram,\n    setDocuments,\n    addDocument,\n    updateDocument,\n    removeDocument,\n    selectDocument,\n    getSelectedDocument,\n    setCollabState,\n    clearSession,\n    reset,\n  } = useSessionStore(\n    useShallow((state) => ({\n      currentSession: state.currentSession,\n      isLoading: state.isLoading,\n      error: state.error,\n      diagrams: state.diagrams,\n      selectedDiagramId: state.selectedDiagramId,\n      documents: state.documents,\n      selectedDocumentId: state.selectedDocumentId,\n      collabState: state.collabState,\n      setCurrentSession: state.setCurrentSession,\n      setLoading: state.setLoading,\n      setError: state.setError,\n      setDiagrams: state.setDiagrams,\n      addDiagram: state.addDiagram,\n      updateDiagram: state.updateDiagram,\n      removeDiagram: state.removeDiagram,\n      selectDiagram: state.selectDiagram,\n      getSelectedDiagram: state.getSelectedDiagram,\n      setDocuments: state.setDocuments,\n      addDocument: state.addDocument,\n      updateDocument: state.updateDocument,\n      removeDocument: state.removeDocument,\n      selectDocument: state.selectDocument,\n      getSelectedDocument: state.getSelectedDocument,\n      setCollabState: state.setCollabState,\n      clearSession: state.clearSession,\n      reset: state.reset,\n    }))\n  );\n\n  // Memoize selected diagram getter\n  const selectedDiagram = useCallback(() => {\n    return getSelectedDiagram();\n  }, [getSelectedDiagram])();\n\n  // Memoize selected document getter\n  const selectedDocument = useCallback(() => {\n    return getSelectedDocument();\n  }, [getSelectedDocument])();\n\n  return {\n    currentSession,\n    isLoading,\n    error,\n    diagrams,\n    selectedDiagramId,\n    selectedDiagram,\n    documents,\n    selectedDocumentId,\n    selectedDocument,\n    collabState,\n    setCurrentSession,\n    setLoading,\n    setError,\n    addDiagram,\n    updateDiagram,\n    removeDiagram,\n    selectDiagram,\n    addDocument,\n    updateDocument,\n    removeDocument,\n    selectDocument,\n    setCollabState,\n    clearSession,\n    reset,\n  };\n}\n",
        "ui/src/hooks/useSessionPolling.ts": "/**\n * useSessionPolling Hook\n *\n * Polls session state at regular intervals as a fallback mechanism\n * when WebSocket updates may be missed. Works alongside the WebSocket\n * handler for dual-channel status sync.\n */\n\nimport { useEffect, useRef } from 'react';\nimport { useShallow } from 'zustand/react/shallow';\nimport { useSessionStore } from '../stores/sessionStore';\n\n/**\n * Hook that polls session state at regular intervals\n *\n * @param project - Project path (null to disable polling)\n * @param session - Session name (null to disable polling)\n * @param intervalMs - Polling interval in milliseconds (default: 5000)\n *\n * @example\n * ```tsx\n * function App() {\n *   const { currentSession } = useSession();\n *   useSessionPolling(\n *     currentSession?.project ?? null,\n *     currentSession?.name ?? null,\n *     5000\n *   );\n * }\n * ```\n */\nexport function useSessionPolling(\n  project: string | null,\n  session: string | null,\n  intervalMs = 5000\n): void {\n  const { collabState, setCollabState } = useSessionStore(\n    useShallow((state) => ({\n      collabState: state.collabState,\n      setCollabState: state.setCollabState,\n    }))\n  );\n\n  // Use ref to track lastActivity to avoid stale closure issues\n  const lastActivityRef = useRef<string | undefined>(undefined);\n\n  useEffect(() => {\n    // Update ref when collabState changes\n    lastActivityRef.current = collabState?.lastActivity;\n  }, [collabState?.lastActivity]);\n\n  useEffect(() => {\n    // Skip polling if project or session is not provided\n    if (!project || !session) {\n      return;\n    }\n\n    const poll = async () => {\n      try {\n        const url = `/api/session-state?project=${encodeURIComponent(project)}&session=${encodeURIComponent(session)}`;\n        const response = await fetch(url);\n\n        if (!response.ok) {\n          // Silently ignore errors - polling should be resilient\n          return;\n        }\n\n        const newState = await response.json();\n\n        // Only update if state has changed (compare lastActivity)\n        if (newState.lastActivity !== lastActivityRef.current) {\n          setCollabState(newState);\n        }\n      } catch {\n        // Silently ignore network errors - polling continues on next interval\n      }\n    };\n\n    // Initial fetch\n    poll();\n\n    // Set up interval\n    const interval = setInterval(poll, intervalMs);\n\n    // Cleanup on unmount or dependency change\n    return () => clearInterval(interval);\n  }, [project, session, intervalMs, setCollabState]);\n}\n",
        "ui/src/hooks/useSyncScroll.test.ts": "/**\n * useSyncScroll Hook Tests\n *\n * Tests verify:\n * - Synchronized scrolling between editor and preview\n * - Debouncing prevents infinite scroll loops\n * - Toggle, enable, disable sync controls\n * - Cleanup on unmount\n * - Edge cases (division by zero, missing refs)\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useRef } from 'react';\nimport { useSyncScroll } from './useSyncScroll';\n\n// Helper to create mock scroll elements\nfunction createMockElement(options: {\n  scrollTop?: number;\n  scrollHeight?: number;\n  clientHeight?: number;\n} = {}): HTMLElement {\n  const element = {\n    scrollTop: options.scrollTop ?? 0,\n    scrollHeight: options.scrollHeight ?? 1000,\n    clientHeight: options.clientHeight ?? 500,\n    addEventListener: vi.fn(),\n    removeEventListener: vi.fn(),\n  } as unknown as HTMLElement;\n  return element;\n}\n\ndescribe('useSyncScroll', () => {\n  beforeEach(() => {\n    vi.useFakeTimers();\n  });\n\n  afterEach(() => {\n    vi.useRealTimers();\n    vi.clearAllMocks();\n  });\n\n  describe('Initial state', () => {\n    it('should initialize with enabled state from options', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      expect(result.current.isSynced).toBe(true);\n    });\n\n    it('should initialize with disabled state from options', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: false,\n        })\n      );\n\n      expect(result.current.isSynced).toBe(false);\n    });\n  });\n\n  describe('Sync controls', () => {\n    it('should toggle sync on/off with toggleSync', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      expect(result.current.isSynced).toBe(true);\n\n      act(() => {\n        result.current.toggleSync();\n      });\n\n      expect(result.current.isSynced).toBe(false);\n\n      act(() => {\n        result.current.toggleSync();\n      });\n\n      expect(result.current.isSynced).toBe(true);\n    });\n\n    it('should enable sync with enableSync', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: false,\n        })\n      );\n\n      expect(result.current.isSynced).toBe(false);\n\n      act(() => {\n        result.current.enableSync();\n      });\n\n      expect(result.current.isSynced).toBe(true);\n    });\n\n    it('should disable sync with disableSync', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      expect(result.current.isSynced).toBe(true);\n\n      act(() => {\n        result.current.disableSync();\n      });\n\n      expect(result.current.isSynced).toBe(false);\n    });\n  });\n\n  describe('Event listeners', () => {\n    it('should add scroll event listeners when synced', () => {\n      const editor = createMockElement();\n      const preview = createMockElement();\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      expect(editor.addEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n      expect(preview.addEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n    });\n\n    it('should not add event listeners when not synced', () => {\n      const editor = createMockElement();\n      const preview = createMockElement();\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: false,\n        })\n      );\n\n      expect(editor.addEventListener).not.toHaveBeenCalled();\n      expect(preview.addEventListener).not.toHaveBeenCalled();\n    });\n\n    it('should remove event listeners on cleanup', () => {\n      const editor = createMockElement();\n      const preview = createMockElement();\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      const { unmount } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      unmount();\n\n      expect(editor.removeEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n      expect(preview.removeEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n    });\n\n    it('should remove event listeners when sync is disabled', () => {\n      const editor = createMockElement();\n      const preview = createMockElement();\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      // Initially added\n      expect(editor.addEventListener).toHaveBeenCalledTimes(1);\n      expect(preview.addEventListener).toHaveBeenCalledTimes(1);\n\n      // Disable sync\n      act(() => {\n        result.current.disableSync();\n      });\n\n      // Event listeners should be removed\n      expect(editor.removeEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n      expect(preview.removeEventListener).toHaveBeenCalledWith('scroll', expect.any(Function));\n    });\n  });\n\n  describe('Scroll synchronization', () => {\n    it('should sync preview scroll when editor scrolls', () => {\n      const editor = createMockElement({\n        scrollTop: 250,\n        scrollHeight: 1000,\n        clientHeight: 500,\n      });\n      const preview = createMockElement({\n        scrollTop: 0,\n        scrollHeight: 2000,\n        clientHeight: 500,\n      });\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n          debounceMs: 16,\n        })\n      );\n\n      // Get the scroll handler\n      const editorScrollHandler = (editor.addEventListener as ReturnType<typeof vi.fn>).mock.calls[0][1];\n\n      // Simulate editor scroll\n      act(() => {\n        editorScrollHandler();\n        vi.advanceTimersByTime(16);\n      });\n\n      // Preview should be scrolled proportionally\n      // Editor: 250 / (1000 - 500) = 0.5\n      // Preview target: 0.5 * (2000 - 500) = 750\n      expect(preview.scrollTop).toBe(750);\n    });\n\n    it('should sync editor scroll when preview scrolls', () => {\n      const editor = createMockElement({\n        scrollTop: 0,\n        scrollHeight: 1000,\n        clientHeight: 500,\n      });\n      const preview = createMockElement({\n        scrollTop: 750,\n        scrollHeight: 2000,\n        clientHeight: 500,\n      });\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n          debounceMs: 16,\n        })\n      );\n\n      // Get the scroll handler\n      const previewScrollHandler = (preview.addEventListener as ReturnType<typeof vi.fn>).mock.calls[0][1];\n\n      // Simulate preview scroll\n      act(() => {\n        previewScrollHandler();\n        vi.advanceTimersByTime(16);\n      });\n\n      // Editor should be scrolled proportionally\n      // Preview: 750 / (2000 - 500) = 0.5\n      // Editor target: 0.5 * (1000 - 500) = 250\n      expect(editor.scrollTop).toBe(250);\n    });\n  });\n\n  describe('Debouncing', () => {\n    it('should use default debounce of 16ms', () => {\n      const editor = createMockElement({ scrollTop: 250, scrollHeight: 1000, clientHeight: 500 });\n      const preview = createMockElement({ scrollHeight: 2000, clientHeight: 500 });\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      const editorScrollHandler = (editor.addEventListener as ReturnType<typeof vi.fn>).mock.calls[0][1];\n\n      // Trigger scroll\n      act(() => {\n        editorScrollHandler();\n      });\n\n      // Not applied yet (within debounce)\n      expect(preview.scrollTop).toBe(0);\n\n      // Advance past debounce\n      act(() => {\n        vi.advanceTimersByTime(16);\n      });\n\n      // Now applied\n      expect(preview.scrollTop).toBe(750);\n    });\n\n    it('should respect custom debounce time', () => {\n      const editor = createMockElement({ scrollTop: 250, scrollHeight: 1000, clientHeight: 500 });\n      const preview = createMockElement({ scrollHeight: 2000, clientHeight: 500 });\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n          debounceMs: 100,\n        })\n      );\n\n      const editorScrollHandler = (editor.addEventListener as ReturnType<typeof vi.fn>).mock.calls[0][1];\n\n      // Trigger scroll\n      act(() => {\n        editorScrollHandler();\n      });\n\n      // Not applied at 50ms\n      act(() => {\n        vi.advanceTimersByTime(50);\n      });\n      expect(preview.scrollTop).toBe(0);\n\n      // Applied at 100ms\n      act(() => {\n        vi.advanceTimersByTime(50);\n      });\n      expect(preview.scrollTop).toBe(750);\n    });\n  });\n\n  describe('Edge cases', () => {\n    it('should handle null refs gracefully', () => {\n      const editorRef = { current: null };\n      const previewRef = { current: null };\n\n      // Should not throw\n      expect(() =>\n        renderHook(() =>\n          useSyncScroll({\n            editorRef,\n            previewRef,\n            enabled: true,\n          })\n        )\n      ).not.toThrow();\n    });\n\n    it('should handle editor ref null gracefully', () => {\n      const editorRef = { current: null };\n      const preview = createMockElement();\n      const previewRef = { current: preview };\n\n      expect(() =>\n        renderHook(() =>\n          useSyncScroll({\n            editorRef,\n            previewRef,\n            enabled: true,\n          })\n        )\n      ).not.toThrow();\n\n      // No event listeners should be added to preview\n      expect(preview.addEventListener).not.toHaveBeenCalled();\n    });\n\n    it('should handle preview ref null gracefully', () => {\n      const editor = createMockElement();\n      const editorRef = { current: editor };\n      const previewRef = { current: null };\n\n      expect(() =>\n        renderHook(() =>\n          useSyncScroll({\n            editorRef,\n            previewRef,\n            enabled: true,\n          })\n        )\n      ).not.toThrow();\n\n      // No event listeners should be added to editor\n      expect(editor.addEventListener).not.toHaveBeenCalled();\n    });\n\n    it('should handle zero scrollable height (content fits without scrolling)', () => {\n      const editor = createMockElement({\n        scrollTop: 0,\n        scrollHeight: 500, // Same as clientHeight\n        clientHeight: 500,\n      });\n      const preview = createMockElement({\n        scrollTop: 0,\n        scrollHeight: 1000,\n        clientHeight: 500,\n      });\n      const editorRef = { current: editor };\n      const previewRef = { current: preview };\n\n      renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n          debounceMs: 16,\n        })\n      );\n\n      const editorScrollHandler = (editor.addEventListener as ReturnType<typeof vi.fn>).mock.calls[0][1];\n\n      // Should not throw on division by zero\n      expect(() => {\n        act(() => {\n          editorScrollHandler();\n          vi.advanceTimersByTime(16);\n        });\n      }).not.toThrow();\n\n      // Preview should be at 0 (ratio is 0 when scrollable height is 0)\n      expect(preview.scrollTop).toBe(0);\n    });\n  });\n\n  describe('Return type', () => {\n    it('should return isSynced, toggleSync, enableSync, disableSync', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      expect(result.current).toHaveProperty('isSynced');\n      expect(result.current).toHaveProperty('toggleSync');\n      expect(result.current).toHaveProperty('enableSync');\n      expect(result.current).toHaveProperty('disableSync');\n      expect(typeof result.current.isSynced).toBe('boolean');\n      expect(typeof result.current.toggleSync).toBe('function');\n      expect(typeof result.current.enableSync).toBe('function');\n      expect(typeof result.current.disableSync).toBe('function');\n    });\n\n    it('should maintain stable function references', () => {\n      const editorRef = { current: createMockElement() };\n      const previewRef = { current: createMockElement() };\n\n      const { result, rerender } = renderHook(() =>\n        useSyncScroll({\n          editorRef,\n          previewRef,\n          enabled: true,\n        })\n      );\n\n      const initialToggleSync = result.current.toggleSync;\n      const initialEnableSync = result.current.enableSync;\n      const initialDisableSync = result.current.disableSync;\n\n      // Re-render\n      rerender();\n\n      // Functions should be stable (same references)\n      expect(result.current.toggleSync).toBe(initialToggleSync);\n      expect(result.current.enableSync).toBe(initialEnableSync);\n      expect(result.current.disableSync).toBe(initialDisableSync);\n    });\n  });\n});\n",
        "ui/src/hooks/useSyncScroll.ts": "/**\n * useSyncScroll Hook\n *\n * Provides synchronized scrolling between editor and preview panes:\n * - Uses proportional scroll position (scrollTop / scrollHeight)\n * - Debounces scroll events to prevent feedback loops\n * - Tracks scroll source to prevent infinite scroll loops\n * - Supports enabling/disabling sync programmatically\n */\n\nimport { RefObject, useState, useRef, useEffect, useCallback } from 'react';\n\nexport interface SyncScrollOptions {\n  /** Editor scroll container ref */\n  editorRef: RefObject<HTMLElement>;\n  /** Preview scroll container ref */\n  previewRef: RefObject<HTMLElement>;\n  /** Whether sync is enabled */\n  enabled: boolean;\n  /** Debounce delay in ms (default: 16) */\n  debounceMs?: number;\n}\n\nexport interface SyncScrollReturn {\n  /** Current sync enabled state */\n  isSynced: boolean;\n  /** Toggle sync on/off */\n  toggleSync: () => void;\n  /** Enable sync */\n  enableSync: () => void;\n  /** Disable sync */\n  disableSync: () => void;\n}\n\n/**\n * Simple debounce utility function\n */\nfunction debounce<T extends (...args: unknown[]) => void>(\n  fn: T,\n  delay: number\n): T {\n  let timeoutId: ReturnType<typeof setTimeout> | null = null;\n\n  return ((...args: unknown[]) => {\n    if (timeoutId) {\n      clearTimeout(timeoutId);\n    }\n    timeoutId = setTimeout(() => {\n      fn(...args);\n      timeoutId = null;\n    }, delay);\n  }) as T;\n}\n\n/**\n * Hook for synchronized scrolling between editor and preview panes.\n * Uses proportional scroll position (scrollTop / scrollHeight).\n *\n * @param options - Configuration options for sync scrolling\n * @returns Object with sync state and control functions\n *\n * @example\n * ```tsx\n * function Editor() {\n *   const editorRef = useRef<HTMLDivElement>(null);\n *   const previewRef = useRef<HTMLDivElement>(null);\n *\n *   const { isSynced, toggleSync } = useSyncScroll({\n *     editorRef,\n *     previewRef,\n *     enabled: true,\n *   });\n *\n *   return (\n *     <div>\n *       <button onClick={toggleSync}>\n *         {isSynced ? 'Disable' : 'Enable'} Sync\n *       </button>\n *       <div ref={editorRef} style={{ overflow: 'auto' }}>\n *         {/* Editor content *\\/}\n *       </div>\n *       <div ref={previewRef} style={{ overflow: 'auto' }}>\n *         {/* Preview content *\\/}\n *       </div>\n *     </div>\n *   );\n * }\n * ```\n */\nexport function useSyncScroll(options: SyncScrollOptions): SyncScrollReturn {\n  const { editorRef, previewRef, enabled, debounceMs = 16 } = options;\n\n  const [isSynced, setIsSynced] = useState(enabled);\n  const scrollSource = useRef<'editor' | 'preview' | null>(null);\n\n  const toggleSync = useCallback(() => setIsSynced((prev) => !prev), []);\n  const enableSync = useCallback(() => setIsSynced(true), []);\n  const disableSync = useCallback(() => setIsSynced(false), []);\n\n  useEffect(() => {\n    if (!isSynced) return;\n\n    const editor = editorRef.current;\n    const preview = previewRef.current;\n    if (!editor || !preview) return;\n\n    const handleEditorScroll = debounce(() => {\n      if (scrollSource.current === 'preview') return;\n      scrollSource.current = 'editor';\n\n      // Calculate proportional position\n      const scrollableHeight = editor.scrollHeight - editor.clientHeight;\n      // Handle edge case: if content fits without scrolling, ratio is 0\n      const scrollRatio = scrollableHeight > 0 ? editor.scrollTop / scrollableHeight : 0;\n      const targetScrollableHeight = preview.scrollHeight - preview.clientHeight;\n      const targetScroll = scrollRatio * targetScrollableHeight;\n\n      preview.scrollTop = targetScroll;\n\n      setTimeout(() => {\n        scrollSource.current = null;\n      }, debounceMs);\n    }, debounceMs);\n\n    const handlePreviewScroll = debounce(() => {\n      if (scrollSource.current === 'editor') return;\n      scrollSource.current = 'preview';\n\n      // Calculate proportional position\n      const scrollableHeight = preview.scrollHeight - preview.clientHeight;\n      // Handle edge case: if content fits without scrolling, ratio is 0\n      const scrollRatio = scrollableHeight > 0 ? preview.scrollTop / scrollableHeight : 0;\n      const targetScrollableHeight = editor.scrollHeight - editor.clientHeight;\n      const targetScroll = scrollRatio * targetScrollableHeight;\n\n      editor.scrollTop = targetScroll;\n\n      setTimeout(() => {\n        scrollSource.current = null;\n      }, debounceMs);\n    }, debounceMs);\n\n    editor.addEventListener('scroll', handleEditorScroll);\n    preview.addEventListener('scroll', handlePreviewScroll);\n\n    return () => {\n      editor.removeEventListener('scroll', handleEditorScroll);\n      preview.removeEventListener('scroll', handlePreviewScroll);\n    };\n  }, [isSynced, editorRef, previewRef, debounceMs]);\n\n  return { isSynced, toggleSync, enableSync, disableSync };\n}\n\nexport default useSyncScroll;\n",
        "ui/src/hooks/useTaskGraph.ts": "/**\n * useTaskGraph Hook\n *\n * Manages task graph state with real-time WebSocket updates.\n *\n * Provides:\n * - Initial fetch of task graph state on mount\n * - CustomEvent listener for task_graph_updated events\n * - Manual refresh function to re-fetch state\n * - Loading and error state tracking\n *\n * @param project - Project absolute path\n * @param session - Session name\n * @returns Task graph state and refresh function\n *\n * @example\n * ```tsx\n * function TaskGraphComponent() {\n *   const { diagram, batches, completedTasks, pendingTasks, isLoading, error, refresh } =\n *     useTaskGraph('/path/to/project', 'session-name');\n *\n *   if (isLoading) return <div>Loading...</div>;\n *   if (error) return <div>Error: {error.message}</div>;\n *\n *   return (\n *     <div>\n *       <button onClick={refresh}>Refresh</button>\n *       {diagram && <DiagramViewer content={diagram} />}\n *     </div>\n *   );\n * }\n * ```\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport { TaskBatch, TaskGraphUpdatedDetail } from '../types';\n\nexport interface UseTaskGraphReturn {\n  diagram: string | null;\n  batches: TaskBatch[];\n  completedTasks: string[];\n  pendingTasks: string[];\n  isLoading: boolean;\n  error: Error | null;\n  refresh: () => Promise<void>;\n}\n\n/**\n * Hook for managing task graph state\n *\n * Fetches initial state on mount and listens for real-time updates via CustomEvent.\n * Automatically cleans up event listeners on unmount.\n */\nexport function useTaskGraph(project: string, session: string): UseTaskGraphReturn {\n  const [diagram, setDiagram] = useState<string | null>(null);\n  const [batches, setBatches] = useState<TaskBatch[]>([]);\n  const [completedTasks, setCompletedTasks] = useState<string[]>([]);\n  const [pendingTasks, setPendingTasks] = useState<string[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  /**\n   * Fetch task graph from API endpoint\n   */\n  const fetchTaskGraph = useCallback(async () => {\n    try {\n      setIsLoading(true);\n      setError(null);\n\n      // Build API URL with project and session in path\n      const encodedProject = encodeURIComponent(project);\n      const encodedSession = encodeURIComponent(session);\n      const url = `/api/projects/${encodedProject}/sessions/${encodedSession}/task-graph`;\n\n      const response = await fetch(url);\n      if (!response.ok) {\n        throw new Error(`Failed to fetch task graph: ${response.statusText}`);\n      }\n\n      const data = await response.json();\n\n      // Update state with API response\n      setDiagram(data.diagram || null);\n      setBatches(data.batches || []);\n      setCompletedTasks(data.completedTasks || []);\n      setPendingTasks(data.pendingTasks || []);\n      setIsLoading(false);\n    } catch (err) {\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      setIsLoading(false);\n      console.error('Failed to fetch task graph:', error);\n    }\n  }, [project, session]);\n\n  /**\n   * Handle task_graph_updated CustomEvent\n   */\n  const handleTaskGraphUpdate = useCallback((event: Event) => {\n    const customEvent = event as CustomEvent<TaskGraphUpdatedDetail>;\n    try {\n      const payload = customEvent.detail.payload;\n\n      // Update state with payload from event\n      setDiagram(payload.diagram || null);\n      setBatches(payload.batches as TaskBatch[] || []);\n      setCompletedTasks(payload.completedTasks || []);\n      setPendingTasks(payload.pendingTasks || []);\n      setError(null);\n    } catch (err) {\n      console.warn('Failed to parse task_graph_updated event:', err);\n    }\n  }, []);\n\n  /**\n   * Set up event listener and fetch initial state on mount\n   */\n  useEffect(() => {\n    // Fetch initial state\n    fetchTaskGraph();\n\n    // Listen for real-time updates via CustomEvent\n    window.addEventListener('task_graph_updated', handleTaskGraphUpdate);\n\n    // Cleanup on unmount\n    return () => {\n      window.removeEventListener('task_graph_updated', handleTaskGraphUpdate);\n    };\n  }, [fetchTaskGraph, handleTaskGraphUpdate]);\n\n  return {\n    diagram,\n    batches,\n    completedTasks,\n    pendingTasks,\n    isLoading,\n    error,\n    refresh: fetchTaskGraph,\n  };\n}\n",
        "ui/src/hooks/useTerminalTabs.test.ts": "/**\n * useTerminalTabs Hook Tests\n *\n * Tests verify:\n * - Hook initialization with project and session\n * - Fetching terminal sessions from API on mount\n * - Loading and error state management\n * - Adding new terminal tabs\n * - Removing terminal tabs\n * - Renaming terminal tabs\n * - Setting active tab\n * - Reordering terminal tabs with optimistic updates\n * - Refreshing terminal sessions\n */\n\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act, waitFor } from '@testing-library/react';\nimport { useTerminalTabs } from './useTerminalTabs';\nimport { api } from '../lib/api';\nimport type { TerminalSession, CreateSessionResult } from '../types/terminal';\n\n// Mock the API\nvi.mock('../lib/api', () => ({\n  api: {\n    getTerminalSessions: vi.fn(),\n    createTerminalSession: vi.fn(),\n    deleteTerminalSession: vi.fn(),\n    renameTerminalSession: vi.fn(),\n    reorderTerminalSessions: vi.fn(),\n  },\n}));\n\ndescribe('useTerminalTabs', () => {\n  const mockProject = '/path/to/project';\n  const mockSession = 'test-session';\n\n  const createMockSession = (id: string, name: string, order: number): TerminalSession => ({\n    id,\n    name,\n    tmuxSession: `mc-${name}-${id.slice(0, 4)}`,\n    created: new Date().toISOString(),\n    order,\n  });\n\n  const mockSessions: TerminalSession[] = [\n    createMockSession('session-1', 'Terminal 1', 0),\n    createMockSession('session-2', 'Terminal 2', 1),\n  ];\n\n  beforeEach(() => {\n    vi.clearAllMocks();\n    localStorage.clear();\n    (api.getTerminalSessions as any).mockResolvedValue(mockSessions);\n  });\n\n  afterEach(() => {\n    vi.clearAllMocks();\n    localStorage.clear();\n  });\n\n  describe('Initialization and Loading', () => {\n    it('should initialize with loading state', () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      expect(result.current.isLoading).toBe(true);\n      expect(result.current.tabs).toEqual([]);\n      expect(result.current.activeTabId).toBeNull();\n      expect(result.current.error).toBeNull();\n    });\n\n    it('should fetch sessions on mount', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenCalledWith(mockProject, mockSession);\n      expect(result.current.tabs).toEqual(mockSessions);\n      expect(result.current.activeTabId).toBe('session-1');\n    });\n\n    it('should set first session as active tab', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.activeTabId).toBe('session-1');\n      expect(result.current.activeTab).toEqual(mockSessions[0]);\n    });\n\n    it('should set activeTabId to null when no sessions', async () => {\n      (api.getTerminalSessions as any).mockResolvedValue([]);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.tabs).toEqual([]);\n      expect(result.current.activeTabId).toBeNull();\n      expect(result.current.activeTab).toBeNull();\n    });\n\n    it('should re-fetch when project changes', async () => {\n      const { result, rerender } = renderHook(\n        ({ project, session }) => useTerminalTabs({ project, session }),\n        { initialProps: { project: mockProject, session: mockSession } }\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenCalledTimes(1);\n\n      const newProject = '/new/project/path';\n      rerender({ project: newProject, session: mockSession });\n\n      await waitFor(() => {\n        expect(api.getTerminalSessions).toHaveBeenCalledTimes(2);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenLastCalledWith(newProject, mockSession);\n    });\n\n    it('should re-fetch when session changes', async () => {\n      const { result, rerender } = renderHook(\n        ({ project, session }) => useTerminalTabs({ project, session }),\n        { initialProps: { project: mockProject, session: mockSession } }\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenCalledTimes(1);\n\n      const newSession = 'new-session';\n      rerender({ project: mockProject, session: newSession });\n\n      await waitFor(() => {\n        expect(api.getTerminalSessions).toHaveBeenCalledTimes(2);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenLastCalledWith(mockProject, newSession);\n    });\n  });\n\n  describe('Error Handling', () => {\n    it('should handle fetch error', async () => {\n      const error = new Error('Network error');\n      (api.getTerminalSessions as any).mockRejectedValue(error);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.error).toEqual(error);\n      expect(result.current.tabs).toEqual([]);\n    });\n\n    it('should set error when API fails', async () => {\n      const apiError = new Error('API Error');\n      (api.getTerminalSessions as any).mockRejectedValue(apiError);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.error).not.toBeNull();\n      });\n\n      expect(result.current.error?.message).toBe('API Error');\n      expect(result.current.isLoading).toBe(false);\n    });\n  });\n\n  describe('addTab', () => {\n    it('should add a new tab and set it as active', async () => {\n      const newSession = createMockSession('session-3', 'Terminal 3', 2);\n      (api.createTerminalSession as any).mockResolvedValue({\n        id: newSession.id,\n        tmuxSession: newSession.tmuxSession,\n        wsUrl: 'ws://localhost:7681/ws',\n      });\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      await act(async () => {\n        await result.current.addTab();\n      });\n\n      expect(api.createTerminalSession).toHaveBeenCalledWith(mockProject, mockSession);\n    });\n\n    it('should handle error when adding tab fails', async () => {\n      const error = new Error('Create failed');\n      (api.createTerminalSession as any).mockRejectedValue(error);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      await act(async () => {\n        try {\n          await result.current.addTab();\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      // Verify the error was propagated\n      expect(api.createTerminalSession).toHaveBeenCalled();\n    });\n  });\n\n  describe('removeTab', () => {\n    it('should remove a tab', async () => {\n      (api.deleteTerminalSession as any).mockResolvedValue(undefined);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const initialCount = result.current.tabs.length;\n\n      await act(async () => {\n        await result.current.removeTab('session-1');\n      });\n\n      expect(api.deleteTerminalSession).toHaveBeenCalledWith(mockProject, mockSession, 'session-1');\n    });\n\n    it('should select adjacent tab when active tab is removed', async () => {\n      (api.deleteTerminalSession as any).mockResolvedValue(undefined);\n      (api.getTerminalSessions as any).mockResolvedValueOnce(mockSessions).mockResolvedValueOnce([mockSessions[1]]);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.activeTabId).toBe('session-1');\n\n      // After removing, should refresh and get updated list\n      await act(async () => {\n        await result.current.removeTab('session-1');\n      });\n\n      // API call made\n      expect(api.deleteTerminalSession).toHaveBeenCalled();\n    });\n\n    it('should handle error when removing tab fails', async () => {\n      const error = new Error('Delete failed');\n      (api.deleteTerminalSession as any).mockRejectedValue(error);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      await act(async () => {\n        try {\n          await result.current.removeTab('session-1');\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      expect(api.deleteTerminalSession).toHaveBeenCalled();\n    });\n  });\n\n  describe('renameTab', () => {\n    it('should rename a tab', async () => {\n      (api.renameTerminalSession as any).mockResolvedValue(undefined);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const newName = 'My Terminal';\n\n      await act(async () => {\n        await result.current.renameTab('session-1', newName);\n      });\n\n      expect(api.renameTerminalSession).toHaveBeenCalledWith(\n        mockProject,\n        mockSession,\n        'session-1',\n        newName\n      );\n    });\n\n    it('should trim whitespace from name', async () => {\n      (api.renameTerminalSession as any).mockResolvedValue(undefined);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      await act(async () => {\n        await result.current.renameTab('session-1', '  New Name  ');\n      });\n\n      expect(api.renameTerminalSession).toHaveBeenCalledWith(\n        mockProject,\n        mockSession,\n        'session-1',\n        '  New Name  '\n      );\n    });\n\n    it('should handle error when renaming tab fails', async () => {\n      const error = new Error('Rename failed');\n      (api.renameTerminalSession as any).mockRejectedValue(error);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      await act(async () => {\n        try {\n          await result.current.renameTab('session-1', 'New Name');\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      expect(api.renameTerminalSession).toHaveBeenCalled();\n    });\n  });\n\n  describe('setActiveTab', () => {\n    it('should set active tab', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.activeTabId).toBe('session-1');\n\n      act(() => {\n        result.current.setActiveTab('session-2');\n      });\n\n      expect(result.current.activeTabId).toBe('session-2');\n      expect(result.current.activeTab).toEqual(mockSessions[1]);\n    });\n\n    it('should not change active tab if id does not exist', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const initialActiveId = result.current.activeTabId;\n\n      act(() => {\n        result.current.setActiveTab('non-existent-id');\n      });\n\n      expect(result.current.activeTabId).toBe(initialActiveId);\n    });\n  });\n\n  describe('reorderTabs', () => {\n    it('should reorder tabs', async () => {\n      (api.reorderTerminalSessions as any).mockResolvedValue(undefined);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const initialOrder = result.current.tabs.map(t => t.id);\n\n      await act(async () => {\n        await result.current.reorderTabs(0, 1);\n      });\n\n      expect(api.reorderTerminalSessions).toHaveBeenCalledWith(\n        mockProject,\n        mockSession,\n        expect.any(Array)\n      );\n    });\n\n    it('should perform optimistic update', async () => {\n      (api.reorderTerminalSessions as any).mockResolvedValue(undefined);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const tab1Id = result.current.tabs[0].id;\n      const tab2Id = result.current.tabs[1].id;\n\n      await act(async () => {\n        await result.current.reorderTabs(0, 1);\n      });\n\n      // After reorder, second tab should be first\n      expect(result.current.tabs[0].id).toBe(tab2Id);\n      expect(result.current.tabs[1].id).toBe(tab1Id);\n    });\n\n    it('should revert optimistic update on error', async () => {\n      const error = new Error('Reorder failed');\n      (api.reorderTerminalSessions as any).mockRejectedValue(error);\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const originalOrder = [...result.current.tabs];\n\n      await act(async () => {\n        try {\n          await result.current.reorderTabs(0, 1);\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      // Order should be reverted\n      expect(result.current.tabs).toEqual(originalOrder);\n    });\n\n    it('should not reorder if indices are invalid', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const originalOrder = [...result.current.tabs];\n\n      await act(async () => {\n        try {\n          await result.current.reorderTabs(0, 99);\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      expect(result.current.tabs).toEqual(originalOrder);\n      expect(api.reorderTerminalSessions).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('refresh', () => {\n    it('should re-fetch sessions from API', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenCalledTimes(1);\n\n      await act(async () => {\n        await result.current.refresh();\n      });\n\n      expect(api.getTerminalSessions).toHaveBeenCalledTimes(2);\n    });\n\n    it('should update tabs with refreshed data', async () => {\n      const newSessions = [\n        createMockSession('session-1', 'Terminal 1', 0),\n        createMockSession('session-2', 'Terminal 2', 1),\n        createMockSession('session-3', 'Terminal 3', 2),\n      ];\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.tabs.length).toBe(2);\n\n      (api.getTerminalSessions as any).mockResolvedValue(newSessions);\n\n      await act(async () => {\n        await result.current.refresh();\n      });\n\n      expect(result.current.tabs.length).toBe(3);\n      expect(result.current.tabs).toEqual(newSessions);\n    });\n\n    it('should handle error during refresh', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      const error = new Error('Refresh failed');\n      (api.getTerminalSessions as any).mockRejectedValue(error);\n\n      await act(async () => {\n        try {\n          await result.current.refresh();\n        } catch (e) {\n          // Expected to throw\n        }\n      });\n\n      expect(result.current.error).toEqual(error);\n    });\n  });\n\n  describe('Return Type', () => {\n    it('should return all required properties', async () => {\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current).toHaveProperty('tabs');\n      expect(result.current).toHaveProperty('activeTabId');\n      expect(result.current).toHaveProperty('activeTab');\n      expect(result.current).toHaveProperty('isLoading');\n      expect(result.current).toHaveProperty('error');\n      expect(result.current).toHaveProperty('addTab');\n      expect(result.current).toHaveProperty('removeTab');\n      expect(result.current).toHaveProperty('renameTab');\n      expect(result.current).toHaveProperty('setActiveTab');\n      expect(result.current).toHaveProperty('reorderTabs');\n      expect(result.current).toHaveProperty('refresh');\n    });\n  });\n\n  describe('addTab - Auto-select new terminal (bugfix)', () => {\n    it('should set new terminal as active after creation', async () => {\n      const newSession = createMockSession('session-3', 'Terminal 3', 2);\n      const updatedSessions = [...mockSessions, newSession];\n\n      // Reset mocks for clean test state\n      vi.clearAllMocks();\n      (api.getTerminalSessions as any)\n        .mockResolvedValueOnce(mockSessions)\n        .mockResolvedValueOnce(updatedSessions);\n      (api.createTerminalSession as any).mockResolvedValue({\n        id: newSession.id,\n        tmuxSession: newSession.tmuxSession,\n        wsUrl: 'ws://localhost:7681/ws',\n      });\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      expect(result.current.activeTabId).toBe('session-1');\n\n      // Add new tab\n      await act(async () => {\n        await result.current.addTab();\n      });\n\n      // New terminal should be active\n      await waitFor(() => {\n        expect(result.current.activeTabId).toBe('session-3');\n      });\n    });\n\n    it('should persist new terminal ID to localStorage', async () => {\n      const newSession = createMockSession('session-4', 'Terminal 4', 2);\n      const updatedSessions = [...mockSessions, newSession];\n\n      vi.clearAllMocks();\n      (api.getTerminalSessions as any)\n        .mockResolvedValueOnce(mockSessions)\n        .mockResolvedValueOnce(updatedSessions);\n      (api.createTerminalSession as any).mockResolvedValue({\n        id: newSession.id,\n        tmuxSession: newSession.tmuxSession,\n        wsUrl: 'ws://localhost:7681/ws',\n      });\n\n      const storageKey = `terminal-active-tab:${mockProject}:${mockSession}`;\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Add new tab\n      await act(async () => {\n        await result.current.addTab();\n      });\n\n      // Verify localStorage was updated\n      await waitFor(() => {\n        expect(localStorage.getItem(storageKey)).toBe('session-4');\n      });\n    });\n\n    it('should update activeTab property when new terminal is selected', async () => {\n      const newSession = createMockSession('session-5', 'Terminal 5', 2);\n      const updatedSessions = [...mockSessions, newSession];\n\n      vi.clearAllMocks();\n      (api.getTerminalSessions as any)\n        .mockResolvedValueOnce(mockSessions)\n        .mockResolvedValueOnce(updatedSessions);\n      (api.createTerminalSession as any).mockResolvedValue({\n        id: newSession.id,\n        tmuxSession: newSession.tmuxSession,\n        wsUrl: 'ws://localhost:7681/ws',\n      });\n\n      const { result } = renderHook(() =>\n        useTerminalTabs({ project: mockProject, session: mockSession })\n      );\n\n      await waitFor(() => {\n        expect(result.current.isLoading).toBe(false);\n      });\n\n      // Add new tab\n      await act(async () => {\n        await result.current.addTab();\n      });\n\n      // Verify activeTab is updated to the new session\n      await waitFor(() => {\n        expect(result.current.activeTab?.id).toBe('session-5');\n        expect(result.current.activeTab?.name).toBe('Terminal 5');\n      });\n    });\n  });\n});\n",
        "ui/src/hooks/useTerminalTabs.ts": "import { useState, useEffect, useCallback } from 'react';\nimport { api } from '../lib/api';\nimport type { TerminalSession, CreateSessionResult } from '../types/terminal';\n\nexport interface UseTerminalTabsOptions {\n  project: string;\n  session: string;\n}\n\nexport interface UseTerminalTabsReturn {\n  tabs: TerminalSession[];\n  activeTabId: string | null;\n  activeTab: TerminalSession | null;\n  isLoading: boolean;\n  error: Error | null;\n  addTab: () => Promise<void>;\n  removeTab: (id: string) => Promise<void>;\n  renameTab: (id: string, name: string) => Promise<void>;\n  setActiveTab: (id: string) => void;\n  reorderTabs: (fromIndex: number, toIndex: number) => Promise<void>;\n  refresh: () => Promise<void>;\n}\n\n// Helper to generate localStorage key for active tab persistence\nconst getStorageKey = (project: string, session: string) =>\n  `terminal-active-tab:${project}:${session}`;\n\nexport function useTerminalTabs({ project, session }: UseTerminalTabsOptions): UseTerminalTabsReturn {\n  const [tabs, setTabs] = useState<TerminalSession[]>([]);\n  const [activeTabId, setActiveTabId] = useState<string | null>(null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  // Fetch sessions from API\n  const refresh = useCallback(async () => {\n    // Skip API call if project or session is empty\n    if (!project || !session) {\n      setTabs([]);\n      setActiveTabId(null);\n      setIsLoading(false);\n      return;\n    }\n\n    try {\n      setIsLoading(true);\n      setError(null);\n      const sessions = await api.getTerminalSessions(project, session);\n      setTabs(sessions);\n      // Restore active tab from localStorage, or default to first session\n      const savedTabId = localStorage.getItem(getStorageKey(project, session));\n      if (savedTabId && sessions.some(s => s.id === savedTabId)) {\n        setActiveTabId(savedTabId);\n      } else if (sessions.length > 0) {\n        setActiveTabId(sessions[0].id);\n      } else {\n        setActiveTabId(null);\n      }\n    } catch (err) {\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      setTabs([]);\n      setActiveTabId(null);\n    } finally {\n      setIsLoading(false);\n    }\n  }, [project, session]);\n\n  // Load on mount and when project/session changes\n  useEffect(() => {\n    refresh();\n  }, [refresh]);\n\n  const addTab = useCallback(async () => {\n    try {\n      const result = await api.createTerminalSession(project, session);\n      // Refresh to get the updated list\n      await refresh();\n      // Auto-select the new terminal and persist to localStorage\n      setActiveTabId(result.id);\n      localStorage.setItem(getStorageKey(project, session), result.id);\n    } catch (err) {\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      throw error;\n    }\n  }, [project, session, refresh]);\n\n  const removeTab = useCallback(async (id: string) => {\n    try {\n      await api.deleteTerminalSession(project, session, id);\n      // Refresh to get the updated list\n      await refresh();\n    } catch (err) {\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      throw error;\n    }\n  }, [project, session, refresh]);\n\n  const renameTab = useCallback(async (id: string, name: string) => {\n    try {\n      await api.renameTerminalSession(project, session, id, name);\n      // Refresh to get the updated list\n      await refresh();\n    } catch (err) {\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      throw error;\n    }\n  }, [project, session, refresh]);\n\n  const reorderTabs = useCallback(async (fromIndex: number, toIndex: number) => {\n    // Validate indices\n    if (\n      fromIndex < 0 ||\n      fromIndex >= tabs.length ||\n      toIndex < 0 ||\n      toIndex >= tabs.length ||\n      fromIndex === toIndex\n    ) {\n      throw new Error('Invalid reorder indices');\n    }\n\n    // Perform optimistic update\n    const originalTabs = tabs;\n    const newTabs = [...tabs];\n    const [removed] = newTabs.splice(fromIndex, 1);\n    newTabs.splice(toIndex, 0, removed);\n    setTabs(newTabs);\n\n    try {\n      // Create ordered IDs array for API call\n      const orderedIds = newTabs.map(t => t.id);\n      await api.reorderTerminalSessions(project, session, orderedIds);\n    } catch (err) {\n      // Revert optimistic update on error\n      setTabs(originalTabs);\n      const error = err instanceof Error ? err : new Error(String(err));\n      setError(error);\n      throw error;\n    }\n  }, [tabs, project, session]);\n\n  const handleSetActiveTab = useCallback((id: string) => {\n    // Verify tab exists before setting\n    if (tabs.some(t => t.id === id)) {\n      setActiveTabId(id);\n      // Persist active tab selection to localStorage\n      localStorage.setItem(getStorageKey(project, session), id);\n    }\n  }, [tabs, project, session]);\n\n  const activeTab = tabs.find(t => t.id === activeTabId) || null;\n\n  return {\n    tabs,\n    activeTabId,\n    activeTab,\n    isLoading,\n    error,\n    addTab,\n    removeTab,\n    renameTab,\n    setActiveTab: handleSetActiveTab,\n    reorderTabs,\n    refresh,\n  };\n}\n",
        "ui/src/hooks/useTheme.ts": "/**\n * useTheme Hook\n *\n * Provides React integration for theme state management with:\n * - Theme state (light/dark) from UI store\n * - Theme getter and setter methods\n * - Theme toggle functionality\n * - Persistent storage of theme preference\n */\n\nimport { useCallback } from 'react';\nimport { useShallow } from 'zustand/react/shallow';\nimport { useUIStore, type Theme } from '../stores/uiStore';\n\nexport interface UseThemeReturn {\n  theme: Theme;\n  setTheme: (theme: Theme) => void;\n  toggleTheme: () => void;\n}\n\n/**\n * Hook for accessing and managing theme state\n *\n * Provides convenient access to theme preferences from the UI store\n * with automatic persistence to localStorage\n *\n * @returns Theme state and control methods\n *\n * @example\n * ```tsx\n * function ThemeToggle() {\n *   const { theme, toggleTheme } = useTheme();\n *\n *   return (\n *     <button onClick={toggleTheme}>\n *       Current theme: {theme}\n *     </button>\n *   );\n * }\n * ```\n */\nexport function useTheme(): UseThemeReturn {\n  // Get theme state using shallow comparison\n  const { theme, setTheme, toggleTheme } = useUIStore(\n    useShallow((state) => ({\n      theme: state.theme,\n      setTheme: state.setTheme,\n      toggleTheme: state.toggleTheme,\n    }))\n  );\n\n  return {\n    theme,\n    setTheme: useCallback((newTheme: Theme) => {\n      setTheme(newTheme);\n    }, [setTheme]),\n    toggleTheme: useCallback(() => {\n      toggleTheme();\n    }, [toggleTheme]),\n  };\n}\n",
        "ui/src/hooks/useWebSocket.ts": "/**\n * useWebSocket Hook\n *\n * Provides React integration for WebSocket connectivity with:\n * - Automatic connection/disconnection on mount/unmount\n * - Connection state tracking (connecting, connected, disconnected, error)\n * - Subscription and unsubscription helpers\n * - Message sending capability\n */\n\nimport { useEffect, useState, useCallback, useRef } from 'react';\nimport { WebSocketClient, WebSocketMessage, getWebSocketClient, resetWebSocketClient } from '../lib/websocket';\n\nexport interface UseWebSocketState {\n  isConnecting: boolean;\n  isConnected: boolean;\n  error: Error | null;\n}\n\nexport interface UseWebSocketReturn extends UseWebSocketState {\n  send: (message: WebSocketMessage) => void;\n  subscribe: (channel: string) => void;\n  unsubscribe: (channel: string) => void;\n  connect: () => Promise<void>;\n  disconnect: () => void;\n}\n\n/**\n * Hook for managing WebSocket connections\n *\n * Automatically connects on mount and disconnects on unmount\n * Provides methods to send messages and manage subscriptions\n *\n * @param url - Optional WebSocket URL (uses default if not provided)\n * @param autoConnect - Whether to automatically connect on mount (default: true)\n * @returns WebSocket state and control methods\n *\n * @example\n * ```tsx\n * function Component() {\n *   const { isConnected, send, subscribe, error } = useWebSocket();\n *\n *   useEffect(() => {\n *     if (isConnected) {\n *       subscribe('diagrams');\n *     }\n *   }, [isConnected, subscribe]);\n *\n *   if (error) return <div>Connection error: {error.message}</div>;\n *   if (!isConnected) return <div>Connecting...</div>;\n *\n *   return <div>Connected</div>;\n * }\n * ```\n */\nexport function useWebSocket(\n  url?: string,\n  autoConnect: boolean = true\n): UseWebSocketReturn {\n  const clientRef = useRef<WebSocketClient | null>(null);\n  const [state, setState] = useState<UseWebSocketState>({\n    isConnecting: false,\n    isConnected: false,\n    error: null,\n  });\n\n  // Get or create WebSocket client\n  const getClient = useCallback(() => {\n    if (!clientRef.current) {\n      clientRef.current = url ? new WebSocketClient(url) : getWebSocketClient();\n    }\n    return clientRef.current;\n  }, [url]);\n\n  // Connect to WebSocket\n  const connect = useCallback(async () => {\n    try {\n      setState((prev) => ({ ...prev, isConnecting: true, error: null }));\n      const client = getClient();\n      await client.connect();\n      setState((prev) => ({\n        ...prev,\n        isConnecting: false,\n        isConnected: true,\n        error: null,\n      }));\n    } catch (error) {\n      const err = error instanceof Error ? error : new Error(String(error));\n      setState((prev) => ({\n        ...prev,\n        isConnecting: false,\n        isConnected: false,\n        error: err,\n      }));\n    }\n  }, [getClient]);\n\n  // Disconnect from WebSocket\n  const disconnect = useCallback(() => {\n    const client = getClient();\n    client.disconnect();\n    setState((prev) => ({\n      ...prev,\n      isConnected: false,\n      error: null,\n    }));\n  }, [getClient]);\n\n  // Send a message\n  const send = useCallback(\n    (message: WebSocketMessage) => {\n      const client = getClient();\n      client.send(message);\n    },\n    [getClient]\n  );\n\n  // Subscribe to a channel\n  const subscribe = useCallback(\n    (channel: string) => {\n      const client = getClient();\n      client.subscribe(channel);\n    },\n    [getClient]\n  );\n\n  // Unsubscribe from a channel\n  const unsubscribe = useCallback(\n    (channel: string) => {\n      const client = getClient();\n      client.unsubscribe(channel);\n    },\n    [getClient]\n  );\n\n  // Setup connection listeners and auto-connect on mount\n  useEffect(() => {\n    const client = getClient();\n\n    // Setup event listeners\n    const connectSub = client.onConnect(() => {\n      setState((prev) => ({\n        ...prev,\n        isConnecting: false,\n        isConnected: true,\n        error: null,\n      }));\n    });\n\n    const disconnectSub = client.onDisconnect(() => {\n      setState((prev) => ({\n        ...prev,\n        isConnected: false,\n      }));\n    });\n\n    // Auto-connect if requested\n    if (autoConnect && !client.isConnected()) {\n      connect().catch((error) => {\n        console.error('Failed to auto-connect WebSocket:', error);\n      });\n    } else if (client.isConnected()) {\n      setState((prev) => ({\n        ...prev,\n        isConnected: true,\n      }));\n    }\n\n    // Cleanup on unmount\n    return () => {\n      connectSub.unsubscribe();\n      disconnectSub.unsubscribe();\n      // Don't disconnect automatically - let it persist across component re-renders\n      // Only disconnect when the app unmounts or explicitly requested\n    };\n  }, [autoConnect, connect, getClient]);\n\n  return {\n    ...state,\n    send,\n    subscribe,\n    unsubscribe,\n    connect,\n    disconnect,\n  };\n}\n"
      },
      "plugins": [
        {
          "name": "mermaid-collab",
          "description": "Collaborative design workflows for Claude Code: mermaid diagrams, wireframes, and design-to-implementation pipelines",
          "version": "5.39.0",
          "source": "./",
          "author": {
            "name": "Ben Maderazo"
          },
          "license": "MIT",
          "keywords": [
            "collaboration",
            "mermaid",
            "wireframes",
            "design",
            "diagrams"
          ],
          "categories": [
            "collaboration",
            "design",
            "diagrams",
            "mermaid",
            "wireframes"
          ],
          "install_commands": [
            "/plugin marketplace add ben-mad-jlp/claude-mermaid-collab",
            "/plugin install mermaid-collab@mermaid-collab-dev"
          ]
        }
      ]
    }
  ]
}