{
  "author": {
    "id": "TJC-LP",
    "display_name": "TJC",
    "avatar_url": "https://avatars.githubusercontent.com/u/138708528?v=4"
  },
  "marketplaces": [
    {
      "name": "sanzaru-marketplace",
      "version": null,
      "description": "MCP server for OpenAI multimodal APIs (Sora video, image generation, audio)",
      "repo_full_name": "TJC-LP/sanzaru",
      "repo_url": "https://github.com/TJC-LP/sanzaru",
      "repo_description": "Lightweight Multimodal MCP Server built with the OpenAI API",
      "signals": {
        "stars": 5,
        "forks": 0,
        "pushed_at": "2026-02-09T19:18:50Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"sanzaru-marketplace\",\n  \"owner\": {\n    \"name\": \"TJC L.P.\",\n    \"url\": \"https://github.com/TJC-LP\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sanzaru\",\n      \"source\": \"./plugin\",\n      \"description\": \"MCP server for OpenAI multimodal APIs (Sora video, image generation, audio)\"\n    }\n  ]\n}\n",
        "README.md": "# sanzaru\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/TJC-LP/sanzaru/main/assets/logo.png\" alt=\"sanzaru logo\" width=\"400\">\n\n  [![PyPI version](https://img.shields.io/pypi/v/sanzaru)](https://pypi.org/project/sanzaru/)\n  [![Python versions](https://img.shields.io/pypi/pyversions/sanzaru)](https://pypi.org/project/sanzaru/)\n  [![License](https://img.shields.io/pypi/l/sanzaru)](https://github.com/TJC-LP/sanzaru/blob/main/LICENSE)\n  [![CI](https://github.com/TJC-LP/sanzaru/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/TJC-LP/sanzaru/actions/workflows/ci-cd.yml)\n  [![PyPI downloads](https://img.shields.io/pypi/dm/sanzaru)](https://pypi.org/project/sanzaru/)\n</div>\n\nA **stateless**, lightweight **MCP** server that wraps **OpenAI's Sora Video API, Whisper, and GPT-4o Audio APIs** via the OpenAI Python SDK.\n\n## Features\n\n### Video Generation (Sora)\n- Create videos with `sora-2` or `sora-2-pro` models\n- Use reference images to guide generation\n- Remix and refine existing videos\n- Download variants (video, thumbnail, spritesheet)\n\n### Image Generation\n- Generate images with gpt-image-1.5 (recommended) or GPT-5\n- Edit and compose images with up to 16 inputs\n- Iterative refinement via Responses API\n- Automatic resizing for Sora compatibility\n\n### Audio Processing\n- **Transcription**: Whisper and GPT-4o models\n- **Audio Chat**: Interactive analysis with GPT-4o\n- **Text-to-Speech**: Multi-voice TTS generation\n- **Processing**: Format conversion, compression, file management\n\n> **Note:** Content guardrails are enforced by OpenAI. This server does not run local moderation.\n\n## Requirements\n- Python 3.10+\n- `OPENAI_API_KEY` environment variable\n\n**Media storage** (choose one):\n```bash\n# Recommended: unified path (auto-creates videos/, images/, audio/ subdirs)\nSANZARU_MEDIA_PATH=\"/path/to/media\"\n\n# Or individual paths (legacy, still supported)\nVIDEO_PATH=\"/path/to/videos\"\nIMAGE_PATH=\"/path/to/images\"\nAUDIO_PATH=\"/path/to/audio\"\n```\n\nFeatures are auto-detected based on configured paths. Set only what you need.\n\n## Quick Start\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/TJC-LP/sanzaru.git\n   cd sanzaru\n   ```\n\n2. **Run the setup script:**\n   ```bash\n   ./setup.sh\n   ```\n   The script will:\n   - Prompt for your OpenAI API key\n   - Create directories and `.env` configuration\n   - Install dependencies with `uv sync --all-extras --dev`\n\n3. **Start using:**\n   ```bash\n   claude\n   ```\n\nThat's it! Claude Code will automatically connect and you can start generating videos, images, and processing audio.\n\n## Installation\n\n### Claude Code Plugin (Recommended)\n\nInstall as a plugin — auto-configures the MCP server + includes prompting guidance:\n\n```bash\n/plugin marketplace add TJC-LP/sanzaru\n```\n\nRequires `OPENAI_API_KEY` and `SANZARU_MEDIA_PATH` environment variables to be set.\n\n### Quick Install\n```bash\n# All features\nuv add \"sanzaru[all]\"\n\n# Specific features\nuv add \"sanzaru[audio]\"  # With audio support\nuv add sanzaru           # Base (video + image only)\n```\n\n<details>\n<summary><strong>Alternative Installation Methods</strong></summary>\n\n### From Source\n```bash\ngit clone https://github.com/TJC-LP/sanzaru.git\ncd sanzaru\nuv sync --all-extras\n```\n\n### Claude Desktop\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"sanzaru\": {\n      \"command\": \"uvx\",\n      \"args\": [\"sanzaru[all]\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\",\n        \"SANZARU_MEDIA_PATH\": \"/absolute/path/to/media\"\n      }\n    }\n  }\n}\n```\n\nOr from source:\n```json\n{\n  \"mcpServers\": {\n    \"sanzaru\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"--directory\", \"/path/to/sanzaru\", \"sanzaru\"]\n    }\n  }\n}\n```\n\n### Codex MCP\n```bash\n# Using uvx (from PyPI)\ncodex mcp add sanzaru \\\n  --env OPENAI_API_KEY=\"sk-...\" \\\n  --env SANZARU_MEDIA_PATH=\"$HOME/sanzaru-media\" \\\n  -- uvx \"sanzaru[all]\"\n```\n\n### Manual Setup\n```bash\nuv venv\nuv sync\n\n# Set required environment variables\nexport OPENAI_API_KEY=sk-...\nexport SANZARU_MEDIA_PATH=~/sanzaru-media\n\n# Run server (stdio for MCP clients)\nuv run sanzaru\n\n# Or HTTP mode (for remote access)\nuv run sanzaru --transport http --port 8000\n```\n\n</details>\n\n## Available Tools\n\n| Category | Tools | Description |\n|----------|-------|-------------|\n| **Video** | `create_video`, `get_video_status`, `download_video`, `list_videos`, `list_local_videos`, `delete_video`, `remix_video` | Generate and manage Sora videos with optional reference images |\n| **Image** | `generate_image`, `edit_image`, `create_image`, `get_image_status`, `download_image` | Generate with gpt-image-1.5 (sync) or GPT-5 (polling) |\n| **Reference** | `list_reference_images`, `prepare_reference_image` | Manage and resize images for Sora compatibility |\n| **Audio** | `transcribe_audio`, `chat_with_audio`, `create_audio`, `convert_audio`, `compress_audio`, `list_audio_files`, `get_latest_audio`, `transcribe_with_enhancement` | Transcription, analysis, TTS, and file management |\n| **Media** | `view_media` | Interactive media player via MCP App protocol |\n\n> **Full API documentation**: See [docs/api-reference.md](docs/api-reference.md)\n\n## Basic Workflows\n\n### Generate a Video\n```python\n# Create video from text\nvideo = create_video(\n    prompt=\"A serene mountain landscape at sunrise\",\n    model=\"sora-2\",\n    seconds=\"8\",\n    size=\"1280x720\"\n)\n\n# Poll for completion\nstatus = get_video_status(video.id)\n\n# Download when ready\ndownload_video(video.id, filename=\"mountain_sunrise.mp4\")\n```\n\n### Generate with Reference Image\n```python\n# 1. Generate reference image (gpt-image-1.5, synchronous)\ngenerate_image(\n    prompt=\"futuristic pilot in mech cockpit\",\n    size=\"1536x1024\",\n    filename=\"pilot.png\"\n)\n\n# 2. Prepare for video (resize to Sora dimensions)\nprepare_reference_image(\"pilot.png\", \"1280x720\", resize_mode=\"crop\")\n\n# 3. Animate\nvideo = create_video(\n    prompt=\"The pilot looks up and smiles\",\n    size=\"1280x720\",\n    input_reference_filename=\"pilot_1280x720.png\"\n)\n```\n\n### Audio Transcription\n```python\n# List available audio files\nfiles = list_audio_files(format=\"mp3\")\n\n# Transcribe\nresult = transcribe_audio(\"interview.mp3\")\n\n# Or analyze with GPT-4o\nanalysis = chat_with_audio(\n    \"meeting.mp3\",\n    user_prompt=\"Summarize key decisions and action items\"\n)\n```\n\n## Documentation\n\n- **[API Reference](docs/api-reference.md)** - Complete tool documentation with parameters and examples\n- **[Reference Images Guide](docs/reference-images.md)** - Working with reference images and resizing\n- **[Image Generation Guide](docs/image-generation.md)** - Generating and editing reference images\n- **[Sora Prompting Guide](docs/sora2-prompting-guide.md)** - Crafting effective video prompts\n- **[Audio Features](docs/audio/README.md)** - Audio transcription, chat, and TTS\n- **[Performance & Architecture](docs/async-optimizations.md)** - Technical details and benchmarks\n\n## Transport Modes\n\n| Mode | Command | Use Case |\n|------|---------|----------|\n| **stdio** (default) | `uv run sanzaru` | Claude Desktop, Claude Code, local MCP clients |\n| **HTTP** | `uv run sanzaru --transport http` | Remote access, Databricks Apps, web clients |\n\n## Storage Backends\n\n| Backend | Config | Use Case |\n|---------|--------|----------|\n| **Local** (default) | `SANZARU_MEDIA_PATH=/path/to/media` | Development, local deployments |\n| **Databricks** | `STORAGE_BACKEND=databricks` | Databricks Apps with Unity Catalog Volumes |\n\nThe Databricks backend supports per-user storage isolation via the `user_context` module, enabling multi-tenant deployments where each user's media is stored under their own volume prefix.\n\nSee [CLAUDE.md](CLAUDE.md) for full configuration details.\n\n## Performance\n\nFully asynchronous architecture with proven scalability:\n- ✅ 32+ concurrent operations verified\n- ✅ 8-10x speedup for parallel tasks\n- ✅ Non-blocking I/O with `aiofiles` + `anyio`\n- ✅ Python 3.14 free-threading ready\n\nSee [docs/async-optimizations.md](docs/async-optimizations.md) for technical details.\n\n## License\n\n[MIT](LICENSE)\n"
      },
      "plugins": [
        {
          "name": "sanzaru",
          "source": "./plugin",
          "description": "MCP server for OpenAI multimodal APIs (Sora video, image generation, audio)",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add TJC-LP/sanzaru",
            "/plugin install sanzaru@sanzaru-marketplace"
          ]
        }
      ]
    }
  ]
}