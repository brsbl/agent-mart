{
  "author": {
    "id": "Aaronontheweb",
    "display_name": "Aaron Stannard",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/326939?u=8a12788a87d75bae37619696ae50c01761be7024&v=4",
    "url": "https://github.com/Aaronontheweb",
    "bio": "CEO @petabridge \r\n\r\nMaintainer: @akkadotnet ",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 26,
      "total_stars": 125,
      "total_forks": 12
    }
  },
  "marketplaces": [
    {
      "name": "dotnet-skills",
      "version": null,
      "description": "Official Claude Code Marketplace for .NET development - C#, F#, Akka.NET, Aspire, testing frameworks, and specialized tools",
      "owner_info": {
        "name": "Aaron Stannard",
        "url": "https://github.com/Aaronontheweb"
      },
      "keywords": [],
      "repo_full_name": "Aaronontheweb/dotnet-skills",
      "repo_url": "https://github.com/Aaronontheweb/dotnet-skills",
      "repo_description": "Claude Code skills and sub-agents for .NET Developers",
      "homepage": null,
      "signals": {
        "stars": 125,
        "forks": 12,
        "pushed_at": "2026-01-29T13:46:40Z",
        "created_at": "2025-11-12T13:54:30Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 600
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 1652
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 10046
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/akka-net-specialist.md",
          "type": "blob",
          "size": 3254
        },
        {
          "path": "agents/docfx-specialist.md",
          "type": "blob",
          "size": 4168
        },
        {
          "path": "agents/dotnet-benchmark-designer.md",
          "type": "blob",
          "size": 3705
        },
        {
          "path": "agents/dotnet-concurrency-specialist.md",
          "type": "blob",
          "size": 3418
        },
        {
          "path": "agents/dotnet-performance-analyst.md",
          "type": "blob",
          "size": 4300
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/aspire-configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/aspire-configuration/SKILL.md",
          "type": "blob",
          "size": 24457
        },
        {
          "path": "skills/akka/best-practices",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/best-practices/SKILL.md",
          "type": "blob",
          "size": 28418
        },
        {
          "path": "skills/akka/hosting-actor-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/hosting-actor-patterns/SKILL.md",
          "type": "blob",
          "size": 16135
        },
        {
          "path": "skills/akka/management",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/management/SKILL.md",
          "type": "blob",
          "size": 21485
        },
        {
          "path": "skills/akka/testing-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/akka/testing-patterns/SKILL.md",
          "type": "blob",
          "size": 38679
        },
        {
          "path": "skills/aspire",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/aspire/integration-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/aspire/integration-testing/SKILL.md",
          "type": "blob",
          "size": 24762
        },
        {
          "path": "skills/aspire/service-defaults",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/aspire/service-defaults/SKILL.md",
          "type": "blob",
          "size": 10416
        },
        {
          "path": "skills/aspnetcore",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/aspnetcore/transactional-emails",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/aspnetcore/transactional-emails/SKILL.md",
          "type": "blob",
          "size": 14554
        },
        {
          "path": "skills/csharp",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/csharp/api-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/csharp/api-design/SKILL.md",
          "type": "blob",
          "size": 9904
        },
        {
          "path": "skills/csharp/coding-standards",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/csharp/coding-standards/SKILL.md",
          "type": "blob",
          "size": 43804
        },
        {
          "path": "skills/csharp/concurrency-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/csharp/concurrency-patterns/SKILL.md",
          "type": "blob",
          "size": 19987
        },
        {
          "path": "skills/csharp/type-design-performance",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/csharp/type-design-performance/SKILL.md",
          "type": "blob",
          "size": 9986
        },
        {
          "path": "skills/data",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/data/database-performance",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/data/database-performance/SKILL.md",
          "type": "blob",
          "size": 12697
        },
        {
          "path": "skills/data/efcore-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/data/efcore-patterns/SKILL.md",
          "type": "blob",
          "size": 16160
        },
        {
          "path": "skills/dotnet",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/local-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/local-tools/SKILL.md",
          "type": "blob",
          "size": 8895
        },
        {
          "path": "skills/dotnet/package-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/package-management/SKILL.md",
          "type": "blob",
          "size": 12119
        },
        {
          "path": "skills/dotnet/project-structure",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/project-structure/SKILL.md",
          "type": "blob",
          "size": 15332
        },
        {
          "path": "skills/dotnet/serialization",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/serialization/SKILL.md",
          "type": "blob",
          "size": 11121
        },
        {
          "path": "skills/dotnet/slopwatch",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dotnet/slopwatch/SKILL.md",
          "type": "blob",
          "size": 8460
        },
        {
          "path": "skills/meta",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/meta/marketplace-publishing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/meta/marketplace-publishing/SKILL.md",
          "type": "blob",
          "size": 6066
        },
        {
          "path": "skills/microsoft-extensions",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/microsoft-extensions/configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/microsoft-extensions/configuration/SKILL.md",
          "type": "blob",
          "size": 19582
        },
        {
          "path": "skills/microsoft-extensions/dependency-injection",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/microsoft-extensions/dependency-injection/SKILL.md",
          "type": "blob",
          "size": 21152
        },
        {
          "path": "skills/testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/testing/crap-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/testing/crap-analysis/SKILL.md",
          "type": "blob",
          "size": 11007
        },
        {
          "path": "skills/testing/playwright-blazor",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/testing/playwright-blazor/SKILL.md",
          "type": "blob",
          "size": 16936
        },
        {
          "path": "skills/testing/snapshot-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/testing/snapshot-testing/SKILL.md",
          "type": "blob",
          "size": 9170
        },
        {
          "path": "skills/testing/testcontainers",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/testing/testcontainers/SKILL.md",
          "type": "blob",
          "size": 25005
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"dotnet-skills\",\n  \"description\": \"Official Claude Code Marketplace for .NET development - C#, F#, Akka.NET, Aspire, testing frameworks, and specialized tools\",\n  \"owner\": {\n    \"name\": \"Aaron Stannard\",\n    \"url\": \"https://github.com/Aaronontheweb\"\n  },\n  \"repository\": \"https://github.com/Aaronontheweb/dotnet-skills\",\n  \"plugins\": [\n    {\n      \"name\": \"dotnet-skills\",\n      \"source\": \"./\",\n      \"version\": \"1.0.0\",\n      \"description\": \"Complete .NET development toolkit with 9 skills and 5 specialized agents covering Akka.NET, Aspire, testing, and modern C# patterns\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"dotnet-skills\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Comprehensive .NET development skills and agents for Claude Code - covering C#, F#, Akka.NET, Aspire, testing frameworks, and specialized tools\",\n  \"author\": {\n    \"name\": \"Aaron Stannard\",\n    \"url\": \"https://github.com/Aaronontheweb\"\n  },\n  \"repository\": \"https://github.com/Aaronontheweb/dotnet-skills\",\n  \"skills\": [\n    \"./skills/akka/best-practices\",\n    \"./skills/akka/testing-patterns\",\n    \"./skills/akka/hosting-actor-patterns\",\n    \"./skills/akka/aspire-configuration\",\n    \"./skills/akka/management\",\n    \"./skills/aspire/integration-testing\",\n    \"./skills/aspire/service-defaults\",\n    \"./skills/aspnetcore/transactional-emails\",\n    \"./skills/csharp/coding-standards\",\n    \"./skills/csharp/concurrency-patterns\",\n    \"./skills/csharp/api-design\",\n    \"./skills/csharp/type-design-performance\",\n    \"./skills/data/efcore-patterns\",\n    \"./skills/data/database-performance\",\n    \"./skills/dotnet/project-structure\",\n    \"./skills/dotnet/local-tools\",\n    \"./skills/dotnet/slopwatch\",\n    \"./skills/dotnet/package-management\",\n    \"./skills/dotnet/serialization\",\n    \"./skills/microsoft-extensions/configuration\",\n    \"./skills/microsoft-extensions/dependency-injection\",\n    \"./skills/testing/testcontainers\",\n    \"./skills/testing/playwright-blazor\",\n    \"./skills/testing/crap-analysis\",\n    \"./skills/testing/snapshot-testing\"\n  ],\n  \"agents\": [\n    \"./agents/akka-net-specialist.md\",\n    \"./agents/docfx-specialist.md\",\n    \"./agents/dotnet-benchmark-designer.md\",\n    \"./agents/dotnet-concurrency-specialist.md\",\n    \"./agents/dotnet-performance-analyst.md\"\n  ]\n}\n",
        "README.md": "# .NET Skills for Claude Code\n\nA comprehensive Claude Code plugin with **25 skills** and **5 specialized agents** for professional .NET development. Battle-tested patterns from production systems covering C#, Akka.NET, Aspire, EF Core, testing, and performance optimization.\n\n## Installation\n\nAdd the marketplace (one-time):\n\n```\n/plugin marketplace add Aaronontheweb/dotnet-skills\n```\n\nInstall the plugin:\n\n```\n/plugin install dotnet-skills\n```\n\nTo update:\n\n```\n/plugin marketplace update\n```\n\n---\n\n## OpenCode Installation\n\nOpenCode (https://opencode.ai/) is an open-source AI coding assistant that supports the same skill/agent format. These skills and agents are fully compatible with OpenCode.\n\n### Manual Installation\n\n#### 1.Clone the repository:\n\n```bash\ngit clone https://github.com/Aaronontheweb/dotnet-skills.git\ncd dotnet-skills\n```\n\n#### 2.Install skills:\n\n```bash\n# Create OpenCode skills directory\nmkdir -p ~/.config/opencode/skills\n\n# Install each skill (skill name must match frontmatter 'name' field)\nfor skill_file in $(find skills -name \"SKILL.md\"); do\n    skill_name=$(grep -m1 \"^name:\" \"$skill_file\" | sed 's/name: *//')\n    mkdir -p ~/.config/opencode/skills/$skill_name\ncp \"$skill_file\" ~/.config/opencode/skills/$skill_name/SKILL.md\ndone\n```\n\n#### 3.Install agents:\n\n```bash\n# Create OpenCode agents directory\nmkdir -p ~/.config/opencode/agents\n\n# Install each agent\nfor agent_file in agents/\\*.md; do\ncp \"$agent_file\" ~/.config/opencode/agents/\ndone\n```\n\n#### 4. Restart OpenCode to load the new skills and agents.\n\n### AI-Assisted Installation\n\nIf you're using OpenCode or another AI coding assistant, you can ask it to install these skills automatically:\n\n```\nInstall the .NET skills from https://github.com/Aaronontheweb/dotnet-skills to my OpenCode configuration\n```\n\n> The AI will:\n\n```\n1. Clone the repository\n2. Extract skill names from SKILL.md frontmatter\n3. Create properly structured directories in ~/.config/opencode/skills/\n4. Copy agent files to ~/.config/opencode/agents/\n   Installed Locations\n   | Type | Location |\n   |------|----------|\n   | Skills | ~/.config/opencode/skills/<skill-name>/SKILL.md |\n   | Agents | ~/.config/opencode/agents/<agent-name>.md |\n   Compatibility Note\n   The SKILL.md and agent markdown formats follow the Agent Skills open standard (https://opencode.ai/docs/skills/), which is compatible with multiple AI coding tools including Claude Code and OpenCode.\n```\n\n---\n\n## Specialized Agents\n\nAgents are AI personas with deep domain expertise. They're invoked automatically when Claude Code detects relevant tasks.\n\n| Agent                             | Expertise                                                              |\n| --------------------------------- | ---------------------------------------------------------------------- |\n| **akka-net-specialist**           | Actor systems, clustering, persistence, Akka.Streams, message patterns |\n| **dotnet-concurrency-specialist** | Threading, async/await, race conditions, deadlock analysis             |\n| **dotnet-benchmark-designer**     | BenchmarkDotNet setup, custom benchmarks, measurement strategies       |\n| **dotnet-performance-analyst**    | Profiler analysis, benchmark interpretation, regression detection      |\n| **docfx-specialist**              | DocFX builds, API documentation, markdown linting                      |\n\n---\n\n## Skills Library\n\n### Akka.NET\n\nProduction patterns for building distributed systems with Akka.NET.\n\n| Skill                      | What You'll Learn                                                           |\n| -------------------------- | --------------------------------------------------------------------------- |\n| **best-practices**         | EventStream vs DistributedPubSub, supervision strategies, actor hierarchies |\n| **testing-patterns**       | Akka.Hosting.TestKit, async assertions, TestProbe patterns                  |\n| **hosting-actor-patterns** | Props factories, `IRequiredActor<T>`, DI scope management in actors         |\n| **aspire-configuration**   | Akka.NET + .NET Aspire integration, HOCON with IConfiguration               |\n| **management**             | Akka.Management, health checks, cluster bootstrap                           |\n\n### C# Language\n\nModern C# patterns for clean, performant code.\n\n| Skill                       | What You'll Learn                                                       |\n| --------------------------- | ----------------------------------------------------------------------- |\n| **coding-standards**        | Records, pattern matching, nullable types, value objects, no AutoMapper |\n| **concurrency-patterns**    | When to use Task vs Channel vs lock vs actors                           |\n| **api-design**              | Extend-only design, API/wire compatibility, versioning strategies       |\n| **type-design-performance** | Sealed classes, readonly structs, static pure functions, Span&lt;T&gt;  |\n\n### Data Access\n\nDatabase patterns that scale.\n\n| Skill                    | What You'll Learn                                               |\n| ------------------------ | --------------------------------------------------------------- |\n| **efcore-patterns**      | Entity configuration, migrations, query optimization            |\n| **database-performance** | Read/write separation, N+1 prevention, AsNoTracking, row limits |\n\n### .NET Aspire\n\nCloud-native application orchestration.\n\n| Skill                   | What You'll Learn                                            |\n| ----------------------- | ------------------------------------------------------------ |\n| **integration-testing** | DistributedApplicationTestingBuilder, Aspire.Hosting.Testing |\n| **service-defaults**    | OpenTelemetry, health checks, resilience, service discovery  |\n\n### ASP.NET Core\n\nWeb application patterns.\n\n| Skill                    | What You'll Learn                                      |\n| ------------------------ | ------------------------------------------------------ |\n| **transactional-emails** | MJML templates, variable substitution, Mailpit testing |\n\n### .NET Ecosystem\n\nCore .NET development practices.\n\n| Skill                  | What You'll Learn                                                      |\n| ---------------------- | ---------------------------------------------------------------------- |\n| **project-structure**  | Solution layout, Directory.Build.props, layered architecture           |\n| **package-management** | Central Package Management (CPM), shared version variables, dotnet CLI |\n| **serialization**      | Protobuf, MessagePack, System.Text.Json source generators, AOT         |\n| **local-tools**        | dotnet tool manifests, team-shared tooling                             |\n| **slopwatch**          | Detect LLM-generated anti-patterns in your codebase                    |\n\n### Microsoft.Extensions\n\nDependency injection and configuration patterns.\n\n| Skill                    | What You'll Learn                                                 |\n| ------------------------ | ----------------------------------------------------------------- |\n| **configuration**        | IOptions pattern, environment-specific config, secrets management |\n| **dependency-injection** | IServiceCollection extensions, scope management, keyed services   |\n\n### Testing\n\nComprehensive testing strategies.\n\n| Skill                 | What You'll Learn                                             |\n| --------------------- | ------------------------------------------------------------- |\n| **testcontainers**    | Docker-based integration tests, PostgreSQL, Redis, RabbitMQ   |\n| **playwright-blazor** | E2E testing for Blazor apps, page objects, async assertions   |\n| **crap-analysis**     | CRAP scores, coverage thresholds, ReportGenerator integration |\n| **snapshot-testing**  | Verify library, approval testing, API response validation     |\n\n---\n\n## Key Principles\n\nThese skills emphasize patterns that work in production:\n\n- **Immutability by default** - Records, readonly structs, value objects\n- **Type safety** - Nullable reference types, strongly-typed IDs\n- **Composition over inheritance** - No abstract base classes, sealed by default\n- **Performance-aware** - Span&lt;T&gt;, pooling, deferred enumeration\n- **Testable** - DI everywhere, pure functions, explicit dependencies\n- **No magic** - No AutoMapper, no reflection-heavy frameworks\n\n---\n\n## Repository Structure\n\n```\ndotnet-skills/\n├── .claude-plugin/\n│   └── plugin.json         # Plugin manifest\n├── agents/                 # 5 specialized agents\n│   ├── akka-net-specialist.md\n│   ├── docfx-specialist.md\n│   ├── dotnet-benchmark-designer.md\n│   ├── dotnet-concurrency-specialist.md\n│   └── dotnet-performance-analyst.md\n└── skills/                 # 25 comprehensive skills\n    ├── akka/               # Akka.NET (5 skills)\n    ├── aspire/             # .NET Aspire (2 skills)\n    ├── aspnetcore/         # ASP.NET Core (1 skill)\n    ├── csharp/             # C# language (4 skills)\n    ├── data/               # Data access (2 skills)\n    ├── dotnet/             # .NET ecosystem (5 skills)\n    ├── microsoft-extensions/  # DI & config (2 skills)\n    └── testing/            # Testing (4 skills)\n```\n\n---\n\n## Contributing\n\nWant to add a skill or agent? PRs welcome!\n\n1. Create `skills/<category>/<skill-name>/SKILL.md` (or `agents/<name>/AGENT.md`)\n2. Add the path to `.claude-plugin/plugin.json`\n3. Submit a PR\n\nSkills should be comprehensive reference documents (10-40KB) with concrete examples and anti-patterns.\n\n---\n\n## Author\n\nCreated by [Aaron Stannard](https://aaronstannard.com/) ([@Aaronontheweb](https://github.com/Aaronontheweb))\n\nPatterns drawn from production systems including [Akka.NET](https://getakka.net/), [Petabridge](https://petabridge.com/), and [Sdkbin](https://sdkbin.com/).\n\n## License\n\nMIT License - Copyright (c) 2025 Aaron Stannard\n\nSee [LICENSE](LICENSE) for full details.\n",
        "agents/akka-net-specialist.md": "---\nname: akka-net-specialist\ndescription: Expert in Akka.NET architecture, actor systems, and distributed computing patterns. Specializes in analyzing actor lifecycle issues, message passing problems, cluster coordination, persistence, and stream processing. Use for Akka.NET-specific debugging, architecture decisions, and understanding actor system behavior.\n---\n\nYou are an Akka.NET architecture specialist with deep expertise in the actor model and distributed systems. You understand the intricacies of concurrent, fault-tolerant systems built with Akka.NET.\n\n**Reference Materials:**\n- **Official Documentation**: Use https://getakka.net/ for definitive API documentation, architecture guides, and technical specifications\n- **Petabridge Bootcamp**: Reference https://petabridge.com/bootcamp/lessons/ for modern Akka.NET patterns, testing approaches, and architectural principles representing current best practices\n- **GitHub Repository**: Consult https://github.com/akkadotnet/akka.net for source code analysis, issue patterns, and test examples\n\n**Core Expertise Areas:**\n\n**Actor System Fundamentals:**\n- Actor lifecycle management (creation, stopping, restarting, supervision)\n- Message passing semantics and delivery guarantees\n- Actor hierarchy and supervision strategies\n- ActorRef resolution and location transparency\n- Dispatcher configuration and threading models\n\n**Concurrency in Actor Systems:**\n- Actor mailbox processing and message ordering\n- Ask vs Tell patterns and their implications\n- Stashing and unstashing message behavior\n- Actor state isolation and thread safety guarantees\n- Scheduler and timer operations within actor context\n\n**Distributed Systems Components:**\n- Akka.Remote: Remote actor communication and serialization\n- Akka.Cluster: Membership, leader election, split-brain handling\n- Akka.ClusterSharding: Entity distribution and rebalancing\n- Akka.ClusterSingleton: Single-point coordination patterns\n- Network partition handling and failure detection\n\n**Persistence Patterns:**\n- Event sourcing with Akka.Persistence\n- Snapshot management and recovery strategies\n- Persistence journals and snapshot stores\n- AtLeastOnceDelivery guarantees and duplicate handling\n\n**Stream Processing:**\n- Akka.Streams backpressure and flow control\n- Stream materialization and lifecycle\n- Error handling in stream processing\n- Integration between actors and streams\n\n**Testing Challenges:**\n- TestKit patterns and limitations\n- MultiNode testing for cluster scenarios\n- Timing-sensitive test patterns\n- Common sources of test flakiness in actor systems\n\n**Diagnostic Approach:**\nWhen analyzing issues:\n1. Identify which Akka.NET subsystem is involved\n2. Consider actor lifecycle state and supervision impact\n3. Analyze message flow and potential ordering issues\n4. Evaluate timing assumptions and async boundaries\n5. Check for proper resource cleanup and disposal\n6. Consider cluster state transitions and network conditions\n\n**Common Anti-Patterns to Identify:**\n- Blocking operations within actors\n- Shared mutable state between actors\n- Improper supervision strategy configuration\n- Resource leaks in actor disposal\n- Incorrect use of Futures/Tasks within actor context\n- Message ordering assumptions across actor boundaries",
        "agents/docfx-specialist.md": "---\nname: docfx-specialist\ndescription: Expert in DocFX documentation system, markdown formatting, and Akka.NET documentation standards. Handles DocFX-specific syntax, API references, build validation, and compliance with project documentation guidelines. Integrates markdownlint and DocFX compilation checks.\n---\n\nYou are a DocFX documentation specialist with expertise in the DocFX static site generator and Akka.NET documentation standards.\n\n**Reference Standards:**\n- **Akka.NET Documentation Guidelines**: Follow https://getakka.net/community/contributing/documentation-guidelines.html for authoritative standards\n- **DocFX Documentation**: Reference official DocFX syntax and best practices\n- **Akka.NET Build Pipeline**: Use validation steps from the project's PR validation pipeline\n\n**DocFX Technical Expertise:**\n\n**Markdown Extensions:**\n- DocFX-specific markdown syntax and metadata headers\n- Cross-reference syntax using `@` notation for API links\n- Include file syntax `[!include[]]` for shared content\n- Code snippet embedding with `[!code-csharp[]]` references\n- Tabbed content using `# [Tab Name]` syntax\n- Note callouts: `[!NOTE]`, `[!WARNING]`, `[!TIP]`, `[!IMPORTANT]`\n\n**API Documentation Integration:**\n- Proper linking to API documentation using `@Namespace.ClassName` syntax\n- Cross-referencing between conceptual and API docs\n- Triple-slash XML comments integration\n- Code analysis attributes for documentation\n\n**Build System Integration:**\n- DocFX project configuration (`docfx.json`)\n- Metadata and table of contents (`toc.yml`) management\n- Template and theme customization\n- Build validation with `docfx build --warningsAsErrors --disableGitFeatures`\n\n**Quality Assurance Tools:**\n\n**Markdown Linting:**\n- Run `markdownlint-cli2` with project-specific configuration\n- Use `.markdownlint-cli2.jsonc` rules for consistency\n- Catch formatting issues: headers, lists, links, whitespace\n- Enforce markdown best practices and standards\n\n**DocFX Validation:**\n- Execute `docfx build docs/docfx.json --warningsAsErrors --disableGitFeatures`\n- Validate all cross-references and API links\n- Detect broken internal and external links\n- Ensure all includes and code embeds resolve correctly\n- Report compilation errors and warnings as actionable feedback\n\n**Content Organization:**\n- Proper folder structure following Akka.NET conventions\n- Logical information hierarchy and navigation flow\n- Consistent naming conventions for files and folders\n- Appropriate use of conceptual vs API documentation sections\n\n**Code Integration Best Practices:**\n- Use `[!code-csharp[SampleName](~/samples/path/file.cs)]` for external code files\n- Prefer linked code files over inline code blocks to prevent drift\n- Ensure sample code compiles and follows project coding standards\n- Maintain synchronization between docs and actual working samples\n\n**Validation Workflow:**\nBefore finalizing documentation:\n1. **Markdown Lint Check**: Run markdownlint-cli2 to catch formatting issues\n2. **DocFX Compile**: Build docs with warnings as errors to validate links\n3. **Link Verification**: Ensure all external links are accessible\n4. **Code Sample Testing**: Verify referenced code files exist and compile\n5. **Navigation Check**: Confirm TOC structure and page relationships\n\n**Common Issues to Detect:**\n- Broken cross-references to API documentation\n- Missing or incorrect include file paths\n- Inconsistent markdown formatting (headers, lists, code blocks)\n- Dead external links or outdated URLs\n- Orphaned documentation pages not linked in TOC\n- Code samples that don't match current API versions\n\n**Error Reporting:**\nProvide specific, actionable feedback:\n- Line numbers and exact syntax corrections\n- Proper DocFX syntax alternatives for common mistakes\n- Clear explanations of why certain patterns are preferred\n- Links to relevant documentation guidelines when appropriate\n\n**Integration with Build Pipeline:**\n- Understand the PR validation workflow used in Akka.NET\n- Recommend running the same validation steps locally before commits\n- Suggest fixes that align with the project's CI/CD quality gates\n- Help troubleshoot DocFX build failures and warning messages",
        "agents/dotnet-benchmark-designer.md": "---\nname: dotnet-benchmark-designer\ndescription: Expert in designing effective .NET performance benchmarks and instrumentation. Specializes in BenchmarkDotNet patterns, custom benchmark design, profiling setup, and choosing the right measurement approach for different scenarios. Knows when BenchmarkDotNet isn't suitable and custom benchmarks are needed.\n---\n\nYou are a .NET performance benchmark design specialist with expertise in creating accurate, reliable, and meaningful performance tests.\n\n**Core Expertise Areas:**\n\n**BenchmarkDotNet Mastery:**\n- Benchmark attribute patterns and configuration\n- Job configuration for different runtime targets\n- Memory diagnostics and allocation measurement\n- Statistical analysis configuration and interpretation\n- Parameterized benchmarks and data sources\n- Setup/cleanup lifecycle management\n- Export formats and CI integration\n\n**When BenchmarkDotNet Isn't Suitable:**\n- Large-scale integration scenarios requiring complex setup\n- Long-running benchmarks (>30 seconds) with state transitions\n- Multi-process or distributed system measurements\n- Real-time performance monitoring during production load\n- Benchmarks requiring external system coordination\n- Memory-mapped files or system resource interaction\n\n**Custom Benchmark Design:**\n- Stopwatch vs QueryPerformanceCounter usage\n- GC measurement and pressure analysis\n- Thread contention and CPU utilization metrics\n- Custom metric collection and aggregation\n- Baseline establishment and storage strategies\n- Statistical significance and confidence intervals\n\n**Profiling Integration:**\n- JetBrains dotTrace integration for CPU profiling\n- JetBrains dotMemory for memory allocation analysis\n- ETW (Event Tracing for Windows) custom events\n- PerfView and custom ETW providers\n- Continuous profiling in benchmark scenarios\n\n**Instrumentation Patterns:**\n- Activity and DiagnosticSource integration\n- Performance counter creation and monitoring\n- Custom metrics collection without affecting performance\n- Async operation measurement challenges\n- Lock-free measurement techniques\n\n**Benchmark Categories:**\n- **Micro-benchmarks**: Single method/operation measurement\n- **Component benchmarks**: Class or module-level testing\n- **Integration benchmarks**: Multi-component interaction\n- **Load benchmarks**: Sustained performance under load\n- **Regression benchmarks**: Change impact measurement\n\n**Design Principles:**\n- Minimize measurement overhead and observer effect\n- Establish proper warmup and iteration counts\n- Control for environmental variables (GC, JIT, CPU affinity)\n- Design for repeatability and determinism\n- Plan for baseline storage and comparison\n- Consider statistical power and sample sizes\n\n**Common Anti-Patterns to Avoid:**\n- Measuring in Debug mode or with debugger attached\n- Insufficient warmup causing JIT compilation noise\n- Shared state between benchmark iterations\n- Console output or logging during measurement\n- Synchronous blocking in async benchmarks\n- Ignoring GC impact on allocation-heavy operations\n\n**Benchmark Code Generation:**\nWhen creating benchmarks, generate complete, runnable code including:\n- Proper using statements and namespace organization\n- BenchmarkDotNet attributes and configuration\n- Setup and cleanup methods\n- Parameter sources and data initialization\n- Memory diagnostic configuration when relevant\n- Export configuration for results analysis\n\n**Measurement Strategy Selection:**\nHelp choose between:\n- BenchmarkDotNet for isolated, repeatable micro/component tests\n- Custom harnesses for integration or long-running scenarios\n- Profiler-assisted measurement for bottleneck identification\n- Production monitoring for real-world performance validation",
        "agents/dotnet-concurrency-specialist.md": "---\nname: dotnet-concurrency-specialist\ndescription: Expert in .NET concurrency, threading, and race condition analysis. Specializes in Task/async patterns, thread safety, synchronization primitives, and identifying timing-dependent bugs in multithreaded .NET applications. Use for analyzing racy unit tests, deadlocks, and concurrent code issues.\n---\n\nYou are a .NET concurrency specialist with deep expertise in multithreading, async programming, and race condition diagnosis.\n\n**Core Expertise Areas:**\n\n**.NET Threading Fundamentals:**\n- Thread vs ThreadPool vs Task execution models\n- Thread safety and memory model guarantees\n- Volatile fields, memory barriers, and CPU caching effects\n- ThreadLocal storage and thread-specific state\n- Thread lifecycle and disposal patterns\n\n**Async/Await and Task Patterns:**\n- Task creation, scheduling, and completion\n- ConfigureAwait(false) implications and context switching\n- Task synchronization and coordination patterns\n- Deadlock scenarios with sync-over-async\n- TaskCompletionSource and manual task control\n- Cancellation tokens and cooperative cancellation\n\n**Synchronization Primitives:**\n- Lock statements and Monitor class behavior\n- Mutex, Semaphore, and SemaphoreSlim usage\n- ReaderWriterLock patterns and upgrade scenarios\n- ManualResetEvent and AutoResetEvent coordination\n- Barrier and CountdownEvent for multi-phase operations\n- Interlocked operations for lock-free programming\n\n**Race Condition Patterns:**\n- Read-modify-write races and compound operations\n- Check-then-act patterns and TOCTOU issues\n- Lazy initialization races and double-checked locking\n- Collection modification during enumeration\n- Resource disposal races and object lifecycle\n- Static initialization and type constructor races\n\n**Common .NET Race Scenarios:**\n- Dictionary/ConcurrentDictionary usage patterns\n- Event handler registration/deregistration races\n- Timer callback overlapping and disposal\n- IDisposable implementation races\n- Finalizer thread interactions\n- Assembly loading and type initialization races\n\n**Testing and Debugging:**\n- Identifying non-deterministic test failures\n- Stress testing techniques for race conditions\n- Memory model considerations in test scenarios\n- Using Thread.Sleep vs proper synchronization in tests\n- Debugging tools: Concurrency Visualizer, PerfView\n- Static analysis for thread safety issues\n\n**Diagnostic Approach:**\nWhen analyzing race conditions:\n1. Identify shared state and access patterns\n2. Map thread boundaries and execution contexts\n3. Analyze synchronization mechanisms in use\n4. Look for timing assumptions and order dependencies\n5. Check for proper resource cleanup and disposal\n6. Evaluate async boundaries and context marshaling\n\n**Anti-Patterns to Identify:**\n- Synchronous blocking on async operations\n- Improper lock ordering leading to deadlocks\n- Missing synchronization on shared mutable state\n- Assuming method call atomicity without proper locking\n- Race-prone lazy initialization patterns\n- Incorrect use of volatile for complex operations\n- Thread.Sleep() for coordination instead of proper signaling\n\n**Race Condition Root Causes:**\n- CPU instruction reordering and compiler optimizations\n- Cache coherency delays between CPU cores\n- Thread scheduling quantum and preemption points\n- Garbage collection thread suspension effects\n- Just-in-time compilation timing variations\n- Hardware-specific timing differences",
        "agents/dotnet-performance-analyst.md": "---\nname: dotnet-performance-analyst\ndescription: Expert in analyzing .NET application performance data, profiling results, and benchmark comparisons. Specializes in JetBrains profiler analysis, BenchmarkDotNet result interpretation, baseline comparisons, regression detection, and performance bottleneck identification.\n---\n\nYou are a .NET performance analysis specialist with expertise in interpreting profiling data, benchmark results, and identifying performance bottlenecks.\n\n**Core Expertise Areas:**\n\n**JetBrains Profiler Analysis:**\n- **dotTrace CPU profiling**: Call tree analysis, hot path identification, thread contention\n- **dotMemory analysis**: Memory allocation patterns, GC pressure, memory leaks\n- Timeline profiling interpretation and UI responsiveness analysis\n- Performance counter correlation with profiler data\n- Sampling vs tracing profiler mode selection and interpretation\n\n**BenchmarkDotNet Results Analysis:**\n- Statistical interpretation: mean, median, standard deviation significance\n- Percentile analysis and outlier identification\n- Memory allocation analysis and GC impact assessment\n- Scaling analysis across different input sizes\n- Cross-platform performance comparison\n- CI/CD performance regression detection\n\n**Baseline Management and Comparison:**\n- Establishing performance baselines from historical data  \n- Regression detection algorithms and thresholds\n- Performance trend analysis over time\n- Environmental factor normalization (hardware, OS, .NET version)\n- Statistical significance testing for performance changes\n- Performance budget establishment and monitoring\n\n**Bottleneck Identification Patterns:**\n- **CPU-bound**: Hot methods, algorithm complexity, loop optimization\n- **Memory-bound**: Allocation patterns, GC pressure, memory layout\n- **I/O-bound**: Async operation efficiency, batching opportunities\n- **Lock contention**: Synchronization bottlenecks, thread starvation\n- **Cache misses**: Data locality and access patterns\n- **JIT compilation**: Warmup characteristics and tier compilation\n\n**Performance Metrics Interpretation:**\n- Throughput vs latency trade-offs and optimization targets\n- Percentile analysis (P50, P95, P99) for SLA compliance\n- Resource utilization correlation (CPU, memory, I/O)\n- Garbage collection impact on application performance\n- Thread pool starvation and async operation efficiency\n\n**Data Analysis Techniques:**\n- Time series analysis for performance trends\n- Statistical process control for regression detection\n- Correlation analysis between metrics and environmental factors\n- A/B testing interpretation for performance optimizations\n- Load testing result analysis and capacity planning\n\n**Reporting and Recommendations:**\n- Performance improvement priority ranking\n- Cost-benefit analysis for optimization efforts\n- Risk assessment for performance changes\n- Actionable optimization recommendations with code examples\n- Performance monitoring and alerting strategy design\n\n**Common Performance Issues to Identify:**\n- **Sync-over-async deadlocks** and context switching overhead\n- **Boxing/unboxing** in hot paths and generic constraints\n- **String concatenation** and StringBuilder usage patterns\n- **LINQ performance** in hot paths vs explicit loops\n- **Exception handling** overhead in normal flow\n- **Reflection usage** and compilation vs interpretation costs\n- **Large Object Heap** pressure and compaction issues\n\n**Profiler Data Correlation:**\n- Cross-reference CPU and memory profiler results\n- Correlate GC events with performance degradation\n- Map thread contention to specific synchronization points\n- Identify resource leaks through allocation tracking\n- Connect performance issues to specific code paths\n\n**Regression Analysis Framework:**\n- Establish statistical confidence for performance changes\n- Account for environmental variability and measurement noise  \n- Identify performance improvements vs degradations\n- Root cause analysis for performance regressions\n- Historical trend analysis and seasonality detection\n\n**Performance Optimization Validation:**\n- Before/after comparison methodology\n- Multi-metric impact assessment (throughput, latency, memory)\n- Unintended consequence identification\n- Performance optimization ROI calculation\n- Long-term stability assessment of optimizations",
        "skills/akka/aspire-configuration/SKILL.md": "---\nname: akka-net-aspire-configuration\ndescription: Configure Akka.NET with .NET Aspire for local development and production deployments. Covers actor system setup, clustering, persistence, Akka.Management integration, and Aspire orchestration patterns.\n---\n\n# Configuring Akka.NET with .NET Aspire\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up a new Akka.NET project with .NET Aspire orchestration\n- Configuring Akka.Cluster with cluster bootstrapping and discovery\n- Integrating Akka.Persistence with SQL Server\n- Setting up Akka.Management for cluster management\n- Configuring multi-replica actor systems in local development\n- Deploying Akka.NET applications to Kubernetes with Aspire\n\n## Related Skills\n\n- **`akka-net-management`** - Deep dive into Akka.Management, Cluster Bootstrap, and discovery providers (Kubernetes, Azure, Config)\n- **`microsoft-extensions-configuration`** - IValidateOptions patterns for configuration validation\n- **`akka-net-best-practices`** - Cluster/local mode abstractions for testable actor systems\n- **`aspire-integration-testing`** - Testing Aspire applications with real infrastructure\n\n## Core Principles\n\n1. **Configuration via Microsoft.Extensions.Configuration** - Use strongly-typed settings classes bound from appsettings.json (see `microsoft-extensions-configuration` skill)\n2. **Akka.Hosting for DI Integration** - Use the Akka.Hosting library for seamless ASP.NET Core integration\n3. **Aspire for Orchestration** - Let Aspire manage service dependencies, networking, and environment configuration\n4. **Health Checks** - Always configure health checks for clustering, persistence, and readiness\n5. **Separate Concerns** - Keep actor definitions, configuration, and Aspire orchestration in separate layers\n6. **Validate Configuration at Startup** - Use `IValidateOptions<T>` and `.ValidateOnStart()` to fail fast on misconfiguration\n\n## Project Structure\n\n```\nYourSolution/\n├── src/\n│   ├── YourApp.Actors/              # Actor definitions and business logic\n│   │   ├── YourActor.cs\n│   │   └── YourApp.Actors.csproj\n│   ├── YourApp/                     # ASP.NET Core web application\n│   │   ├── Config/\n│   │   │   ├── AkkaConfiguration.cs  # Akka setup extension methods\n│   │   │   └── AkkaSettings.cs       # Configuration model\n│   │   ├── Program.cs\n│   │   ├── appsettings.json\n│   │   └── YourApp.csproj\n│   └── YourApp.AppHost/             # Aspire orchestration\n│       ├── Program.cs\n│       ├── AkkaManagementExtensions.cs\n│       └── YourApp.AppHost.csproj\n```\n\n## Required NuGet Packages\n\n### For Actor Project (YourApp.Actors.csproj)\n```xml\n<ItemGroup>\n  <PackageReference Include=\"Akka.Cluster.Hosting\" />\n  <PackageReference Include=\"Akka.Streams\" />\n</ItemGroup>\n```\n\n### For Web Application (YourApp.csproj)\n```xml\n<ItemGroup>\n  <PackageReference Include=\"Akka.Hosting\" />\n  <PackageReference Include=\"Akka.Cluster.Hosting\" />\n  <PackageReference Include=\"Akka.Persistence.Sql.Hosting\" />\n  <PackageReference Include=\"Akka.Management\" />\n  <PackageReference Include=\"Akka.Management.Cluster.Bootstrap\" />\n  <PackageReference Include=\"Akka.Discovery.KubernetesApi\" />\n  <PackageReference Include=\"Akka.Discovery.Azure\" />\n  <PackageReference Include=\"Akka.Discovery.Config.Hosting\" />\n  <PackageReference Include=\"Petabridge.Cmd.Host\" />\n  <PackageReference Include=\"Petabridge.Cmd.Cluster\" />\n</ItemGroup>\n```\n\n### For AppHost (YourApp.AppHost.csproj)\n```xml\n<Sdk Name=\"Aspire.AppHost.Sdk\" Version=\"$(AspireVersion)\" />\n\n<ItemGroup>\n  <PackageReference Include=\"Aspire.Hosting.AppHost\" />\n  <PackageReference Include=\"Aspire.Hosting.Azure.Storage\" />\n  <PackageReference Include=\"Aspire.Hosting.SqlServer\" />\n</ItemGroup>\n```\n\n## Configuration Model (AkkaSettings.cs)\n\nCreate a strongly-typed configuration class:\n\n```csharp\nusing System.Net;\nusing System.Security.Cryptography.X509Certificates;\nusing Akka.Cluster.Hosting;\nusing Akka.Remote.Hosting;\nusing Petabridge.Cmd.Host;\n\nnamespace YourApp.Config;\n\npublic class AkkaSettings\n{\n    public string ActorSystemName { get; set; } = \"YourSystem\";\n\n    public bool LogConfigOnStart { get; set; } = false;\n\n    public RemoteOptions RemoteOptions { get; set; } = new()\n    {\n        PublicHostName = Dns.GetHostName(),\n        HostName = \"0.0.0.0\",\n        Port = 8081\n    };\n\n    public ClusterOptions ClusterOptions { get; set; } = new()\n    {\n        SeedNodes = [$\"akka.tcp://YourSystem@{Dns.GetHostName()}:8081\"],\n        Roles = [\"your-role\"]\n    };\n\n    public ShardOptions ShardOptions { get; set; } = new();\n\n    public AkkaManagementOptions? AkkaManagementOptions { get; set; }\n\n    public PetabridgeCmdOptions PbmOptions { get; set; } = new()\n    {\n        Host = \"0.0.0.0\",\n        Port = 9110\n    };\n\n    public TlsSettings? TlsSettings { get; set; }\n}\n\npublic class TlsSettings\n{\n    public bool Enabled { get; set; } = false;\n    public string? CertificatePath { get; set; }\n    public string? CertificatePassword { get; set; }\n    public bool ValidateCertificates { get; set; } = true;\n\n    public X509Certificate2? LoadCertificate()\n    {\n        if (string.IsNullOrWhiteSpace(CertificatePath))\n            return null;\n\n        if (!File.Exists(CertificatePath))\n            throw new FileNotFoundException($\"Certificate file not found at: {CertificatePath}\");\n\n        return !string.IsNullOrWhiteSpace(CertificatePassword)\n            ? X509CertificateLoader.LoadPkcs12FromFile(CertificatePath, CertificatePassword)\n            : X509CertificateLoader.LoadCertificateFromFile(CertificatePath);\n    }\n}\n\npublic class AkkaManagementOptions\n{\n    public bool Enabled { get; set; }\n    public string? Hostname { get; set; }\n    public int Port { get; set; } = 8558;\n    public string ServiceName { get; set; } = \"your-service\";\n    public string PortName { get; set; } = \"management\";\n    public int RequiredContactPointsNr { get; set; } = 1;\n    public bool FilterOnFallbackPort { get; set; } = true;\n    public DiscoveryMethod DiscoveryMethod { get; set; } = DiscoveryMethod.Config;\n}\n\npublic enum DiscoveryMethod\n{\n    Config,\n    Kubernetes,\n    AzureTableStorage,\n    AwsEcsTagBased,\n    AwsEc2TagBased\n}\n```\n\n## Akka Configuration Extension Methods (AkkaConfiguration.cs)\n\n```csharp\nusing Akka.Cluster.Hosting;\nusing Akka.Discovery.Azure;\nusing Akka.Discovery.Config.Hosting;\nusing Akka.Discovery.KubernetesApi;\nusing Akka.Hosting;\nusing Akka.Management;\nusing Akka.Management.Cluster.Bootstrap;\nusing Akka.Persistence.Sql.Config;\nusing Akka.Persistence.Sql.Hosting;\nusing Akka.Remote.Hosting;\nusing LinqToDB;\n\nnamespace YourApp.Config;\n\npublic static class AkkaConfiguration\n{\n    public static IServiceCollection ConfigureAkka(\n        this IServiceCollection services,\n        IConfiguration configuration,\n        Action<AkkaConfigurationBuilder, IServiceProvider> additionalConfig)\n    {\n        var akkaSettings = BindAkkaSettings(services, configuration);\n\n        var connectionString = configuration.GetConnectionString(\"DefaultConnection\");\n        if (connectionString is null)\n            throw new Exception(\"DefaultConnection ConnectionString is missing\");\n\n        const string roleName = \"your-role\";\n\n        services.AddAkka(akkaSettings.ActorSystemName, (builder, provider) =>\n        {\n            builder.ConfigureNetwork(provider)\n                .WithAkkaClusterReadinessCheck()\n                .WithActorSystemLivenessCheck()\n                .WithSqlPersistence(\n                    connectionString: connectionString,\n                    providerName: ProviderName.SqlServer2022,\n                    databaseMapping: DatabaseMapping.SqlServer,\n                    tagStorageMode: TagMode.TagTable,\n                    deleteCompatibilityMode: true,\n                    useWriterUuidColumn: true,\n                    autoInitialize: true,\n                    journalBuilder: journalBuilder =>\n                    {\n                        journalBuilder.WithHealthCheck(name: \"Akka.Persistence.Sql.Journal[default]\");\n                    },\n                    snapshotBuilder: snapshotBuilder =>\n                    {\n                        snapshotBuilder.WithHealthCheck(name: \"Akka.Persistence.Sql.SnapshotStore[default]\");\n                    });\n\n            // Add your actors here\n            // Example: builder.WithActors((system, registry) => { ... });\n\n            additionalConfig(builder, provider);\n        });\n\n        return services;\n    }\n\n    public static AkkaSettings BindAkkaSettings(IServiceCollection services, IConfiguration configuration)\n    {\n        var akkaSettings = new AkkaSettings();\n        configuration.GetSection(nameof(AkkaSettings)).Bind(akkaSettings);\n        services.AddSingleton(akkaSettings);\n        return akkaSettings;\n    }\n\n    public static AkkaConfigurationBuilder ConfigureNetwork(\n        this AkkaConfigurationBuilder builder,\n        IServiceProvider serviceProvider)\n    {\n        var settings = serviceProvider.GetRequiredService<AkkaSettings>();\n        var configuration = serviceProvider.GetRequiredService<IConfiguration>();\n\n        // Apply TLS configuration if enabled\n        if (settings.TlsSettings is { Enabled: true })\n        {\n            ConfigureRemoteOptionsWithTls(settings);\n        }\n\n        builder.WithRemoting(settings.RemoteOptions);\n\n        if (settings.AkkaManagementOptions is { Enabled: true })\n        {\n            // Clear seed nodes when using Akka.Management\n            var clusterOptions = settings.ClusterOptions;\n            clusterOptions.SeedNodes = [];\n\n            builder\n                .WithClustering(clusterOptions)\n                .WithAkkaManagement(setup =>\n                {\n                    setup.Http.HostName = settings.AkkaManagementOptions.Hostname?.ToLower();\n                    setup.Http.Port = settings.AkkaManagementOptions.Port;\n                    setup.Http.BindHostName = \"0.0.0.0\";\n                    setup.Http.BindPort = settings.AkkaManagementOptions.Port;\n                })\n                .WithClusterBootstrap(options =>\n                {\n                    options.ContactPointDiscovery.ServiceName = settings.AkkaManagementOptions.ServiceName;\n                    options.ContactPointDiscovery.PortName = settings.AkkaManagementOptions.PortName;\n                    options.ContactPointDiscovery.RequiredContactPointsNr =\n                        settings.AkkaManagementOptions.RequiredContactPointsNr;\n                    options.ContactPointDiscovery.ContactWithAllContactPoints = true;\n                    options.ContactPointDiscovery.StableMargin = TimeSpan.FromSeconds(5);\n                    options.ContactPoint.FilterOnFallbackPort =\n                        settings.AkkaManagementOptions.FilterOnFallbackPort;\n                }, autoStart: true);\n\n            ConfigureDiscovery(builder, settings, configuration);\n        }\n        else\n        {\n            builder.WithClustering(settings.ClusterOptions);\n        }\n\n        return builder;\n    }\n\n    private static void ConfigureDiscovery(\n        AkkaConfigurationBuilder builder,\n        AkkaSettings settings,\n        IConfiguration configuration)\n    {\n        switch (settings.AkkaManagementOptions!.DiscoveryMethod)\n        {\n            case DiscoveryMethod.Kubernetes:\n                builder.WithKubernetesDiscovery();\n                break;\n\n            case DiscoveryMethod.AzureTableStorage:\n                var connectionString = configuration.GetConnectionString(\"AkkaManagementAzure\");\n                if (connectionString is null)\n                    throw new Exception(\"AkkaManagement table storage connection string [AkkaManagementAzure] is missing\");\n\n                builder\n                    .WithAzureDiscovery(options =>\n                    {\n                        options.ServiceName = settings.AkkaManagementOptions.ServiceName;\n                        options.ConnectionString = connectionString;\n                        options.HostName = settings.RemoteOptions.PublicHostName?.ToLower() ?? \"localhost\";\n                        options.Port = settings.AkkaManagementOptions.Port;\n                    })\n                    .AddHocon(AzureDiscovery.DefaultConfiguration(), HoconAddMode.Append);\n                break;\n\n            case DiscoveryMethod.Config:\n                builder.WithConfigDiscovery(options =>\n                {\n                    options.Services.Add(new Service\n                    {\n                        Name = settings.AkkaManagementOptions.ServiceName,\n                        Endpoints =\n                        [\n                            $\"{settings.AkkaManagementOptions.Hostname}:{settings.AkkaManagementOptions.Port}\"\n                        ]\n                    });\n                });\n                break;\n\n            default:\n                throw new ArgumentOutOfRangeException();\n        }\n    }\n\n    private static void ConfigureRemoteOptionsWithTls(AkkaSettings settings)\n    {\n        var tlsSettings = settings.TlsSettings!;\n        var remoteOptions = settings.RemoteOptions;\n\n        var certificate = tlsSettings.LoadCertificate();\n        if (certificate is null)\n            throw new InvalidOperationException(\"TLS is enabled but no certificate could be loaded\");\n\n        remoteOptions.EnableSsl = true;\n        remoteOptions.Ssl = new SslOptions\n        {\n            X509Certificate = certificate,\n            SuppressValidation = !tlsSettings.ValidateCertificates\n        };\n\n        // Update seed nodes to use akka.ssl.tcp:// protocol\n        if (settings.ClusterOptions.SeedNodes?.Length > 0)\n        {\n            settings.ClusterOptions.SeedNodes = settings.ClusterOptions.SeedNodes\n                .Select(node => node.Replace(\"akka.tcp://\", \"akka.ssl.tcp://\"))\n                .ToArray();\n        }\n    }\n}\n```\n\n## Program.cs Integration\n\n```csharp\nusing YourApp.Config;\nusing Petabridge.Cmd.Host;\nusing Petabridge.Cmd.Cluster;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services\nbuilder.Services.AddRazorPages(); // or whatever your app needs\n\n// Configure Akka.NET\nbuilder.Services.ConfigureAkka(builder.Configuration,\n    (configurationBuilder, provider) =>\n    {\n        var options = provider.GetRequiredService<AkkaSettings>();\n\n        // Add Petabridge.Cmd for cluster management\n        configurationBuilder.AddPetabridgeCmd(\n            options: options.PbmOptions,\n            hostConfiguration: cmd =>\n            {\n                cmd.RegisterCommandPalette(ClusterCommands.Instance);\n            });\n    });\n\nvar app = builder.Build();\n\n// Configure middleware\napp.MapRazorPages();\napp.Run();\n```\n\n## Aspire AppHost Configuration (Program.cs)\n\n```csharp\nusing System.Net.Sockets;\n\nvar builder = DistributedApplication.CreateBuilder(args);\n\nvar config = builder.Configuration.GetSection(\"YourApp\")\n    .Get<YourAppConfiguration>() ?? new YourAppConfiguration();\n\nvar saPassword = builder.AddParameter(\n    \"sql-sa-password\",\n    () => \"YourStrong!Passw0rd\",\n    secret: true);\n\nvar sqlServer = builder.AddSqlServer(\"sql\", saPassword);\n\nif (config.UseVolumes)\n{\n    sqlServer.WithDataVolume();\n}\n\nvar db = sqlServer.AddDatabase(\"YourDb\");\n\nvar app = builder.AddProject<Projects.YourApp>(\"yourapp\")\n    .WithReplicas(config.Replicas)\n    .WithReference(db, \"DefaultConnection\")\n    .ConfigureAkkaManagementForApp(config);\n\nbuilder.Build().Run();\n\npublic class YourAppConfiguration\n{\n    public int Replicas { get; set; } = 1;\n    public bool UseVolumes { get; set; } = false;\n    public bool UseAkkaManagement { get; set; } = false;\n}\n```\n\n## Aspire Akka.Management Extensions (AkkaManagementExtensions.cs)\n\n```csharp\nusing System.Net.Sockets;\nusing Aspire.Hosting.Azure;\n\nnamespace YourApp.AppHost;\n\npublic static class AkkaManagementExtensions\n{\n    public static IResourceBuilder<ProjectResource> ConfigureAkkaManagementForApp(\n        this IResourceBuilder<ProjectResource> appBuilder,\n        YourAppConfiguration config)\n    {\n        if (!config.UseAkkaManagement) return appBuilder;\n\n        var builder = appBuilder.ApplicationBuilder;\n\n        // Setup Azure Table Storage for discovery\n        var azureStorage = builder.AddAzureStorage(\"storage\")\n            .RunAsEmulator();\n\n        var tableStorage = azureStorage.AddTables(\"akka-discovery\");\n\n        appBuilder.WaitFor(tableStorage)\n            .WithReference(tableStorage, \"AkkaManagementAzure\");\n\n        // Setup network endpoint ports\n        appBuilder\n            .WithEndpoint(name: \"remote\", protocol: ProtocolType.Tcp,\n                env: \"AkkaSettings__RemoteOptions__Port\")\n            .WithEndpoint(name: \"management\", protocol: ProtocolType.Tcp,\n                env: \"AkkaSettings__AkkaManagementOptions__Port\")\n            .WithEndpoint(name: \"pbm\", protocol: ProtocolType.Tcp,\n                env: \"AkkaSettings__PbmOptions__Port\");\n\n        // Configure Akka.Management settings via environment variables\n        appBuilder\n            .WithEnvironment(\"AkkaSettings__RemoteOptions__PublicHostName\", \"localhost\")\n            .WithEnvironment(\"AkkaSettings__AkkaManagementOptions__Enabled\", \"true\")\n            .WithEnvironment(\"AkkaSettings__AkkaManagementOptions__Hostname\", \"localhost\")\n            .WithEnvironment(\"AkkaSettings__AkkaManagementOptions__DiscoveryMethod\", \"AzureTableStorage\")\n            .WithEnvironment(\"AkkaSettings__AkkaManagementOptions__RequiredContactPointsNr\",\n                config.Replicas.ToString())\n            .WithEnvironment(\"AkkaSettings__AkkaManagementOptions__FilterOnFallbackPort\", \"false\");\n\n        return appBuilder;\n    }\n}\n```\n\n## appsettings.json Configuration\n\n```json\n{\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"Server=localhost;Database=YourDb;User Id=sa;Password=YourStrong!Passw0rd;\"\n  },\n  \"AkkaSettings\": {\n    \"ActorSystemName\": \"YourSystem\",\n    \"LogConfigOnStart\": false,\n    \"RemoteOptions\": {\n      \"PublicHostName\": null,\n      \"HostName\": \"0.0.0.0\",\n      \"Port\": 8081\n    },\n    \"ClusterOptions\": {\n      \"Roles\": [\"your-role\"],\n      \"SeedNodes\": []\n    },\n    \"PbmOptions\": {\n      \"Host\": \"0.0.0.0\",\n      \"Port\": 9110\n    }\n  }\n}\n```\n\n## Common Patterns\n\n### Pattern 1: Actor Registration with Dependency Injection\n\n```csharp\n// In your actor project\npublic static class ActorRegistration\n{\n    public static AkkaConfigurationBuilder AddYourActor(\n        this AkkaConfigurationBuilder builder,\n        string roleName)\n    {\n        builder.WithActors((system, registry, resolver) =>\n        {\n            var props = resolver.Props<YourActor>();\n            var actor = system.ActorOf(props, \"your-actor\");\n            registry.Register<YourActor>(actor);\n        });\n\n        return builder;\n    }\n}\n\n// In AkkaConfiguration.cs\nbuilder\n    .ConfigureNetwork(provider)\n    .WithSqlPersistence(...)\n    .AddYourActor(roleName);  // Register your actor\n```\n\n### Pattern 2: Cluster Sharding Setup\n\n```csharp\nbuilder.WithShardRegion<YourEntityActor>(\n    typeName: \"your-entity\",\n    entityPropsFactory: (_, _, resolver) => resolver.Props<YourEntityActor>(),\n    extractEntityId: ExtractEntityId,\n    extractShardId: ExtractShardId,\n    shardOptions: new ShardOptions\n    {\n        Role = \"your-role\",\n        StateStoreMode = StateStoreMode.Persistence\n    });\n\nprivate static string ExtractEntityId(object message)\n{\n    return message switch\n    {\n        IEntityMessage msg => msg.EntityId,\n        _ => null\n    };\n}\n\nprivate static string ExtractShardId(object message)\n{\n    return message switch\n    {\n        IEntityMessage msg => (msg.EntityId.GetHashCode() % 10).ToString(),\n        _ => null\n    };\n}\n```\n\n### Pattern 3: Health Checks\n\nAlways configure health checks in Program.cs:\n\n```csharp\nbuilder.Services.AddHealthChecks()\n    .AddCheck(\"self\", () => HealthCheckResult.Healthy(\"Application is running\"),\n        tags: new[] { \"liveness\" });\n\n// Akka health checks are added automatically by:\n// - .WithAkkaClusterReadinessCheck()\n// - .WithActorSystemLivenessCheck()\n// - journalBuilder.WithHealthCheck()\n// - snapshotBuilder.WithHealthCheck()\n```\n\n## Common Issues and Solutions\n\n### Issue 1: Cluster Nodes Can't Discover Each Other\n\n**Symptoms:** Nodes stay as \"Unreachable\" in cluster status\n\n**Solution:**\n1. Verify `RequiredContactPointsNr` matches the number of replicas\n2. Check that all nodes use the same `ServiceName` in AkkaManagementOptions\n3. Ensure Azure Table Storage connection string is correct\n4. Verify firewall/network allows TCP on remote and management ports\n\n### Issue 2: Persistence Initialization Fails\n\n**Symptoms:** Application fails to start with SQL connection errors\n\n**Solution:**\n1. Ensure SQL Server is running (check Aspire dashboard)\n2. Verify connection string is correctly configured\n3. Set `autoInitialize: true` in WithSqlPersistence\n4. Check that database exists and is accessible\n\n### Issue 3: Split Brain in Development\n\n**Symptoms:** Multiple separate clusters form instead of one unified cluster\n\n**Solution:**\n1. Use `FilterOnFallbackPort = false` in local development\n2. Ensure all replicas use the same discovery configuration\n3. Set `ContactWithAllContactPoints = true`\n4. Increase `StableMargin` for slower dev machines\n\n## Testing Akka.NET Actors\n\nFor comprehensive Akka.NET testing patterns using **Akka.Hosting.TestKit**, see the `akka-net-testing-patterns` skill.\n\nThat skill covers:\n- Modern testing with Akka.Hosting.TestKit and dependency injection\n- TestProbe patterns for verifying actor interactions\n- Testing persistent actors and event sourcing\n- Local cluster sharding tests with `AkkaExecutionMode.LocalTest`\n- Scenario-based integration tests\n- Best practices and anti-patterns\n\n### Quick Example: Testing Akka + Aspire Integration\n\nWhen testing Aspire applications with Akka.NET actors, combine `aspire-integration-testing` patterns with `akka-net-testing-patterns`:\n\n```csharp\n// Use Aspire's DistributedApplicationTestingBuilder for infrastructure\n// Use Akka.Hosting.TestKit for actor testing\npublic class AkkaAspireIntegrationTests : IAsyncLifetime\n{\n    private DistributedApplication? _app;\n\n    public async Task InitializeAsync()\n    {\n        var appHost = await DistributedApplicationTestingBuilder\n            .CreateAsync<Projects.YourApp_AppHost>();\n\n        _app = await appHost.BuildAsync();\n        await _app.StartAsync();\n    }\n\n    [Fact]\n    public async Task ActorSystem_WithRealDatabase_ShouldPersistEvents()\n    {\n        // Get SQL connection string from Aspire\n        var dbResource = _app!.GetResource(\"yourdb\");\n        var connectionString = await dbResource.GetConnectionStringAsync();\n\n        // Create HttpClient to test actor endpoints\n        var httpClient = _app.CreateHttpClient(\"yourapp\");\n\n        // Test actor behavior through HTTP API\n        var response = await httpClient.PostAsJsonAsync(\"/orders\", new\n        {\n            OrderId = \"ORDER-001\",\n            Amount = 100.00m\n        });\n\n        response.Should().BeSuccessStatusCode();\n\n        // Verify data was persisted to real database\n        await using var connection = new SqlConnection(connectionString);\n        await connection.OpenAsync();\n\n        var events = await connection.QueryAsync<string>(\n            \"SELECT EventType FROM EventJournal WHERE PersistenceId = 'order-ORDER-001'\");\n\n        events.Should().Contain(\"OrderCreated\");\n    }\n\n    public async Task DisposeAsync()\n    {\n        if (_app is not null)\n            await _app.DisposeAsync();\n    }\n}\n```\n\n**For unit testing individual actors**, use `akka-net-testing-patterns` with in-memory persistence (no Aspire needed).\n\n## Best Practices Summary\n\n1. **Always use health checks** - Configure readiness and liveness checks for all components\n2. **Bind settings from configuration** - Never hard-code hostnames, ports, or connection strings\n3. **Use Akka.Management for multi-node** - Don't use static seed nodes for clusters with >1 replica\n4. **Configure TLS for production** - Always use TLS in production environments\n5. **Separate actor logic from configuration** - Keep actors pure and configuration in extension methods\n6. **Use Petabridge.Cmd** - Essential for debugging and managing clusters\n7. **Test with multiple replicas** - Always test with `Replicas > 1` to catch clustering issues\n8. **Monitor persistence health** - Configure health checks for journal and snapshot stores\n",
        "skills/akka/best-practices/SKILL.md": "---\nname: akka-net-best-practices\ndescription: Critical Akka.NET best practices including EventStream vs DistributedPubSub, supervision strategies, error handling, Props vs DependencyResolver, work distribution patterns, and cluster/local mode abstractions for testability.\n---\n\n# Akka.NET Best Practices\n\n## When to Use This Skill\n\nUse this skill when:\n- Designing actor communication patterns\n- Deciding between EventStream and DistributedPubSub\n- Implementing error handling in actors\n- Understanding supervision strategies\n- Choosing between Props patterns and DependencyResolver\n- Designing work distribution across nodes\n- Creating testable actor systems that can run with or without cluster infrastructure\n- Abstracting over Cluster Sharding for local testing scenarios\n\n---\n\n## 1. EventStream vs DistributedPubSub\n\n### Critical: EventStream is LOCAL ONLY\n\n`Context.System.EventStream` is **local to a single ActorSystem process**. It does NOT work across cluster nodes.\n\n```csharp\n// BAD: This only works on a single server\n// When you add a second server, subscribers on server 2 won't receive events from server 1\nContext.System.EventStream.Subscribe(Self, typeof(PostCreated));\nContext.System.EventStream.Publish(new PostCreated(postId, authorId));\n```\n\n**When EventStream is appropriate:**\n- Logging and diagnostics within a single process\n- Local event bus for truly single-process applications\n- Development/testing scenarios\n\n### Use DistributedPubSub for Multi-Node\n\nFor events that must reach actors across multiple cluster nodes, use `Akka.Cluster.Tools.PublishSubscribe`:\n\n```csharp\nusing Akka.Cluster.Tools.PublishSubscribe;\n\npublic class TimelineUpdatePublisher : ReceiveActor\n{\n    private readonly IActorRef _mediator;\n\n    public TimelineUpdatePublisher()\n    {\n        // Get the DistributedPubSub mediator\n        _mediator = DistributedPubSub.Get(Context.System).Mediator;\n\n        Receive<PublishTimelineUpdate>(msg =>\n        {\n            // Publish to a topic - reaches all subscribers across all nodes\n            _mediator.Tell(new Publish($\"timeline:{msg.UserId}\", msg.Update));\n        });\n    }\n}\n\npublic class TimelineSubscriber : ReceiveActor\n{\n    public TimelineSubscriber(UserId userId)\n    {\n        var mediator = DistributedPubSub.Get(Context.System).Mediator;\n\n        // Subscribe to user-specific topic\n        mediator.Tell(new Subscribe($\"timeline:{userId}\", Self));\n\n        Receive<TimelineUpdate>(update =>\n        {\n            // Handle the update - this works across cluster nodes\n        });\n\n        Receive<SubscribeAck>(ack =>\n        {\n            // Subscription confirmed\n        });\n    }\n}\n```\n\n### Akka.Hosting Configuration for DistributedPubSub\n\n```csharp\nbuilder.WithDistributedPubSub(role: null); // Available on all roles, or specify a role\n```\n\n### Topic Design Patterns\n\n| Pattern | Topic Format | Use Case |\n|---------|--------------|----------|\n| Per-user | `timeline:{userId}` | Timeline updates, notifications |\n| Per-entity | `post:{postId}` | Post engagement updates |\n| Broadcast | `system:announcements` | System-wide notifications |\n| Role-based | `workers:rss-poller` | Work distribution |\n\n---\n\n## 2. Supervision Strategies\n\n### Key Clarification: Supervision is for CHILDREN\n\nA supervision strategy defined on an actor dictates **how that actor supervises its children**, NOT how the actor itself is supervised.\n\n```csharp\npublic class ParentActor : ReceiveActor\n{\n    // This strategy applies to children of ParentActor, NOT to ParentActor itself\n    protected override SupervisorStrategy SupervisorStrategy()\n    {\n        return new OneForOneStrategy(\n            maxNrOfRetries: 10,\n            withinTimeRange: TimeSpan.FromSeconds(30),\n            decider: ex => ex switch\n            {\n                ArithmeticException => Directive.Resume,\n                NullReferenceException => Directive.Restart,\n                ArgumentException => Directive.Stop,\n                _ => Directive.Escalate\n            });\n    }\n}\n```\n\n### Default Supervision Strategy\n\nThe default `OneForOneStrategy` already includes rate limiting:\n- **10 restarts within 1 second** = actor is permanently stopped\n- This prevents infinite restart loops\n\n**You rarely need a custom strategy** unless you have specific requirements.\n\n### When to Define Custom Supervision\n\n**Good reasons:**\n- Actor throws exceptions indicating irrecoverable state corruption → Restart\n- Actor throws exceptions that should NOT cause restart (expected failures) → Resume\n- Child failures should affect siblings → Use `AllForOneStrategy`\n- Need different retry limits than the default\n\n**Bad reasons:**\n- \"Just to be safe\" - the default is already safe\n- Don't understand what the actor does - understand it first\n\n### Example: When Custom Supervision Makes Sense\n\n```csharp\npublic class RssFeedCoordinator : ReceiveActor\n{\n    protected override SupervisorStrategy SupervisorStrategy()\n    {\n        return new OneForOneStrategy(\n            maxNrOfRetries: -1, // Unlimited retries\n            withinTimeRange: TimeSpan.FromMinutes(1),\n            decider: ex => ex switch\n            {\n                // HTTP timeout - transient, resume and let the actor retry via its own timer\n                HttpRequestException => Directive.Resume,\n\n                // Feed URL permanently invalid - stop this child, don't restart forever\n                InvalidFeedUrlException => Directive.Stop,\n\n                // Unknown error - restart to clear potentially corrupt state\n                _ => Directive.Restart\n            });\n    }\n}\n```\n\n---\n\n## 3. Error Handling: Supervision vs Try-Catch\n\n### When to Use Try-Catch (Most Cases)\n\n**Use try-catch when:**\n- The failure is **expected** (network timeout, invalid input, external service down)\n- You know **exactly why** the exception occurred\n- You can handle it **gracefully** (retry, return error response, log and continue)\n- Restarting would **not help** (same error would occur again)\n\n```csharp\npublic class RssFeedPollerActor : ReceiveActor\n{\n    public RssFeedPollerActor()\n    {\n        ReceiveAsync<PollFeed>(async msg =>\n        {\n            try\n            {\n                var feed = await _httpClient.GetStringAsync(msg.FeedUrl);\n                var items = ParseFeed(feed);\n                // Process items...\n            }\n            catch (HttpRequestException ex)\n            {\n                // Expected failure - log and schedule retry\n                _log.Warning(\"Feed {Url} unavailable: {Error}\", msg.FeedUrl, ex.Message);\n                Context.System.Scheduler.ScheduleTellOnce(\n                    TimeSpan.FromMinutes(5),\n                    Self,\n                    msg,\n                    Self);\n            }\n            catch (XmlException ex)\n            {\n                // Invalid feed format - log and mark as bad\n                _log.Error(\"Feed {Url} has invalid format: {Error}\", msg.FeedUrl, ex.Message);\n                Sender.Tell(new FeedPollResult.InvalidFormat(msg.FeedUrl));\n            }\n        });\n    }\n}\n```\n\n### When to Let Supervision Handle It\n\n**Let exceptions propagate (trigger supervision) when:**\n- You have **no idea** why the exception occurred\n- The actor's **state might be corrupt**\n- A **restart would help** (fresh state, reconnect resources)\n- It's a **programming error** (NullReferenceException, InvalidOperationException from bad logic)\n\n```csharp\npublic class OrderActor : ReceiveActor\n{\n    private OrderState _state;\n\n    public OrderActor()\n    {\n        Receive<ProcessPayment>(msg =>\n        {\n            // If this throws, we have no idea why - let supervision restart us\n            // A restart will reload state from persistence and might fix the issue\n            var result = _state.ApplyPayment(msg.Amount);\n            Persist(new PaymentApplied(msg.Amount), evt =>\n            {\n                _state = _state.With(evt);\n            });\n        });\n    }\n}\n```\n\n### Anti-Pattern: Swallowing Unknown Exceptions\n\n```csharp\n// BAD: Swallowing exceptions hides problems\npublic class BadActor : ReceiveActor\n{\n    public BadActor()\n    {\n        ReceiveAsync<DoWork>(async msg =>\n        {\n            try\n            {\n                await ProcessWork(msg);\n            }\n            catch (Exception ex)\n            {\n                // This hides all errors - you'll never know something is broken\n                _log.Error(ex, \"Error processing work\");\n                // Actor continues with potentially corrupt state\n            }\n        });\n    }\n}\n\n// GOOD: Handle known exceptions, let unknown ones propagate\npublic class GoodActor : ReceiveActor\n{\n    public GoodActor()\n    {\n        ReceiveAsync<DoWork>(async msg =>\n        {\n            try\n            {\n                await ProcessWork(msg);\n            }\n            catch (HttpRequestException ex)\n            {\n                // Known, expected failure - handle gracefully\n                _log.Warning(\"HTTP request failed: {Error}\", ex.Message);\n                Sender.Tell(new WorkResult.TransientFailure());\n            }\n            // Unknown exceptions propagate to supervision\n        });\n    }\n}\n```\n\n---\n\n## 4. Props vs DependencyResolver\n\n### When to Use Plain Props\n\n**Use `Props.Create()` when:**\n- Actor doesn't need `IServiceProvider` or `IRequiredActor<T>`\n- All dependencies can be passed via constructor\n- Actor is simple and self-contained\n\n```csharp\n// Simple actor with no DI needs\npublic static Props Props(PostId postId, IPostWriteStore store)\n    => Akka.Actor.Props.Create(() => new PostEngagementActor(postId, store));\n\n// Usage\nvar actor = Context.ActorOf(PostEngagementActor.Props(postId, store), postId.ToString());\n```\n\n### When to Use DependencyResolver\n\n**Use `resolver.Props<T>()` when:**\n- Actor needs `IServiceProvider` to create scoped services\n- Actor uses `IRequiredActor<T>` to get references to other actors\n- Actor has many dependencies that are already in DI container\n\n```csharp\n// Actor that needs scoped database connections\npublic class OrderProcessorActor : ReceiveActor\n{\n    public OrderProcessorActor(IServiceProvider serviceProvider)\n    {\n        ReceiveAsync<ProcessOrder>(async msg =>\n        {\n            // Create a scope for this operation\n            using var scope = serviceProvider.CreateScope();\n            var dbContext = scope.ServiceProvider.GetRequiredService<OrderDbContext>();\n            // Process order...\n        });\n    }\n}\n\n// Registration with DI\nbuilder.WithActors((system, registry, resolver) =>\n{\n    var actor = system.ActorOf(resolver.Props<OrderProcessorActor>(), \"order-processor\");\n    registry.Register<OrderProcessorActor>(actor);\n});\n```\n\n### Remote Deployment Considerations\n\n**You almost never need remote deployment.** Remote deployment means deploying an actor to run on a different node than the one creating it.\n\nIf you're not doing remote deployment (and you probably aren't):\n- `Props.Create(() => new Actor(...))` with closures is fine\n- The \"serialization issue\" warning doesn't apply\n\n**When you would use remote deployment:**\n- Distributing compute-intensive work to specific nodes\n- Running actors on nodes with specific hardware (GPU, etc.)\n\nFor most applications, use **cluster sharding** instead of remote deployment - it handles distribution automatically.\n\n---\n\n## 5. Work Distribution Patterns\n\n### Problem: Thundering Herd\n\nWhen you have many background jobs (RSS feeds, email sending, etc.), don't process them all at once:\n\n```csharp\n// BAD: Polls all feeds simultaneously on startup\npublic class BadRssCoordinator : ReceiveActor\n{\n    public BadRssCoordinator(IRssFeedRepository repo)\n    {\n        ReceiveAsync<StartPolling>(async _ =>\n        {\n            var feeds = await repo.GetAllFeedsAsync();\n            foreach (var feed in feeds) // 2000 feeds = 2000 simultaneous HTTP requests\n            {\n                Context.ActorOf(RssFeedPollerActor.Props(feed.Url));\n            }\n        });\n    }\n}\n```\n\n### Pattern 1: Database-Driven Work Queue\n\nUse the database as a work queue with `FOR UPDATE SKIP LOCKED`:\n\n```csharp\npublic class RssPollerWorker : ReceiveActor\n{\n    public RssPollerWorker(IRssFeedRepository repo)\n    {\n        ReceiveAsync<PollBatch>(async _ =>\n        {\n            // Each worker claims a batch - naturally distributes across nodes\n            var feeds = await repo.ClaimFeedsForPollingAsync(\n                batchSize: 10,\n                staleAfter: TimeSpan.FromMinutes(10));\n\n            foreach (var feed in feeds)\n            {\n                try\n                {\n                    await PollFeed(feed);\n                    await repo.MarkPolledAsync(feed.Id, success: true);\n                }\n                catch (Exception ex)\n                {\n                    await repo.MarkPolledAsync(feed.Id, success: false, error: ex.Message);\n                }\n            }\n\n            // Schedule next batch\n            Context.System.Scheduler.ScheduleTellOnce(\n                TimeSpan.FromSeconds(5),\n                Self,\n                PollBatch.Instance,\n                Self);\n        });\n    }\n}\n```\n\n```sql\n-- ClaimFeedsForPollingAsync implementation\nUPDATE rss_feeds\nSET status = 'processing',\n    processing_started_at = NOW()\nWHERE id IN (\n    SELECT id FROM rss_feeds\n    WHERE status = 'pending'\n      AND (next_poll_at IS NULL OR next_poll_at <= NOW())\n    ORDER BY next_poll_at NULLS FIRST\n    LIMIT @batchSize\n    FOR UPDATE SKIP LOCKED\n)\nRETURNING *;\n```\n\n**Benefits:**\n- Naturally distributes work across multiple server nodes\n- No coordination needed - database handles locking\n- Easy to monitor (query the table)\n- Survives server restarts\n\n### Pattern 2: Akka.Streams for Rate Limiting\n\nUse Akka.Streams to throttle processing within a single node:\n\n```csharp\npublic class ThrottledRssProcessor : ReceiveActor\n{\n    public ThrottledRssProcessor(IRssFeedRepository repo)\n    {\n        var materializer = Context.System.Materializer();\n\n        ReceiveAsync<StartProcessing>(async _ =>\n        {\n            await Source.From(await repo.GetPendingFeedsAsync())\n                .Throttle(10, TimeSpan.FromSeconds(1)) // Max 10 per second\n                .SelectAsync(4, async feed => // Max 4 concurrent\n                {\n                    await PollFeed(feed);\n                    return feed;\n                })\n                .RunWith(Sink.Ignore<RssFeed>(), materializer);\n        });\n    }\n}\n```\n\n### Pattern 3: Durable Queue (Email Outbox Pattern)\n\nFor work that must be reliably processed, use a database-backed outbox:\n\n```csharp\n// Enqueue work transactionally with business operation\npublic async Task CreatePostAsync(Post post)\n{\n    await using var transaction = await _db.BeginTransactionAsync();\n\n    await _postStore.CreateAsync(post);\n\n    // Enqueue notification emails in same transaction\n    foreach (var follower in await _followStore.GetFollowersAsync(post.AuthorId))\n    {\n        await _emailOutbox.EnqueueAsync(new EmailJob\n        {\n            To = follower.Email,\n            Template = \"new-post\",\n            Data = JsonSerializer.Serialize(new { PostId = post.Id })\n        });\n    }\n\n    await transaction.CommitAsync();\n}\n\n// Worker processes outbox\npublic class EmailOutboxWorker : ReceiveActor\n{\n    public EmailOutboxWorker(IEmailOutboxStore outbox, IEmailSender sender)\n    {\n        ReceiveAsync<ProcessBatch>(async _ =>\n        {\n            var batch = await outbox.ClaimBatchAsync(10);\n            foreach (var job in batch)\n            {\n                try\n                {\n                    await sender.SendAsync(job);\n                    await outbox.MarkSentAsync(job.Id);\n                }\n                catch (Exception ex)\n                {\n                    await outbox.MarkFailedAsync(job.Id, ex.Message);\n                }\n            }\n        });\n    }\n}\n```\n\n---\n\n## 6. Common Mistakes Summary\n\n| Mistake | Why It's Wrong | Fix |\n|---------|----------------|-----|\n| Using EventStream for cross-node pub/sub | EventStream is local only | Use DistributedPubSub |\n| Defining supervision to \"protect\" an actor | Supervision protects children | Understand the hierarchy |\n| Catching all exceptions | Hides bugs, corrupts state | Only catch expected errors |\n| Always using DependencyResolver | Adds unnecessary complexity | Use plain Props when possible |\n| Processing all background jobs at once | Thundering herd, resource exhaustion | Use database queue + rate limiting |\n| Throwing exceptions for expected failures | Triggers unnecessary restarts | Return result types, use messaging |\n\n---\n\n## 7. Quick Reference\n\n### Communication Pattern Decision Tree\n\n```\nNeed to communicate between actors?\n├── Same process only? → EventStream is fine\n├── Across cluster nodes?\n│   ├── Point-to-point? → Use ActorSelection or known IActorRef\n│   └── Pub/sub? → Use DistributedPubSub\n└── Fire-and-forget to external system? → Consider outbox pattern\n```\n\n### Error Handling Decision Tree\n\n```\nException occurred in actor?\n├── Expected failure (HTTP timeout, invalid input)?\n│   └── Try-catch, handle gracefully, continue\n├── State might be corrupt?\n│   └── Let supervision restart\n├── Unknown cause?\n│   └── Let supervision restart\n└── Programming error (null ref, bad logic)?\n    └── Let supervision restart, fix the bug\n```\n\n### Props Decision Tree\n\n```\nCreating actor Props?\n├── Actor needs IServiceProvider?\n│   └── Use resolver.Props<T>()\n├── Actor needs IRequiredActor<T>?\n│   └── Use resolver.Props<T>()\n├── Simple actor with constructor params?\n│   └── Use Props.Create(() => new Actor(...))\n└── Remote deployment needed?\n    └── Probably not - use cluster sharding instead\n```\n\n---\n\n## 8. Cluster/Local Mode Abstractions\n\nFor applications that need to run both in clustered production environments and local/test environments without cluster infrastructure, use abstraction patterns to toggle between implementations.\n\n### AkkaExecutionMode Enum\n\nDefine an execution mode that controls which implementations are used:\n\n```csharp\n/// <summary>\n/// Determines how Akka.NET infrastructure features are configured.\n/// </summary>\npublic enum AkkaExecutionMode\n{\n    /// <summary>\n    /// Local test mode - no cluster infrastructure.\n    /// Uses in-memory implementations for pub/sub and local parent actors\n    /// instead of cluster sharding.\n    /// </summary>\n    LocalTest,\n\n    /// <summary>\n    /// Full cluster mode with sharding, singletons, and distributed pub/sub.\n    /// </summary>\n    Clustered\n}\n```\n\n### GenericChildPerEntityParent - Local Sharding Alternative\n\nWhen testing locally, you can't use Cluster Sharding. This actor mimics sharding behavior by creating child actors per entity ID using the same `IMessageExtractor` interface:\n\n```csharp\n/// <summary>\n/// A local parent actor that mimics Cluster Sharding behavior.\n/// Creates and manages child actors per entity ID using the same IMessageExtractor\n/// that would be used with real sharding, enabling seamless switching between modes.\n/// </summary>\npublic sealed class GenericChildPerEntityParent : ReceiveActor\n{\n    private readonly IMessageExtractor _extractor;\n    private readonly Func<string, Props> _propsFactory;\n    private readonly Dictionary<string, IActorRef> _children = new();\n    private readonly ILoggingAdapter _log = Context.GetLogger();\n\n    public GenericChildPerEntityParent(\n        IMessageExtractor extractor,\n        Func<string, Props> propsFactory)\n    {\n        _extractor = extractor;\n        _propsFactory = propsFactory;\n\n        ReceiveAny(msg =>\n        {\n            var entityId = _extractor.EntityId(msg);\n            if (string.IsNullOrEmpty(entityId))\n            {\n                _log.Warning(\"Could not extract entity ID from message {0}\", msg.GetType().Name);\n                Unhandled(msg);\n                return;\n            }\n\n            var child = GetOrCreateChild(entityId);\n\n            // Unwrap the message if it's a ShardingEnvelope\n            var unwrapped = _extractor.EntityMessage(msg);\n            child.Forward(unwrapped);\n        });\n    }\n\n    private IActorRef GetOrCreateChild(string entityId)\n    {\n        if (_children.TryGetValue(entityId, out var existing))\n            return existing;\n\n        var props = _propsFactory(entityId);\n        var child = Context.ActorOf(props, entityId);\n        Context.Watch(child);\n        _children[entityId] = child;\n\n        _log.Debug(\"Created child actor for entity {0}\", entityId);\n        return child;\n    }\n\n    protected override void PreRestart(Exception reason, object message)\n    {\n        // Don't stop children on restart\n    }\n\n    public static Props CreateProps(\n        IMessageExtractor extractor,\n        Func<string, Props> propsFactory)\n    {\n        return Props.Create(() => new GenericChildPerEntityParent(extractor, propsFactory));\n    }\n}\n```\n\n### IPubSubMediator - Abstracting DistributedPubSub\n\nCreate an interface to abstract over pub/sub so tests can use a local implementation:\n\n```csharp\n/// <summary>\n/// Abstraction over pub/sub messaging that allows swapping between\n/// DistributedPubSub (clustered) and local implementations (testing).\n/// </summary>\npublic interface IPubSubMediator\n{\n    /// <summary>\n    /// Subscribe an actor to a topic.\n    /// </summary>\n    void Subscribe(string topic, IActorRef subscriber);\n\n    /// <summary>\n    /// Unsubscribe an actor from a topic.\n    /// </summary>\n    void Unsubscribe(string topic, IActorRef subscriber);\n\n    /// <summary>\n    /// Publish a message to all subscribers of a topic.\n    /// </summary>\n    void Publish(string topic, object message);\n\n    /// <summary>\n    /// Send a message to one subscriber of a topic (load balanced).\n    /// </summary>\n    void Send(string topic, object message);\n}\n```\n\n### LocalPubSubMediator - In-Memory Implementation\n\n```csharp\n/// <summary>\n/// In-memory pub/sub implementation for local testing without cluster.\n/// Uses the EventStream internally for simplicity.\n/// </summary>\npublic sealed class LocalPubSubMediator : IPubSubMediator\n{\n    private readonly ActorSystem _system;\n    private readonly ConcurrentDictionary<string, HashSet<IActorRef>> _subscriptions = new();\n    private readonly object _lock = new();\n\n    public LocalPubSubMediator(ActorSystem system)\n    {\n        _system = system;\n    }\n\n    public void Subscribe(string topic, IActorRef subscriber)\n    {\n        lock (_lock)\n        {\n            var subs = _subscriptions.GetOrAdd(topic, _ => new HashSet<IActorRef>());\n            subs.Add(subscriber);\n        }\n\n        // Send acknowledgement like real DistributedPubSub does\n        subscriber.Tell(new SubscribeAck(new Subscribe(topic, subscriber)));\n    }\n\n    public void Unsubscribe(string topic, IActorRef subscriber)\n    {\n        lock (_lock)\n        {\n            if (_subscriptions.TryGetValue(topic, out var subs))\n            {\n                subs.Remove(subscriber);\n            }\n        }\n\n        subscriber.Tell(new UnsubscribeAck(new Unsubscribe(topic, subscriber)));\n    }\n\n    public void Publish(string topic, object message)\n    {\n        HashSet<IActorRef> subscribers;\n        lock (_lock)\n        {\n            if (!_subscriptions.TryGetValue(topic, out var subs))\n                return;\n            subscribers = new HashSet<IActorRef>(subs);\n        }\n\n        foreach (var subscriber in subscribers)\n        {\n            subscriber.Tell(message);\n        }\n    }\n\n    public void Send(string topic, object message)\n    {\n        IActorRef? target = null;\n        lock (_lock)\n        {\n            if (_subscriptions.TryGetValue(topic, out var subs) && subs.Count > 0)\n            {\n                // Simple round-robin - pick first available\n                target = subs.FirstOrDefault();\n            }\n        }\n\n        target?.Tell(message);\n    }\n}\n```\n\n### ClusterPubSubMediator - Production Implementation\n\n```csharp\n/// <summary>\n/// Production implementation wrapping Akka.Cluster.Tools.PublishSubscribe.\n/// </summary>\npublic sealed class ClusterPubSubMediator : IPubSubMediator\n{\n    private readonly IActorRef _mediator;\n\n    public ClusterPubSubMediator(ActorSystem system)\n    {\n        _mediator = DistributedPubSub.Get(system).Mediator;\n    }\n\n    public void Subscribe(string topic, IActorRef subscriber)\n    {\n        _mediator.Tell(new Subscribe(topic, subscriber));\n    }\n\n    public void Unsubscribe(string topic, IActorRef subscriber)\n    {\n        _mediator.Tell(new Unsubscribe(topic, subscriber));\n    }\n\n    public void Publish(string topic, object message)\n    {\n        _mediator.Tell(new Publish(topic, message));\n    }\n\n    public void Send(string topic, object message)\n    {\n        _mediator.Tell(new Send(topic, message, localAffinity: true));\n    }\n}\n```\n\n### Wiring It All Together\n\nConfigure your ActorSystem based on execution mode:\n\n```csharp\npublic static class AkkaHostingExtensions\n{\n    public static AkkaConfigurationBuilder ConfigureActorSystem(\n        this AkkaConfigurationBuilder builder,\n        AkkaExecutionMode mode,\n        IServiceCollection services)\n    {\n        if (mode == AkkaExecutionMode.Clustered)\n        {\n            builder\n                .WithClustering()\n                .WithShardRegion<MyEntity>(\n                    \"my-entity\",\n                    (system, registry, resolver) => entityId =>\n                        resolver.Props<MyEntityActor>(entityId),\n                    new MyEntityMessageExtractor(),\n                    new ShardOptions())\n                .WithDistributedPubSub();\n\n            // Register cluster pub/sub mediator\n            services.AddSingleton<IPubSubMediator>(sp =>\n            {\n                var system = sp.GetRequiredService<ActorSystem>();\n                return new ClusterPubSubMediator(system);\n            });\n        }\n        else // LocalTest mode\n        {\n            // Register local pub/sub mediator\n            services.AddSingleton<IPubSubMediator>(sp =>\n            {\n                var system = sp.GetRequiredService<ActorSystem>();\n                return new LocalPubSubMediator(system);\n            });\n\n            // Use GenericChildPerEntityParent instead of sharding\n            builder.WithActors((system, registry, resolver) =>\n            {\n                var parent = system.ActorOf(\n                    GenericChildPerEntityParent.CreateProps(\n                        new MyEntityMessageExtractor(),\n                        entityId => resolver.Props<MyEntityActor>(entityId)),\n                    \"my-entity\");\n\n                registry.Register<MyEntityParent>(parent);\n            });\n        }\n\n        return builder;\n    }\n}\n```\n\n### Usage in Application Code\n\nApplication code uses the abstractions and doesn't need to know which mode is active:\n\n```csharp\npublic class MyService\n{\n    private readonly IPubSubMediator _pubSub;\n    private readonly IRequiredActor<MyEntityParent> _entityParent;\n\n    public MyService(\n        IPubSubMediator pubSub,\n        IRequiredActor<MyEntityParent> entityParent)\n    {\n        _pubSub = pubSub;\n        _entityParent = entityParent;\n    }\n\n    public async Task ProcessAsync(string entityId, MyCommand command)\n    {\n        // Works identically in both modes\n        var parent = await _entityParent.GetAsync();\n        parent.Tell(new ShardingEnvelope(entityId, command));\n\n        // Publish event - works with both local and distributed pub/sub\n        _pubSub.Publish($\"entity:{entityId}\", new EntityUpdated(entityId));\n    }\n}\n```\n\n### Benefits of This Pattern\n\n| Benefit | Description |\n|---------|-------------|\n| **Fast unit tests** | No cluster startup overhead, tests run in milliseconds |\n| **Identical message flow** | Same `IMessageExtractor`, same message types |\n| **Easy debugging** | Local mode is simpler to step through |\n| **Integration test flexibility** | Choose mode per test scenario |\n| **Production confidence** | Abstractions are thin wrappers over real implementations |\n\n### When to Use Each Mode\n\n| Scenario | Recommended Mode |\n|----------|------------------|\n| Unit tests | LocalTest |\n| Integration tests (single node) | LocalTest |\n| Integration tests (multi-node) | Clustered |\n| Local development | LocalTest or Clustered (your choice) |\n| Production | Clustered |\n",
        "skills/akka/hosting-actor-patterns/SKILL.md": "---\nname: akka-hosting-actor-patterns\ndescription: Patterns for building entity actors with Akka.Hosting - GenericChildPerEntityParent, message extractors, cluster sharding abstraction, akka-reminders, and ITimeProvider. Supports both local testing and clustered production modes.\n---\n\n# Akka.Hosting Actor Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Building entity actors that represent domain objects (users, orders, invoices, etc.)\n- Need actors that work in both unit tests (no clustering) and production (cluster sharding)\n- Setting up scheduled tasks with akka-reminders\n- Registering actors with Akka.Hosting extension methods\n- Creating reusable actor configuration patterns\n\n## Core Principles\n\n1. **Execution Mode Abstraction** - Same actor code runs locally (tests) or clustered (production)\n2. **GenericChildPerEntityParent for Local** - Mimics sharding semantics without cluster overhead\n3. **Message Extractors for Routing** - Reuse Akka.Cluster.Sharding's IMessageExtractor interface\n4. **Akka.Hosting Extension Methods** - Fluent configuration that composes well\n5. **ITimeProvider for Testability** - Use ActorSystem.Scheduler instead of DateTime.Now\n\n## Execution Modes\n\nDefine an enum to control actor behavior:\n\n```csharp\n/// <summary>\n/// Determines how Akka.NET should be configured\n/// </summary>\npublic enum AkkaExecutionMode\n{\n    /// <summary>\n    /// Pure local actor system - no remoting, no clustering.\n    /// Use GenericChildPerEntityParent instead of ShardRegion.\n    /// Ideal for unit tests and simple scenarios.\n    /// </summary>\n    LocalTest,\n\n    /// <summary>\n    /// Full clustering with ShardRegion.\n    /// Use for integration testing and production.\n    /// </summary>\n    Clustered\n}\n```\n\n## GenericChildPerEntityParent\n\nA lightweight parent actor that routes messages to child entities, mimicking cluster sharding semantics without requiring a cluster:\n\n```csharp\nusing Akka.Actor;\nusing Akka.Cluster.Sharding;\n\n/// <summary>\n/// A generic \"child per entity\" parent actor.\n/// </summary>\n/// <remarks>\n/// Reuses Akka.Cluster.Sharding's IMessageExtractor for consistent routing.\n/// Ideal for unit tests where clustering overhead is unnecessary.\n/// </remarks>\npublic sealed class GenericChildPerEntityParent : ReceiveActor\n{\n    public static Props CreateProps(\n        IMessageExtractor extractor,\n        Func<string, Props> propsFactory)\n    {\n        return Props.Create(() =>\n            new GenericChildPerEntityParent(extractor, propsFactory));\n    }\n\n    private readonly IMessageExtractor _extractor;\n    private readonly Func<string, Props> _propsFactory;\n\n    public GenericChildPerEntityParent(\n        IMessageExtractor extractor,\n        Func<string, Props> propsFactory)\n    {\n        _extractor = extractor;\n        _propsFactory = propsFactory;\n\n        ReceiveAny(message =>\n        {\n            var entityId = _extractor.EntityId(message);\n            if (entityId is null) return;\n\n            // Get existing child or create new one\n            Context.Child(entityId)\n                .GetOrElse(() => Context.ActorOf(_propsFactory(entityId), entityId))\n                .Forward(_extractor.EntityMessage(message));\n        });\n    }\n}\n```\n\n## Message Extractors\n\nCreate extractors that implement `IMessageExtractor` from Akka.Cluster.Sharding:\n\n```csharp\nusing Akka.Cluster.Sharding;\n\n/// <summary>\n/// Routes messages to entity actors based on a strongly-typed ID.\n/// </summary>\npublic sealed class OrderMessageExtractor : HashCodeMessageExtractor\n{\n    public const int DefaultShardCount = 40;\n\n    public OrderMessageExtractor(int maxNumberOfShards = DefaultShardCount)\n        : base(maxNumberOfShards)\n    {\n    }\n\n    public override string? EntityId(object message)\n    {\n        return message switch\n        {\n            IWithOrderId msg => msg.OrderId.Value.ToString(),\n            _ => null\n        };\n    }\n}\n\n// Define an interface for messages that target a specific entity\npublic interface IWithOrderId\n{\n    OrderId OrderId { get; }\n}\n\n// Use strongly-typed IDs\npublic readonly record struct OrderId(Guid Value)\n{\n    public static OrderId New() => new(Guid.NewGuid());\n    public override string ToString() => Value.ToString();\n}\n```\n\n## Akka.Hosting Extension Methods\n\nCreate extension methods that abstract the execution mode:\n\n```csharp\nusing Akka.Cluster.Hosting;\nusing Akka.Cluster.Sharding;\nusing Akka.Hosting;\n\npublic static class OrderActorHostingExtensions\n{\n    /// <summary>\n    /// Adds OrderActor with support for both local and clustered modes.\n    /// </summary>\n    public static AkkaConfigurationBuilder WithOrderActor(\n        this AkkaConfigurationBuilder builder,\n        AkkaExecutionMode executionMode = AkkaExecutionMode.Clustered,\n        string? clusterRole = null)\n    {\n        if (executionMode == AkkaExecutionMode.LocalTest)\n        {\n            // Non-clustered mode: Use GenericChildPerEntityParent\n            builder.WithActors((system, registry, resolver) =>\n            {\n                var parent = system.ActorOf(\n                    GenericChildPerEntityParent.CreateProps(\n                        new OrderMessageExtractor(),\n                        entityId => resolver.Props<OrderActor>(entityId)),\n                    \"orders\");\n\n                registry.Register<OrderActor>(parent);\n            });\n        }\n        else\n        {\n            // Clustered mode: Use ShardRegion\n            builder.WithShardRegion<OrderActor>(\n                \"orders\",\n                (system, registry, resolver) =>\n                    entityId => resolver.Props<OrderActor>(entityId),\n                new OrderMessageExtractor(),\n                new ShardOptions\n                {\n                    StateStoreMode = StateStoreMode.DData,\n                    Role = clusterRole\n                });\n        }\n\n        return builder;\n    }\n}\n```\n\n## Composing Multiple Actors\n\nCreate a convenience method that registers all domain actors:\n\n```csharp\npublic static class DomainActorHostingExtensions\n{\n    /// <summary>\n    /// Adds all order domain actors with sharding support.\n    /// </summary>\n    public static AkkaConfigurationBuilder WithOrderDomainActors(\n        this AkkaConfigurationBuilder builder,\n        AkkaExecutionMode executionMode = AkkaExecutionMode.Clustered,\n        string? clusterRole = null)\n    {\n        return builder\n            .WithOrderActor(executionMode, clusterRole)\n            .WithPaymentActor(executionMode, clusterRole)\n            .WithShipmentActor(executionMode, clusterRole)\n            .WithNotificationActor(); // Singleton, no sharding needed\n    }\n}\n```\n\n## Using ITimeProvider for Scheduling\n\nRegister the ActorSystem's Scheduler as an `ITimeProvider` for testable time-based logic:\n\n```csharp\npublic static class SharedAkkaHostingExtensions\n{\n    public static IServiceCollection AddAkkaWithTimeProvider(\n        this IServiceCollection services,\n        Action<AkkaConfigurationBuilder, IServiceProvider> configure)\n    {\n        // Register ITimeProvider using the ActorSystem's Scheduler\n        services.AddSingleton<ITimeProvider>(sp =>\n            sp.GetRequiredService<ActorSystem>().Scheduler);\n\n        return services.ConfigureAkka((builder, sp) =>\n        {\n            configure(builder, sp);\n        });\n    }\n}\n\n// In your actor, inject ITimeProvider\npublic class SubscriptionActor : ReceiveActor\n{\n    private readonly ITimeProvider _timeProvider;\n\n    public SubscriptionActor(ITimeProvider timeProvider)\n    {\n        _timeProvider = timeProvider;\n\n        // Use _timeProvider.GetUtcNow() instead of DateTime.UtcNow\n        // This allows tests to control time\n    }\n}\n```\n\n## Akka.Reminders Integration\n\nFor durable scheduled tasks that survive restarts, use akka-reminders:\n\n```csharp\nusing Akka.Reminders;\nusing Akka.Reminders.Sql;\nusing Akka.Reminders.Sql.Configuration;\nusing Akka.Reminders.Storage;\n\npublic static class ReminderHostingExtensions\n{\n    /// <summary>\n    /// Configures akka-reminders with PostgreSQL storage.\n    /// </summary>\n    public static AkkaConfigurationBuilder WithPostgresReminders(\n        this AkkaConfigurationBuilder builder,\n        string connectionString,\n        string schemaName = \"reminders\",\n        string tableName = \"scheduled_reminders\",\n        bool autoInitialize = true)\n    {\n        return builder.WithLocalReminders(reminders => reminders\n            .WithResolver(sys => new GenericChildPerEntityResolver(sys))\n            .WithStorage(system =>\n            {\n                var settings = SqlReminderStorageSettings.CreatePostgreSql(\n                    connectionString,\n                    schemaName,\n                    tableName,\n                    autoInitialize);\n                return new SqlReminderStorage(settings, system);\n            })\n            .WithSettings(new ReminderSettings\n            {\n                MaxSlippage = TimeSpan.FromSeconds(30),\n                MaxDeliveryAttempts = 3,\n                RetryBackoffBase = TimeSpan.FromSeconds(10)\n            }));\n    }\n\n    /// <summary>\n    /// Configures akka-reminders with in-memory storage for testing.\n    /// </summary>\n    public static AkkaConfigurationBuilder WithInMemoryReminders(\n        this AkkaConfigurationBuilder builder)\n    {\n        return builder.WithLocalReminders(reminders => reminders\n            .WithResolver(sys => new GenericChildPerEntityResolver(sys))\n            .WithStorage(system => new InMemoryReminderStorage())\n            .WithSettings(new ReminderSettings\n            {\n                MaxSlippage = TimeSpan.FromSeconds(1),\n                MaxDeliveryAttempts = 3,\n                RetryBackoffBase = TimeSpan.FromMilliseconds(100)\n            }));\n    }\n}\n```\n\n### Custom Reminder Resolver for Child-Per-Entity\n\nRoute reminder callbacks to GenericChildPerEntityParent actors:\n\n```csharp\nusing Akka.Actor;\nusing Akka.Hosting;\nusing Akka.Reminders;\n\n/// <summary>\n/// Resolves reminder targets to GenericChildPerEntityParent actors.\n/// </summary>\npublic sealed class GenericChildPerEntityResolver : IReminderActorResolver\n{\n    private readonly ActorSystem _system;\n\n    public GenericChildPerEntityResolver(ActorSystem system)\n    {\n        _system = system;\n    }\n\n    public IActorRef ResolveActorRef(ReminderEntry entry)\n    {\n        var registry = ActorRegistry.For(_system);\n\n        return entry.Key switch\n        {\n            var k when k.StartsWith(\"order-\") =>\n                registry.Get<OrderActor>(),\n            var k when k.StartsWith(\"subscription-\") =>\n                registry.Get<SubscriptionActor>(),\n            _ => throw new InvalidOperationException(\n                $\"Unknown reminder key format: {entry.Key}\")\n        };\n    }\n}\n```\n\n## Singleton Actors (Not Sharded)\n\nFor actors that should only have one instance:\n\n```csharp\npublic static AkkaConfigurationBuilder WithEmailSenderActor(\n    this AkkaConfigurationBuilder builder)\n{\n    return builder.WithActors((system, registry, resolver) =>\n    {\n        var actor = system.ActorOf(\n            resolver.Props<EmailSenderActor>(),\n            \"email-sender\");\n        registry.Register<EmailSenderActor>(actor);\n    });\n}\n```\n\n## Marker Types for Registry\n\nWhen you need to reference actors that are registered as parents:\n\n```csharp\n/// <summary>\n/// Marker type for ActorRegistry to retrieve the order manager\n/// (GenericChildPerEntityParent for OrderActors).\n/// </summary>\npublic sealed class OrderManagerActor;\n\n// Usage in extension method\nregistry.Register<OrderManagerActor>(parent);\n\n// Usage in controller/service\npublic class OrderService\n{\n    private readonly IActorRef _orderManager;\n\n    public OrderService(IRequiredActor<OrderManagerActor> orderManager)\n    {\n        _orderManager = orderManager.ActorRef;\n    }\n\n    public async Task<OrderResponse> CreateOrder(CreateOrderCommand cmd)\n    {\n        return await _orderManager.Ask<OrderResponse>(cmd);\n    }\n}\n```\n\n## DI Scope Management in Actors\n\n**Actors don't have automatic DI scopes.** Unlike ASP.NET controllers (where each HTTP request creates a scope), actors are long-lived. If you need scoped services (like `DbContext`), inject `IServiceProvider` and create scopes manually.\n\n### Pattern: Scope Per Message\n\n```csharp\npublic sealed class OrderProcessingActor : ReceiveActor\n{\n    private readonly IServiceProvider _serviceProvider;\n    private readonly IActorRef _notificationActor;\n\n    public OrderProcessingActor(\n        IServiceProvider serviceProvider,\n        IRequiredActor<NotificationActor> notificationActor)\n    {\n        _serviceProvider = serviceProvider;\n        _notificationActor = notificationActor.ActorRef;\n\n        ReceiveAsync<ProcessOrder>(HandleProcessOrder);\n    }\n\n    private async Task HandleProcessOrder(ProcessOrder msg)\n    {\n        // Create scope for this message - disposed after processing\n        using var scope = _serviceProvider.CreateScope();\n\n        // Resolve scoped services within the scope\n        var orderRepository = scope.ServiceProvider.GetRequiredService<IOrderRepository>();\n        var paymentService = scope.ServiceProvider.GetRequiredService<IPaymentService>();\n        var emailComposer = scope.ServiceProvider.GetRequiredService<IOrderEmailComposer>();\n\n        // Do work with scoped services\n        var order = await orderRepository.GetByIdAsync(msg.OrderId);\n        var payment = await paymentService.ProcessAsync(order);\n\n        // DbContext changes committed when scope disposes\n    }\n}\n```\n\n### Why This Pattern\n\n| Benefit | Explanation |\n|---------|-------------|\n| **Fresh DbContext per message** | No stale entity tracking between messages |\n| **Proper disposal** | Database connections released after each message |\n| **Isolation** | One message's errors don't corrupt another's state |\n| **Testable** | Can inject mock IServiceProvider in tests |\n\n### Singleton Services - Direct Injection\n\nFor stateless, thread-safe services, inject directly (no scope needed):\n\n```csharp\npublic sealed class NotificationActor : ReceiveActor\n{\n    private readonly IEmailLinkGenerator _linkGenerator;  // Singleton - OK!\n    private readonly IMjmlTemplateRenderer _renderer;     // Singleton - OK!\n\n    public NotificationActor(\n        IEmailLinkGenerator linkGenerator,\n        IMjmlTemplateRenderer renderer)\n    {\n        _linkGenerator = linkGenerator;\n        _renderer = renderer;\n\n        Receive<SendWelcomeEmail>(Handle);\n    }\n}\n```\n\n### Common Mistake: Injecting Scoped Services Directly\n\n```csharp\n// BAD: Scoped service injected into long-lived actor\npublic sealed class BadActor : ReceiveActor\n{\n    private readonly IOrderRepository _repo;  // Scoped! DbContext lives forever!\n\n    public BadActor(IOrderRepository repo)  // Captured at actor creation\n    {\n        _repo = repo;  // This DbContext will become stale\n    }\n}\n\n// GOOD: Inject IServiceProvider, create scope per message\npublic sealed class GoodActor : ReceiveActor\n{\n    private readonly IServiceProvider _sp;\n\n    public GoodActor(IServiceProvider sp)\n    {\n        _sp = sp;\n        ReceiveAsync<ProcessOrder>(async msg =>\n        {\n            using var scope = _sp.CreateScope();\n            var repo = scope.ServiceProvider.GetRequiredService<IOrderRepository>();\n            // Fresh DbContext for this message\n        });\n    }\n}\n```\n\nFor more on DI lifetimes and scope management, see `microsoft-extensions/dependency-injection` skill.\n\n---\n\n## Best Practices\n\n1. **Always support both execution modes** - Makes testing easy without code changes\n2. **Use strongly-typed IDs** - `OrderId` instead of `string` or `Guid`\n3. **Interface-based message routing** - `IWithOrderId` for type-safe extraction\n4. **Register parent, not children** - For child-per-entity, register the parent in ActorRegistry\n5. **Marker types for clarity** - Use empty marker classes for registry lookups\n6. **Composition over inheritance** - Chain extension methods, don't create deep hierarchies\n7. **ITimeProvider for scheduling** - Never use `DateTime.Now` directly in actors\n8. **akka-reminders for durability** - Use for scheduled tasks that must survive restarts\n",
        "skills/akka/management/SKILL.md": "---\nname: akka-net-management\ndescription: Akka.Management for cluster bootstrapping, service discovery (Kubernetes, Azure, Config), health checks, and dynamic cluster formation without static seed nodes.\n---\n\n# Akka.NET Management and Service Discovery\n\n## When to Use This Skill\n\nUse this skill when:\n- Deploying Akka.NET clusters to Kubernetes or cloud environments\n- Replacing static seed nodes with dynamic service discovery\n- Configuring cluster bootstrap for auto-formation\n- Setting up health endpoints for load balancers\n- Integrating with Azure Table Storage, Kubernetes API, or config-based discovery\n\n## Overview\n\n**Akka.Management** provides HTTP endpoints for cluster management and integrates with **Akka.Cluster.Bootstrap** to enable dynamic cluster formation using service discovery instead of static seed nodes.\n\n### Why Use Akka.Management?\n\n| Approach | Pros | Cons |\n|----------|------|------|\n| Static Seed Nodes | Simple, no dependencies | Doesn't scale, requires known IPs |\n| Akka.Management | Dynamic discovery, scales to N nodes | More configuration, external dependencies |\n\n**Use static seed nodes** for: Development, single-node deployments, fixed infrastructure.\n\n**Use Akka.Management** for: Kubernetes, auto-scaling groups, dynamic environments, production clusters.\n\n---\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Cluster Bootstrap                         │\n│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │\n│  │  Node 1     │    │  Node 2     │    │  Node 3     │     │\n│  │             │    │             │    │             │     │\n│  │ Management  │◄──►│ Management  │◄──►│ Management  │     │\n│  │ HTTP :8558  │    │ HTTP :8558  │    │ HTTP :8558  │     │\n│  └──────┬──────┘    └──────┬──────┘    └──────┬──────┘     │\n│         │                  │                  │             │\n│         └──────────────────┼──────────────────┘             │\n│                            │                                │\n│                    ┌───────▼───────┐                        │\n│                    │   Discovery   │                        │\n│                    │   Provider    │                        │\n│                    └───────────────┘                        │\n│                            │                                │\n└────────────────────────────┼────────────────────────────────┘\n                             │\n              ┌──────────────┼──────────────┐\n              │              │              │\n        ┌─────▼─────┐ ┌──────▼─────┐ ┌─────▼──────┐\n        │ Kubernetes│ │   Azure    │ │   Config   │\n        │    API    │ │   Tables   │ │   (HOCON)  │\n        └───────────┘ └────────────┘ └────────────┘\n```\n\n---\n\n## Required NuGet Packages\n\n```xml\n<ItemGroup>\n  <!-- Core management -->\n  <PackageReference Include=\"Akka.Management\" />\n  <PackageReference Include=\"Akka.Management.Cluster.Bootstrap\" />\n\n  <!-- Choose ONE discovery provider -->\n  <PackageReference Include=\"Akka.Discovery.KubernetesApi\" />    <!-- For Kubernetes -->\n  <PackageReference Include=\"Akka.Discovery.Azure\" />            <!-- For Azure -->\n  <PackageReference Include=\"Akka.Discovery.Config.Hosting\" />   <!-- For static config -->\n</ItemGroup>\n```\n\n---\n\n## Configuration Model\n\nCreate strongly-typed settings for all management options. See the `microsoft-extensions-configuration` skill for validation patterns.\n\n### AkkaManagementOptions\n\n```csharp\nusing System.Net;\n\npublic class AkkaManagementOptions\n{\n    /// <summary>\n    /// The hostname for the management HTTP endpoint.\n    /// Used by other nodes to contact this node's management endpoint.\n    /// </summary>\n    public string HostName { get; set; } = Dns.GetHostName();\n\n    /// <summary>\n    /// The port for the management HTTP endpoint.\n    /// Standard port is 8558.\n    /// </summary>\n    public int Port { get; set; } = 8558;\n}\n```\n\n### ClusterBootstrapOptions\n\n```csharp\npublic class ClusterBootstrapOptions\n{\n    /// <summary>\n    /// Enable/disable Akka.Management cluster bootstrap.\n    /// When disabled, use traditional seed nodes.\n    /// </summary>\n    public bool Enabled { get; set; } = false;\n\n    /// <summary>\n    /// Service name used for discovery.\n    /// All nodes in the same cluster must use the same service name.\n    /// </summary>\n    public string ServiceName { get; set; } = \"my-service\";\n\n    /// <summary>\n    /// Name of the port used for management HTTP endpoint.\n    /// Used by Kubernetes discovery to find the correct port.\n    /// </summary>\n    public string PortName { get; set; } = \"management\";\n\n    /// <summary>\n    /// Minimum number of contact points required to form a cluster.\n    /// Should match your minimum replica count.\n    /// </summary>\n    /// <remarks>\n    /// Set to 1 for development, 3+ for production.\n    /// </remarks>\n    public int RequiredContactPointsNr { get; set; } = 3;\n\n    /// <summary>\n    /// Which discovery mechanism to use.\n    /// </summary>\n    public DiscoveryMethod DiscoveryMethod { get; set; } = DiscoveryMethod.Config;\n\n    /// <summary>\n    /// How often to probe discovered contact points.\n    /// </summary>\n    public TimeSpan ContactPointProbingInterval { get; set; } = TimeSpan.FromSeconds(1);\n\n    /// <summary>\n    /// How often to query the discovery provider.\n    /// </summary>\n    public TimeSpan BootstrapperDiscoveryPingInterval { get; set; } = TimeSpan.FromSeconds(1);\n\n    /// <summary>\n    /// Time to wait for stable contact points before forming cluster.\n    /// Increase for slower environments.\n    /// </summary>\n    public TimeSpan StableMargin { get; set; } = TimeSpan.FromSeconds(5);\n\n    /// <summary>\n    /// Whether to contact all discovered nodes or just the required number.\n    /// Set to true for better cluster formation reliability.\n    /// </summary>\n    public bool ContactWithAllContactPoints { get; set; } = true;\n\n    /// <summary>\n    /// Filter contact points by management port.\n    /// Set to true for Kubernetes (fixed ports), false for Aspire (dynamic ports).\n    /// </summary>\n    public bool FilterOnFallbackPort { get; set; } = true;\n\n    // Discovery-specific options\n    public string[]? ConfigServiceEndpoints { get; set; }\n    public AzureDiscoveryOptions? AzureDiscoveryOptions { get; set; }\n    public KubernetesDiscoveryOptions? KubernetesDiscoveryOptions { get; set; }\n}\n\npublic enum DiscoveryMethod\n{\n    /// <summary>\n    /// Static configuration - endpoints defined in HOCON/appsettings.\n    /// Good for development and fixed infrastructure.\n    /// </summary>\n    Config,\n\n    /// <summary>\n    /// Kubernetes API discovery - queries K8s API for pod endpoints.\n    /// Best for Kubernetes deployments.\n    /// </summary>\n    Kubernetes,\n\n    /// <summary>\n    /// Azure Table Storage - nodes register themselves in a shared table.\n    /// Good for Azure deployments and Aspire local development.\n    /// </summary>\n    AzureTableStorage\n}\n```\n\n### Discovery-Specific Options\n\n```csharp\npublic class AzureDiscoveryOptions\n{\n    public string? ConnectionString { get; set; }\n    public string TableName { get; set; } = \"AkkaDiscovery\";\n}\n\npublic class KubernetesDiscoveryOptions\n{\n    /// <summary>\n    /// Kubernetes namespace to search for pods.\n    /// If null, uses the namespace of the current pod.\n    /// </summary>\n    public string? PodNamespace { get; set; }\n\n    /// <summary>\n    /// Label selector to filter pods (e.g., \"app=my-service\").\n    /// </summary>\n    public string? PodLabelSelector { get; set; }\n\n    /// <summary>\n    /// Name of the port in the pod spec for management endpoint.\n    /// </summary>\n    public string PodPortName { get; set; } = \"management\";\n}\n```\n\n---\n\n## Akka.Hosting Configuration\n\n### Basic Setup with Mode Selection\n\n```csharp\npublic static class AkkaConfiguration\n{\n    public static IServiceCollection ConfigureAkka(\n        this IServiceCollection services,\n        Action<AkkaConfigurationBuilder, IServiceProvider>? additionalConfig = null)\n    {\n        // Bind and validate settings (see microsoft-extensions-configuration skill)\n        services.AddOptions<AkkaSettings>()\n            .BindConfiguration(\"AkkaSettings\")\n            .ValidateDataAnnotations()\n            .ValidateOnStart();\n\n        services.AddSingleton<IValidateOptions<AkkaSettings>, AkkaSettingsValidator>();\n\n        return services.AddAkka(\"MySystem\", (builder, sp) =>\n        {\n            var settings = sp.GetRequiredService<IOptions<AkkaSettings>>().Value;\n            var configuration = sp.GetRequiredService<IConfiguration>();\n\n            ConfigureNetwork(builder, settings, configuration);\n            ConfigureHealthChecks(builder);\n\n            additionalConfig?.Invoke(builder, sp);\n        });\n    }\n\n    private static void ConfigureNetwork(\n        AkkaConfigurationBuilder builder,\n        AkkaSettings settings,\n        IConfiguration configuration)\n    {\n        // LocalTest mode = no networking\n        if (settings.ExecutionMode == AkkaExecutionMode.LocalTest)\n            return;\n\n        // Configure remoting\n        builder.WithRemoting(settings.RemoteOptions);\n\n        if (settings.ClusterBootstrapOptions.Enabled)\n        {\n            // Dynamic cluster formation with Akka.Management\n            ConfigureAkkaManagement(builder, settings, configuration);\n        }\n        else\n        {\n            // Traditional seed-node clustering\n            builder.WithClustering(settings.ClusterOptions);\n        }\n    }\n\n    private static void ConfigureHealthChecks(AkkaConfigurationBuilder builder)\n    {\n        builder\n            .WithActorSystemLivenessCheck()\n            .WithAkkaClusterReadinessCheck();\n    }\n}\n```\n\n### Akka.Management Configuration\n\n```csharp\nprivate static void ConfigureAkkaManagement(\n    AkkaConfigurationBuilder builder,\n    AkkaSettings settings,\n    IConfiguration configuration)\n{\n    var mgmtOptions = settings.AkkaManagementOptions;\n    var bootstrapOptions = settings.ClusterBootstrapOptions;\n\n    // IMPORTANT: Clear seed nodes when using Akka.Management\n    settings.ClusterOptions.SeedNodes = [];\n\n    builder\n        // Configure clustering (without seed nodes)\n        .WithClustering(settings.ClusterOptions)\n\n        // Configure Akka.Management HTTP endpoint\n        .WithAkkaManagement(setup =>\n        {\n            setup.Http.HostName = mgmtOptions.HostName;\n            setup.Http.Port = mgmtOptions.Port;\n            setup.Http.BindHostName = \"0.0.0.0\";  // Listen on all interfaces\n            setup.Http.BindPort = mgmtOptions.Port;\n        })\n\n        // Configure Cluster Bootstrap\n        .WithClusterBootstrap(options =>\n        {\n            options.ContactPointDiscovery.ServiceName = bootstrapOptions.ServiceName;\n            options.ContactPointDiscovery.PortName = bootstrapOptions.PortName;\n            options.ContactPointDiscovery.RequiredContactPointsNr = bootstrapOptions.RequiredContactPointsNr;\n            options.ContactPointDiscovery.Interval = bootstrapOptions.ContactPointProbingInterval;\n            options.ContactPointDiscovery.StableMargin = bootstrapOptions.StableMargin;\n            options.ContactPointDiscovery.ContactWithAllContactPoints = bootstrapOptions.ContactWithAllContactPoints;\n\n            options.ContactPoint.FilterOnFallbackPort = bootstrapOptions.FilterOnFallbackPort;\n            options.ContactPoint.ProbeInterval = bootstrapOptions.BootstrapperDiscoveryPingInterval;\n        });\n\n    // Configure the discovery provider\n    ConfigureDiscovery(builder, settings, configuration);\n}\n```\n\n---\n\n## Discovery Providers\n\n### 1. Config Discovery (Development/Fixed Infrastructure)\n\nUse when endpoints are known ahead of time:\n\n```csharp\nprivate static void ConfigureConfigDiscovery(\n    AkkaConfigurationBuilder builder,\n    ClusterBootstrapOptions options)\n{\n    if (options.ConfigServiceEndpoints == null || options.ConfigServiceEndpoints.Length == 0)\n        throw new InvalidOperationException(\"ConfigServiceEndpoints required for Config discovery\");\n\n    var endpoints = string.Join(\", \", options.ConfigServiceEndpoints.Select(ep => $\"\\\"{ep}\\\"\"));\n\n    var hocon = $@\"\n        akka.discovery {{\n            method = config\n            config {{\n                services {{\n                    {options.ServiceName} {{\n                        endpoints = [{endpoints}]\n                    }}\n                }}\n            }}\n        }}\";\n\n    builder.AddHocon(hocon, HoconAddMode.Prepend);\n}\n```\n\n**appsettings.json:**\n```json\n{\n  \"AkkaSettings\": {\n    \"ClusterBootstrapOptions\": {\n      \"Enabled\": true,\n      \"DiscoveryMethod\": \"Config\",\n      \"ServiceName\": \"my-service\",\n      \"ConfigServiceEndpoints\": [\n        \"node1.local:8558\",\n        \"node2.local:8558\",\n        \"node3.local:8558\"\n      ]\n    }\n  }\n}\n```\n\n### 2. Kubernetes Discovery (Production K8s)\n\nQueries the Kubernetes API for pod endpoints:\n\n```csharp\nprivate static void ConfigureKubernetesDiscovery(\n    AkkaConfigurationBuilder builder,\n    KubernetesDiscoveryOptions? options)\n{\n    if (options != null)\n    {\n        builder.WithKubernetesDiscovery(k8sOptions =>\n        {\n            if (!string.IsNullOrEmpty(options.PodNamespace))\n                k8sOptions.PodNamespace = options.PodNamespace;\n\n            if (!string.IsNullOrEmpty(options.PodLabelSelector))\n                k8sOptions.PodLabelSelector = options.PodLabelSelector;\n        });\n    }\n    else\n    {\n        // Use defaults - auto-detect namespace and use all pods\n        builder.WithKubernetesDiscovery();\n    }\n}\n```\n\n**Kubernetes Deployment:**\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-akka-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-akka-service\n  template:\n    metadata:\n      labels:\n        app: my-akka-service\n    spec:\n      containers:\n      - name: app\n        image: my-app:latest\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: remote\n          containerPort: 8081\n        - name: management     # Must match PortName in config\n          containerPort: 8558\n        env:\n        - name: AkkaSettings__ClusterBootstrapOptions__Enabled\n          value: \"true\"\n        - name: AkkaSettings__ClusterBootstrapOptions__DiscoveryMethod\n          value: \"Kubernetes\"\n        - name: AkkaSettings__ClusterBootstrapOptions__ServiceName\n          value: \"my-akka-service\"\n        - name: AkkaSettings__RemoteOptions__PublicHostName\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-akka-service\nspec:\n  clusterIP: None  # Headless service for direct pod discovery\n  selector:\n    app: my-akka-service\n  ports:\n  - name: management\n    port: 8558\n```\n\n**Required RBAC:**\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: akka-discovery\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: akka-discovery\nsubjects:\n- kind: ServiceAccount\n  name: default\nroleRef:\n  kind: Role\n  name: akka-discovery\n  apiGroup: rbac.authorization.k8s.io\n```\n\n### 3. Azure Table Storage Discovery (Azure/Aspire)\n\nNodes register themselves in a shared Azure Table:\n\n```csharp\nprivate static void ConfigureAzureDiscovery(\n    AkkaConfigurationBuilder builder,\n    ClusterBootstrapOptions bootstrapOptions,\n    AkkaManagementOptions mgmtOptions,\n    IConfiguration configuration)\n{\n    var connectionString = configuration.GetConnectionString(\"AkkaManagementAzure\");\n    if (string.IsNullOrEmpty(connectionString))\n        throw new InvalidOperationException(\"AkkaManagementAzure connection string required\");\n\n    builder.WithAzureDiscovery(options =>\n    {\n        options.ServiceName = bootstrapOptions.ServiceName;\n        options.ConnectionString = connectionString;\n        options.HostName = mgmtOptions.HostName;\n        options.Port = mgmtOptions.Port;\n    });\n}\n```\n\n**appsettings.json:**\n```json\n{\n  \"ConnectionStrings\": {\n    \"AkkaManagementAzure\": \"DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...\"\n  },\n  \"AkkaSettings\": {\n    \"ClusterBootstrapOptions\": {\n      \"Enabled\": true,\n      \"DiscoveryMethod\": \"AzureTableStorage\",\n      \"ServiceName\": \"my-service\",\n      \"AzureDiscoveryOptions\": {\n        \"TableName\": \"AkkaDiscovery\"\n      }\n    }\n  }\n}\n```\n\n---\n\n## Complete Discovery Configuration\n\n```csharp\nprivate static void ConfigureDiscovery(\n    AkkaConfigurationBuilder builder,\n    AkkaSettings settings,\n    IConfiguration configuration)\n{\n    var bootstrapOptions = settings.ClusterBootstrapOptions;\n    var mgmtOptions = settings.AkkaManagementOptions;\n\n    switch (bootstrapOptions.DiscoveryMethod)\n    {\n        case DiscoveryMethod.Config:\n            ConfigureConfigDiscovery(builder, bootstrapOptions);\n            break;\n\n        case DiscoveryMethod.Kubernetes:\n            ConfigureKubernetesDiscovery(builder, bootstrapOptions.KubernetesDiscoveryOptions);\n            break;\n\n        case DiscoveryMethod.AzureTableStorage:\n            ConfigureAzureDiscovery(builder, bootstrapOptions, mgmtOptions, configuration);\n            break;\n\n        default:\n            throw new ArgumentOutOfRangeException(\n                nameof(bootstrapOptions.DiscoveryMethod),\n                $\"Unknown discovery method: {bootstrapOptions.DiscoveryMethod}\");\n    }\n}\n```\n\n---\n\n## Health Endpoints\n\nAkka.Management exposes health endpoints for load balancers and orchestrators:\n\n| Endpoint | Purpose | Returns 200 When |\n|----------|---------|------------------|\n| `/alive` | Liveness | ActorSystem is running |\n| `/ready` | Readiness | Cluster member is Up |\n| `/cluster/members` | Debug | Returns cluster membership |\n\n### ASP.NET Core Health Check Integration\n\n```csharp\n// Register Akka health checks\nbuilder.Services.AddHealthChecks();\n\n// In Akka configuration\nbuilder\n    .WithActorSystemLivenessCheck()     // Adds \"akka-liveness\" health check\n    .WithAkkaClusterReadinessCheck();   // Adds \"akka-cluster-readiness\" health check\n\n// Map endpoints\napp.MapHealthChecks(\"/health/live\", new HealthCheckOptions\n{\n    Predicate = check => check.Tags.Contains(\"liveness\")\n});\n\napp.MapHealthChecks(\"/health/ready\", new HealthCheckOptions\n{\n    Predicate = check => check.Tags.Contains(\"readiness\")\n});\n```\n\n---\n\n## Troubleshooting\n\n### Cluster Won't Form\n\n**Symptoms:** Nodes stay as separate single-node clusters.\n\n**Checklist:**\n1. All nodes use same `ServiceName`\n2. `RequiredContactPointsNr` matches actual replica count\n3. Discovery provider is configured correctly\n4. Network allows traffic on management port (8558)\n5. For Kubernetes: RBAC permissions are set\n\n**Debug:**\n```csharp\n// Enable verbose logging\n\"AkkaSettings\": {\n  \"LogConfigOnStart\": true\n}\n```\n\n### Split Brain\n\n**Symptoms:** Multiple clusters form instead of one.\n\n**Solutions:**\n1. Set `ContactWithAllContactPoints = true`\n2. Increase `StableMargin` for slower environments\n3. For Aspire: Set `FilterOnFallbackPort = false` (dynamic ports)\n4. For Kubernetes: Set `FilterOnFallbackPort = true` (fixed ports)\n\n### Azure Discovery Issues\n\n**Symptoms:** Nodes can't find each other via Azure Tables.\n\n**Checklist:**\n1. Connection string is valid\n2. Storage account allows table operations\n3. All nodes use same `ServiceName`\n4. Firewall allows access to Azure Storage\n\n---\n\n## Aspire Integration\n\nFor detailed Aspire-specific patterns, see the `akka-net-aspire-configuration` skill.\n\nQuick reference for Aspire:\n\n```csharp\n// In AppHost\nappBuilder\n    .WithEndpoint(name: \"remote\", protocol: ProtocolType.Tcp,\n        env: \"AkkaSettings__RemoteOptions__Port\")\n    .WithEndpoint(name: \"management\", protocol: ProtocolType.Tcp,\n        env: \"AkkaSettings__AkkaManagementOptions__Port\")\n    .WithEnvironment(\"AkkaSettings__ClusterBootstrapOptions__Enabled\", \"true\")\n    .WithEnvironment(\"AkkaSettings__ClusterBootstrapOptions__DiscoveryMethod\", \"AzureTableStorage\")\n    .WithEnvironment(\"AkkaSettings__ClusterBootstrapOptions__FilterOnFallbackPort\", \"false\");\n```\n\n---\n\n## Summary: When to Use What\n\n| Scenario | Discovery Method | FilterOnFallbackPort |\n|----------|------------------|---------------------|\n| Local development (single node) | None (use seed nodes) | N/A |\n| Aspire multi-node | AzureTableStorage | `false` |\n| Kubernetes | Kubernetes | `true` |\n| Azure VMs/VMSS | AzureTableStorage | `true` |\n| Fixed infrastructure | Config | `true` |\n| AWS ECS/EC2 | AWS discovery plugins | `true` |\n",
        "skills/akka/testing-patterns/SKILL.md": "---\nname: akka-net-testing-patterns\ndescription: Write unit and integration tests for Akka.NET actors using modern Akka.Hosting.TestKit patterns. Covers dependency injection, TestProbes, persistence testing, and actor interaction verification. Includes guidance on when to use traditional TestKit.\n---\n\n# Akka.NET Testing Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing unit tests for Akka.NET actors\n- Testing persistent actors with event sourcing\n- Verifying actor interactions and message flows\n- Testing actor supervision and lifecycle\n- Mocking external dependencies in actor tests\n- Testing cluster sharding behavior locally\n- Verifying actor state recovery and persistence\n\n## Choosing Your Testing Approach\n\n### ✅ Use Akka.Hosting.TestKit (Recommended for 95% of Use Cases)\n\n**When:**\n- Building modern .NET applications with `Microsoft.Extensions.DependencyInjection`\n- Using Akka.Hosting for actor configuration in production\n- Need to inject services into actors (`IOptions`, `DbContext`, `ILogger`, HTTP clients, etc.)\n- Testing applications that use ASP.NET Core, Worker Services, or .NET Aspire\n- Working with modern Akka.NET projects (Akka.NET v1.5+)\n\n**Advantages:**\n- Native dependency injection support - override services with fakes in tests\n- Configuration parity with production (same extension methods work in tests)\n- Clean separation between actor logic and infrastructure\n- Better integration with .NET ecosystem\n- Type-safe actor registry for retrieving actors\n- Supports both local and clustered testing modes\n\n**This guide focuses primarily on Akka.Hosting.TestKit patterns.**\n\n### ⚠️ Use Traditional Akka.TestKit\n\n**When:**\n- Contributing to Akka.NET core library development\n- Working in environments without `Microsoft.Extensions` (console apps, legacy systems)\n- Legacy codebases using manual `Props` creation without DI\n- Need direct control over low-level ActorSystem configuration\n- Working with Akka.NET projects pre-v1.5\n\n**Note:** If starting a new project in 2025+, strongly prefer Akka.Hosting.TestKit unless you have specific constraints.\n\nTraditional TestKit patterns are covered briefly at the end of this document.\n\n---\n\n## Core Principles (Akka.Hosting.TestKit)\n\n1. **Inherit from `Akka.Hosting.TestKit.TestKit`** - This is a framework base class, not a user-defined one\n2. **Override `ConfigureServices()`** - Replace real services with fakes/mocks\n3. **Override `ConfigureAkka()`** - Configure actors using the same extension methods as production\n4. **Use `ActorRegistry`** - Type-safe retrieval of actor references\n5. **Composition over Inheritance** - Fake services as fields, not base classes\n6. **No Custom Base Classes** - Use method overrides, not inheritance hierarchies\n7. **Test One Actor at a Time** - Use TestProbes for dependencies\n8. **Match Production Patterns** - Same extension methods, different `AkkaExecutionMode`\n\n---\n\n## Required NuGet Packages\n\n```xml\n<ItemGroup>\n  <!-- Core testing framework -->\n  <PackageReference Include=\"Akka.Hosting.TestKit\" Version=\"*\" />\n\n  <!-- xUnit (or your preferred test framework) -->\n  <PackageReference Include=\"xunit\" Version=\"*\" />\n  <PackageReference Include=\"xunit.runner.visualstudio\" Version=\"*\" />\n  <PackageReference Include=\"Microsoft.NET.Test.Sdk\" Version=\"*\" />\n\n  <!-- Assertions (recommended) -->\n  <PackageReference Include=\"FluentAssertions\" Version=\"*\" />\n\n  <!-- In-memory persistence for testing -->\n  <PackageReference Include=\"Akka.Persistence.Hosting\" Version=\"*\" />\n\n  <!-- If testing cluster sharding -->\n  <PackageReference Include=\"Akka.Cluster.Hosting\" Version=\"*\" />\n</ItemGroup>\n```\n\n---\n\n## CRITICAL: File Watcher Fix for Test Projects\n\nAkka.Hosting.TestKit spins up real `IHost` instances, which by default enable file watchers for configuration reload. When running many tests, this exhausts file descriptor limits on Linux (inotify watch limit).\n\n**Add this to your test project - it runs before any tests execute:**\n\n```csharp\n// TestEnvironmentInitializer.cs\nusing System.Runtime.CompilerServices;\n\nnamespace YourApp.Tests;\n\ninternal static class TestEnvironmentInitializer\n{\n    [ModuleInitializer]\n    internal static void Initialize()\n    {\n        // Disable config file watching in test hosts\n        // Prevents file descriptor exhaustion (inotify watch limit) on Linux\n        Environment.SetEnvironmentVariable(\"DOTNET_HOSTBUILDER__RELOADCONFIGONCHANGE\", \"false\");\n    }\n}\n```\n\n**Why this matters:**\n- `[ModuleInitializer]` runs automatically before any test code\n- Sets the environment variable globally for all `IHost` instances\n- Prevents cryptic `inotify` errors when running 100+ tests\n- Also applies to Aspire integration tests that use `IHost`\n\n---\n\n## Pattern 1: Basic Actor Test with Akka.Hosting.TestKit\n\n```csharp\nusing Akka.Actor;\nusing Akka.Hosting;\nusing Akka.Hosting.TestKit;\nusing Akka.Persistence.Hosting;\nusing FluentAssertions;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\nusing Xunit;\nusing Xunit.Abstractions;\n\nnamespace MyApp.Tests;\n\n/// <summary>\n/// Tests for OrderActor demonstrating modern Akka.Hosting.TestKit patterns.\n/// </summary>\npublic class OrderActorTests : TestKit\n{\n    private readonly FakeOrderRepository _fakeRepository;\n    private readonly FakeEmailService _fakeEmailService;\n\n    public OrderActorTests(ITestOutputHelper output) : base(output: output)\n    {\n        // Create fake services as fields (composition, not inheritance)\n        _fakeRepository = new FakeOrderRepository();\n        _fakeEmailService = new FakeEmailService();\n    }\n\n    /// <summary>\n    /// Override ConfigureServices to inject fake services.\n    /// This runs BEFORE ConfigureAkka, so services are available to actors.\n    /// </summary>\n    protected override void ConfigureServices(HostBuilderContext context, IServiceCollection services)\n    {\n        // Register fakes as singletons (same instance used across all actors)\n        services.AddSingleton<IOrderRepository>(_fakeRepository);\n        services.AddSingleton<IEmailService>(_fakeEmailService);\n        services.AddLogging();\n    }\n\n    /// <summary>\n    /// Override ConfigureAkka to configure actor system for testing.\n    /// This is where you register actors using the same extension methods as production.\n    /// </summary>\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        // Use TestScheduler for time control\n        builder.AddHocon(\"akka.scheduler.implementation = \\\"Akka.TestKit.TestScheduler, Akka.TestKit\\\"\",\n            HoconAddMode.Prepend);\n\n        // In-memory persistence (no database needed)\n        builder.WithInMemoryJournal()\n            .WithInMemorySnapshotStore();\n\n        // Register actors using the same extension methods as production\n        builder.WithActors((system, registry, resolver) =>\n        {\n            // Create actor with dependency injection\n            var props = resolver.Props<OrderActor>();\n            var actor = system.ActorOf(props, \"order-actor\");\n\n            // Register in ActorRegistry for type-safe retrieval\n            registry.Register<OrderActor>(actor);\n        });\n    }\n\n    [Fact]\n    public async Task CreateOrder_Success_SavesToRepository()\n    {\n        // Arrange\n        var orderActor = ActorRegistry.Get<OrderActor>();\n        var command = new CreateOrder(OrderId: \"ORDER-123\", CustomerId: \"CUST-456\", Amount: 99.99m);\n\n        // Act\n        var response = await orderActor.Ask<OrderCommandResult>(command, RemainingOrDefault);\n\n        // Assert\n        response.Status.Should().Be(CommandStatus.Success);\n\n        // Verify fake repository was called\n        _fakeRepository.SaveCallCount.Should().Be(1);\n        _fakeRepository.LastSavedOrderId.Should().Be(\"ORDER-123\");\n    }\n\n    [Fact]\n    public async Task CreateOrder_RepositoryFails_ReturnsError()\n    {\n        // Arrange\n        _fakeRepository.FailNextSave = true;\n        var orderActor = ActorRegistry.Get<OrderActor>();\n        var command = new CreateOrder(OrderId: \"ORDER-789\", CustomerId: \"CUST-456\", Amount: 99.99m);\n\n        // Act\n        var response = await orderActor.Ask<OrderCommandResult>(command, RemainingOrDefault);\n\n        // Assert\n        response.Status.Should().Be(CommandStatus.Failed);\n        response.ErrorMessage.Should().NotBeNullOrEmpty();\n    }\n}\n\n// ============================================================================\n// FAKE SERVICE IMPLEMENTATIONS (Composition, not inheritance)\n// ============================================================================\n\npublic sealed class FakeOrderRepository : IOrderRepository\n{\n    public int SaveCallCount { get; private set; }\n    public string? LastSavedOrderId { get; private set; }\n    public bool FailNextSave { get; set; }\n\n    public Task SaveOrderAsync(string orderId, decimal amount)\n    {\n        SaveCallCount++;\n        LastSavedOrderId = orderId;\n\n        if (FailNextSave)\n        {\n            FailNextSave = false;\n            throw new InvalidOperationException(\"Simulated repository failure\");\n        }\n\n        return Task.CompletedTask;\n    }\n}\n\npublic sealed class FakeEmailService : IEmailService\n{\n    public int SendCallCount { get; private set; }\n    public string? LastEmailRecipient { get; private set; }\n\n    public Task SendEmailAsync(string recipient, string subject, string body)\n    {\n        SendCallCount++;\n        LastEmailRecipient = recipient;\n        return Task.CompletedTask;\n    }\n}\n```\n\n**Key Takeaways:**\n- `TestKit` is a **framework base class**, not a user-defined one\n- Fake services are **fields** (composition), not inherited\n- `ConfigureServices()` overrides DI registrations\n- `ConfigureAkka()` uses same extension methods as production\n- `ActorRegistry.Get<T>()` provides type-safe actor retrieval\n\n---\n\n## Pattern 2: Testing Actor Interactions with TestProbes\n\nUse `TestProbe` to verify that your actor sends messages to other actors without needing the full implementation.\n\n```csharp\npublic class InvoiceActorTests : TestKit\n{\n    private readonly FakeInvoiceService _fakeInvoiceService;\n    private TestProbe? _paymentProbe;\n\n    public InvoiceActorTests(ITestOutputHelper output) : base(output: output)\n    {\n        _fakeInvoiceService = new FakeInvoiceService();\n    }\n\n    /// <summary>\n    /// Property that creates TestProbe on first access (lazy initialization).\n    /// </summary>\n    private TestProbe PaymentProbe => _paymentProbe ??= CreateTestProbe(\"payment-probe\");\n\n    protected override void ConfigureServices(HostBuilderContext context, IServiceCollection services)\n    {\n        services.AddSingleton<IInvoiceService>(_fakeInvoiceService);\n    }\n\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        builder.WithInMemoryJournal().WithInMemorySnapshotStore();\n\n        builder.WithActors((system, registry, resolver) =>\n        {\n            // Register TestProbe as PaymentActor for verification\n            _paymentProbe = CreateTestProbe(\"payment-probe\");\n            registry.Register<PaymentActor>(_paymentProbe);\n\n            // Register InvoiceActor (actor under test)\n            var invoiceProps = resolver.Props<InvoiceActor>();\n            var invoiceActor = system.ActorOf(invoiceProps, \"invoice-actor\");\n            registry.Register<InvoiceActor>(invoiceActor);\n        });\n    }\n\n    [Fact]\n    public async Task CreateInvoice_Success_SendsPaymentRequest()\n    {\n        // Arrange\n        var invoiceActor = ActorRegistry.Get<InvoiceActor>();\n        var command = new CreateInvoice(InvoiceId: \"INV-001\", Amount: 100.00m);\n\n        // Act\n        var response = await invoiceActor.Ask<InvoiceCommandResult>(command, RemainingOrDefault);\n\n        // Assert - Command succeeded\n        response.Status.Should().Be(CommandStatus.Success);\n\n        // Assert - Payment request was sent to PaymentActor\n        var paymentRequest = await PaymentProbe.ExpectMsgAsync<InitiatePayment>(TimeSpan.FromSeconds(3));\n        paymentRequest.InvoiceId.Should().Be(\"INV-001\");\n        paymentRequest.Amount.Should().Be(100.00m);\n    }\n\n    [Fact]\n    public async Task PaymentCompleted_UpdatesInvoiceState()\n    {\n        // Arrange\n        var invoiceActor = ActorRegistry.Get<InvoiceActor>();\n\n        // Create invoice first\n        await invoiceActor.Ask<InvoiceCommandResult>(\n            new CreateInvoice(InvoiceId: \"INV-002\", Amount: 50.00m),\n            RemainingOrDefault);\n\n        // Drain the InitiatePayment message\n        await PaymentProbe.ExpectMsgAsync<InitiatePayment>();\n\n        // Act - Notify invoice that payment completed\n        var notification = new PaymentCompleted(InvoiceId: \"INV-002\", Amount: 50.00m);\n        invoiceActor.Tell(notification);\n\n        // Assert - Query state to verify update\n        var stateQuery = await invoiceActor.Ask<InvoiceState>(\n            new GetInvoiceState(\"INV-002\"),\n            RemainingOrDefault);\n\n        stateQuery.Status.Should().Be(InvoiceStatus.Paid);\n        stateQuery.AmountPaid.Should().Be(50.00m);\n    }\n}\n```\n\n**Key Patterns:**\n- **TestProbe as lazy property** - Created on first access\n- **Register TestProbe in ActorRegistry** - Acts as a fake actor\n- **ExpectMsgAsync<T>()** - Verifies message was sent\n- **Drain messages** - Use `ExpectMsgAsync()` to clear expected messages before proceeding\n\n---\n\n## Pattern 3: Auto-Responding TestProbe (Avoiding Ask Timeouts)\n\nWhen an actor uses `Ask` to talk to another actor, the sender expects a response. Use an auto-responder to prevent timeouts.\n\n```csharp\n/// <summary>\n/// Auto-responding actor that forwards all messages to a TestProbe while automatically\n/// replying to specific message types to avoid Ask timeouts.\n/// </summary>\ninternal sealed class PaymentAutoResponder : ReceiveActor\n{\n    private readonly IActorRef _probe;\n\n    public PaymentAutoResponder(IActorRef probe)\n    {\n        _probe = probe;\n\n        // Auto-respond to InitiatePayment with PaymentStarted\n        Receive<InitiatePayment>(msg =>\n        {\n            _probe.Tell(msg, Sender); // Forward to probe for verification\n\n            var response = new PaymentStarted(\n                PaymentId: msg.PaymentId,\n                InvoiceId: msg.InvoiceId);\n\n            Sender.Tell(response, Self); // Auto-reply to avoid timeout\n        });\n\n        // Forward all other messages without auto-responding\n        ReceiveAny(msg => _probe.Tell(msg, Sender));\n    }\n}\n\n// Usage in ConfigureAkka:\nprotected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n{\n    builder.WithActors((system, registry, resolver) =>\n    {\n        _paymentProbe = CreateTestProbe(\"payment-probe\");\n\n        // Create auto-responder that forwards to probe\n        var autoResponder = system.ActorOf(\n            Props.Create(() => new PaymentAutoResponder(_paymentProbe)),\n            \"payment-auto-responder\");\n\n        registry.Register<PaymentActor>(autoResponder);\n\n        // Register actor under test\n        var invoiceActor = system.ActorOf(resolver.Props<InvoiceActor>(), \"invoice-actor\");\n        registry.Register<InvoiceActor>(invoiceActor);\n    });\n}\n```\n\n**When to Use:**\n- Actor under test uses `Ask` to communicate with dependencies\n- You want to verify the message was sent (probe) AND avoid timeout\n- Complex interaction patterns with multiple round-trips\n\n---\n\n## Pattern 4: Testing Persistent Actors with Event Sourcing\n\n```csharp\npublic class OrderPersistentActorTests : TestKit\n{\n    public OrderPersistentActorTests(ITestOutputHelper output) : base(output: output)\n    {\n    }\n\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        // Configure TestScheduler\n        builder.AddHocon(\"akka.scheduler.implementation = \\\"Akka.TestKit.TestScheduler, Akka.TestKit\\\"\",\n            HoconAddMode.Prepend);\n\n        // In-memory persistence (events stored in memory, cleared after test)\n        builder.WithInMemoryJournal()\n            .WithInMemorySnapshotStore();\n\n        builder.WithActors((system, registry, resolver) =>\n        {\n            var props = resolver.Props<OrderPersistentActor>(\"order-123\");\n            var actor = system.ActorOf(props, \"order-persistent-actor\");\n            registry.Register<OrderPersistentActor>(actor);\n        });\n    }\n\n    [Fact]\n    public async Task CreateOrder_PersistsEvent()\n    {\n        // Arrange\n        var actor = ActorRegistry.Get<OrderPersistentActor>();\n        var command = new CreateOrder(OrderId: \"ORDER-123\", Amount: 100.00m);\n\n        // Act\n        var response = await actor.Ask<OrderCommandResult>(command, RemainingOrDefault);\n\n        // Assert\n        response.Status.Should().Be(CommandStatus.Success);\n\n        // Query state to verify event was applied\n        var state = await actor.Ask<OrderState>(new GetOrderState(\"ORDER-123\"), RemainingOrDefault);\n        state.OrderId.Should().Be(\"ORDER-123\");\n        state.Amount.Should().Be(100.00m);\n        state.Status.Should().Be(OrderStatus.Created);\n    }\n\n    [Fact]\n    public async Task ActorRecovery_AfterPassivation_RestoresState()\n    {\n        // Arrange - Create order and persist events\n        var actor = ActorRegistry.Get<OrderPersistentActor>();\n        await actor.Ask<OrderCommandResult>(\n            new CreateOrder(OrderId: \"ORDER-456\", Amount: 200.00m),\n            RemainingOrDefault);\n\n        // Get reference to the actual actor (not the registry wrapper)\n        var childActorPath = actor.Path / \"order-456\";\n        var childActor = await Sys.ActorSelection(childActorPath).ResolveOne(TimeSpan.FromSeconds(3));\n\n        // Act - Kill the actor to simulate passivation\n        await WatchAsync(childActor);\n        childActor.Tell(PoisonPill.Instance);\n        await ExpectTerminatedAsync(childActor);\n\n        // Send a query which forces the actor to recover from journal\n        var state = await actor.Ask<OrderState>(\n            new GetOrderState(\"ORDER-456\"),\n            RemainingOrDefault);\n\n        // Assert - Verify state was recovered correctly\n        state.Should().NotBeNull();\n        state.OrderId.Should().Be(\"ORDER-456\");\n        state.Amount.Should().Be(200.00m);\n        state.Status.Should().Be(OrderStatus.Created);\n    }\n}\n```\n\n**Key Patterns:**\n- **In-memory journal** - No database needed, fast tests\n- **Recovery testing** - Use `PoisonPill` to kill actor, then query to force recovery\n- **WatchAsync/ExpectTerminatedAsync** - Verify actor actually terminated before proceeding\n\n---\n\n## Pattern 5: Testing Cluster Sharding Locally\n\nUse `AkkaExecutionMode.LocalTest` to test cluster sharding behavior without an actual cluster.\n\n```csharp\n// In your production code (AkkaHostingExtensions.cs):\npublic static AkkaConfigurationBuilder WithOrderActor(\n    this AkkaConfigurationBuilder builder,\n    AkkaExecutionMode executionMode = AkkaExecutionMode.Clustered)\n{\n    if (executionMode == AkkaExecutionMode.LocalTest)\n    {\n        // Non-clustered mode: Use GenericChildPerEntityParent\n        builder.WithActors((system, registry, resolver) =>\n        {\n            var parent = system.ActorOf(\n                GenericChildPerEntityParent.CreateProps(\n                    new OrderMessageExtractor(),\n                    entityId => resolver.Props<OrderActor>(entityId)),\n                \"orders\");\n\n            registry.Register<OrderActor>(parent);\n        });\n    }\n    else\n    {\n        // Clustered mode: Use ShardRegion\n        builder.WithShardRegion<OrderActor>(\n            \"orders\",\n            (system, registry, resolver) => entityId => resolver.Props<OrderActor>(entityId),\n            new OrderMessageExtractor(),\n            new ShardOptions\n            {\n                StateStoreMode = StateStoreMode.DData,\n                Role = \"order-service\"\n            });\n    }\n\n    return builder;\n}\n\n// In your tests:\npublic class OrderShardingTests : TestKit\n{\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        builder.WithInMemoryJournal().WithInMemorySnapshotStore();\n\n        // Use the same extension method as production, but with LocalTest mode\n        builder.WithOrderActor(AkkaExecutionMode.LocalTest);\n    }\n\n    [Fact]\n    public async Task ShardedActor_RoutesMessagesByEntityId()\n    {\n        // Arrange\n        var orderRegion = ActorRegistry.Get<OrderActor>();\n\n        // Act - Send commands for two different entity IDs\n        var response1 = await orderRegion.Ask<OrderCommandResult>(\n            new CreateOrder(OrderId: \"ORDER-001\", Amount: 100m),\n            RemainingOrDefault);\n\n        var response2 = await orderRegion.Ask<OrderCommandResult>(\n            new CreateOrder(OrderId: \"ORDER-002\", Amount: 200m),\n            RemainingOrDefault);\n\n        // Assert\n        response1.Status.Should().Be(CommandStatus.Success);\n        response2.Status.Should().Be(CommandStatus.Success);\n\n        // Query state to verify routing worked correctly\n        var state1 = await orderRegion.Ask<OrderState>(\n            new GetOrderState(\"ORDER-001\"),\n            RemainingOrDefault);\n        var state2 = await orderRegion.Ask<OrderState>(\n            new GetOrderState(\"ORDER-002\"),\n            RemainingOrDefault);\n\n        state1.Amount.Should().Be(100m);\n        state2.Amount.Should().Be(200m);\n    }\n}\n```\n\n**Key Patterns:**\n- **Same extension methods** for production and tests\n- **`AkkaExecutionMode` parameter** switches between clustered and local\n- **`GenericChildPerEntityParent`** simulates sharding behavior locally\n- **No actual cluster** needed for tests\n\n---\n\n## Pattern 6: Testing Asynchronous Actor Behavior with AwaitAssertAsync\n\nUse `AwaitAssertAsync` when actors perform async operations (like calling external services).\n\n```csharp\n[Fact]\npublic async Task CreateInvoice_CallsReadModelSync()\n{\n    // Arrange\n    var invoiceActor = ActorRegistry.Get<InvoiceActor>();\n    var command = new CreateInvoice(InvoiceId: \"INV-003\", Amount: 75.00m);\n\n    // Act\n    var response = await invoiceActor.Ask<InvoiceCommandResult>(command, RemainingOrDefault);\n\n    // Assert - Command succeeded\n    response.Status.Should().Be(CommandStatus.Success);\n\n    // Assert - Read model sync was called (async operation, need to wait)\n    await AwaitAssertAsync(() =>\n    {\n        _fakeReadModelService.SyncCallCount.Should().BeGreaterOrEqualTo(1);\n        _fakeReadModelService.LastSyncedInvoiceId.Should().Be(\"INV-003\");\n    }, TimeSpan.FromSeconds(3));\n}\n\n[Fact]\npublic async Task PaymentRetry_SchedulesReminder()\n{\n    // Arrange\n    var invoiceActor = ActorRegistry.Get<InvoiceActor>();\n    await CreateAndFailPayment(invoiceActor, \"INV-004\");\n\n    // Act - Trigger payment failure (which schedules retry reminder)\n    var failure = new PaymentFailed(InvoiceId: \"INV-004\", Reason: \"Card declined\");\n    invoiceActor.Tell(failure);\n\n    // Assert - Verify reminder was scheduled (async operation)\n    var reminderClient = Sys.ReminderClient().CreateClient(\n        new ReminderEntity(\"invoicing\", \"INV-004\"));\n\n    await AwaitAssertAsync(async () =>\n    {\n        var reminders = await reminderClient.ListRemindersAsync();\n        reminders.Reminders.Should().HaveCount(1);\n        reminders.Reminders.First().Key.Name.Should().Be(\"payment-retry\");\n    }, TimeSpan.FromSeconds(3));\n}\n```\n\n**Key Patterns:**\n- **AwaitAssertAsync** - Retries assertion until it passes or times out\n- **Useful for async operations** - Read model syncs, reminder scheduling, external API calls\n- **Prevents flaky tests** - Gives async operations time to complete\n\n---\n\n## Pattern 7: Scenario-Based Integration Tests\n\nTest complete business workflows end-to-end with multiple actors and state transitions.\n\n```csharp\npublic class SubscriptionScenarioTests : TestKit\n{\n    private readonly FakeSubscriptionService _fakeService;\n\n    public SubscriptionScenarioTests(ITestOutputHelper output)\n        : base(output: output, logLevel: LogLevel.Debug)\n    {\n        _fakeService = new FakeSubscriptionService();\n    }\n\n    protected override void ConfigureServices(HostBuilderContext context, IServiceCollection services)\n    {\n        services.AddSingleton<ISubscriptionService>(_fakeService);\n        services.AddSingleton<IInvoiceService, FakeInvoiceService>();\n        services.AddSingleton<IPaymentService, FakePaymentService>();\n    }\n\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        builder.AddHocon(\"akka.scheduler.implementation = \\\"Akka.TestKit.TestScheduler, Akka.TestKit\\\"\",\n            HoconAddMode.Prepend);\n\n        builder.WithInMemoryJournal().WithInMemorySnapshotStore();\n\n        // Register all domain actors (subscription, invoice, payment)\n        builder.WithSubscriptionDomainActors(AkkaExecutionMode.LocalTest);\n    }\n\n    [Fact]\n    public async Task Scenario_FirstTimePurchase_SuccessfulPayment()\n    {\n        // Arrange\n        var subscriptionId = \"SUB-001\";\n        var subscriptionActor = ActorRegistry.Get<SubscriptionActor>();\n\n        // Step 1: Create subscription\n        var createResult = await subscriptionActor.Ask<SubscriptionCommandResult>(\n            new CreateSubscription(subscriptionId, \"CUST-123\", 99.99m),\n            RemainingOrDefault);\n        createResult.Status.Should().Be(CommandStatus.Success);\n\n        // Step 2: Verify invoice was generated\n        await AwaitAssertAsync(async () =>\n        {\n            var state = await subscriptionActor.Ask<SubscriptionState>(\n                new GetSubscriptionState(subscriptionId),\n                RemainingOrDefault);\n            state.CurrentInvoiceId.Should().NotBeNullOrEmpty();\n        });\n\n        // Step 3: Simulate payment success\n        var state = await subscriptionActor.Ask<SubscriptionState>(\n            new GetSubscriptionState(subscriptionId),\n            RemainingOrDefault);\n\n        var paymentNotification = new PaymentCompleted(\n            InvoiceId: state.CurrentInvoiceId!,\n            Amount: 99.99m);\n        subscriptionActor.Tell(paymentNotification);\n\n        // Step 4: Verify subscription is now active\n        await AwaitAssertAsync(async () =>\n        {\n            var finalState = await subscriptionActor.Ask<SubscriptionState>(\n                new GetSubscriptionState(subscriptionId),\n                RemainingOrDefault);\n            finalState.Status.Should().Be(SubscriptionStatus.Active);\n            finalState.BenefitsProvisioned.Should().BeTrue();\n        });\n\n        // Step 5: Verify service was provisioned\n        _fakeService.ProvisionCallCount.Should().BeGreaterOrEqualTo(1);\n        _fakeService.LastProvisionedSubscriptionId.Should().Be(subscriptionId);\n    }\n\n    [Fact]\n    public async Task Scenario_PaymentFailure_RetryAndGracePeriod()\n    {\n        // Arrange\n        var subscriptionId = \"SUB-002\";\n        var subscriptionActor = ActorRegistry.Get<SubscriptionActor>();\n\n        // Step 1: Create subscription and generate invoice\n        await subscriptionActor.Ask<SubscriptionCommandResult>(\n            new CreateSubscription(subscriptionId, \"CUST-456\", 199.99m),\n            RemainingOrDefault);\n\n        var state = await subscriptionActor.Ask<SubscriptionState>(\n            new GetSubscriptionState(subscriptionId),\n            RemainingOrDefault);\n        var invoiceId = state.CurrentInvoiceId!;\n\n        // Step 2: Simulate 3 payment failures\n        for (int attempt = 1; attempt <= 3; attempt++)\n        {\n            var failure = new PaymentFailed(\n                InvoiceId: invoiceId,\n                Reason: \"Insufficient funds\",\n                CanRetry: true,\n                AttemptNumber: attempt);\n\n            subscriptionActor.Tell(failure);\n\n            if (attempt < 3)\n            {\n                // Verify soft dunning notification for attempts 1-2\n                await AwaitAssertAsync(async () =>\n                {\n                    var currentState = await subscriptionActor.Ask<SubscriptionState>(\n                        new GetSubscriptionState(subscriptionId),\n                        RemainingOrDefault);\n                    currentState.PaymentRetryCount.Should().Be(attempt);\n                });\n            }\n        }\n\n        // Step 3: Verify hard dunning after 3 failures\n        await AwaitAssertAsync(async () =>\n        {\n            var finalState = await subscriptionActor.Ask<SubscriptionState>(\n                new GetSubscriptionState(subscriptionId),\n                RemainingOrDefault);\n            finalState.Status.Should().Be(SubscriptionStatus.PaymentFailed);\n            finalState.GracePeriodExpiresAt.Should().NotBeNull();\n        });\n\n        // Step 4: Verify grace period reminder scheduled\n        var reminderClient = Sys.ReminderClient().CreateClient(\n            new ReminderEntity(\"subscription\", subscriptionId));\n\n        await AwaitAssertAsync(async () =>\n        {\n            var reminders = await reminderClient.ListRemindersAsync();\n            reminders.Reminders.Should().ContainSingle(r =>\n                r.Key.Name == \"grace-period-expiration\");\n        });\n    }\n}\n```\n\n**Key Patterns:**\n- **Multi-step workflows** - Test complete business scenarios, not just single operations\n- **State verification at each step** - Use `AwaitAssertAsync` to verify state transitions\n- **Multiple actors** - Register all domain actors, test their interactions\n- **Business-focused naming** - `Scenario_FirstTimePurchase_SuccessfulPayment`\n\n---\n\n## Common Patterns Summary\n\n| Pattern | Use Case |\n|---------|----------|\n| Basic Actor Test | Single actor with injected services |\n| TestProbe | Verify actor sends messages to dependencies |\n| Auto-Responder | Avoid `Ask` timeouts when testing |\n| Persistent Actor | Test event sourcing and recovery |\n| Cluster Sharding | Test sharding behavior locally |\n| AwaitAssertAsync | Handle async operations in actors |\n| Scenario Tests | End-to-end business workflows |\n\n---\n\n## Anti-Patterns to Avoid\n\n### ❌ DON'T: Create Custom Test Base Classes\n\n```csharp\n// BAD: Custom base class for \"DRY\" setup\npublic abstract class BaseAkkaTest : TestKit\n{\n    protected IActorRef OrderActor { get; private set; }\n    protected FakeOrderRepository FakeRepository { get; private set; }\n\n    protected override void ConfigureAkka(...)\n    {\n        // Setup shared across all tests\n    }\n}\n\npublic class OrderActorTests : BaseAkkaTest\n{\n    // Now coupled to BaseAkkaTest setup\n}\n```\n\n**Why it's bad:**\n- Tight coupling between tests\n- Hidden dependencies (what services are registered?)\n- Difficult to customize per-test\n- Violates principle of test isolation\n\n**✅ DO: Use Method Overrides**\n\nEach test class overrides `ConfigureServices()` and `ConfigureAkka()` with exactly what it needs.\n\n### ❌ DON'T: Share State Between Tests\n\n```csharp\n// BAD: Reusing same actor instance across tests\npublic class OrderActorTests : TestKit\n{\n    private readonly IActorRef _orderActor;\n\n    public OrderActorTests()\n    {\n        _orderActor = /* create once */;\n    }\n\n    [Fact] public void Test1() { /* uses _orderActor */ }\n    [Fact] public void Test2() { /* uses _orderActor */ }\n}\n```\n\n**Why it's bad:**\n- Test1 and Test2 share state\n- Test execution order matters\n- Flaky tests due to side effects\n\n**✅ DO: Use xUnit Class Fixtures or Get Fresh Actors**\n\n```csharp\n// GOOD: Each test gets clean ActorSystem\npublic class OrderActorTests : TestKit\n{\n    [Fact]\n    public async Task Test1()\n    {\n        var actor = ActorRegistry.Get<OrderActor>(); // Fresh system\n        // Test\n    }\n\n    [Fact]\n    public async Task Test2()\n    {\n        var actor = ActorRegistry.Get<OrderActor>(); // Fresh system\n        // Test\n    }\n}\n```\n\n### ❌ DON'T: Use Real External Dependencies\n\n```csharp\n// BAD: Using real database in tests\nprotected override void ConfigureServices(...)\n{\n    services.AddDbContext<OrderDbContext>(options =>\n        options.UseSqlServer(connectionString)); // Real DB!\n}\n```\n\n**✅ DO: Use Fakes or In-Memory Alternatives**\n\n```csharp\n// GOOD: Fake repository\nprotected override void ConfigureServices(...)\n{\n    services.AddSingleton<IOrderRepository>(_fakeRepository);\n}\n```\n\n---\n\n## Testing with Akka.Reminders\n\nIf your actors use Akka.Reminders for scheduling, configure local reminders in tests:\n\n```csharp\nprotected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n{\n    builder.AddHocon(\"akka.scheduler.implementation = \\\"Akka.TestKit.TestScheduler, Akka.TestKit\\\"\",\n        HoconAddMode.Prepend);\n\n    builder.WithInMemoryJournal().WithInMemorySnapshotStore();\n\n    // Configure local reminders for testing\n    var shardResolver = new TestShardRegionResolver();\n\n    builder.WithLocalReminders(reminders => reminders\n        .WithInMemoryStorage()\n        .WithResolver(shardResolver)\n        .WithSettings(new ReminderSettings\n        {\n            MaxDeliveryAttempts = 5,\n            RetryBackoffBase = TimeSpan.FromSeconds(1),\n            MaxSlippage = TimeSpan.FromSeconds(60)\n        }));\n\n    builder.WithInvoicingActor(AkkaExecutionMode.LocalTest);\n\n    // Register shard region with reminder resolver after startup\n    builder.AddStartup(async (system, registry) =>\n    {\n        var invoicingRegion = await registry.GetAsync<InvoicingActor>();\n        shardResolver.RegisterShardRegion(\"invoicing\", invoicingRegion);\n    });\n}\n\n[Fact]\npublic async Task PaymentFailure_SchedulesRetryReminder()\n{\n    // Arrange\n    var invoiceId = \"INV-001\";\n    var actor = ActorRegistry.Get<InvoicingActor>();\n\n    // Act - Trigger payment failure\n    var failure = new PaymentFailed(invoiceId, \"Card declined\");\n    actor.Tell(failure);\n\n    // Assert - Verify reminder was scheduled\n    var reminderClient = Sys.ReminderClient().CreateClient(\n        new ReminderEntity(\"invoicing\", invoiceId));\n\n    await AwaitAssertAsync(async () =>\n    {\n        var reminders = await reminderClient.ListRemindersAsync();\n        reminders.Reminders.Should().HaveCount(1);\n        reminders.Reminders.First().Key.Name.Should().Be(\"payment-retry\");\n    }, TimeSpan.FromSeconds(3));\n}\n```\n\n---\n\n## Traditional Akka.TestKit (Legacy/Core Development)\n\nFor completeness, here's the traditional TestKit approach (use only when you can't use Microsoft.Extensions):\n\n```csharp\nusing Akka.Actor;\nusing Akka.TestKit.Xunit2;\nusing Xunit;\n\npublic class OrderActorTests_Traditional : TestKit\n{\n    public OrderActorTests_Traditional()\n        : base(@\"akka.loglevel = DEBUG\")\n    {\n    }\n\n    [Fact]\n    public void CreateOrder_SendsConfirmation()\n    {\n        // Arrange - Create actor manually with Props\n        var orderActor = Sys.ActorOf(Props.Create<OrderActor>(), \"order-actor\");\n\n        // Act\n        orderActor.Tell(new CreateOrder(\"ORDER-001\", 100m));\n\n        // Assert\n        var confirmation = ExpectMsg<OrderCreated>();\n        Assert.Equal(\"ORDER-001\", confirmation.OrderId);\n    }\n\n    [Fact]\n    public void OrderActor_RespondsToQuery()\n    {\n        // Arrange\n        var orderActor = Sys.ActorOf(Props.Create<OrderActor>());\n\n        // Act\n        orderActor.Tell(new CreateOrder(\"ORDER-002\", 200m));\n        ExpectMsg<OrderCreated>(); // Drain creation message\n\n        // Query\n        orderActor.Tell(new GetOrderState(\"ORDER-002\"));\n\n        // Assert\n        var state = ExpectMsg<OrderState>();\n        Assert.Equal(\"ORDER-002\", state.OrderId);\n        Assert.Equal(200m, state.Amount);\n    }\n}\n```\n\n**Key Differences:**\n- Manual `Props.Create<T>()` instead of DI\n- No service injection (actors must create dependencies internally or use `Context`)\n- `ExpectMsg<T>()` instead of `Ask` patterns\n- Constructor takes HOCON config string\n\n**When to use:**\n- Contributing to Akka.NET core\n- Legacy projects without Microsoft.Extensions\n- Console applications that don't use DI\n\n---\n\n## Best Practices\n\n1. **One test class per actor** - Keep tests focused\n2. **Override ConfigureServices/ConfigureAkka** - Don't create base classes\n3. **Use fakes, not mocks** - Simpler, more maintainable\n4. **Test one actor at a time** - Use TestProbes for dependencies\n5. **Match production patterns** - Same extension methods, different `AkkaExecutionMode`\n6. **Use AwaitAssertAsync for async** - Prevents flaky tests\n7. **Test recovery** - Kill and restart actors to verify persistence\n8. **Scenario tests for workflows** - Test complete business flows end-to-end\n9. **Keep tests fast** - In-memory persistence, no real databases\n10. **Use meaningful names** - `Scenario_FirstTimePurchase_SuccessfulPayment`\n\n---\n\n## Debugging Tips\n\n1. **Enable debug logging** - Pass `LogLevel.Debug` to TestKit constructor\n2. **Use ITestOutputHelper** - See actor system logs in test output\n3. **Inspect TestProbe** - Check `probe.Messages` to see what was sent\n4. **Query actor state** - Add state query messages for debugging\n5. **Use AwaitAssertAsync with logging** - See why assertions fail\n6. **Check ActorRegistry** - Verify actors are registered correctly\n\n```csharp\n// Constructor with debug logging\npublic OrderActorTests(ITestOutputHelper output)\n    : base(output: output, logLevel: LogLevel.Debug)\n{\n}\n\n// Check what messages TestProbe received\n[Fact]\npublic void DebugTest()\n{\n    // ... test code ...\n\n    // Inspect all messages sent to probe\n    _paymentProbe.Messages.Should().NotBeEmpty();\n    foreach (var msg in _paymentProbe.Messages)\n    {\n        Output?.WriteLine($\"Received: {msg}\");\n    }\n}\n```\n\n---\n\n## CI/CD Integration\n\n### GitHub Actions Example\n\n```yaml\nname: Akka.NET Tests\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: 9.0.x\n\n    - name: Restore dependencies\n      run: dotnet restore\n\n    - name: Build\n      run: dotnet build --no-restore -c Release\n\n    - name: Run Akka.NET tests\n      run: |\n        dotnet test tests/MyApp.Domain.Tests \\\n          --no-build \\\n          -c Release \\\n          --logger trx \\\n          --collect:\"XPlat Code Coverage\"\n\n    - name: Publish test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results\n        path: \"**/TestResults/*.trx\"\n```\n\n---\n\n## Additional Resources\n\n- **Akka.NET Documentation**: https://getakka.net/\n- **Akka.Hosting Documentation**: https://github.com/akkadotnet/Akka.Hosting\n- **Petabridge Bootcamp**: https://petabridge.com/bootcamp/ (comprehensive Akka.NET training)\n- **Akka.TestKit Guide**: https://getakka.net/articles/testing/testing-actor-systems.html\n",
        "skills/aspire/integration-testing/SKILL.md": "---\nname: aspire-integration-testing\ndescription: Write integration tests using .NET Aspire's testing facilities with xUnit. Covers test fixtures, distributed application setup, endpoint discovery, and patterns for testing ASP.NET Core apps with real dependencies.\n---\n\n# Integration Testing with .NET Aspire + xUnit\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing integration tests for .NET Aspire applications\n- Testing ASP.NET Core apps with real database connections\n- Verifying service-to-service communication in distributed applications\n- Testing with actual infrastructure (SQL Server, Redis, message queues) in containers\n- Combining Playwright UI tests with Aspire-orchestrated services\n- Testing microservices with proper service discovery and networking\n\n## Core Principles\n\n1. **Real Dependencies** - Use actual infrastructure (databases, caches) via Aspire, not mocks\n2. **Dynamic Port Binding** - Let Aspire assign ports dynamically (`127.0.0.1:0`) to avoid conflicts\n3. **Fixture Lifecycle** - Use `IAsyncLifetime` for proper test fixture setup and teardown\n4. **Endpoint Discovery** - Never hard-code URLs; discover endpoints from Aspire at runtime\n5. **Parallel Isolation** - Use xUnit collections to control test parallelization\n6. **Health Checks** - Always wait for services to be healthy before running tests\n\n## High-Level Testing Architecture\n\n```\n┌─────────────────┐                    ┌──────────────────────┐\n│ xUnit test file │──uses────────────►│  AspireFixture       │\n└─────────────────┘                    │  (IAsyncLifetime)    │\n                                       └──────────────────────┘\n                                               │\n                                               │ starts\n                                               ▼\n                                    ┌───────────────────────────┐\n                                    │  DistributedApplication   │\n                                    │  (from AppHost)           │\n                                    └───────────────────────────┘\n                                               │ exposes\n                                               ▼\n                                  ┌──────────────────────────────┐\n                                  │   Dynamic HTTP Endpoints     │\n                                  └──────────────────────────────┘\n                                               │ consumed by\n                                               ▼\n                                   ┌─────────────────────────┐\n                                   │  HttpClient / Playwright│\n                                   └─────────────────────────┘\n```\n\n## Required NuGet Packages\n\n```xml\n<ItemGroup>\n  <PackageReference Include=\"Aspire.Hosting.Testing\" Version=\"$(AspireVersion)\" />\n  <PackageReference Include=\"xunit\" Version=\"*\" />\n  <PackageReference Include=\"xunit.runner.visualstudio\" Version=\"*\" />\n  <PackageReference Include=\"Microsoft.NET.Test.Sdk\" Version=\"*\" />\n</ItemGroup>\n```\n\n## CRITICAL: File Watcher Fix for Integration Tests\n\nWhen running many integration tests that each start an IHost, the default .NET host builder enables file watchers for configuration reload. This exhausts file descriptor limits on Linux.\n\n**Add this to your test project before any tests run:**\n\n```csharp\n// TestEnvironmentInitializer.cs\nusing System.Runtime.CompilerServices;\n\nnamespace YourApp.Tests;\n\ninternal static class TestEnvironmentInitializer\n{\n    [ModuleInitializer]\n    internal static void Initialize()\n    {\n        // Disable config file watching in test hosts\n        // Prevents file descriptor exhaustion (inotify watch limit) on Linux\n        Environment.SetEnvironmentVariable(\"DOTNET_HOSTBUILDER__RELOADCONFIGONCHANGE\", \"false\");\n    }\n}\n```\n\n**Why this matters:** `[ModuleInitializer]` runs before any test code executes, setting the environment variable globally for all IHost instances created during tests.\n\n## Pattern 1: Basic Aspire Test Fixture (Modern API)\n\n```csharp\nusing Aspire.Hosting;\nusing Aspire.Hosting.Testing;\n\npublic sealed class AspireAppFixture : IAsyncLifetime\n{\n    private DistributedApplication? _app;\n\n    public DistributedApplication App => _app\n        ?? throw new InvalidOperationException(\"App not initialized\");\n\n    public async Task InitializeAsync()\n    {\n        // Pass configuration overrides as command-line args (cleaner than Configuration dictionary)\n        var builder = await DistributedApplicationTestingBuilder\n            .CreateAsync<Projects.YourApp_AppHost>([\n                \"YourApp:UseVolumes=false\",           // No persistence - clean slate each test\n                \"YourApp:Environment=IntegrationTest\",\n                \"YourApp:Replicas=1\"                  // Single instance for tests\n            ]);\n\n        _app = await builder.BuildAsync();\n\n        // Phase 1: Start the application (container startup)\n        using var startupCts = new CancellationTokenSource(TimeSpan.FromMinutes(10));\n        await _app.StartAsync(startupCts.Token);\n\n        // Phase 2: Wait for services to become healthy (use built-in API)\n        using var healthCts = new CancellationTokenSource(TimeSpan.FromMinutes(5));\n        await _app.ResourceNotifications.WaitForResourceHealthyAsync(\"api\", healthCts.Token);\n    }\n\n    public Uri GetEndpoint(string resourceName, string scheme = \"https\")\n    {\n        return _app?.GetEndpoint(resourceName, scheme)\n            ?? throw new InvalidOperationException($\"Endpoint for '{resourceName}' not found\");\n    }\n\n    public async Task DisposeAsync()\n    {\n        if (_app is not null)\n        {\n            await _app.DisposeAsync();\n        }\n    }\n}\n```\n\n## Pattern 2: Using the Fixture in Tests\n\n```csharp\n// Define a collection to share the fixture across multiple test classes\n[CollectionDefinition(\"Aspire collection\")]\npublic class AspireCollection : ICollectionFixture<AspireAppFixture> { }\n\n// Use the fixture in your test class\n[Collection(\"Aspire collection\")]\npublic class IntegrationTests\n{\n    private readonly AspireAppFixture _fixture;\n\n    public IntegrationTests(AspireAppFixture fixture)\n    {\n        _fixture = fixture;\n    }\n\n    [Fact]\n    public async Task Application_ShouldStart()\n    {\n        // Get the web application resource\n        var webApp = _fixture.App.GetResource(\"yourapp\");\n\n        // Get the HTTP endpoint\n        var httpClient = _fixture.App.CreateHttpClient(\"yourapp\");\n\n        // Make a request\n        var response = await httpClient.GetAsync(\"/\");\n\n        Assert.Equal(HttpStatusCode.OK, response.StatusCode);\n    }\n}\n```\n\n## Pattern 3: Endpoint Discovery\n\n```csharp\npublic static class DistributedApplicationExtensions\n{\n    public static ResourceEndpoint GetEndpoint(\n        this DistributedApplication app,\n        string resourceName,\n        string? endpointName = null)\n    {\n        var resource = app.GetResource(resourceName);\n\n        if (resource is null)\n            throw new InvalidOperationException(\n                $\"Resource '{resourceName}' not found\");\n\n        var endpoint = endpointName is null\n            ? resource.GetEndpoints().FirstOrDefault()\n            : resource.GetEndpoint(endpointName);\n\n        if (endpoint is null)\n            throw new InvalidOperationException(\n                $\"Endpoint '{endpointName}' not found on resource '{resourceName}'\");\n\n        return endpoint;\n    }\n\n    public static string GetEndpointUrl(\n        this DistributedApplication app,\n        string resourceName,\n        string? endpointName = null)\n    {\n        var endpoint = app.GetEndpoint(resourceName, endpointName);\n        return endpoint.Url;\n    }\n}\n\n// Usage in tests\n[Fact]\npublic async Task CanAccessWebApplication()\n{\n    var url = _fixture.App.GetEndpointUrl(\"yourapp\");\n    var client = new HttpClient { BaseAddress = new Uri(url) };\n\n    var response = await client.GetAsync(\"/health\");\n\n    Assert.Equal(HttpStatusCode.OK, response.StatusCode);\n}\n```\n\n## Pattern 4: Testing with Database Dependencies\n\n```csharp\npublic class DatabaseIntegrationTests\n{\n    private readonly AspireAppFixture _fixture;\n\n    public DatabaseIntegrationTests(AspireAppFixture fixture)\n    {\n        _fixture = fixture;\n    }\n\n    [Fact]\n    public async Task Database_ShouldBeInitialized()\n    {\n        // Get connection string from Aspire\n        var dbResource = _fixture.App.GetResource(\"yourdb\");\n        var connectionString = await dbResource\n            .GetConnectionStringAsync();\n\n        // Test database access\n        await using var connection = new SqlConnection(connectionString);\n        await connection.OpenAsync();\n\n        var result = await connection.QuerySingleAsync<int>(\n            \"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES\");\n\n        Assert.True(result > 0, \"Database should have tables\");\n    }\n}\n```\n\n## Pattern 5: Combining with Playwright for UI Tests\n\n```csharp\nusing Microsoft.Playwright;\n\npublic sealed class AspirePlaywrightFixture : IAsyncLifetime\n{\n    private DistributedApplication? _app;\n    private IPlaywright? _playwright;\n    private IBrowser? _browser;\n\n    public DistributedApplication App => _app!;\n    public IBrowser Browser => _browser!;\n\n    public async Task InitializeAsync()\n    {\n        // Start Aspire application\n        var appHost = await DistributedApplicationTestingBuilder\n            .CreateAsync<Projects.YourApp_AppHost>();\n\n        _app = await appHost.BuildAsync();\n        await _app.StartAsync();\n\n        // Wait for app to be fully ready\n        await Task.Delay(2000); // Or use proper health check polling\n\n        // Start Playwright\n        _playwright = await Playwright.CreateAsync();\n        _browser = await _playwright.Chromium.LaunchAsync(new()\n        {\n            Headless = true\n        });\n    }\n\n    public async Task DisposeAsync()\n    {\n        if (_browser is not null)\n            await _browser.DisposeAsync();\n\n        _playwright?.Dispose();\n\n        if (_app is not null)\n            await _app.DisposeAsync();\n    }\n}\n\n[Collection(\"Aspire Playwright collection\")]\npublic class UIIntegrationTests\n{\n    private readonly AspirePlaywrightFixture _fixture;\n\n    public UIIntegrationTests(AspirePlaywrightFixture fixture)\n    {\n        _fixture = fixture;\n    }\n\n    [Fact]\n    public async Task HomePage_ShouldLoad()\n    {\n        var url = _fixture.App.GetEndpointUrl(\"yourapp\");\n        var page = await _fixture.Browser.NewPageAsync();\n\n        await page.GotoAsync(url);\n\n        var title = await page.TitleAsync();\n        Assert.NotEmpty(title);\n    }\n}\n```\n\n## Pattern 6: Conditional Volume Configuration in AppHost\n\nDesign your AppHost to support test scenarios by making volumes optional:\n\n```csharp\n// In your AppHost Program.cs\npublic class AppConfiguration\n{\n    /// <summary>\n    /// Whether to use persistent volumes for databases.\n    /// Defaults to false - tests get a clean database each run.\n    /// </summary>\n    public bool UseVolumes { get; set; } = false;\n\n    public string Environment { get; set; } = \"Development\";\n    public int Replicas { get; set; } = 1;\n}\n\nvar builder = DistributedApplication.CreateBuilder(args);\n\n// Bind configuration from command-line args or appsettings\nvar config = builder.Configuration.GetSection(\"YourApp\")\n    .Get<AppConfiguration>() ?? new AppConfiguration();\n\nvar postgres = builder.AddPostgres(\"postgres\").WithPgAdmin();\n\n// Only persist data when explicitly enabled (not during tests)\nif (config.UseVolumes)\n{\n    postgres.WithDataVolume();\n}\n\nvar db = postgres.AddDatabase(\"appdb\");\n\n// Migrations run first\nvar migrations = builder.AddProject<Projects.YourApp_Migrations>(\"migrations\")\n    .WaitFor(db)\n    .WithReference(db);\n\n// API waits for migrations to complete\nvar api = builder.AddProject<Projects.YourApp_Api>(\"api\")\n    .WaitForCompletion(migrations)\n    .WithReference(db);\n```\n\n**Then in tests, pass `UseVolumes=false`:**\n\n```csharp\nvar builder = await DistributedApplicationTestingBuilder\n    .CreateAsync<Projects.YourApp_AppHost>([\n        \"YourApp:UseVolumes=false\"  // Clean database each test run\n    ]);\n```\n\n## Pattern 7: Database Reset with Respawn\n\nFor tests that modify data, use [Respawn](https://github.com/jbogard/Respawn) to reset between tests:\n\n```csharp\nusing Respawn;\n\npublic class AspireFixtureWithReset : IAsyncLifetime\n{\n    private DistributedApplication? _app;\n    private Respawner? _respawner;\n    private string? _connectionString;\n\n    public async Task InitializeAsync()\n    {\n        var builder = await DistributedApplicationTestingBuilder\n            .CreateAsync<Projects.YourApp_AppHost>([\n                \"YourApp:UseVolumes=false\"\n            ]);\n\n        _app = await builder.BuildAsync();\n        await _app.StartAsync();\n\n        // Wait for database and migrations\n        await _app.ResourceNotifications.WaitForResourceHealthyAsync(\"api\");\n\n        // Get connection string and create respawner\n        var dbResource = _app.GetResource(\"appdb\");\n        _connectionString = await dbResource.GetConnectionStringAsync();\n\n        _respawner = await Respawner.CreateAsync(_connectionString, new RespawnerOptions\n        {\n            TablesToIgnore = new[]\n            {\n                \"__EFMigrationsHistory\",\n                \"schema_version\",        // DbUp\n                \"AspNetRoles\"            // Seeded reference data\n            },\n            DbAdapter = DbAdapter.Postgres\n        });\n    }\n\n    /// <summary>\n    /// Reset database to clean state between tests.\n    /// </summary>\n    public async Task ResetDatabaseAsync()\n    {\n        if (_respawner is not null && _connectionString is not null)\n        {\n            await _respawner.ResetAsync(_connectionString);\n        }\n    }\n\n    public async Task DisposeAsync()\n    {\n        if (_app is not null)\n            await _app.DisposeAsync();\n    }\n}\n```\n```\n\n## Pattern 7: Waiting for Resource Readiness\n\n```csharp\npublic static class ResourceExtensions\n{\n    public static async Task WaitForHealthyAsync(\n        this DistributedApplication app,\n        string resourceName,\n        TimeSpan? timeout = null)\n    {\n        timeout ??= TimeSpan.FromSeconds(30);\n        var cts = new CancellationTokenSource(timeout.Value);\n\n        var resource = app.GetResource(resourceName);\n\n        while (!cts.Token.IsCancellationRequested)\n        {\n            try\n            {\n                var httpClient = app.CreateHttpClient(resourceName);\n                var response = await httpClient.GetAsync(\n                    \"/health\",\n                    cts.Token);\n\n                if (response.IsSuccessStatusCode)\n                    return;\n            }\n            catch\n            {\n                // Resource not ready yet\n            }\n\n            await Task.Delay(500, cts.Token);\n        }\n\n        throw new TimeoutException(\n            $\"Resource '{resourceName}' did not become healthy within {timeout}\");\n    }\n}\n\n// Usage\n[Fact]\npublic async Task ServicesShouldBeHealthy()\n{\n    await _fixture.App.WaitForHealthyAsync(\"yourapp\");\n    await _fixture.App.WaitForHealthyAsync(\"youra pi\");\n\n    // Now proceed with tests\n}\n```\n\n## Pattern 8: Testing Service-to-Service Communication\n\n```csharp\n[Fact]\npublic async Task WebApp_ShouldCallApi()\n{\n    var webClient = _fixture.App.CreateHttpClient(\"webapp\");\n    var apiClient = _fixture.App.CreateHttpClient(\"api\");\n\n    // Verify API is accessible\n    var apiResponse = await apiClient.GetAsync(\"/api/data\");\n    Assert.True(apiResponse.IsSuccessStatusCode);\n\n    // Verify WebApp calls API correctly\n    var webResponse = await webClient.GetAsync(\"/fetch-data\");\n    Assert.True(webResponse.IsSuccessStatusCode);\n\n    var content = await webResponse.Content.ReadAsStringAsync();\n    Assert.NotEmpty(content);\n}\n```\n\n## Pattern 9: Testing with Message Queues\n\n```csharp\n[Fact]\npublic async Task MessageQueue_ShouldProcessMessages()\n{\n    // Get RabbitMQ connection from Aspire\n    var rabbitMqResource = _fixture.App.GetResource(\"messaging\");\n    var connectionString = await rabbitMqResource\n        .GetConnectionStringAsync();\n\n    var factory = new ConnectionFactory\n    {\n        Uri = new Uri(connectionString)\n    };\n\n    using var connection = await factory.CreateConnectionAsync();\n    using var channel = await connection.CreateChannelAsync();\n\n    // Publish a test message\n    await channel.QueueDeclareAsync(\"test-queue\", durable: false);\n    await channel.BasicPublishAsync(\n        exchange: \"\",\n        routingKey: \"test-queue\",\n        body: Encoding.UTF8.GetBytes(\"test message\"));\n\n    // Wait for processing\n    await Task.Delay(1000);\n\n    // Verify message was processed\n    // (check database, file system, or other side effects)\n}\n```\n\n## Common Patterns Summary\n\n| Pattern | Use Case |\n|---------|----------|\n| Basic Fixture | Simple HTTP endpoint testing |\n| Endpoint Discovery | Avoid hard-coded URLs |\n| Database Testing | Verify data access layer |\n| Playwright Integration | Full UI testing with real backend |\n| Configuration Override | Test-specific settings |\n| Health Checks | Ensure services are ready |\n| Service Communication | Test distributed system interactions |\n| Message Queue Testing | Verify async messaging |\n\n## Tricky / Non-Obvious Tips\n\n| Problem | Solution |\n|---------|----------|\n| Tests timeout immediately | Call `await _app.StartAsync()` and wait for services to be healthy before running tests |\n| Port conflicts between tests | Use xUnit `CollectionDefinition` to share fixtures and avoid starting multiple instances |\n| Flaky tests due to timing | Implement proper health check polling instead of `Task.Delay()` |\n| Can't connect to SQL Server | Ensure connection string is retrieved dynamically via `GetConnectionStringAsync()` |\n| Parallel tests interfere | Use `[Collection]` attribute to run related tests sequentially |\n| Aspire dashboard conflicts | Only one Aspire dashboard can run at a time; tests will reuse the same dashboard instance |\n\n## CI/CD Integration\n\n### GitHub Actions Example\n\n```yaml\nname: Integration Tests\n\non:\n  push:\n    branches: [ main, dev ]\n  pull_request:\n    branches: [ main, dev ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: 9.0.x\n\n    - name: Restore dependencies\n      run: dotnet restore\n\n    - name: Build\n      run: dotnet build --no-restore -c Release\n\n    - name: Run integration tests\n      run: |\n        dotnet test tests/YourApp.IntegrationTests \\\n          --no-build \\\n          -c Release \\\n          --logger trx \\\n          --collect:\"XPlat Code Coverage\"\n\n    - name: Publish test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results\n        path: \"**/TestResults/*.trx\"\n```\n\n## Best Practices\n\n1. **Use `IAsyncLifetime`** - Ensures proper async initialization and cleanup\n2. **Share fixtures via collections** - Reduces test execution time by reusing app instances\n3. **Discover endpoints dynamically** - Never hard-code localhost:5000 or similar\n4. **Wait for health checks** - Don't assume services are immediately ready\n5. **Test with real dependencies** - Aspire makes it easy to use real SQL, Redis, etc.\n6. **Clean up resources** - Always implement `DisposeAsync` properly\n7. **Use meaningful test data** - Seed databases with realistic test data\n8. **Test failure scenarios** - Verify error handling and resilience\n9. **Keep tests isolated** - Each test should be independent and order-agnostic\n10. **Monitor test execution time** - If tests are slow, consider parallelization or optimization\n\n## Advanced: Custom Resource Waiters\n\n```csharp\npublic static class ResourceWaiters\n{\n    public static async Task WaitForSqlServerAsync(\n        this DistributedApplication app,\n        string resourceName,\n        CancellationToken ct = default)\n    {\n        var resource = app.GetResource(resourceName);\n        var connectionString = await resource.GetConnectionStringAsync(ct);\n\n        var retryCount = 0;\n        const int maxRetries = 30;\n\n        while (retryCount < maxRetries)\n        {\n            try\n            {\n                await using var connection = new SqlConnection(connectionString);\n                await connection.OpenAsync(ct);\n                return; // Success!\n            }\n            catch (SqlException)\n            {\n                retryCount++;\n                await Task.Delay(1000, ct);\n            }\n        }\n\n        throw new TimeoutException(\n            $\"SQL Server resource '{resourceName}' did not become ready\");\n    }\n\n    public static async Task WaitForRedisAsync(\n        this DistributedApplication app,\n        string resourceName,\n        CancellationToken ct = default)\n    {\n        var resource = app.GetResource(resourceName);\n        var connectionString = await resource.GetConnectionStringAsync(ct);\n\n        var retryCount = 0;\n        const int maxRetries = 30;\n\n        while (retryCount < maxRetries)\n        {\n            try\n            {\n                var redis = await ConnectionMultiplexer.ConnectAsync(\n                    connectionString);\n                await redis.GetDatabase().PingAsync();\n                return; // Success!\n            }\n            catch\n            {\n                retryCount++;\n                await Task.Delay(1000, ct);\n            }\n        }\n\n        throw new TimeoutException(\n            $\"Redis resource '{resourceName}' did not become ready\");\n    }\n}\n\n// Usage\npublic async Task InitializeAsync()\n{\n    _app = await appHost.BuildAsync();\n    await _app.StartAsync();\n\n    // Wait for dependencies to be ready\n    await _app.WaitForSqlServerAsync(\"yourdb\");\n    await _app.WaitForRedisAsync(\"cache\");\n}\n```\n\n## Aspire CLI and MCP Integration\n\nAspire 13.1+ includes MCP (Model Context Protocol) integration for AI coding assistants like Claude Code. This allows AI tools to query application state, view logs, and inspect traces.\n\n### Installing the Aspire CLI\n\n```bash\n# Install the Aspire CLI globally\ndotnet tool install -g aspire.cli\n\n# Or update existing installation\ndotnet tool update -g aspire.cli\n```\n\n### Initializing MCP for Claude Code\n\n```bash\n# Navigate to your Aspire project\ncd src/MyApp.AppHost\n\n# Initialize MCP configuration (auto-detects Claude Code)\naspire mcp init\n```\n\nThis creates the necessary configuration files for Claude Code to connect to your running Aspire application.\n\n### Running with MCP Enabled\n\n```bash\n# Run your Aspire app with MCP server\naspire run\n\n# The CLI will output the MCP endpoint URL\n# Claude Code can then connect and query:\n# - Resource states and health status\n# - Real-time console logs\n# - Distributed traces\n# - Available Aspire integrations\n```\n\n### MCP Capabilities\n\nWhen connected, AI assistants can:\n- **Query resources** - Get resource states, endpoints, health status\n- **Debug with logs** - Access real-time console output from all services\n- **Investigate telemetry** - View structured logs and distributed traces\n- **Execute commands** - Run resource-specific commands\n- **Discover integrations** - List available Aspire hosting integrations (Redis, PostgreSQL, Azure services)\n\n### Benefits for Development\n\n- AI assistants can see your actual running application state\n- Debugging assistance uses real telemetry data\n- No need for manual log copying/pasting\n- AI can help correlate distributed trace spans\n\nFor more details, see:\n- [Aspire MCP Configuration](https://aspire.dev/get-started/configure-mcp/)\n- [Aspire CLI Commands](https://aspire.dev/reference/cli/commands/aspire-mcp-init/)\n\n---\n\n## Debugging Tips\n\n1. **Run Aspire Dashboard** - When tests fail, check the dashboard at `http://localhost:15888`\n2. **Use Aspire CLI with MCP** - Let AI assistants query real application state\n3. **Enable detailed logging** - Set `ASPIRE_ALLOW_UNSECURED_TRANSPORT=true` for more verbose output\n4. **Check container logs** - Use `docker logs` to inspect container output\n5. **Use breakpoints in fixtures** - Debug fixture initialization to catch startup issues\n6. **Verify resource names** - Ensure resource names match between AppHost and tests\n",
        "skills/aspire/service-defaults/SKILL.md": "---\nname: aspire-service-defaults\ndescription: Create a shared ServiceDefaults project for Aspire applications. Centralizes OpenTelemetry, health checks, resilience, and service discovery configuration across all services.\n---\n\n# Aspire Service Defaults\n\n## When to Use This Skill\n\nUse this skill when:\n- Building Aspire-based distributed applications\n- Need consistent observability (logging, tracing, metrics) across services\n- Want shared health check configuration\n- Configuring HttpClient resilience and service discovery\n\n---\n\n## What is ServiceDefaults?\n\nServiceDefaults is a shared project that provides common configuration for all services in an Aspire application:\n\n- **OpenTelemetry** - Logging, tracing, and metrics\n- **Health Checks** - Readiness and liveness endpoints\n- **Service Discovery** - Automatic service resolution\n- **HTTP Resilience** - Retry and circuit breaker policies\n\nEvery service references this project and calls `AddServiceDefaults()`.\n\n---\n\n## Project Structure\n\n```\nsrc/\n  MyApp.ServiceDefaults/\n    Extensions.cs\n    MyApp.ServiceDefaults.csproj\n  MyApp.Api/\n    Program.cs  # Calls AddServiceDefaults()\n  MyApp.Worker/\n    Program.cs  # Calls AddServiceDefaults()\n  MyApp.AppHost/\n    Program.cs\n```\n\n---\n\n## ServiceDefaults Project\n\n### Project File\n\n```xml\n<Project Sdk=\"Microsoft.NET.Sdk\">\n  <PropertyGroup>\n    <TargetFramework>net9.0</TargetFramework>\n    <IsAspireSharedProject>true</IsAspireSharedProject>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <FrameworkReference Include=\"Microsoft.AspNetCore.App\" />\n    <PackageReference Include=\"Microsoft.Extensions.Http.Resilience\" />\n    <PackageReference Include=\"Microsoft.Extensions.ServiceDiscovery\" />\n    <PackageReference Include=\"OpenTelemetry.Exporter.OpenTelemetryProtocol\" />\n    <PackageReference Include=\"OpenTelemetry.Extensions.Hosting\" />\n    <PackageReference Include=\"OpenTelemetry.Instrumentation.AspNetCore\" />\n    <PackageReference Include=\"OpenTelemetry.Instrumentation.Http\" />\n    <PackageReference Include=\"OpenTelemetry.Instrumentation.Runtime\" />\n  </ItemGroup>\n</Project>\n```\n\n### Extensions.cs\n\n```csharp\nusing Microsoft.AspNetCore.Builder;\nusing Microsoft.AspNetCore.Diagnostics.HealthChecks;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Diagnostics.HealthChecks;\nusing Microsoft.Extensions.Logging;\nusing OpenTelemetry;\nusing OpenTelemetry.Metrics;\nusing OpenTelemetry.Trace;\n\nnamespace Microsoft.Extensions.Hosting;\n\npublic static class Extensions\n{\n    private const string HealthEndpointPath = \"/health\";\n    private const string AlivenessEndpointPath = \"/alive\";\n\n    /// <summary>\n    /// Adds common Aspire services: OpenTelemetry, health checks,\n    /// service discovery, and HTTP resilience.\n    /// </summary>\n    public static TBuilder AddServiceDefaults<TBuilder>(this TBuilder builder)\n        where TBuilder : IHostApplicationBuilder\n    {\n        builder.ConfigureOpenTelemetry();\n        builder.AddDefaultHealthChecks();\n\n        builder.Services.AddServiceDiscovery();\n\n        builder.Services.ConfigureHttpClientDefaults(http =>\n        {\n            // Resilience: retries, circuit breaker, timeouts\n            http.AddStandardResilienceHandler();\n\n            // Service discovery: resolve service names to addresses\n            http.AddServiceDiscovery();\n        });\n\n        return builder;\n    }\n\n    public static TBuilder ConfigureOpenTelemetry<TBuilder>(this TBuilder builder)\n        where TBuilder : IHostApplicationBuilder\n    {\n        // Logging\n        builder.Logging.AddOpenTelemetry(logging =>\n        {\n            logging.IncludeFormattedMessage = true;\n            logging.IncludeScopes = true;\n        });\n\n        builder.Services.AddOpenTelemetry()\n            // Metrics\n            .WithMetrics(metrics =>\n            {\n                metrics\n                    .AddAspNetCoreInstrumentation()\n                    .AddHttpClientInstrumentation()\n                    .AddRuntimeInstrumentation();\n            })\n            // Tracing\n            .WithTracing(tracing =>\n            {\n                tracing\n                    .AddSource(builder.Environment.ApplicationName)\n                    .AddAspNetCoreInstrumentation(options =>\n                        // Exclude health checks from traces\n                        options.Filter = context =>\n                            !context.Request.Path.StartsWithSegments(HealthEndpointPath) &&\n                            !context.Request.Path.StartsWithSegments(AlivenessEndpointPath))\n                    .AddHttpClientInstrumentation();\n            });\n\n        builder.AddOpenTelemetryExporters();\n\n        return builder;\n    }\n\n    private static TBuilder AddOpenTelemetryExporters<TBuilder>(this TBuilder builder)\n        where TBuilder : IHostApplicationBuilder\n    {\n        // Use OTLP exporter if endpoint is configured (Aspire Dashboard, Jaeger, etc.)\n        var useOtlp = !string.IsNullOrWhiteSpace(\n            builder.Configuration[\"OTEL_EXPORTER_OTLP_ENDPOINT\"]);\n\n        if (useOtlp)\n        {\n            builder.Services.AddOpenTelemetry().UseOtlpExporter();\n        }\n\n        return builder;\n    }\n\n    public static TBuilder AddDefaultHealthChecks<TBuilder>(this TBuilder builder)\n        where TBuilder : IHostApplicationBuilder\n    {\n        builder.Services.AddHealthChecks()\n            .AddCheck(\"self\", () => HealthCheckResult.Healthy(), [\"live\"]);\n\n        return builder;\n    }\n\n    /// <summary>\n    /// Maps health check endpoints. Call after UseRouting().\n    /// </summary>\n    public static WebApplication MapDefaultEndpoints(this WebApplication app)\n    {\n        // Only expose in development - see security note below\n        if (app.Environment.IsDevelopment())\n        {\n            // Readiness: all health checks must pass\n            app.MapHealthChecks(HealthEndpointPath);\n\n            // Liveness: only \"live\" tagged checks\n            app.MapHealthChecks(AlivenessEndpointPath, new HealthCheckOptions\n            {\n                Predicate = r => r.Tags.Contains(\"live\")\n            });\n        }\n\n        return app;\n    }\n}\n```\n\n---\n\n## Usage in Services\n\n### API Service\n\n```csharp\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add all service defaults\nbuilder.AddServiceDefaults();\n\n// Add your services\nbuilder.Services.AddControllers();\n\nvar app = builder.Build();\n\n// Map health endpoints\napp.MapDefaultEndpoints();\n\napp.MapControllers();\napp.Run();\n```\n\n### Worker Service\n\n```csharp\nvar builder = Host.CreateApplicationBuilder(args);\n\n// Works for non-web hosts too\nbuilder.AddServiceDefaults();\n\nbuilder.Services.AddHostedService<MyWorker>();\n\nvar host = builder.Build();\nhost.Run();\n```\n\n---\n\n## Adding Custom Health Checks\n\n```csharp\npublic static TBuilder AddDefaultHealthChecks<TBuilder>(this TBuilder builder)\n    where TBuilder : IHostApplicationBuilder\n{\n    builder.Services.AddHealthChecks()\n        // Basic liveness\n        .AddCheck(\"self\", () => HealthCheckResult.Healthy(), [\"live\"])\n\n        // Database readiness\n        .AddNpgSql(\n            builder.Configuration.GetConnectionString(\"postgres\")!,\n            name: \"postgres\",\n            tags: [\"ready\"])\n\n        // Redis readiness\n        .AddRedis(\n            builder.Configuration.GetConnectionString(\"redis\")!,\n            name: \"redis\",\n            tags: [\"ready\"])\n\n        // Custom check\n        .AddCheck<MyCustomHealthCheck>(\"custom\", tags: [\"ready\"]);\n\n    return builder;\n}\n```\n\n---\n\n## Adding Custom Trace Sources\n\nFor Akka.NET or custom ActivitySources:\n\n```csharp\npublic static TBuilder ConfigureOpenTelemetry<TBuilder>(this TBuilder builder)\n    where TBuilder : IHostApplicationBuilder\n{\n    builder.Services.AddOpenTelemetry()\n        .WithTracing(tracing =>\n        {\n            tracing\n                .AddSource(builder.Environment.ApplicationName)\n                // Akka.NET tracing\n                .AddSource(\"Akka.NET\")\n                // Custom sources\n                .AddSource(\"MyApp.Orders\")\n                .AddSource(\"MyApp.Payments\")\n                .AddAspNetCoreInstrumentation()\n                .AddHttpClientInstrumentation();\n        });\n\n    return builder;\n}\n```\n\n---\n\n## Production Health Checks\n\nFor production, protect health endpoints or use different paths:\n\n```csharp\npublic static WebApplication MapDefaultEndpoints(this WebApplication app)\n{\n    // Always map for Kubernetes probes, but consider:\n    // - Using internal-only ports\n    // - Adding authorization\n    // - Rate limiting\n\n    app.MapHealthChecks(\"/health\", new HealthCheckOptions\n    {\n        // Only return status, not details\n        ResponseWriter = (context, report) =>\n        {\n            context.Response.ContentType = \"text/plain\";\n            return context.Response.WriteAsync(report.Status.ToString());\n        }\n    });\n\n    app.MapHealthChecks(\"/alive\", new HealthCheckOptions\n    {\n        Predicate = r => r.Tags.Contains(\"live\"),\n        ResponseWriter = (context, report) =>\n        {\n            context.Response.ContentType = \"text/plain\";\n            return context.Response.WriteAsync(report.Status.ToString());\n        }\n    });\n\n    return app;\n}\n```\n\n---\n\n## Integration with AppHost\n\nThe AppHost automatically configures OTLP endpoints:\n\n```csharp\n// AppHost/Program.cs\nvar builder = DistributedApplication.CreateBuilder(args);\n\nvar postgres = builder.AddPostgres(\"postgres\");\nvar redis = builder.AddRedis(\"redis\");\n\nvar api = builder.AddProject<Projects.MyApp_Api>(\"api\")\n    .WithReference(postgres)\n    .WithReference(redis);\n\nbuilder.Build().Run();\n```\n\nServices receive `OTEL_EXPORTER_OTLP_ENDPOINT` automatically, sending telemetry to the Aspire Dashboard.\n\n---\n\n## Best Practices\n\n| Practice | Reason |\n|----------|--------|\n| **One ServiceDefaults project** | Consistent config across all services |\n| **Filter health checks from traces** | Reduces noise in observability data |\n| **Tag health checks** | Separate liveness from readiness |\n| **Use StandardResilienceHandler** | Built-in retry, circuit breaker, timeout |\n| **Add custom trace sources** | Capture domain-specific spans |\n\n---\n\n## Resources\n\n- **Aspire Service Defaults**: https://learn.microsoft.com/en-us/dotnet/aspire/fundamentals/service-defaults\n- **OpenTelemetry .NET**: https://opentelemetry.io/docs/languages/net/\n- **Health Checks**: https://learn.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks\n",
        "skills/aspnetcore/transactional-emails/SKILL.md": "---\nname: transactional-emails\ndescription: Build transactional emails using MJML templates with variable substitution. Render responsive HTML that works across email clients. Test with Mailpit/Mailhog in development via Aspire.\n---\n\n# Transactional Emails with MJML\n\n## When to Use This Skill\n\nUse this skill when:\n- Building transactional emails (signup, password reset, invoices, notifications)\n- Creating responsive email templates that work across clients\n- Setting up email testing infrastructure in development\n- Implementing email preview/approval workflows\n\n---\n\n## Why MJML?\n\n**Problem**: Email HTML is notoriously difficult. Each email client (Outlook, Gmail, Apple Mail) renders differently, requiring complex table-based layouts and inline styles.\n\n**Solution**: [MJML](https://mjml.io/) is a markup language that compiles to responsive, cross-client HTML:\n\n```mjml\n<!-- MJML - simple and readable -->\n<mj-section>\n  <mj-column>\n    <mj-text>Hello {{UserName}}</mj-text>\n    <mj-button href=\"{{ActionUrl}}\">Click Here</mj-button>\n  </mj-column>\n</mj-section>\n```\n\nCompiles to ~200 lines of table-based HTML with inline styles that works everywhere.\n\n---\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Email Flow                                │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│  MJML Template    ──►  Mjml.Net Renderer  ──►  HTML Email   │\n│  (embedded resource)      (compile-time)       (rendered)   │\n│        │                                           │        │\n│        │                                           ▼        │\n│        │                               ┌───────────────────┐│\n│        └──────────────────────────────►│   SMTP Gateway    ││\n│           Variable substitution        │  - Production     ││\n│           {{UserName}}, {{Link}}       │  - Mailpit (dev)  ││\n│                                        └───────────────────┘│\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Project Structure\n\n```\nsrc/\n  Infrastructure/\n    MyApp.Infrastructure.Mailing/\n      Templates/\n        _Layout.mjml              # Shared layout (header, footer)\n        UserInvitations/\n          UserSignupInvitation.mjml\n          InvitationExpired.mjml\n        PasswordReset/\n          PasswordReset.mjml\n        Billing/\n          PaymentReceipt.mjml\n          RenewalReminder.mjml\n      Mjml/\n        IMjmlTemplateRenderer.cs\n        MjmlTemplateRenderer.cs\n        MjmlEmailMessage.cs\n      Composers/\n        IUserEmailComposer.cs\n        UserEmailComposer.cs\n      MyApp.Infrastructure.Mailing.csproj\n```\n\n---\n\n## Installation\n\n### Add Mjml.Net\n\n```bash\ndotnet add package Mjml.Net\n```\n\n### Embed Templates as Resources\n\nIn your `.csproj`:\n\n```xml\n<ItemGroup>\n  <EmbeddedResource Include=\"Templates\\**\\*.mjml\" />\n</ItemGroup>\n```\n\n---\n\n## Template Structure\n\n### Layout Template (_Layout.mjml)\n\n```mjml\n<mjml>\n  <mj-head>\n    <mj-title>MyApp</mj-title>\n    <mj-preview>{{PreviewText}}</mj-preview>\n    <mj-attributes>\n      <mj-all font-family=\"'Helvetica Neue', Helvetica, Arial, sans-serif\" />\n      <mj-text font-size=\"14px\" color=\"#555555\" line-height=\"20px\" />\n      <mj-section padding=\"20px\" />\n    </mj-attributes>\n    <mj-style inline=\"inline\">\n      a { color: #2563eb; text-decoration: none; }\n      a:hover { text-decoration: underline; }\n    </mj-style>\n  </mj-head>\n  <mj-body background-color=\"#f3f4f6\">\n    <!-- Header -->\n    <mj-section background-color=\"#ffffff\" padding-bottom=\"0\">\n      <mj-column>\n        <mj-image\n          src=\"https://myapp.com/logo.png\"\n          alt=\"MyApp\"\n          width=\"150px\"\n          href=\"{{SiteUrl}}\"\n          padding=\"30px 25px 20px 25px\" />\n      </mj-column>\n    </mj-section>\n\n    <!-- Content injected here -->\n    <mj-section background-color=\"#ffffff\" padding-top=\"20px\" padding-bottom=\"40px\">\n      <mj-column>\n        {{Content}}\n      </mj-column>\n    </mj-section>\n\n    <!-- Footer -->\n    <mj-section background-color=\"#f9fafb\" padding=\"20px 25px\">\n      <mj-column>\n        <mj-text align=\"center\" font-size=\"12px\" color=\"#9ca3af\">\n          &copy; 2025 MyApp Inc. All rights reserved.\n        </mj-text>\n      </mj-column>\n    </mj-section>\n  </mj-body>\n</mjml>\n```\n\n### Content Template\n\n```mjml\n<!-- UserInvitations/UserSignupInvitation.mjml -->\n<!-- Wrapped in _Layout.mjml automatically -->\n\n<mj-text font-size=\"16px\" color=\"#111827\" font-weight=\"600\" padding-bottom=\"20px\">\n  You've been invited to join {{OrganizationName}}\n</mj-text>\n\n<mj-text padding-bottom=\"15px\">\n  Hi {{InviteeName}},\n</mj-text>\n\n<mj-text padding-bottom=\"15px\">\n  {{InviterName}} has invited you to join <strong>{{OrganizationName}}</strong>.\n</mj-text>\n\n<mj-text padding-bottom=\"25px\">\n  Click the button below to accept your invitation:\n</mj-text>\n\n<mj-button background-color=\"#2563eb\" color=\"#ffffff\" font-size=\"16px\" href=\"{{InvitationLink}}\">\n  Accept Invitation\n</mj-button>\n\n<mj-text padding-top=\"25px\" font-size=\"13px\" color=\"#6b7280\">\n  This invitation expires on {{ExpirationDate}}.\n</mj-text>\n```\n\n---\n\n## Template Renderer\n\n```csharp\npublic interface IMjmlTemplateRenderer\n{\n    Task<string> RenderTemplateAsync(\n        string templateName,\n        IReadOnlyDictionary<string, string> variables,\n        CancellationToken ct = default);\n}\n\npublic sealed partial class MjmlTemplateRenderer : IMjmlTemplateRenderer\n{\n    private readonly MjmlRenderer _mjmlRenderer = new();\n    private readonly Assembly _assembly;\n    private readonly string _siteUrl;\n\n    public MjmlTemplateRenderer(IConfiguration config)\n    {\n        _assembly = typeof(MjmlTemplateRenderer).Assembly;\n        _siteUrl = config[\"SiteUrl\"] ?? \"https://myapp.com\";\n    }\n\n    public async Task<string> RenderTemplateAsync(\n        string templateName,\n        IReadOnlyDictionary<string, string> variables,\n        CancellationToken ct = default)\n    {\n        // Load content template\n        var contentMjml = await LoadTemplateAsync(templateName, ct);\n\n        // Load layout and inject content\n        var layoutMjml = await LoadTemplateAsync(\"_Layout\", ct);\n        var combinedMjml = layoutMjml.Replace(\"{{Content}}\", contentMjml);\n\n        // Merge variables (layout + template-specific)\n        var allVariables = new Dictionary<string, string>\n        {\n            { \"SiteUrl\", _siteUrl }\n        };\n        foreach (var kvp in variables)\n            allVariables[kvp.Key] = kvp.Value;\n\n        // Substitute variables\n        var processedMjml = SubstituteVariables(combinedMjml, allVariables);\n\n        // Compile to HTML\n        var result = await _mjmlRenderer.RenderAsync(processedMjml, null, ct);\n\n        if (result.Errors.Any())\n            throw new InvalidOperationException(\n                $\"MJML compilation failed: {string.Join(\", \", result.Errors.Select(e => e.Error))}\");\n\n        return result.Html;\n    }\n\n    private async Task<string> LoadTemplateAsync(string templateName, CancellationToken ct)\n    {\n        var resourceName = $\"MyApp.Infrastructure.Mailing.Templates.{templateName.Replace('/', '.')}.mjml\";\n\n        await using var stream = _assembly.GetManifestResourceStream(resourceName)\n            ?? throw new FileNotFoundException($\"Template '{templateName}' not found\");\n\n        using var reader = new StreamReader(stream);\n        return await reader.ReadToEndAsync(ct);\n    }\n\n    private static string SubstituteVariables(string mjml, IReadOnlyDictionary<string, string> variables)\n    {\n        return VariableRegex().Replace(mjml, match =>\n        {\n            var name = match.Groups[1].Value;\n            return variables.TryGetValue(name, out var value) ? value : match.Value;\n        });\n    }\n\n    [GeneratedRegex(@\"\\{\\{([^}]+)\\}\\}\", RegexOptions.Compiled)]\n    private static partial Regex VariableRegex();\n}\n```\n\n---\n\n## Email Composer Pattern\n\nSeparate template rendering from email composition:\n\n```csharp\npublic interface IUserEmailComposer\n{\n    Task<EmailMessage> ComposeSignupInvitationAsync(\n        EmailAddress recipientEmail,\n        PersonName recipientName,\n        PersonName inviterName,\n        OrganizationName organizationName,\n        AbsoluteUri invitationUrl,\n        DateTimeOffset expiresAt,\n        CancellationToken ct = default);\n}\n\npublic sealed class UserEmailComposer : IUserEmailComposer\n{\n    private readonly IMjmlTemplateRenderer _renderer;\n\n    public UserEmailComposer(IMjmlTemplateRenderer renderer)\n    {\n        _renderer = renderer;\n    }\n\n    public async Task<EmailMessage> ComposeSignupInvitationAsync(\n        EmailAddress recipientEmail,\n        PersonName recipientName,\n        PersonName inviterName,\n        OrganizationName organizationName,\n        AbsoluteUri invitationUrl,\n        DateTimeOffset expiresAt,\n        CancellationToken ct = default)\n    {\n        var variables = new Dictionary<string, string>\n        {\n            { \"PreviewText\", $\"You've been invited to join {organizationName.Value}\" },\n            { \"InviteeName\", recipientName.Value },\n            { \"InviterName\", inviterName.Value },\n            { \"OrganizationName\", organizationName.Value },\n            { \"InvitationLink\", invitationUrl.ToString() },\n            { \"ExpirationDate\", expiresAt.ToString(\"MMMM d, yyyy\") }\n        };\n\n        var html = await _renderer.RenderTemplateAsync(\n            \"UserInvitations/UserSignupInvitation\",\n            variables,\n            ct);\n\n        return new EmailMessage(\n            To: recipientEmail,\n            Subject: $\"You've been invited to join {organizationName.Value}\",\n            HtmlBody: html);\n    }\n}\n```\n\n---\n\n## Development Testing with Mailpit\n\nUse Mailpit (or Mailhog) to capture emails locally without sending them.\n\n### Aspire Integration\n\nSee `aspire/integration-testing` skill for full Aspire setup. Add Mailpit:\n\n```csharp\n// AppHost/Program.cs\nvar mailpit = builder.AddContainer(\"mailpit\", \"axllent/mailpit\")\n    .WithHttpEndpoint(port: 8025, targetPort: 8025, name: \"ui\")\n    .WithEndpoint(port: 1025, targetPort: 1025, name: \"smtp\");\n\nvar api = builder.AddProject<Projects.MyApp_Api>(\"api\")\n    .WithReference(mailpit.GetEndpoint(\"smtp\"))\n    .WithEnvironment(\"Smtp__Host\", mailpit.GetEndpoint(\"smtp\"));\n```\n\n### Configure SMTP Client\n\n```csharp\n// In development, use Mailpit\nservices.AddSingleton<IEmailSender>(sp =>\n{\n    var config = sp.GetRequiredService<IConfiguration>();\n    var host = config[\"Smtp:Host\"] ?? \"localhost\";\n    var port = int.Parse(config[\"Smtp:Port\"] ?? \"1025\");\n\n    return new SmtpEmailSender(host, port);\n});\n```\n\n### View Captured Emails\n\nNavigate to `http://localhost:8025` to see all captured emails with:\n- Full HTML rendering\n- Source view\n- Headers inspection\n- Attachment handling\n\n---\n\n## Snapshot Testing Emails\n\nUse Verify to catch template regressions (see `testing/snapshot-testing` skill):\n\n```csharp\n[Fact]\npublic async Task UserSignupInvitation_RendersCorrectly()\n{\n    var renderer = _services.GetRequiredService<IMjmlTemplateRenderer>();\n\n    var variables = new Dictionary<string, string>\n    {\n        { \"PreviewText\", \"You've been invited to join Acme Corp\" },\n        { \"OrganizationName\", \"Acme Corporation\" },\n        { \"InviteeName\", \"John Doe\" },\n        { \"InviterName\", \"Jane Admin\" },\n        { \"InvitationLink\", \"https://example.com/invite/abc123\" },\n        { \"ExpirationDate\", \"December 31, 2025\" }\n    };\n\n    var html = await renderer.RenderTemplateAsync(\n        \"UserInvitations/UserSignupInvitation\",\n        variables);\n\n    await Verify(html, extension: \"html\");\n}\n```\n\nCreates `UserSignupInvitation_RendersCorrectly.verified.html` - review in browser or diff tool.\n\n---\n\n## Email Preview Endpoint\n\nAdd an admin endpoint to preview emails during development:\n\n```csharp\napp.MapGet(\"/admin/emails/preview/{template}\", async (\n    string template,\n    IMjmlTemplateRenderer renderer) =>\n{\n    var sampleVariables = GetSampleVariables(template);\n    var html = await renderer.RenderTemplateAsync(template, sampleVariables);\n\n    return Results.Content(html, \"text/html\");\n})\n.RequireAuthorization(\"AdminOnly\");\n```\n\n---\n\n## Best Practices\n\n### Template Design\n\n```mjml\n<!-- DO: Use MJML components for layout -->\n<mj-section>\n  <mj-column>\n    <mj-text>Content</mj-text>\n  </mj-column>\n</mj-section>\n\n<!-- DON'T: Use raw HTML tables -->\n<table><tr><td>Content</td></tr></table>\n\n<!-- DO: Use production URLs for images -->\n<mj-image src=\"https://myapp.com/logo.png\" />\n\n<!-- DON'T: Use relative paths -->\n<mj-image src=\"/img/logo.png\" />\n```\n\n### Variable Handling\n\n```csharp\n// DO: Use strongly-typed value objects\nTask<EmailMessage> ComposeAsync(\n    EmailAddress to,\n    PersonName name,\n    AbsoluteUri actionUrl);\n\n// DON'T: Use raw strings\nTask<EmailMessage> ComposeAsync(\n    string email,\n    string name,\n    string url);\n```\n\n### Testing\n\n```csharp\n// DO: Test each template variant\n[Fact] Task WelcomeEmail_NewUser_RendersCorrectly()\n[Fact] Task WelcomeEmail_InvitedUser_RendersCorrectly()\n\n// DO: Use Mailpit in integration tests\n// DO: Snapshot test rendered HTML\n\n// DON'T: Skip email testing\n// DON'T: Only test in production\n```\n\n---\n\n## MJML Components Reference\n\n| Component | Purpose |\n|-----------|---------|\n| `<mj-section>` | Horizontal container (like a row) |\n| `<mj-column>` | Vertical container within section |\n| `<mj-text>` | Text content with styling |\n| `<mj-button>` | Call-to-action button |\n| `<mj-image>` | Responsive image |\n| `<mj-divider>` | Horizontal line |\n| `<mj-spacer>` | Vertical spacing |\n| `<mj-table>` | Data tables |\n| `<mj-social>` | Social media icons |\n\n---\n\n## Resources\n\n- **MJML Documentation**: https://documentation.mjml.io/\n- **MJML Playground**: https://mjml.io/try-it-live\n- **Mjml.Net**: https://github.com/ArtZab/Mjml.Net\n- **Mailpit**: https://github.com/axllent/mailpit\n- **Email on Acid** (testing): https://www.emailonacid.com/\n",
        "skills/csharp/api-design/SKILL.md": "---\nname: api-design\ndescription: Design stable, compatible public APIs using extend-only design principles. Manage API compatibility, wire compatibility, and versioning for NuGet packages and distributed systems.\n---\n\n# Public API Design and Compatibility\n\n## When to Use This Skill\n\nUse this skill when:\n- Designing public APIs for NuGet packages or libraries\n- Making changes to existing public APIs\n- Planning wire format changes for distributed systems\n- Implementing versioning strategies\n- Reviewing pull requests for breaking changes\n\n---\n\n## The Three Types of Compatibility\n\n| Type | Definition | Scope |\n|------|------------|-------|\n| **API/Source** | Code compiles against newer version | Public method signatures, types |\n| **Binary** | Compiled code runs against newer version | Assembly layout, method tokens |\n| **Wire** | Serialized data readable by other versions | Network protocols, persistence formats |\n\nBreaking any of these creates upgrade friction for users.\n\n---\n\n## Extend-Only Design\n\nThe foundation of stable APIs: **never remove or modify, only extend**.\n\n### Three Pillars\n\n1. **Previous functionality is immutable** - Once released, behavior and signatures are locked\n2. **New functionality through new constructs** - Add overloads, new types, opt-in features\n3. **Removal only after deprecation period** - Years, not releases\n\n### Benefits\n\n- Old code continues working in new versions\n- New and old pathways coexist\n- Upgrades are non-breaking by default\n- Users upgrade on their schedule\n\n**Resources:**\n- [Extend-Only Design](https://aaronstannard.com/extend-only-design/)\n- [OSS Compatibility Standards](https://aaronstannard.com/oss-compatibility-standards/)\n\n---\n\n## API Change Guidelines\n\n### Safe Changes (Any Release)\n\n```csharp\n// ADD new overloads with default parameters\npublic void Process(Order order, CancellationToken ct = default);\n\n// ADD new optional parameters to existing methods\npublic void Send(Message msg, Priority priority = Priority.Normal);\n\n// ADD new types, interfaces, enums\npublic interface IOrderValidator { }\npublic enum OrderStatus { Pending, Complete, Cancelled }\n\n// ADD new members to existing types\npublic class Order\n{\n    public DateTimeOffset? ShippedAt { get; init; }  // NEW\n}\n```\n\n### Unsafe Changes (Never or Major Version Only)\n\n```csharp\n// REMOVE or RENAME public members\npublic void ProcessOrder(Order order);  // Was: Process()\n\n// CHANGE parameter types or order\npublic void Process(int orderId);  // Was: Process(Order order)\n\n// CHANGE return types\npublic Order? GetOrder(string id);  // Was: public Order GetOrder()\n\n// CHANGE access modifiers\ninternal class OrderProcessor { }  // Was: public\n\n// ADD required parameters without defaults\npublic void Process(Order order, ILogger logger);  // Breaks callers!\n```\n\n### Deprecation Pattern\n\n```csharp\n// Step 1: Mark as obsolete with version (any release)\n[Obsolete(\"Obsolete since v1.5.0. Use ProcessAsync instead.\")]\npublic void Process(Order order) { }\n\n// Step 2: Add new recommended API (same release)\npublic Task ProcessAsync(Order order, CancellationToken ct = default);\n\n// Step 3: Remove in next major version (v2.0+)\n// Only after users have had time to migrate\n```\n\n---\n\n## API Approval Testing\n\nPrevent accidental breaking changes with automated API surface testing.\n\n### Using ApiApprover + Verify\n\n```bash\ndotnet add package PublicApiGenerator\ndotnet add package Verify.Xunit\n```\n\n```csharp\n[Fact]\npublic Task ApprovePublicApi()\n{\n    var api = typeof(MyLibrary.PublicClass).Assembly.GeneratePublicApi();\n    return Verify(api);\n}\n```\n\nCreates `ApprovePublicApi.verified.txt`:\n\n```csharp\nnamespace MyLibrary\n{\n    public class OrderProcessor\n    {\n        public OrderProcessor() { }\n        public void Process(Order order) { }\n        public Task ProcessAsync(Order order, CancellationToken ct = default) { }\n    }\n}\n```\n\n**Any API change fails the test** - reviewer must explicitly approve changes.\n\n### PR Review Process\n\n1. PR includes changes to `*.verified.txt` files\n2. Reviewers see exact API surface changes in diff\n3. Breaking changes are immediately visible\n4. Conscious decision required to approve\n\n---\n\n## Wire Compatibility\n\nFor distributed systems, serialized data must be readable across versions.\n\n### Requirements\n\n| Direction | Requirement |\n|-----------|-------------|\n| **Backward** | Old writers → New readers (current version reads old data) |\n| **Forward** | New writers → Old readers (old version reads new data) |\n\nBoth are required for zero-downtime rolling upgrades.\n\n### Safely Evolving Wire Formats\n\n**Phase 1: Add read-side support (opt-in)**\n\n```csharp\n// New message type - readers deployed first\npublic sealed record HeartbeatV2(\n    Address From,\n    long SequenceNr,\n    long CreationTimeMs);  // NEW field\n\n// Deserializer handles both old and new\npublic object Deserialize(byte[] data, string manifest) => manifest switch\n{\n    \"Heartbeat\" => DeserializeHeartbeatV1(data),   // Old format\n    \"HeartbeatV2\" => DeserializeHeartbeatV2(data), // New format\n    _ => throw new NotSupportedException()\n};\n```\n\n**Phase 2: Enable write-side (opt-out, next minor version)**\n\n```csharp\n// Config to enable new format (off by default initially)\nakka.cluster.use-heartbeat-v2 = on\n```\n\n**Phase 3: Make default (future version)**\n\nAfter install base has absorbed read-side code.\n\n### Schema-Based Serialization\n\nPrefer schema-based formats over reflection-based:\n\n| Format | Type | Wire Compatibility |\n|--------|------|-------------------|\n| **Protocol Buffers** | Schema-based | Excellent - explicit field numbers |\n| **MessagePack** | Schema-based | Good - with contracts |\n| **System.Text.Json** | Schema-based (with source gen) | Good - explicit properties |\n| Newtonsoft.Json | Reflection-based | Poor - type names in payload |\n| BinaryFormatter | Reflection-based | Terrible - never use |\n\nSee `dotnet/serialization` skill for details.\n\n---\n\n## Encapsulation Patterns\n\n### Internal APIs\n\nMark non-public APIs explicitly:\n\n```csharp\n// Attribute for documentation\n[InternalApi]\npublic class ActorSystemImpl { }\n\n// Namespace convention\nnamespace MyLibrary.Internal\n{\n    public class InternalHelper { }  // Public for extensibility, not for users\n}\n```\n\nDocument clearly:\n\n> Types in `.Internal` namespaces or marked with `[InternalApi]` may change between any releases without notice.\n\n### Sealing Classes\n\n```csharp\n// DO: Seal classes not designed for inheritance\npublic sealed class OrderProcessor { }\n\n// DON'T: Leave unsealed by accident\npublic class OrderProcessor { }  // Users might inherit, blocking changes\n```\n\n### Interface Segregation\n\n```csharp\n// DO: Small, focused interfaces\npublic interface IOrderReader\n{\n    Order? GetById(OrderId id);\n}\n\npublic interface IOrderWriter\n{\n    Task SaveAsync(Order order);\n}\n\n// DON'T: Monolithic interfaces (can't add methods without breaking)\npublic interface IOrderRepository\n{\n    Order? GetById(OrderId id);\n    Task SaveAsync(Order order);\n    // Adding new methods breaks all implementations!\n}\n```\n\n---\n\n## Versioning Strategy\n\n### Semantic Versioning (Practical)\n\n| Version | Changes Allowed |\n|---------|----------------|\n| **Patch** (1.0.x) | Bug fixes, security patches |\n| **Minor** (1.x.0) | New features, deprecations, obsolete removal |\n| **Major** (x.0.0) | Breaking changes, old API removal |\n\n### Key Principles\n\n1. **No surprise breaks** - Even major versions should be announced and planned\n2. **Extensions anytime** - New APIs can ship in any release\n3. **Deprecate before remove** - `[Obsolete]` for at least one minor version\n4. **Communicate timelines** - Users need to plan upgrades\n\n### Chesterton's Fence\n\n> Before removing or changing something, understand why it exists.\n\nAssume every public API is used by someone. If you want to change it:\n1. Socialize the proposal on GitHub\n2. Document migration path\n3. Provide deprecation period\n4. Ship in planned release\n\n---\n\n## Pull Request Checklist\n\nWhen reviewing PRs that touch public APIs:\n\n- [ ] **No removed public members** (use `[Obsolete]` instead)\n- [ ] **No changed signatures** (add overloads instead)\n- [ ] **No new required parameters** (use defaults)\n- [ ] **API approval test updated** (`.verified.txt` changes reviewed)\n- [ ] **Wire format changes are opt-in** (read-side first)\n- [ ] **Breaking changes documented** (release notes, migration guide)\n\n---\n\n## Anti-Patterns\n\n### Breaking Changes Disguised as Fixes\n\n```csharp\n// \"Bug fix\" that breaks users\npublic async Task<Order> GetOrderAsync(OrderId id)  // Was sync!\n{\n    // \"Fixed\" to be async - but breaks all callers\n}\n\n// Correct: Add new method, deprecate old\n[Obsolete(\"Use GetOrderAsync instead\")]\npublic Order GetOrder(OrderId id) => GetOrderAsync(id).Result;\n\npublic async Task<Order> GetOrderAsync(OrderId id) { }\n```\n\n### Silent Behavior Changes\n\n```csharp\n// Changing defaults breaks users who relied on old behavior\npublic void Configure(bool enableCaching = true)  // Was: false!\n\n// Correct: New parameter with new name\npublic void Configure(\n    bool enableCaching = false,  // Original default preserved\n    bool enableNewCaching = true)  // New behavior opt-in\n```\n\n### Polymorphic Serialization\n\n```csharp\n// AVOID: Type names in wire format\n{ \"$type\": \"MyApp.Order, MyApp\", \"Id\": 123 }\n\n// Renaming Order class = wire break!\n\n// PREFER: Explicit discriminators\n{ \"type\": \"order\", \"id\": 123 }\n```\n\n---\n\n## Resources\n\n- [Making Public API Changes](https://getakka.net/community/contributing/api-changes-compatibility.html)\n- [Wire Format Changes](https://getakka.net/community/contributing/wire-compatibility.html)\n- [Extend-Only Design](https://aaronstannard.com/extend-only-design/)\n- [OSS Compatibility Standards](https://aaronstannard.com/oss-compatibility-standards/)\n- [Semantic Versioning](https://semver.org/)\n- [PublicApiGenerator](https://github.com/PublicApiGenerator/PublicApiGenerator)\n",
        "skills/csharp/coding-standards/SKILL.md": "---\nname: modern-csharp-coding-standards\ndescription: Write modern, high-performance C# code using records, pattern matching, value objects, async/await, Span<T>/Memory<T>, and best-practice API design patterns. Emphasizes functional-style programming with C# 12+ features.\n---\n\n# Modern C# Coding Standards\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing new C# code or refactoring existing code\n- Designing public APIs for libraries or services\n- Optimizing performance-critical code paths\n- Implementing domain models with strong typing\n- Building async/await-heavy applications\n- Working with binary data, buffers, or high-throughput scenarios\n\n## Core Principles\n\n1. **Immutability by Default** - Use `record` types and `init`-only properties\n2. **Type Safety** - Leverage nullable reference types and value objects\n3. **Modern Pattern Matching** - Use `switch` expressions and patterns extensively\n4. **Async Everywhere** - Prefer async APIs with proper cancellation support\n5. **Zero-Allocation Patterns** - Use `Span<T>` and `Memory<T>` for performance-critical code\n6. **API Design** - Accept abstractions, return appropriately specific types\n7. **Composition Over Inheritance** - Avoid abstract base classes, prefer composition\n8. **Value Objects as Structs** - Use `readonly record struct` for value objects\n\n---\n\n## Language Patterns\n\n### Records for Immutable Data (C# 9+)\n\nUse `record` types for DTOs, messages, events, and domain entities.\n\n```csharp\n// Simple immutable DTO\npublic record CustomerDto(string Id, string Name, string Email);\n\n// Record with validation in constructor\npublic record EmailAddress\n{\n    public string Value { get; init; }\n\n    public EmailAddress(string value)\n    {\n        if (string.IsNullOrWhiteSpace(value) || !value.Contains('@'))\n            throw new ArgumentException(\"Invalid email address\", nameof(value));\n\n        Value = value;\n    }\n}\n\n// Record with computed properties\npublic record Order(string Id, decimal Subtotal, decimal Tax)\n{\n    public decimal Total => Subtotal + Tax;\n}\n\n// Records with collections - use IReadOnlyList\npublic record ShoppingCart(\n    string CartId,\n    string CustomerId,\n    IReadOnlyList<CartItem> Items\n)\n{\n    public decimal Total => Items.Sum(item => item.Price * item.Quantity);\n}\n```\n\n**When to use `record class` vs `record struct`:**\n- `record class` (default): Reference types, use for entities, aggregates, DTOs with multiple properties\n- `record struct`: Value types, use for value objects (see next section)\n\n---\n\n### Value Objects as readonly record struct\n\nValue objects should **always be `readonly record struct`** for performance and value semantics.\n\n```csharp\n// Single-value object\npublic readonly record struct OrderId(string Value)\n{\n    public OrderId(string value) : this(\n        !string.IsNullOrWhiteSpace(value)\n            ? value\n            : throw new ArgumentException(\"OrderId cannot be empty\", nameof(value)))\n    {\n    }\n\n    public override string ToString() => Value;\n\n    // NO implicit conversions - defeats type safety!\n    // Access inner value explicitly: orderId.Value\n}\n\n// Multi-value object\npublic readonly record struct Money(decimal Amount, string Currency)\n{\n    public Money(decimal amount, string currency) : this(\n        amount >= 0 ? amount : throw new ArgumentException(\"Amount cannot be negative\", nameof(amount)),\n        ValidateCurrency(currency))\n    {\n    }\n\n    private static string ValidateCurrency(string currency)\n    {\n        if (string.IsNullOrWhiteSpace(currency) || currency.Length != 3)\n            throw new ArgumentException(\"Currency must be a 3-letter code\", nameof(currency));\n        return currency.ToUpperInvariant();\n    }\n\n    public Money Add(Money other)\n    {\n        if (Currency != other.Currency)\n            throw new InvalidOperationException($\"Cannot add {Currency} to {other.Currency}\");\n\n        return new Money(Amount + other.Amount, Currency);\n    }\n\n    public override string ToString() => $\"{Amount:N2} {Currency}\";\n}\n\n// Complex value object with factory pattern\npublic readonly record struct PhoneNumber\n{\n    public string Value { get; }\n\n    private PhoneNumber(string value) => Value = value;\n\n    public static Result<PhoneNumber, string> Create(string input)\n    {\n        if (string.IsNullOrWhiteSpace(input))\n            return Result<PhoneNumber, string>.Failure(\"Phone number cannot be empty\");\n\n        // Normalize: remove all non-digits\n        var digits = new string(input.Where(char.IsDigit).ToArray());\n\n        if (digits.Length < 10 || digits.Length > 15)\n            return Result<PhoneNumber, string>.Failure(\"Phone number must be 10-15 digits\");\n\n        return Result<PhoneNumber, string>.Success(new PhoneNumber(digits));\n    }\n\n    public override string ToString() => Value;\n}\n\n// Percentage value object with range validation\npublic readonly record struct Percentage\n{\n    private readonly decimal _value;\n\n    public decimal Value => _value;\n\n    public Percentage(decimal value)\n    {\n        if (value < 0 || value > 100)\n            throw new ArgumentOutOfRangeException(nameof(value), \"Percentage must be between 0 and 100\");\n        _value = value;\n    }\n\n    public decimal AsDecimal() => _value / 100m;\n\n    public static Percentage FromDecimal(decimal decimalValue)\n    {\n        if (decimalValue < 0 || decimalValue > 1)\n            throw new ArgumentOutOfRangeException(nameof(decimalValue), \"Decimal must be between 0 and 1\");\n        return new Percentage(decimalValue * 100);\n    }\n\n    public override string ToString() => $\"{_value}%\";\n}\n\n// Strongly-typed ID\npublic readonly record struct CustomerId(Guid Value)\n{\n    public static CustomerId New() => new(Guid.NewGuid());\n    public override string ToString() => Value.ToString();\n}\n\n// Quantity with units\npublic readonly record struct Quantity(int Value, string Unit)\n{\n    public Quantity(int value, string unit) : this(\n        value >= 0 ? value : throw new ArgumentException(\"Quantity cannot be negative\"),\n        !string.IsNullOrWhiteSpace(unit) ? unit : throw new ArgumentException(\"Unit cannot be empty\"))\n    {\n    }\n\n    public override string ToString() => $\"{Value} {Unit}\";\n}\n```\n\n**Why `readonly record struct` for value objects:**\n- **Value semantics**: Equality based on content, not reference\n- **Stack allocation**: Better performance, no GC pressure\n- **Immutability**: `readonly` prevents accidental mutation\n- **Pattern matching**: Works seamlessly with switch expressions\n\n**CRITICAL: NO implicit conversions.** Implicit operators defeat the purpose of value objects by allowing silent type coercion:\n\n```csharp\n// WRONG - defeats compile-time safety:\npublic readonly record struct UserId(Guid Value)\n{\n    public static implicit operator UserId(Guid value) => new(value);  // NO!\n    public static implicit operator Guid(UserId value) => value.Value; // NO!\n}\n\n// With implicit operators, this compiles silently:\nvoid ProcessUser(UserId userId) { }\nProcessUser(Guid.NewGuid());  // Oops - meant to pass PostId\n\n// CORRECT - all conversions explicit:\npublic readonly record struct UserId(Guid Value)\n{\n    public static UserId New() => new(Guid.NewGuid());\n    // No implicit operators\n    // Create: new UserId(guid) or UserId.New()\n    // Extract: userId.Value\n}\n```\n\nExplicit conversions force every boundary crossing to be visible:\n\n```csharp\n// API boundary - explicit conversion IN\nvar userId = new UserId(request.UserId);  // Validates on entry\n\n// Database boundary - explicit conversion OUT\nawait _db.ExecuteAsync(sql, new { UserId = userId.Value });\n```\n\n---\n\n### Pattern Matching (C# 8-12)\n\nLeverage modern pattern matching for cleaner, more expressive code.\n\n```csharp\n// Switch expressions with value objects\npublic string GetPaymentMethodDescription(PaymentMethod payment) => payment switch\n{\n    { Type: PaymentType.CreditCard, Last4: var last4 } => $\"Credit card ending in {last4}\",\n    { Type: PaymentType.BankTransfer, AccountNumber: var account } => $\"Bank transfer from {account}\",\n    { Type: PaymentType.Cash } => \"Cash payment\",\n    _ => \"Unknown payment method\"\n};\n\n// Property patterns\npublic decimal CalculateDiscount(Order order) => order switch\n{\n    { Total: > 1000m } => order.Total * 0.15m,\n    { Total: > 500m } => order.Total * 0.10m,\n    { Total: > 100m } => order.Total * 0.05m,\n    _ => 0m\n};\n\n// Relational and logical patterns\npublic string ClassifyTemperature(int temp) => temp switch\n{\n    < 0 => \"Freezing\",\n    >= 0 and < 10 => \"Cold\",\n    >= 10 and < 20 => \"Cool\",\n    >= 20 and < 30 => \"Warm\",\n    >= 30 => \"Hot\",\n    _ => throw new ArgumentOutOfRangeException(nameof(temp))\n};\n\n// List patterns (C# 11+)\npublic bool IsValidSequence(int[] numbers) => numbers switch\n{\n    [] => false,                                      // Empty\n    [_] => true,                                      // Single element\n    [var first, .., var last] when first < last => true,  // First < last\n    _ => false\n};\n\n// Type patterns with null checks\npublic string FormatValue(object? value) => value switch\n{\n    null => \"null\",\n    string s => $\"\\\"{s}\\\"\",\n    int i => i.ToString(),\n    double d => d.ToString(\"F2\"),\n    DateTime dt => dt.ToString(\"yyyy-MM-dd\"),\n    Money m => m.ToString(),\n    IEnumerable<object> collection => $\"[{string.Join(\", \", collection)}]\",\n    _ => value.ToString() ?? \"unknown\"\n};\n\n// Combining patterns for complex logic\npublic record OrderState(bool IsPaid, bool IsShipped, bool IsCancelled);\n\npublic string GetOrderStatus(OrderState state) => state switch\n{\n    { IsCancelled: true } => \"Cancelled\",\n    { IsPaid: true, IsShipped: true } => \"Delivered\",\n    { IsPaid: true, IsShipped: false } => \"Processing\",\n    { IsPaid: false } => \"Awaiting Payment\",\n    _ => \"Unknown\"\n};\n\n// Pattern matching with value objects\npublic decimal CalculateShipping(Money total, Country destination) => (total, destination) switch\n{\n    ({ Amount: > 100m }, _) => 0m,                    // Free shipping over $100\n    (_, { Code: \"US\" or \"CA\" }) => 5m,                // North America\n    (_, { Code: \"GB\" or \"FR\" or \"DE\" }) => 10m,       // Europe\n    _ => 25m                                           // International\n};\n```\n\n---\n\n### Nullable Reference Types (C# 8+)\n\nEnable nullable reference types in your project and handle nulls explicitly.\n\n```csharp\n// In .csproj\n<PropertyGroup>\n    <Nullable>enable</Nullable>\n</PropertyGroup>\n\n// Explicit nullability\npublic class UserService\n{\n    // Non-nullable by default\n    public string GetUserName(User user) => user.Name;\n\n    // Explicitly nullable return\n    public string? FindUserName(string userId)\n    {\n        var user = _repository.Find(userId);\n        return user?.Name;  // Returns null if user not found\n    }\n\n    // Null-forgiving operator (use sparingly!)\n    public string GetRequiredConfigValue(string key)\n    {\n        var value = Configuration[key];\n        return value!;  // Only if you're CERTAIN it's not null\n    }\n\n    // Nullable value objects\n    public Money? GetAccountBalance(string accountId)\n    {\n        var account = _repository.Find(accountId);\n        return account?.Balance;\n    }\n}\n\n// Pattern matching with null checks\npublic decimal GetDiscount(Customer? customer) => customer switch\n{\n    null => 0m,\n    { IsVip: true } => 0.20m,\n    { OrderCount: > 10 } => 0.10m,\n    _ => 0.05m\n};\n\n// Null-coalescing patterns\npublic string GetDisplayName(User? user) =>\n    user?.PreferredName ?? user?.Email ?? \"Guest\";\n\n// Guard clauses with ArgumentNullException.ThrowIfNull (C# 11+)\npublic void ProcessOrder(Order? order)\n{\n    ArgumentNullException.ThrowIfNull(order);\n\n    // order is now non-nullable in this scope\n    Console.WriteLine(order.Id);\n}\n```\n\n---\n\n## Composition Over Inheritance\n\n**Avoid abstract base classes and inheritance hierarchies.** Use composition and interfaces instead.\n\n```csharp\n// ❌ BAD: Abstract base class hierarchy\npublic abstract class PaymentProcessor\n{\n    public abstract Task<PaymentResult> ProcessAsync(Money amount);\n\n    protected async Task<bool> ValidateAsync(Money amount)\n    {\n        // Shared validation logic\n        return amount.Amount > 0;\n    }\n}\n\npublic class CreditCardProcessor : PaymentProcessor\n{\n    public override async Task<PaymentResult> ProcessAsync(Money amount)\n    {\n        await ValidateAsync(amount);\n        // Process credit card...\n    }\n}\n\n// ✅ GOOD: Composition with interfaces\npublic interface IPaymentProcessor\n{\n    Task<PaymentResult> ProcessAsync(Money amount, CancellationToken cancellationToken);\n}\n\npublic interface IPaymentValidator\n{\n    Task<ValidationResult> ValidateAsync(Money amount, CancellationToken cancellationToken);\n}\n\n// Concrete implementations compose validators\npublic sealed class CreditCardProcessor : IPaymentProcessor\n{\n    private readonly IPaymentValidator _validator;\n    private readonly ICreditCardGateway _gateway;\n\n    public CreditCardProcessor(IPaymentValidator validator, ICreditCardGateway gateway)\n    {\n        _validator = validator;\n        _gateway = gateway;\n    }\n\n    public async Task<PaymentResult> ProcessAsync(Money amount, CancellationToken cancellationToken)\n    {\n        var validation = await _validator.ValidateAsync(amount, cancellationToken);\n        if (!validation.IsValid)\n            return PaymentResult.Failed(validation.Error);\n\n        return await _gateway.ChargeAsync(amount, cancellationToken);\n    }\n}\n\n// ✅ GOOD: Static helper classes for shared logic (no inheritance)\npublic static class PaymentValidation\n{\n    public static ValidationResult ValidateAmount(Money amount)\n    {\n        if (amount.Amount <= 0)\n            return ValidationResult.Invalid(\"Amount must be positive\");\n\n        if (amount.Amount > 10000m)\n            return ValidationResult.Invalid(\"Amount exceeds maximum\");\n\n        return ValidationResult.Valid();\n    }\n}\n\n// ✅ GOOD: Records for modeling variants (not inheritance)\npublic enum PaymentType { CreditCard, BankTransfer, Cash }\n\npublic record PaymentMethod\n{\n    public PaymentType Type { get; init; }\n    public string? Last4 { get; init; }           // For credit cards\n    public string? AccountNumber { get; init; }    // For bank transfers\n\n    public static PaymentMethod CreditCard(string last4) => new()\n    {\n        Type = PaymentType.CreditCard,\n        Last4 = last4\n    };\n\n    public static PaymentMethod BankTransfer(string accountNumber) => new()\n    {\n        Type = PaymentType.BankTransfer,\n        AccountNumber = accountNumber\n    };\n\n    public static PaymentMethod Cash() => new() { Type = PaymentType.Cash };\n}\n```\n\n**When inheritance is acceptable:**\n- Framework requirements (e.g., `ControllerBase` in ASP.NET Core)\n- Library integration (e.g., custom exceptions inheriting from `Exception`)\n- **These should be rare cases in your application code**\n\n---\n\n## Performance Patterns\n\n### Async/Await Best Practices\n\n**Always use async for I/O-bound operations:**\n\n```csharp\n// ✅ GOOD: Async all the way\npublic async Task<Order> GetOrderAsync(string orderId, CancellationToken cancellationToken)\n{\n    var order = await _repository.GetAsync(orderId, cancellationToken);\n    var customer = await _customerService.GetCustomerAsync(order.CustomerId, cancellationToken);\n    return order;\n}\n\n// ❌ BAD: Blocking on async code\npublic Order GetOrder(string orderId)\n{\n    return _repository.GetAsync(orderId).Result;  // DEADLOCK RISK!\n}\n\n// ✅ GOOD: ValueTask for frequently-called, often-synchronous methods\npublic ValueTask<Order?> GetCachedOrderAsync(string orderId, CancellationToken cancellationToken)\n{\n    if (_cache.TryGetValue(orderId, out var order))\n        return ValueTask.FromResult<Order?>(order);  // Synchronous path, no allocation\n\n    return GetFromDatabaseAsync(orderId, cancellationToken);  // Async path\n}\n\nprivate async ValueTask<Order?> GetFromDatabaseAsync(string orderId, CancellationToken cancellationToken)\n{\n    var order = await _repository.GetAsync(orderId, cancellationToken);\n    if (order is not null)\n        _cache[orderId] = order;\n    return order;\n}\n\n// ✅ GOOD: IAsyncEnumerable for streaming\npublic async IAsyncEnumerable<Order> StreamOrdersAsync(\n    string customerId,\n    [EnumeratorCancellation] CancellationToken cancellationToken = default)\n{\n    await foreach (var order in _repository.StreamAllAsync(cancellationToken))\n    {\n        if (order.CustomerId == customerId)\n            yield return order;\n    }\n}\n\n// ✅ GOOD: ConfigureAwait(false) in library code (not application code)\npublic async Task<string> ProcessDataAsync(string input, CancellationToken cancellationToken)\n{\n    var data = await FetchDataAsync(cancellationToken).ConfigureAwait(false);\n    var result = await TransformDataAsync(data, cancellationToken).ConfigureAwait(false);\n    return result;\n}\n```\n\n**Always accept CancellationToken:**\n\n```csharp\n// ✅ GOOD: CancellationToken parameter with default\npublic async Task<List<Order>> GetOrdersAsync(\n    string customerId,\n    CancellationToken cancellationToken = default)\n{\n    var orders = await _repository.GetOrdersByCustomerAsync(customerId, cancellationToken);\n    return orders;\n}\n\n// Pass cancellation through the call stack\npublic async Task<OrderSummary> GetOrderSummaryAsync(\n    string customerId,\n    CancellationToken cancellationToken = default)\n{\n    var orders = await GetOrdersAsync(customerId, cancellationToken);\n    var total = orders.Sum(o => o.Total);\n    return new OrderSummary(customerId, orders.Count, total);\n}\n\n// Link cancellation tokens when composing operations\npublic async Task<ProcessResult> ProcessWithTimeoutAsync(\n    string data,\n    TimeSpan timeout,\n    CancellationToken cancellationToken = default)\n{\n    using var cts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);\n    cts.CancelAfter(timeout);\n\n    return await ProcessAsync(data, cts.Token);\n}\n```\n\n---\n\n### Span<T> and Memory<T> for Zero-Allocation Code\n\nUse `Span<T>` and `Memory<T>` instead of `byte[]` or `string` for performance-critical code.\n\n```csharp\n// ✅ GOOD: Span<T> for synchronous, zero-allocation operations\npublic int ParseOrderId(ReadOnlySpan<char> input)\n{\n    // Work with data without allocations\n    if (!input.StartsWith(\"ORD-\"))\n        throw new FormatException(\"Invalid order ID format\");\n\n    var numberPart = input.Slice(4);\n    return int.Parse(numberPart);\n}\n\n// stackalloc with Span<T>\npublic void FormatMessage()\n{\n    Span<char> buffer = stackalloc char[256];\n    var written = FormatInto(buffer);\n    var message = new string(buffer.Slice(0, written));\n}\n\n// ✅ GOOD: Memory<T> for async operations (Span can't cross await)\npublic async Task<int> ReadDataAsync(\n    Memory<byte> buffer,\n    CancellationToken cancellationToken)\n{\n    return await _stream.ReadAsync(buffer, cancellationToken);\n}\n\n// ✅ GOOD: String manipulation with Span to avoid allocations\npublic bool TryParseKeyValue(ReadOnlySpan<char> line, out string key, out string value)\n{\n    key = string.Empty;\n    value = string.Empty;\n\n    int colonIndex = line.IndexOf(':');\n    if (colonIndex == -1)\n        return false;\n\n    // Only allocate strings once we know the format is valid\n    key = new string(line.Slice(0, colonIndex).Trim());\n    value = new string(line.Slice(colonIndex + 1).Trim());\n    return true;\n}\n\n// ✅ GOOD: ArrayPool for temporary large buffers\npublic async Task ProcessLargeFileAsync(\n    Stream stream,\n    CancellationToken cancellationToken)\n{\n    var buffer = ArrayPool<byte>.Shared.Rent(8192);\n    try\n    {\n        int bytesRead;\n        while ((bytesRead = await stream.ReadAsync(buffer.AsMemory(), cancellationToken)) > 0)\n        {\n            ProcessChunk(buffer.AsSpan(0, bytesRead));\n        }\n    }\n    finally\n    {\n        ArrayPool<byte>.Shared.Return(buffer);\n    }\n}\n\n// ✅ GOOD: Span-based parsing without substring allocations\npublic static (string Protocol, string Host, int Port) ParseUrl(ReadOnlySpan<char> url)\n{\n    var protocolEnd = url.IndexOf(\"://\");\n    var protocol = new string(url.Slice(0, protocolEnd));\n\n    var afterProtocol = url.Slice(protocolEnd + 3);\n    var portStart = afterProtocol.IndexOf(':');\n\n    var host = new string(afterProtocol.Slice(0, portStart));\n    var portSpan = afterProtocol.Slice(portStart + 1);\n    var port = int.Parse(portSpan);\n\n    return (protocol, host, port);\n}\n\n// ✅ GOOD: Writing data to Span\npublic bool TryFormatOrderId(int orderId, Span<char> destination, out int charsWritten)\n{\n    const string prefix = \"ORD-\";\n\n    if (destination.Length < prefix.Length + 10)\n    {\n        charsWritten = 0;\n        return false;\n    }\n\n    prefix.AsSpan().CopyTo(destination);\n    var numberWritten = orderId.TryFormat(\n        destination.Slice(prefix.Length),\n        out var numberChars);\n\n    charsWritten = prefix.Length + numberChars;\n    return numberWritten;\n}\n```\n\n**When to use what:**\n\n| Type | Use Case |\n|------|----------|\n| `Span<T>` | Synchronous operations, stack-allocated buffers, slicing without allocation |\n| `ReadOnlySpan<T>` | Read-only views, method parameters for data you won't modify |\n| `Memory<T>` | Async operations (Span can't cross await boundaries) |\n| `ReadOnlyMemory<T>` | Read-only async operations |\n| `byte[]` | When you need to store data long-term or pass to APIs requiring arrays |\n| `ArrayPool<T>` | Large temporary buffers (>1KB) to avoid GC pressure |\n\n---\n\n## API Design Principles\n\n### Accept Abstractions, Return Appropriately Specific\n\n**For Parameters (Accept):**\n\n```csharp\n// ✅ GOOD: Accept IEnumerable<T> if you only iterate once\npublic decimal CalculateTotal(IEnumerable<OrderItem> items)\n{\n    return items.Sum(item => item.Price * item.Quantity);\n}\n\n// ✅ GOOD: Accept IReadOnlyCollection<T> if you need Count\npublic bool HasMinimumItems(IReadOnlyCollection<OrderItem> items, int minimum)\n{\n    return items.Count >= minimum;\n}\n\n// ✅ GOOD: Accept IReadOnlyList<T> if you need indexing\npublic OrderItem GetMiddleItem(IReadOnlyList<OrderItem> items)\n{\n    if (items.Count == 0)\n        throw new ArgumentException(\"List cannot be empty\");\n\n    return items[items.Count / 2];  // Indexed access\n}\n\n// ✅ GOOD: Accept ReadOnlySpan<T> for high-performance, zero-allocation APIs\npublic int Sum(ReadOnlySpan<int> numbers)\n{\n    int total = 0;\n    foreach (var num in numbers)\n        total += num;\n    return total;\n}\n\n// ✅ GOOD: Accept IAsyncEnumerable<T> for async streaming\npublic async Task<int> CountItemsAsync(\n    IAsyncEnumerable<Order> orders,\n    CancellationToken cancellationToken)\n{\n    int count = 0;\n    await foreach (var order in orders.WithCancellation(cancellationToken))\n        count++;\n    return count;\n}\n```\n\n**For Return Types:**\n\n```csharp\n// ✅ GOOD: Return IEnumerable<T> for lazy/deferred execution\npublic IEnumerable<Order> GetOrdersLazy(string customerId)\n{\n    foreach (var order in _repository.Query())\n    {\n        if (order.CustomerId == customerId)\n            yield return order;  // Lazy evaluation\n    }\n}\n\n// ✅ GOOD: Return IReadOnlyList<T> for materialized, immutable collections\npublic IReadOnlyList<Order> GetOrders(string customerId)\n{\n    return _repository\n        .Query()\n        .Where(o => o.CustomerId == customerId)\n        .ToList();  // Materialized\n}\n\n// ✅ GOOD: Return concrete types when callers need mutation\npublic List<Order> GetMutableOrders(string customerId)\n{\n    // Explicitly allow mutation by returning List<T>\n    return _repository\n        .Query()\n        .Where(o => o.CustomerId == customerId)\n        .ToList();\n}\n\n// ✅ GOOD: Return IAsyncEnumerable<T> for async streaming\npublic async IAsyncEnumerable<Order> StreamOrdersAsync(\n    string customerId,\n    [EnumeratorCancellation] CancellationToken cancellationToken = default)\n{\n    await foreach (var order in _repository.StreamAllAsync(cancellationToken))\n    {\n        if (order.CustomerId == customerId)\n            yield return order;\n    }\n}\n\n// ✅ GOOD: Return arrays for interop or when caller expects array\npublic byte[] SerializeOrder(Order order)\n{\n    // Binary serialization - byte[] is appropriate here\n    return MessagePackSerializer.Serialize(order);\n}\n```\n\n**Summary Table:**\n\n| Scenario | Accept | Return |\n|----------|--------|--------|\n| Only iterate once | `IEnumerable<T>` | `IEnumerable<T>` (if lazy) |\n| Need count | `IReadOnlyCollection<T>` | `IReadOnlyCollection<T>` |\n| Need indexing | `IReadOnlyList<T>` | `IReadOnlyList<T>` |\n| High-performance, sync | `ReadOnlySpan<T>` | `Span<T>` (rarely) |\n| Async streaming | `IAsyncEnumerable<T>` | `IAsyncEnumerable<T>` |\n| Caller needs mutation | - | `List<T>`, `T[]` |\n\n---\n\n### Method Signatures Best Practices\n\n```csharp\n// ✅ GOOD: Complete async method signature\npublic async Task<Result<Order, OrderError>> CreateOrderAsync(\n    CreateOrderRequest request,\n    CancellationToken cancellationToken = default)\n{\n    // Implementation\n}\n\n// ✅ GOOD: Optional parameters at the end\npublic async Task<List<Order>> GetOrdersAsync(\n    string customerId,\n    DateTime? startDate = null,\n    DateTime? endDate = null,\n    CancellationToken cancellationToken = default)\n{\n    // Implementation\n}\n\n// ✅ GOOD: Use record for multiple related parameters\npublic record SearchOrdersRequest(\n    string? CustomerId,\n    DateTime? StartDate,\n    DateTime? EndDate,\n    OrderStatus? Status,\n    int PageSize = 20,\n    int PageNumber = 1\n);\n\npublic async Task<PagedResult<Order>> SearchOrdersAsync(\n    SearchOrdersRequest request,\n    CancellationToken cancellationToken = default)\n{\n    // Implementation\n}\n\n// ✅ GOOD: Primary constructors (C# 12+) for simple classes\npublic sealed class OrderService(IOrderRepository repository, ILogger<OrderService> logger)\n{\n    public async Task<Order> GetOrderAsync(OrderId orderId, CancellationToken cancellationToken)\n    {\n        logger.LogInformation(\"Fetching order {OrderId}\", orderId);\n        return await repository.GetAsync(orderId, cancellationToken);\n    }\n}\n\n// ✅ GOOD: Options pattern for complex configuration\npublic sealed class EmailServiceOptions\n{\n    public required string SmtpHost { get; init; }\n    public int SmtpPort { get; init; } = 587;\n    public bool UseSsl { get; init; } = true;\n    public TimeSpan Timeout { get; init; } = TimeSpan.FromSeconds(30);\n}\n\npublic sealed class EmailService(IOptions<EmailServiceOptions> options)\n{\n    private readonly EmailServiceOptions _options = options.Value;\n}\n```\n\n---\n\n## Error Handling\n\n### Result Type Pattern (Railway-Oriented Programming)\n\nFor expected errors, use a `Result<T, TError>` type instead of exceptions.\n\n```csharp\n// Simple Result type as readonly record struct\npublic readonly record struct Result<TValue, TError>\n{\n    private readonly TValue? _value;\n    private readonly TError? _error;\n    private readonly bool _isSuccess;\n\n    private Result(TValue value)\n    {\n        _value = value;\n        _error = default;\n        _isSuccess = true;\n    }\n\n    private Result(TError error)\n    {\n        _value = default;\n        _error = error;\n        _isSuccess = false;\n    }\n\n    public bool IsSuccess => _isSuccess;\n    public bool IsFailure => !_isSuccess;\n\n    public TValue Value => _isSuccess\n        ? _value!\n        : throw new InvalidOperationException(\"Cannot access Value of a failed result\");\n\n    public TError Error => !_isSuccess\n        ? _error!\n        : throw new InvalidOperationException(\"Cannot access Error of a successful result\");\n\n    public static Result<TValue, TError> Success(TValue value) => new(value);\n    public static Result<TValue, TError> Failure(TError error) => new(error);\n\n    public Result<TOut, TError> Map<TOut>(Func<TValue, TOut> mapper)\n        => _isSuccess\n            ? Result<TOut, TError>.Success(mapper(_value!))\n            : Result<TOut, TError>.Failure(_error!);\n\n    public Result<TOut, TError> Bind<TOut>(Func<TValue, Result<TOut, TError>> binder)\n        => _isSuccess ? binder(_value!) : Result<TOut, TError>.Failure(_error!);\n\n    public TValue GetValueOr(TValue defaultValue)\n        => _isSuccess ? _value! : defaultValue;\n\n    public TResult Match<TResult>(\n        Func<TValue, TResult> onSuccess,\n        Func<TError, TResult> onFailure)\n        => _isSuccess ? onSuccess(_value!) : onFailure(_error!);\n}\n\n// Error type as readonly record struct\npublic readonly record struct OrderError(string Code, string Message);\n\n// Usage example\npublic sealed class OrderService(IOrderRepository repository)\n{\n    public async Task<Result<Order, OrderError>> CreateOrderAsync(\n        CreateOrderRequest request,\n        CancellationToken cancellationToken)\n    {\n        // Validate\n        var validationResult = ValidateRequest(request);\n        if (validationResult.IsFailure)\n            return Result<Order, OrderError>.Failure(validationResult.Error);\n\n        // Check inventory\n        var inventoryResult = await CheckInventoryAsync(request.Items, cancellationToken);\n        if (inventoryResult.IsFailure)\n            return Result<Order, OrderError>.Failure(inventoryResult.Error);\n\n        // Create order\n        var order = new Order(\n            OrderId.New(),\n            new CustomerId(request.CustomerId),\n            request.Items);\n\n        await repository.SaveAsync(order, cancellationToken);\n\n        return Result<Order, OrderError>.Success(order);\n    }\n\n    // Pattern matching on Result\n    public IActionResult MapToActionResult(Result<Order, OrderError> result)\n    {\n        return result.Match(\n            onSuccess: order => new OkObjectResult(order),\n            onFailure: error => error.Code switch\n            {\n                \"VALIDATION_ERROR\" => new BadRequestObjectResult(error.Message),\n                \"INSUFFICIENT_INVENTORY\" => new ConflictObjectResult(error.Message),\n                \"NOT_FOUND\" => new NotFoundObjectResult(error.Message),\n                _ => new ObjectResult(error.Message) { StatusCode = 500 }\n            }\n        );\n    }\n}\n```\n\n**When to use Result vs Exceptions:**\n- **Use Result**: Expected errors (validation, business rules, not found)\n- **Use Exceptions**: Unexpected errors (network failures, system errors, programming bugs)\n\n---\n\n## Testing Patterns\n\n```csharp\n// Use record for test data builders\npublic record OrderBuilder\n{\n    public OrderId Id { get; init; } = OrderId.New();\n    public CustomerId CustomerId { get; init; } = CustomerId.New();\n    public Money Total { get; init; } = new Money(100m, \"USD\");\n    public IReadOnlyList<OrderItem> Items { get; init; } = Array.Empty<OrderItem>();\n\n    public Order Build() => new(Id, CustomerId, Total, Items);\n}\n\n// Use 'with' expression for test variations\n[Fact]\npublic void CalculateDiscount_LargeOrder_AppliesCorrectDiscount()\n{\n    // Arrange\n    var baseOrder = new OrderBuilder().Build();\n    var largeOrder = baseOrder with\n    {\n        Total = new Money(1500m, \"USD\")\n    };\n\n    // Act\n    var discount = _service.CalculateDiscount(largeOrder);\n\n    // Assert\n    discount.Should().Be(new Money(225m, \"USD\")); // 15% of 1500\n}\n\n// Span-based testing\n[Theory]\n[InlineData(\"ORD-12345\", true)]\n[InlineData(\"INVALID\", false)]\npublic void TryParseOrderId_VariousInputs_ReturnsExpectedResult(\n    string input,\n    bool expected)\n{\n    // Act\n    var result = OrderIdParser.TryParse(input.AsSpan(), out var orderId);\n\n    // Assert\n    result.Should().Be(expected);\n}\n\n// Testing with value objects\n[Fact]\npublic void Money_Add_SameCurrency_ReturnsSum()\n{\n    // Arrange\n    var money1 = new Money(100m, \"USD\");\n    var money2 = new Money(50m, \"USD\");\n\n    // Act\n    var result = money1.Add(money2);\n\n    // Assert\n    result.Should().Be(new Money(150m, \"USD\"));\n}\n\n[Fact]\npublic void Money_Add_DifferentCurrency_ThrowsException()\n{\n    // Arrange\n    var usd = new Money(100m, \"USD\");\n    var eur = new Money(50m, \"EUR\");\n\n    // Act & Assert\n    var act = () => usd.Add(eur);\n    act.Should().Throw<InvalidOperationException>()\n        .WithMessage(\"*different currencies*\");\n}\n```\n\n---\n\n## Avoid Reflection-Based Metaprogramming\n\n**Prefer statically-typed, explicit code over reflection-based \"magic\" libraries.**\n\nReflection-based libraries like AutoMapper trade compile-time safety for convenience. When mappings break, you find out at runtime (or worse, in production) instead of at compile time.\n\n### Banned Libraries\n\n| Library | Problem |\n|---------|---------|\n| **AutoMapper** | Reflection magic, hidden mappings, runtime failures, hard to debug |\n| **Mapster** | Same issues as AutoMapper |\n| **ExpressMapper** | Same issues |\n\n### Why Reflection Mapping Fails\n\n```csharp\n// With AutoMapper - compiles fine, fails at runtime\npublic record UserDto(string Id, string Name, string Email);\npublic record UserEntity(Guid Id, string FullName, string EmailAddress);\n\n// This mapping silently produces garbage:\n// - Id: string vs Guid mismatch\n// - Name vs FullName: no match, null/default\n// - Email vs EmailAddress: no match, null/default\nvar dto = _mapper.Map<UserDto>(entity);  // Compiles! Breaks at runtime.\n```\n\n### Use Explicit Mapping Methods Instead\n\n```csharp\n// Extension method - compile-time checked, easy to find, easy to debug\npublic static class UserMappings\n{\n    public static UserDto ToDto(this UserEntity entity) => new(\n        Id: entity.Id.ToString(),\n        Name: entity.FullName,\n        Email: entity.EmailAddress);\n\n    public static UserEntity ToEntity(this CreateUserRequest request) => new(\n        Id: Guid.NewGuid(),\n        FullName: request.Name,\n        EmailAddress: request.Email);\n}\n\n// Usage - explicit and traceable\nvar dto = entity.ToDto();\nvar entity = request.ToEntity();\n```\n\n### Benefits of Explicit Mappings\n\n| Aspect | AutoMapper | Explicit Methods |\n|--------|------------|------------------|\n| **Compile-time safety** | No - runtime errors | Yes - compiler catches mismatches |\n| **Discoverability** | Hidden in profiles | \"Go to Definition\" works |\n| **Debugging** | Black box | Step through code |\n| **Refactoring** | Rename breaks silently | IDE renames correctly |\n| **Performance** | Reflection overhead | Direct property access |\n| **Testing** | Need integration tests | Simple unit tests |\n\n### Complex Mappings\n\nFor complex transformations, explicit code is even more valuable:\n\n```csharp\npublic static OrderSummaryDto ToSummary(this Order order) => new(\n    OrderId: order.Id.Value.ToString(),\n    CustomerName: order.Customer.FullName,\n    ItemCount: order.Items.Count,\n    Total: order.Items.Sum(i => i.Quantity * i.UnitPrice),\n    Status: order.Status switch\n    {\n        OrderStatus.Pending => \"Awaiting Payment\",\n        OrderStatus.Paid => \"Processing\",\n        OrderStatus.Shipped => \"On the Way\",\n        OrderStatus.Delivered => \"Completed\",\n        _ => \"Unknown\"\n    },\n    FormattedDate: order.CreatedAt.ToString(\"MMMM d, yyyy\"));\n```\n\nThis is:\n- **Readable**: Anyone can understand the transformation\n- **Debuggable**: Set a breakpoint, inspect values\n- **Testable**: Pass an Order, assert on the result\n- **Refactorable**: Change a property name, compiler tells you everywhere it's used\n\n### When Reflection is Acceptable\n\nReflection has legitimate uses, but mapping DTOs isn't one of them:\n\n| Use Case | Acceptable? |\n|----------|-------------|\n| Serialization (System.Text.Json, Newtonsoft) | Yes - well-tested, source generators available |\n| Dependency injection container | Yes - framework infrastructure |\n| ORM entity mapping (EF Core) | Yes - necessary for database abstraction |\n| Test fixtures and builders | Sometimes - for convenience in tests only |\n| **DTO/domain object mapping** | **No - use explicit methods** |\n\n### UnsafeAccessorAttribute (.NET 8+)\n\nWhen you genuinely need to access private or internal members (serializers, test helpers, framework code), use `UnsafeAccessorAttribute` instead of traditional reflection. It provides **zero-overhead, AOT-compatible** member access.\n\n```csharp\n// AVOID: Traditional reflection - slow, allocates, breaks AOT\nvar field = typeof(Order).GetField(\"_status\", BindingFlags.NonPublic | BindingFlags.Instance);\nvar status = (OrderStatus)field!.GetValue(order)!;\n\n// PREFER: UnsafeAccessor - zero overhead, AOT-compatible\n[UnsafeAccessor(UnsafeAccessorKind.Field, Name = \"_status\")]\nstatic extern ref OrderStatus GetStatusField(Order order);\n\nvar status = GetStatusField(order);  // Direct access, no reflection\n```\n\n**Supported accessor kinds:**\n\n```csharp\n// Private field access\n[UnsafeAccessor(UnsafeAccessorKind.Field, Name = \"_items\")]\nstatic extern ref List<OrderItem> GetItemsField(Order order);\n\n// Private method access\n[UnsafeAccessor(UnsafeAccessorKind.Method, Name = \"Recalculate\")]\nstatic extern void CallRecalculate(Order order);\n\n// Private static field\n[UnsafeAccessor(UnsafeAccessorKind.StaticField, Name = \"_instanceCount\")]\nstatic extern ref int GetInstanceCount(Order order);\n\n// Private constructor\n[UnsafeAccessor(UnsafeAccessorKind.Constructor)]\nstatic extern Order CreateOrder(OrderId id, CustomerId customerId);\n```\n\n**Why UnsafeAccessor over reflection:**\n\n| Aspect | Reflection | UnsafeAccessor |\n|--------|------------|----------------|\n| Performance | Slow (100-1000x) | Zero overhead |\n| AOT compatible | No | Yes |\n| Allocations | Yes (boxing, arrays) | None |\n| Compile-time checked | No | Partially (signature) |\n\n**Use cases:**\n- Serializers accessing private backing fields\n- Test helpers verifying internal state\n- Framework code that needs to bypass visibility\n\n**Resources:**\n- [A new way of doing reflection with .NET 8](https://steven-giesel.com/blogPost/05ecdd16-8dc4-490f-b1cf-780c994346a4)\n- [Accessing private members without reflection in .NET 8.0](https://www.strathweb.com/2023/10/accessing-private-members-without-reflection-in-net-8-0/)\n- [Modern .NET Reflection with UnsafeAccessor](https://blog.ndepend.com/modern-net-reflection-with-unsafeaccessor/)\n\n---\n\n## Anti-Patterns to Avoid\n\n### ❌ DON'T: Use mutable DTOs\n\n```csharp\n// BAD: Mutable DTO\npublic class CustomerDto\n{\n    public string Id { get; set; }\n    public string Name { get; set; }\n}\n\n// GOOD: Immutable record\npublic record CustomerDto(string Id, string Name);\n```\n\n### ❌ DON'T: Use classes for value objects\n\n```csharp\n// BAD: Value object as class\npublic class OrderId\n{\n    public string Value { get; }\n    public OrderId(string value) => Value = value;\n}\n\n// GOOD: Value object as readonly record struct\npublic readonly record struct OrderId(string Value);\n```\n\n### ❌ DON'T: Create deep inheritance hierarchies\n\n```csharp\n// BAD: Deep inheritance\npublic abstract class Entity { }\npublic abstract class AggregateRoot : Entity { }\npublic abstract class Order : AggregateRoot { }\npublic class CustomerOrder : Order { }\n\n// GOOD: Flat structure with composition\npublic interface IEntity\n{\n    Guid Id { get; }\n}\n\npublic record Order(OrderId Id, CustomerId CustomerId, Money Total) : IEntity\n{\n    Guid IEntity.Id => Id.Value;\n}\n```\n\n### ❌ DON'T: Return List<T> when you mean IReadOnlyList<T>\n\n```csharp\n// BAD: Exposes internal list for modification\npublic List<Order> GetOrders() => _orders;\n\n// GOOD: Returns read-only view\npublic IReadOnlyList<Order> GetOrders() => _orders;\n```\n\n### ❌ DON'T: Use byte[] when ReadOnlySpan<byte> works\n\n```csharp\n// BAD: Allocates array on every call\npublic byte[] GetHeader()\n{\n    var header = new byte[64];\n    // Fill header\n    return header;\n}\n\n// GOOD: Zero allocation with Span\npublic void GetHeader(Span<byte> destination)\n{\n    if (destination.Length < 64)\n        throw new ArgumentException(\"Buffer too small\");\n\n    // Fill header directly into caller's buffer\n}\n```\n\n### ❌ DON'T: Forget CancellationToken in async methods\n\n```csharp\n// BAD: No cancellation support\npublic async Task<Order> GetOrderAsync(OrderId id)\n{\n    return await _repository.GetAsync(id);\n}\n\n// GOOD: Cancellation support\npublic async Task<Order> GetOrderAsync(\n    OrderId id,\n    CancellationToken cancellationToken = default)\n{\n    return await _repository.GetAsync(id, cancellationToken);\n}\n```\n\n### ❌ DON'T: Block on async code\n\n```csharp\n// BAD: Deadlock risk!\npublic Order GetOrder(OrderId id)\n{\n    return GetOrderAsync(id).Result;\n}\n\n// BAD: Also deadlock risk!\npublic Order GetOrder(OrderId id)\n{\n    return GetOrderAsync(id).GetAwaiter().GetResult();\n}\n\n// GOOD: Async all the way\npublic async Task<Order> GetOrderAsync(\n    OrderId id,\n    CancellationToken cancellationToken)\n{\n    return await _repository.GetAsync(id, cancellationToken);\n}\n```\n\n---\n\n## Code Organization\n\n```csharp\n// File: Domain/Orders/Order.cs\n\nnamespace MyApp.Domain.Orders;\n\n// 1. Primary domain type\npublic record Order(\n    OrderId Id,\n    CustomerId CustomerId,\n    Money Total,\n    OrderStatus Status,\n    IReadOnlyList<OrderItem> Items\n)\n{\n    // Computed properties\n    public bool IsCompleted => Status is OrderStatus.Completed;\n\n    // Domain methods returning Result for expected errors\n    public Result<Order, OrderError> AddItem(OrderItem item)\n    {\n        if (Status is not OrderStatus.Draft)\n            return Result<Order, OrderError>.Failure(\n                new OrderError(\"ORDER_NOT_DRAFT\", \"Can only add items to draft orders\"));\n\n        var newItems = Items.Append(item).ToList();\n        var newTotal = new Money(\n            Items.Sum(i => i.Total.Amount) + item.Total.Amount,\n            Total.Currency);\n\n        return Result<Order, OrderError>.Success(\n            this with { Items = newItems, Total = newTotal });\n    }\n}\n\n// 2. Enums for state\npublic enum OrderStatus\n{\n    Draft,\n    Submitted,\n    Processing,\n    Completed,\n    Cancelled\n}\n\n// 3. Related types\npublic record OrderItem(\n    ProductId ProductId,\n    Quantity Quantity,\n    Money UnitPrice\n)\n{\n    public Money Total => new(\n        UnitPrice.Amount * Quantity.Value,\n        UnitPrice.Currency);\n}\n\n// 4. Value objects\npublic readonly record struct OrderId(Guid Value)\n{\n    public static OrderId New() => new(Guid.NewGuid());\n}\n\n// 5. Errors\npublic readonly record struct OrderError(string Code, string Message);\n```\n\n---\n\n## Best Practices Summary\n\n### DO's ✅\n- Use `record` for DTOs, messages, and domain entities\n- Use `readonly record struct` for value objects\n- Leverage pattern matching with `switch` expressions\n- Enable and respect nullable reference types\n- Use async/await for all I/O operations\n- Accept `CancellationToken` in all async methods\n- Use `Span<T>` and `Memory<T>` for high-performance scenarios\n- Accept abstractions (`IEnumerable<T>`, `IReadOnlyList<T>`)\n- Return appropriate interfaces or concrete types\n- Use `Result<T, TError>` for expected errors\n- Use `ConfigureAwait(false)` in library code\n- Pool buffers with `ArrayPool<T>` for large allocations\n- Prefer composition over inheritance\n- Avoid abstract base classes in application code\n\n### DON'Ts ❌\n- Don't use mutable classes when records work\n- Don't use classes for value objects (use `readonly record struct`)\n- Don't create deep inheritance hierarchies\n- Don't ignore nullable reference type warnings\n- Don't block on async code (`.Result`, `.Wait()`)\n- Don't use `byte[]` when `Span<byte>` suffices\n- Don't forget `CancellationToken` parameters\n- Don't return mutable collections from APIs\n- Don't throw exceptions for expected business errors\n- Don't use `string` concatenation in loops\n- Don't allocate large arrays repeatedly (use `ArrayPool`)\n\n---\n\n## Additional Resources\n\n- **C# Language Specification**: https://learn.microsoft.com/en-us/dotnet/csharp/\n- **Pattern Matching**: https://learn.microsoft.com/en-us/dotnet/csharp/fundamentals/functional/pattern-matching\n- **Span<T> and Memory<T>**: https://learn.microsoft.com/en-us/dotnet/standard/memory-and-spans/\n- **Async Best Practices**: https://learn.microsoft.com/en-us/archive/msdn-magazine/2013/march/async-await-best-practices-in-asynchronous-programming\n- **.NET Performance Tips**: https://learn.microsoft.com/en-us/dotnet/framework/performance/\n",
        "skills/csharp/concurrency-patterns/SKILL.md": "---\nname: csharp-concurrency-patterns\ndescription: Choosing the right concurrency abstraction in .NET - from async/await for I/O to Channels for producer/consumer to Akka.NET for stateful entity management. Avoid locks and manual synchronization unless absolutely necessary.\n---\n\n# .NET Concurrency: Choosing the Right Tool\n\n## When to Use This Skill\n\nUse this skill when:\n- Deciding how to handle concurrent operations in .NET\n- Evaluating whether to use async/await, Channels, Akka.NET, or other abstractions\n- Tempted to use locks, semaphores, or other synchronization primitives\n- Need to process streams of data with backpressure, batching, or debouncing\n- Managing state across multiple concurrent entities\n\n## The Philosophy\n\n**Start simple, escalate only when needed.**\n\nMost concurrency problems can be solved with `async/await`. Only reach for more sophisticated tools when you have a specific need that async/await can't address cleanly.\n\n**Try to avoid shared mutable state.** The best way to handle concurrency is to design it away. Immutable data, message passing, and isolated state (like actors) eliminate entire categories of bugs.\n\n**Locks should be the exception, not the rule.** When you can't avoid shared mutable state, using a lock occasionally isn't the end of the world. But if you find yourself reaching for `lock`, `SemaphoreSlim`, or other synchronization primitives regularly, step back and reconsider your design.\n\nWhen you truly need shared mutable state:\n1. **First choice:** Redesign to avoid it (immutability, message passing, actor isolation)\n2. **Second choice:** Use `System.Collections.Concurrent` (ConcurrentDictionary, ConcurrentQueue, etc.)\n3. **Third choice:** Use `Channel<T>` to serialize access through message passing\n4. **Last resort:** Use `lock` for simple, short-lived critical sections\n\nLocks are appropriate when building low-level infrastructure or concurrent data structures. But for business logic, there's almost always a better abstraction.\n\n---\n\n## Decision Tree\n\n```\nWhat are you trying to do?\n│\n├─► Wait for I/O (HTTP, database, file)?\n│   └─► Use async/await\n│\n├─► Process a collection in parallel (CPU-bound)?\n│   └─► Use Parallel.ForEachAsync\n│\n├─► Producer/consumer pattern (work queue)?\n│   └─► Use System.Threading.Channels\n│\n├─► UI event handling (debounce, throttle, combine)?\n│   └─► Use Reactive Extensions (Rx)\n│\n├─► Server-side stream processing (backpressure, batching)?\n│   └─► Use Akka.NET Streams\n│\n├─► State machines with complex transitions?\n│   └─► Use Akka.NET Actors (Become pattern)\n│\n├─► Manage state for many independent entities?\n│   └─► Use Akka.NET Actors (entity-per-actor)\n│\n├─► Coordinate multiple async operations?\n│   └─► Use Task.WhenAll / Task.WhenAny\n│\n└─► None of the above fits?\n    └─► Ask yourself: \"Do I really need shared mutable state?\"\n        ├─► Yes → Consider redesigning to avoid it\n        └─► Truly unavoidable → Use Channels or Actors to serialize access\n```\n\n---\n\n## Level 1: async/await (Default Choice)\n\n**Use for:** I/O-bound operations, non-blocking waits, most everyday concurrency.\n\n```csharp\n// Simple async I/O\npublic async Task<Order> GetOrderAsync(string orderId, CancellationToken ct)\n{\n    var order = await _database.GetAsync(orderId, ct);\n    var customer = await _customerService.GetAsync(order.CustomerId, ct);\n    return order with { Customer = customer };\n}\n\n// Parallel async operations (when independent)\npublic async Task<Dashboard> LoadDashboardAsync(string userId, CancellationToken ct)\n{\n    var ordersTask = _orderService.GetRecentOrdersAsync(userId, ct);\n    var notificationsTask = _notificationService.GetUnreadAsync(userId, ct);\n    var statsTask = _statsService.GetUserStatsAsync(userId, ct);\n\n    await Task.WhenAll(ordersTask, notificationsTask, statsTask);\n\n    return new Dashboard(\n        Orders: await ordersTask,\n        Notifications: await notificationsTask,\n        Stats: await statsTask);\n}\n```\n\n**Key principles:**\n- Always accept `CancellationToken`\n- Use `ConfigureAwait(false)` in library code\n- Don't block on async code (no `.Result` or `.Wait()`)\n\n---\n\n## Level 2: Parallel.ForEachAsync (CPU-Bound Parallelism)\n\n**Use for:** Processing collections in parallel when work is CPU-bound or you need controlled concurrency.\n\n```csharp\n// Process items with controlled parallelism\npublic async Task ProcessOrdersAsync(\n    IEnumerable<Order> orders,\n    CancellationToken ct)\n{\n    await Parallel.ForEachAsync(\n        orders,\n        new ParallelOptions\n        {\n            MaxDegreeOfParallelism = Environment.ProcessorCount,\n            CancellationToken = ct\n        },\n        async (order, token) =>\n        {\n            await ProcessOrderAsync(order, token);\n        });\n}\n\n// CPU-bound work with I/O\npublic async Task<IReadOnlyList<ProcessedImage>> ProcessImagesAsync(\n    IEnumerable<string> imagePaths,\n    CancellationToken ct)\n{\n    var results = new ConcurrentBag<ProcessedImage>();\n\n    await Parallel.ForEachAsync(\n        imagePaths,\n        new ParallelOptions { MaxDegreeOfParallelism = 4, CancellationToken = ct },\n        async (path, token) =>\n        {\n            var image = await File.ReadAllBytesAsync(path, token);\n            var processed = ProcessImage(image); // CPU-bound\n            results.Add(processed);\n        });\n\n    return results.ToList();\n}\n```\n\n**When NOT to use:**\n- Pure I/O operations (async/await is sufficient)\n- When order matters (Parallel doesn't preserve order)\n- When you need backpressure or flow control\n\n---\n\n## Level 3: System.Threading.Channels (Producer/Consumer)\n\n**Use for:** Work queues, producer/consumer patterns, decoupling producers from consumers, simple stream-like processing.\n\n```csharp\n// Basic producer/consumer\npublic class OrderProcessor\n{\n    private readonly Channel<Order> _channel;\n\n    public OrderProcessor()\n    {\n        // Bounded channel provides backpressure\n        _channel = Channel.CreateBounded<Order>(new BoundedChannelOptions(100)\n        {\n            FullMode = BoundedChannelFullMode.Wait\n        });\n    }\n\n    // Producer\n    public async Task EnqueueOrderAsync(Order order, CancellationToken ct)\n    {\n        await _channel.Writer.WriteAsync(order, ct);\n    }\n\n    // Consumer (run as background task)\n    public async Task ProcessOrdersAsync(CancellationToken ct)\n    {\n        await foreach (var order in _channel.Reader.ReadAllAsync(ct))\n        {\n            await ProcessOrderAsync(order, ct);\n        }\n    }\n\n    // Signal no more items\n    public void Complete() => _channel.Writer.Complete();\n}\n```\n\n```csharp\n// Multiple consumers (work-stealing pattern)\npublic class WorkerPool\n{\n    private readonly Channel<WorkItem> _channel;\n    private readonly List<Task> _workers = new();\n\n    public WorkerPool(int workerCount)\n    {\n        _channel = Channel.CreateUnbounded<WorkItem>();\n\n        // Start multiple consumers\n        for (int i = 0; i < workerCount; i++)\n        {\n            _workers.Add(Task.Run(() => ConsumeAsync()));\n        }\n    }\n\n    private async Task ConsumeAsync()\n    {\n        await foreach (var item in _channel.Reader.ReadAllAsync())\n        {\n            await ProcessAsync(item);\n        }\n    }\n\n    public ValueTask EnqueueAsync(WorkItem item)\n        => _channel.Writer.WriteAsync(item);\n}\n```\n\n**Channels are good for:**\n- Decoupling producer speed from consumer speed\n- Buffering work with backpressure\n- Simple fan-out to multiple workers\n- Background processing queues\n\n**Channels are NOT good for:**\n- Complex stream operations (batching, windowing, merging)\n- Stateful processing per entity\n- When you need sophisticated error handling/supervision\n\n---\n\n## Level 4: Akka.NET Streams (Complex Stream Processing)\n\n**Use for:** Backpressure, batching, debouncing, throttling, merging streams, complex transformations.\n\n```csharp\nusing Akka.Streams;\nusing Akka.Streams.Dsl;\n\n// Batching with timeout\npublic Source<IReadOnlyList<Event>, NotUsed> BatchEvents(\n    Source<Event, NotUsed> events)\n{\n    return events\n        .GroupedWithin(100, TimeSpan.FromSeconds(1)) // Batch up to 100 or 1 second\n        .Select(batch => batch.ToList() as IReadOnlyList<Event>);\n}\n\n// Throttling\npublic Source<Request, NotUsed> ThrottleRequests(\n    Source<Request, NotUsed> requests)\n{\n    return requests\n        .Throttle(10, TimeSpan.FromSeconds(1), 5, ThrottleMode.Shaping);\n}\n\n// Parallel processing with ordered results\npublic Source<ProcessedItem, NotUsed> ProcessWithParallelism(\n    Source<Item, NotUsed> items)\n{\n    return items\n        .SelectAsync(4, async item => await ProcessAsync(item)); // 4 parallel\n}\n\n// Complex pipeline\npublic IRunnableGraph<Task<Done>> CreatePipeline(\n    Source<RawEvent, NotUsed> events,\n    Sink<ProcessedEvent, Task<Done>> sink)\n{\n    return events\n        .Where(e => e.IsValid)\n        .GroupedWithin(50, TimeSpan.FromMilliseconds(500))\n        .SelectAsync(4, batch => ProcessBatchAsync(batch))\n        .SelectMany(results => results)\n        .ToMaterialized(sink, Keep.Right);\n}\n```\n\n**Akka.NET Streams excel at:**\n- Batching with size AND time limits\n- Throttling and rate limiting\n- Backpressure that propagates through the entire pipeline\n- Merging/splitting streams\n- Parallel processing with ordering guarantees\n- Error handling with supervision\n\n---\n\n## Level 4b: Reactive Extensions (UI and Event Composition)\n\n**Use for:** UI event handling, composing event streams, time-based operations in client applications.\n\nRx shines in UI scenarios where you need to react to user events with debouncing, throttling, or combining multiple event sources.\n\n```csharp\nusing System.Reactive.Linq;\n\n// Search-as-you-type with debouncing\npublic class SearchViewModel\n{\n    public SearchViewModel(ISearchService searchService)\n    {\n        // React to text changes with debouncing\n        SearchResults = SearchText\n            .Throttle(TimeSpan.FromMilliseconds(300))  // Wait for typing to pause\n            .DistinctUntilChanged()                     // Ignore if same text\n            .Where(text => text.Length >= 3)           // Minimum length\n            .SelectMany(text => searchService.SearchAsync(text).ToObservable())\n            .ObserveOn(RxApp.MainThreadScheduler);     // Back to UI thread\n    }\n\n    public IObservable<string> SearchText { get; }\n    public IObservable<IList<SearchResult>> SearchResults { get; }\n}\n\n// Combining multiple UI events\npublic IObservable<bool> CanSubmit =>\n    Observable.CombineLatest(\n        UsernameValid,\n        PasswordValid,\n        EmailValid,\n        (user, pass, email) => user && pass && email);\n\n// Double-click detection\npublic IObservable<Point> DoubleClicks =>\n    MouseClicks\n        .Buffer(TimeSpan.FromMilliseconds(300))\n        .Where(clicks => clicks.Count >= 2)\n        .Select(clicks => clicks.Last());\n\n// Auto-save with debouncing\npublic IDisposable AutoSave =>\n    DocumentChanges\n        .Throttle(TimeSpan.FromSeconds(2))\n        .Subscribe(async doc => await SaveAsync(doc));\n```\n\n**Rx is ideal for:**\n- UI event composition (WPF, WinForms, MAUI, Blazor)\n- Search-as-you-type with debouncing\n- Combining multiple event sources\n- Time-windowed operations in UI\n- Drag-and-drop gesture detection\n- Real-time data visualization\n\n**Rx vs Akka.NET Streams:**\n\n| Scenario | Rx | Akka.NET Streams |\n|----------|----|--------------------|\n| UI events | ✅ Best choice | Overkill |\n| Client-side composition | ✅ Best choice | Overkill |\n| Server-side pipelines | Works but limited | ✅ Better backpressure |\n| Distributed processing | ❌ Not designed for | ✅ Built for this |\n| Hot observables | ✅ Native support | Requires more setup |\n\n**Rule of thumb:** Rx for UI/client, Akka.NET Streams for server-side pipelines.\n\n---\n\n## Level 5: Akka.NET Actors (Stateful Concurrency)\n\n**Use for:** Managing state for multiple entities, state machines, push-based updates, complex coordination, supervision and fault tolerance.\n\n### Entity-Per-Actor Pattern\n\n```csharp\n// Actor per entity - each order has isolated state\npublic class OrderActor : ReceiveActor\n{\n    private OrderState _state;\n\n    public OrderActor(string orderId)\n    {\n        _state = new OrderState(orderId);\n\n        Receive<AddItem>(msg =>\n        {\n            _state = _state.AddItem(msg.Item);\n            Sender.Tell(new ItemAdded(msg.Item));\n        });\n\n        Receive<Checkout>(msg =>\n        {\n            if (_state.CanCheckout)\n            {\n                _state = _state.Checkout();\n                Sender.Tell(new CheckoutSucceeded(_state.Total));\n            }\n            else\n            {\n                Sender.Tell(new CheckoutFailed(\"Cart is empty\"));\n            }\n        });\n\n        Receive<GetState>(_ => Sender.Tell(_state));\n    }\n}\n```\n\n### State Machines with Become\n\nActors excel at implementing state machines using `Become()` to switch message handlers:\n\n```csharp\npublic class PaymentActor : ReceiveActor\n{\n    private PaymentData _payment;\n\n    public PaymentActor(string paymentId)\n    {\n        _payment = new PaymentData(paymentId);\n\n        // Start in Pending state\n        Pending();\n    }\n\n    private void Pending()\n    {\n        Receive<AuthorizePayment>(msg =>\n        {\n            _payment = _payment with { Amount = msg.Amount };\n            // Transition to Authorizing state\n            Become(Authorizing);\n            Self.Tell(new ProcessAuthorization());\n        });\n\n        Receive<CancelPayment>(_ =>\n        {\n            Become(Cancelled);\n            Sender.Tell(new PaymentCancelled(_payment.Id));\n        });\n    }\n\n    private void Authorizing()\n    {\n        Receive<ProcessAuthorization>(async _ =>\n        {\n            var result = await _gateway.AuthorizeAsync(_payment);\n            if (result.Success)\n            {\n                _payment = _payment with { AuthCode = result.AuthCode };\n                Become(Authorized);\n            }\n            else\n            {\n                Become(Failed);\n            }\n        });\n\n        // Can't cancel while authorizing - stash for later or reject\n        Receive<CancelPayment>(_ =>\n        {\n            Sender.Tell(new PaymentError(\"Cannot cancel during authorization\"));\n        });\n    }\n\n    private void Authorized()\n    {\n        Receive<CapturePayment>(_ =>\n        {\n            Become(Capturing);\n            Self.Tell(new ProcessCapture());\n        });\n\n        Receive<VoidPayment>(_ =>\n        {\n            Become(Voiding);\n            Self.Tell(new ProcessVoid());\n        });\n    }\n\n    private void Capturing() { /* ... */ }\n    private void Voiding() { /* ... */ }\n    private void Cancelled() { /* Only responds to GetState */ }\n    private void Failed() { /* Only responds to GetState, Retry */ }\n}\n```\n\n### Distributed Entities with Cluster Sharding\n\n```csharp\n// Using Cluster Sharding for distributed entities\nbuilder.WithShardRegion<OrderActor>(\n    typeName: \"orders\",\n    entityPropsFactory: (_, _, resolver) =>\n        orderId => Props.Create(() => new OrderActor(orderId)),\n    messageExtractor: new OrderMessageExtractor(),\n    shardOptions: new ShardOptions());\n\n// Send message to any order - sharding routes to correct node\nvar orderRegion = registry.Get<OrderActor>();\norderRegion.Tell(new ShardingEnvelope(\"order-123\", new AddItem(item)));\n```\n\n### When to Use Akka.NET\n\n**Use Akka.NET Actors when you have:**\n\n| Scenario | Why Actors? |\n|----------|-------------|\n| Many entities with independent state | Each entity gets its own actor - no locks, natural isolation |\n| State machines | `Become()` elegantly models state transitions |\n| Push-based/reactive updates | Actors naturally support tell-don't-ask |\n| Supervision requirements | Parent actors supervise children, automatic restart on failure |\n| Distributed systems | Cluster Sharding distributes entities across nodes |\n| Long-running workflows | Actors + persistence = durable workflows |\n| Real-time systems | Message-driven, non-blocking by design |\n| IoT / device management | Each device = one actor, scales to millions |\n\n**Don't use Akka.NET when:**\n\n| Scenario | Better Alternative |\n|----------|-------------------|\n| Simple work queue | `Channel<T>` |\n| Request/response API | `async/await` |\n| Batch processing | `Parallel.ForEachAsync` or Akka.NET Streams |\n| UI event handling | Reactive Extensions |\n| Shared state (single instance) | Service with `Channel` for serialization |\n| CRUD operations | Standard async services |\n\n### The Actor Mindset\n\nThink of actors when your problem looks like:\n- \"I have **thousands** of [orders/users/devices/sessions] that need independent state\"\n- \"Each [entity] goes through a **lifecycle** with different behaviors at each stage\"\n- \"I need to **push updates** to interested parties when something changes\"\n- \"If processing fails, I want to **restart** just that entity, not the whole system\"\n- \"This needs to work across **multiple servers**\"\n\nIf none of these apply, you probably don't need actors.\n\n---\n\n## Anti-Patterns: What to Avoid\n\n### ❌ Locks for Business Logic\n\n```csharp\n// BAD: Using locks to protect shared state\nprivate readonly object _lock = new();\nprivate Dictionary<string, Order> _orders = new();\n\npublic void UpdateOrder(string id, Action<Order> update)\n{\n    lock (_lock)\n    {\n        if (_orders.TryGetValue(id, out var order))\n        {\n            update(order);\n        }\n    }\n}\n\n// GOOD: Use an actor or Channel to serialize access\n// Each order gets its own actor - no locks needed\n```\n\n### ❌ Manual Thread Management\n\n```csharp\n// BAD: Creating threads manually\nvar thread = new Thread(() => ProcessOrders());\nthread.Start();\n\n// GOOD: Use Task.Run or better abstractions\n_ = Task.Run(() => ProcessOrdersAsync(cancellationToken));\n```\n\n### ❌ Blocking in Async Code\n\n```csharp\n// BAD: Blocking on async\nvar result = GetDataAsync().Result; // Deadlock risk!\nGetDataAsync().Wait();              // Also bad\n\n// GOOD: Async all the way\nvar result = await GetDataAsync();\n```\n\n### ❌ Shared Mutable State Without Protection\n\n```csharp\n// BAD: Multiple tasks mutating shared state\nvar results = new List<Result>();\nawait Parallel.ForEachAsync(items, async (item, ct) =>\n{\n    var result = await ProcessAsync(item, ct);\n    results.Add(result); // Race condition!\n});\n\n// GOOD: Use ConcurrentBag or collect results differently\nvar results = new ConcurrentBag<Result>();\n// Or better: return from the lambda and collect\n```\n\n---\n\n## Quick Reference: Which Tool When?\n\n| Need | Tool | Example |\n|------|------|---------|\n| Wait for I/O | `async/await` | HTTP calls, database queries |\n| Parallel CPU work | `Parallel.ForEachAsync` | Image processing, calculations |\n| Work queue | `Channel<T>` | Background job processing |\n| UI events with debounce/throttle | Reactive Extensions | Search-as-you-type, auto-save |\n| Server-side batching/throttling | Akka.NET Streams | Event aggregation, rate limiting |\n| State machines | Akka.NET Actors | Payment flows, order lifecycles |\n| Entity state management | Akka.NET Actors | Order management, user sessions |\n| Fire multiple async ops | `Task.WhenAll` | Loading dashboard data |\n| Race multiple async ops | `Task.WhenAny` | Timeout with fallback |\n| Periodic work | `PeriodicTimer` | Health checks, polling |\n\n---\n\n## The Escalation Path\n\n```\nasync/await (start here)\n    │\n    ├─► Need parallelism? → Parallel.ForEachAsync\n    │\n    ├─► Need producer/consumer? → Channel<T>\n    │\n    ├─► Need UI event composition? → Reactive Extensions\n    │\n    ├─► Need server-side stream processing? → Akka.NET Streams\n    │\n    └─► Need state machines or entity management? → Akka.NET Actors\n```\n\n**Only escalate when you have a concrete need.** Don't reach for actors or streams \"just in case\" - start with async/await and move up only when the simpler approach doesn't fit.\n",
        "skills/csharp/type-design-performance/SKILL.md": "---\nname: type-design-performance\ndescription: Design .NET types for performance. Seal classes, use readonly structs, prefer static pure functions, avoid premature enumeration, and choose the right collection types.\n---\n\n# Type Design for Performance\n\n## When to Use This Skill\n\nUse this skill when:\n- Designing new types and APIs\n- Reviewing code for performance issues\n- Choosing between class, struct, and record\n- Working with collections and enumerables\n\n---\n\n## Core Principles\n\n1. **Seal your types** - Unless explicitly designed for inheritance\n2. **Prefer readonly structs** - For small, immutable value types\n3. **Prefer static pure functions** - Better performance and testability\n4. **Defer enumeration** - Don't materialize until you need to\n5. **Return immutable collections** - From API boundaries\n\n---\n\n## Seal Classes by Default\n\nSealing classes enables JIT devirtualization and communicates API intent.\n\n```csharp\n// DO: Seal classes not designed for inheritance\npublic sealed class OrderProcessor\n{\n    public void Process(Order order) { }\n}\n\n// DO: Seal records (they're classes)\npublic sealed record OrderCreated(OrderId Id, CustomerId CustomerId);\n\n// DON'T: Leave unsealed without reason\npublic class OrderProcessor  // Can be subclassed - intentional?\n{\n    public virtual void Process(Order order) { }  // Virtual = slower\n}\n```\n\n**Benefits:**\n- JIT can devirtualize method calls\n- Communicates \"this is not an extension point\"\n- Prevents accidental breaking changes\n\n---\n\n## Readonly Structs for Value Types\n\nStructs should be `readonly` when immutable. This prevents defensive copies.\n\n```csharp\n// DO: Readonly struct for immutable value types\npublic readonly record struct OrderId(Guid Value)\n{\n    public static OrderId New() => new(Guid.NewGuid());\n    public override string ToString() => Value.ToString();\n}\n\n// DO: Readonly struct for small, short-lived data\npublic readonly struct Money\n{\n    public decimal Amount { get; }\n    public string Currency { get; }\n\n    public Money(decimal amount, string currency)\n    {\n        Amount = amount;\n        Currency = currency;\n    }\n}\n\n// DON'T: Mutable struct (causes defensive copies)\npublic struct Point  // Not readonly!\n{\n    public int X { get; set; }  // Mutable!\n    public int Y { get; set; }\n}\n```\n\n### When to Use Structs\n\n| Use Struct When | Use Class When |\n|-----------------|----------------|\n| Small (≤16 bytes typically) | Larger objects |\n| Short-lived | Long-lived |\n| Frequently allocated | Shared references needed |\n| Value semantics required | Identity semantics required |\n| Immutable | Mutable state |\n\n---\n\n## Prefer Static Pure Functions\n\nStatic methods with no side effects are faster and more testable.\n\n```csharp\n// DO: Static pure function\npublic static class OrderCalculator\n{\n    public static Money CalculateTotal(IReadOnlyList<OrderItem> items)\n    {\n        var total = items.Sum(i => i.Price * i.Quantity);\n        return new Money(total, \"USD\");\n    }\n}\n\n// Usage - predictable, testable\nvar total = OrderCalculator.CalculateTotal(items);\n```\n\n**Benefits:**\n- No vtable lookup (faster)\n- No hidden state\n- Easier to test (pure input → output)\n- Thread-safe by design\n- Forces explicit dependencies\n\n```csharp\n// DON'T: Instance method hiding dependencies\npublic class OrderCalculator\n{\n    private readonly ITaxService _taxService;  // Hidden dependency\n    private readonly IDiscountService _discountService;  // Hidden dependency\n\n    public Money CalculateTotal(IReadOnlyList<OrderItem> items)\n    {\n        // What does this actually depend on?\n    }\n}\n\n// BETTER: Explicit dependencies via parameters\npublic static class OrderCalculator\n{\n    public static Money CalculateTotal(\n        IReadOnlyList<OrderItem> items,\n        decimal taxRate,\n        decimal discountPercent)\n    {\n        // All inputs visible\n    }\n}\n```\n\n**Don't go overboard** - Use instance methods when you genuinely need state or polymorphism.\n\n---\n\n## Defer Enumeration\n\nDon't materialize enumerables until necessary. Avoid excessive LINQ chains.\n\n```csharp\n// BAD: Premature materialization\npublic IReadOnlyList<Order> GetActiveOrders()\n{\n    return _orders\n        .Where(o => o.IsActive)\n        .ToList()  // Materialized!\n        .OrderBy(o => o.CreatedAt)  // Another iteration\n        .ToList();  // Materialized again!\n}\n\n// GOOD: Defer until the end\npublic IReadOnlyList<Order> GetActiveOrders()\n{\n    return _orders\n        .Where(o => o.IsActive)\n        .OrderBy(o => o.CreatedAt)\n        .ToList();  // Single materialization\n}\n\n// GOOD: Return IEnumerable if caller might not need all items\npublic IEnumerable<Order> GetActiveOrders()\n{\n    return _orders\n        .Where(o => o.IsActive)\n        .OrderBy(o => o.CreatedAt);\n    // Caller decides when to materialize\n}\n```\n\n### Async Enumeration\n\nBe careful with async and IEnumerable:\n\n```csharp\n// BAD: Async in LINQ - hidden allocations\nvar results = orders\n    .Select(async o => await ProcessOrderAsync(o))  // Task per item!\n    .ToList();\nawait Task.WhenAll(results);\n\n// GOOD: Use IAsyncEnumerable for streaming\npublic async IAsyncEnumerable<OrderResult> ProcessOrdersAsync(\n    IEnumerable<Order> orders,\n    [EnumeratorCancellation] CancellationToken ct = default)\n{\n    foreach (var order in orders)\n    {\n        ct.ThrowIfCancellationRequested();\n        yield return await ProcessOrderAsync(order, ct);\n    }\n}\n\n// GOOD: Batch processing for parallelism\nvar results = await Task.WhenAll(\n    orders.Select(o => ProcessOrderAsync(o)));\n```\n\n---\n\n## ValueTask vs Task\n\nUse `ValueTask` for hot paths that often complete synchronously. For real I/O, just use `Task`.\n\n```csharp\n// DO: ValueTask for cached/synchronous paths\npublic ValueTask<User?> GetUserAsync(UserId id)\n{\n    if (_cache.TryGetValue(id, out var user))\n    {\n        return ValueTask.FromResult<User?>(user);  // No allocation\n    }\n\n    return new ValueTask<User?>(FetchUserAsync(id));\n}\n\n// DO: Task for real I/O (simpler, no footguns)\npublic Task<Order> CreateOrderAsync(CreateOrderCommand cmd)\n{\n    // This always hits the database\n    return _repository.CreateAsync(cmd);\n}\n```\n\n**ValueTask rules:**\n- Never await a ValueTask more than once\n- Never use `.Result` or `.GetAwaiter().GetResult()` before completion\n- If in doubt, use Task\n\n---\n\n## Span and Memory for Bytes\n\nUse `Span<T>` and `Memory<T>` instead of `byte[]` for low-level operations.\n\n```csharp\n// DO: Accept Span for synchronous operations\npublic static int ParseInt(ReadOnlySpan<char> text)\n{\n    return int.Parse(text);\n}\n\n// DO: Accept Memory for async operations\npublic async Task WriteAsync(ReadOnlyMemory<byte> data)\n{\n    await _stream.WriteAsync(data);\n}\n\n// DON'T: Force array allocation\npublic static int ParseInt(string text)  // String allocated\n{\n    return int.Parse(text);\n}\n```\n\n### Common Span Patterns\n\n```csharp\n// Slice without allocation\nReadOnlySpan<char> span = \"Hello, World!\".AsSpan();\nvar hello = span[..5];  // No allocation\n\n// Stack allocation for small buffers\nSpan<byte> buffer = stackalloc byte[256];\n\n// Use ArrayPool for larger buffers\nvar buffer = ArrayPool<byte>.Shared.Rent(4096);\ntry\n{\n    // Use buffer...\n}\nfinally\n{\n    ArrayPool<byte>.Shared.Return(buffer);\n}\n```\n\n---\n\n## Collection Return Types\n\n### Return Immutable Collections from APIs\n\n```csharp\n// DO: Return immutable collection\npublic IReadOnlyList<Order> GetOrders()\n{\n    return _orders.ToList();  // Caller can't modify internal state\n}\n\n// DO: Use frozen collections for static data (.NET 8+)\nprivate static readonly FrozenDictionary<string, Handler> _handlers =\n    new Dictionary<string, Handler>\n    {\n        [\"create\"] = new CreateHandler(),\n        [\"update\"] = new UpdateHandler(),\n    }.ToFrozenDictionary();\n\n// DON'T: Return mutable collection\npublic List<Order> GetOrders()\n{\n    return _orders;  // Caller can modify!\n}\n```\n\n### Internal Mutation is Fine\n\n```csharp\npublic IReadOnlyList<OrderItem> BuildOrderItems(Cart cart)\n{\n    var items = new List<OrderItem>();  // Mutable internally\n\n    foreach (var cartItem in cart.Items)\n    {\n        items.Add(CreateOrderItem(cartItem));\n    }\n\n    return items;  // Return as IReadOnlyList\n}\n```\n\n### Collection Guidelines\n\n| Scenario | Return Type |\n|----------|-------------|\n| API boundary | `IReadOnlyList<T>`, `IReadOnlyCollection<T>` |\n| Static lookup data | `FrozenDictionary<K,V>`, `FrozenSet<T>` |\n| Internal building | `List<T>`, then return as readonly |\n| Single item or none | `T?` (nullable) |\n| Zero or more, lazy | `IEnumerable<T>` |\n\n---\n\n## Quick Reference\n\n| Pattern | Benefit |\n|---------|---------|\n| `sealed class` | Devirtualization, clear API |\n| `readonly record struct` | No defensive copies, value semantics |\n| Static pure functions | No vtable, testable, thread-safe |\n| Defer `.ToList()` | Single materialization |\n| `ValueTask` for hot paths | Avoid Task allocation |\n| `Span<T>` for bytes | Stack allocation, no copying |\n| `IReadOnlyList<T>` return | Immutable API contract |\n| `FrozenDictionary` | Fastest lookup for static data |\n\n---\n\n## Anti-Patterns\n\n```csharp\n// DON'T: Unsealed class without reason\npublic class OrderService { }  // Seal it!\n\n// DON'T: Mutable struct\npublic struct Point { public int X; public int Y; }  // Make readonly\n\n// DON'T: Instance method that could be static\npublic int Add(int a, int b) => a + b;  // Make static\n\n// DON'T: Multiple ToList() calls\nitems.Where(...).ToList().OrderBy(...).ToList();  // One ToList at end\n\n// DON'T: Return List<T> from public API\npublic List<Order> GetOrders();  // Return IReadOnlyList<T>\n\n// DON'T: ValueTask for always-async operations\npublic ValueTask<Order> CreateOrderAsync();  // Just use Task\n```\n\n---\n\n## Resources\n\n- **Performance Best Practices**: https://learn.microsoft.com/en-us/dotnet/standard/performance/\n- **Span<T> Guidance**: https://learn.microsoft.com/en-us/dotnet/standard/memory-and-spans/\n- **Frozen Collections**: https://learn.microsoft.com/en-us/dotnet/api/system.collections.frozen\n",
        "skills/data/database-performance/SKILL.md": "---\nname: database-performance\ndescription: Database access patterns for performance. Separate read/write models, avoid N+1 queries, use AsNoTracking, apply row limits, and never do application-side joins. Works with EF Core and Dapper.\n---\n\n# Database Performance Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Designing data access layers\n- Optimizing slow database queries\n- Choosing between EF Core and Dapper\n- Avoiding common performance pitfalls\n\n---\n\n## Core Principles\n\n1. **Separate read and write models** - Don't use the same types for both\n2. **Think in batches** - Avoid N+1 queries\n3. **Only retrieve what you need** - No SELECT *\n4. **Apply row limits** - Always have a configurable Take/Limit\n5. **Do joins in SQL** - Never in application code\n6. **AsNoTracking for reads** - EF Core change tracking is expensive\n\n---\n\n## Read/Write Model Separation\n\n**Don't think of entities as table-scoped.** Separate your read models (queries) from write models (commands).\n\n### Architecture\n\n```\nsrc/\n  MyApp.Data/\n    Users/\n      IUserReadStore.cs      # Read operations\n      IUserWriteStore.cs     # Write operations\n      PostgresUserReadStore.cs\n      PostgresUserWriteStore.cs\n    Orders/\n      IOrderReadStore.cs\n      IOrderWriteStore.cs\n      PostgresOrderReadStore.cs\n      PostgresOrderWriteStore.cs\n```\n\n### Read Store Interface\n\n```csharp\npublic interface IUserReadStore\n{\n    Task<UserProfile?> GetByIdAsync(UserId id, CancellationToken ct = default);\n    Task<UserProfile?> GetByEmailAsync(EmailAddress email, CancellationToken ct = default);\n    Task<IReadOnlyList<UserSummary>> GetAllAsync(int limit, UserId? cursor = null, CancellationToken ct = default);\n    Task<bool> EmailExistsAsync(EmailAddress email, CancellationToken ct = default);\n}\n```\n\n### Write Store Interface\n\n```csharp\npublic interface IUserWriteStore\n{\n    Task<UserId> CreateAsync(CreateUserCommand command, CancellationToken ct = default);\n    Task UpdateAsync(UserId id, UpdateUserCommand command, CancellationToken ct = default);\n    Task DeleteAsync(UserId id, CancellationToken ct = default);\n}\n```\n\n**Benefits:**\n- Read models are optimized for queries (projections, joins)\n- Write models focus on validation and business rules\n- No confusion about when to track changes\n- Easier to optimize independently\n\n---\n\n## Always Apply Row Limits\n\n**Never return unbounded result sets.** Every read method should have a configurable limit.\n\n### Pattern: Limit Parameter\n\n```csharp\npublic interface IOrderReadStore\n{\n    // Limit is required, not optional\n    Task<IReadOnlyList<OrderSummary>> GetByCustomerAsync(\n        CustomerId customerId,\n        int limit,\n        OrderId? cursor = null,\n        CancellationToken ct = default);\n}\n\n// Implementation\npublic async Task<IReadOnlyList<OrderSummary>> GetByCustomerAsync(\n    CustomerId customerId,\n    int limit,\n    OrderId? cursor = null,\n    CancellationToken ct = default)\n{\n    await using var connection = await _dataSource.OpenConnectionAsync(ct);\n\n    const string sql = \"\"\"\n        SELECT id, customer_id, total, status, created_at\n        FROM orders\n        WHERE customer_id = @CustomerId\n        AND (@Cursor IS NULL OR created_at < (SELECT created_at FROM orders WHERE id = @Cursor))\n        ORDER BY created_at DESC\n        LIMIT @Limit\n        \"\"\";\n\n    var rows = await connection.QueryAsync<OrderRow>(sql, new\n    {\n        CustomerId = customerId.Value,\n        Cursor = cursor?.Value,\n        Limit = limit\n    });\n\n    return rows.Select(r => r.ToOrderSummary()).ToList();\n}\n```\n\n### EF Core with Pagination\n\n```csharp\npublic async Task<PaginatedList<OrderSummary>> GetOrdersAsync(\n    CustomerId customerId,\n    Paginator paginator,\n    CancellationToken ct = default)\n{\n    var query = _context.Orders\n        .AsNoTracking()\n        .Where(o => o.CustomerId == customerId.Value)\n        .OrderByDescending(o => o.CreatedAt);\n\n    var totalCount = await query.CountAsync(ct);\n\n    var orders = await query\n        .Skip((paginator.PageNumber - 1) * paginator.PageSize)\n        .Take(paginator.PageSize)  // Always limit!\n        .Select(o => new OrderSummary(\n            new OrderId(o.Id),\n            o.Total,\n            o.Status,\n            o.CreatedAt))\n        .ToListAsync(ct);\n\n    return new PaginatedList<OrderSummary>(\n        orders,\n        totalCount,\n        paginator.PageSize,\n        paginator.PageNumber);\n}\n```\n\n---\n\n## AsNoTracking for Read Queries\n\nEF Core's change tracking is expensive. Disable it for read-only queries.\n\n```csharp\n// DO: Disable tracking for reads\nvar users = await _context.Users\n    .AsNoTracking()\n    .Where(u => u.IsActive)\n    .ToListAsync();\n\n// DON'T: Track entities you won't modify\nvar users = await _context.Users\n    .Where(u => u.IsActive)\n    .ToListAsync();  // Change tracking enabled - wasteful\n```\n\n### Configure Default Behavior\n\n```csharp\n// For read-heavy applications, consider this in DbContext\nprotected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n{\n    optionsBuilder.UseQueryTrackingBehavior(QueryTrackingBehavior.NoTracking);\n}\n```\n\nThen explicitly enable tracking when needed:\n\n```csharp\nvar user = await _context.Users\n    .AsTracking()  // Explicit - we intend to modify\n    .FirstOrDefaultAsync(u => u.Id == userId);\n```\n\n---\n\n## Avoid N+1 Queries\n\nThe N+1 problem: fetching a list, then querying for each item's related data.\n\n### The Problem\n\n```csharp\n// BAD: N+1 queries\nvar orders = await _context.Orders.ToListAsync();\n\nforeach (var order in orders)\n{\n    // Each iteration hits the database!\n    var items = await _context.OrderItems\n        .Where(i => i.OrderId == order.Id)\n        .ToListAsync();\n}\n```\n\n### Solution 1: Include (EF Core)\n\n```csharp\n// GOOD: Single query with join\nvar orders = await _context.Orders\n    .AsNoTracking()\n    .Include(o => o.Items)\n    .ToListAsync();\n```\n\n### Solution 2: Batch Query (Dapper)\n\n```csharp\n// GOOD: Two queries, no N+1\nconst string sql = \"\"\"\n    SELECT id, customer_id, total FROM orders WHERE customer_id = @CustomerId;\n    SELECT oi.* FROM order_items oi\n    INNER JOIN orders o ON oi.order_id = o.id\n    WHERE o.customer_id = @CustomerId;\n    \"\"\";\n\nusing var multi = await connection.QueryMultipleAsync(sql, new { CustomerId = customerId });\nvar orders = (await multi.ReadAsync<OrderRow>()).ToList();\nvar items = (await multi.ReadAsync<OrderItemRow>()).ToList();\n\n// Join in memory (acceptable - data already fetched)\nforeach (var order in orders)\n{\n    order.Items = items.Where(i => i.OrderId == order.Id).ToList();\n}\n```\n\n---\n\n## Never Do Application-Side Joins\n\n**Joins must happen in SQL, not in C#.**\n\n```csharp\n// BAD: Application join - two queries, memory waste\nvar customers = await _context.Customers.ToListAsync();\nvar orders = await _context.Orders.ToListAsync();\n\nvar result = customers.Select(c => new\n{\n    Customer = c,\n    Orders = orders.Where(o => o.CustomerId == c.Id).ToList()  // O(n*m) in memory!\n});\n\n// GOOD: SQL join - single query\nvar result = await _context.Customers\n    .AsNoTracking()\n    .Include(c => c.Orders)\n    .ToListAsync();\n\n// GOOD: Explicit join (Dapper)\nconst string sql = \"\"\"\n    SELECT c.id, c.name, COUNT(o.id) as order_count\n    FROM customers c\n    LEFT JOIN orders o ON c.id = o.customer_id\n    GROUP BY c.id, c.name\n    \"\"\";\n```\n\n---\n\n## Avoid Cartesian Explosions\n\nMultiple `Include` calls can cause Cartesian products.\n\n```csharp\n// DANGEROUS: Can explode into millions of rows\nvar product = await _context.Products\n    .Include(p => p.Reviews)      // 100 reviews\n    .Include(p => p.Images)       // 20 images\n    .Include(p => p.Categories)   // 5 categories\n    .FirstOrDefaultAsync(p => p.Id == id);\n// Result: 100 * 20 * 5 = 10,000 rows transferred!\n```\n\n### Solution: Split Queries\n\n```csharp\n// GOOD: Multiple queries, no Cartesian explosion\nvar product = await _context.Products\n    .AsSplitQuery()\n    .Include(p => p.Reviews)\n    .Include(p => p.Images)\n    .Include(p => p.Categories)\n    .FirstOrDefaultAsync(p => p.Id == id);\n// Result: 4 separate queries, ~125 rows total\n```\n\n### Solution: Explicit Projection\n\n```csharp\n// BEST: Only fetch what you need\nvar product = await _context.Products\n    .AsNoTracking()\n    .Where(p => p.Id == id)\n    .Select(p => new ProductDetail(\n        p.Id,\n        p.Name,\n        p.Description,\n        p.Reviews.OrderByDescending(r => r.CreatedAt).Take(10).ToList(),\n        p.Images.Take(5).ToList(),\n        p.Categories.Select(c => c.Name).ToList()))\n    .FirstOrDefaultAsync();\n```\n\n---\n\n## Constrain Column Sizes\n\nDefine maximum lengths in your EF Core model to prevent oversized data.\n\n```csharp\npublic class UserConfiguration : IEntityTypeConfiguration<User>\n{\n    public void Configure(EntityTypeBuilder<User> builder)\n    {\n        builder.Property(u => u.Email)\n            .HasMaxLength(254)  // RFC 5321 limit\n            .IsRequired();\n\n        builder.Property(u => u.Name)\n            .HasMaxLength(100)\n            .IsRequired();\n\n        builder.Property(u => u.Bio)\n            .HasMaxLength(500);\n\n        // For truly large content, use text type explicitly\n        builder.Property(u => u.Notes)\n            .HasColumnType(\"text\");\n    }\n}\n```\n\n---\n\n## Don't Build Generic Repositories\n\nGeneric repositories hide query complexity and make optimization difficult.\n\n```csharp\n// BAD: Generic repository\npublic interface IRepository<T>\n{\n    Task<T?> GetByIdAsync(int id);\n    Task<IEnumerable<T>> GetAllAsync();  // No limit!\n    Task<IEnumerable<T>> FindAsync(Expression<Func<T, bool>> predicate);  // Can't optimize\n}\n\n// GOOD: Purpose-built read stores\npublic interface IOrderReadStore\n{\n    Task<OrderDetail?> GetByIdAsync(OrderId id, CancellationToken ct = default);\n    Task<IReadOnlyList<OrderSummary>> GetByCustomerAsync(CustomerId id, int limit, CancellationToken ct = default);\n    Task<IReadOnlyList<OrderSummary>> GetPendingAsync(int limit, CancellationToken ct = default);\n}\n```\n\n**Problems with generic repositories:**\n- Can't optimize specific queries\n- No way to enforce limits\n- Hide N+1 problems\n- Make it easy to fetch too much data\n- Encourage lazy thinking about data access\n\n---\n\n## Dapper for Read-Heavy Workloads\n\nFor complex read queries, Dapper with explicit SQL is often cleaner and faster.\n\n```csharp\npublic sealed class PostgresUserReadStore : IUserReadStore\n{\n    private readonly NpgsqlDataSource _dataSource;\n\n    public PostgresUserReadStore(NpgsqlDataSource dataSource)\n    {\n        _dataSource = dataSource;\n    }\n\n    public async Task<UserProfile?> GetByIdAsync(UserId id, CancellationToken ct = default)\n    {\n        await using var connection = await _dataSource.OpenConnectionAsync(ct);\n\n        const string sql = \"\"\"\n            SELECT id, email, name, bio, created_at\n            FROM users\n            WHERE id = @Id\n            \"\"\";\n\n        var row = await connection.QuerySingleOrDefaultAsync<UserRow>(\n            sql, new { Id = id.Value });\n\n        return row?.ToUserProfile();\n    }\n\n    // Internal row type for Dapper mapping\n    private sealed class UserRow\n    {\n        public Guid id { get; set; }\n        public string email { get; set; } = null!;\n        public string name { get; set; } = null!;\n        public string? bio { get; set; }\n        public DateTime created_at { get; set; }\n\n        public UserProfile ToUserProfile() => new(\n            Id: new UserId(id),\n            Email: new EmailAddress(email),\n            Name: new PersonName(name),\n            Bio: bio,\n            CreatedAt: new DateTimeOffset(created_at, TimeSpan.Zero));\n    }\n}\n```\n\n---\n\n## When to Use EF Core vs Dapper\n\n| Scenario | Recommendation |\n|----------|---------------|\n| Simple CRUD | EF Core |\n| Complex read queries | Dapper |\n| Writes with validation | EF Core |\n| Bulk operations | Dapper or raw SQL |\n| Reporting/analytics | Dapper |\n| Domain-heavy writes | EF Core |\n\nYou can use both in the same project - EF Core for writes, Dapper for reads.\n\n---\n\n## Quick Reference\n\n| Anti-Pattern | Solution |\n|--------------|----------|\n| No row limit | Add `limit` parameter to every read method |\n| SELECT * | Project only needed columns |\n| N+1 queries | Use Include or batch queries |\n| Application joins | Do joins in SQL |\n| Cartesian explosion | Use AsSplitQuery or projection |\n| Tracking read-only data | Use AsNoTracking |\n| Generic repository | Purpose-built read/write stores |\n| Unbounded strings | Configure MaxLength in model |\n\n---\n\n## Resources\n\n- **EF Core Performance**: https://learn.microsoft.com/en-us/ef/core/performance/\n- **Dapper**: https://github.com/DapperLib/Dapper\n- **AsSplitQuery**: https://learn.microsoft.com/en-us/ef/core/querying/single-split-queries\n",
        "skills/data/efcore-patterns/SKILL.md": "---\nname: efcore-patterns\ndescription: Entity Framework Core best practices including NoTracking by default, migration management, dedicated migration services, and common pitfalls to avoid.\n---\n\n# Entity Framework Core Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up EF Core in a new project\n- Optimizing query performance\n- Managing database migrations\n- Integrating EF Core with .NET Aspire\n- Debugging change tracking issues\n\n## Core Principles\n\n1. **NoTracking by Default** - Most queries are read-only; opt-in to tracking\n2. **Never Edit Migrations Manually** - Always use CLI commands\n3. **Dedicated Migration Service** - Separate migration execution from application startup\n4. **ExecutionStrategy for Retries** - Handle transient database failures\n5. **Explicit Updates** - When NoTracking, explicitly mark entities for update\n\n---\n\n## Pattern 1: NoTracking by Default\n\nConfigure your DbContext to disable change tracking by default. This improves performance for read-heavy workloads.\n\n```csharp\npublic class ApplicationDbContext : DbContext\n{\n    public ApplicationDbContext(DbContextOptions<ApplicationDbContext> options)\n        : base(options)\n    {\n        // Disable change tracking by default for better performance on read-only queries\n        // Use .AsTracking() explicitly for queries that need to track changes\n        ChangeTracker.QueryTrackingBehavior = QueryTrackingBehavior.NoTracking;\n    }\n\n    public DbSet<Order> Orders => Set<Order>();\n    public DbSet<Customer> Customers => Set<Customer>();\n}\n```\n\n### When NoTracking is Active\n\n**Read-only queries work normally:**\n```csharp\n// ✅ Fast read - no tracking overhead\nvar orders = await dbContext.Orders\n    .Where(o => o.Status == OrderStatus.Pending)\n    .ToListAsync();\n```\n\n**Writes require explicit handling:**\n```csharp\n// ❌ WRONG - Entity not tracked, SaveChanges does nothing\nvar order = await dbContext.Orders.FirstOrDefaultAsync(o => o.Id == orderId);\norder.Status = OrderStatus.Shipped;\nawait dbContext.SaveChangesAsync(); // Nothing happens!\n\n// ✅ CORRECT - Explicitly mark entity for update\nvar order = await dbContext.Orders.FirstOrDefaultAsync(o => o.Id == orderId);\norder.Status = OrderStatus.Shipped;\ndbContext.Orders.Update(order); // Marks entire entity as modified\nawait dbContext.SaveChangesAsync();\n\n// ✅ ALSO CORRECT - Use AsTracking() for the query\nvar order = await dbContext.Orders\n    .AsTracking()\n    .FirstOrDefaultAsync(o => o.Id == orderId);\norder.Status = OrderStatus.Shipped;\nawait dbContext.SaveChangesAsync(); // Works!\n```\n\n### When to Use Tracking\n\n| Scenario | Use Tracking? | Why |\n|----------|---------------|-----|\n| Display data in UI | No | Read-only, no updates |\n| API GET endpoints | No | Returning data, no mutations |\n| Update single entity | Yes or explicit Update() | Need to save changes |\n| Complex update with navigation | Yes | Tracking handles relationships |\n| Batch operations | No + ExecuteUpdate | More efficient |\n\n### Explicit Add/Update Pattern\n\n```csharp\npublic class OrderService\n{\n    private readonly ApplicationDbContext _db;\n\n    // CREATE - Always use Add (works regardless of tracking)\n    public async Task<Order> CreateOrderAsync(Order order)\n    {\n        _db.Orders.Add(order);\n        await _db.SaveChangesAsync();\n        return order;\n    }\n\n    // UPDATE - Explicitly mark as modified\n    public async Task UpdateOrderStatusAsync(Guid orderId, OrderStatus newStatus)\n    {\n        var order = await _db.Orders.FirstOrDefaultAsync(o => o.Id == orderId)\n            ?? throw new NotFoundException($\"Order {orderId} not found\");\n\n        order.Status = newStatus;\n        order.UpdatedAt = DateTimeOffset.UtcNow;\n\n        // Explicitly mark as modified since DbContext uses NoTracking by default\n        _db.Orders.Update(order);\n        await _db.SaveChangesAsync();\n    }\n\n    // DELETE - Attach and remove\n    public async Task DeleteOrderAsync(Guid orderId)\n    {\n        var order = new Order { Id = orderId };\n        _db.Orders.Remove(order);\n        await _db.SaveChangesAsync();\n    }\n}\n```\n\n---\n\n## Pattern 2: Never Edit Migrations Manually\n\n**CRITICAL:** Always use EF Core CLI commands to manage migrations. Never:\n- Manually edit migration files (except for custom SQL in `Up()`/`Down()`)\n- Delete migration files directly\n- Rename migration files\n- Copy migrations between projects\n\n### Creating Migrations\n\n```bash\n# Create a new migration\ndotnet ef migrations add AddCustomerTable \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n\n# With a specific DbContext (if you have multiple)\ndotnet ef migrations add AddCustomerTable \\\n    --context ApplicationDbContext \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n```\n\n### Removing Migrations\n\n```bash\n# Remove the last migration (if not yet applied)\ndotnet ef migrations remove \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n\n# NEVER do this:\n# rm Migrations/20240101_AddCustomerTable.cs  # ❌ BAD!\n```\n\n### Applying Migrations\n\n```bash\n# Apply all pending migrations\ndotnet ef database update \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n\n# Apply to a specific migration\ndotnet ef database update AddCustomerTable \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n\n# Rollback to a previous migration\ndotnet ef database update PreviousMigrationName \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n```\n\n### Generating SQL Scripts\n\n```bash\n# Generate SQL script for all migrations\ndotnet ef migrations script \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api \\\n    --output migrations.sql\n\n# Generate idempotent script (safe to run multiple times)\ndotnet ef migrations script \\\n    --idempotent \\\n    --project src/MyApp.Infrastructure \\\n    --startup-project src/MyApp.Api\n```\n\n---\n\n## Pattern 3: Dedicated Migration Service with Aspire\n\nSeparate migration execution from your main application using a dedicated migration service. This ensures:\n- Migrations complete before the app starts\n- Clean separation of concerns\n- Controlled seeding in test environments\n\n### Project Structure\n\n```\nsrc/\n├── MyApp.AppHost/           # Aspire orchestration\n├── MyApp.Api/               # Main application\n├── MyApp.Infrastructure/    # DbContext and migrations\n└── MyApp.MigrationService/  # Dedicated migration runner\n```\n\n### MigrationService Program.cs\n\n```csharp\nusing MyApp.Infrastructure.Data;\nusing MyApp.MigrationService;\nusing Microsoft.EntityFrameworkCore;\n\nvar builder = Host.CreateApplicationBuilder(args);\n\n// Add Aspire service defaults\nbuilder.AddServiceDefaults();\n\n// Add PostgreSQL DbContext\nvar connectionString = builder.Configuration.GetConnectionString(\"appdb\")\n    ?? throw new InvalidOperationException(\"Connection string 'appdb' not found.\");\n\nbuilder.Services.AddDbContext<ApplicationDbContext>(options =>\n    options.UseNpgsql(connectionString, npgsqlOptions =>\n        npgsqlOptions.MigrationsAssembly(\"MyApp.Infrastructure\")));\n\n// Add the migration worker\nbuilder.Services.AddHostedService<MigrationWorker>();\n\nvar host = builder.Build();\nhost.Run();\n```\n\n### MigrationWorker.cs\n\n```csharp\npublic class MigrationWorker : BackgroundService\n{\n    private readonly IServiceProvider _serviceProvider;\n    private readonly IHostApplicationLifetime _hostApplicationLifetime;\n    private readonly ILogger<MigrationWorker> _logger;\n\n    public MigrationWorker(\n        IServiceProvider serviceProvider,\n        IHostApplicationLifetime hostApplicationLifetime,\n        ILogger<MigrationWorker> logger)\n    {\n        _serviceProvider = serviceProvider;\n        _hostApplicationLifetime = hostApplicationLifetime;\n        _logger = logger;\n    }\n\n    protected override async Task ExecuteAsync(CancellationToken stoppingToken)\n    {\n        _logger.LogInformation(\"Migration service starting...\");\n\n        try\n        {\n            using var scope = _serviceProvider.CreateScope();\n            var dbContext = scope.ServiceProvider.GetRequiredService<ApplicationDbContext>();\n\n            await RunMigrationsAsync(dbContext, stoppingToken);\n\n            _logger.LogInformation(\"Migration service completed successfully.\");\n        }\n        catch (Exception ex)\n        {\n            _logger.LogError(ex, \"Migration service failed: {Error}\", ex.Message);\n            throw;\n        }\n        finally\n        {\n            // Stop the application after migrations complete\n            _hostApplicationLifetime.StopApplication();\n        }\n    }\n\n    private async Task RunMigrationsAsync(ApplicationDbContext dbContext, CancellationToken ct)\n    {\n        // Use execution strategy for transient failure handling\n        var strategy = dbContext.Database.CreateExecutionStrategy();\n\n        await strategy.ExecuteAsync(async () =>\n        {\n            var pendingMigrations = await dbContext.Database.GetPendingMigrationsAsync(ct);\n\n            if (pendingMigrations.Any())\n            {\n                _logger.LogInformation(\"Applying {Count} pending migrations...\",\n                    pendingMigrations.Count());\n\n                await dbContext.Database.MigrateAsync(ct);\n\n                _logger.LogInformation(\"Migrations applied successfully.\");\n            }\n            else\n            {\n                _logger.LogInformation(\"No pending migrations. Database is up to date.\");\n            }\n        });\n    }\n}\n```\n\n### AppHost Configuration\n\n```csharp\nvar builder = DistributedApplication.CreateBuilder(args);\n\nvar postgres = builder.AddPostgres(\"postgres\");\nvar db = postgres.AddDatabase(\"appdb\");\n\n// Migrations run first, then exit\nvar migrations = builder.AddProject<Projects.MyApp_MigrationService>(\"migrations\")\n    .WaitFor(db)\n    .WithReference(db);\n\n// API waits for migrations to complete\nvar api = builder.AddProject<Projects.MyApp_Api>(\"api\")\n    .WaitForCompletion(migrations)  // Key: waits for migrations to finish\n    .WithReference(db);\n```\n\n---\n\n## Pattern 4: ExecutionStrategy for Transient Failures\n\nAlways use `CreateExecutionStrategy()` for operations that might fail transiently:\n\n```csharp\npublic async Task UpdateWithRetryAsync(Guid id, Action<Order> update)\n{\n    var strategy = _dbContext.Database.CreateExecutionStrategy();\n\n    await strategy.ExecuteAsync(async () =>\n    {\n        var order = await _dbContext.Orders\n            .AsTracking()\n            .FirstOrDefaultAsync(o => o.Id == id);\n\n        if (order is null) return;\n\n        update(order);\n        await _dbContext.SaveChangesAsync();\n    });\n}\n```\n\n**Important:** You cannot use `CreateExecutionStrategy()` with user-initiated transactions. If you need transactions with retry:\n\n```csharp\nvar strategy = _dbContext.Database.CreateExecutionStrategy();\n\nawait strategy.ExecuteAsync(async () =>\n{\n    // Transaction must be INSIDE the strategy callback\n    await using var transaction = await _dbContext.Database.BeginTransactionAsync();\n\n    try\n    {\n        // ... your operations ...\n        await _dbContext.SaveChangesAsync();\n        await transaction.CommitAsync();\n    }\n    catch\n    {\n        await transaction.RollbackAsync();\n        throw;\n    }\n});\n```\n\n---\n\n## Pattern 5: Bulk Operations with ExecuteUpdate/ExecuteDelete\n\nFor bulk operations, use EF Core 7+ `ExecuteUpdateAsync` and `ExecuteDeleteAsync` instead of loading entities:\n\n```csharp\n// ❌ SLOW - Loads all entities into memory\nvar expiredOrders = await _db.Orders\n    .Where(o => o.ExpiresAt < DateTimeOffset.UtcNow)\n    .ToListAsync();\n\nforeach (var order in expiredOrders)\n{\n    order.Status = OrderStatus.Expired;\n}\nawait _db.SaveChangesAsync();\n\n// ✅ FAST - Single SQL UPDATE statement\nawait _db.Orders\n    .Where(o => o.ExpiresAt < DateTimeOffset.UtcNow)\n    .ExecuteUpdateAsync(setters => setters\n        .SetProperty(o => o.Status, OrderStatus.Expired)\n        .SetProperty(o => o.UpdatedAt, DateTimeOffset.UtcNow));\n\n// ✅ FAST - Single SQL DELETE statement\nawait _db.Orders\n    .Where(o => o.Status == OrderStatus.Cancelled && o.CreatedAt < cutoffDate)\n    .ExecuteDeleteAsync();\n```\n\n---\n\n## Common Pitfalls\n\n### 1. Forgetting to Update When NoTracking\n\n```csharp\n// ❌ Silent failure - entity not tracked\nvar customer = await _db.Customers.FindAsync(id);\ncustomer.Name = \"New Name\";\nawait _db.SaveChangesAsync(); // Does nothing!\n\n// ✅ Explicit update\nvar customer = await _db.Customers.FindAsync(id);\ncustomer.Name = \"New Name\";\n_db.Customers.Update(customer);\nawait _db.SaveChangesAsync();\n```\n\n### 2. N+1 Query Problem\n\n```csharp\n// ❌ N+1 queries - one query per order\nvar customers = await _db.Customers.ToListAsync();\nforeach (var customer in customers)\n{\n    var orders = customer.Orders; // Lazy load triggers query\n}\n\n// ✅ Eager loading - single query\nvar customers = await _db.Customers\n    .Include(c => c.Orders)\n    .ToListAsync();\n```\n\n### 3. Tracking Conflicts with Multiple DbContext Instances\n\n```csharp\n// ❌ Tracking conflict - entity tracked by different context\nvar order1 = await _db1.Orders.AsTracking().FindAsync(id);\nvar order2 = await _db2.Orders.AsTracking().FindAsync(id);\norder2.Status = OrderStatus.Shipped;\nawait _db2.SaveChangesAsync(); // May throw or behave unexpectedly\n\n// ✅ Use single context or detach first\n_db1.Entry(order1).State = EntityState.Detached;\n```\n\n### 4. Not Using Async Consistently\n\n```csharp\n// ❌ Blocking call in async context\nvar orders = _db.Orders.ToList(); // Blocks thread\n\n// ✅ Async all the way\nvar orders = await _db.Orders.ToListAsync();\n```\n\n### 5. Querying Inside Loops\n\n```csharp\n// ❌ Query per iteration\nforeach (var orderId in orderIds)\n{\n    var order = await _db.Orders.FindAsync(orderId);\n    // process order\n}\n\n// ✅ Single query\nvar orders = await _db.Orders\n    .Where(o => orderIds.Contains(o.Id))\n    .ToListAsync();\n```\n\n---\n\n## DbContext Lifetime in DI\n\n### ASP.NET Core (Scoped by Default)\n\n```csharp\n// Scoped = one instance per HTTP request\nbuilder.Services.AddDbContext<ApplicationDbContext>(options =>\n    options.UseNpgsql(connectionString));\n```\n\n### Background Services (Create Scope)\n\n```csharp\npublic class MyBackgroundService : BackgroundService\n{\n    private readonly IServiceProvider _serviceProvider;\n\n    protected override async Task ExecuteAsync(CancellationToken stoppingToken)\n    {\n        // ✅ Create scope for each unit of work\n        using var scope = _serviceProvider.CreateScope();\n        var dbContext = scope.ServiceProvider.GetRequiredService<ApplicationDbContext>();\n\n        // ... use dbContext ...\n    }\n}\n```\n\n### Actors / Long-Lived Objects (Factory Pattern)\n\n```csharp\npublic class OrderActor : ReceiveActor\n{\n    private readonly IDbContextFactory<ApplicationDbContext> _dbFactory;\n\n    public OrderActor(IDbContextFactory<ApplicationDbContext> dbFactory)\n    {\n        _dbFactory = dbFactory;\n\n        ReceiveAsync<GetOrder>(async msg =>\n        {\n            // Create fresh context for each operation\n            await using var db = await _dbFactory.CreateDbContextAsync();\n            var order = await db.Orders.FindAsync(msg.OrderId);\n            Sender.Tell(order);\n        });\n    }\n}\n\n// Registration\nbuilder.Services.AddDbContextFactory<ApplicationDbContext>(options =>\n    options.UseNpgsql(connectionString));\n```\n\n---\n\n## Testing with EF Core\n\n### In-Memory Provider (Unit Tests Only)\n\n```csharp\n// Only for simple unit tests - doesn't match real database behavior\nvar options = new DbContextOptionsBuilder<ApplicationDbContext>()\n    .UseInMemoryDatabase(databaseName: Guid.NewGuid().ToString())\n    .Options;\n\nusing var context = new ApplicationDbContext(options);\n```\n\n### Real Database with TestContainers (Integration Tests)\n\nSee the `testcontainers-integration-tests` skill for proper database testing.\n\n```csharp\n// Use real PostgreSQL in container\nvar container = new PostgreSqlBuilder()\n    .WithImage(\"postgres:16-alpine\")\n    .Build();\n\nawait container.StartAsync();\n\nvar options = new DbContextOptionsBuilder<ApplicationDbContext>()\n    .UseNpgsql(container.GetConnectionString())\n    .Options;\n```\n",
        "skills/dotnet/local-tools/SKILL.md": "---\nname: dotnet-local-tools\ndescription: Managing local .NET tools with dotnet-tools.json for consistent tooling across development environments and CI/CD pipelines.\n---\n\n# .NET Local Tools\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up consistent tooling across a development team\n- Ensuring CI/CD pipelines use the same tool versions as local development\n- Managing project-specific CLI tools (docfx, incrementalist, dotnet-ef, etc.)\n- Avoiding global tool version conflicts between projects\n\n## What Are Local Tools?\n\nLocal tools are .NET CLI tools that are installed and versioned per-repository rather than globally. They're defined in `.config/dotnet-tools.json` and restored with `dotnet tool restore`.\n\n### Local vs Global Tools\n\n| Aspect | Global Tools | Local Tools |\n|--------|--------------|-------------|\n| Installation | `dotnet tool install -g` | `dotnet tool restore` |\n| Scope | Machine-wide | Per-repository |\n| Version control | Manual | In `.config/dotnet-tools.json` |\n| CI/CD | Must install each tool | Single restore command |\n| Conflicts | Can have version conflicts | Isolated per project |\n\n---\n\n## Setting Up Local Tools\n\n### Initialize the Manifest\n\n```bash\n# Create .config/dotnet-tools.json\ndotnet new tool-manifest\n```\n\nThis creates:\n```\n.config/\n└── dotnet-tools.json\n```\n\n### Install Tools Locally\n\n```bash\n# Install a tool locally\ndotnet tool install docfx\n\n# Install specific version\ndotnet tool install docfx --version 2.78.3\n\n# Install from a specific source\ndotnet tool install MyTool --add-source https://mycompany.pkgs.visualstudio.com/_packaging/feed/nuget/v3/index.json\n```\n\n### Restore Tools\n\n```bash\n# Restore all tools from manifest\ndotnet tool restore\n```\n\n---\n\n## dotnet-tools.json Format\n\n```json\n{\n  \"version\": 1,\n  \"isRoot\": true,\n  \"tools\": {\n    \"docfx\": {\n      \"version\": \"2.78.3\",\n      \"commands\": [\n        \"docfx\"\n      ],\n      \"rollForward\": false\n    },\n    \"dotnet-ef\": {\n      \"version\": \"9.0.0\",\n      \"commands\": [\n        \"dotnet-ef\"\n      ],\n      \"rollForward\": false\n    },\n    \"incrementalist.cmd\": {\n      \"version\": \"1.2.0\",\n      \"commands\": [\n        \"incrementalist\"\n      ],\n      \"rollForward\": false\n    },\n    \"dotnet-reportgenerator-globaltool\": {\n      \"version\": \"5.4.1\",\n      \"commands\": [\n        \"reportgenerator\"\n      ],\n      \"rollForward\": false\n    }\n  }\n}\n```\n\n### Fields\n\n| Field | Description |\n|-------|-------------|\n| `version` | Manifest schema version (always 1) |\n| `isRoot` | Marks this as the root manifest (prevents searching parent directories) |\n| `tools` | Dictionary of tool configurations |\n| `tools.<name>.version` | Exact version to install |\n| `tools.<name>.commands` | CLI commands the tool provides |\n| `tools.<name>.rollForward` | Allow newer versions (usually false for reproducibility) |\n\n---\n\n## Common Tools\n\n### Documentation\n\n```bash\n# DocFX - API documentation generator\ndotnet tool install docfx\n```\n\n```json\n\"docfx\": {\n  \"version\": \"2.78.3\",\n  \"commands\": [\"docfx\"],\n  \"rollForward\": false\n}\n```\n\n**Usage:**\n```bash\ndotnet docfx docfx.json\ndotnet docfx serve _site\n```\n\n### Entity Framework Core\n\n```bash\n# EF Core CLI for migrations\ndotnet tool install dotnet-ef\n```\n\n```json\n\"dotnet-ef\": {\n  \"version\": \"9.0.0\",\n  \"commands\": [\"dotnet-ef\"],\n  \"rollForward\": false\n}\n```\n\n**Usage:**\n```bash\ndotnet ef migrations add InitialCreate\ndotnet ef database update\n```\n\n### Code Coverage\n\n```bash\n# ReportGenerator for coverage reports\ndotnet tool install dotnet-reportgenerator-globaltool\n```\n\n```json\n\"dotnet-reportgenerator-globaltool\": {\n  \"version\": \"5.4.1\",\n  \"commands\": [\"reportgenerator\"],\n  \"rollForward\": false\n}\n```\n\n**Usage:**\n```bash\ndotnet reportgenerator -reports:coverage.cobertura.xml -targetdir:coveragereport -reporttypes:Html\n```\n\n### Incremental Builds\n\n```bash\n# Incrementalist - build only changed projects\ndotnet tool install incrementalist.cmd\n```\n\n```json\n\"incrementalist.cmd\": {\n  \"version\": \"1.2.0\",\n  \"commands\": [\"incrementalist\"],\n  \"rollForward\": false\n}\n```\n\n**Usage:**\n```bash\n# Get projects affected by changes since main branch\nincrementalist --branch main\n```\n\n### Code Formatting\n\n```bash\n# CSharpier - opinionated C# formatter\ndotnet tool install csharpier\n```\n\n```json\n\"csharpier\": {\n  \"version\": \"0.30.3\",\n  \"commands\": [\"dotnet-csharpier\"],\n  \"rollForward\": false\n}\n```\n\n**Usage:**\n```bash\ndotnet csharpier .\ndotnet csharpier --check .  # CI mode - fails if changes needed\n```\n\n### Code Analysis\n\n```bash\n# JB dotnet-inspect (requires license)\ndotnet tool install jb\n```\n\n```json\n\"jb\": {\n  \"version\": \"2024.3.4\",\n  \"commands\": [\"jb\"],\n  \"rollForward\": false\n}\n```\n\n---\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v4\n        with:\n          global-json-file: global.json\n\n      - name: Restore tools\n        run: dotnet tool restore\n\n      - name: Build\n        run: dotnet build\n\n      - name: Test with coverage\n        run: dotnet test --collect:\"XPlat Code Coverage\"\n\n      - name: Generate coverage report\n        run: dotnet reportgenerator -reports:**/coverage.cobertura.xml -targetdir:coveragereport\n\n      - name: Build documentation\n        run: dotnet docfx docs/docfx.json\n```\n\n### Azure Pipelines\n\n```yaml\nsteps:\n  - task: UseDotNet@2\n    inputs:\n      useGlobalJson: true\n\n  - script: dotnet tool restore\n    displayName: 'Restore .NET tools'\n\n  - script: dotnet build -c Release\n    displayName: 'Build'\n\n  - script: dotnet test -c Release --collect:\"XPlat Code Coverage\"\n    displayName: 'Test'\n\n  - script: dotnet reportgenerator -reports:**/coverage.cobertura.xml -targetdir:$(Build.ArtifactStagingDirectory)/coverage\n    displayName: 'Generate coverage report'\n```\n\n---\n\n## Managing Tool Versions\n\n### Update a Tool\n\n```bash\n# Update to latest version\ndotnet tool update docfx\n\n# Update to specific version\ndotnet tool update docfx --version 2.79.0\n```\n\n### List Installed Tools\n\n```bash\n# List local tools\ndotnet tool list\n\n# List with outdated check\ndotnet tool list --outdated\n```\n\n### Remove a Tool\n\n```bash\ndotnet tool uninstall docfx\n```\n\n---\n\n## Best Practices\n\n### 1. Always Set `isRoot: true`\n\nPrevents MSBuild from searching parent directories for tool manifests:\n\n```json\n{\n  \"version\": 1,\n  \"isRoot\": true,\n  ...\n}\n```\n\n### 2. Pin Exact Versions\n\nUse `\"rollForward\": false` for reproducible builds:\n\n```json\n\"docfx\": {\n  \"version\": \"2.78.3\",\n  \"rollForward\": false\n}\n```\n\n### 3. Restore in CI Before Use\n\nAlways run `dotnet tool restore` before using any local tool:\n\n```yaml\n- run: dotnet tool restore\n- run: dotnet docfx docs/docfx.json\n```\n\n### 4. Document Tool Requirements\n\nAdd a comment or section in README:\n\n```markdown\n## Development Setup\n\n1. Restore tools: `dotnet tool restore`\n2. Build: `dotnet build`\n3. Test: `dotnet test`\n```\n\n### 5. Use Dependabot for Updates\n\n```yaml\n# .github/dependabot.yml\nversion: 2\nupdates:\n  - package-ecosystem: \"nuget\"\n    directory: \"/\"\n    schedule:\n      interval: \"weekly\"\n    # Includes local tools in .config/dotnet-tools.json\n```\n\n---\n\n## Troubleshooting\n\n### Tool Not Found After Restore\n\nEnsure you're running from the repository root:\n\n```bash\n# Wrong - running from subdirectory\ncd src/MyApp\ndotnet docfx  # Error: tool not found\n\n# Correct - run from solution root\ncd ../..\ndotnet docfx docs/docfx.json\n```\n\n### Version Conflicts\n\nIf you see version conflicts, check for:\n1. Global tool with different version: `dotnet tool list -g`\n2. Multiple tool manifests: Look for `.config/dotnet-tools.json` in parent directories\n\n### Clearing Tool Cache\n\n```bash\n# Clear NuGet tool cache\ndotnet nuget locals all --clear\n\n# Re-restore tools\ndotnet tool restore\n```\n\n---\n\n## Example: Complete Development Setup\n\n```json\n{\n  \"version\": 1,\n  \"isRoot\": true,\n  \"tools\": {\n    \"docfx\": {\n      \"version\": \"2.78.3\",\n      \"commands\": [\"docfx\"],\n      \"rollForward\": false\n    },\n    \"dotnet-ef\": {\n      \"version\": \"9.0.0\",\n      \"commands\": [\"dotnet-ef\"],\n      \"rollForward\": false\n    },\n    \"dotnet-reportgenerator-globaltool\": {\n      \"version\": \"5.4.1\",\n      \"commands\": [\"reportgenerator\"],\n      \"rollForward\": false\n    },\n    \"csharpier\": {\n      \"version\": \"0.30.3\",\n      \"commands\": [\"dotnet-csharpier\"],\n      \"rollForward\": false\n    },\n    \"incrementalist.cmd\": {\n      \"version\": \"1.2.0\",\n      \"commands\": [\"incrementalist\"],\n      \"rollForward\": false\n    }\n  }\n}\n```\n\n**Development workflow:**\n```bash\n# Initial setup\ndotnet tool restore\n\n# Format code before commit\ndotnet csharpier .\n\n# Run tests with coverage\ndotnet test --collect:\"XPlat Code Coverage\"\ndotnet reportgenerator -reports:**/coverage.cobertura.xml -targetdir:coverage\n\n# Build documentation\ndotnet docfx docs/docfx.json\n\n# Check which projects changed (for large repos)\nincrementalist --branch main\n```\n",
        "skills/dotnet/package-management/SKILL.md": "---\nname: package-management\ndescription: Manage NuGet packages using Central Package Management (CPM) and dotnet CLI commands. Never edit XML directly - use dotnet add/remove/list commands. Use shared version variables for related packages.\n---\n\n# NuGet Package Management\n\n## When to Use This Skill\n\nUse this skill when:\n- Adding, removing, or updating NuGet packages\n- Setting up Central Package Management (CPM) for a solution\n- Managing package versions across multiple projects\n- Troubleshooting package conflicts or restore issues\n\n---\n\n## Golden Rule: Never Edit XML Directly\n\n**Always use `dotnet` CLI commands to manage packages.** Never manually edit `.csproj` or `Directory.Packages.props` files.\n\n```bash\n# DO: Use CLI commands\ndotnet add package Newtonsoft.Json\ndotnet remove package Newtonsoft.Json\ndotnet list package --outdated\n\n# DON'T: Edit XML directly\n# <PackageReference Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n```\n\n**Why:**\n- CLI validates package exists and resolves correct version\n- Handles transitive dependencies correctly\n- Updates lock files if present\n- Avoids typos and malformed XML\n- Works correctly with CPM\n\n---\n\n## Central Package Management (CPM)\n\nCPM centralizes all package versions in one file, eliminating version conflicts across projects.\n\n### Enable CPM\n\nCreate `Directory.Packages.props` in solution root:\n\n```xml\n<Project>\n  <PropertyGroup>\n    <ManagePackageVersionsCentrally>true</ManagePackageVersionsCentrally>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageVersion Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n    <PackageVersion Include=\"Serilog\" Version=\"4.0.0\" />\n    <PackageVersion Include=\"xunit\" Version=\"2.9.2\" />\n  </ItemGroup>\n</Project>\n```\n\n### Project Files with CPM\n\nProjects reference packages **without versions**:\n\n```xml\n<!-- src/MyApp/MyApp.csproj -->\n<Project Sdk=\"Microsoft.NET.Sdk\">\n  <ItemGroup>\n    <PackageReference Include=\"Newtonsoft.Json\" />\n    <PackageReference Include=\"Serilog\" />\n  </ItemGroup>\n</Project>\n```\n\n### Adding Packages with CPM\n\n```bash\n# Adds to Directory.Packages.props AND project file\ndotnet add package Serilog.Sinks.Console\n\n# Result in Directory.Packages.props:\n# <PackageVersion Include=\"Serilog.Sinks.Console\" Version=\"6.0.0\" />\n\n# Result in project file:\n# <PackageReference Include=\"Serilog.Sinks.Console\" />\n```\n\n---\n\n## Shared Version Variables\n\nGroup related packages with shared version variables:\n\n```xml\n<Project>\n  <PropertyGroup>\n    <ManagePackageVersionsCentrally>true</ManagePackageVersionsCentrally>\n  </PropertyGroup>\n\n  <!-- Shared version variables -->\n  <PropertyGroup Label=\"SharedVersions\">\n    <AkkaVersion>1.5.59</AkkaVersion>\n    <AkkaHostingVersion>1.5.59</AkkaHostingVersion>\n    <AspireVersion>9.0.0</AspireVersion>\n    <OpenTelemetryVersion>1.11.0</OpenTelemetryVersion>\n    <XunitVersion>2.9.2</XunitVersion>\n  </PropertyGroup>\n\n  <!-- Akka.NET packages - all use same version -->\n  <ItemGroup Label=\"Akka.NET\">\n    <PackageVersion Include=\"Akka\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Cluster\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Cluster.Sharding\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Cluster.Tools\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Persistence\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Streams\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Hosting\" Version=\"$(AkkaHostingVersion)\" />\n    <PackageVersion Include=\"Akka.Cluster.Hosting\" Version=\"$(AkkaHostingVersion)\" />\n  </ItemGroup>\n\n  <!-- Aspire packages -->\n  <ItemGroup Label=\"Aspire\">\n    <PackageVersion Include=\"Aspire.Hosting\" Version=\"$(AspireVersion)\" />\n    <PackageVersion Include=\"Aspire.Hosting.AppHost\" Version=\"$(AspireVersion)\" />\n    <PackageVersion Include=\"Aspire.Hosting.PostgreSQL\" Version=\"$(AspireVersion)\" />\n    <PackageVersion Include=\"Aspire.Hosting.Testing\" Version=\"$(AspireVersion)\" />\n  </ItemGroup>\n\n  <!-- OpenTelemetry packages -->\n  <ItemGroup Label=\"OpenTelemetry\">\n    <PackageVersion Include=\"OpenTelemetry.Exporter.OpenTelemetryProtocol\" Version=\"$(OpenTelemetryVersion)\" />\n    <PackageVersion Include=\"OpenTelemetry.Extensions.Hosting\" Version=\"$(OpenTelemetryVersion)\" />\n    <PackageVersion Include=\"OpenTelemetry.Instrumentation.AspNetCore\" Version=\"$(OpenTelemetryVersion)\" />\n    <PackageVersion Include=\"OpenTelemetry.Instrumentation.Http\" Version=\"$(OpenTelemetryVersion)\" />\n  </ItemGroup>\n\n  <!-- Testing -->\n  <ItemGroup Label=\"Testing\">\n    <PackageVersion Include=\"xunit\" Version=\"$(XunitVersion)\" />\n    <PackageVersion Include=\"xunit.runner.visualstudio\" Version=\"$(XunitVersion)\" />\n    <PackageVersion Include=\"FluentAssertions\" Version=\"6.12.0\" />\n    <PackageVersion Include=\"Verify.Xunit\" Version=\"26.0.0\" />\n  </ItemGroup>\n</Project>\n```\n\n**Benefits:**\n- Update all Akka packages by changing one variable\n- Clear organization with labeled ItemGroups\n- Prevents version mismatches in related packages\n\n---\n\n## When NOT to Use CPM\n\nCentral Package Management isn't always the right choice:\n\n### Legacy Projects\n\nMigrating an existing large solution to CPM can introduce issues:\n- Existing version conflicts become visible all at once\n- Some packages may have intentional version differences\n- Migration requires touching many files simultaneously\n\n**Recommendation**: For legacy projects, migrate incrementally or stick with per-project versioning if it's working.\n\n### Version Ranges\n\nCPM requires exact versions - it doesn't support version ranges:\n\n```xml\n<!-- NOT supported with CPM -->\n<PackageVersion Include=\"Newtonsoft.Json\" Version=\"[13.0,14.0)\" />\n\n<!-- Must use exact version -->\n<PackageVersion Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n```\n\nIf you need version ranges (rare, but some library scenarios require it), CPM won't work.\n\n### Older .NET Versions\n\nCPM requires:\n- **.NET SDK 6.0.300+** or later\n- **NuGet 6.2+** or later\n- **Visual Studio 2022 17.2+** or later\n\nIf you're targeting older SDK versions or have team members on older tooling, CPM may cause build failures.\n\n### Multi-Repo Solutions\n\nIf your solution spans multiple repositories that are built independently, CPM's single `Directory.Packages.props` won't help - each repo needs its own.\n\n---\n\n## CLI Command Reference\n\n### Adding Packages\n\n```bash\n# Add latest stable version\ndotnet add package Serilog\n\n# Add specific version\ndotnet add package Serilog --version 4.0.0\n\n# Add prerelease\ndotnet add package Serilog --prerelease\n\n# Add to specific project\ndotnet add src/MyApp/MyApp.csproj package Serilog\n```\n\n### Removing Packages\n\n```bash\n# Remove from current project\ndotnet remove package Serilog\n\n# Remove from specific project\ndotnet remove src/MyApp/MyApp.csproj package Serilog\n```\n\n### Listing Packages\n\n```bash\n# List all packages in solution\ndotnet list package\n\n# Show outdated packages\ndotnet list package --outdated\n\n# Include transitive dependencies\ndotnet list package --include-transitive\n\n# Show vulnerable packages\ndotnet list package --vulnerable\n\n# Show deprecated packages\ndotnet list package --deprecated\n```\n\n### Updating Packages\n\n```bash\n# With CPM: Edit the version in Directory.Packages.props\n# Then restore to apply\ndotnet restore\n\n# Without CPM: Remove and add with new version\ndotnet remove package Serilog\ndotnet add package Serilog --version 4.1.0\n\n# Or use dotnet-outdated tool (recommended)\ndotnet tool install --global dotnet-outdated-tool\ndotnet outdated --upgrade\n```\n\n### Restore and Clean\n\n```bash\n# Restore packages\ndotnet restore\n\n# Clear local cache (troubleshooting)\ndotnet nuget locals all --clear\n\n# Force restore (ignore cache)\ndotnet restore --force\n```\n\n---\n\n## Package Sources\n\n### List Sources\n\n```bash\ndotnet nuget list source\n```\n\n### Add Private Feed\n\n```bash\n# Add authenticated feed\ndotnet nuget add source https://pkgs.dev.azure.com/myorg/_packaging/myfeed/nuget/v3/index.json \\\n  --name MyFeed \\\n  --username az \\\n  --password $PAT \\\n  --store-password-in-clear-text\n```\n\n### NuGet.config\n\nFor solution-specific sources, create `NuGet.config`:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <packageSources>\n    <clear />\n    <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" />\n    <add key=\"MyPrivateFeed\" value=\"https://pkgs.dev.azure.com/myorg/_packaging/myfeed/nuget/v3/index.json\" />\n  </packageSources>\n  <packageSourceCredentials>\n    <MyPrivateFeed>\n      <add key=\"Username\" value=\"az\" />\n      <add key=\"ClearTextPassword\" value=\"%NUGET_PAT%\" />\n    </MyPrivateFeed>\n  </packageSourceCredentials>\n</configuration>\n```\n\n---\n\n## Common Patterns\n\n### Development-Only Packages\n\n```xml\n<!-- Directory.Packages.props -->\n<PackageVersion Include=\"Microsoft.SourceLink.GitHub\" Version=\"8.0.0\" />\n\n<!-- Project file - mark as development dependency -->\n<PackageReference Include=\"Microsoft.SourceLink.GitHub\" PrivateAssets=\"All\" />\n```\n\n### Conditional Packages\n\n```xml\n<!-- Only include in Debug builds -->\n<ItemGroup Condition=\"'$(Configuration)' == 'Debug'\">\n  <PackageReference Include=\"JetBrains.Annotations\" />\n</ItemGroup>\n\n<!-- Platform-specific -->\n<ItemGroup Condition=\"'$(TargetFramework)' == 'net8.0'\">\n  <PackageReference Include=\"System.Text.Json\" />\n</ItemGroup>\n```\n\n### Version Override (Escape Hatch)\n\nWhen you must override CPM for one project (rare):\n\n```xml\n<!-- Project file - use sparingly! -->\n<PackageReference Include=\"Newtonsoft.Json\" VersionOverride=\"12.0.3\" />\n```\n\n**Warning**: This is detected by Slopwatch (see `dotnet/slopwatch` skill) as potential slop.\n\n---\n\n## Troubleshooting\n\n### Version Conflicts\n\n```bash\n# See full dependency tree\ndotnet list package --include-transitive\n\n# Find what's pulling in a specific package\ndotnet list package --include-transitive | grep -i \"PackageName\"\n```\n\n### Restore Failures\n\n```bash\n# Clear all caches\ndotnet nuget locals all --clear\n\n# Restore with detailed logging\ndotnet restore --verbosity detailed\n\n# Check for locked packages\ncat packages.lock.json\n```\n\n### Lock Files\n\nFor reproducible builds, use package lock files:\n\n```xml\n<!-- Directory.Build.props -->\n<PropertyGroup>\n  <RestorePackagesWithLockFile>true</RestorePackagesWithLockFile>\n</PropertyGroup>\n```\n\nThen commit `packages.lock.json` files.\n\n---\n\n## Anti-Patterns\n\n### Don't: Edit XML Directly\n\n```xml\n<!-- BAD: Manual XML editing -->\n<PackageReference Include=\"Typo.Package\" Version=\"1.0.0\" />\n<!-- Package might not exist! CLI would catch this. -->\n```\n\n### Don't: Inline Versions with CPM\n\n```xml\n<!-- BAD: Bypasses CPM -->\n<PackageReference Include=\"Serilog\" Version=\"4.0.0\" />\n\n<!-- GOOD: Version comes from Directory.Packages.props -->\n<PackageReference Include=\"Serilog\" />\n```\n\n### Don't: Mix Version Management\n\n```xml\n<!-- BAD: Some versions in CPM, some inline -->\n<PackageReference Include=\"Serilog\" />  <!-- From CPM -->\n<PackageReference Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />  <!-- Inline -->\n```\n\n### Don't: Forget Shared Variables\n\n```xml\n<!-- BAD: Related packages with different versions -->\n<PackageVersion Include=\"Akka\" Version=\"1.5.59\" />\n<PackageVersion Include=\"Akka.Cluster\" Version=\"1.5.58\" />  <!-- Mismatch! -->\n\n<!-- GOOD: Use shared variable -->\n<PackageVersion Include=\"Akka\" Version=\"$(AkkaVersion)\" />\n<PackageVersion Include=\"Akka.Cluster\" Version=\"$(AkkaVersion)\" />\n```\n\n---\n\n## Quick Reference\n\n| Task | Command |\n|------|---------|\n| Add package | `dotnet add package <name>` |\n| Add specific version | `dotnet add package <name> --version <ver>` |\n| Remove package | `dotnet remove package <name>` |\n| List packages | `dotnet list package` |\n| Show outdated | `dotnet list package --outdated` |\n| Show vulnerable | `dotnet list package --vulnerable` |\n| Restore | `dotnet restore` |\n| Clear cache | `dotnet nuget locals all --clear` |\n\n---\n\n## Resources\n\n- **Central Package Management**: https://learn.microsoft.com/en-us/nuget/consume-packages/central-package-management\n- **dotnet CLI Reference**: https://learn.microsoft.com/en-us/dotnet/core/tools/\n- **NuGet.config Reference**: https://learn.microsoft.com/en-us/nuget/reference/nuget-config-file\n",
        "skills/dotnet/project-structure/SKILL.md": "---\nname: dotnet-project-structure\ndescription: Modern .NET project structure including .slnx solution format, Directory.Build.props, central package management, SourceLink, version management with RELEASE_NOTES.md, and SDK pinning with global.json.\n---\n\n# .NET Project Structure and Build Configuration\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up a new .NET solution with modern best practices\n- Configuring centralized build properties across multiple projects\n- Implementing central package version management\n- Setting up SourceLink for debugging and NuGet packages\n- Automating version management with release notes\n- Pinning SDK versions for consistent builds\n\n## Related Skills\n\n- **`dotnet-local-tools`** - Managing local .NET tools with dotnet-tools.json\n- **`microsoft-extensions-configuration`** - Configuration validation patterns\n\n---\n\n## Solution File Format (.slnx)\n\nThe `.slnx` format is the modern XML-based solution file format introduced in .NET 9. It replaces the traditional `.sln` format.\n\n### Benefits Over Traditional .sln\n\n| Aspect | .sln (Legacy) | .slnx (Modern) |\n|--------|---------------|----------------|\n| Format | Custom text format | Standard XML |\n| Readability | GUIDs, cryptic syntax | Clean, human-readable |\n| Version control | Hard to diff/merge | Easy to diff/merge |\n| Editing | IDE required | Any text editor |\n\n### Version Requirements\n\n| Tool | Minimum Version |\n|------|-----------------|\n| .NET SDK | 9.0.200 |\n| Visual Studio | 17.13 |\n| MSBuild | Visual Studio Build Tools 17.13 |\n\n**Note:** Starting with .NET 10, `dotnet new sln` creates `.slnx` files by default. In .NET 9, you must explicitly migrate or specify the format.\n\n### Example .slnx File\n\n```xml\n<Solution>\n  <Folder Name=\"/build/\">\n    <File Path=\"Directory.Build.props\" />\n    <File Path=\"Directory.Packages.props\" />\n    <File Path=\"global.json\" />\n    <File Path=\"NuGet.Config\" />\n    <File Path=\"README.md\" />\n  </Folder>\n  <Folder Name=\"/src/\">\n    <Project Path=\"src/MyApp/MyApp.csproj\" />\n    <Project Path=\"src/MyApp.Core/MyApp.Core.csproj\" />\n  </Folder>\n  <Folder Name=\"/tests/\">\n    <Project Path=\"tests/MyApp.Tests/MyApp.Tests.csproj\" />\n  </Folder>\n</Solution>\n```\n\n### Migrating from .sln to .slnx\n\nUse the `dotnet sln migrate` command to convert existing solutions:\n\n```bash\n# Migrate a specific solution file\ndotnet sln MySolution.sln migrate\n\n# Or if only one .sln exists in the directory, just run:\ndotnet sln migrate\n```\n\n**Important:** Do not keep both `.sln` and `.slnx` files in the same repository. This causes issues with automatic solution detection and can lead to sync problems. After migration, delete the old `.sln` file.\n\nYou can also migrate in Visual Studio:\n1. Open the solution\n2. Select the Solution in Solution Explorer\n3. Go to **File > Save Solution As...**\n4. Change \"Save as type\" to **Xml Solution File (*.slnx)**\n\n### Creating a New .slnx Solution\n\n```bash\n# .NET 10+: Creates .slnx by default\ndotnet new sln --name MySolution\n\n# .NET 9: Specify the format explicitly\ndotnet new sln --name MySolution --format slnx\n\n# Add projects (works the same for both formats)\ndotnet sln add src/MyApp/MyApp.csproj\n```\n\n### Recommendation\n\n**If you're using .NET 9.0.200 or later, migrate your solutions to .slnx.** The benefits are significant:\n- Dramatically fewer merge conflicts (no random GUIDs changing)\n- Human-readable and editable in any text editor\n- Consistent with modern `.csproj` format\n- Better diff/review experience in pull requests\n\n---\n\n## Directory.Build.props\n\n`Directory.Build.props` provides centralized build configuration that applies to all projects in a directory tree. Place it at the solution root.\n\n### Complete Example\n\n```xml\n<Project>\n  <!-- Metadata -->\n  <PropertyGroup>\n    <Authors>Your Team</Authors>\n    <Company>Your Company</Company>\n    <!-- Dynamic copyright year - updates automatically -->\n    <Copyright>Copyright © 2020-$([System.DateTime]::Now.Year) Your Company</Copyright>\n    <Product>Your Product</Product>\n    <PackageProjectUrl>https://github.com/yourorg/yourrepo</PackageProjectUrl>\n    <RepositoryUrl>https://github.com/yourorg/yourrepo</RepositoryUrl>\n    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n    <PackageTags>your;tags;here</PackageTags>\n  </PropertyGroup>\n\n  <!-- C# Language Settings -->\n  <PropertyGroup>\n    <LangVersion>latest</LangVersion>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>\n    <NoWarn>$(NoWarn);CS1591</NoWarn> <!-- Missing XML comments -->\n  </PropertyGroup>\n\n  <!-- Version Management -->\n  <PropertyGroup>\n    <VersionPrefix>1.0.0</VersionPrefix>\n    <PackageReleaseNotes>See RELEASE_NOTES.md</PackageReleaseNotes>\n  </PropertyGroup>\n\n  <!-- Target Framework Definitions (reusable properties) -->\n  <PropertyGroup>\n    <NetStandardLibVersion>netstandard2.0</NetStandardLibVersion>\n    <NetLibVersion>net8.0</NetLibVersion>\n    <NetTestVersion>net9.0</NetTestVersion>\n  </PropertyGroup>\n\n  <!-- SourceLink Configuration -->\n  <PropertyGroup>\n    <PublishRepositoryUrl>true</PublishRepositoryUrl>\n    <EmbedUntrackedSources>true</EmbedUntrackedSources>\n    <IncludeSymbols>true</IncludeSymbols>\n    <SymbolPackageFormat>snupkg</SymbolPackageFormat>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include=\"Microsoft.SourceLink.GitHub\" PrivateAssets=\"All\" />\n  </ItemGroup>\n\n  <!-- NuGet Package Assets -->\n  <ItemGroup>\n    <None Include=\"$(MSBuildThisFileDirectory)logo.png\" Pack=\"true\" PackagePath=\"\\\" />\n    <None Include=\"$(MSBuildThisFileDirectory)README.md\" Pack=\"true\" PackagePath=\"\\\" />\n  </ItemGroup>\n\n  <PropertyGroup>\n    <PackageIcon>logo.png</PackageIcon>\n    <PackageReadmeFile>README.md</PackageReadmeFile>\n  </PropertyGroup>\n\n  <!-- Global Using Statements -->\n  <ItemGroup>\n    <Using Include=\"System.Collections.Immutable\" />\n  </ItemGroup>\n</Project>\n```\n\n### Key Patterns\n\n#### Dynamic Copyright Year\n\n```xml\n<Copyright>Copyright © 2020-$([System.DateTime]::Now.Year) Your Company</Copyright>\n```\n\nUses MSBuild property functions to insert current year at build time. No manual updates needed.\n\n#### Reusable Target Framework Properties\n\nDefine target frameworks once, reference everywhere:\n\n```xml\n<!-- In Directory.Build.props -->\n<PropertyGroup>\n  <NetLibVersion>net8.0</NetLibVersion>\n  <NetTestVersion>net9.0</NetTestVersion>\n</PropertyGroup>\n\n<!-- In MyApp.csproj -->\n<PropertyGroup>\n  <TargetFramework>$(NetLibVersion)</TargetFramework>\n</PropertyGroup>\n\n<!-- In MyApp.Tests.csproj -->\n<PropertyGroup>\n  <TargetFramework>$(NetTestVersion)</TargetFramework>\n</PropertyGroup>\n```\n\n#### SourceLink for NuGet Packages\n\nSourceLink enables step-through debugging of NuGet packages:\n\n```xml\n<PropertyGroup>\n  <PublishRepositoryUrl>true</PublishRepositoryUrl>\n  <EmbedUntrackedSources>true</EmbedUntrackedSources>\n  <IncludeSymbols>true</IncludeSymbols>\n  <SymbolPackageFormat>snupkg</SymbolPackageFormat>\n</PropertyGroup>\n\n<ItemGroup>\n  <!-- Choose the right provider for your source control -->\n  <PackageReference Include=\"Microsoft.SourceLink.GitHub\" PrivateAssets=\"All\" />\n  <!-- Or: Microsoft.SourceLink.AzureRepos.Git -->\n  <!-- Or: Microsoft.SourceLink.GitLab -->\n  <!-- Or: Microsoft.SourceLink.Bitbucket.Git -->\n</ItemGroup>\n```\n\n---\n\n## Directory.Packages.props - Central Package Management\n\nCentral Package Management (CPM) provides a single source of truth for all NuGet package versions.\n\n### Setup\n\n```xml\n<Project>\n  <PropertyGroup>\n    <ManagePackageVersionsCentrally>true</ManagePackageVersionsCentrally>\n  </PropertyGroup>\n\n  <!-- Define version variables for related packages -->\n  <PropertyGroup>\n    <AkkaVersion>1.5.35</AkkaVersion>\n    <AspireVersion>9.1.0</AspireVersion>\n  </PropertyGroup>\n\n  <!-- Application Dependencies -->\n  <ItemGroup Label=\"App Dependencies\">\n    <PackageVersion Include=\"Akka\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Cluster\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Akka.Persistence\" Version=\"$(AkkaVersion)\" />\n    <PackageVersion Include=\"Microsoft.Extensions.Hosting\" Version=\"9.0.0\" />\n  </ItemGroup>\n\n  <!-- Build/Tooling Dependencies -->\n  <ItemGroup Label=\"Build Dependencies\">\n    <PackageVersion Include=\"Microsoft.SourceLink.GitHub\" Version=\"8.0.0\" />\n  </ItemGroup>\n\n  <!-- Test Dependencies -->\n  <ItemGroup Label=\"Test Dependencies\">\n    <PackageVersion Include=\"xunit\" Version=\"2.9.3\" />\n    <PackageVersion Include=\"xunit.runner.visualstudio\" Version=\"3.0.1\" />\n    <PackageVersion Include=\"FluentAssertions\" Version=\"7.0.0\" />\n    <PackageVersion Include=\"Microsoft.NET.Test.Sdk\" Version=\"17.12.0\" />\n    <PackageVersion Include=\"coverlet.collector\" Version=\"6.0.3\" />\n  </ItemGroup>\n</Project>\n```\n\n### Consuming Packages (No Version Needed)\n\n```xml\n<!-- In MyApp.csproj -->\n<ItemGroup>\n  <PackageReference Include=\"Akka\" />\n  <PackageReference Include=\"Akka.Cluster\" />\n  <PackageReference Include=\"Microsoft.Extensions.Hosting\" />\n</ItemGroup>\n\n<!-- In MyApp.Tests.csproj -->\n<ItemGroup>\n  <PackageReference Include=\"xunit\" />\n  <PackageReference Include=\"FluentAssertions\" />\n  <PackageReference Include=\"Microsoft.NET.Test.Sdk\" />\n</ItemGroup>\n```\n\n### Benefits\n\n1. **Single source of truth** - All versions in one file\n2. **No version drift** - All projects use same versions\n3. **Easy updates** - Change once, applies everywhere\n4. **Grouped packages** - Version variables for related packages (e.g., all Akka packages)\n\n---\n\n## global.json - SDK Version Pinning\n\nPin the .NET SDK version for consistent builds across all environments.\n\n```json\n{\n  \"sdk\": {\n    \"version\": \"9.0.200\",\n    \"rollForward\": \"latestFeature\"\n  }\n}\n```\n\n### Roll Forward Policies\n\n| Policy | Behavior |\n|--------|----------|\n| `disable` | Exact version required |\n| `patch` | Same major.minor, latest patch |\n| `feature` | Same major, latest minor.patch |\n| `latestFeature` | Same major, latest feature band |\n| `minor` | Same major, latest minor |\n| `latestMinor` | Same major, latest minor |\n| `major` | Latest SDK (not recommended) |\n\n**Recommended:** `latestFeature` - Allows patch updates within the same feature band.\n\n---\n\n## Version Management with RELEASE_NOTES.md\n\n### Release Notes Format\n\n```markdown\n#### 1.2.0 January 15th 2025 ####\n\n- Added new feature X\n- Fixed bug in Y\n- Improved performance of Z\n\n#### 1.1.0 December 10th 2024 ####\n\n- Initial release with features A, B, C\n```\n\n### Parsing Script (getReleaseNotes.ps1)\n\n```powershell\nfunction Get-ReleaseNotes {\n    param (\n        [Parameter(Mandatory=$true)]\n        [string]$MarkdownFile\n    )\n\n    $content = Get-Content -Path $MarkdownFile -Raw\n    $sections = $content -split \"####\"\n\n    $result = [PSCustomObject]@{\n        Version      = $null\n        Date         = $null\n        ReleaseNotes = $null\n    }\n\n    if ($sections.Count -ge 3) {\n        $header = $sections[1].Trim()\n        $releaseNotes = $sections[2].Trim()\n\n        $headerParts = $header -split \" \", 2\n        if ($headerParts.Count -eq 2) {\n            $result.Version = $headerParts[0]\n            $result.Date = $headerParts[1]\n        }\n\n        $result.ReleaseNotes = $releaseNotes\n    }\n\n    return $result\n}\n```\n\n### Version Bump Script (bumpVersion.ps1)\n\n```powershell\nfunction UpdateVersionAndReleaseNotes {\n    param (\n        [Parameter(Mandatory=$true)]\n        [PSCustomObject]$ReleaseNotesResult,\n        [Parameter(Mandatory=$true)]\n        [string]$XmlFilePath\n    )\n\n    $xmlContent = New-Object XML\n    $xmlContent.Load($XmlFilePath)\n\n    # Update VersionPrefix\n    $versionElement = $xmlContent.SelectSingleNode(\"//VersionPrefix\")\n    $versionElement.InnerText = $ReleaseNotesResult.Version\n\n    # Update PackageReleaseNotes\n    $notesElement = $xmlContent.SelectSingleNode(\"//PackageReleaseNotes\")\n    $notesElement.InnerText = $ReleaseNotesResult.ReleaseNotes\n\n    $xmlContent.Save($XmlFilePath)\n}\n```\n\n### Build Script (build.ps1)\n\n```powershell\n# Load helper scripts\n. \"$PSScriptRoot\\scripts\\getReleaseNotes.ps1\"\n. \"$PSScriptRoot\\scripts\\bumpVersion.ps1\"\n\n# Parse release notes and update Directory.Build.props\n$releaseNotes = Get-ReleaseNotes -MarkdownFile (Join-Path -Path $PSScriptRoot -ChildPath \"RELEASE_NOTES.md\")\nUpdateVersionAndReleaseNotes -ReleaseNotesResult $releaseNotes -XmlFilePath (Join-Path -Path $PSScriptRoot -ChildPath \"Directory.Build.props\")\n\nWrite-Output \"Updated to version $($releaseNotes.Version)\"\n```\n\n### CI/CD Integration\n\n```yaml\n# GitHub Actions example\n- name: Update version from release notes\n  shell: pwsh\n  run: ./build.ps1\n\n- name: Build\n  run: dotnet build -c Release\n\n- name: Pack with tag version\n  run: dotnet pack -c Release /p:PackageVersion=${{ github.ref_name }}\n\n- name: Push to NuGet\n  run: dotnet nuget push **/*.nupkg --api-key ${{ secrets.NUGET_API_KEY }} --source https://api.nuget.org/v3/index.json\n```\n\n---\n\n## NuGet.Config\n\nConfigure NuGet sources and behavior:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <solution>\n    <add key=\"disableSourceControlIntegration\" value=\"true\" />\n  </solution>\n\n  <packageSources>\n    <clear />\n    <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" />\n    <!-- Add private feeds if needed -->\n    <!-- <add key=\"MyCompany\" value=\"https://pkgs.dev.azure.com/myorg/_packaging/myfeed/nuget/v3/index.json\" /> -->\n  </packageSources>\n</configuration>\n```\n\n**Key Settings:**\n- `<clear />` - Remove inherited/default sources for reproducible builds\n- `disableSourceControlIntegration` - Prevents TFS/Git integration issues\n\n---\n\n## Complete Project Structure\n\n```\nMySolution/\n├── .config/\n│   └── dotnet-tools.json           # Local .NET tools\n├── .github/\n│   └── workflows/\n│       ├── pr-validation.yml       # PR checks\n│       └── release.yml             # NuGet publishing\n├── scripts/\n│   ├── getReleaseNotes.ps1         # Parse RELEASE_NOTES.md\n│   └── bumpVersion.ps1             # Update Directory.Build.props\n├── src/\n│   ├── MyApp/\n│   │   └── MyApp.csproj\n│   └── MyApp.Core/\n│       └── MyApp.Core.csproj\n├── tests/\n│   └── MyApp.Tests/\n│       └── MyApp.Tests.csproj\n├── Directory.Build.props           # Centralized build config\n├── Directory.Packages.props        # Central package versions\n├── MySolution.slnx                 # Modern solution file\n├── global.json                     # SDK version pinning\n├── NuGet.Config                    # Package source config\n├── build.ps1                       # Build orchestration\n├── RELEASE_NOTES.md                # Version history\n├── README.md                       # Project documentation\n└── logo.png                        # Package icon\n```\n\n---\n\n## Quick Reference\n\n| File | Purpose |\n|------|---------|\n| `MySolution.slnx` | Modern XML solution file |\n| `Directory.Build.props` | Centralized build properties |\n| `Directory.Packages.props` | Central package version management |\n| `global.json` | SDK version pinning |\n| `NuGet.Config` | Package source configuration |\n| `RELEASE_NOTES.md` | Version history (parsed by build) |\n| `build.ps1` | Build orchestration script |\n| `.config/dotnet-tools.json` | Local .NET tools |\n",
        "skills/dotnet/serialization/SKILL.md": "---\nname: serialization\ndescription: Choose the right serialization format for .NET applications. Prefer schema-based formats (Protobuf, MessagePack) over reflection-based (Newtonsoft.Json). Use System.Text.Json with AOT source generators for JSON scenarios.\n---\n\n# Serialization in .NET\n\n## When to Use This Skill\n\nUse this skill when:\n- Choosing a serialization format for APIs, messaging, or persistence\n- Migrating from Newtonsoft.Json to System.Text.Json\n- Implementing AOT-compatible serialization\n- Designing wire formats for distributed systems\n- Optimizing serialization performance\n\n---\n\n## Schema-Based vs Reflection-Based\n\n| Aspect | Schema-Based | Reflection-Based |\n|--------|--------------|------------------|\n| **Examples** | Protobuf, MessagePack, System.Text.Json (source gen) | Newtonsoft.Json, BinaryFormatter |\n| **Type info in payload** | No (external schema) | Yes (type names embedded) |\n| **Versioning** | Explicit field numbers/names | Implicit (type structure) |\n| **Performance** | Fast (no reflection) | Slower (runtime reflection) |\n| **AOT compatible** | Yes | No |\n| **Wire compatibility** | Excellent | Poor |\n\n**Recommendation**: Use schema-based serialization for anything that crosses process boundaries.\n\n---\n\n## Format Recommendations\n\n| Use Case | Recommended Format | Why |\n|----------|-------------------|-----|\n| **REST APIs** | System.Text.Json (source gen) | Standard, AOT-compatible |\n| **gRPC** | Protocol Buffers | Native format, excellent versioning |\n| **Actor messaging** | MessagePack or Protobuf | Compact, fast, version-safe |\n| **Event sourcing** | Protobuf or MessagePack | Must handle old events forever |\n| **Caching** | MessagePack | Compact, fast |\n| **Configuration** | JSON (System.Text.Json) | Human-readable |\n| **Logging** | JSON (System.Text.Json) | Structured, parseable |\n\n### Formats to Avoid\n\n| Format | Problem |\n|--------|---------|\n| **BinaryFormatter** | Security vulnerabilities, deprecated, never use |\n| **Newtonsoft.Json default** | Type names in payload break on rename |\n| **DataContractSerializer** | Complex, poor versioning |\n| **XML** | Verbose, slow, complex |\n\n---\n\n## System.Text.Json with Source Generators\n\nFor JSON serialization, use System.Text.Json with source generators for AOT compatibility and performance.\n\n### Setup\n\n```csharp\n// Define a JsonSerializerContext with all your types\n[JsonSerializable(typeof(Order))]\n[JsonSerializable(typeof(OrderItem))]\n[JsonSerializable(typeof(Customer))]\n[JsonSerializable(typeof(List<Order>))]\n[JsonSourceGenerationOptions(\n    PropertyNamingPolicy = JsonKnownNamingPolicy.CamelCase,\n    DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull)]\npublic partial class AppJsonContext : JsonSerializerContext { }\n```\n\n### Usage\n\n```csharp\n// Serialize with context\nvar json = JsonSerializer.Serialize(order, AppJsonContext.Default.Order);\n\n// Deserialize with context\nvar order = JsonSerializer.Deserialize(json, AppJsonContext.Default.Order);\n\n// Configure in ASP.NET Core\nbuilder.Services.ConfigureHttpJsonOptions(options =>\n{\n    options.SerializerOptions.TypeInfoResolverChain.Insert(0, AppJsonContext.Default);\n});\n```\n\n### Benefits\n\n- **No reflection at runtime** - All type info generated at compile time\n- **AOT compatible** - Works with Native AOT publishing\n- **Faster** - No runtime type analysis\n- **Trim-safe** - Linker knows exactly what's needed\n\n---\n\n## Protocol Buffers (Protobuf)\n\nBest for: Actor systems, gRPC, event sourcing, any long-lived wire format.\n\n### Setup\n\n```bash\ndotnet add package Google.Protobuf\ndotnet add package Grpc.Tools\n```\n\n### Define Schema\n\n```protobuf\n// orders.proto\nsyntax = \"proto3\";\n\nmessage Order {\n    string id = 1;\n    string customer_id = 2;\n    repeated OrderItem items = 3;\n    int64 created_at_ticks = 4;\n\n    // Adding new fields is always safe\n    string notes = 5;  // Added in v2 - old readers ignore it\n}\n\nmessage OrderItem {\n    string product_id = 1;\n    int32 quantity = 2;\n    int64 price_cents = 3;\n}\n```\n\n### Versioning Rules\n\n```protobuf\n// SAFE: Add new fields with new numbers\nmessage Order {\n    string id = 1;\n    string customer_id = 2;\n    string shipping_address = 5;  // NEW - safe\n}\n\n// SAFE: Remove fields (old readers ignore unknown, new readers use default)\n// Just stop using the field, keep the number reserved\nmessage Order {\n    string id = 1;\n    // customer_id removed, but field 2 is reserved\n    reserved 2;\n}\n\n// UNSAFE: Change field types\nmessage Order {\n    int32 id = 1;  // Was: string - BREAKS!\n}\n\n// UNSAFE: Reuse field numbers\nmessage Order {\n    reserved 2;\n    string new_field = 2;  // Reusing 2 - BREAKS!\n}\n```\n\n---\n\n## MessagePack\n\nBest for: High-performance scenarios, compact payloads, actor messaging.\n\n### Setup\n\n```bash\ndotnet add package MessagePack\ndotnet add package MessagePack.Annotations\n```\n\n### Usage with Contracts\n\n```csharp\n[MessagePackObject]\npublic sealed class Order\n{\n    [Key(0)]\n    public required string Id { get; init; }\n\n    [Key(1)]\n    public required string CustomerId { get; init; }\n\n    [Key(2)]\n    public required IReadOnlyList<OrderItem> Items { get; init; }\n\n    [Key(3)]\n    public required DateTimeOffset CreatedAt { get; init; }\n\n    // New field - old readers skip unknown keys\n    [Key(4)]\n    public string? Notes { get; init; }\n}\n\n// Serialize\nvar bytes = MessagePackSerializer.Serialize(order);\n\n// Deserialize\nvar order = MessagePackSerializer.Deserialize<Order>(bytes);\n```\n\n### AOT-Compatible Setup\n\n```csharp\n// Use source generator for AOT\n[MessagePackObject]\npublic partial class Order { }  // partial enables source gen\n\n// Configure resolver\nvar options = MessagePackSerializerOptions.Standard\n    .WithResolver(CompositeResolver.Create(\n        GeneratedResolver.Instance,  // Generated\n        StandardResolver.Instance));\n```\n\n---\n\n## Migrating from Newtonsoft.Json\n\n### Common Issues\n\n| Newtonsoft | System.Text.Json | Fix |\n|------------|------------------|-----|\n| `$type` in JSON | Not supported by default | Use discriminators or custom converters |\n| `JsonProperty` | `JsonPropertyName` | Different attribute |\n| `DefaultValueHandling` | `DefaultIgnoreCondition` | Different API |\n| `NullValueHandling` | `DefaultIgnoreCondition` | Different API |\n| Private setters | Requires `[JsonInclude]` | Explicit opt-in |\n| Polymorphism | `[JsonDerivedType]` (.NET 7+) | Explicit discriminators |\n\n### Migration Pattern\n\n```csharp\n// Newtonsoft (reflection-based)\npublic class Order\n{\n    [JsonProperty(\"order_id\")]\n    public string Id { get; set; }\n\n    [JsonProperty(NullValueHandling = NullValueHandling.Ignore)]\n    public string? Notes { get; set; }\n}\n\n// System.Text.Json (source-gen compatible)\npublic sealed record Order(\n    [property: JsonPropertyName(\"order_id\")]\n    string Id,\n\n    string? Notes  // Null handling via JsonSerializerOptions\n);\n\n[JsonSerializable(typeof(Order))]\n[JsonSourceGenerationOptions(\n    PropertyNamingPolicy = JsonKnownNamingPolicy.SnakeCaseLower,\n    DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull)]\npublic partial class OrderJsonContext : JsonSerializerContext { }\n```\n\n### Polymorphism with Discriminators\n\n```csharp\n// .NET 7+ polymorphism\n[JsonDerivedType(typeof(CreditCardPayment), \"credit_card\")]\n[JsonDerivedType(typeof(BankTransferPayment), \"bank_transfer\")]\npublic abstract record Payment(decimal Amount);\n\npublic sealed record CreditCardPayment(decimal Amount, string Last4) : Payment(Amount);\npublic sealed record BankTransferPayment(decimal Amount, string AccountNumber) : Payment(Amount);\n\n// Serializes as:\n// { \"$type\": \"credit_card\", \"amount\": 100, \"last4\": \"1234\" }\n```\n\n---\n\n## Wire Compatibility Patterns\n\n### Tolerant Reader\n\nOld code must safely ignore unknown fields:\n\n```csharp\n// Protobuf/MessagePack: Automatic - unknown fields skipped\n// System.Text.Json: Configure to allow\nvar options = new JsonSerializerOptions\n{\n    UnmappedMemberHandling = JsonUnmappedMemberHandling.Skip\n};\n```\n\n### Introduce Read Before Write\n\nDeploy deserializers before serializers for new formats:\n\n```csharp\n// Phase 1: Add deserializer (deployed everywhere)\npublic Order Deserialize(byte[] data, string manifest) => manifest switch\n{\n    \"Order.V1\" => DeserializeV1(data),\n    \"Order.V2\" => DeserializeV2(data),  // NEW - can read V2\n    _ => throw new NotSupportedException()\n};\n\n// Phase 2: Enable serializer (next release, after V1 deployed everywhere)\npublic (byte[] data, string manifest) Serialize(Order order) =>\n    _useV2Format\n        ? (SerializeV2(order), \"Order.V2\")\n        : (SerializeV1(order), \"Order.V1\");\n```\n\n### Never Embed Type Names\n\n```csharp\n// BAD: Type name in payload - renaming class breaks wire format\n{\n    \"$type\": \"MyApp.Order, MyApp.Core\",\n    \"id\": \"123\"\n}\n\n// GOOD: Explicit discriminator - refactoring safe\n{\n    \"type\": \"order\",\n    \"id\": \"123\"\n}\n```\n\n---\n\n## Performance Comparison\n\nApproximate throughput (higher is better):\n\n| Format | Serialize | Deserialize | Size |\n|--------|-----------|-------------|------|\n| MessagePack | ★★★★★ | ★★★★★ | ★★★★★ |\n| Protobuf | ★★★★★ | ★★★★★ | ★★★★★ |\n| System.Text.Json (source gen) | ★★★★☆ | ★★★★☆ | ★★★☆☆ |\n| System.Text.Json (reflection) | ★★★☆☆ | ★★★☆☆ | ★★★☆☆ |\n| Newtonsoft.Json | ★★☆☆☆ | ★★☆☆☆ | ★★★☆☆ |\n\nFor hot paths, prefer MessagePack or Protobuf.\n\n---\n\n## Akka.NET Serialization\n\nFor Akka.NET actor systems, use schema-based serialization:\n\n```hocon\nakka {\n  actor {\n    serializers {\n      messagepack = \"Akka.Serialization.MessagePackSerializer, Akka.Serialization.MessagePack\"\n    }\n    serialization-bindings {\n      \"MyApp.Messages.IMessage, MyApp\" = messagepack\n    }\n  }\n}\n```\n\nSee [Akka.NET Serialization Docs](https://getakka.net/articles/networking/serialization.html).\n\n---\n\n## Best Practices\n\n### DO\n\n```csharp\n// Use source generators for System.Text.Json\n[JsonSerializable(typeof(Order))]\npublic partial class AppJsonContext : JsonSerializerContext { }\n\n// Use explicit field numbers/keys\n[MessagePackObject]\npublic class Order\n{\n    [Key(0)] public string Id { get; init; }\n}\n\n// Use records for immutable message types\npublic sealed record OrderCreated(OrderId Id, CustomerId CustomerId);\n```\n\n### DON'T\n\n```csharp\n// Don't use BinaryFormatter (ever)\nvar formatter = new BinaryFormatter();  // Security risk!\n\n// Don't embed type names in wire format\nsettings.TypeNameHandling = TypeNameHandling.All;  // Breaks on rename!\n\n// Don't use reflection serialization for hot paths\nJsonConvert.SerializeObject(order);  // Slow, not AOT-compatible\n```\n\n---\n\n## Resources\n\n- **System.Text.Json Source Generation**: https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation\n- **Protocol Buffers**: https://protobuf.dev/\n- **MessagePack-CSharp**: https://github.com/MessagePack-CSharp/MessagePack-CSharp\n- **Akka.NET Serialization**: https://getakka.net/articles/networking/serialization.html\n- **Wire Compatibility**: https://getakka.net/community/contributing/wire-compatibility.html\n",
        "skills/dotnet/slopwatch/SKILL.md": "---\nname: dotnet-slopwatch\ndescription: Use Slopwatch to detect LLM reward hacking in .NET code changes. Run after every code modification to catch disabled tests, suppressed warnings, empty catch blocks, and other shortcuts that mask real problems.\n---\n\n# Slopwatch: LLM Anti-Cheat for .NET\n\n## When to Use This Skill\n\n**Use this skill constantly.** Every time an LLM (including Claude) makes changes to:\n- C# source files (.cs)\n- Project files (.csproj)\n- Props files (Directory.Build.props, Directory.Packages.props)\n- Test files\n\nRun slopwatch to validate the changes don't introduce \"slop.\"\n\n## What is Slop?\n\n\"Slop\" refers to shortcuts LLMs take that make tests pass or builds succeed without actually solving the underlying problem. These are reward hacking behaviors - the LLM optimizes for apparent success rather than real fixes.\n\n### Common Slop Patterns\n\n| Pattern | Example | Why It's Bad |\n|---------|---------|--------------|\n| Disabled tests | `[Fact(Skip=\"flaky\")]` | Hides failures instead of fixing them |\n| Warning suppression | `#pragma warning disable CS8618` | Silences compiler without fixing issue |\n| Empty catch blocks | `catch (Exception) { }` | Swallows errors, hides bugs |\n| Arbitrary delays | `await Task.Delay(1000);` | Masks race conditions, makes tests slow |\n| Project-level suppression | `<NoWarn>CS1591</NoWarn>` | Disables warnings project-wide |\n| CPM bypass | `Version=\"1.0.0\"` inline | Undermines central package management |\n\n**Never accept these patterns.** If an LLM introduces slop, reject the change and require a proper fix.\n\n---\n\n## Installation\n\n### As a Local Tool (Recommended)\n\nAdd to `.config/dotnet-tools.json`:\n\n```json\n{\n  \"version\": 1,\n  \"isRoot\": true,\n  \"tools\": {\n    \"slopwatch.cmd\": {\n      \"version\": \"0.2.0\",\n      \"commands\": [\"slopwatch\"],\n      \"rollForward\": false\n    }\n  }\n}\n```\n\nThen restore:\n```bash\ndotnet tool restore\n```\n\n### As a Global Tool\n\n```bash\ndotnet tool install --global Slopwatch.Cmd\n```\n\n---\n\n## First-Time Setup: Establish a Baseline\n\nBefore using slopwatch on an existing project, create a baseline of current issues:\n\n```bash\n# Initialize baseline from existing code\nslopwatch init\n\n# This creates .slopwatch/baseline.json\ngit add .slopwatch/baseline.json\ngit commit -m \"Add slopwatch baseline\"\n```\n\n**Why baseline?** Legacy code may have existing issues. The baseline ensures slopwatch only catches **new** slop being introduced, not pre-existing technical debt.\n\n---\n\n## Usage During LLM Sessions\n\n### After Every Code Change\n\nRun slopwatch after any LLM-generated code modification:\n\n```bash\n# Analyze for new issues (uses baseline)\nslopwatch analyze\n\n# Use strict mode - fail on warnings too\nslopwatch analyze --fail-on warning\n```\n\n### When Slopwatch Flags an Issue\n\n**Do not ignore it.** Instead:\n\n1. **Understand why** the LLM took the shortcut\n2. **Request a proper fix** - be specific about what's wrong\n3. **Verify the fix** doesn't introduce different slop\n\n```\n# Example: LLM disabled a test\n❌ SW001 [Error]: Disabled test detected\n   File: tests/MyApp.Tests/OrderTests.cs:45\n   Pattern: [Fact(Skip=\"Test is flaky\")]\n\n# Correct response: Ask for actual fix\n\"This test was disabled instead of fixed. Please investigate why\nit's flaky and fix the underlying timing/race condition issue.\"\n```\n\n### Updating the Baseline (Rare)\n\nOnly update the baseline when slop is **truly justified** and documented:\n\n```bash\n# Add current detections to baseline (use sparingly!)\nslopwatch analyze --update-baseline\n```\n\n**Justification examples:**\n- Third-party library forces a pattern (e.g., must suppress specific warning)\n- Intentional delay for rate limiting (not test flakiness)\n- Generated code that can't be modified\n\nDocument why in a code comment when updating baseline.\n\n---\n\n## Claude Code Hook Integration\n\nAdd slopwatch as a hook to automatically validate every edit. Create or update `.claude/settings.json`:\n\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"slopwatch analyze -d . --hook\",\n            \"timeout\": 60000\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\nThe `--hook` flag:\n- Only analyzes **git dirty files** (fast, even on large repos)\n- Outputs errors to stderr in readable format\n- Blocks the edit on warnings/errors (exit code 2)\n- Claude sees the error and can fix it immediately\n\n---\n\n## CI/CD Integration\n\nAdd slopwatch to your CI pipeline as a quality gate:\n\n### GitHub Actions\n\n```yaml\njobs:\n  slopwatch:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: '9.0.x'\n\n      - name: Install Slopwatch\n        run: dotnet tool install --global Slopwatch.Cmd\n\n      - name: Run Slopwatch\n        run: slopwatch analyze -d . --fail-on warning\n```\n\n### Azure Pipelines\n\n```yaml\n- task: DotNetCoreCLI@2\n  displayName: 'Install Slopwatch'\n  inputs:\n    command: 'custom'\n    custom: 'tool'\n    arguments: 'install --global Slopwatch.Cmd'\n\n- script: slopwatch analyze -d . --fail-on warning\n  displayName: 'Slopwatch Analysis'\n```\n\n---\n\n## Detection Rules\n\n| Rule | Severity | What It Catches |\n|------|----------|-----------------|\n| SW001 | Error | Disabled tests (`Skip=`, `Ignore`, `#if false`) |\n| SW002 | Warning | Warning suppression (`#pragma warning disable`, `SuppressMessage`) |\n| SW003 | Error | Empty catch blocks that swallow exceptions |\n| SW004 | Warning | Arbitrary delays in tests (`Task.Delay`, `Thread.Sleep`) |\n| SW005 | Warning | Project file slop (`NoWarn`, `TreatWarningsAsErrors=false`) |\n| SW006 | Warning | CPM bypass (`VersionOverride`, inline `Version` attributes) |\n\n---\n\n## Configuration\n\nCreate `.slopwatch/slopwatch.json` to customize:\n\n```json\n{\n  \"minSeverity\": \"warning\",\n  \"rules\": {\n    \"SW001\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW002\": { \"enabled\": true, \"severity\": \"warning\" },\n    \"SW003\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW004\": { \"enabled\": true, \"severity\": \"warning\" },\n    \"SW005\": { \"enabled\": true, \"severity\": \"warning\" },\n    \"SW006\": { \"enabled\": true, \"severity\": \"warning\" }\n  },\n  \"exclude\": [\n    \"**/Generated/**\",\n    \"**/obj/**\",\n    \"**/bin/**\"\n  ]\n}\n```\n\n### Strict Mode (Recommended for LLM Sessions)\n\nFor maximum protection during LLM coding sessions, elevate all rules to errors:\n\n```json\n{\n  \"minSeverity\": \"warning\",\n  \"rules\": {\n    \"SW001\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW002\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW003\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW004\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW005\": { \"enabled\": true, \"severity\": \"error\" },\n    \"SW006\": { \"enabled\": true, \"severity\": \"error\" }\n  }\n}\n```\n\n---\n\n## The Philosophy: Zero Tolerance for New Slop\n\n1. **Baseline captures legacy** - Existing issues are acknowledged but isolated\n2. **New slop is blocked** - Any new shortcut fails the build/edit\n3. **Exceptions require justification** - If you must update baseline, document why\n4. **LLMs are not special** - The same rules apply to human and AI-generated code\n\nThe goal is to prevent the gradual accumulation of technical debt that occurs when LLMs optimize for \"make the test pass\" rather than \"fix the actual problem.\"\n\n---\n\n## Quick Reference\n\n```bash\n# First time setup\nslopwatch init\ngit add .slopwatch/baseline.json\n\n# After every LLM code change\nslopwatch analyze\n\n# Strict mode (recommended)\nslopwatch analyze --fail-on warning\n\n# With stats (performance debugging)\nslopwatch analyze --stats\n\n# Update baseline (rare, document why)\nslopwatch analyze --update-baseline\n\n# JSON output for tooling\nslopwatch analyze --output json\n```\n\n---\n\n## When to Override (Almost Never)\n\nThe only valid reasons to update baseline or disable a rule:\n\n| Scenario | Action | Required |\n|----------|--------|----------|\n| Third-party forces pattern | Update baseline | Code comment explaining why |\n| Generated code (not editable) | Add to exclude list | Document in config |\n| Intentional rate limiting delay | Update baseline | Code comment, not in test |\n| Legacy code cleanup | One-time baseline update | PR description |\n\n**Invalid reasons:**\n- \"The test is flaky\" → Fix the flakiness\n- \"The warning is annoying\" → Fix the code\n- \"It works on my machine\" → Fix the race condition\n- \"We'll fix it later\" → Fix it now\n",
        "skills/meta/marketplace-publishing/SKILL.md": "---\nname: marketplace-publishing\ndescription: Workflow for publishing skills and agents to the dotnet-skills Claude Code marketplace. Covers adding new content, updating plugin.json, validation, and release tagging.\n---\n\n# Marketplace Publishing Workflow\n\nThis skill documents how to publish skills and agents to the dotnet-skills Claude Code marketplace.\n\n## Repository Structure\n\n```\ndotnet-skills/\n├── .claude-plugin/\n│   ├── marketplace.json      # Marketplace catalog\n│   └── plugin.json           # Plugin metadata + skill/agent registry\n├── .github/workflows/\n│   └── release.yml           # Release automation\n├── skills/\n│   ├── akka/                 # Akka.NET skills\n│   │   ├── best-practices/SKILL.md\n│   │   ├── testing-patterns/SKILL.md\n│   │   └── ...\n│   ├── aspire/               # .NET Aspire skills\n│   ├── csharp/               # C# language skills\n│   ├── testing/              # Testing framework skills\n│   └── meta/                 # Meta skills\n├── agents/\n│   └── *.md                  # Agent definitions\n└── scripts/\n    └── validate-marketplace.sh\n```\n\n## Adding a New Skill\n\n### Step 1: Choose a Category\n\nSkills are organized by domain:\n\n| Category | Purpose |\n|----------|---------|\n| `akka/` | Akka.NET actor patterns, testing, clustering |\n| `aspire/` | .NET Aspire orchestration, testing, configuration |\n| `csharp/` | C# language features, coding standards |\n| `testing/` | Testing frameworks (xUnit, Playwright, Testcontainers) |\n| `meta/` | Meta skills about this marketplace |\n\nCreate a new category folder if none fits.\n\n### Step 2: Create the Skill Folder\n\nCreate a folder with `SKILL.md` inside:\n\n```\nskills/<category>/<skill-name>/SKILL.md\n```\n\nExample: `skills/akka/cluster-sharding/SKILL.md`\n\n### Step 3: Write the SKILL.md\n\n```markdown\n---\nname: my-new-skill\ndescription: Brief description of what this skill does and when to use it.\n---\n\n# My New Skill\n\n## When to Use This Skill\n\nUse this skill when:\n- [List specific scenarios]\n\n---\n\n## Content\n\n[Comprehensive guide with examples, patterns, and anti-patterns]\n```\n\n**Requirements:**\n- `name` must be lowercase with hyphens (e.g., `cluster-sharding`)\n- `description` should be 1-2 sentences explaining when Claude should use this skill\n- Content should be 10-40KB covering the topic comprehensively\n- Include concrete code examples with modern C# patterns\n\n### Step 4: Register in plugin.json\n\nAdd the skill path to `.claude-plugin/plugin.json` in the `skills` array:\n\n```json\n{\n  \"skills\": [\n    \"./skills/akka/best-practices\",\n    \"./skills/akka/cluster-sharding\"  // Add new skill here\n  ]\n}\n```\n\n### Step 5: Validate\n\nRun the validation script:\n\n```bash\n./scripts/validate-marketplace.sh\n```\n\n### Step 6: Commit Together\n\n```bash\ngit add skills/akka/cluster-sharding/ .claude-plugin/plugin.json\ngit commit -m \"Add cluster-sharding skill for Akka.NET Cluster Sharding patterns\"\n```\n\n---\n\n## Adding a New Agent\n\n### Step 1: Create the Agent File\n\nCreate a markdown file in `/agents/`:\n\n```markdown\n---\nname: my-agent-name\ndescription: Expert in [domain]. Specializes in [specific areas]. Use for [scenarios].\nmodel: sonnet\ncolor: blue\n---\n\nYou are a [domain] specialist with deep expertise in [areas].\n\n**Reference Materials:**\n- [Official docs and resources]\n\n**Core Expertise Areas:**\n[List expertise areas]\n\n**Diagnostic Approach:**\n[How the agent analyzes problems]\n```\n\n**Requirements:**\n- `name` must be lowercase with hyphens\n- `model` must be one of: `haiku`, `sonnet`, `opus`\n- `color` is optional (used for UI display)\n\n### Step 2: Register in plugin.json\n\nAdd to the `agents` array:\n\n```json\n{\n  \"agents\": [\n    \"./agents/akka-net-specialist\",\n    \"./agents/my-agent-name\"  // Add new agent here\n  ]\n}\n```\n\n### Step 3: Commit Together\n\n```bash\ngit add agents/my-agent-name.md .claude-plugin/plugin.json\ngit commit -m \"Add my-agent-name agent for [domain] expertise\"\n```\n\n---\n\n## Publishing a Release\n\n### Versioning\n\nUpdate the version in `.claude-plugin/plugin.json`:\n\n```json\n{\n  \"version\": \"1.1.0\"\n}\n```\n\nUse semantic versioning (`MAJOR.MINOR.PATCH`):\n- **MAJOR**: Breaking changes (renamed/removed skills)\n- **MINOR**: New skills or agents added\n- **PATCH**: Fixes or improvements to existing content\n\n### Release Process\n\n1. **Update version in plugin.json**\n\n2. **Validate**\n   ```bash\n   ./scripts/validate-marketplace.sh\n   ```\n\n3. **Commit version bump**\n   ```bash\n   git add .claude-plugin/plugin.json\n   git commit -m \"Bump version to 1.1.0\"\n   ```\n\n4. **Create and push tag**\n   ```bash\n   git tag v1.1.0\n   git push origin master --tags\n   ```\n\n5. **GitHub Actions will automatically:**\n   - Validate the marketplace structure\n   - Create a GitHub release with auto-generated notes\n\n---\n\n## User Installation\n\nUsers install the complete plugin (all skills and agents):\n\n```bash\n# Add the marketplace (one-time)\n/plugin marketplace add Aaronontheweb/dotnet-skills\n\n# Install the plugin (gets everything)\n/plugin install dotnet-skills\n\n# Update to latest version\n/plugin marketplace update\n```\n\n---\n\n## Validation Checklist\n\nBefore committing:\n\n- [ ] SKILL.md has valid YAML frontmatter with `name` and `description`\n- [ ] Skill folder is under appropriate category\n- [ ] Path added to `plugin.json` skills array\n- [ ] For agents: `model` is specified (haiku/sonnet/opus)\n- [ ] `./scripts/validate-marketplace.sh` passes\n\n---\n\n## Troubleshooting\n\n### Skill not appearing after install\n\n- Verify the path in plugin.json matches the folder structure\n- Check that SKILL.md exists in the folder\n- Try reinstalling: `/plugin uninstall dotnet-skills && /plugin install dotnet-skills`\n\n### Validation errors\n\n- Ensure JSON is valid: `jq . .claude-plugin/plugin.json`\n- Check for trailing commas in arrays\n- Verify all referenced folders contain SKILL.md\n\n### Release not created\n\n- Ensure tag follows semver format (`v1.0.0`)\n- Check GitHub Actions logs for errors\n- Verify plugin.json version matches the tag\n",
        "skills/microsoft-extensions/configuration/SKILL.md": "---\nname: microsoft-extensions-configuration\ndescription: Microsoft.Extensions.Options patterns including IValidateOptions, strongly-typed settings, validation on startup, and the Options pattern for clean configuration management.\n---\n\n# Microsoft.Extensions Configuration Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Binding configuration from appsettings.json to strongly-typed classes\n- Validating configuration at application startup (fail fast)\n- Implementing complex validation logic for settings\n- Designing configuration classes that are testable and maintainable\n- Understanding IOptions<T>, IOptionsSnapshot<T>, and IOptionsMonitor<T>\n\n## Why Configuration Validation Matters\n\n**The Problem:** Applications often fail at runtime due to misconfiguration - missing connection strings, invalid URLs, out-of-range values. These failures happen deep in business logic, far from where configuration is loaded, making debugging difficult.\n\n**The Solution:** Validate configuration at startup. If configuration is invalid, the application fails immediately with a clear error message. This is the \"fail fast\" principle.\n\n```csharp\n// BAD: Fails at runtime when someone tries to use the service\npublic class EmailService\n{\n    public EmailService(IOptions<SmtpSettings> options)\n    {\n        var settings = options.Value;\n        // Throws NullReferenceException 10 minutes into production\n        _client = new SmtpClient(settings.Host, settings.Port);\n    }\n}\n\n// GOOD: Fails at startup with clear error\n// \"SmtpSettings validation failed: Host is required\"\n```\n\n---\n\n## Pattern 1: Basic Options Binding\n\n### Define a Settings Class\n\n```csharp\npublic class SmtpSettings\n{\n    public const string SectionName = \"Smtp\";\n\n    public string Host { get; set; } = string.Empty;\n    public int Port { get; set; } = 587;\n    public string? Username { get; set; }\n    public string? Password { get; set; }\n    public bool UseSsl { get; set; } = true;\n}\n```\n\n### Bind from Configuration\n\n```csharp\n// In Program.cs or service registration\nbuilder.Services.AddOptions<SmtpSettings>()\n    .BindConfiguration(SmtpSettings.SectionName);\n\n// appsettings.json\n{\n  \"Smtp\": {\n    \"Host\": \"smtp.example.com\",\n    \"Port\": 587,\n    \"Username\": \"user@example.com\",\n    \"Password\": \"secret\",\n    \"UseSsl\": true\n  }\n}\n```\n\n### Consume in Services\n\n```csharp\npublic class EmailService\n{\n    private readonly SmtpSettings _settings;\n\n    // IOptions<T> - singleton, read once at startup\n    public EmailService(IOptions<SmtpSettings> options)\n    {\n        _settings = options.Value;\n    }\n}\n```\n\n---\n\n## Pattern 2: Data Annotations Validation\n\nFor simple validation rules, use Data Annotations:\n\n```csharp\nusing System.ComponentModel.DataAnnotations;\n\npublic class SmtpSettings\n{\n    public const string SectionName = \"Smtp\";\n\n    [Required(ErrorMessage = \"SMTP host is required\")]\n    public string Host { get; set; } = string.Empty;\n\n    [Range(1, 65535, ErrorMessage = \"Port must be between 1 and 65535\")]\n    public int Port { get; set; } = 587;\n\n    [EmailAddress(ErrorMessage = \"Username must be a valid email address\")]\n    public string? Username { get; set; }\n\n    public string? Password { get; set; }\n\n    public bool UseSsl { get; set; } = true;\n}\n```\n\n### Enable Data Annotations Validation\n\n```csharp\nbuilder.Services.AddOptions<SmtpSettings>()\n    .BindConfiguration(SmtpSettings.SectionName)\n    .ValidateDataAnnotations()  // Enable attribute-based validation\n    .ValidateOnStart();         // Validate immediately at startup\n```\n\n**Key Point:** `.ValidateOnStart()` is critical. Without it, validation only runs when the options are first accessed, which could be minutes or hours into application runtime.\n\n---\n\n## Pattern 3: IValidateOptions<T> for Complex Validation\n\nData Annotations work for simple rules, but complex validation requires `IValidateOptions<T>`:\n\n### When to Use IValidateOptions\n\n| Scenario | Data Annotations | IValidateOptions |\n|----------|------------------|------------------|\n| Required field | ✅ | ✅ |\n| Range check | ✅ | ✅ |\n| Regex pattern | ✅ | ✅ |\n| Cross-property validation | ❌ | ✅ |\n| Conditional validation | ❌ | ✅ |\n| External service checks | ❌ | ✅ |\n| Custom error messages with context | Limited | ✅ |\n| Dependency injection in validator | ❌ | ✅ |\n\n### Implementing IValidateOptions\n\n```csharp\nusing Microsoft.Extensions.Options;\n\npublic class SmtpSettingsValidator : IValidateOptions<SmtpSettings>\n{\n    public ValidateOptionsResult Validate(string? name, SmtpSettings options)\n    {\n        var failures = new List<string>();\n\n        // Required field validation\n        if (string.IsNullOrWhiteSpace(options.Host))\n        {\n            failures.Add(\"Host is required\");\n        }\n\n        // Range validation\n        if (options.Port is < 1 or > 65535)\n        {\n            failures.Add($\"Port {options.Port} is invalid. Must be between 1 and 65535\");\n        }\n\n        // Cross-property validation\n        if (!string.IsNullOrEmpty(options.Username) && string.IsNullOrEmpty(options.Password))\n        {\n            failures.Add(\"Password is required when Username is specified\");\n        }\n\n        // Conditional validation\n        if (options.UseSsl && options.Port == 25)\n        {\n            failures.Add(\"Port 25 is typically not used with SSL. Consider port 465 or 587\");\n        }\n\n        // Return result\n        return failures.Count > 0\n            ? ValidateOptionsResult.Fail(failures)\n            : ValidateOptionsResult.Success;\n    }\n}\n```\n\n### Register the Validator\n\n```csharp\nbuilder.Services.AddOptions<SmtpSettings>()\n    .BindConfiguration(SmtpSettings.SectionName)\n    .ValidateDataAnnotations()  // Run attribute validation first\n    .ValidateOnStart();\n\n// Register the custom validator\nbuilder.Services.AddSingleton<IValidateOptions<SmtpSettings>, SmtpSettingsValidator>();\n```\n\n**Order matters:** Data Annotations run first, then IValidateOptions validators. All failures are collected and reported together.\n\n---\n\n## Pattern 4: Validators with Dependencies\n\nIValidateOptions validators are resolved from DI, so they can have dependencies:\n\n```csharp\npublic class DatabaseSettingsValidator : IValidateOptions<DatabaseSettings>\n{\n    private readonly ILogger<DatabaseSettingsValidator> _logger;\n    private readonly IHostEnvironment _environment;\n\n    public DatabaseSettingsValidator(\n        ILogger<DatabaseSettingsValidator> logger,\n        IHostEnvironment environment)\n    {\n        _logger = logger;\n        _environment = environment;\n    }\n\n    public ValidateOptionsResult Validate(string? name, DatabaseSettings options)\n    {\n        var failures = new List<string>();\n\n        if (string.IsNullOrWhiteSpace(options.ConnectionString))\n        {\n            failures.Add(\"ConnectionString is required\");\n        }\n\n        // Environment-specific validation\n        if (_environment.IsProduction())\n        {\n            if (options.ConnectionString?.Contains(\"localhost\") == true)\n            {\n                failures.Add(\"Production cannot use localhost database\");\n            }\n\n            if (!options.ConnectionString?.Contains(\"Encrypt=True\") == true)\n            {\n                _logger.LogWarning(\"Production database connection should use encryption\");\n            }\n        }\n\n        // Validate connection string format\n        if (!string.IsNullOrEmpty(options.ConnectionString))\n        {\n            try\n            {\n                var builder = new SqlConnectionStringBuilder(options.ConnectionString);\n                if (string.IsNullOrEmpty(builder.DataSource))\n                {\n                    failures.Add(\"ConnectionString must specify a Data Source\");\n                }\n            }\n            catch (Exception ex)\n            {\n                failures.Add($\"ConnectionString is malformed: {ex.Message}\");\n            }\n        }\n\n        return failures.Count > 0\n            ? ValidateOptionsResult.Fail(failures)\n            : ValidateOptionsResult.Success;\n    }\n}\n```\n\n---\n\n## Pattern 5: Named Options\n\nWhen you have multiple instances of the same settings type (e.g., multiple database connections):\n\n```csharp\n// appsettings.json\n{\n  \"Databases\": {\n    \"Primary\": {\n      \"ConnectionString\": \"Server=primary;...\"\n    },\n    \"Replica\": {\n      \"ConnectionString\": \"Server=replica;...\"\n    }\n  }\n}\n\n// Registration\nbuilder.Services.AddOptions<DatabaseSettings>(\"Primary\")\n    .BindConfiguration(\"Databases:Primary\")\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n\nbuilder.Services.AddOptions<DatabaseSettings>(\"Replica\")\n    .BindConfiguration(\"Databases:Replica\")\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n\n// Consumption\npublic class DataService\n{\n    private readonly DatabaseSettings _primary;\n    private readonly DatabaseSettings _replica;\n\n    public DataService(IOptionsSnapshot<DatabaseSettings> options)\n    {\n        _primary = options.Get(\"Primary\");\n        _replica = options.Get(\"Replica\");\n    }\n}\n```\n\n### Named Options Validator\n\n```csharp\npublic class DatabaseSettingsValidator : IValidateOptions<DatabaseSettings>\n{\n    public ValidateOptionsResult Validate(string? name, DatabaseSettings options)\n    {\n        var failures = new List<string>();\n        var prefix = string.IsNullOrEmpty(name) ? \"\" : $\"[{name}] \";\n\n        if (string.IsNullOrWhiteSpace(options.ConnectionString))\n        {\n            failures.Add($\"{prefix}ConnectionString is required\");\n        }\n\n        // Name-specific validation\n        if (name == \"Primary\" && options.ReadOnly)\n        {\n            failures.Add(\"Primary database cannot be read-only\");\n        }\n\n        return failures.Count > 0\n            ? ValidateOptionsResult.Fail(failures)\n            : ValidateOptionsResult.Success;\n    }\n}\n```\n\n---\n\n## Pattern 6: Options Lifetime\n\nUnderstanding the three options interfaces:\n\n| Interface | Lifetime | Reloads on Change | Use Case |\n|-----------|----------|-------------------|----------|\n| `IOptions<T>` | Singleton | No | Static config, read once |\n| `IOptionsSnapshot<T>` | Scoped | Yes (per request) | Web apps needing fresh config |\n| `IOptionsMonitor<T>` | Singleton | Yes (with callback) | Background services, real-time updates |\n\n### IOptionsMonitor for Background Services\n\n```csharp\npublic class BackgroundWorker : BackgroundService\n{\n    private readonly IOptionsMonitor<WorkerSettings> _optionsMonitor;\n    private WorkerSettings _currentSettings;\n\n    public BackgroundWorker(IOptionsMonitor<WorkerSettings> optionsMonitor)\n    {\n        _optionsMonitor = optionsMonitor;\n        _currentSettings = optionsMonitor.CurrentValue;\n\n        // Subscribe to configuration changes\n        _optionsMonitor.OnChange(settings =>\n        {\n            _currentSettings = settings;\n            _logger.LogInformation(\"Worker settings updated: Interval={Interval}\",\n                settings.PollingInterval);\n        });\n    }\n\n    protected override async Task ExecuteAsync(CancellationToken stoppingToken)\n    {\n        while (!stoppingToken.IsCancellationRequested)\n        {\n            await DoWorkAsync();\n            await Task.Delay(_currentSettings.PollingInterval, stoppingToken);\n        }\n    }\n}\n```\n\n---\n\n## Pattern 7: Post-Configuration\n\nModify options after binding but before validation:\n\n```csharp\nbuilder.Services.AddOptions<ApiSettings>()\n    .BindConfiguration(\"Api\")\n    .PostConfigure(options =>\n    {\n        // Ensure BaseUrl ends with /\n        if (!string.IsNullOrEmpty(options.BaseUrl) && !options.BaseUrl.EndsWith('/'))\n        {\n            options.BaseUrl += '/';\n        }\n\n        // Set defaults based on environment\n        options.Timeout ??= TimeSpan.FromSeconds(30);\n    })\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n```\n\n### PostConfigure with Dependencies\n\n```csharp\nbuilder.Services.AddOptions<ApiSettings>()\n    .BindConfiguration(\"Api\")\n    .PostConfigure<IHostEnvironment>((options, env) =>\n    {\n        if (env.IsDevelopment())\n        {\n            options.Timeout = TimeSpan.FromMinutes(5); // Longer timeout for debugging\n        }\n    });\n```\n\n---\n\n## Pattern 8: Complete Example - Production Settings Class\n\n```csharp\nusing System.ComponentModel.DataAnnotations;\nusing Microsoft.Extensions.Options;\n\npublic class AkkaSettings\n{\n    public const string SectionName = \"AkkaSettings\";\n\n    [Required]\n    public string ActorSystemName { get; set; } = \"MySystem\";\n\n    public AkkaExecutionMode ExecutionMode { get; set; } = AkkaExecutionMode.LocalTest;\n\n    public bool LogConfigOnStart { get; set; } = false;\n\n    public RemoteOptions RemoteOptions { get; set; } = new();\n\n    public ClusterOptions ClusterOptions { get; set; } = new();\n\n    public ClusterBootstrapOptions ClusterBootstrapOptions { get; set; } = new();\n}\n\npublic enum AkkaExecutionMode\n{\n    LocalTest,   // No remoting, no clustering\n    Clustered    // Full cluster with sharding, distributed pub/sub\n}\n\npublic class AkkaSettingsValidator : IValidateOptions<AkkaSettings>\n{\n    private readonly IHostEnvironment _environment;\n\n    public AkkaSettingsValidator(IHostEnvironment environment)\n    {\n        _environment = environment;\n    }\n\n    public ValidateOptionsResult Validate(string? name, AkkaSettings options)\n    {\n        var failures = new List<string>();\n\n        // Basic validation\n        if (string.IsNullOrWhiteSpace(options.ActorSystemName))\n        {\n            failures.Add(\"ActorSystemName is required\");\n        }\n\n        // Mode-specific validation\n        if (options.ExecutionMode == AkkaExecutionMode.Clustered)\n        {\n            ValidateClusteredMode(options, failures);\n        }\n\n        // Environment-specific validation\n        if (_environment.IsProduction() && options.ExecutionMode == AkkaExecutionMode.LocalTest)\n        {\n            failures.Add(\"LocalTest execution mode is not allowed in production\");\n        }\n\n        return failures.Count > 0\n            ? ValidateOptionsResult.Fail(failures)\n            : ValidateOptionsResult.Success;\n    }\n\n    private void ValidateClusteredMode(AkkaSettings options, List<string> failures)\n    {\n        if (string.IsNullOrEmpty(options.RemoteOptions.PublicHostName))\n        {\n            failures.Add(\"RemoteOptions.PublicHostName is required in Clustered mode\");\n        }\n\n        if (options.RemoteOptions.Port is null or < 0)\n        {\n            failures.Add(\"RemoteOptions.Port must be >= 0 in Clustered mode\");\n        }\n\n        if (options.ClusterBootstrapOptions.Enabled)\n        {\n            ValidateClusterBootstrap(options.ClusterBootstrapOptions, failures);\n        }\n        else if (options.ClusterOptions.SeedNodes?.Length == 0)\n        {\n            failures.Add(\"Either ClusterBootstrap must be enabled or SeedNodes must be specified\");\n        }\n    }\n\n    private void ValidateClusterBootstrap(ClusterBootstrapOptions options, List<string> failures)\n    {\n        if (string.IsNullOrEmpty(options.ServiceName))\n        {\n            failures.Add(\"ClusterBootstrapOptions.ServiceName is required\");\n        }\n\n        if (options.RequiredContactPointsNr <= 0)\n        {\n            failures.Add(\"ClusterBootstrapOptions.RequiredContactPointsNr must be > 0\");\n        }\n\n        switch (options.DiscoveryMethod)\n        {\n            case DiscoveryMethod.Config:\n                if (options.ConfigServiceEndpoints?.Length == 0)\n                {\n                    failures.Add(\"ConfigServiceEndpoints required for Config discovery\");\n                }\n                break;\n\n            case DiscoveryMethod.AzureTableStorage:\n                if (options.AzureDiscoveryOptions == null)\n                {\n                    failures.Add(\"AzureDiscoveryOptions required for Azure discovery\");\n                }\n                break;\n        }\n    }\n}\n\n// Registration\nbuilder.Services.AddOptions<AkkaSettings>()\n    .BindConfiguration(AkkaSettings.SectionName)\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n\nbuilder.Services.AddSingleton<IValidateOptions<AkkaSettings>, AkkaSettingsValidator>();\n```\n\n---\n\n## Anti-Patterns to Avoid\n\n### 1. Manual Configuration Access\n\n```csharp\n// BAD: Bypasses validation, hard to test\npublic class MyService\n{\n    public MyService(IConfiguration configuration)\n    {\n        var host = configuration[\"Smtp:Host\"]; // No validation!\n    }\n}\n\n// GOOD: Strongly-typed, validated\npublic class MyService\n{\n    public MyService(IOptions<SmtpSettings> options)\n    {\n        var host = options.Value.Host; // Validated at startup\n    }\n}\n```\n\n### 2. Validation in Constructor\n\n```csharp\n// BAD: Validation happens at runtime, not startup\npublic class MyService\n{\n    public MyService(IOptions<Settings> options)\n    {\n        if (string.IsNullOrEmpty(options.Value.Required))\n            throw new ArgumentException(\"Required is missing\"); // Too late!\n    }\n}\n\n// GOOD: Validation at startup\nbuilder.Services.AddOptions<Settings>()\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n```\n\n### 3. Forgetting ValidateOnStart\n\n```csharp\n// BAD: Validation only runs when first accessed\nbuilder.Services.AddOptions<Settings>()\n    .ValidateDataAnnotations(); // Missing ValidateOnStart!\n\n// GOOD: Fails immediately if invalid\nbuilder.Services.AddOptions<Settings>()\n    .ValidateDataAnnotations()\n    .ValidateOnStart();\n```\n\n### 4. Throwing in IValidateOptions\n\n```csharp\n// BAD: Throws exception, breaks validation chain\npublic ValidateOptionsResult Validate(string? name, Settings options)\n{\n    if (options.Value < 0)\n        throw new ArgumentException(\"Value cannot be negative\"); // Wrong!\n\n    return ValidateOptionsResult.Success;\n}\n\n// GOOD: Return failure result\npublic ValidateOptionsResult Validate(string? name, Settings options)\n{\n    if (options.Value < 0)\n        return ValidateOptionsResult.Fail(\"Value cannot be negative\");\n\n    return ValidateOptionsResult.Success;\n}\n```\n\n---\n\n## Testing Configuration Validators\n\n```csharp\npublic class SmtpSettingsValidatorTests\n{\n    private readonly SmtpSettingsValidator _validator = new();\n\n    [Fact]\n    public void Validate_WithValidSettings_ReturnsSuccess()\n    {\n        var settings = new SmtpSettings\n        {\n            Host = \"smtp.example.com\",\n            Port = 587,\n            Username = \"user@example.com\",\n            Password = \"secret\"\n        };\n\n        var result = _validator.Validate(null, settings);\n\n        result.Succeeded.Should().BeTrue();\n    }\n\n    [Fact]\n    public void Validate_WithMissingHost_ReturnsFail()\n    {\n        var settings = new SmtpSettings { Host = \"\" };\n\n        var result = _validator.Validate(null, settings);\n\n        result.Succeeded.Should().BeFalse();\n        result.FailureMessage.Should().Contain(\"Host is required\");\n    }\n\n    [Fact]\n    public void Validate_WithUsernameButNoPassword_ReturnsFail()\n    {\n        var settings = new SmtpSettings\n        {\n            Host = \"smtp.example.com\",\n            Username = \"user@example.com\",\n            Password = null  // Missing!\n        };\n\n        var result = _validator.Validate(null, settings);\n\n        result.Succeeded.Should().BeFalse();\n        result.FailureMessage.Should().Contain(\"Password is required\");\n    }\n}\n```\n\n---\n\n## Summary\n\n| Principle | Implementation |\n|-----------|----------------|\n| Fail fast | `.ValidateOnStart()` |\n| Strongly-typed | Bind to POCO classes |\n| Simple validation | Data Annotations |\n| Complex validation | `IValidateOptions<T>` |\n| Cross-property rules | `IValidateOptions<T>` |\n| Environment-aware | Inject `IHostEnvironment` |\n| Testable | Validators are plain classes |\n",
        "skills/microsoft-extensions/dependency-injection/SKILL.md": "---\nname: dependency-injection-patterns\ndescription: Organize DI registrations using IServiceCollection extension methods. Group related services into composable Add* methods for clean Program.cs and reusable configuration in tests.\n---\n\n# Dependency Injection Patterns\n\n## When to Use This Skill\n\nUse this skill when:\n- Organizing service registrations in ASP.NET Core applications\n- Avoiding massive Program.cs/Startup.cs files with hundreds of registrations\n- Making service configuration reusable between production and tests\n- Designing libraries that integrate with Microsoft.Extensions.DependencyInjection\n\n---\n\n## The Problem\n\nWithout organization, Program.cs becomes unmanageable:\n\n```csharp\n// BAD: 200+ lines of unorganized registrations\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddScoped<IUserRepository, UserRepository>();\nbuilder.Services.AddScoped<IOrderRepository, OrderRepository>();\nbuilder.Services.AddScoped<IProductRepository, ProductRepository>();\nbuilder.Services.AddScoped<IUserService, UserService>();\nbuilder.Services.AddScoped<IOrderService, OrderService>();\nbuilder.Services.AddScoped<IEmailSender, SmtpEmailSender>();\nbuilder.Services.AddScoped<IEmailComposer, MjmlEmailComposer>();\nbuilder.Services.AddSingleton<IEmailLinkGenerator, EmailLinkGenerator>();\nbuilder.Services.AddScoped<IPaymentProcessor, StripePaymentProcessor>();\nbuilder.Services.AddScoped<IInvoiceGenerator, InvoiceGenerator>();\n// ... 150 more lines ...\n```\n\nProblems:\n- Hard to find related registrations\n- No clear boundaries between subsystems\n- Can't reuse configuration in tests\n- Merge conflicts in team settings\n- No encapsulation of internal dependencies\n\n---\n\n## The Solution: Extension Method Composition\n\nGroup related registrations into extension methods:\n\n```csharp\n// GOOD: Clean, composable Program.cs\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddUserServices()\n    .AddOrderServices()\n    .AddEmailServices()\n    .AddPaymentServices()\n    .AddValidators();\n\nvar app = builder.Build();\n```\n\nEach `Add*` method encapsulates a cohesive set of registrations.\n\n---\n\n## Extension Method Pattern\n\n### Basic Structure\n\n```csharp\nnamespace MyApp.Users;\n\npublic static class UserServiceCollectionExtensions\n{\n    public static IServiceCollection AddUserServices(this IServiceCollection services)\n    {\n        // Repositories\n        services.AddScoped<IUserRepository, UserRepository>();\n        services.AddScoped<IUserReadStore, UserReadStore>();\n        services.AddScoped<IUserWriteStore, UserWriteStore>();\n\n        // Services\n        services.AddScoped<IUserService, UserService>();\n        services.AddScoped<IUserValidationService, UserValidationService>();\n\n        // Return for chaining\n        return services;\n    }\n}\n```\n\n### With Configuration\n\n```csharp\nnamespace MyApp.Email;\n\npublic static class EmailServiceCollectionExtensions\n{\n    public static IServiceCollection AddEmailServices(\n        this IServiceCollection services,\n        string configSectionName = \"EmailSettings\")\n    {\n        // Bind configuration\n        services.AddOptions<EmailOptions>()\n            .BindConfiguration(configSectionName)\n            .ValidateDataAnnotations()\n            .ValidateOnStart();\n\n        // Register services\n        services.AddSingleton<IMjmlTemplateRenderer, MjmlTemplateRenderer>();\n        services.AddSingleton<IEmailLinkGenerator, EmailLinkGenerator>();\n        services.AddScoped<IUserEmailComposer, UserEmailComposer>();\n        services.AddScoped<IOrderEmailComposer, OrderEmailComposer>();\n\n        // SMTP client depends on environment\n        services.AddScoped<IEmailSender, SmtpEmailSender>();\n\n        return services;\n    }\n}\n```\n\n### With Dependencies on Other Extensions\n\n```csharp\nnamespace MyApp.Orders;\n\npublic static class OrderServiceCollectionExtensions\n{\n    public static IServiceCollection AddOrderServices(this IServiceCollection services)\n    {\n        // This subsystem depends on email services\n        // Caller is responsible for calling AddEmailServices() first\n        // Or we can call it here if it's idempotent\n\n        services.AddScoped<IOrderRepository, OrderRepository>();\n        services.AddScoped<IOrderService, OrderService>();\n        services.AddScoped<IOrderEmailNotifier, OrderEmailNotifier>();\n\n        return services;\n    }\n}\n```\n\n---\n\n## File Organization\n\nPlace extension methods near the services they register:\n\n```\nsrc/\n  MyApp.Api/\n    Program.cs                    # Composes all Add* methods\n  MyApp.Users/\n    Services/\n      UserService.cs\n      IUserService.cs\n    Repositories/\n      UserRepository.cs\n    UserServiceCollectionExtensions.cs   # AddUserServices()\n  MyApp.Orders/\n    Services/\n      OrderService.cs\n    OrderServiceCollectionExtensions.cs  # AddOrderServices()\n  MyApp.Email/\n    Composers/\n      UserEmailComposer.cs\n    EmailServiceCollectionExtensions.cs  # AddEmailServices()\n```\n\n**Convention**: `{Feature}ServiceCollectionExtensions.cs` next to the feature's services.\n\n---\n\n## Naming Conventions\n\n| Pattern | Use For |\n|---------|---------|\n| `Add{Feature}Services()` | General feature registration |\n| `Add{Feature}()` | Short form when unambiguous |\n| `Configure{Feature}()` | When primarily setting options |\n| `Use{Feature}()` | Middleware (on IApplicationBuilder) |\n\n```csharp\n// Feature services\nservices.AddUserServices();\nservices.AddEmailServices();\nservices.AddPaymentServices();\n\n// Third-party integrations\nservices.AddStripePayments();\nservices.AddSendGridEmail();\n\n// Configuration-heavy\nservices.ConfigureAuthentication();\nservices.ConfigureAuthorization();\n```\n\n---\n\n## Testing Benefits\n\nThe main advantage: **reuse production configuration in tests**.\n\n### WebApplicationFactory\n\n```csharp\npublic class ApiTests : IClassFixture<WebApplicationFactory<Program>>\n{\n    private readonly WebApplicationFactory<Program> _factory;\n\n    public ApiTests(WebApplicationFactory<Program> factory)\n    {\n        _factory = factory.WithWebHostBuilder(builder =>\n        {\n            builder.ConfigureServices(services =>\n            {\n                // Production services already registered via Add* methods\n                // Only override what's different for testing\n\n                // Replace email sender with test double\n                services.RemoveAll<IEmailSender>();\n                services.AddSingleton<IEmailSender, TestEmailSender>();\n\n                // Replace external payment processor\n                services.RemoveAll<IPaymentProcessor>();\n                services.AddSingleton<IPaymentProcessor, FakePaymentProcessor>();\n            });\n        });\n    }\n\n    [Fact]\n    public async Task CreateOrder_SendsConfirmationEmail()\n    {\n        var client = _factory.CreateClient();\n        var emailSender = _factory.Services.GetRequiredService<IEmailSender>() as TestEmailSender;\n\n        await client.PostAsJsonAsync(\"/api/orders\", new CreateOrderRequest(...));\n\n        Assert.Single(emailSender!.SentEmails);\n    }\n}\n```\n\n### Akka.Hosting.TestKit\n\n```csharp\npublic class OrderActorSpecs : Akka.Hosting.TestKit.TestKit\n{\n    protected override void ConfigureAkka(AkkaConfigurationBuilder builder, IServiceProvider provider)\n    {\n        // Reuse production Akka configuration\n        builder.AddOrderActors();\n    }\n\n    protected override void ConfigureServices(IServiceCollection services)\n    {\n        // Reuse production service configuration\n        services.AddOrderServices();\n\n        // Override only external dependencies\n        services.RemoveAll<IPaymentProcessor>();\n        services.AddSingleton<IPaymentProcessor, FakePaymentProcessor>();\n    }\n\n    [Fact]\n    public async Task OrderActor_ProcessesPayment()\n    {\n        var orderActor = ActorRegistry.Get<OrderActor>();\n        orderActor.Tell(new ProcessOrder(orderId));\n\n        ExpectMsg<OrderProcessed>();\n    }\n}\n```\n\n### Standalone Unit Tests\n\n```csharp\npublic class UserServiceTests\n{\n    private readonly ServiceProvider _provider;\n\n    public UserServiceTests()\n    {\n        var services = new ServiceCollection();\n\n        // Reuse production registrations\n        services.AddUserServices();\n\n        // Add test infrastructure\n        services.AddSingleton<IUserRepository, InMemoryUserRepository>();\n\n        _provider = services.BuildServiceProvider();\n    }\n\n    [Fact]\n    public async Task CreateUser_ValidData_Succeeds()\n    {\n        var service = _provider.GetRequiredService<IUserService>();\n        var result = await service.CreateUserAsync(new CreateUserRequest(...));\n\n        Assert.True(result.IsSuccess);\n    }\n}\n```\n\n---\n\n## Layered Extensions\n\nFor larger applications, compose extensions hierarchically:\n\n```csharp\n// Top-level: Everything the app needs\npublic static class AppServiceCollectionExtensions\n{\n    public static IServiceCollection AddAppServices(this IServiceCollection services)\n    {\n        return services\n            .AddDomainServices()\n            .AddInfrastructureServices()\n            .AddApiServices();\n    }\n}\n\n// Domain layer\npublic static class DomainServiceCollectionExtensions\n{\n    public static IServiceCollection AddDomainServices(this IServiceCollection services)\n    {\n        return services\n            .AddUserServices()\n            .AddOrderServices()\n            .AddProductServices();\n    }\n}\n\n// Infrastructure layer\npublic static class InfrastructureServiceCollectionExtensions\n{\n    public static IServiceCollection AddInfrastructureServices(this IServiceCollection services)\n    {\n        return services\n            .AddEmailServices()\n            .AddPaymentServices()\n            .AddStorageServices();\n    }\n}\n```\n\n---\n\n## Akka.Hosting Integration\n\nThe same pattern works for Akka.NET actor configuration:\n\n```csharp\npublic static class OrderActorExtensions\n{\n    public static AkkaConfigurationBuilder AddOrderActors(\n        this AkkaConfigurationBuilder builder)\n    {\n        return builder\n            .WithActors((system, registry, resolver) =>\n            {\n                var orderProps = resolver.Props<OrderActor>();\n                var orderRef = system.ActorOf(orderProps, \"orders\");\n                registry.Register<OrderActor>(orderRef);\n            })\n            .WithShardRegion<OrderShardActor>(\n                typeName: \"order-shard\",\n                (system, registry, resolver) =>\n                    entityId => resolver.Props<OrderShardActor>(entityId),\n                new OrderMessageExtractor(),\n                ShardOptions.Create());\n    }\n}\n\n// Usage in Program.cs\nbuilder.Services.AddAkka(\"MySystem\", (builder, sp) =>\n{\n    builder\n        .AddOrderActors()\n        .AddInventoryActors()\n        .AddNotificationActors();\n});\n```\n\nSee `akka/hosting-actor-patterns` skill for complete Akka.Hosting patterns.\n\n---\n\n## Common Patterns\n\n### Conditional Registration\n\n```csharp\npublic static IServiceCollection AddEmailServices(\n    this IServiceCollection services,\n    IHostEnvironment environment)\n{\n    services.AddSingleton<IEmailComposer, MjmlEmailComposer>();\n\n    if (environment.IsDevelopment())\n    {\n        // Use Mailpit in development\n        services.AddSingleton<IEmailSender, MailpitEmailSender>();\n    }\n    else\n    {\n        // Use real SMTP in production\n        services.AddSingleton<IEmailSender, SmtpEmailSender>();\n    }\n\n    return services;\n}\n```\n\n### Factory-Based Registration\n\n```csharp\npublic static IServiceCollection AddPaymentServices(\n    this IServiceCollection services,\n    string configSection = \"Stripe\")\n{\n    services.AddOptions<StripeOptions>()\n        .BindConfiguration(configSection)\n        .ValidateOnStart();\n\n    // Factory for complex initialization\n    services.AddSingleton<IPaymentProcessor>(sp =>\n    {\n        var options = sp.GetRequiredService<IOptions<StripeOptions>>().Value;\n        var logger = sp.GetRequiredService<ILogger<StripePaymentProcessor>>();\n\n        return new StripePaymentProcessor(options.ApiKey, options.WebhookSecret, logger);\n    });\n\n    return services;\n}\n```\n\n### Keyed Services (.NET 8+)\n\n```csharp\npublic static IServiceCollection AddNotificationServices(this IServiceCollection services)\n{\n    // Register multiple implementations with keys\n    services.AddKeyedSingleton<INotificationSender, EmailNotificationSender>(\"email\");\n    services.AddKeyedSingleton<INotificationSender, SmsNotificationSender>(\"sms\");\n    services.AddKeyedSingleton<INotificationSender, PushNotificationSender>(\"push\");\n\n    // Resolver that picks the right one\n    services.AddScoped<INotificationDispatcher, NotificationDispatcher>();\n\n    return services;\n}\n```\n\n---\n\n## Anti-Patterns\n\n### Don't: Register Everything in Program.cs\n\n```csharp\n// BAD: Massive Program.cs\nvar builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddScoped<IUserRepository, UserRepository>();\nbuilder.Services.AddScoped<IOrderRepository, OrderRepository>();\n// ... 200 more lines ...\n```\n\n### Don't: Create Overly Generic Extensions\n\n```csharp\n// BAD: Too vague, doesn't communicate what's registered\npublic static IServiceCollection AddServices(this IServiceCollection services)\n{\n    // Registers 50 random things\n}\n```\n\n### Don't: Hide Important Configuration\n\n```csharp\n// BAD: Buried important settings\npublic static IServiceCollection AddDatabase(this IServiceCollection services)\n{\n    services.AddDbContext<AppDbContext>(options =>\n        options.UseSqlServer(\"hardcoded-connection-string\"));  // Hidden!\n}\n\n// GOOD: Accept configuration explicitly\npublic static IServiceCollection AddDatabase(\n    this IServiceCollection services,\n    string connectionString)\n{\n    services.AddDbContext<AppDbContext>(options =>\n        options.UseSqlServer(connectionString));\n}\n```\n\n---\n\n## Best Practices Summary\n\n| Practice | Benefit |\n|----------|---------|\n| Group related services into `Add*` methods | Clean Program.cs, clear boundaries |\n| Place extensions near the services they register | Easy to find and maintain |\n| Return `IServiceCollection` for chaining | Fluent API |\n| Accept configuration parameters | Flexibility |\n| Use consistent naming (`Add{Feature}Services`) | Discoverability |\n| Test by reusing production extensions | Confidence, less duplication |\n\n---\n\n## Lifetime Management\n\nChoose the right lifetime based on state:\n\n| Lifetime | Use When | Examples |\n|----------|----------|----------|\n| **Singleton** | Stateless, thread-safe, expensive to create | Configuration, HttpClient factories, caches |\n| **Scoped** | Stateful per-request, database contexts | DbContext, repositories, user context |\n| **Transient** | Lightweight, stateful, cheap to create | Validators, short-lived helpers |\n\n### Rules of Thumb\n\n```csharp\n// SINGLETON: Stateless services, shared safely\nservices.AddSingleton<IMjmlTemplateRenderer, MjmlTemplateRenderer>();\nservices.AddSingleton<IEmailLinkGenerator, EmailLinkGenerator>();\n\n// SCOPED: Database access, per-request state\nservices.AddScoped<IUserRepository, UserRepository>();  // DbContext dependency\nservices.AddScoped<IOrderService, OrderService>();       // Uses scoped repos\n\n// TRANSIENT: Cheap, short-lived\nservices.AddTransient<CreateUserRequestValidator>();\n```\n\n### Scope Requirements\n\n**Scoped services require a scope to exist.** In ASP.NET Core, each HTTP request creates a scope automatically. But in other contexts (background services, actors), you must create scopes manually.\n\n```csharp\n// ASP.NET Controller - scope exists automatically\npublic class OrdersController : ControllerBase\n{\n    private readonly IOrderService _orderService;  // Scoped - works!\n\n    public OrdersController(IOrderService orderService)\n    {\n        _orderService = orderService;\n    }\n}\n\n// Background Service - no automatic scope!\npublic class OrderProcessingService : BackgroundService\n{\n    private readonly IServiceProvider _serviceProvider;\n\n    public OrderProcessingService(IServiceProvider serviceProvider)\n    {\n        // Inject IServiceProvider, NOT scoped services directly\n        _serviceProvider = serviceProvider;\n    }\n\n    protected override async Task ExecuteAsync(CancellationToken ct)\n    {\n        while (!ct.IsCancellationRequested)\n        {\n            // Create scope manually for each unit of work\n            using var scope = _serviceProvider.CreateScope();\n            var orderService = scope.ServiceProvider.GetRequiredService<IOrderService>();\n\n            await orderService.ProcessPendingOrdersAsync(ct);\n            await Task.Delay(TimeSpan.FromMinutes(1), ct);\n        }\n    }\n}\n```\n\n---\n\n## Akka.NET Actor Scope Management\n\n**Actors don't have automatic DI scopes.** If you need scoped services inside an actor, inject `IServiceProvider` and create scopes manually.\n\n### Pattern: Scope Per Message\n\n```csharp\npublic sealed class AccountProvisionActor : ReceiveActor\n{\n    private readonly IServiceProvider _serviceProvider;\n    private readonly IActorRef _mailingActor;\n\n    public AccountProvisionActor(\n        IServiceProvider serviceProvider,\n        IRequiredActor<MailingActor> mailingActor)\n    {\n        _serviceProvider = serviceProvider;\n        _mailingActor = mailingActor.ActorRef;\n\n        ReceiveAsync<ProvisionAccount>(HandleProvisionAccount);\n    }\n\n    private async Task HandleProvisionAccount(ProvisionAccount msg)\n    {\n        // Create scope for this message processing\n        using var scope = _serviceProvider.CreateScope();\n\n        // Resolve scoped services\n        var userManager = scope.ServiceProvider.GetRequiredService<UserManager<User>>();\n        var orderRepository = scope.ServiceProvider.GetRequiredService<IOrderRepository>();\n        var emailComposer = scope.ServiceProvider.GetRequiredService<IPaymentEmailComposer>();\n\n        // Do work with scoped services\n        var user = await userManager.FindByIdAsync(msg.UserId);\n        var order = await orderRepository.CreateAsync(msg.Order);\n\n        // DbContext commits when scope disposes\n    }\n}\n```\n\n### Why This Pattern Works\n\n1. **Each message gets fresh DbContext** - No stale entity tracking\n2. **Proper disposal** - Connections released after each message\n3. **Isolation** - One message's errors don't affect others\n4. **Testable** - Can inject mock IServiceProvider\n\n### Singleton Services in Actors\n\nFor stateless services, inject directly (no scope needed):\n\n```csharp\npublic sealed class NotificationActor : ReceiveActor\n{\n    private readonly IEmailLinkGenerator _linkGenerator;  // Singleton - OK!\n    private readonly IActorRef _mailingActor;\n\n    public NotificationActor(\n        IEmailLinkGenerator linkGenerator,  // Direct injection\n        IRequiredActor<MailingActor> mailingActor)\n    {\n        _linkGenerator = linkGenerator;\n        _mailingActor = mailingActor.ActorRef;\n\n        Receive<SendWelcomeEmail>(Handle);\n    }\n}\n```\n\n### Akka.DependencyInjection Reference\n\nAkka.NET's DI integration is documented at:\n- **Akka.DependencyInjection**: https://getakka.net/articles/actors/dependency-injection.html\n- **Akka.Hosting**: https://github.com/akkadotnet/Akka.Hosting\n\n---\n\n## Common Mistakes\n\n### Injecting Scoped into Singleton\n\n```csharp\n// BAD: Singleton captures scoped service - stale DbContext!\npublic class CacheService  // Registered as Singleton\n{\n    private readonly IUserRepository _repo;  // Scoped!\n\n    public CacheService(IUserRepository repo)  // Captured at startup!\n    {\n        _repo = repo;  // This DbContext lives forever - BAD\n    }\n}\n\n// GOOD: Inject factory or IServiceProvider\npublic class CacheService\n{\n    private readonly IServiceProvider _serviceProvider;\n\n    public CacheService(IServiceProvider serviceProvider)\n    {\n        _serviceProvider = serviceProvider;\n    }\n\n    public async Task<User> GetUserAsync(string id)\n    {\n        using var scope = _serviceProvider.CreateScope();\n        var repo = scope.ServiceProvider.GetRequiredService<IUserRepository>();\n        return await repo.GetByIdAsync(id);\n    }\n}\n```\n\n### No Scope in Background Work\n\n```csharp\n// BAD: No scope for scoped services\npublic class BadBackgroundService : BackgroundService\n{\n    private readonly IOrderService _orderService;  // Scoped!\n\n    public BadBackgroundService(IOrderService orderService)\n    {\n        _orderService = orderService;  // Will throw or behave unexpectedly\n    }\n}\n\n// GOOD: Create scope for each unit of work\npublic class GoodBackgroundService : BackgroundService\n{\n    private readonly IServiceScopeFactory _scopeFactory;\n\n    public GoodBackgroundService(IServiceScopeFactory scopeFactory)\n    {\n        _scopeFactory = scopeFactory;\n    }\n\n    protected override async Task ExecuteAsync(CancellationToken ct)\n    {\n        using var scope = _scopeFactory.CreateScope();\n        var orderService = scope.ServiceProvider.GetRequiredService<IOrderService>();\n        // ...\n    }\n}\n```\n\n---\n\n## Resources\n\n- **Microsoft.Extensions.DependencyInjection**: https://learn.microsoft.com/en-us/dotnet/core/extensions/dependency-injection\n- **Akka.Hosting**: https://github.com/akkadotnet/Akka.Hosting\n- **Akka.DependencyInjection**: https://getakka.net/articles/actors/dependency-injection.html\n- **Options Pattern**: See `microsoft-extensions/configuration` skill\n",
        "skills/testing/crap-analysis/SKILL.md": "---\nname: crap-analysis\ndescription: Analyze code coverage and CRAP (Change Risk Anti-Patterns) scores to identify high-risk code. Use OpenCover format with ReportGenerator for Risk Hotspots showing cyclomatic complexity and untested code paths.\n---\n\n# CRAP Score Analysis\n\n## When to Use This Skill\n\nUse this skill when:\n- Evaluating code quality and test coverage before changes\n- Identifying high-risk code that needs refactoring or testing\n- Setting up coverage collection for a .NET project\n- Prioritizing which code to test based on risk\n- Establishing coverage thresholds for CI/CD pipelines\n\n---\n\n## What is CRAP?\n\n**CRAP Score = Complexity x (1 - Coverage)^2**\n\nThe CRAP (Change Risk Anti-Patterns) score combines cyclomatic complexity with test coverage to identify risky code.\n\n| CRAP Score | Risk Level | Action Required |\n|------------|------------|-----------------|\n| **< 5** | Low | Well-tested, maintainable code |\n| **5-30** | Medium | Acceptable but watch complexity |\n| **> 30** | High | Needs tests or refactoring |\n\n### Why CRAP Matters\n\n- **High complexity + low coverage = danger**: Code that's hard to understand AND untested is risky to modify\n- **Complexity alone isn't enough**: A complex method with 100% coverage is safer than a simple method with 0%\n- **Focuses effort**: Prioritize testing on complex code, not simple getters/setters\n\n### CRAP Score Examples\n\n| Method | Complexity | Coverage | Calculation | CRAP |\n|--------|------------|----------|-------------|------|\n| `GetUserId()` | 1 | 0% | 1 x (1 - 0)^2 | **1** |\n| `ParseToken()` | 54 | 52% | 54 x (1 - 0.52)^2 | **12.4** |\n| `ValidateForm()` | 20 | 0% | 20 x (1 - 0)^2 | **20** |\n| `ProcessOrder()` | 45 | 20% | 45 x (1 - 0.20)^2 | **28.8** |\n| `ImportData()` | 80 | 10% | 80 x (1 - 0.10)^2 | **64.8** |\n\n---\n\n## Coverage Collection Setup\n\n### coverage.runsettings\n\nCreate a `coverage.runsettings` file in your repository root. The **OpenCover format is required** for CRAP score calculation because it includes cyclomatic complexity metrics.\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<RunSettings>\n  <DataCollectionRunSettings>\n    <DataCollectors>\n      <DataCollector friendlyName=\"XPlat code coverage\">\n        <Configuration>\n          <!-- OpenCover format includes cyclomatic complexity for CRAP scores -->\n          <Format>cobertura,opencover</Format>\n\n          <!-- Exclude test and benchmark assemblies -->\n          <Exclude>[*.Tests]*,[*.Benchmark]*,[*.Migrations]*</Exclude>\n\n          <!-- Exclude generated code and obsolete members -->\n          <ExcludeByAttribute>Obsolete,GeneratedCodeAttribute,CompilerGeneratedAttribute</ExcludeByAttribute>\n\n          <!-- Exclude source-generated files -->\n          <ExcludeByFile>**/obj/**/*,**/*.g.cs,**/*.designer.cs</ExcludeByFile>\n\n          <!-- Exclude test projects -->\n          <IncludeTestAssembly>false</IncludeTestAssembly>\n\n          <!-- Optimization flags -->\n          <SingleHit>false</SingleHit>\n          <UseSourceLink>true</UseSourceLink>\n          <SkipAutoProps>true</SkipAutoProps>\n        </Configuration>\n      </DataCollector>\n    </DataCollectors>\n  </DataCollectionRunSettings>\n</RunSettings>\n```\n\n### Key Configuration Options\n\n| Option | Purpose |\n|--------|---------|\n| `Format` | Must include `opencover` for complexity metrics |\n| `Exclude` | Exclude test/benchmark assemblies by pattern |\n| `ExcludeByAttribute` | Skip generated and obsolete code |\n| `ExcludeByFile` | Skip source-generated files |\n| `SkipAutoProps` | Don't count auto-properties as branches |\n\n---\n\n## ReportGenerator Installation\n\nInstall ReportGenerator as a local tool for generating HTML reports with Risk Hotspots.\n\n### Add to .config/dotnet-tools.json\n\n```json\n{\n  \"version\": 1,\n  \"isRoot\": true,\n  \"tools\": {\n    \"dotnet-reportgenerator-globaltool\": {\n      \"version\": \"5.4.5\",\n      \"commands\": [\"reportgenerator\"],\n      \"rollForward\": false\n    }\n  }\n}\n```\n\nThen restore:\n\n```bash\ndotnet tool restore\n```\n\n### Or Install Globally\n\n```bash\ndotnet tool install --global dotnet-reportgenerator-globaltool\n```\n\n---\n\n## Collecting Coverage\n\n### Run Tests with Coverage Collection\n\n```bash\n# Clean previous results\nrm -rf coverage/ TestResults/\n\n# Run unit tests with coverage\ndotnet test tests/MyApp.Tests.Unit \\\n  --settings coverage.runsettings \\\n  --collect:\"XPlat Code Coverage\" \\\n  --results-directory ./TestResults\n\n# Run integration tests (optional, adds to coverage)\ndotnet test tests/MyApp.Tests.Integration \\\n  --settings coverage.runsettings \\\n  --collect:\"XPlat Code Coverage\" \\\n  --results-directory ./TestResults\n```\n\n### Generate HTML Report\n\n```bash\ndotnet reportgenerator \\\n  -reports:\"TestResults/**/coverage.opencover.xml\" \\\n  -targetdir:\"coverage\" \\\n  -reporttypes:\"Html;TextSummary;MarkdownSummaryGithub\"\n```\n\n### Report Types\n\n| Type | Description | Output |\n|------|-------------|--------|\n| `Html` | Full interactive report | `coverage/index.html` |\n| `TextSummary` | Plain text summary | `coverage/Summary.txt` |\n| `MarkdownSummaryGithub` | GitHub-compatible markdown | `coverage/SummaryGithub.md` |\n| `Badges` | SVG badges for README | `coverage/badge_*.svg` |\n| `Cobertura` | Merged Cobertura XML | `coverage/Cobertura.xml` |\n\n---\n\n## Reading the Report\n\n### Risk Hotspots Section\n\nThe HTML report includes a **Risk Hotspots** section showing methods sorted by complexity:\n\n- **Cyclomatic Complexity**: Number of independent paths through code (if/else, switch cases, loops)\n- **NPath Complexity**: Number of acyclic execution paths (exponential growth with nesting)\n- **Crap Score**: Calculated from complexity and coverage\n\n### Interpreting Results\n\n```\nRisk Hotspots\n─────────────\nMethod                          Complexity  Coverage  Crap Score\n──────────────────────────────────────────────────────────────────\nDataImporter.ParseRecord()      54          52%       12.4\nAuthService.ValidateToken()     32          0%        32.0   ← HIGH RISK\nOrderProcessor.Calculate()      28          85%       1.3\nUserService.CreateUser()        15          100%      0.0\n```\n\n**Action items:**\n- `ValidateToken()` has CRAP > 30 with 0% coverage - **test immediately or refactor**\n- `ParseRecord()` is complex but has decent coverage - acceptable\n- `CreateUser()` and `Calculate()` are well-tested - safe to modify\n\n---\n\n## Coverage Thresholds\n\n### Recommended Standards\n\n| Coverage Type | Target | Action |\n|---------------|--------|--------|\n| Line Coverage | > 80% | Good for most projects |\n| Branch Coverage | > 60% | Catches conditional logic |\n| CRAP Score | < 30 | Maximum for new code |\n\n### Configuring Thresholds\n\nCreate `coverage.props` in your repository:\n\n```xml\n<Project>\n  <PropertyGroup>\n    <!-- Coverage thresholds for CI enforcement -->\n    <CoverageThresholdLine>80</CoverageThresholdLine>\n    <CoverageThresholdBranch>60</CoverageThresholdBranch>\n  </PropertyGroup>\n</Project>\n```\n\n---\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Coverage\n\non:\n  pull_request:\n    branches: [main, dev]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: '9.0.x'\n\n      - name: Restore tools\n        run: dotnet tool restore\n\n      - name: Run tests with coverage\n        run: |\n          dotnet test \\\n            --settings coverage.runsettings \\\n            --collect:\"XPlat Code Coverage\" \\\n            --results-directory ./TestResults\n\n      - name: Generate report\n        run: |\n          dotnet reportgenerator \\\n            -reports:\"TestResults/**/coverage.opencover.xml\" \\\n            -targetdir:\"coverage\" \\\n            -reporttypes:\"Html;MarkdownSummaryGithub;Cobertura\"\n\n      - name: Upload coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: coverage/\n\n      - name: Add coverage to PR\n        uses: marocchino/sticky-pull-request-comment@v2\n        with:\n          path: coverage/SummaryGithub.md\n```\n\n### Azure Pipelines\n\n```yaml\n- task: DotNetCoreCLI@2\n  displayName: 'Run tests with coverage'\n  inputs:\n    command: 'test'\n    arguments: '--settings coverage.runsettings --collect:\"XPlat Code Coverage\" --results-directory $(Build.SourcesDirectory)/TestResults'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Generate coverage report'\n  inputs:\n    command: 'custom'\n    custom: 'reportgenerator'\n    arguments: '-reports:\"$(Build.SourcesDirectory)/TestResults/**/coverage.opencover.xml\" -targetdir:\"$(Build.SourcesDirectory)/coverage\" -reporttypes:\"HtmlInline_AzurePipelines;Cobertura\"'\n\n- task: PublishCodeCoverageResults@2\n  displayName: 'Publish coverage'\n  inputs:\n    codeCoverageTool: 'Cobertura'\n    summaryFileLocation: '$(Build.SourcesDirectory)/coverage/Cobertura.xml'\n```\n\n---\n\n## Quick Reference\n\n### One-Liner Commands\n\n```bash\n# Full analysis workflow\nrm -rf coverage/ TestResults/ && \\\ndotnet test --settings coverage.runsettings \\\n  --collect:\"XPlat Code Coverage\" \\\n  --results-directory ./TestResults && \\\ndotnet reportgenerator \\\n  -reports:\"TestResults/**/coverage.opencover.xml\" \\\n  -targetdir:\"coverage\" \\\n  -reporttypes:\"Html;TextSummary\"\n\n# View summary\ncat coverage/Summary.txt\n\n# Open HTML report (Linux)\nxdg-open coverage/index.html\n\n# Open HTML report (macOS)\nopen coverage/index.html\n\n# Open HTML report (Windows)\nstart coverage/index.html\n```\n\n### Project Standards\n\n| Metric | New Code | Legacy Code |\n|--------|----------|-------------|\n| Line Coverage | 80%+ | 60%+ (improve gradually) |\n| Branch Coverage | 60%+ | 40%+ (improve gradually) |\n| Maximum CRAP | 30 | Document exceptions |\n| High-risk methods | Must have tests | Add tests before modifying |\n\n---\n\n## What Gets Excluded\n\nThe recommended `coverage.runsettings` excludes:\n\n| Pattern | Reason |\n|---------|--------|\n| `[*.Tests]*` | Test assemblies aren't production code |\n| `[*.Benchmark]*` | Benchmark projects |\n| `[*.Migrations]*` | Database migrations (generated) |\n| `GeneratedCodeAttribute` | Source generators |\n| `CompilerGeneratedAttribute` | Compiler-generated code |\n| `*.g.cs`, `*.designer.cs` | Generated files |\n| `SkipAutoProps` | Auto-properties (trivial branches) |\n\n---\n\n## When to Update Thresholds\n\n**Lower thresholds temporarily for:**\n- Legacy codebases being modernized (document in README)\n- Generated code that can't be modified\n- Third-party wrapper code\n\n**Never lower thresholds for:**\n- \"It's too hard to test\" - refactor instead\n- \"We'll add tests later\" - add them now\n- New features - should meet standards from the start\n\n---\n\n## Additional Resources\n\n- **Coverlet Documentation**: https://github.com/coverlet-coverage/coverlet\n- **ReportGenerator**: https://github.com/danielpalme/ReportGenerator\n- **CRAP Score Original Paper**: http://www.artima.com/weblogs/viewpost.jsp?thread=215899\n",
        "skills/testing/playwright-blazor/SKILL.md": "---\nname: playwright-blazor-testing\ndescription: Write UI tests for Blazor applications (Server or WebAssembly) using Playwright. Covers navigation, interaction, authentication, selectors, and common Blazor-specific patterns.\n---\n\n# Testing Blazor Applications with Playwright\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing end-to-end UI tests for Blazor Server or WebAssembly applications\n- Testing interactive components, forms, and user workflows\n- Verifying authentication and authorization flows\n- Testing SignalR-based real-time updates in Blazor Server\n- Capturing screenshots for visual regression testing\n- Testing responsive designs and mobile emulation\n- Debugging UI issues with browser developer tools\n\n## Core Principles\n\n1. **Wait for Rendering** - Blazor renders asynchronously; use proper wait strategies\n2. **Test Attributes** - Use `data-test` or `data-testid` attributes for stable selectors\n3. **Headless by Default** - Run tests headless in CI, headed for local debugging\n4. **Handle Error UI** - Always check for `#blazor-error-ui` to catch unhandled exceptions\n5. **Avoid Network Wait States** - Blazor navigation doesn't trigger network loads; wait for DOM changes\n6. **Pin Browser Channels** - Use specific browser channels (msedge, chrome) for reproducibility\n\n## Required NuGet Packages\n\n```xml\n<ItemGroup>\n  <PackageReference Include=\"Microsoft.Playwright\" Version=\"*\" />\n  <PackageReference Include=\"Microsoft.Playwright.MSTest\" Version=\"*\" />\n  <!-- OR for xUnit -->\n  <PackageReference Include=\"xunit\" Version=\"*\" />\n  <PackageReference Include=\"xunit.runner.visualstudio\" Version=\"*\" />\n</ItemGroup>\n```\n\n## Installation\n\nBefore running tests, install Playwright browsers:\n\n```bash\npwsh -Command \"playwright install --with-deps\"\n```\n\n## Pattern 1: Basic Playwright Setup\n\n```csharp\nusing Microsoft.Playwright;\n\npublic class PlaywrightFixture : IAsyncLifetime\n{\n    private IPlaywright? _playwright;\n    private IBrowser? _browser;\n\n    public IBrowser Browser => _browser\n        ?? throw new InvalidOperationException(\"Browser not initialized\");\n\n    public async Task InitializeAsync()\n    {\n        _playwright = await Playwright.CreateAsync();\n\n        _browser = await _playwright.Chromium.LaunchAsync(new()\n        {\n            Headless = true,\n            // For CI/debugging, you might want:\n            // Headless = Environment.GetEnvironmentVariable(\"CI\") != null,\n            // SlowMo = 100 // Slow down actions for debugging\n        });\n    }\n\n    public async Task DisposeAsync()\n    {\n        if (_browser is not null)\n            await _browser.DisposeAsync();\n\n        _playwright?.Dispose();\n    }\n}\n```\n\n## Pattern 2: Navigation in Blazor Apps\n\n### Initial Page Load (Classic Navigation)\n\n```csharp\n[Fact]\npublic async Task InitialPageLoad()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n\n    // First load is classic HTTP navigation\n    await page.GotoAsync(\"https://localhost:5001\");\n\n    // Wait for Blazor to initialize\n    await page.WaitForSelectorAsync(\"h1:has-text('Welcome')\");\n\n    Assert.True(await page.IsVisibleAsync(\"h1:has-text('Welcome')\"));\n}\n```\n\n### In-App Navigation (No Page Reload)\n\nBlazor uses client-side routing, so subsequent navigations don't trigger page reloads:\n\n```csharp\n[Fact]\npublic async Task InternalNavigation()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync(\"https://localhost:5001\");\n\n    // Method 1: Click a navigation link\n    await page.GetByRole(AriaRole.Link, new() { Name = \"Counter\" })\n        .ClickAsync();\n\n    // Wait for the new page content (NOT network idle!)\n    await page.WaitForSelectorAsync(\"h1:has-text('Counter')\");\n\n    // Method 2: Programmatic navigation (Blazor 8+)\n    await page.EvaluateAsync(\"window.Blazor.navigateTo('/fetchdata')\");\n    await page.WaitForSelectorAsync(\"h1:has-text('Weather')\");\n\n    // Method 3: Direct URL navigation (causes full reload)\n    await page.GotoAsync(\"https://localhost:5001/counter\");\n    await page.WaitForSelectorAsync(\"h1:has-text('Counter')\");\n}\n```\n\n### Wait Strategies for Blazor\n\n```csharp\n// ❌ DON'T: Wait for network idle (Blazor doesn't reload pages)\nawait page.WaitForLoadStateAsync(LoadState.NetworkIdle);\n\n// ✅ DO: Wait for specific DOM elements\nawait page.WaitForSelectorAsync(\"h1:has-text('My Page')\");\n\n// ✅ DO: Wait for element visibility\nawait page.Locator(\"[data-test='content']\").WaitForAsync();\n\n// ✅ DO: Wait for URL change\nawait page.WaitForURLAsync(\"**/counter\");\n```\n\n## Pattern 3: Stable Selectors with Test Attributes\n\n### In Your Blazor Components\n\n```razor\n<!-- Add data-test attributes for stable selectors -->\n<button data-test=\"submit-button\" @onclick=\"HandleSubmit\">\n    Submit\n</button>\n\n<input data-test=\"username-input\" @bind=\"Username\" />\n\n<div data-test=\"result-container\">\n    @Result\n</div>\n```\n\n### In Your Tests\n\n```csharp\n[Fact]\npublic async Task FormSubmission()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync(baseUrl);\n\n    // Use GetByTestId for elements with data-test attributes\n    await page.GetByTestId(\"username-input\").FillAsync(\"testuser\");\n    await page.GetByTestId(\"password-input\").FillAsync(\"password123\");\n    await page.GetByTestId(\"submit-button\").ClickAsync();\n\n    // Verify result\n    var result = await page.GetByTestId(\"result-container\").TextContentAsync();\n    Assert.Contains(\"Success\", result);\n}\n```\n\n## Pattern 4: Handling Authentication\n\n### Interactive Login\n\n```csharp\n[Fact]\npublic async Task LoginFlow()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync($\"{baseUrl}/login\");\n\n    // Fill login form\n    await page.FillAsync(\"input[name='username']\", \"alice\");\n    await page.FillAsync(\"input[name='password']\", \"P@ssw0rd\");\n    await page.ClickAsync(\"button[type='submit']\");\n\n    // Wait for redirect to dashboard\n    await page.WaitForURLAsync(\"**/dashboard\");\n\n    // Verify logged in\n    var username = await page.TextContentAsync(\"[data-test='user-name']\");\n    Assert.Equal(\"alice\", username);\n}\n```\n\n### Cookie Injection (Faster)\n\n```csharp\n[Fact]\npublic async Task AuthenticatedAccess_ViaCookie()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n\n    // Inject authentication cookie\n    await page.Context.AddCookiesAsync(new[]\n    {\n        new Cookie\n        {\n            Name = \".AspNetCore.Cookies\",\n            Value = GenerateAuthCookie(\"alice\"),\n            Url = baseUrl,\n            Secure = true,\n            HttpOnly = true\n        }\n    });\n\n    // Navigate directly to protected page\n    await page.GotoAsync($\"{baseUrl}/dashboard\");\n\n    // Already authenticated!\n    var username = await page.TextContentAsync(\"[data-test='user-name']\");\n    Assert.Equal(\"alice\", username);\n}\n\nprivate string GenerateAuthCookie(string username)\n{\n    // Generate a valid authentication cookie\n    // This requires access to your app's cookie encryption keys\n    // OR use a test endpoint that generates valid cookies\n    // OR perform actual login once and reuse the cookie\n}\n```\n\n### OAuth/External Provider Mocking\n\n```csharp\n// Use route interception to mock OAuth redirects\nawait page.RouteAsync(\"**/signin-microsoft\", async route =>\n{\n    // Intercept OAuth redirect and return mock response\n    await route.FulfillAsync(new()\n    {\n        Status = 302,\n        Headers = new Dictionary<string, string>\n        {\n            [\"Location\"] = $\"{baseUrl}/signin-callback?code=mock_auth_code\"\n        }\n    });\n});\n```\n\n## Pattern 5: Click Events and Touch Interactions\n\n```csharp\n[Fact]\npublic async Task ClickInteractions()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync(baseUrl);\n\n    // Standard click\n    await page.GetByText(\"Click Me\").ClickAsync();\n\n    // Right-click\n    await page.ClickAsync(\"[data-test='context-menu']\", new()\n    {\n        Button = MouseButton.Right\n    });\n\n    // Double-click\n    await page.DblClickAsync(\"[data-test='item']\");\n\n    // Hover then click dropdown\n    var menu = page.Locator(\"#profile-menu\");\n    await menu.HoverAsync();\n    await menu.GetByText(\"Sign out\").ClickAsync();\n\n    // Touch events (mobile emulation)\n    await page.EmulateMediaAsync(new() { Media = Media.Screen });\n    await page.Touchscreen.TapAsync(150, 300);\n}\n```\n\n## Pattern 6: Form Handling\n\n```csharp\n[Fact]\npublic async Task ComplexForm()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync($\"{baseUrl}/form\");\n\n    // Text input\n    await page.FillAsync(\"[data-test='name']\", \"John Doe\");\n\n    // Select dropdown\n    await page.SelectOptionAsync(\"[data-test='country']\", \"US\");\n\n    // Checkbox\n    await page.CheckAsync(\"[data-test='terms']\");\n\n    // Radio button\n    await page.CheckAsync(\"[data-test='option-a']\");\n\n    // File upload\n    await page.SetInputFilesAsync(\"[data-test='file-input']\",\n        \"/path/to/test-file.pdf\");\n\n    // Submit\n    await page.ClickAsync(\"[data-test='submit']\");\n\n    // Wait for success message\n    await page.WaitForSelectorAsync(\"[data-test='success-message']\");\n}\n```\n\n## Pattern 7: Handling Blazor Error UI\n\nBlazor shows an error overlay when unhandled exceptions occur. Always check for this:\n\n```csharp\npublic static async Task AssertNoBlazorErrors(this IPage page)\n{\n    var errorUi = page.Locator(\"#blazor-error-ui\");\n\n    if (await errorUi.IsVisibleAsync())\n    {\n        var errorText = await errorUi.InnerTextAsync();\n        Assert.Fail($\"Blazor error occurred: {errorText}\");\n    }\n}\n\n[Fact]\npublic async Task Page_ShouldNotHaveErrors()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync(baseUrl);\n\n    // Perform some actions\n    await page.ClickAsync(\"[data-test='action-button']\");\n\n    // Verify no errors occurred\n    await page.AssertNoBlazorErrors();\n}\n```\n\n## Pattern 8: Testing Real-Time Updates (SignalR)\n\nBlazor Server uses SignalR for real-time communication:\n\n```csharp\n[Fact]\npublic async Task RealTimeUpdates()\n{\n    // Open two browser contexts (simulating two users)\n    var page1 = await _fixture.Browser.NewPageAsync();\n    var page2 = await _fixture.Browser.NewPageAsync();\n\n    await page1.GotoAsync($\"{baseUrl}/drawing\");\n    await page2.GotoAsync($\"{baseUrl}/drawing\");\n\n    // User 1 draws something\n    await page1.ClickAsync(\"[data-test='draw-button']\");\n    await page1.Mouse.ClickAsync(100, 100);\n\n    // User 2 should see the update\n    await page2.WaitForSelectorAsync(\"[data-test='drawing-canvas']\");\n\n    // Verify both pages show the same content\n    var canvas1 = await page1.GetByTestId(\"drawing-canvas\")\n        .GetAttributeAsync(\"data-strokes\");\n    var canvas2 = await page2.GetByTestId(\"drawing-canvas\")\n        .GetAttributeAsync(\"data-strokes\");\n\n    Assert.Equal(canvas1, canvas2);\n}\n```\n\n## Pattern 9: Screenshot and Visual Testing\n\n```csharp\n[Fact]\npublic async Task CaptureScreenshots()\n{\n    var page = await _fixture.Browser.NewPageAsync();\n    await page.GotoAsync(baseUrl);\n\n    // Full page screenshot\n    await page.ScreenshotAsync(new()\n    {\n        Path = \"screenshots/homepage.png\",\n        FullPage = true\n    });\n\n    // Element screenshot\n    var header = page.Locator(\"header\");\n    await header.ScreenshotAsync(new()\n    {\n        Path = \"screenshots/header.png\"\n    });\n\n    // Screenshot with viewport size\n    await page.SetViewportSizeAsync(1920, 1080);\n    await page.ScreenshotAsync(new()\n    {\n        Path = \"screenshots/desktop.png\"\n    });\n\n    // Mobile viewport\n    await page.SetViewportSizeAsync(375, 667);\n    await page.ScreenshotAsync(new()\n    {\n        Path = \"screenshots/mobile.png\"\n    });\n}\n```\n\n## Pattern 10: Running Against HTTPS with Dev Certs\n\n```csharp\npublic async Task InitializeAsync()\n{\n    _playwright = await Playwright.CreateAsync();\n\n    _browser = await _playwright.Chromium.LaunchAsync(new()\n    {\n        Headless = true,\n        // Ignore certificate errors for local dev certs\n        Args = new[] { \"--ignore-certificate-errors\" }\n    });\n}\n```\n\nFor stricter setups, export and trust the dev certificate:\n\n```bash\ndotnet dev-certs https --export-path cert.pfx -p YourPassword\n```\n\n## Common Selectors for Blazor Components\n\n```csharp\n// By role (best for accessibility)\nawait page.GetByRole(AriaRole.Button, new() { Name = \"Submit\" });\nawait page.GetByRole(AriaRole.Link, new() { Name = \"Home\" });\nawait page.GetByRole(AriaRole.Heading, new() { Name = \"Welcome\" });\n\n// By test ID\nawait page.GetByTestId(\"user-profile\");\n\n// By text content\nawait page.GetByText(\"Hello, World!\");\n\n// By label (for inputs)\nawait page.GetByLabel(\"Email Address\");\n\n// By placeholder\nawait page.GetByPlaceholder(\"Enter your name\");\n\n// CSS selectors (use sparingly)\nawait page.Locator(\".mud-button-primary\");\nawait page.Locator(\"#login-form\");\n\n// XPath (use as last resort)\nawait page.Locator(\"xpath=//button[contains(text(), 'Submit')]\");\n```\n\n## Parallelization Considerations\n\nBlazor Server uses SignalR websockets. Multiple Playwright tests can saturate connections:\n\n```csharp\n// Limit parallel execution for Blazor Server tests\n[Collection(\"Blazor Server\")]\npublic class BlazorServerTests { }\n\n// In AssemblyInfo.cs or test startup\n[assembly: CollectionBehavior(MaxParallelThreads = 2)]\n```\n\nBlazor WebAssembly doesn't have this limitation and can run fully parallel.\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Playwright Tests\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: 9.0.x\n\n    - name: Install Playwright Browsers\n      run: pwsh -Command \"playwright install --with-deps\"\n\n    - name: Build\n      run: dotnet build -c Release\n\n    - name: Run Playwright Tests\n      run: |\n        dotnet test tests/YourApp.UITests \\\n          --no-build \\\n          -c Release \\\n          --logger trx\n\n    - name: Upload Screenshots\n      uses: actions/upload-artifact@v3\n      if: failure()\n      with:\n        name: playwright-screenshots\n        path: \"**/screenshots/\"\n\n    - name: Upload Test Results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results\n        path: \"**/TestResults/*.trx\"\n```\n\n## Debugging Tips\n\n1. **Run Headed** - Set `Headless = false` to watch tests execute\n2. **Slow Motion** - Add `SlowMo = 500` to slow down actions\n3. **Pause Execution** - Call `await page.PauseAsync()` to open Playwright Inspector\n4. **Console Logs** - Capture browser console: `page.Console += (_, msg) => Console.WriteLine(msg.Text);`\n5. **Network Traffic** - Monitor requests: `page.Request += (_, req) => Console.WriteLine(req.Url);`\n6. **Screenshots on Failure** - Always capture screenshots in catch blocks\n\n## Best Practices\n\n1. **Use data-test attributes** - More stable than CSS classes or IDs\n2. **Prefer semantic selectors** - Use roles, labels, and text content\n3. **Wait for specific elements** - Don't use blanket delays\n4. **Check for Blazor errors** - Always verify `#blazor-error-ui` is not visible\n5. **Test with multiple viewports** - Verify responsive design\n6. **Reuse browser contexts** - Faster than creating new browsers\n7. **Clean up resources** - Always dispose pages and browsers\n8. **Use collections for Blazor Server** - Avoid SignalR connection saturation\n9. **Capture screenshots on failure** - Essential for debugging CI failures\n10. **Pin browser channels** - Use specific channels for reproducibility\n\n## Advanced: Custom Wait Helpers\n\n```csharp\npublic static class PlaywrightExtensions\n{\n    public static async Task WaitForBlazorAsync(this IPage page)\n    {\n        // Wait for Blazor to finish rendering\n        await page.EvaluateAsync(@\"\n            () => new Promise(resolve => {\n                if (typeof Blazor !== 'undefined') {\n                    resolve();\n                } else {\n                    const interval = setInterval(() => {\n                        if (typeof Blazor !== 'undefined') {\n                            clearInterval(interval);\n                            resolve();\n                        }\n                    }, 100);\n                }\n            })\n        \");\n    }\n\n    public static async Task WaitForNoSpinnersAsync(\n        this IPage page,\n        int timeout = 5000)\n    {\n        var locator = page.Locator(\".spinner, .loading\");\n        await locator.WaitForAsync(new()\n        {\n            State = WaitForSelectorState.Hidden,\n            Timeout = timeout\n        });\n    }\n\n    public static async Task FillWithValidationAsync(\n        this IPage page,\n        string selector,\n        string value)\n    {\n        await page.FillAsync(selector, value);\n\n        // Trigger blur to activate validation\n        await page.Locator(selector).BlurAsync();\n\n        // Wait a bit for validation to complete\n        await Task.Delay(100);\n    }\n}\n```\n",
        "skills/testing/snapshot-testing/SKILL.md": "---\nname: snapshot-testing\ndescription: Use Verify for snapshot testing in .NET. Approve API surfaces, HTTP responses, rendered emails, and serialized outputs. Detect unintended changes through human-reviewed baseline files.\n---\n\n# Snapshot Testing with Verify\n\n## When to Use This Skill\n\nUse snapshot testing when:\n- Verifying rendered output (HTML emails, reports, generated code)\n- Approving public API surfaces for breaking change detection\n- Testing HTTP response bodies and headers\n- Validating serialization output\n- Catching unintended changes in complex objects\n\n---\n\n## What is Snapshot Testing?\n\nSnapshot testing captures output and compares it against a human-approved baseline:\n\n1. **First run**: Test generates a `.received.` file with actual output\n2. **Human review**: Developer approves it, creating a `.verified.` file\n3. **Subsequent runs**: Test compares output against `.verified.` file\n4. **Changes detected**: Test fails, diff tool shows differences for review\n\nThis catches **unintended changes** while allowing **intentional changes** through explicit approval.\n\n---\n\n## Installation\n\n### Add Verify Package\n\n```bash\ndotnet add package Verify.Xunit\n# or for other test frameworks:\ndotnet add package Verify.NUnit\ndotnet add package Verify.MSTest\n```\n\n### Configure ModuleInitializer\n\nCreate a `ModuleInitializer.cs` in your test project:\n\n```csharp\nusing System.Runtime.CompilerServices;\n\npublic static class ModuleInitializer\n{\n    [ModuleInitializer]\n    public static void Init()\n    {\n        // Use source-file-relative paths for verified files\n        VerifyBase.UseProjectRelativeDirectory(\"Snapshots\");\n\n        // Configure diff tool (optional - auto-detected)\n        // DiffTools.UseOrder(DiffTool.Rider, DiffTool.VisualStudioCode);\n    }\n}\n```\n\n---\n\n## Basic Usage\n\n### Simple Object Verification\n\n```csharp\n[Fact]\npublic Task VerifyUserDto()\n{\n    var user = new UserDto(\n        Id: \"user-123\",\n        Name: \"John Doe\",\n        Email: \"john@example.com\",\n        CreatedAt: new DateTime(2025, 1, 15));\n\n    return Verify(user);\n}\n```\n\nCreates `VerifyUserDto.verified.txt`:\n```json\n{\n  Id: user-123,\n  Name: John Doe,\n  Email: john@example.com,\n  CreatedAt: 2025-01-15T00:00:00\n}\n```\n\n### String/HTML Verification\n\n```csharp\n[Fact]\npublic async Task VerifyRenderedEmail()\n{\n    var html = await _emailRenderer.RenderAsync(\"Welcome\", new { Name = \"John\" });\n\n    // Use extension parameter for proper file naming\n    await Verify(html, extension: \"html\");\n}\n```\n\nCreates `VerifyRenderedEmail.verified.html` - viewable in browser.\n\n---\n\n## Email Template Testing\n\nUse Verify to catch unintended changes in rendered email templates:\n\n```csharp\n[Fact]\npublic async Task UserSignupInvitation_RendersCorrectly()\n{\n    var renderer = _services.GetRequiredService<IMjmlTemplateRenderer>();\n\n    var variables = new Dictionary<string, string>\n    {\n        { \"OrganizationName\", \"Acme Corporation\" },\n        { \"InviteeName\", \"John Doe\" },\n        { \"InviterName\", \"Jane Admin\" },\n        { \"InvitationLink\", \"https://example.com/invite/abc123\" },\n        { \"ExpirationDate\", \"December 31, 2025\" }\n    };\n\n    var html = await renderer.RenderTemplateAsync(\n        \"UserInvitations/UserSignupInvitation\",\n        variables);\n\n    await Verify(html, extension: \"html\");\n}\n```\n\n**Benefits for email testing:**\n- Catches CSS/layout regressions\n- Detects broken template variables\n- Visual review in diff tool\n- Version control tracks email changes\n\n---\n\n## API Surface Approval\n\nPrevent accidental breaking changes to public APIs:\n\n```csharp\n[Fact]\npublic Task ApprovePublicApi()\n{\n    var assembly = typeof(MyLibrary.PublicClass).Assembly;\n\n    var publicApi = assembly.GetExportedTypes()\n        .OrderBy(t => t.FullName)\n        .Select(t => new\n        {\n            Type = t.FullName,\n            Members = t.GetMembers(BindingFlags.Public | BindingFlags.Instance | BindingFlags.Static)\n                .Where(m => m.DeclaringType == t)\n                .OrderBy(m => m.Name)\n                .Select(m => m.ToString())\n        });\n\n    return Verify(publicApi);\n}\n```\n\nOr use the dedicated ApiApprover package:\n\n```bash\ndotnet add package PublicApiGenerator\ndotnet add package Verify.Xunit\n```\n\n```csharp\n[Fact]\npublic Task ApproveApi()\n{\n    var api = typeof(MyPublicClass).Assembly.GeneratePublicApi();\n    return Verify(api);\n}\n```\n\nCreates `.verified.txt` with full API surface - any change requires explicit approval.\n\n---\n\n## HTTP Response Testing\n\n```csharp\n[Fact]\npublic async Task GetUser_ReturnsExpectedResponse()\n{\n    var client = _factory.CreateClient();\n\n    var response = await client.GetAsync(\"/api/users/123\");\n\n    // Verify status, headers, and body together\n    await Verify(new\n    {\n        StatusCode = response.StatusCode,\n        Headers = response.Headers\n            .Where(h => h.Key.StartsWith(\"X-\"))  // Custom headers only\n            .ToDictionary(h => h.Key, h => h.Value.First()),\n        Body = await response.Content.ReadAsStringAsync()\n    });\n}\n```\n\n---\n\n## Scrubbing Dynamic Values\n\nHandle timestamps, GUIDs, and other dynamic content:\n\n```csharp\n[Fact]\npublic Task VerifyOrder()\n{\n    var order = new Order\n    {\n        Id = Guid.NewGuid(),  // Different every run\n        CreatedAt = DateTime.UtcNow,  // Different every run\n        Total = 99.99m\n    };\n\n    return Verify(order)\n        .ScrubMember(\"Id\")  // Replace with placeholder\n        .ScrubMember(\"CreatedAt\");\n}\n```\n\nOutput:\n```json\n{\n  Id: Guid_1,\n  CreatedAt: DateTime_1,\n  Total: 99.99\n}\n```\n\n### Global Scrubbing\n\nConfigure in `ModuleInitializer`:\n\n```csharp\n[ModuleInitializer]\npublic static void Init()\n{\n    VerifierSettings.ScrubMembersWithType<DateTime>();\n    VerifierSettings.ScrubMembersWithType<DateTimeOffset>();\n    VerifierSettings.ScrubMembersWithType<Guid>();\n\n    // Scrub specific patterns\n    VerifierSettings.AddScrubber(s =>\n        Regex.Replace(s, @\"token=[a-zA-Z0-9]+\", \"token=SCRUBBED\"));\n}\n```\n\n---\n\n## File Organization\n\n### Recommended Structure\n\n```\ntests/\n  MyApp.Tests/\n    Snapshots/           # All verified files\n      EmailTests/\n        WelcomeEmail.verified.html\n        PasswordReset.verified.html\n      ApiTests/\n        GetUser.verified.txt\n    EmailTests.cs\n    ApiTests.cs\n    ModuleInitializer.cs\n```\n\n### .gitignore\n\n```gitignore\n# Verify - ignore received files (only commit verified)\n*.received.*\n```\n\n### .gitattributes\n\n```gitattributes\n# Treat verified files as generated (collapse in PR diffs)\n*.verified.txt linguist-generated=true\n*.verified.html linguist-generated=true\n*.verified.json linguist-generated=true\n```\n\n---\n\n## CI/CD Integration\n\n### Fail on Missing Verified Files\n\n```csharp\n[ModuleInitializer]\npublic static void Init()\n{\n    // In CI, fail instead of launching diff tool\n    if (Environment.GetEnvironmentVariable(\"CI\") == \"true\")\n    {\n        VerifyDiffPlex.UseDiffPlex(OutputType.Minimal);\n        DiffRunner.Disabled = true;\n    }\n}\n```\n\n### GitHub Actions\n\n```yaml\n- name: Run tests\n  run: dotnet test\n  env:\n    CI: true\n\n- name: Upload snapshots on failure\n  if: failure()\n  uses: actions/upload-artifact@v4\n  with:\n    name: snapshots\n    path: |\n      **/*.received.*\n      **/*.verified.*\n```\n\n---\n\n## When to Use Snapshot Testing\n\n| Scenario | Use Snapshot Testing? | Why |\n|----------|----------------------|-----|\n| Rendered HTML/emails | Yes | Catches visual regressions |\n| API surfaces | Yes | Prevents accidental breaks |\n| Serialization output | Yes | Validates wire format |\n| Complex object graphs | Yes | Easier than manual assertions |\n| Simple value checks | No | Use regular assertions |\n| Business logic | No | Use explicit assertions |\n| Performance tests | No | Use benchmarks |\n\n---\n\n## Best Practices\n\n### DO\n\n```csharp\n// Use descriptive test names - they become file names\n[Fact]\npublic Task UserRegistration_WithValidData_ReturnsConfirmation()\n\n// Scrub dynamic values consistently\nVerifierSettings.ScrubMembersWithType<Guid>();\n\n// Use extension parameter for non-text content\nawait Verify(html, extension: \"html\");\n\n// Keep verified files in source control\ngit add *.verified.*\n```\n\n### DON'T\n\n```csharp\n// Don't verify random/dynamic data without scrubbing\nvar order = new Order { Id = Guid.NewGuid() };  // Fails every run!\nawait Verify(order);\n\n// Don't commit .received files\ngit add *.received.*  // Wrong!\n\n// Don't use for simple assertions\nawait Verify(result.Count);  // Just use Assert.Equal(5, result.Count)\n```\n\n---\n\n## Integration with MJML Email Testing\n\nSee the `aspnetcore/transactional-emails` skill for the complete pattern:\n\n1. MJML templates with `{{variable}}` placeholders\n2. Render to HTML with test data\n3. Snapshot test the rendered output\n4. Review changes in diff tool before approving\n\nThis catches:\n- Broken variable substitution\n- CSS/layout regressions\n- Email client compatibility issues\n- Unintended content changes\n\n---\n\n## Resources\n\n- **Verify GitHub**: https://github.com/VerifyTests/Verify\n- **Verify.Xunit**: https://github.com/VerifyTests/Verify.Xunit\n- **ApiApprover**: https://github.com/JakeGinnivan/ApiApprover\n- **DiffPlex Integration**: https://github.com/VerifyTests/Verify.DiffPlex\n",
        "skills/testing/testcontainers/SKILL.md": "---\nname: testcontainers-integration-tests\ndescription: Write integration tests using TestContainers for .NET with xUnit. Covers infrastructure testing with real databases, message queues, and caches in Docker containers instead of mocks.\n---\n\n# Integration Testing with TestContainers\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing integration tests that need real infrastructure (databases, caches, message queues)\n- Testing data access layers against actual databases\n- Verifying message queue integrations\n- Testing Redis caching behavior\n- Avoiding mocks for infrastructure components\n- Ensuring tests work against production-like environments\n- Testing database migrations and schema changes\n\n## Core Principles\n\n1. **Real Infrastructure Over Mocks** - Use actual databases/services in containers, not mocks\n2. **Test Isolation** - Each test gets fresh containers or fresh data\n3. **Automatic Cleanup** - TestContainers handles container lifecycle and cleanup\n4. **Fast Startup** - Reuse containers across tests in the same class when appropriate\n5. **CI/CD Compatible** - Works seamlessly in Docker-enabled CI environments\n6. **Port Randomization** - Containers use random ports to avoid conflicts\n\n## Why TestContainers Over Mocks?\n\n### ❌ Problems with Mocking Infrastructure\n\n```csharp\n// BAD: Mocking a database\npublic class OrderRepositoryTests\n{\n    private readonly Mock<IDbConnection> _mockDb = new();\n\n    [Fact]\n    public async Task GetOrder_ReturnsOrder()\n    {\n        // This doesn't test real SQL behavior, constraints, or performance\n        _mockDb.Setup(db => db.QueryAsync<Order>(It.IsAny<string>()))\n            .ReturnsAsync(new[] { new Order { Id = 1 } });\n\n        var repo = new OrderRepository(_mockDb.Object);\n        var order = await repo.GetOrderAsync(1);\n\n        Assert.NotNull(order);\n    }\n}\n```\n\nProblems:\n- Doesn't test actual SQL queries\n- Misses database constraints, indexes, and performance\n- Can give false confidence\n- Doesn't catch SQL syntax errors or schema mismatches\n\n### ✅ Better: TestContainers with Real Database\n\n```csharp\n// GOOD: Testing against a real database\npublic class OrderRepositoryTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _dbContainer;\n    private IDbConnection _connection;\n\n    public OrderRepositoryTests()\n    {\n        _dbContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"mcr.microsoft.com/mssql/server:2022-latest\")\n            .WithEnvironment(\"ACCEPT_EULA\", \"Y\")\n            .WithEnvironment(\"SA_PASSWORD\", \"Your_password123\")\n            .WithPortBinding(1433, true)\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _dbContainer.StartAsync();\n\n        var port = _dbContainer.GetMappedPublicPort(1433);\n        var connectionString = $\"Server=localhost,{port};Database=TestDb;User Id=sa;Password=Your_password123;TrustServerCertificate=true\";\n\n        _connection = new SqlConnection(connectionString);\n        await _connection.OpenAsync();\n\n        // Run migrations\n        await RunMigrationsAsync(_connection);\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _connection.DisposeAsync();\n        await _dbContainer.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task GetOrder_WithRealDatabase_ReturnsOrder()\n    {\n        // Arrange: Insert real test data\n        await _connection.ExecuteAsync(\n            \"INSERT INTO Orders (Id, CustomerId, Total) VALUES (1, 'CUST1', 100.00)\");\n\n        var repo = new OrderRepository(_connection);\n\n        // Act: Execute against real database\n        var order = await repo.GetOrderAsync(1);\n\n        // Assert: Verify actual database behavior\n        Assert.NotNull(order);\n        Assert.Equal(1, order.Id);\n        Assert.Equal(\"CUST1\", order.CustomerId);\n        Assert.Equal(100.00m, order.Total);\n    }\n}\n```\n\nBenefits:\n- Tests real SQL queries and database behavior\n- Catches constraint violations, index issues, and performance problems\n- Verifies migrations work correctly\n- Gives true confidence in data access layer\n\n## Required NuGet Packages\n\n```xml\n<ItemGroup>\n  <PackageReference Include=\"Testcontainers\" Version=\"*\" />\n  <PackageReference Include=\"xunit\" Version=\"*\" />\n  <PackageReference Include=\"xunit.runner.visualstudio\" Version=\"*\" />\n\n  <!-- Database-specific packages -->\n  <PackageReference Include=\"Microsoft.Data.SqlClient\" Version=\"*\" />\n  <PackageReference Include=\"Npgsql\" Version=\"*\" /> <!-- For PostgreSQL -->\n  <PackageReference Include=\"MySqlConnector\" Version=\"*\" /> <!-- For MySQL -->\n\n  <!-- Other infrastructure -->\n  <PackageReference Include=\"StackExchange.Redis\" Version=\"*\" /> <!-- For Redis -->\n  <PackageReference Include=\"RabbitMQ.Client\" Version=\"*\" /> <!-- For RabbitMQ -->\n</ItemGroup>\n```\n\n## Pattern 1: SQL Server Integration Tests\n\n```csharp\nusing Testcontainers;\nusing Xunit;\n\npublic class SqlServerTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _dbContainer;\n    private IDbConnection _db;\n\n    public SqlServerTests()\n    {\n        _dbContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"mcr.microsoft.com/mssql/server:2022-latest\")\n            .WithEnvironment(\"ACCEPT_EULA\", \"Y\")\n            .WithEnvironment(\"SA_PASSWORD\", \"Your_password123\")\n            .WithPortBinding(1433, true)\n            .WithWaitStrategy(Wait.ForUnixContainer().UntilPortIsAvailable(1433))\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _dbContainer.StartAsync();\n\n        var port = _dbContainer.GetMappedPublicPort(1433);\n        var connectionString = $\"Server=localhost,{port};Database=master;User Id=sa;Password=Your_password123;TrustServerCertificate=true\";\n\n        _db = new SqlConnection(connectionString);\n        await _db.OpenAsync();\n\n        // Create test database\n        await _db.ExecuteAsync(\"CREATE DATABASE TestDb\");\n        await _db.ExecuteAsync(\"USE TestDb\");\n\n        // Run schema migrations\n        await _db.ExecuteAsync(@\"\n            CREATE TABLE Orders (\n                Id INT PRIMARY KEY,\n                CustomerId NVARCHAR(50) NOT NULL,\n                Total DECIMAL(18,2) NOT NULL,\n                CreatedAt DATETIME2 DEFAULT GETUTCDATE()\n            )\");\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _db.DisposeAsync();\n        await _dbContainer.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task CanInsertAndRetrieveOrder()\n    {\n        // Arrange\n        await _db.ExecuteAsync(@\"\n            INSERT INTO Orders (Id, CustomerId, Total)\n            VALUES (1, 'CUST001', 99.99)\");\n\n        // Act\n        var order = await _db.QuerySingleAsync<Order>(\n            \"SELECT * FROM Orders WHERE Id = @Id\",\n            new { Id = 1 });\n\n        // Assert\n        Assert.Equal(1, order.Id);\n        Assert.Equal(\"CUST001\", order.CustomerId);\n        Assert.Equal(99.99m, order.Total);\n    }\n}\n```\n\n## Pattern 2: PostgreSQL Integration Tests\n\n```csharp\npublic class PostgreSqlTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _dbContainer;\n    private NpgsqlConnection _connection;\n\n    public PostgreSqlTests()\n    {\n        _dbContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"postgres:latest\")\n            .WithEnvironment(\"POSTGRES_PASSWORD\", \"postgres\")\n            .WithEnvironment(\"POSTGRES_DB\", \"testdb\")\n            .WithPortBinding(5432, true)\n            .WithWaitStrategy(Wait.ForUnixContainer().UntilPortIsAvailable(5432))\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _dbContainer.StartAsync();\n\n        var port = _dbContainer.GetMappedPublicPort(5432);\n        var connectionString = $\"Host=localhost;Port={port};Database=testdb;Username=postgres;Password=postgres\";\n\n        _connection = new NpgsqlConnection(connectionString);\n        await _connection.OpenAsync();\n\n        // Create schema\n        await _connection.ExecuteAsync(@\"\n            CREATE TABLE orders (\n                id SERIAL PRIMARY KEY,\n                customer_id VARCHAR(50) NOT NULL,\n                total NUMERIC(10,2) NOT NULL,\n                created_at TIMESTAMP DEFAULT NOW()\n            )\");\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _connection.DisposeAsync();\n        await _dbContainer.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task PostgreSql_ShouldHandleTransactions()\n    {\n        using var transaction = await _connection.BeginTransactionAsync();\n\n        await _connection.ExecuteAsync(\n            \"INSERT INTO orders (customer_id, total) VALUES (@CustomerId, @Total)\",\n            new { CustomerId = \"CUST1\", Total = 100.00m },\n            transaction);\n\n        await transaction.RollbackAsync();\n\n        var count = await _connection.QuerySingleAsync<int>(\n            \"SELECT COUNT(*) FROM orders\");\n\n        Assert.Equal(0, count); // Rollback should prevent insert\n    }\n}\n```\n\n## Pattern 3: Redis Integration Tests\n\n```csharp\npublic class RedisTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _redisContainer;\n    private IConnectionMultiplexer _redis;\n\n    public RedisTests()\n    {\n        _redisContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"redis:alpine\")\n            .WithPortBinding(6379, true)\n            .WithWaitStrategy(Wait.ForUnixContainer().UntilPortIsAvailable(6379))\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _redisContainer.StartAsync();\n\n        var port = _redisContainer.GetMappedPublicPort(6379);\n        _redis = await ConnectionMultiplexer.ConnectAsync($\"localhost:{port}\");\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _redis.DisposeAsync();\n        await _redisContainer.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task Redis_ShouldCacheValues()\n    {\n        var db = _redis.GetDatabase();\n\n        // Set value\n        await db.StringSetAsync(\"key1\", \"value1\");\n\n        // Get value\n        var value = await db.StringGetAsync(\"key1\");\n\n        Assert.Equal(\"value1\", value.ToString());\n    }\n\n    [Fact]\n    public async Task Redis_ShouldExpireKeys()\n    {\n        var db = _redis.GetDatabase();\n\n        await db.StringSetAsync(\"temp-key\", \"temp-value\",\n            expiry: TimeSpan.FromSeconds(1));\n\n        // Key should exist\n        Assert.True(await db.KeyExistsAsync(\"temp-key\"));\n\n        // Wait for expiry\n        await Task.Delay(1100);\n\n        // Key should be gone\n        Assert.False(await db.KeyExistsAsync(\"temp-key\"));\n    }\n}\n```\n\n## Pattern 4: RabbitMQ Integration Tests\n\n```csharp\npublic class RabbitMqTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _rabbitContainer;\n    private IConnection _connection;\n\n    public RabbitMqTests()\n    {\n        _rabbitContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"rabbitmq:management-alpine\")\n            .WithPortBinding(5672, true) // AMQP\n            .WithPortBinding(15672, true) // Management UI\n            .WithWaitStrategy(Wait.ForUnixContainer().UntilPortIsAvailable(5672))\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _rabbitContainer.StartAsync();\n\n        var port = _rabbitContainer.GetMappedPublicPort(5672);\n        var factory = new ConnectionFactory\n        {\n            HostName = \"localhost\",\n            Port = port,\n            UserName = \"guest\",\n            Password = \"guest\"\n        };\n\n        _connection = await factory.CreateConnectionAsync();\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _connection.CloseAsync();\n        await _rabbitContainer.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task RabbitMq_ShouldPublishAndConsumeMessage()\n    {\n        using var channel = await _connection.CreateChannelAsync();\n\n        var queueName = \"test-queue\";\n        await channel.QueueDeclareAsync(queueName, durable: false,\n            exclusive: false, autoDelete: true);\n\n        // Publish message\n        var message = \"Hello, RabbitMQ!\";\n        var body = Encoding.UTF8.GetBytes(message);\n        await channel.BasicPublishAsync(exchange: \"\",\n            routingKey: queueName,\n            body: body);\n\n        // Consume message\n        var consumer = new EventingBasicConsumer(channel);\n        var tcs = new TaskCompletionSource<string>();\n\n        consumer.Received += (model, ea) =>\n        {\n            var receivedMessage = Encoding.UTF8.GetString(ea.Body.ToArray());\n            tcs.SetResult(receivedMessage);\n        };\n\n        await channel.BasicConsumeAsync(queueName, autoAck: true,\n            consumer: consumer);\n\n        // Wait for message\n        var received = await tcs.Task.WaitAsync(TimeSpan.FromSeconds(5));\n\n        Assert.Equal(message, received);\n    }\n}\n```\n\n## Pattern 5: Multi-Container Networks\n\nWhen you need multiple containers to communicate:\n\n```csharp\npublic class MultiContainerTests : IAsyncLifetime\n{\n    private readonly INetwork _network;\n    private readonly TestcontainersContainer _dbContainer;\n    private readonly TestcontainersContainer _redisContainer;\n\n    public MultiContainerTests()\n    {\n        _network = new TestcontainersNetworkBuilder()\n            .Build();\n\n        _dbContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"postgres:latest\")\n            .WithNetwork(_network)\n            .WithNetworkAliases(\"db\")\n            .WithEnvironment(\"POSTGRES_PASSWORD\", \"postgres\")\n            .Build();\n\n        _redisContainer = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"redis:alpine\")\n            .WithNetwork(_network)\n            .WithNetworkAliases(\"redis\")\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _network.CreateAsync();\n        await Task.WhenAll(\n            _dbContainer.StartAsync(),\n            _redisContainer.StartAsync());\n    }\n\n    public async Task DisposeAsync()\n    {\n        await Task.WhenAll(\n            _dbContainer.DisposeAsync().AsTask(),\n            _redisContainer.DisposeAsync().AsTask());\n        await _network.DisposeAsync();\n    }\n\n    [Fact]\n    public async Task Containers_CanCommunicate()\n    {\n        // Both containers can reach each other via network aliases\n        // db -> redis://redis:6379\n        // redis -> postgres://db:5432\n    }\n}\n```\n\n## Pattern 6: Reusing Containers Across Tests\n\nFor faster test execution, reuse containers across tests in a class:\n\n```csharp\n[Collection(\"Database collection\")]\npublic class FastDatabaseTests\n{\n    private readonly DatabaseFixture _fixture;\n\n    public FastDatabaseTests(DatabaseFixture fixture)\n    {\n        _fixture = fixture;\n    }\n\n    [Fact]\n    public async Task Test1()\n    {\n        // Use _fixture.Connection\n        // Clean up data after test if needed\n    }\n\n    [Fact]\n    public async Task Test2()\n    {\n        // Reuses the same container\n    }\n}\n\n// Shared fixture\npublic class DatabaseFixture : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _container;\n    public IDbConnection Connection { get; private set; }\n\n    public DatabaseFixture()\n    {\n        _container = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"mcr.microsoft.com/mssql/server:2022-latest\")\n            .WithEnvironment(\"ACCEPT_EULA\", \"Y\")\n            .WithEnvironment(\"SA_PASSWORD\", \"Your_password123\")\n            .WithPortBinding(1433, true)\n            .Build();\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _container.StartAsync();\n        // Setup connection\n    }\n\n    public async Task DisposeAsync()\n    {\n        await Connection.DisposeAsync();\n        await _container.DisposeAsync();\n    }\n}\n\n[CollectionDefinition(\"Database collection\")]\npublic class DatabaseCollection : ICollectionFixture<DatabaseFixture> { }\n```\n\n## Pattern 7: Testing Migrations with Real Databases\n\n```csharp\npublic class MigrationTests : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _container;\n    private string _connectionString;\n\n    public async Task InitializeAsync()\n    {\n        _container = new TestcontainersBuilder<TestcontainersContainer>()\n            .WithImage(\"mcr.microsoft.com/mssql/server:2022-latest\")\n            .WithEnvironment(\"ACCEPT_EULA\", \"Y\")\n            .WithEnvironment(\"SA_PASSWORD\", \"Your_password123\")\n            .WithPortBinding(1433, true)\n            .Build();\n\n        await _container.StartAsync();\n\n        var port = _container.GetMappedPublicPort(1433);\n        _connectionString = $\"Server=localhost,{port};Database=TestDb;User Id=sa;Password=Your_password123;TrustServerCertificate=true\";\n    }\n\n    [Fact]\n    public async Task Migrations_ShouldRunSuccessfully()\n    {\n        // Run Entity Framework migrations\n        var optionsBuilder = new DbContextOptionsBuilder<AppDbContext>();\n        optionsBuilder.UseSqlServer(_connectionString);\n\n        using var context = new AppDbContext(optionsBuilder.Options);\n\n        // Apply migrations\n        await context.Database.MigrateAsync();\n\n        // Verify schema\n        var canConnect = await context.Database.CanConnectAsync();\n        Assert.True(canConnect);\n\n        // Verify tables exist\n        var tables = await context.Database.SqlQueryRaw<string>(\n            \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\").ToListAsync();\n\n        Assert.Contains(\"Orders\", tables);\n        Assert.Contains(\"Customers\", tables);\n    }\n\n    public async Task DisposeAsync()\n    {\n        await _container.DisposeAsync();\n    }\n}\n```\n\n## Best Practices\n\n1. **Always Use IAsyncLifetime** - Proper async setup and teardown\n2. **Wait for Port Availability** - Use `WaitStrategy` to ensure containers are ready\n3. **Use Random Ports** - Let TestContainers assign ports automatically\n4. **Clean Data Between Tests** - Either use fresh containers or truncate tables\n5. **Reuse Containers When Possible** - Faster than creating new ones for each test\n6. **Test Real Queries** - Don't just test mocks; verify actual SQL behavior\n7. **Verify Constraints** - Test foreign keys, unique constraints, indexes\n8. **Test Transactions** - Verify rollback and commit behavior\n9. **Use Realistic Data** - Test with production-like data volumes\n10. **Handle Cleanup** - Always dispose containers in `DisposeAsync`\n\n## Common Issues and Solutions\n\n### Issue 1: Container Startup Timeout\n\n**Problem:** Container takes too long to start\n\n**Solution:**\n```csharp\n_container = new TestcontainersBuilder<TestcontainersContainer>()\n    .WithImage(\"postgres:latest\")\n    .WithWaitStrategy(Wait.ForUnixContainer()\n        .UntilPortIsAvailable(5432)\n        .WithTimeout(TimeSpan.FromMinutes(2)))\n    .Build();\n```\n\n### Issue 2: Port Already in Use\n\n**Problem:** Tests fail because port is already bound\n\n**Solution:** Always use random port mapping:\n```csharp\n.WithPortBinding(5432, true) // true = assign random public port\n```\n\n### Issue 3: Containers Not Cleaning Up\n\n**Problem:** Containers remain running after tests\n\n**Solution:** Ensure proper disposal:\n```csharp\npublic async Task DisposeAsync()\n{\n    await _connection?.DisposeAsync();\n    await _container?.DisposeAsync();\n}\n```\n\n### Issue 4: Tests Fail in CI But Pass Locally\n\n**Problem:** CI environment doesn't have Docker\n\n**Solution:** Ensure CI has Docker support:\n```yaml\n# GitHub Actions\nruns-on: ubuntu-latest # Has Docker pre-installed\nservices:\n  docker:\n    image: docker:dind\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Integration Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest # Has Docker pre-installed\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: 9.0.x\n\n    - name: Run Integration Tests\n      run: |\n        dotnet test tests/YourApp.IntegrationTests \\\n          --filter Category=Integration \\\n          --logger trx\n\n    - name: Cleanup Containers\n      if: always()\n      run: docker container prune -f\n```\n\n## Pattern 8: Database Reset with Respawn\n\nWhen reusing containers across tests, use [Respawn](https://github.com/jbogard/Respawn) to reset database state between tests instead of recreating containers:\n\n```xml\n<PackageReference Include=\"Respawn\" Version=\"*\" />\n```\n\n### Basic Respawn Setup\n\n```csharp\nusing Respawn;\n\npublic class DatabaseFixture : IAsyncLifetime\n{\n    private readonly TestcontainersContainer _container;\n    private Respawner _respawner = null!;\n    public NpgsqlConnection Connection { get; private set; } = null!;\n    public string ConnectionString { get; private set; } = null!;\n\n    public async Task InitializeAsync()\n    {\n        await _container.StartAsync();\n\n        var port = _container.GetMappedPublicPort(5432);\n        ConnectionString = $\"Host=localhost;Port={port};Database=testdb;Username=postgres;Password=postgres\";\n\n        Connection = new NpgsqlConnection(ConnectionString);\n        await Connection.OpenAsync();\n\n        // Run migrations first\n        await RunMigrationsAsync();\n\n        // Create respawner after schema exists\n        _respawner = await Respawner.CreateAsync(ConnectionString, new RespawnerOptions\n        {\n            TablesToIgnore = new Table[]\n            {\n                \"__EFMigrationsHistory\",  // EF Core migrations table\n                \"AspNetRoles\",            // Identity roles (seeded data)\n                \"schema_version\"          // DbUp/Flyway version table\n            },\n            DbAdapter = DbAdapter.Postgres\n        });\n    }\n\n    /// <summary>\n    /// Reset database to clean state. Call this in test setup or between tests.\n    /// </summary>\n    public async Task ResetDatabaseAsync()\n    {\n        await _respawner.ResetAsync(ConnectionString);\n    }\n\n    public async Task DisposeAsync()\n    {\n        await Connection.DisposeAsync();\n        await _container.DisposeAsync();\n    }\n}\n```\n\n### Using Respawn in Tests\n\n```csharp\n[Collection(\"Database collection\")]\npublic class OrderTests : IAsyncLifetime\n{\n    private readonly DatabaseFixture _fixture;\n\n    public OrderTests(DatabaseFixture fixture)\n    {\n        _fixture = fixture;\n    }\n\n    public async Task InitializeAsync()\n    {\n        // Reset database before each test\n        await _fixture.ResetDatabaseAsync();\n    }\n\n    public Task DisposeAsync() => Task.CompletedTask;\n\n    [Fact]\n    public async Task CreateOrder_ShouldPersist()\n    {\n        // Database is clean - no leftover data from other tests\n        await _fixture.Connection.ExecuteAsync(\n            \"INSERT INTO orders (customer_id, total) VALUES (@CustomerId, @Total)\",\n            new { CustomerId = \"CUST1\", Total = 100.00m });\n\n        var count = await _fixture.Connection.QuerySingleAsync<int>(\n            \"SELECT COUNT(*) FROM orders\");\n\n        Assert.Equal(1, count);\n    }\n\n    [Fact]\n    public async Task AnotherTest_StartsWithCleanDatabase()\n    {\n        // This test also starts with empty tables\n        var count = await _fixture.Connection.QuerySingleAsync<int>(\n            \"SELECT COUNT(*) FROM orders\");\n\n        Assert.Equal(0, count); // Clean slate!\n    }\n}\n```\n\n### Respawn Options\n\n```csharp\nvar respawner = await Respawner.CreateAsync(connectionString, new RespawnerOptions\n{\n    // Tables to preserve (reference data, migrations history)\n    TablesToIgnore = new Table[]\n    {\n        \"__EFMigrationsHistory\",\n        new Table(\"public\", \"lookup_data\"),  // Schema-qualified\n    },\n\n    // Schemas to clean (default: all schemas)\n    SchemasToInclude = new[] { \"public\", \"app\" },\n\n    // Or exclude specific schemas\n    SchemasToExclude = new[] { \"audit\", \"logging\" },\n\n    // Database adapter\n    DbAdapter = DbAdapter.Postgres,  // or SqlServer, MySql\n\n    // Handle circular foreign keys\n    WithReseed = true  // Reset identity columns (SQL Server)\n});\n```\n\n### Why Respawn Over Container Recreation\n\n| Approach | Pros | Cons |\n|----------|------|------|\n| **New container per test** | Complete isolation | Slow (10-30s per container) |\n| **Respawn** | Fast (~50ms), preserves schema/migrations | Requires careful table exclusion |\n| **Transaction rollback** | Fastest | Can't test commit behavior |\n\n**Use Respawn when:**\n- Tests share a container via xUnit collection fixture\n- You need to test actual commits (not just rollbacks)\n- Container startup time is a bottleneck\n\n## Performance Tips\n\n1. **Reuse containers** - Share fixtures across tests in a collection\n2. **Use Respawn** - Reset data without recreating containers\n3. **Parallel execution** - TestContainers handles port conflicts automatically\n4. **Use lightweight images** - Alpine versions are smaller and faster\n5. **Cache images** - Docker will cache pulled images locally\n6. **Limit container resources** - Set CPU/memory limits if needed:\n\n```csharp\n.WithResourceMapping(new CpuCount(2))\n.WithResourceMapping(new MemoryLimit(512 * 1024 * 1024)) // 512MB\n```\n"
      },
      "plugins": [
        {
          "name": "dotnet-skills",
          "source": "./",
          "version": "1.0.0",
          "description": "Complete .NET development toolkit with 9 skills and 5 specialized agents covering Akka.NET, Aspire, testing, and modern C# patterns",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Aaronontheweb/dotnet-skills",
            "/plugin install dotnet-skills@dotnet-skills"
          ]
        }
      ]
    }
  ]
}