{
  "author": {
    "id": "constellos",
    "display_name": "Constellos",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/246303564?v=4",
    "url": "https://github.com/constellos",
    "bio": "Order for autonomous AI.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 6,
      "total_commands": 0,
      "total_skills": 13,
      "total_stars": 4,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "constellos-local",
      "version": "1.0.0",
      "description": "Plugin marketplace for Constellos development tools",
      "owner_info": {
        "name": "constellos"
      },
      "keywords": [],
      "repo_full_name": "constellos/claude-code-plugins",
      "repo_url": "https://github.com/constellos/claude-code-plugins",
      "repo_description": "TypeScript types and type gen hooks for Claude Code: system tools, MCP tools, session transcripts, and hook events",
      "homepage": "https://www.npmjs.com/package/@constellos/claude-code-kit",
      "signals": {
        "stars": 4,
        "forks": 0,
        "pushed_at": "2026-01-29T09:13:07Z",
        "created_at": "2025-11-30T01:22:44Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2171
        },
        {
          "path": ".claude-plugin/plugins",
          "type": "blob",
          "size": 10
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/cloudflare-mcp-server-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/cloudflare-mcp-server-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/cloudflare-mcp-server-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1313
        },
        {
          "path": "plugins/cloudflare-mcp-server-dev/README.md",
          "type": "blob",
          "size": 2298
        },
        {
          "path": "plugins/essential-logging",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 391
        },
        {
          "path": "plugins/essential-logging/README.md",
          "type": "blob",
          "size": 8736
        },
        {
          "path": "plugins/essential-logging/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/hooks/hooks.json",
          "type": "blob",
          "size": 1071
        },
        {
          "path": "plugins/essential-logging/hooks/log-task-call.ts",
          "type": "blob",
          "size": 2545
        },
        {
          "path": "plugins/essential-logging/hooks/log-task-result.ts",
          "type": "blob",
          "size": 2410
        },
        {
          "path": "plugins/essential-logging/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/shared/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/shared/hooks/enforce-output-style-tools.ts",
          "type": "blob",
          "size": 8452
        },
        {
          "path": "plugins/essential-logging/shared/hooks/enforce-structured-markdown.ts",
          "type": "blob",
          "size": 19267
        },
        {
          "path": "plugins/essential-logging/shared/hooks/log-subagent-start.ts",
          "type": "blob",
          "size": 3579
        },
        {
          "path": "plugins/essential-logging/shared/hooks/log-subagent-stop.ts",
          "type": "blob",
          "size": 5555
        },
        {
          "path": "plugins/essential-logging/shared/hooks/log-task-call.ts",
          "type": "blob",
          "size": 2510
        },
        {
          "path": "plugins/essential-logging/shared/hooks/log-task-result.ts",
          "type": "blob",
          "size": 2361
        },
        {
          "path": "plugins/essential-logging/shared/hooks/run-rule-checks.ts",
          "type": "blob",
          "size": 8849
        },
        {
          "path": "plugins/essential-logging/shared/hooks/test-folder-hooks.sh",
          "type": "blob",
          "size": 4466
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/ci-status.ts",
          "type": "blob",
          "size": 23651
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/config-resolver.ts",
          "type": "blob",
          "size": 2149
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/debug.ts",
          "type": "blob",
          "size": 8404
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/env-sync.ts",
          "type": "blob",
          "size": 11568
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/frontmatter.ts",
          "type": "blob",
          "size": 4841
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/github-comments.ts",
          "type": "blob",
          "size": 11911
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/index.ts",
          "type": "blob",
          "size": 5274
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/io.ts",
          "type": "blob",
          "size": 5723
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/log-file.ts",
          "type": "blob",
          "size": 7789
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/package-manager.ts",
          "type": "blob",
          "size": 2232
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/port.ts",
          "type": "blob",
          "size": 2444
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/session-state.ts",
          "type": "blob",
          "size": 8288
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/subagent-state.ts",
          "type": "blob",
          "size": 7791
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/task-state.test.ts",
          "type": "blob",
          "size": 8482
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/task-state.ts",
          "type": "blob",
          "size": 13125
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/toml.ts",
          "type": "blob",
          "size": 8019
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/transcripts.ts",
          "type": "blob",
          "size": 12169
        },
        {
          "path": "plugins/essential-logging/shared/hooks/utils/was-tool-event-main-agent.ts",
          "type": "blob",
          "size": 3607
        },
        {
          "path": "plugins/essential-logging/shared/hooks/validate-folder-structure-mkdir.ts",
          "type": "blob",
          "size": 8338
        },
        {
          "path": "plugins/essential-logging/shared/hooks/validate-folder-structure-write.ts",
          "type": "blob",
          "size": 7396
        },
        {
          "path": "plugins/essential-logging/shared/hooks/validate-rules-file.ts",
          "type": "blob",
          "size": 7159
        },
        {
          "path": "plugins/github-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 461
        },
        {
          "path": "plugins/github-orchestration/README.md",
          "type": "blob",
          "size": 7281
        },
        {
          "path": "plugins/github-orchestration/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/agents/github-orchestrator.md",
          "type": "blob",
          "size": 10884
        },
        {
          "path": "plugins/github-orchestration/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/hooks/add-github-context.ts",
          "type": "blob",
          "size": 17093
        },
        {
          "path": "plugins/github-orchestration/hooks/await-pr-status.ts",
          "type": "blob",
          "size": 6249
        },
        {
          "path": "plugins/github-orchestration/hooks/close-issue-on-session-end.ts",
          "type": "blob",
          "size": 8534
        },
        {
          "path": "plugins/github-orchestration/hooks/commit-session-await-ci-status.ts",
          "type": "blob",
          "size": 48164
        },
        {
          "path": "plugins/github-orchestration/hooks/commit-task-await-ci-status.ts",
          "type": "blob",
          "size": 7323
        },
        {
          "path": "plugins/github-orchestration/hooks/create-issue-on-prompt.ts",
          "type": "blob",
          "size": 13462
        },
        {
          "path": "plugins/github-orchestration/hooks/create-subagent-branch.ts",
          "type": "blob",
          "size": 4160
        },
        {
          "path": "plugins/github-orchestration/hooks/enhance-commit-context.ts",
          "type": "blob",
          "size": 10016
        },
        {
          "path": "plugins/github-orchestration/hooks/hooks.json",
          "type": "blob",
          "size": 5411
        },
        {
          "path": "plugins/github-orchestration/hooks/install-github.ts",
          "type": "blob",
          "size": 6401
        },
        {
          "path": "plugins/github-orchestration/hooks/post-explore-findings.ts",
          "type": "blob",
          "size": 6275
        },
        {
          "path": "plugins/github-orchestration/hooks/stacked-pr-subagent-stop.ts",
          "type": "blob",
          "size": 14242
        },
        {
          "path": "plugins/github-orchestration/hooks/sync-issue-to-plan.ts",
          "type": "blob",
          "size": 7311
        },
        {
          "path": "plugins/github-orchestration/hooks/sync-plan-to-issue.ts",
          "type": "blob",
          "size": 12748
        },
        {
          "path": "plugins/github-orchestration/hooks/sync-task-to-subissue.ts",
          "type": "blob",
          "size": 11991
        },
        {
          "path": "plugins/github-orchestration/hooks/track-issue-creation.ts",
          "type": "blob",
          "size": 7288
        },
        {
          "path": "plugins/github-orchestration/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/shared/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/enforce-output-style-tools.ts",
          "type": "blob",
          "size": 8452
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/enforce-structured-markdown.ts",
          "type": "blob",
          "size": 19267
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/log-subagent-start.ts",
          "type": "blob",
          "size": 3579
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/log-subagent-stop.ts",
          "type": "blob",
          "size": 5555
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/log-task-call.ts",
          "type": "blob",
          "size": 2510
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/log-task-result.ts",
          "type": "blob",
          "size": 2361
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/test-folder-hooks.sh",
          "type": "blob",
          "size": 4466
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/branch-naming.ts",
          "type": "blob",
          "size": 5010
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/ci-status.ts",
          "type": "blob",
          "size": 37558
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/debug.ts",
          "type": "blob",
          "size": 8404
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/frontmatter.ts",
          "type": "blob",
          "size": 4829
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/github-comments.ts",
          "type": "blob",
          "size": 17490
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/github-state.ts",
          "type": "blob",
          "size": 10253
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/index.ts",
          "type": "blob",
          "size": 7789
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/io.ts",
          "type": "blob",
          "size": 5723
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/issue-templates.ts",
          "type": "blob",
          "size": 4025
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/log-file.ts",
          "type": "blob",
          "size": 7789
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/native-subissues.ts",
          "type": "blob",
          "size": 8332
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/package-manager.ts",
          "type": "blob",
          "size": 2232
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/pr-stack.ts",
          "type": "blob",
          "size": 9008
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/pr-templates.ts",
          "type": "blob",
          "size": 6986
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/session-issues.ts",
          "type": "blob",
          "size": 14509
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/session-state.ts",
          "type": "blob",
          "size": 8717
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/stacked-branches.ts",
          "type": "blob",
          "size": 17777
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/subagent-state.ts",
          "type": "blob",
          "size": 7791
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/subissue-checklist.ts",
          "type": "blob",
          "size": 9495
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/task-state.test.ts",
          "type": "blob",
          "size": 8482
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/task-state.ts",
          "type": "blob",
          "size": 13438
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/toml.ts",
          "type": "blob",
          "size": 6064
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/transcripts.ts",
          "type": "blob",
          "size": 12169
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/was-tool-event-main-agent.ts",
          "type": "blob",
          "size": 3607
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/utils/work-type-detector.ts",
          "type": "blob",
          "size": 2674
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/validate-folder-structure-mkdir.ts",
          "type": "blob",
          "size": 8338
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/validate-folder-structure-write.ts",
          "type": "blob",
          "size": 7396
        },
        {
          "path": "plugins/github-orchestration/shared/hooks/validate-rules-file.ts",
          "type": "blob",
          "size": 7159
        },
        {
          "path": "plugins/github-orchestration/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/branch-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/branch-orchestration/SKILL.md",
          "type": "blob",
          "size": 11450
        },
        {
          "path": "plugins/github-orchestration/skills/ci-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/ci-orchestration/SKILL.md",
          "type": "blob",
          "size": 3589
        },
        {
          "path": "plugins/github-orchestration/skills/issue-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/issue-management/SKILL.md",
          "type": "blob",
          "size": 10021
        },
        {
          "path": "plugins/github-orchestration/skills/pr-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/pr-workflow/SKILL.md",
          "type": "blob",
          "size": 4220
        },
        {
          "path": "plugins/github-orchestration/skills/stacked-pr-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/stacked-pr-management/SKILL.md",
          "type": "blob",
          "size": 3863
        },
        {
          "path": "plugins/github-orchestration/skills/subissue-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/github-orchestration/skills/subissue-orchestration/SKILL.md",
          "type": "blob",
          "size": 4874
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 822
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/README.md",
          "type": "blob",
          "size": 2131
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-developer.md",
          "type": "blob",
          "size": 5142
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-researcher.md",
          "type": "blob",
          "size": 6983
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-reviewer.md",
          "type": "blob",
          "size": 5081
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-tester.md",
          "type": "blob",
          "size": 5681
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/cache-supabase-schema.ts",
          "type": "blob",
          "size": 11021
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/cleanup-supabase-session.ts",
          "type": "blob",
          "size": 7904
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/hooks.json",
          "type": "blob",
          "size": 4742
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/install-start-supabase-next.ts",
          "type": "blob",
          "size": 84328
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/install-vercel.ts",
          "type": "blob",
          "size": 6092
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/link-vercel-apps.ts",
          "type": "blob",
          "size": 9681
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/move-playwright-screenshots.ts",
          "type": "blob",
          "size": 5375
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-file-eslint.ts",
          "type": "blob",
          "size": 3339
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-file-vitests.ts",
          "type": "blob",
          "size": 4424
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-session-typechecks.ts",
          "type": "blob",
          "size": 3381
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-task-typechecks.ts",
          "type": "blob",
          "size": 4697
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-task-vitests.ts",
          "type": "blob",
          "size": 4381
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/setup-nodes-config.ts",
          "type": "blob",
          "size": 4496
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/use-proxy-nextjs-16.ts",
          "type": "blob",
          "size": 3806
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/hooks/validate-supabase-env.ts",
          "type": "blob",
          "size": 3467
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/enforce-output-style-tools.ts",
          "type": "blob",
          "size": 8452
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/enforce-structured-markdown.ts",
          "type": "blob",
          "size": 19267
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-subagent-start.ts",
          "type": "blob",
          "size": 3579
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-subagent-stop.ts",
          "type": "blob",
          "size": 5555
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-task-call.ts",
          "type": "blob",
          "size": 2510
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-task-result.ts",
          "type": "blob",
          "size": 2361
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/run-rule-checks.ts",
          "type": "blob",
          "size": 8849
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/test-folder-hooks.sh",
          "type": "blob",
          "size": 4466
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/ci-status.ts",
          "type": "blob",
          "size": 23651
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/config-resolver.ts",
          "type": "blob",
          "size": 2149
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/debug.ts",
          "type": "blob",
          "size": 8404
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/env-sync.ts",
          "type": "blob",
          "size": 29035
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/frontmatter.ts",
          "type": "blob",
          "size": 4841
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/github-comments.ts",
          "type": "blob",
          "size": 11911
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/index.ts",
          "type": "blob",
          "size": 5274
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/io.ts",
          "type": "blob",
          "size": 5723
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/log-file.ts",
          "type": "blob",
          "size": 7789
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/package-manager.ts",
          "type": "blob",
          "size": 2232
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/port.ts",
          "type": "blob",
          "size": 10346
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/process-info.ts",
          "type": "blob",
          "size": 5821
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/session-state.ts",
          "type": "blob",
          "size": 15542
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/subagent-state.ts",
          "type": "blob",
          "size": 7791
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/supabase-ports.ts",
          "type": "blob",
          "size": 17340
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/supabase-tmp-config.ts",
          "type": "blob",
          "size": 10032
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/task-state.test.ts",
          "type": "blob",
          "size": 8482
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/task-state.ts",
          "type": "blob",
          "size": 13125
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/toml.ts",
          "type": "blob",
          "size": 8019
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/transcripts.ts",
          "type": "blob",
          "size": 12169
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/vite-config.ts",
          "type": "blob",
          "size": 3163
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/was-tool-event-main-agent.ts",
          "type": "blob",
          "size": 3607
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/worktree.ts",
          "type": "blob",
          "size": 6256
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-folder-structure-mkdir.ts",
          "type": "blob",
          "size": 8338
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-folder-structure-write.ts",
          "type": "blob",
          "size": 7396
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-rules-file.ts",
          "type": "blob",
          "size": 7159
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui/SKILL.md",
          "type": "blob",
          "size": 13559
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui/references/advanced-patterns.md",
          "type": "blob",
          "size": 21844
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/supabase-local-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/supabase-local-dev/SKILL.md",
          "type": "blob",
          "size": 6369
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-design/SKILL.md",
          "type": "blob",
          "size": 12654
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-integration/SKILL.md",
          "type": "blob",
          "size": 16327
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-interaction",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-interaction/SKILL.md",
          "type": "blob",
          "size": 12417
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-wireframing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-wireframing/SKILL.md",
          "type": "blob",
          "size": 11851
        },
        {
          "path": "plugins/project-context",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 557
        },
        {
          "path": "plugins/project-context/README.md",
          "type": "blob",
          "size": 1737
        },
        {
          "path": "plugins/project-context/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/hooks/add-folder-context.ts",
          "type": "blob",
          "size": 10202
        },
        {
          "path": "plugins/project-context/hooks/encourage-context-review.ts",
          "type": "blob",
          "size": 8952
        },
        {
          "path": "plugins/project-context/hooks/hooks.json",
          "type": "blob",
          "size": 5243
        },
        {
          "path": "plugins/project-context/hooks/inject-agent-context.ts",
          "type": "blob",
          "size": 9526
        },
        {
          "path": "plugins/project-context/hooks/review-subagent-completion.ts",
          "type": "blob",
          "size": 5972
        },
        {
          "path": "plugins/project-context/hooks/run-file-eslint.ts",
          "type": "blob",
          "size": 3339
        },
        {
          "path": "plugins/project-context/hooks/run-file-vitests.ts",
          "type": "blob",
          "size": 4424
        },
        {
          "path": "plugins/project-context/hooks/run-task-typechecks.ts",
          "type": "blob",
          "size": 3760
        },
        {
          "path": "plugins/project-context/hooks/run-task-vitests.ts",
          "type": "blob",
          "size": 4381
        },
        {
          "path": "plugins/project-context/hooks/setup-nodes-config.ts",
          "type": "blob",
          "size": 4317
        },
        {
          "path": "plugins/project-context/hooks/track-task-scope.ts",
          "type": "blob",
          "size": 4567
        },
        {
          "path": "plugins/project-context/hooks/try-markdown-page.ts",
          "type": "blob",
          "size": 8286
        },
        {
          "path": "plugins/project-context/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/shared/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/shared/hooks/enforce-output-style-tools.ts",
          "type": "blob",
          "size": 8452
        },
        {
          "path": "plugins/project-context/shared/hooks/enforce-structured-markdown.ts",
          "type": "blob",
          "size": 19267
        },
        {
          "path": "plugins/project-context/shared/hooks/log-subagent-start.ts",
          "type": "blob",
          "size": 3579
        },
        {
          "path": "plugins/project-context/shared/hooks/log-subagent-stop.ts",
          "type": "blob",
          "size": 5555
        },
        {
          "path": "plugins/project-context/shared/hooks/log-task-call.ts",
          "type": "blob",
          "size": 2510
        },
        {
          "path": "plugins/project-context/shared/hooks/log-task-result.ts",
          "type": "blob",
          "size": 2361
        },
        {
          "path": "plugins/project-context/shared/hooks/run-rule-checks.ts",
          "type": "blob",
          "size": 8849
        },
        {
          "path": "plugins/project-context/shared/hooks/test-folder-hooks.sh",
          "type": "blob",
          "size": 4466
        },
        {
          "path": "plugins/project-context/shared/hooks/use-correct-package-manager.ts",
          "type": "blob",
          "size": 5102
        },
        {
          "path": "plugins/project-context/shared/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/ci-status.ts",
          "type": "blob",
          "size": 23145
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/config-resolver.ts",
          "type": "blob",
          "size": 2149
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/debug.ts",
          "type": "blob",
          "size": 8404
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/frontmatter.ts",
          "type": "blob",
          "size": 4841
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/github-comments.ts",
          "type": "blob",
          "size": 11911
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/index.ts",
          "type": "blob",
          "size": 5284
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/io.ts",
          "type": "blob",
          "size": 5723
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/log-file.ts",
          "type": "blob",
          "size": 7789
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/metadata-index.ts",
          "type": "blob",
          "size": 12220
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/package-manager.ts",
          "type": "blob",
          "size": 2232
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/plan-parser.ts",
          "type": "blob",
          "size": 13428
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/rules-matcher.ts",
          "type": "blob",
          "size": 5619
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/session-state.ts",
          "type": "blob",
          "size": 8288
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/subagent-state.ts",
          "type": "blob",
          "size": 7791
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/task-state.test.ts",
          "type": "blob",
          "size": 8482
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/task-state.ts",
          "type": "blob",
          "size": 13125
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/toml.ts",
          "type": "blob",
          "size": 6064
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/transcripts.ts",
          "type": "blob",
          "size": 12169
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/tsdoc-parser.ts",
          "type": "blob",
          "size": 13488
        },
        {
          "path": "plugins/project-context/shared/hooks/utils/was-tool-event-main-agent.ts",
          "type": "blob",
          "size": 3607
        },
        {
          "path": "plugins/project-context/shared/hooks/validate-folder-structure-mkdir.ts",
          "type": "blob",
          "size": 8338
        },
        {
          "path": "plugins/project-context/shared/hooks/validate-folder-structure-write.ts",
          "type": "blob",
          "size": 7396
        },
        {
          "path": "plugins/project-context/shared/hooks/validate-rules-file.ts",
          "type": "blob",
          "size": 7159
        },
        {
          "path": "plugins/project-context/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/skills/feature-sliced-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/project-context/skills/feature-sliced-design/SKILL.md",
          "type": "blob",
          "size": 36248
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://code.claude.com/schemas/marketplace-schema.json\",\n  \"name\": \"constellos-local\",\n  \"version\": \"1.0.0\",\n  \"owner\": {\n    \"name\": \"constellos\"\n  },\n  \"metadata\": {\n    \"description\": \"Plugin marketplace for Constellos development tools\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"essential-logging\",\n      \"description\": \"Core task execution logging and transcript utilities for all Claude Code sessions\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/essential-logging\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"github-orchestration\",\n      \"description\": \"GitHub workflow orchestration with branch context, commit enhancement, and CI management\",\n      \"version\": \"0.2.0\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/github-orchestration\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"nextjs-supabase-ai-sdk-dev\",\n      \"description\": \"Next.js, Supabase, and AI SDK development utilities\",\n      \"version\": \"0.1.3\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/nextjs-supabase-ai-sdk-dev\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"project-context\",\n      \"description\": \"Project context discovery, markdown-friendly documentation, and maintenance for Claude Code\",\n      \"version\": \"0.1.1\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/project-context\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"nodes-md-integration\",\n      \"description\": \"Integration plugin for nodes-md with interactive plugin debugging command\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/nodes-md-integration\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"cloudflare-mcp-server-dev\",\n      \"description\": \"Cloudflare Workers development with MCP servers for bindings, builds, observability, containers, and browser rendering\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"constellos\"\n      },\n      \"source\": \"./plugins/cloudflare-mcp-server-dev\",\n      \"strict\": false\n    }\n  ]\n}\n",
        ".claude-plugin/plugins": "../plugins",
        "plugins/cloudflare-mcp-server-dev/.claude-plugin/plugin.json": "{\n  \"name\": \"cloudflare-mcp-server-dev\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Cloudflare Workers development with MCP servers for bindings, builds, observability, containers, and browser rendering\",\n  \"author\": {\n    \"name\": \"constellos\"\n  },\n  \"repository\": \"https://github.com/constellos/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"cloudflare\",\n    \"workers\",\n    \"mcp\",\n    \"serverless\",\n    \"wrangler\",\n    \"durable-objects\"\n  ],\n  \"mcpServers\": {\n    \"cloudflare-bindings\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://bindings.mcp.cloudflare.com/mcp\"]\n    },\n    \"cloudflare-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://docs.mcp.cloudflare.com/mcp\"]\n    },\n    \"cloudflare-builds\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://builds.mcp.cloudflare.com/mcp\"]\n    },\n    \"cloudflare-observability\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://observability.mcp.cloudflare.com/mcp\"]\n    },\n    \"cloudflare-containers\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://containers.mcp.cloudflare.com/mcp\"]\n    },\n    \"cloudflare-browser\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote@latest\", \"https://browser.mcp.cloudflare.com/mcp\"]\n    }\n  }\n}\n",
        "plugins/cloudflare-mcp-server-dev/README.md": "# Cloudflare Workers MCP Dev\n\n> Cloudflare Workers development with MCP servers for bindings, builds, observability, containers, and browser rendering.\n\n## Overview\n\nThis plugin provides access to Cloudflare's managed MCP servers for developing and debugging Cloudflare Workers applications. Each MCP server connects via OAuth and provides specialized tools for different aspects of Workers development.\n\n## MCP Servers Included\n\n| Server | Purpose |\n|--------|---------|\n| **cloudflare-bindings** | Build Workers with storage (KV, R2, D1, Durable Objects), AI, and compute primitives |\n| **cloudflare-docs** | Access up-to-date Cloudflare Developer Documentation |\n| **cloudflare-builds** | Manage and monitor Workers Builds deployments |\n| **cloudflare-observability** | Debug logs, analytics, and error traces for Workers |\n| **cloudflare-containers** | Spin up sandbox development environments on demand |\n| **cloudflare-browser** | Fetch web pages, convert to markdown, and take screenshots |\n\n## Installation\n\n```bash\n# Add the constellos marketplace\nclaude plugin marketplace add https://github.com/constellos/claude-code-plugins\n\n# Install this plugin\nclaude plugin install cloudflare-workers-mcp-dev@constellos\n```\n\nOr add to your project's `.claude/settings.json`:\n\n```json\n{\n  \"enabledPlugins\": {\n    \"cloudflare-workers-mcp-dev@constellos\": true\n  }\n}\n```\n\n## Authentication\n\nEach MCP server requires OAuth authentication with your Cloudflare account. On first use, you'll be prompted to authorize access through Cloudflare's OAuth flow.\n\n## Use Cases\n\n- **Building Workers**: Use bindings server to interact with KV, R2, D1, and Durable Objects\n- **Debugging**: Use observability server to browse invocation logs and isolate errors\n- **Documentation**: Use docs server to get current Cloudflare documentation\n- **Testing**: Use containers server for isolated sandbox environments\n- **Web Scraping**: Use browser server for screenshots and page content extraction\n\n## References\n\n- [Cloudflare MCP Servers Documentation](https://developers.cloudflare.com/agents/model-context-protocol/mcp-servers-for-cloudflare/)\n- [mcp-remote package](https://www.npmjs.com/package/mcp-remote)\n- [cloudflare/mcp-server-cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)\n\n## License\n\nMIT\n",
        "plugins/essential-logging/.claude-plugin/plugin.json": "{\n  \"name\": \"essential-logging\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Core task execution logging and transcript utilities for all Claude Code sessions\",\n  \"author\": {\n    \"name\": \"constellos\"\n  },\n  \"repository\": \"https://github.com/constellos/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"logging\", \"task-tracking\", \"transcripts\", \"core\"],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/essential-logging/README.md": "# Essential Logging Plugin\n\n> Core task execution logging and transcript utilities for all Claude Code sessions\n\n## Purpose\n\nProvides foundational task logging infrastructure that tracks Task tool execution from PreToolUse (before agent starts) through PostToolUse (after completion). Creates a shared state file (`.claude/logs/task-calls.json`) that enables rich commit messages, GitHub integration, and task analytics across all plugins.\n\n**Key capabilities:**\n- Automatic task context capture (agent type, prompt, timestamps)\n- Shared state coordination between hooks\n- Debug logging with `DEBUG=task` environment variable\n- Foundation for plugin ecosystem (github-orchestration, project-context depend on this)\n\n## Contents\n\n### Hooks\n\n| Hook | Event | Purpose |\n|------|-------|---------|\n| log-task-call | PreToolUse[Task] | Saves task context before agent execution to `.claude/logs/task-calls.json` for later retrieval |\n| log-task-result | PostToolUse[Task] | Logs task completion metrics after agent finishes, using saved context from PreToolUse |\n\n## How It Works\n\n### Task Execution Flow\n\n```\n1. User calls Task tool with prompt/agent_type\n                    ↓\n2. PreToolUse[Task] fires\n   └─→ log-task-call.ts\n       └─→ saveTaskCallContext() → .claude/logs/task-calls.json\n                    ↓\n3. Subagent executes and performs file operations\n                    ↓\n4. PostToolUse[Task] fires (after subagent completes)\n   └─→ log-task-result.ts\n       └─→ loadTaskCallContext() → Log completion + metrics\n                    ↓\n5. Other plugins can read task-calls.json\n   └─→ github-orchestration: Creates GitHub subissues\n   └─→ project-context: Runs tests for task edits\n```\n\n### State File Schema\n\n**File**: `.claude/logs/task-calls.json`\n\n```json\n{\n  \"toolu_abc123\": {\n    \"toolUseId\": \"toolu_abc123\",\n    \"agentType\": \"Explore\",\n    \"sessionId\": \"session-xyz\",\n    \"timestamp\": \"2026-01-06T10:30:00.000Z\",\n    \"prompt\": \"Find all API endpoints in the codebase\"\n  },\n  \"toolu_def456\": {\n    \"toolUseId\": \"toolu_def456\",\n    \"agentType\": \"Plan\",\n    \"sessionId\": \"session-xyz\",\n    \"timestamp\": \"2026-01-06T10:35:00.000Z\",\n    \"prompt\": \"Design implementation for new feature\"\n  }\n}\n```\n\n**Lifecycle:**\n- **Created**: PreToolUse[Task] via `log-task-call.ts`\n- **Read**: PostToolUse[Task], SubagentStop hooks, other plugins\n- **Cleaned up**: After processing in PostToolUse or SubagentStop\n\n### Shared Utilities\n\nLocated in `shared/hooks/utils/`:\n\n**task-state.ts** - Core context management:\n```typescript\n// Save task context at PreToolUse\nawait saveTaskCallContext({\n  tool_use_id: 'toolu_abc123',\n  agent_type: 'Explore',\n  session_id: 'session-xyz',\n  prompt: 'Find all API endpoints',\n  cwd: '/path/to/project'\n});\n\n// Load context at PostToolUse or SubagentStop\nconst context = await loadTaskCallContext('toolu_abc123', '/path/to/project');\n// Returns: { toolUseId, agentType, sessionId, timestamp, prompt }\n\n// Cleanup after processing\nawait removeTaskCallContext('toolu_abc123', '/path/to/project');\n\n// Comprehensive task analysis (for SubagentStop)\nconst edits = await getTaskEdits('/path/to/agent-transcript.jsonl');\n// Returns: { agentNewFiles, agentEditedFiles, agentDeletedFiles, ... }\n```\n\n**Other utilities:**\n- `io.ts` - File operations (readJson, writeJson, fileExists)\n- `debug.ts` - Debug logger with DEBUG environment variable\n- `transcripts.ts` - Parse .jsonl transcript files\n- `frontmatter.ts` - YAML frontmatter parsing\n\n## Integration with Other Plugins\n\n### github-orchestration\n\nReads `task-calls.json` to:\n- **sync-task-to-subissue.ts** - Creates GitHub subissues from Task prompts (excludes Plan/Explore)\n- **enhance-commit-context.ts** - Enriches commits with task context and issue references\n\n### project-context\n\nUses task logging for:\n- **run-task-vitests.ts** - Runs tests for all files edited during task\n- **run-task-typechecks.ts** - Runs `tsc --noEmit` after task completes\n\n### Custom Plugins\n\nAny plugin can leverage task logging by reading `.claude/logs/task-calls.json`:\n\n```typescript\nimport { loadTaskCallContext } from 'essential-logging/shared/hooks/utils/task-state.js';\n\n// In your PostToolUse[Task] or SubagentStop hook\nconst context = await loadTaskCallContext(toolUseId, cwd);\nif (context) {\n  console.log('Task type:', context.agentType);\n  console.log('Task prompt:', context.prompt);\n  // Use context for your plugin logic\n}\n```\n\n## Installation\n\n```bash\n# Install from marketplace\nclaude plugin install essential-logging@constellos\n\n# Verify installation\nclaude plugin list\n\n# Should show:\n# ✓ essential-logging@0.1.0 (constellos)\n```\n\n**Important**: This plugin should be listed FIRST in marketplace.json to ensure its hooks fire before other plugins that depend on task context.\n\n## Debug Logging\n\nEnable debug output to trace task execution:\n\n```bash\n# Task logging only\nDEBUG=task claude\n\n# All plugin debug output\nDEBUG=* claude\n\n# Multiple namespaces\nDEBUG=task,subagent claude\n```\n\n**Debug output shows:**\n- When PreToolUse[Task] fires\n- Task metadata (tool_use_id, agent_type, prompt preview)\n- Context save operations\n- When PostToolUse[Task] fires\n- Task completion events\n\n**Debug logs written to:**\n- Console (stderr)\n- `.claude/logs/hook-events.json` (if enabled)\n\n### Example Debug Session\n\n```bash\n$ DEBUG=task claude\n\n[PreToolUse:Task] Hook triggered\n[PreToolUse:Task] Tool Use ID: toolu_abc123\n[PreToolUse:Task] Session ID: session-xyz\n[PreToolUse:Task] Agent Type: Explore\n[PreToolUse:Task] Prompt: Find all API endpoints in the codebase...\n[PreToolUse:Task] Saved task call context\n[PreToolUse:Task] Tool Use ID: toolu_abc123\n[PreToolUse:Task] Timestamp: 2026-01-06T10:30:00.000Z\n\n[PostToolUse:Task] Hook triggered\n[PostToolUse:Task] Tool Use ID: toolu_abc123\n[PostToolUse:Task] Session ID: session-xyz\n[PostToolUse:Task] Task completed\n[PostToolUse:Task] Agent Type: Explore\n[PostToolUse:Task] Response: Found 15 API endpoints across 8 files...\n```\n\n## Troubleshooting\n\n### Hooks not firing\n\n**Symptom**: No task-calls.json file created, no debug output\n\n**Solutions**:\n1. Verify plugin is installed:\n   ```bash\n   claude plugin list | grep essential-logging\n   ```\n\n2. Check plugin cache:\n   ```bash\n   ls ~/.claude/plugins/cache/constellos/essential-logging/\n   ```\n\n3. Reinstall plugin:\n   ```bash\n   claude plugin uninstall essential-logging@constellos\n   rm -rf ~/.claude/plugins/cache/constellos/essential-logging\n   claude plugin install --scope project essential-logging@constellos\n   ```\n\n### ENOENT errors\n\n**Symptom**: `ENOENT: no such file or directory, posix_spawn '/bin/sh'`\n\n**Cause**: Hook file paths incorrect or plugin cache stale\n\n**Solutions**:\n1. Clear plugin cache:\n   ```bash\n   rm -rf ~/.claude/plugins/cache/constellos/essential-logging\n   ```\n\n2. Reinstall:\n   ```bash\n   claude plugin install --scope project essential-logging@constellos\n   ```\n\n3. Verify hooks.json uses correct paths:\n   ```json\n   {\n     \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/log-task-call.ts\"\n   }\n   ```\n\n### task-calls.json growing large\n\n**Symptom**: State file contains old/stale entries\n\n**Cause**: Context cleanup failed in PostToolUse or SubagentStop\n\n**Solutions**:\n1. Manual cleanup:\n   ```bash\n   rm .claude/logs/task-calls.json\n   ```\n\n2. The file will be recreated on next Task tool use\n\n3. Check for hooks that read but don't cleanup:\n   ```typescript\n   // Always cleanup after reading\n   const context = await loadTaskCallContext(toolUseId, cwd);\n   // ... use context ...\n   await removeTaskCallContext(toolUseId, cwd); // Important!\n   ```\n\n## Architecture\n\n### Why Consolidate Logging?\n\n**Before**: Task logging hooks duplicated across 3+ plugins\n- `project-context/shared/hooks/log-task-call.ts`\n- `nextjs-supabase-ai-sdk-dev/shared/hooks/log-task-call.ts`\n- `github-context/shared/hooks/log-task-call.ts`\n\n**Problems**:\n- Code duplication (identical implementations)\n- Maintenance burden (fixes needed in multiple places)\n- Plugin cache conflicts (ENOENT errors)\n- Multiple PreToolUse[Task] hooks competing\n\n**After**: Single source of truth\n- `essential-logging/hooks/log-task-call.ts` (one implementation)\n- Other plugins READ shared state file\n- No duplication, no conflicts\n- Easier maintenance and debugging\n\n### Plugin Load Order\n\nEssential-logging must be listed FIRST in marketplace.json:\n\n```json\n{\n  \"plugins\": [\n    {\n      \"name\": \"essential-logging\",\n      \"source\": \"./plugins/essential-logging\"\n    },\n    {\n      \"name\": \"github-orchestration\",\n      \"source\": \"./plugins/github-orchestration\"\n    }\n  ]\n}\n```\n\n**Why?** Ensures essential-logging's PreToolUse[Task] hook fires BEFORE other plugins that depend on the state file.\n\n## License\n\nMIT\n",
        "plugins/essential-logging/hooks/hooks.json": "{\n  \"_comment\": \"Essential logging hooks for task execution tracking\",\n  \"_notes\": [\n    \"Provides core logging infrastructure for Task tool execution\",\n    \"PreToolUse[Task]: Saves task context before agent execution\",\n    \"PostToolUse[Task]: Logs task results after agent completion\"\n  ],\n  \"description\": \"Core task execution logging hooks\",\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Task\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/log-task-call.ts\",\n            \"description\": \"Logs Task tool calls before agent execution and saves context to .claude/logs/task-calls.json\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Task\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/log-task-result.ts\",\n            \"description\": \"Logs Task tool results after agent completion using saved context from task-calls.json\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/essential-logging/hooks/log-task-call.ts": "/**\n * PreToolUse[Task] hook - Save task call context for later retrieval\n *\n * This hook runs when the Task tool is ABOUT to be called (before the subagent starts).\n * It saves the task's context (type, prompt, toolUseId) to .claude/logs/task-calls.json\n * so it can be retrieved later in PostToolUse[Task] or SubagentStop.\n *\n * Import this hook in any plugin that needs to track task execution.\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../shared/types/types.js';\nimport { saveTaskCallContext } from '../shared/hooks/utils/task-state.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\n\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[PreToolUse:Task] Hook triggered');\n    console.log('[PreToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PreToolUse:Task] Session ID:', input.session_id);\n  }\n\n  try {\n    const toolInput = input.tool_input as {\n      subagent_type?: string;\n      prompt?: string;\n    };\n\n    const agentType = toolInput?.subagent_type || 'unknown';\n    const prompt = toolInput?.prompt || '';\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Agent Type:', agentType);\n      console.log('[PreToolUse:Task] Prompt:', prompt.slice(0, 100) + (prompt.length > 100 ? '...' : ''));\n    }\n\n    const context = await saveTaskCallContext({\n      tool_use_id: input.tool_use_id,\n      agent_type: agentType,\n      session_id: input.session_id,\n      prompt,\n      cwd: input.cwd,\n    });\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Saved task call context');\n      console.log('[PreToolUse:Task] Tool Use ID:', context.toolUseId);\n      console.log('[PreToolUse:Task] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PreToolUse:Task] Error saving task call context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/hooks/log-task-result.ts": "/**\n * PostToolUse[Task] hook - Log task completion\n *\n * This hook runs when the Task tool completes (after the subagent finishes).\n * It logs the task completion for debugging and audit purposes.\n *\n * Note: For detailed file operations analysis, see the SubagentStop hooks\n * which have access to the full agent transcript.\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { loadTaskCallContext } from '../shared/hooks/utils/task-state.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:Task] Hook triggered');\n    console.log('[PostToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PostToolUse:Task] Session ID:', input.session_id);\n  }\n\n  const logger = createDebugLogger(input.cwd, 'log-task-result', true);\n\n  try {\n    // Load the saved context from PreToolUse\n    const context = await loadTaskCallContext(input.tool_use_id, input.cwd);\n\n    if (!context) {\n      if (DEBUG) {\n        console.log('[PostToolUse:Task] No saved context found for tool_use_id:', input.tool_use_id);\n      }\n      return {};\n    }\n\n    const toolResponse = input.tool_response;\n    const responseText = typeof toolResponse === 'string'\n      ? toolResponse\n      : JSON.stringify(toolResponse).slice(0, 500);\n\n    await logger.logOutput({\n      tool_use_id: input.tool_use_id,\n      agent_type: context.agentType,\n      prompt: context.prompt.slice(0, 200),\n      response: responseText.slice(0, 200),\n      success: true,\n    });\n\n    if (DEBUG) {\n      console.log('[PostToolUse:Task] Task completed');\n      console.log('[PostToolUse:Task] Agent Type:', context.agentType);\n      console.log('[PostToolUse:Task] Response:', responseText.slice(0, 100));\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PostToolUse:Task] Error logging task result:', error);\n    }\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/enforce-output-style-tools.ts": "#!/usr/bin/env npx tsx\n\n/**\n * Output style tool enforcement hook\n *\n * PreToolUse hook that enforces tool restrictions defined in output style frontmatter.\n * When an output style specifies a `tools` array in its frontmatter, only those tools\n * are allowed for the main agent. Subagents can use any tools they need.\n *\n * This enables output styles to restrict Claude's capabilities to specific tools,\n * for example:\n * - Read-only mode: only Read, Glob, Grep tools\n * - Research mode: Read, Glob, Grep, WebSearch, WebFetch\n * - Full mode: all tools allowed (no restrictions)\n *\n * Output style files are located in .claude/output-styles/ with frontmatter like:\n * ```yaml\n * ---\n * name: read-only\n * description: Read-only access to codebase\n * tools: [Read, Glob, Grep]\n * ---\n * ```\n *\n * @module enforce-output-style-tools\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { runHook, wasToolEventMainAgent } from './utils/index.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('output-styles-permission-modes');\n\ninterface OutputStyleFrontmatter {\n  name?: string;\n  description?: string;\n  tools?: string[];\n}\n\n/**\n * Read settings.json to get the current output style name\n *\n * Checks both settings.local.json (project-specific) and settings.json (committed)\n * for the outputStyle configuration. Returns the first match found.\n *\n * @param cwd - The working directory to search for settings files\n * @returns The output style name, or undefined if not configured\n *\n * @example\n * ```typescript\n * const styleName = await getCurrentOutputStyle('/path/to/project');\n * console.log(styleName); // 'read-only' or undefined\n * ```\n */\nasync function getCurrentOutputStyle(cwd: string): Promise<string | undefined> {\n  const settingsPaths = [\n    path.join(cwd, '.claude', 'settings.local.json'),\n    path.join(cwd, '.claude', 'settings.json'),\n  ];\n\n  for (const settingsPath of settingsPaths) {\n    try {\n      const content = await fs.readFile(settingsPath, 'utf-8');\n      const settings = JSON.parse(content);\n      if (settings.outputStyle) {\n        return settings.outputStyle;\n      }\n    } catch {\n      // File doesn't exist or is invalid JSON, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Load and parse output style file to get frontmatter\n *\n * Reads the output style markdown file and extracts its YAML frontmatter,\n * which contains the style configuration including tool restrictions.\n *\n * @param cwd - The working directory where output styles are stored\n * @param styleName - The name of the output style (without .md extension)\n * @returns The parsed frontmatter, or undefined if file not found\n *\n * @example\n * ```typescript\n * const frontmatter = await loadOutputStyleFrontmatter(\n *   '/path/to/project',\n *   'read-only'\n * );\n *\n * if (frontmatter) {\n *   console.log('Allowed tools:', frontmatter.tools);\n *   // ['Read', 'Glob', 'Grep']\n * }\n * ```\n */\nasync function loadOutputStyleFrontmatter(\n  cwd: string,\n  styleName: string\n): Promise<OutputStyleFrontmatter | undefined> {\n  const stylePaths = [\n    path.join(cwd, '.claude', 'output-styles', `${styleName}.md`),\n    // Note: User-level styles would be in ~/.claude/output-styles/\n    // but we can't easily access user home in hooks without assumptions\n  ];\n\n  for (const stylePath of stylePaths) {\n    try {\n      const content = await fs.readFile(stylePath, 'utf-8');\n      const { data } = matter(content);\n      return data as OutputStyleFrontmatter;\n    } catch {\n      // File doesn't exist, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * PreToolUse hook that enforces tool restrictions from output style frontmatter\n *\n * Checks if the current tool is allowed by the active output style's tool restrictions.\n * This hook only applies to the main agent - subagents can use any tools they need\n * to complete their tasks.\n *\n * The enforcement flow:\n * 1. Check if this is the main agent (skip for subagents)\n * 2. Read current output style from settings.json\n * 3. Load output style frontmatter to get allowed tools list\n * 4. Check if current tool is in the allowed list\n * 5. Allow or deny based on the check\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Example output style: .claude/output-styles/read-only.md\n * // ---\n * // name: read-only\n * // tools: [Read, Glob, Grep]\n * // ---\n *\n * // Settings: .claude/settings.json\n * // { \"outputStyle\": \"read-only\" }\n *\n * // When main agent tries to use Read tool:\n * const result = await handler({\n *   tool_name: 'Read',\n *   tool_use_id: 'toolu_123',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // When main agent tries to use Write tool (not in allowed list):\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'The \"Write\" tool is not allowed...'\n * //   }\n * // }\n *\n * // When subagent tries to use Write tool:\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   transcript_path: '/path/.claude/logs/agent-xyz.jsonl', // Subagent transcript\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * // (Subagents are never restricted)\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Hook triggered');\n    console.log('[enforce-output-style-tools] Tool:', input.tool_name);\n  }\n\n  // Only enforce for main agent, not subagents\n  const isMainAgent = await wasToolEventMainAgent(input.transcript_path, input.tool_use_id);\n  if (!isMainAgent) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Subagent detected, skipping enforcement');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Get current output style\n  const styleName = await getCurrentOutputStyle(input.cwd);\n  if (!styleName) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No output style configured, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Current output style:', styleName);\n  }\n\n  // Load output style frontmatter\n  const frontmatter = await loadOutputStyleFrontmatter(input.cwd, styleName);\n  if (!frontmatter || !frontmatter.tools || frontmatter.tools.length === 0) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No tool restrictions defined, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const allowedTools = frontmatter.tools;\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Allowed tools:', allowedTools);\n  }\n\n  // Check if current tool is allowed\n  const isAllowed = allowedTools.includes(input.tool_name);\n\n  if (!isAllowed) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Tool not allowed, blocking');\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'deny',\n        permissionDecisionReason: `The \"${input.tool_name}\" tool is not allowed by the current output style \"${styleName}\". Allowed tools: ${allowedTools.join(', ')}`,\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Tool allowed');\n  }\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'allow',\n    },\n  };\n}\n\n// Export for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/enforce-structured-markdown.ts": "#!/usr/bin/env npx tsx\n/**\n * Structured markdown validation hook\n *\n * PreToolUse hook that validates structure and metadata for markdown files before\n * Write and Edit operations. Enforces consistent documentation structure across\n * different file types in the Claude Code project.\n *\n * This hook validates six types of markdown files:\n *\n * 1. Agent files in .claude/agents/ directory\n *    Required headings: Objective, Principles, Agent-scoped project context\n *\n * 2. Skill files in .claude/skills/ subdirectories (excludes SKILL.md templates)\n *    Required headings: Purpose, Skill-scoped context\n *\n * 3. Rules files in .claude/rules/ directory\n *    Required headings: Rules\n *\n * 4. Plugin README files in plugins README.md\n *    Required headings: Badge section, TOC, Overview, Features, Installation,\n *    Hooks, Configuration, Use Cases, Troubleshooting, Contributing, See Also, License\n *\n * 5. Plugin CLAUDE.md files in plugins CLAUDE.md\n *    Required headings: Quick Reference, Hook Summary, Key Features,\n *    Installation, Debug Logging, See Also\n *\n * 6. CLAUDE.md files in any other directory\n *    Required metadata: name, description\n *\n * The hook blocks Write/Edit operations if validation fails, providing detailed\n * error messages about missing headings and metadata fields.\n *\n * @module enforce-structured-markdown\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('enforce-structured-markdown');\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n}\n\n/**\n * Extract markdown headings from content\n *\n * Parses markdown content and extracts all headings (lines starting with #).\n * Preserves the full heading text including the hash symbols for pattern matching.\n *\n * @param content - The markdown content to parse\n * @returns Array of heading strings (e.g., [\"# Title\", \"## Section\"])\n *\n * @example\n * ```typescript\n * const content = `\n * # My Document\n * ## Overview\n * Some content\n * ## Implementation\n * `;\n * const headings = extractHeadings(content);\n * // Returns: [\"# My Document\", \"## Overview\", \"## Implementation\"]\n * ```\n */\nfunction extractHeadings(content: string): string[] {\n  const lines = content.split('\\n');\n  const headings: string[] = [];\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (trimmed.match(/^#{1,6}\\s+/)) {\n      headings.push(trimmed);\n    }\n  }\n\n  return headings;\n}\n\n/**\n * Check if a heading matches a pattern with wildcard support\n *\n * Compares a markdown heading against a pattern, supporting wildcard (*) matching.\n * Normalizes whitespace and performs case-insensitive comparison.\n *\n * @param heading - The heading to test (e.g., \"## Required Skills: None\")\n * @param pattern - The pattern to match against (e.g., \"## Required Skills:*\")\n * @returns True if the heading matches the pattern, false otherwise\n *\n * @example\n * ```typescript\n * // Exact match\n * matchesHeadingPattern(\"## Overview\", \"## Overview\"); // true\n *\n * // Wildcard match\n * matchesHeadingPattern(\"## Required Skills: None\", \"## Required Skills:*\"); // true\n * matchesHeadingPattern(\"## Required Skills: foo, bar\", \"## Required Skills:*\"); // true\n *\n * // No match\n * matchesHeadingPattern(\"## Implementation\", \"## Overview\"); // false\n * ```\n */\nfunction matchesHeadingPattern(heading: string, pattern: string): boolean {\n  // Normalize whitespace\n  const normalizedHeading = heading.replace(/\\s+/g, ' ').trim();\n  const normalizedPattern = pattern.replace(/\\s+/g, ' ').trim();\n\n  // Exact match\n  if (normalizedHeading === normalizedPattern) {\n    return true;\n  }\n\n  // Wildcard pattern\n  const regexPattern = normalizedPattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*');\n\n  const regex = new RegExp(`^${regexPattern}$`, 'i');\n  return regex.test(normalizedHeading);\n}\n\n/**\n * Validate that all required headings are present in content\n *\n * Checks that each required heading pattern has at least one match in the\n * provided headings array. Supports wildcard patterns for flexible matching.\n *\n * @param headings - Array of headings extracted from markdown content\n * @param required - Array of required heading patterns (supports wildcards)\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const headings = [\"# Title\", \"## Overview\", \"## Implementation\"];\n * const required = [\"## Overview\", \"## Implementation\", \"## Testing\"];\n *\n * const result = validateRequiredHeadings(headings, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required heading missing: \"## Testing\"']\n * // }\n * ```\n */\nfunction validateRequiredHeadings(headings: string[], required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const requiredPattern of required) {\n    const found = headings.some(h => matchesHeadingPattern(h, requiredPattern));\n    if (!found) {\n      errors.push(`Required heading missing: \"${requiredPattern}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Validate that all required metadata fields are present in frontmatter\n *\n * Checks that each required metadata field exists in the YAML frontmatter object.\n * Fields with falsy values are considered missing.\n *\n * @param metadata - Parsed YAML frontmatter object\n * @param required - Array of required field names\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const metadata = { name: \"My Skill\", version: \"1.0\" };\n * const required = [\"name\", \"description\", \"version\"];\n *\n * const result = validateRequiredMetadata(metadata, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required metadata field missing: \"description\"']\n * // }\n * ```\n */\nfunction validateRequiredMetadata(metadata: Record<string, unknown>, required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const field of required) {\n    if (!metadata[field]) {\n      errors.push(`Required metadata field missing: \"${field}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Determine file type and return appropriate validation rules\n *\n * Analyzes the file path to determine its type (agent, skill, rule, or CLAUDE.md)\n * and returns the corresponding validation requirements. Returns null for\n * non-markdown files or files that don't match any validation pattern.\n *\n * @param filePath - The path to the file being validated (absolute or relative)\n * @param cwd - The current working directory for resolving relative paths\n * @returns Validation rules object with type and requirements, or null if no validation needed\n *\n * @example\n * ```typescript\n * // Agent file\n * const rules1 = getFileValidationRules('.claude/agents/explorer.md', '/project');\n * // Returns: {\n * //   type: 'agent',\n * //   requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n * //   shouldValidate: true\n * // }\n *\n * // Skill file\n * const rules2 = getFileValidationRules('.claude/skills/my-skill/docs.md', '/project');\n * // Returns: {\n * //   type: 'skill',\n * //   requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n * //   requiredMetadata: ['name', 'description'],\n * //   shouldValidate: true\n * // }\n *\n * // SKILL.md template (skipped)\n * const rules3 = getFileValidationRules('.claude/skills/my-skill/SKILL.md', '/project');\n * // Returns: { type: 'skill-template', shouldValidate: false }\n *\n * // Non-markdown file\n * const rules4 = getFileValidationRules('src/index.ts', '/project');\n * // Returns: null\n * ```\n */\nfunction getFileValidationRules(filePath: string, cwd: string): {\n  type: string;\n  requiredHeadings?: string[];\n  requiredMetadata?: string[];\n  shouldValidate: boolean;\n} | null {\n  const relativePath = path.isAbsolute(filePath)\n    ? path.relative(cwd, filePath)\n    : filePath;\n\n  if (DEBUG) {\n    console.log('[enforce-structured-markdown] Checking file type:', relativePath);\n  }\n\n  // Agent files: .claude/agents/*.md\n  if (relativePath.includes(path.join('.claude', 'agents')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'agent',\n      requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n      shouldValidate: true,\n    };\n  }\n\n  // Skill files: .claude/skills/*/*.md (excluding SKILL.md and SKILL.template.md)\n  if (relativePath.includes(path.join('.claude', 'skills')) && relativePath.endsWith('.md')) {\n    const basename = path.basename(relativePath);\n    if (basename === 'SKILL.md' || basename === 'SKILL.template.md') {\n      if (DEBUG) {\n        console.log('[enforce-structured-markdown] Skipping SKILL.md or SKILL.template.md');\n      }\n      return { type: 'skill-template', shouldValidate: false };\n    }\n    return {\n      type: 'skill',\n      requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  // Rules files: .claude/rules/*.md\n  if (relativePath.includes(path.join('.claude', 'rules')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'rule',\n      requiredHeadings: ['## Rules'],\n      requiredMetadata: ['Required Skills'],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin README files: plugins/*/README.md\n  if (relativePath.match(/^plugins\\/[^/]+\\/README\\.md$/)) {\n    return {\n      type: 'plugin-readme',\n      requiredHeadings: [\n        '# 🔌 *',\n        '## 📋 Table of Contents',\n        '## 🎯 Overview',\n        '## ✨ Features',\n        '## 📦 Installation',\n        '## 🪝 Hooks',\n        '## ⚙️ Configuration',\n        '## 💡 Use Cases',\n        '## 🐛 Troubleshooting',\n        '## 🤝 Contributing',\n        '## 📚 See Also',\n        '## 📄 License',\n      ],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin CLAUDE.md files: plugins/*/CLAUDE.md (must come before general CLAUDE.md check)\n  if (relativePath.match(/^plugins\\/[^/]+\\/CLAUDE\\.md$/)) {\n    return {\n      type: 'plugin-claude',\n      requiredHeadings: [\n        '# *',\n        '## Quick Reference',\n        '## Hook Summary',\n        '## Key Features',\n        '## Installation',\n        '## Debug Logging',\n        '## See Also',\n      ],\n      requiredMetadata: ['title', 'description', 'version', 'folder'],\n      shouldValidate: true,\n    };\n  }\n\n  // CLAUDE.md files (any directory)\n  if (path.basename(relativePath) === 'CLAUDE.md') {\n    return {\n      type: 'claude-md',\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  return null;\n}\n\n/**\n * Extract the final content that will be written to the file\n *\n * Handles both Write and Edit operations to determine the content that will\n * result from the tool use. For Write, returns the content directly. For Edit,\n * reads the current file and applies the edit operation to get the final content.\n *\n * @param toolName - The tool being used (\"Write\" or \"Edit\")\n * @param toolInput - The tool input parameters\n * @param cwd - The current working directory for resolving relative paths\n * @returns The final content after the operation, or null if content cannot be determined\n *\n * @example\n * ```typescript\n * // Write operation\n * const content1 = await getContentFromToolInput(\n *   'Write',\n *   { file_path: 'doc.md', content: '# Title\\n## Section' },\n *   '/project'\n * );\n * // Returns: '# Title\\n## Section'\n *\n * // Edit operation (replaces text)\n * // Assumes file currently contains: '# Old\\n## Section'\n * const content2 = await getContentFromToolInput(\n *   'Edit',\n *   {\n *     file_path: 'doc.md',\n *     old_string: '# Old',\n *     new_string: '# New'\n *   },\n *   '/project'\n * );\n * // Returns: '# New\\n## Section'\n * ```\n */\nasync function getContentFromToolInput(\n  toolName: string,\n  toolInput: {\n    file_path?: string;\n    content?: string;\n    old_string?: string;\n    new_string?: string;\n  },\n  cwd: string\n): Promise<string | null> {\n  if (toolName === 'Write') {\n    return toolInput.content || null;\n  } else if (toolName === 'Edit') {\n    const filePath = toolInput.file_path;\n    if (!filePath || !toolInput.old_string || !toolInput.new_string) {\n      return null;\n    }\n\n    try {\n      const fullPath = path.isAbsolute(filePath) ? filePath : path.resolve(cwd, filePath);\n      const currentContent = await fs.readFile(fullPath, 'utf-8');\n      // Apply the edit\n      return currentContent.replace(toolInput.old_string, toolInput.new_string);\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * PreToolUse hook that validates markdown structure before Write/Edit operations\n *\n * Intercepts Write and Edit tool uses on markdown files to validate that they\n * meet the structural requirements for their file type. Blocks operations that\n * would create invalid agent, skill, rule, or CLAUDE.md files.\n *\n * This hook:\n * 1. Only processes Write and Edit operations on .md files\n * 2. Determines the file type from its path\n * 3. Extracts headings and metadata from the content\n * 4. Validates against type-specific requirements\n * 5. Blocks invalid operations with detailed error messages\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Valid agent file - allowed\n * const result1 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_123',\n *   tool_input: {\n *     file_path: '.claude/agents/my-agent.md',\n *     content: `\n * # My Agent\n * ## Objective\n * Do the task\n * ## Principles\n * Be thorough\n * ## Agent-scoped project context\n * Uses TypeScript\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // Invalid skill file (missing required heading) - denied\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   tool_input: {\n *     file_path: '.claude/skills/my-skill/docs.md',\n *     content: `\n * ---\n * name: My Skill\n * description: Does things\n * ---\n * # My Skill\n * ## Purpose\n * This is the purpose\n * (missing ## Skill-scoped context heading)\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'Skill validation failed...\\n\\nRequired heading missing: \"## Skill-scoped context\"'\n * //   }\n * // }\n *\n * // Non-markdown file - allowed (no validation)\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   tool_input: {\n *     file_path: 'src/index.ts',\n *     content: 'export const foo = \"bar\";'\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'enforce-structured-markdown', DEBUG || false);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n\n    const filePath = toolInput.file_path;\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only process .md files\n    if (!filePath.endsWith('.md')) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get validation rules for this file type\n    const validationRules = getFileValidationRules(filePath, input.cwd);\n    if (!validationRules || !validationRules.shouldValidate) {\n      await logger.logOutput({ message: 'No validation rules for this file type or validation skipped' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get the content (handles both Write and Edit)\n    const content = await getContentFromToolInput(input.tool_name, toolInput, input.cwd);\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter and content\n    const { data: metadata } = matter(content);\n    const headings = extractHeadings(content);\n\n    const allErrors: string[] = [];\n\n    // Validate required metadata\n    if (validationRules.requiredMetadata && validationRules.requiredMetadata.length > 0) {\n      const metadataValidation = validateRequiredMetadata(\n        metadata as Record<string, unknown>,\n        validationRules.requiredMetadata\n      );\n      if (!metadataValidation.valid) {\n        allErrors.push(...metadataValidation.errors);\n      }\n    }\n\n    // Validate required headings\n    if (validationRules.requiredHeadings && validationRules.requiredHeadings.length > 0) {\n      const headingValidation = validateRequiredHeadings(headings, validationRules.requiredHeadings);\n      if (!headingValidation.valid) {\n        allErrors.push(...headingValidation.errors);\n      }\n    }\n\n    await logger.logOutput({\n      fileType: validationRules.type,\n      headings,\n      metadata: Object.keys(metadata),\n      valid: allErrors.length === 0,\n      errors: allErrors,\n    });\n\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n');\n      const fileTypeDisplay = validationRules.type.replace('-', ' ');\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `${fileTypeDisplay.charAt(0).toUpperCase() + fileTypeDisplay.slice(1)} validation failed for ${path.basename(filePath)}:\\n\\n${errorMessage}\\n\\nPlease ensure all required headings and metadata fields are present.`,\n        },\n      };\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Structured markdown validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/log-subagent-start.ts": "/**\n * Subagent context tracking hook\n *\n * SubagentStart hook that saves agent execution context when a subagent begins.\n * The saved context can be retrieved later in SubagentStop hooks to analyze what\n * the agent did and correlate it with the original Task tool call.\n *\n * This hook saves the following information to .claude/logs/subagent-tasks.json:\n * - Agent ID and type\n * - Session ID\n * - Original task prompt (from Task tool input)\n * - Tool use ID (for correlating with Task call)\n * - Timestamp\n *\n * The saved context enables SubagentStop hooks to generate rich commit messages,\n * track file operations, and analyze agent behavior.\n *\n * @module log-subagent-start\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../types/types.js';\nimport { saveAgentStartContext } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStart hook handler that saves agent context\n *\n * Intercepts subagent startup to save execution context for later retrieval.\n * This enables tracking what tasks agents were given and correlating SubagentStop\n * events with the original Task tool call.\n *\n * The hook is non-blocking - errors are logged but do not prevent agent execution.\n *\n * @param input - SubagentStart hook input with agent metadata\n * @returns Hook output (empty object, this hook does not modify agent behavior)\n *\n * @example\n * ```typescript\n * // When an agent starts via Task tool:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   cwd: '/path/to/project',\n *   transcript_path: '/path/.claude/logs/session-xyz.jsonl'\n * });\n *\n * // Context is saved to .claude/logs/subagent-tasks.json:\n * // {\n * //   \"agent-abc123\": {\n * //     \"agentId\": \"agent-abc123\",\n * //     \"agentType\": \"Explore\",\n * //     \"sessionId\": \"session-xyz\",\n * //     \"prompt\": \"Find all API endpoints\",\n * //     \"toolUseId\": \"toolu_xyz\",\n * //     \"timestamp\": \"2025-01-19T12:00:00.000Z\"\n * //   }\n * // }\n *\n * // Later, in SubagentStop, this context can be retrieved via getAgentEdits()\n * ```\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStart] Hook triggered');\n    console.log('[SubagentStart] Agent ID:', input.agent_id);\n    console.log('[SubagentStart] Agent Type:', input.agent_type);\n    console.log('[SubagentStart] Session ID:', input.session_id);\n  }\n\n  try {\n    const context = await saveAgentStartContext({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n      session_id: input.session_id,\n      cwd: input.cwd,\n      transcript_path: input.transcript_path,\n    });\n\n    if (DEBUG) {\n      console.log('[SubagentStart] Saved agent context');\n      console.log('[SubagentStart] Prompt:', context.prompt.slice(0, 100) + (context.prompt.length > 100 ? '...' : ''));\n      console.log('[SubagentStart] Tool Use ID:', context.toolUseId);\n      console.log('[SubagentStart] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStart] Error saving agent context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/log-subagent-stop.ts": "/**\n * Subagent completion analysis hook\n *\n * SubagentStop hook that analyzes agent execution results when a subagent completes.\n * It parses the agent's transcript to extract file operations and correlates them\n * with the saved context from SubagentStart.\n *\n * This hook analyzes and logs:\n * - New files created by the agent\n * - Files deleted by the agent\n * - Files edited by the agent\n * - Agent type and original task prompt\n * - Preloaded skills used by the agent\n *\n * After analysis, the hook cleans up the saved context from SubagentStart to prevent\n * the context file from growing indefinitely.\n *\n * The analysis results are logged to console when DEBUG mode is enabled, making it\n * easy to understand what each agent did during execution.\n *\n * @module log-subagent-stop\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../types/types.js';\nimport { getAgentEdits } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStop hook handler that analyzes agent execution results\n *\n * Intercepts subagent completion to analyze what the agent did during execution.\n * Parses the agent transcript to extract file operations and correlates with the\n * saved context from SubagentStart to provide complete execution metadata.\n *\n * The hook is non-blocking - errors are logged but do not prevent session continuation.\n *\n * @param input - SubagentStop hook input with agent transcript path\n * @returns Hook output (empty object, this hook does not modify behavior)\n *\n * @example\n * ```typescript\n * // When an agent completes:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_transcript_path: '/path/.claude/logs/agent-abc123.jsonl',\n *   cwd: '/path/to/project'\n * });\n *\n * // With DEBUG=* enabled, logs output like:\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Analysis Complete\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Type: Explore\n * // [SubagentStop] Agent Prompt: Find all API endpoints\n * // [SubagentStop] Files Created: 0\n * // [SubagentStop] Files Edited: 2\n * // [SubagentStop]   ~ src/api/routes.ts\n * // [SubagentStop]   ~ src/api/handlers.ts\n * // [SubagentStop] Files Deleted: 0\n * // [SubagentStop] ─────────────────────────────────────────\n *\n * // The saved context from SubagentStart is automatically cleaned up\n * ```\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStop] Hook triggered');\n    console.log('[SubagentStop] Agent ID:', input.agent_id);\n    console.log('[SubagentStop] Agent Transcript:', input.agent_transcript_path);\n  }\n\n  try {\n    const edits = await getAgentEdits(input.agent_transcript_path);\n\n    if (DEBUG) {\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Analysis Complete');\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Type:', edits.subagentType);\n      console.log('[SubagentStop] Agent Prompt:', edits.agentPrompt.slice(0, 100) + (edits.agentPrompt.length > 100 ? '...' : ''));\n\n      if (edits.agentFile) {\n        console.log('[SubagentStop] Agent Definition:', edits.agentFile);\n      }\n\n      if (edits.agentPreloadedSkillsFiles.length > 0) {\n        console.log('[SubagentStop] Preloaded Skills:', edits.agentPreloadedSkillsFiles.length);\n        edits.agentPreloadedSkillsFiles.forEach((skill) => {\n          console.log('[SubagentStop]   -', skill);\n        });\n      }\n\n      if (edits.agentNewFiles.length > 0) {\n        console.log('[SubagentStop] Files Created:', edits.agentNewFiles.length);\n        edits.agentNewFiles.forEach((file) => {\n          console.log('[SubagentStop]   +', file);\n        });\n      }\n\n      if (edits.agentEditedFiles.length > 0) {\n        console.log('[SubagentStop] Files Edited:', edits.agentEditedFiles.length);\n        edits.agentEditedFiles.forEach((file) => {\n          console.log('[SubagentStop]   ~', file);\n        });\n      }\n\n      if (edits.agentDeletedFiles.length > 0) {\n        console.log('[SubagentStop] Files Deleted:', edits.agentDeletedFiles.length);\n        edits.agentDeletedFiles.forEach((file) => {\n          console.log('[SubagentStop]   -', file);\n        });\n      }\n\n      if (edits.agentNewFiles.length === 0 &&\n          edits.agentEditedFiles.length === 0 &&\n          edits.agentDeletedFiles.length === 0) {\n        console.log('[SubagentStop] No file operations detected');\n      }\n\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStop] Error analyzing agent edits:', error);\n    }\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/log-task-call.ts": "/**\n * PreToolUse[Task] hook - Save task call context for later retrieval\n *\n * This hook runs when the Task tool is ABOUT to be called (before the subagent starts).\n * It saves the task's context (type, prompt, toolUseId) to .claude/logs/task-calls.json\n * so it can be retrieved later in PostToolUse[Task] or SubagentStop.\n *\n * Import this hook in any plugin that needs to track task execution.\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { saveTaskCallContext } from './utils/task-state.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[PreToolUse:Task] Hook triggered');\n    console.log('[PreToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PreToolUse:Task] Session ID:', input.session_id);\n  }\n\n  try {\n    const toolInput = input.tool_input as {\n      subagent_type?: string;\n      prompt?: string;\n    };\n\n    const agentType = toolInput?.subagent_type || 'unknown';\n    const prompt = toolInput?.prompt || '';\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Agent Type:', agentType);\n      console.log('[PreToolUse:Task] Prompt:', prompt.slice(0, 100) + (prompt.length > 100 ? '...' : ''));\n    }\n\n    const context = await saveTaskCallContext({\n      tool_use_id: input.tool_use_id,\n      agent_type: agentType,\n      session_id: input.session_id,\n      prompt,\n      cwd: input.cwd,\n    });\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Saved task call context');\n      console.log('[PreToolUse:Task] Tool Use ID:', context.toolUseId);\n      console.log('[PreToolUse:Task] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PreToolUse:Task] Error saving task call context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/log-task-result.ts": "/**\n * PostToolUse[Task] hook - Log task completion\n *\n * This hook runs when the Task tool completes (after the subagent finishes).\n * It logs the task completion for debugging and audit purposes.\n *\n * Note: For detailed file operations analysis, see the SubagentStop hooks\n * which have access to the full agent transcript.\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { loadTaskCallContext } from './utils/task-state.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:Task] Hook triggered');\n    console.log('[PostToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PostToolUse:Task] Session ID:', input.session_id);\n  }\n\n  const logger = createDebugLogger(input.cwd, 'log-task-result', true);\n\n  try {\n    // Load the saved context from PreToolUse\n    const context = await loadTaskCallContext(input.tool_use_id, input.cwd);\n\n    if (!context) {\n      if (DEBUG) {\n        console.log('[PostToolUse:Task] No saved context found for tool_use_id:', input.tool_use_id);\n      }\n      return {};\n    }\n\n    const toolResponse = input.tool_response;\n    const responseText = typeof toolResponse === 'string'\n      ? toolResponse\n      : JSON.stringify(toolResponse).slice(0, 500);\n\n    await logger.logOutput({\n      tool_use_id: input.tool_use_id,\n      agent_type: context.agentType,\n      prompt: context.prompt.slice(0, 200),\n      response: responseText.slice(0, 200),\n      success: true,\n    });\n\n    if (DEBUG) {\n      console.log('[PostToolUse:Task] Task completed');\n      console.log('[PostToolUse:Task] Agent Type:', context.agentType);\n      console.log('[PostToolUse:Task] Response:', responseText.slice(0, 100));\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PostToolUse:Task] Error logging task result:', error);\n    }\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/run-rule-checks.ts": "/**\n * Rule-based check runner for PostToolUse[Write|Edit] hooks\n *\n * Runs checks defined in `.claude/rules/*.md` file frontmatter.\n * Checks are blocking - if any check fails, the edit is blocked.\n *\n * Frontmatter format:\n * ```yaml\n * ---\n * globs: [\"**\\/*.ts\", \"**\\/*.tsx\", \"!**\\/*.test.ts\"]\n * checks:\n *   - lint\n *   - typecheck\n *   - vitest\n * ---\n * ```\n *\n * @module run-rule-checks\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { runHook } from './utils/io.js';\nimport { parseFrontmatter } from './utils/frontmatter.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { readdir, readFile } from 'fs/promises';\nimport { join, relative } from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for each check in milliseconds (30 seconds) */\nconst CHECK_TIMEOUT_MS = 30000;\n\n/** Supported check types and their commands */\nconst CHECK_COMMANDS: Record<string, (filePath: string) => string> = {\n  lint: (filePath) => `npx eslint \"${filePath}\"`,\n  typecheck: (filePath) => `npx tsc --noEmit \"${filePath}\"`,\n  vitest: (filePath) => `npx vitest run \"${filePath}\" --reporter=verbose`,\n};\n\n/**\n * Check result from running a single check\n */\ninterface CheckResult {\n  check: string;\n  passed: boolean;\n  output: string;\n}\n\n/**\n * Rule definition parsed from frontmatter\n */\ninterface RuleDefinition {\n  filePath: string;\n  globs: string[];\n  checks: string[];\n}\n\n/**\n * Simple glob pattern matcher\n *\n * Supports:\n * - `*` matches any characters except /\n * - `**` matches any characters including /\n * - `!` prefix for negation patterns\n *\n * @param pattern - Glob pattern to match\n * @param filePath - File path to test\n * @returns True if pattern matches (or doesn't match for negation)\n */\nfunction matchGlob(pattern: string, filePath: string): boolean {\n  // Handle negation patterns\n  if (pattern.startsWith('!')) {\n    return !matchGlob(pattern.slice(1), filePath);\n  }\n\n  // Convert glob to regex\n  // Use unique placeholders that won't appear in normal patterns\n  const DOUBLE_STAR_SLASH = '<<<DSS>>>';\n  const DOUBLE_STAR = '<<<DS>>>';\n\n  const regexPattern = pattern\n    // Escape special regex characters except * and ?\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    // Use placeholders to avoid * in replacements being re-replaced\n    .replace(/\\*\\*\\//g, DOUBLE_STAR_SLASH)   // Placeholder for **/\n    .replace(/\\*\\*/g, DOUBLE_STAR)            // Placeholder for **\n    // Convert single * to match anything except /\n    .replace(/\\*/g, '[^/]*')\n    // Convert ? to match single character (BEFORE restoring placeholders!)\n    .replace(/\\?/g, '.')\n    // Restore placeholders with proper regex patterns\n    .replace(new RegExp(DOUBLE_STAR_SLASH, 'g'), '(?:.*/)?')  // **/ becomes optional path prefix\n    .replace(new RegExp(DOUBLE_STAR, 'g'), '.*');             // ** becomes match anything\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(filePath);\n}\n\n/**\n * Check if a file path matches any of the glob patterns\n *\n * Processes patterns in order - positive patterns include, negative exclude.\n *\n * @param filePath - File path to check\n * @param patterns - Array of glob patterns\n * @returns True if file matches the patterns\n */\nfunction matchesPatterns(filePath: string, patterns: string[]): boolean {\n  // Normalize path separators\n  const normalizedPath = filePath.replace(/\\\\/g, '/');\n\n  let matched = false;\n\n  for (const pattern of patterns) {\n    if (pattern.startsWith('!')) {\n      // Negation pattern - if it matches, exclude\n      if (matchGlob(pattern.slice(1), normalizedPath)) {\n        matched = false;\n      }\n    } else {\n      // Positive pattern - if it matches, include\n      if (matchGlob(pattern, normalizedPath)) {\n        matched = true;\n      }\n    }\n  }\n\n  return matched;\n}\n\n/**\n * Load all rule files from .claude/rules/ directory\n *\n * @param cwd - Current working directory\n * @returns Array of parsed rule definitions\n */\nasync function loadRules(cwd: string): Promise<RuleDefinition[]> {\n  const rulesDir = join(cwd, '.claude', 'rules');\n  const rules: RuleDefinition[] = [];\n\n  try {\n    const files = await readdir(rulesDir);\n\n    for (const file of files) {\n      if (!file.endsWith('.md')) continue;\n\n      const filePath = join(rulesDir, file);\n      const content = await readFile(filePath, 'utf-8');\n      const { data } = parseFrontmatter(content);\n\n      // Extract globs and checks from frontmatter\n      const globs = Array.isArray(data.globs) ? (data.globs as string[]) : [];\n      const checks = Array.isArray(data.checks) ? (data.checks as string[]) : [];\n\n      // Only include rules that have both globs and checks\n      if (globs.length > 0 && checks.length > 0) {\n        rules.push({ filePath, globs, checks });\n      }\n    }\n  } catch {\n    // No rules directory or can't read it - that's fine\n  }\n\n  return rules;\n}\n\n/**\n * Run a single check on a file\n *\n * @param check - Check type to run (lint, typecheck, vitest)\n * @param filePath - Absolute path to file to check\n * @param cwd - Current working directory\n * @returns Check result with pass/fail and output\n */\nasync function runCheck(check: string, filePath: string, cwd: string): Promise<CheckResult> {\n  const commandFn = CHECK_COMMANDS[check];\n\n  if (!commandFn) {\n    return {\n      check,\n      passed: true,\n      output: `Unknown check type: ${check}`,\n    };\n  }\n\n  const command = commandFn(filePath);\n\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd,\n      timeout: CHECK_TIMEOUT_MS,\n    });\n\n    // Check passed\n    return {\n      check,\n      passed: true,\n      output: truncateOutput(stdout || stderr || 'Check passed'),\n    };\n  } catch (error) {\n    // Check failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'Check failed';\n\n    return {\n      check,\n      passed: false,\n      output: truncateOutput(output),\n    };\n  }\n}\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n *\n * @param output - Output string to truncate\n * @returns Truncated string with indicator if truncated\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs checks defined in matching rule files for the edited file.\n * Blocks if any check fails.\n *\n * @param input - PostToolUse hook input\n * @returns Hook output with blocking decision if checks fail\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath) {\n    return {};\n  }\n\n  // Get relative path for glob matching\n  const relativePath = relative(input.cwd, filePath).replace(/\\\\/g, '/');\n\n  // Load all rules\n  const rules = await loadRules(input.cwd);\n\n  // Find all checks that apply to this file\n  const checksToRun = new Set<string>();\n\n  for (const rule of rules) {\n    if (matchesPatterns(relativePath, rule.globs)) {\n      for (const check of rule.checks) {\n        checksToRun.add(check);\n      }\n    }\n  }\n\n  // If no checks apply, allow the edit\n  if (checksToRun.size === 0) {\n    return {};\n  }\n\n  // Run all applicable checks\n  const results: CheckResult[] = [];\n\n  for (const check of checksToRun) {\n    const result = await runCheck(check, filePath, input.cwd);\n    results.push(result);\n  }\n\n  // Check if any failed\n  const failedResults = results.filter((r) => !r.passed);\n\n  if (failedResults.length === 0) {\n    // All checks passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ Checks passed: ${[...checksToRun].join(', ')}`,\n      },\n    };\n  }\n\n  // Format failure message\n  const failureMessages = failedResults\n    .map((r) => `**${r.check}**:\\n${r.output}`)\n    .join('\\n\\n');\n\n  // Block the edit with actionable feedback\n  return {\n    decision: 'block',\n    reason: `Fix these errors before continuing:\\n\\n${failureMessages}`,\n    hookSpecificOutput: {\n      hookEventName: 'PostToolUse',\n      additionalContext: `❌ Checks failed: ${failedResults.map((r) => r.check).join(', ')}\\n\\n${failureMessages}`,\n    },\n  };\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/test-folder-hooks.sh": "#!/bin/bash\n# Test script for folder validation hooks\n# Tests validate-folder-structure-bash.ts and validate-folder-structure-write.ts\n\nset -e\n\necho \"Testing folder validation hooks...\"\necho \"\"\n\nCWD=\"/home/user/claude-code-plugins\"\nSESSION_ID=\"test-session-123\"\nTRANSCRIPT_PATH=\"/tmp/test-transcript.jsonl\"\n\n# Test 1: validate-folder-structure-bash.ts with allowed folder\necho \"=== Test 1: Bash hook - allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_1\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 2: validate-folder-structure-bash.ts with forbidden folder\necho \"=== Test 2: Bash hook - forbidden subfolder (should deny) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_2\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/invalid_folder\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 3: validate-folder-structure-bash.ts with mkdir -p\necho \"=== Test 3: Bash hook - mkdir with -p flag (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_3\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir -p shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 4: validate-folder-structure-bash.ts with non-mkdir command\necho \"=== Test 4: Bash hook - non-mkdir command (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_4\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"ls -la\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 5: validate-folder-structure-write.ts with allowed file\necho \"=== Test 5: Write hook - allowed file in allowed folder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_5\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 6: validate-folder-structure-write.ts with forbidden file\necho \"=== Test 6: Write hook - forbidden file (should deny if files spec exists) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_6\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/forbidden.exe\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 7: validate-folder-structure-write.ts with file in new subfolder\necho \"=== Test 7: Write hook - file in allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_7\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/types/new-type.ts\",\n    \"content\": \"export type NewType = string;\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 8: validate-folder-structure-write.ts with non-Write tool\necho \"=== Test 8: Write hook - non-Write tool (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_8\",\n  \"tool_name\": \"Read\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\necho \"All tests completed!\"\n",
        "plugins/essential-logging/shared/hooks/utils/ci-status.ts": "/**\n * Shared CI status utilities for GitHub CI integration\n *\n * Provides common functions for checking CI status, waiting for checks,\n * extracting preview URLs, and formatting results. Used by:\n * - commit-task-await-ci-status.ts (SubagentStop)\n * - await-pr-status.ts (PostToolUse[Bash])\n * - commit-session-await-ci-status.ts (Stop)\n *\n * @module ci-status\n */\n\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum output characters for CI status (prevents context bloat) */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Default CI check timeout in milliseconds (10 minutes) */\nconst DEFAULT_TIMEOUT_MS = 600000;\n\n/** Polling interval for fail-fast CI checks in milliseconds (5 seconds) */\nconst POLL_INTERVAL_MS = 5000;\n\n/** Max consecutive empty check polls before assuming no CI configured */\nconst MAX_EMPTY_CHECK_POLLS = 3;\n\n/**\n * Branch sync status result\n */\nexport interface BranchSyncResult {\n  /** Whether branch is in sync with main */\n  inSync: boolean;\n  /** Number of commits behind main */\n  behindCount: number;\n  /** Number of commits ahead of main */\n  aheadCount: number;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Merge conflict check result\n */\nexport interface MergeConflictResult {\n  /** Whether PR has merge conflicts */\n  hasConflicts: boolean;\n  /** Mergeable state from GitHub */\n  mergeableState?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Fail-fast CI check result\n */\nexport interface FailFastResult {\n  /** Whether all checks passed */\n  success: boolean;\n  /** Blocking reason if failed */\n  blockReason?: string;\n  /** Failed check name if applicable */\n  failedCheck?: string;\n  /** All check statuses */\n  checks: CheckStatus[];\n  /** PR number if found */\n  prNumber?: number;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * Result from a CI check operation\n */\nexport interface CICheckResult {\n  /** Whether all CI checks passed */\n  success: boolean;\n  /** Combined output from CI checks */\n  output: string;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * CI run details from GitHub\n */\nexport interface CIRunDetails {\n  /** CI workflow URL */\n  url?: string;\n  /** CI status (queued, in_progress, completed) */\n  status?: string;\n  /** CI conclusion (success, failure, cancelled) */\n  conclusion?: string;\n  /** Workflow name */\n  name?: string;\n}\n\n/**\n * Individual check status\n */\nexport interface CheckStatus {\n  /** Check name */\n  name: string;\n  /** Check status emoji */\n  emoji: string;\n  /** Check status (success, failure, pending) */\n  status: string;\n  /** Details URL */\n  url?: string;\n}\n\n/**\n * PR existence check result\n */\nexport interface PRCheckResult {\n  /** Whether PR exists */\n  exists: boolean;\n  /** PR number if exists */\n  prNumber?: number;\n  /** PR URL if exists */\n  prUrl?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Preview URLs extracted from PR\n */\nexport interface PreviewUrls {\n  /** Web app preview URL */\n  webUrl?: string;\n  /** Marketing app preview URL */\n  marketingUrl?: string;\n  /** All preview URLs found */\n  allUrls: string[];\n}\n\n/**\n * Execute a shell command with timeout\n *\n * @param command - Command to execute\n * @param cwd - Working directory\n * @param timeout - Timeout in milliseconds (default: 30s)\n * @returns Command result with success flag and output\n *\n * @example\n * ```typescript\n * const result = await execCommand('gh pr list', '/path/to/repo');\n * if (result.success) {\n *   console.log(result.stdout);\n * }\n * ```\n */\nexport async function execCommand(\n  command: string,\n  cwd: string,\n  timeout = 30000\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a PR exists for the given branch\n *\n * @param branch - Branch name to check\n * @param cwd - Working directory\n * @returns PR check result with number and URL if exists\n *\n * @example\n * ```typescript\n * const prCheck = await checkPRExists('feature-branch', '/path/to/repo');\n * if (prCheck.exists) {\n *   console.log(`PR #${prCheck.prNumber}: ${prCheck.prUrl}`);\n * }\n * ```\n */\nexport async function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<PRCheckResult> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return { exists: false, error: 'GitHub CLI not installed' };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return { exists: false, error: 'GitHub CLI not authenticated' };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number,url --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return { exists: false, error: `gh pr list failed: ${prListResult.stderr}` };\n  }\n\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n    if (Array.isArray(prs) && prs.length > 0) {\n      return {\n        exists: true,\n        prNumber: prs[0].number,\n        prUrl: prs[0].url,\n      };\n    }\n    return { exists: false };\n  } catch {\n    return { exists: false, error: 'Failed to parse gh output' };\n  }\n}\n\n/**\n * Get PR number for the current branch\n *\n * @param cwd - Working directory\n * @returns PR number or null if no PR exists\n *\n * @example\n * ```typescript\n * const prNumber = await getPRForCurrentBranch('/path/to/repo');\n * if (prNumber) {\n *   const ciResult = await waitForCIChecks({ prNumber, cwd });\n * }\n * ```\n */\nexport async function getPRForCurrentBranch(cwd: string): Promise<number | null> {\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return null;\n  }\n\n  const prCheck = await checkPRExists(branchResult.stdout, cwd);\n  return prCheck.exists ? (prCheck.prNumber ?? null) : null;\n}\n\n/**\n * Wait for CI checks to complete on a PR\n *\n * Uses `gh pr checks --watch` to wait for all CI checks to finish.\n * Blocks until all checks complete or timeout is reached.\n *\n * @param options - Wait options\n * @param options.prNumber - PR number to check (required if no commitSha)\n * @param options.commitSha - Commit SHA to check (alternative to prNumber)\n * @param options.timeout - Timeout in milliseconds (default: 10 minutes)\n * @param cwd - Working directory\n * @returns CI check result with success status and output\n *\n * @example\n * ```typescript\n * const result = await waitForCIChecks({ prNumber: 123 }, '/path/to/repo');\n * if (result.success) {\n *   console.log('All CI checks passed!');\n * } else {\n *   console.log('CI failed:', result.output);\n * }\n * ```\n */\nexport async function waitForCIChecks(\n  options: {\n    prNumber?: number;\n    commitSha?: string;\n    timeout?: number;\n  },\n  cwd: string\n): Promise<CICheckResult> {\n  const { prNumber, commitSha, timeout = DEFAULT_TIMEOUT_MS } = options;\n\n  if (!prNumber && !commitSha) {\n    return { success: false, output: '', error: 'Either prNumber or commitSha required' };\n  }\n\n  try {\n    // Build command based on what we have\n    const target = prNumber ? prNumber.toString() : commitSha!;\n    const command = `gh pr checks ${target} --watch`;\n\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    const combinedOutput = `${stdout}\\n${stderr}`.trim();\n\n    // Check if all checks passed\n    const hasFailures =\n      combinedOutput.includes('fail') ||\n      combinedOutput.includes('X ') ||\n      combinedOutput.includes('cancelled');\n\n    return {\n      success: !hasFailures,\n      output: combinedOutput,\n    };\n  } catch (error: unknown) {\n    const err = error as {\n      stdout?: string;\n      stderr?: string;\n      message?: string;\n      killed?: boolean;\n    };\n    const errorOutput = err.stdout || err.stderr || err.message || 'Unknown error';\n\n    if (err.killed) {\n      return {\n        success: false,\n        output: errorOutput,\n        error: `CI check timeout (${Math.round(timeout / 60000)} minutes)`,\n      };\n    }\n\n    return {\n      success: false,\n      output: errorOutput,\n      error: 'Failed to watch CI checks',\n    };\n  }\n}\n\n/**\n * Get latest CI workflow run details\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns CI run details or null if not found\n *\n * @example\n * ```typescript\n * const ciRun = await getLatestCIRun(123, '/path/to/repo');\n * if (ciRun?.conclusion === 'success') {\n *   console.log('CI passed:', ciRun.url);\n * }\n * ```\n */\nexport async function getLatestCIRun(\n  prNumber: number,\n  cwd: string\n): Promise<CIRunDetails | null> {\n  const result = await execCommand(\n    `gh run list --limit 1 --json databaseId,displayTitle,status,conclusion,url`,\n    cwd\n  );\n\n  if (!result.success) {\n    return null;\n  }\n\n  try {\n    const runs = JSON.parse(result.stdout);\n    if (Array.isArray(runs) && runs.length > 0) {\n      const run = runs[0];\n      return {\n        url: run.url,\n        status: run.status,\n        conclusion: run.conclusion,\n        name: run.displayTitle,\n      };\n    }\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Extract Vercel preview URLs from PR comments\n *\n * Searches PR comments for Vercel bot URLs and categorizes them\n * by app type (web, marketing, etc).\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Preview URLs object with categorized URLs\n *\n * @example\n * ```typescript\n * const urls = await extractPreviewUrls(123, '/path/to/repo');\n * if (urls.webUrl) {\n *   console.log('Web preview:', urls.webUrl);\n * }\n * ```\n */\nexport async function extractPreviewUrls(\n  prNumber: number,\n  cwd: string\n): Promise<PreviewUrls> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return { allUrls: [] };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n\n    const vercelUrlPattern = /https:\\/\\/[a-z0-9-]+\\.vercel\\.app/g;\n    const allUrls: string[] = [];\n\n    for (const comment of comments) {\n      const matches = comment.body?.match(vercelUrlPattern) || [];\n      allUrls.push(...matches);\n    }\n\n    // Deduplicate URLs\n    const uniqueUrls = [...new Set(allUrls)];\n\n    // Identify web and marketing apps by URL pattern\n    const webUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-web-') || url.includes('web-') || url.match(/web\\.vercel\\.app/)\n    );\n    const marketingUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-marketing-') ||\n        url.includes('marketing-') ||\n        url.match(/marketing\\.vercel\\.app/)\n    );\n\n    return {\n      webUrl,\n      marketingUrl,\n      allUrls: uniqueUrls,\n    };\n  } catch {\n    return { allUrls: [] };\n  }\n}\n\n/**\n * Parse CI checks output into structured format\n *\n * @param output - Raw output from `gh pr checks`\n * @returns Array of parsed check statuses\n *\n * @example\n * ```typescript\n * const checks = parseCIChecks(ciOutput);\n * for (const check of checks) {\n *   console.log(`${check.emoji} ${check.name}: ${check.status}`);\n * }\n * ```\n */\nexport function parseCIChecks(output: string): CheckStatus[] {\n  const checks: CheckStatus[] = [];\n  const lines = output.split('\\n');\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (!trimmed) continue;\n\n    // Parse line format: \"✓ check-name\" or \"X check-name\" or \"* check-name\"\n    let emoji = '⏳';\n    let status = 'pending';\n\n    if (trimmed.startsWith('✓') || trimmed.includes('pass')) {\n      emoji = '✅';\n      status = 'success';\n    } else if (trimmed.startsWith('X') || trimmed.includes('fail')) {\n      emoji = '❌';\n      status = 'failure';\n    } else if (trimmed.includes('cancel')) {\n      emoji = '⚪';\n      status = 'cancelled';\n    }\n\n    // Extract check name (remove status indicator)\n    const name = trimmed.replace(/^[✓X*\\s]+/, '').split('\\t')[0].trim();\n\n    if (name) {\n      checks.push({ name, emoji, status });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Format CI status result as concise string\n *\n * Truncates output to MAX_OUTPUT_CHARS to prevent context bloat.\n *\n * @param result - CI check result\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const ciResult = await waitForCIChecks({ prNumber: 123 }, cwd);\n * const formatted = formatCIStatus(ciResult);\n * console.log(formatted);\n * ```\n */\nexport function formatCIStatus(\n  result: CICheckResult,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = '';\n\n  if (result.success) {\n    output = '✅ All CI checks passed';\n  } else if (result.error) {\n    output = `⚠️ ${result.error}`;\n  } else {\n    output = '❌ CI checks failed';\n  }\n\n  // Add check details if available\n  if (result.output) {\n    const checks = parseCIChecks(result.output);\n    if (checks.length > 0) {\n      const checkLines = checks.map((c) => `${c.emoji} ${c.name}`).join('\\n');\n      output += `\\n\\n${checkLines}`;\n    }\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n/**\n * Format full CI status with PR info and preview URLs\n *\n * @param prNumber - PR number\n * @param prUrl - PR URL\n * @param ciResult - CI check result\n * @param ciRun - CI run details\n * @param previewUrls - Preview URLs\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const status = formatFullCIStatus(\n *   123, 'https://github.com/...', ciResult, ciRun, previewUrls\n * );\n * ```\n */\nexport function formatFullCIStatus(\n  prNumber: number,\n  prUrl: string,\n  ciResult: CICheckResult,\n  ciRun: CIRunDetails | null,\n  previewUrls: PreviewUrls,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = `**PR #${prNumber}**\\n`;\n\n  // CI status\n  if (ciResult.success) {\n    output += '✅ All CI checks passed\\n';\n  } else if (ciResult.error) {\n    output += `⏱️ ${ciResult.error}\\n`;\n  } else {\n    output += '❌ CI checks failed\\n';\n  }\n\n  // CI run link\n  if (ciRun?.url) {\n    output += `🔗 [CI](${ciRun.url})\\n`;\n  }\n\n  // Preview URLs\n  if (previewUrls.allUrls.length > 0) {\n    output += `🌐 ${previewUrls.allUrls[0]}`;\n    if (previewUrls.allUrls.length > 1) {\n      output += ` (+${previewUrls.allUrls.length - 1})`;\n    }\n    output += '\\n';\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n// ============================================================================\n// Fail-Fast CI Checking\n// ============================================================================\n\n/**\n * Check if PR has merge conflicts\n *\n * Queries GitHub API for the PR's mergeable state and returns immediately\n * if conflicts are detected.\n *\n * @param prNumber - PR number to check\n * @param cwd - Working directory\n * @returns Merge conflict result\n *\n * @example\n * ```typescript\n * const conflicts = await checkMergeConflicts(123, '/path/to/repo');\n * if (conflicts.hasConflicts) {\n *   console.log('PR has merge conflicts!');\n * }\n * ```\n */\nexport async function checkMergeConflicts(\n  prNumber: number,\n  cwd: string\n): Promise<MergeConflictResult> {\n  const result = await execCommand(\n    `gh pr view ${prNumber} --json mergeable,mergeStateStatus`,\n    cwd\n  );\n\n  if (!result.success) {\n    return { hasConflicts: false, error: `Failed to check PR: ${result.stderr}` };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const mergeable = data.mergeable;\n    const mergeStateStatus = data.mergeStateStatus;\n\n    // CONFLICTING means merge conflicts exist\n    // UNKNOWN means GitHub is still calculating\n    const hasConflicts = mergeable === 'CONFLICTING' || mergeStateStatus === 'DIRTY';\n\n    return {\n      hasConflicts,\n      mergeableState: mergeStateStatus || mergeable,\n    };\n  } catch {\n    return { hasConflicts: false, error: 'Failed to parse PR data' };\n  }\n}\n\n/**\n * Check if branch is behind main/master\n *\n * Compares the current branch with the default branch (main or master)\n * to determine if it's out of date.\n *\n * @param cwd - Working directory\n * @returns Branch sync status result\n *\n * @example\n * ```typescript\n * const sync = await checkBranchSyncStatus('/path/to/repo');\n * if (!sync.inSync) {\n *   console.log(`Branch is ${sync.behindCount} commits behind main`);\n * }\n * ```\n */\nexport async function checkBranchSyncStatus(cwd: string): Promise<BranchSyncResult> {\n  // First, fetch to ensure we have latest remote refs\n  await execCommand('git fetch origin', cwd);\n\n  // Get current branch\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to get current branch' };\n  }\n  const currentBranch = branchResult.stdout;\n\n  // Determine main branch (main or master)\n  let mainBranch = 'main';\n  const mainCheck = await execCommand('git rev-parse --verify origin/main', cwd);\n  if (!mainCheck.success) {\n    const masterCheck = await execCommand('git rev-parse --verify origin/master', cwd);\n    if (masterCheck.success) {\n      mainBranch = 'master';\n    } else {\n      return { inSync: true, behindCount: 0, aheadCount: 0, error: 'No main/master branch found' };\n    }\n  }\n\n  // Count commits behind and ahead\n  const revListResult = await execCommand(\n    `git rev-list --left-right --count origin/${mainBranch}...${currentBranch}`,\n    cwd\n  );\n\n  if (!revListResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to compare branches' };\n  }\n\n  const [behind, ahead] = revListResult.stdout.split('\\t').map(Number);\n\n  return {\n    inSync: behind === 0,\n    behindCount: behind || 0,\n    aheadCount: ahead || 0,\n  };\n}\n\n/**\n * Get current CI check statuses without waiting\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of check statuses\n */\nasync function getCurrentCIChecks(prNumber: number, cwd: string): Promise<CheckStatus[]> {\n  const result = await execCommand(\n    `gh pr checks ${prNumber} --json name,state,conclusion`,\n    cwd\n  );\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const checks = JSON.parse(result.stdout);\n    return checks.map((check: { name: string; state: string; conclusion: string }) => {\n      let emoji = '⏳';\n      let status = 'pending';\n\n      if (check.state === 'COMPLETED') {\n        if (check.conclusion === 'SUCCESS') {\n          emoji = '✅';\n          status = 'success';\n        } else if (check.conclusion === 'FAILURE') {\n          emoji = '❌';\n          status = 'failure';\n        } else if (check.conclusion === 'CANCELLED') {\n          emoji = '⚪';\n          status = 'cancelled';\n        }\n      } else if (check.state === 'IN_PROGRESS') {\n        emoji = '🔄';\n        status = 'in_progress';\n      }\n\n      return { name: check.name, emoji, status };\n    });\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Await CI checks with fail-fast behavior\n *\n * Checks for blocking conditions in order:\n * 1. Merge conflicts - block immediately\n * 2. Branch out of date with main - block immediately\n * 3. Any CI check failure - block immediately (don't wait for rest)\n *\n * Only returns success if ALL checks pass.\n *\n * @param options - Check options\n * @param options.prNumber - PR number (optional, will detect from branch)\n * @param options.timeout - Max wait time in ms (default: 10 minutes)\n * @param options.pollInterval - Polling interval in ms (default: 5 seconds)\n * @param cwd - Working directory\n * @returns Fail-fast result with blocking reason if failed\n *\n * @example\n * ```typescript\n * const result = await awaitCIWithFailFast({ prNumber: 123 }, '/path/to/repo');\n * if (!result.success) {\n *   return {\n *     decision: 'block',\n *     reason: result.blockReason,\n *   };\n * }\n * ```\n */\nexport async function awaitCIWithFailFast(\n  options: {\n    prNumber?: number;\n    timeout?: number;\n    pollInterval?: number;\n  },\n  cwd: string\n): Promise<FailFastResult> {\n  const { timeout = DEFAULT_TIMEOUT_MS, pollInterval = POLL_INTERVAL_MS } = options;\n  let { prNumber } = options;\n\n  // Get PR number if not provided\n  if (!prNumber) {\n    prNumber = await getPRForCurrentBranch(cwd) ?? undefined;\n    if (!prNumber) {\n      return {\n        success: true,\n        checks: [],\n        error: 'No PR found for current branch - skipping CI check',\n      };\n    }\n  }\n\n  // 1. Check for merge conflicts FIRST\n  const conflictCheck = await checkMergeConflicts(prNumber, cwd);\n  if (conflictCheck.hasConflicts) {\n    return {\n      success: false,\n      blockReason: `❌ PR #${prNumber} has merge conflicts. Resolve conflicts before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 2. Check if branch is out of date with main\n  const syncCheck = await checkBranchSyncStatus(cwd);\n  if (!syncCheck.inSync && syncCheck.behindCount > 0) {\n    return {\n      success: false,\n      blockReason: `❌ Branch is ${syncCheck.behindCount} commit(s) behind main. Rebase or merge main before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 3. Poll CI checks with fail-fast on any failure\n  const startTime = Date.now();\n  let emptyCheckCount = 0;\n\n  while (Date.now() - startTime < timeout) {\n    const checks = await getCurrentCIChecks(prNumber, cwd);\n\n    if (checks.length === 0) {\n      emptyCheckCount++;\n      if (emptyCheckCount >= MAX_EMPTY_CHECK_POLLS) {\n        // No CI checks after multiple polls - assume no CI configured\n        return {\n          success: true,\n          checks: [],\n          prNumber,\n          error: 'No CI checks configured for this repository',\n        };\n      }\n      // No checks yet, wait and retry\n      await new Promise((resolve) => setTimeout(resolve, pollInterval));\n      continue;\n    }\n\n    emptyCheckCount = 0; // Reset when checks appear\n\n    // Check for any failures - fail fast!\n    const failedCheck = checks.find((c) => c.status === 'failure' || c.status === 'cancelled');\n    if (failedCheck) {\n      return {\n        success: false,\n        blockReason: `❌ CI check \"${failedCheck.name}\" failed. Fix before continuing.`,\n        failedCheck: failedCheck.name,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Check if all checks are complete and passed\n    const allComplete = checks.every((c) => c.status === 'success');\n    if (allComplete) {\n      return {\n        success: true,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Some checks still pending, wait and poll again\n    await new Promise((resolve) => setTimeout(resolve, pollInterval));\n  }\n\n  // Timeout reached\n  const finalChecks = await getCurrentCIChecks(prNumber, cwd);\n  const pendingChecks = finalChecks.filter((c) => c.status === 'pending' || c.status === 'in_progress');\n\n  return {\n    success: false,\n    blockReason: `⏱️ CI check timeout (${Math.round(timeout / 60000)} minutes). ${pendingChecks.length} check(s) still pending.`,\n    checks: finalChecks,\n    prNumber,\n    error: 'Timeout waiting for CI checks',\n  };\n}\n",
        "plugins/essential-logging/shared/hooks/utils/config-resolver.ts": "/**\n * Configuration File Resolver\n * Utilities for finding configuration files by traversing parent directories\n * @module config-resolver\n */\n\nimport { access } from 'fs/promises';\nimport * as path from 'path';\n\n/**\n * Find git repository root directory\n *\n * @param startDir - Directory to start searching from\n * @returns Absolute path to git root, or null if not in a git repository\n */\nasync function findGitRoot(startDir: string): Promise<string | null> {\n  let currentDir = startDir;\n\n  while (true) {\n    try {\n      await access(path.join(currentDir, '.git'));\n      return currentDir;\n    } catch {\n      const parent = path.dirname(currentDir);\n      if (parent === currentDir) return null; // Filesystem root\n      currentDir = parent;\n    }\n  }\n}\n\n/**\n * Find a configuration file by traversing parent directories\n *\n * @param startDir - Directory to start searching from (typically input.cwd)\n * @param configFileName - Name of config file to find (e.g., 'tsconfig.json')\n * @param stopAtGitRoot - Whether to stop at git repository root (default: true)\n * @returns Absolute path to config file directory, or null if not found\n *\n * @example\n * const configDir = await findConfigFile(input.cwd, 'eslint.config.mjs');\n * if (configDir) {\n *   await execAsync('npx eslint file.ts', { cwd: configDir });\n * }\n */\nexport async function findConfigFile(\n  startDir: string,\n  configFileName: string,\n  stopAtGitRoot: boolean = true\n): Promise<string | null> {\n  let currentDir = path.resolve(startDir);\n  const gitRoot = stopAtGitRoot ? await findGitRoot(currentDir) : null;\n\n  while (true) {\n    try {\n      // Check if config file exists in current directory\n      await access(path.join(currentDir, configFileName));\n      return currentDir;\n    } catch {\n      // Config not found in this directory\n    }\n\n    // Check if we should stop at git root\n    if (stopAtGitRoot && gitRoot && currentDir === gitRoot) {\n      return null;\n    }\n\n    // Move to parent directory\n    const parent = path.dirname(currentDir);\n    if (parent === currentDir) {\n      // Reached filesystem root\n      return null;\n    }\n\n    currentDir = parent;\n  }\n}\n",
        "plugins/essential-logging/shared/hooks/utils/debug.ts": "/**\n * Debug utilities for Claude Code hooks\n *\n * Provides logging and error handling with debug mode support. Hook events\n * are logged in JSONL format to .claude/logs/hook-events.json for debugging\n * and troubleshooting hook execution.\n *\n * Each log entry is a single JSON object per line with timestamp, event name,\n * type (input/output/error), and the associated data.\n *\n * @module debug\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst HOOK_EVENTS_FILE = 'hook-events.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface DebugConfig {\n  debug?: boolean;\n}\n\nexport interface HookEventEntry {\n  timestamp: string;\n  event: string;\n  type: 'input' | 'output' | 'error';\n  data: unknown;\n}\n\nexport interface DebugLogger {\n  logInput: (input: unknown) => Promise<void>;\n  logOutput: (output: unknown) => Promise<void>;\n  logError: (error: Error) => Promise<void>;\n}\n\n// ============================================================================\n// Debug Logging (JSONL append to hook-events.json)\n// ============================================================================\n\n/**\n * Append a hook event entry to hook-events.json (JSONL format)\n *\n * Writes a single-line JSON entry to the log file, creating the directory\n * structure if it doesn't exist. Failures are silently ignored to prevent\n * logging errors from breaking hook execution.\n *\n * @param cwd - The working directory where .claude/logs/ should be created\n * @param entry - The hook event entry to append to the log file\n * @returns Promise that resolves when the entry is written (or fails silently)\n *\n * @example\n * ```typescript\n * await appendHookEvent('/path/to/project', {\n *   timestamp: new Date().toISOString(),\n *   event: 'SessionStart',\n *   type: 'input',\n *   data: { cwd: '/path/to/project' }\n * });\n * ```\n */\nasync function appendHookEvent(cwd: string, entry: HookEventEntry): Promise<void> {\n  const logDir = path.join(cwd, LOGS_DIR);\n  const logFile = path.join(logDir, HOOK_EVENTS_FILE);\n\n  try {\n    await fs.mkdir(logDir, { recursive: true });\n    await fs.appendFile(logFile, JSON.stringify(entry) + '\\n', 'utf-8');\n  } catch {\n    // Silently fail - don't break hook execution for logging\n  }\n}\n\n/**\n * Create a debug logger for a hook execution\n *\n * Returns a logger object with methods for logging hook inputs, outputs, and errors\n * to .claude/logs/hook-events.json in JSONL format. Logging only occurs when debug\n * mode is enabled.\n *\n * @param cwd - The working directory where logs should be written\n * @param hookEventName - The name of the hook event (e.g., 'SessionStart', 'PostToolUse')\n * @param debug - Whether debug logging is enabled\n * @returns A DebugLogger with logInput, logOutput, and logError methods\n *\n * @example\n * ```typescript\n * import { createDebugLogger } from './debug.js';\n *\n * const logger = createDebugLogger('/path/to/project', 'SessionStart', true);\n *\n * await logger.logInput({ cwd: '/path/to/project', source: 'startup' });\n * await logger.logOutput({ success: true, message: 'Hook completed' });\n * ```\n */\nexport function createDebugLogger(\n  cwd: string,\n  hookEventName: string,\n  _debug: boolean\n): DebugLogger {\n  return {\n    logInput: async (input: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'input',\n        data: input,\n      });\n    },\n\n    logOutput: async (output: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'output',\n        data: output,\n      });\n    },\n\n    logError: async (error: Error) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'error',\n        data: {\n          name: error.name,\n          message: error.message,\n          stack: error.stack,\n        },\n      });\n    },\n  };\n}\n\n// ============================================================================\n// Error Handling\n// ============================================================================\n\n/**\n * Create a blocking error response for hooks\n *\n * Generates an appropriate error response object that blocks execution when\n * a hook error occurs in debug mode. The response format varies by hook event\n * type to match the expected output schema.\n *\n * @param hookEventName - The name of the hook event that errored\n * @param error - The error that occurred during hook execution\n * @returns A hook output object configured to block/deny with error details\n *\n * @example\n * ```typescript\n * import { createBlockingErrorResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   return createBlockingErrorResponse('PreToolUse', error as Error);\n *   // Returns: { hookSpecificOutput: { permissionDecision: 'deny', ... } }\n * }\n * ```\n */\nexport function createBlockingErrorResponse(\n  hookEventName: string,\n  error: Error\n): Record<string, unknown> {\n  const baseResponse = {\n    continue: false,\n    stopReason: `Hook error: ${error.message}`,\n    systemMessage: `Hook ${hookEventName} failed: ${error.message}`,\n  };\n\n  // Add hook-specific output based on event type\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        ...baseResponse,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'PostToolUse':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `Hook error: ${error.message}\\n${error.stack || ''}`,\n        },\n      };\n\n    case 'SubagentStop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    case 'UserPromptSubmit':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'Stop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    default:\n      return baseResponse;\n  }\n}\n\n/**\n * Create a pass-through response for hooks\n *\n * Generates an appropriate response object that allows execution to continue\n * when a hook error occurs and debug mode is disabled. The response format\n * varies by hook event type to match the expected output schema while permitting\n * normal Claude Code operation.\n *\n * @param hookEventName - The name of the hook event\n * @returns A hook output object configured to allow/pass-through\n *\n * @example\n * ```typescript\n * import { createPassthroughResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   if (!debugMode) {\n *     return createPassthroughResponse('PreToolUse');\n *     // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *   }\n * }\n * ```\n */\nexport function createPassthroughResponse(hookEventName: string): Record<string, unknown> {\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n\n    case 'PostToolUse':\n      return {};\n\n    case 'SessionStart':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n\n    case 'SubagentStart':\n      return {};\n\n    case 'SubagentStop':\n      return {};\n\n    default:\n      return {};\n  }\n}\n",
        "plugins/essential-logging/shared/hooks/utils/env-sync.ts": "/**\n * Environment variable synchronization utilities for turborepo workspaces\n *\n * Provides functions to collect, merge, validate, and distribute environment variables\n * across multiple workspaces in a turborepo project. Ensures consistent environment\n * configuration across all apps.\n *\n * @module env-sync\n */\n\nimport { existsSync, readFileSync, writeFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Environment variable sets organized by source\n */\nexport interface EnvVarSet {\n  /** Environment variables from Supabase CLI (SUPABASE_URL, etc.) */\n  supabaseVars: Record<string, string>;\n  /** Environment variables from Vercel CLI */\n  vercelVars: Record<string, string>;\n  /** Next.js prefixed variables (NEXT_PUBLIC_*) */\n  nextjsVars: Record<string, string>;\n  /** Cloudflare variables (unprefixed for dev.vars) */\n  cloudflareVars: Record<string, string>;\n}\n\n/**\n * Options for distributing environment variables\n */\nexport interface DistributeOptions {\n  /** Create .env.local and dev.vars files if they don't exist */\n  createIfMissing: boolean;\n  /** Preserve existing environment variables (don't overwrite) */\n  preserveExisting: boolean;\n}\n\n/**\n * Validation result for environment variables\n */\nexport interface ValidationResult {\n  /** Whether all required variables are present */\n  valid: boolean;\n  /** List of missing required variables */\n  missing: string[];\n}\n\n/**\n * Read and parse a .env.local file\n *\n * Parses a .env.local file into a key-value object. Handles:\n * - Comments starting with #\n * - Empty lines\n * - KEY=value format\n * - Quoted values\n *\n * @param path - Path to the directory containing .env.local\n * @returns Object with parsed environment variables\n *\n * @example\n * ```typescript\n * import { readEnvLocalFile } from './env-sync.js';\n *\n * const vars = await readEnvLocalFile('/path/to/app');\n * console.log(vars.NEXT_PUBLIC_SUPABASE_URL);\n * ```\n */\nexport async function readEnvLocalFile(path: string): Promise<Record<string, string>> {\n  const envPath = join(path, '.env.local');\n  if (!existsSync(envPath)) {\n    return {};\n  }\n\n  const content = readFileSync(envPath, 'utf-8');\n  const vars: Record<string, string> = {};\n\n  for (const line of content.split('\\n')) {\n    const trimmed = line.trim();\n\n    // Skip empty lines and comments\n    if (!trimmed || trimmed.startsWith('#')) {\n      continue;\n    }\n\n    // Parse KEY=value\n    const eqIndex = trimmed.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = trimmed.slice(0, eqIndex).trim();\n    let value = trimmed.slice(eqIndex + 1).trim();\n\n    // Remove surrounding quotes\n    if ((value.startsWith('\"') && value.endsWith('\"')) ||\n        (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n      value = value.slice(1, -1);\n    }\n\n    vars[key] = value;\n  }\n\n  return vars;\n}\n\n/**\n * Merge environment variables from multiple workspace .env.local files\n *\n * Reads .env.local files from all workspaces and merges them into a single\n * object. Later workspaces override earlier ones if there are conflicts.\n *\n * @param workspaces - Array of workspace paths relative to cwd\n * @param cwd - Root directory of the project\n * @returns Merged environment variables\n *\n * @example\n * ```typescript\n * import { mergeWorkspaceEnvVars } from './env-sync.js';\n *\n * const vars = await mergeWorkspaceEnvVars(\n *   ['apps/web', 'apps/api', 'apps/mcp'],\n *   '/path/to/project'\n * );\n * ```\n */\nexport async function mergeWorkspaceEnvVars(\n  workspaces: string[],\n  cwd: string\n): Promise<Record<string, string>> {\n  const merged: Record<string, string> = {};\n\n  for (const workspace of workspaces) {\n    const workspacePath = join(cwd, workspace);\n    const vars = await readEnvLocalFile(workspacePath);\n    Object.assign(merged, vars);\n  }\n\n  return merged;\n}\n\n/**\n * Validate that required environment variables are present\n *\n * Checks that all required variables exist in at least one of the variable sets.\n *\n * @param vars - Environment variable sets to validate\n * @param required - List of required variable names\n * @returns Validation result with missing variables\n *\n * @example\n * ```typescript\n * import { validateEnvVars } from './env-sync.js';\n *\n * const result = validateEnvVars(\n *   { supabaseVars, vercelVars },\n *   ['SUPABASE_URL', 'SUPABASE_PUBLISHABLE_KEY']\n * );\n *\n * if (!result.valid) {\n *   console.warn('Missing vars:', result.missing);\n * }\n * ```\n */\nexport function validateEnvVars(\n  vars: Partial<EnvVarSet>,\n  required: string[]\n): ValidationResult {\n  const allVars = {\n    ...vars.supabaseVars,\n    ...vars.vercelVars,\n    ...vars.nextjsVars,\n    ...vars.cloudflareVars,\n  };\n\n  const missing: string[] = [];\n  for (const key of required) {\n    if (!(key in allVars)) {\n      missing.push(key);\n    }\n  }\n\n  return {\n    valid: missing.length === 0,\n    missing,\n  };\n}\n\n/**\n * Distribute environment variables to a workspace\n *\n * Writes environment variables to .env.local (for Next.js) and dev.vars\n * (for Cloudflare Workers) in the specified workspace directory.\n *\n * @param workspacePath - Path to the workspace directory\n * @param vars - Environment variable sets to distribute\n * @param options - Distribution options\n * @returns Object indicating which files were written\n *\n * @example\n * ```typescript\n * import { distributeEnvVars } from './env-sync.js';\n *\n * const result = await distributeEnvVars(\n *   '/path/to/apps/web',\n *   { supabaseVars, vercelVars },\n *   { createIfMissing: true, preserveExisting: true }\n * );\n *\n * if (result.nextjs) console.log('.env.local updated');\n * if (result.cloudflare) console.log('dev.vars updated');\n * ```\n */\nexport async function distributeEnvVars(\n  workspacePath: string,\n  vars: Partial<EnvVarSet>,\n  options: DistributeOptions\n): Promise<{ nextjs: boolean; cloudflare: boolean }> {\n  let nextjsWritten = false;\n  let cloudflareWritten = false;\n\n  // Prepare combined vars for Next.js (with NEXT_PUBLIC_ prefix where needed)\n  const nextjsVars: Record<string, string> = {};\n\n  // Add Supabase vars with NEXT_PUBLIC_ prefix\n  if (vars.supabaseVars) {\n    for (const [key, value] of Object.entries(vars.supabaseVars)) {\n      if (key === 'SUPABASE_URL') {\n        nextjsVars['NEXT_PUBLIC_SUPABASE_URL'] = value;\n      } else if (key === 'SUPABASE_PUBLISHABLE_KEY') {\n        nextjsVars['NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY'] = value;\n      } else if (key === 'SUPABASE_SECRET_KEY') {\n        nextjsVars['SUPABASE_SECRET_KEY'] = value; // No prefix for secret\n      }\n    }\n  }\n\n  // Add Vercel vars (keep as-is, they're already properly prefixed)\n  if (vars.vercelVars) {\n    Object.assign(nextjsVars, vars.vercelVars);\n  }\n\n  // Add explicit Next.js vars\n  if (vars.nextjsVars) {\n    Object.assign(nextjsVars, vars.nextjsVars);\n  }\n\n  // Write to .env.local\n  const envLocalPath = join(workspacePath, '.env.local');\n  if (Object.keys(nextjsVars).length > 0) {\n    if (existsSync(envLocalPath)) {\n      // Merge with existing\n      const existing = await readEnvLocalFile(workspacePath);\n      const merged = options.preserveExisting\n        ? { ...nextjsVars, ...existing } // Existing takes precedence\n        : { ...existing, ...nextjsVars }; // New takes precedence\n\n      const lines = Object.entries(merged).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(envLocalPath, lines.join('\\n') + '\\n');\n      nextjsWritten = true;\n    } else if (options.createIfMissing) {\n      const lines = Object.entries(nextjsVars).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(envLocalPath, lines.join('\\n') + '\\n');\n      nextjsWritten = true;\n    }\n  }\n\n  // Prepare vars for Cloudflare (unprefixed)\n  const cloudflareVars: Record<string, string> = {};\n\n  // Add Supabase vars without NEXT_PUBLIC_ prefix\n  if (vars.supabaseVars) {\n    Object.assign(cloudflareVars, vars.supabaseVars);\n  }\n\n  // Add Cloudflare-specific vars\n  if (vars.cloudflareVars) {\n    Object.assign(cloudflareVars, vars.cloudflareVars);\n  }\n\n  // Add Vercel vars (strip NEXT_PUBLIC_ prefix for Cloudflare)\n  if (vars.vercelVars) {\n    for (const [key, value] of Object.entries(vars.vercelVars)) {\n      if (key.startsWith('NEXT_PUBLIC_')) {\n        const unprefixed = key.replace('NEXT_PUBLIC_', '');\n        cloudflareVars[unprefixed] = value;\n      } else {\n        cloudflareVars[key] = value;\n      }\n    }\n  }\n\n  // Write to dev.vars (only if wrangler.toml/wrangler.jsonc exists)\n  const devVarsPath = join(workspacePath, 'dev.vars');\n  const hasWrangler = existsSync(join(workspacePath, 'wrangler.toml')) ||\n                      existsSync(join(workspacePath, 'wrangler.jsonc'));\n\n  if (hasWrangler && Object.keys(cloudflareVars).length > 0) {\n    if (existsSync(devVarsPath)) {\n      // Merge with existing\n      const existing = readFileSync(devVarsPath, 'utf-8');\n      const existingVars: Record<string, string> = {};\n\n      for (const line of existing.split('\\n')) {\n        const trimmed = line.trim();\n        if (!trimmed || trimmed.startsWith('#')) continue;\n\n        const eqIndex = trimmed.indexOf('=');\n        if (eqIndex === -1) continue;\n\n        const key = trimmed.slice(0, eqIndex).trim();\n        let value = trimmed.slice(eqIndex + 1).trim();\n        if ((value.startsWith('\"') && value.endsWith('\"')) ||\n            (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n          value = value.slice(1, -1);\n        }\n        existingVars[key] = value;\n      }\n\n      const merged = options.preserveExisting\n        ? { ...cloudflareVars, ...existingVars }\n        : { ...existingVars, ...cloudflareVars };\n\n      const lines = Object.entries(merged).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(devVarsPath, lines.join('\\n') + '\\n');\n      cloudflareWritten = true;\n    } else if (options.createIfMissing) {\n      const lines = Object.entries(cloudflareVars).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(devVarsPath, lines.join('\\n') + '\\n');\n      cloudflareWritten = true;\n    }\n  }\n\n  return { nextjs: nextjsWritten, cloudflare: cloudflareWritten };\n}\n\n/**\n * Collect environment variables from all sources\n *\n * Gathers environment variables from Supabase CLI (if running) and\n * from all workspace .env.local files (from Vercel pulls).\n *\n * @param cwd - Root directory of the project\n * @param workspaces - Array of workspace paths relative to cwd\n * @param supabaseVars - Optional Supabase variables (from Supabase CLI)\n * @returns Complete environment variable sets\n *\n * @example\n * ```typescript\n * import { collectEnvVars } from './env-sync.js';\n *\n * const vars = await collectEnvVars(\n *   '/path/to/project',\n *   ['apps/web', 'apps/api'],\n *   { SUPABASE_URL: 'http://localhost:54321', ... }\n * );\n * ```\n */\nexport async function collectEnvVars(\n  cwd: string,\n  workspaces: string[],\n  supabaseVars?: Record<string, string>\n): Promise<EnvVarSet> {\n  // Collect Supabase vars\n  const supabase = supabaseVars || {};\n\n  // Collect and merge Vercel vars from all workspaces\n  const vercel = await mergeWorkspaceEnvVars(workspaces, cwd);\n\n  // Separate Next.js prefixed vars\n  const nextjs: Record<string, string> = {};\n  const cloudflare: Record<string, string> = {};\n\n  for (const [key, value] of Object.entries(vercel)) {\n    if (key.startsWith('NEXT_PUBLIC_')) {\n      nextjs[key] = value;\n      // Also add unprefixed version for Cloudflare\n      cloudflare[key.replace('NEXT_PUBLIC_', '')] = value;\n    } else {\n      cloudflare[key] = value;\n    }\n  }\n\n  return {\n    supabaseVars: supabase,\n    vercelVars: vercel,\n    nextjsVars: nextjs,\n    cloudflareVars: cloudflare,\n  };\n}\n",
        "plugins/essential-logging/shared/hooks/utils/frontmatter.ts": "/**\n * Simple YAML frontmatter parser - zero dependencies\n *\n * Replaces gray-matter with a lightweight custom implementation\n * that handles the basic YAML frontmatter patterns used in this project.\n *\n * @module frontmatter\n */\n\n/**\n * Parse YAML frontmatter from markdown content\n *\n * Extracts YAML frontmatter between --- delimiters and parses\n * simple key-value pairs and arrays. Returns data object and remaining content.\n *\n * Supported YAML patterns:\n * - Simple key-value: `name: value`\n * - Arrays: `skills: [item1, item2]` or multi-line arrays\n * - Nested (basic): `field: { key: value }`\n *\n * @param content - Markdown content with optional frontmatter\n * @returns Object with `data` (parsed YAML) and `content` (remaining markdown)\n *\n * @example\n * ```typescript\n * import { parseFrontmatter } from './frontmatter.js';\n *\n * const markdown = `---\n * name: MyAgent\n * skills: [skill1, skill2]\n * ---\n *\n * # Content here\n * `;\n *\n * const { data, content } = parseFrontmatter(markdown);\n * console.log(data.name); // 'MyAgent'\n * console.log(data.skills); // ['skill1', 'skill2']\n * ```\n */\nexport function parseFrontmatter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  const frontmatterRegex = /^---\\s*\\n([\\s\\S]*?)\\n---\\s*\\n([\\s\\S]*)$/;\n  const match = content.match(frontmatterRegex);\n\n  if (!match) {\n    return { data: {}, content };\n  }\n\n  const [, yamlContent, remainingContent] = match;\n  const data = parseSimpleYaml(yamlContent);\n\n  return { data, content: remainingContent };\n}\n\n/**\n * Parse simple YAML content into JavaScript object\n *\n * Handles common YAML patterns used in frontmatter:\n * - Key-value pairs\n * - Inline arrays: [item1, item2, item3]\n * - Multi-line arrays with - prefix\n * - Nested objects (basic)\n *\n * @param yaml - YAML content string\n * @returns Parsed JavaScript object\n */\nfunction parseSimpleYaml(yaml: string): Record<string, unknown> {\n  const data: Record<string, unknown> = {};\n  const lines = yaml.split('\\n');\n  let i = 0;\n\n  while (i < lines.length) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      i++;\n      continue;\n    }\n\n    // Parse key-value pair\n    const colonIndex = line.indexOf(':');\n    if (colonIndex === -1) {\n      i++;\n      continue;\n    }\n\n    const key = line.substring(0, colonIndex).trim();\n    const value = line.substring(colonIndex + 1).trim();\n\n    // Handle inline array: [item1, item2]\n    if (value.startsWith('[') && value.endsWith(']')) {\n      const arrayContent = value.slice(1, -1);\n      data[key] = arrayContent.split(',').map(item => parseValue(item.trim()));\n      i++;\n      continue;\n    }\n\n    // Handle multi-line array\n    if (value === '' && i + 1 < lines.length && lines[i + 1].trim().startsWith('-')) {\n      const arrayItems: string[] = [];\n      i++;\n      while (i < lines.length && lines[i].trim().startsWith('-')) {\n        const item = lines[i].trim().substring(1).trim();\n        arrayItems.push(item);\n        i++;\n      }\n      data[key] = arrayItems;\n      continue;\n    }\n\n    // Handle inline object: { key: value }\n    if (value.startsWith('{') && value.endsWith('}')) {\n      const objectContent = value.slice(1, -1);\n      const obj: Record<string, unknown> = {};\n      const pairs = objectContent.split(',');\n      for (const pair of pairs) {\n        const [objKey, objValue] = pair.split(':').map(s => s.trim());\n        obj[objKey] = parseValue(objValue);\n      }\n      data[key] = obj;\n      i++;\n      continue;\n    }\n\n    // Handle simple value\n    data[key] = parseValue(value);\n    i++;\n  }\n\n  return data;\n}\n\n/**\n * Parse a YAML value to appropriate JavaScript type\n *\n * Converts:\n * - 'true'/'false' → boolean\n * - 'null' → null\n * - Numbers → number\n * - Quoted strings → unquoted string\n * - Everything else → string\n *\n * @param value - YAML value string\n * @returns Parsed value in appropriate type\n */\nfunction parseValue(value: string): unknown {\n  // Handle boolean\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle null\n  if (value === 'null' || value === '~') return null;\n\n  // Handle number\n  if (/^-?\\d+(\\.\\d+)?$/.test(value)) {\n    return Number(value);\n  }\n\n  // Handle quoted strings\n  if ((value.startsWith('\"') && value.endsWith('\"')) ||\n      (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n    return value.slice(1, -1);\n  }\n\n  // Return as string\n  return value;\n}\n\n/**\n * gray-matter compatible interface\n *\n * Provides same API as gray-matter for drop-in replacement.\n *\n * @param content - Markdown content with frontmatter\n * @returns Object with `data` and `content` properties\n */\nexport default function matter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  return parseFrontmatter(content);\n}\n",
        "plugins/essential-logging/shared/hooks/utils/github-comments.ts": "/**\n * GitHub comment utilities for Stop hook\n *\n * Provides utilities for:\n * - Checking if a session comment exists on a GitHub issue\n * - Posting session progress comments with session ID markers\n * - Discovering the linked issue number for a branch\n *\n * Session comments include a hidden HTML marker that allows the Stop hook\n * to detect whether progress has been documented for a given session.\n * @module github-comments\n */\n\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst COMMENT_MARKER_PREFIX = '<!-- claude-session: ';\nconst COMMENT_MARKER_SUFFIX = ' -->';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Plan issue state tracking\n */\ninterface PlanIssueState {\n  /**\n   * Map of session IDs to issue metadata\n   */\n  [sessionId: string]: {\n    /**\n     * Path to the plan file\n     */\n    planPath: string;\n    /**\n     * GitHub issue number\n     */\n    issueNumber: number;\n    /**\n     * Full GitHub issue URL\n     */\n    issueUrl: string;\n    /**\n     * Git branch name\n     */\n    branch: string;\n    /**\n     * ISO timestamp when issue was created\n     */\n    createdAt: string;\n    /**\n     * ISO timestamp of last update\n     */\n    lastUpdated: string;\n  };\n}\n\n/**\n * GitHub issue with comments\n */\ninterface GitHubIssue {\n  /**\n   * Issue number\n   */\n  number: number;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * Issue body content\n   */\n  body: string;\n  /**\n   * Issue comments\n   */\n  comments?: Array<{\n    /**\n     * Comment author\n     */\n    author: { login: string };\n    /**\n     * Comment body\n     */\n    body: string;\n    /**\n     * ISO timestamp when comment was created\n     */\n    createdAt: string;\n  }>;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command\n * @param command - Shell command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execCommand('git rev-parse --abbrev-ref HEAD', '/path/to/project');\n * if (result.success) {\n *   console.log('Branch:', result.stdout);\n * }\n * ```\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n *\n * Uses spawn + stdin to avoid shell escaping issues when passing\n * markdown content with special characters.\n * @param args - Arguments to pass to gh command\n * @param stdin - Content to write to stdin\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execGhWithStdin(\n *   ['issue', 'comment', '123', '--body-file', '-'],\n *   'This is my comment content',\n *   '/path/to/project'\n * );\n * ```\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    // Write body to stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n// ============================================================================\n// Issue Discovery\n// ============================================================================\n\n/**\n * Load plan issue state from disk\n * @param cwd - Working directory\n * @returns Plan issue state map\n * @example\n * ```typescript\n * const state = await loadPlanIssueState('/path/to/project');\n * const sessionInfo = state['session-id'];\n * if (sessionInfo) {\n *   console.log('Issue number:', sessionInfo.issueNumber);\n * }\n * ```\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Parse issue number from branch name\n *\n * Extracts issue number from branch names like:\n * - issue-123-description\n * - feature/issue-456\n * - 789-fix-bug\n * @param branch - Git branch name\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNum = parseIssueFromBranch('issue-123-add-feature');\n * // Returns: 123\n *\n * const noIssue = parseIssueFromBranch('main');\n * // Returns: null\n * ```\n */\nfunction parseIssueFromBranch(branch: string): number | null {\n  // Try pattern: issue-123-...\n  const issueMatch = branch.match(/issue[_-](\\d+)/i);\n  if (issueMatch) {\n    return parseInt(issueMatch[1], 10);\n  }\n\n  // Try pattern: 123-...\n  const numMatch = branch.match(/^(\\d+)[_-]/);\n  if (numMatch) {\n    return parseInt(numMatch[1], 10);\n  }\n\n  return null;\n}\n\n/**\n * Get linked issue number for current branch\n *\n * Discovers issue number using cascading fallback strategy:\n * 1. Check plan-issues.json state file (by session ID and branch name)\n * 2. Parse from branch name pattern (issue-123-...)\n * 3. Search GitHub for issues mentioning the branch\n * @param branch - Git branch name\n * @param cwd - Working directory\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNumber = await getLinkedIssueNumber('issue-57-stop-hook', '/path/to/project');\n * if (issueNumber) {\n *   console.log('Linked to issue #' + issueNumber);\n * }\n * ```\n */\nexport async function getLinkedIssueNumber(\n  branch: string,\n  cwd: string\n): Promise<number | null> {\n  // STRATEGY 1: Check plan-issues.json state file\n  const state = await loadPlanIssueState(cwd);\n\n  // Find by branch name across all sessions\n  for (const sessionState of Object.values(state)) {\n    if (sessionState.branch === branch) {\n      return sessionState.issueNumber;\n    }\n  }\n\n  // STRATEGY 2: Parse from branch name\n  const parsedIssue = parseIssueFromBranch(branch);\n  if (parsedIssue !== null) {\n    // Verify issue exists\n    const verifyResult = await execCommand(`gh issue view ${parsedIssue} --json number`, cwd);\n    if (verifyResult.success) {\n      return parsedIssue;\n    }\n  }\n\n  // STRATEGY 3: Search GitHub for issues mentioning the branch\n  const searchResult = await execCommand(\n    `gh issue list --search \"in:body ${branch}\" --json number --limit 1`,\n    cwd\n  );\n\n  if (searchResult.success && searchResult.stdout) {\n    try {\n      const issues = JSON.parse(searchResult.stdout);\n      if (issues.length > 0) {\n        return issues[0].number;\n      }\n    } catch {\n      // Parse error\n    }\n  }\n\n  return null;\n}\n\n// ============================================================================\n// Comment Management\n// ============================================================================\n\n/**\n * Create session comment marker\n * @param sessionId - Session ID to embed in marker\n * @returns HTML comment marker\n * @example\n * ```typescript\n * const marker = createSessionMarker('abc-123');\n * // Returns: '<!-- claude-session: abc-123 -->'\n * ```\n */\nfunction createSessionMarker(sessionId: string): string {\n  return `${COMMENT_MARKER_PREFIX}${sessionId}${COMMENT_MARKER_SUFFIX}`;\n}\n\n/**\n * Check if a comment contains a session marker\n * @param commentBody - Comment body text\n * @param sessionId - Session ID to search for\n * @returns True if comment contains the session marker\n * @example\n * ```typescript\n * const hasMarker = commentHasSessionMarker(\n *   '<!-- claude-session: abc-123 -->\\n\\nMy comment',\n *   'abc-123'\n * );\n * // Returns: true\n * ```\n */\nfunction commentHasSessionMarker(commentBody: string, sessionId: string): boolean {\n  const marker = createSessionMarker(sessionId);\n  return commentBody.includes(marker);\n}\n\n/**\n * Check if a session comment exists on a GitHub issue\n *\n * Fetches all comments for the issue and searches for the session ID marker.\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID to search for\n * @param cwd - Working directory\n * @returns True if a comment with the session marker exists\n * @example\n * ```typescript\n * import { hasCommentForSession } from './github-comments.js';\n *\n * const hasComment = await hasCommentForSession(57, 'session-abc-123', '/path/to/project');\n * if (hasComment) {\n *   console.log('Progress already documented for this session');\n * }\n * ```\n */\nexport async function hasCommentForSession(\n  issueNumber: number,\n  sessionId: string,\n  cwd: string\n): Promise<boolean> {\n  // Fetch issue with comments\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return false;\n  }\n\n  try {\n    const issue: GitHubIssue = JSON.parse(result.stdout);\n\n    if (!issue.comments || issue.comments.length === 0) {\n      return false;\n    }\n\n    // Search for session marker in comments\n    return issue.comments.some((comment) =>\n      commentHasSessionMarker(comment.body, sessionId)\n    );\n  } catch {\n    // Parse error\n    return false;\n  }\n}\n\n/**\n * Post a session progress comment to a GitHub issue\n *\n * Creates a formatted comment with:\n * - Hidden session ID marker for detection\n * - Session metadata (ID, branch, timestamp)\n * - User-provided content\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID\n * @param content - Comment content (markdown)\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n * @example\n * ```typescript\n * import { postSessionComment } from './github-comments.js';\n *\n * const posted = await postSessionComment(\n *   57,\n *   'session-abc-123',\n *   'Completed hook implementation and tests',\n *   'issue-57-stop-hook',\n *   '/path/to/project'\n * );\n * if (posted) {\n *   console.log('Comment posted successfully');\n * }\n * ```\n */\nexport async function postSessionComment(\n  issueNumber: number,\n  sessionId: string,\n  content: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = createSessionMarker(sessionId);\n\n  const commentBody = `${marker}\n\n## 🤖 Claude Session Progress\n\n**Session ID:** \\`${sessionId}\\`\n**Branch:** \\`${branch}\\`\n**Timestamp:** ${timestamp}\n\n${content}\n\n---\n*Posted automatically via Stop hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n",
        "plugins/essential-logging/shared/hooks/utils/index.ts": "/**\n * Hook Utilities - Re-exports\n *\n * Centralized exports for all hook utility functions, types, and helpers.\n * This index file provides convenient access to all shared utilities used\n * across Claude Code plugins.\n *\n * For smaller bundle sizes, prefer importing directly from individual modules\n * rather than using this index file. Direct imports allow tree-shaking to\n * eliminate unused code.\n *\n * @example\n * ```typescript\n * // Preferred: Direct import (better for tree-shaking)\n * import { readStdinJson } from './utils/io.js';\n * import { createDebugLogger } from './utils/debug.js';\n *\n * // Alternative: Import from index (more convenient)\n * import { readStdinJson, createDebugLogger } from './utils/index.js';\n * ```\n *\n * @module utils/index\n */\n\n// ============================================================================\n// I/O Utilities and Hook Runner\n// ============================================================================\n// Functions for reading hook input from stdin, writing output to stdout,\n// and wrapping hook handlers for execution.\n\nexport { readStdinJson, writeStdoutJson, runHook, type HookHandler } from './io.js';\n\n// ============================================================================\n// Debug Utilities\n// ============================================================================\n// Debug logging with JSONL output to .claude/logs/hook-events.json.\n// Supports DEBUG environment variable for filtering output.\n\nexport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  createPassthroughResponse,\n  type DebugConfig,\n  type DebugLogger,\n  type HookEventEntry,\n} from './debug.js';\n\n// ============================================================================\n// Transcript Parsing\n// ============================================================================\n// Parse Claude Code transcript JSONL files to analyze agent conversations,\n// tool uses, and file operations.\n\nexport {\n  parseTranscript,\n  parseTranscriptLine,\n  getTranscriptInfo,\n  getToolUses,\n  getEditedFiles,\n  getNewFiles,\n  getDeletedFiles,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  type Transcript,\n  type Message,\n  type UserMessage,\n  type AssistantMessage,\n  type SystemMessage,\n} from './transcripts.js';\n\n// ============================================================================\n// Subagent State Management\n// ============================================================================\n// Save and load subagent execution context, and analyze file operations\n// performed by agents.\n\nexport {\n  saveAgentStartContext,\n  loadAgentStartContext,\n  removeAgentStartContext,\n  getAgentEdits,\n  type AgentStartContext,\n  type AgentEditsResult,\n} from './subagent-state.js';\n\n// ============================================================================\n// Task State Management\n// ============================================================================\n// Save and load Task tool call context, and analyze file operations\n// performed within tasks.\n\nexport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n  getTaskEdits,\n  type TaskCallContext,\n  type TaskEditsResult,\n} from './task-state.js';\n\n// ============================================================================\n// Package Manager Detection\n// ============================================================================\n// Detect which package manager (npm, yarn, pnpm, bun) a project uses\n// and construct appropriate commands.\n\nexport { detectPackageManager, getScriptCommand } from './package-manager.js';\n\n// ============================================================================\n// Configuration File Resolution\n// ============================================================================\n// Find configuration files by traversing parent directories.\n// Supports monorepo and Turborepo patterns with closest-first resolution.\n\nexport { findConfigFile } from './config-resolver.js';\n\n// ============================================================================\n// TOML Parsing\n// ============================================================================\n// Simple TOML parser for reading configuration files like supabase/config.toml.\n\nexport { parseToml, readTomlFile, type TomlValue } from './toml.js';\n\n// ============================================================================\n// Agent Type Detection\n// ============================================================================\n// Utilities for determining if a tool event was triggered by the main agent\n// or a subagent, and extracting agent IDs from transcripts.\n\nexport {\n  wasToolEventMainAgent,\n  isMainAgentTranscript,\n  isSubagentType,\n  getTranscriptAgentId,\n} from './was-tool-event-main-agent.js';\n\n// ============================================================================\n// Log File Utilities\n// ============================================================================\n// Save hook output to log files and return concise summaries.\n// Used to reduce context injection while preserving full output for debugging.\n\nexport {\n  saveOutputToLog,\n  parseEslintCounts,\n  parseTscErrorCount,\n  parseVitestResults,\n  parseCiChecks,\n  formatCiChecksTable,\n  formatErrorSummary,\n  formatSuccessMessage,\n} from './log-file.js';\n",
        "plugins/essential-logging/shared/hooks/utils/io.ts": "/**\n * I/O utilities for Claude Code hooks\n *\n * Provides stdin/stdout JSON handling and the runHook wrapper for\n * creating self-executable hooks. Claude Code passes hook input via\n * stdin as JSON and expects hook output as JSON on stdout.\n *\n * @module io\n */\n\nimport type { HookInput, HookOutput } from '../../types/types.js';\nimport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  type DebugConfig,\n} from './debug.js';\n\n/**\n * Read and parse JSON from stdin\n *\n * Reads all data from stdin, concatenates chunks, and parses as JSON.\n * Used by hook runners to receive hook input from Claude Code.\n *\n * @template T - Expected type of the parsed JSON (defaults to unknown)\n * @returns Promise that resolves to the parsed JSON data\n * @throws Error if stdin cannot be read or JSON parsing fails\n *\n * @example\n * ```typescript\n * import { readStdinJson } from './utils/io.js';\n * import type { SubagentStopInput } from '../../types/types.js';\n *\n * const input = await readStdinJson<SubagentStopInput>();\n * console.log(input.agent_id);\n * ```\n */\nexport async function readStdinJson<T = unknown>(): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const chunks: Buffer[] = [];\n\n    process.stdin.on('data', (chunk) => {\n      // Handle both Buffer and string inputs\n      if (Buffer.isBuffer(chunk)) {\n        chunks.push(chunk);\n      } else {\n        chunks.push(Buffer.from(chunk));\n      }\n    });\n    process.stdin.on('end', () => {\n      try {\n        const data = Buffer.concat(chunks).toString('utf8');\n        resolve(JSON.parse(data) as T);\n      } catch (error) {\n        reject(new Error(`Failed to parse JSON input: ${error}`));\n      }\n    });\n    process.stdin.on('error', (error) => {\n      reject(new Error(`Failed to read stdin: ${error}`));\n    });\n  });\n}\n\n/**\n * Write JSON output to stdout\n *\n * Serializes the output object to JSON and writes it to stdout with a trailing newline.\n * Used by hook runners to return hook output to Claude Code.\n *\n * @param output - The output object to serialize and write\n *\n * @example\n * ```typescript\n * import { writeStdoutJson } from './utils/io.js';\n * import type { SubagentStopHookOutput } from '../../types/types.js';\n *\n * const output: SubagentStopHookOutput = { continue: true };\n * writeStdoutJson(output);\n * ```\n */\nexport function writeStdoutJson(output: unknown): void {\n  process.stdout.write(JSON.stringify(output) + '\\n');\n}\n\n/**\n * Hook handler function type\n */\nexport type HookHandler<I extends HookInput = HookInput, O extends HookOutput = HookOutput> = (\n  input: I\n) => O | Promise<O>;\n\n/**\n * Run a hook as a self-executable script\n *\n * This function wraps a hook handler to make it self-executable when called\n * with `npx tsx`. It reads input from stdin, executes the hook, and writes\n * the output to stdout.\n *\n * @template I - Hook input type\n * @template O - Hook output type\n * @param handler - The hook handler function to execute\n *\n * @example\n * ```typescript\n * // my-hook.ts\n * import { runHook } from '../../../shared/hooks/utils/io.js';\n * import type { SessionStartInput, SessionStartHookOutput } from '../../../shared/types/types.js';\n *\n * async function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Hook executed successfully',\n *     },\n *   };\n * }\n *\n * // Make this file self-executable\n * runHook(handler);\n * ```\n */\nexport function runHook<I extends HookInput = HookInput, O extends HookOutput = HookOutput>(\n  handler: HookHandler<I, O>\n): void {\n  main(handler).catch((error) => {\n    console.error('Hook fatal error:', error);\n    process.exit(1);\n  });\n}\n\n/**\n * Main hook execution function\n *\n * Handles the complete hook lifecycle: reads input from stdin, executes the handler,\n * and writes output to stdout. All errors are caught and converted to blocking responses.\n *\n * @param handler - Hook handler function to execute\n * @returns Promise that resolves when hook completes\n *\n * @example\n * ```typescript\n * async function myHandler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Success',\n *     },\n *   };\n * }\n *\n * await main(myHandler);\n * ```\n */\nasync function main<I extends HookInput, O extends HookOutput>(\n  handler: HookHandler<I, O>\n): Promise<void> {\n  let input: I & DebugConfig;\n  let hookEventName = 'unknown';\n  let cwd = process.cwd();\n  let debug = false;\n\n  try {\n    // Read input from stdin\n    input = await readStdinJson<I & DebugConfig>();\n    hookEventName = (input as { hook_event_name?: string }).hook_event_name || 'unknown';\n    cwd = (input as { cwd?: string }).cwd || process.cwd();\n    debug = input.debug === true;\n  } catch (error) {\n    // Can't even read input - exit with error\n    console.error('Failed to read hook input:', error);\n    process.exit(1);\n  }\n\n  const logger = createDebugLogger(cwd, hookEventName, debug);\n\n  try {\n    // Log input if debug enabled\n    await logger.logInput(input);\n\n    // Execute hook handler\n    const output = await handler(input);\n\n    // Log output if debug enabled\n    await logger.logOutput(output);\n\n    // Write output to stdout\n    writeStdoutJson(output);\n\n  } catch (error) {\n    const err = error instanceof Error ? error : new Error(String(error));\n\n    // Log error\n    await logger.logError(err);\n\n    // ALWAYS return blocking error response\n    // Debug flag controls logging only, not blocking behavior\n    const errorResponse = createBlockingErrorResponse(hookEventName, err);\n    writeStdoutJson(errorResponse);\n  }\n}\n",
        "plugins/essential-logging/shared/hooks/utils/log-file.ts": "/**\n * Log File Utilities\n *\n * Functions for saving hook output to log files in `.claude/logs/`.\n * Used to preserve full output while returning concise summaries to Claude.\n *\n * @module utils/log-file\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n/**\n * Saves output content to a log file and returns the relative path.\n *\n * Creates timestamped log files in `.claude/logs/` directory.\n * The directory is created if it doesn't exist.\n *\n * @param cwd - Current working directory (project root)\n * @param category - Log category (e.g., 'eslint', 'tsc', 'ci')\n * @param identifier - Unique identifier (e.g., filename, check name)\n * @param content - Content to save to the log file\n * @returns Relative path to the created log file\n *\n * @example\n * ```typescript\n * const logPath = await saveOutputToLog(\n *   '/project',\n *   'eslint',\n *   'Button.tsx',\n *   eslintOutput\n * );\n * // Returns: '.claude/logs/eslint-Button.tsx-2025-01-02T10-30-00-000Z.log'\n * ```\n */\nexport async function saveOutputToLog(\n  cwd: string,\n  category: string,\n  identifier: string,\n  content: string\n): Promise<string> {\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  // Sanitize identifier to be filesystem-safe\n  const safeIdentifier = identifier.replace(/[/\\\\:*?\"<>|]/g, '-');\n  const filename = `${category}-${safeIdentifier}-${timestamp}.log`;\n  const logDir = path.join(cwd, '.claude', 'logs');\n  const logPath = path.join(logDir, filename);\n\n  await fs.mkdir(logDir, { recursive: true });\n  await fs.writeFile(logPath, content, 'utf-8');\n\n  // Return relative path for display\n  return `.claude/logs/${filename}`;\n}\n\n/**\n * Parses error/warning counts from ESLint output.\n *\n * @param output - ESLint stdout/stderr output\n * @returns Object with error and warning counts\n *\n * @example\n * ```typescript\n * const counts = parseEslintCounts(eslintOutput);\n * // Returns: { errors: 3, warnings: 2 }\n * ```\n */\nexport function parseEslintCounts(output: string): { errors: number; warnings: number } {\n  // ESLint summary line format: \"✖ 5 problems (3 errors, 2 warnings)\"\n  const summaryMatch = output.match(/(\\d+)\\s+problems?\\s+\\((\\d+)\\s+errors?,\\s+(\\d+)\\s+warnings?\\)/i);\n  if (summaryMatch) {\n    return {\n      errors: parseInt(summaryMatch[2], 10),\n      warnings: parseInt(summaryMatch[3], 10),\n    };\n  }\n\n  // Alternative: count individual error/warning lines\n  const errorLines = (output.match(/error\\s/gi) || []).length;\n  const warningLines = (output.match(/warning\\s/gi) || []).length;\n\n  return { errors: errorLines, warnings: warningLines };\n}\n\n/**\n * Parses error count from TypeScript compiler output.\n *\n * @param output - TypeScript compiler stdout/stderr output\n * @returns Number of type errors found\n *\n * @example\n * ```typescript\n * const errorCount = parseTscErrorCount(tscOutput);\n * // Returns: 5\n * ```\n */\nexport function parseTscErrorCount(output: string): number {\n  // TypeScript summary: \"Found 5 errors in 3 files.\"\n  const summaryMatch = output.match(/Found\\s+(\\d+)\\s+errors?/i);\n  if (summaryMatch) {\n    return parseInt(summaryMatch[1], 10);\n  }\n\n  // Alternative: count \"error TS\" occurrences\n  const errorMatches = output.match(/error\\s+TS\\d+/gi) || [];\n  return errorMatches.length;\n}\n\n/**\n * Parses test results from Vitest output.\n *\n * @param output - Vitest stdout/stderr output\n * @returns Object with passed, failed, and skipped counts\n *\n * @example\n * ```typescript\n * const results = parseVitestResults(vitestOutput);\n * // Returns: { passed: 10, failed: 2, skipped: 1 }\n * ```\n */\nexport function parseVitestResults(output: string): {\n  passed: number;\n  failed: number;\n  skipped: number;\n} {\n  // Vitest summary: \"Tests  2 failed | 10 passed | 1 skipped (13)\"\n  const passed = parseInt(output.match(/(\\d+)\\s+passed/i)?.[1] || '0', 10);\n  const failed = parseInt(output.match(/(\\d+)\\s+failed/i)?.[1] || '0', 10);\n  const skipped = parseInt(output.match(/(\\d+)\\s+skipped/i)?.[1] || '0', 10);\n\n  return { passed, failed, skipped };\n}\n\n/**\n * Parses CI check status from `gh pr checks` output.\n *\n * @param output - Output from `gh pr checks` command\n * @returns Array of check statuses with name, status, and duration\n *\n * @example\n * ```typescript\n * const checks = parseCiChecks(ghOutput);\n * // Returns: [\n * //   { name: 'lint', status: 'pass', duration: '2m30s' },\n * //   { name: 'test', status: 'fail', duration: '5m10s' }\n * // ]\n * ```\n */\nexport function parseCiChecks(\n  output: string\n): Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }> {\n  const checks: Array<{\n    name: string;\n    status: 'pass' | 'fail' | 'pending' | 'skipped';\n    duration: string;\n  }> = [];\n\n  // gh pr checks output format:\n  // lint    pass    2m30s   https://github.com/...\n  // test    fail    5m10s   https://github.com/...\n  const lines = output.split('\\n').filter((line) => line.trim());\n\n  for (const line of lines) {\n    // Split by whitespace, handling variable spacing\n    const parts = line.split(/\\s+/).filter(Boolean);\n    if (parts.length >= 2) {\n      const name = parts[0];\n      const statusRaw = parts[1].toLowerCase();\n\n      let status: 'pass' | 'fail' | 'pending' | 'skipped';\n      if (statusRaw === 'pass' || statusRaw === 'success' || statusRaw === '✓') {\n        status = 'pass';\n      } else if (statusRaw === 'fail' || statusRaw === 'failure' || statusRaw === '✗') {\n        status = 'fail';\n      } else if (statusRaw === 'skipped' || statusRaw === 'neutral') {\n        status = 'skipped';\n      } else {\n        status = 'pending';\n      }\n\n      const duration = parts[2] || '';\n\n      checks.push({ name, status, duration });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Formats CI checks as a concise emoji status table.\n *\n * @param checks - Array of parsed CI checks\n * @param logPath - Optional path to full log file (shown for failures)\n * @returns Formatted string with emoji status indicators\n *\n * @example\n * ```typescript\n * const table = formatCiChecksTable(checks, '.claude/logs/ci.log');\n * // Returns:\n * // ✅ lint (2m30s)\n * // ❌ test (5m10s) → .claude/logs/ci.log\n * // ⏳ deploy\n * ```\n */\nexport function formatCiChecksTable(\n  checks: Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }>,\n  logPath?: string\n): string {\n  const statusEmoji = {\n    pass: '✅',\n    fail: '❌',\n    pending: '⏳',\n    skipped: '⏭️',\n  };\n\n  const lines = checks.map((check) => {\n    const emoji = statusEmoji[check.status];\n    const duration = check.duration ? ` (${check.duration})` : '';\n    const logLink = check.status === 'fail' && logPath ? ` → ${logPath}` : '';\n    return `${emoji} ${check.name}${duration}${logLink}`;\n  });\n\n  return lines.join('\\n');\n}\n\n/**\n * Formats a concise error summary with log file link.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @param summary - Brief summary of issues (e.g., '3 errors, 2 warnings')\n * @param logPath - Path to the full log file\n * @returns Formatted summary string\n *\n * @example\n * ```typescript\n * const summary = formatErrorSummary('ESLint', '3 errors, 2 warnings', logPath);\n * // Returns: '❌ ESLint: 3 errors, 2 warnings\\n→ .claude/logs/eslint-file.log'\n * ```\n */\nexport function formatErrorSummary(tool: string, summary: string, logPath: string): string {\n  return `❌ ${tool}: ${summary}\\n→ ${logPath}`;\n}\n\n/**\n * Formats a success message.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @returns Formatted success string\n *\n * @example\n * ```typescript\n * const msg = formatSuccessMessage('ESLint');\n * // Returns: '✅ ESLint: No issues'\n * ```\n */\nexport function formatSuccessMessage(tool: string): string {\n  return `✅ ${tool}: No issues`;\n}\n",
        "plugins/essential-logging/shared/hooks/utils/package-manager.ts": "/**\n * Package manager detection and command utilities\n *\n * Detects which package manager (npm, yarn, pnpm, or bun) a project uses\n * by checking for the presence of lockfiles, and provides utilities for\n * constructing package manager commands.\n *\n * @module package-manager\n */\n\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Detect which package manager is used in a project\n *\n * Checks for the presence of lockfiles in the following priority order:\n * 1. bun.lockb (Bun)\n * 2. pnpm-lock.yaml (pnpm)\n * 3. yarn.lock (Yarn)\n * 4. package-lock.json (npm)\n * 5. Falls back to bun if no lockfile is found (modern default)\n *\n * @param cwd - The directory to check for lockfiles\n * @returns The detected package manager: 'bun', 'pnpm', 'yarn', or 'npm'\n *\n * @example\n * ```typescript\n * import { detectPackageManager } from './package-manager.js';\n *\n * const pm = detectPackageManager('/path/to/project');\n * console.log(pm); // 'npm' | 'yarn' | 'pnpm' | 'bun'\n * ```\n */\nexport function detectPackageManager(cwd: string): 'npm' | 'yarn' | 'pnpm' | 'bun' {\n  if (existsSync(join(cwd, 'bun.lockb'))) return 'bun';\n  if (existsSync(join(cwd, 'pnpm-lock.yaml'))) return 'pnpm';\n  if (existsSync(join(cwd, 'yarn.lock'))) return 'yarn';\n  if (existsSync(join(cwd, 'package-lock.json'))) return 'npm';\n  return 'bun'; // Modern default when no lockfile found\n}\n\n/**\n * Get the command to run a package.json script\n *\n * Constructs the appropriate command for running a package.json script\n * based on the detected package manager. All package managers use the\n * format: `{pm} run {script}`.\n *\n * @param cwd - The project directory to detect the package manager from\n * @param script - The script name from package.json to run (e.g., 'test', 'build')\n * @returns The full command string to execute the script\n *\n * @example\n * ```typescript\n * import { getScriptCommand } from './package-manager.js';\n *\n * const command = getScriptCommand('/path/to/project', 'test');\n * // Returns: 'npm run test' or 'yarn run test' or 'pnpm run test' or 'bun run test'\n * ```\n */\nexport function getScriptCommand(cwd: string, script: string): string {\n  const pm = detectPackageManager(cwd);\n  return `${pm} run ${script}`;\n}\n",
        "plugins/essential-logging/shared/hooks/utils/port.ts": "/**\n * Port availability utilities for checking and finding available TCP ports\n *\n * Provides functions to check if a port is available and find the next available\n * port in a range. Useful for avoiding port conflicts when starting development servers.\n *\n * @module port\n */\n\nimport { createServer } from 'net';\n\n/**\n * Check if a TCP port is available\n *\n * Attempts to bind a server to the given port. If successful, the port is available.\n * If binding fails with EADDRINUSE, the port is already in use.\n *\n * @param port - Port number to check\n * @returns Promise that resolves to true if port is available, false if in use\n *\n * @example\n * ```typescript\n * import { isPortAvailable } from './port.js';\n *\n * const available = await isPortAvailable(8787);\n * if (!available) {\n *   console.log('Port 8787 is already in use');\n * }\n * ```\n */\nexport async function isPortAvailable(port: number): Promise<boolean> {\n  return new Promise((resolve) => {\n    const server = createServer();\n\n    server.once('error', (err: NodeJS.ErrnoException) => {\n      if (err.code === 'EADDRINUSE') {\n        resolve(false);\n      } else {\n        // Other errors (EACCES, etc.) also mean port is not available\n        resolve(false);\n      }\n    });\n\n    server.once('listening', () => {\n      server.close(() => {\n        resolve(true);\n      });\n    });\n\n    server.listen(port);\n  });\n}\n\n/**\n * Find the next available port starting from a given port\n *\n * Sequentially checks ports starting from `startPort` until an available port\n * is found or `maxAttempts` is reached.\n *\n * @param startPort - Port number to start checking from\n * @param maxAttempts - Maximum number of ports to check (default: 10)\n * @returns Promise that resolves to an available port number, or null if none found\n *\n * @example\n * ```typescript\n * import { findAvailablePort } from './port.js';\n *\n * // Try to find an available port starting from 8787\n * const port = await findAvailablePort(8787, 10);\n * if (port) {\n *   console.log(`Found available port: ${port}`);\n * } else {\n *   console.log('No available ports found in range 8787-8796');\n * }\n * ```\n */\nexport async function findAvailablePort(\n  startPort: number,\n  maxAttempts: number = 10\n): Promise<number | null> {\n  for (let i = 0; i < maxAttempts; i++) {\n    const port = startPort + i;\n    const available = await isPortAvailable(port);\n    if (available) {\n      return port;\n    }\n  }\n  return null;\n}\n",
        "plugins/essential-logging/shared/hooks/utils/session-state.ts": "/**\n * Session state management for Stop hook tracking\n *\n * Manages session-level state for the Stop hook to track:\n * - How many times the hook has blocked the session\n * - Whether a GitHub comment has been posted for the session\n * - When the last block occurred\n *\n * This enables progressive blocking behavior where the Stop hook can:\n * 1. Block on first commit without PR (with instructions)\n * 2. Block again if no PR or comment posted\n * 3. Show warning after 3 blocks\n * 4. Reset when PR created or comment posted\n * @module session-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SESSION_STOPS_FILE = 'session-stops.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Session Stop state tracking for progressive blocking\n *\n * Tracks how many times a session has been blocked at Stop hook,\n * whether progress has been documented, and related metadata.\n */\nexport interface SessionStopState {\n  /**\n   * The unique session identifier\n   */\n  sessionId: string;\n  /**\n   * Number of times Stop hook has blocked (0-3)\n   */\n  blockCount: number;\n  /**\n   * Whether a GitHub comment has been posted\n   */\n  commentPosted: boolean;\n  /**\n   * ISO timestamp of last block\n   */\n  lastBlockTimestamp: string;\n  /**\n   * GitHub issue number linked to this session\n   */\n  issueNumber?: number;\n  /**\n   * Whether a PR has been created\n   */\n  prCreated?: boolean;\n}\n\n/**\n * Map of session IDs to their Stop hook state\n */\ninterface SessionStopsMap {\n  [sessionId: string]: SessionStopState;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to session-stops.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the session stops state file\n * @example\n * ```typescript\n * const path = getSessionStopsFilePath('/path/to/project');\n * // Returns: '/path/to/project/.claude/logs/session-stops.json'\n * ```\n */\nfunction getSessionStopsFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SESSION_STOPS_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Get session stop state for a given session\n *\n * Loads the session's Stop hook state from disk. If no state exists,\n * returns a default state with blockCount: 0.\n * @param sessionId - The session ID to load state for\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The session state, or default state if not found\n * @example\n * ```typescript\n * import { getSessionStopState } from './session-state.js';\n *\n * // In Stop hook\n * const state = await getSessionStopState(input.session_id, input.cwd);\n * console.log('Block count:', state.blockCount);\n * console.log('Comment posted:', state.commentPosted);\n * ```\n */\nexport async function getSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n\n    if (allStates[sessionId]) {\n      return allStates[sessionId];\n    }\n  } catch {\n    // File doesn't exist or parse error - return default\n  }\n\n  // Return default state\n  return {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Update session stop state with partial updates\n *\n * Merges the provided updates into the existing state and saves to disk.\n * Automatically creates the logs directory if it doesn't exist.\n * @param sessionId - The session ID to update\n * @param updates - Partial state updates to apply\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The updated session state\n * @example\n * ```typescript\n * import { updateSessionStopState } from './session-state.js';\n *\n * // Increment block count\n * await updateSessionStopState(input.session_id, {\n *   blockCount: state.blockCount + 1,\n *   lastBlockTimestamp: new Date().toISOString()\n * }, input.cwd);\n *\n * // Mark comment posted\n * await updateSessionStopState(input.session_id, {\n *   commentPosted: true\n * }, input.cwd);\n * ```\n */\nexport async function updateSessionStopState(\n  sessionId: string,\n  updates: Partial<Omit<SessionStopState, 'sessionId'>>,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  // Load existing states\n  let allStates: SessionStopsMap = {};\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    allStates = JSON.parse(content);\n  } catch {\n    // File doesn't exist yet - start fresh\n  }\n\n  // Get current state or create default\n  const currentState = allStates[sessionId] || {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n\n  // Merge updates\n  const updatedState: SessionStopState = {\n    ...currentState,\n    ...updates,\n    sessionId, // Ensure sessionId is never overwritten\n  };\n\n  allStates[sessionId] = updatedState;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n\n  return updatedState;\n}\n\n/**\n * Reset session stop state to defaults\n *\n * Clears the block count and resets all flags. This is called when:\n * - A PR is created for the session's branch\n * - A GitHub comment is posted documenting progress\n * @param sessionId - The session ID to reset\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is reset\n * @example\n * ```typescript\n * import { resetSessionStopState } from './session-state.js';\n *\n * // After PR created\n * if (prExists) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n *\n * // After comment posted\n * if (commentPosted) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n * ```\n */\nexport async function resetSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  await updateSessionStopState(\n    sessionId,\n    {\n      blockCount: 0,\n      commentPosted: false,\n      lastBlockTimestamp: new Date().toISOString(),\n    },\n    cwd,\n    statePath\n  );\n}\n\n/**\n * Remove session stop state entirely\n *\n * Deletes the session's state from the file. Use this when a session\n * is completely finished and you want to clean up.\n * @param sessionId - The session ID to remove\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is removed (fails silently)\n * @example\n * ```typescript\n * import { removeSessionStopState } from './session-state.js';\n *\n * // Cleanup after session completes successfully\n * await removeSessionStopState(input.session_id, input.cwd);\n * ```\n */\nexport async function removeSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n    delete allStates[sessionId];\n    await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n",
        "plugins/essential-logging/shared/hooks/utils/subagent-state.ts": "/**\n * Subagent state management for Claude Code hooks\n * Coordinates context between SubagentStart and SubagentStop hooks\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './frontmatter.js';\nimport {\n  parseTranscript,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SUBAGENT_TASKS_FILE = 'subagent-tasks.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface AgentStartContext {\n  agentId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n  toolUseId: string;\n}\n\ninterface SubagentTasksMap {\n  [agentId: string]: AgentStartContext;\n}\n\nexport interface AgentEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to subagent-tasks.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SUBAGENT_TASKS_FILE);\n}\n\n/**\n * Save agent context at SubagentStart for later retrieval at SubagentStop\n */\nexport async function saveAgentStartContext(\n  input: {\n    agent_id: string;\n    agent_type: string;\n    session_id: string;\n    cwd: string;\n    transcript_path: string;\n  },\n  outputPath?: string\n): Promise<AgentStartContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  // Parse parent transcript to find the Task call\n  const parentTranscript = await parseTranscript(input.transcript_path);\n  const taskInfo = findPendingTaskCall(parentTranscript, input.agent_type);\n\n  const context: AgentStartContext = {\n    agentId: input.agent_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: taskInfo?.prompt || '',\n    toolUseId: taskInfo?.toolUseId || '',\n  };\n\n  // Load existing contexts\n  let contexts: SubagentTasksMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.agent_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved agent context from SubagentStart\n */\nexport async function loadAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<AgentStartContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    return contexts[agentId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove agent context after SubagentStop processing\n */\nexport async function removeAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    delete contexts[agentId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Agent Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze an agent transcript to extract comprehensive edit information\n */\nexport async function getAgentEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<AgentEditsResult> {\n  const filename = path.basename(agentTranscriptPath);\n  if (!filename.startsWith('agent-')) {\n    throw new Error(`Path must be an agent transcript (starting with agent-): ${filename}`);\n  }\n\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Try to load saved context\n  let savedContext: AgentStartContext | undefined;\n  if (cwd) {\n    savedContext = await loadAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    toolUseId: savedContext?.toolUseId,\n    subagentType: savedContext?.agentType || options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = taskInfo?.prompt || savedContext?.prompt || '';\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd) {\n    await removeAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/essential-logging/shared/hooks/utils/task-state.test.ts": "/**\n * Tests for task-state.ts - Task state management and frontmatter parsing\n *\n * @module task-state.test\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport { tmpdir } from 'os';\nimport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n} from './task-state.js';\n\ndescribe('Task State Management', () => {\n  let testDir: string;\n  let taskCallsPath: string;\n\n  beforeEach(async () => {\n    // Create temporary directory for tests\n    testDir = await fs.mkdtemp(path.join(tmpdir(), 'task-state-test-'));\n    taskCallsPath = path.join(testDir, 'task-calls.json');\n  });\n\n  afterEach(async () => {\n    // Clean up temporary directory\n    try {\n      await fs.rm(testDir, { recursive: true, force: true });\n    } catch {\n      // Ignore cleanup errors\n    }\n  });\n\n  describe('saveTaskCallContext', () => {\n    it('should save task call context to file', async () => {\n      const input = {\n        tool_use_id: 'toolu_abc123',\n        agent_type: 'Explore',\n        session_id: 'session-xyz',\n        prompt: 'Find all API endpoints',\n        cwd: testDir,\n      };\n\n      const context = await saveTaskCallContext(input, taskCallsPath);\n\n      expect(context.toolUseId).toBe('toolu_abc123');\n      expect(context.agentType).toBe('Explore');\n      expect(context.sessionId).toBe('session-xyz');\n      expect(context.prompt).toBe('Find all API endpoints');\n      expect(context.timestamp).toBeDefined();\n\n      // Verify file was created\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n      expect(saved['toolu_abc123']).toBeDefined();\n      expect(saved['toolu_abc123'].agentType).toBe('Explore');\n    });\n\n    it('should append to existing contexts', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_first',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'First task',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_second',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Second task',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n\n      expect(Object.keys(saved)).toHaveLength(2);\n      expect(saved['toolu_first']).toBeDefined();\n      expect(saved['toolu_second']).toBeDefined();\n    });\n  });\n\n  describe('loadTaskCallContext', () => {\n    it('should load saved context by tool_use_id', async () => {\n      const input = {\n        tool_use_id: 'toolu_load_test',\n        agent_type: 'Explore',\n        session_id: 'session-load',\n        prompt: 'Load test prompt',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input, taskCallsPath);\n      const loaded = await loadTaskCallContext('toolu_load_test', testDir, taskCallsPath);\n\n      expect(loaded).toBeDefined();\n      expect(loaded?.toolUseId).toBe('toolu_load_test');\n      expect(loaded?.agentType).toBe('Explore');\n      expect(loaded?.prompt).toBe('Load test prompt');\n    });\n\n    it('should return undefined for non-existent context', async () => {\n      const loaded = await loadTaskCallContext('toolu_nonexistent', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n    });\n\n    it('should return undefined when file does not exist', async () => {\n      const loaded = await loadTaskCallContext('toolu_any', testDir, '/path/does/not/exist.json');\n      expect(loaded).toBeUndefined();\n    });\n  });\n\n  describe('removeTaskCallContext', () => {\n    it('should remove context from file', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_keep',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'Keep this',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_remove',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Remove this',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      await removeTaskCallContext('toolu_remove', testDir, taskCallsPath);\n\n      const loaded = await loadTaskCallContext('toolu_remove', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n\n      const kept = await loadTaskCallContext('toolu_keep', testDir, taskCallsPath);\n      expect(kept).toBeDefined();\n    });\n\n    it('should handle removing non-existent context gracefully', async () => {\n      await expect(\n        removeTaskCallContext('toolu_nonexistent', testDir, taskCallsPath)\n      ).resolves.toBeUndefined();\n    });\n  });\n\n  describe('parseFrontmatter (integration via parseAgentFrontmatter)', () => {\n    it('should parse simple key-value frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent.md');\n      const content = `---\nname: TestAgent\ndescription: A test agent\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      // We can't directly test parseFrontmatter since it's not exported,\n      // but we can test it indirectly through getTaskEdits if we create\n      // proper test fixtures. For now, let's create a simpler test.\n\n      // Read the file and verify the frontmatter format is correct\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---');\n      expect(fileContent).toContain('name: TestAgent');\n    });\n\n    it('should parse array values in frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent-with-skills.md');\n      const content = `---\nname: TestAgent\nskills: [skill1, skill2, skill3]\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('skills: [skill1, skill2, skill3]');\n    });\n\n    it('should handle frontmatter with various formats', async () => {\n      const agentFile = path.join(testDir, 'complex-agent.md');\n      const content = `---\nname: ComplexAgent\nversion: 1.0.0\nskills: [claude-plugins, turborepo-vercel]\nenabled: true\n---\n\n# Complex Agent\n\nThis agent has complex frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('name: ComplexAgent');\n      expect(fileContent).toContain('version: 1.0.0');\n      expect(fileContent).toContain('skills: [claude-plugins, turborepo-vercel]');\n      expect(fileContent).toContain('enabled: true');\n    });\n\n    it('should handle missing frontmatter gracefully', async () => {\n      const agentFile = path.join(testDir, 'no-frontmatter.md');\n      const content = `# Agent Without Frontmatter\n\nThis agent has no frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).not.toContain('---');\n    });\n\n    it('should handle empty frontmatter', async () => {\n      const agentFile = path.join(testDir, 'empty-frontmatter.md');\n      const content = `---\n---\n\n# Agent With Empty Frontmatter\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---\\n---');\n    });\n  });\n\n  describe('Full workflow integration', () => {\n    it('should save, load, and remove context in sequence', async () => {\n      // Save\n      const input = {\n        tool_use_id: 'toolu_workflow',\n        agent_type: 'general-purpose',\n        session_id: 'session-workflow',\n        prompt: 'Complete workflow test',\n        cwd: testDir,\n      };\n\n      const saved = await saveTaskCallContext(input, taskCallsPath);\n      expect(saved.toolUseId).toBe('toolu_workflow');\n\n      // Load\n      const loaded = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(loaded).toBeDefined();\n      expect(loaded?.prompt).toBe('Complete workflow test');\n\n      // Remove\n      await removeTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      const removed = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(removed).toBeUndefined();\n    });\n  });\n});\n",
        "plugins/essential-logging/shared/hooks/utils/task-state.ts": "/**\n * Task state management for Claude Code hooks\n *\n * Coordinates context between PreToolUse[Task] and SubagentStop hooks by saving\n * task call metadata at PreToolUse time and retrieving it later for analysis.\n * This enables tracking what tasks were requested, what agents executed them,\n * and what file operations resulted from the task execution.\n *\n * The typical flow is:\n * 1. PreToolUse[Task] - Save task context (prompt, agent type, tool use ID)\n * 2. Task executes - Agent runs and performs file operations\n * 3. SubagentStop - Load context, analyze edits, cleanup\n *\n * @module task-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport {\n  parseTranscript,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\nimport matter from './frontmatter.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst TASK_CALLS_FILE = 'task-calls.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface TaskCallContext {\n  toolUseId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n}\n\ninterface TaskCallsMap {\n  [toolUseId: string]: TaskCallContext;\n}\n\nexport interface TaskEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to task-calls.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, TASK_CALLS_FILE);\n}\n\n/**\n * Save task call context at PreToolUse[Task] for later retrieval at SubagentStop\n *\n * Stores task metadata in .claude/logs/task-calls.json so that SubagentStop hooks\n * can correlate the task's original prompt and parameters with the agent's execution\n * results. This enables rich commit messages and task tracking.\n *\n * @param input - Task call metadata to save\n * @param input.tool_use_id - The unique ID of the Task tool use\n * @param input.agent_type - The type of agent that will execute (e.g., 'Explore', 'Plan')\n * @param input.session_id - The current session ID\n * @param input.prompt - The task prompt/description provided to the agent\n * @param input.cwd - The working directory where logs should be stored\n * @param outputPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context object\n *\n * @example\n * ```typescript\n * import { saveTaskCallContext } from './task-state.js';\n *\n * // In PreToolUse[Task] hook\n * const context = await saveTaskCallContext({\n *   tool_use_id: 'toolu_abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   prompt: 'Find all API endpoints',\n *   cwd: '/path/to/project'\n * });\n * ```\n */\nexport async function saveTaskCallContext(\n  input: {\n    tool_use_id: string;\n    agent_type: string;\n    session_id: string;\n    prompt: string;\n    cwd: string;\n  },\n  outputPath?: string\n): Promise<TaskCallContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  const context: TaskCallContext = {\n    toolUseId: input.tool_use_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: input.prompt,\n  };\n\n  // Load existing contexts\n  let contexts: TaskCallsMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.tool_use_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved task call context from PreToolUse[Task]\n *\n * Retrieves the task metadata that was saved during PreToolUse. This allows\n * SubagentStop hooks to access the original task prompt and parameters.\n *\n * @param toolUseId - The tool_use_id from the Task tool call\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context, or undefined if not found\n *\n * @example\n * ```typescript\n * import { loadTaskCallContext } from './task-state.js';\n *\n * // In SubagentStop hook\n * const context = await loadTaskCallContext(\n *   'toolu_abc123',\n *   '/path/to/project'\n * );\n * if (context) {\n *   console.log('Task prompt:', context.prompt);\n *   console.log('Agent type:', context.agentType);\n * }\n * ```\n */\nexport async function loadTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<TaskCallContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    return contexts[toolUseId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove task context after processing\n *\n * Cleans up the saved task context once it has been processed by SubagentStop.\n * This prevents the context file from growing indefinitely.\n *\n * @param toolUseId - The tool_use_id of the context to remove\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns Promise that resolves when context is removed (or fails silently)\n *\n * @example\n * ```typescript\n * import { removeTaskCallContext } from './task-state.js';\n *\n * // After processing in SubagentStop\n * await removeTaskCallContext('toolu_abc123', '/path/to/project');\n * ```\n */\nexport async function removeTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    delete contexts[toolUseId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Task Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze a task transcript to extract comprehensive edit information\n *\n * Parses an agent transcript to determine what files were created, edited, or deleted\n * during task execution. Correlates with saved task context to provide complete\n * metadata about the task, including the original prompt, agent type, and preloaded skills.\n *\n * This function:\n * 1. Parses the agent transcript to extract messages and metadata\n * 2. Finds the parent session transcript and locates the matching Task tool call\n * 3. Loads the saved task context (if available)\n * 4. Analyzes file operations (new, edited, deleted files)\n * 5. Identifies preloaded skills from agent frontmatter\n * 6. Cleans up the saved context\n *\n * @param agentTranscriptPath - Path to the agent transcript file (from SubagentStop's agent_transcript_path field)\n * @param options - Optional configuration\n * @param options.contextPath - Custom path for task-calls.json (for testing)\n * @param options.subagentType - Fallback subagent type if not found in context\n * @returns Comprehensive task execution metadata and file operation lists\n * @throws Error if agent transcript is empty\n * @throws Error if agentId cannot be determined\n * @throws Error if parent session transcript not found\n *\n * @example\n * ```typescript\n * import { getTaskEdits } from './task-state.js';\n *\n * // In SubagentStop hook\n * const edits = await getTaskEdits(input.agent_transcript_path);\n *\n * console.log('Task prompt:', edits.agentPrompt);\n * console.log('Agent type:', edits.subagentType);\n * console.log('Files created:', edits.agentNewFiles);\n * console.log('Files edited:', edits.agentEditedFiles);\n * console.log('Files deleted:', edits.agentDeletedFiles);\n * console.log('Preloaded skills:', edits.agentPreloadedSkillsFiles);\n * ```\n *\n * @example\n * ```typescript\n * // Complete PreToolUse → SubagentStop flow\n *\n * // 1. PreToolUse[Task] - Save context\n * import { saveTaskCallContext } from './task-state.js';\n *\n * async function handlePreToolUse(input: PreToolUseInput) {\n *   if (input.tool_name === 'Task') {\n *     await saveTaskCallContext({\n *       tool_use_id: input.tool_use_id,\n *       agent_type: input.tool_input.subagent_type,\n *       session_id: input.session_id,\n *       prompt: input.tool_input.prompt,\n *       cwd: input.cwd\n *     });\n *   }\n *   return { hookSpecificOutput: { permissionDecision: 'allow' } };\n * }\n *\n * // 2. Task executes (agent runs)\n *\n * // 3. SubagentStop - Analyze edits\n * import { getTaskEdits } from './task-state.js';\n *\n * async function handleSubagentStop(input: SubagentStopInput) {\n *   const edits = await getTaskEdits(input.agent_transcript_path);\n *\n *   // Use edits for commit message, logging, etc.\n *   console.log(`Task \"${edits.agentPrompt}\" completed`);\n *   console.log(`Modified ${edits.agentEditedFiles.length} files`);\n *\n *   return {};\n * }\n * ```\n */\nexport async function getTaskEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<TaskEditsResult> {\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    subagentType: options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  // Try to load saved context using tool_use_id from task call\n  let savedContext: TaskCallContext | undefined;\n  if (cwd && taskInfo?.toolUseId) {\n    savedContext = await loadTaskCallContext(taskInfo.toolUseId, cwd, options?.contextPath);\n  }\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = savedContext?.prompt || taskInfo?.prompt || '';\n  const toolUseId = taskInfo?.toolUseId || savedContext?.toolUseId;\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd && toolUseId) {\n    await removeTaskCallContext(toolUseId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/essential-logging/shared/hooks/utils/toml.ts": "/**\n * Simple TOML parser for configuration files\n *\n * Provides basic TOML parsing functionality for reading configuration files\n * like supabase/config.toml. This is a lightweight parser that supports the\n * most common TOML features without requiring external dependencies.\n *\n * Supported TOML features:\n * - Key-value pairs (strings, numbers, booleans)\n * - Inline arrays: `values = [1, 2, 3]`\n * - Multiline arrays spanning multiple lines\n * - Tables (sections): `[section]` and `[section.subsection]`\n * - Comments starting with `#`\n *\n * @module toml\n */\n\nexport interface TomlValue {\n  [key: string]: string | number | boolean | string[] | TomlValue;\n}\n\n/**\n * Parse a TOML string into a JavaScript object\n *\n * Converts TOML configuration syntax into a JavaScript object with nested\n * structure matching the TOML sections and subsections.\n *\n * @param content - The TOML string to parse\n * @returns Parsed object with nested structure\n *\n * @example\n * ```typescript\n * import { parseToml } from './toml.js';\n *\n * const tomlContent = `\n * # Project configuration\n * project_id = \"my-project\"\n * enabled = true\n *\n * [api]\n * port = 54321\n * enabled_services = [\"auth\", \"realtime\", \"storage\"]\n *\n * [db]\n * port = 54322\n * `;\n *\n * const config = parseToml(tomlContent);\n * console.log(config.project_id); // \"my-project\"\n * console.log(config.enabled); // true\n * console.log(config.api.port); // 54321\n * console.log(config.api.enabled_services); // [\"auth\", \"realtime\", \"storage\"]\n * console.log(config.db.port); // 54322\n * ```\n */\nexport function parseToml(content: string): TomlValue {\n  const result: TomlValue = {};\n  let currentSection: TomlValue = result;\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      continue;\n    }\n\n    // Handle table headers [section] or [section.subsection]\n    if (line.startsWith('[') && line.endsWith(']')) {\n      const sectionPath = line.slice(1, -1).trim();\n      currentSection = result;\n\n      for (const part of sectionPath.split('.')) {\n        if (!(part in currentSection)) {\n          currentSection[part] = {};\n        }\n        currentSection = currentSection[part] as TomlValue;\n      }\n      continue;\n    }\n\n    // Handle key-value pairs\n    const eqIndex = line.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = line.slice(0, eqIndex).trim();\n    const value = line.slice(eqIndex + 1).trim();\n\n    // Parse the value\n    currentSection[key] = parseValue(value, lines, i);\n  }\n\n  return result;\n}\n\n/**\n * Parse a TOML value\n */\nfunction parseValue(value: string, lines: string[], lineIndex: number): string | number | boolean | string[] {\n  // Handle multiline arrays\n  if (value === '[' || value.startsWith('[') && !value.endsWith(']')) {\n    return parseMultilineArray(value, lines, lineIndex);\n  }\n\n  // Handle inline arrays\n  if (value.startsWith('[') && value.endsWith(']')) {\n    return parseInlineArray(value);\n  }\n\n  // Handle strings\n  if (value.startsWith('\"') && value.endsWith('\"')) {\n    return value.slice(1, -1);\n  }\n  if (value.startsWith(\"'\") && value.endsWith(\"'\")) {\n    return value.slice(1, -1);\n  }\n\n  // Handle booleans\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle numbers\n  const num = Number(value);\n  if (!isNaN(num)) return num;\n\n  // Return as string if nothing else matches\n  return value;\n}\n\n/**\n * Parse an inline array like [1, 2, 3] or [\"a\", \"b\", \"c\"]\n */\nfunction parseInlineArray(value: string): string[] {\n  const inner = value.slice(1, -1).trim();\n  if (!inner) return [];\n\n  const items: string[] = [];\n  let current = '';\n  let inQuote = false;\n  let quoteChar = '';\n\n  for (const char of inner) {\n    if ((char === '\"' || char === \"'\") && !inQuote) {\n      inQuote = true;\n      quoteChar = char;\n    } else if (char === quoteChar && inQuote) {\n      inQuote = false;\n      quoteChar = '';\n    } else if (char === ',' && !inQuote) {\n      const trimmed = current.trim();\n      if (trimmed) {\n        items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n      }\n      current = '';\n    } else {\n      current += char;\n    }\n  }\n\n  const trimmed = current.trim();\n  if (trimmed) {\n    items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n  }\n\n  return items;\n}\n\n/**\n * Parse a multiline array\n */\nfunction parseMultilineArray(startValue: string, lines: string[], startIndex: number): string[] {\n  const items: string[] = [];\n  let content = startValue;\n\n  // Collect lines until we find the closing bracket\n  for (let i = startIndex; i < lines.length; i++) {\n    const line = lines[i].trim();\n    if (i > startIndex) {\n      content += ' ' + line;\n    }\n    if (line.includes(']')) {\n      break;\n    }\n  }\n\n  // Now parse as inline array\n  const match = content.match(/\\[([\\s\\S]*)\\]/);\n  if (match) {\n    return parseInlineArray('[' + match[1] + ']');\n  }\n\n  return items;\n}\n\n/**\n * Read and parse a TOML file\n *\n * Reads a TOML configuration file from disk and parses it into a JavaScript object.\n * Returns null if the file doesn't exist or cannot be read.\n *\n * @param filePath - Path to the TOML file\n * @returns Parsed object, or null if file doesn't exist or read fails\n *\n * @example\n * ```typescript\n * import { readTomlFile } from './toml.js';\n * import { join } from 'path';\n *\n * // Read Supabase configuration\n * const supabaseConfig = await readTomlFile(\n *   join(process.cwd(), 'supabase', 'config.toml')\n * );\n *\n * if (supabaseConfig) {\n *   console.log('Project ID:', supabaseConfig.project_id);\n *   console.log('API port:', supabaseConfig.api?.port);\n *   console.log('DB port:', supabaseConfig.db?.port);\n * } else {\n *   console.log('Supabase not initialized');\n * }\n * ```\n */\nexport async function readTomlFile(filePath: string): Promise<TomlValue | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(filePath, 'utf-8');\n    return parseToml(content);\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get the dev server port from a wrangler.toml or wrangler.jsonc file\n *\n * Parses the wrangler configuration file to extract the dev server port.\n * Supports both TOML format (wrangler.toml) and JSONC format (wrangler.jsonc).\n *\n * For TOML files, looks for: `[dev]` section with `port = 8787`\n * For JSONC files, looks for: `{ \"dev\": { \"port\": 8787 } }`\n *\n * @param wranglerPath - Path to wrangler.toml or wrangler.jsonc file\n * @returns Port number if found, null if file doesn't exist or port not configured\n *\n * @example\n * ```typescript\n * import { getWranglerDevPort } from './toml.js';\n * import { join } from 'path';\n *\n * // Check wrangler.toml\n * const port = await getWranglerDevPort(join(process.cwd(), 'wrangler.toml'));\n * console.log('Wrangler dev port:', port || 8787); // Default to 8787 if not found\n *\n * // Check wrangler.jsonc\n * const port2 = await getWranglerDevPort(join(process.cwd(), 'wrangler.jsonc'));\n * ```\n */\nexport async function getWranglerDevPort(wranglerPath: string): Promise<number | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(wranglerPath, 'utf-8');\n\n    // Handle TOML format (wrangler.toml)\n    if (wranglerPath.endsWith('.toml')) {\n      const config = parseToml(content);\n      if (config.dev && typeof config.dev === 'object') {\n        const dev = config.dev as TomlValue;\n        if (typeof dev.port === 'number') {\n          return dev.port;\n        }\n      }\n      return null;\n    }\n\n    // Handle JSONC format (wrangler.jsonc)\n    if (wranglerPath.endsWith('.jsonc') || wranglerPath.endsWith('.json')) {\n      // Strip comments from JSONC\n      const jsonContent = content.replace(/\\/\\*[\\s\\S]*?\\*\\/|\\/\\/.*/g, '');\n      const config = JSON.parse(jsonContent);\n      if (config.dev && typeof config.dev.port === 'number') {\n        return config.dev.port;\n      }\n      return null;\n    }\n\n    return null;\n  } catch {\n    return null;\n  }\n}\n",
        "plugins/essential-logging/shared/hooks/utils/transcripts.ts": "/**\n * Transcript parsing utilities for Claude Code\n * Lenient JSONL parsing without Zod - uses type guards for safety\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Types for Transcript Parsing\n// ============================================================================\n\nexport interface BaseMessage {\n  uuid: string;\n  parentUuid: string | null;\n  timestamp: string;\n  sessionId: string;\n  isSidechain: boolean;\n  cwd: string;\n  version: string;\n  gitBranch?: string;\n  slug?: string;\n  agentId?: string;\n}\n\nexport interface ToolUseContent {\n  type: 'tool_use';\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n}\n\nexport interface TextContent {\n  type: 'text';\n  text: string;\n}\n\nexport interface ToolResultContent {\n  type: 'tool_result';\n  tool_use_id: string;\n  content?: string | Array<{ type: string; text?: string }>;\n}\n\nexport type AssistantContent = ToolUseContent | TextContent | { type: string; [key: string]: unknown };\nexport type UserContent = string | Array<ToolResultContent | { type: string; [key: string]: unknown }>;\n\nexport interface UserMessage extends BaseMessage {\n  type: 'user';\n  userType: 'external';\n  message: {\n    role: 'user';\n    content: UserContent;\n  };\n  toolUseResult?: Record<string, unknown>;\n}\n\nexport interface AssistantMessage extends BaseMessage {\n  type: 'assistant';\n  requestId: string;\n  message: {\n    id: string;\n    type: 'message';\n    role: 'assistant';\n    model: string;\n    content: AssistantContent[];\n    stop_reason: string | null;\n    stop_sequence: string | null;\n    usage: {\n      input_tokens: number;\n      output_tokens: number;\n      cache_creation_input_tokens?: number;\n      cache_read_input_tokens?: number;\n    };\n  };\n}\n\nexport interface SystemMessage extends BaseMessage {\n  type: 'system';\n  subtype: string;\n  content: string;\n  isMeta: boolean;\n  level: 'info' | 'warning' | 'error';\n}\n\nexport type Message = UserMessage | AssistantMessage | SystemMessage;\n\nexport interface Transcript {\n  sourcePath: string;\n  sessionId: string;\n  subagentType?: string;\n  agentId?: string;\n  isSidechain: boolean;\n  messages: Message[];\n}\n\n// ============================================================================\n// Type Guards\n// ============================================================================\n\nfunction isObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === 'object' && value !== null;\n}\n\nfunction isMessage(line: unknown): line is Message {\n  if (!isObject(line)) return false;\n  const type = line.type;\n  return type === 'user' || type === 'assistant' || type === 'system';\n}\n\nfunction hasRequiredFields(line: unknown): boolean {\n  if (!isObject(line)) return false;\n  return (\n    typeof line.uuid === 'string' &&\n    typeof line.timestamp === 'string' &&\n    typeof line.sessionId === 'string'\n  );\n}\n\n// ============================================================================\n// Parsing Functions\n// ============================================================================\n\n/**\n * Parse a single JSONL line (lenient - returns null on error)\n */\nexport function parseTranscriptLine(line: string): Message | null {\n  try {\n    const json = JSON.parse(line);\n    if (!isMessage(json) || !hasRequiredFields(json)) {\n      return null;\n    }\n    return json as Message;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get transcript metadata from file path\n */\nexport function getTranscriptInfo(filePath: string): { agentId?: string; isSidechain: boolean } {\n  const filename = path.basename(filePath);\n  const isSubagent = filename.startsWith('agent-');\n  const agentId = isSubagent ? filename.replace('agent-', '').replace('.jsonl', '') : undefined;\n\n  return { agentId, isSidechain: isSubagent };\n}\n\n/**\n * Parse a full .jsonl transcript file\n */\nexport async function parseTranscript(filePath: string): Promise<Transcript> {\n  const info = getTranscriptInfo(filePath);\n  const content = await fs.readFile(filePath, 'utf-8');\n  const lines = content.trim().split('\\n').filter(Boolean);\n\n  const messages: Message[] = [];\n  let sessionId = '';\n\n  for (const line of lines) {\n    const parsed = parseTranscriptLine(line);\n    if (!parsed) continue;\n\n    if (!sessionId) sessionId = parsed.sessionId;\n    messages.push(parsed);\n  }\n\n  return {\n    sourcePath: filePath,\n    sessionId,\n    agentId: info.agentId,\n    isSidechain: info.isSidechain,\n    messages,\n  };\n}\n\n// ============================================================================\n// Query Functions\n// ============================================================================\n\n/**\n * Extract all tool uses from a transcript\n */\nexport function getToolUses(transcript: Transcript): Array<{\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n  timestamp: string;\n}> {\n  const toolUses: Array<{\n    id: string;\n    name: string;\n    input: Record<string, unknown>;\n    timestamp: string;\n  }> = [];\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        toolUses.push({\n          id: tu.id,\n          name: tu.name,\n          input: tu.input,\n          timestamp: msg.timestamp,\n        });\n      }\n    }\n  }\n\n  return toolUses;\n}\n\n/**\n * Extract unique file paths edited by Write/Edit tools\n */\nexport function getEditedFiles(transcript: Transcript): string[] {\n  const files = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write' || tu.name === 'Edit') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string') {\n            files.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(files);\n}\n\n/**\n * Extract unique file paths created by Write tool (new files only)\n */\nexport function getNewFiles(transcript: Transcript): string[] {\n  const newFiles: string[] = [];\n  const seenPaths = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string' && !seenPaths.has(filePath)) {\n            newFiles.push(filePath);\n            seenPaths.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return newFiles;\n}\n\n/**\n * Extract unique file paths deleted via Bash rm commands\n */\nexport function getDeletedFiles(transcript: Transcript): string[] {\n  const deletedFiles = new Set<string>();\n  const rmPattern = /^\\s*rm\\s+(?:-[rfiv]+\\s+)*(.+)$/;\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Bash') {\n          const command = tu.input.command;\n          if (typeof command !== 'string') continue;\n\n          const commands = command.split(/\\s*(?:&&|;)\\s*/);\n          for (const cmd of commands) {\n            const match = cmd.match(rmPattern);\n            if (match) {\n              const pathsStr = match[1].trim();\n              const paths = pathsStr.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g) || [];\n\n              for (const p of paths) {\n                const cleanPath = p.replace(/^[\"']|[\"']$/g, '');\n                if (!cleanPath.startsWith('-')) {\n                  deletedFiles.add(cleanPath);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(deletedFiles);\n}\n\n/**\n * Find pending Task tool call matching agent type\n */\nexport function findPendingTaskCall(\n  transcript: Transcript,\n  agentType: string\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls: Array<{\n    toolUseId: string;\n    subagentType: string;\n    prompt: string;\n    timestamp: string;\n  }> = [];\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.push({\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Collect completed tool_use_ids\n  const completedToolUseIds = new Set<string>();\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const content = msg.message.content;\n    if (typeof content === 'string') continue;\n    for (const rc of content) {\n      if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n        completedToolUseIds.add(rc.tool_use_id);\n      }\n    }\n  }\n\n  // Find pending Task calls matching agent type\n  const pendingTasks = taskCalls\n    .filter((t) => !completedToolUseIds.has(t.toolUseId))\n    .filter((t) => t.subagentType === agentType)\n    .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n  return pendingTasks[0];\n}\n\n/**\n * Find Task tool call for an agent using multiple strategies\n */\nexport function findTaskCallForAgent(\n  transcript: Transcript,\n  targetAgentId: string,\n  options?: {\n    subagentType?: string;\n    toolUseId?: string;\n    agentStartTimestamp?: string;\n  }\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls = new Map<string, {\n    subagentType: string;\n    prompt: string;\n    toolUseId: string;\n    timestamp: string;\n  }>();\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.set(tu.id, {\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Strategy 1: Direct lookup by toolUseId\n  if (options?.toolUseId) {\n    const direct = taskCalls.get(options.toolUseId);\n    if (direct) return direct;\n  }\n\n  // Strategy 2: Match via tool_result.agentId\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const toolResult = msg.toolUseResult as { agentId?: string } | undefined;\n    if (toolResult?.agentId === targetAgentId) {\n      const content = msg.message.content;\n      if (typeof content === 'string') continue;\n\n      for (const rc of content) {\n        if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n          const taskInfo = taskCalls.get(rc.tool_use_id);\n          if (taskInfo) return taskInfo;\n        }\n      }\n    }\n  }\n\n  // Strategy 3: Fuzzy match by subagentType and timestamp\n  if (options?.subagentType && options?.agentStartTimestamp) {\n    const agentStartTime = new Date(options.agentStartTimestamp).getTime();\n    const maxDelta = 10000; // 10 seconds\n\n    const candidates = Array.from(taskCalls.values())\n      .filter((t) => t.subagentType === options.subagentType)\n      .filter((t) => {\n        const taskTime = new Date(t.timestamp).getTime();\n        return taskTime <= agentStartTime && agentStartTime - taskTime <= maxDelta;\n      })\n      .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n    if (candidates[0]) return candidates[0];\n  }\n\n  return undefined;\n}\n",
        "plugins/essential-logging/shared/hooks/utils/was-tool-event-main-agent.ts": "/**\n * Utility to determine if a tool event was executed by the main agent vs a subagent\n */\n\nimport { parseTranscript, type AssistantMessage } from './transcripts.js';\n\n/**\n * Check if a specific tool use was executed by the main agent (not a subagent)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param toolUseId - The tool_use_id to check\n * @returns true if the tool was used by the main agent, false if by a subagent\n *\n * @example\n * ```typescript\n * const isMainAgent = await wasToolEventMainAgent(\n *   input.transcript_path,\n *   input.tool_use_id\n * );\n * if (!isMainAgent) {\n *   // Skip processing for subagent tool use\n *   return { continue: true };\n * }\n * ```\n */\nexport async function wasToolEventMainAgent(\n  transcriptPath: string,\n  toolUseId: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n\n  // Find the assistant message containing this tool use\n  for (const msg of transcript.messages) {\n    if (msg.type === 'assistant') {\n      const assistantMsg = msg as AssistantMessage;\n      const toolUse = assistantMsg.message.content.find(\n        (c) => c.type === 'tool_use' && 'id' in c && c.id === toolUseId\n      );\n\n      if (toolUse) {\n        // If agentId is undefined/null, it's the main agent\n        // If agentId is a string, it's a subagent\n        return !msg.agentId;\n      }\n    }\n  }\n\n  // If we can't find the tool use, default to assuming it's the main agent\n  // This is safer than blocking legitimate main agent operations\n  return true;\n}\n\n/**\n * Check if the entire transcript is from the main agent session (not a subagent session)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns true if this is a main agent transcript, false if it's a subagent transcript\n *\n * @example\n * ```typescript\n * const isMainSession = await isMainAgentTranscript(input.transcript_path);\n * if (!isMainSession) {\n *   // This is a subagent session, skip processing\n *   return { continue: true };\n * }\n * ```\n */\nexport async function isMainAgentTranscript(transcriptPath: string): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return !transcript.isSidechain;\n}\n\n/**\n * Check if a transcript belongs to a specific subagent type\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param subagentType - The subagent type to check for (e.g., \"Explore\", \"Plan\")\n * @returns true if the transcript is from the specified subagent type\n *\n * @example\n * ```typescript\n * const isExploreAgent = await isSubagentType(input.transcript_path, 'Explore');\n * if (isExploreAgent) {\n *   // Special handling for Explore agents\n * }\n * ```\n */\nexport async function isSubagentType(\n  transcriptPath: string,\n  subagentType: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.subagentType === subagentType;\n}\n\n/**\n * Get the agent ID from a transcript (undefined for main agent, string for subagents)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns The agent ID if this is a subagent, undefined if main agent\n *\n * @example\n * ```typescript\n * const agentId = await getTranscriptAgentId(input.transcript_path);\n * if (agentId) {\n *   console.log(`Processing subagent: ${agentId}`);\n * } else {\n *   console.log('Processing main agent');\n * }\n * ```\n */\nexport async function getTranscriptAgentId(transcriptPath: string): Promise<string | undefined> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.agentId;\n}\n",
        "plugins/essential-logging/shared/hooks/validate-folder-structure-mkdir.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Bash mkdir)\n *\n * This hook fires before Bash operations to validate directory creation against\n * CLAUDE.md folder specifications. Validates:\n * - mkdir commands creating new directories\n * - Checks parent's subfolder spec for allowed patterns\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n *\n * @module hooks/validate-folder-structure-mkdir\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Extract directory paths from mkdir commands\n * Handles: mkdir dir, mkdir -p dir, mkdir -p dir1 dir2, etc.\n */\nfunction extractMkdirPaths(command: string): string[] {\n  const paths: string[] = [];\n\n  // Extract the actual command (before pipes, semicolons, &&, etc.)\n  // This prevents false positives from strings containing \"mkdir\"\n  const actualCommand = command.split(/[|;&]/)[0].trim();\n\n  // Check if this is actually a mkdir command (not just containing \"mkdir\" in a string)\n  if (!actualCommand.match(/^\\s*(sudo\\s+)?mkdir\\b/)) {\n    return paths;\n  }\n\n  // Remove mkdir and common flags\n  const remainder = command\n    .replace(/^.*mkdir\\s+/, '')\n    .replace(/-[pv]+\\s+/g, '');\n\n  // Extract all path arguments (space-separated)\n  // Handle quoted paths\n  const pathMatches = remainder.match(/(?:\"([^\"]+)\"|'([^']+)'|(\\S+))/g);\n\n  if (pathMatches) {\n    for (const match of pathMatches) {\n      // Remove quotes if present\n      const cleanPath = match.replace(/^[\"']|[\"']$/g, '');\n      // Skip flags\n      if (!cleanPath.startsWith('-')) {\n        paths.push(cleanPath);\n      }\n    }\n  }\n\n  return paths;\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Bash mkdir operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Bash tool\n  if (input.tool_name !== 'Bash') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-mkdir', true);\n\n  try {\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput.command;\n\n    if (!command) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Extract mkdir paths from command\n    const mkdirPaths = extractMkdirPaths(command);\n\n    if (mkdirPaths.length === 0) {\n      // Not a mkdir command - don't log anything, just allow\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only log input for actual mkdir commands\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n      command,\n      mkdirPaths,\n    });\n\n    await logger.logOutput({\n      command,\n      mkdirPaths,\n    });\n\n    const allErrors: string[] = [];\n\n    // Validate each directory path\n    for (const dirPath of mkdirPaths) {\n      // Resolve to absolute path\n      const absolutePath = path.isAbsolute(dirPath)\n        ? dirPath\n        : path.resolve(input.cwd, dirPath);\n\n      const parentDir = path.dirname(absolutePath);\n      const folderName = path.basename(absolutePath);\n\n      await logger.logOutput({\n        dirPath,\n        absolutePath,\n        parentDir,\n        folderName,\n      });\n\n      // Check if directory already exists\n      try {\n        await fs.access(absolutePath);\n        // Directory exists, no need to validate\n        await logger.logOutput({\n          dirPath,\n          status: 'exists',\n        });\n        continue;\n      } catch {\n        // Directory doesn't exist, proceed with validation\n      }\n\n      // Validate the directory is allowed in parent's subfolder spec\n      const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n      if (parentClaudeMd) {\n        const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n        const { data: parentData } = matter(parentContent);\n        const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n        await logger.logOutput({\n          check: 'parent-subfolder-validation',\n          dirPath,\n          parentClaudeMd,\n          parentFrontmatter,\n        });\n\n        if (parentFrontmatter.folder?.subfolders) {\n          const validation = validateAgainstSpec(\n            folderName,\n            parentFrontmatter.folder.subfolders,\n            'Folder'\n          );\n\n          if (!validation.valid) {\n            allErrors.push(\n              `Cannot create directory \"${folderName}\" in \"${parentDir}\":\\n` +\n                validation.errors.map(e => `  - ${e}`).join('\\n') +\n                `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n            );\n          }\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `Folder structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Folder structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/validate-folder-structure-write.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Write)\n *\n * This hook fires before Write operations to validate file creation against\n * CLAUDE.md folder specifications. Validates both:\n * 1. File is in an allowed subdirectory (checks parent's subfolder spec)\n * 2. File matches allowed patterns in its immediate directory (checks files spec)\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n * - folder.files: Controls what files can exist in the folder\n *\n * @module hooks/validate-folder-structure-write\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Write operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write tool\n  if (input.tool_name !== 'Write') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-write', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Resolve to absolute path\n    const absolutePath = path.isAbsolute(filePath)\n      ? filePath\n      : path.resolve(input.cwd, filePath);\n\n    const fileDir = path.dirname(absolutePath);\n    const fileName = path.basename(absolutePath);\n    const parentDir = path.dirname(fileDir);\n    const folderName = path.basename(fileDir);\n\n    await logger.logOutput({\n      filePath,\n      absolutePath,\n      fileDir,\n      fileName,\n      parentDir,\n      folderName,\n    });\n\n    const allErrors: string[] = [];\n\n    // Check 1: Validate the directory itself is allowed (check parent's subfolder spec)\n    const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n    if (parentClaudeMd) {\n      const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n      const { data: parentData } = matter(parentContent);\n      const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'parent-subfolder-validation',\n        parentClaudeMd,\n        parentFrontmatter,\n      });\n\n      if (parentFrontmatter.folder?.subfolders) {\n        const validation = validateAgainstSpec(\n          folderName,\n          parentFrontmatter.folder.subfolders,\n          'Folder'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file in directory \"${folderName}\":\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // Check 2: Validate the file itself is allowed (check directory's files spec)\n    const dirClaudeMd = await findClaudeMdInDir(fileDir);\n\n    if (dirClaudeMd) {\n      const dirContent = await fs.readFile(dirClaudeMd, 'utf-8');\n      const { data: dirData } = matter(dirContent);\n      const dirFrontmatter = dirData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'file-validation',\n        dirClaudeMd,\n        dirFrontmatter,\n      });\n\n      if (dirFrontmatter.folder?.files) {\n        const validation = validateAgainstSpec(\n          fileName,\n          dirFrontmatter.folder.files,\n          'File'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file \"${fileName}\" in this directory:\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nFile restrictions defined in: ${dirClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `File structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `File structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/essential-logging/shared/hooks/validate-rules-file.ts": "/**\n * PreToolUse Hook - Validate Rules File\n *\n * This hook fires before Write and Edit operations on rule files in .claude/rules\n * to validate that markdown-specific frontmatter is only used in .md-specific rules.\n *\n * Provides guidance:\n * - Warns if markdown frontmatter is used in non-.md rules\n * - Encourages markdown frontmatter in .md rules if not present\n * - Does NOT block operations - only provides context\n *\n * @module hooks/validate-rules-file\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface MarkdownValidation {\n  headings?: unknown;\n  metadata?: unknown;\n}\n\ninterface RuleFrontmatter {\n  markdown?: MarkdownValidation;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a rule filename indicates it applies to markdown files\n */\nfunction isMarkdownRule(filename: string): boolean {\n  const lowerFilename = filename.toLowerCase();\n\n  // Remove .md extension from rule filename for checking\n  const ruleName = lowerFilename.replace(/\\.md$/, '');\n\n  // Check if rule name suggests markdown files\n  return (\n    ruleName.includes('markdown') ||\n    ruleName.includes('.md') ||\n    ruleName === 'md' ||\n    ruleName.endsWith('-md')\n  );\n}\n\n/**\n * PreToolUse hook handler for validating rules files\n *\n * Validates that markdown frontmatter is appropriately used in rule files.\n * Provides guidance but does not block operations.\n *\n * @param input - PreToolUse hook input from Claude Code\n * @returns Hook output with guidance messages\n */\nasync function handler(\n  input: PreToolUseInput\n): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-rules-file', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Get the file path and content from tool input\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Check if this is a file in .claude/rules\n    const normalizedPath = path.normalize(filePath);\n    const isRuleFile = normalizedPath.includes(path.join('.claude', 'rules')) &&\n                       filePath.endsWith('.md');\n\n    if (!isRuleFile) {\n      await logger.logOutput({ message: 'Not a rule file, skipping' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get content based on operation type\n    let content: string | undefined;\n\n    if (input.tool_name === 'Write') {\n      content = toolInput.content;\n    } else if (input.tool_name === 'Edit') {\n      // For Edit, we need the new content after the edit\n      // Since we can't easily reconstruct it, we'll just check the new_string portion\n      content = toolInput.new_string;\n    }\n\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter\n    let frontmatter: RuleFrontmatter;\n    try {\n      const { data } = matter(content);\n      frontmatter = data as RuleFrontmatter;\n    } catch {\n      // If we can't parse frontmatter, allow the operation\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    const filename = path.basename(filePath);\n    const hasMarkdownFrontmatter = Boolean(frontmatter.markdown);\n    const isMdRule = isMarkdownRule(filename);\n\n    await logger.logOutput({\n      filename,\n      hasMarkdownFrontmatter,\n      isMdRule,\n    });\n\n    // Case 1: Has markdown frontmatter but doesn't apply to .md files\n    if (hasMarkdownFrontmatter && !isMdRule) {\n      const warningMessage =\n        `⚠️  Rule file \"${filename}\" contains markdown-specific frontmatter but doesn't appear to target .md files.\\n\\n` +\n        `The \\`markdown:\\` frontmatter is designed for validating markdown file structure (headings and metadata).\\n` +\n        `This rule's filename suggests it targets non-markdown files.\\n\\n` +\n        `Consider:\\n` +\n        `- Removing the \\`markdown:\\` frontmatter if this rule doesn't apply to .md files\\n` +\n        `- Renaming the rule to include \".md\" if it does target markdown files (e.g., \"*.md.md\")`;\n\n      await logger.logOutput({ warning: warningMessage });\n\n      return {\n        systemMessage: warningMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Case 2: Applies to .md files but doesn't have markdown frontmatter\n    if (isMdRule && !hasMarkdownFrontmatter) {\n      const encouragementMessage =\n        `💡 Rule file \"${filename}\" appears to target markdown files but doesn't have \\`markdown:\\` frontmatter.\\n\\n` +\n        `You can add markdown validation by including a \\`markdown:\\` section in the frontmatter:\\n\\n` +\n        `\\`\\`\\`yaml\\n` +\n        `---\\n` +\n        `markdown:\\n` +\n        `  headings:\\n` +\n        `    allowed: [\"#*\", \"##*\", \"###*\"]  # Allow h1, h2, h3\\n` +\n        `    required: [\"# *\"]               # Require title heading\\n` +\n        `  frontmatter:\\n` +\n        `    allowed: [\"*\"]                  # Allow any frontmatter fields\\n` +\n        `    required: [\"title\"]             # Require title field\\n` +\n        `---\\n` +\n        `\\`\\`\\`\\n\\n` +\n        `This enables automatic validation of markdown structure and frontmatter fields.`;\n\n      await logger.logOutput({ encouragement: encouragementMessage });\n\n      return {\n        systemMessage: encouragementMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // All good - either has appropriate frontmatter or doesn't need guidance\n    await logger.logOutput({ status: 'valid' });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation\n    return {\n      systemMessage: `Rules file validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/.claude-plugin/plugin.json": "{\n  \"name\": \"github-orchestration\",\n  \"version\": \"0.2.0\",\n  \"description\": \"Comprehensive GitHub workflow orchestration with skills for issues, branches, PRs, subissues, stacked PRs, and CI management\",\n  \"author\": {\n    \"name\": \"constellos\"\n  },\n  \"repository\": \"https://github.com/constellos/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"github\", \"orchestration\", \"workflow\", \"issues\", \"pr\", \"ci\", \"automation\"],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/github-orchestration/README.md": "![Version](https://img.shields.io/badge/version-0.2.0-blue?style=for-the-badge)\n![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)\n![GitHub](https://img.shields.io/badge/GitHub-CLI-black?style=for-the-badge&logo=github)\n\n# GitHub Orchestration Plugin\n\n> Comprehensive GitHub workflow orchestration with skills for issues, branches, PRs, subissues, stacked PRs, and CI management\n\n## Purpose\n\nProvides complete GitHub workflow automation for Claude Code sessions. Combines automatic hooks for session context with 6 specialized skills and a coordinating agent for complex multi-step workflows. Supports issue management, smart branch naming, hierarchical subissues, stacked PRs, CI orchestration, and PR lifecycle automation.\n\n## Contents\n\n### Hooks\n\n| Hook | Event | Purpose |\n|------|-------|---------|\n| install-github | SessionStart | Installs GitHub CLI on remote environments |\n| add-github-context | SessionStart | Displays linked issue, branch sync status, outstanding issues |\n| create-issue-on-prompt | UserPromptSubmit | Creates GitHub issue on first user prompt |\n| sync-plan-to-issue | PostToolUse[Write\\|Edit] | Creates/updates GitHub issues from plan files |\n| sync-task-to-subissue | PostToolUse[Task] | Creates GitHub subissues from Task prompts |\n| enhance-commit-context | PostToolUse[Bash] | Enriches git commits with task context |\n| await-pr-status | PostToolUse[Bash] | Waits for CI after `gh pr create` |\n| create-subagent-branch | SubagentStart | Creates isolated branch for stacked PR workflow |\n| stacked-pr-subagent-stop | SubagentStop | Handles stacked PR: push, create PR, auto-merge |\n| commit-task-await-ci-status | SubagentStop | Auto-commits subagent work, waits for CI |\n| commit-session-await-ci-status | Stop | Auto-commits session, reports CI status (blocking) |\n\n### Skills\n\n| Skill | Purpose |\n|-------|---------|\n| issue-management | Create, update, label, and link GitHub issues with templates |\n| branch-orchestration | Smart branch naming (`{issue}-{type}/{name}`), lifecycle management |\n| subissue-orchestration | Hierarchical issues with parent linking and auto-updated checklists |\n| stacked-pr-management | Create and manage dependent PR chains for large features |\n| ci-orchestration | CI/CD monitoring with fail-fast patterns and preview URL extraction |\n| pr-workflow | PR lifecycle with auto-generated descriptions from commits |\n\n### Agents\n\n| Agent | Purpose |\n|-------|---------|\n| github-orchestrator | Coordinates complex multi-step workflows across issues, branches, PRs, and CI |\n\n## Usage Examples\n\n### Create Issue with Template\n\n```bash\n# Using issue-management skill\ngh issue create \\\n  --title \"Safari auth failure\" \\\n  --label \"bug,priority:high\" \\\n  --body \"$(getBugTemplate | renderTemplate '{description: \"Auth fails on Safari 17.2\", ...}')\"\n```\n\n### Smart Branch Naming\n\n```bash\n# Using branch-orchestration skill\nBRANCH=$(generateBranchName 42 \"feature\" \"Add dark mode\")\n# Returns: \"42-feature/add-dark-mode\"\n\ngit checkout -b \"$BRANCH\"\ngit push -u origin \"$BRANCH\"\n```\n\n### Create Epic with Subissues\n\n```bash\n# Using subissue-orchestration skill\nPARENT=$(gh issue create --title \"Authentication System\" --label \"epic\" ...)\n\n# Create subissues\nfor task in \"OAuth\" \"Email auth\" \"Password reset\"; do\n  gh issue create --body \"**Parent Issue:** #$PARENT\" --title \"$task\"\ndone\n\n# Auto-update checklist\nsyncSubissueStates \"$PWD\" $PARENT\n```\n\n### Stacked PRs\n\n```bash\n# Using stacked-pr-management skill\n# Create PR chain: main → base → middleware → ui\ngh pr create --base main --head 42-feature/base\ngh pr create --base 42-feature/base --head 43-feature/middleware\ngh pr create --base 43-feature/middleware --head 44-feature/ui\n\n# Visualize stack\nvisualizeStack \"$(loadPRStack \"$PWD\")\"\n```\n\n### Automated Subagent Stacked PR Workflow\n\nWhen enabled, subagents automatically work on isolated branches with auto-PR creation:\n\n```\nMain Session (on main branch)\n├── Subagent spawned → isolated branch created\n├── Subagent makes edits locally\n├── SubagentStop → push, create PR, auto-merge\n├── Local changes REVERTED (main stays clean)\n├── CI passes → auto-merge completes\n└── Main agent pulls merged changes and continues\n```\n\n**Enable the workflow:**\n\n```bash\n# Option 1: Environment variable\nexport CLAUDE_STACKED_PR=true\n\n# Option 2: Session config (.claude/logs/session-config.json)\n{\n  \"stackedPrMode\": true,\n  \"stackedPrConfig\": {\n    \"waitForCI\": true,\n    \"waitForMerge\": true\n  }\n}\n\n# Option 3: Auto-detect (Phase 2)\n# Automatically enabled when current branch has an open PR\n```\n\n**Benefits:**\n- Main session stays on clean main branch\n- Subagent work is isolated in separate PRs\n- CI validates each piece independently\n- Failed subagent work doesn't pollute main session\n\n**Skipped agent types:** Explore, Plan (read-only agents)\n\n### CI Monitoring\n\n```bash\n# Using ci-orchestration skill\n# Wait for CI with fail-fast (10min timeout)\nawaitCIWithFailFast \"$PWD\" 42 10\n\n# Extract preview URLs\nURLS=$(extractPreviewUrls \"$(gh pr view 42 --json statusCheckRollup)\")\n```\n\n### Auto-Generated PR Descriptions\n\n```bash\n# Using pr-workflow skill\nCOMMITS=$(git log main..HEAD --oneline)\nISSUE=$(extractIssueNumber \"$(git branch --show-current)\")\nDESC=$(generatePRDescription \"$COMMITS\" \"$ISSUE\")\n\ngh pr create --body \"$DESC\"\n```\n\n### Orchestrate Complete Feature Flow\n\n```bash\n# Using github-orchestrator agent\n# 1. Create epic with subissues\n# 2. Create branches for each subissue\n# 3. Track progress with checklists\n# 4. Create PRs with auto-descriptions\n# 5. Monitor CI and extract previews\n# 6. Merge and close issues\n```\n\n## State Files\n\nThe plugin maintains workflow state in `.claude/logs/`:\n\n- `plan-issues.json` - Plan → Issue mapping\n- `branch-issues.json` - Branch → Issue mapping\n- `task-subissues.json` - Task → Subissue mapping\n- `pr-stack.json` - PR dependency chains\n- `stacked-branches.json` - Subagent branch isolation state\n- `session-config.json` - Session configuration (including stacked PR mode)\n- `session-stops.json` - Session stop state tracking\n- `task-calls.json` - Task tool context coordination\n\n## Branch Naming Convention\n\nFormat: `{issueNumber}-{workType}/{kebab-case-title}`\n\n**Work Types:** `feature` | `fix` | `chore` | `docs` | `refactor`\n\n**Examples:**\n- `42-feature/add-dark-mode`\n- `123-fix/safari-auth-bug`\n- `7-docs/update-readme`\n\n## Installation\n\n```bash\nclaude plugin install github-orchestration@constellos\n```\n\n## Migration from github-context\n\nThis plugin replaces `github-context` with expanded capabilities. All existing hooks remain unchanged. New skills and agent provide explicit control over workflows.\n\n**What's New in v0.2.0:**\n- 6 specialized skills for explicit GitHub operations\n- github-orchestrator agent for complex workflows\n- Extracted utilities (work-type-detector, branch-naming, issue-templates, pr-templates, pr-stack, subissue-checklist)\n- Support for stacked PRs\n- **Automated subagent stacked PR workflow** - Subagents work on isolated branches with auto-PR creation\n- Enhanced CI orchestration with preview URL extraction\n- Auto-generated PR descriptions from commits\n\n**Breaking Changes:** None - all hooks remain backward compatible\n\n## License\n\nMIT © constellos\n",
        "plugins/github-orchestration/agents/github-orchestrator.md": "---\ndescription: Use this agent for complex multi-step GitHub workflows involving issues, PRs, branches, and CI coordination. Triggers on \"orchestrate GitHub workflow\", \"automate PR process\", \"manage issue lifecycle\", \"coordinate stacked PRs\", \"full GitHub automation\", or any task requiring coordination across multiple GitHub operations.\nmodel: sonnet\ntools: [Read, Write, Edit, Glob, Grep, Bash, TodoWrite]\nskills: [github-orchestration:issue-management, github-orchestration:branch-orchestration, github-orchestration:subissue-orchestration, github-orchestration:stacked-pr-management, github-orchestration:ci-orchestration, github-orchestration:pr-workflow]\ncolor: \"#6E40C9\"\n---\n\n# GitHub Orchestrator Agent\n\nYou are a GitHub workflow automation specialist who coordinates complex multi-step operations across issues, branches, PRs, and CI/CD. You excel at breaking down large GitHub workflows into systematic, trackable steps.\n\n## Objective\n\nAutomate and orchestrate complex GitHub workflows that span multiple operations. Coordinate issue creation, branch management, PR workflows, and CI monitoring with intelligent state management and error recovery.\n\n## Core Principles\n\n### Workflow Planning\n- **Always use TodoWrite** to track multi-step workflows\n- Break complex operations into atomic, trackable steps\n- Check preconditions before proceeding (branch sync, no conflicts, etc.)\n- Provide clear progress updates at each step\n\n### State Management\n- Track workflow state in `.claude/logs/` files\n- Resume interrupted workflows from saved state\n- Validate state consistency before operations\n- Clean up state files after completion\n\n### Error Recovery\n- Fail fast on critical errors (merge conflicts, CI failures)\n- Provide actionable error messages with fix suggestions\n- Retry transient failures with exponential backoff\n- Never leave workflows in inconsistent states\n\n### Context Awareness\n- Auto-detect current context (branch, issue, session)\n- Use intelligent defaults from environment\n- Link related entities (branch ↔ issue ↔ PR)\n- Update GitHub issues with workflow progress\n\n## Available Skills\n\nYou have access to 6 specialized skills:\n\n### 1. Issue Management (`issue-management`)\n**Use for:** Creating, updating, labeling, and linking GitHub issues\n\n**Key Capabilities:**\n- Create issues with templates (bug/feature/epic/task)\n- Update metadata (labels, assignees, milestones)\n- Link issues (parent-child, related)\n- Search and filter issues\n- Detect work type from content\n\n**When to use:** Single issue operations, bulk issue creation, issue metadata updates\n\n### 2. Branch Orchestration (`branch-orchestration`)\n**Use for:** Smart branch naming, creation, and lifecycle management\n\n**Key Capabilities:**\n- Generate branch names: `{issueNum}-{workType}/{kebab-name}`\n- Create and rename branches with remote sync\n- Link branches to issues automatically\n- Clean up merged/stale branches\n- Validate naming conventions\n\n**When to use:** Branch creation with smart naming, branch-issue linking, cleanup operations\n\n### 3. Subissue Orchestration (`subissue-orchestration`)\n**Use for:** Hierarchical issue management with automated checklists\n\n**Key Capabilities:**\n- Create subissues with parent references\n- Generate and sync checklists in parent body\n- Bulk subissue creation\n- Auto-update checklist on subissue close\n- Visualize issue hierarchy\n\n**When to use:** Breaking down epics, tracking subtasks, managing complex features\n\n### 4. Stacked PR Management (`stacked-pr-management`)\n**Use for:** Managing dependent PR chains for large features\n\n**Key Capabilities:**\n- Create PR stacks with dependency tracking\n- Visualize stack as ASCII tree\n- Rebase entire stack on base changes\n- Merge stack in correct order\n- Validate stack (detect circular deps)\n\n**When to use:** Large features split across PRs, incremental review workflows\n\n### 5. CI Orchestration (`ci-orchestration`)\n**Use for:** CI/CD monitoring, preview URLs, and workflow management\n\n**Key Capabilities:**\n- Check CI status with fail-fast patterns\n- Extract preview URLs (Vercel, Netlify)\n- Wait for checks with timeout\n- Retry failed workflows\n- Debug CI failures with logs\n\n**When to use:** Waiting for CI, extracting deployments, debugging failures\n\n### 6. PR Workflow (`pr-workflow`)\n**Use for:** PR lifecycle with auto-generated descriptions\n\n**Key Capabilities:**\n- Generate descriptions from commits\n- Use templates by work type\n- Group commits by conventional type\n- Request reviews from CODEOWNERS\n- Manage PR metadata\n\n**When to use:** Creating PRs, updating metadata, managing review process\n\n## Common Workflow Patterns\n\n### Pattern 1: Feature Development Flow\n\nComplete end-to-end feature implementation:\n\n```markdown\n1. Create parent epic issue with subtask checklist\n2. Break into subissues for each component\n3. Create branch for each subissue with smart naming\n4. Track progress by updating checklist as work completes\n5. Create PRs with auto-generated descriptions\n6. Wait for CI and extract preview URLs\n7. Merge PRs and close issues\n```\n\n**Steps:**\n1. Use `issue-management` to create epic with `getEpicTemplate()`\n2. Use `subissue-orchestration` to create child issues\n3. Use `branch-orchestration` to create branches for each subissue\n4. Work on implementation (outside this workflow)\n5. Use `pr-workflow` to create PRs with auto descriptions\n6. Use `ci-orchestration` to wait for checks\n7. Merge and update issue states\n\n### Pattern 2: Stacked PR Creation\n\nSplit large feature into reviewable chunks:\n\n```markdown\n1. Identify logical breakpoints in feature\n2. Create branches for each part (base → middleware → UI)\n3. Create PR chain where each PR builds on previous\n4. Track dependencies in stack state file\n5. Monitor CI for each PR in stack\n6. Merge bottom-up when all checks pass\n7. Update dependent PRs as base merges\n```\n\n**Steps:**\n1. Use TodoWrite to list PR parts\n2. Use `branch-orchestration` to create branches\n3. Use `stacked-pr-management` to create PR chain\n4. Use `ci-orchestration` to check each PR\n5. Use `stacked-pr-management` to merge in order\n\n### Pattern 3: Issue Cleanup\n\nBulk operations on stale issues/branches:\n\n```markdown\n1. Search for stale issues (no activity > 30 days)\n2. Close issues with explanation comment\n3. Find branches for closed issues\n4. Delete branches if merged\n5. Update project boards\n6. Generate cleanup report\n```\n\n**Steps:**\n1. Use `issue-management` to search and filter\n2. Use Bash to close issues with comments\n3. Use `branch-orchestration` to find linked branches\n4. Use Git to delete merged branches\n5. Generate summary report\n\n### Pattern 4: Hotfix Workflow\n\nFast-track urgent bug fixes:\n\n```markdown\n1. Create high-priority bug issue\n2. Create fix/* branch from main\n3. Implement fix (outside workflow)\n4. Create PR with bugfix template\n5. Request expedited review\n6. Auto-merge when CI passes\n7. Backport to release branches\n```\n\n**Steps:**\n1. Use `issue-management` with `getBugTemplate()`\n2. Use `branch-orchestration` for fix branch\n3. Implement fix\n4. Use `pr-workflow` with `getBugfixPRTemplate()`\n5. Use `ci-orchestration` to wait for checks\n6. Enable auto-merge with `gh pr merge --auto`\n\n## Best Practices\n\n### Planning\n- Use TodoWrite at start of every complex workflow\n- Break workflows into 5-10 atomic steps maximum\n- Check prerequisites before starting (auth, permissions, sync)\n- Provide estimated time for long-running operations\n\n### Execution\n- Execute steps sequentially, mark complete after each\n- Validate state after each step before proceeding\n- Log progress to `.claude/logs/` for resumability\n- Update GitHub issues with workflow progress\n\n### Error Handling\n- Check for common errors: merge conflicts, failed CI, missing permissions\n- Provide actionable fix suggestions\n- Save state before risky operations\n- Never use destructive git commands (force push, hard reset) without confirmation\n\n### Communication\n- Start with workflow summary and step count\n- Update todos in real-time\n- Report completion with summary (issues created, PRs merged, etc.)\n- Link to all created/modified resources (issue URLs, PR URLs)\n\n## State Files\n\nTrack workflow state in these files:\n\n- `.claude/logs/plan-issues.json` - Plan → Issue mapping\n- `.claude/logs/branch-issues.json` - Branch → Issue mapping\n- `.claude/logs/task-subissues.json` - Task → Subissue mapping\n- `.claude/logs/pr-stack.json` - PR dependency chains\n- `.claude/logs/github-workflows.json` - Multi-step workflow tracking\n\n## Safety Checks\n\nBefore destructive operations, verify:\n\n1. **Branch deletion:** Check branch is merged and issue is closed\n2. **Force push:** Confirm with user, use --force-with-lease\n3. **Bulk operations:** Show preview, require confirmation for >10 items\n4. **PR merge:** Verify CI passed and required reviewers approved\n5. **Issue close:** Ensure all linked PRs are merged or closed\n\n## Example Orchestration\n\n**User request:** \"Set up the authentication feature with OAuth and email login\"\n\n**Your workflow:**\n\n1. **Plan** (TodoWrite):\n   - Create epic issue for authentication\n   - Create subissues for OAuth and email\n   - Create branches for each subissue\n   - Track implementation\n   - Create and merge PRs\n\n2. **Execute:**\n   ```bash\n   # Create epic\n   EPIC=$(gh issue create --title \"Authentication System\" ...)\n\n   # Create subissues\n   OAUTH=$(gh issue create --body \"Parent: #$EPIC\" ...)\n   EMAIL=$(gh issue create --body \"Parent: #$EPIC\" ...)\n\n   # Create branches\n   git checkout -b \"$EPIC-feature/auth-base\"\n   git checkout -b \"$OAUTH-feature/oauth\"\n   git checkout -b \"$EMAIL-feature/email\"\n\n   # Update checklist\n   syncSubissueStates \"$PWD\" $EPIC\n   ```\n\n3. **Report:**\n   - Epic created: #42\n   - Subissues created: #43 (OAuth), #44 (Email)\n   - Branches created: `42-feature/auth-base`, `43-feature/oauth`, `44-feature/email`\n   - Next steps: Implement features, create PRs\n\n## When NOT to Use This Agent\n\nUse individual skills directly for simple operations:\n\n- Creating a single issue → Use `issue-management` skill\n- Creating a single branch → Use `branch-orchestration` skill\n- Checking CI on one PR → Use `ci-orchestration` skill\n- Creating one PR → Use `pr-workflow` skill\n\nUse this agent when:\n- Workflow spans 3+ operations\n- Operations depend on each other (issue → branch → PR)\n- Need state management across steps\n- Require error recovery and rollback\n- Bulk operations (10+ issues/PRs)\n\n## Remember\n\nYou are the orchestrator, not the implementer. Your job is to:\n- Plan and coordinate GitHub operations\n- Track progress with todos\n- Handle errors gracefully\n- Update state files\n- Link entities together\n- Report status clearly\n\nYou do NOT:\n- Write application code (that's for other agents)\n- Make architectural decisions\n- Review code quality\n- Design features\n\nStay focused on GitHub workflow automation and let other agents handle their specialties.\n",
        "plugins/github-orchestration/hooks/add-github-context.ts": "/**\n * Branch context and issue discovery hook\n *\n * SessionStart hook that displays concise context about the current branch's work.\n * Shows linked issue summary with link (not full content) to minimize context injection.\n *\n * This hook provides:\n * - **Concise linked issue display** - Shows issue number, title, and link (NOT full body/comments)\n * - **Outstanding issue awareness** - Lists titles of open issues not linked to any branch\n * - **Context discovery** - Cascading search through state file, GitHub search, and issue body markers\n * - **Non-blocking** - All errors are gracefully handled without stopping session start\n *\n * Issue-to-branch linking is discovered from:\n * 1. `.claude/logs/plan-issues.json` state file (primary source)\n * 2. GitHub search by branch name (fallback)\n * 3. Issue body `**Branch:** \\`name\\`` markers (last resort)\n *\n * @module add-github-context\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findRelatedIssues, cleanupOldSessions } from '../shared/hooks/utils/session-issues.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\ninterface PlanIssueState {\n  [sessionId: string]: {\n    planPath: string;\n    issueNumber: number;\n    issueUrl: string;\n    branch: string;\n    createdAt: string;\n    lastUpdated: string;\n  };\n}\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\ninterface GitHubIssue {\n  number: number;\n  title: string;\n  body: string;\n  comments?: Array<{\n    author: { login: string };\n    body: string;\n    createdAt: string;\n  }>;\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if branch is synced with remote tracking branch\n */\nasync function checkRemoteSync(cwd: string): Promise<string> {\n  // Check if has upstream\n  const hasUpstream = await execCommand('git rev-parse --abbrev-ref @{u}', cwd);\n  if (!hasUpstream.success) {\n    return '⚠️ No remote tracking branch configured';\n  }\n\n  // Compare with upstream\n  const counts = await execCommand('git rev-list --left-right --count @{u}...HEAD', cwd);\n  if (!counts.success) {\n    return 'ℹ️ Unable to determine sync status';\n  }\n\n  const [behind, ahead] = counts.stdout.split('\\t').map(Number);\n\n  if (behind === 0 && ahead === 0) {\n    return `✅ Up to date with remote`;\n  } else if (behind > 0 && ahead === 0) {\n    return `⚠️ ${behind} commit${behind > 1 ? 's' : ''} behind remote`;\n  } else if (behind === 0 && ahead > 0) {\n    return `ℹ️ ${ahead} commit${ahead > 1 ? 's' : ''} ahead of remote (unpushed)`;\n  } else {\n    return `⚠️ ${behind} behind, ${ahead} ahead of remote (diverged)`;\n  }\n}\n\n/**\n * Check if branch is synced with origin/main\n */\nasync function checkMainSync(cwd: string): Promise<string> {\n  const counts = await execCommand('git rev-list --left-right --count origin/main...HEAD', cwd);\n  if (!counts.success) {\n    return 'ℹ️ Unable to check main sync (is origin/main fetched?)';\n  }\n\n  const [behind, ahead] = counts.stdout.split('\\t').map(Number);\n\n  if (behind === 0 && ahead === 0) {\n    return `✅ In sync with origin/main`;\n  } else if (behind > 0 && ahead === 0) {\n    return `ℹ️ ${behind} commit${behind > 1 ? 's' : ''} behind origin/main`;\n  } else if (behind === 0 && ahead > 0) {\n    return `ℹ️ ${ahead} commit${ahead > 1 ? 's' : ''} ahead of origin/main`;\n  } else {\n    return `ℹ️ ${behind} behind, ${ahead} ahead of origin/main`;\n  }\n}\n\n/**\n * Load plan issue state from disk\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Load branch issue state from disk\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Fetch full issue details from GitHub\n */\nasync function fetchFullIssue(issueNumber: number, cwd: string): Promise<GitHubIssue | null> {\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json number,title,body,comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return null;\n  }\n\n  try {\n    return JSON.parse(result.stdout);\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Find issue linked to current branch using cascading fallback strategy\n *\n * Strategy:\n * 1. Check branch-issues.json state file (by branch name - from UserPromptSubmit hook)\n * 2. Check plan-issues.json state file (by session ID and branch name)\n * 3. Search GitHub using branch name\n * 4. Scan issue bodies for \"Branch: `name`\" marker\n */\nasync function findBranchIssue(\n  branch: string,\n  cwd: string,\n  sessionId: string\n): Promise<{ issueNumber: number; fullIssue: GitHubIssue } | null> {\n  // STRATEGY 1: Check branch-issues.json state file (from UserPromptSubmit hook)\n  const branchState = await loadBranchIssueState(cwd);\n  if (branchState[branch]) {\n    const fullIssue = await fetchFullIssue(branchState[branch].issueNumber, cwd);\n    if (fullIssue) {\n      return { issueNumber: branchState[branch].issueNumber, fullIssue };\n    }\n  }\n\n  // STRATEGY 2: Check plan-issues.json state file\n  const state = await loadPlanIssueState(cwd);\n\n  // Find by session ID\n  if (state[sessionId]?.branch === branch) {\n    const fullIssue = await fetchFullIssue(state[sessionId].issueNumber, cwd);\n    if (fullIssue) {\n      return { issueNumber: state[sessionId].issueNumber, fullIssue };\n    }\n  }\n\n  // Find by branch name across all sessions\n  for (const sessionState of Object.values(state)) {\n    if (sessionState.branch === branch) {\n      const fullIssue = await fetchFullIssue(sessionState.issueNumber, cwd);\n      if (fullIssue) {\n        return { issueNumber: sessionState.issueNumber, fullIssue };\n      }\n    }\n  }\n\n  // STRATEGY 2: Search GitHub using gh CLI\n  const searchResult = await execCommand(\n    `gh issue list --search \"in:body branch:${branch}\" --json number,title,body,comments --limit 1`,\n    cwd\n  );\n\n  if (searchResult.success && searchResult.stdout) {\n    try {\n      const issues = JSON.parse(searchResult.stdout);\n      if (issues.length > 0) {\n        return { issueNumber: issues[0].number, fullIssue: issues[0] };\n      }\n    } catch {\n      // JSON parse failed, continue to next strategy\n    }\n  }\n\n  // STRATEGY 3: Check issue body for \"Branch: `name`\" marker\n  const allIssuesResult = await execCommand(\n    'gh issue list --state open --json number,body --limit 50',\n    cwd\n  );\n\n  if (allIssuesResult.success) {\n    try {\n      const issues = JSON.parse(allIssuesResult.stdout);\n      const branchMarker = `**Branch:** \\`${branch}\\``;\n\n      for (const issue of issues) {\n        if (issue.body?.includes(branchMarker)) {\n          const fullIssue = await fetchFullIssue(issue.number, cwd);\n          if (fullIssue) {\n            return { issueNumber: issue.number, fullIssue };\n          }\n        }\n      }\n    } catch {\n      // JSON parse failed\n    }\n  }\n\n  return null;\n}\n\n/**\n * Find all open issues NOT linked to existing branches\n */\nasync function findUnlinkedIssues(\n  cwd: string\n): Promise<Array<{ number: number; title: string }>> {\n  // Get all branches (local and remote)\n  const branchesResult = await execCommand('git branch -a --format=\"%(refname:short)\"', cwd);\n\n  if (!branchesResult.success) {\n    return [];\n  }\n\n  const branches = new Set(\n    branchesResult.stdout\n      .split('\\n')\n      .map((b) => b.trim().replace(/^origin\\//, ''))\n      .filter(Boolean)\n  );\n\n  // Get all open issues\n  const issuesResult = await execCommand(\n    'gh issue list --state open --json number,title,body,labels --limit 100',\n    cwd\n  );\n\n  if (!issuesResult.success) {\n    return [];\n  }\n\n  try {\n    const allIssues = JSON.parse(issuesResult.stdout);\n    const unlinkedIssues: Array<{ number: number; title: string }> = [];\n\n    // Load state file to check for linked issues\n    const state = await loadPlanIssueState(cwd);\n    const linkedIssueNumbers = new Set(\n      Object.values(state).map((s) => s.issueNumber)\n    );\n\n    for (const issue of allIssues) {\n      let isLinked = false;\n\n      // Check if issue is in state file\n      if (linkedIssueNumbers.has(issue.number)) {\n        isLinked = true;\n      }\n\n      // Check if issue body contains a branch reference\n      if (!isLinked && issue.body) {\n        const branchMatch = issue.body.match(/\\*\\*Branch:\\*\\*\\s+`([^`]+)`/);\n        if (branchMatch && branches.has(branchMatch[1])) {\n          isLinked = true;\n        }\n      }\n\n      if (!isLinked) {\n        unlinkedIssues.push({\n          number: issue.number,\n          title: issue.title,\n        });\n      }\n    }\n\n    return unlinkedIssues;\n  } catch {\n    return [];\n  }\n}\n\n/**\n * SessionStart hook handler\n *\n * Executes at session start to display context about current branch work and\n * outstanding issues.\n *\n * @param input - SessionStart hook input from Claude Code\n * @returns Hook output with formatted issue context\n *\n * @example\n * ```typescript\n * // This hook is automatically called by Claude Code when a new session starts\n * ```\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'add-branch-context', true);\n\n  try {\n    // Clean up old sessions (30 days retention) - non-blocking\n    cleanupOldSessions(input.cwd, 30).catch(() => {\n      // Ignore errors - this is best-effort cleanup\n    });\n\n    // Check if we're in a git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', input.cwd);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n    }\n\n    // Check if gh CLI is authenticated\n    const ghCheck = await execCommand('gh auth status', input.cwd);\n    if (!ghCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'gh CLI not authenticated' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '⚠ GitHub CLI not authenticated. Run: gh auth login',\n        },\n      };\n    }\n\n    // Get current branch\n    const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', input.cwd);\n    const currentBranch = branchResult.stdout;\n\n    if (!currentBranch || currentBranch === 'HEAD') {\n      // Detached HEAD state\n      await logger.logOutput({ skipped: true, reason: 'Detached HEAD' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      current_branch: currentBranch,\n    });\n\n    // Check branch sync status\n    const remoteSync = await checkRemoteSync(input.cwd);\n    const mainSync = await checkMainSync(input.cwd);\n\n    // Find linked issue for current branch\n    const branchIssue = await findBranchIssue(currentBranch, input.cwd, input.session_id);\n\n    // Find unlinked issues\n    const unlinkedIssues = await findUnlinkedIssues(input.cwd);\n\n    // Format output\n    const sections: string[] = [];\n\n    // Section 1: Current branch issue (FULL content)\n    sections.push('## Current Branch Work');\n    sections.push('');\n    sections.push(`**Branch:** \\`${currentBranch}\\``);\n    sections.push('');\n    sections.push('📊 **Sync Status:**');\n    sections.push(`- Remote: ${remoteSync}`);\n    sections.push(`- Main: ${mainSync}`);\n\n    if (branchIssue?.fullIssue) {\n      // Concise issue summary - link to full content instead of injecting it\n      const repoResult = await execCommand('gh repo view --json nameWithOwner -q .nameWithOwner', input.cwd);\n      const repoName = repoResult.success ? repoResult.stdout : '';\n      const issueUrl = repoName\n        ? `https://github.com/${repoName}/issues/${branchIssue.issueNumber}`\n        : `#${branchIssue.issueNumber}`;\n\n      sections.push(`**Issue:** [#${branchIssue.issueNumber} - ${branchIssue.fullIssue.title}](${issueUrl})`);\n      const commentCount = branchIssue.fullIssue.comments?.length || 0;\n      if (commentCount > 0) {\n        sections.push(`💬 ${commentCount} comment${commentCount > 1 ? 's' : ''}`);\n      }\n    } else {\n      sections.push('**Issue:** No linked issue found');\n      sections.push('');\n      sections.push('💡 An issue will be created automatically on your first prompt.');\n      sections.push('');\n      sections.push('**To link to an existing issue instead:**');\n      sections.push('1. Rename branch with issue prefix: `git branch -m ' + currentBranch + ' <issue#>-' + currentBranch + '`');\n      sections.push('2. Example: `git branch -m ' + currentBranch + ' 42-' + currentBranch + '`');\n      sections.push('3. The hook will detect the issue number prefix and link automatically');\n    }\n\n    // Section 1.5: Related issues from previous sessions\n    const repoResult = await execCommand(\n      'gh repo view --json nameWithOwner -q .nameWithOwner',\n      input.cwd\n    );\n    const currentRepo = repoResult.success ? repoResult.stdout : '';\n\n    if (currentRepo) {\n      const relatedIssues = await findRelatedIssues(\n        currentBranch,\n        currentRepo,\n        input.session_id,\n        input.cwd\n      );\n\n      if (relatedIssues.length > 0) {\n        sections.push('');\n        sections.push('---');\n        sections.push('');\n        sections.push('## Related Issues from Previous Sessions');\n        sections.push('');\n\n        // Group by relevance\n        const highPriority = relatedIssues.filter((i) => i.relevance === 'high');\n        const mediumPriority = relatedIssues.filter((i) => i.relevance === 'medium');\n\n        if (highPriority.length > 0) {\n          sections.push('📌 **High Priority** (Same branch family)');\n          for (const issue of highPriority.slice(0, 3)) {\n            sections.push(`- [#${issue.number} - ${issue.title}](${issue.url})`);\n            sections.push(`  ${issue.reason} • ${issue.sessionAge}`);\n          }\n          sections.push('');\n        }\n\n        if (mediumPriority.length > 0) {\n          sections.push('📋 **Same Repository** (Recent work)');\n          for (const issue of mediumPriority.slice(0, 3)) {\n            sections.push(`- [#${issue.number} - ${issue.title}](${issue.url})`);\n            sections.push(`  Created ${issue.sessionAge}`);\n          }\n          sections.push('');\n        }\n\n        sections.push('💡 These issues were created in previous sessions working on related code.');\n      }\n    }\n\n    // Section 2: Outstanding issues (TITLES only)\n    if (unlinkedIssues.length > 0) {\n      sections.push('');\n      sections.push('---');\n      sections.push('');\n      sections.push('## Outstanding Issues (Not Linked to Branches)');\n      sections.push('');\n      for (const issue of unlinkedIssues) {\n        sections.push(`- #${issue.number}: ${issue.title}`);\n      }\n      sections.push('');\n      sections.push('💡 These issues are available for work. Create a branch to link one.');\n    }\n\n    await logger.logOutput({\n      branch: currentBranch,\n      linked_issue: branchIssue?.issueNumber,\n      unlinked_issues_count: unlinkedIssues.length,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: sections.join('\\n'),\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking - just log error\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `⚠ Could not fetch branch context: ${error instanceof Error ? error.message : String(error)}`,\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/await-pr-status.ts": "/**\n * Await PR checks after PR creation\n *\n * PostToolUse[Bash] hook that detects `gh pr create` commands and automatically\n * waits for CI checks to complete on the newly created PR.\n *\n * **What it does:**\n * - Detects when a PR is created via `gh pr create`\n * - Extracts PR number from the output URL\n * - Waits for all CI checks to complete (10-minute timeout)\n * - Reports CI status and preview URLs\n * - Blocks if CI fails, approves if CI passes\n *\n * **Non-blocking:** This hook is informational only and does not block execution.\n *\n * @module await-pr-checks\n */\n\nimport type {\n  PostToolUseInput,\n  PostToolUseHookOutput,\n} from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport {\n  saveOutputToLog,\n  formatCiChecksTable,\n} from '../shared/hooks/utils/log-file.js';\nimport {\n  awaitCIWithFailFast,\n  getLatestCIRun,\n  extractAllPreviews,\n  extractLinkedIssuesFromPR,\n  formatGroupedPreviews,\n} from '../shared/hooks/utils/ci-status.js';\nimport { addPRToState } from '../shared/hooks/utils/github-state.js';\n\n// Local CI functions removed - using shared utilities from ci-status.ts\n\n/**\n * Extract PR number from gh pr create output\n *\n * @param output - Command output containing PR URL\n * @returns PR number or null\n */\nfunction extractPRNumber(output: string): number | null {\n  // Look for PR URL pattern: https://github.com/owner/repo/pull/123\n  const match = output.match(/github\\.com\\/[^/]+\\/[^/]+\\/pull\\/(\\d+)/);\n  return match ? parseInt(match[1], 10) : null;\n}\n\n/**\n * PostToolUse hook handler for awaiting PR checks\n *\n * Detects `gh pr create` commands and waits for CI checks to complete.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with CI status as additional context\n */\nasync function handler(\n  input: PostToolUseInput\n): Promise<PostToolUseHookOutput> {\n  // Only run for Bash tool\n  if (input.tool_name !== 'Bash') {\n    return {};\n  }\n\n  const logger = createDebugLogger(input.cwd, 'await-pr-checks', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Get the bash command from tool input\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput?.command || '';\n\n    // Only run for gh pr create commands\n    if (!command.includes('gh pr create') && !command.includes('gh pr')) {\n      return {};\n    }\n\n    // Get the tool response to extract PR number\n    const toolResponse = input.tool_response as { content?: Array<{ text?: string }> };\n    const resultText = toolResponse?.content?.[0]?.text || '';\n\n    // Extract PR number from output\n    const prNumber = extractPRNumber(resultText);\n\n    if (!prNumber) {\n      await logger.logOutput({\n        success: false,\n        reason: 'Could not extract PR number from output',\n      });\n      return {};\n    }\n\n    await logger.logOutput({\n      success: true,\n      pr_number: prNumber,\n      message: 'PR created, waiting for CI checks...',\n    });\n\n    // Wait for CI checks with fail-fast behavior\n    const ciResult = await awaitCIWithFailFast({ prNumber }, input.cwd);\n\n    // Get latest CI run details, preview URLs, and linked issues in parallel\n    const [ciRun, groupedPreviews, linkedIssues] = await Promise.all([\n      getLatestCIRun(prNumber, input.cwd),\n      extractAllPreviews(prNumber, input.cwd),\n      extractLinkedIssuesFromPR(prNumber, input.cwd),\n    ]);\n\n    // Extract PR URL from original command output\n    const prUrlMatch = resultText.match(/https:\\/\\/github\\.com\\/[^/]+\\/[^/]+\\/pull\\/\\d+/);\n    const prUrl = prUrlMatch ? prUrlMatch[0] : `https://github.com/unknown/unknown/pull/${prNumber}`;\n\n    // Track PR in github.json\n    await addPRToState(\n      input.session_id,\n      {\n        number: prNumber,\n        url: prUrl,\n        title: '', // Title not available from gh pr create output\n        createdAt: new Date().toISOString(),\n        linkedIssues,\n      },\n      input.cwd\n    );\n\n    // Save full CI output to log file if there are checks\n    let logPath: string | undefined;\n    if (ciResult.checks.length > 0) {\n      const checksOutput = ciResult.checks.map(c => `${c.emoji} ${c.name}: ${c.status}`).join('\\n');\n      logPath = await saveOutputToLog(input.cwd, 'ci', `pr-${prNumber}`, checksOutput);\n    }\n\n    // Map ci-status CheckStatus to log-file format for table\n    const mappedChecks = ciResult.checks.map(c => ({\n      name: c.name,\n      status: (c.status === 'success' ? 'pass' :\n               c.status === 'failure' ? 'fail' :\n               c.status === 'cancelled' ? 'skipped' : 'pending') as 'pass' | 'fail' | 'pending' | 'skipped',\n      duration: '',\n    }));\n    const checksTable = formatCiChecksTable(mappedChecks, logPath);\n\n    // Build concise status message\n    let statusMessage = `**PR #${prNumber}**\\n`;\n\n    if (ciResult.success) {\n      statusMessage += `✅ All CI checks passed\\n`;\n    } else if (ciResult.blockReason) {\n      statusMessage += `${ciResult.blockReason}\\n`;\n    } else if (ciResult.error) {\n      statusMessage += `⏱️ ${ciResult.error}\\n`;\n    } else {\n      statusMessage += `❌ CI checks failed\\n`;\n    }\n\n    // Add emoji status table\n    if (checksTable) {\n      statusMessage += `\\n${checksTable}\\n`;\n    }\n\n    // Add CI run link\n    if (ciRun?.url) {\n      statusMessage += `\\n🔗 [CI Run](${ciRun.url})`;\n    }\n\n    // Add all preview URLs grouped by provider\n    const previewSection = formatGroupedPreviews(groupedPreviews);\n    if (previewSection) {\n      statusMessage += previewSection;\n    }\n\n    await logger.logOutput({\n      success: ciResult.success,\n      ci_status: ciRun?.status,\n      vercel_urls: groupedPreviews.vercel,\n      cloudflare_urls: groupedPreviews.cloudflare,\n      supabase_urls: groupedPreviews.supabase,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: statusMessage,\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with npx tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/close-issue-on-session-end.ts": "/**\n * SessionEnd hook to close linked GitHub issues when session ends without PR\n *\n * This hook:\n * 1. Checks if current branch has a linked GitHub issue\n * 2. Checks if a PR exists for the branch\n * 3. If no PR, closes the issue with explanatory comment\n *\n * Non-blocking - fires after session ends, no output needed.\n * @module close-issue-on-session-end\n */\n\nimport type { SessionEndInput, SessionEndHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getLinkedIssueNumber } from '../shared/hooks/utils/github-comments.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst execAsync = promisify(exec);\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command and return the result\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n// ============================================================================\n// Git Operations\n// ============================================================================\n\n/**\n * Get git repository root directory\n */\nasync function getRepoRoot(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --show-toplevel', cwd);\n  return result.success ? result.stdout : cwd;\n}\n\n/**\n * Get current git branch name\n */\nasync function getCurrentBranch(cwd: string): Promise<string | null> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : null;\n}\n\n// ============================================================================\n// Branch Issue State\n// ============================================================================\n\n/**\n * Load branch issue state from disk\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    if (!existsSync(stateFile)) {\n      return {};\n    }\n    const data = readFileSync(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Get issue info for a branch from branch-issues.json\n */\nasync function getBranchIssueInfo(\n  branch: string,\n  cwd: string\n): Promise<{ issueNumber: number; issueUrl: string } | null> {\n  const state = await loadBranchIssueState(cwd);\n  if (state[branch]) {\n    return {\n      issueNumber: state[branch].issueNumber,\n      issueUrl: state[branch].issueUrl,\n    };\n  }\n  return null;\n}\n\n// ============================================================================\n// GitHub CLI Operations\n// ============================================================================\n\n/**\n * Check if a PR exists for the current branch\n */\nasync function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<{ exists: boolean; prNumber?: number; error?: string }> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return { exists: false, error: 'GitHub CLI not installed' };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return { exists: false, error: 'GitHub CLI not authenticated' };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return { exists: false, error: `gh pr list failed: ${prListResult.stderr}` };\n  }\n\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n    if (Array.isArray(prs) && prs.length > 0) {\n      return { exists: true, prNumber: prs[0].number };\n    }\n    return { exists: false };\n  } catch {\n    return { exists: false, error: 'Failed to parse gh output' };\n  }\n}\n\n/**\n * Close a GitHub issue with a session end comment\n */\nasync function closeIssueWithComment(\n  issueNumber: number,\n  sessionId: string,\n  reason: string,\n  cwd: string\n): Promise<{ success: boolean; error?: string }> {\n  const reasonMap: Record<string, string> = {\n    'clear': 'Session was cleared',\n    'logout': 'User logged out',\n    'prompt_input_exit': 'User exited session',\n    'other': 'Session ended',\n  };\n\n  const reasonText = reasonMap[reason] || 'Session ended';\n  const timestamp = new Date().toISOString();\n\n  const comment = `## Session Closed - No PR Created\n\n**Session ID:** \\`${sessionId}\\`\n**Reason:** ${reasonText}\n**Closed at:** ${timestamp}\n\nThis issue was automatically closed because the session ended without creating a pull request.\n\nReopen this issue to continue work.\n\n---\n*Closed automatically via SessionEnd hook*`;\n\n  // Close the issue with comment\n  const closeResult = await execCommand(\n    `gh issue close ${issueNumber} --comment ${JSON.stringify(comment)}`,\n    cwd\n  );\n\n  if (!closeResult.success) {\n    return { success: false, error: closeResult.stderr };\n  }\n\n  return { success: true };\n}\n\n// ============================================================================\n// Main Handler\n// ============================================================================\n\n/**\n * SessionEnd hook handler\n *\n * Closes linked GitHub issues when session ends without a PR.\n * Non-blocking - always returns empty output.\n */\nasync function handler(input: SessionEndInput): Promise<SessionEndHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'close-issue-on-session-end', true);\n\n  try {\n    await logger.logInput({ session_id: input.session_id, reason: input.reason });\n\n    // Normalize to repo root\n    const repoRoot = await getRepoRoot(input.cwd);\n\n    // Check if in git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', repoRoot);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {};\n    }\n\n    // Get current branch\n    const currentBranch = await getCurrentBranch(repoRoot);\n    const mainBranches = ['main', 'master', 'develop'];\n    if (!currentBranch || mainBranches.includes(currentBranch)) {\n      await logger.logOutput({ skipped: true, reason: 'On main branch or no branch' });\n      return {};\n    }\n\n    // Get linked issue from branch-issues.json\n    let issueNumber: number | null = null;\n    const branchIssueInfo = await getBranchIssueInfo(currentBranch, repoRoot);\n    if (branchIssueInfo) {\n      issueNumber = branchIssueInfo.issueNumber;\n    } else {\n      // Fallback: try to discover via github-comments utility\n      issueNumber = await getLinkedIssueNumber(currentBranch, repoRoot);\n    }\n\n    if (!issueNumber) {\n      await logger.logOutput({ skipped: true, reason: 'No linked issue found' });\n      return {};\n    }\n\n    // Check if PR exists\n    const prCheck = await checkPRExists(currentBranch, repoRoot);\n    if (prCheck.exists) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'PR exists',\n        prNumber: prCheck.prNumber,\n      });\n      return {};\n    }\n\n    // No PR - close the issue with comment\n    const closeResult = await closeIssueWithComment(\n      issueNumber,\n      input.session_id,\n      input.reason,\n      repoRoot\n    );\n\n    await logger.logOutput({\n      closed: closeResult.success,\n      issueNumber,\n      reason: input.reason,\n      error: closeResult.error,\n    });\n\n    return {};\n  } catch (error) {\n    await logger.logError(error as Error);\n    return {}; // Non-blocking - always return empty\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/commit-session-await-ci-status.ts": "/**\n * Unified Stop hook: Auto-commit, PR status check, CI waiting, and agent communication\n *\n * This hook performs four main functions at session end:\n *\n * 1. **Blocking validation checks** - Ensures clean git state:\n * - Merge conflicts detection\n * - Branch sync status (behind remote)\n * - Claude settings validation\n * - Hook file existence checks\n *\n * 2. **Auto-commit** - Preserves work in progress:\n * - Automatically commits any uncommitted changes\n * - Adds session metadata to commit message\n * - Tracks commit SHA for one-time blocking\n *\n * 3. **Agent communication** - First-time blocking on new commits:\n * - Blocks ONCE when new commits are detected without a PR\n * - Tracks lastSeenCommitSha to only block on first sight of commits\n * - Subsequent stops show informational message but don't block\n * - Resets when PR created or progress documented via comment\n *\n * 4. **PR status reporting and CI waiting** - Provides PR visibility and ensures quality:\n * - Checks if PR exists for current branch\n * - **Waits for all CI checks to complete** (including Vercel, Supabase integrations)\n * - **Blocks if any CI check fails** (10-minute timeout)\n * - Fetches latest CI run status and link\n * - Extracts Vercel preview URLs (web and marketing apps)\n * - Detects subagent activity to skip instructions intelligently\n *\n * **Session state tracking:**\n * - State stored in `.claude/logs/session-stops.json`\n * - Tracks block count per session\n * - Tracks whether progress has been documented\n *\n * **GitHub comment integration:**\n * - Detects comments with session ID markers\n * - Discovers linked issues from branch context\n * - Accepts progress documentation as alternative to PR\n * @module commit-session-await-status\n */\n\nimport type { StopInput, StopHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getSessionStopState, updateSessionStopState, resetSessionStopState } from '../shared/hooks/utils/session-state.js';\nimport { hasCommentForSession, getLinkedIssueNumber } from '../shared/hooks/utils/github-comments.js';\nimport {\n  saveOutputToLog,\n  formatCiChecksTable,\n} from '../shared/hooks/utils/log-file.js';\nimport {\n  awaitCIWithFailFast,\n  getLatestCIRun as getCIRunDetails,\n  extractAllPreviews,\n  extractLinkedIssuesWithInfo,\n  type GroupedPreviewUrls,\n  type LinkedIssueInfo,\n} from '../shared/hooks/utils/ci-status.js';\nimport { getSessionIssues, type IssueReference } from '../shared/hooks/utils/session-issues.js';\nimport { addPRToState } from '../shared/hooks/utils/github-state.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst execAsync = promisify(exec);\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\n/**\n * Load branch issue state from disk\n * @param cwd - Working directory\n * @returns Branch issue state object\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    if (!existsSync(stateFile)) {\n      return {};\n    }\n    const data = readFileSync(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Get issue info for a branch from branch-issues.json\n * @param branch - Branch name\n * @param cwd - Working directory\n * @returns Issue info or null\n */\nasync function getBranchIssueInfo(\n  branch: string,\n  cwd: string\n): Promise<{ issueNumber: number; issueUrl: string } | null> {\n  const state = await loadBranchIssueState(cwd);\n  if (state[branch]) {\n    return {\n      issueNumber: state[branch].issueNumber,\n      issueUrl: state[branch].issueUrl,\n    };\n  }\n  return null;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command and return the result\n * @param command - Shell command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n// ============================================================================\n// Git State Checks\n// ============================================================================\n\n/**\n * Check if there are uncommitted changes in the working directory\n * Filters out gitignored files - only returns true for tracked/untracked non-ignored files\n * @param cwd - Working directory\n * @returns True if there are non-gitignored uncommitted changes\n * @example\n */\nasync function hasUncommittedChanges(cwd: string): Promise<boolean> {\n  const result = await execCommand('git status --porcelain', cwd);\n  if (!result.success || !result.stdout) {\n    return false;\n  }\n\n  // Filter out gitignored files\n  const lines = result.stdout.split('\\n').filter(Boolean);\n  for (const line of lines) {\n    // Git porcelain format: XY<space>filename (XY = 2 status chars)\n    // But stdout.trim() may have removed a leading space from \" M filename\"\n    // Detect by checking if position 2 is a space (not trimmed) or not (trimmed)\n    const pathStart = (line.length >= 3 && line[2] === ' ') ? 3 : 2;\n    const filePath = line.slice(pathStart).split(' -> ')[0];\n\n    // Check if file is gitignored\n    const ignoreCheck = await execCommand(`git check-ignore -q \"${filePath}\"`, cwd);\n    if (!ignoreCheck.success) {\n      // File is NOT ignored - we have real uncommitted changes\n      return true;\n    }\n  }\n\n  // All files were gitignored\n  return false;\n}\n\n/**\n * Get list of non-gitignored uncommitted files for staging\n * @param cwd - Working directory\n * @returns List of file paths to stage\n * @example\n */\nasync function getNonIgnoredChanges(cwd: string): Promise<string[]> {\n  const result = await execCommand('git status --porcelain', cwd);\n  if (!result.success || !result.stdout) {\n    return [];\n  }\n\n  const nonIgnoredFiles: string[] = [];\n  const lines = result.stdout.split('\\n').filter(Boolean);\n\n  for (const line of lines) {\n    // Git porcelain format: XY<space>filename (XY = 2 status chars)\n    // But stdout.trim() may have removed a leading space from \" M filename\"\n    // Detect by checking if position 2 is a space (not trimmed) or not (trimmed)\n    const pathStart = (line.length >= 3 && line[2] === ' ') ? 3 : 2;\n    const filePath = line.slice(pathStart).split(' -> ')[0];\n    const ignoreCheck = await execCommand(`git check-ignore -q \"${filePath}\"`, cwd);\n    if (!ignoreCheck.success) {\n      nonIgnoredFiles.push(filePath);\n    }\n  }\n\n  return nonIgnoredFiles;\n}\n\n/**\n * Get current git branch name\n * @param cwd - Working directory\n * @returns Branch name or null if detached HEAD\n * @example\n */\nasync function getCurrentBranch(cwd: string): Promise<string | null> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : null;\n}\n\n/**\n * Get current HEAD commit SHA\n * @param cwd - Working directory\n * @returns Full commit SHA or null if not in git repo\n * @example\n */\nasync function getCurrentHeadSha(cwd: string): Promise<string | null> {\n  const result = await execCommand('git rev-parse HEAD', cwd);\n  return result.success ? result.stdout : null;\n}\n\n/**\n * Get git repository root directory\n * Normalizes cwd to repo root to ensure git commands work correctly\n * even when hook is invoked from a subdirectory (e.g., subagent in apps/web/)\n * @param cwd - Working directory (may be subdirectory)\n * @returns Repository root path, or original cwd if not in a git repo\n * @example\n */\nasync function getRepoRoot(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --show-toplevel', cwd);\n  return result.success ? result.stdout : cwd;\n}\n\n/**\n * Check if there are merge conflicts in the working directory\n * @param cwd - Working directory\n * @returns Object with conflict status and list of conflicted files\n * @example\n */\nasync function checkMergeConflicts(cwd: string): Promise<{\n  hasConflicts: boolean;\n  conflictedFiles: string[];\n}> {\n  // Check git status for unmerged paths\n  const unmergedResult = await execCommand('git ls-files --unmerged', cwd);\n  const hasUnmerged = unmergedResult.stdout.length > 0;\n\n  // Get list of conflicted files\n  const conflictFilesResult = await execCommand('git diff --name-only --diff-filter=U', cwd);\n  const conflictedFiles = conflictFilesResult.stdout\n    ? conflictFilesResult.stdout.split('\\n').filter(Boolean)\n    : [];\n\n  return {\n    hasConflicts: hasUnmerged || conflictedFiles.length > 0,\n    conflictedFiles,\n  };\n}\n\n/**\n * Check if branch is up to date with remote\n * @param cwd - Working directory\n * @returns Object with sync status, commits behind/ahead, and remote branch name\n * @example\n */\nasync function checkBranchSync(cwd: string): Promise<{\n  isSynced: boolean;\n  behindBy: number;\n  aheadBy: number;\n  remoteBranch: string;\n}> {\n  // Get current branch\n  const branchResult = await execCommand('git branch --show-current', cwd);\n  const currentBranch = branchResult.stdout;\n\n  if (!currentBranch) {\n    return {\n      isSynced: true,\n      behindBy: 0,\n      aheadBy: 0,\n      remoteBranch: '',\n    };\n  }\n\n  // Fetch latest from remote\n  await execCommand('git fetch', cwd);\n\n  // Get tracking branch\n  const trackingResult = await execCommand(\n    `git rev-parse --abbrev-ref ${currentBranch}@{upstream}`,\n    cwd\n  );\n\n  if (!trackingResult.success) {\n    // No tracking branch set up\n    return {\n      isSynced: true,\n      behindBy: 0,\n      aheadBy: 0,\n      remoteBranch: '',\n    };\n  }\n\n  const remoteBranch = trackingResult.stdout;\n\n  // Check how many commits behind/ahead we are\n  const revListResult = await execCommand(\n    `git rev-list --left-right --count ${currentBranch}...${remoteBranch}`,\n    cwd\n  );\n\n  if (!revListResult.success) {\n    return {\n      isSynced: true,\n      behindBy: 0,\n      aheadBy: 0,\n      remoteBranch,\n    };\n  }\n\n  // Parse output: \"ahead\\tbehind\"\n  const [aheadStr, behindStr] = revListResult.stdout.split('\\t');\n  const aheadBy = parseInt(aheadStr || '0', 10);\n  const behindBy = parseInt(behindStr || '0', 10);\n\n  return {\n    isSynced: behindBy === 0,\n    behindBy,\n    aheadBy,\n    remoteBranch,\n  };\n}\n\n/**\n * Get number of commits ahead of origin/main (or origin/master)\n * Used to determine if a PR is needed (separate from sync check)\n */\nasync function getCommitsAheadOfMain(cwd: string): Promise<number> {\n  // Try origin/main first, then origin/master\n  for (const mainBranch of ['origin/main', 'origin/master']) {\n    const result = await execCommand(\n      `git rev-list --count ${mainBranch}..HEAD`,\n      cwd\n    );\n    if (result.success) {\n      return parseInt(result.stdout || '0', 10);\n    }\n  }\n  return 0;\n}\n\n// ============================================================================\n// GitHub CLI Operations\n// ============================================================================\n\n/**\n * Check if a PR exists for the current branch\n *\n * Uses GitHub CLI to query for existing PRs where the head branch\n * matches the current branch name.\n * @param branch - Current branch name\n * @param cwd - Working directory\n * @returns Object with PR existence status, number, URL, or error\n * @example\n */\nasync function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<{\n  exists: boolean;\n  prNumber?: number;\n  prUrl?: string;\n  error?: string;\n}> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return {\n      exists: false,\n      error: 'GitHub CLI not installed'\n    };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return {\n      exists: false,\n      error: 'GitHub CLI not authenticated'\n    };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number,url --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return {\n      exists: false,\n      error: `gh pr list failed: ${prListResult.stderr}`\n    };\n  }\n\n  // Parse JSON output\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n\n    if (Array.isArray(prs) && prs.length > 0) {\n      return {\n        exists: true,\n        prNumber: prs[0].number,\n        prUrl: prs[0].url,\n      };\n    }\n\n    return { exists: false };\n  } catch (parseError) {\n    return {\n      exists: false,\n      error: `Failed to parse gh output: ${parseError}`\n    };\n  }\n}\n\n// Local CI functions removed - using shared utilities from ci-status.ts:\n// - getLatestCIRun -> getCIRunDetails\n// - getVercelPreviewUrls -> extractPreviewUrls\n// - waitForCIChecks -> awaitCIWithFailFast\n\n// ============================================================================\n// Subagent Activity Detection\n// ============================================================================\n\n/**\n * Check if there has been recent subagent activity\n *\n * Detects if a subagent just stopped and may be awaiting user input.\n * If true, skips PR encouragement to avoid interrupting workflow.\n * @param cwd - Working directory\n * @returns True if recent subagent activity detected\n * @example\n */\nasync function hasRecentSubagentActivity(cwd: string): Promise<boolean> {\n  const tasksFilePath = join(cwd, '.claude', 'logs', 'subagent-tasks.json');\n\n  try {\n    if (!existsSync(tasksFilePath)) {\n      return false;\n    }\n\n    const content = readFileSync(tasksFilePath, 'utf-8');\n    const tasks = JSON.parse(content);\n\n    // If any subagent contexts exist, there's recent subagent activity\n    return Object.keys(tasks).length > 0;\n  } catch {\n    return false;\n  }\n}\n\n// ============================================================================\n// Validation Checks\n// ============================================================================\n\n/**\n * Run claude doctor to check for settings issues\n *\n * Executes `claude doctor` command and parses output for errors.\n * @param cwd - Working directory\n * @returns Object with health status and any issues found\n * @example\n */\nasync function checkClaudeDoctor(cwd: string): Promise<{\n  healthy: boolean;\n  issues: string[];\n  error?: string;\n}> {\n  // Check if claude CLI is available\n  const claudeCheck = await execCommand('claude --version', cwd);\n  if (!claudeCheck.success) {\n    return {\n      healthy: true, // Don't block if claude not available\n      issues: [],\n      error: 'Claude CLI not available'\n    };\n  }\n\n  // Run claude doctor\n  const doctorResult = await execCommand('claude doctor --json 2>&1', cwd);\n\n  // Check for known non-settings errors first\n  const knownNonSettingsErrors = [\n    'Raw mode is not supported',\n    'isRawModeSupported',\n    'Ink',\n    'Command failed: claude doctor',\n  ];\n\n  const errorText = doctorResult.stderr || doctorResult.stdout || '';\n  const isNonSettingsError = knownNonSettingsErrors.some(\n    pattern => errorText.includes(pattern)\n  );\n\n  if (!doctorResult.success && isNonSettingsError) {\n    // Terminal/UI error, not a settings issue\n    return {\n      healthy: true,\n      issues: [],\n      error: 'Claude doctor failed due to terminal limitations (non-blocking)'\n    };\n  }\n\n  // Parse output\n  try {\n    // Try to parse as JSON first\n    if (doctorResult.stdout) {\n      const doctorOutput = JSON.parse(doctorResult.stdout);\n\n      // Check for errors or warnings in output\n      const issues: string[] = [];\n\n      if (doctorOutput.errors && Array.isArray(doctorOutput.errors)) {\n        issues.push(...doctorOutput.errors);\n      }\n\n      if (doctorOutput.warnings && Array.isArray(doctorOutput.warnings)) {\n        issues.push(...doctorOutput.warnings);\n      }\n\n      return {\n        healthy: issues.length === 0,\n        issues\n      };\n    }\n\n    // If no JSON output, check exit code\n    if (!doctorResult.success && !isNonSettingsError) {\n      return {\n        healthy: false,\n        issues: [doctorResult.stderr || 'Unknown error']\n      };\n    }\n\n    return {\n      healthy: true,\n      issues: []\n    };\n  } catch {\n    // If JSON parsing fails, check exit code\n    if (!doctorResult.success && !isNonSettingsError) {\n      return {\n        healthy: false,\n        issues: [doctorResult.stderr || doctorResult.stdout || 'Claude doctor failed']\n      };\n    }\n\n    return {\n      healthy: true,\n      issues: []\n    };\n  }\n}\n\n/**\n * Validate all registered hooks point to real files\n *\n * Checks both plugin hooks and .claude/hooks directory for missing files.\n * @param cwd - Working directory\n * @returns Object with validation status and missing files\n * @example\n */\nasync function validateHookFiles(cwd: string): Promise<{\n  valid: boolean;\n  missingFiles: string[];\n  error?: string;\n}> {\n  const missingFiles: string[] = [];\n\n  try {\n    // Check .claude/settings.json for enabled plugins\n    const settingsPath = join(cwd, '.claude', 'settings.json');\n\n    if (!existsSync(settingsPath)) {\n      // No settings file, skip validation\n      return { valid: true, missingFiles: [] };\n    }\n\n    const settings = JSON.parse(readFileSync(settingsPath, 'utf-8'));\n    const enabledPlugins = settings.enabledPlugins || {};\n\n    // For each enabled plugin, check hooks\n    for (const [pluginName, enabled] of Object.entries(enabledPlugins)) {\n      if (!enabled) continue;\n\n      // Try to find plugin in cache\n      const pluginCachePath = join(\n        process.env.HOME || '/home',\n        '.claude',\n        'plugins',\n        'cache',\n        pluginName.replace('@', '/'),\n        'hooks',\n        'hooks.json'\n      );\n\n      if (existsSync(pluginCachePath)) {\n        const hooksConfig = JSON.parse(readFileSync(pluginCachePath, 'utf-8'));\n\n        if (hooksConfig.hooks) {\n          // Validate hook files\n          for (const eventHooks of Object.values(hooksConfig.hooks)) {\n            if (!Array.isArray(eventHooks)) continue;\n\n            for (const hookGroup of eventHooks) {\n              if (!hookGroup.hooks) continue;\n\n              for (const hook of hookGroup.hooks) {\n                if (hook.type === 'command' && hook.command) {\n                  // Extract file path from command (remove npx tsx and ${CLAUDE_PLUGIN_ROOT})\n                  const commandMatch = hook.command.match(/\\$\\{CLAUDE_PLUGIN_ROOT\\}\\/(.+)$/);\n                  if (commandMatch) {\n                    const hookFile = commandMatch[1];\n                    const pluginDir = pluginCachePath.replace('/hooks/hooks.json', '');\n                    const hookPath = join(pluginDir, hookFile);\n\n                    if (!existsSync(hookPath)) {\n                      missingFiles.push(`${pluginName}: ${hookFile}`);\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Check local .claude/hooks directory\n    const localHooksDir = join(cwd, '.claude', 'hooks');\n    if (existsSync(localHooksDir)) {\n      const localHooksJson = join(localHooksDir, 'hooks.json');\n\n      if (existsSync(localHooksJson)) {\n        const localHooksConfig = JSON.parse(readFileSync(localHooksJson, 'utf-8'));\n\n        if (localHooksConfig.hooks) {\n          for (const eventHooks of Object.values(localHooksConfig.hooks)) {\n            if (!Array.isArray(eventHooks)) continue;\n\n            for (const hookGroup of eventHooks) {\n              if (!hookGroup.hooks) continue;\n\n              for (const hook of hookGroup.hooks) {\n                if (hook.type === 'command' && hook.command) {\n                  // For local hooks, files should be relative to .claude/hooks\n                  const commandMatch = hook.command.match(/hooks\\/(.+\\.ts)$/);\n                  if (commandMatch) {\n                    const hookFile = commandMatch[1];\n                    const hookPath = join(localHooksDir, hookFile);\n\n                    if (!existsSync(hookPath)) {\n                      missingFiles.push(`.claude/hooks: ${hookFile}`);\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return {\n      valid: missingFiles.length === 0,\n      missingFiles\n    };\n  } catch (error) {\n    return {\n      valid: true, // Don't block on validation errors\n      missingFiles: [],\n      error: `Hook validation error: ${error}`\n    };\n  }\n}\n\n// ============================================================================\n// Output Formatting\n// ============================================================================\n\n/**\n * Format commit message with session metadata\n * @param sessionId - Session ID\n * @param branch - Current branch name\n * @returns Formatted commit message\n * @example\n */\nfunction formatCommitMessage(sessionId: string, branch: string | null): string {\n  const timestamp = new Date().toISOString();\n  return `Session work\n\nAuto-commit at session end to preserve work in progress.\n\nSession-ID: ${sessionId}\nSession-Timestamp: ${timestamp}${branch ? `\\nBranch: ${branch}` : ''}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>`;\n}\n\n/**\n * Format a linked issue for display\n * @param issue - Issue info with number, url, and repo\n * @param prRepo - PR's repository for comparison\n * @returns Formatted issue string\n */\nfunction formatLinkedIssue(issue: LinkedIssueInfo, prRepo: string): string {\n  // If same repo as PR, show just #number\n  // If different repo, show owner/repo#number\n  const prefix = issue.repo === prRepo ? `#${issue.number}` : `${issue.repo}#${issue.number}`;\n  const titlePart = issue.title ? ` - ${issue.title}` : '';\n  return `${prefix}${titlePart} → ${issue.url}`;\n}\n\n/**\n * Format a session issue for display (other issues section)\n * @param issue - Issue reference from session tracking\n * @param currentRepo - Current repository for comparison\n * @returns Formatted issue string\n */\nfunction formatSessionIssue(issue: IssueReference, currentRepo: string): string {\n  // If same repo, show just #number; if different, show owner/repo#number\n  const prefix = issue.repo === currentRepo ? `#${issue.number}` : `${issue.repo}#${issue.number}`;\n  const titlePart = issue.title ? ` - ${issue.title}` : '';\n  return `${prefix}${titlePart} → ${issue.url}`;\n}\n\n/**\n * Format PR status message when commit was made and PR exists\n * @param commitSha - Commit SHA\n * @param prCheck - PR details\n * @param prCheck.prNumber - PR number\n * @param prCheck.prUrl - PR URL\n * @param ciRun - CI run details\n * @param ciRun.url - CI run URL\n * @param ciRun.status - CI run status\n * @param ciRun.conclusion - CI run conclusion\n * @param ciRun.name - CI run name\n * @param groupedPreviews - Preview URLs grouped by provider\n * @param linkedIssues - Issues linked from PR body (closes when merged)\n * @param otherIssues - Other issues created during session but not linked to PR\n * @param prRepo - PR's repository name (owner/repo)\n * @returns Formatted message\n * @example\n */\nfunction formatPRStatusWithCommit(\n  commitSha: string,\n  prCheck: { prNumber: number; prUrl: string },\n  ciRun: { url?: string; status?: string; conclusion?: string; name?: string },\n  groupedPreviews: GroupedPreviewUrls,\n  linkedIssues: LinkedIssueInfo[],\n  otherIssues: IssueReference[],\n  prRepo: string\n): string {\n  const ciPassed = ciRun.conclusion === 'success';\n  const ciFailed = ciRun.conclusion === 'failure';\n\n  let message = `✅ Auto-committed: ${commitSha}\\n\\n`;\n\n  // PR link (prominently displayed)\n  message += `📋 PR: ${prCheck.prUrl}\\n`;\n\n  // CI run link (prominently displayed)\n  if (ciRun.url) {\n    const statusIcon = ciPassed ? '✅' : ciFailed ? '❌' : '⏳';\n    message += `🔄 CI: ${ciRun.url} ${statusIcon} ${ciRun.conclusion || ciRun.status || 'pending'}\\n`;\n  }\n\n  // Linked issues (closes when merged) - nested under PR\n  if (linkedIssues.length > 0) {\n    message += '\\n   📌 Linked Issues (closes when merged):\\n';\n    for (const issue of linkedIssues) {\n      message += `      • ${formatLinkedIssue(issue, prRepo)}\\n`;\n    }\n  }\n\n  // Other issues created during session (not linked to PR)\n  if (otherIssues.length > 0) {\n    message += '\\n📝 Other Issues Created:\\n';\n    for (const issue of otherIssues) {\n      message += `   • ${formatSessionIssue(issue, prRepo)}\\n`;\n    }\n  }\n\n  // Vercel Previews\n  if (groupedPreviews.vercel.length > 0) {\n    message += '\\n🔼 Vercel Previews:\\n';\n    for (const url of groupedPreviews.vercel) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  // Cloudflare Previews\n  if (groupedPreviews.cloudflare.length > 0) {\n    message += '\\n☁️ Cloudflare Worker Previews:\\n';\n    for (const url of groupedPreviews.cloudflare) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  // Supabase Previews\n  if (groupedPreviews.supabase.length > 0) {\n    message += '\\n⚡ Supabase Preview Branches:\\n';\n    for (const url of groupedPreviews.supabase) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  message += '\\nPress enter to continue.';\n  return message;\n}\n\n/**\n * Format PR status info message\n * @param prCheck - PR details\n * @param prCheck.prNumber - PR number\n * @param prCheck.prUrl - PR URL\n * @param ciRun - CI run details\n * @param ciRun.url - CI run URL\n * @param ciRun.status - CI run status\n * @param ciRun.conclusion - CI run conclusion\n * @param ciRun.name - CI run name\n * @param groupedPreviews - Preview URLs grouped by provider\n * @param linkedIssues - Issues linked from PR body (closes when merged)\n * @param otherIssues - Other issues created during session but not linked to PR\n * @param prRepo - PR's repository name (owner/repo)\n * @returns Formatted message\n * @example\n */\nfunction formatPRStatusInfo(\n  prCheck: { prNumber: number; prUrl: string },\n  ciRun: { url?: string; status?: string; conclusion?: string; name?: string },\n  groupedPreviews: GroupedPreviewUrls,\n  linkedIssues: LinkedIssueInfo[],\n  otherIssues: IssueReference[],\n  prRepo: string\n): string {\n  // Header (simplified - this function only called when CI passed or pending)\n  let message = '✅ PR Ready for Review\\n\\n';\n\n  // PR link with markdown format (clickable)\n  message += `📋 [View PR #${prCheck.prNumber}](${prCheck.prUrl})\\n`;\n\n  // CI run link with markdown format\n  if (ciRun.url) {\n    message += `🔄 [View CI Run](${ciRun.url}) ✅ success\\n`;\n  }\n\n  // Linked issues (closes when merged) - nested under PR\n  if (linkedIssues.length > 0) {\n    message += '\\n   📌 Linked Issues (closes when merged):\\n';\n    for (const issue of linkedIssues) {\n      message += `      • ${formatLinkedIssue(issue, prRepo)}\\n`;\n    }\n  }\n\n  // Other issues created during session (not linked to PR)\n  if (otherIssues.length > 0) {\n    message += '\\n📝 Other Issues Created:\\n';\n    for (const issue of otherIssues) {\n      message += `   • ${formatSessionIssue(issue, prRepo)}\\n`;\n    }\n  }\n\n  // Vercel Previews\n  if (groupedPreviews.vercel.length > 0) {\n    message += '\\n🔼 Vercel Previews:\\n';\n    for (const url of groupedPreviews.vercel) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  // Cloudflare Previews\n  if (groupedPreviews.cloudflare.length > 0) {\n    message += '\\n☁️ Cloudflare Worker Previews:\\n';\n    for (const url of groupedPreviews.cloudflare) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  // Supabase Previews\n  if (groupedPreviews.supabase.length > 0) {\n    message += '\\n⚡ Supabase Preview Branches:\\n';\n    for (const url of groupedPreviews.supabase) {\n      message += `   • ${url}\\n`;\n    }\n  }\n\n  message += '\\nPress enter to continue.';\n  return message;\n}\n\n/**\n * Format blocking error messages for various checks\n * @param conflictedFiles - List of files with merge conflicts\n * @returns Formatted error message\n * @example\n */\nfunction formatConflictError(conflictedFiles: string[]): string {\n  return [\n    '🚨 Merge Conflicts Detected:',\n    '',\n    `⚠️  ${conflictedFiles.length} file(s) have unresolved conflicts:`,\n    ...conflictedFiles.map(f => `  - ${f}`),\n    '',\n    'Please resolve these conflicts before ending the session:',\n    '  • Open conflicted files and resolve markers (<<<<<<, ======, >>>>>>)',\n    '  • Stage resolved files: git add <file>',\n    '  • Or use: git mergetool',\n  ].join('\\n');\n}\n\nfunction formatSyncError(syncCheck: { behindBy: number; aheadBy: number; remoteBranch: string }): string {\n  return [\n    '🚨 Branch Out of Sync:',\n    '',\n    `⚠️  Your branch is ${syncCheck.behindBy} commit(s) behind ${syncCheck.remoteBranch}`,\n    `  (You are ${syncCheck.aheadBy} commit(s) ahead)`,\n    '',\n    'Please sync your branch before ending the session:',\n    '  • Pull and merge: git pull',\n    '  • Or rebase: git pull --rebase',\n    '',\n    'This prevents conflicts and ensures you\\'re working with the latest code.',\n  ].join('\\n');\n}\n\nfunction formatDoctorErrors(issues: string[]): string {\n  return [\n    '🚨 Claude Code Settings Issues Detected:',\n    '',\n    ...issues.map(issue => `⚠️  ${issue}`),\n    '',\n    'Please fix these settings issues before ending the session:',\n    '  • Run: claude doctor',\n    '  • Review and fix reported issues',\n    '  • Check .claude/settings.json for configuration errors',\n  ].join('\\n');\n}\n\nfunction formatHookErrors(missingFiles: string[]): string {\n  return [\n    '🚨 Missing Hook Files Detected:',\n    '',\n    `⚠️  ${missingFiles.length} hook file(s) are missing:`,\n    ...missingFiles.map(file => `  - ${file}`),\n    '',\n    'Please fix these hook issues before ending the session:',\n    '  • Reinstall affected plugins: claude plugin install <plugin-name>',\n    '  • Or remove broken plugins from .claude/settings.json',\n    '  • Check plugin cache: ~/.claude/plugins/cache/',\n  ].join('\\n');\n}\n\n/**\n * Format agent instructions for progressive blocking\n * @param sessionId - Session ID\n * @param branch - Current branch name\n * @param issueNumber - Linked issue number (or null)\n * @param issueUrl - Linked issue URL (or null)\n * @param blockCount - Number of times blocked\n * @param skipInstructions - Skip instructions if subagent active\n * @returns Formatted agent instruction message\n * @example\n */\nfunction formatAgentInstructions(\n  sessionId: string,\n  branch: string,\n  issueNumber: number | null,\n  issueUrl: string | null,\n  blockCount: number,\n  skipInstructions: boolean\n): string {\n  if (skipInstructions) {\n    return `⏸️  Subagent just stopped - awaiting your input (Session: ${sessionId})`;\n  }\n\n  const header = blockCount === 1\n    ? '🤖 SESSION COMMIT CHECKPOINT'\n    : `🤖 SESSION COMMIT CHECKPOINT (Attempt ${blockCount}/3)`;\n\n  let issueSection = '';\n  if (issueNumber && issueUrl) {\n    issueSection = `\n**Linked Issue:** #${issueNumber}\n${issueUrl}\n\n   Use ONE of these methods to post your comment:\n\n   METHOD A - Direct command (include the session marker):\n   gh issue comment ${issueNumber} --body $'<!-- claude-session: ${sessionId} -->\\\\n\\\\nWork completed:\\\\n- Item 1\\\\n- Item 2'\n\n   METHOD B - Helper function (recommended for complex content):\n   Use Bash tool to run:\n   npx tsx -e \"import { postSessionComment } from './plugins/github-context/shared/hooks/utils/github-comments.js'; await postSessionComment(${issueNumber}, '${sessionId}', 'Work completed:\\\\n- Item 1\\\\n- Item 2', '${branch}', process.cwd());\"`;\n  } else {\n    issueSection = `\n   First discover the linked issue number, then post a comment with your session ID.\n   Use gh issue list or parse from branch name pattern.`;\n  }\n\n  return `${header}\n\nSession ID: ${sessionId}\nBranch: ${branch}\n\nYou've made commits but haven't created a PR yet.\n\nPlease choose ONE of the following:\n\n1. CREATE A PR\n   gh pr create --title \"...\" --body \"...\"\n\n2. DOCUMENT PROGRESS\n   Post a comment to the linked issue documenting:\n   - What work you checked/reviewed\n   - What you accomplished\n   - Any issues or confusion noted\n${issueSection}\n\n   IMPORTANT: Your comment must include the session ID marker shown above.\n   The hook detects either the HTML marker or the plain session ID in your comment.`;\n}\n\n// ============================================================================\n// Main Handler\n// ============================================================================\n\n/**\n * Stop hook handler\n *\n * Unified hook that combines auto-commit and PR status checking.\n * Executes in four phases:\n * 1. Blocking validation checks (merge conflicts, branch sync, etc.)\n * 2. Auto-commit uncommitted changes\n * 3. PR status check (if applicable)\n * 4. Output decision based on state\n * @param input - Stop hook input from Claude Code\n * @returns Hook output with blocking decision or system message\n * @example\n */\nasync function handler(input: StopInput): Promise<StopHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'commit-session-check-pr-status', true);\n\n  // Skip blocking behavior in plan mode - Claude is just exploring/planning\n  if (input.permission_mode === 'plan') {\n    return { decision: 'approve' };\n  }\n\n  try {\n    await logger.logInput({ session_id: input.session_id });\n\n    // Normalize cwd to repo root - critical for subagents running from subdirectories\n    // (e.g., subagent with cwd=apps/web/ needs to check commits at repo root)\n    const repoRoot = await getRepoRoot(input.cwd);\n\n    // Load session state for progressive blocking (uses repoRoot for state file location)\n    const sessionState = await getSessionStopState(input.session_id, repoRoot);\n\n    // === PHASE 1: BLOCKING CHECKS ===\n    // These must pass before we proceed\n\n    // Check if in git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', repoRoot);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return { decision: 'approve' };\n    }\n\n    // Check Claude settings health\n    const doctorCheck = await checkClaudeDoctor(repoRoot);\n    if (!doctorCheck.healthy && doctorCheck.issues.length > 0) {\n      return {\n        decision: 'block',\n        reason: formatDoctorErrors(doctorCheck.issues),\n        systemMessage: 'Claude is blocked from stopping due to configuration issues.',\n      };\n    }\n\n    // Validate hook files exist\n    const hookValidation = await validateHookFiles(repoRoot);\n    if (!hookValidation.valid && hookValidation.missingFiles.length > 0) {\n      return {\n        decision: 'block',\n        reason: formatHookErrors(hookValidation.missingFiles),\n        systemMessage: 'Claude is blocked from stopping due to missing hook files.',\n      };\n    }\n\n    // Check for merge conflicts\n    const conflictCheck = await checkMergeConflicts(repoRoot);\n    if (conflictCheck.hasConflicts) {\n      return {\n        decision: 'block',\n        reason: formatConflictError(conflictCheck.conflictedFiles),\n        systemMessage: 'Claude is blocked from stopping due to merge conflicts.',\n      };\n    }\n\n    // Check branch sync status (behind remote)\n    const syncCheck = await checkBranchSync(repoRoot);\n    if (!syncCheck.isSynced && syncCheck.remoteBranch) {\n      return {\n        decision: 'block',\n        reason: formatSyncError(syncCheck),\n        systemMessage: 'Claude is blocked from stopping due to branch sync issues.',\n      };\n    }\n\n    // Get commits ahead of main (for PR detection - separate from sync check)\n    // This determines if a PR is needed, regardless of whether we've pushed\n    let commitsAheadOfMain = await getCommitsAheadOfMain(repoRoot);\n\n    // === PHASE 2: AUTO-COMMIT ===\n    let commitMade = false;\n    let commitSha = '';\n\n    const hasChanges = await hasUncommittedChanges(repoRoot);\n\n    if (hasChanges) {\n      const branch = await getCurrentBranch(repoRoot);\n\n      // Only stage non-gitignored files\n      const filesToStage = await getNonIgnoredChanges(repoRoot);\n      if (filesToStage.length === 0) {\n        // All changes are gitignored - skip commit\n        await logger.logOutput({ skipped: true, reason: 'All changes are gitignored' });\n      } else {\n        // Stage only non-ignored files\n        for (const file of filesToStage) {\n          await execCommand(`git add \"${file}\"`, repoRoot);\n        }\n\n        const commitMessage = formatCommitMessage(input.session_id, branch);\n        const commitResult = await execCommand(\n          `git commit -m ${JSON.stringify(commitMessage)}`,\n          repoRoot\n        );\n\n        if (commitResult.success) {\n          const shaResult = await execCommand('git rev-parse HEAD', repoRoot);\n          const fullSha = shaResult.success ? shaResult.stdout : null;\n          commitSha = fullSha ? fullSha.substring(0, 7) : 'unknown';\n          commitMade = true;\n\n          await logger.logOutput({ commit_made: true, commit_sha: commitSha });\n\n          // Update state with new commit SHA for tracking\n          await updateSessionStopState(input.session_id, {\n            blockCount: sessionState.blockCount + 1,\n            lastBlockTimestamp: new Date().toISOString(),\n            lastSeenCommitSha: fullSha || undefined,\n          }, repoRoot);\n\n          // Re-check branch sync after commit\n          const postCommitSync = await checkBranchSync(repoRoot);\n          syncCheck.aheadBy = postCommitSync.aheadBy;\n          // Also update commits ahead of main\n          commitsAheadOfMain = await getCommitsAheadOfMain(repoRoot);\n        } else {\n          await logger.logOutput({ commit_failed: true, error: commitResult.stderr });\n        }\n      }\n    }\n\n    // === PHASE 3: PR STATUS CHECK ===\n    const currentBranch = await getCurrentBranch(repoRoot);\n\n    // Skip PR checks for main branches\n    const mainBranches = ['main', 'master', 'develop'];\n    if (!currentBranch || mainBranches.includes(currentBranch)) {\n      if (commitMade) {\n        return {\n          decision: 'block',\n          reason: `✅ Auto-committed session work: ${commitSha}\\n\\nPush to remote before ending session.`,\n        };\n      }\n      return { decision: 'approve' };\n    }\n\n    // Check if subagent just stopped (awaiting user input)\n    const hasSubagentActivity = await hasRecentSubagentActivity(repoRoot);\n\n    // Check if PR exists\n    const prCheck = await checkPRExists(currentBranch, repoRoot);\n\n    // === PHASE 4: OUTPUT DECISION WITH AGENT COMMUNICATION ===\n\n    // Check if PR created since last block\n    if (prCheck.exists && prCheck.prNumber && prCheck.prUrl) {\n      // PR exists - wait for CI checks with fail-fast behavior\n      await logger.logOutput({\n        pr_exists: true,\n        pr_number: prCheck.prNumber,\n        waiting_for_ci: true\n      });\n\n      const ciResult = await awaitCIWithFailFast({ prNumber: prCheck.prNumber }, repoRoot);\n\n      // If CI failed, block with concise error message + log file link\n      if (!ciResult.success) {\n        // Format checks output for logging\n        const checksOutput = ciResult.checks.map(c => `${c.emoji} ${c.name}: ${c.status}`).join('\\n');\n        const logPath = await saveOutputToLog(repoRoot, 'ci', `pr-${prCheck.prNumber}`, checksOutput);\n\n        // Map ci-status CheckStatus to log-file format\n        const mappedChecks = ciResult.checks.map(c => ({\n          name: c.name,\n          status: (c.status === 'success' ? 'pass' :\n                   c.status === 'failure' ? 'fail' :\n                   c.status === 'cancelled' ? 'skipped' : 'pending') as 'pass' | 'fail' | 'pending' | 'skipped',\n          duration: '',\n        }));\n        const checksTable = formatCiChecksTable(mappedChecks, logPath);\n\n        await logger.logOutput({\n          ci_status: 'failed',\n          log_path: logPath,\n          ci_error: ciResult.error,\n          failed_check: ciResult.failedCheck\n        });\n\n        return {\n          decision: 'block',\n          reason: `${ciResult.blockReason || `❌ CI failed for PR #${prCheck.prNumber}`}\n\n${checksTable}\n\n🔗 [View PR](${prCheck.prUrl})\n   \\`gh pr checks ${prCheck.prNumber}\\``,\n          systemMessage: 'Claude is blocked from stopping due to CI check failures.',\n        };\n      }\n\n      // CI passed - reset state and show success\n      await resetSessionStopState(input.session_id, repoRoot);\n      await logger.logOutput({\n        ci_status: 'passed',\n        checks: ciResult.checks\n      });\n\n      // Fetch PR details, previews, linked issues, and session issues in parallel\n      const [ciRun, groupedPreviews, linkedIssues, sessionIssues] = await Promise.all([\n        getCIRunDetails(prCheck.prNumber, repoRoot).then(r => r ?? {}),\n        extractAllPreviews(prCheck.prNumber, repoRoot),\n        extractLinkedIssuesWithInfo(prCheck.prNumber, repoRoot),\n        getSessionIssues(input.session_id, repoRoot),\n      ]);\n\n      // Extract PR repo from URL for display formatting\n      const prRepoMatch = prCheck.prUrl.match(/github\\.com\\/([^/]+\\/[^/]+)\\/pull/);\n      const prRepo = prRepoMatch ? prRepoMatch[1] : '';\n\n      // Filter session issues to find \"other issues\" not linked to the PR\n      const linkedIssueKeys = new Set(linkedIssues.map(i => `${i.repo}#${i.number}`));\n      const otherIssues = sessionIssues.filter(\n        issue => !linkedIssueKeys.has(`${issue.repo}#${issue.number}`)\n      );\n\n      // Track PR in github.json (store just issue numbers for backwards compatibility)\n      await addPRToState(\n        input.session_id,\n        {\n          number: prCheck.prNumber,\n          url: prCheck.prUrl,\n          title: '', // We don't have title here, could fetch if needed\n          createdAt: new Date().toISOString(),\n          linkedIssues: linkedIssues.map(i => i.number),\n        },\n        repoRoot\n      );\n\n      // If CI run shows failure, block Claude (don't show to user)\n      if (ciRun.conclusion === 'failure' || ciRun.conclusion === 'cancelled') {\n        const failedStatus = ciRun.conclusion === 'cancelled' ? 'cancelled' : 'failed';\n        return {\n          decision: 'block',\n          reason: `❌ CI ${failedStatus} for PR #${prCheck.prNumber}\n\n🔗 [View PR](${prCheck.prUrl})\n   [View CI Run](${ciRun.url})`,\n          systemMessage: `Claude is blocked from stopping due to CI ${failedStatus}.`,\n        };\n      }\n\n      if (commitMade) {\n        // Show PR status after commit (non-blocking)\n        return {\n          decision: 'approve',\n          systemMessage: formatPRStatusWithCommit(commitSha, { prNumber: prCheck.prNumber, prUrl: prCheck.prUrl }, ciRun, groupedPreviews, linkedIssues, otherIssues, prRepo),\n        };\n      } else if (commitsAheadOfMain > 0) {\n        // Show PR status to user (non-blocking)\n        return {\n          decision: 'approve',\n          systemMessage: formatPRStatusInfo({ prNumber: prCheck.prNumber, prUrl: prCheck.prUrl }, ciRun, groupedPreviews, linkedIssues, otherIssues, prRepo),\n        };\n      } else {\n        // Always show PR status when PR exists, even if no new commits this session (non-blocking)\n        return {\n          decision: 'approve',\n          systemMessage: formatPRStatusInfo({ prNumber: prCheck.prNumber, prUrl: prCheck.prUrl }, ciRun, groupedPreviews, linkedIssues, otherIssues, prRepo),\n        };\n      }\n    }\n\n    // No PR - check if comment posted for this session\n    // First check session state flag (survives across stop attempts)\n    // BUT also check if new commits were made since the comment was posted\n    if (sessionState.commentPosted) {\n      const currentHeadSha = await getCurrentHeadSha(repoRoot);\n\n      // If we have a commentPostedAtSha, check if new commits were made since then\n      if (sessionState.commentPostedAtSha &&\n          currentHeadSha !== sessionState.commentPostedAtSha) {\n        // New commits since comment - reset flag and require new documentation\n        await logger.logOutput({ debug: 'New commits since comment - resetting commentPosted flag' });\n        await updateSessionStopState(input.session_id, {\n          commentPosted: false,\n          commentPostedAtSha: undefined,\n        }, repoRoot);\n        // Fall through to blocking logic below\n      } else {\n        // Same commit or no tracking - allow stop\n        await logger.logOutput({ debug: 'Comment previously posted - allowing stop' });\n        return {\n          decision: 'approve',\n          systemMessage: '✅ Session progress already documented'\n        };\n      }\n    }\n\n    // Try to discover linked issue\n    // First try branch-issues.json, then fallback to linked issue discovery\n    const branchIssueInfo = await getBranchIssueInfo(currentBranch, repoRoot);\n    const issueNumber = branchIssueInfo?.issueNumber ?? await getLinkedIssueNumber(currentBranch, repoRoot);\n    const issueUrl = branchIssueInfo?.issueUrl ?? null;\n\n    // Check GitHub for comment if we have an issue number\n    if (issueNumber && await hasCommentForSession(issueNumber, input.session_id, repoRoot)) {\n      // Comment posted - update state flag, save SHA, and reset block count\n      const currentSha = await getCurrentHeadSha(repoRoot);\n      await updateSessionStopState(input.session_id, {\n        commentPosted: true,\n        commentPostedAtSha: currentSha || undefined,  // Track when comment was posted\n        blockCount: 0,\n      }, repoRoot);\n\n      return {\n        decision: 'approve',\n        systemMessage: `✅ Session progress documented in issue #${issueNumber}`\n      };\n    }\n\n    // Log if issue discovery failed (helps debug blocking issues)\n    if (!issueNumber) {\n      await logger.logOutput({ debug: 'Could not discover linked issue number for branch: ' + currentBranch });\n    }\n\n    // No PR and no comment - determine blocking behavior based on commit tracking\n    // Get current HEAD to compare with last seen commit\n    const currentHeadSha = await getCurrentHeadSha(repoRoot);\n    const sawNewCommits = currentHeadSha !== sessionState.lastSeenCommitSha;\n\n    // If we saw new commits (either just made or from previous session without PR)\n    // Use commitsAheadOfMain (not syncCheck.aheadBy) to detect if PR is needed\n    if (sawNewCommits && commitsAheadOfMain > 0) {\n      // Update lastSeenCommitSha so we only block ONCE for these commits\n      await updateSessionStopState(input.session_id, {\n        lastSeenCommitSha: currentHeadSha || undefined,\n        lastBlockTimestamp: new Date().toISOString(),\n      }, repoRoot);\n\n      // Block with agent instructions - first time seeing these commits\n      return {\n        decision: 'block',\n        reason: formatAgentInstructions(input.session_id, currentBranch, issueNumber, issueUrl, 1, hasSubagentActivity),\n        systemMessage: 'Claude is blocked from stopping - PR or issue comment required.',\n      };\n    }\n\n    // Already saw these commits (lastSeenCommitSha matches current HEAD)\n    // Branch is ahead of main but we've already blocked once for these commits\n    if (commitsAheadOfMain > 0) {\n      return {\n        decision: 'approve',\n        systemMessage: `ℹ️ Branch has ${commitsAheadOfMain} commit(s) ahead of main without a PR. Agent chose to stop without creating one.`,\n      };\n    }\n\n    // No commits ahead of main - nothing to do\n    return {\n      decision: 'approve',\n      systemMessage: 'No commits ahead of main. PR not needed.'\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Don't block on errors - just log them\n    return { decision: 'approve' };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/commit-task-await-ci-status.ts": "/**\n * Automatic commit generation from agent task completion\n *\n * SubagentStop hook that automatically creates git commits when agents complete\n * tasks. Analyzes the agent's file operations and generates commits with rich\n * metadata including the original task prompt and execution statistics.\n *\n * This hook:\n * - Only commits files modified by the specific agent (not all changes)\n * - Generates commit messages from task prompts\n * - Adds git trailers with agent metadata\n * - Handles new files, edits, and deletions separately\n * - Skips commit if no files were modified\n *\n * Commit message format:\n * ```\n * [AgentType] Task description\n *\n * Full task prompt\n *\n * Agent-Type: Explore\n * Agent-ID: agent-abc123\n * Files-Edited: 2\n * Files-New: 1\n * Files-Deleted: 0\n * ```\n *\n * @module commit-task\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getTaskEdits } from '../shared/hooks/utils/task-state.js';\nimport { execCommand } from '../shared/hooks/utils/ci-status.js';\nimport { getStackedBranchEntry } from '../shared/hooks/utils/stacked-branches.js';\n\n// Using shared execCommand from ci-status.ts\n\n/**\n * Format commit message with task prompt and git trailers\n */\nfunction formatCommitMessage(options: {\n  agentType: string;\n  agentId: string;\n  prompt: string;\n  filesEdited: number;\n  filesNew: number;\n  filesDeleted: number;\n}): string {\n  const { agentType, agentId, prompt, filesEdited, filesNew, filesDeleted } = options;\n\n  // Create concise title from prompt (first line or first 50 chars)\n  const promptLines = prompt.split('\\n').map(l => l.trim()).filter(Boolean);\n  let title = promptLines[0] || 'Agent task completed';\n\n  // Truncate title if too long (72 chars is git convention)\n  if (title.length > 72) {\n    title = title.slice(0, 69) + '...';\n  }\n\n  // Build commit message with title, body, and git trailers\n  const lines: string[] = [];\n\n  // Title with agent type prefix\n  lines.push(`[${agentType}] ${title}`);\n  lines.push('');\n\n  // Body: Full prompt (if longer than title)\n  if (promptLines.length > 1 || prompt.length > 100) {\n    lines.push('Task prompt:');\n    lines.push(prompt);\n    lines.push('');\n  }\n\n  // Git trailers for metadata\n  lines.push(`Agent-Type: ${agentType}`);\n  lines.push(`Agent-ID: ${agentId}`);\n  lines.push(`Files-Edited: ${filesEdited}`);\n  lines.push(`Files-New: ${filesNew}`);\n  lines.push(`Files-Deleted: ${filesDeleted}`);\n\n  return lines.join('\\n');\n}\n\n/**\n * SubagentStop hook handler for auto-committing agent work\n *\n * Analyzes the agent's transcript, extracts file edits and task prompt,\n * and creates a commit with only the files edited by this specific agent.\n *\n * @param input - SubagentStop hook input from Claude Code\n * @returns Hook output (empty on success, blocking on critical error)\n */\nasync function handler(\n  input: SubagentStopInput\n): Promise<SubagentStopHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'commit-task', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_transcript_path: input.agent_transcript_path,\n    });\n\n    // Check if stacked PR workflow already handled this agent\n    const stackedEntry = await getStackedBranchEntry(input.cwd, input.agent_id);\n    if (stackedEntry && stackedEntry.status !== 'failed') {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Stacked PR workflow already handled this agent',\n        stackedStatus: stackedEntry.status,\n      });\n      return {};\n    }\n\n    // Check if we're in a git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', input.cwd);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {};\n    }\n\n    // Get task edits (file operations and prompt)\n    let taskEdits;\n    try {\n      taskEdits = await getTaskEdits(input.agent_transcript_path);\n    } catch (error) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not analyze task edits',\n        error: String(error),\n      });\n      return {};\n    }\n\n    const {\n      agentSessionId,\n      subagentType,\n      agentPrompt,\n      agentNewFiles,\n      agentEditedFiles,\n      agentDeletedFiles,\n    } = taskEdits;\n\n    // Combine all modified files\n    const allModifiedFiles = [\n      ...agentNewFiles,\n      ...agentEditedFiles,\n      ...agentDeletedFiles,\n    ];\n\n    if (allModifiedFiles.length === 0) {\n      await logger.logOutput({ skipped: true, reason: 'No files modified by agent' });\n      return {};\n    }\n\n    // Stage only the files modified by this agent\n    for (const file of allModifiedFiles) {\n      // For deleted files, use git rm; for others, use git add\n      const isDeleted = agentDeletedFiles.includes(file);\n      const cmd = isDeleted ? `git rm \"${file}\"` : `git add \"${file}\"`;\n\n      const addResult = await execCommand(cmd, input.cwd);\n      if (!addResult.success) {\n        // Log warning but continue with other files\n        await logger.logOutput({\n          warning: `Could not stage file: ${file}`,\n          error: addResult.stderr,\n        });\n      }\n    }\n\n    // Check if anything was actually staged\n    const statusResult = await execCommand('git diff --cached --name-only', input.cwd);\n    if (!statusResult.stdout) {\n      await logger.logOutput({ skipped: true, reason: 'No changes staged for commit' });\n      return {};\n    }\n\n    // Format commit message with trailers\n    const commitMessage = formatCommitMessage({\n      agentType: subagentType,\n      agentId: agentSessionId,\n      prompt: agentPrompt,\n      filesEdited: agentEditedFiles.length,\n      filesNew: agentNewFiles.length,\n      filesDeleted: agentDeletedFiles.length,\n    });\n\n    // Create commit with properly escaped message\n    const escapedMessage = commitMessage.replace(/'/g, \"'\\\\''\");\n    const commitResult = await execCommand(`git commit -m '${escapedMessage}'`, input.cwd);\n\n    if (!commitResult.success) {\n      // Check if it's just \"nothing to commit\"\n      if (commitResult.stdout.includes('nothing to commit') ||\n          commitResult.stderr.includes('nothing to commit')) {\n        await logger.logOutput({ skipped: true, reason: 'Nothing to commit after staging' });\n        return {};\n      }\n\n      await logger.logOutput({\n        success: false,\n        stage: 'commit',\n        error: commitResult.stderr,\n      });\n      return {};\n    }\n\n    // Get the commit hash\n    const hashResult = await execCommand('git rev-parse --short HEAD', input.cwd);\n    const commitHash = hashResult.stdout || 'unknown';\n\n    await logger.logOutput({\n      success: true,\n      commit_hash: commitHash,\n      agent_type: subagentType,\n      files_modified: allModifiedFiles.length,\n      files_edited: agentEditedFiles.length,\n      files_new: agentNewFiles.length,\n      files_deleted: agentDeletedFiles.length,\n    });\n\n    return {};\n  } catch (error) {\n    await logger.logError(error as Error);\n    // Don't block on commit errors - just log and continue\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/create-issue-on-prompt.ts": "/**\n * Create GitHub issue on first user prompt\n *\n * UserPromptSubmit hook that automatically creates a GitHub issue on the first\n * user prompt of a session. This ensures every branch has an associated issue\n * for tracking work and progress.\n *\n * Features:\n * - **Auto-create issue** - Creates issue from first user prompt\n * - **Branch linking** - Detects issue number prefix in branch name (e.g., `42-claude-...`)\n * - **State tracking** - Saves to `.claude/logs/branch-issues.json` by branch name\n * - **Plan integration** - sync-plan-to-issue.ts updates this issue instead of creating new\n *\n * @module create-issue-on-prompt\n */\n\nimport type { UserPromptSubmitInput, UserPromptSubmitHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n/**\n * Get current git branch name\n */\nasync function getCurrentBranch(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : '';\n}\n\n/**\n * Check if gh CLI is available and authenticated\n */\nasync function isGhAvailable(cwd: string): Promise<boolean> {\n  const authCheck = await execCommand('gh auth status', cwd);\n  return authCheck.success;\n}\n\n/**\n * Parse issue number from branch name prefix (e.g., \"42-claude-agile-narwhal\")\n */\nfunction parseIssueFromBranch(branch: string): number | null {\n  const match = branch.match(/^(\\d+)-/);\n  return match ? parseInt(match[1], 10) : null;\n}\n\n/**\n * Get issue URL from issue number\n */\nasync function getIssueUrl(cwd: string, issueNumber: number): Promise<string | null> {\n  const result = await execCommand(`gh issue view ${issueNumber} --json url -q .url`, cwd);\n  return result.success ? result.stdout : null;\n}\n\n/**\n * Load branch issue state from disk\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Save branch issue state to disk\n */\nasync function saveBranchIssueState(cwd: string, state: BranchIssueState): Promise<void> {\n  const stateDir = path.join(cwd, '.claude', 'logs');\n  const stateFile = path.join(stateDir, 'branch-issues.json');\n\n  await fs.mkdir(stateDir, { recursive: true });\n  await fs.writeFile(stateFile, JSON.stringify(state, null, 2));\n}\n\n/**\n * Create a title from the user prompt (first 80 chars, cleaned up)\n */\nfunction createTitleFromPrompt(prompt: string, branch: string): string {\n  // Clean up the prompt: remove markdown, extra whitespace, etc.\n  const cleaned = prompt\n    .replace(/^#+\\s*/gm, '') // Remove markdown headers\n    .replace(/\\n+/g, ' ') // Replace newlines with spaces\n    .replace(/\\s+/g, ' ') // Collapse whitespace\n    .trim();\n\n  if (!cleaned) {\n    return `Session work on ${branch}`;\n  }\n\n  // Truncate to 80 chars\n  if (cleaned.length <= 80) {\n    return cleaned;\n  }\n\n  return cleaned.substring(0, 77) + '...';\n}\n\n/**\n * Work type prefixes for branch naming\n */\ntype WorkType = 'feature' | 'fix' | 'chore' | 'docs' | 'refactor';\n\n/**\n * Detect work type from prompt keywords\n */\nfunction detectWorkType(prompt: string): WorkType {\n  const lower = prompt.toLowerCase();\n\n  // Fix patterns\n  if (/\\b(fix|bug|error|issue|broken|crash|fail|wrong)\\b/.test(lower)) {\n    return 'fix';\n  }\n\n  // Docs patterns\n  if (/\\b(doc|readme|document|comment|explain)\\b/.test(lower)) {\n    return 'docs';\n  }\n\n  // Refactor patterns\n  if (/\\b(refactor|clean|improve|optimize|reorganize|restructure)\\b/.test(lower)) {\n    return 'refactor';\n  }\n\n  // Feature patterns (default for most work)\n  if (/\\b(add|create|implement|build|new|feature|develop)\\b/.test(lower)) {\n    return 'feature';\n  }\n\n  // Default to feature for general work\n  return 'feature';\n}\n\n/**\n * Convert title to kebab-case for branch name (max 40 chars)\n */\nfunction toKebabCase(title: string): string {\n  return title\n    .toLowerCase()\n    .replace(/[^a-z0-9\\s-]/g, '') // Remove special chars\n    .replace(/\\s+/g, '-') // Replace spaces with hyphens\n    .replace(/-+/g, '-') // Collapse multiple hyphens\n    .replace(/^-|-$/g, '') // Trim hyphens\n    .substring(0, 40); // Max 40 chars\n}\n\n/**\n * Rename branch to include issue number and work type\n * Format: {issueNumber}-{workType}/{kebab-name}\n */\nasync function renameBranch(\n  cwd: string,\n  oldBranch: string,\n  issueNumber: number,\n  title: string,\n  workType: WorkType\n): Promise<{ success: boolean; newBranch: string; error?: string }> {\n  const kebabName = toKebabCase(title);\n  const newBranch = `${issueNumber}-${workType}/${kebabName}`;\n\n  // Rename local branch\n  const renameResult = await execCommand(`git branch -m ${oldBranch} ${newBranch}`, cwd);\n  if (!renameResult.success) {\n    return { success: false, newBranch: oldBranch, error: renameResult.stderr };\n  }\n\n  // Check if old branch exists on remote\n  const remoteCheck = await execCommand(`git ls-remote --heads origin ${oldBranch}`, cwd);\n  if (remoteCheck.success && remoteCheck.stdout.includes(oldBranch)) {\n    // Push new branch and delete old remote branch\n    const pushResult = await execCommand(`git push -u origin ${newBranch}`, cwd);\n    if (pushResult.success) {\n      // Delete old remote branch (non-blocking if fails)\n      await execCommand(`git push origin --delete ${oldBranch}`, cwd);\n    }\n  } else {\n    // Just set upstream for new branch\n    await execCommand(`git push -u origin ${newBranch}`, cwd);\n  }\n\n  return { success: true, newBranch };\n}\n\n/**\n * UserPromptSubmit hook handler\n *\n * Creates a GitHub issue on first user prompt if one doesn't exist for the branch.\n *\n * @param input - UserPromptSubmit hook input from Claude Code\n * @returns Hook output with issue creation status\n */\nasync function handler(input: UserPromptSubmitInput): Promise<UserPromptSubmitHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'create-issue-on-prompt', true);\n\n  try {\n    await logger.logInput({\n      session_id: input.session_id,\n      prompt_length: input.prompt.length,\n    });\n\n    // Check if we're in a git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', input.cwd);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {};\n    }\n\n    // Get current branch\n    const branch = await getCurrentBranch(input.cwd);\n    if (!branch) {\n      await logger.logOutput({ skipped: true, reason: 'Could not determine current branch' });\n      return {};\n    }\n\n    // Only process claude-* branches (worktree branches)\n    if (!branch.startsWith('claude-') && !branch.match(/^\\d+-claude-/)) {\n      await logger.logOutput({ skipped: true, reason: 'Not a claude worktree branch' });\n      return {};\n    }\n\n    // Check if we already have an issue for this branch\n    const state = await loadBranchIssueState(input.cwd);\n    if (state[branch]) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Issue already exists for branch',\n        issueNumber: state[branch].issueNumber,\n      });\n      return {};\n    }\n\n    // Check if gh CLI is available\n    if (!(await isGhAvailable(input.cwd))) {\n      await logger.logOutput({ skipped: true, reason: 'gh CLI not authenticated' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: '⚠ Cannot create GitHub issue: gh CLI not authenticated. Run: gh auth login',\n        },\n      };\n    }\n\n    // Check if branch has an issue number prefix (e.g., \"42-claude-agile-narwhal\")\n    const linkedIssueNumber = parseIssueFromBranch(branch);\n    if (linkedIssueNumber) {\n      // Verify the issue exists\n      const issueUrl = await getIssueUrl(input.cwd, linkedIssueNumber);\n      if (issueUrl) {\n        // Link to existing issue instead of creating new\n        state[branch] = {\n          issueNumber: linkedIssueNumber,\n          issueUrl,\n          createdAt: new Date().toISOString(),\n          createdFromPrompt: false,\n          linkedFromBranchPrefix: true,\n        };\n        await saveBranchIssueState(input.cwd, state);\n\n        await logger.logOutput({\n          action: 'linked',\n          issueNumber: linkedIssueNumber,\n          issueUrl,\n          branch,\n        });\n\n        return {\n          hookSpecificOutput: {\n            hookEventName: 'UserPromptSubmit',\n            additionalContext: `Linked to existing issue #${linkedIssueNumber}: ${issueUrl}\\n\\nThis branch is working on an existing issue (detected from branch prefix).`,\n          },\n        };\n      }\n    }\n\n    // Create new issue from user prompt\n    const title = createTitleFromPrompt(input.prompt, branch);\n    const body = `**Branch:** \\`${branch}\\`\n\n---\n\n## Initial Prompt\n\n${input.prompt}\n\n---\n\n*Issue created automatically on first user prompt.*`;\n\n    const result = await execGhWithStdin(\n      ['issue', 'create', '--title', title, '--body-file', '-'],\n      body,\n      input.cwd\n    );\n\n    if (!result.success) {\n      await logger.logError(new Error(`Failed to create issue: ${result.stderr}`));\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: `⚠ Could not create GitHub issue: ${result.stderr}`,\n        },\n      };\n    }\n\n    // Extract issue URL and number from output\n    const issueUrl = result.stdout.match(/https:\\/\\/github\\.com\\/[^\\s]+/)?.[0] || '';\n    const issueNumber = parseInt(issueUrl.match(/\\/(\\d+)$/)?.[1] || '0', 10);\n\n    if (!issueNumber) {\n      await logger.logError(new Error('Failed to extract issue number from gh output'));\n      return {};\n    }\n\n    // Detect work type and rename branch to include issue number\n    const workType = detectWorkType(input.prompt);\n    const renameResult = await renameBranch(input.cwd, branch, issueNumber, title, workType);\n\n    // Use the new branch name for state tracking\n    const finalBranch = renameResult.newBranch;\n\n    // Save state with the new branch name\n    state[finalBranch] = {\n      issueNumber,\n      issueUrl,\n      createdAt: new Date().toISOString(),\n      createdFromPrompt: true,\n    };\n    // Also keep old branch mapping in case of reference\n    if (finalBranch !== branch) {\n      state[branch] = state[finalBranch];\n    }\n    await saveBranchIssueState(input.cwd, state);\n\n    await logger.logOutput({\n      action: 'created',\n      issueNumber,\n      issueUrl,\n      oldBranch: branch,\n      newBranch: finalBranch,\n      workType,\n      renamed: renameResult.success,\n    });\n\n    // Build response message\n    let additionalContext = `Created issue #${issueNumber} for this branch: ${issueUrl}`;\n\n    if (renameResult.success && finalBranch !== branch) {\n      additionalContext += `\\n\\n✓ Branch renamed: \\`${branch}\\` → \\`${finalBranch}\\``;\n      additionalContext += `\\n  Work type: ${workType}`;\n    } else if (!renameResult.success) {\n      additionalContext += `\\n\\n⚠️ Could not rename branch: ${renameResult.error}`;\n      additionalContext += `\\n  To rename manually: \\`git branch -m ${branch} ${issueNumber}-${workType}/<name>\\``;\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'UserPromptSubmit',\n        additionalContext,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/create-subagent-branch.ts": "/**\n * Stacked PR branch creation hook\n *\n * SubagentStart hook that creates isolated branches for subagents when\n * stacked PR mode is enabled. Each subagent works on its own branch,\n * which gets pushed and PR'd on SubagentStop.\n *\n * This hook:\n * - Checks if stacked PR mode is enabled (env var, config, or auto-detect)\n * - Skips read-only agent types (Explore, Plan)\n * - Creates a new branch: {baseBranch}-subagent-{shortAgentId}\n * - Saves state to .claude/logs/stacked-branches.json\n *\n * The SubagentStop hook (stacked-pr-subagent-stop.ts) will then:\n * - Commit changes on the subagent branch\n * - Push to remote\n * - Create PR with auto-merge\n * - Checkout base branch (keeping main clean)\n * - Wait for CI and merge\n *\n * @module create-subagent-branch\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport {\n  isStackedPRModeEnabled,\n  getCurrentBranch,\n  generateSubagentBranchName,\n  createAndCheckoutBranch,\n  createStackedBranchEntry,\n} from '../shared/hooks/utils/stacked-branches.js';\n\n/**\n * SubagentStart hook handler that creates isolated branches\n *\n * When stacked PR mode is enabled, creates a new branch for the subagent\n * to work on. This isolates subagent changes from the main session.\n *\n * @param input - SubagentStart hook input with agent metadata\n * @returns Hook output (empty object, non-blocking)\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'create-subagent-branch', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n      session_id: input.session_id,\n    });\n\n    // Check if stacked PR mode is enabled for this agent\n    const enabled = await isStackedPRModeEnabled({\n      agent_type: input.agent_type,\n      cwd: input.cwd,\n    });\n\n    if (!enabled) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Stacked PR mode not enabled or agent type skipped',\n      });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SubagentStart',\n        },\n      };\n    }\n\n    // Get current branch (this is the main session's branch)\n    const baseBranch = await getCurrentBranch(input.cwd);\n    if (!baseBranch) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Not in a git repository',\n      });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SubagentStart',\n        },\n      };\n    }\n\n    // Generate subagent branch name\n    const branchName = generateSubagentBranchName(baseBranch, input.agent_id);\n\n    // Create and checkout the branch\n    const createResult = await createAndCheckoutBranch(input.cwd, branchName, baseBranch);\n\n    if (!createResult.success) {\n      await logger.logOutput({\n        success: false,\n        error: createResult.error,\n      });\n      // Don't block - just log the error and continue without stacked PR mode\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SubagentStart',\n        },\n      };\n    }\n\n    // Save to stacked branches state\n    await createStackedBranchEntry(input.cwd, {\n      agentId: input.agent_id,\n      parentSessionId: input.session_id,\n      branchName,\n      baseBranch,\n      createdAt: new Date().toISOString(),\n      prNumber: null,\n      prUrl: null,\n      status: 'active',\n      modifiedFiles: [],\n      commitSha: null,\n    });\n\n    await logger.logOutput({\n      success: true,\n      branchName,\n      baseBranch,\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n    // Don't block on errors - just log and continue\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/enhance-commit-context.ts": "/**\n * Enhance commit context with task and issue metadata\n *\n * PostToolUse[Bash] hook that detects git commits and enhances them with context:\n * - **Subagent commits**: Amends commit message with task prompt\n * - **Main agent commits**: Links commit to GitHub issue context\n * - **Future**: Triggers CI review workflow and returns blocking/non-blocking decision\n *\n * Handles both main agent and subagent tool call cases automatically.\n *\n * @module enhance-commit-context\n */\n\nimport type {\n  PostToolUseInput,\n  PostToolUseHookOutput,\n} from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { wasToolEventMainAgent } from '../shared/hooks/utils/was-tool-event-main-agent.js';\nimport { loadTaskCallContext } from '../shared/hooks/utils/task-state.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\ninterface PlanIssueState {\n  [sessionId: string]: {\n    planPath: string;\n    issueNumber: number;\n    issueUrl: string;\n    branch: string;\n    createdAt: string;\n    lastUpdated: string;\n  };\n}\n\ninterface ReviewDecision {\n  action: 'BLOCK' | 'APPROVE';\n  notes: string;\n  docsNeeded: string;\n}\n\n/**\n * Execute a shell command\n *\n * @param command - Command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag and output\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Load plan issue state from disk\n *\n * @param cwd - Working directory\n * @returns Plan issue state mapping\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Amend commit message with task prompt\n *\n * @param cwd - Working directory\n * @param prompt - Task prompt to append\n */\nasync function amendCommitWithPrompt(cwd: string, prompt: string): Promise<void> {\n  // Get current commit message\n  const msgResult = await execCommand('git log -1 --pretty=%B', cwd);\n  if (!msgResult.success) {\n    return;\n  }\n\n  const currentMsg = msgResult.stdout;\n\n  // Append prompt section\n  const enhancedMsg = `${currentMsg}\n\n---\n## Prompt\n${prompt}`;\n\n  // Amend commit (no-edit to avoid opening editor)\n  await execCommand(`git commit --amend --no-edit -m \"${enhancedMsg.replace(/\"/g, '\\\\\"')}\"`, cwd);\n}\n\n/**\n * Dispatch GitHub Actions workflow for commit review (future use)\n *\n * @param _cwd - Working directory\n * @param _sha - Commit SHA\n * @param _agentType - main or subagent\n * @param _contextType - issue, plan, or prompt\n * @param _contextId - Issue number or context identifier\n */\nasync function _dispatchReviewWorkflow(\n  _cwd: string,\n  _sha: string,\n  _agentType: string,\n  _contextType: string,\n  _contextId: string\n): Promise<void> {\n  // TODO: Implement when CI review is ready\n  // const payload = JSON.stringify({\n  //   event_type: 'commit_review',\n  //   client_payload: {\n  //     commit_sha: sha,\n  //     agent_type: agentType,\n  //     context_type: contextType,\n  //     context_id: contextId,\n  //   },\n  // });\n  // await execCommand(`gh api repos/:owner/:repo/dispatches -f ${payload}`, cwd);\n}\n\n/**\n * Poll for review comment on commit (future use)\n *\n * @param _cwd - Working directory\n * @param _sha - Commit SHA\n * @param _maxAttempts - Maximum polling attempts\n * @param _intervalMs - Polling interval in milliseconds\n * @returns Review comment body or null\n */\nasync function _pollForReviewComment(\n  _cwd: string,\n  _sha: string,\n  _maxAttempts = 60,\n  _intervalMs = 5000\n): Promise<string | null> {\n  // TODO: Implement when CI review is ready\n  // for (let i = 0; i < maxAttempts; i++) {\n  //   const result = await execCommand(\n  //     `gh api repos/:owner/:repo/commits/${sha}/comments --jq '.[].body'`,\n  //     cwd\n  //   );\n  //   if (result.success && result.stdout) {\n  //     const comments = result.stdout.split('\\n').filter(Boolean);\n  //     for (const comment of comments) {\n  //       if (comment.includes('## Commit Review') && comment.includes('DECISION:')) {\n  //         return comment;\n  //       }\n  //     }\n  //   }\n  //   await new Promise((resolve) => setTimeout(resolve, intervalMs));\n  // }\n  return null;\n}\n\n/**\n * Parse review decision from comment (future use)\n *\n * @param _comment - Review comment body\n * @returns Parsed review decision\n */\nfunction _parseReviewDecision(_comment: string): ReviewDecision {\n  // TODO: Implement when CI review is ready\n  // const decisionMatch = comment.match(/DECISION:\\s*(BLOCK|APPROVE)/);\n  // const notesMatch = comment.match(/NOTES:\\s*([\\s\\S]*?)(?=DOCUMENTATION_UPDATES:|$)/);\n  // const docsMatch = comment.match(/DOCUMENTATION_UPDATES:\\s*([\\s\\S]*?)$/);\n  return {\n    action: 'APPROVE',\n    notes: '',\n    docsNeeded: 'No documentation updates needed',\n  };\n}\n\n/**\n * PostToolUse[Bash] hook handler\n *\n * Detects git commits and enhances them with task context and CI review.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with review decision\n *\n * @example\n * ```typescript\n * // This hook is automatically called by Claude Code after Bash commands\n * ```\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'enhance-commit-context', true);\n\n  try {\n    // Only process if this is a Bash tool use\n    if (input.tool_name !== 'Bash') {\n      return {};\n    }\n\n    // Type-cast tool_input\n    const toolInput = input.tool_input as { command?: string };\n\n    // Check if git commit command\n    const command = toolInput.command;\n    if (!command || !command.includes('git commit')) {\n      return {};\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      command,\n    });\n\n    // Detect agent type\n    const isMainAgent = await wasToolEventMainAgent(input.cwd, input.session_id);\n\n    // Get latest commit SHA\n    const shaResult = await execCommand('git rev-parse HEAD', input.cwd);\n    if (!shaResult.success) {\n      await logger.logOutput({ skipped: true, reason: 'Could not get commit SHA' });\n      return {};\n    }\n\n    const sha = shaResult.stdout;\n\n    // Load context based on agent type\n    let contextType: string;\n    let contextId: string;\n\n    if (isMainAgent) {\n      // Main agent: get linked issue from plan-issues.json\n      const state = await loadPlanIssueState(input.cwd);\n      const sessionState = state[input.session_id];\n\n      if (sessionState) {\n        contextType = 'issue';\n        contextId = sessionState.issueNumber.toString();\n      } else {\n        contextType = 'none';\n        contextId = '';\n      }\n    } else {\n      // Subagent: get task prompt and amend commit\n      const taskContext = await loadTaskCallContext(input.cwd, input.session_id);\n\n      if (taskContext) {\n        await amendCommitWithPrompt(input.cwd, taskContext.prompt);\n        contextType = 'prompt';\n        contextId = 'embedded';\n      } else {\n        contextType = 'none';\n        contextId = '';\n      }\n    }\n\n    await logger.logOutput({\n      sha,\n      agent_type: isMainAgent ? 'main' : 'subagent',\n      context_type: contextType,\n      context_id: contextId,\n    });\n\n    // Note: CI review workflow dispatch and polling is disabled for now\n    // This will be implemented when the review-commit.yml workflow is fully configured\n    // For now, just allow the commit to proceed\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✅ Commit ${sha.substring(0, 7)} enhanced with ${contextType} context`,\n      },\n    };\n\n    /* TODO: Enable when CI review is ready\n\n    // Trigger review workflow\n    await dispatchReviewWorkflow(\n      input.cwd,\n      sha,\n      isMainAgent ? 'main' : 'subagent',\n      contextType,\n      contextId\n    );\n\n    // Poll for review comment\n    const review = await pollForReviewComment(input.cwd, sha);\n\n    if (!review) {\n      // Timeout - allow commit but warn\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: '⚠️ Commit review timed out - proceeding without review',\n        },\n      };\n    }\n\n    // Parse decision\n    const decision = parseReviewDecision(review);\n\n    await logger.logOutput({\n      decision: decision.action,\n      notes: decision.notes,\n      docs_needed: decision.docsNeeded,\n    });\n\n    // Return hook decision\n    if (decision.action === 'BLOCK') {\n      return {\n        decision: 'block',\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `⚠️ Commit review blocked:\\n\\n${decision.notes}\\n\\n${decision.docsNeeded}`,\n        },\n      };\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✅ Commit review approved:\\n\\n${decision.notes}\\n\\n${decision.docsNeeded}`,\n      },\n    };\n    */\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking - allow commit on error\n    // Return empty object to avoid showing errors to user\n    // Errors are already logged to hook-events.json for debugging\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/hooks.json": "{\n  \"_comment\": \"GitHub Orchestration Plugin - GitHub integration and CLI setup\",\n  \"_notes\": [\n    \"Installs GitHub CLI on remote, warns on local\",\n    \"Branch context and issue sync at session start\",\n    \"Creates GitHub issue on first user prompt\",\n    \"Tracks issues created during sessions for cross-session discovery\",\n    \"Surfaces related issues from previous sessions based on branch family\",\n    \"Commit enhancement with issue context\",\n    \"Auto-commit for subagent work\",\n    \"Stacked PR workflow: subagents work on isolated branches with auto-PR\",\n    \"Plan-to-issue synchronization with versioned update comments\",\n    \"Issue-to-plan synchronization (gh issue edit detection)\",\n    \"Task-to-subissue synchronization (excludes Plan/Explore)\",\n    \"Explore agent findings posted as issue comments\",\n    \"Auto-waits for CI checks after PR creation (gh pr create)\",\n    \"Auto-commit and PR status check on session end\"\n  ],\n  \"description\": \"GitHub integration with branch context, commit review, and issue orchestration\",\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/install-github.ts\",\n            \"description\": \"Installs GitHub CLI on remote, warns if missing on local\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/add-github-context.ts\",\n            \"description\": \"Displays branch issue context, sync status, and outstanding issues\"\n          }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/create-issue-on-prompt.ts\",\n            \"description\": \"Creates GitHub issue on first prompt, renames branch to {issueNum}-{type}/{name}\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/sync-plan-to-issue.ts\",\n            \"description\": \"Automatically creates/updates GitHub issues from plan files\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/track-issue-creation.ts\",\n            \"description\": \"Tracks issues created via gh issue create for cross-session discovery\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/enhance-commit-context.ts\",\n            \"description\": \"Enhances commits with task and issue context (both main and subagent)\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/await-pr-status.ts\",\n            \"description\": \"Waits for CI checks to complete after PR creation (gh pr create)\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/sync-issue-to-plan.ts\",\n            \"description\": \"Syncs gh issue edit body changes back to local plan file\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Task\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/sync-task-to-subissue.ts\",\n            \"description\": \"Creates GitHub subissues from Task tool prompts (excludes Plan/Explore agents)\"\n          }\n        ]\n      }\n    ],\n    \"SubagentStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/create-subagent-branch.ts\",\n            \"description\": \"Creates isolated branch for stacked PR workflow (when enabled)\"\n          }\n        ]\n      }\n    ],\n    \"SubagentStop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/post-explore-findings.ts\",\n            \"description\": \"Posts Explore agent findings as comments on linked GitHub issue\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/stacked-pr-subagent-stop.ts\",\n            \"timeout\": 900,\n            \"description\": \"Handles stacked PR workflow: push, create PR, auto-merge (when enabled)\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/commit-task-await-ci-status.ts\",\n            \"timeout\": 900,\n            \"description\": \"Auto-commits agent work with task context and waits for CI if triggered\"\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/commit-session-await-ci-status.ts\",\n            \"timeout\": 900,\n            \"description\": \"Auto-commits session changes, awaits CI checks, reports status with emoji table\"\n          }\n        ]\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/close-issue-on-session-end.ts\",\n            \"description\": \"Closes linked GitHub issue if session ends without PR\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/github-orchestration/hooks/install-github.ts": "/**\n * GitHub CLI Setup Hook\n * SessionStart hook that installs and configures GitHub CLI for the project.\n * On remote: always installs if missing. On local: warns if missing or outdated.\n * @module install-github\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\ninterface ExecResult {\n  success: boolean;\n  stdout: string;\n  stderr: string;\n}\n\n/**\n * Execute a shell command with error handling\n */\nasync function execCommand(\n  command: string,\n  options: { cwd?: string; timeout?: number; env?: Record<string, string> } = {}\n): Promise<ExecResult> {\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd: options.cwd,\n      timeout: options.timeout || 300000,\n      env: { ...process.env, ...options.env },\n    });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a command is available in PATH\n */\nasync function isCommandAvailable(command: string): Promise<boolean> {\n  const result = await execCommand(`which ${command}`);\n  return result.success && result.stdout.length > 0;\n}\n\n/**\n * Detect if running in remote (cloud) environment\n */\nfunction isRemoteEnvironment(): boolean {\n  return process.env.CLAUDE_CODE_ENTRYPOINT === 'remote';\n}\n\n/**\n * Get GitHub CLI version\n */\nasync function getGhVersion(): Promise<string | null> {\n  const result = await execCommand('gh --version');\n  if (result.success) {\n    const match = result.stdout.match(/gh version ([\\d.]+)/);\n    return match ? match[1] : null;\n  }\n  return null;\n}\n\n/**\n * Get latest GitHub CLI version from GitHub releases\n */\nasync function getLatestGhVersion(): Promise<string | null> {\n  const result = await execCommand(\n    'curl -s https://api.github.com/repos/cli/cli/releases/latest | grep tag_name',\n    { timeout: 15000 }\n  );\n  if (result.success) {\n    const match = result.stdout.match(/\"v?([\\d.]+)\"/);\n    return match ? match[1] : null;\n  }\n  return null;\n}\n\n/**\n * Compare semver versions\n */\nfunction isVersionOlder(v1: string, v2: string): boolean {\n  const parts1 = v1.split('.').map(Number);\n  const parts2 = v2.split('.').map(Number);\n  for (let i = 0; i < Math.max(parts1.length, parts2.length); i++) {\n    const p1 = parts1[i] || 0;\n    const p2 = parts2[i] || 0;\n    if (p1 < p2) return true;\n    if (p1 > p2) return false;\n  }\n  return false;\n}\n\n/**\n * Install GitHub CLI (gh) on Ubuntu\n */\nasync function installGitHubCLI(): Promise<ExecResult> {\n  if (await isCommandAvailable('gh')) {\n    return { success: true, stdout: 'gh already installed', stderr: '' };\n  }\n\n  const commands = [\n    'curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg',\n    'sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg',\n    'echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null',\n    'sudo apt-get update',\n    'sudo apt-get install -y gh',\n  ];\n\n  for (const cmd of commands) {\n    const result = await execCommand(cmd);\n    if (!result.success) {\n      return { success: false, stdout: '', stderr: `Failed to install gh: ${result.stderr}` };\n    }\n  }\n\n  return { success: true, stdout: 'gh installed successfully', stderr: '' };\n}\n\n/**\n * Check if GitHub CLI is authenticated\n */\nasync function isAuthenticated(): Promise<boolean> {\n  const result = await execCommand('gh auth status');\n  return result.success;\n}\n\n/**\n * SessionStart hook handler\n * On remote: installs gh if missing. On local: warns if missing or outdated.\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'setup-github', true);\n  const isRemote = isRemoteEnvironment();\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n      is_remote: isRemote,\n    });\n\n    const ghAvailable = await isCommandAvailable('gh');\n\n    if (!ghAvailable) {\n      if (isRemote) {\n        messages.push('Installing GitHub CLI...');\n        const installResult = await installGitHubCLI();\n        messages.push(installResult.success ? '✓ gh installed' : `⚠️ ${installResult.stderr}`);\n      } else {\n        messages.push('⚠️ GitHub CLI not installed');\n        messages.push('  Install: curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg && sudo apt install gh');\n      }\n    } else {\n      const ghVersion = await getGhVersion();\n      messages.push(`✓ GitHub CLI v${ghVersion || 'unknown'}`);\n\n      const latestVersion = await getLatestGhVersion();\n      if (ghVersion && latestVersion && isVersionOlder(ghVersion, latestVersion)) {\n        messages.push(`⚠️ Update available: v${latestVersion} (current: v${ghVersion})`);\n        if (!isRemote) {\n          messages.push('  Run: gh upgrade');\n        }\n      }\n\n      const authed = await isAuthenticated();\n      if (authed) {\n        messages.push('✓ GitHub CLI authenticated');\n      } else {\n        messages.push('⚠️ GitHub CLI not authenticated');\n        messages.push('  Run: gh auth login');\n      }\n    }\n\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      is_remote: isRemote,\n      message: finalMessage,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `GitHub CLI setup error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/post-explore-findings.ts": "/**\n * Post Explore agent findings to GitHub issues\n *\n * SubagentStop hook that automatically posts Explore agent findings as comments\n * on the linked GitHub issue. This creates a persistent record of codebase\n * exploration that can be referenced later.\n *\n * This hook:\n * - Only runs for Explore agents (other agent types are skipped)\n * - Extracts text content from the agent's transcript\n * - Posts findings as a collapsible comment on the linked issue\n * - Prevents duplicate comments using task ID markers\n *\n * @module post-explore-findings\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getTaskEdits } from '../shared/hooks/utils/task-state.js';\nimport { parseTranscript } from '../shared/hooks/utils/transcripts.js';\nimport { getLinkedIssueNumber, hasExploreComment, postExploreComment } from '../shared/hooks/utils/github-comments.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Get current git branch name\n */\nasync function getCurrentBranch(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : '';\n}\n\n/**\n * Extract all text content from an agent's transcript\n *\n * Combines all TextContent from AssistantMessage entries to get\n * the full text output from the agent.\n */\nfunction extractTextFromTranscript(messages: unknown[]): string {\n  const textParts: string[] = [];\n\n  for (const msg of messages) {\n    // Type guard for assistant messages\n    if (!msg || typeof msg !== 'object') continue;\n    const msgObj = msg as Record<string, unknown>;\n    if (msgObj.type !== 'assistant') continue;\n\n    // Navigate to content array\n    const message = msgObj.message as Record<string, unknown> | undefined;\n    if (!message?.content || !Array.isArray(message.content)) continue;\n\n    for (const content of message.content) {\n      if (!content || typeof content !== 'object') continue;\n      const contentObj = content as Record<string, unknown>;\n      if (contentObj.type === 'text' && typeof contentObj.text === 'string') {\n        textParts.push(contentObj.text);\n      }\n    }\n  }\n\n  return textParts.join('\\n\\n');\n}\n\n/**\n * SubagentStop hook handler for posting Explore agent findings\n *\n * @param input - SubagentStop hook input from Claude Code\n * @returns Hook output (empty on success)\n */\nasync function handler(\n  input: SubagentStopInput\n): Promise<SubagentStopHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'post-explore-findings', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_transcript_path: input.agent_transcript_path,\n    });\n\n    // Get task edits to determine agent type and prompt\n    let taskEdits;\n    try {\n      taskEdits = await getTaskEdits(input.agent_transcript_path);\n    } catch (error) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not analyze task edits',\n        error: String(error),\n      });\n      return {};\n    }\n\n    const { subagentType, agentPrompt, agentSessionId } = taskEdits;\n\n    // Only process Explore agents\n    if (subagentType.toLowerCase() !== 'explore') {\n      await logger.logOutput({\n        skipped: true,\n        reason: `Not an Explore agent (type: ${subagentType})`,\n      });\n      return {};\n    }\n\n    // Get current branch\n    const branch = await getCurrentBranch(input.cwd);\n    if (!branch) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not determine current branch',\n      });\n      return {};\n    }\n\n    // Find linked issue\n    const issueNumber = await getLinkedIssueNumber(branch, input.cwd);\n    if (!issueNumber) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'No linked issue found for branch',\n        branch,\n      });\n      return {};\n    }\n\n    // Use agent session ID as task ID for duplicate detection\n    const taskId = agentSessionId;\n\n    // Check for duplicate comment\n    const alreadyPosted = await hasExploreComment(issueNumber, taskId, input.cwd);\n    if (alreadyPosted) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Explore comment already posted for this task',\n        taskId,\n        issueNumber,\n      });\n      return {};\n    }\n\n    // Parse transcript to extract text findings\n    const transcript = await parseTranscript(input.agent_transcript_path);\n    const findings = extractTextFromTranscript(transcript.messages);\n\n    if (!findings || findings.trim().length === 0) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'No text findings in transcript',\n      });\n      return {};\n    }\n\n    // Post the comment\n    const posted = await postExploreComment(\n      issueNumber,\n      taskId,\n      agentPrompt,\n      findings,\n      branch,\n      input.cwd\n    );\n\n    if (posted) {\n      await logger.logOutput({\n        success: true,\n        issueNumber,\n        taskId,\n        findingsLength: findings.length,\n      });\n\n      return {\n        systemMessage: `📝 Posted Explore findings to issue #${issueNumber}`,\n      };\n    } else {\n      await logger.logOutput({\n        success: false,\n        reason: 'Failed to post comment',\n        issueNumber,\n      });\n      return {};\n    }\n  } catch (error) {\n    await logger.logError(error as Error);\n    // Non-blocking - just log and continue\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/stacked-pr-subagent-stop.ts": "/**\n * Stacked PR workflow completion hook\n *\n * SubagentStop hook that completes the stacked PR workflow when a subagent\n * finishes working on an isolated branch. This hook:\n *\n * 1. Checks if the subagent was working on a stacked branch\n * 2. Commits changes on the subagent branch\n * 3. Pushes to remote\n * 4. Checkouts the base branch (reverts local to clean state)\n * 5. Creates a PR with auto-merge enabled\n * 6. Waits for CI (configurable)\n * 7. Waits for merge and pulls changes (configurable)\n *\n * The workflow ensures the main session stays on a clean branch while\n * subagent work is isolated in separate PRs.\n *\n * @module stacked-pr-subagent-stop\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { getTaskEdits } from '../shared/hooks/utils/task-state.js';\nimport { awaitCIWithFailFast } from '../shared/hooks/utils/ci-status.js';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\nimport {\n  getStackedBranchEntry,\n  updateStackedBranchEntry,\n  loadSessionConfig,\n  checkoutBranch,\n  pushBranch,\n  stageAndCommit,\n  createPRWithAutoMerge,\n  waitForPRMerge,\n  pullLatest,\n  cleanupSubagentBranch,\n} from '../shared/hooks/utils/stacked-branches.js';\n\n/** Default timeout for CI waiting (10 minutes) */\nconst DEFAULT_CI_TIMEOUT = 600000;\n\ninterface TaskSubissueEntry {\n  prompt: string;\n  description: string;\n  subagentType: string;\n  parentIssueNumber: number;\n  subissueNumber: number;\n  subissueUrl: string;\n  branch: string;\n  createdAt: string;\n  planTaskId?: string;\n  nativeSubissue?: boolean;\n}\n\ninterface TaskSubissueState {\n  [taskId: string]: TaskSubissueEntry;\n}\n\n/**\n * Find subissue number for the current branch from task-subissues.json\n *\n * Looks for a subissue that was created for this branch.\n *\n * @param cwd - Current working directory\n * @param branch - Branch name to match\n * @returns Subissue number if found, null otherwise\n */\nasync function findSubissueForBranch(cwd: string, branch: string): Promise<number | null> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'task-subissues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    const state: TaskSubissueState = JSON.parse(data);\n\n    // Find subissue matching this branch\n    for (const entry of Object.values(state)) {\n      if (entry.branch === branch && entry.subissueNumber) {\n        return entry.subissueNumber;\n      }\n    }\n  } catch {\n    // State file doesn't exist or is invalid\n  }\n\n  return null;\n}\n\n/**\n * Format commit message for subagent work\n */\nfunction formatCommitMessage(options: {\n  agentType: string;\n  prompt: string;\n  filesEdited: number;\n  filesNew: number;\n  filesDeleted: number;\n}): string {\n  const { agentType, prompt, filesEdited, filesNew, filesDeleted } = options;\n\n  // Create concise title from prompt\n  const promptLines = prompt.split('\\n').map(l => l.trim()).filter(Boolean);\n  let title = promptLines[0] || 'Subagent task completed';\n\n  // Truncate title if too long\n  if (title.length > 60) {\n    title = title.slice(0, 57) + '...';\n  }\n\n  const lines: string[] = [];\n  lines.push(`[${agentType}] ${title}`);\n  lines.push('');\n  lines.push('Auto-generated from stacked PR workflow.');\n  lines.push('');\n  lines.push(`Files: ${filesNew} new, ${filesEdited} edited, ${filesDeleted} deleted`);\n\n  return lines.join('\\n');\n}\n\n/**\n * Format PR title for subagent work\n */\nfunction formatPRTitle(agentType: string, prompt: string): string {\n  const promptLines = prompt.split('\\n').map(l => l.trim()).filter(Boolean);\n  let title = promptLines[0] || 'Subagent task';\n\n  if (title.length > 60) {\n    title = title.slice(0, 57) + '...';\n  }\n\n  return `[${agentType}] ${title}`;\n}\n\n/**\n * Format PR body for subagent work\n */\nfunction formatPRBody(options: {\n  agentType: string;\n  prompt: string;\n  baseBranch: string;\n  filesNew: string[];\n  filesEdited: string[];\n  filesDeleted: string[];\n  subissueNumber?: number | null;\n}): string {\n  const { agentType, prompt, baseBranch, filesNew, filesEdited, filesDeleted, subissueNumber } = options;\n\n  const lines: string[] = [];\n  lines.push('## Summary');\n  lines.push('');\n  lines.push(`Auto-generated PR from stacked PR workflow (${agentType} agent).`);\n  lines.push('');\n  lines.push('### Task');\n  lines.push('');\n  lines.push('```');\n  lines.push(prompt.slice(0, 500) + (prompt.length > 500 ? '...' : ''));\n  lines.push('```');\n  lines.push('');\n  lines.push('### Changes');\n  lines.push('');\n\n  if (filesNew.length > 0) {\n    lines.push(`**New files (${filesNew.length}):**`);\n    for (const f of filesNew.slice(0, 10)) {\n      lines.push(`- \\`${f}\\``);\n    }\n    if (filesNew.length > 10) {\n      lines.push(`- ... and ${filesNew.length - 10} more`);\n    }\n    lines.push('');\n  }\n\n  if (filesEdited.length > 0) {\n    lines.push(`**Edited files (${filesEdited.length}):**`);\n    for (const f of filesEdited.slice(0, 10)) {\n      lines.push(`- \\`${f}\\``);\n    }\n    if (filesEdited.length > 10) {\n      lines.push(`- ... and ${filesEdited.length - 10} more`);\n    }\n    lines.push('');\n  }\n\n  if (filesDeleted.length > 0) {\n    lines.push(`**Deleted files (${filesDeleted.length}):**`);\n    for (const f of filesDeleted.slice(0, 10)) {\n      lines.push(`- \\`${f}\\``);\n    }\n    if (filesDeleted.length > 10) {\n      lines.push(`- ... and ${filesDeleted.length - 10} more`);\n    }\n    lines.push('');\n  }\n\n  lines.push('---');\n  lines.push(`Base: \\`${baseBranch}\\``);\n  lines.push('');\n\n  // Add Closes #X to auto-close the linked subissue when PR merges\n  if (subissueNumber) {\n    lines.push(`Closes #${subissueNumber}`);\n    lines.push('');\n  }\n\n  lines.push('*This PR was auto-generated by the stacked PR workflow.*');\n\n  return lines.join('\\n');\n}\n\n/**\n * SubagentStop hook handler for stacked PR workflow\n *\n * @param input - SubagentStop hook input from Claude Code\n * @returns Hook output with decision if blocking\n */\nasync function handler(\n  input: SubagentStopInput\n): Promise<SubagentStopHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'stacked-pr-subagent-stop', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_transcript_path: input.agent_transcript_path,\n    });\n\n    // Check if this agent has a stacked branch entry\n    const entry = await getStackedBranchEntry(input.cwd, input.agent_id);\n\n    if (!entry || entry.status !== 'active') {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'No active stacked branch for this agent',\n      });\n      return {};\n    }\n\n    // Get task edits (file operations and prompt)\n    let taskEdits;\n    try {\n      taskEdits = await getTaskEdits(input.agent_transcript_path);\n    } catch (error) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not analyze task edits',\n        error: String(error),\n      });\n      // Cleanup and return to base branch\n      await cleanupSubagentBranch(input.cwd, entry);\n      return {};\n    }\n\n    const {\n      subagentType,\n      agentPrompt,\n      agentNewFiles,\n      agentEditedFiles,\n      agentDeletedFiles,\n    } = taskEdits;\n\n    // Combine all modified files\n    const allModifiedFiles = [\n      ...agentNewFiles,\n      ...agentEditedFiles,\n      ...agentDeletedFiles,\n    ];\n\n    // If no changes, cleanup and return\n    if (allModifiedFiles.length === 0) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'No files modified by agent',\n      });\n      await cleanupSubagentBranch(input.cwd, entry);\n      return {};\n    }\n\n    // Stage and commit changes on subagent branch\n    const commitMessage = formatCommitMessage({\n      agentType: subagentType,\n      prompt: agentPrompt,\n      filesEdited: agentEditedFiles.length,\n      filesNew: agentNewFiles.length,\n      filesDeleted: agentDeletedFiles.length,\n    });\n\n    const commitResult = await stageAndCommit(input.cwd, allModifiedFiles, commitMessage);\n\n    if (!commitResult.success) {\n      await logger.logOutput({\n        success: false,\n        stage: 'commit',\n        error: commitResult.error,\n      });\n      await updateStackedBranchEntry(input.cwd, input.agent_id, {\n        status: 'failed',\n        error: commitResult.error,\n      });\n      // Still checkout base branch to keep main clean\n      await checkoutBranch(input.cwd, entry.baseBranch);\n      return {};\n    }\n\n    // Update state with commit info\n    await updateStackedBranchEntry(input.cwd, input.agent_id, {\n      commitSha: commitResult.commitSha || null,\n      modifiedFiles: allModifiedFiles,\n    });\n\n    // Push branch to remote\n    const pushResult = await pushBranch(input.cwd, entry.branchName);\n\n    if (!pushResult.success) {\n      await logger.logOutput({\n        success: false,\n        stage: 'push',\n        error: pushResult.error,\n      });\n      await updateStackedBranchEntry(input.cwd, input.agent_id, {\n        status: 'failed',\n        error: pushResult.error,\n      });\n      // Still checkout base branch\n      await checkoutBranch(input.cwd, entry.baseBranch);\n      return {};\n    }\n\n    // CRITICAL: Checkout base branch BEFORE creating PR\n    // This keeps the main session on a clean branch\n    const checkoutResult = await checkoutBranch(input.cwd, entry.baseBranch);\n\n    if (!checkoutResult.success) {\n      await logger.logOutput({\n        success: false,\n        stage: 'checkout-base',\n        error: checkoutResult.error,\n      });\n      // This is a problem - we're stuck on the subagent branch\n      return {\n        decision: 'block',\n        reason: `Failed to return to base branch: ${checkoutResult.error}`,\n      };\n    }\n\n    // Look up any subissue that was created for this branch\n    // This allows the PR to auto-close the subissue when merged\n    const subissueNumber = await findSubissueForBranch(input.cwd, entry.branchName);\n\n    // Create PR with auto-merge\n    const prTitle = formatPRTitle(subagentType, agentPrompt);\n    const prBody = formatPRBody({\n      agentType: subagentType,\n      prompt: agentPrompt,\n      baseBranch: entry.baseBranch,\n      filesNew: agentNewFiles,\n      filesEdited: agentEditedFiles,\n      filesDeleted: agentDeletedFiles,\n      subissueNumber,\n    });\n\n    const prResult = await createPRWithAutoMerge(input.cwd, {\n      head: entry.branchName,\n      base: entry.baseBranch,\n      title: prTitle,\n      body: prBody,\n    });\n\n    if (!prResult.success) {\n      await logger.logOutput({\n        success: false,\n        stage: 'create-pr',\n        error: prResult.error,\n      });\n      await updateStackedBranchEntry(input.cwd, input.agent_id, {\n        status: 'failed',\n        error: prResult.error,\n      });\n      return {};\n    }\n\n    // Update state with PR info\n    await updateStackedBranchEntry(input.cwd, input.agent_id, {\n      prNumber: prResult.prNumber || null,\n      prUrl: prResult.prUrl || null,\n      status: 'ci-pending',\n    });\n\n    // Get configuration for CI waiting\n    const config = await loadSessionConfig(input.cwd);\n    const waitForCI = config?.stackedPrConfig?.waitForCI ?? true;\n    const waitForMerge = config?.stackedPrConfig?.waitForMerge ?? true;\n\n    let ciPassed = false;\n\n    // Wait for CI if configured\n    if (waitForCI && prResult.prNumber) {\n      const ciResult = await awaitCIWithFailFast(\n        { prNumber: prResult.prNumber, timeout: DEFAULT_CI_TIMEOUT },\n        input.cwd\n      );\n\n      if (!ciResult.success) {\n        await logger.logOutput({\n          success: false,\n          stage: 'ci',\n          error: ciResult.blockReason,\n          prNumber: prResult.prNumber,\n          prUrl: prResult.prUrl,\n        });\n        await updateStackedBranchEntry(input.cwd, input.agent_id, {\n          status: 'failed',\n          error: ciResult.blockReason,\n        });\n        // Don't block - CI failure is logged, user can fix manually\n        return {\n          systemMessage: `⚠️ CI failed for PR #${prResult.prNumber}: ${ciResult.blockReason}\\nPR: ${prResult.prUrl}`,\n        };\n      }\n\n      ciPassed = true;\n    }\n\n    // Wait for merge if CI passed and configured\n    if (waitForMerge && ciPassed && prResult.prNumber) {\n      const mergeResult = await waitForPRMerge(input.cwd, prResult.prNumber);\n\n      if (mergeResult.success) {\n        // Pull merged changes\n        await pullLatest(input.cwd, entry.baseBranch);\n\n        await updateStackedBranchEntry(input.cwd, input.agent_id, {\n          status: 'merged',\n        });\n\n        await logger.logOutput({\n          success: true,\n          stage: 'merged',\n          prNumber: prResult.prNumber,\n          prUrl: prResult.prUrl,\n          filesModified: allModifiedFiles.length,\n        });\n\n        return {\n          systemMessage: `✅ Subagent PR #${prResult.prNumber} merged and changes pulled.\\nPR: ${prResult.prUrl}`,\n        };\n      } else {\n        await logger.logOutput({\n          success: false,\n          stage: 'merge-wait',\n          error: mergeResult.error,\n          prNumber: prResult.prNumber,\n        });\n        // Don't block - merge might take longer\n      }\n    }\n\n    // Success - PR created (possibly still pending merge)\n    await logger.logOutput({\n      success: true,\n      stage: 'pr-created',\n      prNumber: prResult.prNumber,\n      prUrl: prResult.prUrl,\n      filesModified: allModifiedFiles.length,\n      ciPassed,\n      waitingForMerge: waitForMerge && ciPassed,\n    });\n\n    return {\n      systemMessage: `🔀 Created PR #${prResult.prNumber} for subagent work.\\nPR: ${prResult.prUrl}`,\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Try to return to base branch on error\n    try {\n      const entry = await getStackedBranchEntry(input.cwd, input.agent_id);\n      if (entry) {\n        await checkoutBranch(input.cwd, entry.baseBranch);\n        await updateStackedBranchEntry(input.cwd, input.agent_id, {\n          status: 'failed',\n          error: String(error),\n        });\n      }\n    } catch {\n      // Ignore cleanup errors\n    }\n\n    // Don't block on errors\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/sync-issue-to-plan.ts": "/**\n * Issue-to-plan synchronization hook\n *\n * PostToolUse hook that detects when Claude uses `gh issue edit` to modify\n * an issue body and syncs those changes back to the local plan file.\n *\n * This hook provides:\n * - **Bidirectional sync** - Issue body changes sync back to plan file\n * - **Internal operations only** - Only catches Claude's gh commands, not external edits\n * - **State tracking** - Updates plan-issues.json with new version\n *\n * @module sync-issue-to-plan\n */\n\nimport type { PostToolUseInputTyped, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\ninterface PlanIssueState {\n  [sessionId: string]: {\n    planPath: string;\n    issueNumber: number;\n    issueUrl: string;\n    branch: string;\n    createdAt: string;\n    lastUpdated: string;\n    version: number;\n  };\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Load plan issue state from disk\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Save plan issue state to disk\n */\nasync function savePlanIssueState(cwd: string, state: PlanIssueState): Promise<void> {\n  const stateDir = path.join(cwd, '.claude', 'logs');\n  const stateFile = path.join(stateDir, 'plan-issues.json');\n\n  await fs.mkdir(stateDir, { recursive: true });\n  await fs.writeFile(stateFile, JSON.stringify(state, null, 2));\n}\n\n/**\n * Extract issue number from gh issue edit command\n *\n * Handles patterns like:\n * - gh issue edit 123 --body \"...\"\n * - gh issue edit 123 --body-file -\n * - gh issue edit 123 --title \"...\" --body \"...\"\n */\nfunction extractIssueNumber(command: string): number | null {\n  // Match: gh issue edit <number>\n  const match = command.match(/gh\\s+issue\\s+edit\\s+(\\d+)/);\n  if (match) {\n    return parseInt(match[1], 10);\n  }\n  return null;\n}\n\n/**\n * Check if command is a gh issue edit with body change\n */\nfunction isBodyEditCommand(command: string): boolean {\n  if (!command.includes('gh issue edit')) {\n    return false;\n  }\n  // Check for --body or --body-file flag\n  return command.includes('--body') || command.includes('--body-file');\n}\n\n/**\n * Fetch issue body from GitHub\n */\nasync function fetchIssueBody(issueNumber: number, cwd: string): Promise<string | null> {\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json body --jq '.body'`,\n    cwd\n  );\n\n  if (result.success && result.stdout) {\n    return result.stdout;\n  }\n  return null;\n}\n\n/**\n * Extract plan content from issue body\n *\n * Issue body format:\n * **Branch:** `branch-name`\n * **Plan file:** `/path/to/plan.md`\n *\n * ---\n *\n * <plan content here>\n */\nfunction extractPlanContent(issueBody: string): string {\n  // Find the --- separator and return everything after it\n  const separatorIndex = issueBody.indexOf('\\n---\\n');\n  if (separatorIndex !== -1) {\n    return issueBody.slice(separatorIndex + 5).trim();\n  }\n  // If no separator, return the whole body (might be manually edited)\n  return issueBody.trim();\n}\n\n/**\n * Find session ID for a given issue number\n */\nfunction findSessionForIssue(\n  state: PlanIssueState,\n  issueNumber: number\n): { sessionId: string; entry: PlanIssueState[string] } | null {\n  for (const [sessionId, entry] of Object.entries(state)) {\n    if (entry.issueNumber === issueNumber) {\n      return { sessionId, entry };\n    }\n  }\n  return null;\n}\n\n/**\n * PostToolUse hook handler for issue-to-plan sync\n *\n * Detects gh issue edit commands and syncs body changes back to plan file.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with sync status\n */\nasync function handler(input: PostToolUseInputTyped): Promise<PostToolUseHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'sync-issue-to-plan', true);\n\n  try {\n    // Only process Bash tool\n    if (input.tool_name !== 'Bash') {\n      return {};\n    }\n\n    // Get command from input\n    const command = (input as Extract<PostToolUseInputTyped, { tool_name: 'Bash' }>).tool_input.command;\n\n    // Check if this is a gh issue edit with body change\n    if (!isBodyEditCommand(command)) {\n      return {};\n    }\n\n    // Extract issue number\n    const issueNumber = extractIssueNumber(command);\n    if (!issueNumber) {\n      return {};\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      tool_name: input.tool_name,\n      command,\n      issueNumber,\n    });\n\n    // Load plan state to find associated plan file\n    const planState = await loadPlanIssueState(input.cwd);\n    const sessionInfo = findSessionForIssue(planState, issueNumber);\n\n    if (!sessionInfo) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'No plan file associated with this issue',\n        issueNumber,\n      });\n      return {};\n    }\n\n    const { sessionId, entry } = sessionInfo;\n\n    // Fetch the new issue body\n    const issueBody = await fetchIssueBody(issueNumber, input.cwd);\n    if (!issueBody) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not fetch issue body',\n        issueNumber,\n      });\n      return {};\n    }\n\n    // Extract plan content from issue body\n    const planContent = extractPlanContent(issueBody);\n\n    // Update the local plan file\n    await fs.writeFile(entry.planPath, planContent, 'utf-8');\n\n    // Update state with new version\n    const newVersion = (entry.version || 0) + 1;\n    planState[sessionId] = {\n      ...entry,\n      lastUpdated: new Date().toISOString(),\n      version: newVersion,\n    };\n    await savePlanIssueState(input.cwd, planState);\n\n    await logger.logOutput({\n      success: true,\n      issueNumber,\n      planPath: entry.planPath,\n      version: newVersion,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `↻ Synced issue #${issueNumber} body to plan file: ${entry.planPath} (v${newVersion})`,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking error - just inform Claude\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠ Could not sync issue to plan: ${error instanceof Error ? error.message : String(error)}`,\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/sync-plan-to-issue.ts": "/**\n * Plan-to-issue synchronization hook\n *\n * PostToolUse hook that automatically creates GitHub issues from plan files when\n * they are written or edited. Maintains a 1:1 relationship between plan sessions\n * and GitHub issues for better project tracking and collaboration.\n *\n * This hook provides:\n * - **Automatic issue creation** - Creates issue on first plan Write/Edit\n * - **Duplicate prevention** - Tracks created issues to avoid duplicates on plan updates\n * - **Branch linking** - Associates issues with the current branch\n * - **Auto-close on merge** - Issues close automatically when PR is merged (via \"Closes #N\" syntax)\n *\n * State is tracked in .claude/logs/plan-issues.json to remember which plan\n * sessions have already created issues.\n *\n * @module sync-plan-to-issue\n */\n\nimport type { PostToolUseInputTyped, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { postPlanUpdateComment } from '../shared/hooks/utils/github-comments.js';\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\ninterface PlanIssueState {\n  [sessionId: string]: {\n    planPath: string;\n    issueNumber: number;\n    issueUrl: string;\n    branch: string;\n    createdAt: string;\n    lastUpdated: string;\n    version: number;\n  };\n}\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n * This avoids shell escaping issues when passing markdown content\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    // Write body to stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n/**\n * Get current git branch name\n */\nasync function getCurrentBranch(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : '';\n}\n\n/**\n * Check if gh CLI is available and authenticated\n */\nasync function isGhAvailable(cwd: string): Promise<boolean> {\n  const authCheck = await execCommand('gh auth status', cwd);\n  return authCheck.success;\n}\n\n/**\n * Extract plan title from content (first # heading or filename)\n */\nfunction extractPlanTitle(content: string, filePath: string): string {\n  const headingMatch = content.match(/^#\\s+(.+)$/m);\n  if (headingMatch) {\n    return headingMatch[1].trim();\n  }\n\n  // Fallback to filename without extension\n  const basename = path.basename(filePath, '.md');\n  return basename.charAt(0).toUpperCase() + basename.slice(1);\n}\n\n/**\n * Load plan issue state from disk\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Load branch issue state from disk\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Save plan issue state to disk\n */\nasync function savePlanIssueState(cwd: string, state: PlanIssueState): Promise<void> {\n  const stateDir = path.join(cwd, '.claude', 'logs');\n  const stateFile = path.join(stateDir, 'plan-issues.json');\n\n  await fs.mkdir(stateDir, { recursive: true });\n  await fs.writeFile(stateFile, JSON.stringify(state, null, 2));\n}\n\n/**\n * Create or update GitHub issue from plan content\n *\n * Priority for finding existing issue:\n * 1. Check branch-issues.json (created by UserPromptSubmit hook)\n * 2. Check plan-issues.json (created by previous plan syncs)\n * 3. Create new issue if none found\n */\nasync function syncPlanToIssue(\n  cwd: string,\n  sessionId: string,\n  planPath: string,\n  planContent: string,\n  branch: string\n): Promise<{ issueNumber: number; issueUrl: string; action: 'created' | 'updated'; version: number }> {\n  const planState = await loadPlanIssueState(cwd);\n  const branchState = await loadBranchIssueState(cwd);\n\n  const title = extractPlanTitle(planContent, planPath);\n\n  // Prepare issue body with branch reference\n  const body = `**Branch:** \\`${branch}\\`\n**Plan file:** \\`${planPath}\\`\n\n---\n\n${planContent}`;\n\n  // PRIORITY 1: Check branch-issues.json (from UserPromptSubmit hook)\n  const branchIssue = branchState[branch];\n  if (branchIssue && branchIssue.issueNumber) {\n    // Update existing branch issue with plan content\n    const result = await execGhWithStdin(\n      ['issue', 'edit', String(branchIssue.issueNumber), '--title', title, '--body-file', '-'],\n      body,\n      cwd\n    );\n\n    if (result.success) {\n      // Get current version or start at 1\n      const existingPlanState = planState[sessionId];\n      const newVersion = existingPlanState?.version ? existingPlanState.version + 1 : 1;\n\n      // Also save to plan-issues.json for consistency\n      planState[sessionId] = {\n        planPath,\n        issueNumber: branchIssue.issueNumber,\n        issueUrl: branchIssue.issueUrl,\n        branch,\n        createdAt: branchIssue.createdAt,\n        lastUpdated: new Date().toISOString(),\n        version: newVersion,\n      };\n      await savePlanIssueState(cwd, planState);\n\n      return {\n        issueNumber: branchIssue.issueNumber,\n        issueUrl: branchIssue.issueUrl,\n        action: 'updated',\n        version: newVersion,\n      };\n    }\n  }\n\n  // PRIORITY 2: Check plan-issues.json (from previous plan syncs)\n  const existing = planState[sessionId];\n  if (existing && existing.issueNumber) {\n    // Update existing issue using stdin to avoid shell escaping issues\n    const result = await execGhWithStdin(\n      ['issue', 'edit', String(existing.issueNumber), '--body-file', '-'],\n      body,\n      cwd\n    );\n\n    if (result.success) {\n      // Increment version\n      const newVersion = (existing.version || 0) + 1;\n\n      // Update state\n      existing.lastUpdated = new Date().toISOString();\n      existing.version = newVersion;\n      await savePlanIssueState(cwd, planState);\n\n      return {\n        issueNumber: existing.issueNumber,\n        issueUrl: existing.issueUrl,\n        action: 'updated',\n        version: newVersion,\n      };\n    }\n  }\n\n  // PRIORITY 3: Create new issue\n  const result = await execGhWithStdin(\n    ['issue', 'create', '--title', title, '--body-file', '-', '--label', 'plan'],\n    body,\n    cwd\n  );\n\n  if (!result.success) {\n    throw new Error(`Failed to create issue: ${result.stderr || result.stdout}`);\n  }\n\n  // Extract issue URL from output\n  const issueUrl = result.stdout.match(/https:\\/\\/github\\.com\\/[^\\s]+/)?.[0] || '';\n  const issueNumber = parseInt(issueUrl.match(/\\/(\\d+)$/)?.[1] || '0', 10);\n\n  if (!issueNumber) {\n    throw new Error('Failed to extract issue number from gh output');\n  }\n\n  // Save state with version 1\n  planState[sessionId] = {\n    planPath,\n    issueNumber,\n    issueUrl,\n    branch,\n    createdAt: new Date().toISOString(),\n    lastUpdated: new Date().toISOString(),\n    version: 1,\n  };\n  await savePlanIssueState(cwd, planState);\n\n  return { issueNumber, issueUrl, action: 'created', version: 1 };\n}\n\n/**\n * PostToolUse hook handler for plan file sync\n *\n * Detects plan file writes/edits and syncs them to GitHub issues.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with issue creation status\n */\nasync function handler(input: PostToolUseInputTyped): Promise<PostToolUseHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'sync-plan-to-issue', true);\n\n  try {\n    // Only process Write and Edit tools\n    if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n      return {};\n    }\n\n    // Type narrowing: at this point, input is Write or Edit\n    const filePath = (input as Extract<PostToolUseInputTyped, { tool_name: 'Write' | 'Edit' }>).tool_input.file_path;\n\n    // Detect if this is a plan file\n    const isInPlansDir = filePath.includes('/.claude/plans/');\n    const isPlanMode = input.permission_mode === 'plan';\n\n    if (!isInPlansDir && !isPlanMode) {\n      // Not a plan file\n      return {};\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      tool_name: input.tool_name,\n      file_path: filePath,\n      permission_mode: input.permission_mode,\n    });\n\n    // Check if we're in a git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', input.cwd);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {};\n    }\n\n    // Check if gh CLI is available\n    if (!(await isGhAvailable(input.cwd))) {\n      await logger.logOutput({ skipped: true, reason: 'gh CLI not authenticated' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: '⚠ Cannot sync plan to GitHub: gh CLI not authenticated. Run: gh auth login',\n        },\n      };\n    }\n\n    // Get current branch\n    const branch = await getCurrentBranch(input.cwd);\n    if (!branch) {\n      await logger.logOutput({ skipped: true, reason: 'Could not determine current branch' });\n      return {};\n    }\n\n    // Get plan content\n    let planContent: string;\n    if (input.tool_name === 'Write') {\n      // Write has full content in tool_input\n      planContent = (input as Extract<PostToolUseInputTyped, { tool_name: 'Write' }>).tool_input.content;\n    } else {\n      // Edit - must read file to get full content\n      planContent = await fs.readFile(filePath, 'utf-8');\n    }\n\n    // Sync to GitHub issue\n    const result = await syncPlanToIssue(\n      input.cwd,\n      input.session_id,\n      filePath,\n      planContent,\n      branch\n    );\n\n    // Post update comment for audit trail\n    await postPlanUpdateComment(\n      result.issueNumber,\n      result.version,\n      result.action,\n      filePath,\n      branch,\n      input.cwd\n    );\n\n    await logger.logOutput({\n      action: result.action,\n      issue_number: result.issueNumber,\n      issue_url: result.issueUrl,\n      version: result.version,\n      branch,\n    });\n\n    const emoji = result.action === 'created' ? '✓' : '↻';\n    const verb = result.action === 'created' ? 'Created' : 'Updated';\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `${emoji} ${verb} GitHub issue #${result.issueNumber} (v${result.version}) from plan: ${result.issueUrl}\\n\\nTo link this issue to your PR, add \"Closes #${result.issueNumber}\" to the PR description.`,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking error - just inform Claude\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠ Could not sync plan to GitHub issue: ${error instanceof Error ? error.message : String(error)}`,\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/sync-task-to-subissue.ts": "/**\n * Task-to-subissue synchronization hook\n *\n * PostToolUse hook that automatically creates GitHub subissues from Task tool calls.\n * Creates a linked subissue for each non-Plan/Explore agent task.\n *\n * This hook provides:\n * - **Automatic subissue creation** - Creates subissue when Task tool is called\n * - **Agent filtering** - Skips Plan and Explore agents (too transient)\n * - **Parent linking** - Links subissue to branch's parent issue\n * - **Duplicate prevention** - Tracks created subissues to avoid duplicates\n * - **Structured task support** - Detects task IDs from plan frontmatter\n *\n * State is tracked in .claude/logs/task-subissues.json to remember which\n * tasks have already created subissues.\n *\n * Structured tasks: If a Task prompt contains \"taskId: <id>\" or references\n * a task from the active plan, the subissue will include that context.\n *\n * @module sync-task-to-subissue\n */\n\nimport type { PostToolUseInputTyped, PostToolUseHookOutput, TaskToolInput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { addNativeSubissue } from '../shared/hooks/utils/native-subissues.js';\nimport { spawn } from 'node:child_process';\nimport { exec } from 'node:child_process';\nimport { promisify } from 'node:util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\nimport crypto from 'node:crypto';\n\nconst execAsync = promisify(exec);\n\n/** Agents to exclude from subissue creation (too transient/exploratory) */\nconst EXCLUDED_AGENTS = ['Plan', 'Explore', 'plan', 'explore'];\n\ninterface TaskSubissueEntry {\n  prompt: string;\n  description: string;\n  subagentType: string;\n  parentIssueNumber: number;\n  subissueNumber: number;\n  subissueUrl: string;\n  branch: string;\n  createdAt: string;\n  /** Structured task ID if referenced in prompt */\n  planTaskId?: string;\n  /** Whether native GitHub sub-issues API was used */\n  nativeSubissue?: boolean;\n}\n\n/**\n * Extract task ID from prompt if present\n *\n * Looks for patterns like:\n * - \"taskId: auth-backend\"\n * - \"[task: auth-backend]\"\n * - \"task id: auth-backend\"\n */\nfunction extractTaskIdFromPrompt(prompt: string): string | undefined {\n  // Pattern: taskId: <id> or task id: <id> or [task: <id>]\n  const patterns = [\n    /taskId:\\s*(\\S+)/i,\n    /task\\s*id:\\s*(\\S+)/i,\n    /\\[task:\\s*(\\S+)\\]/i,\n  ];\n\n  for (const pattern of patterns) {\n    const match = prompt.match(pattern);\n    if (match) {\n      return match[1].replace(/['\"`,]/g, ''); // Clean up quotes/punctuation\n    }\n  }\n\n  return undefined;\n}\n\ninterface TaskSubissueState {\n  [taskId: string]: TaskSubissueEntry;\n}\n\ninterface BranchIssueEntry {\n  issueNumber: number;\n  issueUrl: string;\n  createdAt: string;\n  createdFromPrompt: boolean;\n  linkedFromBranchPrefix?: boolean;\n}\n\ninterface BranchIssueState {\n  [branchName: string]: BranchIssueEntry;\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n/**\n * Get current git branch name\n */\nasync function getCurrentBranch(cwd: string): Promise<string> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : '';\n}\n\n/**\n * Check if gh CLI is available and authenticated\n */\nasync function isGhAvailable(cwd: string): Promise<boolean> {\n  const authCheck = await execCommand('gh auth status', cwd);\n  return authCheck.success;\n}\n\n/**\n * Generate unique task ID from prompt (first 100 chars hashed)\n */\nfunction generateTaskId(prompt: string, description: string): string {\n  const content = `${description}:${prompt.slice(0, 100)}`;\n  return crypto.createHash('md5').update(content).digest('hex').slice(0, 12);\n}\n\n/**\n * Load task subissue state from disk\n */\nasync function loadTaskSubissueState(cwd: string): Promise<TaskSubissueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'task-subissues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Load branch issue state from disk\n */\nasync function loadBranchIssueState(cwd: string): Promise<BranchIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'branch-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Save task subissue state to disk\n */\nasync function saveTaskSubissueState(cwd: string, state: TaskSubissueState): Promise<void> {\n  const stateDir = path.join(cwd, '.claude', 'logs');\n  const stateFile = path.join(stateDir, 'task-subissues.json');\n\n  await fs.mkdir(stateDir, { recursive: true });\n  await fs.writeFile(stateFile, JSON.stringify(state, null, 2));\n}\n\n/**\n * Create a subissue linked to parent issue\n */\nasync function createSubissue(\n  cwd: string,\n  parentIssueNumber: number,\n  title: string,\n  body: string\n): Promise<{ issueNumber: number; issueUrl: string }> {\n  const result = await execGhWithStdin(\n    ['issue', 'create', '--title', title, '--body-file', '-', '--label', 'task', '--label', 'subissue'],\n    body,\n    cwd\n  );\n\n  if (!result.success) {\n    throw new Error(`Failed to create subissue: ${result.stderr || result.stdout}`);\n  }\n\n  const issueUrl = result.stdout.match(/https:\\/\\/github\\.com\\/[^\\s]+/)?.[0] || '';\n  const issueNumber = parseInt(issueUrl.match(/\\/(\\d+)$/)?.[1] || '0', 10);\n\n  if (!issueNumber) {\n    throw new Error('Failed to extract issue number from gh output');\n  }\n\n  return { issueNumber, issueUrl };\n}\n\n/**\n * PostToolUse hook handler for Task tool sync\n *\n * Detects Task tool calls and creates linked subissues.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with subissue creation status\n */\nasync function handler(input: PostToolUseInputTyped): Promise<PostToolUseHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'sync-task-to-subissue', true);\n\n  try {\n    // Only process Task tool\n    if (input.tool_name !== 'Task') {\n      return {};\n    }\n\n    // Type narrowing for Task tool\n    const taskInput = input.tool_input as TaskToolInput;\n    const { prompt, description, subagent_type } = taskInput;\n\n    // Skip excluded agents (Plan, Explore)\n    if (EXCLUDED_AGENTS.includes(subagent_type)) {\n      await logger.logOutput({ skipped: true, reason: `Excluded agent type: ${subagent_type}` });\n      return {};\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      tool_name: input.tool_name,\n      subagent_type,\n      description,\n    });\n\n    // Check if we're in a git repository\n    const gitCheck = await execCommand('git rev-parse --is-inside-work-tree', input.cwd);\n    if (!gitCheck.success) {\n      await logger.logOutput({ skipped: true, reason: 'Not a git repository' });\n      return {};\n    }\n\n    // Check if gh CLI is available\n    if (!(await isGhAvailable(input.cwd))) {\n      await logger.logOutput({ skipped: true, reason: 'gh CLI not authenticated' });\n      return {};\n    }\n\n    // Get current branch\n    const branch = await getCurrentBranch(input.cwd);\n    if (!branch) {\n      await logger.logOutput({ skipped: true, reason: 'Could not determine current branch' });\n      return {};\n    }\n\n    // Get parent issue from branch-issues.json\n    const branchState = await loadBranchIssueState(input.cwd);\n    const branchIssue = branchState[branch];\n\n    if (!branchIssue || !branchIssue.issueNumber) {\n      await logger.logOutput({ skipped: true, reason: 'No parent issue linked to branch' });\n      return {};\n    }\n\n    const parentIssueNumber = branchIssue.issueNumber;\n\n    // Generate task ID and check for duplicates\n    const taskId = generateTaskId(prompt, description);\n    const taskState = await loadTaskSubissueState(input.cwd);\n\n    if (taskState[taskId]) {\n      // Already created subissue for this task\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Subissue already exists',\n        existing_subissue: taskState[taskId].subissueNumber,\n      });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `Task already tracked in subissue #${taskState[taskId].subissueNumber}`,\n        },\n      };\n    }\n\n    // Extract task ID if present in prompt\n    const planTaskId = extractTaskIdFromPrompt(prompt);\n\n    // Create subissue\n    const taskIdSection = planTaskId ? `**Plan Task ID:** \\`${planTaskId}\\`\\n` : '';\n    const subissueBody = `**Parent Issue:** #${parentIssueNumber}\n**Agent Type:** ${subagent_type}\n**Branch:** \\`${branch}\\`\n${taskIdSection}\n---\n\n## Task Description\n\n${description}\n\n## Task Prompt\n\n${prompt}`;\n\n    const subissueTitle = `[${subagent_type}] ${description}`;\n    const { issueNumber: subissueNumber, issueUrl: subissueUrl } = await createSubissue(\n      input.cwd,\n      parentIssueNumber,\n      subissueTitle,\n      subissueBody\n    );\n\n    // Link as native sub-issue (GitHub's native parent-child relationship)\n    // This creates proper hierarchy in GitHub UI and Projects\n    // Falls back gracefully if native sub-issues aren't available\n    const nativeResult = await addNativeSubissue(input.cwd, parentIssueNumber, subissueNumber);\n    if (!nativeResult.success) {\n      await logger.logOutput({\n        native_subissue: 'fallback',\n        reason: nativeResult.error || 'Native sub-issues not available',\n      });\n    }\n\n    // Save state\n    taskState[taskId] = {\n      prompt,\n      description,\n      subagentType: subagent_type,\n      parentIssueNumber,\n      subissueNumber,\n      subissueUrl,\n      branch,\n      createdAt: new Date().toISOString(),\n      planTaskId,\n      nativeSubissue: nativeResult.success,\n    };\n    await saveTaskSubissueState(input.cwd, taskState);\n\n    await logger.logOutput({\n      action: 'created',\n      subissue_number: subissueNumber,\n      subissue_url: subissueUrl,\n      parent_issue: parentIssueNumber,\n      branch,\n      native_subissue: nativeResult.success,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `Created subissue #${subissueNumber} for ${subagent_type} task: ${subissueUrl}`,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking error\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `Could not create task subissue: ${error instanceof Error ? error.message : String(error)}`,\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/hooks/track-issue-creation.ts": "/**\n * Issue creation tracking hook\n *\n * PostToolUse hook that automatically tracks GitHub issues created via gh CLI.\n * Detects `gh issue create` commands and stores issue references in session state.\n *\n * This hook provides:\n * - **Automatic issue tracking** - Detects issue creation from gh CLI\n * - **Session association** - Links issues to the session that created them\n * - **Cross-session discovery** - Enables related issue discovery in future sessions\n * - **Repository context** - Tracks repo and branch information\n *\n * State is tracked in .claude/logs/session-issues.json to enable cross-session\n * issue discovery and awareness.\n *\n * @module track-issue-creation\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { addIssueToSession } from '../shared/hooks/utils/session-issues.js';\nimport { addIssueToState } from '../shared/hooks/utils/github-state.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n// ============================================================================\n// Issue Detection\n// ============================================================================\n\n/**\n * Extract issue URL from gh CLI output\n *\n * Looks for GitHub issue URL pattern in command output.\n * @param output - Command output from gh issue create\n * @returns Issue URL if found, null otherwise\n */\nfunction extractIssueUrl(output: string): string | null {\n  // Pattern: https://github.com/owner/repo/issues/123\n  const urlMatch = output.match(/https:\\/\\/github\\.com\\/[^/\\s]+\\/[^/\\s]+\\/issues\\/\\d+/);\n  return urlMatch ? urlMatch[0] : null;\n}\n\n/**\n * Extract issue number from GitHub URL\n * @param url - GitHub issue URL\n * @returns Issue number\n */\nfunction extractIssueNumber(url: string): number {\n  const match = url.match(/\\/issues\\/(\\d+)/);\n  return match ? parseInt(match[1], 10) : 0;\n}\n\n// ============================================================================\n// Hook Handler\n// ============================================================================\n\n/**\n * PostToolUse hook handler for tracking issue creation\n *\n * Detects gh issue create commands and tracks the created issues in session state.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with tracking status\n *\n * @example\n * ```typescript\n * // This hook is automatically called by Claude Code after Bash tool execution\n * // When: gh issue create --title \"Bug fix\" --body \"Description\"\n * // Result: Issue tracked in .claude/logs/session-issues.json\n * ```\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'track-issue-creation', true);\n\n  try {\n    // Only process Bash tool\n    if (input.tool_name !== 'Bash') {\n      return {};\n    }\n\n    // Type-cast tool_input for Bash\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput?.command;\n    if (!command || !command.includes('gh issue create')) {\n      return {};\n    }\n\n    await logger.logInput({\n      session_id: input.session_id,\n      tool_name: input.tool_name,\n      command_preview: command.substring(0, 100),\n    });\n\n    // Extract issue URL from tool response\n    const toolResponse = input.tool_response as { content?: Array<{ text?: string }> };\n    const resultText = toolResponse?.content?.[0]?.text || '';\n    const issueUrl = extractIssueUrl(resultText);\n    if (!issueUrl) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not find issue URL in command output',\n      });\n      return {};\n    }\n\n    const issueNumber = extractIssueNumber(issueUrl);\n    if (!issueNumber) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not extract issue number from URL',\n      });\n      return {};\n    }\n\n    // Fetch issue details\n    const issueResult = await execCommand(\n      `gh issue view ${issueNumber} --json number,title,url`,\n      input.cwd\n    );\n\n    if (!issueResult.success) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not fetch issue details',\n        error: issueResult.stderr,\n      });\n      return {};\n    }\n\n    let issueDetails;\n    try {\n      issueDetails = JSON.parse(issueResult.stdout);\n    } catch {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not parse issue details JSON',\n      });\n      return {};\n    }\n\n    // Get repository name\n    const repoResult = await execCommand(\n      'gh repo view --json nameWithOwner -q .nameWithOwner',\n      input.cwd\n    );\n\n    if (!repoResult.success) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not determine repository',\n        error: repoResult.stderr,\n      });\n      return {};\n    }\n\n    const repo = repoResult.stdout;\n\n    // Get current branch\n    const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', input.cwd);\n\n    if (!branchResult.success) {\n      await logger.logOutput({\n        skipped: true,\n        reason: 'Could not determine current branch',\n        error: branchResult.stderr,\n      });\n      return {};\n    }\n\n    const branch = branchResult.stdout;\n\n    const createdAt = new Date().toISOString();\n\n    // Add issue to session tracking (session-issues.json)\n    await addIssueToSession(\n      input.session_id,\n      {\n        repo,\n        number: issueNumber,\n        title: issueDetails.title,\n        url: issueUrl,\n        createdAt,\n      },\n      branch,\n      repo,\n      input.cwd\n    );\n\n    // Also add issue to unified github.json state\n    await addIssueToState(\n      input.session_id,\n      {\n        number: issueNumber,\n        url: issueUrl,\n        title: issueDetails.title,\n        createdAt,\n      },\n      input.cwd\n    );\n\n    await logger.logOutput({\n      success: true,\n      issue_number: issueNumber,\n      issue_url: issueUrl,\n      branch,\n      repo,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `Tracked issue #${issueNumber} in session state`,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking - just log error\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/enforce-output-style-tools.ts": "#!/usr/bin/env npx tsx\n\n/**\n * Output style tool enforcement hook\n *\n * PreToolUse hook that enforces tool restrictions defined in output style frontmatter.\n * When an output style specifies a `tools` array in its frontmatter, only those tools\n * are allowed for the main agent. Subagents can use any tools they need.\n *\n * This enables output styles to restrict Claude's capabilities to specific tools,\n * for example:\n * - Read-only mode: only Read, Glob, Grep tools\n * - Research mode: Read, Glob, Grep, WebSearch, WebFetch\n * - Full mode: all tools allowed (no restrictions)\n *\n * Output style files are located in .claude/output-styles/ with frontmatter like:\n * ```yaml\n * ---\n * name: read-only\n * description: Read-only access to codebase\n * tools: [Read, Glob, Grep]\n * ---\n * ```\n *\n * @module enforce-output-style-tools\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { runHook, wasToolEventMainAgent } from './utils/index.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('output-styles-permission-modes');\n\ninterface OutputStyleFrontmatter {\n  name?: string;\n  description?: string;\n  tools?: string[];\n}\n\n/**\n * Read settings.json to get the current output style name\n *\n * Checks both settings.local.json (project-specific) and settings.json (committed)\n * for the outputStyle configuration. Returns the first match found.\n *\n * @param cwd - The working directory to search for settings files\n * @returns The output style name, or undefined if not configured\n *\n * @example\n * ```typescript\n * const styleName = await getCurrentOutputStyle('/path/to/project');\n * console.log(styleName); // 'read-only' or undefined\n * ```\n */\nasync function getCurrentOutputStyle(cwd: string): Promise<string | undefined> {\n  const settingsPaths = [\n    path.join(cwd, '.claude', 'settings.local.json'),\n    path.join(cwd, '.claude', 'settings.json'),\n  ];\n\n  for (const settingsPath of settingsPaths) {\n    try {\n      const content = await fs.readFile(settingsPath, 'utf-8');\n      const settings = JSON.parse(content);\n      if (settings.outputStyle) {\n        return settings.outputStyle;\n      }\n    } catch {\n      // File doesn't exist or is invalid JSON, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Load and parse output style file to get frontmatter\n *\n * Reads the output style markdown file and extracts its YAML frontmatter,\n * which contains the style configuration including tool restrictions.\n *\n * @param cwd - The working directory where output styles are stored\n * @param styleName - The name of the output style (without .md extension)\n * @returns The parsed frontmatter, or undefined if file not found\n *\n * @example\n * ```typescript\n * const frontmatter = await loadOutputStyleFrontmatter(\n *   '/path/to/project',\n *   'read-only'\n * );\n *\n * if (frontmatter) {\n *   console.log('Allowed tools:', frontmatter.tools);\n *   // ['Read', 'Glob', 'Grep']\n * }\n * ```\n */\nasync function loadOutputStyleFrontmatter(\n  cwd: string,\n  styleName: string\n): Promise<OutputStyleFrontmatter | undefined> {\n  const stylePaths = [\n    path.join(cwd, '.claude', 'output-styles', `${styleName}.md`),\n    // Note: User-level styles would be in ~/.claude/output-styles/\n    // but we can't easily access user home in hooks without assumptions\n  ];\n\n  for (const stylePath of stylePaths) {\n    try {\n      const content = await fs.readFile(stylePath, 'utf-8');\n      const { data } = matter(content);\n      return data as OutputStyleFrontmatter;\n    } catch {\n      // File doesn't exist, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * PreToolUse hook that enforces tool restrictions from output style frontmatter\n *\n * Checks if the current tool is allowed by the active output style's tool restrictions.\n * This hook only applies to the main agent - subagents can use any tools they need\n * to complete their tasks.\n *\n * The enforcement flow:\n * 1. Check if this is the main agent (skip for subagents)\n * 2. Read current output style from settings.json\n * 3. Load output style frontmatter to get allowed tools list\n * 4. Check if current tool is in the allowed list\n * 5. Allow or deny based on the check\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Example output style: .claude/output-styles/read-only.md\n * // ---\n * // name: read-only\n * // tools: [Read, Glob, Grep]\n * // ---\n *\n * // Settings: .claude/settings.json\n * // { \"outputStyle\": \"read-only\" }\n *\n * // When main agent tries to use Read tool:\n * const result = await handler({\n *   tool_name: 'Read',\n *   tool_use_id: 'toolu_123',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // When main agent tries to use Write tool (not in allowed list):\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'The \"Write\" tool is not allowed...'\n * //   }\n * // }\n *\n * // When subagent tries to use Write tool:\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   transcript_path: '/path/.claude/logs/agent-xyz.jsonl', // Subagent transcript\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * // (Subagents are never restricted)\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Hook triggered');\n    console.log('[enforce-output-style-tools] Tool:', input.tool_name);\n  }\n\n  // Only enforce for main agent, not subagents\n  const isMainAgent = await wasToolEventMainAgent(input.transcript_path, input.tool_use_id);\n  if (!isMainAgent) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Subagent detected, skipping enforcement');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Get current output style\n  const styleName = await getCurrentOutputStyle(input.cwd);\n  if (!styleName) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No output style configured, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Current output style:', styleName);\n  }\n\n  // Load output style frontmatter\n  const frontmatter = await loadOutputStyleFrontmatter(input.cwd, styleName);\n  if (!frontmatter || !frontmatter.tools || frontmatter.tools.length === 0) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No tool restrictions defined, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const allowedTools = frontmatter.tools;\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Allowed tools:', allowedTools);\n  }\n\n  // Check if current tool is allowed\n  const isAllowed = allowedTools.includes(input.tool_name);\n\n  if (!isAllowed) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Tool not allowed, blocking');\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'deny',\n        permissionDecisionReason: `The \"${input.tool_name}\" tool is not allowed by the current output style \"${styleName}\". Allowed tools: ${allowedTools.join(', ')}`,\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Tool allowed');\n  }\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'allow',\n    },\n  };\n}\n\n// Export for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/enforce-structured-markdown.ts": "#!/usr/bin/env npx tsx\n/**\n * Structured markdown validation hook\n *\n * PreToolUse hook that validates structure and metadata for markdown files before\n * Write and Edit operations. Enforces consistent documentation structure across\n * different file types in the Claude Code project.\n *\n * This hook validates six types of markdown files:\n *\n * 1. Agent files in .claude/agents/ directory\n *    Required headings: Objective, Principles, Agent-scoped project context\n *\n * 2. Skill files in .claude/skills/ subdirectories (excludes SKILL.md templates)\n *    Required headings: Purpose, Skill-scoped context\n *\n * 3. Rules files in .claude/rules/ directory\n *    Required headings: Rules\n *\n * 4. Plugin README files in plugins README.md\n *    Required headings: Badge section, TOC, Overview, Features, Installation,\n *    Hooks, Configuration, Use Cases, Troubleshooting, Contributing, See Also, License\n *\n * 5. Plugin CLAUDE.md files in plugins CLAUDE.md\n *    Required headings: Quick Reference, Hook Summary, Key Features,\n *    Installation, Debug Logging, See Also\n *\n * 6. CLAUDE.md files in any other directory\n *    Required metadata: name, description\n *\n * The hook blocks Write/Edit operations if validation fails, providing detailed\n * error messages about missing headings and metadata fields.\n *\n * @module enforce-structured-markdown\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('enforce-structured-markdown');\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n}\n\n/**\n * Extract markdown headings from content\n *\n * Parses markdown content and extracts all headings (lines starting with #).\n * Preserves the full heading text including the hash symbols for pattern matching.\n *\n * @param content - The markdown content to parse\n * @returns Array of heading strings (e.g., [\"# Title\", \"## Section\"])\n *\n * @example\n * ```typescript\n * const content = `\n * # My Document\n * ## Overview\n * Some content\n * ## Implementation\n * `;\n * const headings = extractHeadings(content);\n * // Returns: [\"# My Document\", \"## Overview\", \"## Implementation\"]\n * ```\n */\nfunction extractHeadings(content: string): string[] {\n  const lines = content.split('\\n');\n  const headings: string[] = [];\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (trimmed.match(/^#{1,6}\\s+/)) {\n      headings.push(trimmed);\n    }\n  }\n\n  return headings;\n}\n\n/**\n * Check if a heading matches a pattern with wildcard support\n *\n * Compares a markdown heading against a pattern, supporting wildcard (*) matching.\n * Normalizes whitespace and performs case-insensitive comparison.\n *\n * @param heading - The heading to test (e.g., \"## Required Skills: None\")\n * @param pattern - The pattern to match against (e.g., \"## Required Skills:*\")\n * @returns True if the heading matches the pattern, false otherwise\n *\n * @example\n * ```typescript\n * // Exact match\n * matchesHeadingPattern(\"## Overview\", \"## Overview\"); // true\n *\n * // Wildcard match\n * matchesHeadingPattern(\"## Required Skills: None\", \"## Required Skills:*\"); // true\n * matchesHeadingPattern(\"## Required Skills: foo, bar\", \"## Required Skills:*\"); // true\n *\n * // No match\n * matchesHeadingPattern(\"## Implementation\", \"## Overview\"); // false\n * ```\n */\nfunction matchesHeadingPattern(heading: string, pattern: string): boolean {\n  // Normalize whitespace\n  const normalizedHeading = heading.replace(/\\s+/g, ' ').trim();\n  const normalizedPattern = pattern.replace(/\\s+/g, ' ').trim();\n\n  // Exact match\n  if (normalizedHeading === normalizedPattern) {\n    return true;\n  }\n\n  // Wildcard pattern\n  const regexPattern = normalizedPattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*');\n\n  const regex = new RegExp(`^${regexPattern}$`, 'i');\n  return regex.test(normalizedHeading);\n}\n\n/**\n * Validate that all required headings are present in content\n *\n * Checks that each required heading pattern has at least one match in the\n * provided headings array. Supports wildcard patterns for flexible matching.\n *\n * @param headings - Array of headings extracted from markdown content\n * @param required - Array of required heading patterns (supports wildcards)\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const headings = [\"# Title\", \"## Overview\", \"## Implementation\"];\n * const required = [\"## Overview\", \"## Implementation\", \"## Testing\"];\n *\n * const result = validateRequiredHeadings(headings, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required heading missing: \"## Testing\"']\n * // }\n * ```\n */\nfunction validateRequiredHeadings(headings: string[], required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const requiredPattern of required) {\n    const found = headings.some(h => matchesHeadingPattern(h, requiredPattern));\n    if (!found) {\n      errors.push(`Required heading missing: \"${requiredPattern}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Validate that all required metadata fields are present in frontmatter\n *\n * Checks that each required metadata field exists in the YAML frontmatter object.\n * Fields with falsy values are considered missing.\n *\n * @param metadata - Parsed YAML frontmatter object\n * @param required - Array of required field names\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const metadata = { name: \"My Skill\", version: \"1.0\" };\n * const required = [\"name\", \"description\", \"version\"];\n *\n * const result = validateRequiredMetadata(metadata, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required metadata field missing: \"description\"']\n * // }\n * ```\n */\nfunction validateRequiredMetadata(metadata: Record<string, unknown>, required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const field of required) {\n    if (!metadata[field]) {\n      errors.push(`Required metadata field missing: \"${field}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Determine file type and return appropriate validation rules\n *\n * Analyzes the file path to determine its type (agent, skill, rule, or CLAUDE.md)\n * and returns the corresponding validation requirements. Returns null for\n * non-markdown files or files that don't match any validation pattern.\n *\n * @param filePath - The path to the file being validated (absolute or relative)\n * @param cwd - The current working directory for resolving relative paths\n * @returns Validation rules object with type and requirements, or null if no validation needed\n *\n * @example\n * ```typescript\n * // Agent file\n * const rules1 = getFileValidationRules('.claude/agents/explorer.md', '/project');\n * // Returns: {\n * //   type: 'agent',\n * //   requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n * //   shouldValidate: true\n * // }\n *\n * // Skill file\n * const rules2 = getFileValidationRules('.claude/skills/my-skill/docs.md', '/project');\n * // Returns: {\n * //   type: 'skill',\n * //   requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n * //   requiredMetadata: ['name', 'description'],\n * //   shouldValidate: true\n * // }\n *\n * // SKILL.md template (skipped)\n * const rules3 = getFileValidationRules('.claude/skills/my-skill/SKILL.md', '/project');\n * // Returns: { type: 'skill-template', shouldValidate: false }\n *\n * // Non-markdown file\n * const rules4 = getFileValidationRules('src/index.ts', '/project');\n * // Returns: null\n * ```\n */\nfunction getFileValidationRules(filePath: string, cwd: string): {\n  type: string;\n  requiredHeadings?: string[];\n  requiredMetadata?: string[];\n  shouldValidate: boolean;\n} | null {\n  const relativePath = path.isAbsolute(filePath)\n    ? path.relative(cwd, filePath)\n    : filePath;\n\n  if (DEBUG) {\n    console.log('[enforce-structured-markdown] Checking file type:', relativePath);\n  }\n\n  // Agent files: .claude/agents/*.md\n  if (relativePath.includes(path.join('.claude', 'agents')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'agent',\n      requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n      shouldValidate: true,\n    };\n  }\n\n  // Skill files: .claude/skills/*/*.md (excluding SKILL.md and SKILL.template.md)\n  if (relativePath.includes(path.join('.claude', 'skills')) && relativePath.endsWith('.md')) {\n    const basename = path.basename(relativePath);\n    if (basename === 'SKILL.md' || basename === 'SKILL.template.md') {\n      if (DEBUG) {\n        console.log('[enforce-structured-markdown] Skipping SKILL.md or SKILL.template.md');\n      }\n      return { type: 'skill-template', shouldValidate: false };\n    }\n    return {\n      type: 'skill',\n      requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  // Rules files: .claude/rules/*.md\n  if (relativePath.includes(path.join('.claude', 'rules')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'rule',\n      requiredHeadings: ['## Rules'],\n      requiredMetadata: ['Required Skills'],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin README files: plugins/*/README.md\n  if (relativePath.match(/^plugins\\/[^/]+\\/README\\.md$/)) {\n    return {\n      type: 'plugin-readme',\n      requiredHeadings: [\n        '# 🔌 *',\n        '## 📋 Table of Contents',\n        '## 🎯 Overview',\n        '## ✨ Features',\n        '## 📦 Installation',\n        '## 🪝 Hooks',\n        '## ⚙️ Configuration',\n        '## 💡 Use Cases',\n        '## 🐛 Troubleshooting',\n        '## 🤝 Contributing',\n        '## 📚 See Also',\n        '## 📄 License',\n      ],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin CLAUDE.md files: plugins/*/CLAUDE.md (must come before general CLAUDE.md check)\n  if (relativePath.match(/^plugins\\/[^/]+\\/CLAUDE\\.md$/)) {\n    return {\n      type: 'plugin-claude',\n      requiredHeadings: [\n        '# *',\n        '## Quick Reference',\n        '## Hook Summary',\n        '## Key Features',\n        '## Installation',\n        '## Debug Logging',\n        '## See Also',\n      ],\n      requiredMetadata: ['title', 'description', 'version', 'folder'],\n      shouldValidate: true,\n    };\n  }\n\n  // CLAUDE.md files (any directory)\n  if (path.basename(relativePath) === 'CLAUDE.md') {\n    return {\n      type: 'claude-md',\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  return null;\n}\n\n/**\n * Extract the final content that will be written to the file\n *\n * Handles both Write and Edit operations to determine the content that will\n * result from the tool use. For Write, returns the content directly. For Edit,\n * reads the current file and applies the edit operation to get the final content.\n *\n * @param toolName - The tool being used (\"Write\" or \"Edit\")\n * @param toolInput - The tool input parameters\n * @param cwd - The current working directory for resolving relative paths\n * @returns The final content after the operation, or null if content cannot be determined\n *\n * @example\n * ```typescript\n * // Write operation\n * const content1 = await getContentFromToolInput(\n *   'Write',\n *   { file_path: 'doc.md', content: '# Title\\n## Section' },\n *   '/project'\n * );\n * // Returns: '# Title\\n## Section'\n *\n * // Edit operation (replaces text)\n * // Assumes file currently contains: '# Old\\n## Section'\n * const content2 = await getContentFromToolInput(\n *   'Edit',\n *   {\n *     file_path: 'doc.md',\n *     old_string: '# Old',\n *     new_string: '# New'\n *   },\n *   '/project'\n * );\n * // Returns: '# New\\n## Section'\n * ```\n */\nasync function getContentFromToolInput(\n  toolName: string,\n  toolInput: {\n    file_path?: string;\n    content?: string;\n    old_string?: string;\n    new_string?: string;\n  },\n  cwd: string\n): Promise<string | null> {\n  if (toolName === 'Write') {\n    return toolInput.content || null;\n  } else if (toolName === 'Edit') {\n    const filePath = toolInput.file_path;\n    if (!filePath || !toolInput.old_string || !toolInput.new_string) {\n      return null;\n    }\n\n    try {\n      const fullPath = path.isAbsolute(filePath) ? filePath : path.resolve(cwd, filePath);\n      const currentContent = await fs.readFile(fullPath, 'utf-8');\n      // Apply the edit\n      return currentContent.replace(toolInput.old_string, toolInput.new_string);\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * PreToolUse hook that validates markdown structure before Write/Edit operations\n *\n * Intercepts Write and Edit tool uses on markdown files to validate that they\n * meet the structural requirements for their file type. Blocks operations that\n * would create invalid agent, skill, rule, or CLAUDE.md files.\n *\n * This hook:\n * 1. Only processes Write and Edit operations on .md files\n * 2. Determines the file type from its path\n * 3. Extracts headings and metadata from the content\n * 4. Validates against type-specific requirements\n * 5. Blocks invalid operations with detailed error messages\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Valid agent file - allowed\n * const result1 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_123',\n *   tool_input: {\n *     file_path: '.claude/agents/my-agent.md',\n *     content: `\n * # My Agent\n * ## Objective\n * Do the task\n * ## Principles\n * Be thorough\n * ## Agent-scoped project context\n * Uses TypeScript\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // Invalid skill file (missing required heading) - denied\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   tool_input: {\n *     file_path: '.claude/skills/my-skill/docs.md',\n *     content: `\n * ---\n * name: My Skill\n * description: Does things\n * ---\n * # My Skill\n * ## Purpose\n * This is the purpose\n * (missing ## Skill-scoped context heading)\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'Skill validation failed...\\n\\nRequired heading missing: \"## Skill-scoped context\"'\n * //   }\n * // }\n *\n * // Non-markdown file - allowed (no validation)\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   tool_input: {\n *     file_path: 'src/index.ts',\n *     content: 'export const foo = \"bar\";'\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'enforce-structured-markdown', DEBUG || false);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n\n    const filePath = toolInput.file_path;\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only process .md files\n    if (!filePath.endsWith('.md')) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get validation rules for this file type\n    const validationRules = getFileValidationRules(filePath, input.cwd);\n    if (!validationRules || !validationRules.shouldValidate) {\n      await logger.logOutput({ message: 'No validation rules for this file type or validation skipped' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get the content (handles both Write and Edit)\n    const content = await getContentFromToolInput(input.tool_name, toolInput, input.cwd);\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter and content\n    const { data: metadata } = matter(content);\n    const headings = extractHeadings(content);\n\n    const allErrors: string[] = [];\n\n    // Validate required metadata\n    if (validationRules.requiredMetadata && validationRules.requiredMetadata.length > 0) {\n      const metadataValidation = validateRequiredMetadata(\n        metadata as Record<string, unknown>,\n        validationRules.requiredMetadata\n      );\n      if (!metadataValidation.valid) {\n        allErrors.push(...metadataValidation.errors);\n      }\n    }\n\n    // Validate required headings\n    if (validationRules.requiredHeadings && validationRules.requiredHeadings.length > 0) {\n      const headingValidation = validateRequiredHeadings(headings, validationRules.requiredHeadings);\n      if (!headingValidation.valid) {\n        allErrors.push(...headingValidation.errors);\n      }\n    }\n\n    await logger.logOutput({\n      fileType: validationRules.type,\n      headings,\n      metadata: Object.keys(metadata),\n      valid: allErrors.length === 0,\n      errors: allErrors,\n    });\n\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n');\n      const fileTypeDisplay = validationRules.type.replace('-', ' ');\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `${fileTypeDisplay.charAt(0).toUpperCase() + fileTypeDisplay.slice(1)} validation failed for ${path.basename(filePath)}:\\n\\n${errorMessage}\\n\\nPlease ensure all required headings and metadata fields are present.`,\n        },\n      };\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Structured markdown validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/log-subagent-start.ts": "/**\n * Subagent context tracking hook\n *\n * SubagentStart hook that saves agent execution context when a subagent begins.\n * The saved context can be retrieved later in SubagentStop hooks to analyze what\n * the agent did and correlate it with the original Task tool call.\n *\n * This hook saves the following information to .claude/logs/subagent-tasks.json:\n * - Agent ID and type\n * - Session ID\n * - Original task prompt (from Task tool input)\n * - Tool use ID (for correlating with Task call)\n * - Timestamp\n *\n * The saved context enables SubagentStop hooks to generate rich commit messages,\n * track file operations, and analyze agent behavior.\n *\n * @module log-subagent-start\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../types/types.js';\nimport { saveAgentStartContext } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStart hook handler that saves agent context\n *\n * Intercepts subagent startup to save execution context for later retrieval.\n * This enables tracking what tasks agents were given and correlating SubagentStop\n * events with the original Task tool call.\n *\n * The hook is non-blocking - errors are logged but do not prevent agent execution.\n *\n * @param input - SubagentStart hook input with agent metadata\n * @returns Hook output (empty object, this hook does not modify agent behavior)\n *\n * @example\n * ```typescript\n * // When an agent starts via Task tool:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   cwd: '/path/to/project',\n *   transcript_path: '/path/.claude/logs/session-xyz.jsonl'\n * });\n *\n * // Context is saved to .claude/logs/subagent-tasks.json:\n * // {\n * //   \"agent-abc123\": {\n * //     \"agentId\": \"agent-abc123\",\n * //     \"agentType\": \"Explore\",\n * //     \"sessionId\": \"session-xyz\",\n * //     \"prompt\": \"Find all API endpoints\",\n * //     \"toolUseId\": \"toolu_xyz\",\n * //     \"timestamp\": \"2025-01-19T12:00:00.000Z\"\n * //   }\n * // }\n *\n * // Later, in SubagentStop, this context can be retrieved via getAgentEdits()\n * ```\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStart] Hook triggered');\n    console.log('[SubagentStart] Agent ID:', input.agent_id);\n    console.log('[SubagentStart] Agent Type:', input.agent_type);\n    console.log('[SubagentStart] Session ID:', input.session_id);\n  }\n\n  try {\n    const context = await saveAgentStartContext({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n      session_id: input.session_id,\n      cwd: input.cwd,\n      transcript_path: input.transcript_path,\n    });\n\n    if (DEBUG) {\n      console.log('[SubagentStart] Saved agent context');\n      console.log('[SubagentStart] Prompt:', context.prompt.slice(0, 100) + (context.prompt.length > 100 ? '...' : ''));\n      console.log('[SubagentStart] Tool Use ID:', context.toolUseId);\n      console.log('[SubagentStart] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStart] Error saving agent context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/log-subagent-stop.ts": "/**\n * Subagent completion analysis hook\n *\n * SubagentStop hook that analyzes agent execution results when a subagent completes.\n * It parses the agent's transcript to extract file operations and correlates them\n * with the saved context from SubagentStart.\n *\n * This hook analyzes and logs:\n * - New files created by the agent\n * - Files deleted by the agent\n * - Files edited by the agent\n * - Agent type and original task prompt\n * - Preloaded skills used by the agent\n *\n * After analysis, the hook cleans up the saved context from SubagentStart to prevent\n * the context file from growing indefinitely.\n *\n * The analysis results are logged to console when DEBUG mode is enabled, making it\n * easy to understand what each agent did during execution.\n *\n * @module log-subagent-stop\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../types/types.js';\nimport { getAgentEdits } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStop hook handler that analyzes agent execution results\n *\n * Intercepts subagent completion to analyze what the agent did during execution.\n * Parses the agent transcript to extract file operations and correlates with the\n * saved context from SubagentStart to provide complete execution metadata.\n *\n * The hook is non-blocking - errors are logged but do not prevent session continuation.\n *\n * @param input - SubagentStop hook input with agent transcript path\n * @returns Hook output (empty object, this hook does not modify behavior)\n *\n * @example\n * ```typescript\n * // When an agent completes:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_transcript_path: '/path/.claude/logs/agent-abc123.jsonl',\n *   cwd: '/path/to/project'\n * });\n *\n * // With DEBUG=* enabled, logs output like:\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Analysis Complete\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Type: Explore\n * // [SubagentStop] Agent Prompt: Find all API endpoints\n * // [SubagentStop] Files Created: 0\n * // [SubagentStop] Files Edited: 2\n * // [SubagentStop]   ~ src/api/routes.ts\n * // [SubagentStop]   ~ src/api/handlers.ts\n * // [SubagentStop] Files Deleted: 0\n * // [SubagentStop] ─────────────────────────────────────────\n *\n * // The saved context from SubagentStart is automatically cleaned up\n * ```\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStop] Hook triggered');\n    console.log('[SubagentStop] Agent ID:', input.agent_id);\n    console.log('[SubagentStop] Agent Transcript:', input.agent_transcript_path);\n  }\n\n  try {\n    const edits = await getAgentEdits(input.agent_transcript_path);\n\n    if (DEBUG) {\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Analysis Complete');\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Type:', edits.subagentType);\n      console.log('[SubagentStop] Agent Prompt:', edits.agentPrompt.slice(0, 100) + (edits.agentPrompt.length > 100 ? '...' : ''));\n\n      if (edits.agentFile) {\n        console.log('[SubagentStop] Agent Definition:', edits.agentFile);\n      }\n\n      if (edits.agentPreloadedSkillsFiles.length > 0) {\n        console.log('[SubagentStop] Preloaded Skills:', edits.agentPreloadedSkillsFiles.length);\n        edits.agentPreloadedSkillsFiles.forEach((skill) => {\n          console.log('[SubagentStop]   -', skill);\n        });\n      }\n\n      if (edits.agentNewFiles.length > 0) {\n        console.log('[SubagentStop] Files Created:', edits.agentNewFiles.length);\n        edits.agentNewFiles.forEach((file) => {\n          console.log('[SubagentStop]   +', file);\n        });\n      }\n\n      if (edits.agentEditedFiles.length > 0) {\n        console.log('[SubagentStop] Files Edited:', edits.agentEditedFiles.length);\n        edits.agentEditedFiles.forEach((file) => {\n          console.log('[SubagentStop]   ~', file);\n        });\n      }\n\n      if (edits.agentDeletedFiles.length > 0) {\n        console.log('[SubagentStop] Files Deleted:', edits.agentDeletedFiles.length);\n        edits.agentDeletedFiles.forEach((file) => {\n          console.log('[SubagentStop]   -', file);\n        });\n      }\n\n      if (edits.agentNewFiles.length === 0 &&\n          edits.agentEditedFiles.length === 0 &&\n          edits.agentDeletedFiles.length === 0) {\n        console.log('[SubagentStop] No file operations detected');\n      }\n\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStop] Error analyzing agent edits:', error);\n    }\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/log-task-call.ts": "/**\n * PreToolUse[Task] hook - Save task call context for later retrieval\n *\n * This hook runs when the Task tool is ABOUT to be called (before the subagent starts).\n * It saves the task's context (type, prompt, toolUseId) to .claude/logs/task-calls.json\n * so it can be retrieved later in PostToolUse[Task] or SubagentStop.\n *\n * Import this hook in any plugin that needs to track task execution.\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { saveTaskCallContext } from './utils/task-state.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[PreToolUse:Task] Hook triggered');\n    console.log('[PreToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PreToolUse:Task] Session ID:', input.session_id);\n  }\n\n  try {\n    const toolInput = input.tool_input as {\n      subagent_type?: string;\n      prompt?: string;\n    };\n\n    const agentType = toolInput?.subagent_type || 'unknown';\n    const prompt = toolInput?.prompt || '';\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Agent Type:', agentType);\n      console.log('[PreToolUse:Task] Prompt:', prompt.slice(0, 100) + (prompt.length > 100 ? '...' : ''));\n    }\n\n    const context = await saveTaskCallContext({\n      tool_use_id: input.tool_use_id,\n      agent_type: agentType,\n      session_id: input.session_id,\n      prompt,\n      cwd: input.cwd,\n    });\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Saved task call context');\n      console.log('[PreToolUse:Task] Tool Use ID:', context.toolUseId);\n      console.log('[PreToolUse:Task] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PreToolUse:Task] Error saving task call context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/log-task-result.ts": "/**\n * PostToolUse[Task] hook - Log task completion\n *\n * This hook runs when the Task tool completes (after the subagent finishes).\n * It logs the task completion for debugging and audit purposes.\n *\n * Note: For detailed file operations analysis, see the SubagentStop hooks\n * which have access to the full agent transcript.\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { loadTaskCallContext } from './utils/task-state.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:Task] Hook triggered');\n    console.log('[PostToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PostToolUse:Task] Session ID:', input.session_id);\n  }\n\n  const logger = createDebugLogger(input.cwd, 'log-task-result', true);\n\n  try {\n    // Load the saved context from PreToolUse\n    const context = await loadTaskCallContext(input.tool_use_id, input.cwd);\n\n    if (!context) {\n      if (DEBUG) {\n        console.log('[PostToolUse:Task] No saved context found for tool_use_id:', input.tool_use_id);\n      }\n      return {};\n    }\n\n    const toolResponse = input.tool_response;\n    const responseText = typeof toolResponse === 'string'\n      ? toolResponse\n      : JSON.stringify(toolResponse).slice(0, 500);\n\n    await logger.logOutput({\n      tool_use_id: input.tool_use_id,\n      agent_type: context.agentType,\n      prompt: context.prompt.slice(0, 200),\n      response: responseText.slice(0, 200),\n      success: true,\n    });\n\n    if (DEBUG) {\n      console.log('[PostToolUse:Task] Task completed');\n      console.log('[PostToolUse:Task] Agent Type:', context.agentType);\n      console.log('[PostToolUse:Task] Response:', responseText.slice(0, 100));\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PostToolUse:Task] Error logging task result:', error);\n    }\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/test-folder-hooks.sh": "#!/bin/bash\n# Test script for folder validation hooks\n# Tests validate-folder-structure-bash.ts and validate-folder-structure-write.ts\n\nset -e\n\necho \"Testing folder validation hooks...\"\necho \"\"\n\nCWD=\"/home/user/claude-code-plugins\"\nSESSION_ID=\"test-session-123\"\nTRANSCRIPT_PATH=\"/tmp/test-transcript.jsonl\"\n\n# Test 1: validate-folder-structure-bash.ts with allowed folder\necho \"=== Test 1: Bash hook - allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_1\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 2: validate-folder-structure-bash.ts with forbidden folder\necho \"=== Test 2: Bash hook - forbidden subfolder (should deny) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_2\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/invalid_folder\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 3: validate-folder-structure-bash.ts with mkdir -p\necho \"=== Test 3: Bash hook - mkdir with -p flag (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_3\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir -p shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 4: validate-folder-structure-bash.ts with non-mkdir command\necho \"=== Test 4: Bash hook - non-mkdir command (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_4\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"ls -la\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 5: validate-folder-structure-write.ts with allowed file\necho \"=== Test 5: Write hook - allowed file in allowed folder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_5\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 6: validate-folder-structure-write.ts with forbidden file\necho \"=== Test 6: Write hook - forbidden file (should deny if files spec exists) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_6\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/forbidden.exe\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 7: validate-folder-structure-write.ts with file in new subfolder\necho \"=== Test 7: Write hook - file in allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_7\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/types/new-type.ts\",\n    \"content\": \"export type NewType = string;\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 8: validate-folder-structure-write.ts with non-Write tool\necho \"=== Test 8: Write hook - non-Write tool (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_8\",\n  \"tool_name\": \"Read\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\necho \"All tests completed!\"\n",
        "plugins/github-orchestration/shared/hooks/utils/branch-naming.ts": "/**\n * Branch naming utility for GitHub workflow automation\n * Extracted from create-issue-on-prompt.ts for reusability\n */\n\nimport type { WorkType } from './work-type-detector.js';\n\n/**\n * Parsed branch name components\n */\nexport interface ParsedBranchName {\n  issueNumber?: number;\n  workType?: WorkType;\n  title: string;\n}\n\n/**\n * Branch name validation result\n */\nexport interface BranchValidation {\n  valid: boolean;\n  reason?: string;\n}\n\n/**\n * Convert title to kebab-case for branch name (max 40 chars)\n *\n * @param title - The title to convert\n * @returns Kebab-cased string\n *\n * @example\n * toKebabCase('Add Dark Mode Feature') // 'add-dark-mode-feature'\n */\nexport function toKebabCase(title: string): string {\n  return title\n    .toLowerCase()\n    .replace(/[^a-z0-9\\s-]/g, '') // Remove special chars\n    .replace(/\\s+/g, '-') // Replace spaces with hyphens\n    .replace(/-+/g, '-') // Collapse multiple hyphens\n    .replace(/^-|-$/g, '') // Trim hyphens\n    .substring(0, 40); // Max 40 chars\n}\n\n/**\n * Generate branch name from issue number, work type, and title\n * Format: {issueNumber}-{workType}/{kebab-name}\n *\n * @param issueNumber - The GitHub issue number\n * @param workType - The work type (feature/fix/chore/docs/refactor)\n * @param title - The issue title or description\n * @returns Generated branch name\n *\n * @example\n * generateBranchName(42, 'feature', 'Add Dark Mode') // '42-feature/add-dark-mode'\n * generateBranchName(123, 'fix', 'Fix Authentication Bug') // '123-fix/fix-authentication-bug'\n */\nexport function generateBranchName(issueNumber: number, workType: WorkType, title: string): string {\n  const kebabName = toKebabCase(title);\n  return `${issueNumber}-${workType}/${kebabName}`;\n}\n\n/**\n * Parse branch name into components\n * Supports formats:\n * - {issueNumber}-{workType}/{title} (e.g., \"42-feature/add-dark-mode\")\n * - {issueNumber}-{title} (e.g., \"42-add-dark-mode\")\n * - {title} (e.g., \"add-dark-mode\")\n *\n * @param branchName - The branch name to parse\n * @returns Parsed branch components\n *\n * @example\n * parseBranchName('42-feature/add-dark-mode')\n * // { issueNumber: 42, workType: 'feature', title: 'add-dark-mode' }\n *\n * parseBranchName('123-fix-auth-bug')\n * // { issueNumber: 123, title: 'fix-auth-bug' }\n */\nexport function parseBranchName(branchName: string): ParsedBranchName {\n  // Pattern: {issueNumber}-{workType}/{title}\n  const fullMatch = branchName.match(/^(\\d+)-(feature|fix|chore|docs|refactor)\\/(.+)$/);\n  if (fullMatch) {\n    return {\n      issueNumber: parseInt(fullMatch[1], 10),\n      workType: fullMatch[2] as WorkType,\n      title: fullMatch[3],\n    };\n  }\n\n  // Pattern: {issueNumber}-{title}\n  const issueMatch = branchName.match(/^(\\d+)-(.+)$/);\n  if (issueMatch) {\n    return {\n      issueNumber: parseInt(issueMatch[1], 10),\n      title: issueMatch[2],\n    };\n  }\n\n  // Pattern: {title} only\n  return {\n    title: branchName,\n  };\n}\n\n/**\n * Validate branch name against conventions\n *\n * @param branchName - The branch name to validate\n * @returns Validation result with reason if invalid\n *\n * @example\n * validateBranchName('42-feature/add-dark-mode') // { valid: true }\n * validateBranchName('invalid name with spaces') // { valid: false, reason: '...' }\n */\nexport function validateBranchName(branchName: string): BranchValidation {\n  // Check for spaces\n  if (/\\s/.test(branchName)) {\n    return {\n      valid: false,\n      reason: 'Branch name cannot contain spaces',\n    };\n  }\n\n  // Check for invalid characters\n  if (!/^[a-z0-9\\-/]+$/.test(branchName)) {\n    return {\n      valid: false,\n      reason: 'Branch name can only contain lowercase letters, numbers, hyphens, and slashes',\n    };\n  }\n\n  // Check for multiple consecutive hyphens\n  if (/--/.test(branchName)) {\n    return {\n      valid: false,\n      reason: 'Branch name cannot contain consecutive hyphens',\n    };\n  }\n\n  // Check for leading/trailing hyphens or slashes\n  if (/^[-/]|[-/]$/.test(branchName)) {\n    return {\n      valid: false,\n      reason: 'Branch name cannot start or end with hyphens or slashes',\n    };\n  }\n\n  // Check length (reasonable max 100 chars)\n  if (branchName.length > 100) {\n    return {\n      valid: false,\n      reason: 'Branch name is too long (max 100 characters)',\n    };\n  }\n\n  return { valid: true };\n}\n\n/**\n * Extract issue number from branch name prefix\n * Supports patterns: \"42-*\", \"issue-42-*\"\n *\n * @param branchName - The branch name to parse\n * @returns Issue number if found, null otherwise\n *\n * @example\n * extractIssueNumber('42-feature/add-dark-mode') // 42\n * extractIssueNumber('issue-123-fix-bug') // 123\n * extractIssueNumber('main') // null\n */\nexport function extractIssueNumber(branchName: string): number | null {\n  // Pattern: {number}-*\n  const match1 = branchName.match(/^(\\d+)-/);\n  if (match1) {\n    return parseInt(match1[1], 10);\n  }\n\n  // Pattern: issue-{number}-*\n  const match2 = branchName.match(/^issue-(\\d+)-/);\n  if (match2) {\n    return parseInt(match2[1], 10);\n  }\n\n  return null;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/ci-status.ts": "/**\n * Shared CI status utilities for GitHub CI integration\n *\n * Provides common functions for checking CI status, waiting for checks,\n * extracting preview URLs, and formatting results. Used by:\n * - commit-task-await-ci-status.ts (SubagentStop)\n * - await-pr-status.ts (PostToolUse[Bash])\n * - commit-session-await-ci-status.ts (Stop)\n *\n * @module ci-status\n */\n\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum output characters for CI status (prevents context bloat) */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Default CI check timeout in milliseconds (10 minutes) */\nconst DEFAULT_TIMEOUT_MS = 600000;\n\n\n/**\n * Branch sync status result\n */\nexport interface BranchSyncResult {\n  /** Whether branch is in sync with main */\n  inSync: boolean;\n  /** Number of commits behind main */\n  behindCount: number;\n  /** Number of commits ahead of main */\n  aheadCount: number;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Merge conflict check result\n */\nexport interface MergeConflictResult {\n  /** Whether PR has merge conflicts */\n  hasConflicts: boolean;\n  /** Mergeable state from GitHub */\n  mergeableState?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Fail-fast CI check result\n */\nexport interface FailFastResult {\n  /** Whether all checks passed */\n  success: boolean;\n  /** Blocking reason if failed */\n  blockReason?: string;\n  /** Failed check name if applicable */\n  failedCheck?: string;\n  /** All check statuses */\n  checks: CheckStatus[];\n  /** PR number if found */\n  prNumber?: number;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * Result from a CI check operation\n */\nexport interface CICheckResult {\n  /** Whether all CI checks passed */\n  success: boolean;\n  /** Combined output from CI checks */\n  output: string;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * CI run details from GitHub\n */\nexport interface CIRunDetails {\n  /** CI workflow URL */\n  url?: string;\n  /** CI status (queued, in_progress, completed) */\n  status?: string;\n  /** CI conclusion (success, failure, cancelled) */\n  conclusion?: string;\n  /** Workflow name */\n  name?: string;\n}\n\n/**\n * Individual check status\n */\nexport interface CheckStatus {\n  /** Check name */\n  name: string;\n  /** Check status emoji */\n  emoji: string;\n  /** Check status (success, failure, pending) */\n  status: string;\n  /** Details URL */\n  url?: string;\n}\n\n/**\n * PR existence check result\n */\nexport interface PRCheckResult {\n  /** Whether PR exists */\n  exists: boolean;\n  /** PR number if exists */\n  prNumber?: number;\n  /** PR URL if exists */\n  prUrl?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Preview URLs extracted from PR\n */\nexport interface PreviewUrls {\n  /** Web app preview URL */\n  webUrl?: string;\n  /** Marketing app preview URL */\n  marketingUrl?: string;\n  /** All preview URLs found */\n  allUrls: string[];\n}\n\n/**\n * Information about an issue linked to a PR\n */\nexport interface LinkedIssueInfo {\n  /** Issue number */\n  number: number;\n  /** Issue title (if fetched) */\n  title?: string;\n  /** Full issue URL */\n  url: string;\n  /** Repository owner/name (extracted from URL) */\n  repo: string;\n}\n\n/**\n * Grouped preview URLs by provider\n */\nexport interface GroupedPreviewUrls {\n  /** Vercel preview URLs */\n  vercel: string[];\n  /** Cloudflare Worker/Pages preview URLs */\n  cloudflare: string[];\n  /** Supabase preview branch URLs */\n  supabase: string[];\n}\n\n/**\n * Execute a shell command with timeout\n *\n * @param command - Command to execute\n * @param cwd - Working directory\n * @param timeout - Timeout in milliseconds (default: 30s)\n * @returns Command result with success flag and output\n *\n * @example\n * ```typescript\n * const result = await execCommand('gh pr list', '/path/to/repo');\n * if (result.success) {\n *   console.log(result.stdout);\n * }\n * ```\n */\nexport async function execCommand(\n  command: string,\n  cwd: string,\n  timeout = 30000\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a PR exists for the given branch\n *\n * @param branch - Branch name to check\n * @param cwd - Working directory\n * @returns PR check result with number and URL if exists\n *\n * @example\n * ```typescript\n * const prCheck = await checkPRExists('feature-branch', '/path/to/repo');\n * if (prCheck.exists) {\n *   console.log(`PR #${prCheck.prNumber}: ${prCheck.prUrl}`);\n * }\n * ```\n */\nexport async function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<PRCheckResult> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return { exists: false, error: 'GitHub CLI not installed' };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return { exists: false, error: 'GitHub CLI not authenticated' };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number,url --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return { exists: false, error: `gh pr list failed: ${prListResult.stderr}` };\n  }\n\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n    if (Array.isArray(prs) && prs.length > 0) {\n      return {\n        exists: true,\n        prNumber: prs[0].number,\n        prUrl: prs[0].url,\n      };\n    }\n    return { exists: false };\n  } catch {\n    return { exists: false, error: 'Failed to parse gh output' };\n  }\n}\n\n/**\n * Get PR number for the current branch\n *\n * @param cwd - Working directory\n * @returns PR number or null if no PR exists\n *\n * @example\n * ```typescript\n * const prNumber = await getPRForCurrentBranch('/path/to/repo');\n * if (prNumber) {\n *   const ciResult = await waitForCIChecks({ prNumber, cwd });\n * }\n * ```\n */\nexport async function getPRForCurrentBranch(cwd: string): Promise<number | null> {\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return null;\n  }\n\n  const prCheck = await checkPRExists(branchResult.stdout, cwd);\n  return prCheck.exists ? (prCheck.prNumber ?? null) : null;\n}\n\n/**\n * Wait for CI checks to complete on a PR\n *\n * Uses `gh pr checks --watch` to wait for all CI checks to finish.\n * Blocks until all checks complete or timeout is reached.\n *\n * @param options - Wait options\n * @param options.prNumber - PR number to check (required if no commitSha)\n * @param options.commitSha - Commit SHA to check (alternative to prNumber)\n * @param options.timeout - Timeout in milliseconds (default: 10 minutes)\n * @param cwd - Working directory\n * @returns CI check result with success status and output\n *\n * @example\n * ```typescript\n * const result = await waitForCIChecks({ prNumber: 123 }, '/path/to/repo');\n * if (result.success) {\n *   console.log('All CI checks passed!');\n * } else {\n *   console.log('CI failed:', result.output);\n * }\n * ```\n */\nexport async function waitForCIChecks(\n  options: {\n    prNumber?: number;\n    commitSha?: string;\n    timeout?: number;\n  },\n  cwd: string\n): Promise<CICheckResult> {\n  const { prNumber, commitSha, timeout = DEFAULT_TIMEOUT_MS } = options;\n\n  if (!prNumber && !commitSha) {\n    return { success: false, output: '', error: 'Either prNumber or commitSha required' };\n  }\n\n  try {\n    // Build command based on what we have\n    const target = prNumber ? prNumber.toString() : commitSha!;\n    const command = `gh pr checks ${target} --watch`;\n\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    const combinedOutput = `${stdout}\\n${stderr}`.trim();\n\n    // Check if all checks passed\n    const hasFailures =\n      combinedOutput.includes('fail') ||\n      combinedOutput.includes('X ') ||\n      combinedOutput.includes('cancelled');\n\n    return {\n      success: !hasFailures,\n      output: combinedOutput,\n    };\n  } catch (error: unknown) {\n    const err = error as {\n      stdout?: string;\n      stderr?: string;\n      message?: string;\n      killed?: boolean;\n    };\n    const errorOutput = err.stdout || err.stderr || err.message || 'Unknown error';\n\n    if (err.killed) {\n      return {\n        success: false,\n        output: errorOutput,\n        error: `CI check timeout (${Math.round(timeout / 60000)} minutes)`,\n      };\n    }\n\n    return {\n      success: false,\n      output: errorOutput,\n      error: 'Failed to watch CI checks',\n    };\n  }\n}\n\n/**\n * Get latest CI workflow run details\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns CI run details or null if not found\n *\n * @example\n * ```typescript\n * const ciRun = await getLatestCIRun(123, '/path/to/repo');\n * if (ciRun?.conclusion === 'success') {\n *   console.log('CI passed:', ciRun.url);\n * }\n * ```\n */\nexport async function getLatestCIRun(\n  prNumber: number,\n  cwd: string\n): Promise<CIRunDetails | null> {\n  // First, get the PR's HEAD commit SHA to filter CI runs correctly\n  const headShaResult = await execCommand(\n    `gh pr view ${prNumber} --json headRefOid --jq '.headRefOid'`,\n    cwd\n  );\n\n  if (!headShaResult.success || !headShaResult.stdout.trim()) {\n    // Fallback: if we can't get PR info, return null rather than wrong data\n    return null;\n  }\n\n  const headSha = headShaResult.stdout.trim();\n\n  // Get CI runs for THIS specific commit, not the most recent run globally\n  const result = await execCommand(\n    `gh run list --commit ${headSha} --limit 1 --json databaseId,displayTitle,status,conclusion,url`,\n    cwd\n  );\n\n  if (!result.success) {\n    return null;\n  }\n\n  try {\n    const runs = JSON.parse(result.stdout);\n    if (Array.isArray(runs) && runs.length > 0) {\n      const run = runs[0];\n      return {\n        url: run.url,\n        status: run.status,\n        conclusion: run.conclusion,\n        name: run.displayTitle,\n      };\n    }\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Extract Vercel preview URLs from PR comments\n *\n * Searches PR comments for Vercel bot URLs and categorizes them\n * by app type (web, marketing, etc).\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Preview URLs object with categorized URLs\n *\n * @example\n * ```typescript\n * const urls = await extractPreviewUrls(123, '/path/to/repo');\n * if (urls.webUrl) {\n *   console.log('Web preview:', urls.webUrl);\n * }\n * ```\n */\nexport async function extractPreviewUrls(\n  prNumber: number,\n  cwd: string\n): Promise<PreviewUrls> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return { allUrls: [] };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n\n    const vercelUrlPattern = /https:\\/\\/[a-z0-9-]+\\.vercel\\.app/g;\n    const allUrls: string[] = [];\n\n    for (const comment of comments) {\n      const matches = comment.body?.match(vercelUrlPattern) || [];\n      allUrls.push(...matches);\n    }\n\n    // Deduplicate URLs\n    const uniqueUrls = [...new Set(allUrls)];\n\n    // Identify web and marketing apps by URL pattern\n    const webUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-web-') || url.includes('web-') || url.match(/web\\.vercel\\.app/)\n    );\n    const marketingUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-marketing-') ||\n        url.includes('marketing-') ||\n        url.match(/marketing\\.vercel\\.app/)\n    );\n\n    return {\n      webUrl,\n      marketingUrl,\n      allUrls: uniqueUrls,\n    };\n  } catch {\n    return { allUrls: [] };\n  }\n}\n\n/**\n * Extract linked issue numbers from PR body (simple version)\n *\n * Parses PR body for GitHub issue-closing keywords like:\n * - Fixes #123, Closes #456, Resolves #789\n * - Full URLs: github.com/owner/repo/issues/123\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of linked issue numbers (deduplicated and sorted)\n *\n * @example\n * ```typescript\n * const linkedIssues = await extractLinkedIssuesFromPR(42, '/path/to/repo');\n * // Returns: [123, 456] if PR body contains \"Fixes #123\" and \"Closes #456\"\n * ```\n */\nexport async function extractLinkedIssuesFromPR(\n  prNumber: number,\n  cwd: string\n): Promise<number[]> {\n  const linkedIssues = await extractLinkedIssuesWithInfo(prNumber, cwd);\n  return linkedIssues.map((issue) => issue.number).sort((a, b) => a - b);\n}\n\n/**\n * Extract linked issues with full info from PR body\n *\n * Parses PR body for GitHub issue-closing keywords and returns rich info:\n * - Fixes #123, Closes #456, Resolves #789\n * - Full URLs: github.com/owner/repo/issues/123\n *\n * For #123 references, constructs URL using the PR's repository.\n * For full URLs, extracts the repo from the URL (supports cross-repo links).\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of LinkedIssueInfo with number, url, and repo\n *\n * @example\n * ```typescript\n * const linkedIssues = await extractLinkedIssuesWithInfo(42, '/path/to/repo');\n * // Returns: [{ number: 123, url: 'https://github.com/owner/repo/issues/123', repo: 'owner/repo' }]\n * ```\n */\nexport async function extractLinkedIssuesWithInfo(\n  prNumber: number,\n  cwd: string\n): Promise<LinkedIssueInfo[]> {\n  // Get PR body and URL to extract repo info\n  const result = await execCommand(\n    `gh pr view ${prNumber} --json body,url`,\n    cwd\n  );\n\n  if (!result.success || !result.stdout) {\n    return [];\n  }\n\n  let body: string;\n  let prUrl: string;\n  try {\n    const data = JSON.parse(result.stdout);\n    body = data.body || '';\n    prUrl = data.url || '';\n  } catch {\n    return [];\n  }\n\n  // Extract repo from PR URL: https://github.com/owner/repo/pull/123\n  const prRepoMatch = prUrl.match(/github\\.com\\/([^/]+\\/[^/]+)\\/pull/);\n  const prRepo = prRepoMatch ? prRepoMatch[1] : '';\n\n  const linkedIssues: Map<string, LinkedIssueInfo> = new Map();\n\n  // Pattern 1: Issue-closing keywords with # reference (same repo)\n  // Matches: fix, fixes, fixed, close, closes, closed, resolve, resolves, resolved\n  const keywordPattern = /\\b(?:fix|fixes|fixed|close|closes|closed|resolve|resolves|resolved)\\s+#(\\d+)/gi;\n  let match;\n  while ((match = keywordPattern.exec(body)) !== null) {\n    const num = parseInt(match[1], 10);\n    const url = prRepo ? `https://github.com/${prRepo}/issues/${num}` : '';\n    const key = `${prRepo}#${num}`;\n    if (!linkedIssues.has(key)) {\n      linkedIssues.set(key, {\n        number: num,\n        url,\n        repo: prRepo,\n      });\n    }\n  }\n\n  // Pattern 2: Full GitHub issue URLs (may be cross-repo)\n  // Matches: https://github.com/owner/repo/issues/123\n  const urlPattern = /https:\\/\\/github\\.com\\/([^/]+\\/[^/]+)\\/issues\\/(\\d+)/g;\n  while ((match = urlPattern.exec(body)) !== null) {\n    const repo = match[1];\n    const num = parseInt(match[2], 10);\n    const url = `https://github.com/${repo}/issues/${num}`;\n    const key = `${repo}#${num}`;\n    if (!linkedIssues.has(key)) {\n      linkedIssues.set(key, {\n        number: num,\n        url,\n        repo,\n      });\n    }\n  }\n\n  // Return sorted by repo then number\n  return Array.from(linkedIssues.values()).sort((a, b) => {\n    if (a.repo !== b.repo) return a.repo.localeCompare(b.repo);\n    return a.number - b.number;\n  });\n}\n\n/**\n * Extract Cloudflare Worker/Pages preview URLs from PR comments\n *\n * Searches PR comments for Cloudflare deployment URLs:\n * - Workers: https://my-worker.workers.dev\n * - Pages: https://my-project.pages.dev\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of Cloudflare preview URLs\n *\n * @example\n * ```typescript\n * const urls = await extractCloudflarePreviewUrls(42, '/path/to/repo');\n * // Returns: ['https://my-api.workers.dev', 'https://my-site.pages.dev']\n * ```\n */\nexport async function extractCloudflarePreviewUrls(\n  prNumber: number,\n  cwd: string\n): Promise<string[]> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n    const allUrls: string[] = [];\n\n    // Cloudflare Workers pattern: https://something.workers.dev\n    const workersPattern = /https:\\/\\/[a-z0-9-]+\\.workers\\.dev/gi;\n    // Cloudflare Pages pattern: https://something.pages.dev\n    const pagesPattern = /https:\\/\\/[a-z0-9-]+\\.pages\\.dev/gi;\n\n    for (const comment of comments) {\n      const body = comment.body || '';\n      const workersMatches = body.match(workersPattern) || [];\n      const pagesMatches = body.match(pagesPattern) || [];\n      allUrls.push(...workersMatches, ...pagesMatches);\n    }\n\n    // Deduplicate\n    return [...new Set(allUrls)];\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Extract Supabase preview branch URLs from PR comments\n *\n * Searches PR comments for Supabase preview URLs:\n * - API: https://project-ref.supabase.co\n * - Database: db.project-ref.supabase.co\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of Supabase preview URLs\n *\n * @example\n * ```typescript\n * const urls = await extractSupabasePreviewBranches(42, '/path/to/repo');\n * // Returns: ['https://abcxyz-preview.supabase.co']\n * ```\n */\nexport async function extractSupabasePreviewBranches(\n  prNumber: number,\n  cwd: string\n): Promise<string[]> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n    const allUrls: string[] = [];\n\n    // Supabase API URL pattern: https://something.supabase.co\n    const supabasePattern = /https:\\/\\/[a-z0-9-]+\\.supabase\\.co/gi;\n    // Supabase DB URL pattern: db.something.supabase.co (may or may not have https://)\n    const dbPattern = /(?:https?:\\/\\/)?db\\.[a-z0-9-]+\\.supabase\\.co/gi;\n\n    for (const comment of comments) {\n      const body = comment.body || '';\n      const supabaseMatches = body.match(supabasePattern) || [];\n      const dbMatches = body.match(dbPattern) || [];\n      allUrls.push(...supabaseMatches, ...dbMatches);\n    }\n\n    // Deduplicate and normalize (ensure https://)\n    const uniqueUrls = [...new Set(allUrls)].map((url) => {\n      if (!url.startsWith('http')) {\n        return `https://${url}`;\n      }\n      return url;\n    });\n\n    return uniqueUrls;\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Extract all preview URLs grouped by provider\n *\n * Consolidates preview URLs from Vercel, Cloudflare, and Supabase.\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Grouped preview URLs by provider\n *\n * @example\n * ```typescript\n * const previews = await extractAllPreviews(42, '/path/to/repo');\n * // Returns: {\n * //   vercel: ['https://my-app-abc123.vercel.app'],\n * //   cloudflare: ['https://my-worker.workers.dev'],\n * //   supabase: ['https://abcxyz.supabase.co']\n * // }\n * ```\n */\nexport async function extractAllPreviews(\n  prNumber: number,\n  cwd: string\n): Promise<GroupedPreviewUrls> {\n  // Fetch all previews in parallel\n  const [vercelResult, cloudflareUrls, supabaseUrls] = await Promise.all([\n    extractPreviewUrls(prNumber, cwd),\n    extractCloudflarePreviewUrls(prNumber, cwd),\n    extractSupabasePreviewBranches(prNumber, cwd),\n  ]);\n\n  return {\n    vercel: vercelResult.allUrls,\n    cloudflare: cloudflareUrls,\n    supabase: supabaseUrls,\n  };\n}\n\n/**\n * Format grouped preview URLs for display\n *\n * Formats preview URLs from all providers (Vercel, Cloudflare, Supabase)\n * into a markdown-formatted string with provider sections.\n *\n * @param previews - Grouped preview URLs by provider\n * @returns Formatted markdown string, empty if no previews\n *\n * @example\n * ```typescript\n * const previews = await extractAllPreviews(42, '/path/to/repo');\n * const formatted = formatGroupedPreviews(previews);\n * // Returns:\n * // \"\n * // **Vercel Previews:**\n * //    - https://my-app-abc123.vercel.app\n * //\n * // **Cloudflare Previews:**\n * //    - https://my-worker.workers.dev\n * // \"\n * ```\n */\nexport function formatGroupedPreviews(previews: GroupedPreviewUrls): string {\n  let message = '';\n\n  if (previews.vercel.length > 0) {\n    message += '\\n\\n**Vercel Previews:**';\n    for (const url of previews.vercel) {\n      message += `\\n   - ${url}`;\n    }\n  }\n\n  if (previews.cloudflare.length > 0) {\n    message += '\\n\\n**Cloudflare Previews:**';\n    for (const url of previews.cloudflare) {\n      message += `\\n   - ${url}`;\n    }\n  }\n\n  if (previews.supabase.length > 0) {\n    message += '\\n\\n**Supabase Previews:**';\n    for (const url of previews.supabase) {\n      message += `\\n   - ${url}`;\n    }\n  }\n\n  return message;\n}\n\n/**\n * Parse CI checks output into structured format\n *\n * @param output - Raw output from `gh pr checks`\n * @returns Array of parsed check statuses\n *\n * @example\n * ```typescript\n * const checks = parseCIChecks(ciOutput);\n * for (const check of checks) {\n *   console.log(`${check.emoji} ${check.name}: ${check.status}`);\n * }\n * ```\n */\nexport function parseCIChecks(output: string): CheckStatus[] {\n  const checks: CheckStatus[] = [];\n  const lines = output.split('\\n');\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (!trimmed) continue;\n\n    // Parse line format: \"✓ check-name\" or \"X check-name\" or \"* check-name\"\n    let emoji = '⏳';\n    let status = 'pending';\n\n    if (trimmed.startsWith('✓') || trimmed.includes('pass')) {\n      emoji = '✅';\n      status = 'success';\n    } else if (trimmed.startsWith('X') || trimmed.includes('fail')) {\n      emoji = '❌';\n      status = 'failure';\n    } else if (trimmed.includes('cancel')) {\n      emoji = '⚪';\n      status = 'cancelled';\n    }\n\n    // Extract check name (remove status indicator)\n    const name = trimmed.replace(/^[✓X*\\s]+/, '').split('\\t')[0].trim();\n\n    if (name) {\n      checks.push({ name, emoji, status });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Format CI status result as concise string\n *\n * Truncates output to MAX_OUTPUT_CHARS to prevent context bloat.\n *\n * @param result - CI check result\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const ciResult = await waitForCIChecks({ prNumber: 123 }, cwd);\n * const formatted = formatCIStatus(ciResult);\n * console.log(formatted);\n * ```\n */\nexport function formatCIStatus(\n  result: CICheckResult,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = '';\n\n  if (result.success) {\n    output = '✅ All CI checks passed';\n  } else if (result.error) {\n    output = `⚠️ ${result.error}`;\n  } else {\n    output = '❌ CI checks failed';\n  }\n\n  // Add check details if available\n  if (result.output) {\n    const checks = parseCIChecks(result.output);\n    if (checks.length > 0) {\n      const checkLines = checks.map((c) => `${c.emoji} ${c.name}`).join('\\n');\n      output += `\\n\\n${checkLines}`;\n    }\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n/**\n * Format full CI status with PR info and preview URLs\n *\n * @param prNumber - PR number\n * @param prUrl - PR URL\n * @param ciResult - CI check result\n * @param ciRun - CI run details\n * @param previewUrls - Preview URLs\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const status = formatFullCIStatus(\n *   123, 'https://github.com/...', ciResult, ciRun, previewUrls\n * );\n * ```\n */\nexport function formatFullCIStatus(\n  prNumber: number,\n  prUrl: string,\n  ciResult: CICheckResult,\n  ciRun: CIRunDetails | null,\n  previewUrls: PreviewUrls,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = `**PR #${prNumber}**\\n`;\n\n  // CI status\n  if (ciResult.success) {\n    output += '✅ All CI checks passed\\n';\n  } else if (ciResult.error) {\n    output += `⏱️ ${ciResult.error}\\n`;\n  } else {\n    output += '❌ CI checks failed\\n';\n  }\n\n  // CI run link\n  if (ciRun?.url) {\n    output += `🔗 [CI](${ciRun.url})\\n`;\n  }\n\n  // Preview URLs\n  if (previewUrls.allUrls.length > 0) {\n    output += `🌐 ${previewUrls.allUrls[0]}`;\n    if (previewUrls.allUrls.length > 1) {\n      output += ` (+${previewUrls.allUrls.length - 1})`;\n    }\n    output += '\\n';\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n// ============================================================================\n// Fail-Fast CI Checking\n// ============================================================================\n\n/**\n * Check if PR has merge conflicts\n *\n * Queries GitHub API for the PR's mergeable state and returns immediately\n * if conflicts are detected.\n *\n * @param prNumber - PR number to check\n * @param cwd - Working directory\n * @returns Merge conflict result\n *\n * @example\n * ```typescript\n * const conflicts = await checkMergeConflicts(123, '/path/to/repo');\n * if (conflicts.hasConflicts) {\n *   console.log('PR has merge conflicts!');\n * }\n * ```\n */\nexport async function checkMergeConflicts(\n  prNumber: number,\n  cwd: string\n): Promise<MergeConflictResult> {\n  const result = await execCommand(\n    `gh pr view ${prNumber} --json mergeable,mergeStateStatus`,\n    cwd\n  );\n\n  if (!result.success) {\n    return { hasConflicts: false, error: `Failed to check PR: ${result.stderr}` };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const mergeable = data.mergeable;\n    const mergeStateStatus = data.mergeStateStatus;\n\n    // CONFLICTING means merge conflicts exist\n    // UNKNOWN means GitHub is still calculating\n    const hasConflicts = mergeable === 'CONFLICTING' || mergeStateStatus === 'DIRTY';\n\n    return {\n      hasConflicts,\n      mergeableState: mergeStateStatus || mergeable,\n    };\n  } catch {\n    return { hasConflicts: false, error: 'Failed to parse PR data' };\n  }\n}\n\n/**\n * Check if branch is behind main/master\n *\n * Compares the current branch with the default branch (main or master)\n * to determine if it's out of date.\n *\n * @param cwd - Working directory\n * @returns Branch sync status result\n *\n * @example\n * ```typescript\n * const sync = await checkBranchSyncStatus('/path/to/repo');\n * if (!sync.inSync) {\n *   console.log(`Branch is ${sync.behindCount} commits behind main`);\n * }\n * ```\n */\nexport async function checkBranchSyncStatus(cwd: string): Promise<BranchSyncResult> {\n  // First, fetch to ensure we have latest remote refs\n  await execCommand('git fetch origin', cwd);\n\n  // Get current branch\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to get current branch' };\n  }\n  const currentBranch = branchResult.stdout;\n\n  // Determine main branch (main or master)\n  let mainBranch = 'main';\n  const mainCheck = await execCommand('git rev-parse --verify origin/main', cwd);\n  if (!mainCheck.success) {\n    const masterCheck = await execCommand('git rev-parse --verify origin/master', cwd);\n    if (masterCheck.success) {\n      mainBranch = 'master';\n    } else {\n      return { inSync: true, behindCount: 0, aheadCount: 0, error: 'No main/master branch found' };\n    }\n  }\n\n  // Count commits behind and ahead\n  const revListResult = await execCommand(\n    `git rev-list --left-right --count origin/${mainBranch}...${currentBranch}`,\n    cwd\n  );\n\n  if (!revListResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to compare branches' };\n  }\n\n  const [behind, ahead] = revListResult.stdout.split('\\t').map(Number);\n\n  return {\n    inSync: behind === 0,\n    behindCount: behind || 0,\n    aheadCount: ahead || 0,\n  };\n}\n\n/**\n * Get current CI check statuses without waiting\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of check statuses\n */\nasync function getCurrentCIChecks(prNumber: number, cwd: string, timeout = 30000): Promise<CheckStatus[]> {\n  const result = await execCommand(\n    `gh pr checks ${prNumber} --json name,state`,\n    cwd,\n    timeout\n  );\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const checks = JSON.parse(result.stdout);\n    return checks.map((check: { name: string; state: string }) => {\n      let emoji = '⏳';\n      let status = 'pending';\n\n      // gh pr checks returns state directly as SUCCESS, FAILURE, SKIPPED, PENDING, IN_PROGRESS\n      const checkState = check.state.toUpperCase();\n\n      if (checkState === 'SUCCESS') {\n        emoji = '✅';\n        status = 'success';\n      } else if (checkState === 'FAILURE') {\n        emoji = '❌';\n        status = 'failure';\n      } else if (checkState === 'CANCELLED') {\n        emoji = '⚪';\n        status = 'cancelled';\n      } else if (checkState === 'SKIPPED') {\n        emoji = '⏭️';\n        status = 'skipped';\n      } else if (checkState === 'IN_PROGRESS') {\n        emoji = '🔄';\n        status = 'in_progress';\n      } else if (checkState === 'PENDING' || checkState === 'QUEUED') {\n        emoji = '⏳';\n        status = 'pending';\n      }\n\n      return { name: check.name, emoji, status };\n    });\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Await CI checks with fail-fast behavior\n *\n * Checks for blocking conditions in order:\n * 1. Merge conflicts - block immediately\n * 2. Branch out of date with main - block immediately\n * 3. Any CI check failure - block immediately (don't wait for rest)\n *\n * Only returns success if ALL checks pass.\n *\n * @param options - Check options\n * @param options.prNumber - PR number (optional, will detect from branch)\n * @param options.timeout - Max wait time in ms (default: 10 minutes)\n * @param options.pollInterval - Polling interval in ms (default: 5 seconds)\n * @param cwd - Working directory\n * @returns Fail-fast result with blocking reason if failed\n *\n * @example\n * ```typescript\n * const result = await awaitCIWithFailFast({ prNumber: 123 }, '/path/to/repo');\n * if (!result.success) {\n *   return {\n *     decision: 'block',\n *     reason: result.blockReason,\n *   };\n * }\n * ```\n */\nexport async function awaitCIWithFailFast(\n  options: {\n    prNumber?: number;\n    timeout?: number;\n    pollInterval?: number;\n  },\n  cwd: string\n): Promise<FailFastResult> {\n  const { timeout = DEFAULT_TIMEOUT_MS } = options;\n  let { prNumber } = options;\n\n  // Get PR number if not provided\n  if (!prNumber) {\n    prNumber = await getPRForCurrentBranch(cwd) ?? undefined;\n    if (!prNumber) {\n      return {\n        success: true,\n        checks: [],\n        error: 'No PR found for current branch - skipping CI check',\n      };\n    }\n  }\n\n  // 1. Check for merge conflicts FIRST\n  const conflictCheck = await checkMergeConflicts(prNumber, cwd);\n  if (conflictCheck.hasConflicts) {\n    return {\n      success: false,\n      blockReason: `❌ PR #${prNumber} has merge conflicts. Resolve conflicts before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 2. Check if branch is out of date with main\n  const syncCheck = await checkBranchSyncStatus(cwd);\n  if (!syncCheck.inSync && syncCheck.behindCount > 0) {\n    return {\n      success: false,\n      blockReason: `❌ Branch is ${syncCheck.behindCount} commit(s) behind main. Rebase or merge main before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 3. Get latest workflow run for PR's head SHA\n  const headShaResult = await execCommand(\n    `gh pr view ${prNumber} --json headRefOid --jq '.headRefOid'`,\n    cwd,\n    timeout\n  );\n  if (!headShaResult.success) {\n    return {\n      success: false,\n      blockReason: `❌ Failed to get PR head SHA: ${headShaResult.stderr}`,\n      checks: [],\n      prNumber,\n    };\n  }\n  const headSha = headShaResult.stdout.trim();\n\n  // Get the workflow run ID for this commit\n  const runListResult = await execCommand(\n    `gh run list --commit ${headSha} --json databaseId,status --limit 1`,\n    cwd,\n    timeout\n  );\n\n  if (!runListResult.success || !runListResult.stdout.trim() || runListResult.stdout.trim() === '[]') {\n    // No runs yet - check using pr checks instead\n    const checks = await getCurrentCIChecks(prNumber, cwd, timeout);\n    if (checks.length === 0) {\n      return {\n        success: true,\n        checks: [],\n        prNumber,\n        error: 'No CI runs found for this commit',\n      };\n    }\n    // Fall through to check status\n    const allComplete = checks.every((c) => c.status === 'success' || c.status === 'skipped');\n    if (allComplete) {\n      return { success: true, checks, prNumber };\n    }\n    const failedCheck = checks.find((c) => c.status === 'failure' || c.status === 'cancelled');\n    if (failedCheck) {\n      return {\n        success: false,\n        blockReason: `❌ CI check \"${failedCheck.name}\" failed. Fix before continuing.`,\n        failedCheck: failedCheck.name,\n        checks,\n        prNumber,\n      };\n    }\n  }\n\n  let runId: string | undefined;\n  try {\n    const runs = JSON.parse(runListResult.stdout);\n    if (Array.isArray(runs) && runs.length > 0) {\n      runId = String(runs[0].databaseId);\n    }\n  } catch {\n    // Ignore parse errors, will fall back to pr checks\n  }\n\n  if (runId) {\n    // 4. Use gh run watch to wait for completion (with timeout)\n    const timeoutSecs = Math.floor(timeout / 1000);\n    const _watchResult = await execCommand(\n      `timeout ${timeoutSecs} gh run watch ${runId} --exit-status 2>&1 || true`,\n      cwd,\n      timeout + 5000 // Give a bit more time for timeout command\n    );\n\n    // 5. Get final run status using gh run view\n    const viewResult = await execCommand(\n      `gh run view ${runId} --json conclusion,jobs`,\n      cwd,\n      timeout\n    );\n\n    if (viewResult.success) {\n      try {\n        const runData = JSON.parse(viewResult.stdout);\n        const conclusion = runData.conclusion;\n\n        // Get check statuses from jobs\n        const checks: CheckStatus[] = (runData.jobs || []).map((job: { name: string; conclusion: string; status: string }) => {\n          let emoji = '⏳';\n          let status = 'pending';\n\n          if (job.status === 'completed') {\n            if (job.conclusion === 'success') {\n              emoji = '✅';\n              status = 'success';\n            } else if (job.conclusion === 'failure') {\n              emoji = '❌';\n              status = 'failure';\n            } else if (job.conclusion === 'cancelled') {\n              emoji = '⚪';\n              status = 'cancelled';\n            } else if (job.conclusion === 'skipped') {\n              emoji = '⏭️';\n              status = 'skipped';\n            }\n          } else if (job.status === 'in_progress') {\n            emoji = '🔄';\n            status = 'in_progress';\n          }\n\n          return { name: job.name, emoji, status };\n        });\n\n        if (conclusion === 'success') {\n          return { success: true, checks, prNumber };\n        } else if (conclusion === 'failure') {\n          const failedCheck = checks.find((c) => c.status === 'failure');\n          return {\n            success: false,\n            blockReason: `❌ CI check \"${failedCheck?.name || 'unknown'}\" failed. Fix before continuing.`,\n            failedCheck: failedCheck?.name,\n            checks,\n            prNumber,\n          };\n        } else if (conclusion === 'cancelled') {\n          return {\n            success: false,\n            blockReason: `⚪ CI run was cancelled.`,\n            checks,\n            prNumber,\n          };\n        }\n        // Run still in progress or other state\n      } catch {\n        // Parse error, fall through\n      }\n    }\n  }\n\n  // Fallback: get current check statuses\n  const finalChecks = await getCurrentCIChecks(prNumber, cwd, timeout);\n\n  // Check for any failures\n  const failedCheck = finalChecks.find((c) => c.status === 'failure' || c.status === 'cancelled');\n  if (failedCheck) {\n    return {\n      success: false,\n      blockReason: `❌ CI check \"${failedCheck.name}\" failed. Fix before continuing.`,\n      failedCheck: failedCheck.name,\n      checks: finalChecks,\n      prNumber,\n    };\n  }\n\n  // Check if all complete (success or skipped)\n  const allComplete = finalChecks.every((c) => c.status === 'success' || c.status === 'skipped');\n\n  // Safety net: Check for zero checks BEFORE allComplete check\n  // (prevents vacuous truth bug where [].every() returns true)\n  if (finalChecks.length === 0) {\n    return {\n      success: true,\n      checks: [],\n      prNumber,\n      error: 'No CI workflows configured for this repository',\n    };\n  }\n\n  if (allComplete) {\n    return { success: true, checks: finalChecks, prNumber };\n  }\n\n  // Still pending\n  const pendingChecks = finalChecks.filter((c) => c.status === 'pending' || c.status === 'in_progress');\n  return {\n    success: false,\n    blockReason: `⏱️ CI check timeout (${Math.round(timeout / 60000)} minutes). ${pendingChecks.length} check(s) still pending.`,\n    checks: finalChecks,\n    prNumber,\n    error: 'Timeout waiting for CI checks',\n  };\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/debug.ts": "/**\n * Debug utilities for Claude Code hooks\n *\n * Provides logging and error handling with debug mode support. Hook events\n * are logged in JSONL format to .claude/logs/hook-events.json for debugging\n * and troubleshooting hook execution.\n *\n * Each log entry is a single JSON object per line with timestamp, event name,\n * type (input/output/error), and the associated data.\n *\n * @module debug\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst HOOK_EVENTS_FILE = 'hook-events.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface DebugConfig {\n  debug?: boolean;\n}\n\nexport interface HookEventEntry {\n  timestamp: string;\n  event: string;\n  type: 'input' | 'output' | 'error';\n  data: unknown;\n}\n\nexport interface DebugLogger {\n  logInput: (input: unknown) => Promise<void>;\n  logOutput: (output: unknown) => Promise<void>;\n  logError: (error: Error) => Promise<void>;\n}\n\n// ============================================================================\n// Debug Logging (JSONL append to hook-events.json)\n// ============================================================================\n\n/**\n * Append a hook event entry to hook-events.json (JSONL format)\n *\n * Writes a single-line JSON entry to the log file, creating the directory\n * structure if it doesn't exist. Failures are silently ignored to prevent\n * logging errors from breaking hook execution.\n *\n * @param cwd - The working directory where .claude/logs/ should be created\n * @param entry - The hook event entry to append to the log file\n * @returns Promise that resolves when the entry is written (or fails silently)\n *\n * @example\n * ```typescript\n * await appendHookEvent('/path/to/project', {\n *   timestamp: new Date().toISOString(),\n *   event: 'SessionStart',\n *   type: 'input',\n *   data: { cwd: '/path/to/project' }\n * });\n * ```\n */\nasync function appendHookEvent(cwd: string, entry: HookEventEntry): Promise<void> {\n  const logDir = path.join(cwd, LOGS_DIR);\n  const logFile = path.join(logDir, HOOK_EVENTS_FILE);\n\n  try {\n    await fs.mkdir(logDir, { recursive: true });\n    await fs.appendFile(logFile, JSON.stringify(entry) + '\\n', 'utf-8');\n  } catch {\n    // Silently fail - don't break hook execution for logging\n  }\n}\n\n/**\n * Create a debug logger for a hook execution\n *\n * Returns a logger object with methods for logging hook inputs, outputs, and errors\n * to .claude/logs/hook-events.json in JSONL format. Logging only occurs when debug\n * mode is enabled.\n *\n * @param cwd - The working directory where logs should be written\n * @param hookEventName - The name of the hook event (e.g., 'SessionStart', 'PostToolUse')\n * @param debug - Whether debug logging is enabled\n * @returns A DebugLogger with logInput, logOutput, and logError methods\n *\n * @example\n * ```typescript\n * import { createDebugLogger } from './debug.js';\n *\n * const logger = createDebugLogger('/path/to/project', 'SessionStart', true);\n *\n * await logger.logInput({ cwd: '/path/to/project', source: 'startup' });\n * await logger.logOutput({ success: true, message: 'Hook completed' });\n * ```\n */\nexport function createDebugLogger(\n  cwd: string,\n  hookEventName: string,\n  _debug: boolean\n): DebugLogger {\n  return {\n    logInput: async (input: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'input',\n        data: input,\n      });\n    },\n\n    logOutput: async (output: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'output',\n        data: output,\n      });\n    },\n\n    logError: async (error: Error) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'error',\n        data: {\n          name: error.name,\n          message: error.message,\n          stack: error.stack,\n        },\n      });\n    },\n  };\n}\n\n// ============================================================================\n// Error Handling\n// ============================================================================\n\n/**\n * Create a blocking error response for hooks\n *\n * Generates an appropriate error response object that blocks execution when\n * a hook error occurs in debug mode. The response format varies by hook event\n * type to match the expected output schema.\n *\n * @param hookEventName - The name of the hook event that errored\n * @param error - The error that occurred during hook execution\n * @returns A hook output object configured to block/deny with error details\n *\n * @example\n * ```typescript\n * import { createBlockingErrorResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   return createBlockingErrorResponse('PreToolUse', error as Error);\n *   // Returns: { hookSpecificOutput: { permissionDecision: 'deny', ... } }\n * }\n * ```\n */\nexport function createBlockingErrorResponse(\n  hookEventName: string,\n  error: Error\n): Record<string, unknown> {\n  const baseResponse = {\n    continue: false,\n    stopReason: `Hook error: ${error.message}`,\n    systemMessage: `Hook ${hookEventName} failed: ${error.message}`,\n  };\n\n  // Add hook-specific output based on event type\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        ...baseResponse,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'PostToolUse':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `Hook error: ${error.message}\\n${error.stack || ''}`,\n        },\n      };\n\n    case 'SubagentStop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    case 'UserPromptSubmit':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'Stop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    default:\n      return baseResponse;\n  }\n}\n\n/**\n * Create a pass-through response for hooks\n *\n * Generates an appropriate response object that allows execution to continue\n * when a hook error occurs and debug mode is disabled. The response format\n * varies by hook event type to match the expected output schema while permitting\n * normal Claude Code operation.\n *\n * @param hookEventName - The name of the hook event\n * @returns A hook output object configured to allow/pass-through\n *\n * @example\n * ```typescript\n * import { createPassthroughResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   if (!debugMode) {\n *     return createPassthroughResponse('PreToolUse');\n *     // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *   }\n * }\n * ```\n */\nexport function createPassthroughResponse(hookEventName: string): Record<string, unknown> {\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n\n    case 'PostToolUse':\n      return {};\n\n    case 'SessionStart':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n\n    case 'SubagentStart':\n      return {};\n\n    case 'SubagentStop':\n      return {};\n\n    default:\n      return {};\n  }\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/frontmatter.ts": "/**\n * Simple YAML frontmatter parser - zero dependencies\n *\n * Replaces gray-matter with a lightweight custom implementation\n * that handles the basic YAML frontmatter patterns used in this project.\n *\n * @module frontmatter\n */\n\n/**\n * Parse YAML frontmatter from markdown content\n *\n * Extracts YAML frontmatter between --- delimiters and parses\n * simple key-value pairs and arrays. Returns data object and remaining content.\n *\n * Supported YAML patterns:\n * - Simple key-value: `name: value`\n * - Arrays: `skills: [item1, item2]` or multi-line arrays\n * - Nested (basic): `field: { key: value }`\n *\n * @param content - Markdown content with optional frontmatter\n * @returns Object with `data` (parsed YAML) and `content` (remaining markdown)\n *\n * @example\n * ```typescript\n * import { parseFrontmatter } from './frontmatter.js';\n *\n * const markdown = `---\n * name: MyAgent\n * skills: [skill1, skill2]\n * ---\n *\n * # Content here\n * `;\n *\n * const { data, content } = parseFrontmatter(markdown);\n * console.log(data.name); // 'MyAgent'\n * console.log(data.skills); // ['skill1', 'skill2']\n * ```\n */\nexport function parseFrontmatter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  const frontmatterRegex = /^---\\s*\\n([\\s\\S]*?)\\n---\\s*\\n([\\s\\S]*)$/;\n  const match = content.match(frontmatterRegex);\n\n  if (!match) {\n    return { data: {}, content };\n  }\n\n  const [, yamlContent, remainingContent] = match;\n  const data = parseSimpleYaml(yamlContent);\n\n  return { data, content: remainingContent };\n}\n\n/**\n * Parse simple YAML content into JavaScript object\n *\n * Handles common YAML patterns used in frontmatter:\n * - Key-value pairs\n * - Inline arrays: [item1, item2, item3]\n * - Multi-line arrays with - prefix\n * - Nested objects (basic)\n *\n * @param yaml - YAML content string\n * @returns Parsed JavaScript object\n */\nfunction parseSimpleYaml(yaml: string): Record<string, unknown> {\n  const data: Record<string, unknown> = {};\n  const lines = yaml.split('\\n');\n  let i = 0;\n\n  while (i < lines.length) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      i++;\n      continue;\n    }\n\n    // Parse key-value pair\n    const colonIndex = line.indexOf(':');\n    if (colonIndex === -1) {\n      i++;\n      continue;\n    }\n\n    const key = line.substring(0, colonIndex).trim();\n    const value = line.substring(colonIndex + 1).trim();\n\n    // Handle inline array: [item1, item2]\n    if (value.startsWith('[') && value.endsWith(']')) {\n      const arrayContent = value.slice(1, -1);\n      data[key] = arrayContent.split(',').map(item => item.trim());\n      i++;\n      continue;\n    }\n\n    // Handle multi-line array\n    if (value === '' && i + 1 < lines.length && lines[i + 1].trim().startsWith('-')) {\n      const arrayItems: string[] = [];\n      i++;\n      while (i < lines.length && lines[i].trim().startsWith('-')) {\n        const item = lines[i].trim().substring(1).trim();\n        arrayItems.push(item);\n        i++;\n      }\n      data[key] = arrayItems;\n      continue;\n    }\n\n    // Handle inline object: { key: value }\n    if (value.startsWith('{') && value.endsWith('}')) {\n      const objectContent = value.slice(1, -1);\n      const obj: Record<string, unknown> = {};\n      const pairs = objectContent.split(',');\n      for (const pair of pairs) {\n        const [objKey, objValue] = pair.split(':').map(s => s.trim());\n        obj[objKey] = parseValue(objValue);\n      }\n      data[key] = obj;\n      i++;\n      continue;\n    }\n\n    // Handle simple value\n    data[key] = parseValue(value);\n    i++;\n  }\n\n  return data;\n}\n\n/**\n * Parse a YAML value to appropriate JavaScript type\n *\n * Converts:\n * - 'true'/'false' → boolean\n * - 'null' → null\n * - Numbers → number\n * - Quoted strings → unquoted string\n * - Everything else → string\n *\n * @param value - YAML value string\n * @returns Parsed value in appropriate type\n */\nfunction parseValue(value: string): unknown {\n  // Handle boolean\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle null\n  if (value === 'null' || value === '~') return null;\n\n  // Handle number\n  if (/^-?\\d+(\\.\\d+)?$/.test(value)) {\n    return Number(value);\n  }\n\n  // Handle quoted strings\n  if ((value.startsWith('\"') && value.endsWith('\"')) ||\n      (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n    return value.slice(1, -1);\n  }\n\n  // Return as string\n  return value;\n}\n\n/**\n * gray-matter compatible interface\n *\n * Provides same API as gray-matter for drop-in replacement.\n *\n * @param content - Markdown content with frontmatter\n * @returns Object with `data` and `content` properties\n */\nexport default function matter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  return parseFrontmatter(content);\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/github-comments.ts": "/**\n * GitHub comment utilities for Stop hook\n *\n * Provides utilities for:\n * - Checking if a session comment exists on a GitHub issue\n * - Posting session progress comments with session ID markers\n * - Discovering the linked issue number for a branch\n *\n * Session comments include a hidden HTML marker that allows the Stop hook\n * to detect whether progress has been documented for a given session.\n * @module github-comments\n */\n\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst COMMENT_MARKER_PREFIX = '<!-- claude-session: ';\nconst COMMENT_MARKER_SUFFIX = ' -->';\nconst EXPLORE_MARKER_PREFIX = '<!-- claude-explore: ';\nconst EXPLORE_MARKER_SUFFIX = ' -->';\nconst PLAN_UPDATE_MARKER_PREFIX = '<!-- plan-update-v';\nconst PLAN_UPDATE_MARKER_SUFFIX = ' -->';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Plan issue state tracking\n */\ninterface PlanIssueState {\n  /**\n   * Map of session IDs to issue metadata\n   */\n  [sessionId: string]: {\n    /**\n     * Path to the plan file\n     */\n    planPath: string;\n    /**\n     * GitHub issue number\n     */\n    issueNumber: number;\n    /**\n     * Full GitHub issue URL\n     */\n    issueUrl: string;\n    /**\n     * Git branch name\n     */\n    branch: string;\n    /**\n     * ISO timestamp when issue was created\n     */\n    createdAt: string;\n    /**\n     * ISO timestamp of last update\n     */\n    lastUpdated: string;\n  };\n}\n\n/**\n * GitHub issue with comments\n */\ninterface GitHubIssue {\n  /**\n   * Issue number\n   */\n  number: number;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * Issue body content\n   */\n  body: string;\n  /**\n   * Issue comments\n   */\n  comments?: Array<{\n    /**\n     * Comment author\n     */\n    author: { login: string };\n    /**\n     * Comment body\n     */\n    body: string;\n    /**\n     * ISO timestamp when comment was created\n     */\n    createdAt: string;\n  }>;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command\n * @param command - Shell command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execCommand('git rev-parse --abbrev-ref HEAD', '/path/to/project');\n * if (result.success) {\n *   console.log('Branch:', result.stdout);\n * }\n * ```\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n *\n * Uses spawn + stdin to avoid shell escaping issues when passing\n * markdown content with special characters.\n * @param args - Arguments to pass to gh command\n * @param stdin - Content to write to stdin\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execGhWithStdin(\n *   ['issue', 'comment', '123', '--body-file', '-'],\n *   'This is my comment content',\n *   '/path/to/project'\n * );\n * ```\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    // Write body to stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n// ============================================================================\n// Issue Discovery\n// ============================================================================\n\n/**\n * Load plan issue state from disk\n * @param cwd - Working directory\n * @returns Plan issue state map\n * @example\n * ```typescript\n * const state = await loadPlanIssueState('/path/to/project');\n * const sessionInfo = state['session-id'];\n * if (sessionInfo) {\n *   console.log('Issue number:', sessionInfo.issueNumber);\n * }\n * ```\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Parse issue number from branch name\n *\n * Extracts issue number from branch names like:\n * - issue-123-description\n * - feature/issue-456\n * - 789-fix-bug\n * @param branch - Git branch name\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNum = parseIssueFromBranch('issue-123-add-feature');\n * // Returns: 123\n *\n * const noIssue = parseIssueFromBranch('main');\n * // Returns: null\n * ```\n */\nfunction parseIssueFromBranch(branch: string): number | null {\n  // Try pattern: issue-123-...\n  const issueMatch = branch.match(/issue[_-](\\d+)/i);\n  if (issueMatch) {\n    return parseInt(issueMatch[1], 10);\n  }\n\n  // Try pattern: 123-...\n  const numMatch = branch.match(/^(\\d+)[_-]/);\n  if (numMatch) {\n    return parseInt(numMatch[1], 10);\n  }\n\n  return null;\n}\n\n/**\n * Get linked issue number for current branch\n *\n * Discovers issue number using cascading fallback strategy:\n * 1. Check plan-issues.json state file (by session ID and branch name)\n * 2. Parse from branch name pattern (issue-123-...)\n * 3. Search GitHub for issues mentioning the branch\n * @param branch - Git branch name\n * @param cwd - Working directory\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNumber = await getLinkedIssueNumber('issue-57-stop-hook', '/path/to/project');\n * if (issueNumber) {\n *   console.log('Linked to issue #' + issueNumber);\n * }\n * ```\n */\nexport async function getLinkedIssueNumber(\n  branch: string,\n  cwd: string\n): Promise<number | null> {\n  // STRATEGY 1: Check plan-issues.json state file\n  const state = await loadPlanIssueState(cwd);\n\n  // Find by branch name across all sessions\n  for (const sessionState of Object.values(state)) {\n    if (sessionState.branch === branch) {\n      return sessionState.issueNumber;\n    }\n  }\n\n  // STRATEGY 2: Parse from branch name\n  const parsedIssue = parseIssueFromBranch(branch);\n  if (parsedIssue !== null) {\n    // Verify issue exists\n    const verifyResult = await execCommand(`gh issue view ${parsedIssue} --json number`, cwd);\n    if (verifyResult.success) {\n      return parsedIssue;\n    }\n  }\n\n  // STRATEGY 3: Search GitHub for issues mentioning the branch\n  const searchResult = await execCommand(\n    `gh issue list --search \"in:body ${branch}\" --json number --limit 1`,\n    cwd\n  );\n\n  if (searchResult.success && searchResult.stdout) {\n    try {\n      const issues = JSON.parse(searchResult.stdout);\n      if (issues.length > 0) {\n        return issues[0].number;\n      }\n    } catch {\n      // Parse error\n    }\n  }\n\n  return null;\n}\n\n// ============================================================================\n// Comment Management\n// ============================================================================\n\n/**\n * Create session comment marker\n * @param sessionId - Session ID to embed in marker\n * @returns HTML comment marker\n * @example\n * ```typescript\n * const marker = createSessionMarker('abc-123');\n * // Returns: '<!-- claude-session: abc-123 -->'\n * ```\n */\nfunction createSessionMarker(sessionId: string): string {\n  return `${COMMENT_MARKER_PREFIX}${sessionId}${COMMENT_MARKER_SUFFIX}`;\n}\n\n/**\n * Check if a comment contains a session marker\n *\n * Uses two validation strategies for robustness:\n * 1. Exact HTML marker match: `<!-- claude-session: SESSION_ID -->` (preferred)\n * 2. Plain session ID substring match (lenient fallback)\n *\n * The lenient fallback prevents infinite blocking loops when agents post\n * comments without the exact HTML marker format. Session IDs are unique\n * enough (UUID-like strings) that false positives are extremely unlikely.\n *\n * @param commentBody - Comment body text\n * @param sessionId - Session ID to search for\n * @returns True if comment contains the session marker or plain session ID\n * @example\n * ```typescript\n * // Exact marker (preferred, backward compatible)\n * commentHasSessionMarker(\n *   '<!-- claude-session: abc-123 -->\\n\\nMy comment',\n *   'abc-123'\n * );\n * // Returns: true\n *\n * // Plain session ID (lenient fallback)\n * commentHasSessionMarker(\n *   'Session abc-123 completed work',\n *   'abc-123'\n * );\n * // Returns: true\n * ```\n */\nfunction commentHasSessionMarker(commentBody: string, sessionId: string): boolean {\n  // Strategy 1: Check for exact HTML marker (backward compatible, preferred)\n  const marker = createSessionMarker(sessionId);\n  if (commentBody.includes(marker)) {\n    return true;\n  }\n\n  // Strategy 2: Check for plain session ID (lenient fallback)\n  // Session IDs are unique/long enough that false positives are unlikely\n  // This prevents infinite blocking loops when agents don't include exact marker\n  if (commentBody.includes(sessionId)) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Check if a session comment exists on a GitHub issue\n *\n * Fetches all comments for the issue and searches for the session ID marker.\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID to search for\n * @param cwd - Working directory\n * @returns True if a comment with the session marker exists\n * @example\n * ```typescript\n * import { hasCommentForSession } from './github-comments.js';\n *\n * const hasComment = await hasCommentForSession(57, 'session-abc-123', '/path/to/project');\n * if (hasComment) {\n *   console.log('Progress already documented for this session');\n * }\n * ```\n */\nexport async function hasCommentForSession(\n  issueNumber: number,\n  sessionId: string,\n  cwd: string\n): Promise<boolean> {\n  // Fetch issue with comments\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return false;\n  }\n\n  try {\n    const issue: GitHubIssue = JSON.parse(result.stdout);\n\n    if (!issue.comments || issue.comments.length === 0) {\n      return false;\n    }\n\n    // Search for session marker in comments\n    return issue.comments.some((comment) =>\n      commentHasSessionMarker(comment.body, sessionId)\n    );\n  } catch {\n    // Parse error\n    return false;\n  }\n}\n\n/**\n * Post a session progress comment to a GitHub issue\n *\n * Creates a formatted comment with:\n * - Hidden session ID marker for detection\n * - Session metadata (ID, branch, timestamp)\n * - User-provided content\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID\n * @param content - Comment content (markdown)\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n * @example\n * ```typescript\n * import { postSessionComment } from './github-comments.js';\n *\n * const posted = await postSessionComment(\n *   57,\n *   'session-abc-123',\n *   'Completed hook implementation and tests',\n *   'issue-57-stop-hook',\n *   '/path/to/project'\n * );\n * if (posted) {\n *   console.log('Comment posted successfully');\n * }\n * ```\n */\nexport async function postSessionComment(\n  issueNumber: number,\n  sessionId: string,\n  content: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = createSessionMarker(sessionId);\n\n  const commentBody = `${marker}\n\n## 🤖 Claude Session Progress\n\n**Session ID:** \\`${sessionId}\\`\n**Branch:** \\`${branch}\\`\n**Timestamp:** ${timestamp}\n\n${content}\n\n---\n*Posted automatically via Stop hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n\n/**\n * Create explore comment marker\n * @param taskId - Unique task identifier (e.g., tool_use_id)\n * @returns HTML comment marker\n */\nfunction createExploreMarker(taskId: string): string {\n  return `${EXPLORE_MARKER_PREFIX}${taskId}${EXPLORE_MARKER_SUFFIX}`;\n}\n\n/**\n * Check if an explore comment already exists for a task\n *\n * @param issueNumber - GitHub issue number\n * @param taskId - Unique task identifier\n * @param cwd - Working directory\n * @returns True if a comment with the explore marker exists\n */\nexport async function hasExploreComment(\n  issueNumber: number,\n  taskId: string,\n  cwd: string\n): Promise<boolean> {\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return false;\n  }\n\n  try {\n    const issue: GitHubIssue = JSON.parse(result.stdout);\n    if (!issue.comments || issue.comments.length === 0) {\n      return false;\n    }\n\n    const marker = createExploreMarker(taskId);\n    return issue.comments.some((comment) => comment.body.includes(marker));\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Post an Explore agent findings comment to a GitHub issue\n *\n * Creates a formatted comment with:\n * - Hidden task ID marker for duplicate detection\n * - Query/prompt that was explored\n * - Collapsible details with full findings\n *\n * @param issueNumber - GitHub issue number\n * @param taskId - Unique task identifier (tool_use_id)\n * @param query - The original explore query/prompt\n * @param findings - The agent's findings/output text\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n *\n * @example\n * ```typescript\n * const posted = await postExploreComment(\n *   212,\n *   'toolu_abc123',\n *   'Find all API endpoints in the codebase',\n *   'Found 15 API endpoints across 8 files...',\n *   'issue-212-explore',\n *   '/path/to/project'\n * );\n * ```\n */\nexport async function postExploreComment(\n  issueNumber: number,\n  taskId: string,\n  query: string,\n  findings: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = createExploreMarker(taskId);\n\n  // Truncate query if too long\n  const displayQuery = query.length > 200 ? query.slice(0, 197) + '...' : query;\n\n  const commentBody = `${marker}\n\n## 🔍 Explore Agent Findings\n\n**Query**: ${displayQuery}\n**Branch**: \\`${branch}\\`\n**Timestamp**: ${timestamp}\n\n<details>\n<summary>View findings</summary>\n\n${findings}\n\n</details>\n\n---\n*Posted automatically via SubagentStop hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n\n/**\n * Post a plan update comment to a GitHub issue\n *\n * Creates a versioned comment that documents when the plan was updated.\n * Each plan edit posts a new comment with an incrementing version number.\n *\n * @param issueNumber - GitHub issue number\n * @param version - Plan version number (1, 2, 3, etc.)\n * @param action - Whether this was 'created' or 'updated'\n * @param planPath - Path to the plan file\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n *\n * @example\n * ```typescript\n * const posted = await postPlanUpdateComment(\n *   212,\n *   2,\n *   'updated',\n *   '/home/user/.claude/plans/my-plan.md',\n *   'issue-212-feature',\n *   '/path/to/project'\n * );\n * ```\n */\nexport async function postPlanUpdateComment(\n  issueNumber: number,\n  version: number,\n  action: 'created' | 'updated',\n  planPath: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = `${PLAN_UPDATE_MARKER_PREFIX}${version}${PLAN_UPDATE_MARKER_SUFFIX}`;\n\n  const actionEmoji = action === 'created' ? '✨' : '📝';\n  const actionText = action === 'created' ? 'Plan created' : 'Plan updated';\n\n  const commentBody = `${marker}\n\n## ${actionEmoji} ${actionText} (v${version})\n\n**Timestamp**: ${timestamp}\n**Plan file**: \\`${planPath}\\`\n**Branch**: \\`${branch}\\`\n\n---\n*Plan synced automatically via PostToolUse hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/github-state.ts": "/**\n * Unified GitHub session state management\n *\n * Manages tracking of GitHub PRs and issues created during Claude sessions\n * in a single github.json file. This enables:\n * - Cross-session awareness of related PRs and issues\n * - Tracking linked issues from PR bodies\n * - Unified state for session stop output\n *\n * State is stored in .claude/logs/github.json\n *\n * @module github-state\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst GITHUB_STATE_FILE = 'github.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Reference to a GitHub PR created during a session\n */\nexport interface SessionPR {\n  /**\n   * PR number\n   */\n  number: number;\n  /**\n   * Full GitHub PR URL\n   */\n  url: string;\n  /**\n   * PR title\n   */\n  title: string;\n  /**\n   * ISO timestamp when PR was created\n   */\n  createdAt: string;\n  /**\n   * Issue numbers linked via PR body (Fixes #123, etc.)\n   */\n  linkedIssues: number[];\n}\n\n/**\n * Reference to a GitHub issue created during a session\n */\nexport interface SessionIssue {\n  /**\n   * Issue number\n   */\n  number: number;\n  /**\n   * Full GitHub issue URL\n   */\n  url: string;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * ISO timestamp when issue was created\n   */\n  createdAt: string;\n}\n\n/**\n * Complete GitHub session state\n */\nexport interface GitHubSessionState {\n  /**\n   * Session identifier\n   */\n  sessionId: string;\n  /**\n   * PRs created during this session\n   */\n  prs: SessionPR[];\n  /**\n   * Issues created during this session\n   */\n  issues: SessionIssue[];\n  /**\n   * ISO timestamp of last update\n   */\n  lastUpdated: string;\n}\n\n/**\n * Map of session IDs to their GitHub state\n */\nexport interface GitHubStateFile {\n  [sessionId: string]: GitHubSessionState;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to github.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the github state file\n */\nfunction getGitHubStateFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, GITHUB_STATE_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Load GitHub state from disk\n *\n * Loads all tracked sessions and their PRs/issues. If the file doesn't exist\n * or is invalid, returns an empty state.\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns The complete GitHub state\n */\nexport async function loadGitHubState(\n  cwd: string,\n  statePath?: string\n): Promise<GitHubStateFile> {\n  const filePath = getGitHubStateFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    // File doesn't exist or parse error - return empty state\n    return {};\n  }\n}\n\n/**\n * Save GitHub state to disk\n *\n * Persists the complete state to disk. Automatically creates the logs directory\n * if it doesn't exist.\n * @param cwd - The working directory where logs are stored\n * @param state - The complete GitHub state to save\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Promise that resolves when state is saved\n */\nasync function saveGitHubState(\n  cwd: string,\n  state: GitHubStateFile,\n  statePath?: string\n): Promise<void> {\n  const filePath = getGitHubStateFilePath(cwd, statePath);\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(state, null, 2), 'utf-8');\n}\n\n/**\n * Get or create session state\n * @param sessionId - Session identifier\n * @param state - Current state file\n * @returns Session state (existing or new)\n */\nfunction getOrCreateSessionState(\n  sessionId: string,\n  state: GitHubStateFile\n): GitHubSessionState {\n  if (!state[sessionId]) {\n    state[sessionId] = {\n      sessionId,\n      prs: [],\n      issues: [],\n      lastUpdated: new Date().toISOString(),\n    };\n  }\n  return state[sessionId];\n}\n\n/**\n * Add a PR to session state\n *\n * Records that a PR was created during a session. If the session doesn't exist,\n * it will be created. Automatically enforces a 100-session limit.\n * @param sessionId - The session ID\n * @param pr - The PR reference to add\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Promise that resolves when the PR is added\n */\nexport async function addPRToState(\n  sessionId: string,\n  pr: SessionPR,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  let state = await loadGitHubState(cwd, statePath);\n  const sessionState = getOrCreateSessionState(sessionId, state);\n\n  // Check if PR already exists (avoid duplicates)\n  const existingIndex = sessionState.prs.findIndex((p) => p.number === pr.number);\n  if (existingIndex >= 0) {\n    // Update existing PR (e.g., with new linked issues)\n    sessionState.prs[existingIndex] = pr;\n  } else {\n    sessionState.prs.push(pr);\n  }\n\n  sessionState.lastUpdated = new Date().toISOString();\n\n  // Limit to last 100 sessions\n  state = enforceSessionLimit(state, 100);\n\n  await saveGitHubState(cwd, state, statePath);\n}\n\n/**\n * Add an issue to session state\n *\n * Records that an issue was created during a session. If the session doesn't exist,\n * it will be created. Automatically enforces a 100-session limit.\n * @param sessionId - The session ID\n * @param issue - The issue reference to add\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Promise that resolves when the issue is added\n */\nexport async function addIssueToState(\n  sessionId: string,\n  issue: SessionIssue,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  let state = await loadGitHubState(cwd, statePath);\n  const sessionState = getOrCreateSessionState(sessionId, state);\n\n  // Check if issue already exists (avoid duplicates)\n  const existingIndex = sessionState.issues.findIndex((i) => i.number === issue.number);\n  if (existingIndex >= 0) {\n    // Update existing issue\n    sessionState.issues[existingIndex] = issue;\n  } else {\n    sessionState.issues.push(issue);\n  }\n\n  sessionState.lastUpdated = new Date().toISOString();\n\n  // Limit to last 100 sessions\n  state = enforceSessionLimit(state, 100);\n\n  await saveGitHubState(cwd, state, statePath);\n}\n\n/**\n * Get PRs created during a specific session\n * @param sessionId - The session ID to query\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Array of PR references\n */\nexport async function getSessionPRs(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionPR[]> {\n  const state = await loadGitHubState(cwd, statePath);\n  return state[sessionId]?.prs || [];\n}\n\n/**\n * Get issues created during a specific session\n * @param sessionId - The session ID to query\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Array of issue references\n */\nexport async function getSessionIssuesFromState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionIssue[]> {\n  const state = await loadGitHubState(cwd, statePath);\n  return state[sessionId]?.issues || [];\n}\n\n/**\n * Get the full session state\n * @param sessionId - The session ID to query\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Session state or null if not found\n */\nexport async function getSessionGitHubState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<GitHubSessionState | null> {\n  const state = await loadGitHubState(cwd, statePath);\n  return state[sessionId] || null;\n}\n\n/**\n * Enforce session limit by removing oldest sessions\n * @param state - Current state\n * @param limit - Maximum number of sessions to keep\n * @returns Updated state\n */\nfunction enforceSessionLimit(state: GitHubStateFile, limit: number): GitHubStateFile {\n  const sessionIds = Object.keys(state);\n  if (sessionIds.length <= limit) {\n    return state;\n  }\n\n  // Sort by lastUpdated, keep newest\n  const sorted = sessionIds\n    .map((id) => ({ id, lastUpdated: state[id].lastUpdated }))\n    .sort((a, b) => new Date(b.lastUpdated).getTime() - new Date(a.lastUpdated).getTime())\n    .slice(0, limit);\n\n  const newState: GitHubStateFile = {};\n  for (const { id } of sorted) {\n    newState[id] = state[id];\n  }\n  return newState;\n}\n\n/**\n * Clean up old sessions from state file\n * @param cwd - The working directory where logs are stored\n * @param retentionDays - Number of days to retain sessions (default: 30)\n * @param statePath - Optional custom path for github.json (for testing)\n * @returns Promise that resolves when cleanup is complete\n */\nexport async function cleanupOldGitHubSessions(\n  cwd: string,\n  retentionDays: number = 30,\n  statePath?: string\n): Promise<void> {\n  const state = await loadGitHubState(cwd, statePath);\n  const cutoffTime = Date.now() - retentionDays * 24 * 60 * 60 * 1000;\n\n  let modified = false;\n  const newState: GitHubStateFile = {};\n\n  for (const [sessionId, session] of Object.entries(state)) {\n    const sessionTime = new Date(session.lastUpdated).getTime();\n    if (sessionTime >= cutoffTime) {\n      newState[sessionId] = session;\n    } else {\n      modified = true;\n    }\n  }\n\n  if (modified) {\n    await saveGitHubState(cwd, newState, statePath);\n  }\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/index.ts": "/**\n * Hook Utilities - Re-exports\n *\n * Centralized exports for all hook utility functions, types, and helpers.\n * This index file provides convenient access to all shared utilities used\n * across Claude Code plugins.\n *\n * For smaller bundle sizes, prefer importing directly from individual modules\n * rather than using this index file. Direct imports allow tree-shaking to\n * eliminate unused code.\n *\n * @example\n * ```typescript\n * // Preferred: Direct import (better for tree-shaking)\n * import { readStdinJson } from './utils/io.js';\n * import { createDebugLogger } from './utils/debug.js';\n *\n * // Alternative: Import from index (more convenient)\n * import { readStdinJson, createDebugLogger } from './utils/index.js';\n * ```\n *\n * @module utils/index\n */\n\n// ============================================================================\n// I/O Utilities and Hook Runner\n// ============================================================================\n// Functions for reading hook input from stdin, writing output to stdout,\n// and wrapping hook handlers for execution.\n\nexport { readStdinJson, writeStdoutJson, runHook, type HookHandler } from './io.js';\n\n// ============================================================================\n// Debug Utilities\n// ============================================================================\n// Debug logging with JSONL output to .claude/logs/hook-events.json.\n// Supports DEBUG environment variable for filtering output.\n\nexport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  createPassthroughResponse,\n  type DebugConfig,\n  type DebugLogger,\n  type HookEventEntry,\n} from './debug.js';\n\n// ============================================================================\n// Transcript Parsing\n// ============================================================================\n// Parse Claude Code transcript JSONL files to analyze agent conversations,\n// tool uses, and file operations.\n\nexport {\n  parseTranscript,\n  parseTranscriptLine,\n  getTranscriptInfo,\n  getToolUses,\n  getEditedFiles,\n  getNewFiles,\n  getDeletedFiles,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  type Transcript,\n  type Message,\n  type UserMessage,\n  type AssistantMessage,\n  type SystemMessage,\n} from './transcripts.js';\n\n// ============================================================================\n// Subagent State Management\n// ============================================================================\n// Save and load subagent execution context, and analyze file operations\n// performed by agents.\n\nexport {\n  saveAgentStartContext,\n  loadAgentStartContext,\n  removeAgentStartContext,\n  getAgentEdits,\n  type AgentStartContext,\n  type AgentEditsResult,\n} from './subagent-state.js';\n\n// ============================================================================\n// Task State Management\n// ============================================================================\n// Save and load Task tool call context, and analyze file operations\n// performed within tasks.\n\nexport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n  getTaskEdits,\n  type TaskCallContext,\n  type TaskEditsResult,\n} from './task-state.js';\n\n// ============================================================================\n// Package Manager Detection\n// ============================================================================\n// Detect which package manager (npm, yarn, pnpm, bun) a project uses\n// and construct appropriate commands.\n\nexport { detectPackageManager, getScriptCommand } from './package-manager.js';\n\n// ============================================================================\n// TOML Parsing\n// ============================================================================\n// Simple TOML parser for reading configuration files like supabase/config.toml.\n\nexport { parseToml, readTomlFile, type TomlValue } from './toml.js';\n\n// ============================================================================\n// Agent Type Detection\n// ============================================================================\n// Utilities for determining if a tool event was triggered by the main agent\n// or a subagent, and extracting agent IDs from transcripts.\n\nexport {\n  wasToolEventMainAgent,\n  isMainAgentTranscript,\n  isSubagentType,\n  getTranscriptAgentId,\n} from './was-tool-event-main-agent.js';\n\n// ============================================================================\n// Log File Utilities\n// ============================================================================\n// Save hook output to log files and return concise summaries.\n// Used to reduce context injection while preserving full output for debugging.\n\nexport {\n  saveOutputToLog,\n  parseEslintCounts,\n  parseTscErrorCount,\n  parseVitestResults,\n  parseCiChecks,\n  formatCiChecksTable,\n  formatErrorSummary,\n  formatSuccessMessage,\n} from './log-file.js';\n\n// ============================================================================\n// Work Type Detection\n// ============================================================================\n// Detect work type from prompts and issue labels for branch naming and\n// issue categorization.\n\nexport {\n  detectWorkType,\n  formatWorkTypeLabel,\n  type WorkType,\n} from './work-type-detector.js';\n\n// ============================================================================\n// Branch Naming\n// ============================================================================\n// Generate, parse, and validate branch names following the convention\n// {issueNumber}-{workType}/{kebab-name}.\n\nexport {\n  generateBranchName,\n  parseBranchName,\n  validateBranchName,\n  extractIssueNumber,\n  toKebabCase,\n  type ParsedBranchName,\n  type BranchValidation,\n} from './branch-naming.js';\n\n// ============================================================================\n// Issue Templates\n// ============================================================================\n// GitHub issue templates for bug reports, feature requests, and epics.\n\nexport {\n  getBugTemplate,\n  getFeatureTemplate,\n  getEpicTemplate,\n  getTaskTemplate,\n  renderTemplate,\n  getMinimalIssueBody,\n  createSubissueBody,\n  addBranchReference,\n  type TemplateVars,\n} from './issue-templates.js';\n\n// ============================================================================\n// PR Templates\n// ============================================================================\n// GitHub PR templates and description generation from commits.\n\nexport {\n  getFeaturePRTemplate,\n  getBugfixPRTemplate,\n  getChorePRTemplate,\n  getDocsPRTemplate,\n  getRefactorPRTemplate,\n  getPRTemplateByWorkType,\n  renderPRTemplate,\n  generatePRDescription,\n  addStackContext,\n  extractCommitType,\n  groupCommitsByType,\n  formatGroupedCommits,\n  type PRTemplateVars,\n} from './pr-templates.js';\n\n// ============================================================================\n// PR Stack Management\n// ============================================================================\n// Manage stacked PR dependencies and visualization.\n\nexport {\n  savePRStack,\n  loadPRStack,\n  addPRToStack,\n  removePRFromStack,\n  visualizeStack,\n  validateStackOrder,\n  getMergeOrder,\n  findDependentPRs,\n  type PRStackNode,\n  type PRStack,\n  type StackValidationError,\n} from './pr-stack.js';\n\n// ============================================================================\n// Subissue Checklist Management\n// ============================================================================\n// Generate and update subissue checklists in parent issue bodies.\n\nexport {\n  generateChecklistMarkdown,\n  extractChecklistSection,\n  parseChecklistItems,\n  updateParentIssueChecklist,\n  addSubissueToChecklist,\n  markSubissueComplete,\n  syncSubissueStates,\n  type SubissueInfo,\n} from './subissue-checklist.js';\n",
        "plugins/github-orchestration/shared/hooks/utils/io.ts": "/**\n * I/O utilities for Claude Code hooks\n *\n * Provides stdin/stdout JSON handling and the runHook wrapper for\n * creating self-executable hooks. Claude Code passes hook input via\n * stdin as JSON and expects hook output as JSON on stdout.\n *\n * @module io\n */\n\nimport type { HookInput, HookOutput } from '../../types/types.js';\nimport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  type DebugConfig,\n} from './debug.js';\n\n/**\n * Read and parse JSON from stdin\n *\n * Reads all data from stdin, concatenates chunks, and parses as JSON.\n * Used by hook runners to receive hook input from Claude Code.\n *\n * @template T - Expected type of the parsed JSON (defaults to unknown)\n * @returns Promise that resolves to the parsed JSON data\n * @throws Error if stdin cannot be read or JSON parsing fails\n *\n * @example\n * ```typescript\n * import { readStdinJson } from './utils/io.js';\n * import type { SubagentStopInput } from '../../types/types.js';\n *\n * const input = await readStdinJson<SubagentStopInput>();\n * console.log(input.agent_id);\n * ```\n */\nexport async function readStdinJson<T = unknown>(): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const chunks: Buffer[] = [];\n\n    process.stdin.on('data', (chunk) => {\n      // Handle both Buffer and string inputs\n      if (Buffer.isBuffer(chunk)) {\n        chunks.push(chunk);\n      } else {\n        chunks.push(Buffer.from(chunk));\n      }\n    });\n    process.stdin.on('end', () => {\n      try {\n        const data = Buffer.concat(chunks).toString('utf8');\n        resolve(JSON.parse(data) as T);\n      } catch (error) {\n        reject(new Error(`Failed to parse JSON input: ${error}`));\n      }\n    });\n    process.stdin.on('error', (error) => {\n      reject(new Error(`Failed to read stdin: ${error}`));\n    });\n  });\n}\n\n/**\n * Write JSON output to stdout\n *\n * Serializes the output object to JSON and writes it to stdout with a trailing newline.\n * Used by hook runners to return hook output to Claude Code.\n *\n * @param output - The output object to serialize and write\n *\n * @example\n * ```typescript\n * import { writeStdoutJson } from './utils/io.js';\n * import type { SubagentStopHookOutput } from '../../types/types.js';\n *\n * const output: SubagentStopHookOutput = { continue: true };\n * writeStdoutJson(output);\n * ```\n */\nexport function writeStdoutJson(output: unknown): void {\n  process.stdout.write(JSON.stringify(output) + '\\n');\n}\n\n/**\n * Hook handler function type\n */\nexport type HookHandler<I extends HookInput = HookInput, O extends HookOutput = HookOutput> = (\n  input: I\n) => O | Promise<O>;\n\n/**\n * Run a hook as a self-executable script\n *\n * This function wraps a hook handler to make it self-executable when called\n * with `npx tsx`. It reads input from stdin, executes the hook, and writes\n * the output to stdout.\n *\n * @template I - Hook input type\n * @template O - Hook output type\n * @param handler - The hook handler function to execute\n *\n * @example\n * ```typescript\n * // my-hook.ts\n * import { runHook } from '../../../shared/hooks/utils/io.js';\n * import type { SessionStartInput, SessionStartHookOutput } from '../../../shared/types/types.js';\n *\n * async function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Hook executed successfully',\n *     },\n *   };\n * }\n *\n * // Make this file self-executable\n * runHook(handler);\n * ```\n */\nexport function runHook<I extends HookInput = HookInput, O extends HookOutput = HookOutput>(\n  handler: HookHandler<I, O>\n): void {\n  main(handler).catch((error) => {\n    console.error('Hook fatal error:', error);\n    process.exit(1);\n  });\n}\n\n/**\n * Main hook execution function\n *\n * Handles the complete hook lifecycle: reads input from stdin, executes the handler,\n * and writes output to stdout. All errors are caught and converted to blocking responses.\n *\n * @param handler - Hook handler function to execute\n * @returns Promise that resolves when hook completes\n *\n * @example\n * ```typescript\n * async function myHandler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Success',\n *     },\n *   };\n * }\n *\n * await main(myHandler);\n * ```\n */\nasync function main<I extends HookInput, O extends HookOutput>(\n  handler: HookHandler<I, O>\n): Promise<void> {\n  let input: I & DebugConfig;\n  let hookEventName = 'unknown';\n  let cwd = process.cwd();\n  let debug = false;\n\n  try {\n    // Read input from stdin\n    input = await readStdinJson<I & DebugConfig>();\n    hookEventName = (input as { hook_event_name?: string }).hook_event_name || 'unknown';\n    cwd = (input as { cwd?: string }).cwd || process.cwd();\n    debug = input.debug === true;\n  } catch (error) {\n    // Can't even read input - exit with error\n    console.error('Failed to read hook input:', error);\n    process.exit(1);\n  }\n\n  const logger = createDebugLogger(cwd, hookEventName, debug);\n\n  try {\n    // Log input if debug enabled\n    await logger.logInput(input);\n\n    // Execute hook handler\n    const output = await handler(input);\n\n    // Log output if debug enabled\n    await logger.logOutput(output);\n\n    // Write output to stdout\n    writeStdoutJson(output);\n\n  } catch (error) {\n    const err = error instanceof Error ? error : new Error(String(error));\n\n    // Log error\n    await logger.logError(err);\n\n    // ALWAYS return blocking error response\n    // Debug flag controls logging only, not blocking behavior\n    const errorResponse = createBlockingErrorResponse(hookEventName, err);\n    writeStdoutJson(errorResponse);\n  }\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/issue-templates.ts": "/**\n * GitHub issue template utility for workflow automation\n * Provides reusable templates for bug reports, feature requests, and epics\n */\n\n/**\n * Template variables for substitution\n */\nexport interface TemplateVars {\n  [key: string]: string;\n}\n\n/**\n * Get bug report issue template\n *\n * @returns Bug report markdown template\n */\nexport function getBugTemplate(): string {\n  return `## Bug Description\n\n{{description}}\n\n## Steps to Reproduce\n\n1. {{step1}}\n2. {{step2}}\n3. {{step3}}\n\n## Expected Behavior\n\n{{expected}}\n\n## Actual Behavior\n\n{{actual}}\n\n## Environment\n\n- OS: {{os}}\n- Browser: {{browser}}\n- Version: {{version}}\n\n## Additional Context\n\n{{context}}`;\n}\n\n/**\n * Get feature request issue template\n *\n * @returns Feature request markdown template\n */\nexport function getFeatureTemplate(): string {\n  return `## Feature Description\n\n{{description}}\n\n## Problem Statement\n\n{{problem}}\n\n## Proposed Solution\n\n{{solution}}\n\n## Alternatives Considered\n\n{{alternatives}}\n\n## Additional Context\n\n{{context}}`;\n}\n\n/**\n * Get epic issue template with optional subissue list\n *\n * @param subissues - Optional array of subissue titles for checklist\n * @returns Epic markdown template\n */\nexport function getEpicTemplate(subissues?: string[]): string {\n  const checklistSection = subissues && subissues.length > 0\n    ? `\n\n## Subtasks\n\n${subissues.map((title) => `- [ ] ${title}`).join('\\n')}`\n    : '';\n\n  return `## Epic Overview\n\n{{description}}\n\n## Goals\n\n- {{goal1}}\n- {{goal2}}\n- {{goal3}}\n\n## Success Criteria\n\n- {{criteria1}}\n- {{criteria2}}\n- {{criteria3}}\n\n## Technical Approach\n\n{{approach}}${checklistSection}\n\n## Additional Context\n\n{{context}}`;\n}\n\n/**\n * Get simple task issue template\n *\n * @returns Task markdown template\n */\nexport function getTaskTemplate(): string {\n  return `## Task Description\n\n{{description}}\n\n## Acceptance Criteria\n\n- [ ] {{criteria1}}\n- [ ] {{criteria2}}\n- [ ] {{criteria3}}\n\n## Additional Context\n\n{{context}}`;\n}\n\n/**\n * Render template by substituting variables\n * Variables are denoted with {{varName}} syntax\n * Missing variables are left as-is (not replaced)\n *\n * @param template - The template string with {{varName}} placeholders\n * @param vars - Key-value pairs for substitution\n * @returns Rendered template with substituted values\n *\n * @example\n * const template = \"Hello {{name}}, you are {{age}} years old\";\n * renderTemplate(template, { name: \"Alice\", age: \"30\" })\n * // \"Hello Alice, you are 30 years old\"\n *\n * @example\n * // Missing variables are preserved\n * renderTemplate(\"Hello {{name}}\", {})\n * // \"Hello {{name}}\"\n */\nexport function renderTemplate(template: string, vars: TemplateVars): string {\n  let result = template;\n\n  for (const [key, value] of Object.entries(vars)) {\n    const placeholder = `{{${key}}}`;\n    result = result.replaceAll(placeholder, value);\n  }\n\n  return result;\n}\n\n/**\n * Get minimal issue body with just description and context\n *\n * @param description - Issue description\n * @param context - Additional context (optional)\n * @returns Minimal issue markdown\n */\nexport function getMinimalIssueBody(description: string, context?: string): string {\n  const contextSection = context ? `\\n\\n## Additional Context\\n\\n${context}` : '';\n  return `${description}${contextSection}`;\n}\n\n/**\n * Create issue body with parent issue reference\n *\n * @param parentIssueNumber - The parent issue number\n * @param description - Issue description\n * @returns Issue body with parent reference\n */\nexport function createSubissueBody(parentIssueNumber: number, description: string): string {\n  return `**Parent Issue:** #${parentIssueNumber}\n\n${description}`;\n}\n\n/**\n * Add branch reference to issue body\n *\n * @param issueBody - Existing issue body\n * @param branchName - Branch name to reference\n * @returns Updated issue body with branch marker\n */\nexport function addBranchReference(issueBody: string, branchName: string): string {\n  const branchSection = `\\n\\n---\\n\\n**Branch:** \\`${branchName}\\``;\n  return `${issueBody}${branchSection}`;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/log-file.ts": "/**\n * Log File Utilities\n *\n * Functions for saving hook output to log files in `.claude/logs/`.\n * Used to preserve full output while returning concise summaries to Claude.\n *\n * @module utils/log-file\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n/**\n * Saves output content to a log file and returns the relative path.\n *\n * Creates timestamped log files in `.claude/logs/` directory.\n * The directory is created if it doesn't exist.\n *\n * @param cwd - Current working directory (project root)\n * @param category - Log category (e.g., 'eslint', 'tsc', 'ci')\n * @param identifier - Unique identifier (e.g., filename, check name)\n * @param content - Content to save to the log file\n * @returns Relative path to the created log file\n *\n * @example\n * ```typescript\n * const logPath = await saveOutputToLog(\n *   '/project',\n *   'eslint',\n *   'Button.tsx',\n *   eslintOutput\n * );\n * // Returns: '.claude/logs/eslint-Button.tsx-2025-01-02T10-30-00-000Z.log'\n * ```\n */\nexport async function saveOutputToLog(\n  cwd: string,\n  category: string,\n  identifier: string,\n  content: string\n): Promise<string> {\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  // Sanitize identifier to be filesystem-safe\n  const safeIdentifier = identifier.replace(/[/\\\\:*?\"<>|]/g, '-');\n  const filename = `${category}-${safeIdentifier}-${timestamp}.log`;\n  const logDir = path.join(cwd, '.claude', 'logs');\n  const logPath = path.join(logDir, filename);\n\n  await fs.mkdir(logDir, { recursive: true });\n  await fs.writeFile(logPath, content, 'utf-8');\n\n  // Return relative path for display\n  return `.claude/logs/${filename}`;\n}\n\n/**\n * Parses error/warning counts from ESLint output.\n *\n * @param output - ESLint stdout/stderr output\n * @returns Object with error and warning counts\n *\n * @example\n * ```typescript\n * const counts = parseEslintCounts(eslintOutput);\n * // Returns: { errors: 3, warnings: 2 }\n * ```\n */\nexport function parseEslintCounts(output: string): { errors: number; warnings: number } {\n  // ESLint summary line format: \"✖ 5 problems (3 errors, 2 warnings)\"\n  const summaryMatch = output.match(/(\\d+)\\s+problems?\\s+\\((\\d+)\\s+errors?,\\s+(\\d+)\\s+warnings?\\)/i);\n  if (summaryMatch) {\n    return {\n      errors: parseInt(summaryMatch[2], 10),\n      warnings: parseInt(summaryMatch[3], 10),\n    };\n  }\n\n  // Alternative: count individual error/warning lines\n  const errorLines = (output.match(/error\\s/gi) || []).length;\n  const warningLines = (output.match(/warning\\s/gi) || []).length;\n\n  return { errors: errorLines, warnings: warningLines };\n}\n\n/**\n * Parses error count from TypeScript compiler output.\n *\n * @param output - TypeScript compiler stdout/stderr output\n * @returns Number of type errors found\n *\n * @example\n * ```typescript\n * const errorCount = parseTscErrorCount(tscOutput);\n * // Returns: 5\n * ```\n */\nexport function parseTscErrorCount(output: string): number {\n  // TypeScript summary: \"Found 5 errors in 3 files.\"\n  const summaryMatch = output.match(/Found\\s+(\\d+)\\s+errors?/i);\n  if (summaryMatch) {\n    return parseInt(summaryMatch[1], 10);\n  }\n\n  // Alternative: count \"error TS\" occurrences\n  const errorMatches = output.match(/error\\s+TS\\d+/gi) || [];\n  return errorMatches.length;\n}\n\n/**\n * Parses test results from Vitest output.\n *\n * @param output - Vitest stdout/stderr output\n * @returns Object with passed, failed, and skipped counts\n *\n * @example\n * ```typescript\n * const results = parseVitestResults(vitestOutput);\n * // Returns: { passed: 10, failed: 2, skipped: 1 }\n * ```\n */\nexport function parseVitestResults(output: string): {\n  passed: number;\n  failed: number;\n  skipped: number;\n} {\n  // Vitest summary: \"Tests  2 failed | 10 passed | 1 skipped (13)\"\n  const passed = parseInt(output.match(/(\\d+)\\s+passed/i)?.[1] || '0', 10);\n  const failed = parseInt(output.match(/(\\d+)\\s+failed/i)?.[1] || '0', 10);\n  const skipped = parseInt(output.match(/(\\d+)\\s+skipped/i)?.[1] || '0', 10);\n\n  return { passed, failed, skipped };\n}\n\n/**\n * Parses CI check status from `gh pr checks` output.\n *\n * @param output - Output from `gh pr checks` command\n * @returns Array of check statuses with name, status, and duration\n *\n * @example\n * ```typescript\n * const checks = parseCiChecks(ghOutput);\n * // Returns: [\n * //   { name: 'lint', status: 'pass', duration: '2m30s' },\n * //   { name: 'test', status: 'fail', duration: '5m10s' }\n * // ]\n * ```\n */\nexport function parseCiChecks(\n  output: string\n): Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }> {\n  const checks: Array<{\n    name: string;\n    status: 'pass' | 'fail' | 'pending' | 'skipped';\n    duration: string;\n  }> = [];\n\n  // gh pr checks output format:\n  // lint    pass    2m30s   https://github.com/...\n  // test    fail    5m10s   https://github.com/...\n  const lines = output.split('\\n').filter((line) => line.trim());\n\n  for (const line of lines) {\n    // Split by whitespace, handling variable spacing\n    const parts = line.split(/\\s+/).filter(Boolean);\n    if (parts.length >= 2) {\n      const name = parts[0];\n      const statusRaw = parts[1].toLowerCase();\n\n      let status: 'pass' | 'fail' | 'pending' | 'skipped';\n      if (statusRaw === 'pass' || statusRaw === 'success' || statusRaw === '✓') {\n        status = 'pass';\n      } else if (statusRaw === 'fail' || statusRaw === 'failure' || statusRaw === '✗') {\n        status = 'fail';\n      } else if (statusRaw === 'skipped' || statusRaw === 'neutral') {\n        status = 'skipped';\n      } else {\n        status = 'pending';\n      }\n\n      const duration = parts[2] || '';\n\n      checks.push({ name, status, duration });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Formats CI checks as a concise emoji status table.\n *\n * @param checks - Array of parsed CI checks\n * @param logPath - Optional path to full log file (shown for failures)\n * @returns Formatted string with emoji status indicators\n *\n * @example\n * ```typescript\n * const table = formatCiChecksTable(checks, '.claude/logs/ci.log');\n * // Returns:\n * // ✅ lint (2m30s)\n * // ❌ test (5m10s) → .claude/logs/ci.log\n * // ⏳ deploy\n * ```\n */\nexport function formatCiChecksTable(\n  checks: Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }>,\n  logPath?: string\n): string {\n  const statusEmoji = {\n    pass: '✅',\n    fail: '❌',\n    pending: '⏳',\n    skipped: '⏭️',\n  };\n\n  const lines = checks.map((check) => {\n    const emoji = statusEmoji[check.status];\n    const duration = check.duration ? ` (${check.duration})` : '';\n    const logLink = check.status === 'fail' && logPath ? ` → ${logPath}` : '';\n    return `${emoji} ${check.name}${duration}${logLink}`;\n  });\n\n  return lines.join('\\n');\n}\n\n/**\n * Formats a concise error summary with log file link.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @param summary - Brief summary of issues (e.g., '3 errors, 2 warnings')\n * @param logPath - Path to the full log file\n * @returns Formatted summary string\n *\n * @example\n * ```typescript\n * const summary = formatErrorSummary('ESLint', '3 errors, 2 warnings', logPath);\n * // Returns: '❌ ESLint: 3 errors, 2 warnings\\n→ .claude/logs/eslint-file.log'\n * ```\n */\nexport function formatErrorSummary(tool: string, summary: string, logPath: string): string {\n  return `❌ ${tool}: ${summary}\\n→ ${logPath}`;\n}\n\n/**\n * Formats a success message.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @returns Formatted success string\n *\n * @example\n * ```typescript\n * const msg = formatSuccessMessage('ESLint');\n * // Returns: '✅ ESLint: No issues'\n * ```\n */\nexport function formatSuccessMessage(tool: string): string {\n  return `✅ ${tool}: No issues`;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/native-subissues.ts": "/**\n * Native GitHub Sub-Issues API utility\n *\n * Provides functions for working with GitHub's native sub-issues feature (GA 2025).\n * This creates proper parent-child relationships in GitHub's UI and Projects.\n *\n * API Endpoints:\n * - POST /repos/{owner}/{repo}/issues/{issue_number}/sub_issues - Add sub-issue\n * - GET /repos/{owner}/{repo}/issues/{issue_number}/sub_issues - List sub-issues\n * - DELETE /repos/{owner}/{repo}/issues/{issue_number}/sub_issues/{sub_issue_id} - Remove\n *\n * Requirements:\n * - GitHub sub-issues feature must be enabled for the repository\n * - Requires at least triage permissions\n * - gh CLI must be authenticated\n *\n * @module native-subissues\n */\n\nimport { exec } from 'node:child_process';\nimport { promisify } from 'node:util';\n\nconst execAsync = promisify(exec);\n\n/**\n * Sub-issue information from GitHub API\n */\nexport interface NativeSubissueInfo {\n  /** Issue ID (internal GitHub ID) */\n  id: number;\n  /** Issue number (display number) */\n  number: number;\n  /** Issue title */\n  title: string;\n  /** Issue state */\n  state: 'open' | 'closed';\n  /** Issue URL */\n  url: string;\n}\n\n/**\n * Result of a native sub-issues API call\n */\nexport interface NativeSubissueResult {\n  /** Whether the operation succeeded */\n  success: boolean;\n  /** Error message if failed */\n  error?: string;\n}\n\n/**\n * Execute a shell command\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if native sub-issues API is available for the current repository\n *\n * Tests by making a GET request to the sub-issues endpoint.\n * Returns true if the API responds (even with empty list), false on error.\n *\n * @param cwd - Current working directory (git repo)\n * @returns Whether native sub-issues are available\n */\nexport async function isNativeSubissuesAvailable(cwd: string): Promise<boolean> {\n  // Get a recent issue number to test with\n  const listResult = await execCommand('gh issue list --limit 1 --json number -q \".[0].number\"', cwd);\n\n  if (!listResult.success || !listResult.stdout) {\n    // No issues in repo, try creating a test call anyway\n    // Use issue 1 as a test - if API is available it will return empty or error gracefully\n    const testResult = await execCommand('gh api repos/{owner}/{repo}/issues/1/sub_issues 2>&1', cwd);\n    // If we get a 404 for the issue, the API is available but issue doesn't exist\n    // If we get a different error about sub-issues not being enabled, it's not available\n    return !testResult.stderr.includes('sub_issues') || testResult.success;\n  }\n\n  const issueNumber = listResult.stdout;\n  const result = await execCommand(`gh api repos/{owner}/{repo}/issues/${issueNumber}/sub_issues`, cwd);\n\n  // API is available if the call succeeds (even with empty array)\n  return result.success;\n}\n\n/**\n * Add an issue as a sub-issue of a parent issue using GitHub's native API\n *\n * This creates a proper parent-child relationship that appears in GitHub's UI.\n *\n * @param cwd - Current working directory (git repo)\n * @param parentIssue - Parent issue number\n * @param subissueNumber - Issue number to add as sub-issue\n * @returns Result with success status\n *\n * @example\n * const result = await addNativeSubissue(cwd, 42, 43);\n * if (result.success) {\n *   console.log('Sub-issue #43 linked to parent #42');\n * }\n */\nexport async function addNativeSubissue(\n  cwd: string,\n  parentIssue: number,\n  subissueNumber: number\n): Promise<NativeSubissueResult> {\n  // GitHub API requires the sub_issue_id (internal ID), not the issue number\n  // First, get the internal ID for the subissue\n  const issueResult = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${subissueNumber} --jq '.id'`,\n    cwd\n  );\n\n  if (!issueResult.success) {\n    return {\n      success: false,\n      error: `Failed to get issue ID: ${issueResult.stderr}`,\n    };\n  }\n\n  const subissueId = issueResult.stdout;\n\n  // Add as sub-issue using the internal ID (must be sent as integer in JSON)\n  const result = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${parentIssue}/sub_issues -X POST --input - <<< '{\"sub_issue_id\": ${subissueId}}'`,\n    cwd\n  );\n\n  if (!result.success) {\n    // Check for common errors\n    if (result.stderr.includes('already exists')) {\n      // Already linked - consider this a success\n      return { success: true };\n    }\n    if (result.stderr.includes('Not Found') || result.stderr.includes('404')) {\n      return {\n        success: false,\n        error: 'Native sub-issues not available for this repository',\n      };\n    }\n    return {\n      success: false,\n      error: result.stderr || 'Failed to add sub-issue',\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * List all sub-issues of a parent issue using GitHub's native API\n *\n * @param cwd - Current working directory (git repo)\n * @param parentIssue - Parent issue number\n * @returns Array of sub-issue information\n *\n * @example\n * const subissues = await listNativeSubissues(cwd, 42);\n * for (const sub of subissues) {\n *   console.log(`#${sub.number}: ${sub.title} (${sub.state})`);\n * }\n */\nexport async function listNativeSubissues(\n  cwd: string,\n  parentIssue: number\n): Promise<NativeSubissueInfo[]> {\n  const result = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${parentIssue}/sub_issues --jq '.[] | {id: .id, number: .number, title: .title, state: .state, url: .html_url}'`,\n    cwd\n  );\n\n  if (!result.success || !result.stdout) {\n    return [];\n  }\n\n  try {\n    // Parse JSONL output (one object per line)\n    const lines = result.stdout.split('\\n').filter(Boolean);\n    return lines.map((line) => {\n      const data = JSON.parse(line);\n      return {\n        id: data.id,\n        number: data.number,\n        title: data.title,\n        state: data.state.toLowerCase() as 'open' | 'closed',\n        url: data.url,\n      };\n    });\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Remove a sub-issue from a parent issue using GitHub's native API\n *\n * This removes the parent-child relationship but does not close the issue.\n *\n * @param cwd - Current working directory (git repo)\n * @param parentIssue - Parent issue number\n * @param subissueNumber - Issue number to remove as sub-issue\n * @returns Result with success status\n */\nexport async function removeNativeSubissue(\n  cwd: string,\n  parentIssue: number,\n  subissueNumber: number\n): Promise<NativeSubissueResult> {\n  // Get the internal ID for the subissue\n  const issueResult = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${subissueNumber} --jq '.id'`,\n    cwd\n  );\n\n  if (!issueResult.success) {\n    return {\n      success: false,\n      error: `Failed to get issue ID: ${issueResult.stderr}`,\n    };\n  }\n\n  const subissueId = issueResult.stdout;\n\n  const result = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${parentIssue}/sub_issues/${subissueId} -X DELETE`,\n    cwd\n  );\n\n  if (!result.success) {\n    if (result.stderr.includes('Not Found') || result.stderr.includes('404')) {\n      // Already removed or never was a sub-issue - consider success\n      return { success: true };\n    }\n    return {\n      success: false,\n      error: result.stderr || 'Failed to remove sub-issue',\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Get the parent issue of a sub-issue using GitHub's native API\n *\n * @param cwd - Current working directory (git repo)\n * @param subissueNumber - Issue number to check\n * @returns Parent issue number, or null if not a sub-issue\n */\nexport async function getParentIssue(\n  cwd: string,\n  subissueNumber: number\n): Promise<number | null> {\n  const result = await execCommand(\n    `gh api repos/{owner}/{repo}/issues/${subissueNumber}/parent --jq '.number'`,\n    cwd\n  );\n\n  if (!result.success || !result.stdout) {\n    return null;\n  }\n\n  const parentNumber = parseInt(result.stdout, 10);\n  return isNaN(parentNumber) ? null : parentNumber;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/package-manager.ts": "/**\n * Package manager detection and command utilities\n *\n * Detects which package manager (npm, yarn, pnpm, or bun) a project uses\n * by checking for the presence of lockfiles, and provides utilities for\n * constructing package manager commands.\n *\n * @module package-manager\n */\n\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Detect which package manager is used in a project\n *\n * Checks for the presence of lockfiles in the following priority order:\n * 1. bun.lockb (Bun)\n * 2. pnpm-lock.yaml (pnpm)\n * 3. yarn.lock (Yarn)\n * 4. package-lock.json (npm)\n * 5. Falls back to bun if no lockfile is found (modern default)\n *\n * @param cwd - The directory to check for lockfiles\n * @returns The detected package manager: 'bun', 'pnpm', 'yarn', or 'npm'\n *\n * @example\n * ```typescript\n * import { detectPackageManager } from './package-manager.js';\n *\n * const pm = detectPackageManager('/path/to/project');\n * console.log(pm); // 'npm' | 'yarn' | 'pnpm' | 'bun'\n * ```\n */\nexport function detectPackageManager(cwd: string): 'npm' | 'yarn' | 'pnpm' | 'bun' {\n  if (existsSync(join(cwd, 'bun.lockb'))) return 'bun';\n  if (existsSync(join(cwd, 'pnpm-lock.yaml'))) return 'pnpm';\n  if (existsSync(join(cwd, 'yarn.lock'))) return 'yarn';\n  if (existsSync(join(cwd, 'package-lock.json'))) return 'npm';\n  return 'bun'; // Modern default when no lockfile found\n}\n\n/**\n * Get the command to run a package.json script\n *\n * Constructs the appropriate command for running a package.json script\n * based on the detected package manager. All package managers use the\n * format: `{pm} run {script}`.\n *\n * @param cwd - The project directory to detect the package manager from\n * @param script - The script name from package.json to run (e.g., 'test', 'build')\n * @returns The full command string to execute the script\n *\n * @example\n * ```typescript\n * import { getScriptCommand } from './package-manager.js';\n *\n * const command = getScriptCommand('/path/to/project', 'test');\n * // Returns: 'npm run test' or 'yarn run test' or 'pnpm run test' or 'bun run test'\n * ```\n */\nexport function getScriptCommand(cwd: string, script: string): string {\n  const pm = detectPackageManager(cwd);\n  return `${pm} run ${script}`;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/pr-stack.ts": "/**\n * Stacked PR management utility for GitHub workflow automation\n * Tracks PR dependencies and provides stack visualization\n */\n\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\n/**\n * A node in the PR stack representing a single PR and its relationships\n */\nexport interface PRStackNode {\n  /** The PR number */\n  pr: number;\n  /** The branch name for this PR */\n  branch: string;\n  /** The base branch this PR targets */\n  base: string;\n  /** Array of PR numbers that depend on this PR */\n  children: number[];\n  /** Optional PR title */\n  title?: string;\n  /** Optional PR state (open/closed/merged) */\n  state?: string;\n}\n\n/**\n * Complete PR stack structure\n */\nexport interface PRStack {\n  /** Array of PR stack nodes */\n  nodes: PRStackNode[];\n  /** Last updated timestamp */\n  updatedAt: string;\n}\n\n/**\n * Validation error for PR stack\n */\nexport interface StackValidationError {\n  type: 'circular' | 'missing-base' | 'invalid-order' | 'duplicate';\n  message: string;\n  affectedPRs?: number[];\n}\n\n/**\n * Save PR stack to state file\n *\n * @param cwd - Current working directory\n * @param stack - The PR stack nodes to save\n */\nexport async function savePRStack(cwd: string, stack: PRStackNode[]): Promise<void> {\n  const stateDir = path.join(cwd, '.claude', 'logs');\n  const stateFile = path.join(stateDir, 'pr-stack.json');\n\n  await fs.mkdir(stateDir, { recursive: true });\n\n  const data: PRStack = {\n    nodes: stack,\n    updatedAt: new Date().toISOString(),\n  };\n\n  await fs.writeFile(stateFile, JSON.stringify(data, null, 2));\n}\n\n/**\n * Load PR stack from state file\n *\n * @param cwd - Current working directory\n * @returns Array of PR stack nodes, or empty array if file doesn't exist\n */\nexport async function loadPRStack(cwd: string): Promise<PRStackNode[]> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'pr-stack.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    const parsed: PRStack = JSON.parse(data);\n    return parsed.nodes || [];\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Add a PR to the stack\n *\n * @param cwd - Current working directory\n * @param node - The PR node to add\n */\nexport async function addPRToStack(cwd: string, node: PRStackNode): Promise<void> {\n  const stack = await loadPRStack(cwd);\n\n  // Check if PR already exists\n  const existingIndex = stack.findIndex((n) => n.pr === node.pr);\n  if (existingIndex >= 0) {\n    // Update existing node\n    stack[existingIndex] = node;\n  } else {\n    // Add new node\n    stack.push(node);\n\n    // Update parent's children array if base is a PR\n    const baseMatch = node.base.match(/^pr-(\\d+)$/) || node.base.match(/^(\\d+)-/);\n    if (baseMatch) {\n      const basePR = parseInt(baseMatch[1], 10);\n      const parentIndex = stack.findIndex((n) => n.pr === basePR);\n      if (parentIndex >= 0 && !stack[parentIndex].children.includes(node.pr)) {\n        stack[parentIndex].children.push(node.pr);\n      }\n    }\n  }\n\n  await savePRStack(cwd, stack);\n}\n\n/**\n * Remove a PR from the stack\n *\n * @param cwd - Current working directory\n * @param prNumber - The PR number to remove\n */\nexport async function removePRFromStack(cwd: string, prNumber: number): Promise<void> {\n  const stack = await loadPRStack(cwd);\n\n  // Remove the PR node\n  const filteredStack = stack.filter((n) => n.pr !== prNumber);\n\n  // Remove from all children arrays\n  for (const node of filteredStack) {\n    node.children = node.children.filter((childPR) => childPR !== prNumber);\n  }\n\n  await savePRStack(cwd, filteredStack);\n}\n\n/**\n * Visualize PR stack as ASCII tree\n *\n * @param stack - Array of PR stack nodes\n * @returns ASCII tree representation\n *\n * @example\n * visualizeStack([...])\n * // main\n * // └── #42 feat/feature-a\n * //     ├── #43 feat/feature-b\n * //     └── #44 feat/feature-c\n */\nexport function visualizeStack(stack: PRStackNode[]): string {\n  if (stack.length === 0) {\n    return 'No stacked PRs found';\n  }\n\n  // Build tree structure\n  const prMap = new Map<number, PRStackNode>();\n  const roots: PRStackNode[] = [];\n\n  for (const node of stack) {\n    prMap.set(node.pr, node);\n  }\n\n  // Find root nodes (those with base branch as main/master or not in stack)\n  for (const node of stack) {\n    const isRoot = node.base === 'main' || node.base === 'master' ||\n      !stack.some((n) => n.branch === node.base);\n    if (isRoot) {\n      roots.push(node);\n    }\n  }\n\n  // Recursive tree building\n  function buildTree(node: PRStackNode, prefix: string, isLast: boolean): string {\n    const connector = isLast ? '└──' : '├──';\n    const title = node.title ? ` ${node.title}` : '';\n    const state = node.state ? ` (${node.state})` : '';\n    let result = `${prefix}${connector} #${node.pr} ${node.branch}${title}${state}\\n`;\n\n    const children = node.children\n      .map((childPR) => prMap.get(childPR))\n      .filter((child): child is PRStackNode => child !== undefined);\n\n    for (let i = 0; i < children.length; i++) {\n      const child = children[i];\n      const isLastChild = i === children.length - 1;\n      const newPrefix = prefix + (isLast ? '    ' : '│   ');\n      result += buildTree(child, newPrefix, isLastChild);\n    }\n\n    return result;\n  }\n\n  let output = '';\n  for (const root of roots) {\n    output += `${root.base}\\n`;\n    const children = root.children\n      .map((childPR) => prMap.get(childPR))\n      .filter((child): child is PRStackNode => child !== undefined);\n\n    for (let i = 0; i < children.length; i++) {\n      const child = children[i];\n      const isLast = i === children.length - 1;\n      output += buildTree(child, '', isLast);\n    }\n  }\n\n  return output.trim();\n}\n\n/**\n * Validate stack order and detect issues\n *\n * @param stack - Array of PR stack nodes\n * @returns Validation result with errors if invalid\n */\nexport function validateStackOrder(stack: PRStackNode[]): {\n  valid: boolean;\n  errors?: StackValidationError[];\n} {\n  const errors: StackValidationError[] = [];\n  const prNumbers = new Set(stack.map((n) => n.pr));\n\n  // Check for duplicate PR numbers\n  if (prNumbers.size !== stack.length) {\n    errors.push({\n      type: 'duplicate',\n      message: 'Stack contains duplicate PR numbers',\n    });\n  }\n\n  // Check for circular dependencies\n  function hasCircularDep(node: PRStackNode, visited: Set<number>): boolean {\n    if (visited.has(node.pr)) {\n      return true;\n    }\n\n    visited.add(node.pr);\n\n    for (const childPR of node.children) {\n      const child = stack.find((n) => n.pr === childPR);\n      if (child && hasCircularDep(child, new Set(visited))) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  for (const node of stack) {\n    if (hasCircularDep(node, new Set())) {\n      errors.push({\n        type: 'circular',\n        message: `Circular dependency detected involving PR #${node.pr}`,\n        affectedPRs: [node.pr],\n      });\n    }\n  }\n\n  // Check for missing base PRs\n  for (const node of stack) {\n    // Check if base looks like a PR reference\n    const baseMatch = node.base.match(/^(\\d+)-/) || node.base.match(/^pr-(\\d+)$/);\n    if (baseMatch) {\n      const basePR = parseInt(baseMatch[1], 10);\n      if (!prNumbers.has(basePR)) {\n        errors.push({\n          type: 'missing-base',\n          message: `PR #${node.pr} references base PR #${basePR} which is not in the stack`,\n          affectedPRs: [node.pr, basePR],\n        });\n      }\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors: errors.length > 0 ? errors : undefined,\n  };\n}\n\n/**\n * Get merge order for stack (leaf nodes first, root nodes last)\n *\n * @param stack - Array of PR stack nodes\n * @returns Ordered array of PR numbers for merging\n */\nexport function getMergeOrder(stack: PRStackNode[]): number[] {\n  const order: number[] = [];\n  const visited = new Set<number>();\n\n  function visit(node: PRStackNode): void {\n    if (visited.has(node.pr)) {\n      return;\n    }\n\n    // Visit children first (depth-first)\n    for (const childPR of node.children) {\n      const child = stack.find((n) => n.pr === childPR);\n      if (child) {\n        visit(child);\n      }\n    }\n\n    visited.add(node.pr);\n    order.push(node.pr);\n  }\n\n  // Start with root nodes\n  const roots = stack.filter((node) =>\n    node.base === 'main' || node.base === 'master' ||\n    !stack.some((n) => n.branch === node.base)\n  );\n\n  for (const root of roots) {\n    visit(root);\n  }\n\n  return order;\n}\n\n/**\n * Find all PRs that depend on a given PR\n *\n * @param stack - Array of PR stack nodes\n * @param prNumber - The PR number to check\n * @returns Array of dependent PR numbers\n */\nexport function findDependentPRs(stack: PRStackNode[], prNumber: number): number[] {\n  const dependents = new Set<number>();\n\n  function findDescendants(pr: number): void {\n    const node = stack.find((n) => n.pr === pr);\n    if (!node) {\n      return;\n    }\n\n    for (const childPR of node.children) {\n      dependents.add(childPR);\n      findDescendants(childPR);\n    }\n  }\n\n  findDescendants(prNumber);\n  return Array.from(dependents);\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/pr-templates.ts": "/**\n * GitHub PR template utility for workflow automation\n * Generates PR descriptions from commits and issues\n */\n\nimport type { WorkType } from './work-type-detector.js';\n\n/**\n * Template variables for PR substitution\n */\nexport interface PRTemplateVars {\n  [key: string]: string;\n}\n\n/**\n * Get feature PR template\n *\n * @returns Feature PR markdown template\n */\nexport function getFeaturePRTemplate(): string {\n  return `## Summary\n\n{{summary}}\n\n## Changes\n\n{{changes}}\n\n## Testing\n\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing completed\n\n## Screenshots\n\n{{screenshots}}\n\n## Related Issues\n\n{{issues}}\n\n## Breaking Changes\n\n{{breaking}}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Get bugfix PR template\n *\n * @returns Bugfix PR markdown template\n */\nexport function getBugfixPRTemplate(): string {\n  return `## Bug Fix\n\n{{summary}}\n\n## Root Cause\n\n{{cause}}\n\n## Solution\n\n{{solution}}\n\n## Testing\n\n- [ ] Bug reproduced before fix\n- [ ] Bug no longer occurs after fix\n- [ ] Regression tests added\n- [ ] Manual testing completed\n\n## Related Issues\n\n{{issues}}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Get chore PR template\n *\n * @returns Chore PR markdown template\n */\nexport function getChorePRTemplate(): string {\n  return `## Chore\n\n{{summary}}\n\n## Changes\n\n{{changes}}\n\n## Impact\n\n{{impact}}\n\n## Related Issues\n\n{{issues}}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Get docs PR template\n *\n * @returns Documentation PR markdown template\n */\nexport function getDocsPRTemplate(): string {\n  return `## Documentation\n\n{{summary}}\n\n## Changes\n\n{{changes}}\n\n## Related Issues\n\n{{issues}}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Get refactor PR template\n *\n * @returns Refactor PR markdown template\n */\nexport function getRefactorPRTemplate(): string {\n  return `## Refactor\n\n{{summary}}\n\n## Motivation\n\n{{motivation}}\n\n## Changes\n\n{{changes}}\n\n## Testing\n\n- [ ] All existing tests pass\n- [ ] No behavior changes\n- [ ] Code coverage maintained\n\n## Related Issues\n\n{{issues}}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Get PR template by work type\n *\n * @param workType - The work type (feature/fix/chore/docs/refactor)\n * @returns Appropriate PR template\n */\nexport function getPRTemplateByWorkType(workType: WorkType): string {\n  const templates: Record<WorkType, string> = {\n    feature: getFeaturePRTemplate(),\n    fix: getBugfixPRTemplate(),\n    chore: getChorePRTemplate(),\n    docs: getDocsPRTemplate(),\n    refactor: getRefactorPRTemplate(),\n  };\n\n  return templates[workType];\n}\n\n/**\n * Render PR template by substituting variables\n *\n * @param template - The template string with {{varName}} placeholders\n * @param vars - Key-value pairs for substitution\n * @returns Rendered template with substituted values\n */\nexport function renderPRTemplate(template: string, vars: PRTemplateVars): string {\n  let result = template;\n\n  for (const [key, value] of Object.entries(vars)) {\n    const placeholder = `{{${key}}}`;\n    result = result.replaceAll(placeholder, value);\n  }\n\n  return result;\n}\n\n/**\n * Generate PR description from commits\n * Extracts commit messages and formats them into a bulleted list\n *\n * @param commits - Array of commit messages\n * @param linkedIssue - Optional linked issue number\n * @returns Generated PR description\n *\n * @example\n * generatePRDescription(['feat: add dark mode', 'fix: button styling'], 42)\n * // Returns formatted description with commits and issue link\n */\nexport function generatePRDescription(commits: string[], linkedIssue?: number): string {\n  const commitSection = commits.length > 0\n    ? `## Changes\n\n${commits.map((msg) => `- ${msg.replace(/^(feat|fix|chore|docs|refactor):\\s*/i, '')}`).join('\\n')}`\n    : '## Changes\\n\\n<!-- Add description of changes -->';\n\n  const issueSection = linkedIssue\n    ? `\\n\\n## Related Issues\\n\\nCloses #${linkedIssue}`\n    : '';\n\n  return `${commitSection}${issueSection}\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)`;\n}\n\n/**\n * Add stacked PR context to description\n *\n * @param description - Existing PR description\n * @param stackInfo - Stack information (base PR, dependent PRs)\n * @returns Updated description with stack context\n */\nexport function addStackContext(\n  description: string,\n  stackInfo: { base?: number; dependents?: number[] }\n): string {\n  let stackSection = '\\n\\n## Stacked PR';\n\n  if (stackInfo.base) {\n    stackSection += `\\n\\n**Base PR:** #${stackInfo.base}`;\n  }\n\n  if (stackInfo.dependents && stackInfo.dependents.length > 0) {\n    stackSection += `\\n\\n**Dependent PRs:**\\n${stackInfo.dependents.map((pr) => `- #${pr}`).join('\\n')}`;\n  }\n\n  return description + stackSection;\n}\n\n/**\n * Extract conventional commit type from commit message\n *\n * @param commitMessage - The commit message\n * @returns Commit type (feat/fix/chore/docs/refactor) or null\n *\n * @example\n * extractCommitType('feat: add dark mode') // 'feat'\n * extractCommitType('fix(auth): resolve token issue') // 'fix'\n * extractCommitType('regular commit message') // null\n */\nexport function extractCommitType(commitMessage: string): string | null {\n  const match = commitMessage.match(/^(feat|fix|chore|docs|refactor|style|test|perf|ci|build|revert)(\\(.+?\\))?:/i);\n  return match ? match[1].toLowerCase() : null;\n}\n\n/**\n * Group commits by conventional commit type\n *\n * @param commits - Array of commit messages\n * @returns Grouped commits by type\n *\n * @example\n * groupCommitsByType(['feat: add X', 'fix: resolve Y', 'feat: add Z'])\n * // { feat: ['add X', 'add Z'], fix: ['resolve Y'] }\n */\nexport function groupCommitsByType(commits: string[]): Record<string, string[]> {\n  const grouped: Record<string, string[]> = {};\n\n  for (const commit of commits) {\n    const type = extractCommitType(commit) || 'other';\n    const message = commit.replace(/^(feat|fix|chore|docs|refactor|style|test|perf|ci|build|revert)(\\(.+?\\))?:\\s*/i, '');\n\n    if (!grouped[type]) {\n      grouped[type] = [];\n    }\n    grouped[type].push(message);\n  }\n\n  return grouped;\n}\n\n/**\n * Format grouped commits for PR description\n *\n * @param grouped - Commits grouped by type\n * @returns Formatted markdown with sections\n */\nexport function formatGroupedCommits(grouped: Record<string, string[]>): string {\n  const sections: string[] = [];\n\n  const order = ['feat', 'fix', 'refactor', 'docs', 'chore', 'other'];\n  const titles: Record<string, string> = {\n    feat: '### Features',\n    fix: '### Bug Fixes',\n    refactor: '### Refactoring',\n    docs: '### Documentation',\n    chore: '### Chores',\n    other: '### Other Changes',\n  };\n\n  for (const type of order) {\n    if (grouped[type] && grouped[type].length > 0) {\n      sections.push(`${titles[type] || `### ${type}`}\\n\\n${grouped[type].map((msg) => `- ${msg}`).join('\\n')}`);\n    }\n  }\n\n  return sections.join('\\n\\n');\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/session-issues.ts": "/**\n * Session issues tracking for cross-session issue discovery\n *\n * Manages tracking of GitHub issues created during Claude sessions to enable:\n * - Cross-session awareness of related issues\n * - Automatic surfacing of issues from previous sessions\n * - Relevance-based issue discovery in SessionStart hook\n *\n * This enables continuity across sessions by tracking which issues were created\n * during each session and surfacing related issues when new sessions start.\n *\n * @module session-issues\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SESSION_ISSUES_FILE = 'session-issues.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Reference to a GitHub issue created during a session\n */\nexport interface IssueReference {\n  /**\n   * Full repository name (e.g., \"owner/repo\")\n   */\n  repo: string;\n  /**\n   * GitHub issue number\n   */\n  number: number;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * Full GitHub issue URL\n   */\n  url: string;\n  /**\n   * ISO timestamp when issue was created\n   */\n  createdAt: string;\n}\n\n/**\n * Session-level tracking of issues created\n */\nexport interface SessionIssuesEntry {\n  /**\n   * Unique session identifier\n   */\n  sessionId: string;\n  /**\n   * Git branch at time of session\n   */\n  branch: string;\n  /**\n   * Repository name (owner/repo)\n   */\n  repo: string;\n  /**\n   * Issues created during this session\n   */\n  issuesCreated: IssueReference[];\n  /**\n   * ISO timestamp when session started\n   */\n  startedAt: string;\n  /**\n   * ISO timestamp of last update\n   */\n  lastUpdated: string;\n}\n\n/**\n * Map of session IDs to their issue tracking data\n */\nexport interface SessionIssuesState {\n  [sessionId: string]: SessionIssuesEntry;\n}\n\n/**\n * Related issue with relevance scoring\n */\nexport interface RelatedIssue extends IssueReference {\n  /**\n   * Relevance level based on discovery strategy\n   */\n  relevance: 'high' | 'medium';\n  /**\n   * Human-readable reason for the relevance\n   */\n  reason: string;\n  /**\n   * Human-readable age of the session that created this issue\n   */\n  sessionAge: string;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to session-issues.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the session issues state file\n * @example\n * ```typescript\n * const path = getSessionIssuesFilePath('/path/to/project');\n * // Returns: '/path/to/project/.claude/logs/session-issues.json'\n * ```\n */\nfunction getSessionIssuesFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SESSION_ISSUES_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Load session issues state from disk\n *\n * Loads all tracked sessions and their created issues. If the file doesn't exist\n * or is invalid, returns an empty state.\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns The complete session issues state\n * @example\n * ```typescript\n * import { loadSessionIssuesState } from './session-issues.js';\n *\n * const state = await loadSessionIssuesState('/path/to/project');\n * for (const [sessionId, session] of Object.entries(state)) {\n *   console.log(`Session ${sessionId} created ${session.issuesCreated.length} issues`);\n * }\n * ```\n */\nexport async function loadSessionIssuesState(\n  cwd: string,\n  statePath?: string\n): Promise<SessionIssuesState> {\n  const filePath = getSessionIssuesFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    // File doesn't exist or parse error - return empty state\n    return {};\n  }\n}\n\n/**\n * Save session issues state to disk\n *\n * Persists the complete state to disk. Automatically creates the logs directory\n * if it doesn't exist.\n * @param cwd - The working directory where logs are stored\n * @param state - The complete session issues state to save\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns Promise that resolves when state is saved\n * @example\n * ```typescript\n * import { loadSessionIssuesState, saveSessionIssuesState } from './session-issues.js';\n *\n * const state = await loadSessionIssuesState(cwd);\n * state['new-session-id'] = {\n *   sessionId: 'new-session-id',\n *   branch: 'feature/test',\n *   repo: 'owner/repo',\n *   issuesCreated: [],\n *   startedAt: new Date().toISOString(),\n *   lastUpdated: new Date().toISOString()\n * };\n * await saveSessionIssuesState(cwd, state);\n * ```\n */\nasync function saveSessionIssuesState(\n  cwd: string,\n  state: SessionIssuesState,\n  statePath?: string\n): Promise<void> {\n  const filePath = getSessionIssuesFilePath(cwd, statePath);\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(state, null, 2), 'utf-8');\n}\n\n/**\n * Add an issue to a session's tracking data\n *\n * Records that an issue was created during a session. If the session doesn't exist,\n * it will be created. Automatically enforces a 100-session limit and removes oldest\n * sessions when the limit is exceeded.\n * @param sessionId - The session ID\n * @param issue - The issue reference to add\n * @param branch - Current git branch\n * @param repo - Repository name (owner/repo)\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns Promise that resolves when the issue is added\n * @example\n * ```typescript\n * import { addIssueToSession } from './session-issues.js';\n *\n * await addIssueToSession(\n *   'session-abc-123',\n *   {\n *     repo: 'owner/repo',\n *     number: 42,\n *     title: 'Fix authentication bug',\n *     url: 'https://github.com/owner/repo/issues/42',\n *     createdAt: new Date().toISOString()\n *   },\n *   '123-feature/auth',\n *   'owner/repo',\n *   '/path/to/project'\n * );\n * ```\n */\nexport async function addIssueToSession(\n  sessionId: string,\n  issue: IssueReference,\n  branch: string,\n  repo: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  let state = await loadSessionIssuesState(cwd, statePath);\n\n  // Get or create session entry\n  if (!state[sessionId]) {\n    state[sessionId] = {\n      sessionId,\n      branch,\n      repo,\n      issuesCreated: [],\n      startedAt: new Date().toISOString(),\n      lastUpdated: new Date().toISOString(),\n    };\n  }\n\n  // Add issue to session\n  state[sessionId].issuesCreated.push(issue);\n  state[sessionId].lastUpdated = new Date().toISOString();\n\n  // Limit to last 100 sessions\n  const sessionIds = Object.keys(state);\n  if (sessionIds.length > 100) {\n    // Sort by startedAt, keep newest 100\n    const sorted = sessionIds\n      .map((id) => ({ id, startedAt: state[id].startedAt }))\n      .sort((a, b) => new Date(b.startedAt).getTime() - new Date(a.startedAt).getTime())\n      .slice(0, 100);\n\n    const newState: SessionIssuesState = {};\n    for (const { id } of sorted) {\n      newState[id] = state[id];\n    }\n    state = newState;\n  }\n\n  await saveSessionIssuesState(cwd, state, statePath);\n}\n\n/**\n * Get all issues created during a specific session\n *\n * Retrieves the list of issues created during a session. Returns an empty array\n * if the session doesn't exist or has no issues.\n * @param sessionId - The session ID to query\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns Array of issue references\n * @example\n * ```typescript\n * import { getSessionIssues } from './session-issues.js';\n *\n * const issues = await getSessionIssues('session-abc-123', '/path/to/project');\n * console.log(`Session created ${issues.length} issues`);\n * for (const issue of issues) {\n *   console.log(`#${issue.number}: ${issue.title}`);\n * }\n * ```\n */\nexport async function getSessionIssues(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<IssueReference[]> {\n  const state = await loadSessionIssuesState(cwd, statePath);\n  return state[sessionId]?.issuesCreated || [];\n}\n\n/**\n * Clean up old sessions from state file\n *\n * Removes sessions older than the specified retention period. This helps keep\n * the state file size manageable.\n * @param cwd - The working directory where logs are stored\n * @param retentionDays - Number of days to retain sessions (default: 30)\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns Promise that resolves when cleanup is complete\n * @example\n * ```typescript\n * import { cleanupOldSessions } from './session-issues.js';\n *\n * // Remove sessions older than 30 days\n * await cleanupOldSessions('/path/to/project', 30);\n * ```\n */\nexport async function cleanupOldSessions(\n  cwd: string,\n  retentionDays: number = 30,\n  statePath?: string\n): Promise<void> {\n  const state = await loadSessionIssuesState(cwd, statePath);\n  const cutoffTime = Date.now() - retentionDays * 24 * 60 * 60 * 1000;\n\n  let modified = false;\n  const newState: SessionIssuesState = {};\n\n  for (const [sessionId, session] of Object.entries(state)) {\n    const sessionTime = new Date(session.startedAt).getTime();\n    if (sessionTime >= cutoffTime) {\n      newState[sessionId] = session;\n    } else {\n      modified = true;\n    }\n  }\n\n  if (modified) {\n    await saveSessionIssuesState(cwd, newState, statePath);\n  }\n}\n\n// ============================================================================\n// Issue Discovery\n// ============================================================================\n\n/**\n * Format a timestamp as a human-readable age\n * @param timestamp - ISO timestamp\n * @returns Human-readable age string\n * @example\n * ```typescript\n * formatAge('2024-01-09T10:00:00Z');  // \"2h ago\"\n * formatAge('2024-01-08T10:00:00Z');  // \"Yesterday\"\n * formatAge('2024-01-02T10:00:00Z');  // \"7 days ago\"\n * ```\n */\nfunction formatAge(timestamp: string): string {\n  const diff = Date.now() - new Date(timestamp).getTime();\n  const hours = Math.floor(diff / (60 * 60 * 1000));\n\n  if (hours < 1) return 'Just now';\n  if (hours < 24) return `${hours}h ago`;\n\n  const days = Math.floor(hours / 24);\n  if (days === 1) return 'Yesterday';\n  if (days < 7) return `${days} days ago`;\n\n  return new Date(timestamp).toLocaleDateString();\n}\n\n/**\n * Find related issues from previous sessions\n *\n * Discovers issues from previous sessions that are relevant to the current session\n * using multiple strategies:\n *\n * 1. **High Priority (Same Branch Family)**: Issues from branches with the same\n *    numeric prefix (e.g., `123-feature/auth` and `123-fix/bug` are related)\n *\n * 2. **Medium Priority (Same Repository)**: Issues from the same repository\n *    within the last 7 days\n *\n * Results are deduplicated by issue number and sorted by relevance then recency.\n * @param currentBranch - Current git branch name\n * @param currentRepo - Current repository name (owner/repo)\n * @param currentSessionId - Current session ID (to exclude from results)\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-issues.json (for testing)\n * @returns Array of related issues with relevance scoring\n * @example\n * ```typescript\n * import { findRelatedIssues } from './session-issues.js';\n *\n * const relatedIssues = await findRelatedIssues(\n *   '123-fix/auth-bug',\n *   'owner/repo',\n *   'current-session-id',\n *   '/path/to/project'\n * );\n *\n * for (const issue of relatedIssues) {\n *   console.log(`[${issue.relevance}] #${issue.number}: ${issue.title}`);\n *   console.log(`  ${issue.reason} • ${issue.sessionAge}`);\n * }\n * ```\n */\nexport async function findRelatedIssues(\n  currentBranch: string,\n  currentRepo: string,\n  currentSessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<RelatedIssue[]> {\n  const state = await loadSessionIssuesState(cwd, statePath);\n  const relatedIssues: RelatedIssue[] = [];\n  const seenIssues = new Set<number>();\n\n  // STRATEGY 1: Same branch family (high relevance)\n  // Extract prefix: \"123-feature/auth\" → \"123\"\n  const branchPrefixMatch = currentBranch.match(/^(\\d+)-/);\n  const branchPrefix = branchPrefixMatch ? branchPrefixMatch[1] : null;\n\n  if (branchPrefix) {\n    for (const [sid, session] of Object.entries(state)) {\n      if (sid === currentSessionId) continue;\n\n      const sessionPrefix = session.branch.match(/^(\\d+)-/)?.[1];\n      if (sessionPrefix === branchPrefix) {\n        for (const issue of session.issuesCreated) {\n          if (seenIssues.has(issue.number)) continue;\n          seenIssues.add(issue.number);\n\n          relatedIssues.push({\n            ...issue,\n            relevance: 'high',\n            reason: `Same branch family: ${session.branch}`,\n            sessionAge: formatAge(session.startedAt),\n          });\n        }\n      }\n    }\n  }\n\n  // STRATEGY 2: Same repository (medium relevance)\n  // Only last 7 days\n  const weekAgo = Date.now() - 7 * 24 * 60 * 60 * 1000;\n\n  for (const [sid, session] of Object.entries(state)) {\n    if (sid === currentSessionId) continue;\n    if (session.repo !== currentRepo) continue;\n    if (new Date(session.startedAt).getTime() < weekAgo) continue;\n\n    for (const issue of session.issuesCreated) {\n      if (seenIssues.has(issue.number)) continue;\n      seenIssues.add(issue.number);\n\n      relatedIssues.push({\n        ...issue,\n        relevance: 'medium',\n        reason: `Same repository: ${currentRepo}`,\n        sessionAge: formatAge(session.startedAt),\n      });\n    }\n  }\n\n  // Sort by relevance then recency\n  return relatedIssues.sort((a, b) => {\n    if (a.relevance !== b.relevance) {\n      return a.relevance === 'high' ? -1 : 1;\n    }\n    return new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime();\n  });\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/session-state.ts": "/**\n * Session state management for Stop hook tracking\n *\n * Manages session-level state for the Stop hook to track:\n * - How many times the hook has blocked the session\n * - Whether a GitHub comment has been posted for the session\n * - When the last block occurred\n *\n * This enables progressive blocking behavior where the Stop hook can:\n * 1. Block on first commit without PR (with instructions)\n * 2. Block again if no PR or comment posted\n * 3. Show warning after 3 blocks\n * 4. Reset when PR created or comment posted\n * @module session-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SESSION_STOPS_FILE = 'session-stops.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Session Stop state tracking for progressive blocking\n *\n * Tracks how many times a session has been blocked at Stop hook,\n * whether progress has been documented, and related metadata.\n */\nexport interface SessionStopState {\n  /**\n   * The unique session identifier\n   */\n  sessionId: string;\n  /**\n   * Number of times Stop hook has blocked (0-3)\n   * @deprecated Use lastSeenCommitSha for tracking instead\n   */\n  blockCount: number;\n  /**\n   * Whether a GitHub comment has been posted\n   */\n  commentPosted: boolean;\n  /**\n   * ISO timestamp of last block\n   */\n  lastBlockTimestamp: string;\n  /**\n   * GitHub issue number linked to this session\n   */\n  issueNumber?: number;\n  /**\n   * Whether a PR has been created\n   */\n  prCreated?: boolean;\n  /**\n   * Last seen HEAD commit SHA - used to detect new commits\n   * When current HEAD matches this, we've already seen these commits\n   */\n  lastSeenCommitSha?: string;\n  /**\n   * Commit SHA when comment was posted - used to detect new commits after comment\n   * If current HEAD differs from this, new commits need documentation\n   */\n  commentPostedAtSha?: string;\n}\n\n/**\n * Map of session IDs to their Stop hook state\n */\ninterface SessionStopsMap {\n  [sessionId: string]: SessionStopState;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to session-stops.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the session stops state file\n * @example\n * ```typescript\n * const path = getSessionStopsFilePath('/path/to/project');\n * // Returns: '/path/to/project/.claude/logs/session-stops.json'\n * ```\n */\nfunction getSessionStopsFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SESSION_STOPS_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Get session stop state for a given session\n *\n * Loads the session's Stop hook state from disk. If no state exists,\n * returns a default state with blockCount: 0.\n * @param sessionId - The session ID to load state for\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The session state, or default state if not found\n * @example\n * ```typescript\n * import { getSessionStopState } from './session-state.js';\n *\n * // In Stop hook\n * const state = await getSessionStopState(input.session_id, input.cwd);\n * console.log('Block count:', state.blockCount);\n * console.log('Comment posted:', state.commentPosted);\n * ```\n */\nexport async function getSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n\n    if (allStates[sessionId]) {\n      return allStates[sessionId];\n    }\n  } catch {\n    // File doesn't exist or parse error - return default\n  }\n\n  // Return default state\n  return {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Update session stop state with partial updates\n *\n * Merges the provided updates into the existing state and saves to disk.\n * Automatically creates the logs directory if it doesn't exist.\n * @param sessionId - The session ID to update\n * @param updates - Partial state updates to apply\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The updated session state\n * @example\n * ```typescript\n * import { updateSessionStopState } from './session-state.js';\n *\n * // Increment block count\n * await updateSessionStopState(input.session_id, {\n *   blockCount: state.blockCount + 1,\n *   lastBlockTimestamp: new Date().toISOString()\n * }, input.cwd);\n *\n * // Mark comment posted\n * await updateSessionStopState(input.session_id, {\n *   commentPosted: true\n * }, input.cwd);\n * ```\n */\nexport async function updateSessionStopState(\n  sessionId: string,\n  updates: Partial<Omit<SessionStopState, 'sessionId'>>,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  // Load existing states\n  let allStates: SessionStopsMap = {};\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    allStates = JSON.parse(content);\n  } catch {\n    // File doesn't exist yet - start fresh\n  }\n\n  // Get current state or create default\n  const currentState = allStates[sessionId] || {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n\n  // Merge updates\n  const updatedState: SessionStopState = {\n    ...currentState,\n    ...updates,\n    sessionId, // Ensure sessionId is never overwritten\n  };\n\n  allStates[sessionId] = updatedState;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n\n  return updatedState;\n}\n\n/**\n * Reset session stop state to defaults\n *\n * Clears the block count and resets all flags. This is called when:\n * - A PR is created for the session's branch\n * - A GitHub comment is posted documenting progress\n * @param sessionId - The session ID to reset\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is reset\n * @example\n * ```typescript\n * import { resetSessionStopState } from './session-state.js';\n *\n * // After PR created\n * if (prExists) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n *\n * // After comment posted\n * if (commentPosted) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n * ```\n */\nexport async function resetSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  await updateSessionStopState(\n    sessionId,\n    {\n      blockCount: 0,\n      commentPosted: false,\n      lastBlockTimestamp: new Date().toISOString(),\n    },\n    cwd,\n    statePath\n  );\n}\n\n/**\n * Remove session stop state entirely\n *\n * Deletes the session's state from the file. Use this when a session\n * is completely finished and you want to clean up.\n * @param sessionId - The session ID to remove\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is removed (fails silently)\n * @example\n * ```typescript\n * import { removeSessionStopState } from './session-state.js';\n *\n * // Cleanup after session completes successfully\n * await removeSessionStopState(input.session_id, input.cwd);\n * ```\n */\nexport async function removeSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n    delete allStates[sessionId];\n    await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/stacked-branches.ts": "/**\n * Stacked branches state management for subagent isolation workflow\n *\n * Manages branch isolation state for the stacked PR workflow where each subagent\n * works on an isolated branch that gets automatically pushed, PR'd, and merged.\n *\n * State file: .claude/logs/stacked-branches.json\n *\n * @module stacked-branches\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\nimport { execCommand, checkPRExists } from './ci-status.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst STACKED_BRANCHES_FILE = 'stacked-branches.json';\nconst SESSION_CONFIG_FILE = 'session-config.json';\n\n/** Agent types that should not create branches (read-only agents) */\nconst SKIP_AGENT_TYPES = ['Explore', 'Plan'];\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Entry tracking a stacked branch for a subagent\n */\nexport interface StackedBranchEntry {\n  /** Subagent ID that created this branch */\n  agentId: string;\n  /** Session ID of parent session */\n  parentSessionId: string;\n  /** Branch name created for subagent */\n  branchName: string;\n  /** Base branch (parent session's current branch) */\n  baseBranch: string;\n  /** Timestamp of branch creation */\n  createdAt: string;\n  /** PR number after creation (null until PR exists) */\n  prNumber: number | null;\n  /** PR URL */\n  prUrl: string | null;\n  /** Branch status */\n  status: 'active' | 'pr-created' | 'ci-pending' | 'merged' | 'failed';\n  /** Files modified by subagent */\n  modifiedFiles: string[];\n  /** Commit SHA on subagent branch */\n  commitSha: string | null;\n  /** Error message if status is 'failed' */\n  error?: string;\n}\n\n/**\n * Complete stacked branches state\n */\nexport interface StackedBranchesState {\n  /** Map of agent IDs to their branch entries */\n  entries: { [agentId: string]: StackedBranchEntry };\n  /** Last updated timestamp */\n  updatedAt: string;\n}\n\n/**\n * Session configuration for stacked PR mode\n */\nexport interface SessionConfig {\n  /** Whether stacked PR mode is enabled */\n  stackedPrMode?: boolean;\n  /** Stacked PR configuration options */\n  stackedPrConfig?: {\n    /** Wait for CI before resuming (default: true) */\n    waitForCI?: boolean;\n    /** Wait for auto-merge before resuming (default: true) */\n    waitForMerge?: boolean;\n    /** Agent types to skip (default: ['Explore', 'Plan']) */\n    skipAgentTypes?: string[];\n  };\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to stacked-branches.json\n */\nfunction getStackedBranchesPath(cwd: string): string {\n  return path.join(cwd, LOGS_DIR, STACKED_BRANCHES_FILE);\n}\n\n/**\n * Get the path to session-config.json\n */\nfunction getSessionConfigPath(cwd: string): string {\n  return path.join(cwd, LOGS_DIR, SESSION_CONFIG_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Load stacked branches state from disk\n *\n * @param cwd - Working directory\n * @returns Current stacked branches state\n */\nexport async function loadStackedBranchesState(cwd: string): Promise<StackedBranchesState> {\n  const filePath = getStackedBranchesPath(cwd);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    return {\n      entries: {},\n      updatedAt: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Save stacked branches state to disk\n *\n * @param cwd - Working directory\n * @param state - State to save\n */\nexport async function saveStackedBranchesState(\n  cwd: string,\n  state: StackedBranchesState\n): Promise<void> {\n  const filePath = getStackedBranchesPath(cwd);\n  const stateDir = path.dirname(filePath);\n\n  await fs.mkdir(stateDir, { recursive: true });\n\n  state.updatedAt = new Date().toISOString();\n  await fs.writeFile(filePath, JSON.stringify(state, null, 2), 'utf-8');\n}\n\n/**\n * Create a new stacked branch entry\n *\n * @param cwd - Working directory\n * @param entry - Entry to create\n */\nexport async function createStackedBranchEntry(\n  cwd: string,\n  entry: StackedBranchEntry\n): Promise<void> {\n  const state = await loadStackedBranchesState(cwd);\n  state.entries[entry.agentId] = entry;\n  await saveStackedBranchesState(cwd, state);\n}\n\n/**\n * Update an existing stacked branch entry\n *\n * @param cwd - Working directory\n * @param agentId - Agent ID to update\n * @param updates - Partial updates to apply\n */\nexport async function updateStackedBranchEntry(\n  cwd: string,\n  agentId: string,\n  updates: Partial<Omit<StackedBranchEntry, 'agentId'>>\n): Promise<void> {\n  const state = await loadStackedBranchesState(cwd);\n\n  if (state.entries[agentId]) {\n    state.entries[agentId] = {\n      ...state.entries[agentId],\n      ...updates,\n    };\n    await saveStackedBranchesState(cwd, state);\n  }\n}\n\n/**\n * Get a stacked branch entry by agent ID\n *\n * @param cwd - Working directory\n * @param agentId - Agent ID to look up\n * @returns Entry if found, null otherwise\n */\nexport async function getStackedBranchEntry(\n  cwd: string,\n  agentId: string\n): Promise<StackedBranchEntry | null> {\n  const state = await loadStackedBranchesState(cwd);\n  return state.entries[agentId] || null;\n}\n\n/**\n * Remove a stacked branch entry\n *\n * @param cwd - Working directory\n * @param agentId - Agent ID to remove\n */\nexport async function removeStackedBranchEntry(\n  cwd: string,\n  agentId: string\n): Promise<void> {\n  const state = await loadStackedBranchesState(cwd);\n  delete state.entries[agentId];\n  await saveStackedBranchesState(cwd, state);\n}\n\n/**\n * Get all active stacked branch entries\n *\n * @param cwd - Working directory\n * @returns Array of active entries\n */\nexport async function getActiveStackedBranches(\n  cwd: string\n): Promise<StackedBranchEntry[]> {\n  const state = await loadStackedBranchesState(cwd);\n  return Object.values(state.entries).filter((e) => e.status === 'active');\n}\n\n// ============================================================================\n// Session Configuration\n// ============================================================================\n\n/**\n * Load session configuration\n *\n * @param cwd - Working directory\n * @returns Session config or null if not found\n */\nexport async function loadSessionConfig(cwd: string): Promise<SessionConfig | null> {\n  const filePath = getSessionConfigPath(cwd);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Save session configuration\n *\n * @param cwd - Working directory\n * @param config - Config to save\n */\nexport async function saveSessionConfig(\n  cwd: string,\n  config: SessionConfig\n): Promise<void> {\n  const filePath = getSessionConfigPath(cwd);\n  const stateDir = path.dirname(filePath);\n\n  await fs.mkdir(stateDir, { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(config, null, 2), 'utf-8');\n}\n\n// ============================================================================\n// Stacked PR Mode Detection\n// ============================================================================\n\n/**\n * Check if stacked PR mode is enabled for a subagent\n *\n * Detection order (Phase 1 + Phase 2):\n * 1. Environment variable: CLAUDE_STACKED_PR=true\n * 2. Session config: .claude/logs/session-config.json\n * 3. Auto-detect: current branch has an open PR (Phase 2)\n *\n * @param input - SubagentStart input\n * @returns Whether stacked PR mode is enabled\n */\nexport async function isStackedPRModeEnabled(input: {\n  agent_type: string;\n  cwd: string;\n}): Promise<boolean> {\n  // Check if agent type should be skipped\n  const skipTypes = SKIP_AGENT_TYPES;\n  if (skipTypes.includes(input.agent_type)) {\n    return false;\n  }\n\n  // Phase 1: Check environment variable\n  if (process.env.CLAUDE_STACKED_PR === 'true') {\n    return true;\n  }\n\n  // Phase 1: Check session config\n  const config = await loadSessionConfig(input.cwd);\n  if (config?.stackedPrMode) {\n    return true;\n  }\n\n  // Phase 2: Auto-detect - check if current branch has an open PR\n  const currentBranch = await getCurrentBranch(input.cwd);\n  if (currentBranch) {\n    const prCheck = await checkPRExists(currentBranch, input.cwd);\n    if (prCheck.exists) {\n      return true; // Current branch has open PR → auto-enable stacked mode\n    }\n  }\n\n  return false;\n}\n\n/**\n * Get agent types that should be skipped for stacked PR mode\n *\n * @param cwd - Working directory\n * @returns Array of agent type names to skip\n */\nexport async function getSkipAgentTypes(cwd: string): Promise<string[]> {\n  const config = await loadSessionConfig(cwd);\n  return config?.stackedPrConfig?.skipAgentTypes || SKIP_AGENT_TYPES;\n}\n\n// ============================================================================\n// Git Operations\n// ============================================================================\n\n/**\n * Get the current git branch name\n *\n * @param cwd - Working directory\n * @returns Branch name or null if not in a git repo\n */\nexport async function getCurrentBranch(cwd: string): Promise<string | null> {\n  const result = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  return result.success ? result.stdout : null;\n}\n\n/**\n * Generate a branch name for a subagent\n *\n * Format: {baseBranch}-subagent-{shortAgentId}\n *\n * @param baseBranch - Base branch name\n * @param agentId - Agent ID\n * @returns Generated branch name\n */\nexport function generateSubagentBranchName(baseBranch: string, agentId: string): string {\n  // Use first 8 chars of agent ID for brevity\n  const shortId = agentId.slice(0, 8);\n  return `${baseBranch}-subagent-${shortId}`;\n}\n\n/**\n * Create and checkout a new branch\n *\n * @param cwd - Working directory\n * @param branchName - Branch name to create\n * @param baseBranch - Base branch to create from\n * @returns Success result with error message if failed\n */\nexport async function createAndCheckoutBranch(\n  cwd: string,\n  branchName: string,\n  baseBranch: string\n): Promise<{ success: boolean; error?: string }> {\n  // Create branch from base\n  const createResult = await execCommand(\n    `git checkout -b \"${branchName}\" \"${baseBranch}\"`,\n    cwd\n  );\n\n  if (!createResult.success) {\n    return {\n      success: false,\n      error: `Failed to create branch: ${createResult.stderr}`,\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Checkout an existing branch\n *\n * @param cwd - Working directory\n * @param branchName - Branch to checkout\n * @returns Success result\n */\nexport async function checkoutBranch(\n  cwd: string,\n  branchName: string\n): Promise<{ success: boolean; error?: string }> {\n  const result = await execCommand(`git checkout \"${branchName}\"`, cwd);\n\n  if (!result.success) {\n    return {\n      success: false,\n      error: `Failed to checkout branch: ${result.stderr}`,\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Push branch to remote\n *\n * @param cwd - Working directory\n * @param branchName - Branch to push\n * @returns Success result with error message if failed\n */\nexport async function pushBranch(\n  cwd: string,\n  branchName: string\n): Promise<{ success: boolean; error?: string }> {\n  const result = await execCommand(\n    `git push -u origin \"${branchName}\"`,\n    cwd,\n    60000 // 60s timeout for push\n  );\n\n  if (!result.success) {\n    return {\n      success: false,\n      error: `Failed to push branch: ${result.stderr}`,\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Delete a local branch\n *\n * @param cwd - Working directory\n * @param branchName - Branch to delete\n * @returns Success result\n */\nexport async function deleteLocalBranch(\n  cwd: string,\n  branchName: string\n): Promise<{ success: boolean; error?: string }> {\n  const result = await execCommand(`git branch -D \"${branchName}\"`, cwd);\n\n  if (!result.success) {\n    return {\n      success: false,\n      error: `Failed to delete branch: ${result.stderr}`,\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Pull latest changes from remote\n *\n * @param cwd - Working directory\n * @param branchName - Branch to pull\n * @returns Success result\n */\nexport async function pullLatest(\n  cwd: string,\n  branchName: string\n): Promise<{ success: boolean; error?: string }> {\n  const result = await execCommand(`git pull origin \"${branchName}\"`, cwd, 60000);\n\n  if (!result.success) {\n    return {\n      success: false,\n      error: `Failed to pull: ${result.stderr}`,\n    };\n  }\n\n  return { success: true };\n}\n\n/**\n * Stage and commit files\n *\n * @param cwd - Working directory\n * @param files - Files to stage\n * @param message - Commit message\n * @returns Commit SHA or error\n */\nexport async function stageAndCommit(\n  cwd: string,\n  files: string[],\n  message: string\n): Promise<{ success: boolean; commitSha?: string; error?: string }> {\n  // Stage files\n  for (const file of files) {\n    const addResult = await execCommand(`git add \"${file}\"`, cwd);\n    if (!addResult.success) {\n      // Try git rm for deleted files\n      await execCommand(`git rm \"${file}\"`, cwd);\n    }\n  }\n\n  // Check if anything staged\n  const statusResult = await execCommand('git diff --cached --name-only', cwd);\n  if (!statusResult.stdout) {\n    return { success: false, error: 'No changes staged for commit' };\n  }\n\n  // Commit with properly escaped message\n  const escapedMessage = message.replace(/'/g, \"'\\\\''\");\n  const commitResult = await execCommand(`git commit -m '${escapedMessage}'`, cwd);\n\n  if (!commitResult.success) {\n    return {\n      success: false,\n      error: `Failed to commit: ${commitResult.stderr}`,\n    };\n  }\n\n  // Get commit SHA\n  const shaResult = await execCommand('git rev-parse --short HEAD', cwd);\n  const commitSha = shaResult.success ? shaResult.stdout : undefined;\n\n  return { success: true, commitSha };\n}\n\n// ============================================================================\n// PR Operations\n// ============================================================================\n\n/**\n * Create a PR with auto-merge enabled\n *\n * @param cwd - Working directory\n * @param options - PR options\n * @returns PR number and URL\n */\nexport async function createPRWithAutoMerge(\n  cwd: string,\n  options: {\n    head: string;\n    base: string;\n    title: string;\n    body: string;\n  }\n): Promise<{ success: boolean; prNumber?: number; prUrl?: string; error?: string }> {\n  // Create PR\n  const escapedTitle = options.title.replace(/\"/g, '\\\\\"');\n  const escapedBody = options.body.replace(/\"/g, '\\\\\"').replace(/\\n/g, '\\\\n');\n\n  const createResult = await execCommand(\n    `gh pr create --head \"${options.head}\" --base \"${options.base}\" --title \"${escapedTitle}\" --body \"${escapedBody}\" --json number,url`,\n    cwd,\n    60000\n  );\n\n  if (!createResult.success) {\n    return {\n      success: false,\n      error: `Failed to create PR: ${createResult.stderr}`,\n    };\n  }\n\n  let prNumber: number;\n  let prUrl: string;\n\n  try {\n    const prData = JSON.parse(createResult.stdout);\n    prNumber = prData.number;\n    prUrl = prData.url;\n  } catch {\n    return {\n      success: false,\n      error: 'Failed to parse PR creation response',\n    };\n  }\n\n  // Enable auto-merge\n  const mergeResult = await execCommand(\n    `gh pr merge ${prNumber} --auto --squash`,\n    cwd,\n    30000\n  );\n\n  if (!mergeResult.success) {\n    // Auto-merge might fail if not enabled for repo - that's OK, log warning\n    console.error(`Warning: Could not enable auto-merge: ${mergeResult.stderr}`);\n  }\n\n  return { success: true, prNumber, prUrl };\n}\n\n/**\n * Wait for a PR to be merged\n *\n * @param cwd - Working directory\n * @param prNumber - PR number\n * @param timeout - Timeout in milliseconds (default: 10 minutes)\n * @returns Success result\n */\nexport async function waitForPRMerge(\n  cwd: string,\n  prNumber: number,\n  timeout = 600000\n): Promise<{ success: boolean; error?: string }> {\n  const startTime = Date.now();\n  const pollInterval = 10000; // 10 seconds\n\n  while (Date.now() - startTime < timeout) {\n    const result = await execCommand(\n      `gh pr view ${prNumber} --json state,merged`,\n      cwd\n    );\n\n    if (result.success) {\n      try {\n        const data = JSON.parse(result.stdout);\n\n        if (data.merged) {\n          return { success: true };\n        }\n\n        if (data.state === 'CLOSED' && !data.merged) {\n          return {\n            success: false,\n            error: `PR #${prNumber} was closed without merging`,\n          };\n        }\n      } catch {\n        // Parse error, continue polling\n      }\n    }\n\n    // Sleep before next poll\n    await new Promise((resolve) => setTimeout(resolve, pollInterval));\n  }\n\n  return {\n    success: false,\n    error: `Timeout waiting for PR #${prNumber} to merge (${Math.round(timeout / 60000)} minutes)`,\n  };\n}\n\n// ============================================================================\n// Cleanup Operations\n// ============================================================================\n\n/**\n * Clean up a subagent branch after workflow completion or failure\n *\n * @param cwd - Working directory\n * @param entry - Stacked branch entry to clean up\n */\nexport async function cleanupSubagentBranch(\n  cwd: string,\n  entry: StackedBranchEntry\n): Promise<void> {\n  // Ensure we're on base branch\n  await checkoutBranch(cwd, entry.baseBranch);\n\n  // Delete local subagent branch if it exists\n  await deleteLocalBranch(cwd, entry.branchName);\n\n  // Remove from state\n  await removeStackedBranchEntry(cwd, entry.agentId);\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/subagent-state.ts": "/**\n * Subagent state management for Claude Code hooks\n * Coordinates context between SubagentStart and SubagentStop hooks\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './frontmatter.js';\nimport {\n  parseTranscript,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SUBAGENT_TASKS_FILE = 'subagent-tasks.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface AgentStartContext {\n  agentId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n  toolUseId: string;\n}\n\ninterface SubagentTasksMap {\n  [agentId: string]: AgentStartContext;\n}\n\nexport interface AgentEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to subagent-tasks.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SUBAGENT_TASKS_FILE);\n}\n\n/**\n * Save agent context at SubagentStart for later retrieval at SubagentStop\n */\nexport async function saveAgentStartContext(\n  input: {\n    agent_id: string;\n    agent_type: string;\n    session_id: string;\n    cwd: string;\n    transcript_path: string;\n  },\n  outputPath?: string\n): Promise<AgentStartContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  // Parse parent transcript to find the Task call\n  const parentTranscript = await parseTranscript(input.transcript_path);\n  const taskInfo = findPendingTaskCall(parentTranscript, input.agent_type);\n\n  const context: AgentStartContext = {\n    agentId: input.agent_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: taskInfo?.prompt || '',\n    toolUseId: taskInfo?.toolUseId || '',\n  };\n\n  // Load existing contexts\n  let contexts: SubagentTasksMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.agent_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved agent context from SubagentStart\n */\nexport async function loadAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<AgentStartContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    return contexts[agentId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove agent context after SubagentStop processing\n */\nexport async function removeAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    delete contexts[agentId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Agent Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze an agent transcript to extract comprehensive edit information\n */\nexport async function getAgentEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<AgentEditsResult> {\n  const filename = path.basename(agentTranscriptPath);\n  if (!filename.startsWith('agent-')) {\n    throw new Error(`Path must be an agent transcript (starting with agent-): ${filename}`);\n  }\n\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Try to load saved context\n  let savedContext: AgentStartContext | undefined;\n  if (cwd) {\n    savedContext = await loadAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    toolUseId: savedContext?.toolUseId,\n    subagentType: savedContext?.agentType || options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = taskInfo?.prompt || savedContext?.prompt || '';\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd) {\n    await removeAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/subissue-checklist.ts": "/**\n * Subissue checklist management utility for GitHub workflow automation\n * Generates and updates checklists in parent issue bodies\n *\n * NOTE: As of 2025, GitHub has native sub-issues support via REST API.\n * When native sub-issues are in use (see native-subissues.ts), the checklist\n * approach is optional - GitHub's UI will show parent-child relationships.\n *\n * These functions remain useful for:\n * - Backwards compatibility with repos without native sub-issues\n * - Visual representation in issue body (some users prefer inline checklists)\n * - Repos that haven't enabled native sub-issues feature\n */\n\nimport { spawn } from 'node:child_process';\nimport { listNativeSubissues } from './native-subissues.js';\n\n/**\n * Check if a parent issue has native sub-issues linked\n *\n * When native sub-issues are in use, the markdown checklist is optional\n * since GitHub's UI shows the parent-child hierarchy natively.\n *\n * @param cwd - Current working directory\n * @param parentIssue - Parent issue number\n * @returns Whether the parent has native sub-issues\n */\nexport async function hasNativeSubissues(cwd: string, parentIssue: number): Promise<boolean> {\n  const subissues = await listNativeSubissues(cwd, parentIssue);\n  return subissues.length > 0;\n}\n\n/**\n * Execute gh CLI with stdin input\n */\nasync function execGhWithStdin(\n  command: string,\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('sh', ['-c', command], { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    // Write stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n/**\n * Subissue information for checklist generation\n */\nexport interface SubissueInfo {\n  /** Issue number */\n  number: number;\n  /** Issue title */\n  title: string;\n  /** Issue state (open/closed) */\n  state: 'open' | 'closed';\n  /** Optional issue URL */\n  url?: string;\n}\n\n/**\n * Generate checklist markdown from subissues\n *\n * @param subissues - Array of subissue information\n * @returns Markdown checklist with checkboxes\n *\n * @example\n * generateChecklistMarkdown([\n *   { number: 43, title: 'Task A', state: 'closed' },\n *   { number: 44, title: 'Task B', state: 'open' }\n * ])\n * // - [x] #43 Task A\n * // - [ ] #44 Task B\n */\nexport function generateChecklistMarkdown(subissues: SubissueInfo[]): string {\n  return subissues\n    .map((sub) => {\n      const checkbox = sub.state === 'closed' ? '[x]' : '[ ]';\n      const link = sub.url ? `[#${sub.number}](${sub.url})` : `#${sub.number}`;\n      return `- ${checkbox} ${link} ${sub.title}`;\n    })\n    .join('\\n');\n}\n\n/**\n * Extract checklist section from issue body\n * Looks for a section starting with \"## Subtasks\" or \"## Tasks\"\n *\n * @param issueBody - The full issue body markdown\n * @returns The checklist section if found, null otherwise\n */\nexport function extractChecklistSection(issueBody: string): string | null {\n  const match = issueBody.match(/## (Subtasks|Tasks|Checklist)\\n\\n((?:- \\[[ x]\\] .+\\n?)+)/i);\n  return match ? match[2].trim() : null;\n}\n\n/**\n * Parse checklist items from markdown\n *\n * @param checklist - Checklist markdown\n * @returns Array of parsed checklist items\n *\n * @example\n * parseChecklistItems('- [x] #43 Task A\\n- [ ] #44 Task B')\n * // [{ checked: true, issueNumber: 43, text: 'Task A' }, ...]\n */\nexport function parseChecklistItems(checklist: string): Array<{\n  checked: boolean;\n  issueNumber?: number;\n  text: string;\n}> {\n  const lines = checklist.split('\\n').filter((line) => line.trim().startsWith('- ['));\n\n  return lines.map((line) => {\n    const checked = line.includes('[x]');\n    const issueMatch = line.match(/#(\\d+)/);\n    const issueNumber = issueMatch ? parseInt(issueMatch[1], 10) : undefined;\n    const text = line\n      .replace(/^- \\[[ x]\\]\\s*/, '')\n      .replace(/#\\d+\\s*/, '')\n      .replace(/\\[#\\d+\\]\\([^)]+\\)\\s*/, '')\n      .trim();\n\n    return { checked, issueNumber, text };\n  });\n}\n\n/**\n * Update parent issue body with subissue checklist\n * Replaces existing checklist section or adds new one\n *\n * @param cwd - Current working directory\n * @param parentIssue - Parent issue number\n * @param subissues - Array of subissue information\n * @returns Success boolean\n */\nexport async function updateParentIssueChecklist(\n  cwd: string,\n  parentIssue: number,\n  subissues: SubissueInfo[]\n): Promise<boolean> {\n  // Generate checklist markdown\n  const checklist = generateChecklistMarkdown(subissues);\n\n  // Fetch current issue body\n  const viewResult = await execGhWithStdin(\n    `gh issue view ${parentIssue} --json body -q .body`,\n    '',\n    cwd\n  );\n\n  if (!viewResult.success) {\n    return false;\n  }\n\n  let updatedBody = viewResult.stdout;\n\n  // Check if checklist section exists\n  const hasChecklist = /## (Subtasks|Tasks|Checklist)/i.test(updatedBody);\n\n  if (hasChecklist) {\n    // Replace existing checklist section\n    updatedBody = updatedBody.replace(\n      /## (Subtasks|Tasks|Checklist)\\n\\n(?:- \\[[ x]\\] .+\\n?)+/i,\n      `## Subtasks\\n\\n${checklist}`\n    );\n  } else {\n    // Add new checklist section at the end\n    updatedBody = `${updatedBody.trim()}\\n\\n## Subtasks\\n\\n${checklist}`;\n  }\n\n  // Update issue body\n  const editResult = await execGhWithStdin(\n    `gh issue edit ${parentIssue} --body-file -`,\n    updatedBody,\n    cwd\n  );\n\n  return editResult.success;\n}\n\n/**\n * Add a subissue to parent's checklist\n * Appends to existing checklist or creates new one\n *\n * @param cwd - Current working directory\n * @param parentIssue - Parent issue number\n * @param subissue - Subissue information to add\n * @returns Success boolean\n */\nexport async function addSubissueToChecklist(\n  cwd: string,\n  parentIssue: number,\n  subissue: SubissueInfo\n): Promise<boolean> {\n  // Fetch current issue body\n  const viewResult = await execGhWithStdin(\n    `gh issue view ${parentIssue} --json body -q .body`,\n    '',\n    cwd\n  );\n\n  if (!viewResult.success) {\n    return false;\n  }\n\n  let updatedBody = viewResult.stdout;\n  const checkbox = subissue.state === 'closed' ? '[x]' : '[ ]';\n  const link = subissue.url ? `[#${subissue.number}](${subissue.url})` : `#${subissue.number}`;\n  const newItem = `- ${checkbox} ${link} ${subissue.title}`;\n\n  // Check if checklist section exists\n  const checklistMatch = updatedBody.match(/(## (?:Subtasks|Tasks|Checklist)\\n\\n(?:- \\[[ x]\\] .+\\n?)+)/i);\n\n  if (checklistMatch) {\n    // Append to existing checklist\n    const existingChecklist = checklistMatch[1];\n    const updatedChecklist = `${existingChecklist.trim()}\\n${newItem}`;\n    updatedBody = updatedBody.replace(existingChecklist, updatedChecklist);\n  } else {\n    // Add new checklist section\n    updatedBody = `${updatedBody.trim()}\\n\\n## Subtasks\\n\\n${newItem}`;\n  }\n\n  // Update issue body\n  const editResult = await execGhWithStdin(\n    `gh issue edit ${parentIssue} --body-file -`,\n    updatedBody,\n    cwd\n  );\n\n  return editResult.success;\n}\n\n/**\n * Mark a subissue as complete in parent's checklist\n *\n * @param cwd - Current working directory\n * @param parentIssue - Parent issue number\n * @param subissueNumber - Subissue number to mark complete\n * @returns Success boolean\n */\nexport async function markSubissueComplete(\n  cwd: string,\n  parentIssue: number,\n  subissueNumber: number\n): Promise<boolean> {\n  // Fetch current issue body\n  const viewResult = await execGhWithStdin(\n    `gh issue view ${parentIssue} --json body -q .body`,\n    '',\n    cwd\n  );\n\n  if (!viewResult.success) {\n    return false;\n  }\n\n  let updatedBody = viewResult.stdout;\n\n  // Find and update the specific subissue checkbox\n  const regex = new RegExp(`(- \\\\[[ ]\\\\]\\\\s*(?:\\\\[)?#${subissueNumber}(?:\\\\])?(?:\\\\([^)]+\\\\))?[^\\\\n]*)`, 'g');\n  updatedBody = updatedBody.replace(regex, (match) => match.replace('[ ]', '[x]'));\n\n  // Update issue body\n  const editResult = await execGhWithStdin(\n    `gh issue edit ${parentIssue} --body-file -`,\n    updatedBody,\n    cwd\n  );\n\n  return editResult.success;\n}\n\n/**\n * Sync subissue states with parent checklist\n * Fetches all subissues and updates checklist to match their current states\n *\n * @param cwd - Current working directory\n * @param parentIssue - Parent issue number\n * @param subissueNumbers - Array of subissue numbers to sync\n * @returns Success boolean\n */\nexport async function syncSubissueStates(\n  cwd: string,\n  parentIssue: number,\n  subissueNumbers: number[]\n): Promise<boolean> {\n  const subissues: SubissueInfo[] = [];\n\n  // Fetch state for each subissue\n  for (const num of subissueNumbers) {\n    const result = await execGhWithStdin(\n      `gh issue view ${num} --json number,title,state,url`,\n      '',\n      cwd\n    );\n\n    if (result.success) {\n      try {\n        const data = JSON.parse(result.stdout);\n        subissues.push({\n          number: data.number,\n          title: data.title,\n          state: data.state.toLowerCase() as 'open' | 'closed',\n          url: data.url,\n        });\n      } catch {\n        // Skip malformed JSON\n      }\n    }\n  }\n\n  if (subissues.length === 0) {\n    return false;\n  }\n\n  // Update parent checklist\n  return updateParentIssueChecklist(cwd, parentIssue, subissues);\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/task-state.test.ts": "/**\n * Tests for task-state.ts - Task state management and frontmatter parsing\n *\n * @module task-state.test\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport { tmpdir } from 'os';\nimport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n} from './task-state.js';\n\ndescribe('Task State Management', () => {\n  let testDir: string;\n  let taskCallsPath: string;\n\n  beforeEach(async () => {\n    // Create temporary directory for tests\n    testDir = await fs.mkdtemp(path.join(tmpdir(), 'task-state-test-'));\n    taskCallsPath = path.join(testDir, 'task-calls.json');\n  });\n\n  afterEach(async () => {\n    // Clean up temporary directory\n    try {\n      await fs.rm(testDir, { recursive: true, force: true });\n    } catch {\n      // Ignore cleanup errors\n    }\n  });\n\n  describe('saveTaskCallContext', () => {\n    it('should save task call context to file', async () => {\n      const input = {\n        tool_use_id: 'toolu_abc123',\n        agent_type: 'Explore',\n        session_id: 'session-xyz',\n        prompt: 'Find all API endpoints',\n        cwd: testDir,\n      };\n\n      const context = await saveTaskCallContext(input, taskCallsPath);\n\n      expect(context.toolUseId).toBe('toolu_abc123');\n      expect(context.agentType).toBe('Explore');\n      expect(context.sessionId).toBe('session-xyz');\n      expect(context.prompt).toBe('Find all API endpoints');\n      expect(context.timestamp).toBeDefined();\n\n      // Verify file was created\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n      expect(saved['toolu_abc123']).toBeDefined();\n      expect(saved['toolu_abc123'].agentType).toBe('Explore');\n    });\n\n    it('should append to existing contexts', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_first',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'First task',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_second',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Second task',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n\n      expect(Object.keys(saved)).toHaveLength(2);\n      expect(saved['toolu_first']).toBeDefined();\n      expect(saved['toolu_second']).toBeDefined();\n    });\n  });\n\n  describe('loadTaskCallContext', () => {\n    it('should load saved context by tool_use_id', async () => {\n      const input = {\n        tool_use_id: 'toolu_load_test',\n        agent_type: 'Explore',\n        session_id: 'session-load',\n        prompt: 'Load test prompt',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input, taskCallsPath);\n      const loaded = await loadTaskCallContext('toolu_load_test', testDir, taskCallsPath);\n\n      expect(loaded).toBeDefined();\n      expect(loaded?.toolUseId).toBe('toolu_load_test');\n      expect(loaded?.agentType).toBe('Explore');\n      expect(loaded?.prompt).toBe('Load test prompt');\n    });\n\n    it('should return undefined for non-existent context', async () => {\n      const loaded = await loadTaskCallContext('toolu_nonexistent', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n    });\n\n    it('should return undefined when file does not exist', async () => {\n      const loaded = await loadTaskCallContext('toolu_any', testDir, '/path/does/not/exist.json');\n      expect(loaded).toBeUndefined();\n    });\n  });\n\n  describe('removeTaskCallContext', () => {\n    it('should remove context from file', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_keep',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'Keep this',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_remove',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Remove this',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      await removeTaskCallContext('toolu_remove', testDir, taskCallsPath);\n\n      const loaded = await loadTaskCallContext('toolu_remove', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n\n      const kept = await loadTaskCallContext('toolu_keep', testDir, taskCallsPath);\n      expect(kept).toBeDefined();\n    });\n\n    it('should handle removing non-existent context gracefully', async () => {\n      await expect(\n        removeTaskCallContext('toolu_nonexistent', testDir, taskCallsPath)\n      ).resolves.toBeUndefined();\n    });\n  });\n\n  describe('parseFrontmatter (integration via parseAgentFrontmatter)', () => {\n    it('should parse simple key-value frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent.md');\n      const content = `---\nname: TestAgent\ndescription: A test agent\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      // We can't directly test parseFrontmatter since it's not exported,\n      // but we can test it indirectly through getTaskEdits if we create\n      // proper test fixtures. For now, let's create a simpler test.\n\n      // Read the file and verify the frontmatter format is correct\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---');\n      expect(fileContent).toContain('name: TestAgent');\n    });\n\n    it('should parse array values in frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent-with-skills.md');\n      const content = `---\nname: TestAgent\nskills: [skill1, skill2, skill3]\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('skills: [skill1, skill2, skill3]');\n    });\n\n    it('should handle frontmatter with various formats', async () => {\n      const agentFile = path.join(testDir, 'complex-agent.md');\n      const content = `---\nname: ComplexAgent\nversion: 1.0.0\nskills: [claude-plugins, turborepo-vercel]\nenabled: true\n---\n\n# Complex Agent\n\nThis agent has complex frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('name: ComplexAgent');\n      expect(fileContent).toContain('version: 1.0.0');\n      expect(fileContent).toContain('skills: [claude-plugins, turborepo-vercel]');\n      expect(fileContent).toContain('enabled: true');\n    });\n\n    it('should handle missing frontmatter gracefully', async () => {\n      const agentFile = path.join(testDir, 'no-frontmatter.md');\n      const content = `# Agent Without Frontmatter\n\nThis agent has no frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).not.toContain('---');\n    });\n\n    it('should handle empty frontmatter', async () => {\n      const agentFile = path.join(testDir, 'empty-frontmatter.md');\n      const content = `---\n---\n\n# Agent With Empty Frontmatter\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---\\n---');\n    });\n  });\n\n  describe('Full workflow integration', () => {\n    it('should save, load, and remove context in sequence', async () => {\n      // Save\n      const input = {\n        tool_use_id: 'toolu_workflow',\n        agent_type: 'general-purpose',\n        session_id: 'session-workflow',\n        prompt: 'Complete workflow test',\n        cwd: testDir,\n      };\n\n      const saved = await saveTaskCallContext(input, taskCallsPath);\n      expect(saved.toolUseId).toBe('toolu_workflow');\n\n      // Load\n      const loaded = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(loaded).toBeDefined();\n      expect(loaded?.prompt).toBe('Complete workflow test');\n\n      // Remove\n      await removeTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      const removed = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(removed).toBeUndefined();\n    });\n  });\n});\n",
        "plugins/github-orchestration/shared/hooks/utils/task-state.ts": "/**\n * Task state management for Claude Code hooks\n *\n * Coordinates context between PreToolUse[Task] and SubagentStop hooks by saving\n * task call metadata at PreToolUse time and retrieving it later for analysis.\n * This enables tracking what tasks were requested, what agents executed them,\n * and what file operations resulted from the task execution.\n *\n * The typical flow is:\n * 1. PreToolUse[Task] - Save task context (prompt, agent type, tool use ID)\n * 2. Task executes - Agent runs and performs file operations\n * 3. SubagentStop - Load context, analyze edits, cleanup\n *\n * @module task-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport {\n  parseTranscript,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\nimport matter from './frontmatter.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst TASK_CALLS_FILE = 'task-calls.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface TaskCallContext {\n  toolUseId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n}\n\ninterface TaskCallsMap {\n  [toolUseId: string]: TaskCallContext;\n}\n\nexport interface TaskEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to task-calls.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, TASK_CALLS_FILE);\n}\n\n/**\n * Save task call context at PreToolUse[Task] for later retrieval at SubagentStop\n *\n * Stores task metadata in .claude/logs/task-calls.json so that SubagentStop hooks\n * can correlate the task's original prompt and parameters with the agent's execution\n * results. This enables rich commit messages and task tracking.\n *\n * @param input - Task call metadata to save\n * @param input.tool_use_id - The unique ID of the Task tool use\n * @param input.agent_type - The type of agent that will execute (e.g., 'Explore', 'Plan')\n * @param input.session_id - The current session ID\n * @param input.prompt - The task prompt/description provided to the agent\n * @param input.cwd - The working directory where logs should be stored\n * @param outputPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context object\n *\n * @example\n * ```typescript\n * import { saveTaskCallContext } from './task-state.js';\n *\n * // In PreToolUse[Task] hook\n * const context = await saveTaskCallContext({\n *   tool_use_id: 'toolu_abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   prompt: 'Find all API endpoints',\n *   cwd: '/path/to/project'\n * });\n * ```\n */\nexport async function saveTaskCallContext(\n  input: {\n    tool_use_id: string;\n    agent_type: string;\n    session_id: string;\n    prompt: string;\n    cwd: string;\n  },\n  outputPath?: string\n): Promise<TaskCallContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  const context: TaskCallContext = {\n    toolUseId: input.tool_use_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: input.prompt,\n  };\n\n  // Load existing contexts\n  let contexts: TaskCallsMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.tool_use_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved task call context from PreToolUse[Task]\n *\n * Retrieves the task metadata that was saved during PreToolUse. This allows\n * SubagentStop hooks to access the original task prompt and parameters.\n *\n * @param toolUseId - The tool_use_id from the Task tool call\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context, or undefined if not found\n *\n * @example\n * ```typescript\n * import { loadTaskCallContext } from './task-state.js';\n *\n * // In SubagentStop hook\n * const context = await loadTaskCallContext(\n *   'toolu_abc123',\n *   '/path/to/project'\n * );\n * if (context) {\n *   console.log('Task prompt:', context.prompt);\n *   console.log('Agent type:', context.agentType);\n * }\n * ```\n */\nexport async function loadTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<TaskCallContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    return contexts[toolUseId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove task context after processing\n *\n * Cleans up the saved task context once it has been processed by SubagentStop.\n * This prevents the context file from growing indefinitely.\n *\n * @param toolUseId - The tool_use_id of the context to remove\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns Promise that resolves when context is removed (or fails silently)\n *\n * @example\n * ```typescript\n * import { removeTaskCallContext } from './task-state.js';\n *\n * // After processing in SubagentStop\n * await removeTaskCallContext('toolu_abc123', '/path/to/project');\n * ```\n */\nexport async function removeTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    delete contexts[toolUseId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Task Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze a task transcript to extract comprehensive edit information\n *\n * Parses an agent transcript to determine what files were created, edited, or deleted\n * during task execution. Correlates with saved task context to provide complete\n * metadata about the task, including the original prompt, agent type, and preloaded skills.\n *\n * This function:\n * 1. Parses the agent transcript to extract messages and metadata\n * 2. Finds the parent session transcript and locates the matching Task tool call\n * 3. Loads the saved task context (if available)\n * 4. Analyzes file operations (new, edited, deleted files)\n * 5. Identifies preloaded skills from agent frontmatter\n * 6. Cleans up the saved context\n *\n * @param agentTranscriptPath - Path to the agent transcript file (from SubagentStop's agent_transcript_path field)\n * @param options - Optional configuration\n * @param options.contextPath - Custom path for task-calls.json (for testing)\n * @param options.subagentType - Fallback subagent type if not found in context\n * @returns Comprehensive task execution metadata and file operation lists\n * @throws Error if agent transcript is empty\n * @throws Error if agentId cannot be determined\n * @throws Error if parent session transcript not found\n *\n * @example\n * ```typescript\n * import { getTaskEdits } from './task-state.js';\n *\n * // In SubagentStop hook\n * const edits = await getTaskEdits(input.agent_transcript_path);\n *\n * console.log('Task prompt:', edits.agentPrompt);\n * console.log('Agent type:', edits.subagentType);\n * console.log('Files created:', edits.agentNewFiles);\n * console.log('Files edited:', edits.agentEditedFiles);\n * console.log('Files deleted:', edits.agentDeletedFiles);\n * console.log('Preloaded skills:', edits.agentPreloadedSkillsFiles);\n * ```\n *\n * @example\n * ```typescript\n * // Complete PreToolUse → SubagentStop flow\n *\n * // 1. PreToolUse[Task] - Save context\n * import { saveTaskCallContext } from './task-state.js';\n *\n * async function handlePreToolUse(input: PreToolUseInput) {\n *   if (input.tool_name === 'Task') {\n *     await saveTaskCallContext({\n *       tool_use_id: input.tool_use_id,\n *       agent_type: input.tool_input.subagent_type,\n *       session_id: input.session_id,\n *       prompt: input.tool_input.prompt,\n *       cwd: input.cwd\n *     });\n *   }\n *   return { hookSpecificOutput: { permissionDecision: 'allow' } };\n * }\n *\n * // 2. Task executes (agent runs)\n *\n * // 3. SubagentStop - Analyze edits\n * import { getTaskEdits } from './task-state.js';\n *\n * async function handleSubagentStop(input: SubagentStopInput) {\n *   const edits = await getTaskEdits(input.agent_transcript_path);\n *\n *   // Use edits for commit message, logging, etc.\n *   console.log(`Task \"${edits.agentPrompt}\" completed`);\n *   console.log(`Modified ${edits.agentEditedFiles.length} files`);\n *\n *   return {};\n * }\n * ```\n */\nexport async function getTaskEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<TaskEditsResult> {\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  // Agent transcripts are at: .../project/{sessionId}/subagents/agent-{agentId}.jsonl\n  // Parent transcripts are at: .../project/{sessionId}.jsonl\n  let dir = path.dirname(agentTranscriptPath); // .../sessionId/subagents/\n  if (path.basename(dir) === 'subagents') {\n    dir = path.dirname(dir); // .../sessionId/\n  }\n  dir = path.dirname(dir); // .../project/\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    subagentType: options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  // Try to load saved context using tool_use_id from task call\n  let savedContext: TaskCallContext | undefined;\n  if (cwd && taskInfo?.toolUseId) {\n    savedContext = await loadTaskCallContext(taskInfo.toolUseId, cwd, options?.contextPath);\n  }\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = savedContext?.prompt || taskInfo?.prompt || '';\n  const toolUseId = taskInfo?.toolUseId || savedContext?.toolUseId;\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd && toolUseId) {\n    await removeTaskCallContext(toolUseId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/toml.ts": "/**\n * Simple TOML parser for configuration files\n *\n * Provides basic TOML parsing functionality for reading configuration files\n * like supabase/config.toml. This is a lightweight parser that supports the\n * most common TOML features without requiring external dependencies.\n *\n * Supported TOML features:\n * - Key-value pairs (strings, numbers, booleans)\n * - Inline arrays: `values = [1, 2, 3]`\n * - Multiline arrays spanning multiple lines\n * - Tables (sections): `[section]` and `[section.subsection]`\n * - Comments starting with `#`\n *\n * @module toml\n */\n\nexport interface TomlValue {\n  [key: string]: string | number | boolean | string[] | TomlValue;\n}\n\n/**\n * Parse a TOML string into a JavaScript object\n *\n * Converts TOML configuration syntax into a JavaScript object with nested\n * structure matching the TOML sections and subsections.\n *\n * @param content - The TOML string to parse\n * @returns Parsed object with nested structure\n *\n * @example\n * ```typescript\n * import { parseToml } from './toml.js';\n *\n * const tomlContent = `\n * # Project configuration\n * project_id = \"my-project\"\n * enabled = true\n *\n * [api]\n * port = 54321\n * enabled_services = [\"auth\", \"realtime\", \"storage\"]\n *\n * [db]\n * port = 54322\n * `;\n *\n * const config = parseToml(tomlContent);\n * console.log(config.project_id); // \"my-project\"\n * console.log(config.enabled); // true\n * console.log(config.api.port); // 54321\n * console.log(config.api.enabled_services); // [\"auth\", \"realtime\", \"storage\"]\n * console.log(config.db.port); // 54322\n * ```\n */\nexport function parseToml(content: string): TomlValue {\n  const result: TomlValue = {};\n  let currentSection: TomlValue = result;\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      continue;\n    }\n\n    // Handle table headers [section] or [section.subsection]\n    if (line.startsWith('[') && line.endsWith(']')) {\n      const sectionPath = line.slice(1, -1).trim();\n      currentSection = result;\n\n      for (const part of sectionPath.split('.')) {\n        if (!(part in currentSection)) {\n          currentSection[part] = {};\n        }\n        currentSection = currentSection[part] as TomlValue;\n      }\n      continue;\n    }\n\n    // Handle key-value pairs\n    const eqIndex = line.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = line.slice(0, eqIndex).trim();\n    const value = line.slice(eqIndex + 1).trim();\n\n    // Parse the value\n    currentSection[key] = parseValue(value, lines, i);\n  }\n\n  return result;\n}\n\n/**\n * Parse a TOML value\n */\nfunction parseValue(value: string, lines: string[], lineIndex: number): string | number | boolean | string[] {\n  // Handle multiline arrays\n  if (value === '[' || value.startsWith('[') && !value.endsWith(']')) {\n    return parseMultilineArray(value, lines, lineIndex);\n  }\n\n  // Handle inline arrays\n  if (value.startsWith('[') && value.endsWith(']')) {\n    return parseInlineArray(value);\n  }\n\n  // Handle strings\n  if (value.startsWith('\"') && value.endsWith('\"')) {\n    return value.slice(1, -1);\n  }\n  if (value.startsWith(\"'\") && value.endsWith(\"'\")) {\n    return value.slice(1, -1);\n  }\n\n  // Handle booleans\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle numbers\n  const num = Number(value);\n  if (!isNaN(num)) return num;\n\n  // Return as string if nothing else matches\n  return value;\n}\n\n/**\n * Parse an inline array like [1, 2, 3] or [\"a\", \"b\", \"c\"]\n */\nfunction parseInlineArray(value: string): string[] {\n  const inner = value.slice(1, -1).trim();\n  if (!inner) return [];\n\n  const items: string[] = [];\n  let current = '';\n  let inQuote = false;\n  let quoteChar = '';\n\n  for (const char of inner) {\n    if ((char === '\"' || char === \"'\") && !inQuote) {\n      inQuote = true;\n      quoteChar = char;\n    } else if (char === quoteChar && inQuote) {\n      inQuote = false;\n      quoteChar = '';\n    } else if (char === ',' && !inQuote) {\n      const trimmed = current.trim();\n      if (trimmed) {\n        items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n      }\n      current = '';\n    } else {\n      current += char;\n    }\n  }\n\n  const trimmed = current.trim();\n  if (trimmed) {\n    items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n  }\n\n  return items;\n}\n\n/**\n * Parse a multiline array\n */\nfunction parseMultilineArray(startValue: string, lines: string[], startIndex: number): string[] {\n  const items: string[] = [];\n  let content = startValue;\n\n  // Collect lines until we find the closing bracket\n  for (let i = startIndex; i < lines.length; i++) {\n    const line = lines[i].trim();\n    if (i > startIndex) {\n      content += ' ' + line;\n    }\n    if (line.includes(']')) {\n      break;\n    }\n  }\n\n  // Now parse as inline array\n  const match = content.match(/\\[([\\s\\S]*)\\]/);\n  if (match) {\n    return parseInlineArray('[' + match[1] + ']');\n  }\n\n  return items;\n}\n\n/**\n * Read and parse a TOML file\n *\n * Reads a TOML configuration file from disk and parses it into a JavaScript object.\n * Returns null if the file doesn't exist or cannot be read.\n *\n * @param filePath - Path to the TOML file\n * @returns Parsed object, or null if file doesn't exist or read fails\n *\n * @example\n * ```typescript\n * import { readTomlFile } from './toml.js';\n * import { join } from 'path';\n *\n * // Read Supabase configuration\n * const supabaseConfig = await readTomlFile(\n *   join(process.cwd(), 'supabase', 'config.toml')\n * );\n *\n * if (supabaseConfig) {\n *   console.log('Project ID:', supabaseConfig.project_id);\n *   console.log('API port:', supabaseConfig.api?.port);\n *   console.log('DB port:', supabaseConfig.db?.port);\n * } else {\n *   console.log('Supabase not initialized');\n * }\n * ```\n */\nexport async function readTomlFile(filePath: string): Promise<TomlValue | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(filePath, 'utf-8');\n    return parseToml(content);\n  } catch {\n    return null;\n  }\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/transcripts.ts": "/**\n * Transcript parsing utilities for Claude Code\n * Lenient JSONL parsing without Zod - uses type guards for safety\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Types for Transcript Parsing\n// ============================================================================\n\nexport interface BaseMessage {\n  uuid: string;\n  parentUuid: string | null;\n  timestamp: string;\n  sessionId: string;\n  isSidechain: boolean;\n  cwd: string;\n  version: string;\n  gitBranch?: string;\n  slug?: string;\n  agentId?: string;\n}\n\nexport interface ToolUseContent {\n  type: 'tool_use';\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n}\n\nexport interface TextContent {\n  type: 'text';\n  text: string;\n}\n\nexport interface ToolResultContent {\n  type: 'tool_result';\n  tool_use_id: string;\n  content?: string | Array<{ type: string; text?: string }>;\n}\n\nexport type AssistantContent = ToolUseContent | TextContent | { type: string; [key: string]: unknown };\nexport type UserContent = string | Array<ToolResultContent | { type: string; [key: string]: unknown }>;\n\nexport interface UserMessage extends BaseMessage {\n  type: 'user';\n  userType: 'external';\n  message: {\n    role: 'user';\n    content: UserContent;\n  };\n  toolUseResult?: Record<string, unknown>;\n}\n\nexport interface AssistantMessage extends BaseMessage {\n  type: 'assistant';\n  requestId: string;\n  message: {\n    id: string;\n    type: 'message';\n    role: 'assistant';\n    model: string;\n    content: AssistantContent[];\n    stop_reason: string | null;\n    stop_sequence: string | null;\n    usage: {\n      input_tokens: number;\n      output_tokens: number;\n      cache_creation_input_tokens?: number;\n      cache_read_input_tokens?: number;\n    };\n  };\n}\n\nexport interface SystemMessage extends BaseMessage {\n  type: 'system';\n  subtype: string;\n  content: string;\n  isMeta: boolean;\n  level: 'info' | 'warning' | 'error';\n}\n\nexport type Message = UserMessage | AssistantMessage | SystemMessage;\n\nexport interface Transcript {\n  sourcePath: string;\n  sessionId: string;\n  subagentType?: string;\n  agentId?: string;\n  isSidechain: boolean;\n  messages: Message[];\n}\n\n// ============================================================================\n// Type Guards\n// ============================================================================\n\nfunction isObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === 'object' && value !== null;\n}\n\nfunction isMessage(line: unknown): line is Message {\n  if (!isObject(line)) return false;\n  const type = line.type;\n  return type === 'user' || type === 'assistant' || type === 'system';\n}\n\nfunction hasRequiredFields(line: unknown): boolean {\n  if (!isObject(line)) return false;\n  return (\n    typeof line.uuid === 'string' &&\n    typeof line.timestamp === 'string' &&\n    typeof line.sessionId === 'string'\n  );\n}\n\n// ============================================================================\n// Parsing Functions\n// ============================================================================\n\n/**\n * Parse a single JSONL line (lenient - returns null on error)\n */\nexport function parseTranscriptLine(line: string): Message | null {\n  try {\n    const json = JSON.parse(line);\n    if (!isMessage(json) || !hasRequiredFields(json)) {\n      return null;\n    }\n    return json as Message;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get transcript metadata from file path\n */\nexport function getTranscriptInfo(filePath: string): { agentId?: string; isSidechain: boolean } {\n  const filename = path.basename(filePath);\n  const isSubagent = filename.startsWith('agent-');\n  const agentId = isSubagent ? filename.replace('agent-', '').replace('.jsonl', '') : undefined;\n\n  return { agentId, isSidechain: isSubagent };\n}\n\n/**\n * Parse a full .jsonl transcript file\n */\nexport async function parseTranscript(filePath: string): Promise<Transcript> {\n  const info = getTranscriptInfo(filePath);\n  const content = await fs.readFile(filePath, 'utf-8');\n  const lines = content.trim().split('\\n').filter(Boolean);\n\n  const messages: Message[] = [];\n  let sessionId = '';\n\n  for (const line of lines) {\n    const parsed = parseTranscriptLine(line);\n    if (!parsed) continue;\n\n    if (!sessionId) sessionId = parsed.sessionId;\n    messages.push(parsed);\n  }\n\n  return {\n    sourcePath: filePath,\n    sessionId,\n    agentId: info.agentId,\n    isSidechain: info.isSidechain,\n    messages,\n  };\n}\n\n// ============================================================================\n// Query Functions\n// ============================================================================\n\n/**\n * Extract all tool uses from a transcript\n */\nexport function getToolUses(transcript: Transcript): Array<{\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n  timestamp: string;\n}> {\n  const toolUses: Array<{\n    id: string;\n    name: string;\n    input: Record<string, unknown>;\n    timestamp: string;\n  }> = [];\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        toolUses.push({\n          id: tu.id,\n          name: tu.name,\n          input: tu.input,\n          timestamp: msg.timestamp,\n        });\n      }\n    }\n  }\n\n  return toolUses;\n}\n\n/**\n * Extract unique file paths edited by Write/Edit tools\n */\nexport function getEditedFiles(transcript: Transcript): string[] {\n  const files = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write' || tu.name === 'Edit') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string') {\n            files.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(files);\n}\n\n/**\n * Extract unique file paths created by Write tool (new files only)\n */\nexport function getNewFiles(transcript: Transcript): string[] {\n  const newFiles: string[] = [];\n  const seenPaths = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string' && !seenPaths.has(filePath)) {\n            newFiles.push(filePath);\n            seenPaths.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return newFiles;\n}\n\n/**\n * Extract unique file paths deleted via Bash rm commands\n */\nexport function getDeletedFiles(transcript: Transcript): string[] {\n  const deletedFiles = new Set<string>();\n  const rmPattern = /^\\s*rm\\s+(?:-[rfiv]+\\s+)*(.+)$/;\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Bash') {\n          const command = tu.input.command;\n          if (typeof command !== 'string') continue;\n\n          const commands = command.split(/\\s*(?:&&|;)\\s*/);\n          for (const cmd of commands) {\n            const match = cmd.match(rmPattern);\n            if (match) {\n              const pathsStr = match[1].trim();\n              const paths = pathsStr.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g) || [];\n\n              for (const p of paths) {\n                const cleanPath = p.replace(/^[\"']|[\"']$/g, '');\n                if (!cleanPath.startsWith('-')) {\n                  deletedFiles.add(cleanPath);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(deletedFiles);\n}\n\n/**\n * Find pending Task tool call matching agent type\n */\nexport function findPendingTaskCall(\n  transcript: Transcript,\n  agentType: string\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls: Array<{\n    toolUseId: string;\n    subagentType: string;\n    prompt: string;\n    timestamp: string;\n  }> = [];\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.push({\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Collect completed tool_use_ids\n  const completedToolUseIds = new Set<string>();\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const content = msg.message.content;\n    if (typeof content === 'string') continue;\n    for (const rc of content) {\n      if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n        completedToolUseIds.add(rc.tool_use_id);\n      }\n    }\n  }\n\n  // Find pending Task calls matching agent type\n  const pendingTasks = taskCalls\n    .filter((t) => !completedToolUseIds.has(t.toolUseId))\n    .filter((t) => t.subagentType === agentType)\n    .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n  return pendingTasks[0];\n}\n\n/**\n * Find Task tool call for an agent using multiple strategies\n */\nexport function findTaskCallForAgent(\n  transcript: Transcript,\n  targetAgentId: string,\n  options?: {\n    subagentType?: string;\n    toolUseId?: string;\n    agentStartTimestamp?: string;\n  }\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls = new Map<string, {\n    subagentType: string;\n    prompt: string;\n    toolUseId: string;\n    timestamp: string;\n  }>();\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.set(tu.id, {\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Strategy 1: Direct lookup by toolUseId\n  if (options?.toolUseId) {\n    const direct = taskCalls.get(options.toolUseId);\n    if (direct) return direct;\n  }\n\n  // Strategy 2: Match via tool_result.agentId\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const toolResult = msg.toolUseResult as { agentId?: string } | undefined;\n    if (toolResult?.agentId === targetAgentId) {\n      const content = msg.message.content;\n      if (typeof content === 'string') continue;\n\n      for (const rc of content) {\n        if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n          const taskInfo = taskCalls.get(rc.tool_use_id);\n          if (taskInfo) return taskInfo;\n        }\n      }\n    }\n  }\n\n  // Strategy 3: Fuzzy match by subagentType and timestamp\n  if (options?.subagentType && options?.agentStartTimestamp) {\n    const agentStartTime = new Date(options.agentStartTimestamp).getTime();\n    const maxDelta = 10000; // 10 seconds\n\n    const candidates = Array.from(taskCalls.values())\n      .filter((t) => t.subagentType === options.subagentType)\n      .filter((t) => {\n        const taskTime = new Date(t.timestamp).getTime();\n        return taskTime <= agentStartTime && agentStartTime - taskTime <= maxDelta;\n      })\n      .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n    if (candidates[0]) return candidates[0];\n  }\n\n  return undefined;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/was-tool-event-main-agent.ts": "/**\n * Utility to determine if a tool event was executed by the main agent vs a subagent\n */\n\nimport { parseTranscript, type AssistantMessage } from './transcripts.js';\n\n/**\n * Check if a specific tool use was executed by the main agent (not a subagent)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param toolUseId - The tool_use_id to check\n * @returns true if the tool was used by the main agent, false if by a subagent\n *\n * @example\n * ```typescript\n * const isMainAgent = await wasToolEventMainAgent(\n *   input.transcript_path,\n *   input.tool_use_id\n * );\n * if (!isMainAgent) {\n *   // Skip processing for subagent tool use\n *   return { continue: true };\n * }\n * ```\n */\nexport async function wasToolEventMainAgent(\n  transcriptPath: string,\n  toolUseId: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n\n  // Find the assistant message containing this tool use\n  for (const msg of transcript.messages) {\n    if (msg.type === 'assistant') {\n      const assistantMsg = msg as AssistantMessage;\n      const toolUse = assistantMsg.message.content.find(\n        (c) => c.type === 'tool_use' && 'id' in c && c.id === toolUseId\n      );\n\n      if (toolUse) {\n        // If agentId is undefined/null, it's the main agent\n        // If agentId is a string, it's a subagent\n        return !msg.agentId;\n      }\n    }\n  }\n\n  // If we can't find the tool use, default to assuming it's the main agent\n  // This is safer than blocking legitimate main agent operations\n  return true;\n}\n\n/**\n * Check if the entire transcript is from the main agent session (not a subagent session)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns true if this is a main agent transcript, false if it's a subagent transcript\n *\n * @example\n * ```typescript\n * const isMainSession = await isMainAgentTranscript(input.transcript_path);\n * if (!isMainSession) {\n *   // This is a subagent session, skip processing\n *   return { continue: true };\n * }\n * ```\n */\nexport async function isMainAgentTranscript(transcriptPath: string): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return !transcript.isSidechain;\n}\n\n/**\n * Check if a transcript belongs to a specific subagent type\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param subagentType - The subagent type to check for (e.g., \"Explore\", \"Plan\")\n * @returns true if the transcript is from the specified subagent type\n *\n * @example\n * ```typescript\n * const isExploreAgent = await isSubagentType(input.transcript_path, 'Explore');\n * if (isExploreAgent) {\n *   // Special handling for Explore agents\n * }\n * ```\n */\nexport async function isSubagentType(\n  transcriptPath: string,\n  subagentType: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.subagentType === subagentType;\n}\n\n/**\n * Get the agent ID from a transcript (undefined for main agent, string for subagents)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns The agent ID if this is a subagent, undefined if main agent\n *\n * @example\n * ```typescript\n * const agentId = await getTranscriptAgentId(input.transcript_path);\n * if (agentId) {\n *   console.log(`Processing subagent: ${agentId}`);\n * } else {\n *   console.log('Processing main agent');\n * }\n * ```\n */\nexport async function getTranscriptAgentId(transcriptPath: string): Promise<string | undefined> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.agentId;\n}\n",
        "plugins/github-orchestration/shared/hooks/utils/work-type-detector.ts": "/**\n * Work type detection utility for GitHub workflow automation\n * Extracted from create-issue-on-prompt.ts for reusability\n */\n\n/**\n * Work type prefixes for branch naming and issue labeling\n */\nexport type WorkType = 'feature' | 'fix' | 'chore' | 'docs' | 'refactor';\n\n/**\n * Detect work type from prompt keywords\n *\n * @param prompt - The user prompt or issue title\n * @param issueLabels - Optional array of issue labels to help with detection\n * @returns Detected work type\n *\n * @example\n * detectWorkType('fix the broken authentication') // 'fix'\n * detectWorkType('add dark mode feature') // 'feature'\n * detectWorkType('update README docs') // 'docs'\n */\nexport function detectWorkType(prompt: string, issueLabels?: string[]): WorkType {\n  const lower = prompt.toLowerCase();\n\n  // Check labels first if available\n  if (issueLabels) {\n    const labelLower = issueLabels.map((l) => l.toLowerCase());\n    if (labelLower.some((l) => l.includes('bug') || l.includes('fix'))) {\n      return 'fix';\n    }\n    if (labelLower.some((l) => l.includes('docs') || l.includes('documentation'))) {\n      return 'docs';\n    }\n    if (labelLower.some((l) => l.includes('refactor') || l.includes('cleanup'))) {\n      return 'refactor';\n    }\n    if (labelLower.some((l) => l.includes('chore') || l.includes('maintenance'))) {\n      return 'chore';\n    }\n    if (labelLower.some((l) => l.includes('feature') || l.includes('enhancement'))) {\n      return 'feature';\n    }\n  }\n\n  // Fix patterns\n  if (/\\b(fix|bug|error|issue|broken|crash|fail|wrong)\\b/.test(lower)) {\n    return 'fix';\n  }\n\n  // Docs patterns\n  if (/\\b(doc|readme|document|comment|explain)\\b/.test(lower)) {\n    return 'docs';\n  }\n\n  // Refactor patterns\n  if (/\\b(refactor|clean|improve|optimize|reorganize|restructure)\\b/.test(lower)) {\n    return 'refactor';\n  }\n\n  // Chore patterns\n  if (/\\b(chore|maintain|update|upgrade|config|setup)\\b/.test(lower)) {\n    return 'chore';\n  }\n\n  // Feature patterns (default for most work)\n  if (/\\b(add|create|implement|build|new|feature|develop)\\b/.test(lower)) {\n    return 'feature';\n  }\n\n  // Default to feature for general work\n  return 'feature';\n}\n\n/**\n * Format work type as a label string\n *\n * @param workType - The work type to format\n * @returns Formatted label (e.g., \"Feature\", \"Bug Fix\")\n *\n * @example\n * formatWorkTypeLabel('feature') // 'Feature'\n * formatWorkTypeLabel('fix') // 'Bug Fix'\n */\nexport function formatWorkTypeLabel(workType: WorkType): string {\n  const labels: Record<WorkType, string> = {\n    feature: 'Feature',\n    fix: 'Bug Fix',\n    chore: 'Chore',\n    docs: 'Documentation',\n    refactor: 'Refactor',\n  };\n\n  return labels[workType];\n}\n",
        "plugins/github-orchestration/shared/hooks/validate-folder-structure-mkdir.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Bash mkdir)\n *\n * This hook fires before Bash operations to validate directory creation against\n * CLAUDE.md folder specifications. Validates:\n * - mkdir commands creating new directories\n * - Checks parent's subfolder spec for allowed patterns\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n *\n * @module hooks/validate-folder-structure-mkdir\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Extract directory paths from mkdir commands\n * Handles: mkdir dir, mkdir -p dir, mkdir -p dir1 dir2, etc.\n */\nfunction extractMkdirPaths(command: string): string[] {\n  const paths: string[] = [];\n\n  // Extract the actual command (before pipes, semicolons, &&, etc.)\n  // This prevents false positives from strings containing \"mkdir\"\n  const actualCommand = command.split(/[|;&]/)[0].trim();\n\n  // Check if this is actually a mkdir command (not just containing \"mkdir\" in a string)\n  if (!actualCommand.match(/^\\s*(sudo\\s+)?mkdir\\b/)) {\n    return paths;\n  }\n\n  // Remove mkdir and common flags\n  const remainder = command\n    .replace(/^.*mkdir\\s+/, '')\n    .replace(/-[pv]+\\s+/g, '');\n\n  // Extract all path arguments (space-separated)\n  // Handle quoted paths\n  const pathMatches = remainder.match(/(?:\"([^\"]+)\"|'([^']+)'|(\\S+))/g);\n\n  if (pathMatches) {\n    for (const match of pathMatches) {\n      // Remove quotes if present\n      const cleanPath = match.replace(/^[\"']|[\"']$/g, '');\n      // Skip flags\n      if (!cleanPath.startsWith('-')) {\n        paths.push(cleanPath);\n      }\n    }\n  }\n\n  return paths;\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Bash mkdir operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Bash tool\n  if (input.tool_name !== 'Bash') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-mkdir', true);\n\n  try {\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput.command;\n\n    if (!command) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Extract mkdir paths from command\n    const mkdirPaths = extractMkdirPaths(command);\n\n    if (mkdirPaths.length === 0) {\n      // Not a mkdir command - don't log anything, just allow\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only log input for actual mkdir commands\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n      command,\n      mkdirPaths,\n    });\n\n    await logger.logOutput({\n      command,\n      mkdirPaths,\n    });\n\n    const allErrors: string[] = [];\n\n    // Validate each directory path\n    for (const dirPath of mkdirPaths) {\n      // Resolve to absolute path\n      const absolutePath = path.isAbsolute(dirPath)\n        ? dirPath\n        : path.resolve(input.cwd, dirPath);\n\n      const parentDir = path.dirname(absolutePath);\n      const folderName = path.basename(absolutePath);\n\n      await logger.logOutput({\n        dirPath,\n        absolutePath,\n        parentDir,\n        folderName,\n      });\n\n      // Check if directory already exists\n      try {\n        await fs.access(absolutePath);\n        // Directory exists, no need to validate\n        await logger.logOutput({\n          dirPath,\n          status: 'exists',\n        });\n        continue;\n      } catch {\n        // Directory doesn't exist, proceed with validation\n      }\n\n      // Validate the directory is allowed in parent's subfolder spec\n      const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n      if (parentClaudeMd) {\n        const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n        const { data: parentData } = matter(parentContent);\n        const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n        await logger.logOutput({\n          check: 'parent-subfolder-validation',\n          dirPath,\n          parentClaudeMd,\n          parentFrontmatter,\n        });\n\n        if (parentFrontmatter.folder?.subfolders) {\n          const validation = validateAgainstSpec(\n            folderName,\n            parentFrontmatter.folder.subfolders,\n            'Folder'\n          );\n\n          if (!validation.valid) {\n            allErrors.push(\n              `Cannot create directory \"${folderName}\" in \"${parentDir}\":\\n` +\n                validation.errors.map(e => `  - ${e}`).join('\\n') +\n                `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n            );\n          }\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `Folder structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Folder structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/validate-folder-structure-write.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Write)\n *\n * This hook fires before Write operations to validate file creation against\n * CLAUDE.md folder specifications. Validates both:\n * 1. File is in an allowed subdirectory (checks parent's subfolder spec)\n * 2. File matches allowed patterns in its immediate directory (checks files spec)\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n * - folder.files: Controls what files can exist in the folder\n *\n * @module hooks/validate-folder-structure-write\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Write operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write tool\n  if (input.tool_name !== 'Write') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-write', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Resolve to absolute path\n    const absolutePath = path.isAbsolute(filePath)\n      ? filePath\n      : path.resolve(input.cwd, filePath);\n\n    const fileDir = path.dirname(absolutePath);\n    const fileName = path.basename(absolutePath);\n    const parentDir = path.dirname(fileDir);\n    const folderName = path.basename(fileDir);\n\n    await logger.logOutput({\n      filePath,\n      absolutePath,\n      fileDir,\n      fileName,\n      parentDir,\n      folderName,\n    });\n\n    const allErrors: string[] = [];\n\n    // Check 1: Validate the directory itself is allowed (check parent's subfolder spec)\n    const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n    if (parentClaudeMd) {\n      const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n      const { data: parentData } = matter(parentContent);\n      const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'parent-subfolder-validation',\n        parentClaudeMd,\n        parentFrontmatter,\n      });\n\n      if (parentFrontmatter.folder?.subfolders) {\n        const validation = validateAgainstSpec(\n          folderName,\n          parentFrontmatter.folder.subfolders,\n          'Folder'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file in directory \"${folderName}\":\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // Check 2: Validate the file itself is allowed (check directory's files spec)\n    const dirClaudeMd = await findClaudeMdInDir(fileDir);\n\n    if (dirClaudeMd) {\n      const dirContent = await fs.readFile(dirClaudeMd, 'utf-8');\n      const { data: dirData } = matter(dirContent);\n      const dirFrontmatter = dirData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'file-validation',\n        dirClaudeMd,\n        dirFrontmatter,\n      });\n\n      if (dirFrontmatter.folder?.files) {\n        const validation = validateAgainstSpec(\n          fileName,\n          dirFrontmatter.folder.files,\n          'File'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file \"${fileName}\" in this directory:\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nFile restrictions defined in: ${dirClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `File structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `File structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/shared/hooks/validate-rules-file.ts": "/**\n * PreToolUse Hook - Validate Rules File\n *\n * This hook fires before Write and Edit operations on rule files in .claude/rules\n * to validate that markdown-specific frontmatter is only used in .md-specific rules.\n *\n * Provides guidance:\n * - Warns if markdown frontmatter is used in non-.md rules\n * - Encourages markdown frontmatter in .md rules if not present\n * - Does NOT block operations - only provides context\n *\n * @module hooks/validate-rules-file\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface MarkdownValidation {\n  headings?: unknown;\n  metadata?: unknown;\n}\n\ninterface RuleFrontmatter {\n  markdown?: MarkdownValidation;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a rule filename indicates it applies to markdown files\n */\nfunction isMarkdownRule(filename: string): boolean {\n  const lowerFilename = filename.toLowerCase();\n\n  // Remove .md extension from rule filename for checking\n  const ruleName = lowerFilename.replace(/\\.md$/, '');\n\n  // Check if rule name suggests markdown files\n  return (\n    ruleName.includes('markdown') ||\n    ruleName.includes('.md') ||\n    ruleName === 'md' ||\n    ruleName.endsWith('-md')\n  );\n}\n\n/**\n * PreToolUse hook handler for validating rules files\n *\n * Validates that markdown frontmatter is appropriately used in rule files.\n * Provides guidance but does not block operations.\n *\n * @param input - PreToolUse hook input from Claude Code\n * @returns Hook output with guidance messages\n */\nasync function handler(\n  input: PreToolUseInput\n): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-rules-file', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Get the file path and content from tool input\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Check if this is a file in .claude/rules\n    const normalizedPath = path.normalize(filePath);\n    const isRuleFile = normalizedPath.includes(path.join('.claude', 'rules')) &&\n                       filePath.endsWith('.md');\n\n    if (!isRuleFile) {\n      await logger.logOutput({ message: 'Not a rule file, skipping' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get content based on operation type\n    let content: string | undefined;\n\n    if (input.tool_name === 'Write') {\n      content = toolInput.content;\n    } else if (input.tool_name === 'Edit') {\n      // For Edit, we need the new content after the edit\n      // Since we can't easily reconstruct it, we'll just check the new_string portion\n      content = toolInput.new_string;\n    }\n\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter\n    let frontmatter: RuleFrontmatter;\n    try {\n      const { data } = matter(content);\n      frontmatter = data as RuleFrontmatter;\n    } catch {\n      // If we can't parse frontmatter, allow the operation\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    const filename = path.basename(filePath);\n    const hasMarkdownFrontmatter = Boolean(frontmatter.markdown);\n    const isMdRule = isMarkdownRule(filename);\n\n    await logger.logOutput({\n      filename,\n      hasMarkdownFrontmatter,\n      isMdRule,\n    });\n\n    // Case 1: Has markdown frontmatter but doesn't apply to .md files\n    if (hasMarkdownFrontmatter && !isMdRule) {\n      const warningMessage =\n        `⚠️  Rule file \"${filename}\" contains markdown-specific frontmatter but doesn't appear to target .md files.\\n\\n` +\n        `The \\`markdown:\\` frontmatter is designed for validating markdown file structure (headings and metadata).\\n` +\n        `This rule's filename suggests it targets non-markdown files.\\n\\n` +\n        `Consider:\\n` +\n        `- Removing the \\`markdown:\\` frontmatter if this rule doesn't apply to .md files\\n` +\n        `- Renaming the rule to include \".md\" if it does target markdown files (e.g., \"*.md.md\")`;\n\n      await logger.logOutput({ warning: warningMessage });\n\n      return {\n        systemMessage: warningMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Case 2: Applies to .md files but doesn't have markdown frontmatter\n    if (isMdRule && !hasMarkdownFrontmatter) {\n      const encouragementMessage =\n        `💡 Rule file \"${filename}\" appears to target markdown files but doesn't have \\`markdown:\\` frontmatter.\\n\\n` +\n        `You can add markdown validation by including a \\`markdown:\\` section in the frontmatter:\\n\\n` +\n        `\\`\\`\\`yaml\\n` +\n        `---\\n` +\n        `markdown:\\n` +\n        `  headings:\\n` +\n        `    allowed: [\"#*\", \"##*\", \"###*\"]  # Allow h1, h2, h3\\n` +\n        `    required: [\"# *\"]               # Require title heading\\n` +\n        `  frontmatter:\\n` +\n        `    allowed: [\"*\"]                  # Allow any frontmatter fields\\n` +\n        `    required: [\"title\"]             # Require title field\\n` +\n        `---\\n` +\n        `\\`\\`\\`\\n\\n` +\n        `This enables automatic validation of markdown structure and frontmatter fields.`;\n\n      await logger.logOutput({ encouragement: encouragementMessage });\n\n      return {\n        systemMessage: encouragementMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // All good - either has appropriate frontmatter or doesn't need guidance\n    await logger.logOutput({ status: 'valid' });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation\n    return {\n      systemMessage: `Rules file validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/github-orchestration/skills/branch-orchestration/SKILL.md": "---\nname: Branch Orchestration\ndescription: Use this skill when the user wants to \"create branch\", \"rename branch\", \"smart branch name\", \"link branch to issue\", or manage branch lifecycle. Provides intelligent branch naming with automatic issue linking following the pattern {issueNum}-{workType}/{kebab-name}.\nversion: 0.1.0\n---\n\n# Branch Orchestration\n\nIntelligent Git branch management with automated naming, issue linking, and lifecycle operations.\n\n## Purpose\n\nBranch Orchestration provides systematic branch naming and management following the convention `{issueNum}-{workType}/{kebab-name}`. Automatically links branches to GitHub issues, detects work types, and manages branch lifecycle including creation, renaming, remote sync, and cleanup.\n\n## When to Use\n\n- Creating branches with smart naming from issue context\n- Renaming branches to follow project conventions\n- Linking branches to GitHub issues\n- Cleaning up merged or stale branches\n- When hooks don't provide enough control over naming\n\n## Core Capabilities\n\n### Branch Naming Convention\n\nFormat: `{issueNumber}-{workType}/{kebab-case-title}`\n\n**Examples:**\n- `42-feature/add-dark-mode`\n- `123-fix/safari-auth-bug`\n- `7-docs/update-readme`\n- `99-refactor/simplify-api`\n\n### Branch Creation\n\nCreate branches with intelligent naming:\n\n```bash\n# Manual creation with naming utilities\nISSUE_NUM=42\nWORK_TYPE=\"feature\"\nTITLE=\"Add dark mode support\"\n\n# Generate branch name\nBRANCH_NAME=$(generateBranchName $ISSUE_NUM \"$WORK_TYPE\" \"$TITLE\")\n# Result: \"42-feature/add-dark-mode-support\"\n\n# Create and checkout branch\ngit checkout -b \"$BRANCH_NAME\"\n\n# Push to remote with tracking\ngit push -u origin \"$BRANCH_NAME\"\n```\n\n**Utilities:**\n- `generateBranchName(issueNumber, workType, title)` - Generate formatted name\n- `toKebabCase(title)` - Convert title to kebab-case (max 40 chars)\n- `validateBranchName(branchName)` - Check naming conventions\n\n### Branch Renaming\n\nRename branches with remote sync:\n\n```bash\n# Get current branch\nOLD_BRANCH=$(git rev-parse --abbrev-ref HEAD)\n\n# Generate new name\nNEW_BRANCH=\"42-feature/add-dark-mode\"\n\n# Rename local branch\ngit branch -m \"$OLD_BRANCH\" \"$NEW_BRANCH\"\n\n# Check if old branch exists on remote\nif git ls-remote --heads origin \"$OLD_BRANCH\" | grep -q \"$OLD_BRANCH\"; then\n  # Push new branch and delete old remote\n  git push -u origin \"$NEW_BRANCH\"\n  git push origin --delete \"$OLD_BRANCH\"\nelse\n  # Just set upstream for new branch\n  git push -u origin \"$NEW_BRANCH\"\nfi\n```\n\n**Utilities:**\n- `parseBranchName(branchName)` - Extract components (issue#, work type, title)\n- `extractIssueNumber(branchName)` - Get issue number from branch name\n\n### Branch Linking\n\nLink branches to GitHub issues:\n\n```bash\n# Add branch reference to issue body\nISSUE_NUM=42\nBRANCH_NAME=\"42-feature/add-dark-mode\"\n\nCURRENT_BODY=$(gh issue view $ISSUE_NUM --json body -q .body)\nUPDATED_BODY=\"$CURRENT_BODY\n\n---\n\n**Branch:** \\`$BRANCH_NAME\\`\"\n\necho \"$UPDATED_BODY\" | gh issue edit $ISSUE_NUM --body-file -\n\n# Save to state file\nSTATE_FILE=\".claude/logs/branch-issues.json\"\njq --arg branch \"$BRANCH_NAME\" --arg issue \"$ISSUE_NUM\" \\\n  '.[$branch] = {issueNumber: ($issue | tonumber)}' \\\n  \"$STATE_FILE\" > tmp.json && mv tmp.json \"$STATE_FILE\"\n```\n\n**State File:**\n- `.claude/logs/branch-issues.json` - Maps branch names to issue numbers\n\n### Branch Cleanup\n\nClean up merged or stale branches:\n\n```bash\n# Delete merged local branches\ngit branch --merged main | grep -v \"^\\*\\|main\\|master\" | xargs -n 1 git branch -d\n\n# Delete merged remote branches\ngh pr list --state merged --json headRefName -q '.[].headRefName' | \\\n  xargs -I {} git push origin --delete {}\n\n# Delete stale branches (no commits in 30 days)\ngit for-each-ref --sort=-committerdate refs/heads/ \\\n  --format='%(refname:short) %(committerdate:relative)' | \\\n  awk '$2 ~ /months/ && $3 >= 1 {print $1}' | \\\n  xargs -n 1 git branch -D\n```\n\n### Work Type Detection\n\nAutomatically detect work type from context:\n\n```typescript\nimport { detectWorkType } from '../shared/hooks/utils/work-type-detector.js';\n\n// From prompt\nconst workType = detectWorkType('fix the authentication bug');\n// Returns: 'fix'\n\n// From issue labels\nconst workType = detectWorkType(\n  'Update authentication system',\n  ['bug', 'priority:high']\n);\n// Returns: 'fix' (detected from 'bug' label)\n```\n\n**Work Types:**\n- `feature` - New functionality\n- `fix` - Bug fixes\n- `chore` - Maintenance tasks\n- `docs` - Documentation\n- `refactor` - Code improvements\n\n## Integration with Hooks\n\nThis skill complements the automatic hooks:\n\n| Hook | Automatic Behavior | When to Use Skill |\n|------|-------------------|------------------|\n| create-issue-on-prompt | Renames branch after issue creation | Rename before issue creation, custom naming |\n| add-github-context | Discovers issue from branch name | Manual branch-issue linking |\n\n**State Files:**\n- `.claude/logs/branch-issues.json` - Branch → Issue mapping\n\n## Naming Utilities\n\n### generateBranchName\n\n```typescript\ngenerateBranchName(issueNumber: number, workType: WorkType, title: string): string\n```\n\nGenerates formatted branch name.\n\n**Example:**\n```typescript\ngenerateBranchName(42, 'feature', 'Add Dark Mode')\n// Returns: \"42-feature/add-dark-mode\"\n```\n\n### parseBranchName\n\n```typescript\nparseBranchName(branchName: string): ParsedBranchName\n```\n\nParses branch name into components.\n\n**Example:**\n```typescript\nparseBranchName('42-feature/add-dark-mode')\n// Returns: { issueNumber: 42, workType: 'feature', title: 'add-dark-mode' }\n\nparseBranchName('123-fix-auth-bug')\n// Returns: { issueNumber: 123, title: 'fix-auth-bug' }\n```\n\n### validateBranchName\n\n```typescript\nvalidateBranchName(branchName: string): BranchValidation\n```\n\nValidates branch name against conventions.\n\n**Example:**\n```typescript\nvalidateBranchName('42-feature/add-dark-mode')\n// Returns: { valid: true }\n\nvalidateBranchName('invalid name with spaces')\n// Returns: { valid: false, reason: 'Branch name cannot contain spaces' }\n```\n\n### extractIssueNumber\n\n```typescript\nextractIssueNumber(branchName: string): number | null\n```\n\nExtracts issue number from branch name.\n\n**Example:**\n```typescript\nextractIssueNumber('42-feature/add-dark-mode')\n// Returns: 42\n\nextractIssueNumber('main')\n// Returns: null\n```\n\n## Examples\n\n### Example 1: Create Branch for Issue\n\n```bash\n# Get issue details\nISSUE_NUM=42\nISSUE_DATA=$(gh issue view $ISSUE_NUM --json title,labels)\nTITLE=$(echo \"$ISSUE_DATA\" | jq -r '.title')\nLABELS=$(echo \"$ISSUE_DATA\" | jq -r '.labels[].name' | tr '\\n' ',')\n\n# Detect work type\nWORK_TYPE=$(detectWorkType \"$TITLE\" \"$LABELS\")\n# Returns: 'feature' or 'fix' or 'chore', etc.\n\n# Generate branch name\nBRANCH_NAME=$(generateBranchName $ISSUE_NUM \"$WORK_TYPE\" \"$TITLE\")\n# Returns: \"42-feature/add-dark-mode-support\"\n\n# Create and checkout\ngit checkout -b \"$BRANCH_NAME\"\ngit push -u origin \"$BRANCH_NAME\"\n\n# Link to issue\necho \"Branch \\`$BRANCH_NAME\\` created\" | gh issue comment $ISSUE_NUM --body-file -\n```\n\n### Example 2: Rename Branch to Convention\n\n```bash\n# Current branch doesn't follow convention\nCURRENT=$(git rev-parse --abbrev-ref HEAD)\n# e.g., \"claude-agile-narwhal-x7h3k\"\n\n# Get linked issue (if exists)\nISSUE_NUM=$(parseIssueFromBranch \"$CURRENT\")\n\nif [ -z \"$ISSUE_NUM\" ]; then\n  echo \"No issue linked to this branch\"\n  exit 1\nfi\n\n# Get issue details\nISSUE_DATA=$(gh issue view $ISSUE_NUM --json title,labels)\nTITLE=$(echo \"$ISSUE_DATA\" | jq -r '.title')\nLABELS=$(echo \"$ISSUE_DATA\" | jq -r '.labels[].name' | tr '\\n' ',')\n\n# Generate new name\nWORK_TYPE=$(detectWorkType \"$TITLE\" \"$LABELS\")\nNEW_BRANCH=$(generateBranchName $ISSUE_NUM \"$WORK_TYPE\" \"$TITLE\")\n\n# Rename with remote sync\ngit branch -m \"$CURRENT\" \"$NEW_BRANCH\"\ngit push -u origin \"$NEW_BRANCH\"\ngit push origin --delete \"$CURRENT\" 2>/dev/null || true\n```\n\n### Example 3: Validate Branch Names in CI\n\n```bash\n# Get current branch\nBRANCH=$(git rev-parse --abbrev-ref HEAD)\n\n# Skip validation for protected branches\nif [[ \"$BRANCH\" =~ ^(main|master|develop)$ ]]; then\n  exit 0\nfi\n\n# Validate format\nif ! validateBranchName \"$BRANCH\"; then\n  echo \"❌ Branch name '$BRANCH' doesn't follow convention: {issueNum}-{workType}/{kebab-name}\"\n  echo \"Examples: 42-feature/add-dark-mode, 123-fix/safari-bug\"\n  exit 1\nfi\n\n# Check if issue exists\nISSUE_NUM=$(extractIssueNumber \"$BRANCH\")\nif [ -n \"$ISSUE_NUM\" ]; then\n  if ! gh issue view $ISSUE_NUM &>/dev/null; then\n    echo \"⚠️  Issue #$ISSUE_NUM referenced in branch name doesn't exist\"\n  fi\nfi\n```\n\n### Example 4: Bulk Branch Cleanup\n\n```bash\n# Get all merged branches\nMERGED=$(git branch --merged main | grep -v \"^\\*\\|main\\|master\")\n\nfor branch in $MERGED; do\n  # Parse branch name\n  PARSED=$(parseBranchName \"$branch\")\n  ISSUE_NUM=$(echo \"$PARSED\" | jq -r '.issueNumber // empty')\n\n  # Check if issue is closed\n  if [ -n \"$ISSUE_NUM\" ]; then\n    STATE=$(gh issue view $ISSUE_NUM --json state -q .state 2>/dev/null || echo \"\")\n    if [ \"$STATE\" = \"CLOSED\" ]; then\n      echo \"Deleting merged branch: $branch (issue #$ISSUE_NUM closed)\"\n      git branch -d \"$branch\"\n      git push origin --delete \"$branch\" 2>/dev/null || true\n    fi\n  else\n    echo \"Deleting merged branch: $branch (no linked issue)\"\n    git branch -d \"$branch\"\n  fi\ndone\n```\n\n### Example 5: Create Stacked Branches\n\n```bash\n# Create base feature branch\nBASE_ISSUE=42\nBASE_BRANCH=$(generateBranchName $BASE_ISSUE \"feature\" \"Authentication System\")\ngit checkout -b \"$BASE_BRANCH\"\n\n# Create child branches for subissues\nSUBISSUES=(43 44 45)\nSUBTITLES=(\"OAuth Integration\" \"Email Auth\" \"Password Reset\")\n\nfor i in \"${!SUBISSUES[@]}\"; do\n  ISSUE_NUM=${SUBISSUES[$i]}\n  TITLE=${SUBTITLES[$i]}\n\n  # Create branch from base\n  CHILD_BRANCH=$(generateBranchName $ISSUE_NUM \"feature\" \"$TITLE\")\n  git checkout -b \"$CHILD_BRANCH\" \"$BASE_BRANCH\"\n  git push -u origin \"$CHILD_BRANCH\"\n\n  echo \"Created stacked branch: $CHILD_BRANCH (base: $BASE_BRANCH)\"\ndone\n```\n\n## Best Practices\n\n1. **Follow naming convention** - Always use `{issueNum}-{workType}/{kebab-name}`\n2. **Link to issues** - Create branches from issue numbers when possible\n3. **Validate before push** - Use `validateBranchName()` to check format\n4. **Clean up regularly** - Delete merged and stale branches\n5. **Update state files** - Keep `.claude/logs/branch-issues.json` synced\n6. **Use work type detection** - Automatically categorize with `detectWorkType()`\n7. **Sync with remote** - Always use `-u` flag when pushing new branches\n\n## Common Patterns\n\n### Pattern: Create Branch from Current Issue\n\n```bash\n# Auto-detect issue from current context\nISSUE_NUM=$(cat .claude/logs/branch-issues.json | jq -r '.[] | .issueNumber' | head -1)\n\nif [ -n \"$ISSUE_NUM\" ]; then\n  ISSUE_DATA=$(gh issue view $ISSUE_NUM --json title,labels)\n  TITLE=$(echo \"$ISSUE_DATA\" | jq -r '.title')\n  WORK_TYPE=$(detectWorkType \"$TITLE\")\n  BRANCH_NAME=$(generateBranchName $ISSUE_NUM \"$WORK_TYPE\" \"$TITLE\")\n\n  git checkout -b \"$BRANCH_NAME\"\n  git push -u origin \"$BRANCH_NAME\"\nfi\n```\n\n### Pattern: Switch Branch by Issue Number\n\n```bash\n# Switch to branch for issue #42\nISSUE_NUM=42\nBRANCH=$(git branch -a | grep -E \"^[ *]*$ISSUE_NUM-\" | sed 's/^[ *]*//' | head -1)\n\nif [ -n \"$BRANCH\" ]; then\n  git checkout \"$BRANCH\"\nelse\n  echo \"No branch found for issue #$ISSUE_NUM\"\nfi\n```\n\n### Pattern: List Branches by Work Type\n\n```bash\n# List all feature branches\ngit branch | grep -E \"feature/\" | sed 's/^[ *]*//'\n\n# List all fix branches\ngit branch | grep -E \"fix/\" | sed 's/^[ *]*//'\n```\n",
        "plugins/github-orchestration/skills/ci-orchestration/SKILL.md": "---\nname: CI Orchestration\ndescription: Use this skill when the user wants to \"check CI\", \"wait for CI\", \"CI status\", \"retry failed checks\", \"cancel CI\", \"debug CI failure\", or manage CI/CD workflows. Provides comprehensive CI checking with fail-fast patterns and preview URL extraction.\nversion: 0.1.0\n---\n\n# CI Orchestration\n\nComprehensive CI/CD workflow management with fail-fast error detection and preview URL extraction.\n\n## Purpose\n\nCI Orchestration provides explicit control over GitHub Actions and other CI systems. Monitor check status, extract preview URLs, debug failures, and manage workflow retries with intelligent fail-fast patterns.\n\n## When to Use\n\n- Waiting for CI checks with real-time status\n- Extracting preview deployment URLs (Vercel, Netlify)\n- Debugging CI failures\n- Retrying failed workflows\n- Managing CI in complex workflows\n\n## Core Capabilities\n\n### Check CI Status\n\n```bash\n# Check PR status\ngh pr checks 42\n\n# Watch and wait\ngh pr checks 42 --watch\n\n# Get JSON output\ngh pr view 42 --json statusCheckRollup\n```\n\n### Extract Preview URLs\n\nThe existing `ci-status.ts` utility provides comprehensive preview URL extraction:\n\n```typescript\nimport { extractPreviewUrls } from '../shared/hooks/utils/ci-status.js';\n\n// Extract from CI output\nconst urls = extractPreviewUrls(ciOutput);\n// Returns: { web: 'https://...', marketing: 'https://...' }\n```\n\n### Fail-Fast Patterns\n\n```bash\n# Wait with fail-fast\nawaitCIWithFailFast \"$PWD\" 42 10  # 10 minute timeout\n\n# Detects:\n# - Merge conflicts\n# - Branch divergence\n# - Failed checks\n# - Workflow errors\n```\n\n### Retry Failed Checks\n\n```bash\n# Get latest workflow run\nRUN_ID=$(gh run list --branch $(git branch --show-current) --limit 1 --json databaseId -q '.[0].databaseId')\n\n# Re-run failed jobs\ngh run rerun $RUN_ID --failed\n```\n\n## Integration with Hooks\n\n| Hook | Behavior |\n|------|----------|\n| await-pr-status | Waits for CI after `gh pr create` |\n| commit-task-await-ci-status | Auto-commits and checks CI on SubagentStop |\n| commit-session-await-ci-status | Blocking CI check on Stop |\n\n## Utilities\n\nFrom `ci-status.ts`:\n- `awaitCIWithFailFast(cwd, prNumber, timeout)` - Wait with fail-fast\n- `extractPreviewUrls(output)` - Parse Vercel/Netlify URLs\n- `getLatestCIRun(cwd, branch)` - Get workflow run ID\n- `formatCiChecksTable(checks)` - Format as markdown table\n\n## Examples\n\n### Wait for CI with Preview URLs\n\n```bash\n# Create PR\nPR=$(gh pr create --title \"Add feature\" --body \"...\" --json number -q .number)\n\n# Wait for CI\nawaitCIWithFailFast \"$PWD\" $PR 10\n\n# Extract preview URLs\nCHECKS=$(gh pr view $PR --json statusCheckRollup -q '.statusCheckRollup')\nPREVIEW=$(extractPreviewUrls \"$CHECKS\")\n\necho \"Preview: $PREVIEW\"\n```\n\n### Debug Failed CI\n\n```bash\n# Get failed checks\ngh pr checks 42 --json name,conclusion,detailsUrl \\\n  --jq '.[] | select(.conclusion==\"FAILURE\") | {name, url: .detailsUrl}'\n\n# View logs\ngh run view $(gh run list --limit 1 --json databaseId -q '.[0].databaseId') --log-failed\n```\n\n### Retry with Backoff\n\n```bash\nMAX_RETRIES=3\nRETRY=0\n\nwhile [ $RETRY -lt $MAX_RETRIES ]; do\n  if gh pr checks $PR --watch; then\n    echo \"✓ CI passed\"\n    break\n  fi\n\n  RETRY=$((RETRY + 1))\n  if [ $RETRY -lt $MAX_RETRIES ]; then\n    echo \"Retry $RETRY/$MAX_RETRIES...\"\n    gh run rerun $(gh run list --limit 1 --json databaseId -q '.[0].databaseId') --failed\n  fi\ndone\n```\n\n## Best Practices\n\n1. Use fail-fast patterns (10min timeout)\n2. Extract and share preview URLs\n3. Auto-retry transient failures (max 3 times)\n4. Parse logs for actionable errors\n5. Update PR comments with CI status\n",
        "plugins/github-orchestration/skills/issue-management/SKILL.md": "---\nname: Issue Management\ndescription: Use this skill when the user wants to \"create issue\", \"update issue\", \"add labels\", \"assign issue\", \"close issue\", \"link issues\", or manage GitHub issue metadata. Provides comprehensive GitHub issue CRUD operations with intelligent context awareness.\nversion: 0.1.0\n---\n\n# Issue Management\n\nComprehensive GitHub issue lifecycle management with templates, metadata, and intelligent context detection.\n\n## Purpose\n\nIssue Management provides explicit control over GitHub issue operations. While hooks automatically create issues on first prompt, this skill allows users to directly manage issue creation, updates, labeling, assignment, and linking with full control over templates and metadata.\n\n## When to Use\n\n- Creating issues with specific templates (bug/feature/epic/task)\n- Updating existing issue metadata (labels, assignees, milestones)\n- Linking issues as parent-child or related\n- Searching and filtering issues\n- When hooks don't fit the workflow (e.g., creating multiple issues at once)\n\n## Core Capabilities\n\n### Issue Creation\n\nCreate issues using structured templates:\n\n```bash\n# Bug report with template\ngh issue create --title \"Auth fails on Safari\" --body \"$(cat <<'EOF'\n## Bug Description\n\nAuthentication fails silently on Safari 17.2\n\n## Steps to Reproduce\n\n1. Open Safari 17.2\n2. Navigate to /login\n3. Enter credentials\n4. Click Sign In\n\n## Expected Behavior\n\nUser should be redirected to dashboard\n\n## Actual Behavior\n\nPage reloads with no error message\n\n## Environment\n\n- OS: macOS 14.2\n- Browser: Safari 17.2\n- Version: v1.5.0\nEOF\n)\"\n```\n\n**Available Templates:**\n- `getBugTemplate()` - Bug report with repro steps\n- `getFeatureTemplate()` - Feature request with problem statement\n- `getEpicTemplate()` - Epic with subtasks checklist\n- `getTaskTemplate()` - Simple task with acceptance criteria\n\n**Utilities:**\n- `renderTemplate(template, vars)` - Substitute {{varName}} placeholders\n- `getMinimalIssueBody(description, context?)` - Basic issue without template\n- `createSubissueBody(parentNumber, description)` - Issue with parent reference\n\n### Issue Updates\n\nUpdate issue metadata after creation:\n\n```bash\n# Add labels\ngh issue edit 42 --add-label \"bug,priority:high\"\n\n# Assign users\ngh issue edit 42 --add-assignee @me,@username\n\n# Update milestone\ngh issue edit 42 --milestone \"v2.0\"\n\n# Update body\ngh issue edit 42 --body-file updated-description.md\n```\n\n### Issue Linking\n\nLink issues with parent-child or related relationships:\n\n```bash\n# Parent-child (in subissue body)\n**Parent Issue:** #42\n\nThis subissue implements the authentication flow from the parent epic.\n\n# Related issues (in body)\n**Related Issues:** #40, #41, #43\n\n# Closes references (auto-links on merge)\nCloses #42\nFixes #43\n```\n\n**Utilities:**\n- `addBranchReference(issueBody, branchName)` - Add branch marker to issue\n\n### Issue Search\n\nFind issues with advanced queries:\n\n```bash\n# Search by label\ngh issue list --label \"bug\"\n\n# Search by state and assignee\ngh issue list --state open --assignee @me\n\n# Search with text query\ngh issue list --search \"authentication in:title,body\"\n\n# Search by milestone\ngh issue list --milestone \"v2.0\"\n\n# Complex search\ngh issue list --search \"is:open label:bug author:@me created:>2024-01-01\"\n```\n\n### Context Detection\n\nThe skill automatically detects context from:\n\n1. **Branch names** - Extracts issue number from `42-feature/name` format\n2. **State files** - Checks `.claude/logs/branch-issues.json` for linked issues\n3. **Work type** - Detects from prompt using `detectWorkType()` for auto-labeling\n4. **Session context** - Uses current session info for metadata\n\n## Integration with Hooks\n\nThis skill complements the automatic hooks:\n\n| Hook | Automatic Behavior | When to Use Skill |\n|------|-------------------|------------------|\n| create-issue-on-prompt | Creates issue on first prompt | Create multiple issues, use specific templates |\n| sync-plan-to-issue | Syncs plan files to issues | Manually update issue from plan changes |\n| sync-task-to-subissue | Creates subissues from Task prompts | Bulk create subissues, custom subissue structure |\n\n**State Files:**\n- `.claude/logs/plan-issues.json` - Plan → Issue mapping\n- `.claude/logs/branch-issues.json` - Branch → Issue mapping\n- `.claude/logs/task-subissues.json` - Task → Subissue mapping\n\n## Work Type Detection\n\nAutomatically categorize issues:\n\n```typescript\nimport { detectWorkType, formatWorkTypeLabel } from '../shared/hooks/utils/work-type-detector.js';\n\nconst workType = detectWorkType('fix the authentication bug');\n// Returns: 'fix'\n\nconst label = formatWorkTypeLabel(workType);\n// Returns: 'Bug Fix'\n```\n\n**Patterns:**\n- **fix** - bug, error, broken, crash, fail\n- **feature** - add, create, implement, build, new\n- **docs** - document, readme, comment, explain\n- **refactor** - clean, improve, optimize, restructure\n- **chore** - maintain, update, upgrade, config\n\n## Examples\n\n### Example 1: Create Bug with Template\n\n```bash\n# Use getBugTemplate() and renderTemplate()\nTEMPLATE=$(cat <<'EOF'\n## Bug Description\n\n{{description}}\n\n## Steps to Reproduce\n\n1. {{step1}}\n2. {{step2}}\n3. {{step3}}\n\n## Expected Behavior\n\n{{expected}}\n\n## Actual Behavior\n\n{{actual}}\n\n## Environment\n\n- OS: {{os}}\n- Browser: {{browser}}\n- Version: {{version}}\nEOF\n)\n\n# Substitute variables and create issue\ngh issue create \\\n  --title \"Safari auth failure\" \\\n  --label \"bug,priority:high\" \\\n  --body \"$TEMPLATE\" # (after variable substitution)\n```\n\n### Example 2: Create Epic with Subissues\n\n```bash\n# Create parent epic\nPARENT=$(gh issue create \\\n  --title \"Implement authentication system\" \\\n  --label \"epic\" \\\n  --body \"$(cat <<'EOF'\n## Epic Overview\n\nBuild complete authentication system with OAuth and email/password support.\n\n## Goals\n\n- OAuth integration (Google, GitHub)\n- Email/password authentication\n- Password reset flow\n- Session management\n\n## Success Criteria\n\n- All auth flows tested\n- Security audit passed\n- Documentation complete\n\n## Subtasks\n\n- [ ] #43 OAuth integration\n- [ ] #44 Email/password auth\n- [ ] #45 Password reset\n- [ ] #46 Session management\nEOF\n)\" \\\n  --json number -q .number)\n\n# Create subissues with parent reference\nfor task in \"OAuth integration\" \"Email/password auth\" \"Password reset\" \"Session management\"; do\n  gh issue create \\\n    --title \"$task\" \\\n    --label \"task\" \\\n    --body \"**Parent Issue:** #$PARENT\n\n$task for authentication system\"\ndone\n```\n\n### Example 3: Update Issue Labels Based on Work Type\n\n```bash\n# Detect work type from title\nTITLE=\"Fix authentication bug in Safari\"\nWORK_TYPE=\"fix\"  # Detected by detectWorkType()\n\n# Add appropriate labels\ngh issue edit 42 --add-label \"bug,browser:safari,priority:high\"\n```\n\n### Example 4: Link Issue to Branch\n\n```bash\n# Add branch reference to issue body\nCURRENT_BODY=$(gh issue view 42 --json body -q .body)\nUPDATED_BODY=\"$CURRENT_BODY\n\n---\n\n**Branch:** \\`42-fix/safari-auth-bug\\`\"\n\necho \"$UPDATED_BODY\" | gh issue edit 42 --body-file -\n```\n\n### Example 5: Bulk Issue Creation\n\n```bash\n# Create multiple related issues\nISSUES=(\n  \"Implement login form:feature\"\n  \"Add form validation:chore\"\n  \"Create auth API endpoints:feature\"\n  \"Write authentication tests:chore\"\n)\n\nfor item in \"${ISSUES[@]}\"; do\n  TITLE=\"${item%:*}\"\n  TYPE=\"${item#*:}\"\n  LABEL=$(echo \"$TYPE\" | sed 's/feature/enhancement/;s/fix/bug/')\n\n  gh issue create --title \"$TITLE\" --label \"$LABEL\" --body \"Task for authentication epic\"\ndone\n```\n\n## Best Practices\n\n1. **Use templates** - Structured issues are easier to understand and track\n2. **Detect work type** - Automatically label issues based on content\n3. **Link issues** - Use parent-child and related issue references\n4. **Update state files** - Keep `.claude/logs/` files synced when creating issues manually\n5. **Check existing issues** - Search before creating to avoid duplicates\n6. **Use consistent labels** - Follow project's labeling conventions\n7. **Add context** - Include branch names, related PRs, and file references\n\n## Utilities Reference\n\n### Templates\n- `getBugTemplate()` - Bug report template\n- `getFeatureTemplate()` - Feature request template\n- `getEpicTemplate(subissues?)` - Epic with optional subtasks\n- `getTaskTemplate()` - Simple task template\n- `renderTemplate(template, vars)` - Substitute variables\n- `getMinimalIssueBody(description, context?)` - Basic body\n- `createSubissueBody(parentNumber, description)` - Subissue with parent link\n- `addBranchReference(body, branchName)` - Add branch marker\n\n### Work Type\n- `detectWorkType(prompt, issueLabels?)` - Detect work type from text\n- `formatWorkTypeLabel(workType)` - Format as human-readable label\n\n### State Files\n- `.claude/logs/plan-issues.json` - Plan → Issue mapping\n- `.claude/logs/branch-issues.json` - Branch → Issue mapping\n- `.claude/logs/task-subissues.json` - Task → Subissue mapping\n\n## Common Patterns\n\n### Pattern: Create Issue from Plan\n\n```bash\n# Read plan file\nPLAN_CONTENT=$(cat .claude/plans/feature-auth.md)\n\n# Extract title from first heading\nTITLE=$(echo \"$PLAN_CONTENT\" | grep -m1 \"^# \" | sed 's/^# //')\n\n# Create issue with plan content\nISSUE_NUM=$(gh issue create \\\n  --title \"$TITLE\" \\\n  --label \"planned\" \\\n  --body \"$PLAN_CONTENT\" \\\n  --json number -q .number)\n\n# Save to state file\necho \"{\\\"feature-auth\\\": {\\\"issueNumber\\\": $ISSUE_NUM}}\" > .claude/logs/plan-issues.json\n```\n\n### Pattern: Sync Issue with Current Work\n\n```bash\n# Get current branch\nBRANCH=$(git rev-parse --abbrev-ref HEAD)\n\n# Extract issue number\nISSUE_NUM=$(echo \"$BRANCH\" | grep -oE '^[0-9]+')\n\nif [ -n \"$ISSUE_NUM\" ]; then\n  # Update issue with progress\n  gh issue comment $ISSUE_NUM --body \"🚧 Currently working on this in branch \\`$BRANCH\\`\"\nfi\n```\n\n### Pattern: Close Related Issues\n\n```bash\n# Close all issues in epic when epic closes\nPARENT=42\nSUBISSUES=$(gh issue list --search \"in:body \\\"Parent Issue: #$PARENT\\\"\" --json number -q '.[].number')\n\nfor subissue in $SUBISSUES; do\n  gh issue close $subissue --comment \"Closing as part of completed epic #$PARENT\"\ndone\n```\n",
        "plugins/github-orchestration/skills/pr-workflow/SKILL.md": "---\nname: PR Workflow\ndescription: Use this skill when the user wants to \"create PR\", \"update PR\", \"merge PR\", \"PR template\", \"auto-fill PR\", \"request review\", or manage pull request lifecycle. Generates PR descriptions from commits/issues with intelligent defaults.\nversion: 0.1.0\n---\n\n# PR Workflow\n\nComplete PR lifecycle management with auto-generated descriptions from commits and issues.\n\n## Purpose\n\nPR Workflow provides systematic pull request management with intelligent description generation, template selection based on work type, and automated review requests.\n\n## When to Use\n\n- Creating PRs with auto-generated descriptions\n- Using templates based on work type (feature/fix/chore/docs/refactor)\n- Updating PR metadata (reviewers, labels, milestones)\n- Managing PR lifecycle (draft → ready → merge)\n\n## Core Capabilities\n\n### PR Creation with Auto-Description\n\n```bash\n# Get commits since base branch\nCOMMITS=$(git log main..HEAD --oneline --no-decorate)\n\n# Get linked issue\nBRANCH=$(git branch --show-current)\nISSUE=$(extractIssueNumber \"$BRANCH\")\n\n# Generate description\nDESC=$(generatePRDescription \"$COMMITS\" \"$ISSUE\")\n\n# Create PR\ngh pr create --title \"Add authentication system\" --body \"$DESC\"\n```\n\n**Utilities:**\n- `generatePRDescription(commits, linkedIssue?)` - Auto-generate from commits\n- `getPRTemplateByWorkType(workType)` - Get template by type\n- `renderPRTemplate(template, vars)` - Substitute variables\n- `groupCommitsByType(commits)` - Group by conventional commit types\n- `formatGroupedCommits(grouped)` - Format as sections\n\n### Template Selection\n\nTemplates automatically adapt to work type:\n\n**Feature PR:**\n```markdown\n## Summary\nBrief overview\n\n## Changes\n- Change 1\n- Change 2\n\n## Testing\n- [ ] Unit tests\n- [ ] Integration tests\n\n## Related Issues\nCloses #42\n```\n\n**Bug Fix PR:**\n```markdown\n## Bug Fix\nBrief description\n\n## Root Cause\nWhat caused it\n\n## Solution\nHow we fixed it\n\n## Testing\n- [ ] Bug reproduced before fix\n- [ ] Bug resolved after fix\n```\n\n### Review Requests\n\n```bash\n# Auto-request reviewers from CODEOWNERS\nOWNERS=$(grep \"^$(dirname $FILE)\" .github/CODEOWNERS | awk '{print $2}')\n\ngh pr edit $PR --add-reviewer \"$OWNERS\"\n\n# Or manually\ngh pr edit $PR --add-reviewer @user1,@user2\n```\n\n### PR Updates\n\n```bash\n# Update labels\ngh pr edit 42 --add-label \"enhancement,priority:high\"\n\n# Update milestone\ngh pr edit 42 --milestone \"v2.0\"\n\n# Convert to draft\ngh pr ready --undo 42\n\n# Mark ready for review\ngh pr ready 42\n```\n\n## Templates\n\n- `getFeaturePRTemplate()` - New features\n- `getBugfixPRTemplate()` - Bug fixes\n- `getChorePRTemplate()` - Maintenance\n- `getDocsPRTemplate()` - Documentation\n- `getRefactorPRTemplate()` - Code improvements\n\nAll templates include:\n- Summary section\n- Change list\n- Testing checklist\n- Related issues\n- Claude Code footer\n\n## Examples\n\n### Create PR with Grouped Commits\n\n```bash\n# Get commits\nCOMMITS=$(git log main..HEAD --pretty=format:\"%s\")\n\n# Group by type\nGROUPED=$(groupCommitsByType \"$COMMITS\")\n# Returns: { feat: [...], fix: [...], docs: [...] }\n\n# Format as sections\nBODY=$(formatGroupedCommits \"$GROUPED\")\n\n# Add issue reference\nISSUE=$(extractIssueNumber \"$(git branch --show-current)\")\nBODY=\"$BODY\n\n## Related Issues\n\nCloses #$ISSUE\"\n\n# Create PR\ngh pr create --title \"Authentication system\" --body \"$BODY\"\n```\n\n### Auto-Merge When CI Passes\n\n```bash\n# Create PR and enable auto-merge\nPR=$(gh pr create --title \"...\" --body \"...\" --json number -q .number)\n\n# Enable auto-merge (squash)\ngh pr merge $PR --auto --squash --delete-branch\n\n# CI will auto-merge when checks pass\n```\n\n### Request Reviews from CODEOWNERS\n\n```bash\n# Parse CODEOWNERS for file\nFILE=\"src/auth/login.ts\"\nPATTERN=$(grep -E \"^[^#].*$(dirname $FILE)\" .github/CODEOWNERS | head -1)\nREVIEWERS=$(echo \"$PATTERN\" | awk '{for(i=2;i<=NF;i++) print $i}' | tr '\\n' ',' | sed 's/,$//')\n\n# Request review\ngh pr edit $PR --add-reviewer \"$REVIEWERS\"\n```\n\n## Best Practices\n\n1. Auto-generate descriptions from commits\n2. Use conventional commits for grouping (feat:, fix:, etc.)\n3. Link to issues with \"Closes #N\"\n4. Request reviews from CODEOWNERS\n5. Use templates matching work type\n6. Enable auto-merge for simple PRs\n7. Add preview URLs to description\n",
        "plugins/github-orchestration/skills/stacked-pr-management/SKILL.md": "---\nname: Stacked PR Management\ndescription: Use this skill when the user wants to \"create stacked PR\", \"stack PRs\", \"dependent PR\", \"rebase stack\", \"merge stack\", or manage PR dependencies. Handles stacked PR workflows for large features split across multiple dependent pull requests.\nversion: 0.1.0\n---\n\n# Stacked PR Management\n\nManage dependent PR workflows (stacked PRs) for large features requiring multiple review iterations.\n\n## Purpose\n\nStacked PR Management enables creating chains of dependent PRs where each PR builds on the previous one. Useful for large features that need incremental review or when working on multiple related changes simultaneously.\n\n## When to Use\n\n- Breaking large features into reviewable chunks\n- Working on dependent changes in parallel\n- Iterating on features while earlier PRs are in review\n- Maintaining clean commit history across multiple PRs\n\n## Core Capabilities\n\n### Stack Creation\n\n```bash\n# Create PR chain\nBASE=\"main\"\nBRANCHES=(\"42-feature/base\" \"43-feature/middleware\" \"44-feature/ui\")\n\nfor i in \"${!BRANCHES[@]}\"; do\n  BRANCH=\"${BRANCHES[$i]}\"\n  NEXT_BASE=$([[ $i -eq 0 ]] && echo \"$BASE\" || echo \"${BRANCHES[$i-1]}\")\n\n  # Create PR with base as previous branch\n  PR_NUM=$(gh pr create \\\n    --base \"$NEXT_BASE\" \\\n    --head \"$BRANCH\" \\\n    --title \"Feature part $((i+1))\" \\\n    --body \"**Stack:** Part $((i+1)) of ${#BRANCHES[@]}\n\n$([ $i -gt 0 ] && echo \"**Base PR:** Search previous PR\")\" \\\n    --json number -q .number)\n\n  # Save to stack\n  addPRToStack \"$PWD\" \"{\\\"pr\\\": $PR_NUM, \\\"branch\\\": \\\"$BRANCH\\\", \\\"base\\\": \\\"$NEXT_BASE\\\", \\\"children\\\": []}\"\ndone\n```\n\n### Stack Visualization\n\n```bash\nvisualizeStack \"$(loadPRStack \"$PWD\")\"\n# Output:\n# main\n# └── #42 feat/base\n#     └── #43 feat/middleware\n#         └── #44 feat/ui\n```\n\n### Stack Rebase\n\n```bash\n# When base PR merges, rebase stack\nBASE_PR=42\nDEPENDENTS=$(findDependentPRs \"$(loadPRStack \"$PWD\")\" $BASE_PR)\n\nfor pr in $DEPENDENTS; do\n  BRANCH=$(gh pr view $pr --json headRefName -q .headRefName)\n  git checkout \"$BRANCH\"\n  git rebase main\n  git push --force-with-lease\ndone\n```\n\n## Utilities\n\n- `savePRStack(cwd, stack)` - Save stack state\n- `loadPRStack(cwd)` - Load stack state\n- `addPRToStack(cwd, node)` - Add PR to stack\n- `removePRFromStack(cwd, prNumber)` - Remove from stack\n- `visualizeStack(stack)` - ASCII tree visualization\n- `validateStackOrder(stack)` - Check for circular dependencies\n- `getMergeOrder(stack)` - Get bottom-up merge order\n- `findDependentPRs(stack, prNumber)` - Find all descendants\n\n## Examples\n\n### Create 3-PR Stack\n\n```bash\n# Feature split across 3 PRs\ngit checkout main\ngit checkout -b 1-feature/database\n# ... make changes ...\ngit push -u origin 1-feature/database\n\ngh pr create --base main --head 1-feature/database --title \"Part 1: Database schema\"\n\ngit checkout -b 2-feature/api 1-feature/database\n# ... make changes ...\ngit push -u origin 2-feature/api\n\ngh pr create --base 1-feature/database --head 2-feature/api --title \"Part 2: API endpoints\"\n\ngit checkout -b 3-feature/ui 2-feature/api\n# ... make changes ...\ngit push -u origin 3-feature/ui\n\ngh pr create --base 2-feature/api --head 3-feature/ui --title \"Part 3: UI components\"\n```\n\n### Merge Stack in Order\n\n```bash\nSTACK=$(loadPRStack \"$PWD\")\nMERGE_ORDER=$(getMergeOrder \"$STACK\")\n\nfor pr in $MERGE_ORDER; do\n  # Wait for CI\n  gh pr checks $pr --watch\n\n  # Merge\n  gh pr merge $pr --squash --delete-branch\n\n  # Update base of dependent PRs\n  DEPENDENTS=$(findDependentPRs \"$STACK\" $pr)\n  for dep in $DEPENDENTS; do\n    gh pr edit $dep --base main\n  done\ndone\n```\n\n## Best Practices\n\n1. Keep PRs small and focused\n2. Update PR descriptions with stack context\n3. Merge bottom-up (base PR first)\n4. Rebase dependent PRs when base changes\n5. Use --force-with-lease, never --force\n6. Validate stack with `validateStackOrder()` before merge\n",
        "plugins/github-orchestration/skills/subissue-orchestration/SKILL.md": "---\nname: Subissue Orchestration\ndescription: Use this skill when the user wants to \"create subissue\", \"break down issue\", \"split into tasks\", \"track subtasks\", or manage hierarchical GitHub issues. Creates subissues with parent linking using GitHub's native sub-issues API (with markdown fallback).\nversion: 0.2.0\n---\n\n# Subissue Orchestration\n\nHierarchical issue management using GitHub's native sub-issues API with automatic PR-subissue coordination.\n\n## Purpose\n\nSubissue Orchestration enables breaking down large epics or features into smaller, trackable tasks. Uses GitHub's native sub-issues API (GA 2025) for proper parent-child relationships that appear in GitHub's UI and Projects, with markdown checklist fallback for compatibility.\n\n## Native Sub-Issues (Primary)\n\nGitHub's native sub-issues provide:\n- Proper parent-child relationships visible in GitHub UI\n- Integration with GitHub Projects (filtering, grouping by parent)\n- Up to 100 sub-issues per parent, 8 levels of nesting\n- Cross-repository support\n\nThe `sync-task-to-subissue` hook automatically links created subissues using the native API.\n\n## When to Use\n\n- Breaking down epics into implementation tasks\n- Creating subtasks from a task list\n- Tracking progress with automated checklists\n- Managing complex feature development with multiple developers\n\n## Core Capabilities\n\n### Native Sub-Issues API\n\n**Utilities from `native-subissues.ts`:**\n- `addNativeSubissue(cwd, parentIssue, subissueNumber)` - Link as native sub-issue\n- `listNativeSubissues(cwd, parentIssue)` - List native sub-issues\n- `removeNativeSubissue(cwd, parentIssue, subissueNumber)` - Unlink sub-issue\n- `getParentIssue(cwd, subissueNumber)` - Get parent of a sub-issue\n- `isNativeSubissuesAvailable(cwd)` - Check if API is available\n\n### Subissue Creation\n\nCreate child issues with native linking:\n\n```bash\nPARENT=42\nTITLE=\"Implement OAuth integration\"\n\n# Create subissue\nSUBISSUE=$(gh issue create \\\n  --title \"$TITLE\" \\\n  --label \"task\" \\\n  --body \"**Parent Issue:** #$PARENT\n\nImplementation details for OAuth integration...\" \\\n  --json number -q .number)\n\n# Link as native sub-issue (preferred)\nSUBISSUE_ID=$(gh api repos/{owner}/{repo}/issues/$SUBISSUE --jq '.id')\ngh api repos/{owner}/{repo}/issues/$PARENT/sub_issues -X POST -f sub_issue_id=$SUBISSUE_ID\n```\n\n### Checklist Management (Fallback)\n\nFor repos without native sub-issues, markdown checklists are still supported.\n\n**Utilities from `subissue-checklist.ts`:**\n- `hasNativeSubissues(cwd, parentIssue)` - Check if native sub-issues exist\n- `generateChecklistMarkdown(subissues)` - Create checklist from array\n- `updateParentIssueChecklist(cwd, parentIssue, subissues)` - Sync checklist\n- `addSubissueToChecklist(cwd, parentIssue, subissue)` - Add single item\n- `markSubissueComplete(cwd, parentIssue, subissueNumber)` - Check off item\n- `syncSubissueStates(cwd, parentIssue, subissueNumbers)` - Sync all states\n\n### Bulk Creation\n\n```bash\n# Create multiple subissues from list\nPARENT=42\nTASKS=(\"OAuth integration\" \"Email auth\" \"Password reset\" \"2FA support\")\n\nfor task in \"${TASKS[@]}\"; do\n  gh issue create \\\n    --title \"$task\" \\\n    --label \"task\" \\\n    --body \"**Parent Issue:** #$PARENT\" \\\n    --json number -q .number\ndone\n\n# Generate and update parent checklist\nsyncSubissueStates \"$PWD\" $PARENT\n```\n\n## Examples\n\n### Create Epic with Subtasks\n\n```bash\n# Create parent epic\nPARENT=$(gh issue create \\\n  --title \"Authentication System\" \\\n  --label \"epic\" \\\n  --body \"## Subtasks\n\n- [ ] Implement OAuth\n- [ ] Implement email auth\n- [ ] Add password reset\n- [ ] Add 2FA support\" \\\n  --json number -q .number)\n\n# Create subissues\nfor task in \"Implement OAuth\" \"Implement email auth\" \"Add password reset\" \"Add 2FA support\"; do\n  gh issue create --title \"$task\" --label \"task\" --body \"**Parent Issue:** #$PARENT\"\ndone\n```\n\n### Auto-Sync Checklist\n\n```bash\n# Mark subissue as complete\ngh issue close 43\n\n# Update parent checklist\nmarkSubissueComplete \"$PWD\" 42 43\n# Changes \"- [ ] #43 OAuth integration\" to \"- [x] #43 OAuth integration\"\n```\n\n## PR-Subissue Coordination\n\nWhen using stacked PRs with subagents, PRs automatically include `Closes #X` to close the associated subissue when merged.\n\n**Workflow:**\n1. Task tool spawns subagent → `sync-task-to-subissue` creates subissue\n2. Subagent makes changes → `stacked-pr-subagent-stop` creates PR\n3. PR body includes `Closes #subissueNumber` (looked up from `task-subissues.json`)\n4. PR merges → GitHub auto-closes the linked subissue\n\nThis provides end-to-end tracking from task → subissue → PR → merge.\n\n## Best Practices\n\n1. Native sub-issues are preferred when available\n2. Link subissues with \"**Parent Issue:** #N\" in body for compatibility\n3. Use consistent labeling (epic → task hierarchy)\n4. Keep subissues focused and atomic\n5. Let stacked PR workflow handle PR-subissue linking automatically\n",
        "plugins/nextjs-supabase-ai-sdk-dev/.claude-plugin/plugin.json": "{\n  \"name\": \"nextjs-supabase-ai-sdk-dev\",\n  \"version\": \"0.1.4\",\n  \"description\": \"Next.js, Supabase, and AI SDK development utilities and hooks\",\n  \"author\": {\n    \"name\": \"constellos\"\n  },\n  \"repository\": \"https://github.com/constellos/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"nextjs\", \"supabase\", \"ai-sdk\", \"development\"],\n  \"mcpServers\": {\n    \"nodes\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"nodes-md@latest\"]\n    },\n    \"ai-elements\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-remote@latest\", \"https://registry.ai-sdk.dev/api/mcp\"]\n    },\n    \"supabase\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-remote@latest\", \"https://mcp.supabase.com/mcp\"]\n    },\n    \"vercel\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-remote@latest\", \"https://mcp.vercel.com\"]\n    }\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/README.md": "![Version](https://img.shields.io/badge/version-0.1.1-blue?style=for-the-badge)\n![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)\n![Next.js](https://img.shields.io/badge/Next.js-15+-black?style=for-the-badge&logo=next.js)\n![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)\n![Vercel](https://img.shields.io/badge/Vercel-000000?style=for-the-badge&logo=vercel)\n\n# Next.js Supabase AI SDK Dev Plugin\n\n> Development tooling for Next.js, Supabase, and Vercel AI SDK projects\n\n## Purpose\n\nProvides CLI installation for Vercel and Supabase on remote environments, task context tracking for subagent workflows, and a systematic UI development system with 5 progressive skills. Includes 4 specialized agents for UI development, review, testing, and research.\n\n## Contents\n\n### Hooks\n\n| Hook | Event | Purpose |\n|------|-------|---------|\n| install-vercel | SessionStart | Installs Vercel CLI on remote |\n| install-start-supabase-next | SessionStart | Sets up Supabase local dev, installs dependencies, starts dev servers (Next.js, Cloudflare, Elysia, Turborepo) with health checks |\n| log-task-call | PreToolUse[Task] | Saves task context |\n| log-task-result | PostToolUse[Task] | Logs task results |\n\n### Agents\n\n| Agent | Purpose |\n|-------|---------|\n| ui-developer | Full UI implementation with all 5 skills |\n| ui-reviewer | Visual inspection and quality review |\n| ui-tester | Mobile (375px) and desktop (1440px) testing |\n| ui-researcher | Screenshot capture and design research |\n\n### Skills\n\n| Skill | Purpose |\n|-------|---------|\n| ui-wireframing | Mobile-first ASCII wireframes |\n| ui-design | Contract-first static UI, compound components |\n| ui-interaction | Client events, local state, Zod validation |\n| ui-integration | Server actions, Supabase, backend |\n| ai-sdk-ui | Vercel AI SDK streaming UI |\n\n### Output Styles\n\n| Style | Purpose |\n|-------|---------|\n| nextjs-lead-dev | Lead developer delegation patterns |\n\n## Installation\n\n```bash\nclaude plugin install nextjs-supabase-ai-sdk-dev@constellos\n```\n\n## License\n\nMIT © constellos\n",
        "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-developer.md": "---\ndescription: Use this agent for full UI implementation including wireframes, components, interactivity, backend integration, and AI features. Triggers on \"build UI\", \"create page\", \"implement feature\", \"develop component\".\nmodel: sonnet\ntools: [Read, Write, Edit, Glob, Grep, Bash, WebFetch, mcp__plugin_nextjs-supabase-ai-sdk-dev_ai-elements__*, mcp__plugin_nextjs-supabase-ai-sdk-dev_shadcn__*, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__*]\nskills: [ui-wireframing, ui-design, ui-interaction, ui-integration, ai-sdk-ui]\ncolor: \"#3B82F6\"\n---\n\n# UI Developer Agent\n\nYou are a senior UI developer specializing in Next.js applications with the full stack: React Server Components, Supabase backend, and Vercel AI SDK. You implement complete UI features following a systematic, progressive workflow.\n\n## Objective\n\nImplement complete UI features by following the progressive skill workflow: wireframing, design, interaction, integration, and AI features. Every UI implementation starts with a wireframe and progresses through each skill in order.\n\n## Core Principles\n\n### Mobile-First Design\n- Always start with the smallest viewport (375px mobile)\n- Design for mobile constraints first, then progressively enhance\n- Breakpoints: Mobile (375px) -> Tablet (768px) -> Desktop (1024px+)\n\n### Server Components Default\n- All components are React Server Components unless they need:\n  - Event handlers (onClick, onChange)\n  - Browser APIs (localStorage, window)\n  - React hooks (useState, useEffect)\n- Keep \"use client\" components minimal and focused\n\n### Contract-First Development\n- Define TypeScript interfaces before implementation\n- Use Zod schemas for validation (shared between client and server)\n- Generate types from Supabase schema\n\n### Progressive Enhancement\n- Start with basic functionality that works without JavaScript\n- Layer interactivity on top with client components\n- Add AI features as the final enhancement layer\n\n## Workflow\n\n### Step 1: Wireframing (ui-wireframing skill)\n**Always start here.** Create WIREFRAME.md files with:\n- Mobile layout (375px) - Primary design target\n- Tablet layout (768px) - Two column layouts\n- Desktop layout (1024px+) - Full multi-column layouts\n- Interaction annotations\n- Data requirements\n\n### Step 2: Static UI Design (ui-design skill)\nAfter wireframe approval:\n- Define TypeScript interfaces (the \"contract\")\n- Implement compound components with Tailwind CSS\n- Use Shadcn UI as the component foundation\n- Create barrel exports in index.ts\n\n### Step 3: Client Interactivity (ui-interaction skill)\nAdd client-side behavior:\n- Add \"use client\" only when needed\n- Implement Zod validation for forms\n- Use React Hook Form for complex forms\n- Add optimistic updates for mutations\n\n### Step 4: Backend Integration (ui-integration skill)\nConnect to Supabase:\n- Create server actions with \"use server\"\n- Implement defense-in-depth (RLS + explicit auth checks)\n- Use generated TypeScript types\n- Revalidate paths after mutations\n\n### Step 5: AI Features (ai-sdk-ui skill)\nAdd AI-powered functionality:\n- Use useChat for conversational interfaces\n- Use useCompletion for single completions\n- Implement streaming UI patterns\n- Add tool calling with visual feedback\n\n## Agent-scoped Project Context\n\n### MCP Tools Available\n\n**AI Elements** (`mcp__plugin_nextjs-supabase-ai-sdk-dev_ai-elements__*`):\n- Get component list and details\n- Access AI-specific UI patterns\n\n**Shadcn** (`mcp__plugin_nextjs-supabase-ai-sdk-dev_shadcn__*`):\n- Search and view components\n- Get installation commands\n- Find usage examples\n\n**Next.js DevTools** (`mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__*`):\n- Live preview with browser_eval\n- Error detection with nextjs_index and nextjs_call\n- Documentation access with nextjs_docs\n\n### Technology Stack\n\n| Layer | Technology |\n|-------|------------|\n| Components | Shadcn, AI Elements, Radix |\n| Styling | Tailwind CSS (mobile-first) |\n| State | Server Components (default), Client when needed |\n| Validation | Zod (client + server) |\n| Backend | Supabase with RLS + explicit auth |\n| AI | Vercel AI SDK (streaming) |\n\n### Key Patterns\n\n**Compound Components:**\n```tsx\n<Card>\n  <CardHeader>\n    <CardTitle>Title</CardTitle>\n  </CardHeader>\n  <CardContent>Content</CardContent>\n</Card>\n```\n\n**Server Action Template:**\n```tsx\n\"use server\";\nconst { data: { user } } = await supabase.auth.getUser();\nif (!user) return { error: \"Unauthorized\" };\n// ... operation\nrevalidatePath(\"/path\");\n```\n\n**Streaming Chat:**\n```tsx\nconst { messages, input, handleInputChange, handleSubmit } = useChat();\n```\n\n## Quality Standards\n\n- All components must have TypeScript interfaces\n- Mobile layout must be usable (not just responsive)\n- Forms require Zod validation\n- Backend operations require auth checks\n- AI features must have loading states\n\n## Output Format\n\nWhen implementing UI features:\n1. Start by creating or reviewing WIREFRAME.md\n2. Implement components following the progressive workflow\n3. Use MCP tools for component discovery and installation\n4. Test with next-devtools browser_eval for visual verification\n5. Document any deviations from the wireframe\n",
        "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-researcher.md": "---\ndescription: Use this agent to research design patterns, capture competitor screenshots, and gather visual inspiration. Triggers on \"research design\", \"capture screenshots\", \"analyze competitor\", \"find UI inspiration\".\nmodel: sonnet\ntools: [Read, Write, WebFetch, Glob, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__browser_eval]\ncolor: \"#F59E0B\"\n---\n\n# UI Researcher Agent\n\nResearch and document visual design patterns by capturing screenshots and analyzing competitor interfaces.\n\n## Objective\n\nGather visual inspiration and document design patterns from reference sites to inform UI development decisions. Create organized reference libraries with detailed analysis.\n\n## Research Workflow\n\n### Step 1: Identify Target Sites/Patterns\n\nDefine research scope:\n- Competitor analysis (direct competitors)\n- Best-in-class examples (industry leaders)\n- Specific pattern research (navigation, forms, dashboards)\n- Style inspiration (color, typography, spacing)\n\n### Step 2: Navigate and Screenshot\n\nUse browser automation to capture references:\n\n```\nbrowser_eval action: start\nbrowser_eval action: navigate, url: \"https://example.com\"\nbrowser_eval action: screenshot, fullPage: true\n```\n\nCapture multiple views:\n- Landing page / hero section\n- Navigation (expanded and collapsed)\n- Key feature sections\n- Footer / secondary navigation\n- Mobile responsive views\n\n### Step 3: Store in Reference Structure\n\nOrganize screenshots in `docs/design/references/`:\n\n```\ndocs/\n└── design/\n    └── references/\n        ├── competitors/\n        │   ├── competitor-a/\n        │   │   ├── homepage.png\n        │   │   ├── navigation.png\n        │   │   └── analysis.md\n        │   └── competitor-b/\n        │       └── ...\n        ├── patterns/\n        │   ├── navigation/\n        │   ├── forms/\n        │   └── dashboards/\n        └── inspiration/\n            ├── color-palettes/\n            └── typography/\n```\n\n### Step 4: Write Analysis\n\nDocument findings in `analysis.md` for each reference:\n\n```markdown\n# [Site Name] Design Analysis\n\n## Overview\nBrief description of the site and why it's relevant.\n\n## Key Design Patterns\n\n### Navigation\n- Pattern description\n- Implementation notes\n- Screenshot: navigation.png\n\n### Color Palette\n- Primary: #XXXXXX\n- Secondary: #XXXXXX\n- Accent: #XXXXXX\n- Background: #XXXXXX\n- Text: #XXXXXX\n\n### Typography\n- Headings: [Font Family], [Weights]\n- Body: [Font Family], [Weights]\n- Scale: [Size progression]\n\n### Spacing System\n- Base unit: Xpx\n- Common values: [4, 8, 16, 24, 32, 48, 64]px\n\n### Component Patterns\n- Cards: Description and notes\n- Buttons: Variants and states\n- Forms: Input styles and validation\n\n## Takeaways\n1. What to adopt\n2. What to avoid\n3. Unique innovations\n```\n\n## Core Principles\n\n### Capture Key UI Patterns\n\nFocus on reusable patterns:\n- Navigation systems (header, sidebar, mobile)\n- Card layouts and grid systems\n- Form designs and validation states\n- Modal and dialog patterns\n- Loading states and skeletons\n- Empty states and error pages\n\n### Document Spacing/Typography/Color\n\nExtract design tokens:\n- **Spacing**: Measure padding, margins, gaps\n- **Typography**: Font families, sizes, weights, line heights\n- **Color**: Primary, secondary, accent, semantic colors\n- **Border radius**: Consistent corner rounding\n- **Shadows**: Elevation levels\n\n### Organize for Reuse\n\nStructure references for easy discovery:\n- Group by category (competitors, patterns, inspiration)\n- Use consistent naming conventions\n- Include source URLs and capture dates\n- Add context with analysis.md files\n\n## Default Research Target\n\nWhen no specific target is provided, use **blackbox.ai** as an example of modern UI design:\n\n```\nbrowser_eval action: navigate, url: \"https://www.blackbox.ai\"\n```\n\nBlackbox.ai demonstrates:\n- Modern dark theme implementation\n- AI-focused interface patterns\n- Clean typography hierarchy\n- Effective use of accent colors\n- Responsive layout patterns\n\n## Agent-Scoped Context\n\n### Storage Locations\n\n| Content Type | Path |\n|--------------|------|\n| Competitor analysis | `docs/design/references/competitors/` |\n| Pattern research | `docs/design/references/patterns/` |\n| Style inspiration | `docs/design/references/inspiration/` |\n| Wireframe references | `docs/design/references/wireframes/` |\n\n### Analysis File Format\n\nEach reference should include an `analysis.md` with:\n\n```yaml\n---\nsource: https://example.com\ncaptured: 2025-01-15\ncategory: competitor | pattern | inspiration\ntags: [navigation, dark-theme, ai-interface]\n---\n```\n\n### Screenshot Naming Convention\n\nUse descriptive names:\n- `homepage-hero.png` - Above the fold hero section\n- `navigation-desktop.png` - Desktop navigation state\n- `navigation-mobile.png` - Mobile hamburger menu\n- `feature-section-1.png` - Feature highlight areas\n- `footer.png` - Footer and secondary nav\n- `mobile-375.png` - Mobile viewport capture\n\n### Color Extraction\n\nWhen documenting colors, include:\n- Hex values (#XXXXXX)\n- Usage context (background, text, accent)\n- Contrast ratios for accessibility\n- CSS variable naming suggestions\n\nExample:\n```css\n--color-background: #0A0A0A;     /* Main background */\n--color-surface: #1A1A1A;        /* Card/panel background */\n--color-border: #2A2A2A;         /* Subtle borders */\n--color-text-primary: #FFFFFF;   /* Main text */\n--color-text-secondary: #A0A0A0; /* Muted text */\n--color-accent: #3B82F6;         /* Primary accent (blue) */\n```\n\n### Typography Documentation\n\nDocument font stacks and scales:\n```css\n/* Font Families */\n--font-sans: \"Inter\", system-ui, sans-serif;\n--font-mono: \"JetBrains Mono\", monospace;\n\n/* Type Scale */\n--text-xs: 0.75rem;    /* 12px */\n--text-sm: 0.875rem;   /* 14px */\n--text-base: 1rem;     /* 16px */\n--text-lg: 1.125rem;   /* 18px */\n--text-xl: 1.25rem;    /* 20px */\n--text-2xl: 1.5rem;    /* 24px */\n--text-3xl: 1.875rem;  /* 30px */\n--text-4xl: 2.25rem;   /* 36px */\n```\n\n## Research Categories\n\n### Competitor Analysis\n\nDirect and indirect competitors:\n- Feature comparison\n- UI/UX strengths and weaknesses\n- Unique differentiators\n- Areas for improvement\n\n### Pattern Library\n\nCommon UI patterns:\n- Authentication flows\n- Onboarding sequences\n- Dashboard layouts\n- Settings pages\n- Profile management\n- Notification systems\n\n### Style Inspiration\n\nVisual design elements:\n- Color schemes and palettes\n- Typography treatments\n- Iconography styles\n- Animation patterns\n- Micro-interactions\n\n## Error Handling\n\nIf screenshot capture fails:\n\n1. Check if the site is accessible\n2. Try WebFetch for HTML content analysis\n3. Document the URL for manual review\n4. Note any blocking (CORS, auth required)\n\n## See Also\n\n- [UI Tester Agent](./ui-tester.md) - Test UI at multiple viewports\n- [UI Design Skill](../skills/ui-design/SKILL.md) - Apply patterns to components\n- [UI Wireframing Skill](../skills/ui-wireframing/SKILL.md) - Create wireframes from research\n",
        "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-reviewer.md": "---\ndescription: Use this agent to review UI implementations for quality, consistency, and best practices. Triggers on \"review UI\", \"check component\", \"inspect design\", \"validate UI quality\".\nmodel: sonnet\ntools: [Read, Glob, Grep, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__browser_eval]\ncolor: \"#8B5CF6\"\n---\n\n# UI Reviewer Agent\n\nYou are a senior UI reviewer specializing in visual quality assurance, accessibility, and best practices for Next.js applications. You inspect UI implementations for quality, consistency, and adherence to design standards.\n\n## Objective\n\nReview UI code and rendered output for quality, accessibility, and best practices. Identify issues and provide actionable feedback organized by severity.\n\n## Core Principles\n\n### Systematic Review\n- Review code structure first, then visual output\n- Check responsive behavior across all breakpoints\n- Verify accessibility requirements\n- Assess component composition patterns\n\n### Evidence-Based Feedback\n- Use browser_eval to capture and inspect rendered UI\n- Reference specific code locations for issues\n- Provide concrete examples for fixes\n\n### Prioritized Issues\n- Critical: Blocks functionality or major accessibility violation\n- Major: Significant UX problem or performance concern\n- Minor: Code style or minor enhancement opportunity\n\n## Review Checklist\n\n### Visual Hierarchy\n- [ ] Clear heading hierarchy (h1 -> h2 -> h3)\n- [ ] Consistent font sizes following design scale\n- [ ] Appropriate visual weight for CTAs vs secondary actions\n- [ ] Sufficient whitespace between sections\n\n### Spacing and Layout\n- [ ] Consistent spacing using Tailwind spacing scale\n- [ ] Proper alignment within grid/flex containers\n- [ ] Mobile layout is usable (not just compressed desktop)\n- [ ] Touch targets minimum 44x44px on mobile\n\n### Typography\n- [ ] Line height appropriate for text blocks\n- [ ] Maximum line length for readability (~65-75 characters)\n- [ ] Proper font weights for hierarchy\n- [ ] Text is legible at all breakpoints\n\n### Color and Contrast\n- [ ] Minimum 4.5:1 contrast ratio for normal text\n- [ ] Minimum 3:1 contrast ratio for large text\n- [ ] Color is not the only indicator of state\n- [ ] Focus states are visible\n\n### Keyboard Navigation\n- [ ] All interactive elements are focusable\n- [ ] Focus order follows visual order\n- [ ] Focus states are clearly visible\n- [ ] Modal/dialog traps focus appropriately\n\n### Component Composition\n- [ ] Uses compound components over prop-heavy components\n- [ ] Consistent with existing component patterns\n- [ ] Proper separation of Server vs Client components\n- [ ] Minimal \"use client\" boundaries\n\n### Responsive Behavior\n- [ ] Mobile layout (375px) fully functional\n- [ ] Tablet layout (768px) uses space appropriately\n- [ ] Desktop layout (1024px+) doesn't stretch excessively\n- [ ] No horizontal scrolling at any breakpoint\n\n### Accessibility\n- [ ] Semantic HTML elements used correctly\n- [ ] ARIA labels on interactive elements\n- [ ] Form inputs have associated labels\n- [ ] Error messages are announced to screen readers\n- [ ] Images have appropriate alt text\n\n### Performance\n- [ ] Images are optimized (next/image or proper sizing)\n- [ ] No unnecessary client components\n- [ ] Animations use GPU-accelerated properties\n- [ ] Loading states for async operations\n\n## Agent-scoped Project Context\n\n### Browser Automation Tool\n\nUse `mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__browser_eval` for visual inspection:\n\n**Start browser:**\n```\naction: start\nheadless: false (for visual inspection)\n```\n\n**Navigate to page:**\n```\naction: navigate\nurl: http://localhost:3000/path\n```\n\n**Take screenshot:**\n```\naction: screenshot\nfullPage: true\n```\n\n**Get console errors:**\n```\naction: console_messages\nerrorsOnly: true\n```\n\n### Review Workflow\n\n1. **Code Review** - Read component files, check structure\n2. **Visual Inspection** - Use browser_eval to view rendered UI\n3. **Responsive Check** - Test at mobile, tablet, desktop widths\n4. **Accessibility Audit** - Check keyboard nav, contrast, ARIA\n5. **Issue Documentation** - Organize findings by severity\n\n## Output Format\n\nProvide review results in this format:\n\n### Summary\nBrief overview of UI quality (1-2 sentences).\n\n### Critical Issues\nIssues that must be fixed before merge:\n- **[Location]**: Description of issue and impact\n  - **Fix**: Specific action to resolve\n\n### Major Issues\nSignificant problems that should be addressed:\n- **[Location]**: Description\n  - **Fix**: Recommended solution\n\n### Minor Issues\nOptional improvements and suggestions:\n- **[Location]**: Description\n  - **Suggestion**: Recommended enhancement\n\n### Positive Observations\nWhat was done well:\n- Highlight good patterns and practices\n\n### Accessibility Score\nRate accessibility on scale of 1-5 with brief justification.\n\n## Review Standards\n\n**Pass criteria:**\n- No critical issues\n- All major issues have mitigation plan\n- Accessibility score >= 3\n\n**Block criteria:**\n- Any critical accessibility violation\n- Broken functionality at any breakpoint\n- Missing keyboard navigation for interactive elements\n",
        "plugins/nextjs-supabase-ai-sdk-dev/agents/ui-tester.md": "---\ndescription: Use this agent to test UI at mobile (375px) and desktop (1440px) viewports. Triggers on \"test UI\", \"check responsiveness\", \"verify layout\", \"test mobile view\", \"test desktop view\".\nmodel: sonnet\ntools: [Read, Glob, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__browser_eval, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__nextjs_index, mcp__plugin_nextjs-supabase-ai-sdk-dev_next-devtools__nextjs_call]\ncolor: \"#10B981\"\n---\n\n# UI Tester Agent\n\nTest UI functionality and responsiveness across mobile and desktop viewports using browser automation.\n\n## Objective\n\nSystematically test UI components and pages at multiple viewport sizes to ensure responsive behavior, visual consistency, and functional correctness.\n\n## Test Workflow\n\n### Step 1: Start Browser\n\nInitialize browser automation:\n\n```\nbrowser_eval action: start\n```\n\nThis starts a headless browser session for testing.\n\n### Step 2: Navigate to Page\n\nNavigate to the target URL:\n\n```\nbrowser_eval action: navigate, url: \"http://localhost:3000/path\"\n```\n\n### Step 3: Test Mobile Viewport (375px)\n\nSet viewport to mobile width and test:\n\n```\nbrowser_eval action: evaluate, script: \"window.innerWidth = 375; window.dispatchEvent(new Event('resize'));\"\n```\n\nThen capture screenshot:\n\n```\nbrowser_eval action: screenshot, fullPage: true\n```\n\nCheck:\n- Navigation collapses to hamburger menu\n- Content stacks vertically\n- Touch targets are at least 44px\n- Text is readable without horizontal scroll\n- Images scale appropriately\n\n### Step 4: Test Desktop Viewport (1440px)\n\nSet viewport to desktop width and test:\n\n```\nbrowser_eval action: evaluate, script: \"window.innerWidth = 1440; window.dispatchEvent(new Event('resize'));\"\n```\n\nThen capture screenshot:\n\n```\nbrowser_eval action: screenshot, fullPage: true\n```\n\nCheck:\n- Navigation displays full menu\n- Multi-column layouts render correctly\n- Whitespace and spacing are balanced\n- Interactive elements have hover states\n- Content width is appropriately constrained\n\n### Step 5: Test Interactive Elements\n\nFor each interactive element:\n\n```\nbrowser_eval action: click, element: \"button.submit\"\nbrowser_eval action: type, element: \"input[name='email']\", text: \"test@example.com\"\n```\n\nVerify:\n- Buttons respond to clicks\n- Form inputs accept input\n- Modals open and close\n- Dropdowns expand correctly\n\n### Step 6: Report Findings\n\nCompile a structured report with:\n- Screenshots at both viewports\n- Working features list\n- Broken features list\n- Visual hierarchy issues\n- Modern UI/UX recommendations\n\n## Core Principles\n\n### Always Test Both Viewports\n\nEvery page must be verified at:\n- **Mobile (375px)**: iPhone SE / small phone width\n- **Desktop (1440px)**: Standard desktop width\n\n### Check Interactive Elements\n\nVerify all clickable elements:\n- Buttons trigger expected actions\n- Links navigate correctly\n- Form inputs are functional\n- Modals/dialogs work properly\n\n### Verify Visual Hierarchy\n\nEnsure proper visual structure:\n- Headings have clear hierarchy (h1 > h2 > h3)\n- CTAs are visually prominent\n- Important content is above the fold\n- Spacing is consistent\n\n### Modern UI/UX Standards\n\nRecommend improvements based on:\n- Accessibility (WCAG 2.1 AA)\n- Performance (Core Web Vitals)\n- Mobile-first patterns\n- Contemporary design trends\n\n## Report Format\n\n```markdown\n# UI Test Report: [Page Name]\n\n## Test Summary\n- **URL**: http://localhost:3000/path\n- **Date**: [timestamp]\n- **Viewports**: 375px (mobile), 1440px (desktop)\n\n## Screenshots\n- Mobile: [path to screenshot]\n- Desktop: [path to screenshot]\n\n## Working Features\n- [ ] Feature 1: Description\n- [ ] Feature 2: Description\n\n## Broken Features\n- [ ] Issue 1: Description and reproduction steps\n- [ ] Issue 2: Description and reproduction steps\n\n## Visual Hierarchy Issues\n- Issue 1: Description and suggested fix\n- Issue 2: Description and suggested fix\n\n## UI/UX Recommendations\n1. **Recommendation**: Explanation and benefit\n2. **Recommendation**: Explanation and benefit\n```\n\n## Agent-Scoped Context\n\n### MCP Browser Tools\n\nThis agent uses the following MCP tools from next-devtools:\n\n- **browser_eval**: Execute browser automation actions\n  - `action: start` - Initialize browser session\n  - `action: navigate` - Go to URL\n  - `action: click` - Click element\n  - `action: type` - Type into input\n  - `action: screenshot` - Capture page\n  - `action: evaluate` - Run JavaScript\n  - `action: close` - End session\n\n- **nextjs_index**: Discover running Next.js dev servers and their MCP tools\n\n- **nextjs_call**: Call specific tools on Next.js dev server (errors, routes, build status)\n\n### Common Viewport Sizes\n\n| Device | Width | Use Case |\n|--------|-------|----------|\n| Mobile | 375px | iPhone SE, small phones |\n| Tablet | 768px | iPad, tablets |\n| Desktop | 1440px | Standard desktop |\n| Wide | 1920px | Large monitors |\n\n### Test Patterns\n\n1. **Responsive Navigation**: Hamburger on mobile, full menu on desktop\n2. **Grid Layouts**: Single column mobile, multi-column desktop\n3. **Typography**: Smaller fonts mobile, larger desktop\n4. **Touch vs Hover**: Touch targets mobile, hover states desktop\n5. **Image Scaling**: Responsive images, proper aspect ratios\n\n## Error Handling\n\nIf browser automation fails:\n\n1. Check if dev server is running (`nextjs_index`)\n2. Verify the URL is accessible\n3. Check for JavaScript errors (`browser_eval action: console_messages`)\n4. Report the error with context\n\n## See Also\n\n- [UI Design Skill](../skills/ui-design/SKILL.md) - Component design methodology\n- [UI Researcher Agent](./ui-researcher.md) - Design research and screenshots\n- [Next.js DevTools MCP](https://github.com/anthropics/claude-code) - Browser automation docs\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/cache-supabase-schema.ts": "/**\n * Supabase Schema Caching Hook\n * SessionStart hook that caches Supabase table/column metadata for context matching.\n *\n * This hook checks for existing schema cache and provides instructions to Claude\n * for refreshing stale or missing schema metadata. Since hooks cannot directly\n * call MCP tools, it outputs SQL and instructions for Claude to execute.\n *\n * @module cache-supabase-schema\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';\nimport { join, dirname } from 'path';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Column metadata with extracted tags from comments\n */\ninterface ColumnSchema {\n  name: string;\n  type: string;\n  comment?: string;\n  tags: string[];\n}\n\n/**\n * Table metadata with columns and extracted tags from comments\n */\ninterface TableSchema {\n  name: string;\n  schema: string;\n  comment?: string;\n  tags: string[];\n  columns: Record<string, ColumnSchema>;\n}\n\n/**\n * Complete Supabase schema cache structure\n */\ninterface SupabaseSchemaCache {\n  projectId?: string;\n  lastRefreshed: string;\n  tables: Record<string, TableSchema>;\n}\n\n/**\n * Metadata index structure stored in .claude/logs/metadata-index.json\n */\ninterface MetadataIndex {\n  version: string;\n  lastUpdated: string;\n  supabaseSchema?: SupabaseSchemaCache;\n  [key: string]: unknown;\n}\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst CACHE_FILE = '.claude/logs/metadata-index.json';\nconst CACHE_TTL_MS = 60 * 60 * 1000; // 1 hour in milliseconds\n\n/**\n * SQL query for fetching table and column comments from PostgreSQL\n * This query extracts metadata from pg_description and pg_class\n */\nconst SCHEMA_QUERY_SQL = `SELECT\n  c.relname as table_name,\n  d.description as table_comment,\n  a.attname as column_name,\n  pd.description as column_comment,\n  format_type(a.atttypid, a.atttypmod) as column_type\nFROM pg_class c\nLEFT JOIN pg_description d ON d.objoid = c.oid AND d.objsubid = 0\nLEFT JOIN pg_attribute a ON a.attrelid = c.oid AND a.attnum > 0 AND NOT a.attisdropped\nLEFT JOIN pg_description pd ON pd.objoid = c.oid AND pd.objsubid = a.attnum\nWHERE c.relkind = 'r'\n  AND c.relnamespace = 'public'::regnamespace\nORDER BY c.relname, a.attnum;`;\n\n// ============================================================================\n// Helper Functions\n// ============================================================================\n\n/**\n * Check if Supabase is configured in the project\n * Looks for SUPABASE_URL env var or supabase/config.toml\n */\nfunction isSupabaseConfigured(cwd: string): boolean {\n  // Check environment variable\n  if (process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL) {\n    return true;\n  }\n\n  // Check for local Supabase config\n  const configPath = join(cwd, 'supabase', 'config.toml');\n  return existsSync(configPath);\n}\n\n/**\n * Read the project ID from supabase/config.toml\n */\nfunction getSupabaseProjectId(cwd: string): string | undefined {\n  const configPath = join(cwd, 'supabase', 'config.toml');\n  if (!existsSync(configPath)) {\n    return undefined;\n  }\n\n  try {\n    const content = readFileSync(configPath, 'utf-8');\n    const match = content.match(/^\\s*project_id\\s*=\\s*\"([^\"]+)\"/m);\n    return match?.[1];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Read the metadata index file\n */\nfunction readMetadataIndex(cwd: string): MetadataIndex | null {\n  const cachePath = join(cwd, CACHE_FILE);\n  if (!existsSync(cachePath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(cachePath, 'utf-8');\n    return JSON.parse(content) as MetadataIndex;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Write the metadata index file\n */\nfunction writeMetadataIndex(cwd: string, index: MetadataIndex): void {\n  const cachePath = join(cwd, CACHE_FILE);\n  const cacheDir = dirname(cachePath);\n\n  try {\n    mkdirSync(cacheDir, { recursive: true });\n    writeFileSync(cachePath, JSON.stringify(index, null, 2), 'utf-8');\n  } catch {\n    // Silently fail - logging is not critical\n  }\n}\n\n/**\n * Check if the schema cache is stale (older than 1 hour)\n */\nfunction isCacheStale(schemaCache: SupabaseSchemaCache | undefined): boolean {\n  if (!schemaCache?.lastRefreshed) {\n    return true;\n  }\n\n  const lastRefreshed = new Date(schemaCache.lastRefreshed).getTime();\n  const now = Date.now();\n  return now - lastRefreshed > CACHE_TTL_MS;\n}\n\n/**\n * Extract tags from a comment string\n * Tags are denoted with #hashtag or @tag format\n */\nfunction extractTags(comment: string | undefined): string[] {\n  if (!comment) return [];\n  const tagMatches = comment.match(/[#@]\\w+/g);\n  return tagMatches ? tagMatches.map((t) => t.slice(1)) : [];\n}\n\n/**\n * Generate a summary of cached tables\n */\nfunction generateCacheSummary(schemaCache: SupabaseSchemaCache): string {\n  const tableNames = Object.keys(schemaCache.tables);\n  const tableCount = tableNames.length;\n\n  if (tableCount === 0) {\n    return 'Schema cache exists but contains no tables.';\n  }\n\n  // Get tables with comments (more useful for context)\n  const tablesWithComments = tableNames.filter((name) => schemaCache.tables[name].comment);\n\n  let summary = `Supabase schema cached: ${tableCount} tables`;\n  if (schemaCache.projectId) {\n    summary += ` (project: ${schemaCache.projectId})`;\n  }\n  summary += `\\n`;\n\n  // List tables (max 10)\n  const displayTables = tableNames.slice(0, 10);\n  summary += `Tables: ${displayTables.join(', ')}`;\n  if (tableNames.length > 10) {\n    summary += `, +${tableNames.length - 10} more`;\n  }\n  summary += '\\n';\n\n  if (tablesWithComments.length > 0) {\n    summary += `Tables with documentation: ${tablesWithComments.length}\\n`;\n  }\n\n  const lastRefreshed = new Date(schemaCache.lastRefreshed);\n  summary += `Last refreshed: ${lastRefreshed.toLocaleString()}`;\n\n  return summary;\n}\n\n/**\n * Generate instructions for Claude to refresh the schema cache\n */\nfunction generateRefreshInstructions(projectId?: string): string {\n  const instructions = [\n    'Supabase schema cache is stale or missing.',\n    '',\n    'To refresh the schema cache, use the Supabase MCP tool to execute this SQL:',\n    '',\n    '```sql',\n    SCHEMA_QUERY_SQL,\n    '```',\n    '',\n    'After running the query, the schema metadata will be available for context matching.',\n  ];\n\n  if (projectId) {\n    instructions.splice(1, 0, `Project ID: ${projectId}`);\n  }\n\n  return instructions.join('\\n');\n}\n\n// ============================================================================\n// Schema Parsing (for when Claude provides query results)\n// ============================================================================\n\n/**\n * Parse schema query results into SupabaseSchemaCache format\n * This function can be called to update the cache when new data is available\n */\nexport function parseSchemaResults(\n  results: Array<{\n    table_name: string;\n    table_comment?: string;\n    column_name?: string;\n    column_comment?: string;\n    column_type?: string;\n  }>,\n  projectId?: string\n): SupabaseSchemaCache {\n  const tables: Record<string, TableSchema> = {};\n\n  for (const row of results) {\n    const tableName = row.table_name;\n\n    // Initialize table if not exists\n    if (!tables[tableName]) {\n      tables[tableName] = {\n        name: tableName,\n        schema: 'public',\n        comment: row.table_comment ?? undefined,\n        tags: extractTags(row.table_comment ?? undefined),\n        columns: {},\n      };\n    }\n\n    // Add column if present\n    if (row.column_name) {\n      tables[tableName].columns[row.column_name] = {\n        name: row.column_name,\n        type: row.column_type || 'unknown',\n        comment: row.column_comment ?? undefined,\n        tags: extractTags(row.column_comment ?? undefined),\n      };\n    }\n  }\n\n  return {\n    projectId,\n    lastRefreshed: new Date().toISOString(),\n    tables,\n  };\n}\n\n/**\n * Update the metadata index with new schema cache\n */\nexport function updateSchemaCache(cwd: string, schemaCache: SupabaseSchemaCache): void {\n  let index = readMetadataIndex(cwd);\n\n  if (!index) {\n    index = {\n      version: '1.0.0',\n      lastUpdated: new Date().toISOString(),\n    };\n  }\n\n  index.supabaseSchema = schemaCache;\n  index.lastUpdated = new Date().toISOString();\n\n  writeMetadataIndex(cwd, index);\n}\n\n// ============================================================================\n// Main Handler\n// ============================================================================\n\n/**\n * SessionStart hook handler\n * Checks for Supabase configuration and schema cache status\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'cache-supabase-schema', true);\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n    });\n\n    // Check if Supabase is configured\n    if (!isSupabaseConfigured(input.cwd)) {\n      const message = 'Supabase not configured in this project. Skipping schema cache check.';\n      await logger.logOutput({ success: true, message });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '', // No context if Supabase not configured\n        },\n      };\n    }\n\n    const projectId = getSupabaseProjectId(input.cwd);\n\n    // Read existing metadata index\n    const index = readMetadataIndex(input.cwd);\n    const schemaCache = index?.supabaseSchema;\n\n    // Check if cache exists and is fresh\n    if (schemaCache && !isCacheStale(schemaCache)) {\n      const summary = generateCacheSummary(schemaCache);\n      messages.push('[Supabase Schema Cache]');\n      messages.push(summary);\n\n      await logger.logOutput({\n        success: true,\n        status: 'cache_valid',\n        tableCount: Object.keys(schemaCache.tables).length,\n      });\n    } else {\n      // Cache is stale or missing - provide refresh instructions\n      const instructions = generateRefreshInstructions(projectId);\n      messages.push('[Supabase Schema Cache]');\n      messages.push(instructions);\n\n      await logger.logOutput({\n        success: true,\n        status: schemaCache ? 'cache_stale' : 'cache_missing',\n        projectId,\n      });\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: messages.join('\\n'),\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Supabase schema cache error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/cleanup-supabase-session.ts": "/**\n * Supabase Session Cleanup Hook (SessionEnd)\n * SessionEnd hook that:\n * 1. Stops Supabase containers for the current session (using --workdir for tmp configs)\n * 2. Cleans up /tmp/supabase-{worktreeId} directory\n * 3. Marks session state as stopped\n *\n * This is the primary cleanup hook that runs when the user exits the session\n * (Ctrl+C, /clear, logout, etc.)\n *\n * @module cleanup-supabase-session\n */\n\nimport type { SessionEndInput, SessionEndHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { detectWorktree } from '../shared/hooks/utils/worktree.js';\nimport {\n  loadWorktreeSupabaseSession,\n  updateWorktreeSupabaseSession,\n} from '../shared/hooks/utils/session-state.js';\nimport { cleanupTmpSupabaseDir } from '../shared/hooks/utils/supabase-tmp-config.js';\nimport { killProcessesOnPorts } from '../shared/hooks/utils/port.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Docker container config saved by SessionStart hook\n */\ninterface DockerContainerConfig {\n  projectId: string;\n  containerIds: string[];\n  volumeNames: string[];\n  savedAt: string;\n}\n\nconst execAsync = promisify(exec);\n\n/**\n * Execute a command and return result\n */\nasync function execCommand(\n  command: string,\n  options: { cwd: string; timeout?: number }\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd: options.cwd,\n      timeout: options.timeout ?? 30000,\n    });\n    return { success: true, stdout, stderr };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout || '',\n      stderr: err.stderr || err.message || 'Unknown error',\n    };\n  }\n}\n\n/**\n * SessionEnd hook handler - cleanup Supabase containers on session end\n */\nasync function handler(input: SessionEndInput): Promise<SessionEndHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'cleanup-supabase-session', true);\n  await logger.logInput({\n    session_id: input.session_id,\n    reason: input.reason,\n  });\n\n  const worktreeInfo = detectWorktree(input.cwd);\n\n  // Load session state\n  const session = await loadWorktreeSupabaseSession(input.cwd, worktreeInfo.worktreeId);\n\n  // Best-effort cleanup - try to clean up resources regardless of session ownership\n  // This ensures we don't leave orphaned containers/processes when sessions end unexpectedly\n\n  // Track what we cleaned\n  let cleanedContainers = false;\n  let cleanedPorts = false;\n  let cleanedConfig = false;\n  let cleanedVolumes = false;\n\n  // 0. Try supabase stop --workdir first (cleanest approach for tmp directory sessions)\n  // Use --no-backup to delete volumes (without it, supabase stop only stops containers)\n  if (session?.tmpConfigDir && existsSync(session.tmpConfigDir)) {\n    try {\n      const stopResult = await execCommand(\n        `supabase stop --workdir ${session.tmpConfigDir} --no-backup`,\n        { cwd: input.cwd, timeout: 60000 }\n      );\n      if (stopResult.success) {\n        cleanedContainers = true;\n        cleanedVolumes = true;\n      }\n    } catch {\n      // Fall through to docker-based cleanup\n    }\n  }\n\n  // 1. Stop and delete Supabase containers using exact IDs from docker-containers.json\n  // This prevents accidentally deleting containers from other sessions\n  // Skip if supabase stop already succeeded\n  const dockerConfigPath = join(input.cwd, '.claude', 'logs', 'docker-containers.json');\n\n  // Try to use exact container IDs first (more precise, prevents cross-session deletion)\n  let usedExactIds = false;\n  if (!cleanedContainers && existsSync(dockerConfigPath)) {\n    try {\n      const configContent = readFileSync(dockerConfigPath, 'utf-8');\n      const dockerConfig: DockerContainerConfig = JSON.parse(configContent);\n\n      // Stop and remove containers by exact ID\n      if (dockerConfig.containerIds && dockerConfig.containerIds.length > 0) {\n        for (const containerId of dockerConfig.containerIds) {\n          await execCommand(`docker stop ${containerId}`, { cwd: input.cwd, timeout: 30000 });\n          await execCommand(`docker rm ${containerId}`, { cwd: input.cwd, timeout: 30000 });\n        }\n        cleanedContainers = true;\n        usedExactIds = true;\n      }\n\n      // Remove volumes by exact name\n      if (dockerConfig.volumeNames && dockerConfig.volumeNames.length > 0) {\n        for (const volumeName of dockerConfig.volumeNames) {\n          await execCommand(`docker volume rm ${volumeName}`, { cwd: input.cwd, timeout: 30000 });\n        }\n        cleanedVolumes = true;\n      }\n    } catch {\n      // Config file invalid or containers already removed - fall through to filter-based cleanup\n    }\n  }\n\n  // Fallback: use filter-based cleanup if exact IDs not available\n  // This is less precise but ensures cleanup still happens\n  // Skip if supabase stop or exact IDs already succeeded\n  if (!cleanedContainers && !usedExactIds && session?.worktreeProjectId) {\n    try {\n      // Use exact name matching by listing containers and filtering in shell\n      // The filter pattern matches containers ending with the exact project ID\n      await execCommand(\n        `docker ps -a --format \"{{.Names}}\" | grep \"_${session.worktreeProjectId}$\" | xargs -r docker stop`,\n        { cwd: input.cwd, timeout: 30000 }\n      );\n      await execCommand(\n        `docker ps -a --format \"{{.Names}}\" | grep \"_${session.worktreeProjectId}$\" | xargs -r docker rm`,\n        { cwd: input.cwd, timeout: 30000 }\n      );\n      cleanedContainers = true;\n    } catch {\n      // Best effort - don't fail if cleanup fails\n    }\n\n    // 1b. Delete associated Docker volumes to free disk space (exact name match)\n    if (!cleanedVolumes) {\n      try {\n        await execCommand(\n          `docker volume rm \"supabase_db_${session.worktreeProjectId}\"`,\n          { cwd: input.cwd, timeout: 30000 }\n        );\n        await execCommand(\n          `docker volume rm \"supabase_storage_${session.worktreeProjectId}\"`,\n          { cwd: input.cwd, timeout: 30000 }\n        );\n        cleanedVolumes = true;\n      } catch {\n        // Best effort - don't fail if cleanup fails\n      }\n    }\n  }\n\n  // 2. Kill dev server processes by port (if session has port info)\n  if (session?.devServerPorts) {\n    try {\n      const ports = [\n        session.devServerPorts.nextjs,\n        session.devServerPorts.vite,\n        session.devServerPorts.cloudflare,\n      ].filter((p): p is number => typeof p === 'number' && p > 0);\n\n      if (ports.length > 0) {\n        await killProcessesOnPorts(ports);\n        cleanedPorts = true;\n      }\n    } catch {\n      // Best effort - don't fail if cleanup fails\n    }\n  }\n\n  // 3. Also try to kill common dev server ports (3100-3102, 8787) as fallback\n  try {\n    await killProcessesOnPorts([3100, 3101, 3102, 8787]);\n  } catch {\n    // Best effort\n  }\n\n  // 4. Clean up tmp Supabase config directory (for worktree sessions)\n  if (session?.tmpConfigDir) {\n    try {\n      cleanupTmpSupabaseDir(session.tmpConfigDir);\n      cleanedConfig = true;\n    } catch {\n      // Best effort\n    }\n  }\n\n  // 5. Mark session as stopped (if session exists)\n  if (session) {\n    try {\n      await updateWorktreeSupabaseSession(input.cwd, worktreeInfo.worktreeId, {\n        running: false,\n      });\n    } catch {\n      // Best effort\n    }\n  }\n\n  await logger.logOutput({\n    success: true,\n    cleaned: session?.worktreeProjectId,\n    cleanedContainers,\n    cleanedVolumes,\n    cleanedPorts,\n    cleanedConfig,\n    reason: input.reason,\n  });\n\n  // SessionEnd hooks return empty object (cannot block session termination)\n  return {};\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/hooks.json": "{\n  \"_comment\": \"Next.js Supabase AI SDK Dev Plugin - Local dev environment setup\",\n  \"_notes\": [\n    \"Installs Vercel CLI on remote, warns on local\",\n    \"Sets up Supabase local dev: CLI, Docker, server, env vars, dev server\",\n    \"Tracks task/agent calls for context\",\n    \"Check hooks moved to rule-based system in project-context plugin\"\n  ],\n  \"_disabled_hooks\": {\n    \"_note\": \"Disabled hooks preserved for future re-enabling\",\n    \"SessionStart\": [\n      {\n        \"type\": \"command\",\n        \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/install-start-supabase-next.ts\",\n        \"description\": \"Sets up Supabase local dev: installs CLI, starts Docker, starts Supabase, exports env vars, starts dev server\",\n        \"timeout\": 600\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"type\": \"command\",\n        \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/cleanup-supabase-session.ts\",\n        \"description\": \"Stops Supabase containers and marks session as stopped when session ends\",\n        \"timeout\": 60\n      }\n    ]\n  },\n  \"description\": \"Local development environment setup for Next.js, Supabase, and AI SDK projects\",\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"startup|resume|clear\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/setup-nodes-config.ts\",\n            \"description\": \"Creates .nodes/.mcp.nodes.json config for the nodes-md MCP proxy\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/install-vercel.ts\",\n            \"description\": \"Installs Vercel CLI on remote, warns if missing on local\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/link-vercel-apps.ts\",\n            \"description\": \"Auto-links monorepo apps to Vercel projects and pulls env vars\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/cache-supabase-schema.ts\",\n            \"description\": \"Caches Supabase table/column metadata for context matching. Checks for stale cache and provides refresh instructions.\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/validate-supabase-env.ts\",\n            \"description\": \"Validates Supabase environment variables in .env.local and dev.vars files. Blocks deprecated names (SUPABASE_ANON_KEY, SUPABASE_SERVICE_ROLE_KEY) and incorrect prefixes.\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/use-proxy-nextjs-16.ts\",\n            \"description\": \"Blocks middleware.ts creation in Next.js 16+ projects. Requires proxy.ts instead. Exception: Supabase middleware allowed.\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/run-file-eslint.ts\",\n            \"description\": \"Runs ESLint on edited .ts/.tsx/.js/.jsx files. Blocking on errors.\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/run-file-vitests.ts\",\n            \"description\": \"Runs related vitest tests for edited files. Non-blocking (warns only).\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"browser_eval\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/move-playwright-screenshots.ts\",\n            \"description\": \"Moves screenshots to .claude/screenshots/ to prevent permission prompts\"\n          }\n        ]\n      }\n    ],\n    \"SubagentStop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/run-task-vitests.ts\",\n            \"description\": \"Runs vitest for all files edited during agent's task. Blocking on failure.\"\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/run-task-typechecks.ts\",\n            \"description\": \"Runs tsc --noEmit after agent completes. Blocking on type errors.\"\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/run-session-typechecks.ts\",\n            \"description\": \"Runs tsc --noEmit before session stops. Blocking on type errors.\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/install-start-supabase-next.ts": "/**\n * Supabase + Next.js Development Environment Setup Hook\n * SessionStart hook that:\n * 1. Checks/installs Supabase CLI\n * 2. Starts Docker if needed\n * 3. Starts Supabase local server\n * 4. Exports env vars to the correct env file\n * 5. Installs dependencies (skips if node_modules is fresh)\n * 6. Starts Next.js dev server (or Turborepo apps)\n * @module install-start-supabase-next\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { detectPackageManager } from '../shared/hooks/utils/package-manager.js';\nimport { isPortAvailable, findAvailablePort, killProcessOnPort, findAvailablePortAt10Increments } from '../shared/hooks/utils/port.js';\nimport { getWranglerDevPort } from '../shared/hooks/utils/toml.js';\nimport { findViteConfigPort } from '../shared/hooks/utils/vite-config.js';\nimport { distributeEnvVars, mergeWorkspaceEnvVars, validateEnvVars, detectSupabaseUsage, hasSupabaseInMonorepo, generateAppUrls, detectWorkspaceFramework, resolveWorkspacePorts, type DevServerPorts, type WorkspaceInfo } from '../shared/hooks/utils/env-sync.js';\nimport { detectWorktree, type WorktreeInfo } from '../shared/hooks/utils/worktree.js';\nimport {\n  PORT_INCREMENT,\n  calculatePortSet,\n  checkSupabasePortUsage,\n  findAvailableSlot,\n  getSupabaseConfigPath,\n  getOriginalProjectId,\n  generateWorktreeProjectId,\n  buildExcludeFlags,\n  type SupabasePortSet,\n} from '../shared/hooks/utils/supabase-ports.js';\nimport {\n  createTmpSupabaseDir,\n  addToGitignore,\n} from '../shared/hooks/utils/supabase-tmp-config.js';\nimport {\n  loadWorktreeSupabaseSession,\n  saveWorktreeSupabaseSession,\n  updateWorktreeSupabaseSession,\n  type WorktreeSupabaseSession,\n  type DevServerPortSet,\n} from '../shared/hooks/utils/session-state.js';\nimport { getProcessesOnPorts, formatProcessInfo } from '../shared/hooks/utils/process-info.js';\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync, readFileSync, readdirSync, statSync, mkdirSync, openSync, writeFileSync } from 'fs';\nimport { join, dirname, basename } from 'path';\nimport { platform } from 'os';\n\nconst execAsync = promisify(exec);\n\ninterface ExecResult {\n  success: boolean;\n  stdout: string;\n  stderr: string;\n}\n\ntype ProjectType = 'turborepo' | 'nextjs' | 'vite' | 'cloudflare' | 'elysia' | 'unknown';\n\n/**\n * Execute a shell command with error handling\n */\nasync function execCommand(\n  command: string,\n  options: { cwd?: string; timeout?: number; env?: Record<string, string> } = {}\n): Promise<ExecResult> {\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd: options.cwd,\n      timeout: options.timeout || 300000,\n      env: { ...process.env, ...options.env },\n    });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a command is available in PATH\n */\nasync function isCommandAvailable(command: string): Promise<boolean> {\n  const result = await execCommand(`which ${command}`);\n  return result.success && result.stdout.length > 0;\n}\n\n/**\n * Detect if running in remote (cloud) environment\n */\nfunction isRemoteEnvironment(): boolean {\n  return process.env.CLAUDE_CODE_ENTRYPOINT === 'remote';\n}\n\n/**\n * Check if Docker is installed (not just running)\n */\nasync function isDockerInstalled(): Promise<boolean> {\n  const result = await execCommand('which docker', { timeout: 5000 });\n  return result.success && result.stdout.length > 0;\n}\n\n/**\n * Get Supabase CLI version\n */\nasync function getSupabaseVersion(): Promise<string | null> {\n  const result = await execCommand('supabase --version');\n  if (result.success) {\n    const match = result.stdout.match(/(\\d+\\.\\d+\\.\\d+)/);\n    return match ? match[1] : null;\n  }\n  return null;\n}\n\n/**\n * Install Supabase CLI via official binary installer\n */\nasync function installSupabaseCLI(): Promise<ExecResult> {\n  if (await isCommandAvailable('supabase')) {\n    return { success: true, stdout: 'supabase already installed', stderr: '' };\n  }\n\n  const result = await execCommand(\n    'curl -fsSL https://raw.githubusercontent.com/supabase/cli/main/install.sh | sh',\n    { timeout: 120000 }\n  );\n  if (!result.success) {\n    return { success: false, stdout: '', stderr: `Failed to install supabase: ${result.stderr}` };\n  }\n  return { success: true, stdout: 'supabase installed successfully', stderr: '' };\n}\n\n// ==================== Docker Management ====================\n\n/**\n * Check if Docker daemon is running\n */\nasync function isDockerRunning(): Promise<boolean> {\n  const result = await execCommand('docker info', { timeout: 10000 });\n  return result.success;\n}\n\n/**\n * Attempt to start Docker daemon\n */\nasync function startDocker(): Promise<boolean> {\n  const os = platform();\n\n  if (os === 'darwin') {\n    // macOS: Try Docker Desktop, then Rancher Desktop, then OrbStack\n    const apps = ['Docker', 'Rancher Desktop', 'OrbStack'];\n    for (const app of apps) {\n      const result = await execCommand(`open -a \"${app}\"`, { timeout: 5000 });\n      if (result.success) {\n        return true;\n      }\n    }\n  } else if (os === 'linux') {\n    // Linux: Try systemctl\n    const result = await execCommand('sudo systemctl start docker', { timeout: 30000 });\n    return result.success;\n  }\n\n  return false;\n}\n\n/**\n * Wait for Docker to be ready\n */\nasync function waitForDocker(timeoutMs: number): Promise<boolean> {\n  const startTime = Date.now();\n  const pollInterval = 2000;\n\n  while (Date.now() - startTime < timeoutMs) {\n    if (await isDockerRunning()) {\n      return true;\n    }\n    await new Promise(resolve => setTimeout(resolve, pollInterval));\n  }\n\n  return false;\n}\n\n// ==================== Supabase Management ====================\n\n/**\n * Check if Supabase project is initialized\n */\nfunction isSupabaseInitialized(cwd: string): boolean {\n  return existsSync(join(cwd, 'supabase', 'config.toml'));\n}\n\n/**\n * Read project_id from supabase/config.toml\n * Uses regex for lightweight parsing (avoids importing TOML parser)\n */\nfunction getSupabaseProjectId(cwd: string): string | null {\n  const configPath = join(cwd, 'supabase', 'config.toml');\n  if (!existsSync(configPath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(configPath, 'utf-8');\n    const match = content.match(/^\\s*project_id\\s*=\\s*\"([^\"]+)\"/m);\n    return match?.[1] || null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Check if Supabase is already running\n */\nasync function isSupabaseRunning(cwd: string): Promise<boolean> {\n  const result = await execCommand('supabase status', { cwd, timeout: 10000 });\n  // If status returns successfully and contains service info, it's running\n  return result.success && result.stdout.includes('API URL');\n}\n\n/**\n * Export Supabase env vars to .env.local and dev.vars\n * Only saves 3 critical variables with correct prefixes\n * Maps deprecated variable names to modern ones\n *\n * @param supabaseRoot - Directory containing supabase/config.toml (where to run supabase CLI)\n * @param workdir - Optional workdir path (for tmp directory approach)\n * @returns Object with vars, success status, and deprecation warnings\n */\nasync function exportSupabaseEnvVars(\n  supabaseRoot: string,\n  workdir?: string\n): Promise<{ vars: Record<string, string>; success: boolean; warnings: string[] }> {\n  // Get raw env output from supabase root\n  // Use --workdir if tmp directory is provided\n  const workdirFlag = workdir ? ` --workdir ${workdir}` : '';\n  const result = await execCommand(`supabase status -o env${workdirFlag}`, { cwd: supabaseRoot, timeout: 10000 });\n  if (!result.success) {\n    return { vars: {}, success: false, warnings: [] };\n  }\n\n  // Parse only the 3 variables we need from supabase status output\n  // Supabase CLI outputs: API_URL, ANON_KEY, PUBLISHABLE_KEY, SERVICE_ROLE_KEY, SECRET_KEY\n  const envVars: Record<string, string> = {};\n  const warnings: string[] = [];\n  let usedLegacyAnon = false;\n  let usedLegacyService = false;\n\n  for (const line of result.stdout.split('\\n')) {\n    // API_URL -> SUPABASE_URL\n    const urlMatch = line.match(/^API_URL=\"?([^\"]+)\"?$/);\n    // PUBLISHABLE_KEY (new) or ANON_KEY (legacy) -> SUPABASE_PUBLISHABLE_KEY\n    const publishableMatch = line.match(/^PUBLISHABLE_KEY=\"?([^\"]+)\"?$/);\n    const anonMatch = line.match(/^ANON_KEY=\"?([^\"]+)\"?$/);\n    // SECRET_KEY (new) or SERVICE_ROLE_KEY (legacy) -> SUPABASE_SECRET_KEY\n    const secretMatch = line.match(/^SECRET_KEY=\"?([^\"]+)\"?$/);\n    const serviceMatch = line.match(/^SERVICE_ROLE_KEY=\"?([^\"]+)\"?$/);\n\n    if (urlMatch) {\n      envVars.SUPABASE_URL = urlMatch[1];\n    } else if (publishableMatch) {\n      envVars.SUPABASE_PUBLISHABLE_KEY = publishableMatch[1];\n    } else if (anonMatch && !envVars.SUPABASE_PUBLISHABLE_KEY) {\n      // Only use ANON_KEY if PUBLISHABLE_KEY not found\n      envVars.SUPABASE_PUBLISHABLE_KEY = anonMatch[1];\n      usedLegacyAnon = true;\n    } else if (secretMatch) {\n      envVars.SUPABASE_SECRET_KEY = secretMatch[1];\n    } else if (serviceMatch && !envVars.SUPABASE_SECRET_KEY) {\n      // Only use SERVICE_ROLE_KEY if SECRET_KEY not found\n      envVars.SUPABASE_SECRET_KEY = serviceMatch[1];\n      usedLegacyService = true;\n    }\n  }\n\n  // Add deprecation warnings for legacy key names\n  if (usedLegacyAnon || usedLegacyService) {\n    const legacyKeys = [];\n    if (usedLegacyAnon) legacyKeys.push('ANON_KEY');\n    if (usedLegacyService) legacyKeys.push('SERVICE_ROLE_KEY');\n    warnings.push(`⚠️ Deprecated: Using legacy Supabase key names (${legacyKeys.join(', ')})`);\n    warnings.push('  Update to: PUBLISHABLE_KEY, SECRET_KEY');\n    warnings.push('  Run: supabase upgrade to get modern key names');\n  }\n\n  return { vars: envVars, success: true, warnings };\n}\n\n/**\n * Distribute environment variables to all workspaces in a turborepo\n * Collects Supabase vars and Vercel vars, then distributes to all workspaces\n * Also generates per-app URL env vars for cross-app communication\n *\n * @param cwd - Root directory of the project\n * @param workspaces - Array of workspace paths relative to cwd\n * @param supabaseVars - Optional Supabase variables (from Supabase CLI)\n * @param devServerPorts - Optional dev server ports for URL generation\n * @returns Array of status messages\n */\nasync function distributeAllEnvVars(\n  cwd: string,\n  workspaces: string[],\n  supabaseVars?: Record<string, string>,\n  devServerPorts?: DevServerPorts\n): Promise<string[]> {\n  const messages: string[] = [];\n\n  // Collect and merge Vercel vars from all workspaces\n  const vercelVars = await mergeWorkspaceEnvVars(workspaces, cwd);\n\n  // Validate critical Supabase vars\n  if (supabaseVars && Object.keys(supabaseVars).length > 0) {\n    const critical = ['SUPABASE_URL', 'SUPABASE_PUBLISHABLE_KEY'];\n    const validation = validateEnvVars({ supabaseVars, vercelVars }, critical);\n\n    if (!validation.valid) {\n      messages.push(`⚠️ Missing critical env vars: ${validation.missing.join(', ')}`);\n    }\n  }\n\n  // Check if any package in the monorepo uses Supabase (for internal package detection)\n  const monorepoHasSupabase = hasSupabaseInMonorepo(cwd);\n\n  // Generate per-app URL env vars if ports are provided\n  let appUrlsByWorkspace: Map<string, Record<string, string>> | null = null;\n  if (devServerPorts) {\n    // Build workspace info for URL generation\n    // Extract configured ports from package.json dev scripts AND wrangler.toml\n    const workspaceInfos: WorkspaceInfo[] = [];\n    for (const ws of workspaces) {\n      const wsPath = join(cwd, ws);\n      const name = ws.split('/').pop() || ws;\n      const framework = detectWorkspaceFramework(wsPath);\n\n      // First try package.json dev script\n      let configuredPort = extractPortFromDevScript(join(wsPath, 'package.json'));\n\n      // For Cloudflare workers, also check wrangler.toml if no port in dev script\n      if (configuredPort === null && framework === 'cloudflare') {\n        const wranglerTomlPath = join(wsPath, 'wrangler.toml');\n        const wranglerJsoncPath = join(wsPath, 'wrangler.jsonc');\n        configuredPort = await getWranglerDevPort(wranglerTomlPath) ||\n                         await getWranglerDevPort(wranglerJsoncPath) ||\n                         null;\n      }\n\n      workspaceInfos.push({ path: ws, name, framework, configuredPort });\n    }\n\n    // Resolve ports (check availability and find alternatives at +10 increments)\n    // This ensures multiple Claude sessions can run in parallel without port conflicts\n    await resolveWorkspacePorts(workspaceInfos, devServerPorts);\n\n    appUrlsByWorkspace = generateAppUrls(workspaceInfos, devServerPorts);\n  }\n\n  // Distribute to ALL workspaces\n  for (const workspace of workspaces) {\n    const workspacePath = join(cwd, workspace);\n    // Check if this workspace uses Supabase directly, OR if it's an app that might\n    // depend on internal packages that wrap Supabase\n    const usesSupabase = detectSupabaseUsage(workspacePath) ||\n                         (workspace.startsWith('apps/') && monorepoHasSupabase);\n\n    // Merge app URL vars into vercel vars for this workspace\n    const appUrls = appUrlsByWorkspace?.get(workspace) || {};\n    const mergedVercelVars = { ...vercelVars, ...appUrls };\n\n    // Only include Supabase vars if workspace actually uses them\n    const varsToDistribute = usesSupabase\n      ? { supabaseVars: supabaseVars || {}, vercelVars: mergedVercelVars }\n      : { supabaseVars: {}, vercelVars: mergedVercelVars };\n\n    // Build alwaysOverwriteKeys list including URL vars\n    const alwaysOverwriteKeys = [\n      // URL vars should always be updated to reflect current ports\n      ...Object.keys(appUrls),\n    ];\n    if (usesSupabase) {\n      alwaysOverwriteKeys.push(\n        'NEXT_PUBLIC_SUPABASE_URL',\n        'NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY',\n        'SUPABASE_SECRET_KEY',\n        'VITE_SUPABASE_URL',\n        'VITE_SUPABASE_PUBLISHABLE_KEY',\n        // Cloudflare dev.vars uses unprefixed keys\n        'SUPABASE_URL',\n        'SUPABASE_PUBLISHABLE_KEY',\n      );\n    }\n\n    const result = await distributeEnvVars(\n      workspacePath,\n      varsToDistribute,\n      {\n        createIfMissing: true,\n        preserveExisting: true,\n        alwaysOverwriteKeys,\n      }\n    );\n\n    if (result.nextjs || result.vite) {\n      const hasUrls = Object.keys(appUrls).length > 0;\n      const varsWritten = usesSupabase\n        ? (hasUrls ? 'Supabase + Vercel + URLs' : 'Supabase + Vercel')\n        : (hasUrls ? 'Vercel + URLs' : 'Vercel');\n      messages.push(`✓ Environment variables (${varsWritten}) written to ${workspace}/.env.local`);\n    }\n    if (result.cloudflare) {\n      const hasUrls = Object.keys(appUrls).length > 0;\n      const varsWritten = usesSupabase\n        ? (hasUrls ? 'Supabase + Vercel + URLs' : 'Supabase + Vercel')\n        : (hasUrls ? 'Vercel + URLs' : 'Vercel');\n      messages.push(`✓ Environment variables (${varsWritten}) written to ${workspace}/dev.vars`);\n    }\n  }\n\n  return messages;\n}\n\n// ==================== Project Type Detection ====================\n\n/**\n * Detect Turborepo workspace directories\n * Reads package.json workspaces field to find app directories\n */\nfunction detectTurborepoWorkspaces(cwd: string): string[] | null {\n  const turboJsonPath = join(cwd, 'turbo.json');\n  if (!existsSync(turboJsonPath)) {\n    return null;\n  }\n\n  const rootPackageJson = join(cwd, 'package.json');\n  if (!existsSync(rootPackageJson)) {\n    return null;\n  }\n\n  try {\n    const packageData = JSON.parse(readFileSync(rootPackageJson, 'utf-8'));\n\n    // Get workspace patterns (supports npm/yarn/pnpm formats)\n    let workspacePatterns: string[] = [];\n    if (Array.isArray(packageData.workspaces)) {\n      workspacePatterns = packageData.workspaces;\n    } else if (packageData.workspaces?.packages) {\n      workspacePatterns = packageData.workspaces.packages;\n    }\n\n    // Resolve workspace directories\n    const workspaceDirs: string[] = [];\n\n    for (const pattern of workspacePatterns) {\n      if (pattern.includes('*')) {\n        // Handle globs like \"apps/*\" or \"packages/*\"\n        const baseDir = pattern.replace('/*', '');\n        const basePath = join(cwd, baseDir);\n\n        if (existsSync(basePath)) {\n          const entries = readdirSync(basePath);\n          for (const entry of entries) {\n            const entryPath = join(basePath, entry);\n            if (statSync(entryPath).isDirectory() && existsSync(join(entryPath, 'package.json'))) {\n              workspaceDirs.push(join(baseDir, entry));\n            }\n          }\n        }\n      } else {\n        // Direct path like \"apps/web\"\n        if (existsSync(join(cwd, pattern, 'package.json'))) {\n          workspaceDirs.push(pattern);\n        }\n      }\n    }\n\n    return workspaceDirs.length > 0 ? workspaceDirs : null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Port information for a workspace\n */\ninterface WorkspacePortInfo {\n  workspace: string;\n  projectType: ProjectType;\n  configuredPort: number | null;\n  defaultPort: number | null;\n}\n\n/**\n * Detect ports from all workspace package.json files\n * For Turborepo projects, reads each workspace's dev script to find configured ports\n * For Cloudflare workers, also reads wrangler.toml/jsonc for port configuration\n */\nasync function detectWorkspacePorts(cwd: string, workspaces: string[]): Promise<WorkspacePortInfo[]> {\n  const portInfos: WorkspacePortInfo[] = [];\n\n  for (const workspace of workspaces) {\n    const workspacePath = join(cwd, workspace);\n    const packageJsonPath = join(workspacePath, 'package.json');\n\n    // Detect project type for this workspace\n    const wsProjectType = detectWorkspaceProjectType(workspacePath);\n\n    // Extract configured port from dev script\n    let configuredPort = extractPortFromDevScript(packageJsonPath);\n\n    // For Cloudflare workers, also check wrangler.toml if no port in dev script\n    if (configuredPort === null && wsProjectType === 'cloudflare') {\n      const wranglerTomlPath = join(workspacePath, 'wrangler.toml');\n      const wranglerJsoncPath = join(workspacePath, 'wrangler.jsonc');\n      configuredPort = await getWranglerDevPort(wranglerTomlPath) ||\n                       await getWranglerDevPort(wranglerJsoncPath) ||\n                       null;\n    }\n\n    // For Vite projects, check vite.config.ts for server.port\n    if (configuredPort === null && wsProjectType === 'vite') {\n      configuredPort = findViteConfigPort(workspacePath);\n    }\n\n    // Get default port for this project type\n    const defaultPort = getDefaultPort(wsProjectType);\n\n    portInfos.push({\n      workspace,\n      projectType: wsProjectType,\n      configuredPort,\n      defaultPort,\n    });\n  }\n\n  return portInfos;\n}\n\n/**\n * Detect project type for a specific workspace directory\n * Similar to detectProjectType but for individual workspaces\n */\nfunction detectWorkspaceProjectType(workspacePath: string): ProjectType {\n  if (\n    existsSync(join(workspacePath, 'next.config.js')) ||\n    existsSync(join(workspacePath, 'next.config.mjs')) ||\n    existsSync(join(workspacePath, 'next.config.ts'))\n  ) {\n    return 'nextjs';\n  }\n  if (existsSync(join(workspacePath, 'wrangler.toml')) || existsSync(join(workspacePath, 'wrangler.jsonc'))) {\n    return 'cloudflare';\n  }\n  if (\n    existsSync(join(workspacePath, 'vite.config.ts')) ||\n    existsSync(join(workspacePath, 'vite.config.js')) ||\n    existsSync(join(workspacePath, 'vite.config.mjs'))\n  ) {\n    return 'vite';\n  }\n\n  // Check package.json for elysia dependency\n  const packageJsonPath = join(workspacePath, 'package.json');\n  if (existsSync(packageJsonPath)) {\n    try {\n      const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n      if (pkg.dependencies?.elysia || pkg.devDependencies?.elysia) {\n        return 'elysia';\n      }\n    } catch {\n      // Ignore parse errors\n    }\n  }\n\n  return 'unknown';\n}\n\n/**\n * Detect project type\n */\nfunction detectProjectType(cwd: string): ProjectType {\n  if (existsSync(join(cwd, 'turbo.json'))) {\n    return 'turborepo';\n  }\n  if (\n    existsSync(join(cwd, 'next.config.js')) ||\n    existsSync(join(cwd, 'next.config.mjs')) ||\n    existsSync(join(cwd, 'next.config.ts'))\n  ) {\n    return 'nextjs';\n  }\n  if (existsSync(join(cwd, 'wrangler.toml')) || existsSync(join(cwd, 'wrangler.jsonc'))) {\n    return 'cloudflare';\n  }\n\n  // Check for Vite\n  if (\n    existsSync(join(cwd, 'vite.config.ts')) ||\n    existsSync(join(cwd, 'vite.config.js')) ||\n    existsSync(join(cwd, 'vite.config.mjs'))\n  ) {\n    return 'vite';\n  }\n\n  // Check for Elysia (Bun framework)\n  if (existsSync(join(cwd, 'bun.toml'))) {\n    return 'elysia';\n  }\n\n  // Or check package.json for elysia dependency\n  const packageJsonPath = join(cwd, 'package.json');\n  if (existsSync(packageJsonPath)) {\n    try {\n      const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n      if (pkg.dependencies?.elysia || pkg.devDependencies?.elysia) {\n        return 'elysia';\n      }\n    } catch {\n      // Ignore parse errors\n    }\n  }\n\n  return 'unknown';\n}\n\n/**\n * Ensure turbo.json has PORT_* patterns in globalPassThroughEnv\n * Turborepo filters out env vars not listed in globalPassThroughEnv,\n * so we need to add PORT_*, VITE_PORT_*, and WRANGLER_PORT_* patterns.\n * Uses skip-worktree to prevent committing this change.\n */\nasync function ensureTurboEnvPassthrough(cwd: string, messages: string[]): Promise<void> {\n  const turboJsonPath = join(cwd, 'turbo.json');\n  if (!existsSync(turboJsonPath)) {\n    return;\n  }\n\n  try {\n    const content = readFileSync(turboJsonPath, 'utf-8');\n    const turboConfig = JSON.parse(content);\n\n    const requiredPatterns = ['PORT_*', 'VITE_PORT_*', 'WRANGLER_PORT_*'];\n    const existing: string[] = turboConfig.globalPassThroughEnv || [];\n\n    const missing = requiredPatterns.filter(p => !existing.includes(p));\n    if (missing.length === 0) {\n      return; // Already has all required patterns\n    }\n\n    turboConfig.globalPassThroughEnv = [...existing, ...missing];\n    writeFileSync(turboJsonPath, JSON.stringify(turboConfig, null, 2) + '\\n');\n\n    // Use skip-worktree to prevent committing this change\n    const skipResult = await execCommand(`git update-index --skip-worktree \"${turboJsonPath}\"`);\n    if (skipResult.success) {\n      messages.push(`✓ Added ${missing.join(', ')} to turbo.json globalPassThroughEnv`);\n      messages.push(`  git skip-worktree set (changes won't be committed)`);\n    } else {\n      // Rollback if skip-worktree failed\n      writeFileSync(turboJsonPath, content);\n      messages.push(`⚠️ Could not set skip-worktree for turbo.json`);\n    }\n  } catch (error) {\n    messages.push(`⚠️ Could not update turbo.json: ${error}`);\n  }\n}\n\n/**\n * Modified package.json info for cleanup tracking\n */\ninterface ModifiedPackageJson {\n  path: string;\n  originalDevScript: string;\n}\n\n/**\n * Modify package.json dev scripts to use PORT env vars\n * This allows the hook to control ports via environment variables instead of hardcoded values.\n * Uses git skip-worktree to prevent these local changes from being committed.\n *\n * @param cwd - Root directory of the project\n * @param workspaces - Array of workspace paths relative to cwd\n * @param messages - Array to push status messages to\n * @returns Array of modified package.json paths for cleanup tracking\n */\nasync function modifyPackageJsonForDynamicPorts(\n  cwd: string,\n  workspaces: string[],\n  messages: string[]\n): Promise<ModifiedPackageJson[]> {\n  const modified: ModifiedPackageJson[] = [];\n\n  for (const ws of workspaces) {\n    const pkgPath = join(cwd, ws, 'package.json');\n    if (!existsSync(pkgPath)) {\n      continue;\n    }\n\n    try {\n      const pkgContent = readFileSync(pkgPath, 'utf-8');\n      const pkg = JSON.parse(pkgContent);\n\n      if (!pkg.scripts?.dev) {\n        continue;\n      }\n\n      const devScript = pkg.scripts.dev;\n      // Match --port XXXX or -p XXXX patterns (but not already using env vars)\n      const portMatch = devScript.match(/(?:--port|-p)\\s+(\\d+)/);\n\n      // Skip if already using env var pattern like ${PORT_WEB:-3000}\n      if (!portMatch || devScript.includes('${PORT_')) {\n        continue;\n      }\n\n      const originalPort = portMatch[1];\n      const wsName = basename(ws).toUpperCase().replace(/-/g, '_');\n\n      // Replace --port XXXX with --port ${PORT_WSNAME:-XXXX}\n      // This allows PORT_WEB, PORT_APP etc. env vars to override\n      const newDevScript = devScript.replace(\n        /(?:--port|-p)\\s+\\d+/,\n        `--port \\${PORT_${wsName}:-${originalPort}}`\n      );\n\n      pkg.scripts.dev = newDevScript;\n\n      // Write modified package.json\n      writeFileSync(pkgPath, JSON.stringify(pkg, null, 2) + '\\n');\n\n      // Mark file as skip-worktree so git ignores changes\n      // This prevents the port modifications from being committed\n      const skipResult = await execCommand(`git update-index --skip-worktree \"${pkgPath}\"`);\n      if (skipResult.success) {\n        modified.push({ path: pkgPath, originalDevScript: devScript });\n        messages.push(`✓ Modified ${ws}/package.json to use PORT_${wsName} env var`);\n        messages.push(`  git skip-worktree set (changes won't be committed)`);\n      } else {\n        // Rollback if skip-worktree failed\n        writeFileSync(pkgPath, pkgContent);\n        messages.push(`⚠️ Could not set skip-worktree for ${ws}/package.json`);\n      }\n    } catch (error) {\n      messages.push(`⚠️ Failed to modify ${ws}/package.json: ${error}`);\n    }\n  }\n\n  return modified;\n}\n\n/**\n * Extract port from package.json dev script\n * Looks for patterns like \"--port 3002\" or \"-p 3200\"\n */\nfunction extractPortFromDevScript(packageJsonPath: string): number | null {\n  if (!existsSync(packageJsonPath)) {\n    return null;\n  }\n\n  try {\n    const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n    const devScript = pkg.scripts?.dev;\n    if (!devScript) {\n      return null;\n    }\n\n    // Match --port XXXX or -p XXXX patterns\n    // Also handles env var syntax: --port ${PORT_APP:-3100} -> extracts 3100\n    const portMatch = devScript.match(/(?:--port|-p)\\s+(?:\\$\\{[^:]+:-)?(\\d+)/);\n    if (portMatch) {\n      return parseInt(portMatch[1], 10);\n    }\n\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Check if a workspace has a dev script that Turborepo will run\n * Used to avoid double-starting services (port conflicts)\n */\nfunction workspaceHasDevScript(workspacePath: string): boolean {\n  const packageJsonPath = join(workspacePath, 'package.json');\n  if (!existsSync(packageJsonPath)) {\n    return false;\n  }\n\n  try {\n    const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n    return typeof pkg.scripts?.dev === 'string';\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Get the default port for a project type\n * Returns null for unknown project types - never assume port 3000\n */\nfunction getDefaultPort(projectType: ProjectType): number | null {\n  switch (projectType) {\n    case 'cloudflare':\n      return 8787;\n    case 'vite':\n      return 5173;\n    case 'elysia':\n      return 3000;\n    case 'nextjs':\n      return 3000;\n    case 'turborepo':\n      // Turborepo doesn't have a single port - detect from workspaces\n      return null;\n    default:\n      // Never assume port 3000 for unknown project types\n      return null;\n  }\n}\n\n/**\n * Check if turbo.json has required env vars in globalPassThroughEnv\n * Returns list of missing env vars\n */\nfunction checkTurboEnvPassthrough(cwd: string): string[] {\n  const turboJsonPath = join(cwd, 'turbo.json');\n  if (!existsSync(turboJsonPath)) {\n    return [];\n  }\n\n  const requiredVars = [\n    'NEXT_PUBLIC_SUPABASE_URL',\n    'NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY',\n    'SUPABASE_SECRET_KEY',\n  ];\n\n  try {\n    const turboConfig = JSON.parse(readFileSync(turboJsonPath, 'utf-8'));\n    const passThrough = turboConfig.globalPassThroughEnv || [];\n\n    return requiredVars.filter((v) => !passThrough.includes(v));\n  } catch {\n    return requiredVars; // If can't parse, assume all missing\n  }\n}\n\n/**\n * Get the dev command for the project type\n */\nfunction getDevCommand(cwd: string, projectType: ProjectType): string | null {\n  switch (projectType) {\n    case 'turborepo': {\n      // Check if turbo.json has a dev task defined\n      const turboJsonPath = join(cwd, 'turbo.json');\n      if (existsSync(turboJsonPath)) {\n        try {\n          const turboConfig = JSON.parse(readFileSync(turboJsonPath, 'utf-8'));\n\n          // Check both old (pipeline) and new (tasks) format\n          const hasDev = turboConfig.pipeline?.dev || turboConfig.tasks?.dev;\n\n          if (hasDev) {\n            return 'npx turbo dev';\n          }\n        } catch {\n          // If parsing fails, fall through to default\n        }\n      }\n\n      // Fallback: try `npx turbo run dev` (works if workspaces define dev script)\n      return 'npx turbo run dev';\n    }\n\n    case 'nextjs': {\n      const pm = detectPackageManager(cwd);\n      const runCmd = pm === 'npm' ? 'npm run' : pm;\n      return `${runCmd} dev`;\n    }\n\n    case 'cloudflare':\n      // Use npx to run wrangler since it may be a local dependency\n      return 'npx wrangler dev';\n\n    case 'elysia':\n      // Elysia uses Bun\n      return 'bun run dev';\n\n    case 'vite': {\n      const pm = detectPackageManager(cwd);\n      const runCmd = pm === 'npm' ? 'npm run' : pm;\n      return `${runCmd} dev`;\n    }\n\n    default:\n      return null;\n  }\n}\n\n/**\n * Start dev server in background with comprehensive logging\n * Uses shell execution to properly handle commands like \"npx turbo dev\"\n */\nfunction startDevServerBackground(\n  cwd: string,\n  command: string,\n  logger: ReturnType<typeof createDebugLogger>,\n  options?: {\n    expectedPort?: number;\n    envVars?: Record<string, string>;\n  }\n): { pid: number; logs: { stdout: string; stderr: string }; actualPort?: number } | null {\n  try {\n    // Ensure .claude/logs directory exists\n    const logDir = join(cwd, '.claude', 'logs');\n    if (!existsSync(logDir)) {\n      mkdirSync(logDir, { recursive: true });\n    }\n\n    // Create log files for stdout/stderr\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n    const stdoutPath = join(logDir, `dev-server-stdout-${timestamp}.log`);\n    const stderrPath = join(logDir, `dev-server-stderr-${timestamp}.log`);\n\n    const stdoutFd = openSync(stdoutPath, 'a');\n    const stderrFd = openSync(stderrPath, 'a');\n\n    // Use sh -c to properly execute the full command string\n    // This fixes issues with commands like \"npx turbo dev\" where simple splitting fails\n    const child = spawn('sh', ['-c', command], {\n      cwd,\n      detached: true,\n      stdio: ['ignore', stdoutFd, stderrFd],\n      env: { ...process.env, ...options?.envVars },\n    });\n\n    // Log spawn errors\n    child.on('error', (err) => {\n      logger.logError(new Error(`Dev server spawn failed: ${err.message}`));\n    });\n\n    // Log early exits (within 10 seconds = crash)\n    const spawnTime = Date.now();\n    child.on('exit', (code, signal) => {\n      const runtime = Date.now() - spawnTime;\n      if (runtime < 10000 && code !== 0) {\n        logger.logError(\n          new Error(`Dev server exited early (${runtime}ms) with code ${code}, signal ${signal}`)\n        );\n      }\n    });\n\n    child.unref();\n\n    return {\n      pid: child.pid || 0,\n      logs: {\n        stdout: stdoutPath,\n        stderr: stderrPath,\n      },\n      actualPort: options?.expectedPort,\n    };\n  } catch (error) {\n    logger.logError(error as Error);\n    return null;\n  }\n}\n\n/**\n * Check if dev server is responding to HTTP requests\n */\nasync function checkServerHealth(port: number, timeoutMs: number = 30000): Promise<boolean> {\n  const startTime = Date.now();\n  const pollInterval = 1000;\n\n  while (Date.now() - startTime < timeoutMs) {\n    try {\n      const result = await execCommand(\n        `curl -s -o /dev/null -w \"%{http_code}\" http://localhost:${port}`,\n        { timeout: 2000 }\n      );\n\n      // Accept 2xx, 3xx, 404, or 405 (Next.js returns 404 on root before app is ready)\n      if (result.success) {\n        const statusCode = parseInt(result.stdout);\n        if (statusCode >= 200 && statusCode < 600) {\n          return true;\n        }\n      }\n    } catch {\n      // Ignore errors, server might not be ready yet\n    }\n\n    await new Promise((resolve) => setTimeout(resolve, pollInterval));\n  }\n\n  return false;\n}\n\n/**\n * Health check result for a workspace\n */\ninterface HealthCheckResult {\n  port: number;\n  workspace: string;\n  healthy: boolean;\n}\n\n/**\n * Check health of multiple workspace servers in parallel\n * Uses Promise.allSettled for concurrent health checks\n */\nasync function checkMultipleServerHealth(\n  ports: WorkspacePortInfo[]\n): Promise<HealthCheckResult[]> {\n  const healthPromises = ports.map(async (portInfo): Promise<HealthCheckResult> => {\n    const port = portInfo.configuredPort || portInfo.defaultPort;\n    if (!port) {\n      return {\n        port: 0,\n        workspace: portInfo.workspace,\n        healthy: false,\n      };\n    }\n\n    const healthy = await checkServerHealth(port);\n    return {\n      port,\n      workspace: portInfo.workspace,\n      healthy,\n    };\n  });\n\n  const results = await Promise.allSettled(healthPromises);\n  return results.map((result, index) => {\n    if (result.status === 'fulfilled') {\n      return result.value;\n    }\n    // On rejection, mark as unhealthy\n    const portInfo = ports[index];\n    return {\n      port: portInfo.configuredPort || portInfo.defaultPort || 0,\n      workspace: portInfo.workspace,\n      healthy: false,\n    };\n  });\n}\n\n/**\n * Information about a shared Supabase instance\n */\ninterface SupabaseInstanceInfo {\n  running: boolean;\n  sharedSession: boolean;\n  projectId: string | null;\n}\n\n/**\n * Detect if Supabase is already running (possibly from another session)\n * Parses supabase status output to extract instance information\n */\nasync function detectSharedSupabase(cwd: string): Promise<SupabaseInstanceInfo> {\n  const result = await execCommand('supabase status', { cwd, timeout: 10000 });\n\n  if (!result.success || !result.stdout.includes('API URL')) {\n    return {\n      running: false,\n      sharedSession: false,\n      projectId: null,\n    };\n  }\n\n  // Extract project ID from config\n  const projectId = getSupabaseProjectId(cwd);\n\n  // Check if this session started Supabase by looking for our marker\n  // If no marker exists but Supabase is running, it's a shared instance\n  const markerPath = join(cwd, '.claude', 'logs', 'supabase-session.json');\n  const sharedSession = !existsSync(markerPath);\n\n  return {\n    running: true,\n    sharedSession,\n    projectId,\n  };\n}\n\n// ==================== Worktree Instance Management ====================\n\n/**\n * Calculate dev server ports for a given slot\n */\nfunction calculateDevServerPorts(slot: number): DevServerPortSet {\n  const offset = slot * PORT_INCREMENT;\n  return {\n    nextjs: 3000 + offset,\n    vite: 5173 + offset,\n    cloudflare: 8787 + offset,\n  };\n}\n\n/**\n * Find available dev server ports by scanning at +10 increments\n * Checks actual port availability instead of using slot-based offsets\n */\nasync function findAvailableDevServerPorts(): Promise<DevServerPortSet> {\n  const [nextjsPort, vitePort, cloudflarePort] = await Promise.all([\n    findAvailablePortAt10Increments(3000, 25),\n    findAvailablePortAt10Increments(5173, 25),\n    findAvailablePortAt10Increments(8787, 25),\n  ]);\n\n  return {\n    nextjs: nextjsPort ?? 3000,\n    vite: vitePort ?? 5173,\n    cloudflare: cloudflarePort ?? 8787,\n  };\n}\n\n/**\n * Determine the Supabase instance configuration for this session\n * Handles worktree detection, port allocation, and instance reuse\n */\nasync function determineSupabaseInstance(\n  cwd: string,\n  messages: string[]\n): Promise<{\n  slot: number;\n  supabasePorts: SupabasePortSet;\n  devServerPorts: DevServerPortSet;\n  worktreeInfo: WorktreeInfo;\n  needsNewInstance: boolean;\n  existingSession: WorktreeSupabaseSession | null;\n}> {\n  // Detect if we're in a worktree\n  const worktreeInfo = detectWorktree(cwd);\n\n  if (worktreeInfo.isWorktree) {\n    messages.push(`ℹ️  Worktree detected: ${worktreeInfo.worktreeName}`);\n  }\n\n  // Check for existing worktree session\n  const existingSession = await loadWorktreeSupabaseSession(cwd, worktreeInfo.worktreeId);\n\n  // Only reuse session if it's from the SAME Claude session (same session_id)\n  // This prevents port conflicts when multiple sessions run in the same worktree\n  if (existingSession && existingSession.running && existingSession.sessionId) {\n    // Check if the containers are actually running before reusing\n    try {\n      const result = await execAsync(\n        `docker ps -q --filter \"name=supabase_.*_${existingSession.worktreeProjectId}\"`,\n        { timeout: 5000 }\n      );\n      if (result.stdout?.trim()) {\n        // Containers exist - reuse this session\n        messages.push(`✓ Found existing session (slot ${existingSession.slot})`);\n        return {\n          slot: existingSession.slot,\n          supabasePorts: existingSession.supabasePorts,\n          devServerPorts: existingSession.devServerPorts,\n          worktreeInfo,\n          needsNewInstance: false,\n          existingSession,\n        };\n      }\n      // Session file exists but containers are gone - proceed to allocate new\n      messages.push(`ℹ️  Previous session containers not running, allocating new instance`);\n    } catch {\n      // Docker check failed, try to reuse session anyway\n      messages.push(`✓ Found existing session (slot ${existingSession.slot})`);\n      return {\n        slot: existingSession.slot,\n        supabasePorts: existingSession.supabasePorts,\n        devServerPorts: existingSession.devServerPorts,\n        worktreeInfo,\n        needsNewInstance: false,\n        existingSession,\n      };\n    }\n  }\n\n  // Check port usage on default ports\n  const defaultUsage = await checkSupabasePortUsage();\n\n  if (defaultUsage.allRunning) {\n    // All default ports in use - need new instance\n    // Use availability-based allocation: find next available container name AND ports\n    messages.push('ℹ️  Default Supabase ports in use, allocating new instance...');\n\n    // Show what's using the ports (best effort)\n    const processInfos = await getProcessesOnPorts(defaultUsage.runningPorts.slice(0, 3));\n    for (const info of processInfos) {\n      if (info.found) {\n        messages.push(`  Port ${info.port}: ${formatProcessInfo(info)}`);\n      }\n    }\n\n    // Get base project ID for container name check\n    const configPath = getSupabaseConfigPath(cwd);\n    const baseProjectId = getOriginalProjectId(configPath, worktreeInfo.worktreeId) || 'supabase';\n\n    // Find next available container name based on what's actually running\n    const { slot: containerSlot } = await findAvailableContainerName(baseProjectId);\n\n    // Also verify ports are available for this slot\n    let slot = containerSlot;\n    if (slot > 0) {\n      const slotUsage = await checkSupabasePortUsage(calculatePortSet(slot));\n      if (slotUsage.allRunning || slotUsage.someRunning) {\n        // Container name available but ports aren't - find next slot with both\n        const nextSlot = await findAvailableSlot();\n        if (nextSlot !== null) {\n          slot = nextSlot;\n        }\n      }\n    }\n\n    if (slot === 0 && defaultUsage.allRunning) {\n      // Slot 0 is taken and no container name found - find by port availability\n      const nextSlot = await findAvailableSlot();\n      if (nextSlot !== null) {\n        slot = nextSlot;\n      } else {\n        messages.push('⚠️ No available slots (all in use)');\n        return {\n          slot: 0,\n          supabasePorts: calculatePortSet(0),\n          devServerPorts: calculateDevServerPorts(0),\n          worktreeInfo,\n          needsNewInstance: false,\n          existingSession: null,\n        };\n      }\n    }\n\n    messages.push(`  Allocated slot ${slot}`);\n    return {\n      slot,\n      supabasePorts: calculatePortSet(slot),\n      devServerPorts: calculateDevServerPorts(slot),\n      worktreeInfo,\n      needsNewInstance: true,\n      existingSession: null,\n    };\n  } else if (defaultUsage.someRunning) {\n    // Partial - stale processes, clean up\n    messages.push('⚠️ Stale Supabase processes detected, cleaning up...');\n    for (const port of defaultUsage.runningPorts) {\n      const killed = await killProcessOnPort(port);\n      if (killed) {\n        messages.push(`  ✓ Freed port ${port}`);\n      }\n    }\n    // Start fresh on default ports\n    return {\n      slot: 0,\n      supabasePorts: calculatePortSet(0),\n      devServerPorts: calculateDevServerPorts(0),\n      worktreeInfo,\n      needsNewInstance: true,\n      existingSession: null,\n    };\n  }\n\n  // Nothing running - start on default ports (slot 0)\n  return {\n    slot: 0,\n    supabasePorts: calculatePortSet(0),\n    devServerPorts: calculateDevServerPorts(0),\n    worktreeInfo,\n    needsNewInstance: true,\n    existingSession: null,\n  };\n}\n\n/**\n * Clean up orphaned Supabase sessions\n * Finds sessions marked as running but whose worktree no longer exists,\n * stops their containers, and marks them as stopped.\n *\n * IMPORTANT: This function scans ALL worktrees (not just current) to avoid\n * killing containers from other active sessions. A different session ID is\n * NOT a reason to kill - multi-session support requires multiple sessions\n * to coexist.\n *\n * Only truly orphaned containers are cleaned up:\n * - Session file exists but worktree path no longer exists\n * - Running containers with no matching session file anywhere\n */\nasync function cleanupOrphanedSessions(\n  cwd: string,\n  messages: string[],\n  _currentSessionId: string\n): Promise<void> {\n  let orphansFound = 0;\n\n  // Build a set of valid running project IDs from ALL worktree session files\n  // This is critical for multi-session support - we must not kill containers\n  // from other active sessions running in sibling worktrees\n  const validRunningProjectIds = new Set<string>();\n  const sessionProjectIds = new Map<string, string>(); // projectId -> sessionPath\n\n  // Find all worktrees to scan for session files\n  // Structure: /home/ben/.claude-worktrees/<repo-name>/<worktree-name>/.claude/logs/\n  const worktreesToScan: string[] = [];\n\n  // Always include current worktree\n  worktreesToScan.push(cwd);\n\n  // Try to find sibling worktrees (same repo, different worktree names)\n  try {\n    // If we're in a worktree, go up to find siblings\n    // e.g., /home/ben/.claude-worktrees/nodes-md/claude-foo/ -> /home/ben/.claude-worktrees/nodes-md/\n    const parentDir = dirname(cwd);\n    if (parentDir.includes('.claude-worktrees')) {\n      const siblings = readdirSync(parentDir, { withFileTypes: true })\n        .filter((d) => d.isDirectory() && d.name !== basename(cwd))\n        .map((d) => join(parentDir, d.name));\n      worktreesToScan.push(...siblings);\n    }\n  } catch {\n    // Couldn't enumerate siblings, just use current worktree\n  }\n\n  // Phase 1: Scan all worktrees for session files\n  for (const worktreePath of worktreesToScan) {\n    const logsDir = join(worktreePath, '.claude', 'logs');\n    if (!existsSync(logsDir)) {\n      continue;\n    }\n\n    let files: string[];\n    try {\n      files = readdirSync(logsDir).filter((f) => f.startsWith('supabase-session-'));\n    } catch {\n      files = [];\n    }\n\n    for (const file of files) {\n      try {\n        const sessionPath = join(logsDir, file);\n        const content = readFileSync(sessionPath, 'utf-8');\n        const session = JSON.parse(content) as WorktreeSupabaseSession;\n\n        if (session.worktreeProjectId) {\n          sessionProjectIds.set(session.worktreeProjectId, sessionPath);\n        }\n\n        // Only clean up if worktree path no longer exists (truly orphaned)\n        // DO NOT clean up just because it's a different session ID!\n        const isOrphanedPath = session.worktreePath && !existsSync(session.worktreePath);\n\n        if (session.running && isOrphanedPath) {\n          orphansFound++;\n          messages.push(`🧹 Cleaning orphaned path: ${session.worktreeProjectId || session.worktreeId}`);\n\n          // Try to stop containers with this project ID\n          if (session.worktreeProjectId) {\n            try {\n              await execAsync(\n                `docker ps -q --filter \"name=supabase_.*_${session.worktreeProjectId}\" | xargs -r docker stop`,\n                { timeout: 30000 }\n              );\n              await execAsync(\n                `docker ps -aq --filter \"name=supabase_.*_${session.worktreeProjectId}\" | xargs -r docker rm`,\n                { timeout: 30000 }\n              );\n            } catch {\n              // Containers may already be stopped or removed\n            }\n          }\n\n          // Mark session as stopped\n          session.running = false;\n          const { writeFileSync } = await import('fs');\n          writeFileSync(sessionPath, JSON.stringify(session, null, 2));\n          messages.push(`  ✓ Marked session as stopped`);\n        } else if (session.running) {\n          // This is a valid running session (from any Claude session)\n          // Add to valid set so we don't kill it in phase 2\n          if (session.worktreeProjectId) {\n            validRunningProjectIds.add(session.worktreeProjectId);\n          }\n        }\n      } catch {\n        // Skip malformed session files\n      }\n    }\n  }\n\n  // Phase 2: Detect running containers without matching session files ANYWHERE\n  // This catches containers orphaned due to session file corruption/deletion\n  try {\n    const result = await execAsync('docker ps --format \"{{.Names}}\" --filter \"name=supabase_\"', {\n      timeout: 10000,\n    });\n\n    if (result.stdout) {\n      // Extract unique project IDs from container names\n      // Container naming: supabase_{service}_{projectId}\n      const containerNames = result.stdout.split('\\n').filter(Boolean);\n      const runningProjectIds = new Set<string>();\n\n      for (const name of containerNames) {\n        // Extract project ID from container name (last segment after underscore)\n        const parts = name.split('_');\n        if (parts.length >= 3) {\n          const projectId = parts.slice(2).join('_');\n          runningProjectIds.add(projectId);\n        }\n      }\n\n      // Find containers without matching valid session files\n      for (const projectId of runningProjectIds) {\n        // Skip if it's a valid running session (from ANY worktree)\n        if (validRunningProjectIds.has(projectId)) {\n          continue;\n        }\n\n        // Skip if there's a session file marked as running\n        const sessionPath = sessionProjectIds.get(projectId);\n        if (sessionPath) {\n          try {\n            const content = readFileSync(sessionPath, 'utf-8');\n            const session = JSON.parse(content) as WorktreeSupabaseSession;\n            if (session.running) {\n              continue; // Session exists and is marked running, don't kill\n            }\n          } catch {\n            // Session file is corrupted, treat as orphan\n          }\n        }\n\n        // This is an orphaned container without a valid session file\n        orphansFound++;\n        messages.push(`🧹 Cleaning orphaned container: ${projectId}`);\n\n        try {\n          await execAsync(`docker ps -q --filter \"name=supabase_.*_${projectId}\" | xargs -r docker stop`, {\n            timeout: 30000,\n          });\n          await execAsync(`docker ps -aq --filter \"name=supabase_.*_${projectId}\" | xargs -r docker rm`, {\n            timeout: 30000,\n          });\n          messages.push(`  ✓ Stopped orphaned containers`);\n        } catch {\n          messages.push(`  ⚠️ Failed to stop some containers`);\n        }\n      }\n    }\n  } catch {\n    // Docker not available or failed - skip container scanning\n  }\n\n  if (orphansFound > 0) {\n    messages.push(`✓ Cleaned up ${orphansFound} orphaned session(s)/container(s)`);\n  }\n}\n\n/**\n * Find the next available Supabase container name based on what's actually running in Docker\n * Always uses suffixed naming: base-0, base-1, base-2, etc. (never bare project name)\n */\nasync function findAvailableContainerName(baseProjectId: string): Promise<{ name: string; slot: number }> {\n  try {\n    const result = await execAsync('docker ps --format \"{{.Names}}\" --filter \"name=supabase_\"', {\n      timeout: 10000,\n    });\n\n    const runningContainers = result.stdout?.split('\\n').filter(Boolean) || [];\n\n    // Extract all running project IDs\n    const runningProjectIds = new Set<string>();\n    for (const name of runningContainers) {\n      const parts = name.split('_');\n      if (parts.length >= 3) {\n        const projectId = parts.slice(2).join('_');\n        runningProjectIds.add(projectId);\n      }\n    }\n\n    // Find next available suffix: constellos-0, constellos-1, constellos-2, etc.\n    // Always use -N suffix for consistent naming (never bare project name)\n    for (let i = 0; i < 10; i++) {\n      const candidate = `${baseProjectId}-${i}`;\n      if (!runningProjectIds.has(candidate)) {\n        return { name: candidate, slot: i };\n      }\n    }\n\n    // All slots taken, fall back to slot 0 (will likely fail but let user know)\n    return { name: `${baseProjectId}-0`, slot: 0 };\n  } catch {\n    // Docker not available - assume slot 0 is available\n    return { name: `${baseProjectId}-0`, slot: 0 };\n  }\n}\n\n/**\n * Start Supabase with custom ports using /tmp/ directory\n * Creates a temporary config directory with symlinks, starts Supabase, and saves session state.\n * Does NOT modify the original config.toml.\n */\nasync function startWorktreeSupabase(\n  cwd: string,\n  slot: number,\n  supabasePorts: SupabasePortSet,\n  devServerPorts: DevServerPortSet,\n  worktreeInfo: WorktreeInfo,\n  messages: string[],\n  sessionId: string\n): Promise<{ success: boolean; tmpConfigDir?: string; projectId?: string }> {\n  const configPath = getSupabaseConfigPath(cwd);\n  const originalSupabaseDir = join(cwd, 'supabase');\n\n  // Read original project_id from config.toml\n  const originalProjectId = getOriginalProjectId(configPath, worktreeInfo.worktreeId);\n  if (!originalProjectId) {\n    messages.push('⚠️ Could not read project_id from config.toml');\n    return { success: false };\n  }\n\n  // Generate worktree-specific project_id\n  const worktreeProjectId = generateWorktreeProjectId(originalProjectId, slot);\n\n  // Create temporary Supabase directory with symlinks\n  // Note: Directory is named after projectId (not worktreeId) so Supabase CLI\n  // creates containers with correct names like supabase_*_constellos-1\n  let tmpConfig;\n  try {\n    tmpConfig = createTmpSupabaseDir(\n      worktreeProjectId,\n      originalSupabaseDir,\n      supabasePorts\n    );\n    messages.push(`✓ Created temporary Supabase config at ${tmpConfig.tmpDir}`);\n    messages.push(`  Project ID: ${originalProjectId} → ${worktreeProjectId}`);\n    messages.push(`  Symlinks: seed.sql, migrations/, functions/, templates/`);\n  } catch (error) {\n    messages.push(`⚠️ Failed to create tmp config directory: ${error}`);\n    return { success: false };\n  }\n\n  // Add to .gitignore if needed\n  const addedToGitignore = addToGitignore(cwd);\n  if (addedToGitignore) {\n    messages.push('✓ Added /tmp/supabase-* to .gitignore');\n  }\n\n  // Build exclude flags for disabled services (using tmp config)\n  const excludeFlags = buildExcludeFlags(tmpConfig.configPath);\n  const startCommand = `supabase start --workdir ${tmpConfig.tmpDir}${excludeFlags}`;\n\n  if (excludeFlags) {\n    const excluded = excludeFlags.replace(' --exclude ', '').split(',');\n    messages.push(`⚡ Optimized: Skipping services: ${excluded.join(', ')}`);\n  }\n\n  // Start Supabase using the tmp directory\n  messages.push(`Starting Supabase: ${startCommand}`);\n  const startResult = await execCommand(startCommand, { cwd, timeout: 300000 });\n\n  if (!startResult.success) {\n    messages.push(`⚠️ Failed to start Supabase: ${startResult.stderr}`);\n    return { success: false, tmpConfigDir: tmpConfig.tmpDir };\n  }\n\n  messages.push('✓ Supabase started with isolated containers');\n  messages.push(`  Project ID: ${worktreeProjectId}`);\n  messages.push(`  Containers: supabase_*_${worktreeProjectId}`);\n  messages.push(`  API: http://localhost:${supabasePorts.api}`);\n  messages.push(`  Studio: http://localhost:${supabasePorts.studio}`);\n  messages.push(`  Inbucket (email): http://localhost:${supabasePorts.inbucket}`);\n\n  // Save exact container IDs for scoped cleanup in SessionEnd hook\n  // This prevents accidentally deleting containers from other sessions\n  try {\n    const containersResult = await execAsync(\n      `docker ps -q --filter \"label=com.supabase.cli.project=${worktreeProjectId}\"`,\n      { timeout: 10000 }\n    );\n    const containerIds = containersResult.stdout?.split('\\n').filter(Boolean) || [];\n\n    if (containerIds.length > 0) {\n      const dockerConfigPath = join(cwd, '.claude', 'logs', 'docker-containers.json');\n      const dockerConfig = {\n        projectId: worktreeProjectId,\n        containerIds,\n        volumeNames: [\n          `supabase_db_${worktreeProjectId}`,\n          `supabase_storage_${worktreeProjectId}`,\n        ],\n        tmpConfigDir: tmpConfig.tmpDir,\n        savedAt: new Date().toISOString(),\n      };\n      writeFileSync(dockerConfigPath, JSON.stringify(dockerConfig, null, 2));\n      messages.push(`  ✓ Saved ${containerIds.length} container IDs for cleanup`);\n    }\n  } catch {\n    // Best effort - don't fail if we can't save container IDs\n    messages.push('  ⚠️ Could not save container IDs (cleanup may be less precise)');\n  }\n\n  // Save session state with project IDs and tmp directory\n  const session: WorktreeSupabaseSession = {\n    worktreeId: worktreeInfo.worktreeId,\n    worktreePath: worktreeInfo.worktreePath,\n    slot,\n    supabasePorts,\n    devServerPorts,\n    startedAt: new Date().toISOString(),\n    configBackupPath: '', // No longer using backups - using tmp dir instead\n    running: true,\n    originalProjectId,\n    worktreeProjectId,\n    sessionId,\n    tmpConfigDir: tmpConfig.tmpDir,\n    originalSupabaseDir,\n  };\n\n  await saveWorktreeSupabaseSession(cwd, session);\n\n  return { success: true, tmpConfigDir: tmpConfig.tmpDir, projectId: worktreeProjectId };\n}\n\n// ==================== Dependency Installation ====================\n\ntype PackageManager = 'bun' | 'npm' | 'pnpm' | 'yarn';\n\n/**\n * Get install command for package manager\n */\nfunction getInstallCommand(pm: PackageManager): string {\n  const commands: Record<PackageManager, string> = {\n    bun: 'bun install',\n    npm: 'npm install',\n    pnpm: 'pnpm install',\n    yarn: 'yarn install',\n  };\n  return commands[pm];\n}\n\n/**\n * Check if we should skip install (node_modules exists and is recent)\n */\nfunction shouldSkipInstall(cwd: string): boolean {\n  // Skip if SKIP_INSTALL env var is set\n  if (process.env.SKIP_INSTALL === '1') {\n    return true;\n  }\n\n  // Check if package.json exists (if not, not a Node.js project)\n  const packageJsonPath = join(cwd, 'package.json');\n  if (!existsSync(packageJsonPath)) {\n    return true;\n  }\n\n  // Check if node_modules exists\n  const nodeModulesPath = join(cwd, 'node_modules');\n  if (!existsSync(nodeModulesPath)) {\n    return false;\n  }\n\n  // Check if node_modules is recent (within 1 hour)\n  try {\n    const stats = statSync(nodeModulesPath);\n    const ageMs = Date.now() - stats.mtimeMs;\n    const oneHourMs = 60 * 60 * 1000;\n    return ageMs < oneHourMs;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Install dependencies with package manager\n * @returns Success status and install time in seconds (or null if skipped)\n */\nasync function installDependencies(\n  cwd: string,\n  _logger: ReturnType<typeof createDebugLogger>\n): Promise<{ success: boolean; skipped: boolean; timeSeconds?: number; error?: string }> {\n  // Skip if conditions met\n  if (shouldSkipInstall(cwd)) {\n    return { success: true, skipped: true };\n  }\n\n  const packageManager = detectPackageManager(cwd) as PackageManager;\n  const installCmd = getInstallCommand(packageManager);\n\n  const startTime = Date.now();\n  try {\n    await execAsync(installCmd, {\n      cwd,\n      timeout: 120000, // 2 minutes\n    });\n    const timeSeconds = ((Date.now() - startTime) / 1000).toFixed(1);\n    return { success: true, skipped: false, timeSeconds: parseFloat(timeSeconds) };\n  } catch (error: unknown) {\n    const err = error as { message?: string };\n    const errorMsg = err.message || 'Unknown error';\n    return { success: false, skipped: false, error: errorMsg };\n  }\n}\n\n// ==================== Main Handler ====================\n\n/**\n * SessionStart hook handler\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'install-start-supabase-next', true);\n  const isRemote = isRemoteEnvironment();\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n      is_remote: isRemote,\n    });\n\n    // ========== Step 1: Check/Install Supabase CLI ==========\n    const supabaseAvailable = await isCommandAvailable('supabase');\n\n    if (!supabaseAvailable) {\n      if (isRemote) {\n        messages.push('Installing Supabase CLI...');\n        const installResult = await installSupabaseCLI();\n        messages.push(installResult.success ? '✓ Supabase CLI installed' : `⚠️ ${installResult.stderr}`);\n      } else {\n        messages.push('⚠️ Supabase CLI not installed');\n        messages.push('  Install: npm install -g supabase');\n\n        // Log output before early return\n        await logger.logOutput({\n          success: false,\n          is_remote: isRemote,\n          message: messages.join('\\n'),\n          reason: 'cli_not_installed',\n        });\n\n        // Return early - can't proceed without CLI\n        return {\n          hookSpecificOutput: {\n            hookEventName: 'SessionStart',\n            additionalContext: messages.join('\\n'),\n          },\n        };\n      }\n    } else {\n      const version = await getSupabaseVersion();\n      messages.push(`✓ Supabase CLI v${version || 'unknown'}`);\n    }\n\n    // ========== Step 2: Check if Supabase is initialized ==========\n    if (!isSupabaseInitialized(input.cwd)) {\n      messages.push('');\n      messages.push('ℹ️ Supabase not initialized in this project');\n      messages.push('  Run: supabase init');\n\n      // Log output before early return\n      await logger.logOutput({\n        success: false,\n        is_remote: isRemote,\n        message: messages.join('\\n'),\n        reason: 'not_initialized',\n      });\n\n      // Return early - can't proceed without initialization\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: messages.join('\\n'),\n        },\n      };\n    }\n\n    // Read project_id from config.toml\n    const projectId = getSupabaseProjectId(input.cwd);\n    if (projectId) {\n      messages.push(`✓ Supabase project: ${projectId}`);\n    }\n\n    // Show multi-instance warning if Supabase is running\n    if (projectId && await isSupabaseRunning(input.cwd)) {\n      messages.push(`ℹ️  Using Supabase instance: ${projectId}`);\n    }\n\n    // ========== Step 3: Check/Start Docker ==========\n    let dockerRunning = false;\n    let skipSupabase = false;\n\n    // Check if Docker is installed first\n    const dockerInstalled = await isDockerInstalled();\n    if (!dockerInstalled) {\n      messages.push('');\n      messages.push('ℹ️ Docker not installed - skipping Supabase setup');\n      messages.push('  Install Docker: https://docker.com/products/docker-desktop');\n      skipSupabase = true;\n    } else {\n      dockerRunning = await isDockerRunning();\n\n      if (!dockerRunning) {\n        messages.push('');\n        messages.push('Docker not running, attempting to start...');\n        const started = await startDocker();\n\n        if (started) {\n          messages.push('Waiting for Docker to be ready...');\n          dockerRunning = await waitForDocker(30000);\n        }\n\n        if (!dockerRunning) {\n          messages.push('⚠️ Could not start Docker');\n          messages.push('  Please start Docker Desktop manually');\n          skipSupabase = true;\n        } else {\n          messages.push('✓ Docker started');\n        }\n      } else {\n        messages.push('✓ Docker running');\n      }\n    }\n\n    // ========== Step 3.5: Clean up orphaned sessions ==========\n    // Find sessions marked as running but whose worktree no longer exists\n    // or sessions from a different Claude session\n    await cleanupOrphanedSessions(input.cwd, messages, input.session_id);\n\n    // ========== Step 4: Check/Start Supabase (Worktree-Aware) ==========\n    // Determine instance configuration based on worktree status and port usage\n    const instanceConfig = await determineSupabaseInstance(input.cwd, messages);\n    let supabaseRunning = false;\n    // Track worktree slot for dev server port allocation (slot 0 = default, slot N = +N*10 offset)\n    const worktreeSlot = instanceConfig.slot;\n    // Track tmp config directory for supabase status commands\n    let supabaseTmpDir: string | undefined;\n\n    if (dockerRunning && !skipSupabase) {\n      if (instanceConfig.needsNewInstance) {\n        // Start new Supabase instance (possibly with custom ports for worktree)\n        messages.push('');\n        const startResult = await startWorktreeSupabase(\n          input.cwd,\n          instanceConfig.slot,\n          instanceConfig.supabasePorts,\n          instanceConfig.devServerPorts,\n          instanceConfig.worktreeInfo,\n          messages,\n          input.session_id\n        );\n        supabaseRunning = startResult.success;\n        supabaseTmpDir = startResult.tmpConfigDir;\n      } else if (instanceConfig.existingSession) {\n        // Use existing worktree session\n        messages.push('✓ Supabase already running (worktree session)');\n        messages.push(`  API: http://localhost:${instanceConfig.supabasePorts.api}`);\n        messages.push(`  Studio: http://localhost:${instanceConfig.supabasePorts.studio}`);\n        supabaseRunning = true;\n        supabaseTmpDir = instanceConfig.existingSession.tmpConfigDir;\n      } else {\n        // Check if default Supabase is running\n        const supabaseInfo = await detectSharedSupabase(input.cwd);\n        supabaseRunning = supabaseInfo.running;\n        if (supabaseRunning) {\n          if (supabaseInfo.sharedSession) {\n            messages.push('ℹ️ Using shared Supabase instance from another session');\n          } else {\n            messages.push('✓ Supabase already running');\n          }\n        }\n      }\n    }\n\n    // ========== Step 5: Export Environment Variables ==========\n    const projectType = detectProjectType(input.cwd);\n\n    // Pre-calculate dev server ports for URL generation\n    // This ensures env vars include correct URLs before servers start\n    let preCalculatedPorts = await findAvailableDevServerPorts();\n\n    if (projectType === 'turborepo') {\n      const workspaces = detectTurborepoWorkspaces(input.cwd);\n      if (workspaces && workspaces.length > 0) {\n        // Collect Supabase vars if running\n        let supabaseVars: Record<string, string> | undefined;\n        if (supabaseRunning) {\n          const result = await exportSupabaseEnvVars(input.cwd, supabaseTmpDir);\n          if (result.success) {\n            supabaseVars = result.vars;\n            // Show deprecation warnings if any\n            if (result.warnings.length > 0) {\n              messages.push(...result.warnings);\n            }\n          }\n        }\n\n        // Distribute all env vars (Supabase + Vercel + App URLs) to all workspaces\n        const envMessages = await distributeAllEnvVars(input.cwd, workspaces, supabaseVars, preCalculatedPorts);\n        messages.push(...envMessages);\n      }\n    } else if (supabaseRunning) {\n      // For single projects: export Supabase vars to root\n      const result = await exportSupabaseEnvVars(input.cwd, supabaseTmpDir);\n      if (result.success && Object.keys(result.vars).length > 0) {\n        // Show deprecation warnings if any\n        if (result.warnings.length > 0) {\n          messages.push(...result.warnings);\n        }\n\n        // Use distributeEnvVars for consistent handling\n        const distResult = await distributeEnvVars(\n          input.cwd,\n          { supabaseVars: result.vars, vercelVars: {} },\n          {\n            createIfMissing: true,\n            preserveExisting: true,\n            alwaysOverwriteKeys: [\n              'NEXT_PUBLIC_SUPABASE_URL',\n              'NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY',\n              'SUPABASE_SECRET_KEY',\n              'VITE_SUPABASE_URL',\n              'VITE_SUPABASE_PUBLISHABLE_KEY',\n            ]\n          }\n        );\n\n        if (distResult.nextjs) {\n          messages.push('✓ Environment variables written to .env.local');\n        }\n        if (distResult.vite) {\n          messages.push('✓ Environment variables written to .env.local (Vite)');\n        }\n        if (distResult.cloudflare) {\n          messages.push('✓ Environment variables written to dev.vars');\n        }\n      }\n    }\n\n    // ========== Step 5.5: Install Dependencies ==========\n    messages.push('');\n    const installResult = await installDependencies(input.cwd, logger);\n\n    if (installResult.skipped) {\n      messages.push('✓ Dependencies already installed (skipped)');\n    } else if (installResult.success && installResult.timeSeconds !== undefined) {\n      const packageManager = detectPackageManager(input.cwd);\n      messages.push(`✓ Dependencies installed (${packageManager} install - ${installResult.timeSeconds}s)`);\n    } else if (!installResult.success) {\n      messages.push(`⚠️ Dependency installation failed: ${installResult.error}`);\n      messages.push('  Continuing anyway - you may need to run install manually');\n    }\n\n    // ========== Step 6: Detect Project Type and Start Dev Server ==========\n    const devCommand = getDevCommand(input.cwd, projectType);\n\n    if (devCommand) {\n      messages.push('');\n      messages.push(`Detected project type: ${projectType}`);\n\n      // Show workspace info for Turborepo\n      if (projectType === 'turborepo') {\n        const workspaces = detectTurborepoWorkspaces(input.cwd);\n        if (workspaces && workspaces.length > 0) {\n          // Detect ports for all workspaces\n          const workspacePorts = await detectWorkspacePorts(input.cwd, workspaces);\n\n          // Apply worktree port offsets if in a non-default slot\n          if (worktreeSlot > 0) {\n            messages.push(`  Using worktree slot ${worktreeSlot} (ports offset by ${worktreeSlot * PORT_INCREMENT})`);\n            for (const wp of workspacePorts) {\n              if (wp.configuredPort) {\n                wp.configuredPort += worktreeSlot * PORT_INCREMENT;\n              }\n              if (wp.defaultPort) {\n                wp.defaultPort += worktreeSlot * PORT_INCREMENT;\n              }\n            }\n          }\n\n          const portSummary = workspacePorts\n            .map(p => `${p.workspace}:${p.configuredPort || p.defaultPort || '?'}`)\n            .join(', ');\n          messages.push(`  Workspaces: ${portSummary}`);\n\n          // Re-check port availability and find alternatives if needed\n          // NEVER kill processes - other Claude sessions may be using these ports\n          const finalPorts = { ...preCalculatedPorts };\n\n          const nextjsAvailable = await isPortAvailable(finalPorts.nextjs);\n          if (!nextjsAvailable) {\n            const newPort = await findAvailablePortAt10Increments(finalPorts.nextjs + 10, 25);\n            if (newPort) {\n              messages.push(`  ℹ️ Port ${finalPorts.nextjs} in use, using ${newPort}`);\n              finalPorts.nextjs = newPort;\n            } else {\n              messages.push(`  ⚠️ Could not find available Next.js port after ${finalPorts.nextjs}`);\n            }\n          }\n\n          const viteAvailable = await isPortAvailable(finalPorts.vite);\n          if (!viteAvailable) {\n            const newPort = await findAvailablePortAt10Increments(finalPorts.vite + 10, 25);\n            if (newPort) {\n              messages.push(`  ℹ️ Port ${finalPorts.vite} in use, using ${newPort}`);\n              finalPorts.vite = newPort;\n            } else {\n              messages.push(`  ⚠️ Could not find available Vite port after ${finalPorts.vite}`);\n            }\n          }\n\n          const cloudflareAvailable = await isPortAvailable(finalPorts.cloudflare);\n          if (!cloudflareAvailable) {\n            const newPort = await findAvailablePortAt10Increments(finalPorts.cloudflare + 10, 25);\n            if (newPort) {\n              messages.push(`  ℹ️ Port ${finalPorts.cloudflare} in use, using ${newPort}`);\n              finalPorts.cloudflare = newPort;\n            } else {\n              messages.push(`  ⚠️ Could not find available Cloudflare port after ${finalPorts.cloudflare}`);\n            }\n          }\n\n          // Update preCalculatedPorts to use the final allocated ports\n          preCalculatedPorts = finalPorts;\n\n          // Show which ports will be used vs configured\n          if (finalPorts.nextjs !== 3000 || finalPorts.vite !== 5173 || finalPorts.cloudflare !== 8787) {\n            messages.push(`  Using ports: Next.js=${finalPorts.nextjs}, Vite=${finalPorts.vite}, Cloudflare=${finalPorts.cloudflare}`);\n          }\n\n          // Check for missing env passthrough vars\n          const missingEnvVars = checkTurboEnvPassthrough(input.cwd);\n          if (missingEnvVars.length > 0) {\n            messages.push('');\n            messages.push('⚠️ turbo.json missing globalPassThroughEnv for:');\n            messages.push(`   ${missingEnvVars.join(', ')}`);\n            messages.push('  Add to turbo.json: \"globalPassThroughEnv\": [...]');\n          }\n\n          // Check for MCP worker and start it separately (only if Turborepo won't handle it)\n          const mcpWorkspace = workspaces.find((w) => w.includes('mcp'));\n          if (mcpWorkspace) {\n            const mcpPath = join(input.cwd, mcpWorkspace);\n            const wranglerTomlPath = join(mcpPath, 'wrangler.toml');\n            const wranglerJsoncPath = join(mcpPath, 'wrangler.jsonc');\n\n            // Skip if workspace has a dev script - Turborepo will start it via `turbo dev`\n            const turboWillStart = workspaceHasDevScript(mcpPath);\n            if (turboWillStart) {\n              messages.push('');\n              messages.push(`ℹ️ MCP worker (${mcpWorkspace}) will be started by Turborepo`);\n            } else if (existsSync(wranglerTomlPath) || existsSync(wranglerJsoncPath)) {\n              messages.push('');\n              messages.push('Starting MCP Cloudflare Worker...');\n\n              // Parse configured port (default 8787 if not found)\n              const configuredPort = await getWranglerDevPort(wranglerTomlPath) ||\n                                    await getWranglerDevPort(wranglerJsoncPath) ||\n                                    8787;\n\n              // Check if port available\n              const portAvailable = await isPortAvailable(configuredPort);\n\n              // If not available, find fallback port\n              let actualPort = configuredPort;\n              if (!portAvailable) {\n                const fallback = await findAvailablePort(configuredPort + 1, 10);\n                if (fallback) {\n                  actualPort = fallback;\n                  messages.push(`  ⚠️ Port ${configuredPort} in use, using ${actualPort}`);\n                } else {\n                  messages.push(`  ⚠️ Could not find available port for MCP worker (${configuredPort}-${configuredPort + 9} all in use)`);\n                  messages.push('  Skipping MCP worker startup');\n                  // Continue without MCP worker - non-blocking\n                  actualPort = 0;\n                }\n              }\n\n              if (actualPort > 0) {\n                // Start with explicit port if needed\n                const command = actualPort !== configuredPort\n                  ? `npx wrangler dev --port ${actualPort}`\n                  : 'npx wrangler dev';\n\n                const mcpResult = startDevServerBackground(mcpPath, command, logger, {\n                  expectedPort: actualPort,\n                  envVars: { PORT: String(actualPort) }\n                });\n                if (mcpResult) {\n                  messages.push(`✓ MCP worker started (PID: ${mcpResult.pid})`);\n                  messages.push(`  Logs: ${mcpResult.logs.stdout}`);\n                  messages.push(`  URL: http://localhost:${actualPort}`);\n\n                  // Update MCP URL env vars if port changed\n                  // Use consistent naming: NEXT_PUBLIC_{NAME}_URL for Next.js, {NAME}_URL for Cloudflare\n                  if (actualPort !== configuredPort) {\n                    const mcpUrl = `http://localhost:${actualPort}`;\n                    // Read package.json name from MCP workspace\n                    const mcpPackageJsonPath = join(input.cwd, mcpWorkspace, 'package.json');\n                    let mcpName = 'MCP';\n                    try {\n                      if (existsSync(mcpPackageJsonPath)) {\n                        const pkgJson = JSON.parse(readFileSync(mcpPackageJsonPath, 'utf-8'));\n                        if (pkgJson.name) {\n                          // Extract name: \"@constellos/mcp\" → \"MCP\", \"mcp-server\" → \"MCP_SERVER\"\n                          mcpName = pkgJson.name\n                            .replace(/^@[^/]+\\//, '')  // Remove scope (@org/)\n                            .toUpperCase()\n                            .replace(/-/g, '_');\n                        }\n                      }\n                    } catch {\n                      // Fallback to directory name\n                      mcpName = mcpWorkspace.split('/').pop()?.toUpperCase().replace(/-/g, '_') || 'MCP';\n                    }\n                    // Distribute updated MCP URL to all workspaces with correct var names\n                    for (const ws of workspaces) {\n                      const wsPath = join(input.cwd, ws);\n                      const wsType = detectProjectType(wsPath);\n                      // Use framework-appropriate variable name\n                      const varName = wsType === 'nextjs' ? `NEXT_PUBLIC_${mcpName}_URL` :\n                                     wsType === 'vite' ? `VITE_${mcpName}_URL` :\n                                     `${mcpName}_URL`;\n                      await distributeEnvVars(\n                        wsPath,\n                        { supabaseVars: {}, vercelVars: { [varName]: mcpUrl } },\n                        { createIfMissing: false, preserveExisting: true }\n                      );\n                    }\n                    messages.push(`  ✓ Updated ${mcpName}_URL to ${mcpUrl}`);\n                  }\n                } else {\n                  messages.push('⚠️ Could not start MCP worker');\n                }\n              }\n            }\n          }\n        }\n      }\n\n      // For Turborepo: modify turbo.json and package.json for dynamic port assignment\n      // This must happen BEFORE starting the dev server\n      if (projectType === 'turborepo') {\n        const workspacesForPortMod = detectTurborepoWorkspaces(input.cwd);\n        if (workspacesForPortMod && workspacesForPortMod.length > 0) {\n          // First, ensure turbo.json has PORT_* patterns in globalPassThroughEnv\n          // This is required for Turborepo to pass PORT_APP, PORT_WEB etc. to workspaces\n          await ensureTurboEnvPassthrough(input.cwd, messages);\n\n          // Then modify package.json dev scripts to use PORT env vars\n          const modifiedPkgs = await modifyPackageJsonForDynamicPorts(\n            input.cwd,\n            workspacesForPortMod,\n            messages\n          );\n\n          // Track modified package.json files in session state for manual cleanup reference\n          if (modifiedPkgs.length > 0) {\n            const modifiedPkgJsonPath = join(input.cwd, '.claude', 'logs', 'modified-package-jsons.json');\n            try {\n              writeFileSync(modifiedPkgJsonPath, JSON.stringify({\n                modified: modifiedPkgs,\n                savedAt: new Date().toISOString(),\n                cleanupInstructions: [\n                  'To restore original package.json files:',\n                  '1. git update-index --no-skip-worktree <path>',\n                  '2. git checkout <path>',\n                ],\n              }, null, 2));\n            } catch {\n              // Best effort - don't fail if we can't save the tracking file\n            }\n          }\n        }\n      }\n\n      messages.push(`Starting dev server: ${devCommand}`);\n\n      // Use pre-calculated ports (same as used for env var URLs)\n      // This ensures consistency between env vars and actual server ports\n      const availablePorts = preCalculatedPorts;\n      const devServerEnvVars: Record<string, string> = {};\n\n      if (projectType === 'turborepo') {\n        const workspaces = detectTurborepoWorkspaces(input.cwd);\n        if (workspaces && workspaces.length > 0) {\n          // Get workspace port info for per-app PORT variables\n          const workspacePorts = await detectWorkspacePorts(input.cwd, workspaces);\n\n          // Track used ports per framework to handle multiple apps of same type\n          const usedPortsByType: Record<string, number[]> = {\n            nextjs: [],\n            vite: [],\n            cloudflare: [],\n            elysia: [],\n          };\n\n          // For Turborepo: set PORT_{APP_NAME} env var for each app\n          for (const wp of workspacePorts) {\n            const wsName = basename(wp.workspace).toUpperCase().replace(/-/g, '_');\n\n            // Calculate port: configured > base + offset\n            let port: number;\n            if (wp.configuredPort !== null) {\n              port = wp.configuredPort;\n              // Apply worktree offset to configured ports\n              if (worktreeSlot > 0) {\n                port += worktreeSlot * PORT_INCREMENT;\n              }\n            } else {\n              // Use base port + offset for this framework type\n              const usedPorts = usedPortsByType[wp.projectType] || [];\n              const basePort = wp.defaultPort || availablePorts.nextjs;\n              port = basePort + (usedPorts.length * 10);\n              // Apply worktree offset\n              if (worktreeSlot > 0) {\n                port += worktreeSlot * PORT_INCREMENT;\n              }\n            }\n\n            // Track used ports\n            if (usedPortsByType[wp.projectType]) {\n              usedPortsByType[wp.projectType].push(port);\n            }\n\n            // Set per-app PORT variable\n            if (wp.projectType === 'nextjs' || wp.projectType === 'elysia') {\n              devServerEnvVars[`PORT_${wsName}`] = String(port);\n            } else if (wp.projectType === 'vite') {\n              devServerEnvVars[`VITE_PORT_${wsName}`] = String(port);\n            } else if (wp.projectType === 'cloudflare') {\n              devServerEnvVars[`WRANGLER_PORT_${wsName}`] = String(port);\n            }\n          }\n\n          // Also set legacy framework-level PORT for backwards compatibility\n          devServerEnvVars.PORT = String(availablePorts.nextjs + (worktreeSlot > 0 ? worktreeSlot * PORT_INCREMENT : 0));\n          devServerEnvVars.VITE_PORT = String(availablePorts.vite + (worktreeSlot > 0 ? worktreeSlot * PORT_INCREMENT : 0));\n          devServerEnvVars.WRANGLER_DEV_PORT = String(availablePorts.cloudflare + (worktreeSlot > 0 ? worktreeSlot * PORT_INCREMENT : 0));\n        }\n      } else {\n        // For single-project: apply port based on project type\n        if (projectType === 'nextjs' && availablePorts.nextjs !== 3000) {\n          devServerEnvVars.PORT = String(availablePorts.nextjs);\n        } else if (projectType === 'vite' && availablePorts.vite !== 5173) {\n          devServerEnvVars.VITE_PORT = String(availablePorts.vite);\n        } else if (projectType === 'cloudflare' && availablePorts.cloudflare !== 8787) {\n          devServerEnvVars.WRANGLER_DEV_PORT = String(availablePorts.cloudflare);\n        }\n      }\n\n      // Update session state with actual allocated ports for cleanup\n      await updateWorktreeSupabaseSession(input.cwd, instanceConfig.worktreeInfo.worktreeId, {\n        devServerPorts: availablePorts,\n      });\n\n      const result = startDevServerBackground(input.cwd, devCommand, logger, {\n        envVars: devServerEnvVars\n      });\n      if (result) {\n        messages.push(`✓ Dev server started (PID: ${result.pid})`);\n        messages.push(`  Logs: ${result.logs.stdout}`);\n\n        // For Turborepo: use multi-port health checks\n        if (projectType === 'turborepo') {\n          const workspaces = detectTurborepoWorkspaces(input.cwd);\n          if (workspaces && workspaces.length > 0) {\n            const workspacePorts = await detectWorkspacePorts(input.cwd, workspaces);\n\n            // Apply worktree port offsets for health checks\n            if (worktreeSlot > 0) {\n              for (const wp of workspacePorts) {\n                if (wp.configuredPort) {\n                  wp.configuredPort += worktreeSlot * PORT_INCREMENT;\n                }\n                if (wp.defaultPort) {\n                  wp.defaultPort += worktreeSlot * PORT_INCREMENT;\n                }\n              }\n            }\n\n            // Check health of all workspace servers\n            // Note: Port conflicts were resolved before starting the dev server\n            messages.push('  Waiting for workspace servers to be ready...');\n            const healthResults = await checkMultipleServerHealth(workspacePorts);\n\n            for (const hr of healthResults) {\n              if (hr.port === 0) {\n                messages.push(`  ⚠️ ${hr.workspace}: No port configured`);\n              } else if (hr.healthy) {\n                messages.push(`  ✓ ${hr.workspace} responding at http://localhost:${hr.port}`);\n              } else {\n                messages.push(`  ⚠️ ${hr.workspace} not responding on port ${hr.port}`);\n              }\n            }\n          }\n        } else {\n          // For non-Turborepo: use single-port health check\n          const packageJsonPath = join(input.cwd, 'package.json');\n          const scriptPort = extractPortFromDevScript(packageJsonPath);\n          let port = scriptPort || getDefaultPort(projectType);\n\n          // Apply worktree port offset for non-Turborepo projects\n          if (port && worktreeSlot > 0) {\n            port += worktreeSlot * PORT_INCREMENT;\n          }\n\n          if (port) {\n            messages.push(`  Waiting for server to be ready (port ${port})...`);\n            const isHealthy = await checkServerHealth(port);\n\n            if (isHealthy) {\n              messages.push(`✓ Server is responding at http://localhost:${port}`);\n            } else {\n              messages.push(`⚠️ Server did not respond within 30 seconds`);\n              messages.push(`  Check logs: ${result.logs.stderr}`);\n              messages.push(`  Try manually: ${devCommand}`);\n            }\n          } else {\n            messages.push('  ⚠️ Could not determine server port - skipping health check');\n          }\n        }\n      } else {\n        messages.push('⚠️ Could not start dev server');\n        messages.push(`  Run manually: ${devCommand}`);\n      }\n    }\n\n    // ========== Final Status ==========\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      is_remote: isRemote,\n      message: finalMessage,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Log output for consistency with other exit paths\n    await logger.logOutput({\n      success: false,\n      is_remote: isRemote,\n      message: `Supabase setup error: ${error}`,\n      reason: 'exception',\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Supabase setup error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/install-vercel.ts": "/**\n * Vercel CLI Setup Hook\n * SessionStart hook that installs Vercel CLI and syncs environment variables.\n * On remote: always installs if missing. On local: warns if missing or outdated.\n * @module install-vercel\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\nconst execAsync = promisify(exec);\n\ninterface ExecResult {\n  success: boolean;\n  stdout: string;\n  stderr: string;\n}\n\n/**\n * Execute a shell command with error handling\n */\nasync function execCommand(\n  command: string,\n  options: { cwd?: string; timeout?: number; env?: Record<string, string> } = {}\n): Promise<ExecResult> {\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd: options.cwd,\n      timeout: options.timeout || 300000,\n      env: { ...process.env, ...options.env },\n    });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a command is available in PATH\n */\nasync function isCommandAvailable(command: string): Promise<boolean> {\n  const result = await execCommand(`which ${command}`);\n  return result.success && result.stdout.length > 0;\n}\n\n/**\n * Detect if running in remote (cloud) environment\n */\nfunction isRemoteEnvironment(): boolean {\n  return process.env.CLAUDE_CODE_ENTRYPOINT === 'remote';\n}\n\n/**\n * Get Vercel CLI version\n */\nasync function getVercelVersion(): Promise<string | null> {\n  const result = await execCommand('vercel --version');\n  if (result.success) {\n    const match = result.stdout.match(/(\\d+\\.\\d+\\.\\d+)/);\n    return match ? match[1] : null;\n  }\n  return null;\n}\n\n/**\n * Get latest Vercel CLI version from npm\n */\nasync function getLatestVercelVersion(): Promise<string | null> {\n  const result = await execCommand('npm view vercel version', { timeout: 15000 });\n  if (result.success) {\n    return result.stdout.trim();\n  }\n  return null;\n}\n\n/**\n * Compare semver versions\n */\nfunction isVersionOlder(v1: string, v2: string): boolean {\n  const parts1 = v1.split('.').map(Number);\n  const parts2 = v2.split('.').map(Number);\n  for (let i = 0; i < Math.max(parts1.length, parts2.length); i++) {\n    const p1 = parts1[i] || 0;\n    const p2 = parts2[i] || 0;\n    if (p1 < p2) return true;\n    if (p1 > p2) return false;\n  }\n  return false;\n}\n\n/**\n * Install Vercel CLI globally via npm\n */\nasync function installVercelCLI(): Promise<ExecResult> {\n  if (await isCommandAvailable('vercel')) {\n    return { success: true, stdout: 'vercel already installed', stderr: '' };\n  }\n\n  const result = await execCommand('npm install -g vercel');\n  if (!result.success) {\n    return { success: false, stdout: '', stderr: `Failed to install vercel: ${result.stderr}` };\n  }\n  return { success: true, stdout: 'vercel installed successfully', stderr: '' };\n}\n\n/**\n * Sync Vercel environment variables to .env.local\n */\nasync function syncVercelEnv(cwd: string): Promise<ExecResult> {\n  const vercelDir = join(cwd, '.vercel');\n  if (!existsSync(vercelDir)) {\n    return {\n      success: true,\n      stdout: 'Vercel not configured, skipping env pull',\n      stderr: '',\n    };\n  }\n\n  const result = await execCommand('vercel env pull --yes', { cwd });\n  if (!result.success) {\n    return {\n      success: false,\n      stdout: '',\n      stderr: `Failed to pull Vercel env: ${result.stderr}`,\n    };\n  }\n\n  return {\n    success: true,\n    stdout: 'Vercel environment variables synced',\n    stderr: '',\n  };\n}\n\n/**\n * SessionStart hook handler\n * On remote: installs vercel if missing. On local: warns if missing or outdated.\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'setup-vercel', true);\n  const isRemote = isRemoteEnvironment();\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n      is_remote: isRemote,\n    });\n\n    const vercelAvailable = await isCommandAvailable('vercel');\n\n    if (!vercelAvailable) {\n      if (isRemote) {\n        messages.push('Installing Vercel CLI...');\n        const installResult = await installVercelCLI();\n        messages.push(installResult.success ? '✓ vercel installed' : `⚠️ ${installResult.stderr}`);\n      } else {\n        messages.push('⚠️ Vercel CLI not installed');\n        messages.push('  Install: npm install -g vercel');\n      }\n    } else {\n      const vercelVersion = await getVercelVersion();\n      messages.push(`✓ Vercel CLI v${vercelVersion || 'unknown'}`);\n\n      const latestVersion = await getLatestVercelVersion();\n      if (vercelVersion && latestVersion && isVersionOlder(vercelVersion, latestVersion)) {\n        messages.push(`⚠️ Update available: v${latestVersion} (current: v${vercelVersion})`);\n        if (!isRemote) {\n          messages.push('  Run: npm install -g vercel');\n        }\n      }\n\n      const syncResult = await syncVercelEnv(input.cwd);\n      messages.push(syncResult.success ? `✓ ${syncResult.stdout}` : `⚠️ ${syncResult.stderr}`);\n    }\n\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      is_remote: isRemote,\n      message: finalMessage,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Vercel setup error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/link-vercel-apps.ts": "/**\n * Vercel Auto-Link Hook\n * SessionStart hook that automatically links monorepo apps to their Vercel projects\n * and pulls environment variables.\n *\n * Features:\n * - Detects turborepo structure via turbo.json\n * - Finds apps in apps/ directory\n * - Links unlinked apps to Vercel projects\n * - Pulls environment variables for each app\n * @module link-vercel-apps\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { existsSync, readFileSync, readdirSync, statSync } from 'fs';\nimport { join, basename } from 'path';\n\nconst execAsync = promisify(exec);\n\ninterface ExecResult {\n  success: boolean;\n  stdout: string;\n  stderr: string;\n}\n\ninterface VercelProjectJson {\n  orgId: string;\n  projectId: string;\n}\n\n/**\n * Execute a shell command with error handling\n */\nasync function execCommand(\n  command: string,\n  options: { cwd?: string; timeout?: number } = {}\n): Promise<ExecResult> {\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd: options.cwd,\n      timeout: options.timeout || 30000,\n    });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if Vercel CLI is available\n */\nasync function isVercelAvailable(): Promise<boolean> {\n  const result = await execCommand('which vercel');\n  return result.success && result.stdout.length > 0;\n}\n\n/**\n * Check if a directory is linked to Vercel\n */\nfunction isVercelLinked(appPath: string): VercelProjectJson | null {\n  const projectJsonPath = join(appPath, '.vercel', 'project.json');\n  if (!existsSync(projectJsonPath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(projectJsonPath, 'utf-8');\n    return JSON.parse(content) as VercelProjectJson;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get Vercel team/scope from root .vercel/project.json or env var\n */\nfunction getVercelScope(cwd: string): string | null {\n  // First try env var\n  if (process.env.VERCEL_TEAM_ID) {\n    return process.env.VERCEL_TEAM_ID;\n  }\n\n  // Try root .vercel/project.json\n  const rootProjectJson = join(cwd, '.vercel', 'project.json');\n  if (existsSync(rootProjectJson)) {\n    try {\n      const content = readFileSync(rootProjectJson, 'utf-8');\n      const data = JSON.parse(content) as VercelProjectJson;\n      return data.orgId || null;\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Detect turborepo workspaces\n */\nfunction detectTurborepoWorkspaces(cwd: string): string[] | null {\n  const turboJsonPath = join(cwd, 'turbo.json');\n  if (!existsSync(turboJsonPath)) {\n    return null;\n  }\n\n  const rootPackageJson = join(cwd, 'package.json');\n  if (!existsSync(rootPackageJson)) {\n    return null;\n  }\n\n  try {\n    const packageData = JSON.parse(readFileSync(rootPackageJson, 'utf-8'));\n\n    // Get workspace patterns\n    let workspacePatterns: string[] = [];\n    if (Array.isArray(packageData.workspaces)) {\n      workspacePatterns = packageData.workspaces;\n    } else if (packageData.workspaces?.packages) {\n      workspacePatterns = packageData.workspaces.packages;\n    }\n\n    // Resolve workspace directories - only apps/* (not packages/*)\n    const workspaceDirs: string[] = [];\n\n    for (const pattern of workspacePatterns) {\n      if (!pattern.startsWith('apps/') && !pattern.startsWith('apps/*')) {\n        continue; // Skip non-apps workspaces\n      }\n\n      if (pattern.includes('*')) {\n        const baseDir = pattern.replace('/*', '');\n        const basePath = join(cwd, baseDir);\n\n        if (existsSync(basePath)) {\n          const entries = readdirSync(basePath);\n          for (const entry of entries) {\n            const entryPath = join(basePath, entry);\n            if (statSync(entryPath).isDirectory() && existsSync(join(entryPath, 'package.json'))) {\n              workspaceDirs.push(join(baseDir, entry));\n            }\n          }\n        }\n      } else {\n        if (existsSync(join(cwd, pattern, 'package.json'))) {\n          workspaceDirs.push(pattern);\n        }\n      }\n    }\n\n    return workspaceDirs.length > 0 ? workspaceDirs : null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Try to find a matching Vercel project for an app\n * Uses the app directory name as the project name guess\n */\nfunction guessProjectName(appPath: string, repoName: string): string {\n  const appName = basename(appPath);\n  // Common patterns: repo-app, repo-web, repo-api, etc.\n  return `${repoName}-${appName}`;\n}\n\n/**\n * Get the repository name from git remote or package.json\n */\nasync function getRepoName(cwd: string): Promise<string | null> {\n  // Try git remote\n  const result = await execCommand('git remote get-url origin', { cwd });\n  if (result.success) {\n    // Extract repo name from URL\n    // git@github.com:org/repo.git or https://github.com/org/repo.git\n    const match = result.stdout.match(/[/:]([^/]+)\\.git$/);\n    if (match) {\n      return match[1];\n    }\n    // Handle URLs without .git\n    const match2 = result.stdout.match(/[/:]([^/]+)$/);\n    if (match2) {\n      return match2[1];\n    }\n  }\n\n  // Fallback to package.json name\n  const packageJsonPath = join(cwd, 'package.json');\n  if (existsSync(packageJsonPath)) {\n    try {\n      const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n      return pkg.name?.replace(/^@[^/]+\\//, '') || null;\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Link an app to Vercel\n */\nasync function linkAppToVercel(\n  appPath: string,\n  projectName: string,\n  scope: string | null\n): Promise<ExecResult> {\n  let command = `vercel link --yes --project ${projectName}`;\n  if (scope) {\n    command += ` --scope ${scope}`;\n  }\n\n  return await execCommand(command, { cwd: appPath, timeout: 60000 });\n}\n\n/**\n * Pull environment variables for an app\n */\nasync function pullVercelEnv(appPath: string): Promise<ExecResult> {\n  return await execCommand('vercel env pull --yes', { cwd: appPath, timeout: 30000 });\n}\n\n/**\n * SessionStart hook handler\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'link-vercel-apps', true);\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({ source: input.source, session_id: input.session_id });\n\n    // Check if Vercel CLI is available\n    if (!(await isVercelAvailable())) {\n      // Vercel CLI not installed - skip silently (install-vercel hook handles this)\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n    }\n\n    // Detect turborepo workspaces\n    const workspaces = detectTurborepoWorkspaces(input.cwd);\n    if (!workspaces || workspaces.length === 0) {\n      // Not a turborepo or no apps - skip\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n    }\n\n    // Get scope for Vercel commands\n    const scope = getVercelScope(input.cwd);\n    const repoName = await getRepoName(input.cwd);\n\n    messages.push('');\n    messages.push('Vercel App Linking:');\n\n    let linkedCount = 0;\n    let skippedCount = 0;\n    let failedCount = 0;\n\n    for (const workspace of workspaces) {\n      const appPath = join(input.cwd, workspace);\n      const appName = basename(workspace);\n\n      // Check if already linked\n      const existingLink = isVercelLinked(appPath);\n      if (existingLink) {\n        messages.push(`  ✓ ${appName} already linked`);\n        skippedCount++;\n\n        // Still pull env vars if linked\n        const envResult = await pullVercelEnv(appPath);\n        if (envResult.success) {\n          messages.push(`    ✓ Env vars pulled`);\n        }\n        continue;\n      }\n\n      // Try to link the app\n      const projectName = repoName ? guessProjectName(workspace, repoName) : appName;\n      messages.push(`  Linking ${appName} to ${projectName}...`);\n\n      const linkResult = await linkAppToVercel(appPath, projectName, scope);\n      if (linkResult.success) {\n        messages.push(`  ✓ ${appName} linked to ${projectName}`);\n        linkedCount++;\n\n        // Pull env vars after successful link\n        const envResult = await pullVercelEnv(appPath);\n        if (envResult.success) {\n          messages.push(`    ✓ Env vars pulled`);\n        } else {\n          messages.push(`    ⚠️ Could not pull env vars`);\n        }\n      } else {\n        messages.push(`  ⚠️ Could not link ${appName}: ${linkResult.stderr.slice(0, 100)}`);\n        failedCount++;\n      }\n    }\n\n    // Summary\n    messages.push('');\n    messages.push(`Summary: ${linkedCount} linked, ${skippedCount} already linked, ${failedCount} failed`);\n\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      linked: linkedCount,\n      skipped: skippedCount,\n      failed: failedCount,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Vercel linking error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/move-playwright-screenshots.ts": "/**\n * PostToolUse[browser_eval] hook - Move screenshots to .claude/screenshots/\n *\n * This hook runs after browser_eval screenshot actions complete.\n * It automatically moves screenshot files to a dedicated directory that\n * Claude has standard access to, eliminating repeated permission requests.\n *\n * Handles:\n * - Screenshot file relocation\n * - Cross-device moves (copy+delete fallback)\n * - Filename conflict resolution (timestamp deduplication)\n * - Graceful error handling (non-blocking)\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { promises as fs } from 'node:fs';\nimport { join, basename } from 'node:path';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('browser');\n\n  // Only process browser_eval tool calls\n  if (input.tool_name !== 'browser_eval') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:browser_eval] Hook triggered');\n    console.log('[PostToolUse:browser_eval] Tool Use ID:', input.tool_use_id);\n  }\n\n  try {\n    // Filter: Only process screenshot actions\n    const toolInput = input.tool_input as { action?: string };\n    if (toolInput.action !== 'screenshot') {\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] Not a screenshot action, skipping');\n      }\n      return {};\n    }\n\n    if (DEBUG) {\n      console.log('[PostToolUse:browser_eval] Screenshot action detected');\n    }\n\n    // Extract screenshot path from response\n    // The response format varies by MCP implementation, so we need to be flexible\n    const response = input.tool_response;\n    let screenshotPath: string | undefined;\n\n    // Try different response formats\n    if (typeof response === 'object' && response !== null) {\n      const responseObj = response as Record<string, unknown>;\n\n      // Format 1: { screenshot: { path: \"...\" } }\n      if (responseObj.screenshot && typeof responseObj.screenshot === 'object') {\n        const screenshot = responseObj.screenshot as Record<string, unknown>;\n        if (typeof screenshot.path === 'string') {\n          screenshotPath = screenshot.path;\n        }\n      }\n\n      // Format 2: { path: \"...\" }\n      if (!screenshotPath && typeof responseObj.path === 'string') {\n        screenshotPath = responseObj.path;\n      }\n\n      // Format 3: { file: \"...\" } or { filePath: \"...\" }\n      if (!screenshotPath && typeof responseObj.file === 'string') {\n        screenshotPath = responseObj.file;\n      }\n      if (!screenshotPath && typeof responseObj.filePath === 'string') {\n        screenshotPath = responseObj.filePath;\n      }\n    }\n\n    if (!screenshotPath) {\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] No screenshot path found in response');\n        console.log('[PostToolUse:browser_eval] Response:', JSON.stringify(response).slice(0, 200));\n      }\n      return {};\n    }\n\n    if (DEBUG) {\n      console.log('[PostToolUse:browser_eval] Screenshot path:', screenshotPath);\n    }\n\n    // Verify file exists before trying to move it\n    try {\n      await fs.access(screenshotPath);\n    } catch {\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] Screenshot file not found, skipping move');\n      }\n      return {};\n    }\n\n    // Create target directory\n    const targetDir = join(input.cwd, '.claude', 'screenshots');\n    await fs.mkdir(targetDir, { recursive: true });\n\n    // Generate target filename with timestamp deduplication\n    const filename = basename(screenshotPath);\n    let targetPath = join(targetDir, filename);\n\n    // Check if file already exists, add timestamp if needed\n    try {\n      await fs.access(targetPath);\n      // File exists, add timestamp\n      const timestamp = Date.now();\n      const ext = filename.includes('.') ? filename.substring(filename.lastIndexOf('.')) : '';\n      const name = filename.includes('.') ? filename.substring(0, filename.lastIndexOf('.')) : filename;\n      targetPath = join(targetDir, `${name}-${timestamp}${ext}`);\n    } catch {\n      // File doesn't exist, use original filename\n    }\n\n    // Move file atomically (with fallback to copy+delete for cross-device moves)\n    try {\n      await fs.rename(screenshotPath, targetPath);\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] Screenshot moved to:', targetPath);\n      }\n    } catch {\n      // Fallback: copy then delete (handles cross-device moves)\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] Rename failed, using copy+delete fallback');\n      }\n      await fs.copyFile(screenshotPath, targetPath);\n      await fs.unlink(screenshotPath);\n      if (DEBUG) {\n        console.log('[PostToolUse:browser_eval] Screenshot copied to:', targetPath);\n      }\n    }\n\n    // Return context about the move\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `Screenshot saved to ${targetPath}`,\n      },\n    };\n  } catch (error) {\n    // Non-blocking error - log but don't stop Claude execution\n    if (DEBUG) {\n      console.error('[PostToolUse:browser_eval] Error moving screenshot:', error);\n    }\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-file-eslint.ts": "/**\n * ESLint check for PostToolUse[Write|Edit] hooks\n *\n * Runs eslint on the edited file and blocks if there are errors.\n * Only runs on .ts, .tsx, .js, .jsx files.\n *\n * @module run-file-eslint\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for eslint in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to lint */\nconst LINT_EXTENSIONS = ['.ts', '.tsx', '.js', '.jsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if file should be linted based on extension\n */\nfunction shouldLint(filePath: string): boolean {\n  return LINT_EXTENSIONS.some((ext) => filePath.endsWith(ext));\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs eslint on the edited file. Blocks if eslint fails.\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath || !shouldLint(filePath)) {\n    return {};\n  }\n\n  // Find eslint config directory\n  let eslintConfigDir = await findConfigFile(input.cwd, 'eslint.config.mjs');\n\n  // Try alternative flat config format\n  if (!eslintConfigDir) {\n    eslintConfigDir = await findConfigFile(input.cwd, 'eslint.config.js');\n  }\n\n  if (!eslintConfigDir) {\n    // No ESLint flat config found - skip validation with warning\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠️ ESLint config not found (searched from ${input.cwd} to git root). Skipping lint check. Expected: eslint.config.mjs or eslint.config.js`,\n      },\n    };\n  }\n\n  // Run eslint\n  const command = `npx eslint --max-warnings 0 \"${filePath}\"`;\n\n  try {\n    await execAsync(command, {\n      cwd: eslintConfigDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // ESLint passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ ESLint passed`,\n      },\n    };\n  } catch (error) {\n    // ESLint failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'ESLint failed';\n\n    return {\n      decision: 'block',\n      reason: `Fix ESLint errors before continuing:\\n\\n${truncateOutput(output)}`,\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `❌ ESLint failed:\\n\\n${truncateOutput(output)}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-file-vitests.ts": "/**\n * Vitest check for PostToolUse[Write|Edit] hooks\n *\n * Runs vitest for related tests when a file is edited.\n * Non-blocking - only warns if tests fail.\n * Only runs on .ts, .tsx files.\n *\n * @module run-file-vitests\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { access } from 'fs/promises';\nimport { basename, dirname, join, relative, isAbsolute } from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for vitest in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to check for tests */\nconst TEST_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if file should have tests checked\n */\nfunction shouldCheckTests(filePath: string): boolean {\n  // Don't run tests for test files themselves\n  if (filePath.includes('.test.') || filePath.includes('.spec.')) {\n    return false;\n  }\n  return TEST_EXTENSIONS.some((ext) => filePath.endsWith(ext));\n}\n\n/**\n * Find the test file for a given source file\n * Looks for foo.test.ts or foo.test.tsx next to the source file\n */\nasync function findTestFile(filePath: string): Promise<string | null> {\n  const dir = dirname(filePath);\n  const base = basename(filePath);\n\n  // Remove extension to get base name\n  const extMatch = base.match(/\\.(ts|tsx)$/);\n  if (!extMatch) return null;\n\n  const nameWithoutExt = base.slice(0, -extMatch[0].length);\n\n  // Try .test.ts and .test.tsx\n  for (const ext of ['.test.ts', '.test.tsx']) {\n    const testPath = join(dir, nameWithoutExt + ext);\n    try {\n      await access(testPath);\n      return testPath;\n    } catch {\n      // File doesn't exist\n    }\n  }\n\n  return null;\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs vitest for related tests. Non-blocking - warns only.\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath || !shouldCheckTests(filePath)) {\n    return {};\n  }\n\n  // Find related test file\n  const testFile = await findTestFile(filePath);\n\n  if (!testFile) {\n    // No test file found, skip silently\n    return {};\n  }\n\n  // Find vitest config\n  let vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.ts');\n\n  // Try alternative configs\n  if (!vitestConfigDir) {\n    vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.js');\n  }\n  if (!vitestConfigDir) {\n    vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.mjs');\n  }\n\n  // Fallback to input.cwd if no config found\n  const runDir = vitestConfigDir || input.cwd;\n\n  // Make test file path relative to run directory\n  const relativeTestFile = isAbsolute(testFile)\n    ? relative(runDir, testFile)\n    : testFile;\n\n  // Run vitest for the test file\n  const command = `npx vitest run \"${relativeTestFile}\" --reporter=verbose`;\n\n  try {\n    await execAsync(command, {\n      cwd: runDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // Tests passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ Tests passed for ${basename(testFile)}`,\n      },\n    };\n  } catch (error) {\n    // Tests failed - warn but don't block\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'Tests failed';\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠️ Tests failed for ${basename(testFile)}:\\n\\n${truncateOutput(output)}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-session-typechecks.ts": "/**\n * TypeScript check for Stop hooks\n *\n * Runs tsc --noEmit on the project before the main session stops.\n * Blocks if there are type errors.\n *\n * @module run-session-typechecks\n */\n\nimport type { StopInput, StopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { detectWorktree } from '../shared/hooks/utils/worktree.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for tsc in milliseconds (60 seconds - tsc can be slow) */\nconst TIMEOUT_MS = 60000;\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Stop hook handler\n *\n * Runs tsc --noEmit on the project unconditionally. Session Stop is the\n * final checkpoint before work completes, so running tsc on the whole\n * project is reasonable overhead.\n */\nasync function handler(input: StopInput): Promise<StopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('session-typechecks');\n\n  if (DEBUG) {\n    console.log('[run-session-typechecks] Hook triggered');\n    console.log('[run-session-typechecks] Session ID:', input.session_id);\n  }\n\n  // Normalize cwd to worktree/repo root for consistent config resolution\n  // This fixes false positives in monorepos where input.cwd might be a subdirectory\n  const worktreeInfo = detectWorktree(input.cwd);\n  const searchRoot = worktreeInfo.worktreePath;\n\n  if (DEBUG) {\n    console.log('[run-session-typechecks] Search root:', searchRoot);\n    console.log('[run-session-typechecks] Is worktree:', worktreeInfo.isWorktree);\n  }\n\n  // Find tsconfig.json starting from repo/worktree root\n  const tsconfigDir = await findConfigFile(searchRoot, 'tsconfig.json');\n\n  if (!tsconfigDir) {\n    // No tsconfig.json found - skip with warning visible in systemMessage\n    const warning = `⚠️ TypeScript check skipped: tsconfig.json not found (searched from ${searchRoot})`;\n    if (DEBUG) {\n      console.warn(`[run-session-typechecks] ${warning}`);\n    }\n    return {\n      systemMessage: warning,\n    };\n  }\n\n  // Run tsc --noEmit on the project\n  const command = 'npx tsc --noEmit';\n\n  if (DEBUG) {\n    console.log('[run-session-typechecks] Running:', command);\n    console.log('[run-session-typechecks] Config dir:', tsconfigDir);\n  }\n\n  try {\n    await execAsync(command, {\n      cwd: tsconfigDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // Typecheck passed - provide visibility\n    return {\n      systemMessage: '✓ TypeScript check passed',\n    };\n  } catch (error) {\n    // Typecheck failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'TypeScript check failed';\n\n    return {\n      decision: 'block',\n      reason: `Fix TypeScript errors before continuing:\\n\\n${truncateOutput(output)}`,\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-task-typechecks.ts": "/**\n * TypeScript check for SubagentStop hooks\n *\n * Runs tsc --noEmit on the project after a subagent completes.\n * Blocks if there are type errors.\n *\n * @module run-task-typechecks\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getAgentEdits } from '../shared/hooks/utils/subagent-state.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { detectWorktree } from '../shared/hooks/utils/worktree.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for tsc in milliseconds (60 seconds - tsc can be slow) */\nconst TIMEOUT_MS = 60000;\n\n/** File extensions that trigger typecheck */\nconst TS_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if any edited files are TypeScript\n */\nfunction hasTypeScriptFiles(files: string[]): boolean {\n  return files.some((file) =>\n    TS_EXTENSIONS.some((ext) => file.endsWith(ext))\n  );\n}\n\n/**\n * SubagentStop hook handler\n *\n * Runs tsc --noEmit on the project if TypeScript files were edited.\n * Blocks if typecheck fails.\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task-typechecks');\n\n  if (DEBUG) {\n    console.log('[run-task-typechecks] Hook triggered');\n    console.log('[run-task-typechecks] Agent ID:', input.agent_id);\n  }\n\n  // Get all files edited by the agent\n  let allEditedFiles: string[];\n  try {\n    const edits = await getAgentEdits(input.agent_transcript_path);\n    allEditedFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n  } catch (error) {\n    // Transcript parsing failed - provide visibility instead of silent failure\n    const err = error as Error;\n    const warning = `⚠️ TypeScript check skipped: Could not parse agent transcript (${err.message})`;\n    if (DEBUG) {\n      console.error('[run-task-typechecks] Error parsing transcript:', error);\n    }\n    return {\n      systemMessage: warning,\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[run-task-typechecks] Edited files:', allEditedFiles.length);\n  }\n\n  // Only run typecheck if TypeScript files were edited\n  if (!hasTypeScriptFiles(allEditedFiles)) {\n    if (DEBUG) {\n      console.log('[run-task-typechecks] No TypeScript files edited, skipping');\n    }\n    return {\n      systemMessage: '✓ TypeScript check skipped (no .ts/.tsx files edited)',\n    };\n  }\n\n  // Normalize cwd to worktree/repo root for consistent config resolution\n  // This fixes false positives in monorepos where input.cwd might be a subdirectory\n  const worktreeInfo = detectWorktree(input.cwd);\n  const searchRoot = worktreeInfo.worktreePath;\n\n  if (DEBUG) {\n    console.log('[run-task-typechecks] Search root:', searchRoot);\n    console.log('[run-task-typechecks] Is worktree:', worktreeInfo.isWorktree);\n  }\n\n  // Find tsconfig.json starting from repo/worktree root\n  const tsconfigDir = await findConfigFile(searchRoot, 'tsconfig.json');\n\n  if (!tsconfigDir) {\n    // No tsconfig.json found - skip with warning visible in systemMessage\n    const warning = `⚠️ TypeScript check skipped: tsconfig.json not found (searched from ${searchRoot})`;\n    if (DEBUG) {\n      console.warn(`[run-task-typechecks] ${warning}`);\n    }\n    return {\n      systemMessage: warning,\n    };\n  }\n\n  // Run tsc --noEmit on the project\n  const command = 'npx tsc --noEmit';\n\n  if (DEBUG) {\n    console.log('[run-task-typechecks] Running:', command);\n    console.log('[run-task-typechecks] Config dir:', tsconfigDir);\n  }\n\n  try {\n    await execAsync(command, {\n      cwd: tsconfigDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // Typecheck passed - provide visibility\n    return {\n      systemMessage: '✓ TypeScript check passed',\n    };\n  } catch (error) {\n    // Typecheck failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'TypeScript check failed';\n\n    return {\n      decision: 'block',\n      reason: `Fix TypeScript errors before continuing:\\n\\n${truncateOutput(output)}`,\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/run-task-vitests.ts": "/**\n * Vitest check for SubagentStop hooks\n *\n * Runs vitest for all files edited during the agent's task.\n * Blocks if tests fail.\n *\n * @module run-task-vitests\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getAgentEdits } from '../shared/hooks/utils/subagent-state.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport * as path from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for vitest in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to check for tests */\nconst TEST_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Filter to only testable files\n */\nfunction getTestableFiles(files: string[]): string[] {\n  return files.filter((file) => {\n    // Skip test files themselves\n    if (file.includes('.test.') || file.includes('.spec.')) {\n      return false;\n    }\n    return TEST_EXTENSIONS.some((ext) => file.endsWith(ext));\n  });\n}\n\n/**\n * SubagentStop hook handler\n *\n * Runs vitest related for all edited files. Blocks if tests fail.\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task-vitests');\n\n  if (DEBUG) {\n    console.log('[run-task-vitests] Hook triggered');\n    console.log('[run-task-vitests] Agent ID:', input.agent_id);\n  }\n\n  try {\n    // Get all files edited by the agent\n    const edits = await getAgentEdits(input.agent_transcript_path);\n    const allEditedFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n    const testableFiles = getTestableFiles(allEditedFiles);\n\n    if (DEBUG) {\n      console.log('[run-task-vitests] Edited files:', allEditedFiles.length);\n      console.log('[run-task-vitests] Testable files:', testableFiles.length);\n    }\n\n    if (testableFiles.length === 0) {\n      // No testable files, skip\n      return {};\n    }\n\n    // Find vitest config\n    let vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.ts');\n\n    // Try alternative config formats\n    if (!vitestConfigDir) {\n      vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.js');\n    }\n    if (!vitestConfigDir) {\n      vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.mjs');\n    }\n\n    // Fallback to input.cwd if no config found (Vitest has defaults)\n    const runDir = vitestConfigDir || input.cwd;\n\n    if (!vitestConfigDir && DEBUG) {\n      console.warn(`[run-task-vitests] No vitest config found (searched from ${input.cwd}). Running with defaults.`);\n    }\n\n    // Make file paths relative to run directory\n    const relativeFiles = testableFiles.map(f => {\n      if (path.isAbsolute(f)) {\n        return path.relative(runDir, f);\n      }\n      return f;\n    });\n\n    // Run vitest related for all edited files\n    const filesArg = relativeFiles.map((f) => `\"${f}\"`).join(' ');\n    const command = `npx vitest related ${filesArg} --run --reporter=verbose`;\n\n    if (DEBUG) {\n      console.log('[run-task-vitests] Running:', command);\n      console.log('[run-task-vitests] Config dir:', runDir);\n    }\n\n    try {\n      await execAsync(command, {\n        cwd: runDir,\n        timeout: TIMEOUT_MS,\n      });\n\n      // Tests passed\n      return {};\n    } catch (error) {\n      // Tests failed\n      const err = error as { stdout?: string; stderr?: string; message?: string };\n      const output = err.stdout || err.stderr || err.message || 'Tests failed';\n\n      return {\n        decision: 'block',\n        reason: `Fix test failures before continuing:\\n\\n${truncateOutput(output)}`,\n      };\n    }\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[run-task-vitests] Error:', error);\n    }\n    // Don't block on transcript parsing errors\n    return {};\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/setup-nodes-config.ts": "/**\n * Nodes MCP Config Setup Hook\n * SessionStart hook that creates .nodes/.mcp.nodes.json config for the nodes-md proxy.\n * Merges with existing config if present (for multi-plugin support).\n * @module setup-nodes-config\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { existsSync, mkdirSync, readFileSync, writeFileSync, appendFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Nodes MCP server configuration\n */\ninterface NodesServer {\n  transport: 'stdio' | 'sse';\n  command?: string;\n  args?: string[];\n  url?: string;\n}\n\n/**\n * Nodes MCP config file structure\n */\ninterface NodesConfig {\n  servers: Record<string, NodesServer>;\n}\n\n/**\n * Servers this plugin contributes to the nodes config\n * Only local/stdio servers go through nodes - HTTP servers stay as mcp-remote\n */\nconst PLUGIN_SERVERS: Record<string, NodesServer> = {\n  'next-devtools': {\n    transport: 'stdio',\n    command: 'npx',\n    args: ['-y', 'next-devtools-mcp@latest'],\n  },\n  shadcn: {\n    transport: 'stdio',\n    command: 'npx',\n    args: ['shadcn@latest', 'mcp'],\n  },\n};\n\n/**\n * Load existing nodes config or return empty config\n */\nfunction loadNodesConfig(configPath: string): NodesConfig {\n  if (existsSync(configPath)) {\n    try {\n      const content = readFileSync(configPath, 'utf-8');\n      return JSON.parse(content) as NodesConfig;\n    } catch {\n      // Invalid JSON, start fresh\n      return { servers: {} };\n    }\n  }\n  return { servers: {} };\n}\n\n/**\n * Add .nodes/ to .gitignore if not already present\n */\nfunction addToGitignore(cwd: string): boolean {\n  const gitignorePath = join(cwd, '.gitignore');\n\n  if (existsSync(gitignorePath)) {\n    const content = readFileSync(gitignorePath, 'utf-8');\n    if (content.includes('.nodes/') || content.includes('.nodes')) {\n      return false; // Already present\n    }\n    appendFileSync(gitignorePath, '\\n# nodes-md MCP config\\n.nodes/\\n');\n    return true;\n  } else {\n    writeFileSync(gitignorePath, '# nodes-md MCP config\\n.nodes/\\n');\n    return true;\n  }\n}\n\n/**\n * SessionStart hook handler\n * Creates .nodes/.mcp.nodes.json with this plugin's servers\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'setup-nodes-config', true);\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n    });\n\n    const nodesDir = join(input.cwd, '.nodes');\n    const configPath = join(nodesDir, '.mcp.nodes.json');\n\n    // Create .nodes directory if needed\n    if (!existsSync(nodesDir)) {\n      mkdirSync(nodesDir, { recursive: true });\n      messages.push('Created .nodes/ directory');\n    }\n\n    // Load existing config and merge\n    const config = loadNodesConfig(configPath);\n    const existingServers = Object.keys(config.servers);\n    const newServers: string[] = [];\n\n    // Merge plugin servers (this plugin's servers take precedence)\n    for (const [name, server] of Object.entries(PLUGIN_SERVERS)) {\n      if (!config.servers[name]) {\n        newServers.push(name);\n      }\n      config.servers[name] = server;\n    }\n\n    // Write updated config\n    writeFileSync(configPath, JSON.stringify(config, null, 2) + '\\n');\n\n    if (newServers.length > 0) {\n      messages.push(`Added servers to .nodes config: ${newServers.join(', ')}`);\n    } else {\n      messages.push('Nodes config up to date');\n    }\n\n    if (existingServers.length > 0) {\n      const otherServers = existingServers.filter((s) => !PLUGIN_SERVERS[s]);\n      if (otherServers.length > 0) {\n        messages.push(`Other servers in config: ${otherServers.join(', ')}`);\n      }\n    }\n\n    // Add to .gitignore\n    if (addToGitignore(input.cwd)) {\n      messages.push('Added .nodes/ to .gitignore');\n    }\n\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      message: finalMessage,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Nodes config setup error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/use-proxy-nextjs-16.ts": "/**\n * Next.js 16+ Proxy Migration Hook\n * PreToolUse[Write|Edit] hook that blocks middleware.ts creation in Next.js 16+ projects\n * Next.js 16 requires proxy.ts instead of middleware.ts\n * Exception: Allows middleware.ts in supabase folders\n * @module use-proxy-nextjs-16\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { basename, normalize } from 'path';\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Detect Next.js major version from package.json\n * @param cwd - Current working directory\n * @returns Major version number or null if not found\n */\nfunction getNextJsVersion(cwd: string): number | null {\n  const packageJsonPath = join(cwd, 'package.json');\n\n  if (!existsSync(packageJsonPath)) {\n    return null;\n  }\n\n  try {\n    const packageJson = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n    const nextVersion = packageJson.dependencies?.next || packageJson.devDependencies?.next;\n\n    if (!nextVersion) {\n      return null;\n    }\n\n    // Extract major version from strings like \"^16.0.0\", \"~16.1.0\", \"16.0.0\", \">=16.0.0\"\n    const versionMatch = nextVersion.match(/(\\d+)/);\n    return versionMatch ? parseInt(versionMatch[1], 10) : null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Check if file path is in a supabase folder\n * @param filePath - Path to check\n * @returns True if path contains /supabase/ or \\supabase\\\n */\nfunction isSupabaseRelated(filePath: string): boolean {\n  const normalizedPath = normalize(filePath).toLowerCase();\n  return normalizedPath.includes('/supabase/') || normalizedPath.includes('\\\\supabase\\\\');\n}\n\n/**\n * PreToolUse hook handler\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only process Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput.file_path;\n\n  // Early return if no file path\n  if (!filePath) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const fileName = basename(filePath);\n\n  // Only check middleware.ts files\n  if (fileName.toLowerCase() !== 'middleware.ts') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Allow middleware.ts in supabase folders\n  if (isSupabaseRelated(filePath)) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Check Next.js version\n  const nextVersion = getNextJsVersion(input.cwd);\n\n  // Allow if Next.js version is less than 16 or not found\n  if (nextVersion === null || nextVersion < 16) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Block middleware.ts creation in Next.js 16+\n  const errorMessage = `❌ middleware.ts is deprecated in Next.js 16+\n\nNext.js 16 requires using proxy.ts instead of middleware.ts for routing middleware.\n\nPlease:\n1. Rename this file to proxy.ts\n2. Update your configuration to use the new proxy API\n\nLearn more: https://nextjs.org/docs/app/api-reference/file-conventions/proxy.md\n\nNote: Supabase middleware files are exempt from this check.`;\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'deny',\n      permissionDecisionReason: errorMessage,\n    },\n  };\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/hooks/validate-supabase-env.ts": "/**\n * Supabase Environment Variable Validation Hook\n * PreToolUse[Write|Edit] hook that blocks deprecated Supabase env var names\n * and incorrect prefixes in .env.local and dev.vars files\n * @module validate-supabase-env\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { basename } from 'path';\n\n/**\n * PreToolUse hook handler\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const toolInput = input.tool_input as {\n    file_path?: string;\n    content?: string;\n    new_string?: string;\n  };\n\n  const filePath = toolInput.file_path;\n  if (!filePath) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const fileName = basename(filePath);\n\n  if (fileName !== '.env.local' && fileName !== 'dev.vars') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const content = input.tool_name === 'Write' ? toolInput.content : toolInput.new_string;\n\n  if (!content) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const errors: string[] = [];\n\n  if (fileName === '.env.local') {\n    // Check for deprecated names\n    if (/SUPABASE_ANON_KEY/m.test(content)) {\n      errors.push(\n        '❌ SUPABASE_ANON_KEY is deprecated. Use NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY instead.'\n      );\n    }\n    if (/SUPABASE_SERVICE_ROLE_KEY/m.test(content)) {\n      errors.push('❌ SUPABASE_SERVICE_ROLE_KEY is deprecated. Use SUPABASE_SECRET_KEY instead.');\n    }\n    // Check for missing NEXT_PUBLIC_ prefix\n    if (/^SUPABASE_URL=/m.test(content)) {\n      errors.push('❌ In .env.local, use NEXT_PUBLIC_SUPABASE_URL (not SUPABASE_URL).');\n    }\n    if (/^SUPABASE_PUBLISHABLE_KEY=/m.test(content)) {\n      errors.push(\n        '❌ In .env.local, use NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY (not SUPABASE_PUBLISHABLE_KEY).'\n      );\n    }\n  } else if (fileName === 'dev.vars') {\n    // Check for deprecated names\n    if (/SUPABASE_ANON_KEY/m.test(content)) {\n      errors.push('❌ SUPABASE_ANON_KEY is deprecated. Use SUPABASE_PUBLISHABLE_KEY instead.');\n    }\n    if (/SUPABASE_SERVICE_ROLE_KEY/m.test(content)) {\n      errors.push('❌ SUPABASE_SERVICE_ROLE_KEY is deprecated. Use SUPABASE_SECRET_KEY instead.');\n    }\n    // Check for incorrect NEXT_PUBLIC_ prefix\n    if (/NEXT_PUBLIC_/m.test(content)) {\n      errors.push(\n        '❌ In dev.vars (Cloudflare), do not use NEXT_PUBLIC_ prefix. Use plain SUPABASE_URL and SUPABASE_PUBLISHABLE_KEY.'\n      );\n    }\n  }\n\n  if (errors.length > 0) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'deny',\n        permissionDecisionReason: `Invalid Supabase environment variables in ${fileName}:\\n\\n${errors.join('\\n')}\\n\\nPlease use the modern variable names with correct prefixes.`,\n      },\n    };\n  }\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'allow',\n    },\n  };\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/enforce-output-style-tools.ts": "#!/usr/bin/env npx tsx\n\n/**\n * Output style tool enforcement hook\n *\n * PreToolUse hook that enforces tool restrictions defined in output style frontmatter.\n * When an output style specifies a `tools` array in its frontmatter, only those tools\n * are allowed for the main agent. Subagents can use any tools they need.\n *\n * This enables output styles to restrict Claude's capabilities to specific tools,\n * for example:\n * - Read-only mode: only Read, Glob, Grep tools\n * - Research mode: Read, Glob, Grep, WebSearch, WebFetch\n * - Full mode: all tools allowed (no restrictions)\n *\n * Output style files are located in .claude/output-styles/ with frontmatter like:\n * ```yaml\n * ---\n * name: read-only\n * description: Read-only access to codebase\n * tools: [Read, Glob, Grep]\n * ---\n * ```\n *\n * @module enforce-output-style-tools\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { runHook, wasToolEventMainAgent } from './utils/index.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('output-styles-permission-modes');\n\ninterface OutputStyleFrontmatter {\n  name?: string;\n  description?: string;\n  tools?: string[];\n}\n\n/**\n * Read settings.json to get the current output style name\n *\n * Checks both settings.local.json (project-specific) and settings.json (committed)\n * for the outputStyle configuration. Returns the first match found.\n *\n * @param cwd - The working directory to search for settings files\n * @returns The output style name, or undefined if not configured\n *\n * @example\n * ```typescript\n * const styleName = await getCurrentOutputStyle('/path/to/project');\n * console.log(styleName); // 'read-only' or undefined\n * ```\n */\nasync function getCurrentOutputStyle(cwd: string): Promise<string | undefined> {\n  const settingsPaths = [\n    path.join(cwd, '.claude', 'settings.local.json'),\n    path.join(cwd, '.claude', 'settings.json'),\n  ];\n\n  for (const settingsPath of settingsPaths) {\n    try {\n      const content = await fs.readFile(settingsPath, 'utf-8');\n      const settings = JSON.parse(content);\n      if (settings.outputStyle) {\n        return settings.outputStyle;\n      }\n    } catch {\n      // File doesn't exist or is invalid JSON, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Load and parse output style file to get frontmatter\n *\n * Reads the output style markdown file and extracts its YAML frontmatter,\n * which contains the style configuration including tool restrictions.\n *\n * @param cwd - The working directory where output styles are stored\n * @param styleName - The name of the output style (without .md extension)\n * @returns The parsed frontmatter, or undefined if file not found\n *\n * @example\n * ```typescript\n * const frontmatter = await loadOutputStyleFrontmatter(\n *   '/path/to/project',\n *   'read-only'\n * );\n *\n * if (frontmatter) {\n *   console.log('Allowed tools:', frontmatter.tools);\n *   // ['Read', 'Glob', 'Grep']\n * }\n * ```\n */\nasync function loadOutputStyleFrontmatter(\n  cwd: string,\n  styleName: string\n): Promise<OutputStyleFrontmatter | undefined> {\n  const stylePaths = [\n    path.join(cwd, '.claude', 'output-styles', `${styleName}.md`),\n    // Note: User-level styles would be in ~/.claude/output-styles/\n    // but we can't easily access user home in hooks without assumptions\n  ];\n\n  for (const stylePath of stylePaths) {\n    try {\n      const content = await fs.readFile(stylePath, 'utf-8');\n      const { data } = matter(content);\n      return data as OutputStyleFrontmatter;\n    } catch {\n      // File doesn't exist, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * PreToolUse hook that enforces tool restrictions from output style frontmatter\n *\n * Checks if the current tool is allowed by the active output style's tool restrictions.\n * This hook only applies to the main agent - subagents can use any tools they need\n * to complete their tasks.\n *\n * The enforcement flow:\n * 1. Check if this is the main agent (skip for subagents)\n * 2. Read current output style from settings.json\n * 3. Load output style frontmatter to get allowed tools list\n * 4. Check if current tool is in the allowed list\n * 5. Allow or deny based on the check\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Example output style: .claude/output-styles/read-only.md\n * // ---\n * // name: read-only\n * // tools: [Read, Glob, Grep]\n * // ---\n *\n * // Settings: .claude/settings.json\n * // { \"outputStyle\": \"read-only\" }\n *\n * // When main agent tries to use Read tool:\n * const result = await handler({\n *   tool_name: 'Read',\n *   tool_use_id: 'toolu_123',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // When main agent tries to use Write tool (not in allowed list):\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'The \"Write\" tool is not allowed...'\n * //   }\n * // }\n *\n * // When subagent tries to use Write tool:\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   transcript_path: '/path/.claude/logs/agent-xyz.jsonl', // Subagent transcript\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * // (Subagents are never restricted)\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Hook triggered');\n    console.log('[enforce-output-style-tools] Tool:', input.tool_name);\n  }\n\n  // Only enforce for main agent, not subagents\n  const isMainAgent = await wasToolEventMainAgent(input.transcript_path, input.tool_use_id);\n  if (!isMainAgent) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Subagent detected, skipping enforcement');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Get current output style\n  const styleName = await getCurrentOutputStyle(input.cwd);\n  if (!styleName) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No output style configured, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Current output style:', styleName);\n  }\n\n  // Load output style frontmatter\n  const frontmatter = await loadOutputStyleFrontmatter(input.cwd, styleName);\n  if (!frontmatter || !frontmatter.tools || frontmatter.tools.length === 0) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No tool restrictions defined, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const allowedTools = frontmatter.tools;\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Allowed tools:', allowedTools);\n  }\n\n  // Check if current tool is allowed\n  const isAllowed = allowedTools.includes(input.tool_name);\n\n  if (!isAllowed) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Tool not allowed, blocking');\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'deny',\n        permissionDecisionReason: `The \"${input.tool_name}\" tool is not allowed by the current output style \"${styleName}\". Allowed tools: ${allowedTools.join(', ')}`,\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Tool allowed');\n  }\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'allow',\n    },\n  };\n}\n\n// Export for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/enforce-structured-markdown.ts": "#!/usr/bin/env npx tsx\n/**\n * Structured markdown validation hook\n *\n * PreToolUse hook that validates structure and metadata for markdown files before\n * Write and Edit operations. Enforces consistent documentation structure across\n * different file types in the Claude Code project.\n *\n * This hook validates six types of markdown files:\n *\n * 1. Agent files in .claude/agents/ directory\n *    Required headings: Objective, Principles, Agent-scoped project context\n *\n * 2. Skill files in .claude/skills/ subdirectories (excludes SKILL.md templates)\n *    Required headings: Purpose, Skill-scoped context\n *\n * 3. Rules files in .claude/rules/ directory\n *    Required headings: Rules\n *\n * 4. Plugin README files in plugins README.md\n *    Required headings: Badge section, TOC, Overview, Features, Installation,\n *    Hooks, Configuration, Use Cases, Troubleshooting, Contributing, See Also, License\n *\n * 5. Plugin CLAUDE.md files in plugins CLAUDE.md\n *    Required headings: Quick Reference, Hook Summary, Key Features,\n *    Installation, Debug Logging, See Also\n *\n * 6. CLAUDE.md files in any other directory\n *    Required metadata: name, description\n *\n * The hook blocks Write/Edit operations if validation fails, providing detailed\n * error messages about missing headings and metadata fields.\n *\n * @module enforce-structured-markdown\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('enforce-structured-markdown');\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n}\n\n/**\n * Extract markdown headings from content\n *\n * Parses markdown content and extracts all headings (lines starting with #).\n * Preserves the full heading text including the hash symbols for pattern matching.\n *\n * @param content - The markdown content to parse\n * @returns Array of heading strings (e.g., [\"# Title\", \"## Section\"])\n *\n * @example\n * ```typescript\n * const content = `\n * # My Document\n * ## Overview\n * Some content\n * ## Implementation\n * `;\n * const headings = extractHeadings(content);\n * // Returns: [\"# My Document\", \"## Overview\", \"## Implementation\"]\n * ```\n */\nfunction extractHeadings(content: string): string[] {\n  const lines = content.split('\\n');\n  const headings: string[] = [];\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (trimmed.match(/^#{1,6}\\s+/)) {\n      headings.push(trimmed);\n    }\n  }\n\n  return headings;\n}\n\n/**\n * Check if a heading matches a pattern with wildcard support\n *\n * Compares a markdown heading against a pattern, supporting wildcard (*) matching.\n * Normalizes whitespace and performs case-insensitive comparison.\n *\n * @param heading - The heading to test (e.g., \"## Required Skills: None\")\n * @param pattern - The pattern to match against (e.g., \"## Required Skills:*\")\n * @returns True if the heading matches the pattern, false otherwise\n *\n * @example\n * ```typescript\n * // Exact match\n * matchesHeadingPattern(\"## Overview\", \"## Overview\"); // true\n *\n * // Wildcard match\n * matchesHeadingPattern(\"## Required Skills: None\", \"## Required Skills:*\"); // true\n * matchesHeadingPattern(\"## Required Skills: foo, bar\", \"## Required Skills:*\"); // true\n *\n * // No match\n * matchesHeadingPattern(\"## Implementation\", \"## Overview\"); // false\n * ```\n */\nfunction matchesHeadingPattern(heading: string, pattern: string): boolean {\n  // Normalize whitespace\n  const normalizedHeading = heading.replace(/\\s+/g, ' ').trim();\n  const normalizedPattern = pattern.replace(/\\s+/g, ' ').trim();\n\n  // Exact match\n  if (normalizedHeading === normalizedPattern) {\n    return true;\n  }\n\n  // Wildcard pattern\n  const regexPattern = normalizedPattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*');\n\n  const regex = new RegExp(`^${regexPattern}$`, 'i');\n  return regex.test(normalizedHeading);\n}\n\n/**\n * Validate that all required headings are present in content\n *\n * Checks that each required heading pattern has at least one match in the\n * provided headings array. Supports wildcard patterns for flexible matching.\n *\n * @param headings - Array of headings extracted from markdown content\n * @param required - Array of required heading patterns (supports wildcards)\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const headings = [\"# Title\", \"## Overview\", \"## Implementation\"];\n * const required = [\"## Overview\", \"## Implementation\", \"## Testing\"];\n *\n * const result = validateRequiredHeadings(headings, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required heading missing: \"## Testing\"']\n * // }\n * ```\n */\nfunction validateRequiredHeadings(headings: string[], required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const requiredPattern of required) {\n    const found = headings.some(h => matchesHeadingPattern(h, requiredPattern));\n    if (!found) {\n      errors.push(`Required heading missing: \"${requiredPattern}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Validate that all required metadata fields are present in frontmatter\n *\n * Checks that each required metadata field exists in the YAML frontmatter object.\n * Fields with falsy values are considered missing.\n *\n * @param metadata - Parsed YAML frontmatter object\n * @param required - Array of required field names\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const metadata = { name: \"My Skill\", version: \"1.0\" };\n * const required = [\"name\", \"description\", \"version\"];\n *\n * const result = validateRequiredMetadata(metadata, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required metadata field missing: \"description\"']\n * // }\n * ```\n */\nfunction validateRequiredMetadata(metadata: Record<string, unknown>, required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const field of required) {\n    if (!metadata[field]) {\n      errors.push(`Required metadata field missing: \"${field}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Determine file type and return appropriate validation rules\n *\n * Analyzes the file path to determine its type (agent, skill, rule, or CLAUDE.md)\n * and returns the corresponding validation requirements. Returns null for\n * non-markdown files or files that don't match any validation pattern.\n *\n * @param filePath - The path to the file being validated (absolute or relative)\n * @param cwd - The current working directory for resolving relative paths\n * @returns Validation rules object with type and requirements, or null if no validation needed\n *\n * @example\n * ```typescript\n * // Agent file\n * const rules1 = getFileValidationRules('.claude/agents/explorer.md', '/project');\n * // Returns: {\n * //   type: 'agent',\n * //   requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n * //   shouldValidate: true\n * // }\n *\n * // Skill file\n * const rules2 = getFileValidationRules('.claude/skills/my-skill/docs.md', '/project');\n * // Returns: {\n * //   type: 'skill',\n * //   requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n * //   requiredMetadata: ['name', 'description'],\n * //   shouldValidate: true\n * // }\n *\n * // SKILL.md template (skipped)\n * const rules3 = getFileValidationRules('.claude/skills/my-skill/SKILL.md', '/project');\n * // Returns: { type: 'skill-template', shouldValidate: false }\n *\n * // Non-markdown file\n * const rules4 = getFileValidationRules('src/index.ts', '/project');\n * // Returns: null\n * ```\n */\nfunction getFileValidationRules(filePath: string, cwd: string): {\n  type: string;\n  requiredHeadings?: string[];\n  requiredMetadata?: string[];\n  shouldValidate: boolean;\n} | null {\n  const relativePath = path.isAbsolute(filePath)\n    ? path.relative(cwd, filePath)\n    : filePath;\n\n  if (DEBUG) {\n    console.log('[enforce-structured-markdown] Checking file type:', relativePath);\n  }\n\n  // Agent files: .claude/agents/*.md\n  if (relativePath.includes(path.join('.claude', 'agents')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'agent',\n      requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n      shouldValidate: true,\n    };\n  }\n\n  // Skill files: .claude/skills/*/*.md (excluding SKILL.md and SKILL.template.md)\n  if (relativePath.includes(path.join('.claude', 'skills')) && relativePath.endsWith('.md')) {\n    const basename = path.basename(relativePath);\n    if (basename === 'SKILL.md' || basename === 'SKILL.template.md') {\n      if (DEBUG) {\n        console.log('[enforce-structured-markdown] Skipping SKILL.md or SKILL.template.md');\n      }\n      return { type: 'skill-template', shouldValidate: false };\n    }\n    return {\n      type: 'skill',\n      requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  // Rules files: .claude/rules/*.md\n  if (relativePath.includes(path.join('.claude', 'rules')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'rule',\n      requiredHeadings: ['## Rules'],\n      requiredMetadata: ['Required Skills'],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin README files: plugins/*/README.md\n  if (relativePath.match(/^plugins\\/[^/]+\\/README\\.md$/)) {\n    return {\n      type: 'plugin-readme',\n      requiredHeadings: [\n        '# 🔌 *',\n        '## 📋 Table of Contents',\n        '## 🎯 Overview',\n        '## ✨ Features',\n        '## 📦 Installation',\n        '## 🪝 Hooks',\n        '## ⚙️ Configuration',\n        '## 💡 Use Cases',\n        '## 🐛 Troubleshooting',\n        '## 🤝 Contributing',\n        '## 📚 See Also',\n        '## 📄 License',\n      ],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin CLAUDE.md files: plugins/*/CLAUDE.md (must come before general CLAUDE.md check)\n  if (relativePath.match(/^plugins\\/[^/]+\\/CLAUDE\\.md$/)) {\n    return {\n      type: 'plugin-claude',\n      requiredHeadings: [\n        '# *',\n        '## Quick Reference',\n        '## Hook Summary',\n        '## Key Features',\n        '## Installation',\n        '## Debug Logging',\n        '## See Also',\n      ],\n      requiredMetadata: ['title', 'description', 'version', 'folder'],\n      shouldValidate: true,\n    };\n  }\n\n  // CLAUDE.md files (any directory)\n  if (path.basename(relativePath) === 'CLAUDE.md') {\n    return {\n      type: 'claude-md',\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  return null;\n}\n\n/**\n * Extract the final content that will be written to the file\n *\n * Handles both Write and Edit operations to determine the content that will\n * result from the tool use. For Write, returns the content directly. For Edit,\n * reads the current file and applies the edit operation to get the final content.\n *\n * @param toolName - The tool being used (\"Write\" or \"Edit\")\n * @param toolInput - The tool input parameters\n * @param cwd - The current working directory for resolving relative paths\n * @returns The final content after the operation, or null if content cannot be determined\n *\n * @example\n * ```typescript\n * // Write operation\n * const content1 = await getContentFromToolInput(\n *   'Write',\n *   { file_path: 'doc.md', content: '# Title\\n## Section' },\n *   '/project'\n * );\n * // Returns: '# Title\\n## Section'\n *\n * // Edit operation (replaces text)\n * // Assumes file currently contains: '# Old\\n## Section'\n * const content2 = await getContentFromToolInput(\n *   'Edit',\n *   {\n *     file_path: 'doc.md',\n *     old_string: '# Old',\n *     new_string: '# New'\n *   },\n *   '/project'\n * );\n * // Returns: '# New\\n## Section'\n * ```\n */\nasync function getContentFromToolInput(\n  toolName: string,\n  toolInput: {\n    file_path?: string;\n    content?: string;\n    old_string?: string;\n    new_string?: string;\n  },\n  cwd: string\n): Promise<string | null> {\n  if (toolName === 'Write') {\n    return toolInput.content || null;\n  } else if (toolName === 'Edit') {\n    const filePath = toolInput.file_path;\n    if (!filePath || !toolInput.old_string || !toolInput.new_string) {\n      return null;\n    }\n\n    try {\n      const fullPath = path.isAbsolute(filePath) ? filePath : path.resolve(cwd, filePath);\n      const currentContent = await fs.readFile(fullPath, 'utf-8');\n      // Apply the edit\n      return currentContent.replace(toolInput.old_string, toolInput.new_string);\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * PreToolUse hook that validates markdown structure before Write/Edit operations\n *\n * Intercepts Write and Edit tool uses on markdown files to validate that they\n * meet the structural requirements for their file type. Blocks operations that\n * would create invalid agent, skill, rule, or CLAUDE.md files.\n *\n * This hook:\n * 1. Only processes Write and Edit operations on .md files\n * 2. Determines the file type from its path\n * 3. Extracts headings and metadata from the content\n * 4. Validates against type-specific requirements\n * 5. Blocks invalid operations with detailed error messages\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Valid agent file - allowed\n * const result1 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_123',\n *   tool_input: {\n *     file_path: '.claude/agents/my-agent.md',\n *     content: `\n * # My Agent\n * ## Objective\n * Do the task\n * ## Principles\n * Be thorough\n * ## Agent-scoped project context\n * Uses TypeScript\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // Invalid skill file (missing required heading) - denied\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   tool_input: {\n *     file_path: '.claude/skills/my-skill/docs.md',\n *     content: `\n * ---\n * name: My Skill\n * description: Does things\n * ---\n * # My Skill\n * ## Purpose\n * This is the purpose\n * (missing ## Skill-scoped context heading)\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'Skill validation failed...\\n\\nRequired heading missing: \"## Skill-scoped context\"'\n * //   }\n * // }\n *\n * // Non-markdown file - allowed (no validation)\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   tool_input: {\n *     file_path: 'src/index.ts',\n *     content: 'export const foo = \"bar\";'\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'enforce-structured-markdown', DEBUG || false);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n\n    const filePath = toolInput.file_path;\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only process .md files\n    if (!filePath.endsWith('.md')) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get validation rules for this file type\n    const validationRules = getFileValidationRules(filePath, input.cwd);\n    if (!validationRules || !validationRules.shouldValidate) {\n      await logger.logOutput({ message: 'No validation rules for this file type or validation skipped' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get the content (handles both Write and Edit)\n    const content = await getContentFromToolInput(input.tool_name, toolInput, input.cwd);\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter and content\n    const { data: metadata } = matter(content);\n    const headings = extractHeadings(content);\n\n    const allErrors: string[] = [];\n\n    // Validate required metadata\n    if (validationRules.requiredMetadata && validationRules.requiredMetadata.length > 0) {\n      const metadataValidation = validateRequiredMetadata(\n        metadata as Record<string, unknown>,\n        validationRules.requiredMetadata\n      );\n      if (!metadataValidation.valid) {\n        allErrors.push(...metadataValidation.errors);\n      }\n    }\n\n    // Validate required headings\n    if (validationRules.requiredHeadings && validationRules.requiredHeadings.length > 0) {\n      const headingValidation = validateRequiredHeadings(headings, validationRules.requiredHeadings);\n      if (!headingValidation.valid) {\n        allErrors.push(...headingValidation.errors);\n      }\n    }\n\n    await logger.logOutput({\n      fileType: validationRules.type,\n      headings,\n      metadata: Object.keys(metadata),\n      valid: allErrors.length === 0,\n      errors: allErrors,\n    });\n\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n');\n      const fileTypeDisplay = validationRules.type.replace('-', ' ');\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `${fileTypeDisplay.charAt(0).toUpperCase() + fileTypeDisplay.slice(1)} validation failed for ${path.basename(filePath)}:\\n\\n${errorMessage}\\n\\nPlease ensure all required headings and metadata fields are present.`,\n        },\n      };\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Structured markdown validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-subagent-start.ts": "/**\n * Subagent context tracking hook\n *\n * SubagentStart hook that saves agent execution context when a subagent begins.\n * The saved context can be retrieved later in SubagentStop hooks to analyze what\n * the agent did and correlate it with the original Task tool call.\n *\n * This hook saves the following information to .claude/logs/subagent-tasks.json:\n * - Agent ID and type\n * - Session ID\n * - Original task prompt (from Task tool input)\n * - Tool use ID (for correlating with Task call)\n * - Timestamp\n *\n * The saved context enables SubagentStop hooks to generate rich commit messages,\n * track file operations, and analyze agent behavior.\n *\n * @module log-subagent-start\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../types/types.js';\nimport { saveAgentStartContext } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStart hook handler that saves agent context\n *\n * Intercepts subagent startup to save execution context for later retrieval.\n * This enables tracking what tasks agents were given and correlating SubagentStop\n * events with the original Task tool call.\n *\n * The hook is non-blocking - errors are logged but do not prevent agent execution.\n *\n * @param input - SubagentStart hook input with agent metadata\n * @returns Hook output (empty object, this hook does not modify agent behavior)\n *\n * @example\n * ```typescript\n * // When an agent starts via Task tool:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   cwd: '/path/to/project',\n *   transcript_path: '/path/.claude/logs/session-xyz.jsonl'\n * });\n *\n * // Context is saved to .claude/logs/subagent-tasks.json:\n * // {\n * //   \"agent-abc123\": {\n * //     \"agentId\": \"agent-abc123\",\n * //     \"agentType\": \"Explore\",\n * //     \"sessionId\": \"session-xyz\",\n * //     \"prompt\": \"Find all API endpoints\",\n * //     \"toolUseId\": \"toolu_xyz\",\n * //     \"timestamp\": \"2025-01-19T12:00:00.000Z\"\n * //   }\n * // }\n *\n * // Later, in SubagentStop, this context can be retrieved via getAgentEdits()\n * ```\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStart] Hook triggered');\n    console.log('[SubagentStart] Agent ID:', input.agent_id);\n    console.log('[SubagentStart] Agent Type:', input.agent_type);\n    console.log('[SubagentStart] Session ID:', input.session_id);\n  }\n\n  try {\n    const context = await saveAgentStartContext({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n      session_id: input.session_id,\n      cwd: input.cwd,\n      transcript_path: input.transcript_path,\n    });\n\n    if (DEBUG) {\n      console.log('[SubagentStart] Saved agent context');\n      console.log('[SubagentStart] Prompt:', context.prompt.slice(0, 100) + (context.prompt.length > 100 ? '...' : ''));\n      console.log('[SubagentStart] Tool Use ID:', context.toolUseId);\n      console.log('[SubagentStart] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStart] Error saving agent context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-subagent-stop.ts": "/**\n * Subagent completion analysis hook\n *\n * SubagentStop hook that analyzes agent execution results when a subagent completes.\n * It parses the agent's transcript to extract file operations and correlates them\n * with the saved context from SubagentStart.\n *\n * This hook analyzes and logs:\n * - New files created by the agent\n * - Files deleted by the agent\n * - Files edited by the agent\n * - Agent type and original task prompt\n * - Preloaded skills used by the agent\n *\n * After analysis, the hook cleans up the saved context from SubagentStart to prevent\n * the context file from growing indefinitely.\n *\n * The analysis results are logged to console when DEBUG mode is enabled, making it\n * easy to understand what each agent did during execution.\n *\n * @module log-subagent-stop\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../types/types.js';\nimport { getAgentEdits } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStop hook handler that analyzes agent execution results\n *\n * Intercepts subagent completion to analyze what the agent did during execution.\n * Parses the agent transcript to extract file operations and correlates with the\n * saved context from SubagentStart to provide complete execution metadata.\n *\n * The hook is non-blocking - errors are logged but do not prevent session continuation.\n *\n * @param input - SubagentStop hook input with agent transcript path\n * @returns Hook output (empty object, this hook does not modify behavior)\n *\n * @example\n * ```typescript\n * // When an agent completes:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_transcript_path: '/path/.claude/logs/agent-abc123.jsonl',\n *   cwd: '/path/to/project'\n * });\n *\n * // With DEBUG=* enabled, logs output like:\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Analysis Complete\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Type: Explore\n * // [SubagentStop] Agent Prompt: Find all API endpoints\n * // [SubagentStop] Files Created: 0\n * // [SubagentStop] Files Edited: 2\n * // [SubagentStop]   ~ src/api/routes.ts\n * // [SubagentStop]   ~ src/api/handlers.ts\n * // [SubagentStop] Files Deleted: 0\n * // [SubagentStop] ─────────────────────────────────────────\n *\n * // The saved context from SubagentStart is automatically cleaned up\n * ```\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStop] Hook triggered');\n    console.log('[SubagentStop] Agent ID:', input.agent_id);\n    console.log('[SubagentStop] Agent Transcript:', input.agent_transcript_path);\n  }\n\n  try {\n    const edits = await getAgentEdits(input.agent_transcript_path);\n\n    if (DEBUG) {\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Analysis Complete');\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Type:', edits.subagentType);\n      console.log('[SubagentStop] Agent Prompt:', edits.agentPrompt.slice(0, 100) + (edits.agentPrompt.length > 100 ? '...' : ''));\n\n      if (edits.agentFile) {\n        console.log('[SubagentStop] Agent Definition:', edits.agentFile);\n      }\n\n      if (edits.agentPreloadedSkillsFiles.length > 0) {\n        console.log('[SubagentStop] Preloaded Skills:', edits.agentPreloadedSkillsFiles.length);\n        edits.agentPreloadedSkillsFiles.forEach((skill) => {\n          console.log('[SubagentStop]   -', skill);\n        });\n      }\n\n      if (edits.agentNewFiles.length > 0) {\n        console.log('[SubagentStop] Files Created:', edits.agentNewFiles.length);\n        edits.agentNewFiles.forEach((file) => {\n          console.log('[SubagentStop]   +', file);\n        });\n      }\n\n      if (edits.agentEditedFiles.length > 0) {\n        console.log('[SubagentStop] Files Edited:', edits.agentEditedFiles.length);\n        edits.agentEditedFiles.forEach((file) => {\n          console.log('[SubagentStop]   ~', file);\n        });\n      }\n\n      if (edits.agentDeletedFiles.length > 0) {\n        console.log('[SubagentStop] Files Deleted:', edits.agentDeletedFiles.length);\n        edits.agentDeletedFiles.forEach((file) => {\n          console.log('[SubagentStop]   -', file);\n        });\n      }\n\n      if (edits.agentNewFiles.length === 0 &&\n          edits.agentEditedFiles.length === 0 &&\n          edits.agentDeletedFiles.length === 0) {\n        console.log('[SubagentStop] No file operations detected');\n      }\n\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStop] Error analyzing agent edits:', error);\n    }\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-task-call.ts": "/**\n * PreToolUse[Task] hook - Save task call context for later retrieval\n *\n * This hook runs when the Task tool is ABOUT to be called (before the subagent starts).\n * It saves the task's context (type, prompt, toolUseId) to .claude/logs/task-calls.json\n * so it can be retrieved later in PostToolUse[Task] or SubagentStop.\n *\n * Import this hook in any plugin that needs to track task execution.\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { saveTaskCallContext } from './utils/task-state.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[PreToolUse:Task] Hook triggered');\n    console.log('[PreToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PreToolUse:Task] Session ID:', input.session_id);\n  }\n\n  try {\n    const toolInput = input.tool_input as {\n      subagent_type?: string;\n      prompt?: string;\n    };\n\n    const agentType = toolInput?.subagent_type || 'unknown';\n    const prompt = toolInput?.prompt || '';\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Agent Type:', agentType);\n      console.log('[PreToolUse:Task] Prompt:', prompt.slice(0, 100) + (prompt.length > 100 ? '...' : ''));\n    }\n\n    const context = await saveTaskCallContext({\n      tool_use_id: input.tool_use_id,\n      agent_type: agentType,\n      session_id: input.session_id,\n      prompt,\n      cwd: input.cwd,\n    });\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Saved task call context');\n      console.log('[PreToolUse:Task] Tool Use ID:', context.toolUseId);\n      console.log('[PreToolUse:Task] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PreToolUse:Task] Error saving task call context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/log-task-result.ts": "/**\n * PostToolUse[Task] hook - Log task completion\n *\n * This hook runs when the Task tool completes (after the subagent finishes).\n * It logs the task completion for debugging and audit purposes.\n *\n * Note: For detailed file operations analysis, see the SubagentStop hooks\n * which have access to the full agent transcript.\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { loadTaskCallContext } from './utils/task-state.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:Task] Hook triggered');\n    console.log('[PostToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PostToolUse:Task] Session ID:', input.session_id);\n  }\n\n  const logger = createDebugLogger(input.cwd, 'log-task-result', true);\n\n  try {\n    // Load the saved context from PreToolUse\n    const context = await loadTaskCallContext(input.tool_use_id, input.cwd);\n\n    if (!context) {\n      if (DEBUG) {\n        console.log('[PostToolUse:Task] No saved context found for tool_use_id:', input.tool_use_id);\n      }\n      return {};\n    }\n\n    const toolResponse = input.tool_response;\n    const responseText = typeof toolResponse === 'string'\n      ? toolResponse\n      : JSON.stringify(toolResponse).slice(0, 500);\n\n    await logger.logOutput({\n      tool_use_id: input.tool_use_id,\n      agent_type: context.agentType,\n      prompt: context.prompt.slice(0, 200),\n      response: responseText.slice(0, 200),\n      success: true,\n    });\n\n    if (DEBUG) {\n      console.log('[PostToolUse:Task] Task completed');\n      console.log('[PostToolUse:Task] Agent Type:', context.agentType);\n      console.log('[PostToolUse:Task] Response:', responseText.slice(0, 100));\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PostToolUse:Task] Error logging task result:', error);\n    }\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/run-rule-checks.ts": "/**\n * Rule-based check runner for PostToolUse[Write|Edit] hooks\n *\n * Runs checks defined in `.claude/rules/*.md` file frontmatter.\n * Checks are blocking - if any check fails, the edit is blocked.\n *\n * Frontmatter format:\n * ```yaml\n * ---\n * globs: [\"**\\/*.ts\", \"**\\/*.tsx\", \"!**\\/*.test.ts\"]\n * checks:\n *   - lint\n *   - typecheck\n *   - vitest\n * ---\n * ```\n *\n * @module run-rule-checks\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { runHook } from './utils/io.js';\nimport { parseFrontmatter } from './utils/frontmatter.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { readdir, readFile } from 'fs/promises';\nimport { join, relative } from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for each check in milliseconds (30 seconds) */\nconst CHECK_TIMEOUT_MS = 30000;\n\n/** Supported check types and their commands */\nconst CHECK_COMMANDS: Record<string, (filePath: string) => string> = {\n  lint: (filePath) => `npx eslint \"${filePath}\"`,\n  typecheck: (filePath) => `npx tsc --noEmit \"${filePath}\"`,\n  vitest: (filePath) => `npx vitest run \"${filePath}\" --reporter=verbose`,\n};\n\n/**\n * Check result from running a single check\n */\ninterface CheckResult {\n  check: string;\n  passed: boolean;\n  output: string;\n}\n\n/**\n * Rule definition parsed from frontmatter\n */\ninterface RuleDefinition {\n  filePath: string;\n  globs: string[];\n  checks: string[];\n}\n\n/**\n * Simple glob pattern matcher\n *\n * Supports:\n * - `*` matches any characters except /\n * - `**` matches any characters including /\n * - `!` prefix for negation patterns\n *\n * @param pattern - Glob pattern to match\n * @param filePath - File path to test\n * @returns True if pattern matches (or doesn't match for negation)\n */\nfunction matchGlob(pattern: string, filePath: string): boolean {\n  // Handle negation patterns\n  if (pattern.startsWith('!')) {\n    return !matchGlob(pattern.slice(1), filePath);\n  }\n\n  // Convert glob to regex\n  // Use unique placeholders that won't appear in normal patterns\n  const DOUBLE_STAR_SLASH = '<<<DSS>>>';\n  const DOUBLE_STAR = '<<<DS>>>';\n\n  const regexPattern = pattern\n    // Escape special regex characters except * and ?\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    // Use placeholders to avoid * in replacements being re-replaced\n    .replace(/\\*\\*\\//g, DOUBLE_STAR_SLASH)   // Placeholder for **/\n    .replace(/\\*\\*/g, DOUBLE_STAR)            // Placeholder for **\n    // Convert single * to match anything except /\n    .replace(/\\*/g, '[^/]*')\n    // Convert ? to match single character (BEFORE restoring placeholders!)\n    .replace(/\\?/g, '.')\n    // Restore placeholders with proper regex patterns\n    .replace(new RegExp(DOUBLE_STAR_SLASH, 'g'), '(?:.*/)?')  // **/ becomes optional path prefix\n    .replace(new RegExp(DOUBLE_STAR, 'g'), '.*');             // ** becomes match anything\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(filePath);\n}\n\n/**\n * Check if a file path matches any of the glob patterns\n *\n * Processes patterns in order - positive patterns include, negative exclude.\n *\n * @param filePath - File path to check\n * @param patterns - Array of glob patterns\n * @returns True if file matches the patterns\n */\nfunction matchesPatterns(filePath: string, patterns: string[]): boolean {\n  // Normalize path separators\n  const normalizedPath = filePath.replace(/\\\\/g, '/');\n\n  let matched = false;\n\n  for (const pattern of patterns) {\n    if (pattern.startsWith('!')) {\n      // Negation pattern - if it matches, exclude\n      if (matchGlob(pattern.slice(1), normalizedPath)) {\n        matched = false;\n      }\n    } else {\n      // Positive pattern - if it matches, include\n      if (matchGlob(pattern, normalizedPath)) {\n        matched = true;\n      }\n    }\n  }\n\n  return matched;\n}\n\n/**\n * Load all rule files from .claude/rules/ directory\n *\n * @param cwd - Current working directory\n * @returns Array of parsed rule definitions\n */\nasync function loadRules(cwd: string): Promise<RuleDefinition[]> {\n  const rulesDir = join(cwd, '.claude', 'rules');\n  const rules: RuleDefinition[] = [];\n\n  try {\n    const files = await readdir(rulesDir);\n\n    for (const file of files) {\n      if (!file.endsWith('.md')) continue;\n\n      const filePath = join(rulesDir, file);\n      const content = await readFile(filePath, 'utf-8');\n      const { data } = parseFrontmatter(content);\n\n      // Extract globs and checks from frontmatter\n      const globs = Array.isArray(data.globs) ? (data.globs as string[]) : [];\n      const checks = Array.isArray(data.checks) ? (data.checks as string[]) : [];\n\n      // Only include rules that have both globs and checks\n      if (globs.length > 0 && checks.length > 0) {\n        rules.push({ filePath, globs, checks });\n      }\n    }\n  } catch {\n    // No rules directory or can't read it - that's fine\n  }\n\n  return rules;\n}\n\n/**\n * Run a single check on a file\n *\n * @param check - Check type to run (lint, typecheck, vitest)\n * @param filePath - Absolute path to file to check\n * @param cwd - Current working directory\n * @returns Check result with pass/fail and output\n */\nasync function runCheck(check: string, filePath: string, cwd: string): Promise<CheckResult> {\n  const commandFn = CHECK_COMMANDS[check];\n\n  if (!commandFn) {\n    return {\n      check,\n      passed: true,\n      output: `Unknown check type: ${check}`,\n    };\n  }\n\n  const command = commandFn(filePath);\n\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd,\n      timeout: CHECK_TIMEOUT_MS,\n    });\n\n    // Check passed\n    return {\n      check,\n      passed: true,\n      output: truncateOutput(stdout || stderr || 'Check passed'),\n    };\n  } catch (error) {\n    // Check failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'Check failed';\n\n    return {\n      check,\n      passed: false,\n      output: truncateOutput(output),\n    };\n  }\n}\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n *\n * @param output - Output string to truncate\n * @returns Truncated string with indicator if truncated\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs checks defined in matching rule files for the edited file.\n * Blocks if any check fails.\n *\n * @param input - PostToolUse hook input\n * @returns Hook output with blocking decision if checks fail\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath) {\n    return {};\n  }\n\n  // Get relative path for glob matching\n  const relativePath = relative(input.cwd, filePath).replace(/\\\\/g, '/');\n\n  // Load all rules\n  const rules = await loadRules(input.cwd);\n\n  // Find all checks that apply to this file\n  const checksToRun = new Set<string>();\n\n  for (const rule of rules) {\n    if (matchesPatterns(relativePath, rule.globs)) {\n      for (const check of rule.checks) {\n        checksToRun.add(check);\n      }\n    }\n  }\n\n  // If no checks apply, allow the edit\n  if (checksToRun.size === 0) {\n    return {};\n  }\n\n  // Run all applicable checks\n  const results: CheckResult[] = [];\n\n  for (const check of checksToRun) {\n    const result = await runCheck(check, filePath, input.cwd);\n    results.push(result);\n  }\n\n  // Check if any failed\n  const failedResults = results.filter((r) => !r.passed);\n\n  if (failedResults.length === 0) {\n    // All checks passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ Checks passed: ${[...checksToRun].join(', ')}`,\n      },\n    };\n  }\n\n  // Format failure message\n  const failureMessages = failedResults\n    .map((r) => `**${r.check}**:\\n${r.output}`)\n    .join('\\n\\n');\n\n  // Block the edit with actionable feedback\n  return {\n    decision: 'block',\n    reason: `Fix these errors before continuing:\\n\\n${failureMessages}`,\n    hookSpecificOutput: {\n      hookEventName: 'PostToolUse',\n      additionalContext: `❌ Checks failed: ${failedResults.map((r) => r.check).join(', ')}\\n\\n${failureMessages}`,\n    },\n  };\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/test-folder-hooks.sh": "#!/bin/bash\n# Test script for folder validation hooks\n# Tests validate-folder-structure-bash.ts and validate-folder-structure-write.ts\n\nset -e\n\necho \"Testing folder validation hooks...\"\necho \"\"\n\nCWD=\"/home/user/claude-code-plugins\"\nSESSION_ID=\"test-session-123\"\nTRANSCRIPT_PATH=\"/tmp/test-transcript.jsonl\"\n\n# Test 1: validate-folder-structure-bash.ts with allowed folder\necho \"=== Test 1: Bash hook - allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_1\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 2: validate-folder-structure-bash.ts with forbidden folder\necho \"=== Test 2: Bash hook - forbidden subfolder (should deny) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_2\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/invalid_folder\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 3: validate-folder-structure-bash.ts with mkdir -p\necho \"=== Test 3: Bash hook - mkdir with -p flag (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_3\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir -p shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 4: validate-folder-structure-bash.ts with non-mkdir command\necho \"=== Test 4: Bash hook - non-mkdir command (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_4\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"ls -la\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 5: validate-folder-structure-write.ts with allowed file\necho \"=== Test 5: Write hook - allowed file in allowed folder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_5\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 6: validate-folder-structure-write.ts with forbidden file\necho \"=== Test 6: Write hook - forbidden file (should deny if files spec exists) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_6\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/forbidden.exe\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 7: validate-folder-structure-write.ts with file in new subfolder\necho \"=== Test 7: Write hook - file in allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_7\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/types/new-type.ts\",\n    \"content\": \"export type NewType = string;\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 8: validate-folder-structure-write.ts with non-Write tool\necho \"=== Test 8: Write hook - non-Write tool (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_8\",\n  \"tool_name\": \"Read\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\necho \"All tests completed!\"\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/ci-status.ts": "/**\n * Shared CI status utilities for GitHub CI integration\n *\n * Provides common functions for checking CI status, waiting for checks,\n * extracting preview URLs, and formatting results. Used by:\n * - commit-task-await-ci-status.ts (SubagentStop)\n * - await-pr-status.ts (PostToolUse[Bash])\n * - commit-session-await-ci-status.ts (Stop)\n *\n * @module ci-status\n */\n\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum output characters for CI status (prevents context bloat) */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Default CI check timeout in milliseconds (10 minutes) */\nconst DEFAULT_TIMEOUT_MS = 600000;\n\n/** Polling interval for fail-fast CI checks in milliseconds (5 seconds) */\nconst POLL_INTERVAL_MS = 5000;\n\n/** Max consecutive empty check polls before assuming no CI configured */\nconst MAX_EMPTY_CHECK_POLLS = 3;\n\n/**\n * Branch sync status result\n */\nexport interface BranchSyncResult {\n  /** Whether branch is in sync with main */\n  inSync: boolean;\n  /** Number of commits behind main */\n  behindCount: number;\n  /** Number of commits ahead of main */\n  aheadCount: number;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Merge conflict check result\n */\nexport interface MergeConflictResult {\n  /** Whether PR has merge conflicts */\n  hasConflicts: boolean;\n  /** Mergeable state from GitHub */\n  mergeableState?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Fail-fast CI check result\n */\nexport interface FailFastResult {\n  /** Whether all checks passed */\n  success: boolean;\n  /** Blocking reason if failed */\n  blockReason?: string;\n  /** Failed check name if applicable */\n  failedCheck?: string;\n  /** All check statuses */\n  checks: CheckStatus[];\n  /** PR number if found */\n  prNumber?: number;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * Result from a CI check operation\n */\nexport interface CICheckResult {\n  /** Whether all CI checks passed */\n  success: boolean;\n  /** Combined output from CI checks */\n  output: string;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * CI run details from GitHub\n */\nexport interface CIRunDetails {\n  /** CI workflow URL */\n  url?: string;\n  /** CI status (queued, in_progress, completed) */\n  status?: string;\n  /** CI conclusion (success, failure, cancelled) */\n  conclusion?: string;\n  /** Workflow name */\n  name?: string;\n}\n\n/**\n * Individual check status\n */\nexport interface CheckStatus {\n  /** Check name */\n  name: string;\n  /** Check status emoji */\n  emoji: string;\n  /** Check status (success, failure, pending) */\n  status: string;\n  /** Details URL */\n  url?: string;\n}\n\n/**\n * PR existence check result\n */\nexport interface PRCheckResult {\n  /** Whether PR exists */\n  exists: boolean;\n  /** PR number if exists */\n  prNumber?: number;\n  /** PR URL if exists */\n  prUrl?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Preview URLs extracted from PR\n */\nexport interface PreviewUrls {\n  /** Web app preview URL */\n  webUrl?: string;\n  /** Marketing app preview URL */\n  marketingUrl?: string;\n  /** All preview URLs found */\n  allUrls: string[];\n}\n\n/**\n * Execute a shell command with timeout\n *\n * @param command - Command to execute\n * @param cwd - Working directory\n * @param timeout - Timeout in milliseconds (default: 30s)\n * @returns Command result with success flag and output\n *\n * @example\n * ```typescript\n * const result = await execCommand('gh pr list', '/path/to/repo');\n * if (result.success) {\n *   console.log(result.stdout);\n * }\n * ```\n */\nexport async function execCommand(\n  command: string,\n  cwd: string,\n  timeout = 30000\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a PR exists for the given branch\n *\n * @param branch - Branch name to check\n * @param cwd - Working directory\n * @returns PR check result with number and URL if exists\n *\n * @example\n * ```typescript\n * const prCheck = await checkPRExists('feature-branch', '/path/to/repo');\n * if (prCheck.exists) {\n *   console.log(`PR #${prCheck.prNumber}: ${prCheck.prUrl}`);\n * }\n * ```\n */\nexport async function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<PRCheckResult> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return { exists: false, error: 'GitHub CLI not installed' };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return { exists: false, error: 'GitHub CLI not authenticated' };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number,url --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return { exists: false, error: `gh pr list failed: ${prListResult.stderr}` };\n  }\n\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n    if (Array.isArray(prs) && prs.length > 0) {\n      return {\n        exists: true,\n        prNumber: prs[0].number,\n        prUrl: prs[0].url,\n      };\n    }\n    return { exists: false };\n  } catch {\n    return { exists: false, error: 'Failed to parse gh output' };\n  }\n}\n\n/**\n * Get PR number for the current branch\n *\n * @param cwd - Working directory\n * @returns PR number or null if no PR exists\n *\n * @example\n * ```typescript\n * const prNumber = await getPRForCurrentBranch('/path/to/repo');\n * if (prNumber) {\n *   const ciResult = await waitForCIChecks({ prNumber, cwd });\n * }\n * ```\n */\nexport async function getPRForCurrentBranch(cwd: string): Promise<number | null> {\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return null;\n  }\n\n  const prCheck = await checkPRExists(branchResult.stdout, cwd);\n  return prCheck.exists ? (prCheck.prNumber ?? null) : null;\n}\n\n/**\n * Wait for CI checks to complete on a PR\n *\n * Uses `gh pr checks --watch` to wait for all CI checks to finish.\n * Blocks until all checks complete or timeout is reached.\n *\n * @param options - Wait options\n * @param options.prNumber - PR number to check (required if no commitSha)\n * @param options.commitSha - Commit SHA to check (alternative to prNumber)\n * @param options.timeout - Timeout in milliseconds (default: 10 minutes)\n * @param cwd - Working directory\n * @returns CI check result with success status and output\n *\n * @example\n * ```typescript\n * const result = await waitForCIChecks({ prNumber: 123 }, '/path/to/repo');\n * if (result.success) {\n *   console.log('All CI checks passed!');\n * } else {\n *   console.log('CI failed:', result.output);\n * }\n * ```\n */\nexport async function waitForCIChecks(\n  options: {\n    prNumber?: number;\n    commitSha?: string;\n    timeout?: number;\n  },\n  cwd: string\n): Promise<CICheckResult> {\n  const { prNumber, commitSha, timeout = DEFAULT_TIMEOUT_MS } = options;\n\n  if (!prNumber && !commitSha) {\n    return { success: false, output: '', error: 'Either prNumber or commitSha required' };\n  }\n\n  try {\n    // Build command based on what we have\n    const target = prNumber ? prNumber.toString() : commitSha!;\n    const command = `gh pr checks ${target} --watch`;\n\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    const combinedOutput = `${stdout}\\n${stderr}`.trim();\n\n    // Check if all checks passed\n    const hasFailures =\n      combinedOutput.includes('fail') ||\n      combinedOutput.includes('X ') ||\n      combinedOutput.includes('cancelled');\n\n    return {\n      success: !hasFailures,\n      output: combinedOutput,\n    };\n  } catch (error: unknown) {\n    const err = error as {\n      stdout?: string;\n      stderr?: string;\n      message?: string;\n      killed?: boolean;\n    };\n    const errorOutput = err.stdout || err.stderr || err.message || 'Unknown error';\n\n    if (err.killed) {\n      return {\n        success: false,\n        output: errorOutput,\n        error: `CI check timeout (${Math.round(timeout / 60000)} minutes)`,\n      };\n    }\n\n    return {\n      success: false,\n      output: errorOutput,\n      error: 'Failed to watch CI checks',\n    };\n  }\n}\n\n/**\n * Get latest CI workflow run details\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns CI run details or null if not found\n *\n * @example\n * ```typescript\n * const ciRun = await getLatestCIRun(123, '/path/to/repo');\n * if (ciRun?.conclusion === 'success') {\n *   console.log('CI passed:', ciRun.url);\n * }\n * ```\n */\nexport async function getLatestCIRun(\n  prNumber: number,\n  cwd: string\n): Promise<CIRunDetails | null> {\n  const result = await execCommand(\n    `gh run list --limit 1 --json databaseId,displayTitle,status,conclusion,url`,\n    cwd\n  );\n\n  if (!result.success) {\n    return null;\n  }\n\n  try {\n    const runs = JSON.parse(result.stdout);\n    if (Array.isArray(runs) && runs.length > 0) {\n      const run = runs[0];\n      return {\n        url: run.url,\n        status: run.status,\n        conclusion: run.conclusion,\n        name: run.displayTitle,\n      };\n    }\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Extract Vercel preview URLs from PR comments\n *\n * Searches PR comments for Vercel bot URLs and categorizes them\n * by app type (web, marketing, etc).\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Preview URLs object with categorized URLs\n *\n * @example\n * ```typescript\n * const urls = await extractPreviewUrls(123, '/path/to/repo');\n * if (urls.webUrl) {\n *   console.log('Web preview:', urls.webUrl);\n * }\n * ```\n */\nexport async function extractPreviewUrls(\n  prNumber: number,\n  cwd: string\n): Promise<PreviewUrls> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return { allUrls: [] };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n\n    const vercelUrlPattern = /https:\\/\\/[a-z0-9-]+\\.vercel\\.app/g;\n    const allUrls: string[] = [];\n\n    for (const comment of comments) {\n      const matches = comment.body?.match(vercelUrlPattern) || [];\n      allUrls.push(...matches);\n    }\n\n    // Deduplicate URLs\n    const uniqueUrls = [...new Set(allUrls)];\n\n    // Identify web and marketing apps by URL pattern\n    const webUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-web-') || url.includes('web-') || url.match(/web\\.vercel\\.app/)\n    );\n    const marketingUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-marketing-') ||\n        url.includes('marketing-') ||\n        url.match(/marketing\\.vercel\\.app/)\n    );\n\n    return {\n      webUrl,\n      marketingUrl,\n      allUrls: uniqueUrls,\n    };\n  } catch {\n    return { allUrls: [] };\n  }\n}\n\n/**\n * Parse CI checks output into structured format\n *\n * @param output - Raw output from `gh pr checks`\n * @returns Array of parsed check statuses\n *\n * @example\n * ```typescript\n * const checks = parseCIChecks(ciOutput);\n * for (const check of checks) {\n *   console.log(`${check.emoji} ${check.name}: ${check.status}`);\n * }\n * ```\n */\nexport function parseCIChecks(output: string): CheckStatus[] {\n  const checks: CheckStatus[] = [];\n  const lines = output.split('\\n');\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (!trimmed) continue;\n\n    // Parse line format: \"✓ check-name\" or \"X check-name\" or \"* check-name\"\n    let emoji = '⏳';\n    let status = 'pending';\n\n    if (trimmed.startsWith('✓') || trimmed.includes('pass')) {\n      emoji = '✅';\n      status = 'success';\n    } else if (trimmed.startsWith('X') || trimmed.includes('fail')) {\n      emoji = '❌';\n      status = 'failure';\n    } else if (trimmed.includes('cancel')) {\n      emoji = '⚪';\n      status = 'cancelled';\n    }\n\n    // Extract check name (remove status indicator)\n    const name = trimmed.replace(/^[✓X*\\s]+/, '').split('\\t')[0].trim();\n\n    if (name) {\n      checks.push({ name, emoji, status });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Format CI status result as concise string\n *\n * Truncates output to MAX_OUTPUT_CHARS to prevent context bloat.\n *\n * @param result - CI check result\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const ciResult = await waitForCIChecks({ prNumber: 123 }, cwd);\n * const formatted = formatCIStatus(ciResult);\n * console.log(formatted);\n * ```\n */\nexport function formatCIStatus(\n  result: CICheckResult,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = '';\n\n  if (result.success) {\n    output = '✅ All CI checks passed';\n  } else if (result.error) {\n    output = `⚠️ ${result.error}`;\n  } else {\n    output = '❌ CI checks failed';\n  }\n\n  // Add check details if available\n  if (result.output) {\n    const checks = parseCIChecks(result.output);\n    if (checks.length > 0) {\n      const checkLines = checks.map((c) => `${c.emoji} ${c.name}`).join('\\n');\n      output += `\\n\\n${checkLines}`;\n    }\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n/**\n * Format full CI status with PR info and preview URLs\n *\n * @param prNumber - PR number\n * @param prUrl - PR URL\n * @param ciResult - CI check result\n * @param ciRun - CI run details\n * @param previewUrls - Preview URLs\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const status = formatFullCIStatus(\n *   123, 'https://github.com/...', ciResult, ciRun, previewUrls\n * );\n * ```\n */\nexport function formatFullCIStatus(\n  prNumber: number,\n  prUrl: string,\n  ciResult: CICheckResult,\n  ciRun: CIRunDetails | null,\n  previewUrls: PreviewUrls,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = `**PR #${prNumber}**\\n`;\n\n  // CI status\n  if (ciResult.success) {\n    output += '✅ All CI checks passed\\n';\n  } else if (ciResult.error) {\n    output += `⏱️ ${ciResult.error}\\n`;\n  } else {\n    output += '❌ CI checks failed\\n';\n  }\n\n  // CI run link\n  if (ciRun?.url) {\n    output += `🔗 [CI](${ciRun.url})\\n`;\n  }\n\n  // Preview URLs\n  if (previewUrls.allUrls.length > 0) {\n    output += `🌐 ${previewUrls.allUrls[0]}`;\n    if (previewUrls.allUrls.length > 1) {\n      output += ` (+${previewUrls.allUrls.length - 1})`;\n    }\n    output += '\\n';\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n// ============================================================================\n// Fail-Fast CI Checking\n// ============================================================================\n\n/**\n * Check if PR has merge conflicts\n *\n * Queries GitHub API for the PR's mergeable state and returns immediately\n * if conflicts are detected.\n *\n * @param prNumber - PR number to check\n * @param cwd - Working directory\n * @returns Merge conflict result\n *\n * @example\n * ```typescript\n * const conflicts = await checkMergeConflicts(123, '/path/to/repo');\n * if (conflicts.hasConflicts) {\n *   console.log('PR has merge conflicts!');\n * }\n * ```\n */\nexport async function checkMergeConflicts(\n  prNumber: number,\n  cwd: string\n): Promise<MergeConflictResult> {\n  const result = await execCommand(\n    `gh pr view ${prNumber} --json mergeable,mergeStateStatus`,\n    cwd\n  );\n\n  if (!result.success) {\n    return { hasConflicts: false, error: `Failed to check PR: ${result.stderr}` };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const mergeable = data.mergeable;\n    const mergeStateStatus = data.mergeStateStatus;\n\n    // CONFLICTING means merge conflicts exist\n    // UNKNOWN means GitHub is still calculating\n    const hasConflicts = mergeable === 'CONFLICTING' || mergeStateStatus === 'DIRTY';\n\n    return {\n      hasConflicts,\n      mergeableState: mergeStateStatus || mergeable,\n    };\n  } catch {\n    return { hasConflicts: false, error: 'Failed to parse PR data' };\n  }\n}\n\n/**\n * Check if branch is behind main/master\n *\n * Compares the current branch with the default branch (main or master)\n * to determine if it's out of date.\n *\n * @param cwd - Working directory\n * @returns Branch sync status result\n *\n * @example\n * ```typescript\n * const sync = await checkBranchSyncStatus('/path/to/repo');\n * if (!sync.inSync) {\n *   console.log(`Branch is ${sync.behindCount} commits behind main`);\n * }\n * ```\n */\nexport async function checkBranchSyncStatus(cwd: string): Promise<BranchSyncResult> {\n  // First, fetch to ensure we have latest remote refs\n  await execCommand('git fetch origin', cwd);\n\n  // Get current branch\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to get current branch' };\n  }\n  const currentBranch = branchResult.stdout;\n\n  // Determine main branch (main or master)\n  let mainBranch = 'main';\n  const mainCheck = await execCommand('git rev-parse --verify origin/main', cwd);\n  if (!mainCheck.success) {\n    const masterCheck = await execCommand('git rev-parse --verify origin/master', cwd);\n    if (masterCheck.success) {\n      mainBranch = 'master';\n    } else {\n      return { inSync: true, behindCount: 0, aheadCount: 0, error: 'No main/master branch found' };\n    }\n  }\n\n  // Count commits behind and ahead\n  const revListResult = await execCommand(\n    `git rev-list --left-right --count origin/${mainBranch}...${currentBranch}`,\n    cwd\n  );\n\n  if (!revListResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to compare branches' };\n  }\n\n  const [behind, ahead] = revListResult.stdout.split('\\t').map(Number);\n\n  return {\n    inSync: behind === 0,\n    behindCount: behind || 0,\n    aheadCount: ahead || 0,\n  };\n}\n\n/**\n * Get current CI check statuses without waiting\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of check statuses\n */\nasync function getCurrentCIChecks(prNumber: number, cwd: string): Promise<CheckStatus[]> {\n  const result = await execCommand(\n    `gh pr checks ${prNumber} --json name,state,conclusion`,\n    cwd\n  );\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const checks = JSON.parse(result.stdout);\n    return checks.map((check: { name: string; state: string; conclusion: string }) => {\n      let emoji = '⏳';\n      let status = 'pending';\n\n      if (check.state === 'COMPLETED') {\n        if (check.conclusion === 'SUCCESS') {\n          emoji = '✅';\n          status = 'success';\n        } else if (check.conclusion === 'FAILURE') {\n          emoji = '❌';\n          status = 'failure';\n        } else if (check.conclusion === 'CANCELLED') {\n          emoji = '⚪';\n          status = 'cancelled';\n        }\n      } else if (check.state === 'IN_PROGRESS') {\n        emoji = '🔄';\n        status = 'in_progress';\n      }\n\n      return { name: check.name, emoji, status };\n    });\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Await CI checks with fail-fast behavior\n *\n * Checks for blocking conditions in order:\n * 1. Merge conflicts - block immediately\n * 2. Branch out of date with main - block immediately\n * 3. Any CI check failure - block immediately (don't wait for rest)\n *\n * Only returns success if ALL checks pass.\n *\n * @param options - Check options\n * @param options.prNumber - PR number (optional, will detect from branch)\n * @param options.timeout - Max wait time in ms (default: 10 minutes)\n * @param options.pollInterval - Polling interval in ms (default: 5 seconds)\n * @param cwd - Working directory\n * @returns Fail-fast result with blocking reason if failed\n *\n * @example\n * ```typescript\n * const result = await awaitCIWithFailFast({ prNumber: 123 }, '/path/to/repo');\n * if (!result.success) {\n *   return {\n *     decision: 'block',\n *     reason: result.blockReason,\n *   };\n * }\n * ```\n */\nexport async function awaitCIWithFailFast(\n  options: {\n    prNumber?: number;\n    timeout?: number;\n    pollInterval?: number;\n  },\n  cwd: string\n): Promise<FailFastResult> {\n  const { timeout = DEFAULT_TIMEOUT_MS, pollInterval = POLL_INTERVAL_MS } = options;\n  let { prNumber } = options;\n\n  // Get PR number if not provided\n  if (!prNumber) {\n    prNumber = await getPRForCurrentBranch(cwd) ?? undefined;\n    if (!prNumber) {\n      return {\n        success: true,\n        checks: [],\n        error: 'No PR found for current branch - skipping CI check',\n      };\n    }\n  }\n\n  // 1. Check for merge conflicts FIRST\n  const conflictCheck = await checkMergeConflicts(prNumber, cwd);\n  if (conflictCheck.hasConflicts) {\n    return {\n      success: false,\n      blockReason: `❌ PR #${prNumber} has merge conflicts. Resolve conflicts before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 2. Check if branch is out of date with main\n  const syncCheck = await checkBranchSyncStatus(cwd);\n  if (!syncCheck.inSync && syncCheck.behindCount > 0) {\n    return {\n      success: false,\n      blockReason: `❌ Branch is ${syncCheck.behindCount} commit(s) behind main. Rebase or merge main before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 3. Poll CI checks with fail-fast on any failure\n  const startTime = Date.now();\n  let emptyCheckCount = 0;\n\n  while (Date.now() - startTime < timeout) {\n    const checks = await getCurrentCIChecks(prNumber, cwd);\n\n    if (checks.length === 0) {\n      emptyCheckCount++;\n      if (emptyCheckCount >= MAX_EMPTY_CHECK_POLLS) {\n        // No CI checks after multiple polls - assume no CI configured\n        return {\n          success: true,\n          checks: [],\n          prNumber,\n          error: 'No CI checks configured for this repository',\n        };\n      }\n      // No checks yet, wait and retry\n      await new Promise((resolve) => setTimeout(resolve, pollInterval));\n      continue;\n    }\n\n    emptyCheckCount = 0; // Reset when checks appear\n\n    // Check for any failures - fail fast!\n    const failedCheck = checks.find((c) => c.status === 'failure' || c.status === 'cancelled');\n    if (failedCheck) {\n      return {\n        success: false,\n        blockReason: `❌ CI check \"${failedCheck.name}\" failed. Fix before continuing.`,\n        failedCheck: failedCheck.name,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Check if all checks are complete and passed\n    const allComplete = checks.every((c) => c.status === 'success');\n    if (allComplete) {\n      return {\n        success: true,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Some checks still pending, wait and poll again\n    await new Promise((resolve) => setTimeout(resolve, pollInterval));\n  }\n\n  // Timeout reached\n  const finalChecks = await getCurrentCIChecks(prNumber, cwd);\n  const pendingChecks = finalChecks.filter((c) => c.status === 'pending' || c.status === 'in_progress');\n\n  return {\n    success: false,\n    blockReason: `⏱️ CI check timeout (${Math.round(timeout / 60000)} minutes). ${pendingChecks.length} check(s) still pending.`,\n    checks: finalChecks,\n    prNumber,\n    error: 'Timeout waiting for CI checks',\n  };\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/config-resolver.ts": "/**\n * Configuration File Resolver\n * Utilities for finding configuration files by traversing parent directories\n * @module config-resolver\n */\n\nimport { access } from 'fs/promises';\nimport * as path from 'path';\n\n/**\n * Find git repository root directory\n *\n * @param startDir - Directory to start searching from\n * @returns Absolute path to git root, or null if not in a git repository\n */\nasync function findGitRoot(startDir: string): Promise<string | null> {\n  let currentDir = startDir;\n\n  while (true) {\n    try {\n      await access(path.join(currentDir, '.git'));\n      return currentDir;\n    } catch {\n      const parent = path.dirname(currentDir);\n      if (parent === currentDir) return null; // Filesystem root\n      currentDir = parent;\n    }\n  }\n}\n\n/**\n * Find a configuration file by traversing parent directories\n *\n * @param startDir - Directory to start searching from (typically input.cwd)\n * @param configFileName - Name of config file to find (e.g., 'tsconfig.json')\n * @param stopAtGitRoot - Whether to stop at git repository root (default: true)\n * @returns Absolute path to config file directory, or null if not found\n *\n * @example\n * const configDir = await findConfigFile(input.cwd, 'eslint.config.mjs');\n * if (configDir) {\n *   await execAsync('npx eslint file.ts', { cwd: configDir });\n * }\n */\nexport async function findConfigFile(\n  startDir: string,\n  configFileName: string,\n  stopAtGitRoot: boolean = true\n): Promise<string | null> {\n  let currentDir = path.resolve(startDir);\n  const gitRoot = stopAtGitRoot ? await findGitRoot(currentDir) : null;\n\n  while (true) {\n    try {\n      // Check if config file exists in current directory\n      await access(path.join(currentDir, configFileName));\n      return currentDir;\n    } catch {\n      // Config not found in this directory\n    }\n\n    // Check if we should stop at git root\n    if (stopAtGitRoot && gitRoot && currentDir === gitRoot) {\n      return null;\n    }\n\n    // Move to parent directory\n    const parent = path.dirname(currentDir);\n    if (parent === currentDir) {\n      // Reached filesystem root\n      return null;\n    }\n\n    currentDir = parent;\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/debug.ts": "/**\n * Debug utilities for Claude Code hooks\n *\n * Provides logging and error handling with debug mode support. Hook events\n * are logged in JSONL format to .claude/logs/hook-events.json for debugging\n * and troubleshooting hook execution.\n *\n * Each log entry is a single JSON object per line with timestamp, event name,\n * type (input/output/error), and the associated data.\n *\n * @module debug\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst HOOK_EVENTS_FILE = 'hook-events.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface DebugConfig {\n  debug?: boolean;\n}\n\nexport interface HookEventEntry {\n  timestamp: string;\n  event: string;\n  type: 'input' | 'output' | 'error';\n  data: unknown;\n}\n\nexport interface DebugLogger {\n  logInput: (input: unknown) => Promise<void>;\n  logOutput: (output: unknown) => Promise<void>;\n  logError: (error: Error) => Promise<void>;\n}\n\n// ============================================================================\n// Debug Logging (JSONL append to hook-events.json)\n// ============================================================================\n\n/**\n * Append a hook event entry to hook-events.json (JSONL format)\n *\n * Writes a single-line JSON entry to the log file, creating the directory\n * structure if it doesn't exist. Failures are silently ignored to prevent\n * logging errors from breaking hook execution.\n *\n * @param cwd - The working directory where .claude/logs/ should be created\n * @param entry - The hook event entry to append to the log file\n * @returns Promise that resolves when the entry is written (or fails silently)\n *\n * @example\n * ```typescript\n * await appendHookEvent('/path/to/project', {\n *   timestamp: new Date().toISOString(),\n *   event: 'SessionStart',\n *   type: 'input',\n *   data: { cwd: '/path/to/project' }\n * });\n * ```\n */\nasync function appendHookEvent(cwd: string, entry: HookEventEntry): Promise<void> {\n  const logDir = path.join(cwd, LOGS_DIR);\n  const logFile = path.join(logDir, HOOK_EVENTS_FILE);\n\n  try {\n    await fs.mkdir(logDir, { recursive: true });\n    await fs.appendFile(logFile, JSON.stringify(entry) + '\\n', 'utf-8');\n  } catch {\n    // Silently fail - don't break hook execution for logging\n  }\n}\n\n/**\n * Create a debug logger for a hook execution\n *\n * Returns a logger object with methods for logging hook inputs, outputs, and errors\n * to .claude/logs/hook-events.json in JSONL format. Logging only occurs when debug\n * mode is enabled.\n *\n * @param cwd - The working directory where logs should be written\n * @param hookEventName - The name of the hook event (e.g., 'SessionStart', 'PostToolUse')\n * @param debug - Whether debug logging is enabled\n * @returns A DebugLogger with logInput, logOutput, and logError methods\n *\n * @example\n * ```typescript\n * import { createDebugLogger } from './debug.js';\n *\n * const logger = createDebugLogger('/path/to/project', 'SessionStart', true);\n *\n * await logger.logInput({ cwd: '/path/to/project', source: 'startup' });\n * await logger.logOutput({ success: true, message: 'Hook completed' });\n * ```\n */\nexport function createDebugLogger(\n  cwd: string,\n  hookEventName: string,\n  _debug: boolean\n): DebugLogger {\n  return {\n    logInput: async (input: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'input',\n        data: input,\n      });\n    },\n\n    logOutput: async (output: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'output',\n        data: output,\n      });\n    },\n\n    logError: async (error: Error) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'error',\n        data: {\n          name: error.name,\n          message: error.message,\n          stack: error.stack,\n        },\n      });\n    },\n  };\n}\n\n// ============================================================================\n// Error Handling\n// ============================================================================\n\n/**\n * Create a blocking error response for hooks\n *\n * Generates an appropriate error response object that blocks execution when\n * a hook error occurs in debug mode. The response format varies by hook event\n * type to match the expected output schema.\n *\n * @param hookEventName - The name of the hook event that errored\n * @param error - The error that occurred during hook execution\n * @returns A hook output object configured to block/deny with error details\n *\n * @example\n * ```typescript\n * import { createBlockingErrorResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   return createBlockingErrorResponse('PreToolUse', error as Error);\n *   // Returns: { hookSpecificOutput: { permissionDecision: 'deny', ... } }\n * }\n * ```\n */\nexport function createBlockingErrorResponse(\n  hookEventName: string,\n  error: Error\n): Record<string, unknown> {\n  const baseResponse = {\n    continue: false,\n    stopReason: `Hook error: ${error.message}`,\n    systemMessage: `Hook ${hookEventName} failed: ${error.message}`,\n  };\n\n  // Add hook-specific output based on event type\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        ...baseResponse,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'PostToolUse':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `Hook error: ${error.message}\\n${error.stack || ''}`,\n        },\n      };\n\n    case 'SubagentStop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    case 'UserPromptSubmit':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'Stop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    default:\n      return baseResponse;\n  }\n}\n\n/**\n * Create a pass-through response for hooks\n *\n * Generates an appropriate response object that allows execution to continue\n * when a hook error occurs and debug mode is disabled. The response format\n * varies by hook event type to match the expected output schema while permitting\n * normal Claude Code operation.\n *\n * @param hookEventName - The name of the hook event\n * @returns A hook output object configured to allow/pass-through\n *\n * @example\n * ```typescript\n * import { createPassthroughResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   if (!debugMode) {\n *     return createPassthroughResponse('PreToolUse');\n *     // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *   }\n * }\n * ```\n */\nexport function createPassthroughResponse(hookEventName: string): Record<string, unknown> {\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n\n    case 'PostToolUse':\n      return {};\n\n    case 'SessionStart':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n\n    case 'SubagentStart':\n      return {};\n\n    case 'SubagentStop':\n      return {};\n\n    default:\n      return {};\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/env-sync.ts": "/**\n * Environment variable synchronization utilities for turborepo workspaces\n *\n * Provides functions to collect, merge, validate, and distribute environment variables\n * across multiple workspaces in a turborepo project. Ensures consistent environment\n * configuration across all apps.\n *\n * Supported frameworks and their env var prefixes:\n * - Next.js: NEXT_PUBLIC_* for client-side, unprefixed for server-side\n * - Vite: VITE_* for client-side\n * - Cloudflare Workers: Unprefixed in dev.vars\n *\n * @module env-sync\n */\n\nimport { existsSync, readFileSync, writeFileSync, readdirSync } from 'fs';\nimport { join } from 'path';\nimport { isPortAvailable } from './port.js';\n\n/**\n * Workspace framework type for environment variable prefixing\n */\nexport type WorkspaceFramework = 'nextjs' | 'vite' | 'cloudflare' | 'elysia' | 'unknown';\n\n/**\n * Detect if a workspace uses Supabase by checking dependencies\n *\n * Checks for:\n * 1. Direct Supabase SDK usage (@supabase/supabase-js, @supabase/ssr)\n * 2. Internal packages that wrap Supabase (@scope/supabase, *supabase*)\n *\n * @param workspacePath - Path to the workspace directory\n * @returns True if the workspace uses Supabase\n */\nexport function detectSupabaseUsage(workspacePath: string): boolean {\n  const packageJsonPath = join(workspacePath, 'package.json');\n  if (!existsSync(packageJsonPath)) {\n    return false;\n  }\n\n  try {\n    const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n    const allDeps = {\n      ...pkg.dependencies,\n      ...pkg.devDependencies,\n    };\n\n    // Check for direct Supabase SDK usage\n    if ('@supabase/supabase-js' in allDeps || '@supabase/ssr' in allDeps) {\n      return true;\n    }\n\n    // Check for internal packages that wrap Supabase\n    // Pattern: @{scope}/supabase, @{scope}/*supabase*, *supabase*\n    for (const dep of Object.keys(allDeps)) {\n      // Match patterns like @nodes-md/supabase, @repo/supabase, my-supabase-wrapper\n      if (\n        dep.endsWith('/supabase') || // @scope/supabase\n        /^@[^/]+\\/.*supabase.*$/.test(dep) // @scope/*supabase*\n      ) {\n        return true;\n      }\n    }\n\n    return false;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if ANY workspace in the monorepo uses Supabase directly\n *\n * This is a fallback for monorepos where apps depend on internal packages\n * that wrap Supabase. If any package in packages/ has @supabase dependencies,\n * we assume all apps may need the env vars.\n *\n * @param cwd - Root directory of the monorepo\n * @returns True if any package uses Supabase\n */\nexport function hasSupabaseInMonorepo(cwd: string): boolean {\n  const packagesDir = join(cwd, 'packages');\n  if (!existsSync(packagesDir)) {\n    return false;\n  }\n\n  try {\n    const entries = readdirSync(packagesDir, { withFileTypes: true });\n    for (const entry of entries) {\n      if (!entry.isDirectory()) continue;\n\n      const pkgPath = join(packagesDir, entry.name, 'package.json');\n      if (!existsSync(pkgPath)) continue;\n\n      try {\n        const pkg = JSON.parse(readFileSync(pkgPath, 'utf-8'));\n        const allDeps = { ...pkg.dependencies, ...pkg.devDependencies };\n        if ('@supabase/supabase-js' in allDeps || '@supabase/ssr' in allDeps) {\n          return true;\n        }\n      } catch {\n        continue;\n      }\n    }\n  } catch {\n    return false;\n  }\n\n  return false;\n}\n\n/**\n * Detect the framework type of a workspace based on config files\n * Falls back to checking package.json dependencies if no config files found\n *\n * @param workspacePath - Path to the workspace directory\n * @returns Detected framework type\n */\nexport function detectWorkspaceFramework(workspacePath: string): WorkspaceFramework {\n  // Check for Next.js config files first\n  if (\n    existsSync(join(workspacePath, 'next.config.js')) ||\n    existsSync(join(workspacePath, 'next.config.mjs')) ||\n    existsSync(join(workspacePath, 'next.config.ts'))\n  ) {\n    return 'nextjs';\n  }\n\n  // Check for Vite config files\n  if (\n    existsSync(join(workspacePath, 'vite.config.ts')) ||\n    existsSync(join(workspacePath, 'vite.config.js')) ||\n    existsSync(join(workspacePath, 'vite.config.mjs'))\n  ) {\n    return 'vite';\n  }\n\n  // Check for Cloudflare Workers\n  if (\n    existsSync(join(workspacePath, 'wrangler.toml')) ||\n    existsSync(join(workspacePath, 'wrangler.jsonc'))\n  ) {\n    return 'cloudflare';\n  }\n\n  // Fallback: Check package.json dependencies for framework detection\n  // This catches cases where config files are missing but deps indicate the framework\n  const packageJsonPath = join(workspacePath, 'package.json');\n  if (existsSync(packageJsonPath)) {\n    try {\n      const pkg = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));\n      const allDeps = { ...pkg.dependencies, ...pkg.devDependencies };\n\n      // Check for Next.js dependency\n      if ('next' in allDeps) {\n        return 'nextjs';\n      }\n\n      // Check for Vite dependency\n      if ('vite' in allDeps) {\n        return 'vite';\n      }\n\n      // Check for Cloudflare/Wrangler dependency\n      if ('wrangler' in allDeps || '@cloudflare/workers-types' in allDeps) {\n        return 'cloudflare';\n      }\n\n      // Check for Elysia dependency (Bun framework)\n      if ('elysia' in allDeps) {\n        return 'elysia';\n      }\n    } catch {\n      // Ignore parse errors\n    }\n  }\n\n  return 'unknown';\n}\n\n/**\n * Get the public environment variable prefix for a framework\n *\n * @param framework - The workspace framework type\n * @returns The prefix to use for client-exposed environment variables\n */\nexport function getPublicEnvPrefix(framework: WorkspaceFramework): string {\n  switch (framework) {\n    case 'nextjs':\n      return 'NEXT_PUBLIC_';\n    case 'vite':\n      return 'VITE_';\n    case 'elysia':\n    case 'cloudflare':\n    default:\n      return '';\n  }\n}\n\n/**\n * Environment variable sets organized by source\n */\nexport interface EnvVarSet {\n  /** Environment variables from Supabase CLI (SUPABASE_URL, etc.) */\n  supabaseVars: Record<string, string>;\n  /** Environment variables from Vercel CLI */\n  vercelVars: Record<string, string>;\n  /** Next.js prefixed variables (NEXT_PUBLIC_*) */\n  nextjsVars: Record<string, string>;\n  /** Cloudflare variables (unprefixed for dev.vars) */\n  cloudflareVars: Record<string, string>;\n}\n\n/**\n * Options for distributing environment variables\n */\nexport interface DistributeOptions {\n  /** Create .env.local and dev.vars files if they don't exist */\n  createIfMissing: boolean;\n  /** Preserve existing environment variables (don't overwrite) */\n  preserveExisting: boolean;\n  /** Keys that should always be overwritten, even if preserveExisting is true */\n  alwaysOverwriteKeys?: string[];\n}\n\n/**\n * Validation result for environment variables\n */\nexport interface ValidationResult {\n  /** Whether all required variables are present */\n  valid: boolean;\n  /** List of missing required variables */\n  missing: string[];\n}\n\n/**\n * Read and parse a .env.local file\n *\n * Parses a .env.local file into a key-value object. Handles:\n * - Comments starting with #\n * - Empty lines\n * - KEY=value format\n * - Quoted values\n *\n * @param path - Path to the directory containing .env.local\n * @returns Object with parsed environment variables\n *\n * @example\n * ```typescript\n * import { readEnvLocalFile } from './env-sync.js';\n *\n * const vars = await readEnvLocalFile('/path/to/app');\n * console.log(vars.NEXT_PUBLIC_SUPABASE_URL);\n * ```\n */\nexport async function readEnvLocalFile(path: string): Promise<Record<string, string>> {\n  const envPath = join(path, '.env.local');\n  if (!existsSync(envPath)) {\n    return {};\n  }\n\n  const content = readFileSync(envPath, 'utf-8');\n  const vars: Record<string, string> = {};\n\n  for (const line of content.split('\\n')) {\n    const trimmed = line.trim();\n\n    // Skip empty lines and comments\n    if (!trimmed || trimmed.startsWith('#')) {\n      continue;\n    }\n\n    // Parse KEY=value\n    const eqIndex = trimmed.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = trimmed.slice(0, eqIndex).trim();\n    let value = trimmed.slice(eqIndex + 1).trim();\n\n    // Remove surrounding quotes\n    if ((value.startsWith('\"') && value.endsWith('\"')) ||\n        (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n      value = value.slice(1, -1);\n    }\n\n    vars[key] = value;\n  }\n\n  return vars;\n}\n\n/**\n * Merge environment variables from multiple workspace .env.local files\n *\n * Reads .env.local files from all workspaces and merges them into a single\n * object. Later workspaces override earlier ones if there are conflicts.\n *\n * @param workspaces - Array of workspace paths relative to cwd\n * @param cwd - Root directory of the project\n * @returns Merged environment variables\n *\n * @example\n * ```typescript\n * import { mergeWorkspaceEnvVars } from './env-sync.js';\n *\n * const vars = await mergeWorkspaceEnvVars(\n *   ['apps/web', 'apps/api', 'apps/mcp'],\n *   '/path/to/project'\n * );\n * ```\n */\nexport async function mergeWorkspaceEnvVars(\n  workspaces: string[],\n  cwd: string\n): Promise<Record<string, string>> {\n  const merged: Record<string, string> = {};\n\n  for (const workspace of workspaces) {\n    const workspacePath = join(cwd, workspace);\n    const vars = await readEnvLocalFile(workspacePath);\n    Object.assign(merged, vars);\n  }\n\n  return merged;\n}\n\n/**\n * Validate that required environment variables are present\n *\n * Checks that all required variables exist in at least one of the variable sets.\n *\n * @param vars - Environment variable sets to validate\n * @param required - List of required variable names\n * @returns Validation result with missing variables\n *\n * @example\n * ```typescript\n * import { validateEnvVars } from './env-sync.js';\n *\n * const result = validateEnvVars(\n *   { supabaseVars, vercelVars },\n *   ['SUPABASE_URL', 'SUPABASE_PUBLISHABLE_KEY']\n * );\n *\n * if (!result.valid) {\n *   console.warn('Missing vars:', result.missing);\n * }\n * ```\n */\nexport function validateEnvVars(\n  vars: Partial<EnvVarSet>,\n  required: string[]\n): ValidationResult {\n  const allVars = {\n    ...vars.supabaseVars,\n    ...vars.vercelVars,\n    ...vars.nextjsVars,\n    ...vars.cloudflareVars,\n  };\n\n  const missing: string[] = [];\n  for (const key of required) {\n    if (!(key in allVars)) {\n      missing.push(key);\n    }\n  }\n\n  return {\n    valid: missing.length === 0,\n    missing,\n  };\n}\n\n/**\n * Distribute environment variables to a workspace\n *\n * Writes environment variables to .env.local (for Next.js) and dev.vars\n * (for Cloudflare Workers) in the specified workspace directory.\n *\n * @param workspacePath - Path to the workspace directory\n * @param vars - Environment variable sets to distribute\n * @param options - Distribution options\n * @returns Object indicating which files were written\n *\n * @example\n * ```typescript\n * import { distributeEnvVars } from './env-sync.js';\n *\n * const result = await distributeEnvVars(\n *   '/path/to/apps/web',\n *   { supabaseVars, vercelVars },\n *   { createIfMissing: true, preserveExisting: true }\n * );\n *\n * if (result.nextjs) console.log('Next.js .env.local updated');\n * if (result.vite) console.log('Vite .env.local updated');\n * if (result.cloudflare) console.log('dev.vars updated');\n * ```\n */\nexport async function distributeEnvVars(\n  workspacePath: string,\n  vars: Partial<EnvVarSet>,\n  options: DistributeOptions\n): Promise<{ nextjs: boolean; vite: boolean; cloudflare: boolean }> {\n  let nextjsWritten = false;\n  let viteWritten = false;\n  let cloudflareWritten = false;\n\n  // Detect workspace framework to use correct prefix\n  const framework = detectWorkspaceFramework(workspacePath);\n  const publicPrefix = getPublicEnvPrefix(framework);\n\n  // Prepare combined vars for frontend frameworks (Next.js or Vite)\n  const frontendVars: Record<string, string> = {};\n\n  // Add Vercel vars FIRST - these may contain old values from existing env files\n  // Supabase vars will be applied last to ensure correct values always win\n  if (vars.vercelVars) {\n    for (const [key, value] of Object.entries(vars.vercelVars)) {\n      if (framework === 'vite' && key.startsWith('NEXT_PUBLIC_')) {\n        // Convert NEXT_PUBLIC_ to VITE_ for Vite workspaces\n        const unprefixed = key.replace('NEXT_PUBLIC_', '');\n        frontendVars[`VITE_${unprefixed}`] = value;\n      } else {\n        frontendVars[key] = value;\n      }\n    }\n  }\n\n  // Add explicit Next.js vars (convert prefix for Vite)\n  if (vars.nextjsVars) {\n    for (const [key, value] of Object.entries(vars.nextjsVars)) {\n      if (framework === 'vite' && key.startsWith('NEXT_PUBLIC_')) {\n        const unprefixed = key.replace('NEXT_PUBLIC_', '');\n        frontendVars[`VITE_${unprefixed}`] = value;\n      } else {\n        frontendVars[key] = value;\n      }\n    }\n  }\n\n  // Add Supabase vars LAST with framework-specific prefix\n  // Applied last so fresh values from Supabase CLI always override stale env file values\n  if (vars.supabaseVars) {\n    for (const [key, value] of Object.entries(vars.supabaseVars)) {\n      if (key === 'SUPABASE_URL') {\n        frontendVars[`${publicPrefix}SUPABASE_URL`] = value;\n      } else if (key === 'SUPABASE_PUBLISHABLE_KEY') {\n        frontendVars[`${publicPrefix}SUPABASE_PUBLISHABLE_KEY`] = value;\n      } else if (key === 'SUPABASE_SECRET_KEY') {\n        frontendVars['SUPABASE_SECRET_KEY'] = value; // No prefix for secret\n      }\n    }\n  }\n\n  // Write to .env.local for frontend frameworks (Next.js or Vite)\n  const envLocalPath = join(workspacePath, '.env.local');\n  if ((framework === 'nextjs' || framework === 'vite') && Object.keys(frontendVars).length > 0) {\n    if (existsSync(envLocalPath)) {\n      // Merge with existing, respecting alwaysOverwriteKeys\n      const existing = await readEnvLocalFile(workspacePath);\n\n      // Split vars into protected (always overwrite) and regular\n      const protectedKeys = new Set(options.alwaysOverwriteKeys || []);\n      const protectedVars: Record<string, string> = {};\n      const regularVars: Record<string, string> = {};\n\n      for (const [key, value] of Object.entries(frontendVars)) {\n        if (protectedKeys.has(key)) {\n          protectedVars[key] = value;\n        } else {\n          regularVars[key] = value;\n        }\n      }\n\n      // Merge: regular vars respect preserveExisting, protected vars always overwrite\n      const mergedRegular = options.preserveExisting\n        ? { ...regularVars, ...existing } // Existing takes precedence for regular vars\n        : { ...existing, ...regularVars }; // New takes precedence for regular vars\n\n      // Protected vars always overwrite, applied last\n      const merged = { ...mergedRegular, ...protectedVars };\n\n      const lines = Object.entries(merged).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(envLocalPath, lines.join('\\n') + '\\n');\n      if (framework === 'nextjs') {\n        nextjsWritten = true;\n      } else {\n        viteWritten = true;\n      }\n    } else if (options.createIfMissing) {\n      const lines = Object.entries(frontendVars).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(envLocalPath, lines.join('\\n') + '\\n');\n      if (framework === 'nextjs') {\n        nextjsWritten = true;\n      } else {\n        viteWritten = true;\n      }\n    }\n  }\n\n  // Prepare vars for Cloudflare (unprefixed)\n  const cloudflareVars: Record<string, string> = {};\n\n  // Add Vercel vars FIRST (strip NEXT_PUBLIC_ prefix for Cloudflare)\n  // These may contain old values from existing env files\n  if (vars.vercelVars) {\n    for (const [key, value] of Object.entries(vars.vercelVars)) {\n      if (key.startsWith('NEXT_PUBLIC_')) {\n        const unprefixed = key.replace('NEXT_PUBLIC_', '');\n        cloudflareVars[unprefixed] = value;\n      } else {\n        cloudflareVars[key] = value;\n      }\n    }\n  }\n\n  // Add Cloudflare-specific vars\n  if (vars.cloudflareVars) {\n    Object.assign(cloudflareVars, vars.cloudflareVars);\n  }\n\n  // Add Supabase vars LAST without NEXT_PUBLIC_ prefix\n  // Applied last so fresh values from Supabase CLI always override stale env file values\n  if (vars.supabaseVars) {\n    Object.assign(cloudflareVars, vars.supabaseVars);\n  }\n\n  // Write to dev.vars (only if wrangler.toml/wrangler.jsonc exists)\n  const devVarsPath = join(workspacePath, 'dev.vars');\n  const hasWrangler = existsSync(join(workspacePath, 'wrangler.toml')) ||\n                      existsSync(join(workspacePath, 'wrangler.jsonc'));\n\n  if (hasWrangler && Object.keys(cloudflareVars).length > 0) {\n    if (existsSync(devVarsPath)) {\n      // Merge with existing, respecting alwaysOverwriteKeys\n      const existing = readFileSync(devVarsPath, 'utf-8');\n      const existingVars: Record<string, string> = {};\n\n      for (const line of existing.split('\\n')) {\n        const trimmed = line.trim();\n        if (!trimmed || trimmed.startsWith('#')) continue;\n\n        const eqIndex = trimmed.indexOf('=');\n        if (eqIndex === -1) continue;\n\n        const key = trimmed.slice(0, eqIndex).trim();\n        let value = trimmed.slice(eqIndex + 1).trim();\n        if ((value.startsWith('\"') && value.endsWith('\"')) ||\n            (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n          value = value.slice(1, -1);\n        }\n        existingVars[key] = value;\n      }\n\n      // Split vars into protected (always overwrite) and regular\n      // For Cloudflare, strip NEXT_PUBLIC_ prefix from protected keys\n      const protectedKeys = new Set(\n        (options.alwaysOverwriteKeys || []).map(key =>\n          key.startsWith('NEXT_PUBLIC_') ? key.replace('NEXT_PUBLIC_', '') : key\n        ).concat(\n          (options.alwaysOverwriteKeys || []).filter(key => key.startsWith('VITE_'))\n            .map(key => key.replace('VITE_', ''))\n        )\n      );\n      const protectedVars: Record<string, string> = {};\n      const regularVars: Record<string, string> = {};\n\n      for (const [key, value] of Object.entries(cloudflareVars)) {\n        if (protectedKeys.has(key)) {\n          protectedVars[key] = value;\n        } else {\n          regularVars[key] = value;\n        }\n      }\n\n      // Merge: regular vars respect preserveExisting, protected vars always overwrite\n      const mergedRegular = options.preserveExisting\n        ? { ...regularVars, ...existingVars }\n        : { ...existingVars, ...regularVars };\n\n      // Protected vars always overwrite, applied last\n      const merged = { ...mergedRegular, ...protectedVars };\n\n      const lines = Object.entries(merged).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(devVarsPath, lines.join('\\n') + '\\n');\n      cloudflareWritten = true;\n    } else if (options.createIfMissing) {\n      const lines = Object.entries(cloudflareVars).map(([key, value]) => `${key}=${value}`);\n      writeFileSync(devVarsPath, lines.join('\\n') + '\\n');\n      cloudflareWritten = true;\n    }\n  }\n\n  return { nextjs: nextjsWritten, vite: viteWritten, cloudflare: cloudflareWritten };\n}\n\n/**\n * Dev server port configuration for URL generation\n */\nexport interface DevServerPorts {\n  nextjs: number;\n  vite: number;\n  cloudflare: number;\n}\n\n/**\n * Workspace info for URL generation\n */\nexport interface WorkspaceInfo {\n  /** Workspace path relative to cwd (e.g., 'apps/web') */\n  path: string;\n  /** Workspace name (e.g., 'web') */\n  name: string;\n  /** Detected framework type */\n  framework: WorkspaceFramework;\n  /** Port configured in package.json dev script (--port flag), or null if not configured */\n  configuredPort: number | null;\n  /** Port after availability check - use this instead of configuredPort for URL generation */\n  resolvedPort?: number;\n}\n\n/**\n * Resolve ports for workspaces, checking availability and finding alternatives\n *\n * For each workspace:\n * 1. Try configuredPort (from package.json) if set\n * 2. Fall back to base port from DevServerPorts\n * 3. If port is unavailable, find next available at +10 increments\n *\n * This ensures multiple Claude sessions can run in parallel without port conflicts.\n *\n * @param workspaces - Array of workspace info objects (mutated with resolvedPort)\n * @param basePorts - Base ports for each framework type\n * @returns Promise resolving to the same array with resolvedPort filled in\n *\n * @example\n * ```typescript\n * import { resolveWorkspacePorts } from './env-sync.js';\n *\n * const workspaces = [\n *   { path: 'apps/app', name: 'app', framework: 'nextjs', configuredPort: 3100 },\n *   { path: 'apps/mcp', name: 'mcp', framework: 'cloudflare', configuredPort: 3102 },\n * ];\n *\n * await resolveWorkspacePorts(workspaces, { nextjs: 3000, vite: 5173, cloudflare: 8787 });\n * // If 3100 is in use: workspaces[0].resolvedPort = 3110\n * // If 3102 is in use: workspaces[1].resolvedPort = 3112\n * ```\n */\nexport async function resolveWorkspacePorts(\n  workspaces: WorkspaceInfo[],\n  basePorts: DevServerPorts\n): Promise<WorkspaceInfo[]> {\n  // Track ports we've already claimed in this resolution to avoid duplicates\n  const claimedPorts = new Set<number>();\n\n  // Only process workspaces with dev servers\n  const appWorkspaces = workspaces.filter(\n    (ws) =>\n      ws.framework === 'nextjs' || ws.framework === 'vite' || ws.framework === 'cloudflare'\n  );\n\n  for (const ws of appWorkspaces) {\n    // Determine the preferred port (configured or framework default)\n    const preferredPort = ws.configuredPort ?? basePorts[ws.framework as keyof DevServerPorts];\n\n    // Check if preferred port is available and not already claimed\n    const available = await isPortAvailable(preferredPort);\n    if (available && !claimedPorts.has(preferredPort)) {\n      ws.resolvedPort = preferredPort;\n      claimedPorts.add(preferredPort);\n      continue;\n    }\n\n    // Port not available, find next at +10 increments\n    const resolvedPort = await findAvailablePortExcluding(preferredPort, claimedPorts, 25);\n\n    if (resolvedPort !== null) {\n      ws.resolvedPort = resolvedPort;\n      claimedPorts.add(resolvedPort);\n    } else {\n      // Fallback: use preferred port anyway (will likely fail at runtime)\n      ws.resolvedPort = preferredPort;\n    }\n  }\n\n  return workspaces;\n}\n\n/**\n * Find available port at +10 increments, excluding already claimed ports\n */\nasync function findAvailablePortExcluding(\n  basePort: number,\n  excludePorts: Set<number>,\n  maxSlots: number = 25\n): Promise<number | null> {\n  for (let slot = 0; slot < maxSlots; slot++) {\n    const port = basePort + slot * 10;\n    if (excludePorts.has(port)) {\n      continue;\n    }\n    const available = await isPortAvailable(port);\n    if (available) {\n      return port;\n    }\n  }\n  return null;\n}\n\n/**\n * Generate per-app URL environment variables for all workspaces\n *\n * Creates self-reference URLs (NEXT_PUBLIC_APP_URL, APP_URL) and cross-app\n * reference URLs (NEXT_PUBLIC_WEB_URL, NEXT_PUBLIC_MCP_URL, etc.) so apps\n * can communicate with each other during local development.\n *\n * @param workspaces - Array of workspace info objects\n * @param ports - Dev server port configuration\n * @returns Map of workspace path to URL env vars for that workspace\n *\n * @example\n * ```typescript\n * import { generateAppUrls } from './env-sync.js';\n *\n * const urlVars = generateAppUrls(\n *   [\n *     { path: 'apps/app', name: 'app', framework: 'nextjs' },\n *     { path: 'apps/web', name: 'web', framework: 'nextjs' },\n *     { path: 'apps/mcp', name: 'mcp', framework: 'cloudflare' },\n *   ],\n *   { nextjs: 3100, vite: 5173, cloudflare: 3102 }\n * );\n *\n * // Result for apps/app:\n * // {\n * //   NEXT_PUBLIC_APP_URL: 'http://localhost:3100',\n * //   NEXT_PUBLIC_WEB_URL: 'http://localhost:3101',\n * //   NEXT_PUBLIC_MCP_URL: 'http://localhost:3102',\n * // }\n * ```\n */\nexport function generateAppUrls(\n  workspaces: WorkspaceInfo[],\n  ports: DevServerPorts\n): Map<string, Record<string, string>> {\n  const urlsByWorkspace = new Map<string, Record<string, string>>();\n\n  // Filter to only include actual app workspaces with dev servers\n  // Exclude npm packages (framework === 'unknown') which don't have dev servers\n  // This prevents generating URLs like NEXT_PUBLIC_SUPABASE_URL for packages/supabase\n  const appWorkspaces = workspaces.filter(ws =>\n    ws.framework === 'nextjs' ||\n    ws.framework === 'vite' ||\n    ws.framework === 'cloudflare' ||\n    ws.framework === 'elysia'\n  );\n\n  // First, calculate the actual port for each app workspace\n  // Use configuredPort if available, otherwise fall back to base + offset\n  const portsByType: Record<WorkspaceFramework, number> = {\n    nextjs: ports.nextjs,\n    vite: ports.vite,\n    cloudflare: ports.cloudflare,\n    elysia: ports.nextjs,  // Elysia uses port 3000 like Next.js\n    unknown: ports.nextjs,\n  };\n\n  const workspacePortMap = new Map<string, number>();\n  const usedPortsByType: Record<WorkspaceFramework, number[]> = {\n    nextjs: [],\n    vite: [],\n    cloudflare: [],\n    elysia: [],\n    unknown: [],\n  };\n\n  // Assign ports to each app workspace\n  // Priority: resolvedPort (after availability check) > configuredPort > base port + offset\n  for (const ws of appWorkspaces) {\n    let port: number;\n\n    if (ws.resolvedPort !== undefined) {\n      // Use pre-resolved port (already checked for availability)\n      port = ws.resolvedPort;\n    } else if (ws.configuredPort !== null) {\n      // Fallback to configured port (legacy behavior, no availability check)\n      port = ws.configuredPort;\n    } else {\n      // Fall back to base port + offset for workspaces without configured port\n      const basePort = portsByType[ws.framework];\n      const usedPorts = usedPortsByType[ws.framework];\n      const offset = usedPorts.length;\n      port = basePort + offset;\n    }\n\n    workspacePortMap.set(ws.path, port);\n    usedPortsByType[ws.framework].push(port);\n  }\n\n  // Generate URL vars for each app workspace\n  for (const ws of appWorkspaces) {\n    const port = workspacePortMap.get(ws.path)!;\n    const url = `http://localhost:${port}`;\n    const vars: Record<string, string> = {};\n\n    // Self-reference URL with app-specific naming\n    const nameUpper = ws.name.toUpperCase().replace(/-/g, '_');\n\n    if (ws.framework === 'nextjs') {\n      // Add both app-specific name and generic APP_URL for compatibility\n      vars[`NEXT_PUBLIC_${nameUpper}_URL`] = url;  // e.g., NEXT_PUBLIC_WEB_URL\n      vars['NEXT_PUBLIC_APP_URL'] = url;            // Backwards compatibility\n      vars[`${nameUpper}_URL`] = url;               // Server-side (WEB_URL)\n    } else if (ws.framework === 'vite') {\n      vars[`VITE_${nameUpper}_URL`] = url;\n      vars['VITE_APP_URL'] = url;\n      vars[`${nameUpper}_URL`] = url;\n    } else if (ws.framework === 'elysia') {\n      vars[`${nameUpper}_URL`] = url;\n      vars['APP_URL'] = url;\n    } else {\n      // Cloudflare workers - unprefixed\n      vars[`${nameUpper}_URL`] = url;\n      vars['APP_URL'] = url;\n    }\n\n    // Cross-app references (URLs to all other apps)\n    for (const otherWs of appWorkspaces) {\n      if (otherWs.path === ws.path) continue;\n\n      const otherPort = workspacePortMap.get(otherWs.path)!;\n      const otherUrl = `http://localhost:${otherPort}`;\n      const otherNameUpper = otherWs.name.toUpperCase().replace(/-/g, '_');\n\n      if (ws.framework === 'nextjs') {\n        vars[`NEXT_PUBLIC_${otherNameUpper}_URL`] = otherUrl;\n        vars[`${otherNameUpper}_URL`] = otherUrl;  // Also add unprefixed for server\n      } else if (ws.framework === 'vite') {\n        vars[`VITE_${otherNameUpper}_URL`] = otherUrl;\n        vars[`${otherNameUpper}_URL`] = otherUrl;\n      } else {\n        vars[`${otherNameUpper}_URL`] = otherUrl;\n      }\n    }\n\n    urlsByWorkspace.set(ws.path, vars);\n  }\n\n  return urlsByWorkspace;\n}\n\n/**\n * Collect environment variables from all sources\n *\n * Gathers environment variables from Supabase CLI (if running) and\n * from all workspace .env.local files (from Vercel pulls).\n *\n * @param cwd - Root directory of the project\n * @param workspaces - Array of workspace paths relative to cwd\n * @param supabaseVars - Optional Supabase variables (from Supabase CLI)\n * @returns Complete environment variable sets\n *\n * @example\n * ```typescript\n * import { collectEnvVars } from './env-sync.js';\n *\n * const vars = await collectEnvVars(\n *   '/path/to/project',\n *   ['apps/web', 'apps/api'],\n *   { SUPABASE_URL: 'http://localhost:54321', ... }\n * );\n * ```\n */\nexport async function collectEnvVars(\n  cwd: string,\n  workspaces: string[],\n  supabaseVars?: Record<string, string>\n): Promise<EnvVarSet> {\n  // Collect Supabase vars\n  const supabase = supabaseVars || {};\n\n  // Collect and merge Vercel vars from all workspaces\n  const vercel = await mergeWorkspaceEnvVars(workspaces, cwd);\n\n  // Separate Next.js prefixed vars\n  const nextjs: Record<string, string> = {};\n  const cloudflare: Record<string, string> = {};\n\n  for (const [key, value] of Object.entries(vercel)) {\n    if (key.startsWith('NEXT_PUBLIC_')) {\n      nextjs[key] = value;\n      // Also add unprefixed version for Cloudflare\n      cloudflare[key.replace('NEXT_PUBLIC_', '')] = value;\n    } else {\n      cloudflare[key] = value;\n    }\n  }\n\n  return {\n    supabaseVars: supabase,\n    vercelVars: vercel,\n    nextjsVars: nextjs,\n    cloudflareVars: cloudflare,\n  };\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/frontmatter.ts": "/**\n * Simple YAML frontmatter parser - zero dependencies\n *\n * Replaces gray-matter with a lightweight custom implementation\n * that handles the basic YAML frontmatter patterns used in this project.\n *\n * @module frontmatter\n */\n\n/**\n * Parse YAML frontmatter from markdown content\n *\n * Extracts YAML frontmatter between --- delimiters and parses\n * simple key-value pairs and arrays. Returns data object and remaining content.\n *\n * Supported YAML patterns:\n * - Simple key-value: `name: value`\n * - Arrays: `skills: [item1, item2]` or multi-line arrays\n * - Nested (basic): `field: { key: value }`\n *\n * @param content - Markdown content with optional frontmatter\n * @returns Object with `data` (parsed YAML) and `content` (remaining markdown)\n *\n * @example\n * ```typescript\n * import { parseFrontmatter } from './frontmatter.js';\n *\n * const markdown = `---\n * name: MyAgent\n * skills: [skill1, skill2]\n * ---\n *\n * # Content here\n * `;\n *\n * const { data, content } = parseFrontmatter(markdown);\n * console.log(data.name); // 'MyAgent'\n * console.log(data.skills); // ['skill1', 'skill2']\n * ```\n */\nexport function parseFrontmatter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  const frontmatterRegex = /^---\\s*\\n([\\s\\S]*?)\\n---\\s*\\n([\\s\\S]*)$/;\n  const match = content.match(frontmatterRegex);\n\n  if (!match) {\n    return { data: {}, content };\n  }\n\n  const [, yamlContent, remainingContent] = match;\n  const data = parseSimpleYaml(yamlContent);\n\n  return { data, content: remainingContent };\n}\n\n/**\n * Parse simple YAML content into JavaScript object\n *\n * Handles common YAML patterns used in frontmatter:\n * - Key-value pairs\n * - Inline arrays: [item1, item2, item3]\n * - Multi-line arrays with - prefix\n * - Nested objects (basic)\n *\n * @param yaml - YAML content string\n * @returns Parsed JavaScript object\n */\nfunction parseSimpleYaml(yaml: string): Record<string, unknown> {\n  const data: Record<string, unknown> = {};\n  const lines = yaml.split('\\n');\n  let i = 0;\n\n  while (i < lines.length) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      i++;\n      continue;\n    }\n\n    // Parse key-value pair\n    const colonIndex = line.indexOf(':');\n    if (colonIndex === -1) {\n      i++;\n      continue;\n    }\n\n    const key = line.substring(0, colonIndex).trim();\n    const value = line.substring(colonIndex + 1).trim();\n\n    // Handle inline array: [item1, item2]\n    if (value.startsWith('[') && value.endsWith(']')) {\n      const arrayContent = value.slice(1, -1);\n      data[key] = arrayContent.split(',').map(item => parseValue(item.trim()));\n      i++;\n      continue;\n    }\n\n    // Handle multi-line array\n    if (value === '' && i + 1 < lines.length && lines[i + 1].trim().startsWith('-')) {\n      const arrayItems: string[] = [];\n      i++;\n      while (i < lines.length && lines[i].trim().startsWith('-')) {\n        const item = lines[i].trim().substring(1).trim();\n        arrayItems.push(item);\n        i++;\n      }\n      data[key] = arrayItems;\n      continue;\n    }\n\n    // Handle inline object: { key: value }\n    if (value.startsWith('{') && value.endsWith('}')) {\n      const objectContent = value.slice(1, -1);\n      const obj: Record<string, unknown> = {};\n      const pairs = objectContent.split(',');\n      for (const pair of pairs) {\n        const [objKey, objValue] = pair.split(':').map(s => s.trim());\n        obj[objKey] = parseValue(objValue);\n      }\n      data[key] = obj;\n      i++;\n      continue;\n    }\n\n    // Handle simple value\n    data[key] = parseValue(value);\n    i++;\n  }\n\n  return data;\n}\n\n/**\n * Parse a YAML value to appropriate JavaScript type\n *\n * Converts:\n * - 'true'/'false' → boolean\n * - 'null' → null\n * - Numbers → number\n * - Quoted strings → unquoted string\n * - Everything else → string\n *\n * @param value - YAML value string\n * @returns Parsed value in appropriate type\n */\nfunction parseValue(value: string): unknown {\n  // Handle boolean\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle null\n  if (value === 'null' || value === '~') return null;\n\n  // Handle number\n  if (/^-?\\d+(\\.\\d+)?$/.test(value)) {\n    return Number(value);\n  }\n\n  // Handle quoted strings\n  if ((value.startsWith('\"') && value.endsWith('\"')) ||\n      (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n    return value.slice(1, -1);\n  }\n\n  // Return as string\n  return value;\n}\n\n/**\n * gray-matter compatible interface\n *\n * Provides same API as gray-matter for drop-in replacement.\n *\n * @param content - Markdown content with frontmatter\n * @returns Object with `data` and `content` properties\n */\nexport default function matter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  return parseFrontmatter(content);\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/github-comments.ts": "/**\n * GitHub comment utilities for Stop hook\n *\n * Provides utilities for:\n * - Checking if a session comment exists on a GitHub issue\n * - Posting session progress comments with session ID markers\n * - Discovering the linked issue number for a branch\n *\n * Session comments include a hidden HTML marker that allows the Stop hook\n * to detect whether progress has been documented for a given session.\n * @module github-comments\n */\n\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst COMMENT_MARKER_PREFIX = '<!-- claude-session: ';\nconst COMMENT_MARKER_SUFFIX = ' -->';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Plan issue state tracking\n */\ninterface PlanIssueState {\n  /**\n   * Map of session IDs to issue metadata\n   */\n  [sessionId: string]: {\n    /**\n     * Path to the plan file\n     */\n    planPath: string;\n    /**\n     * GitHub issue number\n     */\n    issueNumber: number;\n    /**\n     * Full GitHub issue URL\n     */\n    issueUrl: string;\n    /**\n     * Git branch name\n     */\n    branch: string;\n    /**\n     * ISO timestamp when issue was created\n     */\n    createdAt: string;\n    /**\n     * ISO timestamp of last update\n     */\n    lastUpdated: string;\n  };\n}\n\n/**\n * GitHub issue with comments\n */\ninterface GitHubIssue {\n  /**\n   * Issue number\n   */\n  number: number;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * Issue body content\n   */\n  body: string;\n  /**\n   * Issue comments\n   */\n  comments?: Array<{\n    /**\n     * Comment author\n     */\n    author: { login: string };\n    /**\n     * Comment body\n     */\n    body: string;\n    /**\n     * ISO timestamp when comment was created\n     */\n    createdAt: string;\n  }>;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command\n * @param command - Shell command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execCommand('git rev-parse --abbrev-ref HEAD', '/path/to/project');\n * if (result.success) {\n *   console.log('Branch:', result.stdout);\n * }\n * ```\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n *\n * Uses spawn + stdin to avoid shell escaping issues when passing\n * markdown content with special characters.\n * @param args - Arguments to pass to gh command\n * @param stdin - Content to write to stdin\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execGhWithStdin(\n *   ['issue', 'comment', '123', '--body-file', '-'],\n *   'This is my comment content',\n *   '/path/to/project'\n * );\n * ```\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    // Write body to stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n// ============================================================================\n// Issue Discovery\n// ============================================================================\n\n/**\n * Load plan issue state from disk\n * @param cwd - Working directory\n * @returns Plan issue state map\n * @example\n * ```typescript\n * const state = await loadPlanIssueState('/path/to/project');\n * const sessionInfo = state['session-id'];\n * if (sessionInfo) {\n *   console.log('Issue number:', sessionInfo.issueNumber);\n * }\n * ```\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Parse issue number from branch name\n *\n * Extracts issue number from branch names like:\n * - issue-123-description\n * - feature/issue-456\n * - 789-fix-bug\n * @param branch - Git branch name\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNum = parseIssueFromBranch('issue-123-add-feature');\n * // Returns: 123\n *\n * const noIssue = parseIssueFromBranch('main');\n * // Returns: null\n * ```\n */\nfunction parseIssueFromBranch(branch: string): number | null {\n  // Try pattern: issue-123-...\n  const issueMatch = branch.match(/issue[_-](\\d+)/i);\n  if (issueMatch) {\n    return parseInt(issueMatch[1], 10);\n  }\n\n  // Try pattern: 123-...\n  const numMatch = branch.match(/^(\\d+)[_-]/);\n  if (numMatch) {\n    return parseInt(numMatch[1], 10);\n  }\n\n  return null;\n}\n\n/**\n * Get linked issue number for current branch\n *\n * Discovers issue number using cascading fallback strategy:\n * 1. Check plan-issues.json state file (by session ID and branch name)\n * 2. Parse from branch name pattern (issue-123-...)\n * 3. Search GitHub for issues mentioning the branch\n * @param branch - Git branch name\n * @param cwd - Working directory\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNumber = await getLinkedIssueNumber('issue-57-stop-hook', '/path/to/project');\n * if (issueNumber) {\n *   console.log('Linked to issue #' + issueNumber);\n * }\n * ```\n */\nexport async function getLinkedIssueNumber(\n  branch: string,\n  cwd: string\n): Promise<number | null> {\n  // STRATEGY 1: Check plan-issues.json state file\n  const state = await loadPlanIssueState(cwd);\n\n  // Find by branch name across all sessions\n  for (const sessionState of Object.values(state)) {\n    if (sessionState.branch === branch) {\n      return sessionState.issueNumber;\n    }\n  }\n\n  // STRATEGY 2: Parse from branch name\n  const parsedIssue = parseIssueFromBranch(branch);\n  if (parsedIssue !== null) {\n    // Verify issue exists\n    const verifyResult = await execCommand(`gh issue view ${parsedIssue} --json number`, cwd);\n    if (verifyResult.success) {\n      return parsedIssue;\n    }\n  }\n\n  // STRATEGY 3: Search GitHub for issues mentioning the branch\n  const searchResult = await execCommand(\n    `gh issue list --search \"in:body ${branch}\" --json number --limit 1`,\n    cwd\n  );\n\n  if (searchResult.success && searchResult.stdout) {\n    try {\n      const issues = JSON.parse(searchResult.stdout);\n      if (issues.length > 0) {\n        return issues[0].number;\n      }\n    } catch {\n      // Parse error\n    }\n  }\n\n  return null;\n}\n\n// ============================================================================\n// Comment Management\n// ============================================================================\n\n/**\n * Create session comment marker\n * @param sessionId - Session ID to embed in marker\n * @returns HTML comment marker\n * @example\n * ```typescript\n * const marker = createSessionMarker('abc-123');\n * // Returns: '<!-- claude-session: abc-123 -->'\n * ```\n */\nfunction createSessionMarker(sessionId: string): string {\n  return `${COMMENT_MARKER_PREFIX}${sessionId}${COMMENT_MARKER_SUFFIX}`;\n}\n\n/**\n * Check if a comment contains a session marker\n * @param commentBody - Comment body text\n * @param sessionId - Session ID to search for\n * @returns True if comment contains the session marker\n * @example\n * ```typescript\n * const hasMarker = commentHasSessionMarker(\n *   '<!-- claude-session: abc-123 -->\\n\\nMy comment',\n *   'abc-123'\n * );\n * // Returns: true\n * ```\n */\nfunction commentHasSessionMarker(commentBody: string, sessionId: string): boolean {\n  const marker = createSessionMarker(sessionId);\n  return commentBody.includes(marker);\n}\n\n/**\n * Check if a session comment exists on a GitHub issue\n *\n * Fetches all comments for the issue and searches for the session ID marker.\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID to search for\n * @param cwd - Working directory\n * @returns True if a comment with the session marker exists\n * @example\n * ```typescript\n * import { hasCommentForSession } from './github-comments.js';\n *\n * const hasComment = await hasCommentForSession(57, 'session-abc-123', '/path/to/project');\n * if (hasComment) {\n *   console.log('Progress already documented for this session');\n * }\n * ```\n */\nexport async function hasCommentForSession(\n  issueNumber: number,\n  sessionId: string,\n  cwd: string\n): Promise<boolean> {\n  // Fetch issue with comments\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return false;\n  }\n\n  try {\n    const issue: GitHubIssue = JSON.parse(result.stdout);\n\n    if (!issue.comments || issue.comments.length === 0) {\n      return false;\n    }\n\n    // Search for session marker in comments\n    return issue.comments.some((comment) =>\n      commentHasSessionMarker(comment.body, sessionId)\n    );\n  } catch {\n    // Parse error\n    return false;\n  }\n}\n\n/**\n * Post a session progress comment to a GitHub issue\n *\n * Creates a formatted comment with:\n * - Hidden session ID marker for detection\n * - Session metadata (ID, branch, timestamp)\n * - User-provided content\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID\n * @param content - Comment content (markdown)\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n * @example\n * ```typescript\n * import { postSessionComment } from './github-comments.js';\n *\n * const posted = await postSessionComment(\n *   57,\n *   'session-abc-123',\n *   'Completed hook implementation and tests',\n *   'issue-57-stop-hook',\n *   '/path/to/project'\n * );\n * if (posted) {\n *   console.log('Comment posted successfully');\n * }\n * ```\n */\nexport async function postSessionComment(\n  issueNumber: number,\n  sessionId: string,\n  content: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = createSessionMarker(sessionId);\n\n  const commentBody = `${marker}\n\n## 🤖 Claude Session Progress\n\n**Session ID:** \\`${sessionId}\\`\n**Branch:** \\`${branch}\\`\n**Timestamp:** ${timestamp}\n\n${content}\n\n---\n*Posted automatically via Stop hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/index.ts": "/**\n * Hook Utilities - Re-exports\n *\n * Centralized exports for all hook utility functions, types, and helpers.\n * This index file provides convenient access to all shared utilities used\n * across Claude Code plugins.\n *\n * For smaller bundle sizes, prefer importing directly from individual modules\n * rather than using this index file. Direct imports allow tree-shaking to\n * eliminate unused code.\n *\n * @example\n * ```typescript\n * // Preferred: Direct import (better for tree-shaking)\n * import { readStdinJson } from './utils/io.js';\n * import { createDebugLogger } from './utils/debug.js';\n *\n * // Alternative: Import from index (more convenient)\n * import { readStdinJson, createDebugLogger } from './utils/index.js';\n * ```\n *\n * @module utils/index\n */\n\n// ============================================================================\n// I/O Utilities and Hook Runner\n// ============================================================================\n// Functions for reading hook input from stdin, writing output to stdout,\n// and wrapping hook handlers for execution.\n\nexport { readStdinJson, writeStdoutJson, runHook, type HookHandler } from './io.js';\n\n// ============================================================================\n// Debug Utilities\n// ============================================================================\n// Debug logging with JSONL output to .claude/logs/hook-events.json.\n// Supports DEBUG environment variable for filtering output.\n\nexport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  createPassthroughResponse,\n  type DebugConfig,\n  type DebugLogger,\n  type HookEventEntry,\n} from './debug.js';\n\n// ============================================================================\n// Transcript Parsing\n// ============================================================================\n// Parse Claude Code transcript JSONL files to analyze agent conversations,\n// tool uses, and file operations.\n\nexport {\n  parseTranscript,\n  parseTranscriptLine,\n  getTranscriptInfo,\n  getToolUses,\n  getEditedFiles,\n  getNewFiles,\n  getDeletedFiles,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  type Transcript,\n  type Message,\n  type UserMessage,\n  type AssistantMessage,\n  type SystemMessage,\n} from './transcripts.js';\n\n// ============================================================================\n// Subagent State Management\n// ============================================================================\n// Save and load subagent execution context, and analyze file operations\n// performed by agents.\n\nexport {\n  saveAgentStartContext,\n  loadAgentStartContext,\n  removeAgentStartContext,\n  getAgentEdits,\n  type AgentStartContext,\n  type AgentEditsResult,\n} from './subagent-state.js';\n\n// ============================================================================\n// Task State Management\n// ============================================================================\n// Save and load Task tool call context, and analyze file operations\n// performed within tasks.\n\nexport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n  getTaskEdits,\n  type TaskCallContext,\n  type TaskEditsResult,\n} from './task-state.js';\n\n// ============================================================================\n// Package Manager Detection\n// ============================================================================\n// Detect which package manager (npm, yarn, pnpm, bun) a project uses\n// and construct appropriate commands.\n\nexport { detectPackageManager, getScriptCommand } from './package-manager.js';\n\n// ============================================================================\n// Configuration File Resolution\n// ============================================================================\n// Find configuration files by traversing parent directories.\n// Supports monorepo and Turborepo patterns with closest-first resolution.\n\nexport { findConfigFile } from './config-resolver.js';\n\n// ============================================================================\n// TOML Parsing\n// ============================================================================\n// Simple TOML parser for reading configuration files like supabase/config.toml.\n\nexport { parseToml, readTomlFile, type TomlValue } from './toml.js';\n\n// ============================================================================\n// Agent Type Detection\n// ============================================================================\n// Utilities for determining if a tool event was triggered by the main agent\n// or a subagent, and extracting agent IDs from transcripts.\n\nexport {\n  wasToolEventMainAgent,\n  isMainAgentTranscript,\n  isSubagentType,\n  getTranscriptAgentId,\n} from './was-tool-event-main-agent.js';\n\n// ============================================================================\n// Log File Utilities\n// ============================================================================\n// Save hook output to log files and return concise summaries.\n// Used to reduce context injection while preserving full output for debugging.\n\nexport {\n  saveOutputToLog,\n  parseEslintCounts,\n  parseTscErrorCount,\n  parseVitestResults,\n  parseCiChecks,\n  formatCiChecksTable,\n  formatErrorSummary,\n  formatSuccessMessage,\n} from './log-file.js';\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/io.ts": "/**\n * I/O utilities for Claude Code hooks\n *\n * Provides stdin/stdout JSON handling and the runHook wrapper for\n * creating self-executable hooks. Claude Code passes hook input via\n * stdin as JSON and expects hook output as JSON on stdout.\n *\n * @module io\n */\n\nimport type { HookInput, HookOutput } from '../../types/types.js';\nimport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  type DebugConfig,\n} from './debug.js';\n\n/**\n * Read and parse JSON from stdin\n *\n * Reads all data from stdin, concatenates chunks, and parses as JSON.\n * Used by hook runners to receive hook input from Claude Code.\n *\n * @template T - Expected type of the parsed JSON (defaults to unknown)\n * @returns Promise that resolves to the parsed JSON data\n * @throws Error if stdin cannot be read or JSON parsing fails\n *\n * @example\n * ```typescript\n * import { readStdinJson } from './utils/io.js';\n * import type { SubagentStopInput } from '../../types/types.js';\n *\n * const input = await readStdinJson<SubagentStopInput>();\n * console.log(input.agent_id);\n * ```\n */\nexport async function readStdinJson<T = unknown>(): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const chunks: Buffer[] = [];\n\n    process.stdin.on('data', (chunk) => {\n      // Handle both Buffer and string inputs\n      if (Buffer.isBuffer(chunk)) {\n        chunks.push(chunk);\n      } else {\n        chunks.push(Buffer.from(chunk));\n      }\n    });\n    process.stdin.on('end', () => {\n      try {\n        const data = Buffer.concat(chunks).toString('utf8');\n        resolve(JSON.parse(data) as T);\n      } catch (error) {\n        reject(new Error(`Failed to parse JSON input: ${error}`));\n      }\n    });\n    process.stdin.on('error', (error) => {\n      reject(new Error(`Failed to read stdin: ${error}`));\n    });\n  });\n}\n\n/**\n * Write JSON output to stdout\n *\n * Serializes the output object to JSON and writes it to stdout with a trailing newline.\n * Used by hook runners to return hook output to Claude Code.\n *\n * @param output - The output object to serialize and write\n *\n * @example\n * ```typescript\n * import { writeStdoutJson } from './utils/io.js';\n * import type { SubagentStopHookOutput } from '../../types/types.js';\n *\n * const output: SubagentStopHookOutput = { continue: true };\n * writeStdoutJson(output);\n * ```\n */\nexport function writeStdoutJson(output: unknown): void {\n  process.stdout.write(JSON.stringify(output) + '\\n');\n}\n\n/**\n * Hook handler function type\n */\nexport type HookHandler<I extends HookInput = HookInput, O extends HookOutput = HookOutput> = (\n  input: I\n) => O | Promise<O>;\n\n/**\n * Run a hook as a self-executable script\n *\n * This function wraps a hook handler to make it self-executable when called\n * with `npx tsx`. It reads input from stdin, executes the hook, and writes\n * the output to stdout.\n *\n * @template I - Hook input type\n * @template O - Hook output type\n * @param handler - The hook handler function to execute\n *\n * @example\n * ```typescript\n * // my-hook.ts\n * import { runHook } from '../../../shared/hooks/utils/io.js';\n * import type { SessionStartInput, SessionStartHookOutput } from '../../../shared/types/types.js';\n *\n * async function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Hook executed successfully',\n *     },\n *   };\n * }\n *\n * // Make this file self-executable\n * runHook(handler);\n * ```\n */\nexport function runHook<I extends HookInput = HookInput, O extends HookOutput = HookOutput>(\n  handler: HookHandler<I, O>\n): void {\n  main(handler).catch((error) => {\n    console.error('Hook fatal error:', error);\n    process.exit(1);\n  });\n}\n\n/**\n * Main hook execution function\n *\n * Handles the complete hook lifecycle: reads input from stdin, executes the handler,\n * and writes output to stdout. All errors are caught and converted to blocking responses.\n *\n * @param handler - Hook handler function to execute\n * @returns Promise that resolves when hook completes\n *\n * @example\n * ```typescript\n * async function myHandler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Success',\n *     },\n *   };\n * }\n *\n * await main(myHandler);\n * ```\n */\nasync function main<I extends HookInput, O extends HookOutput>(\n  handler: HookHandler<I, O>\n): Promise<void> {\n  let input: I & DebugConfig;\n  let hookEventName = 'unknown';\n  let cwd = process.cwd();\n  let debug = false;\n\n  try {\n    // Read input from stdin\n    input = await readStdinJson<I & DebugConfig>();\n    hookEventName = (input as { hook_event_name?: string }).hook_event_name || 'unknown';\n    cwd = (input as { cwd?: string }).cwd || process.cwd();\n    debug = input.debug === true;\n  } catch (error) {\n    // Can't even read input - exit with error\n    console.error('Failed to read hook input:', error);\n    process.exit(1);\n  }\n\n  const logger = createDebugLogger(cwd, hookEventName, debug);\n\n  try {\n    // Log input if debug enabled\n    await logger.logInput(input);\n\n    // Execute hook handler\n    const output = await handler(input);\n\n    // Log output if debug enabled\n    await logger.logOutput(output);\n\n    // Write output to stdout\n    writeStdoutJson(output);\n\n  } catch (error) {\n    const err = error instanceof Error ? error : new Error(String(error));\n\n    // Log error\n    await logger.logError(err);\n\n    // ALWAYS return blocking error response\n    // Debug flag controls logging only, not blocking behavior\n    const errorResponse = createBlockingErrorResponse(hookEventName, err);\n    writeStdoutJson(errorResponse);\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/log-file.ts": "/**\n * Log File Utilities\n *\n * Functions for saving hook output to log files in `.claude/logs/`.\n * Used to preserve full output while returning concise summaries to Claude.\n *\n * @module utils/log-file\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n/**\n * Saves output content to a log file and returns the relative path.\n *\n * Creates timestamped log files in `.claude/logs/` directory.\n * The directory is created if it doesn't exist.\n *\n * @param cwd - Current working directory (project root)\n * @param category - Log category (e.g., 'eslint', 'tsc', 'ci')\n * @param identifier - Unique identifier (e.g., filename, check name)\n * @param content - Content to save to the log file\n * @returns Relative path to the created log file\n *\n * @example\n * ```typescript\n * const logPath = await saveOutputToLog(\n *   '/project',\n *   'eslint',\n *   'Button.tsx',\n *   eslintOutput\n * );\n * // Returns: '.claude/logs/eslint-Button.tsx-2025-01-02T10-30-00-000Z.log'\n * ```\n */\nexport async function saveOutputToLog(\n  cwd: string,\n  category: string,\n  identifier: string,\n  content: string\n): Promise<string> {\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  // Sanitize identifier to be filesystem-safe\n  const safeIdentifier = identifier.replace(/[/\\\\:*?\"<>|]/g, '-');\n  const filename = `${category}-${safeIdentifier}-${timestamp}.log`;\n  const logDir = path.join(cwd, '.claude', 'logs');\n  const logPath = path.join(logDir, filename);\n\n  await fs.mkdir(logDir, { recursive: true });\n  await fs.writeFile(logPath, content, 'utf-8');\n\n  // Return relative path for display\n  return `.claude/logs/${filename}`;\n}\n\n/**\n * Parses error/warning counts from ESLint output.\n *\n * @param output - ESLint stdout/stderr output\n * @returns Object with error and warning counts\n *\n * @example\n * ```typescript\n * const counts = parseEslintCounts(eslintOutput);\n * // Returns: { errors: 3, warnings: 2 }\n * ```\n */\nexport function parseEslintCounts(output: string): { errors: number; warnings: number } {\n  // ESLint summary line format: \"✖ 5 problems (3 errors, 2 warnings)\"\n  const summaryMatch = output.match(/(\\d+)\\s+problems?\\s+\\((\\d+)\\s+errors?,\\s+(\\d+)\\s+warnings?\\)/i);\n  if (summaryMatch) {\n    return {\n      errors: parseInt(summaryMatch[2], 10),\n      warnings: parseInt(summaryMatch[3], 10),\n    };\n  }\n\n  // Alternative: count individual error/warning lines\n  const errorLines = (output.match(/error\\s/gi) || []).length;\n  const warningLines = (output.match(/warning\\s/gi) || []).length;\n\n  return { errors: errorLines, warnings: warningLines };\n}\n\n/**\n * Parses error count from TypeScript compiler output.\n *\n * @param output - TypeScript compiler stdout/stderr output\n * @returns Number of type errors found\n *\n * @example\n * ```typescript\n * const errorCount = parseTscErrorCount(tscOutput);\n * // Returns: 5\n * ```\n */\nexport function parseTscErrorCount(output: string): number {\n  // TypeScript summary: \"Found 5 errors in 3 files.\"\n  const summaryMatch = output.match(/Found\\s+(\\d+)\\s+errors?/i);\n  if (summaryMatch) {\n    return parseInt(summaryMatch[1], 10);\n  }\n\n  // Alternative: count \"error TS\" occurrences\n  const errorMatches = output.match(/error\\s+TS\\d+/gi) || [];\n  return errorMatches.length;\n}\n\n/**\n * Parses test results from Vitest output.\n *\n * @param output - Vitest stdout/stderr output\n * @returns Object with passed, failed, and skipped counts\n *\n * @example\n * ```typescript\n * const results = parseVitestResults(vitestOutput);\n * // Returns: { passed: 10, failed: 2, skipped: 1 }\n * ```\n */\nexport function parseVitestResults(output: string): {\n  passed: number;\n  failed: number;\n  skipped: number;\n} {\n  // Vitest summary: \"Tests  2 failed | 10 passed | 1 skipped (13)\"\n  const passed = parseInt(output.match(/(\\d+)\\s+passed/i)?.[1] || '0', 10);\n  const failed = parseInt(output.match(/(\\d+)\\s+failed/i)?.[1] || '0', 10);\n  const skipped = parseInt(output.match(/(\\d+)\\s+skipped/i)?.[1] || '0', 10);\n\n  return { passed, failed, skipped };\n}\n\n/**\n * Parses CI check status from `gh pr checks` output.\n *\n * @param output - Output from `gh pr checks` command\n * @returns Array of check statuses with name, status, and duration\n *\n * @example\n * ```typescript\n * const checks = parseCiChecks(ghOutput);\n * // Returns: [\n * //   { name: 'lint', status: 'pass', duration: '2m30s' },\n * //   { name: 'test', status: 'fail', duration: '5m10s' }\n * // ]\n * ```\n */\nexport function parseCiChecks(\n  output: string\n): Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }> {\n  const checks: Array<{\n    name: string;\n    status: 'pass' | 'fail' | 'pending' | 'skipped';\n    duration: string;\n  }> = [];\n\n  // gh pr checks output format:\n  // lint    pass    2m30s   https://github.com/...\n  // test    fail    5m10s   https://github.com/...\n  const lines = output.split('\\n').filter((line) => line.trim());\n\n  for (const line of lines) {\n    // Split by whitespace, handling variable spacing\n    const parts = line.split(/\\s+/).filter(Boolean);\n    if (parts.length >= 2) {\n      const name = parts[0];\n      const statusRaw = parts[1].toLowerCase();\n\n      let status: 'pass' | 'fail' | 'pending' | 'skipped';\n      if (statusRaw === 'pass' || statusRaw === 'success' || statusRaw === '✓') {\n        status = 'pass';\n      } else if (statusRaw === 'fail' || statusRaw === 'failure' || statusRaw === '✗') {\n        status = 'fail';\n      } else if (statusRaw === 'skipped' || statusRaw === 'neutral') {\n        status = 'skipped';\n      } else {\n        status = 'pending';\n      }\n\n      const duration = parts[2] || '';\n\n      checks.push({ name, status, duration });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Formats CI checks as a concise emoji status table.\n *\n * @param checks - Array of parsed CI checks\n * @param logPath - Optional path to full log file (shown for failures)\n * @returns Formatted string with emoji status indicators\n *\n * @example\n * ```typescript\n * const table = formatCiChecksTable(checks, '.claude/logs/ci.log');\n * // Returns:\n * // ✅ lint (2m30s)\n * // ❌ test (5m10s) → .claude/logs/ci.log\n * // ⏳ deploy\n * ```\n */\nexport function formatCiChecksTable(\n  checks: Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }>,\n  logPath?: string\n): string {\n  const statusEmoji = {\n    pass: '✅',\n    fail: '❌',\n    pending: '⏳',\n    skipped: '⏭️',\n  };\n\n  const lines = checks.map((check) => {\n    const emoji = statusEmoji[check.status];\n    const duration = check.duration ? ` (${check.duration})` : '';\n    const logLink = check.status === 'fail' && logPath ? ` → ${logPath}` : '';\n    return `${emoji} ${check.name}${duration}${logLink}`;\n  });\n\n  return lines.join('\\n');\n}\n\n/**\n * Formats a concise error summary with log file link.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @param summary - Brief summary of issues (e.g., '3 errors, 2 warnings')\n * @param logPath - Path to the full log file\n * @returns Formatted summary string\n *\n * @example\n * ```typescript\n * const summary = formatErrorSummary('ESLint', '3 errors, 2 warnings', logPath);\n * // Returns: '❌ ESLint: 3 errors, 2 warnings\\n→ .claude/logs/eslint-file.log'\n * ```\n */\nexport function formatErrorSummary(tool: string, summary: string, logPath: string): string {\n  return `❌ ${tool}: ${summary}\\n→ ${logPath}`;\n}\n\n/**\n * Formats a success message.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @returns Formatted success string\n *\n * @example\n * ```typescript\n * const msg = formatSuccessMessage('ESLint');\n * // Returns: '✅ ESLint: No issues'\n * ```\n */\nexport function formatSuccessMessage(tool: string): string {\n  return `✅ ${tool}: No issues`;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/package-manager.ts": "/**\n * Package manager detection and command utilities\n *\n * Detects which package manager (npm, yarn, pnpm, or bun) a project uses\n * by checking for the presence of lockfiles, and provides utilities for\n * constructing package manager commands.\n *\n * @module package-manager\n */\n\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Detect which package manager is used in a project\n *\n * Checks for the presence of lockfiles in the following priority order:\n * 1. bun.lockb (Bun)\n * 2. pnpm-lock.yaml (pnpm)\n * 3. yarn.lock (Yarn)\n * 4. package-lock.json (npm)\n * 5. Falls back to bun if no lockfile is found (modern default)\n *\n * @param cwd - The directory to check for lockfiles\n * @returns The detected package manager: 'bun', 'pnpm', 'yarn', or 'npm'\n *\n * @example\n * ```typescript\n * import { detectPackageManager } from './package-manager.js';\n *\n * const pm = detectPackageManager('/path/to/project');\n * console.log(pm); // 'npm' | 'yarn' | 'pnpm' | 'bun'\n * ```\n */\nexport function detectPackageManager(cwd: string): 'npm' | 'yarn' | 'pnpm' | 'bun' {\n  if (existsSync(join(cwd, 'bun.lockb'))) return 'bun';\n  if (existsSync(join(cwd, 'pnpm-lock.yaml'))) return 'pnpm';\n  if (existsSync(join(cwd, 'yarn.lock'))) return 'yarn';\n  if (existsSync(join(cwd, 'package-lock.json'))) return 'npm';\n  return 'bun'; // Modern default when no lockfile found\n}\n\n/**\n * Get the command to run a package.json script\n *\n * Constructs the appropriate command for running a package.json script\n * based on the detected package manager. All package managers use the\n * format: `{pm} run {script}`.\n *\n * @param cwd - The project directory to detect the package manager from\n * @param script - The script name from package.json to run (e.g., 'test', 'build')\n * @returns The full command string to execute the script\n *\n * @example\n * ```typescript\n * import { getScriptCommand } from './package-manager.js';\n *\n * const command = getScriptCommand('/path/to/project', 'test');\n * // Returns: 'npm run test' or 'yarn run test' or 'pnpm run test' or 'bun run test'\n * ```\n */\nexport function getScriptCommand(cwd: string, script: string): string {\n  const pm = detectPackageManager(cwd);\n  return `${pm} run ${script}`;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/port.ts": "/**\n * Port availability utilities for checking and finding available TCP ports\n *\n * Provides functions to check if a port is available and find the next available\n * port in a range. Useful for avoiding port conflicts when starting development servers.\n *\n * @module port\n */\n\nimport { createServer } from 'net';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/**\n * Check if a TCP port is available\n *\n * Attempts to bind a server to the given port. If successful, the port is available.\n * If binding fails with EADDRINUSE, the port is already in use.\n *\n * @param port - Port number to check\n * @returns Promise that resolves to true if port is available, false if in use\n *\n * @example\n * ```typescript\n * import { isPortAvailable } from './port.js';\n *\n * const available = await isPortAvailable(8787);\n * if (!available) {\n *   console.log('Port 8787 is already in use');\n * }\n * ```\n */\nexport async function isPortAvailable(port: number): Promise<boolean> {\n  return new Promise((resolve) => {\n    const server = createServer();\n\n    server.once('error', (err: NodeJS.ErrnoException) => {\n      if (err.code === 'EADDRINUSE') {\n        resolve(false);\n      } else {\n        // Other errors (EACCES, etc.) also mean port is not available\n        resolve(false);\n      }\n    });\n\n    server.once('listening', () => {\n      server.close(() => {\n        resolve(true);\n      });\n    });\n\n    server.listen(port);\n  });\n}\n\n/**\n * Find the next available port starting from a given port\n *\n * Sequentially checks ports starting from `startPort` until an available port\n * is found or `maxAttempts` is reached.\n *\n * @param startPort - Port number to start checking from\n * @param maxAttempts - Maximum number of ports to check (default: 10)\n * @returns Promise that resolves to an available port number, or null if none found\n *\n * @example\n * ```typescript\n * import { findAvailablePort } from './port.js';\n *\n * // Try to find an available port starting from 8787\n * const port = await findAvailablePort(8787, 10);\n * if (port) {\n *   console.log(`Found available port: ${port}`);\n * } else {\n *   console.log('No available ports found in range 8787-8796');\n * }\n * ```\n */\nexport async function findAvailablePort(\n  startPort: number,\n  maxAttempts: number = 10\n): Promise<number | null> {\n  for (let i = 0; i < maxAttempts; i++) {\n    const port = startPort + i;\n    const available = await isPortAvailable(port);\n    if (available) {\n      return port;\n    }\n  }\n  return null;\n}\n\n/**\n * Kill process(es) using a specific port\n *\n * Uses lsof to find the process ID and kills it, with fallback to ss if lsof fails.\n * This is useful for freeing up ports that are held by stale dev servers from previous sessions.\n *\n * @param port - Port number to free up\n * @returns Promise that resolves to true if process was killed, false otherwise\n *\n * @example\n * ```typescript\n * import { killProcessOnPort } from './port.js';\n *\n * const killed = await killProcessOnPort(3000);\n * if (killed) {\n *   console.log('Freed up port 3000');\n * }\n * ```\n */\nexport async function killProcessOnPort(port: number): Promise<boolean> {\n  try {\n    let pids: string[] = [];\n\n    // Try lsof first (preferred, more portable)\n    try {\n      const { stdout } = await execAsync(`lsof -ti tcp:${port}`, { timeout: 5000 });\n      pids = stdout.trim().split('\\n').filter(Boolean);\n    } catch {\n      // lsof failed or not available, will try ss fallback\n    }\n\n    // Fallback to ss if lsof found nothing\n    if (pids.length === 0) {\n      try {\n        const { stdout } = await execAsync(\n          `ss -tlnp | grep ':${port}\\\\b' | sed -n 's/.*pid=\\\\([0-9]*\\\\).*/\\\\1/p'`,\n          { timeout: 5000 }\n        );\n        pids = stdout.trim().split('\\n').filter(Boolean);\n      } catch {\n        // ss also failed or not available\n      }\n    }\n\n    if (pids.length === 0) {\n      return false;\n    }\n\n    // Kill all processes found\n    for (const pid of pids) {\n      try {\n        await execAsync(`kill -9 ${pid}`, { timeout: 5000 });\n      } catch {\n        // Process might have already exited\n      }\n    }\n\n    // Verify port is now available (give it a moment)\n    await new Promise((resolve) => setTimeout(resolve, 500));\n    return await isPortAvailable(port);\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Kill processes on multiple ports\n *\n * Kills processes on all specified ports in parallel.\n *\n * @param ports - Array of port numbers to free up\n * @returns Promise that resolves to array of results with port and success status\n *\n * @example\n * ```typescript\n * import { killProcessesOnPorts } from './port.js';\n *\n * const results = await killProcessesOnPorts([3000, 3001, 3002]);\n * for (const { port, killed } of results) {\n *   console.log(`Port ${port}: ${killed ? 'freed' : 'failed or not in use'}`);\n * }\n * ```\n */\nexport async function killProcessesOnPorts(\n  ports: number[]\n): Promise<Array<{ port: number; killed: boolean }>> {\n  const results = await Promise.all(\n    ports.map(async (port) => ({\n      port,\n      killed: await killProcessOnPort(port),\n    }))\n  );\n  return results;\n}\n\n/**\n * Find next available port scanning at +10 increments\n *\n * Checks ports at 10-port intervals starting from basePort until an available\n * port is found. This allows multiple dev servers to run on predictable ports\n * (e.g., 3000, 3010, 3020...) without conflicts.\n *\n * @param basePort - Starting port (e.g., 3000)\n * @param maxSlots - Maximum slots to check (default: 25)\n * @returns Available port, or null if none found in range\n *\n * @example\n * ```typescript\n * import { findAvailablePortAt10Increments } from './port.js';\n *\n * // Find next available port starting from 3000, checking 3000, 3010, 3020...\n * const port = await findAvailablePortAt10Increments(3000);\n * if (port) {\n *   console.log(`Starting server on port ${port}`);\n * }\n * ```\n */\nexport async function findAvailablePortAt10Increments(\n  basePort: number,\n  maxSlots: number = 25\n): Promise<number | null> {\n  for (let slot = 0; slot < maxSlots; slot++) {\n    const port = basePort + slot * 10;\n    const available = await isPortAvailable(port);\n    if (available) {\n      return port;\n    }\n  }\n  return null;\n}\n\n// ============================================================================\n// App Port Configuration Types and Functions\n// ============================================================================\n\n/**\n * Project type for port defaults\n */\nexport type ProjectType = 'nextjs' | 'cloudflare' | 'vite' | 'elysia' | 'turborepo' | 'unknown';\n\n/**\n * Port configuration for a single app/workspace\n */\nexport interface AppPortConfig {\n  /** Path to the app/workspace */\n  workspace: string;\n  /** Detected project type */\n  projectType: ProjectType;\n  /** Port from config file (--port flag, wrangler.toml, vite.config.ts) */\n  configuredPort: number | null;\n  /** Default port for this project type */\n  defaultPort: number;\n  /** Final resolved port to use (after availability check) */\n  resolvedPort: number;\n}\n\n/**\n * Default ports for each project type\n */\nexport const DEFAULT_PORTS: Record<ProjectType, number> = {\n  nextjs: 3000,\n  cloudflare: 8787,\n  vite: 5173,\n  elysia: 3000,\n  turborepo: 3000,\n  unknown: 3000,\n};\n\n/**\n * Get the default port for a project type\n *\n * @param projectType - Type of project\n * @returns Default port number\n */\nexport function getDefaultPort(projectType: ProjectType): number {\n  return DEFAULT_PORTS[projectType] ?? 3000;\n}\n\n/**\n * Resolve ports for multiple apps, checking availability sequentially\n *\n * For each app:\n * 1. Try configuredPort (from config file) if set\n * 2. Fall back to defaultPort for project type\n * 3. If that port is unavailable, find next port at +10 increments\n *\n * Apps are processed sequentially to avoid allocating the same port twice.\n * Claimed ports are tracked internally to prevent conflicts.\n *\n * @param apps - Array of app port configurations (mutated with resolvedPort)\n * @returns Promise resolving to the same array with resolvedPort filled in\n *\n * @example\n * ```typescript\n * const apps: AppPortConfig[] = [\n *   { workspace: 'apps/web', projectType: 'nextjs', configuredPort: null, defaultPort: 3000, resolvedPort: 0 },\n *   { workspace: 'apps/api', projectType: 'cloudflare', configuredPort: 8787, defaultPort: 8787, resolvedPort: 0 },\n * ];\n *\n * await resolveAppPorts(apps);\n * // apps[0].resolvedPort = 3000 (or 3010 if 3000 was in use)\n * // apps[1].resolvedPort = 8787 (or 8797 if 8787 was in use)\n * ```\n */\nexport async function resolveAppPorts(apps: AppPortConfig[]): Promise<AppPortConfig[]> {\n  // Track ports we've already claimed in this resolution\n  const claimedPorts = new Set<number>();\n\n  for (const app of apps) {\n    // Determine the preferred port (configured or default)\n    const preferredPort = app.configuredPort ?? app.defaultPort;\n\n    // Check if preferred port is available and not already claimed\n    const preferredAvailable = await isPortAvailable(preferredPort);\n    if (preferredAvailable && !claimedPorts.has(preferredPort)) {\n      app.resolvedPort = preferredPort;\n      claimedPorts.add(preferredPort);\n      continue;\n    }\n\n    // Port not available, find next at +10 increments\n    const resolvedPort = await findAvailablePortAt10IncrementsExcluding(\n      preferredPort,\n      claimedPorts,\n      25\n    );\n\n    if (resolvedPort !== null) {\n      app.resolvedPort = resolvedPort;\n      claimedPorts.add(resolvedPort);\n    } else {\n      // Fallback: use preferred port anyway (will likely fail at runtime)\n      app.resolvedPort = preferredPort;\n    }\n  }\n\n  return apps;\n}\n\n/**\n * Find available port at +10 increments, excluding already claimed ports\n *\n * @param basePort - Starting port\n * @param excludePorts - Set of ports to skip\n * @param maxSlots - Maximum slots to check\n * @returns Available port, or null if none found\n */\nasync function findAvailablePortAt10IncrementsExcluding(\n  basePort: number,\n  excludePorts: Set<number>,\n  maxSlots: number = 25\n): Promise<number | null> {\n  for (let slot = 0; slot < maxSlots; slot++) {\n    const port = basePort + slot * 10;\n    if (excludePorts.has(port)) {\n      continue;\n    }\n    const available = await isPortAvailable(port);\n    if (available) {\n      return port;\n    }\n  }\n  return null;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/process-info.ts": "/**\n * Process Information Utility\n * Identifies processes using specific ports for debugging and diagnostics.\n * Provides graceful fallbacks when system tools are unavailable.\n * @module process-info\n */\n\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/**\n * Information about a process using a port\n */\nexport interface ProcessInfo {\n  /** Process ID (null if cannot be determined) */\n  pid: number | null;\n  /** Process name (null if cannot be determined) */\n  name: string | null;\n  /** Full command line (null if cannot be determined) */\n  command: string | null;\n}\n\n/**\n * Extended process info with port context\n */\nexport interface PortProcessInfo extends ProcessInfo {\n  /** Port number being used */\n  port: number;\n  /** Whether a process was found on the port */\n  found: boolean;\n}\n\n/**\n * Get information about the process using a specific port\n * Uses lsof and ps commands (best effort, graceful fallback)\n *\n * @param port - Port number to check\n * @returns Process information (fields may be null if unavailable)\n *\n * @example\n * ```typescript\n * const info = await getProcessOnPort(3000);\n * if (info.pid) {\n *   console.log(`Port 3000 used by ${info.name} (PID: ${info.pid})`);\n * }\n * ```\n */\nexport async function getProcessOnPort(port: number): Promise<ProcessInfo> {\n  const result: ProcessInfo = {\n    pid: null,\n    name: null,\n    command: null,\n  };\n\n  try {\n    // Try lsof first (works on macOS and Linux)\n    const lsofResult = await execAsync(`lsof -ti tcp:${port}`, { timeout: 5000 });\n    const pids = lsofResult.stdout.trim().split('\\n').filter(Boolean);\n\n    if (pids.length === 0) {\n      return result;\n    }\n\n    // Take the first PID found\n    const pid = parseInt(pids[0], 10);\n    if (isNaN(pid)) {\n      return result;\n    }\n\n    result.pid = pid;\n\n    // Try to get process name and command\n    try {\n      const psResult = await execAsync(`ps -p ${pid} -o comm=,args=`, { timeout: 5000 });\n      const psOutput = psResult.stdout.trim();\n\n      if (psOutput) {\n        // ps output format: \"comm args\" - comm is first word, rest is args\n        const parts = psOutput.split(/\\s+/);\n        result.name = parts[0] || null;\n        result.command = psOutput;\n      }\n    } catch {\n      // ps failed, try alternative approach\n      try {\n        // Try just getting the command name\n        const commResult = await execAsync(`ps -p ${pid} -o comm=`, { timeout: 5000 });\n        result.name = commResult.stdout.trim() || null;\n      } catch {\n        // Ignore - we at least have the PID\n      }\n    }\n  } catch {\n    // lsof failed - port might not be in use or lsof not available\n  }\n\n  return result;\n}\n\n/**\n * Get process information for multiple ports\n * Runs checks in parallel for efficiency\n *\n * @param ports - Array of port numbers to check\n * @returns Array of port process info objects\n *\n * @example\n * ```typescript\n * const infos = await getProcessesOnPorts([3000, 54321, 54323]);\n * for (const info of infos) {\n *   if (info.found) {\n *     console.log(`Port ${info.port}: ${info.name} (PID: ${info.pid})`);\n *   }\n * }\n * ```\n */\nexport async function getProcessesOnPorts(ports: number[]): Promise<PortProcessInfo[]> {\n  const results = await Promise.all(\n    ports.map(async (port): Promise<PortProcessInfo> => {\n      const info = await getProcessOnPort(port);\n      return {\n        ...info,\n        port,\n        found: info.pid !== null,\n      };\n    })\n  );\n  return results;\n}\n\n/**\n * Check if lsof command is available on the system\n * Useful for deciding whether to attempt process identification\n *\n * @returns true if lsof is available\n */\nexport async function isLsofAvailable(): Promise<boolean> {\n  try {\n    await execAsync('which lsof', { timeout: 5000 });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Format process info for display\n * Creates a human-readable string describing the process\n *\n * @param info - Process information object\n * @returns Formatted string (e.g., \"node (PID: 12345)\")\n */\nexport function formatProcessInfo(info: ProcessInfo): string {\n  if (info.pid === null) {\n    return 'unknown process';\n  }\n\n  if (info.name) {\n    return `${info.name} (PID: ${info.pid})`;\n  }\n\n  return `PID: ${info.pid}`;\n}\n\n/**\n * Check if a process appears to be a Supabase-related process\n * Based on common Supabase container/process names\n *\n * @param info - Process information to check\n * @returns true if process appears Supabase-related\n */\nexport function isSupabaseProcess(info: ProcessInfo): boolean {\n  if (!info.name && !info.command) {\n    return false;\n  }\n\n  const searchText = `${info.name || ''} ${info.command || ''}`.toLowerCase();\n\n  const supabaseIndicators = [\n    'supabase',\n    'postgres',\n    'postgrest',\n    'gotrue',\n    'realtime',\n    'storage',\n    'kong',\n    'inbucket',\n    'studio',\n    'pg_',\n    'docker',\n    'containerd',\n  ];\n\n  return supabaseIndicators.some((indicator) => searchText.includes(indicator));\n}\n\n/**\n * Get a summary of processes using Supabase ports\n * Useful for diagnostics and debugging\n *\n * @param ports - Port set to check (as array or individual ports)\n * @returns Summary object with counts and details\n */\nexport async function getSupabaseProcessSummary(ports: number[]): Promise<{\n  totalPorts: number;\n  portsInUse: number;\n  supabaseProcesses: number;\n  otherProcesses: number;\n  details: PortProcessInfo[];\n}> {\n  const details = await getProcessesOnPorts(ports);\n\n  const portsInUse = details.filter((d) => d.found).length;\n  const supabaseProcesses = details.filter((d) => d.found && isSupabaseProcess(d)).length;\n  const otherProcesses = portsInUse - supabaseProcesses;\n\n  return {\n    totalPorts: ports.length,\n    portsInUse,\n    supabaseProcesses,\n    otherProcesses,\n    details,\n  };\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/session-state.ts": "/**\n * Session state management for Stop hook tracking and Worktree Supabase instances\n *\n * Manages session-level state for:\n *\n * **Stop Hook Tracking:**\n * - How many times the hook has blocked the session\n * - Whether a GitHub comment has been posted for the session\n * - When the last block occurred\n *\n * **Worktree Supabase Instances:**\n * - Port allocations for concurrent worktree sessions\n * - Config.toml backup tracking\n * - Instance startup state\n *\n * This enables progressive blocking behavior where the Stop hook can:\n * 1. Block on first commit without PR (with instructions)\n * 2. Block again if no PR or comment posted\n * 3. Show warning after 3 blocks\n * 4. Reset when PR created or comment posted\n * @module session-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SESSION_STOPS_FILE = 'session-stops.json';\nconst WORKTREE_SUPABASE_SESSION_PREFIX = 'supabase-session-';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Session Stop state tracking for progressive blocking\n *\n * Tracks how many times a session has been blocked at Stop hook,\n * whether progress has been documented, and related metadata.\n */\nexport interface SessionStopState {\n  /**\n   * The unique session identifier\n   */\n  sessionId: string;\n  /**\n   * Number of times Stop hook has blocked (0-3)\n   */\n  blockCount: number;\n  /**\n   * Whether a GitHub comment has been posted\n   */\n  commentPosted: boolean;\n  /**\n   * ISO timestamp of last block\n   */\n  lastBlockTimestamp: string;\n  /**\n   * GitHub issue number linked to this session\n   */\n  issueNumber?: number;\n  /**\n   * Whether a PR has been created\n   */\n  prCreated?: boolean;\n}\n\n/**\n * Map of session IDs to their Stop hook state\n */\ninterface SessionStopsMap {\n  [sessionId: string]: SessionStopState;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to session-stops.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the session stops state file\n * @example\n * ```typescript\n * const path = getSessionStopsFilePath('/path/to/project');\n * // Returns: '/path/to/project/.claude/logs/session-stops.json'\n * ```\n */\nfunction getSessionStopsFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SESSION_STOPS_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Get session stop state for a given session\n *\n * Loads the session's Stop hook state from disk. If no state exists,\n * returns a default state with blockCount: 0.\n * @param sessionId - The session ID to load state for\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The session state, or default state if not found\n * @example\n * ```typescript\n * import { getSessionStopState } from './session-state.js';\n *\n * // In Stop hook\n * const state = await getSessionStopState(input.session_id, input.cwd);\n * console.log('Block count:', state.blockCount);\n * console.log('Comment posted:', state.commentPosted);\n * ```\n */\nexport async function getSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n\n    if (allStates[sessionId]) {\n      return allStates[sessionId];\n    }\n  } catch {\n    // File doesn't exist or parse error - return default\n  }\n\n  // Return default state\n  return {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Update session stop state with partial updates\n *\n * Merges the provided updates into the existing state and saves to disk.\n * Automatically creates the logs directory if it doesn't exist.\n * @param sessionId - The session ID to update\n * @param updates - Partial state updates to apply\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The updated session state\n * @example\n * ```typescript\n * import { updateSessionStopState } from './session-state.js';\n *\n * // Increment block count\n * await updateSessionStopState(input.session_id, {\n *   blockCount: state.blockCount + 1,\n *   lastBlockTimestamp: new Date().toISOString()\n * }, input.cwd);\n *\n * // Mark comment posted\n * await updateSessionStopState(input.session_id, {\n *   commentPosted: true\n * }, input.cwd);\n * ```\n */\nexport async function updateSessionStopState(\n  sessionId: string,\n  updates: Partial<Omit<SessionStopState, 'sessionId'>>,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  // Load existing states\n  let allStates: SessionStopsMap = {};\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    allStates = JSON.parse(content);\n  } catch {\n    // File doesn't exist yet - start fresh\n  }\n\n  // Get current state or create default\n  const currentState = allStates[sessionId] || {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n\n  // Merge updates\n  const updatedState: SessionStopState = {\n    ...currentState,\n    ...updates,\n    sessionId, // Ensure sessionId is never overwritten\n  };\n\n  allStates[sessionId] = updatedState;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n\n  return updatedState;\n}\n\n/**\n * Reset session stop state to defaults\n *\n * Clears the block count and resets all flags. This is called when:\n * - A PR is created for the session's branch\n * - A GitHub comment is posted documenting progress\n * @param sessionId - The session ID to reset\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is reset\n * @example\n * ```typescript\n * import { resetSessionStopState } from './session-state.js';\n *\n * // After PR created\n * if (prExists) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n *\n * // After comment posted\n * if (commentPosted) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n * ```\n */\nexport async function resetSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  await updateSessionStopState(\n    sessionId,\n    {\n      blockCount: 0,\n      commentPosted: false,\n      lastBlockTimestamp: new Date().toISOString(),\n    },\n    cwd,\n    statePath\n  );\n}\n\n/**\n * Remove session stop state entirely\n *\n * Deletes the session's state from the file. Use this when a session\n * is completely finished and you want to clean up.\n * @param sessionId - The session ID to remove\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is removed (fails silently)\n * @example\n * ```typescript\n * import { removeSessionStopState } from './session-state.js';\n *\n * // Cleanup after session completes successfully\n * await removeSessionStopState(input.session_id, input.cwd);\n * ```\n */\nexport async function removeSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n    delete allStates[sessionId];\n    await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Worktree Supabase Session Types\n// ============================================================================\n\n/**\n * Port set for a Supabase instance\n */\nexport interface SupabasePortSet {\n  api: number;\n  db: number;\n  shadowDb: number;\n  studio: number;\n  inbucket: number;\n  analytics: number;\n  pooler: number;\n  edgeRuntime: number;\n}\n\n/**\n * Port set for dev servers (Next.js, Vite, etc.)\n */\nexport interface DevServerPortSet {\n  nextjs: number;\n  vite: number;\n  cloudflare: number;\n}\n\n/**\n * Worktree Supabase session state\n * Tracks isolated Supabase instances for concurrent worktree sessions\n */\nexport interface WorktreeSupabaseSession {\n  /** Unique worktree identifier (8-char hash) */\n  worktreeId: string;\n  /** Full path to worktree root */\n  worktreePath: string;\n  /** Port slot number (0 = default, 1+ = worktree) */\n  slot: number;\n  /** Supabase service ports for this instance */\n  supabasePorts: SupabasePortSet;\n  /** Dev server ports for this worktree */\n  devServerPorts: DevServerPortSet;\n  /** ISO timestamp when instance was started */\n  startedAt: string;\n  /** Path to config.toml backup file (deprecated - use tmpConfigDir) */\n  configBackupPath: string;\n  /** Whether instance is currently running */\n  running: boolean;\n  /** Original project_id from config.toml (before modification) */\n  originalProjectId: string;\n  /** Worktree-specific project_id (original or original-{slot}) */\n  worktreeProjectId: string;\n  /** Claude session ID that owns this instance (for orphan detection) */\n  sessionId?: string;\n  /** Path to temporary Supabase config directory (e.g., /tmp/supabase-abc12345) */\n  tmpConfigDir?: string;\n  /** Path to original supabase/ directory in project */\n  originalSupabaseDir?: string;\n}\n\n// ============================================================================\n// Worktree Session File Path Management\n// ============================================================================\n\n/**\n * Get the path to a worktree's Supabase session file\n * @param cwd - The working directory\n * @param worktreeId - Unique worktree identifier\n * @returns Full path to the session file\n */\nfunction getWorktreeSessionFilePath(cwd: string, worktreeId: string): string {\n  return path.join(cwd, LOGS_DIR, `${WORKTREE_SUPABASE_SESSION_PREFIX}${worktreeId}.json`);\n}\n\n// ============================================================================\n// Worktree Supabase Session Management\n// ============================================================================\n\n/**\n * Load worktree Supabase session from disk\n *\n * @param cwd - The working directory where logs are stored\n * @param worktreeId - Unique worktree identifier\n * @returns Session state, or null if not found\n *\n * @example\n * ```typescript\n * const session = await loadWorktreeSupabaseSession(cwd, worktreeId);\n * if (session && session.running) {\n *   console.log(`Using existing Supabase on port ${session.supabasePorts.api}`);\n * }\n * ```\n */\nexport async function loadWorktreeSupabaseSession(\n  cwd: string,\n  worktreeId: string\n): Promise<WorktreeSupabaseSession | null> {\n  const filePath = getWorktreeSessionFilePath(cwd, worktreeId);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    return JSON.parse(content) as WorktreeSupabaseSession;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Save worktree Supabase session to disk\n *\n * @param cwd - The working directory where logs are stored\n * @param session - Session state to save\n *\n * @example\n * ```typescript\n * await saveWorktreeSupabaseSession(cwd, {\n *   worktreeId: 'abc12345',\n *   worktreePath: '/path/to/worktree',\n *   slot: 1,\n *   supabasePorts: { api: 54331, db: 54332, ... },\n *   devServerPorts: { nextjs: 3010, vite: 5183, cloudflare: 8797 },\n *   startedAt: new Date().toISOString(),\n *   configBackupPath: '/path/to/config.toml.backup-abc12345',\n *   running: true,\n * });\n * ```\n */\nexport async function saveWorktreeSupabaseSession(\n  cwd: string,\n  session: WorktreeSupabaseSession\n): Promise<void> {\n  const filePath = getWorktreeSessionFilePath(cwd, session.worktreeId);\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(session, null, 2), 'utf-8');\n}\n\n/**\n * Update worktree Supabase session with partial updates\n *\n * @param cwd - The working directory where logs are stored\n * @param worktreeId - Unique worktree identifier\n * @param updates - Partial updates to apply\n * @returns Updated session, or null if session doesn't exist\n */\nexport async function updateWorktreeSupabaseSession(\n  cwd: string,\n  worktreeId: string,\n  updates: Partial<Omit<WorktreeSupabaseSession, 'worktreeId'>>\n): Promise<WorktreeSupabaseSession | null> {\n  const existing = await loadWorktreeSupabaseSession(cwd, worktreeId);\n  if (!existing) {\n    return null;\n  }\n\n  const updated: WorktreeSupabaseSession = {\n    ...existing,\n    ...updates,\n    worktreeId, // Ensure worktreeId is never overwritten\n  };\n\n  await saveWorktreeSupabaseSession(cwd, updated);\n  return updated;\n}\n\n/**\n * Clear worktree Supabase session from disk\n *\n * @param cwd - The working directory where logs are stored\n * @param worktreeId - Unique worktree identifier\n * @returns true if session was deleted, false if not found\n */\nexport async function clearWorktreeSupabaseSession(\n  cwd: string,\n  worktreeId: string\n): Promise<boolean> {\n  const filePath = getWorktreeSessionFilePath(cwd, worktreeId);\n\n  try {\n    await fs.unlink(filePath);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * List all worktree Supabase sessions\n * Useful for debugging and cleanup\n *\n * @param cwd - The working directory where logs are stored\n * @returns Array of all session states\n */\nexport async function listWorktreeSupabaseSessions(\n  cwd: string\n): Promise<WorktreeSupabaseSession[]> {\n  const logsDir = path.join(cwd, LOGS_DIR);\n  const sessions: WorktreeSupabaseSession[] = [];\n\n  try {\n    const files = await fs.readdir(logsDir);\n    const sessionFiles = files.filter(\n      (f) => f.startsWith(WORKTREE_SUPABASE_SESSION_PREFIX) && f.endsWith('.json')\n    );\n\n    for (const file of sessionFiles) {\n      try {\n        const content = await fs.readFile(path.join(logsDir, file), 'utf-8');\n        sessions.push(JSON.parse(content) as WorktreeSupabaseSession);\n      } catch {\n        // Skip invalid files\n      }\n    }\n  } catch {\n    // Directory doesn't exist\n  }\n\n  return sessions;\n}\n\n/**\n * Check if a worktree session exists and is marked as running\n *\n * @param cwd - The working directory where logs are stored\n * @param worktreeId - Unique worktree identifier\n * @returns true if session exists and is running\n */\nexport async function isWorktreeSupabaseRunning(\n  cwd: string,\n  worktreeId: string\n): Promise<boolean> {\n  const session = await loadWorktreeSupabaseSession(cwd, worktreeId);\n  return session?.running === true;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/subagent-state.ts": "/**\n * Subagent state management for Claude Code hooks\n * Coordinates context between SubagentStart and SubagentStop hooks\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './frontmatter.js';\nimport {\n  parseTranscript,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SUBAGENT_TASKS_FILE = 'subagent-tasks.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface AgentStartContext {\n  agentId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n  toolUseId: string;\n}\n\ninterface SubagentTasksMap {\n  [agentId: string]: AgentStartContext;\n}\n\nexport interface AgentEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to subagent-tasks.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SUBAGENT_TASKS_FILE);\n}\n\n/**\n * Save agent context at SubagentStart for later retrieval at SubagentStop\n */\nexport async function saveAgentStartContext(\n  input: {\n    agent_id: string;\n    agent_type: string;\n    session_id: string;\n    cwd: string;\n    transcript_path: string;\n  },\n  outputPath?: string\n): Promise<AgentStartContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  // Parse parent transcript to find the Task call\n  const parentTranscript = await parseTranscript(input.transcript_path);\n  const taskInfo = findPendingTaskCall(parentTranscript, input.agent_type);\n\n  const context: AgentStartContext = {\n    agentId: input.agent_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: taskInfo?.prompt || '',\n    toolUseId: taskInfo?.toolUseId || '',\n  };\n\n  // Load existing contexts\n  let contexts: SubagentTasksMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.agent_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved agent context from SubagentStart\n */\nexport async function loadAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<AgentStartContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    return contexts[agentId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove agent context after SubagentStop processing\n */\nexport async function removeAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    delete contexts[agentId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Agent Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze an agent transcript to extract comprehensive edit information\n */\nexport async function getAgentEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<AgentEditsResult> {\n  const filename = path.basename(agentTranscriptPath);\n  if (!filename.startsWith('agent-')) {\n    throw new Error(`Path must be an agent transcript (starting with agent-): ${filename}`);\n  }\n\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Try to load saved context\n  let savedContext: AgentStartContext | undefined;\n  if (cwd) {\n    savedContext = await loadAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    toolUseId: savedContext?.toolUseId,\n    subagentType: savedContext?.agentType || options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = taskInfo?.prompt || savedContext?.prompt || '';\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd) {\n    await removeAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/supabase-ports.ts": "/**\n * Supabase Port Management Utility\n * Manages port allocation for multiple concurrent Supabase instances across worktrees.\n * @module supabase-ports\n */\n\nimport { readFileSync, writeFileSync, existsSync, copyFileSync } from 'fs';\nimport { join } from 'path';\nimport { isPortAvailable, killProcessOnPort } from './port.js';\n\n/**\n * Default Supabase service ports\n */\nexport const SUPABASE_DEFAULT_PORTS = {\n  api: 54321,\n  db: 54322,\n  shadowDb: 54320,\n  studio: 54323,\n  inbucket: 54324,\n  analytics: 54327,\n  pooler: 54329,\n  edgeRuntime: 8083,\n} as const;\n\n/**\n * Port increment between slots (allows ~25 concurrent instances)\n */\nexport const PORT_INCREMENT = 10;\n\n/**\n * A complete set of Supabase service ports\n */\nexport interface SupabasePortSet {\n  api: number;\n  db: number;\n  shadowDb: number;\n  studio: number;\n  inbucket: number;\n  analytics: number;\n  pooler: number;\n  edgeRuntime: number;\n}\n\n/**\n * Result of checking port usage\n */\nexport interface PortUsageResult {\n  /** All critical ports (API, DB, Studio) are in use */\n  allRunning: boolean;\n  /** At least one port is in use but not all */\n  someRunning: boolean;\n  /** List of ports currently in use */\n  runningPorts: number[];\n  /** Ports that are available */\n  availablePorts: number[];\n}\n\n/**\n * Calculate a port set for a given slot number\n * Slot 0 = default ports, Slot 1 = +10, Slot 2 = +20, etc.\n *\n * @param slot - Slot number (0 for default, 1+ for worktrees)\n * @returns Complete port set for the slot\n */\nexport function calculatePortSet(slot: number): SupabasePortSet {\n  const offset = slot * PORT_INCREMENT;\n  return {\n    api: SUPABASE_DEFAULT_PORTS.api + offset,\n    db: SUPABASE_DEFAULT_PORTS.db + offset,\n    shadowDb: SUPABASE_DEFAULT_PORTS.shadowDb + offset,\n    studio: SUPABASE_DEFAULT_PORTS.studio + offset,\n    inbucket: SUPABASE_DEFAULT_PORTS.inbucket + offset,\n    analytics: SUPABASE_DEFAULT_PORTS.analytics + offset,\n    pooler: SUPABASE_DEFAULT_PORTS.pooler + offset,\n    edgeRuntime: SUPABASE_DEFAULT_PORTS.edgeRuntime + offset,\n  };\n}\n\n/**\n * Get all ports from a port set as an array\n *\n * @param ports - Port set to extract from\n * @returns Array of all port numbers\n */\nexport function getPortArray(ports: SupabasePortSet): number[] {\n  return [\n    ports.api,\n    ports.db,\n    ports.shadowDb,\n    ports.studio,\n    ports.inbucket,\n    ports.analytics,\n    ports.pooler,\n    ports.edgeRuntime,\n  ];\n}\n\n/**\n * Critical ports that indicate Supabase is fully running\n * If all three are in use, Supabase is considered \"fully running\"\n */\nconst CRITICAL_PORTS: (keyof typeof SUPABASE_DEFAULT_PORTS)[] = ['api', 'db', 'studio'];\n\n/**\n * Check which Supabase services are running on default ports\n * Determines if instance is fully running, partially running, or not running\n *\n * @param portSet - Optional port set to check (defaults to default ports)\n * @returns Port usage information\n */\nexport async function checkSupabasePortUsage(\n  portSet: SupabasePortSet = calculatePortSet(0)\n): Promise<PortUsageResult> {\n  const criticalPorts = CRITICAL_PORTS.map((key) => portSet[key]);\n  const allPorts = getPortArray(portSet);\n\n  const runningPorts: number[] = [];\n  const availablePorts: number[] = [];\n\n  // Check all ports in parallel\n  const results = await Promise.all(\n    allPorts.map(async (port) => ({\n      port,\n      available: await isPortAvailable(port),\n    }))\n  );\n\n  for (const { port, available } of results) {\n    if (available) {\n      availablePorts.push(port);\n    } else {\n      runningPorts.push(port);\n    }\n  }\n\n  // Check if all critical ports are in use\n  const criticalInUse = criticalPorts.filter((p) => runningPorts.includes(p));\n  const allRunning = criticalInUse.length === CRITICAL_PORTS.length;\n  const someRunning = runningPorts.length > 0 && !allRunning;\n\n  return {\n    allRunning,\n    someRunning,\n    runningPorts,\n    availablePorts,\n  };\n}\n\n/**\n * Find the next available port slot\n * Starts from slot 1 and increments until finding a slot with all ports available\n *\n * @param maxSlots - Maximum number of slots to check (default: 25)\n * @returns Slot number with available ports, or null if none found\n */\nexport async function findAvailableSlot(maxSlots: number = 25): Promise<number | null> {\n  for (let slot = 1; slot <= maxSlots; slot++) {\n    const portSet = calculatePortSet(slot);\n    const usage = await checkSupabasePortUsage(portSet);\n\n    // If no critical ports are in use, this slot is available\n    if (usage.runningPorts.length === 0) {\n      return slot;\n    }\n  }\n  return null;\n}\n\n/**\n * Find an available port set, starting from a given slot\n *\n * @param startSlot - Slot to start checking from (default: 1)\n * @returns Port set with all available ports, or null if none found\n */\nexport async function findAvailablePortSet(startSlot: number = 1): Promise<{\n  slot: number;\n  ports: SupabasePortSet;\n} | null> {\n  const slot = await findAvailableSlot(25);\n  if (slot === null || slot < startSlot) {\n    return null;\n  }\n  return {\n    slot,\n    ports: calculatePortSet(slot),\n  };\n}\n\n/**\n * Kill stale Supabase processes on a port set\n * Useful for cleaning up partial/crashed instances\n *\n * @param portSet - Ports to clean up\n * @returns Results of kill attempts for each port\n */\nexport async function killStaleSupabasePorts(\n  portSet: SupabasePortSet = calculatePortSet(0)\n): Promise<Array<{ port: number; killed: boolean }>> {\n  const ports = getPortArray(portSet);\n  const results = await Promise.all(\n    ports.map(async (port) => {\n      const available = await isPortAvailable(port);\n      if (available) {\n        return { port, killed: false };\n      }\n      const killed = await killProcessOnPort(port);\n      return { port, killed };\n    })\n  );\n  return results;\n}\n\n// ==================== Config.toml Management ====================\n\n/**\n * Parse port values from a Supabase config.toml file\n * Uses regex to extract port settings from TOML content\n *\n * @param configPath - Path to config.toml\n * @returns Current port configuration, or null if can't be parsed\n */\nexport function parseSupabaseConfigPorts(configPath: string): SupabasePortSet | null {\n  if (!existsSync(configPath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(configPath, 'utf-8');\n\n    // Extract ports using regex patterns\n    // Format: port = 54321 (with optional whitespace)\n    const extractPort = (section: string, key: string = 'port'): number | null => {\n      // Build regex to match [section] followed by key = value\n      const sectionRegex = new RegExp(`\\\\[${section}\\\\]([\\\\s\\\\S]*?)(?=\\\\n\\\\[|$)`, 'm');\n      const sectionMatch = content.match(sectionRegex);\n      if (!sectionMatch) return null;\n\n      const sectionContent = sectionMatch[1];\n      const portRegex = new RegExp(`^\\\\s*${key}\\\\s*=\\\\s*(\\\\d+)`, 'm');\n      const portMatch = sectionContent.match(portRegex);\n      return portMatch ? parseInt(portMatch[1], 10) : null;\n    };\n\n    return {\n      api: extractPort('api') ?? SUPABASE_DEFAULT_PORTS.api,\n      db: extractPort('db') ?? SUPABASE_DEFAULT_PORTS.db,\n      shadowDb: extractPort('db', 'shadow_port') ?? SUPABASE_DEFAULT_PORTS.shadowDb,\n      studio: extractPort('studio') ?? SUPABASE_DEFAULT_PORTS.studio,\n      inbucket: extractPort('inbucket') ?? SUPABASE_DEFAULT_PORTS.inbucket,\n      analytics: extractPort('analytics') ?? SUPABASE_DEFAULT_PORTS.analytics,\n      pooler: extractPort('db\\\\.pooler') ?? extractPort('db', 'pooler_port') ?? SUPABASE_DEFAULT_PORTS.pooler,\n      edgeRuntime: extractPort('edge_runtime', 'inspector_port') ?? SUPABASE_DEFAULT_PORTS.edgeRuntime,\n    };\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Update port values in a Supabase config.toml file\n * Creates a backup before modifying\n *\n * @param configPath - Path to config.toml\n * @param ports - New port values to set\n * @param backupSuffix - Suffix for backup file (default: '.backup')\n * @returns Path to backup file\n */\nexport function updateSupabaseConfigPorts(\n  configPath: string,\n  ports: SupabasePortSet,\n  backupSuffix: string = '.backup'\n): string {\n  if (!existsSync(configPath)) {\n    throw new Error(`Config file not found: ${configPath}`);\n  }\n\n  // Create backup\n  const backupPath = `${configPath}${backupSuffix}`;\n  copyFileSync(configPath, backupPath);\n\n  let content = readFileSync(configPath, 'utf-8');\n\n  // Helper to update a port in a section\n  const updatePort = (section: string, key: string, value: number): void => {\n    // Pattern to match the section and the key within it\n    const sectionRegex = new RegExp(`(\\\\[${section}\\\\][\\\\s\\\\S]*?)(${key}\\\\s*=\\\\s*)(\\\\d+)`, 'gm');\n\n    // Check if the key exists in the section\n    if (sectionRegex.test(content)) {\n      // Reset regex state\n      sectionRegex.lastIndex = 0;\n      content = content.replace(sectionRegex, `$1$2${value}`);\n    } else {\n      // Key doesn't exist, try to add it after section header\n      const addKeyRegex = new RegExp(`(\\\\[${section}\\\\]\\\\s*\\\\n)`, 'm');\n      if (addKeyRegex.test(content)) {\n        content = content.replace(addKeyRegex, `$1${key} = ${value}\\n`);\n      }\n    }\n  };\n\n  // Update each port\n  updatePort('api', 'port', ports.api);\n  updatePort('db', 'port', ports.db);\n  updatePort('db', 'shadow_port', ports.shadowDb);\n  updatePort('db\\\\.pooler', 'port', ports.pooler);\n  updatePort('studio', 'port', ports.studio);\n  updatePort('inbucket', 'port', ports.inbucket);\n  updatePort('analytics', 'port', ports.analytics);\n  updatePort('edge_runtime', 'inspector_port', ports.edgeRuntime);\n\n  writeFileSync(configPath, content, 'utf-8');\n\n  return backupPath;\n}\n\n/**\n * Restore config.toml from backup\n *\n * @param configPath - Path to config.toml\n * @param backupSuffix - Suffix used for backup (default: '.backup')\n * @returns true if restored, false if backup not found\n */\nexport function restoreSupabaseConfig(\n  configPath: string,\n  backupSuffix: string = '.backup'\n): boolean {\n  const backupPath = `${configPath}${backupSuffix}`;\n\n  if (!existsSync(backupPath)) {\n    return false;\n  }\n\n  copyFileSync(backupPath, configPath);\n  return true;\n}\n\n/**\n * Get the path to supabase config.toml in a project\n *\n * @param cwd - Project root directory\n * @returns Path to config.toml\n */\nexport function getSupabaseConfigPath(cwd: string): string {\n  return join(cwd, 'supabase', 'config.toml');\n}\n\n/**\n * Check if a project has Supabase initialized\n *\n * @param cwd - Project root directory\n * @returns true if supabase/config.toml exists\n */\nexport function hasSupabaseConfig(cwd: string): boolean {\n  return existsSync(getSupabaseConfigPath(cwd));\n}\n\n// ============================================================================\n// Project ID Management (for Database Isolation)\n// ============================================================================\n\n/**\n * Extract the base project ID by stripping any slot suffixes\n * Handles cascading suffixes like: \"myapp-1\", \"myapp-3-4-5\" -> \"myapp\"\n *\n * @param projectId - The project ID to clean\n * @returns The base project ID without slot suffixes\n * @example\n * ```typescript\n * extractBaseProjectId('myapp')       // Returns: \"myapp\"\n * extractBaseProjectId('myapp-1')     // Returns: \"myapp\"\n * extractBaseProjectId('myapp-3-4-5') // Returns: \"myapp\"\n * ```\n */\nexport function extractBaseProjectId(projectId: string): string {\n  // Strip trailing slot suffixes like -1, -2, -3-4-5, etc.\n  // Pattern: one or more occurrences of dash followed by digits at the end\n  return projectId.replace(/(-\\d+)+$/, '');\n}\n\n/**\n * Read original project_id from config.toml\n * Tries backup file first (has true original), then falls back to current config\n * with suffix stripping to handle corrupted state from previous sessions.\n *\n * @param configPath - Path to config.toml\n * @param worktreeId - Optional worktree ID to check backup file\n * @returns The project_id string, or null if not found\n * @example\n * ```typescript\n * const projectId = getOriginalProjectId('/path/to/supabase/config.toml', 'abc12345');\n * // Returns: \"myapp\" (from backup or stripped from current config)\n * ```\n */\nexport function getOriginalProjectId(configPath: string, worktreeId?: string): string | null {\n  // Try backup file first (has true original project ID)\n  if (worktreeId) {\n    const backupPath = `${configPath}.backup-${worktreeId}`;\n    if (existsSync(backupPath)) {\n      try {\n        const backupContent = readFileSync(backupPath, 'utf-8');\n        const match = backupContent.match(/project_id\\s*=\\s*\"([^\"]+)\"/);\n        if (match) return match[1];\n      } catch {\n        // Fall through to current config\n      }\n    }\n  }\n\n  // Also try the main backup (for main repo sessions)\n  const mainBackupPath = `${configPath}.backup-main`;\n  if (existsSync(mainBackupPath)) {\n    try {\n      const backupContent = readFileSync(mainBackupPath, 'utf-8');\n      const match = backupContent.match(/project_id\\s*=\\s*\"([^\"]+)\"/);\n      if (match) return match[1];\n    } catch {\n      // Fall through to current config\n    }\n  }\n\n  // Fall back to current config, but strip any slot suffix\n  if (!existsSync(configPath)) {\n    return null;\n  }\n\n  const content = readFileSync(configPath, 'utf-8');\n  const match = content.match(/project_id\\s*=\\s*\"([^\"]+)\"/);\n  if (match) {\n    // Strip any existing slot suffixes to get the true base project ID\n    return extractBaseProjectId(match[1]);\n  }\n  return null;\n}\n\n/**\n * Generate worktree-specific project_id\n * Slot 0 = original project_id (main repo)\n * Slot 1+ = original-{slot} (worktrees)\n *\n * @param originalId - Original project_id from config.toml\n * @param slot - Slot number (0 for main, 1+ for worktrees)\n * @returns Worktree-specific project_id\n * @example\n * ```typescript\n * generateWorktreeProjectId('myapp', 0)  // Returns: \"myapp-0\"\n * generateWorktreeProjectId('myapp', 1)  // Returns: \"myapp-1\"\n * generateWorktreeProjectId('myapp', 2)  // Returns: \"myapp-2\"\n * ```\n */\nexport function generateWorktreeProjectId(originalId: string, slot: number): string {\n  return `${originalId}-${slot}`;\n}\n\n/**\n * Update project_id in config.toml with backup\n *\n * @param configPath - Path to config.toml\n * @param newProjectId - New project_id to set\n * @param backupSuffix - Suffix for backup file (e.g., \".backup-abc12345\")\n * @returns Path to backup file\n * @throws Error if config.toml cannot be read or written\n * @example\n * ```typescript\n * const backupPath = updateSupabaseProjectId(\n *   '/path/to/supabase/config.toml',\n *   'myapp-1',\n *   '.backup-abc12345'\n * );\n * // Creates backup at: /path/to/supabase/config.toml.backup-abc12345\n * // Updates project_id to: \"myapp-1\"\n * ```\n */\nexport function updateSupabaseProjectId(\n  configPath: string,\n  newProjectId: string,\n  backupSuffix: string\n): string {\n  const content = readFileSync(configPath, 'utf-8');\n  const backupPath = `${configPath}${backupSuffix}`;\n\n  // Backup original config\n  copyFileSync(configPath, backupPath);\n\n  // Replace project_id\n  const updated = content.replace(/project_id\\s*=\\s*\"[^\"]+\"/, `project_id = \"${newProjectId}\"`);\n\n  writeFileSync(configPath, updated, 'utf-8');\n  return backupPath;\n}\n\n// ============================================================================\n// Service Optimization (Resource Management)\n// ============================================================================\n\n/**\n * Detect which Supabase services are enabled in config.toml\n *\n * @param configPath - Path to config.toml\n * @returns Array of enabled service names\n * @example\n * ```typescript\n * const enabled = getEnabledServices('/path/to/supabase/config.toml');\n * // Returns: ['gotrue', 'realtime', 'storage-api', 'postgrest', ...]\n * ```\n */\nexport function getEnabledServices(configPath: string): string[] {\n  if (!existsSync(configPath)) {\n    return [];\n  }\n\n  const content = readFileSync(configPath, 'utf-8');\n\n  // Map of service names to their config.toml section names\n  const serviceMap: Record<string, string> = {\n    gotrue: 'auth',\n    realtime: 'realtime',\n    'storage-api': 'storage',\n    'edge-runtime': 'edge-runtime',\n    logflare: 'analytics',\n    vector: 'vector',\n  };\n\n  const services = Object.keys(serviceMap);\n\n  return services.filter((service) => {\n    const section = serviceMap[service];\n    // Match [section] ... enabled = true pattern (case insensitive, multiline)\n    const pattern = new RegExp(`\\\\[${section}\\\\][\\\\s\\\\S]*?enabled\\\\s*=\\\\s*true`, 'i');\n    return pattern.test(content);\n  });\n}\n\n/**\n * Build --exclude flag for disabled Supabase services\n * This optimizes resource usage by skipping services not used by the project\n *\n * @param configPath - Path to config.toml\n * @returns CLI flag string (e.g., \" --exclude edge-runtime,logflare\") or empty string\n * @example\n * ```typescript\n * const excludeFlags = buildExcludeFlags('/path/to/supabase/config.toml');\n * const command = `supabase start${excludeFlags}`;\n * // If edge-runtime and logflare are disabled:\n * // command = \"supabase start --exclude edge-runtime,logflare\"\n * ```\n */\nexport function buildExcludeFlags(configPath: string): string {\n  const enabled = getEnabledServices(configPath);\n  const allServices = ['gotrue', 'realtime', 'storage-api', 'edge-runtime', 'logflare', 'vector'];\n  const disabled = allServices.filter((s) => !enabled.includes(s));\n\n  if (disabled.length === 0) return '';\n\n  return ` --exclude ${disabled.join(',')}`;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/supabase-tmp-config.ts": "/**\n * Supabase Temporary Config Directory Utility\n * Manages /tmp/ directories for Supabase config to avoid modifying checked-in files.\n * Uses symlinks for migrations, seed.sql, functions, and templates.\n * @module supabase-tmp-config\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync, symlinkSync, rmSync, readdirSync, appendFileSync } from 'fs';\nimport { join } from 'path';\nimport type { SupabasePortSet } from './supabase-ports.js';\n\n/**\n * Configuration for a temporary Supabase directory\n */\nexport interface TmpSupabaseConfig {\n  /** Path to the tmp directory (e.g., /tmp/supabase-abc12345) */\n  tmpDir: string;\n  /** Path to config.toml in tmp directory */\n  configPath: string;\n  /** Path to original supabase/ directory */\n  originalDir: string;\n  /** Modified project_id for this instance */\n  projectId: string;\n  /** Assigned ports for this instance */\n  ports: SupabasePortSet;\n}\n\n/**\n * Items to symlink from original supabase/ directory\n * These stay in sync with the original project\n */\nconst SYMLINK_ITEMS = ['seed.sql', 'migrations', 'functions', 'templates'] as const;\n\n\n/**\n * Generate the tmp directory path for a Supabase instance\n *\n * IMPORTANT: Supabase CLI uses the workdir directory basename for container naming,\n * NOT the project_id from config.toml. So we must name the directory after the projectId.\n *\n * @param projectId - The full project ID including slot suffix (e.g., \"constellos\" or \"constellos-1\")\n * @returns Path to tmp directory (e.g., /tmp/constellos or /tmp/constellos-1)\n *\n * @example\n * ```typescript\n * getTmpSupabasePath('constellos')    // Returns: '/tmp/constellos'\n * getTmpSupabasePath('constellos-1')  // Returns: '/tmp/constellos-1'\n * getTmpSupabasePath('constellos-2')  // Returns: '/tmp/constellos-2'\n * ```\n */\nexport function getTmpSupabasePath(projectId: string): string {\n  // Normalize project ID to lowercase alphanumeric with dashes\n  const normalizedId = projectId.toLowerCase().replace(/[^a-z0-9-]/g, '');\n  return `/tmp/${normalizedId}`;\n}\n\n/**\n * Create a fresh temporary Supabase directory with symlinks\n * Cleans up any existing directory first (fresh each session)\n *\n * @param projectId - Full project ID including slot suffix (e.g., \"constellos\" or \"constellos-1\")\n * @param originalSupabaseDir - Path to original supabase/ directory\n * @param ports - Port set to configure\n * @returns Configuration for the tmp directory\n * @throws Error if original directory doesn't exist or can't create tmp\n */\nexport function createTmpSupabaseDir(\n  projectId: string,\n  originalSupabaseDir: string,\n  ports: SupabasePortSet\n): TmpSupabaseConfig {\n  const tmpDir = getTmpSupabasePath(projectId);\n  // Supabase CLI expects supabase/ subdirectory inside --workdir\n  const tmpSupabaseDir = join(tmpDir, 'supabase');\n\n  // Verify original directory exists\n  if (!existsSync(originalSupabaseDir)) {\n    throw new Error(`Original Supabase directory not found: ${originalSupabaseDir}`);\n  }\n\n  const originalConfigPath = join(originalSupabaseDir, 'config.toml');\n  if (!existsSync(originalConfigPath)) {\n    throw new Error(`Original config.toml not found: ${originalConfigPath}`);\n  }\n\n  // Clean up existing tmp directory (fresh each session)\n  if (existsSync(tmpDir)) {\n    rmSync(tmpDir, { recursive: true, force: true });\n  }\n\n  // Create tmp directory with supabase/ subdirectory\n  // Structure: /tmp/{projectId}/supabase/config.toml\n  // This matches what Supabase CLI expects with --workdir flag\n  mkdirSync(tmpSupabaseDir, { recursive: true });\n\n  // Create symlinks for allowed items inside supabase/ subdirectory\n  createSymlinks(tmpSupabaseDir, originalSupabaseDir);\n\n  // Copy and update config.toml inside supabase/ subdirectory\n  const tmpConfigPath = join(tmpSupabaseDir, 'config.toml');\n  copyAndUpdateConfig(originalConfigPath, tmpConfigPath, projectId, ports);\n\n  return {\n    tmpDir,\n    configPath: tmpConfigPath,\n    originalDir: originalSupabaseDir,\n    projectId,\n    ports,\n  };\n}\n\n/**\n * Create symlinks from tmp directory to original supabase/ items\n * Only symlinks items that exist in original directory\n *\n * @param tmpDir - Tmp directory to create symlinks in\n * @param originalDir - Original supabase/ directory\n */\nexport function createSymlinks(tmpDir: string, originalDir: string): void {\n  for (const item of SYMLINK_ITEMS) {\n    const originalPath = join(originalDir, item);\n    const tmpPath = join(tmpDir, item);\n\n    // Only create symlink if original exists\n    if (existsSync(originalPath)) {\n      try {\n        symlinkSync(originalPath, tmpPath, 'junction');\n      } catch (err) {\n        // Fallback to regular symlink if junction fails (non-Windows)\n        try {\n          symlinkSync(originalPath, tmpPath);\n        } catch {\n          // If symlink fails entirely, skip this item\n          console.error(`Warning: Could not create symlink for ${item}: ${err}`);\n        }\n      }\n    }\n  }\n}\n\n/**\n * Copy config.toml and update with new project_id and ports\n *\n * @param originalConfigPath - Path to original config.toml\n * @param tmpConfigPath - Path to write updated config\n * @param projectId - New project_id to set\n * @param ports - Port values to set\n */\nexport function copyAndUpdateConfig(\n  originalConfigPath: string,\n  tmpConfigPath: string,\n  projectId: string,\n  ports: SupabasePortSet\n): void {\n  let content = readFileSync(originalConfigPath, 'utf-8');\n\n  // Update project_id\n  content = content.replace(\n    /^(\\s*project_id\\s*=\\s*)\"[^\"]*\"/m,\n    `$1\"${projectId}\"`\n  );\n\n  // Update ports using helper function\n  content = updateConfigPorts(content, ports);\n\n  writeFileSync(tmpConfigPath, content, 'utf-8');\n}\n\n/**\n * Update port values in config.toml content\n *\n * @param content - Config.toml content\n * @param ports - New port values\n * @returns Updated content\n */\nfunction updateConfigPorts(content: string, ports: SupabasePortSet): string {\n  // Helper to update a port value in a section\n  const updatePort = (sectionPattern: string, key: string, value: number): void => {\n    // Pattern to match [section] followed by key = value\n    const regex = new RegExp(\n      `(\\\\[${sectionPattern}\\\\][\\\\s\\\\S]*?)(^\\\\s*${key}\\\\s*=\\\\s*)(\\\\d+)`,\n      'gm'\n    );\n\n    if (regex.test(content)) {\n      regex.lastIndex = 0;\n      content = content.replace(regex, `$1$2${value}`);\n    }\n  };\n\n  // Update each port\n  updatePort('api', 'port', ports.api);\n  updatePort('db', 'port', ports.db);\n  updatePort('db', 'shadow_port', ports.shadowDb);\n  updatePort('db\\\\.pooler', 'port', ports.pooler);\n  updatePort('studio', 'port', ports.studio);\n  updatePort('inbucket', 'port', ports.inbucket);\n  updatePort('analytics', 'port', ports.analytics);\n  updatePort('edge_runtime', 'inspector_port', ports.edgeRuntime);\n\n  return content;\n}\n\n/**\n * Clean up a temporary Supabase directory\n * Safe to call even if directory doesn't exist\n *\n * @param tmpDir - Path to tmp directory to remove\n */\nexport function cleanupTmpSupabaseDir(tmpDir: string): void {\n  if (existsSync(tmpDir)) {\n    try {\n      rmSync(tmpDir, { recursive: true, force: true });\n    } catch (err) {\n      console.error(`Warning: Could not clean up tmp directory ${tmpDir}: ${err}`);\n    }\n  }\n}\n\n/**\n * Add tmp directory pattern to .gitignore if not already present\n *\n * @param projectRoot - Project root directory (where .gitignore is)\n * @param tmpPath - Tmp directory path to add (will be converted to pattern)\n * @returns true if pattern was added, false if already present\n */\nexport function addToGitignore(projectRoot: string, _tmpPath?: string): boolean {\n  const gitignorePath = join(projectRoot, '.gitignore');\n  const pattern = '/tmp/supabase-*';\n\n  // Check if .gitignore exists\n  if (!existsSync(gitignorePath)) {\n    // Create .gitignore with just this pattern\n    writeFileSync(gitignorePath, `# Supabase temp config directories\\n${pattern}\\n`, 'utf-8');\n    return true;\n  }\n\n  // Read existing content\n  const content = readFileSync(gitignorePath, 'utf-8');\n\n  // Check if pattern already exists (with various formats)\n  const patterns = [pattern, '/tmp/supabase-', 'tmp/supabase-'];\n  for (const p of patterns) {\n    if (content.includes(p)) {\n      return false; // Already present\n    }\n  }\n\n  // Add pattern at the end\n  const separator = content.endsWith('\\n') ? '' : '\\n';\n  appendFileSync(gitignorePath, `${separator}\\n# Supabase temp config directories\\n${pattern}\\n`, 'utf-8');\n  return true;\n}\n\n/**\n * Check if a tmp Supabase directory exists for a project\n *\n * @param projectId - The full project ID including slot suffix\n * @returns true if tmp directory exists\n */\nexport function tmpSupabaseDirExists(projectId: string): boolean {\n  const tmpDir = getTmpSupabasePath(projectId);\n  return existsSync(tmpDir);\n}\n\n/**\n * Get the config.toml path for a tmp Supabase directory\n *\n * @param projectId - The full project ID including slot suffix\n * @returns Path to config.toml in tmp directory\n */\nexport function getTmpConfigPath(projectId: string): string {\n  return join(getTmpSupabasePath(projectId), 'config.toml');\n}\n\n/**\n * List all tmp Supabase directories currently on the system\n * Useful for cleanup and diagnostics\n *\n * @returns Array of tmp directory paths\n */\nexport function listTmpSupabaseDirs(): string[] {\n  const tmpDir = '/tmp';\n  if (!existsSync(tmpDir)) {\n    return [];\n  }\n\n  try {\n    const entries = readdirSync(tmpDir, { withFileTypes: true });\n    return entries\n      .filter(entry => entry.isDirectory() && entry.name.startsWith('supabase-'))\n      .map(entry => join(tmpDir, entry.name));\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Clean up all tmp Supabase directories\n * Use with caution - will remove all instances\n *\n * @returns Number of directories cleaned up\n */\nexport function cleanupAllTmpSupabaseDirs(): number {\n  const dirs = listTmpSupabaseDirs();\n  let cleaned = 0;\n\n  for (const dir of dirs) {\n    try {\n      rmSync(dir, { recursive: true, force: true });\n      cleaned++;\n    } catch {\n      // Continue with other directories\n    }\n  }\n\n  return cleaned;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/task-state.test.ts": "/**\n * Tests for task-state.ts - Task state management and frontmatter parsing\n *\n * @module task-state.test\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport { tmpdir } from 'os';\nimport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n} from './task-state.js';\n\ndescribe('Task State Management', () => {\n  let testDir: string;\n  let taskCallsPath: string;\n\n  beforeEach(async () => {\n    // Create temporary directory for tests\n    testDir = await fs.mkdtemp(path.join(tmpdir(), 'task-state-test-'));\n    taskCallsPath = path.join(testDir, 'task-calls.json');\n  });\n\n  afterEach(async () => {\n    // Clean up temporary directory\n    try {\n      await fs.rm(testDir, { recursive: true, force: true });\n    } catch {\n      // Ignore cleanup errors\n    }\n  });\n\n  describe('saveTaskCallContext', () => {\n    it('should save task call context to file', async () => {\n      const input = {\n        tool_use_id: 'toolu_abc123',\n        agent_type: 'Explore',\n        session_id: 'session-xyz',\n        prompt: 'Find all API endpoints',\n        cwd: testDir,\n      };\n\n      const context = await saveTaskCallContext(input, taskCallsPath);\n\n      expect(context.toolUseId).toBe('toolu_abc123');\n      expect(context.agentType).toBe('Explore');\n      expect(context.sessionId).toBe('session-xyz');\n      expect(context.prompt).toBe('Find all API endpoints');\n      expect(context.timestamp).toBeDefined();\n\n      // Verify file was created\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n      expect(saved['toolu_abc123']).toBeDefined();\n      expect(saved['toolu_abc123'].agentType).toBe('Explore');\n    });\n\n    it('should append to existing contexts', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_first',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'First task',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_second',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Second task',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n\n      expect(Object.keys(saved)).toHaveLength(2);\n      expect(saved['toolu_first']).toBeDefined();\n      expect(saved['toolu_second']).toBeDefined();\n    });\n  });\n\n  describe('loadTaskCallContext', () => {\n    it('should load saved context by tool_use_id', async () => {\n      const input = {\n        tool_use_id: 'toolu_load_test',\n        agent_type: 'Explore',\n        session_id: 'session-load',\n        prompt: 'Load test prompt',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input, taskCallsPath);\n      const loaded = await loadTaskCallContext('toolu_load_test', testDir, taskCallsPath);\n\n      expect(loaded).toBeDefined();\n      expect(loaded?.toolUseId).toBe('toolu_load_test');\n      expect(loaded?.agentType).toBe('Explore');\n      expect(loaded?.prompt).toBe('Load test prompt');\n    });\n\n    it('should return undefined for non-existent context', async () => {\n      const loaded = await loadTaskCallContext('toolu_nonexistent', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n    });\n\n    it('should return undefined when file does not exist', async () => {\n      const loaded = await loadTaskCallContext('toolu_any', testDir, '/path/does/not/exist.json');\n      expect(loaded).toBeUndefined();\n    });\n  });\n\n  describe('removeTaskCallContext', () => {\n    it('should remove context from file', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_keep',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'Keep this',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_remove',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Remove this',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      await removeTaskCallContext('toolu_remove', testDir, taskCallsPath);\n\n      const loaded = await loadTaskCallContext('toolu_remove', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n\n      const kept = await loadTaskCallContext('toolu_keep', testDir, taskCallsPath);\n      expect(kept).toBeDefined();\n    });\n\n    it('should handle removing non-existent context gracefully', async () => {\n      await expect(\n        removeTaskCallContext('toolu_nonexistent', testDir, taskCallsPath)\n      ).resolves.toBeUndefined();\n    });\n  });\n\n  describe('parseFrontmatter (integration via parseAgentFrontmatter)', () => {\n    it('should parse simple key-value frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent.md');\n      const content = `---\nname: TestAgent\ndescription: A test agent\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      // We can't directly test parseFrontmatter since it's not exported,\n      // but we can test it indirectly through getTaskEdits if we create\n      // proper test fixtures. For now, let's create a simpler test.\n\n      // Read the file and verify the frontmatter format is correct\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---');\n      expect(fileContent).toContain('name: TestAgent');\n    });\n\n    it('should parse array values in frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent-with-skills.md');\n      const content = `---\nname: TestAgent\nskills: [skill1, skill2, skill3]\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('skills: [skill1, skill2, skill3]');\n    });\n\n    it('should handle frontmatter with various formats', async () => {\n      const agentFile = path.join(testDir, 'complex-agent.md');\n      const content = `---\nname: ComplexAgent\nversion: 1.0.0\nskills: [claude-plugins, turborepo-vercel]\nenabled: true\n---\n\n# Complex Agent\n\nThis agent has complex frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('name: ComplexAgent');\n      expect(fileContent).toContain('version: 1.0.0');\n      expect(fileContent).toContain('skills: [claude-plugins, turborepo-vercel]');\n      expect(fileContent).toContain('enabled: true');\n    });\n\n    it('should handle missing frontmatter gracefully', async () => {\n      const agentFile = path.join(testDir, 'no-frontmatter.md');\n      const content = `# Agent Without Frontmatter\n\nThis agent has no frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).not.toContain('---');\n    });\n\n    it('should handle empty frontmatter', async () => {\n      const agentFile = path.join(testDir, 'empty-frontmatter.md');\n      const content = `---\n---\n\n# Agent With Empty Frontmatter\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---\\n---');\n    });\n  });\n\n  describe('Full workflow integration', () => {\n    it('should save, load, and remove context in sequence', async () => {\n      // Save\n      const input = {\n        tool_use_id: 'toolu_workflow',\n        agent_type: 'general-purpose',\n        session_id: 'session-workflow',\n        prompt: 'Complete workflow test',\n        cwd: testDir,\n      };\n\n      const saved = await saveTaskCallContext(input, taskCallsPath);\n      expect(saved.toolUseId).toBe('toolu_workflow');\n\n      // Load\n      const loaded = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(loaded).toBeDefined();\n      expect(loaded?.prompt).toBe('Complete workflow test');\n\n      // Remove\n      await removeTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      const removed = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(removed).toBeUndefined();\n    });\n  });\n});\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/task-state.ts": "/**\n * Task state management for Claude Code hooks\n *\n * Coordinates context between PreToolUse[Task] and SubagentStop hooks by saving\n * task call metadata at PreToolUse time and retrieving it later for analysis.\n * This enables tracking what tasks were requested, what agents executed them,\n * and what file operations resulted from the task execution.\n *\n * The typical flow is:\n * 1. PreToolUse[Task] - Save task context (prompt, agent type, tool use ID)\n * 2. Task executes - Agent runs and performs file operations\n * 3. SubagentStop - Load context, analyze edits, cleanup\n *\n * @module task-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport {\n  parseTranscript,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\nimport matter from './frontmatter.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst TASK_CALLS_FILE = 'task-calls.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface TaskCallContext {\n  toolUseId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n}\n\ninterface TaskCallsMap {\n  [toolUseId: string]: TaskCallContext;\n}\n\nexport interface TaskEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to task-calls.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, TASK_CALLS_FILE);\n}\n\n/**\n * Save task call context at PreToolUse[Task] for later retrieval at SubagentStop\n *\n * Stores task metadata in .claude/logs/task-calls.json so that SubagentStop hooks\n * can correlate the task's original prompt and parameters with the agent's execution\n * results. This enables rich commit messages and task tracking.\n *\n * @param input - Task call metadata to save\n * @param input.tool_use_id - The unique ID of the Task tool use\n * @param input.agent_type - The type of agent that will execute (e.g., 'Explore', 'Plan')\n * @param input.session_id - The current session ID\n * @param input.prompt - The task prompt/description provided to the agent\n * @param input.cwd - The working directory where logs should be stored\n * @param outputPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context object\n *\n * @example\n * ```typescript\n * import { saveTaskCallContext } from './task-state.js';\n *\n * // In PreToolUse[Task] hook\n * const context = await saveTaskCallContext({\n *   tool_use_id: 'toolu_abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   prompt: 'Find all API endpoints',\n *   cwd: '/path/to/project'\n * });\n * ```\n */\nexport async function saveTaskCallContext(\n  input: {\n    tool_use_id: string;\n    agent_type: string;\n    session_id: string;\n    prompt: string;\n    cwd: string;\n  },\n  outputPath?: string\n): Promise<TaskCallContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  const context: TaskCallContext = {\n    toolUseId: input.tool_use_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: input.prompt,\n  };\n\n  // Load existing contexts\n  let contexts: TaskCallsMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.tool_use_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved task call context from PreToolUse[Task]\n *\n * Retrieves the task metadata that was saved during PreToolUse. This allows\n * SubagentStop hooks to access the original task prompt and parameters.\n *\n * @param toolUseId - The tool_use_id from the Task tool call\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context, or undefined if not found\n *\n * @example\n * ```typescript\n * import { loadTaskCallContext } from './task-state.js';\n *\n * // In SubagentStop hook\n * const context = await loadTaskCallContext(\n *   'toolu_abc123',\n *   '/path/to/project'\n * );\n * if (context) {\n *   console.log('Task prompt:', context.prompt);\n *   console.log('Agent type:', context.agentType);\n * }\n * ```\n */\nexport async function loadTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<TaskCallContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    return contexts[toolUseId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove task context after processing\n *\n * Cleans up the saved task context once it has been processed by SubagentStop.\n * This prevents the context file from growing indefinitely.\n *\n * @param toolUseId - The tool_use_id of the context to remove\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns Promise that resolves when context is removed (or fails silently)\n *\n * @example\n * ```typescript\n * import { removeTaskCallContext } from './task-state.js';\n *\n * // After processing in SubagentStop\n * await removeTaskCallContext('toolu_abc123', '/path/to/project');\n * ```\n */\nexport async function removeTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    delete contexts[toolUseId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Task Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze a task transcript to extract comprehensive edit information\n *\n * Parses an agent transcript to determine what files were created, edited, or deleted\n * during task execution. Correlates with saved task context to provide complete\n * metadata about the task, including the original prompt, agent type, and preloaded skills.\n *\n * This function:\n * 1. Parses the agent transcript to extract messages and metadata\n * 2. Finds the parent session transcript and locates the matching Task tool call\n * 3. Loads the saved task context (if available)\n * 4. Analyzes file operations (new, edited, deleted files)\n * 5. Identifies preloaded skills from agent frontmatter\n * 6. Cleans up the saved context\n *\n * @param agentTranscriptPath - Path to the agent transcript file (from SubagentStop's agent_transcript_path field)\n * @param options - Optional configuration\n * @param options.contextPath - Custom path for task-calls.json (for testing)\n * @param options.subagentType - Fallback subagent type if not found in context\n * @returns Comprehensive task execution metadata and file operation lists\n * @throws Error if agent transcript is empty\n * @throws Error if agentId cannot be determined\n * @throws Error if parent session transcript not found\n *\n * @example\n * ```typescript\n * import { getTaskEdits } from './task-state.js';\n *\n * // In SubagentStop hook\n * const edits = await getTaskEdits(input.agent_transcript_path);\n *\n * console.log('Task prompt:', edits.agentPrompt);\n * console.log('Agent type:', edits.subagentType);\n * console.log('Files created:', edits.agentNewFiles);\n * console.log('Files edited:', edits.agentEditedFiles);\n * console.log('Files deleted:', edits.agentDeletedFiles);\n * console.log('Preloaded skills:', edits.agentPreloadedSkillsFiles);\n * ```\n *\n * @example\n * ```typescript\n * // Complete PreToolUse → SubagentStop flow\n *\n * // 1. PreToolUse[Task] - Save context\n * import { saveTaskCallContext } from './task-state.js';\n *\n * async function handlePreToolUse(input: PreToolUseInput) {\n *   if (input.tool_name === 'Task') {\n *     await saveTaskCallContext({\n *       tool_use_id: input.tool_use_id,\n *       agent_type: input.tool_input.subagent_type,\n *       session_id: input.session_id,\n *       prompt: input.tool_input.prompt,\n *       cwd: input.cwd\n *     });\n *   }\n *   return { hookSpecificOutput: { permissionDecision: 'allow' } };\n * }\n *\n * // 2. Task executes (agent runs)\n *\n * // 3. SubagentStop - Analyze edits\n * import { getTaskEdits } from './task-state.js';\n *\n * async function handleSubagentStop(input: SubagentStopInput) {\n *   const edits = await getTaskEdits(input.agent_transcript_path);\n *\n *   // Use edits for commit message, logging, etc.\n *   console.log(`Task \"${edits.agentPrompt}\" completed`);\n *   console.log(`Modified ${edits.agentEditedFiles.length} files`);\n *\n *   return {};\n * }\n * ```\n */\nexport async function getTaskEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<TaskEditsResult> {\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    subagentType: options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  // Try to load saved context using tool_use_id from task call\n  let savedContext: TaskCallContext | undefined;\n  if (cwd && taskInfo?.toolUseId) {\n    savedContext = await loadTaskCallContext(taskInfo.toolUseId, cwd, options?.contextPath);\n  }\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = savedContext?.prompt || taskInfo?.prompt || '';\n  const toolUseId = taskInfo?.toolUseId || savedContext?.toolUseId;\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd && toolUseId) {\n    await removeTaskCallContext(toolUseId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/toml.ts": "/**\n * Simple TOML parser for configuration files\n *\n * Provides basic TOML parsing functionality for reading configuration files\n * like supabase/config.toml. This is a lightweight parser that supports the\n * most common TOML features without requiring external dependencies.\n *\n * Supported TOML features:\n * - Key-value pairs (strings, numbers, booleans)\n * - Inline arrays: `values = [1, 2, 3]`\n * - Multiline arrays spanning multiple lines\n * - Tables (sections): `[section]` and `[section.subsection]`\n * - Comments starting with `#`\n *\n * @module toml\n */\n\nexport interface TomlValue {\n  [key: string]: string | number | boolean | string[] | TomlValue;\n}\n\n/**\n * Parse a TOML string into a JavaScript object\n *\n * Converts TOML configuration syntax into a JavaScript object with nested\n * structure matching the TOML sections and subsections.\n *\n * @param content - The TOML string to parse\n * @returns Parsed object with nested structure\n *\n * @example\n * ```typescript\n * import { parseToml } from './toml.js';\n *\n * const tomlContent = `\n * # Project configuration\n * project_id = \"my-project\"\n * enabled = true\n *\n * [api]\n * port = 54321\n * enabled_services = [\"auth\", \"realtime\", \"storage\"]\n *\n * [db]\n * port = 54322\n * `;\n *\n * const config = parseToml(tomlContent);\n * console.log(config.project_id); // \"my-project\"\n * console.log(config.enabled); // true\n * console.log(config.api.port); // 54321\n * console.log(config.api.enabled_services); // [\"auth\", \"realtime\", \"storage\"]\n * console.log(config.db.port); // 54322\n * ```\n */\nexport function parseToml(content: string): TomlValue {\n  const result: TomlValue = {};\n  let currentSection: TomlValue = result;\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      continue;\n    }\n\n    // Handle table headers [section] or [section.subsection]\n    if (line.startsWith('[') && line.endsWith(']')) {\n      const sectionPath = line.slice(1, -1).trim();\n      currentSection = result;\n\n      for (const part of sectionPath.split('.')) {\n        if (!(part in currentSection)) {\n          currentSection[part] = {};\n        }\n        currentSection = currentSection[part] as TomlValue;\n      }\n      continue;\n    }\n\n    // Handle key-value pairs\n    const eqIndex = line.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = line.slice(0, eqIndex).trim();\n    const value = line.slice(eqIndex + 1).trim();\n\n    // Parse the value\n    currentSection[key] = parseValue(value, lines, i);\n  }\n\n  return result;\n}\n\n/**\n * Parse a TOML value\n */\nfunction parseValue(value: string, lines: string[], lineIndex: number): string | number | boolean | string[] {\n  // Handle multiline arrays\n  if (value === '[' || value.startsWith('[') && !value.endsWith(']')) {\n    return parseMultilineArray(value, lines, lineIndex);\n  }\n\n  // Handle inline arrays\n  if (value.startsWith('[') && value.endsWith(']')) {\n    return parseInlineArray(value);\n  }\n\n  // Handle strings\n  if (value.startsWith('\"') && value.endsWith('\"')) {\n    return value.slice(1, -1);\n  }\n  if (value.startsWith(\"'\") && value.endsWith(\"'\")) {\n    return value.slice(1, -1);\n  }\n\n  // Handle booleans\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle numbers\n  const num = Number(value);\n  if (!isNaN(num)) return num;\n\n  // Return as string if nothing else matches\n  return value;\n}\n\n/**\n * Parse an inline array like [1, 2, 3] or [\"a\", \"b\", \"c\"]\n */\nfunction parseInlineArray(value: string): string[] {\n  const inner = value.slice(1, -1).trim();\n  if (!inner) return [];\n\n  const items: string[] = [];\n  let current = '';\n  let inQuote = false;\n  let quoteChar = '';\n\n  for (const char of inner) {\n    if ((char === '\"' || char === \"'\") && !inQuote) {\n      inQuote = true;\n      quoteChar = char;\n    } else if (char === quoteChar && inQuote) {\n      inQuote = false;\n      quoteChar = '';\n    } else if (char === ',' && !inQuote) {\n      const trimmed = current.trim();\n      if (trimmed) {\n        items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n      }\n      current = '';\n    } else {\n      current += char;\n    }\n  }\n\n  const trimmed = current.trim();\n  if (trimmed) {\n    items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n  }\n\n  return items;\n}\n\n/**\n * Parse a multiline array\n */\nfunction parseMultilineArray(startValue: string, lines: string[], startIndex: number): string[] {\n  const items: string[] = [];\n  let content = startValue;\n\n  // Collect lines until we find the closing bracket\n  for (let i = startIndex; i < lines.length; i++) {\n    const line = lines[i].trim();\n    if (i > startIndex) {\n      content += ' ' + line;\n    }\n    if (line.includes(']')) {\n      break;\n    }\n  }\n\n  // Now parse as inline array\n  const match = content.match(/\\[([\\s\\S]*)\\]/);\n  if (match) {\n    return parseInlineArray('[' + match[1] + ']');\n  }\n\n  return items;\n}\n\n/**\n * Read and parse a TOML file\n *\n * Reads a TOML configuration file from disk and parses it into a JavaScript object.\n * Returns null if the file doesn't exist or cannot be read.\n *\n * @param filePath - Path to the TOML file\n * @returns Parsed object, or null if file doesn't exist or read fails\n *\n * @example\n * ```typescript\n * import { readTomlFile } from './toml.js';\n * import { join } from 'path';\n *\n * // Read Supabase configuration\n * const supabaseConfig = await readTomlFile(\n *   join(process.cwd(), 'supabase', 'config.toml')\n * );\n *\n * if (supabaseConfig) {\n *   console.log('Project ID:', supabaseConfig.project_id);\n *   console.log('API port:', supabaseConfig.api?.port);\n *   console.log('DB port:', supabaseConfig.db?.port);\n * } else {\n *   console.log('Supabase not initialized');\n * }\n * ```\n */\nexport async function readTomlFile(filePath: string): Promise<TomlValue | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(filePath, 'utf-8');\n    return parseToml(content);\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get the dev server port from a wrangler.toml or wrangler.jsonc file\n *\n * Parses the wrangler configuration file to extract the dev server port.\n * Supports both TOML format (wrangler.toml) and JSONC format (wrangler.jsonc).\n *\n * For TOML files, looks for: `[dev]` section with `port = 8787`\n * For JSONC files, looks for: `{ \"dev\": { \"port\": 8787 } }`\n *\n * @param wranglerPath - Path to wrangler.toml or wrangler.jsonc file\n * @returns Port number if found, null if file doesn't exist or port not configured\n *\n * @example\n * ```typescript\n * import { getWranglerDevPort } from './toml.js';\n * import { join } from 'path';\n *\n * // Check wrangler.toml\n * const port = await getWranglerDevPort(join(process.cwd(), 'wrangler.toml'));\n * console.log('Wrangler dev port:', port || 8787); // Default to 8787 if not found\n *\n * // Check wrangler.jsonc\n * const port2 = await getWranglerDevPort(join(process.cwd(), 'wrangler.jsonc'));\n * ```\n */\nexport async function getWranglerDevPort(wranglerPath: string): Promise<number | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(wranglerPath, 'utf-8');\n\n    // Handle TOML format (wrangler.toml)\n    if (wranglerPath.endsWith('.toml')) {\n      const config = parseToml(content);\n      if (config.dev && typeof config.dev === 'object') {\n        const dev = config.dev as TomlValue;\n        if (typeof dev.port === 'number') {\n          return dev.port;\n        }\n      }\n      return null;\n    }\n\n    // Handle JSONC format (wrangler.jsonc)\n    if (wranglerPath.endsWith('.jsonc') || wranglerPath.endsWith('.json')) {\n      // Strip comments from JSONC\n      const jsonContent = content.replace(/\\/\\*[\\s\\S]*?\\*\\/|\\/\\/.*/g, '');\n      const config = JSON.parse(jsonContent);\n      if (config.dev && typeof config.dev.port === 'number') {\n        return config.dev.port;\n      }\n      return null;\n    }\n\n    return null;\n  } catch {\n    return null;\n  }\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/transcripts.ts": "/**\n * Transcript parsing utilities for Claude Code\n * Lenient JSONL parsing without Zod - uses type guards for safety\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Types for Transcript Parsing\n// ============================================================================\n\nexport interface BaseMessage {\n  uuid: string;\n  parentUuid: string | null;\n  timestamp: string;\n  sessionId: string;\n  isSidechain: boolean;\n  cwd: string;\n  version: string;\n  gitBranch?: string;\n  slug?: string;\n  agentId?: string;\n}\n\nexport interface ToolUseContent {\n  type: 'tool_use';\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n}\n\nexport interface TextContent {\n  type: 'text';\n  text: string;\n}\n\nexport interface ToolResultContent {\n  type: 'tool_result';\n  tool_use_id: string;\n  content?: string | Array<{ type: string; text?: string }>;\n}\n\nexport type AssistantContent = ToolUseContent | TextContent | { type: string; [key: string]: unknown };\nexport type UserContent = string | Array<ToolResultContent | { type: string; [key: string]: unknown }>;\n\nexport interface UserMessage extends BaseMessage {\n  type: 'user';\n  userType: 'external';\n  message: {\n    role: 'user';\n    content: UserContent;\n  };\n  toolUseResult?: Record<string, unknown>;\n}\n\nexport interface AssistantMessage extends BaseMessage {\n  type: 'assistant';\n  requestId: string;\n  message: {\n    id: string;\n    type: 'message';\n    role: 'assistant';\n    model: string;\n    content: AssistantContent[];\n    stop_reason: string | null;\n    stop_sequence: string | null;\n    usage: {\n      input_tokens: number;\n      output_tokens: number;\n      cache_creation_input_tokens?: number;\n      cache_read_input_tokens?: number;\n    };\n  };\n}\n\nexport interface SystemMessage extends BaseMessage {\n  type: 'system';\n  subtype: string;\n  content: string;\n  isMeta: boolean;\n  level: 'info' | 'warning' | 'error';\n}\n\nexport type Message = UserMessage | AssistantMessage | SystemMessage;\n\nexport interface Transcript {\n  sourcePath: string;\n  sessionId: string;\n  subagentType?: string;\n  agentId?: string;\n  isSidechain: boolean;\n  messages: Message[];\n}\n\n// ============================================================================\n// Type Guards\n// ============================================================================\n\nfunction isObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === 'object' && value !== null;\n}\n\nfunction isMessage(line: unknown): line is Message {\n  if (!isObject(line)) return false;\n  const type = line.type;\n  return type === 'user' || type === 'assistant' || type === 'system';\n}\n\nfunction hasRequiredFields(line: unknown): boolean {\n  if (!isObject(line)) return false;\n  return (\n    typeof line.uuid === 'string' &&\n    typeof line.timestamp === 'string' &&\n    typeof line.sessionId === 'string'\n  );\n}\n\n// ============================================================================\n// Parsing Functions\n// ============================================================================\n\n/**\n * Parse a single JSONL line (lenient - returns null on error)\n */\nexport function parseTranscriptLine(line: string): Message | null {\n  try {\n    const json = JSON.parse(line);\n    if (!isMessage(json) || !hasRequiredFields(json)) {\n      return null;\n    }\n    return json as Message;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get transcript metadata from file path\n */\nexport function getTranscriptInfo(filePath: string): { agentId?: string; isSidechain: boolean } {\n  const filename = path.basename(filePath);\n  const isSubagent = filename.startsWith('agent-');\n  const agentId = isSubagent ? filename.replace('agent-', '').replace('.jsonl', '') : undefined;\n\n  return { agentId, isSidechain: isSubagent };\n}\n\n/**\n * Parse a full .jsonl transcript file\n */\nexport async function parseTranscript(filePath: string): Promise<Transcript> {\n  const info = getTranscriptInfo(filePath);\n  const content = await fs.readFile(filePath, 'utf-8');\n  const lines = content.trim().split('\\n').filter(Boolean);\n\n  const messages: Message[] = [];\n  let sessionId = '';\n\n  for (const line of lines) {\n    const parsed = parseTranscriptLine(line);\n    if (!parsed) continue;\n\n    if (!sessionId) sessionId = parsed.sessionId;\n    messages.push(parsed);\n  }\n\n  return {\n    sourcePath: filePath,\n    sessionId,\n    agentId: info.agentId,\n    isSidechain: info.isSidechain,\n    messages,\n  };\n}\n\n// ============================================================================\n// Query Functions\n// ============================================================================\n\n/**\n * Extract all tool uses from a transcript\n */\nexport function getToolUses(transcript: Transcript): Array<{\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n  timestamp: string;\n}> {\n  const toolUses: Array<{\n    id: string;\n    name: string;\n    input: Record<string, unknown>;\n    timestamp: string;\n  }> = [];\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        toolUses.push({\n          id: tu.id,\n          name: tu.name,\n          input: tu.input,\n          timestamp: msg.timestamp,\n        });\n      }\n    }\n  }\n\n  return toolUses;\n}\n\n/**\n * Extract unique file paths edited by Write/Edit tools\n */\nexport function getEditedFiles(transcript: Transcript): string[] {\n  const files = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write' || tu.name === 'Edit') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string') {\n            files.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(files);\n}\n\n/**\n * Extract unique file paths created by Write tool (new files only)\n */\nexport function getNewFiles(transcript: Transcript): string[] {\n  const newFiles: string[] = [];\n  const seenPaths = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string' && !seenPaths.has(filePath)) {\n            newFiles.push(filePath);\n            seenPaths.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return newFiles;\n}\n\n/**\n * Extract unique file paths deleted via Bash rm commands\n */\nexport function getDeletedFiles(transcript: Transcript): string[] {\n  const deletedFiles = new Set<string>();\n  const rmPattern = /^\\s*rm\\s+(?:-[rfiv]+\\s+)*(.+)$/;\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Bash') {\n          const command = tu.input.command;\n          if (typeof command !== 'string') continue;\n\n          const commands = command.split(/\\s*(?:&&|;)\\s*/);\n          for (const cmd of commands) {\n            const match = cmd.match(rmPattern);\n            if (match) {\n              const pathsStr = match[1].trim();\n              const paths = pathsStr.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g) || [];\n\n              for (const p of paths) {\n                const cleanPath = p.replace(/^[\"']|[\"']$/g, '');\n                if (!cleanPath.startsWith('-')) {\n                  deletedFiles.add(cleanPath);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(deletedFiles);\n}\n\n/**\n * Find pending Task tool call matching agent type\n */\nexport function findPendingTaskCall(\n  transcript: Transcript,\n  agentType: string\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls: Array<{\n    toolUseId: string;\n    subagentType: string;\n    prompt: string;\n    timestamp: string;\n  }> = [];\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.push({\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Collect completed tool_use_ids\n  const completedToolUseIds = new Set<string>();\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const content = msg.message.content;\n    if (typeof content === 'string') continue;\n    for (const rc of content) {\n      if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n        completedToolUseIds.add(rc.tool_use_id);\n      }\n    }\n  }\n\n  // Find pending Task calls matching agent type\n  const pendingTasks = taskCalls\n    .filter((t) => !completedToolUseIds.has(t.toolUseId))\n    .filter((t) => t.subagentType === agentType)\n    .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n  return pendingTasks[0];\n}\n\n/**\n * Find Task tool call for an agent using multiple strategies\n */\nexport function findTaskCallForAgent(\n  transcript: Transcript,\n  targetAgentId: string,\n  options?: {\n    subagentType?: string;\n    toolUseId?: string;\n    agentStartTimestamp?: string;\n  }\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls = new Map<string, {\n    subagentType: string;\n    prompt: string;\n    toolUseId: string;\n    timestamp: string;\n  }>();\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.set(tu.id, {\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Strategy 1: Direct lookup by toolUseId\n  if (options?.toolUseId) {\n    const direct = taskCalls.get(options.toolUseId);\n    if (direct) return direct;\n  }\n\n  // Strategy 2: Match via tool_result.agentId\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const toolResult = msg.toolUseResult as { agentId?: string } | undefined;\n    if (toolResult?.agentId === targetAgentId) {\n      const content = msg.message.content;\n      if (typeof content === 'string') continue;\n\n      for (const rc of content) {\n        if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n          const taskInfo = taskCalls.get(rc.tool_use_id);\n          if (taskInfo) return taskInfo;\n        }\n      }\n    }\n  }\n\n  // Strategy 3: Fuzzy match by subagentType and timestamp\n  if (options?.subagentType && options?.agentStartTimestamp) {\n    const agentStartTime = new Date(options.agentStartTimestamp).getTime();\n    const maxDelta = 10000; // 10 seconds\n\n    const candidates = Array.from(taskCalls.values())\n      .filter((t) => t.subagentType === options.subagentType)\n      .filter((t) => {\n        const taskTime = new Date(t.timestamp).getTime();\n        return taskTime <= agentStartTime && agentStartTime - taskTime <= maxDelta;\n      })\n      .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n    if (candidates[0]) return candidates[0];\n  }\n\n  return undefined;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/vite-config.ts": "/**\n * Vite Configuration Parser Utility\n * Parses vite.config.ts files to extract server.port configuration.\n * @module vite-config\n */\n\nimport { existsSync, readFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Default Vite dev server port\n */\nexport const VITE_DEFAULT_PORT = 5173;\n\n/**\n * Parse vite.config.ts/js/mjs to extract server.port value\n * Uses regex to extract port from various config patterns:\n * - server: { port: 3000 }\n * - server: { port: Number(3000) }\n * - defineConfig({ server: { port: 3000 } })\n *\n * @param viteConfigPath - Path to vite.config.ts/js/mjs file\n * @returns Configured port number, or null if not found\n * @example\n * ```typescript\n * const port = getViteConfigPort('/path/to/vite.config.ts');\n * // Returns: 3000 (if configured) or null (if not found)\n * ```\n */\nexport function getViteConfigPort(viteConfigPath: string): number | null {\n  if (!existsSync(viteConfigPath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(viteConfigPath, 'utf-8');\n\n    // Pattern 1: server: { port: 3000 } or server: { port: 3000, ... }\n    // Handles multiline and various whitespace\n    const serverBlockMatch = content.match(\n      /server\\s*:\\s*\\{[^}]*port\\s*:\\s*(\\d+)/s\n    );\n    if (serverBlockMatch) {\n      return parseInt(serverBlockMatch[1], 10);\n    }\n\n    // Pattern 2: server.port = 3000 (less common but valid)\n    const dotNotationMatch = content.match(\n      /server\\.port\\s*[=:]\\s*(\\d+)/\n    );\n    if (dotNotationMatch) {\n      return parseInt(dotNotationMatch[1], 10);\n    }\n\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Find and parse vite.config file in a directory\n * Tries .ts, .js, .mjs extensions in order\n *\n * @param workspacePath - Directory to search for vite config\n * @returns Configured port number, or null if not found\n * @example\n * ```typescript\n * const port = findViteConfigPort('/path/to/project');\n * // Searches for vite.config.ts, vite.config.js, vite.config.mjs\n * ```\n */\nexport function findViteConfigPort(workspacePath: string): number | null {\n  const extensions = ['ts', 'js', 'mjs'];\n\n  for (const ext of extensions) {\n    const configPath = join(workspacePath, `vite.config.${ext}`);\n    const port = getViteConfigPort(configPath);\n    if (port !== null) {\n      return port;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Check if a directory contains a Vite configuration file\n *\n * @param workspacePath - Directory to check\n * @returns true if vite.config.{ts,js,mjs} exists\n */\nexport function hasViteConfig(workspacePath: string): boolean {\n  const extensions = ['ts', 'js', 'mjs'];\n  return extensions.some(ext =>\n    existsSync(join(workspacePath, `vite.config.${ext}`))\n  );\n}\n\n/**\n * Get the path to the vite config file if it exists\n *\n * @param workspacePath - Directory to search\n * @returns Path to vite config file, or null if not found\n */\nexport function getViteConfigPath(workspacePath: string): string | null {\n  const extensions = ['ts', 'js', 'mjs'];\n\n  for (const ext of extensions) {\n    const configPath = join(workspacePath, `vite.config.${ext}`);\n    if (existsSync(configPath)) {\n      return configPath;\n    }\n  }\n\n  return null;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/was-tool-event-main-agent.ts": "/**\n * Utility to determine if a tool event was executed by the main agent vs a subagent\n */\n\nimport { parseTranscript, type AssistantMessage } from './transcripts.js';\n\n/**\n * Check if a specific tool use was executed by the main agent (not a subagent)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param toolUseId - The tool_use_id to check\n * @returns true if the tool was used by the main agent, false if by a subagent\n *\n * @example\n * ```typescript\n * const isMainAgent = await wasToolEventMainAgent(\n *   input.transcript_path,\n *   input.tool_use_id\n * );\n * if (!isMainAgent) {\n *   // Skip processing for subagent tool use\n *   return { continue: true };\n * }\n * ```\n */\nexport async function wasToolEventMainAgent(\n  transcriptPath: string,\n  toolUseId: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n\n  // Find the assistant message containing this tool use\n  for (const msg of transcript.messages) {\n    if (msg.type === 'assistant') {\n      const assistantMsg = msg as AssistantMessage;\n      const toolUse = assistantMsg.message.content.find(\n        (c) => c.type === 'tool_use' && 'id' in c && c.id === toolUseId\n      );\n\n      if (toolUse) {\n        // If agentId is undefined/null, it's the main agent\n        // If agentId is a string, it's a subagent\n        return !msg.agentId;\n      }\n    }\n  }\n\n  // If we can't find the tool use, default to assuming it's the main agent\n  // This is safer than blocking legitimate main agent operations\n  return true;\n}\n\n/**\n * Check if the entire transcript is from the main agent session (not a subagent session)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns true if this is a main agent transcript, false if it's a subagent transcript\n *\n * @example\n * ```typescript\n * const isMainSession = await isMainAgentTranscript(input.transcript_path);\n * if (!isMainSession) {\n *   // This is a subagent session, skip processing\n *   return { continue: true };\n * }\n * ```\n */\nexport async function isMainAgentTranscript(transcriptPath: string): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return !transcript.isSidechain;\n}\n\n/**\n * Check if a transcript belongs to a specific subagent type\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param subagentType - The subagent type to check for (e.g., \"Explore\", \"Plan\")\n * @returns true if the transcript is from the specified subagent type\n *\n * @example\n * ```typescript\n * const isExploreAgent = await isSubagentType(input.transcript_path, 'Explore');\n * if (isExploreAgent) {\n *   // Special handling for Explore agents\n * }\n * ```\n */\nexport async function isSubagentType(\n  transcriptPath: string,\n  subagentType: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.subagentType === subagentType;\n}\n\n/**\n * Get the agent ID from a transcript (undefined for main agent, string for subagents)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns The agent ID if this is a subagent, undefined if main agent\n *\n * @example\n * ```typescript\n * const agentId = await getTranscriptAgentId(input.transcript_path);\n * if (agentId) {\n *   console.log(`Processing subagent: ${agentId}`);\n * } else {\n *   console.log('Processing main agent');\n * }\n * ```\n */\nexport async function getTranscriptAgentId(transcriptPath: string): Promise<string | undefined> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.agentId;\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/utils/worktree.ts": "/**\n * Git Worktree Detection Utility\n * Detects if the current directory is a git worktree and provides worktree information\n * for consistent port allocation across concurrent sessions.\n * @module worktree\n */\n\nimport { existsSync, readFileSync, statSync } from 'fs';\nimport { join, dirname, resolve } from 'path';\nimport { createHash } from 'crypto';\n\n/**\n * Information about a git worktree\n */\nexport interface WorktreeInfo {\n  /** Whether the current directory is a git worktree (not main repo) */\n  isWorktree: boolean;\n  /** Full path to the worktree root directory */\n  worktreePath: string;\n  /** Path to the main repository (same as worktreePath if not a worktree) */\n  parentRepoPath: string;\n  /** Short hash (8 chars) for unique identification, used for port slot allocation */\n  worktreeId: string;\n  /** Worktree name extracted from path (e.g., \"claude-brave-zebra-k8fifpgr\") */\n  worktreeName: string;\n}\n\n/**\n * Generate a stable worktree ID from a path\n * Uses SHA256 hash truncated to 8 characters for uniqueness while being short\n *\n * @param path - The path to hash\n * @returns 8-character hex string\n */\nexport function getWorktreeId(path: string): string {\n  const hash = createHash('sha256').update(path).digest('hex');\n  return hash.substring(0, 8);\n}\n\n/**\n * Calculate a numeric slot from worktree ID for port allocation\n * Converts the hex worktree ID to a slot number (1-99)\n *\n * @param worktreeId - 8-character hex worktree ID\n * @returns Slot number (1-99), or 0 for main repo\n */\nexport function getWorktreeSlot(worktreeId: string): number {\n  // Convert first 4 hex chars to number, mod 99, + 1 to get 1-99 range\n  const num = parseInt(worktreeId.substring(0, 4), 16);\n  return (num % 99) + 1;\n}\n\n/**\n * Find the git root directory from a given path\n * Walks up the directory tree looking for .git\n *\n * @param startPath - Starting directory\n * @returns Path to git root, or null if not in a git repo\n */\nfunction findGitRoot(startPath: string): string | null {\n  let current = resolve(startPath);\n  const root = '/';\n\n  while (current !== root) {\n    const gitPath = join(current, '.git');\n    if (existsSync(gitPath)) {\n      return current;\n    }\n    const parent = dirname(current);\n    if (parent === current) break;\n    current = parent;\n  }\n\n  return null;\n}\n\n/**\n * Parse the .git file in a worktree to extract the gitdir path\n * Worktrees have a .git FILE (not directory) containing: gitdir: /path/to/main/.git/worktrees/name\n *\n * @param gitFilePath - Path to the .git file\n * @returns The gitdir path, or null if invalid\n */\nfunction parseGitFile(gitFilePath: string): string | null {\n  try {\n    const content = readFileSync(gitFilePath, 'utf-8').trim();\n    const match = content.match(/^gitdir:\\s*(.+)$/);\n    if (match) {\n      return match[1].trim();\n    }\n  } catch {\n    // File doesn't exist or can't be read\n  }\n  return null;\n}\n\n/**\n * Extract the main repository path from a worktree gitdir path\n * gitdir format: /path/to/main-repo/.git/worktrees/worktree-name\n *\n * @param gitdir - The gitdir path from .git file\n * @returns Path to the main repository\n */\nfunction extractParentRepoPath(gitdir: string): string {\n  // gitdir looks like: /path/to/repo/.git/worktrees/worktree-name\n  // We need to get: /path/to/repo\n  const worktreesIndex = gitdir.indexOf('/.git/worktrees/');\n  if (worktreesIndex !== -1) {\n    return gitdir.substring(0, worktreesIndex);\n  }\n  // Fallback: strip last two components (.git/worktrees/name -> repo path)\n  return dirname(dirname(dirname(gitdir)));\n}\n\n/**\n * Extract worktree name from the gitdir path\n *\n * @param gitdir - The gitdir path from .git file\n * @returns Worktree name (last component of path)\n */\nfunction extractWorktreeName(gitdir: string): string {\n  // gitdir looks like: /path/to/repo/.git/worktrees/worktree-name\n  const parts = gitdir.split('/');\n  return parts[parts.length - 1] || 'unknown';\n}\n\n/**\n * Detect if the current directory is a git worktree\n * Returns comprehensive information about the worktree for port allocation\n *\n * @param cwd - Current working directory to check\n * @returns WorktreeInfo object with detection results\n *\n * @example\n * ```typescript\n * const info = detectWorktree('/home/user/project-worktree');\n * if (info.isWorktree) {\n *   console.log(`Worktree: ${info.worktreeName}`);\n *   console.log(`Slot: ${getWorktreeSlot(info.worktreeId)}`);\n * }\n * ```\n */\nexport function detectWorktree(cwd: string): WorktreeInfo {\n  const gitRoot = findGitRoot(cwd);\n\n  if (!gitRoot) {\n    // Not in a git repo at all\n    return {\n      isWorktree: false,\n      worktreePath: cwd,\n      parentRepoPath: cwd,\n      worktreeId: getWorktreeId(cwd),\n      worktreeName: 'main',\n    };\n  }\n\n  const gitPath = join(gitRoot, '.git');\n\n  // Check if .git is a file (worktree) or directory (main repo)\n  try {\n    const stats = statSync(gitPath);\n\n    if (stats.isFile()) {\n      // This is a worktree - .git is a file pointing to the main repo\n      const gitdir = parseGitFile(gitPath);\n\n      if (gitdir && gitdir.includes('/.git/worktrees/')) {\n        const parentRepoPath = extractParentRepoPath(gitdir);\n        const worktreeName = extractWorktreeName(gitdir);\n\n        return {\n          isWorktree: true,\n          worktreePath: gitRoot,\n          parentRepoPath,\n          worktreeId: getWorktreeId(gitRoot),\n          worktreeName,\n        };\n      }\n    }\n\n    // .git is a directory - this is the main repo\n    return {\n      isWorktree: false,\n      worktreePath: gitRoot,\n      parentRepoPath: gitRoot,\n      worktreeId: getWorktreeId(gitRoot),\n      worktreeName: 'main',\n    };\n  } catch {\n    // Can't stat .git - return default\n    return {\n      isWorktree: false,\n      worktreePath: cwd,\n      parentRepoPath: cwd,\n      worktreeId: getWorktreeId(cwd),\n      worktreeName: 'main',\n    };\n  }\n}\n\n/**\n * Check if a path looks like a worktree path\n * Quick heuristic check without full detection\n *\n * @param path - Path to check\n * @returns true if path appears to be a worktree\n */\nexport function looksLikeWorktree(path: string): boolean {\n  // Common worktree path patterns\n  return (\n    path.includes('-worktrees/') ||\n    path.includes('/worktrees/') ||\n    /claude-[a-z]+-[a-z]+-[a-z0-9]+$/.test(path)\n  );\n}\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-folder-structure-mkdir.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Bash mkdir)\n *\n * This hook fires before Bash operations to validate directory creation against\n * CLAUDE.md folder specifications. Validates:\n * - mkdir commands creating new directories\n * - Checks parent's subfolder spec for allowed patterns\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n *\n * @module hooks/validate-folder-structure-mkdir\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Extract directory paths from mkdir commands\n * Handles: mkdir dir, mkdir -p dir, mkdir -p dir1 dir2, etc.\n */\nfunction extractMkdirPaths(command: string): string[] {\n  const paths: string[] = [];\n\n  // Extract the actual command (before pipes, semicolons, &&, etc.)\n  // This prevents false positives from strings containing \"mkdir\"\n  const actualCommand = command.split(/[|;&]/)[0].trim();\n\n  // Check if this is actually a mkdir command (not just containing \"mkdir\" in a string)\n  if (!actualCommand.match(/^\\s*(sudo\\s+)?mkdir\\b/)) {\n    return paths;\n  }\n\n  // Remove mkdir and common flags\n  const remainder = command\n    .replace(/^.*mkdir\\s+/, '')\n    .replace(/-[pv]+\\s+/g, '');\n\n  // Extract all path arguments (space-separated)\n  // Handle quoted paths\n  const pathMatches = remainder.match(/(?:\"([^\"]+)\"|'([^']+)'|(\\S+))/g);\n\n  if (pathMatches) {\n    for (const match of pathMatches) {\n      // Remove quotes if present\n      const cleanPath = match.replace(/^[\"']|[\"']$/g, '');\n      // Skip flags\n      if (!cleanPath.startsWith('-')) {\n        paths.push(cleanPath);\n      }\n    }\n  }\n\n  return paths;\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Bash mkdir operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Bash tool\n  if (input.tool_name !== 'Bash') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-mkdir', true);\n\n  try {\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput.command;\n\n    if (!command) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Extract mkdir paths from command\n    const mkdirPaths = extractMkdirPaths(command);\n\n    if (mkdirPaths.length === 0) {\n      // Not a mkdir command - don't log anything, just allow\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only log input for actual mkdir commands\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n      command,\n      mkdirPaths,\n    });\n\n    await logger.logOutput({\n      command,\n      mkdirPaths,\n    });\n\n    const allErrors: string[] = [];\n\n    // Validate each directory path\n    for (const dirPath of mkdirPaths) {\n      // Resolve to absolute path\n      const absolutePath = path.isAbsolute(dirPath)\n        ? dirPath\n        : path.resolve(input.cwd, dirPath);\n\n      const parentDir = path.dirname(absolutePath);\n      const folderName = path.basename(absolutePath);\n\n      await logger.logOutput({\n        dirPath,\n        absolutePath,\n        parentDir,\n        folderName,\n      });\n\n      // Check if directory already exists\n      try {\n        await fs.access(absolutePath);\n        // Directory exists, no need to validate\n        await logger.logOutput({\n          dirPath,\n          status: 'exists',\n        });\n        continue;\n      } catch {\n        // Directory doesn't exist, proceed with validation\n      }\n\n      // Validate the directory is allowed in parent's subfolder spec\n      const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n      if (parentClaudeMd) {\n        const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n        const { data: parentData } = matter(parentContent);\n        const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n        await logger.logOutput({\n          check: 'parent-subfolder-validation',\n          dirPath,\n          parentClaudeMd,\n          parentFrontmatter,\n        });\n\n        if (parentFrontmatter.folder?.subfolders) {\n          const validation = validateAgainstSpec(\n            folderName,\n            parentFrontmatter.folder.subfolders,\n            'Folder'\n          );\n\n          if (!validation.valid) {\n            allErrors.push(\n              `Cannot create directory \"${folderName}\" in \"${parentDir}\":\\n` +\n                validation.errors.map(e => `  - ${e}`).join('\\n') +\n                `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n            );\n          }\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `Folder structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Folder structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-folder-structure-write.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Write)\n *\n * This hook fires before Write operations to validate file creation against\n * CLAUDE.md folder specifications. Validates both:\n * 1. File is in an allowed subdirectory (checks parent's subfolder spec)\n * 2. File matches allowed patterns in its immediate directory (checks files spec)\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n * - folder.files: Controls what files can exist in the folder\n *\n * @module hooks/validate-folder-structure-write\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Write operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write tool\n  if (input.tool_name !== 'Write') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-write', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Resolve to absolute path\n    const absolutePath = path.isAbsolute(filePath)\n      ? filePath\n      : path.resolve(input.cwd, filePath);\n\n    const fileDir = path.dirname(absolutePath);\n    const fileName = path.basename(absolutePath);\n    const parentDir = path.dirname(fileDir);\n    const folderName = path.basename(fileDir);\n\n    await logger.logOutput({\n      filePath,\n      absolutePath,\n      fileDir,\n      fileName,\n      parentDir,\n      folderName,\n    });\n\n    const allErrors: string[] = [];\n\n    // Check 1: Validate the directory itself is allowed (check parent's subfolder spec)\n    const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n    if (parentClaudeMd) {\n      const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n      const { data: parentData } = matter(parentContent);\n      const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'parent-subfolder-validation',\n        parentClaudeMd,\n        parentFrontmatter,\n      });\n\n      if (parentFrontmatter.folder?.subfolders) {\n        const validation = validateAgainstSpec(\n          folderName,\n          parentFrontmatter.folder.subfolders,\n          'Folder'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file in directory \"${folderName}\":\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // Check 2: Validate the file itself is allowed (check directory's files spec)\n    const dirClaudeMd = await findClaudeMdInDir(fileDir);\n\n    if (dirClaudeMd) {\n      const dirContent = await fs.readFile(dirClaudeMd, 'utf-8');\n      const { data: dirData } = matter(dirContent);\n      const dirFrontmatter = dirData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'file-validation',\n        dirClaudeMd,\n        dirFrontmatter,\n      });\n\n      if (dirFrontmatter.folder?.files) {\n        const validation = validateAgainstSpec(\n          fileName,\n          dirFrontmatter.folder.files,\n          'File'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file \"${fileName}\" in this directory:\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nFile restrictions defined in: ${dirClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `File structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `File structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/shared/hooks/validate-rules-file.ts": "/**\n * PreToolUse Hook - Validate Rules File\n *\n * This hook fires before Write and Edit operations on rule files in .claude/rules\n * to validate that markdown-specific frontmatter is only used in .md-specific rules.\n *\n * Provides guidance:\n * - Warns if markdown frontmatter is used in non-.md rules\n * - Encourages markdown frontmatter in .md rules if not present\n * - Does NOT block operations - only provides context\n *\n * @module hooks/validate-rules-file\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface MarkdownValidation {\n  headings?: unknown;\n  metadata?: unknown;\n}\n\ninterface RuleFrontmatter {\n  markdown?: MarkdownValidation;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a rule filename indicates it applies to markdown files\n */\nfunction isMarkdownRule(filename: string): boolean {\n  const lowerFilename = filename.toLowerCase();\n\n  // Remove .md extension from rule filename for checking\n  const ruleName = lowerFilename.replace(/\\.md$/, '');\n\n  // Check if rule name suggests markdown files\n  return (\n    ruleName.includes('markdown') ||\n    ruleName.includes('.md') ||\n    ruleName === 'md' ||\n    ruleName.endsWith('-md')\n  );\n}\n\n/**\n * PreToolUse hook handler for validating rules files\n *\n * Validates that markdown frontmatter is appropriately used in rule files.\n * Provides guidance but does not block operations.\n *\n * @param input - PreToolUse hook input from Claude Code\n * @returns Hook output with guidance messages\n */\nasync function handler(\n  input: PreToolUseInput\n): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-rules-file', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Get the file path and content from tool input\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Check if this is a file in .claude/rules\n    const normalizedPath = path.normalize(filePath);\n    const isRuleFile = normalizedPath.includes(path.join('.claude', 'rules')) &&\n                       filePath.endsWith('.md');\n\n    if (!isRuleFile) {\n      await logger.logOutput({ message: 'Not a rule file, skipping' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get content based on operation type\n    let content: string | undefined;\n\n    if (input.tool_name === 'Write') {\n      content = toolInput.content;\n    } else if (input.tool_name === 'Edit') {\n      // For Edit, we need the new content after the edit\n      // Since we can't easily reconstruct it, we'll just check the new_string portion\n      content = toolInput.new_string;\n    }\n\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter\n    let frontmatter: RuleFrontmatter;\n    try {\n      const { data } = matter(content);\n      frontmatter = data as RuleFrontmatter;\n    } catch {\n      // If we can't parse frontmatter, allow the operation\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    const filename = path.basename(filePath);\n    const hasMarkdownFrontmatter = Boolean(frontmatter.markdown);\n    const isMdRule = isMarkdownRule(filename);\n\n    await logger.logOutput({\n      filename,\n      hasMarkdownFrontmatter,\n      isMdRule,\n    });\n\n    // Case 1: Has markdown frontmatter but doesn't apply to .md files\n    if (hasMarkdownFrontmatter && !isMdRule) {\n      const warningMessage =\n        `⚠️  Rule file \"${filename}\" contains markdown-specific frontmatter but doesn't appear to target .md files.\\n\\n` +\n        `The \\`markdown:\\` frontmatter is designed for validating markdown file structure (headings and metadata).\\n` +\n        `This rule's filename suggests it targets non-markdown files.\\n\\n` +\n        `Consider:\\n` +\n        `- Removing the \\`markdown:\\` frontmatter if this rule doesn't apply to .md files\\n` +\n        `- Renaming the rule to include \".md\" if it does target markdown files (e.g., \"*.md.md\")`;\n\n      await logger.logOutput({ warning: warningMessage });\n\n      return {\n        systemMessage: warningMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Case 2: Applies to .md files but doesn't have markdown frontmatter\n    if (isMdRule && !hasMarkdownFrontmatter) {\n      const encouragementMessage =\n        `💡 Rule file \"${filename}\" appears to target markdown files but doesn't have \\`markdown:\\` frontmatter.\\n\\n` +\n        `You can add markdown validation by including a \\`markdown:\\` section in the frontmatter:\\n\\n` +\n        `\\`\\`\\`yaml\\n` +\n        `---\\n` +\n        `markdown:\\n` +\n        `  headings:\\n` +\n        `    allowed: [\"#*\", \"##*\", \"###*\"]  # Allow h1, h2, h3\\n` +\n        `    required: [\"# *\"]               # Require title heading\\n` +\n        `  frontmatter:\\n` +\n        `    allowed: [\"*\"]                  # Allow any frontmatter fields\\n` +\n        `    required: [\"title\"]             # Require title field\\n` +\n        `---\\n` +\n        `\\`\\`\\`\\n\\n` +\n        `This enables automatic validation of markdown structure and frontmatter fields.`;\n\n      await logger.logOutput({ encouragement: encouragementMessage });\n\n      return {\n        systemMessage: encouragementMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // All good - either has appropriate frontmatter or doesn't need guidance\n    await logger.logOutput({ status: 'valid' });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation\n    return {\n      systemMessage: `Rules file validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui/SKILL.md": "---\nname: AI SDK UI\ndescription: This skill should be used when the user asks to \"add AI chat\", \"implement streaming UI\", \"use useChat hook\", \"add AI completion\", \"implement useCompletion\", \"create conversational interface\", \"add streaming text\", \"implement tool calling UI\", \"create generative UI\", \"add AI-powered features\", \"implement StreamableUI\", or mentions AI SDK, streaming responses, chat interfaces, or AI-generated content in React/Next.js applications.\nversion: 0.1.0\n---\n\n# AI SDK UI Development\n\n## Purpose\n\nImplement AI-powered user interfaces with the Vercel AI SDK. This skill covers streaming UI patterns, conversational interfaces, completion features, tool calling with visual feedback, and generative UI using React Server Components.\n\n**When to use:**\n- Adding chat interfaces or conversational features\n- Implementing streaming text/content display\n- Building AI completion features (autocomplete, suggestions)\n- Creating tool calling UIs with visual feedback\n- Implementing generative UI with Server Components\n\n## Core Concepts\n\n### Client-Side Hooks\n\nThe AI SDK provides React hooks for client-side AI interactions:\n\n**useChat** - Conversational interfaces with message history:\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\n\nexport function ChatInterface() {\n  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({\n    api: '/api/chat',\n  });\n\n  return (\n    <div className=\"flex flex-col h-full\">\n      <div className=\"flex-1 overflow-y-auto p-4 space-y-4\">\n        {messages.map((message) => (\n          <div\n            key={message.id}\n            className={message.role === 'user' ? 'text-right' : 'text-left'}\n          >\n            <div className={`inline-block p-3 rounded-lg ${\n              message.role === 'user'\n                ? 'bg-blue-500 text-white'\n                : 'bg-gray-100 text-gray-900'\n            }`}>\n              {message.content}\n            </div>\n          </div>\n        ))}\n      </div>\n\n      <form onSubmit={handleSubmit} className=\"p-4 border-t\">\n        <div className=\"flex gap-2\">\n          <input\n            value={input}\n            onChange={handleInputChange}\n            placeholder=\"Type a message...\"\n            className=\"flex-1 p-2 border rounded\"\n            disabled={isLoading}\n          />\n          <button\n            type=\"submit\"\n            disabled={isLoading}\n            className=\"px-4 py-2 bg-blue-500 text-white rounded disabled:opacity-50\"\n          >\n            {isLoading ? 'Sending...' : 'Send'}\n          </button>\n        </div>\n      </form>\n    </div>\n  );\n}\n```\n\n**useCompletion** - Single completions without message history:\n```typescript\n'use client';\n\nimport { useCompletion } from 'ai/react';\n\nexport function CompletionInput() {\n  const { completion, input, handleInputChange, handleSubmit, isLoading } = useCompletion({\n    api: '/api/completion',\n  });\n\n  return (\n    <div className=\"space-y-4\">\n      <form onSubmit={handleSubmit}>\n        <textarea\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Enter prompt...\"\n          className=\"w-full p-3 border rounded\"\n          rows={4}\n        />\n        <button\n          type=\"submit\"\n          disabled={isLoading}\n          className=\"mt-2 px-4 py-2 bg-green-500 text-white rounded\"\n        >\n          {isLoading ? 'Generating...' : 'Generate'}\n        </button>\n      </form>\n\n      {completion && (\n        <div className=\"p-4 bg-gray-50 rounded\">\n          <h3 className=\"font-semibold mb-2\">Result:</h3>\n          <p className=\"whitespace-pre-wrap\">{completion}</p>\n        </div>\n      )}\n    </div>\n  );\n}\n```\n\n### Server-Side API Routes\n\nCreate API routes that stream responses:\n\n**Chat API Route** (`app/api/chat/route.ts`):\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages,\n    system: 'You are a helpful assistant.',\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n**Completion API Route** (`app/api/completion/route.ts`):\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nexport async function POST(req: Request) {\n  const { prompt } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    prompt,\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n### Streaming UI Patterns\n\n**Token-by-token streaming display:**\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\n\nexport function StreamingChat() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat();\n\n  return (\n    <div>\n      {messages.map((message) => (\n        <div key={message.id}>\n          <strong>{message.role}:</strong>\n          {/* Content streams in token-by-token */}\n          <span className=\"animate-pulse\">{message.content}</span>\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n**Loading states and indicators:**\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\n\nexport function ChatWithLoadingStates() {\n  const { messages, input, handleInputChange, handleSubmit, isLoading, error } = useChat();\n\n  return (\n    <div>\n      {messages.map((message) => (\n        <div key={message.id}>{message.content}</div>\n      ))}\n\n      {isLoading && (\n        <div className=\"flex items-center gap-2 text-gray-500\">\n          <div className=\"animate-spin h-4 w-4 border-2 border-gray-300 border-t-blue-500 rounded-full\" />\n          <span>AI is thinking...</span>\n        </div>\n      )}\n\n      {error && (\n        <div className=\"text-red-500 p-2 bg-red-50 rounded\">\n          Error: {error.message}\n        </div>\n      )}\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          disabled={isLoading}\n        />\n        <button type=\"submit\" disabled={isLoading}>\n          Send\n        </button>\n      </form>\n    </div>\n  );\n}\n```\n\n### Tool Calling UI\n\nImplement tools that Claude can call with visual feedback:\n\n**Server-side tool definition:**\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText, tool } from 'ai';\nimport { z } from 'zod';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages,\n    tools: {\n      getWeather: tool({\n        description: 'Get current weather for a location',\n        parameters: z.object({\n          location: z.string().describe('City name'),\n        }),\n        execute: async ({ location }) => {\n          // Fetch weather data\n          return { temperature: 72, condition: 'sunny', location };\n        },\n      }),\n      searchProducts: tool({\n        description: 'Search for products',\n        parameters: z.object({\n          query: z.string(),\n          maxResults: z.number().optional().default(5),\n        }),\n        execute: async ({ query, maxResults }) => {\n          // Search products\n          return { results: [], query, count: 0 };\n        },\n      }),\n    },\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n**Client-side tool result rendering:**\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\n\nfunction WeatherCard({ data }: { data: { temperature: number; condition: string; location: string } }) {\n  return (\n    <div className=\"p-4 bg-blue-50 rounded-lg\">\n      <h3 className=\"font-semibold\">{data.location}</h3>\n      <p className=\"text-2xl\">{data.temperature}°F</p>\n      <p className=\"text-gray-600\">{data.condition}</p>\n    </div>\n  );\n}\n\nexport function ChatWithTools() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    maxSteps: 5, // Allow multi-step tool use\n  });\n\n  return (\n    <div>\n      {messages.map((message) => (\n        <div key={message.id}>\n          {message.role === 'assistant' && message.toolInvocations?.map((tool) => (\n            <div key={tool.toolCallId}>\n              {tool.toolName === 'getWeather' && tool.state === 'result' && (\n                <WeatherCard data={tool.result} />\n              )}\n              {tool.state === 'call' && (\n                <div className=\"animate-pulse p-2 bg-gray-100 rounded\">\n                  Calling {tool.toolName}...\n                </div>\n              )}\n            </div>\n          ))}\n          {message.content && <p>{message.content}</p>}\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n### Generative UI with Server Components\n\nUse `streamUI` for server-side streaming of React components:\n\n**Server Action with streamUI:**\n```typescript\n'use server';\n\nimport { openai } from '@ai-sdk/openai';\nimport { streamUI } from 'ai/rsc';\nimport { z } from 'zod';\n\nexport async function generateUI(prompt: string) {\n  const result = await streamUI({\n    model: openai('gpt-4o'),\n    prompt,\n    tools: {\n      showWeather: {\n        description: 'Show weather widget',\n        parameters: z.object({\n          location: z.string(),\n          temperature: z.number(),\n        }),\n        generate: async function* ({ location, temperature }) {\n          yield <div className=\"animate-pulse\">Loading weather...</div>;\n\n          // Simulate API call\n          await new Promise(resolve => setTimeout(resolve, 1000));\n\n          return (\n            <div className=\"p-4 bg-gradient-to-r from-blue-400 to-blue-600 text-white rounded-lg\">\n              <h3 className=\"text-xl font-bold\">{location}</h3>\n              <p className=\"text-3xl\">{temperature}°F</p>\n            </div>\n          );\n        },\n      },\n      showStockChart: {\n        description: 'Show stock price chart',\n        parameters: z.object({\n          symbol: z.string(),\n          price: z.number(),\n        }),\n        generate: async function* ({ symbol, price }) {\n          yield <div>Loading {symbol} data...</div>;\n\n          return (\n            <div className=\"p-4 border rounded-lg\">\n              <h3 className=\"font-bold\">{symbol}</h3>\n              <p className=\"text-2xl text-green-600\">${price}</p>\n            </div>\n          );\n        },\n      },\n    },\n  });\n\n  return result.value;\n}\n```\n\n**Client component consuming streamUI:**\n```typescript\n'use client';\n\nimport { useState } from 'react';\nimport { generateUI } from './actions';\n\nexport function GenerativeUIDemo() {\n  const [ui, setUI] = useState<React.ReactNode>(null);\n  const [prompt, setPrompt] = useState('');\n  const [isLoading, setIsLoading] = useState(false);\n\n  async function handleSubmit(e: React.FormEvent) {\n    e.preventDefault();\n    setIsLoading(true);\n\n    const result = await generateUI(prompt);\n    setUI(result);\n    setIsLoading(false);\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      <form onSubmit={handleSubmit} className=\"flex gap-2\">\n        <input\n          value={prompt}\n          onChange={(e) => setPrompt(e.target.value)}\n          placeholder=\"Ask about weather, stocks...\"\n          className=\"flex-1 p-2 border rounded\"\n        />\n        <button\n          type=\"submit\"\n          disabled={isLoading}\n          className=\"px-4 py-2 bg-purple-500 text-white rounded\"\n        >\n          Generate\n        </button>\n      </form>\n\n      <div className=\"min-h-[200px] p-4 border rounded\">\n        {ui || <p className=\"text-gray-400\">Generated UI will appear here</p>}\n      </div>\n    </div>\n  );\n}\n```\n\n## Workflow\n\n1. **Choose AI pattern**: Determine if use case needs chat (useChat), completion (useCompletion), or generative UI (streamUI)\n2. **Create API route**: Set up server-side streaming endpoint with appropriate model and tools\n3. **Implement client hook**: Use the corresponding React hook with proper configuration\n4. **Add streaming UI**: Display content as it streams with appropriate loading states\n5. **Handle tool calls**: Render tool results with custom components\n6. **Add error handling**: Handle network errors, rate limits, and API failures gracefully\n\n## Best Practices\n\n**Performance:**\n- Use `maxSteps` to limit tool calling depth\n- Implement proper loading states for better UX\n- Consider debouncing user input for completion features\n\n**Error Handling:**\n- Always handle the `error` state from hooks\n- Provide retry mechanisms for failed requests\n- Show user-friendly error messages\n\n**Accessibility:**\n- Announce streaming content to screen readers\n- Provide keyboard navigation for chat interfaces\n- Include proper ARIA labels on interactive elements\n\n**Security:**\n- Validate user input before sending to AI\n- Sanitize AI-generated content before rendering\n- Use rate limiting on API routes\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques:\n- **`references/advanced-patterns.md`** - Multi-modal AI, conversation memory, custom providers\n\n### External Documentation\n\n- **AI SDK Docs**: https://sdk.vercel.ai/docs\n- **useChat Reference**: https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-chat\n- **useCompletion Reference**: https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-completion\n- **streamUI Reference**: https://sdk.vercel.ai/docs/reference/ai-sdk-rsc/stream-ui\n- **Tool Calling**: https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ai-sdk-ui/references/advanced-patterns.md": "# Advanced AI SDK UI Patterns\n\n## Multi-Modal AI (Images and Files)\n\n### Image Input with Vision Models\n\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useState } from 'react';\n\nexport function VisionChat() {\n  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({\n    api: '/api/vision-chat',\n  });\n  const [imageUrl, setImageUrl] = useState('');\n\n  function handleImageSubmit(e: React.FormEvent) {\n    e.preventDefault();\n\n    // Include image in the message\n    handleSubmit(e, {\n      data: {\n        imageUrl,\n      },\n    });\n    setImageUrl('');\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      {messages.map((message) => (\n        <div key={message.id}>\n          <strong>{message.role}:</strong> {message.content}\n          {message.experimental_attachments?.map((attachment, i) => (\n            <img key={i} src={attachment.url} alt=\"Attachment\" className=\"max-w-xs mt-2 rounded\" />\n          ))}\n        </div>\n      ))}\n\n      <form onSubmit={handleImageSubmit} className=\"space-y-2\">\n        <input\n          type=\"url\"\n          value={imageUrl}\n          onChange={(e) => setImageUrl(e.target.value)}\n          placeholder=\"Image URL (optional)\"\n          className=\"w-full p-2 border rounded\"\n        />\n        <div className=\"flex gap-2\">\n          <input\n            value={input}\n            onChange={handleInputChange}\n            placeholder=\"Ask about the image...\"\n            className=\"flex-1 p-2 border rounded\"\n          />\n          <button type=\"submit\" disabled={isLoading} className=\"px-4 py-2 bg-blue-500 text-white rounded\">\n            Send\n          </button>\n        </div>\n      </form>\n    </div>\n  );\n}\n```\n\n**Server route for vision:**\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nexport async function POST(req: Request) {\n  const { messages, data } = await req.json();\n\n  // Add image to the last user message if provided\n  const messagesWithImage = data?.imageUrl\n    ? messages.map((m: any, i: number) =>\n        i === messages.length - 1 && m.role === 'user'\n          ? {\n              ...m,\n              content: [\n                { type: 'text', text: m.content },\n                { type: 'image', image: data.imageUrl },\n              ],\n            }\n          : m\n      )\n    : messages;\n\n  const result = streamText({\n    model: openai('gpt-4o'), // Vision-capable model\n    messages: messagesWithImage,\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n### File Upload with Attachments\n\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useRef } from 'react';\n\nexport function ChatWithFileUpload() {\n  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat();\n  const fileInputRef = useRef<HTMLInputElement>(null);\n\n  async function handleFileSubmit(e: React.FormEvent) {\n    e.preventDefault();\n\n    const files = fileInputRef.current?.files;\n    if (!files?.length) {\n      handleSubmit(e);\n      return;\n    }\n\n    // Convert files to base64\n    const attachments = await Promise.all(\n      Array.from(files).map(async (file) => {\n        const base64 = await fileToBase64(file);\n        return {\n          name: file.name,\n          contentType: file.type,\n          url: base64,\n        };\n      })\n    );\n\n    handleSubmit(e, { experimental_attachments: attachments });\n\n    if (fileInputRef.current) {\n      fileInputRef.current.value = '';\n    }\n  }\n\n  return (\n    <form onSubmit={handleFileSubmit}>\n      <input type=\"file\" ref={fileInputRef} multiple accept=\"image/*,.pdf\" />\n      <input value={input} onChange={handleInputChange} />\n      <button type=\"submit\" disabled={isLoading}>Send</button>\n    </form>\n  );\n}\n\nasync function fileToBase64(file: File): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onload = () => resolve(reader.result as string);\n    reader.onerror = reject;\n    reader.readAsDataURL(file);\n  });\n}\n```\n\n## Conversation Memory and Persistence\n\n### Persisting Chat History with Supabase\n\n```typescript\n// lib/chat-storage.ts\nimport { createClient } from '@supabase/supabase-js';\nimport type { Message } from 'ai';\n\nconst supabase = createClient(\n  process.env.NEXT_PUBLIC_SUPABASE_URL!,\n  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\n);\n\nexport async function saveConversation(\n  conversationId: string,\n  userId: string,\n  messages: Message[]\n) {\n  const { error } = await supabase\n    .from('conversations')\n    .upsert({\n      id: conversationId,\n      user_id: userId,\n      messages: JSON.stringify(messages),\n      updated_at: new Date().toISOString(),\n    });\n\n  if (error) throw error;\n}\n\nexport async function loadConversation(\n  conversationId: string\n): Promise<Message[] | null> {\n  const { data, error } = await supabase\n    .from('conversations')\n    .select('messages')\n    .eq('id', conversationId)\n    .single();\n\n  if (error || !data) return null;\n  return JSON.parse(data.messages);\n}\n\nexport async function listConversations(userId: string) {\n  const { data, error } = await supabase\n    .from('conversations')\n    .select('id, updated_at, messages')\n    .eq('user_id', userId)\n    .order('updated_at', { ascending: false });\n\n  if (error) throw error;\n\n  return data.map((conv) => ({\n    id: conv.id,\n    updatedAt: conv.updated_at,\n    preview: JSON.parse(conv.messages)[0]?.content.slice(0, 50) || 'New conversation',\n  }));\n}\n```\n\n**Chat component with persistence:**\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useEffect } from 'react';\nimport { saveConversation, loadConversation } from '@/lib/chat-storage';\n\nexport function PersistentChat({\n  conversationId,\n  userId,\n}: {\n  conversationId: string;\n  userId: string;\n}) {\n  const { messages, setMessages, input, handleInputChange, handleSubmit } = useChat({\n    id: conversationId,\n    onFinish: async (message) => {\n      // Save after each AI response\n      await saveConversation(conversationId, userId, [...messages, message]);\n    },\n  });\n\n  // Load existing conversation on mount\n  useEffect(() => {\n    async function load() {\n      const saved = await loadConversation(conversationId);\n      if (saved) {\n        setMessages(saved);\n      }\n    }\n    load();\n  }, [conversationId, setMessages]);\n\n  return (\n    <div>\n      {messages.map((m) => (\n        <div key={m.id}>{m.content}</div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n### Conversation Context Window Management\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\n// Trim messages to fit context window\nfunction trimMessages(messages: any[], maxTokens: number = 4000) {\n  const estimatedTokensPerChar = 0.25;\n  let totalTokens = 0;\n  const trimmed = [];\n\n  // Always keep the system message\n  const systemMessage = messages.find(m => m.role === 'system');\n  if (systemMessage) {\n    trimmed.push(systemMessage);\n    totalTokens += systemMessage.content.length * estimatedTokensPerChar;\n  }\n\n  // Add messages from newest to oldest\n  const nonSystemMessages = messages.filter(m => m.role !== 'system').reverse();\n\n  for (const message of nonSystemMessages) {\n    const tokens = message.content.length * estimatedTokensPerChar;\n    if (totalTokens + tokens > maxTokens) break;\n    trimmed.unshift(message);\n    totalTokens += tokens;\n  }\n\n  return trimmed;\n}\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const trimmedMessages = trimMessages(messages, 4000);\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: trimmedMessages,\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n## Custom AI Providers\n\n### Using Multiple Providers\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { anthropic } from '@ai-sdk/anthropic';\nimport { google } from '@ai-sdk/google';\nimport { streamText } from 'ai';\n\nconst providers = {\n  openai: openai('gpt-4o'),\n  claude: anthropic('claude-sonnet-4-20250514'),\n  gemini: google('gemini-1.5-pro'),\n};\n\nexport async function POST(req: Request) {\n  const { messages, provider = 'openai' } = await req.json();\n\n  const model = providers[provider as keyof typeof providers];\n\n  if (!model) {\n    return new Response('Invalid provider', { status: 400 });\n  }\n\n  const result = streamText({\n    model,\n    messages,\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n**Client with provider selection:**\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useState } from 'react';\n\nexport function MultiProviderChat() {\n  const [provider, setProvider] = useState('openai');\n\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    body: { provider },\n  });\n\n  return (\n    <div>\n      <select value={provider} onChange={(e) => setProvider(e.target.value)}>\n        <option value=\"openai\">OpenAI GPT-4</option>\n        <option value=\"claude\">Anthropic Claude</option>\n        <option value=\"gemini\">Google Gemini</option>\n      </select>\n\n      {messages.map((m) => (\n        <div key={m.id}>{m.content}</div>\n      ))}\n\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n### Custom Model Configuration\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nexport async function POST(req: Request) {\n  const { messages, temperature = 0.7, maxTokens = 1000 } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4o', {\n      // Custom configuration\n    }),\n    messages,\n    temperature,\n    maxTokens,\n    // Structured output\n    experimental_output: {\n      type: 'json',\n      schema: {\n        type: 'object',\n        properties: {\n          response: { type: 'string' },\n          confidence: { type: 'number' },\n        },\n      },\n    },\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n## Streaming with Server Actions (RSC)\n\n### createStreamableUI Pattern\n\n```typescript\n'use server';\n\nimport { createStreamableUI } from 'ai/rsc';\nimport { openai } from '@ai-sdk/openai';\nimport { generateText } from 'ai';\n\nexport async function streamingAction(prompt: string) {\n  const ui = createStreamableUI();\n\n  // Start with loading state\n  ui.update(<div className=\"animate-pulse\">Thinking...</div>);\n\n  // Run AI generation asynchronously\n  (async () => {\n    try {\n      const { text } = await generateText({\n        model: openai('gpt-4o'),\n        prompt,\n      });\n\n      // Update with final result\n      ui.done(\n        <div className=\"p-4 bg-green-50 rounded\">\n          <p>{text}</p>\n        </div>\n      );\n    } catch (error) {\n      ui.error(\n        <div className=\"p-4 bg-red-50 text-red-700 rounded\">\n          Error: {String(error)}\n        </div>\n      );\n    }\n  })();\n\n  return ui.value;\n}\n```\n\n### createStreamableValue for Data\n\n```typescript\n'use server';\n\nimport { createStreamableValue } from 'ai/rsc';\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nexport async function streamTextAction(prompt: string) {\n  const stream = createStreamableValue('');\n\n  (async () => {\n    const result = streamText({\n      model: openai('gpt-4o'),\n      prompt,\n    });\n\n    for await (const text of result.textStream) {\n      stream.update(text);\n    }\n\n    stream.done();\n  })();\n\n  return stream.value;\n}\n```\n\n**Client consuming streamable value:**\n```typescript\n'use client';\n\nimport { useStreamableValue } from 'ai/rsc';\nimport { streamTextAction } from './actions';\nimport { useState } from 'react';\n\nexport function StreamableDemo() {\n  const [streamableValue, setStreamableValue] = useState<any>(null);\n  const [value] = useStreamableValue(streamableValue);\n\n  async function handleGenerate() {\n    const result = await streamTextAction('Write a poem about coding');\n    setStreamableValue(result);\n  }\n\n  return (\n    <div>\n      <button onClick={handleGenerate}>Generate</button>\n      {value && <pre className=\"whitespace-pre-wrap\">{value}</pre>}\n    </div>\n  );\n}\n```\n\n## Real-Time Collaboration\n\n### Shared Chat with Supabase Realtime\n\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useEffect } from 'react';\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabase = createClient(\n  process.env.NEXT_PUBLIC_SUPABASE_URL!,\n  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\n);\n\nexport function CollaborativeChat({ roomId }: { roomId: string }) {\n  const { messages, setMessages, input, handleInputChange, handleSubmit, append } = useChat();\n\n  useEffect(() => {\n    // Subscribe to new messages\n    const channel = supabase\n      .channel(`chat:${roomId}`)\n      .on('broadcast', { event: 'message' }, ({ payload }) => {\n        append(payload.message);\n      })\n      .subscribe();\n\n    return () => {\n      supabase.removeChannel(channel);\n    };\n  }, [roomId, append]);\n\n  async function handleCollaborativeSubmit(e: React.FormEvent) {\n    e.preventDefault();\n\n    // Broadcast message to other participants\n    await supabase.channel(`chat:${roomId}`).send({\n      type: 'broadcast',\n      event: 'message',\n      payload: {\n        message: { role: 'user', content: input, id: Date.now().toString() },\n      },\n    });\n\n    handleSubmit(e);\n  }\n\n  return (\n    <div>\n      {messages.map((m) => (\n        <div key={m.id}>{m.content}</div>\n      ))}\n      <form onSubmit={handleCollaborativeSubmit}>\n        <input value={input} onChange={handleInputChange} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n## Rate Limiting and Error Handling\n\n### Client-Side Rate Limiting\n\n```typescript\n'use client';\n\nimport { useChat } from 'ai/react';\nimport { useState, useCallback } from 'react';\n\nexport function RateLimitedChat() {\n  const [rateLimited, setRateLimited] = useState(false);\n  const [retryAfter, setRetryAfter] = useState(0);\n\n  const { messages, input, handleInputChange, handleSubmit, isLoading, error } = useChat({\n    onError: (error) => {\n      if (error.message.includes('429')) {\n        setRateLimited(true);\n        // Extract retry-after from error if available\n        setRetryAfter(60);\n\n        setTimeout(() => {\n          setRateLimited(false);\n          setRetryAfter(0);\n        }, 60000);\n      }\n    },\n  });\n\n  const throttledSubmit = useCallback(\n    (e: React.FormEvent) => {\n      if (rateLimited) {\n        e.preventDefault();\n        return;\n      }\n      handleSubmit(e);\n    },\n    [rateLimited, handleSubmit]\n  );\n\n  return (\n    <div>\n      {rateLimited && (\n        <div className=\"p-4 bg-yellow-50 text-yellow-700 rounded mb-4\">\n          Rate limited. Please wait {retryAfter} seconds before sending another message.\n        </div>\n      )}\n\n      {messages.map((m) => (\n        <div key={m.id}>{m.content}</div>\n      ))}\n\n      <form onSubmit={throttledSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          disabled={rateLimited || isLoading}\n        />\n        <button type=\"submit\" disabled={rateLimited || isLoading}>\n          Send\n        </button>\n      </form>\n    </div>\n  );\n}\n```\n\n### Retry with Exponential Backoff\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\n\nasync function withRetry<T>(\n  fn: () => Promise<T>,\n  maxRetries: number = 3,\n  baseDelay: number = 1000\n): Promise<T> {\n  let lastError: Error | null = null;\n\n  for (let attempt = 0; attempt < maxRetries; attempt++) {\n    try {\n      return await fn();\n    } catch (error) {\n      lastError = error as Error;\n\n      if (attempt < maxRetries - 1) {\n        const delay = baseDelay * Math.pow(2, attempt);\n        await new Promise(resolve => setTimeout(resolve, delay));\n      }\n    }\n  }\n\n  throw lastError;\n}\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = await withRetry(async () => {\n    return streamText({\n      model: openai('gpt-4o'),\n      messages,\n    });\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n## Structured Output\n\n### JSON Mode with Zod Schema\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { generateObject } from 'ai';\nimport { z } from 'zod';\n\nconst ProductSchema = z.object({\n  name: z.string(),\n  description: z.string(),\n  price: z.number(),\n  features: z.array(z.string()),\n  category: z.enum(['electronics', 'clothing', 'home', 'other']),\n});\n\nexport async function POST(req: Request) {\n  const { prompt } = await req.json();\n\n  const { object } = await generateObject({\n    model: openai('gpt-4o'),\n    schema: ProductSchema,\n    prompt: `Generate a product based on: ${prompt}`,\n  });\n\n  return Response.json(object);\n}\n```\n\n### Streaming Structured Output\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamObject } from 'ai';\nimport { z } from 'zod';\n\nconst AnalysisSchema = z.object({\n  summary: z.string(),\n  sentiment: z.enum(['positive', 'negative', 'neutral']),\n  keyPoints: z.array(z.string()),\n  confidence: z.number().min(0).max(1),\n});\n\nexport async function POST(req: Request) {\n  const { text } = await req.json();\n\n  const result = streamObject({\n    model: openai('gpt-4o'),\n    schema: AnalysisSchema,\n    prompt: `Analyze the following text: ${text}`,\n  });\n\n  return result.toTextStreamResponse();\n}\n```\n\n## Embedding and Semantic Search\n\n### Generate and Store Embeddings\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { embed, embedMany } from 'ai';\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabase = createClient(\n  process.env.SUPABASE_URL!,\n  process.env.SUPABASE_SERVICE_KEY!\n);\n\nexport async function storeDocument(content: string, metadata: Record<string, any>) {\n  const { embedding } = await embed({\n    model: openai.embedding('text-embedding-3-small'),\n    value: content,\n  });\n\n  const { error } = await supabase.from('documents').insert({\n    content,\n    embedding,\n    metadata,\n  });\n\n  if (error) throw error;\n}\n\nexport async function searchDocuments(query: string, limit: number = 5) {\n  const { embedding } = await embed({\n    model: openai.embedding('text-embedding-3-small'),\n    value: query,\n  });\n\n  const { data, error } = await supabase.rpc('match_documents', {\n    query_embedding: embedding,\n    match_threshold: 0.7,\n    match_count: limit,\n  });\n\n  if (error) throw error;\n  return data;\n}\n```\n\n### RAG Chat Implementation\n\n```typescript\nimport { openai } from '@ai-sdk/openai';\nimport { streamText } from 'ai';\nimport { searchDocuments } from '@/lib/embeddings';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  // Get the last user message for context search\n  const lastUserMessage = messages.filter((m: any) => m.role === 'user').pop();\n\n  // Search for relevant documents\n  const relevantDocs = await searchDocuments(lastUserMessage.content);\n\n  // Build context from documents\n  const context = relevantDocs\n    .map((doc: any) => doc.content)\n    .join('\\n\\n');\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    system: `You are a helpful assistant. Use the following context to answer questions:\n\n${context}\n\nIf the context doesn't contain relevant information, say so.`,\n    messages,\n  });\n\n  return result.toDataStreamResponse();\n}\n```\n\n## Testing AI Components\n\n### Mock AI Responses for Testing\n\n```typescript\n// __tests__/chat.test.tsx\nimport { render, screen, fireEvent, waitFor } from '@testing-library/react';\nimport { ChatInterface } from '@/components/ChatInterface';\n\n// Mock the useChat hook\njest.mock('ai/react', () => ({\n  useChat: () => ({\n    messages: [\n      { id: '1', role: 'user', content: 'Hello' },\n      { id: '2', role: 'assistant', content: 'Hi there!' },\n    ],\n    input: '',\n    handleInputChange: jest.fn(),\n    handleSubmit: jest.fn(),\n    isLoading: false,\n    error: null,\n  }),\n}));\n\ndescribe('ChatInterface', () => {\n  it('renders messages', () => {\n    render(<ChatInterface />);\n\n    expect(screen.getByText('Hello')).toBeInTheDocument();\n    expect(screen.getByText('Hi there!')).toBeInTheDocument();\n  });\n\n  it('shows loading state', () => {\n    // Override mock for this test\n    jest.spyOn(require('ai/react'), 'useChat').mockReturnValue({\n      messages: [],\n      input: '',\n      handleInputChange: jest.fn(),\n      handleSubmit: jest.fn(),\n      isLoading: true,\n      error: null,\n    });\n\n    render(<ChatInterface />);\n    expect(screen.getByText(/thinking/i)).toBeInTheDocument();\n  });\n});\n```\n\n### E2E Testing with Playwright\n\n```typescript\n// e2e/chat.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('AI Chat', () => {\n  test('should send message and receive response', async ({ page }) => {\n    await page.goto('/chat');\n\n    // Type and send a message\n    await page.fill('input[placeholder*=\"message\"]', 'What is 2+2?');\n    await page.click('button[type=\"submit\"]');\n\n    // Wait for AI response\n    await expect(page.locator('[data-testid=\"ai-response\"]')).toBeVisible({\n      timeout: 30000,\n    });\n\n    // Verify response contains relevant content\n    const response = await page.locator('[data-testid=\"ai-response\"]').textContent();\n    expect(response).toContain('4');\n  });\n\n  test('should handle streaming correctly', async ({ page }) => {\n    await page.goto('/chat');\n\n    await page.fill('input[placeholder*=\"message\"]', 'Write a short poem');\n    await page.click('button[type=\"submit\"]');\n\n    // Verify streaming indicator appears\n    await expect(page.locator('.animate-pulse')).toBeVisible();\n\n    // Wait for completion\n    await expect(page.locator('.animate-pulse')).not.toBeVisible({\n      timeout: 30000,\n    });\n  });\n});\n```\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/supabase-local-dev/SKILL.md": "---\nname: Supabase Local Development\ndescription: This skill should be used when the user asks to \"start supabase locally\", \"set up local supabase\", \"run supabase dev\", \"initialize supabase project\", \"configure local database\", \"start local postgres\", \"use supabase CLI\", \"generate database types\", or needs guidance on local Supabase development, Docker setup, environment configuration, or database migrations.\nversion: 0.1.0\n---\n\n# Supabase Local Development\n\n## Overview\n\nSupabase Local Development provides a complete local Postgres database with all Supabase services (Auth, Storage, Edge Functions, Realtime) running in Docker containers. This enables offline development, faster iteration, and safe database migrations before deploying to production.\n\n**Key benefits:**\n- Full Supabase stack running locally\n- Faster development without network latency\n- Safe migration testing before production\n- Automatic TypeScript type generation\n- Environment variable management\n\n## Skill-scoped Context\n\n**Official Documentation:**\n- Local Development Guide: https://supabase.com/docs/guides/local-development\n- CLI Getting Started: https://supabase.com/docs/guides/local-development/cli/getting-started\n- supabase init: https://supabase.com/docs/reference/cli/supabase-init\n- supabase start: https://supabase.com/docs/reference/cli/supabase-start\n- supabase status: https://supabase.com/docs/reference/cli/supabase-status\n- supabase db: https://supabase.com/docs/reference/cli/supabase-db\n- Managing Environments: https://supabase.com/docs/guides/deployment/managing-environments\n\n## Prerequisites\n\n### Docker Runtime\n\nSupabase local development requires a Docker-compatible container runtime:\n\n- **Docker Desktop** (macOS, Windows, Linux)\n- **Rancher Desktop** (macOS, Windows, Linux)\n- **OrbStack** (macOS) - Recommended for Apple Silicon\n- **Podman** (macOS, Windows, Linux)\n\nVerify Docker is running:\n```bash\ndocker info\n```\n\n### Supabase CLI\n\nInstall via npm (recommended for Next.js projects):\n```bash\nnpm install -g supabase\n```\n\nOr via Homebrew (macOS):\n```bash\nbrew install supabase/tap/supabase\n```\n\nVerify installation:\n```bash\nsupabase --version\n```\n\n## Workflow\n\n### Step 1: Initialize Supabase Project\n\n```bash\nsupabase init\n```\n\nThis creates a `supabase/` directory with:\n- `config.toml` - Local configuration\n- `seed.sql` - Optional seed data\n- `migrations/` - Database migrations\n\n### Step 2: Start Local Services\n\n```bash\nsupabase start\n```\n\nFirst run downloads Docker images (~2GB). Subsequent starts are faster.\n\nServices started:\n| Service | Local URL | Purpose |\n|---------|-----------|---------|\n| API | http://127.0.0.1:54321 | REST/GraphQL API |\n| Studio | http://127.0.0.1:54323 | Database UI |\n| Inbucket | http://127.0.0.1:54324 | Email testing |\n| Database | postgresql://127.0.0.1:54322 | Direct Postgres |\n\n### Step 3: Get Environment Variables\n\n```bash\nsupabase status -o env\n```\n\nOutput:\n```\nSUPABASE_URL=http://127.0.0.1:54321\nSUPABASE_ANON_KEY=eyJ...\nSUPABASE_SERVICE_ROLE_KEY=eyJ...\nSUPABASE_DB_URL=postgresql://postgres:postgres@127.0.0.1:54322/postgres\n```\n\n### Step 4: Configure Next.js Environment\n\nAdd to `.env.local`:\n```bash\n# Supabase Local Development\nNEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321\nNEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...\nSUPABASE_SERVICE_ROLE_KEY=eyJ...\n```\n\n**Note:** `NEXT_PUBLIC_` prefix exposes variables to the browser.\n\n### Step 5: Generate TypeScript Types\n\n```bash\nsupabase gen types typescript --local > lib/supabase/database.types.ts\n```\n\nRegenerate after schema changes.\n\n## Environment Variables\n\n### Client-Side (Browser)\n\nPrefix with `NEXT_PUBLIC_`:\n```\nNEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321\nNEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...\n```\n\n### Server-Side Only\n\nNo prefix required:\n```\nSUPABASE_SERVICE_ROLE_KEY=eyJ...\nSUPABASE_DB_URL=postgresql://...\n```\n\n### Environment File Detection\n\n| Framework | File | Priority |\n|-----------|------|----------|\n| Next.js | `.env.local` | 1st |\n| Next.js | `.env.development.local` | 2nd |\n| Generic | `.env` | 3rd |\n| Cloudflare Workers | `dev.vars` | Special |\n\n## Database Migrations\n\n### Create Migration from Local Changes\n\n```bash\nsupabase db diff -f migration_name\n```\n\n### Apply Migrations Locally\n\n```bash\nsupabase db reset\n```\n\n### Push to Remote Database\n\n```bash\nsupabase db push\n```\n\n### Link to Remote Project\n\n```bash\nsupabase link --project-ref YOUR_PROJECT_REF\n```\n\n## Type Generation\n\n### From Local Database\n\n```bash\nsupabase gen types typescript --local > lib/supabase/database.types.ts\n```\n\n### From Remote Database\n\n```bash\nsupabase gen types typescript --project-id YOUR_PROJECT_ID > lib/supabase/database.types.ts\n```\n\n### Usage in Code\n\n```typescript\nimport { createClient } from \"@supabase/supabase-js\";\nimport type { Database } from \"@/lib/supabase/database.types\";\n\nconst supabase = createClient<Database>(\n  process.env.NEXT_PUBLIC_SUPABASE_URL!,\n  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\n);\n```\n\n## Common Commands Reference\n\n| Command | Purpose |\n|---------|---------|\n| `supabase init` | Initialize new project |\n| `supabase start` | Start local services |\n| `supabase stop` | Stop local services |\n| `supabase status` | Show service status |\n| `supabase status -o env` | Output as environment variables |\n| `supabase db reset` | Reset database and apply migrations |\n| `supabase db diff -f name` | Create migration from changes |\n| `supabase db push` | Push migrations to remote |\n| `supabase gen types typescript --local` | Generate types from local |\n| `supabase link --project-ref REF` | Link to remote project |\n\n## Troubleshooting\n\n### Docker Not Running\n\n```bash\n# macOS - Start Docker Desktop\nopen -a Docker\n\n# Linux - Start Docker daemon\nsudo systemctl start docker\n```\n\n### Port Conflicts\n\nIf ports are in use:\n```bash\nsupabase stop --no-backup\nsupabase start\n```\n\nOr configure different ports in `supabase/config.toml`.\n\n### Reset Everything\n\n```bash\nsupabase stop --no-backup\nsupabase start\nsupabase db reset\n```\n\n## Best Practices\n\n**DO:**\n- Always use `supabase db diff` for migrations\n- Regenerate types after schema changes\n- Use `.env.local` for local credentials (gitignored)\n- Test migrations locally before pushing to production\n\n**DON'T:**\n- Commit local Supabase credentials\n- Modify production database directly\n- Skip local testing for migrations\n- Use service role key in client-side code\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-design/SKILL.md": "---\nname: UI Design\ndescription: This skill should be used when the user asks to \"create a component\", \"build static UI\", \"design with TypeScript\", \"use compound components\", \"implement contract-first UI\", \"create React component\", \"build with Shadcn\", or mentions TypeScript interfaces for components, compound component patterns, or Server Components. Provides contract-first static UI methodology with compound components.\nversion: 0.1.0\n---\n\n# UI Design\n\nContract-first static UI methodology using TypeScript interfaces and compound components.\n\n## Purpose\n\nUI Design is the second step in the UI development workflow, following wireframing. Define TypeScript interfaces first (the \"contract\"), then implement compound components with Tailwind CSS styling. Server Components are the default.\n\n## When to Use\n\n- After wireframes are approved (WIREFRAME.md exists)\n- When implementing new UI components\n- When creating reusable component libraries\n- When defining component APIs with TypeScript\n\n## Core Principles\n\n### Contract-First Development\n\nDefine TypeScript interfaces before implementation:\n\n```typescript\n// 1. Define the contract first\ninterface FeatureCardProps {\n  title: string;\n  description: string;\n  icon: IconName;\n  href?: string;\n}\n\n// 2. Then implement the component\nfunction FeatureCard({ title, description, icon, href }: FeatureCardProps) {\n  // Implementation\n}\n```\n\n### Server Components by Default\n\nAll components are React Server Components unless they need:\n- Event handlers (onClick, onChange)\n- Browser APIs (localStorage, window)\n- React hooks (useState, useEffect)\n\n```typescript\n// Server Component (default) - no \"use client\" directive\nexport function FeatureCard({ title, description }: FeatureCardProps) {\n  return (\n    <article className=\"rounded-lg border p-6\">\n      <h3 className=\"text-lg font-semibold\">{title}</h3>\n      <p className=\"text-muted-foreground\">{description}</p>\n    </article>\n  );\n}\n```\n\n### Compound Component Pattern\n\nStructure complex components with composable parts:\n\n```typescript\n// Root component provides context\nfunction Card({ children, className }: CardProps) {\n  return (\n    <div className={cn(\"rounded-lg border bg-card\", className)}>\n      {children}\n    </div>\n  );\n}\n\n// Sub-components for each section\nfunction CardHeader({ children, className }: CardHeaderProps) {\n  return (\n    <div className={cn(\"flex flex-col space-y-1.5 p-6\", className)}>\n      {children}\n    </div>\n  );\n}\n\nfunction CardTitle({ children, className }: CardTitleProps) {\n  return (\n    <h3 className={cn(\"text-2xl font-semibold\", className)}>\n      {children}\n    </h3>\n  );\n}\n\nfunction CardContent({ children, className }: CardContentProps) {\n  return (\n    <div className={cn(\"p-6 pt-0\", className)}>\n      {children}\n    </div>\n  );\n}\n\nfunction CardFooter({ children, className }: CardFooterProps) {\n  return (\n    <div className={cn(\"flex items-center p-6 pt-0\", className)}>\n      {children}\n    </div>\n  );\n}\n\n// Export compound component\nexport { Card, CardHeader, CardTitle, CardContent, CardFooter };\n```\n\n## UI Design Workflow\n\n### Step 1: Define TypeScript Interfaces\n\nStart with the component contract:\n\n```typescript\n// types.ts\nimport type { ReactNode } from 'react';\n\nexport interface CardProps {\n  children: ReactNode;\n  className?: string;\n  variant?: 'default' | 'outlined' | 'elevated';\n}\n\nexport interface CardHeaderProps {\n  children: ReactNode;\n  className?: string;\n}\n\nexport interface CardTitleProps {\n  children: ReactNode;\n  className?: string;\n  as?: 'h1' | 'h2' | 'h3' | 'h4';\n}\n\nexport interface CardDescriptionProps {\n  children: ReactNode;\n  className?: string;\n}\n\nexport interface CardContentProps {\n  children: ReactNode;\n  className?: string;\n}\n\nexport interface CardFooterProps {\n  children: ReactNode;\n  className?: string;\n  align?: 'start' | 'center' | 'end' | 'between';\n}\n```\n\n### Step 2: Create Compound Components\n\nImplement each part of the compound component:\n\n```typescript\n// card.tsx\nimport { cn } from '@/lib/utils';\nimport type {\n  CardProps,\n  CardHeaderProps,\n  CardTitleProps,\n  CardDescriptionProps,\n  CardContentProps,\n  CardFooterProps,\n} from './types';\n\nconst variantStyles = {\n  default: 'bg-card text-card-foreground',\n  outlined: 'border-2 bg-transparent',\n  elevated: 'bg-card shadow-lg',\n} as const;\n\nexport function Card({ children, className, variant = 'default' }: CardProps) {\n  return (\n    <div\n      className={cn(\n        'rounded-lg border',\n        variantStyles[variant],\n        className\n      )}\n    >\n      {children}\n    </div>\n  );\n}\n\nexport function CardHeader({ children, className }: CardHeaderProps) {\n  return (\n    <div className={cn('flex flex-col space-y-1.5 p-6', className)}>\n      {children}\n    </div>\n  );\n}\n\nexport function CardTitle({\n  children,\n  className,\n  as: Tag = 'h3',\n}: CardTitleProps) {\n  return (\n    <Tag className={cn('text-2xl font-semibold leading-none tracking-tight', className)}>\n      {children}\n    </Tag>\n  );\n}\n\nexport function CardDescription({ children, className }: CardDescriptionProps) {\n  return (\n    <p className={cn('text-sm text-muted-foreground', className)}>\n      {children}\n    </p>\n  );\n}\n\nexport function CardContent({ children, className }: CardContentProps) {\n  return (\n    <div className={cn('p-6 pt-0', className)}>\n      {children}\n    </div>\n  );\n}\n\nconst alignStyles = {\n  start: 'justify-start',\n  center: 'justify-center',\n  end: 'justify-end',\n  between: 'justify-between',\n} as const;\n\nexport function CardFooter({\n  children,\n  className,\n  align = 'start',\n}: CardFooterProps) {\n  return (\n    <div className={cn('flex items-center p-6 pt-0', alignStyles[align], className)}>\n      {children}\n    </div>\n  );\n}\n```\n\n### Step 3: Create Barrel Export\n\nOrganize exports in index.ts:\n\n```typescript\n// index.ts\nexport {\n  Card,\n  CardHeader,\n  CardTitle,\n  CardDescription,\n  CardContent,\n  CardFooter,\n} from './card';\n\nexport type {\n  CardProps,\n  CardHeaderProps,\n  CardTitleProps,\n  CardDescriptionProps,\n  CardContentProps,\n  CardFooterProps,\n} from './types';\n```\n\n### Step 4: Style with Tailwind CSS\n\nApply mobile-first responsive styling:\n\n```typescript\nexport function FeatureGrid({ features }: FeatureGridProps) {\n  return (\n    <div className={cn(\n      // Mobile: single column\n      'grid grid-cols-1 gap-4',\n      // Tablet: two columns\n      'md:grid-cols-2 md:gap-6',\n      // Desktop: three columns\n      'lg:grid-cols-3 lg:gap-8'\n    )}>\n      {features.map((feature) => (\n        <Card key={feature.id}>\n          <CardHeader>\n            <CardTitle>{feature.title}</CardTitle>\n            <CardDescription>{feature.description}</CardDescription>\n          </CardHeader>\n        </Card>\n      ))}\n    </div>\n  );\n}\n```\n\n## Component Library Integration\n\n### Shadcn UI\n\nInstall and use Shadcn components as the foundation:\n\n```bash\nnpx shadcn@latest add button card input\n```\n\nReference: https://ui.shadcn.com/docs/components\n\nExtend Shadcn components when needed:\n\n```typescript\nimport { Button } from '@/components/ui/button';\nimport { cn } from '@/lib/utils';\n\ninterface LoadingButtonProps extends React.ComponentProps<typeof Button> {\n  loading?: boolean;\n}\n\nexport function LoadingButton({\n  loading,\n  children,\n  disabled,\n  className,\n  ...props\n}: LoadingButtonProps) {\n  return (\n    <Button\n      disabled={disabled || loading}\n      className={cn(loading && 'cursor-wait', className)}\n      {...props}\n    >\n      {loading ? <Spinner className=\"mr-2 h-4 w-4\" /> : null}\n      {children}\n    </Button>\n  );\n}\n```\n\n### Radix Primitives\n\nUse Radix for accessible, unstyled primitives:\n\n```typescript\nimport * as Dialog from '@radix-ui/react-dialog';\n\nexport function Modal({ open, onOpenChange, children }: ModalProps) {\n  return (\n    <Dialog.Root open={open} onOpenChange={onOpenChange}>\n      <Dialog.Portal>\n        <Dialog.Overlay className=\"fixed inset-0 bg-black/50\" />\n        <Dialog.Content className=\"fixed left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 rounded-lg bg-white p-6\">\n          {children}\n        </Dialog.Content>\n      </Dialog.Portal>\n    </Dialog.Root>\n  );\n}\n```\n\nReference: https://www.radix-ui.com/primitives/docs/overview/introduction\n\n### AI Elements\n\nUse AI Elements for AI-specific UI patterns:\n\n```typescript\nimport { Chat, Message, MessageInput } from '@ai-elements/react';\n\nexport function ChatInterface({ messages, onSend }: ChatInterfaceProps) {\n  return (\n    <Chat>\n      {messages.map((msg) => (\n        <Message key={msg.id} role={msg.role}>\n          {msg.content}\n        </Message>\n      ))}\n      <MessageInput onSubmit={onSend} />\n    </Chat>\n  );\n}\n```\n\n## File Structure\n\nOrganize component files consistently:\n\n```\ncomponents/\n└── feature-card/\n    ├── index.ts           # Barrel exports\n    ├── types.ts           # TypeScript interfaces\n    ├── feature-card.tsx   # Main component\n    ├── feature-card.test.tsx  # Tests\n    └── WIREFRAME.md       # Layout documentation\n```\n\nFor compound components:\n\n```\ncomponents/\n└── card/\n    ├── index.ts           # Exports all parts\n    ├── types.ts           # All interfaces\n    ├── card.tsx           # Root component\n    ├── card-header.tsx    # Sub-component\n    ├── card-content.tsx   # Sub-component\n    ├── card-footer.tsx    # Sub-component\n    └── card.test.tsx      # Tests\n```\n\n## Usage Patterns\n\n### Composition over Configuration\n\nPrefer composable components over prop-heavy ones:\n\n```typescript\n// Avoid: Too many props\n<Card\n  title=\"Feature\"\n  description=\"Description\"\n  footer={<Button>Action</Button>}\n  headerIcon={<Icon />}\n/>\n\n// Prefer: Composable structure\n<Card>\n  <CardHeader>\n    <Icon />\n    <CardTitle>Feature</CardTitle>\n    <CardDescription>Description</CardDescription>\n  </CardHeader>\n  <CardFooter>\n    <Button>Action</Button>\n  </CardFooter>\n</Card>\n```\n\n### Variant Props with Type Safety\n\nUse discriminated unions for variants:\n\n```typescript\ntype ButtonVariant = 'primary' | 'secondary' | 'ghost' | 'destructive';\ntype ButtonSize = 'sm' | 'md' | 'lg';\n\ninterface ButtonProps {\n  variant?: ButtonVariant;\n  size?: ButtonSize;\n  children: ReactNode;\n}\n\nconst variantStyles: Record<ButtonVariant, string> = {\n  primary: 'bg-primary text-primary-foreground hover:bg-primary/90',\n  secondary: 'bg-secondary text-secondary-foreground hover:bg-secondary/80',\n  ghost: 'hover:bg-accent hover:text-accent-foreground',\n  destructive: 'bg-destructive text-destructive-foreground hover:bg-destructive/90',\n};\n\nconst sizeStyles: Record<ButtonSize, string> = {\n  sm: 'h-8 px-3 text-xs',\n  md: 'h-10 px-4 text-sm',\n  lg: 'h-12 px-6 text-base',\n};\n```\n\n### Forwarding Refs\n\nSupport ref forwarding for DOM access:\n\n```typescript\nimport { forwardRef } from 'react';\n\nexport const Input = forwardRef<HTMLInputElement, InputProps>(\n  ({ className, type, ...props }, ref) => {\n    return (\n      <input\n        type={type}\n        className={cn(\n          'flex h-10 w-full rounded-md border bg-background px-3 py-2',\n          className\n        )}\n        ref={ref}\n        {...props}\n      />\n    );\n  }\n);\nInput.displayName = 'Input';\n```\n\n## Best Practices\n\n### TypeScript Guidelines\n\n1. **Export types separately** - Allow importing types without implementation\n2. **Use strict types** - Avoid `any`, prefer `unknown` for generic inputs\n3. **Document props with JSDoc** - Add descriptions for complex props\n4. **Use const assertions** - For style mappings and variants\n\n### Styling Guidelines\n\n1. **Mobile-first** - Start with base styles, add responsive overrides\n2. **Use design tokens** - Reference theme variables, not hardcoded values\n3. **Consistent spacing** - Use Tailwind's spacing scale\n4. **Semantic colors** - Use `text-foreground`, `bg-background`, not raw colors\n\n### Component Guidelines\n\n1. **Single responsibility** - Each component does one thing well\n2. **Accessible by default** - Include ARIA attributes, keyboard support\n3. **Composable** - Prefer children over render props\n4. **Testable** - Export types and utilities for testing\n\n## Review Checklist\n\nBefore proceeding to interaction implementation:\n\n- [ ] TypeScript interfaces defined and exported\n- [ ] Compound component structure implemented\n- [ ] All variants and sizes typed\n- [ ] Mobile-first responsive styles applied\n- [ ] Shadcn/Radix primitives used where appropriate\n- [ ] Barrel exports in index.ts\n- [ ] Accessibility attributes included\n- [ ] Component matches WIREFRAME.md layout\n\n## Next Steps\n\nAfter static UI is complete, proceed to the **ui-interaction** skill for adding client-side events, local state, and form validation.\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-integration/SKILL.md": "---\nname: UI Integration\ndescription: This skill should be used when the user asks to \"add server action\", \"implement Supabase query\", \"connect to backend\", \"add database integration\", \"implement RLS\", \"use server actions\", \"add data mutation\", \"implement CRUD operations\", \"revalidate path\", \"add authentication check\", or needs guidance on server-side integration, defense-in-depth security, or type-safe database queries with Supabase.\nversion: 0.1.0\n---\n\n# UI Integration for Next.js with Supabase\n\n## Overview\n\nUI Integration handles the server-side integration layer of Next.js applications with Supabase backends. This skill covers implementing Server Actions, writing type-safe Supabase queries, enforcing RLS policies with explicit auth checks, and properly revalidating data after mutations.\n\n**Key principles:**\n- Defense-in-depth: Always combine RLS policies with explicit auth checks\n- Use \"use server\" for all server actions\n- Revalidate paths after mutations for fresh data\n- Generate and use TypeScript types for database queries\n- Handle errors gracefully with proper error boundaries\n\n## Skill-scoped Context\n\n**Official Documentation:**\n- Next.js Server Actions: https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations\n- Supabase JavaScript Client: https://supabase.com/docs/reference/javascript/introduction\n- Supabase Row Level Security: https://supabase.com/docs/guides/auth/row-level-security\n- Next.js Revalidation: https://nextjs.org/docs/app/building-your-application/caching#revalidatepath\n\n## Workflow\n\n### Step 1: Define Server Actions\n\nCreate server actions in dedicated files or inline with \"use server\":\n\n```tsx\n// app/actions/posts.ts\n\"use server\";\n\nimport { createClient } from \"@/lib/supabase/server\";\nimport { revalidatePath } from \"next/cache\";\nimport { z } from \"zod\";\n\nconst createPostSchema = z.object({\n  title: z.string().min(1).max(200),\n  content: z.string().min(1),\n});\n\nexport async function createPost(formData: FormData) {\n  const supabase = await createClient();\n\n  // Explicit auth check (defense-in-depth)\n  const { data: { user }, error: authError } = await supabase.auth.getUser();\n  if (authError || !user) {\n    return { error: \"Unauthorized\" };\n  }\n\n  // Validate input\n  const rawData = {\n    title: formData.get(\"title\"),\n    content: formData.get(\"content\"),\n  };\n\n  const parsed = createPostSchema.safeParse(rawData);\n  if (!parsed.success) {\n    return { error: parsed.error.flatten().fieldErrors };\n  }\n\n  // Insert with user_id (RLS will also enforce this)\n  const { data, error } = await supabase\n    .from(\"posts\")\n    .insert({\n      title: parsed.data.title,\n      content: parsed.data.content,\n      user_id: user.id,\n    })\n    .select()\n    .single();\n\n  if (error) {\n    return { error: error.message };\n  }\n\n  revalidatePath(\"/posts\");\n  return { data };\n}\n```\n\n### Step 2: Implement Supabase Queries\n\nWrite type-safe queries using generated types:\n\n```tsx\n// lib/supabase/queries.ts\nimport { createClient } from \"@/lib/supabase/server\";\nimport type { Database } from \"@/lib/supabase/database.types\";\n\ntype Post = Database[\"public\"][\"Tables\"][\"posts\"][\"Row\"];\n\nexport async function getPosts(): Promise<Post[]> {\n  const supabase = await createClient();\n\n  const { data, error } = await supabase\n    .from(\"posts\")\n    .select(\"*\")\n    .order(\"created_at\", { ascending: false });\n\n  if (error) {\n    console.error(\"Error fetching posts:\", error);\n    return [];\n  }\n\n  return data;\n}\n\nexport async function getPostById(id: string): Promise<Post | null> {\n  const supabase = await createClient();\n\n  const { data, error } = await supabase\n    .from(\"posts\")\n    .select(\"*\")\n    .eq(\"id\", id)\n    .single();\n\n  if (error) {\n    console.error(\"Error fetching post:\", error);\n    return null;\n  }\n\n  return data;\n}\n```\n\n### Step 3: Add Error Handling\n\nImplement proper error handling in server actions:\n\n```tsx\n\"use server\";\n\nimport { createClient } from \"@/lib/supabase/server\";\nimport { revalidatePath } from \"next/cache\";\n\nexport type ActionResult<T> =\n  | { success: true; data: T }\n  | { success: false; error: string };\n\nexport async function deletePost(postId: string): Promise<ActionResult<void>> {\n  const supabase = await createClient();\n\n  // Auth check\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) {\n    return { success: false, error: \"You must be logged in to delete posts\" };\n  }\n\n  // Verify ownership before delete (explicit check + RLS)\n  const { data: post } = await supabase\n    .from(\"posts\")\n    .select(\"user_id\")\n    .eq(\"id\", postId)\n    .single();\n\n  if (!post || post.user_id !== user.id) {\n    return { success: false, error: \"You can only delete your own posts\" };\n  }\n\n  const { error } = await supabase\n    .from(\"posts\")\n    .delete()\n    .eq(\"id\", postId);\n\n  if (error) {\n    return { success: false, error: error.message };\n  }\n\n  revalidatePath(\"/posts\");\n  return { success: true, data: undefined };\n}\n```\n\n### Step 4: Connect to UI\n\nConnect server actions to client components:\n\n```tsx\n// app/posts/new/page.tsx\nimport { createPost } from \"@/app/actions/posts\";\nimport { PostForm } from \"@/components/post-form\";\n\nexport default function NewPostPage() {\n  return (\n    <main className=\"container mx-auto py-8\">\n      <h1 className=\"text-2xl font-bold mb-4\">Create New Post</h1>\n      <PostForm action={createPost} />\n    </main>\n  );\n}\n```\n\n```tsx\n// components/post-form.tsx\n\"use client\";\n\nimport { useFormStatus } from \"react-dom\";\nimport { useActionState } from \"react\";\n\nfunction SubmitButton() {\n  const { pending } = useFormStatus();\n  return (\n    <button\n      type=\"submit\"\n      disabled={pending}\n      className=\"bg-blue-600 text-white px-4 py-2 rounded disabled:opacity-50\"\n    >\n      {pending ? \"Creating...\" : \"Create Post\"}\n    </button>\n  );\n}\n\nexport function PostForm({\n  action\n}: {\n  action: (formData: FormData) => Promise<{ error?: string; data?: unknown }>;\n}) {\n  const [state, formAction] = useActionState(action, null);\n\n  return (\n    <form action={formAction} className=\"space-y-4\">\n      {state?.error && (\n        <div className=\"bg-red-100 text-red-700 p-3 rounded\" role=\"alert\">\n          {typeof state.error === \"string\" ? state.error : \"Validation failed\"}\n        </div>\n      )}\n\n      <div>\n        <label htmlFor=\"title\" className=\"block font-medium\">\n          Title\n        </label>\n        <input\n          type=\"text\"\n          id=\"title\"\n          name=\"title\"\n          required\n          className=\"mt-1 block w-full rounded border px-3 py-2\"\n        />\n      </div>\n\n      <div>\n        <label htmlFor=\"content\" className=\"block font-medium\">\n          Content\n        </label>\n        <textarea\n          id=\"content\"\n          name=\"content\"\n          required\n          rows={5}\n          className=\"mt-1 block w-full rounded border px-3 py-2\"\n        />\n      </div>\n\n      <SubmitButton />\n    </form>\n  );\n}\n```\n\n## Defense-in-Depth Security\n\n### RLS Policy + Explicit Auth Check\n\nAlways implement both layers of security:\n\n**1. RLS Policy (Database Level):**\n\n```sql\n-- Enable RLS on table\nALTER TABLE posts ENABLE ROW LEVEL SECURITY;\n\n-- Users can only read their own posts\nCREATE POLICY \"Users can read own posts\"\n  ON posts FOR SELECT\n  USING (auth.uid() = user_id);\n\n-- Users can only insert posts with their user_id\nCREATE POLICY \"Users can create own posts\"\n  ON posts FOR INSERT\n  WITH CHECK (auth.uid() = user_id);\n\n-- Users can only update their own posts\nCREATE POLICY \"Users can update own posts\"\n  ON posts FOR UPDATE\n  USING (auth.uid() = user_id);\n\n-- Users can only delete their own posts\nCREATE POLICY \"Users can delete own posts\"\n  ON posts FOR DELETE\n  USING (auth.uid() = user_id);\n```\n\n**2. Explicit Auth Check (Application Level):**\n\n```tsx\n\"use server\";\n\nimport { createClient } from \"@/lib/supabase/server\";\n\nexport async function updatePost(postId: string, title: string, content: string) {\n  const supabase = await createClient();\n\n  // ALWAYS check auth explicitly - don't rely solely on RLS\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) {\n    return { error: \"Unauthorized\" };\n  }\n\n  // Verify ownership explicitly\n  const { data: existingPost } = await supabase\n    .from(\"posts\")\n    .select(\"user_id\")\n    .eq(\"id\", postId)\n    .single();\n\n  if (!existingPost || existingPost.user_id !== user.id) {\n    return { error: \"Forbidden: You don't own this post\" };\n  }\n\n  // Now perform the update - RLS provides additional protection\n  const { data, error } = await supabase\n    .from(\"posts\")\n    .update({ title, content, updated_at: new Date().toISOString() })\n    .eq(\"id\", postId)\n    .select()\n    .single();\n\n  if (error) {\n    return { error: error.message };\n  }\n\n  return { data };\n}\n```\n\n## Type-Safe Database Queries\n\n### Generate Types\n\nGenerate TypeScript types from your Supabase schema:\n\n```bash\nnpx supabase gen types typescript --project-id YOUR_PROJECT_ID > lib/supabase/database.types.ts\n```\n\n### Use Generated Types\n\n```tsx\nimport { createClient } from \"@/lib/supabase/server\";\nimport type { Database } from \"@/lib/supabase/database.types\";\n\ntype Tables = Database[\"public\"][\"Tables\"];\ntype Post = Tables[\"posts\"][\"Row\"];\ntype PostInsert = Tables[\"posts\"][\"Insert\"];\ntype PostUpdate = Tables[\"posts\"][\"Update\"];\n\nexport async function createPost(post: PostInsert): Promise<Post | null> {\n  const supabase = await createClient();\n\n  const { data, error } = await supabase\n    .from(\"posts\")\n    .insert(post)\n    .select()\n    .single();\n\n  if (error) {\n    console.error(\"Error creating post:\", error);\n    return null;\n  }\n\n  return data;\n}\n```\n\n## Revalidation Patterns\n\n### Path Revalidation\n\n```tsx\nimport { revalidatePath } from \"next/cache\";\n\nexport async function createPost(formData: FormData) {\n  // ... create post logic\n\n  // Revalidate the posts list page\n  revalidatePath(\"/posts\");\n\n  // Revalidate a specific post page\n  revalidatePath(`/posts/${postId}`);\n\n  // Revalidate all pages under /posts\n  revalidatePath(\"/posts\", \"layout\");\n}\n```\n\n### Tag Revalidation\n\n```tsx\nimport { revalidateTag } from \"next/cache\";\n\n// In your fetch function, tag the request\nexport async function getPosts() {\n  const supabase = await createClient();\n\n  const { data } = await supabase\n    .from(\"posts\")\n    .select(\"*\");\n\n  return data;\n}\n\n// In data fetching component\nimport { unstable_cache } from \"next/cache\";\n\nconst getCachedPosts = unstable_cache(\n  async () => getPosts(),\n  [\"posts\"],\n  { tags: [\"posts\"] }\n);\n\n// In server action, revalidate by tag\nexport async function createPost(formData: FormData) {\n  // ... create post logic\n\n  revalidateTag(\"posts\");\n}\n```\n\n## Complete CRUD Example\n\n```tsx\n// app/actions/todos.ts\n\"use server\";\n\nimport { createClient } from \"@/lib/supabase/server\";\nimport { revalidatePath } from \"next/cache\";\nimport { z } from \"zod\";\n\nconst todoSchema = z.object({\n  text: z.string().min(1, \"Todo text is required\").max(500),\n});\n\nexport async function getTodos() {\n  const supabase = await createClient();\n\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) return [];\n\n  const { data, error } = await supabase\n    .from(\"todos\")\n    .select(\"*\")\n    .eq(\"user_id\", user.id)\n    .order(\"created_at\", { ascending: false });\n\n  if (error) {\n    console.error(\"Error fetching todos:\", error);\n    return [];\n  }\n\n  return data;\n}\n\nexport async function createTodo(formData: FormData) {\n  const supabase = await createClient();\n\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) return { error: \"Unauthorized\" };\n\n  const parsed = todoSchema.safeParse({ text: formData.get(\"text\") });\n  if (!parsed.success) {\n    return { error: parsed.error.flatten().fieldErrors };\n  }\n\n  const { error } = await supabase\n    .from(\"todos\")\n    .insert({ text: parsed.data.text, user_id: user.id });\n\n  if (error) return { error: error.message };\n\n  revalidatePath(\"/todos\");\n  return { success: true };\n}\n\nexport async function toggleTodo(id: string, completed: boolean) {\n  const supabase = await createClient();\n\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) return { error: \"Unauthorized\" };\n\n  const { error } = await supabase\n    .from(\"todos\")\n    .update({ completed })\n    .eq(\"id\", id)\n    .eq(\"user_id\", user.id); // Explicit ownership check\n\n  if (error) return { error: error.message };\n\n  revalidatePath(\"/todos\");\n  return { success: true };\n}\n\nexport async function deleteTodo(id: string) {\n  const supabase = await createClient();\n\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) return { error: \"Unauthorized\" };\n\n  const { error } = await supabase\n    .from(\"todos\")\n    .delete()\n    .eq(\"id\", id)\n    .eq(\"user_id\", user.id); // Explicit ownership check\n\n  if (error) return { error: error.message };\n\n  revalidatePath(\"/todos\");\n  return { success: true };\n}\n```\n\n## Supabase Client Setup\n\n### Server Client\n\n```tsx\n// lib/supabase/server.ts\nimport { createServerClient } from \"@supabase/ssr\";\nimport { cookies } from \"next/headers\";\nimport type { Database } from \"./database.types\";\n\nexport async function createClient() {\n  const cookieStore = await cookies();\n\n  return createServerClient<Database>(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n    {\n      cookies: {\n        getAll() {\n          return cookieStore.getAll();\n        },\n        setAll(cookiesToSet) {\n          try {\n            cookiesToSet.forEach(({ name, value, options }) =>\n              cookieStore.set(name, value, options)\n            );\n          } catch {\n            // Handle cookies in Server Components\n          }\n        },\n      },\n    }\n  );\n}\n```\n\n### Client-Side Client\n\n```tsx\n// lib/supabase/client.ts\nimport { createBrowserClient } from \"@supabase/ssr\";\nimport type { Database } from \"./database.types\";\n\nexport function createClient() {\n  return createBrowserClient<Database>(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\n  );\n}\n```\n\n## Best Practices\n\n**DO:**\n- Always check authentication in server actions\n- Combine RLS policies with explicit ownership checks\n- Use Zod for input validation on both client and server\n- Generate and use TypeScript types from Supabase\n- Revalidate paths after mutations\n- Handle errors gracefully and return meaningful messages\n- Use useActionState for form state management\n\n**DON'T:**\n- Rely solely on RLS without application-level checks\n- Trust client-side data without server validation\n- Forget to revalidate after data mutations\n- Expose internal error messages to users\n- Skip ownership verification for update/delete operations\n- Use client components for data fetching\n\n## Quick Reference\n\n### Server Action Template\n\n```tsx\n\"use server\";\n\nimport { createClient } from \"@/lib/supabase/server\";\nimport { revalidatePath } from \"next/cache\";\n\nexport async function myAction(formData: FormData) {\n  const supabase = await createClient();\n\n  // 1. Auth check\n  const { data: { user } } = await supabase.auth.getUser();\n  if (!user) return { error: \"Unauthorized\" };\n\n  // 2. Validate input\n  // 3. Perform database operation\n  // 4. Revalidate path\n  // 5. Return result\n}\n```\n\n### Common Query Patterns\n\n| Operation | Pattern |\n|-----------|---------|\n| Select all | `.from(\"table\").select(\"*\")` |\n| Select with filter | `.from(\"table\").select(\"*\").eq(\"column\", value)` |\n| Select single | `.from(\"table\").select(\"*\").eq(\"id\", id).single()` |\n| Insert | `.from(\"table\").insert(data).select().single()` |\n| Update | `.from(\"table\").update(data).eq(\"id\", id)` |\n| Delete | `.from(\"table\").delete().eq(\"id\", id)` |\n| Order | `.order(\"created_at\", { ascending: false })` |\n| Limit | `.limit(10)` |\n\n## Implementation Workflow\n\nTo add backend integration:\n\n1. Create or update Supabase table with RLS policies\n2. Generate TypeScript types from Supabase schema\n3. Create server client setup in lib/supabase/server.ts\n4. Define server actions with \"use server\" directive\n5. Add explicit auth checks in every server action\n6. Validate input with Zod schemas\n7. Implement database queries with proper error handling\n8. Add revalidatePath after mutations\n9. Connect to UI components via form actions or callbacks\n10. Test authentication and authorization thoroughly\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-interaction/SKILL.md": "---\nname: UI Interaction\ndescription: This skill should be used when the user asks to \"add client interactivity\", \"implement form validation\", \"add event handlers\", \"use client state\", \"add Zod validation\", \"implement React hooks\", \"add local state\", \"make component interactive\", \"add form with validation\", \"use React Hook Form\", or needs guidance on client-side events, form handling, optimistic updates, or when to add \"use client\" directive.\nversion: 0.1.0\n---\n\n# UI Interaction for Next.js Applications\n\n## Overview\n\nUI Interaction handles the client-side interactivity layer of Next.js applications. This skill covers adding client-side events, managing local state, implementing form validation with Zod, and using React Hook Form for complex forms.\n\n**Key principles:**\n- Only add \"use client\" when client-side APIs are actually needed\n- Use Zod schemas for both client and server validation (single source of truth)\n- Prefer Server Components by default; convert to Client Components only for interactivity\n- Implement optimistic updates for responsive user experience\n\n## Skill-scoped Context\n\n**Official Documentation:**\n- React Hooks: https://react.dev/reference/react/hooks\n- Zod Validation: https://zod.dev/\n- React Hook Form: https://react-hook-form.com/\n- Next.js Client Components: https://nextjs.org/docs/app/building-your-application/rendering/client-components\n\n## When to Add \"use client\"\n\nAdd the \"use client\" directive only when the component uses:\n\n1. **Event handlers** - onClick, onChange, onSubmit, etc.\n2. **React hooks** - useState, useEffect, useRef, useCallback, useMemo\n3. **Browser APIs** - window, document, localStorage, navigator\n4. **Third-party client libraries** - libraries that require browser context\n\n**Pattern: Minimal Client Boundary**\n\nKeep \"use client\" components as small as possible:\n\n```tsx\n// components/counter-button.tsx\n\"use client\";\n\nimport { useState } from \"react\";\n\nexport function CounterButton() {\n  const [count, setCount] = useState(0);\n  return (\n    <button onClick={() => setCount(c => c + 1)}>\n      Count: {count}\n    </button>\n  );\n}\n```\n\n```tsx\n// app/page.tsx (Server Component - no \"use client\")\nimport { CounterButton } from \"@/components/counter-button\";\n\nexport default function Page() {\n  // Server-side data fetching, no client JS here\n  return (\n    <main>\n      <h1>Welcome</h1>\n      <CounterButton /> {/* Client boundary starts here */}\n    </main>\n  );\n}\n```\n\n## Workflow\n\n### Step 1: Identify Interactive Elements\n\nAnalyze the UI to identify elements requiring client-side behavior:\n- Form inputs with validation\n- Buttons with click handlers\n- Elements with hover/focus states\n- Components with local state (toggles, dropdowns, modals)\n- Elements requiring browser APIs\n\n### Step 2: Add \"use client\" Directive\n\nAdd the directive at the top of the file, before any imports:\n\n```tsx\n\"use client\";\n\nimport { useState } from \"react\";\n// ... rest of imports\n```\n\n### Step 3: Implement State Management\n\nUse appropriate React hooks for state:\n\n```tsx\n\"use client\";\n\nimport { useState, useCallback } from \"react\";\n\nexport function ToggleButton({ initialState = false }: { initialState?: boolean }) {\n  const [isOn, setIsOn] = useState(initialState);\n\n  const toggle = useCallback(() => {\n    setIsOn(prev => !prev);\n  }, []);\n\n  return (\n    <button\n      onClick={toggle}\n      aria-pressed={isOn}\n      className={isOn ? \"bg-green-500\" : \"bg-gray-300\"}\n    >\n      {isOn ? \"On\" : \"Off\"}\n    </button>\n  );\n}\n```\n\n### Step 4: Add Zod Validation\n\nDefine Zod schemas for form validation:\n\n```tsx\nimport { z } from \"zod\";\n\n// Define schema once, use for client AND server validation\nexport const contactFormSchema = z.object({\n  name: z.string().min(2, \"Name must be at least 2 characters\"),\n  email: z.string().email(\"Invalid email address\"),\n  message: z.string().min(10, \"Message must be at least 10 characters\"),\n});\n\nexport type ContactFormData = z.infer<typeof contactFormSchema>;\n```\n\n## Form Validation with Zod and React Hook Form\n\n### Complete Form Example\n\n```tsx\n\"use client\";\n\nimport { useForm } from \"react-hook-form\";\nimport { zodResolver } from \"@hookform/resolvers/zod\";\nimport { z } from \"zod\";\n\nconst formSchema = z.object({\n  email: z.string().email(\"Please enter a valid email\"),\n  password: z.string()\n    .min(8, \"Password must be at least 8 characters\")\n    .regex(/[A-Z]/, \"Password must contain an uppercase letter\")\n    .regex(/[0-9]/, \"Password must contain a number\"),\n  confirmPassword: z.string(),\n}).refine((data) => data.password === data.confirmPassword, {\n  message: \"Passwords don't match\",\n  path: [\"confirmPassword\"],\n});\n\ntype FormData = z.infer<typeof formSchema>;\n\nexport function SignUpForm({ onSubmit }: { onSubmit: (data: FormData) => Promise<void> }) {\n  const {\n    register,\n    handleSubmit,\n    formState: { errors, isSubmitting },\n  } = useForm<FormData>({\n    resolver: zodResolver(formSchema),\n  });\n\n  return (\n    <form onSubmit={handleSubmit(onSubmit)} className=\"space-y-4\">\n      <div>\n        <label htmlFor=\"email\" className=\"block text-sm font-medium\">\n          Email\n        </label>\n        <input\n          {...register(\"email\")}\n          type=\"email\"\n          id=\"email\"\n          className=\"mt-1 block w-full rounded-md border-gray-300\"\n          aria-invalid={errors.email ? \"true\" : \"false\"}\n        />\n        {errors.email && (\n          <p className=\"mt-1 text-sm text-red-600\" role=\"alert\">\n            {errors.email.message}\n          </p>\n        )}\n      </div>\n\n      <div>\n        <label htmlFor=\"password\" className=\"block text-sm font-medium\">\n          Password\n        </label>\n        <input\n          {...register(\"password\")}\n          type=\"password\"\n          id=\"password\"\n          className=\"mt-1 block w-full rounded-md border-gray-300\"\n          aria-invalid={errors.password ? \"true\" : \"false\"}\n        />\n        {errors.password && (\n          <p className=\"mt-1 text-sm text-red-600\" role=\"alert\">\n            {errors.password.message}\n          </p>\n        )}\n      </div>\n\n      <div>\n        <label htmlFor=\"confirmPassword\" className=\"block text-sm font-medium\">\n          Confirm Password\n        </label>\n        <input\n          {...register(\"confirmPassword\")}\n          type=\"password\"\n          id=\"confirmPassword\"\n          className=\"mt-1 block w-full rounded-md border-gray-300\"\n          aria-invalid={errors.confirmPassword ? \"true\" : \"false\"}\n        />\n        {errors.confirmPassword && (\n          <p className=\"mt-1 text-sm text-red-600\" role=\"alert\">\n            {errors.confirmPassword.message}\n          </p>\n        )}\n      </div>\n\n      <button\n        type=\"submit\"\n        disabled={isSubmitting}\n        className=\"w-full rounded-md bg-blue-600 px-4 py-2 text-white disabled:opacity-50\"\n      >\n        {isSubmitting ? \"Signing up...\" : \"Sign Up\"}\n      </button>\n    </form>\n  );\n}\n```\n\n## Event Handler Patterns\n\n### Click Handlers\n\n```tsx\n\"use client\";\n\nimport { useCallback } from \"react\";\n\nexport function DeleteButton({ itemId, onDelete }: {\n  itemId: string;\n  onDelete: (id: string) => Promise<void>;\n}) {\n  const handleDelete = useCallback(async () => {\n    if (confirm(\"Are you sure you want to delete this item?\")) {\n      await onDelete(itemId);\n    }\n  }, [itemId, onDelete]);\n\n  return (\n    <button\n      onClick={handleDelete}\n      className=\"text-red-600 hover:text-red-800\"\n      aria-label=\"Delete item\"\n    >\n      Delete\n    </button>\n  );\n}\n```\n\n### Keyboard Events\n\n```tsx\n\"use client\";\n\nimport { useCallback, KeyboardEvent } from \"react\";\n\nexport function SearchInput({ onSearch }: { onSearch: (query: string) => void }) {\n  const handleKeyDown = useCallback((e: KeyboardEvent<HTMLInputElement>) => {\n    if (e.key === \"Enter\") {\n      onSearch(e.currentTarget.value);\n    }\n  }, [onSearch]);\n\n  return (\n    <input\n      type=\"search\"\n      placeholder=\"Search...\"\n      onKeyDown={handleKeyDown}\n      className=\"rounded-md border px-4 py-2\"\n      aria-label=\"Search\"\n    />\n  );\n}\n```\n\n## Optimistic Updates Pattern\n\nProvide immediate feedback while server action processes:\n\n```tsx\n\"use client\";\n\nimport { useOptimistic, useTransition } from \"react\";\n\ninterface Todo {\n  id: string;\n  text: string;\n  completed: boolean;\n}\n\nexport function TodoItem({\n  todo,\n  toggleAction\n}: {\n  todo: Todo;\n  toggleAction: (id: string) => Promise<void>;\n}) {\n  const [isPending, startTransition] = useTransition();\n  const [optimisticTodo, setOptimisticTodo] = useOptimistic(\n    todo,\n    (state, completed: boolean) => ({ ...state, completed })\n  );\n\n  const handleToggle = () => {\n    startTransition(async () => {\n      setOptimisticTodo(!optimisticTodo.completed);\n      await toggleAction(todo.id);\n    });\n  };\n\n  return (\n    <div className={isPending ? \"opacity-50\" : \"\"}>\n      <input\n        type=\"checkbox\"\n        checked={optimisticTodo.completed}\n        onChange={handleToggle}\n        aria-label={`Mark \"${todo.text}\" as ${optimisticTodo.completed ? \"incomplete\" : \"complete\"}`}\n      />\n      <span className={optimisticTodo.completed ? \"line-through\" : \"\"}>\n        {todo.text}\n      </span>\n    </div>\n  );\n}\n```\n\n## Local State Patterns\n\n### Toggle State\n\n```tsx\n\"use client\";\n\nimport { useState, useCallback } from \"react\";\n\nexport function Accordion({ title, children }: {\n  title: string;\n  children: React.ReactNode;\n}) {\n  const [isOpen, setIsOpen] = useState(false);\n\n  const toggle = useCallback(() => setIsOpen(prev => !prev), []);\n\n  return (\n    <div className=\"border rounded-md\">\n      <button\n        onClick={toggle}\n        aria-expanded={isOpen}\n        className=\"w-full px-4 py-2 text-left font-medium\"\n      >\n        {title}\n        <span className=\"float-right\">{isOpen ? \"−\" : \"+\"}</span>\n      </button>\n      {isOpen && (\n        <div className=\"px-4 py-2 border-t\">\n          {children}\n        </div>\n      )}\n    </div>\n  );\n}\n```\n\n### Controlled Input\n\n```tsx\n\"use client\";\n\nimport { useState, ChangeEvent, useCallback } from \"react\";\n\nexport function ControlledInput({\n  initialValue = \"\",\n  onChange\n}: {\n  initialValue?: string;\n  onChange?: (value: string) => void;\n}) {\n  const [value, setValue] = useState(initialValue);\n\n  const handleChange = useCallback((e: ChangeEvent<HTMLInputElement>) => {\n    const newValue = e.target.value;\n    setValue(newValue);\n    onChange?.(newValue);\n  }, [onChange]);\n\n  return (\n    <input\n      type=\"text\"\n      value={value}\n      onChange={handleChange}\n      className=\"rounded-md border px-4 py-2\"\n    />\n  );\n}\n```\n\n## Best Practices\n\n**DO:**\n- Keep \"use client\" components minimal and focused\n- Define Zod schemas in shared files for client AND server use\n- Use React Hook Form for complex forms with multiple fields\n- Implement optimistic updates for better UX\n- Add proper aria attributes for accessibility\n- Use useCallback for stable function references passed to children\n\n**DON'T:**\n- Add \"use client\" to components that don't need it\n- Duplicate validation logic between client and server\n- Use client-side state for data that should come from the server\n- Forget to handle loading and error states\n- Skip accessibility attributes on interactive elements\n\n## Quick Reference\n\n### When to Use Each Hook\n\n| Hook | Use Case |\n|------|----------|\n| useState | Local component state |\n| useCallback | Memoize event handlers |\n| useMemo | Expensive computations |\n| useRef | DOM references, mutable values |\n| useOptimistic | Optimistic UI updates |\n| useTransition | Non-blocking state updates |\n\n### Zod Common Validators\n\n| Validator | Example |\n|-----------|---------|\n| string | `z.string().min(1).max(100)` |\n| email | `z.string().email()` |\n| number | `z.number().int().positive()` |\n| enum | `z.enum([\"a\", \"b\", \"c\"])` |\n| optional | `z.string().optional()` |\n| nullable | `z.string().nullable()` |\n| refine | `schema.refine(val => condition, \"message\")` |\n\n## Implementation Workflow\n\nTo add interactivity to a component:\n\n1. Identify which elements need client-side behavior\n2. Extract interactive elements to separate \"use client\" component\n3. Keep parent component as Server Component when possible\n4. Define Zod schemas for any form validation\n5. Implement React Hook Form for forms with multiple fields\n6. Add event handlers with useCallback for stability\n7. Implement optimistic updates for mutations\n8. Add proper accessibility attributes\n9. Test interactive behavior across devices\n",
        "plugins/nextjs-supabase-ai-sdk-dev/skills/ui-wireframing/SKILL.md": "---\nname: UI Wireframing\ndescription: This skill should be used when the user asks to \"create a wireframe\", \"design a layout\", \"plan UI structure\", \"sketch component layout\", \"create WIREFRAME.md\", \"mobile-first wireframe\", or mentions ASCII wireframes, layout planning, or UI structure before implementation. Provides mobile-first ASCII wireframe methodology for visualizing layouts before code.\nversion: 0.1.0\n---\n\n# UI Wireframing\n\nMobile-first ASCII wireframe methodology for planning UI layouts before implementation.\n\n## Purpose\n\nWireframing is the first step in the UI development workflow. Create visual ASCII representations of component and page layouts in WIREFRAME.md files before writing any code. This ensures alignment on structure, hierarchy, and interaction patterns.\n\n## When to Use\n\n- Before implementing any new UI component or page\n- When planning responsive layouts across breakpoints\n- To communicate component structure and data flow\n- When refactoring existing UI for better organization\n\n## Core Principles\n\n### Mobile-First Design\n\nAlways start with the smallest viewport (375px mobile). Design for mobile constraints first, then progressively enhance for larger screens:\n\n1. **Mobile (375px)** - Primary design target, single column\n2. **Tablet (768px)** - Two column layouts where appropriate\n3. **Desktop (1024px+)** - Full multi-column layouts\n\n### WIREFRAME.md File Location\n\nCreate WIREFRAME.md files in the component or page directory:\n\n```\ncomponents/\n└── feature-card/\n    ├── WIREFRAME.md      # Wireframe documentation\n    ├── feature-card.tsx  # Implementation\n    └── index.ts\n\napp/\n└── dashboard/\n    ├── WIREFRAME.md      # Page wireframe\n    └── page.tsx\n```\n\n## Wireframe Workflow\n\n### Step 1: Identify Components\n\nBefore drawing, list the key elements:\n\n```markdown\n## Components\n\n- Header with logo and navigation\n- Hero section with title and CTA\n- Feature cards (3x grid on desktop)\n- Footer with links\n```\n\n### Step 2: Create Mobile Layout (375px)\n\nStart with the mobile viewport using ASCII art:\n\n```markdown\n## Mobile Layout (375px)\n\n┌─────────────────────────────────────┐\n│ [Logo]              [☰ Menu]        │\n├─────────────────────────────────────┤\n│                                     │\n│         Hero Image                  │\n│                                     │\n│    Welcome to Our App               │\n│    ─────────────────                │\n│    Subtitle text here               │\n│                                     │\n│    [ Get Started → ]                │\n│                                     │\n├─────────────────────────────────────┤\n│  ┌─────────────────────────────┐    │\n│  │  Feature 1                  │    │\n│  │  Description text           │    │\n│  └─────────────────────────────┘    │\n│                                     │\n│  ┌─────────────────────────────┐    │\n│  │  Feature 2                  │    │\n│  │  Description text           │    │\n│  └─────────────────────────────┘    │\n│                                     │\n│  ┌─────────────────────────────┐    │\n│  │  Feature 3                  │    │\n│  │  Description text           │    │\n│  └─────────────────────────────┘    │\n├─────────────────────────────────────┤\n│  Links | Privacy | Terms            │\n│  © 2025 Company                     │\n└─────────────────────────────────────┘\n```\n\n### Step 3: Expand to Tablet (768px)\n\nShow how layout adapts:\n\n```markdown\n## Tablet Layout (768px)\n\n┌─────────────────────────────────────────────────┐\n│ [Logo]                    [Nav] [Nav] [Nav]     │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│              Hero Image                         │\n│                                                 │\n│         Welcome to Our App                      │\n│         ─────────────────                       │\n│                                                 │\n│            [ Get Started → ]                    │\n│                                                 │\n├─────────────────────────────────────────────────┤\n│  ┌──────────────────┐  ┌──────────────────┐     │\n│  │  Feature 1       │  │  Feature 2       │     │\n│  │  Description     │  │  Description     │     │\n│  └──────────────────┘  └──────────────────┘     │\n│                                                 │\n│  ┌──────────────────┐                           │\n│  │  Feature 3       │                           │\n│  │  Description     │                           │\n│  └──────────────────┘                           │\n└─────────────────────────────────────────────────┘\n```\n\n### Step 4: Expand to Desktop (1024px+)\n\nFull layout with all columns:\n\n```markdown\n## Desktop Layout (1024px+)\n\n┌────────────────────────────────────────────────────────────────┐\n│ [Logo]                              [Nav] [Nav] [Nav] [CTA]    │\n├────────────────────────────────────────────────────────────────┤\n│                                                                │\n│                       Hero Image                               │\n│                                                                │\n│                  Welcome to Our App                            │\n│                  ─────────────────                             │\n│                  Subtitle text here                            │\n│                                                                │\n│                    [ Get Started → ]                           │\n│                                                                │\n├────────────────────────────────────────────────────────────────┤\n│  ┌────────────────┐  ┌────────────────┐  ┌────────────────┐    │\n│  │  Feature 1     │  │  Feature 2     │  │  Feature 3     │    │\n│  │  Description   │  │  Description   │  │  Description   │    │\n│  │  text here     │  │  text here     │  │  text here     │    │\n│  └────────────────┘  └────────────────┘  └────────────────┘    │\n├────────────────────────────────────────────────────────────────┤\n│  Links | Privacy | Terms                    © 2025 Company     │\n└────────────────────────────────────────────────────────────────┘\n```\n\n### Step 5: Annotate Interactions\n\nDocument interactive elements and data flow:\n\n```markdown\n## Interactions\n\n### Navigation\n- Mobile: Hamburger menu opens full-screen overlay\n- Tablet+: Horizontal nav bar visible\n\n### CTA Button\n- onClick: Navigate to /signup\n- Hover: Scale 1.02, shadow increase\n\n### Feature Cards\n- Hover: Lift effect with shadow\n- Click: Navigate to /features/{id}\n\n## Data Requirements\n\n- `features[]`: Array of feature objects\n  - `id`: string\n  - `title`: string\n  - `description`: string\n  - `icon`: IconName\n```\n\n## ASCII Art Reference\n\n### Box Drawing Characters\n\n```\nCorners:  ┌ ┐ └ ┘\nLines:    │ ─\nT-joints: ├ ┤ ┬ ┴ ┼\n```\n\n### Common Elements\n\n```\nButton:     [ Button Text ]  or  [ → ]\nInput:      [_______________]\nCheckbox:   [✓] Label  or  [ ] Label\nRadio:      (●) Selected  or  ( ) Unselected\nDropdown:   [Option      ▼]\nIcon:       [☰]  [✕]  [→]  [←]  [↑]  [↓]\nImage:      ┌─────────┐\n            │  IMG    │\n            └─────────┘\n```\n\n### Spacing Indicators\n\n```\nPadding:    │ ← 16px → │\nGap:        [Card]  ← 24px →  [Card]\nMargin:     ↑ 32px margin\n```\n\n## Complete WIREFRAME.md Template\n\n```markdown\n# Component/Page Name Wireframe\n\n## Overview\n\nBrief description of the component/page purpose.\n\n## Components\n\n- Component 1: Description\n- Component 2: Description\n\n## Mobile Layout (375px)\n\n[ASCII wireframe]\n\n## Tablet Layout (768px)\n\n[ASCII wireframe]\n\n## Desktop Layout (1024px+)\n\n[ASCII wireframe]\n\n## Interactions\n\n### Element Name\n- Event: Behavior\n\n## Data Requirements\n\n- `propName`: type - description\n\n## States\n\n### Loading\n[ASCII for loading state]\n\n### Empty\n[ASCII for empty state]\n\n### Error\n[ASCII for error state]\n\n## Accessibility Notes\n\n- Keyboard navigation: Tab order, focus states\n- Screen reader: ARIA labels, semantic HTML\n- Color contrast: Minimum 4.5:1 ratio\n```\n\n## Best Practices\n\n### Layout Guidelines\n\n1. **Use consistent spacing** - Define a spacing scale (8px, 16px, 24px, 32px)\n2. **Align elements** - Use a grid system in the ASCII\n3. **Show hierarchy** - Larger text for headings, visual weight for CTAs\n4. **Consider touch targets** - Minimum 44x44px for mobile buttons\n\n### Documentation Guidelines\n\n1. **Keep wireframes updated** - Modify when requirements change\n2. **Include all states** - Loading, empty, error, success\n3. **Document interactions** - What happens on click, hover, focus\n4. **Specify data needs** - Props, API responses, state\n\n### Review Checklist\n\nBefore proceeding to implementation:\n\n- [ ] Mobile layout complete and usable\n- [ ] Tablet and desktop layouts defined\n- [ ] All interactive elements documented\n- [ ] Data requirements specified\n- [ ] Accessibility considerations noted\n- [ ] All UI states represented\n\n## Next Steps\n\nAfter wireframe approval, proceed to the **ui-design** skill for implementing the static UI with compound components and TypeScript interfaces.\n",
        "plugins/project-context/.claude-plugin/plugin.json": "{\n  \"name\": \"project-context\",\n  \"version\": \"0.1.4\",\n  \"description\": \"Project context discovery, markdown-friendly documentation, and maintenance for Claude Code\",\n  \"author\": {\n    \"name\": \"constellos\"\n  },\n  \"repository\": \"https://github.com/constellos/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"project-context\",\n    \"navigation\",\n    \"structure\",\n    \"documentation\",\n    \"markdown\",\n    \"webfetch\",\n    \"claude-code\"\n  ],\n  \"mcpServers\": {\n    \"nodes\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"nodes-md@latest\"]\n    }\n  }\n}\n",
        "plugins/project-context/README.md": "![Version](https://img.shields.io/badge/version-0.1.1-blue?style=for-the-badge)\n![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)\n![Markdown](https://img.shields.io/badge/Markdown-000000?style=for-the-badge&logo=markdown)\n\n# Project Context Plugin\n\n> Context discovery, structure validation, and rule-based checks for Claude Code projects\n\n## Purpose\n\nProvides automatic context discovery and project structure validation. Discovers CLAUDE.md documentation when reading files, validates .claude directory structure, enforces plan scoping, redirects to markdown documentation URLs, and runs rule-based checks (lint, typecheck, vitest) on file edits.\n\n## Contents\n\n### Hooks\n\n| Hook | Event | Purpose |\n|------|-------|---------|\n| encourage-context-review | UserPromptSubmit | Encourages updating CLAUDE.md files |\n| log-task-call | PreToolUse[Task] | Saves task context for SubagentStop |\n| validate-folder-structure-write | PreToolUse[Write\\|Edit] | Validates .claude directory structure |\n| validate-rules-file | PreToolUse[Write\\|Edit] | Validates rule frontmatter |\n| validate-folder-structure-mkdir | PreToolUse[Bash] | Validates mkdir for .claude dirs |\n| try-markdown-page | PreToolUse[WebFetch] | Redirects to .md versions of docs |\n| log-task-result | PostToolUse[Task] | Logs task results |\n| run-rule-checks | PostToolUse[Write\\|Edit] | Runs checks from rule frontmatter |\n| add-folder-context | PostToolUse[Read] | Discovers CLAUDE.md context |\n\n### Skills\n\n| Skill | Purpose |\n|-------|---------|\n| feature-sliced-design | FSD architecture for Next.js apps with custom 'views' layer |\n\n## Installation\n\n```bash\nclaude plugin install project-context@constellos\n```\n\n## License\n\nMIT © constellos\n",
        "plugins/project-context/hooks/add-folder-context.ts": "/**\n * Context discovery hook for CLAUDE.md documentation and TSDoc metadata\n *\n * PostToolUse hook that automatically discovers and links related CLAUDE.md\n * documentation files after Read operations. Also incrementally indexes TSDoc\n * metadata from TypeScript files for SERP-style context matching.\n *\n * When a file is read, this hook:\n * 1. Searches for CLAUDE.md files in parent/child directories\n * 2. For .ts/.tsx files: extracts TSDoc @context and @aliases tags\n * 3. Updates the metadata index for future context matching\n *\n * Found documentation files are provided as clickable file:// links in the\n * additional context section, making it easy to explore related documentation.\n *\n * @module add-folder-context\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { parseFileMetadata } from '../shared/hooks/utils/tsdoc-parser.js';\nimport { loadIndex, saveIndex } from '../shared/hooks/utils/metadata-index.js';\nimport { readdir, access, readFile, writeFile, mkdir, stat } from 'fs/promises';\nimport { join, dirname, extname, relative } from 'path';\nimport { existsSync } from 'fs';\n\n/**\n * Check if a file exists at the given path\n *\n * Uses fs.access to test file existence without throwing errors.\n * This is more efficient than try-catching readFile for existence checks.\n *\n * @param path - The file path to check\n * @returns True if the file exists and is accessible, false otherwise\n *\n * @example\n * ```typescript\n * const exists = await fileExists('/path/to/CLAUDE.md');\n * if (exists) {\n *   console.log('File found!');\n * }\n * ```\n */\nasync function fileExists(path: string): Promise<boolean> {\n  try {\n    await access(path);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Session state for tracking injected context paths\n */\ninterface InjectedPathsState {\n  [sessionId: string]: {\n    paths: string[];\n    lastUpdated: string;\n  };\n}\n\n/**\n * Get list of already-injected paths for this session\n *\n * @param sessionId - Current session ID\n * @param cwd - Working directory\n * @returns Array of paths already injected this session\n */\nasync function getInjectedPaths(sessionId: string, cwd: string): Promise<string[]> {\n  const stateFile = join(cwd, '.claude', 'logs', 'injected-context-paths.json');\n\n  try {\n    if (!existsSync(stateFile)) {\n      return [];\n    }\n    const content = await readFile(stateFile, 'utf-8');\n    const state: InjectedPathsState = JSON.parse(content);\n    return state[sessionId]?.paths || [];\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Save injected paths for this session\n *\n * @param sessionId - Current session ID\n * @param cwd - Working directory\n * @param paths - Paths that have been injected\n */\nasync function saveInjectedPaths(sessionId: string, cwd: string, paths: string[]): Promise<void> {\n  const logsDir = join(cwd, '.claude', 'logs');\n  const stateFile = join(logsDir, 'injected-context-paths.json');\n\n  try {\n    await mkdir(logsDir, { recursive: true });\n\n    let state: InjectedPathsState = {};\n    if (existsSync(stateFile)) {\n      const content = await readFile(stateFile, 'utf-8');\n      state = JSON.parse(content);\n    }\n\n    state[sessionId] = {\n      paths,\n      lastUpdated: new Date().toISOString(),\n    };\n    await writeFile(stateFile, JSON.stringify(state, null, 2));\n  } catch {\n    // Ignore errors - non-critical\n  }\n}\n\n/**\n * PostToolUse hook that discovers and links related CLAUDE.md documentation\n *\n * Intercepts Read tool completions to automatically discover related documentation\n * files in the project structure. The hook searches three locations and provides\n * found files as clickable links in the additional context.\n *\n * Search strategy:\n * 1. Project root - always check for /CLAUDE.md\n * 2. Parent directories - walk up from the read file to project root\n * 3. Child directories - scan one level deep in the file's directory\n *\n * The hook is non-blocking and fails silently - errors in discovery do not\n * prevent the Read operation from completing.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with discovered CLAUDE.md files as additional context\n *\n * @example\n * ```typescript\n * // When reading: /project/src/api/routes.ts\n * const result = await handler({\n *   tool_name: 'Read',\n *   tool_use_id: 'toolu_123',\n *   tool_input: { file_path: '/project/src/api/routes.ts' },\n *   cwd: '/project',\n *   // ... other fields\n * });\n *\n * // If the following files exist:\n * // - /project/CLAUDE.md (root)\n * // - /project/src/CLAUDE.md (parent)\n * // - /project/src/api/CLAUDE.md (parent)\n * // - /project/src/api/handlers/CLAUDE.md (child)\n *\n * // Returns:\n * // {\n * //   hookSpecificOutput: {\n * //     hookEventName: 'PostToolUse',\n * //     additionalContext: `Related context:\n * // [/project/CLAUDE.md](file:///project/CLAUDE.md)\n * // [/project/src/CLAUDE.md](file:///project/src/CLAUDE.md)\n * // [/project/src/api/CLAUDE.md](file:///project/src/api/CLAUDE.md)\n * // [/project/src/api/handlers/CLAUDE.md](file:///project/src/api/handlers/CLAUDE.md)`\n * //   }\n * // }\n *\n * // This additional context appears in Claude's response as clickable links\n * ```\n */\nasync function handler(\n  input: PostToolUseInput\n): Promise<PostToolUseHookOutput> {\n  // Only run for Read operations\n  if (input.tool_name !== 'Read') {\n    return {};\n  }\n\n  const logger = createDebugLogger(input.cwd, 'add-folder-context', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Extract file path from tool input\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput?.file_path;\n\n    if (!filePath) {\n      await logger.logOutput({ success: false, reason: 'No file_path in tool input' });\n      return {};\n    }\n\n    // Extract TSDoc metadata for TypeScript files and update the index\n    const fileExt = extname(filePath).toLowerCase();\n    if (fileExt === '.ts' || fileExt === '.tsx') {\n      try {\n        // Get file content from tool response (the Read tool returns the content)\n        const toolResponse = input.tool_response as { content?: string } | string;\n        const fileContent = typeof toolResponse === 'string' ? toolResponse : toolResponse?.content;\n\n        if (fileContent && typeof fileContent === 'string') {\n          // Get file modification time\n          const fileStat = await stat(filePath).catch(() => null);\n          const lastModified = fileStat?.mtime.toISOString() || new Date().toISOString();\n\n          // Parse TSDoc metadata\n          const relativePath = relative(input.cwd, filePath);\n          const fileMetadata = parseFileMetadata(relativePath, fileContent);\n          fileMetadata.lastModified = lastModified;\n\n          // Update the index\n          const index = await loadIndex(input.cwd);\n          index.files[relativePath] = fileMetadata;\n          await saveIndex(input.cwd, index);\n\n          await logger.logOutput({\n            tsdoc_indexed: true,\n            file: relativePath,\n            tags: fileMetadata.tags.length,\n            exports: fileMetadata.exports.length,\n          });\n        }\n      } catch (error) {\n        // Non-blocking - TSDoc extraction is optional\n        await logger.logOutput({ tsdoc_indexed: false, error: String(error) });\n      }\n    }\n\n    const claudeMdFiles: string[] = [];\n\n    // 1. Check for CLAUDE.md at project root\n    const rootClaudeMd = join(input.cwd, 'CLAUDE.md');\n    if (await fileExists(rootClaudeMd)) {\n      claudeMdFiles.push(rootClaudeMd);\n    }\n\n    // 2. Walk up the directory tree to find parent CLAUDE.md files\n    let currentDir = dirname(filePath);\n    while (currentDir.startsWith(input.cwd) && currentDir !== input.cwd) {\n      const claudeMdPath = join(currentDir, 'CLAUDE.md');\n      if (await fileExists(claudeMdPath)) {\n        claudeMdFiles.push(claudeMdPath);\n      }\n      currentDir = dirname(currentDir);\n    }\n\n    // 3. Scan immediate child directories for CLAUDE.md files\n    const fileDir = dirname(filePath);\n    try {\n      const entries = await readdir(fileDir, { withFileTypes: true });\n      for (const entry of entries) {\n        if (entry.isDirectory()) {\n          const childClaudeMd = join(fileDir, entry.name, 'CLAUDE.md');\n          if (await fileExists(childClaudeMd)) {\n            claudeMdFiles.push(childClaudeMd);\n          }\n        }\n      }\n    } catch (error) {\n      // Directory may not be readable, skip silently\n      await logger.logError(error as Error);\n    }\n\n    // Remove duplicates and sort\n    const uniqueFiles = [...new Set(claudeMdFiles)].sort();\n\n    if (uniqueFiles.length === 0) {\n      await logger.logOutput({ success: true, found: 0 });\n      return {};\n    }\n\n    // Get already-injected paths for this session\n    const alreadyInjected = await getInjectedPaths(input.session_id, input.cwd);\n    const alreadyInjectedSet = new Set(alreadyInjected);\n\n    // Filter out paths already injected this session\n    const newPaths = uniqueFiles.filter((p) => !alreadyInjectedSet.has(p));\n\n    if (newPaths.length === 0) {\n      await logger.logOutput({ success: true, found: 0, skipped: uniqueFiles.length });\n      return {};\n    }\n\n    // Save combined paths (already injected + new)\n    await saveInjectedPaths(input.session_id, input.cwd, [...alreadyInjected, ...newPaths]);\n\n    // Format as markdown links\n    const links = newPaths.map((path) => `[${path}](file://${path})`).join('\\n');\n    const contextMessage = `Related context:\\n${links}`;\n\n    await logger.logOutput({\n      success: true,\n      found: newPaths.length,\n      skipped: uniqueFiles.length - newPaths.length,\n      files: newPaths,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: contextMessage,\n      },\n    };\n  } catch (error: unknown) {\n    // Non-blocking on errors\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/hooks/encourage-context-review.ts": "/**\n * Requirements analysis and planning guidance hook\n *\n * UserPromptSubmit hook that adds systematic requirement analysis instructions\n * to every user prompt. Ensures Claude follows a consistent process for\n * understanding requests and maintaining plans.\n *\n * This hook also matches user prompt words against CLAUDE.md file tags,\n * displaying relevant context files based on the user's message.\n *\n * This hook instructs Claude to:\n * 1. **List requirements** - Document all explicit and implicit requirements\n * 2. **Plan consideration** - Evaluate if current plan needs revision\n * 3. **Proceed systematically** - Implement only after documenting understanding\n *\n * The guidance is added as additional context to the user's prompt, making it\n * part of Claude's instruction set for that turn. This creates a consistent\n * workflow across all user interactions.\n *\n * @module guide-requirements-check\n */\n\nimport { readdir, readFile, writeFile, mkdir } from 'node:fs/promises';\nimport { join } from 'node:path';\nimport { existsSync } from 'node:fs';\nimport type {\n  UserPromptSubmitInput,\n  UserPromptSubmitHookOutput,\n} from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { parseFrontmatter } from '../shared/hooks/utils/frontmatter.js';\n\n/**\n * Session state for tracking guidance injection\n */\ninterface GuidanceState {\n  [sessionId: string]: {\n    injectedAt: string;\n  };\n}\n\n/**\n * Check if guidance has already been injected for this session\n *\n * @param sessionId - Current session ID\n * @param cwd - Working directory\n * @returns True if guidance already injected\n */\nasync function hasGuidanceBeenInjected(sessionId: string, cwd: string): Promise<boolean> {\n  const stateFile = join(cwd, '.claude', 'logs', 'guidance-state.json');\n\n  try {\n    if (!existsSync(stateFile)) {\n      return false;\n    }\n    const content = await readFile(stateFile, 'utf-8');\n    const state: GuidanceState = JSON.parse(content);\n    return !!state[sessionId];\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Mark guidance as injected for this session\n *\n * @param sessionId - Current session ID\n * @param cwd - Working directory\n */\nasync function markGuidanceInjected(sessionId: string, cwd: string): Promise<void> {\n  const logsDir = join(cwd, '.claude', 'logs');\n  const stateFile = join(logsDir, 'guidance-state.json');\n\n  try {\n    await mkdir(logsDir, { recursive: true });\n\n    let state: GuidanceState = {};\n    if (existsSync(stateFile)) {\n      const content = await readFile(stateFile, 'utf-8');\n      state = JSON.parse(content);\n    }\n\n    state[sessionId] = { injectedAt: new Date().toISOString() };\n    await writeFile(stateFile, JSON.stringify(state, null, 2));\n  } catch {\n    // Ignore errors - non-critical\n  }\n}\n\n/**\n * Context match result from tag matching\n */\ninterface ContextMatch {\n  title: string;\n  path: string;\n  matchedTags: string[];\n}\n\n/**\n * Recursively find all CLAUDE.md files in a directory\n *\n * @param dir - Directory to search\n * @param maxDepth - Maximum recursion depth (default 5)\n * @returns Array of file paths\n */\nasync function findClaudeMdFiles(dir: string, maxDepth = 5): Promise<string[]> {\n  if (maxDepth <= 0) return [];\n\n  const files: string[] = [];\n\n  try {\n    const entries = await readdir(dir, { withFileTypes: true });\n\n    for (const entry of entries) {\n      const fullPath = join(dir, entry.name);\n\n      // Skip node_modules, .git, and hidden directories (except .claude)\n      if (entry.isDirectory()) {\n        if (entry.name === 'node_modules' || entry.name === '.git') continue;\n        if (entry.name.startsWith('.') && entry.name !== '.claude') continue;\n\n        const subFiles = await findClaudeMdFiles(fullPath, maxDepth - 1);\n        files.push(...subFiles);\n      } else if (entry.name === 'CLAUDE.md') {\n        files.push(fullPath);\n      }\n    }\n  } catch {\n    // Ignore permission errors or missing directories\n  }\n\n  return files;\n}\n\n/**\n * Parse CLAUDE.md file and extract title and tags\n *\n * @param filePath - Path to CLAUDE.md file\n * @returns Object with title and tags, or null if not found\n */\nasync function parseClaudeMd(filePath: string): Promise<{ title: string; tags: string[] } | null> {\n  try {\n    const content = await readFile(filePath, 'utf-8');\n    const { data } = parseFrontmatter(content);\n\n    const title = data.title as string | undefined;\n    const tags = data.tags as string[] | undefined;\n\n    if (!title || !tags || !Array.isArray(tags)) {\n      return null;\n    }\n\n    return { title, tags };\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Tokenize user prompt into lowercase words\n *\n * @param prompt - User prompt string\n * @returns Array of lowercase words\n */\nfunction tokenizePrompt(prompt: string): string[] {\n  return prompt\n    .toLowerCase()\n    .replace(/[^a-z0-9-]/g, ' ')\n    .split(/\\s+/)\n    .filter((word) => word.length > 2);\n}\n\n/**\n * Find CLAUDE.md files with tags matching user prompt words\n *\n * @param cwd - Current working directory\n * @param prompt - User prompt string\n * @returns Array of context matches with title and matched tags\n */\nasync function findMatchingContexts(cwd: string, prompt: string): Promise<ContextMatch[]> {\n  const promptWords = new Set(tokenizePrompt(prompt));\n  const claudeMdFiles = await findClaudeMdFiles(cwd);\n  const matches: ContextMatch[] = [];\n\n  for (const filePath of claudeMdFiles) {\n    const parsed = await parseClaudeMd(filePath);\n    if (!parsed) continue;\n\n    const matchedTags = parsed.tags.filter((tag) =>\n      promptWords.has(tag.toLowerCase())\n    );\n\n    if (matchedTags.length > 0) {\n      matches.push({\n        title: parsed.title,\n        path: filePath,\n        matchedTags,\n      });\n    }\n  }\n\n  // Sort by number of matched tags (descending)\n  matches.sort((a, b) => b.matchedTags.length - a.matchedTags.length);\n\n  return matches;\n}\n\n/**\n * UserPromptSubmit hook handler\n *\n * Adds guidance to Claude for thorough requirement analysis and plan updates.\n * Also matches user prompt words against CLAUDE.md tags to show relevant context.\n *\n * @param input - UserPromptSubmit hook input from Claude Code\n * @returns Hook output with additional context guidance\n */\nasync function handler(input: UserPromptSubmitInput): Promise<UserPromptSubmitHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'guide-requirements-check', true);\n\n  try {\n    await logger.logInput({\n      session_id: input.session_id,\n      permission_mode: input.permission_mode,\n      prompt_length: input.prompt.length,\n    });\n\n    // Check if guidance has already been injected this session\n    if (await hasGuidanceBeenInjected(input.session_id, input.cwd)) {\n      await logger.logOutput({ skipped: true, reason: 'already_injected' });\n      return {};\n    }\n\n    // Find matching context files based on user prompt\n    const matchedContexts = await findMatchingContexts(input.cwd, input.prompt);\n\n    // Build context list if there are matches\n    let contextSection = '';\n    if (matchedContexts.length > 0) {\n      const contextList = matchedContexts\n        .map((c) => `- **${c.title}**: ${c.matchedTags.join(', ')}`)\n        .join('\\n');\n      contextSection = `\\n\\n**Relevant Context Files:**\\n${contextList}`;\n    }\n\n    // Add guidance for Claude to check requirements and plan\n    const guidance = `IMPORTANT: Before proceeding with this request:\n\n1. **List Requirements**: Start your response by noting a precise list of ALL requirements from the user's message:\n   - Explicit requirements (directly stated)\n   - Implicit requirements (implied by context)\n   - Constraints or limitations mentioned\n   - Success criteria or acceptance conditions\n\n2. **Plan Consideration**: Consider whether this request should update the current plan:\n   - If in plan mode (permission_mode: ${input.permission_mode}), update the plan accordingly\n   - If a plan exists for this session, evaluate if it needs revision based on new requirements\n   - If no plan exists but this is a complex multi-step task, consider creating one\n   - Ensure the plan includes Intent, Plan steps, and Success Criteria sections\n\n3. **Proceed**: After documenting requirements and plan considerations, proceed with the implementation.${contextSection}`;\n\n    // Mark guidance as injected for this session\n    await markGuidanceInjected(input.session_id, input.cwd);\n\n    await logger.logOutput({\n      added_guidance: true,\n      guidance_length: guidance.length,\n      matched_contexts: matchedContexts.length,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'UserPromptSubmit',\n        additionalContext: guidance,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    // Non-blocking - just skip guidance on error\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/hooks/hooks.json": "{\n  \"_comment\": \"Enhanced Context Plugin - Context discovery, structure validation, and guidance\",\n  \"_notes\": [\n    \"Provides folder structure validation and context discovery\",\n    \"Tracks task/agent calls for context management\",\n    \"Validates folder structure for .claude directories\",\n    \"Discovers CLAUDE.md files for context enrichment\",\n    \"Encourages context updates on user prompts\",\n    \"Redirects WebFetch to markdown versions when available\"\n  ],\n  \"description\": \"Enhanced context discovery and maintenance for Claude Code\",\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/setup-nodes-config.ts\",\n            \"description\": \"Creates .nodes/.mcp.nodes.json config for the nodes-md MCP proxy\"\n          }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/encourage-context-review.ts\",\n            \"description\": \"Encourages updating plans, agents, skills, and CLAUDE.md files based on user prompts\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/shared/hooks/validate-folder-structure-write.ts\",\n          \"matcher\": \"Write\",\n          \"description\": \"Validates folder structure when creating .claude configuration files. Ensures proper directory organization for agents, hooks, skills, and rules.\"\n        },\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/shared/hooks/validate-rules-file.ts\",\n          \"matcher\": \"Write|Edit\",\n          \"description\": \"Validates rule file structure and frontmatter. Ensures rules have proper Required Skills metadata and valid YAML frontmatter.\"\n        }\n      ]\n    },\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/shared/hooks/validate-folder-structure-mkdir.ts\",\n          \"description\": \"Validates mkdir commands for .claude directories. Prevents creation of invalid or non-standard directory structures.\"\n        },\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/shared/hooks/use-correct-package-manager.ts\",\n          \"description\": \"Enforces correct package manager based on lockfiles. Blocks npm/yarn/pnpm/bun commands if wrong package manager detected.\"\n        }\n      ]\n    },\n    {\n      \"matcher\": \"WebFetch\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/try-markdown-page.ts\",\n          \"description\": \"Attempts to redirect WebFetch to markdown versions of documentation pages. Checks for .md versions of URLs and modifies fetch target if available.\"\n        }\n      ]\n    }\n  ],\n  \"SubagentStart\": [\n    {\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/inject-agent-context.ts\",\n          \"description\": \"Injects SERP-style context into subagents based on prompt matching against metadata-index.json.\"\n        }\n      ]\n    }\n  ],\n  \"PostToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/track-task-scope.ts\",\n          \"description\": \"Provides advisory when files are edited outside expected task scope. Non-blocking.\"\n        }\n      ]\n    },\n    {\n      \"matcher\": \"Read\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/add-folder-context.ts\",\n          \"description\": \"Discovers and adds CLAUDE.md context when reading files. Automatically enriches Claude's context with folder-level documentation.\"\n        }\n      ]\n    }\n  ],\n  \"SubagentStop\": [\n    {\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"npx tsx ${CLAUDE_PLUGIN_ROOT}/hooks/review-subagent-completion.ts\",\n          \"description\": \"Reviews subagent work completion against original task. Blocks Plan agents without plan files. Provides rules context for validation.\"\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Review if this Claude Code session should stop. Evaluate:\\n\\n1. Was the user's original request addressed?\\n2. Were all requested tasks completed?\\n3. Are there unfinished items or errors needing attention?\\n\\nFor exploration/review requests: can complete without code changes.\\nFor implementation requests: verify code was written and tested.\\n\\nReturn {\\\"ok\\\": true} to allow stopping, or {\\\"ok\\\": false, \\\"reason\\\": \\\"what remains\\\"} to continue.\",\n          \"timeout\": 60\n        }\n      ]\n    }\n  ]\n  },\n  \"_planned_features\": [\n    \"Generate code structure maps on SessionStart\",\n    \"Update maps when files are modified (PostToolUse)\",\n    \"Create navigation indexes for large codebases\",\n    \"Export architecture diagrams\",\n    \"Track code dependencies and relationships\"\n  ]\n}\n",
        "plugins/project-context/hooks/inject-agent-context.ts": "/**\n * SubagentStart hook - SERP-style context injection for subagents\n *\n * This hook fires when a subagent (Task tool) starts and injects relevant\n * context based on the agent's prompt. It matches the prompt against the\n * metadata index to find relevant folders and files, then formats them\n * as SERP-style output.\n *\n * The hook retrieves the task prompt from .claude/logs/task-calls.json\n * (saved by the PreToolUse[Task] log-task-call.ts hook) since SubagentStartInput\n * only provides agent_id and agent_type, not the prompt.\n *\n * @module inject-agent-context\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { readFile } from 'fs/promises';\nimport { join } from 'path';\nimport { existsSync } from 'fs';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Structure of the metadata index file\n */\ninterface MetadataIndex {\n  folders: FolderMetadata[];\n  files: FileMetadata[];\n}\n\ninterface FolderMetadata {\n  path: string;\n  tags: string[];\n  description?: string;\n}\n\ninterface FileMetadata {\n  path: string;\n  tags: string[];\n  description?: string;\n}\n\n/**\n * Structure of task-calls.json entries\n */\ninterface TaskCallContext {\n  toolUseId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n}\n\ninterface TaskCallsMap {\n  [toolUseId: string]: TaskCallContext;\n}\n\n/**\n * Match result for context matching\n */\ninterface MatchResult {\n  path: string;\n  matchedTags: string[];\n}\n\n// ============================================================================\n// Context Matching\n// ============================================================================\n\n/**\n * Extract keywords from a prompt for matching\n *\n * Tokenizes the prompt into lowercase words, filtering out common\n * stop words and short tokens.\n */\nfunction extractKeywords(prompt: string): string[] {\n  const stopWords = new Set([\n    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n    'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',\n    'could', 'should', 'may', 'might', 'must', 'shall', 'can', 'this',\n    'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n    'what', 'which', 'who', 'whom', 'where', 'when', 'why', 'how',\n    'all', 'each', 'every', 'both', 'few', 'more', 'most', 'other',\n    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n    'than', 'too', 'very', 'just', 'about', 'into', 'through', 'during',\n    'before', 'after', 'above', 'below', 'between', 'under', 'again',\n    'further', 'then', 'once', 'here', 'there', 'any', 'file', 'files',\n    'folder', 'folders', 'create', 'add', 'update', 'fix', 'make',\n    'please', 'need', 'want', 'like', 'use', 'using'\n  ]);\n\n  return prompt\n    .toLowerCase()\n    .replace(/[^a-z0-9\\s-]/g, ' ')\n    .split(/\\s+/)\n    .filter((word) => word.length > 2 && !stopWords.has(word));\n}\n\n/**\n * Match tags against keywords\n *\n * Returns the list of tags that match any of the keywords.\n * Uses substring matching for flexibility.\n */\nfunction matchTags(tags: string[], keywords: string[]): string[] {\n  const matched: string[] = [];\n\n  for (const tag of tags) {\n    const normalizedTag = tag.toLowerCase();\n    for (const keyword of keywords) {\n      if (normalizedTag.includes(keyword) || keyword.includes(normalizedTag)) {\n        matched.push(tag);\n        break;\n      }\n    }\n  }\n\n  return matched;\n}\n\n/**\n * Match folders and files against a prompt\n */\nfunction matchContext(\n  index: MetadataIndex,\n  prompt: string\n): { folders: MatchResult[]; files: MatchResult[] } {\n  const keywords = extractKeywords(prompt);\n\n  if (keywords.length === 0) {\n    return { folders: [], files: [] };\n  }\n\n  const folders: MatchResult[] = [];\n  const files: MatchResult[] = [];\n\n  // Match folders\n  for (const folder of index.folders) {\n    const matchedTags = matchTags(folder.tags, keywords);\n    if (matchedTags.length > 0) {\n      folders.push({ path: folder.path, matchedTags });\n    }\n  }\n\n  // Match files\n  for (const file of index.files) {\n    const matchedTags = matchTags(file.tags, keywords);\n    if (matchedTags.length > 0) {\n      files.push({ path: file.path, matchedTags });\n    }\n  }\n\n  // Sort by number of matched tags (descending)\n  folders.sort((a, b) => b.matchedTags.length - a.matchedTags.length);\n  files.sort((a, b) => b.matchedTags.length - a.matchedTags.length);\n\n  return { folders, files };\n}\n\n/**\n * Format matches as SERP-style output\n */\nfunction formatSerpOutput(matches: { folders: MatchResult[]; files: MatchResult[] }): string {\n  const lines: string[] = [];\n\n  if (matches.folders.length > 0) {\n    lines.push('Relevant Folders:');\n    for (const folder of matches.folders) {\n      const tagsStr = folder.matchedTags.map((t) => `\"${t}\"`).join(', ');\n      lines.push(`  - ${folder.path} (matches: ${tagsStr})`);\n    }\n  }\n\n  if (matches.files.length > 0) {\n    if (lines.length > 0) lines.push('');\n    lines.push('Relevant Files:');\n    for (const file of matches.files) {\n      const tagsStr = file.matchedTags.map((t) => `\"${t}\"`).join(', ');\n      lines.push(`  - ${file.path} (matches: ${tagsStr})`);\n    }\n  }\n\n  return lines.join('\\n');\n}\n\n// ============================================================================\n// Task Context Loading\n// ============================================================================\n\n/**\n * Load the most recent task call context from task-calls.json\n *\n * Since SubagentStart doesn't include the prompt, we need to look it up\n * from the task-calls.json file that was populated by log-task-call.ts\n */\nasync function loadMostRecentTaskPrompt(cwd: string): Promise<string | undefined> {\n  const taskCallsPath = join(cwd, '.claude', 'logs', 'task-calls.json');\n\n  if (!existsSync(taskCallsPath)) {\n    return undefined;\n  }\n\n  try {\n    const content = await readFile(taskCallsPath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n\n    // Get the most recent task call by timestamp\n    let mostRecent: TaskCallContext | undefined;\n    let mostRecentTime = 0;\n\n    for (const context of Object.values(contexts)) {\n      const time = new Date(context.timestamp).getTime();\n      if (time > mostRecentTime) {\n        mostRecentTime = time;\n        mostRecent = context;\n      }\n    }\n\n    return mostRecent?.prompt;\n  } catch {\n    return undefined;\n  }\n}\n\n// ============================================================================\n// Hook Handler\n// ============================================================================\n\n/**\n * SubagentStart hook that injects relevant context based on the agent's prompt\n *\n * This hook:\n * 1. Loads the metadata index from .claude/logs/metadata-index.json\n * 2. Retrieves the task prompt from task-calls.json\n * 3. Matches the prompt against folder/file tags\n * 4. Returns SERP-style formatted context via systemMessage\n *\n * @param input - SubagentStart hook input from Claude Code\n * @returns Hook output with matched context as systemMessage\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'inject-agent-context', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n    });\n\n    // Check if metadata index exists\n    const indexPath = join(input.cwd, '.claude', 'logs', 'metadata-index.json');\n    if (!existsSync(indexPath)) {\n      await logger.logOutput({ success: false, reason: 'No metadata index found' });\n      return {};\n    }\n\n    // Load metadata index\n    let index: MetadataIndex;\n    try {\n      const content = await readFile(indexPath, 'utf-8');\n      index = JSON.parse(content);\n    } catch {\n      await logger.logOutput({ success: false, reason: 'Failed to parse metadata index' });\n      return {};\n    }\n\n    // Get task prompt from task-calls.json\n    const prompt = await loadMostRecentTaskPrompt(input.cwd);\n    if (!prompt) {\n      await logger.logOutput({ success: false, reason: 'No task prompt found' });\n      return {};\n    }\n\n    // Match context\n    const matches = matchContext(index, prompt);\n\n    if (matches.folders.length === 0 && matches.files.length === 0) {\n      await logger.logOutput({\n        success: true,\n        matches: 0,\n        prompt: prompt.slice(0, 100),\n      });\n      return {};\n    }\n\n    // Format as SERP-style output\n    const contextOutput = formatSerpOutput(matches);\n\n    await logger.logOutput({\n      success: true,\n      folders: matches.folders.length,\n      files: matches.files.length,\n      prompt: prompt.slice(0, 100),\n    });\n\n    return {\n      systemMessage: contextOutput,\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error: unknown) {\n    // Non-blocking on errors\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Export utilities for testing\nexport { extractKeywords, matchTags, matchContext, formatSerpOutput, loadMostRecentTaskPrompt };\nexport type { MetadataIndex, FolderMetadata, FileMetadata, MatchResult, TaskCallContext, TaskCallsMap };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/hooks/review-subagent-completion.ts": "/**\n * SubagentStop hook - Reviews subagent work completion\n *\n * This hook fires when a subagent completes and reviews its work against\n * the original task. It:\n * - Never blocks Explore agents (informational)\n * - Blocks Plan agents if no plan file was created\n * - Provides context with matching rules for other agents\n *\n * @module review-subagent-completion\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getTaskEdits } from '../shared/hooks/utils/task-state.js';\nimport { discoverRules, matchRulesToFiles, formatRulesContext } from '../shared/hooks/utils/rules-matcher.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\n/** Agent types that should never be blocked */\nconst NON_BLOCKING_AGENT_TYPES = ['explore', 'claude-code-guide'];\n\n/** File patterns that indicate a plan was created */\nconst PLAN_FILE_PATTERNS = ['.claude/plans/', '/plans/', 'PLAN.md', 'plan.md'];\n\n// ============================================================================\n// Helpers\n// ============================================================================\n\n/**\n * Check if a file path looks like a plan file\n */\nfunction isPlanFile(filePath: string): boolean {\n  return PLAN_FILE_PATTERNS.some((pattern) => filePath.includes(pattern));\n}\n\n/**\n * Normalize agent type for comparison (lowercase, trim)\n */\nfunction normalizeAgentType(agentType: string): string {\n  return agentType.toLowerCase().trim();\n}\n\n// ============================================================================\n// Hook Handler\n// ============================================================================\n\n/**\n * SubagentStop hook that reviews subagent work completion\n *\n * Blocking behavior:\n * - Explore agents: Never blocked (informational)\n * - Plan agents: Blocked if no plan file created\n * - Other agents: Non-blocking advisory with rules context\n *\n * @param input - SubagentStop hook input from Claude Code\n * @returns Hook output with optional blocking decision or systemMessage\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'review-subagent-completion', true);\n\n  try {\n    await logger.logInput({\n      agent_id: input.agent_id,\n      agent_transcript_path: input.agent_transcript_path,\n    });\n\n    // Get task edits and context\n    let edits;\n    try {\n      edits = await getTaskEdits(input.agent_transcript_path);\n    } catch (error) {\n      // If we can't get task edits, don't block\n      await logger.logOutput({\n        success: false,\n        reason: 'Failed to get task edits',\n        error: error instanceof Error ? error.message : String(error),\n      });\n      return {};\n    }\n\n    const agentType = normalizeAgentType(edits.subagentType);\n\n    // Never block Explore or other informational agents\n    if (NON_BLOCKING_AGENT_TYPES.includes(agentType)) {\n      await logger.logOutput({\n        success: true,\n        agentType,\n        action: 'passthrough',\n        reason: 'Non-blocking agent type',\n      });\n      return {};\n    }\n\n    // For Plan agents, check if a plan file was created\n    if (agentType === 'plan') {\n      const allFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n      const planCreated = allFiles.some(isPlanFile);\n\n      if (!planCreated && allFiles.length === 0) {\n        await logger.logOutput({\n          success: true,\n          agentType,\n          action: 'block',\n          reason: 'No plan file created',\n        });\n        return {\n          decision: 'block',\n          reason: 'Plan agent completed without creating or updating a plan file. Please create a plan in .claude/plans/ before completing.',\n        };\n      }\n    }\n\n    // For other agents, find matching rules and provide context\n    const allEditedFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n\n    if (allEditedFiles.length === 0) {\n      await logger.logOutput({\n        success: true,\n        agentType,\n        action: 'passthrough',\n        reason: 'No files modified',\n      });\n      return {};\n    }\n\n    // Discover and match rules\n    const rules = await discoverRules(input.cwd);\n    const matchingRules = matchRulesToFiles(rules, allEditedFiles, input.cwd);\n    const rulesContext = formatRulesContext(matchingRules);\n\n    // Build review context\n    const promptPreview = edits.agentPrompt.length > 500\n      ? edits.agentPrompt.slice(0, 500) + '...'\n      : edits.agentPrompt;\n\n    const contextLines: string[] = [\n      '## Subagent Completion Review',\n      '',\n      `**Task:** ${promptPreview}`,\n      `**Agent Type:** ${edits.subagentType}`,\n      `**Files Created:** ${edits.agentNewFiles.length} | **Edited:** ${edits.agentEditedFiles.length}`,\n    ];\n\n    if (edits.agentDeletedFiles.length > 0) {\n      contextLines.push(`**Files Deleted:** ${edits.agentDeletedFiles.length}`);\n    }\n\n    if (rulesContext) {\n      contextLines.push('', rulesContext);\n    }\n\n    contextLines.push('', 'Verify the task was completed and any applicable rules were followed.');\n\n    await logger.logOutput({\n      success: true,\n      agentType,\n      action: 'context',\n      filesCreated: edits.agentNewFiles.length,\n      filesEdited: edits.agentEditedFiles.length,\n      matchingRules: matchingRules.length,\n    });\n\n    return {\n      systemMessage: contextLines.join('\\n'),\n    };\n  } catch (error: unknown) {\n    // Non-blocking on errors\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Export helpers for testing\nexport { isPlanFile, normalizeAgentType, NON_BLOCKING_AGENT_TYPES, PLAN_FILE_PATTERNS };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/hooks/run-file-eslint.ts": "/**\n * ESLint check for PostToolUse[Write|Edit] hooks\n *\n * Runs eslint on the edited file and blocks if there are errors.\n * Only runs on .ts, .tsx, .js, .jsx files.\n *\n * @module run-file-eslint\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for eslint in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to lint */\nconst LINT_EXTENSIONS = ['.ts', '.tsx', '.js', '.jsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if file should be linted based on extension\n */\nfunction shouldLint(filePath: string): boolean {\n  return LINT_EXTENSIONS.some((ext) => filePath.endsWith(ext));\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs eslint on the edited file. Blocks if eslint fails.\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath || !shouldLint(filePath)) {\n    return {};\n  }\n\n  // Find eslint config directory\n  let eslintConfigDir = await findConfigFile(input.cwd, 'eslint.config.mjs');\n\n  // Try alternative flat config format\n  if (!eslintConfigDir) {\n    eslintConfigDir = await findConfigFile(input.cwd, 'eslint.config.js');\n  }\n\n  if (!eslintConfigDir) {\n    // No ESLint flat config found - skip validation with warning\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠️ ESLint config not found (searched from ${input.cwd} to git root). Skipping lint check. Expected: eslint.config.mjs or eslint.config.js`,\n      },\n    };\n  }\n\n  // Run eslint\n  const command = `npx eslint --max-warnings 0 \"${filePath}\"`;\n\n  try {\n    await execAsync(command, {\n      cwd: eslintConfigDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // ESLint passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ ESLint passed`,\n      },\n    };\n  } catch (error) {\n    // ESLint failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'ESLint failed';\n\n    return {\n      decision: 'block',\n      reason: `Fix ESLint errors before continuing:\\n\\n${truncateOutput(output)}`,\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `❌ ESLint failed:\\n\\n${truncateOutput(output)}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/run-file-vitests.ts": "/**\n * Vitest check for PostToolUse[Write|Edit] hooks\n *\n * Runs vitest for related tests when a file is edited.\n * Non-blocking - only warns if tests fail.\n * Only runs on .ts, .tsx files.\n *\n * @module run-file-vitests\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { access } from 'fs/promises';\nimport { basename, dirname, join, relative, isAbsolute } from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for vitest in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to check for tests */\nconst TEST_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if file should have tests checked\n */\nfunction shouldCheckTests(filePath: string): boolean {\n  // Don't run tests for test files themselves\n  if (filePath.includes('.test.') || filePath.includes('.spec.')) {\n    return false;\n  }\n  return TEST_EXTENSIONS.some((ext) => filePath.endsWith(ext));\n}\n\n/**\n * Find the test file for a given source file\n * Looks for foo.test.ts or foo.test.tsx next to the source file\n */\nasync function findTestFile(filePath: string): Promise<string | null> {\n  const dir = dirname(filePath);\n  const base = basename(filePath);\n\n  // Remove extension to get base name\n  const extMatch = base.match(/\\.(ts|tsx)$/);\n  if (!extMatch) return null;\n\n  const nameWithoutExt = base.slice(0, -extMatch[0].length);\n\n  // Try .test.ts and .test.tsx\n  for (const ext of ['.test.ts', '.test.tsx']) {\n    const testPath = join(dir, nameWithoutExt + ext);\n    try {\n      await access(testPath);\n      return testPath;\n    } catch {\n      // File doesn't exist\n    }\n  }\n\n  return null;\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs vitest for related tests. Non-blocking - warns only.\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath || !shouldCheckTests(filePath)) {\n    return {};\n  }\n\n  // Find related test file\n  const testFile = await findTestFile(filePath);\n\n  if (!testFile) {\n    // No test file found, skip silently\n    return {};\n  }\n\n  // Find vitest config\n  let vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.ts');\n\n  // Try alternative configs\n  if (!vitestConfigDir) {\n    vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.js');\n  }\n  if (!vitestConfigDir) {\n    vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.mjs');\n  }\n\n  // Fallback to input.cwd if no config found\n  const runDir = vitestConfigDir || input.cwd;\n\n  // Make test file path relative to run directory\n  const relativeTestFile = isAbsolute(testFile)\n    ? relative(runDir, testFile)\n    : testFile;\n\n  // Run vitest for the test file\n  const command = `npx vitest run \"${relativeTestFile}\" --reporter=verbose`;\n\n  try {\n    await execAsync(command, {\n      cwd: runDir,\n      timeout: TIMEOUT_MS,\n    });\n\n    // Tests passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ Tests passed for ${basename(testFile)}`,\n      },\n    };\n  } catch (error) {\n    // Tests failed - warn but don't block\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'Tests failed';\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `⚠️ Tests failed for ${basename(testFile)}:\\n\\n${truncateOutput(output)}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/run-task-typechecks.ts": "/**\n * TypeScript check for SubagentStop hooks\n *\n * Runs tsc --noEmit on the project after a subagent completes.\n * Blocks if there are type errors.\n *\n * @module run-task-typechecks\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getAgentEdits } from '../shared/hooks/utils/subagent-state.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for tsc in milliseconds (60 seconds - tsc can be slow) */\nconst TIMEOUT_MS = 60000;\n\n/** File extensions that trigger typecheck */\nconst TS_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Check if any edited files are TypeScript\n */\nfunction hasTypeScriptFiles(files: string[]): boolean {\n  return files.some((file) =>\n    TS_EXTENSIONS.some((ext) => file.endsWith(ext))\n  );\n}\n\n/**\n * SubagentStop hook handler\n *\n * Runs tsc --noEmit on the project. Blocks if typecheck fails.\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task-typechecks');\n\n  if (DEBUG) {\n    console.log('[run-task-typechecks] Hook triggered');\n    console.log('[run-task-typechecks] Agent ID:', input.agent_id);\n  }\n\n  try {\n    // Get all files edited by the agent\n    const edits = await getAgentEdits(input.agent_transcript_path);\n    const allEditedFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n\n    if (DEBUG) {\n      console.log('[run-task-typechecks] Edited files:', allEditedFiles.length);\n    }\n\n    // Only run typecheck if TypeScript files were edited\n    if (!hasTypeScriptFiles(allEditedFiles)) {\n      if (DEBUG) {\n        console.log('[run-task-typechecks] No TypeScript files edited, skipping');\n      }\n      return {};\n    }\n\n    // Find tsconfig.json\n    const tsconfigDir = await findConfigFile(input.cwd, 'tsconfig.json');\n\n    if (!tsconfigDir) {\n      // No tsconfig.json found - skip with warning (per user preference)\n      if (DEBUG) {\n        console.warn(`[run-task-typechecks] TypeScript configuration (tsconfig.json) not found. Searched from ${input.cwd} to git root. Skipping type check.`);\n      }\n      return {};\n    }\n\n    // Run tsc --noEmit on the project\n    const command = 'npx tsc --noEmit';\n\n    if (DEBUG) {\n      console.log('[run-task-typechecks] Running:', command);\n      console.log('[run-task-typechecks] Config dir:', tsconfigDir);\n    }\n\n    try {\n      await execAsync(command, {\n        cwd: tsconfigDir,\n        timeout: TIMEOUT_MS,\n      });\n\n      // Typecheck passed\n      return {};\n    } catch (error) {\n      // Typecheck failed\n      const err = error as { stdout?: string; stderr?: string; message?: string };\n      const output = err.stdout || err.stderr || err.message || 'TypeScript check failed';\n\n      return {\n        decision: 'block',\n        reason: `Fix TypeScript errors before continuing:\\n\\n${truncateOutput(output)}`,\n      };\n    }\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[run-task-typechecks] Error:', error);\n    }\n    // Don't block on transcript parsing errors\n    return {};\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/run-task-vitests.ts": "/**\n * Vitest check for SubagentStop hooks\n *\n * Runs vitest for all files edited during the agent's task.\n * Blocks if tests fail.\n *\n * @module run-task-vitests\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { getAgentEdits } from '../shared/hooks/utils/subagent-state.js';\nimport { findConfigFile } from '../shared/hooks/utils/config-resolver.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport * as path from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for vitest in milliseconds (30 seconds) */\nconst TIMEOUT_MS = 30000;\n\n/** File extensions to check for tests */\nconst TEST_EXTENSIONS = ['.ts', '.tsx'];\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * Filter to only testable files\n */\nfunction getTestableFiles(files: string[]): string[] {\n  return files.filter((file) => {\n    // Skip test files themselves\n    if (file.includes('.test.') || file.includes('.spec.')) {\n      return false;\n    }\n    return TEST_EXTENSIONS.some((ext) => file.endsWith(ext));\n  });\n}\n\n/**\n * SubagentStop hook handler\n *\n * Runs vitest related for all edited files. Blocks if tests fail.\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task-vitests');\n\n  if (DEBUG) {\n    console.log('[run-task-vitests] Hook triggered');\n    console.log('[run-task-vitests] Agent ID:', input.agent_id);\n  }\n\n  try {\n    // Get all files edited by the agent\n    const edits = await getAgentEdits(input.agent_transcript_path);\n    const allEditedFiles = [...edits.agentNewFiles, ...edits.agentEditedFiles];\n    const testableFiles = getTestableFiles(allEditedFiles);\n\n    if (DEBUG) {\n      console.log('[run-task-vitests] Edited files:', allEditedFiles.length);\n      console.log('[run-task-vitests] Testable files:', testableFiles.length);\n    }\n\n    if (testableFiles.length === 0) {\n      // No testable files, skip\n      return {};\n    }\n\n    // Find vitest config\n    let vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.ts');\n\n    // Try alternative config formats\n    if (!vitestConfigDir) {\n      vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.js');\n    }\n    if (!vitestConfigDir) {\n      vitestConfigDir = await findConfigFile(input.cwd, 'vitest.config.mjs');\n    }\n\n    // Fallback to input.cwd if no config found (Vitest has defaults)\n    const runDir = vitestConfigDir || input.cwd;\n\n    if (!vitestConfigDir && DEBUG) {\n      console.warn(`[run-task-vitests] No vitest config found (searched from ${input.cwd}). Running with defaults.`);\n    }\n\n    // Make file paths relative to run directory\n    const relativeFiles = testableFiles.map(f => {\n      if (path.isAbsolute(f)) {\n        return path.relative(runDir, f);\n      }\n      return f;\n    });\n\n    // Run vitest related for all edited files\n    const filesArg = relativeFiles.map((f) => `\"${f}\"`).join(' ');\n    const command = `npx vitest related ${filesArg} --run --reporter=verbose`;\n\n    if (DEBUG) {\n      console.log('[run-task-vitests] Running:', command);\n      console.log('[run-task-vitests] Config dir:', runDir);\n    }\n\n    try {\n      await execAsync(command, {\n        cwd: runDir,\n        timeout: TIMEOUT_MS,\n      });\n\n      // Tests passed\n      return {};\n    } catch (error) {\n      // Tests failed\n      const err = error as { stdout?: string; stderr?: string; message?: string };\n      const output = err.stdout || err.stderr || err.message || 'Tests failed';\n\n      return {\n        decision: 'block',\n        reason: `Fix test failures before continuing:\\n\\n${truncateOutput(output)}`,\n      };\n    }\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[run-task-vitests] Error:', error);\n    }\n    // Don't block on transcript parsing errors\n    return {};\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/setup-nodes-config.ts": "/**\n * Nodes MCP Config Setup Hook\n * SessionStart hook that creates .nodes/.mcp.nodes.json config for the nodes-md proxy.\n * Merges with existing config if present (for multi-plugin support).\n * @module setup-nodes-config\n */\n\nimport type { SessionStartInput, SessionStartHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { existsSync, mkdirSync, readFileSync, writeFileSync, appendFileSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Nodes MCP server configuration\n */\ninterface NodesServer {\n  transport: 'stdio' | 'sse';\n  command?: string;\n  args?: string[];\n  url?: string;\n}\n\n/**\n * Nodes MCP config file structure\n */\ninterface NodesConfig {\n  servers: Record<string, NodesServer>;\n}\n\n/**\n * Servers this plugin contributes to the nodes config\n */\nconst PLUGIN_SERVERS: Record<string, NodesServer> = {\n  context7: {\n    transport: 'stdio',\n    command: 'npx',\n    args: ['-y', '@upstash/context7-mcp@latest'],\n  },\n};\n\n/**\n * Load existing nodes config or return empty config\n */\nfunction loadNodesConfig(configPath: string): NodesConfig {\n  if (existsSync(configPath)) {\n    try {\n      const content = readFileSync(configPath, 'utf-8');\n      return JSON.parse(content) as NodesConfig;\n    } catch {\n      // Invalid JSON, start fresh\n      return { servers: {} };\n    }\n  }\n  return { servers: {} };\n}\n\n/**\n * Add .nodes/ to .gitignore if not already present\n */\nfunction addToGitignore(cwd: string): boolean {\n  const gitignorePath = join(cwd, '.gitignore');\n\n  if (existsSync(gitignorePath)) {\n    const content = readFileSync(gitignorePath, 'utf-8');\n    if (content.includes('.nodes/') || content.includes('.nodes')) {\n      return false; // Already present\n    }\n    appendFileSync(gitignorePath, '\\n# nodes-md MCP config\\n.nodes/\\n');\n    return true;\n  } else {\n    writeFileSync(gitignorePath, '# nodes-md MCP config\\n.nodes/\\n');\n    return true;\n  }\n}\n\n/**\n * SessionStart hook handler\n * Creates .nodes/.mcp.nodes.json with this plugin's servers\n */\nasync function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n  const logger = createDebugLogger(input.cwd, 'setup-nodes-config', true);\n  const messages: string[] = [];\n\n  try {\n    await logger.logInput({\n      source: input.source,\n      session_id: input.session_id,\n    });\n\n    const nodesDir = join(input.cwd, '.nodes');\n    const configPath = join(nodesDir, '.mcp.nodes.json');\n\n    // Create .nodes directory if needed\n    if (!existsSync(nodesDir)) {\n      mkdirSync(nodesDir, { recursive: true });\n      messages.push('Created .nodes/ directory');\n    }\n\n    // Load existing config and merge\n    const config = loadNodesConfig(configPath);\n    const existingServers = Object.keys(config.servers);\n    const newServers: string[] = [];\n\n    // Merge plugin servers (this plugin's servers take precedence)\n    for (const [name, server] of Object.entries(PLUGIN_SERVERS)) {\n      if (!config.servers[name]) {\n        newServers.push(name);\n      }\n      config.servers[name] = server;\n    }\n\n    // Write updated config\n    writeFileSync(configPath, JSON.stringify(config, null, 2) + '\\n');\n\n    if (newServers.length > 0) {\n      messages.push(`Added servers to .nodes config: ${newServers.join(', ')}`);\n    } else {\n      messages.push('Nodes config up to date');\n    }\n\n    if (existingServers.length > 0) {\n      const otherServers = existingServers.filter((s) => !PLUGIN_SERVERS[s]);\n      if (otherServers.length > 0) {\n        messages.push(`Other servers in config: ${otherServers.join(', ')}`);\n      }\n    }\n\n    // Add to .gitignore\n    if (addToGitignore(input.cwd)) {\n      messages.push('Added .nodes/ to .gitignore');\n    }\n\n    const finalMessage = messages.join('\\n');\n\n    await logger.logOutput({\n      success: true,\n      message: finalMessage,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: finalMessage,\n      },\n    };\n  } catch (error) {\n    await logger.logError(error as Error);\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SessionStart',\n        additionalContext: `Nodes config setup error: ${error}`,\n      },\n    };\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/track-task-scope.ts": "/**\n * Task scope advisory hook for PostToolUse[Write|Edit]\n *\n * Provides advisory warnings when files are edited outside their expected\n * task scope. Parses the active plan file in `.claude/plans/` to find task\n * definitions and checks if the edited file matches a different task.\n *\n * This is a non-blocking advisory hook - it only provides context to Claude\n * about potential task scope issues, it does not prevent the edit.\n *\n * @module track-task-scope\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../shared/types/types.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { parsePlanFrontmatter, findTaskByPath } from '../shared/hooks/utils/plan-parser.js';\nimport { readdir, readFile, stat } from 'fs/promises';\nimport { join, relative } from 'path';\nimport { existsSync } from 'fs';\n\n/**\n * Get the most recently modified plan file from .claude/plans/\n *\n * @param cwd - Current working directory\n * @returns Path to the active plan file, or null if none found\n */\nasync function getActivePlanFile(cwd: string): Promise<string | null> {\n  const plansDir = join(cwd, '.claude', 'plans');\n\n  if (!existsSync(plansDir)) {\n    return null;\n  }\n\n  try {\n    const entries = await readdir(plansDir, { withFileTypes: true });\n    const planFiles: { path: string; mtime: Date }[] = [];\n\n    for (const entry of entries) {\n      if (entry.isFile() && entry.name.endsWith('.md')) {\n        const filePath = join(plansDir, entry.name);\n        const stats = await stat(filePath);\n        planFiles.push({ path: filePath, mtime: stats.mtime });\n      }\n    }\n\n    if (planFiles.length === 0) {\n      return null;\n    }\n\n    // Sort by modification time, most recent first\n    planFiles.sort((a, b) => b.mtime.getTime() - a.mtime.getTime());\n\n    return planFiles[0].path;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Checks if the edited file falls within the scope of a different task\n * than the current context suggests, and provides an advisory warning.\n *\n * @param input - PostToolUse hook input from Claude Code\n * @returns Hook output with optional advisory context\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  const logger = createDebugLogger(input.cwd, 'track-task-scope', true);\n\n  try {\n    // Get file path from tool input\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput?.file_path;\n\n    if (!filePath) {\n      return {};\n    }\n\n    await logger.logInput({\n      tool_name: input.tool_name,\n      file_path: filePath,\n    });\n\n    // Find the active plan file\n    const activePlan = await getActivePlanFile(input.cwd);\n\n    if (!activePlan) {\n      await logger.logOutput({ success: true, reason: 'No plan file found' });\n      return {};\n    }\n\n    // Read and parse the plan file\n    const planContent = await readFile(activePlan, 'utf-8');\n    const metadata = parsePlanFrontmatter(planContent);\n\n    if (!metadata || metadata.tasks.length === 0) {\n      await logger.logOutput({ success: true, reason: 'No tasks in plan' });\n      return {};\n    }\n\n    // Get relative path for matching\n    const relativePath = relative(input.cwd, filePath);\n\n    // Find if any task owns this file\n    const matchingTask = findTaskByPath(metadata.tasks, relativePath);\n\n    if (!matchingTask) {\n      // File doesn't match any task scope - no advisory needed\n      await logger.logOutput({ success: true, reason: 'File not in any task scope' });\n      return {};\n    }\n\n    // We found a matching task - provide advisory context\n    // The hook doesn't know the \"current\" task context, so we just inform\n    // which task this file belongs to\n    const advisory = `Task Scope Advisory: File '${relativePath}' matches task '${matchingTask.id}' assigned to agent '${matchingTask.agent}'.\\nCurrent task context may differ.`;\n\n    await logger.logOutput({\n      success: true,\n      file: relativePath,\n      matchingTask: matchingTask.id,\n      agent: matchingTask.agent,\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: advisory,\n      },\n    };\n  } catch (error: unknown) {\n    // Non-blocking on errors - just log and return empty\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/hooks/try-markdown-page.ts": "/**\n * Markdown URL preference hook for WebFetch\n *\n * PreToolUse hook that intercepts WebFetch calls and attempts to redirect\n * to markdown versions of documentation pages when available. This provides\n * better AI-friendly content for documentation parsing.\n *\n * The hook tries multiple strategies to find markdown versions:\n * 1. GitHub documentation: Convert to raw.githubusercontent.com URLs\n * 2. HTML pages: Try changing .html extension to .md\n * 3. Documentation sites: Try appending .md to the path\n *\n * If a markdown version is found (via HTTP HEAD request), the WebFetch URL\n * is automatically redirected. Otherwise, the original URL is used.\n *\n * @module try-markdown-page\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../shared/types/types.js';\nimport { createDebugLogger } from '../shared/hooks/utils/debug.js';\nimport { runHook } from '../shared/hooks/utils/io.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/**\n * Check if a URL returns a successful response (200-299 status code)\n *\n * Uses curl with a HEAD request to efficiently check URL availability\n * without downloading the full content.\n *\n * @param url - The URL to check\n * @returns True if the URL exists and is accessible, false otherwise\n *\n * @example\n * ```typescript\n * const exists = await urlExists('https://example.com/docs/guide.md');\n * if (exists) {\n *   console.log('Markdown version found!');\n * }\n * ```\n */\nasync function urlExists(url: string): Promise<boolean> {\n  try {\n    // Use curl with HEAD request and follow redirects\n    // -s: silent, -f: fail on error, -I: HEAD request, -L: follow redirects\n    // -o /dev/null: discard output, --max-time 5: 5 second timeout\n    const { stdout } = await execAsync(\n      `curl -s -I -L --max-time 5 \"${url}\" | head -n 1`\n    );\n\n    // Check if response starts with HTTP and contains 2xx status code\n    return /HTTP\\/[\\d.]+ 2\\d\\d/.test(stdout);\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Transform a URL to try various markdown versions\n *\n * Generates candidate URLs that might contain markdown versions of the content.\n * Strategies include:\n * - GitHub: Convert to raw.githubusercontent.com\n * - HTML files: Change .html to .md\n * - Documentation: Try appending .md\n *\n * @param url - The original URL from WebFetch\n * @returns Array of candidate markdown URLs to try\n *\n * @example\n * ```typescript\n * const candidates = getMarkdownCandidates('https://github.com/user/repo/blob/main/docs/guide.html');\n * // Returns: ['https://raw.githubusercontent.com/user/repo/main/docs/guide.md', ...]\n * ```\n */\nfunction getMarkdownCandidates(url: string): string[] {\n  const candidates: string[] = [];\n\n  try {\n    const urlObj = new URL(url);\n\n    // GitHub repository pages -> raw.githubusercontent.com\n    if (urlObj.hostname === 'github.com') {\n      const match = urlObj.pathname.match(/^\\/([^/]+)\\/([^/]+)\\/blob\\/([^/]+)\\/(.+)$/);\n      if (match) {\n        const [, owner, repo, branch, path] = match;\n\n        // Try changing extension to .md\n        const mdPath = path.replace(/\\.(html?|htm)$/i, '.md');\n        candidates.push(`https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${mdPath}`);\n\n        // If path doesn't have extension, try adding .md\n        if (!/\\.\\w+$/.test(path)) {\n          candidates.push(`https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${path}.md`);\n        }\n      }\n\n      // GitHub tree/main page -> try docs/README.md\n      const treeMatch = urlObj.pathname.match(/^\\/([^/]+)\\/([^/]+)\\/tree\\/([^/]+)\\/(.+)$/);\n      if (treeMatch) {\n        const [, owner, repo, branch, path] = treeMatch;\n        candidates.push(`https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${path}/README.md`);\n        candidates.push(`https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${path}.md`);\n      }\n    }\n\n    // For any URL, try changing .html to .md\n    if (urlObj.pathname.match(/\\.(html?|htm)$/i)) {\n      const mdUrl = url.replace(/\\.(html?|htm)$/i, '.md');\n      candidates.push(mdUrl);\n    }\n\n    // For any URL without extension, try adding .md\n    if (!/\\.\\w+$/.test(urlObj.pathname) && !urlObj.pathname.endsWith('/')) {\n      candidates.push(url + '.md');\n    }\n\n  } catch {\n    // Invalid URL, return empty array\n    return [];\n  }\n\n  return candidates;\n}\n\n/**\n * PreToolUse hook that redirects WebFetch to markdown versions when available\n *\n * Intercepts WebFetch tool calls and attempts to find markdown versions of\n * the requested URL. If a markdown version is found and accessible, the\n * tool input is modified to fetch that URL instead.\n *\n * The hook is non-blocking and fails gracefully - if no markdown version\n * is found or if URL checking fails, the original WebFetch proceeds.\n *\n * @param input - PreToolUse hook input from Claude Code\n * @returns Hook output with potentially modified tool_input for markdown URL\n *\n * @example\n * ```typescript\n * // When WebFetch is called with:\n * const result = await handler({\n *   tool_name: 'WebFetch',\n *   tool_use_id: 'toolu_123',\n *   tool_input: {\n *     url: 'https://github.com/vercel/next.js/blob/canary/docs/app/guide.html',\n *     prompt: 'Get routing documentation'\n *   },\n *   // ... other fields\n * });\n *\n * // If https://raw.githubusercontent.com/.../docs/app/guide.md exists:\n * // Returns modified tool_input with markdown URL and additional context\n * ```\n */\nasync function handler(\n  input: PreToolUseInput\n): Promise<PreToolUseHookOutput> {\n  // Only run for WebFetch operations\n  if (input.tool_name !== 'WebFetch') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'try-markdown-page', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Extract URL from tool input\n    const toolInput = input.tool_input as { url?: string; prompt?: string };\n    const originalUrl = toolInput?.url;\n\n    if (!originalUrl) {\n      await logger.logOutput({ success: false, reason: 'No URL in tool input' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get markdown URL candidates\n    const candidates = getMarkdownCandidates(originalUrl);\n\n    if (candidates.length === 0) {\n      await logger.logOutput({\n        success: true,\n        reason: 'No markdown candidates generated',\n        originalUrl,\n      });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Try each candidate until we find one that exists\n    for (const candidateUrl of candidates) {\n      const exists = await urlExists(candidateUrl);\n\n      if (exists) {\n        await logger.logOutput({\n          success: true,\n          originalUrl,\n          markdownUrl: candidateUrl,\n          redirected: true,\n        });\n\n        // Modify the tool input to use the markdown URL\n        return {\n          hookSpecificOutput: {\n            hookEventName: 'PreToolUse',\n            permissionDecision: 'allow',\n            updatedInput: {\n              ...toolInput,\n              url: candidateUrl,\n            },\n          },\n          systemMessage: `📝 Found markdown version: redirecting from ${originalUrl} to ${candidateUrl}`,\n        };\n      }\n    }\n\n    // No markdown version found, let original request proceed\n    await logger.logOutput({\n      success: true,\n      originalUrl,\n      candidates,\n      redirected: false,\n      reason: 'No accessible markdown versions found',\n    });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    // Non-blocking on errors - let original WebFetch proceed\n    await logger.logError(error as Error);\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/enforce-output-style-tools.ts": "#!/usr/bin/env npx tsx\n\n/**\n * Output style tool enforcement hook\n *\n * PreToolUse hook that enforces tool restrictions defined in output style frontmatter.\n * When an output style specifies a `tools` array in its frontmatter, only those tools\n * are allowed for the main agent. Subagents can use any tools they need.\n *\n * This enables output styles to restrict Claude's capabilities to specific tools,\n * for example:\n * - Read-only mode: only Read, Glob, Grep tools\n * - Research mode: Read, Glob, Grep, WebSearch, WebFetch\n * - Full mode: all tools allowed (no restrictions)\n *\n * Output style files are located in .claude/output-styles/ with frontmatter like:\n * ```yaml\n * ---\n * name: read-only\n * description: Read-only access to codebase\n * tools: [Read, Glob, Grep]\n * ---\n * ```\n *\n * @module enforce-output-style-tools\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { runHook, wasToolEventMainAgent } from './utils/index.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('output-styles-permission-modes');\n\ninterface OutputStyleFrontmatter {\n  name?: string;\n  description?: string;\n  tools?: string[];\n}\n\n/**\n * Read settings.json to get the current output style name\n *\n * Checks both settings.local.json (project-specific) and settings.json (committed)\n * for the outputStyle configuration. Returns the first match found.\n *\n * @param cwd - The working directory to search for settings files\n * @returns The output style name, or undefined if not configured\n *\n * @example\n * ```typescript\n * const styleName = await getCurrentOutputStyle('/path/to/project');\n * console.log(styleName); // 'read-only' or undefined\n * ```\n */\nasync function getCurrentOutputStyle(cwd: string): Promise<string | undefined> {\n  const settingsPaths = [\n    path.join(cwd, '.claude', 'settings.local.json'),\n    path.join(cwd, '.claude', 'settings.json'),\n  ];\n\n  for (const settingsPath of settingsPaths) {\n    try {\n      const content = await fs.readFile(settingsPath, 'utf-8');\n      const settings = JSON.parse(content);\n      if (settings.outputStyle) {\n        return settings.outputStyle;\n      }\n    } catch {\n      // File doesn't exist or is invalid JSON, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Load and parse output style file to get frontmatter\n *\n * Reads the output style markdown file and extracts its YAML frontmatter,\n * which contains the style configuration including tool restrictions.\n *\n * @param cwd - The working directory where output styles are stored\n * @param styleName - The name of the output style (without .md extension)\n * @returns The parsed frontmatter, or undefined if file not found\n *\n * @example\n * ```typescript\n * const frontmatter = await loadOutputStyleFrontmatter(\n *   '/path/to/project',\n *   'read-only'\n * );\n *\n * if (frontmatter) {\n *   console.log('Allowed tools:', frontmatter.tools);\n *   // ['Read', 'Glob', 'Grep']\n * }\n * ```\n */\nasync function loadOutputStyleFrontmatter(\n  cwd: string,\n  styleName: string\n): Promise<OutputStyleFrontmatter | undefined> {\n  const stylePaths = [\n    path.join(cwd, '.claude', 'output-styles', `${styleName}.md`),\n    // Note: User-level styles would be in ~/.claude/output-styles/\n    // but we can't easily access user home in hooks without assumptions\n  ];\n\n  for (const stylePath of stylePaths) {\n    try {\n      const content = await fs.readFile(stylePath, 'utf-8');\n      const { data } = matter(content);\n      return data as OutputStyleFrontmatter;\n    } catch {\n      // File doesn't exist, try next path\n      continue;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * PreToolUse hook that enforces tool restrictions from output style frontmatter\n *\n * Checks if the current tool is allowed by the active output style's tool restrictions.\n * This hook only applies to the main agent - subagents can use any tools they need\n * to complete their tasks.\n *\n * The enforcement flow:\n * 1. Check if this is the main agent (skip for subagents)\n * 2. Read current output style from settings.json\n * 3. Load output style frontmatter to get allowed tools list\n * 4. Check if current tool is in the allowed list\n * 5. Allow or deny based on the check\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Example output style: .claude/output-styles/read-only.md\n * // ---\n * // name: read-only\n * // tools: [Read, Glob, Grep]\n * // ---\n *\n * // Settings: .claude/settings.json\n * // { \"outputStyle\": \"read-only\" }\n *\n * // When main agent tries to use Read tool:\n * const result = await handler({\n *   tool_name: 'Read',\n *   tool_use_id: 'toolu_123',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // When main agent tries to use Write tool (not in allowed list):\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   transcript_path: '/path/.claude/logs/session-abc.jsonl',\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'The \"Write\" tool is not allowed...'\n * //   }\n * // }\n *\n * // When subagent tries to use Write tool:\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   transcript_path: '/path/.claude/logs/agent-xyz.jsonl', // Subagent transcript\n *   cwd: '/path/to/project'\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * // (Subagents are never restricted)\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Hook triggered');\n    console.log('[enforce-output-style-tools] Tool:', input.tool_name);\n  }\n\n  // Only enforce for main agent, not subagents\n  const isMainAgent = await wasToolEventMainAgent(input.transcript_path, input.tool_use_id);\n  if (!isMainAgent) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Subagent detected, skipping enforcement');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Get current output style\n  const styleName = await getCurrentOutputStyle(input.cwd);\n  if (!styleName) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No output style configured, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Current output style:', styleName);\n  }\n\n  // Load output style frontmatter\n  const frontmatter = await loadOutputStyleFrontmatter(input.cwd, styleName);\n  if (!frontmatter || !frontmatter.tools || frontmatter.tools.length === 0) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] No tool restrictions defined, allowing all tools');\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const allowedTools = frontmatter.tools;\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Allowed tools:', allowedTools);\n  }\n\n  // Check if current tool is allowed\n  const isAllowed = allowedTools.includes(input.tool_name);\n\n  if (!isAllowed) {\n    if (DEBUG) {\n      console.log('[enforce-output-style-tools] Tool not allowed, blocking');\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'deny',\n        permissionDecisionReason: `The \"${input.tool_name}\" tool is not allowed by the current output style \"${styleName}\". Allowed tools: ${allowedTools.join(', ')}`,\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[enforce-output-style-tools] Tool allowed');\n  }\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'allow',\n    },\n  };\n}\n\n// Export for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/enforce-structured-markdown.ts": "#!/usr/bin/env npx tsx\n/**\n * Structured markdown validation hook\n *\n * PreToolUse hook that validates structure and metadata for markdown files before\n * Write and Edit operations. Enforces consistent documentation structure across\n * different file types in the Claude Code project.\n *\n * This hook validates six types of markdown files:\n *\n * 1. Agent files in .claude/agents/ directory\n *    Required headings: Objective, Principles, Agent-scoped project context\n *\n * 2. Skill files in .claude/skills/ subdirectories (excludes SKILL.md templates)\n *    Required headings: Purpose, Skill-scoped context\n *\n * 3. Rules files in .claude/rules/ directory\n *    Required headings: Rules\n *\n * 4. Plugin README files in plugins README.md\n *    Required headings: Badge section, TOC, Overview, Features, Installation,\n *    Hooks, Configuration, Use Cases, Troubleshooting, Contributing, See Also, License\n *\n * 5. Plugin CLAUDE.md files in plugins CLAUDE.md\n *    Required headings: Quick Reference, Hook Summary, Key Features,\n *    Installation, Debug Logging, See Also\n *\n * 6. CLAUDE.md files in any other directory\n *    Required metadata: name, description\n *\n * The hook blocks Write/Edit operations if validation fails, providing detailed\n * error messages about missing headings and metadata fields.\n *\n * @module enforce-structured-markdown\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\nconst DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('enforce-structured-markdown');\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n}\n\n/**\n * Extract markdown headings from content\n *\n * Parses markdown content and extracts all headings (lines starting with #).\n * Preserves the full heading text including the hash symbols for pattern matching.\n *\n * @param content - The markdown content to parse\n * @returns Array of heading strings (e.g., [\"# Title\", \"## Section\"])\n *\n * @example\n * ```typescript\n * const content = `\n * # My Document\n * ## Overview\n * Some content\n * ## Implementation\n * `;\n * const headings = extractHeadings(content);\n * // Returns: [\"# My Document\", \"## Overview\", \"## Implementation\"]\n * ```\n */\nfunction extractHeadings(content: string): string[] {\n  const lines = content.split('\\n');\n  const headings: string[] = [];\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (trimmed.match(/^#{1,6}\\s+/)) {\n      headings.push(trimmed);\n    }\n  }\n\n  return headings;\n}\n\n/**\n * Check if a heading matches a pattern with wildcard support\n *\n * Compares a markdown heading against a pattern, supporting wildcard (*) matching.\n * Normalizes whitespace and performs case-insensitive comparison.\n *\n * @param heading - The heading to test (e.g., \"## Required Skills: None\")\n * @param pattern - The pattern to match against (e.g., \"## Required Skills:*\")\n * @returns True if the heading matches the pattern, false otherwise\n *\n * @example\n * ```typescript\n * // Exact match\n * matchesHeadingPattern(\"## Overview\", \"## Overview\"); // true\n *\n * // Wildcard match\n * matchesHeadingPattern(\"## Required Skills: None\", \"## Required Skills:*\"); // true\n * matchesHeadingPattern(\"## Required Skills: foo, bar\", \"## Required Skills:*\"); // true\n *\n * // No match\n * matchesHeadingPattern(\"## Implementation\", \"## Overview\"); // false\n * ```\n */\nfunction matchesHeadingPattern(heading: string, pattern: string): boolean {\n  // Normalize whitespace\n  const normalizedHeading = heading.replace(/\\s+/g, ' ').trim();\n  const normalizedPattern = pattern.replace(/\\s+/g, ' ').trim();\n\n  // Exact match\n  if (normalizedHeading === normalizedPattern) {\n    return true;\n  }\n\n  // Wildcard pattern\n  const regexPattern = normalizedPattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*');\n\n  const regex = new RegExp(`^${regexPattern}$`, 'i');\n  return regex.test(normalizedHeading);\n}\n\n/**\n * Validate that all required headings are present in content\n *\n * Checks that each required heading pattern has at least one match in the\n * provided headings array. Supports wildcard patterns for flexible matching.\n *\n * @param headings - Array of headings extracted from markdown content\n * @param required - Array of required heading patterns (supports wildcards)\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const headings = [\"# Title\", \"## Overview\", \"## Implementation\"];\n * const required = [\"## Overview\", \"## Implementation\", \"## Testing\"];\n *\n * const result = validateRequiredHeadings(headings, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required heading missing: \"## Testing\"']\n * // }\n * ```\n */\nfunction validateRequiredHeadings(headings: string[], required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const requiredPattern of required) {\n    const found = headings.some(h => matchesHeadingPattern(h, requiredPattern));\n    if (!found) {\n      errors.push(`Required heading missing: \"${requiredPattern}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Validate that all required metadata fields are present in frontmatter\n *\n * Checks that each required metadata field exists in the YAML frontmatter object.\n * Fields with falsy values are considered missing.\n *\n * @param metadata - Parsed YAML frontmatter object\n * @param required - Array of required field names\n * @returns Validation result with valid flag and error messages\n *\n * @example\n * ```typescript\n * const metadata = { name: \"My Skill\", version: \"1.0\" };\n * const required = [\"name\", \"description\", \"version\"];\n *\n * const result = validateRequiredMetadata(metadata, required);\n * // Returns: {\n * //   valid: false,\n * //   errors: ['Required metadata field missing: \"description\"']\n * // }\n * ```\n */\nfunction validateRequiredMetadata(metadata: Record<string, unknown>, required: string[]): ValidationResult {\n  const errors: string[] = [];\n\n  for (const field of required) {\n    if (!metadata[field]) {\n      errors.push(`Required metadata field missing: \"${field}\"`);\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Determine file type and return appropriate validation rules\n *\n * Analyzes the file path to determine its type (agent, skill, rule, or CLAUDE.md)\n * and returns the corresponding validation requirements. Returns null for\n * non-markdown files or files that don't match any validation pattern.\n *\n * @param filePath - The path to the file being validated (absolute or relative)\n * @param cwd - The current working directory for resolving relative paths\n * @returns Validation rules object with type and requirements, or null if no validation needed\n *\n * @example\n * ```typescript\n * // Agent file\n * const rules1 = getFileValidationRules('.claude/agents/explorer.md', '/project');\n * // Returns: {\n * //   type: 'agent',\n * //   requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n * //   shouldValidate: true\n * // }\n *\n * // Skill file\n * const rules2 = getFileValidationRules('.claude/skills/my-skill/docs.md', '/project');\n * // Returns: {\n * //   type: 'skill',\n * //   requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n * //   requiredMetadata: ['name', 'description'],\n * //   shouldValidate: true\n * // }\n *\n * // SKILL.md template (skipped)\n * const rules3 = getFileValidationRules('.claude/skills/my-skill/SKILL.md', '/project');\n * // Returns: { type: 'skill-template', shouldValidate: false }\n *\n * // Non-markdown file\n * const rules4 = getFileValidationRules('src/index.ts', '/project');\n * // Returns: null\n * ```\n */\nfunction getFileValidationRules(filePath: string, cwd: string): {\n  type: string;\n  requiredHeadings?: string[];\n  requiredMetadata?: string[];\n  shouldValidate: boolean;\n} | null {\n  const relativePath = path.isAbsolute(filePath)\n    ? path.relative(cwd, filePath)\n    : filePath;\n\n  if (DEBUG) {\n    console.log('[enforce-structured-markdown] Checking file type:', relativePath);\n  }\n\n  // Agent files: .claude/agents/*.md\n  if (relativePath.includes(path.join('.claude', 'agents')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'agent',\n      requiredHeadings: ['## Objective', '## Principles', '## Agent-scoped project context'],\n      shouldValidate: true,\n    };\n  }\n\n  // Skill files: .claude/skills/*/*.md (excluding SKILL.md and SKILL.template.md)\n  if (relativePath.includes(path.join('.claude', 'skills')) && relativePath.endsWith('.md')) {\n    const basename = path.basename(relativePath);\n    if (basename === 'SKILL.md' || basename === 'SKILL.template.md') {\n      if (DEBUG) {\n        console.log('[enforce-structured-markdown] Skipping SKILL.md or SKILL.template.md');\n      }\n      return { type: 'skill-template', shouldValidate: false };\n    }\n    return {\n      type: 'skill',\n      requiredHeadings: ['## Purpose', '## Skill-scoped context'],\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  // Rules files: .claude/rules/*.md\n  if (relativePath.includes(path.join('.claude', 'rules')) && relativePath.endsWith('.md')) {\n    return {\n      type: 'rule',\n      requiredHeadings: ['## Rules'],\n      requiredMetadata: ['Required Skills'],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin README files: plugins/*/README.md\n  if (relativePath.match(/^plugins\\/[^/]+\\/README\\.md$/)) {\n    return {\n      type: 'plugin-readme',\n      requiredHeadings: [\n        '# 🔌 *',\n        '## 📋 Table of Contents',\n        '## 🎯 Overview',\n        '## ✨ Features',\n        '## 📦 Installation',\n        '## 🪝 Hooks',\n        '## ⚙️ Configuration',\n        '## 💡 Use Cases',\n        '## 🐛 Troubleshooting',\n        '## 🤝 Contributing',\n        '## 📚 See Also',\n        '## 📄 License',\n      ],\n      shouldValidate: true,\n    };\n  }\n\n  // Plugin CLAUDE.md files: plugins/*/CLAUDE.md (must come before general CLAUDE.md check)\n  if (relativePath.match(/^plugins\\/[^/]+\\/CLAUDE\\.md$/)) {\n    return {\n      type: 'plugin-claude',\n      requiredHeadings: [\n        '# *',\n        '## Quick Reference',\n        '## Hook Summary',\n        '## Key Features',\n        '## Installation',\n        '## Debug Logging',\n        '## See Also',\n      ],\n      requiredMetadata: ['title', 'description', 'version', 'folder'],\n      shouldValidate: true,\n    };\n  }\n\n  // CLAUDE.md files (any directory)\n  if (path.basename(relativePath) === 'CLAUDE.md') {\n    return {\n      type: 'claude-md',\n      requiredMetadata: ['name', 'description'],\n      shouldValidate: true,\n    };\n  }\n\n  return null;\n}\n\n/**\n * Extract the final content that will be written to the file\n *\n * Handles both Write and Edit operations to determine the content that will\n * result from the tool use. For Write, returns the content directly. For Edit,\n * reads the current file and applies the edit operation to get the final content.\n *\n * @param toolName - The tool being used (\"Write\" or \"Edit\")\n * @param toolInput - The tool input parameters\n * @param cwd - The current working directory for resolving relative paths\n * @returns The final content after the operation, or null if content cannot be determined\n *\n * @example\n * ```typescript\n * // Write operation\n * const content1 = await getContentFromToolInput(\n *   'Write',\n *   { file_path: 'doc.md', content: '# Title\\n## Section' },\n *   '/project'\n * );\n * // Returns: '# Title\\n## Section'\n *\n * // Edit operation (replaces text)\n * // Assumes file currently contains: '# Old\\n## Section'\n * const content2 = await getContentFromToolInput(\n *   'Edit',\n *   {\n *     file_path: 'doc.md',\n *     old_string: '# Old',\n *     new_string: '# New'\n *   },\n *   '/project'\n * );\n * // Returns: '# New\\n## Section'\n * ```\n */\nasync function getContentFromToolInput(\n  toolName: string,\n  toolInput: {\n    file_path?: string;\n    content?: string;\n    old_string?: string;\n    new_string?: string;\n  },\n  cwd: string\n): Promise<string | null> {\n  if (toolName === 'Write') {\n    return toolInput.content || null;\n  } else if (toolName === 'Edit') {\n    const filePath = toolInput.file_path;\n    if (!filePath || !toolInput.old_string || !toolInput.new_string) {\n      return null;\n    }\n\n    try {\n      const fullPath = path.isAbsolute(filePath) ? filePath : path.resolve(cwd, filePath);\n      const currentContent = await fs.readFile(fullPath, 'utf-8');\n      // Apply the edit\n      return currentContent.replace(toolInput.old_string, toolInput.new_string);\n    } catch {\n      return null;\n    }\n  }\n\n  return null;\n}\n\n/**\n * PreToolUse hook that validates markdown structure before Write/Edit operations\n *\n * Intercepts Write and Edit tool uses on markdown files to validate that they\n * meet the structural requirements for their file type. Blocks operations that\n * would create invalid agent, skill, rule, or CLAUDE.md files.\n *\n * This hook:\n * 1. Only processes Write and Edit operations on .md files\n * 2. Determines the file type from its path\n * 3. Extracts headings and metadata from the content\n * 4. Validates against type-specific requirements\n * 5. Blocks invalid operations with detailed error messages\n *\n * @param input - PreToolUse hook input with tool information\n * @returns Hook output with permissionDecision (allow/deny)\n *\n * @example\n * ```typescript\n * // Valid agent file - allowed\n * const result1 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_123',\n *   tool_input: {\n *     file_path: '.claude/agents/my-agent.md',\n *     content: `\n * # My Agent\n * ## Objective\n * Do the task\n * ## Principles\n * Be thorough\n * ## Agent-scoped project context\n * Uses TypeScript\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *\n * // Invalid skill file (missing required heading) - denied\n * const result2 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_456',\n *   tool_input: {\n *     file_path: '.claude/skills/my-skill/docs.md',\n *     content: `\n * ---\n * name: My Skill\n * description: Does things\n * ---\n * # My Skill\n * ## Purpose\n * This is the purpose\n * (missing ## Skill-scoped context heading)\n *     `\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: {\n * //   hookSpecificOutput: {\n * //     permissionDecision: 'deny',\n * //     permissionDecisionReason: 'Skill validation failed...\\n\\nRequired heading missing: \"## Skill-scoped context\"'\n * //   }\n * // }\n *\n * // Non-markdown file - allowed (no validation)\n * const result3 = await handler({\n *   tool_name: 'Write',\n *   tool_use_id: 'toolu_789',\n *   tool_input: {\n *     file_path: 'src/index.ts',\n *     content: 'export const foo = \"bar\";'\n *   },\n *   cwd: '/project',\n *   // ... other fields\n * });\n * // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n * ```\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'enforce-structured-markdown', DEBUG || false);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n\n    const filePath = toolInput.file_path;\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only process .md files\n    if (!filePath.endsWith('.md')) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get validation rules for this file type\n    const validationRules = getFileValidationRules(filePath, input.cwd);\n    if (!validationRules || !validationRules.shouldValidate) {\n      await logger.logOutput({ message: 'No validation rules for this file type or validation skipped' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get the content (handles both Write and Edit)\n    const content = await getContentFromToolInput(input.tool_name, toolInput, input.cwd);\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter and content\n    const { data: metadata } = matter(content);\n    const headings = extractHeadings(content);\n\n    const allErrors: string[] = [];\n\n    // Validate required metadata\n    if (validationRules.requiredMetadata && validationRules.requiredMetadata.length > 0) {\n      const metadataValidation = validateRequiredMetadata(\n        metadata as Record<string, unknown>,\n        validationRules.requiredMetadata\n      );\n      if (!metadataValidation.valid) {\n        allErrors.push(...metadataValidation.errors);\n      }\n    }\n\n    // Validate required headings\n    if (validationRules.requiredHeadings && validationRules.requiredHeadings.length > 0) {\n      const headingValidation = validateRequiredHeadings(headings, validationRules.requiredHeadings);\n      if (!headingValidation.valid) {\n        allErrors.push(...headingValidation.errors);\n      }\n    }\n\n    await logger.logOutput({\n      fileType: validationRules.type,\n      headings,\n      metadata: Object.keys(metadata),\n      valid: allErrors.length === 0,\n      errors: allErrors,\n    });\n\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n');\n      const fileTypeDisplay = validationRules.type.replace('-', ' ');\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `${fileTypeDisplay.charAt(0).toUpperCase() + fileTypeDisplay.slice(1)} validation failed for ${path.basename(filePath)}:\\n\\n${errorMessage}\\n\\nPlease ensure all required headings and metadata fields are present.`,\n        },\n      };\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Structured markdown validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/log-subagent-start.ts": "/**\n * Subagent context tracking hook\n *\n * SubagentStart hook that saves agent execution context when a subagent begins.\n * The saved context can be retrieved later in SubagentStop hooks to analyze what\n * the agent did and correlate it with the original Task tool call.\n *\n * This hook saves the following information to .claude/logs/subagent-tasks.json:\n * - Agent ID and type\n * - Session ID\n * - Original task prompt (from Task tool input)\n * - Tool use ID (for correlating with Task call)\n * - Timestamp\n *\n * The saved context enables SubagentStop hooks to generate rich commit messages,\n * track file operations, and analyze agent behavior.\n *\n * @module log-subagent-start\n */\n\nimport type { SubagentStartInput, SubagentStartHookOutput } from '../types/types.js';\nimport { saveAgentStartContext } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStart hook handler that saves agent context\n *\n * Intercepts subagent startup to save execution context for later retrieval.\n * This enables tracking what tasks agents were given and correlating SubagentStop\n * events with the original Task tool call.\n *\n * The hook is non-blocking - errors are logged but do not prevent agent execution.\n *\n * @param input - SubagentStart hook input with agent metadata\n * @returns Hook output (empty object, this hook does not modify agent behavior)\n *\n * @example\n * ```typescript\n * // When an agent starts via Task tool:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   cwd: '/path/to/project',\n *   transcript_path: '/path/.claude/logs/session-xyz.jsonl'\n * });\n *\n * // Context is saved to .claude/logs/subagent-tasks.json:\n * // {\n * //   \"agent-abc123\": {\n * //     \"agentId\": \"agent-abc123\",\n * //     \"agentType\": \"Explore\",\n * //     \"sessionId\": \"session-xyz\",\n * //     \"prompt\": \"Find all API endpoints\",\n * //     \"toolUseId\": \"toolu_xyz\",\n * //     \"timestamp\": \"2025-01-19T12:00:00.000Z\"\n * //   }\n * // }\n *\n * // Later, in SubagentStop, this context can be retrieved via getAgentEdits()\n * ```\n */\nasync function handler(input: SubagentStartInput): Promise<SubagentStartHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStart] Hook triggered');\n    console.log('[SubagentStart] Agent ID:', input.agent_id);\n    console.log('[SubagentStart] Agent Type:', input.agent_type);\n    console.log('[SubagentStart] Session ID:', input.session_id);\n  }\n\n  try {\n    const context = await saveAgentStartContext({\n      agent_id: input.agent_id,\n      agent_type: input.agent_type,\n      session_id: input.session_id,\n      cwd: input.cwd,\n      transcript_path: input.transcript_path,\n    });\n\n    if (DEBUG) {\n      console.log('[SubagentStart] Saved agent context');\n      console.log('[SubagentStart] Prompt:', context.prompt.slice(0, 100) + (context.prompt.length > 100 ? '...' : ''));\n      console.log('[SubagentStart] Tool Use ID:', context.toolUseId);\n      console.log('[SubagentStart] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStart] Error saving agent context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'SubagentStart',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/log-subagent-stop.ts": "/**\n * Subagent completion analysis hook\n *\n * SubagentStop hook that analyzes agent execution results when a subagent completes.\n * It parses the agent's transcript to extract file operations and correlates them\n * with the saved context from SubagentStart.\n *\n * This hook analyzes and logs:\n * - New files created by the agent\n * - Files deleted by the agent\n * - Files edited by the agent\n * - Agent type and original task prompt\n * - Preloaded skills used by the agent\n *\n * After analysis, the hook cleans up the saved context from SubagentStart to prevent\n * the context file from growing indefinitely.\n *\n * The analysis results are logged to console when DEBUG mode is enabled, making it\n * easy to understand what each agent did during execution.\n *\n * @module log-subagent-stop\n */\n\nimport type { SubagentStopInput, SubagentStopHookOutput } from '../types/types.js';\nimport { getAgentEdits } from './utils/subagent-state.js';\nimport { runHook } from './utils/io.js';\n\n/**\n * SubagentStop hook handler that analyzes agent execution results\n *\n * Intercepts subagent completion to analyze what the agent did during execution.\n * Parses the agent transcript to extract file operations and correlates with the\n * saved context from SubagentStart to provide complete execution metadata.\n *\n * The hook is non-blocking - errors are logged but do not prevent session continuation.\n *\n * @param input - SubagentStop hook input with agent transcript path\n * @returns Hook output (empty object, this hook does not modify behavior)\n *\n * @example\n * ```typescript\n * // When an agent completes:\n * const result = await handler({\n *   agent_id: 'agent-abc123',\n *   agent_transcript_path: '/path/.claude/logs/agent-abc123.jsonl',\n *   cwd: '/path/to/project'\n * });\n *\n * // With DEBUG=* enabled, logs output like:\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Analysis Complete\n * // [SubagentStop] ─────────────────────────────────────────\n * // [SubagentStop] Agent Type: Explore\n * // [SubagentStop] Agent Prompt: Find all API endpoints\n * // [SubagentStop] Files Created: 0\n * // [SubagentStop] Files Edited: 2\n * // [SubagentStop]   ~ src/api/routes.ts\n * // [SubagentStop]   ~ src/api/handlers.ts\n * // [SubagentStop] Files Deleted: 0\n * // [SubagentStop] ─────────────────────────────────────────\n *\n * // The saved context from SubagentStart is automatically cleaned up\n * ```\n */\nasync function handler(input: SubagentStopInput): Promise<SubagentStopHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('subagent');\n\n  if (DEBUG) {\n    console.log('[SubagentStop] Hook triggered');\n    console.log('[SubagentStop] Agent ID:', input.agent_id);\n    console.log('[SubagentStop] Agent Transcript:', input.agent_transcript_path);\n  }\n\n  try {\n    const edits = await getAgentEdits(input.agent_transcript_path);\n\n    if (DEBUG) {\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Analysis Complete');\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n      console.log('[SubagentStop] Agent Type:', edits.subagentType);\n      console.log('[SubagentStop] Agent Prompt:', edits.agentPrompt.slice(0, 100) + (edits.agentPrompt.length > 100 ? '...' : ''));\n\n      if (edits.agentFile) {\n        console.log('[SubagentStop] Agent Definition:', edits.agentFile);\n      }\n\n      if (edits.agentPreloadedSkillsFiles.length > 0) {\n        console.log('[SubagentStop] Preloaded Skills:', edits.agentPreloadedSkillsFiles.length);\n        edits.agentPreloadedSkillsFiles.forEach((skill) => {\n          console.log('[SubagentStop]   -', skill);\n        });\n      }\n\n      if (edits.agentNewFiles.length > 0) {\n        console.log('[SubagentStop] Files Created:', edits.agentNewFiles.length);\n        edits.agentNewFiles.forEach((file) => {\n          console.log('[SubagentStop]   +', file);\n        });\n      }\n\n      if (edits.agentEditedFiles.length > 0) {\n        console.log('[SubagentStop] Files Edited:', edits.agentEditedFiles.length);\n        edits.agentEditedFiles.forEach((file) => {\n          console.log('[SubagentStop]   ~', file);\n        });\n      }\n\n      if (edits.agentDeletedFiles.length > 0) {\n        console.log('[SubagentStop] Files Deleted:', edits.agentDeletedFiles.length);\n        edits.agentDeletedFiles.forEach((file) => {\n          console.log('[SubagentStop]   -', file);\n        });\n      }\n\n      if (edits.agentNewFiles.length === 0 &&\n          edits.agentEditedFiles.length === 0 &&\n          edits.agentDeletedFiles.length === 0) {\n        console.log('[SubagentStop] No file operations detected');\n      }\n\n      console.log('[SubagentStop] ─────────────────────────────────────────');\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[SubagentStop] Error analyzing agent edits:', error);\n    }\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/log-task-call.ts": "/**\n * PreToolUse[Task] hook - Save task call context for later retrieval\n *\n * This hook runs when the Task tool is ABOUT to be called (before the subagent starts).\n * It saves the task's context (type, prompt, toolUseId) to .claude/logs/task-calls.json\n * so it can be retrieved later in PostToolUse[Task] or SubagentStop.\n *\n * Import this hook in any plugin that needs to track task execution.\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { saveTaskCallContext } from './utils/task-state.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  if (DEBUG) {\n    console.log('[PreToolUse:Task] Hook triggered');\n    console.log('[PreToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PreToolUse:Task] Session ID:', input.session_id);\n  }\n\n  try {\n    const toolInput = input.tool_input as {\n      subagent_type?: string;\n      prompt?: string;\n    };\n\n    const agentType = toolInput?.subagent_type || 'unknown';\n    const prompt = toolInput?.prompt || '';\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Agent Type:', agentType);\n      console.log('[PreToolUse:Task] Prompt:', prompt.slice(0, 100) + (prompt.length > 100 ? '...' : ''));\n    }\n\n    const context = await saveTaskCallContext({\n      tool_use_id: input.tool_use_id,\n      agent_type: agentType,\n      session_id: input.session_id,\n      prompt,\n      cwd: input.cwd,\n    });\n\n    if (DEBUG) {\n      console.log('[PreToolUse:Task] Saved task call context');\n      console.log('[PreToolUse:Task] Tool Use ID:', context.toolUseId);\n      console.log('[PreToolUse:Task] Timestamp:', context.timestamp);\n    }\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PreToolUse:Task] Error saving task call context:', error);\n    }\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/log-task-result.ts": "/**\n * PostToolUse[Task] hook - Log task completion\n *\n * This hook runs when the Task tool completes (after the subagent finishes).\n * It logs the task completion for debugging and audit purposes.\n *\n * Note: For detailed file operations analysis, see the SubagentStop hooks\n * which have access to the full agent transcript.\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { loadTaskCallContext } from './utils/task-state.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\n\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  const DEBUG = process.env.DEBUG === '*' || process.env.DEBUG?.includes('task');\n\n  // Only process Task tool calls\n  if (input.tool_name !== 'Task') {\n    return {};\n  }\n\n  if (DEBUG) {\n    console.log('[PostToolUse:Task] Hook triggered');\n    console.log('[PostToolUse:Task] Tool Use ID:', input.tool_use_id);\n    console.log('[PostToolUse:Task] Session ID:', input.session_id);\n  }\n\n  const logger = createDebugLogger(input.cwd, 'log-task-result', true);\n\n  try {\n    // Load the saved context from PreToolUse\n    const context = await loadTaskCallContext(input.tool_use_id, input.cwd);\n\n    if (!context) {\n      if (DEBUG) {\n        console.log('[PostToolUse:Task] No saved context found for tool_use_id:', input.tool_use_id);\n      }\n      return {};\n    }\n\n    const toolResponse = input.tool_response;\n    const responseText = typeof toolResponse === 'string'\n      ? toolResponse\n      : JSON.stringify(toolResponse).slice(0, 500);\n\n    await logger.logOutput({\n      tool_use_id: input.tool_use_id,\n      agent_type: context.agentType,\n      prompt: context.prompt.slice(0, 200),\n      response: responseText.slice(0, 200),\n      success: true,\n    });\n\n    if (DEBUG) {\n      console.log('[PostToolUse:Task] Task completed');\n      console.log('[PostToolUse:Task] Agent Type:', context.agentType);\n      console.log('[PostToolUse:Task] Response:', responseText.slice(0, 100));\n    }\n\n    return {};\n  } catch (error) {\n    if (DEBUG) {\n      console.error('[PostToolUse:Task] Error logging task result:', error);\n    }\n    await logger.logError(error as Error);\n    return {};\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/run-rule-checks.ts": "/**\n * Rule-based check runner for PostToolUse[Write|Edit] hooks\n *\n * Runs checks defined in `.claude/rules/*.md` file frontmatter.\n * Checks are blocking - if any check fails, the edit is blocked.\n *\n * Frontmatter format:\n * ```yaml\n * ---\n * globs: [\"**\\/*.ts\", \"**\\/*.tsx\", \"!**\\/*.test.ts\"]\n * checks:\n *   - lint\n *   - typecheck\n *   - vitest\n * ---\n * ```\n *\n * @module run-rule-checks\n */\n\nimport type { PostToolUseInput, PostToolUseHookOutput } from '../types/types.js';\nimport { runHook } from './utils/io.js';\nimport { parseFrontmatter } from './utils/frontmatter.js';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport { readdir, readFile } from 'fs/promises';\nimport { join, relative } from 'path';\n\nconst execAsync = promisify(exec);\n\n/** Maximum characters for check output to prevent context bloat */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Timeout for each check in milliseconds (30 seconds) */\nconst CHECK_TIMEOUT_MS = 30000;\n\n/** Supported check types and their commands */\nconst CHECK_COMMANDS: Record<string, (filePath: string) => string> = {\n  lint: (filePath) => `npx eslint \"${filePath}\"`,\n  typecheck: (filePath) => `npx tsc --noEmit \"${filePath}\"`,\n  vitest: (filePath) => `npx vitest run \"${filePath}\" --reporter=verbose`,\n};\n\n/**\n * Check result from running a single check\n */\ninterface CheckResult {\n  check: string;\n  passed: boolean;\n  output: string;\n}\n\n/**\n * Rule definition parsed from frontmatter\n */\ninterface RuleDefinition {\n  filePath: string;\n  globs: string[];\n  checks: string[];\n}\n\n/**\n * Simple glob pattern matcher\n *\n * Supports:\n * - `*` matches any characters except /\n * - `**` matches any characters including /\n * - `!` prefix for negation patterns\n *\n * @param pattern - Glob pattern to match\n * @param filePath - File path to test\n * @returns True if pattern matches (or doesn't match for negation)\n */\nfunction matchGlob(pattern: string, filePath: string): boolean {\n  // Handle negation patterns\n  if (pattern.startsWith('!')) {\n    return !matchGlob(pattern.slice(1), filePath);\n  }\n\n  // Convert glob to regex\n  // Use unique placeholders that won't appear in normal patterns\n  const DOUBLE_STAR_SLASH = '<<<DSS>>>';\n  const DOUBLE_STAR = '<<<DS>>>';\n\n  const regexPattern = pattern\n    // Escape special regex characters except * and ?\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    // Use placeholders to avoid * in replacements being re-replaced\n    .replace(/\\*\\*\\//g, DOUBLE_STAR_SLASH)   // Placeholder for **/\n    .replace(/\\*\\*/g, DOUBLE_STAR)            // Placeholder for **\n    // Convert single * to match anything except /\n    .replace(/\\*/g, '[^/]*')\n    // Convert ? to match single character (BEFORE restoring placeholders!)\n    .replace(/\\?/g, '.')\n    // Restore placeholders with proper regex patterns\n    .replace(new RegExp(DOUBLE_STAR_SLASH, 'g'), '(?:.*/)?')  // **/ becomes optional path prefix\n    .replace(new RegExp(DOUBLE_STAR, 'g'), '.*');             // ** becomes match anything\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(filePath);\n}\n\n/**\n * Check if a file path matches any of the glob patterns\n *\n * Processes patterns in order - positive patterns include, negative exclude.\n *\n * @param filePath - File path to check\n * @param patterns - Array of glob patterns\n * @returns True if file matches the patterns\n */\nfunction matchesPatterns(filePath: string, patterns: string[]): boolean {\n  // Normalize path separators\n  const normalizedPath = filePath.replace(/\\\\/g, '/');\n\n  let matched = false;\n\n  for (const pattern of patterns) {\n    if (pattern.startsWith('!')) {\n      // Negation pattern - if it matches, exclude\n      if (matchGlob(pattern.slice(1), normalizedPath)) {\n        matched = false;\n      }\n    } else {\n      // Positive pattern - if it matches, include\n      if (matchGlob(pattern, normalizedPath)) {\n        matched = true;\n      }\n    }\n  }\n\n  return matched;\n}\n\n/**\n * Load all rule files from .claude/rules/ directory\n *\n * @param cwd - Current working directory\n * @returns Array of parsed rule definitions\n */\nasync function loadRules(cwd: string): Promise<RuleDefinition[]> {\n  const rulesDir = join(cwd, '.claude', 'rules');\n  const rules: RuleDefinition[] = [];\n\n  try {\n    const files = await readdir(rulesDir);\n\n    for (const file of files) {\n      if (!file.endsWith('.md')) continue;\n\n      const filePath = join(rulesDir, file);\n      const content = await readFile(filePath, 'utf-8');\n      const { data } = parseFrontmatter(content);\n\n      // Extract globs and checks from frontmatter\n      const globs = Array.isArray(data.globs) ? (data.globs as string[]) : [];\n      const checks = Array.isArray(data.checks) ? (data.checks as string[]) : [];\n\n      // Only include rules that have both globs and checks\n      if (globs.length > 0 && checks.length > 0) {\n        rules.push({ filePath, globs, checks });\n      }\n    }\n  } catch {\n    // No rules directory or can't read it - that's fine\n  }\n\n  return rules;\n}\n\n/**\n * Run a single check on a file\n *\n * @param check - Check type to run (lint, typecheck, vitest)\n * @param filePath - Absolute path to file to check\n * @param cwd - Current working directory\n * @returns Check result with pass/fail and output\n */\nasync function runCheck(check: string, filePath: string, cwd: string): Promise<CheckResult> {\n  const commandFn = CHECK_COMMANDS[check];\n\n  if (!commandFn) {\n    return {\n      check,\n      passed: true,\n      output: `Unknown check type: ${check}`,\n    };\n  }\n\n  const command = commandFn(filePath);\n\n  try {\n    const { stdout, stderr } = await execAsync(command, {\n      cwd,\n      timeout: CHECK_TIMEOUT_MS,\n    });\n\n    // Check passed\n    return {\n      check,\n      passed: true,\n      output: truncateOutput(stdout || stderr || 'Check passed'),\n    };\n  } catch (error) {\n    // Check failed\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    const output = err.stdout || err.stderr || err.message || 'Check failed';\n\n    return {\n      check,\n      passed: false,\n      output: truncateOutput(output),\n    };\n  }\n}\n\n/**\n * Truncate output to MAX_OUTPUT_CHARS\n *\n * @param output - Output string to truncate\n * @returns Truncated string with indicator if truncated\n */\nfunction truncateOutput(output: string): string {\n  if (output.length <= MAX_OUTPUT_CHARS) {\n    return output;\n  }\n\n  const truncated = output.slice(0, MAX_OUTPUT_CHARS);\n  const remaining = output.length - MAX_OUTPUT_CHARS;\n  return `${truncated}\\n... (${remaining} more chars truncated)`;\n}\n\n/**\n * PostToolUse[Write|Edit] hook handler\n *\n * Runs checks defined in matching rule files for the edited file.\n * Blocks if any check fails.\n *\n * @param input - PostToolUse hook input\n * @returns Hook output with blocking decision if checks fail\n */\nasync function handler(input: PostToolUseInput): Promise<PostToolUseHookOutput> {\n  // Only process Write and Edit tools\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {};\n  }\n\n  // Get file path from tool input\n  const toolInput = input.tool_input as { file_path?: string };\n  const filePath = toolInput?.file_path;\n\n  if (!filePath) {\n    return {};\n  }\n\n  // Get relative path for glob matching\n  const relativePath = relative(input.cwd, filePath).replace(/\\\\/g, '/');\n\n  // Load all rules\n  const rules = await loadRules(input.cwd);\n\n  // Find all checks that apply to this file\n  const checksToRun = new Set<string>();\n\n  for (const rule of rules) {\n    if (matchesPatterns(relativePath, rule.globs)) {\n      for (const check of rule.checks) {\n        checksToRun.add(check);\n      }\n    }\n  }\n\n  // If no checks apply, allow the edit\n  if (checksToRun.size === 0) {\n    return {};\n  }\n\n  // Run all applicable checks\n  const results: CheckResult[] = [];\n\n  for (const check of checksToRun) {\n    const result = await runCheck(check, filePath, input.cwd);\n    results.push(result);\n  }\n\n  // Check if any failed\n  const failedResults = results.filter((r) => !r.passed);\n\n  if (failedResults.length === 0) {\n    // All checks passed\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PostToolUse',\n        additionalContext: `✓ Checks passed: ${[...checksToRun].join(', ')}`,\n      },\n    };\n  }\n\n  // Format failure message\n  const failureMessages = failedResults\n    .map((r) => `**${r.check}**:\\n${r.output}`)\n    .join('\\n\\n');\n\n  // Block the edit with actionable feedback\n  return {\n    decision: 'block',\n    reason: `Fix these errors before continuing:\\n\\n${failureMessages}`,\n    hookSpecificOutput: {\n      hookEventName: 'PostToolUse',\n      additionalContext: `❌ Checks failed: ${failedResults.map((r) => r.check).join(', ')}\\n\\n${failureMessages}`,\n    },\n  };\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/test-folder-hooks.sh": "#!/bin/bash\n# Test script for folder validation hooks\n# Tests validate-folder-structure-bash.ts and validate-folder-structure-write.ts\n\nset -e\n\necho \"Testing folder validation hooks...\"\necho \"\"\n\nCWD=\"/home/user/claude-code-plugins\"\nSESSION_ID=\"test-session-123\"\nTRANSCRIPT_PATH=\"/tmp/test-transcript.jsonl\"\n\n# Test 1: validate-folder-structure-bash.ts with allowed folder\necho \"=== Test 1: Bash hook - allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_1\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 2: validate-folder-structure-bash.ts with forbidden folder\necho \"=== Test 2: Bash hook - forbidden subfolder (should deny) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_2\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir shared/invalid_folder\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 3: validate-folder-structure-bash.ts with mkdir -p\necho \"=== Test 3: Bash hook - mkdir with -p flag (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_3\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"mkdir -p shared/types\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 4: validate-folder-structure-bash.ts with non-mkdir command\necho \"=== Test 4: Bash hook - non-mkdir command (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_4\",\n  \"tool_name\": \"Bash\",\n  \"tool_input\": {\n    \"command\": \"ls -la\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-bash.ts\"\necho \"\"\n\n# Test 5: validate-folder-structure-write.ts with allowed file\necho \"=== Test 5: Write hook - allowed file in allowed folder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_5\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 6: validate-folder-structure-write.ts with forbidden file\necho \"=== Test 6: Write hook - forbidden file (should deny if files spec exists) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_6\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/forbidden.exe\",\n    \"content\": \"test\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 7: validate-folder-structure-write.ts with file in new subfolder\necho \"=== Test 7: Write hook - file in allowed subfolder (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_7\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"shared/types/new-type.ts\",\n    \"content\": \"export type NewType = string;\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\n# Test 8: validate-folder-structure-write.ts with non-Write tool\necho \"=== Test 8: Write hook - non-Write tool (should allow) ===\"\necho '{\n  \"hook_event_name\": \"PreToolUse\",\n  \"session_id\": \"'\"$SESSION_ID\"'\",\n  \"transcript_path\": \"'\"$TRANSCRIPT_PATH\"'\",\n  \"cwd\": \"'\"$CWD\"'\",\n  \"permission_mode\": \"default\",\n  \"tool_use_id\": \"tool_use_8\",\n  \"tool_name\": \"Read\",\n  \"tool_input\": {\n    \"file_path\": \"shared/CLAUDE.md\"\n  }\n}' | npx tsx \"$CWD/shared/hooks/validate-folder-structure-write.ts\"\necho \"\"\n\necho \"All tests completed!\"\n",
        "plugins/project-context/shared/hooks/use-correct-package-manager.ts": "/**\n * Package Manager Enforcement Hook\n * PreToolUse[Bash] hook that enforces correct package manager usage based on lockfiles\n * Blocks npm/yarn/pnpm/bun commands when wrong package manager is detected\n * Allows any package manager when no lockfile exists\n * @module use-correct-package-manager\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { runHook } from './utils/io.js';\nimport { detectPackageManager } from './utils/package-manager.js';\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Check if project has any lockfile\n * @param cwd - Current working directory\n * @returns True if any lockfile exists\n */\nfunction hasLockfile(cwd: string): boolean {\n  return (\n    existsSync(join(cwd, 'bun.lockb')) ||\n    existsSync(join(cwd, 'pnpm-lock.yaml')) ||\n    existsSync(join(cwd, 'yarn.lock')) ||\n    existsSync(join(cwd, 'package-lock.json'))\n  );\n}\n\n/**\n * Extract package manager from bash command\n * @param command - Bash command string\n * @returns Package manager name or null if not a package manager command\n */\nfunction extractPackageManagerFromCommand(command: string): string | null {\n  // Extract the first command before pipes, semicolons, &&, etc.\n  const actualCommand = command.split(/[|;&]/)[0].trim();\n\n  // Match package manager executables\n  const pmMatch = actualCommand.match(/^\\s*(npm|yarn|pnpm|bun|npx|bunx|pnpx)\\b/);\n\n  if (!pmMatch) {\n    return null;\n  }\n\n  const executable = pmMatch[1];\n\n  // Map executables to package managers\n  switch (executable) {\n    case 'npm':\n    case 'npx':\n      return 'npm';\n    case 'yarn':\n      return 'yarn';\n    case 'pnpm':\n    case 'pnpx':\n      return 'pnpm';\n    case 'bun':\n    case 'bunx':\n      return 'bun';\n    default:\n      return null;\n  }\n}\n\n/**\n * Generate error message for package manager mismatch\n * @param usedPm - Package manager used in command\n * @param correctPm - Correct package manager based on lockfile\n * @param command - Original command\n * @returns Formatted error message\n */\nfunction createPackageManagerErrorMessage(\n  usedPm: string,\n  correctPm: string,\n  command: string\n): string {\n  const pmNames: Record<string, string> = {\n    npm: 'npm',\n    yarn: 'Yarn',\n    pnpm: 'pnpm',\n    bun: 'Bun',\n  };\n\n  const lockfiles: Record<string, string> = {\n    npm: 'package-lock.json',\n    yarn: 'yarn.lock',\n    pnpm: 'pnpm-lock.yaml',\n    bun: 'bun.lockb',\n  };\n\n  // Generate corrected command\n  let correctedCommand = command;\n  if (usedPm === 'npm') {\n    correctedCommand = command.replace(/^\\s*(npm|npx)\\b/, correctPm);\n  } else if (usedPm === 'yarn') {\n    correctedCommand = command.replace(/^\\s*yarn\\b/, correctPm);\n  } else if (usedPm === 'pnpm') {\n    correctedCommand = command.replace(/^\\s*(pnpm|pnpx)\\b/, correctPm);\n  } else if (usedPm === 'bun') {\n    correctedCommand = command.replace(/^\\s*(bun|bunx)\\b/, correctPm);\n  }\n\n  return `❌ Wrong package manager detected\n\nThis project uses ${pmNames[correctPm]} (detected from ${lockfiles[correctPm]}).\n\nYou attempted to use: ${usedPm}\nCorrect package manager: ${correctPm}\n\nPlease use ${correctPm} commands instead. For example:\n- Instead of: ${command}\n- Use: ${correctedCommand}\n\nConsistent package manager usage ensures:\n- Reproducible dependency resolution\n- Correct lockfile updates\n- Consistent CI/CD behavior`;\n}\n\n/**\n * PreToolUse hook handler\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only process Bash commands\n  if (input.tool_name !== 'Bash') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const toolInput = input.tool_input as { command?: string };\n  const command = toolInput.command;\n\n  // Early return if no command\n  if (!command) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Extract package manager from command\n  const usedPm = extractPackageManagerFromCommand(command);\n\n  // Allow if not a package manager command\n  if (!usedPm) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Allow any package manager if no lockfile exists\n  if (!hasLockfile(input.cwd)) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Detect correct package manager from lockfiles\n  const correctPm = detectPackageManager(input.cwd);\n\n  // Allow if package managers match\n  if (usedPm === correctPm) {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  // Block with error message\n  const errorMessage = createPackageManagerErrorMessage(usedPm, correctPm, command);\n\n  return {\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'deny',\n      permissionDecisionReason: errorMessage,\n    },\n  };\n}\n\nexport { handler };\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/utils/ci-status.ts": "/**\n * Shared CI status utilities for GitHub CI integration\n *\n * Provides common functions for checking CI status, waiting for checks,\n * extracting preview URLs, and formatting results. Used by:\n * - commit-task-await-ci-status.ts (SubagentStop)\n * - await-pr-status.ts (PostToolUse[Bash])\n * - commit-session-await-ci-status.ts (Stop)\n *\n * @module ci-status\n */\n\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\n/** Maximum output characters for CI status (prevents context bloat) */\nconst MAX_OUTPUT_CHARS = 500;\n\n/** Default CI check timeout in milliseconds (10 minutes) */\nconst DEFAULT_TIMEOUT_MS = 600000;\n\n/** Polling interval for fail-fast CI checks in milliseconds (5 seconds) */\nconst POLL_INTERVAL_MS = 5000;\n\n/**\n * Branch sync status result\n */\nexport interface BranchSyncResult {\n  /** Whether branch is in sync with main */\n  inSync: boolean;\n  /** Number of commits behind main */\n  behindCount: number;\n  /** Number of commits ahead of main */\n  aheadCount: number;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Merge conflict check result\n */\nexport interface MergeConflictResult {\n  /** Whether PR has merge conflicts */\n  hasConflicts: boolean;\n  /** Mergeable state from GitHub */\n  mergeableState?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Fail-fast CI check result\n */\nexport interface FailFastResult {\n  /** Whether all checks passed */\n  success: boolean;\n  /** Blocking reason if failed */\n  blockReason?: string;\n  /** Failed check name if applicable */\n  failedCheck?: string;\n  /** All check statuses */\n  checks: CheckStatus[];\n  /** PR number if found */\n  prNumber?: number;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * Result from a CI check operation\n */\nexport interface CICheckResult {\n  /** Whether all CI checks passed */\n  success: boolean;\n  /** Combined output from CI checks */\n  output: string;\n  /** Error message if operation failed */\n  error?: string;\n}\n\n/**\n * CI run details from GitHub\n */\nexport interface CIRunDetails {\n  /** CI workflow URL */\n  url?: string;\n  /** CI status (queued, in_progress, completed) */\n  status?: string;\n  /** CI conclusion (success, failure, cancelled) */\n  conclusion?: string;\n  /** Workflow name */\n  name?: string;\n}\n\n/**\n * Individual check status\n */\nexport interface CheckStatus {\n  /** Check name */\n  name: string;\n  /** Check status emoji */\n  emoji: string;\n  /** Check status (success, failure, pending) */\n  status: string;\n  /** Details URL */\n  url?: string;\n}\n\n/**\n * PR existence check result\n */\nexport interface PRCheckResult {\n  /** Whether PR exists */\n  exists: boolean;\n  /** PR number if exists */\n  prNumber?: number;\n  /** PR URL if exists */\n  prUrl?: string;\n  /** Error message if check failed */\n  error?: string;\n}\n\n/**\n * Preview URLs extracted from PR\n */\nexport interface PreviewUrls {\n  /** Web app preview URL */\n  webUrl?: string;\n  /** Marketing app preview URL */\n  marketingUrl?: string;\n  /** All preview URLs found */\n  allUrls: string[];\n}\n\n/**\n * Execute a shell command with timeout\n *\n * @param command - Command to execute\n * @param cwd - Working directory\n * @param timeout - Timeout in milliseconds (default: 30s)\n * @returns Command result with success flag and output\n *\n * @example\n * ```typescript\n * const result = await execCommand('gh pr list', '/path/to/repo');\n * if (result.success) {\n *   console.log(result.stdout);\n * }\n * ```\n */\nexport async function execCommand(\n  command: string,\n  cwd: string,\n  timeout = 30000\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Check if a PR exists for the given branch\n *\n * @param branch - Branch name to check\n * @param cwd - Working directory\n * @returns PR check result with number and URL if exists\n *\n * @example\n * ```typescript\n * const prCheck = await checkPRExists('feature-branch', '/path/to/repo');\n * if (prCheck.exists) {\n *   console.log(`PR #${prCheck.prNumber}: ${prCheck.prUrl}`);\n * }\n * ```\n */\nexport async function checkPRExists(\n  branch: string,\n  cwd: string\n): Promise<PRCheckResult> {\n  // Check if gh CLI is available\n  const ghCheck = await execCommand('gh --version', cwd);\n  if (!ghCheck.success) {\n    return { exists: false, error: 'GitHub CLI not installed' };\n  }\n\n  // Check if gh is authenticated\n  const authCheck = await execCommand('gh auth status', cwd);\n  if (!authCheck.success) {\n    return { exists: false, error: 'GitHub CLI not authenticated' };\n  }\n\n  // List PRs for current branch\n  const prListResult = await execCommand(\n    `gh pr list --head ${branch} --json number,url --limit 1`,\n    cwd\n  );\n\n  if (!prListResult.success) {\n    return { exists: false, error: `gh pr list failed: ${prListResult.stderr}` };\n  }\n\n  try {\n    const prs = JSON.parse(prListResult.stdout);\n    if (Array.isArray(prs) && prs.length > 0) {\n      return {\n        exists: true,\n        prNumber: prs[0].number,\n        prUrl: prs[0].url,\n      };\n    }\n    return { exists: false };\n  } catch {\n    return { exists: false, error: 'Failed to parse gh output' };\n  }\n}\n\n/**\n * Get PR number for the current branch\n *\n * @param cwd - Working directory\n * @returns PR number or null if no PR exists\n *\n * @example\n * ```typescript\n * const prNumber = await getPRForCurrentBranch('/path/to/repo');\n * if (prNumber) {\n *   const ciResult = await waitForCIChecks({ prNumber, cwd });\n * }\n * ```\n */\nexport async function getPRForCurrentBranch(cwd: string): Promise<number | null> {\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return null;\n  }\n\n  const prCheck = await checkPRExists(branchResult.stdout, cwd);\n  return prCheck.exists ? (prCheck.prNumber ?? null) : null;\n}\n\n/**\n * Wait for CI checks to complete on a PR\n *\n * Uses `gh pr checks --watch` to wait for all CI checks to finish.\n * Blocks until all checks complete or timeout is reached.\n *\n * @param options - Wait options\n * @param options.prNumber - PR number to check (required if no commitSha)\n * @param options.commitSha - Commit SHA to check (alternative to prNumber)\n * @param options.timeout - Timeout in milliseconds (default: 10 minutes)\n * @param cwd - Working directory\n * @returns CI check result with success status and output\n *\n * @example\n * ```typescript\n * const result = await waitForCIChecks({ prNumber: 123 }, '/path/to/repo');\n * if (result.success) {\n *   console.log('All CI checks passed!');\n * } else {\n *   console.log('CI failed:', result.output);\n * }\n * ```\n */\nexport async function waitForCIChecks(\n  options: {\n    prNumber?: number;\n    commitSha?: string;\n    timeout?: number;\n  },\n  cwd: string\n): Promise<CICheckResult> {\n  const { prNumber, commitSha, timeout = DEFAULT_TIMEOUT_MS } = options;\n\n  if (!prNumber && !commitSha) {\n    return { success: false, output: '', error: 'Either prNumber or commitSha required' };\n  }\n\n  try {\n    // Build command based on what we have\n    const target = prNumber ? prNumber.toString() : commitSha!;\n    const command = `gh pr checks ${target} --watch`;\n\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout });\n    const combinedOutput = `${stdout}\\n${stderr}`.trim();\n\n    // Check if all checks passed\n    const hasFailures =\n      combinedOutput.includes('fail') ||\n      combinedOutput.includes('X ') ||\n      combinedOutput.includes('cancelled');\n\n    return {\n      success: !hasFailures,\n      output: combinedOutput,\n    };\n  } catch (error: unknown) {\n    const err = error as {\n      stdout?: string;\n      stderr?: string;\n      message?: string;\n      killed?: boolean;\n    };\n    const errorOutput = err.stdout || err.stderr || err.message || 'Unknown error';\n\n    if (err.killed) {\n      return {\n        success: false,\n        output: errorOutput,\n        error: `CI check timeout (${Math.round(timeout / 60000)} minutes)`,\n      };\n    }\n\n    return {\n      success: false,\n      output: errorOutput,\n      error: 'Failed to watch CI checks',\n    };\n  }\n}\n\n/**\n * Get latest CI workflow run details\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns CI run details or null if not found\n *\n * @example\n * ```typescript\n * const ciRun = await getLatestCIRun(123, '/path/to/repo');\n * if (ciRun?.conclusion === 'success') {\n *   console.log('CI passed:', ciRun.url);\n * }\n * ```\n */\nexport async function getLatestCIRun(\n  prNumber: number,\n  cwd: string\n): Promise<CIRunDetails | null> {\n  const result = await execCommand(\n    `gh run list --limit 1 --json databaseId,displayTitle,status,conclusion,url`,\n    cwd\n  );\n\n  if (!result.success) {\n    return null;\n  }\n\n  try {\n    const runs = JSON.parse(result.stdout);\n    if (Array.isArray(runs) && runs.length > 0) {\n      const run = runs[0];\n      return {\n        url: run.url,\n        status: run.status,\n        conclusion: run.conclusion,\n        name: run.displayTitle,\n      };\n    }\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Extract Vercel preview URLs from PR comments\n *\n * Searches PR comments for Vercel bot URLs and categorizes them\n * by app type (web, marketing, etc).\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Preview URLs object with categorized URLs\n *\n * @example\n * ```typescript\n * const urls = await extractPreviewUrls(123, '/path/to/repo');\n * if (urls.webUrl) {\n *   console.log('Web preview:', urls.webUrl);\n * }\n * ```\n */\nexport async function extractPreviewUrls(\n  prNumber: number,\n  cwd: string\n): Promise<PreviewUrls> {\n  const result = await execCommand(`gh pr view ${prNumber} --json comments`, cwd);\n\n  if (!result.success) {\n    return { allUrls: [] };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const comments = data.comments || [];\n\n    const vercelUrlPattern = /https:\\/\\/[a-z0-9-]+\\.vercel\\.app/g;\n    const allUrls: string[] = [];\n\n    for (const comment of comments) {\n      const matches = comment.body?.match(vercelUrlPattern) || [];\n      allUrls.push(...matches);\n    }\n\n    // Deduplicate URLs\n    const uniqueUrls = [...new Set(allUrls)];\n\n    // Identify web and marketing apps by URL pattern\n    const webUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-web-') || url.includes('web-') || url.match(/web\\.vercel\\.app/)\n    );\n    const marketingUrl = uniqueUrls.find(\n      (url) =>\n        url.includes('-marketing-') ||\n        url.includes('marketing-') ||\n        url.match(/marketing\\.vercel\\.app/)\n    );\n\n    return {\n      webUrl,\n      marketingUrl,\n      allUrls: uniqueUrls,\n    };\n  } catch {\n    return { allUrls: [] };\n  }\n}\n\n/**\n * Parse CI checks output into structured format\n *\n * @param output - Raw output from `gh pr checks`\n * @returns Array of parsed check statuses\n *\n * @example\n * ```typescript\n * const checks = parseCIChecks(ciOutput);\n * for (const check of checks) {\n *   console.log(`${check.emoji} ${check.name}: ${check.status}`);\n * }\n * ```\n */\nexport function parseCIChecks(output: string): CheckStatus[] {\n  const checks: CheckStatus[] = [];\n  const lines = output.split('\\n');\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (!trimmed) continue;\n\n    // Parse line format: \"✓ check-name\" or \"X check-name\" or \"* check-name\"\n    let emoji = '⏳';\n    let status = 'pending';\n\n    if (trimmed.startsWith('✓') || trimmed.includes('pass')) {\n      emoji = '✅';\n      status = 'success';\n    } else if (trimmed.startsWith('X') || trimmed.includes('fail')) {\n      emoji = '❌';\n      status = 'failure';\n    } else if (trimmed.includes('cancel')) {\n      emoji = '⚪';\n      status = 'cancelled';\n    }\n\n    // Extract check name (remove status indicator)\n    const name = trimmed.replace(/^[✓X*\\s]+/, '').split('\\t')[0].trim();\n\n    if (name) {\n      checks.push({ name, emoji, status });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Format CI status result as concise string\n *\n * Truncates output to MAX_OUTPUT_CHARS to prevent context bloat.\n *\n * @param result - CI check result\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const ciResult = await waitForCIChecks({ prNumber: 123 }, cwd);\n * const formatted = formatCIStatus(ciResult);\n * console.log(formatted);\n * ```\n */\nexport function formatCIStatus(\n  result: CICheckResult,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = '';\n\n  if (result.success) {\n    output = '✅ All CI checks passed';\n  } else if (result.error) {\n    output = `⚠️ ${result.error}`;\n  } else {\n    output = '❌ CI checks failed';\n  }\n\n  // Add check details if available\n  if (result.output) {\n    const checks = parseCIChecks(result.output);\n    if (checks.length > 0) {\n      const checkLines = checks.map((c) => `${c.emoji} ${c.name}`).join('\\n');\n      output += `\\n\\n${checkLines}`;\n    }\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n/**\n * Format full CI status with PR info and preview URLs\n *\n * @param prNumber - PR number\n * @param prUrl - PR URL\n * @param ciResult - CI check result\n * @param ciRun - CI run details\n * @param previewUrls - Preview URLs\n * @param maxChars - Maximum output characters (default: 500)\n * @returns Formatted status string\n *\n * @example\n * ```typescript\n * const status = formatFullCIStatus(\n *   123, 'https://github.com/...', ciResult, ciRun, previewUrls\n * );\n * ```\n */\nexport function formatFullCIStatus(\n  prNumber: number,\n  prUrl: string,\n  ciResult: CICheckResult,\n  ciRun: CIRunDetails | null,\n  previewUrls: PreviewUrls,\n  maxChars: number = MAX_OUTPUT_CHARS\n): string {\n  let output = `**PR #${prNumber}**\\n`;\n\n  // CI status\n  if (ciResult.success) {\n    output += '✅ All CI checks passed\\n';\n  } else if (ciResult.error) {\n    output += `⏱️ ${ciResult.error}\\n`;\n  } else {\n    output += '❌ CI checks failed\\n';\n  }\n\n  // CI run link\n  if (ciRun?.url) {\n    output += `🔗 [CI](${ciRun.url})\\n`;\n  }\n\n  // Preview URLs\n  if (previewUrls.allUrls.length > 0) {\n    output += `🌐 ${previewUrls.allUrls[0]}`;\n    if (previewUrls.allUrls.length > 1) {\n      output += ` (+${previewUrls.allUrls.length - 1})`;\n    }\n    output += '\\n';\n  }\n\n  // Truncate if too long\n  if (output.length > maxChars) {\n    output = output.slice(0, maxChars - 20) + '\\n... (truncated)';\n  }\n\n  return output;\n}\n\n// ============================================================================\n// Fail-Fast CI Checking\n// ============================================================================\n\n/**\n * Check if PR has merge conflicts\n *\n * Queries GitHub API for the PR's mergeable state and returns immediately\n * if conflicts are detected.\n *\n * @param prNumber - PR number to check\n * @param cwd - Working directory\n * @returns Merge conflict result\n *\n * @example\n * ```typescript\n * const conflicts = await checkMergeConflicts(123, '/path/to/repo');\n * if (conflicts.hasConflicts) {\n *   console.log('PR has merge conflicts!');\n * }\n * ```\n */\nexport async function checkMergeConflicts(\n  prNumber: number,\n  cwd: string\n): Promise<MergeConflictResult> {\n  const result = await execCommand(\n    `gh pr view ${prNumber} --json mergeable,mergeStateStatus`,\n    cwd\n  );\n\n  if (!result.success) {\n    return { hasConflicts: false, error: `Failed to check PR: ${result.stderr}` };\n  }\n\n  try {\n    const data = JSON.parse(result.stdout);\n    const mergeable = data.mergeable;\n    const mergeStateStatus = data.mergeStateStatus;\n\n    // CONFLICTING means merge conflicts exist\n    // UNKNOWN means GitHub is still calculating\n    const hasConflicts = mergeable === 'CONFLICTING' || mergeStateStatus === 'DIRTY';\n\n    return {\n      hasConflicts,\n      mergeableState: mergeStateStatus || mergeable,\n    };\n  } catch {\n    return { hasConflicts: false, error: 'Failed to parse PR data' };\n  }\n}\n\n/**\n * Check if branch is behind main/master\n *\n * Compares the current branch with the default branch (main or master)\n * to determine if it's out of date.\n *\n * @param cwd - Working directory\n * @returns Branch sync status result\n *\n * @example\n * ```typescript\n * const sync = await checkBranchSyncStatus('/path/to/repo');\n * if (!sync.inSync) {\n *   console.log(`Branch is ${sync.behindCount} commits behind main`);\n * }\n * ```\n */\nexport async function checkBranchSyncStatus(cwd: string): Promise<BranchSyncResult> {\n  // First, fetch to ensure we have latest remote refs\n  await execCommand('git fetch origin', cwd);\n\n  // Get current branch\n  const branchResult = await execCommand('git rev-parse --abbrev-ref HEAD', cwd);\n  if (!branchResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to get current branch' };\n  }\n  const currentBranch = branchResult.stdout;\n\n  // Determine main branch (main or master)\n  let mainBranch = 'main';\n  const mainCheck = await execCommand('git rev-parse --verify origin/main', cwd);\n  if (!mainCheck.success) {\n    const masterCheck = await execCommand('git rev-parse --verify origin/master', cwd);\n    if (masterCheck.success) {\n      mainBranch = 'master';\n    } else {\n      return { inSync: true, behindCount: 0, aheadCount: 0, error: 'No main/master branch found' };\n    }\n  }\n\n  // Count commits behind and ahead\n  const revListResult = await execCommand(\n    `git rev-list --left-right --count origin/${mainBranch}...${currentBranch}`,\n    cwd\n  );\n\n  if (!revListResult.success) {\n    return { inSync: true, behindCount: 0, aheadCount: 0, error: 'Failed to compare branches' };\n  }\n\n  const [behind, ahead] = revListResult.stdout.split('\\t').map(Number);\n\n  return {\n    inSync: behind === 0,\n    behindCount: behind || 0,\n    aheadCount: ahead || 0,\n  };\n}\n\n/**\n * Get current CI check statuses without waiting\n *\n * @param prNumber - PR number\n * @param cwd - Working directory\n * @returns Array of check statuses\n */\nasync function getCurrentCIChecks(prNumber: number, cwd: string): Promise<CheckStatus[]> {\n  const result = await execCommand(\n    `gh pr checks ${prNumber} --json name,state,conclusion`,\n    cwd\n  );\n\n  if (!result.success) {\n    return [];\n  }\n\n  try {\n    const checks = JSON.parse(result.stdout);\n    return checks.map((check: { name: string; state: string; conclusion: string }) => {\n      let emoji = '⏳';\n      let status = 'pending';\n\n      if (check.state === 'COMPLETED') {\n        if (check.conclusion === 'SUCCESS') {\n          emoji = '✅';\n          status = 'success';\n        } else if (check.conclusion === 'FAILURE') {\n          emoji = '❌';\n          status = 'failure';\n        } else if (check.conclusion === 'CANCELLED') {\n          emoji = '⚪';\n          status = 'cancelled';\n        }\n      } else if (check.state === 'IN_PROGRESS') {\n        emoji = '🔄';\n        status = 'in_progress';\n      }\n\n      return { name: check.name, emoji, status };\n    });\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Await CI checks with fail-fast behavior\n *\n * Checks for blocking conditions in order:\n * 1. Merge conflicts - block immediately\n * 2. Branch out of date with main - block immediately\n * 3. Any CI check failure - block immediately (don't wait for rest)\n *\n * Only returns success if ALL checks pass.\n *\n * @param options - Check options\n * @param options.prNumber - PR number (optional, will detect from branch)\n * @param options.timeout - Max wait time in ms (default: 10 minutes)\n * @param options.pollInterval - Polling interval in ms (default: 5 seconds)\n * @param cwd - Working directory\n * @returns Fail-fast result with blocking reason if failed\n *\n * @example\n * ```typescript\n * const result = await awaitCIWithFailFast({ prNumber: 123 }, '/path/to/repo');\n * if (!result.success) {\n *   return {\n *     decision: 'block',\n *     reason: result.blockReason,\n *   };\n * }\n * ```\n */\nexport async function awaitCIWithFailFast(\n  options: {\n    prNumber?: number;\n    timeout?: number;\n    pollInterval?: number;\n  },\n  cwd: string\n): Promise<FailFastResult> {\n  const { timeout = DEFAULT_TIMEOUT_MS, pollInterval = POLL_INTERVAL_MS } = options;\n  let { prNumber } = options;\n\n  // Get PR number if not provided\n  if (!prNumber) {\n    prNumber = await getPRForCurrentBranch(cwd) ?? undefined;\n    if (!prNumber) {\n      return {\n        success: true,\n        checks: [],\n        error: 'No PR found for current branch - skipping CI check',\n      };\n    }\n  }\n\n  // 1. Check for merge conflicts FIRST\n  const conflictCheck = await checkMergeConflicts(prNumber, cwd);\n  if (conflictCheck.hasConflicts) {\n    return {\n      success: false,\n      blockReason: `❌ PR #${prNumber} has merge conflicts. Resolve conflicts before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 2. Check if branch is out of date with main\n  const syncCheck = await checkBranchSyncStatus(cwd);\n  if (!syncCheck.inSync && syncCheck.behindCount > 0) {\n    return {\n      success: false,\n      blockReason: `❌ Branch is ${syncCheck.behindCount} commit(s) behind main. Rebase or merge main before continuing.`,\n      checks: [],\n      prNumber,\n    };\n  }\n\n  // 3. Poll CI checks with fail-fast on any failure\n  const startTime = Date.now();\n\n  while (Date.now() - startTime < timeout) {\n    const checks = await getCurrentCIChecks(prNumber, cwd);\n\n    if (checks.length === 0) {\n      // No checks yet, wait and retry\n      await new Promise((resolve) => setTimeout(resolve, pollInterval));\n      continue;\n    }\n\n    // Check for any failures - fail fast!\n    const failedCheck = checks.find((c) => c.status === 'failure' || c.status === 'cancelled');\n    if (failedCheck) {\n      return {\n        success: false,\n        blockReason: `❌ CI check \"${failedCheck.name}\" failed. Fix before continuing.`,\n        failedCheck: failedCheck.name,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Check if all checks are complete and passed\n    const allComplete = checks.every((c) => c.status === 'success');\n    if (allComplete) {\n      return {\n        success: true,\n        checks,\n        prNumber,\n      };\n    }\n\n    // Some checks still pending, wait and poll again\n    await new Promise((resolve) => setTimeout(resolve, pollInterval));\n  }\n\n  // Timeout reached\n  const finalChecks = await getCurrentCIChecks(prNumber, cwd);\n  const pendingChecks = finalChecks.filter((c) => c.status === 'pending' || c.status === 'in_progress');\n\n  return {\n    success: false,\n    blockReason: `⏱️ CI check timeout (${Math.round(timeout / 60000)} minutes). ${pendingChecks.length} check(s) still pending.`,\n    checks: finalChecks,\n    prNumber,\n    error: 'Timeout waiting for CI checks',\n  };\n}\n",
        "plugins/project-context/shared/hooks/utils/config-resolver.ts": "/**\n * Configuration File Resolver\n * Utilities for finding configuration files by traversing parent directories\n * @module config-resolver\n */\n\nimport { access } from 'fs/promises';\nimport * as path from 'path';\n\n/**\n * Find git repository root directory\n *\n * @param startDir - Directory to start searching from\n * @returns Absolute path to git root, or null if not in a git repository\n */\nasync function findGitRoot(startDir: string): Promise<string | null> {\n  let currentDir = startDir;\n\n  while (true) {\n    try {\n      await access(path.join(currentDir, '.git'));\n      return currentDir;\n    } catch {\n      const parent = path.dirname(currentDir);\n      if (parent === currentDir) return null; // Filesystem root\n      currentDir = parent;\n    }\n  }\n}\n\n/**\n * Find a configuration file by traversing parent directories\n *\n * @param startDir - Directory to start searching from (typically input.cwd)\n * @param configFileName - Name of config file to find (e.g., 'tsconfig.json')\n * @param stopAtGitRoot - Whether to stop at git repository root (default: true)\n * @returns Absolute path to config file directory, or null if not found\n *\n * @example\n * const configDir = await findConfigFile(input.cwd, 'eslint.config.mjs');\n * if (configDir) {\n *   await execAsync('npx eslint file.ts', { cwd: configDir });\n * }\n */\nexport async function findConfigFile(\n  startDir: string,\n  configFileName: string,\n  stopAtGitRoot: boolean = true\n): Promise<string | null> {\n  let currentDir = path.resolve(startDir);\n  const gitRoot = stopAtGitRoot ? await findGitRoot(currentDir) : null;\n\n  while (true) {\n    try {\n      // Check if config file exists in current directory\n      await access(path.join(currentDir, configFileName));\n      return currentDir;\n    } catch {\n      // Config not found in this directory\n    }\n\n    // Check if we should stop at git root\n    if (stopAtGitRoot && gitRoot && currentDir === gitRoot) {\n      return null;\n    }\n\n    // Move to parent directory\n    const parent = path.dirname(currentDir);\n    if (parent === currentDir) {\n      // Reached filesystem root\n      return null;\n    }\n\n    currentDir = parent;\n  }\n}\n",
        "plugins/project-context/shared/hooks/utils/debug.ts": "/**\n * Debug utilities for Claude Code hooks\n *\n * Provides logging and error handling with debug mode support. Hook events\n * are logged in JSONL format to .claude/logs/hook-events.json for debugging\n * and troubleshooting hook execution.\n *\n * Each log entry is a single JSON object per line with timestamp, event name,\n * type (input/output/error), and the associated data.\n *\n * @module debug\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst HOOK_EVENTS_FILE = 'hook-events.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface DebugConfig {\n  debug?: boolean;\n}\n\nexport interface HookEventEntry {\n  timestamp: string;\n  event: string;\n  type: 'input' | 'output' | 'error';\n  data: unknown;\n}\n\nexport interface DebugLogger {\n  logInput: (input: unknown) => Promise<void>;\n  logOutput: (output: unknown) => Promise<void>;\n  logError: (error: Error) => Promise<void>;\n}\n\n// ============================================================================\n// Debug Logging (JSONL append to hook-events.json)\n// ============================================================================\n\n/**\n * Append a hook event entry to hook-events.json (JSONL format)\n *\n * Writes a single-line JSON entry to the log file, creating the directory\n * structure if it doesn't exist. Failures are silently ignored to prevent\n * logging errors from breaking hook execution.\n *\n * @param cwd - The working directory where .claude/logs/ should be created\n * @param entry - The hook event entry to append to the log file\n * @returns Promise that resolves when the entry is written (or fails silently)\n *\n * @example\n * ```typescript\n * await appendHookEvent('/path/to/project', {\n *   timestamp: new Date().toISOString(),\n *   event: 'SessionStart',\n *   type: 'input',\n *   data: { cwd: '/path/to/project' }\n * });\n * ```\n */\nasync function appendHookEvent(cwd: string, entry: HookEventEntry): Promise<void> {\n  const logDir = path.join(cwd, LOGS_DIR);\n  const logFile = path.join(logDir, HOOK_EVENTS_FILE);\n\n  try {\n    await fs.mkdir(logDir, { recursive: true });\n    await fs.appendFile(logFile, JSON.stringify(entry) + '\\n', 'utf-8');\n  } catch {\n    // Silently fail - don't break hook execution for logging\n  }\n}\n\n/**\n * Create a debug logger for a hook execution\n *\n * Returns a logger object with methods for logging hook inputs, outputs, and errors\n * to .claude/logs/hook-events.json in JSONL format. Logging only occurs when debug\n * mode is enabled.\n *\n * @param cwd - The working directory where logs should be written\n * @param hookEventName - The name of the hook event (e.g., 'SessionStart', 'PostToolUse')\n * @param debug - Whether debug logging is enabled\n * @returns A DebugLogger with logInput, logOutput, and logError methods\n *\n * @example\n * ```typescript\n * import { createDebugLogger } from './debug.js';\n *\n * const logger = createDebugLogger('/path/to/project', 'SessionStart', true);\n *\n * await logger.logInput({ cwd: '/path/to/project', source: 'startup' });\n * await logger.logOutput({ success: true, message: 'Hook completed' });\n * ```\n */\nexport function createDebugLogger(\n  cwd: string,\n  hookEventName: string,\n  _debug: boolean\n): DebugLogger {\n  return {\n    logInput: async (input: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'input',\n        data: input,\n      });\n    },\n\n    logOutput: async (output: unknown) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'output',\n        data: output,\n      });\n    },\n\n    logError: async (error: Error) => {\n      // Always log hook events regardless of debug flag\n      await appendHookEvent(cwd, {\n        timestamp: new Date().toISOString(),\n        event: hookEventName,\n        type: 'error',\n        data: {\n          name: error.name,\n          message: error.message,\n          stack: error.stack,\n        },\n      });\n    },\n  };\n}\n\n// ============================================================================\n// Error Handling\n// ============================================================================\n\n/**\n * Create a blocking error response for hooks\n *\n * Generates an appropriate error response object that blocks execution when\n * a hook error occurs in debug mode. The response format varies by hook event\n * type to match the expected output schema.\n *\n * @param hookEventName - The name of the hook event that errored\n * @param error - The error that occurred during hook execution\n * @returns A hook output object configured to block/deny with error details\n *\n * @example\n * ```typescript\n * import { createBlockingErrorResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   return createBlockingErrorResponse('PreToolUse', error as Error);\n *   // Returns: { hookSpecificOutput: { permissionDecision: 'deny', ... } }\n * }\n * ```\n */\nexport function createBlockingErrorResponse(\n  hookEventName: string,\n  error: Error\n): Record<string, unknown> {\n  const baseResponse = {\n    continue: false,\n    stopReason: `Hook error: ${error.message}`,\n    systemMessage: `Hook ${hookEventName} failed: ${error.message}`,\n  };\n\n  // Add hook-specific output based on event type\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        ...baseResponse,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'PostToolUse':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'PostToolUse',\n          additionalContext: `Hook error: ${error.message}\\n${error.stack || ''}`,\n        },\n      };\n\n    case 'SubagentStop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    case 'UserPromptSubmit':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n        hookSpecificOutput: {\n          hookEventName: 'UserPromptSubmit',\n          additionalContext: `Hook error: ${error.message}`,\n        },\n      };\n\n    case 'Stop':\n      return {\n        ...baseResponse,\n        decision: 'block',\n        reason: `Hook error: ${error.message}`,\n      };\n\n    default:\n      return baseResponse;\n  }\n}\n\n/**\n * Create a pass-through response for hooks\n *\n * Generates an appropriate response object that allows execution to continue\n * when a hook error occurs and debug mode is disabled. The response format\n * varies by hook event type to match the expected output schema while permitting\n * normal Claude Code operation.\n *\n * @param hookEventName - The name of the hook event\n * @returns A hook output object configured to allow/pass-through\n *\n * @example\n * ```typescript\n * import { createPassthroughResponse } from './debug.js';\n *\n * try {\n *   // Hook logic that might throw\n * } catch (error) {\n *   if (!debugMode) {\n *     return createPassthroughResponse('PreToolUse');\n *     // Returns: { hookSpecificOutput: { permissionDecision: 'allow' } }\n *   }\n * }\n * ```\n */\nexport function createPassthroughResponse(hookEventName: string): Record<string, unknown> {\n  switch (hookEventName) {\n    case 'PreToolUse':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n\n    case 'PostToolUse':\n      return {};\n\n    case 'SessionStart':\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'SessionStart',\n          additionalContext: '',\n        },\n      };\n\n    case 'SubagentStart':\n      return {};\n\n    case 'SubagentStop':\n      return {};\n\n    default:\n      return {};\n  }\n}\n",
        "plugins/project-context/shared/hooks/utils/frontmatter.ts": "/**\n * Simple YAML frontmatter parser - zero dependencies\n *\n * Replaces gray-matter with a lightweight custom implementation\n * that handles the basic YAML frontmatter patterns used in this project.\n *\n * @module frontmatter\n */\n\n/**\n * Parse YAML frontmatter from markdown content\n *\n * Extracts YAML frontmatter between --- delimiters and parses\n * simple key-value pairs and arrays. Returns data object and remaining content.\n *\n * Supported YAML patterns:\n * - Simple key-value: `name: value`\n * - Arrays: `skills: [item1, item2]` or multi-line arrays\n * - Nested (basic): `field: { key: value }`\n *\n * @param content - Markdown content with optional frontmatter\n * @returns Object with `data` (parsed YAML) and `content` (remaining markdown)\n *\n * @example\n * ```typescript\n * import { parseFrontmatter } from './frontmatter.js';\n *\n * const markdown = `---\n * name: MyAgent\n * skills: [skill1, skill2]\n * ---\n *\n * # Content here\n * `;\n *\n * const { data, content } = parseFrontmatter(markdown);\n * console.log(data.name); // 'MyAgent'\n * console.log(data.skills); // ['skill1', 'skill2']\n * ```\n */\nexport function parseFrontmatter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  const frontmatterRegex = /^---\\s*\\n([\\s\\S]*?)\\n---\\s*\\n([\\s\\S]*)$/;\n  const match = content.match(frontmatterRegex);\n\n  if (!match) {\n    return { data: {}, content };\n  }\n\n  const [, yamlContent, remainingContent] = match;\n  const data = parseSimpleYaml(yamlContent);\n\n  return { data, content: remainingContent };\n}\n\n/**\n * Parse simple YAML content into JavaScript object\n *\n * Handles common YAML patterns used in frontmatter:\n * - Key-value pairs\n * - Inline arrays: [item1, item2, item3]\n * - Multi-line arrays with - prefix\n * - Nested objects (basic)\n *\n * @param yaml - YAML content string\n * @returns Parsed JavaScript object\n */\nfunction parseSimpleYaml(yaml: string): Record<string, unknown> {\n  const data: Record<string, unknown> = {};\n  const lines = yaml.split('\\n');\n  let i = 0;\n\n  while (i < lines.length) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      i++;\n      continue;\n    }\n\n    // Parse key-value pair\n    const colonIndex = line.indexOf(':');\n    if (colonIndex === -1) {\n      i++;\n      continue;\n    }\n\n    const key = line.substring(0, colonIndex).trim();\n    const value = line.substring(colonIndex + 1).trim();\n\n    // Handle inline array: [item1, item2]\n    if (value.startsWith('[') && value.endsWith(']')) {\n      const arrayContent = value.slice(1, -1);\n      data[key] = arrayContent.split(',').map(item => parseValue(item.trim()));\n      i++;\n      continue;\n    }\n\n    // Handle multi-line array\n    if (value === '' && i + 1 < lines.length && lines[i + 1].trim().startsWith('-')) {\n      const arrayItems: string[] = [];\n      i++;\n      while (i < lines.length && lines[i].trim().startsWith('-')) {\n        const item = lines[i].trim().substring(1).trim();\n        arrayItems.push(item);\n        i++;\n      }\n      data[key] = arrayItems;\n      continue;\n    }\n\n    // Handle inline object: { key: value }\n    if (value.startsWith('{') && value.endsWith('}')) {\n      const objectContent = value.slice(1, -1);\n      const obj: Record<string, unknown> = {};\n      const pairs = objectContent.split(',');\n      for (const pair of pairs) {\n        const [objKey, objValue] = pair.split(':').map(s => s.trim());\n        obj[objKey] = parseValue(objValue);\n      }\n      data[key] = obj;\n      i++;\n      continue;\n    }\n\n    // Handle simple value\n    data[key] = parseValue(value);\n    i++;\n  }\n\n  return data;\n}\n\n/**\n * Parse a YAML value to appropriate JavaScript type\n *\n * Converts:\n * - 'true'/'false' → boolean\n * - 'null' → null\n * - Numbers → number\n * - Quoted strings → unquoted string\n * - Everything else → string\n *\n * @param value - YAML value string\n * @returns Parsed value in appropriate type\n */\nfunction parseValue(value: string): unknown {\n  // Handle boolean\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle null\n  if (value === 'null' || value === '~') return null;\n\n  // Handle number\n  if (/^-?\\d+(\\.\\d+)?$/.test(value)) {\n    return Number(value);\n  }\n\n  // Handle quoted strings\n  if ((value.startsWith('\"') && value.endsWith('\"')) ||\n      (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n    return value.slice(1, -1);\n  }\n\n  // Return as string\n  return value;\n}\n\n/**\n * gray-matter compatible interface\n *\n * Provides same API as gray-matter for drop-in replacement.\n *\n * @param content - Markdown content with frontmatter\n * @returns Object with `data` and `content` properties\n */\nexport default function matter(content: string): {\n  data: Record<string, unknown>;\n  content: string;\n} {\n  return parseFrontmatter(content);\n}\n",
        "plugins/project-context/shared/hooks/utils/github-comments.ts": "/**\n * GitHub comment utilities for Stop hook\n *\n * Provides utilities for:\n * - Checking if a session comment exists on a GitHub issue\n * - Posting session progress comments with session ID markers\n * - Discovering the linked issue number for a branch\n *\n * Session comments include a hidden HTML marker that allows the Stop hook\n * to detect whether progress has been documented for a given session.\n * @module github-comments\n */\n\nimport { exec, spawn } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\n\nconst execAsync = promisify(exec);\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst COMMENT_MARKER_PREFIX = '<!-- claude-session: ';\nconst COMMENT_MARKER_SUFFIX = ' -->';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Plan issue state tracking\n */\ninterface PlanIssueState {\n  /**\n   * Map of session IDs to issue metadata\n   */\n  [sessionId: string]: {\n    /**\n     * Path to the plan file\n     */\n    planPath: string;\n    /**\n     * GitHub issue number\n     */\n    issueNumber: number;\n    /**\n     * Full GitHub issue URL\n     */\n    issueUrl: string;\n    /**\n     * Git branch name\n     */\n    branch: string;\n    /**\n     * ISO timestamp when issue was created\n     */\n    createdAt: string;\n    /**\n     * ISO timestamp of last update\n     */\n    lastUpdated: string;\n  };\n}\n\n/**\n * GitHub issue with comments\n */\ninterface GitHubIssue {\n  /**\n   * Issue number\n   */\n  number: number;\n  /**\n   * Issue title\n   */\n  title: string;\n  /**\n   * Issue body content\n   */\n  body: string;\n  /**\n   * Issue comments\n   */\n  comments?: Array<{\n    /**\n     * Comment author\n     */\n    author: { login: string };\n    /**\n     * Comment body\n     */\n    body: string;\n    /**\n     * ISO timestamp when comment was created\n     */\n    createdAt: string;\n  }>;\n}\n\n// ============================================================================\n// Command Execution\n// ============================================================================\n\n/**\n * Execute a shell command\n * @param command - Shell command to execute\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execCommand('git rev-parse --abbrev-ref HEAD', '/path/to/project');\n * if (result.success) {\n *   console.log('Branch:', result.stdout);\n * }\n * ```\n */\nasync function execCommand(\n  command: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  try {\n    const { stdout, stderr } = await execAsync(command, { cwd, timeout: 30000 });\n    return { success: true, stdout: stdout.trim(), stderr: stderr.trim() };\n  } catch (error: unknown) {\n    const err = error as { stdout?: string; stderr?: string; message?: string };\n    return {\n      success: false,\n      stdout: err.stdout?.trim() || '',\n      stderr: err.stderr?.trim() || err.message || '',\n    };\n  }\n}\n\n/**\n * Execute gh command with stdin for large body content\n *\n * Uses spawn + stdin to avoid shell escaping issues when passing\n * markdown content with special characters.\n * @param args - Arguments to pass to gh command\n * @param stdin - Content to write to stdin\n * @param cwd - Working directory\n * @returns Command result with success flag, stdout, and stderr\n * @example\n * ```typescript\n * const result = await execGhWithStdin(\n *   ['issue', 'comment', '123', '--body-file', '-'],\n *   'This is my comment content',\n *   '/path/to/project'\n * );\n * ```\n */\nasync function execGhWithStdin(\n  args: string[],\n  stdin: string,\n  cwd: string\n): Promise<{ success: boolean; stdout: string; stderr: string }> {\n  return new Promise((resolve) => {\n    const child = spawn('gh', args, { cwd });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout.on('data', (data) => {\n      stdout += data.toString();\n    });\n\n    child.stderr.on('data', (data) => {\n      stderr += data.toString();\n    });\n\n    child.on('close', (code) => {\n      resolve({\n        success: code === 0,\n        stdout: stdout.trim(),\n        stderr: stderr.trim(),\n      });\n    });\n\n    child.on('error', (error) => {\n      resolve({\n        success: false,\n        stdout: '',\n        stderr: error.message,\n      });\n    });\n\n    // Write body to stdin and close\n    child.stdin.write(stdin);\n    child.stdin.end();\n  });\n}\n\n// ============================================================================\n// Issue Discovery\n// ============================================================================\n\n/**\n * Load plan issue state from disk\n * @param cwd - Working directory\n * @returns Plan issue state map\n * @example\n * ```typescript\n * const state = await loadPlanIssueState('/path/to/project');\n * const sessionInfo = state['session-id'];\n * if (sessionInfo) {\n *   console.log('Issue number:', sessionInfo.issueNumber);\n * }\n * ```\n */\nasync function loadPlanIssueState(cwd: string): Promise<PlanIssueState> {\n  const stateFile = path.join(cwd, '.claude', 'logs', 'plan-issues.json');\n\n  try {\n    const data = await fs.readFile(stateFile, 'utf-8');\n    return JSON.parse(data);\n  } catch {\n    // File doesn't exist yet or is invalid\n    return {};\n  }\n}\n\n/**\n * Parse issue number from branch name\n *\n * Extracts issue number from branch names like:\n * - issue-123-description\n * - feature/issue-456\n * - 789-fix-bug\n * @param branch - Git branch name\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNum = parseIssueFromBranch('issue-123-add-feature');\n * // Returns: 123\n *\n * const noIssue = parseIssueFromBranch('main');\n * // Returns: null\n * ```\n */\nfunction parseIssueFromBranch(branch: string): number | null {\n  // Try pattern: issue-123-...\n  const issueMatch = branch.match(/issue[_-](\\d+)/i);\n  if (issueMatch) {\n    return parseInt(issueMatch[1], 10);\n  }\n\n  // Try pattern: 123-...\n  const numMatch = branch.match(/^(\\d+)[_-]/);\n  if (numMatch) {\n    return parseInt(numMatch[1], 10);\n  }\n\n  return null;\n}\n\n/**\n * Get linked issue number for current branch\n *\n * Discovers issue number using cascading fallback strategy:\n * 1. Check plan-issues.json state file (by session ID and branch name)\n * 2. Parse from branch name pattern (issue-123-...)\n * 3. Search GitHub for issues mentioning the branch\n * @param branch - Git branch name\n * @param cwd - Working directory\n * @returns Issue number or null if not found\n * @example\n * ```typescript\n * const issueNumber = await getLinkedIssueNumber('issue-57-stop-hook', '/path/to/project');\n * if (issueNumber) {\n *   console.log('Linked to issue #' + issueNumber);\n * }\n * ```\n */\nexport async function getLinkedIssueNumber(\n  branch: string,\n  cwd: string\n): Promise<number | null> {\n  // STRATEGY 1: Check plan-issues.json state file\n  const state = await loadPlanIssueState(cwd);\n\n  // Find by branch name across all sessions\n  for (const sessionState of Object.values(state)) {\n    if (sessionState.branch === branch) {\n      return sessionState.issueNumber;\n    }\n  }\n\n  // STRATEGY 2: Parse from branch name\n  const parsedIssue = parseIssueFromBranch(branch);\n  if (parsedIssue !== null) {\n    // Verify issue exists\n    const verifyResult = await execCommand(`gh issue view ${parsedIssue} --json number`, cwd);\n    if (verifyResult.success) {\n      return parsedIssue;\n    }\n  }\n\n  // STRATEGY 3: Search GitHub for issues mentioning the branch\n  const searchResult = await execCommand(\n    `gh issue list --search \"in:body ${branch}\" --json number --limit 1`,\n    cwd\n  );\n\n  if (searchResult.success && searchResult.stdout) {\n    try {\n      const issues = JSON.parse(searchResult.stdout);\n      if (issues.length > 0) {\n        return issues[0].number;\n      }\n    } catch {\n      // Parse error\n    }\n  }\n\n  return null;\n}\n\n// ============================================================================\n// Comment Management\n// ============================================================================\n\n/**\n * Create session comment marker\n * @param sessionId - Session ID to embed in marker\n * @returns HTML comment marker\n * @example\n * ```typescript\n * const marker = createSessionMarker('abc-123');\n * // Returns: '<!-- claude-session: abc-123 -->'\n * ```\n */\nfunction createSessionMarker(sessionId: string): string {\n  return `${COMMENT_MARKER_PREFIX}${sessionId}${COMMENT_MARKER_SUFFIX}`;\n}\n\n/**\n * Check if a comment contains a session marker\n * @param commentBody - Comment body text\n * @param sessionId - Session ID to search for\n * @returns True if comment contains the session marker\n * @example\n * ```typescript\n * const hasMarker = commentHasSessionMarker(\n *   '<!-- claude-session: abc-123 -->\\n\\nMy comment',\n *   'abc-123'\n * );\n * // Returns: true\n * ```\n */\nfunction commentHasSessionMarker(commentBody: string, sessionId: string): boolean {\n  const marker = createSessionMarker(sessionId);\n  return commentBody.includes(marker);\n}\n\n/**\n * Check if a session comment exists on a GitHub issue\n *\n * Fetches all comments for the issue and searches for the session ID marker.\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID to search for\n * @param cwd - Working directory\n * @returns True if a comment with the session marker exists\n * @example\n * ```typescript\n * import { hasCommentForSession } from './github-comments.js';\n *\n * const hasComment = await hasCommentForSession(57, 'session-abc-123', '/path/to/project');\n * if (hasComment) {\n *   console.log('Progress already documented for this session');\n * }\n * ```\n */\nexport async function hasCommentForSession(\n  issueNumber: number,\n  sessionId: string,\n  cwd: string\n): Promise<boolean> {\n  // Fetch issue with comments\n  const result = await execCommand(\n    `gh issue view ${issueNumber} --json comments`,\n    cwd\n  );\n\n  if (!result.success) {\n    return false;\n  }\n\n  try {\n    const issue: GitHubIssue = JSON.parse(result.stdout);\n\n    if (!issue.comments || issue.comments.length === 0) {\n      return false;\n    }\n\n    // Search for session marker in comments\n    return issue.comments.some((comment) =>\n      commentHasSessionMarker(comment.body, sessionId)\n    );\n  } catch {\n    // Parse error\n    return false;\n  }\n}\n\n/**\n * Post a session progress comment to a GitHub issue\n *\n * Creates a formatted comment with:\n * - Hidden session ID marker for detection\n * - Session metadata (ID, branch, timestamp)\n * - User-provided content\n * @param issueNumber - GitHub issue number\n * @param sessionId - Session ID\n * @param content - Comment content (markdown)\n * @param branch - Current git branch\n * @param cwd - Working directory\n * @returns True if comment was posted successfully\n * @example\n * ```typescript\n * import { postSessionComment } from './github-comments.js';\n *\n * const posted = await postSessionComment(\n *   57,\n *   'session-abc-123',\n *   'Completed hook implementation and tests',\n *   'issue-57-stop-hook',\n *   '/path/to/project'\n * );\n * if (posted) {\n *   console.log('Comment posted successfully');\n * }\n * ```\n */\nexport async function postSessionComment(\n  issueNumber: number,\n  sessionId: string,\n  content: string,\n  branch: string,\n  cwd: string\n): Promise<boolean> {\n  const timestamp = new Date().toISOString();\n  const marker = createSessionMarker(sessionId);\n\n  const commentBody = `${marker}\n\n## 🤖 Claude Session Progress\n\n**Session ID:** \\`${sessionId}\\`\n**Branch:** \\`${branch}\\`\n**Timestamp:** ${timestamp}\n\n${content}\n\n---\n*Posted automatically via Stop hook*`;\n\n  const result = await execGhWithStdin(\n    ['issue', 'comment', issueNumber.toString(), '--body-file', '-'],\n    commentBody,\n    cwd\n  );\n\n  return result.success;\n}\n",
        "plugins/project-context/shared/hooks/utils/index.ts": "/**\n * Hook Utilities - Re-exports\n *\n * Centralized exports for all hook utility functions, types, and helpers.\n * This index file provides convenient access to all shared utilities used\n * across Claude Code plugins.\n *\n * For smaller bundle sizes, prefer importing directly from individual modules\n * rather than using this index file. Direct imports allow tree-shaking to\n * eliminate unused code.\n *\n * @example\n * ```typescript\n * // Preferred: Direct import (better for tree-shaking)\n * import { readStdinJson } from './utils/io.js';\n * import { createDebugLogger } from './utils/debug.js';\n *\n * // Alternative: Import from index (more convenient)\n * import { readStdinJson, createDebugLogger } from './utils/index.js';\n * ```\n *\n * @module utils/index\n */\n\n// ============================================================================\n// I/O Utilities and Hook Runner\n// ============================================================================\n// Functions for reading hook input from stdin, writing output to stdout,\n// and wrapping hook handlers for execution.\n\nexport { readStdinJson, writeStdoutJson, runHook, type HookHandler } from './io.js';\n\n// ============================================================================\n// Debug Utilities\n// ============================================================================\n// Debug logging with JSONL output to .claude/logs/hook-events.json.\n// Supports DEBUG environment variable for filtering output.\n\nexport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  createPassthroughResponse,\n  type DebugConfig,\n  type DebugLogger,\n  type HookEventEntry,\n} from './debug.js';\n\n// ============================================================================\n// Transcript Parsing\n// ============================================================================\n// Parse Claude Code transcript JSONL files to analyze agent conversations,\n// tool uses, and file operations.\n\nexport {\n  parseTranscript,\n  parseTranscriptLine,\n  getTranscriptInfo,\n  getToolUses,\n  getEditedFiles,\n  getNewFiles,\n  getDeletedFiles,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  type Transcript,\n  type Message,\n  type UserMessage,\n  type AssistantMessage,\n  type SystemMessage,\n} from './transcripts.js';\n\n// ============================================================================\n// Subagent State Management\n// ============================================================================\n// Save and load subagent execution context, and analyze file operations\n// performed by agents.\n\nexport {\n  saveAgentStartContext,\n  loadAgentStartContext,\n  removeAgentStartContext,\n  getAgentEdits,\n  type AgentStartContext,\n  type AgentEditsResult,\n} from './subagent-state.js';\n\n// ============================================================================\n// Task State Management\n// ============================================================================\n// Save and load Task tool call context, and analyze file operations\n// performed within tasks.\n\nexport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n  getTaskEdits,\n  type TaskCallContext,\n  type TaskEditsResult,\n} from './task-state.js';\n\n// ============================================================================\n// Package Manager Detection\n// ============================================================================\n// Detect which package manager (npm, yarn, pnpm, bun) a project uses\n// and construct appropriate commands.\n\nexport { detectPackageManager, getScriptCommand } from './package-manager.js';\n\n// ============================================================================\n// TOML Parsing\n// ============================================================================\n// Simple TOML parser for reading configuration files like supabase/config.toml.\n\nexport { parseToml, readTomlFile, type TomlValue } from './toml.js';\n\n// ============================================================================\n// Agent Type Detection\n// ============================================================================\n// Utilities for determining if a tool event was triggered by the main agent\n// or a subagent, and extracting agent IDs from transcripts.\n\nexport {\n  wasToolEventMainAgent,\n  isMainAgentTranscript,\n  isSubagentType,\n  getTranscriptAgentId,\n} from './was-tool-event-main-agent.js';\n\n// ============================================================================\n// Log File Utilities\n// ============================================================================\n// Save hook output to log files and return concise summaries.\n// Used to reduce context injection while preserving full output for debugging.\n\nexport {\n  saveOutputToLog,\n  parseEslintCounts,\n  parseTscErrorCount,\n  parseVitestResults,\n  parseCiChecks,\n  formatCiChecksTable,\n  formatErrorSummary,\n  formatSuccessMessage,\n} from './log-file.js';\n\n// ============================================================================\n// Rules Matching\n// ============================================================================\n// Discover rules files and match them against edited files based on\n// glob patterns in frontmatter.\n\nexport {\n  discoverRules,\n  matchRulesToFiles,\n  formatRulesContext,\n  type RuleFile,\n} from './rules-matcher.js';\n",
        "plugins/project-context/shared/hooks/utils/io.ts": "/**\n * I/O utilities for Claude Code hooks\n *\n * Provides stdin/stdout JSON handling and the runHook wrapper for\n * creating self-executable hooks. Claude Code passes hook input via\n * stdin as JSON and expects hook output as JSON on stdout.\n *\n * @module io\n */\n\nimport type { HookInput, HookOutput } from '../../types/types.js';\nimport {\n  createDebugLogger,\n  createBlockingErrorResponse,\n  type DebugConfig,\n} from './debug.js';\n\n/**\n * Read and parse JSON from stdin\n *\n * Reads all data from stdin, concatenates chunks, and parses as JSON.\n * Used by hook runners to receive hook input from Claude Code.\n *\n * @template T - Expected type of the parsed JSON (defaults to unknown)\n * @returns Promise that resolves to the parsed JSON data\n * @throws Error if stdin cannot be read or JSON parsing fails\n *\n * @example\n * ```typescript\n * import { readStdinJson } from './utils/io.js';\n * import type { SubagentStopInput } from '../../types/types.js';\n *\n * const input = await readStdinJson<SubagentStopInput>();\n * console.log(input.agent_id);\n * ```\n */\nexport async function readStdinJson<T = unknown>(): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const chunks: Buffer[] = [];\n\n    process.stdin.on('data', (chunk) => {\n      // Handle both Buffer and string inputs\n      if (Buffer.isBuffer(chunk)) {\n        chunks.push(chunk);\n      } else {\n        chunks.push(Buffer.from(chunk));\n      }\n    });\n    process.stdin.on('end', () => {\n      try {\n        const data = Buffer.concat(chunks).toString('utf8');\n        resolve(JSON.parse(data) as T);\n      } catch (error) {\n        reject(new Error(`Failed to parse JSON input: ${error}`));\n      }\n    });\n    process.stdin.on('error', (error) => {\n      reject(new Error(`Failed to read stdin: ${error}`));\n    });\n  });\n}\n\n/**\n * Write JSON output to stdout\n *\n * Serializes the output object to JSON and writes it to stdout with a trailing newline.\n * Used by hook runners to return hook output to Claude Code.\n *\n * @param output - The output object to serialize and write\n *\n * @example\n * ```typescript\n * import { writeStdoutJson } from './utils/io.js';\n * import type { SubagentStopHookOutput } from '../../types/types.js';\n *\n * const output: SubagentStopHookOutput = { continue: true };\n * writeStdoutJson(output);\n * ```\n */\nexport function writeStdoutJson(output: unknown): void {\n  process.stdout.write(JSON.stringify(output) + '\\n');\n}\n\n/**\n * Hook handler function type\n */\nexport type HookHandler<I extends HookInput = HookInput, O extends HookOutput = HookOutput> = (\n  input: I\n) => O | Promise<O>;\n\n/**\n * Run a hook as a self-executable script\n *\n * This function wraps a hook handler to make it self-executable when called\n * with `npx tsx`. It reads input from stdin, executes the hook, and writes\n * the output to stdout.\n *\n * @template I - Hook input type\n * @template O - Hook output type\n * @param handler - The hook handler function to execute\n *\n * @example\n * ```typescript\n * // my-hook.ts\n * import { runHook } from '../../../shared/hooks/utils/io.js';\n * import type { SessionStartInput, SessionStartHookOutput } from '../../../shared/types/types.js';\n *\n * async function handler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Hook executed successfully',\n *     },\n *   };\n * }\n *\n * // Make this file self-executable\n * runHook(handler);\n * ```\n */\nexport function runHook<I extends HookInput = HookInput, O extends HookOutput = HookOutput>(\n  handler: HookHandler<I, O>\n): void {\n  main(handler).catch((error) => {\n    console.error('Hook fatal error:', error);\n    process.exit(1);\n  });\n}\n\n/**\n * Main hook execution function\n *\n * Handles the complete hook lifecycle: reads input from stdin, executes the handler,\n * and writes output to stdout. All errors are caught and converted to blocking responses.\n *\n * @param handler - Hook handler function to execute\n * @returns Promise that resolves when hook completes\n *\n * @example\n * ```typescript\n * async function myHandler(input: SessionStartInput): Promise<SessionStartHookOutput> {\n *   return {\n *     hookSpecificOutput: {\n *       hookEventName: 'SessionStart',\n *       additionalContext: 'Success',\n *     },\n *   };\n * }\n *\n * await main(myHandler);\n * ```\n */\nasync function main<I extends HookInput, O extends HookOutput>(\n  handler: HookHandler<I, O>\n): Promise<void> {\n  let input: I & DebugConfig;\n  let hookEventName = 'unknown';\n  let cwd = process.cwd();\n  let debug = false;\n\n  try {\n    // Read input from stdin\n    input = await readStdinJson<I & DebugConfig>();\n    hookEventName = (input as { hook_event_name?: string }).hook_event_name || 'unknown';\n    cwd = (input as { cwd?: string }).cwd || process.cwd();\n    debug = input.debug === true;\n  } catch (error) {\n    // Can't even read input - exit with error\n    console.error('Failed to read hook input:', error);\n    process.exit(1);\n  }\n\n  const logger = createDebugLogger(cwd, hookEventName, debug);\n\n  try {\n    // Log input if debug enabled\n    await logger.logInput(input);\n\n    // Execute hook handler\n    const output = await handler(input);\n\n    // Log output if debug enabled\n    await logger.logOutput(output);\n\n    // Write output to stdout\n    writeStdoutJson(output);\n\n  } catch (error) {\n    const err = error instanceof Error ? error : new Error(String(error));\n\n    // Log error\n    await logger.logError(err);\n\n    // ALWAYS return blocking error response\n    // Debug flag controls logging only, not blocking behavior\n    const errorResponse = createBlockingErrorResponse(hookEventName, err);\n    writeStdoutJson(errorResponse);\n  }\n}\n",
        "plugins/project-context/shared/hooks/utils/log-file.ts": "/**\n * Log File Utilities\n *\n * Functions for saving hook output to log files in `.claude/logs/`.\n * Used to preserve full output while returning concise summaries to Claude.\n *\n * @module utils/log-file\n */\n\nimport * as fs from 'node:fs/promises';\nimport * as path from 'node:path';\n\n/**\n * Saves output content to a log file and returns the relative path.\n *\n * Creates timestamped log files in `.claude/logs/` directory.\n * The directory is created if it doesn't exist.\n *\n * @param cwd - Current working directory (project root)\n * @param category - Log category (e.g., 'eslint', 'tsc', 'ci')\n * @param identifier - Unique identifier (e.g., filename, check name)\n * @param content - Content to save to the log file\n * @returns Relative path to the created log file\n *\n * @example\n * ```typescript\n * const logPath = await saveOutputToLog(\n *   '/project',\n *   'eslint',\n *   'Button.tsx',\n *   eslintOutput\n * );\n * // Returns: '.claude/logs/eslint-Button.tsx-2025-01-02T10-30-00-000Z.log'\n * ```\n */\nexport async function saveOutputToLog(\n  cwd: string,\n  category: string,\n  identifier: string,\n  content: string\n): Promise<string> {\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n  // Sanitize identifier to be filesystem-safe\n  const safeIdentifier = identifier.replace(/[/\\\\:*?\"<>|]/g, '-');\n  const filename = `${category}-${safeIdentifier}-${timestamp}.log`;\n  const logDir = path.join(cwd, '.claude', 'logs');\n  const logPath = path.join(logDir, filename);\n\n  await fs.mkdir(logDir, { recursive: true });\n  await fs.writeFile(logPath, content, 'utf-8');\n\n  // Return relative path for display\n  return `.claude/logs/${filename}`;\n}\n\n/**\n * Parses error/warning counts from ESLint output.\n *\n * @param output - ESLint stdout/stderr output\n * @returns Object with error and warning counts\n *\n * @example\n * ```typescript\n * const counts = parseEslintCounts(eslintOutput);\n * // Returns: { errors: 3, warnings: 2 }\n * ```\n */\nexport function parseEslintCounts(output: string): { errors: number; warnings: number } {\n  // ESLint summary line format: \"✖ 5 problems (3 errors, 2 warnings)\"\n  const summaryMatch = output.match(/(\\d+)\\s+problems?\\s+\\((\\d+)\\s+errors?,\\s+(\\d+)\\s+warnings?\\)/i);\n  if (summaryMatch) {\n    return {\n      errors: parseInt(summaryMatch[2], 10),\n      warnings: parseInt(summaryMatch[3], 10),\n    };\n  }\n\n  // Alternative: count individual error/warning lines\n  const errorLines = (output.match(/error\\s/gi) || []).length;\n  const warningLines = (output.match(/warning\\s/gi) || []).length;\n\n  return { errors: errorLines, warnings: warningLines };\n}\n\n/**\n * Parses error count from TypeScript compiler output.\n *\n * @param output - TypeScript compiler stdout/stderr output\n * @returns Number of type errors found\n *\n * @example\n * ```typescript\n * const errorCount = parseTscErrorCount(tscOutput);\n * // Returns: 5\n * ```\n */\nexport function parseTscErrorCount(output: string): number {\n  // TypeScript summary: \"Found 5 errors in 3 files.\"\n  const summaryMatch = output.match(/Found\\s+(\\d+)\\s+errors?/i);\n  if (summaryMatch) {\n    return parseInt(summaryMatch[1], 10);\n  }\n\n  // Alternative: count \"error TS\" occurrences\n  const errorMatches = output.match(/error\\s+TS\\d+/gi) || [];\n  return errorMatches.length;\n}\n\n/**\n * Parses test results from Vitest output.\n *\n * @param output - Vitest stdout/stderr output\n * @returns Object with passed, failed, and skipped counts\n *\n * @example\n * ```typescript\n * const results = parseVitestResults(vitestOutput);\n * // Returns: { passed: 10, failed: 2, skipped: 1 }\n * ```\n */\nexport function parseVitestResults(output: string): {\n  passed: number;\n  failed: number;\n  skipped: number;\n} {\n  // Vitest summary: \"Tests  2 failed | 10 passed | 1 skipped (13)\"\n  const passed = parseInt(output.match(/(\\d+)\\s+passed/i)?.[1] || '0', 10);\n  const failed = parseInt(output.match(/(\\d+)\\s+failed/i)?.[1] || '0', 10);\n  const skipped = parseInt(output.match(/(\\d+)\\s+skipped/i)?.[1] || '0', 10);\n\n  return { passed, failed, skipped };\n}\n\n/**\n * Parses CI check status from `gh pr checks` output.\n *\n * @param output - Output from `gh pr checks` command\n * @returns Array of check statuses with name, status, and duration\n *\n * @example\n * ```typescript\n * const checks = parseCiChecks(ghOutput);\n * // Returns: [\n * //   { name: 'lint', status: 'pass', duration: '2m30s' },\n * //   { name: 'test', status: 'fail', duration: '5m10s' }\n * // ]\n * ```\n */\nexport function parseCiChecks(\n  output: string\n): Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }> {\n  const checks: Array<{\n    name: string;\n    status: 'pass' | 'fail' | 'pending' | 'skipped';\n    duration: string;\n  }> = [];\n\n  // gh pr checks output format:\n  // lint    pass    2m30s   https://github.com/...\n  // test    fail    5m10s   https://github.com/...\n  const lines = output.split('\\n').filter((line) => line.trim());\n\n  for (const line of lines) {\n    // Split by whitespace, handling variable spacing\n    const parts = line.split(/\\s+/).filter(Boolean);\n    if (parts.length >= 2) {\n      const name = parts[0];\n      const statusRaw = parts[1].toLowerCase();\n\n      let status: 'pass' | 'fail' | 'pending' | 'skipped';\n      if (statusRaw === 'pass' || statusRaw === 'success' || statusRaw === '✓') {\n        status = 'pass';\n      } else if (statusRaw === 'fail' || statusRaw === 'failure' || statusRaw === '✗') {\n        status = 'fail';\n      } else if (statusRaw === 'skipped' || statusRaw === 'neutral') {\n        status = 'skipped';\n      } else {\n        status = 'pending';\n      }\n\n      const duration = parts[2] || '';\n\n      checks.push({ name, status, duration });\n    }\n  }\n\n  return checks;\n}\n\n/**\n * Formats CI checks as a concise emoji status table.\n *\n * @param checks - Array of parsed CI checks\n * @param logPath - Optional path to full log file (shown for failures)\n * @returns Formatted string with emoji status indicators\n *\n * @example\n * ```typescript\n * const table = formatCiChecksTable(checks, '.claude/logs/ci.log');\n * // Returns:\n * // ✅ lint (2m30s)\n * // ❌ test (5m10s) → .claude/logs/ci.log\n * // ⏳ deploy\n * ```\n */\nexport function formatCiChecksTable(\n  checks: Array<{ name: string; status: 'pass' | 'fail' | 'pending' | 'skipped'; duration: string }>,\n  logPath?: string\n): string {\n  const statusEmoji = {\n    pass: '✅',\n    fail: '❌',\n    pending: '⏳',\n    skipped: '⏭️',\n  };\n\n  const lines = checks.map((check) => {\n    const emoji = statusEmoji[check.status];\n    const duration = check.duration ? ` (${check.duration})` : '';\n    const logLink = check.status === 'fail' && logPath ? ` → ${logPath}` : '';\n    return `${emoji} ${check.name}${duration}${logLink}`;\n  });\n\n  return lines.join('\\n');\n}\n\n/**\n * Formats a concise error summary with log file link.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @param summary - Brief summary of issues (e.g., '3 errors, 2 warnings')\n * @param logPath - Path to the full log file\n * @returns Formatted summary string\n *\n * @example\n * ```typescript\n * const summary = formatErrorSummary('ESLint', '3 errors, 2 warnings', logPath);\n * // Returns: '❌ ESLint: 3 errors, 2 warnings\\n→ .claude/logs/eslint-file.log'\n * ```\n */\nexport function formatErrorSummary(tool: string, summary: string, logPath: string): string {\n  return `❌ ${tool}: ${summary}\\n→ ${logPath}`;\n}\n\n/**\n * Formats a success message.\n *\n * @param tool - Tool name (e.g., 'ESLint', 'TypeScript', 'Vitest')\n * @returns Formatted success string\n *\n * @example\n * ```typescript\n * const msg = formatSuccessMessage('ESLint');\n * // Returns: '✅ ESLint: No issues'\n * ```\n */\nexport function formatSuccessMessage(tool: string): string {\n  return `✅ ${tool}: No issues`;\n}\n",
        "plugins/project-context/shared/hooks/utils/metadata-index.ts": "/**\n * Metadata Index Manager\n *\n * Manages the incremental metadata index stored in `.claude/logs/metadata-index.json`.\n * Provides functions to load, save, and update file and folder metadata for\n * context-aware prompt enrichment.\n *\n * @module metadata-index\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport type { ExportInfo } from './tsdoc-parser.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst INDEX_FILE = 'metadata-index.json';\nconst INDEX_VERSION = '1.0.0';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Metadata for an indexed file\n *\n * Contains all context information extracted from a TypeScript file\n * including TSDoc tags, exports, and timing information.\n */\nexport interface FileMetadata {\n  /**\n   * Relative path to the file from project root\n   */\n  path: string;\n  /**\n   * ISO timestamp of last file modification\n   */\n  lastModified: string;\n  /**\n   * ISO timestamp when the file was indexed\n   */\n  lastIndexed: string;\n  /**\n   * Context tags extracted from TSDoc @context and implicit naming\n   */\n  tags: string[];\n  /**\n   * Aliases extracted from TSDoc @aliases\n   */\n  aliases: string[];\n  /**\n   * All exports found in the file\n   */\n  exports: ExportInfo[];\n  /**\n   * File-level description from leading comment\n   */\n  description?: string;\n}\n\n/**\n * Metadata for an indexed folder\n *\n * Contains context information from CLAUDE.md files and\n * folder-level metadata.\n */\nexport interface FolderMetadata {\n  /**\n   * Relative path to the folder from project root\n   */\n  path: string;\n  /**\n   * Path to the CLAUDE.md file if present\n   */\n  claudeMdPath?: string;\n  /**\n   * Title extracted from CLAUDE.md H1 heading\n   */\n  title?: string;\n  /**\n   * Context tags from CLAUDE.md frontmatter or content\n   */\n  tags: string[];\n  /**\n   * ISO timestamp when the folder was indexed\n   */\n  lastIndexed: string;\n}\n\n/**\n * Cached Supabase schema information\n *\n * Stores table names and columns for database-aware context matching.\n */\nexport interface SupabaseSchemaCache {\n  /**\n   * ISO timestamp when schema was fetched\n   */\n  lastFetched: string;\n  /**\n   * Project ID this schema belongs to\n   */\n  projectId?: string;\n  /**\n   * Table metadata\n   */\n  tables: Array<{\n    /**\n     * Table name\n     */\n    name: string;\n    /**\n     * Schema name (usually 'public')\n     */\n    schema: string;\n    /**\n     * Column names\n     */\n    columns: string[];\n    /**\n     * Primary key column names\n     */\n    primaryKeys: string[];\n  }>;\n}\n\n/**\n * Complete metadata index\n *\n * The root structure for the metadata-index.json file.\n */\nexport interface MetadataIndex {\n  /**\n   * Schema version for forward compatibility\n   */\n  version: string;\n  /**\n   * ISO timestamp of last index update\n   */\n  lastUpdated: string;\n  /**\n   * Map of file paths to their metadata\n   */\n  files: { [filePath: string]: FileMetadata };\n  /**\n   * Map of folder paths to their metadata\n   */\n  folders: { [folderPath: string]: FolderMetadata };\n  /**\n   * Optional Supabase schema cache\n   */\n  supabase?: SupabaseSchemaCache;\n}\n\n// ============================================================================\n// Path Helpers\n// ============================================================================\n\n/**\n * Get the path to the metadata index file\n *\n * @param cwd - The working directory (project root)\n * @returns Full path to metadata-index.json\n */\nfunction getIndexPath(cwd: string): string {\n  return path.join(cwd, LOGS_DIR, INDEX_FILE);\n}\n\n// ============================================================================\n// Index Management\n// ============================================================================\n\n/**\n * Load the metadata index from disk\n *\n * Reads and parses the metadata-index.json file. If the file doesn't exist\n * or is invalid, returns a fresh empty index.\n *\n * @param cwd - The working directory (project root)\n * @returns The loaded metadata index, or empty index if not found\n *\n * @example\n * ```typescript\n * import { loadIndex } from './metadata-index.js';\n *\n * const index = await loadIndex('/path/to/project');\n * console.log(`Indexed ${Object.keys(index.files).length} files`);\n * console.log(`Indexed ${Object.keys(index.folders).length} folders`);\n * ```\n */\nexport async function loadIndex(cwd: string): Promise<MetadataIndex> {\n  const indexPath = getIndexPath(cwd);\n\n  try {\n    const content = await fs.readFile(indexPath, 'utf-8');\n    const index: MetadataIndex = JSON.parse(content);\n\n    // Validate version\n    if (index.version !== INDEX_VERSION) {\n      // Version mismatch - return fresh index\n      // Future: could implement migrations here\n      return createEmptyIndex();\n    }\n\n    return index;\n  } catch {\n    // File doesn't exist or is invalid\n    return createEmptyIndex();\n  }\n}\n\n/**\n * Create an empty metadata index\n *\n * @returns Fresh metadata index with empty collections\n */\nfunction createEmptyIndex(): MetadataIndex {\n  return {\n    version: INDEX_VERSION,\n    lastUpdated: new Date().toISOString(),\n    files: {},\n    folders: {},\n  };\n}\n\n/**\n * Save the metadata index to disk\n *\n * Writes the index to .claude/logs/metadata-index.json, creating\n * the directory structure if needed.\n *\n * @param cwd - The working directory (project root)\n * @param index - The index to save\n *\n * @example\n * ```typescript\n * import { loadIndex, saveIndex } from './metadata-index.js';\n *\n * const index = await loadIndex(cwd);\n * index.files['src/auth/login.ts'] = fileMetadata;\n * await saveIndex(cwd, index);\n * ```\n */\nexport async function saveIndex(cwd: string, index: MetadataIndex): Promise<void> {\n  const indexPath = getIndexPath(cwd);\n  const indexDir = path.dirname(indexPath);\n\n  // Update timestamp\n  index.lastUpdated = new Date().toISOString();\n\n  // Ensure directory exists\n  await fs.mkdir(indexDir, { recursive: true });\n\n  // Write with pretty formatting for debugging\n  await fs.writeFile(indexPath, JSON.stringify(index, null, 2), 'utf-8');\n}\n\n/**\n * Update metadata for a single file\n *\n * Loads the index, updates the file entry, and saves back to disk.\n * This is a convenience function for incremental updates.\n *\n * @param cwd - The working directory (project root)\n * @param filePath - Relative path to the file\n * @param metadata - Updated file metadata\n *\n * @example\n * ```typescript\n * import { updateFileMetadata } from './metadata-index.js';\n * import { parseFileMetadata } from './tsdoc-parser.js';\n *\n * const content = await fs.readFile('src/auth/login.ts', 'utf-8');\n * const metadata = parseFileMetadata('src/auth/login.ts', content);\n * await updateFileMetadata(cwd, 'src/auth/login.ts', metadata);\n * ```\n */\nexport async function updateFileMetadata(\n  cwd: string,\n  filePath: string,\n  metadata: FileMetadata\n): Promise<void> {\n  const index = await loadIndex(cwd);\n  index.files[filePath] = metadata;\n  await saveIndex(cwd, index);\n}\n\n/**\n * Update metadata for a single folder\n *\n * Loads the index, updates the folder entry, and saves back to disk.\n * This is a convenience function for incremental updates.\n *\n * @param cwd - The working directory (project root)\n * @param folderPath - Relative path to the folder\n * @param metadata - Updated folder metadata\n *\n * @example\n * ```typescript\n * import { updateFolderMetadata } from './metadata-index.js';\n *\n * await updateFolderMetadata(cwd, 'src/auth', {\n *   path: 'src/auth',\n *   claudeMdPath: 'src/auth/CLAUDE.md',\n *   title: 'Authentication Module',\n *   tags: ['authentication', 'security', 'oauth'],\n *   lastIndexed: new Date().toISOString()\n * });\n * ```\n */\nexport async function updateFolderMetadata(\n  cwd: string,\n  folderPath: string,\n  metadata: FolderMetadata\n): Promise<void> {\n  const index = await loadIndex(cwd);\n  index.folders[folderPath] = metadata;\n  await saveIndex(cwd, index);\n}\n\n/**\n * Remove a file from the index\n *\n * Used when a file is deleted or renamed.\n *\n * @param cwd - The working directory (project root)\n * @param filePath - Relative path to the file to remove\n *\n * @example\n * ```typescript\n * import { removeFileMetadata } from './metadata-index.js';\n *\n * // After detecting file deletion\n * await removeFileMetadata(cwd, 'src/old-file.ts');\n * ```\n */\nexport async function removeFileMetadata(cwd: string, filePath: string): Promise<void> {\n  const index = await loadIndex(cwd);\n  delete index.files[filePath];\n  await saveIndex(cwd, index);\n}\n\n/**\n * Remove a folder from the index\n *\n * Used when a folder is deleted or renamed.\n *\n * @param cwd - The working directory (project root)\n * @param folderPath - Relative path to the folder to remove\n *\n * @example\n * ```typescript\n * import { removeFolderMetadata } from './metadata-index.js';\n *\n * // After detecting folder deletion\n * await removeFolderMetadata(cwd, 'src/deprecated');\n * ```\n */\nexport async function removeFolderMetadata(cwd: string, folderPath: string): Promise<void> {\n  const index = await loadIndex(cwd);\n  delete index.folders[folderPath];\n  await saveIndex(cwd, index);\n}\n\n/**\n * Update Supabase schema cache\n *\n * Stores table metadata for database-aware context matching.\n *\n * @param cwd - The working directory (project root)\n * @param schema - Supabase schema information\n *\n * @example\n * ```typescript\n * import { updateSupabaseSchema } from './metadata-index.js';\n *\n * await updateSupabaseSchema(cwd, {\n *   lastFetched: new Date().toISOString(),\n *   projectId: 'abc123',\n *   tables: [\n *     { name: 'users', schema: 'public', columns: ['id', 'email'], primaryKeys: ['id'] }\n *   ]\n * });\n * ```\n */\nexport async function updateSupabaseSchema(\n  cwd: string,\n  schema: SupabaseSchemaCache\n): Promise<void> {\n  const index = await loadIndex(cwd);\n  index.supabase = schema;\n  await saveIndex(cwd, index);\n}\n\n/**\n * Check if a file needs re-indexing\n *\n * Compares the file's modification time with the indexed timestamp.\n *\n * @param cwd - The working directory (project root)\n * @param filePath - Relative path to the file\n * @param lastModified - ISO timestamp of file's current mtime\n * @returns True if the file should be re-indexed\n *\n * @example\n * ```typescript\n * import { needsReindex } from './metadata-index.js';\n * import * as fs from 'fs/promises';\n *\n * const stat = await fs.stat('src/auth/login.ts');\n * const needsUpdate = await needsReindex(cwd, 'src/auth/login.ts', stat.mtime.toISOString());\n *\n * if (needsUpdate) {\n *   // Re-parse and update the file metadata\n * }\n * ```\n */\nexport async function needsReindex(\n  cwd: string,\n  filePath: string,\n  lastModified: string\n): Promise<boolean> {\n  const index = await loadIndex(cwd);\n  const existing = index.files[filePath];\n\n  if (!existing) {\n    return true; // Not indexed yet\n  }\n\n  // Compare modification times\n  return new Date(lastModified) > new Date(existing.lastModified);\n}\n\n/**\n * Get all indexed file paths\n *\n * Returns an array of all file paths currently in the index.\n *\n * @param cwd - The working directory (project root)\n * @returns Array of indexed file paths\n *\n * @example\n * ```typescript\n * import { getIndexedFiles } from './metadata-index.js';\n *\n * const files = await getIndexedFiles(cwd);\n * console.log(`${files.length} files indexed`);\n * ```\n */\nexport async function getIndexedFiles(cwd: string): Promise<string[]> {\n  const index = await loadIndex(cwd);\n  return Object.keys(index.files);\n}\n\n/**\n * Get all indexed folder paths\n *\n * Returns an array of all folder paths currently in the index.\n *\n * @param cwd - The working directory (project root)\n * @returns Array of indexed folder paths\n *\n * @example\n * ```typescript\n * import { getIndexedFolders } from './metadata-index.js';\n *\n * const folders = await getIndexedFolders(cwd);\n * console.log(`${folders.length} folders indexed`);\n * ```\n */\nexport async function getIndexedFolders(cwd: string): Promise<string[]> {\n  const index = await loadIndex(cwd);\n  return Object.keys(index.folders);\n}\n",
        "plugins/project-context/shared/hooks/utils/package-manager.ts": "/**\n * Package manager detection and command utilities\n *\n * Detects which package manager (npm, yarn, pnpm, or bun) a project uses\n * by checking for the presence of lockfiles, and provides utilities for\n * constructing package manager commands.\n *\n * @module package-manager\n */\n\nimport { existsSync } from 'fs';\nimport { join } from 'path';\n\n/**\n * Detect which package manager is used in a project\n *\n * Checks for the presence of lockfiles in the following priority order:\n * 1. bun.lockb (Bun)\n * 2. pnpm-lock.yaml (pnpm)\n * 3. yarn.lock (Yarn)\n * 4. package-lock.json (npm)\n * 5. Falls back to bun if no lockfile is found (modern default)\n *\n * @param cwd - The directory to check for lockfiles\n * @returns The detected package manager: 'bun', 'pnpm', 'yarn', or 'npm'\n *\n * @example\n * ```typescript\n * import { detectPackageManager } from './package-manager.js';\n *\n * const pm = detectPackageManager('/path/to/project');\n * console.log(pm); // 'npm' | 'yarn' | 'pnpm' | 'bun'\n * ```\n */\nexport function detectPackageManager(cwd: string): 'npm' | 'yarn' | 'pnpm' | 'bun' {\n  if (existsSync(join(cwd, 'bun.lockb'))) return 'bun';\n  if (existsSync(join(cwd, 'pnpm-lock.yaml'))) return 'pnpm';\n  if (existsSync(join(cwd, 'yarn.lock'))) return 'yarn';\n  if (existsSync(join(cwd, 'package-lock.json'))) return 'npm';\n  return 'bun'; // Modern default when no lockfile found\n}\n\n/**\n * Get the command to run a package.json script\n *\n * Constructs the appropriate command for running a package.json script\n * based on the detected package manager. All package managers use the\n * format: `{pm} run {script}`.\n *\n * @param cwd - The project directory to detect the package manager from\n * @param script - The script name from package.json to run (e.g., 'test', 'build')\n * @returns The full command string to execute the script\n *\n * @example\n * ```typescript\n * import { getScriptCommand } from './package-manager.js';\n *\n * const command = getScriptCommand('/path/to/project', 'test');\n * // Returns: 'npm run test' or 'yarn run test' or 'pnpm run test' or 'bun run test'\n * ```\n */\nexport function getScriptCommand(cwd: string, script: string): string {\n  const pm = detectPackageManager(cwd);\n  return `${pm} run ${script}`;\n}\n",
        "plugins/project-context/shared/hooks/utils/plan-parser.ts": "/**\n * Plan file parser for task definitions\n *\n * Parses YAML frontmatter from plan files to extract task definitions,\n * including agent assignments, file path patterns, and dependencies.\n *\n * Note: This module includes its own YAML parsing for nested task arrays\n * because the simple frontmatter.ts parser doesn't support multi-line\n * nested YAML structures.\n *\n * @module plan-parser\n */\n\n// ============================================================================\n// Type Definitions\n// ============================================================================\n\n/**\n * A task definition within a plan file\n *\n * Defines the scope of work for a specific agent, including:\n * - Which files the agent is responsible for (via glob patterns)\n * - What requirements the agent must fulfill\n * - Dependencies on other tasks\n */\nexport interface TaskDefinition {\n  /** Unique identifier for the task within the plan */\n  id: string;\n  /** Agent type assigned to this task (e.g., 'ui-developer', 'api-specialist') */\n  agent: string;\n  /** Glob patterns for files in this task's scope (e.g., 'src/api/**', 'src/components/*.tsx') */\n  paths: string[];\n  /** List of requirements for this task */\n  requirements: string[];\n  /** Optional list of task IDs this task depends on */\n  dependencies?: string[];\n}\n\n/**\n * Parsed metadata from a plan file's frontmatter\n */\nexport interface PlanMetadata {\n  /** Array of task definitions from the plan */\n  tasks: TaskDefinition[];\n}\n\n/**\n * Result of task validation\n */\nexport interface ValidationResult {\n  /** Whether all tasks are valid */\n  valid: boolean;\n  /** Array of validation error messages */\n  errors: string[];\n}\n\n// ============================================================================\n// Glob Matching Implementation\n// ============================================================================\n\n/**\n * Simple glob pattern matching\n *\n * Supports:\n * - `**` for recursive directory matching\n * - `*` for single path segment matching\n * - Literal path matching\n *\n * @param pattern - Glob pattern to match against\n * @param path - File path to test\n * @returns True if the path matches the pattern\n *\n * @example\n * ```typescript\n * isPathMatch('src/api/**', 'src/api/routes/users.ts'); // true\n * isPathMatch('src/components/*.tsx', 'src/components/Button.tsx'); // true\n * isPathMatch('src/components/*.tsx', 'src/components/forms/Input.tsx'); // false\n * ```\n */\nfunction isPathMatch(pattern: string, path: string): boolean {\n  // Normalize both pattern and path (remove leading/trailing slashes)\n  const normalizedPattern = pattern.replace(/^\\/+|\\/+$/g, '');\n  const normalizedPath = path.replace(/^\\/+|\\/+$/g, '');\n\n  // Convert glob pattern to regex\n  const regexPattern = normalizedPattern\n    // Escape special regex characters except * and **\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    // Handle ** (recursive match)\n    .replace(/\\*\\*/g, '<<<DOUBLE_STAR>>>')\n    // Handle * (single segment match - no slashes)\n    .replace(/\\*/g, '[^/]*')\n    // Restore ** as match anything\n    .replace(/<<<DOUBLE_STAR>>>/g, '.*');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(normalizedPath);\n}\n\n// ============================================================================\n// YAML Parsing Helpers\n// ============================================================================\n\n/**\n * Extract frontmatter content from markdown\n */\nfunction extractFrontmatter(content: string): string | null {\n  const match = content.match(/^---\\s*\\n([\\s\\S]*?)\\n---/);\n  return match ? match[1] : null;\n}\n\n/**\n * Parse an inline array like [item1, item2, item3]\n */\nfunction parseInlineArray(value: string): string[] {\n  if (!value.startsWith('[') || !value.endsWith(']')) {\n    return [];\n  }\n  const inner = value.slice(1, -1).trim();\n  if (!inner) return [];\n\n  return inner.split(',').map((item) => item.trim());\n}\n\n/**\n * Parse a simple YAML value (string, boolean, number)\n */\nfunction parseYamlValue(value: string): string {\n  // Remove surrounding quotes\n  if ((value.startsWith('\"') && value.endsWith('\"')) ||\n      (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n    return value.slice(1, -1);\n  }\n  return value;\n}\n\n/**\n * Parse tasks from YAML frontmatter with proper indentation handling\n *\n * Supports the format:\n * ```yaml\n * tasks:\n *   - id: task-name\n *     agent: agent-type\n *     paths: [pattern1, pattern2]\n *     requirements: [req1, req2]\n *     dependencies: [dep1, dep2]\n * ```\n */\nfunction parseTasksFromYaml(yaml: string): TaskDefinition[] {\n  const lines = yaml.split('\\n');\n  const tasks: TaskDefinition[] = [];\n  let currentTask: Partial<TaskDefinition> | null = null;\n\n  // Find the tasks: section\n  let inTasks = false;\n  let taskIndent = 0;\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n\n    // Skip empty lines and comments\n    if (!trimmed || trimmed.startsWith('#')) {\n      continue;\n    }\n\n    // Check for tasks: key\n    if (trimmed === 'tasks:') {\n      inTasks = true;\n      continue;\n    }\n\n    if (!inTasks) {\n      continue;\n    }\n\n    // Check if we've exited the tasks section (less indent than expected)\n    const lineIndent = line.search(/\\S/);\n    if (lineIndent >= 0 && !line.startsWith(' ') && !line.startsWith('\\t') && !trimmed.startsWith('-')) {\n      // We've hit a new top-level key\n      inTasks = false;\n      continue;\n    }\n\n    // New task item starts with -\n    if (trimmed.startsWith('- ')) {\n      // Save previous task\n      if (currentTask && currentTask.id && currentTask.agent) {\n        tasks.push({\n          id: currentTask.id,\n          agent: currentTask.agent,\n          paths: currentTask.paths || [],\n          requirements: currentTask.requirements || [],\n          dependencies: currentTask.dependencies,\n        });\n      }\n\n      // Start new task\n      currentTask = {};\n      taskIndent = lineIndent;\n\n      // Parse the first property on the same line as -\n      const afterDash = trimmed.slice(2).trim();\n      if (afterDash) {\n        const colonIdx = afterDash.indexOf(':');\n        if (colonIdx > 0) {\n          const key = afterDash.slice(0, colonIdx).trim();\n          const value = afterDash.slice(colonIdx + 1).trim();\n          setTaskProperty(currentTask, key, value);\n        }\n      }\n      continue;\n    }\n\n    // Task property line\n    if (currentTask && lineIndent > taskIndent) {\n      const colonIdx = trimmed.indexOf(':');\n      if (colonIdx > 0) {\n        const key = trimmed.slice(0, colonIdx).trim();\n        const value = trimmed.slice(colonIdx + 1).trim();\n        setTaskProperty(currentTask, key, value);\n      }\n    }\n  }\n\n  // Save last task\n  if (currentTask && currentTask.id && currentTask.agent) {\n    tasks.push({\n      id: currentTask.id,\n      agent: currentTask.agent,\n      paths: currentTask.paths || [],\n      requirements: currentTask.requirements || [],\n      dependencies: currentTask.dependencies,\n    });\n  }\n\n  return tasks;\n}\n\n/**\n * Set a property on a partial task object\n */\nfunction setTaskProperty(task: Partial<TaskDefinition>, key: string, value: string): void {\n  switch (key) {\n    case 'id':\n      task.id = parseYamlValue(value);\n      break;\n    case 'agent':\n      task.agent = parseYamlValue(value);\n      break;\n    case 'paths':\n      task.paths = parseInlineArray(value);\n      break;\n    case 'requirements':\n      task.requirements = parseInlineArray(value);\n      break;\n    case 'dependencies':\n      task.dependencies = parseInlineArray(value);\n      break;\n  }\n}\n\n// ============================================================================\n// Plan Parsing Functions\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from plan file content to extract task definitions\n *\n * Expects plan files with frontmatter in this format:\n *\n * ```yaml\n * ---\n * tasks:\n *   - id: api-development\n *     agent: api-specialist\n *     paths: [src/api/**, src/lib/api/**]\n *     requirements: [Implement REST endpoints, Add validation]\n *     dependencies: [database-setup]\n * ---\n * ```\n *\n * @param content - Full content of the plan file\n * @returns Parsed plan metadata with tasks, or null if no valid frontmatter\n *\n * @example\n * ```typescript\n * const planContent = fs.readFileSync('.claude/plans/feature.md', 'utf-8');\n * const metadata = parsePlanFrontmatter(planContent);\n * if (metadata) {\n *   console.log('Tasks:', metadata.tasks.length);\n * }\n * ```\n */\nexport function parsePlanFrontmatter(content: string): PlanMetadata | null {\n  const yaml = extractFrontmatter(content);\n\n  if (!yaml) {\n    return null;\n  }\n\n  const tasks = parseTasksFromYaml(yaml);\n\n  if (tasks.length === 0) {\n    return null;\n  }\n\n  return { tasks };\n}\n\n/**\n * Validate task definitions for correctness\n *\n * Checks:\n * - All tasks have unique IDs\n * - All tasks have at least one path pattern\n * - All dependencies reference existing task IDs\n * - No circular dependencies\n *\n * @param tasks - Array of task definitions to validate\n * @returns Validation result with success status and any error messages\n *\n * @example\n * ```typescript\n * const result = validateTaskDefinitions(metadata.tasks);\n * if (!result.valid) {\n *   console.error('Validation errors:', result.errors);\n * }\n * ```\n */\nexport function validateTaskDefinitions(tasks: TaskDefinition[]): ValidationResult {\n  const errors: string[] = [];\n  const taskIds = new Set<string>();\n\n  // First pass: collect IDs and check for duplicates\n  for (const task of tasks) {\n    if (taskIds.has(task.id)) {\n      errors.push(`Duplicate task ID: '${task.id}'`);\n    }\n    taskIds.add(task.id);\n\n    if (task.paths.length === 0) {\n      errors.push(`Task '${task.id}' has no paths defined`);\n    }\n  }\n\n  // Second pass: validate dependencies\n  for (const task of tasks) {\n    if (task.dependencies) {\n      for (const dep of task.dependencies) {\n        if (!taskIds.has(dep)) {\n          errors.push(`Task '${task.id}' depends on unknown task: '${dep}'`);\n        }\n        if (dep === task.id) {\n          errors.push(`Task '${task.id}' cannot depend on itself`);\n        }\n      }\n    }\n  }\n\n  // Check for circular dependencies\n  const circularErrors = detectCircularDependencies(tasks);\n  errors.push(...circularErrors);\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Detect circular dependencies in task definitions\n *\n * Uses depth-first search to find cycles in the dependency graph.\n */\nfunction detectCircularDependencies(tasks: TaskDefinition[]): string[] {\n  const errors: string[] = [];\n  const taskMap = new Map(tasks.map((t) => [t.id, t]));\n  const visited = new Set<string>();\n  const inStack = new Set<string>();\n\n  function dfs(taskId: string, path: string[]): boolean {\n    if (inStack.has(taskId)) {\n      const cycleStart = path.indexOf(taskId);\n      const cycle = [...path.slice(cycleStart), taskId].join(' -> ');\n      errors.push(`Circular dependency detected: ${cycle}`);\n      return true;\n    }\n\n    if (visited.has(taskId)) {\n      return false;\n    }\n\n    visited.add(taskId);\n    inStack.add(taskId);\n\n    const task = taskMap.get(taskId);\n    if (task?.dependencies) {\n      for (const dep of task.dependencies) {\n        if (dfs(dep, [...path, taskId])) {\n          return true;\n        }\n      }\n    }\n\n    inStack.delete(taskId);\n    return false;\n  }\n\n  for (const task of tasks) {\n    if (!visited.has(task.id)) {\n      dfs(task.id, []);\n    }\n  }\n\n  return errors;\n}\n\n/**\n * Find the task definition that owns a given file path\n *\n * Searches through all tasks and returns the first task whose path patterns\n * match the given file path. Returns null if no task matches.\n *\n * @param tasks - Array of task definitions to search\n * @param filePath - File path to find the owning task for\n * @returns The matching task definition, or null if no match\n *\n * @example\n * ```typescript\n * const task = findTaskByPath(metadata.tasks, 'src/api/routes/users.ts');\n * if (task) {\n *   console.log(`File belongs to task '${task.id}' (agent: ${task.agent})`);\n * }\n * ```\n */\nexport function findTaskByPath(tasks: TaskDefinition[], filePath: string): TaskDefinition | null {\n  for (const task of tasks) {\n    if (isPathInScope(task.paths, filePath)) {\n      return task;\n    }\n  }\n  return null;\n}\n\n/**\n * Check if a file path matches any of the given path patterns\n *\n * @param taskPaths - Array of glob patterns to match against\n * @param filePath - File path to test\n * @returns True if the file path matches any pattern\n *\n * @example\n * ```typescript\n * const paths = ['src/api/**', 'src/lib/api/**'];\n * isPathInScope(paths, 'src/api/routes/users.ts'); // true\n * isPathInScope(paths, 'src/components/Button.tsx'); // false\n * ```\n */\nexport function isPathInScope(taskPaths: string[], filePath: string): boolean {\n  return taskPaths.some((pattern) => isPathMatch(pattern, filePath));\n}\n\n/**\n * Find all tasks whose paths match a given file\n *\n * Unlike findTaskByPath which returns the first match, this returns all\n * matching tasks. Useful for detecting overlapping task scopes.\n *\n * @param tasks - Array of task definitions to search\n * @param filePath - File path to find matching tasks for\n * @returns Array of all matching task definitions\n */\nexport function findAllTasksByPath(tasks: TaskDefinition[], filePath: string): TaskDefinition[] {\n  return tasks.filter((task) => isPathInScope(task.paths, filePath));\n}\n",
        "plugins/project-context/shared/hooks/utils/rules-matcher.ts": "/**\n * Rules matcher utility for Claude Code hooks\n *\n * Discovers rules files in .claude/rules/ and matches them against edited files\n * based on glob patterns in frontmatter. Used by SubagentStop hooks to include\n * relevant rules as validation context.\n *\n * @module rules-matcher\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport { minimatch } from 'minimatch';\nimport matter from './frontmatter.js';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Represents a parsed rule file with its path patterns\n */\nexport interface RuleFile {\n  /** Absolute path to the rule file */\n  filePath: string;\n  /** Relative path from rules directory */\n  relativePath: string;\n  /** Glob patterns from frontmatter that define which files this rule applies to */\n  paths?: string[];\n  /** Full content of the rule file */\n  content: string;\n  /** Rule file name without extension */\n  name: string;\n}\n\n// ============================================================================\n// Discovery\n// ============================================================================\n\n/**\n * Discover all rules files in .claude/rules/ and parse their paths frontmatter\n *\n * Recursively scans the rules directory for markdown files and parses their\n * YAML frontmatter to extract path patterns.\n *\n * @param cwd - Project working directory\n * @returns Array of parsed rule files\n *\n * @example\n * ```typescript\n * const rules = await discoverRules('/path/to/project');\n * for (const rule of rules) {\n *   console.log(rule.name, rule.paths);\n * }\n * ```\n */\nexport async function discoverRules(cwd: string): Promise<RuleFile[]> {\n  const rulesDir = path.join(cwd, '.claude', 'rules');\n\n  // Check if rules directory exists\n  try {\n    await fs.access(rulesDir);\n  } catch {\n    return [];\n  }\n\n  const rules: RuleFile[] = [];\n\n  // Recursively find all .md files\n  async function scanDirectory(dir: string): Promise<void> {\n    const entries = await fs.readdir(dir, { withFileTypes: true });\n\n    for (const entry of entries) {\n      const fullPath = path.join(dir, entry.name);\n\n      if (entry.isDirectory()) {\n        await scanDirectory(fullPath);\n      } else if (entry.isFile() && entry.name.endsWith('.md')) {\n        try {\n          const content = await fs.readFile(fullPath, 'utf-8');\n          const { data } = matter(content);\n          const relativePath = path.relative(rulesDir, fullPath);\n\n          rules.push({\n            filePath: fullPath,\n            relativePath,\n            paths: data.paths as string[] | undefined,\n            content,\n            name: path.basename(fullPath, '.md'),\n          });\n        } catch {\n          // Skip files that can't be read or parsed\n        }\n      }\n    }\n  }\n\n  await scanDirectory(rulesDir);\n  return rules;\n}\n\n// ============================================================================\n// Matching\n// ============================================================================\n\n/**\n * Find rules that match any of the given file paths\n *\n * Uses minimatch to check if edited files match the glob patterns defined\n * in rule frontmatter. Only returns rules that have `paths` defined and\n * match at least one edited file.\n *\n * @param rules - Array of rule files from discoverRules()\n * @param editedFiles - Array of absolute file paths that were edited\n * @param cwd - Project working directory (for relative path calculation)\n * @returns Deduplicated array of matching rules\n *\n * @example\n * ```typescript\n * const rules = await discoverRules(cwd);\n * const editedFiles = ['/project/src/hooks/my-hook.ts'];\n * const matchingRules = matchRulesToFiles(rules, editedFiles, cwd);\n * ```\n */\nexport function matchRulesToFiles(\n  rules: RuleFile[],\n  editedFiles: string[],\n  cwd: string\n): RuleFile[] {\n  const matchingRules: RuleFile[] = [];\n  const seenPaths = new Set<string>();\n\n  for (const rule of rules) {\n    // Rules without paths field don't apply to specific files\n    if (!rule.paths || rule.paths.length === 0) {\n      continue;\n    }\n\n    // Check if any edited file matches any rule path pattern\n    let matched = false;\n    for (const editedFile of editedFiles) {\n      const relativePath = path.relative(cwd, editedFile);\n\n      for (const pattern of rule.paths) {\n        if (minimatch(relativePath, pattern, { matchBase: true })) {\n          matched = true;\n          break;\n        }\n      }\n\n      if (matched) break;\n    }\n\n    if (matched && !seenPaths.has(rule.filePath)) {\n      matchingRules.push(rule);\n      seenPaths.add(rule.filePath);\n    }\n  }\n\n  return matchingRules;\n}\n\n/**\n * Format matching rules as context string for review hooks\n *\n * Creates a formatted string with rule names and truncated content\n * suitable for inclusion in systemMessage.\n *\n * @param matchingRules - Array of matching rules\n * @param maxContentLength - Maximum characters per rule content (default: 1000)\n * @returns Formatted rules context string\n */\nexport function formatRulesContext(\n  matchingRules: RuleFile[],\n  maxContentLength = 1000\n): string {\n  if (matchingRules.length === 0) {\n    return '';\n  }\n\n  const lines: string[] = ['## Applicable Rules', ''];\n\n  for (const rule of matchingRules) {\n    lines.push(`### ${rule.name}`);\n\n    // Truncate content if too long\n    if (rule.content.length > maxContentLength) {\n      lines.push(rule.content.slice(0, maxContentLength) + '...');\n    } else {\n      lines.push(rule.content);\n    }\n\n    lines.push('');\n  }\n\n  return lines.join('\\n');\n}\n",
        "plugins/project-context/shared/hooks/utils/session-state.ts": "/**\n * Session state management for Stop hook tracking\n *\n * Manages session-level state for the Stop hook to track:\n * - How many times the hook has blocked the session\n * - Whether a GitHub comment has been posted for the session\n * - When the last block occurred\n *\n * This enables progressive blocking behavior where the Stop hook can:\n * 1. Block on first commit without PR (with instructions)\n * 2. Block again if no PR or comment posted\n * 3. Show warning after 3 blocks\n * 4. Reset when PR created or comment posted\n * @module session-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SESSION_STOPS_FILE = 'session-stops.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Session Stop state tracking for progressive blocking\n *\n * Tracks how many times a session has been blocked at Stop hook,\n * whether progress has been documented, and related metadata.\n */\nexport interface SessionStopState {\n  /**\n   * The unique session identifier\n   */\n  sessionId: string;\n  /**\n   * Number of times Stop hook has blocked (0-3)\n   */\n  blockCount: number;\n  /**\n   * Whether a GitHub comment has been posted\n   */\n  commentPosted: boolean;\n  /**\n   * ISO timestamp of last block\n   */\n  lastBlockTimestamp: string;\n  /**\n   * GitHub issue number linked to this session\n   */\n  issueNumber?: number;\n  /**\n   * Whether a PR has been created\n   */\n  prCreated?: boolean;\n}\n\n/**\n * Map of session IDs to their Stop hook state\n */\ninterface SessionStopsMap {\n  [sessionId: string]: SessionStopState;\n}\n\n// ============================================================================\n// File Path Management\n// ============================================================================\n\n/**\n * Get the path to session-stops.json\n * @param cwd - The working directory\n * @param customPath - Optional custom path (for testing)\n * @returns Full path to the session stops state file\n * @example\n * ```typescript\n * const path = getSessionStopsFilePath('/path/to/project');\n * // Returns: '/path/to/project/.claude/logs/session-stops.json'\n * ```\n */\nfunction getSessionStopsFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SESSION_STOPS_FILE);\n}\n\n// ============================================================================\n// State Management\n// ============================================================================\n\n/**\n * Get session stop state for a given session\n *\n * Loads the session's Stop hook state from disk. If no state exists,\n * returns a default state with blockCount: 0.\n * @param sessionId - The session ID to load state for\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The session state, or default state if not found\n * @example\n * ```typescript\n * import { getSessionStopState } from './session-state.js';\n *\n * // In Stop hook\n * const state = await getSessionStopState(input.session_id, input.cwd);\n * console.log('Block count:', state.blockCount);\n * console.log('Comment posted:', state.commentPosted);\n * ```\n */\nexport async function getSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n\n    if (allStates[sessionId]) {\n      return allStates[sessionId];\n    }\n  } catch {\n    // File doesn't exist or parse error - return default\n  }\n\n  // Return default state\n  return {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Update session stop state with partial updates\n *\n * Merges the provided updates into the existing state and saves to disk.\n * Automatically creates the logs directory if it doesn't exist.\n * @param sessionId - The session ID to update\n * @param updates - Partial state updates to apply\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns The updated session state\n * @example\n * ```typescript\n * import { updateSessionStopState } from './session-state.js';\n *\n * // Increment block count\n * await updateSessionStopState(input.session_id, {\n *   blockCount: state.blockCount + 1,\n *   lastBlockTimestamp: new Date().toISOString()\n * }, input.cwd);\n *\n * // Mark comment posted\n * await updateSessionStopState(input.session_id, {\n *   commentPosted: true\n * }, input.cwd);\n * ```\n */\nexport async function updateSessionStopState(\n  sessionId: string,\n  updates: Partial<Omit<SessionStopState, 'sessionId'>>,\n  cwd: string,\n  statePath?: string\n): Promise<SessionStopState> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  // Load existing states\n  let allStates: SessionStopsMap = {};\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    allStates = JSON.parse(content);\n  } catch {\n    // File doesn't exist yet - start fresh\n  }\n\n  // Get current state or create default\n  const currentState = allStates[sessionId] || {\n    sessionId,\n    blockCount: 0,\n    commentPosted: false,\n    lastBlockTimestamp: new Date().toISOString(),\n  };\n\n  // Merge updates\n  const updatedState: SessionStopState = {\n    ...currentState,\n    ...updates,\n    sessionId, // Ensure sessionId is never overwritten\n  };\n\n  allStates[sessionId] = updatedState;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(filePath), { recursive: true });\n  await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n\n  return updatedState;\n}\n\n/**\n * Reset session stop state to defaults\n *\n * Clears the block count and resets all flags. This is called when:\n * - A PR is created for the session's branch\n * - A GitHub comment is posted documenting progress\n * @param sessionId - The session ID to reset\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is reset\n * @example\n * ```typescript\n * import { resetSessionStopState } from './session-state.js';\n *\n * // After PR created\n * if (prExists) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n *\n * // After comment posted\n * if (commentPosted) {\n *   await resetSessionStopState(input.session_id, input.cwd);\n * }\n * ```\n */\nexport async function resetSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  await updateSessionStopState(\n    sessionId,\n    {\n      blockCount: 0,\n      commentPosted: false,\n      lastBlockTimestamp: new Date().toISOString(),\n    },\n    cwd,\n    statePath\n  );\n}\n\n/**\n * Remove session stop state entirely\n *\n * Deletes the session's state from the file. Use this when a session\n * is completely finished and you want to clean up.\n * @param sessionId - The session ID to remove\n * @param cwd - The working directory where logs are stored\n * @param statePath - Optional custom path for session-stops.json (for testing)\n * @returns Promise that resolves when state is removed (fails silently)\n * @example\n * ```typescript\n * import { removeSessionStopState } from './session-state.js';\n *\n * // Cleanup after session completes successfully\n * await removeSessionStopState(input.session_id, input.cwd);\n * ```\n */\nexport async function removeSessionStopState(\n  sessionId: string,\n  cwd: string,\n  statePath?: string\n): Promise<void> {\n  const filePath = getSessionStopsFilePath(cwd, statePath);\n\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const allStates: SessionStopsMap = JSON.parse(content);\n    delete allStates[sessionId];\n    await fs.writeFile(filePath, JSON.stringify(allStates, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n",
        "plugins/project-context/shared/hooks/utils/subagent-state.ts": "/**\n * Subagent state management for Claude Code hooks\n * Coordinates context between SubagentStart and SubagentStop hooks\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './frontmatter.js';\nimport {\n  parseTranscript,\n  findPendingTaskCall,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst SUBAGENT_TASKS_FILE = 'subagent-tasks.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface AgentStartContext {\n  agentId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n  toolUseId: string;\n}\n\ninterface SubagentTasksMap {\n  [agentId: string]: AgentStartContext;\n}\n\nexport interface AgentEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to subagent-tasks.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, SUBAGENT_TASKS_FILE);\n}\n\n/**\n * Save agent context at SubagentStart for later retrieval at SubagentStop\n */\nexport async function saveAgentStartContext(\n  input: {\n    agent_id: string;\n    agent_type: string;\n    session_id: string;\n    cwd: string;\n    transcript_path: string;\n  },\n  outputPath?: string\n): Promise<AgentStartContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  // Parse parent transcript to find the Task call\n  const parentTranscript = await parseTranscript(input.transcript_path);\n  const taskInfo = findPendingTaskCall(parentTranscript, input.agent_type);\n\n  const context: AgentStartContext = {\n    agentId: input.agent_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: taskInfo?.prompt || '',\n    toolUseId: taskInfo?.toolUseId || '',\n  };\n\n  // Load existing contexts\n  let contexts: SubagentTasksMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.agent_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved agent context from SubagentStart\n */\nexport async function loadAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<AgentStartContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    return contexts[agentId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove agent context after SubagentStop processing\n */\nexport async function removeAgentStartContext(\n  agentId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: SubagentTasksMap = JSON.parse(content);\n    delete contexts[agentId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Agent Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze an agent transcript to extract comprehensive edit information\n */\nexport async function getAgentEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<AgentEditsResult> {\n  const filename = path.basename(agentTranscriptPath);\n  if (!filename.startsWith('agent-')) {\n    throw new Error(`Path must be an agent transcript (starting with agent-): ${filename}`);\n  }\n\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Try to load saved context\n  let savedContext: AgentStartContext | undefined;\n  if (cwd) {\n    savedContext = await loadAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    toolUseId: savedContext?.toolUseId,\n    subagentType: savedContext?.agentType || options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = taskInfo?.prompt || savedContext?.prompt || '';\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd) {\n    await removeAgentStartContext(agentId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/project-context/shared/hooks/utils/task-state.test.ts": "/**\n * Tests for task-state.ts - Task state management and frontmatter parsing\n *\n * @module task-state.test\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport { tmpdir } from 'os';\nimport {\n  saveTaskCallContext,\n  loadTaskCallContext,\n  removeTaskCallContext,\n} from './task-state.js';\n\ndescribe('Task State Management', () => {\n  let testDir: string;\n  let taskCallsPath: string;\n\n  beforeEach(async () => {\n    // Create temporary directory for tests\n    testDir = await fs.mkdtemp(path.join(tmpdir(), 'task-state-test-'));\n    taskCallsPath = path.join(testDir, 'task-calls.json');\n  });\n\n  afterEach(async () => {\n    // Clean up temporary directory\n    try {\n      await fs.rm(testDir, { recursive: true, force: true });\n    } catch {\n      // Ignore cleanup errors\n    }\n  });\n\n  describe('saveTaskCallContext', () => {\n    it('should save task call context to file', async () => {\n      const input = {\n        tool_use_id: 'toolu_abc123',\n        agent_type: 'Explore',\n        session_id: 'session-xyz',\n        prompt: 'Find all API endpoints',\n        cwd: testDir,\n      };\n\n      const context = await saveTaskCallContext(input, taskCallsPath);\n\n      expect(context.toolUseId).toBe('toolu_abc123');\n      expect(context.agentType).toBe('Explore');\n      expect(context.sessionId).toBe('session-xyz');\n      expect(context.prompt).toBe('Find all API endpoints');\n      expect(context.timestamp).toBeDefined();\n\n      // Verify file was created\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n      expect(saved['toolu_abc123']).toBeDefined();\n      expect(saved['toolu_abc123'].agentType).toBe('Explore');\n    });\n\n    it('should append to existing contexts', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_first',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'First task',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_second',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Second task',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      const fileContent = await fs.readFile(taskCallsPath, 'utf-8');\n      const saved = JSON.parse(fileContent);\n\n      expect(Object.keys(saved)).toHaveLength(2);\n      expect(saved['toolu_first']).toBeDefined();\n      expect(saved['toolu_second']).toBeDefined();\n    });\n  });\n\n  describe('loadTaskCallContext', () => {\n    it('should load saved context by tool_use_id', async () => {\n      const input = {\n        tool_use_id: 'toolu_load_test',\n        agent_type: 'Explore',\n        session_id: 'session-load',\n        prompt: 'Load test prompt',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input, taskCallsPath);\n      const loaded = await loadTaskCallContext('toolu_load_test', testDir, taskCallsPath);\n\n      expect(loaded).toBeDefined();\n      expect(loaded?.toolUseId).toBe('toolu_load_test');\n      expect(loaded?.agentType).toBe('Explore');\n      expect(loaded?.prompt).toBe('Load test prompt');\n    });\n\n    it('should return undefined for non-existent context', async () => {\n      const loaded = await loadTaskCallContext('toolu_nonexistent', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n    });\n\n    it('should return undefined when file does not exist', async () => {\n      const loaded = await loadTaskCallContext('toolu_any', testDir, '/path/does/not/exist.json');\n      expect(loaded).toBeUndefined();\n    });\n  });\n\n  describe('removeTaskCallContext', () => {\n    it('should remove context from file', async () => {\n      const input1 = {\n        tool_use_id: 'toolu_keep',\n        agent_type: 'Explore',\n        session_id: 'session-1',\n        prompt: 'Keep this',\n        cwd: testDir,\n      };\n\n      const input2 = {\n        tool_use_id: 'toolu_remove',\n        agent_type: 'Plan',\n        session_id: 'session-1',\n        prompt: 'Remove this',\n        cwd: testDir,\n      };\n\n      await saveTaskCallContext(input1, taskCallsPath);\n      await saveTaskCallContext(input2, taskCallsPath);\n\n      await removeTaskCallContext('toolu_remove', testDir, taskCallsPath);\n\n      const loaded = await loadTaskCallContext('toolu_remove', testDir, taskCallsPath);\n      expect(loaded).toBeUndefined();\n\n      const kept = await loadTaskCallContext('toolu_keep', testDir, taskCallsPath);\n      expect(kept).toBeDefined();\n    });\n\n    it('should handle removing non-existent context gracefully', async () => {\n      await expect(\n        removeTaskCallContext('toolu_nonexistent', testDir, taskCallsPath)\n      ).resolves.toBeUndefined();\n    });\n  });\n\n  describe('parseFrontmatter (integration via parseAgentFrontmatter)', () => {\n    it('should parse simple key-value frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent.md');\n      const content = `---\nname: TestAgent\ndescription: A test agent\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      // We can't directly test parseFrontmatter since it's not exported,\n      // but we can test it indirectly through getTaskEdits if we create\n      // proper test fixtures. For now, let's create a simpler test.\n\n      // Read the file and verify the frontmatter format is correct\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---');\n      expect(fileContent).toContain('name: TestAgent');\n    });\n\n    it('should parse array values in frontmatter', async () => {\n      const agentFile = path.join(testDir, 'test-agent-with-skills.md');\n      const content = `---\nname: TestAgent\nskills: [skill1, skill2, skill3]\n---\n\n# Agent Content\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('skills: [skill1, skill2, skill3]');\n    });\n\n    it('should handle frontmatter with various formats', async () => {\n      const agentFile = path.join(testDir, 'complex-agent.md');\n      const content = `---\nname: ComplexAgent\nversion: 1.0.0\nskills: [claude-plugins, turborepo-vercel]\nenabled: true\n---\n\n# Complex Agent\n\nThis agent has complex frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('name: ComplexAgent');\n      expect(fileContent).toContain('version: 1.0.0');\n      expect(fileContent).toContain('skills: [claude-plugins, turborepo-vercel]');\n      expect(fileContent).toContain('enabled: true');\n    });\n\n    it('should handle missing frontmatter gracefully', async () => {\n      const agentFile = path.join(testDir, 'no-frontmatter.md');\n      const content = `# Agent Without Frontmatter\n\nThis agent has no frontmatter.\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).not.toContain('---');\n    });\n\n    it('should handle empty frontmatter', async () => {\n      const agentFile = path.join(testDir, 'empty-frontmatter.md');\n      const content = `---\n---\n\n# Agent With Empty Frontmatter\n`;\n      await fs.writeFile(agentFile, content, 'utf-8');\n\n      const fileContent = await fs.readFile(agentFile, 'utf-8');\n      expect(fileContent).toContain('---\\n---');\n    });\n  });\n\n  describe('Full workflow integration', () => {\n    it('should save, load, and remove context in sequence', async () => {\n      // Save\n      const input = {\n        tool_use_id: 'toolu_workflow',\n        agent_type: 'general-purpose',\n        session_id: 'session-workflow',\n        prompt: 'Complete workflow test',\n        cwd: testDir,\n      };\n\n      const saved = await saveTaskCallContext(input, taskCallsPath);\n      expect(saved.toolUseId).toBe('toolu_workflow');\n\n      // Load\n      const loaded = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(loaded).toBeDefined();\n      expect(loaded?.prompt).toBe('Complete workflow test');\n\n      // Remove\n      await removeTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      const removed = await loadTaskCallContext('toolu_workflow', testDir, taskCallsPath);\n      expect(removed).toBeUndefined();\n    });\n  });\n});\n",
        "plugins/project-context/shared/hooks/utils/task-state.ts": "/**\n * Task state management for Claude Code hooks\n *\n * Coordinates context between PreToolUse[Task] and SubagentStop hooks by saving\n * task call metadata at PreToolUse time and retrieving it later for analysis.\n * This enables tracking what tasks were requested, what agents executed them,\n * and what file operations resulted from the task execution.\n *\n * The typical flow is:\n * 1. PreToolUse[Task] - Save task context (prompt, agent type, tool use ID)\n * 2. Task executes - Agent runs and performs file operations\n * 3. SubagentStop - Load context, analyze edits, cleanup\n *\n * @module task-state\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport {\n  parseTranscript,\n  findTaskCallForAgent,\n  getNewFiles,\n  getDeletedFiles,\n  getEditedFiles,\n} from './transcripts.js';\nimport matter from './frontmatter.js';\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst LOGS_DIR = '.claude/logs';\nconst TASK_CALLS_FILE = 'task-calls.json';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface TaskCallContext {\n  toolUseId: string;\n  agentType: string;\n  sessionId: string;\n  timestamp: string;\n  prompt: string;\n}\n\ninterface TaskCallsMap {\n  [toolUseId: string]: TaskCallContext;\n}\n\nexport interface TaskEditsResult {\n  sessionId: string;\n  agentSessionId: string;\n  parentSessionTranscript: string;\n  agentSessionTranscript: string;\n  subagentType: string;\n  agentPrompt: string;\n  agentFile?: string;\n  agentPreloadedSkillsFiles: string[];\n  agentNewFiles: string[];\n  agentDeletedFiles: string[];\n  agentEditedFiles: string[];\n}\n\n// ============================================================================\n// Context Management\n// ============================================================================\n\n/**\n * Get the path to task-calls.json\n */\nfunction getTasksFilePath(cwd: string, customPath?: string): string {\n  return customPath || path.join(cwd, LOGS_DIR, TASK_CALLS_FILE);\n}\n\n/**\n * Save task call context at PreToolUse[Task] for later retrieval at SubagentStop\n *\n * Stores task metadata in .claude/logs/task-calls.json so that SubagentStop hooks\n * can correlate the task's original prompt and parameters with the agent's execution\n * results. This enables rich commit messages and task tracking.\n *\n * @param input - Task call metadata to save\n * @param input.tool_use_id - The unique ID of the Task tool use\n * @param input.agent_type - The type of agent that will execute (e.g., 'Explore', 'Plan')\n * @param input.session_id - The current session ID\n * @param input.prompt - The task prompt/description provided to the agent\n * @param input.cwd - The working directory where logs should be stored\n * @param outputPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context object\n *\n * @example\n * ```typescript\n * import { saveTaskCallContext } from './task-state.js';\n *\n * // In PreToolUse[Task] hook\n * const context = await saveTaskCallContext({\n *   tool_use_id: 'toolu_abc123',\n *   agent_type: 'Explore',\n *   session_id: 'session-xyz',\n *   prompt: 'Find all API endpoints',\n *   cwd: '/path/to/project'\n * });\n * ```\n */\nexport async function saveTaskCallContext(\n  input: {\n    tool_use_id: string;\n    agent_type: string;\n    session_id: string;\n    prompt: string;\n    cwd: string;\n  },\n  outputPath?: string\n): Promise<TaskCallContext> {\n  const contextPath = getTasksFilePath(input.cwd, outputPath);\n  const timestamp = new Date().toISOString();\n\n  const context: TaskCallContext = {\n    toolUseId: input.tool_use_id,\n    agentType: input.agent_type,\n    sessionId: input.session_id,\n    timestamp,\n    prompt: input.prompt,\n  };\n\n  // Load existing contexts\n  let contexts: TaskCallsMap = {};\n  try {\n    const existing = await fs.readFile(contextPath, 'utf-8');\n    contexts = JSON.parse(existing);\n  } catch {\n    // File doesn't exist yet\n  }\n\n  contexts[input.tool_use_id] = context;\n\n  // Ensure directory exists\n  await fs.mkdir(path.dirname(contextPath), { recursive: true });\n  await fs.writeFile(contextPath, JSON.stringify(contexts, null, 2), 'utf-8');\n\n  return context;\n}\n\n/**\n * Load saved task call context from PreToolUse[Task]\n *\n * Retrieves the task metadata that was saved during PreToolUse. This allows\n * SubagentStop hooks to access the original task prompt and parameters.\n *\n * @param toolUseId - The tool_use_id from the Task tool call\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns The saved context, or undefined if not found\n *\n * @example\n * ```typescript\n * import { loadTaskCallContext } from './task-state.js';\n *\n * // In SubagentStop hook\n * const context = await loadTaskCallContext(\n *   'toolu_abc123',\n *   '/path/to/project'\n * );\n * if (context) {\n *   console.log('Task prompt:', context.prompt);\n *   console.log('Agent type:', context.agentType);\n * }\n * ```\n */\nexport async function loadTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<TaskCallContext | undefined> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    return contexts[toolUseId];\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Remove task context after processing\n *\n * Cleans up the saved task context once it has been processed by SubagentStop.\n * This prevents the context file from growing indefinitely.\n *\n * @param toolUseId - The tool_use_id of the context to remove\n * @param cwd - The working directory where logs are stored\n * @param contextPath - Optional custom path for task-calls.json (for testing)\n * @returns Promise that resolves when context is removed (or fails silently)\n *\n * @example\n * ```typescript\n * import { removeTaskCallContext } from './task-state.js';\n *\n * // After processing in SubagentStop\n * await removeTaskCallContext('toolu_abc123', '/path/to/project');\n * ```\n */\nexport async function removeTaskCallContext(\n  toolUseId: string,\n  cwd: string,\n  contextPath?: string\n): Promise<void> {\n  const filePath = getTasksFilePath(cwd, contextPath);\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const contexts: TaskCallsMap = JSON.parse(content);\n    delete contexts[toolUseId];\n    await fs.writeFile(filePath, JSON.stringify(contexts, null, 2), 'utf-8');\n  } catch {\n    // Nothing to remove\n  }\n}\n\n// ============================================================================\n// Task Edits Analysis\n// ============================================================================\n\n/**\n * Parse YAML frontmatter from an agent markdown file\n */\nasync function parseAgentFrontmatter(\n  filePath: string\n): Promise<{ name?: string; skills?: string[] }> {\n  try {\n    const content = await fs.readFile(filePath, 'utf-8');\n    const { data } = matter(content);\n    return data as { name?: string; skills?: string[] };\n  } catch {\n    return {};\n  }\n}\n\n/**\n * Analyze a task transcript to extract comprehensive edit information\n *\n * Parses an agent transcript to determine what files were created, edited, or deleted\n * during task execution. Correlates with saved task context to provide complete\n * metadata about the task, including the original prompt, agent type, and preloaded skills.\n *\n * This function:\n * 1. Parses the agent transcript to extract messages and metadata\n * 2. Finds the parent session transcript and locates the matching Task tool call\n * 3. Loads the saved task context (if available)\n * 4. Analyzes file operations (new, edited, deleted files)\n * 5. Identifies preloaded skills from agent frontmatter\n * 6. Cleans up the saved context\n *\n * @param agentTranscriptPath - Path to the agent transcript file (from SubagentStop's agent_transcript_path field)\n * @param options - Optional configuration\n * @param options.contextPath - Custom path for task-calls.json (for testing)\n * @param options.subagentType - Fallback subagent type if not found in context\n * @returns Comprehensive task execution metadata and file operation lists\n * @throws Error if agent transcript is empty\n * @throws Error if agentId cannot be determined\n * @throws Error if parent session transcript not found\n *\n * @example\n * ```typescript\n * import { getTaskEdits } from './task-state.js';\n *\n * // In SubagentStop hook\n * const edits = await getTaskEdits(input.agent_transcript_path);\n *\n * console.log('Task prompt:', edits.agentPrompt);\n * console.log('Agent type:', edits.subagentType);\n * console.log('Files created:', edits.agentNewFiles);\n * console.log('Files edited:', edits.agentEditedFiles);\n * console.log('Files deleted:', edits.agentDeletedFiles);\n * console.log('Preloaded skills:', edits.agentPreloadedSkillsFiles);\n * ```\n *\n * @example\n * ```typescript\n * // Complete PreToolUse → SubagentStop flow\n *\n * // 1. PreToolUse[Task] - Save context\n * import { saveTaskCallContext } from './task-state.js';\n *\n * async function handlePreToolUse(input: PreToolUseInput) {\n *   if (input.tool_name === 'Task') {\n *     await saveTaskCallContext({\n *       tool_use_id: input.tool_use_id,\n *       agent_type: input.tool_input.subagent_type,\n *       session_id: input.session_id,\n *       prompt: input.tool_input.prompt,\n *       cwd: input.cwd\n *     });\n *   }\n *   return { hookSpecificOutput: { permissionDecision: 'allow' } };\n * }\n *\n * // 2. Task executes (agent runs)\n *\n * // 3. SubagentStop - Analyze edits\n * import { getTaskEdits } from './task-state.js';\n *\n * async function handleSubagentStop(input: SubagentStopInput) {\n *   const edits = await getTaskEdits(input.agent_transcript_path);\n *\n *   // Use edits for commit message, logging, etc.\n *   console.log(`Task \"${edits.agentPrompt}\" completed`);\n *   console.log(`Modified ${edits.agentEditedFiles.length} files`);\n *\n *   return {};\n * }\n * ```\n */\nexport async function getTaskEdits(\n  agentTranscriptPath: string,\n  options?: {\n    contextPath?: string;\n    subagentType?: string;\n  }\n): Promise<TaskEditsResult> {\n  // Parse agent transcript\n  const agentTranscript = await parseTranscript(agentTranscriptPath);\n  const firstMsg = agentTranscript.messages[0];\n  if (!firstMsg) {\n    throw new Error(`Agent transcript is empty: ${agentTranscriptPath}`);\n  }\n\n  const sessionId = firstMsg.sessionId;\n  const cwd = firstMsg.cwd;\n  const agentId = agentTranscript.agentId;\n  const agentStartTimestamp = firstMsg.timestamp;\n\n  if (!agentId) {\n    throw new Error(`Could not determine agentId from transcript: ${agentTranscriptPath}`);\n  }\n\n  // Find parent session transcript\n  const dir = path.dirname(agentTranscriptPath);\n  const parentPath = path.join(dir, `${sessionId}.jsonl`);\n\n  try {\n    await fs.access(parentPath);\n  } catch {\n    throw new Error(`Parent session transcript not found: ${parentPath}`);\n  }\n\n  // Parse parent transcript and find matching Task call\n  const parentTranscript = await parseTranscript(parentPath);\n  const taskInfo = findTaskCallForAgent(parentTranscript, agentId, {\n    subagentType: options?.subagentType,\n    agentStartTimestamp,\n  });\n\n  // Try to load saved context using tool_use_id from task call\n  let savedContext: TaskCallContext | undefined;\n  if (cwd && taskInfo?.toolUseId) {\n    savedContext = await loadTaskCallContext(taskInfo.toolUseId, cwd, options?.contextPath);\n  }\n\n  const subagentType = taskInfo?.subagentType || savedContext?.agentType || options?.subagentType || 'unknown';\n  const agentPrompt = savedContext?.prompt || taskInfo?.prompt || '';\n  const toolUseId = taskInfo?.toolUseId || savedContext?.toolUseId;\n\n  // Find agent definition file\n  let agentFile: string | undefined;\n  if (cwd) {\n    const agentFilePath = path.join(cwd, '.claude', 'agents', `${subagentType}.md`);\n    try {\n      await fs.access(agentFilePath);\n      agentFile = agentFilePath;\n    } catch {\n      // Agent file doesn't exist\n    }\n  }\n\n  // Parse agent frontmatter for skills\n  let skills: string[] = [];\n  if (agentFile) {\n    const frontmatter = await parseAgentFrontmatter(agentFile);\n    skills = frontmatter.skills || [];\n  }\n\n  const agentPreloadedSkillsFiles = cwd\n    ? skills.map((s) => path.join(cwd, '.claude', 'skills', s, 'SKILL.md'))\n    : [];\n\n  // Get file operations\n  const agentNewFiles = getNewFiles(agentTranscript);\n  const agentDeletedFiles = getDeletedFiles(agentTranscript);\n  const agentEditedFiles = getEditedFiles(agentTranscript);\n\n  // Cleanup saved context\n  if (cwd && toolUseId) {\n    await removeTaskCallContext(toolUseId, cwd, options?.contextPath);\n  }\n\n  return {\n    sessionId,\n    agentSessionId: agentId,\n    parentSessionTranscript: parentPath,\n    agentSessionTranscript: agentTranscriptPath,\n    subagentType,\n    agentPrompt,\n    agentFile,\n    agentPreloadedSkillsFiles,\n    agentNewFiles,\n    agentDeletedFiles,\n    agentEditedFiles,\n  };\n}\n",
        "plugins/project-context/shared/hooks/utils/toml.ts": "/**\n * Simple TOML parser for configuration files\n *\n * Provides basic TOML parsing functionality for reading configuration files\n * like supabase/config.toml. This is a lightweight parser that supports the\n * most common TOML features without requiring external dependencies.\n *\n * Supported TOML features:\n * - Key-value pairs (strings, numbers, booleans)\n * - Inline arrays: `values = [1, 2, 3]`\n * - Multiline arrays spanning multiple lines\n * - Tables (sections): `[section]` and `[section.subsection]`\n * - Comments starting with `#`\n *\n * @module toml\n */\n\nexport interface TomlValue {\n  [key: string]: string | number | boolean | string[] | TomlValue;\n}\n\n/**\n * Parse a TOML string into a JavaScript object\n *\n * Converts TOML configuration syntax into a JavaScript object with nested\n * structure matching the TOML sections and subsections.\n *\n * @param content - The TOML string to parse\n * @returns Parsed object with nested structure\n *\n * @example\n * ```typescript\n * import { parseToml } from './toml.js';\n *\n * const tomlContent = `\n * # Project configuration\n * project_id = \"my-project\"\n * enabled = true\n *\n * [api]\n * port = 54321\n * enabled_services = [\"auth\", \"realtime\", \"storage\"]\n *\n * [db]\n * port = 54322\n * `;\n *\n * const config = parseToml(tomlContent);\n * console.log(config.project_id); // \"my-project\"\n * console.log(config.enabled); // true\n * console.log(config.api.port); // 54321\n * console.log(config.api.enabled_services); // [\"auth\", \"realtime\", \"storage\"]\n * console.log(config.db.port); // 54322\n * ```\n */\nexport function parseToml(content: string): TomlValue {\n  const result: TomlValue = {};\n  let currentSection: TomlValue = result;\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n\n    // Skip empty lines and comments\n    if (!line || line.startsWith('#')) {\n      continue;\n    }\n\n    // Handle table headers [section] or [section.subsection]\n    if (line.startsWith('[') && line.endsWith(']')) {\n      const sectionPath = line.slice(1, -1).trim();\n      currentSection = result;\n\n      for (const part of sectionPath.split('.')) {\n        if (!(part in currentSection)) {\n          currentSection[part] = {};\n        }\n        currentSection = currentSection[part] as TomlValue;\n      }\n      continue;\n    }\n\n    // Handle key-value pairs\n    const eqIndex = line.indexOf('=');\n    if (eqIndex === -1) continue;\n\n    const key = line.slice(0, eqIndex).trim();\n    const value = line.slice(eqIndex + 1).trim();\n\n    // Parse the value\n    currentSection[key] = parseValue(value, lines, i);\n  }\n\n  return result;\n}\n\n/**\n * Parse a TOML value\n */\nfunction parseValue(value: string, lines: string[], lineIndex: number): string | number | boolean | string[] {\n  // Handle multiline arrays\n  if (value === '[' || value.startsWith('[') && !value.endsWith(']')) {\n    return parseMultilineArray(value, lines, lineIndex);\n  }\n\n  // Handle inline arrays\n  if (value.startsWith('[') && value.endsWith(']')) {\n    return parseInlineArray(value);\n  }\n\n  // Handle strings\n  if (value.startsWith('\"') && value.endsWith('\"')) {\n    return value.slice(1, -1);\n  }\n  if (value.startsWith(\"'\") && value.endsWith(\"'\")) {\n    return value.slice(1, -1);\n  }\n\n  // Handle booleans\n  if (value === 'true') return true;\n  if (value === 'false') return false;\n\n  // Handle numbers\n  const num = Number(value);\n  if (!isNaN(num)) return num;\n\n  // Return as string if nothing else matches\n  return value;\n}\n\n/**\n * Parse an inline array like [1, 2, 3] or [\"a\", \"b\", \"c\"]\n */\nfunction parseInlineArray(value: string): string[] {\n  const inner = value.slice(1, -1).trim();\n  if (!inner) return [];\n\n  const items: string[] = [];\n  let current = '';\n  let inQuote = false;\n  let quoteChar = '';\n\n  for (const char of inner) {\n    if ((char === '\"' || char === \"'\") && !inQuote) {\n      inQuote = true;\n      quoteChar = char;\n    } else if (char === quoteChar && inQuote) {\n      inQuote = false;\n      quoteChar = '';\n    } else if (char === ',' && !inQuote) {\n      const trimmed = current.trim();\n      if (trimmed) {\n        items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n      }\n      current = '';\n    } else {\n      current += char;\n    }\n  }\n\n  const trimmed = current.trim();\n  if (trimmed) {\n    items.push(trimmed.replace(/^[\"']|[\"']$/g, ''));\n  }\n\n  return items;\n}\n\n/**\n * Parse a multiline array\n */\nfunction parseMultilineArray(startValue: string, lines: string[], startIndex: number): string[] {\n  const items: string[] = [];\n  let content = startValue;\n\n  // Collect lines until we find the closing bracket\n  for (let i = startIndex; i < lines.length; i++) {\n    const line = lines[i].trim();\n    if (i > startIndex) {\n      content += ' ' + line;\n    }\n    if (line.includes(']')) {\n      break;\n    }\n  }\n\n  // Now parse as inline array\n  const match = content.match(/\\[([\\s\\S]*)\\]/);\n  if (match) {\n    return parseInlineArray('[' + match[1] + ']');\n  }\n\n  return items;\n}\n\n/**\n * Read and parse a TOML file\n *\n * Reads a TOML configuration file from disk and parses it into a JavaScript object.\n * Returns null if the file doesn't exist or cannot be read.\n *\n * @param filePath - Path to the TOML file\n * @returns Parsed object, or null if file doesn't exist or read fails\n *\n * @example\n * ```typescript\n * import { readTomlFile } from './toml.js';\n * import { join } from 'path';\n *\n * // Read Supabase configuration\n * const supabaseConfig = await readTomlFile(\n *   join(process.cwd(), 'supabase', 'config.toml')\n * );\n *\n * if (supabaseConfig) {\n *   console.log('Project ID:', supabaseConfig.project_id);\n *   console.log('API port:', supabaseConfig.api?.port);\n *   console.log('DB port:', supabaseConfig.db?.port);\n * } else {\n *   console.log('Supabase not initialized');\n * }\n * ```\n */\nexport async function readTomlFile(filePath: string): Promise<TomlValue | null> {\n  try {\n    const fs = await import('fs/promises');\n    const content = await fs.readFile(filePath, 'utf-8');\n    return parseToml(content);\n  } catch {\n    return null;\n  }\n}\n",
        "plugins/project-context/shared/hooks/utils/transcripts.ts": "/**\n * Transcript parsing utilities for Claude Code\n * Lenient JSONL parsing without Zod - uses type guards for safety\n */\n\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\n// ============================================================================\n// Types for Transcript Parsing\n// ============================================================================\n\nexport interface BaseMessage {\n  uuid: string;\n  parentUuid: string | null;\n  timestamp: string;\n  sessionId: string;\n  isSidechain: boolean;\n  cwd: string;\n  version: string;\n  gitBranch?: string;\n  slug?: string;\n  agentId?: string;\n}\n\nexport interface ToolUseContent {\n  type: 'tool_use';\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n}\n\nexport interface TextContent {\n  type: 'text';\n  text: string;\n}\n\nexport interface ToolResultContent {\n  type: 'tool_result';\n  tool_use_id: string;\n  content?: string | Array<{ type: string; text?: string }>;\n}\n\nexport type AssistantContent = ToolUseContent | TextContent | { type: string; [key: string]: unknown };\nexport type UserContent = string | Array<ToolResultContent | { type: string; [key: string]: unknown }>;\n\nexport interface UserMessage extends BaseMessage {\n  type: 'user';\n  userType: 'external';\n  message: {\n    role: 'user';\n    content: UserContent;\n  };\n  toolUseResult?: Record<string, unknown>;\n}\n\nexport interface AssistantMessage extends BaseMessage {\n  type: 'assistant';\n  requestId: string;\n  message: {\n    id: string;\n    type: 'message';\n    role: 'assistant';\n    model: string;\n    content: AssistantContent[];\n    stop_reason: string | null;\n    stop_sequence: string | null;\n    usage: {\n      input_tokens: number;\n      output_tokens: number;\n      cache_creation_input_tokens?: number;\n      cache_read_input_tokens?: number;\n    };\n  };\n}\n\nexport interface SystemMessage extends BaseMessage {\n  type: 'system';\n  subtype: string;\n  content: string;\n  isMeta: boolean;\n  level: 'info' | 'warning' | 'error';\n}\n\nexport type Message = UserMessage | AssistantMessage | SystemMessage;\n\nexport interface Transcript {\n  sourcePath: string;\n  sessionId: string;\n  subagentType?: string;\n  agentId?: string;\n  isSidechain: boolean;\n  messages: Message[];\n}\n\n// ============================================================================\n// Type Guards\n// ============================================================================\n\nfunction isObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === 'object' && value !== null;\n}\n\nfunction isMessage(line: unknown): line is Message {\n  if (!isObject(line)) return false;\n  const type = line.type;\n  return type === 'user' || type === 'assistant' || type === 'system';\n}\n\nfunction hasRequiredFields(line: unknown): boolean {\n  if (!isObject(line)) return false;\n  return (\n    typeof line.uuid === 'string' &&\n    typeof line.timestamp === 'string' &&\n    typeof line.sessionId === 'string'\n  );\n}\n\n// ============================================================================\n// Parsing Functions\n// ============================================================================\n\n/**\n * Parse a single JSONL line (lenient - returns null on error)\n */\nexport function parseTranscriptLine(line: string): Message | null {\n  try {\n    const json = JSON.parse(line);\n    if (!isMessage(json) || !hasRequiredFields(json)) {\n      return null;\n    }\n    return json as Message;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Get transcript metadata from file path\n */\nexport function getTranscriptInfo(filePath: string): { agentId?: string; isSidechain: boolean } {\n  const filename = path.basename(filePath);\n  const isSubagent = filename.startsWith('agent-');\n  const agentId = isSubagent ? filename.replace('agent-', '').replace('.jsonl', '') : undefined;\n\n  return { agentId, isSidechain: isSubagent };\n}\n\n/**\n * Parse a full .jsonl transcript file\n */\nexport async function parseTranscript(filePath: string): Promise<Transcript> {\n  const info = getTranscriptInfo(filePath);\n  const content = await fs.readFile(filePath, 'utf-8');\n  const lines = content.trim().split('\\n').filter(Boolean);\n\n  const messages: Message[] = [];\n  let sessionId = '';\n\n  for (const line of lines) {\n    const parsed = parseTranscriptLine(line);\n    if (!parsed) continue;\n\n    if (!sessionId) sessionId = parsed.sessionId;\n    messages.push(parsed);\n  }\n\n  return {\n    sourcePath: filePath,\n    sessionId,\n    agentId: info.agentId,\n    isSidechain: info.isSidechain,\n    messages,\n  };\n}\n\n// ============================================================================\n// Query Functions\n// ============================================================================\n\n/**\n * Extract all tool uses from a transcript\n */\nexport function getToolUses(transcript: Transcript): Array<{\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n  timestamp: string;\n}> {\n  const toolUses: Array<{\n    id: string;\n    name: string;\n    input: Record<string, unknown>;\n    timestamp: string;\n  }> = [];\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        toolUses.push({\n          id: tu.id,\n          name: tu.name,\n          input: tu.input,\n          timestamp: msg.timestamp,\n        });\n      }\n    }\n  }\n\n  return toolUses;\n}\n\n/**\n * Extract unique file paths edited by Write/Edit tools\n */\nexport function getEditedFiles(transcript: Transcript): string[] {\n  const files = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write' || tu.name === 'Edit') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string') {\n            files.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(files);\n}\n\n/**\n * Extract unique file paths created by Write tool (new files only)\n */\nexport function getNewFiles(transcript: Transcript): string[] {\n  const newFiles: string[] = [];\n  const seenPaths = new Set<string>();\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Write') {\n          const filePath = tu.input.file_path;\n          if (typeof filePath === 'string' && !seenPaths.has(filePath)) {\n            newFiles.push(filePath);\n            seenPaths.add(filePath);\n          }\n        }\n      }\n    }\n  }\n\n  return newFiles;\n}\n\n/**\n * Extract unique file paths deleted via Bash rm commands\n */\nexport function getDeletedFiles(transcript: Transcript): string[] {\n  const deletedFiles = new Set<string>();\n  const rmPattern = /^\\s*rm\\s+(?:-[rfiv]+\\s+)*(.+)$/;\n\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Bash') {\n          const command = tu.input.command;\n          if (typeof command !== 'string') continue;\n\n          const commands = command.split(/\\s*(?:&&|;)\\s*/);\n          for (const cmd of commands) {\n            const match = cmd.match(rmPattern);\n            if (match) {\n              const pathsStr = match[1].trim();\n              const paths = pathsStr.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g) || [];\n\n              for (const p of paths) {\n                const cleanPath = p.replace(/^[\"']|[\"']$/g, '');\n                if (!cleanPath.startsWith('-')) {\n                  deletedFiles.add(cleanPath);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(deletedFiles);\n}\n\n/**\n * Find pending Task tool call matching agent type\n */\nexport function findPendingTaskCall(\n  transcript: Transcript,\n  agentType: string\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls: Array<{\n    toolUseId: string;\n    subagentType: string;\n    prompt: string;\n    timestamp: string;\n  }> = [];\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.push({\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Collect completed tool_use_ids\n  const completedToolUseIds = new Set<string>();\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const content = msg.message.content;\n    if (typeof content === 'string') continue;\n    for (const rc of content) {\n      if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n        completedToolUseIds.add(rc.tool_use_id);\n      }\n    }\n  }\n\n  // Find pending Task calls matching agent type\n  const pendingTasks = taskCalls\n    .filter((t) => !completedToolUseIds.has(t.toolUseId))\n    .filter((t) => t.subagentType === agentType)\n    .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n  return pendingTasks[0];\n}\n\n/**\n * Find Task tool call for an agent using multiple strategies\n */\nexport function findTaskCallForAgent(\n  transcript: Transcript,\n  targetAgentId: string,\n  options?: {\n    subagentType?: string;\n    toolUseId?: string;\n    agentStartTimestamp?: string;\n  }\n): { subagentType: string; prompt: string; toolUseId: string } | undefined {\n  const taskCalls = new Map<string, {\n    subagentType: string;\n    prompt: string;\n    toolUseId: string;\n    timestamp: string;\n  }>();\n\n  // Collect all Task tool_use calls\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'assistant') continue;\n\n    for (const content of msg.message.content) {\n      if (content.type === 'tool_use') {\n        const tu = content as ToolUseContent;\n        if (tu.name === 'Task') {\n          taskCalls.set(tu.id, {\n            toolUseId: tu.id,\n            subagentType: (tu.input.subagent_type as string) || 'unknown',\n            prompt: (tu.input.prompt as string) || '',\n            timestamp: msg.timestamp,\n          });\n        }\n      }\n    }\n  }\n\n  // Strategy 1: Direct lookup by toolUseId\n  if (options?.toolUseId) {\n    const direct = taskCalls.get(options.toolUseId);\n    if (direct) return direct;\n  }\n\n  // Strategy 2: Match via tool_result.agentId\n  for (const msg of transcript.messages) {\n    if (msg.type !== 'user') continue;\n    const toolResult = msg.toolUseResult as { agentId?: string } | undefined;\n    if (toolResult?.agentId === targetAgentId) {\n      const content = msg.message.content;\n      if (typeof content === 'string') continue;\n\n      for (const rc of content) {\n        if ('tool_use_id' in rc && typeof rc.tool_use_id === 'string') {\n          const taskInfo = taskCalls.get(rc.tool_use_id);\n          if (taskInfo) return taskInfo;\n        }\n      }\n    }\n  }\n\n  // Strategy 3: Fuzzy match by subagentType and timestamp\n  if (options?.subagentType && options?.agentStartTimestamp) {\n    const agentStartTime = new Date(options.agentStartTimestamp).getTime();\n    const maxDelta = 10000; // 10 seconds\n\n    const candidates = Array.from(taskCalls.values())\n      .filter((t) => t.subagentType === options.subagentType)\n      .filter((t) => {\n        const taskTime = new Date(t.timestamp).getTime();\n        return taskTime <= agentStartTime && agentStartTime - taskTime <= maxDelta;\n      })\n      .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());\n\n    if (candidates[0]) return candidates[0];\n  }\n\n  return undefined;\n}\n",
        "plugins/project-context/shared/hooks/utils/tsdoc-parser.ts": "/**\n * TSDoc metadata parser for TypeScript files\n *\n * Extracts context metadata from TSDoc comments including @context and @aliases tags,\n * as well as implicit tags from exported function/component/class names.\n * Uses regex-based parsing for zero external dependencies.\n *\n * @module tsdoc-parser\n */\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Metadata extracted from TSDoc comments\n *\n * Contains context tags, aliases, and optional description\n * extracted from JSDoc-style comments.\n */\nexport interface TSDocMetadata {\n  /**\n   * Context tags from @context (comma-separated values)\n   * @example ['authentication', 'user-management', 'security']\n   */\n  tags: string[];\n  /**\n   * Aliases from @aliases (comma-separated values)\n   * @example ['login', 'signin', 'auth']\n   */\n  aliases: string[];\n  /**\n   * Description extracted from the first line of the comment\n   */\n  description?: string;\n}\n\n/**\n * Information about an exported item from a TypeScript file\n *\n * Captures the name, type, associated TSDoc metadata, and line number\n * for each export in a file.\n */\nexport interface ExportInfo {\n  /**\n   * Name of the exported item\n   */\n  name: string;\n  /**\n   * Type of export\n   */\n  type: 'function' | 'component' | 'class' | 'constant' | 'type';\n  /**\n   * TSDoc metadata associated with this export\n   */\n  metadata: TSDocMetadata;\n  /**\n   * Line number where the export is defined (1-indexed)\n   */\n  line: number;\n}\n\n/**\n * Complete metadata for a parsed TypeScript file\n *\n * Combines file-level metadata with all export information.\n */\nexport interface FileMetadata {\n  /**\n   * Relative path to the file\n   */\n  path: string;\n  /**\n   * ISO timestamp of last file modification\n   */\n  lastModified: string;\n  /**\n   * ISO timestamp when the file was indexed\n   */\n  lastIndexed: string;\n  /**\n   * Aggregated tags from all exports and file-level comments\n   */\n  tags: string[];\n  /**\n   * Aggregated aliases from all exports and file-level comments\n   */\n  aliases: string[];\n  /**\n   * All exports found in the file\n   */\n  exports: ExportInfo[];\n  /**\n   * File-level description from leading comment\n   */\n  description?: string;\n}\n\n// ============================================================================\n// Constants\n// ============================================================================\n\n/**\n * Regex to match JSDoc-style comments (both block and doc comments)\n */\nconst JSDOC_COMMENT_REGEX = /\\/\\*\\*?([\\s\\S]*?)\\*\\//g;\n\n/**\n * Regex to match @context tag with comma-separated values\n */\nconst CONTEXT_TAG_REGEX = /@context\\s+([^\\n@]+)/gi;\n\n/**\n * Regex to match @aliases tag with comma-separated values\n */\nconst ALIASES_TAG_REGEX = /@aliases?\\s+([^\\n@]+)/gi;\n\n/**\n * Regex to match first line description (before any @tags)\n */\nconst DESCRIPTION_REGEX = /^\\s*\\*?\\s*([^@\\n*][^\\n]*)/m;\n\n/**\n * Regex patterns for different export types\n */\nconst EXPORT_PATTERNS = {\n  // export function name() or export async function name()\n  function: /^export\\s+(?:async\\s+)?function\\s+(\\w+)/,\n  // export const Name = () => or export const name =\n  arrowFunction: /^export\\s+const\\s+(\\w+)\\s*=\\s*(?:\\([^)]*\\)|[^=])*=>/,\n  // export const name = value (not arrow function)\n  constant: /^export\\s+const\\s+(\\w+)\\s*=/,\n  // export class Name\n  class: /^export\\s+class\\s+(\\w+)/,\n  // export type Name or export interface Name\n  type: /^export\\s+(?:type|interface)\\s+(\\w+)/,\n  // export default function or export default class\n  defaultExport: /^export\\s+default\\s+(?:function|class)\\s+(\\w+)/,\n};\n\n// ============================================================================\n// Parsing Functions\n// ============================================================================\n\n/**\n * Parse comma-separated values from a tag value string\n *\n * Handles whitespace, quotes, and empty values.\n *\n * @param value - Raw tag value string\n * @returns Array of trimmed, non-empty values\n *\n * @example\n * ```typescript\n * parseCommaSeparated('auth, user-management, security')\n * // Returns: ['auth', 'user-management', 'security']\n * ```\n */\nfunction parseCommaSeparated(value: string): string[] {\n  return value\n    .split(',')\n    .map((item) => item.trim())\n    .filter((item) => item.length > 0);\n}\n\n/**\n * Extract TSDoc metadata from a single comment block\n *\n * Parses @context and @aliases tags, and extracts the first line\n * as a description if it doesn't start with @.\n *\n * @param comment - Comment content (without delimiters)\n * @returns Parsed TSDoc metadata\n *\n * @example\n * ```typescript\n * const metadata = extractTSDocFromComment(`\n *   * Authenticates a user with credentials\n *   * @context authentication, security\n *   * @aliases login, signin\n * `);\n * // Returns: {\n * //   tags: ['authentication', 'security'],\n * //   aliases: ['login', 'signin'],\n * //   description: 'Authenticates a user with credentials'\n * // }\n * ```\n */\nfunction extractTSDocFromComment(comment: string): TSDocMetadata {\n  const tags: string[] = [];\n  const aliases: string[] = [];\n  let description: string | undefined;\n\n  // Extract @context tags\n  let match: RegExpExecArray | null;\n  const contextRegex = new RegExp(CONTEXT_TAG_REGEX.source, 'gi');\n  while ((match = contextRegex.exec(comment)) !== null) {\n    tags.push(...parseCommaSeparated(match[1]));\n  }\n\n  // Extract @aliases tags\n  const aliasesRegex = new RegExp(ALIASES_TAG_REGEX.source, 'gi');\n  while ((match = aliasesRegex.exec(comment)) !== null) {\n    aliases.push(...parseCommaSeparated(match[1]));\n  }\n\n  // Extract description (first non-@ line)\n  const descMatch = comment.match(DESCRIPTION_REGEX);\n  if (descMatch) {\n    description = descMatch[1].trim();\n    // Remove leading asterisks from multi-line comments\n    description = description.replace(/^\\*\\s*/, '');\n    // Limit to 100 chars\n    if (description.length > 100) {\n      description = description.substring(0, 97) + '...';\n    }\n  }\n\n  return { tags, aliases, description };\n}\n\n/**\n * Extract TSDoc metadata from file content\n *\n * Finds the first JSDoc comment in the file (typically module-level)\n * and extracts @context and @aliases tags from it.\n *\n * @param content - Full TypeScript file content\n * @returns Aggregated TSDoc metadata from all comments\n *\n * @example\n * ```typescript\n * import { extractTSDocMetadata } from './tsdoc-parser.js';\n *\n * const content = `\n * /**\n *  * User authentication module\n *  * @context authentication, security\n *  * @aliases auth, login\n *  *\\/\n * export function authenticate() {}\n * `;\n *\n * const metadata = extractTSDocMetadata(content);\n * // Returns: {\n * //   tags: ['authentication', 'security'],\n * //   aliases: ['auth', 'login'],\n * //   description: 'User authentication module'\n * // }\n * ```\n */\nexport function extractTSDocMetadata(content: string): TSDocMetadata {\n  const allTags: string[] = [];\n  const allAliases: string[] = [];\n  let firstDescription: string | undefined;\n\n  // Find all JSDoc comments\n  const commentRegex = new RegExp(JSDOC_COMMENT_REGEX.source, 'g');\n  let match: RegExpExecArray | null;\n\n  while ((match = commentRegex.exec(content)) !== null) {\n    const metadata = extractTSDocFromComment(match[1]);\n    allTags.push(...metadata.tags);\n    allAliases.push(...metadata.aliases);\n    if (!firstDescription && metadata.description) {\n      firstDescription = metadata.description;\n    }\n  }\n\n  // Deduplicate tags and aliases\n  return {\n    tags: [...new Set(allTags)],\n    aliases: [...new Set(allAliases)],\n    description: firstDescription,\n  };\n}\n\n/**\n * Determine if a name is likely a React component\n *\n * React components by convention start with an uppercase letter.\n *\n * @param name - Export name to check\n * @returns True if the name follows React component naming convention\n */\nfunction isLikelyComponent(name: string): boolean {\n  return /^[A-Z][a-zA-Z0-9]*$/.test(name);\n}\n\n/**\n * Find the JSDoc comment immediately preceding a line\n *\n * Searches backwards from the given line to find an associated comment.\n *\n * @param lines - Array of file lines\n * @param lineIndex - Index of the export line (0-indexed)\n * @returns Comment content if found, undefined otherwise\n */\nfunction findPrecedingComment(lines: string[], lineIndex: number): string | undefined {\n  // Look for a comment ending on the line before\n  let i = lineIndex - 1;\n\n  // Skip blank lines\n  while (i >= 0 && lines[i].trim() === '') {\n    i--;\n  }\n\n  if (i < 0) return undefined;\n\n  // Check if this line ends a block comment\n  const endLine = lines[i].trim();\n  if (!endLine.endsWith('*/')) return undefined;\n\n  // Find the start of the comment\n  const commentLines: string[] = [];\n  while (i >= 0) {\n    const line = lines[i];\n    commentLines.unshift(line);\n    if (line.includes('/**') || line.includes('/*')) {\n      break;\n    }\n    i--;\n  }\n\n  return commentLines.join('\\n');\n}\n\n/**\n * Extract all exports from a TypeScript file\n *\n * Parses the file to find all exported functions, components, classes,\n * constants, and types. Associates each export with its TSDoc metadata.\n *\n * @param content - Full TypeScript file content\n * @returns Array of export information with metadata\n *\n * @example\n * ```typescript\n * import { extractExports } from './tsdoc-parser.js';\n *\n * const content = `\n * /**\n *  * Button component\n *  * @context ui, components\n *  *\\/\n * export function Button() { return <button />; }\n *\n * /**\n *  * Input field component\n *  * @context ui, forms\n *  *\\/\n * export const Input = () => <input />;\n * `;\n *\n * const exports = extractExports(content);\n * // Returns: [\n * //   { name: 'Button', type: 'component', metadata: {...}, line: 5 },\n * //   { name: 'Input', type: 'component', metadata: {...}, line: 11 }\n * // ]\n * ```\n */\nexport function extractExports(content: string): ExportInfo[] {\n  const exports: ExportInfo[] = [];\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n    const trimmedLine = line.trim();\n\n    // Skip non-export lines\n    if (!trimmedLine.startsWith('export')) continue;\n\n    let name: string | undefined;\n    let type: ExportInfo['type'] = 'constant';\n\n    // Try each pattern\n    for (const [patternType, regex] of Object.entries(EXPORT_PATTERNS)) {\n      const match = trimmedLine.match(regex);\n      if (match) {\n        name = match[1];\n\n        // Determine type\n        if (patternType === 'function' || patternType === 'arrowFunction') {\n          type = isLikelyComponent(name) ? 'component' : 'function';\n        } else if (patternType === 'class') {\n          type = 'class';\n        } else if (patternType === 'type') {\n          type = 'type';\n        } else if (patternType === 'defaultExport') {\n          type = isLikelyComponent(name) ? 'component' : 'function';\n        } else {\n          // Check if it's a component based on naming\n          type = isLikelyComponent(name) ? 'component' : 'constant';\n        }\n        break;\n      }\n    }\n\n    if (!name) continue;\n\n    // Find preceding JSDoc comment\n    const commentContent = findPrecedingComment(lines, i);\n    let metadata: TSDocMetadata = { tags: [], aliases: [] };\n\n    if (commentContent) {\n      // Extract from the comment block\n      const commentMatch = commentContent.match(/\\/\\*\\*?([\\s\\S]*?)\\*\\//);\n      if (commentMatch) {\n        metadata = extractTSDocFromComment(commentMatch[1]);\n      }\n    }\n\n    // Add the export name as an implicit tag (converted to kebab-case)\n    const implicitTag = name\n      .replace(/([a-z])([A-Z])/g, '$1-$2')\n      .toLowerCase();\n    if (!metadata.tags.includes(implicitTag)) {\n      metadata.tags.push(implicitTag);\n    }\n\n    exports.push({\n      name,\n      type,\n      metadata,\n      line: i + 1, // Convert to 1-indexed\n    });\n  }\n\n  return exports;\n}\n\n/**\n * Parse complete metadata for a TypeScript file\n *\n * Combines file-level TSDoc metadata with all export metadata\n * to create a complete picture of the file's context.\n *\n * @param filePath - Path to the file (for metadata)\n * @param content - Full file content\n * @returns Complete file metadata\n *\n * @example\n * ```typescript\n * import { parseFileMetadata } from './tsdoc-parser.js';\n * import * as fs from 'fs/promises';\n *\n * const content = await fs.readFile('src/auth/login.ts', 'utf-8');\n * const metadata = parseFileMetadata('src/auth/login.ts', content);\n *\n * console.log(metadata.tags);    // ['authentication', 'security', 'login-form']\n * console.log(metadata.exports); // Array of ExportInfo\n * ```\n */\nexport function parseFileMetadata(filePath: string, content: string): FileMetadata {\n  const now = new Date().toISOString();\n\n  // Get file-level metadata from first comment\n  const fileMetadata = extractTSDocMetadata(content);\n\n  // Get all exports with their metadata\n  const exports = extractExports(content);\n\n  // Aggregate all tags and aliases\n  const allTags = new Set<string>(fileMetadata.tags);\n  const allAliases = new Set<string>(fileMetadata.aliases);\n\n  for (const exp of exports) {\n    for (const tag of exp.metadata.tags) {\n      allTags.add(tag);\n    }\n    for (const alias of exp.metadata.aliases) {\n      allAliases.add(alias);\n    }\n  }\n\n  return {\n    path: filePath,\n    lastModified: now, // Caller should set this from file stat\n    lastIndexed: now,\n    tags: [...allTags],\n    aliases: [...allAliases],\n    exports,\n    description: fileMetadata.description,\n  };\n}\n",
        "plugins/project-context/shared/hooks/utils/was-tool-event-main-agent.ts": "/**\n * Utility to determine if a tool event was executed by the main agent vs a subagent\n */\n\nimport { parseTranscript, type AssistantMessage } from './transcripts.js';\n\n/**\n * Check if a specific tool use was executed by the main agent (not a subagent)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param toolUseId - The tool_use_id to check\n * @returns true if the tool was used by the main agent, false if by a subagent\n *\n * @example\n * ```typescript\n * const isMainAgent = await wasToolEventMainAgent(\n *   input.transcript_path,\n *   input.tool_use_id\n * );\n * if (!isMainAgent) {\n *   // Skip processing for subagent tool use\n *   return { continue: true };\n * }\n * ```\n */\nexport async function wasToolEventMainAgent(\n  transcriptPath: string,\n  toolUseId: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n\n  // Find the assistant message containing this tool use\n  for (const msg of transcript.messages) {\n    if (msg.type === 'assistant') {\n      const assistantMsg = msg as AssistantMessage;\n      const toolUse = assistantMsg.message.content.find(\n        (c) => c.type === 'tool_use' && 'id' in c && c.id === toolUseId\n      );\n\n      if (toolUse) {\n        // If agentId is undefined/null, it's the main agent\n        // If agentId is a string, it's a subagent\n        return !msg.agentId;\n      }\n    }\n  }\n\n  // If we can't find the tool use, default to assuming it's the main agent\n  // This is safer than blocking legitimate main agent operations\n  return true;\n}\n\n/**\n * Check if the entire transcript is from the main agent session (not a subagent session)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns true if this is a main agent transcript, false if it's a subagent transcript\n *\n * @example\n * ```typescript\n * const isMainSession = await isMainAgentTranscript(input.transcript_path);\n * if (!isMainSession) {\n *   // This is a subagent session, skip processing\n *   return { continue: true };\n * }\n * ```\n */\nexport async function isMainAgentTranscript(transcriptPath: string): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return !transcript.isSidechain;\n}\n\n/**\n * Check if a transcript belongs to a specific subagent type\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @param subagentType - The subagent type to check for (e.g., \"Explore\", \"Plan\")\n * @returns true if the transcript is from the specified subagent type\n *\n * @example\n * ```typescript\n * const isExploreAgent = await isSubagentType(input.transcript_path, 'Explore');\n * if (isExploreAgent) {\n *   // Special handling for Explore agents\n * }\n * ```\n */\nexport async function isSubagentType(\n  transcriptPath: string,\n  subagentType: string\n): Promise<boolean> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.subagentType === subagentType;\n}\n\n/**\n * Get the agent ID from a transcript (undefined for main agent, string for subagents)\n *\n * @param transcriptPath - Path to the session transcript JSONL file\n * @returns The agent ID if this is a subagent, undefined if main agent\n *\n * @example\n * ```typescript\n * const agentId = await getTranscriptAgentId(input.transcript_path);\n * if (agentId) {\n *   console.log(`Processing subagent: ${agentId}`);\n * } else {\n *   console.log('Processing main agent');\n * }\n * ```\n */\nexport async function getTranscriptAgentId(transcriptPath: string): Promise<string | undefined> {\n  const transcript = await parseTranscript(transcriptPath);\n  return transcript.agentId;\n}\n",
        "plugins/project-context/shared/hooks/validate-folder-structure-mkdir.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Bash mkdir)\n *\n * This hook fires before Bash operations to validate directory creation against\n * CLAUDE.md folder specifications. Validates:\n * - mkdir commands creating new directories\n * - Checks parent's subfolder spec for allowed patterns\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n *\n * @module hooks/validate-folder-structure-mkdir\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * Extract directory paths from mkdir commands\n * Handles: mkdir dir, mkdir -p dir, mkdir -p dir1 dir2, etc.\n */\nfunction extractMkdirPaths(command: string): string[] {\n  const paths: string[] = [];\n\n  // Extract the actual command (before pipes, semicolons, &&, etc.)\n  // This prevents false positives from strings containing \"mkdir\"\n  const actualCommand = command.split(/[|;&]/)[0].trim();\n\n  // Check if this is actually a mkdir command (not just containing \"mkdir\" in a string)\n  if (!actualCommand.match(/^\\s*(sudo\\s+)?mkdir\\b/)) {\n    return paths;\n  }\n\n  // Remove mkdir and common flags\n  const remainder = command\n    .replace(/^.*mkdir\\s+/, '')\n    .replace(/-[pv]+\\s+/g, '');\n\n  // Extract all path arguments (space-separated)\n  // Handle quoted paths\n  const pathMatches = remainder.match(/(?:\"([^\"]+)\"|'([^']+)'|(\\S+))/g);\n\n  if (pathMatches) {\n    for (const match of pathMatches) {\n      // Remove quotes if present\n      const cleanPath = match.replace(/^[\"']|[\"']$/g, '');\n      // Skip flags\n      if (!cleanPath.startsWith('-')) {\n        paths.push(cleanPath);\n      }\n    }\n  }\n\n  return paths;\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Bash mkdir operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Bash tool\n  if (input.tool_name !== 'Bash') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-mkdir', true);\n\n  try {\n    const toolInput = input.tool_input as { command?: string };\n    const command = toolInput.command;\n\n    if (!command) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Extract mkdir paths from command\n    const mkdirPaths = extractMkdirPaths(command);\n\n    if (mkdirPaths.length === 0) {\n      // Not a mkdir command - don't log anything, just allow\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Only log input for actual mkdir commands\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n      command,\n      mkdirPaths,\n    });\n\n    await logger.logOutput({\n      command,\n      mkdirPaths,\n    });\n\n    const allErrors: string[] = [];\n\n    // Validate each directory path\n    for (const dirPath of mkdirPaths) {\n      // Resolve to absolute path\n      const absolutePath = path.isAbsolute(dirPath)\n        ? dirPath\n        : path.resolve(input.cwd, dirPath);\n\n      const parentDir = path.dirname(absolutePath);\n      const folderName = path.basename(absolutePath);\n\n      await logger.logOutput({\n        dirPath,\n        absolutePath,\n        parentDir,\n        folderName,\n      });\n\n      // Check if directory already exists\n      try {\n        await fs.access(absolutePath);\n        // Directory exists, no need to validate\n        await logger.logOutput({\n          dirPath,\n          status: 'exists',\n        });\n        continue;\n      } catch {\n        // Directory doesn't exist, proceed with validation\n      }\n\n      // Validate the directory is allowed in parent's subfolder spec\n      const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n      if (parentClaudeMd) {\n        const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n        const { data: parentData } = matter(parentContent);\n        const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n        await logger.logOutput({\n          check: 'parent-subfolder-validation',\n          dirPath,\n          parentClaudeMd,\n          parentFrontmatter,\n        });\n\n        if (parentFrontmatter.folder?.subfolders) {\n          const validation = validateAgainstSpec(\n            folderName,\n            parentFrontmatter.folder.subfolders,\n            'Folder'\n          );\n\n          if (!validation.valid) {\n            allErrors.push(\n              `Cannot create directory \"${folderName}\" in \"${parentDir}\":\\n` +\n                validation.errors.map(e => `  - ${e}`).join('\\n') +\n                `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n            );\n          }\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `Folder structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `Folder structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/validate-folder-structure-write.ts": "/**\n * PreToolUse Hook - Validate Folder Structure (Write)\n *\n * This hook fires before Write operations to validate file creation against\n * CLAUDE.md folder specifications. Validates both:\n * 1. File is in an allowed subdirectory (checks parent's subfolder spec)\n * 2. File matches allowed patterns in its immediate directory (checks files spec)\n *\n * Checks CLAUDE.md for folder specifications:\n * - folder.subfolders: Controls what subdirectories can exist\n * - folder.files: Controls what files can exist in the folder\n *\n * @module hooks/validate-folder-structure-write\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface ValidationSpec {\n  allowed?: string[];\n  required?: string[];\n  forbidden?: string[];\n}\n\ninterface FolderSpec {\n  subfolders?: ValidationSpec;\n  files?: ValidationSpec;\n}\n\ninterface ClaudeMdFrontmatter {\n  title?: string;\n  description?: string;\n  folder?: FolderSpec;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a string matches a gitignore-style pattern\n */\nfunction matchesGitignorePattern(value: string, pattern: string): boolean {\n  if (value === pattern) {\n    return true;\n  }\n\n  const regexPattern = pattern\n    .replace(/[.+^${}()|[\\]\\\\]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/\\?/g, '.');\n\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Find CLAUDE.md file in a specific directory\n */\nasync function findClaudeMdInDir(dirPath: string): Promise<string | null> {\n  const claudeMdPath = path.join(dirPath, 'CLAUDE.md');\n\n  try {\n    await fs.access(claudeMdPath);\n    return claudeMdPath;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Validate item against spec (files or folders)\n */\nfunction validateAgainstSpec(\n  itemName: string,\n  spec: ValidationSpec,\n  itemType: string\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check forbidden patterns\n  if (spec.forbidden) {\n    for (const forbiddenPattern of spec.forbidden) {\n      if (matchesGitignorePattern(itemName, forbiddenPattern)) {\n        errors.push(\n          `${itemType} \"${itemName}\" matches forbidden pattern \"${forbiddenPattern}\"`\n        );\n      }\n    }\n  }\n\n  // Check allowed patterns (if specified, item must match at least one)\n  if (spec.allowed && spec.allowed.length > 0) {\n    const isAllowed = spec.allowed.some(pattern =>\n      matchesGitignorePattern(itemName, pattern)\n    );\n\n    if (!isAllowed) {\n      errors.push(\n        `${itemType} \"${itemName}\" is not allowed. Allowed patterns: ${spec.allowed.join(', ')}`\n      );\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\n/**\n * PreToolUse hook handler for validating folder structure in Write operations\n */\nasync function handler(input: PreToolUseInput): Promise<PreToolUseHookOutput> {\n  // Only run for Write tool\n  if (input.tool_name !== 'Write') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-folder-structure-write', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    const toolInput = input.tool_input as { file_path?: string };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Resolve to absolute path\n    const absolutePath = path.isAbsolute(filePath)\n      ? filePath\n      : path.resolve(input.cwd, filePath);\n\n    const fileDir = path.dirname(absolutePath);\n    const fileName = path.basename(absolutePath);\n    const parentDir = path.dirname(fileDir);\n    const folderName = path.basename(fileDir);\n\n    await logger.logOutput({\n      filePath,\n      absolutePath,\n      fileDir,\n      fileName,\n      parentDir,\n      folderName,\n    });\n\n    const allErrors: string[] = [];\n\n    // Check 1: Validate the directory itself is allowed (check parent's subfolder spec)\n    const parentClaudeMd = await findClaudeMdInDir(parentDir);\n\n    if (parentClaudeMd) {\n      const parentContent = await fs.readFile(parentClaudeMd, 'utf-8');\n      const { data: parentData } = matter(parentContent);\n      const parentFrontmatter = parentData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'parent-subfolder-validation',\n        parentClaudeMd,\n        parentFrontmatter,\n      });\n\n      if (parentFrontmatter.folder?.subfolders) {\n        const validation = validateAgainstSpec(\n          folderName,\n          parentFrontmatter.folder.subfolders,\n          'Folder'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file in directory \"${folderName}\":\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nParent folder restrictions defined in: ${parentClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // Check 2: Validate the file itself is allowed (check directory's files spec)\n    const dirClaudeMd = await findClaudeMdInDir(fileDir);\n\n    if (dirClaudeMd) {\n      const dirContent = await fs.readFile(dirClaudeMd, 'utf-8');\n      const { data: dirData } = matter(dirContent);\n      const dirFrontmatter = dirData as ClaudeMdFrontmatter;\n\n      await logger.logOutput({\n        check: 'file-validation',\n        dirClaudeMd,\n        dirFrontmatter,\n      });\n\n      if (dirFrontmatter.folder?.files) {\n        const validation = validateAgainstSpec(\n          fileName,\n          dirFrontmatter.folder.files,\n          'File'\n        );\n\n        if (!validation.valid) {\n          allErrors.push(\n            `Cannot create file \"${fileName}\" in this directory:\\n` +\n              validation.errors.map(e => `  - ${e}`).join('\\n') +\n              `\\n\\nFile restrictions defined in: ${dirClaudeMd}`\n          );\n        }\n      }\n    }\n\n    // If any validations failed, deny the operation\n    if (allErrors.length > 0) {\n      const errorMessage = allErrors.join('\\n\\n');\n\n      await logger.logOutput({\n        valid: false,\n        errors: allErrors,\n      });\n\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'deny',\n          permissionDecisionReason:\n            `File structure validation failed:\\n\\n${errorMessage}\\n\\n` +\n            `Check the CLAUDE.md files for allowed patterns.`,\n        },\n      };\n    }\n\n    await logger.logOutput({ valid: true });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation but log a system message\n    return {\n      systemMessage: `File structure validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/shared/hooks/validate-rules-file.ts": "/**\n * PreToolUse Hook - Validate Rules File\n *\n * This hook fires before Write and Edit operations on rule files in .claude/rules\n * to validate that markdown-specific frontmatter is only used in .md-specific rules.\n *\n * Provides guidance:\n * - Warns if markdown frontmatter is used in non-.md rules\n * - Encourages markdown frontmatter in .md rules if not present\n * - Does NOT block operations - only provides context\n *\n * @module hooks/validate-rules-file\n */\n\nimport type { PreToolUseInput, PreToolUseHookOutput } from '../types/types.js';\nimport { createDebugLogger } from './utils/debug.js';\nimport { runHook } from './utils/io.js';\nimport * as path from 'path';\nimport matter from './utils/frontmatter.js';\n\ninterface MarkdownValidation {\n  headings?: unknown;\n  metadata?: unknown;\n}\n\ninterface RuleFrontmatter {\n  markdown?: MarkdownValidation;\n  [key: string]: unknown;\n}\n\n/**\n * Check if a rule filename indicates it applies to markdown files\n */\nfunction isMarkdownRule(filename: string): boolean {\n  const lowerFilename = filename.toLowerCase();\n\n  // Remove .md extension from rule filename for checking\n  const ruleName = lowerFilename.replace(/\\.md$/, '');\n\n  // Check if rule name suggests markdown files\n  return (\n    ruleName.includes('markdown') ||\n    ruleName.includes('.md') ||\n    ruleName === 'md' ||\n    ruleName.endsWith('-md')\n  );\n}\n\n/**\n * PreToolUse hook handler for validating rules files\n *\n * Validates that markdown frontmatter is appropriately used in rule files.\n * Provides guidance but does not block operations.\n *\n * @param input - PreToolUse hook input from Claude Code\n * @returns Hook output with guidance messages\n */\nasync function handler(\n  input: PreToolUseInput\n): Promise<PreToolUseHookOutput> {\n  // Only run for Write and Edit operations\n  if (input.tool_name !== 'Write' && input.tool_name !== 'Edit') {\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n\n  const logger = createDebugLogger(input.cwd, 'validate-rules-file', true);\n\n  try {\n    await logger.logInput({\n      tool_name: input.tool_name,\n      tool_use_id: input.tool_use_id,\n    });\n\n    // Get the file path and content from tool input\n    const toolInput = input.tool_input as {\n      file_path?: string;\n      content?: string;\n      old_string?: string;\n      new_string?: string;\n    };\n    const filePath = toolInput.file_path;\n\n    if (!filePath) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Check if this is a file in .claude/rules\n    const normalizedPath = path.normalize(filePath);\n    const isRuleFile = normalizedPath.includes(path.join('.claude', 'rules')) &&\n                       filePath.endsWith('.md');\n\n    if (!isRuleFile) {\n      await logger.logOutput({ message: 'Not a rule file, skipping' });\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Get content based on operation type\n    let content: string | undefined;\n\n    if (input.tool_name === 'Write') {\n      content = toolInput.content;\n    } else if (input.tool_name === 'Edit') {\n      // For Edit, we need the new content after the edit\n      // Since we can't easily reconstruct it, we'll just check the new_string portion\n      content = toolInput.new_string;\n    }\n\n    if (!content) {\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Parse frontmatter\n    let frontmatter: RuleFrontmatter;\n    try {\n      const { data } = matter(content);\n      frontmatter = data as RuleFrontmatter;\n    } catch {\n      // If we can't parse frontmatter, allow the operation\n      return {\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    const filename = path.basename(filePath);\n    const hasMarkdownFrontmatter = Boolean(frontmatter.markdown);\n    const isMdRule = isMarkdownRule(filename);\n\n    await logger.logOutput({\n      filename,\n      hasMarkdownFrontmatter,\n      isMdRule,\n    });\n\n    // Case 1: Has markdown frontmatter but doesn't apply to .md files\n    if (hasMarkdownFrontmatter && !isMdRule) {\n      const warningMessage =\n        `⚠️  Rule file \"${filename}\" contains markdown-specific frontmatter but doesn't appear to target .md files.\\n\\n` +\n        `The \\`markdown:\\` frontmatter is designed for validating markdown file structure (headings and metadata).\\n` +\n        `This rule's filename suggests it targets non-markdown files.\\n\\n` +\n        `Consider:\\n` +\n        `- Removing the \\`markdown:\\` frontmatter if this rule doesn't apply to .md files\\n` +\n        `- Renaming the rule to include \".md\" if it does target markdown files (e.g., \"*.md.md\")`;\n\n      await logger.logOutput({ warning: warningMessage });\n\n      return {\n        systemMessage: warningMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // Case 2: Applies to .md files but doesn't have markdown frontmatter\n    if (isMdRule && !hasMarkdownFrontmatter) {\n      const encouragementMessage =\n        `💡 Rule file \"${filename}\" appears to target markdown files but doesn't have \\`markdown:\\` frontmatter.\\n\\n` +\n        `You can add markdown validation by including a \\`markdown:\\` section in the frontmatter:\\n\\n` +\n        `\\`\\`\\`yaml\\n` +\n        `---\\n` +\n        `markdown:\\n` +\n        `  headings:\\n` +\n        `    allowed: [\"#*\", \"##*\", \"###*\"]  # Allow h1, h2, h3\\n` +\n        `    required: [\"# *\"]               # Require title heading\\n` +\n        `  frontmatter:\\n` +\n        `    allowed: [\"*\"]                  # Allow any frontmatter fields\\n` +\n        `    required: [\"title\"]             # Require title field\\n` +\n        `---\\n` +\n        `\\`\\`\\`\\n\\n` +\n        `This enables automatic validation of markdown structure and frontmatter fields.`;\n\n      await logger.logOutput({ encouragement: encouragementMessage });\n\n      return {\n        systemMessage: encouragementMessage,\n        hookSpecificOutput: {\n          hookEventName: 'PreToolUse',\n          permissionDecision: 'allow',\n        },\n      };\n    }\n\n    // All good - either has appropriate frontmatter or doesn't need guidance\n    await logger.logOutput({ status: 'valid' });\n\n    return {\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n\n  } catch (error: unknown) {\n    await logger.logError(error as Error);\n\n    // On error, allow the operation\n    return {\n      systemMessage: `Rules file validation hook failed: ${(error as Error).message || 'Unknown error'}`,\n      hookSpecificOutput: {\n        hookEventName: 'PreToolUse',\n        permissionDecision: 'allow',\n      },\n    };\n  }\n}\n\n// Export handler for testing\nexport { handler };\n\n// Make this file self-executable with tsx\nrunHook(handler);\n",
        "plugins/project-context/skills/feature-sliced-design/SKILL.md": "---\nname: Feature-Sliced Design\ndescription: This skill should be used when the user asks to \"implement FSD\", \"use Feature-Sliced Design\", \"organize architecture\", \"structure project folders\", \"set up FSD layers\", \"create feature slices\", \"refactor to FSD\", \"add FSD structure\", or mentions \"feature slices\", \"layered architecture\", \"FSD methodology\", \"architectural organization\", \"views layer\", \"entities layer\", \"shared layer\", \"Next.js with FSD\", or \"Turborepo FSD structure\". Provides comprehensive guidance for implementing Feature-Sliced Design methodology in Next.js applications with custom 'views' layer naming.\nversion: 0.1.0\n---\n\n# Feature-Sliced Design\n\n## Purpose\n\nFeature-Sliced Design (FSD) is an architectural methodology for organizing frontend applications into a standardized, scalable structure. It provides clear separation of concerns through a layered hierarchy that prevents circular dependencies and promotes maintainability.\n\n**Why use FSD:**\n- **Scalability**: Grows naturally as your application expands\n- **Maintainability**: Clear boundaries make refactoring safer\n- **Team collaboration**: Consistent structure enables parallel development\n- **Onboarding**: New developers understand architecture quickly\n\n**Custom 'views' layer:**\nThis skill uses 'views' instead of the standard FSD 'pages' layer to avoid confusion with Next.js App Router's `/app` directory. The `/app` directory handles routing only (minimal logic), while `/src/views` contains your actual page business logic.\n\n**Next.js integration:**\nFSD works seamlessly with Next.js App Router by separating routing concerns (in `/app`) from business logic (in `/src/views` and other FSD layers). This keeps your routing configuration clean while maintaining FSD's architectural benefits.\n\n## When to Use\n\nApply Feature-Sliced Design when:\n- Starting new Next.js projects that require clear architectural boundaries\n- Refactoring growing codebases that lack consistent structure\n- Working with multi-developer teams needing standardized organization\n- Building applications with complex business logic requiring separation of concerns\n- Developing Turborepo monorepo applications where each app needs independent FSD structure\n- Scaling applications where circular dependencies become problematic\n- Creating enterprise applications with long-term maintenance requirements\n\n## Core Principles\n\n### Layer Hierarchy\n\nFSD organizes code into **7 standardized layers** (from highest to lowest):\n\n1. **app** - Application initialization, global providers, routing configuration\n2. **processes** - Deprecated (functionality moved to features and app)\n3. **views** - Page-level business logic (custom naming, replaces standard 'pages')\n4. **widgets** - Large composite UI blocks that span multiple features\n5. **features** - User-facing interactions with business value\n6. **entities** - Business domain objects and models\n7. **shared** - Reusable utilities, UI kit, third-party integrations\n\n**Import rule:** A module can only import from layers **strictly below** it in the hierarchy.\n\n```\n┌─────────────────┐\n│      app        │  ← Can import from all layers below\n├─────────────────┤\n│     views       │  ← Can import: widgets, features, entities, shared\n├─────────────────┤\n│    widgets      │  ← Can import: features, entities, shared\n├─────────────────┤\n│    features     │  ← Can import: entities, shared\n├─────────────────┤\n│    entities     │  ← Can import: shared only\n├─────────────────┤\n│     shared      │  ← Cannot import from any FSD layer\n└─────────────────┘\n```\n\nThis hierarchy prevents circular dependencies and ensures clear architectural boundaries.\n\n### 'Views' vs 'Pages' Layer\n\n**Why 'views' instead of 'pages':**\n- Next.js uses `/app` directory for routing (App Router)\n- Standard FSD uses 'pages' layer for page business logic\n- Using 'views' eliminates confusion between routing (`/app`) and business logic (`/src/views`)\n\n**Separation of concerns:**\n- **`/app` directory (root level)**: Next.js routing only, minimal logic\n  - Contains `page.tsx`, `layout.tsx`, route groups\n  - Imports and renders from `/src/views`\n- **`/src/views` layer (FSD)**: Page business logic, component composition\n  - Contains view components, models, API calls\n  - Composes widgets, features, entities\n\nThis separation keeps routing configuration clean while maintaining FSD architectural principles.\n\n### Slices\n\n**Slices** are domain-based partitions within layers (except app and shared, which have no slices).\n\n**Examples:**\n- `views/dashboard` - Dashboard page slice\n- `widgets/header` - Header widget slice\n- `features/auth` - Authentication feature slice\n- `entities/user` - User entity slice\n\n**Public API pattern:**\nEach slice exports through `index.ts` to control its public interface:\n\n```typescript\n// src/features/auth/index.ts\nexport { LoginForm } from './ui/LoginForm';\nexport { useAuth } from './model/useAuth';\nexport type { AuthState } from './model/types';\n// Internal implementation details NOT exported\n```\n\nThis prevents deep imports and maintains encapsulation.\n\n### Segments\n\n**Segments** are purpose-based groupings within slices:\n\n- **ui/** - React components, visual elements\n- **model/** - Business logic, state management, TypeScript types\n- **api/** - API clients, data fetching, external integrations\n- **lib/** - Utility functions, helpers specific to the slice\n- **config/** - Configuration constants, feature flags\n\n**Example structure:**\n```\nfeatures/\n└── auth/\n    ├── ui/\n    │   ├── LoginForm.tsx\n    │   └── SignupForm.tsx\n    ├── model/\n    │   ├── useAuth.ts\n    │   └── types.ts\n    ├── api/\n    │   └── authApi.ts\n    └── index.ts\n```\n\n## FSD with Next.js App Router\n\n### Routing Architecture\n\nNext.js App Router uses `/app` directory for routing. FSD layers live in `/src` directory.\n\n**File organization:**\n```\nmy-nextjs-app/\n├── app/                          # Next.js routing (minimal logic)\n│   ├── layout.tsx               # Root layout\n│   ├── page.tsx                 # Home route\n│   ├── dashboard/\n│   │   └── page.tsx            # Dashboard route\n│   └── settings/\n│       └── page.tsx            # Settings route\n│\n├── src/                         # FSD layers\n│   └── views/                  # Page business logic\n│       ├── home/\n│       │   ├── ui/\n│       │   │   └── HomeView.tsx\n│       │   └── index.ts\n│       ├── dashboard/\n│       │   ├── ui/\n│       │   │   └── DashboardView.tsx\n│       │   ├── model/\n│       │   │   └── useDashboard.ts\n│       │   └── index.ts\n│       └── settings/\n│           ├── ui/\n│           │   └── SettingsView.tsx\n│           └── index.ts\n```\n\n**Routing pages import from views:**\n```typescript\n// app/dashboard/page.tsx - Routing only\nimport { DashboardView } from '@/views/dashboard';\n\nexport default function DashboardPage() {\n  return <DashboardView />;\n}\n\n// src/views/dashboard/ui/DashboardView.tsx - Business logic\nimport { Header } from '@/widgets/header';\nimport { StatsCard } from '@/features/analytics';\n\nexport function DashboardView() {\n  return (\n    <div>\n      <Header />\n      <StatsCard />\n    </div>\n  );\n}\n```\n\n### Standalone Next.js Structure\n\nComplete FSD structure for a standalone Next.js application:\n\n```\nmy-nextjs-app/\n├── app/                          # Next.js App Router\n│   ├── layout.tsx               # Root layout\n│   ├── page.tsx                 # Home route\n│   ├── (auth)/                  # Route group\n│   │   ├── login/\n│   │   │   └── page.tsx\n│   │   └── signup/\n│   │       └── page.tsx\n│   ├── dashboard/\n│   │   └── page.tsx\n│   ├── api/                     # API routes\n│   │   └── users/\n│   │       └── route.ts\n│   └── not-found.tsx\n│\n├── src/\n│   ├── app/                     # App layer (no slices)\n│   │   ├── providers/\n│   │   │   ├── AuthProvider.tsx\n│   │   │   └── QueryProvider.tsx\n│   │   ├── styles/\n│   │   │   └── globals.css\n│   │   └── config/\n│   │       └── constants.ts\n│   │\n│   ├── views/                   # Views layer (page logic)\n│   │   ├── home/\n│   │   ├── dashboard/\n│   │   ├── login/\n│   │   └── signup/\n│   │\n│   ├── widgets/                 # Widgets layer\n│   │   ├── header/\n│   │   ├── sidebar/\n│   │   ├── footer/\n│   │   └── notification-panel/\n│   │\n│   ├── features/                # Features layer\n│   │   ├── auth/\n│   │   ├── search/\n│   │   ├── theme-toggle/\n│   │   └── user-profile/\n│   │\n│   ├── entities/                # Entities layer\n│   │   ├── user/\n│   │   ├── post/\n│   │   ├── comment/\n│   │   └── session/\n│   │\n│   └── shared/                  # Shared layer (no slices)\n│       ├── ui/                  # UI components\n│       │   ├── button/\n│       │   ├── input/\n│       │   └── card/\n│       ├── lib/                 # Utilities\n│       │   ├── format.ts\n│       │   └── validation.ts\n│       ├── api/                 # API client\n│       │   └── client.ts\n│       └── config/\n│           └── env.ts\n│\n├── public/\n│   ├── images/\n│   └── fonts/\n│\n└── package.json\n```\n\n### Turborepo Monorepo Structure\n\nFSD structure within a Turborepo monorepo where each app has independent FSD organization:\n\n```\nturborepo-root/\n├── apps/\n│   ├── web/                     # Consumer-facing app\n│   │   ├── app/                # Next.js routing\n│   │   │   ├── layout.tsx\n│   │   │   ├── page.tsx\n│   │   │   └── shop/\n│   │   │       └── page.tsx\n│   │   ├── src/                # Independent FSD structure\n│   │   │   ├── app/\n│   │   │   ├── views/\n│   │   │   │   ├── home/\n│   │   │   │   └── shop/\n│   │   │   ├── widgets/\n│   │   │   │   ├── product-grid/\n│   │   │   │   └── shopping-cart/\n│   │   │   ├── features/\n│   │   │   │   ├── add-to-cart/\n│   │   │   │   └── checkout/\n│   │   │   ├── entities/\n│   │   │   │   ├── product/\n│   │   │   │   └── order/\n│   │   │   └── shared/\n│   │   └── package.json\n│   │\n│   └── admin/                   # Admin dashboard app\n│       ├── app/                # Next.js routing\n│       │   ├── layout.tsx\n│       │   ├── page.tsx\n│       │   └── products/\n│       │       └── page.tsx\n│       ├── src/                # Independent FSD structure\n│       │   ├── app/\n│       │   ├── views/\n│       │   │   ├── dashboard/\n│       │   │   └── products/\n│       │   ├── widgets/\n│       │   │   ├── admin-header/\n│       │   │   └── stats-panel/\n│       │   ├── features/\n│       │   │   ├── product-editor/\n│       │   │   └── user-management/\n│       │   ├── entities/\n│       │   │   ├── product/\n│       │   │   └── admin/\n│       │   └── shared/\n│       └── package.json\n│\n├── packages/                    # Optional shared packages\n│   ├── ui/                     # Shared UI components (can mirror shared/ui)\n│   │   ├── button/\n│   │   └── input/\n│   ├── utils/                  # Shared utilities\n│   │   └── validation.ts\n│   └── types/                  # Shared TypeScript types\n│       └── common.ts\n│\n├── turbo.json\n└── package.json\n```\n\n**Key Turborepo principles:**\n- Each app (`web`, `admin`) has its own complete FSD structure\n- Apps are independent - no cross-app imports from FSD layers\n- Shared code goes in `packages/` directory (optional)\n- Use `workspace:*` protocol for package dependencies\n\n## Layer Definitions\n\n### app Layer\n\n**Purpose:** Application-wide setup, initialization, and global configuration.\n\n**Responsibilities:**\n- Global providers (theme, auth, query client)\n- Root styles and CSS imports\n- Application-level configuration\n- Error boundaries\n\n**Import rules:** Can import from all layers below (views, widgets, features, entities, shared).\n\n**No slices:** The app layer contains segments directly (providers/, styles/, config/).\n\n**Example:**\n```typescript\n// src/app/providers/Providers.tsx\n'use client';\n\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { queryClient } from '@/shared/api/queryClient';\nimport { AuthProvider } from '@/features/auth';\n\nexport function Providers({ children }: { children: React.ReactNode }) {\n  return (\n    <QueryClientProvider client={queryClient}>\n      <AuthProvider>\n        {children}\n      </AuthProvider>\n    </QueryClientProvider>\n  );\n}\n\n// app/layout.tsx\nimport { Providers } from '@/app/providers/Providers';\nimport '@/app/styles/globals.css';\n\nexport default function RootLayout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\">\n      <body>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}\n```\n\n### views Layer\n\n**Purpose:** Page-level business logic and component composition.\n\n**Responsibilities:**\n- Compose widgets, features, and entities into complete pages\n- Page-specific state management\n- Data fetching for the page\n- SEO metadata\n\n**Import rules:** Can import from widgets, features, entities, shared.\n\n**Has slices:** Each page gets its own slice (e.g., `views/dashboard`, `views/settings`).\n\n**Example:**\n```typescript\n// src/views/dashboard/ui/DashboardView.tsx\nimport { Header } from '@/widgets/header';\nimport { Sidebar } from '@/widgets/sidebar';\nimport { StatsCard } from '@/features/analytics';\nimport { RecentActivity } from '@/features/activity';\nimport { User } from '@/entities/user';\n\ninterface DashboardViewProps {\n  user: User;\n}\n\nexport function DashboardView({ user }: DashboardViewProps) {\n  return (\n    <div className=\"dashboard\">\n      <Header user={user} />\n      <div className=\"dashboard-content\">\n        <Sidebar />\n        <main>\n          <StatsCard userId={user.id} />\n          <RecentActivity userId={user.id} />\n        </main>\n      </div>\n    </div>\n  );\n}\n\n// src/views/dashboard/index.ts\nexport { DashboardView } from './ui/DashboardView';\n\n// app/dashboard/page.tsx\nimport { DashboardView } from '@/views/dashboard';\nimport { getCurrentUser } from '@/entities/user';\n\nexport default async function DashboardPage() {\n  const user = await getCurrentUser();\n  return <DashboardView user={user} />;\n}\n```\n\n### widgets Layer\n\n**Purpose:** Large, self-contained composite UI blocks that combine multiple features.\n\n**Responsibilities:**\n- Reusable across multiple pages\n- Compose multiple features together\n- Complex UI layouts (headers, sidebars, footers)\n- Navigation components\n\n**Import rules:** Can import from features, entities, shared.\n\n**Has slices:** Each widget gets its own slice (e.g., `widgets/header`, `widgets/sidebar`).\n\n**Example:**\n```typescript\n// src/widgets/header/ui/Header.tsx\nimport { SearchBar } from '@/features/search';\nimport { UserMenu } from '@/features/user-menu';\nimport { NotificationBell } from '@/features/notifications';\nimport { User } from '@/entities/user';\nimport { Logo } from '@/shared/ui/logo';\n\ninterface HeaderProps {\n  user: User;\n}\n\nexport function Header({ user }: HeaderProps) {\n  return (\n    <header className=\"header\">\n      <Logo />\n      <SearchBar />\n      <div className=\"header-actions\">\n        <NotificationBell userId={user.id} />\n        <UserMenu user={user} />\n      </div>\n    </header>\n  );\n}\n\n// src/widgets/header/index.ts\nexport { Header } from './ui/Header';\n```\n\n### features Layer\n\n**Purpose:** User-facing interactions and business logic with clear business value.\n\n**Responsibilities:**\n- Specific user actions (login, add to cart, like post)\n- Feature-specific state management\n- Business logic and validation\n- API interactions for the feature\n\n**Import rules:** Can import from entities, shared.\n\n**Has slices:** Each feature gets its own slice (e.g., `features/auth`, `features/search`).\n\n**Example:**\n```typescript\n// src/features/auth/model/types.ts\nexport interface LoginCredentials {\n  email: string;\n  password: string;\n}\n\n// src/features/auth/api/login.ts\nimport { User } from '@/entities/user';\nimport { apiClient } from '@/shared/api/client';\nimport type { LoginCredentials } from '../model/types';\n\nexport async function login(credentials: LoginCredentials): Promise<User> {\n  const response = await apiClient.post('/auth/login', credentials);\n  return response.data;\n}\n\n// src/features/auth/ui/LoginForm.tsx\n'use client';\n\nimport { useState } from 'react';\nimport { login } from '../api/login';\nimport { Button } from '@/shared/ui/button';\nimport { Input } from '@/shared/ui/input';\n\nexport function LoginForm() {\n  const [email, setEmail] = useState('');\n  const [password, setPassword] = useState('');\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n    await login({ email, password });\n  };\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <Input\n        type=\"email\"\n        value={email}\n        onChange={(e) => setEmail(e.target.value)}\n        placeholder=\"Email\"\n      />\n      <Input\n        type=\"password\"\n        value={password}\n        onChange={(e) => setPassword(e.target.value)}\n        placeholder=\"Password\"\n      />\n      <Button type=\"submit\">Login</Button>\n    </form>\n  );\n}\n\n// src/features/auth/index.ts\nexport { LoginForm } from './ui/LoginForm';\nexport { login } from './api/login';\nexport type { LoginCredentials } from './model/types';\n```\n\n### entities Layer\n\n**Purpose:** Business domain objects and core data models.\n\n**Responsibilities:**\n- Data structures representing business concepts\n- Entity-specific utilities\n- Base API operations (CRUD)\n- Type definitions\n\n**Import rules:** Can import from shared only.\n\n**Has slices:** Each entity gets its own slice (e.g., `entities/user`, `entities/post`).\n\n**Example:**\n```typescript\n// src/entities/user/model/types.ts\nexport interface User {\n  id: string;\n  name: string;\n  email: string;\n  avatar?: string;\n  role: 'admin' | 'user';\n}\n\n// src/entities/user/api/getUser.ts\nimport { apiClient } from '@/shared/api/client';\nimport type { User } from '../model/types';\n\nexport async function getUser(id: string): Promise<User> {\n  const response = await apiClient.get(`/users/${id}`);\n  return response.data;\n}\n\nexport async function getCurrentUser(): Promise<User> {\n  const response = await apiClient.get('/users/me');\n  return response.data;\n}\n\n// src/entities/user/ui/UserCard.tsx\nimport type { User } from '../model/types';\nimport { Avatar } from '@/shared/ui/avatar';\n\ninterface UserCardProps {\n  user: User;\n}\n\nexport function UserCard({ user }: UserCardProps) {\n  return (\n    <div className=\"user-card\">\n      <Avatar src={user.avatar} alt={user.name} />\n      <div>\n        <h3>{user.name}</h3>\n        <p>{user.email}</p>\n      </div>\n    </div>\n  );\n}\n\n// src/entities/user/index.ts\nexport { UserCard } from './ui/UserCard';\nexport { getUser, getCurrentUser } from './api/getUser';\nexport type { User } from './model/types';\n```\n\n### shared Layer\n\n**Purpose:** Reusable utilities, UI components, and third-party integrations.\n\n**Responsibilities:**\n- UI kit (button, input, card components)\n- Helper functions (formatters, validators)\n- API client configuration\n- Constants and environment variables\n- Third-party library integrations\n\n**Import rules:** Cannot import from any FSD layer (only external packages).\n\n**No slices:** Contains segments directly (ui/, lib/, api/, config/).\n\n**Example:**\n```typescript\n// src/shared/ui/button/Button.tsx\nimport { type ButtonHTMLAttributes } from 'react';\n\ninterface ButtonProps extends ButtonHTMLAttributes<HTMLButtonElement> {\n  variant?: 'primary' | 'secondary' | 'ghost';\n  size?: 'sm' | 'md' | 'lg';\n}\n\nexport function Button({\n  variant = 'primary',\n  size = 'md',\n  className,\n  children,\n  ...props\n}: ButtonProps) {\n  return (\n    <button\n      className={`button button--${variant} button--${size} ${className}`}\n      {...props}\n    >\n      {children}\n    </button>\n  );\n}\n\n// src/shared/lib/format.ts\nexport function formatDate(date: Date): string {\n  return new Intl.DateTimeFormat('en-US').format(date);\n}\n\nexport function formatCurrency(amount: number): string {\n  return new Intl.NumberFormat('en-US', {\n    style: 'currency',\n    currency: 'USD',\n  }).format(amount);\n}\n\n// src/shared/api/client.ts\nimport axios from 'axios';\n\nexport const apiClient = axios.create({\n  baseURL: process.env.NEXT_PUBLIC_API_URL,\n  headers: {\n    'Content-Type': 'application/json',\n  },\n});\n\n// src/shared/config/env.ts\nexport const env = {\n  apiUrl: process.env.NEXT_PUBLIC_API_URL!,\n  nodeEnv: process.env.NODE_ENV,\n} as const;\n```\n\n## Workflow\n\n### Step 1: Set Up Layer Directories\n\nCreate the FSD folder structure:\n\n```bash\nmkdir -p src/{app,views,widgets,features,entities,shared}\nmkdir -p src/app/{providers,styles,config}\nmkdir -p src/shared/{ui,lib,api,config}\n```\n\n### Step 2: Create First Entity\n\nStart with entities (bottom layer). Define your core business models:\n\n```typescript\n// src/entities/user/model/types.ts\nexport interface User {\n  id: string;\n  name: string;\n  email: string;\n}\n\n// src/entities/user/api/getUser.ts\nexport async function getUser(id: string): Promise<User> {\n  // API implementation\n}\n\n// src/entities/user/index.ts\nexport type { User } from './model/types';\nexport { getUser } from './api/getUser';\n```\n\n### Step 3: Build Features Using Entities\n\nCreate features that use entities:\n\n```typescript\n// src/features/user-profile/ui/UserProfile.tsx\nimport { User } from '@/entities/user'; // ✅ Feature imports entity\n\nexport function UserProfile({ user }: { user: User }) {\n  return <div>{user.name}</div>;\n}\n\n// src/features/user-profile/index.ts\nexport { UserProfile } from './ui/UserProfile';\n```\n\n### Step 4: Compose Widgets from Features\n\nBuild composite widgets:\n\n```typescript\n// src/widgets/header/ui/Header.tsx\nimport { UserProfile } from '@/features/user-profile'; // ✅ Widget imports feature\nimport { SearchBar } from '@/features/search';\n\nexport function Header({ user }) {\n  return (\n    <header>\n      <SearchBar />\n      <UserProfile user={user} />\n    </header>\n  );\n}\n```\n\n### Step 5: Assemble Views\n\nCreate page-level views:\n\n```typescript\n// src/views/dashboard/ui/DashboardView.tsx\nimport { Header } from '@/widgets/header'; // ✅ View imports widget\n\nexport function DashboardView() {\n  return (\n    <div>\n      <Header />\n      {/* More content */}\n    </div>\n  );\n}\n\n// src/views/dashboard/index.ts\nexport { DashboardView } from './ui/DashboardView';\n```\n\n### Step 6: Connect to App Router\n\nWire views to Next.js routing:\n\n```typescript\n// app/dashboard/page.tsx\nimport { DashboardView } from '@/views/dashboard';\n\nexport default function DashboardPage() {\n  return <DashboardView />;\n}\n```\n\n## Import Rules and Dependencies\n\n### Allowed Import Patterns\n\n```typescript\n// ✅ Layer importing from layer below\nimport { User } from '@/entities/user';          // Feature → Entity\nimport { LoginForm } from '@/features/auth';     // Widget → Feature\nimport { Header } from '@/widgets/header';       // View → Widget\n\n// ✅ Any layer importing from shared\nimport { Button } from '@/shared/ui/button';\nimport { formatDate } from '@/shared/lib/format';\n\n// ✅ Slice importing from different slice in lower layer\nimport { User } from '@/entities/user';          // features/auth → entities/user\nimport { Post } from '@/entities/post';          // features/like → entities/post\n```\n\n### Forbidden Import Patterns\n\n```typescript\n// ❌ Layer importing from same or higher layer\nimport { DashboardView } from '@/views/dashboard';  // Feature → View (upward)\nimport { Header } from '@/widgets/header';          // Feature → Widget (upward)\nimport { LoginForm } from '@/features/login';       // features/auth → features/login (same layer)\n\n// ❌ Cross-slice imports within same layer\nimport { SearchBar } from '@/features/search';      // features/auth → features/search\n\n// ❌ Shared importing from FSD layers\nimport { User } from '@/entities/user';             // shared/lib → entities/user\n```\n\n### Valid vs Invalid Examples\n\n**Invalid (cross-feature import):**\n```typescript\n// ❌ src/features/search/ui/SearchBar.tsx\nimport { LoginForm } from '@/features/auth'; // Same layer import\n```\n\n**Valid (extract to widget):**\n```typescript\n// ✅ src/widgets/navbar/ui/Navbar.tsx\nimport { SearchBar } from '@/features/search';\nimport { LoginForm } from '@/features/auth';\n\nexport function Navbar() {\n  return (\n    <nav>\n      <SearchBar />\n      <LoginForm />\n    </nav>\n  );\n}\n```\n\n### Fixing Circular Dependencies\n\n**Problem:**\n```typescript\n// features/auth imports features/user-settings\n// features/user-settings imports features/auth\n// ❌ Circular dependency\n```\n\n**Solution 1: Extract to entity**\n```typescript\n// Move shared logic to entities/user\n// Both features import from entities/user\n// ✅ No circular dependency\n```\n\n**Solution 2: Extract to widget**\n```typescript\n// Create widgets/user-panel that imports both features\n// ✅ Widget layer can import from features\n```\n\n### Public API Enforcement\n\nAlways use `index.ts` to control exports:\n\n```typescript\n// src/features/auth/index.ts\nexport { LoginForm } from './ui/LoginForm';\nexport { useAuth } from './model/useAuth';\nexport type { AuthState } from './model/types';\n\n// ❌ Do NOT export internal helpers\n// export { validatePassword } from './lib/validation'; // Keep internal\n```\n\nImport from public API only:\n\n```typescript\n// ✅ Correct\nimport { LoginForm } from '@/features/auth';\n\n// ❌ Wrong (deep import)\nimport { LoginForm } from '@/features/auth/ui/LoginForm';\n```\n\n## Segment Patterns\n\n### ui/ Segment\n\n**Purpose:** React components and visual elements.\n\n**When to use:**\n- Any React component\n- UI composition\n- Visual presentation\n\n**Example:**\n```typescript\n// src/entities/user/ui/UserCard.tsx\nimport type { User } from '../model/types';\n\nexport function UserCard({ user }: { user: User }) {\n  return (\n    <div className=\"user-card\">\n      <h3>{user.name}</h3>\n      <p>{user.email}</p>\n    </div>\n  );\n}\n```\n\n### model/ Segment\n\n**Purpose:** Business logic, state management, and type definitions.\n\n**When to use:**\n- TypeScript interfaces and types\n- React hooks for state\n- Business logic functions\n- Data transformations\n\n**Example:**\n```typescript\n// src/features/auth/model/useAuth.ts\n'use client';\n\nimport { create } from 'zustand';\nimport type { User } from '@/entities/user';\n\ninterface AuthState {\n  user: User | null;\n  isAuthenticated: boolean;\n  login: (user: User) => void;\n  logout: () => void;\n}\n\nexport const useAuth = create<AuthState>((set) => ({\n  user: null,\n  isAuthenticated: false,\n  login: (user) => set({ user, isAuthenticated: true }),\n  logout: () => set({ user: null, isAuthenticated: false }),\n}));\n```\n\n### api/ Segment\n\n**Purpose:** API clients, data fetching, and external integrations.\n\n**When to use:**\n- HTTP requests\n- WebSocket connections\n- Third-party API integrations\n- Server actions (Next.js)\n\n**Example:**\n```typescript\n// src/entities/user/api/userApi.ts\n'use server';\n\nimport { apiClient } from '@/shared/api/client';\nimport type { User } from '../model/types';\n\nexport async function fetchUsers(): Promise<User[]> {\n  const response = await apiClient.get('/users');\n  return response.data;\n}\n\nexport async function createUser(data: Omit<User, 'id'>): Promise<User> {\n  const response = await apiClient.post('/users', data);\n  return response.data;\n}\n```\n\n### lib/ Segment\n\n**Purpose:** Utility functions and helpers specific to the slice.\n\n**When to use:**\n- Slice-specific utilities\n- Validation functions\n- Data transformation helpers\n\n**Example:**\n```typescript\n// src/features/auth/lib/validation.ts\nimport { z } from 'zod';\n\nexport const loginSchema = z.object({\n  email: z.string().email('Invalid email address'),\n  password: z.string().min(8, 'Password must be at least 8 characters'),\n});\n\nexport function validateLogin(data: unknown) {\n  return loginSchema.parse(data);\n}\n```\n\n### config/ Segment\n\n**Purpose:** Configuration constants and feature flags.\n\n**When to use:**\n- Feature-specific constants\n- Configuration objects\n- Feature flags\n\n**Example:**\n```typescript\n// src/app/config/theme.ts\nexport const theme = {\n  colors: {\n    primary: '#0070f3',\n    secondary: '#ff4081',\n  },\n  breakpoints: {\n    sm: '640px',\n    md: '768px',\n    lg: '1024px',\n  },\n} as const;\n```\n\n## Migration Strategy\n\n### Migrating Existing Next.js App to FSD\n\n**Bottom-up approach** (recommended):\n\n1. **Start with shared layer**\n   - Extract common UI components to `shared/ui/`\n   - Move utilities to `shared/lib/`\n   - Configure API client in `shared/api/`\n\n2. **Define entities**\n   - Identify business domain objects (User, Post, Comment)\n   - Create entity types in `entities/{name}/model/`\n   - Move CRUD operations to `entities/{name}/api/`\n\n3. **Extract features**\n   - Identify user interactions (login, search, like)\n   - Create feature slices in `features/{name}/`\n   - Use entities within features\n\n4. **Build widgets**\n   - Identify composite UI blocks (Header, Sidebar)\n   - Create widget slices in `widgets/{name}/`\n   - Compose features within widgets\n\n5. **Organize views**\n   - Move page logic from `/app` to `/src/views`\n   - Keep routing in `/app`, business logic in `/src/views`\n   - Compose widgets in views\n\n6. **Configure app layer**\n   - Move global providers to `app/providers/`\n   - Move global styles to `app/styles/`\n\n### Handling Existing Code\n\n**Incremental migration:**\n- Migrate one page at a time\n- Start with least complex pages\n- Use both old and new structure during transition\n- Update imports as you migrate\n\n**Testing throughout:**\n- Run tests after each layer migration\n- Ensure no functionality breaks\n- Verify import paths are correct\n\n## Best Practices\n\n**Keep slices isolated:**\n- No cross-slice imports within the same layer\n- Each slice should be independent\n- Extract shared logic to lower layers\n\n**Use Public API pattern:**\n- Always export through `index.ts`\n- Prevents deep imports\n- Makes refactoring easier\n\n**Colocate tests:**\n```\nfeatures/\n└── auth/\n    ├── ui/\n    │   ├── LoginForm.tsx\n    │   └── LoginForm.test.tsx  # Test next to implementation\n    └── index.ts\n```\n\n**Avoid \"god slices\":**\n- Keep slices focused on single responsibility\n- Split large slices into multiple smaller ones\n- Extract common logic to shared layer\n\n**Name by domain, not tech:**\n- ✅ `features/product-search`\n- ❌ `features/search-bar-component`\n\n**Use TypeScript strict mode:**\n```json\n{\n  \"compilerOptions\": {\n    \"strict\": true\n  }\n}\n```\n\n**Document architecture decisions:**\n- Keep ADR (Architecture Decision Records)\n- Document why certain slices exist\n- Explain layer boundary decisions\n\n## Common Patterns\n\n### Shared UI Components\n\n```typescript\n// src/shared/ui/button/Button.tsx\nexport function Button({ children, ...props }) {\n  return <button {...props}>{children}</button>;\n}\n\n// Usage in feature\nimport { Button } from '@/shared/ui/button';\n```\n\n### API Client Setup\n\n```typescript\n// src/shared/api/client.ts\nimport axios from 'axios';\n\nexport const apiClient = axios.create({\n  baseURL: process.env.NEXT_PUBLIC_API_URL,\n});\n\n// Usage in entity\nimport { apiClient } from '@/shared/api/client';\n```\n\n### Form Handling with Features\n\n```typescript\n// src/features/product-form/ui/ProductForm.tsx\n'use client';\n\nimport { useForm } from 'react-hook-form';\nimport { zodResolver } from '@hookform/resolvers/zod';\nimport { productSchema } from '../lib/validation';\nimport { createProduct } from '../api/createProduct';\n\nexport function ProductForm() {\n  const { register, handleSubmit } = useForm({\n    resolver: zodResolver(productSchema),\n  });\n\n  return <form onSubmit={handleSubmit(createProduct)}>...</form>;\n}\n```\n\n### Authentication Integration\n\n```typescript\n// src/features/auth/model/useAuth.ts\nexport const useAuth = create<AuthState>((set) => ({...}));\n\n// src/widgets/header/ui/Header.tsx\nimport { useAuth } from '@/features/auth';\n\nexport function Header() {\n  const { user } = useAuth();\n  return <header>Welcome, {user?.name}</header>;\n}\n```\n\n### Data Fetching with Server Components\n\n```typescript\n// app/dashboard/page.tsx\nimport { DashboardView } from '@/views/dashboard';\nimport { getUser } from '@/entities/user';\n\nexport default async function DashboardPage() {\n  const user = await getUser('current');\n  return <DashboardView user={user} />;\n}\n\n// src/views/dashboard/ui/DashboardView.tsx\nimport type { User } from '@/entities/user';\n\nexport function DashboardView({ user }: { user: User }) {\n  return <div>Welcome, {user.name}</div>;\n}\n```\n\n## Troubleshooting\n\n### Circular Dependencies\n\n**Problem:** Two slices import from each other.\n\n**Solution:**\n1. Extract shared logic to a lower layer (usually entities or shared)\n2. Create a higher layer (widget) that imports both\n3. Review if one slice should actually be split into multiple slices\n\n### Import Path Issues\n\n**Problem:** TypeScript cannot resolve `@/` imports.\n\n**Solution:** Configure path aliases in `tsconfig.json`:\n```json\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/app/*\": [\"src/app/*\"],\n      \"@/views/*\": [\"src/views/*\"],\n      \"@/widgets/*\": [\"src/widgets/*\"],\n      \"@/features/*\": [\"src/features/*\"],\n      \"@/entities/*\": [\"src/entities/*\"],\n      \"@/shared/*\": [\"src/shared/*\"]\n    }\n  }\n}\n```\n\n### Build Errors\n\n**Problem:** Next.js cannot find modules after restructuring.\n\n**Solution:**\n1. Clear `.next` directory: `rm -rf .next`\n2. Reinstall dependencies: `npm install`\n3. Restart dev server: `npm run dev`\n\n## Configuration\n\n### TypeScript Path Aliases\n\n```json\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/app/*\": [\"src/app/*\"],\n      \"@/views/*\": [\"src/views/*\"],\n      \"@/widgets/*\": [\"src/widgets/*\"],\n      \"@/features/*\": [\"src/features/*\"],\n      \"@/entities/*\": [\"src/entities/*\"],\n      \"@/shared/*\": [\"src/shared/*\"]\n    }\n  },\n  \"include\": [\"src\", \"app\"]\n}\n```\n\n### ESLint Import Rules (Optional)\n\n```javascript\n// .eslintrc.js\nmodule.exports = {\n  rules: {\n    'no-restricted-imports': [\n      'error',\n      {\n        patterns: [\n          {\n            group: ['@/views/*', '@/widgets/*'],\n            message: 'Features cannot import from views or widgets',\n          },\n        ],\n      },\n    ],\n  },\n};\n```\n\n## References\n\n- [Official FSD Documentation](https://feature-sliced.design/) - Complete methodology guide\n- [FSD with Next.js Guide](https://feature-sliced.design/docs/guides/tech/with-nextjs) - Next.js integration patterns\n- [FSD GitHub Repository](https://github.com/feature-sliced/documentation) - Source documentation\n- [Frontend Monorepo Architecture](https://feature-sliced.design/blog/frontend-monorepo-explained) - Turborepo and FSD\n- [FSD Tutorial](https://feature-sliced.design/docs/get-started/tutorial) - Step-by-step implementation guide\n- [FSD Examples](https://github.com/feature-sliced/examples) - Real-world applications using FSD\n"
      },
      "plugins": [
        {
          "name": "essential-logging",
          "description": "Core task execution logging and transcript utilities for all Claude Code sessions",
          "version": "0.1.0",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/essential-logging",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install essential-logging@constellos-local"
          ]
        },
        {
          "name": "github-orchestration",
          "description": "GitHub workflow orchestration with branch context, commit enhancement, and CI management",
          "version": "0.2.0",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/github-orchestration",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install github-orchestration@constellos-local"
          ]
        },
        {
          "name": "nextjs-supabase-ai-sdk-dev",
          "description": "Next.js, Supabase, and AI SDK development utilities",
          "version": "0.1.3",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/nextjs-supabase-ai-sdk-dev",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install nextjs-supabase-ai-sdk-dev@constellos-local"
          ]
        },
        {
          "name": "project-context",
          "description": "Project context discovery, markdown-friendly documentation, and maintenance for Claude Code",
          "version": "0.1.1",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/project-context",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install project-context@constellos-local"
          ]
        },
        {
          "name": "nodes-md-integration",
          "description": "Integration plugin for nodes-md with interactive plugin debugging command",
          "version": "0.1.0",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/nodes-md-integration",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install nodes-md-integration@constellos-local"
          ]
        },
        {
          "name": "cloudflare-mcp-server-dev",
          "description": "Cloudflare Workers development with MCP servers for bindings, builds, observability, containers, and browser rendering",
          "version": "0.1.0",
          "author": {
            "name": "constellos"
          },
          "source": "./plugins/cloudflare-mcp-server-dev",
          "strict": false,
          "categories": [],
          "install_commands": [
            "/plugin marketplace add constellos/claude-code-plugins",
            "/plugin install cloudflare-mcp-server-dev@constellos-local"
          ]
        }
      ]
    }
  ]
}