{
  "author": {
    "id": "mmaaz-git",
    "display_name": "Maaz",
    "avatar_url": "https://avatars.githubusercontent.com/u/76714503?v=4"
  },
  "marketplaces": [
    {
      "name": "agentic-pbt",
      "version": null,
      "description": "Hypothesis property-based testing plugin",
      "repo_full_name": "mmaaz-git/agentic-pbt",
      "repo_url": "https://github.com/mmaaz-git/agentic-pbt",
      "repo_description": null,
      "signals": {
        "stars": 25,
        "forks": 3,
        "pushed_at": "2025-11-03T19:19:54Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"agentic-pbt\",\n  \"owner\": {\n    \"name\": \"Muhammad Maaz\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"hypo-plugin\",\n      \"source\": \"./hypo-plugin\",\n      \"description\": \"Hypothesis property-based testing plugin\"\n    }\n  ]\n}\n",
        "README.md": "# Agentic Property-Based Testing\n\nGet a coding agent to find bugs in your codebase by mining *properties* and testing them via *Hypothesis*.\n\nFor the artifacts from the [paper](https://arxiv.org/abs/2510.09907), including bug reports and rankings, see the `paper` directory. Note that the code that was used in the paper is slightly behind what is in the main folder. See `paper/README.md` for more details.\n\nTo see all the bugs our agent found, see our [website](https://mmaaz-git.github.io/agentic-pbt-site).\n\nTo read the blog post on the Hypothesis website, see [here](https://hypothesis.works/articles/claude-code-plugin/).\n\n## Running the agent\n\nThe agent is a Claude Code command. You will need to have Claude Code [installed](https://docs.anthropic.com/en/docs/claude-code/install-claude-code) to run it. You will need a subscription to Claude Code, or an API key (we recommend an API key if you are running it over a large number of packages, or to reproduce the paper).\n\nThe command is contained in the `hypo.md` file. You will need to place this file in the `.claude/commands/` directory, which can either be in `~` or in whichever directory you are running the agent from. The agent can then be invoked with `/hypo <target>`.\n\nYou will need `pytest`, `hypothesis`, and the package you are testing installed.\n\nThe agent takes one argument, which is the target to test. This can be a file, a function, or a module. If no argument is given, it will test the entire codebase, i.e., the current working directory. You can pass whichever other arguments that Claude Code supports, like the model, permissions, etc.\n\nExample usage:\n\n```bash\nclaude \"/hypo numpy\"\nclaude \"/hypo statistics.median\" --model opus\n```\n\nYou can also just start Claude Code, and then invoke the agent.\n\n## Agent runner\n\nThe `run.py` script is a wrapper around the agent to test multiple packages, in parallel. It is what was used in the paper. This script does not require any other requirements beyond the standard library (of course, you still need to have Claude Code installed). You need `python3` and `pip` to be in your `PATH`.\n\nNote that the runner operates at the *module* level.\n\nThe only required argument is the path to a json file containing the packages to test, and which modules to test within each package. It looks like:\n\n```json\n{\n    \"pathlib\": {\n        \"type\": \"stdlib\",\n        \"modules\": [\"pathlib\"]\n    },\n    \"numpy\": {\n        \"type\": \"pypi\",\n        \"modules\": [\"numpy\"]\n    }\n}\n```\n\nThe keys in the json file are the package names, either the standard library name or the PyPI name. For standard library packages, specify \"stdlib\", and for PyPI packages, specify \"pypi\". This is important so the runner knows how to set up the virtual environment.\n\nThe runner takes two optional arguments:\n- `--max-workers`: the number of parallel workers to use. Default is 20.\n- `--model`: the model to use. Default is \"opus\".\n- `--preinstall-workers`: the number of parallel workers to use for setting up the virtual environments. Default is 10.\n\nThe runner will output all bug reports in the `results/` directory.\n\nExample usage:\n\n```bash\npython run.py packages.json\n```\n\nIn the `example_packages/` directory, there are some example package json files to test:\n- `packages_mini.json`: a mini set of modules to test (this took 6 minutes to run, with default settings)\n- `packages_10k.json`: top 10,000 pypi packages, with the main module and all submodules one level deep\n\nThe packages tested in the paper are in the `paper/` directory.\n\n### How the agent works\n\nThe runner sets up virtual environments, with `venv`, for each package. Standard library packages just use the same virtual environment, and PyPI packages get their own virtual environment. The runner will also install `pytest` and `hypothesis` in each virtual environment. It does this in parallel, which is controllable; see the CLI arguments below.\n\nIt then then sets up directories, up to a specified number of maximum workers (see CLI arguments below), which is a \"sandbox\" for the agent to run in. It only has permission to edit files within this sandbox. Each worker directory also contains `.claude/commands/hypo.md`, so that the agent can run. The runner parallelizes across modules.\n\nNote that the runner also checks if the module has already been tested, and skips it if so. So, you can easily resume a run by just running the runner again.\n\n### Security\n\nThe runner calls the agent with restricted permissions. It only has permission to read/write/edit files in the sandbox in which it is called, and it also has read permission to the virtual environment, so that it can read the source code of the package. Furthermore, it can only write/edit `.py` and `.md` files. The only bash commands it can run are `python` and `pytest`. Note that because of how the virtual environments are set up, the Python command will be `python`. Lastly, it also has access to the `Todo` and `WebFetch` tools.\n\nYou should still be careful with the runner, because running arbitrary code is dangerous!\n\n### Outputs\n\nIn the `results/` directory, there will be a directory named after the package. Each of these will have the following structure:\n- `bug_reports/`\n    - \\<all bug reports written by the agent>\n- `logs/`\n    - `claude_call_$id.json` \\<the log of the Claude Code call corresponding to this id>\n- `aux_files/`\n    - `$id`\n        - \\<all other files written by Claude Code during the Claude Code call corresponding to this id, e.g., Python files>\n- `call_mappings.jsonl`, with the following format:\n    - `call_id`: the Claude Code call id\n    - `module`: the module tested\n    - `timestamp`: date executed\n    - `bug_reports`: the filename of any bug reports in the `bug_reports` directory written by this Claude Code call\n    - `aux_files_dir`: the directory containing all files written by the agent during the Claude Code call corresponding to this id\n\n### Ranking the bug reports\n\nTo score the bug reports, you can run `python scoring.py results/`. This uses the rubric contained in that file, and passes it to Claude (not Claude Code, just the Claude API). This script outputs a CSV file containing the scores for each bug report, as well as the reasoning.\n\nIt takes the following arguments:\n- `--retry-failures`: if set, it will retry the bug reports that failed to score. This requires the CSV file to already exist, as it checks for failed scores in the CSV file.\n- `reports_dir`: the directory containing the bug reports to score. Default is \"results/\".\n- `--max-workers`: the number of parallel workers to use. Default is 20.\n- `--model`: the model to use. Default is \"claude-opus-4-1\" (note model names are different when using the Claude API directly)\n- `--csv-path`: the path to the CSV file to write the results to. Default is \"scoring_results.csv\".\n\nExample usage:\n\n```bash\npython scoring.py results/\n```\n"
      },
      "plugins": [
        {
          "name": "hypo-plugin",
          "source": "./hypo-plugin",
          "description": "Hypothesis property-based testing plugin",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add mmaaz-git/agentic-pbt",
            "/plugin install hypo-plugin@agentic-pbt"
          ]
        }
      ]
    }
  ]
}