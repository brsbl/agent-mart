{
  "author": {
    "id": "kanaerulabs",
    "display_name": "Kanaeru Labs",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/238903679?v=4",
    "url": "https://github.com/kanaerulabs",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 6,
      "total_skills": 0,
      "total_stars": 8,
      "total_forks": 2
    }
  },
  "marketplaces": [
    {
      "name": "growth-kit-marketplace",
      "version": null,
      "description": "Content marketing & growth automation toolkit",
      "owner_info": {
        "name": "Kanaeru Labs",
        "email": "support@kanaeru.ai"
      },
      "keywords": [],
      "repo_full_name": "kanaerulabs/growth-kit",
      "repo_url": "https://github.com/kanaerulabs/growth-kit",
      "repo_description": "Content marketing & growth automation toolkit for Claude Code",
      "homepage": "https://www.kanaeru.ai",
      "signals": {
        "stars": 8,
        "forks": 2,
        "pushed_at": "2026-01-22T20:24:15Z",
        "created_at": "2025-10-18T20:43:04Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1755
        },
        {
          "path": "analytics-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "analytics-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "analytics-plugin/commands/vercel.md",
          "type": "blob",
          "size": 1076
        },
        {
          "path": "publisher-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "publisher-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "publisher-plugin/commands/all.md",
          "type": "blob",
          "size": 4101
        },
        {
          "path": "publisher-plugin/commands/devto.md",
          "type": "blob",
          "size": 7230
        },
        {
          "path": "publisher-plugin/commands/linkedin.md",
          "type": "blob",
          "size": 24948
        },
        {
          "path": "publisher-plugin/commands/medium.md",
          "type": "blob",
          "size": 12362
        },
        {
          "path": "publisher-plugin/commands/x.md",
          "type": "blob",
          "size": 16626
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"growth-kit-marketplace\",\n  \"owner\": {\n    \"name\": \"Kanaeru Labs\",\n    \"email\": \"support@kanaeru.ai\"\n  },\n  \"metadata\": {\n    \"description\": \"Content marketing & growth automation toolkit\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"publisher\",\n      \"source\": \"./publisher-plugin\",\n      \"description\": \"Content distribution toolkit - X/Twitter threads, LinkedIn posts, Medium articles. Accepts any input format (markdown, PDF, URL, etc.)\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Kanaeru Labs\",\n        \"email\": \"support@kanaeru.ai\",\n        \"url\": \"https://www.kanaeru.ai\"\n      },\n      \"homepage\": \"https://github.com/kanaerulabs/growth-kit\",\n      \"repository\": \"https://github.com/kanaerulabs/growth-kit\",\n      \"license\": \"MIT\",\n      \"keywords\": [\"blog\", \"marketing\", \"social-media\", \"twitter\", \"linkedin\", \"medium\", \"content\"],\n      \"commands\": [\n        \"./commands/x.md\",\n        \"./commands/linkedin.md\",\n        \"./commands/medium.md\",\n        \"./commands/devto.md\",\n        \"./commands/all.md\"\n      ],\n      \"strict\": false\n    },\n    {\n      \"name\": \"analytics\",\n      \"source\": \"./analytics-plugin\",\n      \"description\": \"Web analytics and tracking toolkit - Vercel Analytics, Google Analytics, and more\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Kanaeru Labs\",\n        \"email\": \"support@kanaeru.ai\",\n        \"url\": \"https://www.kanaeru.ai\"\n      },\n      \"homepage\": \"https://github.com/kanaerulabs/growth-kit\",\n      \"repository\": \"https://github.com/kanaerulabs/growth-kit\",\n      \"license\": \"MIT\",\n      \"keywords\": [\"analytics\", \"tracking\", \"vercel\", \"metrics\"],\n      \"commands\": [\n        \"./commands/vercel.md\"\n      ],\n      \"strict\": false\n    }\n  ]\n}\n",
        "analytics-plugin/commands/vercel.md": "---\ndescription: Set up Vercel Analytics and Speed Insights\nargument-hint:\ntags: [vercel, analytics, monitoring]\n---\n\nSet up essential Vercel integrations for a React/Vite project.\n\n## Tasks\n\n1. **Install Vercel Packages**\n   - Install @vercel/analytics\n   - Install @vercel/speed-insights\n\n2. **Add Components to App**\n   - Import Analytics and SpeedInsights from their respective packages\n   - Add both components to the main App component (typically in src/App.tsx or src/main.tsx)\n   - For React projects, use `/react` imports (not `/next`)\n\n3. **Create vercel.json for SPA Routing**\n   - Create vercel.json in project root\n   - Add rewrite rules to serve index.html for all routes\n   - This fixes 404 errors when accessing routes directly\n\n4. **Verify Setup**\n   - Check that both components are rendered in the app\n   - Test that direct route access works without 404s\n\n## Expected Output\n\nAfter running this command, the project should have:\n- Analytics tracking configured\n- Speed Insights monitoring configured\n- SPA routing properly configured for Vercel deployment\n",
        "publisher-plugin/commands/all.md": "---\ndescription: Generate content for all platforms (X, LinkedIn, Medium, Dev.to) from a single input\nargument-hint: <input> [lang]\ntags: [x, linkedin, medium, devto, social, blog, content, distribution]\n---\n\nGenerate copy-pastable content for all social media platforms from a single input by running all publisher commands in parallel.\n\n**Usage:** `$ARGUMENTS`\n\n**Input:** Pass the same arguments you would use for individual commands - slug, file path, URL, etc.\n\n---\n\n## Process\n\n1. **Parse Arguments and Language Detection**\n   - Extract the full arguments string: `$ARGUMENTS`\n   - Detect language from arguments:\n     - If ends with `ja` ‚Üí Japanese content\n     - If ends with `en` ‚Üí English content\n     - If ends with `both` ‚Üí Generate for both languages\n     - Default ‚Üí English if no language specified\n   - Example: `2025-10-06-my-post ja` ‚Üí Japanese version\n\n2. **Run All Publisher Commands SEQUENTIALLY**\n\n   **CRITICAL:** Execute commands ONE AT A TIME, waiting for each to complete before starting the next:\n\n   ```\n   // Step 1: Run X thread generation\n   SlashCommand(\"/publisher:x $ARGUMENTS\")\n   // Wait for completion, then...\n\n   // Step 2: Run LinkedIn post generation\n   SlashCommand(\"/publisher:linkedin $ARGUMENTS\")\n   // Wait for completion, then...\n\n   // Step 3: Run Medium article generation\n   SlashCommand(\"/publisher:medium $ARGUMENTS\")\n   // Wait for completion, then...\n\n   // Step 4: Run Dev.to RSS generation\n   SlashCommand(\"/publisher:devto\")\n   ```\n\n   **IMPORTANT:** Run commands in SEPARATE messages, waiting for each command to fully complete before proceeding to the next. This ensures stability and prevents resource contention.\n\n3. **Auto-Open Browser Tabs for Immediate Action**\n\n   All commands will process the input and automatically open the necessary tabs:\n   - **X**: Opens HTML preview with copy buttons for each post + X.com compose\n   - **LinkedIn**: Opens draft in LinkedIn feed + browser tab to review\n   - **Medium**: Opens HTML with one-click copy + Medium editor tab\n   - **Dev.to**: Opens Dev.to settings page + generates RSS file\n\n4. **Summary with Clear Next Actions**\n\n   Once all commands complete sequentially, provide a detailed action summary:\n   ```\n   ‚úÖ ALL PLATFORMS GENERATED SEQUENTIALLY\n   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n   üì± X Thread\n      ‚Ü≥ HTML preview opened with thread\n      ‚Ü≥ X.com compose page opened in browser\n      ‚Ü≥ Click \"Copy Post\" buttons to copy each post\n      ‚Ü≥ Post to X using thread composer\n\n   üíº LinkedIn Post\n      ‚Ü≥ Draft created and LinkedIn opened\n      ‚Ü≥ Navigate to your drafts to review\n      ‚Ü≥ Add any final touches and click \"Post\"\n\n   üìù Medium Article\n      ‚Ü≥ HTML preview opened with one-click copy\n      ‚Ü≥ Medium editor opened in new tab\n      ‚Ü≥ Click to copy entire article, then paste in Medium\n\n   üîó Dev.to RSS Feed\n      ‚Ü≥ RSS file generated: public/rss-devto.xml\n      ‚Ü≥ Settings page opened\n      ‚Ü≥ Add RSS URL to \"Publishing from RSS\" section\n\n   ‚ö° All browser tabs opened for immediate action!\n   ```\n\n---\n\n## Example Usage\n\n```bash\n# Generate for all platforms (English - default)\n/publisher:all 2025-10-13-my-post\n/publisher:all 2025-10-13-my-post en\n\n# Generate for all platforms (Japanese)\n/publisher:all 2025-10-13-my-post ja\n\n# Generate for BOTH languages simultaneously\n/publisher:all 2025-10-13-my-post both\n\n# From a file path (with language)\n/publisher:all path/to/article.md ja\n\n# From a URL (auto-detects language from content)\n/publisher:all https://myblog.com/my-post\n```\n\n---\n\n## Implementation Notes\n\n- **Single source of truth:** Each platform command handles its own input detection and generation logic\n- **Sequential execution:** Commands run one at a time to ensure stability and prevent resource contention\n- **No duplication:** Changes to individual platform logic automatically apply when using `/publisher:all`\n- **Extensibility:** Adding new platforms just requires adding another SlashCommand call in the sequence\n",
        "publisher-plugin/commands/devto.md": "---\ndescription: Generate Dev.to-optimized RSS feed for automatic article import\ntags: [devto, rss, blog, syndication]\n---\n\nGenerate a Dev.to-optimized RSS feed that can be used to automatically import your blog posts to Dev.to.\n\n**What this does:** Creates an RSS feed with HTML-encoded content that Dev.to can import and convert to their markdown format.\n\n---\n\n## Process\n\n### 1. Understand the Blog Structure\n\n**Scan the codebase to understand:**\n- Where are markdown blog posts stored?\n- What frontmatter format is used?\n- What's the blog base URL?\n- Where are images/diagrams located?\n\n**Common blog structures:**\n- `src/content/blog/posts/{en,ja}/*.md`\n- `content/blog/*.md`\n- `posts/*.md`\n- `blog/*.md`\n\n### 2. Read All Blog Posts\n\n**Use Glob to find all markdown files:**\n- Search pattern: `**/*.md` in blog directories\n- Read each file with Read tool\n- Extract frontmatter (title, description, date, author)\n- Extract markdown content\n\n**For each post:**\n```typescript\n{\n  title: string,\n  description: string,\n  date: string,\n  author: string,\n  slug: string,\n  content: string (markdown),\n  url: string (full blog post URL)\n}\n```\n\n### 3. Convert Markdown to HTML\n\n**Dev.to Requirements:**\n- Content must be HTML (in `<content:encoded>` field)\n- All URLs must be absolute (not relative)\n- Images must use absolute URLs\n- Dev.to will convert the HTML back to markdown on their end\n\n**Conversion process:**\n- Convert markdown to HTML (use marked.js if available, or simple conversion)\n- Make all image URLs absolute\n- Make all links absolute\n- Preserve code blocks and formatting\n\n### 4. Generate RSS Feed\n\n**Create XML file with RSS 2.0 format:**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<rss version=\"2.0\"\n     xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"\n     xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n     xmlns:atom=\"http://www.w3.org/2005/Atom\">\n  <channel>\n    <title>Blog Title</title>\n    <description>Blog Description</description>\n    <link>https://yourblog.com</link>\n    <atom:link href=\"https://yourblog.com/rss-devto.xml\" rel=\"self\" type=\"application/rss+xml\"/>\n    <language>en</language>\n\n    <item>\n      <title>Post Title</title>\n      <link>https://yourblog.com/blog/post-slug</link>\n      <guid>https://yourblog.com/blog/post-slug</guid>\n      <pubDate>Mon, 01 Jan 2025 00:00:00 GMT</pubDate>\n      <description>Post description</description>\n      <content:encoded><![CDATA[\n        <!-- HTML content here with absolute URLs -->\n      ]]></content:encoded>\n      <dc:creator>Author Name</dc:creator>\n    </item>\n\n    <!-- More items... -->\n  </channel>\n</rss>\n```\n\n### 5. Save and Output\n\n**Save the RSS feed:**\n- File location: `public/rss-devto.xml` (or project root)\n- Ensure proper XML formatting\n- Validate the feed structure\n\n**Auto-open Dev.to settings:**\n```bash\n# Automatically open Dev.to RSS settings page\nopen https://dev.to/settings/extensions\n```\n\n**Display to user with clear actions:**\n```\n‚úÖ Dev.to RSS feed generated & settings opened!\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nüìÑ File Created: public/rss-devto.xml\nüîó Feed URL: https://yourblog.com/rss-devto.xml\nüåê Browser: Dev.to settings page opened\n\nüìã SIMPLE Next Steps:\n  1Ô∏è‚É£ Deploy your site (RSS needs to be live)\n  2Ô∏è‚É£ Dev.to settings is now open in browser\n  3Ô∏è‚É£ Scroll to \"Publishing from RSS\" section\n  4Ô∏è‚É£ Paste: https://yourblog.com/rss-devto.xml\n  5Ô∏è‚É£ Click \"Submit\" - posts will auto-import!\n\nüìù Posts included: X articles\n  - Article 1 title\n  - Article 2 title\n  - Article 3 title\n\nüí° TIP: Dev.to checks RSS every ~30 minutes for new content\n```\n\n---\n\n## Dev.to RSS Import Setup\n\nOnce the RSS feed is generated and deployed:\n\n1. **Go to Dev.to Settings**\n   - Visit: https://dev.to/settings/extensions\n   - Scroll to \"Publishing from RSS\" section\n\n2. **Add Your RSS Feed**\n   - Enter: `https://yourblog.com/rss-devto.xml`\n   - Click \"Submit\"\n\n3. **Configure Import Settings**\n   - Choose: \"Publish immediately\" or \"Save as draft\"\n   - Set canonical URL (points back to your blog)\n\n4. **Automatic Syncing**\n   - Dev.to checks your RSS feed periodically\n   - New posts are automatically imported\n   - Updates to existing posts are NOT synced (manual edits on Dev.to remain)\n\n---\n\n## Key Differences from Regular RSS\n\n**Dev.to-Optimized RSS:**\n- Uses HTML in `<content:encoded>` (not plain markdown)\n- All URLs are absolute (no relative paths)\n- Includes `<dc:creator>` for author attribution\n- Uses `<guid>` for unique identification\n\n**Regular RSS:**\n- May use plain text or summary in description\n- Can have relative URLs\n- May not include full HTML content\n\n---\n\n## Troubleshooting\n\n**Q: Dev.to isn't importing my posts?**\n- Check RSS feed is publicly accessible\n- Validate XML syntax\n- Ensure all URLs are absolute\n- Check pubDate format (RFC 822)\n\n**Q: Images not showing on Dev.to?**\n- Ensure image URLs are absolute (https://...)\n- Images must be publicly accessible\n- Dev.to may cache images\n\n**Q: Want to update an existing post?**\n- RSS updates don't sync to Dev.to after initial import\n- You must manually edit on Dev.to for updates\n\n---\n\n## Example Output\n\nAfter running this command, you'll have:\n\n```\npublic/rss-devto.xml\n```\n\nWith content like:\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<rss version=\"2.0\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\">\n  <channel>\n    <title>Your Blog</title>\n    <link>https://yourblog.com</link>\n    <item>\n      <title>How to Build AI Agents</title>\n      <link>https://yourblog.com/blog/2025-01-15-ai-agents</link>\n      <guid>https://yourblog.com/blog/2025-01-15-ai-agents</guid>\n      <pubDate>Wed, 15 Jan 2025 00:00:00 GMT</pubDate>\n      <description>Learn how to build production-ready AI agents</description>\n      <content:encoded><![CDATA[\n        <h1>How to Build AI Agents</h1>\n        <p>AI agents are transforming...</p>\n        <img src=\"https://yourblog.com/images/diagram.png\" alt=\"Architecture\" />\n        <!-- Full HTML content -->\n      ]]></content:encoded>\n    </item>\n  </channel>\n</rss>\n```\n\n---\n\n## Implementation Notes\n\n**DO NOT use npm scripts.** Generate the RSS feed directly using:\n- Glob tool to find markdown files\n- Read tool to parse frontmatter and content\n- Built-in text processing to convert markdown ‚Üí HTML\n- Write tool to save `public/rss-devto.xml`\n\n**Date formatting:** Use RFC 822 format for `<pubDate>`:\n\n**CRITICAL: For bash scripts, use bash date command** (NOT JavaScript):\n```bash\n# Convert YYYY-MM-DD to RFC 822 in bash\ndate -u -d \"2025-01-15\" \"+%a, %d %b %Y %H:%M:%S GMT\"\n# Output: \"Mon, 15 Jan 2025 00:00:00 GMT\"\n\n# Or for current date:\ndate -u \"+%a, %d %b %Y %H:%M:%S GMT\"\n```\n\n**If generating with TypeScript/Node** (using npx tsx):\n```javascript\nnew Date(post.date).toUTCString()\n// Output: \"Mon, 15 Jan 2025 00:00:00 GMT\"\n```\n\n**DO NOT** use `new Date()` syntax in bash heredocs - it will cause \"Bad substitution\" errors!\n\n**URL construction:**\n- Detect base URL from blog structure or ask user\n- Construct: `${baseUrl}/blog/${slug}`\n- Ensure all image paths are absolute\n\n**Limit to recent posts:** Generate RSS for last 10-20 posts (Dev.to recommendation)\n",
        "publisher-plugin/commands/linkedin.md": "---\ndescription: Create a LinkedIn post from any content source\nargument-hint: <input> [lang] [custom-file-path]\ntags: [linkedin, social, blog, i18n]\n---\n\nCreate a LinkedIn post from any content source - blog posts, articles, PDFs, URLs, or plain text.\n\n**Usage:** `$ARGUMENTS`\n\n**Optional custom file attachment:**\n```bash\n# Auto-generate PDF from ALL blog diagrams (default)\n/publisher:linkedin my-post\n\n# Attach your own image or PDF\n/publisher:linkedin my-post en path/to/image.png\n/publisher:linkedin my-post en path/to/report.pdf\n```\n\n**Media attachment (zero dependencies!):**\n- **With Pillow**: Generates PDF from all diagrams ‚Üí single file\n- **Without Pillow**: Uploads all diagrams as separate images ‚Üí works everywhere!\n- **Custom file**: Just provide the path ‚Üí always works\n- **No install required** for the fallback option!\n\n**CRITICAL:** LinkedIn's \"Little Text Format\" requires escaping reserved characters even for REST API!\n\nReserved characters that MUST be escaped: `\\ | { } @ [ ] ( ) < > # * _ ~`\n\n**DO NOT manually escape these in your commentary** - Claude handles two-step escaping automatically:\n1. LinkedIn Little Text Format escaping (parentheses, brackets, etc.)\n2. JSON escaping (quotes, backslashes)\n\nPass raw text with parentheses, hashtags, etc. directly - the command handles all escaping.\n\n**Process:**\n\n1. **Parse Input Arguments**\n   - Extract content input, optional language parameter, and optional custom file path\n   - Examples:\n     - `2025-10-06-my-post` (slug only, default English)\n     - `2025-10-06-my-post ja` (slug with Japanese)\n     - `2025-10-06-my-post en path/to/custom.png` (with custom file)\n     - `path/to/article.md` (file path)\n     - `https://myblog.com/post` (URL)\n\n2. **Universal Input Detection**\n\n   **If input looks like a file path** (contains `/` or file extension):\n   - Use Read tool to check if file exists\n   - Detect format by extension:\n     - `.md` / `.mdx` ‚Üí Parse markdown with frontmatter (extract title, description, body, metadata)\n     - `.pdf` ‚Üí Inform user PDF parsing is limited, suggest converting to markdown first\n     - `.docx` ‚Üí Inform user DOCX parsing is limited, suggest converting to markdown first\n     - `.html` ‚Üí Read and extract main content, strip HTML tags\n     - `.txt` ‚Üí Read as plain text\n     - `.json` ‚Üí Parse JSON and extract relevant fields\n   - Extract: title, description, body content, metadata\n\n   **If input looks like a URL** (starts with `http://` or `https://`):\n   - Use WebFetch tool to retrieve the page\n   - Prompt: \"Extract the main article content, title, and description from this page\"\n   - Parse and clean the text\n\n   **If input is a slug** (no `/` and no protocol):\n   - Search codebase using Glob: `**/*${input}*.md`\n   - Common patterns to check:\n     - `src/content/blog/posts/{en,ja}/*${input}*.md`\n     - `content/blog/*${input}*.md`\n     - `posts/*${input}*.md`\n     - `blog/*${input}*.md`\n   - If language specified, prioritize matching language folder\n   - Use Read tool to parse markdown file with frontmatter\n\n3. **Determine Language** (default: English):\n   - If user explicitly specifies \"ja\" ‚Üí Japanese\n   - If user explicitly specifies \"en\" ‚Üí English\n   - If file path contains `/ja/` ‚Üí Japanese\n   - If content appears to be in Japanese ‚Üí Japanese\n   - Otherwise ‚Üí English\n\n4. **Generate engaging LinkedIn commentary** in the target language:\n   - **For English**: Follow professional thought leadership voice (see examples below)\n   - **For Japanese**: Use professional Japanese business tone (Êï¨Ë™û), include article link\n   - Use actual blog content and key points\n   - Make it contextual and intelligent, not template-based\n   - **APPLY HUMANIZATION** (see Humanization Guidelines below)\n\n5. **Handle file attachment**:\n\n   **If custom file path provided** (third argument):\n   - Use the specified file path (e.g., `path/to/image.png` or `path/to/report.pdf`)\n   - Verify file exists using Read tool\n   - Supported formats: `.png`, `.jpg`, `.jpeg`, `.pdf`\n   - Use this file for LinkedIn media upload\n\n   **If no custom file specified** (default behavior):\n   - Auto-detect blog diagrams:\n     - English: `public/diagrams/[SLUG]-0-en-light.png`\n     - Japanese: `public/diagrams/[SLUG]-0-ja-light.png`\n   - Script will auto-generate PDF from diagrams if found\n   - Commentary MUST include article URL when diagrams exist\n\n6. **Create the draft** using pure Bash + curl:\n\n   **Truly Universal**: Works in Python, Rust, Go, JavaScript - ANY repo type!\n   **Requirements**: Only `bash` and `curl` (standard on all systems)\n\n   **Process**:\n   a. Check if `.env` file exists (use Read tool):\n      - Look for `LINKEDIN_CLIENT_ID`, `LINKEDIN_CLIENT_SECRET`, `LINKEDIN_ACCESS_TOKEN`\n      - If missing, guide user to create `.env` from `.env.example`\n\n   b. If no access token, help user get one:\n      - Build OAuth URL with proper parameters\n      - Tell user to visit URL and authorize\n      - User will paste back the authorization code\n      - Exchange code for token using Bash + curl\n      - Update `.env` file using Edit tool to save token\n\n   c. Prepare commentary for LinkedIn API (pure bash with TWO-STEP escaping):\n      ```bash\n      # Save commentary to temp file first\n      cat > /tmp/linkedin-commentary-raw.txt << 'COMMENTARYEOF'\n[YOUR COMMENTARY TEXT HERE]\nCOMMENTARYEOF\n\n      # STEP 1: Escape LinkedIn Little Text Format reserved characters\n      # These MUST be escaped or LinkedIn API will truncate the post!\n      # Reserved chars: | { } @ [ ] ( ) < > # * _ ~\n      # NOTE: Do NOT escape backslashes yet - that happens in step 2\n      sed 's/|/\\\\|/g; s/{/\\\\{/g; s/}/\\\\}/g; s/@/\\\\@/g; s/\\[/\\\\[/g; s/\\]/\\\\]/g; s/(/\\\\(/g; s/)/\\\\)/g; s/</\\\\</g; s/>/\\\\>/g; s/#/\\\\#/g; s/\\*/\\\\*/g; s/_/\\\\_/g; s/~/\\\\~/g' /tmp/linkedin-commentary-raw.txt > /tmp/linkedin-escaped.txt\n\n      # STEP 2: Escape for JSON (backslashes AND quotes)\n      # This will escape the backslashes created in step 1\n      sed 's/\\\\/\\\\\\\\/g; s/\"/\\\\\"/g' /tmp/linkedin-escaped.txt > /tmp/linkedin-json-ready.txt\n\n      # Read fully escaped text\n      COMMENTARY_TEXT=$(cat /tmp/linkedin-json-ready.txt)\n      ```\n      **CRITICAL**: LinkedIn's REST API requires Little Text Format escaping!\n      Without escaping `( )` and other reserved chars, posts get truncated.\n      This is documented behavior, not a UI-only requirement!\n\n   c2. Prepare media file (PDF from all diagrams OR custom file):\n      ```bash\n      # Determine which file to upload (custom file takes precedence)\n      MEDIA_FILE=\"\"\n      MEDIA_URN=\"\"\n      FILE_TYPE=\"\"\n\n      # Check if user provided custom file path (3rd argument)\n      if [ -n \"$CUSTOM_FILE_PATH\" ] && [ -f \"$CUSTOM_FILE_PATH\" ]; then\n        MEDIA_FILE=\"$CUSTOM_FILE_PATH\"\n        FILE_TYPE=$(echo \"$CUSTOM_FILE_PATH\" | grep -o '\\.[^.]*$')\n        echo \"üìé Using custom file: $CUSTOM_FILE_PATH\"\n\n      # Otherwise, generate PDF from ALL blog diagrams\n      else\n        # Find all diagrams for this blog post\n        DIAGRAM_COUNT=$(ls public/diagrams/${SLUG}-*-${LANG}-light.png 2>/dev/null | wc -l)\n\n        if [ \"$DIAGRAM_COUNT\" -gt 0 ]; then\n          echo \"üìä Found $DIAGRAM_COUNT blog diagrams\"\n\n          # Check if Python + Pillow available\n          if command -v python3 >/dev/null 2>&1 && python3 -c \"from PIL import Image\" 2>/dev/null; then\n            # Generate PDF from all diagrams\n            echo \"üìÑ Generating PDF from $DIAGRAM_COUNT diagrams...\"\n            PDF_PATH=\"/tmp/${SLUG}-diagrams.pdf\"\n\n            python3 -c \"\nfrom PIL import Image\nfrom pathlib import Path\nimages = [Image.open(str(f)).convert('RGB') for f in sorted(Path('public/diagrams').glob('${SLUG}-*-${LANG}-light.png'))]\nif images:\n    images[0].save('$PDF_PATH', save_all=True, append_images=images[1:])\n    print('‚úÖ PDF created with $DIAGRAM_COUNT pages')\n\" 2>/dev/null\n\n            if [ -f \"$PDF_PATH\" ]; then\n              MEDIA_FILE=\"$PDF_PATH\"\n              FILE_TYPE=\"pdf\"\n            fi\n\n          else\n            # Pillow not available - ask user\n            echo \"\"\n            echo \"üì¶ Python Pillow not installed (needed for PDF generation)\"\n            echo \"\"\n            echo \"Options:\"\n            echo \"  1. Install Pillow now: pip install Pillow (then rerun command)\"\n            echo \"  2. Skip - upload all $DIAGRAM_COUNT diagrams as separate images (works everywhere!)\"\n            echo \"\"\n\n            # Use AskUserQuestion to get user choice\n            # For now, default to uploading all images separately (no install needed)\n            echo \"‚ö° Uploading all $DIAGRAM_COUNT diagrams as separate images...\"\n            MEDIA_FILE=\"multiple\"\n            FILE_TYPE=\"multiple-images\"\n          fi\n        fi\n      fi\n\n      # Upload media (single file or multiple images)\n      if [ \"$FILE_TYPE\" = \"multiple-images\" ]; then\n        # Upload all diagrams separately (LinkedIn supports up to 9 images)\n        echo \"üì§ Uploading $DIAGRAM_COUNT images to LinkedIn...\"\n        MEDIA_URNS=()\n        INDEX=1\n\n        IMAGES_JSON_ARRAY=\"\"\n\n        for img in public/diagrams/${SLUG}-*-${LANG}-light.png; do\n          BASENAME=$(basename \"$img\" .png)\n          echo \"  [$INDEX/$DIAGRAM_COUNT] Uploading $BASENAME...\"\n\n          # Register upload\n          REG_RESP=$(curl -s -X POST \\\n            \"https://api.linkedin.com/rest/images?action=initializeUpload\" \\\n            -H \"Authorization: Bearer $TOKEN\" \\\n            -H \"LinkedIn-Version: 202506\" \\\n            -H \"X-Restli-Protocol-Version: 2.0.0\" \\\n            -H \"Content-Type: application/json\" \\\n            -d \"{\\\"initializeUploadRequest\\\": {\\\"owner\\\": \\\"$MEMBER_URN\\\"}}\")\n\n          UP_URL=$(echo \"$REG_RESP\" | grep -o '\"uploadUrl\":\"[^\"]*\"' | cut -d'\"' -f4 | sed 's/\\\\u0026/\\&/g')\n          IMG_URN=$(echo \"$REG_RESP\" | grep -o '\"image\":\"[^\"]*\"' | cut -d'\"' -f4)\n\n          if [ -n \"$UP_URL\" ] && [ -n \"$IMG_URN\" ]; then\n            curl -s -X PUT \"$UP_URL\" -H \"Authorization: Bearer $TOKEN\" --upload-file \"$img\" >/dev/null 2>&1\n\n            # Add to images array with id AND altText (required!)\n            if [ -n \"$IMAGES_JSON_ARRAY\" ]; then\n              IMAGES_JSON_ARRAY=\"${IMAGES_JSON_ARRAY},\"\n            fi\n            IMAGES_JSON_ARRAY=\"${IMAGES_JSON_ARRAY}{\\\"id\\\":\\\"$IMG_URN\\\",\\\"altText\\\":\\\"Diagram $INDEX\\\"}\"\n            echo \"    ‚úÖ Uploaded\"\n          fi\n\n          INDEX=$((INDEX + 1))\n        done\n\n        # Complete images array\n        MEDIA_URN=\"[${IMAGES_JSON_ARRAY}]\"\n        echo \"‚úÖ All $DIAGRAM_COUNT images uploaded with altText!\"\n\n      elif [ -n \"$MEDIA_FILE\" ]; then\n        # Single file upload\n        case \"$MEDIA_FILE\" in\n          *.pdf) API_ENDPOINT=\"documents\"; URN_KEY=\"document\" ;;\n          *.png|*.jpg|*.jpeg) API_ENDPOINT=\"images\"; URN_KEY=\"image\" ;;\n        esac\n\n        echo \"üì§ Uploading $(basename $MEDIA_FILE)...\"\n        REG_RESP=$(curl -s -X POST \\\n          \"https://api.linkedin.com/rest/${API_ENDPOINT}?action=initializeUpload\" \\\n          -H \"Authorization: Bearer $TOKEN\" \\\n          -H \"LinkedIn-Version: 202506\" \\\n          -H \"X-Restli-Protocol-Version: 2.0.0\" \\\n          -H \"Content-Type: application/json\" \\\n          -d \"{\\\"initializeUploadRequest\\\": {\\\"owner\\\": \\\"$MEMBER_URN\\\"}}\")\n\n        UP_URL=$(echo \"$REG_RESP\" | grep -o '\"uploadUrl\":\"[^\"]*\"' | cut -d'\"' -f4 | sed 's/\\\\u0026/\\&/g')\n        MEDIA_URN=$(echo \"$REG_RESP\" | grep -o \"\\\"${URN_KEY}\\\":\\\"[^\\\"]*\\\"\" | cut -d'\"' -f4)\n\n        if [ -n \"$UP_URL\" ] && [ -n \"$MEDIA_URN\" ]; then\n          curl -s -X PUT \"$UP_URL\" -H \"Authorization: Bearer $TOKEN\" --upload-file \"$MEDIA_FILE\" >/dev/null\n          echo \"‚úÖ Uploaded!\"\n        else\n          echo \"‚ö†Ô∏è  Upload failed\"\n          MEDIA_URN=\"\"\n        fi\n      fi\n      ```\n\n   d. Create JSON payload with optional media (pure bash):\n      ```bash\n      # Escape newlines for JSON (replace \\n with \\\\n)\n      COMMENTARY_JSON=$(echo \"$COMMENTARY_TEXT\" | awk '{printf \"%s\\\\n\", $0}' | sed '$ s/\\\\n$//')\n\n      # Build JSON based on media type\n      if [[ \"$MEDIA_URN\" == \"[\"* ]]; then\n        # Multiple images (array format)\n        cat > /tmp/linkedin-post.json << EOF\n{\n  \"author\": \"$MEMBER_URN\",\n  \"commentary\": \"$COMMENTARY_JSON\",\n  \"visibility\": \"PUBLIC\",\n  \"distribution\": {\"feedDistribution\": \"MAIN_FEED\"},\n  \"content\": {\n    \"multiImage\": {\n      \"images\": $(echo \"$MEDIA_URN\" | sed 's/\"urn/\"id\":\"urn/g' | sed 's/\",/\"},/g' | sed 's/]$/}]/')\n    }\n  },\n  \"lifecycleState\": \"DRAFT\"\n}\nEOF\n      elif [ -n \"$MEDIA_URN\" ]; then\n        # Single media attachment\n        cat > /tmp/linkedin-post.json << EOF\n{\n  \"author\": \"$MEMBER_URN\",\n  \"commentary\": \"$COMMENTARY_JSON\",\n  \"visibility\": \"PUBLIC\",\n  \"distribution\": {\"feedDistribution\": \"MAIN_FEED\"},\n  \"content\": {\n    \"media\": {\n      \"id\": \"$MEDIA_URN\"\n    }\n  },\n  \"lifecycleState\": \"DRAFT\"\n}\nEOF\n      else\n        # Text-only post\n        cat > /tmp/linkedin-post.json << EOF\n{\n  \"author\": \"$MEMBER_URN\",\n  \"commentary\": \"$COMMENTARY_JSON\",\n  \"visibility\": \"PUBLIC\",\n  \"distribution\": {\"feedDistribution\": \"MAIN_FEED\"},\n  \"lifecycleState\": \"DRAFT\"\n}\nEOF\n      fi\n      ```\n      **Pure bash JSON creation** - handles single/multiple media or text-only!\n\n   e. Post to LinkedIn using curl (Bash tool) **with error handling**:\n      ```bash\n      # Post to LinkedIn and capture response\n      RESPONSE=$(curl -s -X POST https://api.linkedin.com/rest/posts \\\n        -H \"Authorization: Bearer $TOKEN\" \\\n        -H \"LinkedIn-Version: 202506\" \\\n        -H \"X-Restli-Protocol-Version: 2.0.0\" \\\n        -H \"Content-Type: application/json\" \\\n        -d @/tmp/linkedin-post.json)\n\n      # Check for errors in response\n      if echo \"$RESPONSE\" | grep -q '\"status\"'; then\n        STATUS=$(echo \"$RESPONSE\" | grep -o '\"status\":[0-9]*' | cut -d':' -f2)\n        if [ \"$STATUS\" -ge 400 ]; then\n          echo \"‚ùå LinkedIn API Error (Status: $STATUS):\"\n          echo \"$RESPONSE\" | grep -o '\"message\":\"[^\"]*\"' | sed 's/\"message\":\"//;s/\"//'\n          echo \"\"\n          echo \"üí° The post content was generated and saved to:\"\n          echo \"   /tmp/linkedin-commentary.txt\"\n          echo \"\"\n          echo \"üìã You can copy it and post manually to LinkedIn\"\n          # Still open LinkedIn so user can post manually\n          open https://www.linkedin.com/feed/\n          exit 0\n        fi\n      fi\n\n      echo \"‚úÖ LinkedIn draft created successfully!\"\n      ```\n\n   f. Extract post ID from response using grep/sed (no jq needed!) - if successful\n\n   g. Open LinkedIn feed using Bash tool: `open https://www.linkedin.com/feed/`\n\n   **Note**: Pure bash/curl implementation - works ANYWHERE!\n\n7. **Report results** to user with draft URL\n\n---\n\n## Professional LinkedIn Voice Guidelines\n\n**Example post styles for thought leadership content:**\n\n### Post 1 Style (No emojis originally, but use emojis now):\n```\nThe Four Ways to Build Software in 2025 (And Why Most Are Getting It Wrong)\n\nAI agents are revolutionizing software development, creating a multi-trillion-dollar market. Notably, 88% of senior executives plan to increase their AI budgets in 2025. However, a concerning reality persists: fewer than 45% are fundamentally rethinking their operating models.\n\nThis oversight leads to 41% of workers facing AI-generated \"workslop\"‚Äîcontent that seems polished but lacks depth‚Äîresulting in nearly two hours of rework for each instance.\n\nIn our latest deep-dive, we explore:\n\n- The four dominant build models in the AI agent era\n- Why Review-Driven Design (RDD) is a game-changer\n- How Spec-Driven Development (SDD) removes ambiguity\n- The hidden economics of AI development that many teams overlook\n- Why review speed‚Äînot coding speed‚Äîis the new bottleneck\n\nKey insight: AI agents can generate 1,000 lines of code in 60 seconds, but humans require 60 minutes to review it. RDD optimizes code for 10x faster human review, cutting that time down to just 6 minutes.\n\nThe disparity between AI adopters and AI adapters is significant. Adopters utilize AI tools, while adapters transform their entire delivery model.\n\nWhich one are you?\n\nRead the full article here: [URL]\n\nhashtag#AI hashtag#SoftwareDevelopment hashtag#AIAgents...\n```\n\n### Post 2 Style (With emojis):\n```\nYour users don't follow specifications. They enter emoji in name fields, submit forms 17 times in 3 seconds, and paste entire novels into comment boxes.\n\nThe question isn't \"if\" something will go wrong-it's \"what\" will go wrong, \"when\", and whether your tests caught it first.\n\nHere's the uncomfortable truth: You can have 100% code coverage and still miss critical edge cases.\n\nCode coverage measures which lines execute during tests-not which behaviors are validated or which edge cases are explored.\n\nWe've developed an edge case taxonomy after researching several production incidents that \"shouldn't have happened\":\n\n1Ô∏è‚É£ Boundary Cases - MIN/MAX values, string lengths, date ranges\n2Ô∏è‚É£ Null/Empty Cases - null, undefined, empty collections\n3Ô∏è‚É£ Format Cases - SQL injection, XSS, Unicode/emoji, malformed data\n4Ô∏è‚É£ State Cases - Race conditions, invalid transitions, timeouts\n5Ô∏è‚É£ Implicit Requirements - The unstated assumptions stakeholders never document\n\nReal war stories from production:\n‚Ä¢ Leap year bug: Payment system added 365 days. Worked perfectly until Feb 29, 2020\n‚Ä¢ Unicode email incident: Regex rejected m√ºller@example.com\n‚Ä¢ Null pointer in prod: Function assumed cart always had items. Empty cart = crash\n\nThe breakthrough approach? \"Review-Driven Design meets TDD\":\n‚úÖ Write edge case tests BEFORE implementing (not after)\n‚úÖ Use constructor injection to make hidden dependencies testable\n‚úÖ Organize tests by edge case category (boundary, security, performance)\n‚úÖ Track edge case coverage, not just code coverage\n\nInstead of:\n‚ùå \"Build us a user dashboard\"\n\nThink:\n‚úÖ \"What happens if username is null?\"\n‚úÖ \"What if email contains SQL injection attempt?\"\n‚úÖ \"What if two users click submit simultaneously?\"\n‚úÖ \"What if the API times out mid-operation?\"\n\nThis is the detective's mindset: asking \"what could possibly go wrong?\" before writing any production code.\n\nOur comprehensive guide covers:\n‚Ä¢ The Red-Green-Refactor cycle optimized for edge case hunting\n‚Ä¢ Constructor injection patterns that make testing 10x easier\n‚Ä¢ Property-based testing techniques\n‚Ä¢ Real-world case studies with lessons learned\n‚Ä¢ Complete edge case checklist for production readiness\n\nBecause edge case testing isn't about paranoia-it's about \"craftsmanship\".\n\nRead the full practitioner's guide: [URL]\n\nhashtag#TDD hashtag#SoftwareTesting...\n```\n\n---\n\n## Commentary Generation Checklist\n\nGenerate LinkedIn commentary that:\n- ‚úÖ Starts with the blog post title\n- ‚úÖ Opens with a hook that grabs attention (stats, contrarian statement, or problem)\n- ‚úÖ Includes \"Here's the uncomfortable truth:\" or similar contrarian angle\n- ‚úÖ Lists 3-5 key points from the ACTUAL blog content with emojis (üéØ, üí°, ‚ö°, ‚úÖ)\n- ‚úÖ Adds a \"Key insight:\" with a specific quantitative or qualitative takeaway\n- ‚úÖ Includes a rhetorical question for engagement (\"Which one are you?\")\n- ‚úÖ Links to the full article: [BLOG_BASE_URL]/blog/[SLUG]\n- ‚úÖ Ends with engagement CTA (\"Drop your thoughts below! üëá\" or similar)\n- ‚úÖ Uses relevant hashtags (5-7 hashtags related to the content)\n- ‚úÖ Keeps professional but conversational tone\n- ‚úÖ Incorporates actual insights/stats from the blog post (not generic)\n\n**IMPORTANT**: Read the blog post content to extract real insights, not generic placeholders!\n\n---\n\n## Humanization Guidelines\n\n**CRITICAL**: All generated content MUST sound human, not AI-generated. Apply the `/humanizer` skill principles:\n\n### Patterns to AVOID:\n\n1. **Inflated significance** - Don't say \"stands as a testament to\", \"pivotal moment\", \"game-changer\", \"transformative\"\n2. **Promotional language** - Avoid \"groundbreaking\", \"revolutionary\", \"stunning\", \"breathtaking\", \"cutting-edge\"\n3. **AI vocabulary overuse** - Cut \"Additionally\", \"Moreover\", \"delve\", \"landscape\", \"tapestry\", \"crucial\", \"foster\"\n4. **Vague attributions** - No \"experts believe\", \"industry reports show\" without specific citations\n5. **Superficial -ing phrases** - Remove \"highlighting the importance of\", \"showcasing the potential\", \"underscoring\"\n6. **Rule of three abuse** - Don't force \"innovation, inspiration, and industry insights\" patterns\n7. **Negative parallelisms** - Avoid \"It's not just X, it's Y\" constructions\n8. **Em dash overuse** - Use sparingly, prefer commas or periods\n9. **Sycophantic tone** - No \"Great question!\", \"You're absolutely right!\", excessive enthusiasm\n10. **Generic conclusions** - Cut \"The future looks bright\", \"exciting times ahead\", \"journey toward excellence\"\n\n### What TO DO:\n\n- **Be specific** - Use actual numbers, names, dates from the blog content\n- **Vary rhythm** - Mix short punchy sentences with longer explanatory ones\n- **Have opinions** - React to the data, don't just report it neutrally\n- **Add personality** - Sound like a real person wrote this, with genuine insights\n- **Use simple verbs** - \"is\" beats \"serves as\", \"has\" beats \"boasts\", \"shows\" beats \"demonstrates\"\n- **Keep it concrete** - Replace vague claims with specific examples from the blog\n\n### Before/After Examples:\n\n‚ùå \"This groundbreaking approach serves as a testament to innovation, ensuring developers accomplish goals efficiently while fostering collaboration\"\n\n‚úÖ \"This approach cut our review time from 60 to 6 minutes. Our team shipped the feature in 3 days instead of 2 weeks.\"\n\n‚ùå \"The landscape of software development is evolving rapidly, and it's crucial to delve into these transformative methodologies\"\n\n‚úÖ \"Most teams still review AI code the old way. That's why they're not seeing the speed gains.\"\n\n‚ùå \"Additionally, this highlights the pivotal role of...\"\n\n‚úÖ \"Here's what actually made the difference:\"\n\n---\n\n## Japanese LinkedIn Voice Guidelines (Êó•Êú¨Ë™ûÊäïÁ®ø„ÅÆ„Ç¨„Ç§„Éâ)\n\nFor Japanese posts, use professional business Japanese with these characteristics:\n\n**Tone & Style:**\n- Use Êï¨Ë™û (polite Japanese) but not overly formal\n- Professional yet approachable („Åß„Åô„Éª„Åæ„ÅôË™ø)\n- Technical content with clear explanations\n- Avoid overly casual expressions\n\n**Structure:**\n- Start with the article title\n- Lead with a compelling fact or insight\n- Use bullet points with numbers (‚ë†‚ë°‚ë¢) or emojis\n- Include key technical points from the blog\n- End with article link: Ë©≥Á¥∞„ÅØ„Åì„Å°„Çâ: [BLOG_BASE_URL]/blog/[SLUG]\n- Add relevant hashtags in English (LinkedIn convention)\n- Include engagement CTA: „ÅîÊÑèË¶ã„Çí„ÅäËÅû„Åã„Åõ„Åè„Å†„Åï„ÅÑ üí¨\n\n**Example Japanese Post Structure:**\n```\n[„Çø„Ç§„Éà„É´]\n\n[Âºï„Åç„Å§„Åë„ÇãÁµ±Ë®à„Éá„Éº„Çø„ÇÑÂïèÈ°åÊèêËµ∑]\n\nÊú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅ‰ª•‰∏ã„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Åæ„ÅôÔºö\n\nüéØ [„Éù„Ç§„É≥„Éà1]\nüí° [„Éù„Ç§„É≥„Éà2]\n‚ö° [„Éù„Ç§„É≥„Éà3]\n‚úÖ [„Éù„Ç§„É≥„Éà4]\n\nÈáçË¶Å„Å™Ê¥ûÂØüÔºö[ÂÖ∑‰ΩìÁöÑ„Å™Êï∞ÂÄ§„ÇÑqualitative takeaway]\n\nË©≥Á¥∞„ÅØ„Åì„Å°„ÇâÔºö[BLOG_BASE_URL]/blog/[SLUG]\n\n„ÅîÊÑèË¶ã„Çí„ÅäËÅû„Åã„Åõ„Åè„Å†„Åï„ÅÑ üí¨\n\n#LangChain #AI„Ç®„Éº„Ç∏„Çß„É≥„Éà #„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÈñãÁô∫\n```\n\n---\n\n## Example Flow\n\n### English Post Example:\nUser: \"Create LinkedIn draft for 2025-10-06-production-ai-agents-langchain\"\n\n1. Read `src/content/blog/posts/en/2025-10-06-production-ai-agents-langchain.md`\n2. Extract key insights from the actual content\n3. Generate contextual, intelligent English commentary\n4. Check for LinkedIn credentials in `.env` (guide through OAuth if needed)\n5. Use `curl` to create LinkedIn draft via REST API\n6. Open LinkedIn in browser: `open https://www.linkedin.com/feed/`\n6. Report with clear next actions:\n   ```\n   ‚úÖ LinkedIn draft created and browser opened!\n\n   Next Steps:\n   1. LinkedIn is now open in your browser\n   2. Look for the draft post (may be at top of feed)\n   3. Review the auto-generated content\n   4. Make any final edits\n   5. Click \"Post\" when ready!\n\n   Note: PDF with diagrams was automatically attached\n   ```\n\n### Japanese Post Example:\nUser: \"Create LinkedIn draft for 2025-10-06-production-ai-agents-langchain ja\"\n\n1. Detect language: Japanese (ja)\n2. Read `src/content/blog/posts/ja/2025-10-06-production-ai-agents-langchain.md`\n3. Extract key insights from the Japanese blog content\n4. Generate contextual Japanese commentary (Êï¨Ë™û style)\n5. Check for LinkedIn credentials in `.env` (guide through OAuth if needed)\n6. Use `curl` to create LinkedIn draft via REST API\n7. Open LinkedIn in browser: `open https://www.linkedin.com/feed/`\n7. Report with clear next actions:\n   ```\n   ‚úÖ LinkedIn draft created! üáØüáµ Browser opened!\n\n   Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó:\n   1. LinkedIn„Åå„Éñ„É©„Ç¶„Ç∂„ÅßÈñã„Åã„Çå„Åæ„Åó„Åü\n   2. ‰∏ãÊõ∏„Åç„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà„Éï„Ç£„Éº„Éâ„ÅÆ‰∏äÈÉ®„Å´„ÅÇ„Çä„Åæ„ÅôÔºâ\n   3. ÂÜÖÂÆπ„Çí„É¨„Éì„É•„Éº„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n   4. ÂøÖË¶Å„Å´Âøú„Åò„Å¶Á∑®ÈõÜ„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n   5. Ê∫ñÂÇô„Åå„Åß„Åç„Åü„Çâ„ÄåÊäïÁ®ø„Äç„Çí„ÇØ„É™„ÉÉ„ÇØÔºÅ\n\n   Ê≥®: „ÉÄ„Ç§„Ç¢„Ç∞„É©„É†‰ªò„ÅçPDF„ÅØËá™ÂãïÁöÑ„Å´Ê∑ª‰ªò„Åï„Çå„Å¶„ÅÑ„Åæ„Åô\n   ```\n",
        "publisher-plugin/commands/medium.md": "---\ndescription: Convert any content source to Medium-ready format\nargument-hint: <input>\n---\n\nConvert any content source to Medium-ready format. This command is **adaptive** - it works with any input format and blog structure.\n\n**Usage:** `$ARGUMENTS`\n\n## Phase 1: Universal Input Detection\n\n**Parse Input:**\n- Extract content input from `$ARGUMENTS`\n- Examples:\n  - `2025-10-06-my-post` (slug)\n  - `path/to/article.md` (file path)\n  - `https://myblog.com/post` (URL)\n\n**Detect and Load Content:**\n\n**If input looks like a file path** (contains `/` or file extension):\n- Use Read tool to load the file\n- Detect format by extension:\n  - `.md` / `.mdx` ‚Üí Parse markdown with frontmatter\n  - `.pdf` ‚Üí Inform user PDF parsing is limited, suggest markdown\n  - `.html` ‚Üí Extract main content, strip HTML tags\n  - `.txt` ‚Üí Read as plain text\n  - `.json` ‚Üí Parse and extract relevant fields\n\n**If input looks like a URL** (starts with `http://` or `https://`):\n- Use WebFetch tool to retrieve the page\n- Extract main article content, title, and description\n- Parse and clean the text\n\n**If input is a slug** (no `/` and no protocol):\n- Search codebase using Glob: `**/*${input}*.md`\n- Common blog locations:\n  - `src/content/blog/posts/**/*${input}*.md`\n  - `content/blog/*${input}*.md`\n  - `posts/*${input}*.md`\n  - `blog/*${input}*.md`\n- Use Read tool to parse found markdown file\n\n**Discover Blog Structure (if slug or file path):**\nExplore the codebase to understand:\n- üìÅ Where are markdown files stored?\n- üìã What frontmatter format is used?\n- üñºÔ∏è Where are images/diagrams stored?\n- üé® How are images referenced? (relative paths, absolute URLs, picture elements?)\n- üîó What's the blog post URL structure?\n\n**For URLs:** Extract and use the content as-is, skip blog structure discovery.\n\n## Phase 2: Create Conversion Script\n\nWrite a **custom TypeScript conversion script** that handles their specific structure.\n\n### Required Outputs (Universal Medium Best Practices):\n\n**1. Image Handling - Upload Markers (CRITICAL)**\n```typescript\n// Medium strips base64 and external URLs fail\n// Solution: Add clear upload marker for FIRST image only\n// IMPORTANT: Only include the FIRST image from the blog post\nreturn `\\n\\n---\\n\\n**üìä [UPLOAD IMAGE HERE: ${altText}]**\\n\\n*File: \\`${relPath}\\`*\\n\\n---\\n\\n`;\n```\n\n**2. References Format - Paragraphs Not Lists**\n```typescript\n// Medium adds blank numbers in lists\n// Solution: Format as individual paragraphs\nreferences.forEach(ref => {\n  output += `\\n\\n**[${ref.number}]** ${ref.content}`;\n});\n```\n\n**3. Footnotes - Inline Citations**\n```typescript\n// Convert [^1] to inline: [Author, Year, Source]\ntext.replace(/\\[\\^(\\d+)\\]/g, (match, num) => {\n  return ` [${footnotes[num]}]`;\n});\n```\n\n**4. Preview HTML with One-Click Copy**\n```typescript\n// Create HTML with simple one-click copy functionality\nconst previewHTML = generateOneClickCopyHTML(content);\nfs.writeFileSync(previewPath, previewHTML);\n\n// Auto-open in browser\nexec(`${openCommand} \"${previewPath}\"`);\n\n// Also open Medium editor\nexec(`${openCommand} \"https://medium.com/new-story\"`);\n```\n\n**5. Attribution Footer - Specific URL**\n```typescript\n// Link to SPECIFIC blog post, not homepage\nconst blogPostURL = `${baseURL}/blog/${slug}`;\nhtml += `<p><em>Originally published at <a href=\"${blogPostURL}\">${siteName}</a></em></p>`;\n```\n\n**6. Clean HTML Conversion**\n```typescript\n// Use marked.js with:\nmarked.setOptions({\n  gfm: true,\n  breaks: false,\n  headerIds: false,\n  mangle: false\n});\n```\n\n### One-Click Copy HTML Template\n\nGenerate an HTML with beautiful, simple one-click copy functionality:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Medium Article - One Click Copy</title>\n  <style>\n    /* Modern gradient background */\n    body { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }\n\n    /* Big prominent copy button */\n    .copy-button {\n      background: #03a87c;\n      color: white;\n      padding: 15px 40px;\n      border-radius: 30px;\n      font-size: 18px;\n      font-weight: bold;\n      cursor: pointer;\n      transition: all 0.3s;\n    }\n\n    .copy-button:hover {\n      transform: translateY(-2px);\n      box-shadow: 0 5px 15px rgba(3,168,124,0.3);\n    }\n\n    /* Content box is clickable */\n    .content-box {\n      background: white;\n      padding: 40px;\n      border-radius: 12px;\n      cursor: pointer;\n      position: relative;\n    }\n\n    .content-box::before {\n      content: \"Click anywhere to copy\";\n      position: absolute;\n      top: 10px;\n      right: 10px;\n      background: #f0f0f0;\n      padding: 5px 10px;\n      border-radius: 5px;\n      font-size: 12px;\n    }\n\n    /* Success notification */\n    .status-message {\n      position: fixed;\n      top: 20px;\n      left: 50%;\n      transform: translateX(-50%);\n      background: #4caf50;\n      color: white;\n      padding: 15px 30px;\n      border-radius: 30px;\n      opacity: 0;\n      transition: opacity 0.3s;\n    }\n\n    .status-message.show { opacity: 1; }\n  </style>\n</head>\n<body>\n  <div class=\"header\">\n    <button class=\"copy-button\" onclick=\"copyContent()\">\n      üìã Copy Article to Clipboard\n    </button>\n    <p>Or click anywhere in the content box below</p>\n  </div>\n\n  <div class=\"content-box\" onclick=\"copyContent()\">\n    <!-- Article content here -->\n  </div>\n\n  <div class=\"status-message\" id=\"statusMessage\">\n    ‚úÖ Content copied to clipboard!\n  </div>\n\n  <script>\n    function copyContent() {\n      const content = document.querySelector('.article-content').innerText;\n      navigator.clipboard.writeText(content).then(() => {\n        document.getElementById('statusMessage').classList.add('show');\n        setTimeout(() => {\n          document.getElementById('statusMessage').classList.remove('show');\n        }, 3000);\n      });\n    }\n  </script>\n</body>\n</html>\n```\n\n### Script Template Structure:\n\n```typescript\nimport fs from 'fs';\nimport path from 'path';\nimport { marked } from 'marked';\n\nconst BLOG_BASE_URL = 'USER_PROVIDED_URL';\n\ninterface BlogMetadata {\n  title: string;\n  description: string;\n  // ... detected fields\n}\n\nfunction parseBlogPost(filePath: string) {\n  // Parse their specific frontmatter format\n}\n\nfunction convertImages(markdown: string, imagePath: string) {\n  // Handle THEIR image format\n  // Always output: upload markers\n}\n\nfunction formatReferences(markdown: string) {\n  // Extract references section\n  // Always output: paragraphs with [N] prefix\n}\n\nfunction convertToMedium(markdown: string, slug: string) {\n  // Apply all universal fixes\n  // Return clean HTML\n}\n\nfunction generatePreviewHTML(content: string, metadata: BlogMetadata) {\n  return `<!DOCTYPE html>\n<html>\n<head>\n  <title>Medium Preview: ${metadata.title}</title>\n  <style>/* Clean, readable styling */</style>\n</head>\n<body>\n  <div class=\"instructions\">\n    <h2>üìã How to Copy to Medium</h2>\n    <ol>\n      <li>Select all (Cmd/Ctrl+A)</li>\n      <li>Copy (Cmd/Ctrl+C)</li>\n      <li>Paste into Medium editor (Cmd/Ctrl+V)</li>\n      <li>Upload images at markers</li>\n      <li>Delete marker text after uploading</li>\n      <li>Publish!</li>\n    </ol>\n  </div>\n  <div id=\"content\">${content}</div>\n</body>\n</html>`;\n}\n\nasync function main() {\n  // Parse blog post with their structure\n  // Convert with universal Medium fixes\n  // Generate preview and auto-open\n}\n```\n\n## Phase 3: Execute & Guide\n\n1. **Run the generated script** OR **Create HTML directly with Write tool**\n   - If using Write tool directly for preview HTML:\n     - **IMPORTANT**: Check if `medium-article-[LANG].html` exists first: `ls -la medium-article-[LANG].html 2>&1`\n     - If exists, use Read tool first (even just 1 line): `Read('medium-article-[LANG].html', limit=1)`\n     - Then use Write tool to create/update the file\n2. **Verify preview opens** in browser\n3. **Provide instructions:**\n   - How many images to upload\n   - Where each diagram file is located\n   - Copy-paste workflow\n\n## Critical Success Factors\n\n‚úÖ **Image markers must be clear** - User needs exact file paths\n‚úÖ **References as paragraphs** - Avoid Medium's numbered list bugs\n‚úÖ **Preview auto-opens** - Streamlined workflow\n‚úÖ **Specific blog URL** - Not just homepage\n‚úÖ **Clean formatting** - No extra blank lines or artifacts\n‚úÖ **Humanized content** - Apply `/humanizer` skill to remove AI patterns\n\n---\n\n## Humanization Guidelines\n\n**CRITICAL**: When converting content for Medium, apply the `/humanizer` skill principles to ensure the article sounds human-written:\n\n### Patterns to DETECT and FIX:\n\n1. **Inflated significance** - Replace \"stands as a testament to\", \"pivotal moment\" with concrete facts\n2. **Promotional language** - Cut \"groundbreaking\", \"revolutionary\", \"stunning\" - use specific outcomes instead\n3. **AI vocabulary** - Remove \"Additionally\", \"Moreover\", \"delve\", \"landscape\", \"tapestry\", \"crucial\"\n4. **Vague attributions** - Replace \"experts believe\" with specific citations or remove\n5. **Superficial -ing phrases** - Cut \"highlighting the importance of\", \"showcasing the potential\"\n6. **Rule of three abuse** - Break up forced triplets into natural phrasing\n7. **Negative parallelisms** - Rewrite \"It's not just X, it's Y\" as direct statements\n8. **Em dash overuse** - Replace excessive em dashes with commas or periods\n9. **Copula avoidance** - Use \"is\" instead of \"serves as\", \"has\" instead of \"boasts\"\n10. **Generic conclusions** - Replace \"the future looks bright\" with specific next steps\n\n### Conversion Process Enhancement:\n\nWhen creating the Medium article:\n1. Scan the source content for AI writing patterns\n2. Rewrite problematic phrases with natural alternatives\n3. Preserve the core meaning while improving readability\n4. Add specific details from the source where vague language existed\n5. Vary sentence structure naturally\n\n### Before/After Examples:\n\n‚ùå \"This comprehensive guide serves as a testament to the evolving landscape of modern development practices\"\n\n‚úÖ \"This guide covers four development approaches we've tested on production projects\"\n\n‚ùå \"Additionally, it's crucial to delve into the intricacies of this transformative methodology\"\n\n‚úÖ \"Here's how the method works in practice:\"\n\n## Testing Checklist\n\nAfter conversion, verify:\n- [ ] Preview HTML opens automatically\n- [ ] All images have upload markers with file paths\n- [ ] References section has no blank numbers\n- [ ] Footer links to specific blog post URL\n- [ ] Footnotes converted to inline citations\n- [ ] Code blocks preserved\n- [ ] No HTML artifacts (picture tags removed, etc.)\n- [ ] Content is humanized (no AI vocabulary, inflated claims, or generic conclusions)\n\n## Example Interaction\n\n```\nUser: /convert-to-medium\nYou: Which blog post would you like to convert? (provide path or slug)\nUser: src/posts/2024-01-15-my-post.md\nYou: What's your blog's base URL? (e.g., https://myblog.com)\nUser: https://myblog.com\n\n[You explore their codebase]\n\nYou: I found:\n- Markdown files in: src/posts/\n- Images in: public/images/\n- Frontmatter format: YAML with title, date, tags\n- URL structure: /posts/{slug}\n\nCreating conversion script...\n\n[Generate and run custom script]\n\n‚úÖ Preview & Medium editor opened!\n- Title: My Post\n- 3 images to upload (markers added)\n- References formatted as paragraphs\n- Footer links to: https://myblog.com/posts/2024-01-15-my-post\n\nSUPER SIMPLE Next Steps:\n1. Click the BIG GREEN BUTTON (or click anywhere in content box) to copy\n2. Switch to Medium tab and paste (Cmd/Ctrl+V)\n3. Upload 3 images at the clearly marked spots\n4. Publish!\n```\n\n## Key Differences from Hardcoded Script\n\n‚ùå **Old way**: Hardcoded paths, specific to Kanaeru\n‚úÖ **New way**: Discovers structure, adapts to any blog\n\n‚ùå **Old way**: One script for one blog\n‚úÖ **New way**: Generate custom script per blog\n\n‚ùå **Old way**: User needs to modify code\n‚úÖ **New way**: User just provides blog post + URL\n\n## Universal Best Practices (Always Apply)\n\nThese work for ANY blog, ANY structure:\n\n1. **Images** ‚Üí Upload markers (Medium limitation)\n2. **References** ‚Üí Paragraphs (Medium bug workaround)\n3. **Footnotes** ‚Üí Inline citations (Medium doesn't support footnotes)\n4. **Preview** ‚Üí Auto-open (UX improvement)\n5. **Footer** ‚Üí Specific URL (proper attribution)\n6. **HTML** ‚Üí Clean, minimal (Medium compatibility)\n\nBe thorough in exploring their blog structure. Generate clean, working code. Test the output before declaring success.\n",
        "publisher-plugin/commands/x.md": "---\ndescription: Generate a copy-pastable X thread from any content source\nargument-hint: <input> [lang]\ntags: [x, social, blog, thread, i18n]\n---\n\nGenerate a copy-pastable X thread from any content source - blog posts, articles, PDFs, URLs, or plain text.\n\n**Usage:** `$ARGUMENTS`\n\n**Process:**\n\n1. **Parse Input Arguments**\n   - Extract content input and optional language parameter\n   - Examples:\n     - `2025-10-06-my-post` (slug only, default English)\n     - `2025-10-06-my-post ja` (slug with Japanese)\n     - `path/to/article.md` (file path)\n     - `https://myblog.com/post` (URL)\n     - `docs/whitepaper.pdf en` (PDF with language)\n\n2. **Universal Input Detection**\n\n   **If input looks like a file path** (contains `/` or file extension):\n   - Use Read tool to check if file exists\n   - Detect format by extension:\n     - `.md` / `.mdx` ‚Üí Parse markdown with frontmatter (extract title, description, body, metadata)\n     - `.pdf` ‚Üí Inform user PDF parsing is limited, suggest converting to markdown first\n     - `.docx` ‚Üí Inform user DOCX parsing is limited, suggest converting to markdown first\n     - `.html` ‚Üí Read and extract main content, strip HTML tags\n     - `.txt` ‚Üí Read as plain text\n     - `.json` ‚Üí Parse JSON and extract relevant fields\n   - Extract: title, description, body content, metadata\n\n   **If input looks like a URL** (starts with `http://` or `https://`):\n   - Use WebFetch tool to retrieve the page\n   - Prompt: \"Extract the main article content, title, and description from this page\"\n   - Parse and clean the text\n\n   **If input is a slug** (no `/` and no protocol):\n   - Search codebase using Glob: `**/*${input}*.md`\n   - Common patterns to check:\n     - `src/content/blog/posts/{en,ja}/*${input}*.md`\n     - `content/blog/*${input}*.md`\n     - `posts/*${input}*.md`\n     - `blog/*${input}*.md`\n   - If language specified, prioritize matching language folder\n   - Use Read tool to parse markdown file with frontmatter\n\n3. **Determine Language** (default: English):\n   - If user explicitly specifies \"ja\" ‚Üí Japanese\n   - If user explicitly specifies \"en\" ‚Üí English\n   - If file path contains `/ja/` ‚Üí Japanese\n   - If content appears to be in Japanese ‚Üí Japanese\n   - Otherwise ‚Üí English\n\n4. **Generate THREE versions** in the target language:\n\n   **Version 1: Thread (5-8 posts)**\n   - **For English**: Follow Kanaeru Labs' X voice (see guidelines below)\n   - **For Japanese**: Use professional yet accessible Japanese tone\n   - Break into digestible posts (max 280 chars each)\n\n   **Version 2: Single Long (Premium)**\n   - Structured format with clear sections\n   - **For Japanese**: Use „Äêbrackets„Äë: „Äê„Å®„ÅØ„Äë„ÄêË™∞„ÅÆ„Åü„ÇÅ„Äë„Äê‰∏ª„Å™ÁâπÂæ¥„Äë„ÄêÊ¨°„Å´„Åô„Åπ„Åç„Åì„Å®„Äë\n   - **For English**: Use headers: **What it is:** **Who it's for:** **Key features:** **What to do next:**\n\n   **Version 3: Single Short (~280 chars)**\n   - Concise announcement\n   - 2-3 key benefits with emojis\n   - Links and hashtags\n\n5. **Generate all three versions directly** using Claude's built-in capabilities:\n   - Read the blog content using Read tool\n   - Extract key insights and stats from the content\n   - Create all 3 versions following the guidelines below\n   - Validate character counts\n   - **PURE CLAUDE - NO external scripts, NO npm, NO dependencies**\n   - **APPLY HUMANIZATION** (see Humanization Guidelines below)\n\n6. **Display all versions** to the user in terminal:\n   - Show thread posts with character counts\n   - Show single long version\n   - Show single short version\n   - Format for easy copy-pasting\n\n7. **Create tri-format HTML preview file** using Write tool:\n   - **IMPORTANT**: Check if file exists first: `ls -la x-thread-[LANG].html 2>&1`\n   - If file exists, use Read tool first (even just 1 line): `Read('x-thread-[LANG].html', limit=1)`\n   - Then use Write tool to create/update: `x-thread-[LANG].html` in user's current directory\n   - **Include THREE tabs with tab switcher UI**:\n     - **Tab 1: Thread** - 5-8 posts with individual \"Copy Post\" buttons\n     - **Tab 2: Single Long** - Structured format with sections, one \"Copy\" button\n     - **Tab 3: Single Short** - Concise version (~280 chars), one \"Copy\" button\n   - Use X branding (black theme)\n   - Tab switcher at top for easy navigation\n   - Use Bash tool to open: `open x-thread-[LANG].html && open https://x.com/compose/post`\n   - Works in ANY repo type (Python, Rust, Go, etc.)\n\n   **User benefits:** Choose the format that fits their audience!\n\n---\n\n## X Thread Guidelines\n\n### Thread Structure (5-8 tweets):\n\n1. **Hook Tweet** (Tweet 1/X)\n   - Grab attention with a contrarian statement, stat, or bold claim\n   - Don't give away everything - create curiosity\n   - NO hashtags or links in first tweet (better algorithm reach)\n   - Max 280 chars including thread indicator\n\n2. **Problem/Context Tweets** (Tweets 2-3/X)\n   - Set up the problem or context\n   - Use specific data points from the blog\n   - Keep each tweet to ONE idea\n   - Max 280 chars each\n\n3. **Insight Tweets** (Tweets 4-6/X)\n   - Share 3-5 key insights from the blog\n   - Use bullet points (‚Ä¢) or numbered lists\n   - Include specific examples or stats\n   - Make each tweet self-contained\n   - Max 280 chars each\n\n4. **CTA Tweet** (Final tweet)\n   - Link to the full article (auto-detect from blog structure or use: https://www.kanaeru.ai/blog/[SLUG])\n   - Simple CTA: \"Read the full guide:\" or \"Full breakdown:\"\n   - Can include 2-3 relevant hashtags here\n   - Encourage engagement: \"What's your take?\"\n   - **Note**: For non-kanaeru blogs, omit URL or use placeholder \"[BLOG URL]\"\n\n---\n\n## Writing Style Guidelines\n\n**Tone:**\n- Conversational but authoritative\n- Use \"you\" to make it personal\n- Short sentences for readability\n- Active voice preferred\n\n**Formatting:**\n- Use line breaks for readability\n- Emojis sparingly (max 1-2 per tweet)\n- Numbers/stats for credibility\n- Avoid jargon unless necessary\n\n**Thread Numbering:**\n- Include \"(1/6)\" style numbering in EVERY tweet\n- Count MUST be accurate\n- Place at the end of each tweet\n\n**Character Limits:**\n- Each post: MAX 280 characters (including thread number)\n- Account for URL shortening: URLs = 23 chars on X\n- Leave buffer of 10-15 chars for safety\n\n---\n\n## Humanization Guidelines\n\n**CRITICAL**: All generated content MUST sound human, not AI-generated. Apply the `/humanizer` skill principles:\n\n### Patterns to AVOID:\n\n1. **Inflated significance** - Don't say \"stands as a testament to\", \"pivotal moment\", \"game-changer\"\n2. **Promotional language** - Avoid \"groundbreaking\", \"revolutionary\", \"stunning\", \"breathtaking\"\n3. **AI vocabulary overuse** - Cut \"Additionally\", \"Moreover\", \"delve\", \"landscape\", \"tapestry\", \"crucial\"\n4. **Vague attributions** - No \"experts believe\", \"industry reports show\" without specifics\n5. **Superficial -ing phrases** - Remove \"highlighting the importance of\", \"showcasing the potential\"\n6. **Rule of three abuse** - Don't force \"innovation, inspiration, and industry insights\"\n7. **Negative parallelisms** - Avoid \"It's not just X, it's Y\" constructions\n8. **Em dash overuse** - Use sparingly, prefer commas or periods\n9. **Sycophantic tone** - No \"Great question!\", \"You're absolutely right!\"\n10. **Generic conclusions** - Cut \"The future looks bright\", \"exciting times ahead\"\n\n### What TO DO:\n\n- **Be specific** - Use actual numbers, names, dates from the content\n- **Vary rhythm** - Mix short punchy sentences with longer ones\n- **Have opinions** - React to facts, don't just report them\n- **Add personality** - Let some edge or humor through when appropriate\n- **Use simple verbs** - \"is\" beats \"serves as\", \"has\" beats \"boasts\"\n- **Keep it concrete** - Replace vague claims with specific examples\n\n### Before/After Examples:\n\n‚ùå \"This groundbreaking approach serves as a testament to innovation, ensuring developers accomplish goals efficiently\"\n\n‚úÖ \"This approach cuts review time from 60 minutes to 6. Beta testers shipped 3x faster.\"\n\n‚ùå \"It's not just about speed‚Äîit's about fundamentally transforming how we think about development\"\n\n‚úÖ \"Speed matters less than reviewability. Fast code that takes hours to review is slower than clear code.\"\n\n---\n\n## Example English Thread Structure\n\n```\nTweet 1/6:\nAI agents can generate 1,000 lines of code in 60 seconds.\n\nBut humans need 60 minutes to review it.\n\nThis is the new bottleneck in software development that nobody's talking about. (1/6)\n\nTweet 2/6:\n88% of senior executives plan to increase AI budgets in 2025.\n\nYet fewer than 45% are rethinking their operating models.\n\nThe result? AI-generated \"workslop\" that creates 2 hours of rework per instance. (2/6)\n\nTweet 3/6:\nWe've identified four dominant build models in the AI era:\n\n‚Ä¢ Traditional development (slow)\n‚Ä¢ AI-assisted coding (faster)\n‚Ä¢ Spec-Driven Development (clear)\n‚Ä¢ Review-Driven Design (optimal)\n\nMost teams are stuck between 1 and 2. (3/6)\n\nTweet 4/6:\nReview-Driven Design (RDD) flips the script:\n\nInstead of optimizing for coding speed, optimize for REVIEW speed.\n\nRDD code can be reviewed 10x faster: 60 mins ‚Üí 6 mins.\n\nThat's where the real productivity gains hide. (4/6)\n\nTweet 5/6:\nThe gap between AI adopters and AI adapters is widening:\n\nAdopters: Use AI tools\nAdapters: Transform their entire delivery model\n\nOne is incrementally faster.\nThe other is fundamentally different. (5/6)\n\nTweet 6/6:\nFull breakdown of all four build models, the hidden economics, and why review speed is the new bottleneck:\n\nhttps://www.kanaeru.ai/blog/2025-10-06-choosing-your-build-model-agent-era-rdd-wins\n\nWhich approach is your team using? (6/6)\n\n#AI #SoftwareDevelopment #DevOps\n```\n\n---\n\n## Japanese Thread Guidelines (Êó•Êú¨Ë™û„Çπ„É¨„ÉÉ„Éâ„ÅÆ„Ç¨„Ç§„Éâ)\n\n**Tone & Style:**\n- Professional yet accessible („Åß„Åô„Éª„Åæ„ÅôË™ø or „Å†„Éª„Åß„ÅÇ„ÇãË™ø)\n- Technical content with clear explanations\n- Less formal than LinkedIn, more conversational\n- Use technical terms in English where appropriate\n\n**Thread Structure:**\n- Same 5-8 post structure as English\n- Use emojis more liberally (Japanese X culture)\n- Include article link in final post\n- Hashtags in English (better reach)\n\n**Example Japanese Hook:**\n```\nAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ60Áßí„Åß1,000Ë°å„ÅÆ„Ç≥„Éº„Éâ„ÇíÁîüÊàê„Åß„Åç„Åæ„Åô„ÄÇ\n\n„Åß„ÇÇ‰∫∫Èñì„Åå„Åù„Çå„Çí„É¨„Éì„É•„Éº„Åô„Çã„Å´„ÅØ60ÂàÜ„Åã„Åã„Çä„Åæ„Åô„ÄÇ\n\n„Åì„Çå„Åå2025Âπ¥„ÅÆ„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÈñãÁô∫„Å´„Åä„Åë„ÇãÊñ∞„Åó„ÅÑ„Éú„Éà„É´„Éç„ÉÉ„ÇØ„Åß„Åô„ÄÇ (1/6)\n```\n\n---\n\n## Single Post Guidelines (Premium Accounts)\n\n### Long Version - Structured Format\n\n**For Japanese** - Use „Äêbracket sections„Äë:\n```\n[Title] üöÄ\n\n„Äê[Product]„Å®„ÅØ„Äë\n[2-3 sentence description]\n\n„ÄêË™∞„ÅÆ„Åü„ÇÅ„Äë\n‚úÖ [Target user 1]\n‚úÖ [Target user 2]\n‚úÖ [Target user 3]\n\n„Äê‰∏ª„Å™ÁâπÂæ¥„Äë\n‚Ä¢ [Feature 1]\n‚Ä¢ [Feature 2]\n\n„ÄêÊôÇÈñìÁØÄÁ¥Ñ/„É°„É™„ÉÉ„Éà„Äë\n‚Ä¢ [Metric 1]\n‚Ä¢ [Metric 2]\n\n„ÄêÊ¨°„Å´„Åô„Åπ„Åç„Åì„Å®„Äë\n1. [Step 1]\n2. [Step 2]\n\nË©≥Á¥∞: [Blog URL]\nGitHub: [Repo URL]\n\n#Hashtags\n```\n\n**For English** - Use clear headers:\n```\n[Title] üöÄ\n\n**What it is:**\n[2-3 sentence description]\n\n**Who it's for:**\n‚úÖ [Target user 1]\n‚úÖ [Target user 2]\n\n**Key features:**\n‚Ä¢ [Feature 1]\n‚Ä¢ [Feature 2]\n\n**Time savings:**\n‚Ä¢ [Metric 1]\n‚Ä¢ [Metric 2]\n\n**What to do next:**\n1. [Step 1]\n2. [Step 2]\n\nFull guide: [Blog URL]\nGitHub: [Repo URL]\n\n#Hashtags\n```\n\n### Short Version - Concise (~280 chars)\n\n**Structure:**\n- Title + emoji\n- 1-line description\n- 2-3 key benefits (emojis)\n- Blog link\n- 2-3 hashtags\n\n**Japanese Example:**\n```\n[Product] v1.0 „É™„É™„Éº„ÇπüöÄ\n[One-line description]\n‚úÖ [Benefit 1]\n‚úÖ [Benefit 2]\n‚úÖ [Benefit 3]\n[URL]\n#Hashtags\n```\n\n---\n\n## Thread Generation Checklist\n\nGenerate X thread that:\n- ‚úÖ Starts with an attention-grabbing hook (no links/hashtags)\n- ‚úÖ Maintains one clear idea per tweet\n- ‚úÖ Stays under 280 chars per tweet (including thread number)\n- ‚úÖ Uses actual insights/stats from the blog post\n- ‚úÖ Numbers tweets correctly (1/6, 2/6, etc.)\n- ‚úÖ Includes blog URL only in final tweet\n- ‚úÖ Ends with engagement question\n- ‚úÖ Uses line breaks for readability\n- ‚úÖ Adds relevant hashtags (2-4) only in final tweet\n- ‚úÖ Is immediately copy-pastable\n\n**IMPORTANT**: Read the blog post content to extract real insights, not generic placeholders!\n\n---\n\n## Example Flow\n\n### English Thread Example:\nUser: \"Create X thread for 2025-10-06-production-ai-agents-langchain\"\n\n1. Read `src/content/blog/posts/en/2025-10-06-production-ai-agents-langchain.md`\n2. Extract key insights from the actual content\n3. Generate engaging 6-7 post thread directly (using Claude's LLM)\n4. Create HTML preview file: `x-thread-en.html` (using Write tool)\n5. Open preview and X.com (using Bash: `open x-thread-en.html && open https://x.com/compose/post`)\n6. Display formatted thread with character counts\n7. Provide copy-paste instructions\n\n### Japanese Thread Example:\nUser: \"Create X thread for 2025-10-06-production-ai-agents-langchain ja\"\n\n1. Detect language: Japanese (ja)\n2. Read `src/content/blog/posts/ja/2025-10-06-production-ai-agents-langchain.md`\n3. Extract key insights from the Japanese blog content\n4. Generate Japanese thread directly (using Claude's LLM)\n5. Create HTML preview file: `x-thread-ja.html` (using Write tool)\n6. Open preview and X.com (using Bash)\n7. Display formatted thread in Japanese with character counts\n8. Provide copy-paste instructions\n\n---\n\n## Output Format\n\nThe script should output in this format:\n\n```\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n‚úÖ X Thread Generated & Browser Tabs Opened!\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nüìÑ Blog: [Blog Title]\nüßµ Thread Length: 6 posts\nüåê Language: English üá∫üá∏\n\nüìã NEXT STEPS (Super Simple):\n  1Ô∏è‚É£ HTML preview opened with \"Copy Post\" buttons\n  2Ô∏è‚É£ X.com opened in new tab for posting\n  3Ô∏è‚É£ Click \"Copy Post\" for each post\n  4Ô∏è‚É£ Paste into X and create your thread\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüìù POST 1/6 (267 chars)\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n[Post content here...]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüìù POST 2/6 (245 chars)\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n[Post content here...]\n\n[... etc for all posts ...]\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n‚ö° QUICK POSTING OPTIONS:\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nOption 1: Use HTML Preview (Recommended)\n  ‚Ü≥ Click \"Copy Post\" buttons in the HTML file\n  ‚Ü≥ Paste each post on X\n\nOption 2: Manual Copy from Terminal\n  ‚Ü≥ Copy each post from above\n  ‚Ü≥ Post to X one by one\n\nOption 3: X Thread Composer\n  ‚Ü≥ Copy entire thread at once\n  ‚Ü≥ X will auto-split at line breaks!\n\nüí° PRO TIP: The HTML preview makes posting 10x faster!\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n```\n\n---\n\n## HTML Preview Template\n\nAfter displaying the thread in the terminal, create an HTML file for easy copying:\n\n**File Location:** `x-thread-en.html` or `x-thread-ja.html` in project root\n\n**HTML Structure:**\n- Clean, modern design with X branding (black color scheme)\n- Each post in its own card with:\n  - Post number badge (1/7, 2/7, etc.)\n  - Post content (preserving line breaks)\n  - Character count\n  - \"Copy Post\" button that copies to clipboard\n- Instructions section at bottom\n- Responsive design for mobile/desktop\n\n**After creating the file:**\n```bash\nopen x-thread-[LANG].html\n```\n\nThis opens the HTML file in the user's default browser for easy copying.\n"
      },
      "plugins": [
        {
          "name": "publisher",
          "source": "./publisher-plugin",
          "description": "Content distribution toolkit - X/Twitter threads, LinkedIn posts, Medium articles. Accepts any input format (markdown, PDF, URL, etc.)",
          "version": "1.0.0",
          "author": {
            "name": "Kanaeru Labs",
            "email": "support@kanaeru.ai",
            "url": "https://www.kanaeru.ai"
          },
          "homepage": "https://github.com/kanaerulabs/growth-kit",
          "repository": "https://github.com/kanaerulabs/growth-kit",
          "license": "MIT",
          "keywords": [
            "blog",
            "marketing",
            "social-media",
            "twitter",
            "linkedin",
            "medium",
            "content"
          ],
          "commands": [
            "./commands/x.md",
            "./commands/linkedin.md",
            "./commands/medium.md",
            "./commands/devto.md",
            "./commands/all.md"
          ],
          "strict": false,
          "categories": [
            "blog",
            "content",
            "linkedin",
            "marketing",
            "medium",
            "social-media",
            "twitter"
          ],
          "install_commands": [
            "/plugin marketplace add kanaerulabs/growth-kit",
            "/plugin install publisher@growth-kit-marketplace"
          ]
        },
        {
          "name": "analytics",
          "source": "./analytics-plugin",
          "description": "Web analytics and tracking toolkit - Vercel Analytics, Google Analytics, and more",
          "version": "1.0.0",
          "author": {
            "name": "Kanaeru Labs",
            "email": "support@kanaeru.ai",
            "url": "https://www.kanaeru.ai"
          },
          "homepage": "https://github.com/kanaerulabs/growth-kit",
          "repository": "https://github.com/kanaerulabs/growth-kit",
          "license": "MIT",
          "keywords": [
            "analytics",
            "tracking",
            "vercel",
            "metrics"
          ],
          "commands": [
            "./commands/vercel.md"
          ],
          "strict": false,
          "categories": [
            "analytics",
            "metrics",
            "tracking",
            "vercel"
          ],
          "install_commands": [
            "/plugin marketplace add kanaerulabs/growth-kit",
            "/plugin install analytics@growth-kit-marketplace"
          ]
        }
      ]
    }
  ]
}