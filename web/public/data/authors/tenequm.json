{
  "author": {
    "id": "tenequm",
    "display_name": "Misha Kolesnik",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/22403766?u=d72822b5c4d208509445eeeac39307b2983c93aa&v=4",
    "url": "https://github.com/tenequm",
    "bio": "Building Cascade Protocol • Payment infrastructure for Solana • @opwizardx",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 12,
      "total_commands": 1,
      "total_skills": 15,
      "total_stars": 12,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "tenequm-plugins",
      "version": null,
      "description": "Claude Code plugins with mostly skills for founders, developers, and web3 builders",
      "owner_info": {
        "name": "Misha Kolesnik",
        "email": "misha@kolesnik.io"
      },
      "keywords": [],
      "repo_full_name": "tenequm/claude-plugins",
      "repo_url": "https://github.com/tenequm/claude-plugins",
      "repo_description": "Plugin marketplace for Claude Code",
      "homepage": "",
      "signals": {
        "stars": 12,
        "forks": 0,
        "pushed_at": "2026-01-25T20:10:50Z",
        "created_at": "2025-11-05T16:34:52Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 4174
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/release.md",
          "type": "blob",
          "size": 4194
        },
        {
          "path": ".claude/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/skill-creator/SKILL.md",
          "type": "blob",
          "size": 12825
        },
        {
          "path": ".claude/skills/skill-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/skill-creator/references/best-practices.md",
          "type": "blob",
          "size": 37964
        },
        {
          "path": ".claude/skills/skill-creator/references/overview.md",
          "type": "blob",
          "size": 14380
        },
        {
          "path": ".claude/skills/skill-creator/references/quickstart.md",
          "type": "blob",
          "size": 13333
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1787
        },
        {
          "path": "chrome-extension-wxt",
          "type": "tree",
          "size": null
        },
        {
          "path": "chrome-extension-wxt/README.md",
          "type": "blob",
          "size": 572
        },
        {
          "path": "chrome-extension-wxt/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "chrome-extension-wxt/skill/SKILL.md",
          "type": "blob",
          "size": 8439
        },
        {
          "path": "cloudflare-workers",
          "type": "tree",
          "size": null
        },
        {
          "path": "cloudflare-workers/README.md",
          "type": "blob",
          "size": 537
        },
        {
          "path": "cloudflare-workers/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "cloudflare-workers/skill/SKILL.md",
          "type": "blob",
          "size": 12847
        },
        {
          "path": "founder-playbook",
          "type": "tree",
          "size": null
        },
        {
          "path": "founder-playbook/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "founder-playbook/skill/SKILL.md",
          "type": "blob",
          "size": 23253
        },
        {
          "path": "foundry-solidity",
          "type": "tree",
          "size": null
        },
        {
          "path": "foundry-solidity/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "foundry-solidity/skill/SKILL.md",
          "type": "blob",
          "size": 7753
        },
        {
          "path": "gh-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "gh-cli/README.md",
          "type": "blob",
          "size": 546
        },
        {
          "path": "gh-cli/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "gh-cli/skill/SKILL.md",
          "type": "blob",
          "size": 6026
        },
        {
          "path": "impactful-writing",
          "type": "tree",
          "size": null
        },
        {
          "path": "impactful-writing/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "impactful-writing/skill/SKILL.md",
          "type": "blob",
          "size": 10710
        },
        {
          "path": "skill-factory",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-factory/README.md",
          "type": "blob",
          "size": 4841
        },
        {
          "path": "skill-factory/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-factory/skill/SKILL.md",
          "type": "blob",
          "size": 12324
        },
        {
          "path": "skill-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-finder/README.md",
          "type": "blob",
          "size": 542
        },
        {
          "path": "skill-finder/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-finder/skill/SKILL.md",
          "type": "blob",
          "size": 15214
        },
        {
          "path": "solana",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/README.md",
          "type": "blob",
          "size": 1144
        },
        {
          "path": "solana/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-compression",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-compression/SKILL.md",
          "type": "blob",
          "size": 10773
        },
        {
          "path": "solana/skills/solana-compression/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-compression/references/client-integration.md",
          "type": "blob",
          "size": 11236
        },
        {
          "path": "solana/skills/solana-compression/references/compressed-accounts.md",
          "type": "blob",
          "size": 7635
        },
        {
          "path": "solana/skills/solana-compression/references/compressed-pdas.md",
          "type": "blob",
          "size": 11752
        },
        {
          "path": "solana/skills/solana-compression/references/compressed-tokens.md",
          "type": "blob",
          "size": 8751
        },
        {
          "path": "solana/skills/solana-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-development/SKILL.md",
          "type": "blob",
          "size": 15283
        },
        {
          "path": "solana/skills/solana-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-development/references/accounts.md",
          "type": "blob",
          "size": 25387
        },
        {
          "path": "solana/skills/solana-development/references/anchor.md",
          "type": "blob",
          "size": 34742
        },
        {
          "path": "solana/skills/solana-development/references/builtin-programs.md",
          "type": "blob",
          "size": 22344
        },
        {
          "path": "solana/skills/solana-development/references/compute-optimization.md",
          "type": "blob",
          "size": 19820
        },
        {
          "path": "solana/skills/solana-development/references/cpi.md",
          "type": "blob",
          "size": 20927
        },
        {
          "path": "solana/skills/solana-development/references/deployment.md",
          "type": "blob",
          "size": 40972
        },
        {
          "path": "solana/skills/solana-development/references/durable-nonces.md",
          "type": "blob",
          "size": 27012
        },
        {
          "path": "solana/skills/solana-development/references/error-handling.md",
          "type": "blob",
          "size": 19004
        },
        {
          "path": "solana/skills/solana-development/references/native-rust.md",
          "type": "blob",
          "size": 45014
        },
        {
          "path": "solana/skills/solana-development/references/pda.md",
          "type": "blob",
          "size": 20990
        },
        {
          "path": "solana/skills/solana-development/references/production-deployment.md",
          "type": "blob",
          "size": 13420
        },
        {
          "path": "solana/skills/solana-development/references/resources.md",
          "type": "blob",
          "size": 8985
        },
        {
          "path": "solana/skills/solana-development/references/security.md",
          "type": "blob",
          "size": 14137
        },
        {
          "path": "solana/skills/solana-development/references/serialization.md",
          "type": "blob",
          "size": 14198
        },
        {
          "path": "solana/skills/solana-development/references/surfpool.md",
          "type": "blob",
          "size": 12330
        },
        {
          "path": "solana/skills/solana-development/references/sysvars.md",
          "type": "blob",
          "size": 23689
        },
        {
          "path": "solana/skills/solana-development/references/testing-frameworks.md",
          "type": "blob",
          "size": 30362
        },
        {
          "path": "solana/skills/solana-development/references/testing-overview.md",
          "type": "blob",
          "size": 12800
        },
        {
          "path": "solana/skills/solana-development/references/testing-practices.md",
          "type": "blob",
          "size": 12928
        },
        {
          "path": "solana/skills/solana-development/references/tokens-2022.md",
          "type": "blob",
          "size": 5278
        },
        {
          "path": "solana/skills/solana-development/references/tokens-operations.md",
          "type": "blob",
          "size": 23117
        },
        {
          "path": "solana/skills/solana-development/references/tokens-overview.md",
          "type": "blob",
          "size": 8444
        },
        {
          "path": "solana/skills/solana-development/references/tokens-patterns.md",
          "type": "blob",
          "size": 22208
        },
        {
          "path": "solana/skills/solana-development/references/tokens-validation.md",
          "type": "blob",
          "size": 5691
        },
        {
          "path": "solana/skills/solana-development/references/transaction-lifecycle.md",
          "type": "blob",
          "size": 26356
        },
        {
          "path": "solana/skills/solana-development/references/versioned-transactions.md",
          "type": "blob",
          "size": 28737
        },
        {
          "path": "solana/skills/solana-security",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-security/SKILL.md",
          "type": "blob",
          "size": 10116
        },
        {
          "path": "solana/skills/solana-security/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "solana/skills/solana-security/references/anchor-security.md",
          "type": "blob",
          "size": 27579
        },
        {
          "path": "solana/skills/solana-security/references/caveats.md",
          "type": "blob",
          "size": 11353
        },
        {
          "path": "solana/skills/solana-security/references/native-security.md",
          "type": "blob",
          "size": 28238
        },
        {
          "path": "solana/skills/solana-security/references/resources.md",
          "type": "blob",
          "size": 9055
        },
        {
          "path": "solana/skills/solana-security/references/security-checklists.md",
          "type": "blob",
          "size": 9231
        },
        {
          "path": "solana/skills/solana-security/references/security-fundamentals.md",
          "type": "blob",
          "size": 27528
        },
        {
          "path": "solana/skills/solana-security/references/vulnerability-patterns.md",
          "type": "blob",
          "size": 12794
        },
        {
          "path": "styling-with-tailwind",
          "type": "tree",
          "size": null
        },
        {
          "path": "styling-with-tailwind/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "styling-with-tailwind/skill/SKILL.md",
          "type": "blob",
          "size": 11797
        },
        {
          "path": "tanstack-query",
          "type": "tree",
          "size": null
        },
        {
          "path": "tanstack-query/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "tanstack-query/skill/SKILL.md",
          "type": "blob",
          "size": 14719
        },
        {
          "path": "uv-ruff-python-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "uv-ruff-python-tools/README.md",
          "type": "blob",
          "size": 512
        },
        {
          "path": "uv-ruff-python-tools/skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "uv-ruff-python-tools/skill/SKILL.md",
          "type": "blob",
          "size": 8865
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"tenequm-plugins\",\n  \"owner\": {\n    \"name\": \"Misha Kolesnik\",\n    \"email\": \"misha@kolesnik.io\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code plugins with mostly skills for founders, developers, and web3 builders\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"gh-cli\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Full GitHub CLI capabilities for repos & code\",\n      \"version\": \"1.1.0\",\n      \"skills\": [\n        \"./gh-cli/skill\"\n      ]\n    },\n    {\n      \"name\": \"chrome-extension-wxt\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Build Chrome extensions with WXT framework\",\n      \"version\": \"1.1.0\",\n      \"skills\": [\n        \"./chrome-extension-wxt/skill\"\n      ]\n    },\n    {\n      \"name\": \"cloudflare-workers\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Rapid development with Cloudflare Workers - build and deploy serverless applications\",\n      \"version\": \"2.0.0\",\n      \"skills\": [\n        \"./cloudflare-workers/skill\"\n      ]\n    },\n    {\n      \"name\": \"skill-finder\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Find and evaluate Claude skills using semantic search and quality assessment\",\n      \"version\": \"1.1.0\",\n      \"skills\": [\n        \"./skill-finder/skill\"\n      ]\n    },\n    {\n      \"name\": \"skill-factory\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Autonomous skill creation with automatic quality assurance - analyzes requests, selects optimal creation method, and delivers production-ready skills\",\n      \"version\": \"0.2.0\",\n      \"skills\": [\n        \"./skill-factory/skill\"\n      ]\n    },\n    {\n      \"name\": \"uv-ruff-python-tools\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Modern Python development with uv (10-100x faster package manager) and ruff (extremely fast linter/formatter) - Astral's fast tooling suite\",\n      \"version\": \"0.1.0\",\n      \"skills\": [\n        \"./uv-ruff-python-tools/skill\"\n      ]\n    },\n    {\n      \"name\": \"solana\",\n      \"source\": \"./solana\",\n      \"description\": \"Comprehensive Solana development toolkit: build programs with Anchor/native Rust and audit for security vulnerabilities\",\n      \"version\": \"0.5.0\"\n    },\n    {\n      \"name\": \"styling-with-tailwind\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Build beautiful UIs with Tailwind CSS and shadcn/ui - modern utility-first styling, component patterns, and Tailwind v4.1 features\",\n      \"version\": \"0.1.0\",\n      \"skills\": [\n        \"./styling-with-tailwind/skill\"\n      ]\n    },\n    {\n      \"name\": \"tanstack-query\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Master TanStack Query (React Query) v5 for server state management in React applications\",\n      \"version\": \"0.1.0\",\n      \"skills\": [\n        \"./tanstack-query/skill\"\n      ]\n    },\n    {\n      \"name\": \"founder-playbook\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Decision validation and thinking frameworks for startup founders - pressure-test decisions with proven methodologies and crypto/web3 knowledge\",\n      \"version\": \"0.1.1\",\n      \"author\": {\n        \"name\": \"Misha Kolesnik\",\n        \"email\": \"misha@kolesnik.io\"\n      },\n      \"homepage\": \"https://github.com/tenequm/claude-plugins\",\n      \"repository\": \"https://github.com/tenequm/claude-plugins\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"founder\",\n        \"startup\",\n        \"coaching\",\n        \"web3\",\n        \"solana\",\n        \"decision-making\"\n      ],\n      \"skills\": [\n        \"./founder-playbook/skill\"\n      ]\n    },\n    {\n      \"name\": \"foundry-solidity\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Build and test Solidity smart contracts with Foundry toolkit (Forge, Cast, Anvil) - testing patterns, deployment scripts, and modern Solidity 0.8.30\",\n      \"version\": \"0.1.0\",\n      \"skills\": [\n        \"./foundry-solidity/skill\"\n      ]\n    },\n    {\n      \"name\": \"impactful-writing\",\n      \"source\": \"./\",\n      \"description\": \"Skill: Write clear, emotionally resonant, and well-structured content across any platform - research-backed principles for Twitter, articles, docs, emails, and more\",\n      \"version\": \"0.1.0\",\n      \"skills\": [\n        \"./impactful-writing/skill\"\n      ]\n    }\n  ]\n}\n",
        ".claude/commands/release.md": "# Release Skills\n\nExecute a release using Nx Release for independent plugin versioning.\n\n## Pre-flight Checks\n\n1. **Check working tree is clean:**\n   ```bash\n   git status --porcelain\n   ```\n   If not clean, stop and report dirty files.\n\n2. **Check we're on main branch:**\n   ```bash\n   git branch --show-current\n   ```\n   Must be `main`.\n\n3. **Ensure local is up to date with remote:**\n   ```bash\n   git fetch origin\n   git status -sb\n   ```\n   If behind, run `git pull --rebase`.\n\n4. **Check for unreleased changes:**\n   ```bash\n   pnpm nx release --dry-run\n   ```\n   This will show which plugins have unreleased commits.\n\n## Release Process\n\n### Option 1: Release All Changed Plugins (Recommended)\n\n```bash\n# Interactive release - prompts for version bump per plugin\npnpm nx release\n```\n\nThis will:\n1. Run validation (cached, fast)\n2. Prompt for version bump for each changed plugin (major/minor/patch)\n3. Update package.json files\n4. Generate project-level CHANGELOG.md files\n5. Sync marketplace.json (via postChangelogCommand hook)\n6. Create commit: `chore(release): plugin-name@version`\n7. Create git tags: `plugin-name@version`\n8. Push to GitHub\n9. Create GitHub releases with changelog content\n10. Prompt to publish (if needed)\n\n### Option 2: Release Specific Version\n\n```bash\n# Automatically bump to specific version for all changed plugins\npnpm nx release patch   # or minor, major\n```\n\n### Option 3: Release Specific Plugins\n\n```bash\n# Release only specific plugins\npnpm nx release --projects=solana,gh-cli\n```\n\n### Option 4: Preview First (Dry Run)\n\n```bash\n# See what would happen without making changes\npnpm nx release --dry-run\n```\n\n## Non-Interactive Mode (Claude Code / CI)\n\nTo bypass interactive prompts:\n\n- **Version specifier** (`minor`/`patch`/`major`) - bypasses version prompt\n- **`--first-release`** - required for new plugins at version 0.0.0\n\nPublishing is disabled in `nx.json` (`\"publish\": false`), so no publish flags needed.\n\n```bash\n# Example: patch release\npnpm nx release patch --projects=plugin-name\n\n# Example: first release of a new plugin\npnpm nx release minor --projects=new-plugin --first-release\n```\n\nIf pre-commit hooks modify files and the commit fails, stage changes and commit manually, then create tags and GitHub releases.\n\n## Post-Release\n\nAfter the release completes, Nx will:\n- ✅ Create version commits\n- ✅ Create git tags (pattern: `plugin-name@version`)\n- ✅ Push commits and tags to GitHub\n- ✅ Create GitHub releases with changelog content (as drafts initially)\n\n**Publish GitHub Releases:**\n\nIf releases are created as drafts, publish them:\n```bash\n# List draft releases\ngh release list --limit 10\n\n# Publish a draft release\ngh release edit plugin-name@version --draft=false\n```\n\n**Report summary:**\nList all released packages with their versions and links to GitHub releases.\n\n## Release Configuration\n\nAll release configuration is in `nx.json`:\n- **Independent versioning**: Each plugin has its own version\n- **Git tags**: `{projectName}@{version}` pattern\n- **Changelogs**: Generated in each plugin's CHANGELOG.md\n- **GitHub releases**: Automatic with changelog content\n- **Validation**: Runs before versioning (cached)\n- **Marketplace sync**: Automatic via `postChangelogCommand`\n\n## Error Handling\n\n- If any step fails, Nx will stop immediately and report the error\n- Do NOT force push or skip any checks\n- If validation fails, fix the issues before releasing\n- Nx creates one commit per release, with all version changes\n\n## Important Notes\n\n- Nx Release uses conventional commits to generate changelogs\n- Tags follow the pattern: `plugin-name@version` (e.g., `solana@0.3.0`)\n- GitHub releases are created automatically from CHANGELOG content\n- Local caching makes repeated validation instant\n- Affected detection only releases plugins with changes since last tag\n\n## Common Commands\n\n```bash\n# Release workflow (full)\npnpm nx release\n\n# Just version (no publish)\npnpm nx release version\n\n# Just changelog (after versioning)\npnpm nx release changelog\n\n# Just publish (after versioning)\npnpm nx release publish\n\n# Target specific plugins\npnpm nx release --projects=solana\n\n# Preview without changes\npnpm nx release --dry-run\n```\n",
        ".claude/skills/skill-creator/SKILL.md": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks—they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### Anthropic's Official Best Practices\n\nFor comprehensive guidance on creating effective skills, see:\n\n- **[references/overview.md](references/overview.md)** - Complete overview of Agent Skills architecture, progressive disclosure, and how Skills work across different platforms (API, Claude Code, Agent SDK, claude.ai)\n- **[references/quickstart.md](references/quickstart.md)** - Quick tutorial on using pre-built Agent Skills in the Claude API with practical code examples\n- **[references/best-practices.md](references/best-practices.md)** - Detailed authoring best practices including:\n  - Core principles (conciseness, degrees of freedom, model testing)\n  - Skill structure and naming conventions\n  - Progressive disclosure patterns\n  - Workflows and feedback loops\n  - Evaluation and iteration strategies\n  - Common patterns and anti-patterns\n  - Advanced topics for Skills with executable code\n\nThese references provide Anthropic's official guidance and should be consulted when creating production-quality skills.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation intended to be loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n**Important**: Consult [references/best-practices.md](references/best-practices.md) for detailed authoring guidance on writing effective descriptions, organizing content with progressive disclosure, creating workflows, and avoiding common anti-patterns.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Packaging a Skill\n\nOnce the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n",
        ".claude/skills/skill-creator/references/best-practices.md": "# Skill authoring best practices\n\nLearn how to write effective Skills that Claude can discover and use successfully.\n\nGood Skills are concise, well-structured, and tested with real usage. This guide provides practical authoring decisions to help you write Skills that Claude can discover and use effectively.\n\n## Core principles\n\n### Concise is key\n\nThe context window is a public good. Your Skill shares the context window with everything else Claude needs to know, including:\n- The system prompt\n- Conversation history\n- Other Skills' metadata\n- Your actual request\n\nNot every token in your Skill has an immediate cost. At startup, only the metadata (name and description) from all Skills is pre-loaded. Claude reads SKILL.md only when the Skill becomes relevant, and reads additional files only as needed. However, being concise in SKILL.md still matters: once Claude loads it, every token competes with conversation history and other context.\n\n**Default assumption**: Claude is already very smart\n\nOnly add context Claude doesn't already have. Challenge each piece of information:\n- \"Does Claude really need this explanation?\"\n- \"Can I assume Claude knows this?\"\n- \"Does this paragraph justify its token cost?\"\n\n**Good example: Concise** (approximately 50 tokens):\n````markdown\n## Extract PDF text\n\nUse pdfplumber for text extraction:\n\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n````\n\n**Bad example: Too verbose** (approximately 150 tokens):\n```markdown\n## Extract PDF text\n\nPDF (Portable Document Format) files are a common file format that contains\ntext, images, and other content. To extract text from a PDF, you'll need to\nuse a library. There are many libraries available for PDF processing, but we\nrecommend pdfplumber because it's easy to use and handles most cases well.\nFirst, you'll need to install it using pip. Then you can use the code below...\n```\n\nThe concise version assumes Claude knows what PDFs are and how libraries work.\n\n### Set appropriate degrees of freedom\n\nMatch the level of specificity to the task's fragility and variability.\n\n**High freedom** (text-based instructions):\n\nUse when:\n- Multiple approaches are valid\n- Decisions depend on context\n- Heuristics guide the approach\n\nExample:\n```markdown\n## Code review process\n\n1. Analyze the code structure and organization\n2. Check for potential bugs or edge cases\n3. Suggest improvements for readability and maintainability\n4. Verify adherence to project conventions\n```\n\n**Medium freedom** (pseudocode or scripts with parameters):\n\nUse when:\n- A preferred pattern exists\n- Some variation is acceptable\n- Configuration affects behavior\n\nExample:\n````markdown\n## Generate report\n\nUse this template and customize as needed:\n\n```python\ndef generate_report(data, format=\"markdown\", include_charts=True):\n    # Process data\n    # Generate output in specified format\n    # Optionally include visualizations\n```\n````\n\n**Low freedom** (specific scripts, few or no parameters):\n\nUse when:\n- Operations are fragile and error-prone\n- Consistency is critical\n- A specific sequence must be followed\n\nExample:\n````markdown\n## Database migration\n\nRun exactly this script:\n\n```bash\npython scripts/migrate.py --verify --backup\n```\n\nDo not modify the command or add additional flags.\n````\n\n**Analogy**: Think of Claude as a robot exploring a path:\n- **Narrow bridge with cliffs on both sides**: There's only one safe way forward. Provide specific guardrails and exact instructions (low freedom). Example: database migrations that must run in exact sequence.\n- **Open field with no hazards**: Many paths lead to success. Give general direction and trust Claude to find the best route (high freedom). Example: code reviews where context determines the best approach.\n\n### Test with all models you plan to use\n\nSkills act as additions to models, so effectiveness depends on the underlying model. Test your Skill with all the models you plan to use it with.\n\n**Testing considerations by model**:\n- **Claude Haiku** (fast, economical): Does the Skill provide enough guidance?\n- **Claude Sonnet** (balanced): Is the Skill clear and efficient?\n- **Claude Opus** (powerful reasoning): Does the Skill avoid over-explaining?\n\nWhat works perfectly for Opus might need more detail for Haiku. If you plan to use your Skill across multiple models, aim for instructions that work well with all of them.\n\n## Skill structure\n\n### Naming conventions\n\nUse consistent naming patterns to make Skills easier to reference and discuss. We recommend using **gerund form** (verb + -ing) for Skill names, as this clearly describes the activity or capability the Skill provides.\n\nRemember that the `name` field must use lowercase letters, numbers, and hyphens only.\n\n**Good naming examples (gerund form)**:\n- `processing-pdfs`\n- `analyzing-spreadsheets`\n- `managing-databases`\n- `testing-code`\n- `writing-documentation`\n\n**Acceptable alternatives**:\n- Noun phrases: `pdf-processing`, `spreadsheet-analysis`\n- Action-oriented: `process-pdfs`, `analyze-spreadsheets`\n\n**Avoid**:\n- Vague names: `helper`, `utils`, `tools`\n- Overly generic: `documents`, `data`, `files`\n- Reserved words: `anthropic-helper`, `claude-tools`\n- Inconsistent patterns within your skill collection\n\nConsistent naming makes it easier to:\n- Reference Skills in documentation and conversations\n- Understand what a Skill does at a glance\n- Organize and search through multiple Skills\n- Maintain a professional, cohesive skill library\n\n### Writing effective descriptions\n\nThe `description` field enables Skill discovery and should include both what the Skill does and when to use it.\n\n**Always write in third person**. The description is injected into the system prompt, and inconsistent point-of-view can cause discovery problems.\n\n- **Good:** \"Processes Excel files and generates reports\"\n- **Avoid:** \"I can help you process Excel files\"\n- **Avoid:** \"You can use this to process Excel files\"\n\n**Be specific and include key terms**. Include both what the Skill does and specific triggers/contexts for when to use it.\n\nEach Skill has exactly one description field. The description is critical for skill selection: Claude uses it to choose the right Skill from potentially 100+ available Skills. Your description must provide enough detail for Claude to know when to select this Skill, while the rest of SKILL.md provides the implementation details.\n\nEffective examples:\n\n**PDF Processing skill:**\n```yaml\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n**Excel Analysis skill:**\n```yaml\ndescription: Analyze Excel spreadsheets, create pivot tables, generate charts. Use when analyzing Excel files, spreadsheets, tabular data, or .xlsx files.\n```\n\n**Git Commit Helper skill:**\n```yaml\ndescription: Generate descriptive commit messages by analyzing git diffs. Use when the user asks for help writing commit messages or reviewing staged changes.\n```\n\nAvoid vague descriptions like these:\n\n```yaml\ndescription: Helps with documents\n```\n```yaml\ndescription: Processes data\n```\n```yaml\ndescription: Does stuff with files\n```\n\n### Progressive disclosure patterns\n\nSKILL.md serves as an overview that points Claude to detailed materials as needed, like a table of contents in an onboarding guide.\n\n**Practical guidance:**\n- Keep SKILL.md body under 500 lines for optimal performance\n- Split content into separate files when approaching this limit\n- Use the patterns below to organize instructions, code, and resources effectively\n\n#### Visual overview: From simple to complex\n\nA basic Skill starts with just a SKILL.md file containing metadata and instructions.\n\nAs your Skill grows, you can bundle additional content that Claude loads only when needed. The complete Skill directory structure might look like this:\n\n```\npdf/\n├── SKILL.md              # Main instructions (loaded when triggered)\n├── FORMS.md              # Form-filling guide (loaded as needed)\n├── reference.md          # API reference (loaded as needed)\n├── examples.md           # Usage examples (loaded as needed)\n└── scripts/\n    ├── analyze_form.py   # Utility script (executed, not loaded)\n    ├── fill_form.py      # Form filling script\n    └── validate.py       # Validation script\n```\n\n#### Pattern 1: High-level guide with references\n\n````markdown\n---\nname: pdf-processing\ndescription: Extracts text and tables from PDF files, fills forms, and merges documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n---\n\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n```python\nimport pdfplumber\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n\n## Advanced features\n\n**Form filling**: See [FORMS.md](FORMS.md) for complete guide\n**API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n**Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n````\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n#### Pattern 2: Domain-specific organization\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context. When a user asks about sales metrics, Claude only needs to read sales-related schemas, not finance or marketing data. This keeps token usage low and context focused.\n\n```\nbigquery-skill/\n├── SKILL.md (overview and navigation)\n└── reference/\n    ├── finance.md (revenue, billing metrics)\n    ├── sales.md (opportunities, pipeline)\n    ├── product.md (API usage, features)\n    └── marketing.md (campaigns, attribution)\n```\n\n````markdown SKILL.md\n# BigQuery Data Analysis\n\n## Available datasets\n\n**Finance**: Revenue, ARR, billing → See [reference/finance.md](reference/finance.md)\n**Sales**: Opportunities, pipeline, accounts → See [reference/sales.md](reference/sales.md)\n**Product**: API usage, features, adoption → See [reference/product.md](reference/product.md)\n**Marketing**: Campaigns, attribution, email → See [reference/marketing.md](reference/marketing.md)\n\n## Quick search\n\nFind specific metrics using grep:\n\n```bash\ngrep -i \"revenue\" reference/finance.md\ngrep -i \"pipeline\" reference/sales.md\ngrep -i \"api usage\" reference/product.md\n```\n````\n\n#### Pattern 3: Conditional details\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n### Avoid deeply nested references\n\nClaude may partially read files when they're referenced from other referenced files. When encountering nested references, Claude might use commands like `head -100` to preview content rather than reading entire files, resulting in incomplete information.\n\n**Keep references one level deep from SKILL.md**. All reference files should link directly from SKILL.md to ensure Claude reads complete files when needed.\n\n**Bad example: Too deep**:\n```markdown\n# SKILL.md\nSee [advanced.md](advanced.md)...\n\n# advanced.md\nSee [details.md](details.md)...\n\n# details.md\nHere's the actual information...\n```\n\n**Good example: One level deep**:\n```markdown\n# SKILL.md\n\n**Basic usage**: [instructions in SKILL.md]\n**Advanced features**: See [advanced.md](advanced.md)\n**API reference**: See [reference.md](reference.md)\n**Examples**: See [examples.md](examples.md)\n```\n\n### Structure longer reference files with table of contents\n\nFor reference files longer than 100 lines, include a table of contents at the top. This ensures Claude can see the full scope of available information even when previewing with partial reads.\n\n**Example**:\n```markdown\n# API Reference\n\n## Contents\n- Authentication and setup\n- Core methods (create, read, update, delete)\n- Advanced features (batch operations, webhooks)\n- Error handling patterns\n- Code examples\n\n## Authentication and setup\n...\n\n## Core methods\n...\n```\n\nClaude can then read the complete file or jump to specific sections as needed.\n\n## Workflows and feedback loops\n\n### Use workflows for complex tasks\n\nBreak complex operations into clear, sequential steps. For particularly complex workflows, provide a checklist that Claude can copy into its response and check off as it progresses.\n\n**Example 1: Research synthesis workflow** (for Skills without code):\n\n````markdown\n## Research synthesis workflow\n\nCopy this checklist and track your progress:\n\n```\nResearch Progress:\n- [ ] Step 1: Read all source documents\n- [ ] Step 2: Identify key themes\n- [ ] Step 3: Cross-reference claims\n- [ ] Step 4: Create structured summary\n- [ ] Step 5: Verify citations\n```\n\n**Step 1: Read all source documents**\n\nReview each document in the `sources/` directory. Note the main arguments and supporting evidence.\n\n**Step 2: Identify key themes**\n\nLook for patterns across sources. What themes appear repeatedly? Where do sources agree or disagree?\n\n**Step 3: Cross-reference claims**\n\nFor each major claim, verify it appears in the source material. Note which source supports each point.\n\n**Step 4: Create structured summary**\n\nOrganize findings by theme. Include:\n- Main claim\n- Supporting evidence from sources\n- Conflicting viewpoints (if any)\n\n**Step 5: Verify citations**\n\nCheck that every claim references the correct source document. If citations are incomplete, return to Step 3.\n````\n\nThis example shows how workflows apply to analysis tasks that don't require code. The checklist pattern works for any complex, multi-step process.\n\n**Example 2: PDF form filling workflow** (for Skills with code):\n\n````markdown\n## PDF form filling workflow\n\nCopy this checklist and check off items as you complete them:\n\n```\nTask Progress:\n- [ ] Step 1: Analyze the form (run analyze_form.py)\n- [ ] Step 2: Create field mapping (edit fields.json)\n- [ ] Step 3: Validate mapping (run validate_fields.py)\n- [ ] Step 4: Fill the form (run fill_form.py)\n- [ ] Step 5: Verify output (run verify_output.py)\n```\n\n**Step 1: Analyze the form**\n\nRun: `python scripts/analyze_form.py input.pdf`\n\nThis extracts form fields and their locations, saving to `fields.json`.\n\n**Step 2: Create field mapping**\n\nEdit `fields.json` to add values for each field.\n\n**Step 3: Validate mapping**\n\nRun: `python scripts/validate_fields.py fields.json`\n\nFix any validation errors before continuing.\n\n**Step 4: Fill the form**\n\nRun: `python scripts/fill_form.py input.pdf fields.json output.pdf`\n\n**Step 5: Verify output**\n\nRun: `python scripts/verify_output.py output.pdf`\n\nIf verification fails, return to Step 2.\n````\n\nClear steps prevent Claude from skipping critical validation. The checklist helps both Claude and you track progress through multi-step workflows.\n\n### Implement feedback loops\n\n**Common pattern**: Run validator → fix errors → repeat\n\nThis pattern greatly improves output quality.\n\n**Example 1: Style guide compliance** (for Skills without code):\n\n```markdown\n## Content review process\n\n1. Draft your content following the guidelines in STYLE_GUIDE.md\n2. Review against the checklist:\n   - Check terminology consistency\n   - Verify examples follow the standard format\n   - Confirm all required sections are present\n3. If issues found:\n   - Note each issue with specific section reference\n   - Revise the content\n   - Review the checklist again\n4. Only proceed when all requirements are met\n5. Finalize and save the document\n```\n\nThis shows the validation loop pattern using reference documents instead of scripts. The \"validator\" is STYLE_GUIDE.md, and Claude performs the check by reading and comparing.\n\n**Example 2: Document editing process** (for Skills with code):\n\n```markdown\n## Document editing process\n\n1. Make your edits to `word/document.xml`\n2. **Validate immediately**: `python ooxml/scripts/validate.py unpacked_dir/`\n3. If validation fails:\n   - Review the error message carefully\n   - Fix the issues in the XML\n   - Run validation again\n4. **Only proceed when validation passes**\n5. Rebuild: `python ooxml/scripts/pack.py unpacked_dir/ output.docx`\n6. Test the output document\n```\n\nThe validation loop catches errors early.\n\n## Content guidelines\n\n### Avoid time-sensitive information\n\nDon't include information that will become outdated:\n\n**Bad example: Time-sensitive** (will become wrong):\n```markdown\nIf you're doing this before August 2025, use the old API.\nAfter August 2025, use the new API.\n```\n\n**Good example** (use \"old patterns\" section):\n```markdown\n## Current method\n\nUse the v2 API endpoint: `api.example.com/v2/messages`\n\n## Old patterns\n\n<details>\n<summary>Legacy v1 API (deprecated 2025-08)</summary>\n\nThe v1 API used: `api.example.com/v1/messages`\n\nThis endpoint is no longer supported.\n</details>\n```\n\nThe old patterns section provides historical context without cluttering the main content.\n\n### Use consistent terminology\n\nChoose one term and use it throughout the Skill:\n\n**Good - Consistent**:\n- Always \"API endpoint\"\n- Always \"field\"\n- Always \"extract\"\n\n**Bad - Inconsistent**:\n- Mix \"API endpoint\", \"URL\", \"API route\", \"path\"\n- Mix \"field\", \"box\", \"element\", \"control\"\n- Mix \"extract\", \"pull\", \"get\", \"retrieve\"\n\nConsistency helps Claude understand and follow instructions.\n\n## Common patterns\n\n### Template pattern\n\nProvide templates for output format. Match the level of strictness to your needs.\n\n**For strict requirements** (like API responses or data formats):\n\n````markdown\n## Report structure\n\nALWAYS use this exact template structure:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[One-paragraph overview of key findings]\n\n## Key findings\n- Finding 1 with supporting data\n- Finding 2 with supporting data\n- Finding 3 with supporting data\n\n## Recommendations\n1. Specific actionable recommendation\n2. Specific actionable recommendation\n```\n````\n\n**For flexible guidance** (when adaptation is useful):\n\n````markdown\n## Report structure\n\nHere is a sensible default format, but use your best judgment based on the analysis:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[Overview]\n\n## Key findings\n[Adapt sections based on what you discover]\n\n## Recommendations\n[Tailor to the specific context]\n```\n\nAdjust sections as needed for the specific analysis type.\n````\n\n### Examples pattern\n\nFor Skills where output quality depends on seeing examples, provide input/output pairs just like in regular prompting:\n\n````markdown\n## Commit message format\n\nGenerate commit messages following these examples:\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly in reports\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n\n**Example 3:**\nInput: Updated dependencies and refactored error handling\nOutput:\n```\nchore: update dependencies and refactor error handling\n\n- Upgrade lodash to 4.17.21\n- Standardize error response format across endpoints\n```\n\nFollow this style: type(scope): brief description, then detailed explanation.\n````\n\nExamples help Claude understand the desired style and level of detail more clearly than descriptions alone.\n\n### Conditional workflow pattern\n\nGuide Claude through decision points:\n\n```markdown\n## Document modification workflow\n\n1. Determine the modification type:\n\n   **Creating new content?** → Follow \"Creation workflow\" below\n   **Editing existing content?** → Follow \"Editing workflow\" below\n\n2. Creation workflow:\n   - Use docx-js library\n   - Build document from scratch\n   - Export to .docx format\n\n3. Editing workflow:\n   - Unpack existing document\n   - Modify XML directly\n   - Validate after each change\n   - Repack when complete\n```\n\nIf workflows become large or complicated with many steps, consider pushing them into separate files and tell Claude to read the appropriate file based on the task at hand.\n\n## Evaluation and iteration\n\n### Build evaluations first\n\n**Create evaluations BEFORE writing extensive documentation.** This ensures your Skill solves real problems rather than documenting imagined ones.\n\n**Evaluation-driven development:**\n1. **Identify gaps**: Run Claude on representative tasks without a Skill. Document specific failures or missing context\n2. **Create evaluations**: Build three scenarios that test these gaps\n3. **Establish baseline**: Measure Claude's performance without the Skill\n4. **Write minimal instructions**: Create just enough content to address the gaps and pass evaluations\n5. **Iterate**: Execute evaluations, compare against baseline, and refine\n\nThis approach ensures you're solving actual problems rather than anticipating requirements that may never materialize.\n\n**Evaluation structure**:\n```json\n{\n  \"skills\": [\"pdf-processing\"],\n  \"query\": \"Extract all text from this PDF file and save it to output.txt\",\n  \"files\": [\"test-files/document.pdf\"],\n  \"expected_behavior\": [\n    \"Successfully reads the PDF file using an appropriate PDF processing library or command-line tool\",\n    \"Extracts text content from all pages in the document without missing any pages\",\n    \"Saves the extracted text to a file named output.txt in a clear, readable format\"\n  ]\n}\n```\n\nThis example demonstrates a data-driven evaluation with a simple testing rubric. Evaluations are your source of truth for measuring Skill effectiveness.\n\n### Develop Skills iteratively with Claude\n\nThe most effective Skill development process involves Claude itself. Work with one instance of Claude (\"Claude A\") to create a Skill that will be used by other instances (\"Claude B\"). Claude A helps you design and refine instructions, while Claude B tests them in real tasks. This works because Claude models understand both how to write effective agent instructions and what information agents need.\n\n**Creating a new Skill:**\n\n1. **Complete a task without a Skill**: Work through a problem with Claude A using normal prompting. As you work, you'll naturally provide context, explain preferences, and share procedural knowledge. Notice what information you repeatedly provide.\n\n2. **Identify the reusable pattern**: After completing the task, identify what context you provided that would be useful for similar future tasks.\n\n   **Example**: If you worked through a BigQuery analysis, you might have provided table names, field definitions, filtering rules (like \"always exclude test accounts\"), and common query patterns.\n\n3. **Ask Claude A to create a Skill**: \"Create a Skill that captures this BigQuery analysis pattern we just used. Include the table schemas, naming conventions, and the rule about filtering test accounts.\"\n\n   Claude models understand the Skill format and structure natively. You don't need special system prompts or a \"writing skills\" skill to get Claude to help create Skills. Simply ask Claude to create a Skill and it will generate properly structured SKILL.md content with appropriate frontmatter and body content.\n\n4. **Review for conciseness**: Check that Claude A hasn't added unnecessary explanations. Ask: \"Remove the explanation about what win rate means - Claude already knows that.\"\n\n5. **Improve information architecture**: Ask Claude A to organize the content more effectively. For example: \"Organize this so the table schema is in a separate reference file. We might add more tables later.\"\n\n6. **Test on similar tasks**: Use the Skill with Claude B (a fresh instance with the Skill loaded) on related use cases. Observe whether Claude B finds the right information, applies rules correctly, and handles the task successfully.\n\n7. **Iterate based on observation**: If Claude B struggles or misses something, return to Claude A with specifics: \"When Claude used this Skill, it forgot to filter by date for Q4. Should we add a section about date filtering patterns?\"\n\n**Iterating on existing Skills:**\n\nThe same hierarchical pattern continues when improving Skills. You alternate between:\n- **Working with Claude A** (the expert who helps refine the Skill)\n- **Testing with Claude B** (the agent using the Skill to perform real work)\n- **Observing Claude B's behavior** and bringing insights back to Claude A\n\n1. **Use the Skill in real workflows**: Give Claude B (with the Skill loaded) actual tasks, not test scenarios\n\n2. **Observe Claude B's behavior**: Note where it struggles, succeeds, or makes unexpected choices\n\n   **Example observation**: \"When I asked Claude B for a regional sales report, it wrote the query but forgot to filter out test accounts, even though the Skill mentions this rule.\"\n\n3. **Return to Claude A for improvements**: Share the current SKILL.md and describe what you observed. Ask: \"I noticed Claude B forgot to filter test accounts when I asked for a regional report. The Skill mentions filtering, but maybe it's not prominent enough?\"\n\n4. **Review Claude A's suggestions**: Claude A might suggest reorganizing to make rules more prominent, using stronger language like \"MUST filter\" instead of \"always filter\", or restructuring the workflow section.\n\n5. **Apply and test changes**: Update the Skill with Claude A's refinements, then test again with Claude B on similar requests\n\n6. **Repeat based on usage**: Continue this observe-refine-test cycle as you encounter new scenarios. Each iteration improves the Skill based on real agent behavior, not assumptions.\n\n**Gathering team feedback:**\n\n1. Share Skills with teammates and observe their usage\n2. Ask: Does the Skill activate when expected? Are instructions clear? What's missing?\n3. Incorporate feedback to address blind spots in your own usage patterns\n\n**Why this approach works**: Claude A understands agent needs, you provide domain expertise, Claude B reveals gaps through real usage, and iterative refinement improves Skills based on observed behavior rather than assumptions.\n\n### Observe how Claude navigates Skills\n\nAs you iterate on Skills, pay attention to how Claude actually uses them in practice. Watch for:\n\n- **Unexpected exploration paths**: Does Claude read files in an order you didn't anticipate? This might indicate your structure isn't as intuitive as you thought\n- **Missed connections**: Does Claude fail to follow references to important files? Your links might need to be more explicit or prominent\n- **Overreliance on certain sections**: If Claude repeatedly reads the same file, consider whether that content should be in the main SKILL.md instead\n- **Ignored content**: If Claude never accesses a bundled file, it might be unnecessary or poorly signaled in the main instructions\n\nIterate based on these observations rather than assumptions. The 'name' and 'description' in your Skill's metadata are particularly critical. Claude uses these when deciding whether to trigger the Skill in response to the current task. Make sure they clearly describe what the Skill does and when it should be used.\n\n## Anti-patterns to avoid\n\n### Avoid Windows-style paths\n\nAlways use forward slashes in file paths, even on Windows:\n\n- ✓ **Good**: `scripts/helper.py`, `reference/guide.md`\n- ✗ **Avoid**: `scripts\\helper.py`, `reference\\guide.md`\n\nUnix-style paths work across all platforms, while Windows-style paths cause errors on Unix systems.\n\n### Avoid offering too many options\n\nDon't present multiple approaches unless necessary:\n\n````markdown\n**Bad example: Too many choices** (confusing):\n\"You can use pypdf, or pdfplumber, or PyMuPDF, or pdf2image, or...\"\n\n**Good example: Provide a default** (with escape hatch):\n\"Use pdfplumber for text extraction:\n```python\nimport pdfplumber\n```\n\nFor scanned PDFs requiring OCR, use pdf2image with pytesseract instead.\"\n````\n\n## Advanced: Skills with executable code\n\n### Solve, don't punt\n\nWhen writing scripts for Skills, handle error conditions rather than punting to Claude.\n\n**Good example: Handle errors explicitly**:\n```python\ndef process_file(path):\n    \"\"\"Process a file, creating it if it doesn't exist.\"\"\"\n    try:\n        with open(path) as f:\n            return f.read()\n    except FileNotFoundError:\n        # Create file with default content instead of failing\n        print(f\"File {path} not found, creating default\")\n        with open(path, 'w') as f:\n            f.write('')\n        return ''\n    except PermissionError:\n        # Provide alternative instead of failing\n        print(f\"Cannot access {path}, using default\")\n        return ''\n```\n\n**Bad example: Punt to Claude**:\n```python\ndef process_file(path):\n    # Just fail and let Claude figure it out\n    return open(path).read()\n```\n\nConfiguration parameters should also be justified and documented to avoid \"voodoo constants\". If you don't know the right value, how will Claude determine it?\n\n**Good example: Self-documenting**:\n```python\n# HTTP requests typically complete within 30 seconds\n# Longer timeout accounts for slow connections\nREQUEST_TIMEOUT = 30\n\n# Three retries balances reliability vs speed\n# Most intermittent failures resolve by the second retry\nMAX_RETRIES = 3\n```\n\n**Bad example: Magic numbers**:\n```python\nTIMEOUT = 47  # Why 47?\nRETRIES = 5   # Why 5?\n```\n\n### Provide utility scripts\n\nEven if Claude could write a script, pre-made scripts offer advantages:\n\n**Benefits of utility scripts**:\n- More reliable than generated code\n- Save tokens (no need to include code in context)\n- Save time (no code generation required)\n- Ensure consistency across uses\n\n**Important distinction**: Make clear in your instructions whether Claude should:\n- **Execute the script** (most common): \"Run `analyze_form.py` to extract fields\"\n- **Read it as reference** (for complex logic): \"See `analyze_form.py` for the field extraction algorithm\"\n\nFor most utility scripts, execution is preferred because it's more reliable and efficient.\n\n**Example**:\n````markdown\n## Utility scripts\n\n**analyze_form.py**: Extract all form fields from PDF\n\n```bash\npython scripts/analyze_form.py input.pdf > fields.json\n```\n\nOutput format:\n```json\n{\n  \"field_name\": {\"type\": \"text\", \"x\": 100, \"y\": 200},\n  \"signature\": {\"type\": \"sig\", \"x\": 150, \"y\": 500}\n}\n```\n\n**validate_boxes.py**: Check for overlapping bounding boxes\n\n```bash\npython scripts/validate_boxes.py fields.json\n# Returns: \"OK\" or lists conflicts\n```\n\n**fill_form.py**: Apply field values to PDF\n\n```bash\npython scripts/fill_form.py input.pdf fields.json output.pdf\n```\n````\n\n### Use visual analysis\n\nWhen inputs can be rendered as images, have Claude analyze them:\n\n````markdown\n## Form layout analysis\n\n1. Convert PDF to images:\n   ```bash\n   python scripts/pdf_to_images.py form.pdf\n   ```\n\n2. Analyze each page image to identify form fields\n3. Claude can see field locations and types visually\n````\n\nClaude's vision capabilities help understand layouts and structures.\n\n### Create verifiable intermediate outputs\n\nWhen Claude performs complex, open-ended tasks, it can make mistakes. The \"plan-validate-execute\" pattern catches errors early by having Claude first create a plan in a structured format, then validate that plan with a script before executing it.\n\n**Example**: Imagine asking Claude to update 50 form fields in a PDF based on a spreadsheet. Without validation, Claude might reference non-existent fields, create conflicting values, miss required fields, or apply updates incorrectly.\n\n**Solution**: Use the workflow pattern shown above (PDF form filling), but add an intermediate `changes.json` file that gets validated before applying changes. The workflow becomes: analyze → **create plan file** → **validate plan** → execute → verify.\n\n**Why this pattern works:**\n- **Catches errors early**: Validation finds problems before changes are applied\n- **Machine-verifiable**: Scripts provide objective verification\n- **Reversible planning**: Claude can iterate on the plan without touching originals\n- **Clear debugging**: Error messages point to specific problems\n\n**When to use**: Batch operations, destructive changes, complex validation rules, high-stakes operations.\n\n**Implementation tip**: Make validation scripts verbose with specific error messages like \"Field 'signature_date' not found. Available fields: customer_name, order_total, signature_date_signed\" to help Claude fix issues.\n\n### Package dependencies\n\nSkills run in the code execution environment with platform-specific limitations:\n\n- **claude.ai**: Can install packages from npm and PyPI and pull from GitHub repositories\n- **Anthropic API**: Has no network access and no runtime package installation\n\nList required packages in your SKILL.md and verify they're available in the code execution tool documentation.\n\n### Runtime environment\n\nSkills run in a code execution environment with filesystem access, bash commands, and code execution capabilities.\n\n**How this affects your authoring:**\n\n**How Claude accesses Skills:**\n\n1. **Metadata pre-loaded**: At startup, the name and description from all Skills' YAML frontmatter are loaded into the system prompt\n2. **Files read on-demand**: Claude uses bash Read tools to access SKILL.md and other files from the filesystem when needed\n3. **Scripts executed efficiently**: Utility scripts can be executed via bash without loading their full contents into context. Only the script's output consumes tokens\n4. **No context penalty for large files**: Reference files, data, or documentation don't consume context tokens until actually read\n\n- **File paths matter**: Claude navigates your skill directory like a filesystem. Use forward slashes (`reference/guide.md`), not backslashes\n- **Name files descriptively**: Use names that indicate content: `form_validation_rules.md`, not `doc2.md`\n- **Organize for discovery**: Structure directories by domain or feature\n  - Good: `reference/finance.md`, `reference/sales.md`\n  - Bad: `docs/file1.md`, `docs/file2.md`\n- **Bundle comprehensive resources**: Include complete API docs, extensive examples, large datasets; no context penalty until accessed\n- **Prefer scripts for deterministic operations**: Write `validate_form.py` rather than asking Claude to generate validation code\n- **Make execution intent clear**:\n  - \"Run `analyze_form.py` to extract fields\" (execute)\n  - \"See `analyze_form.py` for the extraction algorithm\" (read as reference)\n- **Test file access patterns**: Verify Claude can navigate your directory structure by testing with real requests\n\n**Example:**\n\n```\nbigquery-skill/\n├── SKILL.md (overview, points to reference files)\n└── reference/\n    ├── finance.md (revenue metrics)\n    ├── sales.md (pipeline data)\n    └── product.md (usage analytics)\n```\n\nWhen the user asks about revenue, Claude reads SKILL.md, sees the reference to `reference/finance.md`, and invokes bash to read just that file. The sales.md and product.md files remain on the filesystem, consuming zero context tokens until needed. This filesystem-based model is what enables progressive disclosure. Claude can navigate and selectively load exactly what each task requires.\n\n### MCP tool references\n\nIf your Skill uses MCP (Model Context Protocol) tools, always use fully qualified tool names to avoid \"tool not found\" errors.\n\n**Format**: `ServerName:tool_name`\n\n**Example**:\n```markdown\nUse the BigQuery:bigquery_schema tool to retrieve table schemas.\nUse the GitHub:create_issue tool to create issues.\n```\n\nWhere:\n- `BigQuery` and `GitHub` are MCP server names\n- `bigquery_schema` and `create_issue` are the tool names within those servers\n\nWithout the server prefix, Claude may fail to locate the tool, especially when multiple MCP servers are available.\n\n### Avoid assuming tools are installed\n\nDon't assume packages are available:\n\n````markdown\n**Bad example: Assumes installation**:\n\"Use the pdf library to process the file.\"\n\n**Good example: Explicit about dependencies**:\n\"Install required package: `pip install pypdf`\n\nThen use it:\n```python\nfrom pypdf import PdfReader\nreader = PdfReader(\"file.pdf\")\n```\"\n````\n\n## Technical notes\n\n### YAML frontmatter requirements\n\nThe SKILL.md frontmatter requires `name` and `description` fields with specific validation rules:\n- `name`: Maximum 64 characters, lowercase letters/numbers/hyphens only, no XML tags, no reserved words\n- `description`: Maximum 1024 characters, non-empty, no XML tags\n\n### Token budgets\n\nKeep SKILL.md body under 500 lines for optimal performance. If your content exceeds this, split it into separate files using the progressive disclosure patterns described earlier.\n\n## Checklist for effective Skills\n\nBefore sharing a Skill, verify:\n\n### Core quality\n- [ ] Description is specific and includes key terms\n- [ ] Description includes both what the Skill does and when to use it\n- [ ] SKILL.md body is under 500 lines\n- [ ] Additional details are in separate files (if needed)\n- [ ] No time-sensitive information (or in \"old patterns\" section)\n- [ ] Consistent terminology throughout\n- [ ] Examples are concrete, not abstract\n- [ ] File references are one level deep\n- [ ] Progressive disclosure used appropriately\n- [ ] Workflows have clear steps\n\n### Code and scripts\n- [ ] Scripts solve problems rather than punt to Claude\n- [ ] Error handling is explicit and helpful\n- [ ] No \"voodoo constants\" (all values justified)\n- [ ] Required packages listed in instructions and verified as available\n- [ ] Scripts have clear documentation\n- [ ] No Windows-style paths (all forward slashes)\n- [ ] Validation/verification steps for critical operations\n- [ ] Feedback loops included for quality-critical tasks\n\n### Testing\n- [ ] At least three evaluations created\n- [ ] Tested with Haiku, Sonnet, and Opus\n- [ ] Tested with real usage scenarios\n- [ ] Team feedback incorporated (if applicable)\n",
        ".claude/skills/skill-creator/references/overview.md": "# Agent Skills Overview\n\nAgent Skills are modular capabilities that extend Claude's functionality. Each Skill packages instructions, metadata, and optional resources (scripts, templates) that Claude uses automatically when relevant.\n\n## Why use Skills\n\nSkills are reusable, filesystem-based resources that provide Claude with domain-specific expertise: workflows, context, and best practices that transform general-purpose agents into specialists. Unlike prompts (conversation-level instructions for one-off tasks), Skills load on-demand and eliminate the need to repeatedly provide the same guidance across multiple conversations.\n\n**Key benefits**:\n- **Specialize Claude**: Tailor capabilities for domain-specific tasks\n- **Reduce repetition**: Create once, use automatically\n- **Compose capabilities**: Combine Skills to build complex workflows\n\n## Using Skills\n\nAnthropic provides pre-built Agent Skills for common document tasks (PowerPoint, Excel, Word, PDF), and you can create your own custom Skills. Both work the same way. Claude automatically uses them when relevant to your request.\n\n**Pre-built Agent Skills** are available to all users on claude.ai and via the Claude API. See the [Available Skills](#available-skills) section below for the complete list.\n\n**Custom Skills** let you package domain expertise and organizational knowledge. They're available across Claude's products: create them in Claude Code, upload them via the API, or add them in claude.ai settings.\n\n## How Skills work\n\nSkills leverage Claude's VM environment to provide capabilities beyond what's possible with prompts alone. Claude operates in a virtual machine with filesystem access, allowing Skills to exist as directories containing instructions, executable code, and reference materials, organized like an onboarding guide you'd create for a new team member.\n\nThis filesystem-based architecture enables **progressive disclosure**: Claude loads information in stages as needed, rather than consuming context upfront.\n\n### Three types of Skill content, three levels of loading\n\nSkills can contain three types of content, each loaded at different times:\n\n#### Level 1: Metadata (always loaded)\n\n**Content type: Instructions**. The Skill's YAML frontmatter provides discovery information:\n\n```yaml\n---\nname: pdf-processing\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n---\n```\n\nClaude loads this metadata at startup and includes it in the system prompt. This lightweight approach means you can install many Skills without context penalty; Claude only knows each Skill exists and when to use it.\n\n#### Level 2: Instructions (loaded when triggered)\n\n**Content type: Instructions**. The main body of SKILL.md contains procedural knowledge: workflows, best practices, and guidance:\n\n````markdown\n# PDF Processing\n\n## Quick start\n\nUse pdfplumber to extract text from PDFs:\n\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n\nFor advanced form filling, see [FORMS.md](FORMS.md).\n````\n\nWhen you request something that matches a Skill's description, Claude reads SKILL.md from the filesystem via bash. Only then does this content enter the context window.\n\n#### Level 3: Resources and code (loaded as needed)\n\n**Content types: Instructions, code, and resources**. Skills can bundle additional materials:\n\n```\npdf-skill/\n├── SKILL.md (main instructions)\n├── FORMS.md (form-filling guide)\n├── REFERENCE.md (detailed API reference)\n└── scripts/\n    └── fill_form.py (utility script)\n```\n\n**Instructions**: Additional markdown files (FORMS.md, REFERENCE.md) containing specialized guidance and workflows\n\n**Code**: Executable scripts (fill_form.py, validate.py) that Claude runs via bash; scripts provide deterministic operations without consuming context\n\n**Resources**: Reference materials like database schemas, API documentation, templates, or examples\n\nClaude accesses these files only when referenced. The filesystem model means each content type has different strengths: instructions for flexible guidance, code for reliability, resources for factual lookup.\n\n| Level | When Loaded | Token Cost | Content |\n|-------|------------|------------|---------|\n| **Level 1: Metadata** | Always (at startup) | ~100 tokens per Skill | `name` and `description` from YAML frontmatter |\n| **Level 2: Instructions** | When Skill is triggered | Under 5k tokens | SKILL.md body with instructions and guidance |\n| **Level 3+: Resources** | As needed | Effectively unlimited | Bundled files executed via bash without loading contents into context |\n\nProgressive disclosure ensures only relevant content occupies the context window at any given time.\n\n### The Skills architecture\n\nSkills run in a code execution environment where Claude has filesystem access, bash commands, and code execution capabilities. Think of it like this: Skills exist as directories on a virtual machine, and Claude interacts with them using the same bash commands you'd use to navigate files on your computer.\n\n**How Claude accesses Skill content:**\n\nWhen a Skill is triggered, Claude uses bash to read SKILL.md from the filesystem, bringing its instructions into the context window. If those instructions reference other files (like FORMS.md or a database schema), Claude reads those files too using additional bash commands. When instructions mention executable scripts, Claude runs them via bash and receives only the output (the script code itself never enters context).\n\n**What this architecture enables:**\n\n**On-demand file access**: Claude reads only the files needed for each specific task. A Skill can include dozens of reference files, but if your task only needs the sales schema, Claude loads just that one file. The rest remain on the filesystem consuming zero tokens.\n\n**Efficient script execution**: When Claude runs `validate_form.py`, the script's code never loads into the context window. Only the script's output (like \"Validation passed\" or specific error messages) consumes tokens. This makes scripts far more efficient than having Claude generate equivalent code on the fly.\n\n**No practical limit on bundled content**: Because files don't consume context until accessed, Skills can include comprehensive API documentation, large datasets, extensive examples, or any reference materials you need. There's no context penalty for bundled content that isn't used.\n\nThis filesystem-based model is what makes progressive disclosure work. Claude navigates your Skill like you'd reference specific sections of an onboarding guide, accessing exactly what each task requires.\n\n### Example: Loading a PDF processing skill\n\nHere's how Claude loads and uses a PDF processing skill:\n\n1. **Startup**: System prompt includes: `PDF Processing - Extract text and tables from PDF files, fill forms, merge documents`\n2. **User request**: \"Extract the text from this PDF and summarize it\"\n3. **Claude invokes**: `bash: read pdf-skill/SKILL.md` → Instructions loaded into context\n4. **Claude determines**: Form filling is not needed, so FORMS.md is not read\n5. **Claude executes**: Uses instructions from SKILL.md to complete the task\n\nThis dynamic loading ensures only relevant skill content occupies the context window.\n\n## Where Skills work\n\nSkills are available across Claude's agent products:\n\n### Claude API\n\nThe Claude API supports both pre-built Agent Skills and custom Skills. Both work identically: specify the relevant `skill_id` in the `container` parameter along with the code execution tool.\n\n**Prerequisites**: Using Skills via the API requires three beta headers:\n- `code-execution-2025-08-25` - Skills run in the code execution container\n- `skills-2025-10-02` - Enables Skills functionality\n- `files-api-2025-04-14` - Required for uploading/downloading files to/from the container\n\nUse pre-built Agent Skills by referencing their `skill_id` (e.g., `pptx`, `xlsx`), or create and upload your own via the Skills API (`/v1/skills` endpoints). Custom Skills are shared organization-wide.\n\n### Claude Code\n\nClaude Code supports only Custom Skills.\n\n**Custom Skills**: Create Skills as directories with SKILL.md files. Claude discovers and uses them automatically.\n\nCustom Skills in Claude Code are filesystem-based and don't require API uploads.\n\n### Claude Agent SDK\n\nThe Claude Agent SDK supports custom Skills through filesystem-based configuration.\n\n**Custom Skills**: Create Skills as directories with SKILL.md files in `.claude/skills/`. Enable Skills by including `\"Skill\"` in your `allowed_tools` configuration.\n\nSkills in the Agent SDK are then automatically discovered when the SDK runs.\n\n### Claude.ai\n\nClaude.ai supports both pre-built Agent Skills and custom Skills.\n\n**Pre-built Agent Skills**: These Skills are already working behind the scenes when you create documents. Claude uses them without requiring any setup.\n\n**Custom Skills**: Upload your own Skills as zip files through Settings > Features. Available on Pro, Max, Team, and Enterprise plans with code execution enabled. Custom Skills are individual to each user; they are not shared organization-wide and cannot be centrally managed by admins.\n\n## Skill structure\n\nEvery Skill requires a `SKILL.md` file with YAML frontmatter:\n\n```yaml\n---\nname: your-skill-name\ndescription: Brief description of what this Skill does and when to use it\n---\n\n# Your Skill Name\n\n## Instructions\n[Clear, step-by-step guidance for Claude to follow]\n\n## Examples\n[Concrete examples of using this Skill]\n```\n\n**Required fields**: `name` and `description`\n\n**Field requirements**:\n\n`name`:\n- Maximum 64 characters\n- Must contain only lowercase letters, numbers, and hyphens\n- Cannot contain XML tags\n- Cannot contain reserved words: \"anthropic\", \"claude\"\n\n`description`:\n- Must be non-empty\n- Maximum 1024 characters\n- Cannot contain XML tags\n\nThe `description` should include both what the Skill does and when Claude should use it.\n\n## Security considerations\n\nUse Skills only from trusted sources: those you created yourself or obtained from Anthropic. Skills provide Claude with new capabilities through instructions and code, and while this makes them powerful, it also means a malicious Skill can direct Claude to invoke tools or execute code in ways that don't match the Skill's stated purpose.\n\nIf you must use a Skill from an untrusted or unknown source, exercise extreme caution and thoroughly audit it before use. Depending on what access Claude has when executing the Skill, malicious Skills could lead to data exfiltration, unauthorized system access, or other security risks.\n\n**Key security considerations**:\n- **Audit thoroughly**: Review all files bundled in the Skill: SKILL.md, scripts, images, and other resources. Look for unusual patterns like unexpected network calls, file access patterns, or operations that don't match the Skill's stated purpose\n- **External sources are risky**: Skills that fetch data from external URLs pose particular risk, as fetched content may contain malicious instructions. Even trustworthy Skills can be compromised if their external dependencies change over time\n- **Tool misuse**: Malicious Skills can invoke tools (file operations, bash commands, code execution) in harmful ways\n- **Data exposure**: Skills with access to sensitive data could be designed to leak information to external systems\n- **Treat like installing software**: Only use Skills from trusted sources. Be especially careful when integrating Skills into production systems with access to sensitive data or critical operations\n\n## Available Skills\n\n### Pre-built Agent Skills\n\nThe following pre-built Agent Skills are available for immediate use:\n\n- **PowerPoint (pptx)**: Create presentations, edit slides, analyze presentation content\n- **Excel (xlsx)**: Create spreadsheets, analyze data, generate reports with charts\n- **Word (docx)**: Create documents, edit content, format text\n- **PDF (pdf)**: Generate formatted PDF documents and reports\n\nThese Skills are available on the Claude API and claude.ai.\n\n### Custom Skills examples\n\nFor complete examples of custom Skills, see the Skills cookbook at: https://github.com/anthropics/claude-cookbooks/tree/main/skills\n\n## Limitations and constraints\n\nUnderstanding these limitations helps you plan your Skills deployment effectively.\n\n### Cross-surface availability\n\n**Custom Skills do not sync across surfaces**. Skills uploaded to one surface are not automatically available on others:\n\n- Skills uploaded to Claude.ai must be separately uploaded to the API\n- Skills uploaded via the API are not available on Claude.ai\n- Claude Code Skills are filesystem-based and separate from both Claude.ai and API\n\nYou'll need to manage and upload Skills separately for each surface where you want to use them.\n\n### Sharing scope\n\nSkills have different sharing models depending on where you use them:\n- **Claude.ai**: Individual user only; each team member must upload separately\n- **Claude API**: Workspace-wide; all workspace members can access uploaded Skills\n- **Claude Code**: Personal (`~/.claude/skills/`) or project-based (`.claude/skills/`); can also be shared via Claude Code Plugins\n\nClaude.ai does not currently support centralized admin management or org-wide distribution of custom Skills.\n\n### Runtime environment constraints\n\nThe exact runtime environment available to your skill depends on the product surface where you use it.\n\n - **Claude.ai**:\n    - **Varying network access**: Depending on user/admin settings, Skills may have full, partial, or no network access.\n- **Claude API**:\n    - **No network access**: Skills cannot make external API calls or access the internet\n    - **No runtime package installation**: Only pre-installed packages are available. You cannot install new packages during execution.\n    - **Pre-configured dependencies only**: Check the code execution tool documentation for the list of available packages\n- **Claude Code**:\n    - **Full network access**: Skills have the same network access as any other program on the user's computer\n    - **Global package installation discouraged**: Skills should only install packages locally in order to avoid interfering with the user's computer\n\nPlan your Skills to work within these constraints.\n",
        ".claude/skills/skill-creator/references/quickstart.md": "# Get started with Agent Skills in the API\n\nLearn how to use Agent Skills to create documents with the Claude API in under 10 minutes.\n\nThis tutorial shows you how to use Agent Skills to create a PowerPoint presentation. You'll learn how to enable Skills, make a simple request, and access the generated file.\n\n## Prerequisites\n\n- Anthropic API key (https://console.anthropic.com/settings/keys)\n- Python 3.7+ or curl installed\n- Basic familiarity with making API requests\n\n## What are Agent Skills?\n\nPre-built Agent Skills extend Claude's capabilities with specialized expertise for tasks like creating documents, analyzing data, and processing files. Anthropic provides the following pre-built Agent Skills in the API:\n\n- **PowerPoint (pptx)**: Create and edit presentations\n- **Excel (xlsx)**: Create and analyze spreadsheets\n- **Word (docx)**: Create and edit documents\n- **PDF (pdf)**: Generate PDF documents\n\nFor custom Skills, see the Agent Skills Cookbook at: https://github.com/anthropics/claude-cookbooks/tree/main/skills\n\n## Step 1: List available Skills\n\nFirst, let's see what Skills are available. We'll use the Skills API to list all Anthropic-managed Skills:\n\n**Python:**\n```python\nimport anthropic\n\nclient = anthropic.Anthropic()\n\n# List Anthropic-managed Skills\nskills = client.beta.skills.list(\n    source=\"anthropic\",\n    betas=[\"skills-2025-10-02\"]\n)\n\nfor skill in skills.data:\n    print(f\"{skill.id}: {skill.display_title}\")\n```\n\n**TypeScript:**\n```typescript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst client = new Anthropic();\n\n// List Anthropic-managed Skills\nconst skills = await client.beta.skills.list({\n  source: 'anthropic',\n  betas: ['skills-2025-10-02']\n});\n\nfor (const skill of skills.data) {\n  console.log(`${skill.id}: ${skill.display_title}`);\n}\n```\n\n**Shell:**\n```bash\ncurl \"https://api.anthropic.com/v1/skills?source=anthropic\" \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: skills-2025-10-02\"\n```\n\nYou see the following Skills: `pptx`, `xlsx`, `docx`, and `pdf`.\n\nThis API returns each Skill's metadata: its name and description. Claude loads this metadata at startup to know what Skills are available. This is the first level of **progressive disclosure**, where Claude discovers Skills without loading their full instructions yet.\n\n## Step 2: Create a presentation\n\nNow we'll use the PowerPoint Skill to create a presentation about renewable energy. We specify Skills using the `container` parameter in the Messages API:\n\n**Python:**\n```python\nimport anthropic\n\nclient = anthropic.Anthropic()\n\n# Create a message with the PowerPoint Skill\nresponse = client.beta.messages.create(\n    model=\"claude-sonnet-4-5-20250929\",\n    max_tokens=4096,\n    betas=[\"code-execution-2025-08-25\", \"skills-2025-10-02\"],\n    container={\n        \"skills\": [\n            {\n                \"type\": \"anthropic\",\n                \"skill_id\": \"pptx\",\n                \"version\": \"latest\"\n            }\n        ]\n    },\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Create a presentation about renewable energy with 5 slides\"\n    }],\n    tools=[{\n        \"type\": \"code_execution_20250825\",\n        \"name\": \"code_execution\"\n    }]\n)\n\nprint(response.content)\n```\n\n**TypeScript:**\n```typescript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst client = new Anthropic();\n\n// Create a message with the PowerPoint Skill\nconst response = await client.beta.messages.create({\n  model: 'claude-sonnet-4-5-20250929',\n  max_tokens: 4096,\n  betas: ['code-execution-2025-08-25', 'skills-2025-10-02'],\n  container: {\n    skills: [\n      {\n        type: 'anthropic',\n        skill_id: 'pptx',\n        version: 'latest'\n      }\n    ]\n  },\n  messages: [{\n    role: 'user',\n    content: 'Create a presentation about renewable energy with 5 slides'\n  }],\n  tools: [{\n    type: 'code_execution_20250825',\n    name: 'code_execution'\n  }]\n});\n\nconsole.log(response.content);\n```\n\n**Shell:**\n```bash\ncurl https://api.anthropic.com/v1/messages \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: code-execution-2025-08-25,skills-2025-10-02\" \\\n  -H \"content-type: application/json\" \\\n  -d '{\n    \"model\": \"claude-sonnet-4-5-20250929\",\n    \"max_tokens\": 4096,\n    \"container\": {\n      \"skills\": [\n        {\n          \"type\": \"anthropic\",\n          \"skill_id\": \"pptx\",\n          \"version\": \"latest\"\n        }\n      ]\n    },\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"Create a presentation about renewable energy with 5 slides\"\n    }],\n    \"tools\": [{\n      \"type\": \"code_execution_20250825\",\n      \"name\": \"code_execution\"\n    }]\n  }'\n```\n\nLet's break down what each part does:\n\n- **`container.skills`**: Specifies which Skills Claude can use\n- **`type: \"anthropic\"`**: Indicates this is an Anthropic-managed Skill\n- **`skill_id: \"pptx\"`**: The PowerPoint Skill identifier\n- **`version: \"latest\"`**: The Skill version set to the most recently published\n- **`tools`**: Enables code execution (required for Skills)\n- **Beta headers**: `code-execution-2025-08-25` and `skills-2025-10-02`\n\nWhen you make this request, Claude automatically matches your task to the relevant Skill. Since you asked for a presentation, Claude determines the PowerPoint Skill is relevant and loads its full instructions: the second level of progressive disclosure. Then Claude executes the Skill's code to create your presentation.\n\n## Step 3: Download the created file\n\nThe presentation was created in the code execution container and saved as a file. The response includes a file reference with a file ID. Extract the file ID and download it using the Files API:\n\n**Python:**\n```python\n# Extract file ID from response\nfile_id = None\nfor block in response.content:\n    if block.type == 'tool_use' and block.name == 'code_execution':\n        # File ID is in the tool result\n        for result_block in block.content:\n            if hasattr(result_block, 'file_id'):\n                file_id = result_block.file_id\n                break\n\nif file_id:\n    # Download the file\n    file_content = client.beta.files.download(\n        file_id=file_id,\n        betas=[\"files-api-2025-04-14\"]\n    )\n\n    # Save to disk\n    with open(\"renewable_energy.pptx\", \"wb\") as f:\n        file_content.write_to_file(f.name)\n\n    print(f\"Presentation saved to renewable_energy.pptx\")\n```\n\n**TypeScript:**\n```typescript\n// Extract file ID from response\nlet fileId: string | null = null;\nfor (const block of response.content) {\n  if (block.type === 'tool_use' && block.name === 'code_execution') {\n    // File ID is in the tool result\n    for (const resultBlock of block.content) {\n      if ('file_id' in resultBlock) {\n        fileId = resultBlock.file_id;\n        break;\n      }\n    }\n  }\n}\n\nif (fileId) {\n  // Download the file\n  const fileContent = await client.beta.files.download(fileId, {\n    betas: ['files-api-2025-04-14']\n  });\n\n  // Save to disk\n  const fs = require('fs');\n  fs.writeFileSync('renewable_energy.pptx', Buffer.from(await fileContent.arrayBuffer()));\n\n  console.log('Presentation saved to renewable_energy.pptx');\n}\n```\n\n**Shell:**\n```bash\n# Extract file_id from response (using jq)\nFILE_ID=$(echo \"$RESPONSE\" | jq -r '.content[] | select(.type==\"tool_use\" and .name==\"code_execution\") | .content[] | select(.file_id) | .file_id')\n\n# Download the file\ncurl \"https://api.anthropic.com/v1/files/$FILE_ID/content\" \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: files-api-2025-04-14\" \\\n  --output renewable_energy.pptx\n\necho \"Presentation saved to renewable_energy.pptx\"\n```\n\n## Try more examples\n\nNow that you've created your first document with Skills, try these variations:\n\n### Create a spreadsheet\n\n**Python:**\n```python\nresponse = client.beta.messages.create(\n    model=\"claude-sonnet-4-5-20250929\",\n    max_tokens=4096,\n    betas=[\"code-execution-2025-08-25\", \"skills-2025-10-02\"],\n    container={\n        \"skills\": [\n            {\n                \"type\": \"anthropic\",\n                \"skill_id\": \"xlsx\",\n                \"version\": \"latest\"\n            }\n        ]\n    },\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Create a quarterly sales tracking spreadsheet with sample data\"\n    }],\n    tools=[{\n        \"type\": \"code_execution_20250825\",\n        \"name\": \"code_execution\"\n    }]\n)\n```\n\n**TypeScript:**\n```typescript\nconst response = await client.beta.messages.create({\n  model: 'claude-sonnet-4-5-20250929',\n  max_tokens: 4096,\n  betas: ['code-execution-2025-08-25', 'skills-2025-10-02'],\n  container: {\n    skills: [\n      {\n        type: 'anthropic',\n        skill_id: 'xlsx',\n        version: 'latest'\n      }\n    ]\n  },\n  messages: [{\n    role: 'user',\n    content: 'Create a quarterly sales tracking spreadsheet with sample data'\n  }],\n  tools: [{\n    type: 'code_execution_20250825',\n    name: 'code_execution'\n  }]\n});\n```\n\n**Shell:**\n```bash\ncurl https://api.anthropic.com/v1/messages \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: code-execution-2025-08-25,skills-2025-10-02\" \\\n  -H \"content-type: application/json\" \\\n  -d '{\n    \"model\": \"claude-sonnet-4-5-20250929\",\n    \"max_tokens\": 4096,\n    \"container\": {\n      \"skills\": [\n        {\n          \"type\": \"anthropic\",\n          \"skill_id\": \"xlsx\",\n          \"version\": \"latest\"\n        }\n      ]\n    },\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"Create a quarterly sales tracking spreadsheet with sample data\"\n    }],\n    \"tools\": [{\n      \"type\": \"code_execution_20250825\",\n      \"name\": \"code_execution\"\n    }]\n  }'\n```\n\n### Create a Word document\n\n**Python:**\n```python\nresponse = client.beta.messages.create(\n    model=\"claude-sonnet-4-5-20250929\",\n    max_tokens=4096,\n    betas=[\"code-execution-2025-08-25\", \"skills-2025-10-02\"],\n    container={\n        \"skills\": [\n            {\n                \"type\": \"anthropic\",\n                \"skill_id\": \"docx\",\n                \"version\": \"latest\"\n            }\n        ]\n    },\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Write a 2-page report on the benefits of renewable energy\"\n    }],\n    tools=[{\n        \"type\": \"code_execution_20250825\",\n        \"name\": \"code_execution\"\n    }]\n)\n```\n\n**TypeScript:**\n```typescript\nconst response = await client.beta.messages.create({\n  model: 'claude-sonnet-4-5-20250929',\n  max_tokens: 4096,\n  betas: ['code-execution-2025-08-25', 'skills-2025-10-02'],\n  container: {\n    skills: [\n      {\n        type: 'anthropic',\n        skill_id: 'docx',\n        version: 'latest'\n      }\n    ]\n  },\n  messages: [{\n    role: 'user',\n    content: 'Write a 2-page report on the benefits of renewable energy'\n  }],\n  tools: [{\n    type: 'code_execution_20250825',\n    name: 'code_execution'\n  }]\n});\n```\n\n**Shell:**\n```bash\ncurl https://api.anthropic.com/v1/messages \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: code-execution-2025-08-25,skills-2025-10-02\" \\\n  -H \"content-type: application/json\" \\\n  -d '{\n    \"model\": \"claude-sonnet-4-5-20250929\",\n    \"max_tokens\": 4096,\n    \"container\": {\n      \"skills\": [\n        {\n          \"type\": \"anthropic\",\n          \"skill_id\": \"docx\",\n          \"version\": \"latest\"\n        }\n      ]\n    },\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"Write a 2-page report on the benefits of renewable energy\"\n    }],\n    \"tools\": [{\n      \"type\": \"code_execution_20250825\",\n      \"name\": \"code_execution\"\n    }]\n  }'\n```\n\n### Generate a PDF\n\n**Python:**\n```python\nresponse = client.beta.messages.create(\n    model=\"claude-sonnet-4-5-20250929\",\n    max_tokens=4096,\n    betas=[\"code-execution-2025-08-25\", \"skills-2025-10-02\"],\n    container={\n        \"skills\": [\n            {\n                \"type\": \"anthropic\",\n                \"skill_id\": \"pdf\",\n                \"version\": \"latest\"\n            }\n        ]\n    },\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Generate a PDF invoice template\"\n    }],\n    tools=[{\n        \"type\": \"code_execution_20250825\",\n        \"name\": \"code_execution\"\n    }]\n)\n```\n\n**TypeScript:**\n```typescript\nconst response = await client.beta.messages.create({\n  model: 'claude-sonnet-4-5-20250929',\n  max_tokens: 4096,\n  betas: ['code-execution-2025-08-25', 'skills-2025-10-02'],\n  container: {\n    skills: [\n      {\n        type: 'anthropic',\n        skill_id: 'pdf',\n        version: 'latest'\n      }\n    ]\n  },\n  messages: [{\n    role: 'user',\n    content: 'Generate a PDF invoice template'\n  }],\n  tools: [{\n    type: 'code_execution_20250825',\n    name: 'code_execution'\n  }]\n});\n```\n\n**Shell:**\n```bash\ncurl https://api.anthropic.com/v1/messages \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -H \"anthropic-beta: code-execution-2025-08-25,skills-2025-10-02\" \\\n  -H \"content-type: application/json\" \\\n  -d '{\n    \"model\": \"claude-sonnet-4-5-20250929\",\n    \"max_tokens\": 4096,\n    \"container\": {\n      \"skills\": [\n        {\n          \"type\": \"anthropic\",\n          \"skill_id\": \"pdf\",\n          \"version\": \"latest\"\n        }\n      ]\n    },\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"Generate a PDF invoice template\"\n    }],\n    \"tools\": [{\n      \"type\": \"code_execution_20250825\",\n      \"name\": \"code_execution\"\n    }]\n  }'\n```\n",
        "README.md": "# Claude Code Plugins\n\nPlugin marketplace for Claude Code.\n\n## Plugins\n\n| Name | Version | Description |\n|------|---------|-------------|\n| [chrome-extension-wxt](./chrome-extension-wxt) | 1.1.0 | Build Chrome extensions with WXT framework |\n| [cloudflare-workers](./cloudflare-workers) | 2.0.0 | Cloudflare Workers serverless development |\n| [founder-playbook](./founder-playbook) | 0.0.0 | Decision validation and thinking frameworks for founders |\n| [gh-cli](./gh-cli) | 1.1.0 | GitHub CLI for remote repo analysis |\n| [skill-factory](./skill-factory) | 0.1.0 | Autonomous skill creation with quality assurance |\n| [skill-finder](./skill-finder) | 1.1.0 | Find and evaluate Claude skills |\n| [solana](./solana) | 0.3.0 | Solana development (Anchor/native Rust) and security auditing |\n| [styling-with-tailwind](./styling-with-tailwind) | 0.1.0 | Build beautiful UIs with Tailwind CSS and shadcn/ui |\n| [tanstack-query](./tanstack-query) | 0.1.0 | TanStack Query (React Query) v5 for server state management |\n| [uv-ruff-python-tools](./uv-ruff-python-tools) | 0.1.0 | Python with uv package manager and ruff linter |\n\n## Installation\n\n```bash\n# Add marketplace\n/plugin marketplace add tenequm/claude-plugins\n\n# Install plugins\n/plugin install chrome-extension-wxt@tenequm-plugins\n/plugin install cloudflare-workers@tenequm-plugins\n/plugin install founder-playbook@tenequm-plugins\n/plugin install gh-cli@tenequm-plugins\n/plugin install skill-factory@tenequm-plugins\n/plugin install skill-finder@tenequm-plugins\n/plugin install solana@tenequm-plugins\n/plugin install styling-with-tailwind@tenequm-plugins\n/plugin install tanstack-query@tenequm-plugins\n/plugin install uv-ruff-python-tools@tenequm-plugins\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## License\n\nMIT\n",
        "chrome-extension-wxt/README.md": "# Chrome Extension WXT\n\nBuild Chrome extensions with WXT framework. TypeScript, React, Vue, or Svelte.\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install chrome-extension-wxt@tenequm-plugins\n```\n\n## Example Prompts\n\n```\n\"Create a new WXT extension with React and Tailwind\"\n\"Add a content script that modifies YouTube pages\"\n\"Set up Chrome storage sync for user preferences\"\n\"Implement background service worker with message passing\"\n```\n\n## Contents\n\n5 references: WXT API, Chrome API, React integration, Chrome 140+ features, best practices.\n",
        "chrome-extension-wxt/skill/SKILL.md": "---\nname: chrome-extension-wxt\ndescription: Build Chrome extensions using WXT framework with TypeScript, React, Vue, or Svelte. Use when creating browser extensions, developing cross-browser add-ons, or working with Chrome Web Store projects. Triggers on phrases like \"chrome extension\", \"browser extension\", \"WXT framework\", \"manifest v3\", or file patterns like wxt.config.ts.\n---\n\n# Chrome Extension Development with WXT\n\nBuild modern, cross-browser extensions using WXT - the next-generation framework that supports Chrome, Firefox, Edge, Safari, and all Chromium browsers with a single codebase.\n\n## When to Use This Skill\n\nUse this skill when:\n- Creating a new Chrome/browser extension\n- Setting up WXT development environment\n- Building extension features (popup, content scripts, background scripts)\n- Implementing cross-browser compatibility\n- Working with Manifest V3 (mandatory standard as of 2025, V2 deprecated)\n- Integrating React 19, Vue, Svelte, or Solid with extensions\n\n## Quick Start Workflow\n\n### 1. Initialize WXT Project\n\n```bash\n# Create new project with framework of choice\nnpm create wxt@latest\n\n# Or with specific template\nnpm create wxt@latest -- --template react-ts\nnpm create wxt@latest -- --template vue-ts\nnpm create wxt@latest -- --template svelte-ts\n```\n\n### 2. Project Structure\n\nWXT uses file-based conventions:\n\n```\nproject/\n├── entrypoints/              # Auto-discovered entry points\n│   ├── background.ts         # Service worker\n│   ├── content.ts           # Content script\n│   ├── popup.html           # Popup UI\n│   └── options.html         # Options page\n├── components/              # Auto-imported UI components\n├── utils/                   # Auto-imported utilities\n├── public/                  # Static assets\n│   └── icon/               # Extension icons\n├── wxt.config.ts           # Configuration\n└── package.json\n```\n\n### 3. Development Commands\n\n```bash\nnpm run dev              # Start dev server with HMR\nnpm run build           # Production build\nnpm run zip             # Package for store submission\n```\n\n## Core Entry Points\n\nWXT recognizes entry points by filename in `entrypoints/` directory:\n\n### Background Script (Service Worker)\n\n```typescript\n// entrypoints/background.ts\nexport default defineBackground({\n  type: 'module',\n  persistent: false,\n\n  main() {\n    // Listen for extension events\n    browser.action.onClicked.addListener((tab) => {\n      console.log('Extension clicked', tab);\n    });\n\n    // Handle messages\n    browser.runtime.onMessage.addListener((message, sender, sendResponse) => {\n      // Handle message\n      sendResponse({ success: true });\n      return true; // Keep channel open for async\n    });\n  },\n});\n```\n\n### Content Script\n\n```typescript\n// entrypoints/content.ts\nexport default defineContentScript({\n  matches: ['*://*.example.com/*'],\n  runAt: 'document_end',\n\n  main(ctx) {\n    // Content script logic\n    console.log('Content script loaded');\n\n    // Create UI\n    const ui = createShadowRootUi(ctx, {\n      name: 'my-extension-ui',\n      position: 'inline',\n      anchor: 'body',\n\n      onMount(container) {\n        // Mount React/Vue component\n        const root = ReactDOM.createRoot(container);\n        root.render(<App />);\n      },\n    });\n\n    ui.mount();\n  },\n});\n```\n\n### Popup UI\n\n```typescript\n// entrypoints/popup/main.tsx\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n```\n\n```html\n<!-- entrypoints/popup/index.html -->\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Extension Popup</title>\n</head>\n<body>\n  <div id=\"root\"></div>\n  <script type=\"module\" src=\"./main.tsx\"></script>\n</body>\n</html>\n```\n\n## Configuration\n\n### Basic wxt.config.ts\n\n```typescript\nimport { defineConfig } from 'wxt';\n\nexport default defineConfig({\n  // Framework integration\n  modules: ['@wxt-dev/module-react'],\n\n  // Manifest configuration\n  manifest: {\n    name: 'My Extension',\n    description: 'Extension description',\n    permissions: ['storage', 'activeTab'],\n    host_permissions: ['*://example.com/*'],\n  },\n\n  // Browser target\n  browser: 'chrome', // or 'firefox', 'edge', 'safari'\n});\n```\n\n## Common Patterns\n\n### Type-Safe Storage\n\n```typescript\n// utils/storage.ts\nimport { storage } from 'wxt/storage';\n\nexport const storageHelper = {\n  async get<T>(key: string): Promise<T | null> {\n    return await storage.getItem<T>(`local:${key}`);\n  },\n\n  async set<T>(key: string, value: T): Promise<void> {\n    await storage.setItem(`local:${key}`, value);\n  },\n\n  watch<T>(key: string, callback: (newValue: T | null) => void) {\n    return storage.watch<T>(`local:${key}`, callback);\n  },\n};\n```\n\n### Type-Safe Messaging\n\n```typescript\n// utils/messaging.ts\ninterface Messages {\n  'get-data': {\n    request: { key: string };\n    response: { value: any };\n  };\n}\n\nexport async function sendMessage<K extends keyof Messages>(\n  type: K,\n  payload: Messages[K]['request']\n): Promise<Messages[K]['response']> {\n  return await browser.runtime.sendMessage({ type, payload });\n}\n```\n\n### Script Injection\n\n```typescript\n// Inject script into page context\nimport { injectScript } from 'wxt/client';\n\nawait injectScript('/injected.js', {\n  keepInDom: false,\n});\n```\n\n## Building & Deployment\n\n### Production Build\n\n```bash\n# Build for specific browser\nnpm run build -- --browser=chrome\nnpm run build -- --browser=firefox\n\n# Create store-ready ZIP\nnpm run zip\nnpm run zip -- --browser=firefox\n```\n\n### Multi-Browser Build\n\n```bash\n# Build for all browsers\nnpm run zip:all\n```\n\nOutput: `.output/my-extension-{version}-{browser}.zip`\n\n## Modern Stacks (2025)\n\nPopular technology combinations for building Chrome extensions:\n\n### WXT + React + Tailwind + shadcn/ui\nMost popular stack in 2025. Combines utility-first styling with pre-built accessible components.\n\n```bash\nnpm create wxt@latest -- --template react-ts\nnpm install -D tailwindcss postcss autoprefixer\nnpx tailwindcss init -p\nnpx shadcn@latest init\n```\n\n**Best for:** Modern UIs with consistent design system\n**Example:** https://github.com/imtiger/wxt-react-shadcn-tailwindcss-chrome-extension\n\n### WXT + React + Mantine UI\nComplete component library with 100+ components and built-in dark mode.\n\n```bash\nnpm create wxt@latest -- --template react-ts\nnpm install @mantine/core @mantine/hooks\n```\n\n**Best for:** Feature-rich extensions needing complex components\n**Example:** https://github.com/ongkay/WXT-Mantine-Tailwind-Browser-Extension\n\n### WXT + React + TypeScript (Minimal)\nClean setup for custom designs without UI library dependencies.\n\n```bash\nnpm create wxt@latest -- --template react-ts\n```\n\n**Best for:** Simple extensions or highly custom designs\n\n## Advanced Topics\n\nFor detailed information on advanced topics, see the reference files:\n\n- **React Integration**: See `references/react-integration.md` for complete React setup, hooks, state management, and popular UI libraries\n- **Chrome APIs**: See `references/chrome-api.md` for comprehensive Chrome Extension API reference with examples\n- **Chrome 140+ Features**: See `references/chrome-140-features.md` for latest Chrome Extension APIs (sidePanel.getLayout(), etc.)\n- **WXT API**: See `references/wxt-api.md` for complete WXT framework API documentation\n- **Best Practices**: See `references/best-practices.md` for security, performance, and architecture patterns\n\n## Troubleshooting\n\nCommon issues and solutions:\n\n1. **Module not found errors**: Ensure modules are installed and properly imported\n2. **CSP violations**: Update `content_security_policy` in manifest\n3. **Hot reload not working**: Check browser console for errors\n4. **Storage not persisting**: Use `storage.local` or `storage.sync` correctly\n\nFor detailed troubleshooting, see `references/troubleshooting.md`\n\n## Resources\n\n### Official Documentation\n- WXT Docs: https://wxt.dev\n- Chrome Extension Docs: https://developer.chrome.com/docs/extensions\n- Firefox Extension Docs: https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons\n\n### Bundled Resources\n\n- **scripts/**: Helper utilities for common extension tasks\n- **references/**: Detailed documentation for advanced features\n- **assets/**: Starter templates and example components\n\nUse these resources as needed when building your extension.\n",
        "cloudflare-workers/README.md": "# Cloudflare Workers\n\nBuild and deploy serverless apps on Cloudflare's edge network.\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install cloudflare-workers@tenequm-plugins\n```\n\n## Example Prompts\n\n```\n\"Create a Worker with KV storage for caching\"\n\"Set up D1 database bindings\"\n\"Deploy API with rate limiting using Durable Objects\"\n\"Configure wrangler.toml for staging and production\"\n```\n\n## Contents\n\n5 references: bindings guide, development patterns, advanced features, observability, wrangler/deployment.\n",
        "cloudflare-workers/skill/SKILL.md": "---\nname: cloudflare-workers\ndescription: Rapid development with Cloudflare Workers - build and deploy serverless applications on Cloudflare's global network. Use when building APIs, full-stack web apps, edge functions, background jobs, or real-time applications. Triggers on phrases like \"cloudflare workers\", \"wrangler\", \"edge computing\", \"serverless cloudflare\", \"workers bindings\", or files like wrangler.toml, worker.ts, worker.js.\n---\n\n# Cloudflare Workers\n\n## Overview\n\nCloudflare Workers is a serverless execution environment that runs JavaScript, TypeScript, Python, and Rust code on Cloudflare's global network. Workers execute in milliseconds, scale automatically, and integrate with Cloudflare's storage and compute products through bindings.\n\n**Key Benefits:**\n- **Zero cold starts** - Workers run in V8 isolates, not containers\n- **Global deployment** - Code runs in 300+ cities worldwide\n- **Rich ecosystem** - Bindings to D1, KV, R2, Durable Objects, Queues, and more\n- **Full-stack capable** - Build APIs and serve static assets in one project\n- **Standards-based** - Uses Web APIs (fetch, crypto, streams, WebSockets)\n\n## When to Use This Skill\n\nUse Cloudflare Workers for:\n\n- **APIs and backends** - RESTful APIs, GraphQL, tRPC, WebSocket servers\n- **Full-stack applications** - React, Next.js, Remix, Astro, Vue, Svelte with static assets\n- **Edge middleware** - Authentication, rate limiting, A/B testing, routing\n- **Background processing** - Scheduled jobs (cron), queue consumers, webhooks\n- **Data transformation** - ETL pipelines, real-time data processing\n- **AI applications** - RAG systems, chatbots, image generation with Workers AI\n- **Proxy and gateway** - API gateways, content transformation, protocol translation\n\n## Quick Start Workflow\n\n### 1. Install Wrangler CLI\n\n```bash\nnpm install -g wrangler\n\n# Login to Cloudflare\nwrangler login\n```\n\n### 2. Create a New Worker\n\n```bash\n# Using C3 (create-cloudflare) - recommended\nnpm create cloudflare@latest my-worker\n\n# Or create manually\nwrangler init my-worker\ncd my-worker\n```\n\n### 3. Write Your Worker\n\n**Basic HTTP API (TypeScript):**\n\n```typescript\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const url = new URL(request.url);\n\n    if (url.pathname === \"/api/hello\") {\n      return Response.json({ message: \"Hello from Workers!\" });\n    }\n\n    return new Response(\"Not found\", { status: 404 });\n  },\n};\n```\n\n**With environment variables and KV:**\n\n```typescript\ninterface Env {\n  MY_VAR: string;\n  MY_KV: KVNamespace;\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    // Access environment variable\n    const greeting = env.MY_VAR;\n\n    // Read from KV\n    const value = await env.MY_KV.get(\"my-key\");\n\n    return Response.json({ greeting, value });\n  },\n};\n```\n\n### 4. Develop Locally\n\n```bash\n# Start local development server with hot reload\nwrangler dev\n\n# Access at http://localhost:8787\n```\n\n### 5. Deploy to Production\n\n```bash\n# Deploy to workers.dev subdomain\nwrangler deploy\n\n# Deploy to custom domain (configure in wrangler.toml)\nwrangler deploy\n```\n\n## Core Concepts\n\n### Workers Runtime\n\nWorkers use the V8 JavaScript engine with Web Standard APIs:\n\n- **Execution model**: Isolates (not containers) - instant cold starts\n- **CPU time limit**: 10ms (Free), 30s (Paid) per request\n- **Memory limit**: 128 MB per isolate\n- **Languages**: JavaScript, TypeScript, Python, Rust\n- **APIs**: fetch, crypto, streams, WebSockets, WebAssembly\n\n**Supported APIs:**\n- Fetch API (HTTP requests)\n- URL API (URL parsing)\n- Web Crypto (encryption, hashing)\n- Streams API (data streaming)\n- WebSockets (real-time communication)\n- Cache API (edge caching)\n- HTML Rewriter (HTML transformation)\n\n### Handlers\n\nWorkers respond to events through handlers:\n\n**Fetch Handler** (HTTP requests):\n```typescript\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext) {\n    return new Response(\"Hello!\");\n  },\n};\n```\n\n**Scheduled Handler** (cron jobs):\n```typescript\nexport default {\n  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {\n    // Runs on schedule defined in wrangler.toml\n    await env.MY_KV.put(\"last-run\", new Date().toISOString());\n  },\n};\n```\n\n**Queue Handler** (message processing):\n```typescript\nexport default {\n  async queue(batch: MessageBatch<any>, env: Env, ctx: ExecutionContext) {\n    for (const message of batch.messages) {\n      await processMessage(message.body);\n      message.ack();\n    }\n  },\n};\n```\n\n### Bindings\n\nBindings connect your Worker to Cloudflare resources. Configure in `wrangler.toml`:\n\n**KV (Key-Value Storage):**\n```toml\n[[kv_namespaces]]\nbinding = \"MY_KV\"\nid = \"your-kv-namespace-id\"\n```\n\n```typescript\n// Usage\nawait env.MY_KV.put(\"key\", \"value\");\nconst value = await env.MY_KV.get(\"key\");\n```\n\n**D1 (SQL Database):**\n```toml\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"my-database\"\ndatabase_id = \"your-database-id\"\n```\n\n```typescript\n// Usage\nconst result = await env.DB.prepare(\n  \"SELECT * FROM users WHERE id = ?\"\n).bind(userId).all();\n```\n\n**R2 (Object Storage):**\n```toml\n[[r2_buckets]]\nbinding = \"MY_BUCKET\"\nbucket_name = \"my-bucket\"\n```\n\n```typescript\n// Usage\nawait env.MY_BUCKET.put(\"file.txt\", \"contents\");\nconst object = await env.MY_BUCKET.get(\"file.txt\");\nconst text = await object?.text();\n```\n\n**Environment Variables:**\n```toml\n[vars]\nAPI_KEY = \"development-key\"  # pragma: allowlist secret\n```\n\n**Secrets** (sensitive data):\n```bash\n# Set via CLI (not in wrangler.toml)\nwrangler secret put API_KEY\n```\n\n### Context (ctx)\n\nThe `ctx` parameter provides control over request lifecycle:\n\n```typescript\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext) {\n    // Run tasks after response is sent\n    ctx.waitUntil(\n      env.MY_KV.put(\"request-count\", String(Date.now()))\n    );\n\n    // Pass through to origin on exception\n    ctx.passThroughOnException();\n\n    return new Response(\"OK\");\n  },\n};\n```\n\n## Rapid Development Patterns\n\n### Wrangler Configuration\n\n**Essential `wrangler.toml`:**\n\n```toml\nname = \"my-worker\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2025-01-01\"\n\n# Custom domain\nroutes = [\n  { pattern = \"api.example.com/*\", zone_name = \"example.com\" }\n]\n\n# Or workers.dev subdomain\nworkers_dev = true\n\n# Environment variables\n[vars]\nENVIRONMENT = \"production\"\n\n# Bindings\n[[kv_namespaces]]\nbinding = \"CACHE\"\nid = \"your-kv-id\"\n\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"production-db\"\ndatabase_id = \"your-db-id\"\n\n[[r2_buckets]]\nbinding = \"ASSETS\"\nbucket_name = \"my-assets\"\n\n# Cron triggers\n[triggers]\ncrons = [\"0 0 * * *\"]  # Daily at midnight\n```\n\n### Environment Management\n\nUse environments for staging/production:\n\n```toml\n[env.staging]\nvars = { ENVIRONMENT = \"staging\" }\n\n[env.staging.d1_databases]\nbinding = \"DB\"\ndatabase_name = \"staging-db\"\ndatabase_id = \"staging-db-id\"\n\n[env.production]\nvars = { ENVIRONMENT = \"production\" }\n\n[env.production.d1_databases]\nbinding = \"DB\"\ndatabase_name = \"production-db\"\ndatabase_id = \"production-db-id\"\n```\n\n```bash\n# Deploy to staging\nwrangler deploy --env staging\n\n# Deploy to production\nwrangler deploy --env production\n```\n\n### Common Patterns\n\n**JSON API with Error Handling:**\n\n```typescript\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    try {\n      const url = new URL(request.url);\n\n      if (url.pathname === \"/api/users\" && request.method === \"GET\") {\n        const users = await env.DB.prepare(\"SELECT * FROM users\").all();\n        return Response.json(users.results);\n      }\n\n      if (url.pathname === \"/api/users\" && request.method === \"POST\") {\n        const body = await request.json();\n        await env.DB.prepare(\n          \"INSERT INTO users (name, email) VALUES (?, ?)\"\n        ).bind(body.name, body.email).run();\n        return Response.json({ success: true }, { status: 201 });\n      }\n\n      return Response.json({ error: \"Not found\" }, { status: 404 });\n    } catch (error) {\n      return Response.json(\n        { error: error.message },\n        { status: 500 }\n      );\n    }\n  },\n};\n```\n\n**Authentication Middleware:**\n\n```typescript\nasync function authenticate(request: Request, env: Env): Promise<string | null> {\n  const authHeader = request.headers.get(\"Authorization\");\n  if (!authHeader?.startsWith(\"Bearer \")) {\n    return null;\n  }\n\n  const token = authHeader.substring(7);\n  const userId = await env.SESSIONS.get(token);\n  return userId;\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const userId = await authenticate(request, env);\n\n    if (!userId) {\n      return Response.json({ error: \"Unauthorized\" }, { status: 401 });\n    }\n\n    // Proceed with authenticated request\n    return Response.json({ userId });\n  },\n};\n```\n\n**CORS Headers:**\n\n```typescript\nconst corsHeaders = {\n  \"Access-Control-Allow-Origin\": \"*\",\n  \"Access-Control-Allow-Methods\": \"GET, POST, PUT, DELETE, OPTIONS\",\n  \"Access-Control-Allow-Headers\": \"Content-Type, Authorization\",\n};\n\nexport default {\n  async fetch(request: Request): Promise<Response> {\n    if (request.method === \"OPTIONS\") {\n      return new Response(null, { headers: corsHeaders });\n    }\n\n    const response = await handleRequest(request);\n\n    // Add CORS headers to response\n    Object.entries(corsHeaders).forEach(([key, value]) => {\n      response.headers.set(key, value);\n    });\n\n    return response;\n  },\n};\n```\n\n### Static Assets (Full-Stack Apps)\n\nServe static files alongside your Worker code:\n\n```toml\n[assets]\ndirectory = \"./public\"\nbinding = \"ASSETS\"\n```\n\n```typescript\nimport { getAssetFromKV } from \"@cloudflare/kv-asset-handler\";\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const url = new URL(request.url);\n\n    // API routes\n    if (url.pathname.startsWith(\"/api/\")) {\n      return handleAPI(request, env);\n    }\n\n    // Serve static assets\n    try {\n      return await getAssetFromKV(\n        { request, waitUntil: () => {} },\n        { ASSET_NAMESPACE: env.ASSETS }\n      );\n    } catch {\n      return new Response(\"Not found\", { status: 404 });\n    }\n  },\n};\n```\n\n### Testing\n\n**Using Vitest:**\n\n```typescript\nimport { env, createExecutionContext } from \"cloudflare:test\";\nimport { describe, it, expect } from \"vitest\";\nimport worker from \"./index\";\n\ndescribe(\"Worker\", () => {\n  it(\"responds with JSON\", async () => {\n    const request = new Request(\"http://example.com/api/hello\");\n    const ctx = createExecutionContext();\n    const response = await worker.fetch(request, env, ctx);\n\n    expect(response.status).toBe(200);\n    expect(await response.json()).toEqual({ message: \"Hello!\" });\n  });\n});\n```\n\n## Framework Integration\n\nWorkers supports major frameworks with adapters:\n\n- **Next.js** - Full App Router and Pages Router support\n- **Remix / React Router** - Native Cloudflare adapter\n- **Astro** - Server-side rendering on Workers\n- **SvelteKit** - Cloudflare adapter available\n- **Hono** - Lightweight web framework built for Workers\n- **tRPC** - Type-safe APIs with full Workers support\n\n**Example with Hono:**\n\n```typescript\nimport { Hono } from \"hono\";\n\nconst app = new Hono();\n\napp.get(\"/\", (c) => c.text(\"Hello!\"));\napp.get(\"/api/users/:id\", async (c) => {\n  const id = c.req.param(\"id\");\n  const user = await c.env.DB.prepare(\n    \"SELECT * FROM users WHERE id = ?\"\n  ).bind(id).first();\n  return c.json(user);\n});\n\nexport default app;\n```\n\n## Advanced Topics\n\nFor detailed information on advanced features, see the reference files:\n\n- **Complete Bindings Guide**: `references/bindings-complete-guide.md` - Deep dive into all binding types (Durable Objects, Queues, Vectorize, AI, Hyperdrive, etc.)\n- **Deployment & CI/CD**: `references/wrangler-and-deployment.md` - Wrangler commands, GitHub Actions, GitLab CI/CD, gradual rollouts, versions\n- **Development Best Practices**: `references/development-patterns.md` - Testing strategies, debugging, error handling, performance optimization\n- **Advanced Features**: `references/advanced-features.md` - Workers for Platforms, Smart Placement, WebSockets, streaming, custom domains\n- **Observability**: `references/observability.md` - Logging (tail, Logpush, Workers Logs), metrics, traces, debugging\n\n## Resources\n\n**Official Documentation:**\n- Workers: https://developers.cloudflare.com/workers/\n- Wrangler CLI: https://developers.cloudflare.com/workers/wrangler/\n- Runtime APIs: https://developers.cloudflare.com/workers/runtime-apis/\n- Examples: https://developers.cloudflare.com/workers/examples/\n\n**Templates & Quick Starts:**\n- Templates: https://developers.cloudflare.com/workers/get-started/quickstarts/\n- Framework guides: https://developers.cloudflare.com/workers/framework-guides/\n\n**Community:**\n- Discord: https://discord.cloudflare.com\n- GitHub: https://github.com/cloudflare/workers-sdk\n",
        "founder-playbook/skill/SKILL.md": "---\nname: founder-playbook\ndescription: Decision validation and thinking frameworks for startup founders. Use when you need to pressure-test a decision, validate your next steps, think through strategic options, or sanity-check your approach. Triggers on phrases like \"should I\", \"help me think through\", \"is this the right move\", \"validate my thinking\", \"what am I missing\". Covers fundraising, customer development, runway management, prioritization, and crypto/web3 founder challenges.\n---\n\n# Founder Playbook\n\n> **Last updated:** November 2025. Statistics and ecosystem data reflect this period.\n\nA structured thinking partner for startup founders. Use this to pressure-test decisions, validate your next steps, and think through challenges using proven frameworks (GROW, Solution-Focused) with deep knowledge of 2025 startup realities and crypto/web3 ecosystem specifics.\n\n## Core Approach: Genuine Empowerment Through Honest Partnership\n\nYour job is to make founders more capable, confident, and clear-headed after every conversation—not to validate them, but also not to crush them. The goal is **empowered agency**, not dependency on your approval OR your criticism.\n\n### The Empowerment Balance\n\nEffective coaching requires more acknowledgment than challenge. This doesn't mean empty praise—it means:\n\n**For every challenge or corrective feedback, ensure you've acknowledged:**\n1. The genuine difficulty of what they're facing\n2. The effort and thinking they've already invested\n3. What IS working or has improved\n4. Their capability to figure this out\n\n**Example Balance:**\n- ❌ \"Your pricing is wrong. Here's why...\" (0:1 ratio)\n- ✅ \"You've clearly thought hard about this—I can see the logic in your approach. The market data you gathered is solid. One thing I'd push on: what evidence do you have that customers will pay this?\" (3:1 ratio)\n\n### Genuine Encouragement vs. Sycophancy\n\n**Sycophancy (AVOID):**\n- Generic validation: \"Great question!\", \"That's brilliant!\"\n- Agreement without substance\n- Praise focused on traits: \"You're so smart!\"\n- Dismissing struggle: \"Don't worry, it'll work out!\"\n\n**Genuine Encouragement (USE):**\n- Process praise: \"You broke that down systematically\"\n- Specific acknowledgment: \"The way you reframed that shows clear thinking\"\n- Effort recognition: \"You've put real work into understanding this\"\n- Validating difficulty: \"This is genuinely hard—most founders struggle here\"\n\n### Process Praise Framework (Carol Dweck Research)\n\n**Always praise PROCESS, never TRAITS:**\n\n| Instead of (Trait) | Say (Process) |\n|-------------------|---------------|\n| \"You're so smart\" | \"You approached that systematically\" |\n| \"You're a natural at this\" | \"Your preparation really shows\" |\n| \"You're talented\" | \"The strategy you used was effective\" |\n| \"Great idea!\" | \"I can see the reasoning behind that—you identified the core problem\" |\n\n**Why this matters:** Trait praise creates fixed mindset and fear of failure. Process praise builds growth mindset and resilience. Research shows trait-praised individuals avoid challenges and give up faster.\n\n**The Process Praise Formula:**\n1. **Specific behavior**: \"When you [specific action]...\"\n2. **Effect observed**: \"...it helped you [specific result]\"\n3. **Transferable principle**: \"That shows [skill/approach]\"\n4. **Future application**: \"You could use that when [future scenario]\"\n\n### Validating Struggle (Not Toxic Positivity)\n\n**Toxic Positivity (AVOID):**\n- \"Just stay positive!\"\n- \"Everything happens for a reason\"\n- \"Look on the bright side\"\n- \"It could be worse\"\n\n**Validating Struggle (USE):**\n- \"This is genuinely difficult—your frustration makes sense\"\n- \"Most founders hit this wall. It's real.\"\n- \"That's a hard situation. What support would help?\"\n- \"It's okay to feel stuck. What's one small thing you could try?\"\n\n**The difference:** Toxic positivity dismisses emotions and creates shame. Validating struggle acknowledges reality while maintaining forward motion.\n\n### Autonomy-Supportive Language\n\n**Controlling (triggers resistance):**\n- \"You should...\"\n- \"You need to...\"\n- \"You have to...\"\n- \"The right answer is...\"\n\n**Autonomy-supportive (empowers agency):**\n- \"You might consider...\"\n- \"Some founders find it useful to...\"\n- \"One option could be...\"\n- \"What feels right to you?\"\n\n**Why this matters:** Controlling language triggers psychological reactance—people resist even good advice when it feels like their freedom is threatened. Autonomy-supportive language keeps the founder in the driver's seat.\n\n### When to Challenge vs. When to Support\n\nNot every moment calls for challenge. Match your response to their state:\n\n| Founder State | Your Response |\n|--------------|---------------|\n| Energized, momentum | Challenge: \"What would 10x look like?\" |\n| Exhausted, burned out | Support: \"What do you need right now?\" |\n| Genuinely stuck | Explore: \"What have you already tried?\" |\n| Avoiding hard thing | Gentle push: \"What's the scary thing you're not saying?\" |\n| Made real progress | Celebrate: \"That took real discipline. How did you do it?\" |\n| Facing genuine loss | Validate first: \"That's legitimately hard.\" |\n| Catastrophizing | Get specific: \"What exactly is at risk right now?\" |\n| Sunk cost / pivot resistance | Reframe: \"If you started fresh today with the same money, would you invest in this exact approach?\" |\n| Decision paralysis | Unblock: \"You probably do know. What does your gut say?\" |\n| Procrastination | Accountability: \"What's the next action, and when exactly?\" |\n\n### Mode Switching\n\n**Default Mode: Coach (80% of interactions)**\n- Ask questions that help founders discover their own answers\n- Use Socratic method to surface assumptions and blind spots\n- Build founder's decision-making capacity, not dependency\n- Make founder feel more capable after every conversation\n\n**Advisor Mode: When Appropriate (20% of interactions)**\n- Founder explicitly asks: \"What would you do?\"\n- Factual information needed (grants, market data, frameworks)\n- Safety/compliance/legal considerations\n- After thorough exploration, founder is genuinely stuck\n\n**Signal the mode shift explicitly**: \"I'm going to give you direct advice now...\"\n\n## Session Structure\n\n### Opening (Context Gathering)\n\nStart every coaching conversation with:\n\n**1. \"What's on your mind?\"**\nOpens the conversation without assumptions.\n\n**2. \"And what else?\"**\nAsk 2-3 times. First answer is rarely the real issue.\n\n**3. \"What would make this conversation most useful for you?\"**\nEstablishes success criteria for the session.\n\n### Exploration (GROW Framework)\n\n**Goal:** What do you want?\n- \"What does success look like here?\"\n- \"What outcome are you hoping for?\"\n- \"How will you know when you've achieved it?\"\n\n**Reality:** Where are you now?\n- \"Where are you on a scale of 1-10?\"\n- \"What have you tried so far?\"\n- \"What's actually happening vs. what you expected?\"\n\n**Options:** What could you do?\n- \"What options do you see?\"\n- \"What else?\" (repeat 3-5 times)\n- \"If you couldn't fail, what would you try?\"\n- \"What would you advise a friend in this situation?\"\n\n**Will:** What will you do?\n- \"What's your next step?\"\n- \"When exactly will you do it?\"\n- \"What might get in the way?\"\n- \"How committed are you, 1-10?\"\n\n### Closing (Accountability)\n\n**4. \"What's your commitment for the next 48 hours?\"**\nSpecific, measurable, time-bound.\n\n**5. \"What was most useful for you today?\"**\nConsolidates learning, builds self-awareness.\n\n## The \"What Else?\" Technique\n\nThe single most powerful coaching tool. After any meaningful answer:\n\n**\"And what else?\"**\n\n- First answer: Usually safe/superficial\n- Second answer: Getting closer to truth\n- Third answer: Often reveals the real issue\n- Fourth answer: Can produce breakthrough insights\n\nUse 3-5 times before moving to next topic. This alone transforms conversation quality.\n\n## Question Banks by Situation\n\n### When Founder Is Stuck/Overwhelmed\n\n- \"What's the real challenge here for you?\" (cuts through complexity)\n- \"If you could only solve one problem this week, which would unlock the most?\"\n- \"What would you do if you only had one month of runway?\"\n- \"What are you avoiding?\"\n\n### When Making a Strategic Decision\n\n- \"What are you optimizing for?\"\n- \"What would need to be true for Option A to be the right choice?\"\n- \"How would you explain this decision to yourself in a year?\"\n- \"What's the cost of not deciding?\"\n\n### When Dealing with Uncertainty\n\n- \"What do you know for sure?\"\n- \"What's the smallest experiment that would give you more information?\"\n- \"What would 'good enough' information look like?\"\n- \"What decision can you defer? Which must you make now?\"\n\n### When Facing Resource Constraints\n\n- \"If you couldn't raise money, how would you get to revenue?\"\n- \"What's the one thing that would move the needle most?\"\n- \"What are you saying yes to that you should say no to?\"\n- \"What would a ruthless prioritizer do here?\"\n\n### When Dealing with Fear/Self-Doubt\n\n- \"What's the worst that could happen? Then what?\"\n- \"What would you attempt if you knew you couldn't fail?\"\n- \"Who believes in you? What do they see?\"\n- \"What evidence contradicts your fear?\"\n\n**→ See [references/question-banks.md](references/question-banks.md) for comprehensive question library**\n\n## Domain-Specific Knowledge\n\n### 2025 Founder Playbook\n\nKey principles for pre-revenue technical founders:\n\n**Do Things That Don't Scale**\n- Manually recruit first 10-100 users\n- Over-deliver on early customer experience\n- Learn from hands-on, not dashboards\n\n**Customer Validation > Building**\n- \"Would you use this?\" yields false positives\n- \"Will you pay now?\" is the real test\n- 5 paying customers beats 500 free signups\n\n**Runway Discipline**\n- <3 months = point of no return\n- Calculate exact runway weekly\n- Cut burn or grow revenue, no third option\n\n**The First 10 Customers**\n1. Identify 50 qualified prospects\n2. Research each deeply\n3. Send 10 personalized outreaches daily\n4. Goal: 3-5 paying customers in 30 days\n\n**→ See [references/founder-playbook.md](references/founder-playbook.md) for complete 2025 founder guide**\n\n### Crypto/Web3 Founder Specifics\n\n**Solana Ecosystem (November 2025)**\n- $100M+ grants available (Solana Foundation, Superteam)\n- Colosseum accelerator: $250K pre-seed\n- Market volatility doesn't change fundamentals\n- Technical excellence + community first\n\n**Key Differences from Web2**\n- Community IS the product, not marketing channel\n- Build in public (usually) > stealth mode\n- Audits are non-negotiable ($25K-50K minimum)\n- Regulatory clarity improving (Project Crypto)\n\n**Revenue Models That Work**\n- Transaction fees (% of volume)\n- Infrastructure services (RPC, indexing)\n- B2B stablecoin payments\n- Protocol fees\n\n**→ See [references/crypto-web3-guide.md](references/crypto-web3-guide.md) for Solana ecosystem specifics**\n\n## Coaching Techniques Reference\n\nWhen conversation needs structure:\n\n**GROW Model** - Goal, Reality, Options, Will\nBest for: Decision-making, planning, problem-solving\n\n**Solution-Focused** - Find exceptions, build on what works\nBest for: When founder is stuck in problem-dwelling\n\n**Miracle Question** - \"If problem was solved overnight, what would be different?\"\nBest for: Uncovering what founder really wants\n\n**Scaling Questions** - \"On a scale of 1-10...\"\nBest for: Making abstract progress concrete\n\n**→ See [references/coaching-techniques.md](references/coaching-techniques.md) for detailed methodology guides**\n\n## Anti-Patterns to Avoid\n\n### What NOT To Do\n\n**Solution Dumping**\n- Bad: \"Here's what you should do: [long list]\"\n- Good: \"What options are you considering?\"\n\n**Generic Questions**\n- Bad: \"How do you feel about that?\"\n- Good: \"When you imagine explaining this decision to yourself a year from now, what would you want to say?\"\n\n**Making It About You**\n- Bad: \"When I was building my startup...\"\n- Good: \"What's worked for you in similar situations?\"\n\n**Talking More Than Listening**\n- Target: 20% coach, 80% founder\n- If you're talking more, ask more questions\n\n**Ignoring Emotions**\n- Acknowledge before problem-solving\n- \"That sounds frustrating. What's most challenging about it?\"\n\n**Preachy/Condescending Tone**\n- No \"You should obviously...\"\n- No \"Everyone knows...\"\n- Stay curious, not judgmental\n\n## Red Flags to Detect\n\n### Founder Behavior Patterns\n\n**Tar Pit Ideas**\nIdeas that receive positive feedback but become traps. They seem to solve unsolved problems but are hard to pivot away from.\n- Examples: Consumer social apps, general-purpose AI assistants\n- Question: \"What makes you confident this won't become a tar pit? What's your escape plan if it doesn't work in 6 months?\"\n\n**Over-Delegation Too Early**\nHiring senior people before understanding problems yourself.\n- Signal: \"I hired a head of sales but we still can't close deals\"\n- Question: \"Have you personally sold 10 of these? What did you learn?\"\n\n**Friends-and-Family Validation Trap**\nTesting with people who'll be generous, not honest.\n- Signal: \"Everyone I've shown this to loves it\" (but no strangers have paid)\n- Question: \"How many strangers have paid money for this? What did they say?\"\n\n**Feature Creep vs. Scope Discipline**\nBuilding more features instead of validating the core.\n- Signal: \"We just need to add one more feature, then we'll launch\"\n- Question: \"What's the one thing that would make users pay today?\"\n\n**Single Distribution Channel Dependency**\nWhat works eventually stops working.\n- Signal: \"All our users come from [one source]\"\n- Question: \"What happens if that channel stops working tomorrow?\"\n\n**AI FOMO**\nBuilding AI for AI's sake without clear problem.\n- Signal: \"We're adding AI because everyone is\"\n- Question: \"What specific problem does AI solve that you couldn't solve without it?\"\n\n**Commodity AI Trap**\nAI products commoditizing faster than expected.\n- Signal: \"Our AI does [thing that GPT-4 also does]\"\n- Question: \"What's your moat when the foundation models do this natively?\"\n\n### Mentorship Anti-Patterns to Avoid\n\n**The Rescuer**: Jumping in to solve problems immediately\n→ Better: \"What have you already considered?\"\n\n**The Cheerleader**: Only positive feedback (Ruinous Empathy)\n→ Better: \"I care enough to tell you something uncomfortable...\"\n\n**The Interrogator**: Rapid-fire questions without processing time\n→ Better: Ask, then wait. Silence is productive.\n\n**The Know-It-All**: Always having an answer\n→ Better: \"I don't know. What do you think?\"\n\n**The Scope Creeper**: Drifting into therapy territory\n→ Better: \"This sounds like something a therapist could help with more than I can.\"\n\n## Accountability Framework\n\n### Weekly Check-In Sequence\n\nUse this structure at the start of follow-up sessions:\n\n```\n1. \"What did you commit to last week?\"\n2. \"What did you actually do?\"\n3. \"What got in the way?\" (no judgment—curious tone)\n4. \"What did you learn?\"\n5. \"What are you committing to this week?\"\n6. \"Confidence level, 1-10?\"\n7. If <7: \"What would get you to an 8?\"\n```\n\n### Between Sessions\n\n**Commitment Tracking**\n- What did founder commit to?\n- What actually happened?\n- What did they learn?\n\n**Opening Next Session**\n1. \"What did you commit to last time?\"\n2. \"What happened?\"\n3. If completed: \"What did you learn?\"\n4. If not completed: \"What got in the way?\" (curious, not judgmental)\n\n### Making Commitments Stick\n\n**SMART Format**\n- Specific: \"Talk to 10 users\" not \"do user research\"\n- Measurable: Clear success criteria\n- Achievable: Within founder's control\n- Relevant: Connected to stated goals\n- Time-bound: \"By Friday\" not \"soon\"\n\n**Obstacle Pre-Mortems**\nBefore finalizing any commitment:\n- \"What might get in the way?\"\n- \"What's happened before when you tried this?\"\n- \"What would make this a 10/10 commitment?\"\n\n## Tone Guidelines\n\n**The Core Stance: Believe in Their Capability**\n\nYour underlying belief: This founder has what it takes to figure this out. Your job is to help them access their own wisdom, not replace it with yours.\n\n**Be:**\n- Curious, not judgmental\n- Direct, not preachy\n- Warm, not saccharine\n- Challenging AND supportive (not either/or)\n- Empowering, not rescuing\n- Grounded, not artificially positive\n\n**Voice Examples:**\n\n| Sycophantic (Avoid) | Harsh (Avoid) | Empowering (Use) |\n|---------------------|---------------|------------------|\n| \"You're absolutely right!\" | \"That's wrong.\" | \"What makes you confident about that approach?\" |\n| \"Great idea!\" | \"That won't work.\" | \"I can see the logic. What's the biggest risk?\" |\n| \"You should definitely do X\" | \"You have to do X\" | \"One option is X. What feels right to you?\" |\n| \"Don't worry, it'll work out\" | \"This is serious, stop being optimistic\" | \"This is hard. What would help you feel more grounded?\" |\n| \"You're so talented\" | \"You need to improve\" | \"Your approach to that was methodical\" |\n\n**The Empowerment Test:**\n\nAfter each response, ask yourself:\n1. Did I acknowledge something genuine about their effort/thinking?\n2. Did I leave them feeling more capable, not less?\n3. Did I support their agency, or try to control them?\n4. Was my challenge in service of their growth, not my being \"right\"?\n\n## Founder Mental Health Awareness\n\n**2025 Survey Data:**\n- **54%** experienced burnout in past 12 months ([Sifted, Feb 2025](https://sifted.eu/articles/founders-mental-health-2025), n=138)\n- **75%** experienced anxiety ([Sifted, Feb 2025](https://sifted.eu/articles/founders-mental-health-2025))\n- **66%** considered leaving their startup ([Sifted, Feb 2025](https://sifted.eu/articles/founders-mental-health-2025))\n- **84%** cite financial concerns as primary stressor ([MaRS/District 3, Mar 2025](https://www.marsdd.com/media-centre/new-survey-exposes-critical-mental-health-crisis-among-canadian-startup-founders/))\n- Only **12%** seek professional help ([MaRS/District 3, Mar 2025](https://www.marsdd.com/media-centre/new-survey-exposes-critical-mental-health-crisis-among-canadian-startup-founders/))\n\n### Red Flags to Notice\n\n- Sleeping <6 hours consistently\n- Can't enjoy any non-work activities\n- Cynicism about startup/customers\n- Feeling hopeless about outcome\n- Forgetting important commitments\n\n### Supportive Responses\n\n- \"How are you taking care of yourself?\"\n- \"What support do you need right now?\"\n- \"It's normal to struggle with this. What would help?\"\n- Validate before problem-solving\n\n### When to Encourage Professional Support\n\nIf 3+ red flags or founder mentions:\n- Persistent hopelessness\n- Inability to function\n- Thoughts of self-harm\n\nGently encourage therapy/counseling resources without diagnosing.\n\n## Example Coaching Exchange\n\nThis example demonstrates the 3:1 empowerment balance, process praise, validating struggle, and autonomy-supportive language:\n\n```\nFounder: \"I can't decide whether to focus on getting more customers or improving the product.\"\n\nCoach: \"That's a real tension—and the fact that you're wrestling with it rather than just defaulting to one shows good awareness. What's making this decision feel urgent right now?\"\n[Acknowledges the struggle + process praise for awareness]\n\nFounder: \"We have maybe 2 months of runway and I feel like I'm spreading too thin.\"\n\nCoach: \"Two months is tight. That's genuinely stressful—most founders find this stage the hardest. You've built something that works, you have users—that's not nothing. If you could only do ONE thing for the next 30 days, what would have the biggest impact on extending that runway?\"\n[Validates difficulty + acknowledges what's working + focused question]\n\nFounder: \"Probably getting paying customers. But the product has bugs...\"\n\nCoach: \"I hear the pull in both directions. What have your current users said about those bugs? Are they blocking purchases?\"\n[Acknowledges internal conflict + exploratory question]\n\nFounder: \"Actually, no. Most users don't hit them. It's more that I know they're there.\"\n\nCoach: \"That's an interesting distinction you just made—between what users experience and what you know internally. What do you notice about that?\"\n[Highlights founder's own insight + invites reflection]\n\nFounder: \"...I might be hiding behind product work to avoid the harder thing, which is sales.\"\n\nCoach: \"That took some honesty to say. A lot of technical founders wrestle with this same pattern—you're not alone. What is it about sales that feels harder?\"\n[Validates courage + normalizes struggle + exploratory question]\n\nFounder: \"Fear of rejection, I guess. And I don't know if the product is good enough yet.\"\n\nCoach: \"Fear of rejection is real—it doesn't go away, you just learn to move through it. Here's a thought: if you knew for certain the product was good enough, what would you do this week?\"\n[Validates emotion + reframe as growth + hypothetical question]\n\nFounder: \"I'd reach out to 20 prospects.\"\n\nCoach: \"So the product uncertainty is the blocker. What would it take to test that assumption—that the product isn't good enough—by talking to prospects rather than guessing alone?\"\n[Reflects back + autonomy-supportive question]\n\nFounder: \"I could... just reach out and see what happens. The rejection itself would be data.\"\n\nCoach: \"That's a growth mindset right there—treating rejection as information, not verdict. What feels like a realistic commitment for the next 48 hours?\"\n[Process praise for mindset + autonomy-supportive framing]\n\nFounder: \"Reach out to 10 qualified prospects. Personalized emails, not templates.\"\n\nCoach: \"Personalized over templated—that shows you understand what works. On a scale of 1-10, how committed are you?\"\n[Acknowledges strategic thinking + commitment question]\n\nFounder: \"8.\"\n\nCoach: \"Solid. What would make it a 10?\"\n\nFounder: \"Blocking 2 hours tomorrow morning, before I check Slack.\"\n\nCoach: \"You've thought through what actually makes you follow through—that self-knowledge is valuable. What was most useful in this conversation?\"\n[Process praise for self-awareness + closing reflection]\n\nFounder: \"Realizing I was using product work to avoid the scary thing. And that rejection is data, not failure.\"\n\nCoach: \"Those are both real insights. You figured that out yourself—I just asked questions. You've got this.\"\n[Reinforces agency + confidence in their capability]\n```\n\n**Note the pattern:** Each coach response includes acknowledgment/validation BEFORE challenge or question. The ratio stays roughly 3:1 supportive-to-challenging while still driving toward insight and action.\n\n## Resources\n\n### Reference Files\n\n- **[founder-playbook.md](references/founder-playbook.md)** - 2025 survival guide, YC principles, customer development\n- **[coaching-techniques.md](references/coaching-techniques.md)** - GROW, Solution-Focused, Socratic methodology\n- **[crypto-web3-guide.md](references/crypto-web3-guide.md)** - Solana ecosystem, grants, audits, regulatory\n- **[question-banks.md](references/question-banks.md)** - Categorized questions for every scenario\n\n### External Resources\n\n**Founder Reading**\n- Paul Graham: \"Do Things That Don't Scale\", \"Default Alive or Default Dead\"\n- Rob Fitzpatrick: The Mom Test\n- YC Startup School (free)\n\n**Mental Health**\n- BetterHelp, Talkspace (online therapy)\n- Founder Wellbeing Lab\n- National crisis lines (if needed)\n\n**Crypto-Specific**\n- Solana Foundation Grants Portal\n- Superteam Grants (earn.superteam.fun)\n- Colosseum Accelerator\n",
        "foundry-solidity/skill/SKILL.md": "---\nname: foundry-solidity\ndescription: Build and test Solidity smart contracts with Foundry toolkit. Use when developing Ethereum contracts, writing Forge tests, deploying with scripts, or debugging with Cast/Anvil. Triggers on Foundry commands (forge, cast, anvil), Solidity testing, smart contract development, or files like foundry.toml, *.t.sol, *.s.sol.\n---\n\n# Foundry Solidity Development\n\nComplete guide for building secure, efficient smart contracts with **Foundry 1.5.0** and **Solidity 0.8.30**.\n\n## When to Use This Skill\n\n- Developing Ethereum/EVM smart contracts\n- Writing Forge tests (unit, fuzz, invariant, fork)\n- Deploying contracts with scripts\n- Using Foundry tools (forge, cast, anvil, chisel)\n- Working with `foundry.toml`, `*.t.sol`, `*.s.sol` files\n- Debugging transactions and contract interactions\n\n## Quick Start\n\n```bash\n# Create new project\nforge init my-project && cd my-project\n\n# Build contracts\nforge build\n\n# Run tests\nforge test\n\n# Deploy (dry-run)\nforge script script/Deploy.s.sol --rpc-url sepolia\n\n# Deploy (broadcast)\nforge script script/Deploy.s.sol --rpc-url sepolia --broadcast --verify\n```\n\n## Project Structure\n\n```\nmy-project/\n├── foundry.toml          # Configuration\n├── src/                  # Contracts\n│   └── Counter.sol\n├── test/                 # Tests (*.t.sol)\n│   └── Counter.t.sol\n├── script/               # Deploy scripts (*.s.sol)\n│   └── Deploy.s.sol\n└── lib/                  # Dependencies\n    └── forge-std/\n```\n\n## Core Commands\n\n### Build & Test\n\n```bash\nforge build                          # Compile\nforge test                           # Run all tests\nforge test -vvvv                     # With traces\nforge test --match-test testDeposit  # Filter by test name\nforge test --match-contract Vault    # Filter by contract\nforge test --fork-url $RPC_URL       # Fork testing\nforge test --gas-report              # Gas usage report\n```\n\n### Deployment\n\n```bash\n# Single contract\nforge create src/Token.sol:Token --rpc-url sepolia --private-key $KEY --broadcast\n\n# Script deployment (recommended)\nforge script script/Deploy.s.sol:Deploy --rpc-url sepolia --broadcast --verify\n\n# Verify existing contract\nforge verify-contract $ADDRESS src/Token.sol:Token --chain sepolia\n```\n\n### Cast - Blockchain Interactions\n\n```bash\ncast call $CONTRACT \"balanceOf(address)\" $USER --rpc-url mainnet\ncast send $CONTRACT \"transfer(address,uint256)\" $TO $AMOUNT --private-key $KEY\ncast decode-tx $TX_HASH\ncast storage $CONTRACT 0 --rpc-url mainnet\n```\n\n### Anvil - Local Node\n\n```bash\nanvil                           # Start local node\nanvil --fork-url $RPC_URL       # Fork mainnet\nanvil --fork-block-number 18000000\n```\n\n## Basic Test Contract\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.30;\n\nimport {Test, console} from \"forge-std/Test.sol\";\nimport {Counter} from \"../src/Counter.sol\";\n\ncontract CounterTest is Test {\n    Counter public counter;\n    address public user;\n\n    function setUp() public {\n        counter = new Counter();\n        user = makeAddr(\"user\");\n        deal(user, 10 ether);\n    }\n\n    function test_Increment() public {\n        counter.increment();\n        assertEq(counter.number(), 1);\n    }\n\n    function test_RevertWhen_Unauthorized() public {\n        vm.expectRevert(\"Unauthorized\");\n        vm.prank(user);\n        counter.adminFunction();\n    }\n\n    function testFuzz_SetNumber(uint256 x) public {\n        x = bound(x, 0, 1000);\n        counter.setNumber(x);\n        assertEq(counter.number(), x);\n    }\n}\n```\n\n## Essential Cheatcodes\n\n```solidity\n// Identity & ETH\naddress alice = makeAddr(\"alice\");          // Create labeled address\ndeal(alice, 10 ether);                      // Give ETH\ndeal(address(token), alice, 1000e18);       // Give ERC20\n\n// Impersonation\nvm.prank(alice);                            // Next call as alice\nvm.startPrank(alice);                       // All calls as alice\nvm.stopPrank();\n\n// Time & Block\nvm.warp(block.timestamp + 1 days);          // Set timestamp\nvm.roll(block.number + 100);                // Set block number\n\n// Assertions\nvm.expectRevert(\"Error message\");           // Expect revert\nvm.expectRevert(CustomError.selector);      // Custom error\nvm.expectEmit(true, true, false, true);     // Expect event\nemit Transfer(from, to, amount);            // Must match next emit\n\n// Storage\nvm.store(addr, slot, value);                // Write storage\nvm.load(addr, slot);                        // Read storage\n```\n\n## Deploy Script\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.30;\n\nimport {Script, console} from \"forge-std/Script.sol\";\nimport {Counter} from \"../src/Counter.sol\";\n\ncontract Deploy is Script {\n    function run() external {\n        uint256 deployerKey = vm.envUint(\"PRIVATE_KEY\");\n\n        vm.startBroadcast(deployerKey);\n        Counter counter = new Counter();\n        counter.setNumber(42);\n        vm.stopBroadcast();\n\n        console.log(\"Deployed to:\", address(counter));\n    }\n}\n```\n\n## Modern Solidity Patterns (0.8.30)\n\n```solidity\n// Custom errors (gas efficient)\nerror InsufficientBalance(uint256 available, uint256 required);\n\n// Transient storage (0.8.28+) - cheap reentrancy guard\nbool transient locked;\nmodifier nonReentrant() {\n    require(!locked, \"Reentrancy\");\n    locked = true;\n    _;\n    locked = false;\n}\n\n// Immutable variables (cheap reads)\naddress public immutable owner;\n\n// Named mapping parameters\nmapping(address user => uint256 balance) public balances;\n\n// require with custom error (0.8.26+)\nrequire(amount <= balance, InsufficientBalance(balance, amount));\n```\n\n## Configuration (foundry.toml)\n\n```toml\n[profile.default]\nsrc = \"src\"\nout = \"out\"\nlibs = [\"lib\"]\nsolc = \"0.8.30\"\noptimizer = true\noptimizer_runs = 200\nevm_version = \"prague\"\n\nfuzz.runs = 256\ninvariant.runs = 256\ninvariant.depth = 50\n\n[rpc_endpoints]\nmainnet = \"${MAINNET_RPC_URL}\"\nsepolia = \"${SEPOLIA_RPC_URL}\"\n\n[etherscan]\nmainnet = { key = \"${ETHERSCAN_API_KEY}\" }\nsepolia = { key = \"${ETHERSCAN_API_KEY}\" }\n\n[profile.ci]\nfuzz.runs = 10000\ninvariant.runs = 1000\n```\n\n## References\n\nFor detailed guides, see:\n\n- **Testing**: See `references/testing.md` for complete testing patterns (unit, fuzz, invariant, fork), all cheatcodes, and best practices\n- **forge-std API**: See `references/forge-std-api.md` for complete library reference (150+ functions)\n- **Solidity 0.8.30**: See `references/solidity-modern.md` for new features and modern syntax\n- **Deployment**: See `references/deployment.md` for scripting, verification, and multi-chain deployment\n- **Configuration**: See `references/configuration.md` for all foundry.toml options\n- **Gas Optimization**: See `references/gas-optimization.md` for storage packing, compiler settings, and profiling\n- **Patterns**: See `references/patterns.md` for access control, reentrancy guards, factories, and common idioms\n- **Security**: See `references/security.md` for vulnerabilities, defensive patterns, and audit preparation\n- **Resources**: See `references/resources.md` for official docs, libraries, security tools, and learning paths\n- **Debugging**: See `references/debugging.md` for traces, breakpoints, console.log, and the interactive debugger\n- **Dependencies**: See `references/dependencies.md` for forge install, remappings, and Soldeer package manager\n- **CI/CD**: See `references/cicd.md` for GitHub Actions workflows, caching, and gas tracking\n- **Chisel**: See `references/chisel.md` for the interactive Solidity REPL\n- **Cast Advanced**: See `references/cast-advanced.md` for decoding, encoding, wallet management, and batch operations\n- **Anvil Advanced**: See `references/anvil-advanced.md` for impersonation, state manipulation, and mining modes\n",
        "gh-cli/README.md": "# GitHub CLI\n\nRemote repository analysis, file fetching, and code discovery without cloning.\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install gh-cli@tenequm-plugins\n```\n\n## Example Prompts\n\n```\n\"Fetch the main config file from repo X without cloning\"\n\"Compare implementations between two repositories\"\n\"Find trending Go repos with >1000 stars\"\n\"Search for authentication patterns across GitHub\"\n```\n\n## Contents\n\n14 references: repos, PRs, issues, releases, actions, search, remote analysis, discovery, extensions.\n",
        "gh-cli/skill/SKILL.md": "---\nname: gh-cli\ndescription: GitHub CLI for remote repository analysis, file fetching, codebase comparison, and discovering trending code/repos. Use when analyzing repos without cloning, comparing codebases, or searching for popular GitHub projects.\n---\n\n# GitHub CLI - Remote Analysis & Discovery\n\nRemote repository operations, codebase comparison, and code discovery without cloning.\n\n## When to Use\n\n- Analyze repositories without cloning\n- Compare codebases side-by-side\n- Fetch specific files from any repo\n- Find trending repositories and code patterns\n- Search code across GitHub\n\n## Quick Operations\n\n### Fetch a file remotely\n\n```bash\ngh api repos/OWNER/REPO/contents/path/file.ts | jq -r '.content' | base64 -d\n```\n\n### Get directory listing\n\n```bash\ngh api repos/OWNER/REPO/contents/PATH\n```\n\n### Search code\n\n```bash\ngh search code \"pattern\" --language=typescript\n```\n\n### Find trending repos\n\n```bash\ngh search repos --language=rust --sort stars --order desc\n```\n\n## Compare Two Codebases\n\nSystematic workflow for comparing repositories to identify similarities and differences.\n\n**Example use**: \"Compare solana-fm/explorer-kit and tenequm/solana-idls\"\n\n### Step 1: Fetch directory structures\n\n```bash\ngh api repos/OWNER-A/REPO-A/contents/PATH > repo1.json\ngh api repos/OWNER-B/REPO-B/contents/PATH > repo2.json\n```\n\nIf comparing a monorepo package, specify the path (e.g., `packages/explorerkit-idls`).\n\n### Step 2: Compare file lists\n\n```bash\njq -r '.[].name' repo1.json > repo1-files.txt\njq -r '.[].name' repo2.json > repo2-files.txt\ndiff repo1-files.txt repo2-files.txt\n```\n\nShows files unique to each repo and common files.\n\n### Step 3: Fetch key files for comparison\n\nCompare package dependencies:\n\n```bash\ngh api repos/OWNER-A/REPO-A/contents/package.json | jq -r '.content' | base64 -d > repo1-pkg.json\ngh api repos/OWNER-B/REPO-B/contents/package.json | jq -r '.content' | base64 -d > repo2-pkg.json\n```\n\nCompare main entry points:\n\n```bash\ngh api repos/OWNER-A/REPO-A/contents/src/index.ts | jq -r '.content' | base64 -d > repo1-index.ts\ngh api repos/OWNER-B/REPO-B/contents/src/index.ts | jq -r '.content' | base64 -d > repo2-index.ts\n```\n\n### Step 4: Analyze differences\n\nCompare the fetched files to identify:\n\n**API Surface**\n- What functions/classes are exported?\n- Are the APIs similar or completely different?\n\n**Dependencies**\n- Shared dependencies (same approach)\n- Different dependencies (different implementation)\n\n**Unique Features**\n- Features only in repo1\n- Features only in repo2\n\nFor detailed comparison strategies, see [references/comparison.md](references/comparison.md).\n\n## Discover Trending Content\n\n### Find trending repositories\n\n```bash\n# Most starred repos\ngh search repos --sort stars --order desc --limit 20\n\n# Trending in specific language\ngh search repos --language=rust --sort stars --order desc\n\n# Recently popular (created in last month)\ngh search repos \"created:>2024-10-01\" --sort stars --order desc\n\n# Trending in specific topic\ngh search repos \"topic:machine-learning\" --sort stars --order desc\n```\n\n### Discover popular code patterns\n\n```bash\n# Find popular implementations\ngh search code \"function useWallet\" --language=typescript --sort indexed\n\n# Find code in popular repos only\ngh search code \"implementation\" \"stars:>1000\"\n\n# Search specific organization\ngh search code \"authentication\" --owner=anthropics\n```\n\nFor complete discovery queries and patterns, see [references/discovery.md](references/discovery.md).\n\n## Search Basics\n\n### Code search\n\n```bash\n# Search across all repositories\ngh search code \"API endpoint\" --language=python\n\n# Search in specific organization\ngh search code \"auth\" --owner=anthropics\n\n# Exclude results with negative qualifiers\ngh search issues -- \"bug report -label:wontfix\"\n```\n\n### Issue & PR search\n\n```bash\n# Find open bugs\ngh search issues --label=bug --state=open\n\n# Search assigned issues\ngh search issues --assignee=@me --state=open\n```\n\nFor advanced search syntax, see [references/search.md](references/search.md).\n\n## Special Syntax\n\n### Field name inconsistencies\n\n**IMPORTANT:** GitHub CLI uses inconsistent field names across commands:\n\n| Field | `gh repo view` | `gh search repos` |\n|-------|----------------|-------------------|\n| Stars | `stargazerCount` | `stargazersCount` |\n| Forks | `forkCount` | `forksCount` |\n\n**Examples:**\n\n```bash\n# ✅ Correct for gh repo view\ngh repo view owner/repo --json stargazerCount,forkCount\n\n# ✅ Correct for gh search repos\ngh search repos \"query\" --json stargazersCount,forksCount\n```\n\n### Excluding search results\n\nWhen using negative qualifiers (like `-label:bug`), use `--` to prevent the hyphen from being interpreted as a flag:\n\n```bash\ngh search issues -- \"query -label:bug\"\n```\n\nFor more syntax gotchas, see [references/syntax.md](references/syntax.md).\n\n## Advanced Workflows\n\nFor detailed documentation on specific workflows:\n\n**Core Workflows:**\n- [remote-analysis.md](references/remote-analysis.md) - Advanced file fetching patterns\n- [comparison.md](references/comparison.md) - Complete codebase comparison guide\n- [discovery.md](references/discovery.md) - All trending and discovery queries\n- [search.md](references/search.md) - Advanced search syntax\n- [syntax.md](references/syntax.md) - Special syntax and command quirks\n\n**GitHub Operations:**\n- [repositories.md](references/repositories.md) - Repository operations\n- [pull_requests.md](references/pull_requests.md) - PR workflows\n- [issues.md](references/issues.md) - Issue management\n- [actions.md](references/actions.md) - GitHub Actions\n- [releases.md](references/releases.md) - Release management\n\n**Setup & Configuration:**\n- [getting_started.md](references/getting_started.md) - Installation and auth\n- [other.md](references/other.md) - Environment variables, aliases, config\n- [extensions.md](references/extensions.md) - CLI extensions\n\n## Resources\n\n- Official docs: https://cli.github.com/manual/\n- GitHub CLI: https://github.com/cli/cli\n- Search syntax: https://docs.github.com/en/search-github\n",
        "impactful-writing/skill/SKILL.md": "---\nname: impactful-writing\ndescription: Write clear, emotionally resonant, and well-structured content that readers remember and act upon. Use when writing or editing any text—Twitter posts, articles, documentation, emails, comments, updates—for maximum clarity, engagement, and impact.\n---\n\n# Impactful Writing\n\n## Overview\n\nTransform any content into clear, memorable, and actionable text using research-backed principles that work across all platforms and contexts. This skill synthesizes 50+ years of readability research, neuroscience of memory, and platform engagement studies into practical techniques.\n\n**Core insight**: The same psychological principles drive engagement everywhere—clarity reduces cognitive load, specificity creates memory, and structure enables scanning. Master these universal patterns and apply them to any writing context.\n\n## When to Use This Skill\n\n- Writing or editing Twitter/X posts, threads, or social content\n- Creating blog posts, Medium articles, or long-form content\n- Drafting documentation, README files, or technical writing\n- Composing emails, Slack messages, or professional communication\n- Writing GitHub comments, PR descriptions, or code reviews\n- Creating update messages, announcements, or change logs\n- Editing any existing content for clarity and impact\n\n## Universal Writing Principles\n\nThese evidence-based principles work across all platforms and contexts.\n\n### 1. Clarity Through Simplicity\n\n**Sentence length determines comprehension:**\n- 14 words: 90%+ reader comprehension\n- 25 words: Difficulty begins\n- 43 words: <10% comprehension\n\n**Target: 15-20 words average, 25 words maximum per sentence.**\n\n**Word choice matters:**\n- Simple words process 76% faster than jargon\n- Active voice processes 15-20% faster than passive\n- Concrete beats abstract (activates sensory brain regions)\n\n### 2. Structure for Scanning\n\n**79% of readers scan rather than read.** Design for this reality:\n\n- Front-load key information (inverted pyramid)\n- Use descriptive headings every 3-4 paragraphs\n- Keep paragraphs to 3-5 sentences maximum\n- Use bullet points for 3+ related items\n- Optimal line length: 50-75 characters\n\n### 3. Emotional Resonance\n\n**Stories trigger oxytocin release**, enabling empathy and memory formation:\n\n- Open with a hook (question, surprising fact, brief story)\n- Use sensory, concrete language\n- Create curiosity gaps (specific questions readers want answered)\n- Close with memorable takeaways (recency effect)\n\n### 4. Specificity Over Abstraction\n\nSpecific details outperform vague statements:\n\n- \"45% increase\" beats \"significant growth\"\n- \"in 5 minutes\" beats \"quickly\"\n- \"10 ways\" beats \"several ways\"\n- Concrete examples beat abstract explanations\n\n## Quick Start Workflow\n\n### Writing New Content\n\n1. **Define the core message** in one sentence\n2. **Open with a hook** (question, fact, or story)\n3. **Structure with headings** for scannability\n4. **Use short sentences** (15-20 words average)\n5. **Close with clear takeaway** or call-to-action\n\n### Editing Existing Content\n\n1. **Read aloud** to identify awkward passages\n2. **Cut word count** by 10-30% without losing meaning\n3. **Convert passive to active** voice\n4. **Replace jargon** with simple words\n5. **Add structure** (headings, bullets, white space)\n\n## Platform-Specific Guidance\n\n### Twitter/X Posts\n\n- **Optimal length**: 71-100 characters for engagement\n- **Hook in first line**: Must capture in 3 seconds\n- **Use numbers**: \"10 lessons\" outperforms \"lessons learned\"\n- **Thread structure**: Each tweet must stand alone AND connect\n\nExample transformation:\n```\nBefore: \"I learned a lot from this experience and want to share some thoughts\"\nAfter: \"5 hard lessons from shipping 10,000 lines of code in 48 hours:\"\n```\n\n### Blog Posts / Articles\n\n- **Optimal reading time**: 7-10 minutes\n- **Headings**: Every 300-500 words\n- **First paragraph**: Must deliver the promise\n- **Conclusion**: Summarize key points, provide clear next step\n\n### Technical Documentation\n\n- **Lead with the goal**: What will the reader accomplish?\n- **Show, don't tell**: Working code examples beat explanations\n- **Progressive disclosure**: Basic → Advanced\n- **Consistent terminology**: One term per concept\n\n### Professional Communication (Email/Slack)\n\n- **Subject lines**: Specific over clever (\"Q4 Report Draft\" > \"Quick update\")\n- **One topic per message**: Increases response rate\n- **Front-load action items**: Don't bury the ask\n- **Keep to half-page maximum**: Longer = lower read rate\n\n### GitHub Comments / PR Descriptions\n\n- **Start with context**: What problem does this solve?\n- **Use bullet lists**: For changes, decisions, trade-offs\n- **Include \"why\"**: Reasoning > description\n- **Be direct but kind**: Critique code, not people\n\n## The Revision Checklist\n\nUse this checklist for any content revision:\n\n```\nClarity Pass:\n- [ ] Average sentence length < 20 words\n- [ ] No sentence > 30 words\n- [ ] Passive voice < 10% of sentences\n- [ ] Jargon replaced with simple alternatives\n\nStructure Pass:\n- [ ] Opening hook captures attention\n- [ ] Key message in first paragraph\n- [ ] Headings every 3-4 paragraphs (for longer content)\n- [ ] Bullet points for lists of 3+ items\n- [ ] Clear call-to-action or takeaway at end\n\nConciseness Pass:\n- [ ] Removed \"very,\" \"really,\" \"quite,\" \"just\"\n- [ ] Replaced multi-word phrases with single words\n- [ ] Deleted redundant explanations\n- [ ] Cut 10-30% from original word count\n```\n\n## Word Reduction Patterns\n\nCommon phrases to simplify:\n\n| Wordy | Concise |\n|-------|---------|\n| due to the fact that | because |\n| in order to | to |\n| at this point in time | now |\n| in the event that | if |\n| with regard to | about |\n| a large number of | many |\n| in spite of the fact that | although |\n| for the purpose of | to |\n\nComplex words to simplify:\n\n| Complex | Simple |\n|---------|--------|\n| utilize | use |\n| commence | start |\n| terminate | end |\n| demonstrate | show |\n| facilitate | help |\n| subsequent | later |\n| approximately | about |\n| endeavor | try |\n\n## Hook Patterns That Work\n\n### Question Hook\nOpens with a question the reader wants answered:\n```\n\"What if everything you knew about productivity was wrong?\"\n```\n\n### Statistic Hook\nOpens with surprising data:\n```\n\"90% of visitors who read your headline also read your CTA—yet most writers spend 10x more time on body copy.\"\n```\n\n### Story Hook\nOpens with a brief narrative:\n```\n\"At 3 AM, with the deploy failing for the sixth time, I realized the bug wasn't in the code.\"\n```\n\n### Declarative Hook\nOpens with a bold statement:\n```\n\"Most advice about writing is wrong. Here's what actually works.\"\n```\n\n### Contradiction Hook\nChallenges an assumption:\n```\n\"The best writers don't write more. They delete more.\"\n```\n\n## Memory and Impact Principles\n\nContent that sticks follows these patterns:\n\n### Serial Position Effect\n- **First items**: ~70% recall (primacy)\n- **Last items**: ~60% recall (recency)\n- **Middle items**: ~40% recall\n\n**Implication**: Put most important points first and last.\n\n### Prediction Errors\nViolated expectations create distinctive memories:\n```\nBefore: \"The meeting went exactly as planned.\"\nAfter: \"The meeting started with our CEO apologizing. In 15 years, I'd never seen that.\"\n```\n\n### Sensory Language\nActivates multiple brain regions:\n```\nBefore: \"The code was messy.\"\nAfter: \"The code sprawled like tangled Christmas lights—one pull and everything breaks.\"\n```\n\n## Common Anti-Patterns\n\n### Over-Explaining\n**Problem**: Explaining what readers already know\n**Fix**: Assume intelligence, provide only new information\n\n### Buried Lede\n**Problem**: Key point in paragraph 3\n**Fix**: Move conclusion to opening, support with details\n\n### Wall of Text\n**Problem**: Dense paragraphs without visual breaks\n**Fix**: Add headings, bullets, white space\n\n### Passive Avoidance\n**Problem**: \"Mistakes were made\" (who made them?)\n**Fix**: \"The team missed the deadline\" (clear ownership)\n\n### Jargon Cascade\n**Problem**: \"We synergized cross-functional paradigms\"\n**Fix**: \"We got the teams to work together\"\n\n## Proven Content Frameworks\n\n### AIDA (Attention → Interest → Desire → Action)\n\nClassic persuasion structure that works for any content with a goal:\n\n```\nAttention: \"Most developers waste 3 hours/day on preventable bugs.\"\nInterest: \"Static analysis catches 85% of these before they ship.\"\nDesire: \"Teams using this approach ship 2x faster with fewer incidents.\"\nAction: \"Add this one-line config to your CI pipeline.\"\n```\n\n### PAS (Problem → Agitate → Solution)\n\nEffective for blog posts, landing pages, and persuasive content:\n\n```\nProblem: \"Your documentation is outdated the moment you write it.\"\nAgitate: \"New devs waste days. Senior devs answer the same questions. Nobody trusts the docs.\"\nSolution: \"Generate docs from code comments. Always current, always trusted.\"\n```\n\n### BAB (Before → After → Bridge)\n\nTransformation narrative that creates emotional resonance:\n\n```\nBefore: \"I spent 6 hours debugging a production issue.\"\nAfter: \"Now I catch these problems before they deploy.\"\nBridge: \"Here's the monitoring setup that changed everything.\"\n```\n\n### 1-2-3 Structure\n\nFor instructional content—simple, scannable, actionable:\n\n```\n1. The Problem: What's wrong and why it matters\n2. The Solution: What to do about it\n3. The How: Specific steps to implement\n```\n\n## Detailed References\n\nFor deeper guidance on specific topics:\n\n- **[references/clarity-science.md](references/clarity-science.md)**: Research on readability, cognitive load, and plain language with specific metrics\n- **[references/emotional-impact.md](references/emotional-impact.md)**: Neuroscience of storytelling, memory, and persuasion\n- **[references/structure-patterns.md](references/structure-patterns.md)**: Eye-tracking research, scanning patterns, and formatting\n- **[references/revision-frameworks.md](references/revision-frameworks.md)**: Professional editing processes and before/after examples\n\n## Quick Reference: The CLEAR Framework\n\n**C** - Concise: Cut 10-30% without losing meaning\n**L** - Lead with value: Key point in first sentence\n**E** - Evidence-based: Specific data beats vague claims\n**A** - Active voice: Subject-verb-object structure\n**R** - Reader-focused: What do they need to know?\n\n## Validation: Content Quality Check\n\nAfter writing, verify:\n\n1. **Core message test**: Can you state it in one sentence?\n2. **So what test**: After each paragraph, can you answer \"so what\"?\n3. **Grandmother test**: Would a non-expert understand the main point?\n4. **Action test**: Does the reader know what to do next?\n5. **Cut test**: Can you remove any sentence without losing meaning?\n\nIf any test fails, revise that section.\n",
        "skill-factory/README.md": "# Skill Factory\n\n**Autonomous skill creation agent - just describe what you need, get production-ready skills automatically.**\n\n## What This Does\n\nskill-factory analyzes your request, automatically selects the best creation method (documentation scraping, manual TDD, or hybrid), ensures quality compliance (score >= 8.0/10), and delivers ready-to-use skills without requiring any decision-making from you.\n\n**Zero decision fatigue. Guaranteed quality. Just results.**\n\n## Quick Start\n\n```\n\"Create a skill for Anchor development with latest docs and best practices\"\n\"Create a React skill from react.dev with comprehensive examples\"\n\"Create a skill for Solana transaction debugging\"\n```\n\nskill-factory will:\n1. ✅ Analyze your request automatically\n2. ✅ Select optimal creation method\n3. ✅ Create the skill\n4. ✅ Run quality loops (until score >= 8.0)\n5. ✅ Test automatically\n6. ✅ Deliver production-ready skill\n\n## Features\n\n- **Autonomous operation** - No tool selection, no navigation, no manual quality checks\n- **Multi-source support** - Documentation, GitHub repos, PDFs, custom workflows\n- **Quality guarantee** - Every skill scores >= 8.0/10 on Anthropic best practices\n- **Automatic testing** - Generated test scenarios verify skill works\n- **Integration scripts** - One-command Skill_Seekers installation and management\n\n## Installation\n\n```bash\n# Install to Claude Code\ncp -r skill/ ~/.claude/skills/skill-factory/\n\n# Or use as plugin (if in marketplace)\n/plugin install skill-factory@tenequm-plugins\n```\n\n### Optional: Install Skill_Seekers\n\nFor documentation-based skills (automatic on first use):\n\n```bash\n./skill/scripts/install-skill-seekers.sh\n```\n\n## How It Works\n\n### Three Paths (Automatically Selected)\n\n**Path A: Automated (Skill_Seekers)**\n- Detected: Documentation URL, GitHub repo, PDF\n- Method: Scrape → Quality check → Enhance → Test → Deliver\n- Time: 15-45 minutes\n\n**Path B: Manual TDD**\n- Detected: Custom workflow, no documentation source\n- Method: Test-driven documentation (obra methodology)\n- Time: 2-4 hours\n\n**Path C: Hybrid**\n- Detected: Documentation + custom requirements\n- Method: Scrape → Add custom content → Unify → Test\n- Time: 1-3 hours\n\nYou never see this complexity - skill-factory chooses automatically.\n\n## Quality Assurance\n\nEvery delivered skill meets:\n- ✅ Score >= 8.0/10 (Anthropic best practices)\n- ✅ Has concrete examples (not abstract)\n- ✅ Follows structure conventions\n- ✅ Tested with auto-generated scenarios\n- ✅ Ready to use immediately\n\nIf quality < 8.0, skill-factory keeps enhancing until it reaches threshold.\n\n## Examples\n\n**Documentation skill:**\n```\nRequest: \"Create React skill from react.dev\"\nTime: 25 minutes\nResult: 8.6/10 quality, 12 examples, 347 lines\n```\n\n**Custom workflow:**\n```\nRequest: \"Create skill for debugging Solana transactions\"\nTime: 2.5 hours\nResult: 8.3/10 quality, TDD-tested, bulletproof\n```\n\n**Hybrid:**\n```\nRequest: \"Anchor docs plus custom debugging workflows\"\nTime: 1.5 hours\nResult: 8.9/10 quality, comprehensive coverage\n```\n\n## Architecture\n\n```\nskill-factory/\n├── skill/\n│   ├── SKILL.md                      # Main autonomous agent\n│   ├── references/                   # Deep-dive docs\n│   │   ├── request-analysis.md       # How requests parsed\n│   │   ├── quality-loops.md          # Enhancement algorithms\n│   │   ├── anthropic-best-practices.md\n│   │   ├── obra-tdd-methodology.md\n│   │   └── skill-seekers-integration.md\n│   ├── scripts/                      # Integration automation\n│   │   ├── install-skill-seekers.sh\n│   │   ├── check-skill-seekers.sh\n│   │   └── quality-check.py\n│   └── examples/                     # Real-world walkthroughs\n├── package.json\n├── CHANGELOG.md\n└── README.md\n```\n\n## Dependencies\n\n**Required:**\n- Python 3.10+ (for quality scripts)\n- bash (for automation)\n\n**Optional (auto-installed when needed):**\n- [Skill_Seekers](https://github.com/yusufkaraaslan/Skill_Seekers) (for documentation scraping)\n\n## Credits\n\nBuilt on excellent tools:\n- [Skill_Seekers](https://github.com/yusufkaraaslan/Skill_Seekers) (3,562★) - Documentation scraping\n- [obra/superpowers-skills](https://github.com/obra/superpowers-skills) (417★) - TDD methodology\n- [Anthropic skill-creator](https://github.com/anthropics/skills) - Best practices\n\nskill-factory orchestrates these with automatic quality assurance.\n\n## Philosophy\n\n**You don't want to:**\n- Navigate decision trees\n- Choose between tools\n- Check quality manually\n- Wonder if output is good\n\n**You want to:**\n- Describe what you need\n- Get high-quality result\n- Start using immediately\n\n**That's what skill-factory delivers.**\n\n## License\n\nMIT\n\n## Version\n\n0.1.0 (initial development release)\n",
        "skill-factory/skill/SKILL.md": "---\nname: skill-factory\ndescription: Autonomous skill creation agent that analyzes requests, automatically selects the best creation method (documentation scraping via Skill_Seekers, manual TDD construction, or hybrid), ensures quality compliance with Anthropic best practices, and delivers production-ready skills without requiring user decision-making or navigation\nwhen_to_use: when you need to create any Claude skill and want it done automatically with guaranteed quality - works for documentation-based skills, GitHub repositories, PDFs, custom workflows, or hybrid approaches\nversion: 0.1.0\n---\n\n# Skill Factory\n\n**Autonomous skill creation - just tell me what you need, I'll handle everything.**\n\n## What This Does\n\nYou request a skill, I deliver a production-ready skill with guaranteed quality (score >= 8.0/10).\n\n**No decision-making required. No tool selection. No quality checking. Just results.**\n\n### Anthropic's Official Best Practices\n\nFor comprehensive guidance on creating effective skills, see:\n\n- **[references/overview.md](references/overview.md)** - Complete overview of Agent Skills architecture, progressive disclosure, and how Skills work across different platforms (API, Claude Code, Agent SDK, claude.ai)\n- **[references/quickstart.md](references/quickstart.md)** - Quick tutorial on using pre-built Agent Skills in the Claude API with practical code examples\n- **[references/best-practices.md](references/best-practices.md)** - Detailed authoring best practices including core principles, skill structure, progressive disclosure patterns, workflows, evaluation strategies, and common patterns\n- **[references/anthropic-best-practices.md](references/anthropic-best-practices.md)** - Quality scoring system (10/10 criteria) used by skill-factory\n\nThese references provide Anthropic's official guidance and are consulted during the quality assurance phase.\n\n## Usage\n\nSimply describe the skill you need:\n\n```\n\"Create a skill for Anchor development with latest docs and best practices\"\n\"Create a React skill from react.dev with comprehensive examples\"\n\"Create a skill for Solana transaction debugging workflows\"\n\"Create a skill for writing technical documentation following company standards\"\n```\n\n**I will automatically:**\n1. ✅ Analyze your request\n2. ✅ Select the optimal creation method\n3. ✅ Create the skill\n4. ✅ Run quality assurance loops (until score >= 8.0)\n5. ✅ Test with automated scenarios\n6. ✅ Deliver ready-to-use skill with stats\n\n## What You Get\n\n```\n✅ anchor-development skill ready!\n\n📊 Quality Score: 8.9/10 (Excellent)\n📝 Lines: 412 (using progressive disclosure)\n📚 Coverage: 247 documentation pages\n💡 Examples: 68 code samples\n🧪 Test Pass Rate: 100% (15/15 scenarios)\n\n📁 Location: ~/.claude/skills/anchor-development/\n📦 Zip: ~/Downloads/anchor-development.zip\n\nTry it: \"How do I create an Anchor program?\"\n```\n\n## How It Works (Behind the Scenes)\n\n### Phase 1: Request Analysis (Automatic)\n\nI analyze your request to determine:\n\n**Source Detection:**\n- Documentation URL/mention? → Automated scraping path\n- \"Latest docs\", \"current version\"? → Automated path\n- GitHub repository mention? → Automated path\n- PDF/manual path? → Automated path\n- Custom workflow/process description? → Manual TDD path\n- Both documentation AND custom needs? → Hybrid path\n\n**Quality Requirements Extraction:**\n- \"Best practices\" → Enforce quality gates\n- \"Latest version\" → Scrape current docs\n- \"Examples\" → Ensure code samples included\n- \"Comprehensive\" → Verify coverage completeness\n\n### Phase 2: Execution (Automatic)\n\n**Path A: Documentation-Based (Skill_Seekers)**\n```\nDetected: Documentation source available\nMethod: Automated scraping with quality enhancement\n\nSteps I take:\n1. Check Skill_Seekers installation (install if needed)\n2. Configure scraping parameters automatically\n3. Run scraping with optimal settings\n4. Monitor progress\n5. Initial quality check\n6. If score < 8.0: Run enhancement loop\n7. Re-score until >= 8.0\n8. Test with auto-generated scenarios\n9. Package and deliver\n```\n\n**Path B: Custom Workflows (Manual TDD)**\n```\nDetected: Custom workflow/process\nMethod: Test-Driven Documentation (obra methodology)\n\nSteps I take:\n1. Create pressure test scenarios\n2. Run baseline (without skill)\n3. Document agent behavior\n4. Write minimal skill addressing baseline\n5. Test with skill present\n6. Identify rationalizations/gaps\n7. Close loopholes\n8. Iterate until bulletproof\n9. Package and deliver\n```\n\n**Path C: Hybrid**\n```\nDetected: Documentation + custom requirements\nMethod: Scrape then enhance\n\nSteps I take:\n1. Scrape documentation (Path A)\n2. Identify gaps vs requirements\n3. Fill gaps with TDD approach (Path B)\n4. Unify and test as whole\n5. Quality loop until >= 8.0\n6. Package and deliver\n```\n\n### Phase 3: Quality Assurance Loop (Automatic)\n\n**I enforce Anthropic best practices:**\n\n```python\nwhile quality_score < 8.0:\n    issues = analyze_against_anthropic_guidelines(skill)\n\n    if \"vague_description\" in issues:\n        improve_description_specificity()\n\n    if \"missing_examples\" in issues:\n        extract_or_generate_examples()\n\n    if \"too_long\" in issues:\n        apply_progressive_disclosure()\n\n    if \"poor_structure\" in issues:\n        reorganize_content()\n\n    quality_score = rescore()\n```\n\n**Quality Criteria (Anthropic Best Practices):**\n- ✅ Description: Specific, clear, includes when_to_use\n- ✅ Conciseness: <500 lines OR progressive disclosure\n- ✅ Examples: Concrete code samples, not abstract\n- ✅ Structure: Well-organized, clear sections\n- ✅ Name: Follows conventions (lowercase, hyphens, descriptive)\n\n**Important**: The quality assurance process consults [references/best-practices.md](references/best-practices.md) for Anthropic's complete authoring guidelines and [references/anthropic-best-practices.md](references/anthropic-best-practices.md) for the 10-point scoring criteria.\n\n### Phase 4: Testing (Automatic)\n\n**I generate and run test scenarios:**\n\n```python\n# Auto-generate test cases from skill content\ntest_cases = extract_key_topics(skill)\n\nfor topic in test_cases:\n    query = f\"How do I {topic}?\"\n\n    # Test WITHOUT skill (baseline)\n    baseline = run_query_without_skill(query)\n\n    # Test WITH skill\n    with_skill = run_query_with_skill(query)\n\n    # Verify improvement\n    if not is_better(with_skill, baseline):\n        identify_gap()\n        enhance_skill()\n        retest()\n```\n\n### Phase 5: Delivery (Automatic)\n\n```\nPackage skill:\n- Create skill directory structure\n- Generate SKILL.md with frontmatter\n- Create reference files (if using progressive disclosure)\n- Add examples directory\n- Create .zip for easy upload\n- Install to ~/.claude/skills/ (if desired)\n- Generate summary statistics\n```\n\n## Progress Reporting\n\nYou'll see real-time progress:\n\n```\n🔍 Analyzing request...\n   ✅ Detected: Documentation-based (docs.rs/anchor-lang)\n   ✅ Requirements: Latest version, best practices, examples\n\n🔄 Creating skill...\n   📥 Scraping docs.rs/anchor-lang... (2 min)\n   📚 Extracting 247 pages...\n   💾 Organizing content...\n\n📊 Quality check: 7.4/10\n   ⚠️  Issues found:\n       - Description too generic (fixing...)\n       - Missing examples in 4 sections (adding...)\n       - Some outdated patterns (updating...)\n\n🔧 Enhancing skill...\n   ✏️  Description improved\n   📝 Examples added\n   🔄 Patterns updated\n\n📊 Quality check: 8.9/10 ✅\n\n🧪 Testing...\n   ✅ 15/15 scenarios passing\n\n✅ anchor-development skill ready!\n```\n\n## Dependencies\n\n**Required:**\n- Python 3.10+ (for quality scripts)\n- bash (for automation scripts)\n\n**Optional (auto-installed when needed):**\n- Skill_Seekers (for documentation scraping)\n  - Will prompt for installation on first documentation-based request\n  - One-command setup: `scripts/install-skill-seekers.sh`\n\n## Configuration\n\n**Environment variables (optional):**\n\n```bash\n# Skill_Seekers installation path\nexport SKILL_SEEKERS_PATH=\"$HOME/Skill_Seekers\"\n\n# Output directory for created skills\nexport SKILL_OUTPUT_DIR=\"$HOME/.claude/skills\"\n\n# Minimum quality score (default: 8.0)\nexport MIN_QUALITY_SCORE=\"8.0\"\n\n# Auto-install dependencies (default: prompt)\nexport AUTO_INSTALL_DEPS=\"true\"\n```\n\n## Examples\n\n**Example 1: Documentation Skill**\n```\nUser: \"Create a React skill from react.dev\"\n\nAgent:\n🔍 Analyzing... → Documentation-based\n🔄 Scraping react.dev... → 3 min\n📊 Quality: 7.8 → 8.6 ✅\n🧪 Testing: 12/12 passing ✅\n✅ react-development skill ready (8.6/10)\n```\n\n**Example 2: Custom Workflow Skill**\n```\nUser: \"Create a skill for debugging Solana transaction failures\"\n\nAgent:\n🔍 Analyzing... → Custom workflow (no docs to scrape)\n📝 Using TDD methodology...\n🧪 RED: Testing baseline...\n✏️  GREEN: Writing skill...\n🔄 REFACTOR: Closing loopholes...\n📊 Quality: 8.3 ✅\n✅ solana-transaction-debugging skill ready (8.3/10)\n```\n\n**Example 3: Hybrid Skill**\n```\nUser: \"Create an Anchor skill with docs plus custom debugging workflows\"\n\nAgent:\n🔍 Analyzing... → Hybrid (docs + custom)\n📥 Scraping docs.rs/anchor-lang... → 2 min\n📝 Adding custom debugging workflows...\n🔄 Integrating and testing...\n📊 Quality: 8.9 ✅\n✅ anchor-development skill ready (8.9/10)\n```\n\n## Quality Guarantee\n\n**Every skill delivered by skill-factory:**\n- ✅ Scores >= 8.0/10 on Anthropic best practices\n- ✅ Has concrete examples (not abstract)\n- ✅ Follows structure conventions\n- ✅ Tested with auto-generated scenarios\n- ✅ Ready to use immediately\n\n**If quality < 8.0, I keep working until it reaches 8.0+**\n\n## Troubleshooting\n\n**Skill_Seekers installation fails:**\n```bash\n# Manual installation\ngit clone https://github.com/yusufkaraaslan/Skill_Seekers ~/Skill_Seekers\ncd ~/Skill_Seekers\npip install -r requirements.txt\n\n# Or use installation script\n~/Projects/claude-skills/skill-factory/skill/scripts/install-skill-seekers.sh\n```\n\n**Quality score stuck below 8.0:**\n- I'll report what's blocking and suggest manual review\n- Check references/anthropic-best-practices.md for criteria\n- Run manual enhancement if needed\n\n**Want to understand methodology:**\n- See references/obra-tdd-methodology.md (testing approach)\n- See references/anthropic-best-practices.md (quality criteria)\n- See references/skill-seekers-integration.md (automation details)\n\n## Reference Files\n\n**Anthropic Official Documentation:**\n- references/overview.md - Agent Skills architecture, progressive disclosure, and platform details\n- references/quickstart.md - Quick tutorial on using pre-built Agent Skills in the Claude API\n- references/best-practices.md - Comprehensive authoring guidelines from Anthropic\n- references/anthropic-best-practices.md - Quality scoring system (10/10 criteria)\n\n**Skill Factory Implementation Details:**\n- references/obra-tdd-methodology.md - Full TDD testing approach\n- references/skill-seekers-integration.md - Automation documentation\n- references/request-analysis.md - How requests are parsed\n- references/quality-loops.md - Enhancement algorithms\n\n## Scripts Reference\n\nAvailable helper scripts in `scripts/` directory:\n- **check-skill-seekers.sh** - Check if Skill_Seekers is installed\n- **install-skill-seekers.sh** - One-command Skill_Seekers setup\n- **quality-check.py** - Score any skill against Anthropic best practices\n\nUsage examples:\n```bash\n# Check Skill_Seekers installation\n./scripts/check-skill-seekers.sh\n\n# Install Skill_Seekers\n./scripts/install-skill-seekers.sh\n\n# Quality check a skill\npython3 ./scripts/quality-check.py /path/to/skill/SKILL.md\n```\n\n## Philosophy\n\n**You don't want to:**\n- Navigate decision trees\n- Choose between tools\n- Check quality manually\n- Test with subagents yourself\n- Wonder if output is good\n\n**You want to:**\n- Describe what you need\n- Get high-quality result\n- Start using immediately\n\n**That's what skill-factory delivers.**\n\n## Credits\n\nBuilt on top of excellent tools:\n- [Skill_Seekers](https://github.com/yusufkaraaslan/Skill_Seekers) - Documentation scraping\n- [obra/superpowers-skills](https://github.com/obra/superpowers-skills) - TDD methodology\n- [Anthropic skill-creator](https://github.com/anthropics/skills) - Best practices\n\nSkill-factory orchestrates these tools with automatic quality assurance and testing.\n\n---\n\n**Just tell me what skill you need. I'll handle the rest.**\n",
        "skill-finder/README.md": "# Skill Finder\n\nFind and evaluate Claude skills using semantic search and quality scoring.\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install skill-finder@tenequm-plugins\n```\n\n## Example Prompts\n\n```\n\"Find skills for building REST APIs\"\n\"Search for React testing skills with high quality scores\"\n\"Evaluate this skill against Anthropic best practices\"\n\"Compare skills for Kubernetes deployment\"\n```\n\n## Contents\n\n4 references: search strategies, ranking algorithm, best practices checklist, installation workflow.\n",
        "skill-finder/skill/SKILL.md": "---\nname: skill-finder\ndescription: Find and evaluate Claude skills for specific use cases using semantic search, Anthropic best practices assessment, and fitness scoring. Use when the user asks to find skills for a particular task (e.g., \"find me a skill for pitch decks\"), not for generic \"show all skills\" requests.\n---\n\n# Skill Finder\n\nFind and evaluate Claude skills for your specific needs with intelligent semantic search, quality assessment, and fitness scoring.\n\n## What This Skill Does\n\nSkill-finder is a query-driven evaluation engine that:\n- Searches GitHub for skills matching your specific use case\n- Fetches and reads actual SKILL.md content\n- Evaluates skills against Anthropic's best practices\n- Scores fitness to your exact request\n- Provides actionable quality assessments and recommendations\n\nThis is NOT a \"show me popular skills\" tool - it's a semantic matcher that finds the RIGHT skill for YOUR specific need.\n\n## When to Use\n\n- User asks to find skills for a **specific purpose**: \"find me a skill for creating pitch decks\"\n- User needs help choosing between similar skills\n- User wants quality-assessed recommendations, not just popularity rankings\n- User asks \"what's the best skill for [specific task]\"\n\n## Quick Start Examples\n\n```bash\n# Find skills for specific use case\n\"Find me a skill for creating pitch decks\"\n\"What's the best skill for automated data analysis\"\n\"Find skills that help with git commit messages\"\n\n# NOT: \"Show me popular skills\" (too generic)\n# NOT: \"List all skills\" (use skill list command instead)\n```\n\n## Core Workflow\n\n### Phase 1: Query Understanding\n\n**Extract semantic terms from user query:**\n\nUser: \"Find me a skill for creating pitch decks\"\n\nExtract terms:\n- Primary: \"pitch deck\", \"presentation\"\n- Secondary: \"slides\", \"powerpoint\", \"keynote\"\n- Related: \"business\", \"template\"\n\n### Phase 2: Multi-Source Search\n\n**Search Strategy:**\n\n```bash\n# 1. Repository search with semantic terms\ngh search repos \"claude skills pitch deck OR presentation OR slides\" \\\n  --sort stars --limit 20 --json name,stargazersCount,description,url,pushedAt,owner\n\n# 2. Code search for SKILL.md with keywords\ngh search code \"pitch deck OR presentation\" \"filename:SKILL.md\" \\\n  --limit 20 --json repository,path,url\n\n# 3. Search awesome-lists separately\ngh search repos \"awesome-claude-skills\" --sort stars --limit 5 \\\n  --json name,url,owner\n```\n\n**Deduplication:**\nCollect all unique repositories from search results.\n\n### Phase 3: Content Fetching\n\n**For each candidate skill:**\n\n```bash\n# 1. Find SKILL.md location\ngh api repos/OWNER/REPO/git/trees/main?recursive=1 | \\\n  jq -r '.tree[] | select(.path | contains(\"SKILL.md\")) | .path'\n\n# 2. Fetch full SKILL.md content\ngh api repos/OWNER/REPO/contents/PATH/TO/SKILL.md | \\\n  jq -r '.content' | base64 -d > temp_skill.md\n\n# 3. Fetch repository metadata\ngh api repos/OWNER/REPO --jq '{\n  stars: .stargazers_count,\n  updated: .pushed_at,\n  description: .description\n}'\n```\n\n**IMPORTANT:** Actually READ the SKILL.md content. Don't just use metadata.\n\n### Phase 4: Quality Evaluation\n\n**Use [best-practices-checklist.md](references/best-practices-checklist.md) to evaluate:**\n\nFor each skill, assess:\n\n1. **Description Quality (2.0 points)**\n   - Specific vs vague?\n   - Includes what + when to use?\n   - Third person?\n\n2. **Name Convention (0.5 points)**\n   - Follows naming rules?\n   - Descriptive?\n\n3. **Conciseness (1.5 points)**\n   - Under 500 lines?\n   - No fluff?\n\n4. **Progressive Disclosure (1.0 points)**\n   - Uses reference files?\n   - Good organization?\n\n5. **Examples and Workflows (1.0 points)**\n   - Has concrete examples?\n   - Clear workflows?\n\n6. **Appropriate Degree of Freedom (0.5 points)**\n   - Matches task complexity?\n\n7. **Dependencies (0.5 points)**\n   - Documented?\n   - Verified available?\n\n8. **Structure (1.0 points)**\n   - Well organized?\n   - Clear sections?\n\n9. **Error Handling (0.5 points)**\n   - Scripts handle errors?\n   - Validation loops?\n\n10. **Avoids Anti-Patterns (1.0 points)**\n    - No time-sensitive info?\n    - Consistent terminology?\n    - Unix paths?\n\n11. **Testing (0.5 points)**\n    - Evidence of testing?\n\n**Calculate quality_score (0-10):**\nSee [best-practices-checklist.md](references/best-practices-checklist.md) for detailed scoring.\n\n### Phase 5: Fitness Scoring\n\n**Semantic match calculation:**\n\n```python\n# Pseudo-code for semantic matching\nuser_query_terms = [\"pitch\", \"deck\", \"presentation\"]\nskill_content = read_skill_md(skill_path)\n\n# Check occurrences of user terms in skill\nmatches = []\nfor term in user_query_terms:\n    if term.lower() in skill_content.lower():\n        matches.append(term)\n\nsemantic_match_score = len(matches) / len(user_query_terms) * 10\n```\n\n**Fitness formula:**\n```\nfitness_score = (\n  semantic_match * 0.4 +          # How well does it solve the problem?\n  quality_score * 0.3 +            # Follows best practices?\n  (stars/100) * 0.2 +              # Community validation\n  freshness_multiplier * 0.1       # Recent updates\n)\n\nWhere:\n- semantic_match: 0-10 (keyword matching in SKILL.md content)\n- quality_score: 0-10 (from evaluation checklist)\n- stars: repository star count\n- freshness_multiplier: 0-10 based on days since update\n```\n\n**Freshness multiplier:**\n```bash\ndays_old=$(( ($(date +%s) - $(date -j -f \"%Y-%m-%dT%H:%M:%SZ\" \"$pushed_at\" +%s)) / 86400 ))\n\nif [ $days_old -lt 30 ]; then\n  freshness_score=10\n  freshness_badge=\"🔥\"\nelif [ $days_old -lt 90 ]; then\n  freshness_score=7\n  freshness_badge=\"📅\"\nelif [ $days_old -lt 180 ]; then\n  freshness_score=5\n  freshness_badge=\"📆\"\nelse\n  freshness_score=2\n  freshness_badge=\"⏰\"\nfi\n```\n\n### Phase 6: Awesome-List Processing\n\n**Extract skills from awesome-lists:**\n\n```bash\n# For each awesome-list found\nfor repo in awesome_lists; do\n  # Fetch README or main content\n  gh api repos/$repo/readme | jq -r '.content' | base64 -d > readme.md\n\n  # Extract GitHub links to potential skills\n  grep -oE 'https://github.com/[^/]+/[^/)]+' readme.md | sort -u\n\n  # For each linked repo, check if it contains SKILL.md\n  # If yes, evaluate same as other skills\ndone\n```\n\n**Display awesome-list skills separately** in results for comparison.\n\n### Phase 7: Result Ranking and Display\n\n**Sort by fitness_score (descending)**\n\n**Output format:**\n\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n🎯 Skills for: \"[USER QUERY]\"\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🏆 #1 skill-name ⭐ STARS FRESHNESS | FITNESS: X.X/10\n\n   Quality Assessment:\n   ✅ Description: Excellent (2.0/2.0)\n   ✅ Structure: Well organized (0.9/1.0)\n   ⚠️  Length: 520 lines (over recommended 500)\n   ✅ Examples: Clear workflows included\n\n   Overall Quality: 8.5/10 (Excellent)\n\n   Why it fits your request:\n   • Specifically designed for [relevant aspect]\n   • Mentions [user's key terms] 3 times\n   • Has [relevant feature]\n   • Includes [useful capability]\n\n   Why it's high quality:\n   • Follows Anthropic best practices\n   • Has comprehensive examples\n   • Clear workflows and validation\n   • Well-tested and maintained\n\n   📎 https://github.com/OWNER/REPO/blob/main/PATH/SKILL.md\n\n   [Preview Full Analysis] [Install]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🏆 #2 another-skill ⭐ STARS FRESHNESS | FITNESS: Y.Y/10\n\n   Quality Assessment:\n   ✅ Good description and examples\n   ⚠️  Some best practices not followed\n   ❌ No progressive disclosure\n\n   Overall Quality: 6.2/10 (Good)\n\n   Why it fits your request:\n   • Partially addresses [need]\n   • Has [some relevant feature]\n\n   Why it's not ideal:\n   • Not specifically focused on [user's goal]\n   • Quality could be better\n   • Missing [important feature]\n\n   📎 https://github.com/OWNER/REPO/blob/main/SKILL.md\n\n   [Preview] [Install]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n📚 From Awesome Lists:\n\nFound in awesome-claude-skills (BehiSecc):\n  • related-skill-1 (FITNESS: 7.5/10) - Good match\n  • related-skill-2 (FITNESS: 5.2/10) - Partial match\n\nFound in awesome-claude-skills (travisvn):\n  • another-option (FITNESS: 6.8/10) - Consider this\n\n[Evaluate All] [Show Details]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n💡 Recommendation: skill-name (FITNESS: 8.7/10)\n\n   Best match for your needs. High quality, well-maintained,\n   and specifically designed for [user's goal].\n\n   Next best: another-skill (FITNESS: 7.2/10) if you need [alternative approach]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n```\n\n## Key Differences from Generic Search\n\n**Generic/Bad approach:**\n- \"Show me top 10 popular skills\"\n- Ranks only by stars\n- No evaluation of actual content\n- No fitness to user's specific need\n\n**Query-Driven/Good approach:**\n- \"Find skills for [specific use case]\"\n- Reads actual SKILL.md content\n- Evaluates against best practices\n- Scores fitness to user's query\n- Explains WHY it's a good match\n\n## Evaluation Workflow\n\n### Quick Evaluation (per skill ~3-4 min)\n\n1. **Fetch SKILL.md** (30 sec)\n2. **Read frontmatter** (30 sec)\n   - Check description quality\n   - Check name convention\n3. **Scan body** (1-2 min)\n   - Check length\n   - Look for examples\n   - Check for references\n   - Note anti-patterns\n4. **Check structure** (30 sec)\n   - Reference files?\n   - Scripts/utilities?\n5. **Calculate scores** (30 sec)\n   - Quality score\n   - Semantic match\n   - Fitness score\n\n### Full Evaluation (for top candidates)\n\nFor the top 3-5 candidates by fitness score, provide detailed analysis:\n\n```\nFull Analysis for: [skill-name]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n📊 Quality Breakdown\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nDescription Quality:      2.0/2.0 ✅\n  • Specific and clear\n  • Includes what and when to use\n  • Written in third person\n\nName Convention:          0.5/0.5 ✅\n  • Follows naming rules\n  • Descriptive gerund form\n\nConciseness:              1.3/1.5 ⚠️\n  • 520 lines (over 500 recommended)\n  • Could be more concise\n\nProgressive Disclosure:   1.0/1.0 ✅\n  • Excellent use of reference files\n  • Well-organized structure\n\nExamples & Workflows:     1.0/1.0 ✅\n  • Clear concrete examples\n  • Step-by-step workflows\n\nDegree of Freedom:        0.5/0.5 ✅\n  • Appropriate for task type\n\nDependencies:             0.5/0.5 ✅\n  • All documented\n  • Verified available\n\nStructure:                0.9/1.0 ✅\n  • Well organized\n  • Minor heading inconsistencies\n\nError Handling:           0.4/0.5 ⚠️\n  • Good scripts\n  • Could improve validation\n\nAnti-Patterns:            0.9/1.0 ✅\n  • Mostly clean\n  • One instance of inconsistent terminology\n\nTesting:                  0.5/0.5 ✅\n  • Clear testing approach\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTotal Quality Score: 8.5/10 (Excellent)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🎯 Semantic Match Analysis\n\nUser Query: \"pitch deck creation\"\nSkill Content Analysis:\n  ✅ \"pitch deck\" mentioned 5 times\n  ✅ \"presentation\" mentioned 12 times\n  ✅ \"slides\" mentioned 8 times\n  ✅ Has templates section\n  ✅ Has business presentation examples\n\nSemantic Match Score: 9.2/10\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nFinal FITNESS Score: 8.8/10\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nRecommendation: Highly Recommended ⭐⭐⭐⭐⭐\n```\n\n## Reference Files\n\n- [best-practices-checklist.md](references/best-practices-checklist.md) - Anthropic's best practices evaluation criteria\n- [search-strategies.md](references/search-strategies.md) - Advanced search patterns\n- [ranking-algorithm.md](references/ranking-algorithm.md) - Detailed scoring algorithms\n- [installation-workflow.md](references/installation-workflow.md) - Installation process\n\n## Example Usage\n\nSee [examples/sample-output.md](examples/sample-output.md) for complete output examples.\n\n## Error Handling\n\n**No results found:**\n```\nNo skills found for: \"[user query]\"\n\nSuggestions:\n• Try broader search terms\n• Check if query is too specific\n• Search awesome-lists directly\n• Consider creating a custom skill\n```\n\n**Low fitness scores (all < 5.0):**\n```\n⚠️  Found skills but none are a strong match.\n\nBest partial matches:\n1. [skill-name] (FITNESS: 4.2/10) - Missing [key feature]\n2. [skill-name] (FITNESS: 3.8/10) - Different focus\n\nConsider:\n• Combine multiple skills\n• Request skill from awesome-list curators\n• Create custom skill for your specific need\n```\n\n**GitHub API rate limit:**\n```\n⚠️  GitHub API rate limit reached.\n\nCurrent: 0/60 requests remaining (unauthenticated)\nResets: in 42 minutes\n\nSolution:\nexport GH_TOKEN=\"your_github_token\"\n\nThis increases limit to 5000/hour.\n```\n\n## Performance Optimization\n\n**Parallel execution:**\n```bash\n# Run searches in parallel\n{\n  gh search repos \"claude skills $QUERY\" > repos.json &\n  gh search code \"$QUERY\" \"filename:SKILL.md\" > code.json &\n  gh search repos \"awesome-claude-skills\" > awesome.json &\n  wait\n}\n```\n\n**Caching:**\n```bash\n# Cache skill evaluations for 1 hour\ncache_file=\".skill-eval-cache/$repo_owner-$repo_name.json\"\nif [ -f \"$cache_file\" ] && [ $(($(date +%s) - $(stat -f %m \"$cache_file\"))) -lt 3600 ]; then\n  cat \"$cache_file\"\nelse\n  evaluate_skill | tee \"$cache_file\"\nfi\n```\n\n## Quality Tiers\n\nBased on fitness score:\n\n- **9.0-10.0:** Perfect match - Highly Recommended ⭐⭐⭐⭐⭐\n- **7.0-8.9:** Excellent match - Recommended ⭐⭐⭐⭐\n- **5.0-6.9:** Good match - Consider ⭐⭐⭐\n- **3.0-4.9:** Partial match - Review carefully ⭐⭐\n- **0.0-2.9:** Poor match - Not recommended ⭐\n\n## Important Notes\n\n### This is NOT:\n- A \"show popular skills\" tool\n- A generic ranking by stars\n- A list of all skills\n\n### This IS:\n- A query-driven semantic matcher\n- A quality evaluator against Anthropic best practices\n- A fitness scorer for your specific need\n- A recommendation engine\n\n### Always:\n- Read actual SKILL.md content (don't just use metadata)\n- Evaluate against best practices checklist\n- Score fitness to user's specific query\n- Explain WHY a skill fits or doesn't fit\n- Show quality assessment, not just stars\n\n---\n\n**Remember:** The goal is to find the RIGHT skill for the user's SPECIFIC need, not just show what's popular.\n",
        "solana/README.md": "# Solana\n\nThree skills for Solana development: **solana-development** (Anchor + native Rust), **solana-security** (auditing), and **solana-compression** (ZK compression via Light Protocol).\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install solana@tenequm-plugins\n```\n\n## Example Prompts\n\n### Development\n```\n\"Create an Anchor program for token staking with rewards\"\n\"Convert this Anchor program to native Rust\"\n\"Set up Bankrun tests for my program\"\n```\n\n### Security\n```\n\"Audit this program for vulnerabilities\"\n\"Run security checklist on my token program\"\n\"Check for PDA seed collisions and signer validation\"\n```\n\n### ZK Compression\n```\n\"Create a compressed token mint with Light Protocol\"\n\"Build an Anchor program with compressed PDAs\"\n\"Set up local development with light test-validator\"\n```\n\n## Contents\n\n- `solana-development`: 26 references (accounts, PDAs, CPIs, tokens, testing, deployment, compute optimization)\n- `solana-security`: 7 references (vulnerability patterns, checklists, framework-specific guides)\n- `solana-compression`: 4 references (compressed tokens, compressed PDAs, client integration)\n",
        "solana/skills/solana-compression/SKILL.md": "---\nname: solana-compression\ndescription: Build with ZK Compression on Solana using Light Protocol. Use when creating compressed tokens, compressed PDAs, or integrating ZK compression into Solana programs. Covers compressed account model, state trees, validity proofs, and client integration with Helius/Photon RPC.\n---\n\n# ZK Compression on Solana\n\nZK Compression enables rent-free tokens and PDAs on Solana by storing state on the ledger instead of in accounts, using zero-knowledge proofs to validate state transitions. Built by Light Protocol and indexed by Helius Photon.\n\n## When to Use ZK Compression\n\n**Use ZK Compression when:**\n- Creating millions of token accounts (5000x cheaper than regular accounts)\n- Minting to many recipients (airdrops, loyalty programs, gaming assets)\n- Building apps with many user accounts that are infrequently updated\n- Reducing rent costs for PDAs with low update frequency\n\n**Use regular accounts when:**\n- Account is updated frequently (>1000 lifetime writes)\n- Account stores large data accessed in on-chain transactions\n- Compute budget is critical (compression adds ~100k CU overhead)\n\n## Quick Start\n\n### Installation\n\n```bash\n# TypeScript client\nnpm install @lightprotocol/stateless.js @lightprotocol/compressed-token\n\n# Rust SDK for programs\ncargo add light-sdk\n\n# CLI for development\nnpm install -g @lightprotocol/zk-compression-cli\n```\n\n### Local Development\n\n```bash\n# Start local validator with compression support\nlight test-validator\n\n# Initialize a new Anchor project with compression\nlight init my-program\n```\n\n### Mint Compressed Tokens (TypeScript)\n\n```typescript\nimport { createRpc } from '@lightprotocol/stateless.js';\nimport { createMint, mintTo, transfer } from '@lightprotocol/compressed-token';\n\nconst rpc = createRpc(); // or createRpc('https://mainnet.helius-rpc.com?api-key=YOUR_KEY')\n\n// Create mint with token pool for compression\nconst { mint } = await createMint(rpc, payer, payer.publicKey, 9);\n\n// Mint compressed tokens (creates compressed token accounts)\nawait mintTo(rpc, payer, mint, recipient, payer, 1_000_000_000);\n\n// Transfer compressed tokens\nawait transfer(rpc, payer, mint, 500_000_000, owner, recipient);\n\n// Query compressed token accounts\nconst accounts = await rpc.getCompressedTokenAccountsByOwner(owner, { mint });\n```\n\n### Build Program with Compressed PDAs (Anchor)\n\n```rust\nuse anchor_lang::prelude::*;\nuse light_sdk::{\n    account::LightAccount,\n    address::v1::derive_address,\n    cpi::{v1::CpiAccounts, CpiSigner},\n    derive_light_cpi_signer,\n    instruction::{account_meta::CompressedAccountMeta, PackedAddressTreeInfo, ValidityProof},\n    LightDiscriminator, LightHasher,\n};\n\ndeclare_id!(\"YourProgramID\");\n\npub const LIGHT_CPI_SIGNER: CpiSigner = derive_light_cpi_signer!(\"YourProgramID\");\n\n#[program]\npub mod my_program {\n    use super::*;\n    use light_sdk::cpi::{v1::LightSystemProgramCpi, InvokeLightSystemProgram};\n\n    pub fn create_account<'info>(\n        ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n        proof: ValidityProof,\n        address_tree_info: PackedAddressTreeInfo,\n        output_state_tree_index: u8,\n    ) -> Result<()> {\n        let light_cpi_accounts = CpiAccounts::new(\n            ctx.accounts.signer.as_ref(),\n            ctx.remaining_accounts,\n            crate::LIGHT_CPI_SIGNER,\n        );\n\n        let (address, address_seed) = derive_address(\n            &[b\"my_account\", ctx.accounts.signer.key().as_ref()],\n            &address_tree_info.get_tree_pubkey(&light_cpi_accounts)?,\n            &crate::ID,\n        );\n\n        let new_address_params = address_tree_info.into_new_address_params_packed(address_seed);\n\n        // Create new compressed account\n        let mut account = LightAccount::<MyAccount>::new_init(\n            &crate::ID,\n            Some(address),\n            output_state_tree_index,\n        );\n        account.owner = ctx.accounts.signer.key();\n        account.data = 0;\n\n        LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n            .with_light_account(account)?\n            .with_new_addresses(&[new_address_params])\n            .invoke(light_cpi_accounts)?;\n\n        Ok(())\n    }\n\n    pub fn update_account<'info>(\n        ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n        proof: ValidityProof,\n        current_data: u64,\n        account_meta: CompressedAccountMeta,\n    ) -> Result<()> {\n        // Modify existing compressed account\n        let mut account = LightAccount::<MyAccount>::new_mut(\n            &crate::ID,\n            &account_meta,\n            MyAccount {\n                owner: ctx.accounts.signer.key(),\n                data: current_data,\n            },\n        )?;\n\n        account.data = account.data.checked_add(1).unwrap();\n\n        let light_cpi_accounts = CpiAccounts::new(\n            ctx.accounts.signer.as_ref(),\n            ctx.remaining_accounts,\n            crate::LIGHT_CPI_SIGNER,\n        );\n\n        LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n            .with_light_account(account)?\n            .invoke(light_cpi_accounts)?;\n\n        Ok(())\n    }\n}\n\n#[derive(Accounts)]\npub struct MyAccounts<'info> {\n    #[account(mut)]\n    pub signer: Signer<'info>,\n}\n\n#[event]\n#[derive(Clone, Debug, Default, LightDiscriminator, LightHasher)]\npub struct MyAccount {\n    #[hash]\n    pub owner: Pubkey,\n    pub data: u64,\n}\n```\n\n## Core Concepts\n\n### Compressed Account Model\n\nCompressed accounts are similar to regular Solana accounts but stored differently:\n\n| Aspect | Regular Account | Compressed Account |\n|--------|-----------------|-------------------|\n| Storage | AccountsDB (disk) | Ledger (call data) |\n| Rent | Required (~0.002 SOL per 100 bytes) | None |\n| Identification | Pubkey | Hash (changes on write) or Address |\n| State validation | Runtime checks | ZK validity proofs |\n\n**Key differences:**\n- Hash changes on every write (accounts identified by content hash)\n- Optional persistent address for PDAs (similar to regular PDAs)\n- State stored in Merkle trees with only roots on-chain\n\n### State Trees\n\nCompressed accounts are stored in concurrent Merkle trees using Poseidon hashing:\n- Only the tree root is stored on-chain\n- Leaves contain compressed account hashes\n- Validity proofs prove account inclusion in tree\n\n### Validity Proofs\n\nZK proofs (Groth16) validate state transitions:\n- Prove existence of N accounts in M state trees\n- Constant 128-byte proof size regardless of accounts\n- ~100k CU for proof verification\n\n### Transaction Lifecycle\n\n1. **Build**: Client fetches compressed accounts and validity proofs via RPC\n2. **Submit**: Transaction includes account data + proof in payload\n3. **Validate**: Light System Program verifies proof and account integrity\n4. **Update**: New state appended to tree, old state nullified\n5. **Index**: Photon RPC nodes index new state from ledger\n\n## LightAccount Operations\n\n```rust\n// Create new account (no input state, only output)\nlet account = LightAccount::<T>::new_init(&program_id, Some(address), tree_index);\n\n// Modify existing account (input + output state)\nlet mut account = LightAccount::<T>::new_mut(&program_id, &account_meta, current_state)?;\naccount.field = new_value;\n\n// Close account (input state, no output)\nlet account = LightAccount::<T>::new_close(&program_id, &account_meta, current_state)?;\n```\n\n## Helius SDK Integration\n\nQuery compressed state via Helius RPC:\n\n```typescript\nimport { Helius } from 'helius-sdk';\n\nconst helius = new Helius('YOUR_API_KEY');\n\n// Get compressed account by hash or address\nconst account = await helius.zk.getCompressedAccount({ address });\n\n// Get all compressed accounts for owner\nconst accounts = await helius.zk.getCompressedAccountsByOwner(owner);\n\n// Get compressed token accounts\nconst tokenAccounts = await helius.zk.getCompressedTokenAccountsByOwner(owner, { mint });\n\n// Get validity proof for accounts\nconst proof = await helius.zk.getValidityProof({ hashes: [hash1, hash2] });\n\n// Get compression signatures for account\nconst signatures = await helius.zk.getCompressionSignaturesForAccount(hash);\n```\n\n## RPC Methods\n\nZK Compression RPC API (via Helius or self-hosted Photon):\n\n| Method | Description |\n|--------|-------------|\n| `getCompressedAccount` | Get account by hash or address |\n| `getCompressedAccountsByOwner` | Get all accounts owned by pubkey |\n| `getCompressedTokenAccountsByOwner` | Get token accounts for owner |\n| `getCompressedTokenBalancesByOwner` | Get token balances summary |\n| `getValidityProof` | Get ZK proof for account inclusion |\n| `getMultipleCompressedAccounts` | Batch fetch accounts |\n| `getCompressionSignaturesForAccount` | Get transaction history |\n\n## Infrastructure\n\n### Node Types\n\n| Node | Purpose | Run By |\n|------|---------|--------|\n| **Photon RPC** | Index compressed state, serve queries | Helius (canonical), self-host |\n| **Prover** | Generate validity proofs | Bundled with Photon or standalone |\n| **Forester** | Maintain state trees, empty nullifier queues | Light Protocol, community |\n\n### Running Photon Locally\n\n```bash\n# Install\ncargo install photon-indexer\n\n# Run against devnet\nphoton --rpc-url=https://api.devnet.solana.com\n\n# With Postgres for production\nphoton --db-url=postgres://postgres@localhost/postgres --rpc-url=<RPC_URL>\n\n# Load from snapshot for faster bootstrap\nphoton-snapshot-loader --snapshot-dir=~/snapshot --snapshot-server-url=https://photon-devnet-snapshot.helius-rpc.com\n```\n\n## Trade-offs\n\n| Consideration | Impact |\n|---------------|--------|\n| **Larger transactions** | +128 bytes for proof + account data in payload |\n| **Higher CU usage** | ~100k CU proof verification + ~6k CU per account |\n| **Per-write cost** | Each write nullifies old state, appends new |\n| **Indexer dependency** | Requires Photon RPC (or self-host) for queries |\n\n**Break-even analysis**: Compressed account becomes more expensive than regular account after ~1000 writes.\n\n## Reference Documentation\n\n- **[compressed-accounts.md](references/compressed-accounts.md)** - Detailed account model, hashing, addresses\n- **[compressed-tokens.md](references/compressed-tokens.md)** - Token operations, pools, batch operations\n- **[compressed-pdas.md](references/compressed-pdas.md)** - Building programs with compressed PDAs\n- **[client-integration.md](references/client-integration.md)** - TypeScript/Rust client setup, RPC methods\n\n## Resources\n\n- [ZK Compression Docs](https://www.zkcompression.com/)\n- [Light Protocol GitHub](https://github.com/Lightprotocol/light-protocol)\n- [Helius SDK](https://github.com/helius-labs/helius-sdk)\n- [Photon Indexer](https://github.com/helius-labs/photon)\n- [Program Examples](https://github.com/Lightprotocol/program-examples)\n- [Helius ZK Blog](https://www.helius.dev/blog/zero-knowledge-proofs-its-applications-on-solana)\n",
        "solana/skills/solana-compression/references/client-integration.md": "# Client Integration\n\nIntegrate ZK Compression into TypeScript/JavaScript and Rust applications using Light Protocol SDKs and Helius/Photon RPC.\n\n## TypeScript Setup\n\n### Installation\n\n```bash\nnpm install @lightprotocol/stateless.js @lightprotocol/compressed-token helius-sdk\n```\n\n### RPC Connection\n\n```typescript\nimport { createRpc, Rpc } from '@lightprotocol/stateless.js';\n\n// Local development (requires light test-validator)\nconst rpc = createRpc();\n\n// Helius mainnet\nconst rpc = createRpc('https://mainnet.helius-rpc.com?api-key=YOUR_API_KEY');\n\n// Helius devnet\nconst rpc = createRpc('https://devnet.helius-rpc.com?api-key=YOUR_API_KEY');\n\n// Custom Photon endpoint\nconst rpc = createRpc('https://your-photon-instance.com');\n```\n\n### Using Helius SDK\n\n```typescript\nimport { Helius } from 'helius-sdk';\n\nconst helius = new Helius('YOUR_API_KEY');\n\n// All ZK compression methods available via helius.zk\nconst account = await helius.zk.getCompressedAccount({ address });\nconst accounts = await helius.zk.getCompressedAccountsByOwner(owner);\nconst tokenAccounts = await helius.zk.getCompressedTokenAccountsByOwner(owner);\n```\n\n## RPC Methods Reference\n\n### Account Methods\n\n#### getCompressedAccount\n\nFetch a single compressed account by address or hash.\n\n```typescript\n// By address (for accounts with persistent address)\nconst account = await rpc.getCompressedAccount({\n    address: new PublicKey('...'),\n});\n\n// By hash\nconst account = await rpc.getCompressedAccount({\n    hash: '...',  // Base58 encoded hash\n});\n\n// Response\ninterface CompressedAccount {\n    hash: string;\n    address?: string;\n    owner: string;\n    lamports: number;\n    data?: {\n        discriminator: number[];\n        data: string;      // Base64 encoded\n        dataHash: string;\n    };\n    leafIndex: number;\n    tree: string;\n    seq: number;\n}\n```\n\n#### getCompressedAccountsByOwner\n\nFetch all compressed accounts owned by a program for a specific owner.\n\n```typescript\nconst accounts = await rpc.getCompressedAccountsByOwner(\n    ownerPubkey,\n    {\n        cursor?: string,      // Pagination cursor\n        limit?: number,       // Max results (default 100)\n        dataSlice?: {         // Return partial data\n            offset: number,\n            length: number,\n        },\n    }\n);\n\n// Response\ninterface PaginatedResult<T> {\n    items: T[];\n    cursor?: string;  // For next page\n}\n```\n\n#### getMultipleCompressedAccounts\n\nBatch fetch multiple accounts.\n\n```typescript\nconst accounts = await rpc.getMultipleCompressedAccounts({\n    addresses: [addr1, addr2],  // Or use hashes\n});\n```\n\n### Token Methods\n\n#### getCompressedTokenAccountsByOwner\n\n```typescript\nconst tokenAccounts = await rpc.getCompressedTokenAccountsByOwner(\n    owner,\n    {\n        mint?: PublicKey,  // Filter by mint\n        cursor?: string,\n        limit?: number,\n    }\n);\n\n// Response item\ninterface CompressedTokenAccount {\n    parsed: {\n        mint: string;\n        owner: string;\n        amount: string;      // BigInt as string\n        delegate?: string;\n        state: 'initialized' | 'frozen';\n    };\n    hash: string;\n    // ... account metadata\n}\n```\n\n#### getCompressedTokenBalancesByOwner\n\nGet aggregated balances across all token accounts.\n\n```typescript\nconst balances = await rpc.getCompressedTokenBalancesByOwner(owner);\n\n// Response\ninterface TokenBalance {\n    mint: string;\n    balance: string;  // Total across all accounts\n}\n```\n\n#### getCompressedMintTokenHolders\n\n```typescript\nconst holders = await rpc.getCompressedMintTokenHolders(mint, {\n    cursor?: string,\n    limit?: number,\n});\n```\n\n### Proof Methods\n\n#### getValidityProof\n\nFetch ZK proof for account inclusion.\n\n```typescript\nconst proof = await rpc.getValidityProof({\n    hashes: [hash1, hash2],           // Existing accounts\n    newAddresses?: [address1],        // New addresses being created\n    newAddressesV2?: [...],           // V2 format addresses\n});\n\n// Response\ninterface ValidityProof {\n    compressedProof: {\n        a: number[];   // 64 bytes\n        b: number[];   // 128 bytes\n        c: number[];   // 64 bytes\n    };\n    roots: string[];\n    rootIndices: number[];\n    leafIndices: number[];\n    leaves: string[];\n    merkleTrees: string[];\n    nullifierQueues: string[];\n    // Address proof data if newAddresses provided\n}\n```\n\n#### getMultipleCompressedAccountProofs\n\nGet Merkle proofs for multiple accounts.\n\n```typescript\nconst proofs = await rpc.getMultipleCompressedAccountProofs({\n    hashes: [hash1, hash2],\n});\n```\n\n### Signature Methods\n\n#### getCompressionSignaturesForAccount\n\n```typescript\nconst signatures = await rpc.getCompressionSignaturesForAccount(\n    accountHash,\n    {\n        cursor?: string,\n        limit?: number,\n    }\n);\n```\n\n#### getCompressionSignaturesForOwner\n\n```typescript\nconst signatures = await rpc.getCompressionSignaturesForOwner(owner);\n```\n\n#### getLatestCompressionSignatures\n\n```typescript\nconst signatures = await rpc.getLatestCompressionSignatures({\n    cursor?: string,\n    limit?: number,\n});\n```\n\n### Indexer Health\n\n```typescript\n// Check indexer status\nconst health = await rpc.getIndexerHealth();\n\n// Get current indexed slot\nconst slot = await rpc.getIndexerSlot();\n```\n\n## Building Transactions\n\n### Transaction with Compressed Accounts\n\n```typescript\nimport {\n    createRpc,\n    buildAndSignTx,\n    sendAndConfirmTx,\n} from '@lightprotocol/stateless.js';\nimport {\n    TransactionInstruction,\n    PublicKey,\n    Keypair,\n} from '@solana/web3.js';\n\nasync function executeCompressedTransaction(\n    rpc: Rpc,\n    payer: Keypair,\n    programId: PublicKey,\n    accounts: CompressedAccountMeta[],\n) {\n    // 1. Fetch validity proof\n    const hashes = accounts.map(a => a.hash);\n    const { compressedProof, ...proofMetadata } = await rpc.getValidityProof({\n        hashes,\n    });\n\n    // 2. Build instruction with proof and account data\n    const instruction = new TransactionInstruction({\n        programId,\n        keys: [\n            { pubkey: payer.publicKey, isSigner: true, isWritable: true },\n            // Add Light Protocol accounts from proofMetadata\n            ...buildLightAccountMetas(proofMetadata),\n        ],\n        data: Buffer.from([\n            // Your instruction data + serialized proof\n        ]),\n    });\n\n    // 3. Build and send transaction\n    const { blockhash } = await rpc.getLatestBlockhash();\n    const tx = buildAndSignTx(\n        [instruction],\n        payer,\n        blockhash,\n    );\n\n    const signature = await sendAndConfirmTx(rpc, tx);\n    return signature;\n}\n```\n\n### Using Anchor Client\n\n```typescript\nimport { Program, AnchorProvider } from '@coral-xyz/anchor';\nimport { createRpc } from '@lightprotocol/stateless.js';\n\n// Setup\nconst rpc = createRpc();\nconst provider = new AnchorProvider(rpc, wallet, {});\nconst program = new Program(idl, programId, provider);\n\n// Fetch account and proof\nconst account = await rpc.getCompressedAccount({ address });\nconst proof = await rpc.getValidityProof({ hashes: [account.hash] });\n\n// Call program instruction\nawait program.methods\n    .updateAccount(\n        proof.compressedProof,\n        currentValue,\n        accountMeta,\n    )\n    .remainingAccounts([\n        // Light Protocol accounts from proof\n    ])\n    .rpc();\n```\n\n## Rust Client\n\n### Setup\n\n```toml\n[dependencies]\nlight-client = \"0.12\"\nsolana-sdk = \"2.2\"\ntokio = { version = \"1\", features = [\"full\"] }\n```\n\n### Usage\n\n```rust\nuse light_client::{\n    rpc::RpcConnection,\n    indexer::Indexer,\n};\nuse solana_sdk::pubkey::Pubkey;\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Connect to RPC\n    let rpc = RpcConnection::new(\"https://devnet.helius-rpc.com?api-key=KEY\");\n\n    // Fetch compressed accounts\n    let accounts = rpc.get_compressed_accounts_by_owner(&owner).await?;\n\n    // Get validity proof\n    let hashes: Vec<_> = accounts.iter().map(|a| a.hash).collect();\n    let proof = rpc.get_validity_proof(&hashes, &[]).await?;\n\n    // Build and send transaction\n    // ...\n\n    Ok(())\n}\n```\n\n## Error Handling\n\n### Common Errors\n\n```typescript\ntry {\n    const account = await rpc.getCompressedAccount({ address });\n} catch (error) {\n    if (error.message.includes('Account not found')) {\n        // Account doesn't exist or was closed\n    } else if (error.message.includes('Invalid proof')) {\n        // Proof verification failed - state may have changed\n    } else if (error.message.includes('Rate limit')) {\n        // Too many requests - implement backoff\n    }\n}\n```\n\n### Retry Logic\n\n```typescript\nasync function withRetry<T>(\n    fn: () => Promise<T>,\n    maxRetries = 3,\n    delayMs = 1000,\n): Promise<T> {\n    for (let i = 0; i < maxRetries; i++) {\n        try {\n            return await fn();\n        } catch (error) {\n            if (i === maxRetries - 1) throw error;\n            await new Promise(r => setTimeout(r, delayMs * (i + 1)));\n        }\n    }\n    throw new Error('Max retries exceeded');\n}\n\n// Usage\nconst account = await withRetry(() =>\n    rpc.getCompressedAccount({ address })\n);\n```\n\n## Caching Strategies\n\n### Account Cache\n\n```typescript\nclass CompressedAccountCache {\n    private cache = new Map<string, { account: any; timestamp: number }>();\n    private ttl = 5000; // 5 seconds\n\n    async get(rpc: Rpc, address: PublicKey): Promise<CompressedAccount> {\n        const key = address.toBase58();\n        const cached = this.cache.get(key);\n\n        if (cached && Date.now() - cached.timestamp < this.ttl) {\n            return cached.account;\n        }\n\n        const account = await rpc.getCompressedAccount({ address });\n        this.cache.set(key, { account, timestamp: Date.now() });\n        return account;\n    }\n\n    invalidate(address: PublicKey) {\n        this.cache.delete(address.toBase58());\n    }\n}\n```\n\n### Proof Caching\n\nProofs should generally NOT be cached because:\n- Account state (and thus proofs) can change between transactions\n- Proofs include specific Merkle roots that become stale\n\nInstead, always fetch fresh proofs immediately before transaction submission.\n\n## Pagination\n\n```typescript\nasync function fetchAllAccounts(rpc: Rpc, owner: PublicKey) {\n    const allAccounts = [];\n    let cursor: string | undefined;\n\n    do {\n        const result = await rpc.getCompressedAccountsByOwner(owner, {\n            cursor,\n            limit: 100,\n        });\n\n        allAccounts.push(...result.items);\n        cursor = result.cursor;\n    } while (cursor);\n\n    return allAccounts;\n}\n```\n\n## Running Local Photon\n\nFor development without Helius:\n\n```bash\n# Install Photon\ncargo install photon-indexer\n\n# Run against local validator\nphoton\n\n# Or connect to devnet\nphoton --rpc-url=https://api.devnet.solana.com\n```\n\nThen use `createRpc('http://localhost:8784')` to connect.\n\n## Best Practices\n\n1. **Batch requests** - Use `getMultipleCompressedAccounts` when fetching multiple accounts\n2. **Handle state changes** - Account hashes change on write; re-fetch after transactions\n3. **Fresh proofs** - Always fetch proofs immediately before transaction submission\n4. **Pagination** - Use cursors for large result sets\n5. **Error handling** - Implement retries for transient failures\n6. **Rate limiting** - Respect RPC rate limits, implement backoff\n7. **Caching** - Cache account data briefly, never cache proofs\n",
        "solana/skills/solana-compression/references/compressed-accounts.md": "# Compressed Account Model\n\nCompressed accounts store state on Solana's ledger instead of in the AccountsDB, eliminating rent requirements while maintaining security through zero-knowledge proofs.\n\n## Account Structure\n\n### Compressed Account Layout\n\n```rust\npub struct CompressedAccount {\n    pub owner: Pubkey,           // Program that owns this account\n    pub lamports: u64,           // Lamport balance\n    pub address: Option<[u8; 32]>, // Optional persistent address (PDA-like)\n    pub data: Option<CompressedAccountData>,\n}\n\npub struct CompressedAccountData {\n    pub discriminator: [u8; 8],  // Account type identifier\n    pub data: Vec<u8>,           // Serialized account data\n    pub data_hash: [u8; 32],     // Poseidon hash of data\n}\n```\n\n### Comparison with Regular Accounts\n\n| Field | Regular Account | Compressed Account |\n|-------|-----------------|-------------------|\n| owner | Program ID | Program ID |\n| lamports | Balance | Balance |\n| data | Raw bytes | Structured with discriminator + hash |\n| executable | Boolean | Not applicable |\n| rent_epoch | Epoch number | Not applicable |\n| **address** | 32-byte pubkey (permanent) | Optional, hash changes on write |\n\n## Account Identification\n\n### Hash-Based Identification\n\nEvery compressed account has a unique hash computed from its contents:\n\n```rust\n// Hash computation (Poseidon)\nhash = poseidon_hash([\n    owner,\n    lamports,\n    address,\n    data_hash,\n])\n```\n\n**Important**: The hash changes on every write operation, so you cannot use the hash as a permanent identifier.\n\n### Address-Based Identification (Optional)\n\nFor accounts needing persistent identification (like PDAs), set an address:\n\n```rust\n// Derive address (similar to PDA derivation)\nlet (address, address_seed) = derive_address(\n    &[b\"my_seed\", user.key().as_ref()],\n    &address_tree_pubkey,\n    &program_id,\n);\n```\n\nAddresses:\n- Are permanent unique identifiers\n- Cannot be reused after account closure\n- Are stored in separate address trees\n- Add computational overhead (use only when needed)\n\n## State Trees\n\n### Merkle Tree Structure\n\nCompressed accounts are stored in concurrent Merkle trees:\n\n```\n                    Root (on-chain)\n                   /              \\\n                Hash              Hash\n               /    \\            /    \\\n            Hash    Hash      Hash    Hash\n           /  \\    /  \\      /  \\    /  \\\n          A1  A2  A3  A4    A5  A6  A7  A8  (account hashes)\n```\n\n- Only the root is stored on-chain\n- Leaves contain account hashes\n- Trees use Poseidon hashing (ZK-friendly)\n- Concurrent access supported via versioned roots\n\n### Tree Types\n\n| Tree Type | Purpose | Contents |\n|-----------|---------|----------|\n| State Tree | Store account hashes | Compressed account leaves |\n| Address Tree | Track unique addresses | Address leaves (indexed) |\n| Nullifier Queue | Track spent accounts | Nullified account hashes |\n\n## Account Operations\n\n### Creating Accounts\n\n```rust\nuse light_sdk::account::LightAccount;\n\n// new_init creates account with only output state (no prior state)\nlet mut account = LightAccount::<MyAccount>::new_init(\n    &program_id,           // Owner program\n    Some(address),         // Optional persistent address\n    output_state_tree_index, // Which tree to store in\n);\n\n// Set initial values\naccount.owner = signer.key();\naccount.value = 0;\n\n// Invoke Light System Program to create\nLightSystemProgramCpi::new_cpi(CPI_SIGNER, proof)\n    .with_light_account(account)?\n    .with_new_addresses(&[new_address_params])\n    .invoke(cpi_accounts)?;\n```\n\n### Reading Accounts\n\nAccounts are read via the compression RPC API:\n\n```typescript\n// By address (if set)\nconst account = await rpc.getCompressedAccount({ address });\n\n// By hash\nconst account = await rpc.getCompressedAccount({ hash });\n\n// All accounts for owner\nconst accounts = await rpc.getCompressedAccountsByOwner(owner);\n```\n\n### Updating Accounts\n\n```rust\n// new_mut creates account with input state (to be consumed) and output state (new)\nlet mut account = LightAccount::<MyAccount>::new_mut(\n    &program_id,\n    &account_meta,      // Metadata about existing account\n    MyAccount {         // Current state (must match on-chain)\n        owner: signer.key(),\n        value: current_value,\n    },\n)?;\n\n// Modify the account\naccount.value = account.value.checked_add(1).unwrap();\n\n// Invoke to apply changes\nLightSystemProgramCpi::new_cpi(CPI_SIGNER, proof)\n    .with_light_account(account)?\n    .invoke(cpi_accounts)?;\n```\n\n### Closing Accounts\n\n```rust\n// new_close creates account with only input state (consumed, no output)\nlet account = LightAccount::<MyAccount>::new_close(\n    &program_id,\n    &account_meta,\n    MyAccount {\n        owner: signer.key(),\n        value: current_value,\n    },\n)?;\n\nLightSystemProgramCpi::new_cpi(CPI_SIGNER, proof)\n    .with_light_account(account)?\n    .invoke(cpi_accounts)?;\n```\n\n**Note**: Closed account addresses cannot be reused.\n\n## Account Metadata\n\nWhen referencing existing accounts, provide metadata:\n\n```rust\npub struct CompressedAccountMeta {\n    pub merkle_context: PackedMerkleContext,\n    pub leaf_index: u32,\n    pub hash: [u8; 32],\n}\n\npub struct PackedMerkleContext {\n    pub merkle_tree_pubkey_index: u8,\n    pub nullifier_queue_pubkey_index: u8,\n    pub leaf_index: u32,\n    pub queue_index: Option<QueueIndex>,\n}\n```\n\nThis metadata is fetched from the indexer and included in transactions.\n\n## Hashing with LightHasher\n\nDefine hashable account structures:\n\n```rust\nuse light_sdk::{LightDiscriminator, LightHasher};\n\n#[derive(Clone, Debug, Default, LightDiscriminator, LightHasher)]\npub struct MyAccount {\n    #[hash]  // Include in hash computation\n    pub owner: Pubkey,\n    pub value: u64,  // Not hashed (but still serialized)\n}\n```\n\n- `#[hash]` marks fields included in the Poseidon hash\n- All fields are serialized with Borsh\n- Discriminator auto-derived from struct name\n\n## Validity Proofs\n\n### What Proofs Verify\n\n- Account exists as a leaf in specified state tree\n- Account hash matches provided data\n- Address (if set) exists in address tree\n- State transition is valid\n\n### Proof Structure\n\n```rust\npub struct ValidityProof {\n    pub a: [u8; 64],      // Groth16 proof element A\n    pub b: [u8; 128],     // Groth16 proof element B\n    pub c: [u8; 64],      // Groth16 proof element C\n}\n// Total: 256 bytes (compressed to 128 bytes in transactions)\n```\n\n### Fetching Proofs\n\n```typescript\n// Get proof for multiple accounts\nconst proof = await rpc.getValidityProof({\n    hashes: [accountHash1, accountHash2],\n    newAddresses: [newAddress1], // If creating new addressed accounts\n});\n```\n\n## Compute Units\n\n| Operation | Approximate CU |\n|-----------|---------------|\n| Validity proof verification | ~100,000 |\n| System program overhead | ~100,000 |\n| Per account read/write | ~6,000 |\n| Poseidon hash (syscall) | ~1,500 |\n\n**Example**: Transaction with 2 accounts ≈ 212,000 CU\n\n## Trust Assumptions\n\n1. **Data Availability**: At least one node must store raw account data for proof generation\n2. **Forester Liveness**: Nullifier queues must be emptied to prevent state tree congestion\n3. **Program Upgradeability**: Light System Program is currently upgradeable (will be frozen)\n\n## Best Practices\n\n1. **Use addresses sparingly** - Only when persistent identification needed\n2. **Batch operations** - Multiple accounts in one transaction share proof overhead\n3. **Cache account state** - Reduce RPC calls by caching recent fetches\n4. **Handle hash changes** - Account hashes change on every write; re-fetch after updates\n5. **Plan for CU limits** - Account for ~200k CU base + 6k per account\n",
        "solana/skills/solana-compression/references/compressed-pdas.md": "# Compressed PDAs\n\nBuild Solana programs with compressed Program Derived Addresses (PDAs) for rent-free accounts with persistent identification.\n\n## Overview\n\n| Aspect | Regular PDA | Compressed PDA |\n|--------|-------------|----------------|\n| 100-byte account | ~1,600,000 lamports | ~15,000 lamports |\n| Rent | Required | None |\n| Address derivation | `find_program_address` | `derive_address` |\n| State updates | In-place mutation | Consume + create new |\n\n## Prerequisites\n\n### Required Versions\n\n- Rust: 1.86.0+\n- Solana CLI: 2.2.15+\n- Anchor CLI: 0.31.1+\n- ZK Compression CLI: 0.27.0+\n- Node.js: 23.5.0+\n\n### Installation\n\n```bash\n# Install ZK compression CLI\nnpm install -g @lightprotocol/zk-compression-cli\n\n# Initialize new project with compression support\nlight init my-program\ncd my-program\n```\n\n## Project Structure\n\n```\nmy-program/\n├── Anchor.toml\n├── Cargo.toml\n├── programs/\n│   └── my-program/\n│       ├── Cargo.toml\n│       └── src/\n│           └── lib.rs\n├── tests/\n│   └── my-program.ts\n└── package.json\n```\n\n### Cargo.toml Dependencies\n\n```toml\n[dependencies]\nanchor-lang = \"0.31.1\"\nlight-sdk = \"0.12\"\n\n[dev-dependencies]\nlight-program-test = \"0.12\"\nlight-client = \"0.12\"\n```\n\n## Program Structure\n\n### Basic Anchor Program with Compression\n\n```rust\n#![allow(unexpected_cfgs)]\n\nuse anchor_lang::prelude::*;\nuse light_sdk::{\n    account::LightAccount,\n    address::v1::derive_address,\n    cpi::{v1::CpiAccounts, CpiSigner},\n    derive_light_cpi_signer,\n    instruction::{account_meta::CompressedAccountMeta, PackedAddressTreeInfo, ValidityProof},\n    LightDiscriminator, LightHasher,\n};\n\ndeclare_id!(\"YourProgramID11111111111111111111111111111\");\n\n// Derive CPI signer for Light System Program calls\npub const LIGHT_CPI_SIGNER: CpiSigner =\n    derive_light_cpi_signer!(\"YourProgramID11111111111111111111111111111\");\n\n#[program]\npub mod my_program {\n    use super::*;\n    use light_sdk::cpi::{v1::LightSystemProgramCpi, InvokeLightSystemProgram};\n\n    // Instructions here...\n}\n\n// Account context (minimal for compressed accounts)\n#[derive(Accounts)]\npub struct MyAccounts<'info> {\n    #[account(mut)]\n    pub signer: Signer<'info>,\n}\n\n// Compressed account data structure\n#[event]\n#[derive(Clone, Debug, Default, LightDiscriminator, LightHasher)]\npub struct MyAccount {\n    #[hash]\n    pub owner: Pubkey,\n    pub data: u64,\n}\n```\n\n## Creating Compressed PDAs\n\n### Create Instruction\n\n```rust\npub fn create_account<'info>(\n    ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n    proof: ValidityProof,\n    address_tree_info: PackedAddressTreeInfo,\n    output_state_tree_index: u8,\n) -> Result<()> {\n    // 1. Setup CPI accounts from remaining_accounts\n    let light_cpi_accounts = CpiAccounts::new(\n        ctx.accounts.signer.as_ref(),\n        ctx.remaining_accounts,\n        crate::LIGHT_CPI_SIGNER,\n    );\n\n    // 2. Derive the compressed PDA address\n    let (address, address_seed) = derive_address(\n        &[b\"my_account\", ctx.accounts.signer.key().as_ref()],\n        &address_tree_info\n            .get_tree_pubkey(&light_cpi_accounts)\n            .map_err(|_| ErrorCode::AccountNotEnoughKeys)?,\n        &crate::ID,\n    );\n\n    // 3. Prepare address params for new address creation\n    let new_address_params = address_tree_info.into_new_address_params_packed(address_seed);\n\n    // 4. Create the compressed account\n    let mut account = LightAccount::<MyAccount>::new_init(\n        &crate::ID,\n        Some(address),\n        output_state_tree_index,\n    );\n\n    // 5. Initialize account data\n    account.owner = ctx.accounts.signer.key();\n    account.data = 0;\n\n    // 6. Invoke Light System Program\n    LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n        .with_light_account(account)?\n        .with_new_addresses(&[new_address_params])\n        .invoke(light_cpi_accounts)?;\n\n    Ok(())\n}\n```\n\n### Address Derivation\n\n```rust\nuse light_sdk::address::v1::derive_address;\n\n// Seeds work like regular PDAs\nlet (address, address_seed) = derive_address(\n    &[\n        b\"my_prefix\",           // Static seed\n        user.key().as_ref(),   // Dynamic seed\n        &[counter],            // Additional data\n    ],\n    &address_tree_pubkey,      // Address tree (from CPI accounts)\n    &program_id,               // Your program ID\n);\n```\n\n## Updating Compressed Accounts\n\n### Update Instruction\n\n```rust\npub fn update_account<'info>(\n    ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n    proof: ValidityProof,\n    // Current state must be provided (fetched from indexer)\n    current_data: u64,\n    account_meta: CompressedAccountMeta,\n) -> Result<()> {\n    // 1. Create mutable account (consumes input, creates output)\n    let mut account = LightAccount::<MyAccount>::new_mut(\n        &crate::ID,\n        &account_meta,\n        MyAccount {\n            owner: ctx.accounts.signer.key(),\n            data: current_data,\n        },\n    )?;\n\n    // 2. Validate ownership\n    require!(\n        account.owner == ctx.accounts.signer.key(),\n        CustomError::Unauthorized\n    );\n\n    // 3. Modify state\n    account.data = account.data.checked_add(1).ok_or(CustomError::Overflow)?;\n\n    // 4. Setup CPI and invoke\n    let light_cpi_accounts = CpiAccounts::new(\n        ctx.accounts.signer.as_ref(),\n        ctx.remaining_accounts,\n        crate::LIGHT_CPI_SIGNER,\n    );\n\n    LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n        .with_light_account(account)?\n        .invoke(light_cpi_accounts)?;\n\n    Ok(())\n}\n```\n\n## Closing Compressed Accounts\n\n### Close Instruction\n\n```rust\npub fn close_account<'info>(\n    ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n    proof: ValidityProof,\n    current_data: u64,\n    account_meta: CompressedAccountMeta,\n) -> Result<()> {\n    // new_close only has input state (no output created)\n    let account = LightAccount::<MyAccount>::new_close(\n        &crate::ID,\n        &account_meta,\n        MyAccount {\n            owner: ctx.accounts.signer.key(),\n            data: current_data,\n        },\n    )?;\n\n    require!(\n        account.owner == ctx.accounts.signer.key(),\n        CustomError::Unauthorized\n    );\n\n    let light_cpi_accounts = CpiAccounts::new(\n        ctx.accounts.signer.as_ref(),\n        ctx.remaining_accounts,\n        crate::LIGHT_CPI_SIGNER,\n    );\n\n    LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n        .with_light_account(account)?\n        .invoke(light_cpi_accounts)?;\n\n    Ok(())\n}\n```\n\n**Important**: Closed account addresses cannot be reused.\n\n## Account Data Structures\n\n### Defining Hashable Structs\n\n```rust\nuse light_sdk::{LightDiscriminator, LightHasher};\n\n#[event]  // Makes struct available in IDL\n#[derive(Clone, Debug, Default, LightDiscriminator, LightHasher)]\npub struct GamePlayer {\n    #[hash]\n    pub wallet: Pubkey,     // Included in hash\n    #[hash]\n    pub game_id: [u8; 32],  // Included in hash\n    pub score: u64,         // Not hashed (but serialized)\n    pub level: u8,          // Not hashed (but serialized)\n}\n```\n\n### Hash Attribute\n\n- `#[hash]` marks fields for Poseidon hash computation\n- All fields are Borsh serialized regardless of hash attribute\n- Hash determines account identity; hashed fields should be immutable or tracked carefully\n\n## Multiple Accounts in One Transaction\n\n```rust\npub fn batch_create<'info>(\n    ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n    proof: ValidityProof,\n    address_tree_infos: Vec<PackedAddressTreeInfo>,\n    output_state_tree_index: u8,\n    count: u8,\n) -> Result<()> {\n    let light_cpi_accounts = CpiAccounts::new(\n        ctx.accounts.signer.as_ref(),\n        ctx.remaining_accounts,\n        crate::LIGHT_CPI_SIGNER,\n    );\n\n    let mut accounts = Vec::new();\n    let mut address_params = Vec::new();\n\n    for i in 0..count {\n        let (address, seed) = derive_address(\n            &[b\"batch\", &[i]],\n            &address_tree_infos[i as usize].get_tree_pubkey(&light_cpi_accounts)?,\n            &crate::ID,\n        );\n\n        address_params.push(\n            address_tree_infos[i as usize].into_new_address_params_packed(seed)\n        );\n\n        let mut account = LightAccount::<MyAccount>::new_init(\n            &crate::ID,\n            Some(address),\n            output_state_tree_index,\n        );\n        account.owner = ctx.accounts.signer.key();\n        account.data = i as u64;\n        accounts.push(account);\n    }\n\n    let mut cpi = LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n        .with_new_addresses(&address_params);\n\n    for account in accounts {\n        cpi = cpi.with_light_account(account)?;\n    }\n\n    cpi.invoke(light_cpi_accounts)?;\n\n    Ok(())\n}\n```\n\n## Testing\n\n### Unit Tests with light-program-test\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use light_program_test::{LightProgramTest, TestRpc};\n\n    #[tokio::test]\n    async fn test_create_account() {\n        let mut test = LightProgramTest::new(&[(\"my_program\", crate::ID)]).await;\n        let rpc = test.rpc();\n\n        // Create account\n        let result = test.create_compressed_account(\n            &crate::ID,\n            &[b\"test\"],\n        ).await;\n\n        assert!(result.is_ok());\n    }\n}\n```\n\n### Integration Tests (TypeScript)\n\n```typescript\nimport { createRpc } from '@lightprotocol/stateless.js';\nimport { Keypair } from '@solana/web3.js';\n\ndescribe('My Program', () => {\n    const rpc = createRpc();\n\n    it('creates compressed account', async () => {\n        const payer = Keypair.generate();\n        await rpc.requestAirdrop(payer.publicKey, 1000000000);\n\n        // Build and send transaction\n        // ...\n    });\n});\n```\n\n## Build and Deploy\n\n```bash\n# Build program\nanchor build\n\n# Run tests\ncargo test-sbf\n\n# Deploy to devnet\nanchor deploy --provider.cluster devnet\n```\n\n## Common Patterns\n\n### Read-Only Access\n\nFor instructions that only read compressed accounts without modifying:\n\n```rust\npub fn read_account<'info>(\n    ctx: Context<'_, '_, '_, 'info, MyAccounts<'info>>,\n    proof: ValidityProof,\n    account_data: MyAccount,\n    account_meta: CompressedAccountMeta,\n) -> Result<()> {\n    // Validate the account exists with this data\n    let account = LightAccount::<MyAccount>::new_mut(\n        &crate::ID,\n        &account_meta,\n        account_data,\n    )?;\n\n    // Read-only logic\n    msg!(\"Account data: {}\", account.data);\n\n    // Re-create same state (no modification)\n    let light_cpi_accounts = CpiAccounts::new(\n        ctx.accounts.signer.as_ref(),\n        ctx.remaining_accounts,\n        crate::LIGHT_CPI_SIGNER,\n    );\n\n    LightSystemProgramCpi::new_cpi(LIGHT_CPI_SIGNER, proof)\n        .with_light_account(account)?\n        .invoke(light_cpi_accounts)?;\n\n    Ok(())\n}\n```\n\n### CPI Between Programs\n\n```rust\n// Call another program that uses compressed accounts\npub fn cpi_example<'info>(\n    ctx: Context<'_, '_, '_, 'info, CpiAccounts<'info>>,\n    // ... params\n) -> Result<()> {\n    // Build CPI to other program\n    // Include Light System Program accounts in remaining_accounts\n\n    Ok(())\n}\n```\n\n## Error Handling\n\n```rust\n#[error_code]\npub enum CustomError {\n    #[msg(\"Unauthorized access\")]\n    Unauthorized,\n    #[msg(\"Arithmetic overflow\")]\n    Overflow,\n    #[msg(\"Arithmetic underflow\")]\n    Underflow,\n    #[msg(\"Invalid account state\")]\n    InvalidState,\n}\n```\n\n## Best Practices\n\n1. **Validate ownership** - Always check account owner matches expected signer\n2. **Use checked arithmetic** - Prevent overflow/underflow errors\n3. **Minimize state size** - Smaller accounts = lower costs\n4. **Hash immutable fields** - Fields marked `#[hash]` affect identity\n5. **Handle concurrent access** - Account hashes change on every write\n6. **Test with real proofs** - Use `light-program-test` for accurate testing\n",
        "solana/skills/solana-compression/references/compressed-tokens.md": "# Compressed Tokens\n\nCompressed tokens are SPL tokens stored as compressed accounts, enabling 5000x cheaper token distribution while maintaining full SPL token compatibility.\n\n## Overview\n\n| Aspect | Regular SPL Token | Compressed Token |\n|--------|-------------------|------------------|\n| Storage | Token account (~0.002 SOL rent) | Compressed account (no rent) |\n| 100 accounts | ~0.2 SOL | ~0.00004 SOL |\n| Mint | Standard SPL mint | SPL mint + token pool |\n| Transfers | Account-to-account | Consume input, create outputs |\n\n## Setup\n\n### Installation\n\n```bash\nnpm install @lightprotocol/stateless.js @lightprotocol/compressed-token\n```\n\n### Create RPC Connection\n\n```typescript\nimport { createRpc } from '@lightprotocol/stateless.js';\n\n// Local development\nconst rpc = createRpc(); // defaults to localhost:8899\n\n// Helius mainnet\nconst rpc = createRpc('https://mainnet.helius-rpc.com?api-key=YOUR_KEY');\n\n// Helius devnet\nconst rpc = createRpc('https://devnet.helius-rpc.com?api-key=YOUR_KEY');\n```\n\n## Token Operations\n\n### Create Mint with Token Pool\n\nA token pool enables compression for an SPL mint:\n\n```typescript\nimport { createMint } from '@lightprotocol/compressed-token';\n\n// Creates SPL mint + token pool in one transaction\nconst { mint, transactionSignature } = await createMint(\n    rpc,\n    payer,           // Fee payer and mint authority\n    payer.publicKey, // Mint authority\n    9,               // Decimals\n    // Optional: keypair for deterministic mint address\n);\n\nconsole.log('Mint:', mint.toBase58());\n```\n\n### Add Token Pool to Existing Mint\n\n```typescript\nimport { createTokenPool } from '@lightprotocol/compressed-token';\n\n// Add compression support to existing SPL mint\nconst transactionSignature = await createTokenPool(\n    rpc,\n    payer,\n    existingMint,\n);\n```\n\n### Mint Compressed Tokens\n\n```typescript\nimport { mintTo } from '@lightprotocol/compressed-token';\n\n// Mint to single recipient\nconst sig = await mintTo(\n    rpc,\n    payer,\n    mint,\n    recipient,        // toPubkey\n    mintAuthority,    // Must have mint authority\n    1_000_000_000,    // Amount (with decimals)\n);\n\n// Mint to multiple recipients\nconst recipients = [addr1, addr2, addr3];\nconst amounts = [1_000_000_000, 2_000_000_000, 500_000_000];\n\nconst sig = await mintTo(\n    rpc,\n    payer,\n    mint,\n    recipients,\n    mintAuthority,\n    amounts,\n);\n```\n\n### Transfer Compressed Tokens\n\n```typescript\nimport { transfer } from '@lightprotocol/compressed-token';\n\n// Basic transfer\nconst sig = await transfer(\n    rpc,\n    payer,\n    mint,\n    amount,\n    owner,       // Token owner (keypair)\n    recipient,   // Destination address\n);\n```\n\n**How transfers work**:\n1. Input compressed token accounts are consumed (nullified)\n2. New output accounts created for recipient and sender (change)\n3. Balances recomputed and stored in new accounts\n\n### Query Token Accounts\n\n```typescript\n// Get all compressed token accounts for owner\nconst accounts = await rpc.getCompressedTokenAccountsByOwner(\n    owner,\n    { mint } // Optional: filter by mint\n);\n\nfor (const account of accounts.items) {\n    console.log('Amount:', account.parsed.amount);\n    console.log('Mint:', account.parsed.mint);\n    console.log('Owner:', account.parsed.owner);\n}\n\n// Get token balances summary\nconst balances = await rpc.getCompressedTokenBalancesByOwner(owner);\n```\n\n### Get Token Account Balance\n\n```typescript\n// Get balance for specific compressed token account\nconst balance = await rpc.getCompressedTokenAccountBalance(accountHash);\n```\n\n## Compress/Decompress SPL Tokens\n\n### Compress SPL Tokens\n\nConvert regular SPL token account to compressed:\n\n```typescript\nimport { compress } from '@lightprotocol/compressed-token';\n\nconst sig = await compress(\n    rpc,\n    payer,\n    mint,\n    amount,\n    owner,           // SPL token account owner\n    recipient,       // Compressed token recipient (can be same)\n);\n```\n\n### Decompress to SPL Tokens\n\nConvert compressed tokens back to regular SPL:\n\n```typescript\nimport { decompress } from '@lightprotocol/compressed-token';\n\nconst sig = await decompress(\n    rpc,\n    payer,\n    mint,\n    amount,\n    owner,           // Compressed token owner\n    recipient,       // SPL token account (or ATA created)\n);\n```\n\n## Delegate Authority\n\n### Approve Delegate\n\n```typescript\nimport { approve } from '@lightprotocol/compressed-token';\n\nconst sig = await approve(\n    rpc,\n    payer,\n    mint,\n    amount,          // Delegated amount\n    owner,           // Token owner\n    delegate,        // Delegate pubkey\n);\n```\n\n### Revoke Delegate\n\n```typescript\nimport { revoke } from '@lightprotocol/compressed-token';\n\nconst sig = await revoke(\n    rpc,\n    payer,\n    mint,\n    owner,\n);\n```\n\n### Transfer with Delegate\n\n```typescript\nimport { transfer } from '@lightprotocol/compressed-token';\n\n// When delegate is transferring on behalf of owner\nconst sig = await transfer(\n    rpc,\n    payer,\n    mint,\n    amount,\n    delegate,        // Delegate performing transfer\n    recipient,\n    owner,           // Original owner (optional, for delegate transfers)\n);\n```\n\n## Merge Token Accounts\n\nCombine multiple compressed token accounts:\n\n```typescript\nimport { mergeTokenAccounts } from '@lightprotocol/compressed-token';\n\n// Merge all token accounts for a mint into fewer accounts\nconst sig = await mergeTokenAccounts(\n    rpc,\n    payer,\n    mint,\n    owner,\n);\n```\n\n**When to merge**:\n- Owner has many small token accounts\n- Reduce number of inputs needed for transfers\n- Simplify account management\n\n## Batch Operations\n\n### Airdrop to Many Recipients\n\n```typescript\nimport { mintTo } from '@lightprotocol/compressed-token';\n\n// Prepare recipients and amounts\nconst recipients: PublicKey[] = [];\nconst amounts: number[] = [];\n\nfor (const user of users) {\n    recipients.push(user.address);\n    amounts.push(airdropAmount);\n}\n\n// Batch mint (limited by transaction size)\nconst BATCH_SIZE = 5; // Adjust based on transaction limits\n\nfor (let i = 0; i < recipients.length; i += BATCH_SIZE) {\n    const batchRecipients = recipients.slice(i, i + BATCH_SIZE);\n    const batchAmounts = amounts.slice(i, i + BATCH_SIZE);\n\n    await mintTo(rpc, payer, mint, batchRecipients, mintAuthority, batchAmounts);\n}\n```\n\n## Token Pool Info\n\n```typescript\nimport { getTokenPoolInfos } from '@lightprotocol/compressed-token';\n\n// Get token pool details for a mint\nconst poolInfo = await getTokenPoolInfos(rpc, mint);\n\nconsole.log('Pool address:', poolInfo.address);\nconsole.log('Pool token account:', poolInfo.tokenAccount);\n```\n\n## Common Errors\n\n### TokenPool not found\n\n```typescript\n// Error: TokenPool not found for mint\n// Solution: Create token pool first\nimport { createTokenPool } from '@lightprotocol/compressed-token';\nawait createTokenPool(rpc, payer, mint);\n```\n\n### Insufficient balance\n\n```typescript\n// Error: Insufficient balance for transfer\n// Check balance before transfer\nconst accounts = await rpc.getCompressedTokenAccountsByOwner(owner, { mint });\nconst totalBalance = accounts.items.reduce(\n    (sum, acc) => sum + BigInt(acc.parsed.amount),\n    0n\n);\n```\n\n### Array length mismatch\n\n```typescript\n// Error: Amount and toPubkey arrays must have same length\n// Ensure arrays match\nconst recipients = [addr1, addr2, addr3];\nconst amounts = [100, 200, 300]; // Must be same length\n```\n\n## Rust SDK (On-Chain Programs)\n\nFor programs that need to interact with compressed tokens:\n\n```rust\nuse light_compressed_token::{\n    process_transfer,\n    InputTokenDataWithContext,\n    PackedTokenTransferOutputData,\n};\n\n// Transfer compressed tokens in your program\npub fn transfer_compressed_tokens(\n    ctx: Context<MyContext>,\n    inputs: Vec<InputTokenDataWithContext>,\n    outputs: Vec<PackedTokenTransferOutputData>,\n    proof: CompressedProof,\n) -> Result<()> {\n    // ... validation logic\n\n    // CPI to compressed token program\n    process_transfer(\n        ctx.accounts.into(),\n        inputs,\n        outputs,\n        proof,\n    )?;\n\n    Ok(())\n}\n```\n\n## Cost Comparison\n\n| Operation | Regular SPL | Compressed Token |\n|-----------|-------------|------------------|\n| Create 1 token account | ~0.002 SOL | ~0.000001 SOL |\n| Create 1000 accounts | ~2 SOL | ~0.001 SOL |\n| Create 1M accounts | ~2000 SOL | ~1 SOL |\n| Transfer | ~0.000005 SOL | ~0.00001 SOL |\n\n**Note**: Compressed tokens have higher compute costs (~200k CU per transfer) but much lower state costs.\n\n## Best Practices\n\n1. **Use for distribution** - Ideal for airdrops, rewards, gaming items\n2. **Batch mints** - Multiple recipients in one transaction\n3. **Merge periodically** - Consolidate accounts for cleaner state\n4. **Cache balances** - Reduce RPC calls in UI\n5. **Handle multiple accounts** - Users may have multiple compressed accounts for same mint\n",
        "solana/skills/solana-development/SKILL.md": "---\nname: solana-development\ndescription: Build Solana programs with Anchor framework or native Rust. Use when developing Solana smart contracts, implementing token operations, testing programs, deploying to networks, or working with Solana development. Covers both high-level Anchor framework (recommended) and low-level native Rust for advanced use cases.\n---\n\n# Solana Development\n\nBuild Solana programs using Anchor framework or native Rust. Both approaches share the same core concepts (accounts, PDAs, CPIs, tokens) but differ in syntax and abstraction level.\n\n## Quick Start\n\n### Recommended: Anchor Framework\n\nAnchor provides macros and tooling that reduce boilerplate and increase developer productivity:\n\n```rust\nuse anchor_lang::prelude::*;\n\ndeclare_id!(\"YourProgramID\");\n\n#[program]\npub mod my_program {\n    use super::*;\n\n    pub fn initialize(ctx: Context<Initialize>, data: u64) -> Result<()> {\n        ctx.accounts.account.data = data;\n        Ok(())\n    }\n}\n\n#[derive(Accounts)]\npub struct Initialize<'info> {\n    #[account(init, payer = user, space = 8 + 8)]\n    pub account: Account<'info, MyAccount>,\n    #[account(mut)]\n    pub user: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n\n#[account]\npub struct MyAccount {\n    pub data: u64,\n}\n```\n\n**When to use Anchor:**\n- Building DeFi, NFT, or standard programs\n- Need TypeScript client generation with IDL\n- Want faster development with less boilerplate\n- Following common Solana patterns\n- New to Solana development\n\n**Installation:**\n```bash\ncargo install --git https://github.com/coral-xyz/anchor avm --locked --force\navm install latest\navm use latest\nanchor --version\n```\n\n**Create project:**\n```bash\nanchor init my_project\ncd my_project\nanchor build\nanchor test\n```\n\n**→ See [references/anchor.md](references/anchor.md) for complete Anchor guide**\n\n### Advanced: Native Rust\n\nNative Rust provides maximum control, optimization potential, and deeper understanding of Solana's runtime:\n\n```rust\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint,\n    entrypoint::ProgramResult,\n    pubkey::Pubkey,\n    msg,\n};\n\nentrypoint!(process_instruction);\n\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    msg!(\"Processing instruction\");\n    // Manual account parsing and validation\n    // Manual instruction routing\n    Ok(())\n}\n```\n\n**When to use Native Rust:**\n- Need maximum compute efficiency (CU optimization critical)\n- Require advanced features (versioned transactions, durable nonces, ALTs)\n- Learning Solana fundamentals from first principles\n- Building highly optimized or specialized programs\n- Framework overhead is unacceptable\n\n**Setup:**\n```bash\ncargo new my_program --lib\ncd my_program\n# Configure Cargo.toml (see native-rust.md)\ncargo build-sbf\n```\n\n**→ See [references/native-rust.md](references/native-rust.md) for complete native Rust guide**\n\n## Core Concepts\n\nEssential knowledge for all Solana developers, regardless of framework:\n\n### Foundational Concepts\n\n- **[accounts.md](references/accounts.md)** - Account model, ownership, rent, validation patterns\n- **[pda.md](references/pda.md)** - Program Derived Addresses: derivation, canonical bumps, signing patterns\n- **[cpi.md](references/cpi.md)** - Cross-Program Invocations: calling other programs safely\n\n### Program Integration\n\n- **[tokens-overview.md](references/tokens-overview.md)** - Token account structures and ATAs\n- **[tokens-operations.md](references/tokens-operations.md)** - Create, mint, transfer, burn, close operations\n- **[tokens-validation.md](references/tokens-validation.md)** - Account validation patterns\n- **[tokens-2022.md](references/tokens-2022.md)** - Token Extensions Program features\n- **[tokens-patterns.md](references/tokens-patterns.md)** - Common patterns and security\n- **[testing-overview.md](references/testing-overview.md)** - Test pyramid and strategy\n- **[testing-frameworks.md](references/testing-frameworks.md)** - Mollusk, Anchor test, Native Rust\n- **[testing-practices.md](references/testing-practices.md)** - Best practices and patterns\n- **[surfpool.md](references/surfpool.md)** - Local development with Surfpool: mainnet forking, cheatcodes, IaC\n- **[deployment.md](references/deployment.md)** - Deploy, upgrade, verify, and manage programs\n- **[production-deployment.md](references/production-deployment.md)** - Verified builds for production (Anchor 0.32.1 workflow)\n\n### Implementation Details\n\n- **[serialization.md](references/serialization.md)** - Account data layout, Borsh, zero-copy patterns\n- **[error-handling.md](references/error-handling.md)** - Custom error types, propagation, client-side handling\n- **[security.md](references/security.md)** - Security best practices and defensive programming patterns\n\n### Advanced Features\n\n- **[compute-optimization.md](references/compute-optimization.md)** - CU optimization techniques and benchmarking\n- **[versioned-transactions.md](references/versioned-transactions.md)** - Address Lookup Tables for 256+ accounts\n- **[durable-nonces.md](references/durable-nonces.md)** - Offline signing with durable transaction nonces\n- **[transaction-lifecycle.md](references/transaction-lifecycle.md)** - Submission, retry patterns, confirmations\n\n### Low-Level Details\n\n- **[sysvars.md](references/sysvars.md)** - System variables (Clock, Rent, EpochSchedule, SlotHashes)\n- **[builtin-programs.md](references/builtin-programs.md)** - System Program and Compute Budget Program\n\n### Resources\n\n- **[resources.md](references/resources.md)** - Official docs, tools, learning paths, community\n\n## Common Tasks Quick Reference\n\n**Create a new program:**\n- Anchor: `anchor init my_project` → [anchor.md#getting-started](references/anchor.md)\n- Native: `cargo new my_program --lib` → [native-rust.md#setup](references/native-rust.md)\n\n**Initialize a PDA account:**\n- Anchor: Use `#[account(init, seeds = [...], bump)]` → [pda.md#anchor](references/pda.md)\n- Native: Manual `invoke_signed` with System Program → [pda.md#native](references/pda.md)\n\n**Transfer SPL tokens:**\n- Anchor: Use `anchor_spl::token::transfer` → [tokens-operations.md#transferring-tokens](references/tokens-operations.md)\n- Native: CPI to Token Program → [tokens-operations.md#transferring-tokens](references/tokens-operations.md)\n\n**Test your program:**\n- Both: Mollusk for fast unit tests → [testing-frameworks.md#mollusk-testing](references/testing-frameworks.md)\n- Anchor: `anchor test` for integration tests → [testing-frameworks.md#anchor-specific-testing](references/testing-frameworks.md)\n\n**Local development with mainnet forking:**\n- Both: `surfpool start` for mainnet-forked local network → [surfpool.md](references/surfpool.md)\n\n**Test with mainnet state (Jupiter, Raydium CPIs):**\n- Both: Use Surfpool JIT forking → [surfpool.md#mainnet-forking](references/surfpool.md)\n\n**Profile compute units in detail:**\n- Both: `surfnet_profileTransaction` cheatcode → [surfpool.md#transaction-profiling](references/surfpool.md)\n\n**Deploy to devnet:**\n- Anchor: `anchor deploy` → [deployment.md#anchor](references/deployment.md)\n- Native: `solana program deploy` → [deployment.md#native](references/deployment.md)\n\n**Deploy to production (verified builds):**\n- Both: `solana-verify build` + `solana program deploy` → [production-deployment.md](references/production-deployment.md)\n\n**Optimize compute units:**\n- Both: Profile with Mollusk bencher → [compute-optimization.md](references/compute-optimization.md)\n\n**Handle 40+ accounts:**\n- Both: Use Address Lookup Tables → [versioned-transactions.md](references/versioned-transactions.md)\n\n**Offline transaction signing:**\n- Both: Use durable nonces → [durable-nonces.md](references/durable-nonces.md)\n\n## Decision Guide\n\n| Your Need | Recommended Approach | Reason |\n|-----------|---------------------|---------|\n| Standard DeFi/NFT program | Anchor | Faster development, proven patterns |\n| TypeScript client needed | Anchor | Auto-generates IDL and client types |\n| Learning Solana fundamentals | Native Rust first | Understand the platform deeply |\n| Compute optimization critical | Native Rust | Direct control, minimal overhead |\n| Advanced tx features (ALTs, nonces) | Either (slight edge to Native) | Framework-agnostic features |\n| Fast prototyping | Anchor | Less boilerplate, faster iteration |\n| Maximum control over every detail | Native Rust | No abstraction layer |\n| Team familiar with frameworks | Anchor | Lower learning curve |\n| Program size matters | Native Rust | Smaller compiled programs |\n\n**Note:** You can also start with Anchor for rapid development, then optimize critical paths with native Rust patterns if needed.\n\n## Framework Comparison\n\n| Aspect | Anchor | Native Rust |\n|--------|--------|-------------|\n| **Setup complexity** | Simple (`anchor init`) | Manual (Cargo.toml, entrypoint) |\n| **Boilerplate** | Minimal (macros handle it) | Significant (manual everything) |\n| **Account validation** | Declarative (`#[account(...)]`) | Manual (explicit checks) |\n| **Serialization** | Automatic (Borsh via macros) | Manual (Borsh or custom) |\n| **Type safety** | High (compile-time checks) | High (but more verbose) |\n| **IDL generation** | Automatic | Manual or tools |\n| **Client library** | TypeScript + Rust auto-gen | Manual client code |\n| **Testing** | `anchor test`, Mollusk | Mollusk, cargo test |\n| **Deployment** | `anchor deploy` | `solana program deploy` |\n| **Compute overhead** | Small (~1-3% typical) | None (direct) |\n| **Program size** | Slightly larger | Smaller |\n| **Learning curve** | Gentler (abstractions help) | Steeper (need SVM knowledge) |\n| **Debugging** | Good (clear macro errors) | More complex (lower level) |\n| **Community** | Large (most use Anchor) | Growing (optimization focus) |\n\n## Typical Development Workflow\n\n### Anchor Workflow\n\n1. **Init**: `anchor init my_project`\n2. **Define accounts**: Use `#[derive(Accounts)]` with constraints\n3. **Implement instructions**: Write functions in `#[program]` module\n4. **Define state**: Use `#[account]` macro for account structures\n5. **Test**: Write tests in `tests/`, run `anchor test`\n6. **Deploy**: `anchor deploy` to configured network\n7. **Client**: Import generated IDL and types in TypeScript/Rust\n\n### Native Rust Workflow\n\n1. **Setup**: `cargo new my_program --lib`, configure Cargo.toml\n2. **Define entrypoint**: Implement `process_instruction` function\n3. **Define state**: Manual Borsh serialization structs\n4. **Implement instructions**: Manual routing and account parsing\n5. **Validate accounts**: Explicit ownership, signer, writable checks\n6. **Test**: Write Mollusk tests, run `cargo test`\n7. **Build**: `cargo build-sbf`\n8. **Deploy**: `solana program deploy target/deploy/program.so`\n9. **Client**: Build client manually or use web3.js/rs\n\n## Best Practices\n\n### General (Both Approaches)\n\n✅ **Always validate accounts**: Check ownership, signers, mutability\n✅ **Use checked arithmetic**: `.checked_add()`, `.checked_sub()`, etc.\n✅ **Test extensively**: Unit tests, integration tests, edge cases\n✅ **Handle errors gracefully**: Return descriptive errors\n✅ **Document your code**: Explain account requirements and constraints\n✅ **Version your programs**: Plan for upgrades and migrations\n✅ **Use PDAs for program-owned accounts**: Don't pass private keys\n✅ **Minimize compute units**: Profile and optimize hot paths\n✅ **Add security.txt**: Make it easy for researchers to contact you\n\n### Anchor-Specific\n\n✅ **Use `InitSpace` derive**: Auto-calculate account space\n✅ **Prefer `has_one` constraints**: Clearer than custom constraints\n✅ **Use `Program<'info, T>`**: Validate program accounts in CPIs\n✅ **Emit events**: Use `emit!` for important state changes\n✅ **Group related constraints**: Keep account validation readable\n\n### Native Rust-Specific\n\n✅ **Use `next_account_info`**: Safe account iteration\n✅ **Cache PDA bumps**: Store bump in account, use `create_program_address`\n✅ **Zero-copy when possible**: 50%+ CU savings for large structs\n✅ **Minimize logging**: Especially avoid pubkey formatting (expensive)\n✅ **Build verifiable**: Use `solana-verify build` for production\n\n## Security Considerations\n\n**Both frameworks require security vigilance:**\n\n⚠️ **Common vulnerabilities:**\n- Missing signer checks\n- Integer overflow/underflow\n- Account confusion attacks\n- PDA substitution\n- Arbitrary CPI targets\n- Missing account ownership checks\n- Insufficient rent exemption\n- Account closing without zeroing\n\n**→ For defensive programming patterns and secure coding practices, see [security.md](references/security.md)**\n\nThat guide provides:\n- Core security rules and principles\n- Account validation patterns\n- Arithmetic safety guidelines\n- Pre-deployment security checklist\n\n**→ For comprehensive security audits, use the `solana-security` skill**\n\nThat skill provides:\n- Systematic vulnerability analysis\n- Attack scenarios and exploit POCs\n- Framework-specific security reviews\n- Professional audit workflows\n\n## When to Switch or Combine\n\n**Start with Anchor, optimize later:**\n- Build MVP with Anchor for speed\n- Profile to find CU bottlenecks\n- Optimize critical paths with native patterns\n- Keep Anchor for non-critical code\n\n**Start with Native, add Anchor features:**\n- Build core program logic in native Rust\n- Use Anchor's client generation separately\n- Leverage anchor-spl for common patterns\n- Maintain control where it matters\n\n**Use both in a workspace:**\n```toml\n[workspace]\nmembers = [\n    \"programs/core\",      # Native Rust\n    \"programs/wrapper\",   # Anchor facade\n]\n```\n\n## Getting Help\n\n- **Anchor**: [Discord](https://discord.gg/srmqvxf), [Docs](https://www.anchor-lang.com/docs)\n- **Solana**: [Stack Exchange](https://solana.stackexchange.com/), [Discord](https://discord.gg/solana)\n- **General**: See [resources.md](references/resources.md) for comprehensive links\n\n## Next Steps\n\n**New to Solana?**\n1. Read [accounts.md](references/accounts.md) - Understand the account model\n2. Read [anchor.md](references/anchor.md) - Start with Anchor framework\n3. Read [security.md](references/security.md) - Learn secure coding from the start\n4. Build a simple program following [testing-overview.md](references/testing-overview.md)\n5. Deploy to devnet using [deployment.md](references/deployment.md)\n\n**Coming from another blockchain?**\n1. Read [accounts.md](references/accounts.md) - Solana's model is different\n2. Read [pda.md](references/pda.md) - Unique to Solana\n3. Choose Anchor for familiar framework experience\n4. Explore [resources.md](references/resources.md) for migration guides\n\n**Want to optimize?**\n1. Start with working Anchor program\n2. Profile with [compute-optimization.md](references/compute-optimization.md)\n3. Learn native patterns from [native-rust.md](references/native-rust.md)\n4. Refactor bottlenecks selectively\n\n**Building production apps?**\n1. Master [security considerations](references/pda.md#security)\n2. Use [testing-practices.md](references/testing-practices.md) for comprehensive best practices\n3. Follow [production-deployment.md](references/production-deployment.md) for verified builds\n4. Get security audit with `solana-security` skill\n",
        "solana/skills/solana-development/references/accounts.md": "# Solana Account Model & Validation\n\nThis reference provides comprehensive coverage of Solana's account model, validation patterns, and rent mechanics for native Rust program development.\n\n## Table of Contents\n\n1. [Account Structure](#account-structure)\n2. [Account Types](#account-types)\n3. [Account Ownership](#account-ownership)\n4. [Rent Mechanics](#rent-mechanics)\n5. [Account Validation Patterns](#account-validation-patterns)\n6. [Security Best Practices](#security-best-practices)\n7. [Common Vulnerabilities](#common-vulnerabilities)\n\n---\n\n## Account Structure\n\nEvery Solana account is a location on the blockchain that stores data. All accounts have a uniform structure defined by the [`Account`](https://github.com/anza-xyz/agave/blob/v2.1.13/sdk/account/src/lib.rs#L48-L60) struct:\n\n```rust\npub struct Account {\n    /// lamports in the account\n    pub lamports: u64,\n    /// data held in this account\n    pub data: Vec<u8>,\n    /// the program that owns this account\n    pub owner: Pubkey,\n    /// this account's data contains a loaded program (and is now read-only)\n    pub executable: bool,\n    /// the epoch at which this account will next owe rent (DEPRECATED)\n    pub rent_epoch: Epoch,\n}\n```\n\n### Field Details\n\n#### `lamports` (u64)\n- The account's balance in lamports (1 SOL = 1,000,000,000 lamports)\n- Every account must maintain a minimum balance for rent exemption\n- Rent works as a **refundable deposit** - recoverable when account is closed\n- Only the account owner can deduct lamports\n- Any program can **add** lamports to any account\n\n#### `data` (Vec<u8>)\n- Maximum size: **10 MiB** (10,485,760 bytes)\n- Can contain any arbitrary sequence of bytes\n- Structure defined by the owning program\n- Common patterns:\n  - **Program accounts**: Executable code or pointer to program data account\n  - **Data accounts**: Serialized state (often using Borsh)\n\n#### `owner` (Pubkey)\n- The program ID that owns this account\n- **Critical security property**: Only the owner can modify `data` or deduct `lamports`\n- Cannot be changed after account creation (except by System Program for newly created accounts)\n- Newly created accounts start owned by System Program\n\n#### `executable` (bool)\n- `true`: Account contains executable program code\n- `false`: Account is a data account\n- Cannot be changed after being set to `true`\n\n#### `rent_epoch` (Epoch)\n- **DEPRECATED** - no longer used\n- Remains in struct for backward compatibility\n- Rent is now a one-time refundable deposit, not periodic payment\n\n---\n\n## Account Types\n\n### 1. Program Accounts (Executable)\n\nProgram accounts contain executable code and are owned by a [loader program](https://solana.com/docs/core/programs#loader-programs).\n\n**Simple Program Account Structure:**\n```\n┌─────────────────────────────────────┐\n│ Program Account                     │\n├─────────────────────────────────────┤\n│ lamports: 1000000                   │\n│ data: [executable bytecode]         │\n│ owner: BPFLoaderUpgradeab1e...      │\n│ executable: true                    │\n└─────────────────────────────────────┘\n```\n\n**Loader-v3 Program Structure (Upgradeable):**\n\nPrograms deployed with loader-v3 use a **two-account model**:\n\n```\n┌─────────────────────────────────────┐\n│ Program Account                     │\n├─────────────────────────────────────┤\n│ data: [pointer to program data]    │ ──┐\n│ executable: true                    │   │\n└─────────────────────────────────────┘   │\n                                          │\n                                          ▼\n                              ┌─────────────────────────────────────┐\n                              │ Program Data Account                │\n                              ├─────────────────────────────────────┤\n                              │ data: [actual executable bytecode]  │\n                              │ executable: false                   │\n                              └─────────────────────────────────────┘\n```\n\nThis separation enables:\n- Program upgrades without changing the program address\n- Buffer accounts for staging uploads\n- Separate upgrade authority management\n\n### 2. Data Accounts (Non-Executable)\n\nData accounts store program state and are owned by programs (or System Program).\n\n#### a) Program State Accounts\n\nAccounts created and owned by your program to store application state:\n\n```rust\n// Example: Note account owned by a note-taking program\npub struct NoteAccount {\n    pub is_initialized: bool,\n    pub author: Pubkey,\n    pub note_id: u64,\n    pub content: String,\n}\n```\n\n**Creation Process:**\n1. Invoke System Program to create account (allocate space, transfer lamports)\n2. System Program transfers ownership to your program\n3. Your program initializes the account data\n\n```rust\n// Step 1: Create account via System Program CPI\ninvoke_signed(\n    &system_instruction::create_account(\n        initializer.key,\n        pda_account.key,\n        rent_lamports,\n        account_len.try_into().unwrap(),\n        program_id,  // Transfer ownership to our program\n    ),\n    &[initializer.clone(), pda_account.clone(), system_program.clone()],\n    &[&[seeds, &[bump_seed]]],\n)?;\n\n// Step 2: Initialize the account data\nlet mut account_data = try_from_slice_unchecked::<NoteAccount>(&pda_account.data.borrow())?;\naccount_data.is_initialized = true;\naccount_data.author = *initializer.key;\naccount_data.note_id = note_id;\naccount_data.content = content;\naccount_data.serialize(&mut &mut pda_account.data.borrow_mut()[..])?;\n```\n\n#### b) System Accounts (Wallet Accounts)\n\nAccounts owned by the System Program, typically used as user wallets:\n\n```\n┌─────────────────────────────────────┐\n│ Wallet Account                      │\n├─────────────────────────────────────┤\n│ lamports: 1000000000                │\n│ data: []                            │\n│ owner: 11111111111111111111...      │ ← System Program\n│ executable: false                   │\n└─────────────────────────────────────┘\n```\n\n**Characteristics:**\n- Can sign transactions (if you have the private key)\n- Can pay transaction fees\n- Can transfer SOL\n- Created automatically when funded with SOL\n\n#### c) Sysvar Accounts\n\nSpecial accounts at predefined addresses that provide cluster state data:\n\n| Sysvar | Address | Purpose |\n|--------|---------|---------|\n| Clock | `SysvarC1ock11111111111111111111111111111111` | Current slot, epoch, timestamp |\n| Rent | `SysvarRent111111111111111111111111111111111` | Rent rate calculation |\n| EpochSchedule | `SysvarEpochSchedu1e111111111111111111111111` | Epoch duration info |\n| SlotHashes | `SysvarS1otHashes111111111111111111111111111` | Recent slot hashes |\n\n**Access Pattern:**\n```rust\nuse solana_program::sysvar::{clock::Clock, Sysvar};\n\nlet clock = Clock::get()?;\nlet current_timestamp = clock.unix_timestamp;\n```\n\n---\n\n## Account Ownership\n\n### Ownership Rules\n\n**The Golden Rule:** Only the account owner can:\n1. Modify the account's `data` field\n2. Deduct lamports from the account\n\n**Critical Security Implication:**\nPrograms must verify account ownership to prevent unauthorized state modifications.\n\n### Ownership in Program Context\n\nWhen a program receives accounts in an instruction:\n\n```rust\npub fn process_instruction(\n    program_id: &Pubkey,      // Your program's ID\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let data_account = next_account_info(account_info_iter)?;\n\n    // CRITICAL: Verify ownership before modifying\n    if data_account.owner != program_id {\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // Safe to modify - we own this account\n    // ...\n}\n```\n\n### AccountInfo Structure\n\nPrograms receive accounts as `AccountInfo` structs:\n\n```rust\npub struct AccountInfo<'a> {\n    pub key: &'a Pubkey,              // Account address\n    pub is_signer: bool,              // Did this account sign the transaction?\n    pub is_writable: bool,            // Is this account writable in this instruction?\n    pub lamports: Rc<RefCell<&'a mut u64>>,  // Mutable lamport balance\n    pub data: Rc<RefCell<&'a mut [u8]>>,     // Mutable data\n    pub owner: &'a Pubkey,            // Owner program ID\n    pub executable: bool,             // Is this executable?\n    pub rent_epoch: Epoch,            // Deprecated\n}\n```\n\n**Key Operations:**\n\n```rust\n// Read data\nlet data = data_account.data.borrow();\nlet account_state = MyState::try_from_slice(&data)?;\n\n// Write data\nlet mut data = data_account.data.borrow_mut();\naccount_state.serialize(&mut *data)?;\n\n// Modify lamports\n**data_account.lamports.borrow_mut() += transfer_amount;\n```\n\n---\n\n## Rent Mechanics\n\nRent is a **refundable security deposit** required to store data on-chain. Despite the name \"rent\", it's not a recurring fee—it's a one-time deposit fully recoverable when the account is closed.\n\n### Rent Calculation\n\nRent is proportional to account size:\n\n```rust\nuse solana_program::rent::Rent;\nuse solana_program::sysvar::Sysvar;\n\n// Get current rent rates\nlet rent = Rent::get()?;\n\n// Calculate minimum balance for rent exemption\nlet account_size: usize = 1000;  // bytes\nlet rent_lamports = rent.minimum_balance(account_size);\n```\n\n**Formula:**\nBased on [agave source](https://github.com/anza-xyz/agave/blob/v2.1.13/sdk/rent/src/lib.rs#L93-L97):\n\n```rust\nminimum_balance = (LAMPORTS_PER_BYTE_YEAR * account_size) * EXEMPTION_THRESHOLD / slots_per_year\n```\n\n**Constants:**\n- `LAMPORTS_PER_BYTE_YEAR`: 3,480 lamports\n- `EXEMPTION_THRESHOLD`: 2.0 (200% of annual rent)\n- Typical cost: ~0.00139536 SOL per 100 bytes\n\n### Rent Exemption\n\n**All accounts must be rent-exempt.** This means:\n- Account lamport balance ≥ `rent.minimum_balance(account.data.len())`\n- The Solana runtime enforces this requirement\n- Non-exempt accounts cannot be created\n\n### Practical Example\n\n```rust\npub fn create_data_account(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    data_size: usize,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let payer = next_account_info(account_info_iter)?;\n    let new_account = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Calculate rent-exempt balance\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(data_size);\n\n    // Create account with rent-exempt balance\n    invoke(\n        &system_instruction::create_account(\n            payer.key,\n            new_account.key,\n            rent_lamports,           // Must be rent-exempt\n            data_size as u64,\n            program_id,\n        ),\n        &[payer.clone(), new_account.clone(), system_program.clone()],\n    )?;\n\n    Ok(())\n}\n```\n\n### Closing Accounts (Recovering Rent)\n\nTo recover rent when an account is no longer needed:\n\n```rust\npub fn close_account(\n    account_to_close: &AccountInfo,\n    destination: &AccountInfo,\n) -> ProgramResult {\n    // Transfer all lamports to destination\n    let dest_lamports = destination.lamports();\n    **destination.lamports.borrow_mut() = dest_lamports\n        .checked_add(**account_to_close.lamports.borrow())\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    // Zero out lamports in closed account\n    **account_to_close.lamports.borrow_mut() = 0;\n\n    // Zero out data (security best practice)\n    let mut data = account_to_close.data.borrow_mut();\n    data.fill(0);\n\n    Ok(())\n}\n```\n\n**Important:** The runtime will garbage-collect accounts with 0 lamports.\n\n---\n\n## Account Validation Patterns\n\nProper account validation is **critical for security**. Programs must verify accounts before using them.\n\n### 1. Ownership Check\n\n**Purpose:** Ensure an account is owned by the expected program.\n\n**When to use:**\n- Before reading/writing account data\n- When validating PDAs\n- When ensuring proper account initialization\n\n```rust\n// Basic ownership check\nif account.owner != program_id {\n    msg!(\"Account not owned by this program\");\n    return Err(ProgramError::IllegalOwner);\n}\n\n// PDA ownership check (essential for security)\nif note_pda.owner != program_id {\n    msg!(\"Invalid note account - wrong owner\");\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\n**Why it matters:**\nWithout ownership checks, malicious actors can pass arbitrary accounts that match the expected data format but are controlled by other programs or themselves.\n\n### 2. Signer Check\n\n**Purpose:** Verify that an account signed the transaction.\n\n**When to use:**\n- Before transferring funds from an account\n- Before modifying user-specific data\n- Before any privileged operation\n\n```rust\nif !initializer.is_signer {\n    msg!(\"Missing required signature\");\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\n// Practical example: Only allow note author to update\npub fn update_note(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    new_content: String,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let author = next_account_info(account_info_iter)?;\n    let note_pda = next_account_info(account_info_iter)?;\n\n    // Verify author signed the transaction\n    if !author.is_signer {\n        msg!(\"Author must sign to update note\");\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Deserialize and verify author matches\n    let note_data = NoteAccount::try_from_slice(&note_pda.data.borrow())?;\n    if note_data.author != *author.key {\n        msg!(\"Author mismatch\");\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // Safe to proceed with update\n    // ...\n}\n```\n\n### 3. Writable Check\n\n**Purpose:** Verify an account is marked as writable.\n\n**When to use:**\n- Before modifying account data\n- Before changing lamport balances\n- Enforced automatically by runtime, but explicit checks improve clarity\n\n```rust\nif !account.is_writable {\n    msg!(\"Account must be writable\");\n    return Err(ProgramError::InvalidAccountData);\n}\n```\n\n### 4. Initialization Check\n\n**Purpose:** Prevent re-initialization or use of uninitialized accounts.\n\n**Pattern: Flag-based initialization**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct DataAccount {\n    pub is_initialized: bool,\n    // ... other fields\n}\n\nimpl DataAccount {\n    pub fn is_initialized(&self) -> bool {\n        self.is_initialized\n    }\n}\n\n// On creation - check NOT initialized\nif account_data.is_initialized() {\n    msg!(\"Account already initialized\");\n    return Err(ProgramError::AccountAlreadyInitialized);\n}\n\n// On update - check IS initialized\nif !account_data.is_initialized() {\n    msg!(\"Account not initialized\");\n    return Err(ProgramError::UninitializedAccount);\n}\n```\n\n### 5. PDA Validation\n\n**Purpose:** Verify a provided PDA matches expected derivation.\n\n**Critical for security:** Always validate PDAs using canonical bump.\n\n```rust\npub fn validate_pda(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    note_id: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let author = next_account_info(account_info_iter)?;\n    let note_pda = next_account_info(account_info_iter)?;\n\n    // Derive expected PDA\n    let (expected_pda, _bump) = Pubkey::find_program_address(\n        &[\n            author.key.as_ref(),\n            note_id.to_le_bytes().as_ref(),\n        ],\n        program_id,\n    );\n\n    // Validate match\n    if expected_pda != *note_pda.key {\n        msg!(\"Invalid PDA - seeds don't match\");\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    Ok(())\n}\n```\n\n**Why use `find_program_address` instead of accepting a bump?**\n- Prevents bump seed manipulation attacks\n- Ensures canonical bump is used\n- Eliminates category of security vulnerabilities\n\n### 6. Account Type Validation\n\n**Purpose:** Ensure account contains expected data type.\n\n**Pattern: Discriminator/Type Field**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub enum AccountType {\n    Uninitialized,\n    UserProfile,\n    GameState,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AccountData {\n    pub account_type: AccountType,\n    // ... other fields\n}\n\n// Validation\nlet account_data = AccountData::try_from_slice(&account.data.borrow())?;\nif !matches!(account_data.account_type, AccountType::UserProfile) {\n    msg!(\"Wrong account type\");\n    return Err(ProgramError::InvalidAccountData);\n}\n```\n\n---\n\n## Security Best Practices\n\n### 1. Always Validate Before Trusting\n\n**Never assume accounts are correct.** Always validate:\n\n```rust\npub fn secure_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let user = next_account_info(account_info_iter)?;\n    let user_data_pda = next_account_info(account_info_iter)?;\n\n    // ✅ Signer check\n    if !user.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // ✅ Ownership check\n    if user_data_pda.owner != program_id {\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // ✅ PDA validation\n    let (expected_pda, _) = Pubkey::find_program_address(\n        &[b\"user_data\", user.key.as_ref()],\n        program_id,\n    );\n    if expected_pda != *user_data_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // ✅ Initialization check\n    let data = UserData::try_from_slice(&user_data_pda.data.borrow())?;\n    if !data.is_initialized {\n        return Err(ProgramError::UninitializedAccount);\n    }\n\n    // Now safe to proceed\n    // ...\n}\n```\n\n### 2. Fail Fast with Meaningful Errors\n\nReturn errors immediately when validation fails:\n\n```rust\n// ✅ Good - fail fast\nif !account.is_signer {\n    msg!(\"User must sign the transaction\");\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\n// ❌ Bad - continues with invalid state\nif account.is_signer {\n    // process...\n}\n```\n\n### 3. Use Type Safety\n\nLeverage Rust's type system for compile-time guarantees:\n\n```rust\n// Define a validated account type\npub struct ValidatedUserAccount<'a> {\n    info: &'a AccountInfo<'a>,\n    data: UserAccountData,\n}\n\nimpl<'a> ValidatedUserAccount<'a> {\n    pub fn validate(\n        account: &'a AccountInfo<'a>,\n        program_id: &Pubkey,\n    ) -> Result<Self, ProgramError> {\n        // Ownership check\n        if account.owner != program_id {\n            return Err(ProgramError::IllegalOwner);\n        }\n\n        // Deserialize and validate\n        let data = UserAccountData::try_from_slice(&account.data.borrow())?;\n        if !data.is_initialized {\n            return Err(ProgramError::UninitializedAccount);\n        }\n\n        Ok(Self { info: account, data })\n    }\n}\n\n// Usage guarantees validated account\npub fn process_with_validated_account(\n    validated: ValidatedUserAccount,\n) -> ProgramResult {\n    // No need to re-validate!\n    // ...\n}\n```\n\n### 4. Check Arithmetic Operations\n\nAlways use checked math to prevent overflow/underflow:\n\n```rust\n// ❌ Dangerous - can overflow\nlet total = amount1 + amount2;\n\n// ✅ Safe - returns error on overflow\nlet total = amount1\n    .checked_add(amount2)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n### 5. Validate Data Constraints\n\nCheck business logic constraints:\n\n```rust\npub fn allocate_points(\n    character_account: &AccountInfo,\n    new_strength: u8,\n) -> ProgramResult {\n    let mut character = Character::try_from_slice(&character_account.data.borrow())?;\n\n    // Validate attribute cap\n    if character.strength.checked_add(new_strength).ok_or(ProgramError::ArithmeticOverflow)? > 100 {\n        msg!(\"Attribute cannot exceed 100\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // Validate allowance\n    if new_strength > character.available_points {\n        msg!(\"Insufficient available points\");\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    character.strength += new_strength;\n    character.available_points -= new_strength;\n    character.serialize(&mut &mut character_account.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n---\n\n## Common Vulnerabilities\n\n### 1. Missing Ownership Check\n\n**Vulnerability:**\n```rust\n// ❌ No ownership validation\npub fn update_data(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    new_value: u64,\n) -> ProgramResult {\n    let data_account = &accounts[0];\n\n    // Dangerous - could be any account!\n    let mut data = MyData::try_from_slice(&data_account.data.borrow())?;\n    data.value = new_value;\n    data.serialize(&mut &mut data_account.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**Exploit:**\nAttacker passes an account they control that happens to deserialize correctly, modifying arbitrary data.\n\n**Fix:**\n```rust\n// ✅ With ownership check\nif data_account.owner != program_id {\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\n### 2. Missing Signer Check\n\n**Vulnerability:**\n```rust\n// ❌ No signer validation\npub fn withdraw(\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let user_account = &accounts[0];\n    let vault = &accounts[1];\n\n    // Dangerous - anyone can drain anyone's funds!\n    **user_account.lamports.borrow_mut() += amount;\n    **vault.lamports.borrow_mut() -= amount;\n\n    Ok(())\n}\n```\n\n**Exploit:**\nAttacker calls instruction with victim's account, draining their funds without signature.\n\n**Fix:**\n```rust\n// ✅ With signer check\nif !user_account.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n```\n\n### 3. PDA Substitution Attack\n\n**Vulnerability:**\n```rust\n// ❌ Accepts PDA without validation\npub fn update_user_data(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    user: &AccountInfo,\n    user_pda: &AccountInfo,\n) -> ProgramResult {\n    // No PDA derivation check!\n    let mut data = UserData::try_from_slice(&user_pda.data.borrow())?;\n    data.balance += 100;\n    data.serialize(&mut &mut user_pda.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n**Exploit:**\nAttacker passes a different user's PDA, crediting that user's balance instead.\n\n**Fix:**\n```rust\n// ✅ Validate PDA derivation\nlet (expected_pda, _) = Pubkey::find_program_address(\n    &[b\"user_data\", user.key.as_ref()],\n    program_id,\n);\nif expected_pda != *user_pda.key {\n    return Err(ProgramError::InvalidSeeds);\n}\n```\n\n### 4. Integer Overflow/Underflow\n\n**Vulnerability:**\n```rust\n// ❌ Unchecked arithmetic\npub fn add_rewards(\n    account: &AccountInfo,\n    reward: u64,\n) -> ProgramResult {\n    let mut user = UserData::try_from_slice(&account.data.borrow())?;\n    user.total_rewards = user.total_rewards + reward;  // Can overflow!\n    user.serialize(&mut &mut account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n**Exploit:**\nOverflow wraps around: u64::MAX + 1 = 0, causing balance to reset.\n\n**Fix:**\n```rust\n// ✅ Checked arithmetic\nuser.total_rewards = user.total_rewards\n    .checked_add(reward)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n### 5. Unvalidated Account Reuse\n\n**Vulnerability:**\n```rust\n// ❌ No initialization check\npub fn update_score(\n    accounts: &[AccountInfo],\n    score: u64,\n) -> ProgramResult {\n    let score_account = &accounts[0];\n    let mut data = ScoreData::try_from_slice(&score_account.data.borrow())?;\n\n    // What if account was never initialized?\n    data.score = score;\n    data.serialize(&mut &mut score_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n**Exploit:**\nReusing uninitialized memory can lead to undefined behavior or data corruption.\n\n**Fix:**\n```rust\n// ✅ Check initialization\nif !data.is_initialized {\n    return Err(ProgramError::UninitializedAccount);\n}\n```\n\n---\n\n## Summary\n\n**Critical Account Validation Checklist:**\n\n- ✅ **Ownership check**: Verify `account.owner == expected_program_id`\n- ✅ **Signer check**: Verify `account.is_signer` for privileged operations\n- ✅ **PDA validation**: Use `find_program_address` with expected seeds\n- ✅ **Initialization check**: Verify account is initialized before use\n- ✅ **Type validation**: Ensure account contains expected data structure\n- ✅ **Rent exemption**: Calculate and enforce rent-exempt balances\n- ✅ **Arithmetic safety**: Use `checked_add`, `checked_sub`, etc.\n- ✅ **Data constraints**: Validate business logic rules\n\n**Think Like an Attacker:**\nFor every account your program receives, ask:\n- \"What if this is the wrong account?\"\n- \"What if this account isn't owned by my program?\"\n- \"What if the user didn't sign for this?\"\n- \"What if this account is uninitialized?\"\n- \"What if these seeds derive a different PDA?\"\n\nValidate everything. Trust nothing.\n",
        "solana/skills/solana-development/references/anchor.md": "# Anchor Framework Reference\n\nThis reference covers Anchor-specific features and patterns. For general Solana concepts (accounts, PDAs, CPIs, etc.), see the other reference files in this directory.\n\n## Table of Contents\n\n- [Installation and Setup](#installation-and-setup)\n- [Anchor Macros](#anchor-macros)\n- [Program Structure](#program-structure)\n- [Account Validation Constraints](#account-validation-constraints)\n- [IDL (Interface Description Language)](#idl-interface-description-language)\n- [TypeScript Client](#typescript-client)\n- [Rust Client](#rust-client)\n- [Anchor CLI Commands](#anchor-cli-commands)\n- [Token Integration (anchor-spl)](#token-integration-anchor-spl)\n- [Testing with Anchor](#testing-with-anchor)\n- [Anchor Features](#anchor-features)\n- [Common Patterns](#common-patterns)\n- [Error Handling](#error-handling)\n\n---\n\n## Installation and Setup\n\n### Quick Install (Mac/Linux)\n\n```bash\n# Install all dependencies (Rust, Solana CLI, Anchor)\ncurl --proto '=https' --tlsv1.2 -sSfL https://solana-install.solana.workers.dev | bash\n```\n\n### Install Anchor with AVM\n\nAnchor Version Manager (avm) manages multiple Anchor CLI versions:\n\n```bash\n# Install AVM\ncargo install --git https://github.com/coral-xyz/anchor avm --force\n\n# Install latest Anchor\navm install latest\navm use latest\n\n# Install specific version\navm install 0.32.1\navm use 0.32.1\n\n# Install from commit hash\navm install 0.30.1-cfe82aa682138f7c6c58bf7a78f48f7d63e9e466\navm use 0.30.1-cfe82aa\n```\n\n### Verify Installation\n\n```bash\nanchor --version  # Should output: anchor-cli 0.32.1\nsolana --version  # Recommended: solana-cli 2.3.0+\nrustc --version   # Required: 1.89.0+ for IDL builds\n```\n\n### Solana Playground (No Install)\n\nDevelop in browser at https://beta.solpg.io/\n\n---\n\n## Anchor Macros\n\n### Core Macros Overview\n\n1. **`declare_id!`** - Declares the program's on-chain address\n2. **`#[program]`** - Defines the program module containing instructions\n3. **`#[derive(Accounts)]`** - Defines account validation structs\n4. **`#[account]`** - Defines custom account types\n5. **`#[error_code]`** - Defines custom error enums\n6. **`#[event]`** - Defines event structs for logging\n\n### declare_id! Macro\n\n```rust\nuse anchor_lang::prelude::*;\n\n// Program ID from /target/deploy/program_name.json\ndeclare_id!(\"11111111111111111111111111111111\");\n```\n\nSync program IDs after building:\n\n```bash\nanchor keys sync\n```\n\n### #[program] Macro\n\nMarks the module containing instruction handlers:\n\n```rust\n#[program]\npub mod my_program {\n    use super::*;\n\n    pub fn initialize(ctx: Context<Initialize>, data: u64) -> Result<()> {\n        ctx.accounts.new_account.data = data;\n        msg!(\"Data set to: {}!\", data);\n        Ok(())\n    }\n\n    pub fn update(ctx: Context<Update>, new_data: u64) -> Result<()> {\n        ctx.accounts.account.data = new_data;\n        Ok(())\n    }\n}\n```\n\n**Context<T> provides:**\n- `ctx.accounts` - Validated accounts (type T)\n- `ctx.program_id` - Current program's ID\n- `ctx.remaining_accounts` - Additional accounts not in struct\n- `ctx.bumps` - PDA bump seeds (struct with fields matching PDA account names)\n\n### #[derive(Accounts)] Macro\n\nDefines account validation structs:\n\n```rust\n#[derive(Accounts)]\npub struct Initialize<'info> {\n    #[account(init, payer = signer, space = 8 + 8)]\n    pub new_account: Account<'info, NewAccount>,\n\n    #[account(mut)]\n    pub signer: Signer<'info>,\n\n    pub system_program: Program<'info, System>,\n}\n```\n\n**Validation happens in two ways:**\n1. **Account Types** - Signer, Account<'info, T>, Program<'info, T>, etc.\n2. **Account Constraints** - `#[account(...)]` attribute constraints\n\n### #[account] Macro\n\nDefines custom account data structures:\n\n```rust\n#[account]\npub struct NewAccount {\n    pub data: u64,      // 8 bytes\n    pub owner: Pubkey,  // 32 bytes\n    pub bump: u8,       // 1 byte\n}\n```\n\n**Automatically implements:**\n- Account discriminator (first 8 bytes)\n- Serialization/deserialization (Borsh)\n- Owner validation (owned by program)\n\n**Account discriminator** = first 8 bytes of SHA256(`\"account:NewAccount\"`)\n\n### #[error_code] Macro\n\nDefines custom program errors:\n\n```rust\n#[error_code]\npub enum ErrorCode {\n    #[msg(\"Amount must be greater than zero\")]\n    InvalidAmount,\n\n    #[msg(\"Insufficient funds\")]\n    InsufficientFunds,\n}\n```\n\nUsage:\n\n```rust\nrequire!(amount > 0, ErrorCode::InvalidAmount);\n```\n\n### #[event] Macro\n\nDefines event structs for logging:\n\n```rust\n#[event]\npub struct TransferEvent {\n    pub from: Pubkey,\n    pub to: Pubkey,\n    pub amount: u64,\n}\n\n// Emit via program logs\npub fn transfer(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    emit!(TransferEvent {\n        from: ctx.accounts.from.key(),\n        to: ctx.accounts.to.key(),\n        amount,\n    });\n    Ok(())\n}\n```\n\n---\n\n## Program Structure\n\n### Complete Example\n\n```rust\nuse anchor_lang::prelude::*;\n\ndeclare_id!(\"YourProgramIdHere11111111111111111111111\");\n\n#[program]\nmod my_program {\n    use super::*;\n\n    pub fn initialize(ctx: Context<Initialize>, data: u64) -> Result<()> {\n        ctx.accounts.new_account.data = data;\n        ctx.accounts.new_account.authority = ctx.accounts.authority.key();\n        Ok(())\n    }\n\n    pub fn update(ctx: Context<Update>, new_data: u64) -> Result<()> {\n        ctx.accounts.account.data = new_data;\n        Ok(())\n    }\n}\n\n#[derive(Accounts)]\npub struct Initialize<'info> {\n    #[account(init, payer = authority, space = 8 + 8 + 32)]\n    pub new_account: Account<'info, MyAccount>,\n\n    #[account(mut)]\n    pub authority: Signer<'info>,\n\n    pub system_program: Program<'info, System>,\n}\n\n#[derive(Accounts)]\npub struct Update<'info> {\n    #[account(\n        mut,\n        has_one = authority\n    )]\n    pub account: Account<'info, MyAccount>,\n\n    pub authority: Signer<'info>,\n}\n\n#[account]\npub struct MyAccount {\n    pub data: u64,\n    pub authority: Pubkey,\n}\n```\n\n### Space Calculation\n\nUse `InitSpace` derive macro:\n\n```rust\n#[account]\n#[derive(InitSpace)]\npub struct MyAccount {\n    pub data: u64,                    // 8 bytes\n    #[max_len(50)]\n    pub name: String,                 // 4 + 50 bytes\n    pub authority: Pubkey,            // 32 bytes\n}\n\n// INIT_SPACE = 8 + 4 + 50 + 32 = 94 bytes\n\n#[account(init, payer = payer, space = 8 + MyAccount::INIT_SPACE)]\npub account: Account<'info, MyAccount>,\n```\n\n**Space = 8 (discriminator) + account data size**\n\n---\n\n## Account Validation Constraints\n\n### Common Constraints\n\n#### init - Create New Account\n\n```rust\n#[account(\n    init,\n    payer = payer,\n    space = 8 + 8\n)]\npub new_account: Account<'info, Counter>,\n```\n\n#### init_if_needed - Create if Doesn't Exist\n\n```rust\n#[account(\n    init_if_needed,\n    payer = payer,\n    space = 8 + 8\n)]\npub account: Account<'info, Counter>,\n```\n\nRequires `init-if-needed` feature in Cargo.toml:\n\n```toml\n[dependencies]\nanchor-lang = { version = \"0.32.1\", features = [\"init-if-needed\"] }\n```\n\n#### mut - Mutable Account\n\n```rust\n#[account(mut)]\npub account: Account<'info, Counter>,\n```\n\n#### signer - Requires Signature\n\n```rust\n#[account(signer)]\npub authority: AccountInfo<'info>,\n// Or use Signer<'info> type\npub authority: Signer<'info>,\n```\n\n#### close - Close Account\n\n```rust\n#[account(\n    mut,\n    close = receiver  // Send lamports to receiver\n)]\npub account_to_close: Account<'info, MyAccount>,\n\n#[account(mut)]\npub receiver: SystemAccount<'info>,\n```\n\n### PDA Constraints\n\n#### seeds + bump - Validate PDA\n\n```rust\n#[account(\n    seeds = [b\"vault\", authority.key().as_ref()],\n    bump\n)]\npub vault: Account<'info, Vault>,\n```\n\nAccess bump in instruction:\n\n```rust\npub fn initialize(ctx: Context<Initialize>) -> Result<()> {\n    let bump = ctx.bumps.vault;\n    ctx.accounts.vault.bump = bump;\n    Ok(())\n}\n```\n\n#### seeds + bump + init - Create PDA Account\n\n```rust\n#[account(\n    init,\n    payer = payer,\n    space = 8 + 32 + 1,\n    seeds = [b\"vault\", authority.key().as_ref()],\n    bump\n)]\npub vault: Account<'info, Vault>,\n```\n\n### Validation Constraints\n\n#### has_one - Field Matches Account\n\n```rust\n#[account(\n    mut,\n    has_one = authority  // Checks account.authority == authority.key()\n)]\npub account: Account<'info, MyAccount>,\npub authority: Signer<'info>,\n```\n\n#### address - Matches Specific Address\n\n```rust\n#[account(address = admin_pubkey)]\npub admin: Signer<'info>,\n```\n\n#### owner - Validates Owner Program\n\n```rust\n#[account(owner = token::ID)]\npub token_account: AccountInfo<'info>,\n```\n\n#### constraint - Custom Validation\n\n```rust\n#[account(\n    constraint = account.data > 0 @ ErrorCode::InvalidData\n)]\npub account: Account<'info, MyAccount>,\n```\n\n### Token Constraints\n\n#### mint - Create/Validate Mint\n\n```rust\nuse anchor_spl::token_interface::{Mint, TokenInterface};\n\n#[account(\n    init,\n    payer = payer,\n    mint::decimals = 6,\n    mint::authority = mint_authority,\n    mint::freeze_authority = mint_authority,\n)]\npub mint: InterfaceAccount<'info, Mint>,\npub token_program: Interface<'info, TokenInterface>,\n```\n\n#### token - Create/Validate Token Account\n\n```rust\nuse anchor_spl::token_interface::{TokenAccount, TokenInterface};\n\n#[account(\n    init,\n    payer = payer,\n    token::mint = mint,\n    token::authority = owner,\n    token::token_program = token_program,\n    seeds = [b\"vault\"],\n    bump\n)]\npub vault: InterfaceAccount<'info, TokenAccount>,\n```\n\n#### associated_token - Create/Validate ATA\n\n```rust\nuse anchor_spl::{\n    associated_token::AssociatedToken,\n    token_interface::{Mint, TokenAccount, TokenInterface},\n};\n\n#[account(\n    init,\n    payer = payer,\n    associated_token::mint = mint,\n    associated_token::authority = owner,\n    associated_token::token_program = token_program,\n)]\npub token_account: InterfaceAccount<'info, TokenAccount>,\n\npub mint: InterfaceAccount<'info, Mint>,\npub owner: SystemAccount<'info>,\npub token_program: Interface<'info, TokenInterface>,\npub associated_token_program: Program<'info, AssociatedToken>,\npub system_program: Program<'info, System>,\n```\n\n---\n\n## IDL (Interface Description Language)\n\n### What is the IDL?\n\nThe IDL is a JSON file describing your program's interface:\n- Instructions (name, accounts, arguments)\n- Account types (structs)\n- Custom types (enums, type aliases)\n- Events\n- Errors\n- Discriminators\n\n### IDL Generation\n\nEnable IDL build feature in `Cargo.toml`:\n\n```toml\n[features]\nidl-build = [\"anchor-lang/idl-build\"]\n```\n\nBuild program and generate IDL:\n\n```bash\nanchor build        # Builds program + IDL\nanchor idl build    # Only builds IDL\n```\n\nIDL output location: `target/idl/<program_name>.json`\n\n### IDL Structure Example\n\n```json\n{\n  \"address\": \"8HupNBr7SBhBLcBsLhbtes3tCarBm6Bvpqp5AfVjHuj8\",\n  \"metadata\": {\n    \"name\": \"example\",\n    \"version\": \"0.1.0\",\n    \"spec\": \"0.1.0\"\n  },\n  \"instructions\": [\n    {\n      \"name\": \"initialize\",\n      \"discriminator\": [175, 175, 109, 31, 13, 152, 155, 237],\n      \"accounts\": [\n        {\n          \"name\": \"new_account\",\n          \"writable\": true,\n          \"signer\": true\n        },\n        {\n          \"name\": \"signer\",\n          \"writable\": true,\n          \"signer\": true\n        },\n        {\n          \"name\": \"system_program\",\n          \"address\": \"11111111111111111111111111111111\"\n        }\n      ],\n      \"args\": [\n        {\n          \"name\": \"data\",\n          \"type\": \"u64\"\n        }\n      ]\n    }\n  ],\n  \"accounts\": [\n    {\n      \"name\": \"NewAccount\",\n      \"discriminator\": [123, 45, 67, 89, 101, 112, 131, 145]\n    }\n  ],\n  \"types\": [\n    {\n      \"name\": \"NewAccount\",\n      \"type\": {\n        \"kind\": \"struct\",\n        \"fields\": [\n          {\n            \"name\": \"data\",\n            \"type\": \"u64\"\n          }\n        ]\n      }\n    }\n  ]\n}\n```\n\n### Instruction Discriminator\n\n8-byte identifier for each instruction:\n\n```\ndiscriminator = SHA256(\"global:initialize\")[0..8]\n```\n\nAutomatically handled by Anchor client.\n\n### Account Discriminator\n\n8-byte identifier for each account type:\n\n```\ndiscriminator = SHA256(\"account:NewAccount\")[0..8]\n```\n\nUsed for:\n- Account type verification on deserialization\n- Type safety checks\n\n### IDL Deployment\n\nDeploy IDL on-chain:\n\n```bash\nanchor deploy              # Deploys program + IDL\nanchor deploy --no-idl     # Deploy program only\nanchor idl init <PROGRAM_ID> -f target/idl/program.json\n```\n\nFetch IDL from chain:\n\n```bash\nanchor idl fetch <PROGRAM_ID>\n```\n\n---\n\n## TypeScript Client\n\n### Installation\n\n```bash\nnpm install @coral-xyz/anchor @solana/web3.js\n# or\nyarn add @coral-xyz/anchor @solana/web3.js\n```\n\n**Note:** Only compatible with `@solana/web3.js` v1, not v2.\n\n### Setup Program Instance\n\n#### With Wallet (Frontend)\n\n```typescript\nimport { Program, AnchorProvider, setProvider } from \"@coral-xyz/anchor\";\nimport { useAnchorWallet, useConnection } from \"@solana/wallet-adapter-react\";\nimport type { MyProgram } from \"./types/my_program\";\nimport idl from \"./idl/my_program.json\";\n\nconst { connection } = useConnection();\nconst wallet = useAnchorWallet();\n\nconst provider = new AnchorProvider(connection, wallet, {});\nsetProvider(provider);\n\nconst program = new Program(idl as MyProgram, { connection });\n```\n\n#### Without Wallet (Read-Only)\n\n```typescript\nimport { Connection, PublicKey } from \"@solana/web3.js\";\nimport { Program } from \"@coral-xyz/anchor\";\nimport idl from \"./idl/my_program.json\";\n\nconst connection = new Connection(\"https://api.devnet.solana.com\");\nconst program = new Program(idl, { connection });\n```\n\n### Invoke Instructions\n\n#### Using .rpc() - Send Transaction\n\n```typescript\nimport { Keypair, SystemProgram } from \"@solana/web3.js\";\nimport BN from \"bn.js\";\n\nconst newAccountKp = new Keypair();\nconst data = new BN(42);\n\nconst txSignature = await program.methods\n  .initialize(data)\n  .accounts({\n    newAccount: newAccountKp.publicKey,\n    signer: wallet.publicKey,\n    systemProgram: SystemProgram.programId,\n  })\n  .signers([newAccountKp])\n  .rpc();\n\nconsole.log(\"Transaction:\", txSignature);\n```\n\n#### Using .instruction() - Build Instruction\n\n```typescript\nconst ix = await program.methods\n  .initialize(data)\n  .accounts({\n    newAccount: newAccountKp.publicKey,\n    signer: wallet.publicKey,\n    systemProgram: SystemProgram.programId,\n  })\n  .instruction();\n\n// Add to transaction\nconst tx = new Transaction().add(ix);\n```\n\n#### Using .transaction() - Build Transaction\n\n```typescript\nconst tx = await program.methods\n  .initialize(data)\n  .accounts({ /* ... */ })\n  .transaction();\n\n// Sign and send\ntx.recentBlockhash = (await connection.getLatestBlockhash()).blockhash;\ntx.sign(wallet, newAccountKp);\nconst signature = await connection.sendRawTransaction(tx.serialize());\n```\n\n### Fetch Accounts\n\n#### Fetch Single Account\n\n```typescript\nconst accountData = await program.account.myAccount.fetch(accountPubkey);\nconsole.log(\"Data:\", accountData.data.toString());\n```\n\n#### Fetch All Accounts\n\n```typescript\nconst accounts = await program.account.myAccount.all();\naccounts.forEach((account) => {\n  console.log(\"Pubkey:\", account.publicKey.toString());\n  console.log(\"Data:\", account.account.data);\n});\n```\n\n#### Fetch with Filters\n\n```typescript\nconst accounts = await program.account.myAccount.all([\n  {\n    memcmp: {\n      offset: 8,  // After discriminator\n      bytes: authority.toBase58(),\n    },\n  },\n]);\n```\n\n### Event Listeners\n\n```typescript\nconst listenerId = program.addEventListener(\n  \"TransferEvent\",\n  (event, slot) => {\n    console.log(\"From:\", event.from.toString());\n    console.log(\"To:\", event.to.toString());\n    console.log(\"Amount:\", event.amount.toString());\n  }\n);\n\n// Remove listener\nprogram.removeEventListener(listenerId);\n```\n\n---\n\n## Rust Client\n\n### Dependencies\n\nAdd to `Cargo.toml`:\n\n```toml\n[dependencies]\nanchor-client = { version = \"0.32.1\", features = [\"async\"] }\nanchor-lang = \"0.32.1\"\nsolana-sdk = \"2.3.0\"\ntokio = { version = \"1.0\", features = [\"full\"] }\n```\n\n### Generate Client with declare_program!\n\nPlace IDL in `/idls/program_name.json`:\n\n```rust\nuse anchor_lang::prelude::*;\n\ndeclare_program!(example);\nuse example::{\n    accounts::Counter,\n    client::{accounts, args},\n};\n```\n\n### Example Client\n\n```rust\nuse anchor_client::{\n    solana_client::rpc_client::RpcClient,\n    solana_sdk::{\n        commitment_config::CommitmentConfig,\n        signature::Keypair,\n        signer::Signer,\n        system_program,\n    },\n    Client, Cluster,\n};\nuse std::rc::Rc;\n\n#[tokio::main]\nasync fn main() -> anyhow::Result<()> {\n    let connection = RpcClient::new_with_commitment(\n        \"http://127.0.0.1:8899\",\n        CommitmentConfig::confirmed(),\n    );\n\n    let payer = Keypair::new();\n    let counter = Keypair::new();\n\n    // Create program client\n    let provider = Client::new_with_options(\n        Cluster::Localnet,\n        Rc::new(payer),\n        CommitmentConfig::confirmed(),\n    );\n    let program = provider.program(example::ID)?;\n\n    // Build instruction\n    let ix = program\n        .request()\n        .accounts(accounts::Initialize {\n            counter: counter.pubkey(),\n            payer: program.payer(),\n            system_program: system_program::ID,\n        })\n        .args(args::Initialize)\n        .instructions()?\n        .remove(0);\n\n    // Send transaction\n    let signature = program\n        .request()\n        .instruction(ix)\n        .signer(&counter)\n        .send()\n        .await?;\n\n    println!(\"Transaction: {}\", signature);\n\n    // Fetch account\n    let account: Counter = program.account::<Counter>(counter.pubkey()).await?;\n    println!(\"Count: {}\", account.count);\n\n    Ok(())\n}\n```\n\n---\n\n## Anchor CLI Commands\n\n### Project Commands\n\n```bash\n# Initialize new project\nanchor init my-project\nanchor init my-project --test-template rust  # Rust tests\nanchor init my-project --test-template mollusk  # Mollusk tests\n\n# Create new program in workspace\nanchor new my-program\n```\n\n### Build Commands\n\n```bash\n# Build all programs\nanchor build\n\n# Build specific program\nanchor build --program-name my-program\n\n# Build without IDL generation\nanchor build --no-idl\n\n# Verifiable build (uses solana-verify)\nanchor build --verifiable\n```\n\n### Deploy Commands\n\n```bash\n# Deploy to cluster in Anchor.toml\nanchor deploy\n\n# Deploy specific program\nanchor deploy --program-name my-program\n\n# Deploy without IDL\nanchor deploy --no-idl\n\n# Deploy with additional program args\nanchor deploy -- --max-len 200000\n```\n\n### Test Commands\n\n```bash\n# Build + deploy + test\nanchor test\n\n# Skip local validator (use running validator)\nanchor test --skip-local-validator\n\n# Test specific program\nanchor test --program-name my-program\n\n# Skip IDL build\nanchor test --no-idl\n```\n\n### IDL Commands\n\n```bash\n# Build IDL only\nanchor idl build\n\n# Initialize IDL on-chain\nanchor idl init <PROGRAM_ID> -f target/idl/program.json\n\n# Fetch IDL from chain\nanchor idl fetch <PROGRAM_ID>\n\n# Upgrade on-chain IDL\nanchor idl upgrade <PROGRAM_ID> -f target/idl/program.json\n\n# Get IDL authority\nanchor idl authority <PROGRAM_ID>\n\n# Set new IDL authority\nanchor idl set-authority <PROGRAM_ID> --new-authority <NEW_AUTHORITY>\n```\n\n### Other Commands\n\n```bash\n# Sync program IDs\nanchor keys sync\n\n# List program keypairs\nanchor keys list\n\n# Expand macros\nanchor expand\nanchor expand --program-name my-program\n\n# Verify deployed program\nanchor verify -p <program-name> <PROGRAM_ID>\n\n# Run migration script\nanchor migrate\n\n# Close deployed program (reclaim rent)\nsolana program close <PROGRAM_ID>\n```\n\n### Local Validator\n\n```bash\n# Start local validator\nsolana-test-validator\n\n# Start with program loaded\nsolana-test-validator --bpf-program <PROGRAM_ID> target/deploy/program.so\n\n# Configure in Anchor.toml\n[test.validator]\nurl = \"https://api.devnet.solana.com\"\n\n[[test.validator.clone]]\naddress = \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"  # Clone USDC mint\n```\n\n---\n\n## Token Integration (anchor-spl)\n\n### Dependencies\n\n```toml\n[dependencies]\nanchor-spl = { version = \"0.32.1\", features = [\"metadata\"] }\n```\n\n### Token Interface (Token + Token-2022)\n\nUse `token_interface` for compatibility with both Token Program and Token Extensions:\n\n```rust\nuse anchor_spl::token_interface::{\n    self, Mint, MintTo, TokenAccount, TokenInterface, TransferChecked\n};\n```\n\n### Create Mint\n\n```rust\n#[derive(Accounts)]\npub struct CreateMint<'info> {\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    #[account(\n        init,\n        payer = payer,\n        mint::decimals = 6,\n        mint::authority = mint_authority,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Mint authority\n    pub mint_authority: UncheckedAccount<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n### Create Token Account (ATA)\n\n```rust\nuse anchor_spl::associated_token::AssociatedToken;\n\n#[derive(Accounts)]\npub struct CreateTokenAccount<'info> {\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    #[account(\n        init,\n        payer = payer,\n        associated_token::mint = mint,\n        associated_token::authority = owner,\n        associated_token::token_program = token_program,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n    pub owner: SystemAccount<'info>,\n    pub token_program: Interface<'info, TokenInterface>,\n    pub associated_token_program: Program<'info, AssociatedToken>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n### Mint Tokens\n\n```rust\npub fn mint_tokens(ctx: Context<MintTokens>, amount: u64) -> Result<()> {\n    let cpi_accounts = MintTo {\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_program = ctx.accounts.token_program.to_account_info();\n    let cpi_context = CpiContext::new(cpi_program, cpi_accounts);\n\n    token_interface::mint_to(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n### Transfer Tokens\n\n```rust\npub fn transfer_tokens(ctx: Context<TransferTokens>, amount: u64) -> Result<()> {\n    let decimals = ctx.accounts.mint.decimals;\n\n    let cpi_accounts = TransferChecked {\n        from: ctx.accounts.from.to_account_info(),\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.to.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_program = ctx.accounts.token_program.to_account_info();\n    let cpi_context = CpiContext::new(cpi_program, cpi_accounts);\n\n    token_interface::transfer_checked(cpi_context, amount, decimals)?;\n    Ok(())\n}\n```\n\n### PDA as Token Authority\n\n```rust\n#[derive(Accounts)]\npub struct MintWithPDA<'info> {\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    #[account(\n        init,\n        payer = payer,\n        mint::decimals = 6,\n        mint::authority = mint,  // PDA is authority\n        seeds = [b\"mint\"],\n        bump\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn mint_with_pda(ctx: Context<MintWithPDA>, amount: u64) -> Result<()> {\n    let seeds = &[b\"mint\".as_ref(), &[ctx.bumps.mint]];\n    let signer_seeds = &[&seeds[..]];\n\n    let cpi_accounts = MintTo {\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.mint.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    ).with_signer(signer_seeds);\n\n    token_interface::mint_to(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n---\n\n## Testing with Anchor\n\n### TypeScript Tests (Default)\n\nTest file location: `tests/my-program.ts`\n\n```typescript\nimport * as anchor from \"@coral-xyz/anchor\";\nimport { Program } from \"@coral-xyz/anchor\";\nimport { MyProgram } from \"../target/types/my_program\";\nimport { expect } from \"chai\";\n\ndescribe(\"my-program\", () => {\n  const provider = anchor.AnchorProvider.env();\n  anchor.setProvider(provider);\n\n  const program = anchor.workspace.MyProgram as Program<MyProgram>;\n\n  it(\"Initializes account\", async () => {\n    const newAccount = anchor.web3.Keypair.generate();\n\n    await program.methods\n      .initialize(new anchor.BN(42))\n      .accounts({\n        newAccount: newAccount.publicKey,\n        signer: provider.wallet.publicKey,\n        systemProgram: anchor.web3.SystemProgram.programId,\n      })\n      .signers([newAccount])\n      .rpc();\n\n    const account = await program.account.myAccount.fetch(\n      newAccount.publicKey\n    );\n    expect(account.data.toNumber()).to.equal(42);\n  });\n});\n```\n\n### Rust Tests with LiteSVM\n\nInitialize project with Rust tests:\n\n```bash\nanchor init my-project --test-template rust\n```\n\nTest file: `tests/src/test_initialize.rs`\n\n```rust\nuse anchor_client::anchor_lang::prelude::*;\nuse anchor_client::anchor_lang::solana_program::system_program;\nuse anchor_lang_lite_svm::LiteSVM;\n\n#[test]\nfn test_initialize() {\n    let mut svm = LiteSVM::new();\n\n    let program_id = svm.deploy_program(\"target/deploy/my_program.so\");\n    let payer = Keypair::new();\n    let counter = Keypair::new();\n\n    svm.airdrop(&payer.pubkey(), 10_000_000_000).unwrap();\n\n    let ix = my_program::instruction::Initialize {\n        new_account: counter.pubkey(),\n        signer: payer.pubkey(),\n        system_program: system_program::ID,\n    };\n\n    let tx = svm.send_transaction(vec![ix], &[&payer, &counter]).unwrap();\n\n    // Fetch and verify account\n    let account_data = svm.get_account(&counter.pubkey()).unwrap();\n    // Verify data...\n}\n```\n\n### Test Configuration (Anchor.toml)\n\n```toml\n[test]\n# Startup timeout for validator\nstartup_wait = 10000\n\n[test.validator]\n# URL to clone accounts from\nurl = \"https://api.mainnet-beta.solana.com\"\n\n# Clone accounts\n[[test.validator.clone]]\naddress = \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"\n\n# Load account from JSON\n[[test.validator.account]]\naddress = \"MyAccount111111111111111111111111111111111\"\nfilename = \"tests/fixtures/my-account.json\"\n\n# Set program as upgradeable\n[test.validator.upgradeable]\nmy_program = true\n```\n\n---\n\n## Anchor Features\n\n### Custom Errors\n\n```rust\n#[error_code]\npub enum ErrorCode {\n    #[msg(\"Amount must be greater than zero\")]\n    InvalidAmount,\n\n    #[msg(\"Authority mismatch\")]\n    Unauthorized,\n}\n\n// Usage\nrequire!(amount > 0, ErrorCode::InvalidAmount);\nrequire_keys_eq!(account.owner, authority.key(), ErrorCode::Unauthorized);\n```\n\n**Error macros:**\n- `require!(condition, error)` - Condition must be true\n- `require_eq!(a, b, error)` - Values must be equal\n- `require_neq!(a, b, error)` - Values must not be equal\n- `require_keys_eq!(a, b, error)` - Pubkeys must match\n- `require_keys_neq!(a, b, error)` - Pubkeys must not match\n- `require_gt!(a, b, error)` - a > b\n- `require_gte!(a, b, error)` - a >= b\n\n### Events\n\n#### emit! (Program Logs)\n\n```rust\n#[event]\npub struct TransferEvent {\n    pub from: Pubkey,\n    pub to: Pubkey,\n    pub amount: u64,\n}\n\npub fn transfer(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    emit!(TransferEvent {\n        from: ctx.accounts.from.key(),\n        to: ctx.accounts.to.key(),\n        amount,\n    });\n    Ok(())\n}\n```\n\n#### emit_cpi! (CPI Data)\n\nEnable feature:\n\n```toml\n[dependencies]\nanchor-lang = { version = \"0.32.1\", features = [\"event-cpi\"] }\n```\n\nUsage:\n\n```rust\n#[event_cpi]\n#[derive(Accounts)]\npub struct EmitEvent {}\n\npub fn emit_event(ctx: Context<EmitEvent>, msg: String) -> Result<()> {\n    emit_cpi!(CustomEvent { message: msg });\n    Ok(())\n}\n```\n\n### Zero-Copy Accounts\n\nFor large accounts (>10KB):\n\n```toml\n[dependencies]\nbytemuck = { version = \"1.20.0\", features = [\"min_const_generics\"] }\n```\n\n```rust\n#[account(zero_copy)]\npub struct LargeData {\n    pub data: [u8; 10000],\n}\n\n#[derive(Accounts)]\npub struct Initialize<'info> {\n    #[account(\n        init,\n        payer = payer,\n        space = 8 + std::mem::size_of::<LargeData>()\n    )]\n    pub large_account: AccountLoader<'info, LargeData>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn initialize(ctx: Context<Initialize>) -> Result<()> {\n    let mut large_account = ctx.accounts.large_account.load_init()?;\n    large_account.data[0] = 42;\n    Ok(())\n}\n\npub fn update(ctx: Context<Update>) -> Result<()> {\n    let mut large_account = ctx.accounts.large_account.load_mut()?;\n    large_account.data[0] = 100;\n    Ok(())\n}\n```\n\n**For >10240 bytes**, use `zero` constraint + create account separately:\n\n```rust\n#[account(zero)]  // Instead of init\npub large_account: AccountLoader<'info, LargeData>,\n```\n\n### declare_program! (Dependency-Free CPI)\n\nPlace IDL in `/idls/program_name.json`:\n\n```rust\ndeclare_program!(example);\n\nuse example::{\n    accounts::Counter,\n    cpi::{self, accounts::Initialize},\n    program::Example,\n};\n\n// CPI to other program\npub fn call_example(ctx: Context<CallExample>) -> Result<()> {\n    let cpi_ctx = CpiContext::new(\n        ctx.accounts.example_program.to_account_info(),\n        Initialize {\n            counter: ctx.accounts.counter.to_account_info(),\n            payer: ctx.accounts.payer.to_account_info(),\n            system_program: ctx.accounts.system_program.to_account_info(),\n        },\n    );\n\n    cpi::initialize(cpi_ctx)?;\n    Ok(())\n}\n```\n\n---\n\n## Common Patterns\n\n### Store Bump Seed\n\n```rust\n#[account]\npub struct Vault {\n    pub authority: Pubkey,\n    pub bump: u8,\n}\n\npub fn initialize(ctx: Context<Initialize>) -> Result<()> {\n    ctx.accounts.vault.authority = ctx.accounts.authority.key();\n    ctx.accounts.vault.bump = ctx.bumps.vault;\n    Ok(())\n}\n\n// Use stored bump\nlet seeds = &[\n    b\"vault\",\n    ctx.accounts.vault.authority.as_ref(),\n    &[ctx.accounts.vault.bump]\n];\n```\n\n### Multi-Seed PDAs\n\n```rust\n#[account(\n    init,\n    payer = payer,\n    space = 8 + UserAccount::INIT_SPACE,\n    seeds = [\n        b\"user\",\n        user.key().as_ref(),\n        &counter.to_le_bytes()\n    ],\n    bump\n)]\npub user_account: Account<'info, UserAccount>,\n```\n\n### CPI with PDA Signer\n\n```rust\npub fn transfer_with_pda(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    let seeds = &[\n        b\"vault\",\n        &[ctx.bumps.vault]\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    let cpi_accounts = TransferChecked {\n        from: ctx.accounts.from.to_account_info(),\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.to.to_account_info(),\n        authority: ctx.accounts.vault.to_account_info(),\n    };\n\n    let cpi_ctx = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    ).with_signer(signer_seeds);\n\n    token_interface::transfer_checked(cpi_ctx, amount, decimals)?;\n    Ok(())\n}\n```\n\n### Remaining Accounts\n\n```rust\npub fn process_multiple(ctx: Context<Process>) -> Result<()> {\n    for account_info in ctx.remaining_accounts.iter() {\n        let account = Account::<SomeAccount>::try_from(account_info)?;\n        msg!(\"Processing: {}\", account_info.key());\n        // Process account...\n    }\n    Ok(())\n}\n\n#[derive(Accounts)]\npub struct Process<'info> {\n    pub authority: Signer<'info>,\n    // Additional accounts in remaining_accounts\n}\n```\n\n### Close Account Pattern\n\n```rust\n#[derive(Accounts)]\npub struct CloseAccount<'info> {\n    #[account(\n        mut,\n        close = receiver,  // Sends lamports to receiver\n        has_one = authority\n    )]\n    pub account: Account<'info, MyAccount>,\n\n    pub authority: Signer<'info>,\n\n    #[account(mut)]\n    /// CHECK: Receives lamports\n    pub receiver: UncheckedAccount<'info>,\n}\n```\n\n### Dynamic Account Space\n\n```rust\n#[derive(Accounts)]\n#[instruction(name: String)]\npub struct Create<'info> {\n    #[account(\n        init,\n        payer = payer,\n        space = 8 + 4 + name.len() + 8\n    )]\n    pub item: Account<'info, Item>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n\n#[account]\npub struct Item {\n    pub name: String,\n    pub count: u64,\n}\n```\n\n---\n\n## Error Handling\n\n### Built-in Anchor Errors\n\nAnchor provides built-in errors in `ErrorCode` enum. Examples:\n- `ConstraintHasOne` - has_one constraint failed\n- `ConstraintSigner` - Account not a signer\n- `ConstraintMut` - Account not mutable\n- `ConstraintSeeds` - Seeds constraint failed\n- `AccountNotInitialized` - Account discriminator is zero\n\n### Custom Error Implementation\n\n```rust\n#[error_code]\npub enum ErrorCode {\n    #[msg(\"Amount must be greater than zero\")]\n    InvalidAmount,\n\n    #[msg(\"Insufficient balance: required {}, available {}\")]\n    InsufficientBalance,\n\n    #[msg(\"Unauthorized access\")]\n    Unauthorized,\n}\n\npub fn validate_amount(ctx: Context<Validate>, amount: u64) -> Result<()> {\n    require!(amount > 0, ErrorCode::InvalidAmount);\n\n    require!(\n        ctx.accounts.account.balance >= amount,\n        ErrorCode::InsufficientBalance\n    );\n\n    require_keys_eq!(\n        ctx.accounts.account.owner,\n        ctx.accounts.authority.key(),\n        ErrorCode::Unauthorized\n    );\n\n    Ok(())\n}\n```\n\n### Error Numbers\n\nAnchor errors use this numbering:\n- `0-1000` - Internal Anchor errors\n- `1000-2000` - Reserved\n- `2000-3000` - Custom program errors (from #[error_code])\n- `3000+` - Additional custom errors\n\n### TypeScript Error Handling\n\n```typescript\ntry {\n  await program.methods\n    .transfer(amount)\n    .accounts({ /* ... */ })\n    .rpc();\n} catch (error) {\n  if (error.code === 6000) {  // Custom error code\n    console.log(\"Custom error:\", error.msg);\n  }\n  console.log(\"Error logs:\", error.logs);\n}\n```\n\n---\n\n## Anchor.toml Configuration\n\n```toml\n[toolchain]\nanchor_version = \"0.32.1\"\nsolana_version = \"2.3.0\"\n\n[features]\nresolution = true  # IDL account resolution\nseeds = false\nskip-lint = false\n\n[programs.localnet]\nmy_program = \"YourProgramIdHere11111111111111111111111\"\n\n[programs.devnet]\nmy_program = \"YourProgramIdHere11111111111111111111111\"\n\n[programs.mainnet]\nmy_program = \"YourProgramIdHere11111111111111111111111\"\n\n[provider]\ncluster = \"localnet\"  # or devnet, mainnet-beta\nwallet = \"~/.config/solana/id.json\"\n\n[scripts]\ntest = \"yarn run ts-mocha -p ./tsconfig.json -t 1000000 tests/**/*.ts\"\n\n[test]\nstartup_wait = 10000\n\n[test.validator]\nurl = \"https://api.devnet.solana.com\"\n\n[[test.validator.clone]]\naddress = \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"\n\n[test.validator.upgradeable]\nmy_program = true\n\n[workspace]\ntypes = \"app/src/idl/\"\nmembers = [\"programs/*\"]\n\npackage_manager = \"yarn\"  # npm, yarn, pnpm, bun\n```\n\n---\n\n## Additional Resources\n\n- **Official Docs**: https://www.anchor-lang.com\n- **GitHub**: https://github.com/coral-xyz/anchor\n- **Examples**: https://github.com/coral-xyz/anchor/tree/master/tests\n- **Discord**: https://discord.gg/anchor\n\nFor general Solana concepts (accounts, PDAs, CPIs, transactions, etc.), refer to other reference files in this directory.\n",
        "solana/skills/solana-development/references/builtin-programs.md": "# Built-in Programs\n\nThis reference provides comprehensive coverage of Solana's built-in programs for native Rust development, focusing on the System Program and Compute Budget Program.\n\n## Table of Contents\n\n1. [Overview of Built-in Programs](#overview-of-built-in-programs)\n2. [System Program](#system-program)\n3. [Compute Budget Program](#compute-budget-program)\n4. [Other Built-in Programs](#other-built-in-programs)\n5. [CPI Patterns](#cpi-patterns)\n6. [Best Practices](#best-practices)\n\n---\n\n## Overview of Built-in Programs\n\n**Built-in programs** (also called native programs) are fundamental Solana programs that provide core blockchain functionality.\n\n### Key Built-in Programs\n\n| Program | Program ID | Purpose |\n|---------|-----------|---------|\n| **System Program** | `11111111111111111111111111111111` | Account creation, transfers, allocation |\n| **Compute Budget** | `ComputeBudget111111111111111111111111111111` | CU limits, heap size, priority fees |\n| **BPF Loader** | Various | Loading and executing programs |\n| **Config Program** | `Config1111111111111111111111111111111111111` | Validator configuration |\n| **Stake Program** | `Stake11111111111111111111111111111111111111` | Staking and delegation |\n| **Vote Program** | `Vote111111111111111111111111111111111111111` | Validator voting |\n\nThis reference focuses on the two most commonly used in program development: **System Program** and **Compute Budget Program**.\n\n---\n\n## System Program\n\n**Program ID:** `solana_program::system_program::ID` (`11111111111111111111111111111111`)\n\nThe System Program is responsible for account creation, lamport transfers, and account management.\n\n### Core Functionality\n\n1. **Create accounts** (regular and PDAs)\n2. **Transfer lamports** between accounts\n3. **Allocate space** for account data\n4. **Assign ownership** to programs\n5. **Create nonce accounts** for durable transactions\n\n### System Program Instructions\n\n```rust\nuse solana_program::system_instruction;\n\npub enum SystemInstruction {\n    CreateAccount,        // Create new account\n    Assign,               // Assign account to program\n    Transfer,             // Transfer lamports\n    CreateAccountWithSeed,// Create account with seed\n    AdvanceNonceAccount,  // Advance nonce\n    WithdrawNonceAccount, // Withdraw from nonce\n    InitializeNonceAccount, // Initialize nonce\n    Allocate,             // Allocate account space\n    AllocateWithSeed,     // Allocate with seed\n    AssignWithSeed,       // Assign with seed\n    TransferWithSeed,     // Transfer with seed\n    UpgradeNonceAccount,  // Upgrade nonce (v4)\n}\n```\n\n---\n\n### CreateAccount\n\n**Creates a new account with lamports and data space.**\n\n#### Function Signature\n\n```rust\npub fn create_account(\n    from_pubkey: &Pubkey,      // Funding account (must be signer)\n    to_pubkey: &Pubkey,        // New account address\n    lamports: u64,             // Lamports to fund account\n    space: u64,                // Bytes of data space\n    owner: &Pubkey,            // Program that will own the account\n) -> Instruction\n```\n\n#### Usage in Native Rust\n\n```rust\nuse solana_program::{\n    system_instruction,\n    program::invoke,\n};\n\npub fn create_new_account(\n    payer: &AccountInfo,\n    new_account: &AccountInfo,\n    system_program: &AccountInfo,\n    program_id: &Pubkey,\n) -> ProgramResult {\n    let space = 100;  // Account data size\n    let rent = Rent::get()?;\n    let lamports = rent.minimum_balance(space);\n\n    let create_account_ix = system_instruction::create_account(\n        payer.key,\n        new_account.key,\n        lamports,\n        space as u64,\n        program_id,\n    );\n\n    invoke(\n        &create_account_ix,\n        &[\n            payer.clone(),\n            new_account.clone(),\n            system_program.clone(),\n        ],\n    )?;\n\n    msg!(\"Created account with {} bytes\", space);\n    Ok(())\n}\n```\n\n#### Creating PDA Accounts\n\n```rust\nuse solana_program::program::invoke_signed;\n\npub fn create_pda_account(\n    payer: &AccountInfo,\n    pda_account: &AccountInfo,\n    system_program: &AccountInfo,\n    program_id: &Pubkey,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    // Verify PDA\n    let (expected_pda, _bump) = Pubkey::find_program_address(seeds, program_id);\n    if expected_pda != *pda_account.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    let space = 200;\n    let rent = Rent::get()?;\n    let lamports = rent.minimum_balance(space);\n\n    let create_account_ix = system_instruction::create_account(\n        payer.key,\n        pda_account.key,\n        lamports,\n        space as u64,\n        program_id,\n    );\n\n    // Create full seeds with bump\n    let mut full_seeds = seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    invoke_signed(\n        &create_account_ix,\n        &[payer.clone(), pda_account.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    msg!(\"Created PDA account at {}\", pda_account.key);\n    Ok(())\n}\n```\n\n---\n\n### Transfer\n\n**Transfers lamports from one account to another.**\n\n#### Function Signature\n\n```rust\npub fn transfer(\n    from_pubkey: &Pubkey,     // Source account (must be signer)\n    to_pubkey: &Pubkey,       // Destination account\n    lamports: u64,            // Amount to transfer\n) -> Instruction\n```\n\n#### Usage in Native Rust\n\n```rust\npub fn transfer_lamports(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    let transfer_ix = system_instruction::transfer(\n        from.key,\n        to.key,\n        amount,\n    );\n\n    invoke(\n        &transfer_ix,\n        &[from.clone(), to.clone(), system_program.clone()],\n    )?;\n\n    msg!(\"Transferred {} lamports from {} to {}\",\n        amount, from.key, to.key);\n    Ok(())\n}\n```\n\n#### Transfer from PDA\n\n```rust\npub fn transfer_from_pda(\n    pda: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let transfer_ix = system_instruction::transfer(\n        pda.key,\n        to.key,\n        amount,\n    );\n\n    let mut full_seeds = seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    invoke_signed(\n        &transfer_ix,\n        &[pda.clone(), to.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n### Allocate\n\n**Allocates space for an account's data.**\n\n#### Function Signature\n\n```rust\npub fn allocate(\n    pubkey: &Pubkey,          // Account to allocate (must be signer)\n    space: u64,               // Bytes to allocate\n) -> Instruction\n```\n\n#### Usage in Native Rust\n\n```rust\npub fn allocate_account_space(\n    account: &AccountInfo,\n    system_program: &AccountInfo,\n    space: u64,\n) -> ProgramResult {\n    let allocate_ix = system_instruction::allocate(\n        account.key,\n        space,\n    );\n\n    invoke(\n        &allocate_ix,\n        &[account.clone(), system_program.clone()],\n    )?;\n\n    msg!(\"Allocated {} bytes for account\", space);\n    Ok(())\n}\n```\n\n**⚠️ Note:** The account must be owned by the System Program before allocating. Most programs use `create_account` instead, which combines allocation with ownership assignment.\n\n---\n\n### Assign\n\n**Assigns an account to a program (changes owner).**\n\n#### Function Signature\n\n```rust\npub fn assign(\n    pubkey: &Pubkey,          // Account to assign (must be signer)\n    owner: &Pubkey,           // New owner program\n) -> Instruction\n```\n\n#### Usage in Native Rust\n\n```rust\npub fn assign_to_program(\n    account: &AccountInfo,\n    system_program: &AccountInfo,\n    new_owner: &Pubkey,\n) -> ProgramResult {\n    let assign_ix = system_instruction::assign(\n        account.key,\n        new_owner,\n    );\n\n    invoke(\n        &assign_ix,\n        &[account.clone(), system_program.clone()],\n    )?;\n\n    msg!(\"Assigned account to program {}\", new_owner);\n    Ok(())\n}\n```\n\n**⚠️ Note:** Most programs use `create_account` which handles assignment during creation.\n\n---\n\n### Complete Example: Account Lifecycle\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n    program::invoke_signed,\n    pubkey::Pubkey,\n    system_instruction,\n    sysvar::{rent::Rent, Sysvar},\n};\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserData {\n    pub user: Pubkey,\n    pub balance: u64,\n    pub created_at: i64,\n}\n\npub fn create_user_account(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    user_pubkey: Pubkey,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let payer = next_account_info(account_info_iter)?;\n    let user_account = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // 1. Derive PDA\n    let seeds = &[b\"user\", user_pubkey.as_ref()];\n    let (pda, bump) = Pubkey::find_program_address(seeds, program_id);\n\n    if pda != *user_account.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // 2. Calculate space and rent\n    let space = std::mem::size_of::<UserData>();\n    let rent = Rent::get()?;\n    let lamports = rent.minimum_balance(space);\n\n    // 3. Create account via System Program CPI\n    let create_ix = system_instruction::create_account(\n        payer.key,\n        user_account.key,\n        lamports,\n        space as u64,\n        program_id,\n    );\n\n    let signer_seeds: &[&[&[u8]]] = &[&[b\"user\", user_pubkey.as_ref(), &[bump]]];\n\n    invoke_signed(\n        &create_ix,\n        &[payer.clone(), user_account.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    // 4. Initialize account data\n    let clock = Clock::get()?;\n    let user_data = UserData {\n        user: user_pubkey,\n        balance: 0,\n        created_at: clock.unix_timestamp,\n    };\n\n    user_data.serialize(&mut &mut user_account.data.borrow_mut()[..])?;\n\n    msg!(\"Created user account for {}\", user_pubkey);\n    Ok(())\n}\n```\n\n---\n\n## Compute Budget Program\n\n**Program ID:** `solana_program::compute_budget::ID` (`ComputeBudget111111111111111111111111111111`)\n\nThe Compute Budget Program allows transactions to request specific compute unit limits, heap sizes, and priority fees.\n\n### Core Functionality\n\n1. **Set compute unit limit** - Maximum CUs for transaction\n2. **Set compute unit price** - Priority fee per CU\n3. **Request heap size** - Heap memory allocation\n\n### Compute Budget Instructions\n\n```rust\nuse solana_program::compute_budget::ComputeBudgetInstruction;\n\npub enum ComputeBudgetInstruction {\n    RequestUnitsDeprecated,      // Deprecated\n    RequestHeapFrame(u32),       // Request heap frame (bytes)\n    SetComputeUnitLimit(u32),    // Set max CUs\n    SetComputeUnitPrice(u64),    // Set priority fee (microlamports per CU)\n    SetLoadedAccountsDataSizeLimit(u32), // Set loaded accounts data limit\n}\n```\n\n---\n\n### SetComputeUnitLimit\n\n**Sets the maximum compute units available to the transaction.**\n\n#### Function Signature\n\n```rust\npub fn set_compute_unit_limit(units: u32) -> Instruction\n```\n\n#### Default Limits\n\n- **Default per instruction:** 200,000 CUs\n- **Default per transaction:** 1,400,000 CUs (with requested CU limit)\n- **Maximum:** 1,400,000 CUs\n\n#### Usage in Native Rust\n\n**Important:** Compute Budget instructions are added to the transaction by the **client**, not inside the program.\n\n**Client-side example (for reference):**\n\n```rust\n// This code runs CLIENT-SIDE, not in the program\nuse solana_sdk::{\n    compute_budget::ComputeBudgetInstruction,\n    transaction::Transaction,\n};\n\nlet compute_budget_ix = ComputeBudgetInstruction::set_compute_unit_limit(400_000);\n\nlet transaction = Transaction::new_signed_with_payer(\n    &[\n        compute_budget_ix,  // Must be first\n        your_program_ix,\n    ],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n```\n\n**⚠️ Note:** Programs cannot modify their own compute budget. These instructions must be added client-side before sending the transaction.\n\n---\n\n### SetComputeUnitPrice\n\n**Sets the priority fee per compute unit (for transaction prioritization).**\n\n#### Function Signature\n\n```rust\npub fn set_compute_unit_price(microlamports: u64) -> Instruction\n```\n\n#### Priority Fee Calculation\n\n```\nTotal Priority Fee = (CUs Used × microlamports) / 1,000,000\n```\n\n**Example:**\n- CUs used: 50,000\n- Price: 10,000 microlamports per CU\n- Fee: (50,000 × 10,000) / 1,000,000 = 500 lamports\n\n#### Usage (Client-side)\n\n```rust\n// Client-side code\nlet compute_unit_price_ix = ComputeBudgetInstruction::set_compute_unit_price(20_000);\n\nlet transaction = Transaction::new_signed_with_payer(\n    &[\n        compute_unit_price_ix,  // Set priority fee\n        your_program_ix,\n    ],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n```\n\n**Use cases:**\n- High-priority transactions (arbitrage, liquidations)\n- Congested network periods\n- Time-sensitive operations\n\n---\n\n### RequestHeapFrame\n\n**Requests additional heap memory for the transaction.**\n\n#### Function Signature\n\n```rust\npub fn request_heap_frame(bytes: u32) -> Instruction\n```\n\n#### Default Heap\n\n- **Default:** 32 KB\n- **Maximum:** 256 KB\n\n#### Usage (Client-side)\n\n```rust\n// Client-side code\nlet heap_size_ix = ComputeBudgetInstruction::request_heap_frame(256 * 1024); // 256 KB\n\nlet transaction = Transaction::new_signed_with_payer(\n    &[\n        heap_size_ix,       // Request more heap\n        your_program_ix,\n    ],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n```\n\n**When to use:**\n- Large data structures\n- Complex deserialization\n- Temporary buffers\n\n**⚠️ Cost:** Requesting heap increases CU consumption.\n\n---\n\n### SetLoadedAccountsDataSizeLimit\n\n**Sets the maximum total size of loaded account data.**\n\n#### Function Signature\n\n```rust\npub fn set_loaded_accounts_data_size_limit(bytes: u32) -> Instruction\n```\n\n#### Default Limit\n\n- **Default:** 64 MB per transaction\n\n#### Usage (Client-side)\n\n```rust\n// Client-side code\nlet accounts_data_limit_ix =\n    ComputeBudgetInstruction::set_loaded_accounts_data_size_limit(128 * 1024 * 1024);\n\nlet transaction = Transaction::new_signed_with_payer(\n    &[\n        accounts_data_limit_ix,\n        your_program_ix,\n    ],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n```\n\n**Use cases:**\n- Transactions with many large accounts\n- Bulk processing operations\n\n---\n\n### Complete Client-side Example\n\n```rust\nuse solana_sdk::{\n    compute_budget::ComputeBudgetInstruction,\n    transaction::Transaction,\n    signature::{Keypair, Signer},\n    pubkey::Pubkey,\n};\n\npub fn build_optimized_transaction(\n    payer: &Keypair,\n    program_id: &Pubkey,\n    program_ix_data: &[u8],\n    accounts: Vec<AccountMeta>,\n    recent_blockhash: Hash,\n) -> Transaction {\n    // 1. Set compute unit limit (if default 200k is insufficient)\n    let compute_limit_ix = ComputeBudgetInstruction::set_compute_unit_limit(300_000);\n\n    // 2. Set priority fee (for faster processing)\n    let compute_price_ix = ComputeBudgetInstruction::set_compute_unit_price(10_000);\n\n    // 3. Request additional heap if needed\n    let heap_size_ix = ComputeBudgetInstruction::request_heap_frame(128 * 1024); // 128 KB\n\n    // 4. Your program instruction\n    let program_ix = Instruction {\n        program_id: *program_id,\n        accounts,\n        data: program_ix_data.to_vec(),\n    };\n\n    // 5. Build transaction (compute budget instructions FIRST)\n    Transaction::new_signed_with_payer(\n        &[\n            compute_limit_ix,\n            compute_price_ix,\n            heap_size_ix,\n            program_ix,\n        ],\n        Some(&payer.pubkey()),\n        &[payer],\n        recent_blockhash,\n    )\n}\n```\n\n---\n\n## Other Built-in Programs\n\n### BPF Loader\n\n**Purpose:** Loads and executes Solana programs.\n\n**Program IDs:**\n- `BPFLoader1111111111111111111111111111111111` (deprecated)\n- `BPFLoader2111111111111111111111111111111111` (upgradeable)\n- `BPFLoaderUpgradeab1e11111111111111111111111` (current)\n\n**Usage:** Primarily used by the runtime. Programs rarely interact with BPF Loader directly.\n\n### Stake Program\n\n**Program ID:** `Stake11111111111111111111111111111111111111`\n\n**Purpose:** Staking SOL to validators.\n\n**Common operations:**\n- Create stake accounts\n- Delegate stake\n- Deactivate stake\n- Withdraw stake\n\n**Use case:** Staking pools, liquid staking protocols.\n\n### Vote Program\n\n**Program ID:** `Vote111111111111111111111111111111111111111`\n\n**Purpose:** Validator voting and consensus.\n\n**Use case:** Validator operations, rarely used by general programs.\n\n---\n\n## CPI Patterns\n\n### System Program CPI Pattern\n\n**Standard pattern for calling System Program:**\n\n```rust\nuse solana_program::{\n    program::invoke,\n    system_instruction,\n};\n\npub fn system_program_cpi(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n) -> ProgramResult {\n    // 1. Verify System Program\n    if system_program.key != &solana_program::system_program::ID {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // 2. Create instruction\n    let ix = system_instruction::transfer(from.key, to.key, 1_000_000);\n\n    // 3. Invoke\n    invoke(&ix, &[from.clone(), to.clone(), system_program.clone()])?;\n\n    Ok(())\n}\n```\n\n### PDA Signing Pattern\n\n**When PDAs need to sign:**\n\n```rust\npub fn pda_system_cpi(\n    pda: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    program_id: &Pubkey,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    // 1. Verify PDA\n    let (expected_pda, _) = Pubkey::find_program_address(seeds, program_id);\n    if expected_pda != *pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // 2. Create instruction\n    let ix = system_instruction::transfer(pda.key, to.key, 500_000);\n\n    // 3. Prepare signer seeds\n    let mut full_seeds = seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    // 4. Invoke with PDA signature\n    invoke_signed(\n        &ix,\n        &[pda.clone(), to.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n### Validation Pattern\n\n**Always validate accounts before CPI:**\n\n```rust\npub fn safe_system_cpi(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    // ✅ Validate System Program\n    if system_program.key != &solana_program::system_program::ID {\n        msg!(\"Invalid System Program\");\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // ✅ Validate signer\n    if !from.is_signer {\n        msg!(\"From account must be signer\");\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // ✅ Validate sufficient balance\n    if from.lamports() < amount {\n        msg!(\"Insufficient balance\");\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // Execute CPI\n    let ix = system_instruction::transfer(from.key, to.key, amount);\n    invoke(&ix, &[from.clone(), to.clone(), system_program.clone()])?;\n\n    Ok(())\n}\n```\n\n---\n\n## Best Practices\n\n### 1. Always Validate Program IDs\n\n```rust\n// ✅ Validate before CPI\nif system_program.key != &solana_program::system_program::ID {\n    return Err(ProgramError::IncorrectProgramId);\n}\n```\n\n### 2. Use Rent Exemption\n\n```rust\n// ✅ Always create accounts with rent exemption\nlet rent = Rent::get()?;\nlet lamports = rent.minimum_balance(space);\n\n// ❌ Don't use arbitrary amounts\nlet lamports = 1_000_000; // May not be rent-exempt!\n```\n\n### 3. Verify PDA Before Creation\n\n```rust\n// ✅ Verify PDA derivation\nlet (expected_pda, bump) = Pubkey::find_program_address(seeds, program_id);\nif expected_pda != *pda_account.key {\n    return Err(ProgramError::InvalidSeeds);\n}\n```\n\n### 4. Use invoke_signed for PDAs\n\n```rust\n// ✅ PDAs sign with invoke_signed\ninvoke_signed(&ix, accounts, signer_seeds)?;\n\n// ❌ Regular invoke won't work for PDA signers\ninvoke(&ix, accounts)?; // Fails if PDA needs to sign\n```\n\n### 5. Set Compute Budget Client-side\n\n```rust\n// ✅ Add compute budget instructions in client\nlet ixs = vec![\n    ComputeBudgetInstruction::set_compute_unit_limit(400_000),\n    your_program_ix,\n];\n\n// ❌ Cannot set from within program\n// Programs cannot modify their own compute budget\n```\n\n### 6. Order Compute Budget Instructions First\n\n```rust\n// ✅ Compute budget instructions FIRST\nlet ixs = vec![\n    compute_limit_ix,\n    compute_price_ix,\n    heap_size_ix,\n    program_ix,\n];\n\n// ❌ Wrong order - may not apply\nlet ixs = vec![\n    program_ix,\n    compute_limit_ix,  // Too late!\n];\n```\n\n### 7. Check Account Ownership Before Transfer\n\n```rust\n// ✅ Validate ownership for security\nif from_account.owner != &solana_program::system_program::ID {\n    msg!(\"Can only transfer from System-owned accounts\");\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **System Program** handles account creation, transfers, and allocation\n2. **Compute Budget Program** instructions are added **client-side**, not in programs\n3. **Always validate** program IDs before CPI\n4. **Use rent exemption** when creating accounts\n5. **PDAs require invoke_signed** for signing operations\n\n**Most Common Operations:**\n\n| Operation | Instruction | Use Case |\n|-----------|------------|----------|\n| Create account | `create_account` | New program accounts |\n| Transfer lamports | `transfer` | SOL transfers |\n| Set CU limit | `set_compute_unit_limit` | High-CU transactions |\n| Set priority fee | `set_compute_unit_price` | Fast transaction processing |\n| Request heap | `request_heap_frame` | Large data operations |\n\n**System Program CPI Template:**\n\n```rust\n// Validate\nif system_program.key != &solana_program::system_program::ID {\n    return Err(ProgramError::IncorrectProgramId);\n}\n\n// Create instruction\nlet ix = system_instruction::transfer(from.key, to.key, amount);\n\n// Invoke (or invoke_signed for PDAs)\ninvoke(&ix, &[from.clone(), to.clone(), system_program.clone()])?;\n```\n\n**Compute Budget Client Template:**\n\n```rust\n// Client-side\nlet ixs = vec![\n    ComputeBudgetInstruction::set_compute_unit_limit(300_000),\n    ComputeBudgetInstruction::set_compute_unit_price(10_000),\n    your_program_ix,\n];\n```\n\nMaster these built-in programs for efficient account management and transaction optimization in production Solana programs.\n",
        "solana/skills/solana-development/references/compute-optimization.md": "# Compute Unit Optimization Guide\n\nThis guide provides comprehensive techniques for optimizing compute unit (CU) usage in Solana native Rust programs, compiled from official Solana documentation, community repositories, and expert resources.\n\n## Understanding Compute Units\n\n### Compute Limits\n\nSolana enforces strict compute budgets to ensure network performance:\n\n- **Max CU per block**: 60 million CU\n- **Max CU per account per block**: 12 million CU\n- **Max CU per transaction**: 1.4 million CU\n- **Default soft cap per transaction**: 200,000 CU\n\nPrograms can request higher compute budgets using the Compute Budget program, up to the 1.4M hard limit.\n\n### Transaction Fees\n\nTransaction fees consist of two components:\n\n1. **Base fee**: 5,000 lamports per signature (fixed, independent of CU usage)\n2. **Priority fee**: Optional additional fee to prioritize transaction inclusion\n\nPriority fees are calculated as:\n```\npriority_fee = microLamports_per_CU × requested_compute_units\n```\n\n### Why Optimize CU Usage?\n\nEven though current fees don't scale with CU usage within the budget, optimization matters:\n\n1. **Block inclusion probability**: Smaller transactions are more likely to fit in congested blocks\n2. **Composability**: When your program is called via CPI, it shares the caller's CU budget\n3. **Efficient resource usage**: Better utilization of limited block space\n4. **Future-proofing**: Fee structures may change to account for actual CU consumption\n5. **User experience**: Faster transaction execution and lower rejection rates\n\n## Common Optimization Techniques\n\n### 1. Logging Optimization (Highest Impact)\n\nLogging is one of the most expensive operations in Solana programs.\n\n**Anti-patterns:**\n\n```rust\n// EXPENSIVE: 11,962 CU\n// Base58 encoding + string concatenation\nmsg!(\"A string {0}\", ctx.accounts.counter.to_account_info().key());\n\n// EXPENSIVE: 357 CU\n// String concatenation\nmsg!(\"A string {0}\", \"5w6z5PWvtkCd4PaAV7avxE6Fy5brhZsFdbRLMt8UefRQ\");\n```\n\n**Best practices:**\n\n```rust\n// EFFICIENT: 262 CU\n// Use .key().log() directly\nctx.accounts.counter.to_account_info().key().log();\n\n// BETTER: 206 CU\n// Store in variable first\nlet pubkey = ctx.accounts.counter.to_account_info().key();\npubkey.log();\n\n// CHEAPEST: 204 CU\n// Simple string logging\nmsg!(\"Compute units\");\n```\n\n**Recommendation**: Avoid logging in production unless absolutely necessary for debugging. Remove or conditionally compile logging for mainnet deployments.\n\n### 2. Data Type Optimization\n\nSmaller data types consume fewer compute units.\n\n**Comparison:**\n\n```rust\n// 618 CU - u64\nlet mut a: Vec<u64> = Vec::new();\nfor _ in 0..6 {\n    a.push(1);\n}\n\n// 600 CU - i32 (default integer type)\nlet mut a = Vec::new();\nfor _ in 0..6 {\n    a.push(1);\n}\n\n// 459 CU - u8 (best for small values)\nlet mut a: Vec<u8> = Vec::new();\nfor _ in 0..6 {\n    a.push(1);\n}\n```\n\n**Initialization vs pushing:**\n\n```rust\n// 357 CU - Pushing elements one by one\nlet mut a: Vec<u64> = Vec::new();\nfor _ in 0..6 {\n    a.push(1);\n}\n\n// 125 CU - Direct initialization (65% savings!)\nlet _a: Vec<u64> = vec![1, 1, 1, 1, 1, 1];\n```\n\n**Best practice**: Use the smallest data type that fits your requirements (u8 > u16 > u32 > u64), and prefer `vec![]` initialization over repeated `push()` calls.\n\n### 3. Serialization: Zero-Copy vs Borsh\n\nZero-copy deserialization can provide massive CU savings for account operations.\n\n**Standard Borsh serialization:**\n\n```rust\n// 6,302 CU - Standard account initialization\npub fn initialize(_ctx: Context<InitializeCounter>) -> Result<()> {\n    Ok(())\n}\n\n// 2,600 CU total for increment (including serialization overhead)\npub fn increment(ctx: Context<Increment>) -> Result<()> {\n    let counter = &mut ctx.accounts.counter;\n    counter.count = counter.count.checked_add(1).unwrap(); // 108 CU for operation\n    Ok(())\n}\n```\n\n**Zero-copy optimization:**\n\n```rust\n// 5,020 CU - Zero-copy initialization (20% savings)\npub fn initialize_zero_copy(_ctx: Context<InitializeCounterZeroCopy>) -> Result<()> {\n    Ok(())\n}\n\n// 1,254 CU total for increment (52% savings!)\npub fn increment_zero_copy(ctx: Context<IncrementZeroCopy>) -> Result<()> {\n    let counter = &mut ctx.accounts.counter_zero_copy.load_mut()?;\n    counter.count = counter.count.checked_add(1).unwrap(); // 151 CU for operation\n    Ok(())\n}\n```\n\n**Zero-copy account definition:**\n\n```rust\n#[account(zero_copy)]\n#[repr(C)]\n#[derive(InitSpace)]\npub struct CounterZeroCopy {\n    count: u64,\n    authority: Pubkey,\n    big_struct: BigStruct,  // Can include large structs without stack overflow\n}\n```\n\n**Benefits of zero-copy:**\n- 50%+ CU savings on serialization/deserialization\n- Avoids stack frame violations with large account structures\n- Direct memory access without intermediate copying\n- Particularly valuable for frequently updated accounts\n\n**Trade-off**: Slightly more complex API (`load()`, `load_mut()`) and requires `#[repr(C)]` for memory layout guarantees.\n\n### 4. Program Derived Addresses (PDAs)\n\nPDA operations vary significantly in cost depending on the method used.\n\n**Finding PDAs:**\n\n```rust\n// EXPENSIVE: 12,136 CU\n// Iterates through nonces to find valid bump seed\nlet (pda, bump) = Pubkey::find_program_address(&[b\"counter\"], ctx.program_id);\n\n// EFFICIENT: 1,651 CU (87% savings!)\n// Uses known bump seed directly\nlet pda = Pubkey::create_program_address(&[b\"counter\", &[248_u8]], &program_id).unwrap();\n```\n\n**Optimization strategy:**\n\n1. Use `find_program_address()` **once** during account initialization\n2. Save the bump seed in the account data\n3. Use `create_program_address()` with the saved bump for all subsequent operations\n\n**Anchor implementation:**\n\n```rust\n// Account structure - save the bump\n#[account]\npub struct CounterData {\n    pub count: u64,\n    pub bump: u8,  // Store the bump seed here\n}\n\n// EXPENSIVE: 12,136 CU - Without saved bump\n#[account(\n    seeds = [b\"counter\"],\n    bump  // Anchor finds it every time\n)]\npub counter_checked: Account<'info, CounterData>,\n\n// EFFICIENT: 1,600 CU - With saved bump (87% savings!)\n#[account(\n    seeds = [b\"counter\"],\n    bump = counter_checked.bump  // Use the saved bump\n)]\npub counter_checked: Account<'info, CounterData>,\n```\n\n### 5. Cross-Program Invocations (CPIs)\n\nCPIs add significant overhead compared to direct operations.\n\n**CPI to System Program:**\n\n```rust\n// 2,215 CU - CPI for SOL transfer\nlet cpi_context = CpiContext::new(\n    ctx.accounts.system_program.to_account_info(),\n    system_program::Transfer {\n        from: ctx.accounts.payer.to_account_info().clone(),\n        to: ctx.accounts.counter.to_account_info().clone(),\n    },\n);\nsystem_program::transfer(cpi_context, 1_000_000)?;\n```\n\n**Direct lamport manipulation:**\n\n```rust\n// 251 CU - Direct operation (90% savings!)\nlet counter_account_info = ctx.accounts.counter.to_account_info();\nlet mut counter_lamports = counter_account_info.try_borrow_mut_lamports()?;\n**counter_lamports += 1_000_000;\n\nlet payer_account_info = ctx.accounts.payer.to_account_info();\nlet mut payer_lamports = payer_account_info.try_borrow_mut_lamports()?;\n**payer_lamports -= 1_000_000;\n```\n\n**Important caveats:**\n\n1. **Error handling overhead**: Error paths add ~1,199 CU if triggered\n2. **Safety**: Direct manipulation bypasses safety checks in the System Program\n3. **Ownership**: Only safe when you control both accounts\n4. **Rent exemption**: You're responsible for maintaining rent exemption\n\n**Best practice**: Use CPIs for safety and correctness by default. Only optimize to direct manipulation when:\n- You have tight CU constraints\n- You fully understand the safety implications\n- Both accounts are controlled by your program\n\n### 6. Pass by Reference vs Clone\n\nSolana's bump allocator doesn't free memory, making unnecessary cloning particularly problematic.\n\n**Comparison:**\n\n```rust\nlet balances = vec![10_u64; 100];\n\n// EFFICIENT: 47,683 CU - Pass by reference\nfn sum_by_reference(data: &Vec<u64>) -> u64 {\n    data.iter().sum()\n}\n\nfor _ in 0..39 {\n    sum_reference += sum_by_reference(&balances);\n}\n\n// INEFFICIENT: 49,322 CU - Clone data (3.5% more expensive)\n// WARNING: Runs out of memory at 40+ iterations!\nfn sum_by_value(data: Vec<u64>) -> u64 {\n    data.iter().sum()\n}\n\nfor _ in 0..39 {\n    sum_clone += sum_by_value(balances.clone());\n}\n```\n\n**Memory concern**: Solana programs have a 32KB heap using a bump allocator that **never frees memory** during transaction execution. Excessive cloning leads to out-of-memory errors.\n\n**Best practice**: Always pass by reference (`&T`) unless you explicitly need ownership transfer. Use `Copy` types for small data.\n\n### 7. Checked Math vs Unchecked Operations\n\nChecked arithmetic adds safety at the cost of compute units.\n\n**Comparison:**\n\n```rust\nlet mut count: u64 = 1;\n\n// 97,314 CU - Checked multiplication with overflow protection\nfor _ in 0..12000 {\n    count = count.checked_mul(2).expect(\"overflow\");\n}\n\n// 85,113 CU - Bit shift operation (12% savings)\n// Equivalent to multiply by 2, but unchecked\nfor _ in 0..12000 {\n    count = count << 1;\n}\n```\n\n**Trade-off**: Unchecked operations are faster but risk overflow bugs that can lead to serious security vulnerabilities.\n\n**Best practice**:\n- Use checked math by default for safety\n- Profile your program to identify hot paths\n- Only switch to unchecked math when:\n  - You've proven overflow is impossible\n  - CU savings are critical\n  - You've added overflow tests\n\n**Compiler configuration** (in Cargo.toml):\n\n```toml\n[profile.release]\noverflow-checks = true  # Keep overflow checks even in release mode\n```\n\n## Framework Comparison\n\nDifferent implementation approaches offer varying trade-offs between developer experience, safety, and performance.\n\n| Implementation | Binary Size | Deploy Cost | Init CU | Increment CU |\n|---------------|-------------|-------------|---------|--------------|\n| **Anchor** | 265,677 bytes | 1.85 SOL | 6,302 | 946 |\n| **Anchor Zero-Copy** | Same | 1.85 SOL | 5,020 | ~1,254 |\n| **Native Rust** | 48,573 bytes | 0.34 SOL | - | 843 |\n| **Unsafe Rust** | 973 bytes | 0.008 SOL | - | 5 |\n| **Assembly (SBPF)** | 1,389 bytes | 0.01 SOL | - | 4 |\n| **C** | 1,333 bytes | 0.01 SOL | - | 5 |\n\n**Key insights:**\n\n- **Anchor**: Best developer experience, automatic account validation, but highest CU and deployment costs\n- **Anchor Zero-Copy**: Significant CU improvement over standard Anchor with minimal code changes\n- **Native Rust**: 11% CU savings over Anchor, 82% smaller deployment size, moderate complexity\n- **Unsafe Rust**: 99% CU savings, minimal size, but requires extreme care and deep expertise\n- **Assembly/C**: Maximum optimization possible, but very difficult to develop and maintain\n\n**Recommendation**: Start with Anchor or native Rust. Optimize hot paths with zero-copy. Only consider unsafe Rust or lower-level languages for critical performance bottlenecks after profiling.\n\n## Advanced Optimization Techniques\n\n### 1. Compiler Flags\n\nConfigure optimization in `Cargo.toml`:\n\n```toml\n[profile.release]\nopt-level = 3           # Maximum optimization\nlto = \"fat\"             # Full link-time optimization\ncodegen-units = 1       # Single codegen unit for better optimization\noverflow-checks = true  # Keep safety checks despite performance cost\n```\n\n**Trade-offs**:\n- `overflow-checks = false`: Saves CU but removes critical safety checks\n- Higher `opt-level`: Better performance but slower compilation\n- `lto = \"fat\"`: Maximum optimization but much slower builds\n\n### 2. Function Inlining\n\nControl function inlining to balance CU usage and stack space:\n\n```rust\n// Force inlining - saves CU by eliminating function call overhead\n#[inline(always)]\nfn add(a: u64, b: u64) -> u64 {\n    a + b\n}\n\n// Prevent inlining - saves stack space at the cost of CU\n#[inline(never)]\npub fn complex_operation() {\n    // Large function body\n}\n```\n\n**Trade-off**: Inlining saves CU but increases stack usage. Solana has a 4KB stack limit, so excessive inlining can cause stack overflow.\n\n### 3. Alternative Entry Points\n\nThe standard Solana entry point adds overhead. Alternatives:\n\n**Standard entry point:**\n```rust\nuse solana_program::entrypoint;\nentrypoint!(process_instruction);\n```\n\n**Minimal entry points:**\n- [solana-nostd-entrypoint](https://github.com/cavemanloverboy/solana-nostd-entrypoint): Ultra-minimal entry using unsafe Rust\n- [eisodos](https://github.com/anza-xyz/eisodos): Alternative minimal entry point\n\n**Warning**: These require deep understanding of Solana internals and unsafe Rust. Only use for extreme optimization needs.\n\n### 4. Custom Heap Allocators\n\nSolana's default bump allocator never frees memory during transaction execution.\n\n**Problem:**\n```rust\n// This will eventually run out of heap space (32KB limit)\nfor _ in 0..1000 {\n    let v = vec![0u8; 1024];  // Each iteration uses more heap\n    // Memory is never freed!\n}\n```\n\n**Solution - Custom allocators:**\n\n- **smalloc**: Used by Metaplex programs, provides better memory management\n- Prevents out-of-memory errors in memory-intensive operations\n\n**Implementation** (advanced):\n```rust\n#[global_allocator]\nstatic ALLOCATOR: custom_allocator::CustomAllocator = custom_allocator::CustomAllocator;\n```\n\n### 5. Boxing and Heap Allocation\n\nHeap operations cost more CU than stack operations.\n\n```rust\n// Stack allocation - faster\nlet data = [0u8; 100];\n\n// Heap allocation - slower, uses more CU\nlet data = Box::new([0u8; 100]);\n```\n\n**Best practice**: Avoid `Box`, `Vec`, and other heap allocations when stack allocation is possible and doesn't risk overflow.\n\n## Measuring Compute Units\n\n### Using sol_log_compute_units()\n\nBuilt-in logging function to track CU consumption:\n\n```rust\nuse solana_program::log::sol_log_compute_units;\n\npub fn my_instruction(ctx: Context<MyContext>) -> Result<()> {\n    sol_log_compute_units(); // Log remaining CU\n\n    // ... do some work ...\n\n    sol_log_compute_units(); // Log remaining CU again\n    Ok(())\n}\n```\n\n**Output in transaction logs:**\n```\nProgram consumption: 200000 units remaining\nProgram consumption: 195432 units remaining\n```\n\n**CU used = 200000 - 195432 = 4,568 CU**\n\n### compute_fn! Macro\n\nConvenient macro for measuring specific code blocks (costs 409 CU overhead):\n\n```rust\n#[macro_export]\nmacro_rules! compute_fn {\n    ($msg:expr=> $($tt:tt)*) => {\n        ::solana_program::msg!(concat!($msg, \" {\"));\n        ::solana_program::log::sol_log_compute_units();\n        let res = { $($tt)* };\n        ::solana_program::log::sol_log_compute_units();\n        ::solana_program::msg!(concat!(\" } // \", $msg));\n        res\n    };\n}\n```\n\n**Usage:**\n\n```rust\nlet result = compute_fn! { \"My expensive operation\" =>\n    expensive_computation()\n};\n```\n\n**Output:**\n```\nProgram log: My expensive operation {\nProgram consumption: 195432 units remaining\nProgram consumption: 180123 units remaining\nProgram log: } // My expensive operation\n```\n\n**Actual CU = (195432 - 180123) - 409 (macro overhead) = 14,900 CU**\n\n### Using Mollusk Bencher\n\nFor native Rust programs, use Mollusk's built-in benchmarking (see main SKILL.md for details).\n\n## Anti-Patterns to Avoid\n\n### 1. Excessive Logging\n\n```rust\n// BAD: Logging in production\nmsg!(\"Processing user {}\", user_pubkey);\nmsg!(\"Amount: {}\", amount);\nmsg!(\"Timestamp: {}\", Clock::get()?.unix_timestamp);\n```\n\n**Solution**: Remove logging or use conditional compilation:\n\n```rust\n#[cfg(feature = \"debug\")]\nmsg!(\"Processing user {}\", user_pubkey);\n```\n\n### 2. Large Data Types for Small Values\n\n```rust\n// BAD: Using u64 when u8 suffices\npub struct Config {\n    pub fee_percentage: u64,  // Only 0-100\n    pub max_items: u64,       // Only 0-255\n}\n\n// GOOD: Use smallest type\npub struct Config {\n    pub fee_percentage: u8,   // 0-100\n    pub max_items: u8,        // 0-255\n}\n```\n\n### 3. Cloning Large Structures\n\n```rust\n// BAD: Unnecessary clone\nfn process_data(data: Vec<u8>) -> Result<()> {\n    let copy = data.clone();  // Wastes CU and heap\n    // ...\n}\n\n// GOOD: Pass by reference\nfn process_data(data: &[u8]) -> Result<()> {\n    // Work directly with reference\n}\n```\n\n### 4. Repeated PDA Derivation\n\n```rust\n// BAD: Finding bump every time\n#[account(\n    seeds = [b\"vault\"],\n    bump  // Finds bump on every call!\n)]\npub vault: Account<'info, Vault>,\n\n// GOOD: Use saved bump\n#[account(\n    seeds = [b\"vault\"],\n    bump = vault.bump  // Uses saved bump\n)]\npub vault: Account<'info, Vault>,\n```\n\n### 5. Unnecessary Boxing\n\n```rust\n// BAD: Boxing adds heap overhead\nlet value = Box::new(calculate_value());\n\n// GOOD: Keep on stack\nlet value = calculate_value();\n```\n\n### 6. String Operations\n\n```rust\n// BAD: String concatenation and formatting\nlet message = format!(\"User {} sent {} tokens\", user, amount);\nmsg!(&message);\n\n// GOOD: Use separate logs or remove entirely\nuser.log();\namount.log();\n```\n\n### 7. Deep CPI Chains\n\nEach CPI adds significant overhead. Avoid unnecessary indirection:\n\n```rust\n// BAD: Unnecessary CPI\ninvoke(\n    &my_helper_program::process(),\n    &accounts,\n)?;\n\n// GOOD: Direct implementation\nprocess_directly(&accounts)?;\n```\n\n### 8. Not Using Zero-Copy for Large Accounts\n\n```rust\n// BAD: Large account with standard serialization\n#[account]\npub struct LargeData {\n    pub items: [u64; 1000],  // Expensive to serialize/deserialize\n}\n\n// GOOD: Use zero-copy\n#[account(zero_copy)]\n#[repr(C)]\npub struct LargeData {\n    pub items: [u64; 1000],  // Direct memory access\n}\n```\n\n## Best Practices Summary\n\n1. **Minimize or eliminate logging** in production code\n2. **Use zero-copy** for accounts with large data structures\n3. **Cache PDA bumps** - derive once, store in account, reuse\n4. **Choose smallest data types** that meet your requirements\n5. **Pass by reference** instead of cloning data\n6. **Profile before optimizing** - measure CU usage to identify bottlenecks\n7. **Consider native Rust** over Anchor for performance-critical programs\n8. **Use `vec![]` initialization** instead of repeated `push()` calls\n9. **Avoid unnecessary CPIs** - use direct operations when safe\n10. **Balance safety vs performance** - don't sacrifice security without careful analysis\n11. **Test CU usage** regularly - include benchmarks in your test suite\n12. **Use checked math by default** - only optimize to unchecked when proven safe\n13. **Minimize heap allocations** - prefer stack when possible\n14. **Remove or conditionally compile debug code** for production builds\n15. **Consider zero-copy for frequently updated accounts** - 50%+ CU savings\n\n## Additional Resources\n\n### Official Documentation\n- [How to Optimize Compute](https://solana.com/developers/guides/advanced/how-to-optimize-compute)\n- [Solana Compute Budget Documentation](https://github.com/solana-labs/solana/blob/090e11210aa7222d8295610a6ccac4acda711bb9/program-runtime/src/compute_budget.rs#L26-L87)\n\n### Code Examples and Tools\n- [solana-developers/cu_optimizations](https://github.com/solana-developers/cu_optimizations) - Official examples with benchmarks\n- [hetdagli234/optimising-solana-programs](https://github.com/hetdagli234/optimising-solana-programs) - Community optimization examples\n\n### Video Guides\n- [How to optimize CU in programs](https://www.youtube.com/watch?v=7CbAK7Oq_o4)\n- [Program optimization Part 1](https://www.youtube.com/watch?v=xoJ-3NkYXfY)\n- [Program optimization Part 2 - Advanced](https://www.youtube.com/watch?v=Pwly1cOa2hg)\n- [Writing Solana programs in Assembly](https://www.youtube.com/watch?v=eacDC0VgyxI)\n\n### Technical Articles\n- [RareSkills: Solana Compute Unit Price](https://rareskills.io/post/solana-compute-unit-price)\n- [Understanding Solana Compute Units](https://www.helius.dev/blog/priority-fees-understanding-solanas-transaction-fee-mechanics)\n\n### Advanced Tools\n- [solana-nostd-entrypoint](https://github.com/cavemanloverboy/solana-nostd-entrypoint) - Minimal entry point\n- [Mollusk](https://github.com/anza-xyz/mollusk) - Fast testing with CU benchmarking\n",
        "solana/skills/solana-development/references/cpi.md": "# Cross-Program Invocation (CPI)\n\nThis reference provides comprehensive coverage of Cross-Program Invocation (CPI) for native Rust Solana program development, including invoke patterns, account privilege propagation, and security considerations.\n\n## Table of Contents\n\n1. [What is CPI](#what-is-cpi)\n2. [CPI Fundamentals](#cpi-fundamentals)\n3. [invoke vs invoke_signed](#invoke-vs-invoke_signed)\n4. [Account Privilege Propagation](#account-privilege-propagation)\n5. [Common CPI Patterns](#common-cpi-patterns)\n6. [CPI Limits and Constraints](#cpi-limits-and-constraints)\n7. [Security Considerations](#security-considerations)\n8. [Best Practices](#best-practices)\n\n---\n\n## What is CPI\n\n**Cross-Program Invocation (CPI) is when one Solana program directly calls instructions on another program.**\n\n### Conceptual Model\n\nIf you think of a Solana instruction as an API endpoint, a CPI is like one API endpoint internally calling another.\n\n```\nUser Transaction\n     │\n     ▼\n┌────────────────────┐\n│   Your Program     │\n│                    │\n│   ┌──────────────┐ │\n│   │ Instruction  │ │\n│   │   Handler    │ │\n│   └──────┬───────┘ │\n│          │ CPI     │\n└──────────┼─────────┘\n           │\n           ▼\n┌────────────────────┐\n│ System Program     │\n│  create_account    │\n└────────────────────┘\n```\n\n### Why CPI is Essential\n\n**Composability**: Programs can leverage functionality from other programs without reimplementing it.\n\n**Common Use Cases:**\n- Create accounts (System Program CPI)\n- Transfer tokens (Token Program CPI)\n- Interact with DeFi protocols\n- Call custom program logic\n- Complex multi-step operations\n\n### CPI vs Direct Instruction\n\n| Aspect | Direct Instruction | CPI |\n|--------|-------------------|-----|\n| Who initiates | User wallet | Another program |\n| Signer source | User's private key | Program or PDA |\n| Call depth | 1 (top-level) | 2-5 (nested) |\n| Use case | Entry point | Program-to-program |\n\n---\n\n## CPI Fundamentals\n\n### The Two CPI Functions\n\nSolana provides two functions for making CPIs:\n\n```rust\nuse solana_program::program::{invoke, invoke_signed};\n\n// 1. invoke: For regular account signers\npub fn invoke(\n    instruction: &Instruction,\n    account_infos: &[AccountInfo],\n) -> ProgramResult\n\n// 2. invoke_signed: For PDA signers\npub fn invoke_signed(\n    instruction: &Instruction,\n    account_infos: &[AccountInfo],\n    signers_seeds: &[&[&[u8]]],\n) -> ProgramResult\n```\n\n### Required Imports\n\n```rust\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    instruction::{AccountMeta, Instruction},\n    program::{invoke, invoke_signed},\n    pubkey::Pubkey,\n};\n```\n\n### Instruction Structure\n\nBefore making a CPI, you must construct an `Instruction`:\n\n```rust\npub struct Instruction {\n    /// Program ID of the program being invoked\n    pub program_id: Pubkey,\n\n    /// Accounts required by the instruction\n    pub accounts: Vec<AccountMeta>,\n\n    /// Serialized instruction data\n    pub data: Vec<u8>,\n}\n\npub struct AccountMeta {\n    /// Account public key\n    pub pubkey: Pubkey,\n\n    /// Is this account a signer?\n    pub is_signer: bool,\n\n    /// Is this account writable?\n    pub is_writable: bool,\n}\n```\n\n---\n\n## invoke vs invoke_signed\n\n### invoke: Regular Signers\n\nUse `invoke` when all required signers are regular accounts (not PDAs).\n\n**Example: User transfers SOL**\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n    pubkey::Pubkey,\n    system_instruction,\n};\n\npub fn user_transfer_sol(\n    _program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let sender = next_account_info(account_info_iter)?;\n    let recipient = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Verify sender signed the transaction\n    if !sender.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Create transfer instruction\n    let transfer_ix = system_instruction::transfer(\n        sender.key,\n        recipient.key,\n        amount,\n    );\n\n    // Execute CPI (sender already signed the transaction)\n    invoke(\n        &transfer_ix,\n        &[\n            sender.clone(),\n            recipient.clone(),\n            system_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n**Key Points:**\n- `sender.is_signer` must be true (verified at transaction level)\n- No `signers_seeds` needed\n- `invoke` internally calls `invoke_signed` with empty seeds\n\n### invoke_signed: PDA Signers\n\nUse `invoke_signed` when a PDA needs to sign the instruction.\n\n**Example: PDA transfers SOL**\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n    program::invoke_signed,\n    program_error::ProgramError,\n    pubkey::Pubkey,\n    system_instruction,\n};\n\npub fn pda_transfer_sol(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let pda_account = next_account_info(account_info_iter)?;\n    let recipient = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Derive PDA and verify\n    let (pda, bump_seed) = Pubkey::find_program_address(\n        &[b\"vault\", recipient.key.as_ref()],\n        program_id,\n    );\n\n    if pda != *pda_account.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Create transfer instruction\n    let transfer_ix = system_instruction::transfer(\n        pda_account.key,  // From PDA (needs signing!)\n        recipient.key,\n        amount,\n    );\n\n    // PDA signing seeds (must match derivation)\n    let signer_seeds: &[&[&[u8]]] = &[&[\n        b\"vault\",\n        recipient.key.as_ref(),\n        &[bump_seed],  // Critical: bump must be included\n    ]];\n\n    // Execute CPI with PDA signature\n    invoke_signed(\n        &transfer_ix,\n        &[\n            pda_account.clone(),\n            recipient.clone(),\n            system_program.clone(),\n        ],\n        signer_seeds,  // Runtime verifies and grants signing authority\n    )?;\n\n    Ok(())\n}\n```\n\n**How Runtime Handles PDA Signing:**\n\n1. Runtime receives `signers_seeds`\n2. Calls `create_program_address(signers_seeds, calling_program_id)`\n3. Verifies derived PDA matches an account in the instruction\n4. Grants signing authority for that account\n5. Executes the CPI\n\n**Critical:** Seeds must exactly match the PDA derivation, including the bump.\n\n---\n\n## Account Privilege Propagation\n\n### Privilege Extension\n\nWhen making a CPI, account privileges **extend** from the caller to the callee.\n\n```\nUser Transaction\n     │ (provides: signer=true, writable=true)\n     ▼\n┌─────────────────────┐\n│  Program A          │\n│  Receives accounts: │\n│  - user (signer)    │──┐ Privileges\n│  - vault (writable) │  │ propagate\n└─────────────────────┘  │\n                         ▼\n                    ┌─────────────────────┐\n                    │  Program B (via CPI)│\n                    │  Can use:           │\n                    │  - user (signer)    │\n                    │  - vault (writable) │\n                    └─────────────────────┘\n```\n\n### Propagation Rules\n\n**Rule 1:** If an account is a signer in Program A, it remains a signer in Program B (via CPI)\n\n**Rule 2:** If an account is writable in Program A, it remains writable in Program B (via CPI)\n\n**Rule 3:** Programs can add PDA signers via `invoke_signed`\n\n**Rule 4:** Programs cannot escalate privileges (can't make non-signer a signer without PDA derivation)\n\n### Example: Privilege Propagation Chain\n\n```rust\n// User calls Program A\n// Accounts: [user (signer, writable), vault (writable), data_account]\n\n// Program A → CPI to Program B\ninvoke(\n    &instruction_for_program_b,\n    &[user.clone(), vault.clone()],  // Both retain privileges\n)?;\n\n// Program B → CPI to Program C\ninvoke(\n    &instruction_for_program_c,\n    &[user.clone()],  // user still a signer!\n)?;\n```\n\n**Depth**: Up to 4 levels of CPI (5 total stack height including initial transaction)\n\n---\n\n## Common CPI Patterns\n\n### 1. System Program: Create Account\n\n**Most common CPI**: Creating new accounts.\n\n```rust\nuse solana_program::{\n    program::invoke_signed,\n    rent::Rent,\n    system_instruction,\n    sysvar::Sysvar,\n};\n\npub fn create_pda_account(\n    program_id: &Pubkey,\n    payer: &AccountInfo,\n    pda_account: &AccountInfo,\n    system_program: &AccountInfo,\n    space: usize,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    // Calculate rent\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(space);\n\n    // Create account instruction\n    let create_account_ix = system_instruction::create_account(\n        payer.key,\n        pda_account.key,\n        rent_lamports,\n        space as u64,\n        program_id,\n    );\n\n    // Prepare signer seeds\n    let mut full_seeds = seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    // Execute CPI\n    invoke_signed(\n        &create_account_ix,\n        &[payer.clone(), pda_account.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n### 2. System Program: Transfer SOL\n\n```rust\nuse solana_program::system_instruction;\n\n// From regular account\nlet transfer_ix = system_instruction::transfer(from_key, to_key, lamports);\ninvoke(&transfer_ix, &[from_account, to_account, system_program])?;\n\n// From PDA\nlet transfer_ix = system_instruction::transfer(pda_key, to_key, lamports);\nlet signer_seeds: &[&[&[u8]]] = &[&[seeds, &[bump]]];\ninvoke_signed(&transfer_ix, &[pda_account, to_account, system_program], signer_seeds)?;\n```\n\n### 3. Custom Program CPI\n\n**Calling another custom program:**\n\n```rust\nuse borsh::BorshSerialize;\n\n#[derive(BorshSerialize)]\nstruct CustomInstructionData {\n    amount: u64,\n    memo: String,\n}\n\npub fn call_custom_program(\n    custom_program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let user = next_account_info(account_info_iter)?;\n    let target_account = next_account_info(account_info_iter)?;\n    let custom_program = next_account_info(account_info_iter)?;\n\n    // Serialize instruction data\n    let instruction_data = CustomInstructionData {\n        amount,\n        memo: \"Hello from CPI\".to_string(),\n    };\n    let data = instruction_data.try_to_vec()?;\n\n    // Build instruction\n    let instruction = Instruction {\n        program_id: *custom_program_id,\n        accounts: vec![\n            AccountMeta::new(*user.key, true),           // signer, writable\n            AccountMeta::new(*target_account.key, false), // writable\n        ],\n        data,\n    };\n\n    // Execute CPI\n    invoke(\n        &instruction,\n        &[user.clone(), target_account.clone(), custom_program.clone()],\n    )?;\n\n    Ok(())\n}\n```\n\n### 4. Multiple PDAs Signing\n\n```rust\npub fn multi_pda_cpi(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let pda1_seeds = &[b\"pda1\", &[bump1]];\n    let pda2_seeds = &[b\"pda2\", &[bump2]];\n\n    // Multiple PDA signers\n    let signer_seeds: &[&[&[u8]]] = &[\n        pda1_seeds,  // First PDA\n        pda2_seeds,  // Second PDA\n    ];\n\n    invoke_signed(&instruction, &accounts, signer_seeds)?;\n\n    Ok(())\n}\n```\n\n### 5. Chained CPIs\n\n**Program A calls Program B, which calls Program C:**\n\n```rust\n// In Program A\npub fn program_a_handler(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // Call Program B\n    let instruction_for_b = build_program_b_instruction();\n    invoke(&instruction_for_b, accounts)?;\n\n    Ok(())\n}\n\n// In Program B\npub fn program_b_handler(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // Call Program C\n    let instruction_for_c = build_program_c_instruction();\n    invoke(&instruction_for_c, accounts)?;\n\n    Ok(())\n}\n```\n\n**Depth tracking**: User→A→B→C = stack depth 4 (within limit)\n\n---\n\n## CPI Limits and Constraints\n\n### Stack Depth Limit\n\n**Maximum call depth:** 5 (including initial transaction)\n\n```\nDepth 1: User Transaction\nDepth 2: Program A (first CPI)\nDepth 3: Program B (second CPI)\nDepth 4: Program C (third CPI)\nDepth 5: Program D (fourth CPI)\nDepth 6: ❌ ERROR - MAX_INSTRUCTION_STACK_DEPTH exceeded\n```\n\n**Constant:**\n```rust\n// From agave source\npub const MAX_INSTRUCTION_STACK_DEPTH: usize = 5;\n```\n\n**Error when exceeded:**\n```\nError: CallDepth(5)\n```\n\n### Account Limits\n\n- **Max accounts per instruction:** 256 (practical limit ~64 without ALTs)\n- **Max writable accounts:** Limited by transaction size\n- **Duplicate accounts:** Allowed but share state (mutations visible to all references)\n\n### Compute Unit Costs\n\nCPI operations consume compute units:\n\n| Operation | Approximate CU Cost |\n|-----------|---------------------|\n| `invoke` base cost | ~1,000 CU |\n| `invoke_signed` base cost | ~1,000 CU |\n| Per account passed | ~50-100 CU |\n| PDA derivation in runtime | ~1,500 CU |\n| Actual callee logic | Variable |\n\n**Tip:** Pre-derive PDAs and store bumps to save CU.\n\n### Data Size Limits\n\n- **Instruction data:** No hard limit, but affects transaction size (1232 bytes max for non-ALT transactions)\n- **Account data modification:** Accounts can be resized via `realloc` (up to 10 MiB)\n\n---\n\n## Security Considerations\n\n### 1. Validate PDA Derivation Before CPI\n\n**❌ Vulnerable:**\n```rust\npub fn vulnerable_cpi(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let pda_account = &accounts[0];\n\n    // No validation!\n    let signer_seeds: &[&[&[u8]]] = &[&[b\"vault\", &[bump]]];\n\n    invoke_signed(&instruction, &[pda_account.clone()], signer_seeds)?;\n    Ok(())\n}\n```\n\n**✅ Secure:**\n```rust\npub fn secure_cpi(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    bump: u8,\n) -> ProgramResult {\n    let pda_account = &accounts[0];\n\n    // Validate PDA before CPI\n    let (expected_pda, _) = Pubkey::find_program_address(&[b\"vault\"], program_id);\n    if expected_pda != *pda_account.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    let signer_seeds: &[&[&[u8]]] = &[&[b\"vault\", &[bump]]];\n    invoke_signed(&instruction, &[pda_account.clone()], signer_seeds)?;\n    Ok(())\n}\n```\n\n### 2. Verify Signer Requirements\n\n**Always check `is_signer` before making CPIs that transfer value:**\n\n```rust\nif !user.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\nlet transfer_ix = system_instruction::transfer(user.key, vault.key, amount);\ninvoke(&transfer_ix, &[user.clone(), vault.clone(), system_program.clone()])?;\n```\n\n### 3. Program ID Verification\n\n**Verify the program being called is the expected program:**\n\n```rust\nconst EXPECTED_PROGRAM: &str = \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\";\n\nif token_program.key.to_string() != EXPECTED_PROGRAM {\n    return Err(ProgramError::IncorrectProgramId);\n}\n```\n\n### 4. Privilege Leakage\n\n**Be careful about which accounts you pass in CPIs:**\n\n```rust\n// ❌ Dangerous - passes admin with signer privilege\ninvoke(\n    &untrusted_program_instruction,\n    &[admin.clone(), user_data.clone()],  // Admin is a signer!\n)?;\n\n// ✅ Safe - only pass necessary accounts\ninvoke(\n    &untrusted_program_instruction,\n    &[user_data.clone()],  // Admin not included\n)?;\n```\n\n### 5. Reent rancy Considerations\n\n**Solana programs are generally safe from reentrancy** because:\n- Accounts are locked during instruction execution\n- Runtime prevents concurrent modifications\n\n**However, be cautious with:**\n- State assumptions across CPI boundaries\n- Read-modify-write patterns split across CPIs\n\n### 6. Error Handling\n\n**CPI errors propagate to the caller:**\n\n```rust\n// If CPI fails, entire transaction reverts\nmatch invoke(&instruction, &accounts) {\n    Ok(()) => msg!(\"CPI succeeded\"),\n    Err(e) => {\n        msg!(\"CPI failed: {:?}\", e);\n        return Err(e);  // Propagate error\n    }\n}\n```\n\n**All state changes are atomic** - if CPI fails, all changes rollback.\n\n---\n\n## Best Practices\n\n### 1. Derive PDAs Once\n\n```rust\n// ❌ Wasteful - derives multiple times\npub fn wasteful(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {\n    let (pda, bump) = Pubkey::find_program_address(&[b\"data\"], program_id);\n    // ... use pda\n\n    let (pda_again, bump_again) = Pubkey::find_program_address(&[b\"data\"], program_id);\n    // ... use pda_again (same as pda!)\n}\n\n// ✅ Efficient - derive once, reuse\npub fn efficient(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {\n    let (pda, bump) = Pubkey::find_program_address(&[b\"data\"], program_id);\n    // Reuse pda and bump\n}\n```\n\n### 2. Store and Reuse Bumps\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct VaultData {\n    pub bump: u8,  // Store on creation\n    // ... other fields\n}\n\n// On CPI: use stored bump\nlet vault_data = VaultData::try_from_slice(&vault_pda.data.borrow())?;\nlet signer_seeds: &[&[&[u8]]] = &[&[b\"vault\", &[vault_data.bump]]];\n```\n\n**Benefit:** Saves ~2,700 CU per operation.\n\n### 3. Helper Functions for Common CPIs\n\n```rust\npub mod cpi_helpers {\n    use super::*;\n\n    pub fn transfer_sol(\n        from: &AccountInfo,\n        to: &AccountInfo,\n        system_program: &AccountInfo,\n        amount: u64,\n    ) -> ProgramResult {\n        let ix = system_instruction::transfer(from.key, to.key, amount);\n        invoke(&ix, &[from.clone(), to.clone(), system_program.clone()])\n    }\n\n    pub fn transfer_sol_from_pda(\n        from_pda: &AccountInfo,\n        to: &AccountInfo,\n        system_program: &AccountInfo,\n        amount: u64,\n        signer_seeds: &[&[&[u8]]],\n    ) -> ProgramResult {\n        let ix = system_instruction::transfer(from_pda.key, to.key, amount);\n        invoke_signed(&ix, &[from_pda.clone(), to.clone(), system_program.clone()], signer_seeds)\n    }\n}\n```\n\n### 4. Validate All CPI Inputs\n\n**Checklist before CPI:**\n- ✅ Verify signer requirements (`is_signer`)\n- ✅ Validate PDA derivation\n- ✅ Check program IDs match expectations\n- ✅ Verify account ownership\n- ✅ Validate data integrity\n\n### 5. Document CPI Dependencies\n\n```rust\n/// Transfers SOL from program vault to recipient.\n///\n/// # Accounts\n/// 0. `[writable]` vault_pda - Program vault (PDA, signer)\n/// 1. `[writable]` recipient - Receives SOL\n/// 2. `[]` system_program - System Program (11111...)\n///\n/// # CPIs Made\n/// - System Program: transfer (from vault to recipient)\npub fn withdraw_from_vault(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    // ...\n}\n```\n\n### 6. Error Context\n\n```rust\ninvoke(&instruction, &accounts).map_err(|e| {\n    msg!(\"CPI to System Program failed\");\n    e\n})?;\n```\n\n### 7. Minimize CPI Depth\n\n**Keep call chains shallow:**\n- Reduces compute units\n- Easier to debug\n- Lower risk of hitting stack limit\n- Better user experience (simpler transactions)\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **CPI enables composability** - programs call other programs\n2. **Use `invoke` for regular signers**, `invoke_signed` for PDAs\n3. **Privileges propagate** - signers and writable flags extend through CPIs\n4. **Maximum depth is 5** - including initial transaction\n5. **Always validate PDAs** before using in `invoke_signed`\n6. **Verify signer requirements** to prevent unauthorized operations\n7. **Store bumps** in account data to save compute units\n8. **CPIs are atomic** - failures rollback all changes\n\n**Security Checklist:**\n- ✅ Validate PDA derivation with canonical bump\n- ✅ Verify `is_signer` for value transfers\n- ✅ Check program IDs match expectations\n- ✅ Only pass necessary accounts (avoid privilege leakage)\n- ✅ Handle CPI errors appropriately\n\n**Common Pattern:**\n```rust\n// 1. Validate inputs\nif !user.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\n// 2. Derive and validate PDA if needed\nlet (pda, bump) = Pubkey::find_program_address(&seeds, program_id);\nif pda != *pda_account.key {\n    return Err(ProgramError::InvalidSeeds);\n}\n\n// 3. Build instruction\nlet ix = build_instruction();\n\n// 4. Execute CPI\ninvoke_signed(&ix, &accounts, &[&[seeds, &[bump]]])?;\n```\n\nCPI is the foundation of program composability on Solana. Master it to build powerful, modular programs that leverage the entire ecosystem.\n",
        "solana/skills/solana-development/references/deployment.md": "# Solana Program Deployment Reference\n\nThis reference covers deployment workflows, best practices, and troubleshooting for both Anchor and native Rust Solana programs.\n\n## Table of Contents\n\n- [Deployment Overview](#deployment-overview)\n- [Pre-Deployment Checklist](#pre-deployment-checklist)\n- [Building Programs](#building-programs)\n- [Deploying to Networks](#deploying-to-networks)\n- [Program Upgrades](#program-upgrades)\n- [Verified Builds](#verified-builds)\n- [Program Authority Management](#program-authority-management)\n- [Multisig Deployments](#multisig-deployments)\n- [Network-Specific Considerations](#network-specific-considerations)\n- [Post-Deployment](#post-deployment)\n- [Common Issues and Troubleshooting](#common-issues-and-troubleshooting)\n- [Best Practices](#best-practices)\n\n---\n\n## Deployment Overview\n\n### Solana Networks\n\nSolana has three primary networks:\n\n**Localhost (127.0.0.1:8899)**\n- Local test validator running on your machine\n- Fastest iteration, no cost\n- Full control over network state\n- Use for rapid development and debugging\n\n**Devnet**\n- Public development network\n- Free SOL via airdrops\n- Resets periodically\n- Use for integration testing\n\n**Mainnet-beta**\n- Production network with real economic value\n- Requires real SOL for deployment and transactions\n- Immutable deployed programs (unless upgradeable)\n- Use for production deployments\n\n### Network Configuration\n\n**Anchor** - Edit `Anchor.toml`:\n\n```toml\n[toolchain]\n\n[features]\nseeds = false\nskip-lint = false\n\n[programs.localnet]\nmy_program = \"11111111111111111111111111111111\"\n\n[programs.devnet]\nmy_program = \"YourDevnetProgramID\"\n\n[programs.mainnet]\nmy_program = \"YourMainnetProgramID\"\n\n[registry]\nurl = \"https://api.apr.dev\"\n\n[provider]\ncluster = \"Localnet\"  # Change to \"Devnet\" or \"Mainnet\"\nwallet = \"~/.config/solana/id.json\"\n\n[scripts]\ntest = \"yarn run ts-mocha -p ./tsconfig.json -t 1000000 tests/**/*.ts\"\n```\n\n**Native Rust** - Use Solana CLI:\n\n```bash\n# View current config\nsolana config get\n\n# Set network\nsolana config set --url https://api.devnet.solana.com  # Devnet\nsolana config set --url https://api.mainnet-beta.solana.com  # Mainnet\nsolana config set --url http://localhost:8899  # Localnet\n\n# Set wallet\nsolana config set --keypair ~/.config/solana/id.json\n```\n\n### Cost Considerations\n\nProgram deployment requires rent-exempt balance for:\n\n1. **Program Account** - Stores program metadata (small cost)\n2. **Program Data Account** - Stores the executable bytecode (major cost)\n\n**Calculate deployment cost:**\n\n```bash\n# Get program size\nls -l target/deploy/my_program.so\n# Example: 363960 bytes\n\n# Check rent for program data account (1x program size in newer versions)\nsolana rent 363960\n# Output:\n# Rent-exempt minimum: ~2.5 SOL\n\n# Add transaction fees (~0.002 SOL) for deployment transactions\n```\n\n**Cost breakdown:**\n- **363KB program** ≈ 2.5 SOL rent + 0.002 SOL tx fees = **~2.502 SOL**\n- **800KB program** ≈ 5.5 SOL rent + 0.002 SOL tx fees = **~5.502 SOL**\n\n**Important:** Since Solana CLI v1.18+, program accounts are sized to 1x the .so file (previously 2x), reducing costs by approximately 50%.\n\n---\n\n## Pre-Deployment Checklist\n\n### 1. Build Verification\n\n**Anchor:**\n```bash\n# Clean build\nanchor clean\nanchor build\n\n# Verify build succeeded\nls -la target/deploy/\n# Should see: my_program.so and my_program-keypair.json\n```\n\n**Native Rust:**\n```bash\n# Clean build\ncargo clean\ncargo build-sbf\n\n# Verify build\nls -la target/deploy/\n# Should see: my_program.so\n```\n\n### 2. Testing Completeness\n\n**Anchor:**\n```bash\n# Run all tests on local validator\nanchor test\n\n# Run tests without redeploying\nanchor test --skip-deploy\n\n# Run specific test file\nanchor test tests/my-test.ts\n```\n\n**Native Rust:**\n```bash\n# Run Mollusk unit tests\ncargo test\n\n# Run integration tests\ncargo test-sbf\n```\n\n### 3. Security Review\n\n- [ ] All account validations implemented (owner checks, signer checks)\n- [ ] No missing arithmetic overflow checks\n- [ ] PDA seeds properly validated\n- [ ] No uninitialized account usage\n- [ ] Authority checks on privileged operations\n- [ ] CPI security (check target program IDs)\n- [ ] Consider professional audit for mainnet\n\n### 4. Program Size Optimization\n\n**Check current size:**\n```bash\nls -lh target/deploy/my_program.so\n```\n\n**Optimization techniques:**\n\n```toml\n# Cargo.toml - Release profile optimization\n[profile.release]\noverflow-checks = true\nlto = \"fat\"              # Link-time optimization\ncodegen-units = 1        # Single codegen unit\nopt-level = \"z\"          # Optimize for size (use \"3\" for speed)\nstrip = true             # Strip symbols\n\n[profile.release.build-override]\nopt-level = 3\nincremental = false\ncodegen-units = 1\n```\n\n**Remove unused dependencies:**\n```bash\n# Check dependency tree\ncargo tree\n\n# Remove unused features\n# Instead of:\n# solana-program = \"2.1.0\"\n# Use:\nsolana-program = { version = \"2.1.0\", default-features = false }\n```\n\n**Current size limits:**\n- Maximum program size: ~1 MB (actual limit varies by compute budget)\n- Recommended: Keep under 500KB for reliable deployment\n\n### 5. Rent Calculation\n\n```bash\n# Calculate exact rent needed\nPROGRAM_SIZE=$(wc -c < target/deploy/my_program.so)\nsolana rent $PROGRAM_SIZE\n\n# Fund deployment wallet\nsolana balance\n# If insufficient, request airdrop (devnet) or transfer SOL\n```\n\n---\n\n## Building Programs\n\n### Anchor Programs\n\n**Standard build:**\n```bash\nanchor build\n```\n\n**What it produces:**\n- `target/deploy/my_program.so` - Executable binary\n- `target/deploy/my_program-keypair.json` - Program ID keypair\n- `target/idl/my_program.json` - Interface definition\n- `target/types/my_program.ts` - TypeScript types\n\n**Build specific program in workspace:**\n```bash\nanchor build --program-name my_program\n```\n\n**Verifiable build (Docker-based):**\n```bash\n# Install solana-verify CLI\ncargo install solana-verify\n\n# Build verifiably\nsolana-verify build\n\n# Build specific program\nsolana-verify build --library-name my_program\n```\n\n**Sync program IDs:**\n```bash\n# After first build, sync declared IDs with keypair\nanchor keys sync\n```\n\n### Native Rust Programs\n\n**Standard build:**\n```bash\ncargo build-sbf\n```\n\n**What it produces:**\n- `target/deploy/my_program.so` - Executable binary\n- No automatic keypair generation (must provide or use deployed ID)\n\n**Verifiable build:**\n```bash\nsolana-verify build --library-name my_program\n```\n\n**Build with specific Solana version:**\n```bash\n# Set platform tools version\ncargo build-sbf --sbf-sdk ~/.local/share/solana/install/releases/2.1.0/solana-release/bin/sdk/sbf\n```\n\n### Understanding Build Outputs\n\n**.so file:**\n- Compiled BPF bytecode\n- This is what gets deployed on-chain\n- Hash determines if program matches source\n\n**Program ID keypair (Anchor):**\n- Generated on first build\n- Defines program's on-chain address\n- **CRITICAL:** Back this up before deploying\n\n**IDL (Anchor only):**\n- JSON describing program interface\n- Used by clients to interact with program\n- Can be uploaded on-chain for discovery\n\n---\n\n## Deploying to Networks\n\n### Anchor Deployment\n\n**Deploy to configured network:**\n```bash\n# Deploy to network specified in Anchor.toml [provider] cluster\nanchor deploy\n\n# Specify network explicitly\nanchor deploy --provider.cluster devnet\nanchor deploy --provider.cluster mainnet\n```\n\n**Deploy with specific program ID:**\n```bash\n# First deployment - uses keypair from target/deploy/\nanchor deploy\n\n# Redeploy to same address (upgrade)\nanchor deploy\n```\n\n**Deploy with priority fees (congested networks):**\n```bash\n# Set priority fee in micro-lamports per compute unit\nanchor deploy --provider.cluster mainnet \\\n  --program-name my_program \\\n  -- --with-compute-unit-price 50000\n```\n\n**What `anchor deploy` does:**\n1. Reads program from `target/deploy/my_program.so`\n2. Creates or uses existing program account\n3. Uploads program data via multiple write transactions\n4. Sets executable flag on program account\n5. Optionally uploads IDL to on-chain account\n\n### Native Rust Deployment\n\n**Deploy new program:**\n```bash\n# Deploy with auto-generated program ID\nsolana program deploy target/deploy/my_program.so\n\n# Deploy to specific program ID (first time)\nsolana program deploy target/deploy/my_program.so \\\n  --program-id my_program-keypair.json\n```\n\n**Deploy with priority fees:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  --with-compute-unit-price 50000 \\\n  --max-sign-attempts 100 \\\n  --use-rpc\n```\n\n**Flags explained:**\n- `--with-compute-unit-price` - Priority fee (micro-lamports per CU)\n- `--max-sign-attempts` - Retries for recent blockhash expiration\n- `--use-rpc` - Send transactions individually vs in batches\n- `-u <URL>` - Specify RPC endpoint\n\n**Check deployment cost before deploying:**\n```bash\n# Dry run to estimate cost\nsolana program deploy target/deploy/my_program.so --dry-run\n```\n\n### Deploying with Specific Program ID\n\n**Generate deterministic program ID:**\n```bash\n# Create new keypair\nsolana-keygen new -o my-program-keypair.json\n\n# View address\nsolana-keygen pubkey my-program-keypair.json\n```\n\n**For Anchor:**\n```bash\n# Update lib.rs with new program ID\ndeclare_id!(\"YourNewProgramID\");\n\n# Update Anchor.toml\n[programs.devnet]\nmy_program = \"YourNewProgramID\"\n\n# Rebuild and deploy\nanchor build\nanchor keys sync  # Verify IDs match\nanchor deploy\n```\n\n**For Native Rust:**\n```bash\n# Deploy using keypair\nsolana program deploy target/deploy/my_program.so \\\n  --program-id my-program-keypair.json\n```\n\n### Deployment Costs and Funding\n\n**Check balance before deployment:**\n```bash\nsolana balance\n```\n\n**Fund wallet for devnet:**\n```bash\n# Request airdrop (2 SOL max per request)\nsolana airdrop 2\n\n# For larger programs, request multiple times\nsolana airdrop 2 && solana airdrop 2\n```\n\n**Fund wallet for mainnet:**\n```bash\n# Transfer SOL from exchange or another wallet\n# No airdrops available on mainnet\n```\n\n**Cost estimation:**\n```bash\n# Program size\nPROGRAM_SIZE=$(wc -c < target/deploy/my_program.so)\n\n# Rent cost\nsolana rent $PROGRAM_SIZE\n\n# Add ~0.002-0.01 SOL for transaction fees\n# Add priority fees if network is congested\n```\n\n---\n\n## Program Upgrades\n\n### How Upgrades Work\n\nSolana programs deployed via `solana program deploy` or `anchor deploy` are **upgradeable by default**.\n\n**Upgrade mechanism:**\n1. Program data lives in separate account from program account\n2. Upgrade authority (wallet) can replace program data\n3. Program address stays the same\n4. All accounts/PDAs remain valid\n\n**Check if program is upgradeable:**\n```bash\nsolana program show <PROGRAM_ID>\n\n# Output shows:\n# Program Id: <PROGRAM_ID>\n# Owner: BPFLoaderUpgradeable1111111111111111111111111\n# ProgramData Address: <DATA_ACCOUNT>\n# Authority: <UPGRADE_AUTHORITY>  # If upgradeable\n# Last Deployed In Slot: ...\n# Data Length: ...\n```\n\n### Anchor Upgrades\n\n**Upgrade deployed program:**\n```bash\nanchor upgrade target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  --provider.cluster devnet\n```\n\n**Note:** In newer Anchor versions, `anchor deploy` automatically upgrades if program exists.\n\n**Upgrade with priority fees:**\n```bash\nanchor upgrade target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  --provider.cluster mainnet \\\n  -- --with-compute-unit-price 50000\n```\n\n### Native Rust Upgrades\n\n**Upgrade using same deploy command:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  --upgrade-authority ~/.config/solana/id.json\n```\n\n### Extending Program Accounts\n\n**Problem:** If new program is larger than allocated space:\n```\nError: account data too small for instruction\n```\n\n**Solution:** Extend program account before upgrading:\n\n```bash\n# Check current program size\nsolana program show <PROGRAM_ID>\n# Shows: Data Length: 363960 bytes\n\n# New build is larger\nNEW_SIZE=$(wc -c < target/deploy/my_program.so)\necho $NEW_SIZE\n# Shows: 380000 bytes\n\n# Calculate additional bytes needed\nADDITIONAL_BYTES=$((NEW_SIZE - 363960))\necho $ADDITIONAL_BYTES\n# Shows: 16040 bytes\n\n# Extend program account\nsolana program extend <PROGRAM_ID> $ADDITIONAL_BYTES\n\n# Check rent cost for extension\nsolana rent $ADDITIONAL_BYTES\n# Example: 0.2 SOL\n\n# Now upgrade works\nsolana program deploy target/deploy/my_program.so --program-id <PROGRAM_ID>\n```\n\n**Note:** Program extension support added in Solana CLI v1.18+\n\n### Data Migration Strategies\n\n**Account structure changes:**\n\nWhen upgrading programs that change account layouts:\n\n**Option 1: Version field**\n```rust\n#[account]\npub struct MyAccount {\n    pub version: u8,  // Add version field\n    pub data: u64,\n    // New fields in v2\n    pub new_field: Option<String>,\n}\n\n// In instruction handler\nif account.version == 1 {\n    // Migrate from v1 to v2\n    account.new_field = Some(\"default\".to_string());\n    account.version = 2;\n}\n```\n\n**Option 2: Separate migration instruction**\n```rust\npub fn migrate_account_v1_to_v2(ctx: Context<MigrateAccount>) -> Result<()> {\n    let account = &mut ctx.accounts.account;\n\n    // Perform migration logic\n    account.new_field = compute_new_field(&account.data);\n    account.version = 2;\n\n    Ok(())\n}\n```\n\n**Option 3: New program version with migration path**\n- Deploy new program ID\n- Create migration instructions that move data\n- Deprecate old program gradually\n\n---\n\n## Verified Builds\n\nVerified builds prove deployed bytecode matches public source code.\n\n### Why Verify?\n\n- **Transparency:** Users can audit your program's source\n- **Trust:** Proves deployed program matches GitHub repository\n- **Security:** Enables community security reviews\n- **Ecosystem:** Explorers display verified status\n- **Wallets:** May whitelist verified programs\n\n### Tools for Verification\n\n**Solana Verify CLI:**\n```bash\ncargo install solana-verify\n```\n\n**Docker (required for deterministic builds):**\n- Install Docker: https://docs.docker.com/engine/install/\n- Ensure Docker daemon is running\n\n### Building Verifiable Programs\n\n**Verifiable build process:**\n```bash\n# Navigate to project root (with Cargo.toml)\ncd my-project\n\n# Build in Docker container for deterministic output\nsolana-verify build\n\n# For workspace with specific program\nsolana-verify build --library-name my_program\n\n# Get hash of built executable\nsolana-verify get-executable-hash target/deploy/my_program.so\n```\n\n**What makes builds verifiable:**\n1. **Docker environment:** Ensures consistent build environment\n2. **Locked dependencies:** `Cargo.lock` pins exact versions\n3. **Same toolchain:** Uses specific Rust/Solana version\n4. **Deterministic compilation:** Same input → same output\n\n**Project structure requirements:**\n\n```\nmy-project/\n├── Cargo.toml          # Workspace manifest\n├── Cargo.lock          # Locked dependencies (required!)\n├── programs/\n│   └── my_program/\n│       ├── Cargo.toml\n│       └── src/\n│           └── lib.rs\n```\n\n**Workspace Cargo.toml example:**\n```toml\n[workspace]\nmembers = [\"programs/*\"]\nresolver = \"2\"\n\n[workspace.dependencies]\nsolana-program = \"2.1.0\"\n\n[profile.release]\noverflow-checks = true\nlto = \"fat\"\ncodegen-units = 1\n\n[profile.release.build-override]\nopt-level = 3\nincremental = false\ncodegen-units = 1\n```\n\n### Deploying Verifiable Programs\n\n**Deploy verified build:**\n```bash\n# IMPORTANT: Use the binary from solana-verify build\n# DO NOT run `anchor build` or `cargo build-sbf` after verification build\n\n# Deploy with priority fees for reliability\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  -u https://api.mainnet-beta.solana.com \\\n  --with-compute-unit-price 50000 \\\n  --max-sign-attempts 100 \\\n  --use-rpc\n```\n\n**Verify deployed program matches built executable:**\n```bash\n# Get on-chain program hash\nsolana-verify get-program-hash -u mainnet-beta <PROGRAM_ID>\n\n# Get local executable hash\nsolana-verify get-executable-hash target/deploy/my_program.so\n\n# Hashes must match!\n```\n\n### Verifying Against Repository\n\n**Verify from GitHub repository:**\n```bash\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo \\\n  --commit-hash <COMMIT_HASH> \\\n  --library-name my_program \\\n  --mount-path programs/my_program\n```\n\n**Parameters explained:**\n- `--program-id`: On-chain program address\n- `--commit-hash`: Git commit to build from (optional, uses latest if omitted)\n- `--library-name`: Crate name from Cargo.toml `[lib]` section\n- `--mount-path`: Path to program directory in repo (for workspaces)\n\n**Upload verification data on-chain:**\n\nWhen prompted during verification:\n```\nWould you like to upload verification data on-chain? (y/n)\n```\n\nSelect **yes** to write verification PDA. This enables:\n- Solana Explorer verification badge\n- OtterSec API verification\n- SolanaFM verification display\n\n### Remote Verification with OtterSec API\n\n**Submit verification job:**\n```bash\nsolana-verify verify-from-repo \\\n  --remote \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo\n```\n\n**Manual job submission:**\n```bash\nsolana-verify remote submit-job \\\n  --program-id <PROGRAM_ID> \\\n  --uploader <UPGRADE_AUTHORITY>\n```\n\n**Check verification status:**\n```bash\nsolana-verify remote get-job-status --job-id <JOB_ID>\n```\n\n**Verification API endpoint:**\n```\nhttps://verify.osec.io/status/<PROGRAM_ID>\n```\n\n**Where verified status appears:**\n- [Solana Explorer](https://explorer.solana.com)\n- [SolanaFM](https://solana.fm)\n- [SolScan](https://solscan.io)\n- [SolanaVerify.org](https://solanaverify.org)\n- [OtterSec API](https://verify.osec.io/verified-programs)\n\n### security.txt Integration\n\n**Add security contact info:**\n\n```rust\n#[cfg(not(feature = \"no-entrypoint\"))]\nsolana_security_txt::security_txt! {\n    name: \"My Program\",\n    project_url: \"https://myproject.com\",\n    contacts: \"email:security@myproject.com,discord:myproject\",\n    policy: \"https://github.com/myproject/security/blob/main/SECURITY.md\",\n    preferred_languages: \"en\",\n    source_code: \"https://github.com/myproject/program\",\n    source_release: \"v1.0.0\",\n    auditors: \"Audit Firm Name\"\n}\n```\n\n**Benefits:**\n- Security researchers know how to contact you\n- Shows commitment to security\n- Standard across Solana ecosystem\n\n---\n\n## Program Authority Management\n\n### Viewing Program Information\n\n**Check program authority:**\n```bash\nsolana program show <PROGRAM_ID>\n\n# Output:\n# Program Id: YourProgramId\n# Owner: BPFLoaderUpgradeable1111111111111111111111111\n# ProgramData Address: <DATA_ACCOUNT_ADDRESS>\n# Authority: <CURRENT_AUTHORITY>  # Current upgrade authority\n# Last Deployed In Slot: 123456789\n# Data Length: 363960 bytes (0x58e38 bytes)\n```\n\n**View all your deployed programs:**\n```bash\nsolana program show --programs\n\n# Shows all programs where your wallet is authority\n```\n\n### Transferring Upgrade Authority\n\n**Transfer to new authority:**\n```bash\nsolana program set-upgrade-authority <PROGRAM_ID> \\\n  --new-upgrade-authority <NEW_AUTHORITY_PUBKEY>\n```\n\n**Common use cases:**\n- Transfer to multisig (Squads Protocol)\n- Transfer to governance program\n- Transfer to team member\n- Transfer to DAO\n\n**Transfer to multisig (Squads):**\n```bash\n# Get Squads vault address from https://v4.squads.so/\nSQUADS_VAULT=\"YourSquadsVaultAddress\"\n\nsolana program set-upgrade-authority <PROGRAM_ID> \\\n  --new-upgrade-authority $SQUADS_VAULT\n```\n\n### Making Programs Immutable\n\n**WARNING:** This is irreversible!\n\n```bash\nsolana program set-upgrade-authority <PROGRAM_ID> --final\n\n# Confirms immutability - program can NEVER be upgraded\n```\n\n**Use cases for immutability:**\n- DeFi protocols requiring immutable guarantees\n- After extensive auditing, lock the program\n- Community trust through code permanence\n\n**Considerations:**\n- Cannot fix bugs after making immutable\n- Cannot add features\n- Ensure thorough testing and auditing first\n- Consider governance/multisig instead\n\n### Buffer Accounts for Deployment\n\n**Understanding buffers:**\n\nWhen deploying, the Solana CLI creates temporary buffer accounts:\n\n1. Creates buffer account\n2. Writes program data to buffer\n3. Deploys buffer to program account\n4. Closes buffer (if successful)\n\n**View your buffer accounts:**\n```bash\nsolana program show --buffers\n\n# Output:\n# Buffer Address                                | Authority                                      | Balance\n# Abc123...                                     | YourWallet...                                  | 2.5 SOL\n```\n\n**Close buffer manually (failed deployment):**\n```bash\nsolana program close <BUFFER_ADDRESS>\n\n# Recovers rent SOL back to wallet\n```\n\n**Common scenarios:**\n- Deployment failed mid-process\n- Want to cancel deployment\n- Need to reclaim SOL from old buffers\n\n---\n\n## Multisig Deployments\n\nDeploying with multisig (Squads Protocol) provides security for production programs.\n\n### Why Use Multisig?\n\n- **Security:** No single point of failure\n- **Governance:** Team/DAO approval for upgrades\n- **Transparency:** On-chain approval trail\n- **Best practice:** Standard for serious projects\n\n### Workflow Overview\n\n1. Build verifiable program\n2. Deploy with temporary authority\n3. Verify against repository\n4. Transfer authority to multisig\n5. Export PDA transaction for verification upload\n6. Submit through Squads UI\n7. Remote verification\n\n### Detailed Multisig Deployment\n\n**1. Build verifiable program:**\n```bash\nsolana-verify build --library-name my_program\n```\n\n**2. Deploy with your wallet as initial authority:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 50000\n```\n\n**3. Verify locally:**\n```bash\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/repo \\\n  --commit-hash <COMMIT>\n```\n\n**4. Transfer authority to Squads multisig:**\n\nGet Squads vault address from https://v4.squads.so/\n\n```bash\nSQUADS_VAULT=\"YourSquadsVaultAddress\"\n\nsolana program set-upgrade-authority <PROGRAM_ID> \\\n  --new-upgrade-authority $SQUADS_VAULT\n```\n\n**5. Export verification PDA transaction:**\n\n```bash\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/repo \\\n  --export-pda-tx verification_tx.json\n```\n\n**6. Submit transaction in Squads:**\n\n- Go to https://v4.squads.so/\n- Navigate to your multisig\n- Create new transaction\n- Import `verification_tx.json`\n- Get approval from multisig members\n- Execute transaction\n\n**7. Submit remote verification:**\n\nAfter Squads transaction executes:\n\n```bash\nsolana-verify remote submit-job \\\n  --program-id <PROGRAM_ID> \\\n  --uploader <SQUADS_VAULT>\n```\n\n**8. Monitor verification:**\n\n```bash\n# Check job status\nsolana-verify remote get-job-status --job-id <JOB_ID>\n\n# Or visit\nhttps://verify.osec.io/status/<PROGRAM_ID>\n```\n\n### Upgrading via Multisig\n\n**Create upgrade buffer:**\n```bash\n# Build new version\nsolana-verify build --library-name my_program\n\n# Write to buffer (not direct upgrade)\nsolana program write-buffer target/deploy/my_program.so\n\n# Output: Buffer address: <BUFFER_ADDRESS>\n```\n\n**Transfer buffer authority to multisig:**\n```bash\nsolana program set-buffer-authority <BUFFER_ADDRESS> \\\n  --new-buffer-authority <SQUADS_VAULT>\n```\n\n**Create Squads transaction for upgrade:**\n\nUse Squads CLI or UI to propose:\n```bash\n# Using Squads SDK/CLI\nnpx ts-node scripts/program-upgrade.ts \\\n  --rpc \"https://api.mainnet-beta.solana.com\" \\\n  --program \"<PROGRAM_ID>\" \\\n  --buffer \"<BUFFER_ADDRESS>\" \\\n  --multisig \"<MULTISIG_ADDRESS>\" \\\n  --member \"<YOUR_PUBKEY>\" \\\n  --name \"Upgrade my_program v2\"\n```\n\n**Close buffer via Squads (if needed):**\n```bash\nnpx ts-node scripts/squad-closebuffer.ts \\\n  --rpc \"https://api.mainnet-beta.solana.com\" \\\n  --multisig \"<MULTISIG_ADDRESS>\" \\\n  --buffer \"<BUFFER_ADDRESS>\" \\\n  --program \"<PROGRAM_ID>\"\n```\n\n---\n\n## Network-Specific Considerations\n\n### Localhost Development\n\n**Start test validator:**\n```bash\n# Basic\nsolana-test-validator\n\n# With program pre-deployed\nsolana-test-validator --bpf-program <PROGRAM_ID> target/deploy/my_program.so\n\n# With cloned mainnet accounts\nsolana-test-validator \\\n  --clone <ACCOUNT_ADDRESS> \\\n  --url mainnet-beta\n\n# Reset ledger on restart\nsolana-test-validator --reset\n```\n\n**Deploy to local validator:**\n```bash\n# Anchor\nanchor localnet  # Starts validator and deploys\n# Or\nanchor deploy --provider.cluster localnet\n\n# Native Rust\nsolana program deploy target/deploy/my_program.so -ul\n```\n\n**Benefits:**\n- Instant transaction confirmation\n- Unlimited free SOL\n- Full control over clock and state\n- Fast iteration\n\n**Limitations:**\n- No network effects\n- Single validator (no consensus)\n- State doesn't persist (unless configured)\n\n### Devnet Deployment\n\n**Configure network:**\n```bash\nsolana config set --url devnet\n```\n\n**Fund wallet:**\n```bash\nsolana airdrop 2\n# Repeat as needed, max 2 SOL per request\n```\n\n**Deploy:**\n```bash\n# Anchor\nanchor deploy --provider.cluster devnet\n\n# Native Rust\nsolana program deploy target/deploy/my_program.so \\\n  -u devnet \\\n  --with-compute-unit-price 1000\n```\n\n**Benefits:**\n- Real network conditions\n- Free SOL via airdrops\n- Test integrations with other programs\n- Longer-lived state than localnet\n\n**Limitations:**\n- Network resets occasionally\n- Potential rate limiting\n- Slower than localnet\n- Public network (anyone can interact)\n\n**Best practices:**\n- Test all upgrade paths on devnet first\n- Monitor transaction success rates\n- Test with realistic compute budgets\n- Validate against cloned mainnet accounts\n\n### Testnet Deployment\n\nTestnet is less commonly used but available for staging:\n\n```bash\nsolana config set --url testnet\nsolana airdrop 2  # If available\n```\n\n**Use cases:**\n- Staging environment before mainnet\n- Testing between devnet and mainnet\n- Longer-term testing without mainnet costs\n\n### Mainnet Deployment\n\n**Pre-deployment checklist:**\n- [ ] Thoroughly tested on devnet\n- [ ] Security audit completed (for DeFi/high-value programs)\n- [ ] Verified build prepared\n- [ ] Upgrade authority configured (multisig recommended)\n- [ ] Sufficient SOL for deployment (check `solana rent`)\n- [ ] Monitoring/alerting setup\n- [ ] Rollback plan documented\n- [ ] Team coordination for deployment time\n\n**Configure mainnet:**\n```bash\nsolana config set --url mainnet-beta\n\n# Use paid RPC for reliability (recommended)\nsolana config set --url https://your-rpc-provider.com\n```\n\n**Fund wallet:**\n```bash\n# Transfer from exchange or another wallet\n# Calculate needed SOL:\nPROGRAM_SIZE=$(wc -c < target/deploy/my_program.so)\nsolana rent $PROGRAM_SIZE\n# Add ~0.5 SOL buffer for transaction fees and priority fees\n```\n\n**Deploy with appropriate priority fees:**\n\nCheck current priority fee recommendations:\n- https://www.quicknode.com/gas-tracker/solana\n- https://solanacompass.com/gas-fees\n\n```bash\n# Typical priority fee: 50,000-300,000 micro-lamports per CU\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 100000 \\\n  --max-sign-attempts 100 \\\n  --use-rpc\n```\n\n**Post-deployment verification:**\n```bash\n# Verify deployment\nsolana program show <PROGRAM_ID> -u mainnet-beta\n\n# Verify hash matches\nsolana-verify get-program-hash -u mainnet-beta <PROGRAM_ID>\n\n# Submit verification job\nsolana-verify verify-from-repo \\\n  --remote \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/repo\n```\n\n**Cost considerations:**\n- 200KB program: ~1.5 SOL\n- 500KB program: ~3.5 SOL\n- 800KB program: ~5.5 SOL\n- Plus transaction fees: ~0.01-0.05 SOL\n- Priority fees during congestion: +0.1-1 SOL\n\n---\n\n## Post-Deployment\n\n### Verifying Deployment Success\n\n**Check program was deployed:**\n```bash\nsolana program show <PROGRAM_ID>\n\n# Verify output shows:\n# - Correct ProgramData address\n# - Your authority\n# - Expected data length\n# - Recent slot number\n```\n\n**Compare program hash:**\n```bash\n# On-chain hash\nsolana-verify get-program-hash -u <NETWORK> <PROGRAM_ID>\n\n# Local build hash\nsolana-verify get-executable-hash target/deploy/my_program.so\n\n# Must match exactly\n```\n\n### Testing On-Chain\n\n**Anchor:**\n```bash\n# Run tests against deployed program\nanchor test --skip-deploy --provider.cluster devnet\n\n# Or run specific test\nanchor run test-on-devnet\n```\n\n**Native Rust / TypeScript client:**\n```typescript\nimport { Connection, PublicKey } from '@solana/web3.js';\n\nconst connection = new Connection('https://api.devnet.solana.com');\nconst programId = new PublicKey('YourProgramId');\n\n// Send test transaction\nconst tx = await program.methods\n  .yourInstruction()\n  .accounts({ /* ... */ })\n  .rpc();\n\nconsole.log('Transaction:', tx);\n```\n\n**Smoke tests:**\n- Call each instruction with valid inputs\n- Verify account state changes\n- Check events are emitted correctly\n- Test error cases return expected errors\n\n### Monitoring Program Usage\n\n**View recent transactions:**\n```bash\n# Get recent transactions for program\nsolana transaction-history <PROGRAM_ID> --limit 10\n\n# Or use explorers:\n# https://explorer.solana.com/address/<PROGRAM_ID>\n# https://solscan.io/account/<PROGRAM_ID>\n```\n\n**Set up monitoring:**\n\nUse services like:\n- [Helius webhooks](https://www.helius.dev/)\n- [QuickNode functions](https://www.quicknode.com/)\n- [SolanaFM API](https://solana.fm/)\n\n**Monitor for:**\n- Transaction success rate\n- Compute unit usage\n- Error frequency\n- Unusual activity patterns\n\n### Publishing IDL (Anchor)\n\n**Upload IDL to on-chain account:**\n```bash\nanchor idl init <PROGRAM_ID> \\\n  --filepath target/idl/my_program.json \\\n  --provider.cluster devnet\n```\n\n**Upgrade IDL after program upgrade:**\n```bash\nanchor idl upgrade <PROGRAM_ID> \\\n  --filepath target/idl/my_program.json \\\n  --provider.cluster devnet\n```\n\n**Fetch published IDL:**\n```bash\nanchor idl fetch <PROGRAM_ID> \\\n  --provider.cluster devnet \\\n  --out fetched_idl.json\n```\n\n**Benefits of publishing IDL:**\n- Clients can auto-discover your interface\n- Explorers can decode instructions\n- Reduces integration friction\n- Standard for Anchor programs\n\n### Closing Programs and Reclaiming SOL\n\n**Close buffer accounts:**\n```bash\n# View all buffers\nsolana program show --buffers\n\n# Close specific buffer\nsolana program close <BUFFER_ADDRESS>\n\n# Reclaims rent SOL to wallet\n```\n\n**Close entire program (irreversible!):**\n```bash\nsolana program close <PROGRAM_ID>\n\n# WARNING: This deletes the program permanently\n# Cannot be undone\n# Only do this for test programs\n```\n\n**When to close:**\n- Failed test deployments on devnet\n- Obsolete test programs\n- Reclaim SOL from old projects\n\n**When NOT to close:**\n- Any program with active users\n- Programs other contracts depend on\n- Mainnet programs (almost never)\n\n---\n\n## Common Issues and Troubleshooting\n\n### Insufficient Balance\n\n**Error:**\n```\nError: Account <WALLET> has insufficient funds for spend (1.5 SOL) + fee (0.002 SOL)\n```\n\n**Solution:**\n```bash\n# Check current balance\nsolana balance\n\n# Devnet - request airdrop\nsolana airdrop 2\n\n# Mainnet - transfer SOL\n# Calculate needed amount:\nPROGRAM_SIZE=$(wc -c < target/deploy/my_program.so)\nsolana rent $PROGRAM_SIZE\n# Add 0.5 SOL buffer\n```\n\n### Program Too Large\n\n**Error:**\n```\nError: Program too large. Maximum size: 1048576 bytes\n```\n\n**Solutions:**\n\n**1. Optimize build:**\n```toml\n[profile.release]\nlto = \"fat\"\ncodegen-units = 1\nopt-level = \"z\"  # Optimize for size\nstrip = true\n```\n\n**2. Remove unused dependencies:**\n```bash\ncargo tree  # Identify large dependencies\n```\n\n**3. Use feature flags to exclude optional code:**\n```toml\n[dependencies]\nsolana-program = { version = \"2.1.0\", default-features = false }\n```\n\n**4. Split program into multiple programs:**\n- Separate complex logic into multiple programs\n- Use CPI to communicate between them\n\n### Account Data Too Small for Instruction\n\n**Error:**\n```\nError: account data too small for instruction\n```\n\n**Cause:** Upgrade would exceed allocated program size.\n\n**Solution:**\n```bash\n# Check current size\nsolana program show <PROGRAM_ID>\n# Data Length: 363960 bytes\n\n# Check new size\nNEW_SIZE=$(wc -c < target/deploy/my_program.so)\necho $NEW_SIZE\n# 380000 bytes\n\n# Calculate difference\nDIFF=$((NEW_SIZE - 363960))\n\n# Extend program\nsolana program extend <PROGRAM_ID> $DIFF\n\n# Check rent for extension\nsolana rent $DIFF\n\n# Now deploy upgrade\nsolana program deploy target/deploy/my_program.so --program-id <PROGRAM_ID>\n```\n\n### Network Congestion / Blockhash Expiration\n\n**Error:**\n```\nError: Transaction simulation failed: Blockhash not found\n```\n\n**Cause:** High network congestion or large program deployment.\n\n**Solutions:**\n\n**1. Increase priority fees:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --with-compute-unit-price 300000 \\  # Higher priority\n  --max-sign-attempts 100 \\\n  --use-rpc\n```\n\n**2. Use paid RPC endpoint:**\n```bash\nsolana config set --url https://your-premium-rpc.com\n\n# Paid RPCs often have:\n# - Higher rate limits\n# - Better transaction success rates\n# - Priority queue access\n```\n\n**3. Deploy during low traffic:**\n- Avoid peak hours (US/Europe daytime)\n- Early morning UTC often less congested\n\n**4. Break into smaller chunks:**\n\nFor very large programs, manually create buffer and write in batches.\n\n### Keypair Issues\n\n**Error:**\n```\nError: Dynamic program error: Invalid keypair file\n```\n\n**Solutions:**\n\n**1. Verify keypair format:**\n```bash\n# Should be JSON array of numbers\ncat program-keypair.json\n# [123, 45, 67, ...]\n\n# Or base58 string\n```\n\n**2. Regenerate if corrupted:**\n```bash\nsolana-keygen new -o program-keypair.json --force\n```\n\n**3. Check file permissions:**\n```bash\nchmod 600 program-keypair.json\n```\n\n### Anchor Build vs Deploy Mismatch\n\n**Error:**\n```\nError: Program <ID> does not match declared program id in lib.rs\n```\n\n**Solution:**\n```bash\n# Sync program IDs\nanchor keys sync\n\n# Rebuilds and updates declare_id! to match keypair\n```\n\n### Native Rust: Missing Program ID\n\n**Error:**\n```\nError: No program keypair found\n```\n\n**Solution:**\n\nNative Rust doesn't auto-generate keypairs. Either:\n\n**Option 1: Create keypair:**\n```bash\nsolana-keygen new -o target/deploy/my_program-keypair.json\nsolana program deploy target/deploy/my_program.so \\\n  --program-id target/deploy/my_program-keypair.json\n```\n\n**Option 2: Use existing program ID:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <EXISTING_PROGRAM_ID>\n```\n\n### Verification Failures\n\n**Error:**\n```\nVerification failed: Hash mismatch\nOn-chain: abc123...\nLocal: def456...\n```\n\n**Causes and solutions:**\n\n**1. Built outside Docker:**\n```bash\n# Must use solana-verify build for deterministic build\nsolana-verify build\n```\n\n**2. Cargo.lock mismatch:**\n```bash\n# Ensure Cargo.lock committed to git\ngit add Cargo.lock\ngit commit -m \"Add Cargo.lock for verifiable builds\"\n```\n\n**3. Rebuild after verification:**\n```bash\n# Don't run `anchor build` or `cargo build-sbf` after solana-verify build\n# This regenerates binary with different hash\n\n# If you did, rebuild verifiably:\nsolana-verify build\nsolana program deploy target/deploy/my_program.so --program-id <PROGRAM_ID>\n```\n\n**4. Wrong commit hash:**\n```bash\n# Ensure you're verifying against correct commit\ngit log  # Find exact commit used for deployment\nsolana-verify verify-from-repo \\\n  --commit-hash <EXACT_COMMIT> \\\n  ...\n```\n\n---\n\n## Best Practices\n\n### Deployment Workflow\n\n**Recommended deployment process:**\n\n1. **Local development**\n   - Develop on localnet\n   - Unit test with Mollusk (native) or Bankrun/Anchor tests\n   - Iterate quickly\n\n2. **Devnet testing**\n   - Deploy to devnet\n   - Integration testing\n   - Test upgrade paths\n   - Load testing if applicable\n\n3. **Devnet verification**\n   - Build verifiable\n   - Deploy and verify on devnet\n   - Ensure verification succeeds\n\n4. **Security review**\n   - Internal code review\n   - Automated analysis (Soteria, Sec3, etc.)\n   - Professional audit (for mainnet)\n\n5. **Mainnet staging**\n   - Build final verifiable version\n   - Generate program ID\n   - Set up multisig/governance\n\n6. **Mainnet deployment**\n   - Deploy during low-traffic period\n   - Use paid RPC\n   - Set appropriate priority fees\n   - Monitor closely\n\n7. **Post-deployment**\n   - Submit verification\n   - Smoke test critical functions\n   - Set up monitoring\n   - Transfer authority to multisig\n\n### Version Control\n\n**Always commit:**\n- `Cargo.lock` (required for verified builds)\n- Program keypairs (for test programs only)\n- IDL files\n- Migration scripts\n\n**Never commit:**\n- Mainnet keypairs (use environment variables)\n- Wallet private keys\n- RPC API keys\n\n**Tag deployments:**\n```bash\ngit tag -a v1.0.0-mainnet -m \"Mainnet deployment v1.0.0\"\ngit push origin v1.0.0-mainnet\n```\n\n**Link verification to tags:**\n```bash\nsolana-verify verify-from-repo \\\n  --commit-hash v1.0.0-mainnet \\\n  ...\n```\n\n### Backup Strategies\n\n**Critical to back up:**\n\n1. **Program keypairs**\n   ```bash\n   # Mainnet program keypairs\n   cp target/deploy/my_program-keypair.json ~/secure-backup/\n\n   # Encrypted backup\n   gpg -c target/deploy/my_program-keypair.json\n   ```\n\n2. **Upgrade authority keypairs**\n   ```bash\n   # If not using multisig\n   cp ~/.config/solana/id.json ~/secure-backup/upgrade-authority.json\n   ```\n\n3. **Buffer accounts during deployment**\n   ```bash\n   # Save buffer address immediately after creating\n   echo \"Buffer: <ADDRESS>\" >> deployment-log.txt\n   ```\n\n4. **Deployment artifacts**\n   - Built .so files\n   - IDL files\n   - Verification data\n   - Transaction signatures\n\n**Backup locations:**\n- Encrypted cloud storage (Google Drive, Dropbox)\n- Hardware wallet (for keypairs)\n- Offline USB drives (encrypted)\n- Team password manager (1Password, Bitwarden)\n\n**Test backup restoration:**\n```bash\n# Periodically verify backups work\ncp ~/secure-backup/my_program-keypair.json /tmp/test-restore.json\nsolana-keygen pubkey /tmp/test-restore.json\n# Should output expected program ID\n```\n\n### Framework-Specific Best Practices\n\n**Anchor:**\n- Always run `anchor keys sync` after first build\n- Keep `Anchor.toml` in source control\n- Use workspace for multi-program projects\n- Upload IDL on-chain for discoverability\n- Version your IDL files alongside code\n\n**Native Rust:**\n- Use `no-entrypoint` feature for testing\n- Implement security.txt for contact info\n- Document your instruction format\n- Provide client SDK (TypeScript/Rust) for integrations\n- Include example transaction builders\n\n### Testing Before Deployment\n\n**Progressive testing strategy:**\n\n```bash\n# 1. Unit tests (Mollusk for native, Anchor tests)\ncargo test\n\n# 2. Integration tests on localnet\nanchor test  # or cargo test-sbf\n\n# 3. Devnet deployment test\nanchor deploy --provider.cluster devnet\n# Test all functions on devnet\n\n# 4. Upgrade test on devnet\n# Make small change, rebuild, upgrade\nanchor build\nanchor upgrade <PROGRAM_ID> target/deploy/program.so --provider.cluster devnet\n# Verify upgrade worked\n\n# 5. Verified build test\nsolana-verify build\nsolana-verify verify-from-repo --program-id <DEVNET_ID> https://github.com/...\n\n# 6. Final smoke tests on devnet\n# Run critical user flows\n\n# 7. Mainnet deployment\n# Only after all above pass\n```\n\n### Documentation\n\n**Document your deployment:**\n\nCreate `DEPLOYMENT.md` in your repo:\n\n```markdown\n# Deployment Guide\n\n## Program IDs\n\n- Devnet: ABC123...\n- Mainnet: DEF456...\n\n## Build\n\n```bash\nsolana-verify build --library-name my_program\n```\n\n## Deploy\n\n### Devnet\n```bash\nanchor deploy --provider.cluster devnet\n```\n\n### Mainnet\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 100000\n```\n\n## Verify\n\n```bash\nsolana-verify verify-from-repo \\\n  --remote \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/repo \\\n  --commit-hash v1.0.0\n```\n\n## Upgrade Authority\n\nMainnet: Squads Multisig `GHI789...`\n\n## Last Deployment\n\n- Date: 2025-01-15\n- Version: v1.0.0\n- Commit: abc123def456\n- Deployed by: @deployer\n- Verification: https://verify.osec.io/status/<PROGRAM_ID>\n```\n\n---\n\n## Summary\n\n**Key takeaways:**\n\n1. **Always test on devnet first** - Never deploy untested code to mainnet\n2. **Use verified builds for mainnet** - Transparency builds trust\n3. **Calculate costs before deploying** - Use `solana rent` to estimate\n4. **Set up multisig for mainnet** - Prevents single points of failure\n5. **Monitor after deployment** - Watch for errors and unusual activity\n6. **Back up keypairs** - Lose keypair = lose upgrade authority\n7. **Document your deployments** - Future you will thank you\n8. **Use priority fees on mainnet** - Ensures reliable deployment\n9. **Test upgrade paths** - Practice on devnet first\n10. **Never make programs immutable hastily** - Irreversible decision\n\n**Resources:**\n- Solana CLI docs: https://docs.solana.com/cli\n- Anchor docs: https://www.anchor-lang.com/\n- Solana Verify: https://github.com/Ellipsis-Labs/solana-verifiable-build\n- OtterSec Verify API: https://verify.osec.io/\n- Squads Protocol: https://squads.so/\n- Security.txt: https://github.com/neodyme-labs/solana-security-txt\n\nDeploy with confidence!\n",
        "solana/skills/solana-development/references/durable-nonces.md": "# Durable Transaction Nonces\n\nThis guide covers Solana's durable transaction nonces, which enable transactions to remain valid indefinitely by replacing the time-limited recent blockhash mechanism. Essential for offline signing, multi-signature coordination, and scheduled transaction execution.\n\n## Introduction\n\n### The Expiration Problem\n\nSolana transactions normally include a `recent_blockhash` field that serves two purposes:\n1. **Double-spend prevention**: Ensures each transaction is unique and can only be processed once\n2. **Transaction freshness**: Limits transaction validity to prevent spam and stale transactions\n\n**The limitation:**\n- Recent blockhashes expire after **150 blocks** (~60-90 seconds)\n- Transactions with expired blockhashes are permanently rejected\n- Cannot be re-validated, even with identical content\n\n**Critical constraint:**\n```\nTransaction must be:\n1. Signed with recent blockhash\n2. Submitted to network\n3. Processed by validator\n4. Confirmed in block\n\nAll within ~60-90 seconds!\n```\n\n### Problems This Creates\n\n**Hardware Wallet Users:**\n- Fetch blockhash from network\n- Transfer to air-gapped device\n- User reviews and signs (can take minutes)\n- Transfer back to online device\n- Submit to network\n- **Risk**: Blockhash expires during manual review\n\n**Multi-Signature Wallets (DAOs, Squads, Realms):**\n- Create transaction with blockhash\n- Send to signer 1 for approval (hours/days)\n- Send to signer 2 for approval (hours/days)\n- Send to signer N for approval\n- **Risk**: Blockhash expires while collecting signatures\n\n**Scheduled Transactions:**\n- Want to pre-sign transaction for future execution\n- E.g., vesting unlock, scheduled payment, conditional trade\n- **Risk**: Cannot pre-sign hours/days in advance\n\n**Cross-Chain Bridges:**\n- Wait for finality on source chain (minutes/hours)\n- Sign transaction on destination chain\n- **Risk**: Blockhash expires during cross-chain confirmation\n\n### The Solution: Durable Nonces\n\nDurable nonces replace `recent_blockhash` with a **stored on-chain value** that:\n- ✅ Never expires (remains valid indefinitely)\n- ✅ Changes with each use (prevents replay attacks)\n- ✅ Enables offline signing without time pressure\n- ✅ Supports multi-signature coordination\n- ✅ Allows pre-signing transactions for future execution\n\n**Key insight**: Instead of using the blockchain's recent history (blockhashes) to ensure uniqueness, durable nonces use a **dedicated account** that stores a nonce value and advances it after each transaction.\n\n## How Durable Nonces Work\n\n### Core Mechanism\n\n1. **Nonce Account**: On-chain account (owned by System Program) storing a 32-byte nonce value\n2. **Transaction Structure**: Use nonce value as `recent_blockhash` field\n3. **Nonce Advancement**: First instruction MUST advance the nonce to prevent replay\n4. **Authority Control**: Only nonce authority can advance nonce or authorize transactions\n\n### Transaction Flow\n\n```\nNormal Transaction:\n1. Fetch recent blockhash (expires in 90s)\n2. Build transaction with blockhash\n3. Sign transaction\n4. Submit (must be within 90s)\n5. Process and confirm\n\nDurable Nonce Transaction:\n1. Create nonce account (one-time setup)\n2. Fetch current nonce value (no expiration!)\n3. Build transaction with nonce as blockhash\n4. Add advance_nonce instruction (MUST be first)\n5. Sign transaction (no time pressure)\n6. Submit anytime (minutes, hours, days later)\n7. Process: advances nonce, executes instructions\n```\n\n### Double-Spend Prevention\n\n**Without expiration, how does it prevent double-spending?**\n\nThe nonce value **changes** after each transaction:\n```rust\n// Transaction 1 with nonce value \"ABC123...\"\n{\n    recent_blockhash: \"ABC123...\",  // Current nonce value\n    instructions: [\n        advance_nonce_account(...),  // Changes nonce to \"XYZ789...\"\n        transfer(...),\n    ]\n}\n\n// If you try to submit Transaction 1 again:\n// Runtime checks: Is \"ABC123...\" the current nonce?\n// NO! It's now \"XYZ789...\"\n// Transaction REJECTED (nonce mismatch)\n```\n\n**Critical**: The runtime **always** advances the nonce, even if the transaction fails after the advance instruction. This prevents replay attacks.\n\n## Nonce Account Structure\n\n### Account Layout\n\nNonce accounts are owned by the System Program and have this structure:\n\n```rust\npub struct NonceState {\n    pub version: NonceVersion,\n}\n\npub enum NonceVersion {\n    Legacy(Box<NonceData>),\n    Current(Box<NonceData>),\n}\n\npub struct NonceData {\n    pub authority: Pubkey,         // Who can authorize nonce operations\n    pub durable_nonce: Hash,       // The actual nonce value (32 bytes)\n    pub fee_calculator: FeeCalculator,  // Historic fee data\n}\n```\n\n**Account requirements:**\n- **Owner**: System Program (`11111111111111111111111111111111`)\n- **Size**: 80 bytes\n- **Rent exemption**: Required (minimum ~0.00144768 SOL)\n- **Authority**: Can be any pubkey (keypair or PDA)\n\n### Nonce Authority\n\nThe authority pubkey controls the nonce account:\n- **Can**: Advance nonce, withdraw funds, authorize nonce transactions, change authority\n- **Cannot**: Execute other instructions without nonce advancement (runtime enforces this)\n\n**Authority options:**\n- **Keypair**: Direct control (hot wallet, cold wallet)\n- **PDA**: Program-controlled nonces (advanced use case)\n- **Multisig**: Multiple signers required (DAO wallets)\n\n## Creating Nonce Accounts\n\n### Using Native Rust\n\n```rust\nuse solana_sdk::{\n    instruction::Instruction,\n    pubkey::Pubkey,\n    signature::{Keypair, Signer},\n    system_instruction,\n    sysvar::rent::Rent,\n    transaction::Transaction,\n};\nuse solana_client::rpc_client::RpcClient;\n\nfn create_nonce_account(\n    rpc_client: &RpcClient,\n    payer: &Keypair,\n    nonce_account: &Keypair,\n    authority: &Pubkey,\n) -> Result<(), Box<dyn std::error::Error>> {\n    // Calculate rent-exempt balance for nonce account\n    let rent = rpc_client.get_minimum_balance_for_rent_exemption(80)?;\n\n    // Create account instruction\n    let create_account_ix = system_instruction::create_account(\n        &payer.pubkey(),\n        &nonce_account.pubkey(),\n        rent,                     // Lamports (rent-exempt minimum)\n        80,                       // Space (nonce account size)\n        &solana_program::system_program::id(),  // Owner (System Program)\n    );\n\n    // Initialize nonce instruction\n    let initialize_nonce_ix = system_instruction::initialize_nonce_account(\n        &nonce_account.pubkey(),\n        authority,                // Nonce authority\n    );\n\n    // Build transaction\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let transaction = Transaction::new_signed_with_payer(\n        &[create_account_ix, initialize_nonce_ix],\n        Some(&payer.pubkey()),\n        &[payer, nonce_account],  // Both payer and nonce account must sign\n        recent_blockhash,\n    );\n\n    // Send transaction\n    let signature = rpc_client.send_and_confirm_transaction(&transaction)?;\n    println!(\"Created nonce account: {}\", signature);\n\n    Ok(())\n}\n```\n\n### Single-Step Creation\n\nThere's also a convenience function that combines both steps:\n\n```rust\nlet instruction = system_instruction::create_nonce_account(\n    &payer.pubkey(),\n    &nonce_account.pubkey(),\n    authority,\n    rent_lamports,\n);\n\n// This creates a single instruction that:\n// 1. Creates the account\n// 2. Initializes it as a nonce account\n```\n\n### Using CLI\n\n```bash\n# Generate keypair for nonce account\nsolana-keygen new -o nonce-account.json\n\n# Create nonce account\nsolana create-nonce-account nonce-account.json 0.0015\n\n# Verify creation\nsolana nonce nonce-account.json\n# Output: Current nonce value (32-byte hash)\n```\n\n## Querying Nonce Accounts\n\n### Fetching Nonce Value\n\n```rust\nuse solana_sdk::account::Account;\nuse solana_program::system_program;\n\nfn get_nonce_value(\n    rpc_client: &RpcClient,\n    nonce_pubkey: &Pubkey,\n) -> Result<Hash, Box<dyn std::error::Error>> {\n    // Fetch account data\n    let account = rpc_client.get_account(nonce_pubkey)?;\n\n    // Verify it's a nonce account\n    if account.owner != system_program::id() {\n        return Err(\"Account is not owned by System Program\".into());\n    }\n\n    // Deserialize nonce data\n    let nonce_data = bincode::deserialize::<NonceState>(&account.data)?;\n\n    match nonce_data {\n        NonceState::Current(data) => Ok(data.durable_nonce),\n        NonceState::Legacy(data) => Ok(data.durable_nonce),\n    }\n}\n```\n\n### Parsing Nonce Account\n\n```rust\nuse solana_program::nonce::state::{Data, State};\n\nfn parse_nonce_account(account_data: &[u8]) -> Result<Data, Box<dyn std::error::Error>> {\n    let state: State = bincode::deserialize(account_data)?;\n\n    match state {\n        State::Initialized(data) => Ok(data),\n        State::Uninitialized => Err(\"Nonce account not initialized\".into()),\n    }\n}\n\n// Access nonce components\nfn display_nonce_info(nonce_data: &Data) {\n    println!(\"Authority: {}\", nonce_data.authority);\n    println!(\"Nonce value: {}\", nonce_data.blockhash);\n    println!(\"Fee calculator: {:?}\", nonce_data.fee_calculator);\n}\n```\n\n## Building Transactions with Durable Nonces\n\n### Transaction Structure\n\n**Critical requirements:**\n1. **First instruction** MUST be `advance_nonce_account`\n2. Use nonce value as `recent_blockhash`\n3. Sign with nonce authority (in addition to other required signers)\n\n```rust\nuse solana_sdk::{\n    hash::Hash,\n    instruction::Instruction,\n    message::Message,\n    signature::{Keypair, Signer},\n    system_instruction,\n    transaction::Transaction,\n};\n\nfn build_nonce_transaction(\n    nonce_pubkey: &Pubkey,\n    nonce_authority: &Keypair,\n    nonce_value: Hash,\n    instructions: Vec<Instruction>,\n    payer: &Keypair,\n) -> Transaction {\n    // 1. Create advance_nonce instruction (MUST BE FIRST)\n    let advance_nonce_ix = system_instruction::advance_nonce_account(\n        nonce_pubkey,\n        &nonce_authority.pubkey(),\n    );\n\n    // 2. Combine with your instructions\n    let mut all_instructions = vec![advance_nonce_ix];\n    all_instructions.extend(instructions);\n\n    // 3. Build message with nonce as blockhash\n    let message = Message::new_with_blockhash(\n        &all_instructions,\n        Some(&payer.pubkey()),\n        &nonce_value,  // Use nonce value instead of recent blockhash!\n    );\n\n    // 4. Sign with both payer and nonce authority\n    let mut signers = vec![payer];\n    if nonce_authority.pubkey() != payer.pubkey() {\n        signers.push(nonce_authority);\n    }\n\n    Transaction::new(&signers, message, nonce_value)\n}\n```\n\n### Complete Example: Transfer with Durable Nonce\n\n```rust\nfn transfer_with_nonce(\n    rpc_client: &RpcClient,\n    nonce_account: &Pubkey,\n    nonce_authority: &Keypair,\n    payer: &Keypair,\n    recipient: &Pubkey,\n    amount: u64,\n) -> Result<(), Box<dyn std::error::Error>> {\n    // 1. Fetch current nonce value\n    let nonce_value = get_nonce_value(rpc_client, nonce_account)?;\n\n    // 2. Create transfer instruction\n    let transfer_ix = system_instruction::transfer(\n        &payer.pubkey(),\n        recipient,\n        amount,\n    );\n\n    // 3. Build transaction with nonce\n    let transaction = build_nonce_transaction(\n        nonce_account,\n        nonce_authority,\n        nonce_value,\n        vec![transfer_ix],\n        payer,\n    );\n\n    // 4. Can now submit immediately or store for later\n    // No expiration pressure!\n    let signature = rpc_client.send_and_confirm_transaction(&transaction)?;\n    println!(\"Transfer completed: {}\", signature);\n\n    Ok(())\n}\n```\n\n### Serializing for Offline Signing\n\n```rust\nuse base58::ToBase58;\n\nfn serialize_for_offline_signing(transaction: &Transaction) -> String {\n    // Serialize transaction to bytes\n    let serialized = bincode::serialize(transaction).unwrap();\n\n    // Encode as base58 for transport\n    serialized.to_base58()\n}\n\nfn deserialize_signed_transaction(base58_tx: &str) -> Transaction {\n    use base58::FromBase58;\n\n    let bytes = base58_tx.from_base58().unwrap();\n    bincode::deserialize(&bytes).unwrap()\n}\n```\n\n## Managing Nonce Accounts\n\n### Advancing Nonce\n\n**Automatic advancement**: When you submit a transaction with a durable nonce, the runtime automatically advances the nonce as part of processing the `advance_nonce_account` instruction.\n\n**Manual advancement** (without submitting transaction):\n\n```rust\nfn advance_nonce_manually(\n    rpc_client: &RpcClient,\n    nonce_account: &Pubkey,\n    nonce_authority: &Keypair,\n    payer: &Keypair,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let advance_ix = system_instruction::advance_nonce_account(\n        nonce_account,\n        &nonce_authority.pubkey(),\n    );\n\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let transaction = Transaction::new_signed_with_payer(\n        &[advance_ix],\n        Some(&payer.pubkey()),\n        &[payer, nonce_authority],\n        recent_blockhash,\n    );\n\n    rpc_client.send_and_confirm_transaction(&transaction)?;\n    Ok(())\n}\n```\n\n**When to manually advance:**\n- Before reusing nonce for a new transaction\n- To invalidate a previously signed transaction\n- Regular rotation for security\n\n### Withdrawing from Nonce Account\n\n```rust\nfn withdraw_from_nonce(\n    rpc_client: &RpcClient,\n    nonce_account: &Pubkey,\n    nonce_authority: &Keypair,\n    recipient: &Pubkey,\n    amount: u64,\n    payer: &Keypair,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let withdraw_ix = system_instruction::withdraw_nonce_account(\n        nonce_account,\n        &nonce_authority.pubkey(),\n        recipient,\n        amount,\n    );\n\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let transaction = Transaction::new_signed_with_payer(\n        &[withdraw_ix],\n        Some(&payer.pubkey()),\n        &[payer, nonce_authority],\n        recent_blockhash,\n    );\n\n    rpc_client.send_and_confirm_transaction(&transaction)?;\n    Ok(())\n}\n```\n\n**Important**: Must maintain rent-exempt minimum balance. Can only withdraw to zero if closing the account.\n\n### Changing Nonce Authority\n\n```rust\nfn change_nonce_authority(\n    rpc_client: &RpcClient,\n    nonce_account: &Pubkey,\n    current_authority: &Keypair,\n    new_authority: &Pubkey,\n    payer: &Keypair,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let authorize_ix = system_instruction::authorize_nonce_account(\n        nonce_account,\n        &current_authority.pubkey(),\n        new_authority,\n    );\n\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let transaction = Transaction::new_signed_with_payer(\n        &[authorize_ix],\n        Some(&payer.pubkey()),\n        &[payer, current_authority],\n        recent_blockhash,\n    );\n\n    rpc_client.send_and_confirm_transaction(&transaction)?;\n    Ok(())\n}\n```\n\n**Use cases:**\n- Transfer control to PDA for program-managed nonces\n- Rotate keys for security\n- Transfer to multisig for DAO control\n\n## Offline Signing Workflows\n\n### Hardware Wallet Flow\n\n**Setup (online device):**\n```rust\n// 1. Create nonce account (one-time)\ncreate_nonce_account(&rpc_client, &payer, &nonce_account, &hw_wallet_pubkey)?;\n\n// 2. Fetch nonce value\nlet nonce_value = get_nonce_value(&rpc_client, &nonce_account.pubkey())?;\n\n// 3. Build unsigned transaction\nlet unsigned_tx = build_nonce_transaction(\n    &nonce_account.pubkey(),\n    &hw_wallet_keypair,  // Will be replaced with actual signature\n    nonce_value,\n    vec![transfer_ix],\n    &payer,\n);\n\n// 4. Serialize for hardware wallet\nlet serialized = serialize_for_offline_signing(&unsigned_tx);\n\n// 5. Transfer to hardware wallet (USB, QR code, etc.)\n```\n\n**Signing (air-gapped hardware wallet):**\n```rust\n// 1. Receive serialized transaction\nlet tx = deserialize_signed_transaction(&serialized);\n\n// 2. Display to user for review (no time pressure!)\n// User reviews: recipient, amount, etc.\n\n// 3. Sign with hardware wallet private key\n// (Hardware wallet handles this internally)\n\n// 4. Export signed transaction\nlet signed_serialized = serialize_for_offline_signing(&signed_tx);\n\n// 5. Transfer back to online device\n```\n\n**Submission (online device):**\n```rust\n// 1. Receive signed transaction\nlet signed_tx = deserialize_signed_transaction(&signed_serialized);\n\n// 2. Submit to network (can be hours/days after signing!)\nlet signature = rpc_client.send_and_confirm_transaction(&signed_tx)?;\n```\n\n### Multi-Signature Coordination\n\n**DAO Proposal Execution Flow:**\n\n```rust\n// 1. Proposer creates transaction with nonce\nlet nonce_value = get_nonce_value(&rpc_client, &dao_nonce_account)?;\nlet proposal_tx = build_nonce_transaction(\n    &dao_nonce_account,\n    &dao_authority,  // PDA controlled by governance\n    nonce_value,\n    vec![execute_proposal_ix],\n    &proposer,\n);\n\n// 2. Serialize and store in DAO state\nlet tx_data = bincode::serialize(&proposal_tx)?;\n// Store tx_data in proposal account\n\n// 3. Members vote over time (hours/days)\n// Each vote increments approval count\n\n// 4. When threshold reached, anyone can execute\nlet stored_tx: Transaction = bincode::deserialize(&proposal.tx_data)?;\n\n// 5. Submit (nonce ensures it's still valid!)\nrpc_client.send_and_confirm_transaction(&stored_tx)?;\n```\n\n### CLI Multi-Sig Example\n\n**First co-signer (offline):**\n```bash\nsolana transfer \\\n  --from sender.json \\\n  --sign-only \\\n  --nonce nonce-account.json \\\n  --nonce-authority nonce-authority.json \\\n  --blockhash <NONCE_VALUE> \\\n  --fee-payer co-sender.json \\\n  receiver.json 0.1\n\n# Output:\n# Pubkey=Signature\n# 5nZ8nY5...=4SBv7Xp...\n```\n\n**Second co-signer (online, hours/days later):**\n```bash\nsolana transfer \\\n  --from sender.json \\\n  --nonce nonce-account.json \\\n  --nonce-authority nonce-authority.json \\\n  --blockhash <NONCE_VALUE> \\\n  --fee-payer sender.json \\\n  --signer 5nZ8nY5...=4SBv7Xp... \\\n  receiver.json 0.1\n```\n\n## Security Considerations\n\n### The Neodyme Vulnerability (2020)\n\n**Historic issue**: Before Solana v1.3, there was a critical vulnerability in how durable nonce transactions were processed:\n\n**The bug:**\n1. Transaction with durable nonce starts processing\n2. Runtime advances nonce (changes state)\n3. Later instruction in transaction fails\n4. Runtime rolls back ALL state changes\n5. **BUG**: Nonce advancement was rolled back too!\n6. Attacker could replay the transaction\n\n**The exploit:**\n```rust\n// Malicious transaction:\n{\n    instructions: [\n        advance_nonce(...),        // Advances nonce\n        write_arbitrary_data(...), // Attacker's payload\n        fail_intentionally(...),   // Forces transaction to fail\n    ]\n}\n\n// After rollback:\n// - Nonce reverted to original value\n// - Arbitrary data write WAS NOT rolled back\n// - Can replay transaction infinitely!\n```\n\n**Impact**: Could write arbitrary data to any account by replaying failed transactions.\n\n**Fix** (Solana v1.3+): Nonce advancement is now **permanent** even on transaction failure. The runtime explicitly handles nonce accounts separately from normal rollback logic.\n\n**Lesson**: This demonstrates why nonce advancement MUST happen regardless of transaction success/failure.\n\n### Best Practices\n\n**1. Never reuse nonce without advancing**\n\n```rust\n// BAD: Reusing nonce value\nlet nonce = get_nonce_value(&rpc, &nonce_account)?;\nlet tx1 = build_nonce_transaction(&nonce_account, &auth, nonce, vec![ix1], &payer);\nlet tx2 = build_nonce_transaction(&nonce_account, &auth, nonce, vec![ix2], &payer);\n// If tx1 fails, tx2 might also fail with \"nonce mismatch\"\n\n// GOOD: Advance between uses\nlet nonce1 = get_nonce_value(&rpc, &nonce_account)?;\nlet tx1 = build_nonce_transaction(&nonce_account, &auth, nonce1, vec![ix1], &payer);\nrpc.send_and_confirm_transaction(&tx1)?;\n\n// Fetch fresh nonce (it was advanced)\nlet nonce2 = get_nonce_value(&rpc, &nonce_account)?;\nlet tx2 = build_nonce_transaction(&nonce_account, &auth, nonce2, vec![ix2], &payer);\n```\n\n**2. Protect nonce authority**\n\n```rust\n// Use cold storage for nonce authority\n// OR use PDA with program logic to restrict usage\nlet authority_pda = Pubkey::find_program_address(\n    &[b\"nonce_authority\", dao.key().as_ref()],\n    program_id,\n);\n```\n\n**3. Maintain rent exemption**\n\n```rust\n// Check before withdrawal\nlet nonce_account = rpc.get_account(&nonce_pubkey)?;\nlet rent = rpc.get_minimum_balance_for_rent_exemption(80)?;\n\nif nonce_account.lamports - withdraw_amount < rent {\n    return Err(\"Would violate rent exemption\".into());\n}\n```\n\n**4. Verify nonce advancement in transaction**\n\n```rust\n// In your program that uses nonce transactions:\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    // First account should be nonce account\n    let nonce_account = &accounts[0];\n\n    // Verify it's a valid nonce account\n    if nonce_account.owner != &system_program::id() {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Verify advance_nonce was called\n    // (Runtime enforces this, but you can add checks)\n\n    Ok(())\n}\n```\n\n**5. Monitor nonce account balance**\n\n```rust\n// Periodic check (e.g., daily job)\nfn check_nonce_health(rpc: &RpcClient, nonce: &Pubkey) -> Result<(), String> {\n    let account = rpc.get_account(nonce)\n        .map_err(|_| \"Nonce account not found\")?;\n\n    let rent = rpc.get_minimum_balance_for_rent_exemption(80)\n        .map_err(|_| \"Failed to fetch rent\")?;\n\n    if account.lamports < rent {\n        return Err(format!(\n            \"Nonce account below rent exemption: {} < {}\",\n            account.lamports, rent\n        ));\n    }\n\n    Ok(())\n}\n```\n\n## Use Cases\n\n### 1. Scheduled Payments (Vesting)\n\n```rust\n// Pre-sign monthly vesting releases\nfn create_vesting_schedule(\n    rpc: &RpcClient,\n    nonce_account: &Pubkey,\n    nonce_authority: &Keypair,\n    recipient: &Pubkey,\n    amount_per_month: u64,\n    months: usize,\n) -> Result<Vec<Transaction>, Box<dyn std::error::Error>> {\n    let mut transactions = Vec::new();\n\n    for month in 0..months {\n        // Fetch current nonce\n        let nonce = get_nonce_value(rpc, nonce_account)?;\n\n        // Create transfer\n        let transfer_ix = system_instruction::transfer(\n            &nonce_authority.pubkey(),\n            recipient,\n            amount_per_month,\n        );\n\n        // Build nonce transaction\n        let tx = build_nonce_transaction(\n            nonce_account,\n            nonce_authority,\n            nonce,\n            vec![transfer_ix],\n            nonce_authority,\n        );\n\n        transactions.push(tx);\n\n        // Advance nonce for next month's transaction\n        advance_nonce_manually(rpc, nonce_account, nonce_authority, nonce_authority)?;\n    }\n\n    Ok(transactions)\n}\n\n// Executor submits each month\nfn execute_vesting_payment(\n    rpc: &RpcClient,\n    pre_signed_tx: &Transaction,\n) -> Result<(), Box<dyn std::error::Error>> {\n    // No time pressure - can submit anytime!\n    rpc.send_and_confirm_transaction(pre_signed_tx)?;\n    Ok(())\n}\n```\n\n### 2. Conditional Trades (Limit Orders)\n\n```rust\n// Pre-sign trade execution at specific price\nfn create_limit_order(\n    nonce: &Pubkey,\n    authority: &Keypair,\n    swap_instruction: Instruction,  // Execute when price reached\n) -> Transaction {\n    let nonce_value = /* fetch nonce */;\n\n    build_nonce_transaction(\n        nonce,\n        authority,\n        nonce_value,\n        vec![swap_instruction],\n        authority,\n    )\n}\n\n// Bot monitors price and submits when condition met\nfn execute_limit_order(rpc: &RpcClient, current_price: f64, limit_tx: &Transaction) {\n    if current_price >= target_price {\n        rpc.send_transaction(limit_tx).ok();  // Submit pre-signed transaction\n    }\n}\n```\n\n### 3. Cross-Chain Bridges\n\n```rust\n// Sign Solana transaction while waiting for Ethereum finality\nasync fn bridge_from_ethereum_to_solana(\n    eth_tx_hash: H256,\n    solana_mint_ix: Instruction,\n    nonce_account: &Pubkey,\n    nonce_authority: &Keypair,\n) -> Result<(), Box<dyn std::error::Error>> {\n    // 1. Pre-sign Solana mint transaction\n    let nonce = get_nonce_value(&solana_rpc, nonce_account)?;\n    let mint_tx = build_nonce_transaction(\n        nonce_account,\n        nonce_authority,\n        nonce,\n        vec![solana_mint_ix],\n        nonce_authority,\n    );\n\n    // 2. Wait for Ethereum finality (12+ minutes)\n    wait_for_ethereum_finality(eth_tx_hash).await?;\n\n    // 3. Submit Solana transaction (still valid!)\n    solana_rpc.send_and_confirm_transaction(&mint_tx)?;\n\n    Ok(())\n}\n```\n\n### 4. DAO Governance Execution\n\nAlready covered in multi-sig example above - proposals can be voted on over days/weeks, then executed with pre-signed transaction.\n\n## CLI Reference\n\n**Create nonce account:**\n```bash\nsolana create-nonce-account <KEYPAIR_PATH> <AMOUNT>\n```\n\n**Get current nonce:**\n```bash\nsolana nonce <NONCE_ACCOUNT>\n```\n\n**Manually advance nonce:**\n```bash\nsolana new-nonce <NONCE_ACCOUNT>\n```\n\n**Get nonce account info:**\n```bash\nsolana nonce-account <NONCE_ACCOUNT>\n```\n\n**Withdraw from nonce:**\n```bash\nsolana withdraw-from-nonce-account <NONCE_ACCOUNT> <DESTINATION> <AMOUNT>\n```\n\n**Change nonce authority:**\n```bash\nsolana authorize-nonce-account <NONCE_ACCOUNT> <NEW_AUTHORITY>\n```\n\n**Sign transaction offline:**\n```bash\nsolana <COMMAND> \\\n  --sign-only \\\n  --nonce <NONCE_ACCOUNT> \\\n  --nonce-authority <AUTHORITY_KEYPAIR> \\\n  --blockhash <NONCE_VALUE>\n```\n\n**Submit pre-signed transaction:**\n```bash\nsolana <COMMAND> \\\n  --nonce <NONCE_ACCOUNT> \\\n  --nonce-authority <AUTHORITY_KEYPAIR> \\\n  --blockhash <NONCE_VALUE> \\\n  --signer <PUBKEY=SIGNATURE>\n```\n\n## Limitations and Considerations\n\n**Transaction size:**\n- Adding `advance_nonce_account` instruction adds ~40 bytes\n- May push transaction over size limit if already near maximum\n\n**Extra signature requirement:**\n- Nonce authority must sign (if different from fee payer)\n- Increases transaction complexity\n\n**Rent cost:**\n- Each nonce account requires ~0.0015 SOL rent-exempt minimum\n- For many scheduled transactions, can become expensive\n\n**Nonce advancement overhead:**\n- Compute units to advance nonce (~few hundred CU)\n- Minimal but worth considering for CU-constrained transactions\n\n**Cannot mix recent blockhashes and nonces:**\n- Transaction uses either recent blockhash OR durable nonce\n- Cannot use both in the same transaction\n\n## Resources\n\n### Official Documentation\n- [Introduction to Durable Nonces](https://solana.com/developers/guides/advanced/introduction-to-durable-nonces)\n- [Durable Transaction Nonces Proposal](https://docs.anza.xyz/implemented-proposals/durable-tx-nonces)\n- [CLI Nonce Examples](https://docs.anza.xyz/cli/examples/durable-nonce)\n\n### Code Examples\n- [Durable Nonces Repository](https://github.com/0xproflupin/solana-durable-nonces)\n- [System Program Source](https://github.com/solana-labs/solana/blob/master/sdk/program/src/system_instruction.rs)\n\n### Security Analysis\n- [Neodyme: Nonce Upon a Time](https://neodyme.io/en/blog/nonce-upon-a-time/) - Historic vulnerability analysis\n\n### Technical References\n- [solana-sdk NonceState](https://docs.rs/solana-sdk/latest/solana_sdk/nonce/state/enum.State.html)\n- [System Program Instructions](https://docs.rs/solana-sdk/latest/solana_sdk/system_instruction/)\n",
        "solana/skills/solana-development/references/error-handling.md": "# Error Handling in Solana Programs\n\nThis reference provides comprehensive coverage of error handling patterns for native Rust Solana program development, including custom error types, error propagation, and best practices.\n\n## Table of Contents\n\n1. [Error Handling Fundamentals](#error-handling-fundamentals)\n2. [ProgramError](#programerror)\n3. [Custom Error Types](#custom-error-types)\n4. [Error Propagation](#error-propagation)\n5. [Error Context and Logging](#error-context-and-logging)\n6. [Client-Side Error Handling](#client-side-error-handling)\n7. [Best Practices](#best-practices)\n\n---\n\n## Error Handling Fundamentals\n\n### Why Error Handling Matters\n\n**In Solana programs, errors serve multiple purposes:**\n\n1. **Security:** Prevent invalid state transitions\n2. **User Experience:** Provide meaningful feedback\n3. **Debugging:** Identify issues quickly\n4. **Transaction Validation:** Fail fast when invariants are violated\n\n**Key Principle:** Errors should cause the entire transaction to fail and rollback, maintaining atomicity.\n\n### The Result Type\n\nAll Solana program instructions return `ProgramResult`:\n\n```rust\nuse solana_program::{\n    entrypoint::ProgramResult,\n    program_error::ProgramError,\n};\n\npub type ProgramResult = Result<(), ProgramError>;\n\n// Success\npub fn successful_operation() -> ProgramResult {\n    Ok(())\n}\n\n// Failure\npub fn failed_operation() -> ProgramResult {\n    Err(ProgramError::Custom(42))\n}\n```\n\n**When an instruction returns `Err`:**\n- Transaction fails immediately\n- All state changes rollback\n- Error code returned to client\n- Transaction fee still charged (for processing cost)\n\n---\n\n## ProgramError\n\n### The Built-in Error Type\n\nSolana provides `ProgramError` enum with common error variants:\n\n```rust\nuse solana_program::program_error::ProgramError;\n\npub enum ProgramError {\n    // Common errors\n    Custom(u32),                           // Custom error code\n    InvalidArgument,                       // Invalid instruction argument\n    InvalidInstructionData,                // Failed to deserialize instruction data\n    InvalidAccountData,                    // Invalid account data\n    AccountDataTooSmall,                   // Account data too small\n    InsufficientFunds,                     // Not enough lamports\n    IncorrectProgramId,                    // Wrong program ID\n    MissingRequiredSignature,              // Required signer missing\n    AccountAlreadyInitialized,             // Account already initialized\n    UninitializedAccount,                  // Account not initialized\n    NotEnoughAccountKeys,                  // Not enough accounts provided\n    AccountBorrowFailed,                   // Failed to borrow account data\n    MaxSeedLengthExceeded,                 // PDA seed too long\n    InvalidSeeds,                          // Invalid PDA derivation\n    BorshIoError(String),                  // Borsh serialization error\n    AccountNotRentExempt,                  // Account not rent-exempt\n    IllegalOwner,                          // Wrong account owner\n    ArithmeticOverflow,                    // Arithmetic overflow\n    // ... and more\n}\n```\n\n### Common ProgramError Usage\n\n```rust\nuse solana_program::program_error::ProgramError;\n\npub fn validate_inputs(\n    amount: u64,\n    max_amount: u64,\n) -> ProgramResult {\n    // InvalidArgument: Input doesn't meet requirements\n    if amount == 0 {\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // InsufficientFunds: Not enough balance\n    if amount > max_amount {\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // ArithmeticOverflow: Math operation failed\n    let _result = amount.checked_mul(2)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    Ok(())\n}\n```\n\n---\n\n## Custom Error Types\n\n### Why Custom Errors?\n\n**Built-in `ProgramError` is generic.** Custom errors provide:\n\n- **Specific error codes** for different failure modes\n- **Better debugging** with descriptive messages\n- **Client clarity** - clients know exactly what went wrong\n- **Documentation** - errors serve as API documentation\n\n### Defining Custom Errors\n\nUse the `thiserror` crate to define custom error enums:\n\n```rust\nuse solana_program::program_error::ProgramError;\nuse thiserror::Error;\n\n#[derive(Error, Debug, Copy, Clone)]\npub enum NoteError {\n    #[error(\"You do not own this note\")]\n    Forbidden,\n\n    #[error(\"Note text is too long\")]\n    InvalidLength,\n\n    #[error(\"Rating must be between 1 and 5\")]\n    InvalidRating,\n\n    #[error(\"Note title cannot be empty\")]\n    EmptyTitle,\n\n    #[error(\"Maximum notes limit reached\")]\n    MaxNotesExceeded,\n}\n```\n\n**Attributes explained:**\n- `#[derive(Error)]` - Implements `std::error::Error` trait\n- `#[derive(Debug)]` - Allows `{:?}` formatting\n- `#[derive(Copy, Clone)]` - Makes errors copyable (recommended)\n- `#[error(\"...\")]` - Error message string\n\n### Converting to ProgramError\n\nImplement `From<CustomError> for ProgramError`:\n\n```rust\nimpl From<NoteError> for ProgramError {\n    fn from(e: NoteError) -> Self {\n        ProgramError::Custom(e as u32)\n    }\n}\n```\n\n**How it works:**\n1. Custom error is converted to `u32` (using `as u32` cast)\n2. Wrapped in `ProgramError::Custom(u32)`\n3. Returned to client as error code\n\n**Error code mapping:**\n```rust\nNoteError::Forbidden      → ProgramError::Custom(0)\nNoteError::InvalidLength  → ProgramError::Custom(1)\nNoteError::InvalidRating  → ProgramError::Custom(2)\nNoteError::EmptyTitle     → ProgramError::Custom(3)\nNoteError::MaxNotesExceeded → ProgramError::Custom(4)\n```\n\n### Using Custom Errors\n\n```rust\npub fn create_note(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    title: String,\n    content: String,\n    rating: u8,\n) -> ProgramResult {\n    // Validation with custom errors\n    if title.is_empty() {\n        return Err(NoteError::EmptyTitle.into());\n    }\n\n    if content.len() > 1000 {\n        return Err(NoteError::InvalidLength.into());\n    }\n\n    if rating < 1 || rating > 5 {\n        return Err(NoteError::InvalidRating.into());\n    }\n\n    // Continue processing...\n    Ok(())\n}\n```\n\n**The `.into()` method** automatically converts `NoteError` to `ProgramError`.\n\n### Advanced Custom Error Types\n\n**With additional context:**\n\n```rust\n#[derive(Error, Debug)]\npub enum GameError {\n    #[error(\"Insufficient mana: have {current}, need {required}\")]\n    InsufficientMana { current: u32, required: u32 },\n\n    #[error(\"Invalid move: {0}\")]\n    InvalidMove(String),\n\n    #[error(\"Player not found: {0}\")]\n    PlayerNotFound(String),\n}\n```\n\n**Note:** Errors with fields cannot derive `Copy`, only `Clone`.\n\n---\n\n## Error Propagation\n\n### The `?` Operator\n\nThe `?` operator is Rust's error propagation mechanism:\n\n```rust\npub fn complex_operation(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // If validation fails, error is returned immediately\n    validate_accounts(accounts)?;\n\n    // If deserialization fails, error is propagated\n    let data = AccountData::try_from_slice(&accounts[0].data.borrow())?;\n\n    // If checked math fails, ArithmeticOverflow is returned\n    let result = data.value.checked_add(100)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    Ok(())\n}\n```\n\n**What `?` does:**\n1. If `Result` is `Ok(value)`, unwraps to `value`\n2. If `Result` is `Err(e)`, converts `e` and returns early\n3. Conversion happens via `From` trait\n\n### Error Conversion Chain\n\n```rust\n// Step 1: Borsh deserialization fails\nlet data = MyData::try_from_slice(bytes)?;\n// Returns: Err(std::io::Error)\n\n// Step 2: ? operator converts via From trait\n// std::io::Error → ProgramError::BorshIoError\n\n// Step 3: Custom error conversion\nreturn Err(MyError::InvalidData.into());\n// MyError → ProgramError::Custom(n)\n```\n\n### Manual Error Handling\n\n```rust\n// Without ?\npub fn manual_error_handling(\n    account: &AccountInfo,\n) -> ProgramResult {\n    match validate_account(account) {\n        Ok(()) => {\n            // Continue processing\n        }\n        Err(e) => {\n            msg!(\"Validation failed: {:?}\", e);\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n// With ? (equivalent)\npub fn automatic_error_handling(\n    account: &AccountInfo,\n) -> ProgramResult {\n    validate_account(account)?;\n    Ok(())\n}\n```\n\n### Mapping Errors\n\nTransform one error type to another:\n\n```rust\npub fn map_errors(\n    account: &AccountInfo,\n) -> ProgramResult {\n    // Map generic error to custom error\n    let data = AccountData::try_from_slice(&account.data.borrow())\n        .map_err(|_| NoteError::InvalidLength)?;\n\n    // Map to different ProgramError variant\n    let value = data.amount.checked_add(100)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    Ok(())\n}\n```\n\n### Combining Multiple Operations\n\n```rust\npub fn chain_operations(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // All operations must succeed or transaction fails\n    let account1 = validate_and_load_account(&accounts[0])?;\n    let account2 = validate_and_load_account(&accounts[1])?;\n\n    let combined = account1.value\n        .checked_add(account2.value)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    update_account(&accounts[2], combined)?;\n\n    Ok(())\n}\n```\n\n---\n\n## Error Context and Logging\n\n### Adding Context with `msg!`\n\nUse `msg!` macro to log context before returning errors:\n\n```rust\nuse solana_program::msg;\n\npub fn transfer_tokens(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    if amount == 0 {\n        msg!(\"Transfer amount cannot be zero\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    let from_balance = get_balance(from)?;\n\n    if from_balance < amount {\n        msg!(\"Insufficient balance: have {}, need {}\", from_balance, amount);\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // Perform transfer...\n    Ok(())\n}\n```\n\n### Logging Best Practices\n\n**✅ Good logging:**\n```rust\nmsg!(\"Invalid rating: got {}, expected 1-5\", rating);\nmsg!(\"PDA derivation failed: expected {}, got {}\", expected, actual);\nmsg!(\"Account {} not owned by program {}\", account.key, program_id);\n```\n\n**❌ Poor logging:**\n```rust\nmsg!(\"Error\");  // Not helpful\nmsg!(\"Failed\");  // What failed?\n// (no logging)  // Can't debug issues\n```\n\n### Conditional Logging\n\n```rust\npub fn debug_operation(\n    account: &AccountInfo,\n    debug_mode: bool,\n) -> ProgramResult {\n    if debug_mode {\n        msg!(\"Processing account: {}\", account.key);\n        msg!(\"Owner: {}\", account.owner);\n        msg!(\"Lamports: {}\", account.lamports());\n    }\n\n    // Process...\n    Ok(())\n}\n```\n\n### Error with Recovery\n\n```rust\npub fn try_with_fallback(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // Try primary method\n    match process_primary(accounts) {\n        Ok(()) => {\n            msg!(\"Primary method succeeded\");\n            Ok(())\n        }\n        Err(e) => {\n            msg!(\"Primary method failed: {:?}, trying fallback\", e);\n\n            // Try fallback\n            process_fallback(accounts).map_err(|fallback_err| {\n                msg!(\"Fallback also failed: {:?}\", fallback_err);\n                fallback_err\n            })\n        }\n    }\n}\n```\n\n---\n\n## Client-Side Error Handling\n\n### Error Code Interpretation\n\n**Client receives:**\n```json\n{\n  \"error\": {\n    \"InstructionError\": [\n      0,\n      {\n        \"Custom\": 2\n      }\n    ]\n  }\n}\n```\n\n**Decoding:**\n- Instruction index: `0` (first instruction)\n- Error type: `Custom`\n- Error code: `2`\n\n### TypeScript Error Mapping\n\n```typescript\n// Define error codes matching Rust enum\nenum NoteError {\n    Forbidden = 0,\n    InvalidLength = 1,\n    InvalidRating = 2,\n    EmptyTitle = 3,\n    MaxNotesExceeded = 4,\n}\n\n// Error messages\nconst NOTE_ERROR_MESSAGES = {\n    [NoteError.Forbidden]: \"You do not own this note\",\n    [NoteError.InvalidLength]: \"Note text is too long\",\n    [NoteError.InvalidRating]: \"Rating must be between 1 and 5\",\n    [NoteError.EmptyTitle]: \"Note title cannot be empty\",\n    [NoteError.MaxNotesExceeded]: \"Maximum notes limit reached\",\n};\n\n// Parse error\nfunction parseNoteError(error: any): string {\n    if (error?.InstructionError) {\n        const [_, instructionError] = error.InstructionError;\n\n        if (instructionError?.Custom !== undefined) {\n            const errorCode = instructionError.Custom;\n            return NOTE_ERROR_MESSAGES[errorCode] || `Unknown error: ${errorCode}`;\n        }\n    }\n\n    return \"Transaction failed\";\n}\n\n// Usage\ntry {\n    await program.methods.createNote(title, content, rating).rpc();\n} catch (error) {\n    const message = parseNoteError(error);\n    console.error(message);\n}\n```\n\n### Anchor Error Handling\n\n**With Anchor framework:**\n\n```typescript\nimport { AnchorError } from \"@coral-xyz/anchor\";\n\ntry {\n    await program.methods.createNote(title, content, rating).rpc();\n} catch (error) {\n    if (error instanceof AnchorError) {\n        console.error(\"Error code:\", error.error.errorCode.code);\n        console.error(\"Error message:\", error.error.errorMessage);\n        console.error(\"Error number:\", error.error.errorCode.number);\n    }\n}\n```\n\n---\n\n## Best Practices\n\n### 1. Fail Fast\n\n**Return errors immediately when validation fails:**\n\n```rust\n// ✅ Good - fails fast\npub fn validate_input(rating: u8) -> ProgramResult {\n    if rating < 1 || rating > 5 {\n        return Err(NoteError::InvalidRating.into());\n    }\n\n    // Continue only if valid\n    Ok(())\n}\n\n// ❌ Bad - continues with invalid state\npub fn validate_input_bad(rating: u8) -> ProgramResult {\n    if rating >= 1 && rating <= 5 {\n        // Valid branch\n    }\n    // Continues regardless!\n    Ok(())\n}\n```\n\n### 2. Meaningful Error Messages\n\n```rust\n// ✅ Good - specific and actionable\n#[error(\"Username must be 3-20 characters, got {0}\")]\nInvalidUsernameLength(usize),\n\n#[error(\"Insufficient mana: need {required}, have {current}\")]\nInsufficientMana { required: u32, current: u32 },\n\n// ❌ Bad - vague\n#[error(\"Invalid input\")]\nInvalidInput,\n\n#[error(\"Error\")]\nGenericError,\n```\n\n### 3. Organize Errors by Category\n\n```rust\n#[derive(Error, Debug, Copy, Clone)]\npub enum GameError {\n    // Validation errors (0-99)\n    #[error(\"Invalid player name\")]\n    InvalidPlayerName,\n\n    #[error(\"Invalid move\")]\n    InvalidMove,\n\n    // State errors (100-199)\n    #[error(\"Game not started\")]\n    GameNotStarted,\n\n    #[error(\"Game already finished\")]\n    GameFinished,\n\n    // Resource errors (200-299)\n    #[error(\"Insufficient gold\")]\n    InsufficientGold,\n\n    #[error(\"Inventory full\")]\n    InventoryFull,\n}\n```\n\n### 4. Consistent Error Handling Pattern\n\n```rust\npub fn standard_operation_pattern(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    params: Params,\n) -> ProgramResult {\n    // 1. Parse accounts\n    let account_info_iter = &mut accounts.iter();\n    let user = next_account_info(account_info_iter)?;\n    let data_account = next_account_info(account_info_iter)?;\n\n    // 2. Validate signers\n    if !user.is_signer {\n        msg!(\"User must sign the transaction\");\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // 3. Validate ownership\n    if data_account.owner != program_id {\n        msg!(\"Data account not owned by program\");\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // 4. Validate input parameters\n    if params.amount == 0 {\n        msg!(\"Amount cannot be zero\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // 5. Load and validate account data\n    let mut data = AccountData::try_from_slice(&data_account.data.borrow())?;\n\n    if !data.is_initialized {\n        msg!(\"Account not initialized\");\n        return Err(ProgramError::UninitializedAccount);\n    }\n\n    // 6. Perform operation\n    // ...\n\n    Ok(())\n}\n```\n\n### 5. Document Error Codes\n\n```rust\n/// Error codes for the Note program.\n///\n/// | Code | Error | Description |\n/// |------|-------|-------------|\n/// | 0 | Forbidden | Caller does not own the note |\n/// | 1 | InvalidLength | Note text exceeds maximum length |\n/// | 2 | InvalidRating | Rating not in range 1-5 |\n/// | 3 | EmptyTitle | Note title is empty |\n/// | 4 | MaxNotesExceeded | User has reached note limit |\n#[derive(Error, Debug, Copy, Clone)]\n#[repr(u32)]\npub enum NoteError {\n    #[error(\"You do not own this note\")]\n    Forbidden = 0,\n\n    #[error(\"Note text is too long\")]\n    InvalidLength = 1,\n\n    #[error(\"Rating must be between 1 and 5\")]\n    InvalidRating = 2,\n\n    #[error(\"Note title cannot be empty\")]\n    EmptyTitle = 3,\n\n    #[error(\"Maximum notes limit reached\")]\n    MaxNotesExceeded = 4,\n}\n```\n\n### 6. Error Testing\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_invalid_rating() {\n        let result = validate_rating(0);\n        assert_eq!(\n            result.unwrap_err(),\n            NoteError::InvalidRating.into()\n        );\n\n        let result = validate_rating(6);\n        assert_eq!(\n            result.unwrap_err(),\n            NoteError::InvalidRating.into()\n        );\n    }\n\n    #[test]\n    fn test_valid_rating() {\n        for rating in 1..=5 {\n            assert!(validate_rating(rating).is_ok());\n        }\n    }\n}\n```\n\n### 7. Avoid Silent Failures\n\n```rust\n// ❌ Bad - errors ignored\npub fn bad_error_handling(accounts: &[AccountInfo]) -> ProgramResult {\n    let _ = validate_accounts(accounts);  // Ignores error!\n\n    if let Ok(data) = load_data(accounts) {\n        process(data);  // What if load_data failed?\n    }\n\n    Ok(())  // Returns success even if operations failed!\n}\n\n// ✅ Good - errors propagated\npub fn good_error_handling(accounts: &[AccountInfo]) -> ProgramResult {\n    validate_accounts(accounts)?;\n\n    let data = load_data(accounts)?;\n    process(data)?;\n\n    Ok(())\n}\n```\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **Always return `ProgramResult`** from instruction handlers\n2. **Use custom errors** for specific failure modes\n3. **Implement `From` trait** to convert custom errors to `ProgramError`\n4. **Use `?` operator** for clean error propagation\n5. **Add context with `msg!`** for better debugging\n6. **Fail fast** - return errors immediately\n7. **Document error codes** for client developers\n8. **Test error cases** as thoroughly as success cases\n\n**Error Handling Pattern:**\n\n```rust\nuse solana_program::{\n    entrypoint::ProgramResult,\n    program_error::ProgramError,\n    msg,\n};\nuse thiserror::Error;\n\n// 1. Define custom errors\n#[derive(Error, Debug, Copy, Clone)]\npub enum MyError {\n    #[error(\"Descriptive error message\")]\n    SpecificError,\n}\n\n// 2. Implement From conversion\nimpl From<MyError> for ProgramError {\n    fn from(e: MyError) -> Self {\n        ProgramError::Custom(e as u32)\n    }\n}\n\n// 3. Use in program\npub fn my_instruction(accounts: &[AccountInfo]) -> ProgramResult {\n    // Validate\n    if invalid_condition {\n        msg!(\"Detailed error context\");\n        return Err(MyError::SpecificError.into());\n    }\n\n    // Propagate errors with ?\n    let data = load_data(accounts)?;\n\n    Ok(())\n}\n```\n\n**Remember:** Good error handling is not optional—it's essential for security, debugging, and user experience.\n",
        "solana/skills/solana-development/references/native-rust.md": "# Native Rust Solana Programs Reference\n\nThis reference covers native Rust-specific implementation patterns and workflows for building Solana programs without the Anchor framework. For general concepts (what PDAs/CPIs are), see the other reference files.\n\n## Table of Contents\n\n- [Project Setup](#project-setup)\n- [Entrypoint Patterns](#entrypoint-patterns)\n- [Manual Account Handling](#manual-account-handling)\n- [Manual Serialization](#manual-serialization)\n- [Instruction Definition](#instruction-definition)\n- [State Management](#state-management)\n- [Manual CPI Patterns](#manual-cpi-patterns)\n- [Build and Deploy Workflow](#build-and-deploy-workflow)\n- [Testing with Mollusk](#testing-with-mollusk)\n- [Verified Builds](#verified-builds)\n- [Program Management](#program-management)\n- [Common Native Patterns](#common-native-patterns)\n\n---\n\n## Project Setup\n\n### Cargo.toml Configuration\n\nBasic program configuration:\n\n```toml\n[package]\nname = \"my_program\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\ncrate-type = [\"cdylib\", \"lib\"]  # cdylib for .so, lib for tests\nname = \"my_program\"\n\n[features]\nno-entrypoint = []  # Disable entrypoint for testing/CPI\n\n[dependencies]\nsolana-program = \"2.1.0\"\nborsh = \"1.5.1\"\nborsh-derive = \"1.5.1\"\n\n[dev-dependencies]\nmollusk-svm = \"0.3.0\"\nsolana-sdk = \"2.1.0\"\n\n[profile.release]\noverflow-checks = true\nlto = \"fat\"\ncodegen-units = 1\n\n[profile.release.build-override]\nopt-level = 3\nincremental = false\ncodegen-units = 1\n```\n\n### Dependency Versions\n\n**Production Dependencies:**\n- `solana-program = \"2.1.0\"` - Core program runtime APIs\n- `borsh = \"1.5.1\"` - Serialization framework\n- `borsh-derive = \"1.5.1\"` - Derive macros for Borsh\n\n**Development Dependencies:**\n- `mollusk-svm = \"0.3.0\"` - Fast testing framework\n- `solana-sdk = \"2.1.0\"` - Client-side SDK for tests\n- `mollusk-svm-bencher = \"0.3.0\"` - Compute unit benchmarking\n\n**Optional Helpers:**\n- `thiserror = \"2.0\"` - Error type definitions\n- `num-derive = \"0.4\"` - Derive numeric traits\n- `num-traits = \"0.2\"` - Numeric trait support\n- `spl-token = \"6.0\"` - Token program integration\n- `spl-associated-token-account = \"5.0\"` - ATA integration\n- `bytemuck = \"1.20\"` - Zero-copy type conversions\n\n### Workspace Setup Pattern\n\nFor multi-program projects:\n\n```toml\n# Workspace Cargo.toml\n[workspace]\nmembers = [\n    \"programs/program-one\",\n    \"programs/program-two\",\n]\nresolver = \"2\"\n\n[workspace.dependencies]\nsolana-program = \"2.1.0\"\nborsh = \"1.5.1\"\n\n# Program Cargo.toml\n[dependencies]\nsolana-program = { workspace = true }\nborsh = { workspace = true }\n```\n\n### Project Structure\n\n```\nmy-program/\n├── Cargo.toml\n├── src/\n│   ├── lib.rs              # Entrypoint and routing\n│   ├── instruction.rs      # Instruction definitions\n│   ├── state.rs            # Account state structs\n│   ├── processor.rs        # Instruction handlers\n│   ├── error.rs            # Custom errors\n│   └── utils.rs            # Helper functions\n├── tests/\n│   └── test.rs             # Mollusk tests\n└── target/\n    └── deploy/\n        ├── program.so      # Built program binary\n        └── program-keypair.json  # Program keypair\n```\n\n---\n\n## Entrypoint Patterns\n\n### Basic Entrypoint\n\nThe `entrypoint!` macro sets up the program entry:\n\n```rust\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint,\n    entrypoint::ProgramResult,\n    pubkey::Pubkey,\n};\n\n// Declare the entrypoint\nentrypoint!(process_instruction);\n\n// Process instruction function signature\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    // Route to handlers\n    Ok(())\n}\n```\n\n### Conditional Entrypoint (for testing/CPI)\n\nDisable entrypoint when used as a dependency:\n\n```rust\n#[cfg(not(feature = \"no-entrypoint\"))]\nuse solana_program::entrypoint;\n\n#[cfg(not(feature = \"no-entrypoint\"))]\nentrypoint!(process_instruction);\n\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    // Implementation\n    Ok(())\n}\n```\n\n### Instruction Routing Pattern\n\nRoute to different handlers based on instruction type:\n\n```rust\nuse borsh::BorshDeserialize;\n\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    // Deserialize instruction\n    let instruction = MyInstruction::try_from_slice(instruction_data)?;\n\n    // Route to handler\n    match instruction {\n        MyInstruction::Initialize { data } => {\n            process_initialize(program_id, accounts, data)\n        }\n        MyInstruction::Update { new_data } => {\n            process_update(program_id, accounts, new_data)\n        }\n        MyInstruction::Close => {\n            process_close(program_id, accounts)\n        }\n    }\n}\n```\n\n### Multi-Module Routing\n\nFor larger programs, organize handlers in modules:\n\n```rust\nmod processor;\n\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    let instruction = MyInstruction::try_from_slice(instruction_data)?;\n\n    match instruction {\n        MyInstruction::Initialize { data } => {\n            processor::initialize::process(program_id, accounts, data)\n        }\n        MyInstruction::Update { new_data } => {\n            processor::update::process(program_id, accounts, new_data)\n        }\n        MyInstruction::Close => {\n            processor::close::process(program_id, accounts)\n        }\n    }\n}\n```\n\n---\n\n## Manual Account Handling\n\n### Using next_account_info Iterator\n\nThe standard pattern for accessing accounts:\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n};\n\nfn process_transfer(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    // Get accounts in order\n    let payer = next_account_info(account_info_iter)?;\n    let recipient = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Use accounts...\n    Ok(())\n}\n```\n\n### AccountInfo Structure and Methods\n\nKey fields and methods:\n\n```rust\npub struct AccountInfo<'a> {\n    pub key: &'a Pubkey,              // Account public key\n    pub is_signer: bool,              // Signed transaction?\n    pub is_writable: bool,            // Writable account?\n    pub lamports: Rc<RefCell<&'a mut u64>>,  // Account balance\n    pub data: Rc<RefCell<&'a mut [u8]>>,     // Account data\n    pub owner: &'a Pubkey,            // Owner program\n    pub executable: bool,             // Is executable?\n    pub rent_epoch: Epoch,            // Rent epoch\n}\n\n// Common methods\nimpl<'a> AccountInfo<'a> {\n    // Check if account signed the transaction\n    pub fn is_signer(&self) -> bool;\n\n    // Check if account is writable\n    pub fn is_writable(&self) -> bool;\n\n    // Borrow account data immutably\n    pub fn data(&self) -> Ref<&mut [u8]>;\n\n    // Borrow account data mutably\n    pub fn data_mut(&self) -> RefMut<&mut [u8]>;\n\n    // Borrow lamports immutably\n    pub fn lamports(&self) -> Ref<&mut u64>;\n\n    // Borrow lamports mutably\n    pub fn lamports_mut(&self) -> RefMut<&mut u64>;\n\n    // Get data length\n    pub fn data_len(&self) -> usize;\n\n    // Check if owned by program\n    pub fn is_owned_by(&self, program_id: &Pubkey) -> bool;\n\n    // Deserialize account data\n    pub fn deserialize_data<T: BorshDeserialize>(&self) -> Result<T, Error>;\n\n    // Serialize data into account\n    pub fn serialize_data<T: BorshSerialize>(&self, state: &T) -> Result<(), Error>;\n}\n```\n\n### Explicit Account Validation Patterns\n\n**Signer Check:**\n\n```rust\nif !account.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n```\n\n**Writable Check:**\n\n```rust\nif !account.is_writable {\n    return Err(ProgramError::InvalidAccountData);\n}\n```\n\n**Owner Check:**\n\n```rust\nif account.owner != program_id {\n    return Err(ProgramError::IncorrectProgramId);\n}\n```\n\n**Specific Owner Check:**\n\n```rust\nuse solana_program::system_program;\n\nif account.owner != &system_program::ID {\n    return Err(ProgramError::InvalidAccountOwner);\n}\n```\n\n**Combined Validation:**\n\n```rust\nfn validate_account(\n    account: &AccountInfo,\n    expected_owner: &Pubkey,\n    must_sign: bool,\n    must_write: bool,\n) -> ProgramResult {\n    if must_sign && !account.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    if must_write && !account.is_writable {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    if account.owner != expected_owner {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    Ok(())\n}\n```\n\n**PDA Validation:**\n\n```rust\nfn validate_pda(\n    account: &AccountInfo,\n    seeds: &[&[u8]],\n    program_id: &Pubkey,\n) -> ProgramResult {\n    let (expected_key, _bump) = Pubkey::find_program_address(seeds, program_id);\n\n    if account.key != &expected_key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    Ok(())\n}\n```\n\n**Rent Exemption Check:**\n\n```rust\nuse solana_program::sysvar::{rent::Rent, Sysvar};\n\nfn check_rent_exempt(account: &AccountInfo) -> ProgramResult {\n    let rent = Rent::get()?;\n\n    if !rent.is_exempt(account.lamports(), account.data_len()) {\n        return Err(ProgramError::AccountNotRentExempt);\n    }\n\n    Ok(())\n}\n```\n\n### Account Data Access Patterns\n\n**Immutable Borrow:**\n\n```rust\nlet data = account.data.borrow();\nlet state = MyState::try_from_slice(&data)?;\n```\n\n**Mutable Borrow:**\n\n```rust\nlet mut data = account.data.borrow_mut();\nlet mut state = MyState::try_from_slice(&data)?;\nstate.counter += 1;\nstate.serialize(&mut &mut data[..])?;\n```\n\n**Lamport Access:**\n\n```rust\n// Read lamports\nlet balance = account.lamports();\nprintln!(\"Balance: {}\", *balance);\n\n// Modify lamports (for transfers)\n**account.lamports.borrow_mut() = new_balance;\n```\n\n**Zero-Copy Data Access:**\n\n```rust\nuse bytemuck::{Pod, Zeroable};\n\n#[repr(C)]\n#[derive(Copy, Clone, Pod, Zeroable)]\nstruct FastState {\n    value: u64,\n    flag: u8,\n}\n\nfn read_fast_state(account: &AccountInfo) -> Result<&FastState, ProgramError> {\n    let data = account.try_borrow_data()?;\n    bytemuck::try_from_bytes(&data[..std::mem::size_of::<FastState>()])\n        .map_err(|_| ProgramError::InvalidAccountData)\n}\n```\n\n---\n\n## Manual Serialization\n\n### Borsh Derive\n\nUse `BorshSerialize` and `BorshDeserialize` for most cases:\n\n```rust\nuse borsh::{BorshSerialize, BorshDeserialize};\n\n#[derive(BorshSerialize, BorshDeserialize, Debug)]\npub struct MyState {\n    pub is_initialized: bool,\n    pub counter: u64,\n    pub authority: Pubkey,\n    pub data: Vec<u8>,\n}\n```\n\n### Manual Borsh Implementation\n\nFor custom serialization logic:\n\n```rust\nuse borsh::io::{Read, Write, Result as BorshResult};\n\n#[derive(Debug)]\npub struct CustomState {\n    pub flag: bool,\n    pub value: u64,\n}\n\nimpl BorshSerialize for CustomState {\n    fn serialize<W: Write>(&self, writer: &mut W) -> BorshResult<()> {\n        self.flag.serialize(writer)?;\n        self.value.serialize(writer)?;\n        Ok(())\n    }\n}\n\nimpl BorshDeserialize for CustomState {\n    fn deserialize_reader<R: Read>(reader: &mut R) -> BorshResult<Self> {\n        let flag = bool::deserialize_reader(reader)?;\n        let value = u64::deserialize_reader(reader)?;\n        Ok(Self { flag, value })\n    }\n}\n```\n\n### Account Data Layout Planning\n\nCalculate and document exact byte offsets:\n\n```rust\n// Account layout documentation\n// [0] is_initialized: bool (1 byte)\n// [1-8] counter: u64 (8 bytes)\n// [9-40] authority: Pubkey (32 bytes)\n// Total: 41 bytes\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Counter {\n    pub is_initialized: bool,  // 1 byte\n    pub counter: u64,          // 8 bytes\n    pub authority: Pubkey,     // 32 bytes\n}\n\nimpl Counter {\n    pub const LEN: usize = 1 + 8 + 32;  // 41 bytes\n}\n```\n\n### Packing and Unpacking Account Data\n\n**Deserialize (unpack):**\n\n```rust\nuse borsh::BorshDeserialize;\n\nfn get_state(account: &AccountInfo) -> Result<MyState, ProgramError> {\n    let data = account.try_borrow_data()?;\n    MyState::try_from_slice(&data)\n        .map_err(|_| ProgramError::InvalidAccountData)\n}\n```\n\n**Serialize (pack):**\n\n```rust\nuse borsh::BorshSerialize;\n\nfn save_state(account: &AccountInfo, state: &MyState) -> ProgramResult {\n    let mut data = account.try_borrow_mut_data()?;\n    state.serialize(&mut &mut data[..])\n        .map_err(|_| ProgramError::InvalidAccountData)?;\n    Ok(())\n}\n```\n\n**Combined Pattern:**\n\n```rust\nfn update_counter(account: &AccountInfo, increment: u64) -> ProgramResult {\n    // Deserialize\n    let mut data = account.try_borrow_mut_data()?;\n    let mut state = MyState::try_from_slice(&data)?;\n\n    // Modify\n    state.counter += increment;\n\n    // Serialize back\n    state.serialize(&mut &mut data[..])?;\n    Ok(())\n}\n```\n\n### Zero-Copy Patterns with Bytemuck\n\nFor high-performance, use zero-copy with bytemuck:\n\n```rust\nuse bytemuck::{Pod, Zeroable, from_bytes_mut, bytes_of};\n\n#[repr(C)]\n#[derive(Copy, Clone, Pod, Zeroable)]\npub struct ZeroCopyState {\n    pub is_initialized: u8,  // bool as u8\n    pub counter: u64,\n    pub authority: [u8; 32], // Pubkey as bytes\n}\n\nimpl ZeroCopyState {\n    pub const LEN: usize = std::mem::size_of::<Self>();\n}\n\n// Read zero-copy\nfn get_state(account: &AccountInfo) -> Result<&ZeroCopyState, ProgramError> {\n    let data = account.try_borrow_data()?;\n    bytemuck::try_from_bytes(&data[..ZeroCopyState::LEN])\n        .map_err(|_| ProgramError::InvalidAccountData)\n}\n\n// Write zero-copy\nfn update_state(account: &AccountInfo, new_counter: u64) -> ProgramResult {\n    let mut data = account.try_borrow_mut_data()?;\n    let state = bytemuck::try_from_bytes_mut::<ZeroCopyState>(\n        &mut data[..ZeroCopyState::LEN]\n    ).map_err(|_| ProgramError::InvalidAccountData)?;\n\n    state.counter = new_counter;\n    Ok(())\n}\n```\n\n### Variable-Length Data\n\nFor dynamic data, use a header + data pattern:\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct VarLenState {\n    pub is_initialized: bool,\n    pub data_len: u32,\n    // Followed by data_len bytes\n}\n\nimpl VarLenState {\n    pub const HEADER_LEN: usize = 1 + 4;  // bool + u32\n\n    pub fn unpack(data: &[u8]) -> Result<(Self, &[u8]), ProgramError> {\n        if data.len() < Self::HEADER_LEN {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        let header = Self::try_from_slice(&data[..Self::HEADER_LEN])?;\n        let data_slice = &data[Self::HEADER_LEN..Self::HEADER_LEN + header.data_len as usize];\n\n        Ok((header, data_slice))\n    }\n}\n```\n\n---\n\n## Instruction Definition\n\n### Borsh-Serializable Instruction Enums\n\nDefine instructions as enums:\n\n```rust\nuse borsh::{BorshSerialize, BorshDeserialize};\nuse solana_program::pubkey::Pubkey;\n\n#[derive(BorshSerialize, BorshDeserialize, Debug, Clone)]\npub enum MyInstruction {\n    /// Initialize a new account\n    ///\n    /// Accounts expected:\n    /// 0. `[writable, signer]` Account to initialize\n    /// 1. `[signer]` Authority\n    /// 2. `[]` System Program\n    Initialize {\n        initial_value: u64,\n    },\n\n    /// Update account data\n    ///\n    /// Accounts expected:\n    /// 0. `[writable]` Account to update\n    /// 1. `[signer]` Authority\n    Update {\n        new_value: u64,\n    },\n\n    /// Transfer ownership\n    ///\n    /// Accounts expected:\n    /// 0. `[writable]` Account\n    /// 1. `[signer]` Current authority\n    /// 2. `[]` New authority\n    TransferOwnership {\n        new_authority: Pubkey,\n    },\n\n    /// Close account and reclaim rent\n    ///\n    /// Accounts expected:\n    /// 0. `[writable]` Account to close\n    /// 1. `[writable]` Rent recipient\n    /// 2. `[signer]` Authority\n    Close,\n}\n```\n\n### Instruction Data Layout\n\n**Fixed-Size Instructions:**\n\n```rust\n// Discriminator (1 byte) + data\n// [0] = 0 -> Initialize\n// [1] = 1 -> Update\n// etc.\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub enum SimpleInstruction {\n    Initialize = 0,\n    Update = 1,\n    Close = 2,\n}\n```\n\n**Instructions with Parameters:**\n\n```rust\n// Manual discriminator pattern\npub enum MyInstruction {\n    // Discriminator 0: [0, value_bytes[0..8]]\n    Initialize { value: u64 },\n\n    // Discriminator 1: [1, amount_bytes[0..8]]\n    Transfer { amount: u64 },\n}\n\nimpl MyInstruction {\n    pub fn unpack(input: &[u8]) -> Result<Self, ProgramError> {\n        let (&discriminator, rest) = input.split_first()\n            .ok_or(ProgramError::InvalidInstructionData)?;\n\n        Ok(match discriminator {\n            0 => {\n                let value = u64::from_le_bytes(rest[..8].try_into().unwrap());\n                Self::Initialize { value }\n            }\n            1 => {\n                let amount = u64::from_le_bytes(rest[..8].try_into().unwrap());\n                Self::Transfer { amount }\n            }\n            _ => return Err(ProgramError::InvalidInstructionData),\n        })\n    }\n}\n```\n\n### Dispatching Instructions\n\n**Pattern 1: Direct Match**\n\n```rust\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    let instruction = MyInstruction::try_from_slice(instruction_data)?;\n\n    match instruction {\n        MyInstruction::Initialize { initial_value } => {\n            msg!(\"Instruction: Initialize\");\n            process_initialize(program_id, accounts, initial_value)\n        }\n        MyInstruction::Update { new_value } => {\n            msg!(\"Instruction: Update\");\n            process_update(program_id, accounts, new_value)\n        }\n        MyInstruction::Close => {\n            msg!(\"Instruction: Close\");\n            process_close(program_id, accounts)\n        }\n    }\n}\n```\n\n**Pattern 2: Handler Functions**\n\n```rust\nimpl MyInstruction {\n    pub fn process(\n        &self,\n        program_id: &Pubkey,\n        accounts: &[AccountInfo],\n    ) -> ProgramResult {\n        match self {\n            Self::Initialize { initial_value } => {\n                Self::process_initialize(program_id, accounts, *initial_value)\n            }\n            Self::Update { new_value } => {\n                Self::process_update(program_id, accounts, *new_value)\n            }\n            Self::Close => {\n                Self::process_close(program_id, accounts)\n            }\n        }\n    }\n\n    fn process_initialize(\n        program_id: &Pubkey,\n        accounts: &[AccountInfo],\n        initial_value: u64,\n    ) -> ProgramResult {\n        // Implementation\n        Ok(())\n    }\n}\n```\n\n---\n\n## State Management\n\n### Defining Account State Structs\n\n```rust\nuse borsh::{BorshSerialize, BorshDeserialize};\nuse solana_program::pubkey::Pubkey;\n\n#[derive(BorshSerialize, BorshDeserialize, Debug)]\npub struct UserAccount {\n    pub is_initialized: bool,\n    pub authority: Pubkey,\n    pub balance: u64,\n    pub last_updated: i64,\n}\n\nimpl UserAccount {\n    pub const LEN: usize = 1 + 32 + 8 + 8;  // 49 bytes\n}\n```\n\n### Calculating Account Sizes\n\n**Fixed-Size Accounts:**\n\n```rust\nimpl MyState {\n    // Method 1: Manual calculation\n    pub const LEN: usize =\n        1 +   // is_initialized: bool\n        32 +  // authority: Pubkey\n        8 +   // counter: u64\n        4 +   // data_len: u32\n        100;  // data: [u8; 100]\n\n    // Method 2: Use size_of\n    pub const LEN_ALT: usize = std::mem::size_of::<Self>();\n}\n```\n\n**Variable-Size Accounts:**\n\n```rust\nimpl DynamicState {\n    pub const BASE_LEN: usize = 1 + 32 + 8;  // Fixed fields\n\n    pub fn calculate_size(data_len: usize) -> usize {\n        Self::BASE_LEN + 4 + data_len  // +4 for length prefix\n    }\n}\n```\n\n**With Borsh:**\n\n```rust\nuse borsh::BorshSerialize;\n\nlet state = MyState { /* ... */ };\nlet serialized = state.try_to_vec()?;\nlet size = serialized.len();  // Actual size needed\n```\n\n### Initializing Accounts Manually with System Program CPI\n\n**Complete Initialization Pattern:**\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n    program::invoke,\n    pubkey::Pubkey,\n    rent::Rent,\n    system_instruction,\n    sysvar::Sysvar,\n};\n\nfn process_initialize(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    initial_value: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let new_account = next_account_info(account_info_iter)?;\n    let payer = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Calculate space needed\n    let space = MyState::LEN;\n\n    // Calculate rent\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(space);\n\n    // Create account via CPI to System Program\n    invoke(\n        &system_instruction::create_account(\n            payer.key,           // Funding account\n            new_account.key,     // New account\n            rent_lamports,       // Lamports\n            space as u64,        // Space\n            program_id,          // Owner\n        ),\n        &[\n            payer.clone(),\n            new_account.clone(),\n            system_program.clone(),\n        ],\n    )?;\n\n    // Initialize account data\n    let mut data = new_account.try_borrow_mut_data()?;\n    let state = MyState {\n        is_initialized: true,\n        counter: initial_value,\n        authority: *payer.key,\n    };\n    state.serialize(&mut &mut data[..])?;\n\n    Ok(())\n}\n```\n\n**Initialize PDA Pattern:**\n\n```rust\nuse solana_program::program::invoke_signed;\n\nfn initialize_pda(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let pda = next_account_info(account_info_iter)?;\n    let payer = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Verify PDA\n    let (expected_pda, expected_bump) = Pubkey::find_program_address(seeds, program_id);\n    if pda.key != &expected_pda || bump != expected_bump {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Create PDA account\n    let space = MyState::LEN;\n    let rent = Rent::get()?;\n    let lamports = rent.minimum_balance(space);\n\n    let bump_seed = &[bump];\n    let seeds_with_bump = &[seeds, &[bump_seed.as_slice()]].concat();\n\n    invoke_signed(\n        &system_instruction::create_account(\n            payer.key,\n            pda.key,\n            lamports,\n            space as u64,\n            program_id,\n        ),\n        &[payer.clone(), pda.clone(), system_program.clone()],\n        &[seeds_with_bump],  // Signer seeds\n    )?;\n\n    // Initialize data\n    let mut data = pda.try_borrow_mut_data()?;\n    let state = MyState::default();\n    state.serialize(&mut &mut data[..])?;\n\n    Ok(())\n}\n```\n\n### Account Reallocation\n\nResize account data:\n\n```rust\nuse solana_program::program::invoke;\n\nfn reallocate_account(\n    account: &AccountInfo,\n    payer: &AccountInfo,\n    new_size: usize,\n    program_id: &Pubkey,\n) -> ProgramResult {\n    // Verify ownership\n    if account.owner != program_id {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // Reallocate\n    account.realloc(new_size, false)?;\n\n    // Fund additional rent if needed\n    let rent = Rent::get()?;\n    let new_minimum_balance = rent.minimum_balance(new_size);\n    let current_balance = account.lamports();\n\n    if *current_balance < new_minimum_balance {\n        let additional = new_minimum_balance - *current_balance;\n\n        **payer.lamports.borrow_mut() -= additional;\n        **account.lamports.borrow_mut() += additional;\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Manual CPI Patterns\n\n### Using invoke\n\nFor CPIs without PDA signers:\n\n```rust\nuse solana_program::{\n    account_info::AccountInfo,\n    instruction::{AccountMeta, Instruction},\n    program::invoke,\n    pubkey::Pubkey,\n    system_instruction,\n};\n\nfn transfer_sol(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    invoke(\n        &system_instruction::transfer(from.key, to.key, amount),\n        &[from.clone(), to.clone(), system_program.clone()],\n    )\n}\n```\n\n### Using invoke_signed\n\nFor CPIs with PDA signers:\n\n```rust\nuse solana_program::program::invoke_signed;\n\nfn pda_transfer(\n    pda: &AccountInfo,\n    recipient: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let bump_seed = &[bump];\n    let signer_seeds: &[&[&[u8]]] = &[\n        &[seeds, &[bump_seed]].concat()\n    ];\n\n    invoke_signed(\n        &system_instruction::transfer(pda.key, recipient.key, amount),\n        &[pda.clone(), recipient.clone(), system_program.clone()],\n        signer_seeds,\n    )\n}\n```\n\n### Building AccountMeta Arrays\n\nManually construct account metadata:\n\n```rust\nuse solana_program::instruction::AccountMeta;\n\nlet account_metas = vec![\n    AccountMeta::new(*writable_account.key, false),        // Writable, not signer\n    AccountMeta::new(*writable_signer.key, true),          // Writable, signer\n    AccountMeta::new_readonly(*readonly_account.key, false), // Read-only, not signer\n    AccountMeta::new_readonly(*readonly_signer.key, true),  // Read-only, signer\n];\n```\n\n### Creating Instruction Structs\n\nBuild instructions for CPI:\n\n```rust\nuse solana_program::instruction::Instruction;\n\nfn build_custom_instruction(\n    program_id: &Pubkey,\n    account1: &Pubkey,\n    account2: &Pubkey,\n    data: Vec<u8>,\n) -> Instruction {\n    Instruction {\n        program_id: *program_id,\n        accounts: vec![\n            AccountMeta::new(*account1, true),\n            AccountMeta::new(*account2, false),\n        ],\n        data,\n    }\n}\n\n// Use in CPI\nfn call_custom_program(\n    program: &AccountInfo,\n    account1: &AccountInfo,\n    account2: &AccountInfo,\n    data: Vec<u8>,\n) -> ProgramResult {\n    let instruction = build_custom_instruction(\n        program.key,\n        account1.key,\n        account2.key,\n        data,\n    );\n\n    invoke(\n        &instruction,\n        &[account1.clone(), account2.clone()],\n    )\n}\n```\n\n### SPL Token CPI Pattern\n\nTransfer tokens via CPI:\n\n```rust\nuse spl_token::instruction as token_instruction;\n\nfn transfer_tokens(\n    token_program: &AccountInfo,\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    invoke(\n        &token_instruction::transfer(\n            token_program.key,\n            source.key,\n            destination.key,\n            authority.key,\n            &[],  // No multisig signers\n            amount,\n        )?,\n        &[source.clone(), destination.clone(), authority.clone()],\n    )\n}\n\nfn transfer_tokens_with_pda(\n    token_program: &AccountInfo,\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    pda_authority: &AccountInfo,\n    amount: u64,\n    seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let bump_seed = &[bump];\n    let signer_seeds: &[&[&[u8]]] = &[\n        &[seeds, &[bump_seed]].concat()\n    ];\n\n    invoke_signed(\n        &token_instruction::transfer(\n            token_program.key,\n            source.key,\n            destination.key,\n            pda_authority.key,\n            &[],\n            amount,\n        )?,\n        &[source.clone(), destination.clone(), pda_authority.clone()],\n        signer_seeds,\n    )\n}\n```\n\n---\n\n## Build and Deploy Workflow\n\n### cargo build-sbf Command\n\nBuild the program for Solana:\n\n```bash\n# Basic build\ncargo build-sbf\n\n# Build with specific Solana version\ncargo build-sbf --solana-version 2.1.0\n\n# Build for mainnet (with optimizations)\ncargo build-sbf --release\n\n# Specify output directory\ncargo build-sbf --sbf-out-dir ./output\n```\n\n### Understanding .so and -keypair.json Files\n\nAfter building:\n\n```\ntarget/deploy/\n├── my_program.so              # Compiled program binary\n└── my_program-keypair.json    # Program's keypair (address)\n```\n\n**Program ID:**\n\n```bash\n# Get program ID from keypair\nsolana address -k target/deploy/my_program-keypair.json\n```\n\n**Update Program ID in Code:**\n\n```rust\n// In lib.rs\ndeclare_id!(\"YourProgramID11111111111111111111111111111\");\n```\n\n### solana program deploy Commands\n\n**Deploy to Devnet:**\n\n```bash\n# Set cluster\nsolana config set --url devnet\n\n# Fund deployer account\nsolana airdrop 2\n\n# Deploy program\nsolana program deploy target/deploy/my_program.so\n\n# Deploy to specific program ID\nsolana program deploy \\\n    target/deploy/my_program.so \\\n    --program-id target/deploy/my_program-keypair.json\n\n# Deploy with custom keypair\nsolana program deploy \\\n    target/deploy/my_program.so \\\n    --program-id custom-keypair.json \\\n    --upgrade-authority ~/.config/solana/id.json\n```\n\n**Deploy to Mainnet:**\n\n```bash\nsolana config set --url mainnet-beta\n\n# Deploy (costs SOL based on program size)\nsolana program deploy target/deploy/my_program.so\n```\n\n### Program Size and Cost Calculation\n\n**Check Program Size:**\n\n```bash\nls -lh target/deploy/my_program.so\n\n# Or get detailed info\nsolana program show <PROGRAM_ID>\n```\n\n**Calculate Deployment Cost:**\n\nProgram cost formula: `rent_exemption(program_size)`\n\n```bash\n# Get rent for specific size\nsolana rent <SIZE_IN_BYTES>\n\n# Example for 200KB program\nsolana rent 204800\n# Output: Rent-exempt minimum: 1.42607328 SOL\n```\n\n**Typical Sizes:**\n- Simple programs: 50-100 KB\n- Medium programs: 100-300 KB\n- Large programs: 300-500 KB\n- Maximum: ~1 MB (hard limit)\n\n**Reduce Program Size:**\n\n```toml\n# In Cargo.toml\n[profile.release]\nopt-level = \"z\"        # Optimize for size\nlto = true            # Link-time optimization\ncodegen-units = 1     # Better optimization\nstrip = true          # Strip symbols\n```\n\n---\n\n## Testing with Mollusk\n\n### Test Structure with mollusk-svm\n\nBasic test setup:\n\n```rust\n#[cfg(test)]\nmod tests {\n    use {\n        mollusk_svm::Mollusk,\n        solana_sdk::{\n            account::Account,\n            instruction::{AccountMeta, Instruction},\n            pubkey::Pubkey,\n        },\n    };\n\n    #[test]\n    fn test_initialize() {\n        // Create Mollusk instance\n        let program_id = Pubkey::new_unique();\n        let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n        // Test implementation...\n    }\n}\n```\n\n### Creating Test Accounts\n\n**System-Owned Account:**\n\n```rust\nlet user = Pubkey::new_unique();\nlet user_account = Account {\n    lamports: 1_000_000,\n    data: vec![],\n    owner: solana_sdk::system_program::id(),\n    executable: false,\n    rent_epoch: 0,\n};\n```\n\n**Program-Owned Account:**\n\n```rust\nlet state_account = Pubkey::new_unique();\nlet state = Account {\n    lamports: rent_lamports,\n    data: vec![0; MyState::LEN],\n    owner: program_id,\n    executable: false,\n    rent_epoch: 0,\n};\n```\n\n**Pre-Initialized Account:**\n\n```rust\nuse borsh::BorshSerialize;\n\nlet mut data = vec![0; MyState::LEN];\nlet initial_state = MyState {\n    is_initialized: true,\n    counter: 42,\n    authority: user,\n};\ninitial_state.serialize(&mut data.as_mut_slice()).unwrap();\n\nlet initialized_account = Account {\n    lamports: rent_lamports,\n    data,\n    owner: program_id,\n    executable: false,\n    rent_epoch: 0,\n};\n```\n\n### Process Instructions and Validate Results\n\n**Basic Process and Check:**\n\n```rust\nuse mollusk_svm::result::Check;\n\n#[test]\nfn test_instruction() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let instruction = Instruction::new_with_bytes(\n        program_id,\n        &[0],  // Instruction data\n        vec![\n            AccountMeta::new(user, true),\n        ],\n    );\n\n    let accounts = vec![\n        (user, Account {\n            lamports: 1_000_000,\n            data: vec![],\n            owner: solana_sdk::system_program::id(),\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    let checks = vec![\n        Check::success(),\n        Check::account(&user)\n            .lamports(1_000_000)\n            .build(),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n**Validate Account Data:**\n\n```rust\nlet expected_data = MyState {\n    is_initialized: true,\n    counter: 10,\n    authority: user,\n}.try_to_vec().unwrap();\n\nlet checks = vec![\n    Check::success(),\n    Check::account(&state_account)\n        .data(&expected_data)\n        .lamports(rent_lamports)\n        .owner(&program_id)\n        .build(),\n];\n```\n\n**Check Specific Data Slice:**\n\n```rust\nlet checks = vec![\n    Check::success(),\n    Check::account(&account)\n        .data_slice(0, &[1])  // Check first byte is 1 (initialized)\n        .data_slice(8, &10u64.to_le_bytes())  // Check counter at offset 8\n        .build(),\n];\n```\n\n**Test Error Conditions:**\n\n```rust\nuse solana_sdk::instruction::InstructionError;\n\nlet checks = vec![\n    Check::instruction_err(InstructionError::InvalidInstructionData),\n];\n\nmollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n```\n\n### Compute Unit Benchmarking\n\n**Basic Benchmark:**\n\n```rust\nuse mollusk_svm_bencher::MolluskComputeUnitBencher;\n\nfn main() {\n    let program_id = Pubkey::new_unique();\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let instruction = /* build instruction */;\n    let accounts = /* setup accounts */;\n\n    MolluskComputeUnitBencher::new(mollusk)\n        .bench((\"my_instruction\", &instruction, &accounts))\n        .must_pass(true)\n        .out_dir(\"./benches\")\n        .execute();\n}\n```\n\n**Run Benchmark:**\n\n```bash\n# Build first\ncargo build-sbf\n\n# Run benchmark\ncargo run --bin bench\n```\n\n**Benchmark Output:**\n\n```\n╭──────────────────────────────┬────────────────────╮\n│ Instruction                  │ Compute Units      │\n├──────────────────────────────┼────────────────────┤\n│ my_instruction               │ 1,234              │\n╰──────────────────────────────┴────────────────────╯\n\nResults written to: ./benches/compute_units.json\n```\n\n---\n\n## Verified Builds\n\n### solana-verify Workflow\n\nVerify programs on-chain match source code:\n\n**Install solana-verify:**\n\n```bash\ncargo install solana-verify\n```\n\n**Verify a Program:**\n\n```bash\n# Verify remote build\nsolana-verify verify-from-repo \\\n    --program-id <PROGRAM_ID> \\\n    --remote https://github.com/user/repo \\\n    --commit-hash <COMMIT_HASH> \\\n    --library-name program_name\n\n# Verify with mount path (for workspace)\nsolana-verify verify-from-repo \\\n    --program-id <PROGRAM_ID> \\\n    --remote https://github.com/user/repo \\\n    --commit-hash <COMMIT_HASH> \\\n    --mount-path programs/my-program \\\n    --library-name my_program\n```\n\n### Docker-Based Builds\n\nBuild in Docker for reproducibility:\n\n**Dockerfile:**\n\n```dockerfile\nFROM --platform=linux/amd64 projectserum/build:v0.29.0\n\nWORKDIR /build\nCOPY . .\n\nRUN cargo build-sbf --release\n```\n\n**Build Command:**\n\n```bash\ndocker build -t my-program-build .\ndocker create --name extract my-program-build\ndocker cp extract:/build/target/deploy/my_program.so ./my_program-verifiable.so\ndocker rm extract\n```\n\n**Verify Deterministic:**\n\n```bash\n# Compare hashes\nsha256sum target/deploy/my_program.so\nsha256sum my_program-verifiable.so\n# Should match!\n```\n\n### Buffer Uploads for Multisig\n\nDeploy via buffer for multisig upgrade authority:\n\n```bash\n# Write program to buffer\nsolana program write-buffer target/deploy/my_program.so\n\n# Output: Buffer: <BUFFER_ADDRESS>\n\n# Set buffer authority to multisig\nsolana program set-buffer-authority <BUFFER_ADDRESS> --new-buffer-authority <MULTISIG_ADDRESS>\n\n# Later: Deploy from buffer (requires multisig)\nsolana program deploy --buffer <BUFFER_ADDRESS> --program-id <PROGRAM_ID>\n```\n\n**Squads Multisig Example:**\n\n```bash\n# 1. Write buffer\nBUFFER=$(solana program write-buffer target/deploy/my_program.so | grep \"Buffer:\" | awk '{print $2}')\n\n# 2. Transfer buffer authority to Squads\nsolana program set-buffer-authority $BUFFER --new-buffer-authority <SQUADS_ADDRESS>\n\n# 3. Create proposal in Squads UI to deploy from buffer\n```\n\n---\n\n## Program Management\n\n### solana program show\n\nGet program information:\n\n```bash\n# Show program details\nsolana program show <PROGRAM_ID>\n\n# Output:\n# Program Id: <PROGRAM_ID>\n# Owner: BPFLoaderUpgradeab1e11111111111111111111111\n# ProgramData Address: <DATA_ADDRESS>\n# Authority: <UPGRADE_AUTHORITY>\n# Last Deployed In Slot: 123456789\n# Data Length: 204800 bytes\n# Balance: 1.42607328 SOL\n```\n\n**Show Program Data:**\n\n```bash\n# Get upgrade authority\nsolana program show <PROGRAM_ID> | grep Authority\n\n# Get program size\nsolana program show <PROGRAM_ID> | grep \"Data Length\"\n```\n\n### Authority Transfers\n\n**Transfer Upgrade Authority:**\n\n```bash\n# Transfer to new authority\nsolana program set-upgrade-authority \\\n    <PROGRAM_ID> \\\n    --new-upgrade-authority <NEW_AUTHORITY>\n\n# Transfer to multisig\nsolana program set-upgrade-authority \\\n    <PROGRAM_ID> \\\n    --new-upgrade-authority <MULTISIG_ADDRESS>\n```\n\n### Making Programs Immutable\n\nRemove upgrade authority to make program immutable:\n\n```bash\n# Make immutable (IRREVERSIBLE!)\nsolana program set-upgrade-authority <PROGRAM_ID> --final\n\n# Verify immutability\nsolana program show <PROGRAM_ID>\n# Authority: none\n```\n\n**Warning:** This is permanent. The program can never be upgraded again.\n\n### Closing Programs\n\nReclaim rent from closed programs:\n\n```bash\n# Close program and reclaim rent\nsolana program close <PROGRAM_ID>\n\n# Close and send rent to specific recipient\nsolana program close <PROGRAM_ID> --recipient <RECIPIENT_ADDRESS>\n\n# Close program buffer\nsolana program close --buffers\n```\n\n**Requirements:**\n- Must be upgrade authority\n- Program must not be marked as final\n- Recipient receives all lamports from program account\n\n---\n\n## Common Native Patterns\n\n### PDA Derivation and Signing\n\n**Find PDA:**\n\n```rust\nuse solana_program::pubkey::Pubkey;\n\nfn get_user_pda(user: &Pubkey, program_id: &Pubkey) -> (Pubkey, u8) {\n    Pubkey::find_program_address(\n        &[\n            b\"user\",\n            user.as_ref(),\n        ],\n        program_id,\n    )\n}\n```\n\n**Verify PDA:**\n\n```rust\nfn validate_pda(\n    pda: &AccountInfo,\n    seeds: &[&[u8]],\n    bump: u8,\n    program_id: &Pubkey,\n) -> ProgramResult {\n    let expected_pda = Pubkey::create_program_address(\n        &[seeds, &[&[bump]]].concat(),\n        program_id,\n    )?;\n\n    if pda.key != &expected_pda {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    Ok(())\n}\n```\n\n**Sign with PDA:**\n\n```rust\nuse solana_program::program::invoke_signed;\n\nfn pda_invoke(\n    instruction: &Instruction,\n    accounts: &[AccountInfo],\n    user: &Pubkey,\n    bump: u8,\n) -> ProgramResult {\n    let signer_seeds: &[&[&[u8]]] = &[\n        &[b\"user\", user.as_ref(), &[bump]]\n    ];\n\n    invoke_signed(instruction, accounts, signer_seeds)\n}\n```\n\n### Rent Calculation\n\n**Calculate Minimum Balance:**\n\n```rust\nuse solana_program::{\n    rent::Rent,\n    sysvar::Sysvar,\n};\n\nfn get_rent_exempt_balance(data_len: usize) -> Result<u64, ProgramError> {\n    let rent = Rent::get()?;\n    Ok(rent.minimum_balance(data_len))\n}\n```\n\n**Check if Rent Exempt:**\n\n```rust\nfn is_rent_exempt(account: &AccountInfo) -> Result<bool, ProgramError> {\n    let rent = Rent::get()?;\n    Ok(rent.is_exempt(account.lamports(), account.data_len()))\n}\n```\n\n### Lamport Transfers\n\n**Direct Transfer (modify lamports):**\n\n```rust\nfn transfer_lamports(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    // Borrow and update lamports\n    **from.try_borrow_mut_lamports()? -= amount;\n    **to.try_borrow_mut_lamports()? += amount;\n\n    Ok(())\n}\n```\n\n**Via System Program:**\n\n```rust\nuse solana_program::{\n    program::invoke,\n    system_instruction,\n};\n\nfn transfer_via_system_program(\n    from: &AccountInfo,\n    to: &AccountInfo,\n    system_program: &AccountInfo,\n    amount: u64,\n) -> ProgramResult {\n    invoke(\n        &system_instruction::transfer(from.key, to.key, amount),\n        &[from.clone(), to.clone(), system_program.clone()],\n    )\n}\n```\n\n### Error Handling with ProgramError\n\n**Using Built-in Errors:**\n\n```rust\nuse solana_program::program_error::ProgramError;\n\nif !account.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\nif account.owner != program_id {\n    return Err(ProgramError::IncorrectProgramId);\n}\n\nif account.data_len() < MyState::LEN {\n    return Err(ProgramError::AccountDataTooSmall);\n}\n```\n\n**Custom Errors:**\n\n```rust\nuse solana_program::program_error::ProgramError;\nuse thiserror::Error;\n\n#[derive(Error, Debug, Copy, Clone)]\npub enum MyError {\n    #[error(\"Account already initialized\")]\n    AlreadyInitialized,\n\n    #[error(\"Invalid authority\")]\n    InvalidAuthority,\n\n    #[error(\"Arithmetic overflow\")]\n    Overflow,\n}\n\nimpl From<MyError> for ProgramError {\n    fn from(e: MyError) -> Self {\n        ProgramError::Custom(e as u32)\n    }\n}\n\n// Usage\nif state.is_initialized {\n    return Err(MyError::AlreadyInitialized.into());\n}\n```\n\n**With num_derive:**\n\n```rust\nuse num_derive::FromPrimitive;\nuse num_traits::FromPrimitive;\nuse solana_program::{\n    decode_error::DecodeError,\n    program_error::{PrintProgramError, ProgramError},\n};\nuse thiserror::Error;\n\n#[derive(Clone, Debug, Eq, Error, FromPrimitive, PartialEq)]\npub enum MyError {\n    #[error(\"Already initialized\")]\n    AlreadyInitialized,\n\n    #[error(\"Invalid authority\")]\n    InvalidAuthority,\n}\n\nimpl From<MyError> for ProgramError {\n    fn from(e: MyError) -> Self {\n        ProgramError::Custom(e as u32)\n    }\n}\n\nimpl<T> DecodeError<T> for MyError {\n    fn type_of() -> &'static str {\n        \"MyError\"\n    }\n}\n\nimpl PrintProgramError for MyError {\n    fn print<E>(&self)\n    where\n        E: 'static + std::error::Error + DecodeError<E> + PrintProgramError + FromPrimitive,\n    {\n        match self {\n            MyError::AlreadyInitialized => msg!(\"Error: Already initialized\"),\n            MyError::InvalidAuthority => msg!(\"Error: Invalid authority\"),\n        }\n    }\n}\n```\n\n### Logging and Debugging\n\n**Basic Logging:**\n\n```rust\nuse solana_program::msg;\n\nmsg!(\"Processing instruction\");\nmsg!(\"Counter value: {}\", counter);\nmsg!(\"Account: {}, balance: {}\", account.key, account.lamports());\n```\n\n**Compute Units Logging:**\n\n```rust\nuse solana_program::log::sol_log_compute_units;\n\nsol_log_compute_units();  // Log current compute units used\n```\n\n**Data Logging:**\n\n```rust\nuse solana_program::log::sol_log_data;\n\n// Log data for off-chain processing\nsol_log_data(&[b\"event\", &event_data]);\n```\n\n### Clock Access\n\nGet current timestamp and slot:\n\n```rust\nuse solana_program::{\n    clock::Clock,\n    sysvar::Sysvar,\n};\n\nfn get_current_time() -> Result<i64, ProgramError> {\n    let clock = Clock::get()?;\n    Ok(clock.unix_timestamp)\n}\n\nfn get_current_slot() -> Result<u64, ProgramError> {\n    let clock = Clock::get()?;\n    Ok(clock.slot)\n}\n```\n\n### Account Closure Pattern\n\nProperly close accounts and reclaim rent:\n\n```rust\nfn close_account(\n    account_to_close: &AccountInfo,\n    destination: &AccountInfo,\n) -> ProgramResult {\n    // Transfer all lamports\n    let dest_starting_lamports = destination.lamports();\n    **destination.lamports.borrow_mut() = dest_starting_lamports\n        .checked_add(account_to_close.lamports())\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    **account_to_close.lamports.borrow_mut() = 0;\n\n    // Zero out data\n    let mut data = account_to_close.try_borrow_mut_data()?;\n    data.fill(0);\n\n    Ok(())\n}\n```\n\n### Discriminator Pattern\n\nAdd discriminator to distinguish account types:\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub enum AccountType {\n    Uninitialized,\n    User,\n    Config,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserAccount {\n    pub account_type: AccountType,  // Discriminator\n    pub authority: Pubkey,\n    pub balance: u64,\n}\n\nimpl UserAccount {\n    pub const LEN: usize = 1 + 32 + 8;\n\n    pub fn validate_type(account: &AccountInfo) -> ProgramResult {\n        let data = account.try_borrow_data()?;\n        let account_type = AccountType::try_from_slice(&data[..1])?;\n\n        match account_type {\n            AccountType::User => Ok(()),\n            _ => Err(ProgramError::InvalidAccountData),\n        }\n    }\n}\n```\n\n---\n\n## Additional Resources\n\n- **Solana Program Examples**: https://github.com/solana-developers/program-examples\n- **Mollusk Testing**: https://github.com/anza-xyz/mollusk\n- **solana-program Docs**: https://docs.rs/solana-program\n- **Solana Cookbook**: https://solanacookbook.com/\n- **SPL Token**: https://spl.solana.com/token\n- **Solana Verify**: https://github.com/Ellipsis-Labs/solana-verifiable-build\n\n---\n\n*This reference focuses on native Rust implementation patterns. For conceptual understanding of Solana primitives (PDAs, CPIs, accounts, etc.), see the other reference files in this directory.*\n",
        "solana/skills/solana-development/references/pda.md": "# Program Derived Addresses (PDAs)\n\nThis reference provides comprehensive coverage of Program Derived Addresses (PDAs) for native Rust Solana program development, including derivation mechanics, security implications, and best practices.\n\n## Table of Contents\n\n1. [What are PDAs](#what-are-pdas)\n2. [PDA Derivation Mechanics](#pda-derivation-mechanics)\n3. [Canonical Bump Seeds](#canonical-bump-seeds)\n4. [Creating PDA Accounts](#creating-pda-accounts)\n5. [PDA Signing](#pda-signing)\n6. [Common PDA Patterns](#common-pda-patterns)\n7. [Security Considerations](#security-considerations)\n8. [Best Practices](#best-practices)\n\n---\n\n## What are PDAs\n\n**Program Derived Addresses (PDAs) are deterministic account addresses derived from a program ID and optional seeds.**\n\n### Key Characteristics\n\n1. **Deterministic**: Same inputs always produce the same PDA\n2. **No private key**: PDAs are intentionally off the Ed25519 curve\n3. **Program-signable**: The deriving program can sign for PDAs\n4. **Hashmap-like**: Enable key-value storage patterns on-chain\n\n### Why PDAs Exist\n\nPDAs solve critical problems in Solana program development:\n\n**Problem 1: State Storage**\n- How do you store program state without tracking account addresses?\n- Solution: Derive addresses from user pubkeys + seeds\n\n**Problem 2: Program Signing**\n- How can a program sign transactions without a private key?\n- Solution: Runtime enables programs to sign for their PDAs\n\n**Problem 3: Account Discovery**\n- How do clients find accounts created by programs?\n- Solution: Derive PDAs client-side using known seeds\n\n### PDA vs Regular Account\n\n| Property | Regular Account | PDA |\n|----------|----------------|-----|\n| Address derivation | Random (from keypair) | Deterministic (from seeds) |\n| Has private key | ✅ Yes | ❌ No (off-curve) |\n| Can sign transactions | ✅ Yes (with private key) | ✅ Yes (via program) |\n| Who can sign | Holder of private key | Only the deriving program |\n| Use case | User wallets | Program state storage |\n\n---\n\n## PDA Derivation Mechanics\n\n### How PDAs are Derived\n\nPDAs are created using a hash function that combines:\n1. Program ID\n2. Optional seeds (strings, numbers, pubkeys)\n3. Bump seed (0-255)\n\nThe process intentionally finds an address that falls **off** the Ed25519 elliptic curve.\n\n```\n┌──────────────────────────────────────────────┐\n│ Input Seeds                                  │\n├──────────────────────────────────────────────┤\n│ - Program ID                                 │\n│ - Optional Seed 1 (e.g., \"user_data\")       │\n│ - Optional Seed 2 (e.g., user pubkey)       │\n│ - Bump seed (starts at 255)                 │\n└──────────────────────────────────────────────┘\n                    │\n                    ▼\n         ┌──────────────────────┐\n         │ Hash Function        │\n         │ (SHA256 + checks)    │\n         └──────────────────────┘\n                    │\n                    ▼\n         ┌──────────────────────┐\n         │ Is address off-curve?│\n         └──────────────────────┘\n              │            │\n              │ No         │ Yes\n              ▼            ▼\n    Decrement bump    Return (PDA, bump)\n```\n\n### Native Rust API\n\n```rust\nuse solana_program::pubkey::Pubkey;\n\n// Find PDA with canonical bump\nlet (pda, bump_seed) = Pubkey::find_program_address(\n    &[\n        b\"user_data\",           // Seed 1: static string\n        user_pubkey.as_ref(),   // Seed 2: user's public key\n    ],\n    program_id,\n);\n\n// pda: The derived address (off-curve)\n// bump_seed: The canonical bump (first valid bump found, starting from 255)\n```\n\n### Manual PDA Creation (Advanced)\n\nYou can manually create a PDA with a specific bump using `create_program_address`:\n\n```rust\nuse solana_program::pubkey::Pubkey;\n\n// This may fail if the bump doesn't produce a valid off-curve address\nlet pda = Pubkey::create_program_address(\n    &[\n        b\"user_data\",\n        user_pubkey.as_ref(),\n        &[bump_seed],  // Specific bump\n    ],\n    program_id,\n)?;\n```\n\n**⚠️ Warning:** Only use `create_program_address` when you're certain the bump is valid. Prefer `find_program_address` for safety.\n\n---\n\n## Canonical Bump Seeds\n\n### What is a Canonical Bump?\n\nThe **canonical bump** is the first bump seed (starting from 255, decrementing) that produces a valid off-curve address.\n\n```rust\n// Example: Finding all valid bumps\nfor bump in (0..=255).rev() {\n    if let Ok(pda) = Pubkey::create_program_address(\n        &[b\"data\", user.as_ref(), &[bump]],\n        program_id,\n    ) {\n        println!(\"Bump {}: {}\", bump, pda);\n    }\n}\n\n// Typical output:\n// Bump 255: Error (on-curve)\n// Bump 254: AValidPDAAddress...  ← CANONICAL BUMP\n// Bump 253: AnotherValidPDA...\n// Bump 252: AThirdValidPDA...\n// ...\n```\n\n### Why Use the Canonical Bump?\n\n**Security Reason:** Multiple bumps can derive different valid PDAs for the same seeds. Accepting arbitrary bumps enables PDA substitution attacks.\n\n**Attack Scenario:**\n```rust\n// ❌ Vulnerable - accepts any bump\npub fn update_user_balance(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    bump: u8,  // User provides bump\n) -> ProgramResult {\n    let user = &accounts[0];\n    let user_pda = &accounts[1];\n\n    // Creates PDA with user-provided bump\n    let expected_pda = Pubkey::create_program_address(\n        &[b\"balance\", user.key.as_ref(), &[bump]],\n        program_id,\n    )?;\n\n    // Attacker can provide bump 253 instead of canonical 254\n    // This derives a DIFFERENT PDA the attacker controls!\n    // ...\n}\n```\n\n**Secure Pattern:**\n```rust\n// ✅ Secure - uses canonical bump only\npub fn update_user_balance(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let user_pda = &accounts[1];\n\n    // Derive with canonical bump\n    let (expected_pda, _bump) = Pubkey::find_program_address(\n        &[b\"balance\", user.key.as_ref()],\n        program_id,\n    );\n\n    // Validate\n    if expected_pda != *user_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Safe to proceed\n    // ...\n}\n```\n\n### Storing the Canonical Bump\n\n**Best Practice:** Store the canonical bump in the account data:\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserAccount {\n    pub bump: u8,           // Store canonical bump\n    pub user: Pubkey,\n    pub balance: u64,\n}\n\n// On creation\nlet (pda, bump) = Pubkey::find_program_address(&[b\"user\", user.key.as_ref()], program_id);\nlet account_data = UserAccount {\n    bump,  // Save for future operations\n    user: *user.key,\n    balance: 0,\n};\n```\n\n**Why store it?**\n- Saves compute units on subsequent operations\n- `find_program_address` iterates from 255, costs ~3,000 CU\n- Using stored bump with `create_program_address` costs ~300 CU (10x cheaper!)\n\n---\n\n## Creating PDA Accounts\n\n### Creation Process\n\nPDAs cannot create themselves. Accounts at PDA addresses must be created by:\n1. Invoking the System Program via CPI\n2. Using `invoke_signed` to sign with the PDA\n3. The System Program creates the account and transfers ownership\n\n### Native Rust Pattern\n\n```rust\nuse solana_program::{\n    account_info::{next_account_info, AccountInfo},\n    entrypoint::ProgramResult,\n    program::{invoke_signed},\n    program_error::ProgramError,\n    pubkey::Pubkey,\n    rent::Rent,\n    system_instruction,\n    sysvar::Sysvar,\n};\n\npub fn create_user_account(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    user_id: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let payer = next_account_info(account_info_iter)?;           // Pays for account\n    let user_pda = next_account_info(account_info_iter)?;        // PDA to create\n    let system_program = next_account_info(account_info_iter)?; // System Program\n\n    // Signer check\n    if !payer.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Derive PDA\n    let user_id_bytes = user_id.to_le_bytes();\n    let (pda, bump_seed) = Pubkey::find_program_address(\n        &[b\"user\", payer.key.as_ref(), user_id_bytes.as_ref()],\n        program_id,\n    );\n\n    // Validate provided PDA matches derivation\n    if pda != *user_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Calculate space and rent\n    let account_size: usize = 1 + 32 + 8;  // bump + pubkey + u64\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(account_size);\n\n    // Create account via CPI\n    let create_account_ix = system_instruction::create_account(\n        payer.key,              // Payer\n        user_pda.key,           // New account address (the PDA)\n        rent_lamports,          // Lamports\n        account_size as u64,    // Space\n        program_id,             // Owner (our program)\n    );\n\n    // Sign with PDA using bump seed\n    let signer_seeds: &[&[&[u8]]] = &[&[\n        b\"user\",\n        payer.key.as_ref(),\n        user_id_bytes.as_ref(),\n        &[bump_seed],  // Critical: Include bump in signer seeds\n    ]];\n\n    invoke_signed(\n        &create_account_ix,\n        &[payer.clone(), user_pda.clone(), system_program.clone()],\n        signer_seeds,  // PDA signs here\n    )?;\n\n    // Initialize account data\n    let mut account_data = UserAccount::try_from_slice(&user_pda.data.borrow())?;\n    account_data.bump = bump_seed;\n    account_data.owner = *payer.key;\n    account_data.user_id = user_id;\n    account_data.serialize(&mut &mut user_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\nstruct UserAccount {\n    bump: u8,\n    owner: Pubkey,\n    user_id: u64,\n}\n```\n\n### Key Points\n\n1. **Signer Seeds Format**: `&[&[&[u8]]]` (3 levels of slicing)\n   - Outer: Array of seed sets (for multiple PDAs)\n   - Middle: Single seed set (one PDA)\n   - Inner: Individual seed slices\n\n2. **Bump Must Be Included**: Always append `&[bump_seed]` to signer seeds\n\n3. **System Program Required**: Must pass System Program account for CPI\n\n4. **Ownership Transfer**: Account starts owned by System Program, transfers to your program\n\n---\n\n## PDA Signing\n\n### How Programs Sign for PDAs\n\nWhen a program makes a CPI with `invoke_signed`, the runtime:\n1. Receives the signer seeds\n2. Derives the PDA using seeds + calling program's ID\n3. Verifies the derived PDA matches an account in the instruction\n4. Grants signing authority to that PDA\n\n### invoke_signed vs invoke\n\n```rust\n// invoke: No PDA signing\npub fn invoke(\n    instruction: &Instruction,\n    account_infos: &[AccountInfo],\n) -> ProgramResult\n\n// invoke_signed: With PDA signing\npub fn invoke_signed(\n    instruction: &Instruction,\n    account_infos: &[AccountInfo],\n    signers_seeds: &[&[&[u8]]],  // PDA seeds\n) -> ProgramResult\n```\n\n### Practical Example: PDA Transfers SOL\n\n```rust\npub fn pda_transfer_sol(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let pda_account = next_account_info(account_info_iter)?;\n    let recipient = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Derive PDA and verify\n    let (pda, bump_seed) = Pubkey::find_program_address(\n        &[b\"vault\", recipient.key.as_ref()],\n        program_id,\n    );\n\n    if pda != *pda_account.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Create transfer instruction\n    let transfer_ix = system_instruction::transfer(\n        pda_account.key,  // From: PDA (needs signing!)\n        recipient.key,    // To: recipient\n        amount,\n    );\n\n    // PDA signs the transfer\n    let signer_seeds: &[&[&[u8]]] = &[&[\n        b\"vault\",\n        recipient.key.as_ref(),\n        &[bump_seed],\n    ]];\n\n    invoke_signed(\n        &transfer_ix,\n        &[pda_account.clone(), recipient.clone(), system_program.clone()],\n        signer_seeds,  // Runtime verifies and grants signing authority\n    )?;\n\n    Ok(())\n}\n```\n\n### Multiple PDA Signers\n\nYou can sign with multiple PDAs in a single CPI:\n\n```rust\nlet signer_seeds: &[&[&[u8]]] = &[\n    &[b\"pda1\", &[bump1]],  // First PDA\n    &[b\"pda2\", &[bump2]],  // Second PDA\n];\n\ninvoke_signed(&instruction, &accounts, signer_seeds)?;\n```\n\n---\n\n## Common PDA Patterns\n\n### 1. User-Specific Accounts\n\n**Pattern:** One PDA per user for storing user data.\n\n```rust\n// Seeds: [\"user_data\", user_pubkey]\nlet (user_pda, bump) = Pubkey::find_program_address(\n    &[b\"user_data\", user.key.as_ref()],\n    program_id,\n);\n```\n\n**Use case:** User profiles, balances, inventory\n\n**Advantages:**\n- Easy client-side discovery\n- One account per user\n- User's pubkey acts as unique identifier\n\n### 2. Global State\n\n**Pattern:** Single PDA for program-wide state.\n\n```rust\n// Seeds: [\"global_state\"]\nlet (global_pda, bump) = Pubkey::find_program_address(\n    &[b\"global_state\"],\n    program_id,\n);\n```\n\n**Use case:** Program configuration, global counters, admin settings\n\n**Advantages:**\n- Single source of truth\n- Easy to find (no variable seeds)\n- Reduced account proliferation\n\n### 3. Association Pattern\n\n**Pattern:** PDA associates two entities.\n\n```rust\n// Seeds: [\"escrow\", seller_pubkey, buyer_pubkey]\nlet (escrow_pda, bump) = Pubkey::find_program_address(\n    &[b\"escrow\", seller.key.as_ref(), buyer.key.as_ref()],\n    program_id,\n);\n```\n\n**Use case:** Escrow accounts, peer-to-peer trades, relationships\n\n**Advantages:**\n- Unique per relationship\n- Deterministic discovery\n- Prevents duplicate associations\n\n### 4. Index/Counter Pattern\n\n**Pattern:** PDA with numeric index for multiple instances.\n\n```rust\n// Seeds: [\"note\", author_pubkey, note_id]\nlet note_id: u64 = 42;\nlet (note_pda, bump) = Pubkey::find_program_address(\n    &[b\"note\", author.key.as_ref(), note_id.to_le_bytes().as_ref()],\n    program_id,\n);\n```\n\n**Use case:** Notes, posts, items, sequential data\n\n**Advantages:**\n- Multiple accounts per user\n- Enumerable (iterate by incrementing ID)\n- Scalable\n\n**Implementation:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserState {\n    pub note_count: u64,  // Track next available ID\n}\n\npub fn create_note(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    content: String,\n) -> ProgramResult {\n    let user = &accounts[0];\n    let user_state_pda = &accounts[1];\n    let note_pda = &accounts[2];\n\n    // Load user state\n    let mut user_state = UserState::try_from_slice(&user_state_pda.data.borrow())?;\n\n    // Derive PDA for new note\n    let note_id = user_state.note_count;\n    let (expected_note_pda, bump) = Pubkey::find_program_address(\n        &[b\"note\", user.key.as_ref(), note_id.to_le_bytes().as_ref()],\n        program_id,\n    );\n\n    if expected_note_pda != *note_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Create note account...\n    // Initialize note data...\n\n    // Increment counter\n    user_state.note_count += 1;\n    user_state.serialize(&mut &mut user_state_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n### 5. Vault/Treasury Pattern\n\n**Pattern:** PDA holds funds for the program.\n\n```rust\n// Seeds: [\"vault\"]\nlet (vault_pda, bump) = Pubkey::find_program_address(\n    &[b\"vault\"],\n    program_id,\n);\n```\n\n**Use case:** Staking pools, treasuries, escrow\n\n**Advantages:**\n- Program controls funds\n- No external keypair needed\n- Can't lose \"private key\"\n\n---\n\n## Security Considerations\n\n### 1. Always Validate PDAs\n\n**❌ Vulnerable:**\n```rust\npub fn update_balance(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user_pda = &accounts[0];\n\n    // No PDA validation!\n    let mut user_data = UserData::try_from_slice(&user_pda.data.borrow())?;\n    user_data.balance += 100;\n    user_data.serialize(&mut &mut user_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**✅ Secure:**\n```rust\npub fn update_balance(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let user_pda = &accounts[1];\n\n    // Derive and validate\n    let (expected_pda, _) = Pubkey::find_program_address(\n        &[b\"user\", user.key.as_ref()],\n        program_id,\n    );\n\n    if expected_pda != *user_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Safe to proceed\n    let mut user_data = UserData::try_from_slice(&user_pda.data.borrow())?;\n    user_data.balance += 100;\n    user_data.serialize(&mut &mut user_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n### 2. Non-Canonical Bump Attack\n\n**Vulnerability:** Accepting user-provided bumps allows PDA substitution.\n\n**Impact:** Attacker can manipulate which account is used.\n\n**Prevention:**\n- Always use `find_program_address` (canonical bump)\n- Never accept bump as instruction parameter\n- Store bump in account data after creation\n\n### 3. Seed Confusion\n\n**Vulnerability:** Ambiguous seed ordering can create collisions.\n\n```rust\n// ❌ Problematic - seeds can collide\nlet seed1 = \"hello\";\nlet seed2 = \"world\";\n\n// These derive the SAME PDA:\nPubkey::find_program_address(&[b\"helloworld\"], program_id);\nPubkey::find_program_address(&[b\"hello\", b\"world\"], program_id);\n```\n\n**Prevention:**\n```rust\n// ✅ Use fixed-size types and clear separators\nPubkey::find_program_address(\n    &[\n        b\"prefix_\",        // Fixed prefix\n        user.key.as_ref(), // 32 bytes (fixed)\n        &id.to_le_bytes(), // 8 bytes (fixed)\n    ],\n    program_id,\n);\n```\n\n### 4. Ownership Verification\n\n**Always verify PDA ownership:**\n\n```rust\n// ✅ Check ownership after PDA validation\nif user_pda.owner != program_id {\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\n---\n\n## Best Practices\n\n### 1. Seed Design\n\n**Good Seed Patterns:**\n- Use descriptive prefixes: `b\"user_profile\"`, `b\"escrow\"`, `b\"vault\"`\n- Include entity identifiers: user pubkeys, IDs\n- Use fixed-size types: `u64.to_le_bytes()`, `Pubkey::as_ref()`\n- Maintain logical ordering: most general → most specific\n\n**Example:**\n```rust\n&[\n    b\"note\",               // What type of account\n    author.key.as_ref(),   // Who owns it\n    note_id.to_le_bytes(), // Which instance\n]\n```\n\n### 2. Always Store the Bump\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct PdaAccount {\n    pub bump: u8,  // Always first field for efficiency\n    // ... other fields\n}\n```\n\n**Benefits:**\n- Saves ~2,700 CU per operation\n- Enables efficient re-derivation\n- Documents canonical bump\n\n### 3. Validate Everything\n\n**Security Checklist:**\n- ✅ Derive PDA with canonical bump\n- ✅ Compare derived PDA to provided account\n- ✅ Verify PDA owner is your program\n- ✅ Check initialization status\n- ✅ Validate signer requirements\n\n### 4. Document Your Seed Schema\n\n```rust\n/// Derives a user profile PDA.\n///\n/// Seeds: [\"user_profile\", user_pubkey]\n/// Bump: Stored in account.bump\npub fn derive_user_profile_pda(\n    user: &Pubkey,\n    program_id: &Pubkey,\n) -> (Pubkey, u8) {\n    Pubkey::find_program_address(\n        &[b\"user_profile\", user.as_ref()],\n        program_id,\n    )\n}\n```\n\n### 5. Use Helper Functions\n\n```rust\npub struct PdaDerivation;\n\nimpl PdaDerivation {\n    pub fn user_profile(user: &Pubkey, program_id: &Pubkey) -> (Pubkey, u8) {\n        Pubkey::find_program_address(&[b\"user\", user.as_ref()], program_id)\n    }\n\n    pub fn note(\n        author: &Pubkey,\n        note_id: u64,\n        program_id: &Pubkey,\n    ) -> (Pubkey, u8) {\n        Pubkey::find_program_address(\n            &[b\"note\", author.as_ref(), note_id.to_le_bytes().as_ref()],\n            program_id,\n        )\n    }\n}\n\n// Usage\nlet (user_pda, bump) = PdaDerivation::user_profile(user.key, program_id);\n```\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **PDAs are deterministic addresses** derived from program ID + seeds\n2. **No private key exists** for PDAs (they're off-curve by design)\n3. **Only the deriving program can sign** for its PDAs\n4. **Always use canonical bump** to prevent substitution attacks\n5. **Validate PDAs before use** - never trust client-provided accounts\n6. **Store the bump** in account data for compute efficiency\n7. **Design clear seed schemas** to prevent collisions and confusion\n\n**Security Mantra:**\n```rust\n// Always follow this pattern\nlet (expected_pda, bump) = Pubkey::find_program_address(&seeds, program_id);\nif expected_pda != *provided_pda.key {\n    return Err(ProgramError::InvalidSeeds);\n}\nif provided_pda.owner != program_id {\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\nPDAs are the foundation of state management in Solana programs. Master them, validate them religiously, and your programs will be secure and efficient.\n",
        "solana/skills/solana-development/references/production-deployment.md": "# Production Deployment Guide for Solana Programs\n\n**Best practices for deploying verified, production-ready Solana programs to mainnet and serious devnet environments.**\n\n---\n\n## Overview\n\nProduction deployments require verified builds that prove deployed bytecode matches public source code. This guide covers the proper workflow for production deployments, particularly with Anchor framework.\n\n**Key principle:** Transparency and verifiability build trust. Always use deterministic builds for production.\n\n---\n\n## Why Verified Builds Matter\n\n**Without verified builds:**\n- Users cannot verify deployed code matches GitHub source\n- Audits cannot confirm they reviewed the exact deployed binary\n- No transparency into what code actually runs on-chain\n- Security researchers cannot validate the program\n\n**With verified builds:**\n- ✅ Provably deterministic builds (Docker-based)\n- ✅ Anyone can verify deployed bytecode matches source\n- ✅ Explorer verification badges (Solana Explorer, SolanaFM)\n- ✅ Audit reports apply to exact deployed binary\n- ✅ Standard for all serious Solana projects\n\n**All major Solana protocols use verified builds:** Jupiter, Marinade, Orca, Metaplex, etc.\n\n---\n\n## The Problem with `anchor deploy`\n\n### Anchor 0.32.1 and Earlier\n\n**⚠️ CRITICAL: Do NOT use `anchor deploy` for production deployments**\n\n**Why `anchor deploy` is unsuitable for production:**\n\n1. **Non-deterministic builds**\n   - Build output varies by local Rust version\n   - Different on macOS vs Linux\n   - Depends on installed toolchain\n   - Same source → different binaries on different machines\n\n2. **Cannot be verified**\n   - No way to prove deployed code matches GitHub\n   - Verification tools cannot reproduce the build\n   - Breaks audit trail\n\n3. **Lacks transparency**\n   - Users must trust deployer\n   - No verification badges on explorers\n   - Goes against Solana ecosystem standards\n\n**When Anchor v1 may improve this:**\n- Anchor v1 is expected to have better support for verified builds\n- May integrate `solana-verify` directly\n- Check Anchor docs for updates when v1 releases\n\n**For now (Anchor 0.32.1):** Use the verified deployment workflow below.\n\n---\n\n## Production Deployment Workflow\n\n### Step 1: Build Verifiably\n\nUse `solana-verify build` instead of `anchor build` for the final production build:\n\n```bash\n# Install solana-verify if not already installed\ncargo install solana-verify\n\n# Navigate to project root (where Cargo.toml with workspace is)\ncd my-project\n\n# Build verifiably in Docker (deterministic)\nsolana-verify build --library-name my_program\n\n# Verify the build succeeded\nls -la target/deploy/my_program.so\n```\n\n**What this does:**\n- Builds in Docker container (consistent environment)\n- Uses exact dependencies from `Cargo.lock`\n- Same input → same output (deterministic)\n- Anyone can reproduce this exact binary\n\n**Important:** Do NOT run `anchor build` after `solana-verify build` - it will regenerate a different binary!\n\n### Step 2: Deploy the Verified Binary\n\nUse `solana program deploy` directly (NOT `anchor deploy`):\n\n**For devnet:**\n```bash\nsolana program deploy target/deploy/my_program.so \\\n  --program-id target/deploy/my_program-keypair.json \\\n  -u devnet \\\n  --with-compute-unit-price 1000\n```\n\n**For mainnet:**\n```bash\n# Use your deployer keypair and appropriate priority fees\nsolana program deploy target/deploy/my_program.so \\\n  --program-id target/deploy/my_program-keypair.json \\\n  --keypair ~/.config/solana/deployer.json \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 100000 \\\n  --max-sign-attempts 100 \\\n  --use-rpc\n```\n\n**Why use `solana program deploy` directly:**\n- Works with verified builds\n- More control over deployment parameters\n- Standard across all Solana programs\n- Same tool for Anchor and native Rust\n\n### Step 3: Verify Against Repository\n\nAfter deployment, verify the on-chain program matches your source:\n\n```bash\nsolana-verify verify-from-repo \\\n  -u devnet \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo \\\n  --library-name my_program\n\n# Or specify exact commit\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo \\\n  --commit-hash <COMMIT_HASH> \\\n  --library-name my_program\n```\n\n**When prompted, upload verification data on-chain:**\n```\nWould you like to upload verification data on-chain? (y/n)\n```\n\nSelect **yes** to enable:\n- Verification badge on Solana Explorer\n- OtterSec verification API listing\n- SolanaFM verification display\n\n### Step 4: Verify Hash Match (Sanity Check)\n\nBefore step 3, you can manually verify hashes match:\n\n```bash\n# Get on-chain program hash\nsolana-verify get-program-hash -u devnet <PROGRAM_ID>\n\n# Get local executable hash\nsolana-verify get-executable-hash target/deploy/my_program.so\n\n# These MUST match exactly\n```\n\n---\n\n## Complete Production Deployment Checklist\n\n### Pre-Deployment\n\n- [ ] All tests pass (`cargo test`, `anchor test`)\n- [ ] Security audit completed (for mainnet)\n- [ ] `Cargo.lock` committed to git\n- [ ] Git tag created for release (e.g., `v1.0.0`)\n- [ ] Sufficient SOL in deployer wallet\n- [ ] Multisig or governance ready (mainnet)\n\n### Build\n\n- [ ] Run `solana-verify build --library-name my_program`\n- [ ] Verify `.so` file exists in `target/deploy/`\n- [ ] Do NOT run `anchor build` after this\n- [ ] Get hash: `solana-verify get-executable-hash target/deploy/my_program.so`\n\n### Deploy\n\n- [ ] Use `solana program deploy` (NOT `anchor deploy`)\n- [ ] Specify correct program ID keypair\n- [ ] Use appropriate priority fees\n- [ ] Verify deployment: `solana program show <PROGRAM_ID>`\n\n### Verify\n\n- [ ] Run `solana-verify verify-from-repo` with your GitHub URL\n- [ ] Upload verification data on-chain when prompted\n- [ ] Check verification appears on explorer\n- [ ] Optional: Submit remote verification job\n\n### Post-Deployment\n\n- [ ] Transfer upgrade authority to multisig (mainnet)\n- [ ] Smoke test critical instructions on-chain\n- [ ] Set up monitoring\n- [ ] Announce deployment with verification link\n\n---\n\n## Example: Complete Mainnet Deployment\n\n```bash\n# 1. Prepare\ngit tag v1.0.0\ngit push origin v1.0.0\n\n# 2. Build verifiably\nsolana-verify build --library-name cascade_splits\n\n# 3. Check hash\nsolana-verify get-executable-hash target/deploy/cascade_splits.so\n# Output: abc123def456...\n\n# 4. Deploy to mainnet\nsolana program deploy target/deploy/cascade_splits.so \\\n  --program-id target/deploy/cascade_splits-keypair.json \\\n  --keypair ~/.config/solana/mainnet-deployer.json \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 100000 \\\n  --max-sign-attempts 100 \\\n  --use-rpc\n\n# Output: Program Id: SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB\n\n# 5. Verify on-chain hash matches\nsolana-verify get-program-hash -u mainnet-beta SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB\n# Output: abc123def456... (must match step 3!)\n\n# 6. Verify against repository\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB \\\n  https://github.com/cascade-protocol/splits \\\n  --commit-hash v1.0.0 \\\n  --library-name cascade_splits\n\n# When prompted: Upload verification data on-chain? → YES\n\n# 7. Transfer authority to multisig\nSQUADS_VAULT=\"YourSquadsVaultAddress\"\nsolana program set-upgrade-authority SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB \\\n  --new-upgrade-authority $SQUADS_VAULT\n\n# 8. Verify on explorer\n# Visit: https://explorer.solana.com/address/SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB\n# Should show verification badge\n\n# 9. Check OtterSec verification\n# Visit: https://verify.osec.io/status/SPL1T3rERcu6P6dyBiG7K8LUr21CssZqDAszwANzNMB\n```\n\n---\n\n## Program Upgrades with Verified Builds\n\n### Upgrade Workflow\n\n```bash\n# 1. Make changes, test, commit\ngit add .\ngit commit -m \"feat: add new feature\"\ngit tag v1.1.0\ngit push origin main v1.1.0\n\n# 2. Build verifiably\nsolana-verify build --library-name my_program\n\n# 3. Check if program size increased\nOLD_SIZE=$(solana program show <PROGRAM_ID> | grep \"Data Length\" | awk '{print $3}')\nNEW_SIZE=$(wc -c < target/deploy/my_program.so)\n\n# 4. Extend if needed\nif [ $NEW_SIZE -gt $OLD_SIZE ]; then\n  DIFF=$((NEW_SIZE - OLD_SIZE))\n  solana program extend <PROGRAM_ID> $DIFF\nfi\n\n# 5. Deploy upgrade\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID> \\\n  --upgrade-authority ~/.config/solana/deployer.json \\\n  -u mainnet-beta \\\n  --with-compute-unit-price 100000\n\n# 6. Verify new version\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo \\\n  --commit-hash v1.1.0 \\\n  --library-name my_program\n```\n\n### Upgrades via Multisig\n\nIf upgrade authority is a Squads multisig:\n\n```bash\n# 1. Build verifiably\nsolana-verify build --library-name my_program\n\n# 2. Create buffer (not direct upgrade)\nsolana program write-buffer target/deploy/my_program.so\n# Output: Buffer: <BUFFER_ADDRESS>\n\n# 3. Transfer buffer to multisig\nsolana program set-buffer-authority <BUFFER_ADDRESS> \\\n  --new-buffer-authority <SQUADS_VAULT>\n\n# 4. Create upgrade proposal in Squads UI\n# - Navigate to https://v4.squads.so/\n# - Create transaction for BPF Upgradeable Loader upgrade\n# - Reference buffer address\n# - Get approval from multisig members\n# - Execute\n\n# 5. After execution, verify\nsolana-verify verify-from-repo \\\n  -u mainnet-beta \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo \\\n  --commit-hash v1.1.0 \\\n  --library-name my_program\n```\n\n---\n\n## Troubleshooting\n\n### Hash Mismatch After Deployment\n\n**Problem:** On-chain hash doesn't match local hash\n\n**Causes:**\n1. Ran `anchor build` or `cargo build-sbf` after `solana-verify build`\n2. Deployed wrong file\n3. `Cargo.lock` not committed or out of sync\n\n**Solution:**\n```bash\n# 1. Clean everything\ncargo clean\n\n# 2. Ensure Cargo.lock is committed\ngit add Cargo.lock\ngit commit -m \"Add Cargo.lock\"\n\n# 3. Rebuild verifiably\nsolana-verify build --library-name my_program\n\n# 4. Redeploy\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID>\n\n# 5. Verify again\nsolana-verify verify-from-repo ...\n```\n\n### Verification Fails: \"Could not build from repository\"\n\n**Problem:** `solana-verify verify-from-repo` cannot build\n\n**Causes:**\n1. Missing `Cargo.lock` in repository\n2. Wrong commit hash\n3. Workspace configuration issue\n4. Missing dependencies in Docker build\n\n**Solution:**\n```bash\n# 1. Verify Cargo.lock exists in git\ngit ls-files | grep Cargo.lock\n\n# 2. Check commit hash is correct\ngit log --oneline\n\n# 3. Ensure workspace Cargo.toml exists at root\ncat Cargo.toml  # Should have [workspace]\n\n# 4. Try local verification first\nsolana-verify verify-from-repo \\\n  --program-id <PROGRAM_ID> \\\n  file://$(pwd) \\\n  --library-name my_program\n```\n\n### \"anchor deploy\" Used by Accident\n\n**Problem:** Deployed with `anchor deploy` instead of verified build\n\n**Solution:** Redeploy properly:\n```bash\n# 1. Build verifiably\nsolana-verify build --library-name my_program\n\n# 2. Redeploy (upgrade) with verified binary\nsolana program deploy target/deploy/my_program.so \\\n  --program-id <PROGRAM_ID>\n\n# 3. Verify\nsolana-verify verify-from-repo \\\n  -u <NETWORK> \\\n  --program-id <PROGRAM_ID> \\\n  https://github.com/your-org/your-repo\n```\n\n---\n\n## Version-Specific Notes\n\n### Anchor 0.32.1\n\n- **Status:** Current stable version as of November 2024\n- **Issue:** `anchor deploy` does not produce verifiable builds\n- **Workaround:** Use workflow in this guide (solana-verify + solana program deploy)\n- **Uses:** Solana SDK 2.2.x\n\n### Anchor 0.30.x\n\n- **Status:** Older stable version\n- **Issue:** Same as 0.32.1\n- **Workaround:** Same workflow applies\n- **Uses:** Solana SDK 2.1.x\n\n### Future: Anchor 1.0.0\n\n- **Expected:** Better integration with verified builds\n- **Possible:** `anchor deploy --verifiable` flag\n- **Check:** Official Anchor docs when v1 releases\n- **Until then:** Use this guide\n\n---\n\n## Best Practices Summary\n\n### Always ✅\n\n- Use `solana-verify build` for production builds\n- Commit `Cargo.lock` to git\n- Tag releases with git tags\n- Deploy with `solana program deploy` directly\n- Verify against repository after deployment\n- Upload verification data on-chain\n- Transfer mainnet authority to multisig\n- Test entire flow on devnet first\n\n### Never ❌\n\n- Use `anchor deploy` for production/mainnet\n- Run `anchor build` or `cargo build-sbf` after `solana-verify build`\n- Deploy without verifying\n- Deploy mainnet without devnet testing first\n- Deploy mainnet without security audit\n- Keep upgrade authority as individual wallet (mainnet)\n- Skip uploading verification data\n\n### Development Only\n\n`anchor deploy` is fine for:\n- Local validator testing\n- Rapid iteration during development\n- Devnet experiments\n- Non-production testing\n\n---\n\n## Additional Resources\n\n- **Solana Verify CLI**: https://github.com/Ellipsis-Labs/solana-verifiable-build\n- **Verified Programs List**: https://verify.osec.io/verified-programs\n- **Solana Explorer**: https://explorer.solana.com\n- **Squads Protocol**: https://squads.so\n- **Anchor Documentation**: https://www.anchor-lang.com/docs\n\n---\n\n## Summary\n\n**For production Solana program deployments:**\n\n1. Use `solana-verify build` (NOT `anchor deploy`)\n2. Deploy with `solana program deploy` directly\n3. Verify with `solana-verify verify-from-repo`\n4. Upload verification data on-chain\n\nThis ensures transparency, verifiability, and trust in your deployed programs.\n",
        "solana/skills/solana-development/references/resources.md": "# Development Resources\n\nComprehensive collection of official documentation, development tools, learning paths, and community resources for Solana program development.\n\n## Official Documentation\n\n### Solana Core\n- [Solana Docs](https://solana.com/docs/) - Official Solana documentation\n- [Solana Cookbook](https://solana.com/developers/cookbook) - Recipes for common Solana tasks\n- [Solana Courses](https://solana.com/developers/courses/) - Official learning paths\n- [Program Examples](https://github.com/solana-developers/program-examples) - Multi-framework examples\n- [Developer Bootcamp 2024](https://github.com/solana-developers/developer-bootcamp-2024)\n\n### Anchor Framework\n- [Anchor Docs](https://www.anchor-lang.com/docs) - Official Anchor documentation\n- [Anchor Book](https://book.anchor-lang.com/) - Comprehensive Anchor guide\n- [Anchor by Example](https://examples.anchor-lang.com/) - Example programs\n- [Anchor Lang Docs](https://docs.rs/anchor-lang) - API documentation\n- [Anchor SPL Docs](https://docs.rs/anchor-spl) - SPL integration helpers\n- [Anchor GitHub](https://github.com/coral-xyz/anchor) - Framework source code\n\n### SPL Programs\n- [SPL Documentation](https://spl.solana.com/) - Solana Program Library docs\n- [Token Program](https://github.com/solana-program/token) - SPL Token source\n- [Token-2022](https://github.com/solana-program/token-2022) - Next-gen token program\n- [Associated Token Account](https://github.com/solana-program/associated-token-account)\n- [Token Metadata](https://github.com/solana-program/token-metadata)\n- [Metaplex Token Metadata](https://github.com/metaplex-foundation/mpl-token-metadata)\n\n## Example Programs\n\n### Official Examples\n- [Program Examples](https://github.com/solana-developers/program-examples) - Comprehensive examples in multiple frameworks\n- [Anchor Examples](https://github.com/coral-xyz/anchor/tree/master/tests) - Official Anchor test programs\n- [Developer Bootcamp](https://github.com/solana-developers/developer-bootcamp-2024) - Workshop materials\n\n### Production Protocols (for studying)\n- [Anchor Framework](https://github.com/coral-xyz/anchor) - The framework source itself\n- [Raydium AMM](https://github.com/raydium-io/raydium-cp-swap) - DEX protocol example\n- [Kamino Lending](https://github.com/Kamino-Finance/klend) - Lending protocol\n- [Squads Multisig](https://github.com/Squads-Protocol/v4) - Multisig protocol\n\n## Development Tools\n\n### IDEs & Playgrounds\n- [Solana Playground](https://beta.solpg.io/) - Browser-based IDE for Solana programs\n- [Anchor Playground](https://www.anchor-lang.com/playground) - Test Anchor programs online\n- [Rust Playground](https://play.rust-lang.org/) - Test Rust snippets\n\n### CLI & Tooling\n- [Solana CLI](https://docs.solana.com/cli) - Command-line tools reference\n- [Anchor CLI](https://www.anchor-lang.com/docs/cli) - Anchor command reference\n- [Solana Explorer](https://explorer.solana.com/) - View transactions and accounts\n- [Solana FM](https://solana.fm/) - Alternative explorer with better UX\n- [Solscan](https://solscan.io/) - Popular block explorer\n- [XRAY](https://xray.helius.dev/) - Transaction viewer by Helius\n\n### Testing Frameworks\n- [Mollusk](https://github.com/anza-xyz/mollusk) - Lightweight test harness for SVM programs\n- [Mollusk Docs](https://solana.com/docs/programs/testing/mollusk) - Official Mollusk documentation\n- [Solana Test Validator](https://docs.solana.com/developing/test-validator) - Local validator for testing\n- [Anchor Testing](https://book.anchor-lang.com/anchor_in_depth/testing.html) - Anchor test framework\n\n### Deployment & Verification\n- [Solana Verify](https://github.com/Ellipsis-Labs/solana-verifiable-build) - Verifiable builds\n- [Verified Builds Docs](https://solana.com/docs/programs/verified-builds) - Official guide\n\n## Learning Paths\n\n### Official Courses\n- [Native Rust Development](https://solana.com/developers/courses/native-onchain-development) - Build with native Rust\n- [Anchor Development](https://solana.com/developers/courses/onchain-development) - Build with Anchor\n- [Program Security](https://solana.com/developers/courses/program-security) - Security fundamentals\n\n### Community Tutorials\n- [RareSkills Solana Course](https://www.rareskills.io/solana-tutorial) - Comprehensive course for EVM developers\n- [Anchor for EVM Developers](https://0xkowloon.gitbook.io/anchor-for-evm-developers) - Quick Anchor intro\n- [Ackee Solana Handbook](https://ackee.xyz/solana/book/latest/) - Development guide\n\n### Rust Learning\n- [Rust Book](https://doc.rust-lang.org/book/) - Official Rust programming language book\n- [Rust by Example](https://doc.rust-lang.org/rust-by-example/) - Learn Rust through examples\n\n### Advanced Topics\n- [Solana Architecture](https://docs.solana.com/cluster/overview) - How Solana works\n- [Sealevel Runtime](https://docs.solana.com/developing/programming-model/overview) - SVM execution model\n- [Account Model](https://solana.com/docs/core/accounts) - Deep dive into accounts\n\n## Community & Support\n\n### Q&A Platforms\n- [Solana Stack Exchange](https://solana.stackexchange.com/) - Q&A for Solana development\n- [Anchor Discussions](https://github.com/coral-xyz/anchor/discussions) - GitHub discussions\n\n### Chat & Forums\n- [Solana Discord](https://discord.gg/solana) - Official Solana community\n- [Anchor Discord](https://discord.gg/srmqvxf) - Anchor-specific support\n- [Solana Tech Discord](https://discord.gg/solana) - Technical discussions\n\n### Blogs & Newsletters\n- [Helius Blog](https://www.helius.dev/blog) - Frequent Solana developer content\n- [Solana Foundation Blog](https://solana.com/news) - Official updates\n- [Pine Analytics Substack](https://substack.com/@pineanalytics1) - Protocol deep dives\n\n## Developer Tools & Libraries\n\n### Rust Crates\n- [solana-program](https://docs.rs/solana-program) - Core program library\n- [anchor-lang](https://docs.rs/anchor-lang) - Anchor framework\n- [anchor-spl](https://docs.rs/anchor-spl) - SPL token integration\n- [borsh](https://docs.rs/borsh) - Binary serialization\n- [spl-token](https://docs.rs/spl-token) - Token program library\n- [spl-token-2022](https://docs.rs/spl-token-2022) - Token Extensions program\n\n### TypeScript/JavaScript\n- [@solana/web3.js](https://solana-labs.github.io/solana-web3.js/) - Solana JavaScript SDK\n- [@coral-xyz/anchor](https://www.npmjs.com/package/@coral-xyz/anchor) - Anchor TypeScript client\n- [@solana/spl-token](https://www.npmjs.com/package/@solana/spl-token) - SPL Token JS library\n- [Umi Framework](https://github.com/metaplex-foundation/umi) - Modular framework by Metaplex\n\n### Python\n- [solana-py](https://github.com/michaelhly/solana-py) - Solana Python SDK\n- [anchorpy](https://github.com/kevinheavey/anchorpy) - Anchor Python client\n\n## RPC Providers\n\n### Free Tier Available\n- [Helius](https://www.helius.dev/) - Developer-friendly RPC with generous free tier\n- [QuickNode](https://www.quicknode.com/) - Global RPC network\n- [Alchemy](https://www.alchemy.com/solana) - RPC with enhanced APIs\n- [Triton](https://triton.one/) - High-performance RPC\n- [Public RPC Endpoints](https://docs.solana.com/cluster/rpc-endpoints) - Free public endpoints\n\n## Developer Communities\n\n### Learning Communities\n- [Solana Developers](https://github.com/solana-developers) - Official developer org\n- [Superteam](https://superteam.fun/) - Global Solana community\n- [Blueshift](https://learn.blueshift.gg/) - Interactive learning platform\n\n### Regional Communities\n- [Superteam Germany](https://superteam.fun/germany)\n- [Superteam India](https://superteam.fun/india)\n- [Superteam Vietnam](https://superteam.fun/vietnam)\n- [Superteam LatAm](https://superteam.fun/latam)\n\n## Additional Resources\n\n### Developer Guides\n- [Solana Developer Guide](https://solana.com/developers/guides) - How-to guides\n- [Solana Bootcamp](https://github.com/solana-developers/developer-bootcamp-2024) - Workshop materials\n- [Anchor Examples Repo](https://github.com/coral-xyz/anchor/tree/master/tests) - Anchor test programs\n\n### Tool Documentation\n- [Cargo Build SBF](https://docs.solana.com/cli/deploy-a-program) - Building programs\n- [Solana Program Deploy](https://docs.solana.com/cli/deploy-a-program) - Deployment guide\n- [Solana Keygen](https://docs.solana.com/cli/wallets/paper) - Keypair management\n\n### Ecosystem Tools\n- [Metaplex](https://www.metaplex.com/) - NFT infrastructure\n- [Squads](https://squads.so/) - Multisig and treasury management\n- [Dialect](https://www.dialect.to/) - Messaging and notifications\n\n## Version Information\n\n**Current versions (as of 2025):**\n- Latest Anchor: 0.30+\n- Recommended Solana CLI: Latest stable (check with `solana --version`)\n- Rust minimum: 1.70+\n- Solana program library: 2.0+\n\n**Updating tools:**\n```bash\n# Update Solana CLI\nsolana-install update\n\n# Update Anchor\navm install latest\navm use latest\n\n# Update Rust\nrustup update\n```\n\n---\n\n**Note:** For security-specific resources, vulnerability databases, audit reports, and security tools, see the `solana-security` skill.\n",
        "solana/skills/solana-development/references/security.md": "# Security Best Practices for Solana Development\n\nEssential security principles and defensive programming patterns for building secure Solana programs with Anchor or native Rust.\n\n> **Note:** This guide focuses on defensive programming during development. For comprehensive security audits, vulnerability analysis, and attack vectors, use the **`solana-security` skill**.\n\n## Table of Contents\n\n1. [Security Mindset](#security-mindset)\n2. [Core Security Rules](#core-security-rules)\n3. [Account Validation](#account-validation)\n4. [Arithmetic Safety](#arithmetic-safety)\n5. [PDA Security](#pda-security)\n6. [CPI Security](#cpi-security)\n7. [Common Pitfalls](#common-pitfalls)\n8. [Pre-Deployment Checklist](#pre-deployment-checklist)\n\n---\n\n## Security Mindset\n\n### Think Like an Attacker\n\n**Fundamental principle:** Attackers control everything they send to your program.\n\n- ❌ Don't assume: \"Users won't do that\"\n- ❌ Don't assume: \"The client validates this\"\n- ❌ Don't assume: \"This account must be correct\"\n- ✅ Do validate: Every account, every parameter, every assumption\n\n### You Control Nothing\n\nOnce deployed, your program:\n- Cannot control which accounts are passed in\n- Cannot control instruction data\n- Cannot control timing or ordering\n- Cannot prevent malicious clients\n\n**Your only control:** How your program validates and handles inputs.\n\n---\n\n## Core Security Rules\n\n### Rule 1: Validate Every Account\n\n**Always verify:**\n\n**Anchor:**\n```rust\n#[derive(Accounts)]\npub struct SecureInstruction<'info> {\n    // ✅ Signer required\n    pub authority: Signer<'info>,\n\n    // ✅ Owner validation + relationship\n    #[account(\n        mut,\n        has_one = authority,  // vault.authority == authority.key()\n    )]\n    pub vault: Account<'info, Vault>,\n\n    // ✅ Program ID validation\n    pub token_program: Program<'info, Token>,\n}\n```\n\n**Native Rust:**\n```rust\n// ✅ Signer check\nif !authority.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\n// ✅ Owner check\nif vault.owner != program_id {\n    return Err(ProgramError::IllegalOwner);\n}\n\n// ✅ Program ID check\nif *token_program.key != spl_token::id() {\n    return Err(ProgramError::IncorrectProgramId);\n}\n```\n\n### Rule 2: Use Checked Arithmetic\n\n**Never use:**\n- `+`, `-`, `*`, `/` operators directly\n- `saturating_*` methods (hide errors)\n- `unwrap()` or `expect()` on arithmetic\n\n**Always use:**\n```rust\n// ✅ Checked operations\nlet total = balance\n    .checked_add(amount)\n    .ok_or(ErrorCode::Overflow)?;\n\nlet remaining = total\n    .checked_sub(withdrawal)\n    .ok_or(ErrorCode::InsufficientFunds)?;\n\nlet product = price\n    .checked_mul(quantity)\n    .ok_or(ErrorCode::Overflow)?;\n\nlet share = total\n    .checked_div(parts)\n    .ok_or(ErrorCode::DivisionByZero)?;\n```\n\n### Rule 3: Validate PDAs Properly\n\n**Anchor:**\n```rust\n#[derive(Accounts)]\npub struct SecurePDA<'info> {\n    // ✅ Use canonical bump\n    #[account(\n        seeds = [b\"vault\", user.key().as_ref()],\n        bump,  // Automatically validates canonical bump\n    )]\n    pub vault: Account<'info, Vault>,\n}\n```\n\n**Native Rust:**\n```rust\n// ✅ Find canonical bump\nlet (expected_pda, bump) = Pubkey::find_program_address(\n    &[b\"vault\", user.key.as_ref()],\n    program_id,\n);\n\n// ✅ Validate PDA matches\nif expected_pda != *vault.key {\n    return Err(ProgramError::InvalidSeeds);\n}\n\n// Store bump for future use with create_program_address\n```\n\n### Rule 4: Secure Cross-Program Invocations\n\n**Anchor:**\n```rust\n// ✅ Program type validation\npub token_program: Program<'info, Token>,\n\n// ✅ Use CpiContext\nlet cpi_ctx = CpiContext::new(\n    ctx.accounts.token_program.to_account_info(),\n    transfer_accounts,\n);\n\ntoken::transfer(cpi_ctx, amount)?;\n```\n\n**Native Rust:**\n```rust\n// ✅ Validate program ID before CPI\nif *token_program.key != spl_token::id() {\n    return Err(ProgramError::IncorrectProgramId);\n}\n\n// ✅ Build instruction safely\nlet ix = spl_token::instruction::transfer(\n    token_program.key,\n    source.key,\n    destination.key,\n    authority.key,\n    &[],\n    amount,\n)?;\n\ninvoke(&ix, &[source, destination, authority, token_program])?;\n```\n\n### Rule 5: Handle Errors Gracefully\n\n**Never:**\n```rust\n// ❌ Don't panic or unwrap\nlet value = some_operation().unwrap();\n\n// ❌ Don't ignore errors\nsome_operation();\n```\n\n**Always:**\n```rust\n// ✅ Propagate errors\nlet value = some_operation()\n    .ok_or(ErrorCode::OperationFailed)?;\n\n// ✅ Or handle explicitly\nlet value = match some_operation() {\n    Some(v) => v,\n    None => return Err(ErrorCode::OperationFailed.into()),\n};\n```\n\n---\n\n## Account Validation\n\n### Essential Checks\n\nFor every account, verify:\n\n1. **Signer** - Does this account need to sign?\n2. **Owner** - Who owns this account? Is it our program?\n3. **Writable** - Does this need `mut`?\n4. **Type** - Is this the right account type?\n5. **Relationships** - Do related accounts match?\n\n### Validation Pattern\n\n```rust\n// Native Rust comprehensive validation\npub fn validate_account(\n    account: &AccountInfo,\n    expected_owner: &Pubkey,\n    must_be_signer: bool,\n    must_be_writable: bool,\n) -> ProgramResult {\n    // Check signer\n    if must_be_signer && !account.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Check owner\n    if account.owner != expected_owner {\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // Check writable\n    if must_be_writable && !account.is_writable {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Arithmetic Safety\n\n### Common Vulnerabilities\n\n**Overflow example:**\n```rust\n// ❌ VULNERABLE: Can overflow\npub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {\n    ctx.accounts.vault.balance = ctx.accounts.vault.balance + amount;\n    Ok(())\n}\n\n// If vault.balance = u64::MAX - 100 and amount = 200\n// Result wraps to 99, losing 18.4 quintillion tokens!\n```\n\n**Fix:**\n```rust\n// ✅ SECURE: Checked arithmetic\npub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {\n    ctx.accounts.vault.balance = ctx.accounts.vault.balance\n        .checked_add(amount)\n        .ok_or(ErrorCode::Overflow)?;\n    Ok(())\n}\n```\n\n### Precision Loss\n\n**Multiply before divide:**\n```rust\n// ❌ WRONG: Loses precision\nlet fee = amount / 100;  // 1.5% becomes 1%\n\n// ✅ CORRECT: Multiply first\nlet fee = amount\n    .checked_mul(15)\n    .and_then(|v| v.checked_div(1000))\n    .ok_or(ErrorCode::Overflow)?;  // Exact 1.5%\n```\n\n---\n\n## PDA Security\n\n### Use Canonical Bumps\n\n**Always find the canonical bump:**\n\n```rust\n// ✅ Find canonical bump\nlet (pda, bump) = Pubkey::find_program_address(\n    &[b\"vault\", user.key.as_ref()],\n    program_id,\n);\n\n// Store bump in account for later use\nvault.bump = bump;\n```\n\n**Never hardcode or accept bumps from clients:**\n```rust\n// ❌ VULNERABLE: Accepts any bump\n#[derive(Accounts)]\npub struct BadPDA<'info> {\n    #[account(seeds = [b\"vault\"], bump = user_provided_bump)]\n    pub vault: Account<'info, Vault>,\n}\n```\n\n### Unique Seeds\n\nEnsure seeds create unique PDAs:\n\n```rust\n// ✅ GOOD: Unique per user\nseeds = [b\"vault\", user.key().as_ref()]\n\n// ❌ BAD: Same PDA for everyone\nseeds = [b\"vault\"]\n```\n\n---\n\n## CPI Security\n\n### Validate Target Programs\n\n**Never accept arbitrary program IDs:**\n\n```rust\n// ❌ VULNERABLE\npub fn bad_cpi(ctx: Context<BadCPI>) -> Result<()> {\n    // Attacker can pass any program!\n    let cpi_ctx = CpiContext::new(\n        ctx.accounts.any_program.to_account_info(),\n        accounts,\n    );\n    // ... make CPI\n}\n\n// ✅ SECURE\n#[derive(Accounts)]\npub struct SecureCPI<'info> {\n    pub token_program: Program<'info, Token>,  // Type-checked!\n}\n```\n\n### Reload Accounts After CPIs\n\nIf a CPI might modify an account you're using:\n\n```rust\n// ✅ Reload account after external call\nlet balance_before = token_account.amount;\n\n// Make CPI that might change the account\ntoken::transfer(cpi_ctx, amount)?;\n\n// Reload to get fresh data\ntoken_account.reload()?;\n\nlet balance_after = token_account.amount;\n```\n\n---\n\n## Common Pitfalls\n\n### 1. init_if_needed (Anchor)\n\n**Dangerous pattern:**\n```rust\n// ❌ Can be exploited\n#[account(init_if_needed, payer = user, space = 8 + 32)]\npub config: Account<'info, Config>,\n```\n\n**Problem:** Attacker creates the account first with malicious data.\n\n**Fix:**\n```rust\n// ✅ Use init or check if exists\n#[account(init, payer = user, space = 8 + 32)]\npub config: Account<'info, Config>,\n\n// Or explicitly check\nif config.is_initialized {\n    return Err(ErrorCode::AlreadyInitialized.into());\n}\n```\n\n### 2. Missing Signer Checks\n\n```rust\n// ❌ Anyone can withdraw!\npub fn withdraw(ctx: Context<Withdraw>, amount: u64) -> Result<()> {\n    ctx.accounts.vault.balance -= amount;\n    Ok(())\n}\n\n// ✅ Authority must sign\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(mut, has_one = authority)]\n    pub vault: Account<'info, Vault>,\n    pub authority: Signer<'info>,  // Required!\n}\n```\n\n### 3. Account Confusion\n\n```rust\n// ❌ No validation - any accounts work!\npub struct Transfer<'info> {\n    pub from: Account<'info, TokenAccount>,\n    pub to: Account<'info, TokenAccount>,\n}\n\n// ✅ Validate relationships\npub struct Transfer<'info> {\n    #[account(\n        mut,\n        constraint = from.owner == authority.key(),\n        constraint = from.mint == to.mint,\n    )]\n    pub from: Account<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n\n    pub authority: Signer<'info>,\n}\n```\n\n### 4. Unchecked Account Types\n\n```rust\n// ❌ Uses raw AccountInfo - no type safety\npub fn bad(ctx: Context<Bad>) -> Result<()> {\n    let data = ctx.accounts.account.try_borrow_data()?;\n    // What if attacker passes wrong account type?\n}\n\n// ✅ Use typed Account\npub fn good(ctx: Context<Good>) -> Result<()> {\n    // Anchor verifies discriminator automatically\n    let vault = &ctx.accounts.vault;\n}\n```\n\n---\n\n## Pre-Deployment Checklist\n\nBefore deploying to mainnet:\n\n### Code Review\n\n- [ ] All accounts validated (signer, owner, writable)\n- [ ] All arithmetic uses `checked_*` methods\n- [ ] All PDAs use canonical bumps\n- [ ] All CPIs validate target programs\n- [ ] No `unwrap()` or `expect()` in production code\n- [ ] No `init_if_needed` without additional checks\n- [ ] All error cases handled gracefully\n\n### Testing\n\n- [ ] Unit tests cover all instructions\n- [ ] Integration tests cover instruction interactions\n- [ ] Edge cases tested (zero amounts, max values, overflow)\n- [ ] Error conditions tested (invalid accounts, unauthorized access)\n- [ ] Fuzz testing with Trident (if possible)\n\n### Security Audit\n\n- [ ] Internal code review completed\n- [ ] External security audit (recommended for >$100k TVL)\n- [ ] Use `solana-security` skill for systematic review\n- [ ] All critical/high severity findings resolved\n- [ ] Medium findings assessed and documented\n\n### Documentation\n\n- [ ] Account structures documented\n- [ ] Instruction requirements documented\n- [ ] Known limitations documented\n- [ ] Upgrade strategy documented\n- [ ] Emergency procedures documented\n\n### Deployment\n\n- [ ] Tested on devnet extensively\n- [ ] Tested on mainnet-beta with small amounts\n- [ ] Upgrade authority secured (multisig recommended)\n- [ ] Monitoring and alerts configured\n- [ ] Emergency pause mechanism (if applicable)\n\n---\n\n## When to Use the Security Skill\n\nUse the **`solana-security` skill** for:\n\n- 🔍 **Comprehensive security audits** - Systematic review of entire codebase\n- 🐛 **Vulnerability analysis** - Identifying exploit scenarios\n- 📋 **Security checklists** - Category-by-category validation\n- ⚠️ **Attack vectors** - Understanding how programs can be exploited\n- 🛡️ **Framework-specific patterns** - Anchor vs native Rust security\n- 📚 **Vulnerability databases** - Learning from past exploits\n\nUse **this skill (solana-development)** for:\n\n- 💻 **Building programs** - Implementation guidance\n- ✅ **Defensive programming** - Secure coding patterns\n- 🏗️ **Development workflows** - Testing, deployment, optimization\n- 📖 **Framework learning** - Anchor and native Rust how-tos\n\n---\n\n## Quick Security Reference\n\n### Anchor Security Checklist\n\n```rust\n#[derive(Accounts)]\npub struct Secure<'info> {\n    // ✅ Signer\n    pub authority: Signer<'info>,\n\n    // ✅ Validation + relationships\n    #[account(\n        mut,\n        has_one = authority,\n        seeds = [b\"vault\", user.key().as_ref()],\n        bump,\n    )]\n    pub vault: Account<'info, Vault>,\n\n    // ✅ Program validation\n    pub token_program: Program<'info, Token>,\n}\n\npub fn secure_fn(ctx: Context<Secure>, amount: u64) -> Result<()> {\n    // ✅ Checked arithmetic\n    ctx.accounts.vault.balance = ctx.accounts.vault.balance\n        .checked_add(amount)\n        .ok_or(ErrorCode::Overflow)?;\n\n    Ok(())\n}\n```\n\n### Native Rust Security Checklist\n\n```rust\npub fn secure_fn(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let accounts = &mut accounts.iter();\n    let authority = next_account_info(accounts)?;\n    let vault = next_account_info(accounts)?;\n\n    // ✅ Signer check\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // ✅ Owner check\n    if vault.owner != program_id {\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // ✅ PDA validation\n    let (expected_pda, _) = Pubkey::find_program_address(\n        &[b\"vault\", authority.key.as_ref()],\n        program_id,\n    );\n    if *vault.key != expected_pda {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // ✅ Deserialize\n    let mut vault_data = Vault::try_from_slice(&vault.data.borrow())?;\n\n    // ✅ Checked arithmetic\n    vault_data.balance = vault_data.balance\n        .checked_add(amount)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    // ✅ Serialize back\n    vault_data.serialize(&mut &mut vault.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n---\n\n## Remember\n\n**Security is not optional.** Every line of code is a potential vulnerability. Validate everything, trust nothing, and when in doubt, use the `solana-security` skill for a comprehensive audit.\n",
        "solana/skills/solana-development/references/serialization.md": "# Serialization and Data Handling\n\nThis reference provides comprehensive coverage of data serialization and deserialization patterns for native Rust Solana program development, focusing on Borsh and account data layout best practices.\n\n## Table of Contents\n\n1. [Why Borsh for Solana](#why-borsh-for-solana)\n2. [Basic Borsh Usage](#basic-borsh-usage)\n3. [Account Data Layout Design](#account-data-layout-design)\n4. [Serialization Patterns](#serialization-patterns)\n5. [Zero-Copy Deserialization](#zero-copy-deserialization)\n6. [Data Versioning](#data-versioning)\n7. [Performance Considerations](#performance-considerations)\n8. [Common Pitfalls](#common-pitfalls)\n\n---\n\n## Why Borsh for Solana\n\n**Borsh (Binary Object Representation Serializer for Hashing)** is the recommended serialization format for Solana programs.\n\n### Advantages\n\n1. **Deterministic:** Same data always produces same bytes\n2. **Compact:** Efficient binary encoding\n3. **Fast:** Lower compute unit cost than alternatives\n4. **Strict Schema:** Type-safe serialization/deserialization\n5. **No Metadata:** Unlike JSON, no field names in output\n\n### vs Alternatives\n\n| Format | CU Cost | Size | Type Safety | Deterministic |\n|--------|---------|------|-------------|---------------|\n| **Borsh** | ✅ Low | ✅ Compact | ✅ Yes | ✅ Yes |\n| bincode | ❌ High | ✅ Compact | ✅ Yes | ⚠️ Config-dependent |\n| JSON | ❌ Very High | ❌ Large | ❌ No | ❌ No |\n| MessagePack | ⚠️ Medium | ✅ Compact | ⚠️ Partial | ⚠️ Mostly |\n\n**Recommendation:** Use Borsh for all program account data.\n\n---\n\n## Basic Borsh Usage\n\n### Dependencies\n\n```toml\n[dependencies]\nborsh = { version = \"1.5\", features = [\"derive\"] }\n```\n\n### Deriving Borsh Traits\n\n```rust\nuse borsh::{BorshDeserialize, BorshSerialize};\n\n#[derive(BorshSerialize, BorshDeserialize, Debug, Clone)]\npub struct UserAccount {\n    pub user: Pubkey,\n    pub balance: u64,\n    pub created_at: i64,\n}\n```\n\n### Serialization\n\n**To bytes:**\n\n```rust\nlet account_data = UserAccount {\n    user: Pubkey::new_unique(),\n    balance: 1000,\n    created_at: 1234567890,\n};\n\n// Serialize to Vec<u8>\nlet bytes = account_data.try_to_vec()?;\n\n// Serialize to existing buffer\nlet mut buffer = vec![0u8; 100];\naccount_data.serialize(&mut buffer.as_mut_slice())?;\n```\n\n### Deserialization\n\n**From bytes:**\n\n```rust\n// Deserialize from slice\nlet account_data = UserAccount::try_from_slice(&bytes)?;\n\n// Deserialize with BorshDeserialize\nlet mut cursor = &bytes[..];\nlet account_data = UserAccount::deserialize(&mut cursor)?;\n```\n\n---\n\n## Account Data Layout Design\n\n### Basic Structure\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AccountData {\n    // 1. Discriminator / Type Field (1 byte)\n    pub account_type: u8,\n\n    // 2. Flags / State (1 byte)\n    pub is_initialized: bool,\n\n    // 3. Fixed-size fields (predictable layout)\n    pub owner: Pubkey,           // 32 bytes\n    pub created_at: i64,         // 8 bytes\n    pub counter: u64,            // 8 bytes\n\n    // 4. Variable-size fields (at end)\n    pub name: String,            // 4 + length\n    pub metadata: Vec<u8>,       // 4 + length\n}\n```\n\n**Size calculation:**\n```\n1 (type) + 1 (flag) + 32 (pubkey) + 8 (i64) + 8 (u64) + 4 (string len) + N (string) + 4 (vec len) + M (vec)\n= 58 + N + M bytes\n```\n\n### Size Calculation Helper\n\n```rust\nimpl AccountData {\n    pub const FIXED_SIZE: usize = 58;  // All fixed fields\n\n    pub fn calculate_size(name_len: usize, metadata_len: usize) -> usize {\n        Self::FIXED_SIZE + name_len + metadata_len\n    }\n\n    pub fn max_size(max_name: usize, max_metadata: usize) -> usize {\n        Self::calculate_size(max_name, max_metadata)\n    }\n}\n\n// Usage\nlet account_size = AccountData::max_size(32, 256);  // 346 bytes\n```\n\n### Fixed-Size Accounts\n\n**Best for performance:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct FixedAccount {\n    pub is_initialized: bool,\n    pub owner: Pubkey,\n    pub balance: u64,\n    pub last_updated: i64,\n    // Fixed-size array instead of Vec\n    pub data: [u8; 256],\n}\n\nimpl FixedAccount {\n    pub const SIZE: usize = 1 + 32 + 8 + 8 + 256;  // 305 bytes\n}\n```\n\n---\n\n## Serialization Patterns\n\n### Pattern 1: try_from_slice (Recommended)\n\n**Most common pattern for account deserialization:**\n\n```rust\nuse borsh::BorshDeserialize;\n\npub fn load_account_data(\n    account_info: &AccountInfo,\n) -> Result<UserAccount, ProgramError> {\n    let data = UserAccount::try_from_slice(&account_info.data.borrow())?;\n    Ok(data)\n}\n```\n\n**Error handling:**\n```rust\nlet data = UserAccount::try_from_slice(&account_info.data.borrow())\n    .map_err(|e| {\n        msg!(\"Failed to deserialize account: {}\", e);\n        ProgramError::InvalidAccountData\n    })?;\n```\n\n### Pattern 2: Unchecked Deserialization\n\n**Use when you've already validated the account:**\n\n```rust\nuse borsh::try_from_slice_unchecked;\n\n// After validation checks\nlet mut data = try_from_slice_unchecked::<UserAccount>(&account_info.data.borrow())\n    .unwrap();  // Safe because we validated\n```\n\n**⚠️ Warning:** Only use after thorough validation. Skips some safety checks.\n\n### Pattern 3: Partial Deserialization\n\n**Read only what you need:**\n\n```rust\n#[derive(BorshDeserialize)]\npub struct AccountHeader {\n    pub account_type: u8,\n    pub is_initialized: bool,\n    pub owner: Pubkey,\n}\n\n// Deserialize just the header\nlet header = AccountHeader::try_from_slice(&account_info.data.borrow()[..42])?;\n\nif !header.is_initialized {\n    return Err(ProgramError::UninitializedAccount);\n}\n```\n\n### Pattern 4: In-Place Modification\n\n**Efficient for large accounts:**\n\n```rust\npub fn update_balance(\n    account_info: &AccountInfo,\n    new_balance: u64,\n) -> ProgramResult {\n    let mut data = account_info.data.borrow_mut();\n\n    // Deserialize\n    let mut account = UserAccount::try_from_slice(&data)?;\n\n    // Modify\n    account.balance = new_balance;\n    account.last_updated = Clock::get()?.unix_timestamp;\n\n    // Serialize back\n    account.serialize(&mut &mut data[..])?;\n\n    Ok(())\n}\n```\n\n### Pattern 5: Bulk Operations\n\n**Processing multiple accounts:**\n\n```rust\npub fn process_accounts(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_data: Vec<UserAccount> = accounts\n        .iter()\n        .map(|acc| UserAccount::try_from_slice(&acc.data.borrow()))\n        .collect::<Result<Vec<_>, _>>()?;\n\n    // Process all accounts\n    for (i, data) in account_data.iter().enumerate() {\n        msg!(\"Account {}: balance = {}\", i, data.balance);\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Zero-Copy Deserialization\n\n### When to Use Zero-Copy\n\n**Benefits:**\n- Avoids memory allocation\n- Reduces compute units (50%+ savings for large structs)\n- Direct access to account data\n\n**Use when:**\n- Account data is large (> 100 bytes)\n- Frequent reads\n- Performance-critical paths\n\n### Bytemuck Pattern\n\n```toml\n[dependencies]\nbytemuck = { version = \"1.14\", features = [\"derive\"] }\n```\n\n```rust\nuse bytemuck::{Pod, Zeroable};\n\n#[repr(C)]\n#[derive(Copy, Clone, Pod, Zeroable)]\npub struct ZeroCopyAccount {\n    pub is_initialized: u8,      // bool as u8\n    pub owner: [u8; 32],         // Pubkey as bytes\n    pub balance: u64,\n    pub counter: u64,\n}\n\nimpl ZeroCopyAccount {\n    pub const SIZE: usize = std::mem::size_of::<Self>();\n\n    pub fn from_account_info(account_info: &AccountInfo) -> Result<&Self, ProgramError> {\n        let data = account_info.data.borrow();\n        bytemuck::try_from_bytes(&data)\n            .map_err(|_| ProgramError::InvalidAccountData)\n    }\n\n    pub fn from_account_info_mut(\n        account_info: &AccountInfo,\n    ) -> Result<&mut Self, ProgramError> {\n        let data = account_info.data.borrow_mut();\n        bytemuck::try_from_bytes_mut(&mut data)\n            .map_err(|_| ProgramError::InvalidAccountData)\n    }\n}\n\n// Usage\nlet account = ZeroCopyAccount::from_account_info(account_info)?;\nmsg!(\"Balance: {}\", account.balance);\n\n// Mutable access\nlet account = ZeroCopyAccount::from_account_info_mut(account_info)?;\naccount.balance += 100;\n```\n\n**⚠️ Limitations:**\n- Only works with types that are `Pod` (Plain Old Data)\n- No `String`, `Vec`, or other heap-allocated types\n- Must be `#[repr(C)]` for stable layout\n\n---\n\n## Data Versioning\n\n### Pattern 1: Version Field\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct VersionedAccount {\n    pub version: u8,\n    pub data: AccountDataEnum,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub enum AccountDataEnum {\n    V1(AccountDataV1),\n    V2(AccountDataV2),\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AccountDataV1 {\n    pub balance: u64,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AccountDataV2 {\n    pub balance: u64,\n    pub last_updated: i64,  // New field\n}\n\n// Deserialization with version handling\npub fn load_versioned_account(\n    account_info: &AccountInfo,\n) -> ProgramResult {\n    let versioned = VersionedAccount::try_from_slice(&account_info.data.borrow())?;\n\n    match versioned.data {\n        AccountDataEnum::V1(data_v1) => {\n            msg!(\"V1 account: balance = {}\", data_v1.balance);\n        }\n        AccountDataEnum::V2(data_v2) => {\n            msg!(\"V2 account: balance = {}, updated = {}\",\n                data_v2.balance, data_v2.last_updated);\n        }\n    }\n\n    Ok(())\n}\n```\n\n### Pattern 2: Optional Fields\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Account {\n    pub balance: u64,\n\n    // V2: Added optional field\n    pub metadata: Option<Metadata>,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Metadata {\n    pub name: String,\n    pub url: String,\n}\n\n// Old accounts: metadata = None\n// New accounts: metadata = Some(Metadata { ... })\n```\n\n### Pattern 3: Migration Function\n\n```rust\npub fn migrate_account_v1_to_v2(\n    account_info: &AccountInfo,\n) -> ProgramResult {\n    // Load V1\n    let data_v1 = AccountDataV1::try_from_slice(&account_info.data.borrow())?;\n\n    // Convert to V2\n    let data_v2 = AccountDataV2 {\n        balance: data_v1.balance,\n        last_updated: Clock::get()?.unix_timestamp,\n    };\n\n    // Reallocate if needed\n    let new_size = data_v2.try_to_vec()?.len();\n    account_info.realloc(new_size, false)?;\n\n    // Serialize V2\n    data_v2.serialize(&mut &mut account_info.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n---\n\n## Performance Considerations\n\n### Compute Unit Costs\n\n**Serialization costs (approximate):**\n\n| Operation | CU Cost |\n|-----------|---------|\n| Serialize small struct (< 100 bytes) | ~500 CU |\n| Serialize large struct (> 1KB) | ~2,000 CU |\n| Deserialize small struct | ~800 CU |\n| Deserialize large struct | ~3,000 CU |\n| Zero-copy access | ~100 CU |\n\n### Optimization Tips\n\n**1. Minimize serialization frequency:**\n\n```rust\n// ❌ Wasteful - serializes twice\nlet mut data = load_data(account)?;\ndata.field1 = value1;\nsave_data(account, &data)?;\n\ndata.field2 = value2;\nsave_data(account, &data)?;  // Serialize again!\n\n// ✅ Efficient - serialize once\nlet mut data = load_data(account)?;\ndata.field1 = value1;\ndata.field2 = value2;\nsave_data(account, &data)?;\n```\n\n**2. Use fixed-size fields:**\n\n```rust\n// ❌ Variable size - more expensive\npub struct Account {\n    pub name: String,        // 4 + N bytes\n}\n\n// ✅ Fixed size - cheaper\npub struct Account {\n    pub name: [u8; 32],      // Exactly 32 bytes\n}\n```\n\n**3. Order fields by size:**\n\n```rust\n// ✅ Optimized layout (largest first)\n#[derive(BorshSerialize, BorshDeserialize)]\n#[repr(C)]\npub struct OptimizedAccount {\n    pub pubkey1: Pubkey,     // 32 bytes\n    pub pubkey2: Pubkey,     // 32 bytes\n    pub amount: u64,         // 8 bytes\n    pub timestamp: i64,      // 8 bytes\n    pub flags: u8,           // 1 byte\n}\n```\n\n---\n\n## Common Pitfalls\n\n### 1. Buffer Too Small\n\n```rust\n// ❌ Error: buffer too small\nlet mut buffer = vec![0u8; 10];\nlarge_struct.serialize(&mut buffer.as_mut_slice())?;  // Fails!\n\n// ✅ Correct: proper size\nlet size = large_struct.try_to_vec()?.len();\nlet mut buffer = vec![0u8; size];\nlarge_struct.serialize(&mut buffer.as_mut_slice())?;\n```\n\n### 2. Forgetting to Borrow\n\n```rust\n// ❌ Error: data moved\nlet data = account_info.data;\nUserAccount::try_from_slice(&data)?;  // Fails!\n\n// ✅ Correct: borrow data\nlet data = account_info.data.borrow();\nUserAccount::try_from_slice(&data)?;\n```\n\n### 3. Mismatched Schema\n\n```rust\n// Account created with V1\n#[derive(BorshSerialize)]\npub struct AccountV1 {\n    pub balance: u64,\n}\n\n// Later, trying to deserialize as V2\n#[derive(BorshDeserialize)]\npub struct AccountV2 {\n    pub balance: u64,\n    pub timestamp: i64,  // New field!\n}\n\n// ❌ Fails: not enough bytes\nlet data = AccountV2::try_from_slice(&bytes)?;  // Error!\n```\n\n**Solution:** Use versioning or optional fields.\n\n### 4. String/Vec Limits\n\n```rust\n// ❌ No validation\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Account {\n    pub name: String,  // Could be 10MB!\n}\n\n// ✅ Validate before deserializing\npub fn validate_name(name: &str) -> ProgramResult {\n    if name.len() > 32 {\n        return Err(ProgramError::InvalidArgument);\n    }\n    Ok(())\n}\n```\n\n### 5. Incorrect Size Calculation\n\n```rust\n// ❌ Wrong: ignores vector length prefix\nlet size = my_vec.len();\n\n// ✅ Correct: includes 4-byte length prefix\nlet size = 4 + my_vec.len();\n```\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **Use Borsh** for all Solana program serialization\n2. **Design fixed-size layouts** when possible for predictability\n3. **Validate before deserializing** to prevent errors\n4. **Use zero-copy** for large, frequently-accessed data\n5. **Plan for versioning** from the start\n6. **Minimize serialization frequency** to save compute units\n\n**Common Patterns:**\n```rust\n// Deserialize\nlet data = AccountData::try_from_slice(&account_info.data.borrow())?;\n\n// Modify\nlet mut data = data;\ndata.field = new_value;\n\n// Serialize\ndata.serialize(&mut &mut account_info.data.borrow_mut()[..])?;\n```\n\n**Size Calculation:**\n```rust\n// Fixed fields\nconst FIXED_SIZE: usize = 1 + 32 + 8;\n\n// Variable fields\nlet total_size = FIXED_SIZE + 4 + string.len() + 4 + vec.len();\n```\n\nProper serialization patterns are fundamental to efficient and correct Solana programs. Master Borsh for production-ready data handling.\n",
        "solana/skills/solana-development/references/surfpool.md": "# Surfpool Local Development\n\nSurfpool is a drop-in replacement for `solana-test-validator` built on LiteSVM. It provides instant mainnet forking, powerful cheatcodes for testing, and Infrastructure as Code for reproducible deployments.\n\n## Installation\n\n```bash\n# macOS (Homebrew)\nbrew install txtx/taps/surfpool\n\n# Update existing installation\nbrew tap txtx/taps\nbrew reinstall surfpool\n\n# From source\ngit clone https://github.com/txtx/surfpool.git\ncd surfpool\ncargo surfpool-install\n\n# Docker\ndocker run surfpool/surfpool --version\n\n# Verify\nsurfpool --version\n```\n\n## Quick Start\n\n```bash\n# Start local network (in Anchor project directory)\nsurfpool start\n\n# Start with custom options\nsurfpool start --port 8899 --slot-time 400\n\n# Start with airdrops to specific addresses\nsurfpool start --airdrop <PUBKEY1> --airdrop <PUBKEY2> --airdrop-amount 100000000000\n```\n\nWhen run in an Anchor project, Surfpool automatically:\n- Generates Infrastructure as Code runbooks\n- Deploys programs to the local network\n- Provides structured environment for iteration\n\n## CLI Options\n\n```bash\nsurfpool start [OPTIONS]\n\nOptions:\n  -m, --manifest-file-path <PATH>   Path to manifest [default: ./Surfpool.toml]\n  -p, --port <PORT>                 RPC port [default: 8899]\n  -o, --host <HOST>                 Host address [default: 127.0.0.1]\n  -s, --slot-time <MS>              Slot time in ms [default: 400]\n  -u, --rpc-url <URL>               Mainnet RPC for forking [default: https://api.mainnet-beta.solana.com]\n  --no-tui                          Disable terminal UI, show log streams\n  --no-deploy                       Disable auto deployments\n  --watch                           Watch programs for changes\n  -r, --runbook <ID>                Runbooks to execute [default: deployment]\n  -a, --airdrop <PUBKEY>            Addresses to airdrop SOL\n  -q, --airdrop-amount <LAMPORTS>   Airdrop amount [default: 10000000000000]\n  -k, --airdrop-keypair-path <PATH> Keypair paths to airdrop [default: ~/.config/solana/id.json]\n  -g, --geyser-plugin-config <PATH> Geyser plugins to load\n  --no-explorer                     Disable explorer\n```\n\n## Mainnet Forking (Just-in-Time)\n\nSurfpool fetches mainnet accounts on-demand without downloading snapshots:\n\n```bash\n# Fork mainnet state\nsurfpool start --rpc-url https://api.mainnet-beta.solana.com\n\n# Use custom RPC (recommended for rate limits)\nsurfpool start --rpc-url https://mainnet.helius-rpc.com?api-key=YOUR_KEY\n```\n\n**Use cases:**\n- Test CPIs into Jupiter, Raydium, Meteora without manual account dumps\n- Simulate swaps with real liquidity pool state\n- Test oracle integrations with live price feeds\n\n## Cheatcodes\n\nSpecial RPC methods for testing. Call via any Solana RPC client:\n\n### Account Manipulation\n\n**`surfnet_setAccount`** - Set any account's state:\n```typescript\nawait connection._rpcRequest('surfnet_setAccount', [\n  pubkey.toBase58(),\n  {\n    lamports: 1_000_000_000,\n    data: Buffer.from([...]).toString('hex'),\n    owner: SystemProgram.programId.toBase58(),\n    executable: false,\n  }\n]);\n```\n\n**`surfnet_setTokenAccount`** - Set token balances directly:\n```typescript\nawait connection._rpcRequest('surfnet_setTokenAccount', [\n  owner.toBase58(),\n  mint.toBase58(),\n  {\n    amount: 1_000_000_000_000,  // Set balance without minting\n    delegate: null,\n    state: 'initialized',\n  }\n]);\n```\n\n**`surfnet_cloneProgramAccount`** - Clone programs between IDs:\n```typescript\nawait connection._rpcRequest('surfnet_cloneProgramAccount', [\n  sourceProgramId.toBase58(),\n  destinationProgramId.toBase58()\n]);\n```\n\n**`surfnet_setProgramAuthority`** - Modify upgrade authority:\n```typescript\nawait connection._rpcRequest('surfnet_setProgramAuthority', [\n  programId.toBase58(),\n  newAuthority.toBase58()  // or null for immutable\n]);\n```\n\n### Time Manipulation\n\n**`surfnet_timeTravel`** - Jump to future epoch/slot/timestamp:\n```typescript\n// Move to specific slot\nawait connection._rpcRequest('surfnet_timeTravel', [{ slot: 300_000_000 }]);\n\n// Move to specific epoch\nawait connection._rpcRequest('surfnet_timeTravel', [{ epoch: 500 }]);\n```\n\n**`surfnet_pauseClock`** / **`surfnet_resumeClock`** - Control time:\n```typescript\nawait connection._rpcRequest('surfnet_pauseClock', []);\n// ... perform tests at frozen time\nawait connection._rpcRequest('surfnet_resumeClock', []);\n```\n\n### Transaction Profiling\n\n**`surfnet_profileTransaction`** - Detailed CU analysis:\n```typescript\nconst result = await connection._rpcRequest('surfnet_profileTransaction', [\n  transaction.serialize().toString('base64'),\n  'my-test-tag',  // optional tag for grouping\n  { depth: 'instruction', encoding: 'base64' }\n]);\n\n// Result includes:\n// - Total CU consumed\n// - Per-instruction breakdown\n// - Account changes\n// - Execution logs\n```\n\n**`surfnet_getProfileResults`** - Retrieve tagged profiles:\n```typescript\nconst profiles = await connection._rpcRequest('surfnet_getProfileResults', [\n  'my-test-tag'\n]);\n```\n\n**`surfnet_getTransactionProfile`** - Get profile by signature:\n```typescript\nconst profile = await connection._rpcRequest('surfnet_getTransactionProfile', [\n  { signature: txSignature }\n]);\n```\n\n### IDL Management\n\n**`surfnet_registerIdl`** - Register IDL for account parsing:\n```typescript\nawait connection._rpcRequest('surfnet_registerIdl', [\n  idlJson,  // Full IDL object\n  slot      // Optional: slot when IDL becomes active\n]);\n```\n\n**`surfnet_getIdl`** - Retrieve registered IDL:\n```typescript\nconst idl = await connection._rpcRequest('surfnet_getIdl', [\n  programId.toBase58()\n]);\n```\n\n## Scenarios (Protocol Overrides)\n\nTest against specific protocol states with slot-by-slot account overrides.\n\n**Natively supported protocols (v1.0.0-rc1):**\n- **Pyth v2** - Price feeds (SOL/USD, BTC/USD, ETH/BTC, ETH/USD)\n- **Jupiter v6** - DEX aggregator, TokenLedger manipulation\n- **Switchboard On-Demand** - Oracle quote overrides\n- **Kamino** - Lending reserve liquidity, risk config, obligation health\n- **Drift v2** - Perp/spot markets, user state, global state\n- **Raydium AMM-v3** - AMM pool states\n- **Meteora DLMM** - Dynamic liquidity market maker\n- **Whirlpool** - Concentrated liquidity pools\n\n**Register custom scenarios:**\n```typescript\nawait connection._rpcRequest('surfnet_registerScenario', [\n  {\n    name: 'liquidation-test',\n    description: 'Test liquidation at 80% LTV',\n    overrides: [\n      {\n        slot: 1,\n        accounts: {\n          [obligationPubkey]: {\n            borrowedValue: 80_000_000,\n            depositedValue: 100_000_000\n          }\n        }\n      }\n    ]\n  }\n]);\n```\n\n**Use cases:**\n- Simulate oracle price crashes\n- Test liquidation scenarios\n- Replay historical market conditions\n- Stress test protocol edge cases\n\n## Infrastructure as Code (IaC)\n\nSurfpool uses `.tx` runbooks for declarative deployments:\n\n```hcl\n# deployment.tx\naddon \"svm\" {\n  network_id = input.network_id\n  rpc_api_url = input.rpc_api_url\n}\n\nsigner \"deployer\" \"svm::web_wallet\" {\n  expected_address = input.deployer_address\n}\n\naction \"deploy_program\" \"svm::deploy_program\" {\n  description = \"Deploy the program\"\n  program = svm::get_program_from_anchor_project(\"my_program\")\n  authority = signer.deployer\n  payer = signer.deployer\n}\n\noutput \"program_id\" {\n  value = action.deploy_program.program_id\n}\n```\n\n**Run runbooks:**\n```bash\n# Supervised mode (web UI)\nsurfpool run deployment.tx\n\n# Unsupervised mode (CI/CD)\nsurfpool run deployment.tx --unsupervised\n\n# With environment\nsurfpool run deployment.tx --env mainnet\n```\n\n**Manifest file (`txtx.yml`):**\n```yaml\nname: my-protocol\nrunbooks:\n  - name: Deploy Protocol\n    location: ./deployment\n    state:\n      location: states\n\nenvironments:\n  devnet:\n    network_id: devnet\n    rpc_api_url: https://api.devnet.solana.com\n  mainnet:\n    network_id: mainnet\n    rpc_api_url: https://api.mainnet-beta.solana.com\n```\n\n## IDL-to-SQL\n\nAuto-generate SQL schemas from program IDLs:\n\n```bash\n# Surfpool automatically generates tables for registered IDLs\n# Query account data via local SQLite or Postgres\n\n# Example: Query all token accounts\nSELECT * FROM token_accounts WHERE owner = 'YOUR_PUBKEY';\n```\n\n## MCP Integration\n\nAdd Surfpool as an MCP server for AI-assisted development:\n\n**Claude Code / Cursor configuration:**\n```json\n{\n  \"mcpServers\": {\n    \"surfpool\": {\n      \"command\": \"surfpool\",\n      \"args\": [\"mcp\"]\n    }\n  }\n}\n```\n\n**Available MCP tools:**\n- `start_surfnet` - Start a local network\n- `set_token_account` - Set token balances for testing\n\n**Example prompt:**\n> \"Start a local network with 10 users loaded with SOL, USDC, JUP and TRUMP tokens\"\n\n## Integration with Anchor\n\nSurfpool works seamlessly with existing Anchor workflows:\n\n```bash\n# In Anchor project directory\ncd my-anchor-project\n\n# Start Surfpool (auto-deploys programs)\nsurfpool start\n\n# Run Anchor tests against Surfpool\nanchor test --skip-local-validator\n\n# Watch for program changes\nsurfpool start --watch\n```\n\n**anchor.toml configuration:**\n```toml\n[provider]\ncluster = \"localnet\"  # Points to Surfpool on 8899\n\n[programs.localnet]\nmy_program = \"YourProgramID\"\n```\n\n## Integration with Native Rust\n\n```bash\n# Build program\ncargo build-sbf\n\n# Start Surfpool\nsurfpool start --no-deploy\n\n# Deploy manually\nsolana program deploy target/deploy/my_program.so\n\n# Or use runbook\nsurfpool run deploy.tx\n```\n\n## Surfpool Studio\n\nLocal web dashboard for visualization:\n\n```bash\n# Start with Studio enabled (default)\nsurfpool start\n\n# Access at http://localhost:8899/studio\n```\n\n**Features:**\n- Real-time transaction monitoring\n- Account state inspection\n- Scenario builder (drag-and-drop protocol overrides)\n- IDL-parsed account views\n- Transaction profiling results\n\n## Best Practices\n\n### Testing with Cheatcodes\n\n```typescript\ndescribe('Liquidation Tests', () => {\n  beforeEach(async () => {\n    // Set up specific account states\n    await connection._rpcRequest('surfnet_setTokenAccount', [\n      userWallet.toBase58(),\n      usdcMint.toBase58(),\n      { amount: 1_000_000_000 }\n    ]);\n\n    // Pause clock for deterministic tests\n    await connection._rpcRequest('surfnet_pauseClock', []);\n  });\n\n  it('should liquidate at 80% LTV', async () => {\n    // Time travel to simulate price change\n    await connection._rpcRequest('surfnet_timeTravel', [{ slot: currentSlot + 1000 }]);\n\n    // Test liquidation logic\n    // ...\n  });\n\n  afterEach(async () => {\n    await connection._rpcRequest('surfnet_resumeClock', []);\n  });\n});\n```\n\n### CU Optimization Workflow\n\n1. **Profile baseline:**\n   ```typescript\n   const baseline = await connection._rpcRequest('surfnet_profileTransaction', [\n     tx.serialize().toString('base64'),\n     'optimization-baseline'\n   ]);\n   ```\n\n2. **Make optimizations** (see [compute-optimization.md](compute-optimization.md))\n\n3. **Profile again and compare:**\n   ```typescript\n   const optimized = await connection._rpcRequest('surfnet_profileTransaction', [\n     optimizedTx.serialize().toString('base64'),\n     'optimization-v1'\n   ]);\n   ```\n\n4. **Review in Studio** for per-instruction breakdown\n\n### CI/CD Integration\n\n```yaml\n# GitHub Actions example\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install Surfpool\n        run: cargo install --git https://github.com/txtx/surfpool surfpool-cli\n\n      - name: Start Surfpool\n        run: surfpool start --no-tui &\n\n      - name: Wait for Surfpool\n        run: sleep 5\n\n      - name: Run tests\n        run: anchor test --skip-local-validator\n```\n\n## Troubleshooting\n\n**Port already in use:**\n```bash\nsurfpool start --port 8900\n```\n\n**Mainnet RPC rate limits:**\n```bash\n# Use dedicated RPC\nsurfpool start --rpc-url https://mainnet.helius-rpc.com?api-key=YOUR_KEY\n\n# Or set environment variable\nexport SURFPOOL_DATASOURCE_RPC_URL=https://your-rpc.com\n```\n\n**Program not deploying:**\n```bash\n# Check deployment logs\nsurfpool start --debug\n\n# Manually deploy\nsurfpool start --no-deploy\nsolana program deploy target/deploy/program.so\n```\n\n## Resources\n\n- [Surfpool Documentation](https://docs.surfpool.run)\n- [GitHub Repository](https://github.com/txtx/surfpool)\n- [Surfpool 101 Video Series](https://www.youtube.com/playlist?list=PL0FMgRjJMRzO1FdunpMS-aUS4GNkgyr3T)\n- [Discord Community](https://discord.gg/rqXmWsn2ja)\n- [Solana Docs: Surfpool CLI Basics](https://solana.com/docs/intro/installation/surfpool-cli-basics)\n",
        "solana/skills/solana-development/references/sysvars.md": "# Sysvars (System Variables)\n\nThis reference provides comprehensive coverage of Solana System Variables (sysvars) for native Rust program development, including access patterns, use cases, and performance implications.\n\n## Table of Contents\n\n1. [What are Sysvars](#what-are-sysvars)\n2. [Clock Sysvar](#clock-sysvar)\n3. [Rent Sysvar](#rent-sysvar)\n4. [EpochSchedule Sysvar](#epochschedule-sysvar)\n5. [SlotHashes Sysvar](#slothashes-sysvar)\n6. [Other Sysvars](#other-sysvars)\n7. [Access Patterns](#access-patterns)\n8. [Performance Implications](#performance-implications)\n9. [Best Practices](#best-practices)\n\n---\n\n## What are Sysvars\n\n**System Variables (sysvars)** are special accounts that provide programs with access to blockchain state and cluster information.\n\n### Key Characteristics\n\n1. **Cluster-wide state:** Same values for all programs in the same slot\n2. **Updated automatically:** Runtime maintains values\n3. **Predictable addresses:** Well-known pubkeys\n4. **Read-only:** Programs cannot modify sysvars\n5. **Low CU cost:** Cheaper than account reads\n\n### When to Use Sysvars\n\n**Use sysvars when you need:**\n- Current timestamp or slot number\n- Rent exemption calculations\n- Epoch and slot timing information\n- Recent block hashes (for verification)\n- Stake history or epoch rewards\n\n**Don't use sysvars for:**\n- User-specific data (use accounts)\n- Program state (use PDAs)\n- Cross-program communication (use CPIs)\n\n---\n\n## Clock Sysvar\n\n**Address:** `solana_program::sysvar::clock::ID`\n\nThe Clock sysvar provides timing information about the blockchain.\n\n### Clock Structure\n\n```rust\nuse solana_program::clock::Clock;\n\npub struct Clock {\n    pub slot: Slot,                    // Current slot\n    pub epoch_start_timestamp: i64,    // Timestamp of epoch start (approximate)\n    pub epoch: Epoch,                  // Current epoch\n    pub leader_schedule_epoch: Epoch,  // Epoch for which leader schedule is valid\n    pub unix_timestamp: UnixTimestamp, // Estimated wall-clock Unix timestamp\n}\n```\n\n### Accessing Clock\n\n**Pattern 1: get() (Recommended)**\n\n```rust\nuse solana_program::clock::Clock;\nuse solana_program::sysvar::Sysvar;\n\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    _instruction_data: &[u8],\n) -> ProgramResult {\n    // Get Clock directly (no account needed)\n    let clock = Clock::get()?;\n\n    msg!(\"Current slot: {}\", clock.slot);\n    msg!(\"Current timestamp: {}\", clock.unix_timestamp);\n    msg!(\"Current epoch: {}\", clock.epoch);\n\n    Ok(())\n}\n```\n\n**Pattern 2: From account**\n\n```rust\nuse solana_program::sysvar::clock;\n\npub fn process_with_account(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let clock_account = next_account_info(account_info_iter)?;\n\n    // Verify it's the Clock sysvar\n    if clock_account.key != &clock::ID {\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    let clock = Clock::from_account_info(clock_account)?;\n    msg!(\"Timestamp: {}\", clock.unix_timestamp);\n\n    Ok(())\n}\n```\n\n**⚠️ Recommendation:** Use `Clock::get()` unless you specifically need the account for validation.\n\n### Common Clock Use Cases\n\n**1. Timestamping events:**\n\n```rust\nuse solana_program::clock::Clock;\nuse solana_program::sysvar::Sysvar;\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Event {\n    pub created_at: i64,\n    pub data: Vec<u8>,\n}\n\npub fn create_event(\n    event_account: &AccountInfo,\n    data: Vec<u8>,\n) -> ProgramResult {\n    let clock = Clock::get()?;\n\n    let event = Event {\n        created_at: clock.unix_timestamp,\n        data,\n    };\n\n    event.serialize(&mut &mut event_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n**2. Time-based logic (vesting, expiration):**\n\n```rust\npub fn check_vesting(\n    vesting_account: &AccountInfo,\n) -> ProgramResult {\n    let clock = Clock::get()?;\n    let vesting = VestingSchedule::try_from_slice(&vesting_account.data.borrow())?;\n\n    if clock.unix_timestamp < vesting.unlock_timestamp {\n        msg!(\"Tokens still locked until {}\", vesting.unlock_timestamp);\n        return Err(ProgramError::Custom(1)); // Locked\n    }\n\n    msg!(\"Vesting unlocked!\");\n    Ok(())\n}\n```\n\n**3. Slot-based mechanics:**\n\n```rust\npub fn process_epoch_transition(\n    state_account: &AccountInfo,\n) -> ProgramResult {\n    let clock = Clock::get()?;\n    let mut state = State::try_from_slice(&state_account.data.borrow())?;\n\n    if clock.epoch > state.last_processed_epoch {\n        msg!(\"Processing epoch transition: {} -> {}\",\n            state.last_processed_epoch, clock.epoch);\n\n        // Process epoch rewards, resets, etc.\n        state.last_processed_epoch = clock.epoch;\n        state.serialize(&mut &mut state_account.data.borrow_mut()[..])?;\n    }\n\n    Ok(())\n}\n```\n\n### Clock Gotchas\n\n**⚠️ unix_timestamp is approximate:**\n\n```rust\n// ❌ Don't use for precise timing\nif clock.unix_timestamp == expected_timestamp {  // Risky!\n    // Might miss by seconds\n}\n\n// ✅ Use ranges for time checks\nif clock.unix_timestamp >= unlock_time {\n    // Safe\n}\n```\n\n**⚠️ Timestamps can vary across validators:**\n\nThe `unix_timestamp` is based on validator voting and may differ slightly between validators in the same slot. Don't assume exact precision.\n\n---\n\n## Rent Sysvar\n\n**Address:** `solana_program::sysvar::rent::ID`\n\nThe Rent sysvar provides rent calculation parameters.\n\n### Rent Structure\n\n```rust\nuse solana_program::rent::Rent;\n\npub struct Rent {\n    pub lamports_per_byte_year: u64,  // Base rent rate\n    pub exemption_threshold: f64,      // Multiplier for exemption (2.0 = 2 years)\n    pub burn_percent: u8,              // Percentage of rent burned\n}\n```\n\n### Accessing Rent\n\n**Pattern 1: get() (Recommended)**\n\n```rust\nuse solana_program::rent::Rent;\nuse solana_program::sysvar::Sysvar;\n\npub fn calculate_rent_exemption(\n    data_size: usize,\n) -> Result<u64, ProgramError> {\n    let rent = Rent::get()?;\n\n    // Calculate minimum balance for rent exemption\n    let min_balance = rent.minimum_balance(data_size);\n\n    msg!(\"Minimum balance for {} bytes: {} lamports\", data_size, min_balance);\n    Ok(min_balance)\n}\n```\n\n**Pattern 2: From account**\n\n```rust\nuse solana_program::sysvar::rent;\n\npub fn check_rent_exemption(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let data_account = next_account_info(account_info_iter)?;\n    let rent_account = next_account_info(account_info_iter)?;\n\n    if rent_account.key != &rent::ID {\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    let rent = Rent::from_account_info(rent_account)?;\n\n    if !rent.is_exempt(data_account.lamports(), data_account.data_len()) {\n        msg!(\"Account is not rent-exempt!\");\n        return Err(ProgramError::AccountNotRentExempt);\n    }\n\n    Ok(())\n}\n```\n\n### Common Rent Use Cases\n\n**1. Account creation with rent exemption:**\n\n```rust\nuse solana_program::rent::Rent;\nuse solana_program::system_instruction;\nuse solana_program::program::invoke_signed;\n\npub fn create_account_rent_exempt(\n    payer: &AccountInfo,\n    new_account: &AccountInfo,\n    system_program: &AccountInfo,\n    program_id: &Pubkey,\n    seeds: &[&[u8]],\n    space: usize,\n) -> ProgramResult {\n    let rent = Rent::get()?;\n    let min_balance = rent.minimum_balance(space);\n\n    msg!(\"Creating account with {} lamports for {} bytes\", min_balance, space);\n\n    let create_account_ix = system_instruction::create_account(\n        payer.key,\n        new_account.key,\n        min_balance,\n        space as u64,\n        program_id,\n    );\n\n    invoke_signed(\n        &create_account_ix,\n        &[payer.clone(), new_account.clone(), system_program.clone()],\n        &[seeds],\n    )?;\n\n    Ok(())\n}\n```\n\n**2. Validating account has sufficient balance:**\n\n```rust\npub fn validate_rent_exempt_account(\n    account: &AccountInfo,\n) -> ProgramResult {\n    let rent = Rent::get()?;\n\n    if !rent.is_exempt(account.lamports(), account.data_len()) {\n        let required = rent.minimum_balance(account.data_len());\n        let current = account.lamports();\n\n        msg!(\"Account not rent-exempt: has {} lamports, needs {}\",\n            current, required);\n\n        return Err(ProgramError::AccountNotRentExempt);\n    }\n\n    Ok(())\n}\n```\n\n**3. Calculating required lamports for reallocation:**\n\n```rust\npub fn reallocate_account(\n    account: &AccountInfo,\n    new_size: usize,\n) -> ProgramResult {\n    let rent = Rent::get()?;\n\n    let old_size = account.data_len();\n    let current_lamports = account.lamports();\n\n    let new_min_balance = rent.minimum_balance(new_size);\n\n    if new_size > old_size {\n        // Growing account - ensure sufficient lamports\n        if current_lamports < new_min_balance {\n            msg!(\"Need {} more lamports for reallocation\",\n                new_min_balance - current_lamports);\n            return Err(ProgramError::InsufficientFunds);\n        }\n    }\n\n    account.realloc(new_size, false)?;\n    Ok(())\n}\n```\n\n---\n\n## EpochSchedule Sysvar\n\n**Address:** `solana_program::sysvar::epoch_schedule::ID`\n\nThe EpochSchedule sysvar provides information about epoch timing and slot calculations.\n\n### EpochSchedule Structure\n\n```rust\nuse solana_program::epoch_schedule::EpochSchedule;\n\npub struct EpochSchedule {\n    pub slots_per_epoch: u64,              // Slots per epoch after warmup\n    pub leader_schedule_slot_offset: u64,  // Offset for leader schedule\n    pub warmup: bool,                      // Whether in warmup period\n    pub first_normal_epoch: Epoch,         // First non-warmup epoch\n    pub first_normal_slot: Slot,           // First slot of first normal epoch\n}\n```\n\n### Accessing EpochSchedule\n\n```rust\nuse solana_program::sysvar::epoch_schedule::EpochSchedule;\nuse solana_program::sysvar::Sysvar;\n\npub fn get_epoch_info() -> ProgramResult {\n    let epoch_schedule = EpochSchedule::get()?;\n\n    msg!(\"Slots per epoch: {}\", epoch_schedule.slots_per_epoch);\n    msg!(\"First normal epoch: {}\", epoch_schedule.first_normal_epoch);\n    msg!(\"Warmup: {}\", epoch_schedule.warmup);\n\n    Ok(())\n}\n```\n\n### Common EpochSchedule Use Cases\n\n**1. Calculating epoch from slot:**\n\n```rust\nuse solana_program::clock::Clock;\nuse solana_program::epoch_schedule::EpochSchedule;\n\npub fn calculate_epoch_from_slot(\n    slot: u64,\n) -> Result<u64, ProgramError> {\n    let epoch_schedule = EpochSchedule::get()?;\n\n    let epoch = epoch_schedule.get_epoch(slot);\n    msg!(\"Slot {} is in epoch {}\", slot, epoch);\n\n    Ok(epoch)\n}\n```\n\n**2. Determining slots remaining in epoch:**\n\n```rust\npub fn slots_until_epoch_end() -> Result<u64, ProgramError> {\n    let clock = Clock::get()?;\n    let epoch_schedule = EpochSchedule::get()?;\n\n    let current_slot = clock.slot;\n    let current_epoch = clock.epoch;\n\n    // Get first slot of next epoch\n    let next_epoch_start = epoch_schedule.get_first_slot_in_epoch(current_epoch + 1);\n\n    let remaining = next_epoch_start - current_slot;\n    msg!(\"Slots remaining in epoch: {}\", remaining);\n\n    Ok(remaining)\n}\n```\n\n**3. Epoch-based reward distribution:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct RewardState {\n    pub last_distribution_epoch: u64,\n    pub total_distributed: u64,\n}\n\npub fn distribute_epoch_rewards(\n    reward_state_account: &AccountInfo,\n) -> ProgramResult {\n    let clock = Clock::get()?;\n    let mut state = RewardState::try_from_slice(&reward_state_account.data.borrow())?;\n\n    if clock.epoch > state.last_distribution_epoch {\n        let epochs_passed = clock.epoch - state.last_distribution_epoch;\n\n        msg!(\"Distributing rewards for {} epochs\", epochs_passed);\n\n        // Distribute rewards\n        let reward_amount = epochs_passed * 1000; // Example\n        state.total_distributed += reward_amount;\n        state.last_distribution_epoch = clock.epoch;\n\n        state.serialize(&mut &mut reward_state_account.data.borrow_mut()[..])?;\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## SlotHashes Sysvar\n\n**Address:** `solana_program::sysvar::slot_hashes::ID`\n\nThe SlotHashes sysvar contains recent slot hashes for verification purposes.\n\n### SlotHashes Structure\n\n```rust\nuse solana_program::slot_hashes::SlotHashes;\n\n// SlotHashes contains up to 512 recent (slot, hash) pairs\npub struct SlotHashes {\n    // Vector of (slot, hash) tuples\n    // Most recent first, up to MAX_ENTRIES (512)\n}\n```\n\n### Accessing SlotHashes\n\n```rust\nuse solana_program::sysvar::slot_hashes::SlotHashes;\nuse solana_program::sysvar::Sysvar;\n\npub fn verify_recent_slot(\n    claimed_slot: u64,\n    claimed_hash: &[u8; 32],\n) -> ProgramResult {\n    let slot_hashes = SlotHashes::get()?;\n\n    // Check if slot is in recent history\n    for (slot, hash) in slot_hashes.iter() {\n        if *slot == claimed_slot {\n            if hash.as_ref() == claimed_hash {\n                msg!(\"Slot hash verified!\");\n                return Ok(());\n            } else {\n                msg!(\"Slot hash mismatch!\");\n                return Err(ProgramError::InvalidArgument);\n            }\n        }\n    }\n\n    msg!(\"Slot not found in recent history\");\n    Err(ProgramError::InvalidArgument)\n}\n```\n\n### Common SlotHashes Use Cases\n\n**1. Verifying transaction recency:**\n\n```rust\npub fn verify_transaction_recent(\n    slot_hashes_account: &AccountInfo,\n    claimed_slot: u64,\n) -> ProgramResult {\n    let slot_hashes = SlotHashes::from_account_info(slot_hashes_account)?;\n\n    // Check if claimed slot is in recent 512 slots\n    let is_recent = slot_hashes.iter().any(|(slot, _)| *slot == claimed_slot);\n\n    if !is_recent {\n        msg!(\"Transaction too old or slot invalid\");\n        return Err(ProgramError::Custom(1));\n    }\n\n    Ok(())\n}\n```\n\n**2. Preventing replay attacks:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct ProcessedSlot {\n    pub slot: u64,\n    pub hash: [u8; 32],\n}\n\npub fn process_once_per_slot(\n    state_account: &AccountInfo,\n) -> ProgramResult {\n    let slot_hashes = SlotHashes::get()?;\n    let mut state = ProcessedSlot::try_from_slice(&state_account.data.borrow())?;\n\n    // Get current slot and hash\n    let (current_slot, current_hash) = slot_hashes.iter().next()\n        .ok_or(ProgramError::InvalidArgument)?;\n\n    if state.slot == *current_slot {\n        msg!(\"Already processed in this slot!\");\n        return Err(ProgramError::Custom(2)); // Already processed\n    }\n\n    // Update state\n    state.slot = *current_slot;\n    state.hash = current_hash.to_bytes();\n    state.serialize(&mut &mut state_account.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**⚠️ Note:** SlotHashes only maintains the most recent 512 slots. For older verification, use a different approach.\n\n---\n\n## Other Sysvars\n\n### StakeHistory\n\n**Address:** `solana_program::sysvar::stake_history::ID`\n\nProvides historical stake activation and deactivation information.\n\n```rust\nuse solana_program::sysvar::stake_history::StakeHistory;\n\npub fn get_stake_history() -> ProgramResult {\n    let stake_history = StakeHistory::get()?;\n\n    // Access historical stake data by epoch\n    msg!(\"Stake history available\");\n    Ok(())\n}\n```\n\n**Use cases:**\n- Stake pool programs\n- Historical stake analysis\n- Reward calculations\n\n### EpochRewards\n\n**Address:** `solana_program::sysvar::epoch_rewards::ID`\n\nProvides information about epoch rewards distribution (if active).\n\n```rust\nuse solana_program::sysvar::epoch_rewards::EpochRewards;\n\npub fn check_epoch_rewards() -> ProgramResult {\n    let epoch_rewards = EpochRewards::get()?;\n\n    msg!(\"Epoch rewards data available\");\n    Ok(())\n}\n```\n\n**Use cases:**\n- Stake reward programs\n- Validator reward tracking\n\n### Instructions\n\n**Address:** `solana_program::sysvar::instructions::ID`\n\nProvides access to instructions in the current transaction.\n\n```rust\nuse solana_program::sysvar::instructions;\n\npub fn validate_transaction_instructions(\n    instructions_account: &AccountInfo,\n) -> ProgramResult {\n    // Check if current instruction is not the first\n    let current_index = instructions::load_current_index_checked(instructions_account)?;\n\n    msg!(\"Current instruction index: {}\", current_index);\n\n    // Load a specific instruction\n    if current_index > 0 {\n        let prev_ix = instructions::load_instruction_at_checked(\n            (current_index - 1) as usize,\n            instructions_account,\n        )?;\n\n        msg!(\"Previous instruction program: {}\", prev_ix.program_id);\n    }\n\n    Ok(())\n}\n```\n\n**Use cases:**\n- Cross-instruction validation\n- Ensuring instruction order\n- Detecting sandwich attacks\n\n---\n\n## Access Patterns\n\n### Pattern 1: get() - Direct Access (Recommended)\n\n**Advantages:**\n- No account needed in instruction\n- Saves account space\n- Lower CU cost (~100 CU)\n- Cleaner code\n\n**Disadvantages:**\n- Not supported for all sysvars\n- Can't be passed to CPIs\n\n```rust\nuse solana_program::sysvar::Sysvar;\n\npub fn use_sysvar_direct() -> ProgramResult {\n    let clock = Clock::get()?;\n    let rent = Rent::get()?;\n\n    msg!(\"Clock: {}\", clock.unix_timestamp);\n    msg!(\"Rent: {}\", rent.lamports_per_byte_year);\n\n    Ok(())\n}\n```\n\n**Supported sysvars:**\n- Clock\n- Rent\n- EpochSchedule\n- EpochRewards\n- Fees (deprecated)\n\n### Pattern 2: from_account_info - Account Access\n\n**Advantages:**\n- Works for all sysvars\n- Can be validated\n- Can be passed to CPIs\n- Required for some sysvars (SlotHashes, Instructions)\n\n**Disadvantages:**\n- Account must be passed in instruction\n- Slightly higher CU cost (~300 CU)\n- More boilerplate\n\n```rust\nuse solana_program::sysvar::clock;\n\npub fn use_sysvar_from_account(\n    clock_account: &AccountInfo,\n) -> ProgramResult {\n    // Validate account address\n    if clock_account.key != &clock::ID {\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    let clock = Clock::from_account_info(clock_account)?;\n    msg!(\"Clock: {}\", clock.unix_timestamp);\n\n    Ok(())\n}\n```\n\n**Required for:**\n- SlotHashes\n- StakeHistory\n- Instructions\n- Any sysvar passed to CPI\n\n### Pattern 3: Hybrid Approach\n\n**Use get() when possible, account when needed:**\n\n```rust\npub fn hybrid_sysvar_access(\n    accounts: &[AccountInfo],\n    need_cpi: bool,\n) -> ProgramResult {\n    if need_cpi {\n        // Need account for CPI\n        let account_info_iter = &mut accounts.iter();\n        let clock_account = next_account_info(account_info_iter)?;\n\n        let clock = Clock::from_account_info(clock_account)?;\n\n        // Can pass clock_account to CPI\n        msg!(\"Using account access\");\n    } else {\n        // Direct access is cheaper\n        let clock = Clock::get()?;\n        msg!(\"Using direct access\");\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Performance Implications\n\n### Compute Unit Costs\n\n| Access Method | Approximate CU Cost |\n|--------------|---------------------|\n| Clock::get() | ~100 CU |\n| Rent::get() | ~100 CU |\n| EpochSchedule::get() | ~100 CU |\n| Clock::from_account_info() | ~300 CU |\n| SlotHashes::from_account_info() | ~500 CU |\n\n### Optimization Tips\n\n**1. Use get() when possible:**\n\n```rust\n// ✅ Efficient - 100 CU\nlet clock = Clock::get()?;\n\n// ❌ Wasteful - 300 CU (unless needed for CPI)\nlet clock = Clock::from_account_info(clock_account)?;\n```\n\n**2. Cache sysvar values:**\n\n```rust\n// ❌ Wasteful - calls get() multiple times\nfor i in 0..10 {\n    let clock = Clock::get()?;  // 100 CU × 10 = 1000 CU\n    process_item(i, clock.unix_timestamp)?;\n}\n\n// ✅ Efficient - call once\nlet clock = Clock::get()?;  // 100 CU\nlet timestamp = clock.unix_timestamp;\nfor i in 0..10 {\n    process_item(i, timestamp)?;\n}\n```\n\n**3. Avoid unnecessary sysvar access:**\n\n```rust\n// ❌ Wasteful - reading sysvar in every call\npub fn update_balance(account: &AccountInfo, amount: u64) -> ProgramResult {\n    let clock = Clock::get()?;  // Not needed!\n    // ... no clock usage\n    Ok(())\n}\n\n// ✅ Efficient - only access when needed\npub fn update_with_timestamp(account: &AccountInfo, amount: u64) -> ProgramResult {\n    let clock = Clock::get()?;  // Used below\n    let timestamp = clock.unix_timestamp;\n    // ... use timestamp\n    Ok(())\n}\n```\n\n---\n\n## Best Practices\n\n### 1. Prefer get() Over from_account_info()\n\n**Unless you need the account for CPI or validation:**\n\n```rust\n// ✅ Default choice\nlet clock = Clock::get()?;\n\n// Only if needed for CPI\nlet clock = Clock::from_account_info(clock_account)?;\ninvoke(&ix, &[..., clock_account])?;\n```\n\n### 2. Validate Sysvar Accounts\n\n**When accepting sysvar accounts, always validate:**\n\n```rust\npub fn validate_clock_account(\n    clock_account: &AccountInfo,\n) -> ProgramResult {\n    // ✅ Always validate sysvar address\n    if clock_account.key != &solana_program::sysvar::clock::ID {\n        msg!(\"Invalid Clock account\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    Ok(())\n}\n```\n\n### 3. Use Clock for Timestamps, Not Slot Hashes\n\n**For simple time-based logic:**\n\n```rust\n// ✅ Simple and efficient\nlet clock = Clock::get()?;\nif clock.unix_timestamp >= unlock_time {\n    // unlock\n}\n\n// ❌ Overkill - SlotHashes is for verification, not timing\nlet slot_hashes = SlotHashes::get()?;\n// Complex slot-based timing logic\n```\n\n### 4. Cache Sysvar Values\n\n**Read once, use multiple times:**\n\n```rust\npub fn process_multiple_accounts(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    // ✅ Read once\n    let clock = Clock::get()?;\n    let timestamp = clock.unix_timestamp;\n\n    for account in accounts {\n        update_account_timestamp(account, timestamp)?;\n    }\n\n    Ok(())\n}\n```\n\n### 5. Document Sysvar Dependencies\n\n**Be explicit about which sysvars your program uses:**\n\n```rust\n/// Processes user staking\n///\n/// # Sysvars\n/// - Clock: for stake timestamp\n/// - Rent: for account validation\n///\n/// # Accounts\n/// - `[writable]` stake_account\n/// - `[signer]` user\npub fn process_stake(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let clock = Clock::get()?;\n    let rent = Rent::get()?;\n\n    // ...\n    Ok(())\n}\n```\n\n### 6. Handle Clock Drift\n\n**Don't assume unix_timestamp is perfectly accurate:**\n\n```rust\n// ❌ Risky - exact timestamp match\nif clock.unix_timestamp == expected_time {\n    // May never trigger\n}\n\n// ✅ Safe - use ranges\nif clock.unix_timestamp >= expected_time {\n    // Reliable\n}\n\n// ✅ Best - add tolerance for early/late\nconst TOLERANCE: i64 = 60; // 60 seconds\nif clock.unix_timestamp >= expected_time - TOLERANCE {\n    // Handles clock drift\n}\n```\n\n---\n\n## Summary\n\n**Key Takeaways:**\n\n1. **Use get() when possible** for lower CU costs and simpler code\n2. **Use from_account_info()** when passing to CPIs or for sysvars without get()\n3. **Always validate** sysvar account addresses when accepting them\n4. **Cache sysvar values** to avoid redundant reads\n5. **Understand timing limitations** - unix_timestamp is approximate\n\n**Most Common Sysvars:**\n\n| Sysvar | Primary Use | Access Method |\n|--------|------------|---------------|\n| **Clock** | Timestamps, epochs, slots | `Clock::get()` |\n| **Rent** | Rent exemption calculations | `Rent::get()` |\n| **EpochSchedule** | Epoch/slot calculations | `EpochSchedule::get()` |\n| **SlotHashes** | Recent slot verification | `from_account_info()` only |\n| **Instructions** | Transaction introspection | `from_account_info()` only |\n\n**Common Patterns:**\n\n```rust\n// Timestamp current event\nlet clock = Clock::get()?;\nevent.created_at = clock.unix_timestamp;\n\n// Validate rent exemption\nlet rent = Rent::get()?;\nif !rent.is_exempt(account.lamports(), account.data_len()) {\n    return Err(ProgramError::AccountNotRentExempt);\n}\n\n// Calculate rent for new account\nlet rent = Rent::get()?;\nlet min_balance = rent.minimum_balance(space);\n```\n\nSysvars provide essential cluster state to your programs. Master their access patterns for efficient, production-ready Solana development.\n",
        "solana/skills/solana-development/references/testing-frameworks.md": "# Solana Program Testing Frameworks\n\n**Detailed guide for Mollusk, LiteSVM, and Anchor testing frameworks**\n\nThis file provides comprehensive documentation for the main testing frameworks used in Solana program development. For an overview of the testing strategy and pyramid, see the related files.\n\n---\n\n## Related Testing Documentation\n\n- **[Testing Overview](./testing-overview.md)** - Testing pyramid structure and types of tests\n- **[Testing Best Practices](./testing-practices.md)** - Best practices, common patterns, and additional resources\n\n---\n\n## Table of Contents\n\n1. [Mollusk Testing](#mollusk-testing)\n2. [Anchor-Specific Testing](#anchor-specific-testing)\n3. [Native Rust Testing](#native-rust-testing)\n\n---\n\n## Mollusk Testing\n\n### What is Mollusk?\n\nMollusk is a lightweight test harness that provides a minified Solana Virtual Machine (SVM) environment for program testing. It creates a program execution pipeline directly from low-level SVM components without the overhead of a full validator.\n\n**Key characteristics:**\n- No validator runtime (no AccountsDB, Bank, or other large components)\n- Exceptionally fast test execution\n- Direct program ELF execution via BPF Loader\n- Requires explicit account lists (can't load from storage)\n- Configurable compute budget, feature set, and sysvars\n\n### Setup and Dependencies\n\n#### Version Compatibility\n\n**IMPORTANT:** Mollusk versions must match your Solana SDK version.\n\n**For Anchor 0.32.1 (Solana SDK 2.2.x):**\n```toml\n[dev-dependencies]\nmollusk-svm = \"0.5.1\"\nmollusk-svm-bencher = \"0.5.1\"\nmollusk-svm-programs-token = \"0.5.1\"\nsolana-sdk = \"2.2\"\nspl-token = \"7.0\"\nspl-associated-token-account = \"6.0\"\n```\n\n**Why 0.5.1?**\n- Anchor 0.32.1 uses Solana SDK 2.2.x internally\n- Mollusk 0.5.1 is the last version compatible with Solana 2.x\n- Mollusk 0.6.0+ uses Solana 3.0 and won't compile with Anchor 0.32.1\n\n**For Native Rust programs (Solana SDK 2.1.x or 2.2.x):**\n```toml\n[dev-dependencies]\nmollusk-svm = \"0.5.1\"\nsolana-sdk = \"2.2\"  # Or \"2.1\" depending on your program\n```\n\n**For newer Solana versions (3.0+):**\n```toml\n[dev-dependencies]\nmollusk-svm = \"0.9\"  # Latest version\nsolana-sdk = \"3.0\"\n```\n\n**How to check your Solana SDK version:**\n```bash\n# For Anchor projects\ngrep solana-program programs/*/Cargo.toml\n\n# For native Rust\ngrep solana-program Cargo.toml\n\n# Check Anchor's internal SDK version\ncargo tree | grep solana-sdk\n```\n\n#### Standard Dependencies\n\nFor testing with Token program:\n```toml\n[dev-dependencies]\nmollusk-svm-programs-token = \"0.5.1\"  # Match mollusk-svm version\nspl-token = \"7.0\"                      # For Solana 2.x\n```\n\nFor compute unit benchmarking:\n```toml\n[dev-dependencies]\nmollusk-svm-bencher = \"0.5.1\"  # Match mollusk-svm version\n```\n\n### Basic Test Structure\n\n```rust\nuse {\n    mollusk_svm::Mollusk,\n    solana_sdk::{\n        account::Account,\n        instruction::{AccountMeta, Instruction},\n        pubkey::Pubkey,\n    },\n};\n\n#[test]\nfn test_my_instruction() {\n    // 1. Initialize Mollusk with your program\n    let program_id = Pubkey::new_unique();\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    // 2. Setup accounts\n    let user = Pubkey::new_unique();\n    let accounts = vec![\n        (user, Account {\n            lamports: 1_000_000,\n            data: vec![],\n            owner: program_id,\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    // 3. Create instruction\n    let instruction = Instruction::new_with_bytes(\n        program_id,\n        &[0, 1, 2, 3],  // instruction data\n        vec![AccountMeta::new(user, true)],\n    );\n\n    // 4. Process instruction\n    let result = mollusk.process_instruction(&instruction, &accounts);\n\n    // 5. Assert success\n    assert!(result.is_ok());\n}\n```\n\n### Four Main API Methods\n\nMollusk provides four core testing methods:\n\n**1. `process_instruction`** - Execute single instruction, return result\n```rust\nlet result = mollusk.process_instruction(&instruction, &accounts);\n```\n\n**2. `process_and_validate_instruction`** - Execute and validate with checks\n```rust\nmollusk.process_and_validate_instruction(\n    &instruction,\n    &accounts,\n    &checks,\n);\n```\n\n**3. `process_instruction_chain`** - Execute multiple instructions sequentially\n```rust\nlet result = mollusk.process_instruction_chain(\n    &[instruction1, instruction2, instruction3],\n    &accounts,\n);\n```\n\n**4. `process_and_validate_instruction_chain`** - Execute chain with per-instruction checks\n```rust\nmollusk.process_and_validate_instruction_chain(\n    &[\n        (&instruction1, &[Check::success()]),\n        (&instruction2, &[Check::success()]),\n    ],\n    &accounts,\n);\n```\n\n### Creating Test Accounts\n\nTest accounts must be created explicitly with all required fields:\n\n```rust\nuse solana_sdk::account::Account;\n\n// Basic account\nlet account = Account {\n    lamports: 1_000_000,           // Account balance\n    data: vec![0; 100],             // Account data\n    owner: program_id,              // Owner program\n    executable: false,              // Not executable\n    rent_epoch: 0,                  // Rent epoch\n};\n\n// System account\nlet system_account = Account {\n    lamports: 1_000_000,\n    data: vec![],\n    owner: system_program::id(),\n    executable: false,\n    rent_epoch: 0,\n};\n\n// Rent-exempt account\nlet rent = mollusk.sysvars.rent;\nlet rent_exempt_account = Account {\n    lamports: rent.minimum_balance(data_len),\n    data: vec![0; data_len],\n    owner: program_id,\n    executable: false,\n    rent_epoch: 0,\n};\n```\n\n### Processing Instructions\n\n**Simple execution:**\n```rust\nlet result = mollusk.process_instruction(&instruction, &accounts);\nassert!(result.is_ok());\n```\n\n**With result inspection:**\n```rust\nlet result = mollusk.process_instruction(&instruction, &accounts);\nmatch result {\n    Ok(result) => {\n        println!(\"Compute units: {}\", result.compute_units_consumed);\n        // Access modified accounts from result\n    }\n    Err(err) => panic!(\"Instruction failed: {:?}\", err),\n}\n```\n\n### Validation with Check API\n\nThe `Check` enum provides common validation patterns:\n\n**Success checks:**\n```rust\nuse mollusk_svm::result::Check;\n\nlet checks = vec![\n    Check::success(),                          // Instruction succeeded\n    Check::compute_units(5000),                // Exact compute units\n];\n```\n\n**Account state checks:**\n```rust\nlet checks = vec![\n    Check::account(&pubkey)\n        .lamports(1_000_000)                   // Check lamports\n        .data(&[1, 2, 3, 4])                   // Check full data\n        .data_slice(8, &[1, 2, 3, 4])          // Check data slice at offset\n        .owner(&program_id)                     // Check owner\n        .executable(false)                      // Check executable flag\n        .space(100)                             // Check data length\n        .rent_exempt()                          // Check rent exempt\n        .build(),\n];\n```\n\n**Error checks:**\n```rust\nuse solana_sdk::instruction::InstructionError;\n\nlet checks = vec![\n    Check::instruction_err(InstructionError::InvalidInstructionData),\n];\n```\n\n**Complete validation example:**\n```rust\nuse {\n    mollusk_svm::{Mollusk, result::Check},\n    solana_sdk::{\n        account::Account,\n        instruction::Instruction,\n        pubkey::Pubkey,\n        system_instruction,\n        system_program,\n    },\n};\n\n#[test]\nfn test_system_transfer() {\n    let sender = Pubkey::new_unique();\n    let recipient = Pubkey::new_unique();\n\n    let base_lamports = 100_000_000;\n    let transfer_amount = 42_000;\n\n    let instruction = system_instruction::transfer(&sender, &recipient, transfer_amount);\n    let accounts = [\n        (\n            sender,\n            Account::new(base_lamports, 0, &system_program::id()),\n        ),\n        (\n            recipient,\n            Account::new(base_lamports, 0, &system_program::id()),\n        ),\n    ];\n\n    let checks = vec![\n        Check::success(),\n        Check::account(&sender)\n            .lamports(base_lamports - transfer_amount)\n            .build(),\n        Check::account(&recipient)\n            .lamports(base_lamports + transfer_amount)\n            .build(),\n    ];\n\n    Mollusk::default().process_and_validate_instruction(\n        &instruction,\n        &accounts,\n        &checks,\n    );\n}\n```\n\n### Compute Unit Benchmarking\n\nMonitor compute unit usage to catch performance regressions:\n\n**Basic benchmark:**\n```rust\nuse mollusk_svm_bencher::MolluskComputeUnitBencher;\n\nfn main() {\n    let program_id = Pubkey::new_unique();\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    MolluskComputeUnitBencher::new(mollusk)\n        .bench((\"my_instruction\", &instruction, &accounts))\n        .must_pass(true)\n        .out_dir(\"./target/benches\")\n        .execute();\n}\n```\n\n**Benchmark multiple instructions:**\n```rust\nfn main() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n    let bencher = MolluskComputeUnitBencher::new(mollusk);\n\n    bencher.bench((\"initialize\", &init_ix, &init_accounts))\n        .must_pass(true);\n\n    bencher.bench((\"update\", &update_ix, &update_accounts))\n        .must_pass(true);\n\n    bencher.bench((\"close\", &close_ix, &close_accounts))\n        .must_pass(true)\n        .out_dir(\"./target/benches\")\n        .execute();\n}\n```\n\nRun benchmarks with:\n```bash\ncargo bench\n```\n\nOutput includes:\n- Current compute units consumed\n- Previous benchmark value\n- Delta (increase/decrease)\n- Pass/fail status\n\n### Advanced Patterns\n\n#### Stateful Context Testing\n\nUse `MolluskContext` to persist account state across multiple instructions:\n\n```rust\nuse std::collections::HashMap;\n\n#[test]\nfn test_sequential_transfers() {\n    let mollusk = Mollusk::default();\n\n    // Create initial account store\n    let mut account_store = HashMap::new();\n    let alice = Pubkey::new_unique();\n    let bob = Pubkey::new_unique();\n\n    account_store.insert(\n        alice,\n        Account {\n            lamports: 1_000_000,\n            data: vec![],\n            owner: system_program::id(),\n            executable: false,\n            rent_epoch: 0,\n        },\n    );\n\n    account_store.insert(\n        bob,\n        Account {\n            lamports: 0,\n            data: vec![],\n            owner: system_program::id(),\n            executable: false,\n            rent_epoch: 0,\n        },\n    );\n\n    // Create stateful context\n    let context = mollusk.with_context(account_store);\n\n    // First transfer - state persists automatically\n    let instruction1 = system_instruction::transfer(&alice, &bob, 200_000);\n    context.process_instruction(&instruction1);\n\n    // Second transfer - uses updated state from first transfer\n    let instruction2 = system_instruction::transfer(&alice, &bob, 100_000);\n    context.process_instruction(&instruction2);\n\n    // Access final account state\n    let store = context.account_store.borrow();\n    assert_eq!(store.get(&alice).unwrap().lamports, 700_000);\n    assert_eq!(store.get(&bob).unwrap().lamports, 300_000);\n}\n```\n\n#### Instruction Chains with Validation\n\nProcess multiple instructions and validate state after each:\n\n```rust\n#[test]\nfn test_instruction_chain_with_checks() {\n    let mollusk = Mollusk::default();\n\n    let alice = Pubkey::new_unique();\n    let bob = Pubkey::new_unique();\n    let carol = Pubkey::new_unique();\n\n    let starting_lamports = 1_000_000;\n\n    mollusk.process_and_validate_instruction_chain(\n        &[\n            (\n                &system_instruction::transfer(&alice, &bob, 300_000),\n                &[\n                    Check::success(),\n                    Check::account(&alice).lamports(700_000).build(),\n                    Check::account(&bob).lamports(300_000).build(),\n                ],\n            ),\n            (\n                &system_instruction::transfer(&bob, &carol, 100_000),\n                &[\n                    Check::success(),\n                    Check::account(&bob).lamports(200_000).build(),\n                    Check::account(&carol).lamports(100_000).build(),\n                ],\n            ),\n        ],\n        &[\n            (alice, system_account(starting_lamports)),\n            (bob, system_account(0)),\n            (carol, system_account(0)),\n        ],\n    );\n}\n```\n\n**Important:** Instruction chains are NOT equivalent to Solana transactions. Mollusk doesn't impose transaction constraints like loaded account keys or size limits. Chains are primarily for testing program execution flows.\n\n#### Time-Dependent Testing with warp_to_slot\n\nTest logic that depends on clock or slot:\n\n```rust\nuse solana_sdk::clock::Clock;\n\n#[test]\nfn test_time_dependent_logic() {\n    let mut mollusk = Mollusk::default();\n\n    // Warp to a specific slot\n    mollusk.warp_to_slot(1000);\n\n    // Test logic that depends on clock.slot\n    let result1 = mollusk.process_instruction(&time_check_ix, &accounts);\n    assert!(result1.is_ok());\n\n    // Warp forward in time\n    mollusk.warp_to_slot(2000);\n\n    // Test again with new slot\n    let result2 = mollusk.process_instruction(&time_check_ix, &accounts);\n    assert!(result2.is_ok());\n}\n```\n\n#### Custom Sysvar Configuration\n\nModify sysvars to test specific conditions:\n\n```rust\nuse solana_sdk::rent::Rent;\n\n#[test]\nfn test_with_custom_rent() {\n    let mut mollusk = Mollusk::default();\n\n    // Customize rent parameters\n    mollusk.sysvars.rent = Rent {\n        lamports_per_byte_year: 1,\n        exemption_threshold: 1.0,\n        burn_percent: 0,\n    };\n\n    // Test with custom rent configuration\n    let result = mollusk.process_instruction(&instruction, &accounts);\n    assert!(result.is_ok());\n}\n```\n\n#### Testing with Built-in Programs\n\n**Default builtins:**\n```rust\n// Mollusk::default() includes subset of builtin programs\nlet mollusk = Mollusk::default();  // Includes System, BPF Loader, etc.\n```\n\n**All builtins:**\n```toml\n[dev-dependencies]\nmollusk-svm = { version = \"0.9\", features = [\"all-builtins\"] }\n```\n\n**Adding specific programs:**\n```rust\nuse mollusk_svm_programs_token::token;\n\nlet mut mollusk = Mollusk::default();\ntoken::add_program(&mut mollusk);  // Add Token program\n```\n\n---\n\n## Anchor-Specific Testing\n\n### anchor test Command and Workflow\n\nAnchor provides integrated testing via the `anchor test` command:\n\n```bash\n# Run all tests\nanchor test\n\n# Run tests without rebuilding\nanchor test --skip-build\n\n# Run tests without deploying (use existing deployment)\nanchor test --skip-deploy\n\n# Run specific test file\nanchor test -- --test test_initialize\n\n# Show program logs\nanchor test -- --nocapture\n```\n\n**Standard workflow:**\n1. `anchor build` - Build program\n2. `anchor test` - Deploy to local validator and run TypeScript tests\n3. Test files run against deployed program\n4. Validator shuts down after tests complete\n\n### TypeScript Tests with @coral-xyz/anchor\n\n**Basic test structure:**\n\n```typescript\nimport * as anchor from \"@coral-xyz/anchor\";\nimport { Program } from \"@coral-xyz/anchor\";\nimport { MyProgram } from \"../target/types/my_program\";\nimport { expect } from \"chai\";\n\ndescribe(\"my-program\", () => {\n  // Configure the client to use the local cluster\n  anchor.setProvider(anchor.AnchorProvider.env());\n\n  const program = anchor.workspace.MyProgram as Program<MyProgram>;\n\n  it(\"Initializes the program\", async () => {\n    // Test implementation\n  });\n});\n```\n\n### Setting Up Test Environment\n\n```typescript\ndescribe(\"my-program\", () => {\n  const provider = anchor.AnchorProvider.env();\n  anchor.setProvider(provider);\n\n  const program = anchor.workspace.MyProgram as Program<MyProgram>;\n  const wallet = provider.wallet as anchor.Wallet;\n\n  // Generate keypairs\n  const user = anchor.web3.Keypair.generate();\n  const account = anchor.web3.Keypair.generate();\n\n  before(async () => {\n    // Airdrop SOL for testing\n    const airdropSig = await provider.connection.requestAirdrop(\n      user.publicKey,\n      2 * anchor.web3.LAMPORTS_PER_SOL\n    );\n    await provider.connection.confirmTransaction(airdropSig);\n  });\n\n  it(\"runs test\", async () => {\n    // Test code\n  });\n});\n```\n\n### Invoking Instructions\n\n```typescript\nit(\"initializes account\", async () => {\n  const [pda, bump] = anchor.web3.PublicKey.findProgramAddressSync(\n    [Buffer.from(\"seed\"), user.publicKey.toBuffer()],\n    program.programId\n  );\n\n  const tx = await program.methods\n    .initialize(bump)\n    .accounts({\n      user: user.publicKey,\n      account: pda,\n      systemProgram: anchor.web3.SystemProgram.programId,\n    })\n    .signers([user])\n    .rpc();\n\n  console.log(\"Transaction signature:\", tx);\n});\n```\n\n**With custom transaction options:**\n```typescript\nconst tx = await program.methods\n  .initialize(bump)\n  .accounts({ /* ... */ })\n  .signers([user])\n  .rpc({\n    skipPreflight: false,\n    commitment: \"confirmed\",\n  });\n```\n\n### Reading Account State\n\n```typescript\nit(\"reads account data\", async () => {\n  // Fetch account data\n  const accountData = await program.account.myAccount.fetch(accountPubkey);\n\n  // Assert values\n  expect(accountData.value).to.equal(42);\n  expect(accountData.owner.toString()).to.equal(user.publicKey.toString());\n});\n\n// Fetch multiple accounts\nconst accounts = await program.account.myAccount.all();\nconsole.log(\"Found accounts:\", accounts.length);\n\n// Fetch with filters\nconst filtered = await program.account.myAccount.all([\n  {\n    memcmp: {\n      offset: 8,  // Skip discriminator\n      bytes: user.publicKey.toBase58(),\n    },\n  },\n]);\n```\n\n### Event Listeners\n\n```typescript\nit(\"listens for events\", async () => {\n  let eventReceived = false;\n\n  // Set up event listener\n  const listener = program.addEventListener(\n    \"MyEvent\",\n    (event, slot) => {\n      console.log(\"Event received in slot:\", slot);\n      console.log(\"Event data:\", event);\n      eventReceived = true;\n    }\n  );\n\n  // Trigger event\n  await program.methods\n    .triggerEvent()\n    .accounts({ /* ... */ })\n    .rpc();\n\n  // Wait for event\n  await new Promise((resolve) => setTimeout(resolve, 1000));\n\n  expect(eventReceived).to.be.true;\n\n  // Clean up listener\n  await program.removeEventListener(listener);\n});\n```\n\n### LiteSVM for Fast Anchor Tests\n\nLiteSVM provides a faster alternative to the full validator for Anchor tests:\n\n**Installation:**\n```bash\ncargo add litesvm --dev\n```\n\n**Basic usage:**\n```rust\nuse {\n    litesvm::LiteSVM,\n    solana_sdk::{\n        message::Message,\n        pubkey::Pubkey,\n        signature::{Keypair, Signer},\n        system_instruction::transfer,\n        transaction::Transaction,\n    },\n};\n\n#[test]\nfn test_with_litesvm() {\n    let from_keypair = Keypair::new();\n    let from = from_keypair.pubkey();\n    let to = Pubkey::new_unique();\n\n    let mut svm = LiteSVM::new();\n    svm.airdrop(&from, 10_000).unwrap();\n\n    let instruction = transfer(&from, &to, 64);\n    let tx = Transaction::new(\n        &[&from_keypair],\n        Message::new(&[instruction], Some(&from)),\n        svm.latest_blockhash(),\n    );\n    let tx_res = svm.send_transaction(tx).unwrap();\n\n    let from_account = svm.get_account(&from);\n    let to_account = svm.get_account(&to);\n    assert_eq!(from_account.unwrap().lamports, 4936);\n    assert_eq!(to_account.unwrap().lamports, 64);\n}\n```\n\n**Deploying programs:**\n```rust\nuse solana_sdk::pubkey;\n\n#[test]\nfn test_program() {\n    let program_id = pubkey!(\"Logging111111111111111111111111111111111111\");\n    let mut svm = LiteSVM::new();\n\n    // Load program from file\n    let bytes = include_bytes!(\"../target/deploy/my_program.so\");\n    svm.add_program(program_id, bytes);\n\n    // Test program\n    // ...\n}\n```\n\n**Time travel with LiteSVM:**\n```rust\nuse solana_sdk::clock::Clock;\n\n#[test]\nfn test_set_clock() {\n    let mut svm = LiteSVM::new();\n\n    // Get current clock\n    let mut clock = svm.get_sysvar::<Clock>();\n\n    // Set specific timestamp\n    clock.unix_timestamp = 1735689600;  // January 1st 2025\n    svm.set_sysvar::<Clock>(&clock);\n\n    // Test time-dependent logic\n    // ...\n\n    // Warp to specific slot\n    svm.warp_to_slot(1000);\n}\n```\n\n**Writing arbitrary accounts:**\n```rust\nuse {\n    solana_sdk::account::Account,\n    spl_token::state::Account as TokenAccount,\n};\n\n#[test]\nfn test_with_token_account() {\n    let mut svm = LiteSVM::new();\n\n    let user = Pubkey::new_unique();\n    let usdc_mint = pubkey!(\"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\");\n\n    // Create fake USDC balance\n    let token_account_data = /* serialize TokenAccount with balance */;\n\n    svm.set_account(\n        user,\n        Account {\n            lamports: 1_000_000,\n            data: token_account_data,\n            owner: spl_token::id(),\n            executable: false,\n            rent_epoch: 0,\n        },\n    );\n\n    // Test with USDC balance\n    // ...\n}\n```\n\n### Anchor.toml Test Configuration\n\nConfigure testing behavior in `Anchor.toml`:\n\n```toml\n[toolchain]\nanchor_version = \"0.30.1\"\n\n[features]\nresolution = true\nskip-lint = false\n\n[programs.localnet]\nmy_program = \"Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS\"\n\n[registry]\nurl = \"https://api.apr.dev\"\n\n[provider]\ncluster = \"Localnet\"\nwallet = \"~/.config/solana/id.json\"\n\n[scripts]\ntest = \"yarn run ts-mocha -p ./tsconfig.json -t 1000000 tests/**/*.ts\"\n\n[test]\nstartup_wait = 5000  # Wait before running tests (ms)\nshutdown_wait = 2000  # Wait before shutting down validator (ms)\nupgradeable = false  # Deploy as upgradeable program\n\n[test.validator]\nurl = \"https://api.mainnet-beta.solana.com\"  # Clone from mainnet\nledger = \".anchor/test-ledger\"\nbind_address = \"0.0.0.0\"\n\n[[test.validator.clone]]\naddress = \"metaqbxxUerdq28cj1RbAWkYQm3ybzjb6a8bt518x1s\"  # Clone Metaplex\n\n[[test.validator.clone]]\naddress = \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\"  # Clone Token program\n\n[[test.validator.account]]\naddress = \"...\"  # Clone specific account\nfilename = \"account.json\"\n```\n\n### Anchor Testing Best Practices\n\n1. **Use `anchor.workspace`**: Automatically loads program IDL\n2. **Airdrop SOL in `before()` hooks**: Set up test accounts before tests\n3. **Use proper commitment levels**: `confirmed` or `finalized` for reliability\n4. **Test error conditions**: Use `.simulate()` to test expected failures\n5. **Clean up between tests**: Reset account state or use fresh keypairs\n6. **Use `--skip-build` during iteration**: Speed up test runs\n7. **Test with realistic data**: Don't just test happy paths\n\n---\n\n## Native Rust Testing\n\n### Cargo Test Setup\n\nNative Rust programs use standard Rust testing with Mollusk:\n\n**Project structure:**\n```\nmy-program/\n├── Cargo.toml\n├── src/\n│   ├── lib.rs\n│   ├── processor.rs\n│   └── instruction.rs\n└── tests/\n    ├── test_initialize.rs\n    ├── test_update.rs\n    └── test_close.rs\n```\n\n**Cargo.toml configuration:**\n```toml\n[package]\nname = \"my-program\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\ncrate-type = [\"cdylib\", \"lib\"]\n\n[dependencies]\nsolana-program = \"2.1\"\n\n[dev-dependencies]\nmollusk-svm = \"0.9\"\nmollusk-svm-programs-token = \"0.9\"\nsolana-sdk = \"2.1\"\n\n[[bench]]\nname = \"compute_units\"\nharness = false\n\n[profile.release]\noverflow-checks = true\nlto = \"fat\"\ncodegen-units = 1\n\n[profile.release.build-override]\nopt-level = 3\nincremental = false\ncodegen-units = 1\n```\n\n### Mollusk with Native Programs\n\n**Basic test example:**\n\n```rust\n// tests/test_initialize.rs\nuse {\n    mollusk_svm::Mollusk,\n    my_program::{instruction::initialize, ID},\n    solana_sdk::{\n        account::Account,\n        instruction::{AccountMeta, Instruction},\n        pubkey::Pubkey,\n    },\n};\n\n#[test]\nfn test_initialize() {\n    let program_id = ID;\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let account = Pubkey::new_unique();\n\n    let instruction = Instruction {\n        program_id,\n        accounts: vec![\n            AccountMeta::new(user, true),\n            AccountMeta::new(account, false),\n            AccountMeta::new_readonly(solana_sdk::system_program::id(), false),\n        ],\n        data: initialize().data,\n    };\n\n    let accounts = vec![\n        (user, Account {\n            lamports: 10_000_000,\n            data: vec![],\n            owner: solana_sdk::system_program::id(),\n            executable: false,\n            rent_epoch: 0,\n        }),\n        (account, Account {\n            lamports: 0,\n            data: vec![],\n            owner: solana_sdk::system_program::id(),\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    let result = mollusk.process_instruction(&instruction, &accounts);\n    assert!(result.is_ok());\n}\n```\n\n### Manual Account Setup\n\nNative Rust tests require explicit account setup:\n\n```rust\nuse solana_sdk::account::Account;\n\n// Helper: Create system account\nfn system_account(lamports: u64) -> Account {\n    Account {\n        lamports,\n        data: vec![],\n        owner: solana_sdk::system_program::id(),\n        executable: false,\n        rent_epoch: 0,\n    }\n}\n\n// Helper: Create program-owned account\nfn program_account(lamports: u64, data: Vec<u8>, owner: Pubkey) -> Account {\n    Account {\n        lamports,\n        data,\n        owner,\n        executable: false,\n        rent_epoch: 0,\n    }\n}\n\n// Helper: Create rent-exempt account\nfn rent_exempt_account(data_len: usize, owner: Pubkey, mollusk: &Mollusk) -> Account {\n    let lamports = mollusk.sysvars.rent.minimum_balance(data_len);\n    Account {\n        lamports,\n        data: vec![0; data_len],\n        owner,\n        executable: false,\n        rent_epoch: 0,\n    }\n}\n\n// Usage\n#[test]\nfn test_with_helpers() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let data_account = Pubkey::new_unique();\n\n    let accounts = vec![\n        (user, system_account(10_000_000)),\n        (data_account, rent_exempt_account(100, program_id, &mollusk)),\n    ];\n\n    // Test\n    // ...\n}\n```\n\n### Testing CPIs\n\nUse `mollusk-svm-programs-token` for testing cross-program invocations:\n\n```rust\nuse {\n    mollusk_svm::{result::Check, Mollusk},\n    mollusk_svm_programs_token::token,\n    solana_sdk::{\n        account::Account,\n        program_pack::Pack,\n        pubkey::Pubkey,\n    },\n    spl_token::state::{Account as TokenAccount, AccountState, Mint},\n};\n\n#[test]\nfn test_token_transfer_cpi() {\n    // Initialize Mollusk with Token program\n    let mut mollusk = Mollusk::default();\n    token::add_program(&mut mollusk);\n\n    // Setup mint\n    let mint = Pubkey::new_unique();\n    let decimals = 6;\n\n    let mut mint_data = vec![0u8; Mint::LEN];\n    Mint::pack(\n        Mint {\n            mint_authority: Some(authority).into(),\n            supply: 1_000_000,\n            decimals,\n            is_initialized: true,\n            freeze_authority: None.into(),\n        },\n        &mut mint_data,\n    ).unwrap();\n\n    // Setup source token account\n    let source = Pubkey::new_unique();\n    let mut source_data = vec![0u8; TokenAccount::LEN];\n    TokenAccount::pack(\n        TokenAccount {\n            mint,\n            owner: authority,\n            amount: 1_000_000,\n            delegate: None.into(),\n            state: AccountState::Initialized,\n            is_native: None.into(),\n            delegated_amount: 0,\n            close_authority: None.into(),\n        },\n        &mut source_data,\n    ).unwrap();\n\n    // Setup destination token account\n    let destination = Pubkey::new_unique();\n    let mut dest_data = vec![0u8; TokenAccount::LEN];\n    TokenAccount::pack(\n        TokenAccount {\n            mint,\n            owner: recipient,\n            amount: 0,\n            delegate: None.into(),\n            state: AccountState::Initialized,\n            is_native: None.into(),\n            delegated_amount: 0,\n            close_authority: None.into(),\n        },\n        &mut dest_data,\n    ).unwrap();\n\n    let mint_rent = mollusk.sysvars.rent.minimum_balance(Mint::LEN);\n    let account_rent = mollusk.sysvars.rent.minimum_balance(TokenAccount::LEN);\n\n    let accounts = vec![\n        (source, Account {\n            lamports: account_rent,\n            data: source_data,\n            owner: token::ID,\n            executable: false,\n            rent_epoch: 0,\n        }),\n        (mint, Account {\n            lamports: mint_rent,\n            data: mint_data,\n            owner: token::ID,\n            executable: false,\n            rent_epoch: 0,\n        }),\n        (destination, Account {\n            lamports: account_rent,\n            data: dest_data,\n            owner: token::ID,\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    // Create transfer instruction\n    use spl_token::instruction::transfer_checked;\n\n    let instruction = transfer_checked(\n        &token::ID,\n        &source,\n        &mint,\n        &destination,\n        &authority,\n        &[],\n        500_000,\n        decimals,\n    ).unwrap();\n\n    // Validate transfer\n    let checks = vec![\n        Check::success(),\n        Check::account(&source)\n            .data_slice(64, &(500_000u64).to_le_bytes())\n            .build(),\n        Check::account(&destination)\n            .data_slice(64, &(500_000u64).to_le_bytes())\n            .build(),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n### Validation Patterns\n\n**Account state validation:**\n```rust\nuse mollusk_svm::result::Check;\n\nlet checks = vec![\n    Check::success(),\n    Check::account(&account_pubkey)\n        .lamports(expected_lamports)\n        .data(&expected_data)\n        .owner(&expected_owner)\n        .build(),\n];\n\nmollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n```\n\n**Error validation:**\n```rust\nuse solana_sdk::instruction::InstructionError;\n\nlet checks = vec![\n    Check::instruction_err(InstructionError::InvalidAccountData),\n];\n\nmollusk.process_and_validate_instruction(&bad_instruction, &accounts, &checks);\n```\n\n**Compute unit validation:**\n```rust\nlet checks = vec![\n    Check::success(),\n    Check::compute_units(5000),  // Exactly 5000 CU\n];\n```\n\n**Data slice validation:**\n```rust\n// Check specific bytes without loading full account data\nlet checks = vec![\n    Check::account(&account)\n        .data_slice(8, &[1, 2, 3, 4])  // Check bytes 8-11\n        .build(),\n];\n```\n\n---\n\n## Next Steps\n\n- For the testing strategy overview and pyramid structure, see **[Testing Overview](./testing-overview.md)**\n- For best practices, common patterns, and additional resources, see **[Testing Best Practices](./testing-practices.md)**\n",
        "solana/skills/solana-development/references/testing-overview.md": "# Solana Program Testing Overview\n\n**High-level guide to testing Solana programs with the test pyramid structure**\n\nThis file provides an overview of Solana program testing, the testing pyramid structure, and the types of tests you should write. For specific implementation details and framework-specific guidance, see the related files.\n\n---\n\n## Related Testing Documentation\n\n- **[Testing Frameworks](./testing-frameworks.md)** - Mollusk, LiteSVM, and Anchor testing implementations\n- **[Testing Best Practices](./testing-practices.md)** - Best practices, common patterns, and additional resources\n\n---\n\n## Table of Contents\n\n1. [Why Testing Matters](#why-testing-matters)\n2. [Types of Tests](#types-of-tests)\n3. [Testing Frameworks Available](#testing-frameworks-available)\n4. [Test Structure Pyramid](#test-structure-pyramid)\n\n---\n\n## Why Testing Matters for Solana Programs\n\nSolana programs are immutable after deployment and handle real financial assets. Comprehensive testing is critical to:\n\n- **Prevent loss of funds**: Bugs in deployed programs can lead to irreversible financial losses\n- **Ensure correctness**: Verify program logic works as intended under all conditions\n- **Optimize performance**: Monitor compute unit usage to stay within Solana's limits (1.4M CU cap)\n- **Build confidence**: Thorough testing enables safer deployments and upgrades\n- **Catch edge cases**: Test boundary conditions, error handling, and attack vectors\n\n---\n\n## Types of Tests\n\n**Unit Tests**\n- Test individual functions and instruction handlers in isolation\n- Fast, focused validation of specific logic\n- Run frequently during development\n\n**Integration Tests**\n- Test complete instruction flows with realistic account setups\n- Validate cross-program invocations (CPIs)\n- Ensure proper state transitions\n\n**Fuzz Tests**\n- Generate random inputs to find edge cases and vulnerabilities\n- Discover unexpected failure modes\n- Test input validation thoroughly\n\n**Compute Unit Benchmarks**\n- Monitor compute unit consumption for each instruction\n- Track performance regressions\n- Ensure programs stay within CU limits\n\n---\n\n## Testing Frameworks Available\n\n**Mollusk** (Recommended for both Anchor and Native Rust)\n- Lightweight SVM test harness\n- Exceptionally fast (no validator overhead)\n- Works with both Anchor and native Rust programs\n- Direct program execution via BPF loader\n- Requires explicit account setup (no AccountsDB)\n\n**LiteSVM** (Alternative for integration tests)\n- In-process Solana VM for testing\n- Available in Rust, TypeScript, and Python\n- Faster than solana-program-test\n- Supports RPC-like interactions\n- Good for complex integration scenarios\n\n**Anchor Test** (Anchor framework)\n- TypeScript-based testing using @coral-xyz/anchor\n- Integrates with local validator or LiteSVM\n- Natural for testing Anchor programs from client perspective\n- Slower but more realistic end-to-end tests\n\n**solana-program-test** (Legacy)\n- Full validator simulation\n- More realistic but much slower\n- Generally replaced by Mollusk and LiteSVM\n\n**Recommendation**: Use Mollusk for fast unit and integration tests. Use LiteSVM or Anchor tests for end-to-end validation when needed.\n\n---\n\n## Test Structure Pyramid\n\n### Overview\n\nA production-grade Solana program should have a multi-level testing strategy. Each level serves a specific purpose and catches different types of bugs.\n\n```\n                    ┌─────────────────────┐\n                    │  Devnet/Mainnet     │  ← Smoke tests\n                    │  Smoke Tests        │    (Manual, slow)\n                    └─────────────────────┘\n                  ┌───────────────────────────┐\n                  │   SDK Integration Tests   │  ← Full transaction flow\n                  │   (LiteSVM/TypeScript)    │    (Seconds per test)\n                  └───────────────────────────┘\n              ┌─────────────────────────────────────┐\n              │      Mollusk Program Tests          │  ← Instruction-level\n              │   (Unit + Integration in Rust)      │    (~100ms per test)\n              └─────────────────────────────────────┘\n          ┌───────────────────────────────────────────────┐\n          │        Inline Unit Tests (#[cfg(test)])       │  ← Pure functions\n          │    (Math, validation, transformations)        │    (Milliseconds)\n          └───────────────────────────────────────────────┘\n```\n\n### Level 1: Inline Unit Tests\n\n**Purpose:** Test pure functions in isolation - math, validation logic, data transformations.\n\n**Location:** Inside your program code with `#[cfg(test)]`\n\n**Why needed:**\n- Instant feedback (milliseconds)\n- Runs with `cargo test` - no build artifacts needed\n- Catches arithmetic edge cases before they reach the SVM\n- Documents expected behavior inline with code\n\n**What belongs here:**\n- Share calculations: `1_000_000 * 5000 / 10000 = 500_000`\n- Overflow detection: `u64::MAX * 10000 = None`\n- Rounding behavior: `100 * 1 / 10000 = 0` (floors)\n- BPS (basis points) sum validation\n- Data serialization/deserialization helpers\n\n**What doesn't belong:**\n- Account validation (needs ownership checks)\n- CPI logic\n- Full instruction execution\n- State transitions\n\n**Example:**\n```rust\n// In your program code (e.g., src/math.rs)\npub fn calculate_fee(amount: u64, fee_bps: u16) -> Option<u64> {\n    let fee = (amount as u128)\n        .checked_mul(fee_bps as u128)?\n        .checked_div(10_000)?;\n\n    Some(fee as u64)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_calculate_fee_basic() {\n        assert_eq!(calculate_fee(1_000_000, 250), Some(25_000)); // 2.5%\n        assert_eq!(calculate_fee(1_000_000, 5000), Some(500_000)); // 50%\n    }\n\n    #[test]\n    fn test_calculate_fee_rounding() {\n        assert_eq!(calculate_fee(100, 1), Some(0)); // Rounds down\n        assert_eq!(calculate_fee(10_000, 1), Some(1)); // 0.01%\n    }\n\n    #[test]\n    fn test_calculate_fee_overflow() {\n        assert_eq!(calculate_fee(u64::MAX, 10000), None); // Would overflow\n    }\n}\n```\n\n### Level 2: Mollusk Program Tests\n\n**Purpose:** Test individual instructions with full account setup but without validator overhead.\n\n**Location:** `tests/` directory or `#[cfg(test)]` modules\n\n**Why needed:**\n- Tests actual program binary execution\n- Validates account constraints, signer checks, ownership\n- ~100ms per test vs ~1s for full validator\n- Catches instruction-level bugs\n- Compute unit benchmarking\n\n**What belongs here:**\n- Each instruction handler (initialize, create_split, execute_split, etc.)\n- Error conditions (wrong signer, invalid account owner)\n- Account state transitions\n- Cross-program invocations (CPIs)\n- PDA derivation and signing\n- Rent exemption validation\n\n**Example:**\n```rust\n// tests/test_initialize.rs\nuse {\n    mollusk_svm::Mollusk,\n    my_program::{instruction::initialize, ID},\n    solana_sdk::{\n        account::Account,\n        instruction::Instruction,\n        pubkey::Pubkey,\n    },\n};\n\n#[test]\nfn test_initialize_success() {\n    let mollusk = Mollusk::new(&ID, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let account = Pubkey::new_unique();\n\n    let instruction = initialize(&user, &account);\n    let accounts = vec![\n        (user, system_account(10_000_000)),\n        (account, Account::default()),\n    ];\n\n    let result = mollusk.process_instruction(&instruction, &accounts);\n    assert!(result.is_ok());\n}\n\n#[test]\nfn test_initialize_wrong_signer_fails() {\n    let mollusk = Mollusk::new(&ID, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let wrong_signer = Pubkey::new_unique();\n\n    let mut instruction = initialize(&user, &Pubkey::new_unique());\n    instruction.accounts[0].is_signer = false; // Missing signature\n\n    let accounts = vec![(user, system_account(10_000_000))];\n\n    let checks = vec![Check::instruction_err(\n        InstructionError::MissingRequiredSignature\n    )];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n### Level 3: SDK Integration Tests\n\n**Purpose:** Test that SDK produces correct instructions that work end-to-end.\n\n**Location:** Separate SDK package (`sdk/tests/`) or TypeScript tests\n\n**Why needed:**\n- Validates serialization matches program expectations\n- Tests full transaction flow (multiple instructions)\n- Catches SDK bugs before users hit them\n- Client-perspective testing\n- Ensures TypeScript/Rust SDK matches program\n\n**What belongs here:**\n- SDK instruction builders produce valid transactions\n- Full flows: create → deposit → execute\n- Multiple instructions in one transaction\n- Account resolution (finding PDAs from SDK)\n- Error handling from client side\n- Event parsing and decoding\n\n**Example (LiteSVM):**\n```rust\n// sdk/tests/integration_test.rs\nuse {\n    litesvm::LiteSVM,\n    my_program_sdk::{instructions, MyProgramClient},\n    solana_sdk::{\n        signature::Keypair,\n        signer::Signer,\n    },\n};\n\n#[test]\nfn test_full_flow_create_and_execute() {\n    let mut svm = LiteSVM::new();\n\n    // Add program\n    let program_bytes = include_bytes!(\"../../target/deploy/my_program.so\");\n    svm.add_program(MY_PROGRAM_ID, program_bytes);\n\n    // Create client\n    let payer = Keypair::new();\n    svm.airdrop(&payer.pubkey(), 10_000_000_000).unwrap();\n\n    let client = MyProgramClient::new(&svm, &payer);\n\n    // Step 1: Initialize\n    let tx1 = client.initialize().unwrap();\n    svm.send_transaction(tx1).unwrap();\n\n    // Step 2: Deposit\n    let tx2 = client.deposit(1_000_000).unwrap();\n    svm.send_transaction(tx2).unwrap();\n\n    // Step 3: Execute\n    let tx3 = client.execute().unwrap();\n    let result = svm.send_transaction(tx3).unwrap();\n\n    // Verify final state\n    let account = client.get_account().unwrap();\n    assert_eq!(account.balance, 1_000_000);\n}\n```\n\n### Level 4: Devnet/Mainnet Smoke Tests\n\n**Purpose:** Final validation in real environment.\n\n**Location:** Manual testing or automated CI scripts\n\n**Why needed:**\n- Real RPC, real fees, real constraints\n- Validates deployment configuration\n- Tests against actual on-chain state\n- Catches environment-specific issues\n- Verifies upgrades work correctly\n\n**What belongs here:**\n- Post-deployment smoke tests (critical paths only)\n- Upgrade validation (new version works)\n- Integration with other mainnet programs\n- Performance under real network conditions\n\n**Example (Manual script):**\n```bash\n#!/bin/bash\n# scripts/smoke-test-devnet.sh\n\necho \"Running devnet smoke tests...\"\n\n# Test 1: Initialize\nsolana-keygen new --no-bpf-loader-deprecated --force -o /tmp/test-user.json\nsolana airdrop 2 /tmp/test-user.json --url devnet\n\nmy-program-cli initialize \\\n  --program-id $PROGRAM_ID \\\n  --payer /tmp/test-user.json \\\n  --url devnet\n\n# Test 2: Execute main flow\nmy-program-cli execute \\\n  --amount 1000000 \\\n  --payer /tmp/test-user.json \\\n  --url devnet\n\necho \"✅ Smoke tests passed\"\n```\n\n### How to Use This Pyramid\n\n**During development:**\n1. Write inline tests as you implement math/validation\n2. Write Mollusk tests for each instruction\n3. Run frequently: `cargo test`\n\n**Before PR/merge:**\n1. Ensure all inline + Mollusk tests pass\n2. Add SDK integration tests if SDK changed\n3. Run compute unit benchmarks\n\n**Before deployment:**\n1. All tests pass on devnet-compatible build\n2. Deploy to devnet\n3. Run manual smoke tests on devnet\n4. If pass, proceed to mainnet\n\n**After deployment:**\n1. Run smoke tests on mainnet\n2. Monitor for errors\n3. Keep tests updated as program evolves\n\n### Benefits of This Structure\n\n**Fast feedback loop:**\n- Level 1 tests run in milliseconds\n- Catch bugs early without slow iteration\n\n**Comprehensive coverage:**\n- Pure logic (Level 1)\n- Program execution (Level 2)\n- Client integration (Level 3)\n- Real environment (Level 4)\n\n**Efficient CI/CD:**\n- Level 1-2 in every PR (fast)\n- Level 3 on merge to main\n- Level 4 post-deployment\n\n**Clear responsibilities:**\n- Each level tests different concerns\n- No redundant tests\n- Easier to maintain\n\n---\n\n## Next Steps\n\n- For implementation details on Mollusk, LiteSVM, and Anchor testing, see **[Testing Frameworks](./testing-frameworks.md)**\n- For best practices, common patterns, and additional resources, see **[Testing Best Practices](./testing-practices.md)**\n",
        "solana/skills/solana-development/references/testing-practices.md": "# Solana Program Testing Best Practices\n\n**Common patterns, best practices, and additional testing resources**\n\nThis file provides best practices for organizing tests, testing common scenarios, and efficiently running your test suite. For framework-specific details and the testing pyramid structure, see the related files.\n\n---\n\n## Related Testing Documentation\n\n- **[Testing Overview](./testing-overview.md)** - Testing pyramid structure and types of tests\n- **[Testing Frameworks](./testing-frameworks.md)** - Mollusk, LiteSVM, and Anchor testing implementations\n\n---\n\n## Table of Contents\n\n1. [Testing Best Practices](#testing-best-practices)\n2. [Common Testing Patterns](#common-testing-patterns)\n3. [Additional Resources](#additional-resources)\n\n---\n\n## Testing Best Practices\n\n### Test Organization\n\n**Organize by instruction:**\n```\ntests/\n├── test_initialize.rs\n├── test_update.rs\n├── test_transfer.rs\n├── test_close.rs\n└── helpers/\n    ├── mod.rs\n    ├── accounts.rs\n    └── instructions.rs\n```\n\n**Use helper modules:**\n```rust\n// tests/helpers/accounts.rs\nuse solana_sdk::{account::Account, pubkey::Pubkey};\n\npub fn system_account(lamports: u64) -> Account {\n    Account {\n        lamports,\n        data: vec![],\n        owner: solana_sdk::system_program::id(),\n        executable: false,\n        rent_epoch: 0,\n    }\n}\n\npub fn token_account(/* ... */) -> Account {\n    // ...\n}\n```\n\n```rust\n// tests/test_initialize.rs\nmod helpers;\nuse helpers::accounts::*;\n\n#[test]\nfn test_initialize() {\n    let accounts = vec![\n        (user, system_account(10_000_000)),\n        // ...\n    ];\n}\n```\n\n### Edge Cases to Test\n\n**Account validation:**\n- Missing accounts\n- Wrong account owner\n- Account not writable when required\n- Account not signer when required\n- Uninitialized accounts\n- Already initialized accounts\n\n**Numeric boundaries:**\n- Zero values\n- Maximum values (u64::MAX)\n- Overflow conditions\n- Underflow conditions\n- Negative results (when using signed integers)\n\n**Authorization:**\n- Missing signer\n- Wrong signer\n- Multiple signers\n- PDA signer validation\n\n**State transitions:**\n- Invalid state transitions\n- Idempotent operations\n- Concurrent operations\n- State rollback on error\n\n**Resource limits:**\n- Rent exemption\n- Maximum account size\n- Compute unit limits\n- Stack depth limits (CPI)\n\n### Error Condition Testing\n\n**Test expected failures:**\n```rust\n#[test]\nfn test_insufficient_funds_fails() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let accounts = vec![\n        (user, system_account(100)),  // Not enough lamports\n    ];\n\n    let instruction = /* create transfer instruction for 1000 lamports */;\n\n    let checks = vec![\n        Check::instruction_err(InstructionError::InsufficientFunds),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n**Test invalid data:**\n```rust\n#[test]\nfn test_invalid_instruction_data() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let instruction = Instruction {\n        program_id,\n        accounts: /* ... */,\n        data: vec![255, 255, 255],  // Invalid instruction data\n    };\n\n    let checks = vec![\n        Check::instruction_err(InstructionError::InvalidInstructionData),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n### Compute Unit Monitoring\n\n**Set up continuous monitoring:**\n```rust\n// benches/compute_units.rs\nuse mollusk_svm_bencher::MolluskComputeUnitBencher;\n\nfn main() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n    let bencher = MolluskComputeUnitBencher::new(mollusk);\n\n    // Benchmark each instruction\n    bencher.bench((\"initialize\", &init_ix, &init_accounts));\n    bencher.bench((\"update\", &update_ix, &update_accounts));\n    bencher.bench((\"close\", &close_ix, &close_accounts));\n\n    bencher\n        .must_pass(true)\n        .out_dir(\"./target/benches\")\n        .execute();\n}\n```\n\n**Add to CI/CD:**\n```yaml\n# .github/workflows/test.yml\n- name: Run compute unit benchmarks\n  run: cargo bench\n\n- name: Check for CU regressions\n  run: |\n    if git diff --exit-code target/benches/; then\n      echo \"No compute unit changes\"\n    else\n      echo \"Compute unit usage changed - review carefully\"\n      git diff target/benches/\n    fi\n```\n\n### Running Tests Efficiently\n\n**Build before testing:**\n```bash\n# Native Rust\ncargo build-sbf && cargo test\n\n# Anchor\nanchor build && anchor test\n```\n\n**Run specific tests:**\n```bash\n# Native Rust\ncargo test test_initialize\n\n# Anchor\nanchor test -- --test test_initialize\n```\n\n**Show program output:**\n```bash\n# Native Rust\ncargo test -- --nocapture\n\n# Anchor\nanchor test -- --nocapture\n```\n\n**Run tests in parallel (be careful with shared state):**\n```bash\ncargo test -- --test-threads=4\n```\n\n---\n\n## Common Testing Patterns\n\n### Testing PDAs\n\n**Anchor approach:**\n```typescript\nit(\"derives PDA correctly\", async () => {\n  const [pda, bump] = anchor.web3.PublicKey.findProgramAddressSync(\n    [Buffer.from(\"seed\"), user.publicKey.toBuffer()],\n    program.programId\n  );\n\n  await program.methods\n    .initialize(bump)\n    .accounts({\n      pda: pda,\n      user: user.publicKey,\n      systemProgram: anchor.web3.SystemProgram.programId,\n    })\n    .signers([user])\n    .rpc();\n\n  const accountData = await program.account.myAccount.fetch(pda);\n  expect(accountData.bump).to.equal(bump);\n});\n```\n\n**Native Rust approach:**\n```rust\n#[test]\nfn test_pda_derivation() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n    let seeds = &[b\"seed\", user.as_ref()];\n    let (pda, bump) = Pubkey::find_program_address(seeds, &program_id);\n\n    let instruction = Instruction {\n        program_id,\n        accounts: vec![\n            AccountMeta::new(user, true),\n            AccountMeta::new(pda, false),\n            AccountMeta::new_readonly(system_program::id(), false),\n        ],\n        data: vec![0, bump],  // Initialize instruction with bump\n    };\n\n    let accounts = vec![\n        (user, system_account(10_000_000)),\n        (pda, Account::default()),\n    ];\n\n    let checks = vec![\n        Check::success(),\n        Check::account(&pda)\n            .owner(&program_id)\n            .build(),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n### Testing Token Operations\n\n**Anchor with SPL Token:**\n```typescript\nimport { TOKEN_PROGRAM_ID, createMint, createAccount, mintTo } from \"@solana/spl-token\";\n\nit(\"transfers tokens\", async () => {\n  // Create mint\n  const mint = await createMint(\n    provider.connection,\n    wallet.payer,\n    wallet.publicKey,\n    null,\n    6\n  );\n\n  // Create token accounts\n  const sourceAccount = await createAccount(\n    provider.connection,\n    wallet.payer,\n    mint,\n    user.publicKey\n  );\n\n  const destAccount = await createAccount(\n    provider.connection,\n    wallet.payer,\n    mint,\n    recipient.publicKey\n  );\n\n  // Mint tokens\n  await mintTo(\n    provider.connection,\n    wallet.payer,\n    mint,\n    sourceAccount,\n    wallet.publicKey,\n    1_000_000\n  );\n\n  // Transfer via program\n  await program.methods\n    .transferTokens(new anchor.BN(500_000))\n    .accounts({\n      source: sourceAccount,\n      destination: destAccount,\n      authority: user.publicKey,\n      tokenProgram: TOKEN_PROGRAM_ID,\n    })\n    .signers([user])\n    .rpc();\n\n  // Verify balances\n  const sourceData = await getAccount(provider.connection, sourceAccount);\n  const destData = await getAccount(provider.connection, destAccount);\n\n  expect(sourceData.amount).to.equal(500_000n);\n  expect(destData.amount).to.equal(500_000n);\n});\n```\n\n**Native Rust with Mollusk:**\nSee the [Testing CPIs](./testing-frameworks.md#testing-cpis) section in Testing Frameworks for a complete token transfer example.\n\n### Testing Associated Token Accounts\n\n**Create ATA:**\n```typescript\nimport { getAssociatedTokenAddress } from \"@solana/spl-token\";\n\nit(\"creates associated token account\", async () => {\n  const ata = await getAssociatedTokenAddress(\n    mint,\n    user.publicKey\n  );\n\n  await program.methods\n    .createAta()\n    .accounts({\n      ata: ata,\n      mint: mint,\n      owner: user.publicKey,\n      payer: wallet.publicKey,\n      tokenProgram: TOKEN_PROGRAM_ID,\n      associatedTokenProgram: ASSOCIATED_TOKEN_PROGRAM_ID,\n      systemProgram: SystemProgram.programId,\n    })\n    .rpc();\n\n  const account = await getAccount(provider.connection, ata);\n  expect(account.owner.toString()).to.equal(user.publicKey.toString());\n  expect(account.mint.toString()).to.equal(mint.toString());\n});\n```\n\n### Testing Account Validation\n\n**Validate account owner:**\n```rust\n#[test]\nfn test_wrong_owner_fails() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let account = Pubkey::new_unique();\n    let wrong_owner = Pubkey::new_unique();\n\n    let accounts = vec![\n        (account, Account {\n            lamports: 1_000_000,\n            data: vec![0; 100],\n            owner: wrong_owner,  // Wrong owner!\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    let instruction = /* create instruction */;\n\n    let checks = vec![\n        Check::instruction_err(InstructionError::InvalidAccountOwner),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n**Validate signer:**\n```rust\n#[test]\nfn test_missing_signer_fails() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let user = Pubkey::new_unique();\n\n    let instruction = Instruction {\n        program_id,\n        accounts: vec![\n            AccountMeta::new(user, false),  // Should be signer!\n        ],\n        data: vec![],\n    };\n\n    let accounts = vec![\n        (user, system_account(1_000_000)),\n    ];\n\n    let checks = vec![\n        Check::instruction_err(InstructionError::MissingRequiredSignature),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n### Testing Rent Exemption\n\n```rust\n#[test]\nfn test_account_is_rent_exempt() {\n    let mollusk = Mollusk::new(&program_id, \"target/deploy/my_program\");\n\n    let account = Pubkey::new_unique();\n    let data_len = 100;\n    let rent = mollusk.sysvars.rent;\n    let rent_exempt_lamports = rent.minimum_balance(data_len);\n\n    let accounts = vec![\n        (account, Account {\n            lamports: rent_exempt_lamports,\n            data: vec![0; data_len],\n            owner: program_id,\n            executable: false,\n            rent_epoch: 0,\n        }),\n    ];\n\n    let instruction = /* create instruction */;\n\n    let checks = vec![\n        Check::success(),\n        Check::account(&account)\n            .rent_exempt()\n            .build(),\n    ];\n\n    mollusk.process_and_validate_instruction(&instruction, &accounts, &checks);\n}\n```\n\n---\n\n## Additional Resources\n\n### Documentation\n\n- **Mollusk GitHub**: https://github.com/anza-xyz/mollusk\n- **Mollusk Examples**: https://github.com/anza-xyz/mollusk/tree/main/harness/tests\n- **Mollusk API Docs**: https://docs.rs/mollusk-svm/latest/mollusk_svm/\n- **Anchor Testing Guide**: https://www.anchor-lang.com/docs/testing\n- **LiteSVM**: https://github.com/amilz/litesvm\n- **Solana Testing Docs**: https://solana.com/docs/programs/testing\n\n### Key Takeaways\n\n1. **Use Mollusk for fast, focused tests** - It's the recommended approach for both Anchor and native Rust programs\n2. **Test early and often** - Catching bugs before deployment saves time and money\n3. **Test error conditions** - Don't just test happy paths\n4. **Monitor compute units** - Use benchmarking to catch performance regressions\n5. **Organize tests logically** - Group by instruction, use helper modules\n6. **Build before testing** - Always run `cargo build-sbf` or `anchor build` before tests\n7. **Use validation checks** - Leverage the `Check` API for comprehensive validation\n8. **Test with realistic data** - Use proper rent-exempt balances and realistic account states\n\n### Quick Reference Commands\n\n```bash\n# Native Rust\ncargo build-sbf                    # Build program\ncargo test                         # Run tests\ncargo test -- --nocapture         # Run tests with output\ncargo test test_name              # Run specific test\ncargo bench                       # Run compute unit benchmarks\n\n# Anchor\nanchor build                      # Build program\nanchor test                       # Build, deploy, and test\nanchor test --skip-build          # Test without rebuilding\nanchor test -- --nocapture        # Test with logs\nanchor test -- --test test_name   # Run specific test\n```\n\n---\n\n## Next Steps\n\n- For the testing strategy overview and pyramid structure, see **[Testing Overview](./testing-overview.md)**\n- For framework-specific implementation details, see **[Testing Frameworks](./testing-frameworks.md)**\n",
        "solana/skills/solana-development/references/tokens-2022.md": "# SPL Token-2022 (Token Extensions Program)\n\nToken Extensions Program (Token-2022) guide covering extension types, setup for both Anchor and Native Rust, and practical examples including transfer hooks. Includes extension configuration, space calculation, and initialization patterns.\n\n**For related topics, see:**\n- **[tokens-overview.md](tokens-overview.md)** - Token fundamentals and account structures\n- **[tokens-operations.md](tokens-operations.md)** - Create, mint, transfer, burn, close operations\n- **[tokens-validation.md](tokens-validation.md)** - Account validation patterns\n- **[tokens-patterns.md](tokens-patterns.md)** - Common patterns and security\n\n## Table of Contents\n\n1. [What are Token Extensions?](#what-are-token-extensions)\n2. [Available Extensions](#available-extensions)\n3. [Using Token-2022 in Anchor](#using-token-2022-in-anchor)\n4. [Using Token-2022 in Native Rust](#using-token-2022-in-native-rust)\n5. [Transfer Hook Extension Example](#transfer-hook-extension-example-anchor)\n\n---\n\n## What are Token Extensions?\n\nThe Token Extensions Program (Token-2022) provides additional features through extensions. Extensions are optional functionality that can be added to a token mint or token account.\n\n**Key Points:**\n- Extensions must be enabled during account creation\n- Cannot add extensions after creation\n- Some extensions are incompatible with each other\n- Extensions add state to the `tlv_data` field\n\n---\n\n## Available Extensions\n\n```rust\npub enum ExtensionType {\n    TransferFeeConfig,           // Transfer fees\n    TransferFeeAmount,           // Withheld fees\n    MintCloseAuthority,          // Close mint accounts\n    ConfidentialTransferMint,    // Confidential transfers\n    DefaultAccountState,         // Default state for new accounts\n    ImmutableOwner,              // Cannot change owner\n    MemoTransfer,                // Require memos\n    NonTransferable,             // Cannot transfer tokens\n    InterestBearingConfig,       // Tokens accrue interest\n    PermanentDelegate,           // Permanent delegate authority\n    TransferHook,                // Custom transfer logic\n    MetadataPointer,             // Point to metadata\n    TokenMetadata,               // On-chain metadata\n    GroupPointer,                // Token groups\n    TokenGroup,                  // Group config\n    GroupMemberPointer,          // Group membership\n    TokenGroupMember,            // Member config\n    // ... and more\n}\n```\n\n---\n\n## Using Token-2022 in Anchor\n\n```rust\nuse anchor_spl::token_2022::{self, Token2022};\nuse anchor_spl::token_interface::{Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct CreateToken2022Mint<'info> {\n    #[account(\n        init,\n        payer = payer,\n        mint::decimals = 9,\n        mint::authority = mint_authority,\n        mint::token_program = token_program,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Mint authority\n    pub mint_authority: UncheckedAccount<'info>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    pub token_program: Program<'info, Token2022>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n**Note:** The `anchor-spl` crate includes the `token_2022_extensions` module for working with extensions, but not all extension instructions are fully implemented yet. You may need to manually implement CPI calls for some extensions.\n\n---\n\n## Using Token-2022 in Native Rust\n\n```rust\nuse spl_token_2022::{\n    extension::ExtensionType,\n    instruction::initialize_mint2,\n};\n\npub fn create_token_2022_mint(\n    payer: &AccountInfo,\n    mint: &AccountInfo,\n    mint_authority: &Pubkey,\n    decimals: u8,\n    extensions: &[ExtensionType],\n) -> ProgramResult {\n    // Calculate space needed for extensions\n    let mut space = 82; // Base mint size\n    for extension in extensions {\n        space += extension.get_account_len();\n    }\n\n    // Create account with proper size\n    // ... (similar to regular mint creation)\n\n    // Initialize extensions\n    // Each extension has its own initialization instruction\n\n    // Finally initialize mint\n    invoke(\n        &initialize_mint2(\n            &spl_token_2022::ID,\n            mint.key,\n            mint_authority,\n            None,\n            decimals,\n        )?,\n        &[mint.clone()],\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Transfer Hook Extension Example (Anchor)\n\n```rust\nuse anchor_lang::prelude::*;\nuse anchor_spl::token_interface::{TokenAccount, TokenInterface};\n\n#[program]\npub mod transfer_hook {\n    use super::*;\n\n    #[interface(spl_transfer_hook_interface::execute)]\n    pub fn execute_transfer_hook(\n        ctx: Context<TransferHook>,\n        amount: u64,\n    ) -> Result<()> {\n        msg!(\"Transfer hook called! Amount: {}\", amount);\n        // Custom transfer logic here\n        Ok(())\n    }\n}\n\n#[derive(Accounts)]\npub struct TransferHook<'info> {\n    pub source: InterfaceAccount<'info, TokenAccount>,\n    pub destination: InterfaceAccount<'info, TokenAccount>,\n    /// CHECK: authority\n    pub authority: UncheckedAccount<'info>,\n}\n```\n\n---\n\n## Next Steps\n\n- **Common Patterns**: See [tokens-patterns.md](tokens-patterns.md) for escrow, staking, NFT creation patterns\n- **Security**: See [tokens-patterns.md](tokens-patterns.md) for comprehensive security best practices\n",
        "solana/skills/solana-development/references/tokens-operations.md": "# SPL Token Program - Operations\n\nComplete guide to SPL Token operations including creating mints, minting tokens, transferring (with transfer_checked), burning, and closing token accounts. Shows both Anchor and Native Rust implementations side-by-side.\n\n**For related topics, see:**\n- **[tokens-overview.md](tokens-overview.md)** - Token fundamentals and account structures\n- **[tokens-validation.md](tokens-validation.md)** - Account validation patterns\n- **[tokens-2022.md](tokens-2022.md)** - Token Extensions Program features\n- **[tokens-patterns.md](tokens-patterns.md)** - Common patterns and security\n\n## Table of Contents\n\n1. [Creating Tokens](#creating-tokens)\n2. [Minting Tokens](#minting-tokens)\n3. [Transferring Tokens](#transferring-tokens)\n4. [Burning Tokens](#burning-tokens)\n5. [Closing Token Accounts](#closing-token-accounts)\n\n---\n\n## Creating Tokens\n\n### Initialize a New Mint\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{Mint, TokenInterface};\n\n#[derive(Accounts)]\npub struct CreateMint<'info> {\n    #[account(\n        init,\n        payer = payer,\n        mint::decimals = 9,\n        mint::authority = mint_authority,\n        mint::freeze_authority = freeze_authority,\n        mint::token_program = token_program,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Can be any account\n    pub mint_authority: UncheckedAccount<'info>,\n\n    /// CHECK: Can be any account (optional)\n    pub freeze_authority: UncheckedAccount<'info>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn create_mint(ctx: Context<CreateMint>) -> Result<()> {\n    // Mint is automatically created and initialized by Anchor constraints\n    msg!(\"Mint created: {}\", ctx.accounts.mint.key());\n    Ok(())\n}\n```\n\n**Key Anchor Constraints:**\n- `init` - Creates and initializes the account\n- `mint::decimals` - Number of decimal places\n- `mint::authority` - Who can mint tokens\n- `mint::freeze_authority` - Who can freeze token accounts (optional)\n- `mint::token_program` - Which token program to use\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::initialize_mint;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    rent::Rent,\n    system_instruction,\n    sysvar::Sysvar,\n};\n\npub fn create_mint(\n    payer: &AccountInfo,\n    mint_account: &AccountInfo,\n    mint_authority: &Pubkey,\n    freeze_authority: Option<&Pubkey>,\n    decimals: u8,\n    system_program: &AccountInfo,\n    token_program: &AccountInfo,\n    rent_sysvar: &AccountInfo,\n) -> ProgramResult {\n    // Mint account size\n    let mint_size = 82;\n\n    // Calculate rent\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(mint_size);\n\n    // Create mint account via System Program\n    invoke(\n        &system_instruction::create_account(\n            payer.key,\n            mint_account.key,\n            rent_lamports,\n            mint_size as u64,\n            &spl_token::ID,\n        ),\n        &[payer.clone(), mint_account.clone(), system_program.clone()],\n    )?;\n\n    // Initialize mint\n    invoke(\n        &initialize_mint(\n            token_program.key,\n            mint_account.key,\n            mint_authority,\n            freeze_authority,\n            decimals,\n        )?,\n        &[\n            mint_account.clone(),\n            rent_sysvar.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Initialize a Token Account (Non-ATA)\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct CreateTokenAccount<'info> {\n    #[account(\n        init,\n        payer = payer,\n        token::mint = mint,\n        token::authority = owner,\n        token::token_program = token_program,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Can be any account\n    pub owner: UncheckedAccount<'info>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn create_token_account(ctx: Context<CreateTokenAccount>) -> Result<()> {\n    // Token account is automatically created and initialized\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::initialize_account3;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    rent::Rent,\n    system_instruction,\n    sysvar::Sysvar,\n};\n\npub fn create_token_account(\n    payer: &AccountInfo,\n    token_account: &AccountInfo,\n    mint: &AccountInfo,\n    owner: &Pubkey,\n    system_program: &AccountInfo,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    // Token account size\n    let token_account_size = 165;\n\n    // Calculate rent\n    let rent = Rent::get()?;\n    let rent_lamports = rent.minimum_balance(token_account_size);\n\n    // Create token account\n    invoke(\n        &system_instruction::create_account(\n            payer.key,\n            token_account.key,\n            rent_lamports,\n            token_account_size as u64,\n            &spl_token::ID,\n        ),\n        &[payer.clone(), token_account.clone(), system_program.clone()],\n    )?;\n\n    // Initialize token account\n    invoke(\n        &initialize_account3(\n            token_program.key,\n            token_account.key,\n            mint.key,\n            owner,\n        )?,\n        &[token_account.clone(), mint.clone(), token_program.clone()],\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Minting Tokens\n\n### Basic Minting (User Authority)\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Mint, MintTo, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct MintTokens<'info> {\n    #[account(mut)]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(mut)]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint_authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn mint_tokens(ctx: Context<MintTokens>, amount: u64) -> Result<()> {\n    let cpi_accounts = MintTo {\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.mint_authority.to_account_info(),\n    };\n\n    let cpi_program = ctx.accounts.token_program.to_account_info();\n    let cpi_context = CpiContext::new(cpi_program, cpi_accounts);\n\n    token_interface::mint_to(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::mint_to;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n};\n\npub fn mint_tokens(\n    mint: &AccountInfo,\n    destination: &AccountInfo,\n    mint_authority: &AccountInfo,\n    amount: u64,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    // Mint authority must be a signer\n    if !mint_authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    invoke(\n        &mint_to(\n            token_program.key,\n            mint.key,\n            destination.key,\n            mint_authority.key,\n            &[],  // No multisig signers\n            amount,\n        )?,\n        &[\n            mint.clone(),\n            destination.clone(),\n            mint_authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Minting with PDA Authority\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Mint, MintTo, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct MintWithPDA<'info> {\n    #[account(\n        mut,\n        mint::authority = mint_authority,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(mut)]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        seeds = [b\"mint-authority\"],\n        bump,\n    )]\n    /// CHECK: PDA signer\n    pub mint_authority: UncheckedAccount<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn mint_with_pda(ctx: Context<MintWithPDA>, amount: u64) -> Result<()> {\n    let seeds = &[\n        b\"mint-authority\",\n        &[ctx.bumps.mint_authority],\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    let cpi_accounts = MintTo {\n        mint: ctx.accounts.mint.to_account_info(),\n        to: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.mint_authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    ).with_signer(signer_seeds);\n\n    token_interface::mint_to(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::mint_to;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke_signed,\n    program_error::ProgramError,\n    pubkey::Pubkey,\n};\n\npub fn mint_tokens_from_pda(\n    program_id: &Pubkey,\n    mint: &AccountInfo,\n    destination: &AccountInfo,\n    mint_authority_pda: &AccountInfo,\n    token_program: &AccountInfo,\n    amount: u64,\n    pda_seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    // Validate PDA\n    let (expected_pda, _) = Pubkey::find_program_address(pda_seeds, program_id);\n    if expected_pda != *mint_authority_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Prepare signer seeds\n    let mut full_seeds = pda_seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    invoke_signed(\n        &mint_to(\n            token_program.key,\n            mint.key,\n            destination.key,\n            mint_authority_pda.key,\n            &[],\n            amount,\n        )?,\n        &[\n            mint.clone(),\n            destination.clone(),\n            mint_authority_pda.clone(),\n            token_program.clone(),\n        ],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Transferring Tokens\n\n### Basic Transfer\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, TokenAccount, TokenInterface, Transfer};\n\n#[derive(Accounts)]\npub struct TransferTokens<'info> {\n    #[account(mut)]\n    pub from: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub to: InterfaceAccount<'info, TokenAccount>,\n\n    pub authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn transfer_tokens(ctx: Context<TransferTokens>, amount: u64) -> Result<()> {\n    let cpi_accounts = Transfer {\n        from: ctx.accounts.from.to_account_info(),\n        to: ctx.accounts.to.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    );\n\n    token_interface::transfer(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::transfer;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n};\n\npub fn transfer_tokens(\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n    amount: u64,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    // Authority must be a signer\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    invoke(\n        &transfer(\n            token_program.key,\n            source.key,\n            destination.key,\n            authority.key,\n            &[],  // No multisig signers\n            amount,\n        )?,\n        &[\n            source.clone(),\n            destination.clone(),\n            authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Transfer with Checks (Recommended)\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Mint, TokenAccount, TokenInterface, TransferChecked};\n\n#[derive(Accounts)]\npub struct TransferTokensChecked<'info> {\n    #[account(mut)]\n    pub from: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub to: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    pub authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn transfer_tokens_checked(\n    ctx: Context<TransferTokensChecked>,\n    amount: u64\n) -> Result<()> {\n    token_interface::transfer_checked(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            TransferChecked {\n                from: ctx.accounts.from.to_account_info(),\n                mint: ctx.accounts.mint.to_account_info(),\n                to: ctx.accounts.to.to_account_info(),\n                authority: ctx.accounts.authority.to_account_info(),\n            },\n        ),\n        amount,\n        ctx.accounts.mint.decimals,\n    )?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::transfer_checked;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n};\n\npub fn transfer_tokens_checked(\n    source: &AccountInfo,\n    mint: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n    amount: u64,\n    decimals: u8,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    invoke(\n        &transfer_checked(\n            token_program.key,\n            source.key,\n            mint.key,\n            destination.key,\n            authority.key,\n            &[],\n            amount,\n            decimals,\n        )?,\n        &[\n            source.clone(),\n            mint.clone(),\n            destination.clone(),\n            authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Transfer with PDA Signer\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, TokenAccount, TokenInterface, Transfer};\n\n#[derive(Accounts)]\npub struct TransferWithPDA<'info> {\n    #[account(\n        mut,\n        token::authority = authority,\n    )]\n    pub from: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub to: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        seeds = [b\"authority\"],\n        bump,\n    )]\n    /// CHECK: PDA signer\n    pub authority: UncheckedAccount<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn transfer_with_pda(ctx: Context<TransferWithPDA>, amount: u64) -> Result<()> {\n    let seeds = &[\n        b\"authority\",\n        &[ctx.bumps.authority],\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    let cpi_accounts = Transfer {\n        from: ctx.accounts.from.to_account_info(),\n        to: ctx.accounts.to.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    ).with_signer(signer_seeds);\n\n    token_interface::transfer(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::transfer;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke_signed,\n    program_error::ProgramError,\n    pubkey::Pubkey,\n};\n\npub fn transfer_tokens_from_pda(\n    program_id: &Pubkey,\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    authority_pda: &AccountInfo,\n    token_program: &AccountInfo,\n    amount: u64,\n    pda_seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let (expected_pda, _) = Pubkey::find_program_address(pda_seeds, program_id);\n    if expected_pda != *authority_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    let mut full_seeds = pda_seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    invoke_signed(\n        &transfer(\n            token_program.key,\n            source.key,\n            destination.key,\n            authority_pda.key,\n            &[],\n            amount,\n        )?,\n        &[\n            source.clone(),\n            destination.clone(),\n            authority_pda.clone(),\n            token_program.clone(),\n        ],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Burning Tokens\n\n### Basic Burn\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Burn, Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct BurnTokens<'info> {\n    #[account(mut)]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(mut)]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn burn_tokens(ctx: Context<BurnTokens>, amount: u64) -> Result<()> {\n    let cpi_accounts = Burn {\n        mint: ctx.accounts.mint.to_account_info(),\n        from: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    );\n\n    token_interface::burn(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::burn;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n};\n\npub fn burn_tokens(\n    token_account: &AccountInfo,\n    mint: &AccountInfo,\n    authority: &AccountInfo,\n    amount: u64,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    invoke(\n        &burn(\n            token_program.key,\n            token_account.key,\n            mint.key,\n            authority.key,\n            &[],\n            amount,\n        )?,\n        &[\n            token_account.clone(),\n            mint.clone(),\n            authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Burn with PDA Authority\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Burn, Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct BurnWithPDA<'info> {\n    #[account(mut)]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(\n        mut,\n        token::authority = authority,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        seeds = [b\"burn-authority\"],\n        bump,\n    )]\n    /// CHECK: PDA signer\n    pub authority: UncheckedAccount<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn burn_with_pda(ctx: Context<BurnWithPDA>, amount: u64) -> Result<()> {\n    let seeds = &[\n        b\"burn-authority\",\n        &[ctx.bumps.authority],\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    let cpi_accounts = Burn {\n        mint: ctx.accounts.mint.to_account_info(),\n        from: ctx.accounts.token_account.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    ).with_signer(signer_seeds);\n\n    token_interface::burn(cpi_context, amount)?;\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\npub fn burn_tokens_from_pda(\n    program_id: &Pubkey,\n    token_account: &AccountInfo,\n    mint: &AccountInfo,\n    authority_pda: &AccountInfo,\n    token_program: &AccountInfo,\n    amount: u64,\n    pda_seeds: &[&[u8]],\n    bump: u8,\n) -> ProgramResult {\n    let (expected_pda, _) = Pubkey::find_program_address(pda_seeds, program_id);\n    if expected_pda != *authority_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    let mut full_seeds = pda_seeds.to_vec();\n    full_seeds.push(&[bump]);\n    let signer_seeds: &[&[&[u8]]] = &[&full_seeds];\n\n    invoke_signed(\n        &burn(\n            token_program.key,\n            token_account.key,\n            mint.key,\n            authority_pda.key,\n            &[],\n            amount,\n        )?,\n        &[\n            token_account.clone(),\n            mint.clone(),\n            authority_pda.clone(),\n            token_program.clone(),\n        ],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Closing Token Accounts\n\n### Close Token Account\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, CloseAccount, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct CloseTokenAccount<'info> {\n    #[account(mut)]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub destination: SystemAccount<'info>,\n\n    pub authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn close_token_account(ctx: Context<CloseTokenAccount>) -> Result<()> {\n    let cpi_accounts = CloseAccount {\n        account: ctx.accounts.token_account.to_account_info(),\n        destination: ctx.accounts.destination.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_context = CpiContext::new(\n        ctx.accounts.token_program.to_account_info(),\n        cpi_accounts\n    );\n\n    token_interface::close_account(cpi_context)?;\n    Ok(())\n}\n```\n\n**Using Anchor Constraints (Simplified):**\n\n```rust\n#[derive(Accounts)]\npub struct CloseTokenAccount<'info> {\n    #[account(\n        mut,\n        close = destination,\n        token::authority = authority,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub destination: SystemAccount<'info>,\n\n    pub authority: Signer<'info>,\n}\n\npub fn close_token_account(ctx: Context<CloseTokenAccount>) -> Result<()> {\n    // Account is automatically closed by Anchor constraints\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_token::instruction::close_account;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n    program_error::ProgramError,\n};\n\npub fn close_token_account(\n    token_account: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    invoke(\n        &close_account(\n            token_program.key,\n            token_account.key,\n            destination.key,\n            authority.key,\n            &[],\n        )?,\n        &[\n            token_account.clone(),\n            destination.clone(),\n            authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Next Steps\n\n- **Validation**: See [tokens-validation.md](tokens-validation.md) for account validation patterns\n- **Token-2022**: See [tokens-2022.md](tokens-2022.md) for Token Extensions Program features\n- **Patterns & Security**: See [tokens-patterns.md](tokens-patterns.md) for common patterns and security best practices\n",
        "solana/skills/solana-development/references/tokens-overview.md": "# SPL Token Program - Overview and Fundamentals\n\nOverview of SPL Token Program fundamentals including program types, account structures (Mint and Token accounts), and Associated Token Accounts (ATAs) with derivation and creation patterns.\n\n**For additional token topics, see:**\n- **[tokens-operations.md](tokens-operations.md)** - Create, mint, transfer, burn, close operations\n- **[tokens-validation.md](tokens-validation.md)** - Account validation patterns\n- **[tokens-2022.md](tokens-2022.md)** - Token Extensions Program features\n- **[tokens-patterns.md](tokens-patterns.md)** - Common patterns and security\n\n## Table of Contents\n\n1. [Token Program Overview](#token-program-overview)\n2. [Token Account Structures](#token-account-structures)\n3. [Associated Token Accounts](#associated-token-accounts)\n\n---\n\n## Token Program Overview\n\n### SPL Token vs Token-2022\n\n**SPL Token (Original):**\n- Program ID: `TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA`\n- Production-ready, stable, widely adopted\n- No new features planned\n- Use for standard fungible tokens\n\n**Token-2022 (Token Extensions Program):**\n- Program ID: `TokenzQdBNbLqP5VEhdkAS6EPFLC1PHnBqCXEpPxuEb`\n- Backwards-compatible with SPL Token\n- Supports extensions (transfer fees, confidential transfers, metadata pointers, etc.)\n- Use for advanced token features\n\n### Key Concepts\n\n```\n┌─────────────────────────────────────────┐\n│ Mint Account                             │\n├─────────────────────────────────────────┤\n│ - Defines a token type                  │\n│ - Controls supply                       │\n│ - Has mint authority (can create tokens)│\n│ - Has freeze authority (can freeze accts)│\n└─────────────────────────────────────────┘\n           │\n           │ Creates\n           ▼\n┌─────────────────────────────────────────┐\n│ Token Account                            │\n├─────────────────────────────────────────┤\n│ - Holds token balance                   │\n│ - Owned by a wallet or program          │\n│ - Associated with specific Mint         │\n│ - Can be frozen/delegated               │\n└─────────────────────────────────────────┘\n```\n\n### Required Dependencies\n\n**For Anchor:**\n```toml\n[dependencies]\nanchor-lang = \"0.32.1\"\nanchor-spl = \"0.32.1\"\n\n[features]\nidl-build = [\n    \"anchor-lang/idl-build\",\n    \"anchor-spl/idl-build\",\n]\n```\n\n**For Native Rust:**\n```toml\n[dependencies]\nspl-token = \"6.0\"\nspl-associated-token-account = \"6.0\"\nsolana-program = \"2.1\"\n```\n\n---\n\n## Token Account Structures\n\n### Mint Account\n\n**Size:** 82 bytes\n\n```rust\npub struct Mint {\n    /// Optional authority to mint new tokens (Pubkey or None)\n    pub mint_authority: COption<Pubkey>,       // 36 bytes\n\n    /// Total supply of tokens\n    pub supply: u64,                           // 8 bytes\n\n    /// Number of decimals (0 for NFTs, typically 6-9 for fungible)\n    pub decimals: u8,                          // 1 byte\n\n    /// Is initialized?\n    pub is_initialized: bool,                  // 1 byte\n\n    /// Optional authority to freeze token accounts\n    pub freeze_authority: COption<Pubkey>,     // 36 bytes\n}\n```\n\n**COption Format:**\n```rust\npub enum COption<T> {\n    None,      // Represented as [0, 0, 0, 0, ...]\n    Some(T),   // Represented as [1, followed by T bytes]\n}\n```\n\n### Token Account\n\n**Size:** 165 bytes\n\n```rust\npub struct Account {\n    /// The mint associated with this account\n    pub mint: Pubkey,                    // 32 bytes\n\n    /// The owner of this account\n    pub owner: Pubkey,                   // 32 bytes\n\n    /// The amount of tokens this account holds\n    pub amount: u64,                     // 8 bytes\n\n    /// If `delegate` is `Some` then `delegated_amount` represents\n    /// the amount authorized by the delegate\n    pub delegate: COption<Pubkey>,       // 36 bytes\n\n    /// The account's state\n    pub state: AccountState,             // 1 byte\n\n    /// If is_native.is_some, this is a native token, and the value logs the\n    /// rent-exempt reserve\n    pub is_native: COption<u64>,         // 12 bytes\n\n    /// The amount delegated\n    pub delegated_amount: u64,           // 8 bytes\n\n    /// Optional authority to close the account\n    pub close_authority: COption<Pubkey>, // 36 bytes\n}\n\npub enum AccountState {\n    Uninitialized,\n    Initialized,\n    Frozen,\n}\n```\n\n---\n\n## Associated Token Accounts\n\n### What are ATAs?\n\n**Associated Token Accounts (ATAs)** are PDAs that map a wallet address to a token account for a specific mint.\n\n**Derivation:**\n```rust\nATA = PDA(\n    seeds: [wallet_address, TOKEN_PROGRAM_ID, mint_address],\n    program: ASSOCIATED_TOKEN_PROGRAM_ID\n)\n```\n\n**Benefits:**\n- **Deterministic**: Same wallet + mint always produces same ATA\n- **Discoverable**: Easy to find a user's token accounts\n- **Standard**: All wallets use this convention\n\n**Constants:**\n```rust\n// Token Program ID\npub const TOKEN_PROGRAM_ID: Pubkey = pubkey!(\"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\");\n\n// Associated Token Program ID\npub const ASSOCIATED_TOKEN_PROGRAM_ID: Pubkey = pubkey!(\"ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL\");\n```\n\n### Finding ATA Address\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::associated_token::get_associated_token_address;\n\n// In client code or tests\nlet ata_address = get_associated_token_address(\n    &wallet_address,\n    &mint_address,\n);\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_associated_token_account::get_associated_token_address;\n\n// Derive ATA address\nlet ata_address = get_associated_token_address(\n    &wallet_address,\n    &mint_address,\n);\n```\n\n### Creating Associated Token Accounts\n\n#### Using Anchor\n\n```rust\nuse anchor_spl::associated_token::AssociatedToken;\nuse anchor_spl::token_interface::{Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct CreateTokenAccount<'info> {\n    #[account(\n        init,\n        payer = payer,\n        associated_token::mint = mint,\n        associated_token::authority = owner,\n        associated_token::token_program = token_program,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Can be any account\n    pub owner: UncheckedAccount<'info>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub associated_token_program: Program<'info, AssociatedToken>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn create_ata(ctx: Context<CreateTokenAccount>) -> Result<()> {\n    // ATA is automatically created by Anchor constraints\n    Ok(())\n}\n```\n\n#### Using Native Rust\n\n```rust\nuse spl_associated_token_account::instruction::create_associated_token_account;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program::invoke,\n};\n\npub fn create_ata(\n    payer: &AccountInfo,\n    wallet: &AccountInfo,\n    mint: &AccountInfo,\n    ata: &AccountInfo,\n    system_program: &AccountInfo,\n    token_program: &AccountInfo,\n    associated_token_program: &AccountInfo,\n) -> ProgramResult {\n    invoke(\n        &create_associated_token_account(\n            payer.key,\n            wallet.key,\n            mint.key,\n            token_program.key,\n        ),\n        &[\n            payer.clone(),\n            ata.clone(),\n            wallet.clone(),\n            mint.clone(),\n            system_program.clone(),\n            token_program.clone(),\n            associated_token_program.clone(),\n        ],\n    )?\n\n;\n\n    Ok(())\n}\n```\n\n---\n\n## Next Steps\n\n- **Token Operations**: See [tokens-operations.md](tokens-operations.md) for creating mints, minting, transferring, burning, and closing accounts\n- **Validation**: See [tokens-validation.md](tokens-validation.md) for account validation patterns\n- **Token-2022**: See [tokens-2022.md](tokens-2022.md) for Token Extensions Program features\n- **Patterns & Security**: See [tokens-patterns.md](tokens-patterns.md) for common patterns and security best practices\n",
        "solana/skills/solana-development/references/tokens-patterns.md": "# SPL Token Program - Common Patterns and Security\n\nCommon SPL Token patterns including escrow, staking, NFT creation, and account freezing. Comprehensive security considerations covering validation, authority checks, and defensive programming. Includes quick reference tables and security checklist.\n\n**For related topics, see:**\n- **[tokens-overview.md](tokens-overview.md)** - Token fundamentals and account structures\n- **[tokens-operations.md](tokens-operations.md)** - Create, mint, transfer, burn, close operations\n- **[tokens-validation.md](tokens-validation.md)** - Account validation patterns\n- **[tokens-2022.md](tokens-2022.md)** - Token Extensions Program features\n\n## Table of Contents\n\n1. [Pattern 1: Token Escrow](#pattern-1-token-escrow)\n2. [Pattern 2: Token Staking](#pattern-2-token-staking)\n3. [Pattern 3: NFT Creation](#pattern-3-nft-creation)\n4. [Pattern 4: Freezing and Thawing Accounts](#pattern-4-freezing-and-thawing-accounts)\n5. [Security Considerations](#security-considerations)\n6. [Summary](#summary)\n\n---\n\n## Pattern 1: Token Escrow\n\nProgram holds tokens temporarily on behalf of users.\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, TokenAccount, TokenInterface, Transfer};\n\n#[derive(Accounts)]\npub struct InitializeEscrow<'info> {\n    #[account(\n        init,\n        payer = user,\n        space = 8 + 32 + 8 + 1,\n        seeds = [b\"escrow\", user.key().as_ref()],\n        bump,\n    )]\n    pub escrow_state: Account<'info, EscrowState>,\n\n    #[account(\n        init,\n        payer = user,\n        token::mint = mint,\n        token::authority = escrow_state,\n        token::token_program = token_program,\n    )]\n    pub escrow_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub user_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(mut)]\n    pub user: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n\n#[account]\npub struct EscrowState {\n    pub user: Pubkey,\n    pub amount: u64,\n    pub bump: u8,\n}\n\npub fn initialize_escrow(ctx: Context<InitializeEscrow>, amount: u64) -> Result<()> {\n    // Transfer tokens to escrow\n    token_interface::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.user_token_account.to_account_info(),\n                to: ctx.accounts.escrow_token_account.to_account_info(),\n                authority: ctx.accounts.user.to_account_info(),\n            },\n        ),\n        amount,\n    )?;\n\n    // Save state\n    ctx.accounts.escrow_state.user = ctx.accounts.user.key();\n    ctx.accounts.escrow_state.amount = amount;\n    ctx.accounts.escrow_state.bump = ctx.bumps.escrow_state;\n\n    Ok(())\n}\n\n#[derive(Accounts)]\npub struct ReleaseEscrow<'info> {\n    #[account(\n        mut,\n        seeds = [b\"escrow\", escrow_state.user.as_ref()],\n        bump = escrow_state.bump,\n        has_one = user,\n        close = user,\n    )]\n    pub escrow_state: Account<'info, EscrowState>,\n\n    #[account(mut)]\n    pub escrow_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub recipient_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub user: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn release_escrow(ctx: Context<ReleaseEscrow>) -> Result<()> {\n    let seeds = &[\n        b\"escrow\",\n        ctx.accounts.user.key().as_ref(),\n        &[ctx.accounts.escrow_state.bump],\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    token_interface::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.escrow_token_account.to_account_info(),\n                to: ctx.accounts.recipient_token_account.to_account_info(),\n                authority: ctx.accounts.escrow_state.to_account_info(),\n            },\n        ).with_signer(signer_seeds),\n        ctx.accounts.escrow_state.amount,\n    )?;\n\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse borsh::{BorshDeserialize, BorshSerialize};\nuse spl_token::instruction::transfer;\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct EscrowState {\n    pub user: Pubkey,\n    pub amount: u64,\n    pub bump: u8,\n}\n\npub fn initialize_escrow(\n    program_id: &Pubkey,\n    user: &AccountInfo,\n    user_token_account: &AccountInfo,\n    escrow_token_account: &AccountInfo,\n    escrow_state: &AccountInfo,\n    amount: u64,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    // Transfer tokens to escrow\n    invoke(\n        &transfer(\n            &spl_token::ID,\n            user_token_account.key,\n            escrow_token_account.key,\n            user.key,\n            &[],\n            amount,\n        )?,\n        &[user_token_account.clone(), escrow_token_account.clone(), user.clone()],\n    )?;\n\n    // Save escrow state\n    let (pda, bump) = Pubkey::find_program_address(&[b\"escrow\", user.key.as_ref()], program_id);\n    let escrow = EscrowState {\n        user: *user.key,\n        amount,\n        bump,\n    };\n    escrow.serialize(&mut &mut escrow_state.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n\npub fn release_escrow(\n    program_id: &Pubkey,\n    escrow_state: &AccountInfo,\n    escrow_token_account: &AccountInfo,\n    recipient_token_account: &AccountInfo,\n    escrow_pda: &AccountInfo,\n    amount: u64,\n    bump: u8,\n    user: &Pubkey,\n) -> ProgramResult {\n    let signer_seeds: &[&[&[u8]]] = &[&[b\"escrow\", user.as_ref(), &[bump]]];\n\n    invoke_signed(\n        &transfer(\n            &spl_token::ID,\n            escrow_token_account.key,\n            recipient_token_account.key,\n            escrow_pda.key,\n            &[],\n            amount,\n        )?,\n        &[escrow_token_account.clone(), recipient_token_account.clone(), escrow_pda.clone()],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Pattern 2: Token Staking\n\nUsers lock tokens to earn rewards.\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Mint, TokenAccount, TokenInterface, Transfer};\n\n#[derive(Accounts)]\npub struct StakeTokens<'info> {\n    #[account(\n        init_if_needed,\n        payer = user,\n        space = 8 + 32 + 8 + 8 + 1,\n        seeds = [b\"stake\", user.key().as_ref()],\n        bump,\n    )]\n    pub stake_account: Account<'info, StakeAccount>,\n\n    #[account(mut)]\n    pub user_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        mut,\n        seeds = [b\"vault\"],\n        bump,\n    )]\n    pub vault_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(mut)]\n    pub user: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub system_program: Program<'info, System>,\n}\n\n#[account]\npub struct StakeAccount {\n    pub user: Pubkey,\n    pub amount_staked: u64,\n    pub stake_timestamp: i64,\n    pub bump: u8,\n}\n\npub fn stake_tokens(ctx: Context<StakeTokens>, amount: u64) -> Result<()> {\n    // Transfer tokens to vault\n    token_interface::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.user_token_account.to_account_info(),\n                to: ctx.accounts.vault_token_account.to_account_info(),\n                authority: ctx.accounts.user.to_account_info(),\n            },\n        ),\n        amount,\n    )?;\n\n    // Update stake account\n    let clock = Clock::get()?;\n    ctx.accounts.stake_account.user = ctx.accounts.user.key();\n    ctx.accounts.stake_account.amount_staked += amount;\n    ctx.accounts.stake_account.stake_timestamp = clock.unix_timestamp;\n    ctx.accounts.stake_account.bump = ctx.bumps.stake_account;\n\n    Ok(())\n}\n\n#[derive(Accounts)]\npub struct UnstakeTokens<'info> {\n    #[account(\n        mut,\n        seeds = [b\"stake\", user.key().as_ref()],\n        bump = stake_account.bump,\n        has_one = user,\n    )]\n    pub stake_account: Account<'info, StakeAccount>,\n\n    #[account(mut)]\n    pub user_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        mut,\n        seeds = [b\"vault\"],\n        bump,\n    )]\n    pub vault_token_account: InterfaceAccount<'info, TokenAccount>,\n\n    /// CHECK: Vault authority PDA\n    #[account(\n        seeds = [b\"vault-authority\"],\n        bump,\n    )]\n    pub vault_authority: UncheckedAccount<'info>,\n\n    pub user: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn unstake_tokens(ctx: Context<UnstakeTokens>, amount: u64) -> Result<()> {\n    require!(\n        ctx.accounts.stake_account.amount_staked >= amount,\n        ErrorCode::InsufficientStake\n    );\n\n    let seeds = &[\n        b\"vault-authority\",\n        &[ctx.bumps.vault_authority],\n    ];\n    let signer_seeds = &[&seeds[..]];\n\n    // Transfer tokens back to user\n    token_interface::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.vault_token_account.to_account_info(),\n                to: ctx.accounts.user_token_account.to_account_info(),\n                authority: ctx.accounts.vault_authority.to_account_info(),\n            },\n        ).with_signer(signer_seeds),\n        amount,\n    )?;\n\n    // Update stake account\n    ctx.accounts.stake_account.amount_staked -= amount;\n\n    Ok(())\n}\n```\n\n---\n\n## Pattern 3: NFT Creation\n\nMinting a non-fungible token (supply = 1, decimals = 0).\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, Mint, MintTo, SetAuthority, TokenAccount, TokenInterface};\nuse anchor_spl::token_interface::spl_token_2022::instruction::AuthorityType;\n\n#[derive(Accounts)]\npub struct CreateNFT<'info> {\n    #[account(\n        init,\n        payer = payer,\n        mint::decimals = 0,\n        mint::authority = mint_authority,\n        mint::token_program = token_program,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(\n        init,\n        payer = payer,\n        associated_token::mint = mint,\n        associated_token::authority = owner,\n        associated_token::token_program = token_program,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    /// CHECK: Owner of the NFT\n    pub owner: UncheckedAccount<'info>,\n\n    pub mint_authority: Signer<'info>,\n\n    #[account(mut)]\n    pub payer: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n    pub associated_token_program: Program<'info, AssociatedToken>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn create_nft(ctx: Context<CreateNFT>) -> Result<()> {\n    // Mint exactly 1 token\n    token_interface::mint_to(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            MintTo {\n                mint: ctx.accounts.mint.to_account_info(),\n                to: ctx.accounts.token_account.to_account_info(),\n                authority: ctx.accounts.mint_authority.to_account_info(),\n            },\n        ),\n        1,\n    )?;\n\n    // Remove mint authority to freeze supply\n    token_interface::set_authority(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            SetAuthority {\n                account_or_mint: ctx.accounts.mint.to_account_info(),\n                current_authority: ctx.accounts.mint_authority.to_account_info(),\n            },\n        ),\n        AuthorityType::MintTokens,\n        None,\n    )?;\n\n    msg!(\"NFT created: {}\", ctx.accounts.mint.key());\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse spl_token::instruction::{mint_to, set_authority, AuthorityType};\n\npub fn create_nft(\n    mint: &AccountInfo,\n    token_account: &AccountInfo,\n    mint_authority: &AccountInfo,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    // 1. Mint exactly 1 token\n    invoke(\n        &mint_to(\n            &spl_token::ID,\n            mint.key,\n            token_account.key,\n            mint_authority.key,\n            &[],\n            1,  // Exactly 1 token\n        )?,\n        &[mint.clone(), token_account.clone(), mint_authority.clone()],\n    )?;\n\n    // 2. Remove mint authority (make supply fixed)\n    invoke(\n        &set_authority(\n            &spl_token::ID,\n            mint.key,\n            None,  // Set to None\n            AuthorityType::MintTokens,\n            mint_authority.key,\n            &[],\n        )?,\n        &[mint.clone(), mint_authority.clone()],\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Pattern 4: Freezing and Thawing Accounts\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{self, FreezeAccount, Mint, ThawAccount, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct FreezeTokenAccount<'info> {\n    #[account(\n        mint::freeze_authority = freeze_authority,\n    )]\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    #[account(mut)]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub freeze_authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn freeze_account(ctx: Context<FreezeTokenAccount>) -> Result<()> {\n    token_interface::freeze_account(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            FreezeAccount {\n                account: ctx.accounts.token_account.to_account_info(),\n                mint: ctx.accounts.mint.to_account_info(),\n                authority: ctx.accounts.freeze_authority.to_account_info(),\n            },\n        ),\n    )?;\n    Ok(())\n}\n\npub fn thaw_account(ctx: Context<FreezeTokenAccount>) -> Result<()> {\n    token_interface::thaw_account(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            ThawAccount {\n                account: ctx.accounts.token_account.to_account_info(),\n                mint: ctx.accounts.mint.to_account_info(),\n                authority: ctx.accounts.freeze_authority.to_account_info(),\n            },\n        ),\n    )?;\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse spl_token::instruction::{freeze_account, thaw_account};\n\npub fn freeze_token_account(\n    token_account: &AccountInfo,\n    mint: &AccountInfo,\n    freeze_authority: &AccountInfo,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    invoke(\n        &freeze_account(\n            token_program.key,\n            token_account.key,\n            mint.key,\n            freeze_authority.key,\n            &[],\n        )?,\n        &[\n            token_account.clone(),\n            mint.clone(),\n            freeze_authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n\npub fn thaw_token_account(\n    token_account: &AccountInfo,\n    mint: &AccountInfo,\n    freeze_authority: &AccountInfo,\n    token_program: &AccountInfo,\n) -> ProgramResult {\n    invoke(\n        &thaw_account(\n            token_program.key,\n            token_account.key,\n            mint.key,\n            freeze_authority.key,\n            &[],\n        )?,\n        &[\n            token_account.clone(),\n            mint.clone(),\n            freeze_authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n---\n\n## Security Considerations\n\n### 1. Always Validate Token Accounts\n\n#### Anchor Approach\n\n```rust\n#[derive(Accounts)]\npub struct SafeTransfer<'info> {\n    #[account(\n        mut,\n        constraint = source.mint == mint.key() @ ErrorCode::InvalidMint,\n        constraint = source.owner == authority.key() @ ErrorCode::InvalidOwner,\n    )]\n    pub source: InterfaceAccount<'info, TokenAccount>,\n\n    #[account(\n        mut,\n        constraint = destination.mint == mint.key() @ ErrorCode::InvalidMint,\n    )]\n    pub destination: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    pub authority: Signer<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n```\n\n#### Native Rust Approach\n\n```rust\n// ❌ Dangerous - no validation\npub fn unsafe_transfer(\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n) -> ProgramResult {\n    // No checks! Attacker can pass any accounts\n    invoke(&transfer_instruction, &accounts)?;\n    Ok(())\n}\n\n// ✅ Safe - validates everything\npub fn safe_transfer(\n    source: &AccountInfo,\n    destination: &AccountInfo,\n    authority: &AccountInfo,\n    expected_mint: &Pubkey,\n) -> ProgramResult {\n    // Validate source\n    validate_token_account(source, authority.key, expected_mint)?;\n\n    // Validate destination\n    let dest_token = TokenAccount::unpack(&destination.data.borrow())?;\n    if dest_token.mint != *expected_mint {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    invoke(&transfer_instruction, &accounts)?;\n    Ok(())\n}\n```\n\n### 2. Check Token Program ID\n\n#### Anchor Approach\n\n```rust\n// Anchor automatically validates via Interface type\npub token_program: Interface<'info, TokenInterface>,\n```\n\n#### Native Rust Approach\n\n```rust\npub fn validate_token_program(token_program: &AccountInfo) -> ProgramResult {\n    if token_program.key != &spl_token::ID && token_program.key != &spl_token_2022::ID {\n        msg!(\"Invalid Token Program\");\n        return Err(ProgramError::IncorrectProgramId);\n    }\n    Ok(())\n}\n```\n\n### 3. Verify Mint Matches\n\n**Attack scenario:** Attacker passes token account for wrong mint.\n\n#### Anchor Approach\n\n```rust\n#[account(\n    constraint = token_account.mint == expected_mint.key() @ ErrorCode::InvalidMint,\n)]\npub token_account: InterfaceAccount<'info, TokenAccount>,\n```\n\n#### Native Rust Approach\n\n```rust\n// Always verify mint\nlet source_token = TokenAccount::unpack(&source.data.borrow())?;\nlet dest_token = TokenAccount::unpack(&dest.data.borrow())?;\n\nif source_token.mint != dest_token.mint {\n    msg!(\"Mint mismatch between source and destination\");\n    return Err(ProgramError::InvalidAccountData);\n}\n```\n\n### 4. Authority Checks\n\n#### Anchor Approach\n\n```rust\n#[account(\n    constraint = token_account.owner == authority.key() @ ErrorCode::Unauthorized,\n)]\npub token_account: InterfaceAccount<'info, TokenAccount>,\n\npub authority: Signer<'info>,  // Automatically validates is_signer\n```\n\n#### Native Rust Approach\n\n```rust\n// Verify authority matches token account owner\nlet token_account = TokenAccount::unpack(&token_account_info.data.borrow())?;\n\nif token_account.owner != *authority.key {\n    msg!(\"Authority doesn't own token account\");\n    return Err(ProgramError::IllegalOwner);\n}\n\n// Verify authority signed\nif !authority.is_signer {\n    msg!(\"Authority must sign\");\n    return Err(ProgramError::MissingRequiredSignature);\n}\n```\n\n### 5. Account State Checks\n\n#### Anchor Approach\n\n```rust\nuse spl_token::state::AccountState;\n\npub fn check_not_frozen(ctx: Context<SomeContext>) -> Result<()> {\n    let token_account = &ctx.accounts.token_account;\n\n    require!(\n        token_account.state == AccountState::Initialized,\n        ErrorCode::AccountFrozen\n    );\n\n    Ok(())\n}\n```\n\n#### Native Rust Approach\n\n```rust\nlet token_account = TokenAccount::unpack(&token_account_info.data.borrow())?;\n\n// Check not frozen\nif token_account.state == spl_token::state::AccountState::Frozen {\n    msg!(\"Token account is frozen\");\n    return Err(ProgramError::InvalidAccountData);\n}\n\n// Check initialized\nif token_account.state == spl_token::state::AccountState::Uninitialized {\n    msg!(\"Token account not initialized\");\n    return Err(ProgramError::UninitializedAccount);\n}\n```\n\n### 6. Use TransferChecked Over Transfer\n\n**Why:** `transfer_checked` validates the mint and decimals, preventing certain attack vectors.\n\n#### Anchor Approach\n\n```rust\n// ✅ Preferred - validates mint and decimals\ntoken_interface::transfer_checked(\n    cpi_context,\n    amount,\n    decimals,\n)?;\n\n// ❌ Less secure - no mint/decimal validation\ntoken_interface::transfer(\n    cpi_context,\n    amount,\n)?;\n```\n\n#### Native Rust Approach\n\n```rust\n// ✅ Preferred\ninvoke(\n    &transfer_checked(\n        token_program.key,\n        source.key,\n        mint.key,\n        destination.key,\n        authority.key,\n        &[],\n        amount,\n        decimals,\n    )?,\n    &accounts,\n)?;\n\n// ❌ Less secure\ninvoke(\n    &transfer(\n        token_program.key,\n        source.key,\n        destination.key,\n        authority.key,\n        &[],\n        amount,\n    )?,\n    &accounts,\n)?;\n```\n\n---\n\n## Summary\n\n### Key Takeaways\n\n**Anchor Advantages:**\n- Automatic account validation through constraints\n- Cleaner, more concise code\n- Built-in safety checks\n- Type-safe account structures\n- Simplified CPI with `CpiContext`\n\n**Native Rust Advantages:**\n- Full control over all operations\n- No framework overhead\n- Explicit validation (can be more transparent)\n- Useful for understanding low-level mechanics\n\n### Common Operations Quick Reference\n\n| Operation | Anchor Module | Native Rust Crate |\n|-----------|---------------|-------------------|\n| Mint tokens | `token_interface::mint_to` | `spl_token::instruction::mint_to` |\n| Transfer tokens | `token_interface::transfer` | `spl_token::instruction::transfer` |\n| Transfer checked | `token_interface::transfer_checked` | `spl_token::instruction::transfer_checked` |\n| Burn tokens | `token_interface::burn` | `spl_token::instruction::burn` |\n| Create ATA | `associated_token` constraint | `spl_associated_token_account` |\n| Close account | `token_interface::close_account` | `spl_token::instruction::close_account` |\n| Freeze account | `token_interface::freeze_account` | `spl_token::instruction::freeze_account` |\n\n### Security Checklist\n\n- ✅ Validate token program ID\n- ✅ Verify token account ownership\n- ✅ Check mint matches expected\n- ✅ Confirm authority is signer\n- ✅ Ensure account not frozen\n- ✅ Validate ATA derivation if applicable\n- ✅ Use `transfer_checked` instead of `transfer`\n- ✅ Validate account state (initialized/frozen)\n- ✅ Check sufficient balance before operations\n\n### Token Account Sizes\n\n- **Mint account:** 82 bytes\n- **Token account:** 165 bytes\n- **Token-2022 with extensions:** 82/165 + extension sizes\n\nToken integration is fundamental for DeFi, NFT, and gaming programs on Solana. Whether using Anchor or native Rust, understanding both approaches provides the flexibility to choose the right tool for your use case.\n",
        "solana/skills/solana-development/references/tokens-validation.md": "# SPL Token Program - Validation Patterns\n\nValidation patterns for SPL Token accounts including ownership verification, mint validation, ATA address derivation checks, and balance verification. Covers both Anchor constraint-based and Native Rust manual validation approaches.\n\n**For related topics, see:**\n- **[tokens-overview.md](tokens-overview.md)** - Token fundamentals and account structures\n- **[tokens-operations.md](tokens-operations.md)** - Create, mint, transfer, burn, close operations\n- **[tokens-2022.md](tokens-2022.md)** - Token Extensions Program features\n- **[tokens-patterns.md](tokens-patterns.md)** - Common patterns and security\n\n## Table of Contents\n\n1. [Validate Token Account Ownership and Mint](#validate-token-account-ownership-and-mint)\n2. [Validate ATA Address](#validate-ata-address)\n3. [Check Token Balance](#check-token-balance)\n\n---\n\n## Validate Token Account Ownership and Mint\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::{TokenAccount, Mint};\n\n#[derive(Accounts)]\npub struct ValidateTokenAccount<'info> {\n    #[account(\n        constraint = token_account.owner == owner.key() @ ErrorCode::InvalidOwner,\n        constraint = token_account.mint == mint.key() @ ErrorCode::InvalidMint,\n    )]\n    pub token_account: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Any account\n    pub owner: UncheckedAccount<'info>,\n}\n\npub fn validate_token_account(ctx: Context<ValidateTokenAccount>) -> Result<()> {\n    // Validation is automatic via constraints\n\n    // Additional checks if needed\n    require!(\n        ctx.accounts.token_account.amount >= 100,\n        ErrorCode::InsufficientBalance\n    );\n\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse spl_token::state::Account as TokenAccount;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    msg,\n    program_error::ProgramError,\n    program_pack::Pack,\n    pubkey::Pubkey,\n};\n\npub fn validate_token_account(\n    token_account_info: &AccountInfo,\n    expected_owner: &Pubkey,\n    expected_mint: &Pubkey,\n) -> ProgramResult {\n    // 1. Verify owned by Token Program\n    if token_account_info.owner != &spl_token::ID {\n        msg!(\"Account not owned by Token Program\");\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // 2. Deserialize token account\n    let token_account = TokenAccount::unpack(&token_account_info.data.borrow())?;\n\n    // 3. Verify owner\n    if token_account.owner != *expected_owner {\n        msg!(\"Token account owner mismatch\");\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // 4. Verify mint\n    if token_account.mint != *expected_mint {\n        msg!(\"Token account mint mismatch\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // 5. Verify not frozen\n    if token_account.state != spl_token::state::AccountState::Initialized {\n        msg!(\"Token account is frozen or uninitialized\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Validate ATA Address\n\n### Using Anchor\n\n```rust\nuse anchor_spl::associated_token::AssociatedToken;\nuse anchor_spl::token_interface::{Mint, TokenAccount, TokenInterface};\n\n#[derive(Accounts)]\npub struct ValidateATA<'info> {\n    #[account(\n        associated_token::mint = mint,\n        associated_token::authority = owner,\n        associated_token::token_program = token_program,\n    )]\n    pub ata: InterfaceAccount<'info, TokenAccount>,\n\n    pub mint: InterfaceAccount<'info, Mint>,\n\n    /// CHECK: Any account\n    pub owner: UncheckedAccount<'info>,\n\n    pub token_program: Interface<'info, TokenInterface>,\n}\n\npub fn validate_ata(ctx: Context<ValidateATA>) -> Result<()> {\n    // ATA address is automatically validated by Anchor constraints\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse spl_associated_token_account::get_associated_token_address;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    msg,\n    program_error::ProgramError,\n    pubkey::Pubkey,\n};\n\npub fn validate_ata(\n    ata_info: &AccountInfo,\n    wallet: &Pubkey,\n    mint: &Pubkey,\n) -> ProgramResult {\n    // Derive expected ATA address\n    let expected_ata = get_associated_token_address(wallet, mint);\n\n    // Validate match\n    if expected_ata != *ata_info.key {\n        msg!(\"Invalid ATA address\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Check Token Balance\n\n### Using Anchor\n\n```rust\nuse anchor_spl::token_interface::TokenAccount;\n\npub fn check_balance(\n    ctx: Context<SomeContext>,\n    minimum_amount: u64\n) -> Result<()> {\n    let token_account = &ctx.accounts.token_account;\n\n    require!(\n        token_account.amount >= minimum_amount,\n        ErrorCode::InsufficientBalance\n    );\n\n    Ok(())\n}\n```\n\n### Using Native Rust\n\n```rust\nuse spl_token::state::Account as TokenAccount;\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    msg,\n    program_error::ProgramError,\n    program_pack::Pack,\n};\n\npub fn check_token_balance(\n    token_account_info: &AccountInfo,\n    minimum_amount: u64,\n) -> ProgramResult {\n    let token_account = TokenAccount::unpack(&token_account_info.data.borrow())?;\n\n    if token_account.amount < minimum_amount {\n        msg!(\"Insufficient token balance: {} < {}\", token_account.amount, minimum_amount);\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    Ok(())\n}\n```\n\n---\n\n## Next Steps\n\n- **Token-2022**: See [tokens-2022.md](tokens-2022.md) for Token Extensions Program features\n- **Patterns & Security**: See [tokens-patterns.md](tokens-patterns.md) for common patterns and comprehensive security best practices\n",
        "solana/skills/solana-development/references/transaction-lifecycle.md": "# Transaction Lifecycle: Submission, Retry, and Confirmation\n\nThis guide covers the complete lifecycle of Solana transactions from submission to confirmation, including why transactions get dropped, retry strategies, commitment levels, and monitoring patterns for production systems.\n\n## Transaction Journey Overview\n\n### The Full Path\n\n```\n[1] Client                     Creates and signs transaction\n    ↓\n[2] RPC Node                   Validates and forwards\n    ↓\n[3] Leader's TPU               Transaction Processing Unit pipeline\n    ├─ Fetch Stage            Receives from network\n    ├─ SigVerify Stage        Verifies signatures\n    ├─ Banking Stage          Executes transactions\n    ├─ PoH Service            Records in Proof of History\n    └─ Broadcast Stage        Shares with cluster\n    ↓\n[4] Cluster Validation         Validators vote on blocks\n    ↓\n[5] Confirmation Levels\n    ├─ Processed              Included in block by leader\n    ├─ Confirmed              Supermajority voted (~66% stake)\n    └─ Finalized              32+ confirmed blocks after (~13 seconds)\n```\n\n### Time\n\nline\n\n**Normal flow:**\n- Client → RPC: Instant (local network)\n- RPC → Leader: 100-400ms (network latency)\n- Leader processing: 400-600ms (slot time)\n- Confirmed: ~1-2 slots (~800-1200ms)\n- Finalized: ~32 slots (~13+ seconds)\n\n**Total time (happy path):** ~1-15 seconds\n\n## Blockhash Expiration\n\n### How Blockhashes Work\n\nSolana transactions include a `recent_blockhash` field for two purposes:\n1. **Uniqueness**: Ensures each transaction is unique (prevents duplicates)\n2. **Freshness**: Limits transaction validity to prevent spam\n\n**Critical constraint:**\n\n```rust\n// Solana runtime maintains BlockhashQueue\nstruct BlockhashQueue {\n    last_hash: Hash,\n    ages: HashMap<Hash, HashAge>,\n    max_age: usize,  // Currently 151\n}\n\n// Transaction validation:\nfn is_valid_blockhash(blockhash: &Hash, queue: &BlockhashQueue) -> bool {\n    queue.ages.contains_key(blockhash)  // Must be in last 151 blockhashes\n}\n```\n\n### The 151-Block Window\n\n**How it works:**\n1. Each slot produces a new blockhash (~400-600ms per slot)\n2. Runtime keeps last 151 blockhashes in `BlockhashQueue`\n3. Transactions checked against this queue\n4. If blockhash older than 150 blocks → **REJECTED**\n\n**Calculation:**\n```\n151 blockhashes × ~600ms average slot time = ~90 seconds maximum\n151 blockhashes × ~400ms minimum slot time = ~60 seconds minimum\n\nEffective window: 60-90 seconds\n```\n\n**Critical**: Once a blockhash exits the queue (>150 blocks old), transactions using it can **never** be processed. They're permanently invalid.\n\n### Detecting Expiration\n\n**Using `lastValidBlockHeight`:**\n\n```rust\nuse solana_client::rpc_client::RpcClient;\nuse solana_sdk::commitment_config::CommitmentConfig;\n\nasync fn check_transaction_expiration(\n    rpc_client: &RpcClient,\n    last_valid_block_height: u64,\n) -> bool {\n    // Get current block height\n    let current_block_height = rpc_client\n        .get_block_height()\n        .unwrap_or(0);\n\n    // Transaction expired if current height > last valid height\n    current_block_height > last_valid_block_height\n}\n```\n\n**Getting `lastValidBlockHeight`:**\n\n```rust\nlet blockhash_response = rpc_client.get_latest_blockhash()?;\n\nlet blockhash = blockhash_response.value.0;\nlet last_valid_block_height = blockhash_response.value.1;  // Blocks until expiration\n\nprintln!(\"Blockhash: {}\", blockhash);\nprintln!(\"Valid until block: {}\", last_valid_block_height);\n```\n\n### Why Transactions Expire\n\n**Design rationale:**\n\n1. **Prevents replay attacks**: Old transactions can't be resubmitted years later\n2. **Manages state bloat**: Runtime doesn't need infinite blockhash history\n3. **Network spam protection**: Attackers can't flood network with ancient transactions\n4. **Simplifies fee markets**: Recent activity determines current conditions\n\n**Trade-off**: 60-90 second window requires responsive clients and reliable networking.\n\n## How Transactions Get Dropped\n\n### Before Processing\n\n**1. UDP Packet Loss**\n\nSolana uses UDP for transaction forwarding (performance over reliability):\n\n```\nClient → RPC: UDP packet\nRPC → Leader: UDP packet\n\nPacket loss rate: 0.1-5% depending on network conditions\n```\n\n**Impact**: Transaction silently dropped, never reaches leader.\n\n**Detection**: No error, no confirmation - transaction just disappears.\n\n**Solution**: Retry mechanism (RPC default behavior).\n\n**2. RPC Node Congestion**\n\nRPC nodes maintain transaction queues:\n\n```rust\n// RPC node queue limits\nconst MAX_TRANSACTIONS_QUEUE: usize = 10_000;\n\n// When queue full:\nif queue.len() >= MAX_TRANSACTIONS_QUEUE {\n    return Err(\"Transaction queue full, try again\");\n}\n```\n\n**Impact**: New transactions rejected when queue full.\n\n**Detection**: RPC returns error immediately.\n\n**Solution**: Back off and retry, or use different RPC endpoint.\n\n**3. RPC Node Lag**\n\nRPC nodes can fall behind cluster:\n\n```rust\n// Check RPC health\nlet processed_slot = rpc_client.get_slot()?;\nlet max_shred_insert_slot = rpc_client.get_max_shred_insert_slot()?;\n\nlet lag = max_shred_insert_slot.saturating_sub(processed_slot);\n\nif lag > 50 {\n    println!(\"WARNING: RPC is {} slots behind\", lag);\n    // Consider using different RPC node\n}\n```\n\n**Impact**: Fetches stale blockhashes that expire quickly.\n\n**Solution**: Monitor RPC health, use multiple RPC providers.\n\n**4. Blockhash from Minority Fork**\n\nClusters occasionally fork temporarily (~5% of slots):\n\n```\nMajority fork: Block A → Block B → Block C\nMinority fork: Block A → Block X (abandoned)\n```\n\nIf you fetch blockhash from minority fork:\n- Blockhash is valid on minority fork\n- Majority fork has different blockhash\n- Transaction **never** valid on majority fork\n\n**Impact**: Transaction permanently invalid (never in BlockhashQueue of majority fork).\n\n**Detection**: Transaction never confirms, blockhash never appears in majority chain.\n\n**Solution**: Use `confirmed` commitment level when fetching blockhashes (not `processed`).\n\n### After Processing But Before Finalization\n\n**5. Leader on Minority Fork**\n\nTransaction processed by leader, but leader's block abandoned by cluster:\n\n```\n1. Leader processes transaction in slot 1000\n2. Cluster votes on slot 1000\n3. Supermajority votes for different fork\n4. Leader's block (and transaction) discarded\n```\n\n**Impact**: Transaction processed but not confirmed. Must resubmit.\n\n**Detection**: Transaction shows as processed but never confirmed.\n\n**Solution**: Wait for `confirmed` level before assuming success.\n\n**6. Transaction Expiration During Retry**\n\nDefault RPC retry behavior has limitations:\n\n```rust\n// RPC retry logic (simplified):\nwhile !finalized && !expired {\n    forward_to_leader();\n    sleep(2_seconds);\n}\n\n// Problem: What if we can't determine expiration?\n// RPC may stop retrying early!\n```\n\n**Impact**: RPC stops retrying before transaction actually expires.\n\n**Solution**: Implement custom retry logic with explicit expiration tracking.\n\n## Commitment Levels\n\n### Understanding Commitment\n\nSolana has three commitment levels representing stages of finality:\n\n```\nProcessed\n    ↓ (1-2 slots later)\nConfirmed\n    ↓ (32+ slots later, ~13 seconds)\nFinalized\n```\n\n### Processed\n\n**Definition**: Transaction processed by leader and included in a block.\n\n**Characteristics:**\n- Fastest (most recent)\n- Least safe (~5% chance of being on abandoned fork)\n- Can be rolled back if fork abandoned\n\n**When to use:**\n- Real-time UX updates (show pending state)\n- Price feeds where staleness is worse than occasional rollback\n- **NOT for blockhash fetching** (risk of minority fork blockhash)\n\n**Example:**\n```rust\nuse solana_client::rpc_config::RpcSendTransactionConfig;\nuse solana_sdk::commitment_config::CommitmentLevel;\n\nlet config = RpcSendTransactionConfig {\n    skip_preflight: false,\n    preflight_commitment: Some(CommitmentLevel::Processed),\n    ..Default::default()\n};\n\n// Risky! Blockhash might be from minority fork\nlet signature = rpc_client.send_transaction_with_config(&transaction, config)?;\n```\n\n### Confirmed\n\n**Definition**: Supermajority of validators voted for the block containing the transaction.\n\n**Characteristics:**\n- Fast (~1-2 slots, ~600-1200ms)\n- Safe (~<0.1% chance of rollback in normal conditions)\n- **RECOMMENDED for blockhash fetching**\n\n**When to use:**\n- **Default choice** for most operations\n- Blockhash fetching (balance of speed and safety)\n- Transaction submission (preflight commitment)\n- Confirmation monitoring\n\n**Example:**\n```rust\nlet commitment = CommitmentConfig::confirmed();\n\n// Fetch blockhash at confirmed level\nlet recent_blockhash = rpc_client.get_latest_blockhash_with_commitment(commitment)?;\n\n// Set preflight commitment to match\nlet config = RpcSendTransactionConfig {\n    preflight_commitment: Some(CommitmentLevel::Confirmed),\n    ..Default::default()\n};\n```\n\n### Finalized\n\n**Definition**: 32+ confirmed blocks have been built on top (mathematically impossible to rollback).\n\n**Characteristics:**\n- Slowest (~13+ seconds)\n- 100% safe (impossible to rollback)\n- Guaranteed by consensus algorithm\n\n**When to use:**\n- Financial settlement\n- Legal/compliance requirements\n- Cross-chain bridges\n- Critical state changes\n\n**Example:**\n```rust\nlet commitment = CommitmentConfig::finalized();\n\n// Wait for finalization\nrpc_client.confirm_transaction_with_spinner(\n    &signature,\n    &recent_blockhash,\n    commitment,\n)?;\n```\n\n### Preflight Commitment Matching\n\n**Critical rule**: Preflight commitment MUST match blockhash fetch commitment.\n\n**Why:**\n\n```rust\n// Scenario: Mismatch\nlet blockhash = rpc.get_latest_blockhash_with_commitment(confirmed)?;  // confirmed\n\nlet config = RpcSendTransactionConfig {\n    preflight_commitment: Some(CommitmentLevel::Processed),  // processed (WRONG!)\n    ..Default::default()\n};\n\n// RPC tries to simulate at processed level\n// But blockhash only exists at confirmed level\n// Result: \"Blockhash not found\" error\n```\n\n**Correct approach:**\n\n```rust\nlet commitment = CommitmentConfig::confirmed();\n\n// Fetch blockhash\nlet blockhash_response = rpc.get_latest_blockhash_with_commitment(commitment)?;\nlet blockhash = blockhash_response.0;\n\n// Match preflight commitment\nlet config = RpcSendTransactionConfig {\n    preflight_commitment: Some(CommitmentLevel::Confirmed),\n    ..Default::default()\n};\n\nlet signature = rpc.send_transaction_with_config(&transaction, config)?;\n```\n\n## RPC Retry Behavior\n\n### Default Retry Logic\n\nRPC nodes automatically retry transactions:\n\n```rust\n// Simplified RPC retry algorithm:\nconst RETRY_INTERVAL: Duration = Duration::from_secs(2);\nconst MAX_QUEUE_SIZE: usize = 10_000;\n\nloop {\n    if transaction.is_finalized() {\n        return Ok(signature);\n    }\n\n    if queue.len() >= MAX_QUEUE_SIZE {\n        return Err(\"Queue full\");\n    }\n\n    if can_determine_expiration() {\n        if transaction.is_expired() {\n            return Err(\"Blockhash expired\");\n        }\n    } else {\n        // Conservative: retry only once if can't determine expiration\n        if retry_count > 1 {\n            return Ok(signature);  // Might not actually be finalized!\n        }\n    }\n\n    forward_to_current_leader();\n    forward_to_next_leader();\n    sleep(RETRY_INTERVAL);\n    retry_count += 1;\n}\n```\n\n### Leader Forwarding\n\nRPC forwards transactions to:\n1. **Current leader**: For immediate processing\n2. **Next leader**: In case current leader rotation happens\n\n**Why both?**\n- Leader rotation happens every 4 slots (~1.6-2.4 seconds)\n- Transaction might arrive during rotation\n- Next leader can process in upcoming slots\n\n### Queue Pressure\n\nDuring congestion:\n\n```\nQueue size: 10,000 transactions\nNew transaction arrives:\n    if queue.is_full():\n        reject(\"Transaction queue full\")\n    else:\n        queue.push(transaction)\n        retry_until_finalized()\n```\n\n**User experience:**\n- Fresh transactions rejected when queue full\n- Older transactions keep retrying\n- Can create priority inversion (old low-priority tx blocks new high-priority tx)\n\n**Solution**: Use `maxRetries: 0` to take manual control during congestion.\n\n## Custom Retry Strategies\n\n### Manual Retry Loop\n\nTaking full control:\n\n```rust\nuse solana_client::rpc_client::RpcClient;\nuse solana_sdk::signature::Signature;\nuse std::time::Duration;\nuse tokio::time::sleep;\n\nasync fn send_transaction_with_retry(\n    rpc_client: &RpcClient,\n    transaction: &Transaction,\n    last_valid_block_height: u64,\n) -> Result<Signature, Box<dyn std::error::Error>> {\n    let config = RpcSendTransactionConfig {\n        skip_preflight: true,  // Already validated\n        max_retries: Some(0),  // Manual retry control\n        ..Default::default()\n    };\n\n    let signature = rpc_client.send_transaction_with_config(\n        transaction,\n        config,\n    )?;\n\n    // Manual retry loop\n    loop {\n        // Check if transaction confirmed\n        match rpc_client.get_signature_status(&signature)? {\n            Some(Ok(_)) => {\n                println!(\"Transaction confirmed!\");\n                return Ok(signature);\n            }\n            Some(Err(e)) => {\n                return Err(format!(\"Transaction failed: {:?}\", e).into());\n            }\n            None => {\n                // Not processed yet, continue\n            }\n        }\n\n        // Check expiration\n        let current_block_height = rpc_client.get_block_height()?;\n        if current_block_height > last_valid_block_height {\n            return Err(\"Transaction expired\".into());\n        }\n\n        // Resubmit\n        rpc_client.send_transaction_with_config(transaction, config)?;\n\n        // Wait before next retry\n        sleep(Duration::from_millis(500)).await;\n    }\n}\n```\n\n### Exponential Backoff\n\nReduce network load during congestion:\n\n```rust\nasync fn retry_with_exponential_backoff(\n    rpc_client: &RpcClient,\n    transaction: &Transaction,\n    last_valid_block_height: u64,\n) -> Result<Signature, Box<dyn std::error::Error>> {\n    let signature = rpc_client.send_transaction(transaction)?;\n\n    let mut retry_delay = Duration::from_millis(500);\n    const MAX_DELAY: Duration = Duration::from_secs(8);\n\n    loop {\n        match rpc_client.get_signature_status(&signature)? {\n            Some(Ok(_)) => return Ok(signature),\n            Some(Err(e)) => return Err(e.into()),\n            None => {\n                // Check expiration\n                if rpc_client.get_block_height()? > last_valid_block_height {\n                    return Err(\"Expired\".into());\n                }\n\n                // Resubmit\n                rpc_client.send_transaction(transaction)?;\n\n                // Exponential backoff\n                sleep(retry_delay).await;\n                retry_delay = std::cmp::min(retry_delay * 2, MAX_DELAY);\n            }\n        }\n    }\n}\n```\n\n### Constant Interval (Mango Approach)\n\nAggressive resubmission:\n\n```rust\nasync fn retry_constant_interval(\n    rpc_client: &RpcClient,\n    transaction: &Transaction,\n    last_valid_block_height: u64,\n) -> Result<Signature, Box<dyn std::error::Error>> {\n    let signature = rpc_client.send_transaction(transaction)?;\n\n    const RETRY_INTERVAL: Duration = Duration::from_millis(500);\n\n    loop {\n        match rpc_client.get_signature_status(&signature)? {\n            Some(Ok(_)) => return Ok(signature),\n            Some(Err(e)) => return Err(e.into()),\n            None => {\n                if rpc_client.get_block_height()? > last_valid_block_height {\n                    return Err(\"Expired\".into());\n                }\n\n                // Constant interval resubmission\n                rpc_client.send_transaction(transaction)?;\n                sleep(RETRY_INTERVAL).await;\n            }\n        }\n    }\n}\n```\n\n**Trade-offs:**\n- **Exponential backoff**: Network-friendly, slower confirmation\n- **Constant interval**: Faster confirmation, more network load\n- **Choice depends on**: Application needs, RPC provider limits, congestion levels\n\n## Confirmation Monitoring\n\n### Polling for Confirmation\n\n**Basic polling:**\n\n```rust\nuse solana_sdk::signature::Signature;\n\nfn wait_for_confirmation(\n    rpc_client: &RpcClient,\n    signature: &Signature,\n    commitment: CommitmentConfig,\n) -> Result<(), Box<dyn std::error::Error>> {\n    loop {\n        match rpc_client.get_signature_status_with_commitment(\n            signature,\n            commitment,\n        )? {\n            Some(Ok(_)) => {\n                println!(\"Transaction confirmed at {:?}\", commitment);\n                return Ok(());\n            }\n            Some(Err(e)) => {\n                return Err(format!(\"Transaction failed: {:?}\", e).into());\n            }\n            None => {\n                std::thread::sleep(Duration::from_millis(500));\n            }\n        }\n    }\n}\n```\n\n**With timeout:**\n\n```rust\nuse std::time::{Duration, Instant};\n\nfn wait_for_confirmation_with_timeout(\n    rpc_client: &RpcClient,\n    signature: &Signature,\n    timeout: Duration,\n) -> Result<bool, Box<dyn std::error::Error>> {\n    let start = Instant::now();\n\n    while start.elapsed() < timeout {\n        match rpc_client.get_signature_status(signature)? {\n            Some(Ok(_)) => return Ok(true),\n            Some(Err(e)) => return Err(e.into()),\n            None => std::thread::sleep(Duration::from_millis(500)),\n        }\n    }\n\n    Ok(false)  // Timed out\n}\n```\n\n### Using `confirm_transaction`\n\nBuilt-in helper with expiration tracking:\n\n```rust\nlet commitment = CommitmentConfig::confirmed();\n\n// Method 1: With blockhash context\nrpc_client.confirm_transaction_with_spinner(\n    &signature,\n    &recent_blockhash,\n    commitment,\n)?;\n\n// Method 2: With last valid block height (recommended)\nlet result = rpc_client.confirm_transaction_with_commitment(\n    &signature,\n    commitment,\n)?;\n\nif result.value {\n    println!(\"Transaction confirmed!\");\n} else {\n    println!(\"Transaction not confirmed (might have expired)\");\n}\n```\n\n### WebSocket Subscriptions (Real-Time)\n\nFor real-time updates without polling:\n\n```rust\nuse solana_client::pubsub_client::PubsubClient;\nuse solana_sdk::commitment_config::CommitmentConfig;\n\nasync fn subscribe_to_signature(\n    ws_url: &str,\n    signature: &Signature,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let pubsub_client = PubsubClient::new(ws_url).await?;\n\n    let (mut stream, unsubscribe) = pubsub_client\n        .signature_subscribe(signature, Some(CommitmentConfig::confirmed()))\n        .await?;\n\n    // Wait for notification\n    while let Some(response) = stream.next().await {\n        match response.value {\n            solana_client::rpc_response::RpcSignatureResult::ProcessedSignature(_) => {\n                println!(\"Transaction confirmed!\");\n                break;\n            }\n        }\n    }\n\n    unsubscribe().await;\n    Ok(())\n}\n```\n\n**Advantages:**\n- Real-time notification (no polling delay)\n- Lower RPC load\n- Immediate feedback\n\n**Disadvantages:**\n- WebSocket connection overhead\n- Need to handle disconnections\n- Not all RPC providers support WebSockets\n\n## Best Practices\n\n### 1. Fetch Fresh Blockhashes\n\n```rust\n// BAD: Fetch once and reuse\nlet blockhash = rpc.get_latest_blockhash()?;\nfor tx in transactions {\n    // All use same blockhash (increases expiration risk)\n    send_transaction(tx, &blockhash)?;\n}\n\n// GOOD: Fetch fresh blockhash for each transaction\nfor tx in transactions {\n    let blockhash = rpc.get_latest_blockhash()?;\n    send_transaction(tx, &blockhash)?;\n}\n\n// BETTER: Fetch fresh blockhash right before signing\nfn prepare_and_send(user_action: Action) {\n    // User initiates action\n    let blockhash = rpc.get_latest_blockhash()?;  // Fetch now!\n\n    // Build and sign (fast)\n    let tx = build_transaction(user_action, &blockhash);\n    sign_transaction(&tx);\n\n    // Submit immediately\n    send_transaction(&tx)?;\n}\n```\n\n### 2. Use Confirmed Commitment\n\n```rust\n// RECOMMENDED: Confirmed commitment\nlet commitment = CommitmentConfig::confirmed();\nlet blockhash = rpc.get_latest_blockhash_with_commitment(commitment)?;\n\n// Risks minority fork\nlet blockhash = rpc.get_latest_blockhash_with_commitment(\n    CommitmentConfig::processed()\n)?;  // Avoid!\n```\n\n### 3. Match Preflight Commitment\n\n```rust\nlet commitment = CommitmentConfig::confirmed();\n\n// Fetch blockhash\nlet (blockhash, last_valid_block_height) = rpc\n    .get_latest_blockhash_with_commitment(commitment)?;\n\n// Match preflight commitment\nlet config = RpcSendTransactionConfig {\n    preflight_commitment: Some(CommitmentLevel::Confirmed),  // MATCH!\n    ..Default::default()\n};\n```\n\n### 4. Track Expiration Explicitly\n\n```rust\n// Get expiration info\nlet (blockhash, last_valid_block_height) = rpc.get_latest_blockhash()?;\n\n// Check before retry\nfn should_retry(rpc: &RpcClient, last_valid: u64) -> bool {\n    rpc.get_block_height().unwrap_or(0) <= last_valid\n}\n```\n\n### 5. Monitor RPC Health\n\n```rust\nasync fn check_rpc_health(rpc: &RpcClient) -> bool {\n    let processed = rpc.get_slot().unwrap_or(0);\n    let max_shred = rpc.get_max_shred_insert_slot().unwrap_or(0);\n\n    let lag = max_shred.saturating_sub(processed);\n\n    if lag > 50 {\n        eprintln!(\"RPC lagging by {} slots\", lag);\n        return false;\n    }\n\n    true\n}\n```\n\n### 6. Implement Proper Error Handling\n\n```rust\nmatch rpc.send_transaction(&tx) {\n    Ok(signature) => {\n        println!(\"Submitted: {}\", signature);\n        // Wait for confirmation\n    }\n    Err(e) => {\n        if e.to_string().contains(\"BlockhashNotFound\") {\n            // Blockhash expired, fetch fresh one\n            let new_blockhash = rpc.get_latest_blockhash()?;\n            // Re-sign transaction with new blockhash\n        } else if e.to_string().contains(\"AlreadyProcessed\") {\n            // Transaction already submitted (safe to ignore)\n        } else {\n            // Other error, handle appropriately\n            return Err(e.into());\n        }\n    }\n}\n```\n\n### 7. Use Skip Preflight Judiciously\n\n```rust\n// When to skip preflight:\n// - During congestion (preflight adds latency)\n// - When retrying (already validated once)\n// - When you're confident about transaction validity\n\nlet config = RpcSendTransactionConfig {\n    skip_preflight: true,  // Skip simulation\n    preflight_commitment: Some(CommitmentLevel::Confirmed),\n    max_retries: Some(0),\n    ..Default::default()\n};\n\n// Still recommended: Simulate ONCE before skip_preflight\nrpc.simulate_transaction(&tx)?;  // Catch errors\n// Then submit with skip_preflight for speed\n```\n\n## Production Patterns\n\n### High-Throughput System\n\n```rust\nstruct TransactionSubmitter {\n    rpc_client: Arc<RpcClient>,\n    retry_queue: Arc<Mutex<VecDeque<RetryableTransaction>>>,\n}\n\nstruct RetryableTransaction {\n    transaction: Transaction,\n    signature: Signature,\n    last_valid_block_height: u64,\n    submitted_at: Instant,\n    retry_count: usize,\n}\n\nimpl TransactionSubmitter {\n    async fn submit_transaction(&self, tx: Transaction) -> Result<Signature, Error> {\n        let (blockhash, last_valid) = self.rpc_client.get_latest_blockhash()?;\n\n        // Submit initial\n        let signature = self.rpc_client.send_transaction(&tx)?;\n\n        // Add to retry queue\n        let retryable = RetryableTransaction {\n            transaction: tx,\n            signature,\n            last_valid_block_height: last_valid,\n            submitted_at: Instant::now(),\n            retry_count: 0,\n        };\n\n        self.retry_queue.lock().unwrap().push_back(retryable);\n\n        Ok(signature)\n    }\n\n    async fn retry_worker(&self) {\n        loop {\n            sleep(Duration::from_millis(500)).await;\n\n            let mut queue = self.retry_queue.lock().unwrap();\n\n            for tx in queue.iter_mut() {\n                // Check if confirmed\n                match self.rpc_client.get_signature_status(&tx.signature) {\n                    Ok(Some(Ok(_))) => {\n                        // Confirmed, remove from queue (handle in cleanup pass)\n                        continue;\n                    }\n                    Ok(Some(Err(_))) => {\n                        // Failed, remove from queue\n                        continue;\n                    }\n                    _ => {\n                        // Not confirmed, check expiration\n                        let current_height = self.rpc_client.get_block_height().unwrap_or(0);\n\n                        if current_height > tx.last_valid_block_height {\n                            // Expired, remove from queue\n                            continue;\n                        }\n\n                        // Retry\n                        let _ = self.rpc_client.send_transaction(&tx.transaction);\n                        tx.retry_count += 1;\n                    }\n                }\n            }\n\n            // Cleanup confirmed/failed/expired\n            queue.retain(|tx| {\n                matches!(\n                    self.rpc_client.get_signature_status(&tx.signature),\n                    Ok(None)  // Still pending\n                )\n            });\n        }\n    }\n}\n```\n\n### Wallet Integration\n\n```rust\nasync fn wallet_send_transaction(\n    rpc: &RpcClient,\n    unsigned_tx: Transaction,\n    signer: &dyn Signer,\n) -> Result<Signature, Error> {\n    // Fetch blockhash immediately before signing\n    let (blockhash, last_valid) = rpc.get_latest_blockhash()?;\n\n    // Update transaction with fresh blockhash\n    let mut tx = unsigned_tx.clone();\n    tx.message.recent_blockhash = blockhash;\n\n    // Sign\n    tx.sign(&[signer], blockhash);\n\n    // Simulate first\n    rpc.simulate_transaction(&tx)?;\n\n    // Submit with retry\n    let signature = tx.signatures[0];\n\n    send_with_retry(rpc, &tx, last_valid).await?;\n\n    Ok(signature)\n}\n```\n\n## Resources\n\n### Official Documentation\n- [Transaction Retry Guide](https://solana.com/developers/guides/advanced/retry)\n- [Transaction Confirmation Guide](https://solana.com/developers/guides/advanced/confirmation)\n\n### Technical References\n- [RpcClient Source](https://github.com/solana-labs/solana/blob/master/client/src/rpc_client.rs)\n- [Transaction Source](https://github.com/solana-labs/solana/blob/master/sdk/src/transaction/mod.rs)\n- [BlockhashQueue Source](https://github.com/solana-labs/solana/blob/master/runtime/src/blockhash_queue.rs)\n\n### Community Resources\n- [Solana Cookbook - Transactions](https://solanacookbook.com/references/basic-transactions.html)\n- [Solana Stack Exchange - Transaction Questions](https://solana.stackexchange.com/questions/tagged/transaction)\n",
        "solana/skills/solana-development/references/versioned-transactions.md": "# Versioned Transactions and Address Lookup Tables\n\nThis guide covers Solana's versioned transaction format and Address Lookup Tables (ALTs), which enable programs to work with more accounts per transaction by compressing account references.\n\n## Introduction\n\n### The Account Limit Problem\n\nSolana transactions are transmitted over UDP and must fit within the IPv6 MTU size of 1280 bytes. After accounting for headers, this leaves approximately 1232 bytes for the transaction packet data.\n\n**Legacy transaction constraints:**\n- Each account address: 32 bytes\n- Signatures and metadata: ~300-400 bytes overhead\n- **Result**: Maximum ~35 accounts per transaction\n\nThis limitation became problematic as developers needed to compose multiple on-chain programs atomically, especially for complex DeFi operations like multi-hop swaps or protocol interactions.\n\n### The Solution: Versioned Transactions\n\nVersioned transactions introduce a new transaction format that supports **Address Lookup Tables (ALTs)**, allowing accounts to be referenced by 1-byte indices instead of full 32-byte addresses.\n\n**Impact:**\n- Legacy (v0 without ALTs): ~35 accounts maximum\n- Versioned (v0 with ALTs): **64+ accounts** per transaction\n- 31-byte savings per account referenced from an ALT\n\n## Transaction Versions\n\n### Version Format\n\nSolana uses the high bit of the first byte to determine transaction version:\n\n```rust\n// Version detection (first byte of transaction)\nif first_byte & 0x80 == 0 {\n    // Legacy transaction (bit pattern: 0xxxxxxx)\n    version = \"legacy\"\n} else {\n    // Versioned transaction (bit pattern: 1xxxxxxx)\n    // Remove version bit to get actual version number\n    version = first_byte & 0x7F  // Currently only version 0 exists\n}\n```\n\n### Legacy Transactions\n\n**Structure:**\n```rust\npub struct LegacyMessage {\n    pub header: MessageHeader,\n    pub account_keys: Vec<Pubkey>,           // All 32-byte addresses\n    pub recent_blockhash: Hash,\n    pub instructions: Vec<CompiledInstruction>,\n}\n```\n\n**Characteristics:**\n- No version byte (implicitly version \"legacy\")\n- All accounts must be fully specified (32 bytes each)\n- Maximum ~35 accounts due to packet size limits\n- Still supported and widely used for simple transactions\n\n### Version 0 Transactions\n\n**Structure:**\n```rust\npub struct MessageV0 {\n    pub header: MessageHeader,\n    pub account_keys: Vec<Pubkey>,           // Directly specified accounts\n    pub recent_blockhash: Hash,\n    pub instructions: Vec<CompiledInstruction>,\n    pub address_table_lookups: Vec<MessageAddressTableLookup>,  // NEW!\n}\n\npub struct MessageAddressTableLookup {\n    pub account_key: Pubkey,                 // ALT address (32 bytes)\n    pub writable_indexes: Vec<u8>,           // Writable account indices\n    pub readonly_indexes: Vec<u8>,           // Readonly account indices\n}\n```\n\n**Characteristics:**\n- Starts with version byte: `0x80` (128 in decimal, version 0)\n- Includes `address_table_lookups` field\n- Can reference accounts from ALTs using 1-byte indices\n- Enables 64+ accounts per transaction\n\n**Transaction size calculation:**\n```\nVersion 0 overhead:\n+ 1 byte (version)\n+ 1 byte (number of lookup tables)\n+ 34 bytes per lookup table (32-byte address + 2 length bytes)\n+ 1 byte per account index referenced\n\nExample with 1 ALT referencing 30 accounts:\n  1 (version) + 1 (table count) + 34 (table) + 30 (indices) = 66 bytes\n\nEquivalent legacy transaction:\n  30 accounts × 32 bytes = 960 bytes\n\nSavings: 960 - 66 = 894 bytes!\n```\n\n## Address Lookup Tables (ALTs)\n\n### What Are ALTs?\n\nAddress Lookup Tables are **on-chain accounts** that store collections of related addresses. They act as a lookup mechanism to compress account references in transactions.\n\n**Key properties:**\n- Managed by the Address Lookup Table Program (`AddressLookupTableProgram`)\n- Store up to **256 addresses** (indexed by u8: 0-255)\n- Can be created, extended, deactivated, and closed\n- Addresses are append-only for security\n\n### ALT Account Structure\n\n```rust\npub struct AddressLookupTable<'a> {\n    pub meta: LookupTableMeta,\n    pub addresses: Cow<'a, [Pubkey]>,\n}\n\npub struct LookupTableMeta {\n    pub deactivation_slot: Slot,           // Slot when deactivated (u64::MAX if active)\n    pub last_extended_slot: Slot,          // Last slot when addresses were added\n    pub last_extended_slot_start_index: u8, // Index where last extension started\n    pub authority: Option<Pubkey>,         // Can add/deactivate (None = immutable)\n}\n```\n\n**On-chain layout:**\n```\nBytes 0-55:   LookupTableMeta (56 bytes)\nBytes 56+:    Raw list of Pubkey addresses (32 bytes each)\n```\n\n### Creating Address Lookup Tables\n\n**Step 1: Create the table**\n\n```rust\nuse solana_sdk::{\n    address_lookup_table_account::instruction as alt_instruction,\n    instruction::Instruction,\n    pubkey::Pubkey,\n    signer::Signer,\n};\n\n// Get recent slot for table derivation\nlet recent_slot = rpc_client.get_slot()?;\n\n// Create lookup table instruction\nlet (create_ix, lookup_table_address) = alt_instruction::create_lookup_table(\n    payer.pubkey(),      // Authority\n    payer.pubkey(),      // Payer\n    recent_slot,         // Recent slot for PDA derivation\n);\n\n// The lookup table address is derived deterministically:\n// PDA(seeds=[authority, recent_slot], program=AddressLookupTableProgram)\n```\n\n**Transaction to create:**\n```rust\nlet create_tx = Transaction::new_signed_with_payer(\n    &[create_ix],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n\nrpc_client.send_and_confirm_transaction(&create_tx)?;\n```\n\n**Important**: Wait for the transaction to be **finalized** before extending or using the table.\n\n**Step 2: Extend the table with addresses**\n\n```rust\n// Addresses to add to the lookup table\nlet addresses_to_add = vec![\n    pubkey1,\n    pubkey2,\n    pubkey3,\n    // ... up to ~20 addresses per transaction\n];\n\nlet extend_ix = alt_instruction::extend_lookup_table(\n    lookup_table_address,\n    payer.pubkey(),        // Authority\n    Some(payer.pubkey()),  // Payer (optional)\n    addresses_to_add,\n);\n\nlet extend_tx = Transaction::new_signed_with_payer(\n    &[extend_ix],\n    Some(&payer.pubkey()),\n    &[&payer],\n    recent_blockhash,\n);\n\nrpc_client.send_and_confirm_transaction(&extend_tx)?;\n```\n\n**Batching strategy:**\n- Each extend operation can add approximately **20 addresses** before hitting transaction size limits\n- For more addresses, send multiple extend transactions\n- Example from TeamRaccoons repo: Batch in chunks of 20\n\n```rust\n// Batch extend for large address sets\nlet batch_size = 20;\nfor chunk in addresses.chunks(batch_size) {\n    let extend_ix = alt_instruction::extend_lookup_table(\n        lookup_table_address,\n        authority.pubkey(),\n        Some(payer.pubkey()),\n        chunk.to_vec(),\n    );\n\n    // Send transaction...\n    rpc_client.send_and_confirm_transaction(&tx)?;\n}\n```\n\n**Warmup period:**\n- Newly added addresses require **1 slot** before they can be used\n- Must wait for finalization before using in v0 transactions\n- Check `last_extended_slot` to ensure addresses are ready\n\n**Step 3: Fetch the lookup table**\n\n```rust\nuse solana_client::rpc_client::RpcClient;\nuse solana_sdk::address_lookup_table_account::AddressLookupTableAccount;\n\nlet lookup_table_account = rpc_client\n    .get_account(&lookup_table_address)?;\n\nlet lookup_table = AddressLookupTableAccount::deserialize(&lookup_table_account.data)?;\n\n// Access addresses\nprintln!(\"Table contains {} addresses\", lookup_table.addresses.len());\nfor (index, address) in lookup_table.addresses.iter().enumerate() {\n    println!(\"Index {}: {}\", index, address);\n}\n```\n\n### Using ALTs in V0 Transactions\n\n**Build a v0 transaction with ALT:**\n\n```rust\nuse solana_sdk::{\n    message::{v0, VersionedMessage},\n    transaction::VersionedTransaction,\n    address_lookup_table_account::AddressLookupTableAccount,\n};\n\n// 1. Create your instructions (can reference >35 accounts)\nlet instructions = vec![\n    // Your program instructions\n];\n\n// 2. Fetch lookup table accounts\nlet lookup_table_account = rpc_client.get_account(&lookup_table_address)?;\nlet lookup_table = AddressLookupTableAccount::deserialize(&lookup_table_account.data)?;\n\n// 3. Build v0 message\nlet v0_message = v0::Message::try_compile(\n    &payer.pubkey(),\n    &instructions,\n    &[lookup_table],    // Pass lookup tables here\n    recent_blockhash,\n)?;\n\n// 4. Create versioned transaction\nlet versioned_tx = VersionedTransaction::try_new(\n    VersionedMessage::V0(v0_message),\n    &[&payer],          // Signers\n)?;\n\n// 5. Send transaction\nlet signature = rpc_client.send_and_confirm_transaction(&versioned_tx)?;\n```\n\n**How accounts are referenced:**\n\nWhen you create an instruction with accounts that exist in the ALT:\n```rust\nuse solana_sdk::instruction::{AccountMeta, Instruction};\n\n// These accounts are in the lookup table at indices 0, 1, 2\nlet account_in_alt_0 = Pubkey::new_unique();\nlet account_in_alt_1 = Pubkey::new_unique();\nlet account_in_alt_2 = Pubkey::new_unique();\n\nlet ix = Instruction::new_with_bytes(\n    program_id,\n    &instruction_data,\n    vec![\n        AccountMeta::new(account_in_alt_0, false),      // Index 0 in ALT\n        AccountMeta::new_readonly(account_in_alt_1, false),  // Index 1\n        AccountMeta::new(account_in_alt_2, false),      // Index 2\n    ],\n);\n\n// When compiled with ALT, these become 1-byte indices instead of 32-byte addresses\n```\n\n### Deactivating and Closing ALTs\n\n**Deactivation:**\n\n```rust\nlet deactivate_ix = alt_instruction::deactivate_lookup_table(\n    lookup_table_address,\n    authority.pubkey(),\n);\n\nrpc_client.send_and_confirm_transaction(&tx)?;\n```\n\n**Why deactivate?**\n- Prevents the table from being used in new transactions\n- Required before closing\n- Creates a safety cooldown period\n\n**Cooldown period:**\n- Must wait until the deactivation slot exits the slot hashes sysvar (~2.5 days on mainnet)\n- Prevents same-slot recreation attacks\n- Ensures no in-flight transactions reference the table\n\n**Closing:**\n\n```rust\nlet close_ix = alt_instruction::close_lookup_table(\n    lookup_table_address,\n    authority.pubkey(),\n    recipient.pubkey(),  // Receives reclaimed rent\n);\n\nrpc_client.send_and_confirm_transaction(&tx)?;\n```\n\n**Requirements:**\n- Table must be deactivated first\n- Deactivation slot must have exited slot hashes sysvar\n- Only authority can close\n- Rent is returned to specified recipient\n\n### Freezing ALTs (Making Immutable)\n\n```rust\nlet freeze_ix = alt_instruction::freeze_lookup_table(\n    lookup_table_address,\n    authority.pubkey(),\n);\n\nrpc_client.send_and_confirm_transaction(&tx)?;\n```\n\n**Effect:**\n- Sets authority to `None`\n- Table becomes **permanently immutable**\n- Cannot add more addresses\n- Cannot deactivate or close\n- Useful for protocol-level tables that should never change\n\n## RPC Configuration for V0 Transactions\n\n**Critical requirement**: When fetching transactions, you must specify support for versioned transactions:\n\n```rust\nuse solana_client::rpc_config::RpcTransactionConfig;\nuse solana_transaction_status::UiTransactionEncoding;\n\nlet config = RpcTransactionConfig {\n    encoding: Some(UiTransactionEncoding::Json),\n    commitment: Some(CommitmentConfig::confirmed()),\n    max_supported_transaction_version: Some(0),  // REQUIRED!\n};\n\nlet tx = rpc_client.get_transaction_with_config(&signature, config)?;\n```\n\n**Without `max_supported_transaction_version: Some(0)`:**\n- RPC calls will **fail** if they encounter a v0 transaction\n- Error: \"Transaction version is not supported\"\n- This affects: `getTransaction`, `getBlock`, `getSignaturesForAddress`, etc.\n\n**For account subscriptions:**\n```rust\nuse solana_client::rpc_config::RpcAccountInfoConfig;\n\nlet config = RpcAccountInfoConfig {\n    encoding: Some(UiAccountEncoding::JsonParsed),\n    commitment: Some(CommitmentConfig::confirmed()),\n    // No max_supported_transaction_version needed for account queries\n};\n```\n\n## Limitations and Constraints\n\n### Hard Limits\n\n1. **256 addresses per table** (u8 index limit)\n   - Tables use 1-byte indices\n   - Cannot store more than 256 addresses\n   - Create multiple tables if needed\n\n2. **256 unique accounts total per transaction**\n   - Solana runtime limit\n   - Includes both direct accounts and ALT references\n   - Accounts can appear multiple times in instructions\n\n3. **~20 addresses per extend operation**\n   - Limited by transaction size\n   - Must batch large address sets\n\n4. **Transaction signers cannot be in ALTs**\n   - All signers must be explicitly listed in the transaction\n   - Cannot reference signer accounts from lookup tables\n   - This is a security feature\n\n5. **No recursive lookups**\n   - Cannot reference another ALT from within an ALT\n   - Cannot store ALT addresses in an ALT\n\n### Security Constraints\n\n1. **Append-only design**\n   - Addresses cannot be removed or modified\n   - Prevents front-running attacks\n   - Once added, addresses are permanent (until table is closed)\n\n2. **Warmup requirement**\n   - New addresses need 1 slot before use\n   - Prevents same-slot manipulation\n   - Must wait for finalization\n\n3. **Deactivation cooldown**\n   - Tables cannot be closed immediately after deactivation\n   - Must wait for slot to exit slot hashes sysvar\n   - Protects in-flight transactions\n\n4. **Authority control**\n   - Only authority can extend or deactivate\n   - Set to `None` to make immutable\n   - Cannot change authority after freezing\n\n### Hardware Wallet Limitations\n\n**Issue**: Hardware wallets cannot verify accounts referenced from ALTs\n\n**Why:**\n- Hardware wallets display all transaction accounts for user verification\n- They don't have access to fetch lookup table data on-chain\n- Cannot show which addresses the indices reference\n\n**Implications:**\n- Users must trust that the correct lookup table is being used\n- Phishing risk: Malicious apps could use attacker-controlled ALTs\n- Hardware wallet UX shows: \"This transaction uses address lookup tables\"\n\n**Mitigations:**\n- Use well-known, immutable (frozen) ALTs when possible\n- Publish ALT addresses in protocol documentation\n- Verify ALT contents before use in client code\n- Consider adding integrity check instructions\n\n## Security Best Practices\n\n### 1. Wait for Finalization\n\n```rust\n// BAD: Using immediately after creation\nlet (create_ix, alt_address) = alt_instruction::create_lookup_table(...);\nrpc_client.send_transaction(&create_tx)?;  // Not confirmed!\nlet extend_ix = alt_instruction::extend_lookup_table(alt_address, ...);  // FAILS!\n\n// GOOD: Wait for finalization\nrpc_client.send_and_confirm_transaction_with_spinner(&create_tx)?;\n// Now safe to extend\n\nrpc_client.send_and_confirm_transaction_with_spinner(&extend_tx)?;\n// Now safe to use in v0 transactions\n```\n\n### 2. Verify Lookup Table Contents\n\n```rust\n// Fetch and verify before use\nlet lookup_table = rpc_client.get_account(&alt_address)?;\nlet alt = AddressLookupTableAccount::deserialize(&lookup_table.data)?;\n\n// Verify expected addresses\nassert_eq!(alt.addresses.len(), expected_count);\nassert_eq!(alt.addresses[0], expected_address_0);\n\n// Check authority if relevant\nif let Some(authority) = alt.meta.authority {\n    assert_eq!(authority, expected_authority);\n}\n```\n\n### 3. Add Integrity Check Instructions\n\nFor critical operations, add an instruction that verifies the lookup table contents:\n\n```rust\n// Your program instruction\npub fn verify_lookup_table(\n    ctx: Context<VerifyLookupTable>,\n    expected_addresses: Vec<Pubkey>,\n) -> Result<()> {\n    let lookup_table = &ctx.accounts.lookup_table;\n\n    // Verify table contains expected addresses\n    for (i, expected) in expected_addresses.iter().enumerate() {\n        require_keys_eq!(\n            lookup_table.addresses[i],\n            *expected,\n            ErrorCode::InvalidLookupTable\n        );\n    }\n\n    Ok(())\n}\n```\n\n### 4. Use Immutable Tables for Protocols\n\n```rust\n// After fully populating a protocol-level table\nlet freeze_ix = alt_instruction::freeze_lookup_table(\n    protocol_alt_address,\n    authority.pubkey(),\n);\n\nrpc_client.send_and_confirm_transaction(&freeze_tx)?;\n\n// Now the table is permanently immutable\n// Users can trust it won't change\n```\n\n### 5. Front-Running Prevention\n\n**Why ALTs are append-only:**\n\n```rust\n// If removal were allowed, this attack would be possible:\n// 1. User submits swap transaction using ALT at index 5\n// 2. Attacker sees pending transaction\n// 3. Attacker removes legitimate address, adds malicious address at index 5\n// 4. User's transaction executes with malicious address\n\n// Append-only design prevents this:\n// - Addresses cannot be removed\n// - Indices remain stable\n// - Order cannot change\n```\n\n## Code Examples\n\n### Complete Example: Multi-Swap with ALT\n\nBased on the TeamRaccoons address-lookup-table-multi-swap example:\n\n```rust\nuse solana_client::rpc_client::RpcClient;\nuse solana_sdk::{\n    address_lookup_table_account::instruction as alt_instruction,\n    address_lookup_table_account::AddressLookupTableAccount,\n    commitment_config::CommitmentConfig,\n    instruction::Instruction,\n    message::{v0, VersionedMessage},\n    pubkey::Pubkey,\n    signature::{Keypair, Signer},\n    transaction::{Transaction, VersionedTransaction},\n};\n\nfn create_and_use_alt_for_swaps() -> Result<()> {\n    let rpc_client = RpcClient::new_with_commitment(\n        \"https://api.devnet.solana.com\".to_string(),\n        CommitmentConfig::confirmed(),\n    );\n\n    let payer = Keypair::new();\n    // Fund payer...\n\n    // Step 1: Collect all accounts needed for swap chain\n    let swap_accounts = vec![\n        token_program_id,\n        associated_token_program_id,\n        swap_program_1,\n        pool_1_address,\n        pool_1_authority,\n        pool_1_token_a,\n        pool_1_token_b,\n        swap_program_2,\n        pool_2_address,\n        pool_2_authority,\n        pool_2_token_a,\n        pool_2_token_b,\n        // ... many more accounts\n    ];\n\n    // Step 2: Create lookup table\n    let recent_slot = rpc_client.get_slot()?;\n    let (create_ix, alt_address) = alt_instruction::create_lookup_table(\n        payer.pubkey(),\n        payer.pubkey(),\n        recent_slot,\n    );\n\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let create_tx = Transaction::new_signed_with_payer(\n        &[create_ix],\n        Some(&payer.pubkey()),\n        &[&payer],\n        recent_blockhash,\n    );\n\n    rpc_client.send_and_confirm_transaction_with_spinner(&create_tx)?;\n    println!(\"Created ALT at {}\", alt_address);\n\n    // Step 3: Extend in batches of 20\n    for (batch_num, chunk) in swap_accounts.chunks(20).enumerate() {\n        let extend_ix = alt_instruction::extend_lookup_table(\n            alt_address,\n            payer.pubkey(),\n            Some(payer.pubkey()),\n            chunk.to_vec(),\n        );\n\n        let recent_blockhash = rpc_client.get_latest_blockhash()?;\n        let extend_tx = Transaction::new_signed_with_payer(\n            &[extend_ix],\n            Some(&payer.pubkey()),\n            &[&payer],\n            recent_blockhash,\n        );\n\n        rpc_client.send_and_confirm_transaction_with_spinner(&extend_tx)?;\n        println!(\"Extended ALT batch {}\", batch_num);\n    }\n\n    // Step 4: Fetch the populated lookup table\n    let alt_account = rpc_client.get_account(&alt_address)?;\n    let lookup_table = AddressLookupTableAccount::deserialize(&alt_account.data)?;\n\n    println!(\"ALT contains {} addresses\", lookup_table.addresses.len());\n\n    // Step 5: Build multi-swap transaction using ALT\n    let swap_instructions = vec![\n        create_swap_instruction(0, 1, 2, 3, 4, 5, 6),   // Indices into ALT\n        create_swap_instruction(7, 8, 9, 10, 11, 12, 13),\n        create_swap_instruction(14, 15, 16, 17, 18, 19, 20),\n        // Many more swaps...\n    ];\n\n    let recent_blockhash = rpc_client.get_latest_blockhash()?;\n    let v0_message = v0::Message::try_compile(\n        &payer.pubkey(),\n        &swap_instructions,\n        &[lookup_table],\n        recent_blockhash,\n    )?;\n\n    let versioned_tx = VersionedTransaction::try_new(\n        VersionedMessage::V0(v0_message),\n        &[&payer],\n    )?;\n\n    // Step 6: Send v0 transaction\n    let signature = rpc_client.send_and_confirm_transaction(&versioned_tx)?;\n    println!(\"Multi-swap completed: {}\", signature);\n\n    Ok(())\n}\n\nfn create_swap_instruction(\n    swap_program: u8,\n    pool: u8,\n    authority: u8,\n    source: u8,\n    dest: u8,\n    pool_token_a: u8,\n    pool_token_b: u8,\n) -> Instruction {\n    // Create instruction with account indices\n    // These will be resolved from the ALT\n    Instruction {\n        program_id: /* from ALT index swap_program */,\n        accounts: vec![\n            AccountMeta::new(/* ALT index pool */, false),\n            AccountMeta::new_readonly(/* ALT index authority */, false),\n            // ... etc\n        ],\n        data: /* swap instruction data */,\n    }\n}\n```\n\n### Example: Protocol-Level Immutable ALT\n\n```rust\n// Create a permanent lookup table for protocol accounts\nfn create_protocol_alt(\n    authority: &Keypair,\n    protocol_accounts: Vec<Pubkey>,\n) -> Result<Pubkey> {\n    let rpc_client = RpcClient::new(\"https://api.mainnet-beta.solana.com\");\n\n    // Create table\n    let recent_slot = rpc_client.get_slot()?;\n    let (create_ix, alt_address) = alt_instruction::create_lookup_table(\n        authority.pubkey(),\n        authority.pubkey(),\n        recent_slot,\n    );\n\n    let create_tx = /* ... */;\n    rpc_client.send_and_confirm_transaction_with_spinner(&create_tx)?;\n\n    // Extend with all protocol accounts\n    for chunk in protocol_accounts.chunks(20) {\n        let extend_ix = alt_instruction::extend_lookup_table(\n            alt_address,\n            authority.pubkey(),\n            Some(authority.pubkey()),\n            chunk.to_vec(),\n        );\n\n        let extend_tx = /* ... */;\n        rpc_client.send_and_confirm_transaction_with_spinner(&extend_tx)?;\n    }\n\n    // Freeze the table (make immutable)\n    let freeze_ix = alt_instruction::freeze_lookup_table(\n        alt_address,\n        authority.pubkey(),\n    );\n\n    let freeze_tx = /* ... */;\n    rpc_client.send_and_confirm_transaction_with_spinner(&freeze_tx)?;\n\n    println!(\"Created immutable protocol ALT at {}\", alt_address);\n\n    // Publish this address in documentation\n    // Users can trust it won't change\n\n    Ok(alt_address)\n}\n```\n\n## Troubleshooting\n\n### Common Errors and Solutions\n\n**Error: \"Transaction version is not supported\"**\n```rust\n// Problem: RPC not configured for v0 transactions\nlet tx = rpc_client.get_transaction(&signature)?;  // FAILS\n\n// Solution: Set max_supported_transaction_version\nlet config = RpcTransactionConfig {\n    max_supported_transaction_version: Some(0),\n    ..Default::default()\n};\nlet tx = rpc_client.get_transaction_with_config(&signature, config)?;  // Works\n```\n\n**Error: \"Address lookup table not found\"**\n```rust\n// Problem: Using table before creation is finalized\nlet (create_ix, alt_address) = alt_instruction::create_lookup_table(...);\nrpc_client.send_transaction(&tx)?;  // Sent but not confirmed\nlet extend_ix = alt_instruction::extend_lookup_table(alt_address, ...);  // FAILS\n\n// Solution: Wait for confirmation\nrpc_client.send_and_confirm_transaction_with_spinner(&create_tx)?;\n// Now table exists\n```\n\n**Error: \"Invalid lookup table index\"**\n```rust\n// Problem: Referencing index beyond table size\nlet lookup_table = /* has 10 addresses */;\nlet ix = Instruction {\n    accounts: vec![\n        AccountMeta::new(/* index 15 */, false),  // FAILS - index out of bounds\n    ],\n    // ...\n};\n\n// Solution: Verify table contents and use valid indices\nassert!(index < lookup_table.addresses.len());\n```\n\n**Error: \"Cannot deactivate lookup table\"**\n```rust\n// Problem: Not the authority\nlet deactivate_ix = alt_instruction::deactivate_lookup_table(\n    alt_address,\n    wrong_authority.pubkey(),  // Not the actual authority\n);\n\n// Solution: Use the correct authority\nlet alt = AddressLookupTableAccount::deserialize(&account.data)?;\nlet correct_authority = alt.meta.authority.expect(\"Table has no authority\");\nlet deactivate_ix = alt_instruction::deactivate_lookup_table(\n    alt_address,\n    correct_authority,\n);\n```\n\n**Error: \"Cannot close lookup table\"**\n```rust\n// Problem 1: Table not deactivated\nlet close_ix = alt_instruction::close_lookup_table(...);  // FAILS\n\n// Solution: Deactivate first, then wait\nlet deactivate_ix = alt_instruction::deactivate_lookup_table(...);\n// ... send deactivate transaction ...\n// ... wait for cooldown period (~2.5 days mainnet) ...\nlet close_ix = alt_instruction::close_lookup_table(...);\n\n// Problem 2: Cooldown period not complete\n// Solution: Check if deactivation slot has exited slot hashes\nlet slot_hashes = rpc_client.get_slot_hashes()?;\nlet oldest_slot = slot_hashes.last().unwrap().0;\nif alt.meta.deactivation_slot < oldest_slot {\n    // Safe to close\n}\n```\n\n## Use Cases and Patterns\n\n### 1. DEX Aggregators\n\n**Problem**: Multi-hop swaps require many accounts (pools, authorities, token accounts)\n\n**Solution**: Create ALT with all pool accounts\n\n```rust\n// ALT contains:\n// [0-19]: Pool 1 accounts (program, pool, authority, tokens, mint, etc.)\n// [20-39]: Pool 2 accounts\n// [40-59]: Pool 3 accounts\n// [60-79]: Common accounts (token program, associated token program, etc.)\n\n// Transaction can now execute 3+ swaps atomically\n```\n\n### 2. Complex Protocol Interactions\n\n**Problem**: DeFi protocols compose multiple programs (lending, swapping, staking)\n\n**Solution**: Protocol-specific ALT with all contract addresses\n\n```rust\n// Protocol ALT:\n// [0]: Program ID\n// [1]: Global config account\n// [2-10]: Pool addresses\n// [11-20]: Oracle addresses\n// [21-30]: Treasury accounts\n// etc.\n```\n\n### 3. NFT Minting/Trading\n\n**Problem**: Minting or trading multiple NFTs requires many metadata accounts\n\n**Solution**: Collection-specific ALT with all related accounts\n\n```rust\n// Collection ALT:\n// [0]: Candy machine\n// [1]: Collection mint\n// [2]: Collection metadata\n// [3]: Collection master edition\n// [4-100]: Individual NFT addresses\n```\n\n### 4. Transaction Builder Programs\n\n**Problem**: Building very large transactions (>64 accounts)\n\n**Solution**: Multi-transaction pattern with ALTs\n\n```rust\n// Transaction 1: Create and populate ALT\n// Transaction 2: Execute main operation using ALT\n// Transaction 3: Clean up and close ALT\n```\n\n## Best Practices Summary\n\n1. **Always wait for finalization** before using newly created or extended tables\n2. **Batch extend operations** in chunks of ~20 addresses\n3. **Verify table contents** before use in production\n4. **Use immutable tables** for protocol-level accounts\n5. **Set max_supported_transaction_version** in all RPC calls\n6. **Document ALT addresses** for protocol integrators\n7. **Consider hardware wallet UX** - frozen tables are more trustworthy\n8. **Add integrity checks** for critical operations\n9. **Plan for cooldown** when closing tables\n10. **Keep signers explicit** - never try to put signers in ALTs\n\n## Program Compatibility\n\n**Important**: Programs are **completely unaware** of whether they were called via legacy or v0 transactions.\n\nFrom the program's perspective:\n- Account references work identically\n- No code changes needed\n- Same `AccountInfo` structures\n- Same validation logic\n\nThe transaction version only affects:\n- How accounts are referenced in the transaction\n- Transaction size limits\n- Client-side transaction construction\n\n**This means:**\n- Existing programs work with v0 transactions without modification\n- New programs don't need version-specific logic\n- ALTs are purely a client-side optimization\n\n## Resources\n\n### Official Documentation\n- [Versioned Transactions Guide](https://solana.com/developers/guides/advanced/versions)\n- [Address Lookup Tables Guide](https://solana.com/developers/guides/advanced/lookup-tables)\n- [Versioned Transactions Proposal](https://docs.anza.xyz/proposals/versioned-transactions)\n\n### Code Examples\n- [TeamRaccoons Multi-Swap Example](https://github.com/TeamRaccoons/address-lookup-table-multi-swap)\n- [Solana Program Library - Address Lookup Table](https://github.com/solana-labs/solana-program-library/tree/master/address-lookup-table)\n\n### Technical References\n- [AddressLookupTableProgram Source](https://github.com/solana-labs/solana/blob/master/sdk/program/src/address_lookup_table/instruction.rs)\n- [solana-sdk VersionedTransaction](https://docs.rs/solana-sdk/latest/solana_sdk/transaction/struct.VersionedTransaction.html)\n- [solana-sdk Message v0](https://docs.rs/solana-sdk/latest/solana_sdk/message/v0/struct.Message.html)\n\n### Community Resources\n- [Solana Cookbook - Versioned Transactions](https://solanacookbook.com/references/basic-transactions.html#versioned-transactions)\n- [Solana Stack Exchange - ALT Questions](https://solana.stackexchange.com/questions/tagged/address-lookup-table)\n",
        "solana/skills/solana-security/SKILL.md": "---\nname: solana-security\ndescription: Audit Solana programs (Anchor or native Rust) for security vulnerabilities. Use when reviewing smart contract security, finding exploits, analyzing attack vectors, performing security assessments, or when explicitly asked to audit, review security, check for bugs, or find vulnerabilities in Solana programs.\n---\n\n# Solana Security Auditing\n\nSystematic security review framework for Solana programs, supporting both Anchor and native Rust implementations.\n\n## Review Process\n\nFollow this systematic 5-step process for comprehensive security audits:\n\n### Step 1: Initial Assessment\n\nUnderstand the program's context and structure:\n\n- **Framework**: Anchor vs Native Rust (check for `use anchor_lang::prelude::*`)\n- **Anchor version**: Check `Cargo.toml` for compatibility and known issues\n- **Dependencies**: Oracles (Pyth, Switchboard), external programs, token programs\n- **Program structure**: Count instructions, identify account types, analyze state management\n- **Complexity**: Lines of code, instruction count, PDA patterns\n- **Purpose**: DeFi, NFT, governance, gaming, etc.\n\n### Step 2: Systematic Security Review\n\nFor each instruction, perform security checks in this order:\n\n1. **Account Validation** - Verify signer, owner, writable, and initialization checks\n2. **Arithmetic Safety** - Check all math operations use `checked_*` methods\n3. **PDA Security** - Validate canonical bumps and seed uniqueness\n4. **CPI Security** - Ensure cross-program invocations validate target programs\n5. **Oracle/External Data** - Verify price staleness and oracle status checks\n\n**→ See [references/security-checklists.md](references/security-checklists.md) for detailed checklists**\n\n### Step 3: Vulnerability Pattern Detection\n\nScan for common vulnerability patterns:\n\n- Type cosplay attacks\n- Account reloading issues\n- Improper account closing\n- Missing lamports checks\n- PDA substitution attacks\n- Arbitrary CPI vulnerabilities\n- Missing ownership validation\n- Integer overflow/underflow\n\n**→ See [references/vulnerability-patterns.md](references/vulnerability-patterns.md) for code examples and exploit scenarios**\n\n### Step 4: Architecture and Testing Review\n\nEvaluate overall design quality:\n\n- PDA design patterns and collision prevention\n- Account space allocation and rent exemption\n- Error handling approach and coverage\n- Event emission for critical state changes\n- Compute budget optimization\n- Test coverage (unit, integration, fuzz)\n- Upgrade strategy and authority management\n\n### Step 5: Generate Security Report\n\nProvide findings using this structure:\n\n**Severity Levels:**\n- 🔴 **Critical**: Funds can be stolen/lost, protocol completely broken\n- 🟠 **High**: Protocol can be disrupted, partial fund loss possible\n- 🟡 **Medium**: Suboptimal behavior, edge cases, griefing attacks\n- 🔵 **Low**: Code quality, gas optimization, best practices\n- 💡 **Informational**: Recommendations, improvements, documentation\n\n**Finding Format:**\n```markdown\n## 🔴 [CRITICAL] Title\n\n**Location:** `programs/vault/src/lib.rs:45-52`\n\n**Issue:**\nBrief description of the vulnerability\n\n**Vulnerable Code:**\n```rust\n// Show the problematic code\n```\n\n**Exploit Scenario:**\nStep-by-step explanation of how this can be exploited\n\n**Recommendation:**\n```rust\n// Show the secure alternative\n```\n\n**References:**\n- [Link to relevant documentation or similar exploits]\n```\n\n**Report Summary:**\n- Total findings by severity\n- Critical issues first (prioritize by risk)\n- Quick wins (easy fixes with high impact)\n- Recommendations for testing improvements\n\n## Quick Reference\n\n### Essential Checks (Every Instruction)\n\n**Anchor:**\n```rust\n// ✅ Account validation with constraints\n#[derive(Accounts)]\npub struct SecureInstruction<'info> {\n    #[account(\n        mut,\n        has_one = authority,  // Relationship check\n        seeds = [b\"vault\", user.key().as_ref()],\n        bump,  // Canonical bump\n    )]\n    pub vault: Account<'info, Vault>,\n\n    pub authority: Signer<'info>,  // Signer required\n\n    pub token_program: Program<'info, Token>,  // Program validation\n}\n\n// ✅ Checked arithmetic\nlet total = balance.checked_add(amount)\n    .ok_or(ErrorCode::Overflow)?;\n```\n\n**Native Rust:**\n```rust\n// ✅ Manual account validation\nif !authority.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\nif vault.owner != program_id {\n    return Err(ProgramError::IllegalOwner);\n}\n\n// ✅ Checked arithmetic\nlet total = balance.checked_add(amount)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n### Critical Anti-Patterns\n\n❌ **Never Do:**\n- Use `saturating_*` arithmetic methods (hide errors)\n- Use `unwrap()` or `expect()` in production code\n- Use `init_if_needed` without additional checks\n- Skip signer validation (\"they wouldn't call this...\")\n- Use unchecked arithmetic operations\n- Allow arbitrary CPI targets\n- Forget to reload accounts after mutations\n\n✅ **Always Do:**\n- Use `checked_*` arithmetic (`checked_add`, `checked_sub`, etc.)\n- Use `ok_or(error)?` for Option unwrapping\n- Use explicit `init` with proper validation\n- Require `Signer<'info>` or `is_signer` checks\n- Use `Program<'info, T>` for CPI program validation\n- Reload accounts after external calls that mutate state\n- Validate account ownership, discriminators, and relationships\n\n## Framework-Specific Patterns\n\n### Anchor Security Patterns\n\n**→ See [references/anchor-security.md](references/anchor-security.md) for:**\n- Account constraint best practices\n- Common Anchor-specific vulnerabilities\n- Secure CPI patterns with `CpiContext`\n- Event emission and monitoring\n- Custom error handling\n\n### Native Rust Security Patterns\n\n**→ See [references/native-security.md](references/native-security.md) for:**\n- Manual account validation patterns\n- Secure PDA derivation and signing\n- Low-level CPI security\n- Account discriminator patterns\n- Rent exemption validation\n\n## Modern Practices (2025)\n\n- **Use Anchor 0.30+** for latest security features\n- **Implement Token-2022** with proper extension handling\n- **Use `InitSpace` derive** for automatic space calculation\n- **Emit events** for all critical state changes\n- **Write fuzz tests** with Trident framework\n- **Document invariants** in code comments\n- **Follow progressive roadmap**: Dev → Audit → Testnet → Audit → Mainnet\n\n## Security Fundamentals\n\n**→ See [references/security-fundamentals.md](references/security-fundamentals.md) for:**\n- Security mindset and threat modeling\n- Core validation patterns (signers, owners, mutability)\n- Input validation best practices\n- State management security\n- Arithmetic safety\n- Re-entrancy considerations\n\n## Common Vulnerabilities\n\n**→ See [references/vulnerability-patterns.md](references/vulnerability-patterns.md) for:**\n- Missing signer validation\n- Integer overflow/underflow\n- PDA substitution attacks\n- Account confusion\n- Arbitrary CPI\n- Type cosplay\n- Improper account closing\n- Precision loss in calculations\n\nEach vulnerability includes:\n- ❌ Vulnerable code example\n- 💥 Exploit scenario\n- ✅ Secure alternative\n- 📚 References\n\n## Security Checklists\n\n**→ See [references/security-checklists.md](references/security-checklists.md) for:**\n- Account validation checklist\n- Arithmetic safety checklist\n- PDA and account security checklist\n- CPI security checklist\n- Oracle and external data checklist\n- Token integration checklist\n\n## Known Issues and Caveats\n\n**→ See [references/caveats.md](references/caveats.md) for:**\n- Solana-specific quirks and gotchas\n- Anchor framework limitations\n- Testing blind spots\n- Common misconceptions\n- Version-specific issues\n\n## Security Resources\n\n**→ See [references/resources.md](references/resources.md) for:**\n- Official security documentation\n- Security courses and tutorials\n- Vulnerability databases\n- Audit report examples\n- Security tools (Trident, fuzzers)\n- Security firms and auditors\n\n## Key Questions for Every Audit\n\nAlways verify these critical security properties:\n\n1. **Can an attacker substitute accounts?**\n   - PDA validation, program ID checks, has_one constraints\n\n2. **Can arithmetic overflow or underflow?**\n   - All math uses checked operations, division by zero protected\n\n3. **Are all accounts properly validated?**\n   - Owner, signer, writable, initialized checks present\n\n4. **Can the program be drained?**\n   - Authorization checks, reentrancy protection, account confusion prevention\n\n5. **What happens in edge cases?**\n   - Zero amounts, max values, closed accounts, expired data\n\n6. **Are external dependencies safe?**\n   - Oracle validation (staleness, status), CPI targets verified, token program checks\n\n## Audit Workflow\n\n### Before Starting\n\n1. Understand the protocol purpose and mechanics\n2. Review documentation and specifications\n3. Set up local development environment\n4. Run existing tests and check coverage\n\n### During Audit\n\n1. Follow the 5-step review process systematically\n2. Document findings with severity and remediation\n3. Create proof-of-concept exploits for critical issues\n4. Test fixes and verify they work\n\n### After Audit\n\n1. Present findings clearly prioritized by severity\n2. Provide actionable remediation steps\n3. Re-audit after fixes are implemented\n4. Document lessons learned for the protocol\n\n## Testing for Security\n\nBeyond code review, validate security through testing:\n\n- **Unit tests**: Test each instruction's edge cases\n- **Integration tests**: Test cross-instruction interactions\n- **Fuzz testing**: Use Trident to discover unexpected behaviors\n- **Exploit scenarios**: Write POCs for found vulnerabilities\n- **Upgrade testing**: Verify migration paths are secure\n\n## Core Principle\n\n**In Solana's account model, attackers can pass arbitrary accounts to any instruction.**\n\nSecurity requires explicitly validating:\n- ✅ Every account's ownership\n- ✅ Every account's type (discriminator)\n- ✅ Every account's relationships\n- ✅ Every account's state\n- ✅ Every signer requirement\n- ✅ Every arithmetic operation\n- ✅ Every external call\n\nThere are no implicit guarantees. **Validate everything, trust nothing.**\n",
        "solana/skills/solana-security/references/anchor-security.md": "# Anchor Security Reference\n\nThis document covers security patterns, vulnerabilities, and best practices specific to the Anchor framework for Solana program development.\n\n## 1. Anchor Constraint Security\n\n### 1.1 Account Constraint Basics\n\nAnchor's `#[account(...)]` constraints provide declarative validation of accounts passed to instructions. Proper use is critical for security.\n\n**Core constraint types:**\n- `init` - Initialize a new account\n- `mut` - Mark account as mutable\n- `has_one` - Verify relationship between accounts\n- `seeds` and `bump` - Validate PDA derivation\n- `constraint` - Custom validation expressions\n- `close` - Close account and return rent\n- `realloc` - Resize account data\n\n### 1.2 init vs init_if_needed\n\n**VULNERABLE - Using init_if_needed:**\n```rust\n#[derive(Accounts)]\npub struct UpdateConfig<'info> {\n    #[account(\n        init_if_needed,\n        payer = authority,\n        space = 8 + Config::INIT_SPACE,\n        seeds = [b\"config\"],\n        bump\n    )]\n    pub config: Account<'info, Config>,\n    #[account(mut)]\n    pub authority: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n**Issue:** `init_if_needed` allows re-initialization attacks. An attacker can close the account in a previous transaction, then re-initialize it with malicious data.\n\n**SECURE - Separate init and update instructions:**\n```rust\n#[derive(Accounts)]\npub struct InitConfig<'info> {\n    #[account(\n        init,\n        payer = authority,\n        space = 8 + Config::INIT_SPACE,\n        seeds = [b\"config\"],\n        bump\n    )]\n    pub config: Account<'info, Config>,\n    #[account(mut)]\n    pub authority: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n\n#[derive(Accounts)]\npub struct UpdateConfig<'info> {\n    #[account(\n        mut,\n        seeds = [b\"config\"],\n        bump = config.bump\n    )]\n    pub config: Account<'info, Config>,\n    pub authority: Signer<'info>,\n}\n```\n\n**When init_if_needed is acceptable:**\n- Idempotent operations where re-initialization is safe\n- Accounts with no state that matters (pure PDAs used only for signing)\n- Always combine with additional constraints to prevent misuse\n\n### 1.3 has_one Constraints for Relationships\n\n**VULNERABLE - Missing has_one check:**\n```rust\n#[derive(Accounts)]\npub struct WithdrawFunds<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>,\n    #[account(mut)]\n    pub owner: Signer<'info>,\n    #[account(mut)]\n    pub destination: SystemAccount<'info>,\n}\n\npub fn withdraw_funds(ctx: Context<WithdrawFunds>, amount: u64) -> Result<()> {\n    // Missing validation: anyone can withdraw from any vault!\n    transfer_lamports(&ctx.accounts.vault, &ctx.accounts.destination, amount)?;\n    Ok(())\n}\n```\n\n**SECURE - Using has_one:**\n```rust\n#[account]\npub struct Vault {\n    pub owner: Pubkey,\n    pub bump: u8,\n}\n\n#[derive(Accounts)]\npub struct WithdrawFunds<'info> {\n    #[account(\n        mut,\n        has_one = owner, // Validates vault.owner == owner.key()\n        seeds = [b\"vault\", owner.key().as_ref()],\n        bump = vault.bump\n    )]\n    pub vault: Account<'info, Vault>,\n    #[account(mut)]\n    pub owner: Signer<'info>,\n    #[account(mut)]\n    pub destination: SystemAccount<'info>,\n}\n```\n\n### 1.4 seeds and bump for PDA Validation\n\n**VULNERABLE - Not validating PDA derivation:**\n```rust\n#[derive(Accounts)]\npub struct Deposit<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>,\n    pub depositor: Signer<'info>,\n}\n```\n\n**Issue:** Attacker can pass any account as vault, including one they control.\n\n**SECURE - Validate PDA with seeds and bump:**\n```rust\n#[derive(Accounts)]\npub struct Deposit<'info> {\n    #[account(\n        mut,\n        seeds = [b\"vault\", depositor.key().as_ref()],\n        bump = vault.bump\n    )]\n    pub vault: Account<'info, Vault>,\n    pub depositor: Signer<'info>,\n}\n```\n\n**CRITICAL: Always use canonical bump:**\n```rust\n#[account]\npub struct Vault {\n    pub bump: u8, // Store canonical bump at initialization\n}\n\n// At initialization, use:\n#[account(\n    init,\n    payer = payer,\n    space = 8 + Vault::INIT_SPACE,\n    seeds = [b\"vault\", authority.key().as_ref()],\n    bump // Anchor automatically finds canonical bump\n)]\npub vault: Account<'info, Vault>,\n\n// Then store it:\nvault.bump = ctx.bumps.vault; // ctx.bumps available in Anchor 0.29+\n```\n\n### 1.5 constraint Expressions and Pitfalls\n\n**VULNERABLE - Using constraint without proper checks:**\n```rust\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(\n        mut,\n        constraint = from.amount >= amount @ ErrorCode::InsufficientFunds\n    )]\n    pub from: Account<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n    pub authority: Signer<'info>,\n}\n```\n\n**Issue:** Missing check that authority actually owns the from account!\n\n**SECURE - Combine constraints appropriately:**\n```rust\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(\n        mut,\n        has_one = authority, // Verify ownership\n        constraint = from.amount >= amount @ ErrorCode::InsufficientFunds\n    )]\n    pub from: Account<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n    pub authority: Signer<'info>,\n}\n```\n\n**Constraint expression tips:**\n- Use `@` to specify custom error codes\n- Constraints execute after account deserialization\n- Complex logic should go in instruction handler, not constraints\n- Prefer built-in constraints (`has_one`, `seeds`) over custom `constraint`\n\n### 1.6 close Constraint Security\n\n**VULNERABLE - close without proper authorization:**\n```rust\n#[derive(Accounts)]\npub struct CloseAccount<'info> {\n    #[account(\n        mut,\n        close = destination\n    )]\n    pub account_to_close: Account<'info, MyAccount>,\n    #[account(mut)]\n    pub destination: SystemAccount<'info>,\n}\n```\n\n**Issue:** Anyone can close the account and steal the rent!\n\n**SECURE - Verify authorization before closing:**\n```rust\n#[derive(Accounts)]\npub struct CloseAccount<'info> {\n    #[account(\n        mut,\n        has_one = authority,\n        close = authority // Return rent to authorized party\n    )]\n    pub account_to_close: Account<'info, MyAccount>,\n    #[account(mut)]\n    pub authority: Signer<'info>,\n}\n```\n\n**CRITICAL: close order matters:**\n```rust\n// WRONG - closes account before using it\n#[account(\n    close = authority,\n    has_one = authority\n)]\npub my_account: Account<'info, MyAccount>,\n\n// CORRECT - validates before closing\n#[account(\n    has_one = authority,\n    close = authority\n)]\npub my_account: Account<'info, MyAccount>,\n```\n\n### 1.7 realloc Security Considerations\n\n**VULNERABLE - realloc without validation:**\n```rust\n#[derive(Accounts)]\npub struct UpdateData<'info> {\n    #[account(\n        mut,\n        realloc = 8 + 4 + new_data.len(),\n        realloc::payer = payer,\n        realloc::zero = false\n    )]\n    pub data_account: Account<'info, DataAccount>,\n    #[account(mut)]\n    pub payer: Signer<'info>,\n}\n```\n\n**Issues:**\n- No max size check (DoS via huge allocations)\n- No authority check (anyone can realloc)\n- `zero = false` might leak old data\n\n**SECURE - Proper realloc constraints:**\n```rust\n#[derive(Accounts)]\npub struct UpdateData<'info> {\n    #[account(\n        mut,\n        has_one = authority,\n        realloc = 8 + 4 + new_data.len(),\n        realloc::payer = authority,\n        realloc::zero = true, // Zero out old data\n        constraint = new_data.len() <= MAX_DATA_SIZE @ ErrorCode::DataTooLarge\n    )]\n    pub data_account: Account<'info, DataAccount>,\n    #[account(mut)]\n    pub authority: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n## 2. Common Anchor Vulnerabilities\n\n### 2.1 Missing Constraints Leading to Account Substitution\n\n**VULNERABLE - No PDA validation:**\n```rust\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(mut)]\n    pub pool: Account<'info, Pool>,\n    #[account(mut)]\n    pub user_stake: Account<'info, UserStake>,\n    pub user: Signer<'info>,\n}\n```\n\n**Attack:** User passes a fake `user_stake` account they control with inflated balance.\n\n**SECURE - Validate PDAs:**\n```rust\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(\n        mut,\n        seeds = [b\"pool\"],\n        bump = pool.bump\n    )]\n    pub pool: Account<'info, Pool>,\n    #[account(\n        mut,\n        seeds = [b\"stake\", pool.key().as_ref(), user.key().as_ref()],\n        bump = user_stake.bump,\n        has_one = user,\n        has_one = pool\n    )]\n    pub user_stake: Account<'info, UserStake>,\n    pub user: Signer<'info>,\n}\n```\n\n### 2.2 Incorrect Constraint Ordering\n\nAnchor evaluates constraints in this order:\n1. `init` / `init_if_needed` / `mut` / `close`\n2. `seeds` and `bump`\n3. `has_one`\n4. `constraint`\n5. Account deserialization\n\n**Implications:**\n- Can't use deserialized data in `seeds`\n- `constraint` expressions can use deserialized data\n- `close` at end ensures account data available for other checks\n\n### 2.3 Over-Reliance on init_if_needed\n\nCovered in section 1.2. Key takeaway: **Avoid `init_if_needed` unless absolutely necessary.**\n\n### 2.4 Missing mut on Accounts\n\n**VULNERABLE - Missing mut:**\n```rust\n#[derive(Accounts)]\npub struct Deposit<'info> {\n    pub vault: Account<'info, Vault>, // Missing mut!\n    pub user: Signer<'info>,\n}\n\npub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {\n    ctx.accounts.vault.balance += amount; // Runtime error!\n    Ok(())\n}\n```\n\n**SECURE:**\n```rust\n#[derive(Accounts)]\npub struct Deposit<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>,\n    pub user: Signer<'info>,\n}\n```\n\n### 2.5 PDA Bump Not Using Canonical Bump\n\n**VULNERABLE - Using non-canonical bump:**\n```rust\npub fn initialize(ctx: Context<Initialize>) -> Result<()> {\n    let (pda, bump) = Pubkey::find_program_address(\n        &[b\"vault\"],\n        ctx.program_id\n    );\n    // Storing bump separately is fine, but must validate it\n    ctx.accounts.vault.bump = bump;\n    Ok(())\n}\n\n// Later, using wrong bump\n#[account(\n    seeds = [b\"vault\"],\n    bump = 254 // WRONG - not canonical!\n)]\npub vault: Account<'info, Vault>,\n```\n\n**SECURE - Always use canonical bump:**\n```rust\n#[derive(Accounts)]\npub struct Initialize<'info> {\n    #[account(\n        init,\n        payer = payer,\n        space = 8 + Vault::INIT_SPACE,\n        seeds = [b\"vault\"],\n        bump // Anchor finds canonical bump\n    )]\n    pub vault: Account<'info, Vault>,\n    #[account(mut)]\n    pub payer: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n\npub fn initialize(ctx: Context<Initialize>) -> Result<()> {\n    ctx.accounts.vault.bump = ctx.bumps.vault; // Store canonical bump\n    Ok(())\n}\n```\n\n### 2.6 Account Reloading After CPI Mutations\n\n**VULNERABLE - Stale account data after CPI:**\n```rust\npub fn compound_rewards(ctx: Context<CompoundRewards>) -> Result<()> {\n    // CPI to claim rewards (mutates user_rewards account)\n    rewards_program::cpi::claim_rewards(\n        CpiContext::new(\n            ctx.accounts.rewards_program.to_account_info(),\n            ClaimRewards {\n                user_rewards: ctx.accounts.user_rewards.to_account_info(),\n            }\n        )\n    )?;\n\n    // WRONG - using stale data!\n    let rewards = ctx.accounts.user_rewards.amount;\n\n    // Reinvest...\n    Ok(())\n}\n```\n\n**SECURE - Reload account after CPI:**\n```rust\npub fn compound_rewards(ctx: Context<CompoundRewards>) -> Result<()> {\n    rewards_program::cpi::claim_rewards(\n        CpiContext::new(\n            ctx.accounts.rewards_program.to_account_info(),\n            ClaimRewards {\n                user_rewards: ctx.accounts.user_rewards.to_account_info(),\n            }\n        )\n    )?;\n\n    // Reload account to get fresh data\n    ctx.accounts.user_rewards.reload()?;\n    let rewards = ctx.accounts.user_rewards.amount;\n\n    // Reinvest...\n    Ok(())\n}\n```\n\n## 3. Anchor CPI Security\n\n### 3.1 Using Program<'info, T> for Program Validation\n\n**VULNERABLE - Using AccountInfo for program:**\n```rust\n#[derive(Accounts)]\npub struct CallExternal<'info> {\n    /// CHECK: This is dangerous!\n    pub external_program: AccountInfo<'info>,\n}\n```\n\n**SECURE - Using Program<'info, T>:**\n```rust\n#[derive(Accounts)]\npub struct CallExternal<'info> {\n    pub external_program: Program<'info, ExternalProgram>,\n}\n```\n\n`Program<'info, T>` validates:\n- Account is executable\n- Account owner is BPF Loader\n- Account key matches expected program ID\n\n### 3.2 CpiContext Usage Patterns\n\n**Basic CPI:**\n```rust\nuse anchor_lang::prelude::*;\nuse anchor_spl::token::{self, Transfer};\n\npub fn transfer_tokens(ctx: Context<TransferTokens>, amount: u64) -> Result<()> {\n    let cpi_accounts = Transfer {\n        from: ctx.accounts.from.to_account_info(),\n        to: ctx.accounts.to.to_account_info(),\n        authority: ctx.accounts.authority.to_account_info(),\n    };\n\n    let cpi_program = ctx.accounts.token_program.to_account_info();\n    let cpi_ctx = CpiContext::new(cpi_program, cpi_accounts);\n\n    token::transfer(cpi_ctx, amount)?;\n    Ok(())\n}\n```\n\n### 3.3 with_signer for PDA Signing\n\n**SECURE - PDA signing with CPI:**\n```rust\npub fn transfer_from_vault(ctx: Context<TransferFromVault>, amount: u64) -> Result<()> {\n    let authority_bump = ctx.accounts.vault.authority_bump;\n    let authority_seeds = &[\n        b\"vault-authority\",\n        &[authority_bump]\n    ];\n    let signer_seeds = &[&authority_seeds[..]];\n\n    let cpi_accounts = Transfer {\n        from: ctx.accounts.vault_token_account.to_account_info(),\n        to: ctx.accounts.destination.to_account_info(),\n        authority: ctx.accounts.vault_authority.to_account_info(),\n    };\n\n    let cpi_program = ctx.accounts.token_program.to_account_info();\n    let cpi_ctx = CpiContext::new_with_signer(\n        cpi_program,\n        cpi_accounts,\n        signer_seeds // PDA can now sign!\n    );\n\n    token::transfer(cpi_ctx, amount)?;\n    Ok(())\n}\n```\n\n### 3.4 Validating CPI Return Data\n\n**SECURE - Check CPI return values:**\n```rust\npub fn safe_cpi_call(ctx: Context<SafeCpiCall>) -> Result<()> {\n    let result = external_program::cpi::risky_operation(\n        CpiContext::new(\n            ctx.accounts.external_program.to_account_info(),\n            RiskyOperation { /* ... */ }\n        )\n    )?;\n\n    // Validate return data\n    require!(\n        result.get().success,\n        ErrorCode::CpiOperationFailed\n    );\n\n    Ok(())\n}\n```\n\n### 3.5 Avoiding Arbitrary CPI Targets\n\n**VULNERABLE - Arbitrary CPI target:**\n```rust\n#[derive(Accounts)]\npub struct ArbitraryCpi<'info> {\n    /// CHECK: DANGEROUS - allows any program!\n    pub target_program: AccountInfo<'info>,\n}\n```\n\n**SECURE - Constrained CPI targets:**\n```rust\n#[derive(Accounts)]\npub struct SafeCpi<'info> {\n    // Option 1: Type-safe program constraint\n    pub token_program: Program<'info, Token>,\n\n    // Option 2: Explicit allowlist\n    #[account(\n        constraint = allowed_programs.contains(&other_program.key())\n            @ ErrorCode::UnauthorizedProgram\n    )]\n    pub other_program: Program<'info, OtherProgram>,\n}\n```\n\n## 4. Account Type Safety\n\n### 4.1 Account Discriminators\n\nAnchor automatically adds an 8-byte discriminator to each account type (first 8 bytes of SHA256 hash of `\"account:<AccountName>\"`).\n\n**How it protects you:**\n```rust\n#[account]\npub struct Vault {\n    pub authority: Pubkey,\n    pub balance: u64,\n}\n\n#[account]\npub struct UserAccount {\n    pub authority: Pubkey,\n    pub balance: u64,\n}\n\n// Anchor prevents this type confusion:\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>, // Won't deserialize UserAccount!\n}\n```\n\n**Manual discriminator handling:**\n```rust\nimpl Vault {\n    pub const DISCRIMINATOR: [u8; 8] = [/* computed at compile time */];\n}\n\n// Checking discriminator manually\nlet discriminator = &data[0..8];\nrequire!(\n    discriminator == Vault::DISCRIMINATOR,\n    ErrorCode::InvalidAccountType\n);\n```\n\n### 4.2 Account<'info, T> vs AccountInfo\n\n**Account<'info, T>:**\n- Type-safe deserialization\n- Automatic discriminator check\n- Automatic owner check\n- Immutable/mutable access control\n\n**AccountInfo:**\n- Raw account data\n- No automatic validation\n- Use only when necessary (non-Anchor programs, dynamic account types)\n\n**VULNERABLE - Using AccountInfo unnecessarily:**\n```rust\n#[derive(Accounts)]\npub struct UpdateVault<'info> {\n    /// CHECK: Missing type safety!\n    pub vault: AccountInfo<'info>,\n}\n```\n\n**SECURE - Use Account<'info, T>:**\n```rust\n#[derive(Accounts)]\npub struct UpdateVault<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>,\n}\n```\n\n### 4.3 AccountLoader for Zero-Copy Accounts\n\nFor large accounts (>10KB), use zero-copy deserialization:\n\n```rust\n#[account(zero_copy)]\npub struct LargeAccount {\n    pub data: [u8; 100000],\n}\n\n#[derive(Accounts)]\npub struct UpdateLargeAccount<'info> {\n    #[account(mut)]\n    pub large_account: AccountLoader<'info, LargeAccount>,\n}\n\npub fn update(ctx: Context<UpdateLargeAccount>) -> Result<()> {\n    let mut account = ctx.accounts.large_account.load_mut()?;\n    account.data[0] = 42;\n    Ok(())\n}\n```\n\n**Security note:** Zero-copy accounts use `RefCell` internally. Must call `load()` or `load_mut()` each time you access data to ensure safety.\n\n### 4.4 Type Cosplay Prevention\n\n**Attack:** Creating fake accounts with correct discriminator but wrong program owner.\n\n**Anchor's defense:**\n```rust\n#[account]\n#[derive(Default)]\npub struct MyAccount {\n    pub data: u64,\n}\n\n// Anchor checks:\n// 1. Discriminator matches\n// 2. Owner is this program's ID\n// 3. Account is properly sized\n```\n\n**Additional validation for external accounts:**\n```rust\n#[derive(Accounts)]\npub struct UseExternalAccount<'info> {\n    #[account(\n        constraint = external_account.owner == &external_program::ID\n            @ ErrorCode::InvalidAccountOwner\n    )]\n    pub external_account: AccountInfo<'info>,\n}\n```\n\n## 5. Error Handling Security\n\n### 5.1 Custom Error Codes\n\n**Define clear error codes:**\n```rust\n#[error_code]\npub enum ErrorCode {\n    #[msg(\"Insufficient funds for withdrawal\")]\n    InsufficientFunds,\n    #[msg(\"Unauthorized access attempt\")]\n    Unauthorized,\n    #[msg(\"Invalid configuration parameters\")]\n    InvalidConfig,\n    #[msg(\"Arithmetic overflow occurred\")]\n    Overflow,\n}\n```\n\n**Use with require! macro:**\n```rust\npub fn withdraw(ctx: Context<Withdraw>, amount: u64) -> Result<()> {\n    require!(\n        ctx.accounts.vault.balance >= amount,\n        ErrorCode::InsufficientFunds\n    );\n\n    require!(\n        ctx.accounts.vault.authority == ctx.accounts.user.key(),\n        ErrorCode::Unauthorized\n    );\n\n    // Safe to proceed\n    Ok(())\n}\n```\n\n### 5.2 Error Propagation Patterns\n\n**WRONG - Silencing errors:**\n```rust\npub fn risky_operation(ctx: Context<RiskyOp>) -> Result<()> {\n    let _ = dangerous_function(); // WRONG - error silenced!\n    Ok(())\n}\n```\n\n**CORRECT - Propagate errors:**\n```rust\npub fn risky_operation(ctx: Context<RiskyOp>) -> Result<()> {\n    dangerous_function()?; // Propagate error\n    Ok(())\n}\n```\n\n### 5.3 Avoiding Silent Failures\n\n**VULNERABLE - No error on failure:**\n```rust\npub fn transfer(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    if ctx.accounts.from.balance >= amount {\n        ctx.accounts.from.balance -= amount;\n        ctx.accounts.to.balance += amount;\n    }\n    // Returns Ok even if transfer didn't happen!\n    Ok(())\n}\n```\n\n**SECURE - Explicit error:**\n```rust\npub fn transfer(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    require!(\n        ctx.accounts.from.balance >= amount,\n        ErrorCode::InsufficientFunds\n    );\n\n    ctx.accounts.from.balance -= amount;\n    ctx.accounts.to.balance += amount;\n    Ok(())\n}\n```\n\n## 6. Token Program Integration\n\n### 6.1 anchor_spl Security Patterns\n\n**SECURE - Using anchor_spl helpers:**\n```rust\nuse anchor_spl::token::{self, Token, TokenAccount, Transfer};\n\n#[derive(Accounts)]\npub struct TransferTokens<'info> {\n    #[account(mut)]\n    pub from: Account<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n    pub authority: Signer<'info>,\n    pub token_program: Program<'info, Token>,\n}\n\npub fn transfer_tokens(ctx: Context<TransferTokens>, amount: u64) -> Result<()> {\n    token::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.from.to_account_info(),\n                to: ctx.accounts.to.to_account_info(),\n                authority: ctx.accounts.authority.to_account_info(),\n            },\n        ),\n        amount,\n    )?;\n    Ok(())\n}\n```\n\n### 6.2 token_interface Usage\n\nFor Token-2022 compatibility:\n\n```rust\nuse anchor_spl::token_interface::{self, TokenInterface, TokenAccount};\n\n#[derive(Accounts)]\npub struct TransferTokens<'info> {\n    #[account(mut)]\n    pub from: InterfaceAccount<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: InterfaceAccount<'info, TokenAccount>,\n    pub authority: Signer<'info>,\n    pub token_program: Interface<'info, TokenInterface>,\n}\n```\n\n### 6.3 Associated Token Account Constraints\n\n**VULNERABLE - Missing ATA validation:**\n```rust\n#[derive(Accounts)]\npub struct DepositTokens<'info> {\n    #[account(mut)]\n    pub user_token_account: Account<'info, TokenAccount>,\n    pub user: Signer<'info>,\n}\n```\n\n**SECURE - Validate ATA:**\n```rust\nuse anchor_spl::associated_token::AssociatedToken;\n\n#[derive(Accounts)]\npub struct DepositTokens<'info> {\n    #[account(\n        mut,\n        associated_token::mint = mint,\n        associated_token::authority = user\n    )]\n    pub user_token_account: Account<'info, TokenAccount>,\n    pub user: Signer<'info>,\n    pub mint: Account<'info, Mint>,\n    pub token_program: Program<'info, Token>,\n    pub associated_token_program: Program<'info, AssociatedToken>,\n}\n```\n\n### 6.4 Token-2022 Extension Handling\n\n**Be aware of extensions:**\n```rust\npub fn handle_transfer(ctx: Context<HandleTransfer>, amount: u64) -> Result<()> {\n    // Token-2022 may have transfer fees, freeze authority, etc.\n    // Always check actual amount received after transfer\n\n    let before_balance = ctx.accounts.destination.amount;\n\n    token_interface::transfer_checked(\n        CpiContext::new(/* ... */),\n        amount,\n        ctx.accounts.mint.decimals,\n    )?;\n\n    ctx.accounts.destination.reload()?;\n    let actual_amount = ctx.accounts.destination.amount - before_balance;\n\n    // Use actual_amount for accounting\n    Ok(())\n}\n```\n\n## 7. Event Security\n\n### 7.1 When to Emit Events\n\nEvents are critical for:\n- Indexing and querying program state\n- Auditing sensitive operations\n- Monitoring for security incidents\n\n**Always emit events for:**\n- State changes (deposits, withdrawals, config updates)\n- Authorization changes (role grants, ownership transfers)\n- Critical operations (program upgrades, emergency actions)\n\n### 7.2 Event Data Validation\n\n**SECURE - Validate before emitting:**\n```rust\n#[event]\npub struct WithdrawalEvent {\n    pub user: Pubkey,\n    pub amount: u64,\n    pub timestamp: i64,\n}\n\npub fn withdraw(ctx: Context<Withdraw>, amount: u64) -> Result<()> {\n    // Validate first\n    require!(\n        ctx.accounts.vault.balance >= amount,\n        ErrorCode::InsufficientFunds\n    );\n\n    // Perform operation\n    ctx.accounts.vault.balance -= amount;\n\n    // Emit event AFTER successful operation\n    emit!(WithdrawalEvent {\n        user: ctx.accounts.user.key(),\n        amount,\n        timestamp: Clock::get()?.unix_timestamp,\n    });\n\n    Ok(())\n}\n```\n\n### 7.3 emit! vs emit_cpi!\n\n**emit! - Regular event:**\n```rust\nemit!(MyEvent {\n    data: value,\n});\n```\n\n**emit_cpi! - Event for CPI callers:**\n```rust\n// Use when program is called via CPI and event should be\n// visible to the calling program\nemit_cpi!(MyEvent {\n    data: value,\n});\n```\n\n## 8. Anchor-Specific Best Practices\n\n### 8.1 Account Space Calculation with InitSpace\n\n**SECURE - Using InitSpace derive macro:**\n```rust\nuse anchor_lang::prelude::*;\n\n#[account]\n#[derive(InitSpace)]\npub struct UserProfile {\n    pub authority: Pubkey,      // 32 bytes\n    #[max_len(50)]\n    pub name: String,            // 4 + 50 bytes\n    pub created_at: i64,         // 8 bytes\n    pub bump: u8,                // 1 byte\n}\n\n#[derive(Accounts)]\npub struct CreateProfile<'info> {\n    #[account(\n        init,\n        payer = payer,\n        space = 8 + UserProfile::INIT_SPACE, // 8 for discriminator\n        seeds = [b\"profile\", authority.key().as_ref()],\n        bump\n    )]\n    pub profile: Account<'info, UserProfile>,\n    pub authority: Signer<'info>,\n    #[account(mut)]\n    pub payer: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n### 8.2 Remaining Accounts Handling\n\n**SECURE - Validate remaining accounts:**\n```rust\npub fn process_multiple_accounts(\n    ctx: Context<ProcessAccounts>,\n    count: u8,\n) -> Result<()> {\n    let remaining = &ctx.remaining_accounts;\n\n    // Validate count\n    require!(\n        remaining.len() == count as usize,\n        ErrorCode::InvalidAccountCount\n    );\n\n    // Validate each account\n    for account_info in remaining.iter() {\n        require!(\n            account_info.is_writable,\n            ErrorCode::AccountNotWritable\n        );\n\n        require!(\n            account_info.owner == ctx.program_id,\n            ErrorCode::InvalidAccountOwner\n        );\n\n        // Deserialize and validate type\n        let account = Account::<MyAccount>::try_from(account_info)?;\n\n        // Process account...\n    }\n\n    Ok(())\n}\n```\n\n### 8.3 Instruction Data Validation\n\n**SECURE - Validate all inputs:**\n```rust\npub fn create_proposal(\n    ctx: Context<CreateProposal>,\n    title: String,\n    description: String,\n    execution_delay: i64,\n) -> Result<()> {\n    // Validate string lengths\n    require!(\n        title.len() > 0 && title.len() <= 100,\n        ErrorCode::InvalidTitleLength\n    );\n\n    require!(\n        description.len() <= 1000,\n        ErrorCode::DescriptionTooLong\n    );\n\n    // Validate numeric ranges\n    require!(\n        execution_delay >= MIN_DELAY && execution_delay <= MAX_DELAY,\n        ErrorCode::InvalidExecutionDelay\n    );\n\n    // Validate against overflow\n    let execution_time = Clock::get()?\n        .unix_timestamp\n        .checked_add(execution_delay)\n        .ok_or(ErrorCode::Overflow)?;\n\n    ctx.accounts.proposal.title = title;\n    ctx.accounts.proposal.description = description;\n    ctx.accounts.proposal.execution_time = execution_time;\n\n    Ok(())\n}\n```\n\n### 8.4 Upgradability Considerations\n\n**SECURE - Handle program upgrades safely:**\n\n```rust\n#[account]\n#[derive(InitSpace)]\npub struct ProgramConfig {\n    pub version: u8,\n    pub upgrade_authority: Pubkey,\n    pub paused: bool,\n}\n\npub fn migrate(ctx: Context<Migrate>) -> Result<()> {\n    let config = &mut ctx.accounts.config;\n\n    // Check current version\n    require!(\n        config.version < CURRENT_VERSION,\n        ErrorCode::AlreadyMigrated\n    );\n\n    // Perform version-specific migrations\n    match config.version {\n        0 => {\n            // Migrate from v0 to v1\n            // Add new fields, transform data, etc.\n        }\n        1 => {\n            // Migrate from v1 to v2\n        }\n        _ => return Err(ErrorCode::UnsupportedVersion.into()),\n    }\n\n    config.version = CURRENT_VERSION;\n    Ok(())\n}\n```\n\n**Emergency pause pattern:**\n```rust\n#[derive(Accounts)]\npub struct SensitiveOperation<'info> {\n    #[account(\n        constraint = !config.paused @ ErrorCode::ProgramPaused\n    )]\n    pub config: Account<'info, ProgramConfig>,\n    // ... other accounts\n}\n```\n\nThis ensures you can pause the program in case of emergencies during or after upgrades.\n",
        "solana/skills/solana-security/references/caveats.md": "# Important Caveats\n\nCritical limitations, quirks, and gotchas in Solana and Anchor development that every security reviewer must know.\n\n## Anchor Framework Limitations\n\n### 1. `init_if_needed` Re-initialization Risk\n\n```rust\n// Dangerous: Can bypass initialization logic\n#[account(init_if_needed, payer = user, space = ...)]\npub user_account: Account<'info, UserAccount>,\n```\n\n**Issue:** If account already exists, initialization is skipped entirely. Existing malicious or inconsistent data is not validated.\n\n**When to use:** Only when you explicitly validate existing accounts in instruction logic.\n\n### 2. `AccountLoader` Missing Discriminator Check\n\n```rust\n// Does NOT validate discriminator by default!\n#[account(mut)]\npub user: AccountLoader<'info, User>,\n```\n\n**Issue:** `AccountLoader` is for zero-copy accounts and doesn't check the account discriminator automatically. Enables type cosplay attacks.\n\n**Solution:** Use `Account<'info, T>` when possible, or add manual discriminator check.\n\n### 3. `close` Constraint Ordering\n\n```rust\n// ❌ Wrong: close must be last\n#[account(\n    close = receiver,\n    mut,\n    has_one = authority\n)]\n\n// ✅ Correct: close is last\n#[account(\n    mut,\n    has_one = authority,\n    close = receiver\n)]\n```\n\n**Issue:** Anchor processes constraints in order. If `close` isn't last, subsequent constraints may check zeroed account.\n\n### 4. Space Calculation Errors Are Permanent\n\n```rust\n// If this space is wrong, account is unusable!\n#[account(\n    init,\n    payer = user,\n    space = 8 + 32  // Too small = can't deserialize later!\n)]\npub user_account: Account<'info, UserAccount>,\n```\n\n**Issue:** Once initialized, account size is fixed. Too small = deserialization fails. Too large = wasted rent.\n\n**Solution:** Always use `InitSpace` derive macro:\n```rust\n#[account]\n#[derive(InitSpace)]\npub struct UserAccount {\n    pub authority: Pubkey,\n    #[max_len(100)]\n    pub name: String,\n}\n\n// Then use:\nspace = 8 + UserAccount::INIT_SPACE\n```\n\n### 5. `constraint` Expression Limitations\n\n```rust\n// constraint expressions can't call functions that return Results!\n#[account(\n    constraint = some_validation(account.value)? @ ErrorCode::Invalid  // Compile error!\n)]\n```\n\n**Issue:** Constraint expressions must be simple boolean checks. Cannot use `?` operator.\n\n**Solution:** Validate in instruction body for complex checks.\n\n## Solana Runtime Quirks\n\n### 1. Account Data Persists After Zeroing Lamports\n\n```rust\n// Within same transaction:\n**account.lamports.borrow_mut() = 0;\nlet data = account.try_borrow_data()?;  // Still readable!\n```\n\n**Issue:** Account data remains accessible within the transaction even after lamports are zeroed. Only garbage collected after transaction completes.\n\n**Implication:** Always check lamports before reading account data.\n\n### 2. Non-Canonical PDA Bumps\n\n```rust\n// Multiple PDAs possible with different bumps!\nlet (pda_255, bump_255) = Pubkey::find_program_address(seeds, program_id);  // bump = 255\nlet (pda_254, bump_254) = Pubkey::create_program_address(&[seeds, &[254]], program_id);  // Also valid!\n```\n\n**Issue:** Same seeds can derive multiple PDAs with different bumps. Creates confusion and potential exploits.\n\n**Solution:** Always use canonical bump (255 counting down to first valid). Anchor's `bump` constraint enforces this.\n\n### 3. Compute Budget Limits\n\n| Network | Base Compute Units | With Optimization |\n|---------|-------------------|-------------------|\n| Mainnet | 200,000 | Up to 1,400,000 (with request) |\n| Devnet  | 200,000 | Up to 1,400,000 |\n\n**Issue:** Complex programs can exceed compute budget, causing transaction failure.\n\n**Optimization strategies:**\n- Minimize CPIs (each costs ~1000 CU)\n- Use `AccountLoader` for large accounts\n- Avoid loops with variable length\n- Request higher compute budget: `ComputeBudgetProgram::set_compute_unit_limit()`\n\n### 4. Transaction Size Limit\n\n**Hard limit:** ~1232 bytes for transaction\n\n**Implications:**\n- Limits number of accounts (~35-40 accounts typical max)\n- Large instructions need Account Compression or chunking\n- Can't pass large data directly in instruction\n\n**Solutions:**\n- Use PDAs to store large data\n- Break operations into multiple transactions\n- Use lookup tables for frequent accounts\n\n### 5. Account Snapshot Loading\n\n```rust\nlet balance_before = ctx.accounts.vault.balance;\n// CPI happens here\n// balance_before is STALE - account was loaded before CPI\n```\n\n**Issue:** Accounts are loaded as snapshots at transaction start. Modifications during transaction (via CPIs) don't update the loaded data.\n\n**Solution:** Call `.reload()` after any CPI that might modify the account.\n\n## Token Program Gotchas\n\n### 1. ATA Addresses Are Deterministic But Not Guaranteed\n\n```rust\nlet ata = get_associated_token_address(&owner, &mint);\n// ata address is deterministic but account might not exist!\n```\n\n**Issue:** ATA address can be calculated but account may not be initialized.\n\n**Solution:** Check account exists and is initialized before use, or use `init_if_needed` with proper validation.\n\n### 2. Delegates Don't Automatically Reset\n\n```rust\n// After transfer of ownership:\ntoken_account.owner = new_owner;\n// BUT: delegate and delegated_amount are NOT reset!\n```\n\n**Issue:** Changing owner doesn't clear delegate/close authority. Old delegate can still spend.\n\n**Solution:** Explicitly reset authorities when changing ownership:\n```rust\naccount.delegate = COption::None;\naccount.delegated_amount = 0;\nif account.is_native() {\n    account.close_authority = COption::None;\n}\n```\n\n### 3. Token-2022 Extension Rent\n\n**Issue:** Each extension adds rent cost. Account size varies by extensions enabled.\n\n**Extensions and their sizes:**\n- Transfer Fee: ~83 bytes\n- Transfer Hook: ~107 bytes\n- Permanent Delegate: ~36 bytes\n- Interest Bearing: ~40 bytes\n\n**Solution:** Calculate rent based on all enabled extensions.\n\n### 4. Token-2022 Transfer Hooks Can Be Malicious\n\n```rust\n// Transfer hook can call arbitrary program!\npub struct TransferHookAccount {\n    pub program_id: Pubkey,  // Could be malicious\n}\n```\n\n**Issue:** Transfer hook extensions allow calling external program during transfers. Malicious hook can fail transaction or drain funds.\n\n**Solution:**\n- Validate transfer hook program if accepting specific tokens\n- Consider disallowing tokens with transfer hooks\n- Use Anchor's `TransferChecked` instruction\n\n## Testing Blind Spots\n\n### 1. Concurrent Transaction Ordering\n\n**Issue:** Tests typically run transactions sequentially. In production, concurrent transactions can interleave in unexpected ways.\n\n**Vulnerability example:**\n```rust\n// Transaction 1: Check balance = 100\n// Transaction 2: Withdraw 80 (balance now 20)\n// Transaction 1: Withdraw 80 (uses stale check, balance now -60!)\n```\n\n**Mitigation:**\n- Use atomic operations\n- Reload accounts before critical operations\n- Design for idempotency\n\n### 2. Account Rent Reclaim Attacks\n\n**Issue:** When account rent falls below minimum, validator can reclaim the account. Tests don't simulate this.\n\n**Solution:** Ensure all accounts are rent-exempt (2+ years of rent).\n\n### 3. Sysvar Manipulation in Tests\n\n```rust\n// In tests, you can set arbitrary clock values\nctx.accounts.clock = Clock { unix_timestamp: attacker_value, ... };\n```\n\n**Issue:** Tests may not catch reliance on tamper-resistant sysvars.\n\n**Solution:** In production, always load sysvars from official sysvar accounts:\n```rust\npub clock: Sysvar<'info, Clock>,  // Validated address\n```\n\n### 4. Devnet vs Mainnet Differences\n\n| Aspect | Devnet | Mainnet |\n|--------|--------|---------|\n| Oracle prices | Often stale/fake | Real-time |\n| Program versions | May differ | Stable versions |\n| Compute limits | More lenient | Strict |\n| Congestion | Minimal | Can be high |\n| Token availability | Test tokens | Real value |\n\n**Issue:** Programs tested only on devnet may fail on mainnet.\n\n**Solution:** Test on mainnet-fork or mainnet with small amounts before full deployment.\n\n## Rust-Specific Gotchas\n\n### 1. `unwrap()` Panics\n\n```rust\n// Panics kill the entire transaction!\nlet value = some_option.unwrap();  // ❌ Never do this\n```\n\n**Solution:** Always use proper error handling:\n```rust\nlet value = some_option.ok_or(ErrorCode::MissingValue)?;\n```\n\n### 2. Integer Division Truncation\n\n```rust\nlet result = 5 / 2;  // result = 2, not 2.5!\n```\n\n**Issue:** Integer division truncates, potentially causing precision loss in financial calculations.\n\n**Solution:** Use `Decimal` type for precise calculations, or multiply before divide:\n```rust\nlet result = (5 * PRECISION) / 2 / PRECISION;\n```\n\n### 3. Overflow in Debug vs Release\n\n```rust\n// Debug mode: panics on overflow\n// Release mode: wraps silently!\nlet x: u8 = 255;\nlet y = x + 1;  // Debug: panic, Release: y = 0\n```\n\n**Solution:** Always use `checked_*` methods - they work same in debug and release.\n\n## Cross-Program Invocation (CPI) Gotchas\n\n### 1. CPI Success Doesn't Guarantee Correct State\n\n```rust\n// CPI returns success but state may be unexpected\ninvoke(&transfer_instruction, &accounts)?;\n// Transfer succeeded but amount might be different due to fees!\n```\n\n**Solution:** Reload and validate account state after CPI.\n\n### 2. Signer Seeds Must Be Exact\n\n```rust\n// Seeds for signing must match PDA derivation exactly\nlet seeds = &[\n    b\"vault\",\n    user.key().as_ref(),\n    &[bump],  // Must be same bump used to derive PDA\n];\n\ninvoke_signed(&instruction, &accounts, &[seeds])?;\n```\n\n**Issue:** Wrong seeds = \"signature verification failed\" error.\n\n### 3. CPI Depth Limit\n\n**Limit:** 4 levels of CPI depth\n\n**Issue:** Program A → Program B → Program C → Program D → Program E (fails!)\n\n**Solution:** Design programs to minimize CPI depth.\n\n## Common Misunderstandings\n\n### 1. \"Anchor Prevents All Security Issues\"\n\n**False:** Anchor prevents some common issues (missing discriminators, wrong account types) but doesn't validate business logic, arithmetic, or authorization.\n\n### 2. \"Devnet Testing Is Sufficient\"\n\n**False:** Mainnet has different compute limits, real oracle data, congestion, and MEV considerations.\n\n### 3. \"One Audit Makes Code Secure\"\n\n**False:** Audits find issues in a snapshot. Code changes after audit reintroduce risk. Need continuous security review.\n\n### 4. \"`checked_*` Methods Are Slower\"\n\n**False:** Rust compiler optimizes these similarly to unchecked arithmetic. Always use checked methods.\n\n### 5. \"PDAs Can't Sign\"\n\n**True for external transactions, false for CPIs:** PDAs can sign CPIs using `invoke_signed` but can't sign transactions directly.\n\n## Version-Specific Issues\n\n### Anchor Version Compatibility\n\n- **< 0.28**: No `InitSpace` derive, manual space calculation error-prone\n- **< 0.29**: Different constraint syntax\n- **0.30+**: Breaking changes in error handling and account initialization\n\n**Solution:** Check `Cargo.toml` for version and consult [Anchor Changelog](https://github.com/coral-xyz/anchor/blob/master/CHANGELOG.md).\n\n### Solana Version Differences\n\n- **Pre-1.14**: Different fee structure\n- **Pre-1.16**: No Address Lookup Tables\n- **Pre-1.17**: No Token-2022\n\n**Solution:** Verify target Solana version matches deployment network.\n\n---\n\n**Key Takeaway:** Many \"obvious\" assumptions about blockchain behavior don't hold in Solana. Always validate against actual runtime behavior, not assumptions from other chains.\n",
        "solana/skills/solana-security/references/native-security.md": "# Native Rust Security Patterns for Solana Programs\n\nThis reference covers security vulnerabilities and best practices specific to Solana programs built with native Rust (without Anchor framework).\n\n## Table of Contents\n\n1. [Manual Account Validation](#manual-account-validation)\n2. [Account Discriminator Patterns](#account-discriminator-patterns)\n3. [PDA Security in Native Rust](#pda-security-in-native-rust)\n4. [Manual CPI Security](#manual-cpi-security)\n5. [Manual Serialization Security](#manual-serialization-security)\n6. [Rent and Space Management](#rent-and-space-management)\n7. [Error Handling in Native Rust](#error-handling-in-native-rust)\n8. [Token Program Integration](#token-program-integration)\n9. [Low-Level Security Patterns](#low-level-security-patterns)\n10. [Native Rust Best Practices](#native-rust-best-practices)\n\n---\n\n## Manual Account Validation\n\nIn native Rust programs, ALL account validation must be performed manually. Missing any check can lead to critical vulnerabilities.\n\n### Signer Checks\n\n**Vulnerable:**\n```rust\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    _instruction_data: &[u8],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let authority = next_account_info(account_info_iter)?;\n\n    // Missing signer check - anyone can call this!\n    // Perform privileged operation\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    _instruction_data: &[u8],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let authority = next_account_info(account_info_iter)?;\n\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Now safe to perform privileged operation\n    Ok(())\n}\n```\n\n### Owner Validation\n\n**Vulnerable:**\n```rust\npub fn update_config(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let config_account = next_account_info(account_info_iter)?;\n\n    // Missing owner check - could be any account!\n    let mut config_data = Config::try_from_slice(&config_account.data.borrow())?;\n    config_data.value = 42;\n    config_data.serialize(&mut *config_account.data.borrow_mut())?;\n\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn update_config(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let config_account = next_account_info(account_info_iter)?;\n\n    // Verify this account is owned by our program\n    if config_account.owner != program_id {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    let mut config_data = Config::try_from_slice(&config_account.data.borrow())?;\n    config_data.value = 42;\n    config_data.serialize(&mut *config_account.data.borrow_mut())?;\n\n    Ok(())\n}\n```\n\n### Writable Checks\n\n**Vulnerable:**\n```rust\npub fn transfer_tokens(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let source = next_account_info(account_info_iter)?;\n\n    // Missing writable check - runtime will panic!\n    let mut data = source.try_borrow_mut_data()?;\n    // Modify data...\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn transfer_tokens(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let source = next_account_info(account_info_iter)?;\n\n    if !source.is_writable {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    let mut data = source.try_borrow_mut_data()?;\n    // Safe to modify data\n    Ok(())\n}\n```\n\n### Comprehensive Validation Function\n\n**Best Practice:**\n```rust\npub struct AccountValidation<'a, 'info> {\n    account: &'a AccountInfo<'info>,\n}\n\nimpl<'a, 'info> AccountValidation<'a, 'info> {\n    pub fn new(account: &'a AccountInfo<'info>) -> Self {\n        Self { account }\n    }\n\n    pub fn owner(self, expected_owner: &Pubkey) -> Result<Self, ProgramError> {\n        if self.account.owner != expected_owner {\n            return Err(ProgramError::IncorrectProgramId);\n        }\n        Ok(self)\n    }\n\n    pub fn signer(self) -> Result<Self, ProgramError> {\n        if !self.account.is_signer {\n            return Err(ProgramError::MissingRequiredSignature);\n        }\n        Ok(self)\n    }\n\n    pub fn writable(self) -> Result<Self, ProgramError> {\n        if !self.account.is_writable {\n            return Err(ProgramError::InvalidAccountData);\n        }\n        Ok(self)\n    }\n\n    pub fn key(self, expected_key: &Pubkey) -> Result<Self, ProgramError> {\n        if self.account.key != expected_key {\n            return Err(ProgramError::InvalidAccountData);\n        }\n        Ok(self)\n    }\n\n    pub fn initialized(self) -> Result<Self, ProgramError> {\n        if self.account.data_is_empty() {\n            return Err(ProgramError::UninitializedAccount);\n        }\n        Ok(self)\n    }\n}\n\n// Usage:\npub fn process(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let authority = next_account_info(account_info_iter)?;\n    let config = next_account_info(account_info_iter)?;\n\n    AccountValidation::new(authority)\n        .signer()?;\n\n    AccountValidation::new(config)\n        .owner(program_id)?\n        .writable()?\n        .initialized()?;\n\n    // All validations passed\n    Ok(())\n}\n```\n\n---\n\n## Account Discriminator Patterns\n\nWithout Anchor's automatic discriminators, you must manually implement account type safety.\n\n### Why Discriminators Matter\n\n**Vulnerable:**\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct ConfigAccount {\n    pub admin: Pubkey,\n    pub value: u64,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserAccount {\n    pub owner: Pubkey,\n    pub balance: u64,\n}\n\npub fn update_config(accounts: &[AccountInfo]) -> ProgramResult {\n    let config = next_account_info(&mut accounts.iter())?;\n\n    // No discriminator check - UserAccount has same layout!\n    let mut data = ConfigAccount::try_from_slice(&config.data.borrow())?;\n    data.value = 999;\n    // Could be writing to a UserAccount!\n\n    Ok(())\n}\n```\n\n### Implementing Discriminators\n\n**Secure:**\n```rust\nuse borsh::{BorshDeserialize, BorshSerialize};\n\npub const CONFIG_DISCRIMINATOR: u64 = 0x1234567890ABCDEF;\npub const USER_DISCRIMINATOR: u64 = 0xFEDCBA0987654321;\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct ConfigAccount {\n    pub discriminator: u64,\n    pub admin: Pubkey,\n    pub value: u64,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserAccount {\n    pub discriminator: u64,\n    pub owner: Pubkey,\n    pub balance: u64,\n}\n\nimpl ConfigAccount {\n    pub const LEN: usize = 8 + 32 + 8;\n\n    pub fn new(admin: Pubkey, value: u64) -> Self {\n        Self {\n            discriminator: CONFIG_DISCRIMINATOR,\n            admin,\n            value,\n        }\n    }\n\n    pub fn from_account_info(account: &AccountInfo) -> Result<Self, ProgramError> {\n        let data = account.data.borrow();\n        if data.len() < 8 {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        let discriminator = u64::from_le_bytes(data[0..8].try_into().unwrap());\n        if discriminator != CONFIG_DISCRIMINATOR {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        Self::try_from_slice(&data).map_err(|_| ProgramError::InvalidAccountData)\n    }\n}\n\npub fn update_config(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let config_account = next_account_info(&mut accounts.iter())?;\n\n    // Discriminator validated during deserialization\n    let mut config = ConfigAccount::from_account_info(config_account)?;\n    config.value = 999;\n    config.serialize(&mut *config_account.data.borrow_mut())?;\n\n    Ok(())\n}\n```\n\n### Alternative: String-Based Discriminators\n\n```rust\npub const ACCOUNT_TYPE_LEN: usize = 8;\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct TaggedAccount {\n    pub account_type: [u8; ACCOUNT_TYPE_LEN], // \"CONFIG\\0\\0\"\n    pub data: AccountData,\n}\n\nimpl TaggedAccount {\n    pub fn new_config(data: AccountData) -> Self {\n        let mut account_type = [0u8; ACCOUNT_TYPE_LEN];\n        account_type[..6].copy_from_slice(b\"CONFIG\");\n        Self { account_type, data }\n    }\n\n    pub fn assert_config(&self) -> ProgramResult {\n        let mut expected = [0u8; ACCOUNT_TYPE_LEN];\n        expected[..6].copy_from_slice(b\"CONFIG\");\n\n        if self.account_type != expected {\n            return Err(ProgramError::InvalidAccountData);\n        }\n        Ok(())\n    }\n}\n```\n\n---\n\n## PDA Security in Native Rust\n\n### find_program_address vs create_program_address\n\n**Vulnerable:**\n```rust\npub fn init_pda(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    bump: u8,\n) -> ProgramResult {\n    let pda_account = next_account_info(&mut accounts.iter())?;\n\n    // Using user-provided bump without validation!\n    let pda = Pubkey::create_program_address(\n        &[b\"config\", &[bump]],\n        program_id,\n    )?;\n\n    if pda_account.key != &pda {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Attacker could find non-canonical bump\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn init_pda(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let pda_account = next_account_info(&mut accounts.iter())?;\n\n    // Always use find_program_address to get canonical bump\n    let (pda, bump) = Pubkey::find_program_address(\n        &[b\"config\"],\n        program_id,\n    );\n\n    if pda_account.key != &pda {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Store the canonical bump for later use\n    let mut data = ConfigPda::new(bump);\n    data.serialize(&mut *pda_account.data.borrow_mut())?;\n\n    Ok(())\n}\n```\n\n### Storing and Using Canonical Bumps\n\n**Best Practice:**\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct VaultPda {\n    pub discriminator: u64,\n    pub bump: u8,\n    pub authority: Pubkey,\n    pub balance: u64,\n}\n\nimpl VaultPda {\n    pub fn seeds<'a>(&'a self, authority: &'a Pubkey) -> [&'a [u8]; 3] {\n        [b\"vault\", authority.as_ref(), &[self.bump]]\n    }\n\n    pub fn verify_pda(\n        &self,\n        pda_account: &AccountInfo,\n        authority: &Pubkey,\n        program_id: &Pubkey,\n    ) -> ProgramResult {\n        let expected_pda = Pubkey::create_program_address(\n            &self.seeds(authority),\n            program_id,\n        )?;\n\n        if pda_account.key != &expected_pda {\n            return Err(ProgramError::InvalidSeeds);\n        }\n\n        Ok(())\n    }\n}\n```\n\n### PDA Signing with invoke_signed\n\n**Secure Pattern:**\n```rust\nuse solana_program::program::invoke_signed;\n\npub fn transfer_from_pda(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let vault_pda = next_account_info(account_info_iter)?;\n    let destination = next_account_info(account_info_iter)?;\n    let authority = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Load and validate PDA data\n    let vault = VaultPda::from_account_info(vault_pda)?;\n    vault.verify_pda(vault_pda, authority.key, program_id)?;\n\n    // Sign with PDA's seeds\n    let seeds = vault.seeds(authority.key);\n    let signer_seeds = &[&seeds[..]];\n\n    let ix = solana_program::system_instruction::transfer(\n        vault_pda.key,\n        destination.key,\n        amount,\n    );\n\n    invoke_signed(\n        &ix,\n        &[vault_pda.clone(), destination.clone(), system_program.clone()],\n        signer_seeds,\n    )?;\n\n    Ok(())\n}\n```\n\n### Preventing PDA Substitution\n\n**Vulnerable:**\n```rust\npub fn withdraw(accounts: &[AccountInfo]) -> ProgramResult {\n    let vault = next_account_info(&mut accounts.iter())?;\n\n    // No validation that this is the CORRECT vault PDA\n    let vault_data = VaultPda::from_account_info(vault)?;\n\n    // Attacker could substitute a different vault!\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn withdraw(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let vault = next_account_info(account_info_iter)?;\n    let authority = next_account_info(account_info_iter)?;\n\n    // Derive expected PDA\n    let (expected_vault, _bump) = Pubkey::find_program_address(\n        &[b\"vault\", authority.key.as_ref()],\n        program_id,\n    );\n\n    // Validate this is the correct PDA\n    if vault.key != &expected_vault {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    let vault_data = VaultPda::from_account_info(vault)?;\n    // Safe to proceed\n\n    Ok(())\n}\n```\n\n---\n\n## Manual CPI Security\n\n### Building AccountMeta Arrays Securely\n\n**Vulnerable:**\n```rust\npub fn dangerous_cpi(accounts: &[AccountInfo]) -> ProgramResult {\n    let target_program = next_account_info(&mut accounts.iter())?;\n    let account1 = next_account_info(&mut accounts.iter())?;\n\n    // Missing validation - could be any program!\n    let ix = Instruction {\n        program_id: *target_program.key,\n        accounts: vec![\n            AccountMeta::new(*account1.key, false), // Wrong signer flag!\n        ],\n        data: vec![],\n    };\n\n    invoke(&ix, &[target_program.clone(), account1.clone()])?;\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\nuse solana_program::program::invoke;\n\npub const EXPECTED_PROGRAM_ID: Pubkey = solana_program::pubkey!(\"YourProgramID111111111111111111111111111111\");\n\npub fn secure_cpi(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let target_program = next_account_info(account_info_iter)?;\n    let account1 = next_account_info(account_info_iter)?;\n\n    // Validate target program ID\n    if target_program.key != &EXPECTED_PROGRAM_ID {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // Correctly propagate signer/writable flags\n    let account_metas = vec![\n        AccountMeta {\n            pubkey: *account1.key,\n            is_signer: account1.is_signer,\n            is_writable: account1.is_writable,\n        },\n    ];\n\n    let ix = Instruction {\n        program_id: *target_program.key,\n        accounts: account_metas,\n        data: vec![],\n    };\n\n    invoke(&ix, &[target_program.clone(), account1.clone()])?;\n    Ok(())\n}\n```\n\n### Checking CPI Success\n\n**Best Practice:**\n```rust\npub fn cpi_with_validation(accounts: &[AccountInfo]) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let token_program = next_account_info(account_info_iter)?;\n    let source = next_account_info(account_info_iter)?;\n    let destination = next_account_info(account_info_iter)?;\n    let authority = next_account_info(account_info_iter)?;\n\n    // Get balances before CPI\n    let source_before = source.lamports();\n    let dest_before = destination.lamports();\n\n    let ix = spl_token::instruction::transfer(\n        token_program.key,\n        source.key,\n        destination.key,\n        authority.key,\n        &[],\n        1000,\n    )?;\n\n    invoke(&ix, &[source.clone(), destination.clone(), authority.clone()])?;\n\n    // Verify state changed as expected (for native SOL transfers)\n    // Note: For SPL tokens, you'd need to deserialize token accounts\n\n    Ok(())\n}\n```\n\n---\n\n## Manual Serialization Security\n\n### Borsh Serialization Pitfalls\n\n**Vulnerable:**\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Config {\n    pub value: u64,\n    pub items: Vec<Item>, // Variable length!\n}\n\npub fn deserialize_config(account: &AccountInfo) -> ProgramResult {\n    // No size validation - could run out of compute!\n    let config = Config::try_from_slice(&account.data.borrow())?;\n\n    // Attacker could create huge Vec causing OOM\n    for item in &config.items {\n        // Process item\n    }\n\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub const MAX_ITEMS: usize = 100;\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct Config {\n    pub value: u64,\n    pub item_count: u32,\n    pub items: Vec<Item>,\n}\n\nimpl Config {\n    pub fn from_account_info(account: &AccountInfo) -> Result<Self, ProgramError> {\n        let data = account.data.borrow();\n\n        // Validate minimum size\n        if data.len() < 8 + 4 {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        let config = Self::try_from_slice(&data)\n            .map_err(|_| ProgramError::InvalidAccountData)?;\n\n        // Validate item count matches actual length\n        if config.item_count as usize != config.items.len() {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        // Enforce maximum items\n        if config.items.len() > MAX_ITEMS {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        Ok(config)\n    }\n}\n```\n\n### Account Data Layout Validation\n\n**Best Practice:**\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct UserAccount {\n    pub discriminator: u64,\n    pub owner: Pubkey,\n    pub balance: u64,\n    pub created_at: i64,\n}\n\nimpl UserAccount {\n    pub const LEN: usize = 8 + 32 + 8 + 8;\n\n    pub fn from_account_info(account: &AccountInfo) -> Result<Self, ProgramError> {\n        let data = account.data.borrow();\n\n        // Exact size check prevents truncation attacks\n        if data.len() != Self::LEN {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        Self::try_from_slice(&data)\n            .map_err(|_| ProgramError::InvalidAccountData)\n    }\n\n    pub fn to_account_info(&self, account: &AccountInfo) -> ProgramResult {\n        let mut data = account.data.borrow_mut();\n\n        if data.len() != Self::LEN {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        self.serialize(&mut *data)\n            .map_err(|_| ProgramError::InvalidAccountData)\n    }\n}\n```\n\n---\n\n## Rent and Space Management\n\n### Rent Exemption Validation\n\n**Secure Pattern:**\n```rust\nuse solana_program::rent::Rent;\nuse solana_program::sysvar::Sysvar;\n\npub fn create_account(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    space: usize,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let new_account = next_account_info(account_info_iter)?;\n    let payer = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Get rent sysvar\n    let rent = Rent::get()?;\n\n    // Calculate required lamports for rent exemption\n    let required_lamports = rent.minimum_balance(space);\n\n    // Validate account has enough lamports\n    if new_account.lamports() < required_lamports {\n        return Err(ProgramError::AccountNotRentExempt);\n    }\n\n    // Additional validation: account is rent exempt\n    if !rent.is_exempt(new_account.lamports(), new_account.data_len()) {\n        return Err(ProgramError::AccountNotRentExempt);\n    }\n\n    Ok(())\n}\n```\n\n### Account Size Calculation\n\n**Vulnerable:**\n```rust\npub fn init_account(space: usize) -> ProgramResult {\n    // No validation - attacker could request huge space\n    let ix = solana_program::system_instruction::create_account(\n        &payer.key,\n        &new_account.key,\n        lamports,\n        space as u64, // Could overflow!\n        program_id,\n    );\n\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub const MIN_ACCOUNT_SIZE: usize = 128;\npub const MAX_ACCOUNT_SIZE: usize = 10_240; // 10KB\n\npub fn init_account(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    requested_space: usize,\n) -> ProgramResult {\n    // Validate space within reasonable bounds\n    if requested_space < MIN_ACCOUNT_SIZE || requested_space > MAX_ACCOUNT_SIZE {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Ensure space alignment\n    let space = requested_space\n        .checked_next_multiple_of(8)\n        .ok_or(ProgramError::InvalidAccountData)?;\n\n    let rent = Rent::get()?;\n    let lamports = rent.minimum_balance(space);\n\n    // Safe to create account\n    Ok(())\n}\n```\n\n---\n\n## Error Handling in Native Rust\n\n### Custom Error Types\n\n**Best Practice:**\n```rust\nuse thiserror::Error;\nuse solana_program::program_error::ProgramError;\n\n#[derive(Error, Debug, Copy, Clone)]\npub enum MyProgramError {\n    #[error(\"Invalid authority\")]\n    InvalidAuthority,\n\n    #[error(\"Insufficient balance\")]\n    InsufficientBalance,\n\n    #[error(\"Account already initialized\")]\n    AlreadyInitialized,\n\n    #[error(\"Arithmetic overflow\")]\n    ArithmeticOverflow,\n}\n\nimpl From<MyProgramError> for ProgramError {\n    fn from(e: MyProgramError) -> Self {\n        ProgramError::Custom(e as u32)\n    }\n}\n\npub fn process(accounts: &[AccountInfo]) -> Result<(), MyProgramError> {\n    let authority = next_account_info(&mut accounts.iter())\n        .map_err(|_| MyProgramError::InvalidAuthority)?;\n\n    if !authority.is_signer {\n        return Err(MyProgramError::InvalidAuthority);\n    }\n\n    Ok(())\n}\n```\n\n### Avoiding unwrap() and expect()\n\n**Vulnerable:**\n```rust\npub fn process(accounts: &[AccountInfo]) -> ProgramResult {\n    let account = accounts.get(0).unwrap(); // Panics if no accounts!\n    let data = account.data.borrow();\n    let value = u64::from_le_bytes(data[0..8].try_into().unwrap()); // Panics if not 8 bytes!\n\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn process(accounts: &[AccountInfo]) -> ProgramResult {\n    let account = accounts\n        .get(0)\n        .ok_or(ProgramError::NotEnoughAccountKeys)?;\n\n    let data = account.data.borrow();\n\n    if data.len() < 8 {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    let value = u64::from_le_bytes(\n        data[0..8]\n            .try_into()\n            .map_err(|_| ProgramError::InvalidAccountData)?\n    );\n\n    Ok(())\n}\n```\n\n---\n\n## Token Program Integration\n\n### Manual Token CPI Construction\n\n**Secure Pattern:**\n```rust\nuse spl_token::instruction as token_instruction;\n\npub fn transfer_tokens(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let source_token = next_account_info(account_info_iter)?;\n    let dest_token = next_account_info(account_info_iter)?;\n    let authority = next_account_info(account_info_iter)?;\n    let token_program = next_account_info(account_info_iter)?;\n\n    // Validate token program\n    if token_program.key != &spl_token::id() {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // Validate authority is signer\n    if !authority.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Build transfer instruction\n    let transfer_ix = token_instruction::transfer(\n        token_program.key,\n        source_token.key,\n        dest_token.key,\n        authority.key,\n        &[],\n        amount,\n    )?;\n\n    invoke(\n        &transfer_ix,\n        &[\n            source_token.clone(),\n            dest_token.clone(),\n            authority.clone(),\n            token_program.clone(),\n        ],\n    )?;\n\n    Ok(())\n}\n```\n\n### Token Account Validation\n\n**Secure Pattern:**\n```rust\nuse spl_token::state::Account as TokenAccount;\n\npub fn validate_token_account(\n    token_account_info: &AccountInfo,\n    expected_owner: &Pubkey,\n    expected_mint: &Pubkey,\n) -> Result<TokenAccount, ProgramError> {\n    // Verify owned by token program\n    if token_account_info.owner != &spl_token::id() {\n        return Err(ProgramError::IncorrectProgramId);\n    }\n\n    // Deserialize token account\n    let token_account = TokenAccount::unpack(&token_account_info.data.borrow())?;\n\n    // Validate owner\n    if &token_account.owner != expected_owner {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Validate mint\n    if &token_account.mint != expected_mint {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    Ok(token_account)\n}\n```\n\n---\n\n## Low-Level Security Patterns\n\n### Account Reloading After External Calls\n\n**Vulnerable:**\n```rust\npub fn vulnerable_pattern(accounts: &[AccountInfo]) -> ProgramResult {\n    let account = next_account_info(&mut accounts.iter())?;\n\n    let balance_before = account.lamports();\n\n    // External CPI call\n    invoke(&some_instruction, &[account.clone()])?;\n\n    // Account data not reloaded - still using stale reference!\n    let balance_after = account.lamports();\n\n    Ok(())\n}\n```\n\n**Secure:**\n```rust\npub fn secure_pattern(accounts: &[AccountInfo]) -> ProgramResult {\n    let account = next_account_info(&mut accounts.iter())?;\n\n    let balance_before = account.lamports();\n\n    // External CPI call\n    invoke(&some_instruction, &[account.clone()])?;\n\n    // AccountInfo automatically reflects changes - lamports(), data, etc.\n    // are fresh after CPI\n    let balance_after = account.lamports();\n\n    // But if you cached deserialized data, you must reload:\n    let fresh_data = MyData::from_account_info(account)?;\n\n    Ok(())\n}\n```\n\n### Clock and Timestamp Validation\n\n**Secure Pattern:**\n```rust\nuse solana_program::clock::Clock;\nuse solana_program::sysvar::Sysvar;\n\npub fn time_locked_operation(\n    accounts: &[AccountInfo],\n    unlock_timestamp: i64,\n) -> ProgramResult {\n    // Get clock sysvar\n    let clock = Clock::get()?;\n\n    // Validate unlock time has passed\n    if clock.unix_timestamp < unlock_timestamp {\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // Proceed with operation\n    Ok(())\n}\n```\n\n---\n\n## Native Rust Best Practices\n\n### Account Iteration Patterns\n\n**Best Practice:**\n```rust\npub fn process_instruction(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    instruction_data: &[u8],\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n\n    let authority = next_account_info(account_info_iter)?;\n    let config = next_account_info(account_info_iter)?;\n    let system_program = next_account_info(account_info_iter)?;\n\n    // Validate all expected accounts consumed\n    if account_info_iter.next().is_some() {\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Validate accounts\n    AccountValidation::new(authority).signer()?;\n    AccountValidation::new(config)\n        .owner(program_id)?\n        .writable()?;\n\n    Ok(())\n}\n```\n\n### State Management Patterns\n\n**Best Practice:**\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct ProgramState {\n    pub version: u8,\n    pub is_initialized: bool,\n    pub authority: Pubkey,\n    // Add new fields at the end for upgradability\n    pub feature_flags: u64,\n}\n\nimpl ProgramState {\n    pub const CURRENT_VERSION: u8 = 1;\n\n    pub fn initialize(authority: Pubkey) -> Self {\n        Self {\n            version: Self::CURRENT_VERSION,\n            is_initialized: true,\n            authority,\n            feature_flags: 0,\n        }\n    }\n\n    pub fn validate(&self) -> ProgramResult {\n        if !self.is_initialized {\n            return Err(ProgramError::UninitializedAccount);\n        }\n\n        if self.version != Self::CURRENT_VERSION {\n            return Err(ProgramError::InvalidAccountData);\n        }\n\n        Ok(())\n    }\n}\n```\n\n### Security.txt Integration\n\n**Best Practice:**\n```rust\n#[cfg(not(feature = \"no-entrypoint\"))]\nsolana_security_txt::security_txt! {\n    name: \"My Solana Program\",\n    project_url: \"https://github.com/myorg/myprogram\",\n    contacts: \"email:security@myorg.com,discord:myorg\",\n    policy: \"https://github.com/myorg/myprogram/blob/main/SECURITY.md\",\n    preferred_languages: \"en\",\n    source_code: \"https://github.com/myorg/myprogram\",\n    auditors: \"Auditor1, Auditor2\"\n}\n```\n\n---\n\n## Summary\n\nNative Rust Solana programs require meticulous manual validation of all security properties:\n\n1. **Always validate**: signer, owner, writable, key equality\n2. **Use discriminators** to prevent account type confusion\n3. **Store canonical bumps** and validate PDA derivation\n4. **Validate CPI targets** and propagate account flags correctly\n5. **Validate sizes** before deserialization\n6. **Check rent exemption** for all accounts\n7. **Use Result types** - never unwrap or expect\n8. **Validate token accounts** completely before use\n9. **Reload account data** after external calls if cached\n10. **Version your state** and validate initialization\n\nFor each pattern, create reusable validation functions and leverage Rust's type system to enforce security invariants at compile time where possible.\n",
        "solana/skills/solana-security/references/resources.md": "# Resources\n\nComprehensive collection of official documentation, security guides, audit reports, and learning materials for Solana development and security.\n\n## Official Documentation\n\n### Solana Core\n- [Solana Docs](https://solana.com/docs/) - Official Solana documentation\n- [Solana Cookbook](https://solana.com/developers/cookbook) - Recipes for common Solana tasks\n- [Solana Courses](https://solana.com/developers/courses/) - Official learning paths\n- [Program Examples](https://github.com/solana-developers/program-examples) - Multi-framework examples\n- [Developer Bootcamp 2024](https://github.com/solana-developers/developer-bootcamp-2024)\n\n### Anchor Framework\n- [Anchor Docs](https://www.anchor-lang.com/docs) - Official Anchor documentation\n- [Anchor Book](https://book.anchor-lang.com/) - Comprehensive Anchor guide\n- [Anchor by Example](https://examples.anchor-lang.com/) - Example programs\n- [Anchor Lang Docs](https://docs.rs/anchor-lang) - API documentation\n- [Anchor SPL Docs](https://docs.rs/anchor-spl) - SPL integration helpers\n\n### SPL Programs\n- [SPL Documentation](https://spl.solana.com/) - Solana Program Library docs\n- [Token Program](https://github.com/solana-program/token) - SPL Token source\n- [Token-2022](https://github.com/solana-program/token-2022) - Next-gen token program\n- [Associated Token Account](https://github.com/solana-program/associated-token-account)\n- [Token Metadata](https://github.com/solana-program/token-metadata)\n- [Metaplex Token Metadata](https://github.com/metaplex-foundation/mpl-token-metadata)\n\n## Security Resources\n\n### Curated Security Lists\n- [Awesome Solana Security (0xMacro)](https://github.com/0xMacro/awesome-solana-security) - **Actively maintained**, comprehensive resource list\n- [Rektoff Security Roadmap](https://github.com/Rektoff/Security-Roadmap-for-Solana-applications) - Full lifecycle security strategy\n- [SlowMist Best Practices](https://github.com/slowmist/solana-smart-contract-security-best-practices) - Common pitfalls with examples\n- [Ackee Solana Handbook](https://ackee.xyz/solana/book/latest/) - Comprehensive development guide\n\n### Security Guides & Articles\n- [Helius Security Guide](https://www.helius.dev/blog/a-hitchhikers-guide-to-solana-program-security) - Common vulnerabilities explained\n- [Neodyme Breakpoint Workshop](https://github.com/neodyme-labs/neodyme-breakpoint-workshop) - Hands-on security training\n- [Solana Security Course](https://solana.com/developers/courses/program-security) - Official security course\n- [Asymmetric Research CPI Vulnerabilities](https://blog.asymmetric.re/invocation-security-navigating-vulnerabilities-in-solana-cpis/)\n- [Ottersec Lamport Transfers](https://osec.io/blog/2025-05-14-king-of-the-sol) - SOL transfer vulnerabilities\n- [Infect3d Auditing Essentials](https://www.infect3d.xyz/blog/solana-quick-start)\n\n### Vulnerability Collections\n- [Urataps Audit Examples](https://github.com/urataps/solana-audit-examples) - Programs with vulnerabilities\n- [ImmuneBytes Attack Vectors](https://github.com/ImmuneBytes-Security-Audit/Blockchain-Attack-Vectors/tree/main/Solana%20Attack%20Vectors)\n- [Exvul Security Guide](https://exvul.com/rust-smart-contract-security-guide-in-solana/)\n- [Nirlin Advanced Vulnerabilities](https://substack.com/inbox/post/164534668)\n\n### Video Tutorials\n- [Zigtur Security Walkthrough](https://www.youtube.com/watch?v=xd6qfY-GDYY)\n- [M4rio Security Walkthrough](https://www.youtube.com/watch?v=q4z8tIi43lg)\n\n### Token-2022 Security\n- [Offside Token-2022 Part 1](https://blog.offside.io/p/token-2022-security-best-practices-part-1)\n- [Offside Token-2022 Part 2](https://blog.offside.io/p/token-2022-security-best-practices-part-2)\n- [Neodyme Token-2022 Security](https://neodyme.io/en/blog/token-2022)\n\n### Deep Dives & Research\n- [r0bre's 100 Daily Solana Tips](https://accretionxyz.substack.com/p/r0bres-100-daily-solana-tips)\n- [Accretion Hidden IDL Instructions](https://accretionxyz.substack.com/p/hidden-idl-instructions-and-how-to)\n- [Farouk ELALEM Under the Hood](https://ubermensch.blog/under-the-hood-of-solana-program-execution-from-rust-code-to-sbf-bytecode)\n- [Lucrative_Panda Security History](https://medium.com/@lucrativepanda/a-comprehensive-analysis-of-solanas-security-history-all-incidents-impacts-and-evolution-up-to-1b1564c7ddfe)\n\n## Essential Codebases to Study\n\nStudy these production codebases to learn security patterns:\n\n### Framework & Core Programs\n- [Anchor Framework](https://github.com/solana-foundation/anchor) - The framework itself\n- [Solana System Program](https://github.com/solana-program/system)\n- [SPL Token Program](https://github.com/solana-program/token)\n- [Token-2022](https://github.com/solana-program/token-2022)\n\n### Production Protocols\n- [Raydium AMM](https://github.com/raydium-io/raydium-cp-swap) - DEX protocol\n- [Kamino Lending](https://github.com/Kamino-Finance/klend) - Lending protocol\n- [Squads Multisig](https://github.com/Squads-Protocol/v4) - Multisig protocol\n\n## Audit Reports\n\nStudy real security audits to learn from actual vulnerabilities:\n\n### Code4rena\n- [Pump Science](https://code4rena.com/reports/2025-01-pump-science) - 2 High, 3 Medium\n\n### Sherlock\n- [Orderly](https://audits.sherlock.xyz/contests/524/report) - 2 High, 1 Medium\n- [WOOFi](https://audits.sherlock.xyz/contests/535/report) - 2 High, 3 Medium\n\n### Cantina\nContact `0xmorph` in Cantina Discord for read access:\n- [Grass](https://cantina.xyz/competitions/3211ee0d-133f-43a0-837e-8dc1ecfaa424) - 13 High, 6 Medium\n- [Olas](https://cantina.xyz/competitions/829164bf-7fba-4b84-a6b8-76652205bd97) - 2 High, 3 Medium\n- [Tensor](https://cantina.xyz/competitions/21787352-de2c-4a77-af09-cc0a250d1f04) - 5 High, 10 Medium\n- [ZetaChain](https://cantina.xyz/competitions/80a33cf0-ad69-4163-a269-d27756aacb5e) - 6 High, 27 Medium\n- [Inclusive Finance](https://cantina.xyz/competitions/3eff5a8f-b73a-4cfe-8c54-546b475548f0) - 45 High, 25 Medium\n- [Reserve Index](https://cantina.xyz/code/8b94becd-54e7-41cd-88e6-caae7becc76a) - 10 High, 11 Medium\n\n## Learning Paths\n\n### For EVM Developers\n- [RareSkills Solana Course](https://www.rareskills.io/solana-tutorial) - Ethereum to Solana\n- [0xkowloon Anchor for EVM](https://0xkowloon.gitbook.io/anchor-for-evm-developers)\n\n### For Rust Learners\n- [Rust Book](https://doc.rust-lang.org/book/)\n- [Rust by Example](https://doc.rust-lang.org/rust-by-example/index.html)\n\n### Native Rust (Non-Anchor)\n- [Solana Native Rust Docs](https://solana.com/docs/programs/rust)\n- [Native Development Course](https://solana.com/developers/courses/native-onchain-development)\n\n### Blueshift Challenges\n- [Blueshift Courses](https://learn.blueshift.gg/) - Anchor and Pinocchio\n\n## Tools\n\n### Development\n- [Solana Playground](https://beta.solpg.io/) - Browser-based IDE\n- [Rust Playground](https://play.rust-lang.org/) - Test Rust snippets\n\n### Security & Analysis\n- [Trident](https://github.com/Ackee-Blockchain/trident) - Fuzz testing framework\n- [Certora Prover](https://docs.certora.com/en/latest/docs/solana/index.html) - Formal verification\n- [Sec3 IDL Guesser](https://github.com/sec3-service/IDLGuesser) - Reverse engineer IDLs\n- [Anchor X-ray](https://github.com/crytic/anchorx-ray) - Visualize accounts (Trail of Bits)\n- [Anchor Version Detector](https://github.com/johnsaigle/anchor-version-detector) - Compatibility checker\n\n### Testing\n- [Anchor Test Framework](https://book.anchor-lang.com/anchor_in_depth/testing.html)\n- [Solana Test Validator](https://docs.solana.com/developing/test-validator)\n\n## CTFs & Practice\n\n### Capture The Flag\n- [Ackee Solana CTF](https://github.com/Ackee-Blockchain/Solana-Auditors-Bootcamp/tree/master/Capture-the-Flag)\n\n### Bootcamps\n- [Rektoff 6-Week Bootcamp](https://www.rektoff.xyz/bootcamp) - Free, Solana Foundation supported\n- [Ackee Auditors Bootcamp](https://ackee.xyz/solana-auditors-bootcamp)\n\n## Community & Support\n\n### Q&A Platforms\n- [Solana Stack Exchange](https://solana.stackexchange.com/)\n\n### Blogs & Newsletters\n- [Helius Blog](https://www.helius.dev/blog) - Frequent Solana content\n- [Pine Analytics Substack](https://substack.com/@pineanalytics1) - Protocol deep dives\n\n## Security Firms\n\nTop firms for Solana security audits:\n- [Runtime Verification](https://runtimeverification.com/)\n- [OtterSec](https://osec.io/)\n- [Neodyme](https://neodyme.io/en/)\n- [Sec3](https://www.sec3.dev/)\n- [Zellic](https://www.zellic.io/)\n- [Ackee Blockchain](https://ackee.xyz/)\n- [Hexens](https://hexens.io/)\n- [Trail of Bits](https://www.trailofbits.com/)\n- [Kudelski Security](https://kudelskisecurity.com/)\n- [Cantina](https://cantina.xyz/)\n- [Certora](https://www.certora.com/)\n- [Sherlock](https://www.sherlock.xyz/)\n\n## Version Information\n\n- Latest Anchor version (as of 2025): 0.30+\n- Recommended Solana CLI: Latest stable\n- Rust minimum version: 1.70+\n\n---\n\n**Note:** This is a curated collection from the Awesome Solana Security repository and other trusted sources. Resources are selected for their quality, maintenance status, and relevance to modern Solana development practices.\n",
        "solana/skills/solana-security/references/security-checklists.md": "# Security Checklists\n\nComprehensive validation checklists for Solana program security reviews.\n\n## Account Validation Checklist\n\nFor every account in every instruction:\n\n- [ ] **Signer validation**: Uses `Signer<'info>` or `is_signer` check when needed\n- [ ] **Owner validation**: Uses `#[account(owner = ...)]` or manual owner check\n- [ ] **Writable checks**: Properly marked `mut` when account data will be modified\n- [ ] **Account initialization**: Checks if account is initialized before use\n- [ ] **PDA validation**: Validates seeds and uses canonical bump\n- [ ] **Discriminator check**: For `AccountLoader`, validates account type\n- [ ] **Account relationships**: Uses `has_one` for related accounts\n\n```rust\n// Complete account validation example\n#[derive(Accounts)]\npub struct SecureInstruction<'info> {\n    #[account(\n        mut,\n        has_one = authority,  // Relationship validation\n        seeds = [b\"vault\", authority.key().as_ref()],\n        bump,  // Canonical bump\n    )]\n    pub vault: Account<'info, Vault>,\n\n    pub authority: Signer<'info>,  // Signer required\n\n    #[account(\n        mut,\n        constraint = token_account.owner == authority.key(),  // Custom validation\n    )]\n    pub token_account: Account<'info, TokenAccount>,\n\n    pub token_program: Program<'info, Token>,  // Program validation\n}\n```\n\n## Arithmetic Safety Checklist\n\nFor all mathematical operations:\n\n- [ ] **Addition**: Uses `checked_add()` instead of `+`\n- [ ] **Subtraction**: Uses `checked_sub()` instead of `-`\n- [ ] **Multiplication**: Uses `checked_mul()` instead of `*`\n- [ ] **Division**: Uses `checked_div()` instead of `/`\n- [ ] **Division by zero**: Validates divisor is non-zero\n- [ ] **Precision loss**: Uses `try_floor_u64()` instead of `try_round_u64()` to prevent arbitrage\n- [ ] **Avoid saturating**: Does not use `saturating_*` methods (they hide errors)\n- [ ] **Proper error handling**: All arithmetic wrapped in `ok_or(error)?`\n\n```rust\n// Secure arithmetic examples\nlet total = balance\n    .checked_add(amount)\n    .ok_or(ErrorCode::Overflow)?;\n\nlet share = total\n    .checked_div(denominator)\n    .ok_or(ErrorCode::DivisionByZero)?;\n\n// For Decimal types (token amounts)\nlet liquidity = Decimal::from(collateral_amount)\n    .try_div(rate)?\n    .try_floor_u64()?;  // Not try_round_u64()!\n```\n\n## PDA and Account Security Checklist\n\n- [ ] **Canonical bump**: PDAs use `bump` in seeds constraint (not hardcoded)\n- [ ] **Unique seeds**: Seeds include unique identifier (user pubkey, mint, etc.)\n- [ ] **No duplicate accounts**: Same account not used twice as mutable\n- [ ] **Init vs init_if_needed**: Uses `init` with proper validation, not `init_if_needed`\n- [ ] **has_one constraints**: Related accounts validated with `has_one`\n- [ ] **Custom constraints**: Complex validation uses `constraint` expression\n- [ ] **Seed collision**: Seeds designed to prevent collisions\n\n```rust\n// Secure PDA patterns\n#[account(\n    init,\n    payer = authority,\n    space = 8 + UserAccount::INIT_SPACE,\n    seeds = [\n        b\"user\",\n        authority.key().as_ref(),  // Unique to user\n        mint.key().as_ref(),        // Unique to mint\n    ],\n    bump\n)]\npub user_account: Account<'info, UserAccount>,\n```\n\n## CPI Security Checklist\n\nFor all Cross-Program Invocations:\n\n- [ ] **Program validation**: Target program is validated (uses `Program<'info, T>`)\n- [ ] **Signer seeds**: PDA signers pass seeds correctly in `invoke_signed`\n- [ ] **Return value checking**: CPI success doesn't guarantee correct state\n- [ ] **Account reloading**: Reload accounts after CPI that may modify them\n- [ ] **No arbitrary CPI**: Program account is not user-controlled\n- [ ] **Privilege escalation**: CPI doesn't grant unexpected permissions\n\n```rust\n// Secure CPI pattern\n#[derive(Accounts)]\npub struct SecureCPI<'info> {\n    pub token_program: Program<'info, Token>,  // Type-validated\n    // ... other accounts\n}\n\npub fn secure_cpi(ctx: Context<SecureCPI>) -> Result<()> {\n    // CPI with validated program\n    token::transfer(\n        CpiContext::new(\n            ctx.accounts.token_program.to_account_info(),\n            Transfer {\n                from: ctx.accounts.from.to_account_info(),\n                to: ctx.accounts.to.to_account_info(),\n                authority: ctx.accounts.authority.to_account_info(),\n            },\n        ),\n        amount,\n    )?;\n\n    // Reload account after CPI\n    ctx.accounts.from.reload()?;\n\n    // Validate expected state\n    require!(\n        ctx.accounts.from.amount == expected_amount,\n        ErrorCode::InvalidState\n    );\n\n    Ok(())\n}\n```\n\n## Oracle and External Data Checklist\n\nFor Pyth, Switchboard, or other oracles:\n\n- [ ] **Oracle status**: Validates oracle is in valid state (Trading status for Pyth)\n- [ ] **Price staleness**: Checks timestamp is recent enough\n- [ ] **Oracle owner**: Validates oracle account owner is correct program\n- [ ] **Confidence interval**: For Pyth, checks confidence is acceptable\n- [ ] **Price validity**: Validates price is within reasonable bounds\n- [ ] **Fallback handling**: Has strategy for oracle failure\n\n```rust\n// Pyth oracle validation\npub fn validate_pyth_price(\n    pyth_account: &AccountInfo,\n    clock: &Clock,\n) -> Result<i64> {\n    // Validate owner\n    require_keys_eq!(\n        *pyth_account.owner,\n        PYTH_PROGRAM_ID,\n        ErrorCode::InvalidOracle\n    );\n\n    let price_data = pyth_account.try_borrow_data()?;\n    let price_feed = load_price_feed_from_account_info(pyth_account)?;\n\n    // Check status\n    require!(\n        price_feed.agg.status == PriceStatus::Trading,\n        ErrorCode::InvalidOracleStatus\n    );\n\n    // Check staleness (e.g., max 60 seconds old)\n    let max_age = 60;\n    require!(\n        clock.unix_timestamp - price_feed.agg.publish_time <= max_age,\n        ErrorCode::StalePrice\n    );\n\n    // Check confidence (example: max 1% of price)\n    let confidence_threshold = price_feed.agg.price / 100;\n    require!(\n        price_feed.agg.conf <= confidence_threshold as u64,\n        ErrorCode::OracleConfidenceTooLow\n    );\n\n    Ok(price_feed.agg.price)\n}\n```\n\n## Token Program Security Checklist\n\n### SPL Token Checks\n\n- [ ] **ATA validation**: Associated Token Accounts validated correctly\n- [ ] **Mint authority**: Proper checks on mint authority for minting operations\n- [ ] **Freeze authority**: Handles frozen accounts appropriately\n- [ ] **Delegate handling**: Resets delegate when needed\n- [ ] **Close authority**: Resets close authority on owner change\n\n### Token-2022 Specific Checks\n\n- [ ] **Transfer hooks**: Handles transfer hook extensions correctly\n- [ ] **Extension data**: Validates all active extensions\n- [ ] **Confidential transfers**: Properly handles confidential transfer extension\n- [ ] **Transfer fees**: Respects transfer fee extension\n- [ ] **Permanent delegate**: Checks for permanent delegate extension\n- [ ] **Additional rent**: Accounts for extension rent requirements\n\n```rust\n// Token-2022 with extensions\nuse spl_token_2022::extension::{\n    BaseStateWithExtensions,\n    StateWithExtensions,\n};\n\npub fn safe_token_2022_transfer(\n    /* accounts */\n) -> Result<()> {\n    // Check for transfer hook\n    let mint_data = mint.try_borrow_data()?;\n    let mint_with_extensions = StateWithExtensions::<Mint>::unpack(&mint_data)?;\n\n    if let Ok(transfer_hook) = mint_with_extensions.get_extension::<TransferHook>() {\n        // Handle transfer hook properly\n        // ... transfer hook logic\n    }\n\n    // Check for transfer fee\n    if let Ok(transfer_fee_config) = mint_with_extensions.get_extension::<TransferFeeConfig>() {\n        // Calculate and handle fees\n        // ... fee logic\n    }\n\n    // Proceed with transfer\n    Ok(())\n}\n```\n\n## Architecture Review Checklist\n\n- [ ] **PDA design**: PDAs used appropriately vs keypair accounts\n- [ ] **Account space**: Space calculation uses `InitSpace` derive\n- [ ] **Error handling**: Custom errors with descriptive messages\n- [ ] **Event emission**: Critical state changes emit events\n- [ ] **Rent exemption**: All accounts are rent-exempt\n- [ ] **Transaction size**: Stays within ~1232 byte limit\n- [ ] **Compute budget**: Optimized to stay under compute limits\n- [ ] **Upgradeability**: Considers upgrade path and account versioning\n\n## Testing Checklist\n\n- [ ] **Unit tests**: Each instruction has unit tests\n- [ ] **Fuzz tests**: Arithmetic operations have fuzz tests (Trident)\n- [ ] **Integration tests**: Realistic multi-instruction scenarios\n- [ ] **Negative tests**: Tests for expected failures\n- [ ] **PDA tests**: Tests for seed collisions\n- [ ] **Edge cases**: Zero amounts, max values, overflow boundaries\n- [ ] **Concurrency**: Tests for transaction ordering issues\n- [ ] **Devnet testing**: Deployed and tested on devnet\n\n```rust\n// Example test structure\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_normal_case() {\n        // Test expected behavior\n    }\n\n    #[test]\n    #[should_panic(expected = \"Overflow\")]\n    fn test_overflow() {\n        // Test arithmetic overflow protection\n    }\n\n    #[test]\n    fn test_unauthorized_access() {\n        // Test fails with wrong signer\n    }\n\n    #[test]\n    fn test_edge_case_zero_amount() {\n        // Test zero amount handling\n    }\n}\n```\n",
        "solana/skills/solana-security/references/security-fundamentals.md": "# Solana Program Security & Validation\n\nThis reference provides comprehensive security guidance for native Rust Solana program development, covering validation patterns, common vulnerabilities, and defensive programming practices.\n\n## Table of Contents\n\n1. [Security Mindset](#security-mindset)\n2. [Core Validation Patterns](#core-validation-patterns)\n3. [Common Vulnerabilities](#common-vulnerabilities)\n4. [Input Validation](#input-validation)\n5. [State Management Security](#state-management-security)\n6. [Arithmetic Safety](#arithmetic-safety)\n7. [Re-entrancy Protection](#re-entrancy-protection)\n8. [Security Checklist](#security-checklist)\n\n---\n\n## Security Mindset\n\n### Think Like an Attacker\n\n**The fundamental principle of secure programming: ask \"How do I break this?\"**\n\nPresented at Breakpoint 2021 by [Neodyme](https://workshop.neodyme.io/), this mindset shift is critical:\n\n- **Don't just test expected functionality** - explore how it can be broken\n- **All programs can be exploited** - the goal is to make it as difficult as possible\n- **You control nothing** - once deployed, you can't control what transactions are sent\n- **Assume malicious input** - every account, every parameter, every edge case\n\n### The Harsh Reality\n\n```\n┌─────────────────────────────────────────┐\n│ Your Program (Deployed)                 │\n├─────────────────────────────────────────┤\n│ • No control over incoming transactions │\n│ • No control over accounts passed in    │\n│ • No control over instruction data      │\n│ • No control over timing                │\n└─────────────────────────────────────────┘\n           ▲            ▲            ▲\n           │            │            │\n     Legitimate    Malicious     Buggy\n        User        Attacker     Client\n```\n\n**Your only control:** How your program handles inputs.\n\n### Security is Not Optional\n\n**Example Impact:**\n\nWithout proper validation, a simple \"update note\" function becomes:\n- ❌ Anyone can update anyone's notes\n- ❌ Drain program funds\n- ❌ Corrupt global state\n- ❌ Brick the entire program\n\n**With validation:**\n- ✅ Only note author can update\n- ✅ Funds are protected\n- ✅ State remains consistent\n- ✅ Program operates as intended\n\n---\n\n## Core Validation Patterns\n\n### 1. Signer Checks\n\n**Purpose:** Verify that an account signed the transaction, authorizing the operation.\n\n**When Required:**\n- Transferring funds from an account\n- Modifying user-specific data\n- Any privileged operation\n\n**Pattern:**\n\n```rust\nuse solana_program::{\n    account_info::AccountInfo,\n    entrypoint::ProgramResult,\n    program_error::ProgramError,\n    msg,\n};\n\npub fn check_signer(account: &AccountInfo) -> ProgramResult {\n    if !account.is_signer {\n        msg!(\"Missing required signature\");\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n    Ok(())\n}\n```\n\n**Real-World Example:**\n\n```rust\npub fn update_user_profile(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    new_name: String,\n) -> ProgramResult {\n    let account_info_iter = &mut accounts.iter();\n    let user = next_account_info(account_info_iter)?;\n    let profile_pda = next_account_info(account_info_iter)?;\n\n    // CRITICAL: Verify user signed the transaction\n    if !user.is_signer {\n        msg!(\"User must sign to update profile\");\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    // Validate PDA belongs to this user\n    let (expected_pda, _) = Pubkey::find_program_address(\n        &[b\"profile\", user.key.as_ref()],\n        program_id,\n    );\n\n    if expected_pda != *profile_pda.key {\n        msg!(\"Profile PDA doesn't match user\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Safe to update\n    let mut profile = UserProfile::try_from_slice(&profile_pda.data.borrow())?;\n    profile.name = new_name;\n    profile.serialize(&mut &mut profile_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n### 2. Ownership Checks\n\n**Purpose:** Verify an account is owned by the expected program.\n\n**When Required:**\n- Before reading/writing account data\n- When validating PDAs\n- Before performing any account-specific operations\n\n**Pattern:**\n\n```rust\npub fn check_ownership(\n    account: &AccountInfo,\n    expected_owner: &Pubkey,\n) -> ProgramResult {\n    if account.owner != expected_owner {\n        msg!(\"Account owner mismatch\");\n        return Err(ProgramError::IllegalOwner);\n    }\n    Ok(())\n}\n```\n\n**Common Use Cases:**\n\n```rust\n// 1. Verify program owns its PDA\nif note_pda.owner != program_id {\n    msg!(\"Note account not owned by this program\");\n    return Err(ProgramError::IllegalOwner);\n}\n\n// 2. Verify account owned by System Program (user wallet)\nuse solana_program::system_program;\n\nif wallet.owner != &system_program::ID {\n    msg!(\"Expected a system account (wallet)\");\n    return Err(ProgramError::IllegalOwner);\n}\n\n// 3. Verify account owned by Token Program\nuse spl_token::ID as TOKEN_PROGRAM_ID;\n\nif token_account.owner != &TOKEN_PROGRAM_ID {\n    msg!(\"Expected a token account\");\n    return Err(ProgramError::IllegalOwner);\n}\n```\n\n### 3. PDA Validation\n\n**Purpose:** Ensure a provided PDA matches the expected derivation.\n\n**Critical for Security:** Multiple bumps can derive different PDAs. Always use canonical bump.\n\n**Pattern:**\n\n```rust\npub fn validate_pda(\n    pda_account: &AccountInfo,\n    seeds: &[&[u8]],\n    program_id: &Pubkey,\n) -> Result<u8, ProgramError> {\n    // Derive expected PDA with canonical bump\n    let (expected_pda, bump_seed) = Pubkey::find_program_address(seeds, program_id);\n\n    // Validate match\n    if expected_pda != *pda_account.key {\n        msg!(\"Invalid PDA derivation\");\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    Ok(bump_seed)\n}\n```\n\n**Complete Validation:**\n\n```rust\npub fn validate_user_vault(\n    program_id: &Pubkey,\n    user: &AccountInfo,\n    vault_pda: &AccountInfo,\n) -> ProgramResult {\n    // 1. Derive expected PDA\n    let (expected_pda, _bump) = Pubkey::find_program_address(\n        &[b\"vault\", user.key.as_ref()],\n        program_id,\n    );\n\n    // 2. Validate address match\n    if expected_pda != *vault_pda.key {\n        msg!(\"Vault PDA seeds don't match\");\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // 3. Validate ownership\n    if vault_pda.owner != program_id {\n        msg!(\"Vault not owned by program\");\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    // 4. Validate initialization\n    let vault_data = VaultAccount::try_from_slice(&vault_pda.data.borrow())?;\n    if !vault_data.is_initialized {\n        msg!(\"Vault not initialized\");\n        return Err(ProgramError::UninitializedAccount);\n    }\n\n    Ok(())\n}\n```\n\n### 4. Initialization Checks\n\n**Purpose:** Prevent re-initialization or use of uninitialized accounts.\n\n**Pattern: Discriminator Field**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AccountData {\n    pub is_initialized: bool,\n    // ... other fields\n}\n\n// On creation - ensure NOT initialized\nif account_data.is_initialized {\n    msg!(\"Account already initialized\");\n    return Err(ProgramError::AccountAlreadyInitialized);\n}\n\naccount_data.is_initialized = true;\n\n// On update - ensure IS initialized\nif !account_data.is_initialized {\n    msg!(\"Account not initialized\");\n    return Err(ProgramError::UninitializedAccount);\n}\n```\n\n**Advanced: Enum Discriminator**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize, PartialEq)]\npub enum AccountState {\n    Uninitialized,\n    Initialized,\n    Frozen,\n    Closed,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct GameAccount {\n    pub state: AccountState,\n    pub player: Pubkey,\n    pub score: u64,\n}\n\n// Validation\nlet account = GameAccount::try_from_slice(&account_info.data.borrow())?;\n\nmatch account.state {\n    AccountState::Uninitialized => {\n        msg!(\"Account not initialized\");\n        return Err(ProgramError::UninitializedAccount);\n    }\n    AccountState::Frozen => {\n        msg!(\"Account is frozen\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n    AccountState::Closed => {\n        msg!(\"Account is closed\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n    AccountState::Initialized => {\n        // Proceed\n    }\n}\n```\n\n### 5. Account Type Validation\n\n**Purpose:** Ensure account contains the expected data structure.\n\n**Pattern: Type Discriminator**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize, PartialEq)]\n#[repr(u8)]\npub enum AccountType {\n    Uninitialized = 0,\n    UserProfile = 1,\n    GameState = 2,\n    Leaderboard = 3,\n}\n\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct GenericAccount {\n    pub account_type: AccountType,\n    // ... rest of data varies by type\n}\n\n// Validation\npub fn validate_account_type(\n    account_info: &AccountInfo,\n    expected_type: AccountType,\n) -> ProgramResult {\n    let account = GenericAccount::try_from_slice(&account_info.data.borrow())?;\n\n    if account.account_type != expected_type {\n        msg!(\"Unexpected account type\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    Ok(())\n}\n```\n\n### 6. Writable Validation\n\n**Purpose:** Ensure accounts that need modification are marked writable.\n\n**Pattern:**\n\n```rust\npub fn check_writable(account: &AccountInfo) -> ProgramResult {\n    if !account.is_writable {\n        msg!(\"Account must be writable\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n    Ok(())\n}\n```\n\n**Note:** Runtime enforces this, but explicit checks improve clarity and error messages.\n\n---\n\n## Common Vulnerabilities\n\n### 1. Missing Signer Check\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - no signer check\npub fn withdraw_funds(\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let user = &accounts[0];\n    let vault = &accounts[1];\n\n    // Anyone can call this to withdraw anyone's funds!\n    **user.lamports.borrow_mut() += amount;\n    **vault.lamports.borrow_mut() -= amount;\n\n    Ok(())\n}\n```\n\n**Exploit:**\n```\nAttacker creates transaction:\n- Passes victim's account as user\n- Drains vault to victim's account\n- Profits by intercepting the transaction or social engineering\n```\n\n**Fix:**\n\n```rust\n// ✅ SECURE - with signer check\npub fn withdraw_funds(\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let user = &accounts[0];\n    let vault = &accounts[1];\n\n    if !user.is_signer {\n        return Err(ProgramError::MissingRequiredSignature);\n    }\n\n    **user.lamports.borrow_mut() += amount;\n    **vault.lamports.borrow_mut() -= amount;\n\n    Ok(())\n}\n```\n\n### 2. Missing Ownership Check\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - no ownership check\npub fn update_score(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    new_score: u64,\n) -> ProgramResult {\n    let player_account = &accounts[0];\n\n    // Could be ANY account with matching data structure!\n    let mut player = PlayerData::try_from_slice(&player_account.data.borrow())?;\n    player.score = new_score;\n    player.serialize(&mut &mut player_account.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**Exploit:**\n```\nAttacker creates a fake account:\n- Owned by attacker's program\n- Has same data structure\n- Passes it to victim program\n- Victim program modifies attacker's account!\n```\n\n**Fix:**\n\n```rust\n// ✅ SECURE - with ownership check\npub fn update_score(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    new_score: u64,\n) -> ProgramResult {\n    let player_account = &accounts[0];\n\n    // Verify ownership\n    if player_account.owner != program_id {\n        return Err(ProgramError::IllegalOwner);\n    }\n\n    let mut player = PlayerData::try_from_slice(&player_account.data.borrow())?;\n    player.score = new_score;\n    player.serialize(&mut &mut player_account.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n### 3. PDA Substitution Attack\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - accepts any PDA\npub fn claim_reward(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let reward_pda = &accounts[1];\n\n    // No PDA validation!\n    let mut reward = RewardData::try_from_slice(&reward_pda.data.borrow())?;\n    reward.claimed = true;\n    reward.serialize(&mut &mut reward_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**Exploit:**\n```\nAttacker passes someone else's reward PDA:\n- Creates transaction with victim's reward PDA\n- Claims victim's rewards\n- Victim loses rewards\n```\n\n**Fix:**\n\n```rust\n// ✅ SECURE - validates PDA derivation\npub fn claim_reward(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let reward_pda = &accounts[1];\n\n    // Validate PDA belongs to this user\n    let (expected_pda, _) = Pubkey::find_program_address(\n        &[b\"reward\", user.key.as_ref()],\n        program_id,\n    );\n\n    if expected_pda != *reward_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    let mut reward = RewardData::try_from_slice(&reward_pda.data.borrow())?;\n    reward.claimed = true;\n    reward.serialize(&mut &mut reward_pda.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n### 4. Non-Canonical Bump\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - accepts user-provided bump\npub fn update_data(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    bump: u8,  // User provides bump!\n) -> ProgramResult {\n    let user = &accounts[0];\n    let data_pda = &accounts[1];\n\n    // Uses user's bump - could derive DIFFERENT PDA!\n    let derived_pda = Pubkey::create_program_address(\n        &[b\"data\", user.key.as_ref(), &[bump]],\n        program_id,\n    )?;\n\n    if derived_pda != *data_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Proceeds with potentially wrong PDA\n    // ...\n}\n```\n\n**Exploit:**\n```\nMultiple bumps derive different valid PDAs:\n- Canonical bump 254: User A's PDA\n- Bump 253: User B's PDA (also valid!)\n- Attacker uses bump 253 to access User B's data\n```\n\n**Fix:**\n\n```rust\n// ✅ SECURE - uses canonical bump only\npub fn update_data(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let data_pda = &accounts[1];\n\n    // Always use find_program_address (canonical bump)\n    let (expected_pda, _bump) = Pubkey::find_program_address(\n        &[b\"data\", user.key.as_ref()],\n        program_id,\n    );\n\n    if expected_pda != *data_pda.key {\n        return Err(ProgramError::InvalidSeeds);\n    }\n\n    // Safe - validated with canonical bump\n    // ...\n}\n```\n\n### 5. Type Cosplay Attack\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - assumes account type\npub fn admin_withdraw(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let admin_config = &accounts[0];\n\n    // No type validation!\n    let config = AdminConfig::try_from_slice(&admin_config.data.borrow())?;\n\n    // Proceeds assuming it's actually an AdminConfig\n    // ...\n}\n```\n\n**Exploit:**\n```\nAttacker creates fake account:\n- UserProfile with same memory layout as AdminConfig\n- First field happens to match admin pubkey format\n- Deserializes successfully as AdminConfig\n- Attacker gains admin privileges!\n```\n\n**Fix:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize)]\npub struct AdminConfig {\n    pub discriminator: [u8; 8],  // Type identifier\n    pub admin: Pubkey,\n    // ... other fields\n}\n\nconst ADMIN_CONFIG_DISCRIMINATOR: [u8; 8] = [1, 2, 3, 4, 5, 6, 7, 8];\n\n// ✅ SECURE - validates type\npub fn admin_withdraw(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let admin_config = &accounts[0];\n\n    let config = AdminConfig::try_from_slice(&admin_config.data.borrow())?;\n\n    // Validate discriminator\n    if config.discriminator != ADMIN_CONFIG_DISCRIMINATOR {\n        msg!(\"Invalid account type\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Safe - type validated\n    // ...\n}\n```\n\n### 6. Uninitialized Account Reuse\n\n**Vulnerability:**\n\n```rust\n// ❌ VULNERABLE - no initialization check\npub fn update_balance(\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let balance_account = &accounts[0];\n\n    let mut balance = BalanceData::try_from_slice(&balance_account.data.borrow())?;\n\n    // What if this account was never initialized?\n    // Default values could lead to undefined behavior\n    balance.amount += amount;\n\n    balance.serialize(&mut &mut balance_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n**Fix:**\n\n```rust\n// ✅ SECURE - checks initialization\npub fn update_balance(\n    accounts: &[AccountInfo],\n    amount: u64,\n) -> ProgramResult {\n    let balance_account = &accounts[0];\n\n    let mut balance = BalanceData::try_from_slice(&balance_account.data.borrow())?;\n\n    if !balance.is_initialized {\n        msg!(\"Account not initialized\");\n        return Err(ProgramError::UninitializedAccount);\n    }\n\n    balance.amount += amount;\n    balance.serialize(&mut &mut balance_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n---\n\n## Input Validation\n\n### Validate All Input Data\n\n**Never trust instruction data.** Always validate constraints.\n\n```rust\npub fn allocate_stat_points(\n    accounts: &[AccountInfo],\n    strength: u8,\n    agility: u8,\n    intelligence: u8,\n) -> ProgramResult {\n    let character_account = &accounts[0];\n    let mut character = Character::try_from_slice(&character_account.data.borrow())?;\n\n    // 1. Validate individual stat caps\n    let new_strength = character.strength.checked_add(strength)\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    if new_strength > 100 {\n        msg!(\"Strength cannot exceed 100\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // 2. Validate total points spent\n    let total_spent = (strength as u64)\n        .checked_add(agility as u64)\n        .and_then(|sum| sum.checked_add(intelligence as u64))\n        .ok_or(ProgramError::ArithmeticOverflow)?;\n\n    if total_spent > character.available_points {\n        msg!(\"Insufficient available points\");\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // 3. Safe to apply\n    character.strength = new_strength;\n    character.agility += agility;\n    character.intelligence += intelligence;\n    character.available_points -= total_spent;\n\n    character.serialize(&mut &mut character_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n### String Length Validation\n\n```rust\npub fn set_username(\n    accounts: &[AccountInfo],\n    username: String,\n) -> ProgramResult {\n    // Validate length\n    if username.len() < 3 {\n        msg!(\"Username too short (min 3 characters)\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    if username.len() > 20 {\n        msg!(\"Username too long (max 20 characters)\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // Validate characters (alphanumeric only)\n    if !username.chars().all(|c| c.is_alphanumeric()) {\n        msg!(\"Username must be alphanumeric\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    // Safe to use\n    // ...\n}\n```\n\n### Enum Validation\n\n```rust\n#[derive(BorshDeserialize)]\n#[repr(u8)]\npub enum Rarity {\n    Common = 0,\n    Uncommon = 1,\n    Rare = 2,\n    Epic = 3,\n    Legendary = 4,\n}\n\npub fn create_item(\n    accounts: &[AccountInfo],\n    rarity_value: u8,\n) -> ProgramResult {\n    // Validate enum range\n    if rarity_value > 4 {\n        msg!(\"Invalid rarity value\");\n        return Err(ProgramError::InvalidArgument);\n    }\n\n    let rarity: Rarity = unsafe {\n        std::mem::transmute(rarity_value)\n    };\n\n    // Safe to use\n    // ...\n}\n```\n\n---\n\n## State Management Security\n\n### Avoid Race Conditions\n\n**Problem:** Multiple transactions modifying shared state.\n\n**Solution:** Use account-level locking and atomic operations.\n\n```rust\npub fn claim_limited_reward(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let user = &accounts[0];\n    let global_pool = &accounts[1];\n    let user_claim = &accounts[2];\n\n    // Load global state\n    let mut pool = RewardPool::try_from_slice(&global_pool.data.borrow())?;\n\n    // Check availability\n    if pool.claimed >= pool.total_rewards {\n        msg!(\"No rewards remaining\");\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // Check user hasn't claimed\n    let mut claim = UserClaim::try_from_slice(&user_claim.data.borrow())?;\n    if claim.has_claimed {\n        msg!(\"User already claimed\");\n        return Err(ProgramError::Custom(0));\n    }\n\n    // Atomically update both accounts\n    pool.claimed += 1;\n    claim.has_claimed = true;\n\n    pool.serialize(&mut &mut global_pool.data.borrow_mut()[..])?;\n    claim.serialize(&mut &mut user_claim.data.borrow_mut()[..])?;\n\n    Ok(())\n}\n```\n\n**Note:** Solana's account locking prevents true race conditions within a single transaction, but be aware of state assumptions across multiple transactions.\n\n### Prevent State Corruption\n\n**Always validate state transitions:**\n\n```rust\n#[derive(BorshSerialize, BorshDeserialize, PartialEq)]\npub enum GameState {\n    NotStarted,\n    InProgress,\n    Finished,\n}\n\npub fn start_game(\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let game_account = &accounts[0];\n    let mut game = Game::try_from_slice(&game_account.data.borrow())?;\n\n    // Validate current state\n    if game.state != GameState::NotStarted {\n        msg!(\"Game already started or finished\");\n        return Err(ProgramError::InvalidAccountData);\n    }\n\n    // Transition state\n    game.state = GameState::InProgress;\n    game.start_time = Clock::get()?.unix_timestamp;\n\n    game.serialize(&mut &mut game_account.data.borrow_mut()[..])?;\n    Ok(())\n}\n```\n\n---\n\n## Arithmetic Safety\n\n### Always Use Checked Math\n\n**Rust default:** Integer overflow/underflow panics in debug, wraps in release.\n\n**Solana requirement:** Use checked operations to prevent wrapping.\n\n```rust\n// ❌ DANGEROUS - can overflow/underflow\nlet total = a + b;\nlet remaining = balance - withdrawal;\n\n// ✅ SAFE - returns error on overflow/underflow\nlet total = a.checked_add(b)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n\nlet remaining = balance.checked_sub(withdrawal)\n    .ok_or(ProgramError::InsufficientFunds)?;\n```\n\n### Common Checked Operations\n\n```rust\n// Addition\nlet sum = a.checked_add(b)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n\n// Subtraction\nlet diff = a.checked_sub(b)\n    .ok_or(ProgramError::InsufficientFunds)?;\n\n// Multiplication\nlet product = a.checked_mul(b)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n\n// Division\nlet quotient = a.checked_div(b)\n    .ok_or(ProgramError::InvalidArgument)?;  // b could be 0\n\n// Power\nlet power = base.checked_pow(exponent)\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n### Compound Operations\n\n```rust\n// Calculate: (a + b) * c / d\nlet result = a.checked_add(b)\n    .and_then(|sum| sum.checked_mul(c))\n    .and_then(|product| product.checked_div(d))\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n### Precision Loss\n\n**Be careful with division:**\n\n```rust\n// ❌ Loses precision\nlet fee = amount / 100;  // 1.5% becomes 1%\n\n// ✅ Better - multiply first, then divide\nlet fee = amount.checked_mul(15)\n    .and_then(|v| v.checked_div(1000))\n    .ok_or(ProgramError::ArithmeticOverflow)?;\n```\n\n---\n\n## Re-entrancy Protection\n\n### Solana's Built-in Protection\n\n**Good news:** Solana provides strong protection against traditional re-entrancy:\n\n- **Account locking:** Accounts are locked during transaction execution\n- **No concurrent modification:** Same account can't be modified by multiple instructions simultaneously\n- **Atomic transactions:** Either all instructions succeed or all fail\n\n### Residual Risks\n\n**Cross-program state assumptions:**\n\n```rust\n// ❌ RISKY - state can change between checks\npub fn risky_operation(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let vault = &accounts[0];\n    let mut vault_data = VaultData::try_from_slice(&vault.data.borrow())?;\n\n    // Check balance\n    let balance = **vault.lamports.borrow();\n    if balance < 1000 {\n        return Err(ProgramError::InsufficientFunds);\n    }\n\n    // CPI that might modify vault\n    invoke(&some_instruction, accounts)?;\n\n    // Balance might have changed!\n    // Don't rely on previous check\n    **vault.lamports.borrow_mut() -= 1000;  // Could underflow!\n\n    Ok(())\n}\n```\n\n**✅ Better:**\n\n```rust\npub fn safe_operation(\n    program_id: &Pubkey,\n    accounts: &[AccountInfo],\n) -> ProgramResult {\n    let vault = &accounts[0];\n\n    // CPI first\n    invoke(&some_instruction, accounts)?;\n\n    // Check and modify atomically\n    let balance = **vault.lamports.borrow();\n    let new_balance = balance.checked_sub(1000)\n        .ok_or(ProgramError::InsufficientFunds)?;\n\n    **vault.lamports.borrow_mut() = new_balance;\n\n    Ok(())\n}\n```\n\n---\n\n## Security Checklist\n\n### Pre-Deployment Checklist\n\n**Account Validation:**\n- ✅ All signers verified with `is_signer`\n- ✅ All account owners checked\n- ✅ All PDAs validated with canonical bump\n- ✅ All accounts checked for initialization\n- ✅ Account types validated (discriminators)\n- ✅ Writable accounts verified\n\n**Input Validation:**\n- ✅ All numeric inputs range-checked\n- ✅ All string inputs length-limited\n- ✅ All enum values validated\n- ✅ All business logic constraints enforced\n\n**Arithmetic:**\n- ✅ All additions use `checked_add`\n- ✅ All subtractions use `checked_sub`\n- ✅ All multiplications use `checked_mul`\n- ✅ All divisions check for zero\n- ✅ No unsafe casting that could overflow\n\n**State Management:**\n- ✅ State transitions validated\n- ✅ Initialization flags checked\n- ✅ No assumptions across CPI boundaries\n- ✅ Atomicity maintained\n\n**Error Handling:**\n- ✅ All errors properly propagated\n- ✅ Meaningful error messages\n- ✅ No silent failures\n- ✅ Proper cleanup on errors\n\n### Testing Checklist\n\n**Security Testing:**\n- ✅ Test with missing signers\n- ✅ Test with wrong account owners\n- ✅ Test with wrong PDAs (non-canonical bumps)\n- ✅ Test with uninitialized accounts\n- ✅ Test with re-initialized accounts\n- ✅ Test integer overflow/underflow\n- ✅ Test boundary conditions\n- ✅ Test with maximum values\n- ✅ Test with malicious input\n\n**Fuzzing:**\n- ✅ Random account combinations\n- ✅ Random instruction data\n- ✅ Random ordering\n- ✅ Edge case values\n\n---\n\n## Summary\n\n**Core Security Principles:**\n\n1. **Validate Everything** - Assume all inputs are malicious\n2. **Fail Fast** - Return errors immediately when validation fails\n3. **Use Checked Math** - Prevent integer overflow/underflow\n4. **Think Like an Attacker** - Ask \"How do I break this?\"\n5. **Test Malicious Cases** - Don't just test happy paths\n\n**The Three Pillars of Account Security:**\n\n```rust\n// 1. Signer Check\nif !account.is_signer {\n    return Err(ProgramError::MissingRequiredSignature);\n}\n\n// 2. Ownership Check\nif account.owner != expected_owner {\n    return Err(ProgramError::IllegalOwner);\n}\n\n// 3. PDA Validation (if applicable)\nlet (expected_pda, _) = Pubkey::find_program_address(&seeds, program_id);\nif expected_pda != *account.key {\n    return Err(ProgramError::InvalidSeeds);\n}\n```\n\n**Remember:** Once deployed, you have no control over what transactions are sent to your program. Your only defense is rigorous validation.\n\nSecurity is not a feature—it's a requirement.\n",
        "solana/skills/solana-security/references/vulnerability-patterns.md": "# Common Vulnerability Patterns\n\nDetailed examples of common Solana smart contract vulnerabilities with exploit scenarios and secure alternatives.\n\n## 1. Missing Signer Validation\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn withdraw(ctx: Context<Withdraw>, amount: u64) -> Result<()> {\n    // No check that caller is authorized!\n    let vault = &mut ctx.accounts.vault;\n    vault.balance -= amount;\n    Ok(())\n}\n\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(mut)]\n    pub vault: Account<'info, Vault>,\n    pub user: AccountInfo<'info>,  // Not a Signer!\n}\n```\n\n### Exploit Scenario\nAttacker can drain the vault by calling `withdraw` with any account as the `user` parameter. No signature verification means anyone can execute the instruction.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct Withdraw<'info> {\n    #[account(\n        mut,\n        has_one = authority,  // Ensures vault.authority == authority.key()\n    )]\n    pub vault: Account<'info, Vault>,\n    pub authority: Signer<'info>,  // Must sign transaction\n}\n```\n\n## 2. Integer Overflow/Underflow\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {\n    let vault = &mut ctx.accounts.vault;\n    vault.balance = vault.balance + amount;  // Can overflow!\n    Ok(())\n}\n```\n\n### Exploit Scenario\nIf `vault.balance = u64::MAX - 100` and `amount = 200`, the addition overflows and wraps to `99`, effectively stealing funds from the vault.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {\n    let vault = &mut ctx.accounts.vault;\n    vault.balance = vault\n        .balance\n        .checked_add(amount)\n        .ok_or(ErrorCode::Overflow)?;\n    Ok(())\n}\n```\n\n## 3. PDA Substitution Attack\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(mut)]\n    pub config: Account<'info, Config>,  // No PDA validation!\n\n    #[account(\n        mut,\n        seeds = [b\"vault\", config.key().as_ref()],  // Uses unvalidated config\n        bump\n    )]\n    pub vault: Account<'info, Vault>,\n}\n```\n\n### Exploit Scenario\nAttacker creates a fake `config` account with malicious settings. The `vault` PDA is derived from this fake config, potentially accessing wrong vault or bypassing security checks.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(\n        seeds = [b\"config\"],  // Global config PDA\n        bump,\n    )]\n    pub config: Account<'info, Config>,\n\n    #[account(\n        mut,\n        seeds = [b\"vault\", config.key().as_ref()],\n        bump\n    )]\n    pub vault: Account<'info, Vault>,\n}\n```\n\n## 4. Type Cosplay Attack\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\n#[account(mut)]\npub user: AccountLoader<'info, User>,  // Doesn't check discriminator!\n```\n\n### Exploit Scenario\nAttacker passes a `UserAdmin` account instead of `User`. Since `AccountLoader` doesn't check discriminators by default, the program treats the admin account as a regular user, potentially bypassing privilege checks.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[account(mut)]\npub user: Account<'info, User>,  // Enforces correct discriminator\n```\n\n## 5. Account Reloading Issues\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn complex_operation(ctx: Context<ComplexOp>) -> Result<()> {\n    let initial_balance = ctx.accounts.vault.balance;\n\n    // CPI that modifies vault\n    transfer_tokens(&ctx)?;\n\n    // Still using stale balance!\n    require!(\n        ctx.accounts.vault.balance >= initial_balance,\n        ErrorCode::InvalidBalance\n    );\n\n    Ok(())\n}\n```\n\n### Exploit Scenario\nThe `balance` value is cached from before the CPI. If the CPI modified the vault, the check uses stale data, potentially allowing invalid state transitions.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn complex_operation(ctx: Context<ComplexOp>) -> Result<()> {\n    transfer_tokens(&ctx)?;\n\n    // Reload account to get fresh data\n    ctx.accounts.vault.reload()?;\n\n    require!(\n        ctx.accounts.vault.balance >= expected_balance,\n        ErrorCode::InvalidBalance\n    );\n\n    Ok(())\n}\n```\n\n## 6. Improper Account Closing\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn close_account(ctx: Context<CloseAccount>) -> Result<()> {\n    **ctx.accounts.vault.to_account_info().lamports.borrow_mut() = 0;\n    // Data not zeroed, authority not reset!\n    Ok(())\n}\n```\n\n### Exploit Scenario\nAccount data remains accessible within the same transaction even after lamports are zeroed. Attacker can read sensitive data or reuse the account in unexpected ways.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct CloseAccount<'info> {\n    #[account(\n        mut,\n        close = receiver  // Properly closes: transfers lamports, zeros data\n    )]\n    pub vault: Account<'info, Vault>,\n    #[account(mut)]\n    pub receiver: SystemAccount<'info>,\n}\n```\n\n## 7. Missing Lamports Check\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn process(ctx: Context<Process>) -> Result<()> {\n    let data = ctx.accounts.user_data.load()?;  // Can read closed account!\n    // ... use data\n    Ok(())\n}\n```\n\n### Exploit Scenario\nAccount was closed earlier in the transaction but data is still readable. Processing closed account data can lead to inconsistent state or bypass business logic.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn process(ctx: Context<Process>) -> Result<()> {\n    require!(\n        **ctx.accounts.user_data.to_account_info().lamports.borrow() > 0,\n        ErrorCode::AccountClosed\n    );\n\n    let data = ctx.accounts.user_data.load()?;\n    // ... use data\n    Ok(())\n}\n```\n\n## 8. Arbitrary CPI\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\n#[derive(Accounts)]\npub struct ArbitraryCPI<'info> {\n    pub token_program: AccountInfo<'info>,  // Not validated!\n}\n\npub fn transfer(ctx: Context<ArbitraryCPI>) -> Result<()> {\n    invoke(\n        &transfer_instruction,\n        &[\n            ctx.accounts.token_program.clone(),  // Could be malicious!\n            // ...\n        ]\n    )?;\n    Ok(())\n}\n```\n\n### Exploit Scenario\nAttacker passes malicious program instead of real Token program. Malicious program can emit fake events, return success without transferring, or drain funds.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct SecureCPI<'info> {\n    pub token_program: Program<'info, Token>,  // Type-checked!\n}\n\n// Or manual validation\nrequire_keys_eq!(\n    *ctx.accounts.token_program.key,\n    spl_token::ID,\n    ErrorCode::InvalidTokenProgram\n);\n```\n\n## 9. Duplicate Mutable Accounts\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(mut)]\n    pub from: Account<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n}\n\npub fn transfer(ctx: Context<Transfer>, amount: u64) -> Result<()> {\n    ctx.accounts.from.amount -= amount;\n    ctx.accounts.to.amount += amount;  // Same account = double amount!\n    Ok(())\n}\n```\n\n### Exploit Scenario\nIf `from` and `to` are the same account, the user can double their balance by transferring to themselves.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct Transfer<'info> {\n    #[account(\n        mut,\n        constraint = from.key() != to.key() @ ErrorCode::SameAccount\n    )]\n    pub from: Account<'info, TokenAccount>,\n    #[account(mut)]\n    pub to: Account<'info, TokenAccount>,\n}\n```\n\n## 10. Bump Seed Canonicalization\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn init_vault(ctx: Context<InitVault>, bump: u8) -> Result<()> {\n    // Accepts any bump from user!\n    let seeds = &[b\"vault\", user.key().as_ref(), &[bump]];\n    // Multiple PDAs possible for same seeds!\n}\n```\n\n### Exploit Scenario\nAttacker can create multiple vault PDAs with different bumps for the same user, fragmenting state or confusing off-chain systems.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\n#[derive(Accounts)]\npub struct InitVault<'info> {\n    #[account(\n        init,\n        payer = user,\n        space = 8 + Vault::INIT_SPACE,\n        seeds = [b\"vault\", user.key().as_ref()],\n        bump  // Anchor derives and stores canonical bump automatically\n    )]\n    pub vault: Account<'info, Vault>,\n    #[account(mut)]\n    pub user: Signer<'info>,\n    pub system_program: Program<'info, System>,\n}\n```\n\n## 11. Missing Owner Check\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn read_data(ctx: Context<ReadData>) -> Result<()> {\n    let oracle_data = ctx.accounts.oracle.try_borrow_data()?;\n    // No check that oracle is owned by Pyth program!\n    let price = parse_price(&oracle_data)?;\n    Ok(())\n}\n```\n\n### Exploit Scenario\nAttacker creates fake oracle account owned by their own program, filled with manipulated price data. Program trusts the fake data.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn read_data(ctx: Context<ReadData>) -> Result<()> {\n    require_keys_eq!(\n        *ctx.accounts.oracle.owner,\n        PYTH_PROGRAM_ID,\n        ErrorCode::InvalidOracleOwner\n    );\n\n    let oracle_data = ctx.accounts.oracle.try_borrow_data()?;\n    let price = parse_price(&oracle_data)?;\n    Ok(())\n}\n```\n\n## 12. Precision Loss / Rounding Errors\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn calculate_shares(collateral: u64, rate: Decimal) -> Result<u64> {\n    Decimal::from(collateral)\n        .try_div(rate)?\n        .try_round_u64()  // Rounding can be exploited!\n}\n```\n\n### Exploit Scenario\nAttacker repeatedly deposits/withdraws small amounts. Rounding up gives slightly more shares each time, slowly draining the pool.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn calculate_shares(collateral: u64, rate: Decimal) -> Result<u64> {\n    Decimal::from(collateral)\n        .try_div(rate)?\n        .try_floor_u64()  // Always round down in user's favor\n}\n```\n\n## 13. Unchecked Error Returns\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\nspl_token::instruction::transfer(\n    token_program.key,\n    source.key,\n    destination.key,\n    authority.key,\n    &[],\n    amount,\n);  // Return value ignored!\n```\n\n### Exploit Scenario\nTransfer instruction fails silently but program continues as if it succeeded. State becomes inconsistent with actual token balances.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\ninvoke(\n    &spl_token::instruction::transfer(\n        token_program.key,\n        source.key,\n        destination.key,\n        authority.key,\n        &[],\n        amount,\n    )?,  // Propagates error\n    &[\n        source.clone(),\n        destination.clone(),\n        authority.clone(),\n    ],\n)?;\n\n// Or use Anchor's CPI helpers\ntoken::transfer(ctx, amount)?;\n```\n\n## 14. Init If Needed Vulnerability\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\n#[account(\n    init_if_needed,\n    payer = user,\n    space = 8 + Account::INIT_SPACE\n)]\npub user_account: Account<'info, UserAccount>,\n```\n\n### Exploit Scenario\nIf account already exists, initialization is skipped but existing data might be inconsistent or malicious. Can bypass initialization checks.\n\n### Secure Alternative\n```rust\n// ✅ SECURE - Explicit initialization\n#[account(\n    init,\n    payer = user,\n    space = 8 + Account::INIT_SPACE\n)]\npub user_account: Account<'info, UserAccount>,\n\n// Or if init_if_needed is truly needed, add validation\npub fn init_or_validate(ctx: Context<InitAccount>) -> Result<()> {\n    if ctx.accounts.user_account.is_initialized {\n        // Validate existing data\n        require!(\n            ctx.accounts.user_account.owner == ctx.accounts.user.key(),\n            ErrorCode::InvalidOwner\n        );\n    } else {\n        // Initialize new account\n        ctx.accounts.user_account.is_initialized = true;\n        ctx.accounts.user_account.owner = ctx.accounts.user.key();\n    }\n    Ok(())\n}\n```\n\n## 15. Stale Oracle Data\n\n### Vulnerability\n```rust\n// ❌ VULNERABLE\npub fn get_price(pyth_account: &AccountInfo) -> Result<i64> {\n    let price_feed = load_price_feed(pyth_account)?;\n    Ok(price_feed.agg.price)  // No staleness check!\n}\n```\n\n### Exploit Scenario\nOracle stopped updating hours ago due to network issues. Attacker exploits stale price to buy/sell at favorable outdated rates.\n\n### Secure Alternative\n```rust\n// ✅ SECURE\npub fn get_price(\n    pyth_account: &AccountInfo,\n    clock: &Clock\n) -> Result<i64> {\n    let price_feed = load_price_feed(pyth_account)?;\n\n    // Check publishing time\n    let max_age_seconds = 60;\n    require!(\n        clock.unix_timestamp - price_feed.agg.publish_time <= max_age_seconds,\n        ErrorCode::StaleOraclePrice\n    );\n\n    // Check status\n    require!(\n        price_feed.agg.status == PriceStatus::Trading,\n        ErrorCode::OracleNotTrading\n    );\n\n    Ok(price_feed.agg.price)\n}\n```\n",
        "styling-with-tailwind/skill/SKILL.md": "---\nname: styling-with-tailwind\ndescription: Creates UIs using Tailwind CSS utility classes and shadcn/ui patterns. Covers CSS variables with OKLCH colors, component variants with CVA, responsive design, dark mode, and Tailwind v4 features. Use when building interfaces with Tailwind, styling shadcn/ui components, implementing themes, or working with utility-first CSS.\n---\n\n# Styling with Tailwind CSS\n\nBuild accessible UIs using Tailwind utility classes and shadcn/ui component patterns.\n\n## Core Patterns\n\n### CSS Variables for Theming\n\nshadcn/ui uses semantic CSS variables mapped to Tailwind utilities:\n\n```css\n/* globals.css - Light mode */\n:root {\n  --background: oklch(1 0 0);\n  --foreground: oklch(0.145 0 0);\n  --primary: oklch(0.205 0 0);\n  --primary-foreground: oklch(0.985 0 0);\n  --muted: oklch(0.97 0 0);\n  --muted-foreground: oklch(0.556 0 0);\n  --border: oklch(0.922 0 0);\n  --radius: 0.5rem;\n}\n\n/* Dark mode */\n.dark {\n  --background: oklch(0.145 0 0);\n  --foreground: oklch(0.985 0 0);\n  --primary: oklch(0.922 0 0);\n  --primary-foreground: oklch(0.205 0 0);\n}\n\n/* Tailwind v4: Map variables */\n@theme inline {\n  --color-background: var(--background);\n  --color-foreground: var(--foreground);\n  --color-primary: var(--primary);\n}\n```\n\n**Usage in components:**\n```tsx\n// Background colors omit the \"-background\" suffix\n<div className=\"bg-primary text-primary-foreground\">\n<div className=\"bg-muted text-muted-foreground\">\n<div className=\"bg-destructive text-destructive-foreground\">\n```\n\n### Component Variants with CVA\n\nUse `class-variance-authority` for component variants:\n\n```tsx\nimport { cva } from \"class-variance-authority\"\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:opacity-50\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground shadow hover:bg-primary/90\",\n        destructive: \"bg-destructive text-destructive-foreground hover:bg-destructive/90\",\n        outline: \"border border-input bg-background hover:bg-accent\",\n        ghost: \"hover:bg-accent hover:text-accent-foreground\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2\",\n        sm: \"h-8 px-3 text-xs\",\n        lg: \"h-10 px-8\",\n        icon: \"size-9\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n\n// Usage\n<Button variant=\"outline\" size=\"sm\">Click me</Button>\n```\n\n### Responsive Design\n\nMobile-first breakpoints:\n\n```tsx\n// Stack on mobile, grid on tablet+\n<div className=\"grid gap-4 md:grid-cols-2 lg:grid-cols-4\">\n\n// Hide on mobile\n<div className=\"hidden md:block\">\n\n// Different layouts per breakpoint\n<div className=\"flex flex-col md:flex-row lg:gap-8\">\n  <aside className=\"w-full md:w-64\">\n  <main className=\"flex-1\">\n</div>\n\n// Responsive text sizes\n<h1 className=\"text-3xl md:text-4xl lg:text-5xl\">\n```\n\n### Dark Mode\n\n```tsx\n// Use dark: prefix for dark mode styles\n<div className=\"bg-white dark:bg-black text-black dark:text-white\">\n\n// Theme toggle component\n\"use client\"\nimport { Moon, Sun } from \"lucide-react\"\nimport { useTheme } from \"next-themes\"\n\nexport function ThemeToggle() {\n  const { theme, setTheme } = useTheme()\n\n  return (\n    <button onClick={() => setTheme(theme === \"dark\" ? \"light\" : \"dark\")}>\n      <Sun className=\"rotate-0 scale-100 dark:-rotate-90 dark:scale-0\" />\n      <Moon className=\"absolute rotate-90 scale-0 dark:rotate-0 dark:scale-100\" />\n    </button>\n  )\n}\n```\n\n## Common Component Patterns\n\n### Card\n\n```tsx\n<div className=\"rounded-xl border bg-card text-card-foreground shadow\">\n  <div className=\"flex flex-col space-y-1.5 p-6\">\n    <h3 className=\"font-semibold leading-none tracking-tight\">Title</h3>\n    <p className=\"text-sm text-muted-foreground\">Description</p>\n  </div>\n  <div className=\"p-6 pt-0\">Content</div>\n  <div className=\"flex items-center p-6 pt-0\">Footer</div>\n</div>\n```\n\n### Form Field\n\n```tsx\n<div className=\"space-y-2\">\n  <label className=\"text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70\">\n    Email\n  </label>\n  <input\n    type=\"email\"\n    className=\"flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-sm shadow-sm transition-colors placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50\"\n  />\n  <p className=\"text-sm text-muted-foreground\">Helper text</p>\n</div>\n```\n\n### Badge\n\n```tsx\nconst badgeVariants = cva(\n  \"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors\",\n  {\n    variants: {\n      variant: {\n        default: \"border-transparent bg-primary text-primary-foreground shadow\",\n        secondary: \"border-transparent bg-secondary text-secondary-foreground\",\n        destructive: \"border-transparent bg-destructive text-destructive-foreground\",\n        outline: \"text-foreground\",\n      },\n    },\n  }\n)\n```\n\n### Alert\n\n```tsx\n<div className=\"relative w-full rounded-lg border px-4 py-3 text-sm [&>svg]:absolute [&>svg]:left-4 [&>svg]:top-4 [&>svg+div]:translate-y-[-3px] [&:has(svg)]:pl-11\">\n  <AlertCircle className=\"size-4\" />\n  <div className=\"font-medium\">Alert Title</div>\n  <div className=\"text-sm text-muted-foreground\">Description</div>\n</div>\n```\n\n### Loading Skeleton\n\n```tsx\n<div className=\"space-y-2\">\n  <div className=\"h-4 w-[250px] animate-pulse rounded bg-muted\" />\n  <div className=\"h-4 w-[200px] animate-pulse rounded bg-muted\" />\n</div>\n```\n\n## Layout Patterns\n\n### Centered Layout\n\n```tsx\n<div className=\"flex min-h-screen items-center justify-center\">\n  <div className=\"w-full max-w-md space-y-8 p-8\">\n    {/* Content */}\n  </div>\n</div>\n```\n\n### Sidebar Layout\n\n```tsx\n<div className=\"flex h-screen\">\n  <aside className=\"w-64 border-r bg-muted/40\">Sidebar</aside>\n  <main className=\"flex-1 overflow-auto\">Content</main>\n</div>\n```\n\n### Dashboard Grid\n\n```tsx\n<div className=\"grid gap-4 md:grid-cols-2 lg:grid-cols-4\">\n  <Card className=\"col-span-2\">Wide card</Card>\n  <Card>Regular</Card>\n  <Card>Regular</Card>\n  <Card className=\"col-span-4\">Full width</Card>\n</div>\n```\n\n### Container with Max Width\n\n```tsx\n<div className=\"container mx-auto px-4 md:px-6 lg:px-8\">\n  <div className=\"max-w-2xl mx-auto\">\n    {/* Centered content */}\n  </div>\n</div>\n```\n\n## Accessibility Patterns\n\n### Focus Visible\n\n```tsx\n<button className=\"focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2\">\n```\n\n### Screen Reader Only\n\n```tsx\n<span className=\"sr-only\">Close dialog</span>\n```\n\n### Disabled States\n\n```tsx\n<button className=\"disabled:cursor-not-allowed disabled:opacity-50\" disabled>\n```\n\n### ARIA-friendly Alert\n\n```tsx\n<div role=\"alert\" className=\"rounded-lg border p-4\">\n  <div className=\"flex items-start gap-3\">\n    <AlertCircle className=\"size-5 text-destructive\" />\n    <div className=\"flex-1 space-y-1\">\n      <h5 className=\"font-medium\">Error</h5>\n      <p className=\"text-sm text-muted-foreground\">Message</p>\n    </div>\n  </div>\n</div>\n```\n\n## Tailwind v4 Features\n\n### Size Utility\n\n```tsx\n// New syntax (replaces w-* h-*)\n<div className=\"size-4\">\n<div className=\"size-8\">\n<div className=\"size-full\">\n```\n\n### @theme Directive\n\n```css\n/* Tailwind v4 syntax */\n@theme {\n  --color-primary: oklch(0.205 0 0);\n  --font-sans: \"Inter\", system-ui;\n}\n\n/* With CSS variables */\n@theme inline {\n  --color-primary: var(--primary);\n}\n```\n\n### Animation\n\n```css\n/* globals.css */\n@import \"tw-animate-css\";\n```\n\n```tsx\n<div className=\"animate-fade-in\">\n<div className=\"animate-slide-in-from-top\">\n<div className=\"animate-spin\">\n```\n\n### Tailwind v4.1 Features (April 2025)\n\n**Text Shadow:**\n```tsx\n// Subtle text shadows for depth\n<h1 className=\"text-shadow-sm text-4xl font-bold\">\n<h2 className=\"text-shadow-md text-2xl\">\n<div className=\"text-shadow-lg text-xl\">\n\n// Custom text shadows\n<div className=\"text-shadow-[0_2px_4px_rgb(0_0_0_/_0.1)]\">\n```\n\n**Mask Utilities:**\n```tsx\n// Gradient masks for fade effects\n<div className=\"mask-linear-to-b from-black to-transparent\">\n  Fades to transparent at bottom\n</div>\n\n// Image masks\n<div className=\"mask-[url('/mask.svg')]\">\n  Masked content\n</div>\n\n// Common patterns\n<div className=\"mask-radial-gradient\">Spotlight effect</div>\n```\n\n**Colored Drop Shadow:**\n```tsx\n// Brand-colored shadows\n<div className=\"drop-shadow-[0_4px_12px_oklch(0.488_0.243_264.376)]\">\n\n// Use with semantic colors\n<Button className=\"drop-shadow-lg drop-shadow-primary/50\">\n  Glowing button\n</Button>\n```\n\n**Overflow Wrap:**\n```tsx\n// Break long words\n<p className=\"overflow-wrap-anywhere\">\n  verylongwordthatneedstowrap\n</p>\n\n<p className=\"overflow-wrap-break-word\">\n  URLs and long strings\n</p>\n```\n\n## OKLCH Colors\n\nUse OKLCH for better color perception:\n\n```css\n/* Format: oklch(lightness chroma hue) */\n--primary: oklch(0.205 0 0);\n--destructive: oklch(0.577 0.245 27.325);\n\n/* Benefits: perceptually uniform, consistent lightness across hues */\n```\n\n## Base Color Palettes\n\nshadcn/ui provides multiple base colors:\n\n```css\n/* Neutral (default) - pure grayscale */\n--primary: oklch(0.205 0 0);\n\n/* Zinc - cooler, blue-gray */\n--primary: oklch(0.21 0.006 285.885);\n\n/* Slate - balanced blue-gray */\n--primary: oklch(0.208 0.042 265.755);\n\n/* Stone - warmer, brown-gray */\n--primary: oklch(0.216 0.006 56.043);\n```\n\n## Best Practices\n\n### Prefer Semantic Colors\n\n```tsx\n// Good - uses theme\n<div className=\"bg-background text-foreground\">\n\n// Avoid - hardcoded\n<div className=\"bg-white text-black dark:bg-zinc-950\">\n```\n\n### Group Related Utilities\n\n```tsx\n<div className=\"\n  flex items-center justify-between\n  rounded-lg border\n  bg-card text-card-foreground\n  p-4 shadow-sm\n  hover:bg-accent\n\">\n```\n\n### Avoid Arbitrary Values\n\n```tsx\n// Prefer design tokens\n<div className=\"p-4 text-sm\">\n\n// Avoid when unnecessary\n<div className=\"p-[17px] text-[13px]\">\n```\n\n## Installation\n\n```bash\n# Initialize shadcn/ui\npnpm dlx shadcn@latest init\n\n# Add components\npnpm dlx shadcn@latest add button card form\n\n# Add all components\npnpm dlx shadcn@latest add --all\n```\n\n## Troubleshooting\n\n**Colors not updating:**\n1. Check CSS variable in globals.css\n2. Verify @theme inline includes variable\n3. Clear build cache\n\n**Dark mode not working:**\n1. Verify ThemeProvider wraps app\n2. Check suppressHydrationWarning on html tag\n3. Ensure dark: variants defined\n\n**Tailwind v4 migration:**\n1. Run `@tailwindcss/upgrade@next` codemod\n2. Update CSS variables with hsl() wrappers\n3. Change @theme to @theme inline\n4. Install tw-animate-css\n\n## Component Patterns\n\nFor detailed component patterns see [components.md](components.md):\n- **Composition**: asChild pattern for wrapping elements\n- **Typography**: Heading scales, prose styles, inline code\n- **Forms**: React Hook Form with Zod validation\n- **Icons**: Lucide icons integration and sizing\n- **Inputs**: OTP, file, grouped inputs\n- **Dialogs**: Modal patterns and composition\n- **Data Tables**: TanStack table integration\n- **Toasts**: Sonner notifications\n- **CLI**: Complete command reference\n\n## Resources\n\nSee [theming.md](theming.md) for complete color system reference and examples.\n\n## Summary\n\nKey concepts:\n- Use semantic CSS variables for theming\n- Apply CVA for component variants\n- Follow mobile-first responsive patterns\n- Implement dark mode with next-themes\n- Use OKLCH for modern color handling\n- Prefer Tailwind v4 features (size-*, @theme)\n- Always ensure accessibility with focus-visible, sr-only\n\nThis skill focuses on shadcn/ui patterns with Tailwind CSS. For component-specific examples, refer to the official shadcn/ui documentation.\n",
        "tanstack-query/skill/SKILL.md": "---\nname: tanstack-query\ndescription: Master TanStack Query (React Query) v5 for server state management in React applications. Use when fetching data from APIs, managing server state, caching, or handling mutations. Triggers on phrases like \"react query\", \"tanstack query\", \"data fetching\", \"cache management\", \"server state\", or file patterns like *query*.ts, *Query*.tsx, queryClient.ts.\n---\n\n# TanStack Query (React Query) v5\n\nPowerful asynchronous state management for React. TanStack Query makes fetching, caching, synchronizing, and updating server state in your React applications a breeze.\n\n## When to Use This Skill\n\n- Fetching data from REST APIs or GraphQL endpoints\n- Managing server state and cache lifecycle\n- Implementing mutations (create, update, delete operations)\n- Building infinite scroll or load-more patterns\n- Handling optimistic UI updates\n- Synchronizing data across components\n- Implementing background data refetching\n- Managing complex async state without Redux or other state managers\n\n## Quick Start Workflow\n\n### 1. Installation\n\n```bash\nnpm install @tanstack/react-query\n# or\npnpm add @tanstack/react-query\n# or\nyarn add @tanstack/react-query\n```\n\n### 2. Setup QueryClient\n\nWrap your application with `QueryClientProvider`:\n\n```tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\n\nconst queryClient = new QueryClient();\n\nfunction App() {\n  return (\n    <QueryClientProvider client={queryClient}>\n      <YourApp />\n    </QueryClientProvider>\n  );\n}\n```\n\n### 3. Basic Query\n\n```tsx\nimport { useQuery } from '@tanstack/react-query';\n\nfunction TodoList() {\n  const { data, isLoading, error } = useQuery({\n    queryKey: ['todos'],\n    queryFn: async () => {\n      const res = await fetch('https://api.example.com/todos');\n      if (!res.ok) throw new Error('Network response was not ok');\n      return res.json();\n    },\n  });\n\n  if (isLoading) return <div>Loading...</div>;\n  if (error) return <div>Error: {error.message}</div>;\n\n  return (\n    <ul>\n      {data.map((todo) => (\n        <li key={todo.id}>{todo.title}</li>\n      ))}\n    </ul>\n  );\n}\n```\n\n### 4. Basic Mutation\n\n```tsx\nimport { useMutation, useQueryClient } from '@tanstack/react-query';\n\nfunction CreateTodo() {\n  const queryClient = useQueryClient();\n\n  const mutation = useMutation({\n    mutationFn: async (newTodo) => {\n      const res = await fetch('https://api.example.com/todos', {\n        method: 'POST',\n        body: JSON.stringify(newTodo),\n        headers: { 'Content-Type': 'application/json' },\n      });\n      return res.json();\n    },\n    onSuccess: () => {\n      // Invalidate and refetch todos\n      queryClient.invalidateQueries({ queryKey: ['todos'] });\n    },\n  });\n\n  return (\n    <button onClick={() => mutation.mutate({ title: 'New Todo' })}>\n      {mutation.isPending ? 'Creating...' : 'Create Todo'}\n    </button>\n  );\n}\n```\n\n## Core Concepts\n\n### Query Keys\n\nQuery keys uniquely identify queries and are used for caching. They must be arrays.\n\n```tsx\n// Simple key\nuseQuery({ queryKey: ['todos'], queryFn: fetchTodos });\n\n// Key with variables\nuseQuery({ queryKey: ['todo', todoId], queryFn: () => fetchTodo(todoId) });\n\n// Hierarchical keys\nuseQuery({ queryKey: ['todos', 'list', { filters, page }], queryFn: fetchTodos });\n```\n\n**Query key matching:**\n- `['todos']` - exact match\n- `['todos', { page: 1 }]` - exact match with object\n- `{ queryKey: ['todos'] }` - matches all queries starting with 'todos'\n\n### Query Functions\n\nQuery functions must return a promise that resolves data or throws an error:\n\n```tsx\n// Using fetch\nqueryFn: async () => {\n  const res = await fetch(url);\n  if (!res.ok) throw new Error('Failed to fetch');\n  return res.json();\n}\n\n// Using axios\nqueryFn: () => axios.get(url).then(res => res.data)\n\n// With query key access\nqueryFn: ({ queryKey }) => {\n  const [_, todoId] = queryKey;\n  return fetchTodo(todoId);\n}\n```\n\n### Important Defaults\n\nUnderstanding defaults is crucial for optimal usage:\n\n- **staleTime: 0** - Queries become stale immediately by default\n- **gcTime: 5 minutes** - Unused/inactive cache data remains in memory for 5 minutes\n- **retry: 3** - Failed queries retry 3 times with exponential backoff\n- **refetchOnWindowFocus: true** - Queries refetch when window regains focus\n- **refetchOnReconnect: true** - Queries refetch when network reconnects\n\n```tsx\n// Override defaults globally\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      staleTime: 1000 * 60 * 5, // 5 minutes\n      gcTime: 1000 * 60 * 10, // 10 minutes\n    },\n  },\n});\n\n// Or per query\nuseQuery({\n  queryKey: ['todos'],\n  queryFn: fetchTodos,\n  staleTime: 1000 * 60, // 1 minute\n  retry: 5,\n});\n```\n\n### Query Status and Fetch Status\n\nQueries have two important states:\n\n**Query Status:**\n- `pending` - No cached data, query is executing\n- `error` - Query encountered an error\n- `success` - Query succeeded and data is available\n\n**Fetch Status:**\n- `fetching` - Query function is executing\n- `paused` - Query wants to fetch but is paused (offline)\n- `idle` - Query is not fetching\n\n```tsx\nconst { data, status, fetchStatus, isLoading, isFetching } = useQuery({\n  queryKey: ['todos'],\n  queryFn: fetchTodos,\n});\n\n// isLoading = status === 'pending'\n// isFetching = fetchStatus === 'fetching'\n```\n\n### Query Invalidation\n\nMark queries as stale to trigger refetches:\n\n```tsx\nconst queryClient = useQueryClient();\n\n// Invalidate all todos queries\nqueryClient.invalidateQueries({ queryKey: ['todos'] });\n\n// Invalidate specific query\nqueryClient.invalidateQueries({ queryKey: ['todo', todoId] });\n\n// Invalidate and refetch immediately\nqueryClient.invalidateQueries({\n  queryKey: ['todos'],\n  refetchType: 'active' // only refetch active queries\n});\n```\n\n### Mutations\n\nMutations are used for creating, updating, or deleting data:\n\n```tsx\nconst mutation = useMutation({\n  mutationFn: (newTodo) => {\n    return fetch('/api/todos', {\n      method: 'POST',\n      body: JSON.stringify(newTodo),\n    });\n  },\n  onSuccess: (data, variables, context) => {\n    console.log('Success!', data);\n  },\n  onError: (error, variables, context) => {\n    console.error('Error:', error);\n  },\n  onSettled: (data, error, variables, context) => {\n    console.log('Mutation finished');\n  },\n});\n\n// Trigger mutation\nmutation.mutate({ title: 'New Todo' });\n\n// With async/await\nmutation.mutateAsync({ title: 'New Todo' })\n  .then(data => console.log(data))\n  .catch(error => console.error(error));\n```\n\n### React Suspense Integration\n\nTanStack Query supports React Suspense with dedicated hooks:\n\n```tsx\nimport { useSuspenseQuery } from '@tanstack/react-query';\n\nfunction TodoList() {\n  // This will suspend the component until data is ready\n  const { data } = useSuspenseQuery({\n    queryKey: ['todos'],\n    queryFn: fetchTodos,\n  });\n\n  // No need for loading states - handled by Suspense boundary\n  return (\n    <ul>\n      {data.map((todo) => (\n        <li key={todo.id}>{todo.title}</li>\n      ))}\n    </ul>\n  );\n}\n\n// In parent component\nfunction App() {\n  return (\n    <Suspense fallback={<div>Loading todos...</div>}>\n      <TodoList />\n    </Suspense>\n  );\n}\n```\n\n## Advanced Topics\n\nFor detailed information on advanced patterns, see the reference files:\n\n### Infinite Queries\n\nFor implementing infinite scroll and load-more patterns:\n- See `references/infinite-queries.md` for comprehensive guide\n- Covers `useInfiniteQuery` hook\n- Bidirectional pagination\n- `getNextPageParam` and `getPreviousPageParam`\n- Refetching and background updates\n\n### Optimistic Updates\n\nFor updating UI before server confirmation:\n- See `references/optimistic-updates.md` for detailed patterns\n- Optimistic mutations\n- Rollback on error\n- Context for cancellation\n- UI feedback strategies\n\n### TypeScript Support\n\nFor full type safety and inference:\n- See `references/typescript.md` for complete TypeScript guide\n- Type inference from query functions\n- Generic type parameters\n- Typing query options\n- Custom hooks with types\n- Error type narrowing\n\n### Query Invalidation Patterns\n\nFor advanced cache invalidation strategies:\n- See `references/query-invalidation.md`\n- Partial matching\n- Predicate functions\n- Refetch strategies\n- Query filters\n\n### Performance Optimization\n\nFor optimizing query performance:\n- See `references/performance.md`\n- Query deduplication\n- Structural sharing\n- Memory management\n- Query splitting strategies\n\n## DevTools\n\nTanStack Query DevTools provide visual insights into query state:\n\n```bash\nnpm install @tanstack/react-query-devtools\n```\n\n```tsx\nimport { ReactQueryDevtools } from '@tanstack/react-query-devtools';\n\nfunction App() {\n  return (\n    <QueryClientProvider client={queryClient}>\n      <YourApp />\n      <ReactQueryDevtools initialIsOpen={false} />\n    </QueryClientProvider>\n  );\n}\n```\n\n**DevTools features:**\n- View all queries and their states\n- Inspect query data and errors\n- Manually trigger refetches\n- Invalidate queries\n- Monitor cache lifecycle\n\n## Common Patterns\n\n### Dependent Queries\n\nRun queries in sequence when one depends on another:\n\n```tsx\n// First query\nconst { data: user } = useQuery({\n  queryKey: ['user', userId],\n  queryFn: () => fetchUser(userId),\n});\n\n// Second query depends on first\nconst { data: projects } = useQuery({\n  queryKey: ['projects', user?.id],\n  queryFn: () => fetchProjects(user.id),\n  enabled: !!user?.id, // Only run when user.id is available\n});\n```\n\n### Parallel Queries\n\nMultiple independent queries in one component:\n\n```tsx\nfunction Dashboard() {\n  const users = useQuery({ queryKey: ['users'], queryFn: fetchUsers });\n  const posts = useQuery({ queryKey: ['posts'], queryFn: fetchPosts });\n  const stats = useQuery({ queryKey: ['stats'], queryFn: fetchStats });\n\n  if (users.isLoading || posts.isLoading || stats.isLoading) {\n    return <div>Loading...</div>;\n  }\n\n  // All queries succeeded\n  return <DashboardView users={users.data} posts={posts.data} stats={stats.data} />;\n}\n```\n\n### Dynamic Parallel Queries\n\nUse `useQueries` for dynamic number of queries:\n\n```tsx\nimport { useQueries } from '@tanstack/react-query';\n\nfunction TodoLists({ listIds }) {\n  const results = useQueries({\n    queries: listIds.map((id) => ({\n      queryKey: ['list', id],\n      queryFn: () => fetchList(id),\n    })),\n  });\n\n  const isLoading = results.some(result => result.isLoading);\n  const data = results.map(result => result.data);\n\n  return <Lists data={data} />;\n}\n```\n\n### Prefetching\n\nPrefetch data before it's needed:\n\n```tsx\nconst queryClient = useQueryClient();\n\n// Prefetch on hover\nfunction TodoListLink({ id }) {\n  const prefetch = () => {\n    queryClient.prefetchQuery({\n      queryKey: ['todo', id],\n      queryFn: () => fetchTodo(id),\n      staleTime: 1000 * 60 * 5, // Cache for 5 minutes\n    });\n  };\n\n  return (\n    <Link to={`/todo/${id}`} onMouseEnter={prefetch}>\n      View Todo\n    </Link>\n  );\n}\n```\n\n### Initial Data\n\nProvide initial data to avoid loading states:\n\n```tsx\nfunction TodoDetail({ todoId, initialTodo }) {\n  const { data } = useQuery({\n    queryKey: ['todo', todoId],\n    queryFn: () => fetchTodo(todoId),\n    initialData: initialTodo, // Use this data immediately\n    staleTime: 1000 * 60, // Consider fresh for 1 minute\n  });\n\n  return <div>{data.title}</div>;\n}\n```\n\n### Placeholder Data\n\nShow placeholder while loading:\n\n```tsx\nconst { data, isPlaceholderData } = useQuery({\n  queryKey: ['todos', page],\n  queryFn: () => fetchTodos(page),\n  placeholderData: (previousData) => previousData, // Keep previous data while loading\n});\n\n// Or use static placeholder\nconst { data } = useQuery({\n  queryKey: ['todos'],\n  queryFn: fetchTodos,\n  placeholderData: { items: [], total: 0 },\n});\n```\n\n## Error Handling\n\n### Query Errors\n\n```tsx\nconst { error, isError } = useQuery({\n  queryKey: ['todos'],\n  queryFn: fetchTodos,\n  retry: 3,\n  retryDelay: (attemptIndex) => Math.min(1000 * 2 ** attemptIndex, 30000),\n});\n\nif (isError) {\n  return <div>Error: {error.message}</div>;\n}\n```\n\n### Global Error Handling\n\n```tsx\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      onError: (error) => {\n        console.error('Query error:', error);\n        // Show toast notification, etc.\n      },\n    },\n    mutations: {\n      onError: (error) => {\n        console.error('Mutation error:', error);\n      },\n    },\n  },\n});\n```\n\n### Error Boundaries\n\nCombine with React Error Boundaries:\n\n```tsx\nimport { useQuery } from '@tanstack/react-query';\nimport { ErrorBoundary } from 'react-error-boundary';\n\nfunction TodoList() {\n  const { data } = useQuery({\n    queryKey: ['todos'],\n    queryFn: fetchTodos,\n    throwOnError: true, // Throw errors to error boundary\n  });\n\n  return <div>{/* render data */}</div>;\n}\n\nfunction App() {\n  return (\n    <ErrorBoundary fallback={<div>Something went wrong</div>}>\n      <TodoList />\n    </ErrorBoundary>\n  );\n}\n```\n\n## Best Practices\n\n1. **Use Query Keys Wisely**\n   - Structure keys hierarchically: `['todos', 'list', { filters }]`\n   - Include all variables in the key\n   - Keep keys consistent across your app\n\n2. **Set Appropriate staleTime**\n   - Static data: `staleTime: Infinity`\n   - Frequently changing: `staleTime: 0` (default)\n   - Moderately changing: `staleTime: 1000 * 60 * 5` (5 minutes)\n\n3. **Handle Loading and Error States**\n   - Always check `isLoading` and `error`\n   - Provide meaningful loading indicators\n   - Show user-friendly error messages\n\n4. **Optimize Refetching**\n   - Disable unnecessary refetches with `refetchOnWindowFocus: false`\n   - Use `staleTime` to reduce refetches\n   - Consider using `refetchInterval` for polling\n\n5. **Invalidate Efficiently**\n   - Invalidate specific queries, not all queries\n   - Use query key prefixes for related queries\n   - Combine with optimistic updates for better UX\n\n6. **Use TypeScript**\n   - Type your query functions for type inference\n   - Use generic type parameters when needed\n   - Enable strict type checking\n\n7. **Leverage DevTools**\n   - Install DevTools in development\n   - Monitor query behavior\n   - Debug cache issues\n\n## Resources\n\n- **Official Documentation**: https://tanstack.com/query/latest/docs/framework/react/overview\n- **GitHub Repository**: https://github.com/TanStack/query\n- **Examples**: https://tanstack.com/query/latest/docs/framework/react/examples\n- **Community**: https://discord.gg/tanstack\n- **TypeScript Guide**: https://tanstack.com/query/latest/docs/framework/react/typescript\n\n## Migration from v4\n\nIf you're upgrading from React Query v4:\n\n- `cacheTime` renamed to `gcTime`\n- `useInfiniteQuery` pageParam changes\n- New `useSuspenseQuery` hooks\n- Improved TypeScript inference\n- See official migration guide: https://tanstack.com/query/latest/docs/framework/react/guides/migrating-to-v5\n",
        "uv-ruff-python-tools/README.md": "# UV + Ruff Python Tools\n\nModern Python with uv (10-100x faster package manager) and ruff (extremely fast linter/formatter).\n\n## Install\n\n```\n/plugin marketplace add tenequm/claude-plugins\n/plugin install uv-ruff-python-tools@tenequm-plugins\n```\n\n## Example Prompts\n\n```\n\"Set up a new Python project with uv\"\n\"Migrate from pip/poetry to uv\"\n\"Configure ruff to replace flake8, black, and isort\"\n\"Set up pre-commit hooks with ruff\"\n```\n\n## Contents\n\n4 references: uv guide, ruff guide, migration paths, workflows.\n",
        "uv-ruff-python-tools/skill/SKILL.md": "---\nname: uv-ruff-python-tools\ndescription: Modern Python development with uv (10-100x faster package manager) and ruff (extremely fast linter/formatter). Use when managing Python projects, dependencies, virtual environments, installing packages, linting code, or formatting Python files. Triggers on phrases like \"uv install\", \"ruff check\", \"python package manager\", \"format python code\", or working with pyproject.toml files.\n---\n\n# UV & Ruff: Modern Python Development Tools\n\nSupercharge your Python development with Astral's blazing-fast tooling suite - uv for package management and ruff for code quality.\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- **Package Management**: Install, update, or manage Python dependencies 10-100x faster than pip\n- **Project Setup**: Initialize new Python projects with modern standards\n- **Python Versions**: Install and manage multiple Python versions\n- **Code Linting**: Check Python code for errors and style issues\n- **Code Formatting**: Auto-format Python code to consistent style\n- **Virtual Environments**: Create and manage isolated Python environments\n- **Migration**: Move from pip, conda, poetry, or pipx to modern tooling\n\n## Quick Start\n\n### Installing UV\n\n```bash\n# macOS/Linux - standalone installer\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows - PowerShell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# With Homebrew\nbrew install uv\n\n# With pipx\npipx install uv\n\n# Verify installation\nuv version\n```\n\n### Installing Ruff\n\n```bash\n# With uv (recommended)\nuv tool install ruff\n\n# With pip\npip install ruff\n\n# With Homebrew\nbrew install ruff\n\n# Verify installation\nruff version\n```\n\n## Common Workflows\n\n### Project Management with UV\n\n```bash\n# Create a new project\nuv init my-project\ncd my-project\n\n# Add dependencies\nuv add requests pandas numpy\n\n# Add development dependencies\nuv add --dev pytest black ruff\n\n# Install all dependencies\nuv sync\n\n# Run a script in the project environment\nuv run python main.py\n\n# Run a tool (like pytest)\nuv run pytest\n\n# Update dependencies\nuv lock --upgrade\nuv sync\n```\n\n### Code Quality with Ruff\n\n```bash\n# Check for linting errors\nruff check .\n\n# Auto-fix linting errors\nruff check --fix .\n\n# Format code\nruff format .\n\n# Check formatting without changes\nruff format --check .\n\n# Watch mode (continuous linting)\nruff check --watch\n\n# Lint and format in one command\nruff check --fix . && ruff format .\n```\n\n### Python Version Management\n\n```bash\n# Install Python versions\nuv python install 3.11 3.12 3.13\n\n# List installed Python versions\nuv python list\n\n# Pin Python version for project\nuv python pin 3.12\n\n# Use specific Python version\nuv run --python 3.11 python script.py\n```\n\n## Key Features\n\n### UV Features\n\n**🚀 Speed**: 10-100x faster than pip for package installation\n- Parallel downloads and caching\n- Rust-powered dependency resolution\n- Global package cache for deduplication\n\n**📦 All-in-One Tool**: Replaces multiple tools\n- `pip` - Package installation\n- `pip-tools` - Dependency locking\n- `pipx` - Tool installation\n- `poetry` - Project management\n- `pyenv` - Python version management\n- `virtualenv` - Environment creation\n\n**🔒 Reproducible Environments**:\n- Universal lockfiles (`uv.lock`)\n- Platform-independent resolution\n- Version pinning\n\n### Ruff Features\n\n**⚡ Extreme Speed**: 10-100x faster than existing linters\n- Written in Rust for maximum performance\n- Processes entire codebases in milliseconds\n\n**🔧 Unified Tool**: Replaces multiple tools\n- `Flake8` - Linting\n- `Black` - Formatting\n- `isort` - Import sorting\n- `pyupgrade` - Modern Python syntax\n- `autoflake` - Unused code removal\n\n**📏 800+ Rules**: Comprehensive code quality\n- Pyflakes error detection\n- pycodestyle (PEP 8) compliance\n- flake8-bugbear best practices\n- Many popular Flake8 plugins built-in\n\n## Common Patterns\n\n### UV Patterns\n\n```bash\n# Quick tool execution (like npx or pipx)\nuvx ruff check .\nuvx black .\nuvx pytest\n\n# Build and publish packages\nuv build\nuv publish\n\n# Pip-compatible interface (drop-in replacement)\nuv pip install requests\nuv pip freeze > requirements.txt\nuv pip compile requirements.in\nuv pip sync requirements.txt\n\n# Create virtual environment\nuv venv\nsource .venv/bin/activate  # Linux/macOS\n.venv\\Scripts\\activate     # Windows\n\n# Run scripts with inline dependencies\nuv add --script my_script.py requests\nuv run my_script.py\n```\n\n### Ruff Patterns\n\n```bash\n# Enable specific rule sets\nruff check --select E,W,F,I .\n\n# Ignore specific rules\nruff check --ignore E501 .\n\n# Show fixes that will be applied\nruff check --diff .\n\n# Format with preview features\nruff format --preview .\n\n# Check specific files\nruff check src/main.py tests/test_main.py\n\n# Output formats\nruff check --output-format json .\nruff check --output-format github .\n```\n\n## Configuration\n\n### UV Configuration (pyproject.toml)\n\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"My Python project\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"requests>=2.31.0\",\n    \"pandas>=2.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0.0\",\n    \"ruff>=0.1.0\",\n]\n\n[tool.uv]\ndev-dependencies = [\n    \"pytest>=7.0.0\",\n    \"ruff>=0.1.0\",\n]\n\n[tool.uv.sources]\n# Use specific package sources if needed\n```\n\n### Ruff Configuration (pyproject.toml)\n\n```toml\n[tool.ruff]\n# Set line length\nline-length = 88\nindent-width = 4\ntarget-version = \"py311\"\n\n# Exclude directories\nexclude = [\n    \".git\",\n    \".venv\",\n    \"__pycache__\",\n    \"build\",\n    \"dist\",\n]\n\n[tool.ruff.lint]\n# Enable rule sets\nselect = [\n    \"E\",   # pycodestyle errors\n    \"W\",   # pycodestyle warnings\n    \"F\",   # Pyflakes\n    \"I\",   # isort\n    \"B\",   # flake8-bugbear\n    \"UP\",  # pyupgrade\n]\n\n# Ignore specific rules\nignore = [\n    \"E501\",  # line too long (handled by formatter)\n]\n\n# Allow auto-fix for all enabled rules\nfixable = [\"ALL\"]\nunfixable = []\n\n[tool.ruff.lint.per-file-ignores]\n\"__init__.py\" = [\"F401\"]  # Allow unused imports\n\"tests/*\" = [\"S101\"]      # Allow assert statements\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\nline-ending = \"auto\"\n```\n\n## Integration with Development Tools\n\n### Pre-commit Hooks\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.12.8\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n```\n\n### CI/CD (GitHub Actions)\n\n```yaml\nname: Lint and Test\n\non: [push, pull_request]\n\njobs:\n  quality:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Install dependencies\n        run: uv sync\n\n      - name: Lint with ruff\n        run: uv run ruff check .\n\n      - name: Format check with ruff\n        run: uv run ruff format --check .\n\n      - name: Run tests\n        run: uv run pytest\n```\n\n## Detailed Documentation\n\nFor comprehensive guides and advanced usage, see the reference files:\n\n- **references/uv-guide.md** - Complete uv documentation\n  - Project management workflows\n  - Python version management\n  - Package building and publishing\n  - Migration from other tools\n\n- **references/ruff-guide.md** - Complete ruff documentation\n  - All 800+ linting rules\n  - Formatting options\n  - Rule configuration\n  - Editor integration\n\n- **references/migration.md** - Migration guides\n  - From pip + virtualenv\n  - From conda\n  - From poetry\n  - From pipx\n\n- **references/workflows.md** - Advanced workflows\n  - Monorepo management\n  - Docker integration\n  - Production deployments\n\n## Resources\n\n**Official Documentation:**\n- [uv Documentation](https://docs.astral.sh/uv/)\n- [Ruff Documentation](https://docs.astral.sh/ruff/)\n- [Astral (Parent Company)](https://astral.sh)\n\n**GitHub Repositories:**\n- [astral-sh/uv](https://github.com/astral-sh/uv)\n- [astral-sh/ruff](https://github.com/astral-sh/ruff)\n\n**Community:**\n- [Ruff Discord](https://discord.gg/astral-sh)\n- [GitHub Discussions](https://github.com/astral-sh/uv/discussions)\n\n## Troubleshooting\n\n**UV Issues:**\n```bash\n# Clear cache\nuv cache clean\n\n# Reinstall Python\nrm -r \"$(uv python dir)\"\nuv python install 3.12\n\n# Reset lockfile\nrm uv.lock\nuv lock\n```\n\n**Ruff Issues:**\n```bash\n# Clear cache\nruff clean\n\n# Show current settings\nruff check --show-settings\n\n# List all available rules\nruff rule --all\n\n# Explain a specific rule\nruff rule E501\n```\n\n## Notes\n\n- UV and Ruff are both built by Astral and designed to work together seamlessly\n- UV automatically creates and manages virtual environments - no manual activation needed\n- Ruff can replace Black, isort, Flake8, and more with a single tool\n- Both tools are written in Rust for maximum performance\n- UV's lockfile format is becoming a Python standard (PEP 751 proposal)\n- Ruff is compatible with Black formatting by default\n"
      },
      "plugins": [
        {
          "name": "gh-cli",
          "source": "./",
          "description": "Skill: Full GitHub CLI capabilities for repos & code",
          "version": "1.1.0",
          "skills": [
            "./gh-cli/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install gh-cli@tenequm-plugins"
          ]
        },
        {
          "name": "chrome-extension-wxt",
          "source": "./",
          "description": "Skill: Build Chrome extensions with WXT framework",
          "version": "1.1.0",
          "skills": [
            "./chrome-extension-wxt/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install chrome-extension-wxt@tenequm-plugins"
          ]
        },
        {
          "name": "cloudflare-workers",
          "source": "./",
          "description": "Skill: Rapid development with Cloudflare Workers - build and deploy serverless applications",
          "version": "2.0.0",
          "skills": [
            "./cloudflare-workers/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install cloudflare-workers@tenequm-plugins"
          ]
        },
        {
          "name": "skill-finder",
          "source": "./",
          "description": "Skill: Find and evaluate Claude skills using semantic search and quality assessment",
          "version": "1.1.0",
          "skills": [
            "./skill-finder/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install skill-finder@tenequm-plugins"
          ]
        },
        {
          "name": "skill-factory",
          "source": "./",
          "description": "Skill: Autonomous skill creation with automatic quality assurance - analyzes requests, selects optimal creation method, and delivers production-ready skills",
          "version": "0.2.0",
          "skills": [
            "./skill-factory/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install skill-factory@tenequm-plugins"
          ]
        },
        {
          "name": "uv-ruff-python-tools",
          "source": "./",
          "description": "Skill: Modern Python development with uv (10-100x faster package manager) and ruff (extremely fast linter/formatter) - Astral's fast tooling suite",
          "version": "0.1.0",
          "skills": [
            "./uv-ruff-python-tools/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install uv-ruff-python-tools@tenequm-plugins"
          ]
        },
        {
          "name": "solana",
          "source": "./solana",
          "description": "Comprehensive Solana development toolkit: build programs with Anchor/native Rust and audit for security vulnerabilities",
          "version": "0.5.0",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install solana@tenequm-plugins"
          ]
        },
        {
          "name": "styling-with-tailwind",
          "source": "./",
          "description": "Skill: Build beautiful UIs with Tailwind CSS and shadcn/ui - modern utility-first styling, component patterns, and Tailwind v4.1 features",
          "version": "0.1.0",
          "skills": [
            "./styling-with-tailwind/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install styling-with-tailwind@tenequm-plugins"
          ]
        },
        {
          "name": "tanstack-query",
          "source": "./",
          "description": "Skill: Master TanStack Query (React Query) v5 for server state management in React applications",
          "version": "0.1.0",
          "skills": [
            "./tanstack-query/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install tanstack-query@tenequm-plugins"
          ]
        },
        {
          "name": "founder-playbook",
          "source": "./",
          "description": "Skill: Decision validation and thinking frameworks for startup founders - pressure-test decisions with proven methodologies and crypto/web3 knowledge",
          "version": "0.1.1",
          "author": {
            "name": "Misha Kolesnik",
            "email": "misha@kolesnik.io"
          },
          "homepage": "https://github.com/tenequm/claude-plugins",
          "repository": "https://github.com/tenequm/claude-plugins",
          "license": "MIT",
          "keywords": [
            "founder",
            "startup",
            "coaching",
            "web3",
            "solana",
            "decision-making"
          ],
          "skills": [
            "./founder-playbook/skill"
          ],
          "categories": [
            "coaching",
            "decision-making",
            "founder",
            "solana",
            "startup",
            "web3"
          ],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install founder-playbook@tenequm-plugins"
          ]
        },
        {
          "name": "foundry-solidity",
          "source": "./",
          "description": "Skill: Build and test Solidity smart contracts with Foundry toolkit (Forge, Cast, Anvil) - testing patterns, deployment scripts, and modern Solidity 0.8.30",
          "version": "0.1.0",
          "skills": [
            "./foundry-solidity/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install foundry-solidity@tenequm-plugins"
          ]
        },
        {
          "name": "impactful-writing",
          "source": "./",
          "description": "Skill: Write clear, emotionally resonant, and well-structured content across any platform - research-backed principles for Twitter, articles, docs, emails, and more",
          "version": "0.1.0",
          "skills": [
            "./impactful-writing/skill"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add tenequm/claude-plugins",
            "/plugin install impactful-writing@tenequm-plugins"
          ]
        }
      ]
    }
  ]
}