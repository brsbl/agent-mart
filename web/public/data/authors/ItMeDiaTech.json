{
  "author": {
    "id": "ItMeDiaTech",
    "display_name": "DiaTech",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/101601860?u=24ce52172d519d81caaf88e5fdf35e99fd03740e&v=4",
    "url": "https://github.com/ItMeDiaTech",
    "bio": null,
    "stats": {
      "total_marketplaces": 2,
      "total_plugins": 2,
      "total_commands": 15,
      "total_skills": 1,
      "total_stars": 19,
      "total_forks": 3
    }
  },
  "marketplaces": [
    {
      "name": "rag-cli",
      "version": null,
      "description": "Advanced Retrieval-Augmented Generation marketplace for Claude Code. Features local vector search with FAISS, semantic embeddings, multi-agent orchestration (7 specialized agents), parallel RAG+MAF execution, HyDE optimization, and comprehensive monitoring. Enhances Claude with knowledge retrieval, intelligent query routing, and production-ready observability.",
      "owner_info": {
        "name": "DiaTech",
        "email": "support@rag-cli.dev"
      },
      "keywords": [],
      "repo_full_name": "ItMeDiaTech/rag-cli",
      "repo_url": "https://github.com/ItMeDiaTech/rag-cli",
      "repo_description": "Local Retrieval-Augmented Generation (RAG) plugin for Claude Code that combines Chroma db vector embeddings with intelligent info retrieval with Multi-Agent Framework (MAF) orchestration for context-aware development assistance. Uses Open Source / Free frameworks. Implements bridge to Claude Code CLI so no token use. And it's easy to setup.",
      "homepage": "",
      "signals": {
        "stars": 17,
        "forks": 3,
        "pushed_at": "2025-11-11T10:17:21Z",
        "created_at": "2025-10-30T03:42:31Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/hooks.json",
          "type": "blob",
          "size": 3149
        },
        {
          "path": ".claude-plugin/lifecycle.json",
          "type": "blob",
          "size": 1065
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1420
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 1325
        },
        {
          "path": ".githooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".githooks/README.md",
          "type": "blob",
          "size": 1732
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 24950
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 868
        },
        {
          "path": "src",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin/commands/rag-disable.md",
          "type": "blob",
          "size": 436
        },
        {
          "path": "src/rag_cli_plugin/commands/rag-enable.md",
          "type": "blob",
          "size": 432
        },
        {
          "path": "src/rag_cli_plugin/commands/rag-maf-config.md",
          "type": "blob",
          "size": 1441
        },
        {
          "path": "src/rag_cli_plugin/commands/rag-project.md",
          "type": "blob",
          "size": 549
        },
        {
          "path": "src/rag_cli_plugin/commands/search.md",
          "type": "blob",
          "size": 638
        },
        {
          "path": "src/rag_cli_plugin/commands/update-rag.md",
          "type": "blob",
          "size": 461
        },
        {
          "path": "src/rag_cli_plugin/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin/hooks/__init__.py",
          "type": "blob",
          "size": 109
        },
        {
          "path": "src/rag_cli_plugin/hooks/document-indexing.py",
          "type": "blob",
          "size": 8677
        },
        {
          "path": "src/rag_cli_plugin/hooks/error-handler.py",
          "type": "blob",
          "size": 6928
        },
        {
          "path": "src/rag_cli_plugin/hooks/event_validator.py",
          "type": "blob",
          "size": 4246
        },
        {
          "path": "src/rag_cli_plugin/hooks/path_utils.py",
          "type": "blob",
          "size": 6787
        },
        {
          "path": "src/rag_cli_plugin/hooks/plugin-state-change.py",
          "type": "blob",
          "size": 6668
        },
        {
          "path": "src/rag_cli_plugin/hooks/response-post.py",
          "type": "blob",
          "size": 7050
        },
        {
          "path": "src/rag_cli_plugin/hooks/session-end.py",
          "type": "blob",
          "size": 5653
        },
        {
          "path": "src/rag_cli_plugin/hooks/session-start.py",
          "type": "blob",
          "size": 7169
        },
        {
          "path": "src/rag_cli_plugin/hooks/slash-command-blocker.py",
          "type": "blob",
          "size": 5400
        },
        {
          "path": "src/rag_cli_plugin/hooks/user-prompt-submit.py",
          "type": "blob",
          "size": 31439
        },
        {
          "path": "src/rag_cli_plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin/skills/rag-retrieval",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/rag_cli_plugin/skills/rag-retrieval/SKILL.md",
          "type": "blob",
          "size": 2490
        }
      ],
      "files": {
        ".claude-plugin/hooks.json": "{\n  \"hooks\": {\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/slash-command-blocker.py\",\n            \"name\": \"slash-command-blocker\",\n            \"priority\": 150,\n            \"description\": \"Prevents Claude from responding to slash commands, showing only execution status\"\n          }\n        ]\n      },\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/user-prompt-submit.py\",\n            \"name\": \"user-prompt-submit\",\n            \"priority\": 100,\n            \"description\": \"Automatically enhances queries with RAG context and multi-agent orchestration\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/response-post.py\",\n            \"name\": \"response-post\",\n            \"priority\": 80,\n            \"enabled\": false,\n            \"description\": \"Adds inline citations to Claude responses when RAG context is used (DISABLED: Claude Code framework bug)\"\n          }\n        ]\n      }\n    ],\n    \"Notification\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/error-handler.py\",\n            \"name\": \"error-handler\",\n            \"priority\": 70,\n            \"description\": \"Provides graceful error handling with helpful troubleshooting tips\"\n          }\n        ]\n      },\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/plugin-state-change.py\",\n            \"name\": \"plugin-state-change\",\n            \"priority\": 60,\n            \"description\": \"Persists RAG settings across Claude Code restarts\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/document-indexing.py\",\n            \"name\": \"document-indexing\",\n            \"priority\": 50,\n            \"description\": \"Automatically indexes new or modified documents\"\n          }\n        ]\n      }\n    ],\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/session-start.py\",\n            \"name\": \"session-start\",\n            \"priority\": 40,\n            \"description\": \"Initializes RAG-CLI resources when a Claude Code session starts\"\n          }\n        ]\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python ${CLAUDE_PLUGIN_ROOT}/src/rag_cli_plugin/hooks/session-end.py\",\n            \"name\": \"session-end\",\n            \"priority\": 30,\n            \"description\": \"Cleanup and state persistence when Claude Code session ends\"\n          }\n        ]\n      }\n    ]\n  }\n}",
        ".claude-plugin/lifecycle.json": "{\n  \"hooks\": {\n    \"post_install\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"rag_cli_plugin.lifecycle.installer\",\n        \"--mode\", \"marketplace\"\n      ],\n      \"env\": {\n        \"CLAUDE_LIFECYCLE_HOOK\": \"true\"\n      },\n      \"timeout\": 60000,\n      \"required\": true,\n      \"description\": \"Install dependencies and initialize RAG-CLI configuration\"\n    },\n    \"pre_update\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"rag_cli_plugin.lifecycle.updater\",\n        \"--mode\", \"pre\"\n      ],\n      \"env\": {\n        \"CLAUDE_LIFECYCLE_HOOK\": \"true\"\n      },\n      \"timeout\": 30000,\n      \"required\": false,\n      \"description\": \"Backup configuration before update\"\n    },\n    \"post_update\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"rag_cli_plugin.lifecycle.updater\",\n        \"--mode\", \"post\"\n      ],\n      \"env\": {\n        \"CLAUDE_LIFECYCLE_HOOK\": \"true\"\n      },\n      \"timeout\": 60000,\n      \"required\": true,\n      \"description\": \"Reinstall dependencies and migrate configuration\"\n    }\n  }\n}\n",
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"rag-cli\",\n  \"owner\": {\n    \"name\": \"DiaTech\",\n    \"email\": \"support@rag-cli.dev\"\n  },\n  \"description\": \"Advanced Retrieval-Augmented Generation marketplace for Claude Code. Features local vector search with FAISS, semantic embeddings, multi-agent orchestration (7 specialized agents), parallel RAG+MAF execution, HyDE optimization, and comprehensive monitoring. Enhances Claude with knowledge retrieval, intelligent query routing, and production-ready observability.\",\n  \"homepage\": \"https://github.com/ItMeDiaTech/rag-cli\",\n  \"repository\": \"https://github.com/ItMeDiaTech/rag-cli\",\n  \"license\": \"MIT\",\n  \"plugins\": [\n    {\n      \"name\": \"rag-cli\",\n      \"source\": \"./\",\n      \"description\": \"Local RAG (Retrieval-Augmented Generation) system for enhanced Claude Code responses with multi-agent orchestration\",\n      \"version\": \"2.0.0\",\n      \"author\": {\n        \"name\": \"DiaTech\",\n        \"email\": \"support@rag-cli.dev\"\n      },\n      \"homepage\": \"https://github.com/ItMeDiaTech/rag-cli\",\n      \"repository\": \"https://github.com/ItMeDiaTech/rag-cli\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"rag\",\n        \"retrieval\",\n        \"augmented-generation\",\n        \"vector-search\",\n        \"semantic-search\",\n        \"multi-agent\",\n        \"orchestration\",\n        \"documentation\",\n        \"knowledge-base\",\n        \"faiss\",\n        \"embeddings\"\n      ],\n      \"category\": \"productivity\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"rag-cli\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Local RAG system with embedded Multi-Agent Framework for Claude Code plugin\",\n  \"author\": {\n    \"name\": \"DiaTech\",\n    \"email\": \"support@rag-cli.dev\",\n    \"url\": \"https://github.com/ItMeDiaTech/rag-cli\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/ItMeDiaTech/rag-cli.git\",\n  \"homepage\": \"https://github.com/ItMeDiaTech/rag-cli\",\n  \"keywords\": [\n    \"rag\",\n    \"retrieval\",\n    \"augmented-generation\",\n    \"vector-search\",\n    \"semantic-search\",\n    \"multi-agent\",\n    \"orchestration\",\n    \"documentation\",\n    \"knowledge-base\",\n    \"claude-code\",\n    \"plugin\"\n  ],\n  \"commands\": \"./src/rag_cli_plugin/commands\",\n  \"hooks\": \"./.claude-plugin/hooks.json\",\n  \"skills\": \"./src/rag_cli_plugin/skills\",\n  \"mcpServers\": {\n    \"rag-cli\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"rag_cli_plugin.mcp.unified_server\"\n      ],\n      \"env\": {\n        \"PYTHONUNBUFFERED\": \"1\",\n        \"RAG_CLI_MODE\": \"claude_code\",\n        \"RAG_CLI_ROOT\": \"${CLAUDE_PLUGIN_ROOT}\",\n        \"PYTHONPATH\": \"${CLAUDE_PLUGIN_ROOT}:${CLAUDE_PLUGIN_ROOT}/src\"\n      },\n      \"alwaysAllowTrust\": false,\n      \"features\": {\n        \"autoStart\": true,\n        \"retryOnFailure\": true,\n        \"maxRetries\": 3,\n        \"retryDelayMs\": 1000\n      }\n    }\n  }\n}\n",
        ".githooks/README.md": "# Git Hooks for RAG-CLI\n\nThis directory contains git hooks to maintain code quality standards for the RAG-CLI project.\n\n## Available Hooks\n\n### pre-commit\n\nValidates that no emoji characters are present in the codebase before allowing commits.\n\n**Checks:**\n- Python files (.py) for emoji characters\n- Markdown files (.md) for emoji characters\n- Prevents accidental emoji introduction\n\n## Installation\n\n### Method 1: Configure Git to Use This Directory\n\n```bash\ngit config core.hooksPath .githooks\n```\n\nThis tells git to use the hooks in `.githooks/` directory instead of `.git/hooks/`.\n\n### Method 2: Copy Hooks Manually\n\n```bash\n# On Unix/Linux/Mac\ncp .githooks/pre-commit .git/hooks/pre-commit\nchmod +x .git/hooks/pre-commit\n\n# On Windows (Git Bash)\ncp .githooks/pre-commit .git/hooks/pre-commit\n```\n\n### Method 3: Use Setup Script\n\n```bash\npython scripts/setup_git_hooks.py\n```\n\n## Manual Validation\n\nYou can manually run the emoji validation at any time:\n\n```bash\npython scripts/validate_no_emojis.py\n```\n\nIf emojis are detected, fix them with:\n\n```bash\npython scripts/remove_emojis.py\n```\n\n## Why No Emojis?\n\n1. **Windows Terminal Compatibility**: Emoji characters cause UnicodeEncodeError on Windows terminals using CP1252 encoding\n2. **Professional Standards**: Text-based indicators are more professional and universally readable\n3. **Accessibility**: Screen readers and text-based tools handle ASCII better than Unicode emojis\n4. **Consistency**: Plain text ensures consistent rendering across all platforms and editors\n\n## Bypassing Hooks (Not Recommended)\n\nIf you absolutely must bypass the pre-commit hook:\n\n```bash\ngit commit --no-verify\n```\n\nHowever, this is **strongly discouraged** as it violates project standards.\n",
        "README.md": "# RAG-CLI v2.0\n\n**Local Retrieval-Augmented Generation system for Claude Code with Multi-Agent Framework integration.**\n\nA production-ready Claude Code plugin that combines ChromaDB vector embeddings with intelligent document retrieval and Multi-Agent Framework (MAF) orchestration for context-aware development assistance.\n\n## Project Status\n\n**Current Version**: 2.0.0\n**Status**: Production Ready (with known limitations documented in KNOWN_ISSUES.md)\n\n**Key Features:**\n- ChromaDB-based vector storage with HNSW indexing\n- Hybrid search combining semantic and keyword matching\n- Multi-Agent Framework for intelligent query routing\n- Zero external API costs for document processing\n- Comprehensive plugin system (hooks, MCP server, slash commands)\n\n**Alternative Project**: For a standalone CLI experience with extended features, see [dt-cli](https://github.com/ItMeDiaTech/dt-cli). Both projects are actively maintained and can be used together.\n\n## Overview\n\nRAG-CLI is a production-ready local Retrieval-Augmented Generation system that enhances your development workflow by providing instant access to your project documentation, codebase context, and external resources. It works seamlessly with Claude Code as a native plugin, eliminating the need for external API calls while processing documents locally with enterprise-grade security and performance.\n\n### Why Use RAG-CLI?\n\n1. **Zero API Overhead**: Process documents locally without incurring API costs\n2. **Instant Context**: Get relevant documentation in milliseconds instead of manual searches\n3. **Improved Code Quality**: Make better decisions with context-aware assistance\n4. **Complete Privacy**: All document processing stays on your machine\n5. **Developer Focused**: Optimized for development workflows and Claude Code integration\n\n## Features\n\n- **Local-First Architecture**: Everything runs locally except Claude API calls\n- **Fast Performance**: <100ms vector search, <5s end-to-end responses\n- **Hybrid Search**: Combines semantic vector search with keyword matching for superior accuracy\n- **Claude Code Integration**: Seamless plugin for enhanced development workflow\n- **Multi-Format Support**: Process MD, PDF, DOCX, HTML, and TXT files\n- **Real-Time Monitoring**: TCP server with PowerShell interface for system observability\n- **Background File Watching**: Automatic document indexing with watchdog library (debounced events)\n- **Multi-Agent Orchestration**: Intelligent routing between RAG and code analysis agents\n- **Production Ready**: Comprehensive error handling, logging, and monitoring\n\n## Installation Guide\n\n### Prerequisites\n\n- **Python**: 3.8 or higher (tested with 3.13)\n- **RAM**: 4GB minimum (8GB recommended for large document sets)\n- **Disk Space**: 2GB for dependencies + space for document vectors\n- **Claude Code**: Latest version (for plugin mode)\n- **Anthropic API Key**: Optional (only for standalone mode)\n\n### System Requirements\n\nRAG-CLI runs efficiently on:\n- Windows 10+ / macOS / Linux\n- Laptops with limited resources (scales gracefully)\n- Cloud instances and Docker containers\n- CI/CD pipelines\n\n### Installation Methods\n\n#### Method 1: Claude Code Marketplace (Recommended)\n\nThe easiest way to get RAG-CLI as a Claude Code plugin:\n\n```bash\n# In Claude Code terminal\n/plugin marketplace add https://github.com/ItMeDiaTech/rag-cli.git\n/plugin install rag-cli\n```\n\nThen restart Claude Code. The plugin will activate automatically with zero configuration.\n\nBenefits:\n- Automatic installation of all dependencies\n- Plugin manages its own lifecycle\n- No API key needed (uses Claude Code internally)\n- One-command updates via `/plugin update rag-cli`\n\n#### Method 2: Manual Installation from Source\n\nFor development, testing, or custom configuration:\n\n```bash\n# Clone the repository\ngit clone https://github.com/ItMeDiaTech/rag-cli.git\ncd rag-cli\n\n# Create virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Verify installation\npython -c \"from rag_cli.core import embeddings; print('Installation successful!')\"\n```\n\n#### Method 3: Development Installation\n\nFor contributing to RAG-CLI:\n\n```bash\n# Clone and install in editable mode\ngit clone https://github.com/ItMeDiaTech/rag-cli.git\ncd rag-cli\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# Install with development dependencies\npip install -e \".[dev]\"\n\n# Configure MCP server for development mode\npython scripts/configure_mcp.py\n\n# Run tests to verify\npytest tests/\n```\n\n**Important for Contributors**: The `configure_mcp.py` script generates `.mcp.json` with absolute paths for your system. This file is gitignored and preserves any other MCP servers you have configured. You can re-run the script anytime if your project path changes.\n\n### Plugin Sync for Manual Installation\n\nIf you installed manually and want to use it as a Claude Code plugin:\n\n```bash\n# From the RAG-CLI directory\npython scripts/sync_plugin.py\n\n# This will copy necessary files to:\n# ~/.claude/plugins/marketplaces/rag-cli/\n\n# Then restart Claude Code\n```\n\n### Configuration Setup\n\n#### As a Claude Code Plugin (Recommended)\n\nNo configuration needed. RAG-CLI auto-detects Claude Code environment:\n\n```bash\n# First time setup: Index your documents\n/rag-project\n\n# Or manually index\npython scripts/index.py --input /path/to/docs\n```\n\n#### Standalone Mode (with API key)\n\nFor development or testing outside Claude Code:\n\n```bash\n# Set environment variables\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\nexport RAG_CLI_MODE=\"standalone\"\nexport RAG_CLI_LOG_LEVEL=\"INFO\"\n\n# Index documents\npython scripts/index.py --input data/documents\n\n# Test retrieval\npython scripts/retrieve.py \"Your question here\"\n```\n\n#### Custom Configuration\n\nEdit `config/default.yaml` to customize:\n\n```yaml\n# Model selection\nembeddings:\n  model_name: sentence-transformers/all-MiniLM-L6-v2  # Fast, 384-dim\n\n# Search parameters\nretrieval:\n  top_k: 5                 # Number of results\n  hybrid_ratio: 0.7        # 70% semantic, 30% keyword\n  rerank: true             # Use cross-encoder reranking\n\n# Claude settings (standalone only)\nclaude:\n  model: claude-haiku-4-5-20251001\n  max_tokens: 4096\n  temperature: 0.7\n```\n\n### Post-Installation Verification\n\n```bash\n# Test plugin installation\n/plugin\n\n# Should show: RAG-CLI plugin is installed and loaded\n\n# Test basic functionality\n/search \"test query\"\n\n# Check system status\npython scripts/validate_plugin.py\n```\n\n## Getting Started: Step-by-Step\n\n### Step 1: Install RAG-CLI\n\nUse Method 1 (Marketplace) for easiest setup.\n\n### Step 2: Prepare Documents\n\nGather your documentation:\n\n```bash\n# Create documents directory\nmkdir -p data/documents\n\n# Copy your files\ncp /path/to/docs/*.md data/documents/\ncp /path/to/docs/*.pdf data/documents/\n```\n\nSupported formats: Markdown, PDF, DOCX, HTML, TXT\n\n### Step 3: Index Documents\n\nIn Claude Code or terminal:\n\n```bash\n# Option 1: As Claude Code plugin (easiest)\n/rag-project  # Auto-indexes current project\n\n# Option 2: Manual indexing\npython scripts/index.py --input data/documents --output data/vectors\n```\n\n### Step 4: Test Retrieval\n\nAsk Claude Code questions about your documents:\n\n```bash\n# In Claude Code\n/search \"How do I configure authentication?\"\n\n# Or directly ask Claude\n\"How do I configure authentication?\"\n# RAG-CLI will automatically enhance with context\n```\n\n### Step 5: Enable Auto-Enhancement (Optional)\n\n```bash\n# In Claude Code\n/rag-enable\n\n# Now all your questions will automatically get document context\n```\n\nDisable with: `/rag-disable`\n\n## How RAG-CLI Improves Your Development Performance\n\n### Faster Problem Solving\n\nTraditional workflow:\n1. Search for documentation (browser, help files)\n2. Copy/paste relevant sections\n3. Ask Claude about the problem\n4. Time: 2-5 minutes per question\n\nWith RAG-CLI:\n1. Ask Claude directly\n2. RAG-CLI retrieves relevant docs automatically\n3. Claude responds with context\n4. Time: <5 seconds per question\n\nReal-world impact: Process 10x more questions per session.\n\n### Better Decision Making\n\nRAG-CLI provides Claude with your actual documentation, code patterns, and project conventions:\n\n**Without RAG-CLI:**\n- Claude makes general assumptions\n- Recommendations may conflict with your patterns\n- Need to manually validate advice against your codebase\n\n**With RAG-CLI:**\n- Claude knows your exact requirements\n- Recommendations match your conventions\n- Context-aware solutions specific to your project\n\n### Reduced Cognitive Load\n\nStop mentally tracking:\n- API documentation details\n- Code structure and patterns\n- Configuration requirements\n- Best practices for your project\n\nRAG-CLI automatically provides this context, freeing your mind for actual problem-solving.\n\n### Cost Savings\n\n**API Usage:**\n- Claude Code mode: No API calls for document retrieval\n- Saves $$ on large projects with extensive documentation\n\n**Time Savings:**\n- 80% reduction in documentation lookup time\n- 50% reduction in clarification questions\n- Faster code reviews and architectural decisions\n\n### Real-World Metrics\n\nOrganizations using RAG-CLI report:\n\n| Metric | Improvement |\n|--------|------------|\n| Development Speed | 30-40% faster completion |\n| Code Quality | 25% fewer bugs in reviews |\n| Documentation Accuracy | 90% vs 60% without context |\n| Onboarding Time | 50% reduction |\n| API Costs | Up to 60% savings |\n\n## Technical Implementation\n\n### How It Works (Under the Hood)\n\nRAG-CLI implements a sophisticated document retrieval pipeline:\n\n1. **Document Ingestion**\n   - Supports: Markdown, PDF, DOCX, HTML, TXT\n   - Automatic metadata extraction\n   - Intelligent chunking (500 tokens with 100-token overlap, configurable via `core.constants`)\n\n2. **Embedding Generation**\n   - Model: `sentence-transformers/all-MiniLM-L6-v2`\n   - Fast: <200ms for 100 documents\n   - Efficient: 384-dimensional vectors\n   - Cached for repeat queries\n\n3. **Intelligent Retrieval**\n   - Hybrid search: 70% semantic + 30% keyword (configurable via `core.constants`)\n   - Cross-encoder reranking for accuracy\n   - Returns top-K results with confidence scores (default: 5, max: 100)\n   - Sub-100ms retrieval time\n\n4. **Query Enhancement**\n   - Automatic document classification\n   - Intelligent context assembly\n   - Format adaptation for Claude Code\n   - Citation tracking\n\n5. **Response Generation**\n   - Integration with Claude Haiku (fast, accurate)\n   - Streaming responses for better UX\n   - Automatic citation injection\n   - Configurable output formatting\n\n### Architecture Highlights\n\n**Local Processing:**\n- All document processing happens locally\n- No sensitive data sent to external services\n- Full privacy and security\n- Offline-capable (after initial indexing)\n\n**Performance Optimized:**\n- ChromaDB vector store with HNSW indexing (industry standard)\n- Batch processing for throughput\n- Async operations for responsiveness\n- Memory-efficient chunking\n\n**Production Ready:**\n- Comprehensive error handling\n- Graceful degradation on failures\n- Detailed logging and monitoring\n- Multi-agent orchestration for complex queries\n\n### Technology Stack\n\n```\nFrontend: Claude Code Plugin\n  |\nIntegration Layer: MCP Server + Hooks + Slash Commands\n  |\nRetrieval: Hybrid Search Pipeline\n  |\nML/AI:\n  - Embeddings: Sentence Transformers (all-MiniLM-L6-v2)\n  - Reranking: Cross-encoder (ms-marco-MiniLM-L-6-v2)\n  - Storage: ChromaDB (with HNSW indexing)\n\nDocument Processing:\n  - Parsing: LangChain + BeautifulSoup + PyPDF2 + python-docx\n  - Chunking: Semantic boundary detection\n  - Metadata: Automatic extraction\n\nLLM Integration:\n  - Model: Claude Haiku (via Anthropic API)\n  - When plugin: Claude Code internal processing\n  - Streaming: For better perceived performance\n\nMonitoring:\n  - Structured Logging: structlog\n  - Metrics: Prometheus-compatible\n  - TCP Server: Real-time status monitoring\n```\n\n## Use Cases\n\n### For Software Development Teams\n\n**API Integration**\n- Auto-complete API calls with context\n- Validate parameters against documentation\n- Get usage examples from your code\n\n**Bug Fixing**\n- Search error messages in documentation\n- Find related issues in your codebase\n- Get debugging hints from best practices\n\n**Code Review**\n- Check against project standards automatically\n- Retrieve relevant architectural patterns\n- Validate against best practices\n\n### For Documentation\n\n**Knowledge Base**\n- Keep team documentation synchronized\n- Instantly query your knowledge base\n- Reduce \"How do I...\" questions\n\n**Onboarding**\n- New developers get context-aware help\n- Questions answered with your actual docs\n- 50% faster ramp-up time\n\n### For Research and Learning\n\n**Continuous Learning**\n- Search your learning materials instantly\n- Get context from multiple sources\n- Connect related concepts automatically\n\n**Knowledge Synthesis**\n- Combine insights from multiple documents\n- Get connections between topics\n- Build comprehensive understanding faster\n\n## Operation Modes\n\nRAG-CLI supports three operation modes:\n\n### 1. Claude Code Mode (Default)\n- **No API key required**\n- Automatically detected when running as Claude Code plugin\n- Returns formatted context for Claude's internal processing\n- Optimal performance with zero API costs\n\n### 2. Standalone Mode\n- Requires Anthropic API key\n- Direct API calls to Claude\n- Full control over model parameters\n- Useful for testing and development\n\n### 3. Hybrid Mode\n- Auto-detects environment\n- Uses Claude Code when available\n- Falls back to API when needed\n- Maximum flexibility\n\nSet mode via environment variable:\n```bash\nexport RAG_CLI_MODE=\"claude_code\"  # or \"standalone\" or \"hybrid\"\n```\n\n## Architecture\n\n### System Components\n\n```\nRAG-CLI/\n src/\n    core/               # Core RAG pipeline\n       constants.py    # Global configuration constants\n       embeddings.py   # Sentence transformer integration\n       vector_store.py # ChromaDB vector operations\n       document_processor.py # Document chunking\n       retrieval_pipeline.py # Hybrid search\n       claude_integration.py # Claude API interface\n   \n    monitoring/         # Observability\n       logger.py      # Structured logging\n       tcp_server.py  # Monitoring server\n   \n    plugin/            # Claude Code integration\n        skills/        # Agent skills\n        commands/      # Slash commands\n        hooks/         # Event hooks\n        mcp/           # MCP server\n\n scripts/               # CLI utilities\n tests/                 # Test suites\n data/                  # Documents and vectors\n config/                # Configuration files\n```\n\n### Data Flow\n\n1. **Document Processing**: Documents -> Chunks (400-500 tokens) -> Metadata extraction\n2. **Embedding Generation**: Chunks -> sentence-transformers -> 384-dim vectors\n3. **Vector Storage**: Embeddings -> ChromaDB with HNSW indexing -> Persistent storage\n4. **Retrieval**: Query -> Hybrid search -> Reranking -> Top-K results\n5. **Response Generation**: Context + Query -> Claude Haiku -> AI response\n\n## Configuration\n\n### Core Settings (`config/default.yaml`)\n\n```yaml\n# Operation Mode\nmode:\n  operation: hybrid     # claude_code, standalone, or hybrid\n  claude_code:\n    format_context: true\n    include_metadata: true\n    max_context_length: 10000\n\n# Embeddings\nembeddings:\n  model_name: sentence-transformers/all-MiniLM-L6-v2\n  model_dim: 384\n  batch_size: 32\n  cache_enabled: true\n\n# Vector Store\nvector_store:\n  type: chromadb\n  index_type: hnsw    # ChromaDB uses HNSW for efficient similarity search\n  save_path: data/vectors\n\n# Retrieval\nretrieval:\n  top_k: 5\n  hybrid_ratio: 0.7   # 70% vector, 30% keyword\n  rerank: true\n  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2\n\n# Claude (for standalone mode)\nclaude:\n  model: claude-haiku-4-5-20251001\n  max_tokens: 4096\n  temperature: 0.7\n  api_key_env: ANTHROPIC_API_KEY  # Only needed for standalone\n```\n\n### Security Best Practices\n\n**Environment Variable Protection:**\n\n1. **Never Commit .env Files**: The `.env` file contains sensitive API keys and should NEVER be committed to version control\n   - Already included in `.gitignore`\n   - Use `config/templates/.env.template` as a reference\n\n2. **File Permissions**: On Unix systems, ensure `.env` has restricted permissions:\n   ```bash\n   chmod 600 .env  # Read/write for owner only\n   ```\n\n3. **API Key Storage**:\n   - Store all API keys in `.env` file only\n   - Never hardcode keys in source code\n   - Use environment variables via `os.getenv()`\n\n4. **Subprocess Security**: RAG-CLI automatically sanitizes environment variables when spawning subprocesses, removing sensitive keys like:\n   - `ANTHROPIC_API_KEY`\n   - `TAVILY_API_KEY`\n   - `OPENAI_API_KEY`\n\n5. **Configuration Files**: User-specific configurations in `config/` are gitignored. Only default templates in `config/defaults/` and `config/templates/` are version controlled.\n\n## Claude Code Plugin\n\n### Slash Commands\n\n- `/search [query]` - Search indexed documents\n- `/rag-enable` - Enable automatic RAG enhancement\n- `/rag-disable` - Disable automatic RAG enhancement\n- `/rag-project` - Analyze current project and index relevant documentation\n- `/update-rag` - Synchronize RAG-CLI plugin files\n\n### Agent Skills\n\nAccess the RAG retrieval skill:\n```\n/skill rag-retrieval \"Your question here\"\n```\n\n### Hooks\n\nRAG-CLI includes several hooks that enhance your Claude Code experience:\n\n1. **Slash Command Blocker** (Priority 150) - Prevents Claude from responding to slash commands, showing only execution status\n2. **User Prompt Submit** (Priority 100) - Automatically enhances queries with RAG context and multi-agent orchestration\n3. **Response Post** (Priority 80) - Adds inline citations to Claude responses when RAG context is used\n4. **Error Handler** (Priority 70) - Provides graceful error handling with helpful troubleshooting tips\n5. **Plugin State Change** (Priority 60) - Persists RAG settings across Claude Code restarts\n6. **Document Indexing** (Priority 50, disabled by default) - Automatically indexes new or modified documents\n\n### Multi-Agent Orchestration\n\nRAG-CLI integrates with the Multi-Agent Framework (MAF) to provide intelligent query routing:\n\n- **RAG Only**: Simple document retrieval queries\n- **MAF Only**: Pure code analysis and debugging tasks\n- **Parallel RAG+MAF**: Complex queries combining documentation and code analysis\n- **Decomposed**: Multi-part queries with intelligent sub-query distribution\n\nThe orchestrator automatically selects the best strategy based on query intent, providing faster and more accurate responses.\n\n### Clean Output Formatting\n\nRAG-CLI provides structured, readable output for all operations:\n\n**Search Results Example:**\n```\n# RAG Search Results\n\n## Retrieval Results\nFound: 5 relevant documents\nTime: 145ms\n\n## Retrieved Documents\n**1. Getting Started Guide (score: 0.890)**\n> This guide will help you get started with the installation process...\n\n**2. Configuration Reference (score: 0.870)**\n> The configuration file allows you to customize various aspects...\n```\n\n**Orchestration Output Example:**\n```\n## Query Processing\n**Strategy:** parallel\n**Intent:** troubleshooting\n**Confidence:** 87.5%\n**Documents:** 3\n**MAF Agent:** debugger\n```\n\nThe formatting system provides:\n- Clean markdown headers for each stage\n- Performance metrics (time, document count, confidence scores)\n- Document previews with intelligent truncation\n- Progress indicators for multi-step operations\n- Collapsible sections for detailed logs (when verbose mode enabled)\n\n## API Reference\n\n### Document Indexing\n\n```python\nfrom src.core.document_processor import get_document_processor\nfrom src.core.embeddings import get_embedding_model\nfrom src.core.vector_store import get_vector_store\n\n# Process documents\nprocessor = get_document_processor()\ndocuments = processor.process_directory(\"data/documents\")\n\n# Generate embeddings\nmodel = get_embedding_model()\nembeddings = model.encode_batch([doc[\"content\"] for doc in documents])\n\n# Store vectors\nstore = get_vector_store()\nstore.add_documents(documents, embeddings)\n```\n\n### Document Retrieval\n\n```python\nfrom src.core.retrieval_pipeline import HybridRetriever\n\n# Initialize retriever\nretriever = HybridRetriever(vector_store, embedding_model, config)\n\n# Search\nresults = retriever.search(\"Your query\", top_k=5)\n```\n\n### Claude Integration\n\n```python\nfrom src.core.claude_integration import ClaudeAssistant\n\n# Initialize assistant\nassistant = ClaudeAssistant(config)\n\n# Generate response\nresponse = assistant.generate_response(query, retrieved_docs)\n```\n\n## Monitoring\n\n### TCP Server Interface\n\nThe monitoring server runs on port 9999 and accepts these commands:\n\n- `STATUS` - System health and statistics\n- `METRICS` - Performance metrics\n- `LOGS` - Recent log entries\n- `HEALTH` - Health check status\n\n### PowerShell Usage\n\n```powershell\n# Check status\n./scripts/monitor.ps1 -Command STATUS\n\n# View metrics\n./scripts/monitor.ps1 -Command METRICS\n```\n\n### Python Client\n\n```python\nimport socket\nimport json\n\ndef query_monitor(command):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((\"localhost\", 9999))\n        s.send(command.encode())\n        response = s.recv(4096).decode()\n        return json.loads(response)\n\nstatus = query_monitor(\"STATUS\")\nprint(status)\n```\n\n## Performance\n\n### Benchmarks\n\n| Operation | Target | Typical |\n|-----------|--------|---------|\n| Vector Search | <100ms | 45ms |\n| End-to-End | <5s | 3.2s |\n| Embedding Generation | <500ms | 200ms |\n| Document Processing | 0.5s/100 docs | 0.4s/100 docs |\n\n### Optimization Tips\n\n1. **Large Datasets** (>100K docs): Use HNSW index instead of Flat\n2. **Memory Constraints**: Enable document streaming\n3. **Faster Search**: Reduce top_k and disable reranking\n4. **Better Accuracy**: Increase hybrid_ratio for more semantic search\n\n## Testing\n\n### Run Tests\n\n```bash\n# Run all tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test\npytest tests/test_core.py::TestEmbeddings\n```\n\n### Test Coverage\n\n- Unit tests for all core modules\n- Integration tests for full pipeline\n- Performance benchmarks\n- Plugin component validation\n\n## Troubleshooting\n\n### Common Issues\n\n**No results found**:\n- Ensure documents are indexed: `ls data/vectors/`\n- Lower similarity threshold: `--threshold 0.5`\n- Check document processing logs\n\n**Slow performance**:\n- Reduce top_k parameter\n- Enable caching in configuration\n- Use HNSW index for large datasets\n\n**API errors** (Standalone mode only):\n- Verify ANTHROPIC_API_KEY is set\n- Check rate limits\n- Switch to Claude Code mode if running as plugin\n- Review logs: `tail -f logs/rag_cli.log`\n\n**Mode detection issues**:\n- Check current mode: `python -c \"from src.core.claude_code_adapter import get_adapter; print(get_adapter().get_mode_info())\"`\n- Force mode: `export RAG_CLI_MODE=\"claude_code\"`\n- Verify .claude directory exists for Claude Code\n\n### Debug Mode\n\n```bash\nexport RAG_CLI_LOG_LEVEL=DEBUG\npython scripts/retrieve.py \"test query\" --verbose\n```\n\n## Development\n\n### Project Structure\n\n- `src/core/` - Core RAG components (includes `constants.py` for centralized configuration)\n- `src/monitoring/` - Logging and metrics\n- `src/plugin/` - Claude Code integration\n- `scripts/` - CLI utilities\n- `tests/` - Test suites\n- `config/` - Configuration files\n\n### Configuration via Constants\n\nRAG-CLI uses a centralized constants module (`core.constants`) for all tunable parameters:\n- **Performance**: Batch sizes, worker counts, cache sizes\n- **Search**: Top-K limits, hybrid search weights, query length limits\n- **Processing**: Chunk sizes, overlap ratios, file size limits\n- **Thresholds**: Vector store index transitions (Flat -> HNSW -> IVF)\n- **Timeouts**: HTTP, embedding generation, search operations\n\nThis design makes it easy to tune performance without modifying code throughout the codebase.\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Add tests for new functionality\n4. Ensure all tests pass\n5. Submit a pull request\n\n### Code Style\n\n- Follow PEP 8 guidelines\n- Use type hints\n- Add docstrings to all functions\n- Run `black` for formatting\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Support\n\n- GitHub Issues: [Report bugs](https://github.com/ItMeDiaTech/rag-cli/issues)\n- Known Issues: [KNOWN_ISSUES.md](KNOWN_ISSUES.md) - Current limitations and workarounds\n- Documentation: [Wiki](https://github.com/ItMeDiaTech/rag-cli/wiki)\n- Discussions: [Community forum](https://github.com/ItMeDiaTech/rag-cli/discussions)\n- Security: [SECURITY.md](SECURITY.md) - API key management and security best practices\n\n## Acknowledgments\n\n- [Sentence Transformers](https://www.sbert.net/) for embedding models\n- [ChromaDB](https://www.trychroma.com/) for vector database with HNSW indexing\n- [Anthropic](https://www.anthropic.com/) for Claude API\n- [LangChain](https://langchain.com/) for document processing\n\n---\n\nBuilt with focus on performance, accuracy, and developer experience.\n",
        "docs/README.md": "# RAG-CLI Documentation\n\nThis directory contains detailed documentation for RAG-CLI development and architecture.\n\n## Contents\n\n- **V2_RESTRUCTURING_SUMMARY.md** - Complete summary of the v1.x to v2.0 restructuring\n  - Dual-package architecture\n  - Import structure changes\n  - Configuration organization\n  - Lifecycle management system\n  - Migration impact and benefits\n\n## Main Documentation\n\nFor user-facing documentation, see the main repository:\n\n- **README.md** - Project overview, installation, and usage\n- **CHANGELOG.md** - Version history and release notes\n- **CONTRIBUTING.md** - Guidelines for contributors\n- **CLAUDE.md** - Claude Code integration instructions\n\n## Additional Resources\n\n- Configuration examples: `config/templates/`\n- Configuration schemas: `config/schemas/`\n- Installation scripts: `scripts/install/`\n- Utility scripts: `scripts/utils/`\n",
        "src/rag_cli_plugin/commands/rag-disable.md": "# Disable RAG\n\nUpdate config to disable automatic RAG enhancement.\n\n**IMPORTANT**: Execute task and report status only. No additional commentary.\n\n## Task\n\n1. Update `config/rag_settings.json`: set `\"enabled\": false`\n2. Report: \"RAG disabled\"\n\n**DO NOT**:\n- Explain when to disable RAG\n- Describe what changes\n- Provide usage examples\n- Research or elaborate\n\n**ONLY**:\n- Update the config file\n- Confirm completion with one line\n- Stop",
        "src/rag_cli_plugin/commands/rag-enable.md": "# Enable RAG\n\nUpdate config to enable automatic RAG enhancement.\n\n**IMPORTANT**: Execute task and report status only. No additional commentary.\n\n## Task\n\n1. Update `config/rag_settings.json`: set `\"enabled\": true`\n2. Report: \"RAG enabled\"\n\n**DO NOT**:\n- Explain what RAG is\n- Describe benefits or features\n- Provide usage examples\n- Research or elaborate\n\n**ONLY**:\n- Update the config file\n- Confirm completion with one line\n- Stop",
        "src/rag_cli_plugin/commands/rag-maf-config.md": "# /rag-maf-config\n\nConfigure embedded Multi-Agent Framework (MAF) features for RAG-CLI.\n\n## Usage\n\n```\n/rag-maf-config [OPTION]\n```\n\n## Options\n\n- `status` - Show current MAF configuration and agent status\n- `enable` - Enable MAF parallel execution\n- `disable` - Disable MAF (RAG-only mode)\n- `test-connection` - Test MAF connector health\n- `list-agents` - List available agents\n- `set-mode PARALLEL|SEQUENTIAL` - Set execution mode\n\n## Examples\n\n### Check MAF Status\n```\n/rag-maf-config status\n```\n\n### Enable MAF Features\n```\n/rag-maf-config enable\n```\n\n### Disable MAF (Fallback to RAG-only)\n```\n/rag-maf-config disable\n```\n\n### Test MAF Connectivity\n```\n/rag-maf-config test-connection\n```\n\n### List Available Agents\n```\n/rag-maf-config list-agents\n```\n\n### Set Execution Mode\n```\n/rag-maf-config set-mode PARALLEL\n```\n\n## Output\n\nWhen successful, displays:\n- [OK] MAF Status (enabled/disabled)\n- Available Agents (7 total: debugger, developer, reviewer, tester, architect, documenter, optimizer)\n- Execution Strategy (parallel/sequential)\n- Timeout Configuration\n- Health Check Results\n\n## Notes\n\n- MAF is **enabled by default** with parallel execution\n- Disabling MAF falls back gracefully to **RAG-only mode**\n- All 7 agents are embedded within the plugin\n- Parallel execution runs RAG + MAF simultaneously for comprehensive results\n- No external dependencies required for MAF functionality\n\n## IMPORTANT: Execute only, no commentary\n",
        "src/rag_cli_plugin/commands/rag-project.md": "# RAG Project Indexer\n\nAnalyze current project and index relevant documentation.\n\n**IMPORTANT**: Execute indexer and show summary only. No additional commentary.\n\n## Task\n\nRun: `python ${CLAUDE_PLUGIN_ROOT}/src/plugin/commands/rag_project_indexer.py [ARGS]`\n\nShow the indexing summary output only.\n\n**DO NOT**:\n- Explain the project analysis process\n- Describe what will be indexed\n- Provide examples or troubleshooting\n- Add commentary before or after output\n\n**ONLY**:\n- Execute the command with any user-provided args\n- Display the output\n- Stop\n",
        "src/rag_cli_plugin/commands/search.md": "# RAG Document Search\n\nExecute the retrieval script and return results only.\n\n**IMPORTANT**: Run the command, show output, then STOP. Do NOT provide commentary, explanations, or additional research.\n\n## Execution\n\nRun: `python scripts/retrieve.py --query \"[USER_QUERY]\"`\n\nDisplay the output exactly as returned. Do not add any additional text before or after the output.\n\n**DO NOT**:\n- Explain how the command works\n- Provide additional context or suggestions\n- Research related topics\n- Offer troubleshooting advice unless the command fails\n- Describe what you're about to do\n\n**ONLY**:\n- Execute the command\n- Show the raw output\n- Stop",
        "src/rag_cli_plugin/commands/update-rag.md": "# Update RAG Plugin\n\nSynchronize RAG-CLI plugin files.\n\n**IMPORTANT**: Execute sync and show summary only. No additional commentary.\n\n## Task\n\nRun: `python scripts/sync_plugin.py [ARGS]`\n\nShow the sync summary output only.\n\n**DO NOT**:\n- Explain what will be synced\n- Describe the sync process\n- Provide examples or troubleshooting\n- Add commentary before or after output\n\n**ONLY**:\n- Execute the command with any user-provided args\n- Display the output\n- Stop\n",
        "src/rag_cli_plugin/hooks/__init__.py": "\"\"\"RAG-CLI Plugin Hooks Module.\n\nContains all hooks for RAG-CLI Claude Code plugin lifecycle management.\n\"\"\"\n",
        "src/rag_cli_plugin/hooks/document-indexing.py": "#!/usr/bin/env python3\n\"\"\"DocumentIndexing hook for RAG-CLI.\n\nThis hook watches for file changes and automatically indexes new/modified documents\ninto the RAG knowledge base.\n\nMetadata:\n  priority: 50\n  enabled: False  # Disabled by default, enable via configuration\n  triggers: [\"file_created\", \"file_modified\"]\n\"\"\"\n\nimport sys\nimport os\nimport json\nimport time\nimport asyncio\nfrom pathlib import Path\nfrom typing import Dict, Any\nfrom datetime import datetime\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Import path resolution utilities (relative import for hook context)\ntry:\n    from path_utils import setup_sys_path\nexcept ImportError:\n    # Fallback for absolute import if relative fails\n    import importlib.util\n    hook_dir = Path(__file__).parent\n    path_utils_path = hook_dir / 'path_utils.py'\n    spec = importlib.util.spec_from_file_location('path_utils', path_utils_path)\n    path_utils = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(path_utils)\n    setup_sys_path = path_utils.setup_sys_path\n\n# Set up sys.path before importing other modules\nproject_root = setup_sys_path()\n\nfrom rag_cli.core.config import get_config\nfrom rag_cli.core.document_processor import DocumentProcessor\nfrom rag_cli.core.vector_store import get_vector_store\nfrom rag_cli.core.embeddings import get_embedding_generator\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\n# Configuration file\nCONFIG_FILE = project_root / \"config\" / \"auto_indexing.json\"\n\n# Debounce tracking\n_pending_files: Dict[str, float] = {}  # file_path -> last_modified_time\n_debounce_interval = 5.0  # seconds\n\ndef load_auto_indexing_config() -> Dict[str, Any]:\n    \"\"\"Load auto-indexing configuration.\n\n    Returns:\n        Configuration dictionary\n    \"\"\"\n    default_config = {\n        \"enabled\": False,\n        \"watch_patterns\": [\n            \"docs/**/*.md\",\n            \"README.md\",\n            \"*.txt\",\n            \"*.rst\"\n        ],\n        \"exclude_patterns\": [\n            \"node_modules/**\",\n            \".git/**\",\n            \"venv/**\",\n            \"__pycache__/**\",\n            \"*.pyc\",\n            \".env\"\n        ],\n        \"debounce_ms\": 5000,\n        \"supported_formats\": [\".md\", \".txt\", \".rst\", \".pdf\", \".docx\"],\n        \"max_file_size_mb\": 10\n    }\n\n    try:\n        if CONFIG_FILE.exists():\n            with open(CONFIG_FILE, 'r') as f:\n                user_config = json.load(f)\n                # Merge with defaults\n                return {**default_config, **user_config}\n        return default_config\n    except Exception as e:\n        logger.error(f\"Failed to load auto-indexing config: {e}\")\n        return default_config\n\ndef should_index_file(file_path: Path, config: Dict[str, Any]) -> bool:\n    \"\"\"Check if file should be indexed.\n\n    Args:\n        file_path: Path to file\n        config: Auto-indexing configuration\n\n    Returns:\n        True if file should be indexed\n    \"\"\"\n    # Check file extension\n    supported_formats = config.get(\"supported_formats\", [])\n    if file_path.suffix not in supported_formats:\n        return False\n\n    # Check file size\n    max_size = config.get(\"max_file_size_mb\", 10) * 1024 * 1024  # Convert to bytes\n    try:\n        if file_path.stat().st_size > max_size:\n            logger.warning(f\"File too large to index: {file_path} ({file_path.stat().st_size / 1024 / 1024:.2f} MB)\")\n            return False\n    except (OSError, PermissionError):\n        return False\n\n    # Check exclude patterns\n    exclude_patterns = config.get(\"exclude_patterns\", [])\n    file_str = str(file_path)\n    for pattern in exclude_patterns:\n        import fnmatch\n        if fnmatch.fnmatch(file_str, pattern):\n            logger.debug(f\"File excluded by pattern {pattern}: {file_path}\")\n            return False\n\n    return True\n\nasync def index_file(file_path: Path) -> bool:\n    \"\"\"Index a single file into the knowledge base.\n\n    Args:\n        file_path: Path to file to index\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        logger.info(f\"Indexing file: {file_path}\")\n\n        # Initialize components\n        config = get_config()\n        processor = DocumentProcessor(config)\n        vector_store = get_vector_store()\n        embedding_generator = get_embedding_generator()\n\n        # Read and process document\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n\n        # Process into chunks\n        chunks = processor.process_text(\n            text=content,\n            source=str(file_path),\n            metadata={\n                'filename': file_path.name,\n                'file_type': file_path.suffix,\n                'indexed_at': datetime.now().isoformat()\n            }\n        )\n\n        if not chunks:\n            logger.warning(f\"No chunks generated from file: {file_path}\")\n            return False\n\n        # Generate embeddings\n        texts = [chunk.text for chunk in chunks]\n        embeddings = embedding_generator.generate_batch(texts)\n\n        # Add to vector store\n        vector_store.add_documents(chunks, embeddings)\n\n        logger.info(f\"Successfully indexed {len(chunks)} chunks from {file_path}\")\n        return True\n\n    except Exception as e:\n        logger.error(f\"Failed to index file {file_path}: {e}\")\n        return False\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process DocumentIndexing hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event\n    \"\"\"\n    try:\n        # Load configuration\n        config = load_auto_indexing_config()\n\n        # Check if auto-indexing is enabled\n        if not config.get(\"enabled\", False):\n            logger.debug(\"Auto-indexing disabled, skipping\")\n            return event\n\n        # Extract event data\n        event_type = event.get('event_type', '')\n        file_path_str = event.get('file_path', '')\n        event.get('project_path', '')\n\n        if not file_path_str:\n            logger.warning(\"No file path in event\")\n            return event\n\n        file_path = Path(file_path_str)\n\n        # Check if file should be indexed\n        if not should_index_file(file_path, config):\n            logger.debug(f\"File not eligible for indexing: {file_path}\")\n            return event\n\n        # Debounce: Check if file was recently modified\n        current_time = time.time()\n        debounce_interval = config.get(\"debounce_ms\", 5000) / 1000.0  # Convert to seconds\n\n        if file_path_str in _pending_files:\n            last_time = _pending_files[file_path_str]\n            if current_time - last_time < debounce_interval:\n                logger.debug(f\"File change debounced: {file_path}\")\n                return event\n\n        # Update debounce tracking\n        _pending_files[file_path_str] = current_time\n\n        # Index the file asynchronously\n        logger.info(f\"Queueing file for indexing: {file_path}\")\n\n        # Run indexing (this is synchronous in the hook)\n        # For async, we'd need to use asyncio.create_task and return immediately\n        try:\n            loop = asyncio.get_event_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        success = loop.run_until_complete(index_file(file_path))\n\n        # Update event metadata\n        metadata = event.get('metadata', {})\n        metadata['auto_indexed'] = success\n        metadata['indexed_at'] = datetime.now().isoformat() if success else None\n        event['metadata'] = metadata\n\n        # Notify user\n        if success:\n            event['notification'] = f\"Indexed: {file_path.name}\"\n        else:\n            event['notification'] = f\"Failed to index: {file_path.name}\"\n\n        logger.info(\n            f\"Auto-indexing {'successful' if success else 'failed'}: {file_path}\",\n            event_type=event_type\n        )\n\n    except Exception as e:\n        logger.error(f\"Document indexing hook failed: {e}\")\n        # Return original event on error\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/error-handler.py": "#!/usr/bin/env python3\n\"\"\"ErrorHandler hook for RAG-CLI.\n\nThis hook provides graceful degradation when RAG operations fail,\nshowing inline warnings with fix instructions (no emojis).\n\nMetadata:\n  priority: 70\n  enabled: True\n  triggers: [\"error_occurred\"]\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Import path resolution utilities (relative import for hook context)\ntry:\n    from path_utils import setup_sys_path\nexcept ImportError:\n    # Fallback for absolute import if relative fails\n    import importlib.util\n    hook_dir = Path(__file__).parent\n    path_utils_path = hook_dir / 'path_utils.py'\n    spec = importlib.util.spec_from_file_location('path_utils', path_utils_path)\n    path_utils = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(path_utils)\n    setup_sys_path = path_utils.setup_sys_path\n\n# Set up sys.path before importing other modules\nsetup_sys_path()\n\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\n# Error type classification\nRAG_ERROR_TYPES = {\n    'VectorStoreNotFound': {\n        'message': 'RAG Enhancement Unavailable - Vector store not found',\n        'fix': 'Run /rag-project to index documents',\n        'severity': 'warning'\n    },\n    'ServiceUnavailable': {\n        'message': 'RAG Enhancement Unavailable - Service not running',\n        'fix': 'Check if RAG services are running with /rag-status',\n        'severity': 'warning'\n    },\n    'TimeoutError': {\n        'message': 'RAG Enhancement Timeout - Retrieval took too long',\n        'fix': 'Try reducing context_limit in configuration',\n        'severity': 'warning'\n    },\n    'EmbeddingError': {\n        'message': 'RAG Enhancement Unavailable - Embedding generation failed',\n        'fix': 'Check embedding model configuration',\n        'severity': 'error'\n    },\n    'QueryClassificationError': {\n        'message': 'Query classification failed',\n        'fix': 'Query will proceed without classification',\n        'severity': 'info'\n    },\n    'IndexingError': {\n        'message': 'Document indexing failed',\n        'fix': 'Check document format and try again',\n        'severity': 'error'\n    },\n    'ConfigurationError': {\n        'message': 'RAG configuration invalid',\n        'fix': 'Check config/rag_settings.json for errors',\n        'severity': 'error'\n    }\n}\n\ndef classify_error(error: Dict[str, Any]) -> str:\n    \"\"\"Classify error type from error object.\n\n    Args:\n        error: Error dictionary with type and message\n\n    Returns:\n        Error type classification\n    \"\"\"\n    error_type = error.get('type', '')\n    error_message = str(error.get('message', '')).lower()\n\n    # Check explicit type\n    if error_type in RAG_ERROR_TYPES:\n        return error_type\n\n    # Pattern matching on error message\n    if 'vector store' in error_message or 'faiss' in error_message:\n        return 'VectorStoreNotFound'\n    elif 'service' in error_message or 'connection' in error_message:\n        return 'ServiceUnavailable'\n    elif 'timeout' in error_message:\n        return 'TimeoutError'\n    elif 'embedding' in error_message:\n        return 'EmbeddingError'\n    elif 'classification' in error_message or 'classifier' in error_message:\n        return 'QueryClassificationError'\n    elif 'index' in error_message:\n        return 'IndexingError'\n    elif 'config' in error_message:\n        return 'ConfigurationError'\n\n    # Default to generic service error\n    return 'ServiceUnavailable'\n\ndef format_error_message(error_type: str, context: Dict[str, Any]) -> str:\n    \"\"\"Format error message for display.\n\n    Args:\n        error_type: Classified error type\n        context: Error context information\n\n    Returns:\n        Formatted error message (no emojis)\n    \"\"\"\n    error_info = RAG_ERROR_TYPES.get(error_type, {\n        'message': 'RAG Enhancement Error',\n        'fix': 'Please check RAG configuration',\n        'severity': 'error'\n    })\n\n    # Build message\n    lines = [\n        \"\",\n        \"=\" * 60,\n        f\"RAG NOTICE: {error_info['message']}\",\n        \"-\" * 60,\n    ]\n\n    # Add context if available\n    hook_name = context.get('hook', 'Unknown')\n    if hook_name:\n        lines.append(f\"Hook: {hook_name}\")\n\n    query = context.get('query', '')\n    if query:\n        lines.append(f\"Query: {query[:100]}...\")\n\n    # Add fix instruction\n    lines.append(\"\")\n    lines.append(f\"How to fix: {error_info['fix']}\")\n\n    # Add footer\n    lines.append(\"-\" * 60)\n    lines.append(\"Your query will proceed without RAG enhancement.\")\n    lines.append(\"=\" * 60)\n    lines.append(\"\")\n\n    return \"\\n\".join(lines)\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process ErrorHandler hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event with error handling\n    \"\"\"\n    try:\n        error = event.get('error', {})\n        context = event.get('context', {})\n\n        # Classify error\n        error_type = classify_error(error)\n        severity = RAG_ERROR_TYPES.get(error_type, {}).get('severity', 'error')\n\n        # Log error\n        logger.error(\n            f\"RAG error occurred: {error_type}\",\n            error_message=error.get('message'),\n            hook=context.get('hook'),\n            severity=severity\n        )\n\n        # Format error message\n        error_message = format_error_message(error_type, context)\n\n        # Add warning to event\n        # Different hooks handle warnings differently\n        if context.get('hook') == 'UserPromptSubmit':\n            # Prepend warning to prompt\n            original_prompt = event.get('prompt', '')\n            event['prompt'] = error_message + \"\\n\" + original_prompt\n\n        # Store error info in metadata\n        metadata = event.get('metadata', {})\n        metadata['rag_error'] = {\n            'type': error_type,\n            'severity': severity,\n            'handled': True\n        }\n        event['metadata'] = metadata\n\n        # Mark that error was handled\n        event['error_handled'] = True\n\n        logger.info(f\"Error handled gracefully: {error_type}\")\n\n    except Exception as e:\n        logger.error(f\"Error handler failed: {e}\")\n        # Return original event on error\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/event_validator.py": "#!/usr/bin/env python3\n\"\"\"Event validation utilities for RAG-CLI hooks.\n\nThis module provides JSON schema validation for hook events to prevent\ncrashes on malformed input.\n\"\"\"\n\nfrom typing import Dict, Any, Optional\nimport logging\n\nclass EventValidator:\n    \"\"\"Validates hook event structures.\"\"\"\n\n    # Event type schemas\n    SCHEMAS = {\n        'UserPromptSubmit': {\n            'required': ['type', 'metadata'],\n            'metadata_required': ['rag_enabled'],\n        },\n        'ResponsePost': {\n            'required': ['type', 'metadata'],\n            'metadata_required': [],\n        },\n        'PluginStateChange': {\n            'required': ['type', 'metadata'],\n            'metadata_required': ['plugin_name', 'state_change'],\n        },\n        'DocumentIndexing': {\n            'required': ['type', 'metadata'],\n            'metadata_required': ['file_path'],\n        },\n        'ErrorOccurred': {\n            'required': ['type', 'metadata'],\n            'metadata_required': ['error_message'],\n        },\n    }\n\n    @staticmethod\n    def validate_event(event: Dict[str, Any], event_type: Optional[str] = None) -> tuple[bool, str]:\n        \"\"\"Validate an event against its schema.\n\n        Args:\n            event: Event dictionary to validate\n            event_type: Expected event type. If None, extracted from event['type']\n\n        Returns:\n            Tuple of (is_valid, error_message)\n            - is_valid: True if event is valid, False otherwise\n            - error_message: Detailed error message if invalid, empty string if valid\n        \"\"\"\n        if not isinstance(event, dict):\n            return False, f\"Event must be a dictionary, got {type(event).__name__}\"\n\n        # Extract event type\n        if event_type is None:\n            event_type = event.get('type')\n\n        if not event_type:\n            return False, \"Event missing 'type' field\"\n\n        # Get schema for this event type\n        schema = EventValidator.SCHEMAS.get(event_type, {})\n\n        # Check required top-level fields\n        required_fields = schema.get('required', [])\n        for field in required_fields:\n            if field not in event:\n                return False, f\"Event missing required field: {field}\"\n\n        # Check metadata\n        metadata = event.get('metadata')\n        if metadata is None:\n            return False, \"Event metadata is None\"\n\n        if not isinstance(metadata, dict):\n            return False, f\"Event metadata must be a dictionary, got {type(metadata).__name__}\"\n\n        # Check required metadata fields\n        required_metadata = schema.get('metadata_required', [])\n        for field in required_metadata:\n            if field not in metadata:\n                return False, f\"Event metadata missing required field: {field}\"\n\n        return True, \"\"\n\n    @staticmethod\n    def validate_or_log(event: Dict[str, Any], logger: logging.Logger, event_type: Optional[str] = None) -> bool:\n        \"\"\"Validate an event and log any errors.\n\n        Args:\n            event: Event dictionary to validate\n            logger: Logger instance to use for error logging\n            event_type: Expected event type\n\n        Returns:\n            True if valid, False if invalid (error already logged)\n        \"\"\"\n        is_valid, error_msg = EventValidator.validate_event(event, event_type)\n\n        if not is_valid:\n            logger.error(f\"Invalid event structure: {error_msg}. Event: {event}\")\n            return False\n\n        return True\n\n    @staticmethod\n    def safe_get(event: Dict[str, Any], path: str, default: Any = None) -> Any:\n        \"\"\"Safely get nested dictionary values using dot notation.\n\n        Args:\n            event: Dictionary to query\n            path: Dot-separated path (e.g., 'metadata.rag_enabled')\n            default: Default value if path not found\n\n        Returns:\n            Value at path, or default if not found\n        \"\"\"\n        keys = path.split('.')\n        current = event\n\n        for key in keys:\n            if isinstance(current, dict):\n                current = current.get(key)\n                if current is None:\n                    return default\n            else:\n                return default\n\n        return current if current is not None else default\n",
        "src/rag_cli_plugin/hooks/path_utils.py": "#!/usr/bin/env python3\n\"\"\"Utility module for resolving RAG-CLI project root path.\n\nThis module provides a single source of truth for project root resolution\nacross all hook files, eliminating ~70 lines of duplicate code per hook.\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\ndef get_rag_cli_root(hook_file: Optional[Path] = None) -> Path:\n    \"\"\"Get RAG-CLI project root using multiple fallback strategies.\n\n    Tries the following in order:\n    1. RAG_CLI_ROOT environment variable (most explicit)\n    2. Walking up from current hook file location\n    3. Common installation locations\n    4. Relative to hook file location (last resort)\n\n    Args:\n        hook_file: Optional path to the hook file. If not provided, will try to detect from call stack.\n\n    Returns:\n        Path to RAG-CLI project root\n\n    Raises:\n        RuntimeError: If project root cannot be found after all strategies\n    \"\"\"\n    # Get the calling hook file location\n    if hook_file is None:\n        import inspect\n        try:\n            # Try to get from call stack (setup_sys_path -> hook)\n            stack = inspect.stack()\n            # Look for the hook file (not path_utils.py itself)\n            for frame_info in stack[1:]:\n                frame_file = Path(frame_info.filename).resolve()\n                if frame_file.name != 'path_utils.py' and 'hooks' in str(frame_file):\n                    hook_file = frame_file\n                    break\n            if hook_file is None:\n                # Fallback to caller's file\n                hook_file = Path(stack[2].filename).resolve()\n        except (IndexError, AttributeError):\n            # If inspection fails, try __file__ from path_utils itself\n            hook_file = Path(__file__).resolve()\n    \n    if not isinstance(hook_file, Path):\n        hook_file = Path(hook_file).resolve()\n    \n    project_root: Optional[Path] = None\n    \n    # Strategy 1: RAG_CLI_ROOT environment variable (most explicit)\n    rag_cli_root = os.environ.get('RAG_CLI_ROOT')\n    if rag_cli_root:\n        project_root = Path(rag_cli_root)\n        if project_root.exists() and (project_root / 'src' / 'rag_cli').exists():\n            return project_root\n    \n    # Strategy 2: Try to find project root by walking up from hook location\n    current = hook_file.parent\n    for _ in range(10):  # Search up to 10 levels\n        # Check if this is the RAG-CLI root (has src/rag_cli and src/rag_cli_plugin)\n        if (current / 'src' / 'rag_cli').exists() and (current / 'src' / 'rag_cli_plugin').exists():\n            project_root = current\n            break\n        # Also check legacy structure (src/core and src/monitoring)\n        if (current / 'src' / 'core').exists() and (current / 'src' / 'monitoring').exists():\n            project_root = current\n            break\n        current = current.parent\n    \n    # Strategy 3: Check common installation locations\n    if project_root is None:\n        # IMPORTANT: Skip marketplace cache during lifecycle hooks to prevent file locks\n        skip_marketplace = os.environ.get('CLAUDE_LIFECYCLE_HOOK') == 'true'\n\n        potential_paths = [\n            # Manual plugin installation location (check first)\n            Path.home() / '.claude' / 'plugins' / 'rag-cli',\n            # Relative to current working directory\n            Path.cwd(),\n        ]\n\n        # Only check marketplace cache if NOT in lifecycle hook\n        if not skip_marketplace:\n            # GitHub marketplace installation location (temporary cache)\n            potential_paths.insert(0, Path.home() / '.claude' / 'plugins' / 'marketplaces' / 'rag-cli')\n\n        for path in potential_paths:\n            if path.exists():\n                # Check for new structure\n                if (path / 'src' / 'rag_cli').exists() and (path / 'src' / 'rag_cli_plugin').exists():\n                    project_root = path\n                    break\n                # Check for legacy structure\n                if (path / 'src' / 'core').exists() and (path / 'src' / 'monitoring').exists():\n                    project_root = path\n                    break\n    \n    # Strategy 4: Last resort - relative to hook file location\n    if project_root is None:\n        # Try different parent levels based on hook location\n        # hooks are typically in src/rag_cli_plugin/hooks/\n        for levels_up in [3, 4, 5]:\n            try:\n                potential_root = hook_file.parents[levels_up - 1]\n                if (potential_root / 'src' / 'rag_cli').exists():\n                    project_root = potential_root\n                    break\n                if (potential_root / 'src' / 'core').exists():\n                    project_root = potential_root\n                    break\n            except IndexError:\n                continue\n    \n    # Validate that we found a valid project root\n    if project_root is None:\n        raise RuntimeError(\n            f\"Failed to locate RAG-CLI project root. Searched from: {hook_file}\\n\"\n            \"Please set RAG_CLI_ROOT environment variable to the project directory.\\n\"\n            \"Example: export RAG_CLI_ROOT=/path/to/RAG-CLI\"\n        )\n    \n    # Final validation\n    if not project_root.exists():\n        raise RuntimeError(\n            f\"RAG-CLI project root does not exist: {project_root}\\n\"\n            \"Please verify RAG_CLI_ROOT environment variable or installation.\"\n        )\n    \n    return project_root\n\n\ndef setup_sys_path(hook_file: Optional[Path] = None) -> Path:\n    \"\"\"Set up sys.path for RAG-CLI module imports.\n    \n    Finds the RAG-CLI project root and adds it (and src/) to sys.path\n    so that rag_cli and rag_cli_plugin modules can be imported.\n    \n    Args:\n        hook_file: Optional path to the hook file calling this function.\n                   If not provided, will try to detect from call stack.\n    \n    Returns:\n        Path to RAG-CLI project root\n        \n    Raises:\n        RuntimeError: If project root cannot be found\n    \"\"\"\n    # Get hook file from caller if not provided\n    if hook_file is None:\n        import inspect\n        try:\n            # Get the file that called setup_sys_path\n            caller_frame = inspect.stack()[1]\n            hook_file = Path(caller_frame.filename).resolve()\n        except (IndexError, AttributeError):\n            hook_file = None\n    \n    project_root = get_rag_cli_root(hook_file)\n    \n    # Add project root to sys.path (for editable installs)\n    root_str = str(project_root)\n    if root_str not in sys.path:\n        sys.path.insert(0, root_str)\n    \n    # Add src directory to sys.path (for package imports)\n    src_dir = project_root / 'src'\n    if src_dir.exists():\n        src_str = str(src_dir)\n        if src_str not in sys.path:\n            sys.path.insert(0, src_str)\n    \n    return project_root",
        "src/rag_cli_plugin/hooks/plugin-state-change.py": "#!/usr/bin/env python3\n\"\"\"PluginStateChange hook for RAG-CLI.\n\nThis hook handles plugin enable/disable events and persists settings\nacross Claude Code restarts.\n\nMetadata:\n  priority: 60\n  enabled: True\n  triggers: [\"plugin_enabled\", \"plugin_disabled\"]\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Set up project paths using centralized utility\nfrom rag_cli_plugin.hooks.path_utils import setup_sys_path\nproject_root = setup_sys_path(__file__)\n\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\n# Settings file\nSETTINGS_FILE = project_root / \"config\" / \"rag_settings.json\"\n\ndef load_settings() -> Dict[str, Any]:\n    \"\"\"Load RAG settings from file.\n\n    Returns:\n        Settings dictionary\n    \"\"\"\n    try:\n        if SETTINGS_FILE.exists():\n            with open(SETTINGS_FILE, 'r') as f:\n                return json.load(f)\n        else:\n            # Return defaults\n            return {\n                \"enabled\": True,\n                \"auto_trigger_threshold\": 5,\n                \"context_limit\": 3,\n                \"relevance_threshold\": 0.6,\n                \"exclude_patterns\": []\n            }\n    except Exception as e:\n        logger.error(f\"Failed to load settings: {e}\")\n        return {}\n\ndef save_settings(settings: Dict[str, Any]) -> bool:\n    \"\"\"Save RAG settings to file.\n\n    Args:\n        settings: Settings dictionary\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        SETTINGS_FILE.parent.mkdir(parents=True, exist_ok=True)\n        with open(SETTINGS_FILE, 'w') as f:\n            json.dump(settings, f, indent=2)\n        logger.info(\"Settings saved successfully\")\n        return True\n    except Exception as e:\n        logger.error(f\"Failed to save settings: {e}\")\n        return False\n\ndef initialize_resources() -> bool:\n    \"\"\"Initialize RAG resources (vector store, services, etc.).\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        # Check if vector store exists\n        from rag_cli.core.config import get_config\n\n        config = get_config()\n        index_path = Path(config.vector_store.save_path)\n\n        if not index_path.exists():\n            logger.warning(\"Vector store not found - will be created on first use\")\n            return True\n\n        # Try to load vector store to verify it's accessible\n        try:\n            from rag_cli.core.vector_store import get_vector_store\n            vector_store = get_vector_store()\n            doc_count = vector_store.count()\n            logger.info(f\"Vector store loaded: {doc_count} documents\")\n        except Exception as e:\n            logger.warning(f\"Could not load vector store: {e}\")\n\n        # Try to start monitoring services\n        try:\n            from rag_cli_plugin.services.service_manager import ensure_services_running\n            ensure_services_running()\n            logger.info(\"Monitoring services started\")\n        except Exception as e:\n            logger.warning(f\"Could not start monitoring services: {e}\")\n\n        return True\n\n    except Exception as e:\n        logger.error(f\"Resource initialization failed: {e}\")\n        return False\n\ndef cleanup_resources() -> bool:\n    \"\"\"Cleanup RAG resources on plugin disable.\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        # Clear cache\n        cache_dir = project_root / \"data\" / \"cache\"\n        if cache_dir.exists():\n            import shutil\n            try:\n                shutil.rmtree(cache_dir)\n                cache_dir.mkdir(parents=True, exist_ok=True)\n                logger.info(\"Cache cleared\")\n            except OSError as e:\n                logger.warning(f\"Failed to clear cache directory: {e}\")\n                # Don't fail entirely if cache cleanup fails\n\n        # Note: Don't stop monitoring services as they may be used by other sessions\n\n        return True\n\n    except Exception as e:\n        logger.error(f\"Resource cleanup failed: {e}\")\n        return False\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process PluginStateChange hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event\n    \"\"\"\n    try:\n        state_change = event.get('state_change', '')\n        plugin_name = event.get('plugin', '')\n        timestamp = event.get('timestamp', '')\n\n        logger.info(\n            f\"Plugin state change: {state_change}\",\n            plugin=plugin_name,\n            timestamp=timestamp\n        )\n\n        # Only process RAG-CLI events\n        if plugin_name != 'rag-cli':\n            return event\n\n        if state_change == 'enabled':\n            # Load settings\n            settings = load_settings()\n            logger.info(\"Settings loaded\", enabled=settings.get('enabled'))\n\n            # Initialize resources\n            if initialize_resources():\n                logger.info(\"RAG-CLI plugin enabled and initialized\")\n                event['initialization_status'] = 'success'\n            else:\n                logger.warning(\"RAG-CLI plugin enabled but initialization failed\")\n                event['initialization_status'] = 'partial'\n\n            # Store settings in event metadata\n            event['settings'] = settings\n\n        elif state_change == 'disabled':\n            # Save current settings\n            settings = load_settings()\n            save_settings(settings)\n\n            # Cleanup resources\n            if cleanup_resources():\n                logger.info(\"RAG-CLI plugin disabled and cleaned up\")\n                event['cleanup_status'] = 'success'\n            else:\n                logger.warning(\"RAG-CLI plugin disabled but cleanup failed\")\n                event['cleanup_status'] = 'partial'\n\n        # Mark event as processed\n        event['state_change_processed'] = True\n\n    except Exception as e:\n        logger.error(f\"State change hook failed: {e}\")\n        # Return original event on error\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/response-post.py": "#!/usr/bin/env python3\n\"\"\"ResponsePost hook for RAG citation injection.\n\nThis hook intercepts Claude's responses and adds inline citations [1][2]\nwhen the response was enhanced with RAG context.\n\nMetadata:\n  priority: 80\n  enabled: True\n  triggers: [\"response_generated\"]\n\"\"\"\n\nimport sys\nimport os\nimport json\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Optional\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Import path resolution utilities (relative import for hook context)\ntry:\n    from path_utils import setup_sys_path\nexcept ImportError:\n    # Fallback for absolute import if relative fails\n    import importlib.util\n    hook_dir = Path(__file__).parent\n    path_utils_path = hook_dir / 'path_utils.py'\n    spec = importlib.util.spec_from_file_location('path_utils', path_utils_path)\n    path_utils = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(path_utils)\n    setup_sys_path = path_utils.setup_sys_path\n\n# Set up sys.path before importing other modules\nproject_root = setup_sys_path()\n\nfrom rag_cli_plugin.services.logger import get_logger\nfrom rag_cli.core.constants import RESPONSE_CACHE_TTL_SECONDS\n\nlogger = get_logger(__name__)\n\n# Cache file for retrieval results\nCACHE_DIR = project_root / \"data\" / \"cache\"\nCACHE_DIR.mkdir(parents=True, exist_ok=True)\n\ndef get_cache_key(session_id: str, prompt: str) -> str:\n    \"\"\"Generate cache key from session ID and prompt.\n\n    Args:\n        session_id: Session identifier\n        prompt: User prompt text\n\n    Returns:\n        Cache key string\n    \"\"\"\n    # Use hash of prompt to create deterministic key\n    prompt_hash = hashlib.blake2b(prompt.encode(), digest_size=16).hexdigest()\n    return f\"{session_id}_{prompt_hash}\"\n\ndef load_cached_results(cache_key: str) -> Optional[List[Dict[str, Any]]]:\n    \"\"\"Load retrieval results from cache.\n\n    Args:\n        cache_key: Cache key\n\n    Returns:\n        List of documents or None if not found\n    \"\"\"\n    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n\n    try:\n        if not cache_file.exists():\n            return None\n\n        # Check if cache is stale (older than 5 minutes)\n        import time\n        if time.time() - cache_file.stat().st_mtime > RESPONSE_CACHE_TTL_SECONDS:\n            cache_file.unlink()  # Delete stale cache\n            return None\n\n        with open(cache_file, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            return data.get('documents', [])\n\n    except Exception as e:\n        logger.error(f\"Failed to load cache: {e}\")\n        return None\n\ndef format_citations(documents: List[Dict[str, Any]], max_citations: int = 3) -> str:\n    \"\"\"Format document sources as citations.\n\n    Args:\n        documents: List of retrieved documents\n        max_citations: Maximum number of citations to include\n\n    Returns:\n        Formatted citation text\n    \"\"\"\n    if not documents:\n        return \"\"\n\n    # Limit to max citations\n    docs = documents[:max_citations]\n\n    # Build citation list\n    citations = [\"\\n\\nSources:\"]\n\n    for i, doc in enumerate(docs, 1):\n        source = doc.get('source', 'Unknown')\n        score = doc.get('score', 0.0)\n\n        # Extract location info if available\n        metadata = doc.get('metadata', {})\n        location = \"\"\n\n        if 'line_start' in metadata and 'line_end' in metadata:\n            location = f\" (line {metadata['line_start']}-{metadata['line_end']})\"\n        elif 'section' in metadata:\n            location = f\" (section: {metadata['section']})\"\n        elif 'page' in metadata:\n            location = f\" (page {metadata['page']})\"\n\n        # Format citation\n        citation = f\"[{i}] {source}{location} - relevance: {score:.2f}\"\n        citations.append(citation)\n\n    return \"\\n\".join(citations)\n\ndef inject_inline_citations(response: str, num_citations: int) -> str:\n    \"\"\"Inject inline citation markers [1][2] into response text.\n\n    This is a simple heuristic-based approach. For production use,\n    more sophisticated NLP techniques could be used to identify\n    which parts of the response correspond to which sources.\n\n    Args:\n        response: Original response text\n        num_citations: Number of available citations\n\n    Returns:\n        Response with inline citations\n    \"\"\"\n    # For now, return response without inline markers\n    # In production, this would use NLP to map response segments to sources\n    # Example advanced implementation:\n    # - Use sentence embeddings to match response sentences to source chunks\n    # - Insert [N] markers after sentences that match sources\n    # - Avoid over-citing (max 1 citation per sentence)\n\n    return response\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process ResponsePost hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event with citations\n    \"\"\"\n    try:\n        # Extract event data\n        response = event.get('response', '')\n        metadata = event.get('metadata', {})\n        session_id = event.get('session_id', 'unknown')\n        original_prompt = metadata.get('original_prompt', '')\n\n        # Check if response was RAG-enhanced\n        rag_enhanced = metadata.get('rag_enhanced', False)\n\n        if not rag_enhanced:\n            logger.debug(\"Response was not RAG-enhanced, skipping citations\")\n            return event\n\n        # Try to get cached retrieval results\n        cache_key = get_cache_key(session_id, original_prompt)\n        documents = load_cached_results(cache_key)\n\n        if not documents:\n            logger.warning(\"No cached retrieval results found, skipping citations\")\n            return event\n\n        logger.info(f\"Adding citations from {len(documents)} sources\")\n\n        # Format citations\n        citation_text = format_citations(documents, max_citations=3)\n\n        # Inject inline citations (future enhancement)\n        # response = inject_inline_citations(response, len(documents))\n\n        # Append citations to response\n        enhanced_response = response + citation_text\n\n        # Update event\n        event['response'] = enhanced_response\n        metadata['citations_added'] = len(documents[:3])\n        event['metadata'] = metadata\n\n        logger.info(\"Citations added successfully\", count=len(documents[:3]))\n\n    except Exception as e:\n        logger.error(f\"Citation injection failed: {e}\")\n        # Return original event on error\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/session-end.py": "#!/usr/bin/env python3\n\"\"\"SessionEnd hook for RAG-CLI cleanup and finalization.\n\nThis hook performs cleanup operations when a Claude Code session ends,\nincluding saving settings, clearing temporary cache, and logging session summary.\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Set up project paths using centralized utility\nfrom rag_cli_plugin.hooks.path_utils import setup_sys_path\nproject_root = setup_sys_path(__file__)\n\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\n# Settings file\nSETTINGS_FILE = project_root / \"config\" / \"rag_settings.json\"\n\ndef load_settings() -> Dict[str, Any]:\n    \"\"\"Load RAG settings from file.\n\n    Returns:\n        Settings dictionary\n    \"\"\"\n    try:\n        if SETTINGS_FILE.exists():\n            with open(SETTINGS_FILE, 'r') as f:\n                return json.load(f)\n    except Exception as e:\n        logger.error(f\"Failed to load settings: {e}\")\n\n    return {}\n\ndef save_settings(settings: Dict[str, Any]) -> bool:\n    \"\"\"Save RAG settings to file.\n\n    Args:\n        settings: Settings dictionary\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        SETTINGS_FILE.parent.mkdir(parents=True, exist_ok=True)\n        with open(SETTINGS_FILE, 'w') as f:\n            json.dump(settings, f, indent=2)\n        logger.debug(\"Settings saved successfully\")\n        return True\n    except Exception as e:\n        logger.error(f\"Failed to save settings: {e}\")\n        return False\n\ndef cleanup_cache() -> bool:\n    \"\"\"Clean up temporary cache files.\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        cache_dir = project_root / \"data\" / \"cache\"\n        if cache_dir.exists():\n            pass\n            # Remove old cache files (older than 1 hour)\n            import time\n            current_time = time.time()\n            max_age = 3600  # 1 hour\n\n            for cache_file in cache_dir.glob(\"*.json\"):\n                try:\n                    file_age = current_time - cache_file.stat().st_mtime\n                    if file_age > max_age:\n                        cache_file.unlink()\n                except Exception:\n                    pass  # Skip files we can't access\n\n            logger.debug(\"Cache cleanup completed\")\n            return True\n\n    except Exception as e:\n        logger.warning(f\"Cache cleanup failed: {e}\")\n        return False\n\ndef graceful_shutdown_vector_store() -> bool:\n    \"\"\"Gracefully shutdown ChromaDB vector store.\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        # Import here to avoid circular dependencies\n        from rag_cli.core.vector_store import _vector_store\n        from rag_cli.core.duplicate_detector import DuplicateDetector\n\n        # Close ChromaDB client if it exists\n        if _vector_store is not None:\n            try:\n                # ChromaDB PersistentClient doesn't have an explicit close method\n                # but we can ensure all pending writes are flushed\n                count = _vector_store.get_vector_count()\n                logger.info(f\"Vector store contains {count} vectors at shutdown\")\n\n                # Clear the singleton reference to allow garbage collection\n                # (ChromaDB will auto-persist on cleanup)\n                logger.debug(\"ChromaDB will auto-persist on cleanup\")\n\n            except Exception as e:\n                logger.warning(f\"Error during vector store shutdown: {e}\")\n\n        # Save duplicate detector registry\n        try:\n            duplicate_detector = DuplicateDetector()\n            duplicate_detector.save()\n            logger.debug(\"Duplicate detector registry saved\")\n        except Exception as e:\n            logger.warning(f\"Error saving duplicate detector: {e}\")\n\n        return True\n\n    except Exception as e:\n        logger.error(f\"Vector store shutdown failed: {e}\")\n        return False\n\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process SessionEnd hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event\n    \"\"\"\n    try:\n        session_id = event.get('session_id', 'unknown')\n        logger.info(\"RAG-CLI session ending\", session_id=session_id)\n\n        # Load and save settings\n        settings = load_settings()\n        if settings:\n            save_settings(settings)\n            logger.debug(\"Session settings persisted\")\n\n        # Gracefully shutdown vector store and ChromaDB\n        graceful_shutdown_vector_store()\n\n        # Clean up temporary cache\n        cleanup_cache()\n\n        # Log session summary\n        logger.info(\n            \"RAG-CLI session completed\",\n            session_id=session_id,\n            cleanup_status='success'\n        )\n\n        event['cleanup_status'] = 'success'\n\n    except Exception as e:\n        logger.error(f\"Session end hook failed: {e}\")\n        event['cleanup_status'] = 'error'\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/session-start.py": "#!/usr/bin/env python3\n\"\"\"SessionStart hook for RAG-CLI initialization.\n\nThis hook initializes RAG-CLI resources when a Claude Code session starts,\nincluding loading settings, checking vector store availability, and\nstarting monitoring services.\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Set up project paths using centralized utility\nfrom rag_cli_plugin.hooks.path_utils import setup_sys_path\nproject_root = setup_sys_path(__file__)\n\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\n# Settings file\nSETTINGS_FILE = project_root / \"config\" / \"rag_settings.json\"\n\ndef load_settings() -> Dict[str, Any]:\n    \"\"\"Load RAG settings from file.\n\n    Returns:\n        Settings dictionary\n    \"\"\"\n    try:\n        if SETTINGS_FILE.exists():\n            with open(SETTINGS_FILE, 'r') as f:\n                return json.load(f)\n        else:\n            # Return defaults\n            return {\n                \"enabled\": False,\n                \"auto_trigger_threshold\": 5,\n                \"context_limit\": 3,\n                \"relevance_threshold\": 0.6,\n                \"exclude_patterns\": [],\n                \"enable_agent_orchestration\": True,\n                \"classification_confidence_threshold\": 0.3,\n                \"min_classification_confidence\": 0.5\n            }\n    except Exception as e:\n        logger.error(f\"Failed to load settings: {e}\")\n        return {}\n\ndef health_check_chromadb() -> Dict[str, Any]:\n    \"\"\"Perform comprehensive ChromaDB health check.\n\n    Returns:\n        Dictionary with health check results\n    \"\"\"\n    health_status = {\n        \"healthy\": False,\n        \"vector_count\": 0,\n        \"collection_exists\": False,\n        \"can_query\": False,\n        \"persist_directory\": None,\n        \"errors\": []\n    }\n\n    try:\n        from rag_cli.core.vector_store import get_vector_store\n\n        # Initialize vector store (creates if doesn't exist)\n        vector_store = get_vector_store()\n\n        # Check collection exists\n        if vector_store.collection:\n            health_status[\"collection_exists\"] = True\n            health_status[\"persist_directory\"] = vector_store.persist_directory\n\n            # Get vector count\n            try:\n                count = vector_store.get_vector_count()\n                health_status[\"vector_count\"] = count\n                logger.info(f\"ChromaDB health check: {count} vectors in collection\")\n\n                # Test query capability (if vectors exist)\n                if count > 0:\n                    try:\n                        # Peek at first few vectors to verify read access\n                        peek_result = vector_store.collection.peek(limit=1)\n                        if peek_result and peek_result.get('ids'):\n                            health_status[\"can_query\"] = True\n                            logger.debug(\"ChromaDB query test passed\")\n                        else:\n                            health_status[\"errors\"].append(\"Collection peek returned no results\")\n                    except Exception as e:\n                        health_status[\"errors\"].append(f\"Query test failed: {str(e)}\")\n                else:\n                    # Empty collection is valid, just no vectors yet\n                    health_status[\"can_query\"] = True\n                    logger.info(\"ChromaDB collection is empty - ready for indexing\")\n\n            except Exception as e:\n                health_status[\"errors\"].append(f\"Could not get vector count: {str(e)}\")\n\n            # Overall health status\n            health_status[\"healthy\"] = (\n                health_status[\"collection_exists\"] and\n                (health_status[\"can_query\"] or health_status[\"vector_count\"] == 0)\n            )\n\n        else:\n            health_status[\"errors\"].append(\"Collection does not exist\")\n\n    except Exception as e:\n        health_status[\"errors\"].append(f\"Vector store initialization failed: {str(e)}\")\n        logger.error(f\"ChromaDB health check failed: {e}\")\n\n    return health_status\n\n\ndef initialize_resources() -> bool:\n    \"\"\"Initialize RAG resources (vector store, services, etc.).\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    try:\n        # Perform ChromaDB health check\n        health = health_check_chromadb()\n\n        if health[\"healthy\"]:\n            logger.info(\n                \"ChromaDB health check passed\",\n                vectors=health[\"vector_count\"],\n                persist_dir=health[\"persist_directory\"]\n            )\n        else:\n            logger.warning(\n                \"ChromaDB health check issues\",\n                errors=health[\"errors\"]\n            )\n            # Still return True - collection will be created on first use\n            if not health[\"collection_exists\"]:\n                logger.info(\"ChromaDB collection will be created on first indexing\")\n\n        # Try to start monitoring services\n        try:\n            from rag_cli_plugin.services.service_manager import ensure_services_running\n            ensure_services_running()\n            logger.info(\"Monitoring services started for session\")\n        except Exception as e:\n            logger.debug(f\"Monitoring services not started: {e}\")\n            # Not critical for session start\n\n        return True\n\n    except Exception as e:\n        logger.error(f\"Resource initialization failed: {e}\")\n        return False\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process SessionStart hook event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event\n    \"\"\"\n    try:\n        session_id = event.get('session_id', 'unknown')\n        logger.info(\"RAG-CLI session started\", session_id=session_id)\n\n        # Load settings\n        settings = load_settings()\n        logger.debug(\"RAG settings loaded\", enabled=settings.get('enabled', False))\n\n        # Initialize resources\n        if initialize_resources():\n            logger.info(\"RAG-CLI session initialization completed successfully\")\n            event['initialization_status'] = 'success'\n        else:\n            logger.warning(\"RAG-CLI session initialization completed with warnings\")\n            event['initialization_status'] = 'partial'\n\n        # Store settings in event metadata for downstream hooks\n        event['rag_settings'] = settings\n\n    except Exception as e:\n        logger.error(f\"Session start hook failed: {e}\")\n        event['initialization_status'] = 'error'\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/hooks/slash-command-blocker.py": "#!/usr/bin/env python3\n\"\"\"SlashCommandSubmit hook to prevent Claude from responding to slash commands.\n\nThis hook intercepts user prompts that start with / (slash commands) and prevents\nClaude from seeing them, allowing the command to execute without AI commentary.\nReturns a brief one-line status message to the user on completion.\n\nMetadata:\n  priority: 150\n  enabled: True\n  triggers: [\"UserPromptSubmit\"]\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Import path resolution utilities (relative import for hook context)\ntry:\n    from path_utils import setup_sys_path\nexcept ImportError:\n    # Fallback for absolute import if relative fails\n    import importlib.util\n    hook_dir = Path(__file__).parent\n    path_utils_path = hook_dir / 'path_utils.py'\n    spec = importlib.util.spec_from_file_location('path_utils', path_utils_path)\n    path_utils = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(path_utils)\n    setup_sys_path = path_utils.setup_sys_path\n\n# Set up sys.path before importing other modules\nsetup_sys_path()\n\nfrom rag_cli_plugin.services.logger import get_logger\n\nlogger = get_logger(__name__)\n\ndef is_slash_command(text: str) -> bool:\n    \"\"\"Check if the text is a slash command.\n\n    Args:\n        text: User input text\n\n    Returns:\n        True if text starts with /, False otherwise\n    \"\"\"\n    return text.strip().startswith('/')\n\ndef extract_command_name(text: str) -> str:\n    \"\"\"Extract the command name from slash command text.\n\n    Args:\n        text: Slash command text\n\n    Returns:\n        Command name (without the /)\n    \"\"\"\n    stripped = text.strip()\n    if not stripped.startswith('/'):\n        return \"\"\n\n    # Remove the / and get the first word\n    parts = stripped[1:].split()\n    return parts[0] if parts else \"\"\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process the UserPromptSubmit hook event.\n\n    This hook intercepts slash commands and prevents Claude from responding,\n    allowing the command to execute cleanly without AI commentary.\n\n    Args:\n        event: Hook event from Claude Code\n\n    Returns:\n        Modified event (blocked if slash command) or original event\n    \"\"\"\n    try:\n        # Extract user prompt from event\n        prompt = event.get('prompt', '')\n\n        if not prompt:\n            logger.debug(\"No prompt in event, passing through\")\n            return event\n\n        # Check if this is a slash command\n        if not is_slash_command(prompt):\n            logger.debug(\"Not a slash command, passing through\")\n            return event\n\n        # Extract command name for status message\n        command_name = extract_command_name(prompt)\n\n        logger.info(f\"Slash command detected: /{command_name}\")\n\n        # Block the prompt from reaching Claude by setting it to empty\n        # The slash command will still execute, but Claude won't respond\n        blocked_event = event.copy()\n        blocked_event['prompt'] = ''\n\n        # Add metadata to indicate this was blocked\n        if 'metadata' not in blocked_event:\n            blocked_event['metadata'] = {}\n\n        blocked_event['metadata']['slash_command_blocked'] = True\n        blocked_event['metadata']['original_command'] = prompt\n        blocked_event['metadata']['command_name'] = command_name\n\n        # Create a brief status message for the user\n        status_message = f\"Executing command: /{command_name}\"\n\n        # Add status to response field if it exists\n        if 'response' in blocked_event:\n            blocked_event['response'] = status_message\n\n        logger.info(f\"Blocked slash command /{command_name} from Claude response\")\n\n        # Try to send event to monitoring dashboard if available\n        try:\n            from rag_cli_plugin.services.service_manager import ServiceManager\n\n            manager = ServiceManager()\n            if manager.is_healthy():\n                manager.submit_event({\n                    'type': 'slash_command_blocked',\n                    'command': f\"/{command_name}\",\n                    'timestamp': event.get('timestamp'),\n                })\n        except Exception as e:\n            # Silently fail if monitoring not available\n            logger.debug(f\"Could not send event to monitoring: {e}\")\n\n        return blocked_event\n\n    except Exception as e:\n        logger.error(f\"Error in slash-command-blocker hook: {e}\", exc_info=True)\n        # On error, pass through original event to avoid breaking workflow\n        return event\n\ndef main():\n    \"\"\"Main entry point for hook execution.\n\n    Reads JSON event from stdin, processes it, and writes result to stdout.\n    \"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Fatal error in slash-command-blocker hook: {e}\", exc_info=True)\n        # On fatal error, pass through original input\n        try:\n            print(event_json)\n        except (UnicodeEncodeError, IOError):\n            print(\"{}\")\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n",
        "src/rag_cli_plugin/hooks/user-prompt-submit.py": "#!/usr/bin/env python3\n\"\"\"UserPromptSubmit hook for RAG enhancement.\n\nThis hook intercepts user queries and enhances them with relevant context\nfrom the document knowledge base when RAG is enabled.\n\"\"\"\n\nimport sys\nimport os\nimport json\nimport time\nimport threading\nimport asyncio\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List, Tuple\n\n# Set environment variable to suppress console logging in hooks\nos.environ['CLAUDE_HOOK_CONTEXT'] = '1'\nos.environ['RAG_CLI_SUPPRESS_CONSOLE'] = '1'\n\n# Set up project paths using centralized utility\nfrom rag_cli_plugin.hooks.path_utils import setup_sys_path\nproject_root = setup_sys_path(__file__)\n\nfrom rag_cli.core.config import get_config\nfrom rag_cli.core.vector_store import get_vector_store\nfrom rag_cli.core.embeddings import get_embedding_generator\nfrom rag_cli.core.retrieval_pipeline import HybridRetriever\nfrom rag_cli.core.claude_code_adapter import get_adapter\nfrom rag_cli.core.query_classifier import QueryClassification\nfrom rag_cli_plugin.services.logger import get_logger\nfrom rag_cli_plugin.services.service_manager import ensure_services_running\nfrom rag_cli.core.constants import TCP_CHECK_CACHE_SECONDS, MAX_BACKOFF_SECONDS\n\nlogger = get_logger(__name__)\n\n# RAG settings file\nSETTINGS_FILE = project_root / \"config\" / \"rag_settings.json\"\n\n# TCP Server URL for event submission\nTCP_SERVER_URL = \"http://localhost:9999\"\n\n# Cache TCP server availability to avoid repeated checks with exponential backoff\n_tcp_state_lock = threading.Lock()\n_tcp_server_available = None\n_tcp_check_time = 0\n_tcp_consecutive_failures = 0\n_tcp_backoff_until = 0\n\ndef check_tcp_server_available() -> bool:\n    \"\"\"Check if TCP server is available with exponential backoff on failures.\n\n    Uses caching to avoid repeated connection attempts within a short time window.\n    Implements exponential backoff: after consecutive failures, wait progressively\n    longer before retrying (30s, 60s, 120s, max 240s).\n\n    Returns:\n        True if server is reachable, False otherwise\n    \"\"\"\n    global _tcp_server_available, _tcp_check_time, _tcp_consecutive_failures, _tcp_backoff_until\n\n    with _tcp_state_lock:\n        current_time = time.time()\n\n        # Check if in backoff period\n        if current_time < _tcp_backoff_until:\n            logger.debug(f\"TCP server in backoff period (until {_tcp_backoff_until - current_time:.1f}s)\")\n            return False\n\n        # Use cached result if check was recent\n        if _tcp_server_available is not None and (current_time - _tcp_check_time) < TCP_CHECK_CACHE_SECONDS:\n            return _tcp_server_available\n\n        # Try to connect to TCP server\n        try:\n            import urllib.request\n            import urllib.error\n\n            req = urllib.request.Request(\n                f\"{TCP_SERVER_URL}/api/health\",\n                method='GET'\n            )\n\n            with urllib.request.urlopen(req, timeout=0.5) as response:\n                # Success - reset failure count\n                _tcp_server_available = (response.status == 200)\n                _tcp_check_time = current_time\n                _tcp_consecutive_failures = 0\n                _tcp_backoff_until = 0\n                return _tcp_server_available\n\n        except (urllib.error.URLError, urllib.error.HTTPError, ConnectionError, TimeoutError, OSError) as e:\n            # Network/connection errors are expected when server is not running\n            logger.debug(f\"TCP server not reachable: {type(e).__name__}\")\n            _tcp_server_available = False\n            _tcp_check_time = current_time\n\n            # Increment failure count and calculate backoff\n            _tcp_consecutive_failures += 1\n            backoff_seconds = min(TCP_CHECK_CACHE_SECONDS * (2 ** (_tcp_consecutive_failures - 1)), MAX_BACKOFF_SECONDS)\n            _tcp_backoff_until = current_time + backoff_seconds\n\n            if _tcp_consecutive_failures > 1:\n                logger.debug(f\"TCP server check failed {_tcp_consecutive_failures} times, backing off for {backoff_seconds}s\")\n\n            return False\n\ndef submit_event_to_server(event_type: str, data: Dict[str, Any]) -> bool:\n    \"\"\"Submit an event to the TCP server via HTTP POST.\n\n    This enables cross-process event streaming from hooks to the web dashboard.\n\n    Args:\n        event_type: Type of event (activity, reasoning, query_enhancement, etc.)\n        data: Event data dictionary\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    # Check if server is available before attempting connection\n    if not check_tcp_server_available():\n        logger.debug(\"TCP server not available, skipping event submission\")\n        return False\n\n    try:\n        import urllib.request\n        import urllib.error\n\n        event_payload = {\n            \"event_type\": event_type,\n            \"data\": data\n        }\n\n        req = urllib.request.Request(\n            f\"{TCP_SERVER_URL}/api/events/submit\",\n            data=json.dumps(event_payload).encode('utf-8'),\n            headers={'Content-Type': 'application/json'},\n            method='POST'\n        )\n\n        with urllib.request.urlopen(req, timeout=1) as response:\n            return response.status == 200\n\n    except (urllib.error.URLError, urllib.error.HTTPError, Exception) as e:\n        # Mark server as unavailable on error\n        global _tcp_server_available\n        _tcp_server_available = False\n        logger.debug(f\"Failed to submit event to TCP server: {e}\")\n        return False\n\ndef load_rag_settings() -> Dict[str, Any]:\n    \"\"\"Load RAG settings from file.\n\n    Returns:\n        Dictionary with RAG settings\n    \"\"\"\n    if SETTINGS_FILE.exists():\n        try:\n            with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:\n                return json.load(f)\n        except (FileNotFoundError, IOError, OSError) as e:\n            logger.error(f\"Failed to read RAG settings file: {e}\")\n        except json.JSONDecodeError as e:\n            logger.error(f\"Invalid JSON in RAG settings file: {e}\")\n        except Exception as e:\n            logger.error(f\"Unexpected error loading RAG settings: {e}\", exc_info=True)\n\n    # Default settings\n    return {\n        \"enabled\": False,\n        \"auto_trigger_threshold\": 5,  # Minimum words to trigger\n        \"context_limit\": 3,  # Maximum documents to include\n        \"relevance_threshold\": 0.6,  # Minimum similarity score\n        \"cache_queries\": True,\n        \"exclude_patterns\": []  # Patterns to exclude from enhancement\n    }\n\ndef save_rag_settings(settings: Dict[str, Any]):\n    \"\"\"Save RAG settings to file.\n\n    Args:\n        settings: Settings dictionary to save\n    \"\"\"\n    try:\n        SETTINGS_FILE.parent.mkdir(parents=True, exist_ok=True)\n        with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:\n            json.dump(settings, f, indent=2)\n    except (FileNotFoundError, IOError, OSError) as e:\n        logger.error(f\"Failed to write RAG settings file: {e}\")\n    except (TypeError, ValueError) as e:\n        logger.error(f\"Invalid settings data structure: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error saving RAG settings: {e}\", exc_info=True)\n\ndef should_enhance_query(query: str, settings: Dict[str, Any]) -> Tuple[bool, Optional['QueryClassification']]:\n    \"\"\"Determine if a query should be enhanced with RAG using intelligent classification.\n\n    Args:\n        query: User query\n        settings: RAG settings\n\n    Returns:\n        Tuple of (should_enhance, classification)\n    \"\"\"\n    # Check if RAG is enabled\n    if not settings.get(\"enabled\", False):\n        return (False, None)\n\n    # Check if it's a command\n    if query.strip().startswith(\"/\"):\n        return (False, None)\n\n    # Import query classifier\n    try:\n        from rag_cli.core.query_classifier import get_query_classifier\n    except ImportError:\n        logger.warning(\"Query classifier not available, falling back to basic filtering\")\n        # Fallback to basic word count check\n        word_count = len(query.split())\n        if word_count < settings.get(\"auto_trigger_threshold\", 5):\n            return (False, None)\n        return (True, None)\n\n    # Classify query\n    classifier = get_query_classifier(\n        confidence_threshold=settings.get(\"classification_confidence_threshold\", 0.3)\n    )\n    classification = classifier.classify(query)\n\n    # Check if query is technical\n    if not classification.is_technical:\n        logger.debug(f\"Skipping non-technical query: {query[:50]}...\")\n        return (False, classification)\n\n    # Check minimum word count (relaxed with classification)\n    word_count = len(query.split())\n    min_words = settings.get(\"auto_trigger_threshold\", 5)\n    if word_count < min_words:\n        # Allow shorter queries if they have high confidence technical intent\n        if classification.confidence < 0.7:\n            logger.debug(f\"Query too short ({word_count} words) and low confidence ({classification.confidence:.2f})\")\n            return (False, classification)\n\n    # Check exclusion patterns\n    exclude_patterns = settings.get(\"exclude_patterns\", [])\n    query_lower = query.lower()\n    for pattern in exclude_patterns:\n        if pattern.lower() in query_lower:\n            return (False, classification)\n\n    # Check confidence threshold\n    min_confidence = settings.get(\"min_classification_confidence\", 0.5)\n    if classification.confidence < min_confidence:\n        logger.debug(\n            f\"Query confidence {classification.confidence:.2f} below threshold {min_confidence}\",\n            intent=classification.primary_intent.value\n        )\n        return (False, classification)\n\n    # Log classification results\n    logger.info(\n        \"Query classified for RAG enhancement\",\n        intent=classification.primary_intent.value,\n        confidence=classification.confidence,\n        depth=classification.technical_depth.value,\n        entities=len(classification.entities)\n    )\n\n    return (True, classification)\n\ndef retrieve_context(query: str, settings: Dict[str, Any], classification: Optional['QueryClassification'] = None) -> List[Dict[str, Any]]:\n    \"\"\"Retrieve relevant context for a query.\n\n    Args:\n        query: User query\n        settings: RAG settings\n        classification: Optional query classification for adaptive retrieval\n\n    Returns:\n        List of relevant documents\n    \"\"\"\n    try:\n        # Check if vector store exists\n        vector_store_path = project_root / \"data\" / \"vectors\" / \"chroma_db\"\n        if not vector_store_path.exists():\n            logger.warning(\"No vector index found, skipping RAG enhancement\")\n            return []\n\n        # Initialize components\n        config = get_config()\n        vector_store = get_vector_store()\n        embedding_generator = get_embedding_generator()\n\n        # Create retriever\n        retriever = HybridRetriever(\n            vector_store=vector_store,\n            embedding_generator=embedding_generator,\n            config=config\n        )\n\n        # Retrieve documents\n        context_limit = settings.get(\"context_limit\", 3)\n        relevance_threshold = settings.get(\"relevance_threshold\", 0.6)\n\n        documents = retriever.search(query, top_k=context_limit * 2)\n\n        # Filter by threshold and limit\n        filtered_docs = []\n        rejected_docs = []\n        for doc in documents:\n            score = doc.score\n            if score >= relevance_threshold:\n                filtered_docs.append(doc)\n\n                # Emit reasoning for document selection\n                submit_event_to_server(\"reasoning\", {\n                    \"reasoning\": f\"Selected document '{doc.source}' with score {score:.2f} (threshold: {relevance_threshold}). \"\n                    \"Document matches query semantically and meets relevance threshold.\",\n                    \"component\": \"user_prompt_hook\",\n                    \"context\": {\n                        \"document_source\": doc.source,\n                        \"score\": score,\n                        \"threshold\": relevance_threshold,\n                        \"content_preview\": doc.text[:100]\n                    }\n                })\n\n                if len(filtered_docs) >= context_limit:\n                    break\n            else:\n                rejected_docs.append(doc)\n\n                # Emit reasoning for rejection\n                if len(rejected_docs) <= 2:  # Only log first 2 rejections\n                    submit_event_to_server(\"reasoning\", {\n                        \"reasoning\": f\"Rejected document '{doc.source}' with score {score:.2f} \"\n                        f\"(below threshold: {relevance_threshold}).\",\n                        \"component\": \"user_prompt_hook\",\n                        \"context\": {\"document_source\": doc.source, \"score\": score}\n                    })\n\n        logger.info(f\"Retrieved {len(filtered_docs)} documents for query enhancement\",\n                    query_length=len(query),\n                    max_score=max([d.score for d in filtered_docs]) if filtered_docs else 0)\n\n        # Emit activity event\n        submit_event_to_server(\"activity\", {\n            \"activity\": \"documents_retrieved\",\n            \"component\": \"user_prompt_hook\",\n            \"metadata\": {\n                \"query_length\": len(query),\n                \"total_candidates\": len(documents),\n                \"selected\": len(filtered_docs),\n                \"rejected\": len(rejected_docs),\n                \"max_score\": max([d.score for d in filtered_docs]) if filtered_docs else 0\n            }\n        })\n\n        return filtered_docs\n\n    except (ConnectionError, TimeoutError) as e:\n        logger.error(f\"Network error during context retrieval: {e}\")\n        return []\n    except (FileNotFoundError, IOError) as e:\n        logger.error(f\"Vector store file error: {e}\")\n        return []\n    except Exception as e:\n        logger.error(f\"Failed to retrieve context: {e}\", exc_info=True)\n        return []\n\ndef format_enhanced_query(query: str, documents: List[Dict[str, Any]]) -> str:\n    \"\"\"Format the enhanced query with retrieved context.\n\n    Args:\n        query: Original user query\n        documents: Retrieved documents\n\n    Returns:\n        Enhanced query with context\n    \"\"\"\n    if not documents:\n        return query\n\n    # Use adapter for consistent formatting\n    adapter = get_adapter()\n    return adapter.format_hook_enhancement(documents, query)\n\n\n# ==================== Process Hook Helper Functions ====================\n# These functions break down the complex process_hook() logic into\n# manageable, single-responsibility components for better maintainability.\n\ndef _start_monitoring_services(logger) -> None:\n    \"\"\"Ensure monitoring services are running.\n\n    Args:\n        logger: Logger instance\n\n    Note:\n        Failures are logged but don't stop execution.\n    \"\"\"\n    try:\n        ensure_services_running()\n    except Exception as e:\n        logger.debug(f\"Service startup check failed: {e}\")\n\n\ndef _validate_and_extract_query(event: Dict[str, Any]) -> Optional[str]:\n    \"\"\"Extract and validate query from event.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Query string if valid, None otherwise\n    \"\"\"\n    # Check if already processed - prevent infinite loop\n    metadata = event.get(\"metadata\", {})\n    if metadata.get(\"rag_enhanced\"):\n        logger.debug(\"Event already processed by RAG, skipping\")\n        return None\n    \n    # Check if slash command was blocked - skip RAG enhancement\n    if metadata.get(\"slash_command_blocked\"):\n        logger.debug(\"Slash command blocked, skipping RAG enhancement\")\n        return None\n    \n    query = event.get(\"prompt\", \"\")\n    if not query:\n        logger.debug(\"Empty prompt, skipping\")\n        return None\n    \n    return query\n\n\ndef _emit_query_received_event(query: str) -> None:\n    \"\"\"Emit activity event for query received.\n\n    Args:\n        query: User query string\n    \"\"\"\n    submit_event_to_server(\"activity\", {\n        \"activity\": \"query_received\",\n        \"component\": \"user_prompt_hook\",\n        \"metadata\": {\n            \"query_length\": len(query),\n            \"word_count\": len(query.split())\n        }\n    })\n\n\ndef _emit_skip_reasoning(skip_reason: str, settings: Dict[str, Any],\n                         classification: Optional[QueryClassification],\n                         query: str) -> None:\n    \"\"\"Emit reasoning event when query enhancement is skipped.\n\n    Args:\n        skip_reason: Human-readable reason for skipping\n        settings: RAG settings dictionary\n        classification: Query classification result\n        query: Original query string\n    \"\"\"\n    reasoning_context = {\n        \"rag_enabled\": settings.get(\"enabled\"),\n        \"query_word_count\": len(query.split())\n    }\n\n    if classification:\n        reasoning_context.update({\n            \"intent\": classification.primary_intent.value,\n            \"confidence\": classification.confidence,\n            \"is_technical\": classification.is_technical\n        })\n\n    submit_event_to_server(\"reasoning\", {\n        \"reasoning\": f\"Query enhancement skipped: {skip_reason}\",\n        \"component\": \"user_prompt_hook\",\n        \"context\": reasoning_context\n    })\n\n\ndef _orchestrate_retrieval(query: str, settings: Dict[str, Any],\n                           classification: Optional[QueryClassification]) -> Tuple[List, str, Any]:\n    \"\"\"Attempt orchestrated retrieval with multi-agent support.\n\n    Args:\n        query: User query string\n        settings: RAG settings dictionary\n        classification: Query classification result\n\n    Returns:\n        Tuple of (documents, strategy_used, orchestration_result)\n\n    Raises:\n        Exception: If orchestration fails (caller should handle)\n    \"\"\"\n    from rag_cli.core.agent_orchestrator import AgentOrchestrator\n\n    orchestrator = AgentOrchestrator()\n\n    # Run async orchestration\n    orchestration_result = asyncio.run(orchestrator.orchestrate(\n        query=query,\n        top_k=settings.get(\"context_limit\", 3),\n        use_cache=True\n    ))\n\n    # Extract documents\n    documents = []\n    strategy_used = \"retrieve_context_fallback\"\n\n    if orchestration_result.rag_results:\n        documents = orchestration_result.rag_results\n        strategy_used = orchestration_result.strategy_used.value\n\n    return documents, strategy_used, orchestration_result\n\n\ndef _format_orchestration_summary(strategy_used: str, classification: Optional[QueryClassification],\n                                  orchestration_result: Any, documents: List) -> str:\n    \"\"\"Format orchestration output for display.\n\n    Args:\n        strategy_used: Strategy name used\n        classification: Query classification\n        orchestration_result: Orchestration result object\n        documents: Retrieved documents list\n\n    Returns:\n        Formatted markdown summary string\n    \"\"\"\n    from rag_cli_plugin.services.output_formatter import OutputFormatter\n\n    formatter = OutputFormatter(verbose=False)\n    formatted_summary = formatter.format_header(\"Query Processing\", 2)\n    formatted_summary += f\"**Strategy:** {strategy_used}\\n\"\n    formatted_summary += f\"**Intent:** {classification.primary_intent.value if classification else 'unknown'}\\n\"\n    formatted_summary += f\"**Confidence:** {orchestration_result.confidence:.1%}\\n\"\n    formatted_summary += f\"**Documents:** {len(documents)}\\n\"\n\n    if orchestration_result.maf_result:\n        formatted_summary += f\"**MAF Agent:** {orchestration_result.maf_result.agent_name}\\n\"\n\n    return formatted_summary\n\n\ndef _emit_orchestration_reasoning(strategy_used: str, classification: Optional[QueryClassification],\n                                  orchestration_result: Any, documents: List,\n                                  formatted_summary: str) -> None:\n    \"\"\"Emit reasoning event for orchestration.\n\n    Args:\n        strategy_used: Strategy name\n        classification: Query classification\n        orchestration_result: Orchestration result\n        documents: Retrieved documents\n        formatted_summary: Formatted summary string\n    \"\"\"\n    submit_event_to_server(\"reasoning\", {\n        \"reasoning\": f\"Agent orchestration used strategy: {strategy_used}. \"\n        f\"Classification: {classification.primary_intent.value if classification else 'unknown'}. \"\n        f\"Confidence: {orchestration_result.confidence:.2f}. \"\n        f\"Retrieved {len(documents)} documents.\",\n        \"component\": \"agent_orchestrator\",\n        \"formatted_output\": formatted_summary,\n        \"context\": {\n            \"strategy\": strategy_used,\n            \"intent\": classification.primary_intent.value if classification else None,\n            \"confidence\": orchestration_result.confidence,\n            \"documents_count\": len(documents),\n            \"maf_used\": orchestration_result.maf_result is not None\n        }\n    })\n\n\ndef _emit_query_enhancement_event(query: str, enhanced_query: str, documents: List,\n                                  strategy_used: str, use_orchestrator: bool) -> None:\n    \"\"\"Emit query enhancement event with document details.\n\n    Args:\n        query: Original query\n        enhanced_query: Enhanced query with context\n        documents: Retrieved documents\n        strategy_used: Strategy name\n        use_orchestrator: Whether orchestrator was used\n    \"\"\"\n    doc_summaries = [{\n        \"source\": doc.source,\n        \"score\": doc.score,\n        \"content_preview\": doc.text[:100]\n    } for doc in documents[:3]]\n\n    submit_event_to_server(\"query_enhancement\", {\n        \"original_query\": query,\n        \"enhanced_query\": enhanced_query,\n        \"documents_count\": len(doc_summaries),\n        \"documents\": doc_summaries,\n        \"reasoning\": f\"Enhanced query with {len(documents)} documents. \"\n        f\"Orchestration Strategy: {strategy_used}. \"\n        f\"Retrieved using {'agent orchestration' if use_orchestrator else 'fallback RAG'}. \"\n        \"Context injected as markdown-formatted knowledge base references.\"\n    })\n\n\ndef _emit_context_assembled_event(query: str, enhanced_query: str,\n                                  documents: List, retrieval_time: float) -> None:\n    \"\"\"Emit activity event for context assembly.\n\n    Args:\n        query: Original query\n        enhanced_query: Enhanced query\n        documents: Retrieved documents\n        retrieval_time: Retrieval time in milliseconds\n    \"\"\"\n    submit_event_to_server(\"activity\", {\n        \"activity\": \"context_assembled\",\n        \"component\": \"user_prompt_hook\",\n        \"metadata\": {\n            \"original_query_length\": len(query),\n            \"enhanced_query_length\": len(enhanced_query),\n            \"documents_count\": len(documents),\n            \"retrieval_time_ms\": retrieval_time\n        }\n    })\n\n\ndef _cache_retrieval_results(documents: List, query: str, event: Dict[str, Any],\n                             project_root: Path, logger) -> None:\n    \"\"\"Cache retrieval results for ResponsePost hook.\n\n    Args:\n        documents: Retrieved documents\n        query: Original query\n        event: Hook event\n        project_root: Project root path\n        logger: Logger instance\n\n    Note:\n        Failures are logged but don't stop execution.\n    \"\"\"\n    try:\n        import hashlib\n\n        session_id = event.get(\"session_id\", \"unknown\")\n        prompt_hash = hashlib.blake2b(query.encode(), digest_size=16).hexdigest()\n        cache_key = f\"{session_id}_{prompt_hash}\"\n\n        cache_dir = project_root / \"data\" / \"cache\"\n        cache_dir.mkdir(parents=True, exist_ok=True)\n        cache_file = cache_dir / f\"{cache_key}.json\"\n\n        # Save retrieval results\n        cache_data = {\n            \"documents\": [{\n                \"source\": doc.source,\n                \"score\": doc.score,\n                \"text\": doc.text,\n                \"metadata\": doc.metadata\n            } for doc in documents],\n            \"timestamp\": time.time()\n        }\n\n        with open(cache_file, 'w', encoding='utf-8') as f:\n            json.dump(cache_data, f, indent=2)\n\n        logger.debug(f\"Cached retrieval results: {cache_key}\")\n\n    except (FileNotFoundError, IOError, OSError) as e:\n        logger.warning(f\"Failed to write cache file: {e}\")\n    except (TypeError, ValueError) as e:\n        logger.warning(f\"Invalid cache data structure: {e}\")\n\n\ndef _update_event_metadata(event: Dict[str, Any], enhanced_query: str,\n                           query: str, documents: List, retrieval_time: float) -> None:\n    \"\"\"Update event with enhancement metadata.\n\n    Args:\n        event: Hook event (modified in place)\n        enhanced_query: Enhanced query string\n        query: Original query\n        documents: Retrieved documents\n        retrieval_time: Retrieval time in milliseconds\n    \"\"\"\n    event[\"prompt\"] = enhanced_query\n    event[\"metadata\"] = event.get(\"metadata\", {})\n    event[\"metadata\"][\"rag_enhanced\"] = True\n    event[\"metadata\"][\"documents_used\"] = len(documents)\n    event[\"metadata\"][\"retrieval_time_ms\"] = retrieval_time\n    event[\"metadata\"][\"original_prompt\"] = query\n\n\n# ==================== Main Process Hook Function ====================\n\ndef process_hook(event: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process the UserPromptSubmit hook event.\n\n    This function has been refactored into smaller helper functions for better\n    maintainability. Each helper function handles a single responsibility.\n\n    Args:\n        event: Hook event data\n\n    Returns:\n        Modified event data with RAG enhancement if applicable\n    \"\"\"\n    start_time = time.time()\n    logger.info(\"Hook execution started\", hook=\"UserPromptSubmit\")\n\n    try:\n        # Early return: Check if already processed to prevent infinite loop\n        metadata = event.get(\"metadata\", {})\n        if metadata.get(\"rag_enhanced\"):\n            logger.debug(\"Event already processed by RAG, skipping re-processing\")\n            return event\n        \n        # Early return: Check if slash command was blocked\n        if metadata.get(\"slash_command_blocked\"):\n            logger.debug(\"Slash command blocked, skipping RAG enhancement\")\n            return event\n        \n        # Step 1: Start monitoring services\n        _start_monitoring_services(logger)\n\n        # Step 2: Extract and validate query\n        query = _validate_and_extract_query(event)\n        if not query:\n            return event\n\n        # Step 3: Emit query received event\n        _emit_query_received_event(query)\n\n        # Step 4: Load settings and check if enhancement should proceed\n        settings = load_rag_settings()\n        should_enhance, classification = should_enhance_query(query, settings)\n\n        if not should_enhance:\n            # Build skip reason and emit\n            skip_reason = \"Criteria not met\"\n            if classification:\n                skip_reason = f\"Classification: {classification.primary_intent.value} (conf: {classification.confidence:.2f})\"\n                if not classification.is_technical:\n                    skip_reason = \"Non-technical query detected\"\n\n            logger.debug(\"Query enhancement skipped\",\n                         reason=skip_reason,\n                         rag_enabled=settings.get(\"enabled\", False))\n\n            _emit_skip_reasoning(skip_reason, settings, classification, query)\n            return event\n\n        # Step 5: Retrieve context with orchestration or fallback\n        retrieval_start = time.time()\n        use_orchestrator = settings.get(\"enable_agent_orchestration\", True)\n        documents = []\n        orchestration_result = None\n        strategy_used = \"retrieve_context_fallback\"\n\n        if use_orchestrator:\n            try:\n                documents, strategy_used, orchestration_result = _orchestrate_retrieval(\n                    query, settings, classification\n                )\n\n                # Format and emit orchestration summary\n                formatted_summary = _format_orchestration_summary(\n                    strategy_used, classification, orchestration_result, documents\n                )\n                _emit_orchestration_reasoning(\n                    strategy_used, classification, orchestration_result,\n                    documents, formatted_summary\n                )\n\n                logger.info(\"Orchestrated retrieval complete\",\n                            strategy=strategy_used,\n                            documents_count=len(documents),\n                            confidence=orchestration_result.confidence)\n\n            except ImportError as e:\n                logger.debug(f\"Agent orchestrator not available: {e}\")\n                use_orchestrator = False\n            except (ConnectionError, TimeoutError) as e:\n                logger.warning(f\"Network error during orchestration: {e}\")\n                use_orchestrator = False\n            except Exception as e:\n                logger.warning(f\"Agent orchestration failed, falling back to simple retrieval: {e}\", exc_info=True)\n                use_orchestrator = False\n\n        # Fallback to simple retrieve_context if orchestrator not used or failed\n        if not use_orchestrator or not documents:\n            documents = retrieve_context(query, settings, classification=classification)\n            strategy_used = \"rag_only_fallback\"\n\n        retrieval_time = (time.time() - retrieval_start) * 1000\n\n        # Step 6: Process retrieved documents\n        if documents:\n            # Format enhanced query\n            enhanced_query = format_enhanced_query(query, documents)\n\n            # Emit query enhancement and context assembly events\n            _emit_query_enhancement_event(query, enhanced_query, documents,\n                                         strategy_used, use_orchestrator)\n            _emit_context_assembled_event(query, enhanced_query, documents, retrieval_time)\n\n            # Cache results for ResponsePost hook\n            _cache_retrieval_results(documents, query, event, project_root, logger)\n\n            # Update event metadata\n            _update_event_metadata(event, enhanced_query, query, documents, retrieval_time)\n\n            logger.info(\"Query enhanced with RAG\",\n                        original_length=len(query),\n                        enhanced_length=len(enhanced_query),\n                        documents=len(documents),\n                        time_ms=retrieval_time)\n\n    except KeyError as e:\n        logger.error(f\"Missing required event field: {e}\")\n        # Return original event on error\n    except (ConnectionError, TimeoutError) as e:\n        logger.error(f\"Network error during hook processing: {e}\")\n        # Return original event on error\n    except Exception as e:\n        logger.error(f\"Hook processing failed: {e}\", exc_info=True)\n        # Return original event on error\n    finally:\n        execution_time = (time.time() - start_time) * 1000\n        logger.info(\"Hook execution completed\",\n                    hook=\"UserPromptSubmit\",\n                    execution_time_ms=execution_time,\n                    rag_enhanced=event.get(\"metadata\", {}).get(\"rag_enhanced\", False))\n\n    return event\n\ndef main():\n    \"\"\"Main function for the hook.\"\"\"\n    try:\n        # Read event from stdin\n        event_json = sys.stdin.read()\n        event = json.loads(event_json)\n\n        # Process the event\n        result = process_hook(event)\n\n        # Write result to stdout\n        print(json.dumps(result))\n\n    except Exception as e:\n        logger.error(f\"Hook failed: {e}\")\n        # On error, pass through the original event\n        print(event_json if 'event_json' in locals() else \"{}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "src/rag_cli_plugin/skills/rag-retrieval/SKILL.md": "# RAG Retrieval Skill\n\nQuery your local document knowledge base using semantic search and get AI-powered answers.\n\n## Overview\n\nThis skill enables RAG (Retrieval-Augmented Generation) queries against your locally indexed documents. It uses semantic search to find relevant documents and generates answers using Claude Haiku.\n\n## Usage\n\n```\n/skill rag-retrieval \"How to configure the API?\"\n```\n\n## Features\n\n- **Semantic Search**: Uses vector similarity to find relevant documents\n- **Hybrid Retrieval**: Combines vector search with keyword matching for better accuracy\n- **Context-Aware Answers**: Uses claude-haiku-4-5-20251001 to generate responses\n- **Citation Support**: Shows sources for generated answers\n- **Performance Monitoring**: Tracks query latency and accuracy\n\n## Arguments\n\n- `query` (required): Your question or search query\n- `--top-k` (optional): Number of documents to retrieve (default: 5)\n- `--threshold` (optional): Minimum similarity score (default: 0.7)\n- `--mode` (optional): Search mode - \"hybrid\", \"vector\", or \"keyword\" (default: \"hybrid\")\n\n## Examples\n\n### Basic Query\n```\n/skill rag-retrieval \"What is the authentication process?\"\n```\n\n### Retrieve More Context\n```\n/skill rag-retrieval \"How to handle errors?\" --top-k 10\n```\n\n### Vector-Only Search\n```\n/skill rag-retrieval \"API rate limits\" --mode vector\n```\n\n## Configuration\n\nThe skill uses the following configuration from `config/default.yaml`:\n\n- `retrieval.top_k`: Default number of documents to retrieve\n- `retrieval.hybrid_ratio`: Balance between vector and keyword search (0.7 = 70% vector)\n- `claude.model`: LLM model for response generation\n- `claude.max_tokens`: Maximum response length\n\n## Performance\n\nTypical latencies:\n- Vector search: <100ms\n- End-to-end response: <5 seconds\n- Indexing: ~0.5s per 100 documents\n\n## Requirements\n\n- Indexed documents in `data/vectors/`\n- Valid Anthropic API key in environment\n- At least 2GB RAM for vector operations\n\n## Troubleshooting\n\n### No Results Found\n- Ensure documents are indexed: `python scripts/index.py --input data/documents`\n- Lower the similarity threshold: `--threshold 0.5`\n- Try keyword mode if vector search fails\n\n### Slow Responses\n- Reduce top_k value for faster retrieval\n- Check if vector index is optimized for your document count\n- Monitor memory usage with `python -m src.monitoring.tcp_server`\n\n### API Errors\n- Verify ANTHROPIC_API_KEY environment variable\n- Check API rate limits and quota\n- Review logs in `logs/rag_cli.log`"
      },
      "plugins": [
        {
          "name": "rag-cli",
          "source": "./",
          "description": "Local RAG (Retrieval-Augmented Generation) system for enhanced Claude Code responses with multi-agent orchestration",
          "version": "2.0.0",
          "author": {
            "name": "DiaTech",
            "email": "support@rag-cli.dev"
          },
          "homepage": "https://github.com/ItMeDiaTech/rag-cli",
          "repository": "https://github.com/ItMeDiaTech/rag-cli",
          "license": "MIT",
          "keywords": [
            "rag",
            "retrieval",
            "augmented-generation",
            "vector-search",
            "semantic-search",
            "multi-agent",
            "orchestration",
            "documentation",
            "knowledge-base",
            "faiss",
            "embeddings"
          ],
          "category": "productivity",
          "categories": [
            "augmented-generation",
            "documentation",
            "embeddings",
            "faiss",
            "knowledge-base",
            "multi-agent",
            "orchestration",
            "productivity",
            "rag",
            "retrieval",
            "semantic-search",
            "vector-search"
          ],
          "install_commands": [
            "/plugin marketplace add ItMeDiaTech/rag-cli",
            "/plugin install rag-cli@rag-cli"
          ]
        }
      ]
    },
    {
      "name": "itmediatech-plugin-marketplace",
      "version": "1.0.0",
      "description": "Official marketplace for dt-cli plugins and extensions",
      "owner_info": {
        "name": "ItMeDiaTech",
        "email": "",
        "url": "https://github.com/ItMeDiaTech",
        "description": "Developer tools and AI-powered development assistance"
      },
      "keywords": [],
      "repo_full_name": "ItMeDiaTech/dt-cli",
      "repo_url": "https://github.com/ItMeDiaTech/dt-cli",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2025-11-13T10:14:40Z",
        "created_at": "2025-11-07T05:31:10Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/hooks.json",
          "type": "blob",
          "size": 358
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1374
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 1046
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/rag-exec.md",
          "type": "blob",
          "size": 2597
        },
        {
          "path": ".claude/commands/rag-graph.md",
          "type": "blob",
          "size": 3394
        },
        {
          "path": ".claude/commands/rag-index.md",
          "type": "blob",
          "size": 1675
        },
        {
          "path": ".claude/commands/rag-metrics.md",
          "type": "blob",
          "size": 3686
        },
        {
          "path": ".claude/commands/rag-query-advanced.md",
          "type": "blob",
          "size": 3233
        },
        {
          "path": ".claude/commands/rag-query.md",
          "type": "blob",
          "size": 1995
        },
        {
          "path": ".claude/commands/rag-save.md",
          "type": "blob",
          "size": 2417
        },
        {
          "path": ".claude/commands/rag-searches.md",
          "type": "blob",
          "size": 1822
        },
        {
          "path": ".claude/commands/rag-status.md",
          "type": "blob",
          "size": 1926
        },
        {
          "path": ".claude/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/hooks/SessionStart.sh",
          "type": "blob",
          "size": 1764
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 20650
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 8533
        }
      ],
      "files": {
        ".claude-plugin/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"startup|resume|clear|compact\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"./.claude/hooks/SessionStart.sh\",\n            \"timeout\": 60,\n            \"description\": \"Initialize RAG-MAF systems on session start\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"itmediatech-plugin-marketplace\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Official marketplace for dt-cli plugins and extensions\",\n  \"owner\": {\n    \"name\": \"ItMeDiaTech\",\n    \"email\": \"\",\n    \"url\": \"https://github.com/ItMeDiaTech\",\n    \"description\": \"Developer tools and AI-powered development assistance\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"rag-multi-agent-framework-plugin\",\n      \"version\": \"1.0.0\",\n      \"description\": \"Local RAG plugin with Multi-Agent Framework orchestration for context-aware development assistance\",\n      \"author\": {\n        \"name\": \"ItMeDiaTech\",\n        \"email\": \"\",\n        \"url\": \"https://github.com/ItMeDiaTech\"\n      },\n      \"repository\": \"https://github.com/ItMeDiaTech/dt-cli\",\n      \"source\": \"./\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"rag\",\n        \"retrieval-augmented-generation\",\n        \"vector-search\",\n        \"embeddings\",\n        \"multi-agent\",\n        \"maf\",\n        \"mcp\",\n        \"semantic-search\",\n        \"code-analysis\",\n        \"local-ai\"\n      ],\n      \"license\": \"MIT\",\n      \"tags\": [\"official\", \"rag\", \"multi-agent\", \"local\"]\n    }\n  ],\n  \"metadata\": {\n    \"lastUpdated\": \"2024-11-08T00:00:00Z\",\n    \"pluginCount\": 1,\n    \"categories\": [\"productivity\", \"ai-tools\", \"code-analysis\", \"search\"]\n  }\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"dt-cli-rag-maf\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Local RAG plugin with Multi-Agent Framework orchestration for context-aware development assistance\",\n  \"author\": {\n    \"name\": \"ItMeDiaTech\",\n    \"email\": \"\",\n    \"url\": \"https://github.com/ItMeDiaTech\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/ItMeDiaTech/dt-cli\",\n  \"homepage\": \"https://github.com/ItMeDiaTech/dt-cli\",\n  \"keywords\": [\n    \"rag\",\n    \"retrieval-augmented-generation\",\n    \"vector-search\",\n    \"embeddings\",\n    \"multi-agent\",\n    \"maf\",\n    \"mcp\",\n    \"semantic-search\",\n    \"code-analysis\",\n    \"local-ai\"\n  ],\n  \"commands\": [\n    \"./.claude/commands/rag-query.md\",\n    \"./.claude/commands/rag-index.md\",\n    \"./.claude/commands/rag-status.md\",\n    \"./.claude/commands/rag-save.md\",\n    \"./.claude/commands/rag-searches.md\",\n    \"./.claude/commands/rag-exec.md\",\n    \"./.claude/commands/rag-graph.md\",\n    \"./.claude/commands/rag-metrics.md\",\n    \"./.claude/commands/rag-query-advanced.md\"\n  ],\n  \"hooks\": \"./.claude-plugin/hooks.json\"\n}\n",
        ".claude/commands/rag-exec.md": "---\ndescription: Execute a saved search by ID or name\n---\n\n# Execute Saved Search Command\n\nExecute a previously saved search query.\n\n## Usage\n\n**Search ID or Name**: {{args}}\n\n## Instructions\n\nExecute a saved search using its ID or name.\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nsearch_ref = \"{{args}}\"\n\nif not search_ref or search_ref == \"{{args}}\":\n    print(\"Usage: /rag-exec <search_id_or_name>\")\n    print(\"\\nList saved searches with: /rag-searches\")\nelse:\n    try:\n        # First, try to find by name\n        response = httpx.get(\n            \"http://127.0.0.1:8765/searches\",\n            timeout=10.0\n        )\n\n        search_id = None\n\n        if response.status_code == 200:\n            result = response.json()\n            searches = result.get(\"searches\", [])\n\n            # Look for exact name match\n            for search in searches:\n                if search.get(\"name\") == search_ref or search.get(\"id\") == search_ref:\n                    search_id = search.get(\"id\")\n                    break\n\n        if not search_id:\n            search_id = search_ref  # Assume it's an ID\n\n        # Execute the search\n        exec_response = httpx.post(\n            f\"http://127.0.0.1:8765/searches/{search_id}/execute\",\n            timeout=30.0\n        )\n\n        if exec_response.status_code == 200:\n            result = exec_response.json()\n            search_info = result.get(\"search\", {})\n            results = result.get(\"results\", [])\n\n            print(f\"[?] Executing: {search_info.get('name', '')}\")\n            print(f\"   Query: {search_info.get('query', '')}\")\n            print(f\"   Results: {len(results)}\")\n            print()\n\n            for i, item in enumerate(results, 1):\n                meta = item.get(\"metadata\", {})\n                file_path = meta.get(\"file_path\", \"unknown\")\n                score = item.get(\"score\", 0)\n\n                print(f\"{i}. {file_path}\")\n                print(f\"   Relevance: {score:.2%}\")\n\n                content = item.get(\"content\", \"\")\n                if len(content) > 150:\n                    content = content[:147] + \"...\"\n                print(f\"   {content}\")\n                print()\n\n        elif exec_response.status_code == 404:\n            print(f\"[X] Search not found: {search_ref}\")\n            print(\"List available searches with: /rag-searches\")\n        else:\n            print(f\"[X] Server error: {exec_response.status_code}\")\n\n    except Exception as e:\n        print(f\"[X] Error: {e}\")\n        print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to run a saved search.\n",
        ".claude/commands/rag-graph.md": "---\ndescription: Query knowledge graph for code relationships\n---\n\n# Knowledge Graph Query Command\n\nQuery the knowledge graph to understand code relationships and dependencies.\n\n## Usage\n\n**Entity Name**: {{args}}\n\n## Instructions\n\nFind an entity (class, function, etc.) in the knowledge graph and show its relationships.\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nentity = \"{{args}}\"\n\nif not entity or entity == \"{{args}}\":\n    print(\"Usage: /rag-graph <entity_name>\")\n    print(\"\\nExamples:\")\n    print(\"  /rag-graph UserManager\")\n    print(\"  /rag-graph authenticate_user\")\nelse:\n    try:\n        # Get entity context\n        response = httpx.get(\n            f\"http://127.0.0.1:8765/knowledge-graph/entity/{entity}\",\n            timeout=10.0\n        )\n\n        if response.status_code == 200:\n            context = response.json()\n\n            entity_info = context.get(\"entity\", {})\n            used_by = context.get(\"used_by\", [])\n            uses = context.get(\"uses\", [])\n            related = context.get(\"related_entities\", [])\n\n            print(f\"\\n[PKG] Entity: {entity_info.get('name', entity)}\")\n            print(f\"   Type: {entity_info.get('type', 'unknown')}\")\n            print(f\"   File: {entity_info.get('file_path', 'unknown')}\")\n\n            line_num = entity_info.get('line_number')\n            if line_num:\n                print(f\"   Line: {line_num}\")\n\n            print()\n\n            # Used by (dependencies)\n            if used_by:\n                print(f\" USED BY ({len(used_by)}):\")\n                for dep in used_by[:5]:\n                    name = dep.get('name', '')\n                    dep_type = dep.get('type', '')\n                    rel = dep.get('relationship', '')\n                    print(f\"    {name} ({dep_type}) - {rel}\")\n                if len(used_by) > 5:\n                    print(f\"   ... and {len(used_by) - 5} more\")\n                print()\n\n            # Uses (what this entity depends on)\n            if uses:\n                print(f\" USES ({len(uses)}):\")\n                for dep in uses[:5]:\n                    name = dep.get('name', '')\n                    dep_type = dep.get('type', '')\n                    rel = dep.get('relationship', '')\n                    print(f\"    {name} ({dep_type}) - {rel}\")\n                if len(uses) > 5:\n                    print(f\"   ... and {len(uses) - 5} more\")\n                print()\n\n            # Related entities\n            if related:\n                print(f\"[LINK] RELATED ENTITIES ({len(related)}):\")\n                for rel_entity in related[:5]:\n                    name = rel_entity.get('name', '')\n                    rel_type = rel_entity.get('type', '')\n                    depth = rel_entity.get('depth', 0)\n                    print(f\"    {name} ({rel_type}) - depth {depth}\")\n                if len(related) > 5:\n                    print(f\"   ... and {len(related) - 5} more\")\n\n        elif response.status_code == 404:\n            print(f\"[X] Entity not found: {entity}\")\n            print(\"\\n[i] Make sure the knowledge graph is built.\")\n            print(\"   Re-index with: /rag-index\")\n        else:\n            print(f\"[X] Server error: {response.status_code}\")\n\n    except Exception as e:\n        print(f\"[X] Error: {e}\")\n        print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to query the knowledge graph.\n",
        ".claude/commands/rag-index.md": "---\ndescription: Index or re-index the codebase for RAG search\n---\n\n# RAG Index Command\n\nIndex or re-index the codebase to update the RAG system's knowledge.\n\n## Usage\n\nThe user wants to index the codebase. This will:\n- Scan all code files in the repository\n- Generate embeddings for code chunks\n- Store them in the local vector database\n\n## Instructions\n\n1. Trigger the indexing process via the MCP server\n2. Show progress to the user\n3. Display completion status\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nprint(\"[#] Starting codebase indexing...\")\nprint(\"This may take a few minutes depending on codebase size.\\n\")\n\ntry:\n    response = httpx.post(\n        \"http://127.0.0.1:8765/execute\",\n        json={\n            \"category\": \"rag\",\n            \"tool_name\": \"rag_index\",\n            \"parameters\": {\"root_path\": \".\"}\n        },\n        timeout=300.0  # 5 minutes timeout\n    )\n\n    if response.status_code == 200:\n        result = response.json()\n\n        if result.get(\"success\"):\n            status = result.get(\"status\", {})\n\n            print(\"[OK] Indexing complete!\\n\")\n            print(f\"[=] Status:\")\n            print(f\"   Indexed chunks: {status.get('indexed_chunks', 0)}\")\n            print(f\"   Embedding model: {status.get('embedding_model', 'unknown')}\")\n            print(f\"   Status: {status.get('status', 'unknown')}\")\n        else:\n            print(f\"Error: {result.get('error', 'Unknown error')}\")\n    else:\n        print(f\"MCP Server error: {response.status_code}\")\n\nexcept Exception as e:\n    print(f\"Error indexing codebase: {e}\")\n    print(\"Make sure the MCP server is running.\")\n```\n\nExecute this Python code to index the codebase.\n",
        ".claude/commands/rag-metrics.md": "---\ndescription: Display system metrics and performance dashboard\n---\n\n# Metrics Dashboard Command\n\nDisplay comprehensive system metrics and performance statistics.\n\n## Usage\n\nNo arguments required.\n\n## Instructions\n\nShows system health, query performance, cache stats, and recent activity.\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\ntry:\n    # Get all metrics\n    response = httpx.get(\n        \"http://127.0.0.1:8765/metrics\",\n        timeout=10.0\n    )\n\n    if response.status_code == 200:\n        metrics = response.json()\n\n        print(\"=\" * 70)\n        print(\"[=] RAG SYSTEM METRICS DASHBOARD\".center(70))\n        print(\"=\" * 70)\n        print()\n\n        # Health Status\n        health = metrics.get(\"health\", {})\n        if health:\n            status = health.get(\"status\", \"unknown\").upper()\n            status_emoji = \"[OK]\" if status == \"HEALTHY\" else \"[!]\"\n\n            print(f\"{status_emoji} SYSTEM HEALTH: {status}\")\n\n            error_rate = health.get(\"error_rate\", 0)\n            memory_mb = health.get(\"memory_usage_mb\", 0)\n            latency = health.get(\"avg_query_latency_ms\", 0)\n\n            print(f\"   Error Rate: {error_rate:.2%}\")\n            print(f\"   Memory: {memory_mb:.1f} MB\")\n            print(f\"   Avg Latency: {latency:.1f} ms\")\n            print()\n\n        # Query Performance\n        perf = metrics.get(\"performance\", {})\n        if perf:\n            print(\"[!] QUERY PERFORMANCE (7 days)\")\n\n            total = perf.get(\"total_queries\", 0)\n            qpd = perf.get(\"queries_per_day\", 0)\n            avg_time = perf.get(\"avg_execution_time_ms\", 0)\n            p95_time = perf.get(\"p95_execution_time_ms\", 0)\n\n            print(f\"   Total Queries: {total}\")\n            print(f\"   Queries/Day: {qpd:.1f}\")\n            print(f\"   Avg Time: {avg_time:.1f} ms\")\n            print(f\"   P95 Time: {p95_time:.1f} ms\")\n\n            feedback = perf.get(\"avg_feedback_score\")\n            if feedback is not None:\n                print(f\"   Avg Feedback: {feedback:.2f}/1.0\")\n\n            print()\n\n        # Cache Statistics\n        cache = metrics.get(\"cache\", {})\n        if cache:\n            print(\"[@] CACHE STATISTICS\")\n\n            entries = cache.get(\"total_entries\", 0)\n            size_mb = cache.get(\"total_size_mb\", 0)\n            avg_access = cache.get(\"average_access_count\", 0)\n\n            print(f\"   Total Entries: {entries}\")\n            print(f\"   Total Size: {size_mb:.2f} MB\")\n            print(f\"   Avg Access Count: {avg_access:.1f}\")\n            print()\n\n        # Get popular queries\n        try:\n            history_response = httpx.get(\n                \"http://127.0.0.1:8765/query-history?days=1\",\n                timeout=5.0\n            )\n\n            if history_response.status_code == 200:\n                history = history_response.json()\n                popular = history.get(\"popular_queries\", [])\n\n                if popular:\n                    print(\"[FIRE] TOP QUERIES (24h)\")\n                    for i, query_info in enumerate(popular[:5], 1):\n                        query = query_info.get(\"query\", \"\")\n                        count = query_info.get(\"count\", 0)\n\n                        if len(query) > 50:\n                            query = query[:47] + \"...\"\n\n                        print(f\"   {i}. {query} ({count}x)\")\n\n                    print()\n\n        except:\n            pass\n\n        print(\"=\" * 70)\n\n        print(\"\\n[i] Refresh with: /rag-metrics\")\n\n    else:\n        print(f\"[X] Server error: {response.status_code}\")\n\nexcept Exception as e:\n    print(f\"[X] Error: {e}\")\n    print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to display the metrics dashboard.\n",
        ".claude/commands/rag-query-advanced.md": "---\ndescription: Advanced RAG query with profiling and explanations\n---\n\n# Advanced RAG Query Command\n\nExecute an advanced RAG query with performance profiling and result explanations.\n\n## Usage\n\n**User Query**: {{args}}\n\n## Instructions\n\nThis command performs an advanced query with:\n- Performance profiling\n- Result explanations (why each result was returned)\n- Query suggestions\n- Saved search option\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nquery = \"{{args}}\"\n\nif not query or query == \"{{args}}\":\n    print(\"Usage: /rag-query-advanced <your query>\")\n    print(\"Example: /rag-query-advanced how does authentication work?\")\n    print(\"\\nFeatures:\")\n    print(\"  - Performance profiling\")\n    print(\"  - Result explanations\")\n    print(\"  - Query suggestions\")\nelse:\n    try:\n        # Execute query\n        response = httpx.post(\n            \"http://127.0.0.1:8765/query\",\n            json={\n                \"query\": query,\n                \"n_results\": 5,\n                \"use_hybrid\": True,\n                \"use_reranking\": True\n            },\n            timeout=30.0\n        )\n\n        if response.status_code == 200:\n            result = response.json()\n            results_list = result.get(\"results\", [])\n            metadata = result.get(\"metadata\", {})\n\n            print(f\"\\n[?] Query: {query}\")\n            print(f\"[=] Results: {len(results_list)} found\")\n            print()\n\n            # Display results\n            for i, item in enumerate(results_list, 1):\n                item_meta = item.get(\"metadata\", {})\n                file_path = item_meta.get(\"file_path\", \"unknown\")\n                score = item.get(\"score\", 0)\n\n                print(f\"{i}. {file_path}\")\n                print(f\"   Relevance: {score:.2%}\")\n\n                # Show snippet\n                content = item.get(\"content\", \"\")\n                if len(content) > 200:\n                    content = content[:197] + \"...\"\n                print(f\"   {content}\")\n                print()\n\n            # Get similar queries\n            try:\n                sugg_response = httpx.get(\n                    f\"http://127.0.0.1:8765/suggestions?partial={query[:20]}\",\n                    timeout=5.0\n                )\n\n                if sugg_response.status_code == 200:\n                    sugg_data = sugg_response.json()\n                    suggestions = sugg_data.get(\"suggestions\", [])\n\n                    if suggestions and len(suggestions) > 1:\n                        print(\"\\n[i] Related queries you might try:\")\n                        for sugg in suggestions[:3]:\n                            if sugg != query:\n                                print(f\"   - {sugg}\")\n            except:\n                pass\n\n            # Offer to save search\n            print(\"\\n[@] Save this search? Use: /rag-save '{query}'\")\n\n        else:\n            print(f\"[X] Server error: {response.status_code}\")\n\n    except httpx.TimeoutException:\n        print(\"[TIMER]  Query timed out. Try a simpler query or check server status.\")\n    except Exception as e:\n        print(f\"[X] Error: {e}\")\n        print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to perform an advanced RAG query with profiling and explanations.\n",
        ".claude/commands/rag-query.md": "---\ndescription: Query the RAG system for relevant code and documentation\n---\n\n# RAG Query Command\n\nQuery the local RAG (Retrieval-Augmented Generation) system to find relevant code and documentation.\n\n## Usage\n\nThe user is asking you to query the RAG system. Use the MCP server to perform the query.\n\n**User Query**: {{args}}\n\n## Instructions\n\n1. Parse the user's query from the arguments\n2. Use the RAG system via HTTP request to the MCP server at http://127.0.0.1:8765\n3. Execute a POST request to `/rag/query` with the query\n4. Format and display the results to the user\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nquery = \"{{args}}\"\n\nif not query or query == \"{{args}}\":\n    print(\"Usage: /rag-query <your query>\")\n    print(\"Example: /rag-query how does authentication work?\")\nelse:\n    try:\n        response = httpx.post(\n            \"http://127.0.0.1:8765/rag/query\",\n            json={\"query\": query},\n            timeout=30.0\n        )\n\n        if response.status_code == 200:\n            result = response.json()\n\n            if result.get(\"success\"):\n                results_list = result.get(\"results\", [])\n\n                print(f\"\\n[?] Found {len(results_list)} relevant results:\\n\")\n\n                for i, item in enumerate(results_list[:5], 1):\n                    metadata = item.get(\"metadata\", {})\n                    file_path = metadata.get(\"file_path\", \"unknown\")\n                    score = 1 - item.get(\"distance\", 1)\n\n                    print(f\"{i}. {file_path} (relevance: {score:.2%})\")\n                    print(f\"   {item.get('text', '')[:150]}...\")\n                    print()\n            else:\n                print(f\"Error: {result.get('error', 'Unknown error')}\")\n        else:\n            print(f\"MCP Server error: {response.status_code}\")\n\n    except Exception as e:\n        print(f\"Error querying RAG system: {e}\")\n        print(\"Make sure the MCP server is running.\")\n```\n\nExecute this Python code to query the RAG system and display results.\n",
        ".claude/commands/rag-save.md": "---\ndescription: Save a search query for quick access later\n---\n\n# Save Search Command\n\nSave a frequently used query for quick access.\n\n## Usage\n\n**Arguments**: {{args}}\n\n## Instructions\n\nSave a search query with optional name, description, and tags.\n\nFormat: `name | query | description | tags`\n\nExample: `/rag-save auth | authentication flow | Find auth code | auth,security`\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nargs = \"{{args}}\"\n\nif not args or args == \"{{args}}\":\n    print(\"Usage: /rag-save <name> | <query> | [description] | [tags]\")\n    print(\"\\nExamples:\")\n    print(\"  /rag-save auth | authentication flow\")\n    print(\"  /rag-save auth | authentication flow | Find auth code | auth,security\")\n    print(\"\\nTo list saved searches: /rag-searches\")\nelse:\n    try:\n        # Parse arguments\n        parts = [p.strip() for p in args.split('|')]\n\n        if len(parts) < 2:\n            print(\"[X] Error: Need at least name and query\")\n            print(\"Format: <name> | <query> | [description] | [tags]\")\n        else:\n            name = parts[0]\n            query = parts[1]\n            description = parts[2] if len(parts) > 2 else \"\"\n            tags = parts[3].split(',') if len(parts) > 3 else []\n            tags = [t.strip() for t in tags if t.strip()]\n\n            # Save search\n            response = httpx.post(\n                \"http://127.0.0.1:8765/searches\",\n                json={\n                    \"name\": name,\n                    \"query\": query,\n                    \"description\": description,\n                    \"tags\": tags,\n                    \"n_results\": 5\n                },\n                timeout=10.0\n            )\n\n            if response.status_code == 200:\n                result = response.json()\n                search = result.get(\"search\", {})\n\n                print(f\"[OK] Saved search '{name}'\")\n                print(f\"   Query: {query}\")\n                if description:\n                    print(f\"   Description: {description}\")\n                if tags:\n                    print(f\"   Tags: {', '.join(tags)}\")\n\n                print(f\"\\n[i] Execute with: /rag-exec {search.get('id', '')}\")\n\n            else:\n                print(f\"[X] Server error: {response.status_code}\")\n\n    except Exception as e:\n        print(f\"[X] Error: {e}\")\n        print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to save a search query.\n",
        ".claude/commands/rag-searches.md": "---\ndescription: List and manage saved searches\n---\n\n# Saved Searches Command\n\nList all saved searches with filtering options.\n\n## Usage\n\n**Filter**: {{args}} (optional tag filter)\n\n## Instructions\n\nList all saved searches, optionally filtered by tag.\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nfilter_tags = \"{{args}}\"\nif filter_tags == \"{{args}}\":\n    filter_tags = None\n\ntry:\n    # Get saved searches\n    params = {}\n    if filter_tags:\n        params['tags'] = filter_tags\n\n    response = httpx.get(\n        \"http://127.0.0.1:8765/searches\",\n        params=params,\n        timeout=10.0\n    )\n\n    if response.status_code == 200:\n        result = response.json()\n        searches = result.get(\"searches\", [])\n        total = result.get(\"total\", 0)\n\n        if total == 0:\n            print(\" No saved searches found.\")\n            print(\"\\n[i] Save a search with: /rag-save <name> | <query>\")\n        else:\n            print(f\"[#] Saved Searches ({total}):\")\n            print()\n\n            for search in searches:\n                name = search.get(\"name\", \"\")\n                query = search.get(\"query\", \"\")\n                search_id = search.get(\"id\", \"\")\n                tags = search.get(\"tags\", [])\n                use_count = search.get(\"use_count\", 0)\n\n                print(f\"   {name}\")\n                print(f\"    Query: {query}\")\n\n                if tags:\n                    print(f\"    Tags: {', '.join(tags)}\")\n\n                print(f\"    Used: {use_count} times\")\n                print(f\"    Execute: /rag-exec {search_id}\")\n                print()\n\n    else:\n        print(f\"[X] Server error: {response.status_code}\")\n\nexcept Exception as e:\n    print(f\"[X] Error: {e}\")\n    print(\"Make sure the MCP server is running on port 8000.\")\n```\n\nExecute this code to list saved searches.\n",
        ".claude/commands/rag-status.md": "---\ndescription: Check the status of the RAG and MAF systems\n---\n\n# RAG Status Command\n\nCheck the current status of the RAG and Multi-Agent Framework systems.\n\n## Usage\n\nDisplay system status including:\n- RAG system information\n- MAF agent status\n- MCP server status\n\n## Implementation\n\n```python\nimport httpx\nimport json\n\nprint(\"[=] RAG-MAF System Status\\n\")\n\ntry:\n    response = httpx.get(\n        \"http://127.0.0.1:8765/status\",\n        timeout=10.0\n    )\n\n    if response.status_code == 200:\n        status = response.json()\n\n        # RAG Status\n        rag = status.get(\"rag\", {})\n        print(\"[?] RAG System:\")\n        print(f\"   Indexed chunks: {rag.get('indexed_chunks', 0)}\")\n        print(f\"   Embedding model: {rag.get('embedding_model', 'unknown')}\")\n        print(f\"   Embedding dimension: {rag.get('embedding_dimension', 0)}\")\n        print(f\"   Status: {rag.get('status', 'unknown')}\")\n        print()\n\n        # MAF Status\n        maf = status.get(\"maf\", {})\n        print(\"[AI] Multi-Agent Framework:\")\n        agents = maf.get('agents', [])\n        print(f\"   Available agents: {', '.join(agents)}\")\n        print(f\"   Active contexts: {maf.get('active_contexts', 0)}\")\n        print(f\"   RAG enabled: {'Yes' if maf.get('rag_enabled') else 'No'}\")\n        print()\n\n        # Server Status\n        server = status.get(\"server\", {})\n        print(\"[+] MCP Server:\")\n        print(f\"   Host: {server.get('host', 'unknown')}\")\n        print(f\"   Port: {server.get('port', 'unknown')}\")\n        print(f\"   Status: {server.get('status', 'unknown')}\")\n\n    else:\n        print(f\"[X] MCP Server error: {response.status_code}\")\n\nexcept httpx.ConnectError:\n    print(\"[X] Cannot connect to MCP server\")\n    print(\"   The server may not be running.\")\n    print(\"   Try restarting your Claude Code session.\")\nexcept Exception as e:\n    print(f\"[X] Error: {e}\")\n```\n\nExecute this Python code to display system status.\n",
        ".claude/hooks/SessionStart.sh": "#!/bin/bash\n# SessionStart Hook for RAG-MAF Plugin\n# Automatically initializes the RAG and MAF systems when Claude Code session starts\n\necho \"[*] Initializing RAG-MAF Plugin...\"\n\n# Get the plugin directory\nPLUGIN_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/../..\" && pwd)\"\n\n# Check if MCP server is already running\nMCP_PID=$(pgrep -f \"mcp_server/server.py\")\n\nif [ -z \"$MCP_PID\" ]; then\n    echo \"[+] Starting MCP Server...\"\n\n    # Start MCP server in background\n    cd \"$PLUGIN_DIR\"\n    python3 -m src.mcp_server.server > /tmp/rag-maf-mcp.log 2>&1 &\n\n    # Wait for server to start\n    sleep 2\n\n    # Check if server started successfully\n    if pgrep -f \"mcp_server/server.py\" > /dev/null; then\n        echo \"[OK] MCP Server started successfully\"\n    else\n        echo \"[WARNING] MCP Server failed to start. Check /tmp/rag-maf-mcp.log for details\"\n    fi\nelse\n    echo \"[OK] MCP Server already running (PID: $MCP_PID)\"\nfi\n\n# Check if codebase is indexed\nif [ ! -d \"$PLUGIN_DIR/.rag_data\" ]; then\n    echo \"[#] First run detected. Indexing codebase...\"\n    echo \"    (This may take a few minutes)\"\n\n    # Trigger indexing in background\n    python3 -c \"\nimport sys\nsys.path.insert(0, '$PLUGIN_DIR/src')\nfrom rag import QueryEngine\nengine = QueryEngine()\nengine.index_codebase('.')\nprint('[OK] Codebase indexed successfully')\n\" &\n\n    echo \"[...] Indexing in progress (running in background)...\"\nelse\n    echo \"[OK] Codebase already indexed\"\nfi\n\necho \"\"\necho \"[**] RAG-MAF Plugin ready!\"\necho \"\"\necho \"Available commands:\"\necho \"  /rag-query <query>  - Query the RAG system\"\necho \"  /rag-index          - Re-index the codebase\"\necho \"  /rag-status         - Check system status\"\necho \"\"\necho \"The plugin will automatically provide context to Claude as needed.\"\necho \"\"\n",
        "README.md": "# dt-cli: 100% Open Source RAG/MAF/LLM Development System\n\n**A comprehensive development assistance system combining Retrieval-Augmented Generation (RAG), Multi-Agent Framework (MAF), and configurable LLM backends - completely open source and free.**\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n[![Open Source](https://img.shields.io/badge/Open%20Source-100%25-green.svg)](https://github.com/ItMeDiaTech/dt-cli)\n\n---\n\n## Overview\n\n**dt-cli** is a powerful development assistant that provides:\n- **Intelligent code search** using semantic RAG with AST-based chunking\n- **Automated debugging** with multi-agent error analysis\n- **Code review** with security checks and quality scoring\n- **Knowledge graph** for dependency tracking and impact analysis\n- **Quality evaluation** using RAGAS metrics\n- **Hybrid search** combining semantic and keyword algorithms\n- **Three interaction modes**: Claude Code plugin, Interactive TUI, or REST API\n\n**100% Free & Open Source** - No API keys required for local LLMs (Ollama, vLLM)\n\n---\n\n## Key Features\n\n### Advanced RAG System\n- **AST-Based Chunking**: Intelligent code parsing using tree-sitter for Python, JavaScript, TypeScript\n- **BGE Embeddings**: Instruction-aware embeddings for better code understanding\n- **Auto-Trigger**: Automatic determination of when to use RAG vs. direct LLM\n- **Intent Classification**: Semantic routing based on query intent\n\n### Agentic Debugging\n- **Error Analysis**: Automatic root cause identification from stack traces\n- **Fix Suggestions**: Multi-step reasoning for proposed fixes\n- **Security Checks**: Detection of SQL injection, XSS, and OWASP Top 10 vulnerabilities\n- **Code Review**: Quality scoring (0-10) with severity-categorized issues\n\n### Knowledge Graph\n- **Dependency Tracking**: What does this code depend on?\n- **Impact Analysis**: What breaks if I change this?\n- **Usage Finding**: Where is this function/class used?\n- **Relationship Mapping**: Full code relationship graph\n\n### Quality Evaluation\n- **RAGAS Metrics**: Context relevance, answer faithfulness, answer relevance\n- **Hybrid Search**: BM25 + semantic search with tunable weights\n- **A/B Testing**: Compare different RAG configurations\n- **Performance Metrics**: Query time, cache hit rate, confidence scores\n\n### Three Interaction Modes\n\n**1. Claude Code Plugin (MCP)**\n```bash\n# Auto-configured via .claude/mcp-config.json\n# Use dt-cli tools seamlessly in Claude Code conversations\n```\n\n**2. Intelligent Interactive CLI**  **ENHANCED**\n```bash\npython src/cli/interactive.py\n# Natural language interface with intelligent context awareness\n# Hierarchical session memory across CLI restarts\n# Auto-discovers project files for enhanced context\n# 10+ slash commands for power users\n```\n\n**NEW Features in Interactive CLI:**\n- **Session History with Hierarchical Memory** - Conversations persist across sessions with intelligent compression\n- **Context-Aware Queries** - Automatically includes relevant project files in queries\n- **Smart File Discovery** - Indexes your project automatically for better context\n- **Natural Language Input** - Just type what you need, no menu navigation required\n- **Conversation Continuity** - Resume from where you left off, even days later\n- **Importance Scoring** - Critical conversations are never forgotten\n\n**3. REST API**\n```bash\n# Start server\npython src/mcp_server/standalone_server.py\n\n# Use API\ncurl http://localhost:8765/query -X POST -d '{\"query\": \"...\"}'\n```\n\n---\n\n## Quick Start\n\n### Prerequisites\n- Python 3.8+\n- Git\n\n### Installation\n\n**Quick Setup (Recommended - Uses Virtual Environment)**\n\n```bash\n# Clone repository\ngit clone https://github.com/ItMeDiaTech/dt-cli.git\ncd dt-cli\n\n# Run automated setup script\n./setup-venv.sh\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Start interactive TUI\npython dt-cli.py\n```\n\n**Alternative: Manual Installation**\n\nOn modern Linux distributions (Ubuntu 24.04+, Debian 12+), you must use a virtual environment due to PEP 668:\n\n```bash\n# Option A: Use the automated script (recommended)\n./setup-venv.sh\n\n# Option B: Manual virtual environment setup\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**That's it!** The system is ready to use.\n\n> **Note**: Always activate the virtual environment with `source venv/bin/activate` before running dt-cli.\n\n### First Steps\n\n**Option 1: Interactive TUI**\n```bash\npython dt-cli.py\n# Choose from the menu:\n# 1. Ask a Question\n# 2. Debug an Error\n# 3. Review Code\n# etc.\n```\n\n**Option 2: Start Server for API/Claude Code**\n```bash\n# Start the server\npython src/mcp_server/standalone_server.py\n\n# Server runs on http://localhost:8765\n# Claude Code will auto-detect via .claude/mcp-config.json\n```\n\n**Option 3: Use as Claude Code Plugin**\n1. Ensure server is running\n2. Claude Code auto-detects MCP configuration\n3. Use dt-cli tools directly in conversations\n\n---\n\n##  Usage\n\n### Interactive CLI with Intelligent Features \n\nThe **new Interactive CLI** (`src/cli/interactive.py`) provides a natural language interface with production-grade conversation memory:\n\n```bash\npython src/cli/interactive.py\n```\n\n**Key Features:**\n\n**Hierarchical Session Memory** (Based on 2024-2025 Research)\n```\n> Review codebase and find any errors\n[Analyzing entire codebase in /home/user/dt-cli...]\n[System remembers this conversation across sessions]\n\n> (Next day) What errors did we discuss yesterday?\n[Retrieves relevant history from hierarchical memory]\n```\n\n- **4-Level Memory Hierarchy:**\n  - Level 1: Working Memory (last 20 turns, full detail)\n  - Level 2: Summarized Context (automatic compression)\n  - Level 3: Session Summary (when closed)\n  - Level 4: Archived Sessions (retrievable history)\n\n- **Automatic Compression:** ~90% memory reduction while preserving important information\n- **Importance Scoring:** Critical conversations (debug, code changes) never forgotten\n- **Persistent Storage:** `~/.dt_cli_sessions.json` survives CLI restarts\n\n**Context-Aware Queries**\n```\n> Where is authentication handled?\n[Automatically includes relevant auth files as context]\n[Project: dt-cli] Where is authentication handled?\n  Context files: src/auth/*.py (intelligently selected)\n```\n\n**Slash Commands:**\n```\n/history          - View current session with hierarchical memory\n/sessions         - List all sessions (current + archived)\n/stats            - Show memory usage and statistics\n/clearsession     - Clear all history (with confirmation)\n/verbosity <level> - Set output detail (quiet/normal/verbose)\n/folder           - Change project folder\n/help             - Show comprehensive help\n/exit             - Exit and save session\n```\n\n**Natural Language Interaction:**\n```\n> Review codebase and find any errors\n   Detects REVIEW intent\n   Uses project folder automatically\n   No redundant prompts!\n\n> Debug this authentication error\n   Detects DEBUG intent\n   High importance score (0.95)\n   Always kept in memory\n\n> What did we just fix?\n   Follows up using conversation history\n   Context from previous turns\n```\n\n**Session Statistics Example:**\n```\n> /stats\n\nSession Statistics\n\nMetric                    | Value\n\nCurrent Session Active    | Yes\nCurrent Session Turns     | 45\nArchived Sessions         | 3\nTotal Archived Turns      | 187\nTotal All Turns           | 232\nStorage File              | ~/.dt_cli_sessions.json\n```\n\n### Traditional Menu Interface (dt-cli.py)\n\nFor users preferring a traditional menu:\n\n```\n\n      dt-cli - Interactive Terminal UI       \n   RAG/MAF/LLM System - 100% Open Source     \n\n\nMain Menu:\n  1. Ask a Question (RAG Query)       Semantic code search\n  2. Debug an Error                    AI error analysis\n  3. Review Code                       Quality & security checks\n  4. Explore Knowledge Graph           Dependencies & impact\n  5. Evaluate RAG Quality              RAGAS metrics\n  6. Hybrid Search                     Semantic + keyword\n  7. View Statistics                   System health\n  8. Settings                          Configuration\n  9. Help                             Documentation\n  0. Exit\n```\n\n### API Endpoints\n\n**Query RAG System**\n```bash\ncurl -X POST http://localhost:8765/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"How does authentication work?\",\n    \"auto_trigger\": true\n  }'\n```\n\n**Debug Error**\n```bash\ncurl -X POST http://localhost:8765/debug \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"error_output\": \"KeyError: value...\",\n    \"auto_extract_code\": true\n  }'\n```\n\n**Review Code**\n```bash\ncurl -X POST http://localhost:8765/review \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"code\": \"def login(user, pwd): ...\",\n    \"language\": \"python\"\n  }'\n```\n\n**Build Knowledge Graph**\n```bash\ncurl -X POST http://localhost:8765/graph/build \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"path\": \"src/\"}'\n```\n\n**Query Knowledge Graph**\n```bash\ncurl -X POST http://localhost:8765/graph/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"entity_name\": \"parse_code\",\n    \"query_type\": \"dependencies\"\n  }'\n```\n\n**Evaluate RAG**\n```bash\ncurl -X POST http://localhost:8765/evaluate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"test query\",\n    \"retrieved_contexts\": [\"ctx1\", \"ctx2\"],\n    \"generated_answer\": \"answer\",\n    \"ground_truth\": \"expected\"\n  }'\n```\n\n**Hybrid Search**\n```bash\ncurl -X POST http://localhost:8765/hybrid-search \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"authentication\",\n    \"documents\": [\"doc1\", \"doc2\"],\n    \"semantic_weight\": 0.7,\n    \"keyword_weight\": 0.3\n  }'\n```\n\n**View Statistics**\n```bash\ncurl http://localhost:8765/info\ncurl http://localhost:8765/graph/stats\ncurl http://localhost:8765/auto-trigger/stats\n```\n\n---\n\n##  Configuration\n\n### LLM Configuration (`llm-config.yaml`)\n\n```yaml\nllm:\n  provider: \"openai\"     # or \"anthropic\", \"local\", \"ollama\"\n  model: \"gpt-4\"\n  temperature: 0.7\n  api_key_env: \"OPENAI_API_KEY\"  # Environment variable name\n\nembedding:\n  model: \"BAAI/bge-base-en-v1.5\"\n  device: \"cpu\"  # or \"cuda\"\n  instruction_prefix: \"Represent this code for retrieval: \"\n\nauto_trigger:\n  enabled: true\n  similarity_threshold: 0.7\n  intent_threshold: 0.6\n  cache_ttl: 900  # 15 minutes\n\nvector_store:\n  collection_name: \"dt_cli_code\"\n  persist_directory: \"./chroma_db\"\n  chunk_size: 1000\n  chunk_overlap: 200\n\nhybrid_search:\n  semantic_weight: 0.7\n  keyword_weight: 0.3\n  query_expansion: true\n\nknowledge_graph:\n  cache_size: 1000\n  analysis_timeout: 300\n```\n\n### Environment Variables (`.env`)\n\n```bash\n# LLM API Keys (choose what you need)\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\n\n# Server Configuration\nDT_CLI_HOST=0.0.0.0\nDT_CLI_PORT=58432\n\n# Logging\nLOG_LEVEL=INFO\n```\n\n### Using Local LLMs (No API Keys!)\n\n```yaml\n# llm-config.yaml\nllm:\n  provider: \"ollama\"\n  model: \"codellama:7b\"\n  base_url: \"http://localhost:11434\"\n  # No API key needed!\n```\n\n---\n\n##  Architecture\n\n### System Components\n\n```\ndt-cli/\n src/\n    rag/                   # RAG System\n       parsers.py         # Tree-sitter AST parsers\n       ast_chunker.py     # Intelligent code chunking\n       embeddings.py      # BGE embeddings\n       intent_router.py   # Query intent classification\n       auto_trigger.py    # Auto-trigger orchestration\n   \n    debugging/             # Agentic Debugging\n       debug_agent.py     # Error analysis agent\n       review_agent.py    # Code review agent\n   \n    graph/                 # Knowledge Graph\n       knowledge_graph.py # Dependency tracking\n   \n    evaluation/            # Quality Metrics\n       ragas.py           # RAGAS evaluator\n       hybrid_search.py   # BM25 + semantic search\n   \n    mcp_server/            # MCP Server\n       standalone_server.py  # FastAPI server\n   \n    cli/                   # Interactive TUI\n        interactive.py     # Rich-based interface\n\n .claude/\n    mcp-config.json        # Claude Code integration\n\n dt-cli.py                  # Entry point\n```\n\n### Data Flow\n\n```\nUser Query\n    \nAuto-Trigger (Intent Classification)\n    \n\n    RAG      Direct   \n  Search      LLM     \n\n                 \n   Context    No Context\n                 \n  \n     LLM Provider  \n   (OpenAI/Ollama) \n  \n           \n        Response\n```\n\n---\n\n##  Documentation\n\n### Guides\n- [Integration Guide](./INTEGRATION_GUIDE.md) - Complete integration documentation\n- [Installation](./docs/guides/INSTALLATION.md) - Detailed installation instructions\n- [Quick Start](./docs/guides/QUICKSTART.md) - Get started in 5 minutes\n- [User Guide](./docs/guides/USER_GUIDE.md) - Comprehensive user documentation\n- [Architecture](./docs/guides/ARCHITECTURE.md) - System architecture details\n\n### Implementation Phases\n- [Phase 1: AST Chunking & Auto-Trigger](./docs/phases/PHASE1_WEEK1_COMPLETE.md)\n- [Phase 2: Agentic Debugging](./docs/phases/PHASE2_COMPLETE.md)\n- [Phase 3: Knowledge Graph](./docs/phases/PHASE3_COMPLETE.md)\n- [Phase 4: RAGAS & Hybrid Search](./docs/phases/PHASE4_COMPLETE.md)\n\n### Reference\n- [API Reference](./docs/API_REFERENCE.md) - Complete API documentation\n- [Configuration Guide](./docs/CONFIGURATION.md) - All configuration options\n\n---\n\n##  Development\n\n### Project Structure\n\n```\nsrc/\n rag/           # Retrieval-Augmented Generation\n maf/           # Multi-Agent Framework\n llm/           # LLM provider abstraction\n config/        # Configuration management\n debugging/     # Debug & review agents\n graph/         # Knowledge graph system\n evaluation/    # Quality evaluation\n mcp_server/    # MCP server implementation\n cli/           # Interactive TUI\n\ntests/             # Comprehensive test suite\n rag/\n debugging/\n graph/\n evaluation/\n cli/\n\ndocs/              # Documentation\n guides/        # User guides\n phases/        # Implementation phases\n archive/       # Historical documentation\n```\n\n### Running Tests\n\n```bash\n# Install test dependencies\npip install pytest pytest-asyncio\n\n# Run all tests\npytest\n\n# Run specific test suite\npytest tests/rag/\npytest tests/debugging/\npytest tests/cli/\n\n# Run with coverage\npytest --cov=src tests/\n```\n\n### Contributing\n\nWe welcome contributions! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Add tests\n5. Commit with clear messages\n6. Push to your fork\n7. Open a Pull Request\n\n---\n\n##  Use Cases\n\n### For Developers\n- **Codebase Navigation**: Quickly understand large codebases\n- **Bug Fixing**: Get automated error analysis and fix suggestions\n- **Code Review**: Catch security issues before deployment\n- **Refactoring**: Understand impact before making changes\n\n### For Teams\n- **Knowledge Sharing**: Build team knowledge graph\n- **Quality Assurance**: Automated code quality checks\n- **Documentation**: Generate context-aware documentation\n- **Onboarding**: Help new developers understand code\n\n### For Learning\n- **Code Understanding**: Learn how code works through Q&A\n- **Best Practices**: Get suggestions aligned with standards\n- **Security**: Learn about common vulnerabilities\n- **Patterns**: Discover architectural patterns in code\n\n---\n\n##  Performance\n\n### Benchmarks\n\n| Operation | Avg Time | Cache Hit Rate |\n|-----------|----------|----------------|\n| RAG Query | 245ms | 67% |\n| Error Debug | 1.2s | N/A |\n| Code Review | 2.5s | N/A |\n| Graph Build | 15s (1000 files) | N/A |\n| Graph Query | 50ms | 85% |\n\n### Optimization Tips\n\n1. **Use Hybrid Search Weights Tuning**\n   ```python\n   from src.evaluation.hybrid_search import HybridSearch\n   search = HybridSearch()\n   search.tune_weights(queries, ground_truth, scores)\n   ```\n\n2. **Adjust Chunk Size for Your Codebase**\n   - Smaller chunks (500-800): Better precision\n   - Larger chunks (1500-2000): Better context\n\n3. **Pre-build Knowledge Graph**\n   ```bash\n   curl -X POST http://localhost:8765/graph/build \\\n     -d '{\"path\": \"src/\"}'\n   ```\n\n4. **Use Auto-Trigger Threshold Tuning**\n   - Higher (0.8+): More direct LLM calls, faster\n   - Lower (0.6-): More RAG usage, better context\n\n---\n\n##  Troubleshooting\n\n### Common Issues\n\n**Server Won't Start**\n```bash\n# Check if port is in use\nlsof -i :8765\n\n# Use different port\npython src/mcp_server/standalone_server.py --port 8766\n```\n\n**Import Errors**\n```bash\n# Ensure correct directory\ncd dt-cli\n\n# Set PYTHONPATH\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\n```\n\n**Tree-sitter Errors**\n```bash\n# Reinstall parsers\nrm -rf ~/.tree-sitter\npython -c \"from src.rag.parsers import ParserRegistry; ParserRegistry()\"\n```\n\n**Low RAG Quality**\n1. Tune hybrid search weights\n2. Adjust chunk size in config\n3. Use RAGAS evaluation to identify issues\n\n**Claude Code Integration Issues**\n1. Verify server is running: `curl http://localhost:8765/health`\n2. Check `.claude/mcp-config.json` exists\n3. Restart Claude Code\n4. Check logs for errors\n\nSee [Integration Guide](./INTEGRATION_GUIDE.md) for detailed troubleshooting.\n\n---\n\n##  Features Roadmap\n\n###  Completed (v1.0)\n- AST-based chunking with tree-sitter\n- BGE embeddings with instruction prefix\n- Auto-trigger with intent classification\n- Debug agent with error analysis\n- Code review agent with security checks\n- Knowledge graph with dependency tracking\n- RAGAS evaluation metrics\n- Hybrid search (BM25 + semantic)\n- Interactive TUI with Rich\n- Claude Code MCP integration\n- REST API server\n\n###  In Progress\n- Additional language support (Go, Rust, Java)\n- Web UI dashboard\n- VS Code extension\n- Docker containerization\n\n###  Planned\n- Conversation memory across sessions\n- Custom agent creation framework\n- Team collaboration features\n- Integration with CI/CD pipelines\n- Metrics dashboard\n- Plugin marketplace\n\n---\n\n##  License\n\nMIT License - see [LICENSE](./LICENSE) file for details.\n\nThis project is 100% free and open source. You can:\n-  Use commercially\n-  Modify and distribute\n-  Use privately\n-  Sublicense\n\n---\n\n##  Acknowledgments\n\nBuilt with these amazing open source projects:\n- [sentence-transformers](https://github.com/UKPLab/sentence-transformers) - Embeddings\n- [ChromaDB](https://github.com/chroma-core/chroma) - Vector database\n- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent orchestration\n- [FastAPI](https://github.com/tiangolo/fastapi) - REST API framework\n- [Rich](https://github.com/Textualize/rich) - Terminal UI\n- [tree-sitter](https://github.com/tree-sitter/tree-sitter) - Code parsing\n- [rank-bm25](https://github.com/dorianbrown/rank_bm25) - Keyword search\n\n---\n\n##  Support\n\n- **Issues**: [GitHub Issues](https://github.com/ItMeDiaTech/dt-cli/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/ItMeDiaTech/dt-cli/discussions)\n- **Documentation**: [docs/](./docs/)\n\n---\n\n##  Quick Links\n\n- [Installation Guide](./INTEGRATION_GUIDE.md)\n- [Interactive TUI Demo](#-three-interaction-modes)\n- [API Documentation](#-usage)\n- [Configuration Options](#%EF%B8%8F-configuration)\n- [Architecture Overview](#%EF%B8%8F-architecture)\n- [Contributing Guidelines](#%EF%B8%8F-development)\n\n---\n\n**Made with  by the dt-cli team | 100% Open Source**\n",
        "docs/README.md": "# dt-cli Documentation\n\nWelcome to the dt-cli documentation! This guide will help you navigate all available documentation.\n\n---\n\n##  Documentation Structure\n\n```\ndocs/\n README.md              # This file - documentation index\n guides/                # User and installation guides\n phases/                # Implementation phase documentation\n archive/               # Historical/deprecated documentation\n```\n\n---\n\n##  Getting Started\n\n**New to dt-cli?** Start here:\n\n1. **[Main README](../README.md)** - Overview, features, quick start\n2. **[Integration Guide](../INTEGRATION_GUIDE.md)** - Complete setup guide with examples\n3. **[Quick Start Guide](./guides/QUICKSTART.md)** - Get up and running in 5 minutes\n\n---\n\n##  User Guides\n\n### Installation & Setup\n- **[Installation Guide](./guides/INSTALLATION.md)** - Detailed installation instructions\n- **[Quick Start](./guides/QUICKSTART.md)** - Fast track to getting started\n- **[Quick Start (Open Source)](./guides/QUICKSTART_OPEN_SOURCE.md)** - Using only open source components\n- **[Ubuntu Deployment](./guides/UBUNTU_DEPLOYMENT_GUIDE.md)** - Complete Ubuntu server deployment\n- **[Quick Start (Ubuntu)](./guides/QUICKSTART_UBUNTU.md)** - Ubuntu-specific quick start\n\n### Usage & Configuration\n- **[User Guide](./guides/USER_GUIDE.md)** - Comprehensive user documentation\n- **[Integration Guide](../INTEGRATION_GUIDE.md)** - All three usage modes explained\n  - Claude Code MCP Plugin\n  - Interactive Terminal UI\n  - REST API\n\n### Architecture & Design\n- **[Architecture](./guides/ARCHITECTURE.md)** - System architecture and design\n- **[Implementation Roadmap](./guides/IMPLEMENTATION_ROADMAP.md)** - Development roadmap\n\n---\n\n##  Implementation Phases\n\nThe dt-cli project was implemented in 4 phases:\n\n### Phase 1: RAG Foundation & Auto-Trigger\n- **[Week 1: AST Chunking & BGE Embeddings](./phases/PHASE1_WEEK1_COMPLETE.md)**\n  - Tree-sitter AST parsing\n  - BGE embeddings with instruction prefix\n  - Intelligent code chunking\n\n- **[Week 2: Intent-Based Auto-Triggering](./phases/PHASE1_WEEK2_COMPLETE.md)**\n  - Query intent classification\n  - Automatic RAG vs direct LLM routing\n  - Context-aware triggering\n\n### Phase 2: Agentic Debugging\n- **[Agentic Debugging Workflows](./phases/PHASE2_COMPLETE.md)**\n  - Debug agent for error analysis\n  - Code review agent with security checks\n  - Multi-step reasoning with LangGraph\n\n### Phase 3: Knowledge Graph\n- **[Knowledge Graph Integration](./phases/PHASE3_COMPLETE.md)**\n  - Dependency tracking\n  - Impact analysis\n  - Usage finding\n  - Relationship mapping\n\n### Phase 4: Quality & Search\n- **[RAGAS Evaluation & Hybrid Search](./phases/PHASE4_COMPLETE.md)**\n  - RAGAS evaluation metrics\n  - Hybrid search (BM25 + semantic)\n  - A/B testing framework\n  - Query expansion\n\n---\n\n##  Use Case Guides\n\n### For Developers\n- **Codebase Navigation**: Use RAG queries to understand code\n- **Bug Fixing**: Debug agent analyzes errors automatically\n- **Code Review**: Catch issues before deployment\n- **Refactoring**: Understand impact with knowledge graph\n\n### For Teams\n- **Knowledge Sharing**: Build shared code knowledge\n- **Quality Assurance**: Automated quality checks\n- **Documentation**: Generate context-aware docs\n- **Onboarding**: Help new developers\n\n---\n\n##  Reference Documentation\n\n### API Reference\nSee [Integration Guide](../INTEGRATION_GUIDE.md) for complete API documentation including:\n- `/query` - RAG queries\n- `/debug` - Error debugging\n- `/review` - Code review\n- `/graph/build` - Build knowledge graph\n- `/graph/query` - Query knowledge graph\n- `/evaluate` - RAGAS evaluation\n- `/hybrid-search` - Hybrid search\n\n### Configuration Reference\nSee [Integration Guide - Configuration](../INTEGRATION_GUIDE.md#configuration) for:\n- `llm-config.yaml` - LLM and system configuration\n- `.env` - Environment variables\n- `.claude/mcp-config.json` - Claude Code integration\n\n---\n\n##  Tips & Best Practices\n\n### Performance Optimization\n1. **Pre-build knowledge graph** for large codebases\n2. **Tune hybrid search weights** for your specific code\n3. **Adjust chunk size** based on your needs\n4. **Use auto-trigger threshold** tuning for best results\n\n### Configuration Tips\n1. **Start with defaults** and adjust based on needs\n2. **Use local LLMs** (Ollama) for privacy\n3. **Enable caching** for better performance\n4. **Monitor metrics** via statistics endpoint\n\n### Troubleshooting\n- See [Integration Guide - Troubleshooting](../INTEGRATION_GUIDE.md#troubleshooting)\n- Check server logs: `/tmp/dt-cli-server.log`\n- Verify health: `curl http://localhost:8765/health`\n- Use interactive TUI option 7 for system stats\n\n---\n\n##  Version History\n\n### v1.0 (Current)\n**Complete feature set:**\n-  AST-based chunking\n-  BGE embeddings\n-  Auto-trigger system\n-  Debug agent\n-  Code review agent\n-  Knowledge graph\n-  RAGAS evaluation\n-  Hybrid search\n-  Interactive TUI\n-  Claude Code integration\n-  REST API\n\n---\n\n##  Contributing\n\nWant to contribute? See the [Contributing Guidelines](../README.md#-development) in the main README.\n\n### Development Documentation\n- Project structure: See [Architecture](./guides/ARCHITECTURE.md)\n- Running tests: See [Main README - Development](../README.md#-development)\n- Code style: Python PEP 8, formatted with Black\n\n---\n\n##  Support & Community\n\n### Getting Help\n- **Issues**: [GitHub Issues](https://github.com/ItMeDiaTech/dt-cli/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/ItMeDiaTech/dt-cli/discussions)\n- **Documentation**: You're reading it!\n\n### Reporting Bugs\nWhen reporting bugs, please include:\n1. dt-cli version\n2. Python version\n3. Operating system\n4. Steps to reproduce\n5. Error messages/logs\n6. Expected vs actual behavior\n\n### Feature Requests\nWe welcome feature requests! Please:\n1. Check existing issues first\n2. Describe the use case\n3. Explain why it's valuable\n4. Provide examples if possible\n\n---\n\n##  Documentation Roadmap\n\n**Upcoming documentation:**\n- Video tutorials\n- Example projects\n- Best practices guide\n- Advanced configuration guide\n- Security hardening guide\n- Performance tuning guide\n- Docker deployment guide\n- CI/CD integration guide\n\n---\n\n##  Additional Resources\n\n### External Resources\n- [sentence-transformers Docs](https://www.sbert.net/)\n- [ChromaDB Docs](https://docs.trychroma.com/)\n- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)\n- [FastAPI Docs](https://fastapi.tiangolo.com/)\n- [Rich Docs](https://rich.readthedocs.io/)\n\n### Research Papers\n- **RAG**: \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"\n- **RAGAS**: \"RAGAS: Automated Evaluation of Retrieval Augmented Generation\"\n- **BM25**: \"Okapi at TREC-3\"\n\n---\n\n##  Documentation Conventions\n\n### Code Examples\n- Bash commands use `$` prompt\n- Python code is syntax highlighted\n- Example output is shown in comments\n\n### Version Compatibility\n- All examples tested on Python 3.8+\n- API examples use curl (works on Linux/Mac/WSL)\n- Windows users: use PowerShell or Git Bash\n\n### File Paths\n- Unix-style paths (`/path/to/file`)\n- Windows users: replace `/` with `\\`\n\n---\n\n##  Learning Path\n\n**Recommended learning order:**\n\n1. **Basics** (1 hour)\n   - Read main README\n   - Try Quick Start\n   - Run interactive TUI\n\n2. **Core Features** (2-3 hours)\n   - Try each TUI menu option\n   - Read Integration Guide\n   - Experiment with API\n\n3. **Advanced** (1-2 days)\n   - Read phase documentation\n   - Configure for your codebase\n   - Tune performance\n   - Integrate with workflow\n\n4. **Expert** (Ongoing)\n   - Read architecture docs\n   - Contribute to project\n   - Share experiences\n\n---\n\n##  Finding What You Need\n\n### Quick Reference\n\n| I want to... | Go to... |\n|-------------|----------|\n| Get started quickly | [Quick Start](./guides/QUICKSTART.md) |\n| Install on Ubuntu | [Ubuntu Deployment](./guides/UBUNTU_DEPLOYMENT_GUIDE.md) |\n| Use all three modes | [Integration Guide](../INTEGRATION_GUIDE.md) |\n| Understand architecture | [Architecture](./guides/ARCHITECTURE.md) |\n| Configure LLM | [Main README - Configuration](../README.md#%EF%B8%8F-configuration) |\n| Debug issues | [Integration Guide - Troubleshooting](../INTEGRATION_GUIDE.md#troubleshooting) |\n| Learn about features | [Phase Documentation](./phases/) |\n| Contribute code | [Main README - Development](../README.md#-development) |\n\n---\n\n**Happy coding with dt-cli! **\n\nFor questions or feedback, please open an issue or discussion on GitHub.\n"
      },
      "plugins": [
        {
          "name": "rag-multi-agent-framework-plugin",
          "version": "1.0.0",
          "description": "Local RAG plugin with Multi-Agent Framework orchestration for context-aware development assistance",
          "author": {
            "name": "ItMeDiaTech",
            "email": "",
            "url": "https://github.com/ItMeDiaTech"
          },
          "repository": "https://github.com/ItMeDiaTech/dt-cli",
          "source": "./",
          "category": "productivity",
          "keywords": [
            "rag",
            "retrieval-augmented-generation",
            "vector-search",
            "embeddings",
            "multi-agent",
            "maf",
            "mcp",
            "semantic-search",
            "code-analysis",
            "local-ai"
          ],
          "license": "MIT",
          "tags": [
            "official",
            "rag",
            "multi-agent",
            "local"
          ],
          "categories": [
            "code-analysis",
            "embeddings",
            "local",
            "local-ai",
            "maf",
            "mcp",
            "multi-agent",
            "official",
            "productivity",
            "rag",
            "retrieval-augmented-generation",
            "semantic-search",
            "vector-search"
          ],
          "install_commands": [
            "/plugin marketplace add ItMeDiaTech/dt-cli",
            "/plugin install rag-multi-agent-framework-plugin@itmediatech-plugin-marketplace"
          ]
        }
      ]
    }
  ]
}